[{"type": "text", "text": "BMRS: Bayesian Model Reduction for Structured Pruning ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Dustin Wright, Christian Igel, and Raghavendra Selvan Department of Computer Science, University of Copenhagen {dw,igel,raghav}@di.ku.dk ", "page_idx": 0}, {"type": "text", "text": "Abstract ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Modern neural networks are often massively overparameterized leading to high compute costs during training and at inference. One effective method to improve both the compute and energy efficiency of neural networks while maintaining good performance is structured pruning, where full network structures (e.g. neurons or convolutional fliters) that have limited impact on the model output are removed. In this work, we propose Bayesian Model Reduction for Structured pruning (BMRS), a fully end-to-end Bayesian method of structured pruning. BMRS is based on two recent methods: Bayesian structured pruning with multiplicative noise, and Bayesian model reduction (BMR), a method which allows efficient comparison of Bayesian models under a change in prior. We present two realizations of BMRS derived from different priors which yield different structured pruning characteristics: 1) $\\mathrm{BMRS}_{\\mathcal{N}}$ with the truncated log-normal prior, which offers reliable compression rates and accuracy without the need for tuning any thresholds and 2) $\\mathbf{B}\\mathbf{M}\\mathbf{R}\\mathbf{S}_{\\mathcal{U}}$ with the truncated log-uniform prior that can achieve more aggressive compression based on the boundaries of truncation. Overall, we find that BMRS offers a theoretically grounded approach to structured pruning of neural networks yielding both high compression rates and accuracy. Experiments on multiple datasets and neural networks of varying complexity showed that the two BMRS methods offer a competitive performance-efficiency trade-off compared to other pruning methods.1 ", "page_idx": 0}, {"type": "text", "text": "1 Introduction ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Modern neural networks come with an increasing computational burden, as scale is often seen to be associated with performance [34]. The response to this has been a focus on research around the topic of neural network efficiency [3], where the goal is to reduce the computational cost of a system while maintaining other desirable metrics. As such, selecting a method to improve efficiency comes with many tradeoffs, including how to balance compute and energy consumption with accuracy [35]. ", "page_idx": 0}, {"type": "text", "text": "Neural network pruning seeks to do this by removing parts of a network which have limited impact on its output. This comes in two primary forms: unstructured pruning, where individual weights are removed, and structured pruning, where entire neural network structures such as neurons and convolutional fliters are removed [27]. Structured pruning is often desirable as unstructured pruning can result in sparse computations which are energy intensive on current hardware, while structured pruning can maintain more energy efficient dense operations [14, 17, 31]. Many ways to perform structured pruning have been proposed, but the challenge of how to appropriately balance accuracy and complexity in a principled manner has remained. ", "page_idx": 0}, {"type": "text", "text": "In this work, we address this challenge by proposing BMRS: Bayesian Model Reduction for Structured pruning. BMRS is a principled method based on combining two complementary lines of work: Bayesian structured pruning with multiplicative noise [30] and Bayesian model reduction (BMR) [6], a method of efficient Bayesian model comparison under a change in prior. Multiplicative noise allows one to flexibly induce sparsity at any structural level without the need to use computationally complex spike-and-slab priors [16, 29], while BMR enables principled pruning rules without the need for task-specific threshold tuning. Starting with the approach from [30], we derive two versions of BMRS using different priors which offer their own benefits. $\\mathrm{BMRS}_{\\mathcal{N}}$ is based on the truncated log-normal prior and has the benefti of achieving a high compression rate without needing to tune a threshold for compression, while $\\mathbf{B}\\mathbf{M}\\mathbf{R}\\mathbf{S}_{\\mathcal{U}}$ offers tunable compression by controlling the allowable precision of noise variables in the network. In sum, our contributions are: ", "page_idx": 0}, {"type": "image", "img_path": "ktpG37Dzh5/tmp/02ad35f018b9c0d32125acf5075ed483ea9686d01d4ad3b450915655187e88db.jpg", "img_caption": ["Figure 1: BMRS uses BMR to perform structured pruning under multiplicative noise by calculating the change in log-evidence of noise variables $\\theta$ under a prior which would shrink them to 0. "], "img_footnote": [], "page_idx": 1}, {"type": "text", "text": "", "page_idx": 1}, {"type": "text", "text": "\u2022 BMRS: a method for Bayesian structured pruning based on multiplicative noise and Bayesian model reduction;   \n\u2022 Derivations of pruning algorithms for two priors with theoretical motivation;   \n\u2022 Empirical results on a range of neural networks and datasets demonstrating high compression rates without any threshold tuning, with more extreme compression achievable via a parameter controlling allowable precision. ", "page_idx": 1}, {"type": "text", "text": "2 Related work ", "text_level": 1, "page_idx": 1}, {"type": "text", "text": "The primary goal of neural network pruning is to determine the elements of a network which can be removed with minimal impact on the output. Ideally, a pruning method ranks all elements in the order in which they can be removed and provides a criterion for truncating the resulting ordered list. Since the early works on gradient based methods for pruning [23, 12], the literature around neural network pruning has expanded rapidly, with the two main lines of work exploring pruning individual weights (unstructured pruning) and pruning full network structures (structured pruning). For a recent survey, see [27]. The closest related works to ours are those pruning methods which perform Bayesian pruning [30, 28, 10, 16, 26], and those which use Bayesian model reduction to determine what elements to remove from a neural network [5, 29]. ", "page_idx": 1}, {"type": "text", "text": "Bayesian pruning. Bayesian structured pruning was first explored in Kingma et al. [20], where the authors demonstrate that dropout has a Bayesian interpretation as multiplicative noise with a sparsity inducing prior. The studies of [30, 28, 10] follow this work by explicitly modeling the random noise in dropout with different priors, [30] using a truncated log-uniform prior and [28, 10] using horseshoe priors. Following this, the works of [2, 15, 16, 33, 29, 26] have explored pruning of Bayesian neural networks (BNNs) with spike-and-slab priors to induce both weight sparsity and group sparsity with flat and hierarchical priors, respectively. [16] demonstrate that thresholdless pruning is achievable by placing an explicit spike-and-slab prior on the nodes of a BNN to induce group sparsity. However, this setup requires complex and carefully constructed posteriors due to the discrete nature of spike-and-slab distributions and is thus computationally inefficient [29, 16]. ", "page_idx": 1}, {"type": "text", "text": "Bayesian model reduction. Bayesian model reduction, discussed in detail in $\\S3.2$ , is an efficient method of Bayesian model comparison which allows for analytic solutions for the model evidence under a change in priors. BMR has found application across multiple scientific disciplines [9, 8, 18], and has recently been used as a method for neural network pruning [29, 5]. More specifically, [5] demonstrate the benefits of BMR-based pruning for the case of a BNN with a Gaussian prior on the weights, and [29] demonstrate the utility of BMR for unstructured pruning of BNNs with priors inducing both weight and group sparsity. ", "page_idx": 1}, {"type": "text", "text": "", "page_idx": 2}, {"type": "text", "text": "3 Problem formulation ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "3.1 Structured pruning with multiplicative noise and variational inference ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "We approach the problem of structured pruning using sparsity inducing multiplicative noise as described in [30]. In this setting, we have a dataset consisting of $N$ i.i.d. input-output pairs, $\\mathcal D\\,=\\,\\{(\\mathbf{x}_{j},y_{j})\\ \\forall j\\,=\\,1,\\ldots,N\\}$ . We consider a parametric model, here a deep neural network, that maps the input data $\\mathbf{x}_{j}$ to their output $y_{j}$ using the trainable parameters W giving rise to the likelihood function $\\begin{array}{r}{p(\\mathcal{D}|\\boldsymbol{\\Theta},\\mathbf{W})=\\prod_{j=1}^{N}p(\\dot{y_{j}}|\\mathbf{x}_{j},\\boldsymbol{\\Theta},\\mathbf{W})}\\end{array}$ . In addition to the trainable weights, W, the model consists of the sparsity inducing multiplicative noise given by the random variable, $\\Theta$ , with prior $p(\\Theta)$ . This is in contrast to BNNs where the weights are random variables but aligns with the setting when using multiplicative noise for Bayesian pruning [30]. ", "page_idx": 2}, {"type": "text", "text": "The effect of the multiplicative noise $\\theta_{i}\\in\\Theta$ for a structural element in a neural network with index $i$ , parameters $\\mathbf{w}_{i}$ , and input $\\mathbf{h}_{i-1}$ is given as ", "page_idx": 2}, {"type": "equation", "text": "$$\n\\mathbf{h}_{i}=\\theta_{i}\\cdot(\\mathbf{w}_{i}\\mathbf{h}_{i-1})\\quad,\\quad\\theta_{i}\\sim p(\\theta_{i}).\n$$", "text_format": "latex", "page_idx": 2}, {"type": "text", "text": "We note that $\\mathbf{w}_{i}$ could be the parameters of any structural element in the network, for example, a single neuron or an entire convolutional filter. Given this, we would like to learn the maximum likelihood estimate (MLE) $\\hat{\\mathbf{w}}_{i}$ of the weights as well as the posterior distribution over the multiplicative noise, $p(\\theta_{i}|\\mathcal{D},\\hat{\\mathbf{w}}_{i})$ , when using a sparsity inducing prior $p(\\theta_{i})$ such that $\\theta_{i}$ favors values closer to 0. ", "page_idx": 2}, {"type": "text", "text": "Following [30], the neural network weights are learned via gradient descent as in standard deep learning model optimization. The posterior distribution, $p(\\theta|\\mathcal{D},\\mathbf{\\bar{w}}_{i})=p(\\mathcal{D}|\\theta_{i},\\hat{\\mathbf{w}}_{i})p(\\theta_{i})/p(\\mathcal{D})$ , however, is intractable. We resort to a variational approximation from a tractable family of approximating distributions, $q_{\\phi}(\\theta)$ , parameterized by $\\phi$ (for the sake of brevity we do not indicate the dependence on $\\mathbf{w}_{i}$ and omit the subscript $i$ ). The parameters $\\phi$ are obtained by optimizing the following objective w.r.t. $\\theta$ : ", "page_idx": 2}, {"type": "equation", "text": "$$\n\\mathrm{F}[p,q]=D_{\\mathrm{KL}}[q_{\\phi}(\\theta)||p(\\theta|\\mathcal{D})]\\stackrel{c}{=}D_{\\mathrm{KL}}[q_{\\phi}(\\theta)||p(\\theta)]-\\mathbb{E}_{q_{\\phi}}[\\log p(y_{j}|\\mathbf{x}_{j},\\theta,\\hat{\\mathbf{w}})]\n$$", "text_format": "latex", "page_idx": 2}, {"type": "text", "text": "This is the commonly used variational free energy (VFE) or negative evidence lower bound (ELBO) [4]. Here $\\underline{{\\underline{{c}}}}$ denotes equality up to a positive constant. ", "page_idx": 2}, {"type": "text", "text": "The expectation $\\mathbb{E}_{q_{\\phi}}[\\cdot]$ is approximated by a Monte Carlo estimator acting on minibatch samples from $\\mathcal{D}$ , and reparameterization allows to backpropagate gradients through stochastic variables [19, 28]. Under this reparameterization, the variational distribution, $q_{\\phi}(\\theta)$ , becomes a deterministic function of the non-parametric noise $\\epsilon\\sim p(\\epsilon)$ and the VFE is calculated as ", "page_idx": 2}, {"type": "equation", "text": "$$\n\\mathrm{F}[p,q]\\stackrel{c}{=}D_{\\mathrm{KL}}[q_{\\phi}(\\theta)||p(\\theta)]-\\sum_{(x_{j},y_{j})\\in\\mathcal{D}}\\log p(y_{j}|x_{j},\\theta=f(\\phi,\\epsilon);\\hat{\\mathbf{w}}),\n$$", "text_format": "latex", "page_idx": 2}, {"type": "text", "text": "where $f$ is a function that allows us to sample $\\theta$ via deterministic parameters $\\phi$ and the non-parametric stochastic variable, $\\epsilon$ . Optimization of Equation 3 allows us to jointly learn $\\hat{\\mathbf{w}}$ and $\\theta$ . The particular choice of priors and the approximating distributions to induce sparsity are discussed in $\\S4.1$ . ", "page_idx": 2}, {"type": "text", "text": "3.2 Bayesian model reduction ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "Bayesian model reduction (BMR) allows one to efficiently compute the change in VFE (Equation 2) under a change in prior without the need to re-estimate model parameters. To perform pruning, one can start out by selecting a broad prior for the original model estimation and then pick a narrower prior (i.e. reduced prior) with the density concentrated around 0. Then, BMR can be used to determine if the VFE is greater under the reduced model, and prune those parameters for which this condition holds. We briefly describe how this is achieved in the general case, followed by the specific realization for BMRS in $\\S4.2$ ; for further details see [6]. ", "page_idx": 2}, {"type": "text", "text": "Consider the likelihood function $p({\\mathcal{D}}|\\theta)$ and a prior $p(\\theta)$ on the variable $\\theta$ . We can introduce a new prior $\\tilde{p}(\\theta)$ which shares the same likelihood as the original model (i.e. $p(\\mathcal{D}|\\theta)=\\tilde{p}(\\mathcal{D}|\\theta))$ and get: ", "page_idx": 2}, {"type": "equation", "text": "$$\np(\\mathcal{D}|\\theta)=\\frac{p(\\theta|\\mathcal{D})p(\\mathcal{D})}{p(\\theta)}=\\frac{\\tilde{p}(\\theta|\\mathcal{D})\\tilde{p}(\\mathcal{D})}{\\tilde{p}(\\theta)}\\Rightarrow\\tilde{p}(\\theta|\\mathcal{D})=\\frac{p(\\mathcal{D})}{\\tilde{p}(\\mathcal{D})}p(\\theta|\\mathcal{D})\\frac{\\tilde{p}(\\theta)}{p(\\theta)}\n$$", "text_format": "latex", "page_idx": 2}, {"type": "text", "text": "By marginalizing over $\\theta$ and taking the log, we obtain the difference in log evidence as: ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\log\\tilde{p}(\\mathcal{D})-\\log p(\\mathcal{D})=\\log\\int p(\\theta|\\mathcal{D})\\frac{\\tilde{p}(\\theta)}{p(\\theta)}d\\theta\\approx\\log\\int q_{\\phi}(\\theta)\\frac{\\tilde{p}(\\theta)}{p(\\theta)}d\\theta=\\log\\mathbb{E}_{\\tilde{p}}\\left[\\frac{q_{\\phi}(\\theta)}{p(\\theta)}\\right]\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "More concisely, we call the change in log evidence $\\Delta F$ and thus have: ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\Delta F\\triangleq\\log\\tilde{p}(\\mathcal{D})-\\log p(\\mathcal{D})\\approx\\log\\mathbb{E}_{\\tilde{p}}\\left[\\frac{q_{\\phi}(\\theta)}{p(\\theta)}\\right]\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "If the new prior, ${\\tilde{p}}(\\theta)$ , is selected so that $\\theta$ would be removed, pruning can be performed when $\\Delta F\\geq0$ . Additionally, when the type of distributions between $p(\\theta),\\tilde{p}(\\theta)$ , and $q_{\\phi}(\\theta)$ are the same or similar (e.g. Gaussian), $\\Delta F$ can be calculated efficiently in closed form (see [7]). ", "page_idx": 3}, {"type": "text", "text": "We presented BMR for a general likelihood function $p({\\mathcal{D}}|\\theta)$ ; it holds analogously for the likelihood function $p(\\mathcal{D}|\\theta,\\mathbf{W})$ introduced with the multiplicative noise described in $\\S3.1$ . ", "page_idx": 3}, {"type": "text", "text": "4 Bayesian model reduction for structured pruning (BMRS) ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "Our goal is to derive a principled structured pruning algorithm starting from the general formulation in $\\S\\ 3$ which can automatically determine which structures to prune. BMRS accomplishes this by following the multiplicative noise setup in [30] with BMR used on the noise terms. Figure 1 illustrates the general approach, where $\\Delta F$ is calculated for a model trained with multiplicative noise under a reduced prior, and elements of the model are removed if the new VFE is greater. We next describe the multiplicative noise layer trained using Equation 2, and then derive two variants of BMRS from Equation 6 using different reduced priors. ", "page_idx": 3}, {"type": "text", "text": "4.1 Multiplicative noise layer ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "The concept of multiplicative noise inducing sparsity in neural networks was first introduced with variational dropout, where [20] show that dropout has a Bayesian interpretation as multiplicative noise with a log-uniform prior. One can use this interpretation of dropout in order to explicitly learn dropout parameters, $\\theta_{i}$ , as in $\\S3$ , by selecting appropriate prior and variational distributions and optimizing Equation 2 directly. [30] propose to do so by using the truncated log-uniform distribution as a prior and the truncated log-normal distribution as the variational distribution. As such, the variational approximation can be performed using ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\mathbf{h}_{i}=\\theta_{i}\\cdot(\\mathbf{w}_{i}\\mathbf{h}_{i-1});\\quad q_{\\phi}(\\theta_{i})=\\mathrm{LogN}_{[a,b]}(\\theta_{i}|\\mu_{i},\\sigma_{i}^{2});\\quad p(\\theta_{i})=\\mathrm{LogU}_{[a,b]}(\\theta_{i})\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "with bounded support between $a$ and $b$ and $0<a<b\\le1$ . We refer to [30] for details on how to learn $q_{\\phi}$ , which is obtained by optimizing Equation 3. ", "page_idx": 3}, {"type": "text", "text": "The log-uniform distribution serves as a sparsity inducing prior as most of its density is concentrated around 0 (see panel 2 in Figure 1). Additionally, it acts as a regularizer on the floating point precision of the multiplicative noise terms [20]. In [30] this is used to perform structured pruning by removing all structures $\\mathbf{h}_{i}$ where the signal-to-noise ratio of the noise term $\\theta_{i}$ falls below a pre-defined threshold. We next show how to derive principled pruning algorithms based on BMR which induce sparsity while maintaining accuracy without the need for tuning pruning thresholds. ", "page_idx": 3}, {"type": "text", "text": "4.2 Deriving BMRS ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "Our goal is to use BMR in order to perform structured pruning of models trained with multiplicative noise. To do so, we must select a new prior $\\tilde{p}(\\theta)$ from which we can: 1) induce sparsity; 2) efficiently calculate $\\Delta F$ and; 3) prune the network while maintaining good performance. ", "page_idx": 3}, {"type": "text", "text": "Selecting the reduced prior, $\\tilde{p}(\\theta)$ , is straightforward when the prior and approximate posterior are the same type of distributions. For example, in a fully BNN where one assumes a prior distribution of $\\mathcal{N}(\\Theta|\\mathbf{0},\\mathbf{I})$ over all the model weights with a mean-field variational approximation resulting in a factorisation over individual weights, $\\bar{N}(\\theta|\\mu,\\sigma^{2})$ , the three criteria above can be met when one selects a Gaussian reduced prior with slight variance around 0 i.e. $\\mathcal{N}(\\theta|0,\\epsilon),\\epsilon\\approx0$ .2 However, in the case of multiplicative noise, our prior and variational distributions are of different types and thus the selection of the reduced prior is not immediately obvious. Here, we derive and compare the characteristics of two different reduced priors: one based on a truncated log-normal distribution, which we can use to approximate a Dirac delta at $)\\;(\\mathrm{BMRS}_{\\mathcal{N}})$ ), and one based on a truncated log-uniform distribution with reduced support $(\\mathbf{B}\\mathbf{M}\\mathbf{R}\\mathbf{S}_{\\mathcal{U}}$ ). ", "page_idx": 3}, {"type": "text", "text": "", "page_idx": 4}, {"type": "text", "text": "4.2.1 BMRS with log-normal reduced prior $({\\bf B M R S}_{\\mathcal{N}})$ ) ", "text_level": 1, "page_idx": 4}, {"type": "text", "text": "First, we derive $\\Delta F$ when using the log-uniform distribution as the original prior, $p(\\theta)\\ =$ $\\mathrm{LogU}_{[a,b]}(\\theta)$ , and the truncated log-normal distribution as the reduced prior, $\\begin{array}{r l r}{{\\tilde{p}}(\\theta)}&{{}=}&{}\\end{array}$ $\\mathrm{LogN}_{[a,b]}(\\theta|\\tilde{\\mu}_{p},\\tilde{\\sigma}_{p}^{2})$ . We select a truncated log-normal distribution, as it matches the variational distribution $q_{\\phi}(\\theta)$ , and the log-uniform prior, because it is a special case of the log-normal distribution when the variance goes to infinity. Because of this, we expect that $\\Delta F$ will have a closed form solution, and that the computation will be efficient. We briefly present the results of the derivation here; for the full derivation see $\\S\\mathrm{~A.l~}$ . ", "page_idx": 4}, {"type": "text", "text": "We can use the specific forms of $p(\\theta)$ and $\\tilde{p}(\\theta)$ for the truncated log-uniform and truncated log-normal distributions, respectively, in Equation 6 to determine $\\Delta F$ : ", "page_idx": 4}, {"type": "text", "text": "$\\Delta F\\approx\\log\\mathbb{E}_{\\tilde{p}}\\left[\\frac{q_{\\phi}(\\theta)}{p(\\theta)}\\right]=\\log\\frac{Z_{\\tilde{q}}(\\log b-\\log a)}{Z_{\\tilde{p}}Z_{q}}+\\frac{1}{2}\\log\\frac{\\tilde{\\sigma}_{q}^{2}}{2\\pi\\tilde{\\sigma}_{p}^{2}\\sigma_{q}^{2}}-\\frac{1}{2}\\left(\\frac{\\mu_{q}^{2}}{\\sigma_{q}^{2}}+\\frac{\\tilde{\\mu}_{p}^{2}}{\\tilde{\\sigma}_{p}^{2}}-\\frac{\\tilde{\\mu}_{q}^{2}}{\\tilde{\\sigma}_{q}^{2}}\\right)$ (8) with $\\tilde{\\sigma}_{q}^{2}\\;=\\;\\left(\\frac{1}{\\sigma_{q}^{2}}+\\frac{1}{\\tilde{\\sigma}_{p}^{2}}\\right)^{-1}$ and $\\tilde{\\mu}_{q}\\;=\\;\\tilde{\\sigma}_{q}^{2}\\left(\\frac{\\mu_{q}}{\\sigma_{q}^{2}}+\\frac{\\tilde{\\mu}_{p}}{\\tilde{\\sigma}_{p}^{2}}\\right)$ Here, $Z_{p}\\,=\\,\\Phi(\\beta_{p})\\,-\\,\\Phi(\\alpha_{p});\\,\\Phi(t)\\,=$ $\\textstyle{\\frac{1}{2}}[1+\\operatorname{erf}({\\frac{t}{\\sqrt{2}}})]$ is the CDF of the standard Normal distribution, $t\\sim\\mathcal{N}(0,1)$ ; $\\alpha_{p}=(a-\\mu_{p})/\\sigma_{p}$ ; and $\\beta_{p}=(\\dot{b}-\\mu_{p})/\\sigma_{p}$ . ", "page_idx": 4}, {"type": "text", "text": "As can be seen from Equation 8, the calculation for $\\Delta F$ can be performed directly using only the statistics of the priors and variational distribution. In order for Equation 8 to induce sparsity, we must select a $\\tilde{\\mu}_{p}$ and $\\bar{\\tilde{\\sigma}}_{p}^{2}$ that effectively collapse $\\theta$ to 0. To achieve this, we can approximate a Dirac delta at 0 by selecting $\\tilde{\\mu}_{p}$ to be close to 0 (e.g., the lower bound of truncation $a$ ), and $\\tilde{\\sigma}_{p}^{2}$ to be sufficiently small. We will demonstrate in $\\S5$ that this reduced prior results in high sparsity while maintaining performance without any need for tuning pruning thresholds. ", "page_idx": 4}, {"type": "text", "text": "4.2.2 BMRS with log-uniform reduced prior $(\\mathbf{B}\\mathbf{M}\\mathbf{R}\\mathbf{S}_{\\mathcal{U}}$ ) ", "text_level": 1, "page_idx": 4}, {"type": "text", "text": "Next, we derive the change in VFE, $\\Delta F$ , when using a truncated log-uniform distribution as the original prior, $p(\\theta)=\\mathbf{Log}\\mathbf{\\bar{U}}_{[a,b]}(\\theta)$ , and a truncated log-uniform distribution with reduced support as the reduced prior, $\\tilde{p}(\\theta)=\\mathrm{LogU}_{[a^{\\prime},b^{\\prime}]}(\\theta)$ . We select a reduced truncated log-uniform distribution for the same reasons as the truncated log-normal: we expect that $\\Delta F$ will have an efficiently calculable closed form, given that the priors are of the same type and are a special case of the variational distribution. The PDF of the reduced truncated log-uniform distribution is given as follows: ", "page_idx": 4}, {"type": "equation", "text": "$$\n{\\tilde{p}}(\\theta)=\\mathop{\\mathrm{Log}}\\!{\\mathrm{U}}_{[a^{\\prime},b^{\\prime}]}(\\theta)=\\left\\{\\left(\\theta\\log\\frac{b^{\\prime}}{a^{\\prime}}\\right)^{-1},\\quad a<a^{\\prime}\\leq\\theta\\leq b^{\\prime}<b\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "Using this, we can directly solve the integral under the expectation given in Equation 6 for $\\Delta F$ (full details in $\\S\\ A.2)$ : ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\exp\\Delta F\\approx\\mathbb{E}_{\\Tilde{p}}\\left[\\frac{q_{\\phi}(\\theta)}{p(\\theta)}\\right]=\\int_{a}^{b}\\mathrm{LogU}_{[a^{\\prime},b^{\\prime}]}(\\theta)\\frac{q_{\\phi}(\\theta)}{\\mathrm{LogU}_{[a,b]}(\\theta)}d\\theta=\\frac{\\log\\frac{b}{a}}{\\log\\frac{b^{\\prime}}{a^{\\prime}}}q_{\\phi}(a^{\\prime}\\leq\\theta_{i}\\leq b^{\\prime})\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "where $q_{\\phi}(a^{\\prime}\\leq\\theta_{i}\\leq b^{\\prime})$ is the CDF of the variational distribution evaluated between $a^{\\prime}$ and $b^{\\prime}$ . We know from Equation 5 that the VFE under $\\tilde{p}(\\theta)$ is greater when $\\exp\\Delta F\\geq1$ . Plugging this in: ", "page_idx": 4}, {"type": "equation", "text": "$$\n1\\leq\\frac{\\log\\frac{b}{a}}{\\log\\frac{b^{\\prime}}{a^{\\prime}}}q_{\\phi}(a^{\\prime}\\leq\\theta_{i}\\leq b^{\\prime})\\Rightarrow\\frac{\\log\\frac{b^{\\prime}}{a^{\\prime}}}{\\log\\frac{b}{a}}\\leq q_{\\phi}(a^{\\prime}\\leq\\theta\\leq b^{\\prime})\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "Here, the left hand side of the inequality is the CDF of the truncated log-uniform distribution between $a^{\\prime}$ and $b^{\\prime}$ . In other words, when the new prior is a log-uniform distribution with reduced support, input :dataset $\\mathcal{D}$ ; neural network with deterministic weights W and variational parameters $\\phi$ ; original prior $\\mathfrak{p}(\\Theta)$ ; reduced prior $\\tilde{p}(\\Theta)$ ; number of training epochs $e_{T}$ ; number of fine-tuning epochs $e_{F}$ ; number of pruning epochs $P$ ", "page_idx": 4}, {"type": "text", "text": "", "page_idx": 5}, {"type": "image", "img_path": "ktpG37Dzh5/tmp/2907446470fb0ae95bda4867d1ae6e9fb51241fa62ffe1841dd80ef50314dc7e.jpg", "img_caption": [], "img_footnote": [], "page_idx": 5}, {"type": "text", "text": "the BMR pruning criterion amounts to a comparison between the CDF of the original prior and the variational distribution along the interval $\\bar{[}\\bar{a}^{\\prime},b^{\\prime}]$ . Additionally, Equation 11 shows that this is generalizable to any variational distribution with support broader than the reduced prior. ", "page_idx": 5}, {"type": "text", "text": "$\\mathbf{BMRS}_{\\mathcal{U}}$ pruning and connection to floating point precision. To see how $\\mathbf{B}\\mathbf{M}\\mathbf{R}\\mathbf{S}_{\\mathcal{U}}$ can be used for pruning, we first briefly summarize the relationship between the log-uniform distribution and floating point numbers. Floating point numbers are commonly encoded in binary as a combination of a sign bit $s$ , a set of exponent bits $e$ , and a set of mantissa bits $m$ denoting the fractional part of a real-number: $r=s\\cdot(\\dot{m}/2^{p-1})\\cdot2^{e}$ , where $p$ determines the precision of the encoding. As discussed in [11], the mantissae of \u201cnaturally observed\u201d floating point numbers (e.g., natural constants) tend to follow a log-uniform distribution and repeated multiplications/divisions on a digital computer transform a broad class of distributions towards a log-uniform distribution ", "page_idx": 5}, {"type": "equation", "text": "$$\nm\\sim\\left(m\\log B\\right)^{-1},\\quad1/B\\leq m\\leq1,\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "where $B$ is the base of the number system. In the case where the mantissa uses $p$ bits, there are $2^{p}$ representable fractional numbers so $B=2^{p}$ . As such, $p$ determines the smallest fractional value which can be represented. We can use this to have the reduced prior cover a finite range of high precision values which are acceptable to prune. To accomplish this, we use a reduced log-uniform prior of the following form by selecting two integers $p_{1},p_{2}$ where $0\\le p_{1}<p_{2}$ : ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\tilde{p}(\\theta)=\\left\\{\\left(\\theta\\log\\frac{2^{p_{2}}}{2^{p_{1}}}\\right)^{-1},\\quad1/2^{p_{2}}\\leq\\theta\\leq1/2^{p_{1}}\\right.\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "Thus we can reduce the prior to a range of precision between $p_{1}$ and $p_{2}$ by selecting $a^{\\prime}=1/2^{p_{2}}$ and $b^{\\prime}=1/2^{p_{1}}$ . Equation 11 then has a natural interpretation as comparing the probability of drawing a random mantissa from the interval $[1/2^{p_{2}},1/2^{\\bar{p_{1}}}]$ to the probability of drawing a value within that interval from the variational distribution. If we select $p_{2}$ to be the limit of the precision of values in the number system used $y_{2}=23$ for single-point precision), then we can interpret $p_{1}$ as determining the prunable range of precision of all variables $\\Theta$ . The accuracy-complexity tradeoff inherent in the selection of ${\\tilde{p}}(\\theta)$ is then controlled through $p_{1}$ , the desired cutoff of the precision of the network. ", "page_idx": 5}, {"type": "text", "text": "4.3 Training and pruning ", "text_level": 1, "page_idx": 5}, {"type": "text", "text": "The details on how to train a network and use BMRS for pruning are given in Algorithm 1. We train a model for a fixed number of epochs (or until convergence) and perform pruning every $P$ epochs. This lends itself to either post-training pruning, where the network is fully trained followed by pruning and fine-tuning, or continuous pruning, where pruning is performed during model training. In our experiments, we explore both of these setups and contrast BMRS with alternative pruning methods. ", "page_idx": 5}, {"type": "text", "text": "5 Experiments ", "text_level": 1, "page_idx": 6}, {"type": "text", "text": "We demonstrate the pruning behavior of BMRS through several experiments with neural networks of varying complexity measured as the number of trainable parameters. We use the following datasets (full details in Appendix B): MNIST [22], Fashion-MNIST [37], CIFAR10 [21], and TinyImagenet. For MNIST, Fashion-MNIST, and CIFAR10 we experiment with both a multi-layer perceptron (MLP) and a small CNN (Lenet5 [24]). Pruning layers are applied after each fully connected layer for the MLP, and for each convolutional filter and fully connected layer for Lenet5. For CIFAR10 and TinyImagenet, we further experiment with a pretrained ResNet-50 [13] and a pretrained vision transformer (ViT) [36]. For ResNet-50, we apply pruning layers after each layer of batch normalization, and for ViT we apply pruning layers to the output of each transformer block. For the multiplicative noise layers, we set the left bound of truncation to be $\\log a=-20$ and the right bound of truncation to be $\\log b=0$ . Hyperparameters for the MLPs and Lenet5 are tuned on a model with no pruning performed and kept the same for each variant (see Appendix C). We perform experiments using the following model variants and baselines which cover both Bayesian pruning criteria (e.g. ours, SNR, and $\\mathbb{E}_{q_{\\phi}}[\\theta])$ as well as magnitude pruning (L2): ", "page_idx": 6}, {"type": "text", "text": "\u2022 None: A baseline with no compression and no multiplicative noise. ", "page_idx": 6}, {"type": "text", "text": "\u2022 L2: A magnitude pruning baseline based on the L2 Norm of weight vectors (matrices in the case of convolutional fliters) at the input of each neuron to be pruned [25]. We set the pruning threshold to the compression rate achieved by $\\mathrm{BMRS}_{\\mathcal{N}}$ using the same settings of a given experiment.   \n\u2022 $\\mathbb{E}_{q_{\\phi}}[\\theta]$ : The expected value of noise variables $\\theta$ . For continuous pruning, we use a set threshold of 0.1.   \n\u2022 SNR: The signal-to-noise ratio $\\mathbb{E}_{q_{\\phi}}[\\theta]/\\sqrt{\\mathrm{Var}[\\theta]}$ as used in [30]. For continuous pruning, we use a set threshold of 1 as recommended in [30].   \n\u2022 $\\mathbf{BMRS}_{\\mathcal{N}}$ : BMRS using the log-normal prior from Equation 6. In order to reduce the prior to 0, we set $\\tilde{\\mu}_{p}$ to the left bound of truncation $(a)$ , and $\\tilde{\\sigma}_{p}^{2}$ to $\\mathrm{i0^{-12}}$ .   \n\u2022 $\\mathbf{B}\\mathbf{M}\\mathbf{R}\\mathbf{S}_{\\mathcal{U}}\\!-\\!p_{1}$ : BMRS using the log-uniform prior from Equation 11. In our experiments, we set $a^{\\prime}$ to be the limit of the precision of single-point floats $\\mathcal{p}_{2}=23$ so $a^{\\prime}=1/2^{23}$ ) and $b^{\\prime}$ to either $p_{1}=$ 8-bit precision $(b^{\\prime}=\\dot{1}/2^{8})$ ) or $p_{1}=4$ -bit $\\begin{array}{r}{\\hat{(b^{\\prime}=1/2^{4})}}\\end{array}$ ). ", "page_idx": 6}, {"type": "text", "text": "Post-training pruning. We first look at the behavior of BMRS when used in the post-training setting. To do so, we first train a model on a given dataset, then use each method to rank the neurons based on their pruning function (L2 norm, signal-to-noise ratio, or $\\Delta F$ ). To observe the accuracy at different compression rates, neurons are progressively removed based on their rank, and the model is fine-tuned for one epoch before measuring the test accuracy. For BMRS methods, we additionally stop pruning once $\\Delta F\\,<\\,0$ for a given structure. The plots of accuracy vs. compression for 10 different random seeds are given in Figure 2 (Further experiments given in Appendix E). ", "page_idx": 6}, {"type": "text", "text": "First, we find that BMRS generally stops compressing near the knee point of the trade-off curve \u2013 a preferred solution of a Pareto front if there is no a priori preferences \u2013 in all settings except for $\\mathbf{B}\\mathbf{M}\\mathbf{R}\\mathbf{S}_{\\mathcal{U}}$ -4 which only does so in 4 out of 6 settings. Notably, $\\mathrm{BMRS}_{\\mathcal{N}}$ accomplishes this with no need to tune additional thresholds as is common in pruning literature. To further visualize this, the right plot in each subfigure shows a scatter plot of the accuracy at the maximum compression rate (pruning all neurons where $\\Delta F\\geq0]$ ) along with the curve of accuracy vs. compression for SNR pruning near the knee point. We can see that the density of points for BMRS is concentrated near the optimal point in all cases except for the MLP on MNIST, indicating the robustness of the proposed methods. ", "page_idx": 6}, {"type": "text", "text": "We additionally observe much similarity in the curves for BMRS and SNR pruning, suggesting that they may be performing similar functions. To further investigate this, we look at the Spearman rank correlation coefficient [32] of the neurons based on their respective functions in Figure 3 (plots for additional datasets in Appendix E). We see that $\\mathrm{BMRS}_{\\mathcal{N}}$ tends to have a high correlation with SNR, suggesting that it learns a qualitatively similar function with the benefit of providing a threshold for compression. $\\mathbf{B}\\mathbf{M}\\mathbf{R}\\mathbf{S}_{\\mathcal{U}}$ , on the other hand, tends to have very low or even negative correlation. This, combined with the more rapidly declining accuracy for a given level of compression, suggests that $\\mathbf{B}\\mathbf{M}\\mathbf{R}\\mathbf{S}_{\\mathcal{U}}$ is only apt for determining a single split into elements to keep and to remove, but does not provide an accurate ranking of the elements.. ", "page_idx": 6}, {"type": "image", "img_path": "ktpG37Dzh5/tmp/f8eb17e72c482f28757a5ac8bd8c15505f8bff7170a7c1711113c9f6877459dd.jpg", "img_caption": ["Figure 2: Accuracy vs. compression for post-training pruning on CIFAR10, Fashion-MNIST, and MNIST. The left plot in each subfigure shows the average accuracy across 10 seeds, shading shows the standard deviation. For BMRS, we mark the maximum compression rate based on when $\\Delta F\\geq0$ . The right plot in each subfigure shows a scatter plot and kernel density estimation of accuracy vs. compression of BMRS compared to SNR accuracy. $\\mathrm{BMRS}_{\\mathcal{N}}$ and $\\mathrm{BMRS}_{\\mathcal{U}}$ -8 consistently stop pruning near the knee point, a preferred trade-off solution. "], "img_footnote": [], "page_idx": 7}, {"type": "image", "img_path": "ktpG37Dzh5/tmp/fc7a90648e9034a470c11659ffa513d1b8bb2021fc4db3e156c9b76491761b8b.jpg", "img_caption": ["Figure 3: Average Spearman\u2019s rank correlation Figure 4: Accuracy and compression rate vs. $p_{1}$ between the ranks of neurons for pruning when for $\\mathbf{B}\\mathbf{M}\\mathbf{R}\\mathbf{S}_{\\mathcal{U}}$ on CIFAR10 with Lenet5. Results using different methods on CIFAR10 (plots for are averaged across 10 seeds with standard deviaadditional datasets are given in Appendix E). tion indicated by the error bars. "], "img_footnote": [], "page_idx": 7}, {"type": "text", "text": "Continuous pruning. Next, we experiment with continuous pruning, where neurons are pruned continuously throughout training based on either a provided pruning threshold (SNR, $\\mathbb{E}_{q_{\\phi}}[\\theta])$ or $\\Delta F$ (BMRS). For SNR, we prune a neuron when its SNR falls below 1 (as in [30]), and for $\\mathbb{E}_{q_{\\phi}}[\\theta]$ we set a threshold of 0.1. For L2 pruning, we perform post-training pruning based on the compression rate achieved by $\\mathrm{BMRS}_{\\mathcal{N}}$ . Neurons are pruned after every epoch during training, followed by 10 epochs of fine-tuning at the very end of training. ", "page_idx": 7}, {"type": "table", "img_path": "ktpG37Dzh5/tmp/4ef517c774375bea2f7e18dd70ad8e558d1c8fac1db465a0f16ddefd6cd4f03b.jpg", "table_caption": ["Table 1: Parameter compression $\\%$ and accuracy for different baseline methods and settings of the proposed method. Standard deviations over ten runs are included. Best accuracy for the compression methods is given in bold. "], "table_footnote": [], "page_idx": 8}, {"type": "text", "text": "", "page_idx": 8}, {"type": "text", "text": "We compare the raw performance of each variant using an MLP and Lenet5 on MNIST, FashionMNIST, and CIFAR10 in Table 1. First, we note that using the L2 norm with the same compression rate as $\\mathrm{BMRS}_{\\mathcal{N}}$ results in a degenerate model; the accuracy degrades to random in all settings. Additionally, we see that using the SNR as a pruning criterion with the recommended threshold of 1 from [30] is also inconsistent, resulting in large drops in performance for 3 out of 6 settings. $\\mathrm{BMRS}_{\\mathcal{N}}$ and $\\mathbf{B}\\mathbf{M}\\mathbf{R}\\mathbf{S}_{\\mathcal{U}}$ result in both high compression rate and high performance in all settings. $\\mathrm{BMRS}_{\\mathcal{N}}$ accomplishes this without the need for tuning any pruning thresholds, in one case yielding a higher compression rate than $\\mathbf{B}\\mathbf{M}\\mathbf{R}\\mathbf{S}_{\\mathcal{U}}$ -4 while keeping the accuracy high. $\\mathbf{B}\\mathbf{M}\\mathbf{R}\\mathbf{S}_{\\mathcal{U}}$ -4 results in both the highest compression rate among the three BMRS variants in 4 out of 6 settings, and the highest accuracy in 5 out of 6 settings, with the caveat of needing to select $p_{1}$ as a hyperparameter. To explore the effect of this hyperparameter further, we plot accuracy and compression vs. $p_{1}$ for Lenet5 trained on CIFAR10 in Figure 4. We see that compression rapidly increases after $p_{1}=11$ , continuing until $p_{1}=1$ . Additionally, we find that accuracy also steadily increases with a higher compression rate, indicating that $\\mathrm{BMRS}_{\\mathcal{U}}$ reduces complexity while increasing the generalization capacity of the model. ", "page_idx": 8}, {"type": "text", "text": "Finally, a comparison of ResNet-50 and ViT on CIFAR10 and TinyImagenet is given in Table 2. Here, SNR and the three BMRS variants achieve similar accuracies at different compression rates. $\\mathrm{BMRS}_{\\mathcal{N}}$ achieves a modest compression rate compared to SNR with a threshold of 1 for each case. $\\mathbf{B}\\mathbf{M}\\mathbf{R}\\mathbf{S}_{\\mathcal{U}}.$ -4 yields a higher compression rate than $\\mathrm{BMRS}_{\\mathcal{N}}$ and $\\mathrm{BMRS}_{\\mathcal{U}}$ -8 in all settings. As such, we show that $\\mathrm{BMRS}_{\\mathcal{N}}$ is capable of achieving high compression with no threshold tuning, while a more extreme compression rate is possible by selecting $p_{1}$ for $\\mathbf{B}\\mathbf{M}\\mathbf{R}\\mathbf{S}_{\\mathcal{U}}$ . ", "page_idx": 8}, {"type": "text", "text": "6 Discussion and conclusion ", "text_level": 1, "page_idx": 8}, {"type": "text", "text": "Our experimental results demonstrate the pruning characteristics of BMRS in two settings: continuous pruning and post-training pruning. One of the benefits of BMRS, and $\\mathrm{BMRS}_{\\mathcal{N}}$ in particular, is that no threshold tuning is needed, making it particularly useful for the continuous pruning setting. Here, the compression rate improves as the model converges, allowing one to gradually increase the compression rate without sacrificing accuracy. The choice of $\\mathrm{BMRS}_{\\mathcal{N}}$ vs. $\\mathrm{BMRS}_{\\mathcal{U}}$ is then dependent on the problem, where more complex scenarios (e.g., over-parameterized models) are suitable for $\\mathbf{B}\\mathbf{M}\\mathbf{R}\\mathbf{S}_{\\mathcal{U}}$ if a higher compression rate is desired. In this case, a hyperparameter search over $p_{1}$ in the range [\u03f5, 23] can be done to select $\\mathbf{B}\\mathbf{M}\\mathbf{R}\\mathbf{S}_{\\mathcal{U}}$ (see Figure 4 for an example), or one can simply use $\\mathrm{BMRS}_{\\mathcal{N}}$ to achieve good compression with no hyperparameter tuning. Additionally, we expect that the more over-specified the model is, the lower we can set $p_{1}$ and maintain accuracy (i.e., lower bit-rate). ", "page_idx": 8}, {"type": "table", "img_path": "ktpG37Dzh5/tmp/b2bb915647acd0dcc4d4474a2e883113f4d1b0dbfeafdffc82c2c43edb81208c.jpg", "table_caption": ["Table 2: Parameter compression $\\%$ and accuracy for different baseline methods and settings of the proposed method. Standard deviations over three runs are included. Best accuracy for the compression methods is given in bold. "], "table_footnote": [], "page_idx": 9}, {"type": "text", "text": "Limitations: We note a few of the limitations of BMRS. First, while multiplicative noise pruning allows for the flexible application of pruning at different structural levels, BNNs may offer more aggressive compression rates as they apply sparsity inducing priors at multiple hierarchical levels [2, 15, 16, 33, 29]. BMR based approaches may be derived for such networks; as of this work and as far we we know, it has only been successfully applied in practice to models with flat priors for unstructured pruning [5, 29]. Additionally, multiplicative noise creates an overhead of additional parameters $\\phi$ which increase the training time and storage requirements. Third, more exhaustive baseline pruning criteria could be used for comparison in the future, for example classic methods based on the Hessian or gradient of weights (e.g. see Figure 5 in Appendix E) [23, 12]. Fourth, we apply multiplicative noise to linear layers and convolutional filters, while it could be useful to explore pruning more complex structures in the future. Finally, while structured pruning can reduce the inference time and energy consumption of neural networks, improvements in efficiency have been shown to have potential negative consequences in terms of energy consumption and carbon emissions based on how efficiency can affect how a model is used in practice [35]. ", "page_idx": 9}, {"type": "text", "text": "Conclusions: In this work we presented BMRS, an efficiently calculable method for threshold-free structured pruning of neural networks. We derived two versions of BMRS: $\\mathrm{BMRS}_{\\mathcal{N}}$ based on the truncated log-normal prior, and $\\mathbf{B}\\mathbf{M}\\mathbf{R}\\mathbf{S}_{\\mathcal{U}}$ based on a reduced truncated log-uniform prior. BMRS offers several key features over existing work: by basing the method off of the approach of multiplicative noise [30], the structured pruning aspect is flexible as it is not dependent on assuming any prior over individual weights and can be easily applied at any structural level [16, 2]. Additionally, the prior and variational posterior in the multiplicative noise approach lend themselves to the derivation of BMRS using multiple reduced priors which have different pruning properties, allowing for flexibility in the compression rate when desired and threshold free pruning otherwise. Finally, our experimental results demonstrate the competitive compression and accuracy of BMRS compared to baseline compression methods on multiple networks of varying complexity and across multiple datasets. The methods presented here based on BMR could form a template for developing more aggressive pruning schemes by incorporating more complex hierarchical priors on both structures and individual weights, as well as for studying limits on the number of neural network structures required to solve a given dataset. ", "page_idx": 9}, {"type": "text", "text": "Acknowledgments DW, CI and RS are partly funded by European Union\u2019s Horizon Europe Research and Innovation Programme under grant agreements No. 101070284 and No. 101070408. DW is also partly supported by a Danish Data Science Academy postdoctoral fellowship (grant: 2023-1425). ", "page_idx": 9}, {"type": "text", "text": "References ", "text_level": 1, "page_idx": 10}, {"type": "text", "text": "[1] L. F. W. Anthony, B. Kanding, and R. Selvan. Carbontracker: Tracking and predicting the carbon footprint of training deep learning models. In ICML Workshop on Challenges in Deploying and Monitoring Machine Learning Systems, 2020.   \n[2] J. Bai, Q. Song, and G. Cheng. Efficient variational inference for sparse deep learning with theoretical guarantee. In Advances in Neural Information Processing Systems (NeurIPS), 2020. [3] B. R. Bartoldson, B. Kailkhura, and D. Blalock. Compute-efficient deep learning: Algorithmic trends and opportunities. Journal of Machine Learning Research, 24:122\u20131, 2023. [4] M. J. Beal. Variational algorithms for approximate Bayesian inference. University of London, University College London (United Kingdom), 2003.   \n[5] J. Beckers, B. Van Erp, Z. Zhao, K. Kondrashov, and B. De Vries. Principled pruning of bayesian neural networks through variational free energy minimization. IEEE Open Journal of Signal Processing, 2024. [6] K. Friston, T. Parr, and P. Zeidman. Bayesian model reduction. arXiv:1805.07092 [stat.ME], 2018.   \n[7] K. J. Friston and W. D. Penny. Post hoc Bayesian model selection. NeuroImage, 56(4): 2089\u20132099, 2011.   \n[8] K. J. Friston, V. Litvak, A. Oswal, A. Razi, K. E. Stephan, B. C. M. van Wijk, G. Ziegler, and P. Zeidman. Bayesian model reduction and empirical bayes for group (DCM) studies. NeuroImage, 128:413\u2013431, 2016. [9] K. J. Friston, M. Lin, C. D. Frith, G. Pezzulo, J. A. Hobson, and S. Ondobaka. Active inference, curiosity and insight. Neural Computation, 29(10):2633\u20132683, 2017.   \n[10] S. Ghosh, J. Yao, and F. Doshi-Velez. Model selection in bayesian neural networks via horseshoe priors. Journal of Machine Learning Research, 20:182:1\u2013182:46, 2019.   \n[11] R. W. Hamming. On the distribution of numbers. The Bell System Technical Journal, 49(8): 1609\u20131625, 1970.   \n[12] B. Hassibi and D. G. Stork. Second order derivatives for network pruning: Optimal brain surgeon. In Advances in Neural Information Processing Systems (NeurIPS), pages 164\u2013171. Morgan Kaufmann, 1992.   \n[13] K. He, X. Zhang, S. Ren, and J. Sun. Deep residual learning for image recognition. In Computer Vision and Pattern Recognition (CVPR), pages 770\u2013778, 2016.   \n[14] P. Henderson, J. Hu, J. Romoff, E. Brunskill, D. Jurafsky, and J. Pineau. Towards the Systematic Reporting of the Energy and Carbon Footprints of Machine Learning. Journal of Machine Learning Research, 21(1):10039\u201310081, 2020.   \n[15] A. Hubin and G. Storvik. Variational inference for Bayesian neural networks under model and parameter uncertainty. arXiv:2305.00934 [stat.ML], 2023.   \n[16] S. R. Jantre, S. Bhattacharya, and T. Maiti. Layer adaptive node selection in bayesian neural networks: Statistical guarantees and implementation details. Neural Networks, 167:309\u2013330, 2023.   \n[17] Y. Jeon and J. Kim. Constructing fast network through deconstruction of convolution. In Advances in Neural Information Processing Systems (NeurIPS), pages 5955\u20135965, 2018.   \n[18] S. J. Kiebel, M. I. Garrido, R. J. Moran, and K. J. Friston. Dynamic causal modelling for EEG and MEG. Cognitive Neurodynamics, 2:121\u2013136, 2008.   \n[19] D. P. Kingma and M. Welling. Auto-encoding variational bayes. In International Conference on Learning Representation (ICLR), 2014.   \n[20] D. P. Kingma, T. Salimans, and M. Welling. Variational dropout and the local reparameterization trick. In Advances in Neural Information Processing Systems (NeurIPS), pages 2575\u20132583, 2015.   \n[21] A. Krizhevsky. Learning multiple layers of features from tiny images. Technical report, University of Toronto, 2009.   \n[22] Y. LeCun. The MNIST database of handwritten digits. http://yann.lecun.com/exdb/ mnist/, 1998.   \n[23] Y. LeCun, J. S. Denker, and S. A. Solla. Optimal brain damage. In Advances in Neural Information Processing Systems (NeurIPS), pages 598\u2013605. Morgan Kaufmann, 1989.   \n[24] Y. LeCun, L. Bottou, Y. Bengio, and P. Haffner. Gradient-based learning applied to document recognition. Proceedings of the IEEE, 86(11):2278\u20132324, 1998.   \n[25] H. Li, A. Kadav, I. Durdanovic, H. Samet, and H. P. Graf. Pruning fliters for efficient convnets. In International Conference on Learning Representation (ICLR), 2017.   \n[26] J. Li, Z. Miao, Q. Qiu, and R. Zhang. Training bayesian neural networks with sparse subspace variational inference. In The Twelfth International Conference on Learning Representations, ICLR, 2024.   \n[27] T. Liang, J. Glossner, L. Wang, S. Shi, and X. Zhang. Pruning and quantization for deep neural network acceleration: A survey. Neurocomputing, 461:370\u2013403, 2021.   \n[28] C. Louizos, K. Ullrich, and M. Welling. Bayesian compression for deep learning. In Advances in Neural Information Processing Systems (NeurIPS), pages 3288\u20133298, 2017.   \n[29] D. Markovic, K. J. Friston, and S. J. Kiebel. Bayesian sparsification for deep neural networks with Bayesian model reduction. arXiv:2309.12095 [stat.ML], 2023.   \n[30] K. Neklyudov, D. Molchanov, A. Ashukha, and D. P. Vetrov. Structured bayesian pruning via log-normal multiplicative noise. In Advances in Neural Information Processing Systems (NeurIPS), pages 6775\u20136784, 2017.   \n[31] H. Peng, Q. Cao, J. Dodge, M. E. Peters, J. Fernandez, T. Sherborne, K. Lo, S. Skjonsberg, E. Strubell, D. Plessas, I. B. end Evan Pete Walsh, N. A. Smith, and H. Hajishirzi. Efficiency Pentathlon: A standardized arena for efficiency evaluation. arXiv:2307.09701 [cs.CL], 2023.   \n[32] P. Sedgwick. Spearman\u2019s rank correlation coefficient. BMJ, 349, 2014.   \n[33] Y. Sun, Q. Song, and F. Liang. Learning sparse deep neural networks with a spike-and-slab prior. Statistics & Probability Letters, 180:109246, 2022.   \n[34] N. Thompson, K. Greenewald, K. Lee, and G. F. Manso. The Computational Limits of Deep Learning. In Workshop on Computing within Limits, 2023.   \n[35] D. Wright, C. Igel, G. Samuel, and R. Selvan. Efficiency is not enough: A critical perspective of environmentally sustainable AI. arXiv:2309.02065 [cs.LG], 2023.   \n[36] B. Wu, C. Xu, X. Dai, A. Wan, P. Zhang, Z. Yan, M. Tomizuka, J. Gonzalez, K. Keutzer, and P. Vajda. Visual transformers: Token-based image representation and processing for computer vision. arXiv:2006.03677 [cs.CV], 2020.   \n[37] H. Xiao, K. Rasul, and R. Vollgraf. Fashion-MNIST: a novel image dataset for benchmarking machine learning algorithms. arXiv:1708.07747 [cs.LG], 2017. ", "page_idx": 10}, {"type": "text", "text": "", "page_idx": 11}, {"type": "text", "text": "A Derivations ", "text_level": 1, "page_idx": 12}, {"type": "text", "text": "We use the following notation and distributions: ", "page_idx": 12}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\Phi(x)=\\frac{1}{n}\\Big[1+\\mathrm{erf}\\left(\\frac{x}{\\sqrt{2}}\\right)\\Big]\\quad\\mathrm{(CDFof~}N(0,1)\\mathrm{~enduated~a~z~)}}\\\\ &{=-\\frac{a-y}{n}}\\\\ &{\\partial_{y}=\\frac{b-y}{\\sigma_{p}}}\\\\ &{Z_{p}=\\Phi(\\lambda_{p})-\\Phi(a_{p})}\\\\ &{\\mathrm{Lop}\\Lambda_{(a_{1})}(\\theta|_{p},\\sigma_{p}^{2})=\\left\\{\\frac{1}{\\lambda_{0}},\\mathrm{e}^{\\gamma}\\mathrm{Zre}^{2\\epsilon}\\right\\}\\left\\{-\\frac{1(86-\\theta-\\mu_{p})^{2}}{a_{p}^{2}}\\right\\}\\quad a\\leq\\theta\\leq b}\\\\ &{\\mathrm{Lop}\\Lambda_{(a_{1})}(\\theta)=\\left\\{0\\quad\\mathrm{(a_{1})}^{-1}\\right\\}\\quad a\\leq\\theta\\leq b}\\\\ &{\\mathrm{(e}^{\\gamma}\\theta)=\\mathrm{Lop}\\Lambda_{(a_{1})}(\\theta|_{p},\\sigma_{q}^{2})}\\\\ &{\\rho(\\theta)=\\mathrm{Lop}\\Lambda_{(a_{1})}(\\theta|_{p},\\sigma_{p}^{2})}\\\\ &{\\rho(\\theta)=\\mathrm{Lop}\\Lambda_{(a_{1})}(\\theta|_{p},\\partial_{y}^{2})}\\end{array}\n$$", "text_format": "latex", "page_idx": 12}, {"type": "text", "text": "A.1 $\\mathbf{BMRS}_{\\mathcal{N}}$ ", "text_level": 1, "page_idx": 12}, {"type": "text", "text": "We start by finding $q_{\\phi}(\\theta)\\frac{\\tilde{p}(\\theta)}{p(\\theta)}$ ", "page_idx": 12}, {"type": "text", "text": "1. First we look at ", "page_idx": 12}, {"type": "equation", "text": "$$\nq_{\\phi}(\\theta)\\tilde{p}(\\theta)=\\frac{1}{\\theta^{2}2\\pi Z_{q}\\tilde{Z}_{p}\\sqrt{\\sigma_{q}^{2}\\tilde{\\sigma}_{p}^{2}}}\\exp\\left\\{-\\frac{1}{2}\\left(\\frac{(\\log\\theta-\\mu_{q})^{2}}{\\sigma_{q}^{2}}+\\frac{(\\log\\theta-\\tilde{\\mu}_{p})^{2}}{\\tilde{\\sigma}_{p}^{2}}\\right)\\right\\}.\n$$", "text_format": "latex", "page_idx": 12}, {"type": "text", "text": "The exponent can be rewritten as ", "page_idx": 12}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{-\\,\\frac{1}{2}\\left(\\frac{(\\log\\theta-\\mu_{q})^{2}}{\\sigma_{q}^{2}}+\\frac{(\\log\\theta-\\tilde{\\mu}_{p})^{2}}{\\tilde{\\sigma}_{p}^{2}}\\right)=}\\\\ &{\\phantom{-\\frac{1}{2}\\frac{\\tilde{\\sigma}_{p}^{2}(\\log^{2}\\theta-2\\log\\theta\\mu_{q}+\\mu_{q}^{2})+\\sigma_{q}^{2}(\\log^{2}\\theta-2\\log\\theta\\tilde{\\mu}_{p}+\\tilde{\\mu}_{p}^{2})}{\\sigma_{q}^{2}\\tilde{\\sigma}_{p}^{2}}=}\\\\ &{-\\frac{1}{2}\\frac{(\\sigma_{q}^{2}+\\tilde{\\sigma}_{p}^{2})\\left(\\log\\theta-\\frac{\\sigma_{q}^{2}\\tilde{\\sigma}_{p}^{2}}{\\sigma_{q}^{2}+\\tilde{\\sigma}_{p}^{2}}\\left(\\frac{\\mu_{q}}{\\sigma_{q}^{2}}+\\frac{\\tilde{\\mu}_{p}}{\\tilde{\\sigma}_{p}^{2}}\\right)\\right)^{2}+\\tilde{\\sigma}_{p}^{2}\\mu_{q}^{2}+\\sigma_{q}^{2}\\tilde{\\mu}_{p}^{2}-(\\sigma_{q}^{2}+\\tilde{\\sigma}_{p}^{2})\\left(\\frac{\\sigma_{q}^{2}\\tilde{\\sigma}_{p}^{2}}{\\sigma_{q}^{2}+\\tilde{\\sigma}_{p}^{2}}\\left(\\frac{\\mu_{q}}{\\sigma_{q}^{2}}+\\frac{\\tilde{\\mu}_{p}}{\\tilde{\\sigma}_{p}^{2}}\\right)\\right)^{2}}{\\sigma_{q}^{2}\\tilde{\\sigma}_{p}^{2}}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 12}, {"type": "text", "text": "Defining ", "page_idx": 12}, {"type": "equation", "text": "$$\n\\tilde{\\sigma}_{q}^{2}:=\\frac{\\sigma_{q}^{2}\\tilde{\\sigma}_{p}^{2}}{\\sigma_{q}^{2}+\\tilde{\\sigma}_{p}^{2}}=\\left(\\frac{1}{\\sigma_{q}^{2}}+\\frac{1}{\\tilde{\\sigma}_{p}^{2}}\\right)^{-1}\\mathrm{~and~}\\tilde{\\mu}_{q}:=\\tilde{\\sigma}_{q}^{2}\\left(\\frac{\\mu_{q}}{\\sigma_{q}^{2}}+\\frac{\\tilde{\\mu}_{p}}{\\tilde{\\sigma}_{p}^{2}}\\right)\n$$", "text_format": "latex", "page_idx": 12}, {"type": "text", "text": "we get ", "page_idx": 12}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\quad\\varphi(\\theta)\\tilde{p}(\\theta)=\\frac{1}{\\theta^{2}2\\pi Z_{q}\\tilde{Z}_{p}\\sqrt{\\sigma_{q}^{2}\\tilde{\\sigma}_{p}^{2}}}\\exp\\left\\{-\\frac{1}{2}\\frac{(\\log\\theta-\\tilde{\\mu}_{q})^{2}}{\\tilde{\\sigma}_{q}^{2}}\\right\\}\\exp\\left\\{-\\frac{1}{2}\\left(\\frac{\\mu_{q}^{2}}{\\sigma_{q}^{2}}+\\frac{\\tilde{\\mu}_{p}^{2}}{\\tilde{\\sigma}_{p}^{2}}-\\frac{\\tilde{\\mu}_{q}^{2}}{\\tilde{\\sigma}_{q}^{2}}\\right)\\right\\}}\\\\ &{\\quad\\quad\\quad=\\frac{\\theta\\tilde{Z}_{q}\\sqrt{2\\pi\\tilde{\\sigma}_{q}^{2}}}{\\theta^{2}2\\pi Z_{q}\\tilde{Z}_{p}\\sqrt{\\sigma_{q}^{2}\\tilde{\\sigma}_{p}^{2}}}\\frac{1}{\\theta\\tilde{Z}_{q}\\sqrt{2\\pi\\tilde{\\sigma}_{q}^{2}}}\\exp\\left\\{-\\frac{1}{2}\\frac{(\\log\\theta-\\tilde{\\mu}_{q})^{2}}{\\tilde{\\sigma}_{q}^{2}}\\right\\}\\exp\\left\\{-\\frac{1}{2}\\left(\\frac{\\mu_{q}^{2}}{\\sigma_{q}^{2}}+\\frac{\\tilde{\\mu}_{p}^{2}}{\\tilde{\\sigma}_{p}^{2}}-\\frac{\\tilde{\\mu}_{q}^{2}}{\\tilde{\\sigma}_{q}^{2}}\\right)\\right.}\\\\ &{\\quad\\quad\\quad\\left.=\\frac{\\tilde{Z}_{q}\\sqrt{\\tilde{\\sigma}_{q}^{2}}}{\\theta Z_{q}\\tilde{Z}_{p}\\sqrt{2\\pi\\sigma_{q}^{2}\\tilde{\\sigma}_{p}^{2}}}\\exp\\left\\{-\\frac{1}{2}\\left(\\frac{\\mu_{q}^{2}}{\\sigma_{q}^{2}}+\\frac{\\tilde{\\mu}_{p}^{2}}{\\tilde{\\sigma}_{p}^{2}}-\\frac{\\tilde{\\mu}_{q}^{2}}{\\tilde{\\sigma}_{q}^{2}}\\right)\\right\\}\\mathrm{LogN}_{[a,b]}(\\theta|\\tilde{\\mu}_{q},\\tilde{\\sigma}_{q}^{2}).}\\end{array}\n$$", "text_format": "latex", "page_idx": 12}, {"type": "text", "text": "2. Then we divide out $p(\\theta)$ : ", "page_idx": 13}, {"type": "equation", "text": "$$\nq_{\\phi}(\\theta)\\frac{\\tilde{p}(\\theta)}{p(\\theta)}=\\frac{(\\log b-\\log a)\\tilde{Z}_{q}\\sqrt{\\tilde{\\sigma}_{q}^{2}}}{Z_{q}\\tilde{Z}_{p}\\sqrt{2\\pi\\sigma_{q}^{2}\\tilde{\\sigma}_{p}^{2}}}\\exp\\left\\{-\\frac{1}{2}\\left(\\frac{\\mu_{q}^{2}}{\\sigma_{q}^{2}}+\\frac{\\tilde{\\mu}_{p}^{2}}{\\tilde{\\sigma}_{p}^{2}}-\\frac{\\tilde{\\mu}_{q}^{2}}{\\tilde{\\sigma}_{q}^{2}}\\right)\\right\\}\\mathrm{LogN}_{[a,b]}(\\theta|\\tilde{\\mu}_{q},\\tilde{\\sigma}_{q}^{2})\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "3. Now we can find ${\\tilde{q}}(\\theta)$ and $\\Delta F$ using Equation 6. Start with ${\\tilde{q}}(\\theta)$ : ", "page_idx": 13}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\dot{q}(\\theta)=\\frac{q_{0}(\\theta)\\dot{\\rho}\\dot{\\theta}_{0}^{(0)}}{\\exp{\\Delta\\phi}}}&{}\\\\ {=\\frac{q_{0}(\\theta)\\dot{\\rho}\\dot{\\theta}_{0}^{(0)}}{f_{0}(\\theta)\\dot{\\rho}(\\theta)}}&{}\\\\ {=\\frac{\\frac{(\\ln{\\rho}\\dot{\\theta}_{0})\\dot{\\rho}(\\theta)}{f_{0}(\\theta)}}{\\frac{(\\ln{\\rho}\\dot{\\theta}_{0})\\int_{0}^{\\infty}{\\Delta\\phi}}{\\int_{0}^{\\infty}{2\\pi^{2}\\sqrt{2\\pi^{2}\\phi^{2}}}}\\exp\\left\\{-\\frac{1}{2}\\left(\\frac{\\rho_{0}^{2}}{\\sigma_{q}^{2}}+\\frac{\\dot{\\rho}^{2}}{\\dot{\\theta}_{0}^{2}}-\\frac{\\dot{\\theta}_{0}^{2}}{\\theta_{0}^{2}}\\right)\\right\\}\\mathrm{LogN}_{\\mathrm{i}\\times}(\\theta)\\dot{\\mu}_{0}\\frac{\\partial_{q}^{2}}{\\partial q})}\\\\ {=\\frac{\\frac{(\\ln{\\rho}\\dot{\\theta}_{0}-\\ln{\\rho}\\omega)\\dot{\\rho}}{\\int_{0}^{\\infty}{2\\pi^{2}\\sqrt{2\\pi^{2}\\phi^{2}}}}\\exp\\left\\{-\\frac{1}{2}\\left(\\frac{\\rho_{0}^{2}}{\\sigma_{q}^{2}}+\\frac{\\dot{\\rho}^{2}}{\\dot{\\theta}_{0}^{2}}-\\frac{\\dot{\\theta}_{0}^{2}}{\\theta_{0}^{2}}\\right)\\right\\}\\mathrm{LogN}_{\\mathrm{i}\\times}(\\theta)\\dot{\\mu}_{0}\\frac{\\partial_{q}^{2}}{\\partial q}\\mathrm{i}\\theta}\\\\ {=\\frac{\\frac{(\\ln{\\rho}\\dot{\\theta}_{0}-\\ln{\\rho}\\omega)\\dot{\\rho}(\\theta)}{\\frac{(\\ln{\\rho}\\dot{\\theta}_{0})\\Delta^{2}}{\\int_{0}^{\\infty}{2\\pi^{2}\\sqrt{2\\pi^{2}\\phi^{2}}}}\\exp\\left\\{-\\frac{1}{2}\\left(\\frac{\\rho_{0}^{2}}{\\sigma_{q}^{2}}+\\frac{\\dot{\\rho}^{2}}{\\theta_{0}^{2} \n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "4. Finally we get $\\Delta F$ : ", "page_idx": 13}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\Delta F=\\log\\frac{q_{\\phi}(\\theta)\\frac{\\bar{p}(\\theta)}{\\bar{p}(\\theta)}}{\\tilde{q}(\\theta)}}\\\\ &{\\qquad=\\log\\frac{\\left(\\log b-\\log a\\right)\\tilde{Z}_{q}\\sqrt{\\tilde{\\sigma}_{q}^{2}}}{Z_{q}\\tilde{Z}_{p}\\sqrt{2\\pi\\sigma_{q}^{2}\\tilde{\\sigma}_{p}^{2}}}\\exp\\left\\lbrace-\\frac{1}{2}\\left(\\frac{\\mu_{q}^{2}}{\\sigma_{q}^{2}}+\\frac{\\tilde{\\mu}_{p}^{2}}{\\tilde{\\sigma}_{p}^{2}}-\\frac{\\tilde{\\mu}_{q}^{2}}{\\tilde{\\sigma}_{q}^{2}}\\right)\\right\\rbrace}\\\\ &{\\qquad=\\log\\frac{\\tilde{Z}_{q}\\left(\\log b-\\log a\\right)}{Z_{q}\\tilde{Z}_{p}}+\\frac{1}{2}\\log\\frac{\\tilde{\\sigma}_{q}^{2}}{2\\pi\\sigma_{q}^{2}\\tilde{\\sigma}_{p}^{2}}-\\frac{1}{2}\\left(\\frac{\\mu_{q}^{2}}{\\sigma_{q}^{2}}+\\frac{\\tilde{\\mu}_{p}^{2}}{\\tilde{\\sigma}_{p}^{2}}-\\frac{\\tilde{\\mu}_{q}^{2}}{\\tilde{\\sigma}_{q}^{2}}\\right)}\\end{array}\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "A.2 $\\mathbf{BMRS}_{\\mathcal{U}}$ ", "text_level": 1, "page_idx": 13}, {"type": "text", "text": "The PDF of the reduced truncated log-uniform distribution is given as follows: ", "page_idx": 13}, {"type": "equation", "text": "$$\n\\tilde{p}(\\theta)=\\mathrm{LogU}_{[a^{\\prime},b^{\\prime}]}(\\theta)=\\left\\{\\left(\\theta\\log\\frac{b^{\\prime}}{a^{\\prime}}\\right)^{-1},\\ \\ \\ a\\leq a^{\\prime}<b^{\\prime}\\leq b\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "Using this, we can directly solve the integral under the expectation given in Equation 6 for $\\Delta F$ ", "page_idx": 13}, {"type": "equation", "text": "$$\n\\exp\\Delta F=\\mathbb{E}_{\\Tilde{p}}\\left[\\frac{q_{\\phi}(\\theta)}{p(\\theta)}\\right]=\\int_{a}^{b}\\mathrm{LogU}_{[a^{\\prime},b^{\\prime}]}(\\theta)\\frac{q_{\\phi}(\\theta)}{\\mathrm{LogU}_{[a,b]}(\\theta)}d\\theta=\\int_{a}^{b}\\frac{\\theta\\log\\frac{b}{a}}{\\theta\\log\\frac{b^{\\prime}}{a^{\\prime}}}q_{\\phi}(\\theta)d\\theta\n$$", "text_format": "latex", "page_idx": 13}, {"type": "equation", "text": "$$\n=\\int_{a}^{a^{\\prime}}0d\\theta+\\int_{a^{\\prime}}^{b^{\\prime}}\\frac{\\log\\frac{b}{a}}{\\log\\frac{b^{\\prime}}{a^{\\prime}}}q_{\\phi}(\\theta)d\\theta+\\int_{b^{\\prime}}^{b}0d\\theta=\\frac{\\log\\frac{b}{a}}{\\log\\frac{b^{\\prime}}{a^{\\prime}}}q_{\\phi}(a^{\\prime}\\leq\\theta_{i}\\leq b^{\\prime})\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "Plugging this in to Equation 5 where $\\exp\\Delta F\\geq1$ : ", "page_idx": 13}, {"type": "equation", "text": "$$\n1\\leq\\frac{\\log\\frac{b}{a}}{\\log\\frac{b^{\\prime}}{a^{\\prime}}}q_{\\phi}(a^{\\prime}\\leq\\theta_{i}\\leq b^{\\prime})\\Rightarrow\\frac{\\log\\frac{b^{\\prime}}{a^{\\prime}}}{\\log\\frac{b}{a}}\\leq q_{\\phi}(a^{\\prime}\\leq\\theta\\leq b^{\\prime})\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "B Dataset details ", "text_level": 1, "page_idx": 14}, {"type": "text", "text": "MNIST MNIST [22] is a classic image classification dataset consisting of $70\\small{,}000\\ 28\\mathrm{x}28$ black and white images of handwritten digits (10 classes). We use the original 10,000 image test set for testing and split the 60,000 image train set into $80\\%$ training and $20\\%$ validation images. ", "page_idx": 14}, {"type": "text", "text": "Fashion-MNIST Fashion-MNIST [37] is a modernized version of MNIST using images of different articles of clothing as opposed to handwritten digits. The dataset statistics are the same as MNIST: $28\\mathrm{x}28$ greyscale images, 60,000 training images, 10,000 test images, 10 classes. Similar to MNIST, we split the training set into $80\\%$ training and $20\\%$ validation images. ", "page_idx": 14}, {"type": "text", "text": "CIFAR10 CIFAR10 [21] is an image classification dataset of $32\\mathtt{x32}$ color images with 10 classes. There are 50,000 training images and 10,000 test images. Again, we split the training set to $80\\%$ training and $20\\%$ validation. ", "page_idx": 14}, {"type": "text", "text": "TinyImagenet TinyImagenet is a reduced version of ImageNet consisting of $110\\small{,}000\\,64\\times64$ color images in 200 classes. We use the 10,000 image validation split for testing, and split the 100,000 image train set into $80\\%$ training and $20\\%$ validation images. ", "page_idx": 14}, {"type": "text", "text": "C Model details ", "text_level": 1, "page_idx": 14}, {"type": "text", "text": "For each model and dataset we use the Adam optimizer with no weight decay. We train for 50 epochs for each experiment with an MLP and Lenet5, and for 100 epochs for each experiment with Resnet50 and ViT. Further details about each model are given as follows: ", "page_idx": 14}, {"type": "text", "text": "C.1 MLP ", "text_level": 1, "page_idx": 14}, {"type": "text", "text": "We use a multilayer perceptron (MLP) for several experiments, with different network sizes based on a hyperparameter sweep for each dataset. Multiplicative noise for pruning is applied to every neuron in the network. We sweep through the following hyperparmeters: ", "page_idx": 14}, {"type": "text", "text": "\u2022 Number of layers $=\\{1,3,5,7,9\\}$ \u2022 Hidden dimension $=\\{10,30,50,100,150\\}$ \u2022 Batch $\\mathrm{size}=\\{16,32,64,128\\}$ \u2022 Learning rate [0.0001, 0.1]. ", "page_idx": 14}, {"type": "text", "text": "The final network settings for each dataset are given as follows: ", "page_idx": 14}, {"type": "text", "text": "MNIST: Number of layers: 7; Hidden dimension: 100; Batch size: 128; Learning rate: $8.5{\\cdot}10^{-4}$ . ", "page_idx": 14}, {"type": "text", "text": "Fashion-MNIST Number of layers: 1; Hidden dimension: 150; Batch size: 128; Learning rate: $1.5{\\cdot}10^{-3}$ . ", "page_idx": 14}, {"type": "text", "text": "CIFAR10 Number of layers: 5; Hidden dimension: 150; Batch size: 32; Learning rate: $6.8{\\cdot}10^{-4}$ . ", "page_idx": 14}, {"type": "text", "text": "C.2 Lenet5 ", "text_level": 1, "page_idx": 14}, {"type": "text", "text": "Lenet5 [24] is an early CNN architecture consisting of 2 convolutional layers with 6 and 16 filters per channel, respectively, each followed by a ReLU activation and max pooling layer, followed by 3 linear layers. Multiplicative noise is applied to each convolutional fliter map, as well as each neuron the the linear layers. We use the same architecture for each experiments and tune hyperparameters based on the dataset. We sweep through the following hyperparameters: ", "page_idx": 14}, {"type": "text", "text": "\u2022 Batch $\\mathrm{size}=\\{16,32,64,128\\}$ \u2022 Learning rate [0.0001, 0.1]. ", "page_idx": 14}, {"type": "text", "text": "The final settings for each dataset are given as follows: ", "page_idx": 14}, {"type": "text", "text": "MNIST: Batch size 128; Learning rate $1.4{\\cdot}10^{-3}$ ", "page_idx": 14}, {"type": "text", "text": "Table 3: Training and inference runtimes in milliseconds. Each runtime is averaged across 1000 forward passes of a batch of 32 images. Inference runtimes are before pruning (i.e., with the full network). ", "page_idx": 15}, {"type": "table", "img_path": "ktpG37Dzh5/tmp/c2e667e49bcc014b8f5a2a6a28a80eb7753614732d4c11f0fc9b5b0a5d4e1cac.jpg", "table_caption": [], "table_footnote": [], "page_idx": 15}, {"type": "text", "text": "Fashion-MNIST Batch size 32; Learning rate $1.4{\\cdot}10^{-3}$ . ", "page_idx": 15}, {"type": "text", "text": "CIFAR10 Batch size 64; Learning rate $1{\\cdot}10^{-3}$ ", "page_idx": 15}, {"type": "text", "text": "C.3 Resnet50 ", "text_level": 1, "page_idx": 15}, {"type": "text", "text": "Resnet50 [13] is a deep 50-layer CNN which uses residual connections to stabilize optimization and improve accuracy. We start with a model pretrained on ImageNet-1k,3 then fine-tuned on the downstream dataset with pruning layers added to each output layer after batch normalization. We use a learning rate of 6.8e-4, a batch size of 32, and train for 100 epochs for both CIFAR10 and TinyImagenet. ", "page_idx": 15}, {"type": "text", "text": "C.4 Vision Transformer (ViT) ", "text_level": 1, "page_idx": 15}, {"type": "text", "text": "Vision Transformer (ViT) [36] is a transformer model tailored for image data based on tokenizing an image as 16x16 image patches. We use a ViT which is pretrained on ImageNet-21k (14M images and 21,843 classes) as well as ImageNet-1k.4 We add multiplicative noise to the output layer of each transformer block for pruning. We use a learning rate of 6.8e-4, a batch size of 32, and train for 100 epochs for both CIFAR10 and TinyImagenet. ", "page_idx": 15}, {"type": "text", "text": "D Compute resources ", "text_level": 1, "page_idx": 15}, {"type": "text", "text": "All experiments were run on a shared cluster. Requested jobs consisted of 16GB of RAM and 4 Intel Xeon Silver 4110 CPUs. We used a single NVIDIA Titan X GPU with 24GB of RAM for all experiments, though utilization was generally much lower due the the average size of each network. Runtimes for each experiment ranged from approx. 7 minutes for Lenet5 on MNIST with no pruning layers to approx. 44 hours for ViT on TinyImagenet with multiplicative noise trained for 100 epochs. The training of models in this work over the course of the entire project (prototyping, experimentation, etc.) is estimated to have used $3773.785\\;\\mathrm{kWh}$ of electricity contributing to $599.892\\,\\mathrm{kg}$ of CO2eq (as measured by carbontracker [1]; this is equivalent to $5580.395\\;\\mathrm{km}$ travelled by car). ", "page_idx": 15}, {"type": "text", "text": "We additionally benchmark the training and inference runtimes of each model before pruning in Table 3 and Table 4 (i.e., the inference runtimes are without removing structures). ", "page_idx": 15}, {"type": "text", "text": "Table 4: Training and inference runtimes in milliseconds. Each runtime is averaged across 1000 forward passes of a batch of 32 images. Inference runtimes are before pruning (i.e., with the full network). ", "page_idx": 16}, {"type": "table", "img_path": "ktpG37Dzh5/tmp/2f7179d46d3d6c598636dfa3df5c0ae906aa046d8a7cb1433b8168173128955b.jpg", "table_caption": [], "table_footnote": [], "page_idx": 16}, {"type": "text", "text": "E Additional plots ", "text_level": 1, "page_idx": 16}, {"type": "text", "text": "An additional experiment for post-training pruning including gradient-based thersholding for pruning is given in Figure 5. For gradient based pruning, we use two thresholds: one for the L2-Norm (magnitude) of structures, and one for the L2-Norm of the gradients of weights in a given structure. The neuron rank correlations for Fashion-MNIST are given in Figure 6. and for MNIST in Figure 7. ", "page_idx": 16}, {"type": "image", "img_path": "ktpG37Dzh5/tmp/813d2c92ea0bb8176a9449f90b9cf4081a3e5a823efdaecac106ed89d49f171b.jpg", "img_caption": ["Figure 5: Additional accuracy vs. compression results for post-training pruning including gradientbased pruning. "], "img_footnote": [], "page_idx": 17}, {"type": "image", "img_path": "ktpG37Dzh5/tmp/2cd530d9f80e9689a5d915d28bbf76cac35109a8ef5809fe25cfe859fc9636b3.jpg", "img_caption": ["Figure 6: Average correlation between the ranks of neurons for pruning when using different methods on Fashion-MNIST. "], "img_footnote": [], "page_idx": 17}, {"type": "image", "img_path": "ktpG37Dzh5/tmp/b914b8ba52e40a0d1b9e056c158f16f9966e89dd185157ae12eb7b01cfbe26e8.jpg", "img_caption": ["Figure 7: Average correlation between the ranks of neurons for pruning when using different methods on MNIST. "], "img_footnote": [], "page_idx": 18}, {"type": "text", "text": "NeurIPS Paper Checklist ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "1. Claims ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "Question: Do the main claims made in the abstract and introduction accurately reflect the paper\u2019s contributions and scope? ", "page_idx": 19}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 19}, {"type": "text", "text": "Justification: The abstract accurately reflects the main claims of the paper; see the last paragraph of $\\S1$ for the primary contributions for comparison. ", "page_idx": 19}, {"type": "text", "text": "Guidelines: ", "page_idx": 19}, {"type": "text", "text": "\u2022 The answer NA means that the abstract and introduction do not include the claims made in the paper.   \n\u2022 The abstract and/or introduction should clearly state the claims made, including the contributions made in the paper and important assumptions and limitations. A No or NA answer to this question will not be perceived well by the reviewers.   \n\u2022 The claims made should match theoretical and experimental results, and reflect how much the results can be expected to generalize to other settings.   \n\u2022 It is fine to include aspirational goals as motivation as long as it is clear that these goals are not attained by the paper. ", "page_idx": 19}, {"type": "text", "text": "2. Limitations ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "Question: Does the paper discuss the limitations of the work performed by the authors? ", "page_idx": 19}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "Justification: The limitations are discussed after $\\S6$ in a paragraph marked \u201cLimitations\u201d. Guidelines: ", "page_idx": 19}, {"type": "text", "text": "\u2022 The answer NA means that the paper has no limitation while the answer No means that the paper has limitations, but those are not discussed in the paper.   \n\u2022 The authors are encouraged to create a separate \"Limitations\" section in their paper.   \n\u2022 The paper should point out any strong assumptions and how robust the results are to violations of these assumptions (e.g., independence assumptions, noiseless settings, model well-specification, asymptotic approximations only holding locally). The authors should reflect on how these assumptions might be violated in practice and what the implications would be.   \n\u2022 The authors should reflect on the scope of the claims made, e.g., if the approach was only tested on a few datasets or with a few runs. In general, empirical results often depend on implicit assumptions, which should be articulated.   \n\u2022 The authors should reflect on the factors that influence the performance of the approach. For example, a facial recognition algorithm may perform poorly when image resolution is low or images are taken in low lighting. Or a speech-to-text system might not be used reliably to provide closed captions for online lectures because it fails to handle technical jargon.   \n\u2022 The authors should discuss the computational efficiency of the proposed algorithms and how they scale with dataset size.   \n\u2022 If applicable, the authors should discuss possible limitations of their approach to address problems of privacy and fairness.   \n\u2022 While the authors might fear that complete honesty about limitations might be used by reviewers as grounds for rejection, a worse outcome might be that reviewers discover limitations that aren\u2019t acknowledged in the paper. The authors should use their best judgment and recognize that individual actions in favor of transparency play an important role in developing norms that preserve the integrity of the community. Reviewers will be specifically instructed to not penalize honesty concerning limitations. ", "page_idx": 19}, {"type": "text", "text": "3. Theory Assumptions and Proofs ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "Question: For each theoretical result, does the paper provide the full set of assumptions and a complete (and correct) proof? ", "page_idx": 19}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 19}, {"type": "text", "text": "Justification: We provide detailed derivations and describe assumptions for each new theoretical result in $\\S4.2$ and Appendix A. ", "page_idx": 20}, {"type": "text", "text": "Guidelines: ", "page_idx": 20}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include theoretical results.   \n\u2022 All the theorems, formulas, and proofs in the paper should be numbered and crossreferenced.   \n\u2022 All assumptions should be clearly stated or referenced in the statement of any theorems.   \n\u2022 The proofs can either appear in the main paper or the supplemental material, but if they appear in the supplemental material, the authors are encouraged to provide a short proof sketch to provide intuition.   \n\u2022 Inversely, any informal proof provided in the core of the paper should be complemented by formal proofs provided in appendix or supplemental material.   \n\u2022 Theorems and Lemmas that the proof relies upon should be properly referenced. ", "page_idx": 20}, {"type": "text", "text": "4. Experimental Result Reproducibility ", "text_level": 1, "page_idx": 20}, {"type": "text", "text": "Question: Does the paper fully disclose all the information needed to reproduce the main experimental results of the paper to the extent that it affects the main claims and/or conclusions of the paper (regardless of whether the code and data are provided or not)? ", "page_idx": 20}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 20}, {"type": "text", "text": "Justification: The full methodology is given in $\\S3$ and $\\S4$ ; the experimental setting is given in $\\S5$ ; the full dataset and model details are given in Appendix B and Appendix C, respectively. Guidelines: ", "page_idx": 20}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 If the paper includes experiments, a No answer to this question will not be perceived well by the reviewers: Making the paper reproducible is important, regardless of whether the code and data are provided or not.   \n\u2022 If the contribution is a dataset and/or model, the authors should describe the steps taken to make their results reproducible or verifiable.   \n\u2022 Depending on the contribution, reproducibility can be accomplished in various ways. For example, if the contribution is a novel architecture, describing the architecture fully might suffice, or if the contribution is a specific model and empirical evaluation, it may be necessary to either make it possible for others to replicate the model with the same dataset, or provide access to the model. In general. releasing code and data is often one good way to accomplish this, but reproducibility can also be provided via detailed instructions for how to replicate the results, access to a hosted model (e.g., in the case of a large language model), releasing of a model checkpoint, or other means that are appropriate to the research performed.   \n\u2022 While NeurIPS does not require releasing code, the conference does require all submissions to provide some reasonable avenue for reproducibility, which may depend on the nature of the contribution. For example (a) If the contribution is primarily a new algorithm, the paper should make it clear how to reproduce that algorithm. (b) If the contribution is primarily a new model architecture, the paper should describe the architecture clearly and fully. (c) If the contribution is a new model (e.g., a large language model), then there should either be a way to access this model for reproducing the results or a way to reproduce the model (e.g., with an open-source dataset or instructions for how to construct the dataset). (d) We recognize that reproducibility may be tricky in some cases, in which case authors are welcome to describe the particular way they provide for reproducibility. In the case of closed-source models, it may be that access to the model is limited in some way (e.g., to registered users), but it should be possible for other researchers to have some path to reproducing or verifying the results. ", "page_idx": 20}, {"type": "text", "text": "5. Open access to data and code ", "text_level": 1, "page_idx": 20}, {"type": "text", "text": "Question: Does the paper provide open access to the data and code, with sufficient instructions to faithfully reproduce the main experimental results, as described in supplemental material? ", "page_idx": 21}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 21}, {"type": "text", "text": "Justification: The datasets we use are all open source, and details are given in Appendix B. The code is made available and can be downloaded/viewed at https://github.com/ saintslab/bmrs-structured-pruning/. ", "page_idx": 21}, {"type": "text", "text": "Guidelines: ", "page_idx": 21}, {"type": "text", "text": "\u2022 The answer NA means that paper does not include experiments requiring code.   \n\u2022 Please see the NeurIPS code and data submission guidelines (https://nips.cc/ public/guides/CodeSubmissionPolicy) for more details.   \n\u2022 While we encourage the release of code and data, we understand that this might not be possible, so \u201cNo\u201d is an acceptable answer. Papers cannot be rejected simply for not including code, unless this is central to the contribution (e.g., for a new open-source benchmark).   \n\u2022 The instructions should contain the exact command and environment needed to run to reproduce the results. See the NeurIPS code and data submission guidelines (https: //nips.cc/public/guides/CodeSubmissionPolicy) for more details.   \n\u2022 The authors should provide instructions on data access and preparation, including how to access the raw data, preprocessed data, intermediate data, and generated data, etc.   \n\u2022 The authors should provide scripts to reproduce all experimental results for the new proposed method and baselines. If only a subset of experiments are reproducible, they should state which ones are omitted from the script and why.   \n\u2022 At submission time, to preserve anonymity, the authors should release anonymized versions (if applicable).   \n\u2022 Providing as much information as possible in supplemental material (appended to the paper) is recommended, but including URLs to data and code is permitted. ", "page_idx": 21}, {"type": "text", "text": "6. Experimental Setting/Details ", "text_level": 1, "page_idx": 21}, {"type": "text", "text": "Question: Does the paper specify all the training and test details (e.g., data splits, hyperparameters, how they were chosen, type of optimizer, etc.) necessary to understand the results? ", "page_idx": 21}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 21}, {"type": "text", "text": "Justification: The experimental setting is given in $\\S5$ ; the full dataset and model details are given in Appendix B and Appendix C, respectively. ", "page_idx": 21}, {"type": "text", "text": "Guidelines: ", "page_idx": 21}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments. \u2022 The experimental setting should be presented in the core of the paper to a level of detail that is necessary to appreciate the results and make sense of them. \u2022 The full details can be provided either with the code, in appendix, or as supplemental material. ", "page_idx": 21}, {"type": "text", "text": "7. Experiment Statistical Significance ", "text_level": 1, "page_idx": 21}, {"type": "text", "text": "Question: Does the paper report error bars suitably and correctly defined or other appropriate information about the statistical significance of the experiments? ", "page_idx": 21}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 21}, {"type": "text", "text": "Justification: All of our experiments are run across multiple seeds. All plots include error bars (areas of standard deviation or confidence intervals). All tables include the mean and standard deviation across multiple seeds. ", "page_idx": 21}, {"type": "text", "text": "Guidelines: ", "page_idx": 21}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments. \u2022 The authors should answer \"Yes\" if the results are accompanied by error bars, confidence intervals, or statistical significance tests, at least for the experiments that support the main claims of the paper. ", "page_idx": 21}, {"type": "text", "text": "\u2022 The factors of variability that the error bars are capturing should be clearly stated (for example, train/test split, initialization, random drawing of some parameter, or overall run with given experimental conditions).   \n\u2022 The method for calculating the error bars should be explained (closed form formula, call to a library function, bootstrap, etc.)   \n\u2022 The assumptions made should be given (e.g., Normally distributed errors).   \n\u2022 It should be clear whether the error bar is the standard deviation or the standard error of the mean.   \n\u2022 It is OK to report 1-sigma error bars, but one should state it. The authors should preferably report a 2-sigma error bar than state that they have a $96\\%$ CI, if the hypothesis of Normality of errors is not verified.   \n\u2022 For asymmetric distributions, the authors should be careful not to show in tables or figures symmetric error bars that would yield results that are out of range (e.g. negative error rates).   \n\u2022 If error bars are reported in tables or plots, The authors should explain in the text how they were calculated and reference the corresponding figures or tables in the text. ", "page_idx": 22}, {"type": "text", "text": "8. Experiments Compute Resources ", "text_level": 1, "page_idx": 22}, {"type": "text", "text": "Question: For each experiment, does the paper provide sufficient information on the computer resources (type of compute workers, memory, time of execution) needed to reproduce the experiments? ", "page_idx": 22}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 22}, {"type": "text", "text": "Justification: Information on the compute infrastructure and resources are given in Appendix D. ", "page_idx": 22}, {"type": "text", "text": "Guidelines: ", "page_idx": 22}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 The paper should indicate the type of compute workers CPU or GPU, internal cluster, or cloud provider, including relevant memory and storage.   \n\u2022 The paper should provide the amount of compute required for each of the individual experimental runs as well as estimate the total compute.   \n\u2022 The paper should disclose whether the full research project required more compute than the experiments reported in the paper (e.g., preliminary or failed experiments that didn\u2019t make it into the paper). ", "page_idx": 22}, {"type": "text", "text": "9. Code Of Ethics ", "text_level": 1, "page_idx": 22}, {"type": "text", "text": "Question: Does the research conducted in the paper conform, in every respect, with the NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines? ", "page_idx": 22}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 22}, {"type": "text", "text": "Justification: We conform to the NeurIPS code of ethics. Guidelines: ", "page_idx": 22}, {"type": "text", "text": "\u2022 The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics.   \n\u2022 If the authors answer No, they should explain the special circumstances that require a deviation from the Code of Ethics.   \n\u2022 The authors should make sure to preserve anonymity (e.g., if there is a special consideration due to laws or regulations in their jurisdiction). ", "page_idx": 22}, {"type": "text", "text": "10. Broader Impacts ", "text_level": 1, "page_idx": 22}, {"type": "text", "text": "Question: Does the paper discuss both potential positive societal impacts and negative societal impacts of the work performed? ", "page_idx": 22}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 22}, {"type": "text", "text": "Justification: We point out in the limitations that efficiency can also have potential negative environmental aspects due to e.g. the rebound effect. ", "page_idx": 22}, {"type": "text", "text": "Guidelines: \u2022 The answer NA means that there is no societal impact of the work performed. ", "page_idx": 22}, {"type": "text", "text": "\u2022 If the authors answer NA or No, they should explain why their work has no societal impact or why the paper does not address societal impact.   \n\u2022 Examples of negative societal impacts include potential malicious or unintended uses (e.g., disinformation, generating fake profiles, surveillance), fairness considerations (e.g., deployment of technologies that could make decisions that unfairly impact specific groups), privacy considerations, and security considerations.   \n\u2022 The conference expects that many papers will be foundational research and not tied to particular applications, let alone deployments. However, if there is a direct path to any negative applications, the authors should point it out. For example, it is legitimate to point out that an improvement in the quality of generative models could be used to generate deepfakes for disinformation. On the other hand, it is not needed to point out that a generic algorithm for optimizing neural networks could enable people to train models that generate Deepfakes faster.   \n\u2022 The authors should consider possible harms that could arise when the technology is being used as intended and functioning correctly, harms that could arise when the technology is being used as intended but gives incorrect results, and harms following from (intentional or unintentional) misuse of the technology.   \n\u2022 If there are negative societal impacts, the authors could also discuss possible mitigation strategies (e.g., gated release of models, providing defenses in addition to attacks, mechanisms for monitoring misuse, mechanisms to monitor how a system learns from feedback over time, improving the efficiency and accessibility of ML). ", "page_idx": 23}, {"type": "text", "text": "11. Safeguards ", "text_level": 1, "page_idx": 23}, {"type": "text", "text": "Question: Does the paper describe safeguards that have been put in place for responsible release of data or models that have a high risk for misuse (e.g., pretrained language models, image generators, or scraped datasets)? ", "page_idx": 23}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 23}, {"type": "text", "text": "Justification: As we propose a general method for neural network pruning, we do not see where safeguards could be put in place or that there is a high risk of misuse. ", "page_idx": 23}, {"type": "text", "text": "Guidelines: ", "page_idx": 23}, {"type": "text", "text": "\u2022 The answer NA means that the paper poses no such risks.   \n\u2022 Released models that have a high risk for misuse or dual-use should be released with necessary safeguards to allow for controlled use of the model, for example by requiring that users adhere to usage guidelines or restrictions to access the model or implementing safety filters.   \n\u2022 Datasets that have been scraped from the Internet could pose safety risks. The authors should describe how they avoided releasing unsafe images.   \n\u2022 We recognize that providing effective safeguards is challenging, and many papers do not require this, but we encourage authors to take this into account and make a best faith effort. ", "page_idx": 23}, {"type": "text", "text": "12. Licenses for existing assets ", "text_level": 1, "page_idx": 23}, {"type": "text", "text": "Question: Are the creators or original owners of assets (e.g., code, data, models), used in the paper, properly credited and are the license and terms of use explicitly mentioned and properly respected? ", "page_idx": 23}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 23}, {"type": "text", "text": "Justification: We clearly mark where any non-original code is used (see e.g. modules/utils.py in the code). ", "page_idx": 23}, {"type": "text", "text": "Guidelines: ", "page_idx": 23}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not use existing assets.   \n\u2022 The authors should cite the original paper that produced the code package or dataset.   \n\u2022 The authors should state which version of the asset is used and, if possible, include a URL.   \n\u2022 The name of the license (e.g., CC-BY 4.0) should be included for each asset.   \n\u2022 For scraped data from a particular source (e.g., website), the copyright and terms of service of that source should be provided.   \n\u2022 If assets are released, the license, copyright information, and terms of use in the package should be provided. For popular datasets, paperswithcode.com/datasets has curated licenses for some datasets. Their licensing guide can help determine the license of a dataset.   \n\u2022 For existing datasets that are re-packaged, both the original license and the license of the derived asset (if it has changed) should be provided.   \n\u2022 If this information is not available online, the authors are encouraged to reach out to the asset\u2019s creators. ", "page_idx": 23}, {"type": "text", "text": "", "page_idx": 24}, {"type": "text", "text": "13. New Assets ", "text_level": 1, "page_idx": 24}, {"type": "text", "text": "Question: Are new assets introduced in the paper well documented and is the documentation provided alongside the assets? ", "page_idx": 24}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 24}, {"type": "text", "text": "Justification: We provide links to the code in the paper and have documented the code for ease of use/reproducibility. ", "page_idx": 24}, {"type": "text", "text": "Guidelines: ", "page_idx": 24}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not release new assets.   \n\u2022 Researchers should communicate the details of the dataset/code/model as part of their submissions via structured templates. This includes details about training, license, limitations, etc.   \n\u2022 The paper should discuss whether and how consent was obtained from people whose asset is used.   \n\u2022 At submission time, remember to anonymize your assets (if applicable). You can either create an anonymized URL or include an anonymized zip file. ", "page_idx": 24}, {"type": "text", "text": "14. Crowdsourcing and Research with Human Subjects ", "text_level": 1, "page_idx": 24}, {"type": "text", "text": "Question: For crowdsourcing experiments and research with human subjects, does the paper include the full text of instructions given to participants and screenshots, if applicable, as well as details about compensation (if any)? ", "page_idx": 24}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 24}, {"type": "text", "text": "Justification: We do not perform crowdsourced experiments. ", "page_idx": 24}, {"type": "text", "text": "Guidelines: ", "page_idx": 24}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u2022 Including this information in the supplemental material is fine, but if the main contribution of the paper involves human subjects, then as much detail as possible should be included in the main paper.   \n\u2022 According to the NeurIPS Code of Ethics, workers involved in data collection, curation, or other labor should be paid at least the minimum wage in the country of the data collector. ", "page_idx": 24}, {"type": "text", "text": "15. Institutional Review Board (IRB) Approvals or Equivalent for Research with Human Subjects ", "text_level": 1, "page_idx": 24}, {"type": "text", "text": "Question: Does the paper describe potential risks incurred by study participants, whether such risks were disclosed to the subjects, and whether Institutional Review Board (IRB) approvals (or an equivalent approval/review based on the requirements of your country or institution) were obtained? ", "page_idx": 24}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 24}, {"type": "text", "text": "Justification: We do not do crowdsourcing or involve human subjects. ", "page_idx": 24}, {"type": "text", "text": "Guidelines: ", "page_idx": 24}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects. ", "page_idx": 24}, {"type": "text", "text": "\u2022 Depending on the country in which research is conducted, IRB approval (or equivalent) may be required for any human subjects research. If you obtained IRB approval, you should clearly state this in the paper.   \n\u2022 We recognize that the procedures for this may vary significantly between institutions and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the guidelines for their institution.   \n\u2022 For initial submissions, do not include any information that would break anonymity (if applicable), such as the institution conducting the review. ", "page_idx": 25}]