[{"type": "text", "text": "Selective Generation for Controllable Language Models ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Minjae Lee\u2217 GSAI POSTECH minjae.lee@postech.ac.kr ", "page_idx": 0}, {"type": "text", "text": "Kyungmin Kim\u2217 GSAI POSTECH kkm959595@postech.ac.kr ", "page_idx": 0}, {"type": "text", "text": "Taesoo Kim   \nSCS & SCP   \nGaTech   \ntaesoo@gatech.edu   \nSangdon Park   \nGSAI & CSE   \nPOSTECH   \nsangdon@postech.ac.kr ", "page_idx": 0}, {"type": "text", "text": "", "page_idx": 0}, {"type": "text", "text": "Abstract ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Trustworthiness of generative language models (GLMs) is crucial in their deployment to critical decision making systems. Hence, certified risk control methods such as selective prediction and conformal prediction have been applied to mitigating the hallucination problem in various supervised downstream tasks. However, the lack of appropriate correctness metric hinders applying such principled methods to language generation tasks. In this paper, we circumvent this problem by leveraging the concept of textual entailment to evaluate the correctness of the generated sequence, and propose two selective generation algorithms which control the false discovery rate with respect to the textual entailment relation (FDR-E) with a theoretical guarantee: $\\mathsf{S G e n}^{\\hat{\\mathsf{S u p}}}$ and $\\mathsf{S G e n}^{\\mathsf{S e m i}}$ . SGenSup, a direct modification of the selective prediction, is a supervised learning algorithm which exploits entailment-labeled data, annotated by humans. Since human annotation is costly, we further propose a semisupervised version, $\\mathsf{S G e n}^{\\mathrm{Semi}}$ , which fully utilizes the unlabeled data by pseudolabeling, leveraging an entailment set function learned via conformal prediction. Furthermore, $\\bar{\\mathsf{S G e n}}^{\\bar{\\mathsf{S e m i}}}$ enables to use more general class of selection functions, neuro-selection functions, and provides users with an optimal selection function class given multiple candidates. Finally, we demonstrate the efficacy of the SGen family in achieving a desired FDR-E level with comparable selection efficiency to those from baselines on both open and closed source GLMs. Code and datasets are provided at https://github.com/ml-postech/selective-generation. ", "page_idx": 0}, {"type": "text", "text": "1 Introduction ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Generative language models (GLMs) [1, 2, 3, 4] have garnered significant attention for their ability to generate human-level language [5] primarily due to underlying transformer architectures [6]. However, GLMs raise concerns about generating hallucinated facts [7], which is an undesirable property when they are used as knowledge retrieval sources. This issue can be mitigated by finetuning with human feedback [7, 8], but it remains expensive in terms of training and labeling costs. Certified risk control methods such as selective prediction [9] and conformal prediction [10] are promising cost-efficient alternatives, which have been applied to the hallucination mitigation in various supervised downstream tasks [9, 10, 11, 12, 13, 14]. ", "page_idx": 0}, {"type": "image", "img_path": "glfYOAzh2f/tmp/a6db9413fcd1b0f1e43284aa46223da33acabd7dc038b90eb710708769e54741.jpg", "img_caption": ["Two different selection function training (\u00a0 \u00a0 \u00a0)\u00a0schemes, using existing \uff1aInferenceusinganentailment-awareselectivegenerator. (left)\u00a0and proposed (right) methods, respectively. Note LLM is frozen (\u00a0 \u00a0 \u00a0 ). Here, a selective generator refers to an LLM and selection function pair. "], "img_footnote": [], "page_idx": 1}, {"type": "text", "text": "Figure 1: An overview and qualitative results of our proposed method. The key idea is to learn an entailment-aware selective generator with an abstaining option that controls the rate of hallucination, measured in a false discovery rate, on the generated sequence with a probabilistic guarantee. ", "page_idx": 1}, {"type": "text", "text": "The main bottleneck in applying such certified methods to language generation tasks is that provided risk control guarantees require correctness labels during the learning process. Specifically, in classification, high-quality correctness labels can be directly acquired by comparing true and predicted labels using exact match (EM). However, this is not the case for language generation tasks, since multiple valid answers can exist for the same question. As correctness metrics such as EM and F1-score do not account for the multiple valid answers, directly applying them to language generation tasks results in a significant gap between the true and measured correctness, which we call the metric misalignment. Thus, a correctness evaluation metric that accounts for multiple answers is required. ", "page_idx": 1}, {"type": "text", "text": "In this paper, we resolve the metric misalignment problem by leveraging textual entailment to evaluate the correctness of generated answers and define the false discovery rate with respect to the textual entailment relation (FDR-E). Given two ordered sequences, a premise and a hypothesis, we say that the premise entails the hypothesis if the hypothesis is true given the premise. Based on this notion of entailment, we propose two selective generation algorithms, $\\mathsf{S G e n}^{\\mathsf{S u p}}$ and $\\mathsf{S G e n}^{\\mathrm{Semi}}$ , which are generalized versions of selective classification [9] to control the FDR-E by abstaining from returning an answer when a GLM is uncertain of its answer. ", "page_idx": 1}, {"type": "text", "text": "In particular, $\\mathsf{S G e n}^{\\mathsf{S u p}}$ , a direct modification of [9], is a supervised selective generator learning algorithm which requires entailment labels. This necessitates human annotations on textual entailment, where a generated answer is the premise and a true answer is the hypothesis. As labeling is expensive and $\\mathsf{S G e n}^{\\mathsf{S u p}}$ solely relies on entailment-labeled data, we propose a semi-supervised method, $\\mathsf{S G e n}^{\\mathsf{S e m i}}$ , which enables the exploitation of entailment-unlabeled data in learning a selective generator by pseudo-labeling textual entailment using an entailment set function learned via conformal prediction [10]. Based on a entailment classifier originally developed for the natural language inference problem [15, 16], the estimated entailment set function approximates a true entailment set function, which returns all entailed answers if a true answer is given as a hypothesis. ", "page_idx": 1}, {"type": "text", "text": "Additionally, $\\mathsf{S G e n}^{\\mathsf{S e m i}}$ introduces the general class of selection functions for selective generation, called neuro-selection functions. In selective prediction, learning a selective predictor is equivalent to learning a selection function, which is an indicator function to decide whether to abstain from returning a prediction. The standard selective prediction algorithm [9] considers the class of singlethreshold indicator functions using a pre-specified confidence-rate function. For the same risk level, the better the confidence-rate function quantifies the model\u2019s uncertainty, the less likely the selective predictor is to abstain from making a prediction. We refer to this as selection efficiency henceforth. As appropriate confidence calibration for language generation remains challenging, optimizing a single-threshold indicator function with a poorly calibrated confidence-rate function leads to low selection efficiency. Instead, we generalize the selection function by using a multiple-threshold indicator function with trainable features. Furthermore, $\\mathsf{S G e n}^{\\mathrm{Semi}}$ provides a user with an optimal class of selection functions among possible candidates in terms of the FDR-E. ", "page_idx": 1}, {"type": "text", "text": "Finally, we empirically demonstrate the efficacy of $\\mathsf{S G e n}^{\\mathrm{Semi}}$ over open and closed source GLMs, where we consider $\\mathsf{S G e n}^{\\mathsf{S u p}}$ as one of our baselines as it is a direct modification of [9]. To validate our method and its theoretical guarantee, we create a new dataset on textual entailment using the Natural Questions (NQ) dataset [17] for each GLM. Given a question and answer pair, the textual entailment is labeled by letting a generated answer as a premise and the true answer in declarative form as a hypothesis. As communities lack human-annotated entailment-labeled data for language generation, we believe that our dataset contributes to the hallucination evaluation of GLMs. For both open and closed source GLMs, $\\mathsf{S G e n}^{\\mathrm{Semi}}$ is effective in achieving a desired FDR-E level with better selection efficiency compared to baselines. ", "page_idx": 1}, {"type": "text", "text": "", "page_idx": 2}, {"type": "text", "text": "1.1 Related Work ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "We introduce two main research directions to mitigate hallucination in GLMs. ", "page_idx": 2}, {"type": "text", "text": "Heuristics for hallucination mitigation. The hallucination in language generation usually refers to the situation where a GLM generates wrong answers with high confidence, which hinders the reliable deployment of GLMs. As fine-tuning methods are expensive, heuristics for hallucination mitigation without tuning have been proposed [18, 19]. Notably, [19] proposes a performant hallucination detection method, which quantifies the self-consistency among multiple generated answers for the same question using textual entailment models to detect the hallucination. However, these methods do not provide certified control over the occurrence of hallucinated contents. ", "page_idx": 2}, {"type": "text", "text": "Certified methods for hallucination mitigation. Conformal prediction outputs a prediction set that is guaranteed to contain a true label with high probability, where a provided coverage guarantee is model-agnostic under a mild assumption on a data [10]. Although this property enables the safe deployment of complex models and has made conformal prediction popular [10, 12, 13, 20, 21, 22], the constructed prediction sets in language generation are often less-informative due to an unbounded label space, which frequently renders the coverage guarantee ineffective [23, 24]. To restrict the prediction set to a moderate size, [23] constructs the prediction set over answers by sampling them sequentially, while still satisfying the coverage guarantee. Still, post-selection of answers from the prediction set is necessary for final decision making, which may result in the selection bias [25, 26]. [27, 28] decompose generated answers into alignment-labeled sub-claims and return a set of sub-claims that contains no contradiction with high probability via conformal prediction. Even though the post-selection is unnecessary, it requires expensive alignment labels for every sub-claim. ", "page_idx": 2}, {"type": "text", "text": "Unlike conformal prediction, selective prediction directly manages target risk at a desired level by introducing an abstaining option on unsure predictions. [9] proposes a selective prediction method mainly for classification, which learns a threshold-based selection function that controls the false discovery rate (FDR) to a desired level. [24] generalizes the selective prediction to language generation. However, their theoretical guarantee is not focused on the target risk to control, but on a consistency property of a surrogate loss function with respect to a true loss function in optimization process. [29], concurrently published with our paper, proposes a certified selective generation method for context-given language generation which controls the FDR. Unlike [9] which takes the number of selected samples as constraint in learning the selection function, [29] set the power as constraint. However, as [24] does, they require an additional calibration set for training an entailment scoring function. Importantly, while existing selective generation methods are supervised learning methods, we propose a semi-supervised learning algorithm that can fully leverage entailment-unlabeled data. ", "page_idx": 2}, {"type": "text", "text": "2 Background ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "While we consider general language generation tasks, we confine our scope to the open-ended question-answering task and define the notation accordingly for the sake of clarity and for maintaining consistency in descriptions on the experiment. Specifically, let $\\mathcal{W}$ denote a token space constructed using a tokenizer, such as Byte Pair Encoding [30], and let $\\mathcal{W}^{*}$ denote a token sequence space, defined as $\\mathcal{W}^{*}:=\\cup_{i=0}^{\\infty}\\mathcal{W}^{i}$ . Let $(\\mathbf{x},\\mathbf{y})\\in\\mathcal{X}\\times\\mathcal{Y}$ be a question and answer sequence pair, where $\\mathcal{X}:=\\mathcal{W}^{\\ast}$ and $\\mathcal{V}:=\\mathcal{W}^{\\ast}$ refer to the token sequence spaces of questions and answers, respectively. We assume the answer sequence is in a declarative form. Finally, $\\mathbf{x}_{i:j}$ refers to the sub-sequence of $\\mathbf{x}$ from the $i$ -th to the $j$ -th token. ", "page_idx": 2}, {"type": "text", "text": "2.1 Language Generation ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "Given a question as input, a GLM generates an answer through the sequential process called decoding, which we call language generation. Here, we consider the greedy decoding, a deterministic generation process described as follows. Let $p_{M}:\\mathcal X\\times\\mathcal W\\to\\mathbb R_{\\geq0}$ denote a GLM which returns a next-token distribution given the input sequence $\\mathbf{x}$ , where $\\begin{array}{r}{\\sum_{w\\in\\mathcal{W}}p_{M}(w\\mid\\mathbf{x})=1}\\end{array}$ for all $\\mathbf{x}\\in\\mathcal{X}$ . A language generator $G:\\mathcal{X}\\rightarrow\\mathcal{Y}$ using greedy decoding sequentially generates tokens from the GLM as follows: $\\hat{\\mathbf{y}}_{i}\\,:=\\,\\arg\\operatorname*{max}_{w\\in\\mathcal{W}}$ $p_{M}(\\bar{w^{\\textit{\\textcent}}}|\\;\\left(\\bar{\\mathbf{x}_{,}}\\hat{\\mathbf{y}}_{1:i-1}\\right))$ for $i\\geq2$ and $\\hat{\\mathbf{y}}_{1}\\,:=\\,\\arg\\operatorname*{max}_{w\\in\\mathcal{W}}\\,p_{M}(w\\mid\\mathbf{x})$ . The generator $G$ returns a generated answer $\\hat{\\mathbf{y}}:=G(\\mathbf{x})$ and terminates the decoding process when the end-of-sequence (EOS) token is returned. Here, the conditional probability of the answer $\\hat{\\mathbf{y}}$ is defined as $\\begin{array}{r}{f_{M}(\\mathbf{x},\\bar{\\hat{\\mathbf{y}}}):=p_{M}(\\hat{\\mathbf{y}}_{1}\\mid\\mathbf{x})\\prod_{i=2}^{|\\hat{\\mathbf{y}}|}p_{M}(\\hat{\\mathbf{y}}_{i}\\mid(\\mathbf{x},\\hat{\\mathbf{y}}_{1:i-1}))}\\end{array}$ , commonly used as its uncertainty measure. ", "page_idx": 2}, {"type": "text", "text": "", "page_idx": 3}, {"type": "text", "text": "2.2 Selective Prediction ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "Selective prediction refuses to make a prediction by returning \u201cI don\u2019t know\u201d (IDK) if the prediction is uncertain. In classification, the selective classifier $\\hat{S}$ consists of a pair of a classifier $\\hat{y}$ and a selection function $\\hat{s}$ , and is defined as follows: $\\hat{S}(\\mathbf x)\\;:=\\;\\binom{G(\\mathbf x)}{\\mathrm{IDK}}\\quad\\mathrm{if}\\;\\hat{s}(\\mathbf x)=1$ IDK otherwise , where y\u02c6(x) := arg $\\operatorname*{max}_{y\\in{\\mathcal{Y}}}\\;f(\\mathbf{x},y)$ . Here, $f(\\mathbf{x},y)$ refers to an estimated likelihood of the given input $\\mathbf{x}$ for being a class $y$ , determined by an underlying classification model $f$ . Although the selection function can be of arbitrary form, the common choice is a single threshold indicator function using the maximum likelihood as the confidence-rate function, i.e., $\\hat{s}(\\mathbf{x}):=\\mathbb{1}(f(\\mathbf{x},\\hat{y})\\geq\\tau)$ . Here, the confidence-rate function is defined to quantify the uncertainty of the model\u2019s prediction. Under the independent and identically distributed (i.i.d.) assumption, [9] proposed the certified threshold learning algorithm which controls the false discovery rate (FDR) with respect to the EM metric with the PAC guarantee, where the FDR is defined as $\\mathcal{R}_{\\mathrm{EM}}(\\hat{S}):=\\mathbb{P}\\{\\hat{y}(\\mathbf{x})\\,\\neq\\,y\\ |\\ \\hat{S}(\\mathbf{x})\\,\\neq\\,\\mathrm{IDK}\\}$ . Since EM considers the answer ${\\hat{y}}(\\mathbf{x})$ to be correct when it is exactly the same as the reference answer $y$ , it is an inappropriate correctness metric for language generation problems that can have multiple valid sequences for the same input. This results in learning a too conservative and vacuous selection function for language generation, which is empirically verified by our experiments. Thus, we leverage the textual entailment to evaluate the correctness of the generated sequence to alleviate the metric misalignment problem. ", "page_idx": 3}, {"type": "text", "text": "2.3 Textual Entailment ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "Natural language inference (NLI), also denoted as recognizing textual entailment, predicts whether one sequence implies another. The former refers to a premise $(\\mathbf{p})$ , and the latter refers to a hypothesis (h). Since the release of two large-scale benchmarks of ordered sequence pairs labeled with textual entailment [15, 16], a number of transformer-based entailment classifiers have been proposed and shown impressive results. Each pair is classified into one of three categories: entailment if $\\mathbf{h}$ is true given p; contradiction if $\\mathbf{h}$ is false given p; and neutral otherwise. In this paper, we define the entailment scoring function as $f_{E}(G(\\mathbf{x}),\\mathbf{y}):=1-p_{E}$ (contradict $|\\mathbf{\\partial}\\mathbf{p}=G(\\mathbf{x}),\\mathbf{\\bar{h}}=\\mathbf{y})$ to estimate and pseudo-label the correctness of $G(\\mathbf{x})$ , where $p_{E}(c o n t r a d i c t\\mid\\mathbf{p}=G(\\mathbf{x}),\\mathbf{h}=\\mathbf{y})$ is the likelihood that $G(\\mathbf{x})$ contradicts y. While pseudo-labeling enables the full exploitation of unlabeled data to learn a selection function, controlling the mislabeling error remains as a challenge. ", "page_idx": 3}, {"type": "text", "text": "2.4 Conformal Prediction ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "Conformal prediction [10] outputs a prediction set to quantify the uncertainty of a given model with a model-agnostic correctness guarantee under minimal assumptions on data generating process. Specifically, under the i.i.d. assumption, PAC conformal prediction [11] incorporates the interpretation of tolerance regions [31] and training-conditional inductive conformal prediction [20] through the lens of PAC learning theory [32]. In this paper, we adopt the PAC prediction set learning algorithm to control the rate of mislabeling error in pseudo-labeled samples used to learn a selection function for selective generation. See Section A.1 for detailed discussion on conformal prediction. ", "page_idx": 3}, {"type": "text", "text": "Scalar-parameterized Conformal Set. In this paper, we consider a conformal set $C:\\mathcal{X}\\rightarrow2^{\\mathcal{Y}}$ parameterized by a scalar [11, 33] as $C(\\mathbf{x}):=\\bar{\\{y\\in\\mathcal{y}\\,|\\,\\,f(\\mathbf{x},y)\\geq\\tau\\}}$ , where $\\tau\\in\\mathcal{H}$ is a scalar parameter to learn, $\\mathcal{H}$ is a hypothesis space (e.g., $\\mathcal{H}$ a finely discretized non-negative real numbers), and $f:\\mathcal{X}\\times\\mathcal{Y}\\to\\mathbb{R}_{\\geq0}$ is called a scoring function. The scoring function corresponds to a target model whose uncertainty is to be quantified, where the softmax output is a common choice in classification. Specifically, $f(\\mathbf{x},y)$ measures the likelihood of $y$ as a response given $\\mathbf{x}$ as input. ", "page_idx": 3}, {"type": "text", "text": "PAC Guarantee. The PAC prediction set learning algorithm outputs a conformal set $\\hat{C}$ which upper bounds a miscoverage rate $\\mathcal{R}_{\\mathrm{MC}}(\\hat{C})\\,:=\\,\\mathbb{P}\\{y\\,\\notin\\,\\hat{C}({\\bf x})\\}$ to a desired level $\\varepsilon\\,\\in\\,(0,1)$ , where the miscoverage rate can be generalized to risk $\\mathcal{R}_{01}(\\hat{C}):=\\mathbb{E}\\{\\ell_{01}(\\hat{C},\\mathbf{x},y)\\}$ , on any indicator losses that are monotonic with respect to $\\tau$ . The algorithm is probably approximately correct (PAC) in the sense that it provides a calibration data-conditional guarantee at every risk and confidence level. Specifically, it controls the risk to a desired level irrespective of which calibration data is used to learn $\\hat{C}$ with a desired confidence $\\delta\\in(0,1)$ as follows: $\\mathbb{P}\\{\\mathcal{R}_{01}(\\hat{C})\\leq\\varepsilon\\}\\geq1-\\delta$ , where the probability is taken over the calibration set $\\mathbf{Z}\\sim\\mathcal{D}^{n}$ to learn the conformal set. In this paper, we leverage the PAC conformal set for a pseudo-labeling function such that the guarantee on the labeling quality provides the overall PAC guarantee in semi-supervised selective generator learning algorithm. ", "page_idx": 3}, {"type": "text", "text": "", "page_idx": 4}, {"type": "text", "text": "Algorithm. The PAC conformal set learning algorithm $A_{\\mathrm{Binom}}:({\\mathcal{X}}\\times{\\mathcal{Y}})^{*}\\to{\\mathcal{H}}$ [11, 20, 34] returns the conformal set parameter $\\hat{\\tau}$ , where $\\mathcal{H}$ is a finely-discretized $\\mathbb{R}_{\\geq0}$ . Specifically, the algorithm returns $\\hat{\\tau}=\\operatorname*{max}_{\\tau\\in\\mathcal{H}}\\,\\tau$ subject to $U_{\\mathrm{Binom}}(k_{\\tau};n,\\delta)\\le\\varepsilon$ , where $\\begin{array}{r}{k_{\\tau}\\stackrel{-}{:=}\\sum_{i=1}^{n}\\ell_{01}(\\hat{C},\\mathbf{x}_{i},y_{i})}\\end{array}$ . Letting $F(k;n,\\theta)$ be a cumulative distribution function of a binomial distribu tion with $n$ trials and success probability $\\theta$ , $U_{\\mathrm{Binom}}(k;n,\\delta):=\\operatorname*{inf}\\left\\{\\theta\\in[0,1]\\mid F(k;n,\\theta)\\leq\\delta\\right\\}\\cup\\{1\\}$ is an upper binomial tail bound that satisfies $\\mathbb{P}\\{\\mathcal{R}_{01}(\\hat{C})\\leq U_{\\mathrm{Binom}}(k_{\\tau};n,\\delta)\\}\\geq1-\\delta$ , where $\\delta$ is the desired confidence. Note that we similarly denote a lower binomial tail bound by $L_{\\mathrm{Binom}}$ . If optimization in the algorithm $\\mathcal{A}_{\\mathrm{Binom}}$ is infeasible, the algorithm returns $\\hat{\\tau}=0$ , a vacuous conformal set. Thus, the algorithm is PAC, and see Section A.1 for proof. ", "page_idx": 4}, {"type": "text", "text": "2.5 Calibration ", "text_level": 1, "page_idx": 4}, {"type": "text", "text": "In classification, calibration aims to adjust the classifier\u2019s maximum likelihood response, or confidence, to be correct. We say the classifier response $f:\\mathcal{X}\\times\\mathcal{Y}\\to\\mathbb{R}_{>0}$ is perfectly calibrated with respect to a distribution $\\mathcal{D}$ over $\\mathcal X\\times\\mathcal Y$ and a classifier $\\hat{y}$ if $\\mathbb{P}\\left\\{\\mathbf{y}=\\hat{y}(\\bar{\\mathbf{x}})\\mid f(\\mathbf{x},\\hat{y}(\\mathbf{x}))=t\\right\\}=t$ for all $t\\in[0,1]$ [35, 36]. Calibration aims to find the classifier response such that it is perfectly calibrated asymptotically. In this paper, we make an interesting connection between calibration and selective generation. In particular, given the definition of the perfect calibration for a language scoring function $f_{M}$ , we formally provide a sufficient condition for a selective generator to control the FDR with respect to the textual entailment relation at any desired risk level. ", "page_idx": 4}, {"type": "text", "text": "3 Problem: Selective Generation ", "text_level": 1, "page_idx": 4}, {"type": "text", "text": "Let $\\mathbf{x}\\in\\mathcal{X}$ be a question and $\\mathbf{y}\\in\\mathcal{V}$ be an answer, assuming that each question has a desired answer. Here, we assume $(\\mathbf{x},\\mathbf{y})^{\\mathrm{i.i.d.}}\\mathcal{D}^{\\prime}$ , where $\\mathcal{D}^{\\prime}$ is a data generating process of question-answering pairs. Then, given a generator $G:\\mathcal{X}\\rightarrow\\mathcal{Y}$ , we consider a selective generator $\\hat{S}:\\mathcal{X}\\to\\mathcal{V}\\cup\\{\\mathrm{IDK}\\}$ which refuses to return $G(\\mathbf{x})$ if a selection function $\\hat{s}(\\mathbf{x},G(\\mathbf{x}))\\in\\{0,1\\}$ deems uncertain as follows: ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\hat{S}(\\mathbf x):=\\left\\{G(\\mathbf x)\\quad\\mathrm{if}\\;\\hat{s}(\\mathbf x,G(\\mathbf x))=1\\right._{\\cdot}\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "Our main goal is to learn a selective generator $\\hat{S}$ to control a generalized false discovery rate (FDR) with respect to a relation $R$ as ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\mathcal{R}_{R}(\\hat{S}):=\\mathbb{P}\\left\\{(G(\\mathbf{x}),\\mathbf{y})\\notin R\\ \\Big|\\ \\hat{S}(\\mathbf{x})\\neq\\mathbf{IDK}\\right\\}.\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "Here, the probability is taken over examples $(\\mathbf{x},\\mathbf{y},e,v)$ , where $e:=\\mathbb{1}((G(\\mathbf{x}),\\mathbf{y})\\in R)$ is an additional label to be annotated due to unknown $R$ and $v\\,\\in\\,\\{0,1\\}$ is a visibility flag of $e$ for semisupervised learning. For the data generation of $(\\mathbf{x},\\mathbf{y},e,v)$ , we assume that a label $e$ is observed with an unknown success probability of $p_{v}$ , independent of the generative process of $(\\mathbf{x},\\mathbf{y},e)$ , i.e., $(\\mathbf{x},\\mathbf{y},e,v)\\sim\\mathcal{D}:=\\mathcal{D}^{\\prime}\\langle\\bar{\\nu}$ , where $\\mathcal{D}^{\\prime}$ is a distribution over $\\mathcal{X}\\!\\times\\!\\mathcal{Y}\\!\\times\\!\\{0,1\\}$ and $\\nu:=\\mathrm{Bernoulli}(p_{v})$ . Note that the definition of $e$ , $\\mathcal{D}^{\\prime}$ varies by generator $G$ even with the same data generating distribution of $(\\mathbf{x},\\mathbf{y})$ . In this paper, we design a learning algorithm $\\boldsymbol{\\mathcal{A}}$ that returns a selective generator $\\hat{S}$ to control the generalized FDR with respect to $R$ within a desired level $\\varepsilon\\in\\left(0,1\\right)$ with probability at least $\\bar{\\mathbf{\\Psi}}1-\\bar{\\mathbf{\\Psi}}\\delta\\,\\in\\,(0,1)$ , i.e., $\\mathbb{P}\\left\\{\\mathcal{R}_{R}(\\bar{\\mathcal{A}}(\\mathbf{Z}))\\leq\\varepsilon\\right\\}\\geq1-\\delta$ . Here, the probability is taken over a calibration set $\\mathbf{Z}\\sim\\mathcal{D}^{n}$ . This guarantee is called a probably approximately correct (PAC) guarantee [32]. Among selective generators that satisfies the PAC guarantee, we choose one that minimizes the ratio of IDK-answers with the highest selection efficiency. The main challenge is to find a sample and selection efficient PAC algorithm for any $\\varepsilon$ and $\\delta$ along with designing a relation $R$ for structured labels, as in question-answering. Frequently, we may not obtain a PAC algorithm for any $\\varepsilon$ , so in this paper, we use a relaxed notion of controllable instead of correct if the algorithm provides minimum achievable risk beoyond a given $\\varepsilon$ . ", "page_idx": 4}, {"type": "text", "text": "4 Semi-Supervised Learning for Controllable Selective-Generation ", "text_level": 1, "page_idx": 5}, {"type": "text", "text": "In this paper, we leverage the textual entailment as the evaluation metric in language generation to consider multiple valid answers in a principled way, and propose two selective generator learning algorithms which control FDR with respect to the textual entailment: $\\mathsf{S G e n}^{\\mathsf{S u p}}$ and $\\mathsf{S G e n}^{\\mathrm{Semi}}$ . ", "page_idx": 5}, {"type": "text", "text": "4.1 False Discovery Rate via Textual Entailment (FDR-E) ", "text_level": 1, "page_idx": 5}, {"type": "text", "text": "A textual entailment relation $R_{E}$ is an ordered subset of $y\\times y$ where $(\\mathbf{y}^{\\prime},\\mathbf{y})\\in R_{E}$ if $\\mathbf{y}^{\\prime}$ entails $\\mathbf{y}$ . In question-answering as an example, the generated answer $G(\\mathbf{x})$ is correct if the reference answer $\\mathbf{y}$ is a logical consequence of $G(\\mathbf{x})$ . In other words, $G(\\mathbf{x})$ is valid if $G(\\mathbf{x})\\in E_{\\mathrm{true}}(\\mathbf{y})$ , where the true entailment set function $E_{\\mathrm{true}}:\\mathcal{V}\\to2^{\\mathcal{V}}$ is defined as follows: $E_{\\mathrm{true}}(\\mathbf{y}):=\\left\\{\\mathbf{y}^{\\prime}\\in\\dot{\\mathcal{V}}\\mid(\\mathbf{y}^{\\prime},\\mathbf{y})\\in R_{E}\\right\\}$ . Then, an FDR with respect to the entailment relation $R_{E}$ (FDR-E) that we aim to control is as follows: ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\mathcal{R}_{R_{E}}(\\hat{S}):=\\mathbb{P}\\{G(\\mathbf{x})\\notin E_{\\mathrm{true}}(\\mathbf{y})\\mid\\hat{S}(\\mathbf{x})\\neq\\mathtt{I D K}\\},\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "where the probability is taken over labeled examples, i.e., $(\\mathbf{x},\\mathbf{y},e)\\,\\sim\\,\\mathcal{D}$ . Here, the label $e$ is specifically called an entailment label, i.e., $e:=G(\\mathbf{x})\\in E_{\\mathrm{true}}(\\mathbf{y})$ . Then, for any $G,\\mathcal{D},\\mathcal{V}$ , and $\\hat{S}$ , the FDR-E can be decomposed as follows: ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\underbrace{\\mathbb{P}_{\\mathcal{D}_{\\delta}}\\{G(\\mathbf{x})\\notin E_{\\mathrm{true}}(\\mathbf{y})\\}}_{(\\mathbf{A})}=\\underbrace{\\mathbb{P}_{\\mathcal{D}_{\\delta}}\\{v=1\\}}_{(\\mathbf{B})}\\underbrace{\\mathbb{P}_{\\mathcal{D}_{\\delta}}\\{e=0\\}}_{(\\mathbf{C})}+\\underbrace{\\mathbb{P}_{\\mathcal{D}_{\\delta}}\\{v=0\\}}_{(\\mathbf{D})}\\underbrace{\\mathbb{P}_{\\mathcal{D}_{\\delta}}\\{e=0\\}}_{(\\mathbf{E})},\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "where $\\mathbb{P}_{\\mathcal{D}_{\\hat{S}}}\\{\\cdot\\}:=\\mathbb{P}\\{\\cdot\\mid\\hat{S}(\\mathbf{x})\\neq\\mathrm{IDK})$ . Note that as $(\\mathbf{x},\\mathbf{y},e)$ and $v$ are independent, (A), (C), and (E) in (2) are of the same quantity, which is the target risk that we aim to find an upper bound. ", "page_idx": 5}, {"type": "text", "text": "4.2 FDR-E Bound for Supervised Learning ", "text_level": 1, "page_idx": 5}, {"type": "text", "text": "We first propose the supervised learning algorithm $\\mathsf{S G e n}^{\\mathsf{S u p}}$ (Algorithm 8), a direct modification of [9] to language generation tasks. In particular, $\\mathsf{S G e n}^{\\mathsf{S u p}}$ is a supervised method in the sense that it solely exploits labeled examples $\\mathbf{Z}_{E}:=\\{(\\mathbf{x},\\mathbf{y},e)\\mid(\\mathbf{x},\\mathbf{y},e,v)\\in\\mathbf{Z}\\land v=1\\}$ to learn a selective generator that controls the upper bound (C) in (2). Note that for supervised learning, we assume that (B) in (2) is always 1, so we only consider the the upper bound (C) via the binomial tail bound as [9]. ", "page_idx": 5}, {"type": "text", "text": "4.3 FDR-E Bound for Semi-Supervised Learning ", "text_level": 1, "page_idx": 5}, {"type": "text", "text": "As $\\mathsf{S G e n}^{\\mathsf{S u p}}$ requires human annotations for entailment labels and makes no use of abundant unlabeled examples $\\mathbf{Z}_{U}:=\\{(\\mathbf{x},\\mathbf{y})\\mid(\\mathbf{x},\\mathbf{y},e,v)\\in\\mathbf{Z}\\land v=0\\}$ , we further propose a novel semi-supervised learning algorithm $\\mathsf{S G e n}^{\\mathrm{Semi}}$ (Algorithm 5), which fully exploits both $\\mathbf{Z}_{E}$ and $\\mathbf{Z}_{U}$ while controlling the FDR-E in (2). In particular, we (1) estimate a true entailment set $E_{\\mathrm{true}}$ via conformal prediction with labeled examples $\\mathbf{Z}_{E}$ and then (2) use the estimated entailment set $\\hat{E}$ to annotate pseudo-labels on $\\mathbf{Z}_{U}$ . Finally, we (3) use both labeled and pseudo-labeled examples to learn a selective generator. Interestingly, this heuristic-looking algorithm could be a rigorous algorithm that controls the FDR-E of a selective generator, which will be described in the following sections. ", "page_idx": 5}, {"type": "text", "text": "4.3.1 FDR-E Decomposition ", "text_level": 1, "page_idx": 5}, {"type": "text", "text": "$\\mathsf{S G e n}^{\\mathsf{S e m i}}$ leverages unlabeled examples by estimating an entailment set as a pseudo-labeling function. However, the estimation error introduces wrong pseudo-labels. Here, we consider a rigorous way to derive the FDR-E upper bound by controlling the estimation error of the pseudolabeling function. In particular, two different types of estimation errors of an estimated entailment set $\\hat{E}$ are illustrated in Figure 2, i.e., a false negative entailment rate (FNER) and a false entailment rate (FER). This results in the following decomposition. ", "page_idx": 5}, {"type": "image", "img_path": "glfYOAzh2f/tmp/2293b75b69fe9351b813e3c73825762e9d1ca5830621da42d68cfdac39609ca1.jpg", "img_caption": ["Figure 2: Decomposition of a false discovery rate with respect to an entailment set $E_{\\mathrm{true}}$ (FDR-E). Here, $\\Omega_{\\mathrm{TD}}^{\\bar{E}}:=\\{(\\mathbf x,\\mathbf y,e,v)\\mid G(\\mathbf x)\\in E(\\mathbf y)\\}$ . "], "img_footnote": [], "page_idx": 5}, {"type": "text", "text": "Lemma 1. $(E)$ in (2) is decomposed as follows: ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\underbrace{\\mathbb{P}_{\\mathcal{D}_{\\delta}}\\{e=0\\}}_{(E)}=\\underbrace{\\mathbb{P}_{\\mathcal{D}_{\\delta}}\\{e=0,\\hat{e}=1\\}}_{F E R}-\\underbrace{\\mathbb{P}_{\\mathcal{D}_{\\delta}}\\{e=1,\\hat{e}=0\\}}_{F N E R}+\\underbrace{\\mathbb{P}_{\\mathcal{D}_{\\delta}}\\{\\hat{e}=0\\}}_{N E R}.\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "Here, the first two terms are related to the entailment label estimation error and the last term is the approximate FDR-E using pseudo-labels. As three terms are inter-related, we choose to control the FER term to control (E) in (2) via conformal prediction in the following section. ", "page_idx": 6}, {"type": "text", "text": "4.3.2 Pseudo-labeling via Conformalized Entailment Set Learning ", "text_level": 1, "page_idx": 6}, {"type": "text", "text": "$\\mathsf{S G e n}^{\\mathrm{Semi}}$ leverages the PAC conformal prediction for the entailment label estimation to control the mislabeling error. Specifically, we estimate the true entailment set function $E_{\\mathrm{true}}$ via an estimated entailment set $\\hat{E}$ using $\\mathbf{Z}_{E}$ , where we use the entailment scoring function $f_{E}$ as a scoring function, i.e., $\\hat{E}(\\mathbf{y}):=\\{\\mathbf{y}^{\\prime}\\in\\mathcal{Y}\\mid f_{E}(\\mathbf{y}^{\\prime},\\mathbf{y})\\geq\\tau_{E}\\}$ . Here, the corresponding loss $\\ell(\\hat{E},\\mathbf{x},\\mathbf{y},e):=\\mathbb{1}(e=0\\wedge$ $G(\\mathbf{x})\\in\\hat{E}(\\mathbf{y}))$ is a monotonically non-increasing function with respect to $\\tau_{E}$ , so we can use the PAC conformal set learning algorithm. Given a desired risk $\\varepsilon_{E}$ and confidence $\\delta_{E}$ level, the corresponding algorithm $\\mathcal{A}_{\\mathrm{FER}}$ (i.e., Algorithm 1) returns the estimated entailment set function $\\hat{E}$ which controls the false entailment rate (FER) of pseudo-labeled examples $\\mathcal{R}_{\\mathrm{FER}}(\\hat{E}):=\\mathbb{P}_{\\mathcal{D}_{\\hat{S}}}\\{e=0\\wedge G(\\mathbf{x})_{\\sim}\\in\\hat{E}(\\mathbf{y})\\}$ with the following PAC guarantee, where the probability is taken over training examples from $\\mathcal{D}_{\\hat{S}}$ . ", "page_idx": 6}, {"type": "equation", "text": "$$\n\\mathbb{P}\\{\\mathcal{R}_{\\mathrm{FER}}(\\hat{E})\\leq\\varepsilon_{E}\\}\\geq1-\\delta_{E}.\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "4.3.3 FDR-E Bound ", "text_level": 1, "page_idx": 6}, {"type": "text", "text": "We then bound the FDR-E for semi-supervised learning, i.e., (E) in (2), via the PAC guarantee by the conformal set learning on $\\mathbf{Z}_{E}$ and the binomial tail bound on $\\mathbf{Z}_{E}$ and $\\mathbf{Z}_{U}$ . In particular, the FER is upper-bounded by $\\varepsilon_{E}$ , the FNER is lower-bounded by the binomial tail bound using $\\mathbf{Z}_{E}$ , and NER is upper-bounded by the binomial tail bound using $\\mathbf{Z}_{U}$ . These bounds hold with high probability, and are therefore combined via a union bound, as in the following lemma. See Appendix $\\mathrm{G}$ for a proof. ", "page_idx": 6}, {"type": "text", "text": "Lemma 2. Let $\\hat{\\mathbf{Z}}_{E}:=\\{(\\mathbf{x},\\mathbf{y},e)\\in\\mathbf{Z}_{E}\\ |\\ \\hat{S}(\\mathbf{x})\\neq{\\cal I}{\\cal D}K\\}$ and $\\hat{\\mathbf{Z}}_{U}:=\\{(\\mathbf{x},\\mathbf{y})\\in\\mathbf{Z}_{U}\\mid\\hat{S}(\\mathbf{x})\\neq I D K\\}$ . For any $G,\\,{\\mathcal{D}},\\,\\nu_{i}$ , and $\\hat{S}$ , $i f\\hat{E}:=\\mathcal{A}_{F E R}(\\hat{\\mathbf{Z}}_{E})$ satisfies $\\mathbb{P}_{\\hat{\\mathbf{z}}_{E}}\\{\\mathcal{R}_{F E R}(\\hat{E})\\leq\\varepsilon_{E}\\}\\geq1-\\delta_{E}^{\\prime}/2$ , we have ", "page_idx": 6}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathbb{P}_{\\mathcal{D}}\\{e=0\\}\\le\\varepsilon_{E}-L_{\\mathrm{Binom}}(\\hat{k};|\\hat{\\mathbf{Z}}_{E}|,\\delta_{E}^{\\prime}/2)+U_{\\mathrm{Binom}}(\\hat{l};|\\hat{\\mathbf{Z}}_{U}|,\\delta_{S}^{\\prime})=:U_{S S L}}\\end{array}\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "with probability at least $1\\,-\\,\\delta_{E}^{\\prime}\\,-\\,\\delta_{S}^{\\prime}$ , where the probability is taken over $\\mathbf{Z}$ . Here, $\\begin{array}{r l}{\\widehat{k}}&{{}:=}\\end{array}$ $\\begin{array}{r}{\\sum_{(\\mathbf{x},\\mathbf{y},e)\\in\\hat{\\mathbf{Z}}_{E}}\\mathbb{1}(e=1\\wedge G(\\mathbf{x})\\notin\\hat{E}(\\mathbf{y}))}\\end{array}$ and $\\begin{array}{r}{\\hat{l}:=\\sum_{(\\mathbf{x},\\mathbf{y})\\in\\hat{\\mathbf{Z}}_{U}}\\mathbb{1}(G(\\mathbf{x})\\notin\\hat{E}(\\mathbf{y}))}\\end{array}$ . ", "page_idx": 6}, {"type": "text", "text": "Notably, each of three bounds holds over a conditional distribution $\\mathcal{D}_{\\hat{S}}$ , but Lemma 2 relaxes this to an unconditional distribution $\\mathcal{D}$ for our final FDR-E guarantee. ", "page_idx": 6}, {"type": "text", "text": "Optimizing the FDR-E Bound (5). Lemma 2 introduces a hyper-parameter $\\varepsilon_{E}$ , which controls a trade-off between the FER and other terms. To find a best trade-off, we optimize $\\varepsilon_{E}$ to minimize the upper bound (5) among $Q$ candidates of $\\varepsilon_{E}$ via $A_{U_{\\mathrm{SSL}}-\\mathrm{Opt}}$ , described in Algorithm 3. This optimization algorithm can find a tighter FDR-E bound, as in the following lemma. See Appendix $\\mathrm{H}$ for a proof. ", "page_idx": 6}, {"type": "text", "text": "Lemma 3. Let $U_{S S L}^{O P T}=m i n_{\\varepsilon_{E}}U_{S S L}$ be the smallest bound of (5). Then, ", "page_idx": 6}, {"type": "equation", "text": "$$\n\\mathbb{P}_{\\mathcal{D}}\\{e=0\\}\\le U_{S S L}^{O P T}\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "with probability at least $1-\\delta_{E}^{\\prime}-\\delta_{S}^{\\prime}$ , where the probability is taken over $\\mathbf{Z}$ . ", "page_idx": 6}, {"type": "text", "text": "Note that for semi-supervised learning, the upper bound of (B), (C), (D), and $\\mathrm{(E)}$ in (2) should be provided. The upper bound of (E) is provided in (5), which we denote by $U_{\\mathrm{SSL}}$ . The upper bound of (B), (C), and (D) are denoted by $w_{\\mathrm{{SL}}},U_{\\mathrm{{SL}}}$ , and $w_{\\mathrm{SSL}}$ , respectively, each of which is computed by the binomial tail bound. See Algorithm 4 and the proof of Theorem 1 for details. ", "page_idx": 6}, {"type": "text", "text": "4.4 Neuro-selection Functions ", "text_level": 1, "page_idx": 6}, {"type": "text", "text": "The FDR-E bounds for both supervised and semi-supervised learning are crucial for controlling the final FDR-E of a selective generator given a selection function $\\hat{s}$ . But, the choice of the selection function is critical for a good selection efficiency and here we discuss a better selection function than the standard one, i.e., $\\hat{s}(\\mathbf x)\\;:=\\;\\mathbb{1}\\left(f_{M}(\\mathbf x,G(\\mathbf x))\\ge\\tau_{S}\\right)$ for $\\tau_{S}\\,\\in\\,\\mathbb{R}_{\\geq0}$ . In particular, certified selective classification [9] considers the single-threshold indicator function using the maximum likelihood as the confidence rate function. For the language generation, the conditional probability of the answer $\\hat{\\mathbf{y}}$ , i.e., $f_{M_{1}}({\\bf x},\\hat{{\\bf y}})$ , would be a natural and commonly-used candidate. However, as it is known to be poorly calibrated [37], an alternative would be a self-consistency score, i.e., $\\begin{array}{r}{f_{M_{2}}(\\mathbf{x},G(\\mathbf{x})):=\\frac{1}{K}\\sum_{k=1}^{K}f_{E}(\\tilde{\\mathbf{y}}_{k},G(\\mathbf{x}))}\\end{array}$ kK=1 fE(y\u02dck, G(x)), where y\u02dck are generated answers with the same question $\\mathbf{x}$ but different random seeds. It is empirically shown that the self-consistency score properly quantifies uncertainty when a language model is uncertain of an answer [19]. The importance of score calibration with respect to the true entailment relation is demonstrated in Lemma 4, which provides the sufficient condition for the selective generation algorithm using the single-threshold indicator function (Algorithm 5) to control the FDR-E at any level. See Appendix J for a proof. ", "page_idx": 6}, {"type": "text", "text": "", "page_idx": 7}, {"type": "text", "text": "Lemma 4. If we have access to $E_{t r u e}$ and $f_{M}$ is perfectly calibrated with respect to $E_{t r u e}$ , the FDR- $\\cdot E$ is monotonically non-increasing in $\\tau_{S}$ . ", "page_idx": 7}, {"type": "text", "text": "However, as [37] points out, calibrating the language scoring function remains an uneasy task, os it is still an active research area. Therefore, we propose a general class of selection functions, neuroselection functions, which is the multiple-threshold indicator function using possibly learnable feature map $\\Phi:\\mathbf{x}\\mapsto\\mathbb{R}^{v}$ as follows: $\\hat{s}(\\mathbf{x};\\Phi,\\mathbf{W},\\mathbf{b}):=\\wedge_{i=1}^{u}(\\mathbf{W}\\Phi(\\mathbf{x}))_{i}+\\mathbf{b}_{i}\\ge0$ , where $\\mathbf{W}\\,\\in\\,\\mathbb{R}^{u\\times v}$ and $\\mathbf{b}\\in\\mathbb{R}^{u\\times1}$ are linear proejction and bias terms, respectively. In this paper, we only consider two specific sub-classes of neuro-selection functions, where the former reduces to learning the single-threshold selection function using a scoring function (Algorithm 5) and the latter reduces to learning the bi-threshold selection function using two scoring functions (Algorithm 6). Only the bias term $\\mathbf{b}$ is the learnable parameter for both algorithms, where the others set as hyperparameters. Specifically, $\\mathbf{W}=\\mathbf{I}_{1}$ , $\\Phi_{1}(\\bar{\\mathbf{x}})=\\left[f_{M}(\\mathbf{x},G(\\mathbf{x}))\\right]$ , and ${\\mathbf b}=-\\tau_{S}$ for Algorithm 5, while $\\mathbf{W}=\\mathbf{I}_{2}$ , $\\Phi_{2}(\\mathbf{x})=[f_{M_{1}}(\\mathbf{x},G(\\mathbf{x}))\\,\\,f_{M_{2}}(\\mathbf{x},G(\\mathbf{x}))]^{T}$ , and $\\mathbf{b}=-[\\tau_{S,1},\\tau_{S,2}]^{T}$ for Algorithm 6 if two promising scoring functions exist. Here, developing a selection function learning algorithm where $\\mathbf{W}$ and $\\Phi({\\bar{\\cdot}})$ are also fully learning parameters is left as future work. In the following section, we introduce our algorithm that chooses the optimal combination of scoring functions via neuro-selection functions. ", "page_idx": 7}, {"type": "text", "text": "4.5 Semi-Supervised Selective Generator Learning Algorithm with Model Selection ", "text_level": 1, "page_idx": 7}, {"type": "text", "text": "$\\mathsf{S G e n}^{\\mathrm{Semi}}$ is a certified semi-supervised selective generator learning algorithm, which fully exploits unlabeled data in learning a selection function via certified pseudo-labeling and uses a neuro-selection function for choosing an optimal combination of scoring functions. In particular, $\\mathsf{S G e n}^{\\mathrm{Semi}}$ solves the following optimization problem over selective generators $\\mathcal{H}$ such that $\\hat{S}$ closely satisfies the equality in the constraint, as described in Algorithm 7: ", "page_idx": 7}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\mathrm{find}_{\\hat{S}\\in\\mathcal{H}}\\,\\,\\hat{S}\\quad\\mathrm{subj.\\,\\,to}\\quad w_{\\mathrm{SL}}U_{\\mathrm{SL}}+w_{\\mathrm{SSL}}U_{\\mathrm{SSL}}\\leq\\varepsilon_{S},}\\end{array}\n$$", "text_format": "latex", "page_idx": 7}, {"type": "text", "text": "Here, $\\hat{S}\\in\\mathcal{H}$ has a selection function $\\hat{s}(\\mathbf{x};\\Phi_{2}(\\mathbf{x}),\\sf d i a g(w),\\mathbf{b})$ , where $\\mathbf{w}\\in\\{[1,0]^{T},[0,1]^{T},[1,1]^{T}\\}$ and $\\mathbf{b}\\in\\mathbb{R}_{\\leq0}^{2}$ . Note that $\\mathsf{S G e n}^{\\mathrm{Semi}}$ returns an additional term $\\hat{U}$ , which is the FDR-E bound given the selective generator $\\hat{S}$ (i.e., Algorithm 4) and informs the infeasibility of the optimization. The proposed Algorithm 7 satisfies the following controllability guarantee. See Appendix I for a proof. ", "page_idx": 7}, {"type": "text", "text": "Theorem 1. $\\mathcal{A}_{S G e n}s e m i$ satisfies the following controllable guarantee on the FDR-E, i.e., ", "page_idx": 7}, {"type": "equation", "text": "$$\n\\mathbb{P}\\big\\{\\mathbb{P}\\{G(\\mathbf{x})\\notin E_{\\mathrm{true}}(\\mathbf{y})\\mid\\hat{S}(\\mathbf{x})\\neq\\mathrm{IDK}\\}\\leq\\hat{U}\\big\\}\\geq1-\\delta,\n$$", "text_format": "latex", "page_idx": 7}, {"type": "text", "text": "where the inner and outer probabilities are taken over $(\\mathbf{x},\\mathbf{y},e,v)\\sim\\mathcal{D}$ and $\\mathbf{Z}\\sim\\mathcal{D}^{n}$ , respectively, and $(\\hat{S},\\hat{U}):=\\mathcal{A}_{\\sf S G e n}{}^{\\sf S e n i}\\left({\\bf Z}\\right)$ . Here, $\\delta:=\\delta_{W}+\\delta_{S}+\\delta_{E}$ is a desired confidence level, where $\\delta_{W}$ is for the upper bounds on $w_{\\mathrm{SL}}$ and $w_{\\mathrm{SSL}}$ , $\\delta_{S}$ is for (C) in (2) and the NER, and $\\delta_{E}$ is for the FER and FNER. ", "page_idx": 7}, {"type": "text", "text": "Here, $\\boldsymbol{A}_{\\mathrm{SGen}}\\mathrm{semi}$ is controllable in the sense that it upper bounds the FDR-E of a learned selective generator to a desired level $\\varepsilon_{S}$ or at least to a minimum achievable level $\\hat{U}$ with confidence $\\delta$ . ", "page_idx": 7}, {"type": "text", "text": "5 Experiments ", "text_level": 1, "page_idx": 7}, {"type": "text", "text": "We demonstrate the efficacy of our methods in controlling the FDR-E on pre-trained GLMs under various setups. We use two GLMs, GPT-3.5-Turbo and Alpaca-7B, alongside the Natural Questions (NQ) dataset to annotate entailment labels for question-answer pairs. Details on model configurations, datasets, and additional experimental results can be found in Section A.3 and Appendix K. ", "page_idx": 7}, {"type": "text", "text": "gMoeritthhomd s9. ) Waen dc oanns iudnesr utpweor vhiseeudri slteiacr sneinmgi -aslugpoerrivtihsmed [ a9l]g oSrGitehnms,( SAGlgeonrHPi-LtShemmi a1n0)d $\\mathsf{S G e n}_{\\mathrm{PFL}}^{\\mathrm{H-Semi}}$ s( Atlopfaefrixcaapmlcoyei ttoe tfr  howeu itru hncoleaurbtt ieaflnieeydd   gsdeuaatmrai a-bnstyue pepe sroevnui sdmeoid-s llamabbeetellhiinongdg   tSeerGxretounr.Sa elS meiG ne(tnaAHPill-FgSLmoeemriinttha dbmad is7te)i.do $\\mathsf{S G e n}_{\\mathrm{PL}}^{\\mathrm{H-Semi}}$ h aoonluddt $\\mathsf{S G e n}_{\\mathrm{PFL}}^{\\mathrm{H-Semi}}$ ", "page_idx": 7}, {"type": "table", "img_path": "glfYOAzh2f/tmp/30e766d6b4fffb8d52629a5307905dac57186bef58374535b8134694f03b024a.jpg", "table_caption": ["Table 1: Comparison results of semi-supervised methods. Here, $|\\mathbf{Z}_{U}|\\,=10K$ for GPT-3.5-turbo and Alpaca-7B. The best results are highlighted in bold and results from methods that do not satisfy desired FDR-E guarantees in learning are underlined. "], "table_footnote": [], "page_idx": 8}, {"type": "table", "img_path": "glfYOAzh2f/tmp/848634725095bcf21970b33be401c2f2557fe788f742670e4d78361370080d31.jpg", "table_caption": ["Table 2: Qualitative results by Alpaca7B. "], "table_footnote": [], "page_idx": 8}, {"type": "text", "text": "a pseudo-labeled sample if its entailment score is below a specific threshold. $\\mathsf{S G e n}_{\\mathtt{E M}}$ is a certified suunlstsu poenr $\\mathsf{S G e n}_{\\mathrm{NoMS}}^{\\mathrm{Semi}}$ t(hAoldg otrhitath tma k5e) sf othr et wEo Md ifmfeertreinct  fsocro rminega sfuurnicntgi otnhse , $f_{M_{1}}$ eacntnd $f_{M_{2}}$ , Wues eadl sion $\\mathsf{S G e n}^{\\mathrm{Semi}}$ ${\\sf S G e n}_{\\tt N o M S}^{\\tt S e m i}$ is a certified semi-supervised learning Saulpg orithm using a single1-threshol2d indicator function given a scoring function. We also take (Algorithm 8) as a baseline, since it is a direct modification of [9] to the language generation problem. ", "page_idx": 8}, {"type": "text", "text": "Scoring Functions. We use the conditional probability of an answer as $f_{M_{1}}$ and the self-consistency score [19] as $f_{M_{2}}$ , since our goal is to generate the sequence which is not only logically consistent to the true answer but also linguistically correct. ", "page_idx": 8}, {"type": "text", "text": "wwee  uhsaev e( 0.f2iv5e,  0c.o0n2t)r oul nlpeasrsa smpeetceirfsi ,o dws $(i.e.,\\,\\mathsf{S G e n}^{\\mathsf{S e m i}}$ , ${\\sf S G e n}_{\\tt N o M S}^{\\tt S e m i}$ ,s :a $(\\varepsilon,\\delta)$ nSemi-Sup), $(\\varepsilon_{S},\\delta_{S},\\delta_{E},\\delta_{W})$ $\\varepsilon_{S}~=~\\varepsilon$ $\\delta_{S}~=~$ $(\\delta\\,-\\,\\delta_{W})/2,\\delta_{E}\\,=\\,(\\delta^{'}\\!-\\,\\delta_{W})/2,\\delta_{W}\\,=\\,10^{-5}$ . For other methods without using entailment sets, Algorithm 8, Algorithm 9, and Algorithm 10, we use $\\varepsilon$ and $\\delta$ accordingly. Additionally, we use $Q=5$ for Algorithm 3. ", "page_idx": 8}, {"type": "text", "text": "FDR-E Guarantee and Efficiency. As can be seen in Table 1, our method $\\mathsf{S G e n}^{\\mathsf{S e m i}}$ can overall achieve desired FDR-E guarantees with better efficiency compared to baselines. Depending on the quality of scoring functions (e.g., $f_{M_{1}}$ ), our variation $\\mathsf{S G e n}_{\\mathrm{NoMS}}^{\\mathrm{Semi}}$ may not find a selective generator that satisfies a desired FDR-E (denoted in the underlined FDR-E). The heuristic methods, i.e., SGenHP-LS and SGenHP-FSLemi , do not provide theoretical guarantees on FDR-E. In Figure 1 and Table 2, we can correctly predict even with the complicated answers, e.g., which have many equivalent words, because we do not rely on the EM metric. We conducted 100 random experiments for each method to show how well FDR-E is bounded under a desired FDR-E. As shown by the green boxes In Figure 4, which are successfully bounded under $\\varepsilon_{S}=0.25$ , we can see that the FDR-E for a learned selective generator is well controlled below $\\varepsilon_{S}$ under the test environment. Among the certified methods with theoretical guarantees, results appear to align well with the expected theoretical basis. ", "page_idx": 8}, {"type": "text", "text": "Why Entailment Labels. As expected and can be seen in Table 3 by comparing $\\mathsf{S G e n}_{\\mathtt{E M}}$ and $\\mathsf{S G e n}^{\\mathsf{S u p}}$ , a metric like EM cannot measure correctness correctly. Unlike classification, generative tasks can have infinite number of true answers so it is not likely to have exact match. Instead, entailment labels provide semantic correctness, so $\\mathsf{S G e n}^{\\mathsf{S u p}}$ can perform better and more efficient than $\\mathsf{S G e n}_{\\mathtt{E M}}$ . ", "page_idx": 8}, {"type": "image", "img_path": "glfYOAzh2f/tmp/54fe0c69b5ae5a33d1e0ff2d1f7ce9a174b36b72e81f16201e92d96d014076c1.jpg", "img_caption": ["Figure 3: Efficiency results over different numbers of unlabeled samples. (a) and (b) use $\\mathsf{S G e n}_{\\mathrm{NoMS}}^{\\mathrm{Semi}}$ with $f_{M_{2}}$ score. (c) and (d) use $\\mathsf{S G e n}^{\\mathrm{Semi}}$ that has neuro-selection function. Both methods show increasing performance as more unlabeled samples $\\mathbf{Z}_{U}$ are used. For each experiment, the values were measured after averaging 10 random splits and an error bar means standard deviation. "], "img_footnote": [], "page_idx": 9}, {"type": "text", "text": "Why Semi-Supervised Learning. We observe that our semi-supervised learning for selective generation is effective. In particular, the fully supervised methods in Table 3 achieves the efficiency of 0.7535 and 0.2959 for GPT-3.5 and Alpaca-7B, respectively, with the entire labeled samples $\\mathbf{Z}_{E}$ (when they satisfy a $\\varepsilon$ -FDR-E guarantee). Compared to these, the proposed semi-supervised method $\\mathsf{S G e n}^{\\mathrm{Semi}}$ achieves the efficiency of 0.7584 and 0.3173 for GPT-3.5 and Alpaca-7B, respectively, by only using $75\\%$ of labeled examples. Additionally, we observe that more unlabeled samples are beneficial to achieving better efficiency as can be seen in Figure 3. This implies that if we can approximate the entailment set well and the size of $\\mathbf{Z}_{U}$ is enough, we can enjoy our certified pseudo-entailment labeling by the semi-supervised learning even with small $\\mathbf{Z}_{E}$ . ", "page_idx": 9}, {"type": "text", "text": "Why Model Selection. It is hard to manually find a well calibrated scoring function. But, given multiple scoring functions, a neuro-selection function learns to choose right scoring functions that achieves a desired FDR-E and maximizes selection efficiency. This is empiricially validated in Table 1, as $\\mathsf{S G e n}^{\\mathrm{Semi}}$ is better on average efficiency. ", "page_idx": 9}, {"type": "text", "text": "6 Conclusion ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "We propose selective generation, a generalized version of [9] for GLMs to handle semantic correctness between two structured answers. To this end, we leverage logical entailment to define a new entailment-based FDR (FDR-E) metric. As obtaining entailment labels are expensive, we propose novel semi-supervised learning for selective generation by using entailment sets as a pseudo-labeling function. To enhance the low selective efficiency due to inefficient scoring functions, we propose neuro-selection functions for effectively optimizing scoring functions for better selective efficiency and the FDR-E guarantee. The efficacy of our proposed algorithms $\\mathsf{S G e n}^{\\mathrm{Semi}}$ and $\\mathsf{S G e n}^{\\mathsf{S u p}}$ are theoretically and empirically justified. ", "page_idx": 9}, {"type": "text", "text": "Limitations. Our algorithm needs the i.i.d. assumption for a correctness guarantee, which can be violated in practical situations. We leverage expensive entailment labels, where the labels are obtained by considering logical entailment between a true answer and a generated answer. This limitation is partially mitigated by proposing the semi-supervised method to propagate entailment-labeled samples to samples without entailment labels. Also, our results show the empirical FDR-E is not much closely bounded under $\\varepsilon$ , especially on Alpaca7B, which implies that we may need a tighter FDR-E bound. ", "page_idx": 9}, {"type": "text", "text": "Acknowledgements ", "text_level": 1, "page_idx": 10}, {"type": "text", "text": "This work was supported by Institute of Information & communications Technology Planning & Evaluation (IITP) grant funded by the Korea government (MSIT) (No.RS-2019-II191906, Artificial Intelligence Graduate School Program (POSTECH) $(50\\%)$ ; RS-2024-00457882, Artificial Intelligence Research Hub Project $(25\\%)$ ; RS-2024-00509258, AI GUARDIANS: Development of Robust, Controllable, and Unbiased Trustworthy AI Technology $(25\\%)$ ). Also, we appreciate valuable comments by NeurIPS reviewers. ", "page_idx": 10}, {"type": "text", "text": "References ", "text_level": 1, "page_idx": 10}, {"type": "text", "text": "[1] Alec Radford, Jeffrey Wu, Rewon Child, David Luan, Dario Amodei, Ilya Sutskever, et al. Language models are unsupervised multitask learners. OpenAI blog, 1(8):9, 2019. [2] Tom B. Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Sandhini Agarwal, Ariel Herbert-Voss, Gretchen Krueger, Tom Henighan, Rewon Child, Aditya Ramesh, Daniel M. Ziegler, Jeffrey Wu, Clemens Winter, Christopher Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Scott Gray, Benjamin Chess, Jack Clark, Christopher Berner, Sam McCandlish, Alec Radford, Ilya Sutskever, and Dario Amodei. Language models are few-shot learners, 2020. [3] Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-Anne Lachaux, Timoth\u00e9e Lacroix, Baptiste Rozi\u00e8re, Naman Goyal, Eric Hambro, Faisal Azhar, Aurelien Rodriguez, Armand Joulin, Edouard Grave, and Guillaume Lample. Llama: Open and efficient foundation language models, 2023. [4] Rohan Taori, Ishaan Gulrajani, Tianyi Zhang, Yann Dubois, Xuechen Li, Carlos Guestrin, Percy Liang, and Tatsunori B. Hashimoto. Stanford alpaca: An instruction-following llama model. https://github.com/tatsu-lab/stanford_alpaca, 2023. [5] OpenAI Team. ChatGPT. https://chat.openai.com/, 2021. [6] Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Lukasz Kaiser, and Illia Polosukhin. Attention is all you need. Advances in neural information processing systems, 30, 2017. [7] Margaret Li, Stephen Roller, Ilia Kulikov, Sean Welleck, Y-Lan Boureau, Kyunghyun Cho, and Jason Weston. Don\u2019t say that! making inconsistent dialogue unlikely with unlikelihood training. In Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pages 4715\u20134728, Online, July 2020. Association for Computational Linguistics.   \n[8] Long Ouyang, Jeff Wu, Xu Jiang, Diogo Almeida, Carroll L. Wainwright, Pamela Mishkin, Chong Zhang, Sandhini Agarwal, Katarina Slama, Alex Ray, John Schulman, Jacob Hilton, Fraser Kelton, Luke Miller, Maddie Simens, Amanda Askell, Peter Welinder, Paul Christiano, Jan Leike, and Ryan Lowe. Training language models to follow instructions with human feedback, 2022. [9] Yonatan Geifman and Ran El-Yaniv. Selective classification for deep neural networks. Advances in neural information processing systems, 30, 2017.   \n[10] Vladimir Vovk, Alex Gammerman, and Glenn Shafer. Algorithmic learning in a random world. Springer Science & Business Media, 2005.   \n[11] Sangdon Park, Osbert Bastani, Nikolai Matni, and Insup Lee. Pac confidence sets for deep neural networks via calibrated prediction. In International Conference on Learning Representations, 2020.   \n[12] Stephen Bates, Anastasios Angelopoulos, Lihua Lei, Jitendra Malik, and Michael I Jordan. Distribution-free, risk-controlling prediction sets. arXiv preprint arXiv:2101.02703, 2021.   \n[13] Isaac Gibbs and Emmanuel Cand\u00e8s. Adaptive conformal inference under distribution shift, 2021.   \n[14] Sangdon Park, Osbert Bastani, and Taesoo Kim. Acon2: Adaptive conformal consensus for provable blockchain oracles, 2023.   \n[15] Samuel Bowman, Gabor Angeli, Christopher Potts, and Christopher D Manning. A large annotated corpus for learning natural language inference. In Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, pages 632\u2013642, 2015.   \n[16] Adina Williams, Nikita Nangia, and Samuel R Bowman. A broad-coverage challenge corpus for sentence understanding through inference. In Proceedings of NAACL-HLT, pages 1112\u20131122, 2018.   \n[17] Tom Kwiatkowski, Jennimaria Palomaki, Olivia Redfield, Michael Collins, Ankur Parikh, Chris Alberti, Danielle Epstein, Illia Polosukhin, Jacob Devlin, Kenton Lee, et al. Natural questions: a benchmark for question answering research. Transactions of the Association for Computational Linguistics, 7:453\u2013466, 2019.   \n[18] Zhengbao Jiang, Jun Araki, Haibo Ding, and Graham Neubig. How Can We Know When Language Models Know? On the Calibration of Language Models for Question Answering. Transactions of the Association for Computational Linguistics, 9:962\u2013977, 09 2021.   \n[19] Potsawee Manakul, Adian Liusie, and Mark Gales. Selfcheckgpt: Zero-resource black-box hallucination detection for generative large language models. In The 2023 Conference on Empirical Methods in Natural Language Processing, 2023.   \n[20] Vladimir Vovk. Conditional validity of inductive conformal predictors. Machine learning, 92(2-3):349\u2013376, 2013.   \n[21] Adam Fisch, Tal Schuster, Tommi Jaakkola, and Regina Barzilay. Few-shot conformal prediction with auxiliary tasks, 2021.   \n[22] Sangdon Park, Edgar Dobriban, Insup Lee, and Osbert Bastani. PAC prediction sets for metalearning. In Alice H. Oh, Alekh Agarwal, Danielle Belgrave, and Kyunghyun Cho, editors, Advances in Neural Information Processing Systems, 2022.   \n[23] Victor Quach, Adam Fisch, Tal Schuster, Adam Yala, Jae Ho Sohn, Tommi S. Jaakkola, and Regina Barzilay. Conformal Language Modeling, June 2024. arXiv:2306.10193 [cs].   \n[24] Christopher Mohri, Daniel Andor, Eunsol Choi, and Michael Collins. Learning to reject with a fixed predictor: Application to decontextualization. arXiv preprint arXiv:2301.09044, 2023.   \n[25] Ying Jin and Emmanuel J. Cand\u00e8s. Selection by Prediction with Conformal p-values, May 2023. arXiv:2210.01408 [stat].   \n[26] Ying Jin and Zhimei Ren. Confidence on the Focal: Conformal Prediction with SelectionConditional Coverage, March 2024. arXiv:2403.03868 [math, stat].   \n[27] Christopher Mohri and Tatsunori Hashimoto. Language models with conformal factuality guarantees. arXiv preprint arXiv:2402.10978, 2024.   \n[28] John J. Cherian, Isaac Gibbs, and Emmanuel J. Cand\u00e8s. Large language model validity via enhanced conformal prediction methods, June 2024. arXiv:2406.09714 [cs, stat].   \n[29] Yu Gui, Ying Jin, and Zhimei Ren. Conformal Alignment: Knowing When to Trust Foundation Models with Guarantees, May 2024. arXiv:2405.10301 [cs, stat].   \n[30] Philip Gage. A new algorithm for data compression. C Users Journal, 12(2):23\u201338, 1994.   \n[31] Samuel S Wilks. Determination of sample sizes for setting tolerance limits. The Annals of Mathematical Statistics, 12(1):91\u201396, 1941.   \n[32] Leslie G Valiant. A theory of the learnable. Communications of the ACM, 27(11):1134\u20131142, 1984.   \n[33] Harris Papadopoulos, Kostas Proedrou, Volodya Vovk, and Alex Gammerman. Inductive confidence machines for regression. In European Conference on Machine Learning, pages 345\u2013356. Springer, 2002.   \n[34] Sangdon Park, Edgar Dobriban, Insup Lee, and Osbert Bastani. PAC prediction sets under covariate shift. In International Conference on Learning Representations, 2022.   \n[35] Morris H DeGroot and Stephen E Fienberg. The comparison and evaluation of forecasters. Journal of the Royal Statistical Society: Series D (The Statistician), 32(1-2):12\u201322, 1983.   \n[36] Bianca Zadrozny and Charles Elkan. Transforming classifier scores into accurate multiclass probability estimates. In Proceedings of the eighth ACM SIGKDD international conference on Knowledge discovery and data mining, pages 694\u2013699. ACM, 2002.   \n[37] Yao Zhao, Mikhail Khalman, Rishabh Joshi, Shashi Narayan, Mohammad Saleh, and Peter J Liu. Calibrating sequence likelihood improves conditional language generation. In The Eleventh International Conference on Learning Representations, 2022.   \n[38] Dorottya Demszky, Kelvin Guu, and Percy Liang. Transforming question answering datasets into natural language inference datasets. arXiv preprint arXiv:1809.02922, 2018.   \n[39] Jifan Chen, Eunsol Choi, and Greg Durrett. Can NLI Models Verify QA Systems\u2019 Predictions?, September 2021. arXiv:2104.08731 [cs]. ", "page_idx": 10}, {"type": "text", "text": "", "page_idx": 11}, {"type": "text", "text": "", "page_idx": 12}, {"type": "text", "text": "A Discussion ", "text_level": 1, "page_idx": 13}, {"type": "text", "text": "A.1 Conformal Prediction ", "text_level": 1, "page_idx": 13}, {"type": "text", "text": "Conformal prediction [10] provides a promising way to quantify uncertainty of a model with a correctness guarantee under minimal assumptions. Here, we consider PAC prediction sets [11], an interpretation of tolerance region [31] and training-conditional inductive conformal prediction [20] in the lens of PAC learning theory [32] (i.e., learning a \u201cgood\u201d function within a function family from data). This interpretation inspires us to generalize selective generation for GLMs via neural selection functions. ", "page_idx": 13}, {"type": "text", "text": "Conformal Set Model. We consider a conformal (prediction) set model ${\\hat{C}}:{\\mathcal{X}}\\rightarrow2^{\\mathcal{Y}}$ that measures the uncertainty of a target model; in conformal prediction, this model is specifically called a scoring function $f:\\mathcal{X}\\times\\mathcal{Y}\\to\\mathbb{R}_{\\geq0}$ that measures the conformity (or likelihood) of $\\mathbf{x}$ for being y with respect to $f$ ; thus, $f(\\mathbf{x},\\mathbf{y})$ is called a conformity score. In particular, we consider scalar parameterization of a conformal set [11, 33] as follows: ${\\dot{C}}(\\mathbf{x}):=\\{\\mathbf{y}\\ {\\dot{\\in}}\\ y\\ |\\ f(\\mathbf{x},\\mathbf{y})\\geq\\tau\\}$ , where $\\tau\\in\\mathbb{R}_{\\geq0}$ is a scalar parameter. ", "page_idx": 13}, {"type": "text", "text": "Conformal Sets and Uncertainty. The output of the conformal set model is a set of labels, which naturally represents the uncertainty of a scoring function on an example via the size of a conformal set. In particular, if the scoring function $f$ is unsure on its prediction on $\\mathbf{x}$ (due to uncertainty on a label distribution of x, i.e., aleatoric uncertainty, and due to uncertainty in the modeling of $f$ , i.e., epistemic uncertainty), the conformal set is larger than it is when the scoring function is sure on its prediction. ", "page_idx": 13}, {"type": "text", "text": "To be precise, we consider a true conformal set $C^{*}(\\mathbf{x}):=\\{\\mathbf{y}\\in\\mathcal{y}\\mid f(\\mathbf{x},\\mathbf{y})\\geq f(\\mathbf{x},\\mathbf{y}^{*})\\}$ , where $\\mathbf{y}^{*}$ is the true label of $x$ . In particular, the true conformal set is a minimal set that contains a true label and labels with larger scores than the true label score; thus, the size of the true conformal set intuitively measures the uncertainty of a scoring function on the given example, i.e., the scoring function\u2019s possibilities on making wrong predictions, instead of the true prediction. ", "page_idx": 13}, {"type": "text", "text": "The true conformal set clearly captures the uncertainty, but the true label is unknown in inference time. Thus, the true conformal set is approximated via scalar parameterization [11, 33] as follows: ", "page_idx": 13}, {"type": "equation", "text": "$$\nC(\\mathbf{x}):=\\{\\mathbf{y}\\in\\mathcal{y}\\mid f(\\mathbf{x},\\mathbf{y})\\geq\\tau\\}\\,,\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "where $\\tau\\in\\mathbb{R}_{\\geq0}$ is a scalar parameter. ", "page_idx": 13}, {"type": "text", "text": "Correctness. As we desire to construct a conformal set close to the true conformal set, we define the correctness of the conformal set based on its similarity to the true one. In particular, we wish to have the smallest $C(\\mathbf{x})$ such that $C^{*}(\\mathbf{x})\\subseteq C(\\mathbf{x})$ , or equivalently $C(\\mathbf{x})$ needs to have the smallest $\\tau$ while $y\\in C(\\mathbf{x})$ . This correctness definition is realized into two ways: a coverage guarantee [10] or a PAC guarantee [20]. ", "page_idx": 13}, {"type": "text", "text": "Assumption. We assume that samples are independent and identically distributed (i.i.d.), i.e., the i.i.d. assumption. In particular, all samples for testing and learning prediction sets are independently drawn from the same but known distribution $\\mathcal{D}$ . ", "page_idx": 13}, {"type": "text", "text": "PAC guarantee. Under the i.i.d. assumption, we learn a conformal set $\\hat{C}$ that includes the most true labels (approximately correct). In particular, this means that the miscoverage of $\\hat{C}$ is less than a desired level $\\varepsilon\\in(0,1)$ , i.e., $\\mathcal{R}_{\\mathrm{MC}}(\\boldsymbol{\\hat{C}})\\stackrel{}{:=}\\mathbb{P}\\{\\mathbf{y}\\notin\\boldsymbol{\\hat{C}}(\\mathbf{x})\\}\\leq\\varepsilon$ , where the probability is taken over i.i.d. samples $(\\mathbf{x},\\mathbf{y})\\sim\\mathcal{D}$ . This risk on micoverage can be generalized to be the risk on indicator loss, $\\mathcal{R}_{01}(\\hat{C}):=\\mathbb{E}_{\\mathcal{D}}\\ell_{01}(\\hat{C},\\mathbf{x},\\mathbf{y})$ . Here, the conformal set $\\hat{C}$ is learned from a randomly drawn calibration set, so we desire to construct $\\hat{C}$ that has a desired error for the most of random calibration sets (probably approximately correct), i.e., $\\mathbb{P}\\{\\mathcal{R}_{01}(\\hat{C})\\leq\\varepsilon\\}\\geq1-\\delta$ , where $\\delta\\in(0,1)$ is a desired confidence level and the probability is taken over $n$ i.i.d. calibration samples $\\mathbf{Z}\\sim\\mathcal{D}^{n}$ , used to learn $\\hat{C}$ . ", "page_idx": 13}, {"type": "text", "text": "Algorithm. The PAC conformal prediction set method [11, 34] considers the following algorithm $A_{\\mathrm{Binom}}:(\\mathcal X\\times\\mathcal Y)^{*}\\to\\mathcal H$ to learn a conformal set model $\\hat{C}$ , parameterized by $\\hat{\\tau}$ , where $\\mathcal{H}$ is a finely-discretized $\\mathbb{R}_{\\geq0}$ : ", "page_idx": 13}, {"type": "equation", "text": "$$\nA_{\\mathrm{Binom}}:\\quad\\hat{\\tau}=\\operatorname*{max}_{\\tau\\in\\mathcal{H}}\\,\\tau\\quad\\mathrm{subj.}\\,\\,\\mathrm{to}\\quad U_{\\mathrm{Binom}}(k_{\\tau};n,\\delta)\\leq\\varepsilon,\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "where $\\begin{array}{r l r}{k_{\\tau}}&{{}:=}&{\\sum_{i=1}^{n}\\ell_{01}(\\hat{C},\\mathbf{x}_{i},\\mathbf{y}_{i})}\\end{array}$ . Here, $U_{\\mathrm{Binom}}$ is a binomial tail bound, i.e., $\\begin{array}{r l r}{\\mathsf{P}\\left\\{\\mathcal{R}_{01}(C)\\leq U_{\\mathrm{Binom}}(k_{\\tau};n,\\delta)\\right\\}}&{{}\\geq}&{1\\;\\;-\\;\\;\\delta}\\end{array}$ for any $C$ , where $\\begin{array}{r l}{U_{\\mathrm{Binom}}(k;n,\\delta)}&{{}:=}\\end{array}$ inf $\\{\\theta\\in[0,1]\\,|\\,F(k;n,\\theta)\\!\\leq\\!\\delta\\}\\cup\\{1\\}$ and $F(k;n,\\theta)$ is a cumulative distribution function (CDF) of a binomial distribution with $n$ trials and success probability $\\theta$ . This algorithm is PAC. ", "page_idx": 14}, {"type": "text", "text": "Theorem 2. $([I I,\\,20,\\,34J)$ The algorithm $\\mathcal{A}_{B i n o m}$ is $P\\!A C_{;}$ , i.e., for any $f$ $\\dot{\\mathbf{\\theta}},\\,\\varepsilon\\in(0,1)$ , $\\delta\\in(0,1)$ , and $n\\,\\in\\,\\mathbb{Z}_{\\geq0}$ , we have $\\mathbb{P}\\{\\mathcal{R}_{01}(\\hat{C})\\,\\le\\,\\varepsilon\\}\\ge1-\\delta$ , where the probability is taken over i.i.d. labeled examples $\\mathbf{Z}\\sim\\mathcal{D}^{n}$ , and $\\hat{C}=\\mathcal{A}_{B i n o m}(\\mathbf{Z})$ . ", "page_idx": 14}, {"type": "text", "text": "Here, we slightly generalize the known PAC guarantee to hold for any risk with indicator loss. See Appendix F for a proof. Note that the PAC guarantee generally holds only if an enough number of samples is provided (when we know a function family including a true function). However, we consider PAC algorithms that hold for any number of samples due to the structural property of prediction sets, i.e., a prediction set is always correct if $\\tau\\,=\\,0$ (thus $\\hat{C}(\\mathbf{x})\\,=\\,\\mathcal{V})$ , regardless of the sample size. In other words, if the calibration samples are not sufficient, the prediction set is constructed to return $\\boldsymbol{\\wp}$ to satisfy the PAC guarantee. ", "page_idx": 14}, {"type": "text", "text": "A.2 Sample Space Decomposition ", "text_level": 1, "page_idx": 14}, {"type": "text", "text": "Given the generator $G$ and the entailment set function $\\hat{E}$ , the sample space $\\Omega:=\\mathcal{X}\\times\\mathcal{Y}\\times\\mathcal{E}\\times\\mathcal{V}$ can be partitioned as follows: ", "page_idx": 14}, {"type": "image", "img_path": "glfYOAzh2f/tmp/35e7f33d271ed8152716c5b69d30316807cf2843d660f51b21931f8934b0bbd8.jpg", "img_caption": [], "img_footnote": [], "page_idx": 14}, {"type": "text", "text": "Here, the short-hands are defined as follows: ", "page_idx": 14}, {"type": "text", "text": "\u2022 True discovery rate (TDR): $\\mathbb{P}(\\Omega_{\\mathrm{TD}}^{E_{\\mathrm{true}}})$ \u2022 False discovery rate (FDR): $\\mathbb{P}(\\Omega_{\\mathrm{FD}}^{E_{\\mathrm{true}}})$ \u2022 True entailment rate (TER): $\\mathbb{P}(\\Omega_{\\mathrm{TE}}^{\\hat{E}})$ \u2022 False non-entailment rate (FNER): $\\mathbb{P}(\\Omega_{\\mathrm{FNE}}^{\\hat{E}})$ \u2022 True non-entailment rate (TNER): $\\mathbb{P}(\\Omega_{\\mathrm{TNE}}^{\\hat{E}})$ \u2022 False entailment rate (FER): $\\mathbb{P}(\\Omega_{\\mathrm{FER}}^{\\hat{E}})$ ", "page_idx": 14}, {"type": "text", "text": "A.3 Experiment Setup ", "text_level": 1, "page_idx": 14}, {"type": "text", "text": "A.3.1 Computing Environment ", "text_level": 1, "page_idx": 14}, {"type": "text", "text": "Our system environment consists of 4 NVIDIA A100 80GB with 128 CPUs. ", "page_idx": 14}, {"type": "text", "text": "A.3.2 Models and Datasets ", "text_level": 1, "page_idx": 14}, {"type": "text", "text": "We use two large language models (LLMs), GPT-3.5-Turbo and Alpaca-7B, for language generation.   \nWe use deberta-v2-xxlarge-mnli as our entailment model. ", "page_idx": 14}, {"type": "text", "text": "For each GLM to annotate entailment labels for each question, answer, and generated answer pair, we annotate entailment labels. Specifically, we consider the open-ended QA task, where the model is prompted to generate the answer in a declarative form given a question. To validate our method and its theoretical guarantee on controlling FDR-E, we create a dataset on textual entailment using the Natural Questions (NQ) dataset [17] for each GLM. Based on the transformation method by [38] that converts the question and answer pair in QA dataset into a declarative form, we manually labeled textual entailment by letting the generated sequence as the premise and the reference answer in declarative form as the hypothesis. Similar work can be found in [39], but they label the textual entailment based on the extractive answer from the model. Approximately $7.3\\mathbf{k}$ (7,374) and $4.6\\mathrm{k}$ (4,595) samples are labeled for Alpaca-7B and GPT-3.5-Turbo, respectively, and both are split into calibration and test data at an 8:2 ratio. For semi-supervised learning algorithms that exploit unlabeled data (Algorithm 7, Algorithm 9), at most $27\\mathbf{k}$ and 10k unlabeled samples are used to train a selective generator, varying its size. Besides, semi-supervised learning algorithms use only $75\\%$ of the labeled calibration data compared to what is used by supervised methods (Algorithm 8, Algorithm 10). ", "page_idx": 15}, {"type": "text", "text": "B Semi-supervised Selective Generation Algorithms (Certified) ", "text_level": 1, "page_idx": 15}, {"type": "table", "img_path": "glfYOAzh2f/tmp/14956dd41ebe8d587c1ede9c50b2de474575549be0a95b8af0ddfbb937b257bd.jpg", "table_caption": [], "table_footnote": [], "page_idx": 15}, {"type": "table", "img_path": "glfYOAzh2f/tmp/8f74cc3f89dc28edbb487529078f2fb70d16ed8171de1bbb73114493c0584fd5.jpg", "table_caption": [], "table_footnote": [], "page_idx": 15}, {"type": "table", "img_path": "glfYOAzh2f/tmp/8bf79100779f15152c95c088dc6414956991900f7e5b4a27297a2ea57c8c2190.jpg", "table_caption": [], "table_footnote": [], "page_idx": 15}, {"type": "text", "text": "Algorithm 4 FDR-E Bound Computation ", "text_level": 1, "page_idx": 16}, {"type": "text", "text": "1: procedure FDR-E-BOUND(fE, ZE, ZU, \u03b4S, Q, \u03b4E, \u03b4W )   \n2: $w_{\\mathrm{SL}}\\leftarrow U_{\\mathrm{Binom}}(|\\mathbf{Z}_{E}|;|\\mathbf{Z}_{E}|+|\\mathbf{Z}_{U}|,\\delta_{W}/2)$ (\u25b7) Upper bound of (B) in (2)   \n3: $\\begin{array}{r}{k_{\\mathrm{SL}}\\leftarrow\\sum_{(\\mathbf{x},\\mathbf{y},e)\\in\\mathbf{Z}_{E}}\\mathbb{1}(e=0)}\\end{array}$   \n4: $U_{\\mathrm{SL}}\\leftarrow U_{\\mathrm{Binom}}(k_{\\mathrm{SL}};|\\mathbf{Z}_{E}|,\\delta_{S}/2)$ (\u25b7) Upper bound of (C) in (2)   \n56:: $w_{\\mathrm{SSL}}\\leftarrow U_{\\mathrm{Binom}}(|\\mathbf{Z}_{U}|;|\\mathbf{Z}_{E}|+|\\mathbf{Z}_{U}|,\\delta_{W}/2)$ 2, Q, \u03b4E/2) ((\u25b7\u25b7))  UUppppeerr  bboouunndd  ooff  ((DE))  iinn  ((22))   \n7: $U\\gets w_{\\mathrm{SL}}U_{\\mathrm{SL}}+w_{\\mathrm{SSL}}U_{\\mathrm{SSI}}^{\\mathrm{OPI}}$   \n8: return U ", "page_idx": 16}, {"type": "text", "text": "Algorithm 5 Semi-supervised Selective Generator Learning (Single-threshold Selection Function) ", "text_level": 1, "page_idx": 16}, {"type": "text", "text": "1: procedure SGEN-SEMI(fM, fE, G, ZE, ZU, \u03b5S, $\\delta_{S}$ , Q, \u03b4E, $\\delta_{W}$ , return_bool = False)   \n2: ZU,E \u2190ZU \u222aZE   \n3: $\\mathbf{Z}_{U,E}\\gets\\mathsf{S o R T}_{f_{M}}(\\mathbf{Z}_{U,E})$ (\u25b7) In an increasing order of $f_{M}\\big(\\mathbf{y}_{i},G\\big(\\mathbf{x}_{i}\\big)\\big)$   \n4: $(\\underline{{i}},\\overline{{i}})\\leftarrow(1,\\mathbf{Z}_{U,E})$   \n5: $U_{\\mathrm{min}}\\leftarrow\\infty$ ; \u03c4min \u2190NULL   \n6: for $i=1$ to $\\lceil\\log_{2}\\mathbf{Z}_{U,E}\\rceil$ do   \n7: $\\begin{array}{r l}&{\\tau_{S}^{(i)}\\leftarrow f_{M}(\\mathbf{x}_{\\lceil(\\underline{{i}}+\\bar{i})/2\\rceil},G(\\mathbf{x}_{\\lceil(\\underline{{i}}+\\bar{i})/2\\rceil}))}\\\\ &{\\mathbf{Z}_{E}^{(i)}\\leftarrow\\{(\\mathbf{x},\\mathbf{y},e)\\in\\mathbf{Z}_{E}\\ |\\ f_{M}(\\mathbf{x},G(\\mathbf{x}))\\geq\\tau_{S}^{(i)}\\}}\\\\ &{\\mathbf{Z}_{U}^{(i)}\\leftarrow\\{(\\mathbf{x},\\mathbf{y})\\in\\mathbf{Z}_{U}\\ |\\ f_{M}(\\mathbf{x},G(\\mathbf{x}))\\geq\\tau_{S}^{(i)}\\}}\\\\ &{U^{(i)}\\leftarrow\\mathrm{FDR-E-BoUND}(f_{E},\\mathbf{Z}_{E}^{(i)},\\mathbf{Z}_{U}^{(i)},\\frac{\\delta_{S}}{\\lceil\\log_{2}|\\mathbf{Z}_{U,E}|\\rceil},Q,\\frac{\\delta_{E}}{\\lceil\\log_{2}\\mathbf{Z}_{U,E}\\rceil},\\frac{\\delta_{W}}{\\lceil\\log_{2}\\mathbf{Z}_{U,E}\\rceil})}\\\\ &{\\cdots}\\end{array}$   \n8:   \n190::   \n11: if $U^{(i)}\\leq U_{\\operatorname*{min}}$ then   \n12: $U_{\\mathrm{min}}\\gets U^{(i)};~\\tau_{\\mathrm{min}}\\gets\\tau_{S}^{(i)}$   \n13: if $U^{(i)}\\leq\\varepsilon_{S}$ then   \n14: i \u2190i   \n15: else   \n16: $\\tau_{S}\\gets\\tau_{S}^{i\\leftarrow i}$   \n17:   \n18: if $U_{\\operatorname*{min}}\\leq\\varepsilon_{S}$ then   \n19: U\u02c6 \u2190U (i)   \n20: Bounded $\\leftarrow$ Success   \n21: else   \n22: U\u02c6 \u2190Umin   \n23: \u03c4S \u2190\u03c4min   \n24: Bounded \u2190Fail   \n25: return (\u03c4S, U\u02c6, Bounded) if return_bool else $(\\tau_{S},\\hat{U})$ .   \nAlgorithm 6 Semi-supervised Selective Generator Learning (Double-threshold Selection Function)   \n1: procedure SGEN-SEMI2 $\\boldsymbol{f}_{M_{1}}$ , $f_{M_{2}}$ , fE, G, $\\mathbf{Z}_{E}$ , $\\mathbf{Z}_{U}$ , $\\varepsilon_{S}$ , $\\delta_{S}$ , $Q$ , $\\delta_{E}$ , $\\delta_{W}$ , return_bool =   \nFalse)   \n2: 3: ZU ZU $\\begin{array}{r l r l}&{a s_{\\mathcal{A}}}&{=\\operatorname{Sup}\\mathbb{E}_{\\mathcal{H}}\\left(\\Vert\\mathcal{H}_{\\mathcal{X}}\\Vert\\geq\\left(\\mathbb{H}_{\\mathcal{X}}\\right)\\Vert\\mathcal{H}_{\\mathcal{X}}\\right)}&&{\\mathrm{(6)Hha~inercoulaged~eff_{\\mathcal{H}}~}}\\\\ &{a s_{\\mathcal{A}}}&{=\\operatorname{Sup}\\mathbb{E}_{\\mathcal{H}}\\left(\\Vert\\mathcal{H}_{\\mathcal{X}}\\Vert\\geq\\left(\\mathbb{H}_{\\mathcal{X}}\\right)\\Vert\\mathcal{H}_{\\mathcal{X}}\\right)}&&{\\mathrm{(6)H~an~inercoulag~edf_{\\mathcal{H}}~}}\\\\ &{\\mathrm{)}}&&{=\\Vert\\mathcal{H}_{\\mathcal{X}}\\Vert\\geq\\left(\\mathbb{H}_{\\mathcal{X}}\\right)\\Vert\\Vert\\mathcal{H}_{\\mathcal{X}}\\Vert}\\\\ &{a\\cdot\\left(\\mathbb{H}_{\\mathcal{X}}^{1}-\\mathbb{H}_{\\mathcal{X}}^{1}\\right)\\Vert\\Vert\\mathcal{H}_{\\mathcal{H}}\\Vert}&&{}\\\\ &{\\mathrm{)}}&{=\\Vert\\mathcal{H}_{\\mathcal{X}}\\Vert\\geq\\left(\\mathbb{H}_{\\mathcal{X}}^{1}-\\mathbb{H}_{\\mathcal{X}}^{1}\\right)\\Vert\\mathcal{H}_{\\mathcal{X}}\\Vert}\\\\ &{a\\cdot\\left(\\mathbb{H}_{\\mathcal{H}}^{1}\\right)\\Vert\\Vert\\mathcal{H}_{\\mathcal{H}}\\Vert}&&{}\\\\ &{\\mathrm{(7)H}=\\int_{\\mathcal{H}}\\Vert\\mathcal{H}_{\\mathcal{X}}\\Vert=\\left(\\mathbb{H}_{\\mathcal{X}}^{1}-\\mathbb{H}_{\\mathcal{X}}^{1}\\right)\\Vert\\mathcal{H}_{\\mathcal{X}}\\Vert}\\\\ &{\\mathrm{)}}&{=\\Vert\\mathcal{H}_{\\mathcal{X}}\\Vert=\\Vert\\mathcal{H}_{\\mathcal{X}}\\Vert=\\Vert\\mathcal{H}_{\\mathcal{X}}\\Vert}\\\\ &{\\left(\\mathbb{H}_{\\mathcal{X}}^{1}\\right)\\Vert\\mathcal{H}_{\\mathcal{X}}\\Vert\\geq\\left(\\mathbb{H}_{\\mathcal{X}}^{1}-\\mathbb{H}_{\\mathcal{X}}^{1}\\right)\\Vert\\mathcal{H}_{\\mathcal{H}}\\Vert}\\\\ &{\\mathrm{(6)H}\\left(\\mathbb{H}_{\\mathcal{X}}^{1}-\\mathbb{H}_{\\mathcal{X}}^{1}\\right)\\Vert\\mathcal{H}_{\\mathcal{X}}\\Vert}&{\\mathrm{(10)}}\\\\ &{\\$ $f_{M_{1}}(\\mathbf{y}_{i},G(\\mathbf{x}_{i}))$   \n4: ZU $f_{M_{2}}(\\mathbf{y}_{i},G(\\mathbf{x}_{i}))$   \n5: Um   \n6: (i,   \n7: n_i   \n8: for   \n9:   \n10:   \n11:   \n12:   \n13:   \n14:   \n15:   \n16:   \n17:   \n18:   \n19:   \n20:   \n21:   \n22: $j\\leftarrow j$   \n23: if $U_{\\mathrm{min}}^{(i)}\\le U_{\\mathrm{min}}$ then   \n24: $U_{\\mathrm{min}}\\leftarrow U_{\\mathrm{min}}^{(i)};~\\tau_{\\mathrm{min}}\\leftarrow\\tau_{\\mathrm{min}}^{(i)}$   \n25: if $i\\neq\\lceil\\log_{2}\\lvert\\mathbf{Z}_{U,E}\\rvert\\rceil$ then   \n26: if U (mii)n \u2264\u03b5S then   \n27: i \u2190i   \n28: else   \n29: $\\underline{{i}}\\leftarrow i$   \n30: else   \n31: $\\tau_{S}\\gets(\\tau_{S}^{(i)},\\tau_{S}^{(j)})$   \n32: if $U_{\\operatorname*{min}}\\leq\\varepsilon_{S}$ then   \n33: $\\hat{U}\\gets U^{(i,j)}$ ; Bounded $\\leftarrow$ Success   \n34: else   \n35: $\\hat{U}\\gets U_{\\mathrm{min}}$ ; $\\tau_{S}\\gets\\tau_{\\mathrm{min}}$ ; Bounded $\\leftarrow$ Fail   \n36: return (\u03c4S, U\u02c6, Bounded) if return_bool else $(\\tau_{S},\\hat{U})$ ", "page_idx": 16}, {"type": "text", "text": "", "page_idx": 17}, {"type": "text", "text": "Algorithm 7 Semi-supervised Selective Generator Learning with Model Selection ", "text_level": 1, "page_idx": 18}, {"type": "text", "text": "1: proced $\\mathbf{re}\\;\\mathrm{SGEN-SEMI-MS}(f_{M_{1}},\\,f_{M_{2}},\\,f_{E},\\,G,\\,\\mathbf{Z}_{E},\\,\\mathbf{Z}_{U},\\,\\varepsilon_{S},\\,\\delta_{S},\\,Q,\\,\\delta_{E},\\,\\delta_{W})$   \n2: $\\mathcal{M}_{\\mathrm{Success}}=\\left\\{\\right\\}$ ; $\\mathcal{M}_{\\mathrm{Fail}}=\\{\\}$   \n3: $\\langle\\tau_{S_{1}},\\hat{U}_{1},\\mathtt{B o u n d e d}_{1}\\rangle\\gets\\mathsf{S G e n\\mathrm{-}S e n i}(f_{M_{1}},\\,f_{E},G,\\mathbf{Z}_{E},\\mathbf{Z}_{U},\\varepsilon_{S},\\delta_{S}/\\3)$ , Q, $\\delta_{E}/3$ , \u03b4W /3, return_bool $=$ True)   \n4: $\\mathsf{e d}_{2})\\gets\\mathsf{S G e n}-\\mathsf{S e m i}(f_{M_{2}},\\,f_{E},G,\\mathbf{Z}_{E},\\mathbf{Z}_{U},\\varepsilon_{S},\\delta_{S}/3,Q,\\delta_{E}/3,\\delta_{W}/3)$ 3, return_bool $=$ True)   \n5: $(\\tau_{S},\\hat{U}_{3},\\mathtt{B o u n d e d}_{3})\\gets\\mathsf{S G e n\\mathrm{-}S e n i}\\,2(f_{M},\\,f_{M}_{2},\\,f_{E},\\,G,\\,\\mathbf{Z}_{E},\\,\\mathbf{Z}_{U},\\,\\varepsilon_{S},\\,\\delta_{S}/3,\\,Q,\\,\\delta_{E}/3,\\,\\delta_{W})\\,.$ $\\delta_{W}/3$ , return_bool $=$ True)   \n6: M := {(\u03c4S1, U\u02c61, s1, Bounded1), (\u03c4S2, U\u02c62, s2, Bounded2), $(\\tau_{S_{3}},\\hat{U}_{3},s_{3}$ , Bounded3)}   \n7: $(\\mathsf{D})\\,s_{i}$ refers to the scoring function(s) used in each algorithm.   \n8: for $(\\tau_{S},\\hat{U},s$ , Bounded) in $\\mathcal{M}$ do   \n9: if Bounded $=$ Success then   \n10: $\\mathcal{M}_{\\mathrm{Success}}\\leftarrow\\mathcal{M}_{\\mathrm{Success}}\\cup\\{(\\tau_{S},\\hat{U},s)\\}$   \n11: else   \n12: $\\mathcal{M}_{\\mathrm{Fail}}\\leftarrow\\mathcal{M}_{\\mathrm{Fail}}\\cup\\{(\\tau_{S},\\hat{U},s)\\}$   \n13: if $\\mathcal{M}_{\\mathrm{Success}}=\\left\\{\\begin{array}{r l}\\end{array}\\right\\}$ then   \n14: return (\u03c4S, U\u02c6, s) \u2190arg min(\u03c4S, U\u02c6,s)\u2208M   \n15: else   \n16: return (\u03c4S, U\u02c6, s) \u2190arg max(\u03c4S, U\u02c6,s)\u2208MSuccess ", "page_idx": 18}, {"type": "text", "text": "C Supervised Selective Generation Algorithms (Certified) ", "text_level": 1, "page_idx": 19}, {"type": "table", "img_path": "glfYOAzh2f/tmp/56bce0518546c7e5df338e4cff068f5c1084b88ce8b65cb1440b559305b7f7db.jpg", "table_caption": [], "table_footnote": [], "page_idx": 19}, {"type": "text", "text": "D Semi-supervised Selective Generation Algorithms (Heuristic) ", "text_level": 1, "page_idx": 20}, {"type": "text", "text": "Algorithm 9 Semi-supervised Selective Generator Learning with Pseudo-entailment Labels   \n$1;\\ \\mathbf{procedure\\;SG-PSL-H-SEM}(f_{M},f_{E},G,\\mathbf{Z}_{E},\\mathbf{Z}_{U},\\varepsilon,\\delta,\\tau_{\\mathrm{PL}},\\mathbf{F}\\mathrm{{IL}}\\cdot\\mathbf{Z}_{E},\\mathbf{Z}_{E},\\varepsilon,\\delta,\\tau_{\\mathrm{PL}},\\mathbf{k},\\tau_{\\mathrm{NL}});$ TER)   \n2: if FILTER $==$ TRUE then   \n3: 4: $\\begin{array}{r l}&{\\quad2_{U}+\\langle\\mathbf{x},\\mathbf{y}\\rangle\\mid f_{G}(G(\\mathbf{x}),\\mathbf{y})\\geq\\pi_{\\mathbf{0}},\\mathrm{~or~}1-f_{G}(G(\\mathbf{x}),\\mathbf{y})\\geq\\pi_{\\mathbf{0}},}\\\\ &{\\quad2_{U}+\\langle\\mathbf{x},\\mathbf{y},\\vec{G}\\rangle\\mid(\\mathbf{x},\\mathbf{y})\\in\\mathbf{Z}_{U},\\vec{G}\\mid\\vec{\\pi}_{G}(\\mathbf{x}),}\\\\ &{\\quad2_{U}+\\langle\\mathbf{y},\\mathbf{y},\\vec{G}\\rangle\\mid(\\mathbf{x},\\mathbf{y},\\mathbf{e})\\in\\mathbf{Z}_{U},\\vec{G}=\\epsilon_{\\mathbf{y}}^{\\prime}(G(\\mathbf{x}),\\mathbf{y})\\geq\\pi_{\\mathbf{0}}\\rangle,}\\\\ &{\\quad\\langle\\mathbf{z},\\vec{G}\\rangle<0,}\\\\ &{\\quad\\langle\\mathbf{j}_{\\mathbf{0}}^{\\prime}\\rangle\\leq-(1,\\pi)_{U,K}/2_{U,K}\\/\\epsilon_{\\mathbf{0}},}\\\\ &{\\quad\\vec{U}_{m+}<\\infty}\\\\ &{\\quad\\vec{\\pi}\\mathbf{0}\\,\\mathrm{~}\\,\\vec{\\Pi}\\,\\mathrm{~for~}j_{G}[\\mathbf{z}_{U,E}]\\mid\\mathbf{d}\\mathbf{0}}\\\\ &{\\quad\\tau_{\\mathbf{0}}^{\\prime}\\cup\\vec{f}_{i,E}^{\\phantom{\\dagger}}+\\int_{M}(\\mathbf{x}_{[(i+\\vec{j})\\tau_{i}]},G(\\mathbf{x}_{[(i+\\vec{i})\\tau_{j}]}))}\\\\ &{\\quad\\tau_{\\mathbf{0}}^{\\prime}\\cup\\vec{f}_{i,E}^{\\phantom{\\dagger}}+\\left\\{\\left(\\mathbf{x},\\mathbf{y}\\right)\\in\\mathbf{Z}_{U,E}\\right\\}\\int_{M}(\\mathbf{x},G(\\mathbf{x}))\\geq\\tau_{S}^{(i)}\\rangle}\\\\ &{\\quad k^{(i)}\\leftarrow\\sum_{(\\mathbf{x},\\mathbf{y})\\in\\mathbf{Z}_{V,E}^{\\prime}}\\mathbb{L}\\left(\\varepsilon=0\\right)}\\\\ &{\\quad U^{(i)}\\leftarrow D_{\\mathbf{0},\\mathbf{0}}\\left(k^{(i)},[\\mathbf{Z}_{U,E}^{\\prime}],\\vec{\\xi}/\\left\\lceil\\mathbf{0}\\right\\rceil_{\\mathbf{0},\\mathbf{2}}\\left[\\mathbf{Z}_{U,E}\\right]\\right)}\\\\ &{\\quad$   \n5:   \n6:   \n7:   \n8:   \n190::   \n11:   \n12:   \n13:   \n14:   \n15:   \n16:   \n17: else   \n18: i \u2190i   \n19: \u03c4S \u2190\u03c4 S(i)   \n20: return \u03c4S, Umin ", "page_idx": 20}, {"type": "text", "text": "E Unsupervised Selective Generation Algorithms (Certified) ", "text_level": 1, "page_idx": 20}, {"type": "text", "text": "Algorithm 10 Unsupervised Selective Generator Learning with $\\mathcal{R}_{\\mathrm{EM}}(\\hat{S})$ Control [9]   \n1: procedure SG-EM(fM, G, ZE, ZU, \u03b5, \u03b4)   \n2: ZU,E \u2190ZU \u222aZE   \n3: ZU,E \u2190SORTfM (ZU,E)   \n4: (i, i) \u2190(1, |ZU,E|)   \n5: $U_{\\mathrm{min}}\\leftarrow\\infty$   \n6: for $i=1$ to $\\lceil\\log_{2}\\lvert\\mathbf{Z}_{U,E}\\rvert\\rceil$ do   \n7: $\\begin{array}{r l}&{\\tau_{S}^{(i)}\\leftarrow f_{M}(\\mathbf{x}_{[(\\pm+\\bar{i})/2]},G(\\mathbf{x}_{[(\\pm\\bar{i})/2]}))}\\\\ &{\\mathbf{Z}_{U,E}^{(i)}\\leftarrow\\{(\\mathbf{x},\\mathbf{y})\\in\\mathbf{Z}_{U,E}\\mid f_{M}(\\mathbf{x},G(\\mathbf{x}))\\geq\\tau_{S}^{(i)}\\}}\\\\ &{k^{(i)}\\leftarrow\\sum_{(\\mathbf{x},\\mathbf{y})\\in\\mathbf{Z}_{U,E}^{(i)}}\\mathbb{I}(G(\\mathbf{x})\\neq\\mathbf{y})}\\\\ &{U^{(i)}\\leftarrow U_{\\mathrm{Binom}}(k^{(i)};|\\mathbf{Z}_{U,E}^{(i)}|,\\delta/\\lceil\\log_{2}|\\mathbf{Z}_{U,E}||)}\\\\ &{U_{\\mathrm{min}}\\leftarrow\\operatorname*{min}(U_{\\mathrm{min}},U^{(i)})}\\\\ &{\\mathbf{if}\\:U_{\\mathrm{\\s}}^{(i)}\\leq\\varepsilon\\:\\mathbf{then}}\\\\ &{\\:\\:\\bar{i}\\leftarrow i}\\end{array}$   \n8:   \n9:   \n10:   \n11:   \n12:   \n13:   \n14: else   \n15: $\\begin{array}{r l}&{\\underset{\\tau_{S}}{\\mathrm{~\\sum~}}\\leftarrow i}\\\\ &{\\mathbf{return~}\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\$   \n16:   \n17: ", "page_idx": 20}, {"type": "text", "text": "F Proof of Theorem 2 ", "text_level": 1, "page_idx": 21}, {"type": "text", "text": "Let $C_{\\tau}$ be a prediction set $C$ with a parameter $\\tau$ , $\\mathcal{H}_{\\varepsilon}:=\\{\\tau\\in\\mathcal{H}\\;|\\;\\mathcal{R}_{01}(C_{\\tau})>\\varepsilon\\}$ , and $\\tau^{*}:=\\operatorname*{inf}\\mathcal{H}_{\\varepsilon}$ , where $\\mathcal{H}$ is finely-discretized non-negative real values. Then, we have ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{P}\\Big\\{\\mathcal{R}_{01}(\\mathcal{A}_{\\mathrm{Binom}}(\\mathbf{Z}))>\\varepsilon\\Big\\}\\leq\\mathbb{P}\\Big\\{\\exists\\tau\\in\\mathcal{H}_{\\varepsilon},U_{\\mathrm{Binom}}(k_{\\tau};n,\\delta)\\leq\\varepsilon\\Big\\}}\\\\ &{\\qquad\\qquad\\qquad\\leq\\mathbb{P}\\Big\\{U_{\\mathrm{Binom}}(k_{\\tau^{*}};n,\\delta)\\leq\\varepsilon\\Big\\}}\\\\ &{\\qquad\\qquad\\qquad\\leq\\mathbb{P}\\Big\\{\\mathcal{R}_{01}(C_{\\tau^{*}})>\\varepsilon\\wedge U_{\\mathrm{Binom}}(k_{\\tau^{*}};n,\\delta)\\leq\\varepsilon\\Big\\}}\\\\ &{\\qquad\\qquad\\leq\\mathbb{P}\\Big\\{\\mathcal{R}_{01}(C_{\\tau^{*}})>U_{\\mathrm{Binom}}(k_{\\tau^{*}};n,\\delta)\\Big\\}\\leq\\delta,}\\end{array}\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "where the last equality in (11) holds as $\\mathbb{1}\\left(\\mathbf{y}\\notin C_{\\tau}(\\mathbf{x})\\right)$ and $U_{\\mathrm{B}}$ are non-decreasing in $\\tau$ (i.e., Lemma 2 in [34]) and the last inequality in (12) is due to the property of the binomial tail bound $U_{\\mathrm{Binom}}$ . ", "page_idx": 21}, {"type": "text", "text": "G Proof of Lemma 2 ", "text_level": 1, "page_idx": 21}, {"type": "text", "text": "Since (E) in (2) is decomposed into three terms in Lemma 1, we first find upper bounds on each of the terms and take the union bound as follows. This will return a single upper bound on $\\mathrm{(E)}$ in (2), which we denote $U_{\\mathrm{SSL}}$ . ", "page_idx": 21}, {"type": "text", "text": "FER Bound. First, recall that ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\mathcal{R}_{\\mathrm{FER}}(\\hat{E}):=\\mathbb{P}_{\\mathcal{D}_{\\hat{S}}}\\{e=0\\wedge G(\\mathbf{x})\\in\\hat{E}(\\mathbf{y})\\}.\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "Learning $\\hat{E}$ via $\\mathcal{A}_{\\mathtt{F E R}}$ is equivalent to the PAC prediction set learning algorithm that considers the optimization problem in (10), where the indicator loss is $\\ell_{01}(\\hat{E},\\mathbf{x},\\mathbf{y},e):=\\mathbb{1}(e=0\\wedge G(\\mathbf{x})\\in\\hat{E}(\\mathbf{y}))$ and the target model is the entailment scoring function $f_{E}$ . Therefore, by Theorem 2, for any $n_{E}:=|\\mathbf{Z}_{E}|$ , we have ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{P}_{\\mathbf{Z}_{E}}\\left\\{\\mathcal{R}_{\\mathrm{FER}}(\\hat{E})\\leq\\varepsilon_{E}\\right\\}=\\displaystyle\\sum_{m=1}^{n_{E}}\\mathbb{P}_{\\mathbf{Z}_{E}}\\left\\{\\mathcal{R}_{\\mathrm{FER}}(\\hat{E})\\leq\\varepsilon_{E}\\;\\Big|\\;|\\hat{\\mathbf{Z}}_{E}|=m\\right\\}\\cdot\\mathbb{P}_{\\mathbf{Z}_{E}}\\left\\{|\\hat{\\mathbf{Z}}_{E}|=m\\right\\}}\\\\ &{\\qquad\\qquad\\qquad\\geq\\displaystyle\\sum_{m=1}^{n_{E}}(1-\\delta_{E}^{\\prime}/2)\\cdot\\mathbb{P}_{\\mathbf{Z}_{E}}\\left\\{|\\hat{\\mathbf{Z}}_{E}|=m\\right\\}}\\\\ &{\\qquad\\qquad=1-\\delta_{E}^{\\prime}/2.}\\end{array}\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "Note that (13) holds as the PAC guarantee for conformal prediction holds for any number of samples. ", "page_idx": 21}, {"type": "text", "text": "The same bound holds with respect to $\\mathbf{Z}$ . Specifically, letting $\\ell_{\\mathrm{FER}}(\\mathbf{Z}_{E},\\mathbf{Z}_{U}):=\\mathbb{1}(\\mathcal{R}_{\\mathrm{FER}}(\\boldsymbol{\\hat{E}})\\leq\\varepsilon_{E})$ , we have ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{P}_{\\mathbf{Z}}\\left\\{\\mathcal{R}_{\\mathrm{FER}}(\\hat{E})\\leq\\varepsilon_{E}\\right\\}=\\int\\ell_{\\mathrm{FER}}(\\mathbf{Z}_{E},\\mathbf{Z}_{U})\\,\\mathrm{d}\\mathbb{P}(\\mathbf{Z})}\\\\ &{\\qquad\\qquad\\qquad\\qquad=\\int\\ell_{\\mathrm{FER}}(\\mathbf{Z}_{E},\\mathbf{Z}_{U})\\,\\mathrm{d}\\mathbb{P}(\\mathbf{Z}_{E})\\mathrm{d}\\mathbb{P}(\\mathbf{Z}_{U})}\\\\ &{\\qquad\\qquad\\qquad\\geq\\int(1-\\delta_{E}^{\\prime}/2)d\\mathbb{P}(\\mathbf{Z}_{U})}\\\\ &{\\qquad\\qquad\\qquad=1-\\delta_{E}^{\\prime}/2,}\\end{array}\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "where the second equality holds due to the i.i.d. assumption on the calibration data and the inequality holds due to (14). ", "page_idx": 21}, {"type": "text", "text": "FNER Bound. Recall ", "text_level": 1, "page_idx": 21}, {"type": "equation", "text": "$$\n\\mathcal{R}_{\\mathrm{FNER}}(\\hat{E}):=\\mathbb{P}_{\\mathcal{D}_{\\hat{S}}}\\{e=1\\wedge\\hat{e}=0\\}.\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "Since our goal is to upper-bound $-\\mathcal{R}_{\\mathrm{FNER}}(\\hat{E})$ , we consider a lower bound $\\mathcal{R}_{\\mathrm{FNER}}(\\hat{E})$ as follows for any $n_{E}:=|\\mathbf{Z}_{E}|$ : ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{P}_{\\mathbf{Z}_{E}}\\left\\{\\mathcal{R}_{\\mathrm{FNER}}(\\hat{E})\\geq L_{\\mathrm{binom}}(\\hat{k};|\\hat{\\mathbf{Z}}_{E}|,\\delta_{E}^{\\prime}/2)\\right\\}}\\\\ &{\\qquad=\\displaystyle\\sum_{m=1}^{n_{E}}\\mathbb{P}_{\\mathbf{Z}_{E}}\\left\\{\\mathcal{R}_{\\mathrm{FNER}}(\\hat{E})\\geq L_{\\mathrm{binom}}(\\hat{k};|\\hat{\\mathbf{Z}}_{E}|,\\delta_{E}^{\\prime}/2)\\;\\Big|\\;|\\hat{\\mathbf{Z}}_{E}|=m\\right\\}\\cdot\\mathbb{P}_{\\mathbf{Z}_{E}}\\{|\\hat{\\mathbf{Z}}_{E}|=m\\}}\\\\ &{\\qquad\\geq\\displaystyle\\sum_{m=1}^{n_{E}}(1-\\delta_{E}^{\\prime}/2)\\cdot\\mathbb{P}_{\\mathbf{Z}_{E}}\\{|\\hat{\\mathbf{Z}}_{E}|=m\\},}\\\\ &{\\qquad=1-\\delta_{E}^{\\prime}/2}\\end{array}\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "where the inequality holds due to the binomial tail bound. The same bound holds when the probability is taken over $\\mathbf{Z}$ . First, let ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\ell_{\\mathrm{FNER}}(\\mathbf{Z}_{E},\\mathbf{Z}_{U}):=\\mathbb{1}\\Big(\\mathcal{R}_{\\mathrm{FNER}}(\\boldsymbol{\\hat{E}})\\geq L_{\\mathrm{Binom}}(\\boldsymbol{\\hat{k}};|\\boldsymbol{\\hat{\\mathbf{Z}}}_{E}|,\\delta_{E}^{\\prime}/2)\\Big).\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "Then, ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{P}_{\\mathbf{Z}}\\{\\mathcal{R}_{\\mathrm{FNER}}(\\hat{E})\\geq L_{\\mathrm{Binom}}(\\hat{k};|\\hat{\\mathbf{Z}}_{E}|,\\delta_{E}^{\\prime}/2)\\}=\\int\\ell_{\\mathrm{FNER}}(\\mathbf{Z}_{E},\\mathbf{Z}_{U})d\\mathbb{P}(\\mathbf{Z})}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad=\\int\\ell_{\\mathrm{FNER}}(\\mathbf{Z}_{E},\\mathbf{Z}_{U})d\\mathbb{P}(\\mathbf{Z}_{E})d\\mathbb{P}(\\mathbf{Z}_{U})}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\qquad\\geq\\int(1-\\delta_{E}^{\\prime}/2)d\\mathbb{P}(\\mathbf{Z}_{U})}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad=1-\\delta_{E}^{\\prime}/2,}\\end{array}\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "where the second equality holds due to the i.i.d. assumption and the inequality holds due to (16). ", "page_idx": 22}, {"type": "text", "text": "NER Bound. Recall ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\mathcal{R}_{\\mathrm{NER}}(\\hat{E}):=\\mathbb{P}_{\\mathcal{D}_{\\hat{S}}}\\{\\hat{e}=0\\}=\\mathbb{P}_{\\mathcal{D}_{\\hat{S}}}\\{G(\\mathbf{x})\\notin\\hat{E}(\\mathbf{y})\\}.\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "Then, we upper bound $\\mathcal{R}_{\\mathrm{NER}}(\\hat{E})$ as follows for any $n_{U}:=|\\mathbf{Z}_{U}|$ : ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{P}_{\\mathbf{Z}_{U}}\\left\\{\\mathcal{R}_{\\mathrm{NER}}(\\hat{E})\\leq U_{\\mathrm{Binom}}(\\hat{l};|\\hat{\\mathbf{Z}}_{U}|,\\delta_{S}^{\\prime})\\right\\}}\\\\ &{\\qquad=\\displaystyle\\sum_{m=1}^{n_{U}}\\mathbb{P}_{\\mathbf{Z}_{U}}\\left\\{\\mathcal{R}_{\\mathrm{NER}}(\\hat{E})\\leq U_{\\mathrm{Binom}}(\\hat{l};|\\hat{\\mathbf{Z}}_{U}|,\\delta_{S}^{\\prime})\\;\\middle|\\;|\\hat{\\mathbf{Z}}_{U}|=m\\right\\}\\cdot\\mathbb{P}_{\\mathbf{Z}_{U}}\\{|\\hat{\\mathbf{Z}}_{U}|=m\\}}\\\\ &{\\quad\\geq\\displaystyle\\sum_{m=1}^{n_{U}}(1-\\delta_{S}^{\\prime})\\cdot\\mathbb{P}_{\\mathbf{Z}_{U}}\\{|\\hat{\\mathbf{Z}}_{U}|=m\\}}\\\\ &{\\quad=1-\\delta_{S}^{\\prime},}\\end{array}\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "where the inequality holds due to the binomial tail bound. Again, the same bound holds when the probability is taken over $\\mathbf{Z}$ . First, let ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\ell_{\\mathrm{NER}}(\\mathbf{Z}_{E},\\mathbf{Z}_{U}):=\\mathbb{1}\\Big(\\mathcal{R}_{\\mathrm{NER}}(\\boldsymbol{\\hat{E}})\\leq U_{\\mathrm{Binom}}(\\boldsymbol{\\hat{l}};|\\mathbf{\\hat{Z}}_{U}|,\\delta_{S}^{\\prime})\\Big)\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "Then, ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{P}_{\\mathbf{Z}}\\big\\{\\mathcal{R}_{\\mathrm{NER}}(\\hat{E})\\leq U_{\\mathrm{Binom}}(\\hat{l};|\\hat{\\mathbf{Z}}_{U}|,\\delta_{S}^{\\prime})\\big\\}=\\displaystyle\\int\\ell_{\\mathrm{NER}}(\\mathbf{Z}_{E},\\mathbf{Z}_{U})d\\mathbb{P}(\\mathbf{Z})}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad=\\displaystyle\\int\\ell_{\\mathrm{NER}}(\\mathbf{Z}_{E},\\mathbf{Z}_{U})d\\mathbb{P}(\\mathbf{Z}_{U})d\\mathbb{P}(\\mathbf{Z}_{E})}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\geq\\displaystyle\\int(1-\\delta_{S}^{\\prime})d\\mathbb{P}(\\mathbf{Z}_{E})}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad=1-\\delta_{S}^{\\prime},}\\end{array}\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "where the inequality holds due to (18). ", "page_idx": 22}, {"type": "text", "text": "Finally, taking the union bound of (15), (17), and (19) completes the proof. ", "page_idx": 22}, {"type": "text", "text": "H Proof of Lemma 3 ", "text_level": 1, "page_idx": 23}, {"type": "text", "text": "$U_{\\mathrm{SSL}}^{(i)}$ be $U_{\\mathrm{SSL}}$ for the $i$ -th candidate of $\\varepsilon_{E}$ in Algorithm 3. Due to Lemma 2, the following holds: ", "page_idx": 23}, {"type": "equation", "text": "$$\n\\mathbb{P}_{\\mathbf{Z}}\\{\\mathbb{P}_{\\mathcal{D}_{\\hat{S}}}\\{e=0\\}>U_{\\mathrm{SSL}}^{(i)})\\}\\le(\\delta_{E}^{\\prime}+\\delta_{S}^{\\prime})/Q.\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "Since U OPT $U_{\\mathrm{SSL}}^{\\mathrm{OPT}}=\\operatorname*{min}_{i\\in[Q]}U_{\\mathrm{SSL}}^{(i)}$ U SSL, we have ", "page_idx": 23}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{P}_{\\mathbf{z}}\\big\\{\\mathbb{P}_{\\mathcal{D}_{\\delta}}\\{e=0\\}>U_{\\mathrm{SSL}}^{\\mathrm{opr}}\\big\\}\\leq\\mathbb{P}_{\\mathbf{z}}\\big\\{\\exists\\,i\\in\\{1,\\dots,Q\\},\\mathbb{P}_{\\mathcal{D}_{\\delta}}\\big\\{e=0\\big\\}>U_{\\mathrm{SSL}}^{(i)}\\big\\}}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\qquad\\leq\\displaystyle\\sum_{i=1}^{Q}\\mathbb{P}_{\\mathbf{z}}\\big\\{\\mathbb{P}_{\\mathcal{D}_{\\delta}}\\big\\{e=0\\big\\}>U_{\\mathrm{SSL}}^{(i)}\\big\\}}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\leq\\delta_{E}^{\\prime}+\\delta_{S}^{\\prime},}\\end{array}\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "where the second inequality is due to a union bound. This completes the proof. ", "page_idx": 23}, {"type": "text", "text": "I Proof of Theorem 1 ", "text_level": 1, "page_idx": 23}, {"type": "text", "text": "Let $\\mathcal{H}$ be the calibration set-dependent hypothesis space of selective generators, where $n_{\\mathcal{H}}:=|\\mathcal{H}|$ is always calibration set independent. Letting $U^{(i)}$ be the FDR-E bound computed given the $i$ -th selective generator $S_{i}$ in $\\mathcal{H}$ , we first describe how to derive an upper bound of the FDR-E for a given hypothesis $S_{i}$ . ", "page_idx": 23}, {"type": "text", "text": "Since an upper bound of (E) in (2) is proved in Lemma 3, the remaining parts are (i) to derive upper bounds on the others and (ii) to take the union bound. For proportions of the visibility of textual entailment labels, i.e., (B) and (D) in (2), and the FDR-E for the supervised case only using entailment-labeled examples, i.e., (C) in (2), the followings hold due to the binomial tail bound: ", "page_idx": 23}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{P}_{\\mathbf{Z}}\\Big\\{\\mathbb{P}_{\\mathcal{D}_{s_{i}}}\\{v=1\\}\\le\\underbrace{U_{\\mathrm{Binon}}\\big(|\\hat{\\mathbf{Z}}_{E}|;|\\hat{\\mathbf{Z}}_{E}|+|\\hat{\\mathbf{Z}}_{U}|,\\delta_{W}/(2\\times|\\mathcal{H}|)\\big)}_{:=w_{\\mathrm{s.}}^{(i)}}\\Big\\}\\ge1-\\delta_{W}/(2\\times|\\mathcal{H}|);}\\\\ &{\\mathbb{P}_{\\mathbf{Z}}\\Big\\{\\mathbb{P}_{\\mathcal{D}_{s_{i}}}\\{v=0\\}\\le\\underbrace{U_{\\mathrm{Binon}}\\big(|\\hat{\\mathbf{Z}}_{U}|;|\\hat{\\mathbf{Z}}_{E}|+|\\hat{\\mathbf{Z}}_{U}|,\\delta_{W}/(2\\times|\\mathcal{H}|)\\big)}_{:=w_{\\mathrm{s.}}^{(i)}}\\Big\\}\\ge1-\\delta_{W}/(2\\times|\\mathcal{H}|);}\\\\ &{\\mathbb{P}_{\\mathbf{Z}}\\Big\\{\\mathbb{P}_{\\mathcal{D}_{s_{i}}}\\{e=0\\}\\le\\underbrace{U_{\\mathrm{Binon}}\\big(|\\hat{\\mathbf{Z}}_{E}^{\\in0}|;|\\hat{\\mathbf{Z}}_{E}|,\\delta_{S}/(2\\times|\\mathcal{H}|)\\big)}_{:=U_{\\mathrm{s.}}^{(i)}}\\Big\\}\\ge1-\\delta_{S}/(2\\times|\\mathcal{H}|),}\\end{array}\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "where $\\hat{\\mathbf{Z}}_{E}$ and $\\hat{\\mathbf{Z}}_{U}$ are defined same as Lemma 2 does, and $\\hat{\\mathbf{Z}}_{E}^{e=0}:=\\{(\\mathbf{x},\\mathbf{y},e)\\in\\hat{\\mathbf{Z}}_{E}\\mid e=0\\}$ . Note that the binomial tail bound is applied to flitered sets by the given selective generator (e.g., $\\hat{\\mathbf{Z}}_{E}^{\\phantom{\\dagger}}$ ), but we can use the same bound for the non-filtered set $\\mathbf{Z}$ , by using the same marginalization technique over the size of a filtered set, as in, e.g., (15). ", "page_idx": 23}, {"type": "text", "text": "Thus, by taking the union bound along with Lemma 3 when $\\delta_{E}^{\\prime}=\\delta_{E}$ and $\\delta_{S}^{\\prime}=\\delta_{S}/2$ , ", "page_idx": 23}, {"type": "equation", "text": "$$\n\\mathbb{P}_{\\mathbf{Z}}\\{\\mathcal{R}_{E}(S_{i})\\leq U^{(i)}\\}\\geq1-(\\delta_{E}+\\delta_{S}+\\delta_{W})/|\\mathcal{H}|,\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "where Ui := wSL U SL + wSSLU SOSPLT is the computed FDR-E bound a given selective generator $S_{i}$ .   \nHere, U OPT(i)r efers to the smallest FDR-E bound of (E) in (2) given the $i$ -th selective generator. ", "page_idx": 23}, {"type": "text", "text": "Since (20) holds for all $S_{i}\\in{\\mathcal{H}}$ , and the final bound $\\hat{U}$ is chosen among them, this completes the proof by taking an union bound, i.e., ", "page_idx": 23}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\mathbb{P}_{\\mathbf{Z}}\\left\\{\\mathcal{R}_{E}(\\hat{S})>\\hat{U}\\right\\}\\leq\\mathbb{P}_{\\mathbf{Z}}\\left\\{\\mathcal{I}S_{i}\\in\\mathcal{H},\\mathcal{R}_{E}(S_{i})>U_{i}\\right\\}}&{}\\\\ {=\\displaystyle\\sum_{k=1}^{n_{E}}d\\mathbb{P}_{\\mathbf{Z}}\\left\\{\\exists S_{i}\\in\\mathcal{H},\\mathcal{R}_{E}(S_{i})>U_{i},|\\mathcal{R}|=k\\right\\}}\\\\ {=\\displaystyle\\sum_{k=1}^{n_{E}}\\mathbb{P}_{\\mathbf{Z}}\\left\\{\\exists S_{i}\\in\\mathcal{H},\\mathcal{R}_{E}(S_{i})>U_{i}\\ |\\ |\\mathcal{H}|=k\\right\\}\\mathbb{P}_{\\mathbf{Z}}\\left\\{|\\mathcal{H}|=k\\right\\}}\\\\ {\\leq\\displaystyle\\sum_{k=1}^{n_{E}}\\sum_{i=1}^{k}\\mathbb{P}_{\\mathbf{Z}}\\left\\{\\mathcal{R}_{E}(S_{i})>U_{i}\\ |\\ |\\mathcal{H}|=k\\right\\}\\mathbb{P}_{\\mathbf{Z}}\\left\\{|\\mathcal{H}|=k\\right\\}}\\\\ {\\leq\\displaystyle\\sum_{k=1}^{n_{E}}\\sum_{i=1}^{k}\\left(\\frac{\\delta_{E}+\\delta_{S}+\\delta_{W}}{k}\\right)\\mathbb{P}_{\\mathbf{Z}}\\left\\{|\\mathcal{H}|=k\\right\\}}\\\\ {=\\delta_{E}+\\delta_{S}+\\delta_{W}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "J Proof of Lemma 4 ", "text_level": 1, "page_idx": 24}, {"type": "text", "text": "We say $f_{M}$ is perfectly calibrated with respect to $\\mathcal{D},G,E_{\\mathrm{true}}$ if ", "page_idx": 24}, {"type": "equation", "text": "$$\n\\mathbb{P}_{\\mathcal{D}}\\{G(\\mathbf{x})\\in E_{\\mathrm{true}}(\\mathbf{y})\\mid f_{M}(\\mathbf{x},G(\\mathbf{x}))=t\\})=t,\\forall t.\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "The true discovery rate with respect to $E_{\\mathrm{true}}$ conditioned on $f_{M}(\\mathbf{x},G(\\mathbf{x}))\\geq\\tau_{S}$ , i.e., 1 \u2212FDR-E, is as follows: ", "page_idx": 24}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{P}\\{G(\\mathbf{x})\\in E_{\\mathrm{tue}}(\\mathbf{y})\\mid f_{M}(\\mathbf{x},G(\\mathbf{x}))\\geq\\tau_{S}\\}}\\\\ &{\\quad=\\frac{\\int_{\\tau_{S}}^{1}\\mathbb{P}\\{G(\\mathbf{x})\\in E_{\\mathrm{tue}}(\\mathbf{y})\\mid f_{M}(\\mathbf{x},G(\\mathbf{x}))=t\\}\\mathbb{P}\\{f_{M}(\\mathbf{x},G(\\mathbf{x}))=t\\}d t}{\\int_{\\tau_{S}}^{1}\\mathbb{P}\\{f_{M}(\\mathbf{x},G(\\mathbf{x}))=t\\}d t}}\\\\ &{\\quad=\\frac{\\int_{\\tau_{S}}^{1}t\\mathbb{P}\\left\\{f_{M}(\\mathbf{x},G(\\mathbf{x}))=t\\right\\}d t}{\\int_{\\tau_{S}}^{1}\\mathbb{P}\\left\\{f_{M}(\\mathbf{x},G(\\mathbf{x}))=t\\right\\}d t},}\\end{array}\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "where and (22) holds as $f_{M}$ is perfectly calibrated, i.e., (21). ", "page_idx": 24}, {"type": "text", "text": "Letting $h(t)\\,:=\\,\\mathbb{P}\\{f_{M}(\\mathbf{x},G(\\mathbf{x}))\\,=\\,t\\}.$ , $\\begin{array}{r}{H(t):=\\int_{t}^{1}h(t^{\\prime})d t^{\\prime}}\\end{array}$ , $i(t):=t\\mathbb{P}\\{f_{M}(\\mathbf{x},G(\\mathbf{x}))\\,=\\,t\\}$ , and I(t) := t1 i(t\u2032)dt\u2032, since we have \u03c4S \u2264 $\\begin{array}{r}{\\tau_{S}\\leq\\frac{\\int_{\\tau_{S}}^{1}t\\mathbb{P}\\{f_{M}(\\mathbf{x},G(\\mathbf{x}))=t\\}d t}{\\int_{\\tau_{S}}^{1}\\mathbb{P}\\{f_{M}(\\mathbf{x},G(\\mathbf{x}))=t\\}d t}\\leq1}\\end{array}$ \u03c41S P{fM(x,G(x))=t}dt \u22641, the following holds: ", "page_idx": 24}, {"type": "equation", "text": "$$\nI(1)-I(\\tau_{S})\\geq\\tau_{S}(H(1)-H(\\tau_{S})).\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "Therefore, ", "page_idx": 24}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\displaystyle\\frac{d}{d\\tau_{S}}\\mathbb{P}\\{G(\\mathbf{x})\\in E_{\\mathrm{true}}(\\mathbf{y})\\mid f_{M}(\\mathbf{x},G(\\mathbf{x}))\\geq\\tau_{S}\\}=\\displaystyle\\frac{d}{d\\tau_{S}}\\left\\{\\frac{I(1)-I(\\tau_{S})}{H(1)-H(\\tau_{S})}\\right\\}}\\\\ &{\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad=\\displaystyle\\frac{-h(\\tau_{S})\\left[\\tau_{S}(H(1)-H(\\tau_{S}))-(I(1)-I(\\tau_{S}))\\right]}{(H(1)-H(\\tau_{S}))^{2}}}\\\\ &{\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\ge0.}\\end{array}\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "This completes the proof. ", "page_idx": 24}, {"type": "text", "text": "Note that the classification problem can be reduced from the special case, i.e., $E_{\\mathrm{true}}(y):=E_{\\mathrm{EM}}(y)$ , where $\\mathscr{V}:=\\mathscr{W}$ and $E_{\\mathrm{EM}}(y)\\\":=\\{y\\}=\\arg\\operatorname*{max}_{w\\in{\\mathcal{W}}}\\;\\mathbb{P}(Y=\\Bar{w_{\\big|}}\\;\\mathbf{X}=\\mathbf{x})$ . ", "page_idx": 24}, {"type": "image", "img_path": "glfYOAzh2f/tmp/694b56178a1eb3258d7e22f3d143a8a8dab7aa353bc597ae53e875eec02e1fb8.jpg", "img_caption": ["(a) supervised methods "], "img_footnote": [], "page_idx": 25}, {"type": "image", "img_path": "glfYOAzh2f/tmp/82d3d1e510e85138ef25655a3287cd165f5e1f836184bc22812afcf55b4963eb.jpg", "img_caption": ["(b) unsupervised and semi-supervised methods "], "img_footnote": [], "page_idx": 25}, {"type": "text", "text": "Figure 4: FDR-E box plots of methods for GPT-3.5-turbo. We randomly split the calibration ad test set 100 times for box plots. For supervised methods (a), we use all entailment labels, i.e., $|\\mathbf{Z}_{E}|=|\\mathbf{Z}_{E}^{\\mathrm{cal}}|$ . For (b), which includes an unsupervised method $(\\mathtt{S G e n}_{\\mathtt{E M}})$ and semi-supervised methods, we use $|\\mathbf{Z}_{E}|=0.75|\\mathbf{Z}_{E}^{\\mathrm{cal}}|$ . All methods except for $\\mathsf{S G e n}^{\\mathrm{Semi}}$ use $f_{M_{1}}$ as a score function. The methods that do not control $\\varepsilon_{S}$ FDR-E in learning at least once are drawn using red boxes but otherwise using green boxes in Figure 4(a) and Figure 4(b). We draw the whisker plot to indicate $100\\delta\\%$ and $100(1-\\delta)\\%$ quantiles. In both (a) and (b) with green boxes, as the top of the whisker is below of the dotted line, we can see that the FDR-E is well controlled with probability at least $\\delta$ , i.e., they satisfy the PAC agruea r(aaSn)e , $\\varepsilon_{S}$ aRn-dE  (ibn) , , ${\\mathsf{S G e n}}_{\\mathtt{E M}}{=}\\ 0$ $\\mathtt{S G e n}^{\\mathtt{S u p}}\\mathrm{=}\\,100$ $\\mathtt{S G e n}_{\\mathtt{N o M S}}^{\\mathtt{S e m i-S u p}}\\!=\\!100$ $\\mathsf{S G e n_{P L}^{H-S e m i}}\\mathrm{=100}$ $\\mathsf{S G e n}_{\\mathrm{PFL}}^{\\mathrm{H-Semi}}\\mathrm{=100}$ $\\mathtt{S G e n}_{\\mathtt{N o M S}}^{\\mathtt{S e m i}}\\mathrm{=18}$ , $\\mathtt{S G e n}^{\\mathtt{S e m i}}\\!=100$ . ", "page_idx": 25}, {"type": "text", "text": "K Additional Experiments ", "text_level": 1, "page_idx": 25}, {"type": "text", "text": "Table 3: Comparison results of fully supervised methods. Here, we use all entailment labels, i.e., $|\\mathbf{Z}_{E}|\\ =\\ |\\mathbf{\\bar{Z}}_{E}^{\\mathrm{cal}}|$ for GPT-3.5-turbo and Alpaca-7B. The best results are highlighted in bold, results from methods that do not satisfy desired FDR-E guarantee are underlined. In GPT-3.5-turbo and Alpaca-7B, the best efficiency values among methods that satisfy a desired FDR-E guarantee are 0.7535 and 0.2959, respectively, which serve as the best achievable efficiency results of semisupervised methods. ", "page_idx": 25}, {"type": "table", "img_path": "glfYOAzh2f/tmp/22749479d4f9bafc86c96ab91fd7da829be120abb0181e8fe7643edfbbd01293.jpg", "table_caption": [], "table_footnote": [], "page_idx": 25}, {"type": "text", "text": "Table 4: Comparison results of semi-supervised methods. Here, $|\\mathbf{Z}_{U}|\\,=10K$ for GPT-3.5-turbo and Alpaca-7B. The best results are highlighted in bold and results from methods that do not satisfy desired FDR-E guarantee are underlined. We used QA2D dataset, flitered with only SQuAD, where human transformed QA sentences exist. $\\varepsilon=0.15$ . ", "page_idx": 26}, {"type": "table", "img_path": "glfYOAzh2f/tmp/f5b6b2e45e1f3d316dd50398546513d68a151367d9d2ecd15dbabcc14ed967c1.jpg", "table_caption": [], "table_footnote": [], "page_idx": 26}, {"type": "table", "img_path": "glfYOAzh2f/tmp/dc9117555683682188e217def9015860027b71d9ea40c940a205ca9c3fb6e799.jpg", "table_caption": ["Table 5: Comparison results of fully supervised methods. Here, we use all entailment labels, i.e., $|\\mathbf{Z}_{E}|=|\\mathbf{Z}_{E}^{\\mathrm{cal}}|$ for GPT-3.5-turbo and Alpaca-7B. The best results are highlighted in bold, results from methods that do not satisfy desired FDR-E guarantee are underlined. We used QA2D dataset, filtered with only SQuAD, where human transformed QA sentences exist. $\\varepsilon=0.15$ . "], "table_footnote": [], "page_idx": 26}, {"type": "text", "text": "NeurIPS Paper Checklist ", "text_level": 1, "page_idx": 26}, {"type": "text", "text": "The checklist is designed to encourage best practices for responsible machine learning research, addressing issues of reproducibility, transparency, research ethics, and societal impact. Do not remove the checklist: The papers not including the checklist will be desk rejected. The checklist should follow the references and follow the (optional) supplemental material. The checklist does NOT count towards the page limit. ", "page_idx": 26}, {"type": "text", "text": "Please read the checklist guidelines carefully for information on how to answer these questions. For each question in the checklist: ", "page_idx": 26}, {"type": "text", "text": "\u2022 You should answer [Yes] , [No] , or [NA] .   \n\u2022 [NA] means either that the question is Not Applicable for that particular paper or the relevant information is Not Available.   \n\u2022 Please provide a short (1\u20132 sentence) justification right after your answer (even for NA). ", "page_idx": 26}, {"type": "text", "text": "The checklist answers are an integral part of your paper submission. They are visible to the reviewers, area chairs, senior area chairs, and ethics reviewers. You will be asked to also include it (after eventual revisions) with the final version of your paper, and its final version will be published with the paper. ", "page_idx": 26}, {"type": "text", "text": "The reviewers of your paper will be asked to use the checklist as one of the factors in their evaluation. While \"[Yes] \" is generally preferable to \"[No] \", it is perfectly acceptable to answer \"[No] \" provided a proper justification is given (e.g., \"error bars are not reported because it would be too computationally expensive\" or \"we were unable to find the license for the dataset we used\"). In general, answering \"[No] \" or \"[NA] \" is not grounds for rejection. While the questions are phrased in a binary way, we acknowledge that the true answer is often more nuanced, so please just use your best judgment and write a justification to elaborate. All supporting evidence can appear either in the main paper or the supplemental material, provided in appendix. If you answer [Yes] to a question, in the justification please point to the section(s) where related material for the question can be found. ", "page_idx": 26}, {"type": "text", "text": "", "page_idx": 27}, {"type": "text", "text": "IMPORTANT, please: ", "text_level": 1, "page_idx": 27}, {"type": "text", "text": "\u2022 Delete this instruction block, but keep the section heading \u201cNeurIPS paper checklist\", \u2022 Keep the checklist subsection headings, questions/answers and guidelines below. \u2022 Do not modify the questions and only use the provided macros for your answers. ", "page_idx": 27}, {"type": "text", "text": "1. Claims ", "text_level": 1, "page_idx": 27}, {"type": "text", "text": "Question: Do the main claims made in the abstract and introduction accurately reflect the paper\u2019s contributions and scope? ", "page_idx": 27}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 27}, {"type": "text", "text": "Justification: The theoretical guarantee and the proposed algorithm are illustrated in Section 4. Detailed proofs and algorithmic descriptions can be found in the appendix. Experimental results are illustrated in Section 5 ", "page_idx": 27}, {"type": "text", "text": "Guidelines: ", "text_level": 1, "page_idx": 27}, {"type": "text", "text": "\u2022 The answer NA means that the abstract and introduction do not include the claims made in the paper.   \n\u2022 The abstract and/or introduction should clearly state the claims made, including the contributions made in the paper and important assumptions and limitations. A No or NA answer to this question will not be perceived well by the reviewers.   \n\u2022 The claims made should match theoretical and experimental results, and reflect how much the results can be expected to generalize to other settings.   \n\u2022 It is fine to include aspirational goals as motivation as long as it is clear that these goals are not attained by the paper. ", "page_idx": 27}, {"type": "text", "text": "2. Limitations ", "text_level": 1, "page_idx": 27}, {"type": "text", "text": "Question: Does the paper discuss the limitations of the work performed by the authors? Answer: [Yes] ", "page_idx": 27}, {"type": "text", "text": "Justification: The limitations due to assumptions made for the theoretical guarantee and the expensive data labeling process are illustrated in Section 6. ", "page_idx": 27}, {"type": "text", "text": "Guidelines: ", "text_level": 1, "page_idx": 27}, {"type": "text", "text": "\u2022 The answer NA means that the paper has no limitation while the answer No means that the paper has limitations, but those are not discussed in the paper.   \n\u2022 The authors are encouraged to create a separate \"Limitations\" section in their paper.   \n\u2022 The paper should point out any strong assumptions and how robust the results are to violations of these assumptions (e.g., independence assumptions, noiseless settings, model well-specification, asymptotic approximations only holding locally). The authors should reflect on how these assumptions might be violated in practice and what the implications would be.   \n\u2022 The authors should reflect on the scope of the claims made, e.g., if the approach was only tested on a few datasets or with a few runs. In general, empirical results often depend on implicit assumptions, which should be articulated.   \n\u2022 The authors should reflect on the factors that influence the performance of the approach. For example, a facial recognition algorithm may perform poorly when image resolution is low or images are taken in low lighting. Or a speech-to-text system might not be used reliably to provide closed captions for online lectures because it fails to handle technical jargon.   \n\u2022 The authors should discuss the computational efficiency of the proposed algorithms and how they scale with dataset size.   \n\u2022 If applicable, the authors should discuss possible limitations of their approach to address problems of privacy and fairness. ", "page_idx": 27}, {"type": "text", "text": "\u2022 While the authors might fear that complete honesty about limitations might be used by reviewers as grounds for rejection, a worse outcome might be that reviewers discover limitations that aren\u2019t acknowledged in the paper. The authors should use their best judgment and recognize that individual actions in favor of transparency play an important role in developing norms that preserve the integrity of the community. Reviewers will be specifically instructed to not penalize honesty concerning limitations. ", "page_idx": 28}, {"type": "text", "text": "3. Theory Assumptions and Proofs ", "text_level": 1, "page_idx": 28}, {"type": "text", "text": "Question: For each theoretical result, does the paper provide the full set of assumptions and a complete (and correct) proof? ", "page_idx": 28}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 28}, {"type": "text", "text": "Justification: We provide the correct and complete proofs with full set of assumptions made for each theoretical result, which are illustrated in detail in the appendix. Furthermore, the limitations of the theoretical guarantees induced by the assumptions are stated in Section 6. Guidelines: ", "page_idx": 28}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include theoretical results.   \n\u2022 All the theorems, formulas, and proofs in the paper should be numbered and crossreferenced.   \n\u2022 All assumptions should be clearly stated or referenced in the statement of any theorems.   \n\u2022 The proofs can either appear in the main paper or the supplemental material, but if they appear in the supplemental material, the authors are encouraged to provide a short proof sketch to provide intuition.   \n\u2022 Inversely, any informal proof provided in the core of the paper should be complemented by formal proofs provided in appendix or supplemental material.   \n\u2022 Theorems and Lemmas that the proof relies upon should be properly referenced. ", "page_idx": 28}, {"type": "text", "text": "4. Experimental Result Reproducibility ", "text_level": 1, "page_idx": 28}, {"type": "text", "text": "Question: Does the paper fully disclose all the information needed to reproduce the main experimental results of the paper to the extent that it affects the main claims and/or conclusions of the paper (regardless of whether the code and data are provided or not)? ", "page_idx": 28}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 28}, {"type": "text", "text": "Justification: Datasets, models, and hyperparameters used in implementing proposed algorithms are all described in detail. See Section 5. ", "page_idx": 28}, {"type": "text", "text": "Guidelines: ", "text_level": 1, "page_idx": 28}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 If the paper includes experiments, a No answer to this question will not be perceived well by the reviewers: Making the paper reproducible is important, regardless of whether the code and data are provided or not.   \n\u2022 If the contribution is a dataset and/or model, the authors should describe the steps taken to make their results reproducible or verifiable.   \n\u2022 Depending on the contribution, reproducibility can be accomplished in various ways. For example, if the contribution is a novel architecture, describing the architecture fully might suffice, or if the contribution is a specific model and empirical evaluation, it may be necessary to either make it possible for others to replicate the model with the same dataset, or provide access to the model. In general. releasing code and data is often one good way to accomplish this, but reproducibility can also be provided via detailed instructions for how to replicate the results, access to a hosted model (e.g., in the case of a large language model), releasing of a model checkpoint, or other means that are appropriate to the research performed.   \n\u2022 While NeurIPS does not require releasing code, the conference does require all submissions to provide some reasonable avenue for reproducibility, which may depend on the nature of the contribution. For example (a) If the contribution is primarily a new algorithm, the paper should make it clear how to reproduce that algorithm. (b) If the contribution is primarily a new model architecture, the paper should describe the architecture clearly and fully.   \n(c) If the contribution is a new model (e.g., a large language model), then there should either be a way to access this model for reproducing the results or a way to reproduce the model (e.g., with an open-source dataset or instructions for how to construct the dataset).   \n(d) We recognize that reproducibility may be tricky in some cases, in which case authors are welcome to describe the particular way they provide for reproducibility. In the case of closed-source models, it may be that access to the model is limited in some way (e.g., to registered users), but it should be possible for other researchers to have some path to reproducing or verifying the results. ", "page_idx": 28}, {"type": "text", "text": "", "page_idx": 29}, {"type": "text", "text": "5. Open access to data and code ", "text_level": 1, "page_idx": 29}, {"type": "text", "text": "Question: Does the paper provide open access to the data and code, with sufficient instructions to faithfully reproduce the main experimental results, as described in supplemental material? ", "page_idx": 29}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 29}, {"type": "text", "text": "Justification: We will provide the code to train and evaluate the proposed algorithm, which reproduces the experiment results in the paper after the rebuttal process. ", "page_idx": 29}, {"type": "text", "text": "Guidelines: ", "page_idx": 29}, {"type": "text", "text": "\u2022 The answer NA means that paper does not include experiments requiring code.   \n\u2022 Please see the NeurIPS code and data submission guidelines (https://nips.cc/ public/guides/CodeSubmissionPolicy) for more details.   \n\u2022 While we encourage the release of code and data, we understand that this might not be possible, so \u201cNo\u201d is an acceptable answer. Papers cannot be rejected simply for not including code, unless this is central to the contribution (e.g., for a new open-source benchmark).   \n\u2022 The instructions should contain the exact command and environment needed to run to reproduce the results. See the NeurIPS code and data submission guidelines (https: //nips.cc/public/guides/CodeSubmissionPolicy) for more details.   \n\u2022 The authors should provide instructions on data access and preparation, including how to access the raw data, preprocessed data, intermediate data, and generated data, etc.   \n\u2022 The authors should provide scripts to reproduce all experimental results for the new proposed method and baselines. If only a subset of experiments are reproducible, they should state which ones are omitted from the script and why.   \n\u2022 At submission time, to preserve anonymity, the authors should release anonymized versions (if applicable).   \n\u2022 Providing as much information as possible in supplemental material (appended to the paper) is recommended, but including URLs to data and code is permitted. ", "page_idx": 29}, {"type": "text", "text": "6. Experimental Setting/Details ", "text_level": 1, "page_idx": 29}, {"type": "text", "text": "Question: Does the paper specify all the training and test details (e.g., data splits, hyperparameters, how they were chosen, type of optimizer, etc.) necessary to understand the results? ", "page_idx": 29}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 29}, {"type": "text", "text": "Justification: We provide the details of our experiments including generation. Guidelines: ", "page_idx": 29}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments. \u2022 The experimental setting should be presented in the core of the paper to a level of detail that is necessary to appreciate the results and make sense of them. \u2022 The full details can be provided either with the code, in appendix, or as supplemental material. ", "page_idx": 29}, {"type": "text", "text": "7. Experiment Statistical Significance ", "text_level": 1, "page_idx": 29}, {"type": "text", "text": "Question: Does the paper report error bars suitably and correctly defined or other appropriate information about the statistical significance of the experiments? ", "page_idx": 29}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 29}, {"type": "text", "text": "Justification: This paper includes holdout experiments to assess statistical significance and provide error bars for the reported results. ", "page_idx": 30}, {"type": "text", "text": "Guidelines: ", "page_idx": 30}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 The authors should answer \"Yes\" if the results are accompanied by error bars, confidence intervals, or statistical significance tests, at least for the experiments that support the main claims of the paper.   \n\u2022 The factors of variability that the error bars are capturing should be clearly stated (for example, train/test split, initialization, random drawing of some parameter, or overall run with given experimental conditions).   \n\u2022 The method for calculating the error bars should be explained (closed form formula, call to a library function, bootstrap, etc.)   \n\u2022 The assumptions made should be given (e.g., Normally distributed errors).   \n\u2022 It should be clear whether the error bar is the standard deviation or the standard error of the mean.   \n\u2022 It is OK to report 1-sigma error bars, but one should state it. The authors should preferably report a 2-sigma error bar than state that they have a $96\\%$ CI, if the hypothesis of Normality of errors is not verified.   \n\u2022 For asymmetric distributions, the authors should be careful not to show in tables or figures symmetric error bars that would yield results that are out of range (e.g. negative error rates).   \n\u2022 If error bars are reported in tables or plots, The authors should explain in the text how they were calculated and reference the corresponding figures or tables in the text. ", "page_idx": 30}, {"type": "text", "text": "8. Experiments Compute Resources ", "text_level": 1, "page_idx": 30}, {"type": "text", "text": "Question: For each experiment, does the paper provide sufficient information on the computer resources (type of compute workers, memory, time of execution) needed to reproduce the experiments? ", "page_idx": 30}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 30}, {"type": "text", "text": "Justification: We wrote the details in Appendix. Guidelines: ", "page_idx": 30}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 The paper should indicate the type of compute workers CPU or GPU, internal cluster, or cloud provider, including relevant memory and storage.   \n\u2022 The paper should provide the amount of compute required for each of the individual experimental runs as well as estimate the total compute.   \n\u2022 The paper should disclose whether the full research project required more compute than the experiments reported in the paper (e.g., preliminary or failed experiments that didn\u2019t make it into the paper). ", "page_idx": 30}, {"type": "text", "text": "9. Code Of Ethics ", "text_level": 1, "page_idx": 30}, {"type": "text", "text": "Question: Does the research conducted in the paper conform, in every respect, with the NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines? ", "page_idx": 30}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 30}, {"type": "text", "text": "Justification: The research is conducted with the NeurIPS Code of Ethics. Guidelines: ", "page_idx": 30}, {"type": "text", "text": "\u2022 The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics.   \n\u2022 If the authors answer No, they should explain the special circumstances that require a deviation from the Code of Ethics.   \n\u2022 The authors should make sure to preserve anonymity (e.g., if there is a special consideration due to laws or regulations in their jurisdiction). ", "page_idx": 30}, {"type": "text", "text": "10. Broader Impacts ", "text_level": 1, "page_idx": 30}, {"type": "text", "text": "Question: Does the paper discuss both potential positive societal impacts and negative societal impacts of the work performed? ", "page_idx": 30}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 31}, {"type": "text", "text": "Justification: The paper can measure the uncertainty of generative large language models, which is crucial for decision making problems. ", "page_idx": 31}, {"type": "text", "text": "Guidelines: ", "page_idx": 31}, {"type": "text", "text": "\u2022 The answer NA means that there is no societal impact of the work performed.   \n\u2022 If the authors answer NA or No, they should explain why their work has no societal impact or why the paper does not address societal impact.   \n\u2022 Examples of negative societal impacts include potential malicious or unintended uses (e.g., disinformation, generating fake profiles, surveillance), fairness considerations (e.g., deployment of technologies that could make decisions that unfairly impact specific groups), privacy considerations, and security considerations.   \n\u2022 The conference expects that many papers will be foundational research and not tied to particular applications, let alone deployments. However, if there is a direct path to any negative applications, the authors should point it out. For example, it is legitimate to point out that an improvement in the quality of generative models could be used to generate deepfakes for disinformation. On the other hand, it is not needed to point out that a generic algorithm for optimizing neural networks could enable people to train models that generate Deepfakes faster.   \n\u2022 The authors should consider possible harms that could arise when the technology is being used as intended and functioning correctly, harms that could arise when the technology is being used as intended but gives incorrect results, and harms following from (intentional or unintentional) misuse of the technology.   \n\u2022 If there are negative societal impacts, the authors could also discuss possible mitigation strategies (e.g., gated release of models, providing defenses in addition to attacks, mechanisms for monitoring misuse, mechanisms to monitor how a system learns from feedback over time, improving the efficiency and accessibility of ML). ", "page_idx": 31}, {"type": "text", "text": "11. Safeguards ", "text_level": 1, "page_idx": 31}, {"type": "text", "text": "Question: Does the paper describe safeguards that have been put in place for responsible release of data or models that have a high risk for misuse (e.g., pretrained language models, image generators, or scraped datasets)? ", "page_idx": 31}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 31}, {"type": "text", "text": "Justification: This paper poses no such risks ", "page_idx": 31}, {"type": "text", "text": "Guidelines: ", "page_idx": 31}, {"type": "text", "text": "\u2022 The answer NA means that the paper poses no such risks.   \n\u2022 Released models that have a high risk for misuse or dual-use should be released with necessary safeguards to allow for controlled use of the model, for example by requiring that users adhere to usage guidelines or restrictions to access the model or implementing safety filters.   \n\u2022 Datasets that have been scraped from the Internet could pose safety risks. The authors should describe how they avoided releasing unsafe images.   \n\u2022 We recognize that providing effective safeguards is challenging, and many papers do not require this, but we encourage authors to take this into account and make a best faith effort. ", "page_idx": 31}, {"type": "text", "text": "12. Licenses for existing assets ", "text_level": 1, "page_idx": 31}, {"type": "text", "text": "Question: Are the creators or original owners of assets (e.g., code, data, models), used in the paper, properly credited and are the license and terms of use explicitly mentioned and properly respected? ", "page_idx": 31}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 31}, {"type": "text", "text": "Justification: This paper cite the original papers such as dataset. ", "page_idx": 31}, {"type": "text", "text": "Guidelines: ", "page_idx": 31}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not use existing assets.   \n\u2022 The authors should cite the original paper that produced the code package or dataset.   \n\u2022 The authors should state which version of the asset is used and, if possible, include a URL.   \n\u2022 The name of the license (e.g., CC-BY 4.0) should be included for each asset.   \n\u2022 For scraped data from a particular source (e.g., website), the copyright and terms of service of that source should be provided.   \n\u2022 If assets are released, the license, copyright information, and terms of use in the package should be provided. For popular datasets, paperswithcode.com/datasets has curated licenses for some datasets. Their licensing guide can help determine the license of a dataset.   \n\u2022 For existing datasets that are re-packaged, both the original license and the license of the derived asset (if it has changed) should be provided.   \n\u2022 If this information is not available online, the authors are encouraged to reach out to the asset\u2019s creators. ", "page_idx": 31}, {"type": "text", "text": "", "page_idx": 32}, {"type": "text", "text": "13. New Assets ", "text_level": 1, "page_idx": 32}, {"type": "text", "text": "Question: Are new assets introduced in the paper well documented and is the documentation provided alongside the assets? ", "page_idx": 32}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 32}, {"type": "text", "text": "Justification: This paper will release code for running experiments and it is well documented. Guidelines: ", "page_idx": 32}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not release new assets.   \n\u2022 Researchers should communicate the details of the dataset/code/model as part of their submissions via structured templates. This includes details about training, license, limitations, etc.   \n\u2022 The paper should discuss whether and how consent was obtained from people whose asset is used.   \n\u2022 At submission time, remember to anonymize your assets (if applicable). You can either create an anonymized URL or include an anonymized zip file. ", "page_idx": 32}, {"type": "text", "text": "14. Crowdsourcing and Research with Human Subjects ", "text_level": 1, "page_idx": 32}, {"type": "text", "text": "Question: For crowdsourcing experiments and research with human subjects, does the paper include the full text of instructions given to participants and screenshots, if applicable, as well as details about compensation (if any)? ", "page_idx": 32}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 32}, {"type": "text", "text": "Justification: This paper does not involve crowdsourcing nor research with human subjects. Guidelines: ", "page_idx": 32}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u2022 Including this information in the supplemental material is fine, but if the main contribution of the paper involves human subjects, then as much detail as possible should be included in the main paper.   \n\u2022 According to the NeurIPS Code of Ethics, workers involved in data collection, curation, or other labor should be paid at least the minimum wage in the country of the data collector. ", "page_idx": 32}, {"type": "text", "text": "15. Institutional Review Board (IRB) Approvals or Equivalent for Research with Human Subjects ", "page_idx": 32}, {"type": "text", "text": "Question: Does the paper describe potential risks incurred by study participants, whether such risks were disclosed to the subjects, and whether Institutional Review Board (IRB) approvals (or an equivalent approval/review based on the requirements of your country or institution) were obtained? ", "page_idx": 32}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 32}, {"type": "text", "text": "Justification: This paper does not involve crowdsourcing nor research with human subjects. Guidelines: ", "page_idx": 32}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u2022 Depending on the country in which research is conducted, IRB approval (or equivalent) may be required for any human subjects research. If you obtained IRB approval, you should clearly state this in the paper.   \n\u2022 We recognize that the procedures for this may vary significantly between institutions and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the guidelines for their institution.   \n\u2022 For initial submissions, do not include any information that would break anonymity (if applicable), such as the institution conducting the review. ", "page_idx": 33}]