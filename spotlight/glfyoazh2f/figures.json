[{"figure_path": "glfYOAzh2f/figures/figures_1_1.jpg", "caption": "Figure 1: An overview and qualitative results of our proposed method. The key idea is to learn an entailment-aware selective generator with an abstaining option that controls the rate of hallucination, measured in a false discovery rate, on the generated sequence with a probabilistic guarantee.", "description": "This figure provides a high-level overview of the proposed method for selective generation in language models.  It illustrates two example question-answer scenarios, highlighting the difference between using exact match and entailment-based selection functions. The left side shows a case where an exact match is used for evaluation, while the right side uses textual entailment. The key concept is that the model can abstain from answering if it is uncertain about the correctness of its response. This uncertainty is evaluated through textual entailment to ensure a controlled false discovery rate, offering a probabilistic guarantee of accuracy.", "section": "1 Introduction"}, {"figure_path": "glfYOAzh2f/figures/figures_5_1.jpg", "caption": "Figure 2: Decomposition of a false discovery rate with respect to an entailment set Etrue (FDR-E). Here, p := {(x, y, e, v) | G(x) \u2208 E(y)}.", "description": "This figure shows the decomposition of the false discovery rate with respect to the true entailment set (FDR-E).  It breaks down the FDR-E into four components to illustrate the different types of errors that can occur when estimating the entailment set: True Discovery (TD), False Negative Entailment Rate (FNER), False Entailment Rate (FER), and Non-Entailment Rate (NER).  These components are used in the analysis and derivation of the FDR-E bounds for semi-supervised learning. The relationship between the estimated entailment set and the true entailment set illustrates the error rates.", "section": "4.3.1 FDR-E Decomposition"}, {"figure_path": "glfYOAzh2f/figures/figures_9_1.jpg", "caption": "Figure 1: An overview and qualitative results of our proposed method. The key idea is to learn an entailment-aware selective generator with an abstaining option that controls the rate of hallucination, measured in a false discovery rate, on the generated sequence with a probabilistic guarantee.", "description": "This figure provides a high-level overview of the proposed method for selective generation, highlighting its key components and illustrating its qualitative performance. The core idea is to develop a selective generator capable of abstaining from making predictions when uncertain, thereby controlling the rate of hallucination (false discovery rate) in generated text sequences.  The figure displays two examples illustrating different selection functions (exact match and entailment) applied to the language model's generated answer in order to decide whether the answer is correct and should be accepted or incorrect and should be rejected. It shows that the proposed entailment-based approach provides a more robust method for evaluating answer correctness, particularly in handling scenarios with multiple valid answers.", "section": "1 Introduction"}, {"figure_path": "glfYOAzh2f/figures/figures_14_1.jpg", "caption": "Figure 1: An overview and qualitative results of our proposed method. The key idea is to learn an entailment-aware selective generator with an abstaining option that controls the rate of hallucination, measured in a false discovery rate, on the generated sequence with a probabilistic guarantee.", "description": "This figure provides a high-level overview of the proposed method for selective generation, highlighting its key components and illustrating its application with qualitative examples. The core idea is to combine a language model (LLM) with a selection function to filter out unreliable predictions (hallucinations).  The selection function leverages textual entailment, comparing generated answers to known correct answers to determine correctness. This approach ensures a controlled false discovery rate (FDR) on the generated text while offering a probabilistic guarantee on the quality of the remaining predictions.", "section": "1 Introduction"}, {"figure_path": "glfYOAzh2f/figures/figures_25_1.jpg", "caption": "Figure 4: FDR-E box plots of methods for GPT-3.5-turbo. We randomly split the calibration and test set 100 times for box plots. For supervised methods (a), we use all entailment labels, i.e., |ZE| = |Z|. For (b), which includes an unsupervised method (SGenEM) and semi-supervised methods, we use |ZE| = 0.75|Z|. All methods except for SGenSemi use fM\u2081 as a score function. The methods that do not control \u03b5s FDR-E in learning at least once are drawn using red boxes but otherwise using green boxes in Figure 4(a) and Figure 4(b). We draw the whisker plot to indicate 100(1 \u2013 \u03b4)% and 100% quantiles. In both (a) and (b) with green boxes, as the top of the whisker is below of the dotted line, we can see that the FDR-E is well controlled with probability at least \u03b4, i.e., they satisfy the PAC guarantee. The numbers of iterations that satisfy \u03b5s FDR-E in learning while running 100 iterations are (a) SGenEM= 0, SGenSup= 100, SGenSemi-Sup = 100 and (b) SGenSemi = 100, SGenFSemi = 100, SGenem = 18, SGenSemi = 100.", "description": "This figure shows box plots illustrating the False Discovery Rate with respect to textual entailment (FDR-E) for different methods on the GPT-3.5-turbo language model.  The plots compare supervised and semi-supervised approaches, highlighting the effectiveness of the proposed methods in controlling FDR-E and satisfying the Probably Approximately Correct (PAC) guarantee.  Red boxes indicate methods that failed to control FDR-E in at least one of 100 trials.", "section": "5 Experiments"}, {"figure_path": "glfYOAzh2f/figures/figures_25_2.jpg", "caption": "Figure 1: An overview and qualitative results of our proposed method. The key idea is to learn an entailment-aware selective generator with an abstaining option that controls the rate of hallucination, measured in a false discovery rate, on the generated sequence with a probabilistic guarantee.", "description": "This figure provides a visual overview of the proposed method for selective generation, highlighting its key components and illustrating its performance. The main idea is to create a language model that can abstain from generating an answer when uncertain, thus controlling the rate of hallucination (incorrect answers).  The left side shows a method using an exact match selection function while the right shows one using an entailment-based approach.  The graphic demonstrates how the selection functions decide whether to accept or reject the LLM\u2019s output by evaluating its correctness against a true answer. This ensures a controlled false discovery rate, providing a probabilistic guarantee for the correctness of the generated answers.", "section": "1 Introduction"}]