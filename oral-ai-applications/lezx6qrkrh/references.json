{"references": [{"fullname_first_author": "Guanzhi Wang", "paper_title": "Voyager: An open-ended embodied agent with large language models", "publication_date": "2023-05-16", "reason": "This paper introduces Voyager, a sophisticated embodied agent leveraging LLMs for open-ended tasks, providing a strong comparative baseline and context for RL-GPT's approach."}, {"fullname_first_author": "Danny Driess", "paper_title": "Palm-E: An embodied multimodal language model", "publication_date": "2023-03-03", "reason": "Palm-E is a significant contribution demonstrating the capabilities of embodied multimodal LLMs, offering valuable insights into the integration of LLMs and RL in complex environments."}, {"fullname_first_author": "Linxi Fan", "paper_title": "MineDojo: Building open-ended embodied agents with internet-scale knowledge", "publication_date": "2022-12-01", "reason": "MineDojo is the benchmark environment used in this paper, and its introduction is crucial to understanding the experimental setting and contributions of RL-GPT."}, {"fullname_first_author": "Jacky Liang", "paper_title": "Code as policies: Language model programs for embodied control", "publication_date": "2023-05-01", "reason": "This paper introduces the \"Code as Policies\" concept, which is directly related to the approach presented in RL-GPT, making it a highly relevant foundational paper."}, {"fullname_first_author": "Bowen Baker", "paper_title": "Video pretraining (VPT): Learning to act by watching unlabeled online videos", "publication_date": "2022-12-01", "reason": "VPT is a highly influential work showcasing the effectiveness of video pre-training for embodied agents, offering valuable comparative context and setting a precedent for large-scale training methods."}]}