[{"figure_path": "aIPwlkdOut/figures/figures_2_1.jpg", "caption": "Figure 1: (a) depicts the human decision-making process for a binary query x \u2208 X, where the human selects between two arms. The human first spends a fixed non-decision time tnondec encoding the query. Then, the human's evidence accumulates according to a Brownian motion with drift x0*. When the evidence reaches the upper barrier a or lower barrier -a, the human makes a choice, denoted by Cx = 1 or Cx = \u22121, respectively. The random stopping time of the accumulation process is the decision time tx, and the total response time is tRT,x = tnondec + tx. (b) and (c) plot the expected choice E[C#] and the expected decision time E[tx], with shaded regions representing one standard deviation, plotted as functions of the utility difference x\u0f0b0* for two barrier values a.", "description": "This figure illustrates the human decision-making process as a diffusion process and shows how choice and response time depend on the utility difference and the barrier parameter.  Panel (a) shows a graphical representation of the process, illustrating the accumulation of evidence until a decision threshold is reached. Panels (b) and (c) show how the expected choice and response time vary with the utility difference for different barrier values.", "section": "Problem setting and preliminaries"}, {"figure_path": "aIPwlkdOut/figures/figures_5_1.jpg", "caption": "Figure 2: This figure presents the key terms from our theoretical analyses, illustrating the different contributions of choices and decision times for utility estimation. These terms are functions of the utility difference xT\u03b8* and are plotted for two barrier values a. (a) compares the terms E [tx] and a\u00b2V [Cx] in the asymptotic variances for the choice-decision-time estimator (orange, Theorem 3.1) and the choice-only estimator (gray, Theorem 3.2), respectively. This comparison shows that incorporating decision times makes easy queries more informative. Additionally, higher barrier values a lead to more conservative decision-making, increasing informativeness for both choices and decision times. (b) compares the weights in the non-asymptotic concentration bounds (Theorems 3.3 and 3.4), showing similar trends, though these terms may not be optimal due to proof techniques.", "description": "This figure shows the key terms from the theoretical analysis comparing the choice-decision-time estimator and choice-only estimator.  Panel (a) compares the asymptotic variances, highlighting how incorporating response times makes easy queries more informative.  Panel (b) compares the weights in non-asymptotic concentration bounds, showing similar trends.", "section": "3.2 Asymptotic normality of the two estimators"}, {"figure_path": "aIPwlkdOut/figures/figures_8_1.jpg", "caption": "Figure 3: Three heatmaps show the estimation error probabilities, P[arg maxzez z\u00af\u00db \u2260 z*], for the three GSE variations as functions of the arm scaling factor cz and barrier a. Darker colors indicate better estimation performance. In (a) and (b), the choice-only estimator \u03b8ch with both the transductive design (Atrans) and the hard-query design (Ahard) struggles as cz increases (i.e., queries become easier), suggesting that choices from easy queries provide limited information. In contrast, in (c), the choice-decision-time estimator @CH,DT with transductive design (Atrans) consistently achieves better estimation across all cz values, indicating that decision times make easy queries more informative.", "description": "This figure compares the estimation performance of three GSE variations using synthetic data. The x-axis represents the barrier *a*, and the y-axis represents the scaling factor *cz*.  Each heatmap shows the error probability of incorrectly identifying the best arm. The results demonstrate that the choice-decision-time estimator consistently outperforms the choice-only estimator, especially when queries are easy (high *cz*).", "section": "Estimation performance on synthetic data"}, {"figure_path": "aIPwlkdOut/figures/figures_9_1.jpg", "caption": "Figure 4: This figure shows violin plots (with overlaid box plots) for datasets (a), (b), and (c), showing the distribution of best-arm identification error probabilities, P[\u2260 z*], for all bandit instances across six GSE variations and two budgets. The box plots follow the convention of the matplotlib Python package. For each GSE variation and budget, the horizontal line in the middle of the box represents the median of the error probabilities across all bandit instances. Each error probability is averaged over 300 repeated simulations under different random seeds. The box's upper and lower borders represent the third and first quartiles, respectively, with whiskers extending to the farthest points within 1.5\u00d7 the interquartile range. Flier points indicate outliers beyond the whiskers.", "description": "Figure 4 presents the best-arm identification error probability for six GSE variations across three datasets and two budgets. Each plot shows violin and box plots summarizing error probabilities from 300 simulations, with error bars illustrating the range and distribution of results. The variations represent different combinations of experimental design and utility estimator.", "section": "5.2 Fixed-budget best-arm identification performance on real datasets"}, {"figure_path": "aIPwlkdOut/figures/figures_28_1.jpg", "caption": "Figure 5: A violin plot overlaid with a box plot showing the best-arm identification error probability, P[\u02c6z \u2260 z*], as a function of budget for each GSE variation, simulated using the food-risk dataset with choices (-1 or 1) [57], as described in appendix D.1. The box plots follow the convention of the matplotlib Python package. For each GSE variation and budget, the horizontal line in the middle of the box represents the median of the error probabilities across all bandit instances. Each error probability is averaged over 300 repeated simulations under different random seeds. The box\u2019s upper and lower borders represent the third and first quartiles, respectively, with whiskers extending to the farthest points within 1.5\u00d7 the interquartile range. Flier points indicate outliers beyond the whiskers.", "description": "This figure shows the best-arm identification error probability as a function of budget for six different GSE variations using the food-risk dataset.  Violin plots and box plots are used to show the distributions of error probabilities. The results indicate that the choice-decision-time estimator consistently outperforms the choice-only estimators in the task.", "section": "5.2 Fixed-budget best-arm identification performance on real datasets"}, {"figure_path": "aIPwlkdOut/figures/figures_30_1.jpg", "caption": "Figure 3: Three heatmaps show the estimation error probabilities, P[arg maxzez z\u00af\u00db \u2260 z*], for the three GSE variations as functions of the arm scaling factor cz and barrier a. Darker colors indicate better estimation performance. In (a) and (b), the choice-only estimator \u03b8ch with both the transductive design (Atrans) and the hard-query design (hard) struggles as cz increases (i.e., queries become easier), suggesting that choices from easy queries provide limited information. In contrast, in (c), the choice-decision-time estimator @CH,DT with transductive design (Atrans) consistently achieves better estimation across all cz values, indicating that decision times make easy queries more informative.", "description": "This figure compares the performance of three GSE variations in estimating human preferences (\u03b8*) from synthetic data.  The three variations differ in their approach to using response times (choice-decision-time estimator vs. choice-only estimator) and the query selection strategy (transductive vs hard-query design). The heatmaps show the error probability of identifying the best arm as a function of arm scaling factor (cz, representing query easiness) and decision barrier (a, representing human decision making conservativeness).  The figure demonstrates that incorporating response times significantly improves estimation, especially when queries are easy (large cz).", "section": "Estimation performance on synthetic data"}, {"figure_path": "aIPwlkdOut/figures/figures_31_1.jpg", "caption": "Figure 5: A violin plot overlaid with a box plot showing the best-arm identification error probability, P[ \u2260 z*], as a function of budget for each GSE variation, simulated using the food-risk dataset with choices (-1 or 1) [57], as described in appendix D.1. The box plots follow the convention of the matplotlib Python package. For each GSE variation and budget, the horizontal line in the middle of the box represents the median of the error probabilities across all bandit instances. Each error probability is averaged over 300 repeated simulations under different random seeds. The box's upper and lower borders represent the third and first quartiles, respectively, with whiskers extending to the farthest points within 1.5\u00d7 the interquartile range. Flier points indicate outliers beyond the whiskers.", "description": "This figure compares the performance of six different GSE variations on the food-risk dataset using a violin plot. The x-axis shows different budgets, and the y-axis shows the error probability. Each violin plot represents the distribution of error probabilities across multiple simulations for a specific GSE variation. The plot shows that incorporating response time into the estimator consistently outperforms the traditional choice-only estimators across various budgets.", "section": "5.2 Fixed-budget best-arm identification performance on real datasets"}, {"figure_path": "aIPwlkdOut/figures/figures_33_1.jpg", "caption": "Figure 8: Violin plots overlaid with box plots, used for tuning the elimination parameter \u03b7 in algorithm 1 for each GSE variation, simulated based on the snack dataset with choices (-1 or 1) [39], as discussed in appendix D.3. Each plot shows the best-arm identification error probability, P[\u2260 z*], as a function of \u03b7. The box plots follow the convention of the matplotlib Python package. The horizontal line in each box represents the median of the error probabilities across all bandit instances and budgets. Each error probability is averaged over 50 repeated simulations under different random seeds. The top and bottom borders of the box represent the third and first quartiles, respectively, while the whiskers extend to the farthest points within 1.5\u00d7 the interquartile range. Flier points are the outliers past the end of the whiskers.", "description": "This figure shows the result of tuning the elimination parameter (\u03b7) in the GSE algorithm for six different variations.  Each plot represents a different GSE variation and displays the best-arm identification error probability as a function of \u03b7.  Violin plots show the distribution of errors and box plots summarize the central tendencies, offering insights into the effectiveness of the various GSE setups for different \u03b7 values and offering the best choice of \u03b7 for each algorithm. The data is from the snack dataset with choices (-1 or 1) [39].", "section": "5.2 Fixed-budget best-arm identification performance on real datasets"}, {"figure_path": "aIPwlkdOut/figures/figures_34_1.jpg", "caption": "Figure 5: A violin plot overlaid with a box plot showing the best-arm identification error probability, P[\u02c6z \u2260 z*], as a function of budget for each GSE variation, simulated using the food-risk dataset with choices (-1 or 1) [57], as described in appendix D.1. The box plots follow the convention of the matplotlib Python package. For each GSE variation and budget, the horizontal line in the middle of the box represents the median of the error probabilities across all bandit instances. Each error probability is averaged over 300 repeated simulations under different random seeds. The box\u2019s upper and lower borders represent the third and first quartiles, respectively, with whiskers extending to the farthest points within 1.5\u00d7 the interquartile range. Flier points indicate outliers beyond the whiskers.", "description": "Figure 5 shows the best-arm identification error probability across different GSE variations for varying budgets.  The violin plots and overlaid box plots illustrate the distribution of error probabilities across multiple simulations.  It is based on the food-risk dataset and displays the performance of various algorithms at different time budgets for identifying the best arm.", "section": "5.2 Fixed-budget best-arm identification performance on real datasets"}]