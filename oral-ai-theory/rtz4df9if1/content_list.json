[{"type": "text", "text": "Optimal Parallelization of Boosting ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Arthur da Cunha Department of Computer Science Aarhus University dac@cs.au.dk ", "page_idx": 0}, {"type": "text", "text": "Mikael M\u00f8ller H\u00f8gsgaard Department of Computer Science Aarhus University hogsgaard@cs.au.dk ", "page_idx": 0}, {"type": "text", "text": "Kasper Green Larsen Department of Computer Science Aarhus University larsen@cs.au.dk ", "page_idx": 0}, {"type": "text", "text": "Abstract ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Recent works on the parallel complexity of Boosting have established strong lower bounds on the tradeoff between the number of training rounds $p$ and the total parallel work per round $t$ . These works have also presented highly non-trivial parallel algorithms that shed light on different regions of this tradeoff. Despite these advancements, a significant gap persists between the theoretical lower bounds and the performance of these algorithms across much of the tradeoff space. In this work, we essentially close this gap by providing both improved lower bounds on the parallel complexity of weak-to-strong learners, and a parallel Boosting algorithm whose performance matches these bounds across the entire $p$ vs. $t$ compromise spectrum, up to logarithmic factors. Ultimately, this work settles the parallel complexity of Boosting algorithms that are nearly sample-optimal. ", "page_idx": 0}, {"type": "text", "text": "1 Introduction ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Boosting is an extremely powerful and elegant idea that allows one to combine multiple inaccurate classifiers into a highly accurate voting classifier. Algorithms such as AdaBoost [Freund and Schapire, 1997] work by iteratively running a base learning algorithm on reweighted versions of the training data to produce a sequence of classifiers $h_{1},\\ldots,h_{p}$ . After obtaining $h_{i}$ , the weighting of the training data is updated to put larger weights on samples misclassified by $h_{i}$ , and smaller weights on samples classified correctly. This effectively forces the next training iteration to focus on points with which the previous classifiers struggle. After sufficiently many rounds, the classifiers $h_{1},\\ldots,h_{p}$ are finally combined by taking a (weighted) majority vote among their predictions. Many Boosting algorithms have been developed over the years, for example Grove and Schuurmans [1998], R\u00e4tsch et al. [2005], Servedio [2003], Friedman [2001], with modern Gradient Boosting [Friedman, 2001] algorithms like XGBoost [Chen and Guestrin, 2016] and LightGBM [Ke et al., 2017] often achieving state-of-the-art performance on learning tasks while requiring little to no data cleaning. See e.g. the excellent survey by Natekin and Knoll [2013] for more background on Boosting. ", "page_idx": 0}, {"type": "text", "text": "While Boosting enjoys many advantages, it does have one severe drawback, also highlighted in Natekin and Knoll [2013]: Boosting is completely sequential as each of the consecutive training steps requires the output of previous steps to determine the reweighted learning problem. This property is shared by all Boosting algorithms and prohibits the use of computationally heavy training by the base learning algorithm in each iteration. For instance, Gradient Boosting algorithms often require hundreds to thousands of iterations to achieve the best accuracy. The crucial point is that even if you have access to thousands of machines for training, there is no way to parallelize the steps of Boosting and distribute the work among the machines (at least beyond the parallelization possible for the base learner). In effect, the training time of the base learning algorithm is directly multiplied by the number of steps of Boosting. ", "page_idx": 0}, {"type": "text", "text": "", "page_idx": 1}, {"type": "text", "text": "Multiple recent works [Long and Servedio, 2013, Karbasi and Larsen, 2024, Lyu et al., 2024] have studied parallelization of Boosting from a theoretical point of view, aiming for an understanding of the inherent tradeoffs between the number of training rounds $p$ and the total parallel work per round $t$ . These works include both strong lower bounds on the cost of parallelization and highly non-trivial parallel Boosting algorithms with provable guarantees on accuracy. Previous studies however leave a significant gap between the performance of the parallel algorithms and the proven lower bounds. ", "page_idx": 1}, {"type": "text", "text": "The main contribution of this work is to close this gap by both developing a parallel algorithm with a better tradeoff between $p$ and $t$ , as well as proving a stronger lower bound on this tradeoff. To formally state our improved results and compare them to previous works, we first introduce the theoretical framework under which parallel Boosting is studied. ", "page_idx": 1}, {"type": "text", "text": "Weak-to-Strong Learning. Following the previous works Karbasi and Larsen [2024], Lyu et al. [2024], we study parallel Boosting in the theoretical setup of weak-to-strong learning. Weak-tostrong learning was introduced by Kearns [1988], Kearns and Valiant [1994] and has inspired the development of the first Boosting algorithms [Schapire, 1990]. In this framework, we consider binary classification over an input domain $\\mathcal{X}$ with an unknown target concept $c\\colon{\\mathcal{X}}\\ \\rightarrow\\ \\{-1,1\\}$ assigning labels to samples. A $\\gamma$ -weak learner for $c$ is then a learning algorithm $\\mathcal{W}$ that for any distribution $\\mathcal{D}$ over $\\mathcal{X}$ , when given at least some constant $m_{0}$ i.i.d. samples from $\\mathcal{D}$ , produces with constant probability a hypothesis $h$ with $\\mathcal{L}_{\\mathcal{D}}(h)\\leq1/2-\\gamma$ . Here $\\mathcal{L}_{\\mathcal{D}}(h)=\\operatorname*{Pr}_{\\mathbf{x}\\sim\\mathcal{D}}[h(\\mathbf{x})\\neq c(\\mathbf{x})]$ . The goal in weak-to-strong learning is then to boost the accuracy of $\\mathcal{W}$ by invoking it multiple times. Concretely, the aim is to produce a strong learner: A learning algorithm that for any distribution $\\mathcal{D}$ over $\\mathcal{X}$ and any $0<\\delta,\\varepsilon<1$ , when given $m(\\varepsilon,\\delta)$ i.i.d. samples from $\\mathcal{D}$ , produces with probability at least $1-\\delta$ a hypothesis $h\\colon{\\mathcal{X}}\\rightarrow\\{-1,1\\}$ such that $\\underline{{c}}_{\\mathcal{D}}(h)\\bar{\\leq}\\,\\varepsilon$ . We refer to $m(\\varepsilon,\\delta)$ as the sample complexity of the weak-to-strong learner. ", "page_idx": 1}, {"type": "text", "text": "Weak-to-strong learning has been extensively studied over the years, with many proposed algorithms, among which AdaBoost [Freund and Schapire, 1997] is perhaps the most famous. If $\\mathcal{H}$ denotes a hypothesis set such that $\\mathcal{W}$ always produces hypotheses from $\\mathcal{H}$ , and if $d$ denotes the VC-dimension of $\\mathcal{H}$ , then in terms of sample complexity, AdaBoost is known to produce a strong learner with sample complexity $m_{\\mathrm{Ada}}(\\varepsilon,\\delta)$ satisfying ", "page_idx": 1}, {"type": "equation", "text": "$$\nm_{\\mathrm{Ada}}(\\varepsilon,\\delta)=\\mathrm{O}\\left(\\frac{d\\ln(\\frac{d}{\\varepsilon\\gamma})\\ln(\\frac{1}{\\varepsilon\\gamma})}{\\gamma^{2}\\varepsilon}+\\frac{\\ln(1/\\delta)}{\\varepsilon}\\right).\n$$", "text_format": "latex", "page_idx": 1}, {"type": "text", "text": "This can be proved by observing that after $t=\\mathrm{O}(\\gamma^{-2}\\ln m)$ iterations, AdaBoost produces a voting classifier $\\begin{array}{r}{f(x)=\\mathrm{sign}(\\sum_{i=1}^{t}\\alpha_{i}h_{i}(x))}\\end{array}$ with all margins on the training data being $\\Omega(\\gamma)$ . The sample complexity bound then follows by invoking the best known generalization bounds for large margin voting classifiers [Breiman, 1999, Gao and Zhou, 2013]. Here the margin of the voting classifier $f$ on a training sample $(x,c(x))$ is defined as $\\begin{array}{r}{c(x)\\sum_{i=1}^{t}\\alpha_{i}h_{i}(x)/\\sum_{i=1}^{t}\\lvert\\alpha_{i}\\rvert}\\end{array}$ . This sample complexity comes within logarithmic factors of the optimal sample complexity $\\overset{\\cdot\\cdot}{m_{\\mathrm{OPT}}}(\\varepsilon,\\delta)\\,=\\,\\Theta(d/(\\gamma^{2}\\varepsilon)\\,+$ $\\ln(1/\\delta)/\\varepsilon)$ obtained e.g. in Larsen and Ritzert [2022]. ", "page_idx": 1}, {"type": "text", "text": "Parallel Weak-to-Strong Learning. The recent work by Karbasi and Larsen [2024] formalized parallel Boosting in the above weak-to-strong learning setup. Observing that all training happens in the weak learner, they proposed the following definition of parallel Boosting: A weak-to-strong learning algorithm has parallel complexity $(p,t)$ if for $p$ consecutive rounds it queries the weak learner with $t$ distributions. In each round $i$ , if $D_{1}^{i},\\ldots,D_{t}^{i}$ denotes the distributions queried, the weak learner returns $t$ hypotheses $h_{1}^{i},\\ldots,h_{t}^{i}\\in\\mathcal{H}$ such that $\\mathcal{L}_{D_{j}^{i}}(h_{j}^{i})\\leq1/2-\\gamma$ for all $j$ . At the end of the $p$ rounds, the weak-to-strong learner outputs a hypothesis $f\\colon\\mathcal{X}\\rightarrow\\{-1,1\\}$ . The queries made in each round and the final hypothesis $f$ must be computable from the training data as well as all hypotheses $h_{j}^{i}$ seen in previous rounds. The motivation for the above definition is that we could let one machine/thread handle each of the $t$ parallel query distributions in a round. ", "page_idx": 1}, {"type": "text", "text": "Since parallel weak-to-strong learning is trivial if we make no requirements on $\\mathcal{L}_{\\mathcal{D}}(f)$ for the output $f\\colon\\mathcal{X}\\rightarrow\\{-1,1\\}$ (simply output $f(x)=1$ for all $x\\in\\mathscr{X}$ ), we from hereon focus on parallel weakto-strong learners that are near-optimal in terms of the sample complexity and accuracy tradeoff. ", "page_idx": 1}, {"type": "text", "text": "More formally, from the upper bound side, our goal is to obtain a sample complexity matching at least that of AdaBoost, stated in Eq. (1). That is, rewriting the loss $\\varepsilon$ as a function of the number of samples $m$ , we aim for output classifiers $f$ satisfying ", "page_idx": 2}, {"type": "equation", "text": "$$\n\\mathcal{L}_{\\mathcal{D}}(f)=\\mathrm{O}\\bigg(\\frac{d\\ln(m)\\ln(m/d)+\\ln(1/\\delta)}{\\gamma^{2}m}\\bigg).\n$$", "text_format": "latex", "page_idx": 2}, {"type": "text", "text": "When stating lower bounds in the following, we have simplified the expressions by requiring that the expected loss satisfies $\\mathcal{L}_{\\mathcal{D}}(f)=\\mathrm{O}(m^{-0.01})$ . Note that this is far larger than the upper bounds, except for values of $m$ very close to $\\gamma^{-2}d$ . This only makes the lower bounds stronger. We remark that all the lower bounds are more general than this, but focusing on $m^{-0.01}$ in this introduction yields the cleanest bounds. ", "page_idx": 2}, {"type": "text", "text": "With these definitions, classic AdaBoost and other weak-to-strong learners producing voting classifiers with margins $\\Omega(\\gamma)$ all have a parallel complexity of $(\\bar{\\Theta}(\\gamma^{-2}\\ln\\dot{m}),1)$ : They all need $\\gamma^{-2}\\ln m$ rounds to obtain $\\Omega(\\gamma)$ margins. Karbasi and Larsen [2024] presented the first alternative tradeoff by giving an algorithm with parallel complexity $(1,\\exp(\\operatorname{O}(d\\ln(m)/\\gamma^{2})))$ ). Subsequent work by Lyu et al. [2024] gave a general tradeoff between $p$ and $t$ . When requiring near-optimal accuracy, their tradeoff gives, for any $1\\,\\leq\\,R\\,\\leq\\,1/(2\\gamma)$ , a parallel complexity of $(O(\\gamma^{-2}\\ln(m)/R)$ , $\\exp(\\mathrm{O}(d R^{2}))\\ln(\\bar{1/\\gamma}))$ . The accuracy of both of these algorithms was proved by arguing that they produce a voting classifier with all margins $\\Omega(\\gamma)$ . ", "page_idx": 2}, {"type": "text", "text": "On the lower bound side, Karbasi and Larsen [2024] showed that one of three things must hold: Either $p\\ \\geq\\ \\operatorname*{min}\\{\\Omega(\\gamma^{-1}\\ln m),\\exp(\\Omega(d))\\}$ , or $t\\ \\stackrel{!}{\\geq}\\ \\operatorname*{min}\\{\\exp(\\Omega(d\\gamma^{-2})),\\exp(\\exp(\\Omega(d)))\\}$ or $p\\ln(t p)=\\Omega(d\\ln(m)\\gamma^{-2})$ . ", "page_idx": 2}, {"type": "text", "text": "Lyu et al. [2024] also presented a lower bound that for some parameters is stronger than that of Karbasi and Larsen [2024], and for some is weaker. Concretely, they show that one of the following two must hold: Either $p\\geq\\operatorname*{min}\\{\\Omega(\\gamma^{-2}d),\\Omega(\\gamma^{-2}\\ln m),\\exp(\\Omega(d))\\}$ , or $t\\geq\\exp(\\Omega(d))$ . Observe that the constraint on $t$ is only single-exponential in $d$ , whereas the previous lower bound is doubleexponential. On the other hand, the lower bound on $p$ is essentially stronger by a $\\gamma^{-1}$ factor. Finally, they also give an alternative lower bound for $p=\\bar{\\mathrm{O}(\\gamma^{-2})}$ , essentially yielding $p\\ln t=\\Omega(\\gamma^{-2}d)$ . ", "page_idx": 2}, {"type": "text", "text": "Even in light of the previous works, it is still unclear what the true complexity of parallel boosting is. In fact, the upper and lower bounds only match in the single case where $\\dot{p}=\\dot{\\Omega}(\\gamma^{-2}\\ln m)$ and $t=1$ , i.e. when standard AdaBoost is optimal. ", "page_idx": 2}, {"type": "text", "text": "Our Contributions. In this work, we essentially close the gap between the upper and lower bounds for parallel boosting. From the upper bound side, we show the following general result. ", "page_idx": 2}, {"type": "text", "text": "Theorem 1.1. Let $c\\colon\\mathcal{X}\\rightarrow\\{-1,1\\}$ be an unknown concept, $\\mathcal{W}$ be a $\\gamma$ -weak learner for c using a hypothesis set of VC-dimension $d$ , $\\mathcal{D}$ be an arbitrary distribution, and $\\mathbf{S}\\sim\\mathcal{D}^{m}$ be a training set of size m. For all $R\\,\\in\\,\\mathbb{N},$ , Algorithm $^{\\,l}$ yields a weak-to-strong learner $A_{R}$ with parallel complexity $(p,t)$ for ", "page_idx": 2}, {"type": "equation", "text": "$$\np=\\mathrm{O}\\bigg(\\frac{\\ln m}{\\gamma^{2}R}\\bigg)\\qquad a n d\\qquad t=e^{\\mathrm{O}(d R)}\\cdot\\ln\\frac{\\ln m}{\\delta\\gamma^{2}},\n$$", "text_format": "latex", "page_idx": 2}, {"type": "text", "text": "such that, with probability at least $1-\\delta$ over S and the randomness of $A_{R}$ , it holds that ", "page_idx": 2}, {"type": "equation", "text": "$$\n\\mathcal{L}_{\\mathcal{D}}(A_{R}(\\mathbf{S}))=\\mathrm{O}\\bigg(\\frac{d\\ln(m)\\ln(m/d)+\\ln(1/\\delta)}{\\gamma^{2}m}\\bigg).\n$$", "text_format": "latex", "page_idx": 2}, {"type": "text", "text": "Observe that this is a factor $R$ better than the bound by Lyu et al. [2024] in the exponent of $t$ . Furthermore, if we ignore the $\\ln(\\ln(m)/(\\delta\\gamma^{2}))$ factor, it gives the clean tradeoff ", "page_idx": 2}, {"type": "equation", "text": "$$\np\\ln t=\\mathrm{O}\\bigg(\\frac{d\\ln m}{\\gamma^{2}}\\bigg),\n$$", "text_format": "latex", "page_idx": 2}, {"type": "text", "text": "for any $p$ from 1 to ${\\mathrm{O}}(\\gamma^{-2}\\ln m)$ . ", "page_idx": 2}, {"type": "text", "text": "We complement our new upper bound by an essentially matching lower bound. Here we show that ", "page_idx": 2}, {"type": "text", "text": "Theorem 1.2. There is a universal constant $C\\geq1$ for which the following holds. For any $0~<$ $\\gamma<1/C$ , any $d\\geq C$ , any sample size $m\\geq C$ , and any weak-to-strong learner $\\boldsymbol{\\mathcal{A}}$ with parallel complexity $(p,t)$ , there exists an input domain $\\mathcal{X}$ , a distribution $\\mathcal{D}$ , a concept $c\\colon\\mathcal{X}\\rightarrow\\{-1,1\\}$ , and $a\\sim$ -weak learner $\\mathcal{W}$ for c using a hypothesis set $\\mathcal{H}$ of VC-dimension $d$ such that if the expected loss of $\\boldsymbol{\\mathcal{A}}$ over the sample is no more than $m^{-0.01}$ , then either $p\\geq\\operatorname*{min}\\{\\exp(\\Omega(d)),\\Omega(\\gamma^{-2}\\ln m)\\}$ , or $\\bar{t}\\geq\\mathrm{exp}(\\mathrm{exp}(\\Omega(\\bar{d})))$ , or $p\\ln t=\\Omega(\\gamma^{-2}d\\ln m)$ . ", "page_idx": 3}, {"type": "text", "text": "Comparing Theorem 1.2 to known upper bounds, we first observe that $p\\,=\\,\\Omega(\\gamma^{-2}\\ln m)$ corresponds to standard AdaBoost and is thus tight. The term $p\\,=\\,\\exp(\\Omega(d))$ is also near-tight. In particular, given $m$ samples, by Sauer-Shelah, there are only $\\mathrm{O}((m/d)^{d})\\,=\\,\\exp(\\mathrm{O}(d\\ln(m/d)))$ distinct labellings by $\\mathcal{H}$ on the training set. If we run AdaBoost, and in every iteration, we check whether a previously obtained hypothesis has advantage $\\gamma$ under the current weighing, then we make no more than $\\exp(\\dot{\\mathrm{O}}(d\\ln(m/d)))$ queries to the weak learner (since every returned hypothesis must be distinct). The $p\\ln t=\\Omega(\\gamma^{-2}d\\ln m)$ matches our new upper bound in Theorem 1.1. Thus, only the $t\\geq\\exp(\\exp(\\Omega(d)))$ term does not match any known upper bound. ", "page_idx": 3}, {"type": "text", "text": "Other Related Work. Finally, we mention the work by Long and Servedio [2013], which initiated the study of the parallel complexity of Boosting. In their work, they proved that the parallel complexity $(p,t)$ must satisfy $p=\\Omega(\\gamma^{\\dot{-}2}\\ln m)$ , regardless of $t$ (they state it as $p=\\Omega(\\gamma^{-2})$ , but it is not hard to improve by a $\\ln m$ factor for loss $m^{-0.01}$ ). This seems to contradict the upper bounds above. The reason is that their lower bound has restrictions on which query distributions the weak-to-strong learner makes to the weak learner. The upper bounds above thus all circumvent these restrictions. As a second restriction, their lower bound instance has a VC-dimension that grows with $m$ . ", "page_idx": 3}, {"type": "text", "text": "2 Upper Bound ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "In this section, we discuss our proposed method, Algorithm 1. Here, $C_{\\mathrm{n}}$ refers a universal constant shared among results. ", "page_idx": 3}, {"type": "text", "text": "We provide a theoretical analysis of the algorithm, showing that it realizes the claims in Theorem 1.1. Our proof goes via the following intermediate theorem: ", "page_idx": 3}, {"type": "text", "text": "Theorem 2.1. There exists universal constant $C_{\\mathrm{n}}~\\geq~1$ such that for all $0\\,<\\,\\gamma\\,<\\,1/2,\\,R\\,\\in\\,\\mathbb{N},$ , concept $c\\colon\\mathcal{X}\\rightarrow\\{-1,1\\}$ , and hypothesis set $\\mathcal{H}\\subseteq\\{-1,1\\}^{\\mathcal{X}}$ of $V C$ -dimension $d$ , Algorithm $^{\\,l}$ given an input training set $S\\in\\mathcal{X}^{m}$ , $a\\sim$ -weak learner $\\mathcal{W}$ , ", "page_idx": 3}, {"type": "equation", "text": "$$\np\\geq\\frac{4\\ln m}{\\gamma^{2}R},\\qquad a n d\\qquad t\\geq e^{16C_{\\mathrm{n}}d R}\\cdot R\\ln\\frac{p R}{\\delta},\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "produces a linear classifier g at Line 21 such that with probability at least $1\\!-\\!\\delta$ over the randomness of Algorithm 1, $\\mathbf{g}(x)c(x)\\geq\\gamma/8$ for all $x\\in S$ . ", "page_idx": 3}, {"type": "text", "text": "In Theorem 2.1 and throughout the paper, we define a linear classifier $g$ as linear combination of hypotheses $\\begin{array}{r}{g(x)=\\sum_{i=1}^{k}\\alpha_{i}h_{i}(x)}\\end{array}$ with $\\textstyle\\sum_{i}\\left|\\alpha_{i}\\right|=1$ . A linear classifier thus corresponds to a voting classifier with coefficients normalized and no sign operation. Observe that the voting classifier $f(x)\\;=\\;\\mathrm{sign}(g(x))$ is correct if and only if $c(x)\\bar{g}(x)\\,>\\,0$ , where $c(x)$ is the correct label of $x$ . Furthermore, $c({\\dot{x}})g(x)$ is the margin of the voting classifier $f$ on input $x$ . ", "page_idx": 3}, {"type": "text", "text": "Theorem 1.1 follows from Theorem 2.1 via generalization bounds for linear classifiers with large margins. Namely, we apply Breiman\u2019s min-margin bound: ", "page_idx": 3}, {"type": "text", "text": "Theorem 2.2 (Breiman [1999]). Let $c\\colon{\\mathcal{X}}\\,\\rightarrow\\,\\{-1,1\\}$ be an unknown concept, $\\mathcal{H}\\subseteq\\{-1,1\\}^{\\mathcal{X}}$ a hypothesis set of VC-dimension $d$ and $\\mathcal{D}$ an arbitrary distribution over $\\mathcal{X}$ . There is a universal constant $C>0$ such that with probability at least $1-\\delta$ over a set of m samples $\\mathbf{S}\\sim\\mathcal{D}^{m}$ , it holds for every linear classifier $g$ satisfying $c(\\dot{x})g(x)\\geq\\gamma$ for all $(x,c(x))\\in\\mathbf{S}$ that ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\mathcal{L}_{\\mathcal{D}}(\\mathrm{sign}(g))\\leq C\\cdot\\frac{d\\ln(m)\\ln(m/d)+\\ln(1/\\delta)}{\\gamma^{2}m}.\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "Thus far, our general strategy mirrors that of previous works: We seek to show that given suitable parameters Algorithm 1 produces a linear classifier with margins of order $\\gamma$ with good probability. ", "page_idx": 3}, {"type": "text", "text": "Input : Training set ${\\cal S}=\\{(x_{1},c(x_{1})),\\dots,(x_{m},c(x_{m}))\\}$ , $\\gamma$ -weak learner $\\mathcal{W}$ , number of calls to weak learner per round $t$ , number of rounds $p$ 1 $\\begin{array}{r}{\\alpha\\gets\\frac{1}{2}\\ln\\frac{1/2+\\overline{\\gamma}/2}{1/2-\\gamma/2}}\\end{array}$ assifier $f$ 2 n \u2190Cnd/\u03b32 3 $\\begin{array}{r}{D_{1}\\gets(\\frac{1}{m},\\frac{1}{m},\\dots,\\frac{1}{m})}\\end{array}$ 4 for $k\\leftarrow0$ to $p-1$ do 5 parallel for $r\\gets1$ to $R$ do 6 parallel for $j\\leftarrow1$ to $t/R$ do 7 Sample $\\mathbf{T}_{k R+r,j}\\sim D_{k R+1}^{n}$ 8 $\\begin{array}{r l}&{\\underset{\\mathbf{\\theta}}{\\min}_{k R+r,j}\\leftarrow\\mathcal{W}(\\mathbf{T}_{k R+r,j},\\mathrm{Uniform}(\\mathbf{T}_{k R+r,j}))}\\\\ &{\\mathbf{\\theta}_{k R+r}\\leftarrow\\{\\mathbf{h}_{k R+r,1},\\dots,\\mathbf{h}_{k R+r,t/R}\\}\\cup\\{-\\mathbf{h}_{k R+r,1},\\dots,-\\mathbf{h}_{k R+r,t/R}\\}}\\end{array}$ 9 10 for $r\\gets1$ to $R$ do 11 if there exists $\\mathbf{h}^{*}\\in\\mathcal{H}_{k R+r}$ s.t. $\\mathcal{L}_{D_{k R+r}}(\\mathbf{h}^{*})\\leq1/2-\\gamma/2$ then 12 $\\begin{array}{l}{\\mathbf{h}_{k R+r}\\leftarrow\\mathbf{h}^{*}}\\\\ {\\alpha_{k R+r}\\leftarrow\\alpha}\\end{array}$ 13 14 else 15 $h_{k R+r}\\leftarrow$ arbitrary hypothesis from $\\mathcal{H}_{k R+r}$ 16 $\\alpha_{k R+r}\\gets0$ 17 for $i\\gets1$ to $m$ do 18 $\\begin{array}{r l}{\\mid}&{{}D_{k R+r+1}(i)\\leftarrow D_{k R+r}(i)\\exp(-\\alpha_{k R+r}c(x_{i})\\mathbf{h}_{k R+r}(x_{i}))}\\end{array}$ 19 ZkR+r \u2190 im=1 DkR+r(i) exp(\u2212\u03b1kR+rc(xi)hkR+r(xi)) 20 $D_{k R+r+1}\\leftarrow D_{k R+r+1}/\\mathbf{Z}_{k R+r}$ 21 $\\begin{array}{r}{\\mathbf{g}\\leftarrow x\\mapsto\\frac{1}{\\sum_{j=1}^{p R}\\alpha_{j}}\\sum_{j=1}^{p R}\\alpha_{j}\\mathbf{h}_{j}(x)}\\end{array}$ 22 return f : $x\\mapsto\\operatorname{sign}(\\mathbf{g}(x))$ ", "page_idx": 4}, {"type": "text", "text": "Therefore, this section focuses on the lemmas that describe how, with suitable parameters, Algorithm 1 produces a classifier with large margins. With these results in hand, the proof of Theorem 2.1 becomes quite straightforward, so we defer it to Appendix B.3. ", "page_idx": 4}, {"type": "text", "text": "Algorithm 1 is a variant of Lyu et al. [2024, Algorithm 2]. The core idea is to use bagging to produce (in parallel) a set of hypotheses and use it to simulate a weak learner. To be more precise, we reason in terms of the following definition. ", "page_idx": 4}, {"type": "text", "text": "Definition 1 ( $\\dot{\\varepsilon}$ -approximation). Given a concept $c\\colon\\mathcal{X}\\rightarrow\\{-1,1\\}$ , a hypothesis set $\\mathcal{H}\\subseteq\\{-1,1\\}^{\\mathcal{X}}$ , and a distribution $\\mathcal{D}$ over $\\mathcal{X}$ , a multiset $T$ is an $\\varepsilon$ -approximation for $\\mathcal{D},c$ , and $\\mathcal{H}$ if for all $h\\in\\mathcal H$ , it holds that ", "page_idx": 4}, {"type": "equation", "text": "$$\n|{\\mathcal{L}}_{\\mathcal{D}}(h)-{\\mathcal{L}}_{T}(h)|\\leq\\varepsilon,\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "where $\\mathcal{L}_{T}(h):=\\mathcal{L}_{\\mathrm{Uniform}(T)}(h)$ is the empirical loss of $h$ on $T$ . Moreover, we omit the reference to $c$ and $\\mathcal{H}$ when no confusion seems possible. ", "page_idx": 4}, {"type": "text", "text": "Consider a reference distribution $D_{0}$ over a training dataset $S$ . The bagging part of the method leverages the fact that if a subsample $\\mathbf{T}\\,\\sim\\,D_{0}^{n}$ is a $\\gamma/2$ -approximation for $D_{0}$ , then inputting $\\mathbf{T}$ (with the uniform distribution over it) to a $\\gamma.$ -weak learner produces a hypothesis $h$ that, besides having advantage $\\gamma$ on $\\mathbf{T}$ , also has advantage $\\gamma/2$ on the entire dataset $S$ (relative to $D_{0}$ ). Indeed, in this setting, we have that $\\mathcal{L}_{D_{0}}(h)\\leq\\mathcal{L}_{\\mathbf{T}}(h)\\overset{}{+}\\gamma/2\\leq1/2\\!-\\!\\gamma\\!+\\!\\gamma/2=1/2\\!-\\!\\gamma/2$ . We can then take $h$ as if produced by a $\\gamma/2$ -weak learner queried with $(S,D_{0})$ , and compute a new distribution $D_{1}$ via a standard Boosting step1. That is, we can simulate a $\\gamma/2$ -weak learner as long as we can provide a $\\gamma/2$ -approximation for the target distribution. The strategy is to have a parallel bagging step in which we sample $\\mathbf{T}_{1},\\mathbf{T}_{2},\\ldots,\\mathbf{T}_{t}\\overset{\\mathrm{iid}}{\\sim}D_{0}^{n}$ and query the $\\gamma.$ -weak learner on each $\\mathbf{T}_{j}$ to obtain hypotheses $\\mathbf{h}_{1},\\ldots,\\mathbf{h}_{t}$ . Then, we search within these hypotheses to sequentially perform $R$ Boosting steps, obtaining distributions $D_{1},D_{2},\\ldots,D_{R}$ . As argued, this approach will succeed whenever we can find at least one $\\gamma/2$ -approximation for each $D_{r}$ among $\\mathbf h_{1},\\mathbf h_{2},\\ldots,\\mathbf h_{t}$ . A single parallel round of querying the weak learner is thus sufficient for performing $R$ steps of Boosting, effectively reducing $p$ by a factor $R$ . Crucially, testing the performance of the returned hypotheses $\\mathbf{h}_{1},\\ldots,\\mathbf{h}_{t}$ uses only inference/predictions and no calls to the weak learner. ", "page_idx": 4}, {"type": "text", "text": "", "page_idx": 5}, {"type": "text", "text": "The challenge is that the distributions $D_{r}$ diverge (exponentially fast) from $D_{0}$ as we progress in the Boosting steps. For the first Boosting step, the following classic result ensures a good probability of obtaining an approximation for $D_{0}$ when sampling from $D_{0}$ itself. ", "page_idx": 5}, {"type": "text", "text": "Theorem 2.3 (Li et al. [2001], Talagrand [1994], Vapnik and Chervonenkis [1971]). There is $a$ universal constant $C\\,>\\,0$ such that for any $0\\,<\\,\\varepsilon,\\delta\\,<\\,1_{\\!}$ , $\\mathcal{H}\\subseteq\\{-1,1\\}^{\\mathcal{X}}$ of VC-dimension $d,$ , and distribution $\\mathcal{D}$ over $\\mathcal{X}$ , it holds with probability at least $1-\\delta$ over a set $\\mathbf{T}\\sim\\mathcal{D}^{n}$ that $\\mathbf{T}$ is an $\\varepsilon$ -approximation for $\\mathcal{D},\\,c,$ , and $\\mathcal{H}$ provided that $n\\geq C((d+\\ln(1/\\delta))/\\varepsilon^{2})$ . ", "page_idx": 5}, {"type": "text", "text": "However, we are interested in approximations for $D_{r}$ when we only have access to samples from $D_{0}$ . Lyu et al. [2024] approaches this problem by tracking the \u201cdistance\u201d between the distributions in terms of their max-divergence ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\mathrm{D}_{\\infty}(D_{r},D_{0}):=\\ln\\bigl(\\operatorname*{sup}_{x\\in\\mathcal{X}}D_{r}(x)/D_{0}(x)\\bigr).\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "By bounding both $\\mathrm{D}_{\\infty}(D_{r},D_{0})$ and $\\mathrm{D}_{\\infty}(D_{0},D_{r})$ , the authors can leverage the advanced composition theorem [Dwork et al., $2010]^{2}$ from the differential privacy literature to bound the probability of obtaining an approximation for $D_{r}$ when sampling from $D_{0}$ . In turn, this allows them to relate the number of samples $t$ and the (sufficiently small) number of Boosting steps $R$ in a way that ensures a good probability of success at each step. ", "page_idx": 5}, {"type": "text", "text": "Besides setting up the application of advanced composition, the use of the max-divergence also simplifies the analysis since its \u201clocality\u201d allows one to bound the divergence between the two distributions via a worst-case study of a single entry. However, this approach sacrifices global information, limiting how much we can leverage our understanding of the distributions generated by Boosting algorithms. With that in mind, we instead track the distance between $D_{r}$ and $D_{0}$ in terms of the Kullback-Leibler divergence (KL divergence) [Kullback and Leibler, 1951] between them: ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\mathrm{KL}(D_{r}\\parallel D_{0}):=\\sum_{x\\in\\mathcal{X}}D_{r}(x)\\ln\\frac{D_{r}(x)}{D_{0}(x)}.\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "Comparing this expression to Eq. (2) reveals that the max-divergence is indeed a worst-case estimation of the KL divergence. ", "page_idx": 5}, {"type": "text", "text": "The KL divergence \u2014also known as relative entropy\u2014 between two distributions $P$ and $Q$ is always non-negative and equal to zero if and only if $P=Q$ . Moreover, in our setting, it is always finite due to the following remark.3 ", "page_idx": 5}, {"type": "text", "text": "Remark 1. In the execution Algorithm 1, every distribution $D_{\\ell}$ , for $\\ell\\in[p R]$ , has the same support.   \nThis must be the case since Line 20 always preserves the support of $D_{1}$ . ", "page_idx": 5}, {"type": "text", "text": "On the other hand, the KL divergence is not a proper metric as it is not symmetric and it does not satisfy the triangle inequality, unlike the max-divergence. This introduces a number of difficulties in bounding the divergence between $\\mathcal{D}_{0}$ and $\\mathcal{D}_{r}$ . Overcoming these challenges requires a deeper and highly novel analysis. Our results reveal that the KL divergence captures particularly well the behavior of our Boosting algorithm. We remark that we are not the first to relate KL divergence and Boosting, see e.g. Schapire and Freund [2012, Chapter 8 and the references therein], yet we make several new contributions to this connection. ", "page_idx": 5}, {"type": "text", "text": "To study the probability of obtaining a $\\gamma/2$ -approximation for $D_{r}$ when sampling from $D_{0}$ , rather than using advanced composition, we employ the duality formula for variational inference [Donsker and Varadhan, 1975] \u2014also known as Gibbs variational principle, or Donsker-Varadhan formula\u2014 to estimate such a probability in terms of ${\\mathrm{KL}}(D_{r}\\parallel D_{0})$ . ", "page_idx": 5}, {"type": "text", "text": "Lemma 2.4 (Duality formula4). Given finite probability spaces $(\\Omega,{\\mathcal{F}},P)$ and $\\textstyle(\\Omega,{\\mathcal{F}},Q)$ , if $P$ and $Q$ have the same support, then for any real-valued random variable $\\mathbf{X}$ on $(\\Omega,{\\mathcal{F}},P)$ we have that ", "page_idx": 6}, {"type": "equation", "text": "$$\n\\ln\\mathbb{E}_{P}\\big[e^{\\mathbf{X}}\\big]\\geq\\mathbb{E}_{Q}[\\mathbf{X}]-\\mathrm{KL}(Q\\parallel P).\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "Lemma 2.4 allows us to prove that if ${\\mathrm{KL}}(D_{r}\\parallel D_{0})$ is sufficiently small, then the probability of obtaining a $\\gamma/2$ -approximation for $D_{r}$ when sampling from $D_{0}$ is sufficiently large. Namely, we prove the following. ", "page_idx": 6}, {"type": "text", "text": "Lemma 2.5. There exists universal constant $C_{\\mathrm{n}}\\geq1$ for which the following holds. Given $0<\\gamma<$ $1/2,\\,R,m\\in\\mathbb{N}$ , concept $c\\colon{\\mathcal{X}}\\rightarrow\\{-1,1\\}.$ , and hypothesis set $\\mathcal{H}\\subseteq\\{-1,1\\}^{\\mathcal{X}}$ of $V C$ -dimension $d_{\\cdot}$ , let $\\tilde{D}$ and $D$ be distributions over $[m]$ and $\\mathcal{G}\\in[m]^{*}$ be the family of $\\gamma/2$ -approximations for $D,\\,c,$ and $\\mathcal{H}$ . If $\\tilde{D}$ and $D$ have the same support and ", "page_idx": 6}, {"type": "equation", "text": "$$\n\\mathrm{KL}(D\\parallel\\tilde{D})\\leq4\\gamma^{2}R,\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "then for all $n\\geq C_{\\mathrm{n}}\\cdot d/\\gamma^{2}$ it holds that ", "page_idx": 6}, {"type": "equation", "text": "$$\n\\operatorname*{Pr}_{\\mathbf{T}\\sim\\tilde{D}^{n}}[\\mathbf{T}\\in\\mathcal{G}]\\ge\\exp(-16C_{\\mathrm{n}}d R).\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "Proof sketch. Our argument resembles a proof of the Chernoff bound: After taking exponentials on both sides of Eq. (3), we exploit the generality of Lemma 2.4 by defining the random variable $\\mathbf{X}\\colon T\\mapsto\\lambda\\mathbf{1}_{\\{T\\in\\mathcal{G}\\}}$ and later carefully choosing $\\lambda$ . We then note that Theorem 2.3 ensures that $\\mathbf{X}$ has high expectation for $\\mathbf{T}\\sim D^{n}$ . Setting $\\lambda$ to leverage this fact, we obtain a lower bound on the expectation of $\\mathbf{X}$ relative to $\\mathbf{T}\\sim\\tilde{D}^{n}$ , yielding the thesis. \u53e3 ", "page_idx": 6}, {"type": "text", "text": "We defer the detailed proof to Appendix B.1. ", "page_idx": 6}, {"type": "text", "text": "With Lemma 2.5 in hand, recall that our general goal is to show that, with high probability, the linear classifier $g$ produced by Algorithm 1 satisfies that $c(x)g(x)=\\Omega(\\gamma)$ for all $x\\in S$ . Standard techniques allow us to further reduce this goal to that of showing that the product of the normalization factors, $\\prod_{\\ell=1}^{p R}Z_{\\ell}$ , is sufficiently small. Accordingly, in our next lemma, we bound the number of samples needed in the bagging step to obtain a small product of the normalization factors produced by the Boosting steps. ", "page_idx": 6}, {"type": "text", "text": "Here, the analysis in terms of the KL divergence delivers a clear insight into the problem, revealing an interesting trichotomy: if $\\mathrm{KL}(D_{r}\\parallel D_{0})$ is small, Lemma 2.5 yields the result; on the other hand, if $D_{r}$ has diverged too far from $D_{0}$ , then either the algorithm has already made enough progress for us to skip a step, or the negation of some hypothesis used in a previous step has sufficient advantage relative to the distribution at hand. Formally, we prove the following. ", "page_idx": 6}, {"type": "text", "text": "Lemma 2.6. There exists universal constant $C_{\\mathrm{n}}\\geq1$ such that for all $R\\,\\in\\,\\mathbb{N}$ , $0\\,<\\,\\delta\\,<\\,1$ , $0~<$ $\\gamma<1/2$ , and $\\gamma$ -weak learner $\\mathcal{W}$ using a hypothesis set $\\mathcal{H}\\subseteq\\{-1,1\\}^{\\chi}$ with VC-dimension d, if $t\\ge$ $R\\cdot\\exp(16C_{\\mathrm{n}}d R)\\cdot\\ln(R/\\delta)$ , then with probability at least $1-\\delta$ the hypotheses $\\mathbf{h}_{k R+1},\\ldots,\\mathbf{h}_{k R+R}$ obtained by Algorithm $^{\\,l}$ induce normalization factors $\\mathbf{Z}_{k R+1},\\ldots,\\mathbf{Z}_{k R+R}$ such that ", "page_idx": 6}, {"type": "equation", "text": "$$\n\\prod_{r=1}^{R}{\\bf Z}_{k R+r}<\\exp(-\\gamma^{2}R/2).\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "Proof sketch. We assume for simplicity that $k\\,=\\,0$ and argue by induction on $R^{\\prime}\\,\\in\\,[R]$ . After handling the somewhat intricate stochastic relationships of the problem, we leverage the simple ", "page_idx": 6}, {"type": "text", "text": "remark that $\\mathrm{KL}(D_{R^{\\prime}}\\parallel D_{R^{\\prime}})=0$ to reveal the following telescopic decomposition: ", "page_idx": 7}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathrm{KL}(D_{R^{\\prime}}\\parallel D_{1})=\\mathrm{KL}(D_{R^{\\prime}}\\parallel D_{1})-\\mathrm{KL}(D_{R^{\\prime}}\\parallel D_{R^{\\prime}})}\\\\ &{\\quad\\quad\\quad\\quad=\\mathrm{KL}(D_{R^{\\prime}}\\parallel D_{1})-\\mathrm{KL}(D_{R^{\\prime}}\\parallel D_{2})}\\\\ &{\\quad\\quad\\quad\\quad\\quad\\quad+\\mathrm{KL}(D_{R^{\\prime}}\\parallel D_{2})-\\mathrm{KL}(D_{R^{\\prime}}\\parallel D_{3})}\\\\ &{\\quad\\quad\\quad\\quad\\quad\\quad\\quad+\\dots}\\\\ &{\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad+\\mathrm{KL}(D_{R^{\\prime}}\\parallel D_{R^{\\prime}-1})-\\mathrm{KL}(D_{R^{\\prime}}\\parallel D_{R^{\\prime}})}\\\\ &{\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad=\\displaystyle\\sum_{r=1}^{R^{\\prime}-1}\\mathrm{KL}(D_{R^{\\prime}}\\parallel D_{r})-\\mathrm{KL}(D_{R^{\\prime}}\\parallel D_{r+1}).}\\end{array}\n$$", "text_format": "latex", "page_idx": 7}, {"type": "text", "text": "Moreover, given $r\\in\\{1,\\ldots,R^{\\prime}-1\\}$ , ", "page_idx": 7}, {"type": "equation", "text": "$$\n\\begin{array}{l}{\\mathrm{KL}(D_{R^{\\prime}}\\parallel D_{r})-\\mathrm{KL}(D_{R^{\\prime}}\\parallel D_{r+1})=\\displaystyle\\sum_{i=1}^{m}D_{R^{\\prime}}(i)\\ln\\frac{D_{R^{\\prime}}(i)}{D_{r}(i)}-\\displaystyle\\sum_{i=1}^{m}D_{R^{\\prime}}(i)\\ln\\frac{D_{R^{\\prime}}(i)}{D_{r+1}(i)}}\\\\ {\\displaystyle=\\sum_{i=1}^{m}D_{R^{\\prime}}(i)\\ln\\frac{D_{r+1}(i)}{D_{r}(i)}}\\\\ {\\displaystyle=-\\ln\\mathbf{Z}_{r}-\\displaystyle\\sum_{i=1}^{m}D_{R^{\\prime}}(i)\\alpha_{r}c(x_{i})\\mathbf{h}_{r}(x_{i}).}\\end{array}\n$$", "text_format": "latex", "page_idx": 7}, {"type": "text", "text": "Altogether, we obtain that ", "page_idx": 7}, {"type": "equation", "text": "$$\n\\mathrm{KL}(D_{R^{\\prime}}\\parallel D_{1})=-\\ln\\prod_{r=1}^{R^{\\prime}-1}{\\mathbf Z}_{r}+\\sum_{r=1}^{R^{\\prime}-1}\\alpha_{r}\\sum_{i=1}^{m}D_{R^{\\prime}}(i)c(x_{i})(-{\\mathbf h}_{r}(x_{i})).\n$$", "text_format": "latex", "page_idx": 7}, {"type": "text", "text": "Now, if $\\mathrm{KL}(D_{R^{\\prime}}\\parallel D_{1})$ is small (at most $4\\gamma^{2}R)$ ), Lemma 2.5 ensures that with sufficient probability there exists a $\\gamma/2$ -approximation for $D_{R^{\\prime}}$ within $\\mathbf{T}_{R^{\\prime},1},\\dotsc\\dotsc,\\mathbf{T}_{R^{\\prime},t/R}$ , yielding the induction step (by Claim 1). Otherwise, if $\\mathrm{KL}(D_{R^{\\prime}}\\parallel D_{1})$ is large, then either $(i)$ the term $-\\ln\\prod_{r=1}^{R^{\\prime}-1}\\mathbf Z_{r}$ is large enough for us to conclude that $\\prod_{r=1}^{R^{\\prime}-1}\\mathbf{Z}_{r}$ is already less than $\\exp(-\\gamma^{2}R^{\\prime}/2)$ and we can skip the step; or (ii) the term rR=\u221211 \u03b1 $\\begin{array}{r}{\\sum_{r=1}^{R^{\\prime}-1}\\alpha_{r}\\sum_{i=1}^{m}D_{R^{\\prime}}(i)c(x_{i})(-\\mathbf{h}_{r}(x_{i}))}\\end{array}$ is sufficiently large to imply the existence of $\\mathbf{h}^{*}\\in\\{-\\mathbf{h}_{1},\\overline{{\\ldots}};\\bar{-}\\mathbf{h}_{R^{\\prime}-1}\\overline{{\\ldots}}\\}$ satisfying that ", "page_idx": 7}, {"type": "equation", "text": "$$\n\\sum_{i=1}^{m}D_{R^{\\prime}}(i)c(x_{i}){\\bf h^{*}}(x_{i})>\\gamma,\n$$", "text_format": "latex", "page_idx": 7}, {"type": "text", "text": "which implies that such $\\mathbf{h}^{*}$ has margin at least $\\gamma$ with respect to $D_{R^{\\prime}}$ and we can conclude the induction step as before. \u53e3 ", "page_idx": 7}, {"type": "text", "text": "We defer the detailed proof to Appendix B.2. ", "page_idx": 7}, {"type": "text", "text": "3 Overview of the Lower Bound ", "text_level": 1, "page_idx": 7}, {"type": "text", "text": "In this section, we overview of the main ideas behind our improved lower bound. The details are available in Appendix C. Our lower bound proof is inspired by, and builds upon, that of Lyu et al. [2024]. Let us first give the high level idea in their proof. Similarly to Karbasi and Larsen [2024], they consider an input domain $\\mathcal{X}=[2m]$ , where $m$ denotes the number if training samples available for a weak-to-strong learner $\\boldsymbol{\\mathcal{A}}$ with parallel complexity $(p,t)$ . In their construction, they consider a uniform random concept $\\mathbf{c}\\colon{\\mathcal{X}}\\to\\{-1,1\\}$ and give a randomized construction of a weak learner. Proving a lower bound on the expected error of $\\boldsymbol{\\mathcal{A}}$ under this random choice of concept and weak learner implies, by averaging, the existence of a deterministic choice of concept and weak learner for which $\\boldsymbol{\\mathcal{A}}$ has at least the same error. ", "page_idx": 7}, {"type": "text", "text": "The weak learner is constructed by drawing a random hypothesis set $\\varkappa$ , using inspiration from the so-called coin problem. In the coin problem, we observe $p$ independent outcomes of a biased coin and the goal is to determine the direction of the bias. If a coin has a bias of $\\beta$ , then upon seeing $n$ outcomes of the coin, any algorithm for guessing the bias of the coin is wrong with probability at least $\\exp\\!\\left(-\\,\\mathrm{O}(\\beta^{2}n)\\right)$ . Now to connect this to parallel Boosting, Lyu et al. construct $\\varkappa$ by adding c as well as $p$ random hypotheses $\\mathbf{h}_{1},\\ldots,\\mathbf{h}_{p}$ to $\\varkappa$ . Each hypothesis $\\mathbf{h}_{i}$ has each ${\\bf h}_{i}(x)$ chosen independently with $\\mathbf{h}_{i}(x)=\\mathbf{c}(x)$ with probability $1/2+2\\gamma$ . The weak learner $\\mathcal{W}$ now processes a query distribution $D$ by returning the first hypothesis $\\mathbf{h}_{i}$ with advantage $\\gamma$ under $D$ . If no such hypothesis exists, it instead returns $\\mathbf{c}$ . The key observation is that if $\\mathcal{W}$ is never forced to return c, then the only information $\\boldsymbol{\\mathcal{A}}$ has about $\\mathbf{c}(x)$ for each $x$ not in the training data (which is at least half of all $x$ , since $|{\\mathcal{X}}|=2m)$ ), is the outcomes of up to $p$ coin tosses that are $2\\gamma$ biased towards $\\mathbf{c}(x)$ . Thus, the expected error becomes $\\exp(-\\,\\mathrm{O}(\\gamma^{2}p\\dot{)})$ . For this to be smaller than $m^{-0.01}$ then requires $p=\\Omega(\\gamma^{-2}\\ln m)$ as claimed in their lower bound. ", "page_idx": 7}, {"type": "text", "text": "", "page_idx": 8}, {"type": "text", "text": "The last step of their proof, is then to argue that $\\mathcal{W}$ rarely has to return c upon a query. The idea here is to show that in the $i$ th parallel round, $\\mathcal{W}$ can use $\\mathbf{h}_{i}$ to answer all queries, provided that $t$ is small enough. This is done by observing that for any query distribution $D$ that is independent of $\\mathbf{h}_{i}$ , the expected loss satisfies $\\ddot{\\mathbb{E}}_{{\\bf h}_{i}}[{\\mathcal{L}}_{D}({\\bf h}_{i}\\mathbf{\\bar{)}}]\\,=\\,1/2-\\,\\dot{2}\\gamma$ due to the bias. Using inspiration from [Karbasi and Larsen, 2024], they then show that for sufficiently \"well-spread\" queries $D$ , the loss of $\\mathbf{h}_{i}$ under $D$ is extremely well concentrated around its expectation (over the random choice of $\\mathbf{h}_{i}$ ) and thus $\\mathbf{h}_{i}$ may simultaneously answer all (up to) $t$ well-spread queries in round $i$ . To handle \"concentrated\" queries, i.e. query distribution with most of the weight on a few $x$ , they also use ideas from [Karbasi and Larsen, 2024] to argue that if we add $2^{\\mathrm{O}(d)}$ uniform random hypotheses to $\\varkappa$ , then these may be used to answer all concentrated queries. ", "page_idx": 8}, {"type": "text", "text": "Note that the proof crucially uses that $\\mathbf{h}_{i}$ is independent of the queries in the ith round. Here the key idea is that if $\\mathcal{W}$ can answer all the queries in round $i$ using $\\mathbf{h}_{i}$ , then $\\mathbf h_{i+1},\\ldots,\\mathbf h_{p}$ are independent of any queries the weak-to-strong learner makes in round $i+1$ . ", "page_idx": 8}, {"type": "text", "text": "In our improved lower bound, we observe that the expected error of $\\exp(-\\,\\mathrm{O}(\\gamma^{2}p))$ is much larger than $m^{-0.01}$ for small $p$ . That is, the previous proof is in some sense showing something much too strong when trying to understand the tradeoff between $p$ and $t$ . What this gives us, is that we can afford to make the coins/hypotheses $\\mathbf{h}_{i}$ much more biased towards $\\mathbf{c}$ when $p$ is small. Concretely, we can let the bias be as large as $\\beta=\\Theta(\\sqrt{\\ln(m)/p})$ , which may be much larger than $2\\gamma$ . This in turns gives us that it is significantly more likely that $\\mathbf{h}_{i}$ may answer an independently chosen query distribution $D$ . In this way, the same $\\mathbf{h}_{i}$ may answer a much larger number of queries $t$ , resulting in a tight tradeoff between the parameters. As a second contribution, we also find a better way of analyzing this lower bound instance, improving one term in the lower bound on $t$ from $\\exp(\\Omega(d))$ to $\\exp(\\exp(d))$ . We refer the reader to the full proof for details. ", "page_idx": 8}, {"type": "text", "text": "4 Conclusion ", "text_level": 1, "page_idx": 8}, {"type": "text", "text": "In this paper, we have addressed the parallelization of Boosting algorithms. By establishing both improved lower bounds and an essentially optimal algorithm, we have effectively closed the gap between theoretical lower bounds and performance guarantees across the entire tradeoff spectrum between the number of training rounds and the parallel work per round. ", "page_idx": 8}, {"type": "text", "text": "Given that, we believe future work may focus on better understanding the applicability of the theoretical tools developed here to other settings since some lemmas obtained seem quite general. They may aid, for example, in investigating to which extent the post-processing of hypotheses obtained in the bagging step can improve the complexity of parallel Boosting algorithms, which remains as an interesting research direction. ", "page_idx": 8}, {"type": "text", "text": "Acknowledgments and Disclosure of Funding ", "text_level": 1, "page_idx": 8}, {"type": "text", "text": "This research is co-funded by the European Union (ERC, TUCLA, 101125203) and Independent Research Fund Denmark (DFF) Sapere Aude Research Leader Grant No. 9064-00068B. Views and opinions expressed are however those of the author(s) only and do not necessarily reflect those of the European Union or the European Research Council. Neither the European Union nor the granting authority can be held responsible for them. ", "page_idx": 8}, {"type": "text", "text": "References ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "Yoav Freund and Robert E Schapire. A decision-theoretic generalization of on-line learning and an application to boosting. Journal of computer and system sciences, 55(1):119\u2013139, 1997.   \nAdam J Grove and Dale Schuurmans. Boosting in the limit: Maximizing the margin of learned ensembles. In AAAI/IAAI, pages 692\u2013699, 1998.   \nGunnar R\u00e4tsch, Manfred K Warmuth, and John Shawe-Taylor. Efficient margin maximizing with boosting. Journal of Machine Learning Research, 6(12), 2005.   \nRocco A. Servedio. Smooth boosting and learning with malicious noise. J. Mach. Learn. Res., 4 (null):633\u2013648, dec 2003. ISSN 1532-4435. doi: 10.1162/153244304773936072. URL https: //doi.org/10.1162/153244304773936072.   \nJerome H. Friedman. Greedy function approximation: A gradient boosting machine. The Annals of Statistics, 29(5):1189 \u2013 1232, 2001.   \nTianqi Chen and Carlos Guestrin. Xgboost: A scalable tree boosting system. In KDD, pages 785\u2013 794. ACM, 2016. ISBN 978-1-4503-4232-2.   \nGuolin Ke, Qi Meng, Thomas Finley, Taifeng Wang, Wei Chen, Weidong Ma, Qiwei Ye, and TieYan Liu. Lightgbm: A highly efficient gradient boosting decision tree. In NIPS, 2017.   \nAlexey Natekin and Alois Knoll. Gradient boosting machines, a tutorial. Frontiers in Neurorobotics, 7, 2013. ISSN 1662-5218.   \nPhilip M. Long and Rocco A. Servedio. Algorithms and hardness results for parallel large margin learning. J. Mach. Learn. Res., 14(1):3105\u20133128, jan 2013. ISSN 1532-4435.   \nAmin Karbasi and Kasper Green Larsen. The impossibility of parallelizing boosting. In Claire Vernade and Daniel Hsu, editors, Proceedings of The 35th International Conference on Algorithmic Learning Theory, volume 237 of Proceedings of Machine Learning Research, pages 635\u2013653. PMLR, 25\u201328 Feb 2024. URL https://proceedings.mlr.press/v237/karbasi24a.html.   \nXin Lyu, Hongxun Wu, and Junzhao Yang. The cost of parallelizing boosting. In David P. Woodruff, editor, Proceedings of the 2024 ACM-SIAM Symposium on Discrete Algorithms, SODA 2024, Alexandria, VA, USA, January 7-10, 2024, pages 3140\u20133155. SIAM, 2024. doi: 10.1137/1. 9781611977912.112. URL https://doi.org/10.1137/1.9781611977912.112.   \nMichael Kearns. Learning boolean formulae or finite automata is as hard as factoring. Technical Report TR-14-88 Harvard University Aikem Computation Laboratory, 1988.   \nMichael Kearns and Leslie Valiant. Cryptographic limitations on learning boolean formulae and finite automata. Journal of the ACM (JACM), 41(1):67\u201395, 1994.   \nRobert E Schapire. The strength of weak learnability. Machine learning, 5(2):197\u2013227, 1990.   \nLeo Breiman. Prediction games and arcing algorithms. Neural Computation, 11(7):1493\u2013 1517, 1999. doi: 10.1162/089976699300016106. URL https://doi.org/10.1162/ 089976699300016106.   \nWei Gao and Zhi-Hua Zhou. On the doubt about margin explanation of boosting. Artif. Intell., 203: 1\u201318, 2013.   \nKasper Green Larsen and Martin Ritzert. Optimal weak to strong learning. In Sanmi Koyejo, S. Mohamed, A. Agarwal, Danielle Belgrave, K. Cho, and A. Oh, editors, Advances in Neural Information Processing Systems 35: Annual Conference on Neural Information Processing Systems 2022, NeurIPS 2022, New Orleans, LA, USA, November 28 - December 9, 2022, 2022. URL http://papers.nips.cc/paper_files/paper/2022/hash/ d38653cdaa8e992549e1e9e1621610d7-Abstract-Conference.html.   \nYi Li, Philip M. Long, and Aravind Srinivasan. Improved bounds on the sample complexity of learning. Journal of Computer and System Sciences, 62(3):516\u2013527, 2001. doi: 10.1006/JCSS. 2000.1741. URL https://doi.org/10.1006/jcss.2000.1741.   \nMichel Talagrand. Sharper bounds for gaussian and empirical processes. The Annals of Probability, pages 28\u201376, 1994.   \nVladimir N Vapnik and A Ya Chervonenkis. On the uniform convergence of relative frequencies of events to their probabilities. Theory of Probability and its Applications, 16(2):264\u2013280, 1971.   \nCynthia Dwork, Guy N. Rothblum, and Salil P. Vadhan. Boosting and differential privacy. In 51th Annual IEEE Symposium on Foundations of Computer Science, FOCS 2010, October 23-26, 2010, Las Vegas, Nevada, USA, pages 51\u201360. IEEE Computer Society, 2010. doi: 10.1109/FOCS. 2010.12. URL https://doi.org/10.1109/FOCS.2010.12.   \nSolomon Kullback and Richard A Leibler. On information and sufficiency. The annals of mathematical statistics, 22(1):79\u201386, 1951.   \nRobert E. Schapire and Yoav Freund. Boosting: Foundations and Algorithms. The MIT Press, 05 2012. ISBN 9780262301183. doi: 10.7551/mitpress/8291.001.0001. URL https://doi.org/ 10.7551/mitpress/8291.001.0001.   \nMonroe D Donsker and SRS386024 Varadhan. Asymptotic evaluation of certain markov process expectations for large time, i and ii. Communications on Pure and Applied Mathematics, 28(1-2): 279\u2013301, 1975.   \nAmir Dembo and Ofer Zeitouni. Large Deviations Techniques and Applications. Springer, 1998. ISBN 978-1-4612-5320-4. doi: 10.1007/978-1-4612-5320-4. URL https://doi.org/10. 1007/978-1-4612-5320-4.   \nSe Yoon Lee. Gibbs sampler and coordinate ascent variational inference: A set-theoretical review. Communications in Statistics-Theory and Methods, 51(6):1549\u20131568, 2022. ", "page_idx": 9}, {"type": "text", "text": "", "page_idx": 10}, {"type": "text", "text": "A Auxiliary Results ", "text_level": 1, "page_idx": 11}, {"type": "text", "text": "In this section we state and proof claims utilized in our argument. The arguments behind those are fairly standard, so they are not explicitly stated in the main text. ", "page_idx": 11}, {"type": "text", "text": "Claim 1. Let $\\ell\\in\\mathbb{N}$ and $0<\\gamma<1/2$ . If a hypothesis $h_{\\ell}$ has advantage $\\gamma_{\\ell}$ satisfying $\\mathscr{L}_{D_{\\ell}}(h_{\\ell})=$ $1/2-\\gamma_{\\ell}\\leq1/2-\\gamma/2$ and $\\alpha\\ell=\\alpha$ , then ", "page_idx": 11}, {"type": "equation", "text": "$$\nZ_{\\ell}\\le\\sqrt{1-\\gamma^{2}}\\le e^{-\\gamma^{2}/2}.\n$$", "text_format": "latex", "page_idx": 11}, {"type": "text", "text": "Proof. It holds that ", "page_idx": 11}, {"type": "equation", "text": "$$\n\\begin{array}{l}{\\displaystyle Z_{\\ell}=\\sum_{i=1}^{m}D_{\\ell}(i)\\exp(-\\alpha_{\\ell}c(x_{i})h_{\\ell}(x_{i}))}\\\\ {\\displaystyle\\quad=\\sum_{i+h_{\\ell}(x_{i})=c(x_{i})}D_{\\ell}(i)e^{-\\alpha}+\\sum_{i:h_{\\ell}(x_{i})\\neq c(x_{i})}D_{\\ell}(i)e^{\\alpha}}\\\\ {\\displaystyle\\quad=\\left(\\frac{1}{2}+\\gamma_{\\ell}\\right)\\sqrt{\\frac{1-\\gamma}{1+\\gamma}}+\\left(\\frac{1}{2}-\\gamma_{\\ell}\\right)\\cdot\\sqrt{\\frac{1+\\gamma}{1-\\gamma}}}\\\\ {\\displaystyle\\quad=\\left(\\frac{1/2+\\gamma_{\\ell}}{1+\\gamma}+\\frac{1/2-\\gamma_{\\ell}}{1-\\gamma}\\right)\\sqrt{(1+\\gamma)(1-\\gamma)}}\\\\ {\\displaystyle\\quad=\\left(\\frac{1-2\\gamma\\cdot\\gamma_{\\ell}}{1-\\gamma^{2}}\\right)\\sqrt{1-\\gamma^{2}}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 11}, {"type": "text", "text": "Finally, since $\\gamma_{\\ell}\\ge\\gamma/2$ and $\\gamma\\in(0,1/2)$ , and, thus, $1-\\gamma^{2}>0$ , we have that ", "page_idx": 11}, {"type": "equation", "text": "$$\n\\frac{1-2\\gamma\\cdot\\gamma_{\\ell}}{1-\\gamma^{2}}\\leq\\frac{1-\\gamma^{2}}{1-\\gamma^{2}}=1.\n$$", "text_format": "latex", "page_idx": 11}, {"type": "text", "text": "Claim 2. Algorithm 1 produces a linear classifier g whose exponential loss satisfies ", "page_idx": 11}, {"type": "equation", "text": "$$\n\\sum_{i=1}^{m}\\exp\\biggl(-c(x_{i})\\sum_{j=1}^{p R}\\alpha_{j}\\mathbf{h}_{j}(x_{i})\\biggr)=m\\prod_{j=1}^{p R}\\mathbf{Z}_{j}.\n$$", "text_format": "latex", "page_idx": 11}, {"type": "text", "text": "Proof. It suffices to consider the last distribution $D_{p R+1}$ produced by the algorithm. It holds that ", "page_idx": 11}, {"type": "equation", "text": "$$\n\\begin{array}{c l}{\\displaystyle1=\\sum_{i=1}^{m}{D_{p R+1}(i)}}\\\\ {\\displaystyle}&{\\displaystyle=\\sum_{i=1}^{m}{D_{p R}(i)}\\cdot\\frac{\\exp(-\\alpha_{p R}c(x_{i}){\\bf h}_{p R}(x_{i}))}{{\\bf Z}_{p R}}}\\\\ {\\displaystyle}&{\\displaystyle=\\sum_{i=1}^{m}{D_{1}(i)}\\cdot\\prod_{j=1}^{p R}\\frac{\\exp(-\\alpha_{j}c(x_{i}){\\bf h}_{j}(x_{i}))}{{\\bf Z}_{j}}}\\\\ {\\displaystyle}&{\\displaystyle=\\frac{1}{m}\\cdot\\sum_{i=1}^{m}\\frac{\\exp(-c(x_{i})\\sum_{j=1}^{p R}\\alpha_{j}{\\bf h}_{j}(x_{i}))}{\\prod_{j=1}^{p R}{\\bf Z}_{j}}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 11}, {"type": "text", "text": "B Detailed Proofs ", "text_level": 1, "page_idx": 11}, {"type": "text", "text": "In this section, provide full proofs for the results from Section 2. For convenience, we provide copies of the statements before each proof. ", "page_idx": 11}, {"type": "text", "text": "B.1 Proof of Lemma 2.5 ", "text_level": 1, "page_idx": 12}, {"type": "text", "text": "Lemma 2.5. There exists universal constant $C_{\\mathrm{n}}\\geq1$ for which the following holds. Given $0<\\gamma<$ $1/2,\\,R,m\\in\\mathbb{N}$ , concept $c\\colon\\mathcal{X}\\rightarrow\\{-1,1\\}$ , and hypothesis set $\\mathcal{H}\\subseteq\\{-1,1\\}^{\\chi}$ of $V C$ -dimension $d_{\\cdot}$ , let $\\tilde{D}$ and $D$ be distributions over $[m]$ and $\\mathcal{G}\\in[m]^{*}$ be the family of $\\gamma/2$ -approximations for $D$ , $c,$ and $\\mathcal{H}$ . If $\\tilde{D}$ and $D$ have the same support and ", "page_idx": 12}, {"type": "equation", "text": "$$\n\\mathrm{KL}(D\\parallel\\tilde{D})\\leq4\\gamma^{2}R,\n$$", "text_format": "latex", "page_idx": 12}, {"type": "text", "text": "then for all $n\\geq C_{\\mathrm{n}}\\cdot d/\\gamma^{2}$ it holds that ", "page_idx": 12}, {"type": "equation", "text": "$$\n\\operatorname*{Pr}_{\\mathbf{T}\\sim\\tilde{D}^{n}}[\\mathbf{T}\\in\\mathcal{G}]\\ge\\exp(-16C_{\\mathrm{n}}d R).\n$$", "text_format": "latex", "page_idx": 12}, {"type": "text", "text": "Proof. Let $\\lambda\\in\\mathbb{R}_{>0}$ (to be chosen later) and $\\mathbf{X}\\colon[m]^{n}\\to\\{0,\\lambda\\}$ be the random variable given by ", "page_idx": 12}, {"type": "equation", "text": "$$\n\\mathbf{X}(T)=\\lambda\\mathbf{1}_{\\{T\\in{\\mathcal{G}}\\}}.\n$$", "text_format": "latex", "page_idx": 12}, {"type": "text", "text": "Since $\\tilde{D}$ and $D$ have the same support, so do ${\\tilde{D}}^{n}$ and $D^{n}$ . Thus, taking the exponential of both sides of Eq. (3), Lemma 2.4 yields that ", "page_idx": 12}, {"type": "equation", "text": "$$\n\\exp(-\\operatorname{KL}(D^{n}\\parallel{\\tilde{D}}^{n})+\\mathbb{E}_{D^{n}}[\\mathbf{X}])\\leq\\mathbb{E}_{{\\tilde{D}}^{n}}[e^{\\mathbf{X}}].\n$$", "text_format": "latex", "page_idx": 12}, {"type": "text", "text": "We have that ", "page_idx": 12}, {"type": "equation", "text": "$$\n\\mathbb{E}_{D^{n}}[\\mathbf{X}]=\\lambda\\cdot\\operatorname*{Pr}_{\\mathbf{T}\\sim D^{n}}[\\mathbf{T}\\in\\mathcal{G}].\n$$", "text_format": "latex", "page_idx": 12}, {"type": "text", "text": "Moreover, ", "page_idx": 12}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{E}_{\\tilde{D}^{n}}\\big[e^{\\mathbf{X}}\\big]=\\mathbb{E}_{\\mathbf{T}\\sim\\tilde{D}^{n}}\\big[e^{\\lambda}\\cdot\\mathbf{1}_{\\{\\mathbf{T}\\in\\mathcal{G}\\}}+\\mathbf{1}_{\\{\\mathbf{T}\\in\\mathcal{G}\\}}\\big]}\\\\ &{\\quad\\quad\\quad\\quad=\\mathbb{E}_{\\mathbf{T}\\sim\\tilde{D}^{n}}\\big[e^{\\lambda}\\cdot\\mathbf{1}_{\\{\\mathbf{T}\\in\\mathcal{G}\\}}+1-\\mathbf{1}_{\\{\\mathbf{T}\\in\\mathcal{G}\\}}\\big]}\\\\ &{\\quad\\quad\\quad\\quad=1+(e^{\\lambda}-1)\\,\\mathbb{E}_{\\mathbf{T}\\sim\\tilde{D}^{n}}\\big[\\mathbf{1}_{\\{\\mathbf{T}\\in\\mathcal{G}\\}}\\big]}\\\\ &{\\quad\\quad\\quad=1+(e^{\\lambda}-1)\\,\\underset{\\mathbf{T}\\sim\\tilde{D}^{n}}{\\mathrm{~Pr~}}\\big[\\mathbf{T}\\in\\mathcal{G}\\big].}\\end{array}\n$$", "text_format": "latex", "page_idx": 12}, {"type": "text", "text": "Applying Eqs. (5) and (6) to Eq. (4), we obtain that ", "page_idx": 12}, {"type": "equation", "text": "$$\n\\exp\\Bigl(-\\,\\mathrm{KL}(D^{n}\\parallel\\tilde{D}^{n})+\\lambda\\,\\underset{\\mathbf{T}\\sim D^{n}}{\\operatorname*{Pr}}[\\mathbf{T}\\in\\mathcal{G}]\\Bigr)\\leq1+(e^{\\lambda}-1)\\underset{\\mathbf{T}\\sim\\tilde{D}^{n}}{\\operatorname*{Pr}}[\\mathbf{T}\\in\\mathcal{G}]\n$$", "text_format": "latex", "page_idx": 12}, {"type": "text", "text": "and, thus, ", "page_idx": 12}, {"type": "equation", "text": "$$\n\\operatorname*{Pr}_{\\mathbf{T}\\sim\\tilde{D}^{n}}[\\mathbf{T}\\in\\mathcal{G}]\\geq\\frac{\\exp\\Bigl[-\\,\\mathrm{KL}(D^{n}\\parallel\\tilde{D}^{n})+\\lambda\\operatorname*{Pr}_{\\mathbf{T}\\sim D^{n}}[\\mathbf{T}\\in\\mathcal{G}]\\Bigr]-1}{e^{\\lambda}-1}\n$$", "text_format": "latex", "page_idx": 12}, {"type": "text", "text": "for any $\\lambda>0$ . Choosing ", "page_idx": 12}, {"type": "equation", "text": "$$\n\\lambda=\\frac{\\mathrm{KL}(D^{n}\\parallel\\tilde{D}^{n})+\\ln2}{\\mathrm{Pr}_{\\mathbf{T}\\sim D^{n}}[\\mathbf{T}\\in\\mathcal{G}]},\n$$", "text_format": "latex", "page_idx": 12}, {"type": "text", "text": "we obtain that ", "page_idx": 12}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{~~\\displaystyle\\operatorname*{Pr}_{\\mathbf{T}\\sim\\tilde{D}^{n}}[\\mathbf{T}\\in\\mathcal{G}]\\geq\\frac{1}{e^{\\lambda}-1}}\\\\ &{~~\\quad~~~~~~~~~~~~\\geq e^{-\\lambda}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 12}, {"type": "text", "text": "Now, by Theorem 2.3 (using $\\delta=1/2$ ), there exists a constant $C_{\\mathrm{n}}\\geq1$ such that having ", "page_idx": 12}, {"type": "equation", "text": "$$\nn\\geq C_{\\mathrm{n}}\\cdot{\\frac{d}{\\gamma^{2}}}\n$$", "text_format": "latex", "page_idx": 12}, {"type": "text", "text": "ensures that ", "page_idx": 12}, {"type": "equation", "text": "$$\n\\operatorname*{Pr}_{\\mathbf{T}\\sim D^{n}}[\\mathbf{T}\\in{\\mathcal{G}}]\\geq{\\frac{1}{2}}.\n$$", "text_format": "latex", "page_idx": 12}, {"type": "text", "text": "Also, since, by hypothesis, $\\mathrm{KL}(D\\parallel\\tilde{D})\\leq4\\gamma^{2}R$ , we have that ", "page_idx": 13}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathrm{KL}(D^{n}\\parallel\\tilde{D}^{n})=n\\,\\mathrm{KL}(D\\parallel\\tilde{D})}\\\\ {\\leq4C_{\\mathrm{n}}d R.\\qquad\\qquad}\\end{array}\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "Applying it to Eq. (7), we conclude that ", "page_idx": 13}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{~~\\operatorname*{Pr}_{\\mathbf{T}\\sim\\tilde{D}^{n}}[\\mathbf{T}\\in\\mathcal{G}]\\geq\\exp\\biggl(-\\frac{4C_{\\mathrm{n}}d R+\\ln2}{1/2}\\biggr)}\\\\ &{~~\\!\\!~\\!~\\!\\!\\!\\!\\!\\geq\\exp(-16C_{\\mathrm{n}}d R).}\\end{array}\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "B.2 Proof of Lemma 2.6 ", "text_level": 1, "page_idx": 13}, {"type": "text", "text": "Lemma 2.6. There exists universal constant $C_{\\mathrm{n}}\\geq1$ such that for all $R\\in\\mathbb{N},\\,0\\,<\\,\\delta\\,<\\,1,\\,0\\,<$ $\\gamma<1/2$ , and $\\gamma$ -weak learner $\\mathcal{W}$ using a hypothesis set $\\mathcal{H}\\subseteq\\{-1,1\\}^{\\chi}$ with VC-dimension d, if $t\\ge$ $R\\cdot\\exp(16C_{\\mathrm{n}}d R)\\cdot\\ln(R/\\delta)$ , then with probability at least $1-\\delta$ the hypotheses $\\mathbf{h}_{k R+1},\\ldots,\\mathbf{h}_{k R+R}$ obtained by Algorithm $^{\\,l}$ induce normalization factors $\\mathbf{Z}_{k R+1},\\ldots,\\mathbf{Z}_{k R+R}$ such that ", "page_idx": 13}, {"type": "equation", "text": "$$\n\\prod_{r=1}^{R}{\\bf Z}_{k R+r}<\\exp(-\\gamma^{2}R/2).\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "Proof. Assume, for simplicity, that $k=0$ . ", "page_idx": 13}, {"type": "text", "text": "Letting ", "page_idx": 13}, {"type": "equation", "text": "$$\n\\mathcal{E}_{R^{\\prime}}=\\bigg\\{\\prod_{r=1}^{R^{\\prime}}\\mathbf{Z}_{r}<\\exp(-\\gamma^{2}R^{\\prime}/2)\\bigg\\},\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "we will show that for all $R^{\\prime}\\in[R]$ it holds that ", "page_idx": 13}, {"type": "equation", "text": "$$\n\\operatorname*{Pr}[{\\mathcal{E}}_{R^{\\prime}}\\mid{\\mathcal{E}}_{1},\\ldots,{\\mathcal{E}}_{R^{\\prime}-1}]\\geq1-\\delta/R.\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "The thesis then follows by noting that ", "page_idx": 13}, {"type": "equation", "text": "$$\n\\begin{array}{l}{\\displaystyle\\mathrm{Pr}[\\mathcal{E}_{1}\\cap\\cdots\\cap\\mathcal{E}_{R}]=\\prod_{r=1}^{R}\\operatorname*{Pr}[\\mathcal{E}_{r}\\mid\\mathcal{E}_{1},\\ldots,\\mathcal{E}_{r-1}]}\\\\ {\\displaystyle\\geq\\left(1-\\frac{\\delta}{R}\\right)^{R}}\\\\ {\\displaystyle\\geq1-R\\cdot\\frac{\\delta}{R}}\\\\ {\\displaystyle=1-\\delta.}\\end{array}\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "(by Bernoulli\u2019s inequality) ", "page_idx": 13}, {"type": "text", "text": "Let $\\mathcal{G}_{D_{R^{\\prime}}}\\subseteq\\,[m]^{n}$ be the family of $\\gamma/2$ -approximations for $D_{R^{\\prime}}$ and recall that if $T\\,\\in\\,\\mathcal{G}_{D_{R^{\\prime}}}$ , then any $h\\,={\\bar{\\mathcal{W}}}(T,\\operatorname{Uniform}(T))$ satisfies $\\bar{\\mathcal{L}}_{D_{R^{\\prime}}}(h)\\,\\le\\,1/2\\,-\\,\\gamma/2$ . Therefore, the existence of $\\mathbf{T}_{R^{\\prime},j^{*}}\\in\\mathcal{G}_{D_{R^{\\prime}}}$ , for some $j^{*}\\in[t/R]$ , implies that $\\mathbf{h}_{R^{\\prime},j^{*}}\\in\\pmb{\\mathcal{H}}_{R^{\\prime}}$ has margin at least $\\gamma/2$ relative to $D_{R^{\\prime}}$ . Hence, Algorithm 1 can select ${\\bf{h}}_{R^{\\prime},j^{*}}$ at Line 11, setting $\\alpha_{R^{\\prime}}=\\alpha$ so that, by Claim 1, we have that $\\mathbf{Z}_{R^{\\prime}}\\leq\\exp(-\\gamma^{2}/2)$ . ", "page_idx": 13}, {"type": "text", "text": "Now notice that, by the law of total probability, ", "page_idx": 13}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\operatorname*{Pr}\\Big[\\mathcal{E}_{R^{\\prime}}\\;\\Big|\\;\\cap_{r=1}^{R^{\\prime}-1}\\mathcal{E}_{r}\\Big]}\\\\ &{\\quad=\\operatorname*{Pr}\\Big[\\mathrm{KL}(D_{R^{\\prime}}\\;\\|\\;D_{1})\\leq4\\gamma^{2}R\\;\\Big|\\;\\cap_{r=1}^{R^{\\prime}-1}\\mathcal{E}_{r}\\Big]\\cdot\\operatorname*{Pr}\\Big[\\mathcal{E}_{R^{\\prime}}\\;\\Big|\\;\\cap_{r=1}^{R^{\\prime}-1}\\mathcal{E}_{r},\\ \\mathrm{KL}(D_{R^{\\prime}}\\;\\|\\;D_{1})\\leq4\\gamma^{2}R\\Big]}\\\\ &{\\quad\\quad+\\operatorname*{Pr}\\Big[\\mathrm{KL}(D_{R^{\\prime}}\\;\\|\\;D_{1})>4\\gamma^{2}R\\;\\Big|\\;\\cap_{r=1}^{R^{\\prime}-1}\\mathcal{E}_{r}\\Big]\\cdot\\operatorname*{Pr}\\Big[\\mathcal{E}_{R^{\\prime}}\\;\\Big|\\;\\cap_{r=1}^{R^{\\prime}-1}\\mathcal{E}_{r},\\ \\mathrm{KL}(D_{R^{\\prime}}\\;\\|\\;D_{1})>4\\gamma^{2}R\\Big]\\,.}\\end{array}\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "We will show that, conditioned on $\\cap_{r=1}^{R^{\\prime}-1}\\mathcal{E}_{r}$ , if $\\mathrm{KL}(D_{R^{\\prime}}||D_{1})\\leq4\\gamma^{2}R$ , we can leverage Lemma 2.5 to argue that with probability at least $\\mathrm{1}{\\mathrm{~-~}}\\delta/R$ there exists a $\\gamma/2$ -approximation for $D_{R^{\\prime}}$ within $\\mathbf{T}_{R^{\\prime},1},\\dotsc,\\mathbf{T}_{R^{\\prime},t/R}$ , and that $\\mathcal{E}_{R^{\\prime}}$ follows. On the other hand, if $\\mathrm{KL}(\\bar{D}_{R^{\\prime}}\\parallel D_{1})>4\\gamma^{2}R$ , we shall prove that $\\mathcal{E}_{R^{\\prime}}$ necessarily holds. Under those two claims, Eq. (9) yields that ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\operatorname*{Pr}\\left[\\mathcal{E}_{R^{\\prime}}\\left|\\cap_{r=1}^{R^{\\prime}-1}\\mathcal{E}_{r}\\right|\\geq\\operatorname*{Pr}\\!\\left[\\mathrm{KL}(D_{R^{\\prime}}\\left|\\right.\\right|D_{1})\\leq4\\gamma^{2}R\\left|\\cap_{r=1}^{R^{\\prime}-1}\\mathcal{E}_{r}\\right]\\cdot\\left(1-\\frac{d}{R}\\right)}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\qquad+\\operatorname*{Pr}\\!\\left[\\mathrm{KL}(D_{R^{\\prime}}\\left|\\right.\\right|D_{1})>4\\gamma^{2}R\\left|\\cap_{r=1}^{R^{\\prime}-1}\\mathcal{E}_{r}\\right]\\cdot1}\\\\ &{\\qquad\\qquad\\qquad\\geq\\operatorname*{Pr}\\!\\left[\\mathrm{KL}(D_{R^{\\prime}}\\left|\\right.\\right|D_{1})\\leq4\\gamma^{2}R\\left|\\cap_{r=1}^{R^{\\prime}-1}\\mathcal{E}_{r}\\right]\\cdot\\left(1-\\frac{d}{R}\\right)}\\\\ &{\\qquad\\qquad\\qquad+\\operatorname*{Pr}\\!\\left[\\mathrm{KL}(D_{R^{\\prime}}\\left|\\right.\\right|D_{1})>4\\gamma^{2}R\\left|\\cap_{r=1}^{R^{\\prime}-1}\\mathcal{E}_{r}\\right]\\cdot\\left(1-\\frac{d}{R}\\right)}\\\\ &{\\qquad=1-\\frac{\\delta}{R},}\\end{array}\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "which, as argued, concludes the proof. ", "page_idx": 14}, {"type": "text", "text": "To proceed, we ought to consider the relationships between the random variables involved. To do so, for $r\\in[R]$ let $\\mathcal{T}_{r}=\\{\\mathbf{T}_{r,1},\\dots,\\mathbf{T}_{r,t/R}\\}$ . Notice that $D_{R^{\\prime}}^{n}$ is itself random and determined by $D_{1}$ , and $\\tau_{1},...,\\tau_{R^{\\prime}-1}$ . ", "page_idx": 14}, {"type": "text", "text": "For the first part, let $D_{1}$ and $\\tau_{1},\\dots,\\tau_{R^{\\prime}-1}$ be realizations of $D_{1}$ and $\\tau_{1},...,\\tau_{R^{\\prime}-1}$ such that $\\cap_{r=1}^{R^{\\prime}-1}\\mathcal{E}_{r}$ holds and $\\mathrm{KL}(D_{R^{\\prime}}\\parallel D_{1})\\,\\leq\\,4\\gamma^{2}R$ . Notice that if there exists a $\\gamma/2$ -approximation for $D_{R^{\\prime}}$ within $\\boldsymbol{\\tau}_{R}$ , then we can choose some $\\mathbf{h}_{R^{\\prime}}\\in\\pmb{\\mathcal{H}}_{R^{\\prime}}$ with advantage at least $\\gamma/2$ so that ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\lefteqn{\\prod_{r=1}^{R^{\\prime}}\\mathbf Z_{r}=\\mathbf Z_{R^{\\prime}}\\cdot\\prod_{r=1}^{R^{\\prime}-1}Z_{r}}}\\\\ &{<\\mathbf Z_{R^{\\prime}}\\cdot\\exp(-\\gamma^{2}(R^{\\prime}-1)/2)}\\\\ &{\\le\\exp(-\\gamma^{2}R^{\\prime}/2)}\\end{array}\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "and, thus, $\\mathcal{E}_{R^{\\prime}}$ follows. That is, ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\operatorname*{Pr}\\left[\\mathcal{E}_{R^{\\prime}}\\,\\Big|\\,\\cap_{r=1}^{R^{\\prime}-1}\\mathcal{E}_{r},\\,\\operatorname{KL}(D_{R^{\\prime}}\\,\\|\\,D_{1})\\leq4\\gamma^{2}R\\right]\\geq\\operatorname*{Pr}_{\\substack{\\mathbf T_{R^{\\prime},1},\\ldots,\\mathbf T_{R^{\\prime},t}\\,|R^{\\sharp}D_{1}^{n}}}\\!\\left[\\exists j\\in[t/R],\\mathbf T_{R^{\\prime},j}\\in\\mathcal{G}_{D_{R^{\\prime}}}\\right].\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "Finally, since by Remark 1 the distributions $D_{R^{\\prime}}$ and $D_{1}$ must have the same support, and we assume that $\\mathrm{KL}(D_{R^{\\prime}}\\,||\\,\\bar{D}_{1})\\leq4\\gamma^{2}R$ , Lemma 2.5 ensures that ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\operatorname*{Pr}_{\\mathbf{T}\\sim D_{1}^{n}}[\\mathbf{T}\\in\\mathcal{G}_{D_{R^{\\prime}}}]\\ge\\exp(-16C_{\\mathrm{n}}d R).\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "Therefore, ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\underset{\\mathbf{T}_{R^{\\prime},1},\\dots,\\mathbf{T}_{R^{\\prime},t/R}|\\overset{\\mathrm{bf}}{\\sim}D_{1}^{n}}{\\left[\\forall j\\in[t/R],\\mathbf{T}_{R^{\\prime},j}\\notin\\mathcal{G}_{D_{R^{\\prime}}}\\right]}=\\left(\\underset{\\mathbf{T}_{N^{\\prime},1}}{\\operatorname*{Pr}}\\big[\\mathbf{T}\\notin\\mathcal{G}_{D_{R^{\\prime}}}\\big]\\right)^{t/R}}&{{}(\\mathrm{by}}\\\\ {\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\leq(1-\\exp(-16C_{\\mathrm{n}}d R))^{t/R}}\\\\ {\\qquad\\qquad\\qquad\\qquad\\qquad\\leq\\exp\\biggl(-\\frac{t}{R}\\cdot\\exp(-16C_{\\mathrm{n}}d R)\\biggr)}\\\\ {\\qquad\\qquad\\qquad\\qquad\\qquad\\leq\\frac{\\delta}{R},}\\end{array}\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "where the second inequality follows since $1+x\\leq e^{x}$ for all $x\\in\\mathbb R$ and the last from the hypothesis that $t\\geq R\\cdot\\exp(16C_{\\mathrm{n}}d R)\\cdot\\ln(R/\\delta)$ . Considering the complementary event and applying Eq. (10), we obtain that $\\mathcal{E}_{R^{\\prime}}$ holds with probability at least $1-\\delta/R$ . ", "page_idx": 14}, {"type": "text", "text": "For the second part, consider instead $D_{1}$ and $\\tau_{1},\\dots,\\tau_{R^{\\prime}-1}$ realizations of $D_{1}$ and $\\tau_{1},...,\\tau_{R^{\\prime}-1}$ such that $\\cap_{r=1}^{R^{\\prime}-\\bar{1}}\\mathcal{E}_{r}$ holds and ", "page_idx": 14}, {"type": "equation", "text": "$$\n4\\gamma^{2}R<\\mathrm{KL}(D_{R^{\\prime}}\\parallel D_{1}),\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "and argue that $\\mathcal{E}_{R^{\\prime}}$ necessarily follows. ", "page_idx": 15}, {"type": "text", "text": "Observe that ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathrm{KL}(D_{R^{\\prime}}\\parallel D_{1})=\\mathrm{KL}(D_{R^{\\prime}}\\parallel D_{1})-\\mathrm{KL}(D_{R^{\\prime}}\\parallel D_{R^{\\prime}})}\\\\ &{\\qquad\\qquad\\qquad=\\mathrm{KL}(D_{R^{\\prime}}\\parallel D_{1})-\\mathrm{KL}(D_{R^{\\prime}}\\parallel D_{2})}\\\\ &{\\qquad\\qquad\\qquad\\quad+\\mathrm{KL}(D_{R^{\\prime}}\\parallel D_{2})-\\mathrm{KL}(D_{R^{\\prime}}\\parallel D_{3})}\\\\ &{\\qquad\\qquad\\qquad\\quad+\\dots}\\\\ &{\\qquad\\qquad\\qquad\\quad+\\mathrm{KL}(D_{R^{\\prime}}\\parallel D_{R^{\\prime}-1})-\\mathrm{KL}(D_{R^{\\prime}}\\parallel D_{R^{\\prime}})}\\\\ &{\\qquad\\qquad\\qquad\\quad=\\displaystyle\\sum_{r=1}^{R^{\\prime}-1}\\mathrm{KL}(D_{R^{\\prime}}\\parallel D_{r})-\\mathrm{KL}(D_{R^{\\prime}}\\parallel D_{r+1}).}\\end{array}\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "Moreover, given $r\\in\\{1,\\ldots,R^{\\prime}-1\\}$ , ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\begin{array}{l}{{\\mathrm{KL}(D_{R^{\\prime}}\\parallel D_{r})-\\mathrm{KL}(D_{R^{\\prime}}\\parallel D_{r+1})=\\displaystyle\\sum_{i=1}^{m}D_{R^{\\prime}}(i)\\ln\\frac{D_{R^{\\prime}}(i)}{D_{r}(i)}-\\displaystyle\\sum_{i=1}^{m}D_{R^{\\prime}}(i)\\ln\\frac{D_{R^{\\prime}}(i)}{D_{r+1}(i)}}}\\\\ {{{}~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~}}\\\\ {{=\\displaystyle\\sum_{i=1}^{m}D_{R^{\\prime}}(i)\\ln\\frac{D_{r+1}(i)}{D_{r}(i)}}}\\\\ {{{}~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~}}\\\\ {{=\\displaystyle\\sum_{i=1}^{m}D_{R^{\\prime}}(i)\\ln\\frac{\\exp(-\\alpha_{r}c(x_{i})h_{r}(x_{i}))}{Z_{r}}}}\\\\ {{{}~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~Z_{r}}}\\\\ {{=-\\ln Z_{r}-\\displaystyle\\sum_{i=1}^{m}D_{R^{\\prime}}(i)\\alpha_{r}c(x_{i})h_{r}(x_{i}).}}\\end{array}\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "Applying it to Eqs. (11) and (12) yields that ", "page_idx": 15}, {"type": "equation", "text": "$$\n4\\gamma^{2}R<\\mathrm{KL}(D_{R^{\\prime}}\\parallel D_{1})=-\\ln\\prod_{r=1}^{R^{\\prime}-1}Z_{r}-\\sum_{r=1}^{R^{\\prime}-1}\\alpha_{r}\\sum_{i=1}^{m}D_{R^{\\prime}}(i)c(x_{i})h_{r}(x_{i}).\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "Thus, either ", "page_idx": 15}, {"type": "equation", "text": "$$\n-\\ln\\prod_{r=1}^{R^{\\prime}-1}Z_{r}>\\frac{4\\gamma^{2}R}{2},\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "or ", "page_idx": 15}, {"type": "equation", "text": "$$\n-\\sum_{r=1}^{R^{\\prime}-1}\\alpha_{r}\\sum_{i=1}^{m}D_{R^{\\prime}}(i)c(x_{i})h_{r}(x_{i})>\\frac{4\\gamma^{2}R}{2}.\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "We proceed to analyze each case. ", "page_idx": 15}, {"type": "text", "text": "If Eq. (13) holds, then ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\lefteqn{\\prod_{r=1}^{R^{\\prime}-1}Z_{r}<\\exp(-2\\gamma^{2}R)}}\\\\ &{\\leq\\exp(-\\gamma^{2}R^{\\prime}/2)}\\end{array}\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "and $\\mathcal{E}_{R^{\\prime}}$ follows by noting that $\\mathbf{Z}_{R^{\\prime}}~=~1$ regardless of the outcome of Line 11 so $\\prod_{r=1}^{R^{\\prime}}Z_{r}\\ \\le$ $\\prod_{r=1}^{R^{\\prime}-1}Z_{r}$ . ", "page_idx": 15}, {"type": "text", "text": "On the other hand, if Eq. (14) holds, then, letting $\\mathcal{R}=\\left\\{r\\in\\left[R^{\\prime}-1\\right]\\vert\\,\\alpha_{r}\\neq0\\right\\}$ , ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\begin{array}{r l r}{\\lefteqn{2\\gamma^{2}R<-\\sum_{r=1}^{R^{\\prime}-1}\\alpha_{r}\\sum_{i=1}^{m}D_{R^{\\prime}}(i)c(x_{i})h_{r}(x_{i})}}\\\\ &{}&{=-\\sum_{r\\in\\mathcal{R}}\\alpha\\sum_{i=1}^{m}D_{R^{\\prime}}(i)c(x_{i})h_{r}(x_{i}).}\\end{array}\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "Since $|\\mathcal{R}|\\leq R$ , we obtain that ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\sum_{r\\in\\mathcal{R}}\\frac{1}{|\\mathcal{R}|}\\sum_{i=1}^{m}D_{R^{\\prime}}(i)c(x_{i})(-h_{r}(x_{i}))>\\frac{2\\gamma^{2}}{\\alpha}\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "so that there exists $h^{\\ast}\\in\\{-h_{r}\\mid r\\in\\mathcal{R}\\}$ such that ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\sum_{i=1}^{m}D_{R^{\\prime}}(i)c(x_{i})h^{*}(x_{i})>\\frac{2\\gamma^{2}}\\alpha.\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "Moreover, from the definition of $\\alpha$ , ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\begin{array}{l}{\\displaystyle\\alpha=\\frac{1}{2}\\ln\\frac{1/2+\\gamma/2}{1/2-\\gamma/2}}\\\\ {\\displaystyle\\quad=\\frac{1}{2}\\ln\\Biggl(1+\\frac{2\\gamma}{1-\\gamma}\\Biggr)}\\\\ {\\displaystyle\\quad\\leq\\frac{\\gamma}{1-\\gamma}}\\\\ {\\displaystyle\\quad<2\\gamma,}\\end{array}\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "where the last inequality holds for any $\\gamma\\in(0,1/2)$ . Applying it to Eq. (15) yields that ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\begin{array}{r l r}{\\lefteqn{\\sum_{i=1}^{m}D_{R^{\\prime}}(i)c(x_{i})h^{*}(x_{i})>\\frac{2\\gamma^{2}}{2\\gamma}}}\\\\ &{}&{\\ge\\gamma,}\\end{array}\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "thus $\\mathcal{L}_{D_{R^{\\prime}}}(h^{*})~<~1/2\\,-\\,\\gamma/2$ and, as before, $\\mathcal{E}_{R^{\\prime}}$ follows by Claim 1 and the conditioning on $\\cap_{r=1}^{R^{\\prime}-1}\\mathcal{E}_{r}$ . \u53e3 ", "page_idx": 16}, {"type": "text", "text": "B.3 Proof of Theorem 2.1 ", "text_level": 1, "page_idx": 16}, {"type": "text", "text": "Theorem 2.1. There exists universal constant $C_{\\mathrm{n}}~\\geq~1$ such that for all $0\\,<\\,\\gamma\\,<\\,1/2,\\,R\\,\\in\\,\\mathbb{N},$ , concept $c\\colon\\mathcal{X}\\rightarrow\\{-1,1\\}$ , and hypothesis set $\\mathcal{H}\\subseteq\\{-1,1\\}^{\\mathcal{X}}$ of $V C$ -dimension $d$ , Algorithm $^{\\,l}$ given an input training set $S\\in\\mathcal{X}^{m}$ , $a\\sim$ -weak learner $\\mathcal{W}$ , ", "page_idx": 16}, {"type": "equation", "text": "$$\np\\geq\\frac{4\\ln m}{\\gamma^{2}R},\\qquad a n d\\qquad t\\geq e^{16C_{\\mathrm{n}}d R}\\cdot R\\ln\\frac{p R}{\\delta},\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "produces a linear classifier g at Line 21 such that with probability at least $1\\!-\\!\\delta$ over the randomness of Algorithm 1, $\\mathbf{g}(x)c(x)\\geq\\gamma/8$ for all $x\\in S$ . ", "page_idx": 16}, {"type": "text", "text": "Proof. Let $k\\in\\{0,1,\\ldots,p-1\\}$ . Applying Lemma 2.6 with failure probability $\\delta/p$ , we obtain that with probability at least $1-\\delta/p$ , ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\prod_{r=1}^{R}{\\bf Z}_{k R+r}<\\exp(-\\gamma^{2}R/2).\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "Thus, by the union bound, the probability that this holds for all $k\\in\\{0,1,\\ldots,p-1\\}$ is at least $1-\\delta$ . Under this event, we have that ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\displaystyle\\sum_{i=1}^{m}\\exp\\biggl(-c(x_{i})\\displaystyle\\sum_{j=1}^{p R}\\alpha_{j}\\mathbf{h}_{j}(x_{i})\\biggr)=m\\displaystyle\\prod_{j=1}^{p R}\\mathbf{Z}_{j}}&{}\\\\ {\\displaystyle=m\\displaystyle\\prod_{k=0}^{p-1}\\prod_{r=1}^{R}\\mathbf{Z}_{k R+r}}&{}\\\\ {\\displaystyle\\leq m\\displaystyle\\prod_{k=0}^{p-1}\\exp(-\\gamma^{2}R/2)}&{}\\\\ {\\displaystyle=m\\exp(-\\gamma^{2}p R/2).}&{}\\end{array}\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "Now, let $\\theta~\\ge~0$ . If $c(x)\\mathbf{g}(x)~<~\\theta$ , then, by the definition of $\\mathbf{g}$ at Line 21, it must hold that $\\begin{array}{r}{c(x)\\sum_{j=1}^{p R}\\alpha_{j}\\mathbf{h}_{j}(x)<\\sum_{j=1}^{p R}\\alpha_{j}\\theta}\\end{array}$ , thus the difference $\\begin{array}{r}{\\sum_{j=1}^{p R}\\alpha_{j}\\theta-c(x)\\sum_{j=1}^{p R}\\alpha_{j}\\mathbf{h}_{j}(x)}\\end{array}$ is strictly positive. Taking the exponential, we obtain that, for all $x\\in S$ , ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\begin{array}{l}{\\displaystyle\\mathbf{1}_{\\{c(x)\\mathbf{g}(x)<\\theta\\}}\\leq1}\\\\ {\\displaystyle<\\exp\\left(\\sum_{j=1}^{p R}\\alpha_{j}\\theta-c(x)\\sum_{j=1}^{p R}\\alpha_{j}\\mathbf{h}_{j}(x)\\right)}\\\\ {\\displaystyle\\leq\\exp(p R\\alpha\\theta)\\exp\\left(-c(x)\\sum_{j=1}^{p R}\\alpha_{j}\\mathbf{h}_{j}(x)\\right).}\\end{array}\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "Therefore, ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\sum_{i=1}^{m}\\mathbf{1}_{\\{c(x_{i})\\mathbf{g}(x_{i})<\\theta\\}}<\\exp(p R\\alpha\\theta)\\sum_{i=1}^{m}\\exp\\left(-c(x_{i})\\sum_{j=1}^{p R}\\alpha_{j}\\mathbf{h}_{j}(x_{i})\\right).\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "Applying Eq. (17), we obtain that ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\begin{array}{r l r}{\\lefteqn{\\sum_{i=1}^{m}\\mathbf{1}_{\\left\\{c(x_{i})\\mathbf{g}(x_{i})<\\theta\\right\\}}<m\\exp(p R\\alpha\\theta)\\exp(-\\gamma^{2}p R/2)}}\\\\ &{}&{=m\\exp\\bigl(p R(\\alpha\\theta-\\gamma^{2}/2)\\bigr).}\\end{array}\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "Finally, since $0\\leq\\alpha\\leq2\\gamma$ (see Eq. (16)), we have that, for $0\\leq\\theta\\leq\\gamma/8$ , ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\begin{array}{c}{\\alpha\\theta-\\gamma^{2}/2\\leq2\\gamma\\cdot\\gamma/8-\\gamma^{2}/2}\\\\ {\\leq-\\gamma^{2}/4}\\end{array}\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "and thus ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\displaystyle\\sum_{i=1}^{m}\\mathbf{1}_{\\left\\{c(x_{i})\\mathbf{g}(x_{i})<\\gamma/8\\right\\}}<m\\exp\\!\\left(-p R\\gamma^{2}/4\\right)}&{}\\\\ {\\leq m\\cdot m^{-1}}&{}\\\\ {=1,}\\end{array}\n$$", "text_format": "latex", "page_idx": 17}, {"type": "equation", "text": "$$\n(\\operatorname{as}p\\geq4R^{-1}\\gamma^{-2}\\ln m)\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "and we can conclude that all points have a margin greater than $\\gamma/8$ . ", "page_idx": 17}, {"type": "text", "text": "C Lower Bound ", "text_level": 1, "page_idx": 17}, {"type": "text", "text": "In this section, we prove Theorem 1.2. Theorem 1.2 is a consequence of the following Theorem C.2. Before we state Theorem C.2 we will: state the assumptions that we make in the lower bound for a learning algorithm $\\boldsymbol{\\mathcal{A}}$ with parallel complexity $(p,t)$ , the definition of a $\\gamma.$ -weak learner in this section and describe the hard instance. For this let $c\\colon{\\mathcal{X}}\\to\\{-1,1\\}$ denote a labelling function. Furthermore, throughout Appendix C let $C_{s i z e}:=C_{s}\\geq1$ , $C_{b i a s}:=C_{b}\\geq1$ and $C_{l o s s}:=C_{l}\\ge1$ denote the same universal constants. ", "page_idx": 17}, {"type": "text", "text": "Assumption C.1. Let $\\mathbf{Q}^{i}$ with $|\\mathbf{Q}^{i}|\\leq t$ be the queries made by a learning algorithm $\\boldsymbol{\\mathcal{A}}$ with parallel complexity $(p,t)$ during the $i$ th round. We assume that a query $\\mathbf{Q}_{j}^{i}\\;\\in\\;\\mathbf{Q}^{\\bar{i}}$ for $i\\,=\\,1,...\\,,p$ and $j=1,\\dots,t$ is on the form $(\\mathbf{S}_{j}^{i},c(\\mathbf{S}_{j}^{i}),\\mathbf{D}_{j}^{i})$ , where the elements in $\\mathbf{S}_{j}^{i}$ are contained in S, and that the distribution $\\mathbf{D}_{j}^{i}$ has support s $\\mathrm{upp}(\\mathbf{D}_{j}^{i})\\subset\\{(\\mathbf{S}_{j}^{i})_{1},\\dots,(\\mathbf{S}_{j}^{i})_{m}\\}$ . Furthermore, we assume ${\\bf{Q}}^{1}$ only depends on the given sample $\\mathbf{S}\\in\\mathcal{X}^{m}$ and the sample labels $c(\\mathbf{S})$ where $c(\\mathbf{S})_{i}=c(\\mathbf{S}_{i})$ , and that $\\mathbf{Q}^{i}$ for $i=2,\\dots,p$ only depends on the label sample $\\mathbf{S},\\mathbf{c}(\\mathbf{S})$ and the previous $i-1$ queries and the responses to these queries. ", "page_idx": 17}, {"type": "text", "text": "We now clarify what we mean by a weak learner in this section. ", "page_idx": 17}, {"type": "text", "text": "Definition 2. A $\\gamma$ -weak learner $\\mathcal{W}$ acting on a hypothesis set $\\mathcal{H}$ , takes as input $(S,c(S),D)$ , where $S\\ \\in\\ \\chi^{*}\\ =\\ \\cup_{i=1}^{\\infty}\\chi^{i}$ , $c(S)_{i}~=~c(S_{i})$ and $\\operatorname{supp}(D)\\ \\subseteq\\ \\{S_{1},S_{2}\\ldots\\}$ . The output of $h=\\mathcal{W}(\\mathcal{H})(S,c(S),D)$ is such that $\\begin{array}{r}{\\sum_{i}D(i)\\mathbf{1}\\{h(i)\\neq c(i)\\}\\le1/2-\\gamma}\\end{array}$ . ", "page_idx": 17}, {"type": "text", "text": "We now define the hard instance which is the same construction as used in Lyu et al. [2024](which found inspiration in Karbasi and Larsen [2024]). For d \u2208N, samples size m, and 0 < \u03b3 <41Cb we consider the following hard instance ", "page_idx": 18}, {"type": "text", "text": "1. The universe $\\mathcal{X}$ we take to be $[2m]$ .   \n2. The distribution $\\mathcal{D}$ we will use on $[2m]$ will be the uniform distribution $\\boldsymbol{\\mathcal{U}}$ over $[2m]$ . ", "page_idx": 18}, {"type": "text", "text": "3. The random concept $\\mathbf{c}$ that we are going to use is the uniform random concept $\\{-1,1\\}^{2m}$ , i.e. all the labels of $\\mathbf{c}$ are i.i.d. and $\\mathrm{Pr}_{\\mathbf{c}}[\\bar{\\mathbf{c}}(i)\\,{\\bar{=}}\\,1]=1/2$ for $i=1,\\hdots,m$ . ", "page_idx": 18}, {"type": "text", "text": "4. The random hypothesis set will depend on the number of parallel rounds $p$ , a scalar $R\\in\\mathbb N$ , and the random concept c, thus we will denote it $\\mathcal{H}_{p,\\mathbf{c},R}$ . We will see $\\mathcal{H}_{p,\\mathbf{c},R}$ as a matrix where the rows are the hypothesis so vectors of length $2m$ , where the $i$ th entry specifies the prediction the hypothesis makes on element $i\\,\\in\\,[2m]$ . To define $\\mathcal{H}_{p,\\mathbf{c},R}$ we first define two random matrices $\\mathcal{H}_{u}$ and $\\mathcal{H}_{\\mathrm{c}}$ . $\\mathcal{H}_{u}$ is a random matrix consisting of $R$ $\\mathrm{~\\d~}\\bar{\\mathrm{~\\pexp}}\\left(C_{s}d\\right)]$ rows, where the rows in $\\mathcal{H}_{u}$ are i.i.d. with distribution $\\mathbf{r}\\sim\\{-1,1\\}^{2m}$ (r has i.i.d. entries $\\mathrm{{Pr}}_{\\mathbf{r}\\sim\\{-1,1\\}^{2m}}[\\mathbf{r}(1)=1]=1/2,$ ). $\\varkappa_{c}$ is a random matrix with $R$ rows, where the rows in $\\varkappa_{c}$ are i.i.d. \u02d9with distribution $\\mathbf{b}\\sim\\{-1,1\\}_{C_{b}}^{2m}$ , meaning the entries of $\\mathbf{b}$ are independent and has distribution $\\mathrm{Pr}_{\\mathbf{b}\\sim\\{-1,1\\}_{C_{b}}^{2m}}[\\mathbf{b}(i)\\ \\neq\\ c(i)]\\ =$ $1/2-C_{b}\\gamma$ (so $C_{b}\\gamma$ biased towards the sign of $c$ ). We now let $\\mathcal{H}_{u}^{1},\\mathcal{H}_{\\mathbf{c}}^{1},\\ldots,\\mathcal{H}_{u}^{p},\\mathcal{H}_{\\mathbf{c}}^{p}$ denote i.i.d. copies of respectively $\\mathcal{H}_{u}$ and $\\mathcal{H}_{\\mathrm{c}}$ , and set $\\mathcal{H}_{p,\\mathbf{c},R}$ to be these i.i.d. copies stack on top of each other and $\\#_{p,\\mathbf{c},R}\\cup\\mathbf{c}$ to be the random matrix which first rows are $\\mathcal{H}_{p,\\mathbf{c},R}$ and its last row is $\\mathbf{c}$ , ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathcal{H}_{p,\\mathbf{c},R}=\\left[\\begin{array}{c}{\\mathcal{H}_{u}^{1}}\\\\ {\\mathcal{H}_{\\mathbf{c}}^{1}}\\\\ {\\vdots}\\\\ {\\mathcal{H}_{u}^{p}}\\\\ {\\mathcal{H}_{\\mathbf{c}}^{p}}\\end{array}\\right]\\quad\\mathcal{H}_{p,\\mathbf{c},R}\\cup\\mathbf{c}=\\left[\\begin{array}{c}{\\mathcal{H}_{p,\\mathbf{c},R}}\\\\ {\\mathbf{c}}\\end{array}\\right].}\\end{array}\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "5. The algorithm $\\mathcal{W}$ which given matrix/hypothesis set $M\\in\\mathbb{R}^{\\ell}\\times\\mathbb{R}^{2m}$ (where $M_{i},$ \u00b7 denotes the ith row of $M$ ) is the following algorithm $\\mathcal{W}(M)$ . ", "page_idx": 18}, {"type": "text", "text": "Algorithm 2: W(M) Input : Triple $(S,c(S),D)$ where $S\\in[2m]^{*}$ , $c(S)_{i}=c(S_{i})$ and probability distribution $D$ with $\\mathrm{supp}(\\bar{D})\\subset\\{S_{1},S_{2},.\\;.\\;.\\;,\\}$ . Output: Hypothesis $h=M_{i}$ \u00b7 for some $i=1,\\dots,\\ell$ such that: $\\begin{array}{r}{\\sum_{i}D(i)\\mathbf{1}\\{\\mathbf{h}(i)\\neq c(i)\\}\\le1/2-\\gamma}\\end{array}$ .   \n1 for $i\\in[\\bar{\\ell}]$ do   \n2 if $\\begin{array}{r}{{\\sum_{j}D(j)\\mathbf{1}\\{M_{i,j}\\ne c(j)\\}}\\le1/2-\\gamma\\;\\;/\\prime}\\end{array}$ Notice that $\\mathcal{W}$ doesn\u2019t know $c$ but can calculate this quantity using the information in $(S,c(S),D)$ which is given as input.   \n3 then   \n4 return $M_{i,}.$ .   \n5 return $M_{1}$ ,\u00b7. ", "page_idx": 18}, {"type": "text", "text": "We notice that with this construction, we have that $|\\mathcal{H}_{p,\\mathbf{c},R}|\\leq R\\,\\lceil\\exp\\left(C_{s}d\\right)\\rceil\\,+R p$ and $\\mathscr{W}(\\pmb{\\mathscr{H}}_{p,\\mathbf{c},R}\\cup\\$ c) a weak learner since it either finds a row in $\\mathcal{H}_{p,\\mathbf{c},R}$ with error less than $1/2-\\gamma$ for a query or outputs c which has 0 error for any query - this follows by the Assumption C.1 that the learning algorithm given $\\left(S,\\mathbf{c}(S)\\right)$ make queries which is consistent with c. ", "page_idx": 18}, {"type": "text", "text": "With these definitions and notation in place, we now state Theorem C.2, which Theorem 1.2 is a consequence of. ", "page_idx": 18}, {"type": "text", "text": "Theorem C.2. For $d\\,\\in\\,\\mathbb{N}$ , $m\\,\\in\\,\\mathbb{N},$ margin $\\begin{array}{r}{0\\;<\\;\\gamma\\;<\\;\\frac{1}{4C_{b}}}\\end{array}$ , $R,p,t\\,\\in\\,\\mathbb{N},$ , universe $[2m]$ , $\\boldsymbol{\\mathcal{U}}$ the uniform distribution on $[2m]$ , and c the uniform concept on $[2m]$ any learning algorithm $\\boldsymbol{\\mathcal{A}}$ with parallel complexity $(p,t)$ , given labelled training set $(\\mathbf{S},\\mathbf{c}(\\mathbf{S}))$ , where ${\\bf S}\\sim\\mathcal{U}^{m}$ , and query access to $\\mathcal{W}(\\pmb{\\mathscr{H}}_{p,c,R}\\cup\\mathbf{c})$ we have that ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{E}_{{\\bf S},{\\bf c},\\mathcal{H}}[\\mathcal{L}_{\\mathcal{U}}^{\\bf c}(A({\\bf S},{\\bf c}({\\bf S}),\\mathcal{W}(\\mathcal{H}_{p,{\\bf c},R}\\cup{\\bf c})))]}\\\\ &{\\ge\\frac{\\exp(-C_{l}C_{b}^{2}\\gamma^{2}R p)}{4C_{l}}\\left(1-\\exp\\left(-\\frac{m\\exp(-C_{l}C_{b}^{2}\\gamma^{2}R p)}{8C_{l}}\\right)-p t\\exp\\left(-R d\\right)\\right),}\\end{array}\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "We now restate and give the proof of Theorem 1.2. ", "page_idx": 19}, {"type": "text", "text": "Theorem 1.2. There is a universal constant $C\\geq1$ for which the following holds. For any $0~<$ $\\gamma<1/C$ , any $d\\geq C$ , any sample size $m\\geq C$ , and any weak-to-strong learner $\\boldsymbol{\\mathcal{A}}$ with parallel complexity $(p,t)$ , there exists an input domain $\\mathcal{X}$ , a distribution $\\mathcal{D}$ , a concept $z\\colon X\\rightarrow\\{-1,1\\}$ , and a $\\gamma$ -weak learner $\\mathcal{W}$ for c using a hypothesis set $\\mathcal{H}$ of $V C$ -dimension $d$ such that if the expected loss of $\\boldsymbol{\\mathcal{A}}$ over the sample is no more than $m^{-0.01}$ , then either $p\\geq\\operatorname*{min}\\{\\exp(\\Omega(d)),\\Omega(\\gamma^{-2}\\ln m)\\}$ , or $t\\geq\\exp(\\exp(\\Omega(d)))$ , or $p\\ln t=\\Omega(\\gamma^{-2}d\\ln m)$ . ", "page_idx": 19}, {"type": "text", "text": "Proof of Theorem 1.2. Fix $d\\,\\geq\\,1$ , sample size $m\\:\\geq\\:(e80C_{l})^{100}$ , margin $\\begin{array}{r}{0\\;<\\;\\gamma\\;\\leq\\;\\frac{1}{4C_{b}}}\\end{array}$ , $p$ such that $\\begin{array}{r}{p\\leq\\operatorname*{min}\\left\\{\\exp(d/8),\\frac{\\ln\\left(m^{0.01}/(80C_{l})\\right)}{2C_{l}C_{b}^{2}\\gamma^{2}}\\right\\}}\\end{array}$ ,ln(m20C.0l1C/2( 8\u03b302Cl)) , t \u2264exp(exp(d)/8) and p ln(t) \u2264 d $\\begin{array}{r}{p\\ln(t)\\,\\leq\\,\\frac{d\\ln\\left(m^{0.01}/(80C_{l})\\right)}{8C_{l}C_{b}^{2}\\gamma^{2}}}\\end{array}$ We now want to invoke Theorem C.2 with different values of $R$ depending on the value of $p$ . We consider 2 cases. Firstly, the case ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\frac{\\ln\\left(m^{0.01}/(80C_{l})\\right)}{2C_{l}C_{b}^{2}\\gamma^{2}\\left\\{\\exp(d)\\right\\}}\\le p\\le\\frac{\\ln\\left(m^{0.01}/(80C_{l})\\right)}{2C_{l}C_{b}^{2}\\gamma^{2}}.\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "In this case one can choose $R\\in\\mathbb N$ such that $1<R\\leq\\lfloor\\exp(d)\\rfloor$ and ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\frac{\\ln\\left(m^{0.01}/(80C_{l})\\right)}{2C_{l}C_{b}^{2}\\gamma^{2}R}\\leq p\\leq\\frac{\\ln\\left(m^{0.01}/(80C_{l})\\right)}{2C_{l}C_{b}^{2}\\gamma^{2}(R-1)}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "Let now $R$ be such. We now invoke Theorem C.2 with the above parameters and get ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{E}_{{\\bf S},{\\bf c},\\mathcal{H}}[\\mathcal{L}_{\\mathcal{U}}^{\\bf c}(A({\\bf S},{\\bf c}({\\bf S}),\\mathcal{W}(\\mathcal{H}_{p,{\\bf c},R}\\cup{\\bf c})))]}\\\\ &{\\ge\\frac{\\exp(-C_{l}C_{b}^{2}\\gamma^{2}R p)}{4C_{l}}\\left(1-\\exp\\left(-\\frac{m\\exp(-C_{l}C_{b}^{2}\\gamma^{2}R p)}{8C_{l}}\\right)-p t\\exp\\left(-R d\\right)\\right),}\\end{array}\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "We now bound the individual terms on the right-hand side of Eq. (18). First by $p\\ \\leq$   \n$\\begin{array}{r}{\\frac{\\ln\\left(m^{0.01}/(80C_{l})\\right)}{2C_{l}C_{b}^{2}\\gamma^{2}(R-1)}\\ \\leq\\ \\frac{\\ln\\left(m^{0.01}/(80C_{l})\\right)}{C_{l}C_{b}^{2}\\gamma^{2}R}}\\end{array}$ we get that exp(\u2212ClCb2 \u03b32Rp) $\\begin{array}{r}{\\frac{\\exp(-C_{l}C_{b}^{2}\\gamma^{2}R p)}{4C_{l}}\\;\\geq\\;20m^{-0.01}}\\end{array}$ which further im  \npwlie ehs $\\begin{array}{r}{\\exp\\left(-\\frac{m\\exp(-C_{l}C_{b}^{2}\\gamma^{2}R p)}{8C_{l}}\\right)\\le\\exp(-10m^{0.99})\\le e^{-10}}\\end{array}$ .l ieWse t fhuart $R$ ea se lasbe owvee $\\begin{array}{r}{p\\ln(\\exp(R d/4))\\ge\\frac{d\\ln\\left(m^{0.01}/(80C_{l})\\right)}{8C_{l}C_{b}^{2}\\gamma^{2}}}\\end{array}$ $t\\leq\\exp(R d/4)$   \ntwioonu lwdi thha voeu $t>\\exp(R d/4)$ $\\begin{array}{r}{p\\ln(t)>p\\exp(R d/4)\\,\\ge\\,\\frac{d\\ln\\bigl(m^{0.01}/(80C_{l})\\bigr)}{8C_{l}C_{b}^{2}\\gamma^{2}}}\\end{array}$ ewdh tihcaht $\\begin{array}{r}{p\\ln(t)\\leq\\frac{d\\ln\\left(m^{0.01}/(80C_{l})\\right)}{8C_{l}C_{b}^{2}\\gamma^{2}}}\\end{array}$ $p\\leq\\exp(d/8)$   \nwe have that $p t\\,\\leq\\,\\exp(d/8\\,+\\,R d/4\\cdot)$ . Combining this with $R\\,>\\,1$ and $d\\,\\geq\\,1$ we have that   \n$p t\\exp\\left(R d\\right)\\,\\leq\\,\\exp\\left(R d/2\\right)\\,\\geq\\,e^{-1}$ . Combining the above observations we get that the right-hand   \nside of Eq. (18) is at least ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\mathbb{E}_{\\mathbf{S},\\mathbf{c},\\mathcal{H}}[\\mathcal{L}_{\\mathcal{U}}^{\\mathbf{c}}(\\mathcal{A}(\\mathbf{S},\\mathbf{c}(\\mathbf{S}),\\mathcal{W}(\\mathcal{H}_{p,\\mathbf{c},R}\\cup\\mathbf{c})))]\\ge20m^{-0.01}\\left(1-e^{-10}-e^{-1}\\right)\\ge m^{-0.01}.\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "Now in the case that ", "page_idx": 19}, {"type": "equation", "text": "$$\np<\\frac{\\ln\\left(m^{0.01}/(80C_{l})\\right)}{2C_{l}C_{b}^{2}\\gamma^{2}\\left\\lfloor\\exp(d)\\right\\rfloor},\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "we choose $\\textit{R}=\\,\\lfloor\\exp(d)\\rfloor$ . Invoking Theorem C.2 again give use the expression in Eq. (18) (with the parameter $R\\,=\\,[\\exp(d)]$ now) and we again proceed to lower bound the right-hand side of Eq. (18). First we observe that by the upper bound on $p$ in Eq. (19), $R\\,=\\,\\lfloor\\exp(d)\\rfloor$ and exp(\u2212x/2) \u2265 exp (\u2212x) for x \u2265 1 we get that exp(\u2212C4lCCb2 \u03b32Rp) $\\begin{array}{r}{\\frac{\\exp(-C_{l}C_{b}^{2}\\gamma^{2}R p)}{4C_{l}}\\ \\geq\\ \\frac{\\exp(-\\ln\\left(m^{0.01}/(80C_{l})\\right)/2)}{4C_{l}}\\ \\geq}\\end{array}$ $20m^{-0.01}$ , which further implies that $\\begin{array}{r}{\\exp\\left(-\\frac{m\\exp(-C_{l}C_{b}^{2}\\gamma^{2}R p)}{8C_{l}}\\right)\\,\\le\\,e^{-10}}\\end{array}$ . Now since $\\lfloor x\\rfloor\\geq x/2$ for $x\\geq1$ , $R=\\lfloor\\exp(d)\\lfloor$ and we assumed that $t\\leq\\exp(\\exp(d)/8)$ and $p\\leq\\exp(d/8)$ we get that pt $\\exp(-R d)\\leq\\exp\\left(\\exp(d)/8+d/8-d\\exp(d)/2\\right)\\leq\\exp\\left(-d\\exp(d)/4\\right)\\leq e^{-e/4}$ . Combining the above observations we get that the right-hand side of Eq. (18) is at least ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathbb{E}_{\\mathbf{S},\\mathbf{c},\\mathcal{H}}[\\mathcal{L}_{\\mathcal{U}}^{\\mathbf{c}}(A(\\mathbf{S},\\mathbf{c}(\\mathbf{S}),\\mathcal{W}(\\mathcal{H}_{p,\\mathbf{c},R}\\cup\\mathbf{c})))]\\ge20m^{-0.01}\\left(1-e^{-10}-e^{-e/4}\\right)\\ge m^{-0.01}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "Thus, for any of the above parameters $d,m,\\gamma,p,t$ in the specified parameter ranges, we have that the expected loss of $\\boldsymbol{\\mathcal{A}}$ over S, c, $\\mathcal{H}_{p,\\mathbf{c},R}$ is at least $m^{-0.01}$ , so there exists concept $c$ and hypothesis $\\mathcal{H}$ such that the expected loss of $\\boldsymbol{\\mathcal{A}}$ over $\\mathbf{S}$ is at least $m^{-0.01}$ . Furthermore, if $\\boldsymbol{\\mathcal{A}}$ were a random algorithm Yao\u2019s minimax principle would give the same lower bound for the expected loss over $\\boldsymbol{\\mathcal{A}}$ and S as the above bound holds for any deterministic $\\boldsymbol{\\mathcal{A}}$ . ", "page_idx": 20}, {"type": "text", "text": "Now as remarked on before the proof the size of the hypothesis set $\\mathcal{H}_{p,\\mathbf{c},R}$ is at most $|\\pmb{\\mathcal{H}}_{p,\\mathbf{c},R}|\\leq$ $R\\left\\lceil\\exp\\left(C_{s}d\\right)\\right\\rceil+R p$ , see Item 4. Combining this with us in the above arguments having $p\\ \\leq$ $\\exp(d/8)$ , $R\\ \\leq\\ \\exp(d)$ we conclude that $|\\mathcal{H}\\cup c|~\\leq~\\exp(\\tilde{C}d/2)$ for $\\tilde{C}$ large enough. Thus, we get at bound of $\\log_{2}(|\\mathcal{H}\\cup c|)\\,\\leq\\,\\log_{2}(\\exp(\\tilde{C}d/2))\\,\\leq\\,\\tilde{C}d$ which is also an upper bound of the VC-dimension of $\\mathcal{H}\\cup c$ . Now redoing the above arguments with $d$ scaled by $1/\\tilde{C}$ we get that the VC-dimension of $\\mathcal{H}\\cup c$ is upper bounded by $d$ and the same expected loss of $m^{-0.{\\breve{0}}1}$ . The constraints given in the start of the proof with this rescaling of $d$ is now $d\\ \\geq\\ {\\tilde{C}}$ , $m~\\geq$ $(e80C_{l})^{100}$ , $\\begin{array}{r}{0<\\gamma\\le\\frac{1}{4C_{b}}}\\end{array}$ , $\\begin{array}{r}{p\\leq\\operatorname*{min}\\left\\{\\exp(\\bar{d}/(8\\tilde{C})),\\frac{\\ln{(m^{0.01}/(80C_{l}))}}{2C_{l}C_{b}^{2}\\gamma^{2}}\\right\\}}\\end{array}$ , $t\\leq\\exp{(\\exp{(d/\\tilde{C})}/8)}$ and \u2264 d ln(m\u02dc0.01/2(802Cl)). Thus, with the universal constant C = max $C\\,=\\,\\operatorname*{max}\\left\\{(e80C_{l})^{100},4C_{b},\\tilde{C}\\right\\}$ and $m,d~\\geq~C$ and $\\gamma\\ \\leq\\ 1/C$ we have that the expected loss is at least $m^{-0.01}$ when $p~\\leq$ $\\operatorname*{min}\\left\\{\\exp(O(d)),O(\\ln\\left(m\\right)/\\gamma^{2})\\right\\}$ , $t\\leq\\exp{(\\exp{(O(d))})}$ and $p\\ln(t)\\leq O(d\\ln(m)/\\gamma^{2})$ which concludes the proof. \u53e3 ", "page_idx": 20}, {"type": "text", "text": "We now move on to prove Theorem C.2. For this, we now introduce what we will call the extension of $\\boldsymbol{\\mathcal{A}}$ which still terminates if it receives a hypothesis with loss more than $1/2-\\gamma$ . We further show two results about this extension one which says that with high probability we can replace $\\boldsymbol{\\mathcal{A}}$ with its extension and another saying that with high probability the loss of the extension is large, which combined will give us Theorem C.2. ", "page_idx": 20}, {"type": "text", "text": "6. The output of the extension $B_{A}$ of $\\boldsymbol{\\mathcal{A}}$ on input $(S,c(S),\\mathcal{W})$ is given through the outcome of recursive query sets $Q^{1},\\ldots$ where each of the sets contains $t$ queries. The recursion is given in the following way: Make $Q^{1}$ to $\\mathcal{W}$ as $\\boldsymbol{\\mathcal{A}}$ would have done on input $(S,c(S),\\cdot)$ (this is possible by Assumption C.1 which say $Q^{1}$ is a function of only $(S,c(S))$ . For $i=1,\\hdots,p$ such that for all $j\\,=\\,1,\\ldots,t$ it is the case that $\\mathcal{W}(Q_{j}^{i-1})$ has loss less than $1/2-\\gamma$ under $D_{j}^{i-1}$ let $Q^{i}$ be the query set $Q$ that $\\boldsymbol{\\mathcal{A}}$ would have made after having made query sets $Q^{1},\\ldots,Q^{i-1}$ and received hypothesis $\\{\\mathcal{W}(Q_{j}^{l})\\}_{(l,j)\\in[i-1]\\times[t]}$ . If this loop ends output the hypothesis that $\\boldsymbol{\\mathcal{A}}$ would have made with responses $\\{\\mathcal{W}(Q_{j}^{l})\\}_{(l,j)\\in[i]\\times[t]}$ to its queries. If there is an $l,j$ such that $\\mathcal{W}(Q_{j}^{l})$ return a hypothesis with loss larger than $1/2-\\gamma$ return the all 1 hypothesis. ", "page_idx": 20}, {"type": "text", "text": "We now go to the two results we need in the proof of Theorem C.2. The first result Corollary 1 says that there exists an event $E$ which happens with high probability over $\\mathcal{H}_{p,\\mathbf{c},R}$ such that $\\boldsymbol{\\mathcal{A}}$ run with $\\mathcal{W}(\\pmb{\\mathcal{H}}_{p,\\mathbf{c},R},\\mathbf{c})$ is the same as $B_{A}$ run with $\\mathscr{W}(\\pmb{\\mathscr{H}}_{p,\\mathbf{c},R})$ . This corollary can be proved by following the proofs of Theorem 5 and 8 in Lyu et al. [2024] and is thus not included here. ", "page_idx": 20}, {"type": "text", "text": "Corollary 1. For $d\\in\\mathbb{N}$ , $m\\in\\mathbb{N},$ , margin $\\begin{array}{r}{0\\,<\\,\\gamma\\,<\\,\\frac{1}{4C_{b}}}\\end{array}$ , labelling function $c:[2m]\\rightarrow\\{-1,1\\}$ , $R,p,t\\,\\in\\,\\mathbb{N}$ , random matrix $\\mathcal{H}_{p,c,R;}$ , learning algorithm $\\mathcal{A}$ , $B_{\\mathcal{A}}$ , training sample $S\\,\\in\\,[2m]^{m}$ , we have that there exist and event $E$ over outcomes of $\\mathcal{H}_{p,c,R}$ such that ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\boldsymbol{A}(\\boldsymbol{S},\\boldsymbol{c}(\\boldsymbol{S}),\\mathcal{W}(\\mathcal{H}_{p,c,R}\\cup\\boldsymbol{c}))\\mathbf{1}_{E}=\\boldsymbol{B}_{\\mathcal{A}}(\\boldsymbol{S},\\boldsymbol{c}(\\boldsymbol{S}),\\mathcal{W}(\\mathcal{H}_{p,c,R}))\\mathbf{1}_{E}\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "and ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\Pr_{\\varkappa_{p,c,R}}[E]\\geq1-p t\\exp\\left(-R d\\right).\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "The second result that we are going to need is Lemma C.3 which relates parameters $R,\\beta,p$ to the success of any function of $(\\bar{S overline{{,}}}\\mathbf{c}(\\bar{S}),\\mathcal{H}_{p,\\mathbf{c},R})$ which tries to guess the signs of $\\mathbf{c}$ \u2014 which is the number of failures in our hard instance. For a training sample $S\\in[2m]^{*}$ we will use $|S|$ to denote the number of distinct elements in $S$ from $[2m]$ , so for $S\\in[2m]^{m}$ we have $|S|\\leq m$ . ", "page_idx": 20}, {"type": "text", "text": "Lemma C.3. There exists universal constant $C_{s},C_{l}\\ge1$ such that: For $m\\in\\mathbb{N},\\,p\\in\\mathbb{N},\\,\\mathcal{H}_{p,\\beta,\\mathbf{c},R},$ , function $\\boldsymbol{\\mathrm{\\Delta}}\\boldsymbol{\\mathrm{\\Omega}}^{\\beta}$ that takes as input $S\\,\\in\\,[2m]^{m}$ with labels $\\mathbf{c}(S)$ , and hypothesis set $\\mathcal{H}_{p,\\beta,\\mathbf{c},R;}$ , we have ", "page_idx": 20}, {"type": "text", "text": "that ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\displaystyle\\operatorname*{Pr}_{\\mathbf{c},\\mathcal{H}_{p,\\mathbf{c},R}}\\left[\\sum_{i=1}^{2m}\\mathbf{1}\\{B(S,\\mathbf{c}(S),\\mathcal{H}_{p,\\mathbf{c},R})(i)\\neq\\mathbf{c}(i)\\}\\geq\\frac{(2m-|S|)\\exp(-C_{l}C_{b}^{2}\\gamma^{2}R p)}{2C_{l}}\\right]}\\\\ &{\\displaystyle\\geq1-\\exp\\left(-\\frac{(2m-|S|)\\exp(-C_{l}C_{b}^{2}\\gamma^{2}R p)}{8C_{l}}\\right).}\\end{array}\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "We postpone the proof of Lemma C.3 and now give the proof of Theorem C.2. ", "page_idx": 21}, {"type": "text", "text": "Proof of Theorem C.2. We want to lower bound $\\mathbb{E}_{\\mathbf{S},\\mathbf{c},\\mathcal{H}}[\\mathcal{L}_{\\mathcal{U}}^{\\mathbf{c}}(A(\\mathbf{S},\\mathcal{W}(\\mathcal{H}\\cup\\mathbf{c})))]$ . To this end since S and $\\mathbf{c}$ are independent and $\\mathcal{H}_{p,\\mathbf{c},R}$ depended on c the expected loss can be written as ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\quad\\mathbb{E}_{\\mathbf{S},\\mathbf{c},\\mathbf{\\mathcal{H}}}[\\mathcal{L}_{\\mathcal{U}}^{\\mathbf{c}}(\\mathcal{A}(\\mathbf{S},\\mathbf{c}(\\mathbf{S}),\\mathcal{W}(\\mathbf{\\mathcal{H}}_{p,\\mathbf{c},R}\\cup\\mathbf{c})))]}\\\\ &{=\\mathbb{E}_{\\mathbf{S}}\\left[\\mathbb{E}_{\\mathbf{c}}\\left[\\mathbb{E}_{\\mathbf{\\mathcal{H}}_{p,\\mathbf{c},R}}[\\mathcal{L}_{\\mathcal{U}}^{\\mathbf{c}}(\\mathcal{A}(\\mathbf{S},\\mathbf{c}(\\mathbf{S}),\\mathcal{W}(\\mathbf{\\mathcal{H}}_{p,\\mathbf{c},R}\\cup\\mathbf{c})))]\\right]\\right].}\\end{array}\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "Now let $S\\in[2m]^{m}$ , $c$ be any outcome of $\\mathbf{S}$ and $\\mathbf{c}$ . Then for these $S,c$ we have by Lemma C.3 that there exists some event $E$ over $\\mathcal{H}_{p,c,R}$ such that ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\mathcal{L}_{\\mathcal{U}}^{c}(\\boldsymbol{A}(\\boldsymbol{S},\\boldsymbol{c}(\\boldsymbol{S}),\\mathcal{W}(\\mathcal{H}_{p,c,R},\\boldsymbol{c})))\\boldsymbol{1}_{E}=\\mathcal{L}_{\\mathcal{U}}^{c}(\\mathcal{B}_{A}(\\boldsymbol{S},\\boldsymbol{c}(\\boldsymbol{S}),\\mathcal{W}(\\mathcal{H}_{p,c,R})))\\boldsymbol{1}_{E},\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "and ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\Pr_{\\varkappa_{p,c,R}}[E]\\geq1-p t\\exp\\left(-R d\\right),\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "furthermore, define $E^{\\prime}$ be the event that ", "page_idx": 21}, {"type": "equation", "text": "$$\nE^{\\prime}=\\left\\{\\sum_{i=1}^{2m}{\\bf1}\\{B_{A}(S,c(S),\\mathcal{W}(\\mathcal{H}_{p,c,R}))(i)\\neq c(i)\\}\\ge\\frac{(2m-|S|)\\exp(-C_{l}C_{b}^{2}\\gamma^{2}R p)}{2C_{l}}\\right\\}.\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "Using the above and $\\boldsymbol{\\mathcal{U}}$ being the uniform measure on $[2m]$ so assigns $1/(2m)$ mass to every point and that $|S|\\leq m$ we now get that, ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{E}_{\\mathcal{H}_{p,c,R}}[\\mathcal{L}_{\\mathcal{U}}^{c}(A(S,c(S),\\mathcal{W}(\\mathcal{H}_{p,c,R},c)))]\\ge\\mathbb{E}_{\\mathcal{H}_{p,c,R}}[\\mathcal{L}_{\\mathcal{U}}^{c}(A(S,c(S),\\mathcal{W}(\\mathcal{H}_{p,c,R},c)))\\mathbf{1}_{E}\\mathbf{1}_{E^{\\prime}}]}\\\\ &{=\\mathbb{E}_{\\mathcal{H}_{p,c,R}}[\\mathcal{L}_{\\mathcal{U}}^{c}(B_{A}(S,c(S),\\mathcal{W}(\\mathcal{H}_{p,c,R})))\\mathbf{1}_{E}\\mathbf{1}_{E^{\\prime}}]\\ge\\frac{(2m-|S|)\\exp(-C_{l}C_{b}^{2}\\gamma^{2}R p)}{4C_{l}m}\\,\\mathbb{E}_{\\mathcal{H}_{p,c,R}}[\\mathbf{1}_{E}\\mathbf{1}_{E^{\\prime}}]}\\\\ &{\\ge\\!\\frac{\\exp(-C_{l}C_{b}^{2}\\gamma^{2}R p)}{4C_{l}}\\left(1-\\underset{\\mathcal{H}_{p,c,R}}{\\operatorname*{Pr}}[\\overline{{E^{\\prime}}}]-p t\\exp\\left(-R d\\right)\\right).}\\end{array}\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "We can do this for any pair $c$ and $S\\in[2m]^{m}$ , so we have that ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\quad\\mathbb{E}_{\\mathbf{c}}\\left[\\mathbb{E}_{\\mathbf{\\mathcal{H}}_{p,\\mathbf{c},R}}[\\mathcal{L}_{\\mathcal{U}}^{\\mathbf{c}}(\\boldsymbol{A}(S,\\mathbf{c}(S),\\mathcal{W}(\\mathbf{\\mathcal{H}}_{p,\\mathbf{c},R}\\cup\\mathbf{c})))]\\right]}\\\\ &{\\geq\\!\\frac{\\exp(-C_{l}C_{b}^{2}\\gamma^{2}R p)}{4C_{l}}\\left(1-\\!\\underset{\\mathbf{c},\\mathbf{\\mathcal{H}}_{p,\\mathbf{c},R}}{\\operatorname*{Pr}}[\\overline{{E^{\\prime}}}]-p t\\exp{(-R d)}\\right).}\\end{array}\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "Now by Lemma C.3 and $|S|\\leq m$ we have that $\\operatorname*{Pr}_{\\mathbf{c},\\pmb{\\mathcal{H}}_{p,\\mathbf{c},R}}\\left[\\overline{{E^{\\prime}}}\\right]$ is at most ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\operatorname*{Pr}_{\\mathbf{c},\\mathcal{H}_{r,\\mathbf{c},R}}[E^{\\prime}]\\leq\\exp\\left(-\\frac{(2m-|S|)\\exp(-C_{l}C_{b}^{2}\\gamma^{2}R p)}{8C_{l}}\\right)\\leq\\exp\\left(-\\frac{m\\exp(-C_{l}C_{b}^{2}\\gamma^{2}R p)}{8C_{l}}\\right).\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "I.e. we have shown that ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\quad\\mathbb{E}_{\\mathbf{c}}\\left[\\mathbb{E}_{\\mathcal{H}_{p,\\mathbf{c},R}}[\\mathcal{L}_{\\mathcal{U}}^{\\mathbf{c}}(A(S,\\mathbf{c}(S),\\mathcal{W}(\\mathcal{H}_{p,\\mathbf{c},R}\\cup\\mathbf{c})))]\\right]}\\\\ &{\\geq\\!\\frac{\\exp\\left(-C_{l}C_{b}^{2}\\gamma^{2}R p\\right)}{4C_{l}}\\left(1-\\exp\\left(-\\frac{m\\exp\\left(-C_{l}C_{b}^{2}\\gamma^{2}R p\\right)}{8C_{l}}\\right)-p t\\exp\\left(-R d\\right)\\right),}\\end{array}\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "for any $S\\in[2m]^{m}$ . Now by taking expectation over ${\\bf S}\\sim\\mathcal{U}^{m}$ we get that ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{E}_{{\\bf S},{\\bf c},\\mathcal{H}}[\\mathcal{L}_{\\mathcal{U}}^{\\bf c}(A({\\bf S},{\\bf c}({\\bf S}),\\mathcal{W}(\\mathcal{H}_{p,{\\bf c},R}\\cup{\\bf c})))]}\\\\ &{\\ge\\frac{\\exp(-C_{l}C_{b}^{2}\\gamma^{2}R p)}{4C_{l}}\\left(1-\\exp\\left(-\\frac{m\\exp(-C_{l}C_{b}^{2}\\gamma^{2}R p)}{8C_{l}}\\right)-p t\\exp\\left(-R d\\right)\\right),}\\end{array}\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "which concludes the proof. ", "page_idx": 21}, {"type": "text", "text": "We now prove Lemma C.3 which is a consequence of maximum-likelihood, and the following Fact 1, where Fact 1 gives a lower bound on how well one from $n$ trials of a biased $\\{-1,1\\}$ random variable, where the direction of the bias itself is random, can guess this random direction of the bias. ", "page_idx": 22}, {"type": "text", "text": "Fact 1. For function $f:\\{-1,1\\}^{n}\\rightarrow\\{-1,1\\}$ and $\\begin{array}{r}{0<\\gamma\\le\\frac{1}{4C_{b}}}\\end{array}$ ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\mathbb{E}_{\\mathbf{c}\\sim\\{-1,1\\}}[\\mathbb{E}_{\\mathbf{b}\\sim\\{-1,1\\}_{C_{b}}^{n}}[1\\{f(\\mathbf{b})\\neq\\mathbf{c}\\}]]\\ge\\exp(-C_{l}C_{b}^{2}\\gamma^{2}n)/C_{l}.\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "Proof. This is the classic coin problem. The lower bound follows by first observing, by maximumlikelihood, that the function $f^{\\star}$ minimizing the above error is the majority function. The result then follows by tightness of the Chernoff bound up to constant factors in the exponent. \u53e3 ", "page_idx": 22}, {"type": "text", "text": "With Fact 1 in place we are now ready to proof Lemma C.3, which we restate before the proof ", "page_idx": 22}, {"type": "text", "text": "Proof of Lemma C.3. Let $\\mathcal{H}_{C_{b}}$ be the matrix consisting of the i.i.d $C_{b}\\gamma$ biased matrices in $\\mathcal{H}_{p,c,R}$ , $\\mathbf{\\mathcal{H}_{c}}^{1},\\ldots,\\mathbf{\\mathcal{H}_{c}}^{p}$ stack on top of each other, ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\mathbf{\\mathcal{H}}_{C_{b}}=\\left[\\begin{array}{c}{\\mathbf{\\mathcal{H}}_{\\mathbf{c}}^{1}}\\\\ {\\vdots}\\\\ {\\mathbf{\\mathcal{\\dot{H}}}_{\\mathbf{c}}^{p}}\\end{array}\\right].\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "Furthermore, for $i=1,\\ldots,2m$ let $\\mathcal{H}_{C_{b},i}$ denote the $i$ th column of $\\mathcal{H}_{C_{b}}$ which is a vector of length $p R$ . Now for $i$ inside $S,\\,B$ has the sign of $\\mathbf{c}(i)$ , so the best function that $\\boldsymbol{\\mathrm{\\Delta}}\\boldsymbol{\\mathrm{\\Omega}}_{\\boldsymbol{B}}$ can be is to be equal to $\\mathbf{c}(i)$ . For $i$ outside $S,B$ does not know $\\mathbf{c}(i)$ from the input but has information about it through $\\mathcal{H}_{C_{b},i}$ , we notice that the sign\u2019s of the hypotheses in $\\mathcal{H}_{u}^{1},\\ldots,\\mathcal{H}_{u}^{p}$ and $\\mathbf{\\mathcal{H}}_{C_{b},j}\\mathbf{\\mathcal{j}}\\neq\\mathbf{\\mathcal{i}}$ and $\\mathbf{c}(S)$ is independent of $\\mathbf{c}(i)$ and does not hold information about $\\mathbf{c}(i)$ , thus the best possible answer any can make is to choose the sign which is the majority of the sign\u2019s in $\\mathcal{H}_{C_{b},i}$ - the maximum likelihood estimator. We now assume that $\\boldsymbol{\\mathrm{\\Delta}}\\boldsymbol{\\mathrm{\\Omega}}_{\\boldsymbol{B}}$ is this above-described \"best\" function - as this function will be a lower bound for the probability of failures for any other $\\boldsymbol{\\mathrm{\\Delta}}\\boldsymbol{\\mathrm{\\Omega}}_{\\boldsymbol{B}}$ , so it suffices to show the lower bound for this $\\boldsymbol{\\mathrm{\\Delta}}\\boldsymbol{\\mathrm{\\Omega}}^{\\beta}$ . Now with the above described $\\boldsymbol{\\mathrm{\\Delta}}\\boldsymbol{\\mathrm{\\Omega}}_{\\boldsymbol{B}}$ , we have that ", "page_idx": 22}, {"type": "equation", "text": "$$\nX:=\\sum_{i=1}^{2m}\\mathbf{1}\\{B(S,\\mathbf{c}(S),\\mathcal{H}_{p,\\mathbf{c},R})(i)\\neq\\mathbf{c}(i)\\}=\\sum_{i\\notin S}\\mathbf{1}\\{\\mathrm{sign}\\left(\\sum_{j=1}^{p R}\\mathcal{H}_{C_{b}{i,j}}\\right)\\neq\\mathbf{c}(i)\\}.\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "Thus, we have that $X$ is a sum of $2m-|S|$ (where $|S|$ is the number of distinct elements in $S$ ) independent $\\{0,1\\}$ -random variables and by Fact 1 we have that the expectation of each these random variables is at least $\\mathbb{E}_{\\mathbf{c},\\mathcal{H}_{p,\\mathbf{c},R}}[X]\\ge(\\bar{2}m-|S|)\\exp(-C_{l}C_{b}^{2}\\gamma^{2}R\\bar{p})/C_{l}$ . Thus, we now get by Chernoff that ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\underset{\\mathbf{c},\\mathcal{H}_{p,\\mathbf{c},R}}{\\mathrm{Pr}}\\biggl[X\\geq\\frac{\\left(2m-|S|\\right)\\exp\\left(-C_{l}C_{b}^{2}\\gamma^{2}R p\\right)}{2C_{l}}\\biggr]\\geq\\underset{\\mathbf{c},\\mathcal{H}_{p,\\mathbf{c},R}}{\\mathrm{Pr}}[X\\geq\\mathbb{E}[X]/2]}\\\\ &{\\geq1-\\exp(-\\mathbb{E}[X]/8)\\geq1-\\exp\\left(-\\frac{\\left(2m-|S|\\right)\\exp\\left(-C_{l}C_{b}^{2}\\gamma^{2}R p\\right)}{8C_{l}}\\right),}\\end{array}\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "as claimed. ", "page_idx": 22}, {"type": "text", "text": "NeurIPS Paper Checklist ", "text_level": 1, "page_idx": 23}, {"type": "text", "text": "1. Claims ", "text_level": 1, "page_idx": 23}, {"type": "text", "text": "Question: Do the main claims made in the abstract and introduction accurately reflect the paper\u2019s contributions and scope? ", "page_idx": 23}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 23}, {"type": "text", "text": "Justification: The theoretical claims in the introduction and abstract exactly match what we prove in the paper and claim as the scope and contributions. ", "page_idx": 23}, {"type": "text", "text": "Guidelines: ", "page_idx": 23}, {"type": "text", "text": "\u2022 The answer NA means that the abstract and introduction do not include the claims made in the paper.   \n\u2022 The abstract and/or introduction should clearly state the claims made, including the contributions made in the paper and important assumptions and limitations. A No or NA answer to this question will not be perceived well by the reviewers.   \n\u2022 The claims made should match theoretical and experimental results, and reflect how much the results can be expected to generalize to other settings.   \n\u2022 It is fine to include aspirational goals as motivation as long as it is clear that these goals are not attained by the paper. ", "page_idx": 23}, {"type": "text", "text": "2. Limitations ", "text_level": 1, "page_idx": 23}, {"type": "text", "text": "Question: Does the paper discuss the limitations of the work performed by the authors? Answer: [NA] ", "page_idx": 23}, {"type": "text", "text": "", "page_idx": 23}, {"type": "text", "text": "Justification: The paper is theoretical, so given the assumptions of the claims, there are no limitations. ", "page_idx": 23}, {"type": "text", "text": "Guidelines: ", "text_level": 1, "page_idx": 23}, {"type": "text", "text": "\u2022 The answer NA means that the paper has no limitation while the answer No means that the paper has limitations, but those are not discussed in the paper.   \n\u2022 The authors are encouraged to create a separate \"Limitations\" section in their paper.   \n\u2022 The paper should point out any strong assumptions and how robust the results are to violations of these assumptions (e.g., independence assumptions, noiseless settings, model well-specification, asymptotic approximations only holding locally). The authors should reflect on how these assumptions might be violated in practice and what the implications would be.   \n\u2022 The authors should reflect on the scope of the claims made, e.g., if the approach was only tested on a few datasets or with a few runs. In general, empirical results often depend on implicit assumptions, which should be articulated.   \n\u2022 The authors should reflect on the factors that influence the performance of the approach. For example, a facial recognition algorithm may perform poorly when image resolution is low or images are taken in low lighting. Or a speech-to-text system might not be used reliably to provide closed captions for online lectures because it fails to handle technical jargon.   \n\u2022 The authors should discuss the computational efficiency of the proposed algorithms and how they scale with dataset size.   \n\u2022 If applicable, the authors should discuss possible limitations of their approach to address problems of privacy and fairness.   \n\u2022 While the authors might fear that complete honesty about limitations might be used by reviewers as grounds for rejection, a worse outcome might be that reviewers discover limitations that aren\u2019t acknowledged in the paper. The authors should use their best judgment and recognize that individual actions in favor of transparency play an important role in developing norms that preserve the integrity of the community. Reviewers will be specifically instructed to not penalize honesty concerning limitations. ", "page_idx": 23}, {"type": "text", "text": "3. Theory Assumptions and Proofs ", "text_level": 1, "page_idx": 23}, {"type": "text", "text": "Question: For each theoretical result, does the paper provide the full set of assumptions and a complete (and correct) proof? ", "page_idx": 23}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 24}, {"type": "text", "text": "Justification: The main paper includes a proof sketch for both the upper and lower bound. Parts of the formal proofs of the upper bound and lower bound are in the main text and the remaining are in the appendix. ", "page_idx": 24}, {"type": "text", "text": "Guidelines: ", "page_idx": 24}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include theoretical results.   \n\u2022 All the theorems, formulas, and proofs in the paper should be numbered and crossreferenced.   \n\u2022 All assumptions should be clearly stated or referenced in the statement of any theorems.   \n\u2022 The proofs can either appear in the main paper or the supplemental material, but if they appear in the supplemental material, the authors are encouraged to provide a short proof sketch to provide intuition.   \n\u2022 Inversely, any informal proof provided in the core of the paper should be complemented by formal proofs provided in appendix or supplemental material.   \n\u2022 Theorems and Lemmas that the proof relies upon should be properly referenced. ", "page_idx": 24}, {"type": "text", "text": "4. Experimental Result Reproducibility ", "text_level": 1, "page_idx": 24}, {"type": "text", "text": "Question: Does the paper fully disclose all the information needed to reproduce the main experimental results of the paper to the extent that it affects the main claims and/or conclusions of the paper (regardless of whether the code and data are provided or not)? ", "page_idx": 24}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 24}, {"type": "text", "text": "Justification: The paper is theoretical, and we have no experiments, data or code in the paper. ", "page_idx": 24}, {"type": "text", "text": "Guidelines: ", "page_idx": 24}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 If the paper includes experiments, a No answer to this question will not be perceived well by the reviewers: Making the paper reproducible is important, regardless of whether the code and data are provided or not.   \n\u2022 If the contribution is a dataset and/or model, the authors should describe the steps taken to make their results reproducible or verifiable.   \n\u2022 Depending on the contribution, reproducibility can be accomplished in various ways. For example, if the contribution is a novel architecture, describing the architecture fully might suffice, or if the contribution is a specific model and empirical evaluation, it may be necessary to either make it possible for others to replicate the model with the same dataset, or provide access to the model. In general. releasing code and data is often one good way to accomplish this, but reproducibility can also be provided via detailed instructions for how to replicate the results, access to a hosted model (e.g., in the case of a large language model), releasing of a model checkpoint, or other means that are appropriate to the research performed.   \n\u2022 While NeurIPS does not require releasing code, the conference does require all submissions to provide some reasonable avenue for reproducibility, which may depend on the nature of the contribution. For example (a) If the contribution is primarily a new algorithm, the paper should make it clear how to reproduce that algorithm. (b) If the contribution is primarily a new model architecture, the paper should describe the architecture clearly and fully. (c) If the contribution is a new model (e.g., a large language model), then there should either be a way to access this model for reproducing the results or a way to reproduce the model (e.g., with an open-source dataset or instructions for how to construct the dataset). (d) We recognize that reproducibility may be tricky in some cases, in which case authors are welcome to describe the particular way they provide for reproducibility. In the case of closed-source models, it may be that access to the model is limited in some way (e.g., to registered users), but it should be possible for other researchers to have some path to reproducing or verifying the results. ", "page_idx": 24}, {"type": "text", "text": "5. Open access to data and code ", "text_level": 1, "page_idx": 25}, {"type": "text", "text": "Question: Does the paper provide open access to the data and code, with sufficient instructions to faithfully reproduce the main experimental results, as described in supplemental material? ", "page_idx": 25}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 25}, {"type": "text", "text": "Justification: The paper is theoretical, and we have no experiments, data or code in the paper. ", "page_idx": 25}, {"type": "text", "text": "Guidelines: ", "page_idx": 25}, {"type": "text", "text": "\u2022 The answer NA means that paper does not include experiments requiring code.   \n\u2022 Please see the NeurIPS code and data submission guidelines (https://nips.cc/ public/guides/CodeSubmissionPolicy) for more details.   \n\u2022 While we encourage the release of code and data, we understand that this might not be possible, so \u201cNo\u201d is an acceptable answer. Papers cannot be rejected simply for not including code, unless this is central to the contribution (e.g., for a new open-source benchmark).   \n\u2022 The instructions should contain the exact command and environment needed to run to reproduce the results. See the NeurIPS code and data submission guidelines (https: //nips.cc/public/guides/CodeSubmissionPolicy) for more details.   \n\u2022 The authors should provide instructions on data access and preparation, including how to access the raw data, preprocessed data, intermediate data, and generated data, etc.   \n\u2022 The authors should provide scripts to reproduce all experimental results for the new proposed method and baselines. If only a subset of experiments are reproducible, they should state which ones are omitted from the script and why.   \n\u2022 At submission time, to preserve anonymity, the authors should release anonymized versions (if applicable).   \n\u2022 Providing as much information as possible in supplemental material (appended to the paper) is recommended, but including URLs to data and code is permitted. ", "page_idx": 25}, {"type": "text", "text": "6. Experimental Setting/Details ", "text_level": 1, "page_idx": 25}, {"type": "text", "text": "Question: Does the paper specify all the training and test details (e.g., data splits, hyperparameters, how they were chosen, type of optimizer, etc.) necessary to understand the results? ", "page_idx": 25}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 25}, {"type": "text", "text": "Justification: The paper is theoretical, and we have no experiments, data or code in the paper. ", "page_idx": 25}, {"type": "text", "text": "Guidelines: ", "page_idx": 25}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments. \u2022 The experimental setting should be presented in the core of the paper to a level of detail that is necessary to appreciate the results and make sense of them. \u2022 The full details can be provided either with the code, in appendix, or as supplemental material. ", "page_idx": 25}, {"type": "text", "text": "7. Experiment Statistical Significance ", "text_level": 1, "page_idx": 25}, {"type": "text", "text": "Question: Does the paper report error bars suitably and correctly defined or other appropriate information about the statistical significance of the experiments? ", "page_idx": 25}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 25}, {"type": "text", "text": "Justification: The paper is theoretical, and we have no experiments, data or code in the paper. ", "page_idx": 25}, {"type": "text", "text": "Guidelines: ", "page_idx": 25}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments. \u2022 The authors should answer \"Yes\" if the results are accompanied by error bars, confidence intervals, or statistical significance tests, at least for the experiments that support the main claims of the paper. ", "page_idx": 25}, {"type": "text", "text": "\u2022 The factors of variability that the error bars are capturing should be clearly stated (for example, train/test split, initialization, random drawing of some parameter, or overall run with given experimental conditions).   \n\u2022 The method for calculating the error bars should be explained (closed form formula, call to a library function, bootstrap, etc.)   \n\u2022 The assumptions made should be given (e.g., Normally distributed errors).   \n\u2022 It should be clear whether the error bar is the standard deviation or the standard error of the mean.   \n\u2022 It is OK to report 1-sigma error bars, but one should state it. The authors should preferably report a 2-sigma error bar than state that they have a $96\\%$ CI, if the hypothesis of Normality of errors is not verified.   \n\u2022 For asymmetric distributions, the authors should be careful not to show in tables or figures symmetric error bars that would yield results that are out of range (e.g. negative error rates).   \n\u2022 If error bars are reported in tables or plots, The authors should explain in the text how they were calculated and reference the corresponding figures or tables in the text. ", "page_idx": 26}, {"type": "text", "text": "8. Experiments Compute Resources ", "text_level": 1, "page_idx": 26}, {"type": "text", "text": "Question: For each experiment, does the paper provide sufficient information on the computer resources (type of compute workers, memory, time of execution) needed to reproduce the experiments? ", "page_idx": 26}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 26}, {"type": "text", "text": "Justification: The paper is theoretical, and we have no experiments, data or code in the paper. ", "page_idx": 26}, {"type": "text", "text": "Guidelines: ", "page_idx": 26}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 The paper should indicate the type of compute workers CPU or GPU, internal cluster, or cloud provider, including relevant memory and storage.   \n\u2022 The paper should provide the amount of compute required for each of the individual experimental runs as well as estimate the total compute.   \n\u2022 The paper should disclose whether the full research project required more compute than the experiments reported in the paper (e.g., preliminary or failed experiments that didn\u2019t make it into the paper). ", "page_idx": 26}, {"type": "text", "text": "9. Code Of Ethics ", "text_level": 1, "page_idx": 26}, {"type": "text", "text": "Question: Does the research conducted in the paper conform, in every respect, with the NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines? ", "page_idx": 26}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 26}, {"type": "text", "text": "Justification: We see no violations of the NeurIPS Code of Ethics. ", "page_idx": 26}, {"type": "text", "text": "Guidelines: ", "page_idx": 26}, {"type": "text", "text": "\u2022 The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics.   \n\u2022 If the authors answer No, they should explain the special circumstances that require a deviation from the Code of Ethics.   \n\u2022 The authors should make sure to preserve anonymity (e.g., if there is a special consideration due to laws or regulations in their jurisdiction). ", "page_idx": 26}, {"type": "text", "text": "10. Broader Impacts ", "text_level": 1, "page_idx": 26}, {"type": "text", "text": "Question: Does the paper discuss both potential positive societal impacts and negative societal impacts of the work performed? ", "page_idx": 26}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 26}, {"type": "text", "text": "Justification: The result of the paper is theoretical/foundational research, so we have no experiments, data or code in the paper. ", "page_idx": 26}, {"type": "text", "text": "Guidelines: \u2022 The answer NA means that there is no societal impact of the work performed. ", "page_idx": 26}, {"type": "text", "text": "\u2022 If the authors answer NA or No, they should explain why their work has no societal impact or why the paper does not address societal impact.   \n\u2022 Examples of negative societal impacts include potential malicious or unintended uses (e.g., disinformation, generating fake profiles, surveillance), fairness considerations (e.g., deployment of technologies that could make decisions that unfairly impact specific groups), privacy considerations, and security considerations.   \n\u2022 The conference expects that many papers will be foundational research and not tied to particular applications, let alone deployments. However, if there is a direct path to any negative applications, the authors should point it out. For example, it is legitimate to point out that an improvement in the quality of generative models could be used to generate deepfakes for disinformation. On the other hand, it is not needed to point out that a generic algorithm for optimizing neural networks could enable people to train models that generate Deepfakes faster.   \n\u2022 The authors should consider possible harms that could arise when the technology is being used as intended and functioning correctly, harms that could arise when the technology is being used as intended but gives incorrect results, and harms following from (intentional or unintentional) misuse of the technology.   \n\u2022 If there are negative societal impacts, the authors could also discuss possible mitigation strategies (e.g., gated release of models, providing defenses in addition to attacks, mechanisms for monitoring misuse, mechanisms to monitor how a system learns from feedback over time, improving the efficiency and accessibility of ML). ", "page_idx": 27}, {"type": "text", "text": "11. Safeguards ", "text_level": 1, "page_idx": 27}, {"type": "text", "text": "Question: Does the paper describe safeguards that have been put in place for responsible release of data or models that have a high risk for misuse (e.g., pretrained language models, image generators, or scraped datasets)? ", "page_idx": 27}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 27}, {"type": "text", "text": "Justification: The paper is theoretical, and we have no experiments, data or code in the paper. ", "page_idx": 27}, {"type": "text", "text": "Guidelines: ", "page_idx": 27}, {"type": "text", "text": "\u2022 The answer NA means that the paper poses no such risks.   \n\u2022 Released models that have a high risk for misuse or dual-use should be released with necessary safeguards to allow for controlled use of the model, for example by requiring that users adhere to usage guidelines or restrictions to access the model or implementing safety filters.   \n\u2022 Datasets that have been scraped from the Internet could pose safety risks. The authors should describe how they avoided releasing unsafe images.   \n\u2022 We recognize that providing effective safeguards is challenging, and many papers do not require this, but we encourage authors to take this into account and make a best faith effort. ", "page_idx": 27}, {"type": "text", "text": "12. Licenses for existing assets ", "text_level": 1, "page_idx": 27}, {"type": "text", "text": "Question: Are the creators or original owners of assets (e.g., code, data, models), used in the paper, properly credited and are the license and terms of use explicitly mentioned and properly respected? ", "page_idx": 27}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 27}, {"type": "text", "text": "Justification: The paper is theoretical, and we have no experiments, data or code in the paper. ", "page_idx": 27}, {"type": "text", "text": "Guidelines: ", "page_idx": 27}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not use existing assets.   \n\u2022 The authors should cite the original paper that produced the code package or dataset.   \n\u2022 The authors should state which version of the asset is used and, if possible, include a URL.   \n\u2022 The name of the license (e.g., CC-BY 4.0) should be included for each asset.   \n\u2022 For scraped data from a particular source (e.g., website), the copyright and terms of service of that source should be provided.   \n\u2022 If assets are released, the license, copyright information, and terms of use in the package should be provided. For popular datasets, paperswithcode.com/datasets has curated licenses for some datasets. Their licensing guide can help determine the license of a dataset.   \n\u2022 For existing datasets that are re-packaged, both the original license and the license of the derived asset (if it has changed) should be provided.   \n\u2022 If this information is not available online, the authors are encouraged to reach out to the asset\u2019s creators. ", "page_idx": 27}, {"type": "text", "text": "", "page_idx": 28}, {"type": "text", "text": "13. New Assets ", "text_level": 1, "page_idx": 28}, {"type": "text", "text": "Question: Are new assets introduced in the paper well documented and is the documentation provided alongside the assets? ", "page_idx": 28}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 28}, {"type": "text", "text": "Justification: The paper is theoretical, and we have no experiments, data or code in the paper. ", "page_idx": 28}, {"type": "text", "text": "Guidelines: ", "page_idx": 28}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not release new assets.   \n\u2022 Researchers should communicate the details of the dataset/code/model as part of their submissions via structured templates. This includes details about training, license, limitations, etc.   \n\u2022 The paper should discuss whether and how consent was obtained from people whose asset is used.   \n\u2022 At submission time, remember to anonymize your assets (if applicable). You can either create an anonymized URL or include an anonymized zip file. ", "page_idx": 28}, {"type": "text", "text": "14. Crowdsourcing and Research with Human Subjects ", "text_level": 1, "page_idx": 28}, {"type": "text", "text": "Question: For crowdsourcing experiments and research with human subjects, does the paper include the full text of instructions given to participants and screenshots, if applicable, as well as details about compensation (if any)? ", "page_idx": 28}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 28}, {"type": "text", "text": "Justification: The paper is theoretical, and we have no experiments, data or code in the paper. ", "page_idx": 28}, {"type": "text", "text": "Guidelines: ", "page_idx": 28}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u2022 Including this information in the supplemental material is fine, but if the main contribution of the paper involves human subjects, then as much detail as possible should be included in the main paper.   \n\u2022 According to the NeurIPS Code of Ethics, workers involved in data collection, curation, or other labor should be paid at least the minimum wage in the country of the data collector. ", "page_idx": 28}, {"type": "text", "text": "15. Institutional Review Board (IRB) Approvals or Equivalent for Research with Human Subjects ", "page_idx": 28}, {"type": "text", "text": "Question: Does the paper describe potential risks incurred by study participants, whether such risks were disclosed to the subjects, and whether Institutional Review Board (IRB) approvals (or an equivalent approval/review based on the requirements of your country or institution) were obtained? ", "page_idx": 28}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 28}, {"type": "text", "text": "Justification: The paper is theoretical, and we have no experiments, data or code in the paper. ", "page_idx": 28}, {"type": "text", "text": "Guidelines: ", "page_idx": 28}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u2022 Depending on the country in which research is conducted, IRB approval (or equivalent) may be required for any human subjects research. If you obtained IRB approval, you should clearly state this in the paper.   \n\u2022 We recognize that the procedures for this may vary significantly between institutions and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the guidelines for their institution.   \n\u2022 For initial submissions, do not include any information that would break anonymity (if applicable), such as the institution conducting the review. ", "page_idx": 29}]