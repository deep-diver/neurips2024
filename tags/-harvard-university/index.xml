<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>üè¢ Harvard University on NeurIPS 2024</title><link>https://deep-diver.github.io/neurips2024/tags/-harvard-university/</link><description>Recent content in üè¢ Harvard University on NeurIPS 2024</description><generator>Hugo -- gohugo.io</generator><language>en</language><copyright>¬© 2024 AI Paper Reviewer</copyright><lastBuildDate>Thu, 26 Sep 2024 00:00:00 +0000</lastBuildDate><atom:link href="https://deep-diver.github.io/neurips2024/tags/-harvard-university/index.xml" rel="self" type="application/rss+xml"/><item><title>Approximating mutual information of high-dimensional variables using learned representations</title><link>https://deep-diver.github.io/neurips2024/spotlight/hn05dqxyll/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight/hn05dqxyll/</guid><description>Latent Mutual Information (LMI) approximation accurately estimates mutual information in high-dimensional data using low-dimensional learned representations, solving a critical problem in various scie&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight/hn05dqxyll/cover.png"/></item><item><title>Axioms for AI Alignment from Human Feedback</title><link>https://deep-diver.github.io/neurips2024/spotlight/cmbjkpruvw/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight/cmbjkpruvw/</guid><description>This paper revolutionizes AI alignment by applying social choice theory axioms to RLHF, exposing flaws in existing methods and proposing novel, axiomatically guaranteed reward learning rules.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight/cmbjkpruvw/cover.png"/></item><item><title>Emergence of Hidden Capabilities: Exploring Learning Dynamics in Concept Space</title><link>https://deep-diver.github.io/neurips2024/spotlight/owuect6btl/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight/owuect6btl/</guid><description>Generative models learn hidden capabilities suddenly during training, which can be explained and predicted using a novel &amp;lsquo;concept space&amp;rsquo; framework that analyzes learning dynamics and concept signal.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight/owuect6btl/cover.png"/></item><item><title>Evaluating the World Model Implicit in a Generative Model</title><link>https://deep-diver.github.io/neurips2024/spotlight/avk4jfpegy/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight/avk4jfpegy/</guid><description>New metrics reveal that generative models often possess surprisingly incoherent world models, despite seemingly accurate next-token predictions. This incoherence leads to fragility in solving related &amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight/avk4jfpegy/cover.png"/></item><item><title>Generalized Protein Pocket Generation with Prior-Informed Flow Matching</title><link>https://deep-diver.github.io/neurips2024/spotlight/wyvtj77kev/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight/wyvtj77kev/</guid><description>PocketFlow: a novel generative model designs high-affinity protein pockets using prior-informed flow matching, outperforming existing methods.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight/wyvtj77kev/cover.png"/></item><item><title>Hardness of Learning Neural Networks under the Manifold Hypothesis</title><link>https://deep-diver.github.io/neurips2024/spotlight/dkkgkzmni7/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight/dkkgkzmni7/</guid><description>Neural network learnability under the manifold hypothesis is hard except for efficiently sampleable manifolds.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight/dkkgkzmni7/cover.png"/></item><item><title>Honor Among Bandits: No-Regret Learning for Online Fair Division</title><link>https://deep-diver.github.io/neurips2024/spotlight/ocqbc0edjj/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight/ocqbc0edjj/</guid><description>Online fair division algorithm achieves √ï(T¬≤/¬≥) regret while guaranteeing envy-freeness or proportionality in expectation, a result proven tight.</description></item><item><title>Multistable Shape from Shading Emerges from Patch Diffusion</title><link>https://deep-diver.github.io/neurips2024/spotlight/bhsfbjs6j9/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight/bhsfbjs6j9/</guid><description>A novel diffusion model reconstructs multimodal shape distributions from shading, mirroring human multistable perception.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight/bhsfbjs6j9/cover.png"/></item><item><title>Optimal ablation for interpretability</title><link>https://deep-diver.github.io/neurips2024/spotlight/opt72tyzwz/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight/opt72tyzwz/</guid><description>Optimal ablation (OA) improves model interpretability by precisely measuring component importance, outperforming existing methods. OA-based importance shines in circuit discovery, factual recall, and &amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight/opt72tyzwz/cover.png"/></item><item><title>Unitary Convolutions for Learning on Graphs and Groups</title><link>https://deep-diver.github.io/neurips2024/spotlight/lg1veqjvuh/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight/lg1veqjvuh/</guid><description>Stable deep learning on graphs achieved using novel unitary group convolutions, preventing over-smoothing and enhancing model robustness.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight/lg1veqjvuh/cover.png"/></item></channel></rss>