<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Text Classification on NeurIPS 2024</title><link>https://deep-diver.github.io/neurips2024/tags/text-classification/</link><description>Recent content in Text Classification on NeurIPS 2024</description><generator>Hugo -- gohugo.io</generator><language>en</language><copyright>Â© 2024 AI Paper Reviewer</copyright><lastBuildDate>Thu, 26 Sep 2024 00:00:00 +0000</lastBuildDate><atom:link href="https://deep-diver.github.io/neurips2024/tags/text-classification/index.xml" rel="self" type="application/rss+xml"/><item><title>Concentrate Attention: Towards Domain-Generalizable Prompt Optimization for Language Models</title><link>https://deep-diver.github.io/neurips2024/posters/zoarr5qmfx/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/zoarr5qmfx/</guid><description>Boost language model performance across domains with &amp;lsquo;Concentration&amp;rsquo;: a new prompt optimization objective that prioritizes stable, deep-layer attention.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/zoarr5qmfx/cover.png"/></item><item><title>Continual Learning with Global Alignment</title><link>https://deep-diver.github.io/neurips2024/posters/4vp0edvy4o/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/4vp0edvy4o/</guid><description>Researchers developed a novel continual learning method achieving state-of-the-art performance by aligning data representations across tasks using pre-trained tokens, eliminating the need for experien&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/4vp0edvy4o/cover.png"/></item><item><title>Is the MMI Criterion Necessary for Interpretability? Degenerating Non-causal Features to Plain Noise for Self-Rationalization</title><link>https://deep-diver.github.io/neurips2024/posters/eaqcvzx30k/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/eaqcvzx30k/</guid><description>New criterion maximizes remaining discrepancy after rationale removal, treating spurious features as noise, improving rationale extraction.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/eaqcvzx30k/cover.png"/></item><item><title>Navigating Extremes: Dynamic Sparsity in Large Output Spaces</title><link>https://deep-diver.github.io/neurips2024/posters/ra6rzoj2zi/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/ra6rzoj2zi/</guid><description>SPARTEX achieves memory-efficient extreme multi-label classification by integrating dynamic sparse training with an auxiliary loss function, enabling end-to-end training with millions of labels on com&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/ra6rzoj2zi/cover.png"/></item><item><title>Soft-Label Integration for Robust Toxicity Classification</title><link>https://deep-diver.github.io/neurips2024/posters/iykhthixg1/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/iykhthixg1/</guid><description>Boosting toxicity classification robustness, this paper introduces a novel bi-level optimization framework integrating crowdsourced soft-labels and GroupDRO to enhance resistance against out-of-distri&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/iykhthixg1/cover.png"/></item></channel></rss>