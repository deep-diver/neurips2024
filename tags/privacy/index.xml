<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Privacy on NeurIPS 2024</title><link>https://deep-diver.github.io/neurips2024/tags/privacy/</link><description>Recent content in Privacy on NeurIPS 2024</description><generator>Hugo -- gohugo.io</generator><language>en</language><copyright>© 2024 AI Paper Reviewer</copyright><lastBuildDate>Thu, 26 Sep 2024 00:00:00 +0000</lastBuildDate><atom:link href="https://deep-diver.github.io/neurips2024/tags/privacy/index.xml" rel="self" type="application/rss+xml"/><item><title>Auditing Privacy Mechanisms via Label Inference Attacks</title><link>https://deep-diver.github.io/neurips2024/spotlight-ai-theory/ai76atrb2y/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-ai-theory/ai76atrb2y/</guid><description>New metrics audit label privatization, revealing differentially private schemes often outperform heuristic methods in the privacy-utility tradeoff.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-ai-theory/ai76atrb2y/cover.png"/></item><item><title>Banded Square Root Matrix Factorization for Differentially Private Model Training</title><link>https://deep-diver.github.io/neurips2024/posters/ksytvgosrx/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/ksytvgosrx/</guid><description>This paper introduces BSR, a novel banded square root matrix factorization for differentially private model training. Unlike existing methods, BSR avoids computationally expensive optimization, enabli&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/ksytvgosrx/cover.png"/></item><item><title>Can Graph Neural Networks Expose Training Data Properties? An Efficient Risk Assessment Approach</title><link>https://deep-diver.github.io/neurips2024/posters/luxk3z1tsg/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/luxk3z1tsg/</guid><description>New efficient attack reveals GNN model training data properties.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/luxk3z1tsg/cover.png"/></item><item><title>Credit Attribution and Stable Compression</title><link>https://deep-diver.github.io/neurips2024/posters/crlfvsorzt/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/crlfvsorzt/</guid><description>New definitions of differential privacy enable machine learning algorithms to credit sources appropriately, balancing data utility and copyright compliance.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/crlfvsorzt/cover.png"/></item><item><title>Debiasing Synthetic Data Generated by Deep Generative Models</title><link>https://deep-diver.github.io/neurips2024/posters/aetbfmccwg/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/aetbfmccwg/</guid><description>Debiasing synthetic data generated by deep generative models enhances statistical convergence rates, yielding reliable results for specific analyses.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/aetbfmccwg/cover.png"/></item><item><title>Differentially Private Graph Diffusion with Applications in Personalized PageRanks</title><link>https://deep-diver.github.io/neurips2024/posters/aon7bwybiq/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/aon7bwybiq/</guid><description>This paper introduces a novel differentially private graph diffusion framework ensuring edge-level privacy, significantly improving utility-privacy trade-offs for personalized PageRank computation.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/aon7bwybiq/cover.png"/></item><item><title>Differentially Private Optimization with Sparse Gradients</title><link>https://deep-diver.github.io/neurips2024/posters/4ktifp48wd/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/4ktifp48wd/</guid><description>This paper presents new, nearly optimal differentially private algorithms for handling sparse gradients, significantly improving efficiency and scalability in large embedding models.</description></item><item><title>Differentially Private Reinforcement Learning with Self-Play</title><link>https://deep-diver.github.io/neurips2024/posters/t07ohxceyp/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/t07ohxceyp/</guid><description>This paper presents DP-Nash-VI, a novel algorithm ensuring trajectory-wise privacy in multi-agent reinforcement learning, achieving near-optimal regret bounds under both joint and local differential p&amp;hellip;</description></item><item><title>Differentially Private Stochastic Gradient Descent with Fixed-Size Minibatches: Tighter RDP Guarantees with or without Replacement</title><link>https://deep-diver.github.io/neurips2024/posters/tjskngasmy/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/tjskngasmy/</guid><description>Tighter differential privacy (RDP) guarantees for DP-SGD with fixed-size minibatches are achieved, improving private deep learning model training.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/tjskngasmy/cover.png"/></item><item><title>DOPPLER: Differentially Private Optimizers with Low-pass Filter for Privacy Noise Reduction</title><link>https://deep-diver.github.io/neurips2024/posters/r8yntmad0g/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/r8yntmad0g/</guid><description>DOPPLER, a novel low-pass filter, significantly enhances differentially private (DP) optimizer performance by reducing the impact of privacy noise, bridging the gap between DP and non-DP training.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/r8yntmad0g/cover.png"/></item><item><title>Exactly Minimax-Optimal Locally Differentially Private Sampling</title><link>https://deep-diver.github.io/neurips2024/posters/dr7uarlhve/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/dr7uarlhve/</guid><description>This paper provides the first exact minimax-optimal mechanisms for locally differentially private sampling, applicable across all f-divergences.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/dr7uarlhve/cover.png"/></item><item><title>Faster Algorithms for User-Level Private Stochastic Convex Optimization</title><link>https://deep-diver.github.io/neurips2024/posters/hnlk9cigo9/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/hnlk9cigo9/</guid><description>Faster algorithms achieve optimal excess risk in user-level private stochastic convex optimization, overcoming limitations of prior methods without restrictive assumptions.</description></item><item><title>Faster Differentially Private Top-$k$ Selection: A Joint Exponential Mechanism with Pruning</title><link>https://deep-diver.github.io/neurips2024/posters/qyxe3w9yni/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/qyxe3w9yni/</guid><description>Faster differentially private top-k selection achieved via a novel joint exponential mechanism with pruning, reducing time complexity from O(dk) to O(d+k²/ɛlnd).</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/qyxe3w9yni/cover.png"/></item><item><title>Instance-Optimal Private Density Estimation in the Wasserstein Distance</title><link>https://deep-diver.github.io/neurips2024/posters/apq6corvfz/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/apq6corvfz/</guid><description>Instance-optimal private density estimation algorithms, adapting to data characteristics for improved accuracy in the Wasserstein distance, are introduced.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/apq6corvfz/cover.png"/></item><item><title>Instance-Specific Asymmetric Sensitivity in Differential Privacy</title><link>https://deep-diver.github.io/neurips2024/posters/4i2aeav51n/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/4i2aeav51n/</guid><description>New algorithm improves differentially private estimations by adapting to dataset hardness, enhancing accuracy for variance, classification, and regression tasks.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/4i2aeav51n/cover.png"/></item><item><title>Langevin Unlearning: A New Perspective of Noisy Gradient Descent for Machine Unlearning</title><link>https://deep-diver.github.io/neurips2024/spotlight-ai-theory/3lkuc8rbyv/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-ai-theory/3lkuc8rbyv/</guid><description>Langevin unlearning offers a novel, privacy-preserving machine unlearning framework based on noisy gradient descent, handling both convex and non-convex problems efficiently.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-ai-theory/3lkuc8rbyv/cover.png"/></item><item><title>Locally Private and Robust Multi-Armed Bandits</title><link>https://deep-diver.github.io/neurips2024/posters/bohnxyipww/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/bohnxyipww/</guid><description>This research unveils a fundamental interplay between local differential privacy (LDP) and robustness against data corruption and heavy-tailed rewards in multi-armed bandits, offering a tight characte&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/bohnxyipww/cover.png"/></item><item><title>Nearly Tight Black-Box Auditing of Differentially Private Machine Learning</title><link>https://deep-diver.github.io/neurips2024/posters/ccdmxxiamp/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/ccdmxxiamp/</guid><description>This paper presents a new auditing method for DP-SGD that provides substantially tighter black-box privacy analyses than previous methods, yielding significantly closer empirical estimates to theoreti&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/ccdmxxiamp/cover.png"/></item><item><title>On Differentially Private Subspace Estimation in a Distribution-Free Setting</title><link>https://deep-diver.github.io/neurips2024/posters/acchvnwnlf/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/acchvnwnlf/</guid><description>This paper presents novel measures quantifying data easiness for DP subspace estimation, supporting them with improved upper and lower bounds and a practical algorithm.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/acchvnwnlf/cover.png"/></item><item><title>On Differentially Private U Statistics</title><link>https://deep-diver.github.io/neurips2024/posters/zapfyclg6k/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/zapfyclg6k/</guid><description>New algorithms achieve near-optimal differentially private U-statistic estimation, significantly improving accuracy over existing methods.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/zapfyclg6k/cover.png"/></item><item><title>On provable privacy vulnerabilities of graph representations</title><link>https://deep-diver.github.io/neurips2024/posters/lsqdcfx3xu/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/lsqdcfx3xu/</guid><description>Graph representation learning&amp;rsquo;s structural vulnerabilities are proven and mitigated via noisy aggregation, revealing crucial privacy-utility trade-offs.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/lsqdcfx3xu/cover.png"/></item><item><title>On the Ability of Developers' Training Data Preservation of Learnware</title><link>https://deep-diver.github.io/neurips2024/posters/wsqdjhpuhn/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/wsqdjhpuhn/</guid><description>Learnware systems enable model reuse; this paper proves RKME specifications protect developers&amp;rsquo; training data while enabling effective model identification.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/wsqdjhpuhn/cover.png"/></item><item><title>On the Computational Complexity of Private High-dimensional Model Selection</title><link>https://deep-diver.github.io/neurips2024/posters/pzg7xvlyqm/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/pzg7xvlyqm/</guid><description>This paper proposes a computationally efficient, differentially private best subset selection method for high-dimensional sparse linear regression, achieving both strong statistical utility and provab&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/pzg7xvlyqm/cover.png"/></item><item><title>Oracle-Efficient Differentially Private Learning with Public Data</title><link>https://deep-diver.github.io/neurips2024/posters/bajjinf0oh/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/bajjinf0oh/</guid><description>This paper introduces computationally efficient algorithms for differentially private learning by leveraging public data, overcoming previous computational limitations and enabling broader practical a&amp;hellip;</description></item><item><title>OSLO: One-Shot Label-Only Membership Inference Attacks</title><link>https://deep-diver.github.io/neurips2024/posters/zjbbeyeayx/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/zjbbeyeayx/</guid><description>One-shot label-only attack (OSLO) achieves high membership inference accuracy with only one query, surpassing existing methods by a large margin.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/zjbbeyeayx/cover.png"/></item><item><title>Prior-itizing Privacy: A Bayesian Approach to Setting the Privacy Budget in Differential Privacy</title><link>https://deep-diver.github.io/neurips2024/posters/kamaxsjxgv/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/kamaxsjxgv/</guid><description>This paper introduces a Bayesian approach to setting the privacy budget in differential privacy, enabling agencies to balance data utility and confidentiality by customizing risk profiles.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/kamaxsjxgv/cover.png"/></item><item><title>Privacy Backdoors: Enhancing Membership Inference through Poisoning Pre-trained Models</title><link>https://deep-diver.github.io/neurips2024/posters/kppbawjbry/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/kppbawjbry/</guid><description>Researchers reveal &amp;lsquo;privacy backdoors,&amp;rsquo; a new attack that exploits pre-trained models to leak user training data, highlighting critical vulnerabilities and prompting stricter model security measures.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/kppbawjbry/cover.png"/></item><item><title>Private Edge Density Estimation for Random Graphs: Optimal, Efficient and Robust</title><link>https://deep-diver.github.io/neurips2024/spotlight-ai-theory/4nq24chnoi/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-ai-theory/4nq24chnoi/</guid><description>This paper delivers a groundbreaking polynomial-time algorithm for optimally estimating edge density in random graphs while ensuring node privacy and robustness against data corruption.</description></item><item><title>Private Geometric Median</title><link>https://deep-diver.github.io/neurips2024/posters/cpzjn7kabv/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/cpzjn7kabv/</guid><description>This paper introduces new differentially private algorithms to compute the geometric median, achieving improved accuracy by scaling with the effective data diameter instead of a known radius.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/cpzjn7kabv/cover.png"/></item><item><title>Private Stochastic Convex Optimization with Heavy Tails: Near-Optimality from Simple Reductions</title><link>https://deep-diver.github.io/neurips2024/posters/ox6ail9f0y/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/ox6ail9f0y/</guid><description>Achieving near-optimal rates for differentially private stochastic convex optimization with heavy-tailed gradients is possible using simple reduction-based techniques.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/ox6ail9f0y/cover.png"/></item><item><title>PrivCirNet: Efficient Private Inference via Block Circulant Transformation</title><link>https://deep-diver.github.io/neurips2024/posters/vpsx3n6ice/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/vpsx3n6ice/</guid><description>PrivCirNet accelerates private deep learning inference by cleverly transforming DNN weights into circulant matrices, converting matrix-vector multiplications into efficient 1D convolutions suitable fo&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/vpsx3n6ice/cover.png"/></item><item><title>Reconstruction Attacks on Machine Unlearning: Simple Models are Vulnerable</title><link>https://deep-diver.github.io/neurips2024/posters/i4gqcm1r3z/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/i4gqcm1r3z/</guid><description>Deleting data from machine learning models exposes individuals to highly accurate reconstruction attacks, even when models are simple; this research demonstrates the vulnerability.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/i4gqcm1r3z/cover.png"/></item><item><title>Reimagining Mutual Information for Enhanced Defense against Data Leakage in Collaborative Inference</title><link>https://deep-diver.github.io/neurips2024/posters/tdzlky9usl/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/tdzlky9usl/</guid><description>InfoScissors defends collaborative inference from data leakage by cleverly reducing the mutual information between model outputs and sensitive device data, thus ensuring robust privacy without comprom&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/tdzlky9usl/cover.png"/></item><item><title>Revisiting Differentially Private ReLU Regression</title><link>https://deep-diver.github.io/neurips2024/posters/3uuiwmxybr/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/3uuiwmxybr/</guid><description>Differentially private ReLU regression algorithms, DP-GLMtron and DP-TAGLMtron, achieve comparable performance with only an additional factor of O(log N) in the utility upper bound compared to the con&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/3uuiwmxybr/cover.png"/></item><item><title>Sample-Efficient Private Learning of Mixtures of Gaussians</title><link>https://deep-diver.github.io/neurips2024/spotlight-ai-theory/74b6qx62vw/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-ai-theory/74b6qx62vw/</guid><description>Researchers achieve a breakthrough in privacy-preserving machine learning by developing sample-efficient algorithms for learning Gaussian Mixture Models, significantly reducing the data needed while m&amp;hellip;</description></item><item><title>The Limits of Differential Privacy in Online Learning</title><link>https://deep-diver.github.io/neurips2024/posters/cqr6e81ib7/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/cqr6e81ib7/</guid><description>This paper reveals fundamental limits of differential privacy in online learning, demonstrating a clear separation between pure, approximate, and non-private settings.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/cqr6e81ib7/cover.png"/></item><item><title>Truthful High Dimensional Sparse Linear Regression</title><link>https://deep-diver.github.io/neurips2024/posters/zmiad3jazn/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/zmiad3jazn/</guid><description>This paper presents a novel, truthful, and privacy-preserving mechanism for high-dimensional sparse linear regression, incentivizing data contribution while safeguarding individual privacy.</description></item><item><title>Universal Exact Compression of Differentially Private Mechanisms</title><link>https://deep-diver.github.io/neurips2024/posters/cggjt8eg8a/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/cggjt8eg8a/</guid><description>Poisson Private Representation (PPR) enables exact compression of any local differential privacy mechanism, achieving order-wise optimal trade-offs between communication, accuracy, and privacy.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/cggjt8eg8a/cover.png"/></item></channel></rss>