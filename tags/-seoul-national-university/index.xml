<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>üè¢ Seoul National University on NeurIPS 2024</title><link>https://deep-diver.github.io/neurips2024/tags/-seoul-national-university/</link><description>Recent content in üè¢ Seoul National University on NeurIPS 2024</description><generator>Hugo -- gohugo.io</generator><language>en</language><copyright>¬© 2025 AI Paper Reviewer</copyright><lastBuildDate>Thu, 26 Sep 2024 00:00:00 +0000</lastBuildDate><atom:link href="https://deep-diver.github.io/neurips2024/tags/-seoul-national-university/index.xml" rel="self" type="application/rss+xml"/><item><title>4D Gaussian Splatting in the Wild with Uncertainty-Aware Regularization</title><link>https://deep-diver.github.io/neurips2024/posters/0syctgl4in/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/0syctgl4in/</guid><description>Uncertainty-aware 4D Gaussian Splatting enhances dynamic scene reconstruction from monocular videos by selectively applying regularization to uncertain regions, improving both novel view synthesis and&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/0syctgl4in/cover.png"/></item><item><title>A Gradient Accumulation Method for Dense Retriever under Memory Constraint</title><link>https://deep-diver.github.io/neurips2024/posters/qdg2q5myhv/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/qdg2q5myhv/</guid><description>CONTACCUM: Stable, efficient memory reduction for dense retrievers using dual memory banks, surpassing high-resource baselines.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/qdg2q5myhv/cover.png"/></item><item><title>A Versatile Diffusion Transformer with Mixture of Noise Levels for Audiovisual Generation</title><link>https://deep-diver.github.io/neurips2024/posters/cs1hisjklu/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/cs1hisjklu/</guid><description>A single model tackles diverse audiovisual generation tasks using a novel Mixture of Noise Levels approach, resulting in temporally consistent and high-quality outputs.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/cs1hisjklu/cover.png"/></item><item><title>Adversarial Environment Design via Regret-Guided Diffusion Models</title><link>https://deep-diver.github.io/neurips2024/spotlight-reinforcement-learning/eezclkwx6t/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-reinforcement-learning/eezclkwx6t/</guid><description>Regret-Guided Diffusion Models enhance unsupervised environment design by generating challenging, diverse training environments that improve agent robustness and zero-shot generalization.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-reinforcement-learning/eezclkwx6t/cover.png"/></item><item><title>An Adaptive Approach for Infinitely Many-armed Bandits under Generalized Rotting Constraints</title><link>https://deep-diver.github.io/neurips2024/posters/1cxdndzkxu/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/1cxdndzkxu/</guid><description>Adaptive algorithm achieves tight regret bounds for infinitely many-armed bandits under generalized rotting constraints, addressing the challenge of decreasing rewards over time.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/1cxdndzkxu/cover.png"/></item><item><title>Are Self-Attentions Effective for Time Series Forecasting?</title><link>https://deep-diver.github.io/neurips2024/posters/in43sjoib7/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/in43sjoib7/</guid><description>Cross-Attention-only Time Series Transformer (CATS) outperforms existing models by removing self-attention, improving long-term forecasting accuracy, and reducing computational cost.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/in43sjoib7/cover.png"/></item><item><title>DropBP: Accelerating Fine-Tuning of Large Language Models by Dropping Backward Propagation</title><link>https://deep-diver.github.io/neurips2024/posters/x4eotqw7ka/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/x4eotqw7ka/</guid><description>DropBP: Accelerate LLM fine-tuning by 44% while preserving accuracy!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/x4eotqw7ka/cover.png"/></item><item><title>FedAvP: Augment Local Data via Shared Policy in Federated Learning</title><link>https://deep-diver.github.io/neurips2024/posters/m1pru0x1iz/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/m1pru0x1iz/</guid><description>FedAvP enhances federated learning&amp;rsquo;s privacy by sharing only augmentation policies, improving performance in diverse settings.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/m1pru0x1iz/cover.png"/></item><item><title>FIFO-Diffusion: Generating Infinite Videos from Text without Training</title><link>https://deep-diver.github.io/neurips2024/posters/uikhna4wam/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/uikhna4wam/</guid><description>FIFO-Diffusion generates infinitely long, high-quality videos from text prompts using a pretrained model, solving the challenge of long video generation without retraining.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/uikhna4wam/cover.png"/></item><item><title>Gated Inference Network: Inference and Learning State-Space Models</title><link>https://deep-diver.github.io/neurips2024/posters/z4duw3kzld/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/z4duw3kzld/</guid><description>GIN, a novel approximate Bayesian inference algorithm, efficiently handles nonlinear state-space models with high-dimensional, noisy observations by disentangling observation and dynamics. Achieving l&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/z4duw3kzld/cover.png"/></item><item><title>Gradient-free Decoder Inversion in Latent Diffusion Models</title><link>https://deep-diver.github.io/neurips2024/posters/nbqvjkos6s/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/nbqvjkos6s/</guid><description>This paper introduces a novel gradient-free decoder inversion method for latent diffusion models, improving efficiency and memory usage compared to existing gradient-based methods. The method is theo&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/nbqvjkos6s/cover.png"/></item><item><title>Improved Regret of Linear Ensemble Sampling</title><link>https://deep-diver.github.io/neurips2024/posters/6sszmq3wtn/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/6sszmq3wtn/</guid><description>Linear ensemble sampling achieves a state-of-the-art regret bound of √ï(d¬≥/¬≤‚àöT) with a logarithmic ensemble size, closing the theory-practice gap in linear bandit algorithms.</description></item><item><title>Introducing Spectral Attention for Long-Range Dependency in Time Series Forecasting</title><link>https://deep-diver.github.io/neurips2024/posters/dxynvebqmp/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/dxynvebqmp/</guid><description>Spectral Attention boosts long-range dependency capture in time series forecasting, achieving state-of-the-art results across various models and datasets.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/dxynvebqmp/cover.png"/></item><item><title>Mitigating Spurious Correlations via Disagreement Probability</title><link>https://deep-diver.github.io/neurips2024/posters/obujbhbx8o/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/obujbhbx8o/</guid><description>DPR, a novel bias mitigation method, robustly improves model performance by leveraging disagreement probability without needing bias labels, achieving state-of-the-art results.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/obujbhbx8o/cover.png"/></item><item><title>Mixture of Scales: Memory-Efficient Token-Adaptive Binarization for Large Language Models</title><link>https://deep-diver.github.io/neurips2024/posters/pgobeycxzs/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/pgobeycxzs/</guid><description>BinaryMoS: a novel token-adaptive binarization method that boosts LLM accuracy and efficiency by dynamically merging multiple scaling experts for each token.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/pgobeycxzs/cover.png"/></item><item><title>Nearly Minimax Optimal Regret for Multinomial Logistic Bandit</title><link>https://deep-diver.github.io/neurips2024/posters/q4nwfstqvf/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/q4nwfstqvf/</guid><description>This paper presents OFU-MNL+, a constant-time algorithm achieving nearly minimax optimal regret for contextual multinomial logistic bandits, closing the gap between existing upper and lower bounds.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/q4nwfstqvf/cover.png"/></item><item><title>Paralinguistics-Aware Speech-Empowered Large Language Models for Natural Conversation</title><link>https://deep-diver.github.io/neurips2024/posters/njewxjudyq/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/njewxjudyq/</guid><description>Unified Spoken Dialog Model (USDM) directly generates coherent spoken responses with natural prosody, surpassing cascaded baselines and enhancing natural conversation in speech-enabled LLMs.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/njewxjudyq/cover.png"/></item><item><title>Queueing Matching Bandits with Preference Feedback</title><link>https://deep-diver.github.io/neurips2024/posters/0tumaab3of/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/0tumaab3of/</guid><description>Novel algorithms stabilize multi-server queueing systems with unknown service rates, achieving sublinear regret by learning server preferences via preference feedback.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/0tumaab3of/cover.png"/></item><item><title>Randomized Exploration for Reinforcement Learning with Multinomial Logistic Function Approximation</title><link>https://deep-diver.github.io/neurips2024/posters/7trth0aobl/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/7trth0aobl/</guid><description>First provably efficient randomized RL algorithms using multinomial logistic function approximation are introduced, achieving superior performance and constant-time computational cost.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/7trth0aobl/cover.png"/></item><item><title>Sample Selection via Contrastive Fragmentation for Noisy Label Regression</title><link>https://deep-diver.github.io/neurips2024/posters/gyd5afzaor/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/gyd5afzaor/</guid><description>ConFrag, a novel approach to noisy label regression, leverages contrastive fragmentation and neighborhood agreement to select clean samples, significantly outperforming state-of-the-art baselines on s&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/gyd5afzaor/cover.png"/></item><item><title>Self-Guided Masked Autoencoder</title><link>https://deep-diver.github.io/neurips2024/posters/7vxufiezsy/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/7vxufiezsy/</guid><description>Self-guided MAE boosts self-supervised learning by intelligently masking image patches based on internal clustering patterns, dramatically accelerating training without external data.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/7vxufiezsy/cover.png"/></item><item><title>Spectral-Risk Safe Reinforcement Learning with Convergence Guarantees</title><link>https://deep-diver.github.io/neurips2024/posters/9jfsjitkc0/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/9jfsjitkc0/</guid><description>SRCPO: a novel spectral risk measure-constrained RL algorithm guaranteeing convergence to a global optimum, outperforming existing methods in continuous control tasks.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/9jfsjitkc0/cover.png"/></item><item><title>Textual Training for the Hassle-Free Removal of Unwanted Visual Data: Case Studies on OOD and Hateful Image Detection</title><link>https://deep-diver.github.io/neurips2024/posters/xerwgdxafu/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/xerwgdxafu/</guid><description>Hassle-Free Textual Training (HFTT) uses only textual data to effectively remove unwanted visual data from AI training datasets, significantly reducing human annotation needs.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/xerwgdxafu/cover.png"/></item></channel></rss>