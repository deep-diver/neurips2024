<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Image Generation on NeurIPS 2024</title><link>https://deep-diver.github.io/neurips2024/tags/image-generation/</link><description>Recent content in Image Generation on NeurIPS 2024</description><generator>Hugo -- gohugo.io</generator><language>en</language><copyright>© 2024 AI Paper Reviewer</copyright><lastBuildDate>Thu, 26 Sep 2024 00:00:00 +0000</lastBuildDate><atom:link href="https://deep-diver.github.io/neurips2024/tags/image-generation/index.xml" rel="self" type="application/rss+xml"/><item><title>2DQuant: Low-bit Post-Training Quantization for Image Super-Resolution</title><link>https://deep-diver.github.io/neurips2024/posters/adjase9uq2/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/adjase9uq2/</guid><description>2DQuant achieves highly efficient and accurate low-bit image super-resolution by using a dual-stage post-training quantization method that minimizes accuracy loss in transformer-based models, surpassi&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/adjase9uq2/cover.png"/></item><item><title>A Modular Conditional Diffusion Framework for Image Reconstruction</title><link>https://deep-diver.github.io/neurips2024/posters/mecc0is5hs/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/mecc0is5hs/</guid><description>A novel modular diffusion framework for image reconstruction dramatically cuts computational costs and achieves state-of-the-art perceptual quality across various tasks by cleverly combining pre-train&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/mecc0is5hs/cover.png"/></item><item><title>ACFun: Abstract-Concrete Fusion Facial Stylization</title><link>https://deep-diver.github.io/neurips2024/posters/d2vk206haj/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/d2vk206haj/</guid><description>ACFun: A novel facial stylization method fusing abstract &amp;amp; concrete features for high-quality, artistically pleasing results from only one style &amp;amp; one face image.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/d2vk206haj/cover.png"/></item><item><title>Action Imitation in Common Action Space for Customized Action Image Synthesis</title><link>https://deep-diver.github.io/neurips2024/posters/h2e4g2yiwr/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/h2e4g2yiwr/</guid><description>TwinAct: Decoupling actions and actors for customizable text-guided action image generation.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/h2e4g2yiwr/cover.png"/></item><item><title>Adapting Diffusion Models for Improved Prompt Compliance and Controllable Image Synthesis</title><link>https://deep-diver.github.io/neurips2024/posters/sntv8ac3u2/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/sntv8ac3u2/</guid><description>FG-DMs revolutionize image synthesis by jointly modeling image and condition distributions, achieving higher object recall and enabling flexible editing.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/sntv8ac3u2/cover.png"/></item><item><title>Adversarial Schrödinger Bridge Matching</title><link>https://deep-diver.github.io/neurips2024/posters/l3knnigicu/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/l3knnigicu/</guid><description>Accelerate Schrödinger Bridge Matching with Discrete-time IMF using only a few steps, achieving comparable results to existing hundred-step methods via D-GAN implementation.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/l3knnigicu/cover.png"/></item><item><title>AID: Attention Interpolation of Text-to-Image Diffusion</title><link>https://deep-diver.github.io/neurips2024/posters/nb5xlelv0c/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/nb5xlelv0c/</guid><description>AID, a novel training-free method, significantly improves image interpolation by fusing inner/outer interpolated attention layers and using beta-distribution for coefficient selection, enhancing consi&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/nb5xlelv0c/cover.png"/></item><item><title>AirSketch: Generative Motion to Sketch</title><link>https://deep-diver.github.io/neurips2024/posters/ttlcbekaj6/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/ttlcbekaj6/</guid><description>AirSketch generates aesthetically pleasing sketches directly from noisy hand-motion tracking data using a self-supervised controllable diffusion model, eliminating the need for expensive AR/VR equipme&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/ttlcbekaj6/cover.png"/></item><item><title>Aligning Diffusion Models by Optimizing Human Utility</title><link>https://deep-diver.github.io/neurips2024/posters/mtmshu5qac/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/mtmshu5qac/</guid><description>Diffusion-KTO: Aligning text-to-image models with human preferences using simple likes/dislikes, maximizing expected human utility.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/mtmshu5qac/cover.png"/></item><item><title>Alleviating Distortion in Image Generation via Multi-Resolution Diffusion Models and Time-Dependent Layer Normalization</title><link>https://deep-diver.github.io/neurips2024/posters/3jwmwl8i5f/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/3jwmwl8i5f/</guid><description>DiMR boosts image generation fidelity by cleverly combining multi-resolution networks with time-dependent layer normalization in diffusion models, achieving state-of-the-art results on ImageNet.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/3jwmwl8i5f/cover.png"/></item><item><title>An Expectation-Maximization Algorithm for Training Clean Diffusion Models from Corrupted Observations</title><link>https://deep-diver.github.io/neurips2024/posters/jurbh4v9n4/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/jurbh4v9n4/</guid><description>EMDiffusion trains clean diffusion models from corrupted data using an expectation-maximization algorithm, achieving state-of-the-art results on diverse imaging tasks.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/jurbh4v9n4/cover.png"/></item><item><title>An Image is Worth 32 Tokens for Reconstruction and Generation</title><link>https://deep-diver.github.io/neurips2024/posters/toxoqprzpl/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/toxoqprzpl/</guid><description>Image generation gets a speed boost with TiTok, a novel 1D image tokenizer that uses just 32 tokens for high-quality image reconstruction and generation, achieving up to 410x faster processing than st&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/toxoqprzpl/cover.png"/></item><item><title>AnyFit: Controllable Virtual Try-on for Any Combination of Attire Across Any Scenario</title><link>https://deep-diver.github.io/neurips2024/posters/carfm6kkle/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/carfm6kkle/</guid><description>AnyFit: Controllable virtual try-on for any attire combination across any scenario, exceeding existing methods in accuracy and scalability.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/carfm6kkle/cover.png"/></item><item><title>Applying Guidance in a Limited Interval Improves Sample and Distribution Quality in Diffusion Models</title><link>https://deep-diver.github.io/neurips2024/posters/naihvny15t/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/naihvny15t/</guid><description>Boosting image generation: Applying guidance selectively during diffusion model sampling drastically enhances image quality and inference speed, achieving state-of-the-art results.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/naihvny15t/cover.png"/></item><item><title>ART: Automatic Red-teaming for Text-to-Image Models to Protect Benign Users</title><link>https://deep-diver.github.io/neurips2024/posters/h2ato32ilj/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/h2ato32ilj/</guid><description>ART: A novel automatic red-teaming framework reveals safety vulnerabilities in popular text-to-image models by identifying unsafe outputs even from seemingly harmless prompts.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/h2ato32ilj/cover.png"/></item><item><title>AsCAN: Asymmetric Convolution-Attention Networks for Efficient Recognition and Generation</title><link>https://deep-diver.github.io/neurips2024/posters/r0escj6qsl/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/r0escj6qsl/</guid><description>AsCAN, a novel hybrid architecture, achieves superior efficiency and performance in image recognition and generation by asymmetrically combining convolutional and transformer blocks.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/r0escj6qsl/cover.png"/></item><item><title>Association of Objects May Engender Stereotypes: Mitigating Association-Engendered Stereotypes in Text-to-Image Generation</title><link>https://deep-diver.github.io/neurips2024/spotlight-others/shyqxpnblb/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-others/shyqxpnblb/</guid><description>New framework, MAS, effectively mitigates stereotypes in text-to-image generation by aligning the probability distribution of generated images to stereotype-free distributions.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-others/shyqxpnblb/cover.png"/></item><item><title>AsyncDiff: Parallelizing Diffusion Models by Asynchronous Denoising</title><link>https://deep-diver.github.io/neurips2024/posters/46jtdc6gxu/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/46jtdc6gxu/</guid><description>AsyncDiff accelerates diffusion model inference by 2.8x using asynchronous denoising and model parallelism, maintaining near-perfect image quality.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/46jtdc6gxu/cover.png"/></item><item><title>Attack-Resilient Image Watermarking Using Stable Diffusion</title><link>https://deep-diver.github.io/neurips2024/posters/e6krsoughj/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/e6krsoughj/</guid><description>ZoDiac: a novel image watermarking framework leveraging pre-trained stable diffusion models for robust, invisible watermarks resistant to state-of-the-art attacks.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/e6krsoughj/cover.png"/></item><item><title>Autoregressive Image Generation without Vector Quantization</title><link>https://deep-diver.github.io/neurips2024/spotlight-others/vnbif0gmkb/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-others/vnbif0gmkb/</guid><description>Autoregressive image generation is revolutionized by eliminating vector quantization, achieving strong results with increased speed using a novel diffusion procedure.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-others/vnbif0gmkb/cover.png"/></item><item><title>BELM: Bidirectional Explicit Linear Multi-step Sampler for Exact Inversion in Diffusion Models</title><link>https://deep-diver.github.io/neurips2024/posters/ccq4fmwldb/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/ccq4fmwldb/</guid><description>O-BELM, a novel diffusion model sampler, achieves mathematically exact inversion with superior sampling quality, offering a new gold standard for diffusion model applications.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/ccq4fmwldb/cover.png"/></item><item><title>BiDM: Pushing the Limit of Quantization for Diffusion Models</title><link>https://deep-diver.github.io/neurips2024/posters/owaitgb8lj/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/owaitgb8lj/</guid><description>BiDM achieves full 1-bit quantization in diffusion models, significantly improving storage and speed without sacrificing image quality, setting a new state-of-the-art.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/owaitgb8lj/cover.png"/></item><item><title>Binarized Diffusion Model for Image Super-Resolution</title><link>https://deep-diver.github.io/neurips2024/posters/yxpfrlmir2/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/yxpfrlmir2/</guid><description>BI-DiffSR, a novel binarized diffusion model, achieves high-quality image super-resolution with significantly reduced memory and computational costs, outperforming existing methods.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/yxpfrlmir2/cover.png"/></item><item><title>BitsFusion: 1.99 bits Weight Quantization of Diffusion Model</title><link>https://deep-diver.github.io/neurips2024/posters/0m19blqt6y/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/0m19blqt6y/</guid><description>BitsFusion achieves 7.9x smaller Stable Diffusion models by quantizing UNet weights to 1.99 bits, surprisingly improving image generation quality!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/0m19blqt6y/cover.png"/></item><item><title>BLAST: Block-Level Adaptive Structured Matrices for Efficient Deep Neural Network Inference</title><link>https://deep-diver.github.io/neurips2024/posters/n0ars0ddot/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/n0ars0ddot/</guid><description>BLAST matrix learns efficient weight structures for faster deep learning inference, achieving significant compression and performance gains on various models.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/n0ars0ddot/cover.png"/></item><item><title>Blind Image Restoration via Fast Diffusion Inversion</title><link>https://deep-diver.github.io/neurips2024/posters/hfsjlbrkkj/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/hfsjlbrkkj/</guid><description>BIRD: a novel blind image restoration method jointly optimizes degradation model parameters and the restored image, ensuring realistic outputs via fast diffusion inversion and achieving state-of-the-a&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/hfsjlbrkkj/cover.png"/></item><item><title>BrainBits: How Much of the Brain are Generative Reconstruction Methods Using?</title><link>https://deep-diver.github.io/neurips2024/posters/kaauvi4kpb/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/kaauvi4kpb/</guid><description>BrainBits reveals that surprisingly little brain information is needed for high-fidelity image &amp;amp; text reconstruction, highlighting the dominance of generative model priors over neural signal extractio&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/kaauvi4kpb/cover.png"/></item><item><title>Breaking Semantic Artifacts for Generalized AI-generated Image Detection</title><link>https://deep-diver.github.io/neurips2024/posters/ntntfrtje8/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/ntntfrtje8/</guid><description>Researchers developed a new AI-generated image detection method that overcomes the limitation of existing detectors, achieving superior cross-scene generalization by shuffling image patches and traini&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/ntntfrtje8/cover.png"/></item><item><title>Can Simple Averaging Defeat Modern Watermarks?</title><link>https://deep-diver.github.io/neurips2024/posters/x2g7la7av9/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/x2g7la7av9/</guid><description>Simple averaging of watermarked images reveals hidden patterns, enabling watermark removal and forgery, thus highlighting the vulnerability of content-agnostic watermarking methods.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/x2g7la7av9/cover.png"/></item><item><title>Classification Diffusion Models: Revitalizing Density Ratio Estimation</title><link>https://deep-diver.github.io/neurips2024/posters/d99ycfonwk/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/d99ycfonwk/</guid><description>Classification Diffusion Models (CDMs) revolutionize density ratio estimation by integrating the strengths of diffusion models and classifiers, achieving state-of-the-art image generation and likeliho&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/d99ycfonwk/cover.png"/></item><item><title>ColJailBreak: Collaborative Generation and Editing for Jailbreaking Text-to-Image Deep Generation</title><link>https://deep-diver.github.io/neurips2024/posters/egizetmate/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/egizetmate/</guid><description>ColJailBreak cleverly circumvents AI safety filters by first generating safe images and then subtly injecting unsafe content using image editing.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/egizetmate/cover.png"/></item><item><title>Consistency Diffusion Bridge Models</title><link>https://deep-diver.github.io/neurips2024/posters/ffjfgx78ok/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/ffjfgx78ok/</guid><description>Consistency Diffusion Bridge Models (CDBMs) dramatically speed up diffusion bridge model sampling by learning a consistency function, achieving up to a 50x speedup with improved sample quality.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/ffjfgx78ok/cover.png"/></item><item><title>Consistency Purification: Effective and Efficient Diffusion Purification towards Certified Robustness</title><link>https://deep-diver.github.io/neurips2024/posters/tlwoxftjvh/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/tlwoxftjvh/</guid><description>Consistency Purification boosts certified robustness by efficiently purifying noisy images using a one-step generative model, achieving state-of-the-art results while maintaining semantic alignment.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/tlwoxftjvh/cover.png"/></item><item><title>Constrained Diffusion with Trust Sampling</title><link>https://deep-diver.github.io/neurips2024/posters/djub9xrozi/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/djub9xrozi/</guid><description>Trust Sampling enhances guided diffusion by iteratively optimizing constrained generation at each step, improving efficiency and accuracy in image and 3D motion generation.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/djub9xrozi/cover.png"/></item><item><title>Cooperative Hardware-Prompt Learning for Snapshot Compressive Imaging</title><link>https://deep-diver.github.io/neurips2024/posters/zxswidyw3a/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/zxswidyw3a/</guid><description>Federated Hardware-Prompt Learning (FedHP) enables robust cross-hardware SCI training by aligning inconsistent data distributions using a hardware-conditioned prompter, outperforming existing FL metho&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/zxswidyw3a/cover.png"/></item><item><title>Cross-Scale Self-Supervised Blind Image Deblurring via Implicit Neural Representation</title><link>https://deep-diver.github.io/neurips2024/posters/cfez7mfufd/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/cfez7mfufd/</guid><description>Self-supervised blind image deblurring (BID) breakthrough! A novel cross-scale consistency loss and progressive training scheme using implicit neural representations achieves superior performance wit&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/cfez7mfufd/cover.png"/></item><item><title>CryoGEM: Physics-Informed Generative Cryo-Electron Microscopy</title><link>https://deep-diver.github.io/neurips2024/posters/edozifvwmi/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/edozifvwmi/</guid><description>CryoGEM: Physics-informed generative model creates realistic synthetic cryo-EM datasets, boosting particle picking and pose estimation accuracy for higher-resolution protein structure determination.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/edozifvwmi/cover.png"/></item><item><title>Ctrl-X: Controlling Structure and Appearance for Text-To-Image Generation Without Guidance</title><link>https://deep-diver.github.io/neurips2024/posters/zulwewqop9/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/zulwewqop9/</guid><description>Ctrl-X: Zero-shot text-to-image generation with training-free structure &amp;amp; appearance control!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/zulwewqop9/cover.png"/></item><item><title>Data Attribution for Text-to-Image Models by Unlearning Synthesized Images</title><link>https://deep-diver.github.io/neurips2024/posters/kvr3l73pnh/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/kvr3l73pnh/</guid><description>Unlearning synthesized images efficiently reveals influential training data for text-to-image models, improving data attribution accuracy and facilitating better model understanding.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/kvr3l73pnh/cover.png"/></item><item><title>DDR: Exploiting Deep Degradation Response as Flexible Image Descriptor</title><link>https://deep-diver.github.io/neurips2024/posters/rxlo4zv3wb/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/rxlo4zv3wb/</guid><description>Deep Degradation Response (DDR) uses image deep feature changes under degradation to create a flexible image descriptor, excelling in blind image quality assessment and unsupervised image restoration.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/rxlo4zv3wb/cover.png"/></item><item><title>Dealing with Synthetic Data Contamination in Online Continual Learning</title><link>https://deep-diver.github.io/neurips2024/posters/lc8gemv97y/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/lc8gemv97y/</guid><description>AI-generated images contaminate online continual learning datasets, hindering performance. A new method, ESRM, leverages entropy and real/synthetic similarity maximization to select high-quality data&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/lc8gemv97y/cover.png"/></item><item><title>Defensive Unlearning with Adversarial Training for Robust Concept Erasure in Diffusion Models</title><link>https://deep-diver.github.io/neurips2024/posters/dkpmfiydrf/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/dkpmfiydrf/</guid><description>AdvUnlearn enhances diffusion model robustness against adversarial attacks during concept erasure by integrating adversarial training, improving the trade-off between robustness and model utility.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/dkpmfiydrf/cover.png"/></item><item><title>Diffusion Priors for Variational Likelihood Estimation and Image Denoising</title><link>https://deep-diver.github.io/neurips2024/spotlight-others/oukw8cuiuy/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-others/oukw8cuiuy/</guid><description>Adaptive likelihood estimation and MAP inference during reverse diffusion tackles real-world image noise.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-others/oukw8cuiuy/cover.png"/></item><item><title>Diffusion4D: Fast Spatial-temporal Consistent 4D generation via Video Diffusion Models</title><link>https://deep-diver.github.io/neurips2024/posters/grrefkwees/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/grrefkwees/</guid><description>Diffusion4D: Fast, consistent 4D content generation via a novel 4D-aware video diffusion model, surpassing existing methods in efficiency and 4D geometry consistency.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/grrefkwees/cover.png"/></item><item><title>DiMSUM: Diffusion Mamba - A Scalable and Unified Spatial-Frequency Method for Image Generation</title><link>https://deep-diver.github.io/neurips2024/posters/kqblzsixkm/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/kqblzsixkm/</guid><description>DiMSUM: A novel diffusion model boosts image generation by unifying spatial and frequency information, achieving superior results and faster training.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/kqblzsixkm/cover.png"/></item><item><title>DiP-GO: A Diffusion Pruner via Few-step Gradient Optimization</title><link>https://deep-diver.github.io/neurips2024/posters/sbsarj475e/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/sbsarj475e/</guid><description>DiP-GO: A novel pruning method accelerates diffusion models via few-step gradient optimization, achieving a 4.4x speedup on Stable Diffusion 1.5 without accuracy loss.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/sbsarj475e/cover.png"/></item><item><title>Direct Consistency Optimization for Robust Customization of Text-to-Image Diffusion models</title><link>https://deep-diver.github.io/neurips2024/posters/vazkrbcgxt/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/vazkrbcgxt/</guid><description>Boosting personalized image generation! Direct Consistency Optimization (DCO) fine-tunes text-to-image models, ensuring subject consistency and prompt fidelity, even when merging separately customized&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/vazkrbcgxt/cover.png"/></item><item><title>Direct Unlearning Optimization for Robust and Safe Text-to-Image Models</title><link>https://deep-diver.github.io/neurips2024/posters/udxe5v2d0o/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/udxe5v2d0o/</guid><description>Direct Unlearning Optimization (DUO) robustly removes unsafe content from text-to-image models by using paired image data and output-preserving regularization, effectively defending against adversaria&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/udxe5v2d0o/cover.png"/></item><item><title>Disentangled Style Domain for Implicit $z$-Watermark Towards Copyright Protection</title><link>https://deep-diver.github.io/neurips2024/posters/4vl5qwqfbv/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/4vl5qwqfbv/</guid><description>This paper introduces a novel implicit Zero-Watermarking scheme using disentangled style domains to detect unauthorized dataset usage in text-to-image models, offering robust copyright protection via &amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/4vl5qwqfbv/cover.png"/></item><item><title>DiTFastAttn: Attention Compression for Diffusion Transformer Models</title><link>https://deep-diver.github.io/neurips2024/posters/51hqpkqy3t/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/51hqpkqy3t/</guid><description>DiTFastAttn: A post-training compression method drastically speeds up diffusion transformer models by cleverly reducing redundancy in attention calculations, leading to up to a 1.8x speedup at high re&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/51hqpkqy3t/cover.png"/></item><item><title>DomainGallery: Few-shot Domain-driven Image Generation by Attribute-centric Finetuning</title><link>https://deep-diver.github.io/neurips2024/posters/zmmj1z8vee/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/zmmj1z8vee/</guid><description>DomainGallery: Few-shot domain-driven image generation via attribute-centric finetuning, solving key issues of previous works by introducing attribute erasure, disentanglement, regularization, and enh&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/zmmj1z8vee/cover.png"/></item><item><title>Doubly Hierarchical Geometric Representations for Strand-based Human Hairstyle Generation</title><link>https://deep-diver.github.io/neurips2024/posters/h34jvnpo1c/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/h34jvnpo1c/</guid><description>Doubly hierarchical geometric representations enable realistic human hairstyle generation by separating low and high-frequency details in hair strands, resulting in high-quality, detailed virtual hair&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/h34jvnpo1c/cover.png"/></item><item><title>DRACO: A Denoising-Reconstruction Autoencoder for Cryo-EM</title><link>https://deep-diver.github.io/neurips2024/posters/u1mnglyn74/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/u1mnglyn74/</guid><description>DRACO, a denoising-reconstruction autoencoder, revolutionizes cryo-EM by leveraging a large-scale dataset and hybrid training for superior image denoising and downstream task performance.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/u1mnglyn74/cover.png"/></item><item><title>DreamSteerer: Enhancing Source Image Conditioned Editability using Personalized Diffusion Models</title><link>https://deep-diver.github.io/neurips2024/posters/uekhycx0lz/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/uekhycx0lz/</guid><description>DreamSteerer enhances source image-conditioned editability in personalized diffusion models via a novel Editability Driven Score Distillation objective and mode shifting regularization, achieving sign&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/uekhycx0lz/cover.png"/></item><item><title>ECMamba: Consolidating Selective State Space Model with Retinex Guidance for Efficient Multiple Exposure Correction</title><link>https://deep-diver.github.io/neurips2024/posters/mzsvm58fpg/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/mzsvm58fpg/</guid><description>ECMamba: A novel dual-branch framework efficiently corrects multiple exposure images by integrating Retinex theory and an innovative 2D selective state-space layer, achieving state-of-the-art performa&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/mzsvm58fpg/cover.png"/></item><item><title>EDT: An Efficient Diffusion Transformer Framework Inspired by Human-like Sketching</title><link>https://deep-diver.github.io/neurips2024/posters/mihocxte41/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/mihocxte41/</guid><description>The Efficient Diffusion Transformer (EDT) framework significantly speeds up and improves image generation by leveraging a lightweight architecture, human-like sketching-inspired Attention Modulation M&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/mihocxte41/cover.png"/></item><item><title>EM Distillation for One-step Diffusion Models</title><link>https://deep-diver.github.io/neurips2024/posters/rafvvthuxd/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/rafvvthuxd/</guid><description>EM Distillation (EMD) efficiently trains one-step diffusion models by using an Expectation-Maximization approach, achieving state-of-the-art image generation quality and outperforming existing methods&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/rafvvthuxd/cover.png"/></item><item><title>ENAT: Rethinking Spatial-temporal Interactions in Token-based Image Synthesis</title><link>https://deep-diver.github.io/neurips2024/posters/phsyfytehr/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/phsyfytehr/</guid><description>EfficientNAT: a novel approach to token-based image synthesis boosts performance and slashes computational costs by cleverly disentangling and optimizing spatial-temporal interactions between image to&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/phsyfytehr/cover.png"/></item><item><title>Enhancing Consistency-Based Image Generation via Adversarialy-Trained Classification and Energy-Based Discrimination</title><link>https://deep-diver.github.io/neurips2024/posters/ubvcpamdgk/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/ubvcpamdgk/</guid><description>This paper introduces a novel post-processing technique that significantly boosts the perceptual quality of images generated by consistency models using a joint classifier-discriminator adversarially &amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/ubvcpamdgk/cover.png"/></item><item><title>Erasing Undesirable Concepts in Diffusion Models with Adversarial Preservation</title><link>https://deep-diver.github.io/neurips2024/posters/gdz8rkfikp/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/gdz8rkfikp/</guid><description>This research introduces adversarial concept preservation, a novel method for safely erasing undesirable concepts from diffusion models, outperforming existing techniques by preserving related sensiti&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/gdz8rkfikp/cover.png"/></item><item><title>Exploring DCN-like architecture for fast image generation with arbitrary resolution</title><link>https://deep-diver.github.io/neurips2024/posters/e57b7bfa2b/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/e57b7bfa2b/</guid><description>FlowDCN: A purely convolutional generative model achieves state-of-the-art image generation speed and quality at arbitrary resolutions, surpassing transformer-based models.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/e57b7bfa2b/cover.png"/></item><item><title>Exploring Fixed Point in Image Editing: Theoretical Support and Convergence Optimization</title><link>https://deep-diver.github.io/neurips2024/posters/2wmj4wq4az/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/2wmj4wq4az/</guid><description>This paper theoretically proves the existence and uniqueness of fixed points in DDIM inversion, optimizing the loss function for improved image editing and extending this approach to unsupervised imag&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/2wmj4wq4az/cover.png"/></item><item><title>Exploring Low-Dimensional Subspace in Diffusion Models for Controllable Image Editing</title><link>https://deep-diver.github.io/neurips2024/posters/50aoefb2km/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/50aoefb2km/</guid><description>LOCO Edit achieves precise, localized image editing in diffusion models via a single-step, training-free method leveraging low-dimensional semantic subspaces.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/50aoefb2km/cover.png"/></item><item><title>Face2QR: A Unified Framework for Aesthetic, Face-Preserving, and Scannable QR Code Generation</title><link>https://deep-diver.github.io/neurips2024/posters/rvbabl7duu/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/rvbabl7duu/</guid><description>Face2QR: A unified framework generates aesthetically pleasing, scannable QR codes that faithfully preserve facial features, solving the conflict between aesthetics, identity, and scannability.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/rvbabl7duu/cover.png"/></item><item><title>Factorized Diffusion Architectures for Unsupervised Image Generation and Segmentation</title><link>https://deep-diver.github.io/neurips2024/posters/7g362fgjfd/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/7g362fgjfd/</guid><description>This paper presents a novel neural network architecture that simultaneously learns to generate and segment images in an unsupervised manner, achieving accurate results across multiple datasets without&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/7g362fgjfd/cover.png"/></item><item><title>FairQueue: Rethinking Prompt Learning for Fair Text-to-Image Generation</title><link>https://deep-diver.github.io/neurips2024/posters/3mw44indrd/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/3mw44indrd/</guid><description>FairQueue improves fair text-to-image generation by addressing prompt learning&amp;rsquo;s quality issues through prompt queuing and attention amplification.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/3mw44indrd/cover.png"/></item><item><title>FashionR2R: Texture-preserving Rendered-to-Real Image Translation with Diffusion Models</title><link>https://deep-diver.github.io/neurips2024/posters/qaenr5j172/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/qaenr5j172/</guid><description>FashionR2R leverages diffusion models to realistically translate rendered fashion images into photorealistic counterparts, enhancing realism and preserving fine-grained clothing textures.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/qaenr5j172/cover.png"/></item><item><title>Fast samplers for Inverse Problems in Iterative Refinement models</title><link>https://deep-diver.github.io/neurips2024/posters/qxs4ivtldd/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/qxs4ivtldd/</guid><description>Conditional Conjugate Integrators (CCI) drastically accelerate sampling in iterative refinement models for inverse problems, achieving high-quality results with only a few steps.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/qxs4ivtldd/cover.png"/></item><item><title>FastDrag: Manipulate Anything in One Step</title><link>https://deep-diver.github.io/neurips2024/posters/1pnwaczyik/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/1pnwaczyik/</guid><description>FastDrag: One-step image manipulation using generative models, drastically improving editing speed without sacrificing quality.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/1pnwaczyik/cover.png"/></item><item><title>Faster Diffusion: Rethinking the Role of the Encoder for Diffusion Model Inference</title><link>https://deep-diver.github.io/neurips2024/posters/ca2mabgv6p/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/ca2mabgv6p/</guid><description>Faster Diffusion achieves significant speedups in diffusion model inference by cleverly reusing encoder features and enabling parallel processing, eliminating the need for computationally expensive di&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/ca2mabgv6p/cover.png"/></item><item><title>FasterDiT: Towards Faster Diffusion Transformers Training without Architecture Modification</title><link>https://deep-diver.github.io/neurips2024/posters/cqrgodfagn/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/cqrgodfagn/</guid><description>FasterDiT accelerates Diffusion Transformers training 7x without architecture modification by analyzing SNR probability density functions and implementing a new supervision method.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/cqrgodfagn/cover.png"/></item><item><title>Finding NeMo: Localizing Neurons Responsible For Memorization in Diffusion Models</title><link>https://deep-diver.github.io/neurips2024/posters/yaekmfzyjm/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/yaekmfzyjm/</guid><description>NEMO pinpoints &amp;amp; deactivates neurons memorizing training data in diffusion models, boosting privacy &amp;amp; image diversity.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/yaekmfzyjm/cover.png"/></item><item><title>Flow Priors for Linear Inverse Problems via Iterative Corrupted Trajectory Matching</title><link>https://deep-diver.github.io/neurips2024/posters/1h2e7usi09/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/1h2e7usi09/</guid><description>ICTM efficiently solves linear inverse problems using flow priors by iteratively optimizing local MAP objectives, outperforming other flow-based methods.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/1h2e7usi09/cover.png"/></item><item><title>FlowTurbo: Towards Real-time Flow-Based Image Generation with Velocity Refiner</title><link>https://deep-diver.github.io/neurips2024/posters/1jg5ngxvs3/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/1jg5ngxvs3/</guid><description>FlowTurbo: Blazing-fast, high-quality flow-based image generation via a velocity refiner!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/1jg5ngxvs3/cover.png"/></item><item><title>FouRA: Fourier Low-Rank Adaptation</title><link>https://deep-diver.github.io/neurips2024/posters/qcj1dq5m7n/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/qcj1dq5m7n/</guid><description>FouRA: a novel low-rank adaptation method improves text-to-image generation by learning projections in the Fourier domain and using an adaptive rank selection strategy, addressing LoRA&amp;rsquo;s limitations o&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/qcj1dq5m7n/cover.png"/></item><item><title>Fourier Amplitude and Correlation Loss: Beyond Using L2 Loss for Skillful Precipitation Nowcasting</title><link>https://deep-diver.github.io/neurips2024/posters/0an7vwwp4g/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/0an7vwwp4g/</guid><description>This work proposes FACL, a novel loss function for precipitation nowcasting, improving forecast sharpness and meteorological skill without sacrificing accuracy.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/0an7vwwp4g/cover.png"/></item><item><title>Fourier-enhanced Implicit Neural Fusion Network for Multispectral and Hyperspectral Image Fusion</title><link>https://deep-diver.github.io/neurips2024/posters/cscowtrop9/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/cscowtrop9/</guid><description>FeINFN: a novel Fourier-enhanced Implicit Neural Fusion Network, achieves state-of-the-art hyperspectral image fusion by innovatively combining spatial and frequency information in both the spatial an&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/cscowtrop9/cover.png"/></item><item><title>FreqMark: Invisible Image Watermarking via Frequency Based Optimization in Latent Space</title><link>https://deep-diver.github.io/neurips2024/posters/01s5odihkd/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/01s5odihkd/</guid><description>FreqMark: Robust invisible image watermarking via latent frequency space optimization, resisting regeneration attacks and achieving &amp;gt;90% bit accuracy with high image quality.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/01s5odihkd/cover.png"/></item><item><title>From Trojan Horses to Castle Walls: Unveiling Bilateral Data Poisoning Effects in Diffusion Models</title><link>https://deep-diver.github.io/neurips2024/posters/yixzzc5qdi/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/yixzzc5qdi/</guid><description>Diffusion models, while excelling in image generation, are vulnerable to data poisoning. This paper demonstrates a BadNets-like attack&amp;rsquo;s effectiveness against diffusion models, causing image misalign&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/yixzzc5qdi/cover.png"/></item><item><title>FuseAnyPart: Diffusion-Driven Facial Parts Swapping via Multiple Reference Images</title><link>https://deep-diver.github.io/neurips2024/spotlight-others/x2umdvcmmo/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-others/x2umdvcmmo/</guid><description>FuseAnyPart: Swap facial parts seamlessly using multiple reference images via diffusion, achieving high-fidelity results.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-others/x2umdvcmmo/cover.png"/></item><item><title>General Articulated Objects Manipulation in Real Images via Part-Aware Diffusion Process</title><link>https://deep-diver.github.io/neurips2024/posters/wrd9lcbvxn/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/wrd9lcbvxn/</guid><description>Part-Aware Diffusion Model (PA-Diffusion) enables precise and efficient manipulation of articulated objects in real images by using abstract 3D models and dynamic feature maps, overcoming limitations &amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/wrd9lcbvxn/cover.png"/></item><item><title>Generalizable and Animatable Gaussian Head Avatar</title><link>https://deep-diver.github.io/neurips2024/posters/gvm2az5xa6/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/gvm2az5xa6/</guid><description>One-shot animatable head avatar reconstruction is achieved using a novel dual-lifting method that generates 3D Gaussians from a single image, enabling real-time expression control and rendering with s&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/gvm2az5xa6/cover.png"/></item><item><title>Generating compositional scenes via Text-to-image RGBA Instance Generation</title><link>https://deep-diver.github.io/neurips2024/posters/mwfeh4rqva/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/mwfeh4rqva/</guid><description>This paper introduces a novel multi-stage generation framework for creating compositional scenes with fine-grained control by leveraging a trained diffusion model to produce individual scene component&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/mwfeh4rqva/cover.png"/></item><item><title>GenWarp: Single Image to Novel Views with Semantic-Preserving Generative Warping</title><link>https://deep-diver.github.io/neurips2024/posters/rljisjmmkw/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/rljisjmmkw/</guid><description>GenWarp generates high-quality novel image views from a single input image by using a semantic-preserving generative warping framework, outperforming existing methods.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/rljisjmmkw/cover.png"/></item><item><title>Goal Conditioned Reinforcement Learning for Photo Finishing Tuning</title><link>https://deep-diver.github.io/neurips2024/posters/4kvhi2uxre/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/4kvhi2uxre/</guid><description>This paper introduces a goal-conditioned reinforcement learning approach that efficiently tunes photo finishing pipelines, achieving high-quality results in fewer iterations than optimization-based me&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/4kvhi2uxre/cover.png"/></item><item><title>Gradient-free Decoder Inversion in Latent Diffusion Models</title><link>https://deep-diver.github.io/neurips2024/posters/nbqvjkos6s/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/nbqvjkos6s/</guid><description>This paper introduces a novel gradient-free decoder inversion method for latent diffusion models, improving efficiency and memory usage compared to existing gradient-based methods. The method is theo&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/nbqvjkos6s/cover.png"/></item><item><title>Guiding a Diffusion Model with a Bad Version of Itself</title><link>https://deep-diver.github.io/neurips2024/oral-image-generation/bg6fvpvs3s/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/oral-image-generation/bg6fvpvs3s/</guid><description>Boost image quality in diffusion models without reducing variation using Autoguidance: guide a high-quality model with a less-trained version of itself!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/oral-image-generation/bg6fvpvs3s/cover.png"/></item><item><title>HairDiffusion: Vivid Multi-Colored Hair Editing via Latent Diffusion</title><link>https://deep-diver.github.io/neurips2024/posters/uqflshlbzv/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/uqflshlbzv/</guid><description>HairDiffusion uses latent diffusion models and a multi-stage blending technique to achieve vivid, multi-colored hair editing in images, preserving other facial features.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/uqflshlbzv/cover.png"/></item><item><title>HairFastGAN: Realistic and Robust Hair Transfer with a Fast Encoder-Based Approach</title><link>https://deep-diver.github.io/neurips2024/posters/sgvzyv2iqn/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/sgvzyv2iqn/</guid><description>HairFastGAN achieves realistic and robust hairstyle transfer in near real-time using a novel encoder-based approach, significantly outperforming optimization-based methods.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/sgvzyv2iqn/cover.png"/></item><item><title>HiCo: Hierarchical Controllable Diffusion Model for Layout-to-image Generation</title><link>https://deep-diver.github.io/neurips2024/posters/i9qprjuahv/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/i9qprjuahv/</guid><description>HiCo: Hierarchical Controllable Diffusion Model achieves superior layout-to-image generation by disentangling spatial layouts through a multi-branch network structure, resulting in high-quality images&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/i9qprjuahv/cover.png"/></item><item><title>Hierarchical Uncertainty Exploration via Feedforward Posterior Trees</title><link>https://deep-diver.github.io/neurips2024/posters/uddvrqtrjt/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/uddvrqtrjt/</guid><description>Visualizing high-dimensional posterior distributions is challenging. This paper introduces &amp;lsquo;Posterior Trees,&amp;rsquo; a novel method using tree-structured neural network predictions for hierarchical uncertai&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/uddvrqtrjt/cover.png"/></item><item><title>High-Resolution Image Harmonization with Adaptive-Interval Color Transformation</title><link>https://deep-diver.github.io/neurips2024/posters/jxghewtxs8/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/jxghewtxs8/</guid><description>AICT: Adaptive-Interval Color Transformation harmonizes high-resolution images by predicting pixel-wise color changes, adaptively adjusting sampling intervals to capture local variations, and using a &amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/jxghewtxs8/cover.png"/></item><item><title>Hollowed Net for On-Device Personalization of Text-to-Image Diffusion Models</title><link>https://deep-diver.github.io/neurips2024/posters/pa8jsrdonu/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/pa8jsrdonu/</guid><description>Hollowed Net efficiently personalizes text-to-image diffusion models on-device by temporarily removing deep U-Net layers during training, drastically reducing memory usage without sacrificing performa&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/pa8jsrdonu/cover.png"/></item><item><title>How Diffusion Models Learn to Factorize and Compose</title><link>https://deep-diver.github.io/neurips2024/posters/nzfg1lxtds/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/nzfg1lxtds/</guid><description>Diffusion models surprisingly learn factorized representations, enabling compositional generalization, but struggle with interpolation; training with independent factors drastically improves data effi&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/nzfg1lxtds/cover.png"/></item><item><title>How to Continually Adapt Text-to-Image Diffusion Models for Flexible Customization?</title><link>https://deep-diver.github.io/neurips2024/posters/o4rcfjvubj/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/o4rcfjvubj/</guid><description>Concept-Incremental Flexible Customization (CIFC) model tackles catastrophic forgetting and concept neglect in continually adapting text-to-image diffusion models, enabling flexible personalization.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/o4rcfjvubj/cover.png"/></item><item><title>Hyper-SD: Trajectory Segmented Consistency Model for Efficient Image Synthesis</title><link>https://deep-diver.github.io/neurips2024/posters/o5xbooi0x3/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/o5xbooi0x3/</guid><description>Hyper-SD boosts diffusion model speed by using trajectory segmented consistency distillation and human feedback, achieving state-of-the-art performance.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/o5xbooi0x3/cover.png"/></item><item><title>Identifying and Solving Conditional Image Leakage in Image-to-Video Diffusion Model</title><link>https://deep-diver.github.io/neurips2024/posters/o9lkiv1qpc/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/o9lkiv1qpc/</guid><description>Researchers solve the conditional image leakage problem in image-to-video diffusion models by proposing a new inference strategy and a time-dependent noise distribution for training. This yields video&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/o9lkiv1qpc/cover.png"/></item><item><title>Identity Decoupling for Multi-Subject Personalization of Text-to-Image Models</title><link>https://deep-diver.github.io/neurips2024/posters/teepvpdarf/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/teepvpdarf/</guid><description>MuDI: a novel framework for multi-subject image personalization, effectively decoupling identities to prevent mixing using segmented subjects and a new evaluation metric.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/teepvpdarf/cover.png"/></item><item><title>Image Copy Detection for Diffusion Models</title><link>https://deep-diver.github.io/neurips2024/posters/gvloqc6op1/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/gvloqc6op1/</guid><description>ICDiff, a novel Image Copy Detection system, tackles the unique challenge of identifying replicated content in diffusion model outputs, introducing a specialized dataset and deep embedding method for &amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/gvloqc6op1/cover.png"/></item><item><title>Image Reconstruction Via Autoencoding Sequential Deep Image Prior</title><link>https://deep-diver.github.io/neurips2024/posters/k1eg2abzne/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/k1eg2abzne/</guid><description>aSeqDIP: A new unsupervised image reconstruction method using sequential deep image priors, achieving competitive performance with fewer data needs and faster runtimes.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/k1eg2abzne/cover.png"/></item><item><title>Image Understanding Makes for A Good Tokenizer for Image Generation</title><link>https://deep-diver.github.io/neurips2024/posters/rmmgu49lwn/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/rmmgu49lwn/</guid><description>Leveraging image understanding models for image tokenizer training dramatically boosts image generation quality, achieving state-of-the-art results.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/rmmgu49lwn/cover.png"/></item><item><title>IMAGPose: A Unified Conditional Framework for Pose-Guided Person Generation</title><link>https://deep-diver.github.io/neurips2024/posters/6iyya4getn/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/6iyya4getn/</guid><description>IMAGPose: A unified framework generating high-fidelity person images from single or multiple source images &amp;amp; poses, addressing existing methods&amp;rsquo; limitations.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/6iyya4getn/cover.png"/></item><item><title>Immiscible Diffusion: Accelerating Diffusion Training with Noise Assignment</title><link>https://deep-diver.github.io/neurips2024/posters/kk23omge9g/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/kk23omge9g/</guid><description>Immiscible Diffusion boosts diffusion model training efficiency up to 3x by cleverly assigning noise to images, preventing the mixing of data in noise space and thus improving optimization.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/kk23omge9g/cover.png"/></item><item><title>Improved Distribution Matching Distillation for Fast Image Synthesis</title><link>https://deep-diver.github.io/neurips2024/oral-image-generation/tqukgcdant/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/oral-image-generation/tqukgcdant/</guid><description>DMD2 dramatically speeds up image generation by cleverly distilling expensive diffusion models, achieving state-of-the-art results without sacrificing quality.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/oral-image-generation/tqukgcdant/cover.png"/></item><item><title>Improving the Training of Rectified Flows</title><link>https://deep-diver.github.io/neurips2024/posters/mshs6c7nfa/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/mshs6c7nfa/</guid><description>Researchers significantly boosted the efficiency and quality of rectified flow, a method for generating samples from diffusion models, by introducing novel training techniques that surpass state-of-th&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/mshs6c7nfa/cover.png"/></item><item><title>Interpretable Lightweight Transformer via Unrolling of Learned Graph Smoothness Priors</title><link>https://deep-diver.github.io/neurips2024/posters/i8lowbjf7j/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/i8lowbjf7j/</guid><description>Interpretable lightweight transformers are built by unrolling graph smoothness priors, achieving high performance with significantly fewer parameters than conventional transformers.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/i8lowbjf7j/cover.png"/></item><item><title>Interpreting the Weight Space of Customized Diffusion Models</title><link>https://deep-diver.github.io/neurips2024/posters/dao2bfzmfy/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/dao2bfzmfy/</guid><description>Researchers model a manifold of customized diffusion models as a subspace of weights, enabling controllable creation of new models via sampling, editing, and inversion from a single image.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/dao2bfzmfy/cover.png"/></item><item><title>Invertible Consistency Distillation for Text-Guided Image Editing in Around 7 Steps</title><link>https://deep-diver.github.io/neurips2024/posters/b1xphc7mqb/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/b1xphc7mqb/</guid><description>Invertible Consistency Distillation (iCD) achieves high-quality image editing in ~7 steps by enabling both fast editing and strong generation using a generalized distillation framework and dynamic cla&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/b1xphc7mqb/cover.png"/></item><item><title>IODA: Instance-Guided One-shot Domain Adaptation for Super-Resolution</title><link>https://deep-diver.github.io/neurips2024/posters/qbvt3ocqxb/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/qbvt3ocqxb/</guid><description>IODA achieves efficient one-shot domain adaptation for super-resolution using a novel instance-guided strategy and image-level domain alignment, significantly improving performance with limited target&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/qbvt3ocqxb/cover.png"/></item><item><title>IR-CM: The Fast and Universal Image Restoration Method Based on Consistency Model</title><link>https://deep-diver.github.io/neurips2024/posters/2bon4hlfkn/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/2bon4hlfkn/</guid><description>IR-CM: One-step image restoration using a novel consistency model for fast and universal performance.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/2bon4hlfkn/cover.png"/></item><item><title>Is One GPU Enough? Pushing Image Generation at Higher-Resolutions with Foundation Models.</title><link>https://deep-diver.github.io/neurips2024/posters/ffb30ovvca/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/ffb30ovvca/</guid><description>Pixelsmith: Generate gigapixel images with a single GPU, surpassing limitations of existing methods through a cascading approach and innovative guidance mechanism.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/ffb30ovvca/cover.png"/></item><item><title>KOALA: Empirical Lessons Toward Memory-Efficient and Fast Diffusion Models for Text-to-Image Synthesis</title><link>https://deep-diver.github.io/neurips2024/posters/kndubpwv9b/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/kndubpwv9b/</guid><description>KOALA: New efficient text-to-image diffusion models achieving 4x speed and 69% size reduction of SDXL, generating 1024px images on consumer GPUs with 8GB VRAM.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/kndubpwv9b/cover.png"/></item><item><title>Latent Intrinsics Emerge from Training to Relight</title><link>https://deep-diver.github.io/neurips2024/spotlight-others/ltndg0ezf9/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-others/ltndg0ezf9/</guid><description>A novel data-driven relighting model achieves state-of-the-art accuracy by learning latent intrinsic and extrinsic scene properties, even recovering albedo without explicit supervision.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-others/ltndg0ezf9/cover.png"/></item><item><title>Latent Representation Matters: Human-like Sketches in One-shot Drawing Tasks</title><link>https://deep-diver.github.io/neurips2024/posters/tzrpvlxevu/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/tzrpvlxevu/</guid><description>AI now draws almost as well as humans, thanks to novel latent diffusion model regularizations that mimic human cognitive biases.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/tzrpvlxevu/cover.png"/></item><item><title>Learning from Pattern Completion: Self-supervised Controllable Generation</title><link>https://deep-diver.github.io/neurips2024/posters/83pv20dd2s/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/83pv20dd2s/</guid><description>Self-Supervised Controllable Generation (SCG) framework achieves brain-like associative generation by using a modular autoencoder with equivariance constraints and a self-supervised pattern completion&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/83pv20dd2s/cover.png"/></item><item><title>Learning Group Actions on Latent Representations</title><link>https://deep-diver.github.io/neurips2024/posters/hgntcy4eep/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/hgntcy4eep/</guid><description>This paper proposes a novel method to model group actions within autoencoders by learning these actions in the latent space, enhancing model versatility and improving performance in various real-world&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/hgntcy4eep/cover.png"/></item><item><title>Learning Image Priors Through Patch-Based Diffusion Models for Solving Inverse Problems</title><link>https://deep-diver.github.io/neurips2024/posters/hgnxhhz6ss/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/hgnxhhz6ss/</guid><description>PaDIS: Patch-based diffusion inverse solver learns efficient image priors from image patches, enabling high-resolution inverse problem solutions with reduced computational costs and data needs.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/hgnxhhz6ss/cover.png"/></item><item><title>Learning Transferable Features for Implicit Neural Representations</title><link>https://deep-diver.github.io/neurips2024/posters/abydkpdb8p/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/abydkpdb8p/</guid><description>STRAINER: A new framework enabling faster, higher-quality INR fitting by leveraging transferable features across similar signals, significantly boosting INR performance.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/abydkpdb8p/cover.png"/></item><item><title>Learning-to-Cache: Accelerating Diffusion Transformer via Layer Caching</title><link>https://deep-diver.github.io/neurips2024/posters/zupomzmnro/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/zupomzmnro/</guid><description>Learning-to-Cache (L2C) dramatically accelerates diffusion transformers by intelligently caching layer computations, achieving significant speedups with minimal performance loss.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/zupomzmnro/cover.png"/></item><item><title>LiteVAE: Lightweight and Efficient Variational Autoencoders for Latent Diffusion Models</title><link>https://deep-diver.github.io/neurips2024/posters/mtabl8kuzq/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/mtabl8kuzq/</guid><description>LiteVAE: A new autoencoder design for latent diffusion models boosts efficiency sixfold without sacrificing image quality, achieving faster training and lower memory needs via the 2D discrete wavelet &amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/mtabl8kuzq/cover.png"/></item><item><title>Localize, Understand, Collaborate: Semantic-Aware Dragging via Intention Reasoner</title><link>https://deep-diver.github.io/neurips2024/posters/kcqkizqpzj/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/kcqkizqpzj/</guid><description>LucidDrag: Semantic-aware dragging transforms image editing with an intention reasoner and collaborative guidance, achieving superior accuracy, image fidelity, and semantic diversity.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/kcqkizqpzj/cover.png"/></item><item><title>Locating What You Need: Towards Adapting Diffusion Models to OOD Concepts In-the-Wild</title><link>https://deep-diver.github.io/neurips2024/posters/65htepluye/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/65htepluye/</guid><description>CATOD framework improves text-to-image generation by actively learning high-quality training data to accurately depict out-of-distribution concepts.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/65htepluye/cover.png"/></item><item><title>Masked Pre-training Enables Universal Zero-shot Denoiser</title><link>https://deep-diver.github.io/neurips2024/posters/ofgtscasbr/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/ofgtscasbr/</guid><description>Masked Pre-training empowers a universal, fast zero-shot image denoiser!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/ofgtscasbr/cover.png"/></item><item><title>MC-DiT: Contextual Enhancement via Clean-to-Clean Reconstruction for Masked Diffusion Models</title><link>https://deep-diver.github.io/neurips2024/posters/y9shkrdnrt/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/y9shkrdnrt/</guid><description>MC-DiT: A novel training paradigm for masked diffusion models achieving state-of-the-art image generation by leveraging clean-to-clean reconstruction.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/y9shkrdnrt/cover.png"/></item><item><title>MimicTalk: Mimicking a personalized and expressive 3D talking face in minutes</title><link>https://deep-diver.github.io/neurips2024/posters/gjezl0bamb/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/gjezl0bamb/</guid><description>MimicTalk generates realistic, expressive talking videos in minutes using a pre-trained model adapted to individual identities.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/gjezl0bamb/cover.png"/></item><item><title>MonkeySee: Space-time-resolved reconstructions of natural images from macaque multi-unit activity</title><link>https://deep-diver.github.io/neurips2024/posters/owwdlxwnfn/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/owwdlxwnfn/</guid><description>MonkeySee reconstructs natural images from macaque brain signals with high accuracy using a novel CNN decoder, advancing neural decoding and offering insights into visual perception.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/owwdlxwnfn/cover.png"/></item><item><title>Multistep Distillation of Diffusion Models via Moment Matching</title><link>https://deep-diver.github.io/neurips2024/posters/c62d2ns3ko/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/c62d2ns3ko/</guid><description>New method distills slow diffusion models into fast, few-step models by matching data expectations, achieving state-of-the-art results on ImageNet.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/c62d2ns3ko/cover.png"/></item><item><title>Neural Assets: 3D-Aware Multi-Object Scene Synthesis with Image Diffusion Models</title><link>https://deep-diver.github.io/neurips2024/spotlight-others/ednslswqij/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-others/ednslswqij/</guid><description>Neural Assets enables intuitive 3D multi-object scene editing via image diffusion models by using per-object representations to control individual object poses, achieving state-of-the-art results.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-others/ednslswqij/cover.png"/></item><item><title>Neural Cover Selection for Image Steganography</title><link>https://deep-diver.github.io/neurips2024/posters/tzzz5kaee2/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/tzzz5kaee2/</guid><description>This study introduces a neural cover selection framework for image steganography, optimizing latent spaces in generative models to improve message recovery and image quality.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/tzzz5kaee2/cover.png"/></item><item><title>Neural Gaffer: Relighting Any Object via Diffusion</title><link>https://deep-diver.github.io/neurips2024/posters/zv2gdszb5a/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/zv2gdszb5a/</guid><description>Neural Gaffer: Relighting any object via diffusion using a single image and an environment map to produce high-quality, realistic relit images.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/zv2gdszb5a/cover.png"/></item><item><title>Neural Residual Diffusion Models for Deep Scalable Vision Generation</title><link>https://deep-diver.github.io/neurips2024/posters/ng16csomca/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/ng16csomca/</guid><description>Neural-RDM: A novel framework for deep, scalable vision generation using residual diffusion models, achieving state-of-the-art results on image and video benchmarks.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/ng16csomca/cover.png"/></item><item><title>Not All Diffusion Model Activations Have Been Evaluated as Discriminative Features</title><link>https://deep-diver.github.io/neurips2024/spotlight-others/7uqvfzw6mo/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-others/7uqvfzw6mo/</guid><description>Unlocking superior discriminative features from diffusion models, this research reveals key activation properties for effective feature selection, surpassing state-of-the-art methods.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-others/7uqvfzw6mo/cover.png"/></item><item><title>On improved Conditioning Mechanisms and Pre-training Strategies for Diffusion Models</title><link>https://deep-diver.github.io/neurips2024/posters/b3rzzralhk/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/b3rzzralhk/</guid><description>Researchers achieve state-of-the-art image generation by disentangling semantic and control metadata in diffusion models and optimizing pre-training across resolutions.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/b3rzzralhk/cover.png"/></item><item><title>One-Step Diffusion Distillation through Score Implicit Matching</title><link>https://deep-diver.github.io/neurips2024/posters/ogk236hsjm/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/ogk236hsjm/</guid><description>Score Implicit Matching (SIM) revolutionizes diffusion model distillation by creating high-quality, single-step generators from complex, multi-step models, achieving comparable performance and enablin&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/ogk236hsjm/cover.png"/></item><item><title>One-Step Effective Diffusion Network for Real-World Image Super-Resolution</title><link>https://deep-diver.github.io/neurips2024/posters/tptxnprvur/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/tptxnprvur/</guid><description>OSEDiff: One-step diffusion network for real-world image super-resolution, achieving comparable or better results than multi-step methods with significantly reduced computational cost and improved ima&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/tptxnprvur/cover.png"/></item><item><title>OneActor: Consistent Subject Generation via Cluster-Conditioned Guidance</title><link>https://deep-diver.github.io/neurips2024/posters/2gtna14v45/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/2gtna14v45/</guid><description>OneActor: One-shot tuning for consistent subject image generation, bypassing laborious backbone tuning via semantic guidance, achieving 4x faster speed.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/2gtna14v45/cover.png"/></item><item><title>Optical Diffusion Models for Image Generation</title><link>https://deep-diver.github.io/neurips2024/posters/ry3rdqv0tq/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/ry3rdqv0tq/</guid><description>Researchers created an energy-efficient optical system for generating images using light propagation, drastically reducing the latency and energy consumption of diffusion models.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/ry3rdqv0tq/cover.png"/></item><item><title>PaGoDA: Progressive Growing of a One-Step Generator from a Low-Resolution Diffusion Teacher</title><link>https://deep-diver.github.io/neurips2024/posters/h5zygf68kh/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/h5zygf68kh/</guid><description>PaGoDA: Train high-resolution image generators efficiently by progressively growing a one-step generator from a low-resolution diffusion model. This innovative pipeline drastically cuts training cost&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/h5zygf68kh/cover.png"/></item><item><title>PeRFlow: Piecewise Rectified Flow as Universal Plug-and-Play Accelerator</title><link>https://deep-diver.github.io/neurips2024/posters/qrlguvku7a/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/qrlguvku7a/</guid><description>PeRFlow accelerates diffusion models by straightening their sampling trajectories using a piecewise reflow operation, enabling fast and high-quality image generation with minimal computational cost.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/qrlguvku7a/cover.png"/></item><item><title>Phased Consistency Models</title><link>https://deep-diver.github.io/neurips2024/posters/mtbmkqyqgs/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/mtbmkqyqgs/</guid><description>Phased Consistency Models (PCMs) revolutionize diffusion model generation by overcoming LCM limitations, achieving superior speed and quality in image and video generation.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/mtbmkqyqgs/cover.png"/></item><item><title>PrefPaint: Aligning Image Inpainting Diffusion Model with Human Preference</title><link>https://deep-diver.github.io/neurips2024/posters/fvrcsk4eom/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/fvrcsk4eom/</guid><description>PrefPaint: Aligning image inpainting diffusion models with human preferences using reinforcement learning, resulting in significantly improved visual appeal.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/fvrcsk4eom/cover.png"/></item><item><title>Principled Probabilistic Imaging using Diffusion Models as Plug-and-Play Priors</title><link>https://deep-diver.github.io/neurips2024/posters/xq9hqf7vnv/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/xq9hqf7vnv/</guid><description>Principled Probabilistic Imaging uses diffusion models as plug-and-play priors for accurate posterior sampling in inverse problems, surpassing existing methods.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/xq9hqf7vnv/cover.png"/></item><item><title>Prompt-Agnostic Adversarial Perturbation for Customized Diffusion Models</title><link>https://deep-diver.github.io/neurips2024/posters/omhpejygdx/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/omhpejygdx/</guid><description>Prompt-Agnostic Adversarial Perturbation (PAP) defends customized diffusion models against image tampering, achieving superior generalization over prompt-specific methods.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/omhpejygdx/cover.png"/></item><item><title>PromptFix: You Prompt and We Fix the Photo</title><link>https://deep-diver.github.io/neurips2024/posters/p1lpxnpmia/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/p1lpxnpmia/</guid><description>PromptFix: a novel framework enables diffusion models to precisely follow instructions for diverse image processing tasks, using a new high-frequency guidance sampling method and an auxiliary prompt a&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/p1lpxnpmia/cover.png"/></item><item><title>Prune and Repaint: Content-Aware Image Retargeting for any Ratio</title><link>https://deep-diver.github.io/neurips2024/posters/qwi6esgbjb/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/qwi6esgbjb/</guid><description>Prune and Repaint: A new content-aware method for superior image retargeting across any aspect ratio, preserving key features and avoiding artifacts.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/qwi6esgbjb/cover.png"/></item><item><title>PTQ4DiT: Post-training Quantization for Diffusion Transformers</title><link>https://deep-diver.github.io/neurips2024/posters/nlmagkn6nn/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/nlmagkn6nn/</guid><description>PTQ4DiT achieves 8-bit and even 4-bit weight precision for Diffusion Transformers, significantly improving efficiency for image generation without sacrificing quality.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/nlmagkn6nn/cover.png"/></item><item><title>PuLID: Pure and Lightning ID Customization via Contrastive Alignment</title><link>https://deep-diver.github.io/neurips2024/posters/e6zodzu0hq/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/e6zodzu0hq/</guid><description>PuLID: Lightning-fast, tuning-free ID customization for text-to-image!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/e6zodzu0hq/cover.png"/></item><item><title>RAW: A Robust and Agile Plug-and-Play Watermark Framework for AI-Generated Images with Provable Guarantees</title><link>https://deep-diver.github.io/neurips2024/posters/ogaechzbku/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/ogaechzbku/</guid><description>RAW: A novel watermark framework ensures the authenticity of AI-generated images by embedding learnable watermarks directly into the image data, providing provable guarantees even under adversarial at&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/ogaechzbku/cover.png"/></item><item><title>Real-world Image Dehazing with Coherence-based Pseudo Labeling and Cooperative Unfolding Network</title><link>https://deep-diver.github.io/neurips2024/spotlight-others/i6tbncje2f/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-others/i6tbncje2f/</guid><description>CORUN-Colabator: a novel cooperative unfolding network and coherence-based label generator achieves state-of-the-art real-world image dehazing by effectively integrating physical knowledge and generat&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-others/i6tbncje2f/cover.png"/></item><item><title>RealCompo: Balancing Realism and Compositionality Improves Text-to-Image Diffusion Models</title><link>https://deep-diver.github.io/neurips2024/posters/r8mfn3rhd5/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/r8mfn3rhd5/</guid><description>RealCompo: A novel training-free framework dynamically balances realism and compositionality in text-to-image generation, achieving state-of-the-art results.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/r8mfn3rhd5/cover.png"/></item><item><title>Reconstructing the Image Stitching Pipeline: Integrating Fusion and Rectangling into a Unified Inpainting Model</title><link>https://deep-diver.github.io/neurips2024/posters/zviypzh9wq/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/zviypzh9wq/</guid><description>SRStitcher revolutionizes image stitching by integrating fusion and rectangling into a unified inpainting model, eliminating model training and achieving superior performance and stability.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/zviypzh9wq/cover.png"/></item><item><title>RectifID: Personalizing Rectified Flow with Anchored Classifier Guidance</title><link>https://deep-diver.github.io/neurips2024/posters/kkrj1vcqag/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/kkrj1vcqag/</guid><description>RectifID personalizes image generation by cleverly guiding a diffusion model using off-the-shelf classifiers, achieving identity preservation without needing extra training data.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/kkrj1vcqag/cover.png"/></item><item><title>ReF-LDM: A Latent Diffusion Model for Reference-based Face Image Restoration</title><link>https://deep-diver.github.io/neurips2024/posters/qy4spbhqzi/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/qy4spbhqzi/</guid><description>ReF-LDM uses reference images to improve the accuracy of face image restoration, achieving high-quality results faithful to the subject&amp;rsquo;s true appearance.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/qy4spbhqzi/cover.png"/></item><item><title>RefDrop: Controllable Consistency in Image or Video Generation via Reference Feature Guidance</title><link>https://deep-diver.github.io/neurips2024/posters/09nybqsduz/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/09nybqsduz/</guid><description>RefDrop: A training-free method enhances image and video generation consistency by directly controlling the influence of reference features on the diffusion process, enabling precise manipulation of c&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/09nybqsduz/cover.png"/></item><item><title>ReFIR: Grounding Large Restoration Models with Retrieval Augmentation</title><link>https://deep-diver.github.io/neurips2024/posters/ifkmfuxqdh/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/ifkmfuxqdh/</guid><description>ReFIR enhances Large Restoration Models&amp;rsquo; accuracy by incorporating retrieved images as external knowledge, mitigating hallucination without retraining.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/ifkmfuxqdh/cover.png"/></item><item><title>Remix-DiT: Mixing Diffusion Transformers for Multi-Expert Denoising</title><link>https://deep-diver.github.io/neurips2024/posters/vo5longado/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/vo5longado/</guid><description>Remix-DiT: Boosting diffusion model image generation quality by cleverly mixing smaller basis models into numerous specialized denoisers, improving efficiency and lowering costs!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/vo5longado/cover.png"/></item><item><title>ReNO: Enhancing One-step Text-to-Image Models through Reward-based Noise Optimization</title><link>https://deep-diver.github.io/neurips2024/posters/mxy0qsggeo/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/mxy0qsggeo/</guid><description>ReNO: Boost one-step text-to-image models by cleverly optimizing initial noise using reward signals, achieving state-of-the-art results efficiently.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/mxy0qsggeo/cover.png"/></item><item><title>Resfusion: Denoising Diffusion Probabilistic Models for Image Restoration Based on Prior Residual Noise</title><link>https://deep-diver.github.io/neurips2024/posters/jripbxwis8/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/jripbxwis8/</guid><description>Resfusion, a novel framework, accelerates image restoration by integrating residual noise into the diffusion process, achieving superior results with fewer steps.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/jripbxwis8/cover.png"/></item><item><title>RestoreAgent: Autonomous Image Restoration Agent via Multimodal Large Language Models</title><link>https://deep-diver.github.io/neurips2024/posters/xgp5ynlzwf/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/xgp5ynlzwf/</guid><description>RestoreAgent, an AI-powered image restoration agent, autonomously identifies and corrects multiple image degradations, exceeding human expert performance.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/xgp5ynlzwf/cover.png"/></item><item><title>Rethinking Imbalance in Image Super-Resolution for Efficient Inference</title><link>https://deep-diver.github.io/neurips2024/posters/fyyrzbwtnz/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/fyyrzbwtnz/</guid><description>WBSR: A novel framework for efficient image super-resolution that tackles data and model imbalances for superior performance and approximately a 34% reduction in computational cost.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/fyyrzbwtnz/cover.png"/></item><item><title>Rethinking No-reference Image Exposure Assessment from Holism to Pixel: Models, Datasets and Benchmarks</title><link>https://deep-diver.github.io/neurips2024/posters/zvrqeopioq/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/zvrqeopioq/</guid><description>Revolutionizing image exposure assessment, Pixel-level IEA Network (P-IEANet) achieves state-of-the-art performance with a novel pixel-level approach, a new dataset (IEA40K), and a benchmark of 19 met&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/zvrqeopioq/cover.png"/></item><item><title>Rethinking Score Distillation as a Bridge Between Image Distributions</title><link>https://deep-diver.github.io/neurips2024/posters/i8pkicj9km/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/i8pkicj9km/</guid><description>Researchers enhanced image generation by improving score distillation sampling via a novel Schrödinger Bridge framework, improving realism without computational overhead.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/i8pkicj9km/cover.png"/></item><item><title>Rethinking The Training And Evaluation of Rich-Context Layout-to-Image Generation</title><link>https://deep-diver.github.io/neurips2024/posters/83e3dpvrfc/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/83e3dpvrfc/</guid><description>This paper presents a novel regional cross-attention module for rich-context layout-to-image generation, significantly improving image accuracy while addressing limitations of existing methods. Two n&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/83e3dpvrfc/cover.png"/></item><item><title>Return of Unconditional Generation: A Self-supervised Representation Generation Method</title><link>https://deep-diver.github.io/neurips2024/oral-image-generation/clta4jfbml/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/oral-image-generation/clta4jfbml/</guid><description>Revolutionizing image generation, Representation-Conditioned Generation (RCG) achieves state-of-the-art results in unconditional image synthesis by leveraging self-supervised representations to condit&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/oral-image-generation/clta4jfbml/cover.png"/></item><item><title>ROBIN: Robust and Invisible Watermarks for Diffusion Models with Adversarial Optimization</title><link>https://deep-diver.github.io/neurips2024/posters/rvoxlfvnlx/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/rvoxlfvnlx/</guid><description>ROBIN: A novel watermarking method for diffusion models that actively conceals robust watermarks using adversarial optimization, enabling strong, imperceptible, and verifiable image authentication.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/rvoxlfvnlx/cover.png"/></item><item><title>Scaling the Codebook Size of VQ-GAN to 100,000 with a Utilization Rate of 99%</title><link>https://deep-diver.github.io/neurips2024/posters/rbu10yvkk6/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/rbu10yvkk6/</guid><description>VQGAN-LC massively scales VQGAN&amp;rsquo;s codebook to 100,000 entries while maintaining a 99% utilization rate, significantly boosting image generation and downstream task performance.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/rbu10yvkk6/cover.png"/></item><item><title>Scene Graph Disentanglement and Composition for Generalizable Complex Image Generation</title><link>https://deep-diver.github.io/neurips2024/spotlight-others/zgn0ywy2he/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-others/zgn0ywy2he/</guid><description>DisCo: a novel framework for generalizable complex image generation using scene graph disentanglement and composition, achieving superior performance over existing methods.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-others/zgn0ywy2he/cover.png"/></item><item><title>Schedule Your Edit: A Simple yet Effective Diffusion Noise Schedule for Image Editing</title><link>https://deep-diver.github.io/neurips2024/posters/yu6cdt7q9z/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/yu6cdt7q9z/</guid><description>Logistic Schedule: A novel noise schedule revolutionizes image editing by improving DDIM inversion, enhancing content preservation and edit fidelity without model retraining!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/yu6cdt7q9z/cover.png"/></item><item><title>Score Distillation via Reparametrized DDIM</title><link>https://deep-diver.github.io/neurips2024/posters/4dcpfagq9e/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/4dcpfagq9e/</guid><description>Researchers improved 3D shape generation from 2D diffusion models by showing that existing Score Distillation Sampling is a reparameterized version of DDIM and fixing its high-variance noise issue via&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/4dcpfagq9e/cover.png"/></item><item><title>Self-Play Fine-tuning of Diffusion Models for Text-to-image Generation</title><link>https://deep-diver.github.io/neurips2024/posters/q3xavkporv/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/q3xavkporv/</guid><description>Self-Play Fine-Tuning (SPIN-Diffusion) revolutionizes diffusion model training, achieving superior text-to-image results with less data via iterative self-improvement, surpassing supervised and RLHF m&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/q3xavkporv/cover.png"/></item><item><title>SemFlow: Binding Semantic Segmentation and Image Synthesis via Rectified Flow</title><link>https://deep-diver.github.io/neurips2024/posters/e3p1x94y51/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/e3p1x94y51/</guid><description>SemFlow: A unified framework uses rectified flow to seamlessly bridge semantic segmentation and image synthesis, achieving competitive results and offering reversible image-mask transformations.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/e3p1x94y51/cover.png"/></item><item><title>SHMT: Self-supervised Hierarchical Makeup Transfer via Latent Diffusion Models</title><link>https://deep-diver.github.io/neurips2024/posters/eexcoyf3lg/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/eexcoyf3lg/</guid><description>SHMT: Self-supervised Hierarchical Makeup Transfer uses latent diffusion models to realistically and precisely apply diverse makeup styles to faces, even without paired training data, achieving high f&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/eexcoyf3lg/cover.png"/></item><item><title>ShowMaker: Creating High-Fidelity 2D Human Video via Fine-Grained Diffusion Modeling</title><link>https://deep-diver.github.io/neurips2024/posters/lpxdg0hk4h/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/lpxdg0hk4h/</guid><description>ShowMaker: Generating high-fidelity 2D human conversational videos using fine-grained diffusion modeling and 2D key points.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/lpxdg0hk4h/cover.png"/></item><item><title>Simple and Fast Distillation of Diffusion Models</title><link>https://deep-diver.github.io/neurips2024/posters/ao0fizqrxa/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/ao0fizqrxa/</guid><description>Simple and Fast Distillation (SFD) drastically accelerates diffusion model training by 1000x, achieving state-of-the-art results in few-step image generation with minimal fine-tuning.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/ao0fizqrxa/cover.png"/></item><item><title>Single Image Reflection Separation via Dual-Stream Interactive Transformers</title><link>https://deep-diver.github.io/neurips2024/posters/shwtw8uv8l/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/shwtw8uv8l/</guid><description>Dual-Stream Interactive Transformers (DSIT) revolutionizes single image reflection separation by using a novel dual-attention mechanism that captures inter- and intra-layer correlations, significantly&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/shwtw8uv8l/cover.png"/></item><item><title>Slight Corruption in Pre-training Data Makes Better Diffusion Models</title><link>https://deep-diver.github.io/neurips2024/spotlight-others/vfpxybqmsu/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-others/vfpxybqmsu/</guid><description>Slightly corrupting pre-training data significantly improves diffusion models&amp;rsquo; image generation quality, diversity, and fidelity.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-others/vfpxybqmsu/cover.png"/></item><item><title>Smoothed Energy Guidance: Guiding Diffusion Models with Reduced Energy Curvature of Attention</title><link>https://deep-diver.github.io/neurips2024/posters/jk728xy8g7/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/jk728xy8g7/</guid><description>Smoothed Energy Guidance (SEG) improves unconditional image generation by reducing self-attention&amp;rsquo;s energy curvature, leading to higher-quality outputs with fewer artifacts.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/jk728xy8g7/cover.png"/></item><item><title>Spatio-Temporal Interactive Learning for Efficient Image Reconstruction of Spiking Cameras</title><link>https://deep-diver.github.io/neurips2024/posters/s4zqnmywcm/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/s4zqnmywcm/</guid><description>STIR: A novel spatio-temporal network reconstructs high-quality images from spiking camera data by jointly refining motion and intensity information for efficient and accurate high-speed imaging.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/s4zqnmywcm/cover.png"/></item><item><title>SpikeReveal: Unlocking Temporal Sequences from Real Blurry Inputs with Spike Streams</title><link>https://deep-diver.github.io/neurips2024/spotlight-others/9fyat8hppv/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-others/9fyat8hppv/</guid><description>SpikeReveal: Self-supervised learning unlocks sharp video sequences from blurry, real-world spike camera data, overcoming limitations of prior supervised approaches.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-others/9fyat8hppv/cover.png"/></item><item><title>SSDiff: Spatial-spectral Integrated Diffusion Model for Remote Sensing Pansharpening</title><link>https://deep-diver.github.io/neurips2024/posters/qmvydwvrx7/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/qmvydwvrx7/</guid><description>SSDiff: A novel spatial-spectral integrated diffusion model for superior remote sensing pansharpening.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/qmvydwvrx7/cover.png"/></item><item><title>Stability and Generalizability in SDE Diffusion Models with Measure-Preserving Dynamics</title><link>https://deep-diver.github.io/neurips2024/posters/vtjvta41d0/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/vtjvta41d0/</guid><description>D³GM, a novel score-based diffusion model, enhances stability &amp;amp; generalizability in solving inverse problems by leveraging measure-preserving dynamics, enabling robust image reconstruction across dive&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/vtjvta41d0/cover.png"/></item><item><title>Stabilize the Latent Space for Image Autoregressive Modeling: A Unified Perspective</title><link>https://deep-diver.github.io/neurips2024/posters/waq5x4qc3w/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/waq5x4qc3w/</guid><description>DiGIT stabilizes image autoregressive models&amp;rsquo; latent space using a novel discrete tokenizer from self-supervised learning, achieving state-of-the-art image generation.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/waq5x4qc3w/cover.png"/></item><item><title>Stable-Pose: Leveraging Transformers for Pose-Guided Text-to-Image Generation</title><link>https://deep-diver.github.io/neurips2024/posters/iwntinpxft/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/iwntinpxft/</guid><description>Stable-Pose: Precise human pose guidance for text-to-image synthesis.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/iwntinpxft/cover.png"/></item><item><title>StepbaQ: Stepping backward as Correction for Quantized Diffusion Models</title><link>https://deep-diver.github.io/neurips2024/posters/cetexbakyv/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/cetexbakyv/</guid><description>StepbaQ enhances quantized diffusion models by correcting accumulated quantization errors via a novel sampling step correction mechanism, significantly improving model accuracy without modifying exist&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/cetexbakyv/cover.png"/></item><item><title>StoryDiffusion: Consistent Self-Attention for Long-Range Image and Video Generation</title><link>https://deep-diver.github.io/neurips2024/spotlight-others/vfqzxhinfu/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-others/vfqzxhinfu/</guid><description>StoryDiffusion enhances long-range image &amp;amp; video generation by introducing a simple yet effective self-attention mechanism and a semantic motion predictor, achieving high content consistency without t&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-others/vfqzxhinfu/cover.png"/></item><item><title>Stylus: Automatic Adapter Selection for Diffusion Models</title><link>https://deep-diver.github.io/neurips2024/oral-image-generation/3odq2tgspp/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/oral-image-generation/3odq2tgspp/</guid><description>Stylus: an automatic adapter selection system for diffusion models, boosts image quality and diversity by intelligently composing task-specific adapters based on prompt keywords.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/oral-image-generation/3odq2tgspp/cover.png"/></item><item><title>Suppress Content Shift: Better Diffusion Features via Off-the-Shelf Generation Techniques</title><link>https://deep-diver.github.io/neurips2024/posters/qvqldeslwa/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/qvqldeslwa/</guid><description>Boosting diffusion model features: This paper introduces GATE, a novel method to suppress &amp;lsquo;content shift&amp;rsquo; in diffusion features, improving their quality via off-the-shelf generation techniques.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/qvqldeslwa/cover.png"/></item><item><title>SyncTweedies: A General Generative Framework Based on Synchronized Diffusions</title><link>https://deep-diver.github.io/neurips2024/posters/06vt6f2js7/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/06vt6f2js7/</guid><description>SyncTweedies: a zero-shot diffusion synchronization framework generates diverse visual content (images, panoramas, 3D textures) by synchronizing multiple diffusion processes without fine-tuning, demon&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/06vt6f2js7/cover.png"/></item><item><title>Taming Diffusion Prior for Image Super-Resolution with Domain Shift SDEs</title><link>https://deep-diver.github.io/neurips2024/posters/u7oktt4zye/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/u7oktt4zye/</guid><description>DoSSR: A novel SR model boosts efficiency by 5-7x, achieving state-of-the-art performance with only 5 sampling steps by cleverly integrating a domain shift equation into pretrained diffusion models.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/u7oktt4zye/cover.png"/></item><item><title>Taming Generative Diffusion Prior for Universal Blind Image Restoration</title><link>https://deep-diver.github.io/neurips2024/posters/nbforcwqbr/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/nbforcwqbr/</guid><description>BIR-D tames generative diffusion models for universal blind image restoration, dynamically updating parameters to handle various complex degradations without assuming degradation model types.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/nbforcwqbr/cover.png"/></item><item><title>TextCtrl: Diffusion-based Scene Text Editing with Prior Guidance Control</title><link>https://deep-diver.github.io/neurips2024/spotlight-others/sqvns9hwjt/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-others/sqvns9hwjt/</guid><description>TextCtrl: a novel diffusion-based scene text editing method using prior guidance control, achieving superior style fidelity and accuracy with a new real-world benchmark dataset, ScenePair.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-others/sqvns9hwjt/cover.png"/></item><item><title>The GAN is dead; long live the GAN! A Modern GAN Baseline</title><link>https://deep-diver.github.io/neurips2024/posters/ortn9hpp7v/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/ortn9hpp7v/</guid><description>R3GAN, a minimalist GAN baseline, surpasses state-of-the-art models by using a novel regularized relativistic GAN loss and modern architectures, proving GANs can be trained efficiently without relying&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/ortn9hpp7v/cover.png"/></item><item><title>Time-Varying LoRA: Towards Effective Cross-Domain Fine-Tuning of Diffusion Models</title><link>https://deep-diver.github.io/neurips2024/posters/sgodu2mx9t/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/sgodu2mx9t/</guid><description>Terra, a novel time-varying low-rank adapter, enables effective cross-domain fine-tuning of diffusion models by creating a continuous parameter manifold, facilitating efficient knowledge sharing and g&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/sgodu2mx9t/cover.png"/></item><item><title>TinyLUT: Tiny Look-Up Table for Efficient Image Restoration at the Edge</title><link>https://deep-diver.github.io/neurips2024/posters/tn0xnyplt6/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/tn0xnyplt6/</guid><description>TinyLUT achieves 10x lower memory consumption and superior accuracy in image restoration on edge devices using innovative separable mapping and dynamic discretization of LUTs.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/tn0xnyplt6/cover.png"/></item><item><title>TPC: Test-time Procrustes Calibration for Diffusion-based Human Image Animation</title><link>https://deep-diver.github.io/neurips2024/posters/h6nse8awct/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/h6nse8awct/</guid><description>Boosting diffusion-based human image animation, Test-time Procrustes Calibration (TPC) ensures high-quality outputs by aligning reference and target images, overcoming common compositional misalignmen&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/h6nse8awct/cover.png"/></item><item><title>Training-Free Adaptive Diffusion with Bounded Difference Approximation Strategy</title><link>https://deep-diver.github.io/neurips2024/posters/cs63ytj49a/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/cs63ytj49a/</guid><description>AdaptiveDiffusion accelerates diffusion model inference by adaptively skipping noise prediction steps, achieving 2-5x speedup without quality loss.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/cs63ytj49a/cover.png"/></item><item><title>U-DiTs: Downsample Tokens in U-Shaped Diffusion Transformers</title><link>https://deep-diver.github.io/neurips2024/posters/srws2wxns7/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/srws2wxns7/</guid><description>U-DiT: Revolutionizing diffusion transformers with a U-Net design and token downsampling for superior image generation and drastically reduced computation cost.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/srws2wxns7/cover.png"/></item><item><title>UDPM: Upsampling Diffusion Probabilistic Models</title><link>https://deep-diver.github.io/neurips2024/posters/9utmgibhbt/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/9utmgibhbt/</guid><description>UDPM: Upsampling Diffusion Probabilistic Models achieves high-quality image generation with fewer computations by incorporating downsampling and upsampling within the diffusion process.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/9utmgibhbt/cover.png"/></item><item><title>UltraPixel: Advancing Ultra High-Resolution Image Synthesis to New Peaks</title><link>https://deep-diver.github.io/neurips2024/posters/vojcpdlw53/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/vojcpdlw53/</guid><description>UltraPixel generates high-quality images at various resolutions (1K-6K) efficiently using cascade diffusion models, achieving state-of-the-art performance.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/vojcpdlw53/cover.png"/></item><item><title>Understanding and Improving Training-free Loss-based Diffusion Guidance</title><link>https://deep-diver.github.io/neurips2024/posters/eu80dguocs/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/eu80dguocs/</guid><description>Training-free guidance revolutionizes diffusion models by enabling zero-shot conditional generation, but suffers from misaligned gradients and slow convergence. This paper provides theoretical analysi&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/eu80dguocs/cover.png"/></item><item><title>Understanding Hallucinations in Diffusion Models through Mode Interpolation</title><link>https://deep-diver.github.io/neurips2024/posters/antnhbkw4t/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/antnhbkw4t/</guid><description>Diffusion models generate unrealistic images by smoothly interpolating between data modes; this paper identifies this &amp;lsquo;mode interpolation&amp;rsquo; failure and proposes a metric to detect and reduce it.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/antnhbkw4t/cover.png"/></item><item><title>Unified Gradient-Based Machine Unlearning with Remain Geometry Enhancement</title><link>https://deep-diver.github.io/neurips2024/spotlight-others/dhedf5epbt/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-others/dhedf5epbt/</guid><description>Enhance deep neural network privacy and trustworthiness with unified gradient-based machine unlearning, leveraging remain geometry for efficient forgetting and performance preservation.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-others/dhedf5epbt/cover.png"/></item><item><title>UniFL: Improve Latent Diffusion Model via Unified Feedback Learning</title><link>https://deep-diver.github.io/neurips2024/posters/sy2smstdob/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/sy2smstdob/</guid><description>UniFL: Unified Feedback Learning revolutionizes latent diffusion models by improving image quality, aesthetics, and inference speed through a unified feedback learning framework, surpassing existing m&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/sy2smstdob/cover.png"/></item><item><title>Unleashing the Denoising Capability of Diffusion Prior for Solving Inverse Problems</title><link>https://deep-diver.github.io/neurips2024/posters/2fiyzs3ykh/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/2fiyzs3ykh/</guid><description>ProjDiff: A novel algorithm unleashes diffusion models&amp;rsquo; denoising power for superior inverse problem solutions.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/2fiyzs3ykh/cover.png"/></item><item><title>Unlocking the Capabilities of Masked Generative Models for Image Synthesis via Self-Guidance</title><link>https://deep-diver.github.io/neurips2024/posters/1l9ceyfmxg/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/1l9ceyfmxg/</guid><description>Self-guidance boosts masked generative models&amp;rsquo; image synthesis, achieving superior quality and diversity with fewer steps!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/1l9ceyfmxg/cover.png"/></item><item><title>Unsupervised Homography Estimation on Multimodal Image Pair via Alternating Optimization</title><link>https://deep-diver.github.io/neurips2024/posters/zkhyrxlwqh/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/zkhyrxlwqh/</guid><description>AltO: a novel unsupervised learning framework for accurately estimating homography from multimodal image pairs, achieving performance comparable to supervised methods.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/zkhyrxlwqh/cover.png"/></item><item><title>Untrained Neural Nets for Snapshot Compressive Imaging: Theory and Algorithms</title><link>https://deep-diver.github.io/neurips2024/posters/7afeqib1dp/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/7afeqib1dp/</guid><description>Untrained neural networks revolutionize snapshot compressive imaging (SCI) by enabling high-dimensional data recovery from a single 2D measurement, achieving state-of-the-art results without needing e&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/7afeqib1dp/cover.png"/></item><item><title>UPS: Unified Projection Sharing for Lightweight Single-Image Super-resolution and Beyond</title><link>https://deep-diver.github.io/neurips2024/posters/tacb2bfzcm/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/tacb2bfzcm/</guid><description>UPS: A novel algorithm for lightweight single-image super-resolution, decoupling feature extraction and similarity modeling for enhanced efficiency and robustness.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/tacb2bfzcm/cover.png"/></item><item><title>Virtual Scanning: Unsupervised Non-line-of-sight Imaging from Irregularly Undersampled Transients</title><link>https://deep-diver.github.io/neurips2024/posters/r4ibzrsf5d/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/r4ibzrsf5d/</guid><description>Unsupervised learning framework enables high-fidelity non-line-of-sight (NLOS) imaging from irregularly undersampled transients, surpassing state-of-the-art methods in speed and robustness.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/r4ibzrsf5d/cover.png"/></item><item><title>Visual Autoregressive Modeling: Scalable Image Generation via Next-Scale Prediction</title><link>https://deep-diver.github.io/neurips2024/oral-image-generation/gojl67cfs8/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/oral-image-generation/gojl67cfs8/</guid><description>Visual Autoregressive Modeling (VAR) revolutionizes image generation by using a coarse-to-fine &amp;rsquo;next-scale prediction&amp;rsquo;, outperforming diffusion models and exhibiting scaling laws similar to LLMs.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/oral-image-generation/gojl67cfs8/cover.png"/></item><item><title>Visual Decoding and Reconstruction via EEG Embeddings with Guided Diffusion</title><link>https://deep-diver.github.io/neurips2024/posters/rxkcroc8qp/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/rxkcroc8qp/</guid><description>Researchers developed a novel zero-shot EEG-based framework for visual reconstruction using a tailored brain encoder and a two-stage image generation strategy, achieving state-of-the-art performance i&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/rxkcroc8qp/cover.png"/></item><item><title>Vivid-ZOO: Multi-View Video Generation with Diffusion Model</title><link>https://deep-diver.github.io/neurips2024/posters/bpoahf8ocx/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/bpoahf8ocx/</guid><description>Vivid-ZOO: Generating high-quality multi-view videos from text using a novel diffusion model.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/bpoahf8ocx/cover.png"/></item><item><title>Warped Diffusion: Solving Video Inverse Problems with Image Diffusion Models</title><link>https://deep-diver.github.io/neurips2024/posters/lh94zpv8cu/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/lh94zpv8cu/</guid><description>Warped Diffusion cleverly adapts image diffusion models for video inverse problems, solving flickering and temporal inconsistency issues by viewing video frames as continuous warping transformations a&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/lh94zpv8cu/cover.png"/></item><item><title>Zero-shot Image Editing with Reference Imitation</title><link>https://deep-diver.github.io/neurips2024/posters/lzv0u6uhb6/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/lzv0u6uhb6/</guid><description>MimicBrush: a novel image editing approach using reference imitation for intuitive zero-shot edits.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/lzv0u6uhb6/cover.png"/></item><item><title>Zero-to-Hero: Enhancing Zero-Shot Novel View Synthesis via Attention Map Filtering</title><link>https://deep-diver.github.io/neurips2024/posters/3uqtnwntwz/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/3uqtnwntwz/</guid><description>Zero-to-Hero enhances zero-shot novel view synthesis by cleverly filtering attention maps during inference, achieving significantly higher fidelity and realism without retraining.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/3uqtnwntwz/cover.png"/></item></channel></rss>