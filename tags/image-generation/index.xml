<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Image Generation on NeurIPS 2024</title><link>https://deep-diver.github.io/neurips2024/tags/image-generation/</link><description>Recent content in Image Generation on NeurIPS 2024</description><generator>Hugo -- gohugo.io</generator><language>en</language><copyright>© 2024 AI Paper Reviewer</copyright><lastBuildDate>Thu, 26 Sep 2024 00:00:00 +0000</lastBuildDate><atom:link href="https://deep-diver.github.io/neurips2024/tags/image-generation/index.xml" rel="self" type="application/rss+xml"/><item><title>Action Imitation in Common Action Space for Customized Action Image Synthesis</title><link>https://deep-diver.github.io/neurips2024/posters/h2e4g2yiwr/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/h2e4g2yiwr/</guid><description>TwinAct: Decoupling actions and actors for customizable text-guided action image generation.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/h2e4g2yiwr/cover.png"/></item><item><title>Adapting Diffusion Models for Improved Prompt Compliance and Controllable Image Synthesis</title><link>https://deep-diver.github.io/neurips2024/posters/sntv8ac3u2/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/sntv8ac3u2/</guid><description>FG-DMs revolutionize image synthesis by jointly modeling image and condition distributions, achieving higher object recall and enabling flexible editing.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/sntv8ac3u2/cover.png"/></item><item><title>Adversarial Schrödinger Bridge Matching</title><link>https://deep-diver.github.io/neurips2024/posters/l3knnigicu/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/l3knnigicu/</guid><description>Accelerate Schrödinger Bridge Matching with Discrete-time IMF using only a few steps, achieving comparable results to existing hundred-step methods via D-GAN implementation.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/l3knnigicu/cover.png"/></item><item><title>AirSketch: Generative Motion to Sketch</title><link>https://deep-diver.github.io/neurips2024/posters/ttlcbekaj6/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/ttlcbekaj6/</guid><description>AirSketch generates aesthetically pleasing sketches directly from noisy hand-motion tracking data using a self-supervised controllable diffusion model, eliminating the need for expensive AR/VR equipme&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/ttlcbekaj6/cover.png"/></item><item><title>An Image is Worth 32 Tokens for Reconstruction and Generation</title><link>https://deep-diver.github.io/neurips2024/posters/toxoqprzpl/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/toxoqprzpl/</guid><description>Image generation gets a speed boost with TiTok, a novel 1D image tokenizer that uses just 32 tokens for high-quality image reconstruction and generation, achieving up to 410x faster processing than st&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/toxoqprzpl/cover.png"/></item><item><title>Applying Guidance in a Limited Interval Improves Sample and Distribution Quality in Diffusion Models</title><link>https://deep-diver.github.io/neurips2024/posters/naihvny15t/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/naihvny15t/</guid><description>Boosting image generation: Applying guidance selectively during diffusion model sampling drastically enhances image quality and inference speed, achieving state-of-the-art results.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/naihvny15t/cover.png"/></item><item><title>AsCAN: Asymmetric Convolution-Attention Networks for Efficient Recognition and Generation</title><link>https://deep-diver.github.io/neurips2024/posters/r0escj6qsl/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/r0escj6qsl/</guid><description>AsCAN, a novel hybrid architecture, achieves superior efficiency and performance in image recognition and generation by asymmetrically combining convolutional and transformer blocks.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/r0escj6qsl/cover.png"/></item><item><title>Association of Objects May Engender Stereotypes: Mitigating Association-Engendered Stereotypes in Text-to-Image Generation</title><link>https://deep-diver.github.io/neurips2024/spotlight-others/shyqxpnblb/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-others/shyqxpnblb/</guid><description>New framework, MAS, effectively mitigates stereotypes in text-to-image generation by aligning the probability distribution of generated images to stereotype-free distributions.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-others/shyqxpnblb/cover.png"/></item><item><title>Attack-Resilient Image Watermarking Using Stable Diffusion</title><link>https://deep-diver.github.io/neurips2024/posters/e6krsoughj/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/e6krsoughj/</guid><description>ZoDiac: a novel image watermarking framework leveraging pre-trained stable diffusion models for robust, invisible watermarks resistant to state-of-the-art attacks.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/e6krsoughj/cover.png"/></item><item><title>Autoregressive Image Generation without Vector Quantization</title><link>https://deep-diver.github.io/neurips2024/spotlight-others/vnbif0gmkb/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-others/vnbif0gmkb/</guid><description>Autoregressive image generation is revolutionized by eliminating vector quantization, achieving strong results with increased speed using a novel diffusion procedure.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-others/vnbif0gmkb/cover.png"/></item><item><title>BiDM: Pushing the Limit of Quantization for Diffusion Models</title><link>https://deep-diver.github.io/neurips2024/posters/owaitgb8lj/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/owaitgb8lj/</guid><description>BiDM achieves full 1-bit quantization in diffusion models, significantly improving storage and speed without sacrificing image quality, setting a new state-of-the-art.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/owaitgb8lj/cover.png"/></item><item><title>Binarized Diffusion Model for Image Super-Resolution</title><link>https://deep-diver.github.io/neurips2024/posters/yxpfrlmir2/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/yxpfrlmir2/</guid><description>BI-DiffSR, a novel binarized diffusion model, achieves high-quality image super-resolution with significantly reduced memory and computational costs, outperforming existing methods.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/yxpfrlmir2/cover.png"/></item><item><title>BLAST: Block-Level Adaptive Structured Matrices for Efficient Deep Neural Network Inference</title><link>https://deep-diver.github.io/neurips2024/posters/n0ars0ddot/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/n0ars0ddot/</guid><description>BLAST matrix learns efficient weight structures for faster deep learning inference, achieving significant compression and performance gains on various models.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/n0ars0ddot/cover.png"/></item><item><title>Blind Image Restoration via Fast Diffusion Inversion</title><link>https://deep-diver.github.io/neurips2024/posters/hfsjlbrkkj/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/hfsjlbrkkj/</guid><description>BIRD: a novel blind image restoration method jointly optimizes degradation model parameters and the restored image, ensuring realistic outputs via fast diffusion inversion and achieving state-of-the-a&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/hfsjlbrkkj/cover.png"/></item><item><title>BrainBits: How Much of the Brain are Generative Reconstruction Methods Using?</title><link>https://deep-diver.github.io/neurips2024/posters/kaauvi4kpb/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/kaauvi4kpb/</guid><description>BrainBits reveals that surprisingly little brain information is needed for high-fidelity image &amp;amp; text reconstruction, highlighting the dominance of generative model priors over neural signal extractio&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/kaauvi4kpb/cover.png"/></item><item><title>Can Simple Averaging Defeat Modern Watermarks?</title><link>https://deep-diver.github.io/neurips2024/posters/x2g7la7av9/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/x2g7la7av9/</guid><description>Simple averaging of watermarked images reveals hidden patterns, enabling watermark removal and forgery, thus highlighting the vulnerability of content-agnostic watermarking methods.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/x2g7la7av9/cover.png"/></item><item><title>Classification Diffusion Models: Revitalizing Density Ratio Estimation</title><link>https://deep-diver.github.io/neurips2024/posters/d99ycfonwk/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/d99ycfonwk/</guid><description>Classification Diffusion Models (CDMs) revolutionize density ratio estimation by integrating the strengths of diffusion models and classifiers, achieving state-of-the-art image generation and likeliho&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/d99ycfonwk/cover.png"/></item><item><title>ColJailBreak: Collaborative Generation and Editing for Jailbreaking Text-to-Image Deep Generation</title><link>https://deep-diver.github.io/neurips2024/posters/egizetmate/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/egizetmate/</guid><description>ColJailBreak cleverly circumvents AI safety filters by first generating safe images and then subtly injecting unsafe content using image editing.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/egizetmate/cover.png"/></item><item><title>Consistency Purification: Effective and Efficient Diffusion Purification towards Certified Robustness</title><link>https://deep-diver.github.io/neurips2024/posters/tlwoxftjvh/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/tlwoxftjvh/</guid><description>Consistency Purification boosts certified robustness by efficiently purifying noisy images using a one-step generative model, achieving state-of-the-art results while maintaining semantic alignment.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/tlwoxftjvh/cover.png"/></item><item><title>Constrained Diffusion with Trust Sampling</title><link>https://deep-diver.github.io/neurips2024/posters/djub9xrozi/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/djub9xrozi/</guid><description>Trust Sampling enhances guided diffusion by iteratively optimizing constrained generation at each step, improving efficiency and accuracy in image and 3D motion generation.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/djub9xrozi/cover.png"/></item><item><title>Cooperative Hardware-Prompt Learning for Snapshot Compressive Imaging</title><link>https://deep-diver.github.io/neurips2024/posters/zxswidyw3a/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/zxswidyw3a/</guid><description>Federated Hardware-Prompt Learning (FedHP) enables robust cross-hardware SCI training by aligning inconsistent data distributions using a hardware-conditioned prompter, outperforming existing FL metho&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/zxswidyw3a/cover.png"/></item><item><title>CryoGEM: Physics-Informed Generative Cryo-Electron Microscopy</title><link>https://deep-diver.github.io/neurips2024/posters/edozifvwmi/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/edozifvwmi/</guid><description>CryoGEM: Physics-informed generative model creates realistic synthetic cryo-EM datasets, boosting particle picking and pose estimation accuracy for higher-resolution protein structure determination.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/edozifvwmi/cover.png"/></item><item><title>Ctrl-X: Controlling Structure and Appearance for Text-To-Image Generation Without Guidance</title><link>https://deep-diver.github.io/neurips2024/posters/zulwewqop9/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/zulwewqop9/</guid><description>Ctrl-X: Zero-shot text-to-image generation with training-free structure &amp;amp; appearance control!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/zulwewqop9/cover.png"/></item><item><title>DDR: Exploiting Deep Degradation Response as Flexible Image Descriptor</title><link>https://deep-diver.github.io/neurips2024/posters/rxlo4zv3wb/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/rxlo4zv3wb/</guid><description>Deep Degradation Response (DDR) uses image deep feature changes under degradation to create a flexible image descriptor, excelling in blind image quality assessment and unsupervised image restoration.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/rxlo4zv3wb/cover.png"/></item><item><title>Dealing with Synthetic Data Contamination in Online Continual Learning</title><link>https://deep-diver.github.io/neurips2024/posters/lc8gemv97y/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/lc8gemv97y/</guid><description>AI-generated images contaminate online continual learning datasets, hindering performance. A new method, ESRM, leverages entropy and real/synthetic similarity maximization to select high-quality data&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/lc8gemv97y/cover.png"/></item><item><title>Defensive Unlearning with Adversarial Training for Robust Concept Erasure in Diffusion Models</title><link>https://deep-diver.github.io/neurips2024/posters/dkpmfiydrf/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/dkpmfiydrf/</guid><description>AdvUnlearn enhances diffusion model robustness against adversarial attacks during concept erasure by integrating adversarial training, improving the trade-off between robustness and model utility.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/dkpmfiydrf/cover.png"/></item><item><title>Diffusion Priors for Variational Likelihood Estimation and Image Denoising</title><link>https://deep-diver.github.io/neurips2024/spotlight-others/oukw8cuiuy/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-others/oukw8cuiuy/</guid><description>Adaptive likelihood estimation and MAP inference during reverse diffusion tackles real-world image noise.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-others/oukw8cuiuy/cover.png"/></item><item><title>Diffusion4D: Fast Spatial-temporal Consistent 4D generation via Video Diffusion Models</title><link>https://deep-diver.github.io/neurips2024/posters/grrefkwees/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/grrefkwees/</guid><description>Diffusion4D: Fast, consistent 4D content generation via a novel 4D-aware video diffusion model, surpassing existing methods in efficiency and 4D geometry consistency.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/grrefkwees/cover.png"/></item><item><title>DiMSUM: Diffusion Mamba - A Scalable and Unified Spatial-Frequency Method for Image Generation</title><link>https://deep-diver.github.io/neurips2024/posters/kqblzsixkm/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/kqblzsixkm/</guid><description>DiMSUM: A novel diffusion model boosts image generation by unifying spatial and frequency information, achieving superior results and faster training.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/kqblzsixkm/cover.png"/></item><item><title>DiP-GO: A Diffusion Pruner via Few-step Gradient Optimization</title><link>https://deep-diver.github.io/neurips2024/posters/sbsarj475e/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/sbsarj475e/</guid><description>DiP-GO: A novel pruning method accelerates diffusion models via few-step gradient optimization, achieving a 4.4x speedup on Stable Diffusion 1.5 without accuracy loss.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/sbsarj475e/cover.png"/></item><item><title>Direct Consistency Optimization for Robust Customization of Text-to-Image Diffusion models</title><link>https://deep-diver.github.io/neurips2024/posters/vazkrbcgxt/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/vazkrbcgxt/</guid><description>Boosting personalized image generation! Direct Consistency Optimization (DCO) fine-tunes text-to-image models, ensuring subject consistency and prompt fidelity, even when merging separately customized&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/vazkrbcgxt/cover.png"/></item><item><title>DomainGallery: Few-shot Domain-driven Image Generation by Attribute-centric Finetuning</title><link>https://deep-diver.github.io/neurips2024/posters/zmmj1z8vee/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/zmmj1z8vee/</guid><description>DomainGallery: Few-shot domain-driven image generation via attribute-centric finetuning, solving key issues of previous works by introducing attribute erasure, disentanglement, regularization, and enh&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/zmmj1z8vee/cover.png"/></item><item><title>Doubly Hierarchical Geometric Representations for Strand-based Human Hairstyle Generation</title><link>https://deep-diver.github.io/neurips2024/posters/h34jvnpo1c/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/h34jvnpo1c/</guid><description>Doubly hierarchical geometric representations enable realistic human hairstyle generation by separating low and high-frequency details in hair strands, resulting in high-quality, detailed virtual hair&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/h34jvnpo1c/cover.png"/></item><item><title>DRACO: A Denoising-Reconstruction Autoencoder for Cryo-EM</title><link>https://deep-diver.github.io/neurips2024/posters/u1mnglyn74/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/u1mnglyn74/</guid><description>DRACO, a denoising-reconstruction autoencoder, revolutionizes cryo-EM by leveraging a large-scale dataset and hybrid training for superior image denoising and downstream task performance.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/u1mnglyn74/cover.png"/></item><item><title>ECMamba: Consolidating Selective State Space Model with Retinex Guidance for Efficient Multiple Exposure Correction</title><link>https://deep-diver.github.io/neurips2024/posters/mzsvm58fpg/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/mzsvm58fpg/</guid><description>ECMamba: A novel dual-branch framework efficiently corrects multiple exposure images by integrating Retinex theory and an innovative 2D selective state-space layer, achieving state-of-the-art performa&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/mzsvm58fpg/cover.png"/></item><item><title>EM Distillation for One-step Diffusion Models</title><link>https://deep-diver.github.io/neurips2024/posters/rafvvthuxd/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/rafvvthuxd/</guid><description>EM Distillation (EMD) efficiently trains one-step diffusion models by using an Expectation-Maximization approach, achieving state-of-the-art image generation quality and outperforming existing methods&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/rafvvthuxd/cover.png"/></item><item><title>ENAT: Rethinking Spatial-temporal Interactions in Token-based Image Synthesis</title><link>https://deep-diver.github.io/neurips2024/posters/phsyfytehr/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/phsyfytehr/</guid><description>EfficientNAT: a novel approach to token-based image synthesis boosts performance and slashes computational costs by cleverly disentangling and optimizing spatial-temporal interactions between image to&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/phsyfytehr/cover.png"/></item><item><title>Enhancing Consistency-Based Image Generation via Adversarialy-Trained Classification and Energy-Based Discrimination</title><link>https://deep-diver.github.io/neurips2024/posters/ubvcpamdgk/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/ubvcpamdgk/</guid><description>This paper introduces a novel post-processing technique that significantly boosts the perceptual quality of images generated by consistency models using a joint classifier-discriminator adversarially &amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/ubvcpamdgk/cover.png"/></item><item><title>Exploring DCN-like architecture for fast image generation with arbitrary resolution</title><link>https://deep-diver.github.io/neurips2024/posters/e57b7bfa2b/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/e57b7bfa2b/</guid><description>FlowDCN: A purely convolutional generative model achieves state-of-the-art image generation speed and quality at arbitrary resolutions, surpassing transformer-based models.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/e57b7bfa2b/cover.png"/></item><item><title>Face2QR: A Unified Framework for Aesthetic, Face-Preserving, and Scannable QR Code Generation</title><link>https://deep-diver.github.io/neurips2024/posters/rvbabl7duu/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/rvbabl7duu/</guid><description>Face2QR: A unified framework generates aesthetically pleasing, scannable QR codes that faithfully preserve facial features, solving the conflict between aesthetics, identity, and scannability.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/rvbabl7duu/cover.png"/></item><item><title>FashionR2R: Texture-preserving Rendered-to-Real Image Translation with Diffusion Models</title><link>https://deep-diver.github.io/neurips2024/posters/qaenr5j172/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/qaenr5j172/</guid><description>FashionR2R leverages diffusion models to realistically translate rendered fashion images into photorealistic counterparts, enhancing realism and preserving fine-grained clothing textures.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/qaenr5j172/cover.png"/></item><item><title>Finding NeMo: Localizing Neurons Responsible For Memorization in Diffusion Models</title><link>https://deep-diver.github.io/neurips2024/posters/yaekmfzyjm/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/yaekmfzyjm/</guid><description>NEMO pinpoints &amp;amp; deactivates neurons memorizing training data in diffusion models, boosting privacy &amp;amp; image diversity.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/yaekmfzyjm/cover.png"/></item><item><title>From Trojan Horses to Castle Walls: Unveiling Bilateral Data Poisoning Effects in Diffusion Models</title><link>https://deep-diver.github.io/neurips2024/posters/yixzzc5qdi/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/yixzzc5qdi/</guid><description>Diffusion models, while excelling in image generation, are vulnerable to data poisoning. This paper demonstrates a BadNets-like attack&amp;rsquo;s effectiveness against diffusion models, causing image misalign&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/yixzzc5qdi/cover.png"/></item><item><title>FuseAnyPart: Diffusion-Driven Facial Parts Swapping via Multiple Reference Images</title><link>https://deep-diver.github.io/neurips2024/spotlight-others/x2umdvcmmo/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-others/x2umdvcmmo/</guid><description>FuseAnyPart: Swap facial parts seamlessly using multiple reference images via diffusion, achieving high-fidelity results.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-others/x2umdvcmmo/cover.png"/></item><item><title>General Articulated Objects Manipulation in Real Images via Part-Aware Diffusion Process</title><link>https://deep-diver.github.io/neurips2024/posters/wrd9lcbvxn/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/wrd9lcbvxn/</guid><description>Part-Aware Diffusion Model (PA-Diffusion) enables precise and efficient manipulation of articulated objects in real images by using abstract 3D models and dynamic feature maps, overcoming limitations &amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/wrd9lcbvxn/cover.png"/></item><item><title>GenWarp: Single Image to Novel Views with Semantic-Preserving Generative Warping</title><link>https://deep-diver.github.io/neurips2024/posters/rljisjmmkw/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/rljisjmmkw/</guid><description>GenWarp generates high-quality novel image views from a single input image by using a semantic-preserving generative warping framework, outperforming existing methods.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/rljisjmmkw/cover.png"/></item><item><title>Gradient-free Decoder Inversion in Latent Diffusion Models</title><link>https://deep-diver.github.io/neurips2024/posters/nbqvjkos6s/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/nbqvjkos6s/</guid><description>This paper introduces a novel gradient-free decoder inversion method for latent diffusion models, improving efficiency and memory usage compared to existing gradient-based methods. The method is theo&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/nbqvjkos6s/cover.png"/></item><item><title>Guiding a Diffusion Model with a Bad Version of Itself</title><link>https://deep-diver.github.io/neurips2024/oral-image-generation/bg6fvpvs3s/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/oral-image-generation/bg6fvpvs3s/</guid><description>Boost image quality in diffusion models without reducing variation using Autoguidance: guide a high-quality model with a less-trained version of itself!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/oral-image-generation/bg6fvpvs3s/cover.png"/></item><item><title>HairFastGAN: Realistic and Robust Hair Transfer with a Fast Encoder-Based Approach</title><link>https://deep-diver.github.io/neurips2024/posters/sgvzyv2iqn/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/sgvzyv2iqn/</guid><description>HairFastGAN achieves realistic and robust hairstyle transfer in near real-time using a novel encoder-based approach, significantly outperforming optimization-based methods.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/sgvzyv2iqn/cover.png"/></item><item><title>HiCo: Hierarchical Controllable Diffusion Model for Layout-to-image Generation</title><link>https://deep-diver.github.io/neurips2024/posters/i9qprjuahv/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/i9qprjuahv/</guid><description>HiCo: Hierarchical Controllable Diffusion Model achieves superior layout-to-image generation by disentangling spatial layouts through a multi-branch network structure, resulting in high-quality images&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/i9qprjuahv/cover.png"/></item><item><title>High-Resolution Image Harmonization with Adaptive-Interval Color Transformation</title><link>https://deep-diver.github.io/neurips2024/posters/jxghewtxs8/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/jxghewtxs8/</guid><description>AICT: Adaptive-Interval Color Transformation harmonizes high-resolution images by predicting pixel-wise color changes, adaptively adjusting sampling intervals to capture local variations, and using a &amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/jxghewtxs8/cover.png"/></item><item><title>Hollowed Net for On-Device Personalization of Text-to-Image Diffusion Models</title><link>https://deep-diver.github.io/neurips2024/posters/pa8jsrdonu/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/pa8jsrdonu/</guid><description>Hollowed Net efficiently personalizes text-to-image diffusion models on-device by temporarily removing deep U-Net layers during training, drastically reducing memory usage without sacrificing performa&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/pa8jsrdonu/cover.png"/></item><item><title>Identifying and Solving Conditional Image Leakage in Image-to-Video Diffusion Model</title><link>https://deep-diver.github.io/neurips2024/posters/o9lkiv1qpc/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/o9lkiv1qpc/</guid><description>Researchers solve the conditional image leakage problem in image-to-video diffusion models by proposing a new inference strategy and a time-dependent noise distribution for training. This yields video&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/o9lkiv1qpc/cover.png"/></item><item><title>Identity Decoupling for Multi-Subject Personalization of Text-to-Image Models</title><link>https://deep-diver.github.io/neurips2024/posters/teepvpdarf/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/teepvpdarf/</guid><description>MuDI: a novel framework for multi-subject image personalization, effectively decoupling identities to prevent mixing using segmented subjects and a new evaluation metric.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/teepvpdarf/cover.png"/></item><item><title>Image Reconstruction Via Autoencoding Sequential Deep Image Prior</title><link>https://deep-diver.github.io/neurips2024/posters/k1eg2abzne/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/k1eg2abzne/</guid><description>aSeqDIP: A new unsupervised image reconstruction method using sequential deep image priors, achieving competitive performance with fewer data needs and faster runtimes.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/k1eg2abzne/cover.png"/></item><item><title>Image Understanding Makes for A Good Tokenizer for Image Generation</title><link>https://deep-diver.github.io/neurips2024/posters/rmmgu49lwn/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/rmmgu49lwn/</guid><description>Leveraging image understanding models for image tokenizer training dramatically boosts image generation quality, achieving state-of-the-art results.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/rmmgu49lwn/cover.png"/></item><item><title>Improved Distribution Matching Distillation for Fast Image Synthesis</title><link>https://deep-diver.github.io/neurips2024/oral-image-generation/tqukgcdant/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/oral-image-generation/tqukgcdant/</guid><description>DMD2 dramatically speeds up image generation by cleverly distilling expensive diffusion models, achieving state-of-the-art results without sacrificing quality.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/oral-image-generation/tqukgcdant/cover.png"/></item><item><title>Invertible Consistency Distillation for Text-Guided Image Editing in Around 7 Steps</title><link>https://deep-diver.github.io/neurips2024/posters/b1xphc7mqb/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/b1xphc7mqb/</guid><description>Invertible Consistency Distillation (iCD) achieves high-quality image editing in ~7 steps by enabling both fast editing and strong generation using a generalized distillation framework and dynamic cla&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/b1xphc7mqb/cover.png"/></item><item><title>KOALA: Empirical Lessons Toward Memory-Efficient and Fast Diffusion Models for Text-to-Image Synthesis</title><link>https://deep-diver.github.io/neurips2024/posters/kndubpwv9b/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/kndubpwv9b/</guid><description>KOALA: New efficient text-to-image diffusion models achieving 4x speed and 69% size reduction of SDXL, generating 1024px images on consumer GPUs with 8GB VRAM.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/kndubpwv9b/cover.png"/></item><item><title>Latent Intrinsics Emerge from Training to Relight</title><link>https://deep-diver.github.io/neurips2024/spotlight-others/ltndg0ezf9/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-others/ltndg0ezf9/</guid><description>A novel data-driven relighting model achieves state-of-the-art accuracy by learning latent intrinsic and extrinsic scene properties, even recovering albedo without explicit supervision.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-others/ltndg0ezf9/cover.png"/></item><item><title>Latent Representation Matters: Human-like Sketches in One-shot Drawing Tasks</title><link>https://deep-diver.github.io/neurips2024/posters/tzrpvlxevu/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/tzrpvlxevu/</guid><description>AI now draws almost as well as humans, thanks to novel latent diffusion model regularizations that mimic human cognitive biases.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/tzrpvlxevu/cover.png"/></item><item><title>Learning Group Actions on Latent Representations</title><link>https://deep-diver.github.io/neurips2024/posters/hgntcy4eep/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/hgntcy4eep/</guid><description>This paper proposes a novel method to model group actions within autoencoders by learning these actions in the latent space, enhancing model versatility and improving performance in various real-world&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/hgntcy4eep/cover.png"/></item><item><title>Learning Image Priors Through Patch-Based Diffusion Models for Solving Inverse Problems</title><link>https://deep-diver.github.io/neurips2024/posters/hgnxhhz6ss/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/hgnxhhz6ss/</guid><description>PaDIS: Patch-based diffusion inverse solver learns efficient image priors from image patches, enabling high-resolution inverse problem solutions with reduced computational costs and data needs.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/hgnxhhz6ss/cover.png"/></item><item><title>Learning-to-Cache: Accelerating Diffusion Transformer via Layer Caching</title><link>https://deep-diver.github.io/neurips2024/posters/zupomzmnro/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/zupomzmnro/</guid><description>Learning-to-Cache (L2C) dramatically accelerates diffusion transformers by intelligently caching layer computations, achieving significant speedups with minimal performance loss.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/zupomzmnro/cover.png"/></item><item><title>LiteVAE: Lightweight and Efficient Variational Autoencoders for Latent Diffusion Models</title><link>https://deep-diver.github.io/neurips2024/posters/mtabl8kuzq/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/mtabl8kuzq/</guid><description>LiteVAE: A new autoencoder design for latent diffusion models boosts efficiency sixfold without sacrificing image quality, achieving faster training and lower memory needs via the 2D discrete wavelet &amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/mtabl8kuzq/cover.png"/></item><item><title>Masked Pre-training Enables Universal Zero-shot Denoiser</title><link>https://deep-diver.github.io/neurips2024/posters/ofgtscasbr/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/ofgtscasbr/</guid><description>Masked Pre-training empowers a universal, fast zero-shot image denoiser!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/ofgtscasbr/cover.png"/></item><item><title>MC-DiT: Contextual Enhancement via Clean-to-Clean Reconstruction for Masked Diffusion Models</title><link>https://deep-diver.github.io/neurips2024/posters/y9shkrdnrt/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/y9shkrdnrt/</guid><description>MC-DiT: A novel training paradigm for masked diffusion models achieving state-of-the-art image generation by leveraging clean-to-clean reconstruction.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/y9shkrdnrt/cover.png"/></item><item><title>MimicTalk: Mimicking a personalized and expressive 3D talking face in minutes</title><link>https://deep-diver.github.io/neurips2024/posters/gjezl0bamb/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/gjezl0bamb/</guid><description>MimicTalk generates realistic, expressive talking videos in minutes using a pre-trained model adapted to individual identities.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/gjezl0bamb/cover.png"/></item><item><title>Neural Assets: 3D-Aware Multi-Object Scene Synthesis with Image Diffusion Models</title><link>https://deep-diver.github.io/neurips2024/spotlight-others/ednslswqij/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-others/ednslswqij/</guid><description>Neural Assets enables intuitive 3D multi-object scene editing via image diffusion models by using per-object representations to control individual object poses, achieving state-of-the-art results.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-others/ednslswqij/cover.png"/></item><item><title>Neural Gaffer: Relighting Any Object via Diffusion</title><link>https://deep-diver.github.io/neurips2024/posters/zv2gdszb5a/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/zv2gdszb5a/</guid><description>Neural Gaffer: Relighting any object via diffusion using a single image and an environment map to produce high-quality, realistic relit images.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/zv2gdszb5a/cover.png"/></item><item><title>Not All Diffusion Model Activations Have Been Evaluated as Discriminative Features</title><link>https://deep-diver.github.io/neurips2024/spotlight-others/7uqvfzw6mo/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-others/7uqvfzw6mo/</guid><description>Unlocking superior discriminative features from diffusion models, this research reveals key activation properties for effective feature selection, surpassing state-of-the-art methods.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-others/7uqvfzw6mo/cover.png"/></item><item><title>One-Step Diffusion Distillation through Score Implicit Matching</title><link>https://deep-diver.github.io/neurips2024/posters/ogk236hsjm/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/ogk236hsjm/</guid><description>Score Implicit Matching (SIM) revolutionizes diffusion model distillation by creating high-quality, single-step generators from complex, multi-step models, achieving comparable performance and enablin&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/ogk236hsjm/cover.png"/></item><item><title>One-Step Effective Diffusion Network for Real-World Image Super-Resolution</title><link>https://deep-diver.github.io/neurips2024/posters/tptxnprvur/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/tptxnprvur/</guid><description>OSEDiff: One-step diffusion network for real-world image super-resolution, achieving comparable or better results than multi-step methods with significantly reduced computational cost and improved ima&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/tptxnprvur/cover.png"/></item><item><title>Optical Diffusion Models for Image Generation</title><link>https://deep-diver.github.io/neurips2024/posters/ry3rdqv0tq/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/ry3rdqv0tq/</guid><description>Researchers created an energy-efficient optical system for generating images using light propagation, drastically reducing the latency and energy consumption of diffusion models.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/ry3rdqv0tq/cover.png"/></item><item><title>PaGoDA: Progressive Growing of a One-Step Generator from a Low-Resolution Diffusion Teacher</title><link>https://deep-diver.github.io/neurips2024/posters/h5zygf68kh/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/h5zygf68kh/</guid><description>PaGoDA: Train high-resolution image generators efficiently by progressively growing a one-step generator from a low-resolution diffusion model. This innovative pipeline drastically cuts training cost&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/h5zygf68kh/cover.png"/></item><item><title>Phased Consistency Models</title><link>https://deep-diver.github.io/neurips2024/posters/mtbmkqyqgs/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/mtbmkqyqgs/</guid><description>Phased Consistency Models (PCMs) revolutionize diffusion model generation by overcoming LCM limitations, achieving superior speed and quality in image and video generation.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/mtbmkqyqgs/cover.png"/></item><item><title>PrefPaint: Aligning Image Inpainting Diffusion Model with Human Preference</title><link>https://deep-diver.github.io/neurips2024/posters/fvrcsk4eom/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/fvrcsk4eom/</guid><description>PrefPaint: Aligning image inpainting diffusion models with human preferences using reinforcement learning, resulting in significantly improved visual appeal.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/fvrcsk4eom/cover.png"/></item><item><title>Principled Probabilistic Imaging using Diffusion Models as Plug-and-Play Priors</title><link>https://deep-diver.github.io/neurips2024/posters/xq9hqf7vnv/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/xq9hqf7vnv/</guid><description>Principled Probabilistic Imaging uses diffusion models as plug-and-play priors for accurate posterior sampling in inverse problems, surpassing existing methods.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/xq9hqf7vnv/cover.png"/></item><item><title>Prompt-Agnostic Adversarial Perturbation for Customized Diffusion Models</title><link>https://deep-diver.github.io/neurips2024/posters/omhpejygdx/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/omhpejygdx/</guid><description>Prompt-Agnostic Adversarial Perturbation (PAP) defends customized diffusion models against image tampering, achieving superior generalization over prompt-specific methods.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/omhpejygdx/cover.png"/></item><item><title>Prune and Repaint: Content-Aware Image Retargeting for any Ratio</title><link>https://deep-diver.github.io/neurips2024/posters/qwi6esgbjb/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/qwi6esgbjb/</guid><description>Prune and Repaint: A new content-aware method for superior image retargeting across any aspect ratio, preserving key features and avoiding artifacts.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/qwi6esgbjb/cover.png"/></item><item><title>RAW: A Robust and Agile Plug-and-Play Watermark Framework for AI-Generated Images with Provable Guarantees</title><link>https://deep-diver.github.io/neurips2024/posters/ogaechzbku/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/ogaechzbku/</guid><description>RAW: A novel watermark framework ensures the authenticity of AI-generated images by embedding learnable watermarks directly into the image data, providing provable guarantees even under adversarial at&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/ogaechzbku/cover.png"/></item><item><title>Real-world Image Dehazing with Coherence-based Pseudo Labeling and Cooperative Unfolding Network</title><link>https://deep-diver.github.io/neurips2024/spotlight-others/i6tbncje2f/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-others/i6tbncje2f/</guid><description>CORUN-Colabator: a novel cooperative unfolding network and coherence-based label generator achieves state-of-the-art real-world image dehazing by effectively integrating physical knowledge and generat&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-others/i6tbncje2f/cover.png"/></item><item><title>RealCompo: Balancing Realism and Compositionality Improves Text-to-Image Diffusion Models</title><link>https://deep-diver.github.io/neurips2024/posters/r8mfn3rhd5/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/r8mfn3rhd5/</guid><description>RealCompo: A novel training-free framework dynamically balances realism and compositionality in text-to-image generation, achieving state-of-the-art results.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/r8mfn3rhd5/cover.png"/></item><item><title>Reconstructing the Image Stitching Pipeline: Integrating Fusion and Rectangling into a Unified Inpainting Model</title><link>https://deep-diver.github.io/neurips2024/posters/zviypzh9wq/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/zviypzh9wq/</guid><description>SRStitcher revolutionizes image stitching by integrating fusion and rectangling into a unified inpainting model, eliminating model training and achieving superior performance and stability.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/zviypzh9wq/cover.png"/></item><item><title>RectifID: Personalizing Rectified Flow with Anchored Classifier Guidance</title><link>https://deep-diver.github.io/neurips2024/posters/kkrj1vcqag/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/kkrj1vcqag/</guid><description>RectifID personalizes image generation by cleverly guiding a diffusion model using off-the-shelf classifiers, achieving identity preservation without needing extra training data.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/kkrj1vcqag/cover.png"/></item><item><title>ReF-LDM: A Latent Diffusion Model for Reference-based Face Image Restoration</title><link>https://deep-diver.github.io/neurips2024/posters/qy4spbhqzi/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/qy4spbhqzi/</guid><description>ReF-LDM uses reference images to improve the accuracy of face image restoration, achieving high-quality results faithful to the subject&amp;rsquo;s true appearance.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/qy4spbhqzi/cover.png"/></item><item><title>ReFIR: Grounding Large Restoration Models with Retrieval Augmentation</title><link>https://deep-diver.github.io/neurips2024/posters/ifkmfuxqdh/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/ifkmfuxqdh/</guid><description>ReFIR enhances Large Restoration Models&amp;rsquo; accuracy by incorporating retrieved images as external knowledge, mitigating hallucination without retraining.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/ifkmfuxqdh/cover.png"/></item><item><title>Remix-DiT: Mixing Diffusion Transformers for Multi-Expert Denoising</title><link>https://deep-diver.github.io/neurips2024/posters/vo5longado/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/vo5longado/</guid><description>Remix-DiT: Boosting diffusion model image generation quality by cleverly mixing smaller basis models into numerous specialized denoisers, improving efficiency and lowering costs!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/vo5longado/cover.png"/></item><item><title>Resfusion: Denoising Diffusion Probabilistic Models for Image Restoration Based on Prior Residual Noise</title><link>https://deep-diver.github.io/neurips2024/posters/jripbxwis8/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/jripbxwis8/</guid><description>Resfusion, a novel framework, accelerates image restoration by integrating residual noise into the diffusion process, achieving superior results with fewer steps.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/jripbxwis8/cover.png"/></item><item><title>RestoreAgent: Autonomous Image Restoration Agent via Multimodal Large Language Models</title><link>https://deep-diver.github.io/neurips2024/posters/xgp5ynlzwf/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/xgp5ynlzwf/</guid><description>RestoreAgent, an AI-powered image restoration agent, autonomously identifies and corrects multiple image degradations, exceeding human expert performance.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/xgp5ynlzwf/cover.png"/></item><item><title>Rethinking Imbalance in Image Super-Resolution for Efficient Inference</title><link>https://deep-diver.github.io/neurips2024/posters/fyyrzbwtnz/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/fyyrzbwtnz/</guid><description>WBSR: A novel framework for efficient image super-resolution that tackles data and model imbalances for superior performance and approximately a 34% reduction in computational cost.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/fyyrzbwtnz/cover.png"/></item><item><title>Rethinking No-reference Image Exposure Assessment from Holism to Pixel: Models, Datasets and Benchmarks</title><link>https://deep-diver.github.io/neurips2024/posters/zvrqeopioq/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/zvrqeopioq/</guid><description>Revolutionizing image exposure assessment, Pixel-level IEA Network (P-IEANet) achieves state-of-the-art performance with a novel pixel-level approach, a new dataset (IEA40K), and a benchmark of 19 met&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/zvrqeopioq/cover.png"/></item><item><title>Rethinking Score Distillation as a Bridge Between Image Distributions</title><link>https://deep-diver.github.io/neurips2024/posters/i8pkicj9km/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/i8pkicj9km/</guid><description>Researchers enhanced image generation by improving score distillation sampling via a novel Schrödinger Bridge framework, improving realism without computational overhead.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/i8pkicj9km/cover.png"/></item><item><title>Return of Unconditional Generation: A Self-supervised Representation Generation Method</title><link>https://deep-diver.github.io/neurips2024/oral-image-generation/clta4jfbml/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/oral-image-generation/clta4jfbml/</guid><description>Revolutionizing image generation, Representation-Conditioned Generation (RCG) achieves state-of-the-art results in unconditional image synthesis by leveraging self-supervised representations to condit&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/oral-image-generation/clta4jfbml/cover.png"/></item><item><title>ROBIN: Robust and Invisible Watermarks for Diffusion Models with Adversarial Optimization</title><link>https://deep-diver.github.io/neurips2024/posters/rvoxlfvnlx/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/rvoxlfvnlx/</guid><description>ROBIN: A novel watermarking method for diffusion models that actively conceals robust watermarks using adversarial optimization, enabling strong, imperceptible, and verifiable image authentication.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/rvoxlfvnlx/cover.png"/></item><item><title>Scaling the Codebook Size of VQ-GAN to 100,000 with a Utilization Rate of 99%</title><link>https://deep-diver.github.io/neurips2024/posters/rbu10yvkk6/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/rbu10yvkk6/</guid><description>VQGAN-LC massively scales VQGAN&amp;rsquo;s codebook to 100,000 entries while maintaining a 99% utilization rate, significantly boosting image generation and downstream task performance.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/rbu10yvkk6/cover.png"/></item><item><title>Scene Graph Disentanglement and Composition for Generalizable Complex Image Generation</title><link>https://deep-diver.github.io/neurips2024/spotlight-others/zgn0ywy2he/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-others/zgn0ywy2he/</guid><description>DisCo: a novel framework for generalizable complex image generation using scene graph disentanglement and composition, achieving superior performance over existing methods.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-others/zgn0ywy2he/cover.png"/></item><item><title>Schedule Your Edit: A Simple yet Effective Diffusion Noise Schedule for Image Editing</title><link>https://deep-diver.github.io/neurips2024/posters/yu6cdt7q9z/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/yu6cdt7q9z/</guid><description>Logistic Schedule: A novel noise schedule revolutionizes image editing by improving DDIM inversion, enhancing content preservation and edit fidelity without model retraining!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/yu6cdt7q9z/cover.png"/></item><item><title>ShowMaker: Creating High-Fidelity 2D Human Video via Fine-Grained Diffusion Modeling</title><link>https://deep-diver.github.io/neurips2024/posters/lpxdg0hk4h/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/lpxdg0hk4h/</guid><description>ShowMaker: Generating high-fidelity 2D human conversational videos using fine-grained diffusion modeling and 2D key points.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/lpxdg0hk4h/cover.png"/></item><item><title>Single Image Reflection Separation via Dual-Stream Interactive Transformers</title><link>https://deep-diver.github.io/neurips2024/posters/shwtw8uv8l/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/shwtw8uv8l/</guid><description>Dual-Stream Interactive Transformers (DSIT) revolutionizes single image reflection separation by using a novel dual-attention mechanism that captures inter- and intra-layer correlations, significantly&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/shwtw8uv8l/cover.png"/></item><item><title>Slight Corruption in Pre-training Data Makes Better Diffusion Models</title><link>https://deep-diver.github.io/neurips2024/spotlight-others/vfpxybqmsu/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-others/vfpxybqmsu/</guid><description>Slightly corrupting pre-training data significantly improves diffusion models&amp;rsquo; image generation quality, diversity, and fidelity.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-others/vfpxybqmsu/cover.png"/></item><item><title>Smoothed Energy Guidance: Guiding Diffusion Models with Reduced Energy Curvature of Attention</title><link>https://deep-diver.github.io/neurips2024/posters/jk728xy8g7/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/jk728xy8g7/</guid><description>Smoothed Energy Guidance (SEG) improves unconditional image generation by reducing self-attention&amp;rsquo;s energy curvature, leading to higher-quality outputs with fewer artifacts.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/jk728xy8g7/cover.png"/></item><item><title>Spatio-Temporal Interactive Learning for Efficient Image Reconstruction of Spiking Cameras</title><link>https://deep-diver.github.io/neurips2024/posters/s4zqnmywcm/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/s4zqnmywcm/</guid><description>STIR: A novel spatio-temporal network reconstructs high-quality images from spiking camera data by jointly refining motion and intensity information for efficient and accurate high-speed imaging.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/s4zqnmywcm/cover.png"/></item><item><title>SpikeReveal: Unlocking Temporal Sequences from Real Blurry Inputs with Spike Streams</title><link>https://deep-diver.github.io/neurips2024/spotlight-others/9fyat8hppv/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-others/9fyat8hppv/</guid><description>SpikeReveal: Self-supervised learning unlocks sharp video sequences from blurry, real-world spike camera data, overcoming limitations of prior supervised approaches.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-others/9fyat8hppv/cover.png"/></item><item><title>SSDiff: Spatial-spectral Integrated Diffusion Model for Remote Sensing Pansharpening</title><link>https://deep-diver.github.io/neurips2024/posters/qmvydwvrx7/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/qmvydwvrx7/</guid><description>SSDiff: A novel spatial-spectral integrated diffusion model for superior remote sensing pansharpening.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/qmvydwvrx7/cover.png"/></item><item><title>Stability and Generalizability in SDE Diffusion Models with Measure-Preserving Dynamics</title><link>https://deep-diver.github.io/neurips2024/posters/vtjvta41d0/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/vtjvta41d0/</guid><description>D³GM, a novel score-based diffusion model, enhances stability &amp;amp; generalizability in solving inverse problems by leveraging measure-preserving dynamics, enabling robust image reconstruction across dive&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/vtjvta41d0/cover.png"/></item><item><title>Stabilize the Latent Space for Image Autoregressive Modeling: A Unified Perspective</title><link>https://deep-diver.github.io/neurips2024/posters/waq5x4qc3w/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/waq5x4qc3w/</guid><description>DiGIT stabilizes image autoregressive models&amp;rsquo; latent space using a novel discrete tokenizer from self-supervised learning, achieving state-of-the-art image generation.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/waq5x4qc3w/cover.png"/></item><item><title>Stable-Pose: Leveraging Transformers for Pose-Guided Text-to-Image Generation</title><link>https://deep-diver.github.io/neurips2024/posters/iwntinpxft/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/iwntinpxft/</guid><description>Stable-Pose: Precise human pose guidance for text-to-image synthesis.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/iwntinpxft/cover.png"/></item><item><title>StoryDiffusion: Consistent Self-Attention for Long-Range Image and Video Generation</title><link>https://deep-diver.github.io/neurips2024/spotlight-others/vfqzxhinfu/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-others/vfqzxhinfu/</guid><description>StoryDiffusion enhances long-range image &amp;amp; video generation by introducing a simple yet effective self-attention mechanism and a semantic motion predictor, achieving high content consistency without t&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-others/vfqzxhinfu/cover.png"/></item><item><title>Stylus: Automatic Adapter Selection for Diffusion Models</title><link>https://deep-diver.github.io/neurips2024/oral-image-generation/3odq2tgspp/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/oral-image-generation/3odq2tgspp/</guid><description>Stylus: an automatic adapter selection system for diffusion models, boosts image quality and diversity by intelligently composing task-specific adapters based on prompt keywords.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/oral-image-generation/3odq2tgspp/cover.png"/></item><item><title>Suppress Content Shift: Better Diffusion Features via Off-the-Shelf Generation Techniques</title><link>https://deep-diver.github.io/neurips2024/posters/qvqldeslwa/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/qvqldeslwa/</guid><description>Boosting diffusion model features: This paper introduces GATE, a novel method to suppress &amp;lsquo;content shift&amp;rsquo; in diffusion features, improving their quality via off-the-shelf generation techniques.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/qvqldeslwa/cover.png"/></item><item><title>Taming Diffusion Prior for Image Super-Resolution with Domain Shift SDEs</title><link>https://deep-diver.github.io/neurips2024/posters/u7oktt4zye/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/u7oktt4zye/</guid><description>DoSSR: A novel SR model boosts efficiency by 5-7x, achieving state-of-the-art performance with only 5 sampling steps by cleverly integrating a domain shift equation into pretrained diffusion models.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/u7oktt4zye/cover.png"/></item><item><title>TextCtrl: Diffusion-based Scene Text Editing with Prior Guidance Control</title><link>https://deep-diver.github.io/neurips2024/spotlight-others/sqvns9hwjt/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-others/sqvns9hwjt/</guid><description>TextCtrl: a novel diffusion-based scene text editing method using prior guidance control, achieving superior style fidelity and accuracy with a new real-world benchmark dataset, ScenePair.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-others/sqvns9hwjt/cover.png"/></item><item><title>The GAN is dead; long live the GAN! A Modern GAN Baseline</title><link>https://deep-diver.github.io/neurips2024/posters/ortn9hpp7v/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/ortn9hpp7v/</guid><description>R3GAN, a minimalist GAN baseline, surpasses state-of-the-art models by using a novel regularized relativistic GAN loss and modern architectures, proving GANs can be trained efficiently without relying&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/ortn9hpp7v/cover.png"/></item><item><title>Time-Varying LoRA: Towards Effective Cross-Domain Fine-Tuning of Diffusion Models</title><link>https://deep-diver.github.io/neurips2024/posters/sgodu2mx9t/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/sgodu2mx9t/</guid><description>Terra, a novel time-varying low-rank adapter, enables effective cross-domain fine-tuning of diffusion models by creating a continuous parameter manifold, facilitating efficient knowledge sharing and g&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/sgodu2mx9t/cover.png"/></item><item><title>TinyLUT: Tiny Look-Up Table for Efficient Image Restoration at the Edge</title><link>https://deep-diver.github.io/neurips2024/posters/tn0xnyplt6/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/tn0xnyplt6/</guid><description>TinyLUT achieves 10x lower memory consumption and superior accuracy in image restoration on edge devices using innovative separable mapping and dynamic discretization of LUTs.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/tn0xnyplt6/cover.png"/></item><item><title>TPC: Test-time Procrustes Calibration for Diffusion-based Human Image Animation</title><link>https://deep-diver.github.io/neurips2024/posters/h6nse8awct/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/h6nse8awct/</guid><description>Boosting diffusion-based human image animation, Test-time Procrustes Calibration (TPC) ensures high-quality outputs by aligning reference and target images, overcoming common compositional misalignmen&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/h6nse8awct/cover.png"/></item><item><title>Training-Free Adaptive Diffusion with Bounded Difference Approximation Strategy</title><link>https://deep-diver.github.io/neurips2024/posters/cs63ytj49a/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/cs63ytj49a/</guid><description>AdaptiveDiffusion accelerates diffusion model inference by adaptively skipping noise prediction steps, achieving 2-5x speedup without quality loss.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/cs63ytj49a/cover.png"/></item><item><title>U-DiTs: Downsample Tokens in U-Shaped Diffusion Transformers</title><link>https://deep-diver.github.io/neurips2024/posters/srws2wxns7/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/srws2wxns7/</guid><description>U-DiT: Revolutionizing diffusion transformers with a U-Net design and token downsampling for superior image generation and drastically reduced computation cost.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/srws2wxns7/cover.png"/></item><item><title>UltraPixel: Advancing Ultra High-Resolution Image Synthesis to New Peaks</title><link>https://deep-diver.github.io/neurips2024/posters/vojcpdlw53/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/vojcpdlw53/</guid><description>UltraPixel generates high-quality images at various resolutions (1K-6K) efficiently using cascade diffusion models, achieving state-of-the-art performance.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/vojcpdlw53/cover.png"/></item><item><title>Understanding Hallucinations in Diffusion Models through Mode Interpolation</title><link>https://deep-diver.github.io/neurips2024/posters/antnhbkw4t/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/antnhbkw4t/</guid><description>Diffusion models generate unrealistic images by smoothly interpolating between data modes; this paper identifies this &amp;lsquo;mode interpolation&amp;rsquo; failure and proposes a metric to detect and reduce it.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/antnhbkw4t/cover.png"/></item><item><title>Unified Gradient-Based Machine Unlearning with Remain Geometry Enhancement</title><link>https://deep-diver.github.io/neurips2024/spotlight-others/dhedf5epbt/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-others/dhedf5epbt/</guid><description>Enhance deep neural network privacy and trustworthiness with unified gradient-based machine unlearning, leveraging remain geometry for efficient forgetting and performance preservation.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-others/dhedf5epbt/cover.png"/></item><item><title>UniFL: Improve Latent Diffusion Model via Unified Feedback Learning</title><link>https://deep-diver.github.io/neurips2024/posters/sy2smstdob/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/sy2smstdob/</guid><description>UniFL: Unified Feedback Learning revolutionizes latent diffusion models by improving image quality, aesthetics, and inference speed through a unified feedback learning framework, surpassing existing m&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/sy2smstdob/cover.png"/></item><item><title>Unsupervised Homography Estimation on Multimodal Image Pair via Alternating Optimization</title><link>https://deep-diver.github.io/neurips2024/posters/zkhyrxlwqh/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/zkhyrxlwqh/</guid><description>AltO: a novel unsupervised learning framework for accurately estimating homography from multimodal image pairs, achieving performance comparable to supervised methods.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/zkhyrxlwqh/cover.png"/></item><item><title>UPS: Unified Projection Sharing for Lightweight Single-Image Super-resolution and Beyond</title><link>https://deep-diver.github.io/neurips2024/posters/tacb2bfzcm/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/tacb2bfzcm/</guid><description>UPS: A novel algorithm for lightweight single-image super-resolution, decoupling feature extraction and similarity modeling for enhanced efficiency and robustness.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/tacb2bfzcm/cover.png"/></item><item><title>Virtual Scanning: Unsupervised Non-line-of-sight Imaging from Irregularly Undersampled Transients</title><link>https://deep-diver.github.io/neurips2024/posters/r4ibzrsf5d/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/r4ibzrsf5d/</guid><description>Unsupervised learning framework enables high-fidelity non-line-of-sight (NLOS) imaging from irregularly undersampled transients, surpassing state-of-the-art methods in speed and robustness.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/r4ibzrsf5d/cover.png"/></item><item><title>Visual Autoregressive Modeling: Scalable Image Generation via Next-Scale Prediction</title><link>https://deep-diver.github.io/neurips2024/oral-image-generation/gojl67cfs8/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/oral-image-generation/gojl67cfs8/</guid><description>Visual Autoregressive Modeling (VAR) revolutionizes image generation by using a coarse-to-fine &amp;rsquo;next-scale prediction&amp;rsquo;, outperforming diffusion models and exhibiting scaling laws similar to LLMs.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/oral-image-generation/gojl67cfs8/cover.png"/></item><item><title>Visual Decoding and Reconstruction via EEG Embeddings with Guided Diffusion</title><link>https://deep-diver.github.io/neurips2024/posters/rxkcroc8qp/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/rxkcroc8qp/</guid><description>Researchers developed a novel zero-shot EEG-based framework for visual reconstruction using a tailored brain encoder and a two-stage image generation strategy, achieving state-of-the-art performance i&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/rxkcroc8qp/cover.png"/></item><item><title>Vivid-ZOO: Multi-View Video Generation with Diffusion Model</title><link>https://deep-diver.github.io/neurips2024/posters/bpoahf8ocx/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/bpoahf8ocx/</guid><description>Vivid-ZOO: Generating high-quality multi-view videos from text using a novel diffusion model.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/bpoahf8ocx/cover.png"/></item><item><title>Warped Diffusion: Solving Video Inverse Problems with Image Diffusion Models</title><link>https://deep-diver.github.io/neurips2024/posters/lh94zpv8cu/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/lh94zpv8cu/</guid><description>Warped Diffusion cleverly adapts image diffusion models for video inverse problems, solving flickering and temporal inconsistency issues by viewing video frames as continuous warping transformations a&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/lh94zpv8cu/cover.png"/></item><item><title>Zero-shot Image Editing with Reference Imitation</title><link>https://deep-diver.github.io/neurips2024/posters/lzv0u6uhb6/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/lzv0u6uhb6/</guid><description>MimicBrush: a novel image editing approach using reference imitation for intuitive zero-shot edits.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/lzv0u6uhb6/cover.png"/></item></channel></rss>