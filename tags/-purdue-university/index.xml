<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>üè¢ Purdue University on NeurIPS 2024</title><link>https://deep-diver.github.io/neurips2024/tags/-purdue-university/</link><description>Recent content in üè¢ Purdue University on NeurIPS 2024</description><generator>Hugo -- gohugo.io</generator><language>en</language><copyright>¬© 2024 AI Paper Reviewer</copyright><lastBuildDate>Thu, 26 Sep 2024 00:00:00 +0000</lastBuildDate><atom:link href="https://deep-diver.github.io/neurips2024/tags/-purdue-university/index.xml" rel="self" type="application/rss+xml"/><item><title>A Unified Debiasing Approach for Vision-Language Models across Modalities and Tasks</title><link>https://deep-diver.github.io/neurips2024/spotlight-others/181llen2gw/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-others/181llen2gw/</guid><description>SFID, a novel debiasing method, effectively mitigates bias in vision-language models across various tasks without retraining, improving fairness and efficiency.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-others/181llen2gw/cover.png"/></item><item><title>Conditional Generative Models are Sufficient to Sample from Any Causal Effect Estimand</title><link>https://deep-diver.github.io/neurips2024/posters/vymkubmllh/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/vymkubmllh/</guid><description>ID-GEN: Sample high-dimensional interventional distributions using any conditional generative model!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/vymkubmllh/cover.png"/></item><item><title>Curvature Clues: Decoding Deep Learning Privacy with Input Loss Curvature</title><link>https://deep-diver.github.io/neurips2024/spotlight-others/zevdmq6mu5/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-others/zevdmq6mu5/</guid><description>Deep learning privacy is enhanced by a new membership inference attack using input loss curvature, exceeding existing methods, especially on large datasets.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-others/zevdmq6mu5/cover.png"/></item><item><title>DiGRAF: Diffeomorphic Graph-Adaptive Activation Function</title><link>https://deep-diver.github.io/neurips2024/posters/zzow4z3le4/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/zzow4z3le4/</guid><description>DIGRAF, a novel graph-adaptive activation function, significantly boosts Graph Neural Network performance by dynamically adapting to graph structure, offering consistent superior results across divers&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/zzow4z3le4/cover.png"/></item><item><title>ECLipsE: Efficient Compositional Lipschitz Constant Estimation for Deep Neural Networks</title><link>https://deep-diver.github.io/neurips2024/spotlight-ai-theory/61yysy078z/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-ai-theory/61yysy078z/</guid><description>ECLipsE: A novel compositional approach drastically accelerates Lipschitz constant estimation for deep neural networks, achieving speedups of thousands of times compared to the state-of-the-art while &amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-ai-theory/61yysy078z/cover.png"/></item><item><title>Efficient Policy Evaluation Across Multiple Different Experimental Datasets</title><link>https://deep-diver.github.io/neurips2024/posters/psubtzaitm/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/psubtzaitm/</guid><description>This paper presents novel graphical criteria and estimators for accurately evaluating policy effectiveness across multiple experimental datasets, even when data distributions differ.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/psubtzaitm/cover.png"/></item><item><title>FIARSE: Model-Heterogeneous Federated Learning via Importance-Aware Submodel Extraction</title><link>https://deep-diver.github.io/neurips2024/posters/bmbteqrhdi/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/bmbteqrhdi/</guid><description>FIARSE dynamically optimizes submodels in federated learning based on parameter importance, improving efficiency and global model accuracy.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/bmbteqrhdi/cover.png"/></item><item><title>Hierarchical Federated Learning with Multi-Timescale Gradient Correction</title><link>https://deep-diver.github.io/neurips2024/posters/acab1qnxi0/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/acab1qnxi0/</guid><description>MTGC tackles multi-timescale model drift in hierarchical federated learning.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/acab1qnxi0/cover.png"/></item><item><title>Improved Sample Complexity for Multiclass PAC Learning</title><link>https://deep-diver.github.io/neurips2024/posters/l2yvtrz3on/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/l2yvtrz3on/</guid><description>This paper significantly improves our understanding of multiclass PAC learning by reducing the sample complexity gap and proposing two novel approaches to fully resolve the optimal sample complexity.</description></item><item><title>LLMDFA: Analyzing Dataflow in Code with Large Language Models</title><link>https://deep-diver.github.io/neurips2024/posters/qz2d8e8whu/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/qz2d8e8whu/</guid><description>LLMDFA: A novel LLM-powered framework performs compilation-free and customizable dataflow analysis, achieving high accuracy in bug detection by decomposing the task into sub-problems and mitigating L&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/qz2d8e8whu/cover.png"/></item><item><title>Multiclass Transductive Online Learning</title><link>https://deep-diver.github.io/neurips2024/spotlight-ai-theory/3erevfwalz/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-ai-theory/3erevfwalz/</guid><description>Unbounded label spaces conquered! New algorithm achieves optimal mistake bounds in multiclass transductive online learning.</description></item><item><title>OPEL: Optimal Transport Guided ProcedurE Learning</title><link>https://deep-diver.github.io/neurips2024/posters/leqd3bj4ly/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/leqd3bj4ly/</guid><description>OPEL: a novel optimal transport framework for procedure learning, significantly outperforms SOTA methods by aligning similar video frames and relaxing strict temporal assumptions.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/leqd3bj4ly/cover.png"/></item><item><title>Partial Structure Discovery is Sufficient for No-regret Learning in Causal Bandits</title><link>https://deep-diver.github.io/neurips2024/posters/um3rq14iex/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/um3rq14iex/</guid><description>Learning optimal interventions in causal bandits with unknown causal graphs is now efficient; this paper identifies the minimal causal knowledge needed and offers a two-stage algorithm with sublinear &amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/um3rq14iex/cover.png"/></item><item><title>Sample Efficient Bayesian Learning of Causal Graphs from Interventions</title><link>https://deep-diver.github.io/neurips2024/posters/rfsvaom7ss/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/rfsvaom7ss/</guid><description>Efficiently learn causal graphs from limited interventions using a novel Bayesian algorithm that outperforms existing methods and requires fewer experiments.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/rfsvaom7ss/cover.png"/></item><item><title>Source Code Foundation Models are Transferable Binary Analysis Knowledge Bases</title><link>https://deep-diver.github.io/neurips2024/posters/qppvdzphsl/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/qppvdzphsl/</guid><description>ProRec, a novel framework, bridges the binary-source semantic gap by using a binary-source encoder-decoder model and LLMs, achieving significant improvements in zero-shot binary summarization and func&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/qppvdzphsl/cover.png"/></item><item><title>Unified Covariate Adjustment for Causal Inference</title><link>https://deep-diver.github.io/neurips2024/posters/ax9z2et6ul/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/ax9z2et6ul/</guid><description>Unified Covariate Adjustment (UCA) offers a scalable, doubly robust estimator for a wide array of causal estimands beyond standard methods.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/ax9z2et6ul/cover.png"/></item><item><title>Universal Rates for Active Learning</title><link>https://deep-diver.github.io/neurips2024/posters/t0e4nw09xx/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/t0e4nw09xx/</guid><description>Active learning&amp;rsquo;s optimal rates are completely characterized, resolving an open problem and providing new algorithms achieving exponential and sublinear rates depending on combinatorial complexity mea&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/t0e4nw09xx/cover.png"/></item></channel></rss>