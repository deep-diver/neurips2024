<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>üè¢ University of Toronto on NeurIPS 2024</title><link>https://deep-diver.github.io/neurips2024/tags/-university-of-toronto/</link><description>Recent content in üè¢ University of Toronto on NeurIPS 2024</description><generator>Hugo -- gohugo.io</generator><language>en</language><copyright>¬© 2024 AI Paper Reviewer</copyright><lastBuildDate>Thu, 26 Sep 2024 00:00:00 +0000</lastBuildDate><atom:link href="https://deep-diver.github.io/neurips2024/tags/-university-of-toronto/index.xml" rel="self" type="application/rss+xml"/><item><title>Cell ontology guided transcriptome foundation model</title><link>https://deep-diver.github.io/neurips2024/spotlight-others/aeynvtto7o/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-others/aeynvtto7o/</guid><description>scCello: A Cell Ontology-Guided Transcriptome Foundation Model improves single-cell RNA sequencing analysis by incorporating cell lineage information, significantly boosting accuracy and generalizabil&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-others/aeynvtto7o/cover.png"/></item><item><title>Improved off-policy training of diffusion samplers</title><link>https://deep-diver.github.io/neurips2024/posters/vieiamy2gi/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/vieiamy2gi/</guid><description>Researchers enhanced diffusion samplers by developing a novel exploration strategy and a unified library, improving sample quality and addressing reproducibility challenges.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/vieiamy2gi/cover.png"/></item><item><title>Minimum Entropy Coupling with Bottleneck</title><link>https://deep-diver.github.io/neurips2024/spotlight-ai-theory/ylmym7shde/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-ai-theory/ylmym7shde/</guid><description>A novel lossy compression framework, Minimum Entropy Coupling with Bottleneck (MEC-B), extends existing methods by integrating a bottleneck for controlled stochasticity, enhancing performance in scen&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-ai-theory/ylmym7shde/cover.png"/></item><item><title>Observational Scaling Laws and the Predictability of Langauge Model Performance</title><link>https://deep-diver.github.io/neurips2024/spotlight-large-language-models/on5win7xyd/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-large-language-models/on5win7xyd/</guid><description>Researchers predict language model performance by observing existing models, bypassing costly training, revealing surprising predictability in complex scaling phenomena.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-large-language-models/on5win7xyd/cover.png"/></item><item><title>Paths to Equilibrium in Games</title><link>https://deep-diver.github.io/neurips2024/spotlight-ai-theory/lxxiiinmuf/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-ai-theory/lxxiiinmuf/</guid><description>In n-player games, a satisficing path always exists leading from any initial strategy profile to a Nash equilibrium by allowing unsatisfied players to explore suboptimal strategies.</description></item><item><title>Policy Aggregation</title><link>https://deep-diver.github.io/neurips2024/posters/ybiuvixjth/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/ybiuvixjth/</guid><description>This paper introduces efficient algorithms that leverage social choice theory to aggregate multiple individual preferences, resulting in a desirable collective AI policy.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/ybiuvixjth/cover.png"/></item><item><title>Self-Consuming Generative Models with Curated Data Provably Optimize Human Preferences</title><link>https://deep-diver.github.io/neurips2024/spotlight-others/cyv0lkiaoh/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-others/cyv0lkiaoh/</guid><description>Curated synthetic data provably optimizes human preferences in iterative generative model training, maximizing expected reward while mitigating variance.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-others/cyv0lkiaoh/cover.png"/></item><item><title>Sequential Decision Making with Expert Demonstrations under Unobserved Heterogeneity</title><link>https://deep-diver.github.io/neurips2024/posters/c8cpmlpubi/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/c8cpmlpubi/</guid><description>ExPerior leverages expert demonstrations to enhance online decision-making, even when experts use hidden contextual information unseen by the learner.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/c8cpmlpubi/cover.png"/></item><item><title>Sequential Probability Assignment with Contexts: Minimax Regret, Contextual Shtarkov Sums, and Contextual Normalized Maximum Likelihood</title><link>https://deep-diver.github.io/neurips2024/posters/urntypkf3v/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/urntypkf3v/</guid><description>This paper introduces contextual Shtarkov sums, a new complexity measure characterizing minimax regret in sequential probability assignment with contexts, and derives the minimax optimal algorithm, co&amp;hellip;</description></item></channel></rss>