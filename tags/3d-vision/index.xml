<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>3D Vision on NeurIPS 2024</title><link>https://deep-diver.github.io/neurips2024/tags/3d-vision/</link><description>Recent content in 3D Vision on NeurIPS 2024</description><generator>Hugo -- gohugo.io</generator><language>en</language><copyright>© 2025 AI Paper Reviewer</copyright><lastBuildDate>Thu, 26 Sep 2024 00:00:00 +0000</lastBuildDate><atom:link href="https://deep-diver.github.io/neurips2024/tags/3d-vision/index.xml" rel="self" type="application/rss+xml"/><item><title>$ ext{Di}^2 ext{Pose}$: Discrete Diffusion Model for Occluded 3D Human Pose Estimation</title><link>https://deep-diver.github.io/neurips2024/posters/p2po2pupfy/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/p2po2pupfy/</guid><description>Di²Pose, a novel discrete diffusion model, tackles occluded 3D human pose estimation by employing a two-stage process: pose quantization and discrete diffusion, achieving state-of-the-art results.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/p2po2pupfy/cover.png"/></item><item><title>$SE(3)$ Equivariant Ray Embeddings for Implicit Multi-View Depth Estimation</title><link>https://deep-diver.github.io/neurips2024/posters/yrujqowocs/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/yrujqowocs/</guid><description>SE(3)-equivariant ray embeddings in Perceiver IO achieve state-of-the-art implicit multi-view depth estimation, surpassing methods that rely on data augmentation for approximate equivariance.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/yrujqowocs/cover.png"/></item><item><title>3D Equivariant Pose Regression via Direct Wigner-D Harmonics Prediction</title><link>https://deep-diver.github.io/neurips2024/posters/nw8cxonvep/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/nw8cxonvep/</guid><description>3D pose estimation is revolutionized by a novel SO(3)-equivariant network directly predicting Wigner-D harmonics, achieving state-of-the-art accuracy and efficiency.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/nw8cxonvep/cover.png"/></item><item><title>3D Focusing-and-Matching Network for Multi-Instance Point Cloud Registration</title><link>https://deep-diver.github.io/neurips2024/posters/0sjbw05a2w/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/0sjbw05a2w/</guid><description>3DFMNet: A novel two-stage network for multi-instance point cloud registration, achieving state-of-the-art accuracy by focusing on object centers first and then performing pairwise registration.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/0sjbw05a2w/cover.png"/></item><item><title>3D Gaussian Rendering Can Be Sparser: Efficient Rendering via Learned Fragment Pruning</title><link>https://deep-diver.github.io/neurips2024/posters/ivqzbulfol/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/ivqzbulfol/</guid><description>Learned fragment pruning accelerates 3D Gaussian splatting rendering by selectively removing fragments, achieving up to 1.71x speedup on edge GPUs and 0.16 PSNR improvement.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/ivqzbulfol/cover.png"/></item><item><title>3D Gaussian Splatting as Markov Chain Monte Carlo</title><link>https://deep-diver.github.io/neurips2024/spotlight-others/ucst4gk6ix/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-others/ucst4gk6ix/</guid><description>Researchers rethink 3D Gaussian Splatting as MCMC sampling, improving rendering quality and Gaussian control via a novel relocation strategy.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-others/ucst4gk6ix/cover.png"/></item><item><title>3DET-Mamba: Causal Sequence Modelling for End-to-End 3D Object Detection</title><link>https://deep-diver.github.io/neurips2024/posters/ioleslc80f/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/ioleslc80f/</guid><description>3DET-Mamba: A novel end-to-end 3D object detector leveraging the Mamba state space model for efficient and accurate object detection in complex indoor scenes, outperforming previous 3DETR models.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/ioleslc80f/cover.png"/></item><item><title>3DGS-Enhancer: Enhancing Unbounded 3D Gaussian Splatting with View-consistent 2D Diffusion Priors</title><link>https://deep-diver.github.io/neurips2024/spotlight-others/p4s6fupcbg/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-others/p4s6fupcbg/</guid><description>3DGS-Enhancer boosts unbounded 3D Gaussian splatting, generating high-fidelity novel views even with sparse input data using view-consistent 2D diffusion priors.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-others/p4s6fupcbg/cover.png"/></item><item><title>4D Gaussian Splatting in the Wild with Uncertainty-Aware Regularization</title><link>https://deep-diver.github.io/neurips2024/posters/0syctgl4in/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/0syctgl4in/</guid><description>Uncertainty-aware 4D Gaussian Splatting enhances dynamic scene reconstruction from monocular videos by selectively applying regularization to uncertain regions, improving both novel view synthesis and&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/0syctgl4in/cover.png"/></item><item><title>4Diffusion: Multi-view Video Diffusion Model for 4D Generation</title><link>https://deep-diver.github.io/neurips2024/posters/sfk7ampyhx/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/sfk7ampyhx/</guid><description>4Diffusion generates high-quality, temporally consistent 4D content from monocular videos using a unified multi-view diffusion model and novel loss functions.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/sfk7ampyhx/cover.png"/></item><item><title>A Consistency-Aware Spot-Guided Transformer for Versatile and Hierarchical Point Cloud Registration</title><link>https://deep-diver.github.io/neurips2024/posters/btllwaorfs/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/btllwaorfs/</guid><description>CAST: a novel consistency-aware spot-guided Transformer achieves state-of-the-art accuracy and efficiency in point cloud registration.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/btllwaorfs/cover.png"/></item><item><title>A General Protocol to Probe Large Vision Models for 3D Physical Understanding</title><link>https://deep-diver.github.io/neurips2024/posters/0hrrneaqfp/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/0hrrneaqfp/</guid><description>Researchers developed a lightweight protocol to probe large vision models&amp;rsquo; 3D physical understanding by training classifiers on model features for various scene properties (geometry, material, lightin&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/0hrrneaqfp/cover.png"/></item><item><title>A Global Depth-Range-Free Multi-View Stereo Transformer Network with Pose Embedding</title><link>https://deep-diver.github.io/neurips2024/posters/1fikbpewu9/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/1fikbpewu9/</guid><description>Depth-range-free MVS network using pose embedding achieves robust and accurate 3D reconstruction.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/1fikbpewu9/cover.png"/></item><item><title>A robust inlier identification algorithm for point cloud registration via l_0-minimization</title><link>https://deep-diver.github.io/neurips2024/posters/bjrbalodrj/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/bjrbalodrj/</guid><description>This paper introduces a novel, robust inlier identification algorithm for point cloud registration that leverages lo-minimization.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/bjrbalodrj/cover.png"/></item><item><title>A Simple yet Universal Framework for Depth Completion</title><link>https://deep-diver.github.io/neurips2024/posters/y4thp5jilp/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/y4thp5jilp/</guid><description>UniDC framework achieves universal depth completion across various sensors and scenes using minimal labeled data, leveraging a foundation model and hyperbolic embedding for enhanced generalization.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/y4thp5jilp/cover.png"/></item><item><title>A Unified Framework for 3D Scene Understanding</title><link>https://deep-diver.github.io/neurips2024/posters/de1btyyc9a/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/de1btyyc9a/</guid><description>UniSeg3D: One model to rule them all! This unified framework masters six 3D segmentation tasks (panoptic, semantic, instance, interactive, referring, and open-vocabulary) simultaneously, outperforming&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/de1btyyc9a/cover.png"/></item><item><title>Activating Self-Attention for Multi-Scene Absolute Pose Regression</title><link>https://deep-diver.github.io/neurips2024/posters/rm24uugzg8/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/rm24uugzg8/</guid><description>Boosting Multi-Scene Pose Regression: Novel methods activate transformer self-attention, significantly improving camera pose estimation accuracy and efficiency.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/rm24uugzg8/cover.png"/></item><item><title>AlphaTablets: A Generic Plane Representation for 3D Planar Reconstruction from Monocular Videos</title><link>https://deep-diver.github.io/neurips2024/posters/7rrjq9iwox/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/7rrjq9iwox/</guid><description>AlphaTablets revolutionizes 3D planar reconstruction from monocular videos with its novel rectangle-based representation featuring continuous surfaces and precise boundaries, achieving state-of-the-ar&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/7rrjq9iwox/cover.png"/></item><item><title>Animate3D: Animating Any 3D Model with Multi-view Video Diffusion</title><link>https://deep-diver.github.io/neurips2024/posters/hb6kacfimn/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/hb6kacfimn/</guid><description>Animate3D animates any 3D model using multi-view video diffusion, achieving superior spatiotemporal consistency and straightforward mesh animation.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/hb6kacfimn/cover.png"/></item><item><title>Articulate your NeRF: Unsupervised articulated object modeling via conditional view synthesis</title><link>https://deep-diver.github.io/neurips2024/posters/9b6j64etp4/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/9b6j64etp4/</guid><description>Unsupervised Articulated Object Modeling using Conditional View Synthesis learns pose and part segmentation from only two object observations, achieving significantly better performance than previous &amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/9b6j64etp4/cover.png"/></item><item><title>Assembly Fuzzy Representation on Hypergraph for Open-Set 3D Object Retrieval</title><link>https://deep-diver.github.io/neurips2024/posters/xocaurlvm9/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/xocaurlvm9/</guid><description>Hypergraph-Based Assembly Fuzzy Representation (HAFR) excels at open-set 3D object retrieval by using part-level shapes and fuzzy representations to overcome challenges posed by unseen object categori&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/xocaurlvm9/cover.png"/></item><item><title>BetterDepth: Plug-and-Play Diffusion Refiner for Zero-Shot Monocular Depth Estimation</title><link>https://deep-diver.github.io/neurips2024/posters/35wwzhkush/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/35wwzhkush/</guid><description>BetterDepth: A plug-and-play diffusion refiner boosts zero-shot monocular depth estimation by adding fine details while preserving accurate geometry.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/35wwzhkush/cover.png"/></item><item><title>Binocular-Guided 3D Gaussian Splatting with View Consistency for Sparse View Synthesis</title><link>https://deep-diver.github.io/neurips2024/posters/otettmiymz/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/otettmiymz/</guid><description>Binocular-guided 3D Gaussian splatting with self-supervision generates high-quality novel views from sparse inputs without external priors, significantly outperforming state-of-the-art methods.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/otettmiymz/cover.png"/></item><item><title>CAT3D: Create Anything in 3D with Multi-View Diffusion Models</title><link>https://deep-diver.github.io/neurips2024/oral-others/tfzlfrl9ks/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/oral-others/tfzlfrl9ks/</guid><description>CAT3D: Generate high-quality 3D scenes from as little as one image using a novel multi-view diffusion model, outperforming existing methods in speed and quality.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/oral-others/tfzlfrl9ks/cover.png"/></item><item><title>CoFie: Learning Compact Neural Surface Representations with Coordinate Fields</title><link>https://deep-diver.github.io/neurips2024/posters/0ksesacluj/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/0ksesacluj/</guid><description>CoFie: A novel local geometry-aware neural surface representation dramatically improves accuracy and efficiency in 3D shape modeling by using coordinate fields to compress local shape information.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/0ksesacluj/cover.png"/></item><item><title>ContactField: Implicit Field Representation for Multi-Person Interaction Geometry</title><link>https://deep-diver.github.io/neurips2024/posters/7su2gfqvmn/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/7su2gfqvmn/</guid><description>Novel implicit field representation accurately reconstructs multi-person interaction geometry in 3D, simultaneously capturing occupancy, instance IDs, and contact fields, surpassing existing methods.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/7su2gfqvmn/cover.png"/></item><item><title>Context and Geometry Aware Voxel Transformer for Semantic Scene Completion</title><link>https://deep-diver.github.io/neurips2024/spotlight-others/9bu627mtfs/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-others/9bu627mtfs/</guid><description>CGFormer: a novel voxel transformer boosting semantic scene completion accuracy by using context-aware queries and 3D deformable attention, outperforming existing methods on SemanticKITTI and SSCBench&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-others/9bu627mtfs/cover.png"/></item><item><title>ContextGS : Compact 3D Gaussian Splatting with Anchor Level Context Model</title><link>https://deep-diver.github.io/neurips2024/posters/w2qgsml2uu/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/w2qgsml2uu/</guid><description>ContextGS: Revolutionizing 3D scene compression with an anchor-level autoregressive model, achieving 15x size reduction in 3D Gaussian Splatting while boosting rendering quality.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/w2qgsml2uu/cover.png"/></item><item><title>Continuous Heatmap Regression for Pose Estimation via Implicit Neural Representation</title><link>https://deep-diver.github.io/neurips2024/posters/ggijeosljq/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/ggijeosljq/</guid><description>NerPE: continuous heatmap regression via implicit neural representation resolves the accuracy-limiting quantization errors in human pose estimation, achieving sub-pixel precision.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/ggijeosljq/cover.png"/></item><item><title>CRAYM: Neural Field Optimization via Camera RAY Matching</title><link>https://deep-diver.github.io/neurips2024/posters/wk0z49myyi/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/wk0z49myyi/</guid><description>CRAYM: Neural field optimization via camera RAY matching enhances 3D reconstruction by using camera rays, not pixels, improving both novel view synthesis and geometry.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/wk0z49myyi/cover.png"/></item><item><title>CryoSPIN: Improving Ab-Initio Cryo-EM Reconstruction with Semi-Amortized Pose Inference</title><link>https://deep-diver.github.io/neurips2024/posters/1mcsewafzb/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/1mcsewafzb/</guid><description>CryoSPIN revolutionizes ab-initio cryo-EM reconstruction with semi-amortized pose inference, achieving faster and more accurate 3D structure determination.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/1mcsewafzb/cover.png"/></item><item><title>DC-Gaussian: Improving 3D Gaussian Splatting for Reflective Dash Cam Videos</title><link>https://deep-diver.github.io/neurips2024/posters/ja20bpfapa/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/ja20bpfapa/</guid><description>DC-Gaussian: A novel method generates high-fidelity novel views from dashcam videos by addressing common windshield obstructions (reflections, occlusions) using adaptive image decomposition, illumina&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/ja20bpfapa/cover.png"/></item><item><title>DCDepth: Progressive Monocular Depth Estimation in Discrete Cosine Domain</title><link>https://deep-diver.github.io/neurips2024/posters/463te4n8vj/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/463te4n8vj/</guid><description>DCDepth achieves state-of-the-art monocular depth estimation by progressively predicting depth in the frequency domain via DCT, capturing local correlations and global context effectively.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/463te4n8vj/cover.png"/></item><item><title>DeBaRA: Denoising-Based 3D Room Arrangement Generation</title><link>https://deep-diver.github.io/neurips2024/posters/rajrj6wkj2/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/rajrj6wkj2/</guid><description>DeBaRA: a novel denoising-based model generates realistic &amp;amp; controllable 3D room layouts, surpassing existing methods.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/rajrj6wkj2/cover.png"/></item><item><title>DEL: Discrete Element Learner for Learning 3D Particle Dynamics with Neural Rendering</title><link>https://deep-diver.github.io/neurips2024/posters/2nvkd0spok/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/2nvkd0spok/</guid><description>DEL: Learns 3D particle dynamics from 2D images via physics-informed neural rendering, exceeding existing methods&amp;rsquo; accuracy and robustness.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/2nvkd0spok/cover.png"/></item><item><title>Depth Anything V2</title><link>https://deep-diver.github.io/neurips2024/posters/cfti3glj1x/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/cfti3glj1x/</guid><description>Depth Anything V2 drastically improves monocular depth estimation by using synthetic training data, scaling up the teacher model, and employing pseudo-labeled real images. It outperforms previous met&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/cfti3glj1x/cover.png"/></item><item><title>Depth Anywhere: Enhancing 360 Monocular Depth Estimation via Perspective Distillation and Unlabeled Data Augmentation</title><link>https://deep-diver.github.io/neurips2024/posters/vzoybrqj4o/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/vzoybrqj4o/</guid><description>Depth Anywhere enhances 360-degree monocular depth estimation by cleverly using perspective models to label unlabeled 360-degree data, significantly improving accuracy.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/vzoybrqj4o/cover.png"/></item><item><title>DiffuBox: Refining 3D Object Detection with Point Diffusion</title><link>https://deep-diver.github.io/neurips2024/posters/j2wootkbx0/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/j2wootkbx0/</guid><description>DiffuBox refines 3D object detection using a novel diffusion-based approach, significantly improving accuracy across various domains by refining bounding boxes based on surrounding LiDAR point clouds.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/j2wootkbx0/cover.png"/></item><item><title>DiffusionBlend: Learning 3D Image Prior through Position-aware Diffusion Score Blending for 3D Computed Tomography Reconstruction</title><link>https://deep-diver.github.io/neurips2024/posters/h3kv6sdtwo/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/h3kv6sdtwo/</guid><description>DiffusionBlend++ learns a 3D image prior via position-aware diffusion score blending, achieving state-of-the-art 3D CT reconstruction with superior efficiency.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/h3kv6sdtwo/cover.png"/></item><item><title>Direct3D: Scalable Image-to-3D Generation via 3D Latent Diffusion Transformer</title><link>https://deep-diver.github.io/neurips2024/posters/vcogjbizul/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/vcogjbizul/</guid><description>Direct3D: Revolutionizing image-to-3D generation with a scalable, native 3D diffusion model achieving state-of-the-art quality.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/vcogjbizul/cover.png"/></item><item><title>Director3D: Real-world Camera Trajectory and 3D Scene Generation from Text</title><link>https://deep-diver.github.io/neurips2024/posters/08a6x7fsts/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/08a6x7fsts/</guid><description>Director3D generates realistic 3D scenes and camera trajectories from text descriptions using a three-stage pipeline: Cinematographer, Decorator, and Detailer.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/08a6x7fsts/cover.png"/></item><item><title>DisC-GS: Discontinuity-aware Gaussian Splatting</title><link>https://deep-diver.github.io/neurips2024/posters/scbmemtsh5/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/scbmemtsh5/</guid><description>DisC-GS enhances Gaussian Splatting for real-time novel view synthesis by accurately rendering image discontinuities and boundaries, improving visual quality.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/scbmemtsh5/cover.png"/></item><item><title>DistillNeRF: Perceiving 3D Scenes from Single-Glance Images by Distilling Neural Fields and Foundation Model Features</title><link>https://deep-diver.github.io/neurips2024/posters/7fscrgj3an/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/7fscrgj3an/</guid><description>DistillNeRF: a self-supervised learning framework enabling accurate 3D scene reconstruction from sparse, single-frame images by cleverly distilling features from offline NeRFs and 2D foundation models&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/7fscrgj3an/cover.png"/></item><item><title>Distribution Guidance Network for Weakly Supervised Point Cloud Semantic Segmentation</title><link>https://deep-diver.github.io/neurips2024/posters/jj2peazpwk/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/jj2peazpwk/</guid><description>DGNet enhances weakly supervised point cloud segmentation by aligning feature embeddings to a mixture of von Mises-Fisher distributions, achieving state-of-the-art performance.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/jj2peazpwk/cover.png"/></item><item><title>DMesh: A Differentiable Mesh Representation</title><link>https://deep-diver.github.io/neurips2024/posters/io1qkqcvik/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/io1qkqcvik/</guid><description>DMesh: A novel differentiable mesh representation enabling efficient gradient-based optimization for diverse 3D shape applications.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/io1qkqcvik/cover.png"/></item><item><title>DN-4DGS: Denoised Deformable Network with Temporal-Spatial Aggregation for Dynamic Scene Rendering</title><link>https://deep-diver.github.io/neurips2024/posters/qqsynx5s83/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/qqsynx5s83/</guid><description>DN-4DGS: Real-time dynamic scene rendering is revolutionized by a denoised deformable network with temporal-spatial aggregation, achieving state-of-the-art quality.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/qqsynx5s83/cover.png"/></item><item><title>DOGS: Distributed-Oriented Gaussian Splatting for Large-Scale 3D Reconstruction Via Gaussian Consensus</title><link>https://deep-diver.github.io/neurips2024/posters/haocq9dsax/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/haocq9dsax/</guid><description>DOGS: Distributed-Oriented Gaussian Splatting accelerates large-scale 3D reconstruction by distributing the training of 3D Gaussian Splatting models across multiple machines, achieving 6x faster train&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/haocq9dsax/cover.png"/></item><item><title>DreamMesh4D: Video-to-4D Generation with Sparse-Controlled Gaussian-Mesh Hybrid Representation</title><link>https://deep-diver.github.io/neurips2024/posters/6zwjsk2kvu/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/6zwjsk2kvu/</guid><description>DreamMesh4D: Generating high-fidelity dynamic 3D meshes from monocular video using a novel Gaussian-mesh hybrid representation and adaptive hybrid skinning.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/6zwjsk2kvu/cover.png"/></item><item><title>Dual Encoder GAN Inversion for High-Fidelity 3D Head Reconstruction from Single Images</title><link>https://deep-diver.github.io/neurips2024/posters/sldx451mjc/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/sldx451mjc/</guid><description>Dual encoder GAN inversion achieves high-fidelity 3D head reconstruction from single images by cleverly combining outputs from encoders specialized for visible and invisible regions, surpassing existi&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/sldx451mjc/cover.png"/></item><item><title>Dual-Diffusion for Binocular 3D Human Pose Estimation</title><link>https://deep-diver.github.io/neurips2024/posters/nt8z5njwxf/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/nt8z5njwxf/</guid><description>Dual-Diffusion boosts binocular 3D human pose estimation accuracy by simultaneously denoising 2D and 3D pose uncertainties using a diffusion model.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/nt8z5njwxf/cover.png"/></item><item><title>Dual-frame Fluid Motion Estimation with Test-time Optimization and Zero-divergence Loss</title><link>https://deep-diver.github.io/neurips2024/posters/wobhjs9gqu/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/wobhjs9gqu/</guid><description>Self-supervised dual-frame fluid motion estimation achieves superior accuracy with 99% less training data, using a novel zero-divergence loss and dynamic velocimetry enhancement.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/wobhjs9gqu/cover.png"/></item><item><title>Dynamic 3D Gaussian Fields for Urban Areas</title><link>https://deep-diver.github.io/neurips2024/spotlight-others/xzxxnhndxu/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-others/xzxxnhndxu/</guid><description>4DGF, a novel neural scene representation, achieves interactive-speed novel view synthesis for large-scale dynamic urban areas by efficiently combining 3D Gaussians and neural fields.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-others/xzxxnhndxu/cover.png"/></item><item><title>Effective Rank Analysis and Regularization for Enhanced 3D Gaussian Splatting</title><link>https://deep-diver.github.io/neurips2024/posters/ewwpapzcay/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/ewwpapzcay/</guid><description>Effective rank regularization enhances 3D Gaussian splatting, resolving needle-like artifacts and improving 3D model quality.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/ewwpapzcay/cover.png"/></item><item><title>EfficientCAPER: An End-to-End Framework for Fast and Robust Category-Level Articulated Object Pose Estimation</title><link>https://deep-diver.github.io/neurips2024/posters/lbxsp79ocd/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/lbxsp79ocd/</guid><description>EfficientCAPER: A novel end-to-end framework achieves fast &amp;amp; robust category-level articulated object pose estimation by using a joint-centric approach, eliminating post-processing optimization and en&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/lbxsp79ocd/cover.png"/></item><item><title>EgoChoir: Capturing 3D Human-Object Interaction Regions from Egocentric Views</title><link>https://deep-diver.github.io/neurips2024/posters/ea4oxkimp7/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/ea4oxkimp7/</guid><description>EgoChoir: a novel framework harmonizes visual appearance, head motion, and 3D objects to accurately estimate 3D human contact and object affordance from egocentric videos, surpassing existing methods.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/ea4oxkimp7/cover.png"/></item><item><title>Epipolar-Free 3D Gaussian Splatting for Generalizable Novel View Synthesis</title><link>https://deep-diver.github.io/neurips2024/posters/io6tcljewa/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/io6tcljewa/</guid><description>eFreeSplat: a novel, epipolar-free 3D Gaussian splatting model for generalizable novel view synthesis, surpassing state-of-the-art methods by achieving superior geometry reconstruction and novel view &amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/io6tcljewa/cover.png"/></item><item><title>Era3D: High-Resolution Multiview Diffusion using Efficient Row-wise Attention</title><link>https://deep-diver.github.io/neurips2024/posters/xdcjayyitp/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/xdcjayyitp/</guid><description>Era3D: High-resolution multiview diffusion using efficient row-wise attention, generates high-quality multiview images from single views, overcoming prior limitations.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/xdcjayyitp/cover.png"/></item><item><title>Estimating Ego-Body Pose from Doubly Sparse Egocentric Video Data</title><link>https://deep-diver.github.io/neurips2024/posters/mhcnlo2qea/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/mhcnlo2qea/</guid><description>DSPoser: A novel two-stage approach accurately estimates full-body pose from doubly sparse egocentric video data using masked autoencoders for temporal completion and conditional diffusion models for &amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/mhcnlo2qea/cover.png"/></item><item><title>Event-3DGS: Event-based 3D Reconstruction Using 3D Gaussian Splatting</title><link>https://deep-diver.github.io/neurips2024/posters/ejzfckxdit/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/ejzfckxdit/</guid><description>Event-3DGS: First event-based 3D reconstruction using 3D Gaussian splatting, enabling high-quality, efficient, and robust 3D scene reconstruction in challenging real-world conditions.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/ejzfckxdit/cover.png"/></item><item><title>Expressive Gaussian Human Avatars from Monocular RGB Video</title><link>https://deep-diver.github.io/neurips2024/posters/3cwelzfnyl/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/3cwelzfnyl/</guid><description>EVA: a novel method generates expressive 3D Gaussian human avatars from monocular RGB videos, excelling in detailed hand and facial expressions via context-aware density control and improved SMPL-X al&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/3cwelzfnyl/cover.png"/></item><item><title>Fast Encoder-Based 3D from Casual Videos via Point Track Processing</title><link>https://deep-diver.github.io/neurips2024/posters/bqgaheaeqy/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/bqgaheaeqy/</guid><description>TRACKSTO4D: Fast &amp;amp; accurate 3D reconstruction from casual videos using 2D point tracks, drastically reducing runtime by up to 95% while matching state-of-the-art accuracy.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/bqgaheaeqy/cover.png"/></item><item><title>FewViewGS: Gaussian Splatting with Few View Matching and Multi-stage Training</title><link>https://deep-diver.github.io/neurips2024/posters/lihe9iumii/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/lihe9iumii/</guid><description>FewViewGS: A novel method for high-quality novel view synthesis from sparse images using a multi-stage training scheme and a new locality-preserving regularization for 3D Gaussians.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/lihe9iumii/cover.png"/></item><item><title>FFAM: Feature Factorization Activation Map for Explanation of 3D Detectors</title><link>https://deep-diver.github.io/neurips2024/posters/rpzwsdjc4n/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/rpzwsdjc4n/</guid><description>FFAM uses feature factorization and gradient weighting to produce high-quality visual explanations for 3D object detectors, improving model interpretability and trust.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/rpzwsdjc4n/cover.png"/></item><item><title>Fine-grained Image-to-LiDAR Contrastive Distillation with Visual Foundation Models</title><link>https://deep-diver.github.io/neurips2024/posters/63xewav1lu/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/63xewav1lu/</guid><description>OLIVINE uses visual foundation models for fine-grained image-to-LiDAR contrastive distillation, mitigating self-conflict issues and improving 3D representation learning.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/63xewav1lu/cover.png"/></item><item><title>Flatten Anything: Unsupervised Neural Surface Parameterization</title><link>https://deep-diver.github.io/neurips2024/posters/eneqgc9agr/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/eneqgc9agr/</guid><description>Flatten Anything Model (FAM) revolutionizes neural surface parameterization with unsupervised learning, handling complex topologies and unstructured data fully automatically.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/eneqgc9agr/cover.png"/></item><item><title>FreeSplat: Generalizable 3D Gaussian Splatting Towards Free View Synthesis of Indoor Scenes</title><link>https://deep-diver.github.io/neurips2024/posters/ml01xyp698/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/ml01xyp698/</guid><description>FreeSplat achieves state-of-the-art novel view synthesis by accurately localizing 3D Gaussians from long image sequences, overcoming limitations of prior methods confined to narrow-range interpolation&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/ml01xyp698/cover.png"/></item><item><title>From an Image to a Scene: Learning to Imagine the World from a Million 360° Videos</title><link>https://deep-diver.github.io/neurips2024/posters/otxotswcmb/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/otxotswcmb/</guid><description>ODIN, trained on a million 360° videos (360-1M), generates realistic novel views and reconstructs 3D scenes from single images.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/otxotswcmb/cover.png"/></item><item><title>From Chaos to Clarity: 3DGS in the Dark</title><link>https://deep-diver.github.io/neurips2024/posters/lwhe7pmk7c/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/lwhe7pmk7c/</guid><description>Researchers developed a self-supervised learning framework to create high-dynamic-range 3D Gaussian Splatting (3DGS) models from noisy raw images, significantly improving reconstruction quality and sp&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/lwhe7pmk7c/cover.png"/></item><item><title>From Transparent to Opaque: Rethinking Neural Implicit Surfaces with $lpha$-NeuS</title><link>https://deep-diver.github.io/neurips2024/posters/pojt9rwijj/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/pojt9rwijj/</guid><description>α-NeuS: A novel method for neural implicit surface reconstruction that accurately reconstructs both transparent and opaque objects simultaneously by leveraging the unique properties of distance fields&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/pojt9rwijj/cover.png"/></item><item><title>Fully Explicit Dynamic Gaussian Splatting</title><link>https://deep-diver.github.io/neurips2024/posters/g8pytkxyiv/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/g8pytkxyiv/</guid><description>Ex4DGS achieves real-time high-quality dynamic scene rendering using explicit 4D Gaussian representations and keyframe interpolation.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/g8pytkxyiv/cover.png"/></item><item><title>Gaussian Graph Network: Learning Efficient and Generalizable Gaussian Representations from Multi-view Images</title><link>https://deep-diver.github.io/neurips2024/posters/2dfbpyqh0a/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/2dfbpyqh0a/</guid><description>Gaussian Graph Network (GGN) revolutionizes novel view synthesis by efficiently generating generalizable Gaussian representations from multi-view images, achieving superior rendering quality with fewe&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/2dfbpyqh0a/cover.png"/></item><item><title>GaussianCube: A Structured and Explicit Radiance Representation for 3D Generative Modeling</title><link>https://deep-diver.github.io/neurips2024/posters/dg2f1rvem5/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/dg2f1rvem5/</guid><description>GaussianCube revolutionizes 3D generative modeling with a structured, explicit radiance representation, achieving state-of-the-art results using significantly fewer parameters.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/dg2f1rvem5/cover.png"/></item><item><title>GaussianMarker: Uncertainty-Aware Copyright Protection of 3D Gaussian Splatting</title><link>https://deep-diver.github.io/neurips2024/posters/wcxhbay8b3/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/wcxhbay8b3/</guid><description>GaussianMarker: A novel uncertainty-aware watermarking method ensures robust copyright protection for 3D Gaussian Splatting assets, invisibly embedding messages into model parameters and extractable &amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/wcxhbay8b3/cover.png"/></item><item><title>GeoLRM: Geometry-Aware Large Reconstruction Model for High-Quality 3D Gaussian Generation</title><link>https://deep-diver.github.io/neurips2024/posters/em5d7zmeka/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/em5d7zmeka/</guid><description>GeoLRM: Generate stunning 3D models from just 21 images using a novel geometry-aware transformer, surpassing existing methods in efficiency and quality!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/em5d7zmeka/cover.png"/></item><item><title>Geometry Cloak: Preventing TGS-based 3D Reconstruction from Copyrighted Images</title><link>https://deep-diver.github.io/neurips2024/posters/utriehobxi/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/utriehobxi/</guid><description>Geometry Cloak embeds invisible perturbations in images to thwart AI-based 3D reconstruction, forcing the AI to generate identifiable patterns that act as watermarks to assert copyright.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/utriehobxi/cover.png"/></item><item><title>GeoNLF: Geometry guided Pose-Free Neural LiDAR Fields</title><link>https://deep-diver.github.io/neurips2024/posters/v3y785tn7b/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/v3y785tn7b/</guid><description>GeoNLF: Geometry-guided Pose-free Neural LiDAR Fields revolutionizes LiDAR point cloud processing by cleverly combining neural and geometric optimization for superior novel view synthesis and multi-vi&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/v3y785tn7b/cover.png"/></item><item><title>GIC: Gaussian-Informed Continuum for Physical Property Identification and Simulation</title><link>https://deep-diver.github.io/neurips2024/oral-others/ssctcq2mh2/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/oral-others/ssctcq2mh2/</guid><description>GIC: Novel hybrid framework leverages 3D Gaussian representation for accurate physical property estimation from visual observations, achieving state-of-the-art performance.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/oral-others/ssctcq2mh2/cover.png"/></item><item><title>GL-NeRF: Gauss-Laguerre Quadrature Enables Training-Free NeRF Acceleration</title><link>https://deep-diver.github.io/neurips2024/posters/gdnzajkrml/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/gdnzajkrml/</guid><description>GL-NeRF accelerates NeRF rendering by using Gauss-Laguerre quadrature, drastically reducing MLP calls without needing additional networks or data structures.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/gdnzajkrml/cover.png"/></item><item><title>Grid4D: 4D Decomposed Hash Encoding for High-fidelity Dynamic Gaussian Splatting</title><link>https://deep-diver.github.io/neurips2024/posters/eyfyc19god/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/eyfyc19god/</guid><description>Grid4D: A novel 4D decomposed hash encoding boosts high-fidelity dynamic Gaussian splatting, surpassing state-of-the-art models in visual quality and rendering speed.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/eyfyc19god/cover.png"/></item><item><title>GS-Hider: Hiding Messages into 3D Gaussian Splatting</title><link>https://deep-diver.github.io/neurips2024/posters/3xlqp2xx3j/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/3xlqp2xx3j/</guid><description>GS-Hider: A novel framework secures 3D Gaussian Splatting by embedding messages in a coupled, secured feature attribute, enabling invisible data hiding and accurate extraction.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/3xlqp2xx3j/cover.png"/></item><item><title>GSDF: 3DGS Meets SDF for Improved Neural Rendering and Reconstruction</title><link>https://deep-diver.github.io/neurips2024/posters/r6v7ejanuk/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/r6v7ejanuk/</guid><description>GSDF: A novel dual-branch neural scene representation elegantly resolves the rendering-reconstruction trade-off by synergistically combining 3D Gaussian Splatting and Signed Distance Fields via mutual&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/r6v7ejanuk/cover.png"/></item><item><title>GSGAN: Adversarial Learning for Hierarchical Generation of 3D Gaussian Splats</title><link>https://deep-diver.github.io/neurips2024/posters/sfafdcvnbw/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/sfafdcvnbw/</guid><description>GSGAN introduces a hierarchical 3D Gaussian representation for faster, high-quality 3D model generation in GANs, achieving 100x speed improvement over existing methods.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/sfafdcvnbw/cover.png"/></item><item><title>GVKF: Gaussian Voxel Kernel Functions for Highly Efficient Surface Reconstruction in Open Scenes</title><link>https://deep-diver.github.io/neurips2024/posters/dqd0dnrjxk/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/dqd0dnrjxk/</guid><description>GVKF: A novel method achieves highly efficient and accurate 3D surface reconstruction in open scenes by integrating fast 3D Gaussian splatting with continuous scene representation using kernel regres&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/dqd0dnrjxk/cover.png"/></item><item><title>Hallo3D: Multi-Modal Hallucination Detection and Mitigation for Consistent 3D Content Generation</title><link>https://deep-diver.github.io/neurips2024/posters/pqi4vqbyxw/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/pqi4vqbyxw/</guid><description>Hallo3D: a tuning-free method resolving 3D generation hallucinations via multi-modal inconsistency detection and mitigation for consistent 3D content.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/pqi4vqbyxw/cover.png"/></item><item><title>Hamba: Single-view 3D Hand Reconstruction with Graph-guided Bi-Scanning Mamba</title><link>https://deep-diver.github.io/neurips2024/posters/pcj0l1jvux/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/pcj0l1jvux/</guid><description>Hamba: a novel graph-guided framework for single-view 3D hand reconstruction, significantly outperforms existing methods by efficiently modeling spatial relationships between joints using a fraction o&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/pcj0l1jvux/cover.png"/></item><item><title>Harmonizing Stochasticity and Determinism: Scene-responsive Diverse Human Motion Prediction</title><link>https://deep-diver.github.io/neurips2024/posters/nqcknm6tes/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/nqcknm6tes/</guid><description>DiMoP3D: Predicting diverse, physically realistic human motions in 3D scenes by harmonizing stochasticity and determinism.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/nqcknm6tes/cover.png"/></item><item><title>HDR-GS: Efficient High Dynamic Range Novel View Synthesis at 1000x Speed via Gaussian Splatting</title><link>https://deep-diver.github.io/neurips2024/posters/hkmccfrykt/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/hkmccfrykt/</guid><description>HDR-GS: 1000x faster HDR novel view synthesis via Gaussian splatting!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/hkmccfrykt/cover.png"/></item><item><title>HiCoM: Hierarchical Coherent Motion for Dynamic Streamable Scenes with 3D Gaussian Splatting</title><link>https://deep-diver.github.io/neurips2024/posters/de4vwe4rbz/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/de4vwe4rbz/</guid><description>HiCoM, a novel framework, achieves high-fidelity streamable dynamic scene reconstruction by using a hierarchical coherent motion mechanism and parallel processing to significantly reduce training time&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/de4vwe4rbz/cover.png"/></item><item><title>HOPE: Shape Matching Via Aligning Different K-hop Neighbourhoods</title><link>https://deep-diver.github.io/neurips2024/posters/1ziiqfo4tj/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/1ziiqfo4tj/</guid><description>HOPE: a novel shape matching method achieving both accuracy and smoothness by aligning different k-hop neighborhoods and refining maps via local map distortion.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/1ziiqfo4tj/cover.png"/></item><item><title>How to Use Diffusion Priors under Sparse Views?</title><link>https://deep-diver.github.io/neurips2024/posters/i6bbclcymr/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/i6bbclcymr/</guid><description>Inline Prior Guided Score Matching (IPSM) improves sparse-view 3D reconstruction by leveraging visual inline priors from pose relationships to rectify rendered image distribution and effectively guide&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/i6bbclcymr/cover.png"/></item><item><title>Human-3Diffusion: Realistic Avatar Creation via Explicit 3D Consistent Diffusion Models</title><link>https://deep-diver.github.io/neurips2024/posters/7w0f7lifdk/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/7w0f7lifdk/</guid><description>Human-3Diffusion generates realistic 3D avatars from single RGB images using coupled 2D multi-view and 3D consistent diffusion models, achieving high-fidelity geometry and texture.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/7w0f7lifdk/cover.png"/></item><item><title>HumanSplat: Generalizable Single-Image Human Gaussian Splatting with Structure Priors</title><link>https://deep-diver.github.io/neurips2024/posters/jbaug7o8yv/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/jbaug7o8yv/</guid><description>HumanSplat: single image-based 3D human reconstruction using Gaussian Splatting with structural priors, achieving state-of-the-art quality and speed.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/jbaug7o8yv/cover.png"/></item><item><title>ID-to-3D: Expressive ID-guided 3D Heads via Score Distillation Sampling</title><link>https://deep-diver.github.io/neurips2024/posters/sluzpdmdfg/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/sluzpdmdfg/</guid><description>ID-to-3D: Generate expressive, identity-consistent 3D human heads from just a few in-the-wild images using score distillation sampling and 2D diffusion models.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/sluzpdmdfg/cover.png"/></item><item><title>IllumiNeRF: 3D Relighting Without Inverse Rendering</title><link>https://deep-diver.github.io/neurips2024/posters/k6m3y6qnsj/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/k6m3y6qnsj/</guid><description>IllumiNeRF: Relightable 3D reconstruction without inverse rendering using image diffusion and NeRF.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/k6m3y6qnsj/cover.png"/></item><item><title>ImOV3D: Learning Open Vocabulary Point Clouds 3D Object Detection from Only 2D Images</title><link>https://deep-diver.github.io/neurips2024/posters/rco9frp8aj/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/rco9frp8aj/</guid><description>ImOV3D: Revolutionizing open-vocabulary 3D object detection by learning from 2D images alone!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/rco9frp8aj/cover.png"/></item><item><title>Improving Robustness of 3D Point Cloud Recognition from a Fourier Perspective</title><link>https://deep-diver.github.io/neurips2024/posters/4jn7kwphsd/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/4jn7kwphsd/</guid><description>Boosting 3D point cloud recognition robustness, Frequency Adversarial Training (FAT) leverages frequency-domain adversarial examples to improve model resilience against corruptions, achieving state-of&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/4jn7kwphsd/cover.png"/></item><item><title>In-N-Out: Lifting 2D Diffusion Prior for 3D Object Removal via Tuning-Free Latents Alignment</title><link>https://deep-diver.github.io/neurips2024/posters/gffaydu9mm/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/gffaydu9mm/</guid><description>In-N-Out: Lifting 2D Diffusion Priors for 3D Object Removal via Tuning-Free Latents Alignment enhances 3D scene reconstruction by aligning 2D diffusion model latents for consistent multi-view inpainti&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/gffaydu9mm/cover.png"/></item><item><title>Incorporating Test-Time Optimization into Training with Dual Networks for Human Mesh Recovery</title><link>https://deep-diver.github.io/neurips2024/posters/ugqx9tgyum/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/ugqx9tgyum/</guid><description>Meta-learning enhances human mesh recovery by unifying training and test-time objectives, significantly improving accuracy and generalization.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/ugqx9tgyum/cover.png"/></item><item><title>Inferring Neural Signed Distance Functions by Overfitting on Single Noisy Point Clouds through Finetuning Data-Driven based Priors</title><link>https://deep-diver.github.io/neurips2024/posters/hgqs1b4ecy/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/hgqs1b4ecy/</guid><description>This research presents LocalN2NM, a novel method for inferring neural signed distance functions (SDF) from single, noisy point clouds by finetuning data-driven priors, achieving faster inference and b&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/hgqs1b4ecy/cover.png"/></item><item><title>Key-Grid: Unsupervised 3D Keypoints Detection using Grid Heatmap Features</title><link>https://deep-diver.github.io/neurips2024/posters/4pcu9c8lex/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/4pcu9c8lex/</guid><description>Key-Grid: An unsupervised 3D keypoint detector achieving state-of-the-art semantic consistency and accuracy for both rigid and deformable objects using novel grid heatmap features.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/4pcu9c8lex/cover.png"/></item><item><title>L4GM: Large 4D Gaussian Reconstruction Model</title><link>https://deep-diver.github.io/neurips2024/posters/psptj26lbp/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/psptj26lbp/</guid><description>L4GM: The first 4D model generating high-quality animated 3D objects from single-view videos in a single feed-forward pass.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/psptj26lbp/cover.png"/></item><item><title>LAM3D: Large Image-Point Clouds Alignment Model for 3D Reconstruction from Single Image</title><link>https://deep-diver.github.io/neurips2024/posters/7s53dajlwz/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/7s53dajlwz/</guid><description>LAM3D: A novel framework uses point cloud data to boost single-image 3D mesh reconstruction accuracy, achieving state-of-the-art results in just 6 seconds.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/7s53dajlwz/cover.png"/></item><item><title>Large Spatial Model: End-to-end Unposed Images to Semantic 3D</title><link>https://deep-diver.github.io/neurips2024/posters/ybhpzl7eyt/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/ybhpzl7eyt/</guid><description>Large Spatial Model (LSM) achieves real-time semantic 3D reconstruction from just two unposed images, unifying multiple 3D vision tasks in a single feed-forward pass.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/ybhpzl7eyt/cover.png"/></item><item><title>LCM: Locally Constrained Compact Point Cloud Model for Masked Point Modeling</title><link>https://deep-diver.github.io/neurips2024/posters/h1nklrkpyi/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/h1nklrkpyi/</guid><description>LCM: a novel, locally constrained, compact point cloud model surpasses Transformer-based methods by significantly improving performance and efficiency in various downstream tasks.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/h1nklrkpyi/cover.png"/></item><item><title>Learning 3D Equivariant Implicit Function with Patch-Level Pose-Invariant Representation</title><link>https://deep-diver.github.io/neurips2024/posters/axs1pwma8i/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/axs1pwma8i/</guid><description>3D surface reconstruction revolutionized: PEIF leverages patch-level pose-invariant representations and 3D patch-level equivariance for state-of-the-art accuracy, even with varied poses and datasets!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/axs1pwma8i/cover.png"/></item><item><title>Learning 3D Garment Animation from Trajectories of A Piece of Cloth</title><link>https://deep-diver.github.io/neurips2024/posters/yefx5nqmr7/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/yefx5nqmr7/</guid><description>Animates diverse garments realistically from a single cloth&amp;rsquo;s trajectory using a disentangled learning approach and Energy Unit Network (EUNet).</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/yefx5nqmr7/cover.png"/></item><item><title>Learning Disentangled Representations for Perceptual Point Cloud Quality Assessment via Mutual Information Minimization</title><link>https://deep-diver.github.io/neurips2024/posters/mssrhxwzp7/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/mssrhxwzp7/</guid><description>DisPA: a novel disentangled representation learning framework for perceptual point cloud quality assessment achieves superior performance by minimizing mutual information between content and distortio&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/mssrhxwzp7/cover.png"/></item><item><title>Learning Interaction-aware 3D Gaussian Splatting for One-shot Hand Avatars</title><link>https://deep-diver.github.io/neurips2024/posters/bxpa7sn5zq/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/bxpa7sn5zq/</guid><description>Create animatable interacting hand avatars from a single image using a novel two-stage interaction-aware 3D Gaussian splatting framework!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/bxpa7sn5zq/cover.png"/></item><item><title>Learning to be Smooth: An End-to-End Differentiable Particle Smoother</title><link>https://deep-diver.github.io/neurips2024/posters/wdmhbqcoqw/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/wdmhbqcoqw/</guid><description>Learned Mixture Density Particle Smoother (MDPS) surpasses state-of-the-art for accurate, differentiable city-scale vehicle localization.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/wdmhbqcoqw/cover.png"/></item><item><title>LightGaussian: Unbounded 3D Gaussian Compression with 15x Reduction and 200+ FPS</title><link>https://deep-diver.github.io/neurips2024/spotlight-others/6aeidnrtn2/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-others/6aeidnrtn2/</guid><description>LightGaussian achieves 15x compression of 3D Gaussian scene representations, boosting rendering speed to 200+ FPS while maintaining visual quality, solving storage and efficiency issues in real-time n&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-others/6aeidnrtn2/cover.png"/></item><item><title>Lighting Every Darkness with 3DGS: Fast Training and Real-Time Rendering for HDR View Synthesis</title><link>https://deep-diver.github.io/neurips2024/posters/6w3lbkkril/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/6w3lbkkril/</guid><description>LE3D: Real-time HDR view synthesis from noisy RAW images is achieved using 3DGS, significantly reducing training time and improving rendering speed.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/6w3lbkkril/cover.png"/></item><item><title>LinNet: Linear Network for Efficient Point Cloud Representation Learning</title><link>https://deep-diver.github.io/neurips2024/posters/ehfcxpdsrw/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/ehfcxpdsrw/</guid><description>LinNet: A linear-time point cloud network achieving 10x speedup over PointNeXt, with state-of-the-art accuracy on various benchmarks.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/ehfcxpdsrw/cover.png"/></item><item><title>LoCo: Learning 3D Location-Consistent Image Features with a Memory-Efficient Ranking Loss</title><link>https://deep-diver.github.io/neurips2024/posters/l6iczoxafi/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/l6iczoxafi/</guid><description>LoCo: Memory-efficient location-consistent image features learned via a novel ranking loss, enabling three orders of magnitude memory improvement and outperforming state-of-the-art.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/l6iczoxafi/cover.png"/></item><item><title>LoD-Loc: Aerial Visual Localization using LoD 3D Map with Neural Wireframe Alignment</title><link>https://deep-diver.github.io/neurips2024/posters/pqlkliexyj/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/pqlkliexyj/</guid><description>LoD-Loc: A novel aerial visual localization method uses lightweight LoD 3D maps &amp;amp; neural wireframe alignment for accurate and efficient 6-DoF pose estimation, surpassing state-of-the-art methods.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/pqlkliexyj/cover.png"/></item><item><title>LP-3DGS: Learning to Prune 3D Gaussian Splatting</title><link>https://deep-diver.github.io/neurips2024/posters/kzj9p7vpns/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/kzj9p7vpns/</guid><description>LP-3DGS learns to optimally prune 3D Gaussian splatting, achieving significant efficiency gains without compromising rendering quality via a trainable binary mask and the Gumbel-Sigmoid method.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/kzj9p7vpns/cover.png"/></item><item><title>LRM-Zero: Training Large Reconstruction Models with Synthesized Data</title><link>https://deep-diver.github.io/neurips2024/posters/mtrvzjbsba/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/mtrvzjbsba/</guid><description>LRM-Zero: Training large reconstruction models solely on synthetic data, achieving quality comparable to real-data trained models.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/mtrvzjbsba/cover.png"/></item><item><title>LuSh-NeRF: Lighting up and Sharpening NeRFs for Low-light Scenes</title><link>https://deep-diver.github.io/neurips2024/posters/ccmhle6n6u/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/ccmhle6n6u/</guid><description>LuSh-NeRF: A novel model reconstructs sharp, bright NeRFs from hand-held low-light photos by sequentially modeling and removing noise and blur, outperforming existing methods.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/ccmhle6n6u/cover.png"/></item><item><title>ManiPose: Manifold-Constrained Multi-Hypothesis 3D Human Pose Estimation</title><link>https://deep-diver.github.io/neurips2024/posters/xxy8d4rnsb/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/xxy8d4rnsb/</guid><description>ManiPose: Manifold-constrained multi-hypothesis model solves 3D human pose estimation&amp;rsquo;s depth ambiguity, outperforming state-of-the-art models in pose consistency.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/xxy8d4rnsb/cover.png"/></item><item><title>Memorize What Matters: Emergent Scene Decomposition from Multitraverse</title><link>https://deep-diver.github.io/neurips2024/spotlight-others/6qr3932rwe/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-others/6qr3932rwe/</guid><description>3D Gaussian Mapping (3DGM) achieves self-supervised camera-only 3D scene decomposition by leveraging multi-traverse driving data, memorizing permanent structures while filtering out transient objects.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-others/6qr3932rwe/cover.png"/></item><item><title>MeshFormer : High-Quality Mesh Generation with 3D-Guided Reconstruction Model</title><link>https://deep-diver.github.io/neurips2024/oral-others/x7pjddod6z/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/oral-others/x7pjddod6z/</guid><description>MeshFormer: High-quality 3D mesh generation from sparse views in seconds, using transformers and 3D convolutions.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/oral-others/x7pjddod6z/cover.png"/></item><item><title>MeshXL: Neural Coordinate Field for Generative 3D Foundation Models</title><link>https://deep-diver.github.io/neurips2024/posters/gcks157fi3/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/gcks157fi3/</guid><description>MeshXL: Autoregressively generating high-quality 3D meshes using a novel Neural Coordinate Field (NeurCF) representation and large language model approaches.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/gcks157fi3/cover.png"/></item><item><title>Meta 3D AssetGen: Text-to-Mesh Generation with High-Quality Geometry, Texture, and PBR Materials</title><link>https://deep-diver.github.io/neurips2024/posters/m3bisggqnb/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/m3bisggqnb/</guid><description>Meta 3D AssetGen: High-quality text-to-mesh generation with realistic PBR materials and lighting, exceeding prior methods in speed and accuracy.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/m3bisggqnb/cover.png"/></item><item><title>Metric from Human: Zero-shot Monocular Metric Depth Estimation via Test-time Adaptation</title><link>https://deep-diver.github.io/neurips2024/posters/ga8tvtxudf/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/ga8tvtxudf/</guid><description>Humans as landmarks: A novel zero-shot monocular metric depth estimation method leverages generative models and human mesh recovery to transfer metric scale information, achieving superior generalizat&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/ga8tvtxudf/cover.png"/></item><item><title>MIDGArD: Modular Interpretable Diffusion over Graphs for Articulated Designs</title><link>https://deep-diver.github.io/neurips2024/posters/re2jpcnzka/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/re2jpcnzka/</guid><description>MIDGARD: Generate high-quality, simulatable 3D articulated assets with enhanced control and interpretability using a novel diffusion-based framework.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/re2jpcnzka/cover.png"/></item><item><title>Mining and Transferring Feature-Geometry Coherence for Unsupervised Point Cloud Registration</title><link>https://deep-diver.github.io/neurips2024/posters/occfkzxded/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/occfkzxded/</guid><description>INTEGER: a novel unsupervised point cloud registration method leveraging feature-geometry coherence for reliable pseudo-label mining and density-invariant feature learning, achieving state-of-the-art &amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/occfkzxded/cover.png"/></item><item><title>Mixture of neural fields for heterogeneous reconstruction in cryo-EM</title><link>https://deep-diver.github.io/neurips2024/posters/tusponzidb/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/tusponzidb/</guid><description>Hydra: a novel cryo-EM reconstruction method resolves both conformational and compositional heterogeneity ab initio, enabling the analysis of complex, unpurified samples with state-of-the-art accuracy&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/tusponzidb/cover.png"/></item><item><title>MotionGS: Exploring Explicit Motion Guidance for Deformable 3D Gaussian Splatting</title><link>https://deep-diver.github.io/neurips2024/posters/6ftlhaxcpr/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/6ftlhaxcpr/</guid><description>MotionGS enhances deformable 3D Gaussian splatting for dynamic scenes by using motion flow to guide deformation, significantly improving reconstruction accuracy and outperforming state-of-the-art meth&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/6ftlhaxcpr/cover.png"/></item><item><title>Multi-hypotheses Conditioned Point Cloud Diffusion for 3D Human Reconstruction from Occluded Images</title><link>https://deep-diver.github.io/neurips2024/posters/e2jcqyyu0e/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/e2jcqyyu0e/</guid><description>MHCDIFF: a novel pipeline using multi-hypotheses conditioned point cloud diffusion for accurate 3D human reconstruction from occluded images, outperforming state-of-the-art methods.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/e2jcqyyu0e/cover.png"/></item><item><title>Multi-scale Consistency for Robust 3D Registration via Hierarchical Sinkhorn Tree</title><link>https://deep-diver.github.io/neurips2024/posters/sfpxuqzdpi/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/sfpxuqzdpi/</guid><description>Hierarchical Sinkhorn Tree (HST) robustly retrieves accurate 3D point cloud correspondences using multi-scale consistency, outperforming state-of-the-art methods.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/sfpxuqzdpi/cover.png"/></item><item><title>Multi-times Monte Carlo Rendering for Inter-reflection Reconstruction</title><link>https://deep-diver.github.io/neurips2024/posters/tlugoshy30/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/tlugoshy30/</guid><description>Ref-MC2 reconstructs high-fidelity 3D objects with inter-reflections by using a novel multi-times Monte Carlo sampling strategy, achieving superior performance in accuracy and efficiency.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/tlugoshy30/cover.png"/></item><item><title>MultiPull: Detailing Signed Distance Functions by Pulling Multi-Level Queries at Multi-Step</title><link>https://deep-diver.github.io/neurips2024/posters/xxe8ml1bco/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/xxe8ml1bco/</guid><description>MultiPull: a novel method reconstructing detailed 3D surfaces from raw point clouds using multi-step optimization of multi-level features, significantly improving accuracy and detail.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/xxe8ml1bco/cover.png"/></item><item><title>Multistable Shape from Shading Emerges from Patch Diffusion</title><link>https://deep-diver.github.io/neurips2024/spotlight-others/bhsfbjs6j9/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-others/bhsfbjs6j9/</guid><description>A novel diffusion model reconstructs multimodal shape distributions from shading, mirroring human multistable perception.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-others/bhsfbjs6j9/cover.png"/></item><item><title>MV2Cyl: Reconstructing 3D Extrusion Cylinders from Multi-View Images</title><link>https://deep-diver.github.io/neurips2024/posters/jdf2zxi8ax/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/jdf2zxi8ax/</guid><description>MV2Cyl: A novel method reconstructs 3D extrusion cylinder CAD models directly from multi-view images, surpassing accuracy of methods using raw 3D geometry.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/jdf2zxi8ax/cover.png"/></item><item><title>MVGamba: Unify 3D Content Generation as State Space Sequence Modeling</title><link>https://deep-diver.github.io/neurips2024/posters/aprsvxrwxt/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/aprsvxrwxt/</guid><description>MVGamba: A unified, feed-forward 3D content generation model achieving state-of-the-art quality and speed using an RNN-like state space model for efficient multi-view Gaussian reconstruction.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/aprsvxrwxt/cover.png"/></item><item><title>MVInpainter: Learning Multi-View Consistent Inpainting to Bridge 2D and 3D Editing</title><link>https://deep-diver.github.io/neurips2024/posters/xiscpcmuse/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/xiscpcmuse/</guid><description>MVInpainter: Pose-free multi-view consistent inpainting bridges 2D and 3D editing by simplifying 3D editing to a multi-view 2D inpainting task.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/xiscpcmuse/cover.png"/></item><item><title>MVSDet: Multi-View Indoor 3D Object Detection via Efficient Plane Sweeps</title><link>https://deep-diver.github.io/neurips2024/posters/gqrwhroxrg/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/gqrwhroxrg/</guid><description>MVSDet uses efficient plane sweeps for accurate indoor 3D object detection from multiple images, significantly outperforming previous NeRF-based methods.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/gqrwhroxrg/cover.png"/></item><item><title>MVSplat360: Feed-Forward 360 Scene Synthesis from Sparse Views</title><link>https://deep-diver.github.io/neurips2024/posters/b0owokmwhz/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/b0owokmwhz/</guid><description>MVSplat360: Generating stunning 360° views from just a few images!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/b0owokmwhz/cover.png"/></item><item><title>NeuMA: Neural Material Adaptor for Visual Grounding of Intrinsic Dynamics</title><link>https://deep-diver.github.io/neurips2024/posters/avwb40qxzh/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/avwb40qxzh/</guid><description>NeuMA: a novel neural material adaptor corrects existing physical models, accurately learning complex dynamics from visual observations.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/avwb40qxzh/cover.png"/></item><item><title>Neural Experts: Mixture of Experts for Implicit Neural Representations</title><link>https://deep-diver.github.io/neurips2024/posters/wwguwyhpay/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/wwguwyhpay/</guid><description>Boosting implicit neural representations, Neural Experts uses a Mixture of Experts architecture to achieve faster, more accurate, and memory-efficient signal reconstruction across various tasks.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/wwguwyhpay/cover.png"/></item><item><title>Neural Isometries: Taming Transformations for Equivariant ML</title><link>https://deep-diver.github.io/neurips2024/posters/kcabcehqwv/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/kcabcehqwv/</guid><description>Neural Isometries learns a latent space where geometric relationships in the observation space are represented as isometries in the latent space, enabling efficient handling of complex symmetries and &amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/kcabcehqwv/cover.png"/></item><item><title>Neural Localizer Fields for Continuous 3D Human Pose and Shape Estimation</title><link>https://deep-diver.github.io/neurips2024/posters/rrtjcbcheh/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/rrtjcbcheh/</guid><description>Neural Localizer Fields (NLF) revolutionizes 3D human pose and shape estimation by learning a continuous field of point localizer functions, enabling flexible training on diverse data and on-the-fly p&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/rrtjcbcheh/cover.png"/></item><item><title>Neural Pose Representation Learning for Generating and Transferring Non-Rigid Object Poses</title><link>https://deep-diver.github.io/neurips2024/posters/nu54mokwla/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/nu54mokwla/</guid><description>Learn disentangled 3D object poses and transfer them between different object identities using a novel neural pose representation, boosting 3D shape generation!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/nu54mokwla/cover.png"/></item><item><title>Neural Signed Distance Function Inference through Splatting 3D Gaussians Pulled on Zero-Level Set</title><link>https://deep-diver.github.io/neurips2024/posters/r6tndxikns/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/r6tndxikns/</guid><description>Neural SDF inference is revolutionized by dynamically aligning 3D Gaussians to a neural SDF&amp;rsquo;s zero-level set, enabling accurate, smooth 3D surface reconstruction.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/r6tndxikns/cover.png"/></item><item><title>NeuRodin: A Two-stage Framework for High-Fidelity Neural Surface Reconstruction</title><link>https://deep-diver.github.io/neurips2024/posters/hvgagu4tkk/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/hvgagu4tkk/</guid><description>NeuRodin: A two-stage neural framework achieves high-fidelity 3D surface reconstruction from posed RGB images by innovatively addressing limitations in SDF-based methods, resulting in superior reconst&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/hvgagu4tkk/cover.png"/></item><item><title>NeuroGauss4D-PCI: 4D Neural Fields and Gaussian Deformation Fields for Point Cloud Interpolation</title><link>https://deep-diver.github.io/neurips2024/posters/lkdckv31t7/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/lkdckv31t7/</guid><description>NeuroGauss4D-PCI masters complex point cloud interpolation using 4D neural fields and Gaussian deformation fields, achieving superior accuracy in dynamic scenes.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/lkdckv31t7/cover.png"/></item><item><title>Normal-GS: 3D Gaussian Splatting with Normal-Involved Rendering</title><link>https://deep-diver.github.io/neurips2024/posters/kngls5h6l1/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/kngls5h6l1/</guid><description>Normal-GS improves 3D Gaussian Splatting by integrating normal vectors into the rendering pipeline, achieving near state-of-the-art visual quality with accurate surface normals in real-time.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/kngls5h6l1/cover.png"/></item><item><title>OccFusion: Rendering Occluded Humans with Generative Diffusion Priors</title><link>https://deep-diver.github.io/neurips2024/posters/czwphz5vgz/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/czwphz5vgz/</guid><description>OccFusion: High-fidelity human rendering from videos, even with occlusions, using 3D Gaussian splatting and 2D diffusion priors.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/czwphz5vgz/cover.png"/></item><item><title>OctreeOcc: Efficient and Multi-Granularity Occupancy Prediction Using Octree Queries</title><link>https://deep-diver.github.io/neurips2024/posters/os14qxhy55/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/os14qxhy55/</guid><description>OctreeOcc uses octree queries for efficient and multi-granularity 3D occupancy prediction, surpassing state-of-the-art methods with reduced computational costs.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/os14qxhy55/cover.png"/></item><item><title>ODGS: 3D Scene Reconstruction from Omnidirectional Images with 3D Gaussian Splattings</title><link>https://deep-diver.github.io/neurips2024/posters/covjsqmnod/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/covjsqmnod/</guid><description>ODGS: Lightning-fast 3D scene reconstruction from single omnidirectional images using 3D Gaussian splatting, achieving 100x speedup over NeRF-based methods.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/covjsqmnod/cover.png"/></item><item><title>One for All: Multi-Domain Joint Training for Point Cloud Based 3D Object Detection</title><link>https://deep-diver.github.io/neurips2024/posters/ndoehx1acq/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/ndoehx1acq/</guid><description>OneDet3D: A universal 3D object detector trained jointly on diverse indoor/outdoor datasets, achieving one-for-all performance across domains and categories.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/ndoehx1acq/cover.png"/></item><item><title>OpenDlign: Open-World Point Cloud Understanding with Depth-Aligned Images</title><link>https://deep-diver.github.io/neurips2024/posters/igcatq4n1r/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/igcatq4n1r/</guid><description>OpenDlign uses novel depth-aligned images from a diffusion model to boost open-world 3D understanding, achieving significant performance gains on diverse benchmarks.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/igcatq4n1r/cover.png"/></item><item><title>OpenGaussian: Towards Point-Level 3D Gaussian-based Open Vocabulary Understanding</title><link>https://deep-diver.github.io/neurips2024/posters/3naeowlh7q/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/3naeowlh7q/</guid><description>OpenGaussian achieves 3D point-level open vocabulary understanding using 3D Gaussian Splatting by training 3D instance features with high 3D consistency, employing a two-level codebook for feature dis&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/3naeowlh7q/cover.png"/></item><item><title>Optimal-state Dynamics Estimation for Physics-based Human Motion Capture from Videos</title><link>https://deep-diver.github.io/neurips2024/posters/rkot8ramrr/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/rkot8ramrr/</guid><description>OSDCap: Online optimal-state dynamics estimation selectively incorporates physics models with kinematic observations to achieve highly accurate, physically-plausible human motion capture from videos.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/rkot8ramrr/cover.png"/></item><item><title>OPUS: Occupancy Prediction Using a Sparse Set</title><link>https://deep-diver.github.io/neurips2024/posters/zyr0srqrdd/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/zyr0srqrdd/</guid><description>OPUS: a novel, real-time occupancy prediction framework using a sparse set prediction paradigm, outperforms state-of-the-art methods on Occ3D-nuScenes.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/zyr0srqrdd/cover.png"/></item><item><title>PCoTTA: Continual Test-Time Adaptation for Multi-Task Point Cloud Understanding</title><link>https://deep-diver.github.io/neurips2024/posters/739jazuxk7/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/739jazuxk7/</guid><description>PCoTTA: A novel framework enables multi-task point cloud models to seamlessly adapt to continuously changing target domains during testing, overcoming catastrophic forgetting and error accumulation.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/739jazuxk7/cover.png"/></item><item><title>PCP-MAE: Learning to Predict Centers for Point Masked Autoencoders</title><link>https://deep-diver.github.io/neurips2024/spotlight-others/i1xjk5a0x8/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-others/i1xjk5a0x8/</guid><description>PCP-MAE enhances point cloud self-supervised learning by cleverly predicting masked patch centers, leading to superior 3D object classification and scene segmentation.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-others/i1xjk5a0x8/cover.png"/></item><item><title>Pedestrian-Centric 3D Pre-collision Pose and Shape Estimation from Dashcam Perspective</title><link>https://deep-diver.github.io/neurips2024/posters/ldvfayzg35/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/ldvfayzg35/</guid><description>New Pedestrian-Vehicle Collision Pose dataset (PVCP) and Pose Estimation Network (PPSENet) improve pedestrian pre-collision pose estimation from dashcam video.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/ldvfayzg35/cover.png"/></item><item><title>PhyRecon: Physically Plausible Neural Scene Reconstruction</title><link>https://deep-diver.github.io/neurips2024/posters/qre9qpq4ya/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/qre9qpq4ya/</guid><description>PHYRECON: A novel neural scene reconstruction method uses differentiable rendering and physics simulation for physically plausible 3D models.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/qre9qpq4ya/cover.png"/></item><item><title>Physically Compatible 3D Object Modeling from a Single Image</title><link>https://deep-diver.github.io/neurips2024/spotlight-others/k29iv0xrbf/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-others/k29iv0xrbf/</guid><description>Single image to physically compatible 3D objects: A new framework ensures 3D models maintain stability and mirror real-world equilibrium states, advancing realism in dynamic simulations and 3D printi&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-others/k29iv0xrbf/cover.png"/></item><item><title>Point-PRC: A Prompt Learning Based Regulation Framework for Generalizable Point Cloud Analysis</title><link>https://deep-diver.github.io/neurips2024/posters/g7lyp11erv/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/g7lyp11erv/</guid><description>Point-PRC improves generalizable 3D point cloud analysis by regulating prompt learning to harmonize task-specific and general knowledge within large 3D models.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/g7lyp11erv/cover.png"/></item><item><title>PointAD: Comprehending 3D Anomalies from Points and Pixels for Zero-shot 3D Anomaly Detection</title><link>https://deep-diver.github.io/neurips2024/posters/02ciz8qedc/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/02ciz8qedc/</guid><description>PointAD: a novel zero-shot 3D anomaly detection method using CLIP&amp;rsquo;s strong generalization abilities to identify anomalies in unseen objects by transferring knowledge from both points and pixels.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/02ciz8qedc/cover.png"/></item><item><title>PointMamba: A Simple State Space Model for Point Cloud Analysis</title><link>https://deep-diver.github.io/neurips2024/posters/kc37srxvan/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/kc37srxvan/</guid><description>PointMamba: A linear-complexity state space model achieving superior performance in point cloud analysis, reducing computational cost significantly.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/kc37srxvan/cover.png"/></item><item><title>Polyhedral Complex Derivation from Piecewise Trilinear Networks</title><link>https://deep-diver.github.io/neurips2024/posters/xz4xsutgrb/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/xz4xsutgrb/</guid><description>This paper presents a novel method for analytically extracting meshes from neural implicit surface networks using trilinear interpolation, offering theoretical insights and practical efficiency.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/xz4xsutgrb/cover.png"/></item><item><title>PPLNs: Parametric Piecewise Linear Networks for Event-Based Temporal Modeling and Beyond</title><link>https://deep-diver.github.io/neurips2024/posters/s8wfxyt4dy/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/s8wfxyt4dy/</guid><description>Parametric Piecewise Linear Networks (PPLNs) achieve state-of-the-art results in event-based and frame-based computer vision tasks by mimicking biological neural principles.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/s8wfxyt4dy/cover.png"/></item><item><title>ProEdit: Simple Progression is All You Need for High-Quality 3D Scene Editing</title><link>https://deep-diver.github.io/neurips2024/posters/ic869bbmc5/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/ic869bbmc5/</guid><description>ProEdit: High-quality 3D scene editing via progressive subtask decomposition.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/ic869bbmc5/cover.png"/></item><item><title>ProvNeRF: Modeling per Point Provenance in NeRFs as a Stochastic Field</title><link>https://deep-diver.github.io/neurips2024/posters/k5pa3sk2jb/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/k5pa3sk2jb/</guid><description>ProvNeRF enhances NeRF reconstruction by modeling per-point provenance as a stochastic field, improving novel view synthesis and uncertainty estimation, particularly in sparse, unconstrained view sett&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/k5pa3sk2jb/cover.png"/></item><item><title>QUEEN: QUantized Efficient ENcoding for Streaming Free-viewpoint Videos</title><link>https://deep-diver.github.io/neurips2024/posters/7xhwe7vh4s/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/7xhwe7vh4s/</guid><description>QUEEN: A novel framework for quantized and efficient streaming of free-viewpoint videos achieving high compression, quality, and speed.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/7xhwe7vh4s/cover.png"/></item><item><title>Reconstruction of Manipulated Garment with Guided Deformation Prior</title><link>https://deep-diver.github.io/neurips2024/posters/a2ccaxtb4i/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/a2ccaxtb4i/</guid><description>Researchers developed a novel method for reconstructing the 3D shape of manipulated garments, achieving superior accuracy compared to existing techniques, particularly for complex, non-rigid deformati&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/a2ccaxtb4i/cover.png"/></item><item><title>ReGS: Reference-based Controllable Scene Stylization with Gaussian Splatting</title><link>https://deep-diver.github.io/neurips2024/posters/ynjr0rw6fr/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/ynjr0rw6fr/</guid><description>ReGS: Real-time reference-based 3D scene stylization using Gaussian Splatting for high-fidelity texture editing and free-view navigation.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/ynjr0rw6fr/cover.png"/></item><item><title>Rethinking 3D Convolution in $ll_p$-norm Space</title><link>https://deep-diver.github.io/neurips2024/spotlight-others/kmxdv4blhn/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-others/kmxdv4blhn/</guid><description>L1-norm based 3D convolution achieves competitive performance with lower energy consumption and latency compared to traditional methods, as proven through universal approximation theorem and experimen&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-others/kmxdv4blhn/cover.png"/></item><item><title>RobIR: Robust Inverse Rendering for High-Illumination Scenes</title><link>https://deep-diver.github.io/neurips2024/posters/y7oxy5pq4j/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/y7oxy5pq4j/</guid><description>RobIR: Robust inverse rendering in high-illumination scenes using ACES tone mapping and regularized visibility estimation for accurate BRDF reconstruction.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/y7oxy5pq4j/cover.png"/></item><item><title>SA3DIP: Segment Any 3D Instance with Potential 3D Priors</title><link>https://deep-diver.github.io/neurips2024/spotlight-others/3ui4cer4iz/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-others/3ui4cer4iz/</guid><description>SA3DIP boosts 3D instance segmentation accuracy by cleverly using 3D spatial and textural cues alongside 2D multi-view masks, overcoming limitations of previous methods.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-others/3ui4cer4iz/cover.png"/></item><item><title>SAM-Guided Masked Token Prediction for 3D Scene Understanding</title><link>https://deep-diver.github.io/neurips2024/posters/f9i1avqtla/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/f9i1avqtla/</guid><description>This paper introduces SAM-guided masked token prediction, a novel framework for 3D scene understanding that leverages foundation models to significantly improve 3D object detection and semantic segmen&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/f9i1avqtla/cover.png"/></item><item><title>SCube: Instant Large-Scale Scene Reconstruction using VoxSplats</title><link>https://deep-diver.github.io/neurips2024/posters/tlxgzq5wzl/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/tlxgzq5wzl/</guid><description>SCube: Instant large-scale 3D scene reconstruction from sparse images using VoxSplats, a novel 3D Gaussian splat representation.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/tlxgzq5wzl/cover.png"/></item><item><title>SE(3)-bi-equivariant Transformers for Point Cloud Assembly</title><link>https://deep-diver.github.io/neurips2024/posters/eehs4erxwb/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/eehs4erxwb/</guid><description>SE(3)-bi-equivariant Transformers (BITR) revolutionizes point cloud assembly by guaranteeing robust alignment even with non-overlapping clouds, thanks to its unique equivariance properties.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/eehs4erxwb/cover.png"/></item><item><title>Self-Distilled Depth Refinement with Noisy Poisson Fusion</title><link>https://deep-diver.github.io/neurips2024/posters/nequ0ica0s/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/nequ0ica0s/</guid><description>Self-Distilled Depth Refinement (SDDR) tackles noisy depth maps via a novel noisy Poisson fusion approach, achieving significant improvements in depth accuracy and edge quality.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/nequ0ica0s/cover.png"/></item><item><title>Semi-Open 3D Object Retrieval via Hierarchical Equilibrium on Hypergraph</title><link>https://deep-diver.github.io/neurips2024/posters/a3jhvchr8k/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/a3jhvchr8k/</guid><description>HERT: a novel framework for semi-open 3D object retrieval using hierarchical hypergraph equilibrium, achieving state-of-the-art performance on four new benchmark datasets.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/a3jhvchr8k/cover.png"/></item><item><title>SfPUEL: Shape from Polarization under Unknown Environment Light</title><link>https://deep-diver.github.io/neurips2024/posters/skeopn3q5y/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/skeopn3q5y/</guid><description>SfPUEL: A novel end-to-end SfP method achieves robust single-shot surface normal estimation under diverse lighting, integrating PS priors and material segmentation.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/skeopn3q5y/cover.png"/></item><item><title>Sparse-view Pose Estimation and Reconstruction via Analysis by Generative Synthesis</title><link>https://deep-diver.github.io/neurips2024/posters/wgpmdyjgsg/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/wgpmdyjgsg/</guid><description>SparseAGS: High-fidelity 3D reconstruction &amp;amp; camera pose estimation from sparse views via generative synthesis.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/wgpmdyjgsg/cover.png"/></item><item><title>Spec-Gaussian: Anisotropic View-Dependent Appearance for 3D Gaussian Splatting</title><link>https://deep-diver.github.io/neurips2024/posters/qdfpswxslt/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/qdfpswxslt/</guid><description>Spec-Gaussian enhances 3D Gaussian splatting by using anisotropic spherical Gaussians for view-dependent appearance modeling, achieving superior real-time rendering of scenes with specular and anisotr&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/qdfpswxslt/cover.png"/></item><item><title>SpelsNet: Surface Primitive Elements Segmentation by B-Rep Graph Structure Supervision</title><link>https://deep-diver.github.io/neurips2024/posters/ad3pztuqiq/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/ad3pztuqiq/</guid><description>SpelsNet, a novel neural architecture, achieves accurate 3D point cloud segmentation into surface primitives by incorporating B-Rep graph structure supervision, leading to topologically consistent res&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/ad3pztuqiq/cover.png"/></item><item><title>Spherical Frustum Sparse Convolution Network for LiDAR Point Cloud Semantic Segmentation</title><link>https://deep-diver.github.io/neurips2024/posters/lqdcdqievd/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/lqdcdqievd/</guid><description>SFCNet, a novel spherical frustum sparse convolution network, tackles LiDAR point cloud semantic segmentation by eliminating quantized information loss, leading to superior performance, especially for&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/lqdcdqievd/cover.png"/></item><item><title>SplitNeRF: Split Sum Approximation Neural Field for Joint Geometry, Illumination, and Material Estimation</title><link>https://deep-diver.github.io/neurips2024/posters/claosszt6v/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/claosszt6v/</guid><description>SplitNeRF: One-hour training on a single GPU yields state-of-the-art scene geometry, lighting, and material property estimation!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/claosszt6v/cover.png"/></item><item><title>STONE: A Submodular Optimization Framework for Active 3D Object Detection</title><link>https://deep-diver.github.io/neurips2024/posters/eqhqzrjy75/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/eqhqzrjy75/</guid><description>STONE: A novel submodular optimization framework drastically cuts 3D object detection training costs by cleverly selecting the most informative LiDAR point cloud data for labeling, achieving state-of-&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/eqhqzrjy75/cover.png"/></item><item><title>Subsurface Scattering for Gaussian Splatting</title><link>https://deep-diver.github.io/neurips2024/posters/2vmvh5xp0p/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/2vmvh5xp0p/</guid><description>Real-time rendering of objects with subsurface scattering effects is now possible with SSS-GS, a novel method combining explicit surface geometry and implicit subsurface scattering for high-quality no&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/2vmvh5xp0p/cover.png"/></item><item><title>Target-Guided Adversarial Point Cloud Transformer Towards Recognition Against Real-world Corruptions</title><link>https://deep-diver.github.io/neurips2024/posters/fcuyz33oed/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/fcuyz33oed/</guid><description>APCT: a novel architecture enhances 3D point cloud recognition by using an adversarial feature erasing mechanism to improve global structure capture and robustness against real-world corruptions.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/fcuyz33oed/cover.png"/></item><item><title>Template-free Articulated Gaussian Splatting for Real-time Reposable Dynamic View Synthesis</title><link>https://deep-diver.github.io/neurips2024/posters/vcgev6m5m2/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/vcgev6m5m2/</guid><description>This research introduces a template-free articulated Gaussian splatting method for real-time dynamic view synthesis, automatically discovering object skeletons from videos to enable reposing.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/vcgev6m5m2/cover.png"/></item><item><title>Tensor-Based Synchronization and the Low-Rankness of the Block Trifocal Tensor</title><link>https://deep-diver.github.io/neurips2024/posters/dt7n4f2bbp/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/dt7n4f2bbp/</guid><description>Low-rank block trifocal tensor unlocks accurate, efficient camera pose synchronization.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/dt7n4f2bbp/cover.png"/></item><item><title>Tetrahedron Splatting for 3D Generation</title><link>https://deep-diver.github.io/neurips2024/spotlight-others/qvsp1uk7b5/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-others/qvsp1uk7b5/</guid><description>TeT-Splatting: a novel 3D representation enabling fast convergence, real-time rendering, and precise mesh extraction for high-fidelity 3D generation.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-others/qvsp1uk7b5/cover.png"/></item><item><title>TFS-NeRF: Template-Free NeRF for Semantic 3D Reconstruction of Dynamic Scene</title><link>https://deep-diver.github.io/neurips2024/posters/upxfyvhsyn/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/upxfyvhsyn/</guid><description>TFS-NeRF: A template-free neural radiance field efficiently reconstructs semantically separable 3D geometries of dynamic scenes featuring multiple interacting entities from sparse RGB videos.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/upxfyvhsyn/cover.png"/></item><item><title>Toward Approaches to Scalability in 3D Human Pose Estimation</title><link>https://deep-diver.github.io/neurips2024/posters/xse8qmgnym/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/xse8qmgnym/</guid><description>Boosting 3D human pose estimation: Biomechanical Pose Generator and Binary Depth Coordinates enhance accuracy and scalability.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/xse8qmgnym/cover.png"/></item><item><title>Toward Dynamic Non-Line-of-Sight Imaging with Mamba Enforced Temporal Consistency</title><link>https://deep-diver.github.io/neurips2024/posters/qicjomiw3l/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/qicjomiw3l/</guid><description>Dynamic NLOS imaging gets a speed boost! New ST-Mamba method leverages temporal consistency across frames for high-resolution video reconstruction, overcoming speed limitations of traditional methods.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/qicjomiw3l/cover.png"/></item><item><title>Towards Flexible 3D Perception: Object-Centric Occupancy Completion Augments 3D Object Detection</title><link>https://deep-diver.github.io/neurips2024/posters/yktqnqtepd/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/yktqnqtepd/</guid><description>Object-centric occupancy completion boosts 3D object detection accuracy by using temporal information from long sequences to precisely reconstruct object shapes, particularly for incomplete or distant&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/yktqnqtepd/cover.png"/></item><item><title>Towards Learning Group-Equivariant Features for Domain Adaptive 3D Detection</title><link>https://deep-diver.github.io/neurips2024/posters/yetirxhsh1/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/yetirxhsh1/</guid><description>GroupEXP-DA boosts domain adaptive 3D object detection by using a grouping-exploration strategy to reduce bias in pseudo-label collection and account for multiple factors affecting object perception i&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/yetirxhsh1/cover.png"/></item><item><title>Training an Open-Vocabulary Monocular 3D Detection Model without 3D Data</title><link>https://deep-diver.github.io/neurips2024/posters/efkw0ogzor/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/efkw0ogzor/</guid><description>Train open-vocabulary 3D object detectors using only RGB images and large language models, achieving state-of-the-art performance without expensive LiDAR data.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/efkw0ogzor/cover.png"/></item><item><title>UniDSeg: Unified Cross-Domain 3D Semantic Segmentation via Visual Foundation Models Prior</title><link>https://deep-diver.github.io/neurips2024/posters/dddc3inza7/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/dddc3inza7/</guid><description>UniDSeg uses Visual Foundation Models to create a unified framework for adaptable and generalizable cross-domain 3D semantic segmentation, achieving state-of-the-art results.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/dddc3inza7/cover.png"/></item><item><title>Unified Domain Generalization and Adaptation for Multi-View 3D Object Detection</title><link>https://deep-diver.github.io/neurips2024/posters/lxuxvjsocp/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/lxuxvjsocp/</guid><description>Unified Domain Generalization and Adaptation (UDGA) tackles 3D object detection&amp;rsquo;s domain adaptation challenges by leveraging multi-view overlap and label-efficient learning, achieving state-of-the-art&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/lxuxvjsocp/cover.png"/></item><item><title>Unique3D: High-Quality and Efficient 3D Mesh Generation from a Single Image</title><link>https://deep-diver.github.io/neurips2024/posters/uo7mvch1z5/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/uo7mvch1z5/</guid><description>Unique3D: Single image to high-fidelity 3D mesh in 30 seconds!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/uo7mvch1z5/cover.png"/></item><item><title>UniSDF: Unifying Neural Representations for High-Fidelity 3D Reconstruction of Complex Scenes with Reflections</title><link>https://deep-diver.github.io/neurips2024/posters/ty25ovktqj/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/ty25ovktqj/</guid><description>UniSDF: Unifying neural representations reconstructs complex scenes with reflections, achieving state-of-the-art performance by blending camera and reflected view radiance fields.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/ty25ovktqj/cover.png"/></item><item><title>Unlearnable 3D Point Clouds: Class-wise Transformation Is All You Need</title><link>https://deep-diver.github.io/neurips2024/posters/seefza7vmq/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/seefza7vmq/</guid><description>New unlearnable framework secures 3D point cloud data by using class-wise transformations, enabling authorized training while preventing unauthorized access.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/seefza7vmq/cover.png"/></item><item><title>UV-free Texture Generation with Denoising and Geodesic Heat Diffusion</title><link>https://deep-diver.github.io/neurips2024/posters/cb1md0rvqf/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/cb1md0rvqf/</guid><description>UV3-TeD generates high-quality 3D textures directly on object surfaces using a novel diffusion probabilistic model, eliminating UV-mapping limitations.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/cb1md0rvqf/cover.png"/></item><item><title>Variational Multi-scale Representation for Estimating Uncertainty in 3D Gaussian Splatting</title><link>https://deep-diver.github.io/neurips2024/posters/qpeatfuwoq/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/qpeatfuwoq/</guid><description>New uncertainty estimation method for 3D Gaussian Splatting improves scene reconstruction quality by leveraging variational multi-scale representation and efficiently removing noisy data.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/qpeatfuwoq/cover.png"/></item><item><title>VCR-GauS: View Consistent Depth-Normal Regularizer for Gaussian Surface Reconstruction</title><link>https://deep-diver.github.io/neurips2024/posters/axnjx20ssl/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/axnjx20ssl/</guid><description>VCR-GauS: Novel view-consistent depth-normal regularizer for superior, real-time 3D surface reconstruction using Gaussian splatting.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/axnjx20ssl/cover.png"/></item><item><title>Vision Foundation Model Enables Generalizable Object Pose Estimation</title><link>https://deep-diver.github.io/neurips2024/posters/ftpkguxefy/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/ftpkguxefy/</guid><description>VFM-6D: a novel framework achieving generalizable object pose estimation for unseen categories by leveraging vision-language models.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/ftpkguxefy/cover.png"/></item><item><title>Voxel Mamba: Group-Free State Space Models for Point Cloud based 3D Object Detection</title><link>https://deep-diver.github.io/neurips2024/spotlight-others/ghyhvsctdh/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-others/ghyhvsctdh/</guid><description>Voxel Mamba: a group-free 3D object detection method using state space models, achieving higher accuracy and efficiency by overcoming limitations of serialization-based Transformers.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-others/ghyhvsctdh/cover.png"/></item><item><title>Voxel Proposal Network via Multi-Frame Knowledge Distillation for Semantic Scene Completion</title><link>https://deep-diver.github.io/neurips2024/posters/02hwt9c4lp/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/02hwt9c4lp/</guid><description>VPNet, a novel semantic scene completion network, uses multi-frame knowledge distillation and confident voxel proposals to improve accuracy and handle dynamic aspects of 3D scenes from point clouds, a&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/02hwt9c4lp/cover.png"/></item><item><title>VQ-Map: Bird's-Eye-View Map Layout Estimation in Tokenized Discrete Space via Vector Quantization</title><link>https://deep-diver.github.io/neurips2024/posters/bkuxygbw2y/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/bkuxygbw2y/</guid><description>VQ-Map leverages vector quantization to estimate bird&amp;rsquo;s-eye-view maps with unprecedented accuracy, setting new benchmarks.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/bkuxygbw2y/cover.png"/></item><item><title>Wild-GS: Real-Time Novel View Synthesis from Unconstrained Photo Collections</title><link>https://deep-diver.github.io/neurips2024/posters/ss7l98dvvd/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/ss7l98dvvd/</guid><description>Wild-GS achieves real-time novel view synthesis from unconstrained photos by efficiently adapting 3D Gaussian Splatting, significantly improving speed and quality over existing methods.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/ss7l98dvvd/cover.png"/></item><item><title>WildGaussians: 3D Gaussian Splatting In the Wild</title><link>https://deep-diver.github.io/neurips2024/posters/nu3te3liqf/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/nu3te3liqf/</guid><description>WildGaussians enhances 3D Gaussian splatting for real-time rendering of photorealistic 3D scenes from in-the-wild images featuring occlusions and appearance changes.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/nu3te3liqf/cover.png"/></item><item><title>X-Ray: A Sequential 3D Representation For Generation</title><link>https://deep-diver.github.io/neurips2024/spotlight-others/36tmv15dpo/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-others/36tmv15dpo/</guid><description>X-Ray: A novel 3D representation generating complete object surfaces from a single image!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-others/36tmv15dpo/cover.png"/></item><item><title>Zero-Shot Event-Intensity Asymmetric Stereo via Visual Prompting from Image Domain</title><link>https://deep-diver.github.io/neurips2024/posters/e3zmsqdo0d/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/e3zmsqdo0d/</guid><description>Zero-shot Event-Intensity Asymmetric Stereo (ZEST) uses visual prompting and monocular cues to achieve robust 3D perception without event-specific training, outperforming existing methods.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/e3zmsqdo0d/cover.png"/></item><item><title>Zero-Shot Scene Reconstruction from Single Images with Deep Prior Assembly</title><link>https://deep-diver.github.io/neurips2024/posters/sotk84ewb7/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/sotk84ewb7/</guid><description>Zero-shot 3D scene reconstruction from single images is achieved by assembling diverse deep priors from large models, eliminating the need for 3D/2D training data and achieving superior performance.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/sotk84ewb7/cover.png"/></item><item><title>ZOPP: A Framework of Zero-shot Offboard Panoptic Perception for Autonomous Driving</title><link>https://deep-diver.github.io/neurips2024/posters/4jxaca2nya/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/4jxaca2nya/</guid><description>ZOPP: A groundbreaking framework for zero-shot offboard panoptic perception in autonomous driving, enabling high-quality 3D scene understanding without human labeling.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/4jxaca2nya/cover.png"/></item></channel></rss>