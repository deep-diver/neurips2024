<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>3D Vision on NeurIPS 2024</title><link>https://deep-diver.github.io/neurips2024/tags/3d-vision/</link><description>Recent content in 3D Vision on NeurIPS 2024</description><generator>Hugo -- gohugo.io</generator><language>en</language><copyright>Â© 2024 AI Paper Reviewer</copyright><lastBuildDate>Thu, 26 Sep 2024 00:00:00 +0000</lastBuildDate><atom:link href="https://deep-diver.github.io/neurips2024/tags/3d-vision/index.xml" rel="self" type="application/rss+xml"/><item><title>$SE(3)$ Equivariant Ray Embeddings for Implicit Multi-View Depth Estimation</title><link>https://deep-diver.github.io/neurips2024/posters/yrujqowocs/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/yrujqowocs/</guid><description>SE(3)-equivariant ray embeddings in Perceiver IO achieve state-of-the-art implicit multi-view depth estimation, surpassing methods that rely on data augmentation for approximate equivariance.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/yrujqowocs/cover.png"/></item><item><title>3D Equivariant Pose Regression via Direct Wigner-D Harmonics Prediction</title><link>https://deep-diver.github.io/neurips2024/posters/nw8cxonvep/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/nw8cxonvep/</guid><description>3D pose estimation is revolutionized by a novel SO(3)-equivariant network directly predicting Wigner-D harmonics, achieving state-of-the-art accuracy and efficiency.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/nw8cxonvep/cover.png"/></item><item><title>3D Gaussian Splatting as Markov Chain Monte Carlo</title><link>https://deep-diver.github.io/neurips2024/spotlight-others/ucst4gk6ix/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-others/ucst4gk6ix/</guid><description>Researchers rethink 3D Gaussian Splatting as MCMC sampling, improving rendering quality and Gaussian control via a novel relocation strategy.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-others/ucst4gk6ix/cover.png"/></item><item><title>3DGS-Enhancer: Enhancing Unbounded 3D Gaussian Splatting with View-consistent 2D Diffusion Priors</title><link>https://deep-diver.github.io/neurips2024/spotlight-others/p4s6fupcbg/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-others/p4s6fupcbg/</guid><description>3DGS-Enhancer boosts unbounded 3D Gaussian splatting, generating high-fidelity novel views even with sparse input data using view-consistent 2D diffusion priors.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-others/p4s6fupcbg/cover.png"/></item><item><title>A Consistency-Aware Spot-Guided Transformer for Versatile and Hierarchical Point Cloud Registration</title><link>https://deep-diver.github.io/neurips2024/posters/btllwaorfs/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/btllwaorfs/</guid><description>CAST: a novel consistency-aware spot-guided Transformer achieves state-of-the-art accuracy and efficiency in point cloud registration.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/btllwaorfs/cover.png"/></item><item><title>A Unified Framework for 3D Scene Understanding</title><link>https://deep-diver.github.io/neurips2024/posters/de1btyyc9a/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/de1btyyc9a/</guid><description>UniSeg3D: One model to rule them all! This unified framework masters six 3D segmentation tasks (panoptic, semantic, instance, interactive, referring, and open-vocabulary) simultaneously, outperforming&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/de1btyyc9a/cover.png"/></item><item><title>Activating Self-Attention for Multi-Scene Absolute Pose Regression</title><link>https://deep-diver.github.io/neurips2024/posters/rm24uugzg8/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/rm24uugzg8/</guid><description>Boosting Multi-Scene Pose Regression: Novel methods activate transformer self-attention, significantly improving camera pose estimation accuracy and efficiency.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/rm24uugzg8/cover.png"/></item><item><title>Assembly Fuzzy Representation on Hypergraph for Open-Set 3D Object Retrieval</title><link>https://deep-diver.github.io/neurips2024/posters/xocaurlvm9/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/xocaurlvm9/</guid><description>Hypergraph-Based Assembly Fuzzy Representation (HAFR) excels at open-set 3D object retrieval by using part-level shapes and fuzzy representations to overcome challenges posed by unseen object categori&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/xocaurlvm9/cover.png"/></item><item><title>Binocular-Guided 3D Gaussian Splatting with View Consistency for Sparse View Synthesis</title><link>https://deep-diver.github.io/neurips2024/posters/otettmiymz/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/otettmiymz/</guid><description>Binocular-guided 3D Gaussian splatting with self-supervision generates high-quality novel views from sparse inputs without external priors, significantly outperforming state-of-the-art methods.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/otettmiymz/cover.png"/></item><item><title>CAT3D: Create Anything in 3D with Multi-View Diffusion Models</title><link>https://deep-diver.github.io/neurips2024/oral-others/tfzlfrl9ks/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/oral-others/tfzlfrl9ks/</guid><description>CAT3D: Generate high-quality 3D scenes from as little as one image using a novel multi-view diffusion model, outperforming existing methods in speed and quality.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/oral-others/tfzlfrl9ks/cover.png"/></item><item><title>Context and Geometry Aware Voxel Transformer for Semantic Scene Completion</title><link>https://deep-diver.github.io/neurips2024/spotlight-others/9bu627mtfs/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-others/9bu627mtfs/</guid><description>CGFormer: a novel voxel transformer boosting semantic scene completion accuracy by using context-aware queries and 3D deformable attention, outperforming existing methods on SemanticKITTI and SSCBench&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-others/9bu627mtfs/cover.png"/></item><item><title>CRAYM: Neural Field Optimization via Camera RAY Matching</title><link>https://deep-diver.github.io/neurips2024/posters/wk0z49myyi/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/wk0z49myyi/</guid><description>CRAYM: Neural field optimization via camera RAY matching enhances 3D reconstruction by using camera rays, not pixels, improving both novel view synthesis and geometry.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/wk0z49myyi/cover.png"/></item><item><title>Depth Anything V2</title><link>https://deep-diver.github.io/neurips2024/posters/cfti3glj1x/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/cfti3glj1x/</guid><description>Depth Anything V2 drastically improves monocular depth estimation by using synthetic training data, scaling up the teacher model, and employing pseudo-labeled real images. It outperforms previous met&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/cfti3glj1x/cover.png"/></item><item><title>Direct3D: Scalable Image-to-3D Generation via 3D Latent Diffusion Transformer</title><link>https://deep-diver.github.io/neurips2024/posters/vcogjbizul/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/vcogjbizul/</guid><description>Direct3D: Revolutionizing image-to-3D generation with a scalable, native 3D diffusion model achieving state-of-the-art quality.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/vcogjbizul/cover.png"/></item><item><title>Dynamic 3D Gaussian Fields for Urban Areas</title><link>https://deep-diver.github.io/neurips2024/spotlight-others/xzxxnhndxu/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-others/xzxxnhndxu/</guid><description>4DGF, a novel neural scene representation, achieves interactive-speed novel view synthesis for large-scale dynamic urban areas by efficiently combining 3D Gaussians and neural fields.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-others/xzxxnhndxu/cover.png"/></item><item><title>Fast Encoder-Based 3D from Casual Videos via Point Track Processing</title><link>https://deep-diver.github.io/neurips2024/posters/bqgaheaeqy/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/bqgaheaeqy/</guid><description>TRACKSTO4D: Fast &amp;amp; accurate 3D reconstruction from casual videos using 2D point tracks, drastically reducing runtime by up to 95% while matching state-of-the-art accuracy.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/bqgaheaeqy/cover.png"/></item><item><title>Flatten Anything: Unsupervised Neural Surface Parameterization</title><link>https://deep-diver.github.io/neurips2024/posters/eneqgc9agr/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/eneqgc9agr/</guid><description>Flatten Anything Model (FAM) revolutionizes neural surface parameterization with unsupervised learning, handling complex topologies and unstructured data fully automatically.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/eneqgc9agr/cover.png"/></item><item><title>GaussianMarker: Uncertainty-Aware Copyright Protection of 3D Gaussian Splatting</title><link>https://deep-diver.github.io/neurips2024/posters/wcxhbay8b3/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/wcxhbay8b3/</guid><description>GaussianMarker: A novel uncertainty-aware watermarking method ensures robust copyright protection for 3D Gaussian Splatting assets, invisibly embedding messages into model parameters and extractable &amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/wcxhbay8b3/cover.png"/></item><item><title>GeoNLF: Geometry guided Pose-Free Neural LiDAR Fields</title><link>https://deep-diver.github.io/neurips2024/posters/v3y785tn7b/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/v3y785tn7b/</guid><description>GeoNLF: Geometry-guided Pose-free Neural LiDAR Fields revolutionizes LiDAR point cloud processing by cleverly combining neural and geometric optimization for superior novel view synthesis and multi-vi&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/v3y785tn7b/cover.png"/></item><item><title>GIC: Gaussian-Informed Continuum for Physical Property Identification and Simulation</title><link>https://deep-diver.github.io/neurips2024/oral-others/ssctcq2mh2/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/oral-others/ssctcq2mh2/</guid><description>GIC: Novel hybrid framework leverages 3D Gaussian representation for accurate physical property estimation from visual observations, achieving state-of-the-art performance.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/oral-others/ssctcq2mh2/cover.png"/></item><item><title>Incorporating Test-Time Optimization into Training with Dual Networks for Human Mesh Recovery</title><link>https://deep-diver.github.io/neurips2024/posters/ugqx9tgyum/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/ugqx9tgyum/</guid><description>Meta-learning enhances human mesh recovery by unifying training and test-time objectives, significantly improving accuracy and generalization.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/ugqx9tgyum/cover.png"/></item><item><title>Large Spatial Model: End-to-end Unposed Images to Semantic 3D</title><link>https://deep-diver.github.io/neurips2024/posters/ybhpzl7eyt/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/ybhpzl7eyt/</guid><description>Large Spatial Model (LSM) achieves real-time semantic 3D reconstruction from just two unposed images, unifying multiple 3D vision tasks in a single feed-forward pass.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/ybhpzl7eyt/cover.png"/></item><item><title>Learning 3D Garment Animation from Trajectories of A Piece of Cloth</title><link>https://deep-diver.github.io/neurips2024/posters/yefx5nqmr7/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/yefx5nqmr7/</guid><description>Animates diverse garments realistically from a single cloth&amp;rsquo;s trajectory using a disentangled learning approach and Energy Unit Network (EUNet).</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/yefx5nqmr7/cover.png"/></item><item><title>LightGaussian: Unbounded 3D Gaussian Compression with 15x Reduction and 200+ FPS</title><link>https://deep-diver.github.io/neurips2024/spotlight-others/6aeidnrtn2/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-others/6aeidnrtn2/</guid><description>LightGaussian achieves 15x compression of 3D Gaussian scene representations, boosting rendering speed to 200+ FPS while maintaining visual quality, solving storage and efficiency issues in real-time n&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-others/6aeidnrtn2/cover.png"/></item><item><title>ManiPose: Manifold-Constrained Multi-Hypothesis 3D Human Pose Estimation</title><link>https://deep-diver.github.io/neurips2024/posters/xxy8d4rnsb/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/xxy8d4rnsb/</guid><description>ManiPose: Manifold-constrained multi-hypothesis model solves 3D human pose estimation&amp;rsquo;s depth ambiguity, outperforming state-of-the-art models in pose consistency.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/xxy8d4rnsb/cover.png"/></item><item><title>Memorize What Matters: Emergent Scene Decomposition from Multitraverse</title><link>https://deep-diver.github.io/neurips2024/spotlight-others/6qr3932rwe/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-others/6qr3932rwe/</guid><description>3D Gaussian Mapping (3DGM) achieves self-supervised camera-only 3D scene decomposition by leveraging multi-traverse driving data, memorizing permanent structures while filtering out transient objects.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-others/6qr3932rwe/cover.png"/></item><item><title>MeshFormer : High-Quality Mesh Generation with 3D-Guided Reconstruction Model</title><link>https://deep-diver.github.io/neurips2024/oral-others/x7pjddod6z/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/oral-others/x7pjddod6z/</guid><description>MeshFormer: High-quality 3D mesh generation from sparse views in seconds, using transformers and 3D convolutions.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/oral-others/x7pjddod6z/cover.png"/></item><item><title>Multistable Shape from Shading Emerges from Patch Diffusion</title><link>https://deep-diver.github.io/neurips2024/spotlight-others/bhsfbjs6j9/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-others/bhsfbjs6j9/</guid><description>A novel diffusion model reconstructs multimodal shape distributions from shading, mirroring human multistable perception.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-others/bhsfbjs6j9/cover.png"/></item><item><title>Neural Experts: Mixture of Experts for Implicit Neural Representations</title><link>https://deep-diver.github.io/neurips2024/posters/wwguwyhpay/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/wwguwyhpay/</guid><description>Boosting implicit neural representations, Neural Experts uses a Mixture of Experts architecture to achieve faster, more accurate, and memory-efficient signal reconstruction across various tasks.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/wwguwyhpay/cover.png"/></item><item><title>Neural Signed Distance Function Inference through Splatting 3D Gaussians Pulled on Zero-Level Set</title><link>https://deep-diver.github.io/neurips2024/posters/r6tndxikns/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/r6tndxikns/</guid><description>Neural SDF inference is revolutionized by dynamically aligning 3D Gaussians to a neural SDF&amp;rsquo;s zero-level set, enabling accurate, smooth 3D surface reconstruction.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/r6tndxikns/cover.png"/></item><item><title>One for All: Multi-Domain Joint Training for Point Cloud Based 3D Object Detection</title><link>https://deep-diver.github.io/neurips2024/posters/ndoehx1acq/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/ndoehx1acq/</guid><description>OneDet3D: A universal 3D object detector trained jointly on diverse indoor/outdoor datasets, achieving one-for-all performance across domains and categories.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/ndoehx1acq/cover.png"/></item><item><title>PCP-MAE: Learning to Predict Centers for Point Masked Autoencoders</title><link>https://deep-diver.github.io/neurips2024/spotlight-others/i1xjk5a0x8/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-others/i1xjk5a0x8/</guid><description>PCP-MAE enhances point cloud self-supervised learning by cleverly predicting masked patch centers, leading to superior 3D object classification and scene segmentation.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-others/i1xjk5a0x8/cover.png"/></item><item><title>Physically Compatible 3D Object Modeling from a Single Image</title><link>https://deep-diver.github.io/neurips2024/spotlight-others/k29iv0xrbf/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-others/k29iv0xrbf/</guid><description>Single image to physically compatible 3D objects: A new framework ensures 3D models maintain stability and mirror real-world equilibrium states, advancing realism in dynamic simulations and 3D printi&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-others/k29iv0xrbf/cover.png"/></item><item><title>ReGS: Reference-based Controllable Scene Stylization with Gaussian Splatting</title><link>https://deep-diver.github.io/neurips2024/posters/ynjr0rw6fr/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/ynjr0rw6fr/</guid><description>ReGS: Real-time reference-based 3D scene stylization using Gaussian Splatting for high-fidelity texture editing and free-view navigation.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/ynjr0rw6fr/cover.png"/></item><item><title>Rethinking 3D Convolution in $ll_p$-norm Space</title><link>https://deep-diver.github.io/neurips2024/spotlight-others/kmxdv4blhn/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-others/kmxdv4blhn/</guid><description>L1-norm based 3D convolution achieves competitive performance with lower energy consumption and latency compared to traditional methods, as proven through universal approximation theorem and experimen&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-others/kmxdv4blhn/cover.png"/></item><item><title>RobIR: Robust Inverse Rendering for High-Illumination Scenes</title><link>https://deep-diver.github.io/neurips2024/posters/y7oxy5pq4j/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/y7oxy5pq4j/</guid><description>RobIR: Robust inverse rendering in high-illumination scenes using ACES tone mapping and regularized visibility estimation for accurate BRDF reconstruction.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/y7oxy5pq4j/cover.png"/></item><item><title>SA3DIP: Segment Any 3D Instance with Potential 3D Priors</title><link>https://deep-diver.github.io/neurips2024/spotlight-others/3ui4cer4iz/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-others/3ui4cer4iz/</guid><description>SA3DIP boosts 3D instance segmentation accuracy by cleverly using 3D spatial and textural cues alongside 2D multi-view masks, overcoming limitations of previous methods.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-others/3ui4cer4iz/cover.png"/></item><item><title>Self-Distilled Depth Refinement with Noisy Poisson Fusion</title><link>https://deep-diver.github.io/neurips2024/posters/nequ0ica0s/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/nequ0ica0s/</guid><description>Self-Distilled Depth Refinement (SDDR) tackles noisy depth maps via a novel noisy Poisson fusion approach, achieving significant improvements in depth accuracy and edge quality.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/nequ0ica0s/cover.png"/></item><item><title>Sparse-view Pose Estimation and Reconstruction via Analysis by Generative Synthesis</title><link>https://deep-diver.github.io/neurips2024/posters/wgpmdyjgsg/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/wgpmdyjgsg/</guid><description>SparseAGS: High-fidelity 3D reconstruction &amp;amp; camera pose estimation from sparse views via generative synthesis.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/wgpmdyjgsg/cover.png"/></item><item><title>Template-free Articulated Gaussian Splatting for Real-time Reposable Dynamic View Synthesis</title><link>https://deep-diver.github.io/neurips2024/posters/vcgev6m5m2/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/vcgev6m5m2/</guid><description>This research introduces a template-free articulated Gaussian splatting method for real-time dynamic view synthesis, automatically discovering object skeletons from videos to enable reposing.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/vcgev6m5m2/cover.png"/></item><item><title>Tetrahedron Splatting for 3D Generation</title><link>https://deep-diver.github.io/neurips2024/spotlight-others/qvsp1uk7b5/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-others/qvsp1uk7b5/</guid><description>TeT-Splatting: a novel 3D representation enabling fast convergence, real-time rendering, and precise mesh extraction for high-fidelity 3D generation.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-others/qvsp1uk7b5/cover.png"/></item><item><title>Toward Approaches to Scalability in 3D Human Pose Estimation</title><link>https://deep-diver.github.io/neurips2024/posters/xse8qmgnym/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/xse8qmgnym/</guid><description>Boosting 3D human pose estimation: Biomechanical Pose Generator and Binary Depth Coordinates enhance accuracy and scalability.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/xse8qmgnym/cover.png"/></item><item><title>Towards Flexible 3D Perception: Object-Centric Occupancy Completion Augments 3D Object Detection</title><link>https://deep-diver.github.io/neurips2024/posters/yktqnqtepd/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/yktqnqtepd/</guid><description>Object-centric occupancy completion boosts 3D object detection accuracy by using temporal information from long sequences to precisely reconstruct object shapes, particularly for incomplete or distant&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/yktqnqtepd/cover.png"/></item><item><title>Voxel Mamba: Group-Free State Space Models for Point Cloud based 3D Object Detection</title><link>https://deep-diver.github.io/neurips2024/spotlight-others/ghyhvsctdh/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-others/ghyhvsctdh/</guid><description>Voxel Mamba: a group-free 3D object detection method using state space models, achieving higher accuracy and efficiency by overcoming limitations of serialization-based Transformers.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-others/ghyhvsctdh/cover.png"/></item><item><title>X-Ray: A Sequential 3D Representation For Generation</title><link>https://deep-diver.github.io/neurips2024/spotlight-others/36tmv15dpo/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-others/36tmv15dpo/</guid><description>X-Ray: A novel 3D representation generating complete object surfaces from a single image!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-others/36tmv15dpo/cover.png"/></item></channel></rss>