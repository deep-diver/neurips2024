<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>üè¢ UC Santa Barbara on NeurIPS 2024</title><link>https://deep-diver.github.io/neurips2024/tags/-uc-santa-barbara/</link><description>Recent content in üè¢ UC Santa Barbara on NeurIPS 2024</description><generator>Hugo -- gohugo.io</generator><language>en</language><copyright>¬© 2024 AI Paper Reviewer</copyright><lastBuildDate>Thu, 26 Sep 2024 00:00:00 +0000</lastBuildDate><atom:link href="https://deep-diver.github.io/neurips2024/tags/-uc-santa-barbara/index.xml" rel="self" type="application/rss+xml"/><item><title>Can Language Models Learn to Skip Steps?</title><link>https://deep-diver.github.io/neurips2024/posters/w4antvxao9/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/w4antvxao9/</guid><description>Language models learn to skip steps in reasoning, improving efficiency and generalization, showcasing emergent human-like cognitive abilities.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/w4antvxao9/cover.png"/></item><item><title>Global Distortions from Local Rewards: Neural Coding Strategies in Path-Integrating Neural Systems</title><link>https://deep-diver.github.io/neurips2024/posters/938eyyewtq/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/938eyyewtq/</guid><description>Reward-driven distortions in grid cell patterns are global, not local, preserving path integration while encoding environmental landmarks in spatial navigation.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/938eyyewtq/cover.png"/></item><item><title>Learning Neural Contracting Dynamics: Extended Linearization and Global Guarantees</title><link>https://deep-diver.github.io/neurips2024/posters/yynp3xpv3y/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/yynp3xpv3y/</guid><description>ELCD: The first neural network guaranteeing globally contracting dynamics!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/yynp3xpv3y/cover.png"/></item><item><title>Nonparametric Classification on Low Dimensional Manifolds using Overparameterized Convolutional Residual Networks</title><link>https://deep-diver.github.io/neurips2024/posters/guzwig7ody/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/guzwig7ody/</guid><description>Overparameterized ConvResNets surprisingly excel at prediction; this study proves they efficiently learn smooth functions on low-dimensional manifolds, avoiding the curse of dimensionality.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/guzwig7ody/cover.png"/></item><item><title>Reversing the Forget-Retain Objectives: An Efficient LLM Unlearning Framework from Logit Difference</title><link>https://deep-diver.github.io/neurips2024/posters/tydr1ltwqh/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/tydr1ltwqh/</guid><description>Reverse the forget-retain objectives for efficient LLM unlearning!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/tydr1ltwqh/cover.png"/></item><item><title>Stochastic Zeroth-Order Optimization under Strongly Convexity and Lipschitz Hessian: Minimax Sample Complexity</title><link>https://deep-diver.github.io/neurips2024/posters/jtyjwrplz5/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/jtyjwrplz5/</guid><description>Stochastic zeroth-order optimization of strongly convex functions with Lipschitz Hessian achieves optimal sample complexity, as proven by matching upper and lower bounds with a novel two-stage algorit&amp;hellip;</description></item><item><title>T2V-Turbo: Breaking the Quality Bottleneck of Video Consistency Model with Mixed Reward Feedback</title><link>https://deep-diver.github.io/neurips2024/posters/53dai9kbvf/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/53dai9kbvf/</guid><description>T2V-Turbo breaks the quality bottleneck of video consistency models by integrating mixed reward feedback during consistency distillation, enabling high-quality video generation with significantly fast&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/53dai9kbvf/cover.png"/></item></channel></rss>