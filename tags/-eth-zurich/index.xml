<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>üè¢ ETH Zurich on NeurIPS 2024</title><link>https://deep-diver.github.io/neurips2024/tags/-eth-zurich/</link><description>Recent content in üè¢ ETH Zurich on NeurIPS 2024</description><generator>Hugo -- gohugo.io</generator><language>en</language><copyright>¬© 2024 AI Paper Reviewer</copyright><lastBuildDate>Thu, 26 Sep 2024 00:00:00 +0000</lastBuildDate><atom:link href="https://deep-diver.github.io/neurips2024/tags/-eth-zurich/index.xml" rel="self" type="application/rss+xml"/><item><title>Bandits with Preference Feedback: A Stackelberg Game Perspective</title><link>https://deep-diver.github.io/neurips2024/posters/wie991zhxh/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/wie991zhxh/</guid><description>MAXMINLCB, a novel game-theoretic algorithm, efficiently solves bandit problems with preference feedback over continuous domains, providing anytime-valid, rate-optimal regret guarantees.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/wie991zhxh/cover.png"/></item><item><title>Bayes-optimal learning of an extensive-width neural network from quadratically many samples</title><link>https://deep-diver.github.io/neurips2024/posters/r8znyrjxj3/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/r8znyrjxj3/</guid><description>This study solves a key challenge in neural network learning, deriving a closed-form expression for the Bayes-optimal test error of extensive-width networks with quadratic activation functions from qu&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/r8znyrjxj3/cover.png"/></item><item><title>Beyond Concept Bottleneck Models: How to Make Black Boxes Intervenable?</title><link>https://deep-diver.github.io/neurips2024/posters/kyhma7hzjr/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/kyhma7hzjr/</guid><description>This paper presents a novel method to make black box neural networks intervenable using only a small validation set with concept labels, improving the effectiveness of concept-based interventions.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/kyhma7hzjr/cover.png"/></item><item><title>Binarized Diffusion Model for Image Super-Resolution</title><link>https://deep-diver.github.io/neurips2024/posters/yxpfrlmir2/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/yxpfrlmir2/</guid><description>BI-DiffSR, a novel binarized diffusion model, achieves high-quality image super-resolution with significantly reduced memory and computational costs, outperforming existing methods.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/yxpfrlmir2/cover.png"/></item><item><title>Can an AI Agent Safely Run a Government? Existence of Probably Approximately Aligned Policies</title><link>https://deep-diver.github.io/neurips2024/posters/xm5m7j6lbl/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/xm5m7j6lbl/</guid><description>This paper introduces a novel quantitative definition of AI alignment for social decision-making, proposing probably approximately aligned policies and a method to safeguard any autonomous agent&amp;rsquo;s act&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/xm5m7j6lbl/cover.png"/></item><item><title>Causal Effect Identification in a Sub-Population with Latent Variables</title><link>https://deep-diver.github.io/neurips2024/posters/iesyrsg6t1/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/iesyrsg6t1/</guid><description>This paper introduces a novel algorithm to accurately compute causal effects within specific sub-populations, even when hidden factors influence the data, advancing causal inference significantly.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/iesyrsg6t1/cover.png"/></item><item><title>Compositional PAC-Bayes: Generalization of GNNs with persistence and beyond</title><link>https://deep-diver.github.io/neurips2024/posters/zncjtnn3e8/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/zncjtnn3e8/</guid><description>Novel compositional PAC-Bayes framework delivers data-dependent generalization bounds for persistence-enhanced Graph Neural Networks, improving model design and performance.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/zncjtnn3e8/cover.png"/></item><item><title>Contextual Bilevel Reinforcement Learning for Incentive Alignment</title><link>https://deep-diver.github.io/neurips2024/posters/w3dx1tgw3f/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/w3dx1tgw3f/</guid><description>Contextual Bilevel Reinforcement Learning (CB-RL) tackles real-world strategic decision-making where optimal policies depend on environmental configurations and exogenous events, proposing a stochasti&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/w3dx1tgw3f/cover.png"/></item><item><title>Dynamic 3D Gaussian Fields for Urban Areas</title><link>https://deep-diver.github.io/neurips2024/spotlight-others/xzxxnhndxu/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-others/xzxxnhndxu/</guid><description>4DGF, a novel neural scene representation, achieves interactive-speed novel view synthesis for large-scale dynamic urban areas by efficiently combining 3D Gaussians and neural fields.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-others/xzxxnhndxu/cover.png"/></item><item><title>Exploiting LLM Quantization</title><link>https://deep-diver.github.io/neurips2024/posters/isa7mme7vg/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/isa7mme7vg/</guid><description>LLM quantization, while improving efficiency, creates a security risk: attackers can craft seemingly benign models that exhibit malicious behavior only when quantized.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/isa7mme7vg/cover.png"/></item><item><title>Fairness in Social Influence Maximization via Optimal Transport</title><link>https://deep-diver.github.io/neurips2024/posters/axw8xvqpkf/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/axw8xvqpkf/</guid><description>Fairness in social influence maximization is achieved via optimal transport, optimizing both outreach and a new &amp;lsquo;mutual fairness&amp;rsquo; metric that considers variability in outreach scenarios.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/axw8xvqpkf/cover.png"/></item><item><title>Implicit Regularization of Sharpness-Aware Minimization for Scale-Invariant Problems</title><link>https://deep-diver.github.io/neurips2024/posters/osovme9kl2/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/osovme9kl2/</guid><description>Boosting deep learning generalization, this work unveils SAM&amp;rsquo;s implicit regularization using &amp;lsquo;balancedness&amp;rsquo;, a new metric. A resource-efficient variant, BAR, achieves 95% computational savings with i&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/osovme9kl2/cover.png"/></item><item><title>Learning Bregman Divergences with Application to Robustness</title><link>https://deep-diver.github.io/neurips2024/posters/yuckudjae0/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/yuckudjae0/</guid><description>Learned Bregman divergences significantly improve image corruption robustness in adversarial training.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/yuckudjae0/cover.png"/></item><item><title>Learning diffusion at lightspeed</title><link>https://deep-diver.github.io/neurips2024/oral-ai-theory/y10avdrfnk/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/oral-ai-theory/y10avdrfnk/</guid><description>JKOnet* learns diffusion processes at unprecedented speed and accuracy by directly minimizing a simple quadratic loss function, bypassing complex bilevel optimization problems.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/oral-ai-theory/y10avdrfnk/cover.png"/></item><item><title>LiteVAE: Lightweight and Efficient Variational Autoencoders for Latent Diffusion Models</title><link>https://deep-diver.github.io/neurips2024/posters/mtabl8kuzq/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/mtabl8kuzq/</guid><description>LiteVAE: A new autoencoder design for latent diffusion models boosts efficiency sixfold without sacrificing image quality, achieving faster training and lower memory needs via the 2D discrete wavelet &amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/mtabl8kuzq/cover.png"/></item><item><title>MultiOOD: Scaling Out-of-Distribution Detection for Multiple Modalities</title><link>https://deep-diver.github.io/neurips2024/spotlight-others/a5pabdzp2f/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-others/a5pabdzp2f/</guid><description>MultiOOD benchmark and novel A2D &amp;amp; NP-Mix algorithms drastically improve multimodal out-of-distribution detection.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-others/a5pabdzp2f/cover.png"/></item><item><title>NeoRL: Efficient Exploration for Nonepisodic RL</title><link>https://deep-diver.github.io/neurips2024/spotlight-reinforcement-learning/zwndgc13aw/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-reinforcement-learning/zwndgc13aw/</guid><description>NEORL: Novel nonepisodic RL algorithm guarantees optimal average cost with sublinear regret for nonlinear systems!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-reinforcement-learning/zwndgc13aw/cover.png"/></item><item><title>Policy Mirror Descent with Lookahead</title><link>https://deep-diver.github.io/neurips2024/posters/om2aa0guha/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/om2aa0guha/</guid><description>Boosting reinforcement learning, this paper introduces h-PMD, a novel algorithm enhancing policy mirror descent with lookahead for faster convergence and improved sample complexity.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/om2aa0guha/cover.png"/></item><item><title>Poseidon: Efficient Foundation Models for PDEs</title><link>https://deep-diver.github.io/neurips2024/posters/jc1vkk3uxk/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/jc1vkk3uxk/</guid><description>POSEIDON: a novel foundation model for PDEs achieves significant gains in accuracy and sample efficiency, generalizing well to unseen physics.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/jc1vkk3uxk/cover.png"/></item><item><title>Private Edge Density Estimation for Random Graphs: Optimal, Efficient and Robust</title><link>https://deep-diver.github.io/neurips2024/spotlight-ai-theory/4nq24chnoi/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-ai-theory/4nq24chnoi/</guid><description>This paper delivers a groundbreaking polynomial-time algorithm for optimally estimating edge density in random graphs while ensuring node privacy and robustness against data corruption.</description></item><item><title>Recurrent neural networks: vanishing and exploding gradients are not the end of the story</title><link>https://deep-diver.github.io/neurips2024/posters/46jr4sgtwa/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/46jr4sgtwa/</guid><description>Recurrent neural networks struggle with long-term memory due to a newly identified &amp;lsquo;curse of memory&amp;rsquo;: increasing parameter sensitivity with longer memory. This work provides insights into RNN optimiza&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/46jr4sgtwa/cover.png"/></item><item><title>Safe Time-Varying Optimization based on Gaussian Processes with Spatio-Temporal Kernel</title><link>https://deep-diver.github.io/neurips2024/posters/ykvhjje9le/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/ykvhjje9le/</guid><description>TVSAFEOPT: Safe time-varying optimization using spatio-temporal kernels ensures safety while tracking time-varying reward and safety functions, providing optimality guarantees in stationary settings.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/ykvhjje9le/cover.png"/></item><item><title>SPEAR: Exact Gradient Inversion of Batches in Federated Learning</title><link>https://deep-diver.github.io/neurips2024/posters/lpdxpvs6ix/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/lpdxpvs6ix/</guid><description>SPEAR, a novel algorithm, precisely reconstructs entire data batches from gradients in federated learning, defying previous limitations and enhancing privacy risk assessment.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/lpdxpvs6ix/cover.png"/></item><item><title>Super Consistency of Neural Network Landscapes and Learning Rate Transfer</title><link>https://deep-diver.github.io/neurips2024/posters/rgwhj7intz/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/rgwhj7intz/</guid><description>Neural network hyperparameter transferability across vastly different model sizes is achieved via a newly discovered property called &amp;lsquo;Super Consistency&amp;rsquo; of loss landscapes.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/rgwhj7intz/cover.png"/></item><item><title>Transductive Active Learning: Theory and Applications</title><link>https://deep-diver.github.io/neurips2024/posters/tztepjbthg/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/tztepjbthg/</guid><description>This paper introduces transductive active learning, proving its efficiency in minimizing uncertainty and achieving state-of-the-art results in neural network fine-tuning and safe Bayesian optimization&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/tztepjbthg/cover.png"/></item><item><title>Understanding and Minimising Outlier Features in Transformer Training</title><link>https://deep-diver.github.io/neurips2024/posters/npjq6qs4bg/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/npjq6qs4bg/</guid><description>New methods minimize outlier features in transformer training, improving quantization and efficiency without sacrificing convergence speed.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/npjq6qs4bg/cover.png"/></item><item><title>Understanding the Differences in Foundation Models: Attention, State Space Models, and Recurrent Neural Networks</title><link>https://deep-diver.github.io/neurips2024/posters/if7mnxnxrw/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/if7mnxnxrw/</guid><description>Unifying framework reveals hidden connections between attention, recurrent, and state-space models, boosting foundation model efficiency.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/if7mnxnxrw/cover.png"/></item><item><title>UniBias: Unveiling and Mitigating LLM Bias through Internal Attention and FFN Manipulation</title><link>https://deep-diver.github.io/neurips2024/posters/luqivmnvix/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/luqivmnvix/</guid><description>UniBias unveils and mitigates LLM bias by identifying and eliminating biased internal components (FFN vectors and attention heads), significantly improving in-context learning performance and robustne&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/luqivmnvix/cover.png"/></item><item><title>Unity by Diversity: Improved Representation Learning for Multimodal VAEs</title><link>https://deep-diver.github.io/neurips2024/posters/z4r2rkpgby/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/z4r2rkpgby/</guid><description>MMVM VAE enhances multimodal data analysis by using a soft constraint to guide each modality&amp;rsquo;s latent representation toward a shared aggregate, improving latent representation learning and missing dat&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/z4r2rkpgby/cover.png"/></item><item><title>Weight decay induces low-rank attention layers</title><link>https://deep-diver.github.io/neurips2024/posters/odeqjim9sk/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/odeqjim9sk/</guid><description>Weight decay in deep learning surprisingly induces low-rank attention layers, potentially harming performance but offering optimization strategies for large language models.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/odeqjim9sk/cover.png"/></item></channel></rss>