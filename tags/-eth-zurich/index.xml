<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>üè¢ ETH Zurich on NeurIPS 2024</title><link>https://deep-diver.github.io/neurips2024/tags/-eth-zurich/</link><description>Recent content in üè¢ ETH Zurich on NeurIPS 2024</description><generator>Hugo -- gohugo.io</generator><language>en</language><copyright>¬© 2024 AI Paper Reviewer</copyright><lastBuildDate>Thu, 26 Sep 2024 00:00:00 +0000</lastBuildDate><atom:link href="https://deep-diver.github.io/neurips2024/tags/-eth-zurich/index.xml" rel="self" type="application/rss+xml"/><item><title>Achievable distributional robustness when the robust risk is only partially identified</title><link>https://deep-diver.github.io/neurips2024/posters/g2dyzjo4be/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/g2dyzjo4be/</guid><description>This paper introduces a novel framework for evaluating the robustness of machine learning models when the true data distribution is only partially known. It defines a new risk measure (&amp;lsquo;identifiable r&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/g2dyzjo4be/cover.png"/></item><item><title>Achieving Near-Optimal Convergence for Distributed Minimax Optimization with Adaptive Stepsizes</title><link>https://deep-diver.github.io/neurips2024/posters/o7in4nsaio/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/o7in4nsaio/</guid><description>D-AdaST: A novel distributed adaptive minimax optimization method achieves near-optimal convergence by tracking stepsizes, solving the inconsistency problem hindering existing adaptive methods.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/o7in4nsaio/cover.png"/></item><item><title>Bandits with Preference Feedback: A Stackelberg Game Perspective</title><link>https://deep-diver.github.io/neurips2024/posters/wie991zhxh/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/wie991zhxh/</guid><description>MAXMINLCB, a novel game-theoretic algorithm, efficiently solves bandit problems with preference feedback over continuous domains, providing anytime-valid, rate-optimal regret guarantees.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/wie991zhxh/cover.png"/></item><item><title>Bayes-optimal learning of an extensive-width neural network from quadratically many samples</title><link>https://deep-diver.github.io/neurips2024/posters/r8znyrjxj3/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/r8znyrjxj3/</guid><description>This study solves a key challenge in neural network learning, deriving a closed-form expression for the Bayes-optimal test error of extensive-width networks with quadratic activation functions from qu&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/r8znyrjxj3/cover.png"/></item><item><title>BetterDepth: Plug-and-Play Diffusion Refiner for Zero-Shot Monocular Depth Estimation</title><link>https://deep-diver.github.io/neurips2024/posters/35wwzhkush/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/35wwzhkush/</guid><description>BetterDepth: A plug-and-play diffusion refiner boosts zero-shot monocular depth estimation by adding fine details while preserving accurate geometry.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/35wwzhkush/cover.png"/></item><item><title>Beyond Concept Bottleneck Models: How to Make Black Boxes Intervenable?</title><link>https://deep-diver.github.io/neurips2024/posters/kyhma7hzjr/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/kyhma7hzjr/</guid><description>This paper presents a novel method to make black box neural networks intervenable using only a small validation set with concept labels, improving the effectiveness of concept-based interventions.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/kyhma7hzjr/cover.png"/></item><item><title>Binarized Diffusion Model for Image Super-Resolution</title><link>https://deep-diver.github.io/neurips2024/posters/yxpfrlmir2/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/yxpfrlmir2/</guid><description>BI-DiffSR, a novel binarized diffusion model, achieves high-quality image super-resolution with significantly reduced memory and computational costs, outperforming existing methods.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/yxpfrlmir2/cover.png"/></item><item><title>Can an AI Agent Safely Run a Government? Existence of Probably Approximately Aligned Policies</title><link>https://deep-diver.github.io/neurips2024/posters/xm5m7j6lbl/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/xm5m7j6lbl/</guid><description>This paper introduces a novel quantitative definition of AI alignment for social decision-making, proposing probably approximately aligned policies and a method to safeguard any autonomous agent&amp;rsquo;s act&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/xm5m7j6lbl/cover.png"/></item><item><title>Causal Effect Identification in a Sub-Population with Latent Variables</title><link>https://deep-diver.github.io/neurips2024/posters/iesyrsg6t1/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/iesyrsg6t1/</guid><description>This paper introduces a novel algorithm to accurately compute causal effects within specific sub-populations, even when hidden factors influence the data, advancing causal inference significantly.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/iesyrsg6t1/cover.png"/></item><item><title>Compositional PAC-Bayes: Generalization of GNNs with persistence and beyond</title><link>https://deep-diver.github.io/neurips2024/posters/zncjtnn3e8/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/zncjtnn3e8/</guid><description>Novel compositional PAC-Bayes framework delivers data-dependent generalization bounds for persistence-enhanced Graph Neural Networks, improving model design and performance.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/zncjtnn3e8/cover.png"/></item><item><title>Confidence Regulation Neurons in Language Models</title><link>https://deep-diver.github.io/neurips2024/posters/0og7nmvdbe/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/0og7nmvdbe/</guid><description>LLMs regulate uncertainty via specialized &amp;rsquo;entropy&amp;rsquo; and &amp;rsquo;token frequency&amp;rsquo; neurons, impacting prediction confidence without directly altering logits.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/0og7nmvdbe/cover.png"/></item><item><title>ConStat: Performance-Based Contamination Detection in Large Language Models</title><link>https://deep-diver.github.io/neurips2024/posters/alispmdpcq/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/alispmdpcq/</guid><description>ConStat: Exposing hidden LLM contamination!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/alispmdpcq/cover.png"/></item><item><title>Contextual Bilevel Reinforcement Learning for Incentive Alignment</title><link>https://deep-diver.github.io/neurips2024/posters/w3dx1tgw3f/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/w3dx1tgw3f/</guid><description>Contextual Bilevel Reinforcement Learning (CB-RL) tackles real-world strategic decision-making where optimal policies depend on environmental configurations and exogenous events, proposing a stochasti&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/w3dx1tgw3f/cover.png"/></item><item><title>Cooperate or Collapse: Emergence of Sustainable Cooperation in a Society of LLM Agents</title><link>https://deep-diver.github.io/neurips2024/posters/0zwzjj6lo3/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/0zwzjj6lo3/</guid><description>LLMs struggle to cooperate sustainably; GOVSIM reveals this, showing communication and &amp;lsquo;universalization&amp;rsquo; reasoning improve outcomes.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/0zwzjj6lo3/cover.png"/></item><item><title>DeltaDEQ: Exploiting Heterogeneous Convergence for Accelerating Deep Equilibrium Iterations</title><link>https://deep-diver.github.io/neurips2024/posters/7qbkadv4zd/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/7qbkadv4zd/</guid><description>DeltaDEQ accelerates deep equilibrium model inference by 73-84% via a novel &amp;lsquo;heterogeneous convergence&amp;rsquo; exploitation technique, maintaining accuracy.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/7qbkadv4zd/cover.png"/></item><item><title>Dynamic 3D Gaussian Fields for Urban Areas</title><link>https://deep-diver.github.io/neurips2024/spotlight-others/xzxxnhndxu/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-others/xzxxnhndxu/</guid><description>4DGF, a novel neural scene representation, achieves interactive-speed novel view synthesis for large-scale dynamic urban areas by efficiently combining 3D Gaussians and neural fields.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-others/xzxxnhndxu/cover.png"/></item><item><title>Exploiting LLM Quantization</title><link>https://deep-diver.github.io/neurips2024/posters/isa7mme7vg/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/isa7mme7vg/</guid><description>LLM quantization, while improving efficiency, creates a security risk: attackers can craft seemingly benign models that exhibit malicious behavior only when quantized.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/isa7mme7vg/cover.png"/></item><item><title>Fairness in Social Influence Maximization via Optimal Transport</title><link>https://deep-diver.github.io/neurips2024/posters/axw8xvqpkf/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/axw8xvqpkf/</guid><description>Fairness in social influence maximization is achieved via optimal transport, optimizing both outreach and a new &amp;lsquo;mutual fairness&amp;rsquo; metric that considers variability in outreach scenarios.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/axw8xvqpkf/cover.png"/></item><item><title>FUSE: Fast Unified Simulation and Estimation for PDEs</title><link>https://deep-diver.github.io/neurips2024/posters/dbnef790kv/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/dbnef790kv/</guid><description>FUSE, a novel framework, efficiently predicts continuous fields &amp;amp; estimates discrete parameters in PDEs, significantly improving accuracy and robustness.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/dbnef790kv/cover.png"/></item><item><title>Implicit Regularization of Sharpness-Aware Minimization for Scale-Invariant Problems</title><link>https://deep-diver.github.io/neurips2024/posters/osovme9kl2/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/osovme9kl2/</guid><description>Boosting deep learning generalization, this work unveils SAM&amp;rsquo;s implicit regularization using &amp;lsquo;balancedness&amp;rsquo;, a new metric. A resource-efficient variant, BAR, achieves 95% computational savings with i&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/osovme9kl2/cover.png"/></item><item><title>Learning Bregman Divergences with Application to Robustness</title><link>https://deep-diver.github.io/neurips2024/posters/yuckudjae0/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/yuckudjae0/</guid><description>Learned Bregman divergences significantly improve image corruption robustness in adversarial training.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/yuckudjae0/cover.png"/></item><item><title>Learning diffusion at lightspeed</title><link>https://deep-diver.github.io/neurips2024/oral-ai-theory/y10avdrfnk/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/oral-ai-theory/y10avdrfnk/</guid><description>JKOnet* learns diffusion processes at unprecedented speed and accuracy by directly minimizing a simple quadratic loss function, bypassing complex bilevel optimization problems.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/oral-ai-theory/y10avdrfnk/cover.png"/></item><item><title>LiteVAE: Lightweight and Efficient Variational Autoencoders for Latent Diffusion Models</title><link>https://deep-diver.github.io/neurips2024/posters/mtabl8kuzq/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/mtabl8kuzq/</guid><description>LiteVAE: A new autoencoder design for latent diffusion models boosts efficiency sixfold without sacrificing image quality, achieving faster training and lower memory needs via the 2D discrete wavelet &amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/mtabl8kuzq/cover.png"/></item><item><title>MultiOOD: Scaling Out-of-Distribution Detection for Multiple Modalities</title><link>https://deep-diver.github.io/neurips2024/spotlight-others/a5pabdzp2f/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-others/a5pabdzp2f/</guid><description>MultiOOD benchmark and novel A2D &amp;amp; NP-Mix algorithms drastically improve multimodal out-of-distribution detection.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-others/a5pabdzp2f/cover.png"/></item><item><title>NeoRL: Efficient Exploration for Nonepisodic RL</title><link>https://deep-diver.github.io/neurips2024/spotlight-reinforcement-learning/zwndgc13aw/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-reinforcement-learning/zwndgc13aw/</guid><description>NEORL: Novel nonepisodic RL algorithm guarantees optimal average cost with sublinear regret for nonlinear systems!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-reinforcement-learning/zwndgc13aw/cover.png"/></item><item><title>On Affine Homotopy between Language Encoders</title><link>https://deep-diver.github.io/neurips2024/posters/ftpowiawuz/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/ftpowiawuz/</guid><description>This paper introduces a novel notion of intrinsic similarity between language encoders, based on affine homotopy, and demonstrates its strong correlation with extrinsic similarity (downstream task per&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/ftpowiawuz/cover.png"/></item><item><title>Policy Mirror Descent with Lookahead</title><link>https://deep-diver.github.io/neurips2024/posters/om2aa0guha/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/om2aa0guha/</guid><description>Boosting reinforcement learning, this paper introduces h-PMD, a novel algorithm enhancing policy mirror descent with lookahead for faster convergence and improved sample complexity.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/om2aa0guha/cover.png"/></item><item><title>Poseidon: Efficient Foundation Models for PDEs</title><link>https://deep-diver.github.io/neurips2024/posters/jc1vkk3uxk/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/jc1vkk3uxk/</guid><description>POSEIDON: a novel foundation model for PDEs achieves significant gains in accuracy and sample efficiency, generalizing well to unseen physics.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/jc1vkk3uxk/cover.png"/></item><item><title>Private Edge Density Estimation for Random Graphs: Optimal, Efficient and Robust</title><link>https://deep-diver.github.io/neurips2024/spotlight-ai-theory/4nq24chnoi/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-ai-theory/4nq24chnoi/</guid><description>This paper delivers a groundbreaking polynomial-time algorithm for optimally estimating edge density in random graphs while ensuring node privacy and robustness against data corruption.</description></item><item><title>QuaRot: Outlier-Free 4-Bit Inference in Rotated LLMs</title><link>https://deep-diver.github.io/neurips2024/posters/dfqsw38v1x/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/dfqsw38v1x/</guid><description>QuaRot: Revolutionizing 4-bit LLM inference with lossless quantization via rotation!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/dfqsw38v1x/cover.png"/></item><item><title>Recurrent neural networks: vanishing and exploding gradients are not the end of the story</title><link>https://deep-diver.github.io/neurips2024/posters/46jr4sgtwa/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/46jr4sgtwa/</guid><description>Recurrent neural networks struggle with long-term memory due to a newly identified &amp;lsquo;curse of memory&amp;rsquo;: increasing parameter sensitivity with longer memory. This work provides insights into RNN optimiza&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/46jr4sgtwa/cover.png"/></item><item><title>Robust Mixture Learning when Outliers Overwhelm Small Groups</title><link>https://deep-diver.github.io/neurips2024/posters/trxv4dmdcg/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/trxv4dmdcg/</guid><description>Outlier-robust mixture learning gets order-optimal error guarantees, even when outliers massively outnumber small groups, via a novel meta-algorithm leveraging mixture structure.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/trxv4dmdcg/cover.png"/></item><item><title>Safe Time-Varying Optimization based on Gaussian Processes with Spatio-Temporal Kernel</title><link>https://deep-diver.github.io/neurips2024/posters/ykvhjje9le/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/ykvhjje9le/</guid><description>TVSAFEOPT: Safe time-varying optimization using spatio-temporal kernels ensures safety while tracking time-varying reward and safety functions, providing optimality guarantees in stationary settings.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/ykvhjje9le/cover.png"/></item><item><title>SPEAR: Exact Gradient Inversion of Batches in Federated Learning</title><link>https://deep-diver.github.io/neurips2024/posters/lpdxpvs6ix/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/lpdxpvs6ix/</guid><description>SPEAR, a novel algorithm, precisely reconstructs entire data batches from gradients in federated learning, defying previous limitations and enhancing privacy risk assessment.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/lpdxpvs6ix/cover.png"/></item><item><title>Stochastic Concept Bottleneck Models</title><link>https://deep-diver.github.io/neurips2024/posters/isjqtq5s1f/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/isjqtq5s1f/</guid><description>Stochastic Concept Bottleneck Models (SCBMs) revolutionize interpretable ML by efficiently modeling concept dependencies, drastically improving intervention effectiveness and enabling CLIP-based conce&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/isjqtq5s1f/cover.png"/></item><item><title>Super Consistency of Neural Network Landscapes and Learning Rate Transfer</title><link>https://deep-diver.github.io/neurips2024/posters/rgwhj7intz/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/rgwhj7intz/</guid><description>Neural network hyperparameter transferability across vastly different model sizes is achieved via a newly discovered property called &amp;lsquo;Super Consistency&amp;rsquo; of loss landscapes.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/rgwhj7intz/cover.png"/></item><item><title>SWT-Bench: Testing and Validating Real-World Bug-Fixes with Code Agents</title><link>https://deep-diver.github.io/neurips2024/posters/9y8zuo11eq/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/9y8zuo11eq/</guid><description>SWT-Bench, a new benchmark, reveals that LLMs excel at generating tests for real-world bug fixes, surpassing dedicated test generation systems and significantly improving code-fix precision.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/9y8zuo11eq/cover.png"/></item><item><title>Testably Learning Polynomial Threshold Functions</title><link>https://deep-diver.github.io/neurips2024/posters/5g0z6pdogj/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/5g0z6pdogj/</guid><description>Testably learning polynomial threshold functions efficiently, matching agnostic learning&amp;rsquo;s best guarantees, is achieved, solving a key problem in robust machine learning.</description></item><item><title>Transductive Active Learning: Theory and Applications</title><link>https://deep-diver.github.io/neurips2024/posters/tztepjbthg/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/tztepjbthg/</guid><description>This paper introduces transductive active learning, proving its efficiency in minimizing uncertainty and achieving state-of-the-art results in neural network fine-tuning and safe Bayesian optimization&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/tztepjbthg/cover.png"/></item><item><title>Understanding and Minimising Outlier Features in Transformer Training</title><link>https://deep-diver.github.io/neurips2024/posters/npjq6qs4bg/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/npjq6qs4bg/</guid><description>New methods minimize outlier features in transformer training, improving quantization and efficiency without sacrificing convergence speed.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/npjq6qs4bg/cover.png"/></item><item><title>Understanding the Differences in Foundation Models: Attention, State Space Models, and Recurrent Neural Networks</title><link>https://deep-diver.github.io/neurips2024/posters/if7mnxnxrw/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/if7mnxnxrw/</guid><description>Unifying framework reveals hidden connections between attention, recurrent, and state-space models, boosting foundation model efficiency.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/if7mnxnxrw/cover.png"/></item><item><title>UniBias: Unveiling and Mitigating LLM Bias through Internal Attention and FFN Manipulation</title><link>https://deep-diver.github.io/neurips2024/posters/luqivmnvix/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/luqivmnvix/</guid><description>UniBias unveils and mitigates LLM bias by identifying and eliminating biased internal components (FFN vectors and attention heads), significantly improving in-context learning performance and robustne&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/luqivmnvix/cover.png"/></item><item><title>UniSDF: Unifying Neural Representations for High-Fidelity 3D Reconstruction of Complex Scenes with Reflections</title><link>https://deep-diver.github.io/neurips2024/posters/ty25ovktqj/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/ty25ovktqj/</guid><description>UniSDF: Unifying neural representations reconstructs complex scenes with reflections, achieving state-of-the-art performance by blending camera and reflected view radiance fields.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/ty25ovktqj/cover.png"/></item><item><title>Unity by Diversity: Improved Representation Learning for Multimodal VAEs</title><link>https://deep-diver.github.io/neurips2024/posters/z4r2rkpgby/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/z4r2rkpgby/</guid><description>MMVM VAE enhances multimodal data analysis by using a soft constraint to guide each modality&amp;rsquo;s latent representation toward a shared aggregate, improving latent representation learning and missing dat&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/z4r2rkpgby/cover.png"/></item><item><title>Weight decay induces low-rank attention layers</title><link>https://deep-diver.github.io/neurips2024/posters/odeqjim9sk/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/odeqjim9sk/</guid><description>Weight decay in deep learning surprisingly induces low-rank attention layers, potentially harming performance but offering optimization strategies for large language models.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/odeqjim9sk/cover.png"/></item><item><title>When to Sense and Control? A Time-adaptive Approach for Continuous-Time RL</title><link>https://deep-diver.github.io/neurips2024/posters/0jskjdepgq/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/0jskjdepgq/</guid><description>TACOS: A novel time-adaptive RL framework drastically reduces interactions in continuous-time systems while improving performance, offering both model-free and model-based algorithms.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/0jskjdepgq/cover.png"/></item><item><title>WildGaussians: 3D Gaussian Splatting In the Wild</title><link>https://deep-diver.github.io/neurips2024/posters/nu3te3liqf/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/nu3te3liqf/</guid><description>WildGaussians enhances 3D Gaussian splatting for real-time rendering of photorealistic 3D scenes from in-the-wild images featuring occlusions and appearance changes.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/nu3te3liqf/cover.png"/></item></channel></rss>