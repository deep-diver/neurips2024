<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Question Answering on NeurIPS 2024</title><link>https://deep-diver.github.io/neurips2024/tags/question-answering/</link><description>Recent content in Question Answering on NeurIPS 2024</description><generator>Hugo -- gohugo.io</generator><language>en</language><copyright>Â© 2024 AI Paper Reviewer</copyright><lastBuildDate>Thu, 26 Sep 2024 00:00:00 +0000</lastBuildDate><atom:link href="https://deep-diver.github.io/neurips2024/tags/question-answering/index.xml" rel="self" type="application/rss+xml"/><item><title>A Gradient Accumulation Method for Dense Retriever under Memory Constraint</title><link>https://deep-diver.github.io/neurips2024/posters/qdg2q5myhv/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/qdg2q5myhv/</guid><description>CONTACCUM: Stable, efficient memory reduction for dense retrievers using dual memory banks, surpassing high-resource baselines.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/qdg2q5myhv/cover.png"/></item><item><title>A Prompt-Based Knowledge Graph Foundation Model for Universal In-Context Reasoning</title><link>https://deep-diver.github.io/neurips2024/posters/vqyb9lkmuh/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/vqyb9lkmuh/</guid><description>KG-ICL, a novel prompt-based knowledge graph foundation model, achieves universal in-context reasoning by leveraging in-context learning and a unified tokenizer, outperforming various baselines on 43 &amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/vqyb9lkmuh/cover.png"/></item><item><title>AMOR: A Recipe for Building Adaptable Modular Knowledge Agents Through Process Feedback</title><link>https://deep-diver.github.io/neurips2024/posters/jimxgqemx3/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/jimxgqemx3/</guid><description>AMOR: Adaptable Modular knowledge agent using LLMs, excels with FSM-based reasoning and process feedback, enabling human supervision and domain adaptation.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/jimxgqemx3/cover.png"/></item><item><title>Conformal Alignment: Knowing When to Trust Foundation Models with Guarantees</title><link>https://deep-diver.github.io/neurips2024/posters/yzycejlv9z/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/yzycejlv9z/</guid><description>Conformal Alignment certifies trustworthy foundation model outputs by guaranteeing a user-specified fraction meet alignment criteria, regardless of the model or data.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/yzycejlv9z/cover.png"/></item><item><title>Decompose, Analyze and Rethink: Solving Intricate Problems with Human-like Reasoning Cycle</title><link>https://deep-diver.github.io/neurips2024/oral-others/npkzf1wdjz/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/oral-others/npkzf1wdjz/</guid><description>DeAR: A novel framework lets LLMs solve complex problems with human-like iterative reasoning.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/oral-others/npkzf1wdjz/cover.png"/></item><item><title>KnowGPT: Knowledge Graph based Prompting for Large Language Models</title><link>https://deep-diver.github.io/neurips2024/posters/pacbluo5m7/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/pacbluo5m7/</guid><description>KnowGPT: A novel framework boosts Large Language Model accuracy by intelligently integrating knowledge graphs, significantly reducing factual errors and achieving near-human performance on benchmark d&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/pacbluo5m7/cover.png"/></item><item><title>LIVE: Learnable In-Context Vector for Visual Question Answering</title><link>https://deep-diver.github.io/neurips2024/posters/qhremvrzbg/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/qhremvrzbg/</guid><description>LIVE, a novel learnable in-context vector, significantly improves visual question answering by reducing computational costs and enhancing accuracy compared to traditional ICL methods.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/qhremvrzbg/cover.png"/></item><item><title>Look, Listen, and Answer: Overcoming Biases for Audio-Visual Question Answering</title><link>https://deep-diver.github.io/neurips2024/posters/twppd9umun/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/twppd9umun/</guid><description>New dataset MUSIC-AVQA-R and a multi-faceted cycle collaborative debiasing strategy significantly improve audio-visual question answering robustness.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/twppd9umun/cover.png"/></item><item><title>MDAgents: An Adaptive Collaboration of LLMs for Medical Decision-Making</title><link>https://deep-diver.github.io/neurips2024/oral-others/ekdk4vxko4/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/oral-others/ekdk4vxko4/</guid><description>MDAgents: An adaptive multi-agent LLM framework boosts medical decision-making accuracy by dynamically adjusting collaboration structures based on task complexity.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/oral-others/ekdk4vxko4/cover.png"/></item><item><title>MediQ: Question-Asking LLMs and a Benchmark for Reliable Interactive Clinical Reasoning</title><link>https://deep-diver.github.io/neurips2024/posters/w4pibq7bai/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/w4pibq7bai/</guid><description>MEDIQ benchmark revolutionizes LLM evaluation by shifting from static to interactive clinical reasoning, revealing LLMs&amp;rsquo; struggles with proactive information-seeking and highlighting the importance of&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/w4pibq7bai/cover.png"/></item><item><title>RankRAG: Unifying Context Ranking with Retrieval-Augmented Generation in LLMs</title><link>https://deep-diver.github.io/neurips2024/posters/s1fc92uemc/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/s1fc92uemc/</guid><description>RankRAG: One LLM, dual-purpose instruction-tuning for superior RAG!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/s1fc92uemc/cover.png"/></item><item><title>RG-SAN: Rule-Guided Spatial Awareness Network for End-to-End 3D Referring Expression Segmentation</title><link>https://deep-diver.github.io/neurips2024/oral-others/r5spnry6h3/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/oral-others/r5spnry6h3/</guid><description>RG-SAN achieves state-of-the-art 3D referring expression segmentation by leveraging spatial awareness and rule-guided weak supervision, significantly improving accuracy and handling of ambiguous descr&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/oral-others/r5spnry6h3/cover.png"/></item><item><title>SpikedAttention: Training-Free and Fully Spike-Driven Transformer-to-SNN Conversion with Winner-Oriented Spike Shift for Softmax Operation</title><link>https://deep-diver.github.io/neurips2024/posters/fs28jccjj5/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/fs28jccjj5/</guid><description>SpikedAttention: Training-free transformer-to-SNN conversion achieving state-of-the-art accuracy and 42% energy reduction!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/fs28jccjj5/cover.png"/></item></channel></rss>