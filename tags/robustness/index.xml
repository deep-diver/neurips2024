<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Robustness on NeurIPS 2024</title><link>https://deep-diver.github.io/neurips2024/tags/robustness/</link><description>Recent content in Robustness on NeurIPS 2024</description><generator>Hugo -- gohugo.io</generator><language>en</language><copyright>© 2024 AI Paper Reviewer</copyright><lastBuildDate>Thu, 26 Sep 2024 00:00:00 +0000</lastBuildDate><atom:link href="https://deep-diver.github.io/neurips2024/tags/robustness/index.xml" rel="self" type="application/rss+xml"/><item><title>Achieving Domain-Independent Certified Robustness via Knowledge Continuity</title><link>https://deep-diver.github.io/neurips2024/posters/v07krlyxdx/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/v07krlyxdx/</guid><description>Certifying neural network robustness across diverse domains, this paper introduces knowledge continuity—a novel framework ensuring model stability independent of input type, norms, and distribution.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/v07krlyxdx/cover.png"/></item><item><title>Adversarially Robust Decision Transformer</title><link>https://deep-diver.github.io/neurips2024/posters/wef2lt8nty/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/wef2lt8nty/</guid><description>Adversarially Robust Decision Transformer (ARDT) enhances offline RL robustness against powerful adversaries by conditioning policies on minimax returns, achieving superior worst-case performance.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/wef2lt8nty/cover.png"/></item><item><title>CausalDiff: Causality-Inspired Disentanglement via Diffusion Model for Adversarial Defense</title><link>https://deep-diver.github.io/neurips2024/posters/bzldxbjb8o/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/bzldxbjb8o/</guid><description>CausalDiff leverages causal inference and diffusion models to create a robust AI defense against unseen adversarial attacks, significantly outperforming state-of-the-art methods.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/bzldxbjb8o/cover.png"/></item><item><title>Certified Robustness for Deep Equilibrium Models via Serialized Random Smoothing</title><link>https://deep-diver.github.io/neurips2024/posters/x64ijvdftr/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/x64ijvdftr/</guid><description>Accelerate DEQ certification up to 7x with Serialized Random Smoothing (SRS), achieving certified robustness on large-scale datasets without sacrificing accuracy.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/x64ijvdftr/cover.png"/></item><item><title>Constrained Adaptive Attack: Effective Adversarial Attack Against Deep Neural Networks for Tabular Data</title><link>https://deep-diver.github.io/neurips2024/spotlight-ai-theory/zttwkr51yh/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-ai-theory/zttwkr51yh/</guid><description>Constrained Adaptive Attack (CAA) significantly improves adversarial attacks on deep learning models for tabular data by combining gradient and search-based methods, achieving up to 96.1% accuracy dro&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-ai-theory/zttwkr51yh/cover.png"/></item><item><title>Corruption-Robust Linear Bandits: Minimax Optimality and Gap-Dependent Misspecification</title><link>https://deep-diver.github.io/neurips2024/posters/wqs2rmq4cw/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/wqs2rmq4cw/</guid><description>This paper presents novel algorithms for linear bandits that are robust to corrupted rewards, achieving minimax optimality and optimal scaling for gap-dependent misspecification, extending to reinforc&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/wqs2rmq4cw/cover.png"/></item><item><title>Detecting Brittle Decisions for Free: Leveraging Margin Consistency in Deep Robust Classifiers</title><link>https://deep-diver.github.io/neurips2024/posters/xhcyznmqnv/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/xhcyznmqnv/</guid><description>Deep learning models&amp;rsquo; robustness can be efficiently evaluated using a novel method, margin consistency, which leverages the correlation between input and logit margins for faster, accurate vulnerabili&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/xhcyznmqnv/cover.png"/></item><item><title>DiffHammer: Rethinking the Robustness of Diffusion-Based Adversarial Purification</title><link>https://deep-diver.github.io/neurips2024/posters/zj2onmsgcs/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/zj2onmsgcs/</guid><description>DiffHammer unveils weaknesses in diffusion-based adversarial defenses by introducing a novel attack bypassing existing evaluation limitations, leading to more robust security solutions.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/zj2onmsgcs/cover.png"/></item><item><title>Diffusion Models are Certifiably Robust Classifiers</title><link>https://deep-diver.github.io/neurips2024/posters/wgp1tbcp1e/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/wgp1tbcp1e/</guid><description>Diffusion models are certifiably robust classifiers due to their inherent O(1) Lipschitzness, a property further enhanced by generalizing to noisy data, achieving over 80% certified robustness on CIFA&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/wgp1tbcp1e/cover.png"/></item><item><title>ECLipsE: Efficient Compositional Lipschitz Constant Estimation for Deep Neural Networks</title><link>https://deep-diver.github.io/neurips2024/spotlight-ai-theory/61yysy078z/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-ai-theory/61yysy078z/</guid><description>ECLipsE: A novel compositional approach drastically accelerates Lipschitz constant estimation for deep neural networks, achieving speedups of thousands of times compared to the state-of-the-art while &amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-ai-theory/61yysy078z/cover.png"/></item><item><title>Energy-based Epistemic Uncertainty for Graph Neural Networks</title><link>https://deep-diver.github.io/neurips2024/spotlight-ai-theory/6vnpptwh1q/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-ai-theory/6vnpptwh1q/</guid><description>GEBM: a novel graph-based energy model for robust GNN uncertainty estimation.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-ai-theory/6vnpptwh1q/cover.png"/></item><item><title>Enhancing Robustness of Graph Neural Networks on Social Media with Explainable Inverse Reinforcement Learning</title><link>https://deep-diver.github.io/neurips2024/spotlight-ai-theory/zieha15y8k/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-ai-theory/zieha15y8k/</guid><description>MoE-BiEntIRL: A novel explainable inverse reinforcement learning method enhances GNN robustness against diverse social media attacks by reconstructing attacker policies and generating more robust trai&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-ai-theory/zieha15y8k/cover.png"/></item><item><title>Exploring Adversarial Robustness of Deep State Space Models</title><link>https://deep-diver.github.io/neurips2024/posters/rsb32ebmbj/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/rsb32ebmbj/</guid><description>Deep state space models (SSMs) gain adversarial robustness through an adaptive scaling mechanism, improving performance without overfitting issues.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/rsb32ebmbj/cover.png"/></item><item><title>GREAT Score: Global Robustness Evaluation of Adversarial Perturbation using Generative Models</title><link>https://deep-diver.github.io/neurips2024/posters/vunjcq9pwu/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/vunjcq9pwu/</guid><description>GREAT Score: A novel framework using generative models for efficiently and accurately evaluating the global robustness of machine learning models against adversarial attacks.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/vunjcq9pwu/cover.png"/></item><item><title>If You Want to Be Robust, Be Wary of Initialization</title><link>https://deep-diver.github.io/neurips2024/posters/nxumywxjpb/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/nxumywxjpb/</guid><description>Proper weight initialization significantly boosts Graph Neural Network (GNN) and Deep Neural Network (DNN) robustness against adversarial attacks, highlighting a critical, often-overlooked factor.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/nxumywxjpb/cover.png"/></item><item><title>Improving Subgroup Robustness via Data Selection</title><link>https://deep-diver.github.io/neurips2024/posters/vjltccbzvt/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/vjltccbzvt/</guid><description>Data Debiasing with Datamodels (D3M) efficiently improves machine learning model robustness by identifying and removing specific training examples that disproportionately harm minority groups&amp;rsquo; accurac&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/vjltccbzvt/cover.png"/></item><item><title>Injecting Undetectable Backdoors in Obfuscated Neural Networks and Language Models</title><link>https://deep-diver.github.io/neurips2024/posters/kyvbzkcono/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/kyvbzkcono/</guid><description>Researchers developed a novel method to inject undetectable backdoors into obfuscated neural networks and language models, even with white-box access, posing significant security risks.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/kyvbzkcono/cover.png"/></item><item><title>Intruding with Words: Towards Understanding Graph Injection Attacks at the Text Level</title><link>https://deep-diver.github.io/neurips2024/posters/otzydukwpq/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/otzydukwpq/</guid><description>Researchers unveil text-level graph injection attacks, revealing a new vulnerability in GNNs and highlighting the importance of text interpretability in attack success.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/otzydukwpq/cover.png"/></item><item><title>Is O(log N) practical? Near-Equivalence Between Delay Robustness and Bounded Regret in Bandits and RL</title><link>https://deep-diver.github.io/neurips2024/posters/hyjofwfw1p/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/hyjofwfw1p/</guid><description>Zero Graves-Lai constant ensures both bounded regret and delay robustness in online decision-making, particularly for linear models.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/hyjofwfw1p/cover.png"/></item><item><title>Learning a Single Neuron Robustly to Distributional Shifts and Adversarial Label Noise</title><link>https://deep-diver.github.io/neurips2024/posters/rv5dug4jcz/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/rv5dug4jcz/</guid><description>This work presents a computationally efficient algorithm that robustly learns a single neuron despite adversarial label noise and distributional shifts, providing provable approximation guarantees.</description></item><item><title>Learning from Uncertain Data: From Possible Worlds to Possible Models</title><link>https://deep-diver.github.io/neurips2024/posters/v9rqrfslq2/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/v9rqrfslq2/</guid><description>ZORRO: A new method for learning linear models from uncertain data, providing sound over-approximations of all possible models and prediction ranges.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/v9rqrfslq2/cover.png"/></item><item><title>Learning Neural Contracting Dynamics: Extended Linearization and Global Guarantees</title><link>https://deep-diver.github.io/neurips2024/posters/yynp3xpv3y/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/yynp3xpv3y/</guid><description>ELCD: The first neural network guaranteeing globally contracting dynamics!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/yynp3xpv3y/cover.png"/></item><item><title>MAC Advice for facility location mechanism design</title><link>https://deep-diver.github.io/neurips2024/posters/lpbqzszt8y/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/lpbqzszt8y/</guid><description>Improved facility location mechanisms are designed using &amp;lsquo;Mostly Approximately Correct&amp;rsquo; predictions, exceeding prior bounds despite large prediction errors.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/lpbqzszt8y/cover.png"/></item><item><title>MALT Powers Up Adversarial Attacks</title><link>https://deep-diver.github.io/neurips2024/posters/bcqix5q8qx/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/bcqix5q8qx/</guid><description>MALT: a novel adversarial attack, is 5x faster than AutoAttack, achieving higher success rates on CIFAR-100 and ImageNet by exploiting mesoscopic almost linearity in neural networks.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/bcqix5q8qx/cover.png"/></item><item><title>On the Robustness of Spectral Algorithms for Semirandom Stochastic Block Models</title><link>https://deep-diver.github.io/neurips2024/posters/klen1xyw6p/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/klen1xyw6p/</guid><description>Spectral algorithms for graph bisection show surprising robustness to helpful adversaries in semirandom models, with unnormalized Laplacian consistently outperforming the normalized one.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/klen1xyw6p/cover.png"/></item><item><title>Provable Editing of Deep Neural Networks using Parametric Linear Relaxation</title><link>https://deep-diver.github.io/neurips2024/posters/ighpud496d/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/ighpud496d/</guid><description>PREPARED efficiently edits DNNs to provably satisfy properties by relaxing the problem to a linear program, minimizing parameter changes.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/ighpud496d/cover.png"/></item><item><title>Relational Verification Leaps Forward with RABBit</title><link>https://deep-diver.github.io/neurips2024/posters/w5u3xb1c11/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/w5u3xb1c11/</guid><description>RABBit: A novel Branch-and-Bound verifier for precise relational verification of Deep Neural Networks, achieving substantial precision gains over current state-of-the-art baselines.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/w5u3xb1c11/cover.png"/></item><item><title>Rethinking Weight Decay for Robust Fine-Tuning of Foundation Models</title><link>https://deep-diver.github.io/neurips2024/posters/4neqdbz8eg/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/4neqdbz8eg/</guid><description>Selective Projection Decay (SPD) enhances robust fine-tuning of foundation models by selectively applying weight decay, improving generalization and out-of-distribution robustness.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/4neqdbz8eg/cover.png"/></item><item><title>Robust Gaussian Processes via Relevance Pursuit</title><link>https://deep-diver.github.io/neurips2024/posters/5fatpilwuj/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/5fatpilwuj/</guid><description>Robust Gaussian Processes via Relevance Pursuit tackles noisy data by cleverly inferring data-point specific noise levels, leading to more accurate predictions.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/5fatpilwuj/cover.png"/></item><item><title>Robust Graph Neural Networks via Unbiased Aggregation</title><link>https://deep-diver.github.io/neurips2024/posters/dz6ex9ee0q/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/dz6ex9ee0q/</guid><description>RUNG: a novel GNN architecture boasting superior robustness against adaptive attacks by employing an unbiased aggregation technique.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/dz6ex9ee0q/cover.png"/></item><item><title>Robust Sparse Regression with Non-Isotropic Designs</title><link>https://deep-diver.github.io/neurips2024/posters/ybsvnfd21c/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/ybsvnfd21c/</guid><description>New algorithms achieve near-optimal error rates for sparse linear regression, even under adversarial data corruption and heavy-tailed noise distributions.</description></item><item><title>Score-based generative models are provably robust: an uncertainty quantification perspective</title><link>https://deep-diver.github.io/neurips2024/posters/ki5tane02e/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/ki5tane02e/</guid><description>Score-based generative models are provably robust to multiple error sources, as shown via a novel Wasserstein uncertainty propagation theorem.</description></item><item><title>Statistical Multicriteria Benchmarking via the GSD-Front</title><link>https://deep-diver.github.io/neurips2024/spotlight-ai-theory/jxxvskb9hd/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-ai-theory/jxxvskb9hd/</guid><description>Researchers can now reliably benchmark classifiers using multiple quality metrics via the GSD-front, a new information-efficient technique that accounts for statistical uncertainty and deviations from&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-ai-theory/jxxvskb9hd/cover.png"/></item><item><title>The Implicit Bias of Gradient Descent toward Collaboration between Layers: A Dynamic Analysis of Multilayer Perceptions</title><link>https://deep-diver.github.io/neurips2024/posters/jv6z08u7y0/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/jv6z08u7y0/</guid><description>Deep learning models&amp;rsquo; success hinges on understanding gradient descent&amp;rsquo;s implicit bias. This study reveals how this bias influences layer collaboration, revealing a decreasing trend in adversarial rob&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/jv6z08u7y0/cover.png"/></item><item><title>Treatment of Statistical Estimation Problems in Randomized Smoothing for Adversarial Robustness</title><link>https://deep-diver.github.io/neurips2024/posters/s4wx2qxhv9/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/s4wx2qxhv9/</guid><description>This paper optimizes randomized smoothing, a crucial certified defense against adversarial attacks, by introducing novel statistical methods that drastically reduce the computational cost, leading to &amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/s4wx2qxhv9/cover.png"/></item><item><title>Unveiling the Hidden Structure of Self-Attention via Kernel Principal Component Analysis</title><link>https://deep-diver.github.io/neurips2024/posters/vuwvvvni6r/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/vuwvvvni6r/</guid><description>Self-attention, a key component of transformers, is revealed to be a projection of query vectors onto the principal components of the key matrix, derived from kernel PCA. This novel perspective leads&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/vuwvvvni6r/cover.png"/></item></channel></rss>