<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Robustness on NeurIPS 2024</title><link>https://deep-diver.github.io/neurips2024/tags/robustness/</link><description>Recent content in Robustness on NeurIPS 2024</description><generator>Hugo -- gohugo.io</generator><language>en</language><copyright>© 2024 AI Paper Reviewer</copyright><lastBuildDate>Thu, 26 Sep 2024 00:00:00 +0000</lastBuildDate><atom:link href="https://deep-diver.github.io/neurips2024/tags/robustness/index.xml" rel="self" type="application/rss+xml"/><item><title>Achievable distributional robustness when the robust risk is only partially identified</title><link>https://deep-diver.github.io/neurips2024/posters/g2dyzjo4be/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/g2dyzjo4be/</guid><description>This paper introduces a novel framework for evaluating the robustness of machine learning models when the true data distribution is only partially known. It defines a new risk measure (&amp;lsquo;identifiable r&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/g2dyzjo4be/cover.png"/></item><item><title>Achieving Domain-Independent Certified Robustness via Knowledge Continuity</title><link>https://deep-diver.github.io/neurips2024/posters/v07krlyxdx/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/v07krlyxdx/</guid><description>Certifying neural network robustness across diverse domains, this paper introduces knowledge continuity—a novel framework ensuring model stability independent of input type, norms, and distribution.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/v07krlyxdx/cover.png"/></item><item><title>Adversarially Robust Decision Transformer</title><link>https://deep-diver.github.io/neurips2024/posters/wef2lt8nty/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/wef2lt8nty/</guid><description>Adversarially Robust Decision Transformer (ARDT) enhances offline RL robustness against powerful adversaries by conditioning policies on minimax returns, achieving superior worst-case performance.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/wef2lt8nty/cover.png"/></item><item><title>Adversarially Robust Dense-Sparse Tradeoffs via Heavy-Hitters</title><link>https://deep-diver.github.io/neurips2024/posters/mpidscd9e7/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/mpidscd9e7/</guid><description>Improved adversarially robust streaming algorithms for L_p estimation are presented, surpassing previous state-of-the-art space bounds and disproving the existence of inherent barriers.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/mpidscd9e7/cover.png"/></item><item><title>CausalDiff: Causality-Inspired Disentanglement via Diffusion Model for Adversarial Defense</title><link>https://deep-diver.github.io/neurips2024/posters/bzldxbjb8o/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/bzldxbjb8o/</guid><description>CausalDiff leverages causal inference and diffusion models to create a robust AI defense against unseen adversarial attacks, significantly outperforming state-of-the-art methods.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/bzldxbjb8o/cover.png"/></item><item><title>Certified Robustness for Deep Equilibrium Models via Serialized Random Smoothing</title><link>https://deep-diver.github.io/neurips2024/posters/x64ijvdftr/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/x64ijvdftr/</guid><description>Accelerate DEQ certification up to 7x with Serialized Random Smoothing (SRS), achieving certified robustness on large-scale datasets without sacrificing accuracy.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/x64ijvdftr/cover.png"/></item><item><title>Computational Aspects of Bayesian Persuasion under Approximate Best Response</title><link>https://deep-diver.github.io/neurips2024/posters/9b0iokn3up/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/9b0iokn3up/</guid><description>This paper presents efficient algorithms for Bayesian persuasion under approximate best response, offering polynomial-time solutions for specific cases and a quasi-polynomial-time approximation scheme&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/9b0iokn3up/cover.png"/></item><item><title>Constrained Adaptive Attack: Effective Adversarial Attack Against Deep Neural Networks for Tabular Data</title><link>https://deep-diver.github.io/neurips2024/spotlight-ai-theory/zttwkr51yh/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-ai-theory/zttwkr51yh/</guid><description>Constrained Adaptive Attack (CAA) significantly improves adversarial attacks on deep learning models for tabular data by combining gradient and search-based methods, achieving up to 96.1% accuracy dro&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-ai-theory/zttwkr51yh/cover.png"/></item><item><title>Corruption-Robust Linear Bandits: Minimax Optimality and Gap-Dependent Misspecification</title><link>https://deep-diver.github.io/neurips2024/posters/wqs2rmq4cw/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/wqs2rmq4cw/</guid><description>This paper presents novel algorithms for linear bandits that are robust to corrupted rewards, achieving minimax optimality and optimal scaling for gap-dependent misspecification, extending to reinforc&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/wqs2rmq4cw/cover.png"/></item><item><title>DAT: Improving Adversarial Robustness via Generative Amplitude Mix-up in Frequency Domain</title><link>https://deep-diver.github.io/neurips2024/posters/teqvz5ali8/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/teqvz5ali8/</guid><description>Boost AI model robustness against adversarial attacks by creatively mixing training sample&amp;rsquo;s frequency amplitude with distractor images, focusing model learning on phase patterns, thus enhancing accur&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/teqvz5ali8/cover.png"/></item><item><title>Detecting Brittle Decisions for Free: Leveraging Margin Consistency in Deep Robust Classifiers</title><link>https://deep-diver.github.io/neurips2024/posters/xhcyznmqnv/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/xhcyznmqnv/</guid><description>Deep learning models&amp;rsquo; robustness can be efficiently evaluated using a novel method, margin consistency, which leverages the correlation between input and logit margins for faster, accurate vulnerabili&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/xhcyznmqnv/cover.png"/></item><item><title>DiffHammer: Rethinking the Robustness of Diffusion-Based Adversarial Purification</title><link>https://deep-diver.github.io/neurips2024/posters/zj2onmsgcs/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/zj2onmsgcs/</guid><description>DiffHammer unveils weaknesses in diffusion-based adversarial defenses by introducing a novel attack bypassing existing evaluation limitations, leading to more robust security solutions.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/zj2onmsgcs/cover.png"/></item><item><title>Diffusion Models are Certifiably Robust Classifiers</title><link>https://deep-diver.github.io/neurips2024/posters/wgp1tbcp1e/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/wgp1tbcp1e/</guid><description>Diffusion models are certifiably robust classifiers due to their inherent O(1) Lipschitzness, a property further enhanced by generalizing to noisy data, achieving over 80% certified robustness on CIFA&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/wgp1tbcp1e/cover.png"/></item><item><title>Diversity Is Not All You Need: Training A Robust Cooperative Agent Needs Specialist Partners</title><link>https://deep-diver.github.io/neurips2024/posters/15460jjoco/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/15460jjoco/</guid><description>Training robust cooperative AI agents requires diverse and specialized training partners, but existing methods often produce overfit partners. This paper proposes novel methods using reinforcement and&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/15460jjoco/cover.png"/></item><item><title>ECLipsE: Efficient Compositional Lipschitz Constant Estimation for Deep Neural Networks</title><link>https://deep-diver.github.io/neurips2024/spotlight-ai-theory/61yysy078z/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-ai-theory/61yysy078z/</guid><description>ECLipsE: A novel compositional approach drastically accelerates Lipschitz constant estimation for deep neural networks, achieving speedups of thousands of times compared to the state-of-the-art while &amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-ai-theory/61yysy078z/cover.png"/></item><item><title>Elliptical Attention</title><link>https://deep-diver.github.io/neurips2024/posters/ejg4d4fvrs/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/ejg4d4fvrs/</guid><description>Elliptical Attention enhances transformers by using a Mahalanobis distance metric, stretching the feature space to focus on contextually relevant information, thus improving robustness and reducing re&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/ejg4d4fvrs/cover.png"/></item><item><title>Energy-based Epistemic Uncertainty for Graph Neural Networks</title><link>https://deep-diver.github.io/neurips2024/spotlight-ai-theory/6vnpptwh1q/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-ai-theory/6vnpptwh1q/</guid><description>GEBM: a novel graph-based energy model for robust GNN uncertainty estimation.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-ai-theory/6vnpptwh1q/cover.png"/></item><item><title>Enhancing Robustness of Graph Neural Networks on Social Media with Explainable Inverse Reinforcement Learning</title><link>https://deep-diver.github.io/neurips2024/spotlight-ai-theory/zieha15y8k/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-ai-theory/zieha15y8k/</guid><description>MoE-BiEntIRL: A novel explainable inverse reinforcement learning method enhances GNN robustness against diverse social media attacks by reconstructing attacker policies and generating more robust trai&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-ai-theory/zieha15y8k/cover.png"/></item><item><title>Exploring Adversarial Robustness of Deep State Space Models</title><link>https://deep-diver.github.io/neurips2024/posters/rsb32ebmbj/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/rsb32ebmbj/</guid><description>Deep state space models (SSMs) gain adversarial robustness through an adaptive scaling mechanism, improving performance without overfitting issues.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/rsb32ebmbj/cover.png"/></item><item><title>Faster Repeated Evasion Attacks in Tree Ensembles</title><link>https://deep-diver.github.io/neurips2024/posters/ugr0ypzy71/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/ugr0ypzy71/</guid><description>Speed up repeated evasion attacks on tree ensembles by 36x using feature perturbation insights!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/ugr0ypzy71/cover.png"/></item><item><title>FEEL-SNN: Robust Spiking Neural Networks with Frequency Encoding and Evolutionary Leak Factor</title><link>https://deep-diver.github.io/neurips2024/posters/tucqdbo4nc/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/tucqdbo4nc/</guid><description>FEEL-SNN enhances spiking neural network robustness by mimicking biological visual attention and adaptive leak factors, resulting in improved resilience against noise and attacks.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/tucqdbo4nc/cover.png"/></item><item><title>GREAT Score: Global Robustness Evaluation of Adversarial Perturbation using Generative Models</title><link>https://deep-diver.github.io/neurips2024/posters/vunjcq9pwu/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/vunjcq9pwu/</guid><description>GREAT Score: A novel framework using generative models for efficiently and accurately evaluating the global robustness of machine learning models against adversarial attacks.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/vunjcq9pwu/cover.png"/></item><item><title>If You Want to Be Robust, Be Wary of Initialization</title><link>https://deep-diver.github.io/neurips2024/posters/nxumywxjpb/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/nxumywxjpb/</guid><description>Proper weight initialization significantly boosts Graph Neural Network (GNN) and Deep Neural Network (DNN) robustness against adversarial attacks, highlighting a critical, often-overlooked factor.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/nxumywxjpb/cover.png"/></item><item><title>Improving Adversarial Robust Fairness via Anti-Bias Soft Label Distillation</title><link>https://deep-diver.github.io/neurips2024/posters/kw30lbnwdv/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/kw30lbnwdv/</guid><description>Boosting adversarial robustness fairness in deep neural networks, Anti-Bias Soft Label Distillation (ABSLD) adaptively adjusts soft label smoothness to reduce error gap between classes.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/kw30lbnwdv/cover.png"/></item><item><title>Improving Subgroup Robustness via Data Selection</title><link>https://deep-diver.github.io/neurips2024/posters/vjltccbzvt/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/vjltccbzvt/</guid><description>Data Debiasing with Datamodels (D3M) efficiently improves machine learning model robustness by identifying and removing specific training examples that disproportionately harm minority groups&amp;rsquo; accurac&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/vjltccbzvt/cover.png"/></item><item><title>Injecting Undetectable Backdoors in Obfuscated Neural Networks and Language Models</title><link>https://deep-diver.github.io/neurips2024/posters/kyvbzkcono/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/kyvbzkcono/</guid><description>Researchers developed a novel method to inject undetectable backdoors into obfuscated neural networks and language models, even with white-box access, posing significant security risks.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/kyvbzkcono/cover.png"/></item><item><title>Intrinsic Robustness of Prophet Inequality to Strategic Reward Signaling</title><link>https://deep-diver.github.io/neurips2024/posters/mmcy1p15hc/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/mmcy1p15hc/</guid><description>Strategic players can manipulate reward signals, but simple threshold policies still achieve a surprisingly good approximation to the optimal prophet value, even in this more realistic setting.</description></item><item><title>Intruding with Words: Towards Understanding Graph Injection Attacks at the Text Level</title><link>https://deep-diver.github.io/neurips2024/posters/otzydukwpq/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/otzydukwpq/</guid><description>Researchers unveil text-level graph injection attacks, revealing a new vulnerability in GNNs and highlighting the importance of text interpretability in attack success.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/otzydukwpq/cover.png"/></item><item><title>Is O(log N) practical? Near-Equivalence Between Delay Robustness and Bounded Regret in Bandits and RL</title><link>https://deep-diver.github.io/neurips2024/posters/hyjofwfw1p/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/hyjofwfw1p/</guid><description>Zero Graves-Lai constant ensures both bounded regret and delay robustness in online decision-making, particularly for linear models.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/hyjofwfw1p/cover.png"/></item><item><title>Learning a Single Neuron Robustly to Distributional Shifts and Adversarial Label Noise</title><link>https://deep-diver.github.io/neurips2024/posters/rv5dug4jcz/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/rv5dug4jcz/</guid><description>This work presents a computationally efficient algorithm that robustly learns a single neuron despite adversarial label noise and distributional shifts, providing provable approximation guarantees.</description></item><item><title>Learning from Uncertain Data: From Possible Worlds to Possible Models</title><link>https://deep-diver.github.io/neurips2024/posters/v9rqrfslq2/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/v9rqrfslq2/</guid><description>ZORRO: A new method for learning linear models from uncertain data, providing sound over-approximations of all possible models and prediction ranges.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/v9rqrfslq2/cover.png"/></item><item><title>Learning Neural Contracting Dynamics: Extended Linearization and Global Guarantees</title><link>https://deep-diver.github.io/neurips2024/posters/yynp3xpv3y/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/yynp3xpv3y/</guid><description>ELCD: The first neural network guaranteeing globally contracting dynamics!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/yynp3xpv3y/cover.png"/></item><item><title>MAC Advice for facility location mechanism design</title><link>https://deep-diver.github.io/neurips2024/posters/lpbqzszt8y/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/lpbqzszt8y/</guid><description>Improved facility location mechanisms are designed using &amp;lsquo;Mostly Approximately Correct&amp;rsquo; predictions, exceeding prior bounds despite large prediction errors.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/lpbqzszt8y/cover.png"/></item><item><title>MALT Powers Up Adversarial Attacks</title><link>https://deep-diver.github.io/neurips2024/posters/bcqix5q8qx/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/bcqix5q8qx/</guid><description>MALT: a novel adversarial attack, is 5x faster than AutoAttack, achieving higher success rates on CIFAR-100 and ImageNet by exploiting mesoscopic almost linearity in neural networks.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/bcqix5q8qx/cover.png"/></item><item><title>On the Adversarial Robustness of Benjamini Hochberg</title><link>https://deep-diver.github.io/neurips2024/posters/5jyfoldunm/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/5jyfoldunm/</guid><description>Even a few data changes can break the Benjamini-Hochberg (BH) procedure, a widely used multiple testing method, highlighting a critical vulnerability.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/5jyfoldunm/cover.png"/></item><item><title>On the Robustness of Spectral Algorithms for Semirandom Stochastic Block Models</title><link>https://deep-diver.github.io/neurips2024/posters/klen1xyw6p/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/klen1xyw6p/</guid><description>Spectral algorithms for graph bisection show surprising robustness to helpful adversaries in semirandom models, with unnormalized Laplacian consistently outperforming the normalized one.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/klen1xyw6p/cover.png"/></item><item><title>Optimal Classification under Performative Distribution Shift</title><link>https://deep-diver.github.io/neurips2024/posters/3j5hvo5uaw/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/3j5hvo5uaw/</guid><description>This paper introduces a novel push-forward model for performative learning, proving the convexity of performative risk under new assumptions and linking performative learning to adversarial robustness&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/3j5hvo5uaw/cover.png"/></item><item><title>ProTransformer: Robustify Transformers via Plug-and-Play Paradigm</title><link>https://deep-diver.github.io/neurips2024/posters/ukauurtbxx/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/ukauurtbxx/</guid><description>ProTransformer robustifies transformers with a novel plug-and-play attention mechanism, significantly improving robustness across various tasks and domains without retraining.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/ukauurtbxx/cover.png"/></item><item><title>Provable Editing of Deep Neural Networks using Parametric Linear Relaxation</title><link>https://deep-diver.github.io/neurips2024/posters/ighpud496d/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/ighpud496d/</guid><description>PREPARED efficiently edits DNNs to provably satisfy properties by relaxing the problem to a linear program, minimizing parameter changes.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/ighpud496d/cover.png"/></item><item><title>Relational Verification Leaps Forward with RABBit</title><link>https://deep-diver.github.io/neurips2024/posters/w5u3xb1c11/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/w5u3xb1c11/</guid><description>RABBit: A novel Branch-and-Bound verifier for precise relational verification of Deep Neural Networks, achieving substantial precision gains over current state-of-the-art baselines.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/w5u3xb1c11/cover.png"/></item><item><title>Rethinking Weight Decay for Robust Fine-Tuning of Foundation Models</title><link>https://deep-diver.github.io/neurips2024/posters/4neqdbz8eg/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/4neqdbz8eg/</guid><description>Selective Projection Decay (SPD) enhances robust fine-tuning of foundation models by selectively applying weight decay, improving generalization and out-of-distribution robustness.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/4neqdbz8eg/cover.png"/></item><item><title>Robust Gaussian Processes via Relevance Pursuit</title><link>https://deep-diver.github.io/neurips2024/posters/5fatpilwuj/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/5fatpilwuj/</guid><description>Robust Gaussian Processes via Relevance Pursuit tackles noisy data by cleverly inferring data-point specific noise levels, leading to more accurate predictions.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/5fatpilwuj/cover.png"/></item><item><title>Robust Graph Neural Networks via Unbiased Aggregation</title><link>https://deep-diver.github.io/neurips2024/posters/dz6ex9ee0q/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/dz6ex9ee0q/</guid><description>RUNG: a novel GNN architecture boasting superior robustness against adaptive attacks by employing an unbiased aggregation technique.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/dz6ex9ee0q/cover.png"/></item><item><title>Robust Mixture Learning when Outliers Overwhelm Small Groups</title><link>https://deep-diver.github.io/neurips2024/posters/trxv4dmdcg/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/trxv4dmdcg/</guid><description>Outlier-robust mixture learning gets order-optimal error guarantees, even when outliers massively outnumber small groups, via a novel meta-algorithm leveraging mixture structure.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/trxv4dmdcg/cover.png"/></item><item><title>Robust Neural Contextual Bandit against Adversarial Corruptions</title><link>https://deep-diver.github.io/neurips2024/posters/6u8iv9hvps/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/6u8iv9hvps/</guid><description>R-NeuralUCB: A robust neural contextual bandit algorithm uses a context-aware gradient descent training to defend against adversarial reward corruptions, achieving better performance with theoretical &amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/6u8iv9hvps/cover.png"/></item><item><title>Robust Sparse Regression with Non-Isotropic Designs</title><link>https://deep-diver.github.io/neurips2024/posters/ybsvnfd21c/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/ybsvnfd21c/</guid><description>New algorithms achieve near-optimal error rates for sparse linear regression, even under adversarial data corruption and heavy-tailed noise distributions.</description></item><item><title>Sample and Computationally Efficient Robust Learning of Gaussian Single-Index Models</title><link>https://deep-diver.github.io/neurips2024/posters/mn7d0s2i1d/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/mn7d0s2i1d/</guid><description>This paper presents a computationally efficient algorithm for robustly learning Gaussian single-index models under adversarial label noise, achieving near-optimal sample complexity.</description></item><item><title>Score-based generative models are provably robust: an uncertainty quantification perspective</title><link>https://deep-diver.github.io/neurips2024/posters/ki5tane02e/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/ki5tane02e/</guid><description>Score-based generative models are provably robust to multiple error sources, as shown via a novel Wasserstein uncertainty propagation theorem.</description></item><item><title>Stability and Generalization of Adversarial Training for Shallow Neural Networks with Smooth Activation</title><link>https://deep-diver.github.io/neurips2024/posters/9nsa4lvzed/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/9nsa4lvzed/</guid><description>This paper provides novel theoretical guarantees for adversarial training of shallow neural networks, improving generalization bounds via early stopping and Moreau&amp;rsquo;s envelope smoothing.</description></item><item><title>Statistical Multicriteria Benchmarking via the GSD-Front</title><link>https://deep-diver.github.io/neurips2024/spotlight-ai-theory/jxxvskb9hd/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-ai-theory/jxxvskb9hd/</guid><description>Researchers can now reliably benchmark classifiers using multiple quality metrics via the GSD-front, a new information-efficient technique that accounts for statistical uncertainty and deviations from&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-ai-theory/jxxvskb9hd/cover.png"/></item><item><title>SuperDeepFool: a new fast and accurate minimal adversarial attack</title><link>https://deep-diver.github.io/neurips2024/posters/pqd7ckr8af/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/pqd7ckr8af/</guid><description>SuperDeepFool: a fast, accurate algorithm generating minimal adversarial perturbations, significantly improving deep learning model robustness evaluation and adversarial training.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/pqd7ckr8af/cover.png"/></item><item><title>The Implicit Bias of Gradient Descent toward Collaboration between Layers: A Dynamic Analysis of Multilayer Perceptions</title><link>https://deep-diver.github.io/neurips2024/posters/jv6z08u7y0/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/jv6z08u7y0/</guid><description>Deep learning models&amp;rsquo; success hinges on understanding gradient descent&amp;rsquo;s implicit bias. This study reveals how this bias influences layer collaboration, revealing a decreasing trend in adversarial rob&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/jv6z08u7y0/cover.png"/></item><item><title>The Price of Implicit Bias in Adversarially Robust Generalization</title><link>https://deep-diver.github.io/neurips2024/posters/h1grus6cjn/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/h1grus6cjn/</guid><description>Optimization&amp;rsquo;s implicit bias in robust machine learning hurts generalization; this work reveals how algorithm/architecture choices impact robustness, suggesting better optimization strategies are need&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/h1grus6cjn/cover.png"/></item><item><title>Transferability Bound Theory: Exploring Relationship between Adversarial Transferability and Flatness</title><link>https://deep-diver.github.io/neurips2024/posters/g522upazh3/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/g522upazh3/</guid><description>Challenging common assumptions, researchers prove that flatter adversarial examples don&amp;rsquo;t guarantee better transferability and introduce TPA, a theoretically-grounded attack creating more transferable&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/g522upazh3/cover.png"/></item><item><title>Treatment of Statistical Estimation Problems in Randomized Smoothing for Adversarial Robustness</title><link>https://deep-diver.github.io/neurips2024/posters/s4wx2qxhv9/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/s4wx2qxhv9/</guid><description>This paper optimizes randomized smoothing, a crucial certified defense against adversarial attacks, by introducing novel statistical methods that drastically reduce the computational cost, leading to &amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/s4wx2qxhv9/cover.png"/></item><item><title>Understanding and Improving Adversarial Collaborative Filtering for Robust Recommendation</title><link>https://deep-diver.github.io/neurips2024/posters/k8ayft5ed1/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/k8ayft5ed1/</guid><description>PamaCF, a novel personalized adversarial collaborative filtering technique, significantly improves recommendation robustness and accuracy against poisoning attacks by dynamically adjusting perturbatio&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/k8ayft5ed1/cover.png"/></item><item><title>Unveiling the Hidden Structure of Self-Attention via Kernel Principal Component Analysis</title><link>https://deep-diver.github.io/neurips2024/posters/vuwvvvni6r/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/vuwvvvni6r/</guid><description>Self-attention, a key component of transformers, is revealed to be a projection of query vectors onto the principal components of the key matrix, derived from kernel PCA. This novel perspective leads&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/vuwvvvni6r/cover.png"/></item><item><title>Wide Two-Layer Networks can Learn from Adversarial Perturbations</title><link>https://deep-diver.github.io/neurips2024/posters/1yggaouvgz/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/1yggaouvgz/</guid><description>Wide two-layer neural networks can generalize well from mislabeled adversarial examples because adversarial perturbations surprisingly contain sufficient class-specific features.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/1yggaouvgz/cover.png"/></item></channel></rss>