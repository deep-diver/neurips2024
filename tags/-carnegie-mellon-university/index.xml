<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>üè¢ Carnegie Mellon University on NeurIPS 2024</title><link>https://deep-diver.github.io/neurips2024/tags/-carnegie-mellon-university/</link><description>Recent content in üè¢ Carnegie Mellon University on NeurIPS 2024</description><generator>Hugo -- gohugo.io</generator><language>en</language><copyright>¬© 2025 AI Paper Reviewer</copyright><lastBuildDate>Thu, 26 Sep 2024 00:00:00 +0000</lastBuildDate><atom:link href="https://deep-diver.github.io/neurips2024/tags/-carnegie-mellon-university/index.xml" rel="self" type="application/rss+xml"/><item><title>A theoretical case-study of Scalable Oversight in Hierarchical Reinforcement Learning</title><link>https://deep-diver.github.io/neurips2024/posters/3tj3a26wsv/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/3tj3a26wsv/</guid><description>Bounded human feedback hinders large AI model training. This paper introduces hierarchical reinforcement learning to enable scalable oversight, efficiently acquiring feedback and learning optimal poli&amp;hellip;</description></item><item><title>Accelerating ERM for data-driven algorithm design using output-sensitive techniques</title><link>https://deep-diver.github.io/neurips2024/posters/yw3tlswusb/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/yw3tlswusb/</guid><description>Accelerating ERM for data-driven algorithm design using output-sensitive techniques achieves computationally efficient learning by scaling with the actual number of pieces in the dual loss function, n&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/yw3tlswusb/cover.png"/></item><item><title>Achieving Domain-Independent Certified Robustness via Knowledge Continuity</title><link>https://deep-diver.github.io/neurips2024/posters/v07krlyxdx/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/v07krlyxdx/</guid><description>Certifying neural network robustness across diverse domains, this paper introduces knowledge continuity‚Äîa novel framework ensuring model stability independent of input type, norms, and distribution.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/v07krlyxdx/cover.png"/></item><item><title>Active, anytime-valid risk controlling prediction sets</title><link>https://deep-diver.github.io/neurips2024/posters/4zh48agd60/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/4zh48agd60/</guid><description>This paper introduces anytime-valid risk-controlling prediction sets for active learning, guaranteeing low risk even with adaptive data collection and limited label budgets.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/4zh48agd60/cover.png"/></item><item><title>Adversarially Robust Dense-Sparse Tradeoffs via Heavy-Hitters</title><link>https://deep-diver.github.io/neurips2024/posters/mpidscd9e7/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/mpidscd9e7/</guid><description>Improved adversarially robust streaming algorithms for L_p estimation are presented, surpassing previous state-of-the-art space bounds and disproving the existence of inherent barriers.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/mpidscd9e7/cover.png"/></item><item><title>Aggregating Quantitative Relative Judgments: From Social Choice to Ranking Prediction</title><link>https://deep-diver.github.io/neurips2024/posters/37cya1k0vv/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/37cya1k0vv/</guid><description>This paper introduces Quantitative Relative Judgment Aggregation (QRJA), a novel social choice model, and applies it to ranking prediction, yielding effective and interpretable results on various real&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/37cya1k0vv/cover.png"/></item><item><title>Alignment for Honesty</title><link>https://deep-diver.github.io/neurips2024/posters/67k3xlvw8l/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/67k3xlvw8l/</guid><description>This paper introduces a novel framework for aligning LLMs with honesty, proposing new metrics and training techniques to make LLMs more truthful and less prone to confidently incorrect responses.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/67k3xlvw8l/cover.png"/></item><item><title>Analytically deriving Partial Information Decomposition for affine systems of stable and convolution-closed distributions</title><link>https://deep-diver.github.io/neurips2024/posters/7cuutpdeqn/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/7cuutpdeqn/</guid><description>This paper presents novel theoretical results enabling the analytical calculation of Partial Information Decomposition for various probability distributions, including those relevant to neuroscience, &amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/7cuutpdeqn/cover.png"/></item><item><title>AutoMix: Automatically Mixing Language Models</title><link>https://deep-diver.github.io/neurips2024/posters/e6wrwivgzx/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/e6wrwivgzx/</guid><description>AutoMix intelligently routes queries to different-sized LLMs based on a smaller model&amp;rsquo;s self-verification, minimizing cost while maintaining performance.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/e6wrwivgzx/cover.png"/></item><item><title>BECAUSE: Bilinear Causal Representation for Generalizable Offline Model-based Reinforcement Learning</title><link>https://deep-diver.github.io/neurips2024/posters/4i9xupeu9w/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/4i9xupeu9w/</guid><description>BECAUSE: a novel algorithm for generalizable offline model-based reinforcement learning that leverages bilinear causal representation to mitigate objective mismatch caused by confounders in offline da&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/4i9xupeu9w/cover.png"/></item><item><title>Causal Inference in the Closed-Loop: Marginal Structural Models for Sequential Excursion Effects</title><link>https://deep-diver.github.io/neurips2024/posters/bgzcuesyu8/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/bgzcuesyu8/</guid><description>Researchers introduce a non-parametric causal inference framework to analyze closed-loop optogenetics designs, revealing previously hidden causal effects of neural circuit manipulations on behavior.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/bgzcuesyu8/cover.png"/></item><item><title>Causal Temporal Representation Learning with Nonstationary Sparse Transition</title><link>https://deep-diver.github.io/neurips2024/posters/j709rtaud1/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/j709rtaud1/</guid><description>CtrlNS: A novel framework for causal temporal representation learning tackles the challenge of nonstationary time series by leveraging sparse transition assumptions, achieving improved accuracy in ide&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/j709rtaud1/cover.png"/></item><item><title>Communication Bounds for the Distributed Experts Problem</title><link>https://deep-diver.github.io/neurips2024/posters/hyxjsi3szf/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/hyxjsi3szf/</guid><description>This paper presents communication-efficient protocols for the distributed experts problem, achieving near-optimal regret with theoretical and empirical validation.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/hyxjsi3szf/cover.png"/></item><item><title>Connecting Joint-Embedding Predictive Architecture with Contrastive Self-supervised Learning</title><link>https://deep-diver.github.io/neurips2024/spotlight-others/jvqnjwij6m/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-others/jvqnjwij6m/</guid><description>C-JEPA boosts self-supervised visual learning by integrating contrastive learning with a joint-embedding predictive architecture, enhancing stability and representation quality.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-others/jvqnjwij6m/cover.png"/></item><item><title>Convergence of $ ext{log}(1/psilon)$ for Gradient-Based Algorithms in Zero-Sum Games without the Condition Number: A Smoothed Analysis</title><link>https://deep-diver.github.io/neurips2024/posters/hovxlc8vqu/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/hovxlc8vqu/</guid><description>Gradient-based methods for solving large zero-sum games achieve polynomial smoothed complexity, demonstrating efficiency even in high-precision scenarios without condition number dependence.</description></item><item><title>Data Attribution for Text-to-Image Models by Unlearning Synthesized Images</title><link>https://deep-diver.github.io/neurips2024/posters/kvr3l73pnh/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/kvr3l73pnh/</guid><description>Unlearning synthesized images efficiently reveals influential training data for text-to-image models, improving data attribution accuracy and facilitating better model understanding.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/kvr3l73pnh/cover.png"/></item><item><title>Data Distribution Valuation</title><link>https://deep-diver.github.io/neurips2024/posters/1067784f6e/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/1067784f6e/</guid><description>This paper proposes a novel MMD-based method for data distribution valuation, enabling theoretically-principled comparison of data distributions from limited samples, outperforming existing methods in&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/1067784f6e/cover.png"/></item><item><title>Diffusion PID: Interpreting Diffusion via Partial Information Decomposition</title><link>https://deep-diver.github.io/neurips2024/posters/abpxukzs37/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/abpxukzs37/</guid><description>DiffusionPID unveils the secrets of text-to-image diffusion models by decomposing text prompts into unique, redundant, and synergistic components, providing insights into how individual words and thei&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/abpxukzs37/cover.png"/></item><item><title>Divergences between Language Models and Human Brains</title><link>https://deep-diver.github.io/neurips2024/posters/dpp5f3ufkw/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/dpp5f3ufkw/</guid><description>Language models struggle with social/emotional intelligence and physical commonsense, unlike human brains. Fine-tuning models on these aspects improves their brain response prediction accuracy.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/dpp5f3ufkw/cover.png"/></item><item><title>Don't Look Twice: Faster Video Transformers with Run-Length Tokenization</title><link>https://deep-diver.github.io/neurips2024/spotlight-others/b1ggjw00ni/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-others/b1ggjw00ni/</guid><description>Run-Length Tokenization (RLT) dramatically speeds up video transformer training and inference by efficiently removing redundant video tokens, matching baseline model performance with significant time &amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-others/b1ggjw00ni/cover.png"/></item><item><title>Doubly Hierarchical Geometric Representations for Strand-based Human Hairstyle Generation</title><link>https://deep-diver.github.io/neurips2024/posters/h34jvnpo1c/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/h34jvnpo1c/</guid><description>Doubly hierarchical geometric representations enable realistic human hairstyle generation by separating low and high-frequency details in hair strands, resulting in high-quality, detailed virtual hair&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/h34jvnpo1c/cover.png"/></item><item><title>DreamScene4D: Dynamic Multi-Object Scene Generation from Monocular Videos</title><link>https://deep-diver.github.io/neurips2024/posters/ylivhhfwq2/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/ylivhhfwq2/</guid><description>DreamScene4D generates realistic 3D dynamic multi-object scenes from monocular videos via novel view synthesis, addressing limitations of existing methods with a novel decompose-recompose approach.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/ylivhhfwq2/cover.png"/></item><item><title>Dual Prototype Evolving for Test-Time Generalization of Vision-Language Models</title><link>https://deep-diver.github.io/neurips2024/posters/jsgyyxasis/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/jsgyyxasis/</guid><description>Dual Prototype Evolving (DPE) significantly boosts vision-language model generalization by cumulatively learning multi-modal prototypes from unlabeled test data, outperforming current state-of-the-art&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/jsgyyxasis/cover.png"/></item><item><title>Easy-to-Hard Generalization: Scalable Alignment Beyond Human Supervision</title><link>https://deep-diver.github.io/neurips2024/posters/qwgfh2fttn/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/qwgfh2fttn/</guid><description>AI alignment beyond human supervision is achieved via easy-to-hard generalization: training reward models on easy tasks to effectively evaluate and improve generators on harder tasks, achieving superh&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/qwgfh2fttn/cover.png"/></item><item><title>Efficient $‚Ä©hi$-Regret Minimization with Low-Degree Swap Deviations in Extensive-Form Games</title><link>https://deep-diver.github.io/neurips2024/posters/c4elkpa0kh/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/c4elkpa0kh/</guid><description>New efficient algorithms minimize regret in extensive-form games by cleverly using low-degree swap deviations and a relaxed fixed-point concept, improving correlated equilibrium computation.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/c4elkpa0kh/cover.png"/></item><item><title>Efficient LLM Jailbreak via Adaptive Dense-to-sparse Constrained Optimization</title><link>https://deep-diver.github.io/neurips2024/posters/bn5pa3hho8/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/bn5pa3hho8/</guid><description>Adaptive Dense-to-sparse Constrained Optimization (ADC) efficiently jailbreaks LLMs by transforming discrete token optimization into a continuous process, achieving higher success rates than existing &amp;hellip;</description></item><item><title>Emotion-LLaMA: Multimodal Emotion Recognition and Reasoning with Instruction Tuning</title><link>https://deep-diver.github.io/neurips2024/posters/qxzvsy9lfr/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/qxzvsy9lfr/</guid><description>Emotion-LLaMA: A new multimodal large language model excels at emotion recognition and reasoning, outperforming existing models and leveraging a newly created dataset, MERR.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/qxzvsy9lfr/cover.png"/></item><item><title>Fast Best-of-N Decoding via Speculative Rejection</title><link>https://deep-diver.github.io/neurips2024/posters/348hfcprus/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/348hfcprus/</guid><description>Speculative Rejection: A novel algorithm boosts Large Language Model (LLM) alignment by speeding up inference-time alignment by 16-32x!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/348hfcprus/cover.png"/></item><item><title>Federated Natural Policy Gradient and Actor Critic Methods for Multi-task Reinforcement Learning</title><link>https://deep-diver.github.io/neurips2024/posters/dufd6vsyf8/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/dufd6vsyf8/</guid><description>This paper introduces federated natural policy gradient and actor-critic methods achieving near dimension-free global convergence for decentralized multi-task reinforcement learning, a significant bre&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/dufd6vsyf8/cover.png"/></item><item><title>From Causal to Concept-Based Representation Learning</title><link>https://deep-diver.github.io/neurips2024/posters/r5nev2shtj/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/r5nev2shtj/</guid><description>This paper introduces a novel geometric approach to concept-based representation learning, provably recovering interpretable concepts from diverse data without strict causal assumptions or many interv&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/r5nev2shtj/cover.png"/></item><item><title>GL-NeRF: Gauss-Laguerre Quadrature Enables Training-Free NeRF Acceleration</title><link>https://deep-diver.github.io/neurips2024/posters/gdnzajkrml/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/gdnzajkrml/</guid><description>GL-NeRF accelerates NeRF rendering by using Gauss-Laguerre quadrature, drastically reducing MLP calls without needing additional networks or data structures.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/gdnzajkrml/cover.png"/></item><item><title>Global Rewards in Restless Multi-Armed Bandits</title><link>https://deep-diver.github.io/neurips2024/posters/3apt5aj5qn/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/3apt5aj5qn/</guid><description>Restless multi-armed bandits with global rewards (RMAB-G) are introduced, extending the model to handle non-separable rewards and offering novel index-based and adaptive policies that outperform exist&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/3apt5aj5qn/cover.png"/></item><item><title>Hamba: Single-view 3D Hand Reconstruction with Graph-guided Bi-Scanning Mamba</title><link>https://deep-diver.github.io/neurips2024/posters/pcj0l1jvux/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/pcj0l1jvux/</guid><description>Hamba: a novel graph-guided framework for single-view 3D hand reconstruction, significantly outperforms existing methods by efficiently modeling spatial relationships between joints using a fraction o&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/pcj0l1jvux/cover.png"/></item><item><title>Hydra: Bidirectional State Space Models Through Generalized Matrix Mixers</title><link>https://deep-diver.github.io/neurips2024/posters/preo49p1vy/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/preo49p1vy/</guid><description>Hydra: Bidirectional sequence modeling redefined with quasiseparable matrix mixers, outperforming existing models on various benchmarks!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/preo49p1vy/cover.png"/></item><item><title>Identifying Latent State-Transition Processes for Individualized Reinforcement Learning</title><link>https://deep-diver.github.io/neurips2024/posters/krepcqthdn/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/krepcqthdn/</guid><description>This study introduces a novel framework for individualized reinforcement learning, guaranteeing the identifiability of latent factors influencing state transitions and providing a practical method for&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/krepcqthdn/cover.png"/></item><item><title>Identifying Selections for Unsupervised Subtask Discovery</title><link>https://deep-diver.github.io/neurips2024/posters/hh4bpkohhh/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/hh4bpkohhh/</guid><description>This paper introduces seq-NMF, a novel method for unsupervised subtask discovery in reinforcement learning that leverages selection variables to enhance generalization and data efficiency.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/hh4bpkohhh/cover.png"/></item><item><title>Implicit Regularization Paths of Weighted Neural Representations</title><link>https://deep-diver.github.io/neurips2024/posters/oxcmwwkqtz/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/oxcmwwkqtz/</guid><description>Weighted pretrained features implicitly regularize models, and this paper reveals equivalent paths between weighting schemes and ridge regularization, enabling efficient hyperparameter tuning.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/oxcmwwkqtz/cover.png"/></item><item><title>Imprecise Label Learning: A Unified Framework for Learning with Various Imprecise Label Configurations</title><link>https://deep-diver.github.io/neurips2024/posters/0lr9hqija1/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/0lr9hqija1/</guid><description>Unified framework for imprecise label learning handles noisy, partial, and semi-supervised data, improving model training efficiency and accuracy.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/0lr9hqija1/cover.png"/></item><item><title>Improving the Training of Rectified Flows</title><link>https://deep-diver.github.io/neurips2024/posters/mshs6c7nfa/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/mshs6c7nfa/</guid><description>Researchers significantly boosted the efficiency and quality of rectified flow, a method for generating samples from diffusion models, by introducing novel training techniques that surpass state-of-th&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/mshs6c7nfa/cover.png"/></item><item><title>In-Context Learning with Representations: Contextual Generalization of Trained Transformers</title><link>https://deep-diver.github.io/neurips2024/posters/ik37kkxkbm/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/ik37kkxkbm/</guid><description>Transformers learn contextual information for generalization to unseen examples and tasks, even with limited training data, converging linearly to a global minimum.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/ik37kkxkbm/cover.png"/></item><item><title>Incremental Learning of Retrievable Skills For Efficient Continual Task Adaptation</title><link>https://deep-diver.github.io/neurips2024/posters/rcpajanpnm/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/rcpajanpnm/</guid><description>IsCiL: a novel adapter-based continual imitation learning framework that efficiently adapts to new tasks by incrementally learning and retrieving reusable skills.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/rcpajanpnm/cover.png"/></item><item><title>Interventional Causal Discovery in a Mixture of DAGs</title><link>https://deep-diver.github.io/neurips2024/posters/mfrlci8sov/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/mfrlci8sov/</guid><description>This study presents CADIM, an adaptive algorithm using interventions to learn true causal relationships from mixtures of DAGs, achieving near-optimal intervention sizes and providing quantifiable opti&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/mfrlci8sov/cover.png"/></item><item><title>John Ellipsoids via Lazy Updates</title><link>https://deep-diver.github.io/neurips2024/posters/lcj0rvr4d6/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/lcj0rvr4d6/</guid><description>Faster John ellipsoid computation achieved via lazy updates and fast matrix multiplication, improving efficiency and enabling low-space streaming algorithms.</description></item><item><title>Learning Discrete Concepts in Latent Hierarchical Models</title><link>https://deep-diver.github.io/neurips2024/posters/bo5buxvh6m/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/bo5buxvh6m/</guid><description>This paper introduces a novel framework for learning discrete concepts from high-dimensional data, establishing theoretical conditions for identifying underlying hierarchical causal structures and pro&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/bo5buxvh6m/cover.png"/></item><item><title>Learning Discrete Latent Variable Structures with Tensor Rank Conditions</title><link>https://deep-diver.github.io/neurips2024/posters/6eqfoqklsw/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/6eqfoqklsw/</guid><description>This paper introduces a novel tensor rank condition for identifying causal structures among discrete latent variables, advancing causal discovery in complex scenarios.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/6eqfoqklsw/cover.png"/></item><item><title>Learning Social Welfare Functions</title><link>https://deep-diver.github.io/neurips2024/spotlight-ai-theory/7o6ktaar8n/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-ai-theory/7o6ktaar8n/</guid><description>Learning social welfare functions from past decisions is possible! This paper shows how to efficiently learn power mean functions, a widely used family, using both cardinal and pairwise welfare compar&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-ai-theory/7o6ktaar8n/cover.png"/></item><item><title>Learning to Reason Iteratively and Parallelly for Complex Visual Reasoning Scenarios</title><link>https://deep-diver.github.io/neurips2024/posters/uojq9qadjy/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/uojq9qadjy/</guid><description>Boosting complex visual reasoning, a new Iterative and Parallel Reasoning Mechanism (IPRM) outperforms existing methods by combining step-by-step and simultaneous computations, improving accuracy and &amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/uojq9qadjy/cover.png"/></item><item><title>Linear Causal Representation Learning from Unknown Multi-node Interventions</title><link>https://deep-diver.github.io/neurips2024/posters/weemasptzg/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/weemasptzg/</guid><description>Unlocking Causal Structures: New algorithms identify latent causal relationships from interventions, even when multiple variables are affected simultaneously.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/weemasptzg/cover.png"/></item><item><title>Lips Are Lying: Spotting the Temporal Inconsistency between Audio and Visual in Lip-Syncing DeepFakes</title><link>https://deep-diver.github.io/neurips2024/posters/yms7ansbr6/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/yms7ansbr6/</guid><description>LipFD: a novel method leverages audio-visual inconsistencies to accurately spot lip-syncing deepfakes, outperforming existing methods and introducing a high-quality dataset for future research.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/yms7ansbr6/cover.png"/></item><item><title>LLM Dataset Inference: Did you train on my dataset?</title><link>https://deep-diver.github.io/neurips2024/posters/fr9d1umc37/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/fr9d1umc37/</guid><description>LLM dataset inference reliably detects if a dataset was used in training, overcoming limitations of existing membership inference attacks.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/fr9d1umc37/cover.png"/></item><item><title>MAmmoTH2: Scaling Instructions from the Web</title><link>https://deep-diver.github.io/neurips2024/posters/yvu5dnplqa/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/yvu5dnplqa/</guid><description>MAmmoTH2: Harvesting 10M web instructions for enhanced LLM reasoning!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/yvu5dnplqa/cover.png"/></item><item><title>Markov Equivalence and Consistency in Differentiable Structure Learning</title><link>https://deep-diver.github.io/neurips2024/posters/tmlgqw7ebc/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/tmlgqw7ebc/</guid><description>Researchers developed a new, differentiable score function for learning causal relationships from data that reliably recovers the simplest causal model, even with complex data.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/tmlgqw7ebc/cover.png"/></item><item><title>Metric from Human: Zero-shot Monocular Metric Depth Estimation via Test-time Adaptation</title><link>https://deep-diver.github.io/neurips2024/posters/ga8tvtxudf/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/ga8tvtxudf/</guid><description>Humans as landmarks: A novel zero-shot monocular metric depth estimation method leverages generative models and human mesh recovery to transfer metric scale information, achieving superior generalizat&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/ga8tvtxudf/cover.png"/></item><item><title>MGF: Mixed Gaussian Flow for Diverse Trajectory Prediction</title><link>https://deep-diver.github.io/neurips2024/posters/muyhndlxwc/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/muyhndlxwc/</guid><description>MGF: Mixed Gaussian Flow enhances trajectory prediction by using a mixed Gaussian prior, achieving state-of-the-art diversity and alignment accuracy.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/muyhndlxwc/cover.png"/></item><item><title>MiSO: Optimizing brain stimulation to create neural activity states</title><link>https://deep-diver.github.io/neurips2024/posters/gb0mxhn5h3/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/gb0mxhn5h3/</guid><description>MiSO: a novel closed-loop brain stimulation framework optimizes stimulation parameters to achieve desired neural population activity states, overcoming limitations of current methods by merging data a&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/gb0mxhn5h3/cover.png"/></item><item><title>Model-based Diffusion for Trajectory Optimization</title><link>https://deep-diver.github.io/neurips2024/posters/bjndysco6o/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/bjndysco6o/</guid><description>Model-Based Diffusion (MBD) uses diffusion processes and model information for data-free trajectory optimization, outperforming existing methods on complex tasks.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/bjndysco6o/cover.png"/></item><item><title>Multi-Agent Imitation Learning: Value is Easy, Regret is Hard</title><link>https://deep-diver.github.io/neurips2024/posters/qk3ibhyv6z/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/qk3ibhyv6z/</guid><description>In multi-agent imitation learning, achieving regret equivalence is harder than value equivalence; this paper introduces novel algorithms that efficiently minimize the regret gap under various assumpti&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/qk3ibhyv6z/cover.png"/></item><item><title>No Free Lunch in LLM Watermarking: Trade-offs in Watermarking Design Choices</title><link>https://deep-diver.github.io/neurips2024/posters/riol7kbskv/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/riol7kbskv/</guid><description>LLM watermarking faces inherent trade-offs; this paper reveals simple attacks exploiting common design choices, proposing guidelines and defenses for more secure systems.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/riol7kbskv/cover.png"/></item><item><title>OASIS: Conditional Distribution Shaping for Offline Safe Reinforcement Learning</title><link>https://deep-diver.github.io/neurips2024/posters/3udemsf3jf/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/3udemsf3jf/</guid><description>OASIS, a novel data-centric approach, shapes offline data distributions toward safer, higher-reward policies using a conditional diffusion model, outperforming existing offline safe RL methods.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/3udemsf3jf/cover.png"/></item><item><title>Omnigrasp: Simulated Humanoid Grasping on Diverse Objects</title><link>https://deep-diver.github.io/neurips2024/posters/glt37xou7e/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/glt37xou7e/</guid><description>Omnigrasp: A novel RL-based method enables simulated humanoids to grasp diverse objects and precisely follow complex trajectories, advancing realistic human-object interaction in virtual environments.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/glt37xou7e/cover.png"/></item><item><title>On the Benefits of Public Representations for Private Transfer Learning under Distribution Shift</title><link>https://deep-diver.github.io/neurips2024/posters/e1nblreajo/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/e1nblreajo/</guid><description>Public data boosts private AI accuracy even with extreme distribution shifts, improving private model training by up to 67% in three tasks. This is due to shared low-dimensional representations betwe&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/e1nblreajo/cover.png"/></item><item><title>On the Parameter Identifiability of Partially Observed Linear Causal Models</title><link>https://deep-diver.github.io/neurips2024/posters/eqzlefjrkv/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/eqzlefjrkv/</guid><description>Researchers achieve full parameter identifiability in partially observed linear causal models using novel graphical conditions and a likelihood-based estimation method, addressing previous limitations&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/eqzlefjrkv/cover.png"/></item><item><title>On the Surprising Effectiveness of Attention Transfer for Vision Transformers</title><link>https://deep-diver.github.io/neurips2024/posters/5dwqmoce1n/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/5dwqmoce1n/</guid><description>Vision Transformers achieve surprisingly high accuracy by transferring only pre-training attention maps, challenging the conventional belief that feature learning is crucial.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/5dwqmoce1n/cover.png"/></item><item><title>Pard: Permutation-Invariant Autoregressive Diffusion for Graph Generation</title><link>https://deep-diver.github.io/neurips2024/posters/x4kk4fxls3/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/x4kk4fxls3/</guid><description>PARD: a novel permutation-invariant autoregressive diffusion model for efficient and high-quality graph generation, achieving state-of-the-art results.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/x4kk4fxls3/cover.png"/></item><item><title>Predicting the Performance of Foundation Models via Agreement-on-the-Line</title><link>https://deep-diver.github.io/neurips2024/posters/ajx9onwsr4/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/ajx9onwsr4/</guid><description>Foundation model OOD performance prediction is reliably achieved via ensemble diversity, especially through random linear head initialization, enabling precise estimations without extensive OOD labels&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/ajx9onwsr4/cover.png"/></item><item><title>Private and Personalized Frequency Estimation in a Federated Setting</title><link>https://deep-diver.github.io/neurips2024/posters/0nzkzncjfg/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/0nzkzncjfg/</guid><description>This paper introduces a novel privacy-preserving algorithm for personalized frequency estimation in federated settings, significantly improving accuracy and efficiency over existing methods.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/0nzkzncjfg/cover.png"/></item><item><title>Protein-Nucleic Acid Complex Modeling with Frame Averaging Transformer</title><link>https://deep-diver.github.io/neurips2024/posters/xngi3z3wkn/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/xngi3z3wkn/</guid><description>Unsupervised learning predicts protein-nucleic acid binding using contact map prediction, significantly improving aptamer screening via FAFormer, a novel equivariant transformer.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/xngi3z3wkn/cover.png"/></item><item><title>Provably Robust Score-Based Diffusion Posterior Sampling for Plug-and-Play Image Reconstruction</title><link>https://deep-diver.github.io/neurips2024/posters/slnsoay4u1/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/slnsoay4u1/</guid><description>Provably robust diffusion posterior sampling for plug-and-play image reconstruction is achieved via a novel algorithmic framework, DPnP, offering both asymptotic and non-asymptotic performance guarant&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/slnsoay4u1/cover.png"/></item><item><title>Recursive Introspection: Teaching Language Model Agents How to Self-Improve</title><link>https://deep-diver.github.io/neurips2024/posters/drc9pzwbwr/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/drc9pzwbwr/</guid><description>RISE: Recursive Introspection teaches LLMs to iteratively improve their responses, enabling self-correction and enhanced performance on challenging reasoning tasks.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/drc9pzwbwr/cover.png"/></item><item><title>Regret Minimization in Stackelberg Games with Side Information</title><link>https://deep-diver.github.io/neurips2024/posters/rpkcrzdqjx/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/rpkcrzdqjx/</guid><description>This research shows how to improve Stackelberg game strategies by considering side information, achieving no-regret learning in online settings with stochastic contexts or followers.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/rpkcrzdqjx/cover.png"/></item><item><title>Rethinking LLM Memorization through the Lens of Adversarial Compression</title><link>https://deep-diver.github.io/neurips2024/posters/kfmrmvzazy/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/kfmrmvzazy/</guid><description>Researchers propose Adversarial Compression Ratio (ACR) to assess LLM memorization, offering an adversarial, flexible, and computationally efficient method for monitoring data misuse and compliance.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/kfmrmvzazy/cover.png"/></item><item><title>RL on Incorrect Synthetic Data Scales the Efficiency of LLM Math Reasoning by Eight-Fold</title><link>https://deep-diver.github.io/neurips2024/posters/9m87e9keq1/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/9m87e9keq1/</guid><description>Leveraging model-generated synthetic data for LLM finetuning significantly improves efficiency when using both positive and strategically constructed negative examples, resulting in an eight-fold incr&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/9m87e9keq1/cover.png"/></item><item><title>S$^{2}$FT: Efficient, Scalable and Generalizable LLM Fine-tuning by Structured Sparsity</title><link>https://deep-diver.github.io/neurips2024/posters/leule8s4xq/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/leule8s4xq/</guid><description>S2FT: Structured Sparse Fine-Tuning achieves state-of-the-art LLM fine-tuning performance, training efficiency, and inference scalability by selecting sparsely and computing densely.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/leule8s4xq/cover.png"/></item><item><title>Sample Complexity of Interventional Causal Representation Learning</title><link>https://deep-diver.github.io/neurips2024/posters/xl9aaxl0u6/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/xl9aaxl0u6/</guid><description>First finite-sample analysis of interventional causal representation learning shows that surprisingly few samples suffice for accurate graph and latent variable recovery.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/xl9aaxl0u6/cover.png"/></item><item><title>Sequoia: Scalable and Robust Speculative Decoding</title><link>https://deep-diver.github.io/neurips2024/spotlight-large-language-models/rk2l9ygdi2/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-large-language-models/rk2l9ygdi2/</guid><description>SEQUOIA: A novel algorithm boosts Large Language Model (LLM) inference speed by up to 9.5x using a scalable and robust speculative decoding approach!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-large-language-models/rk2l9ygdi2/cover.png"/></item><item><title>SIRIUS : Contexual Sparisty with Correction for Efficient LLMs</title><link>https://deep-diver.github.io/neurips2024/posters/5br2l1b2eh/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/5br2l1b2eh/</guid><description>SIRIUS: A novel correction mechanism boosts the efficiency of contextually sparse LLMs for complex reasoning tasks, achieving significant latency reduction.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/5br2l1b2eh/cover.png"/></item><item><title>Slight Corruption in Pre-training Data Makes Better Diffusion Models</title><link>https://deep-diver.github.io/neurips2024/spotlight-others/vfpxybqmsu/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-others/vfpxybqmsu/</guid><description>Slightly corrupting pre-training data significantly improves diffusion models&amp;rsquo; image generation quality, diversity, and fidelity.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-others/vfpxybqmsu/cover.png"/></item><item><title>Sparse-view Pose Estimation and Reconstruction via Analysis by Generative Synthesis</title><link>https://deep-diver.github.io/neurips2024/posters/wgpmdyjgsg/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/wgpmdyjgsg/</guid><description>SparseAGS: High-fidelity 3D reconstruction &amp;amp; camera pose estimation from sparse views via generative synthesis.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/wgpmdyjgsg/cover.png"/></item><item><title>Synatra: Turning Indirect Knowledge into Direct Demonstrations for Digital Agents at Scale</title><link>https://deep-diver.github.io/neurips2024/posters/kjnezwriqn/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/kjnezwriqn/</guid><description>Synatra synthesizes high-quality digital agent training data from online tutorials and web pages, significantly improving agent performance on complex web-based tasks at a fraction of the cost of huma&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/kjnezwriqn/cover.png"/></item><item><title>Tactile DreamFusion: Exploiting Tactile Sensing for 3D Generation</title><link>https://deep-diver.github.io/neurips2024/posters/fa3rmml8ii/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/fa3rmml8ii/</guid><description>Tactile DreamFusion: High-resolution tactile sensing enhances 3D generation, creating realistic geometric details previously unattainable.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/fa3rmml8ii/cover.png"/></item><item><title>Test-Time Adaptation Induces Stronger Accuracy and Agreement-on-the-Line</title><link>https://deep-diver.github.io/neurips2024/posters/gixux4vh9t/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/gixux4vh9t/</guid><description>Test-time adaptation strengthens the linear correlation between in- and out-of-distribution accuracy, enabling precise OOD performance prediction and hyperparameter optimization without labeled OOD da&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/gixux4vh9t/cover.png"/></item><item><title>The Importance of Online Data: Understanding Preference Fine-tuning via Coverage</title><link>https://deep-diver.github.io/neurips2024/posters/hbj86rmdz8/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/hbj86rmdz8/</guid><description>Hybrid Preference Optimization (HyPO) outperforms existing offline methods for fine-tuning LLMs by leveraging both offline and online data, achieving better performance and efficiency.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/hbj86rmdz8/cover.png"/></item><item><title>The Sample-Communication Complexity Trade-off in Federated Q-Learning</title><link>https://deep-diver.github.io/neurips2024/oral-reinforcement-learning/6yipvnkjuk/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/oral-reinforcement-learning/6yipvnkjuk/</guid><description>Federated Q-learning achieves optimal sample &amp;amp; communication complexities simultaneously via Fed-DVR-Q, a novel algorithm.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/oral-reinforcement-learning/6yipvnkjuk/cover.png"/></item><item><title>Towards Understanding Extrapolation: a Causal Lens</title><link>https://deep-diver.github.io/neurips2024/posters/2squ766iq4/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/2squ766iq4/</guid><description>This work unveils a causal lens on extrapolation, offering theoretical guarantees for accurate predictions on out-of-support data, even with limited target samples.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/2squ766iq4/cover.png"/></item><item><title>Transformers to SSMs: Distilling Quadratic Knowledge to Subquadratic Models</title><link>https://deep-diver.github.io/neurips2024/posters/fjlrszbmcd/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/fjlrszbmcd/</guid><description>MOHAWK: Distilling Transformers&amp;rsquo; quadratic knowledge into faster subquadratic SSMs, achieving state-of-the-art performance with &amp;lt;1% of training data!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/fjlrszbmcd/cover.png"/></item><item><title>Understanding Hallucinations in Diffusion Models through Mode Interpolation</title><link>https://deep-diver.github.io/neurips2024/posters/antnhbkw4t/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/antnhbkw4t/</guid><description>Diffusion models generate unrealistic images by smoothly interpolating between data modes; this paper identifies this &amp;lsquo;mode interpolation&amp;rsquo; failure and proposes a metric to detect and reduce it.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/antnhbkw4t/cover.png"/></item><item><title>Visual Data Diagnosis and Debiasing with Concept Graphs</title><link>https://deep-diver.github.io/neurips2024/posters/xngsx3wcu9/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/xngsx3wcu9/</guid><description>CONBIAS tackles dataset bias by representing visual data as concept graphs, diagnosing imbalances via clique analysis, and debiasing through targeted data augmentation for improved model generalizatio&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/xngsx3wcu9/cover.png"/></item><item><title>VLM Agents Generate Their Own Memories: Distilling Experience into Embodied Programs of Thought</title><link>https://deep-diver.github.io/neurips2024/spotlight-others/5g7mrfpngt/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-others/5g7mrfpngt/</guid><description>VLMs learn to generate their own memories by abstracting experiences from noisy demonstrations and human feedback, significantly boosting in-context learning performance.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-others/5g7mrfpngt/cover.png"/></item></channel></rss>