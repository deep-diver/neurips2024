<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>üè¢ Carnegie Mellon University on NeurIPS 2024</title><link>https://deep-diver.github.io/neurips2024/tags/-carnegie-mellon-university/</link><description>Recent content in üè¢ Carnegie Mellon University on NeurIPS 2024</description><generator>Hugo -- gohugo.io</generator><language>en</language><copyright>¬© 2024 AI Paper Reviewer</copyright><lastBuildDate>Thu, 26 Sep 2024 00:00:00 +0000</lastBuildDate><atom:link href="https://deep-diver.github.io/neurips2024/tags/-carnegie-mellon-university/index.xml" rel="self" type="application/rss+xml"/><item><title>Accelerating ERM for data-driven algorithm design using output-sensitive techniques</title><link>https://deep-diver.github.io/neurips2024/posters/yw3tlswusb/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/yw3tlswusb/</guid><description>Accelerating ERM for data-driven algorithm design using output-sensitive techniques achieves computationally efficient learning by scaling with the actual number of pieces in the dual loss function, n&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/yw3tlswusb/cover.png"/></item><item><title>Achieving Domain-Independent Certified Robustness via Knowledge Continuity</title><link>https://deep-diver.github.io/neurips2024/posters/v07krlyxdx/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/v07krlyxdx/</guid><description>Certifying neural network robustness across diverse domains, this paper introduces knowledge continuity‚Äîa novel framework ensuring model stability independent of input type, norms, and distribution.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/v07krlyxdx/cover.png"/></item><item><title>AutoMix: Automatically Mixing Language Models</title><link>https://deep-diver.github.io/neurips2024/posters/e6wrwivgzx/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/e6wrwivgzx/</guid><description>AutoMix intelligently routes queries to different-sized LLMs based on a smaller model&amp;rsquo;s self-verification, minimizing cost while maintaining performance.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/e6wrwivgzx/cover.png"/></item><item><title>Causal Temporal Representation Learning with Nonstationary Sparse Transition</title><link>https://deep-diver.github.io/neurips2024/posters/j709rtaud1/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/j709rtaud1/</guid><description>CtrlNS: A novel framework for causal temporal representation learning tackles the challenge of nonstationary time series by leveraging sparse transition assumptions, achieving improved accuracy in ide&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/j709rtaud1/cover.png"/></item><item><title>Communication Bounds for the Distributed Experts Problem</title><link>https://deep-diver.github.io/neurips2024/posters/hyxjsi3szf/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/hyxjsi3szf/</guid><description>This paper presents communication-efficient protocols for the distributed experts problem, achieving near-optimal regret with theoretical and empirical validation.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/hyxjsi3szf/cover.png"/></item><item><title>Connecting Joint-Embedding Predictive Architecture with Contrastive Self-supervised Learning</title><link>https://deep-diver.github.io/neurips2024/spotlight-others/jvqnjwij6m/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-others/jvqnjwij6m/</guid><description>C-JEPA boosts self-supervised visual learning by integrating contrastive learning with a joint-embedding predictive architecture, enhancing stability and representation quality.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-others/jvqnjwij6m/cover.png"/></item><item><title>Convergence of $ ext{log}(1/psilon)$ for Gradient-Based Algorithms in Zero-Sum Games without the Condition Number: A Smoothed Analysis</title><link>https://deep-diver.github.io/neurips2024/posters/hovxlc8vqu/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/hovxlc8vqu/</guid><description>Gradient-based methods for solving large zero-sum games achieve polynomial smoothed complexity, demonstrating efficiency even in high-precision scenarios without condition number dependence.</description></item><item><title>Diffusion PID: Interpreting Diffusion via Partial Information Decomposition</title><link>https://deep-diver.github.io/neurips2024/posters/abpxukzs37/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/abpxukzs37/</guid><description>DiffusionPID unveils the secrets of text-to-image diffusion models by decomposing text prompts into unique, redundant, and synergistic components, providing insights into how individual words and thei&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/abpxukzs37/cover.png"/></item><item><title>Divergences between Language Models and Human Brains</title><link>https://deep-diver.github.io/neurips2024/posters/dpp5f3ufkw/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/dpp5f3ufkw/</guid><description>Language models struggle with social/emotional intelligence and physical commonsense, unlike human brains. Fine-tuning models on these aspects improves their brain response prediction accuracy.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/dpp5f3ufkw/cover.png"/></item><item><title>Don't Look Twice: Faster Video Transformers with Run-Length Tokenization</title><link>https://deep-diver.github.io/neurips2024/spotlight-others/b1ggjw00ni/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-others/b1ggjw00ni/</guid><description>Run-Length Tokenization (RLT) dramatically speeds up video transformer training and inference by efficiently removing redundant video tokens, matching baseline model performance with significant time &amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-others/b1ggjw00ni/cover.png"/></item><item><title>Doubly Hierarchical Geometric Representations for Strand-based Human Hairstyle Generation</title><link>https://deep-diver.github.io/neurips2024/posters/h34jvnpo1c/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/h34jvnpo1c/</guid><description>Doubly hierarchical geometric representations enable realistic human hairstyle generation by separating low and high-frequency details in hair strands, resulting in high-quality, detailed virtual hair&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/h34jvnpo1c/cover.png"/></item><item><title>DreamScene4D: Dynamic Multi-Object Scene Generation from Monocular Videos</title><link>https://deep-diver.github.io/neurips2024/posters/ylivhhfwq2/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/ylivhhfwq2/</guid><description>DreamScene4D generates realistic 3D dynamic multi-object scenes from monocular videos via novel view synthesis, addressing limitations of existing methods with a novel decompose-recompose approach.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/ylivhhfwq2/cover.png"/></item><item><title>Dual Prototype Evolving for Test-Time Generalization of Vision-Language Models</title><link>https://deep-diver.github.io/neurips2024/posters/jsgyyxasis/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/jsgyyxasis/</guid><description>Dual Prototype Evolving (DPE) significantly boosts vision-language model generalization by cumulatively learning multi-modal prototypes from unlabeled test data, outperforming current state-of-the-art&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/jsgyyxasis/cover.png"/></item><item><title>Easy-to-Hard Generalization: Scalable Alignment Beyond Human Supervision</title><link>https://deep-diver.github.io/neurips2024/posters/qwgfh2fttn/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/qwgfh2fttn/</guid><description>AI alignment beyond human supervision is achieved via easy-to-hard generalization: training reward models on easy tasks to effectively evaluate and improve generators on harder tasks, achieving superh&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/qwgfh2fttn/cover.png"/></item><item><title>Efficient LLM Jailbreak via Adaptive Dense-to-sparse Constrained Optimization</title><link>https://deep-diver.github.io/neurips2024/posters/bn5pa3hho8/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/bn5pa3hho8/</guid><description>Adaptive Dense-to-sparse Constrained Optimization (ADC) efficiently jailbreaks LLMs by transforming discrete token optimization into a continuous process, achieving higher success rates than existing &amp;hellip;</description></item><item><title>Federated Natural Policy Gradient and Actor Critic Methods for Multi-task Reinforcement Learning</title><link>https://deep-diver.github.io/neurips2024/posters/dufd6vsyf8/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/dufd6vsyf8/</guid><description>This paper introduces federated natural policy gradient and actor-critic methods achieving near dimension-free global convergence for decentralized multi-task reinforcement learning, a significant bre&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/dufd6vsyf8/cover.png"/></item><item><title>From Causal to Concept-Based Representation Learning</title><link>https://deep-diver.github.io/neurips2024/posters/r5nev2shtj/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/r5nev2shtj/</guid><description>This paper introduces a novel geometric approach to concept-based representation learning, provably recovering interpretable concepts from diverse data without strict causal assumptions or many interv&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/r5nev2shtj/cover.png"/></item><item><title>Identifying Latent State-Transition Processes for Individualized Reinforcement Learning</title><link>https://deep-diver.github.io/neurips2024/posters/krepcqthdn/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/krepcqthdn/</guid><description>This study introduces a novel framework for individualized reinforcement learning, guaranteeing the identifiability of latent factors influencing state transitions and providing a practical method for&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/krepcqthdn/cover.png"/></item><item><title>Implicit Regularization Paths of Weighted Neural Representations</title><link>https://deep-diver.github.io/neurips2024/posters/oxcmwwkqtz/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/oxcmwwkqtz/</guid><description>Weighted pretrained features implicitly regularize models, and this paper reveals equivalent paths between weighting schemes and ridge regularization, enabling efficient hyperparameter tuning.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/oxcmwwkqtz/cover.png"/></item><item><title>In-Context Learning with Representations: Contextual Generalization of Trained Transformers</title><link>https://deep-diver.github.io/neurips2024/posters/ik37kkxkbm/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/ik37kkxkbm/</guid><description>Transformers learn contextual information for generalization to unseen examples and tasks, even with limited training data, converging linearly to a global minimum.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/ik37kkxkbm/cover.png"/></item><item><title>Incremental Learning of Retrievable Skills For Efficient Continual Task Adaptation</title><link>https://deep-diver.github.io/neurips2024/posters/rcpajanpnm/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/rcpajanpnm/</guid><description>IsCiL: a novel adapter-based continual imitation learning framework that efficiently adapts to new tasks by incrementally learning and retrieving reusable skills.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/rcpajanpnm/cover.png"/></item><item><title>John Ellipsoids via Lazy Updates</title><link>https://deep-diver.github.io/neurips2024/posters/lcj0rvr4d6/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/lcj0rvr4d6/</guid><description>Faster John ellipsoid computation achieved via lazy updates and fast matrix multiplication, improving efficiency and enabling low-space streaming algorithms.</description></item><item><title>Learning Discrete Concepts in Latent Hierarchical Models</title><link>https://deep-diver.github.io/neurips2024/posters/bo5buxvh6m/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/bo5buxvh6m/</guid><description>This paper introduces a novel framework for learning discrete concepts from high-dimensional data, establishing theoretical conditions for identifying underlying hierarchical causal structures and pro&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/bo5buxvh6m/cover.png"/></item><item><title>Learning Social Welfare Functions</title><link>https://deep-diver.github.io/neurips2024/spotlight-ai-theory/7o6ktaar8n/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-ai-theory/7o6ktaar8n/</guid><description>Learning social welfare functions from past decisions is possible! This paper shows how to efficiently learn power mean functions, a widely used family, using both cardinal and pairwise welfare compar&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-ai-theory/7o6ktaar8n/cover.png"/></item><item><title>Learning to Reason Iteratively and Parallelly for Complex Visual Reasoning Scenarios</title><link>https://deep-diver.github.io/neurips2024/posters/uojq9qadjy/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/uojq9qadjy/</guid><description>Boosting complex visual reasoning, a new Iterative and Parallel Reasoning Mechanism (IPRM) outperforms existing methods by combining step-by-step and simultaneous computations, improving accuracy and &amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/uojq9qadjy/cover.png"/></item><item><title>Linear Causal Representation Learning from Unknown Multi-node Interventions</title><link>https://deep-diver.github.io/neurips2024/posters/weemasptzg/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/weemasptzg/</guid><description>Unlocking Causal Structures: New algorithms identify latent causal relationships from interventions, even when multiple variables are affected simultaneously.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/weemasptzg/cover.png"/></item><item><title>Lips Are Lying: Spotting the Temporal Inconsistency between Audio and Visual in Lip-Syncing DeepFakes</title><link>https://deep-diver.github.io/neurips2024/posters/yms7ansbr6/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/yms7ansbr6/</guid><description>LipFD: a novel method leverages audio-visual inconsistencies to accurately spot lip-syncing deepfakes, outperforming existing methods and introducing a high-quality dataset for future research.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/yms7ansbr6/cover.png"/></item><item><title>MAmmoTH2: Scaling Instructions from the Web</title><link>https://deep-diver.github.io/neurips2024/posters/yvu5dnplqa/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/yvu5dnplqa/</guid><description>MAmmoTH2: Harvesting 10M web instructions for enhanced LLM reasoning!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/yvu5dnplqa/cover.png"/></item><item><title>Markov Equivalence and Consistency in Differentiable Structure Learning</title><link>https://deep-diver.github.io/neurips2024/posters/tmlgqw7ebc/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/tmlgqw7ebc/</guid><description>Researchers developed a new, differentiable score function for learning causal relationships from data that reliably recovers the simplest causal model, even with complex data.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/tmlgqw7ebc/cover.png"/></item><item><title>MGF: Mixed Gaussian Flow for Diverse Trajectory Prediction</title><link>https://deep-diver.github.io/neurips2024/posters/muyhndlxwc/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/muyhndlxwc/</guid><description>MGF: Mixed Gaussian Flow enhances trajectory prediction by using a mixed Gaussian prior, achieving state-of-the-art diversity and alignment accuracy.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/muyhndlxwc/cover.png"/></item><item><title>Multi-Agent Imitation Learning: Value is Easy, Regret is Hard</title><link>https://deep-diver.github.io/neurips2024/posters/qk3ibhyv6z/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/qk3ibhyv6z/</guid><description>In multi-agent imitation learning, achieving regret equivalence is harder than value equivalence; this paper introduces novel algorithms that efficiently minimize the regret gap under various assumpti&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/qk3ibhyv6z/cover.png"/></item><item><title>No Free Lunch in LLM Watermarking: Trade-offs in Watermarking Design Choices</title><link>https://deep-diver.github.io/neurips2024/posters/riol7kbskv/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/riol7kbskv/</guid><description>LLM watermarking faces inherent trade-offs; this paper reveals simple attacks exploiting common design choices, proposing guidelines and defenses for more secure systems.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/riol7kbskv/cover.png"/></item><item><title>Pard: Permutation-Invariant Autoregressive Diffusion for Graph Generation</title><link>https://deep-diver.github.io/neurips2024/posters/x4kk4fxls3/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/x4kk4fxls3/</guid><description>PARD: a novel permutation-invariant autoregressive diffusion model for efficient and high-quality graph generation, achieving state-of-the-art results.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/x4kk4fxls3/cover.png"/></item><item><title>Predicting the Performance of Foundation Models via Agreement-on-the-Line</title><link>https://deep-diver.github.io/neurips2024/posters/ajx9onwsr4/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/ajx9onwsr4/</guid><description>Foundation model OOD performance prediction is reliably achieved via ensemble diversity, especially through random linear head initialization, enabling precise estimations without extensive OOD labels&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/ajx9onwsr4/cover.png"/></item><item><title>Protein-Nucleic Acid Complex Modeling with Frame Averaging Transformer</title><link>https://deep-diver.github.io/neurips2024/posters/xngi3z3wkn/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/xngi3z3wkn/</guid><description>Unsupervised learning predicts protein-nucleic acid binding using contact map prediction, significantly improving aptamer screening via FAFormer, a novel equivariant transformer.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/xngi3z3wkn/cover.png"/></item><item><title>Provably Robust Score-Based Diffusion Posterior Sampling for Plug-and-Play Image Reconstruction</title><link>https://deep-diver.github.io/neurips2024/posters/slnsoay4u1/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/slnsoay4u1/</guid><description>Provably robust diffusion posterior sampling for plug-and-play image reconstruction is achieved via a novel algorithmic framework, DPnP, offering both asymptotic and non-asymptotic performance guarant&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/slnsoay4u1/cover.png"/></item><item><title>Recursive Introspection: Teaching Language Model Agents How to Self-Improve</title><link>https://deep-diver.github.io/neurips2024/posters/drc9pzwbwr/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/drc9pzwbwr/</guid><description>RISE: Recursive Introspection teaches LLMs to iteratively improve their responses, enabling self-correction and enhanced performance on challenging reasoning tasks.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/drc9pzwbwr/cover.png"/></item><item><title>Regret Minimization in Stackelberg Games with Side Information</title><link>https://deep-diver.github.io/neurips2024/posters/rpkcrzdqjx/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/rpkcrzdqjx/</guid><description>This research shows how to improve Stackelberg game strategies by considering side information, achieving no-regret learning in online settings with stochastic contexts or followers.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/rpkcrzdqjx/cover.png"/></item><item><title>Rethinking LLM Memorization through the Lens of Adversarial Compression</title><link>https://deep-diver.github.io/neurips2024/posters/kfmrmvzazy/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/kfmrmvzazy/</guid><description>Researchers propose Adversarial Compression Ratio (ACR) to assess LLM memorization, offering an adversarial, flexible, and computationally efficient method for monitoring data misuse and compliance.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/kfmrmvzazy/cover.png"/></item><item><title>S$^{2}$FT: Efficient, Scalable and Generalizable LLM Fine-tuning by Structured Sparsity</title><link>https://deep-diver.github.io/neurips2024/posters/leule8s4xq/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/leule8s4xq/</guid><description>S2FT: Structured Sparse Fine-Tuning achieves state-of-the-art LLM fine-tuning performance, training efficiency, and inference scalability by selecting sparsely and computing densely.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/leule8s4xq/cover.png"/></item><item><title>Sample Complexity of Interventional Causal Representation Learning</title><link>https://deep-diver.github.io/neurips2024/posters/xl9aaxl0u6/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/xl9aaxl0u6/</guid><description>First finite-sample analysis of interventional causal representation learning shows that surprisingly few samples suffice for accurate graph and latent variable recovery.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/xl9aaxl0u6/cover.png"/></item><item><title>Sequoia: Scalable and Robust Speculative Decoding</title><link>https://deep-diver.github.io/neurips2024/spotlight-large-language-models/rk2l9ygdi2/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-large-language-models/rk2l9ygdi2/</guid><description>SEQUOIA: A novel algorithm boosts Large Language Model (LLM) inference speed by up to 9.5x using a scalable and robust speculative decoding approach!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-large-language-models/rk2l9ygdi2/cover.png"/></item><item><title>Slight Corruption in Pre-training Data Makes Better Diffusion Models</title><link>https://deep-diver.github.io/neurips2024/spotlight-others/vfpxybqmsu/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-others/vfpxybqmsu/</guid><description>Slightly corrupting pre-training data significantly improves diffusion models&amp;rsquo; image generation quality, diversity, and fidelity.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-others/vfpxybqmsu/cover.png"/></item><item><title>Sparse-view Pose Estimation and Reconstruction via Analysis by Generative Synthesis</title><link>https://deep-diver.github.io/neurips2024/posters/wgpmdyjgsg/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/wgpmdyjgsg/</guid><description>SparseAGS: High-fidelity 3D reconstruction &amp;amp; camera pose estimation from sparse views via generative synthesis.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/wgpmdyjgsg/cover.png"/></item><item><title>Synatra: Turning Indirect Knowledge into Direct Demonstrations for Digital Agents at Scale</title><link>https://deep-diver.github.io/neurips2024/posters/kjnezwriqn/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/kjnezwriqn/</guid><description>Synatra synthesizes high-quality digital agent training data from online tutorials and web pages, significantly improving agent performance on complex web-based tasks at a fraction of the cost of huma&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/kjnezwriqn/cover.png"/></item><item><title>Tactile DreamFusion: Exploiting Tactile Sensing for 3D Generation</title><link>https://deep-diver.github.io/neurips2024/posters/fa3rmml8ii/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/fa3rmml8ii/</guid><description>Tactile DreamFusion: High-resolution tactile sensing enhances 3D generation, creating realistic geometric details previously unattainable.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/fa3rmml8ii/cover.png"/></item><item><title>Test-Time Adaptation Induces Stronger Accuracy and Agreement-on-the-Line</title><link>https://deep-diver.github.io/neurips2024/posters/gixux4vh9t/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/gixux4vh9t/</guid><description>Test-time adaptation strengthens the linear correlation between in- and out-of-distribution accuracy, enabling precise OOD performance prediction and hyperparameter optimization without labeled OOD da&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/gixux4vh9t/cover.png"/></item><item><title>The Importance of Online Data: Understanding Preference Fine-tuning via Coverage</title><link>https://deep-diver.github.io/neurips2024/posters/hbj86rmdz8/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/hbj86rmdz8/</guid><description>Hybrid Preference Optimization (HyPO) outperforms existing offline methods for fine-tuning LLMs by leveraging both offline and online data, achieving better performance and efficiency.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/hbj86rmdz8/cover.png"/></item><item><title>The Sample-Communication Complexity Trade-off in Federated Q-Learning</title><link>https://deep-diver.github.io/neurips2024/oral-reinforcement-learning/6yipvnkjuk/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/oral-reinforcement-learning/6yipvnkjuk/</guid><description>Federated Q-learning achieves optimal sample &amp;amp; communication complexities simultaneously via Fed-DVR-Q, a novel algorithm.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/oral-reinforcement-learning/6yipvnkjuk/cover.png"/></item><item><title>Understanding Hallucinations in Diffusion Models through Mode Interpolation</title><link>https://deep-diver.github.io/neurips2024/posters/antnhbkw4t/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/antnhbkw4t/</guid><description>Diffusion models generate unrealistic images by smoothly interpolating between data modes; this paper identifies this &amp;lsquo;mode interpolation&amp;rsquo; failure and proposes a metric to detect and reduce it.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/antnhbkw4t/cover.png"/></item><item><title>Visual Data Diagnosis and Debiasing with Concept Graphs</title><link>https://deep-diver.github.io/neurips2024/posters/xngsx3wcu9/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/xngsx3wcu9/</guid><description>CONBIAS tackles dataset bias by representing visual data as concept graphs, diagnosing imbalances via clique analysis, and debiasing through targeted data augmentation for improved model generalizatio&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/xngsx3wcu9/cover.png"/></item><item><title>VLM Agents Generate Their Own Memories: Distilling Experience into Embodied Programs of Thought</title><link>https://deep-diver.github.io/neurips2024/spotlight-others/5g7mrfpngt/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-others/5g7mrfpngt/</guid><description>VLMs learn to generate their own memories by abstracting experiences from noisy demonstrations and human feedback, significantly boosting in-context learning performance.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-others/5g7mrfpngt/cover.png"/></item></channel></rss>