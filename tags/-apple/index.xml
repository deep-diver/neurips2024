<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>üè¢ Apple on NeurIPS 2024</title><link>https://deep-diver.github.io/neurips2024/tags/-apple/</link><description>Recent content in üè¢ Apple on NeurIPS 2024</description><generator>Hugo -- gohugo.io</generator><language>en</language><copyright>¬© 2024 AI Paper Reviewer</copyright><lastBuildDate>Thu, 26 Sep 2024 00:00:00 +0000</lastBuildDate><atom:link href="https://deep-diver.github.io/neurips2024/tags/-apple/index.xml" rel="self" type="application/rss+xml"/><item><title>Aggregate-and-Adapt Natural Language Prompts for Downstream Generalization of CLIP</title><link>https://deep-diver.github.io/neurips2024/posters/yz3wbkok0k/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/yz3wbkok0k/</guid><description>Aggregate-and-Adapt Prompt Embedding (AAPE) boosts CLIP&amp;rsquo;s downstream generalization by distilling textual knowledge from natural language prompts, achieving competitive performance across various visi&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/yz3wbkok0k/cover.png"/></item><item><title>Bridging semantics and pragmatics in information-theoretic emergent communication</title><link>https://deep-diver.github.io/neurips2024/posters/2wlnniqcb7/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/2wlnniqcb7/</guid><description>AI agents learn human-like communication, combining semantic categorization and pragmatic context-sensitive reasoning, through a novel information-theoretic framework.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/2wlnniqcb7/cover.png"/></item><item><title>Dataset Decomposition: Faster LLM Training with Variable Sequence Length Curriculum</title><link>https://deep-diver.github.io/neurips2024/posters/r8m9sfymdi/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/r8m9sfymdi/</guid><description>This paper introduces dataset decomposition (DD), a novel approach to accelerate LLM training while enhancing performance. DD significantly reduces training time by decomposing datasets into buckets &amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/r8m9sfymdi/cover.png"/></item><item><title>Grounding Multimodal Large Language Models in Actions</title><link>https://deep-diver.github.io/neurips2024/posters/0gl5wxy6es/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/0gl5wxy6es/</guid><description>Researchers unveil unified architecture for grounding multimodal large language models in actions, showing superior performance with learned tokenization for continuous actions and semantic alignment &amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/0gl5wxy6es/cover.png"/></item><item><title>How Far Can Transformers Reason? The Globality Barrier and Inductive Scratchpad</title><link>https://deep-diver.github.io/neurips2024/posters/fogwifxzun/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/fogwifxzun/</guid><description>Transformers struggle with complex reasoning tasks. This paper introduces &amp;lsquo;globality degree&amp;rsquo; to measure task difficulty and shows that high globality hinders efficient learning. However, using &amp;lsquo;induc&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/fogwifxzun/cover.png"/></item><item><title>Instance-Optimal Private Density Estimation in the Wasserstein Distance</title><link>https://deep-diver.github.io/neurips2024/posters/apq6corvfz/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/apq6corvfz/</guid><description>Instance-optimal private density estimation algorithms, adapting to data characteristics for improved accuracy in the Wasserstein distance, are introduced.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/apq6corvfz/cover.png"/></item><item><title>Kaleido Diffusion: Improving Conditional Diffusion Models with Autoregressive Latent Modeling</title><link>https://deep-diver.github.io/neurips2024/posters/qzswlclmcs/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/qzswlclmcs/</guid><description>Kaleido Diffusion boosts the diversity of images generated by diffusion models without sacrificing quality, using autoregressive latent modeling to add more control and interpretability to the image g&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/qzswlclmcs/cover.png"/></item><item><title>Learning Elastic Costs to Shape Monge Displacements</title><link>https://deep-diver.github.io/neurips2024/posters/aauvnpqvbz/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/aauvnpqvbz/</guid><description>Learn optimal transport maps with structured displacements using elastic costs and a novel bilevel loss function!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/aauvnpqvbz/cover.png"/></item><item><title>Private Online Learning via Lazy Algorithms</title><link>https://deep-diver.github.io/neurips2024/posters/fkf0oqud3q/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/fkf0oqud3q/</guid><description>New transformation boosts privacy in online learning!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/fkf0oqud3q/cover.png"/></item><item><title>Private Stochastic Convex Optimization with Heavy Tails: Near-Optimality from Simple Reductions</title><link>https://deep-diver.github.io/neurips2024/posters/ox6ail9f0y/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/ox6ail9f0y/</guid><description>Achieving near-optimal rates for differentially private stochastic convex optimization with heavy-tailed gradients is possible using simple reduction-based techniques.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/ox6ail9f0y/cover.png"/></item><item><title>Progressive Entropic Optimal Transport Solvers</title><link>https://deep-diver.github.io/neurips2024/posters/7wvwzuykuq/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/7wvwzuykuq/</guid><description>Progressive Entropic Optimal Transport (PROGOT) solvers efficiently and robustly compute optimal transport plans and maps, even at large scales, by progressively scheduling parameters.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/7wvwzuykuq/cover.png"/></item></channel></rss>