<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Large Language Models on NeurIPS 2024</title><link>https://deep-diver.github.io/neurips2024/tags/large-language-models/</link><description>Recent content in Large Language Models on NeurIPS 2024</description><generator>Hugo -- gohugo.io</generator><language>en</language><copyright>© 2024 AI Paper Reviewer</copyright><lastBuildDate>Thu, 26 Sep 2024 00:00:00 +0000</lastBuildDate><atom:link href="https://deep-diver.github.io/neurips2024/tags/large-language-models/index.xml" rel="self" type="application/rss+xml"/><item><title>A Phase Transition between Positional and Semantic Learning in a Solvable Model of Dot-Product Attention</title><link>https://deep-diver.github.io/neurips2024/spotlight-large-language-models/bfwdipplgz/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-large-language-models/bfwdipplgz/</guid><description>A solvable model reveals a phase transition in dot-product attention, showing how semantic attention emerges from positional attention with increased data, explaining the qualitative improvements in l&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-large-language-models/bfwdipplgz/cover.png"/></item><item><title>Aligner: Efficient Alignment by Learning to Correct</title><link>https://deep-diver.github.io/neurips2024/oral-large-language-models/kq166jacvp/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/oral-large-language-models/kq166jacvp/</guid><description>Aligner efficiently aligns LLMs by learning to correct initial responses, achieving significant improvements in helpfulness and harmlessness across various models with resource efficiency.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/oral-large-language-models/kq166jacvp/cover.png"/></item><item><title>An Analysis of Tokenization: Transformers under Markov Data</title><link>https://deep-diver.github.io/neurips2024/spotlight-large-language-models/wm9jzq7rce/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-large-language-models/wm9jzq7rce/</guid><description>Tokenization&amp;rsquo;s crucial role in transformer language models is revealed: Transformers struggle on simple Markov data &lt;em>without&lt;/em> tokenization, but achieve near-optimal performance &lt;em>with&lt;/em> appropriate tok&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-large-language-models/wm9jzq7rce/cover.png"/></item><item><title>Bridging The Gap between Low-rank and Orthogonal Adaptation via Householder Reflection Adaptation</title><link>https://deep-diver.github.io/neurips2024/spotlight-large-language-models/lzleaschnj/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-large-language-models/lzleaschnj/</guid><description>Householder Reflection Adaptation (HRA) bridges low-rank and orthogonal LLM adaptation, achieving superior performance with fewer parameters than existing methods. By using a chain of Householder refl&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-large-language-models/lzleaschnj/cover.png"/></item><item><title>Buffer of Thoughts: Thought-Augmented Reasoning with Large Language Models</title><link>https://deep-diver.github.io/neurips2024/spotlight-large-language-models/ano1i9jptb/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-large-language-models/ano1i9jptb/</guid><description>Buffer of Thoughts (BoT) boosts Large Language Model reasoning by storing and reusing high-level &amp;rsquo;thought-templates&amp;rsquo;, achieving significant accuracy and efficiency gains across diverse tasks.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-large-language-models/ano1i9jptb/cover.png"/></item><item><title>Co-occurrence is not Factual Association in Language Models</title><link>https://deep-diver.github.io/neurips2024/spotlight-large-language-models/xabstwautr/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-large-language-models/xabstwautr/</guid><description>Language models struggle to learn facts; this study reveals they prioritize word co-occurrence over true factual associations, proposing new training strategies for improved factual knowledge generali&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-large-language-models/xabstwautr/cover.png"/></item><item><title>DeTikZify: Synthesizing Graphics Programs for Scientific Figures and Sketches with TikZ</title><link>https://deep-diver.github.io/neurips2024/spotlight-large-language-models/bcvlfqcojc/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-large-language-models/bcvlfqcojc/</guid><description>DeTikZify: AI synthesizes publication-ready scientific figures from sketches and existing figures, automatically generating semantically-preserving TikZ code.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-large-language-models/bcvlfqcojc/cover.png"/></item><item><title>Discrete Flow Matching</title><link>https://deep-diver.github.io/neurips2024/spotlight-large-language-models/gtdko3sv9p/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-large-language-models/gtdko3sv9p/</guid><description>Discrete Flow Matching (DFM) revolutionizes discrete data generation by introducing a novel flow paradigm that surpasses existing methods. DFM leverages flexible probability paths, enabling efficient &amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-large-language-models/gtdko3sv9p/cover.png"/></item><item><title>Divide-and-Conquer Meets Consensus: Unleashing the Power of Functions in Code Generation</title><link>https://deep-diver.github.io/neurips2024/oral-large-language-models/cfqaaningw/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/oral-large-language-models/cfqaaningw/</guid><description>FUNCODER: a novel code generation framework that uses a divide-and-conquer approach with functional consensus to generate code that meets complex requirements.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/oral-large-language-models/cfqaaningw/cover.png"/></item><item><title>DuQuant: Distributing Outliers via Dual Transformation Makes Stronger Quantized LLMs</title><link>https://deep-diver.github.io/neurips2024/oral-large-language-models/mp8u2pcmqz/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/oral-large-language-models/mp8u2pcmqz/</guid><description>DuQuant: Dual transformations distribute outliers for stronger quantized LLMs.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/oral-large-language-models/mp8u2pcmqz/cover.png"/></item><item><title>Efficient Adversarial Training in LLMs with Continuous Attacks</title><link>https://deep-diver.github.io/neurips2024/spotlight-large-language-models/8jb6sgqvgq/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-large-language-models/8jb6sgqvgq/</guid><description>Boosting LLM robustness against attacks efficiently: Continuous adversarial training in embedding space outperforms discrete methods, achieving improved robustness with less computation.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-large-language-models/8jb6sgqvgq/cover.png"/></item><item><title>Ensemble Learning for Heterogeneous Large Language Models with Deep Parallel Collaboration</title><link>https://deep-diver.github.io/neurips2024/spotlight-large-language-models/7araaduk6d/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-large-language-models/7araaduk6d/</guid><description>DEEPEN: a training-free LLM ensemble framework fusing probability distributions in a relative space to overcome vocabulary misalignment, improving performance consistently across benchmarks.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-large-language-models/7araaduk6d/cover.png"/></item><item><title>Evaluating the World Model Implicit in a Generative Model</title><link>https://deep-diver.github.io/neurips2024/spotlight-large-language-models/avk4jfpegy/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-large-language-models/avk4jfpegy/</guid><description>New metrics reveal that generative models often possess surprisingly incoherent world models, despite seemingly accurate next-token predictions. This incoherence leads to fragility in solving related &amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-large-language-models/avk4jfpegy/cover.png"/></item><item><title>Exploring Context Window of Large Language Models via Decomposed Positional Vectors</title><link>https://deep-diver.github.io/neurips2024/spotlight-large-language-models/zeyyq0gpxo/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-large-language-models/zeyyq0gpxo/</guid><description>Researchers extended large language models&amp;rsquo; context windows by training-free methods via analyzing and manipulating positional vectors, improving long-text processing.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-large-language-models/zeyyq0gpxo/cover.png"/></item><item><title>FlashAttention-3: Fast and Accurate Attention with Asynchrony and Low-precision</title><link>https://deep-diver.github.io/neurips2024/spotlight-large-language-models/tvconyid20/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-large-language-models/tvconyid20/</guid><description>FlashAttention-3: Achieves 1.5-2x faster attention on H100 GPUs using asynchrony and low-precision, reaching 1.3 PFLOPs/s.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-large-language-models/tvconyid20/cover.png"/></item><item><title>Generated and Pseudo Content guided Prototype Refinement for Few-shot Point Cloud Segmentation</title><link>https://deep-diver.github.io/neurips2024/spotlight-large-language-models/tbvlqjdfca/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-large-language-models/tbvlqjdfca/</guid><description>LLM-powered prototype refinement boosts few-shot 3D point cloud segmentation accuracy.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-large-language-models/tbvlqjdfca/cover.png"/></item><item><title>Graph-based Uncertainty Metrics for Long-form Language Model Generations</title><link>https://deep-diver.github.io/neurips2024/spotlight-large-language-models/ygjpqw0lko/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-large-language-models/ygjpqw0lko/</guid><description>Graph Uncertainty boosts LLM factuality by 6.8% using graph centrality to estimate claim-level uncertainty and a novel uncertainty-aware decoding process.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-large-language-models/ygjpqw0lko/cover.png"/></item><item><title>GREATS: Online Selection of High-Quality Data for LLM Training in Every Iteration</title><link>https://deep-diver.github.io/neurips2024/spotlight-large-language-models/232vcn8tsx/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-large-language-models/232vcn8tsx/</guid><description>GREATS: a novel online batch selection method significantly speeds up LLM training by greedily selecting high-quality data batches in every iteration, improving both convergence and generalization per&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-large-language-models/232vcn8tsx/cover.png"/></item><item><title>HaloScope: Harnessing Unlabeled LLM Generations for Hallucination Detection</title><link>https://deep-diver.github.io/neurips2024/spotlight-large-language-models/nfk0zxffsn/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-large-language-models/nfk0zxffsn/</guid><description>HaloScope leverages unlabeled LLM outputs to accurately detect AI hallucinations without human annotation, significantly outperforming existing methods.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-large-language-models/nfk0zxffsn/cover.png"/></item><item><title>Heavy-Tailed Class Imbalance and Why Adam Outperforms Gradient Descent on Language Models</title><link>https://deep-diver.github.io/neurips2024/spotlight-large-language-models/t56j6av8oc/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-large-language-models/t56j6av8oc/</guid><description>Adam&amp;rsquo;s superior performance on language models stems from its resilience to heavy-tailed class imbalance, unlike SGD, which struggles with infrequent word losses.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-large-language-models/t56j6av8oc/cover.png"/></item><item><title>HydraLoRA: An Asymmetric LoRA Architecture for Efficient Fine-Tuning</title><link>https://deep-diver.github.io/neurips2024/oral-large-language-models/qepi8uwx3n/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/oral-large-language-models/qepi8uwx3n/</guid><description>HydraLoRA: Asymmetric LoRA boosts LLM fine-tuning efficiency by sharing parameters across tasks while specializing others, outperforming existing methods.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/oral-large-language-models/qepi8uwx3n/cover.png"/></item><item><title>Induced Model Matching: Restricted Models Help Train Full-Featured Models</title><link>https://deep-diver.github.io/neurips2024/spotlight-large-language-models/iw0wxe0vyr/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-large-language-models/iw0wxe0vyr/</guid><description>Restricted models often outperform full-featured models when training data is limited. This paper introduces Induced Model Matching (IMM), a novel technique that uses a restricted model as a guide to&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-large-language-models/iw0wxe0vyr/cover.png"/></item><item><title>Learn To be Efficient: Build Structured Sparsity in Large Language Models</title><link>https://deep-diver.github.io/neurips2024/spotlight-large-language-models/isfcwhvega/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-large-language-models/isfcwhvega/</guid><description>Learn-To-be-Efficient (LTE) trains LLMs to achieve structured sparsity, boosting inference speed by 25% at 50% sparsity without sacrificing accuracy.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-large-language-models/isfcwhvega/cover.png"/></item><item><title>Learning to grok: Emergence of in-context learning and skill composition in modular arithmetic tasks</title><link>https://deep-diver.github.io/neurips2024/oral-large-language-models/avh9krzdrk/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/oral-large-language-models/avh9krzdrk/</guid><description>Large language models surprisingly solve unseen arithmetic tasks; this work reveals how they learn to compose simple skills into complex ones through in-context learning, showing a transition from mem&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/oral-large-language-models/avh9krzdrk/cover.png"/></item><item><title>LLM Evaluators Recognize and Favor Their Own Generations</title><link>https://deep-diver.github.io/neurips2024/oral-large-language-models/4njbv6wp0h/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/oral-large-language-models/4njbv6wp0h/</guid><description>LLMs show self-preference bias in evaluations, favoring their own outputs. This study reveals that LLMs surprisingly recognize their own generations, and this self-recognition directly causes the self&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/oral-large-language-models/4njbv6wp0h/cover.png"/></item><item><title>Localized Zeroth-Order Prompt Optimization</title><link>https://deep-diver.github.io/neurips2024/spotlight-large-language-models/hs1jvv3dk3/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-large-language-models/hs1jvv3dk3/</guid><description>Localized Zeroth-Order Prompt Optimization (ZOPO) efficiently finds high-performing local optima for prompt optimization in black-box LLMs, outperforming existing global optimization methods.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-large-language-models/hs1jvv3dk3/cover.png"/></item><item><title>Many-Shot In-Context Learning</title><link>https://deep-diver.github.io/neurips2024/spotlight-large-language-models/ab6xpmzvqh/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-large-language-models/ab6xpmzvqh/</guid><description>Scaling up in-context learning using thousands of examples significantly boosts Large Language Model (LLM) performance, particularly for complex tasks. Novel training methods mitigate reliance on hum&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-large-language-models/ab6xpmzvqh/cover.png"/></item><item><title>MaskLLM: Learnable Semi-Structured Sparsity for Large Language Models</title><link>https://deep-diver.github.io/neurips2024/spotlight-large-language-models/llu9njal7b/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-large-language-models/llu9njal7b/</guid><description>MaskLLM learns efficient semi-structured sparsity in LLMs via end-to-end training, achieving significant speedup and memory reduction without sacrificing performance.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-large-language-models/llu9njal7b/cover.png"/></item><item><title>MetaLA: Unified Optimal Linear Approximation to Softmax Attention Map</title><link>https://deep-diver.github.io/neurips2024/oral-large-language-models/y8yvcomepz/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/oral-large-language-models/y8yvcomepz/</guid><description>MetaLA: Unified optimal linear approximation to softmax attention map, achieving linear complexity and surpassing existing models in various benchmarks.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/oral-large-language-models/y8yvcomepz/cover.png"/></item><item><title>MInference 1.0: Accelerating Pre-filling for Long-Context LLMs via Dynamic Sparse Attention</title><link>https://deep-diver.github.io/neurips2024/spotlight-large-language-models/fpbacabqsn/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-large-language-models/fpbacabqsn/</guid><description>MInference 1.0 accelerates LLM pre-filling via dynamic sparse attention, achieving up to 10x speedup on an A100 GPU while maintaining accuracy.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-large-language-models/fpbacabqsn/cover.png"/></item><item><title>MKGL: Mastery of a Three-Word Language</title><link>https://deep-diver.github.io/neurips2024/spotlight-large-language-models/eqmnwxvoqn/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-large-language-models/eqmnwxvoqn/</guid><description>Researchers taught a large language model (LLM) a three-word &amp;lsquo;Knowledge Graph Language&amp;rsquo; (KGL) to improve knowledge graph (KG) completion, drastically reducing errors compared to other methods.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-large-language-models/eqmnwxvoqn/cover.png"/></item><item><title>Model Fusion through Bayesian Optimization in Language Model Fine-Tuning</title><link>https://deep-diver.github.io/neurips2024/spotlight-large-language-models/lv4kthtgpj/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-large-language-models/lv4kthtgpj/</guid><description>Bayesian Optimization Model Fusion (BOMF) significantly boosts language model fine-tuning by optimizing both loss and metrics through multi-objective Bayesian optimization, yielding considerable perfo&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-large-language-models/lv4kthtgpj/cover.png"/></item><item><title>Not All Tokens Are What You Need for Pretraining</title><link>https://deep-diver.github.io/neurips2024/oral-large-language-models/0nmzbwqaaj/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/oral-large-language-models/0nmzbwqaaj/</guid><description>RHO-1, a novel language model, uses selective pretraining focusing on high-value tokens, achieving state-of-the-art results with significantly less data than existing models.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/oral-large-language-models/0nmzbwqaaj/cover.png"/></item><item><title>Observational Scaling Laws and the Predictability of Langauge Model Performance</title><link>https://deep-diver.github.io/neurips2024/spotlight-large-language-models/on5win7xyd/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-large-language-models/on5win7xyd/</guid><description>Researchers predict language model performance by observing existing models, bypassing costly training, revealing surprising predictability in complex scaling phenomena.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-large-language-models/on5win7xyd/cover.png"/></item><item><title>One-Shot Safety Alignment for Large Language Models via Optimal Dualization</title><link>https://deep-diver.github.io/neurips2024/spotlight-large-language-models/da7hum4css/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-large-language-models/da7hum4css/</guid><description>One-shot dualization aligns large language models with safety constraints efficiently, eliminating iterative primal-dual methods for improved stability and reduced computational burden.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-large-language-models/da7hum4css/cover.png"/></item><item><title>PiSSA: Principal Singular Values and Singular Vectors Adaptation of Large Language Models</title><link>https://deep-diver.github.io/neurips2024/spotlight-large-language-models/6zbhietdp4/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-large-language-models/6zbhietdp4/</guid><description>PiSSA, a novel parameter-efficient fine-tuning method, surpasses LoRA by initializing adapter matrices using the principal components of the original model, achieving faster convergence and enhanced p&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-large-language-models/6zbhietdp4/cover.png"/></item><item><title>Policy Learning from Tutorial Books via Understanding, Rehearsing and Introspecting</title><link>https://deep-diver.github.io/neurips2024/oral-large-language-models/ddak3nsqqm/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/oral-large-language-models/ddak3nsqqm/</guid><description>Researchers developed Policy Learning from tutorial Books (PLfB), a novel method that trains AI agents using knowledge from tutorial books instead of relying solely on real-world data.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/oral-large-language-models/ddak3nsqqm/cover.png"/></item><item><title>PV-Tuning: Beyond Straight-Through Estimation for Extreme LLM Compression</title><link>https://deep-diver.github.io/neurips2024/oral-large-language-models/yva8uf0i37/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/oral-large-language-models/yva8uf0i37/</guid><description>PV-Tuning achieves new state-of-the-art in extreme LLM compression by going beyond traditional straight-through estimators (STE). This novel framework provides a more accurate and efficient fine-tunin&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/oral-large-language-models/yva8uf0i37/cover.png"/></item><item><title>QTIP: Quantization with Trellises and Incoherence Processing</title><link>https://deep-diver.github.io/neurips2024/spotlight-large-language-models/7sdklvuycu/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-large-language-models/7sdklvuycu/</guid><description>QTIP: Ultra-high dimensional LLM quantization using trellis codes for faster, higher-quality inference.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-large-language-models/7sdklvuycu/cover.png"/></item><item><title>Questioning the Survey Responses of Large Language Models</title><link>https://deep-diver.github.io/neurips2024/oral-large-language-models/oo7dllgqqx/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/oral-large-language-models/oo7dllgqqx/</guid><description>LLM survey responses are systematically biased, often masking genuine model capabilities and leading to misleading alignment conclusions.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/oral-large-language-models/oo7dllgqqx/cover.png"/></item><item><title>ReFT: Representation Finetuning for Language Models</title><link>https://deep-diver.github.io/neurips2024/spotlight-large-language-models/fykjplmc0v/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-large-language-models/fykjplmc0v/</guid><description>ReFT: Revolutionizing language model finetuning by directly manipulating hidden representations, achieving superior efficiency and performance compared to existing methods.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-large-language-models/fykjplmc0v/cover.png"/></item><item><title>Reranking Laws for Language Generation: A Communication-Theoretic Perspective</title><link>https://deep-diver.github.io/neurips2024/spotlight-large-language-models/rhcgiznupi/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-large-language-models/rhcgiznupi/</guid><description>Boost LLM reliability by adding redundancy! This paper uses a communication theory framework to show that generating multiple LLM outputs and reranking them significantly reduces errors, even with imp&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-large-language-models/rhcgiznupi/cover.png"/></item><item><title>Resolving Discrepancies in Compute-Optimal Scaling of Language Models</title><link>https://deep-diver.github.io/neurips2024/spotlight-large-language-models/4fssqpk1sm/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-large-language-models/4fssqpk1sm/</guid><description>New research resolves discrepancies in language model scaling laws, revealing three key factors driving the differences and improving accuracy in predicting optimal model size based on compute budget.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-large-language-models/4fssqpk1sm/cover.png"/></item><item><title>Robust Prompt Optimization for Defending Language Models Against Jailbreaking Attacks</title><link>https://deep-diver.github.io/neurips2024/spotlight-large-language-models/jxs6cvpe7k/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-large-language-models/jxs6cvpe7k/</guid><description>Robust Prompt Optimization (RPO) creates robust LLM defenses against jailbreaking attacks by optimizing a transferable suffix, achieving state-of-the-art robustness.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-large-language-models/jxs6cvpe7k/cover.png"/></item><item><title>Rule Extrapolation in Language Modeling: A Study of Compositional Generalization on OOD Prompts</title><link>https://deep-diver.github.io/neurips2024/spotlight-large-language-models/li2rprzwjy/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-large-language-models/li2rprzwjy/</guid><description>LLMs struggle with out-of-distribution (OOD) generalization. This research introduces &amp;lsquo;rule extrapolation&amp;rsquo; using formal languages to rigorously evaluate OOD behavior in various LLM architectures, rev&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-large-language-models/li2rprzwjy/cover.png"/></item><item><title>Scaling Laws and Compute-Optimal Training Beyond Fixed Training Durations</title><link>https://deep-diver.github.io/neurips2024/spotlight-large-language-models/y13gsftjgr/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-large-language-models/y13gsftjgr/</guid><description>Revolutionizing LLM training: Constant learning rate with cooldown replaces cosine schedule, enabling cost-effective scaling experiments!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-large-language-models/y13gsftjgr/cover.png"/></item><item><title>Selective Generation for Controllable Language Models</title><link>https://deep-diver.github.io/neurips2024/spotlight-large-language-models/glfyoazh2f/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-large-language-models/glfyoazh2f/</guid><description>Certified selective generation controls language model hallucinations by leveraging textual entailment and a novel semi-supervised algorithm, guaranteeing a controlled false discovery rate.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-large-language-models/glfyoazh2f/cover.png"/></item><item><title>Sequoia: Scalable and Robust Speculative Decoding</title><link>https://deep-diver.github.io/neurips2024/spotlight-large-language-models/rk2l9ygdi2/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-large-language-models/rk2l9ygdi2/</guid><description>SEQUOIA: A novel algorithm boosts Large Language Model (LLM) inference speed by up to 9.5x using a scalable and robust speculative decoding approach!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-large-language-models/rk2l9ygdi2/cover.png"/></item><item><title>Stacking Your Transformers: A Closer Look at Model Growth for Efficient LLM Pre-Training</title><link>https://deep-diver.github.io/neurips2024/spotlight-large-language-models/fxjdcrimyh/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-large-language-models/fxjdcrimyh/</guid><description>Stacking Your Transformers accelerates LLM pre-training by leveraging smaller, pre-trained models to efficiently train larger ones, achieving significant speedups and improved performance.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-large-language-models/fxjdcrimyh/cover.png"/></item><item><title>Time-Reversal Provides Unsupervised Feedback to LLMs</title><link>https://deep-diver.github.io/neurips2024/spotlight-large-language-models/ny0brzdqlt/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-large-language-models/ny0brzdqlt/</guid><description>Time-reversed language models provide unsupervised feedback for improving LLMs, offering a cost-effective alternative to human feedback and enhancing LLM safety.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-large-language-models/ny0brzdqlt/cover.png"/></item><item><title>TOPA: Extending Large Language Models for Video Understanding via Text-Only Pre-Alignment</title><link>https://deep-diver.github.io/neurips2024/spotlight-large-language-models/5nmbqpy7bn/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-large-language-models/5nmbqpy7bn/</guid><description>TOPA: Extending LLMs for video understanding using only text data.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-large-language-models/5nmbqpy7bn/cover.png"/></item><item><title>Toxicity Detection for Free</title><link>https://deep-diver.github.io/neurips2024/spotlight-large-language-models/5a27ee8lxx/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-large-language-models/5a27ee8lxx/</guid><description>Moderation Using LLM Introspection (MULI) leverages the first response token&amp;rsquo;s logits from LLMs to create a highly accurate toxicity detector, surpassing state-of-the-art methods with minimal overhead&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-large-language-models/5a27ee8lxx/cover.png"/></item><item><title>Training Compute-Optimal Protein Language Models</title><link>https://deep-diver.github.io/neurips2024/spotlight-large-language-models/uczi8gsfd4/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-large-language-models/uczi8gsfd4/</guid><description>Compute-optimal protein language models are trained efficiently using scaling laws derived from a massive dataset, improving performance while optimizing compute budgets.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-large-language-models/uczi8gsfd4/cover.png"/></item><item><title>Unlocking the Capabilities of Thought: A Reasoning Boundary Framework to Quantify and Optimize Chain-of-Thought</title><link>https://deep-diver.github.io/neurips2024/oral-large-language-models/pc44umwy2v/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/oral-large-language-models/pc44umwy2v/</guid><description>Reasoning Boundary Framework (RBF) quantitatively assesses and optimizes chain-of-thought (CoT) in LLMs, offering novel metrics and optimization strategies validated across various models and tasks.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/oral-large-language-models/pc44umwy2v/cover.png"/></item><item><title>Unlocking Tokens as Data Points for Generalization Bounds on Larger Language Models</title><link>https://deep-diver.github.io/neurips2024/spotlight-large-language-models/5jru8ufi8h/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-large-language-models/5jru8ufi8h/</guid><description>Unlocking tight generalization bounds for massive LLMs using a novel token-level approach.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-large-language-models/5jru8ufi8h/cover.png"/></item><item><title>Watermarking Makes Language Models Radioactive</title><link>https://deep-diver.github.io/neurips2024/spotlight-large-language-models/qgizqb1khm/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-large-language-models/qgizqb1khm/</guid><description>LLM watermarking leaves detectable traces in subsequently trained models, enabling detection of synthetic data usage—a phenomenon termed &amp;lsquo;radioactivity&amp;rsquo;.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-large-language-models/qgizqb1khm/cover.png"/></item><item><title>Who's asking? User personas and the mechanics of latent misalignment</title><link>https://deep-diver.github.io/neurips2024/spotlight-large-language-models/eses1mic9d/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-large-language-models/eses1mic9d/</guid><description>User personas significantly impact the safety of large language models, bypassing safety filters more effectively than direct prompting methods.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-large-language-models/eses1mic9d/cover.png"/></item><item><title>xLSTM: Extended Long Short-Term Memory</title><link>https://deep-diver.github.io/neurips2024/spotlight-large-language-models/araxppiahq/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-large-language-models/araxppiahq/</guid><description>XLSTM: Extended Long Short-Term Memory, introduces exponential gating and novel memory structures to overcome LSTM limitations, achieving performance comparable to state-of-the-art Transformers and St&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-large-language-models/araxppiahq/cover.png"/></item><item><title>You Only Cache Once: Decoder-Decoder Architectures for Language Models</title><link>https://deep-diver.github.io/neurips2024/oral-large-language-models/25ioxw576r/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/oral-large-language-models/25ioxw576r/</guid><description>YOCO: A decoder-decoder architecture for LLMs dramatically reduces memory usage and improves inference speed by caching key-value pairs only once.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/oral-large-language-models/25ioxw576r/cover.png"/></item></channel></rss>