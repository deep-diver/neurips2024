<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Large Language Models on NeurIPS 2024</title><link>https://deep-diver.github.io/neurips2024/tags/large-language-models/</link><description>Recent content in Large Language Models on NeurIPS 2024</description><generator>Hugo -- gohugo.io</generator><language>en</language><copyright>Â© 2024 AI Paper Reviewer</copyright><lastBuildDate>Thu, 26 Sep 2024 00:00:00 +0000</lastBuildDate><atom:link href="https://deep-diver.github.io/neurips2024/tags/large-language-models/index.xml" rel="self" type="application/rss+xml"/><item><title>Aligner: Efficient Alignment by Learning to Correct</title><link>https://deep-diver.github.io/neurips2024/oral/kq166jacvp/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/oral/kq166jacvp/</guid><description>Aligner efficiently aligns LLMs by learning to correct initial responses, achieving significant improvements in helpfulness and harmlessness across various models with resource efficiency.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/oral/kq166jacvp/cover.png"/></item><item><title>Divide-and-Conquer Meets Consensus: Unleashing the Power of Functions in Code Generation</title><link>https://deep-diver.github.io/neurips2024/oral/cfqaaningw/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/oral/cfqaaningw/</guid><description>FUNCODER: a novel code generation framework that uses a divide-and-conquer approach with functional consensus to generate code that meets complex requirements.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/oral/cfqaaningw/cover.png"/></item><item><title>DuQuant: Distributing Outliers via Dual Transformation Makes Stronger Quantized LLMs</title><link>https://deep-diver.github.io/neurips2024/oral/mp8u2pcmqz/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/oral/mp8u2pcmqz/</guid><description>DuQuant: Dual transformations distribute outliers for stronger quantized LLMs.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/oral/mp8u2pcmqz/cover.png"/></item><item><title>HydraLoRA: An Asymmetric LoRA Architecture for Efficient Fine-Tuning</title><link>https://deep-diver.github.io/neurips2024/oral/qepi8uwx3n/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/oral/qepi8uwx3n/</guid><description>HydraLoRA: Asymmetric LoRA boosts LLM fine-tuning efficiency by sharing parameters across tasks while specializing others, outperforming existing methods.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/oral/qepi8uwx3n/cover.png"/></item><item><title>Learning to grok: Emergence of in-context learning and skill composition in modular arithmetic tasks</title><link>https://deep-diver.github.io/neurips2024/oral/avh9krzdrk/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/oral/avh9krzdrk/</guid><description>Large language models surprisingly solve unseen arithmetic tasks; this work reveals how they learn to compose simple skills into complex ones through in-context learning, showing a transition from mem&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/oral/avh9krzdrk/cover.png"/></item><item><title>LLM Evaluators Recognize and Favor Their Own Generations</title><link>https://deep-diver.github.io/neurips2024/oral/4njbv6wp0h/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/oral/4njbv6wp0h/</guid><description>LLMs show self-preference bias in evaluations, favoring their own outputs. This study reveals that LLMs surprisingly recognize their own generations, and this self-recognition directly causes the self&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/oral/4njbv6wp0h/cover.png"/></item><item><title>MetaLA: Unified Optimal Linear Approximation to Softmax Attention Map</title><link>https://deep-diver.github.io/neurips2024/oral/y8yvcomepz/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/oral/y8yvcomepz/</guid><description>MetaLA: Unified optimal linear approximation to softmax attention map, achieving linear complexity and surpassing existing models in various benchmarks.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/oral/y8yvcomepz/cover.png"/></item><item><title>Not All Tokens Are What You Need for Pretraining</title><link>https://deep-diver.github.io/neurips2024/oral/0nmzbwqaaj/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/oral/0nmzbwqaaj/</guid><description>RHO-1, a novel language model, uses selective pretraining focusing on high-value tokens, achieving state-of-the-art results with significantly less data than existing models.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/oral/0nmzbwqaaj/cover.png"/></item><item><title>Policy Learning from Tutorial Books via Understanding, Rehearsing and Introspecting</title><link>https://deep-diver.github.io/neurips2024/oral/ddak3nsqqm/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/oral/ddak3nsqqm/</guid><description>Researchers developed Policy Learning from tutorial Books (PLfB), a novel method that trains AI agents using knowledge from tutorial books instead of relying solely on real-world data.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/oral/ddak3nsqqm/cover.png"/></item><item><title>PV-Tuning: Beyond Straight-Through Estimation for Extreme LLM Compression</title><link>https://deep-diver.github.io/neurips2024/oral/yva8uf0i37/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/oral/yva8uf0i37/</guid><description>PV-Tuning achieves new state-of-the-art in extreme LLM compression by going beyond traditional straight-through estimators (STE). This novel framework provides a more accurate and efficient fine-tunin&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/oral/yva8uf0i37/cover.png"/></item><item><title>Questioning the Survey Responses of Large Language Models</title><link>https://deep-diver.github.io/neurips2024/oral/oo7dllgqqx/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/oral/oo7dllgqqx/</guid><description>LLM survey responses are systematically biased, often masking genuine model capabilities and leading to misleading alignment conclusions.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/oral/oo7dllgqqx/cover.png"/></item><item><title>Unlocking the Capabilities of Thought: A Reasoning Boundary Framework to Quantify and Optimize Chain-of-Thought</title><link>https://deep-diver.github.io/neurips2024/oral/pc44umwy2v/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/oral/pc44umwy2v/</guid><description>Reasoning Boundary Framework (RBF) quantitatively assesses and optimizes chain-of-thought (CoT) in LLMs, offering novel metrics and optimization strategies validated across various models and tasks.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/oral/pc44umwy2v/cover.png"/></item><item><title>You Only Cache Once: Decoder-Decoder Architectures for Language Models</title><link>https://deep-diver.github.io/neurips2024/oral/25ioxw576r/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/oral/25ioxw576r/</guid><description>YOCO: A decoder-decoder architecture for LLMs dramatically reduces memory usage and improves inference speed by caching key-value pairs only once.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/oral/25ioxw576r/cover.png"/></item></channel></rss>