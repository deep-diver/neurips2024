<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Large Language Models on NeurIPS 2024</title><link>https://deep-diver.github.io/neurips2024/tags/large-language-models/</link><description>Recent content in Large Language Models on NeurIPS 2024</description><generator>Hugo -- gohugo.io</generator><language>en</language><copyright>Â© 2024 AI Paper Reviewer</copyright><lastBuildDate>Thu, 26 Sep 2024 00:00:00 +0000</lastBuildDate><atom:link href="https://deep-diver.github.io/neurips2024/tags/large-language-models/index.xml" rel="self" type="application/rss+xml"/><item><title>A Phase Transition between Positional and Semantic Learning in a Solvable Model of Dot-Product Attention</title><link>https://deep-diver.github.io/neurips2024/spotlight-large-language-models/bfwdipplgz/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-large-language-models/bfwdipplgz/</guid><description>A solvable model reveals a phase transition in dot-product attention, showing how semantic attention emerges from positional attention with increased data, explaining the qualitative improvements in l&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-large-language-models/bfwdipplgz/cover.png"/></item><item><title>A teacher-teacher framework for clinical language representation learning</title><link>https://deep-diver.github.io/neurips2024/posters/zdad8zv8tg/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/zdad8zv8tg/</guid><description>A lightweight knowledge alignment module enables two pre-trained LLMs to mutually learn and improve clinical language representation, exceeding individual model performance on various downstream tasks&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/zdad8zv8tg/cover.png"/></item><item><title>A Theoretical Perspective for Speculative Decoding Algorithm</title><link>https://deep-diver.github.io/neurips2024/posters/wsqpnemvlu/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/wsqpnemvlu/</guid><description>This paper theoretically analyzes speculative decoding, revealing its optimality and providing formulas for expected rejections, paving the way for more efficient large language model inference.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/wsqpnemvlu/cover.png"/></item><item><title>Adversarial Representation Engineering: A General Model Editing Framework for Large Language Models</title><link>https://deep-diver.github.io/neurips2024/posters/dq9ji8e9qq/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/dq9ji8e9qq/</guid><description>Adversarial Representation Engineering (ARE) offers a unified, interpretable approach for editing large language models (LLMs) by using a representation sensor as an editing oracle, enhancing model sa&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/dq9ji8e9qq/cover.png"/></item><item><title>Aligner: Efficient Alignment by Learning to Correct</title><link>https://deep-diver.github.io/neurips2024/oral-large-language-models/kq166jacvp/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/oral-large-language-models/kq166jacvp/</guid><description>Aligner efficiently aligns LLMs by learning to correct initial responses, achieving significant improvements in helpfulness and harmlessness across various models with resource efficiency.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/oral-large-language-models/kq166jacvp/cover.png"/></item><item><title>Aligning to Thousands of Preferences via System Message Generalization</title><link>https://deep-diver.github.io/neurips2024/posters/recsheq7e8/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/recsheq7e8/</guid><description>JANUS, a 7B LLM, achieves high alignment to thousands of user preferences by generalizing from diverse system messages, outperforming existing LLMs on various benchmarks.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/recsheq7e8/cover.png"/></item><item><title>An Analysis of Tokenization: Transformers under Markov Data</title><link>https://deep-diver.github.io/neurips2024/spotlight-large-language-models/wm9jzq7rce/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-large-language-models/wm9jzq7rce/</guid><description>Tokenization&amp;rsquo;s crucial role in transformer language models is revealed: Transformers struggle on simple Markov data &lt;em>without&lt;/em> tokenization, but achieve near-optimal performance &lt;em>with&lt;/em> appropriate tok&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-large-language-models/wm9jzq7rce/cover.png"/></item><item><title>Boosting the Potential of Large Language Models with an Intelligent Information Assistant</title><link>https://deep-diver.github.io/neurips2024/posters/ozy4a11sug/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/ozy4a11sug/</guid><description>Boosting LLMs with an intelligent information assistant, ASSISTRAG, significantly improves accuracy and reasoning, especially for less advanced models.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/ozy4a11sug/cover.png"/></item><item><title>Bridging The Gap between Low-rank and Orthogonal Adaptation via Householder Reflection Adaptation</title><link>https://deep-diver.github.io/neurips2024/spotlight-large-language-models/lzleaschnj/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-large-language-models/lzleaschnj/</guid><description>Householder Reflection Adaptation (HRA) bridges low-rank and orthogonal LLM adaptation, achieving superior performance with fewer parameters than existing methods. By using a chain of Householder refl&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-large-language-models/lzleaschnj/cover.png"/></item><item><title>Buffer of Thoughts: Thought-Augmented Reasoning with Large Language Models</title><link>https://deep-diver.github.io/neurips2024/spotlight-large-language-models/ano1i9jptb/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-large-language-models/ano1i9jptb/</guid><description>Buffer of Thoughts (BoT) boosts Large Language Model reasoning by storing and reusing high-level &amp;rsquo;thought-templates&amp;rsquo;, achieving significant accuracy and efficiency gains across diverse tasks.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-large-language-models/ano1i9jptb/cover.png"/></item><item><title>Calibrating Reasoning in Language Models with Internal Consistency</title><link>https://deep-diver.github.io/neurips2024/posters/udzkvmpf3s/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/udzkvmpf3s/</guid><description>LLMs&amp;rsquo; reasoning can be improved by using internal consistency to calibrate their outputs.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/udzkvmpf3s/cover.png"/></item><item><title>Can Graph Learning Improve Planning in LLM-based Agents?</title><link>https://deep-diver.github.io/neurips2024/posters/bmos6ggw4j/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/bmos6ggw4j/</guid><description>GNNs enhance LLM-based task planning by improving the ability to process task graphs, surpassing existing solutions even without training.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/bmos6ggw4j/cover.png"/></item><item><title>Can Language Models Learn to Skip Steps?</title><link>https://deep-diver.github.io/neurips2024/posters/w4antvxao9/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/w4antvxao9/</guid><description>Language models learn to skip steps in reasoning, improving efficiency and generalization, showcasing emergent human-like cognitive abilities.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/w4antvxao9/cover.png"/></item><item><title>Co-occurrence is not Factual Association in Language Models</title><link>https://deep-diver.github.io/neurips2024/spotlight-large-language-models/xabstwautr/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-large-language-models/xabstwautr/</guid><description>Language models struggle to learn facts; this study reveals they prioritize word co-occurrence over true factual associations, proposing new training strategies for improved factual knowledge generali&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-large-language-models/xabstwautr/cover.png"/></item><item><title>Code Repair with LLMs gives an Exploration-Exploitation Tradeoff</title><link>https://deep-diver.github.io/neurips2024/posters/o863gx6dxa/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/o863gx6dxa/</guid><description>New program synthesis method, REX, leverages Thompson Sampling to balance exploration and exploitation in iterative LLM code refinement, solving more problems with fewer model calls.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/o863gx6dxa/cover.png"/></item><item><title>Compositional 3D-aware Video Generation with LLM Director</title><link>https://deep-diver.github.io/neurips2024/posters/oqdy2efrja/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/oqdy2efrja/</guid><description>LLM-directed compositional 3D-aware video generation (C3V) achieves high-fidelity video generation with diverse motion and flexible concept control by decomposing prompts, generating 3D concepts, and &amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/oqdy2efrja/cover.png"/></item><item><title>Context-Aware Testing: A New Paradigm for Model Testing with Large Language Models</title><link>https://deep-diver.github.io/neurips2024/posters/d75qczb7tx/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/d75qczb7tx/</guid><description>Context-Aware Testing (CAT) revolutionizes ML model testing by using contextual information to identify relevant failures, surpassing traditional data-only methods.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/d75qczb7tx/cover.png"/></item><item><title>DART-Math: Difficulty-Aware Rejection Tuning for Mathematical Problem-Solving</title><link>https://deep-diver.github.io/neurips2024/posters/zlu21oqjd5/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/zlu21oqjd5/</guid><description>DART-Math tackles LLM limitations in mathematical problem-solving by introducing Difficulty-Aware Rejection Tuning, a novel method that generates high-quality, bias-reduced datasets, resulting in supe&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/zlu21oqjd5/cover.png"/></item><item><title>Dataset Decomposition: Faster LLM Training with Variable Sequence Length Curriculum</title><link>https://deep-diver.github.io/neurips2024/posters/r8m9sfymdi/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/r8m9sfymdi/</guid><description>This paper introduces dataset decomposition (DD), a novel approach to accelerate LLM training while enhancing performance. DD significantly reduces training time by decomposing datasets into buckets &amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/r8m9sfymdi/cover.png"/></item><item><title>DeTikZify: Synthesizing Graphics Programs for Scientific Figures and Sketches with TikZ</title><link>https://deep-diver.github.io/neurips2024/spotlight-large-language-models/bcvlfqcojc/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-large-language-models/bcvlfqcojc/</guid><description>DeTikZify: AI synthesizes publication-ready scientific figures from sketches and existing figures, automatically generating semantically-preserving TikZ code.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-large-language-models/bcvlfqcojc/cover.png"/></item><item><title>Discovery of the Hidden World with Large Language Models</title><link>https://deep-diver.github.io/neurips2024/posters/w50icqc6qj/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/w50icqc6qj/</guid><description>COAT leverages LLMs to identify high-level causal factors from unstructured data, enabling causal discovery in real-world scenarios where well-defined variables are lacking.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/w50icqc6qj/cover.png"/></item><item><title>Discrete Flow Matching</title><link>https://deep-diver.github.io/neurips2024/spotlight-large-language-models/gtdko3sv9p/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-large-language-models/gtdko3sv9p/</guid><description>Discrete Flow Matching (DFM) revolutionizes discrete data generation by introducing a novel flow paradigm that surpasses existing methods. DFM leverages flexible probability paths, enabling efficient &amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-large-language-models/gtdko3sv9p/cover.png"/></item><item><title>Divide-and-Conquer Meets Consensus: Unleashing the Power of Functions in Code Generation</title><link>https://deep-diver.github.io/neurips2024/oral-large-language-models/cfqaaningw/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/oral-large-language-models/cfqaaningw/</guid><description>FUNCODER: a novel code generation framework that uses a divide-and-conquer approach with functional consensus to generate code that meets complex requirements.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/oral-large-language-models/cfqaaningw/cover.png"/></item><item><title>DuQuant: Distributing Outliers via Dual Transformation Makes Stronger Quantized LLMs</title><link>https://deep-diver.github.io/neurips2024/oral-large-language-models/mp8u2pcmqz/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/oral-large-language-models/mp8u2pcmqz/</guid><description>DuQuant: Dual transformations distribute outliers for stronger quantized LLMs.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/oral-large-language-models/mp8u2pcmqz/cover.png"/></item><item><title>Easy-to-Hard Generalization: Scalable Alignment Beyond Human Supervision</title><link>https://deep-diver.github.io/neurips2024/posters/qwgfh2fttn/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/qwgfh2fttn/</guid><description>AI alignment beyond human supervision is achieved via easy-to-hard generalization: training reward models on easy tasks to effectively evaluate and improve generators on harder tasks, achieving superh&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/qwgfh2fttn/cover.png"/></item><item><title>Efficient Adversarial Training in LLMs with Continuous Attacks</title><link>https://deep-diver.github.io/neurips2024/spotlight-large-language-models/8jb6sgqvgq/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-large-language-models/8jb6sgqvgq/</guid><description>Boosting LLM robustness against attacks efficiently: Continuous adversarial training in embedding space outperforms discrete methods, achieving improved robustness with less computation.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-large-language-models/8jb6sgqvgq/cover.png"/></item><item><title>Efficient LLM Jailbreak via Adaptive Dense-to-sparse Constrained Optimization</title><link>https://deep-diver.github.io/neurips2024/posters/bn5pa3hho8/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/bn5pa3hho8/</guid><description>Adaptive Dense-to-sparse Constrained Optimization (ADC) efficiently jailbreaks LLMs by transforming discrete token optimization into a continuous process, achieving higher success rates than existing &amp;hellip;</description></item><item><title>Efficient LLM Scheduling by Learning to Rank</title><link>https://deep-diver.github.io/neurips2024/posters/wlljyl0gi6/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/wlljyl0gi6/</guid><description>Learning to rank request outputs improves LLM scheduling, resulting in 2.8x lower chatbot latency and 6.5x higher synthetic data generation throughput.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/wlljyl0gi6/cover.png"/></item><item><title>Enhancing In-Context Learning Performance with just SVD-Based Weight Pruning: A Theoretical Perspective</title><link>https://deep-diver.github.io/neurips2024/posters/wt6ghk5shc/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/wt6ghk5shc/</guid><description>SVD-based weight pruning surprisingly boosts in-context learning in large language models, especially when applied to deeper layers, offering a novel approach to model compression and efficiency.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/wt6ghk5shc/cover.png"/></item><item><title>Ensemble Learning for Heterogeneous Large Language Models with Deep Parallel Collaboration</title><link>https://deep-diver.github.io/neurips2024/spotlight-large-language-models/7araaduk6d/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-large-language-models/7araaduk6d/</guid><description>DEEPEN: a training-free LLM ensemble framework fusing probability distributions in a relative space to overcome vocabulary misalignment, improving performance consistently across benchmarks.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-large-language-models/7araaduk6d/cover.png"/></item><item><title>Entity Alignment with Noisy Annotations from Large Language Models</title><link>https://deep-diver.github.io/neurips2024/posters/qfcq54ztx1/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/qfcq54ztx1/</guid><description>LLM4EA: A novel framework efficiently merges knowledge graphs using LLMs, overcoming noisy annotations and high costs via active learning and unsupervised label refinement, boosting accuracy and effic&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/qfcq54ztx1/cover.png"/></item><item><title>Evaluating the World Model Implicit in a Generative Model</title><link>https://deep-diver.github.io/neurips2024/spotlight-large-language-models/avk4jfpegy/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-large-language-models/avk4jfpegy/</guid><description>New metrics reveal that generative models often possess surprisingly incoherent world models, despite seemingly accurate next-token predictions. This incoherence leads to fragility in solving related &amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-large-language-models/avk4jfpegy/cover.png"/></item><item><title>Exploring Context Window of Large Language Models via Decomposed Positional Vectors</title><link>https://deep-diver.github.io/neurips2024/spotlight-large-language-models/zeyyq0gpxo/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-large-language-models/zeyyq0gpxo/</guid><description>Researchers extended large language models&amp;rsquo; context windows by training-free methods via analyzing and manipulating positional vectors, improving long-text processing.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-large-language-models/zeyyq0gpxo/cover.png"/></item><item><title>Fight Back Against Jailbreaking via Prompt Adversarial Tuning</title><link>https://deep-diver.github.io/neurips2024/posters/nrdst1qifj/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/nrdst1qifj/</guid><description>Prompt Adversarial Tuning (PAT) defends against LLM jailbreaking by training a protective prompt prefix. PAT uses adversarial and benign prompts to optimize this prefix, significantly reducing succes&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/nrdst1qifj/cover.png"/></item><item><title>FLAME : Factuality-Aware Alignment for Large Language Models</title><link>https://deep-diver.github.io/neurips2024/posters/zwuhsialbh/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/zwuhsialbh/</guid><description>FLAME: A novel alignment method enhances large language model factuality by addressing hallucination in supervised fine-tuning and reinforcement learning, resulting in more accurate and helpful AI ass&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/zwuhsialbh/cover.png"/></item><item><title>FlashAttention-3: Fast and Accurate Attention with Asynchrony and Low-precision</title><link>https://deep-diver.github.io/neurips2024/spotlight-large-language-models/tvconyid20/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-large-language-models/tvconyid20/</guid><description>FlashAttention-3: Achieves 1.5-2x faster attention on H100 GPUs using asynchrony and low-precision, reaching 1.3 PFLOPs/s.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-large-language-models/tvconyid20/cover.png"/></item><item><title>Fractal Patterns May Illuminate the Success of Next-Token Prediction</title><link>https://deep-diver.github.io/neurips2024/posters/clafyreaye/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/clafyreaye/</guid><description>LLMs&amp;rsquo; success is explained by the self-similar, long-range dependent fractal structure of language; small-scale patterns reflect larger ones.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/clafyreaye/cover.png"/></item><item><title>From Unstructured Data to In-Context Learning: Exploring What Tasks Can Be Learned and When</title><link>https://deep-diver.github.io/neurips2024/posters/x9efgahvbi/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/x9efgahvbi/</guid><description>LLMs&amp;rsquo; in-context learning surprisingly arises from simple co-occurrence patterns in unstructured data, but positional information is key for complex tasks; ICL fails when patterns are unseen or fixed.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/x9efgahvbi/cover.png"/></item><item><title>Generated and Pseudo Content guided Prototype Refinement for Few-shot Point Cloud Segmentation</title><link>https://deep-diver.github.io/neurips2024/spotlight-large-language-models/tbvlqjdfca/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-large-language-models/tbvlqjdfca/</guid><description>LLM-powered prototype refinement boosts few-shot 3D point cloud segmentation accuracy.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-large-language-models/tbvlqjdfca/cover.png"/></item><item><title>Getting More Juice Out of the SFT Data: Reward Learning from Human Demonstration Improves SFT for LLM Alignment</title><link>https://deep-diver.github.io/neurips2024/posters/orxqccn8fm/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/orxqccn8fm/</guid><description>Reward learning from human demonstrations enhances supervised fine-tuning (SFT) for better LLM alignment.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/orxqccn8fm/cover.png"/></item><item><title>Gradient Cuff: Detecting Jailbreak Attacks on Large Language Models by Exploring Refusal Loss Landscapes</title><link>https://deep-diver.github.io/neurips2024/posters/vi1wqfn15v/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/vi1wqfn15v/</guid><description>Gradient Cuff: A novel defense mechanism against LLM jailbreaks, leveraging refusal loss landscapes for improved malicious query rejection without harming model performance on benign inputs.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/vi1wqfn15v/cover.png"/></item><item><title>Graph-based Uncertainty Metrics for Long-form Language Model Generations</title><link>https://deep-diver.github.io/neurips2024/spotlight-large-language-models/ygjpqw0lko/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-large-language-models/ygjpqw0lko/</guid><description>Graph Uncertainty boosts LLM factuality by 6.8% using graph centrality to estimate claim-level uncertainty and a novel uncertainty-aware decoding process.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-large-language-models/ygjpqw0lko/cover.png"/></item><item><title>GREATS: Online Selection of High-Quality Data for LLM Training in Every Iteration</title><link>https://deep-diver.github.io/neurips2024/spotlight-large-language-models/232vcn8tsx/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-large-language-models/232vcn8tsx/</guid><description>GREATS: a novel online batch selection method significantly speeds up LLM training by greedily selecting high-quality data batches in every iteration, improving both convergence and generalization per&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-large-language-models/232vcn8tsx/cover.png"/></item><item><title>GTBench: Uncovering the Strategic Reasoning Capabilities of LLMs via Game-Theoretic Evaluations</title><link>https://deep-diver.github.io/neurips2024/posters/ypggxvwiv2/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/ypggxvwiv2/</guid><description>GTBENCH reveals LLMs&amp;rsquo; strategic reasoning weaknesses via game-theoretic evaluations, showing strengths in probabilistic scenarios but struggles with deterministic ones; code-pretraining helps.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/ypggxvwiv2/cover.png"/></item><item><title>HaloScope: Harnessing Unlabeled LLM Generations for Hallucination Detection</title><link>https://deep-diver.github.io/neurips2024/spotlight-large-language-models/nfk0zxffsn/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-large-language-models/nfk0zxffsn/</guid><description>HaloScope leverages unlabeled LLM outputs to accurately detect AI hallucinations without human annotation, significantly outperforming existing methods.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-large-language-models/nfk0zxffsn/cover.png"/></item><item><title>Heavy-Tailed Class Imbalance and Why Adam Outperforms Gradient Descent on Language Models</title><link>https://deep-diver.github.io/neurips2024/spotlight-large-language-models/t56j6av8oc/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-large-language-models/t56j6av8oc/</guid><description>Adam&amp;rsquo;s superior performance on language models stems from its resilience to heavy-tailed class imbalance, unlike SGD, which struggles with infrequent word losses.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-large-language-models/t56j6av8oc/cover.png"/></item><item><title>How do Large Language Models Handle Multilingualism?</title><link>https://deep-diver.github.io/neurips2024/posters/ctxyooagry/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/ctxyooagry/</guid><description>LLMs surprisingly process multilingual queries via an English-centric intermediate stage before generating responses in the original language, a phenomenon explained by the proposed MWork framework an&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/ctxyooagry/cover.png"/></item><item><title>HydraLoRA: An Asymmetric LoRA Architecture for Efficient Fine-Tuning</title><link>https://deep-diver.github.io/neurips2024/oral-large-language-models/qepi8uwx3n/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/oral-large-language-models/qepi8uwx3n/</guid><description>HydraLoRA: Asymmetric LoRA boosts LLM fine-tuning efficiency by sharing parameters across tasks while specializing others, outperforming existing methods.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/oral-large-language-models/qepi8uwx3n/cover.png"/></item><item><title>IDGen: Item Discrimination Induced Prompt Generation for LLM Evaluation</title><link>https://deep-diver.github.io/neurips2024/posters/zv4uiszzp5/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/zv4uiszzp5/</guid><description>IDGen synthesizes LLM evaluation prompts using Item Discrimination theory, creating a more challenging and discriminative dataset than previous methods.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/zv4uiszzp5/cover.png"/></item><item><title>Improved Few-Shot Jailbreaking Can Circumvent Aligned Language Models and Their Defenses</title><link>https://deep-diver.github.io/neurips2024/posters/zmnd0jucef/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/zmnd0jucef/</guid><description>Improved few-shot jailbreaking techniques efficiently circumvent aligned language models and their defenses, achieving high success rates even against advanced protection methods.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/zmnd0jucef/cover.png"/></item><item><title>Improving Sparse Decomposition of Language Model Activations with Gated Sparse Autoencoders</title><link>https://deep-diver.github.io/neurips2024/posters/zlblin2zvw/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/zlblin2zvw/</guid><description>Gated Sparse Autoencoders (GSAEs) achieve Pareto improvement over baseline SAEs for unsupervised feature discovery in language models, resolving the shrinkage bias of L1 penalty by separating feature &amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/zlblin2zvw/cover.png"/></item><item><title>Induced Model Matching: Restricted Models Help Train Full-Featured Models</title><link>https://deep-diver.github.io/neurips2024/spotlight-large-language-models/iw0wxe0vyr/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-large-language-models/iw0wxe0vyr/</guid><description>Restricted models often outperform full-featured models when training data is limited. This paper introduces Induced Model Matching (IMM), a novel technique that uses a restricted model as a guide to&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-large-language-models/iw0wxe0vyr/cover.png"/></item><item><title>Interpreting Learned Feedback Patterns in Large Language Models</title><link>https://deep-diver.github.io/neurips2024/posters/xuongr1byy/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/xuongr1byy/</guid><description>Researchers developed methods to measure and interpret the divergence between learned feedback patterns (LFPs) in LLMs and human preferences, helping minimize discrepancies between LLM behavior and tr&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/xuongr1byy/cover.png"/></item><item><title>Is Programming by Example solved by LLMs?</title><link>https://deep-diver.github.io/neurips2024/posters/xqc8yyhscl/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/xqc8yyhscl/</guid><description>Large Language Models (LLMs) surprisingly improve the challenging task of Programming by Example (PBE) when fine-tuned on problem-specific data, outperforming classic symbolic methods and even surpass&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/xqc8yyhscl/cover.png"/></item><item><title>KV Cache is 1 Bit Per Channel: Efficient Large Language Model Inference with Coupled Quantization</title><link>https://deep-diver.github.io/neurips2024/posters/pnnvzqss4p/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/pnnvzqss4p/</guid><description>Boost LLM inference speed 1.4-3.5x by using Coupled Quantization (CQ) to compress KV cache down to 1 bit per channel, while preserving model accuracy.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/pnnvzqss4p/cover.png"/></item><item><title>Large Language Model Unlearning via Embedding-Corrupted Prompts</title><link>https://deep-diver.github.io/neurips2024/posters/e5icsxbd8q/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/e5icsxbd8q/</guid><description>ECO prompts enable efficient LLM unlearning by corrupting prompts flagged for forgetting, achieving promising results across various LLMs and tasks with minimal side effects.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/e5icsxbd8q/cover.png"/></item><item><title>Learn To be Efficient: Build Structured Sparsity in Large Language Models</title><link>https://deep-diver.github.io/neurips2024/spotlight-large-language-models/isfcwhvega/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-large-language-models/isfcwhvega/</guid><description>Learn-To-be-Efficient (LTE) trains LLMs to achieve structured sparsity, boosting inference speed by 25% at 50% sparsity without sacrificing accuracy.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-large-language-models/isfcwhvega/cover.png"/></item><item><title>Learning to grok: Emergence of in-context learning and skill composition in modular arithmetic tasks</title><link>https://deep-diver.github.io/neurips2024/oral-large-language-models/avh9krzdrk/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/oral-large-language-models/avh9krzdrk/</guid><description>Large language models surprisingly solve unseen arithmetic tasks; this work reveals how they learn to compose simple skills into complex ones through in-context learning, showing a transition from mem&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/oral-large-language-models/avh9krzdrk/cover.png"/></item><item><title>Learning to Reason via Program Generation, Emulation, and Search</title><link>https://deep-diver.github.io/neurips2024/posters/te6vagjf6g/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/te6vagjf6g/</guid><description>Language models excel at generating programs for algorithmic tasks, but struggle with soft reasoning. COGEX leverages pseudo-programs and program emulation to tackle these tasks, while COTACS searches&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/te6vagjf6g/cover.png"/></item><item><title>Limits of Transformer Language Models on Learning to Compose Algorithms</title><link>https://deep-diver.github.io/neurips2024/posters/x7ad0343jz/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/x7ad0343jz/</guid><description>Large Language Models struggle with compositional tasks, requiring exponentially more data than expected for learning compared to learning sub-tasks individually. This paper reveals surprising sample &amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/x7ad0343jz/cover.png"/></item><item><title>LLM Evaluators Recognize and Favor Their Own Generations</title><link>https://deep-diver.github.io/neurips2024/oral-large-language-models/4njbv6wp0h/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/oral-large-language-models/4njbv6wp0h/</guid><description>LLMs show self-preference bias in evaluations, favoring their own outputs. This study reveals that LLMs surprisingly recognize their own generations, and this self-recognition directly causes the self&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/oral-large-language-models/4njbv6wp0h/cover.png"/></item><item><title>Localized Zeroth-Order Prompt Optimization</title><link>https://deep-diver.github.io/neurips2024/spotlight-large-language-models/hs1jvv3dk3/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-large-language-models/hs1jvv3dk3/</guid><description>Localized Zeroth-Order Prompt Optimization (ZOPO) efficiently finds high-performing local optima for prompt optimization in black-box LLMs, outperforming existing global optimization methods.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-large-language-models/hs1jvv3dk3/cover.png"/></item><item><title>MAmmoTH2: Scaling Instructions from the Web</title><link>https://deep-diver.github.io/neurips2024/posters/yvu5dnplqa/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/yvu5dnplqa/</guid><description>MAmmoTH2: Harvesting 10M web instructions for enhanced LLM reasoning!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/yvu5dnplqa/cover.png"/></item><item><title>Many-Shot In-Context Learning</title><link>https://deep-diver.github.io/neurips2024/spotlight-large-language-models/ab6xpmzvqh/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-large-language-models/ab6xpmzvqh/</guid><description>Scaling up in-context learning using thousands of examples significantly boosts Large Language Model (LLM) performance, particularly for complex tasks. Novel training methods mitigate reliance on hum&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-large-language-models/ab6xpmzvqh/cover.png"/></item><item><title>MaskLLM: Learnable Semi-Structured Sparsity for Large Language Models</title><link>https://deep-diver.github.io/neurips2024/spotlight-large-language-models/llu9njal7b/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-large-language-models/llu9njal7b/</guid><description>MaskLLM learns efficient semi-structured sparsity in LLMs via end-to-end training, achieving significant speedup and memory reduction without sacrificing performance.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-large-language-models/llu9njal7b/cover.png"/></item><item><title>Mesa-Extrapolation: A Weave Position Encoding Method for Enhanced Extrapolation in LLMs</title><link>https://deep-diver.github.io/neurips2024/posters/zaxumqoaf4/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/zaxumqoaf4/</guid><description>Mesa-Extrapolation enhances LLM extrapolation using a novel weave position encoding method, boosting performance while significantly reducing memory and inference time.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/zaxumqoaf4/cover.png"/></item><item><title>MetaLA: Unified Optimal Linear Approximation to Softmax Attention Map</title><link>https://deep-diver.github.io/neurips2024/oral-large-language-models/y8yvcomepz/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/oral-large-language-models/y8yvcomepz/</guid><description>MetaLA: Unified optimal linear approximation to softmax attention map, achieving linear complexity and surpassing existing models in various benchmarks.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/oral-large-language-models/y8yvcomepz/cover.png"/></item><item><title>Microstructures and Accuracy of Graph Recall by Large Language Models</title><link>https://deep-diver.github.io/neurips2024/posters/tnhwg9u767/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/tnhwg9u767/</guid><description>LLMs struggle with graph recall, exhibiting biases like favoring triangles and underperforming compared to humans; advanced models show striking domain dependence.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/tnhwg9u767/cover.png"/></item><item><title>MInference 1.0: Accelerating Pre-filling for Long-Context LLMs via Dynamic Sparse Attention</title><link>https://deep-diver.github.io/neurips2024/spotlight-large-language-models/fpbacabqsn/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-large-language-models/fpbacabqsn/</guid><description>MInference 1.0 accelerates LLM pre-filling via dynamic sparse attention, achieving up to 10x speedup on an A100 GPU while maintaining accuracy.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-large-language-models/fpbacabqsn/cover.png"/></item><item><title>Mixture of Scales: Memory-Efficient Token-Adaptive Binarization for Large Language Models</title><link>https://deep-diver.github.io/neurips2024/posters/pgobeycxzs/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/pgobeycxzs/</guid><description>BinaryMoS: a novel token-adaptive binarization method that boosts LLM accuracy and efficiency by dynamically merging multiple scaling experts for each token.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/pgobeycxzs/cover.png"/></item><item><title>MKGL: Mastery of a Three-Word Language</title><link>https://deep-diver.github.io/neurips2024/spotlight-large-language-models/eqmnwxvoqn/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-large-language-models/eqmnwxvoqn/</guid><description>Researchers taught a large language model (LLM) a three-word &amp;lsquo;Knowledge Graph Language&amp;rsquo; (KGL) to improve knowledge graph (KG) completion, drastically reducing errors compared to other methods.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-large-language-models/eqmnwxvoqn/cover.png"/></item><item><title>Model Fusion through Bayesian Optimization in Language Model Fine-Tuning</title><link>https://deep-diver.github.io/neurips2024/spotlight-large-language-models/lv4kthtgpj/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-large-language-models/lv4kthtgpj/</guid><description>Bayesian Optimization Model Fusion (BOMF) significantly boosts language model fine-tuning by optimizing both loss and metrics through multi-objective Bayesian optimization, yielding considerable perfo&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-large-language-models/lv4kthtgpj/cover.png"/></item><item><title>MutaPLM: Protein Language Modeling for Mutation Explanation and Engineering</title><link>https://deep-diver.github.io/neurips2024/posters/yppclfezgy/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/yppclfezgy/</guid><description>MutaPLM: a novel protein language model, provides human-understandable mutation explanations and designs novel mutations with desirable properties using a unique protein delta network and chain-of-tho&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/yppclfezgy/cover.png"/></item><item><title>No Free Lunch in LLM Watermarking: Trade-offs in Watermarking Design Choices</title><link>https://deep-diver.github.io/neurips2024/posters/riol7kbskv/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/riol7kbskv/</guid><description>LLM watermarking faces inherent trade-offs; this paper reveals simple attacks exploiting common design choices, proposing guidelines and defenses for more secure systems.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/riol7kbskv/cover.png"/></item><item><title>Not All Tokens Are What You Need for Pretraining</title><link>https://deep-diver.github.io/neurips2024/oral-large-language-models/0nmzbwqaaj/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/oral-large-language-models/0nmzbwqaaj/</guid><description>RHO-1, a novel language model, uses selective pretraining focusing on high-value tokens, achieving state-of-the-art results with significantly less data than existing models.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/oral-large-language-models/0nmzbwqaaj/cover.png"/></item><item><title>Observational Scaling Laws and the Predictability of Langauge Model Performance</title><link>https://deep-diver.github.io/neurips2024/spotlight-large-language-models/on5win7xyd/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-large-language-models/on5win7xyd/</guid><description>Researchers predict language model performance by observing existing models, bypassing costly training, revealing surprising predictability in complex scaling phenomena.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-large-language-models/on5win7xyd/cover.png"/></item><item><title>On Softmax Direct Preference Optimization for Recommendation</title><link>https://deep-diver.github.io/neurips2024/posters/qp5vbgtam0/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/qp5vbgtam0/</guid><description>Softmax-DPO boosts LM-based recommender performance by directly optimizing for personalized ranking using a novel loss function that incorporates multiple negative samples, significantly outperforming&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/qp5vbgtam0/cover.png"/></item><item><title>One Token to Seg Them All: Language Instructed Reasoning Segmentation in Videos</title><link>https://deep-diver.github.io/neurips2024/posters/bqmevgcyvm/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/bqmevgcyvm/</guid><description>VideoLISA: A video-based multimodal large language model enabling precise, language-instructed video object segmentation with superior performance.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/bqmevgcyvm/cover.png"/></item><item><title>One-Shot Safety Alignment for Large Language Models via Optimal Dualization</title><link>https://deep-diver.github.io/neurips2024/spotlight-large-language-models/da7hum4css/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-large-language-models/da7hum4css/</guid><description>One-shot dualization aligns large language models with safety constraints efficiently, eliminating iterative primal-dual methods for improved stability and reduced computational burden.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-large-language-models/da7hum4css/cover.png"/></item><item><title>Parallelizing Linear Transformers with the Delta Rule over Sequence Length</title><link>https://deep-diver.github.io/neurips2024/posters/y8rm4vnrph/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/y8rm4vnrph/</guid><description>DeltaNet, a linear transformer boosting associative recall, now trains efficiently via a novel algorithm, scaling to large language models and outperforming existing linear baselines.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/y8rm4vnrph/cover.png"/></item><item><title>PiSSA: Principal Singular Values and Singular Vectors Adaptation of Large Language Models</title><link>https://deep-diver.github.io/neurips2024/spotlight-large-language-models/6zbhietdp4/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-large-language-models/6zbhietdp4/</guid><description>PiSSA, a novel parameter-efficient fine-tuning method, surpasses LoRA by initializing adapter matrices using the principal components of the original model, achieving faster convergence and enhanced p&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-large-language-models/6zbhietdp4/cover.png"/></item><item><title>Policy Learning from Tutorial Books via Understanding, Rehearsing and Introspecting</title><link>https://deep-diver.github.io/neurips2024/oral-large-language-models/ddak3nsqqm/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/oral-large-language-models/ddak3nsqqm/</guid><description>Researchers developed Policy Learning from tutorial Books (PLfB), a novel method that trains AI agents using knowledge from tutorial books instead of relying solely on real-world data.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/oral-large-language-models/ddak3nsqqm/cover.png"/></item><item><title>Protecting Your LLMs with Information Bottleneck</title><link>https://deep-diver.github.io/neurips2024/posters/u9shp64fjv/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/u9shp64fjv/</guid><description>IBProtector shields LLMs from harmful outputs via prompt compression, selectively preserving essential information using a trainable extractor.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/u9shp64fjv/cover.png"/></item><item><title>PV-Tuning: Beyond Straight-Through Estimation for Extreme LLM Compression</title><link>https://deep-diver.github.io/neurips2024/oral-large-language-models/yva8uf0i37/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/oral-large-language-models/yva8uf0i37/</guid><description>PV-Tuning achieves new state-of-the-art in extreme LLM compression by going beyond traditional straight-through estimators (STE). This novel framework provides a more accurate and efficient fine-tunin&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/oral-large-language-models/yva8uf0i37/cover.png"/></item><item><title>QTIP: Quantization with Trellises and Incoherence Processing</title><link>https://deep-diver.github.io/neurips2024/spotlight-large-language-models/7sdklvuycu/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-large-language-models/7sdklvuycu/</guid><description>QTIP: Ultra-high dimensional LLM quantization using trellis codes for faster, higher-quality inference.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-large-language-models/7sdklvuycu/cover.png"/></item><item><title>Questioning the Survey Responses of Large Language Models</title><link>https://deep-diver.github.io/neurips2024/oral-large-language-models/oo7dllgqqx/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/oral-large-language-models/oo7dllgqqx/</guid><description>LLM survey responses are systematically biased, often masking genuine model capabilities and leading to misleading alignment conclusions.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/oral-large-language-models/oo7dllgqqx/cover.png"/></item><item><title>Reasons and Solutions for the Decline in Model Performance after Editing</title><link>https://deep-diver.github.io/neurips2024/posters/xjxygdfm5m/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/xjxygdfm5m/</guid><description>Boosting large language model performance after knowledge editing: A new method (D4S) minimizes model damage by regulating the explosive growth of parameter layers, enabling multiple effective edits.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/xjxygdfm5m/cover.png"/></item><item><title>ReFT: Representation Finetuning for Language Models</title><link>https://deep-diver.github.io/neurips2024/spotlight-large-language-models/fykjplmc0v/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-large-language-models/fykjplmc0v/</guid><description>ReFT: Revolutionizing language model finetuning by directly manipulating hidden representations, achieving superior efficiency and performance compared to existing methods.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-large-language-models/fykjplmc0v/cover.png"/></item><item><title>Representation Noising: A Defence Mechanism Against Harmful Finetuning</title><link>https://deep-diver.github.io/neurips2024/posters/ep9auejqfg/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/ep9auejqfg/</guid><description>RepNoise: a novel defense against harmful fine-tuning of LLMs by removing information about harmful representations, generalizing across different harmful tasks, and maintaining LLM capabilities.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/ep9auejqfg/cover.png"/></item><item><title>Reranking Laws for Language Generation: A Communication-Theoretic Perspective</title><link>https://deep-diver.github.io/neurips2024/spotlight-large-language-models/rhcgiznupi/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-large-language-models/rhcgiznupi/</guid><description>Boost LLM reliability by adding redundancy! This paper uses a communication theory framework to show that generating multiple LLM outputs and reranking them significantly reduces errors, even with imp&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-large-language-models/rhcgiznupi/cover.png"/></item><item><title>Resolving Discrepancies in Compute-Optimal Scaling of Language Models</title><link>https://deep-diver.github.io/neurips2024/spotlight-large-language-models/4fssqpk1sm/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-large-language-models/4fssqpk1sm/</guid><description>New research resolves discrepancies in language model scaling laws, revealing three key factors driving the differences and improving accuracy in predicting optimal model size based on compute budget.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-large-language-models/4fssqpk1sm/cover.png"/></item><item><title>Reversing the Forget-Retain Objectives: An Efficient LLM Unlearning Framework from Logit Difference</title><link>https://deep-diver.github.io/neurips2024/posters/tydr1ltwqh/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/tydr1ltwqh/</guid><description>Reverse the forget-retain objectives for efficient LLM unlearning!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/tydr1ltwqh/cover.png"/></item><item><title>Robust Prompt Optimization for Defending Language Models Against Jailbreaking Attacks</title><link>https://deep-diver.github.io/neurips2024/spotlight-large-language-models/jxs6cvpe7k/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-large-language-models/jxs6cvpe7k/</guid><description>Robust Prompt Optimization (RPO) creates robust LLM defenses against jailbreaking attacks by optimizing a transferable suffix, achieving state-of-the-art robustness.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-large-language-models/jxs6cvpe7k/cover.png"/></item><item><title>Rule Extrapolation in Language Modeling: A Study of Compositional Generalization on OOD Prompts</title><link>https://deep-diver.github.io/neurips2024/spotlight-large-language-models/li2rprzwjy/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-large-language-models/li2rprzwjy/</guid><description>LLMs struggle with out-of-distribution (OOD) generalization. This research introduces &amp;lsquo;rule extrapolation&amp;rsquo; using formal languages to rigorously evaluate OOD behavior in various LLM architectures, rev&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-large-language-models/li2rprzwjy/cover.png"/></item><item><title>Scaling Laws and Compute-Optimal Training Beyond Fixed Training Durations</title><link>https://deep-diver.github.io/neurips2024/spotlight-large-language-models/y13gsftjgr/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-large-language-models/y13gsftjgr/</guid><description>Revolutionizing LLM training: Constant learning rate with cooldown replaces cosine schedule, enabling cost-effective scaling experiments!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-large-language-models/y13gsftjgr/cover.png"/></item><item><title>Scaling Laws for Reward Model Overoptimization in Direct Alignment Algorithms</title><link>https://deep-diver.github.io/neurips2024/posters/pf4oujyn4q/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/pf4oujyn4q/</guid><description>Direct Alignment Algorithms (DAAs) for LLM alignment suffer from over-optimization, even without explicit reward models; this paper empirically demonstrates this and proposes scaling laws to understan&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/pf4oujyn4q/cover.png"/></item><item><title>Scaling Laws with Vocabulary: Larger Models Deserve Larger Vocabularies</title><link>https://deep-diver.github.io/neurips2024/posters/skckpr8crl/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/skckpr8crl/</guid><description>Boosting LLM performance: This research shows how larger language models need bigger vocabularies for optimal efficiency and performance.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/skckpr8crl/cover.png"/></item><item><title>Selective Generation for Controllable Language Models</title><link>https://deep-diver.github.io/neurips2024/spotlight-large-language-models/glfyoazh2f/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-large-language-models/glfyoazh2f/</guid><description>Certified selective generation controls language model hallucinations by leveraging textual entailment and a novel semi-supervised algorithm, guaranteeing a controlled false discovery rate.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-large-language-models/glfyoazh2f/cover.png"/></item><item><title>Self-playing Adversarial Language Game Enhances LLM Reasoning</title><link>https://deep-diver.github.io/neurips2024/posters/ocgksh7ys2/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/ocgksh7ys2/</guid><description>Self-play adversarial language game boosts LLM reasoning!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/ocgksh7ys2/cover.png"/></item><item><title>Sequoia: Scalable and Robust Speculative Decoding</title><link>https://deep-diver.github.io/neurips2024/spotlight-large-language-models/rk2l9ygdi2/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-large-language-models/rk2l9ygdi2/</guid><description>SEQUOIA: A novel algorithm boosts Large Language Model (LLM) inference speed by up to 9.5x using a scalable and robust speculative decoding approach!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-large-language-models/rk2l9ygdi2/cover.png"/></item><item><title>Spectral Editing of Activations for Large Language Model Alignment</title><link>https://deep-diver.github.io/neurips2024/posters/pqyceea87j/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/pqyceea87j/</guid><description>Spectral Editing of Activations (SEA) improves large language model truthfulness and fairness by projecting input representations to maximize covariance with positive demonstrations while minimizing c&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/pqyceea87j/cover.png"/></item><item><title>Stacking Your Transformers: A Closer Look at Model Growth for Efficient LLM Pre-Training</title><link>https://deep-diver.github.io/neurips2024/spotlight-large-language-models/fxjdcrimyh/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-large-language-models/fxjdcrimyh/</guid><description>Stacking Your Transformers accelerates LLM pre-training by leveraging smaller, pre-trained models to efficiently train larger ones, achieving significant speedups and improved performance.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-large-language-models/fxjdcrimyh/cover.png"/></item><item><title>Stealth edits to large language models</title><link>https://deep-diver.github.io/neurips2024/posters/qap6ryyijc/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/qap6ryyijc/</guid><description>Researchers unveil stealth edits for large language models, offering a new metric to assess editability and reveal vulnerability to malicious attacks.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/qap6ryyijc/cover.png"/></item><item><title>Stress-Testing Capability Elicitation With Password-Locked Models</title><link>https://deep-diver.github.io/neurips2024/posters/zzooqd6r1b/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/zzooqd6r1b/</guid><description>Fine-tuning, even on a single demonstration, effectively uncovers hidden LLM capabilities, surpassing simple prompting methods.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/zzooqd6r1b/cover.png"/></item><item><title>Synthesize, Partition, then Adapt: Eliciting Diverse Samples from Foundation Models</title><link>https://deep-diver.github.io/neurips2024/posters/sp8whisnu9/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/sp8whisnu9/</guid><description>The Synthesize-Partition-Adapt (SPA) framework leverages synthetic data to generate diverse, high-quality responses from foundation models, enriching user experience.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/sp8whisnu9/cover.png"/></item><item><title>The Evolution of Statistical Induction Heads: In-Context Learning Markov Chains</title><link>https://deep-diver.github.io/neurips2024/posters/qart6qtiqj/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/qart6qtiqj/</guid><description>Transformers learn to perform in-context learning of Markov chains hierarchically, progressing from simpler unigram strategies to more complex bigram solutions, with the presence of simpler solutions &amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/qart6qtiqj/cover.png"/></item><item><title>The Expressive Capacity of State Space Models: A Formal Language Perspective</title><link>https://deep-diver.github.io/neurips2024/posters/ev5yirjpdy/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/ev5yirjpdy/</guid><description>State-space models (SSMs) rival transformers in language modeling, but their capabilities remain unclear; this paper rigorously analyzes SSM expressivity, revealing unique strengths and limitations, i&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/ev5yirjpdy/cover.png"/></item><item><title>The Fine-Grained Complexity of Gradient Computation for Training Large Language Models</title><link>https://deep-diver.github.io/neurips2024/posters/up4twnwrol/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/up4twnwrol/</guid><description>New research precisely defines the computational limits of training large language models, revealing a sharp threshold based on parameter matrix entries, paving the way for faster algorithms.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/up4twnwrol/cover.png"/></item><item><title>The Impact of Initialization on LoRA Finetuning Dynamics</title><link>https://deep-diver.github.io/neurips2024/posters/sn3uryritk/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/sn3uryritk/</guid><description>LoRA&amp;rsquo;s initialization significantly impacts finetuning; initializing matrix A randomly and B to zero yields better performance than vice-versa due to enabling larger learning rates.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/sn3uryritk/cover.png"/></item><item><title>Thinking Forward: Memory-Efficient Federated Finetuning of Language Models</title><link>https://deep-diver.github.io/neurips2024/posters/dgqtja9x2c/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/dgqtja9x2c/</guid><description>SPRY: A memory-efficient federated learning algorithm for finetuning LLMs on resource-constrained devices, achieving high accuracy and speed.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/dgqtja9x2c/cover.png"/></item><item><title>Time-Reversal Provides Unsupervised Feedback to LLMs</title><link>https://deep-diver.github.io/neurips2024/spotlight-large-language-models/ny0brzdqlt/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-large-language-models/ny0brzdqlt/</guid><description>Time-reversed language models provide unsupervised feedback for improving LLMs, offering a cost-effective alternative to human feedback and enhancing LLM safety.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-large-language-models/ny0brzdqlt/cover.png"/></item><item><title>TOPA: Extending Large Language Models for Video Understanding via Text-Only Pre-Alignment</title><link>https://deep-diver.github.io/neurips2024/spotlight-large-language-models/5nmbqpy7bn/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-large-language-models/5nmbqpy7bn/</guid><description>TOPA: Extending LLMs for video understanding using only text data.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-large-language-models/5nmbqpy7bn/cover.png"/></item><item><title>Toward Self-Improvement of LLMs via Imagination, Searching, and Criticizing</title><link>https://deep-diver.github.io/neurips2024/posters/tpdj2qhkob/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/tpdj2qhkob/</guid><description>ALPHALLM boosts LLM performance in complex reasoning tasks by using imagination, search, and criticism to create a self-improving loop, eliminating the need for extra training data.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/tpdj2qhkob/cover.png"/></item><item><title>Towards Understanding How Transformers Learn In-context Through a Representation Learning Lens</title><link>https://deep-diver.github.io/neurips2024/posters/db6gwsdxkl/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/db6gwsdxkl/</guid><description>Transformers&amp;rsquo; in-context learning (ICL) is explained using representation learning, revealing its ICL process as gradient descent on a dual model and offering modifiable attention layers for enhanced &amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/db6gwsdxkl/cover.png"/></item><item><title>Toxicity Detection for Free</title><link>https://deep-diver.github.io/neurips2024/spotlight-large-language-models/5a27ee8lxx/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-large-language-models/5a27ee8lxx/</guid><description>Moderation Using LLM Introspection (MULI) leverages the first response token&amp;rsquo;s logits from LLMs to create a highly accurate toxicity detector, surpassing state-of-the-art methods with minimal overhead&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-large-language-models/5a27ee8lxx/cover.png"/></item><item><title>Training Compute-Optimal Protein Language Models</title><link>https://deep-diver.github.io/neurips2024/spotlight-large-language-models/uczi8gsfd4/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-large-language-models/uczi8gsfd4/</guid><description>Compute-optimal protein language models are trained efficiently using scaling laws derived from a massive dataset, improving performance while optimizing compute budgets.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-large-language-models/uczi8gsfd4/cover.png"/></item><item><title>Training Dynamics of Transformers to Recognize Word Co-occurrence via Gradient Flow Analysis</title><link>https://deep-diver.github.io/neurips2024/posters/w6q46islsr/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/w6q46islsr/</guid><description>Researchers reveal how transformers learn word co-occurrence using a novel gradient flow analysis, uncovering a two-phase training process that leads to near-minimum loss and improved model performanc&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/w6q46islsr/cover.png"/></item><item><title>Unlocking the Capabilities of Thought: A Reasoning Boundary Framework to Quantify and Optimize Chain-of-Thought</title><link>https://deep-diver.github.io/neurips2024/oral-large-language-models/pc44umwy2v/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/oral-large-language-models/pc44umwy2v/</guid><description>Reasoning Boundary Framework (RBF) quantitatively assesses and optimizes chain-of-thought (CoT) in LLMs, offering novel metrics and optimization strategies validated across various models and tasks.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/oral-large-language-models/pc44umwy2v/cover.png"/></item><item><title>Unlocking Tokens as Data Points for Generalization Bounds on Larger Language Models</title><link>https://deep-diver.github.io/neurips2024/spotlight-large-language-models/5jru8ufi8h/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-large-language-models/5jru8ufi8h/</guid><description>Unlocking tight generalization bounds for massive LLMs using a novel token-level approach.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-large-language-models/5jru8ufi8h/cover.png"/></item><item><title>Verified Code Transpilation with LLMs</title><link>https://deep-diver.github.io/neurips2024/posters/spwe9slrfg/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/spwe9slrfg/</guid><description>LLMLIFT: An LLM-powered approach builds verified lifting tools for DSLs, outperforming prior symbolic methods in benchmark transpilation and requiring less development effort.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/spwe9slrfg/cover.png"/></item><item><title>Watermarking Makes Language Models Radioactive</title><link>https://deep-diver.github.io/neurips2024/spotlight-large-language-models/qgizqb1khm/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-large-language-models/qgizqb1khm/</guid><description>LLM watermarking leaves detectable traces in subsequently trained models, enabling detection of synthetic data usageâa phenomenon termed &amp;lsquo;radioactivity&amp;rsquo;.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-large-language-models/qgizqb1khm/cover.png"/></item><item><title>Weak-to-Strong Search: Align Large Language Models via Searching over Small Language Models</title><link>https://deep-diver.github.io/neurips2024/posters/doj6cqwdf1/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/doj6cqwdf1/</guid><description>Align LLMs efficiently via test-time search using smaller models!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/doj6cqwdf1/cover.png"/></item><item><title>Who's asking? User personas and the mechanics of latent misalignment</title><link>https://deep-diver.github.io/neurips2024/spotlight-large-language-models/eses1mic9d/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-large-language-models/eses1mic9d/</guid><description>User personas significantly impact the safety of large language models, bypassing safety filters more effectively than direct prompting methods.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-large-language-models/eses1mic9d/cover.png"/></item><item><title>xLSTM: Extended Long Short-Term Memory</title><link>https://deep-diver.github.io/neurips2024/spotlight-large-language-models/araxppiahq/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-large-language-models/araxppiahq/</guid><description>XLSTM: Extended Long Short-Term Memory, introduces exponential gating and novel memory structures to overcome LSTM limitations, achieving performance comparable to state-of-the-art Transformers and St&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-large-language-models/araxppiahq/cover.png"/></item><item><title>You Only Cache Once: Decoder-Decoder Architectures for Language Models</title><link>https://deep-diver.github.io/neurips2024/oral-large-language-models/25ioxw576r/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/oral-large-language-models/25ioxw576r/</guid><description>YOCO: A decoder-decoder architecture for LLMs dramatically reduces memory usage and improves inference speed by caching key-value pairs only once.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/oral-large-language-models/25ioxw576r/cover.png"/></item></channel></rss>