<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>üè¢ University of Cambridge on NeurIPS 2024</title><link>https://deep-diver.github.io/neurips2024/tags/-university-of-cambridge/</link><description>Recent content in üè¢ University of Cambridge on NeurIPS 2024</description><generator>Hugo -- gohugo.io</generator><language>en</language><copyright>¬© 2024 AI Paper Reviewer</copyright><lastBuildDate>Thu, 26 Sep 2024 00:00:00 +0000</lastBuildDate><atom:link href="https://deep-diver.github.io/neurips2024/tags/-university-of-cambridge/index.xml" rel="self" type="application/rss+xml"/><item><title>A Generative Model of Symmetry Transformations</title><link>https://deep-diver.github.io/neurips2024/posters/afp24eypwh/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/afp24eypwh/</guid><description>Generative model learns data symmetries for improved efficiency and higher test log-likelihoods.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/afp24eypwh/cover.png"/></item><item><title>A theoretical design of concept sets: improving the predictability of concept bottleneck models</title><link>https://deep-diver.github.io/neurips2024/posters/otv6qa12g0/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/otv6qa12g0/</guid><description>Boosting concept bottleneck model predictability, this paper introduces a theoretical framework linking concept set properties to model performance, proposing a method for effective concept identifica&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/otv6qa12g0/cover.png"/></item><item><title>Accelerating Relative Entropy Coding with Space Partitioning</title><link>https://deep-diver.github.io/neurips2024/posters/ouqywnunxm/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/ouqywnunxm/</guid><description>Space partitioning dramatically speeds up relative entropy coding (REC) for neural compression, achieving 5-15% better bitrates than previous methods.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/ouqywnunxm/cover.png"/></item><item><title>An Improved Empirical Fisher Approximation for Natural Gradient Descent</title><link>https://deep-diver.github.io/neurips2024/posters/lmjlrhvcmg/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/lmjlrhvcmg/</guid><description>Improved Empirical Fisher (iEF) approximation significantly boosts the performance of Natural Gradient Descent (NGD) optimizers, offering superior convergence and generalization.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/lmjlrhvcmg/cover.png"/></item><item><title>Approximately Equivariant Neural Processes</title><link>https://deep-diver.github.io/neurips2024/posters/dqt9mc5nql/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/dqt9mc5nql/</guid><description>Boosting meta-learning, this paper introduces a novel, flexible approach to create approximately equivariant neural processes that outperform both non-equivariant and strictly equivariant counterparts&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/dqt9mc5nql/cover.png"/></item><item><title>Automatically Learning Hybrid Digital Twins of Dynamical Systems</title><link>https://deep-diver.github.io/neurips2024/spotlight-others/sosiobsdu2/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-others/sosiobsdu2/</guid><description>AI autonomously designs highly effective hybrid digital twins by combining neural networks and mechanistic models, significantly advancing digital twin technology.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-others/sosiobsdu2/cover.png"/></item><item><title>Beyond Slow Signs in High-fidelity Model Extraction</title><link>https://deep-diver.github.io/neurips2024/posters/mrs9a1xqap/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/mrs9a1xqap/</guid><description>Researchers drastically sped up high-fidelity deep learning model extraction, improving efficiency by up to 14.8x and challenging previous assumptions on the extraction bottleneck.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/mrs9a1xqap/cover.png"/></item><item><title>Bias in Motion: Theoretical Insights into the Dynamics of Bias in SGD Training</title><link>https://deep-diver.github.io/neurips2024/posters/quylbzwttv/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/quylbzwttv/</guid><description>AI systems acquire bias during training, impacting accuracy across sub-populations. This research unveils bias&amp;rsquo;s dynamic nature, revealing how classifier preferences shift over time, influenced by dat&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/quylbzwttv/cover.png"/></item><item><title>CLUES: Collaborative Private-domain High-quality Data Selection for LLMs via Training Dynamics</title><link>https://deep-diver.github.io/neurips2024/posters/ou1uqd1vyw/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/ou1uqd1vyw/</guid><description>CLUES: Collaborative learning selects high-quality private data for LLM fine-tuning via training dynamics, significantly boosting performance in diverse domains.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/ou1uqd1vyw/cover.png"/></item><item><title>Constructing Semantics-Aware Adversarial Examples with Probabilistic Perspective</title><link>https://deep-diver.github.io/neurips2024/posters/wbe0qcbwji/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/wbe0qcbwji/</guid><description>Researchers developed semantics-aware adversarial examples using a probabilistic approach, achieving higher success rates in bypassing defenses while remaining undetectable to humans.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/wbe0qcbwji/cover.png"/></item><item><title>Context-Aware Testing: A New Paradigm for Model Testing with Large Language Models</title><link>https://deep-diver.github.io/neurips2024/posters/d75qczb7tx/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/d75qczb7tx/</guid><description>Context-Aware Testing (CAT) revolutionizes ML model testing by using contextual information to identify relevant failures, surpassing traditional data-only methods.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/d75qczb7tx/cover.png"/></item><item><title>Data-Driven Discovery of Dynamical Systems in Pharmacology using Large Language Models</title><link>https://deep-diver.github.io/neurips2024/posters/kirzmlta92/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/kirzmlta92/</guid><description>LLMs iteratively discover and refine interpretable dynamical systems models, achieving high accuracy and uncovering new insights; demonstrated by a novel Warfarin model.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/kirzmlta92/cover.png"/></item><item><title>Decomposable Transformer Point Processes</title><link>https://deep-diver.github.io/neurips2024/posters/oestejf0ls/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/oestejf0ls/</guid><description>Decomposable Transformer Point Processes (DTPP) dramatically accelerates marked point process inference by using a mixture of log-normals for inter-event times and Transformers for marks, outperformin&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/oestejf0ls/cover.png"/></item><item><title>Deep Equilibrium Algorithmic Reasoning</title><link>https://deep-diver.github.io/neurips2024/posters/sulxkxcena/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/sulxkxcena/</guid><description>Deep Equilibrium Algorithmic Reasoners (DEARs) achieve superior performance on algorithmic tasks by directly solving for the equilibrium point of a neural network, eliminating the need for iterative r&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/sulxkxcena/cover.png"/></item><item><title>Deep Learning Through A Telescoping Lens: A Simple Model Provides Empirical Insights On Grokking, Gradient Boosting &amp; Beyond</title><link>https://deep-diver.github.io/neurips2024/posters/nhucgztike/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/nhucgztike/</guid><description>A simple, yet accurate model unveils deep learning&amp;rsquo;s mysteries, providing empirical insights into grokking, double descent, and gradient boosting, offering a new lens for analyzing neural network beha&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/nhucgztike/cover.png"/></item><item><title>Efficient Lifelong Model Evaluation in an Era of Rapid Progress</title><link>https://deep-diver.github.io/neurips2024/posters/a7wc1ctkyl/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/a7wc1ctkyl/</guid><description>Sort &amp;amp; Search: 1000x faster lifelong model evaluation!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/a7wc1ctkyl/cover.png"/></item><item><title>End-to-End Ontology Learning with Large Language Models</title><link>https://deep-diver.github.io/neurips2024/posters/uqvehancjc/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/uqvehancjc/</guid><description>OLLM: An end-to-end LLM method builds ontologies from scratch, outperforming subtask approaches and improving semantic accuracy with novel evaluation metrics.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/uqvehancjc/cover.png"/></item><item><title>Fearless Stochasticity in Expectation Propagation</title><link>https://deep-diver.github.io/neurips2024/spotlight-others/3kdwoqs2x2/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-others/3kdwoqs2x2/</guid><description>This paper introduces EP-Œ∑ and EP-Œº, novel EP variants remarkably robust to Monte Carlo noise, achieving improved speed and accuracy.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-others/3kdwoqs2x2/cover.png"/></item><item><title>Generating Origin-Destination Matrices in Neural Spatial Interaction Models</title><link>https://deep-diver.github.io/neurips2024/posters/eucyie1azy/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/eucyie1azy/</guid><description>GeNSIT: a neural framework efficiently generates origin-destination matrices for agent-based models, outperforming existing methods in accuracy and scalability by directly operating on the discrete sp&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/eucyie1azy/cover.png"/></item><item><title>GRANOLA: Adaptive Normalization for Graph Neural Networks</title><link>https://deep-diver.github.io/neurips2024/posters/qd8blc0o0f/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/qd8blc0o0f/</guid><description>GRANOLA: A novel graph-adaptive normalization layer significantly boosts GNN performance by dynamically adjusting node features based on the input graph&amp;rsquo;s unique structure.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/qd8blc0o0f/cover.png"/></item><item><title>HEALNet: Multimodal Fusion for Heterogeneous Biomedical Data</title><link>https://deep-diver.github.io/neurips2024/posters/huxtjcqpds/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/huxtjcqpds/</guid><description>HEALNet: a novel multimodal fusion network achieving state-of-the-art performance on biomedical survival analysis by effectively integrating heterogeneous data while handling missing modalities.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/huxtjcqpds/cover.png"/></item><item><title>Improving Linear System Solvers for Hyperparameter Optimisation in Iterative Gaussian Processes</title><link>https://deep-diver.github.io/neurips2024/posters/cadbtyblov/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/cadbtyblov/</guid><description>Accelerate Gaussian process hyperparameter optimization by up to 72x using novel linear system solver techniques.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/cadbtyblov/cover.png"/></item><item><title>Localized Adaptive Risk Control</title><link>https://deep-diver.github.io/neurips2024/posters/fogjgrozu1/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/fogjgrozu1/</guid><description>Localized Adaptive Risk Control (L-ARC) improves fairness and reliability of online prediction by providing localized statistical risk guarantees, surpassing existing methods in high-stakes applicatio&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/fogjgrozu1/cover.png"/></item><item><title>Multi-language Diversity Benefits Autoformalization</title><link>https://deep-diver.github.io/neurips2024/posters/2jjfrm2r6d/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/2jjfrm2r6d/</guid><description>Researchers created MMA, a large multilingual dataset of informal-formal mathematical pairs, leveraging a language model for reverse translation. Fine-tuned models achieved significantly improved aut&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/2jjfrm2r6d/cover.png"/></item><item><title>Neural Characteristic Activation Analysis and Geometric Parameterization for ReLU Networks</title><link>https://deep-diver.github.io/neurips2024/posters/7hfqfrjdcn/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/7hfqfrjdcn/</guid><description>Researchers introduce Geometric Parameterization (GmP), a novel neural network parameterization resolving instability in ReLU network training, leading to faster convergence and better generalization.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/7hfqfrjdcn/cover.png"/></item><item><title>On conditional diffusion models for PDE simulations</title><link>https://deep-diver.github.io/neurips2024/posters/nql8ejymzh/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/nql8ejymzh/</guid><description>This paper introduces novel autoregressive sampling and hybrid training strategies for score-based diffusion models, significantly boosting PDE forecasting and assimilation accuracy.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/nql8ejymzh/cover.png"/></item><item><title>Partially Observable Cost-Aware Active-Learning with Large Language Models</title><link>https://deep-diver.github.io/neurips2024/posters/besco94wog/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/besco94wog/</guid><description>¬µPOCA: a new active learning approach maximizes model generalization using strategically acquired labels/features in data-scarce, costly scenarios with partial observability, leveraging LLMs for effic&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/besco94wog/cover.png"/></item><item><title>Predicting Future Actions of Reinforcement Learning Agents</title><link>https://deep-diver.github.io/neurips2024/posters/qgags7peye/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/qgags7peye/</guid><description>Predicting RL agent behavior is key for safety and interaction; this study reveals that explicitly planned agents are significantly easier to predict due to their internal plans.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/qgags7peye/cover.png"/></item><item><title>Predicting Ground State Properties: Constant Sample Complexity and Deep Learning Algorithms</title><link>https://deep-diver.github.io/neurips2024/posters/yblxvqjyqa/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/yblxvqjyqa/</guid><description>Deep learning algorithms now predict quantum ground state properties with constant sample complexity, regardless of system size, improving upon previous methods.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/yblxvqjyqa/cover.png"/></item><item><title>Recurrent neural network dynamical systems for biological vision</title><link>https://deep-diver.github.io/neurips2024/spotlight-others/zz94albmok/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-others/zz94albmok/</guid><description>CordsNet: a hybrid CNN-RNN architecture enabling biologically realistic, robust image recognition through continuous-time recurrent dynamics.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-others/zz94albmok/cover.png"/></item><item><title>Relational Concept Bottleneck Models</title><link>https://deep-diver.github.io/neurips2024/posters/g99bsv9pt5/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/g99bsv9pt5/</guid><description>Relational Concept Bottleneck Models (R-CBMs) merge interpretable CBMs with powerful GNNs for high-performing, explainable relational deep learning.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/g99bsv9pt5/cover.png"/></item><item><title>Repurposing Language Models into Embedding Models: Finding the Compute-Optimal Recipe</title><link>https://deep-diver.github.io/neurips2024/posters/kvl5rvkqgg/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/kvl5rvkqgg/</guid><description>This research unveils a compute-optimal recipe for fine-tuning language models into high-quality text embedding models, offering practical guidance and scaling laws for resource-constrained settings.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/kvl5rvkqgg/cover.png"/></item><item><title>Rule Extrapolation in Language Modeling: A Study of Compositional Generalization on OOD Prompts</title><link>https://deep-diver.github.io/neurips2024/spotlight-large-language-models/li2rprzwjy/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-large-language-models/li2rprzwjy/</guid><description>LLMs struggle with out-of-distribution (OOD) generalization. This research introduces &amp;lsquo;rule extrapolation&amp;rsquo; using formal languages to rigorously evaluate OOD behavior in various LLM architectures, rev&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-large-language-models/li2rprzwjy/cover.png"/></item><item><title>Second-order forward-mode optimization of recurrent neural networks for neuroscience</title><link>https://deep-diver.github.io/neurips2024/spotlight-others/pox8jnqoo5/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-others/pox8jnqoo5/</guid><description>SOFO: a novel second-order optimizer enables efficient and memory-friendly RNN training for neuroscience tasks, surpassing Adam&amp;rsquo;s performance, especially on long time horizons.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-others/pox8jnqoo5/cover.png"/></item><item><title>Self-Healing Machine Learning: A Framework for Autonomous Adaptation in Real-World Environments</title><link>https://deep-diver.github.io/neurips2024/posters/f63dkipx0i/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/f63dkipx0i/</guid><description>Self-healing machine learning (SHML) autonomously diagnoses and fixes model performance degradation caused by data shifts, outperforming reason-agnostic methods.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/f63dkipx0i/cover.png"/></item><item><title>TabEBM: A Tabular Data Augmentation Method with Distinct Class-Specific Energy-Based Models</title><link>https://deep-diver.github.io/neurips2024/posters/fmnofiimzg/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/fmnofiimzg/</guid><description>TabEBM: Class-specific EBMs boost tabular data augmentation, improving classification accuracy, especially on small datasets, by generating high-quality synthetic data.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/fmnofiimzg/cover.png"/></item><item><title>TinyTTA: Efficient Test-time Adaptation via Early-exit Ensembles on Edge Devices</title><link>https://deep-diver.github.io/neurips2024/posters/xicbcbe6c3/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/xicbcbe6c3/</guid><description>TinyTTA enables efficient test-time adaptation on memory-constrained edge devices using a novel self-ensemble and early-exit strategy, improving accuracy and reducing memory usage.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/xicbcbe6c3/cover.png"/></item><item><title>Zero-Shot Reinforcement Learning from Low Quality Data</title><link>https://deep-diver.github.io/neurips2024/posters/79ewvkljib/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/79ewvkljib/</guid><description>Zero-shot RL struggles with low-quality data; this paper introduces conservative algorithms that significantly boost performance on such data without sacrificing performance on high-quality data.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/79ewvkljib/cover.png"/></item><item><title>Zero-Shot Tokenizer Transfer</title><link>https://deep-diver.github.io/neurips2024/posters/rwbobrsizc/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/rwbobrsizc/</guid><description>Zero-Shot Tokenizer Transfer (ZeTT) detaches language models from their tokenizers via a hypernetwork, enabling efficient on-the-fly tokenizer swapping without retraining, significantly improving LLM &amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/rwbobrsizc/cover.png"/></item></channel></rss>