<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>üè¢ Stanford University on NeurIPS 2024</title><link>https://deep-diver.github.io/neurips2024/tags/-stanford-university/</link><description>Recent content in üè¢ Stanford University on NeurIPS 2024</description><generator>Hugo -- gohugo.io</generator><language>en</language><copyright>¬© 2025 AI Paper Reviewer</copyright><lastBuildDate>Thu, 26 Sep 2024 00:00:00 +0000</lastBuildDate><atom:link href="https://deep-diver.github.io/neurips2024/tags/-stanford-university/index.xml" rel="self" type="application/rss+xml"/><item><title>A Critical Evaluation of AI Feedback for Aligning Large Language Models</title><link>https://deep-diver.github.io/neurips2024/posters/fzqyfmsmx9/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/fzqyfmsmx9/</guid><description>Contrary to popular belief, simple supervised fine-tuning with strong language models outperforms complex reinforcement learning in aligning large language models, significantly improving efficiency.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/fzqyfmsmx9/cover.png"/></item><item><title>Accelerated Regularized Learning in Finite N-Person Games</title><link>https://deep-diver.github.io/neurips2024/posters/lw2zyqm0ox/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/lw2zyqm0ox/</guid><description>Accelerated learning in games achieved! FTXL algorithm exponentially speeds up convergence to Nash equilibria in finite N-person games, even under limited feedback.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/lw2zyqm0ox/cover.png"/></item><item><title>Accelerating Diffusion Models with Parallel Sampling: Inference at Sub-Linear Time Complexity</title><link>https://deep-diver.github.io/neurips2024/spotlight-others/f9ndzhqtol/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-others/f9ndzhqtol/</guid><description>Researchers achieve sub-linear time complexity for diffusion model inference using parallel sampling with poly-logarithmic time complexity.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-others/f9ndzhqtol/cover.png"/></item><item><title>ActAnywhere: Subject-Aware Video Background Generation</title><link>https://deep-diver.github.io/neurips2024/posters/ntlfrew59a/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/ntlfrew59a/</guid><description>ActAnywhere, a novel video diffusion model, seamlessly integrates foreground subjects into new backgrounds by generating realistic video backgrounds tailored to subject motion, significantly reducing &amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/ntlfrew59a/cover.png"/></item><item><title>Active Learning for Derivative-Based Global Sensitivity Analysis with Gaussian Processes</title><link>https://deep-diver.github.io/neurips2024/posters/da0zjatrcn/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/da0zjatrcn/</guid><description>Boost global sensitivity analysis efficiency by 10x with novel active learning methods targeting derivative-based measures for expensive black-box functions!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/da0zjatrcn/cover.png"/></item><item><title>ActSort: An active-learning accelerated cell sorting algorithm for large-scale calcium imaging datasets</title><link>https://deep-diver.github.io/neurips2024/posters/4czwwexzkq/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/4czwwexzkq/</guid><description>ActSort: Active learning dramatically accelerates cell sorting in massive calcium imaging datasets, minimizing human effort and improving accuracy.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/4czwwexzkq/cover.png"/></item><item><title>Adaptive Sampling for Efficient Softmax Approximation</title><link>https://deep-diver.github.io/neurips2024/posters/xsna2b8gpz/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/xsna2b8gpz/</guid><description>AdaptiveSoftmax: Achieve 10x+ speedup in softmax computation via adaptive sampling!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/xsna2b8gpz/cover.png"/></item><item><title>Aligning Model Properties via Conformal Risk Control</title><link>https://deep-diver.github.io/neurips2024/posters/9ohxqybmzb/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/9ohxqybmzb/</guid><description>Post-processing pre-trained models for alignment using conformal risk control and property testing guarantees better alignment, even when training data is biased.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/9ohxqybmzb/cover.png"/></item><item><title>Aligning Target-Aware Molecule Diffusion Models with Exact Energy Optimization</title><link>https://deep-diver.github.io/neurips2024/posters/ewcvxxtznu/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/ewcvxxtznu/</guid><description>ALIDIFF aligns target-aware molecule diffusion models with exact energy optimization, generating molecules with state-of-the-art binding energies and improved properties.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/ewcvxxtznu/cover.png"/></item><item><title>An Efficient High-dimensional Gradient Estimator for Stochastic Differential Equations</title><link>https://deep-diver.github.io/neurips2024/posters/780uxna4wn/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/780uxna4wn/</guid><description>New unbiased gradient estimator for high-dimensional SDEs drastically reduces computation time without sacrificing estimation accuracy.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/780uxna4wn/cover.png"/></item><item><title>Are More LLM Calls All You Need? Towards the Scaling Properties of Compound AI Systems</title><link>https://deep-diver.github.io/neurips2024/posters/m5106rrlgx/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/m5106rrlgx/</guid><description>More LM calls don&amp;rsquo;t always mean better results for compound AI; this study reveals performance can initially increase then decrease, highlighting the importance of optimal call number prediction.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/m5106rrlgx/cover.png"/></item><item><title>Automatic Outlier Rectification via Optimal Transport</title><link>https://deep-diver.github.io/neurips2024/posters/udxhmgjvjb/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/udxhmgjvjb/</guid><description>This study presents a novel single-step outlier rectification method using optimal transport with a concave cost function, surpassing the limitations of conventional two-stage approaches by jointly op&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/udxhmgjvjb/cover.png"/></item><item><title>AvaTaR: Optimizing LLM Agents for Tool Usage via Contrastive Reasoning</title><link>https://deep-diver.github.io/neurips2024/posters/n4qurxe19p/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/n4qurxe19p/</guid><description>AVATAR: A novel automated framework optimizes LLM agents for effective tool usage via contrastive reasoning, significantly boosting performance on complex tasks.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/n4qurxe19p/cover.png"/></item><item><title>Bayesian Strategic Classification</title><link>https://deep-diver.github.io/neurips2024/posters/sadbrpog2k/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/sadbrpog2k/</guid><description>Learners can improve accuracy in strategic classification by selectively revealing partial classifier information to agents, strategically guiding agent behavior and maximizing accuracy.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/sadbrpog2k/cover.png"/></item><item><title>Boosted Conformal Prediction Intervals</title><link>https://deep-diver.github.io/neurips2024/posters/tw032h2ons/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/tw032h2ons/</guid><description>Boosting conformal prediction intervals improves accuracy and precision by tailoring them to specific desired properties via machine learning.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/tw032h2ons/cover.png"/></item><item><title>Collaborative Video Diffusion: Consistent Multi-video Generation with Camera Control</title><link>https://deep-diver.github.io/neurips2024/posters/arhjlyiy2j/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/arhjlyiy2j/</guid><description>Collaborative Video Diffusion (CVD) generates multiple consistent videos from various camera angles using a novel cross-video synchronization module, significantly improving consistency compared to ex&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/arhjlyiy2j/cover.png"/></item><item><title>Compressing Large Language Models using Low Rank and Low Precision Decomposition</title><link>https://deep-diver.github.io/neurips2024/posters/lkx3opcqsz/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/lkx3opcqsz/</guid><description>CALDERA: a new post-training LLM compression algorithm achieving state-of-the-art zero-shot performance using low-rank, low-precision decomposition.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/lkx3opcqsz/cover.png"/></item><item><title>Consistency of Neural Causal Partial Identification</title><link>https://deep-diver.github.io/neurips2024/posters/gebnpxd9ef/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/gebnpxd9ef/</guid><description>Neural causal models consistently estimate partial causal effects, even with continuous/categorical variables, thanks to Lipschitz regularization.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/gebnpxd9ef/cover.png"/></item><item><title>Constrained Diffusion with Trust Sampling</title><link>https://deep-diver.github.io/neurips2024/posters/djub9xrozi/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/djub9xrozi/</guid><description>Trust Sampling enhances guided diffusion by iteratively optimizing constrained generation at each step, improving efficiency and accuracy in image and 3D motion generation.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/djub9xrozi/cover.png"/></item><item><title>Convolutional Differentiable Logic Gate Networks</title><link>https://deep-diver.github.io/neurips2024/oral-others/4bkefyuht4/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/oral-others/4bkefyuht4/</guid><description>Convolutional Differentiable Logic Gate Networks achieve state-of-the-art accuracy on CIFAR-10 with 29x fewer gates than existing models, demonstrating highly efficient deep learning inference.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/oral-others/4bkefyuht4/cover.png"/></item><item><title>CRONOS: Enhancing Deep Learning with Scalable GPU Accelerated Convex Neural Networks</title><link>https://deep-diver.github.io/neurips2024/posters/yflzyczao3/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/yflzyczao3/</guid><description>CRONOS: Scaling convex neural network training to ImageNet!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/yflzyczao3/cover.png"/></item><item><title>Deep Learning for Computing Convergence Rates of Markov Chains</title><link>https://deep-diver.github.io/neurips2024/spotlight-others/fqmsgk8c0b/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-others/fqmsgk8c0b/</guid><description>Deep learning tackles Markov chain convergence rate analysis! Deep Contractive Drift Calculator (DCDC) provides sample-based bounds in Wasserstein distance, surpassing traditional methods&amp;rsquo; limitations&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-others/fqmsgk8c0b/cover.png"/></item><item><title>Depth Anywhere: Enhancing 360 Monocular Depth Estimation via Perspective Distillation and Unlabeled Data Augmentation</title><link>https://deep-diver.github.io/neurips2024/posters/vzoybrqj4o/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/vzoybrqj4o/</guid><description>Depth Anywhere enhances 360-degree monocular depth estimation by cleverly using perspective models to label unlabeled 360-degree data, significantly improving accuracy.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/vzoybrqj4o/cover.png"/></item><item><title>Directional Smoothness and Gradient Methods: Convergence and Adaptivity</title><link>https://deep-diver.github.io/neurips2024/posters/m9wzrexwl5/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/m9wzrexwl5/</guid><description>New sub-optimality bounds for gradient descent leverage directional smoothness, a localized gradient variation measure, achieving tighter convergence guarantees and adapting to optimization paths.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/m9wzrexwl5/cover.png"/></item><item><title>Distributionally Robust Reinforcement Learning with Interactive Data Collection: Fundamental Hardness and Near-Optimal Algorithms</title><link>https://deep-diver.github.io/neurips2024/posters/aywtfsf3up/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/aywtfsf3up/</guid><description>Provably sample-efficient robust RL via interactive data collection is achieved by introducing the vanishing minimal value assumption to mitigate the curse of support shift, enabling near-optimal algo&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/aywtfsf3up/cover.png"/></item><item><title>FactorSim: Generative Simulation via Factorized Representation</title><link>https://deep-diver.github.io/neurips2024/posters/wbzvyh3pra/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/wbzvyh3pra/</guid><description>FACTORSim generates full, coded simulations from natural language descriptions, outperforming existing methods in accuracy and zero-shot transfer learning by using a factored POMDP representation.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/wbzvyh3pra/cover.png"/></item><item><title>Generalized Linear Bandits with Limited Adaptivity</title><link>https://deep-diver.github.io/neurips2024/spotlight-reinforcement-learning/ftpdbqut4g/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-reinforcement-learning/ftpdbqut4g/</guid><description>This paper introduces two novel algorithms, achieving optimal regret in generalized linear contextual bandits despite limited policy updates, a significant advancement for real-world applications.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-reinforcement-learning/ftpdbqut4g/cover.png"/></item><item><title>Geometric Trajectory Diffusion Models</title><link>https://deep-diver.github.io/neurips2024/posters/oymms5mv9h/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/oymms5mv9h/</guid><description>GeoTDM: First diffusion model generating realistic 3D geometric trajectories, capturing complex spatial interactions and temporal correspondence, significantly improving generation quality.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/oymms5mv9h/cover.png"/></item><item><title>Get rich quick: exact solutions reveal how unbalanced initializations promote rapid feature learning</title><link>https://deep-diver.github.io/neurips2024/spotlight-ai-theory/enm94i7r3a/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-ai-theory/enm94i7r3a/</guid><description>Unbalanced initializations dramatically accelerate neural network feature learning by modifying the geometry of learning trajectories, enabling faster feature extraction and improved generalization.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-ai-theory/enm94i7r3a/cover.png"/></item><item><title>Graph-based Uncertainty Metrics for Long-form Language Model Generations</title><link>https://deep-diver.github.io/neurips2024/spotlight-large-language-models/ygjpqw0lko/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-large-language-models/ygjpqw0lko/</guid><description>Graph Uncertainty boosts LLM factuality by 6.8% using graph centrality to estimate claim-level uncertainty and a novel uncertainty-aware decoding process.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-large-language-models/ygjpqw0lko/cover.png"/></item><item><title>GraphMETRO: Mitigating Complex Graph Distribution Shifts via Mixture of Aligned Experts</title><link>https://deep-diver.github.io/neurips2024/posters/qtyg4g3deu/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/qtyg4g3deu/</guid><description>GraphMETRO tackles complex graph distribution shifts by using a Mixture-of-Experts model to decompose shifts into interpretable components, achieving state-of-the-art results.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/qtyg4g3deu/cover.png"/></item><item><title>Grasp as You Say: Language-guided Dexterous Grasp Generation</title><link>https://deep-diver.github.io/neurips2024/posters/qewibatmnn/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/qewibatmnn/</guid><description>Robots can now dexterously grasp objects based on natural language commands thanks to DexGYS, a new language-guided dexterous grasp generation framework and dataset.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/qewibatmnn/cover.png"/></item><item><title>Higher-Order Causal Message Passing for Experimentation with Complex Interference</title><link>https://deep-diver.github.io/neurips2024/posters/3vjbgcjgvd/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/3vjbgcjgvd/</guid><description>Higher-Order Causal Message Passing (HO-CMP) accurately estimates treatment effects in complex systems with unknown interference by using observed data to learn the system&amp;rsquo;s dynamics over time.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/3vjbgcjgvd/cover.png"/></item><item><title>Instructor-inspired Machine Learning for Robust Molecular Property Prediction</title><link>https://deep-diver.github.io/neurips2024/posters/j7sw0nxljz/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/j7sw0nxljz/</guid><description>InstructMol, a novel semi-supervised learning algorithm, leverages unlabeled data and an instructor model to significantly improve the accuracy and robustness of molecular property prediction, even wi&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/j7sw0nxljz/cover.png"/></item><item><title>Large language model validity via enhanced conformal prediction methods</title><link>https://deep-diver.github.io/neurips2024/posters/jd3nypeq3r/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/jd3nypeq3r/</guid><description>New conformal inference methods enhance LLM validity by providing adaptive validity guarantees and improving the quality of LLM outputs, addressing prior methods&amp;rsquo; limitations.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/jd3nypeq3r/cover.png"/></item><item><title>Learning Formal Mathematics From Intrinsic Motivation</title><link>https://deep-diver.github.io/neurips2024/oral-reinforcement-learning/unkltq8mbd/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/oral-reinforcement-learning/unkltq8mbd/</guid><description>AI agent MINIMO learns to generate challenging mathematical conjectures and prove them, bootstrapping from axioms alone and self-improving in both conjecture generation and theorem proving.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/oral-reinforcement-learning/unkltq8mbd/cover.png"/></item><item><title>Learning Linear Causal Representations from General Environments: Identifiability and Intrinsic Ambiguity</title><link>https://deep-diver.github.io/neurips2024/spotlight-ai-theory/db99jjwx3h/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-ai-theory/db99jjwx3h/</guid><description>LiNGCREL, a novel algorithm, provably recovers linear causal representations from diverse environments, achieving identifiability despite intrinsic ambiguities, thus advancing causal AI.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-ai-theory/db99jjwx3h/cover.png"/></item><item><title>Make-it-Real: Unleashing Large Multimodal Model for Painting 3D Objects with Realistic Materials</title><link>https://deep-diver.github.io/neurips2024/posters/88rbnotaez/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/88rbnotaez/</guid><description>Make-it-Real uses a large multimodal language model to automatically paint realistic materials onto 3D objects, drastically improving realism and saving developers time.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/88rbnotaez/cover.png"/></item><item><title>Mixture of neural fields for heterogeneous reconstruction in cryo-EM</title><link>https://deep-diver.github.io/neurips2024/posters/tusponzidb/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/tusponzidb/</guid><description>Hydra: a novel cryo-EM reconstruction method resolves both conformational and compositional heterogeneity ab initio, enabling the analysis of complex, unpurified samples with state-of-the-art accuracy&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/tusponzidb/cover.png"/></item><item><title>Modeling Latent Neural Dynamics with Gaussian Process Switching Linear Dynamical Systems</title><link>https://deep-diver.github.io/neurips2024/posters/lx1lwp90kt/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/lx1lwp90kt/</guid><description>gpSLDS, a novel model, balances expressiveness and interpretability in modeling complex neural dynamics by combining Gaussian processes with switching linear dynamical systems, improving accuracy and &amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/lx1lwp90kt/cover.png"/></item><item><title>MoEUT: Mixture-of-Experts Universal Transformers</title><link>https://deep-diver.github.io/neurips2024/posters/zxvrkm7bjl/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/zxvrkm7bjl/</guid><description>MoEUT: Mixture-of-Experts Universal Transformers significantly improves the compute efficiency of Universal Transformers, making them competitive with standard Transformers in large-scale language mod&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/zxvrkm7bjl/cover.png"/></item><item><title>Near-Optimal Streaming Heavy-Tailed Statistical Estimation with Clipped SGD</title><link>https://deep-diver.github.io/neurips2024/posters/8jauriwdeh/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/8jauriwdeh/</guid><description>Clipped SGD achieves near-optimal sub-Gaussian rates for high-dimensional heavy-tailed statistical estimation in streaming settings, improving upon existing state-of-the-art results.</description></item><item><title>Neural decoding from stereotactic EEG: accounting for electrode variability across subjects</title><link>https://deep-diver.github.io/neurips2024/posters/lr1nnsd7h0/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/lr1nnsd7h0/</guid><description>Scalable SEEG decoding model, seegnificant, leverages transformers to decode behavior across subjects despite electrode variability, achieving high accuracy and transfer learning capability.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/lr1nnsd7h0/cover.png"/></item><item><title>Newton Losses: Using Curvature Information for Learning with Differentiable Algorithms</title><link>https://deep-diver.github.io/neurips2024/posters/vjaorqq71s/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/vjaorqq71s/</guid><description>Newton Losses enhance training of neural networks with complex objectives by using second-order information from loss functions, achieving significant performance gains.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/vjaorqq71s/cover.png"/></item><item><title>OccFusion: Rendering Occluded Humans with Generative Diffusion Priors</title><link>https://deep-diver.github.io/neurips2024/posters/czwphz5vgz/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/czwphz5vgz/</guid><description>OccFusion: High-fidelity human rendering from videos, even with occlusions, using 3D Gaussian splatting and 2D diffusion priors.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/czwphz5vgz/cover.png"/></item><item><title>Off-Policy Selection for Initiating Human-Centric Experimental Design</title><link>https://deep-diver.github.io/neurips2024/posters/swp3lpdmze/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/swp3lpdmze/</guid><description>First-Glance Off-Policy Selection (FPS) revolutionizes human-centric AI by enabling personalized policy selection for new participants without prior data, improving learning and healthcare outcomes.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/swp3lpdmze/cover.png"/></item><item><title>OPERA: Automatic Offline Policy Evaluation with Re-weighted Aggregates of Multiple Estimators</title><link>https://deep-diver.github.io/neurips2024/posters/t6logzbc2m/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/t6logzbc2m/</guid><description>OPERA: A new algorithm intelligently blends multiple offline policy evaluation estimators for more accurate policy performance estimates.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/t6logzbc2m/cover.png"/></item><item><title>Optimistic Verifiable Training by Controlling Hardware Nondeterminism</title><link>https://deep-diver.github.io/neurips2024/posters/bf0mdflz1i/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/bf0mdflz1i/</guid><description>Researchers developed a verifiable training method that uses high-precision training with adaptive rounding and logging to achieve exact training replication across different GPUs, enabling efficient &amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/bf0mdflz1i/cover.png"/></item><item><title>Optimization Algorithm Design via Electric Circuits</title><link>https://deep-diver.github.io/neurips2024/spotlight-ai-theory/9jmt1eer9p/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-ai-theory/9jmt1eer9p/</guid><description>Design provably convergent optimization algorithms swiftly using electric circuit analogies; a novel methodology automating discretization for diverse algorithms.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-ai-theory/9jmt1eer9p/cover.png"/></item><item><title>PaGoDA: Progressive Growing of a One-Step Generator from a Low-Resolution Diffusion Teacher</title><link>https://deep-diver.github.io/neurips2024/posters/h5zygf68kh/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/h5zygf68kh/</guid><description>PaGoDA: Train high-resolution image generators efficiently by progressively growing a one-step generator from a low-resolution diffusion model. This innovative pipeline drastically cuts training cost&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/h5zygf68kh/cover.png"/></item><item><title>Policy-shaped prediction: avoiding distractions in model-based reinforcement learning</title><link>https://deep-diver.github.io/neurips2024/posters/hgdh4foghu/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/hgdh4foghu/</guid><description>Policy-Shaped Prediction (PSP) improves model-based reinforcement learning by focusing world models on task-relevant information, significantly enhancing robustness against distracting stimuli.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/hgdh4foghu/cover.png"/></item><item><title>Post-Hoc Reversal: Are We Selecting Models Prematurely?</title><link>https://deep-diver.github.io/neurips2024/posters/3r7go6wkdm/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/3r7go6wkdm/</guid><description>Post-hoc model transformations can reverse performance trends, prompting a reevaluation of model selection strategies and suggesting a new &amp;lsquo;post-hoc selection&amp;rsquo; method for improved model development.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/3r7go6wkdm/cover.png"/></item><item><title>ProvNeRF: Modeling per Point Provenance in NeRFs as a Stochastic Field</title><link>https://deep-diver.github.io/neurips2024/posters/k5pa3sk2jb/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/k5pa3sk2jb/</guid><description>ProvNeRF enhances NeRF reconstruction by modeling per-point provenance as a stochastic field, improving novel view synthesis and uncertainty estimation, particularly in sparse, unconstrained view sett&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/k5pa3sk2jb/cover.png"/></item><item><title>Quantifying the Gain in Weak-to-Strong Generalization</title><link>https://deep-diver.github.io/neurips2024/posters/myvyh5jo1l/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/myvyh5jo1l/</guid><description>Weakly supervised strong models outperform weak models; this gain is precisely quantified by the strong model&amp;rsquo;s misfit error on weak labels.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/myvyh5jo1l/cover.png"/></item><item><title>RaVL: Discovering and Mitigating Spurious Correlations in Fine-Tuned Vision-Language Models</title><link>https://deep-diver.github.io/neurips2024/posters/ufrzhfyw8e/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/ufrzhfyw8e/</guid><description>RAVL: a novel approach that accurately discovers and effectively mitigates spurious correlations in fine-tuned vision-language models, improving zero-shot classification accuracy.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/ufrzhfyw8e/cover.png"/></item><item><title>ReFT: Representation Finetuning for Language Models</title><link>https://deep-diver.github.io/neurips2024/spotlight-large-language-models/fykjplmc0v/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-large-language-models/fykjplmc0v/</guid><description>ReFT: Revolutionizing language model finetuning by directly manipulating hidden representations, achieving superior efficiency and performance compared to existing methods.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-large-language-models/fykjplmc0v/cover.png"/></item><item><title>Scaling Laws for Reward Model Overoptimization in Direct Alignment Algorithms</title><link>https://deep-diver.github.io/neurips2024/posters/pf4oujyn4q/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/pf4oujyn4q/</guid><description>Direct Alignment Algorithms (DAAs) for LLM alignment suffer from over-optimization, even without explicit reward models; this paper empirically demonstrates this and proposes scaling laws to understan&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/pf4oujyn4q/cover.png"/></item><item><title>Scaling Laws with Vocabulary: Larger Models Deserve Larger Vocabularies</title><link>https://deep-diver.github.io/neurips2024/posters/skckpr8crl/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/skckpr8crl/</guid><description>Boosting LLM performance: This research shows how larger language models need bigger vocabularies for optimal efficiency and performance.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/skckpr8crl/cover.png"/></item><item><title>Segment Any Change</title><link>https://deep-diver.github.io/neurips2024/posters/d7x9grmd7l/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/d7x9grmd7l/</guid><description>AnyChange achieves zero-shot image change detection by adapting the Segment Anything Model (SAM) via a training-free bitemporal latent matching method, significantly outperforming previous state-of-th&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/d7x9grmd7l/cover.png"/></item><item><title>Self-Refining Diffusion Samplers: Enabling Parallelization via Parareal Iterations</title><link>https://deep-diver.github.io/neurips2024/posters/xhwkhfwi3k/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/xhwkhfwi3k/</guid><description>Self-Refining Diffusion Samplers (SRDS) dramatically speeds up diffusion model sampling by leveraging Parareal iterations for parallel-in-time computation, maintaining high-quality outputs.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/xhwkhfwi3k/cover.png"/></item><item><title>Self-Supervised Alignment with Mutual Information: Learning to Follow Principles without Preference Labels</title><link>https://deep-diver.github.io/neurips2024/posters/uvbpbehgaw/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/uvbpbehgaw/</guid><description>SAMI: Self-Supervised Alignment with Mutual Information, effectively teaches language models to follow principles without human preference labels by maximizing the mutual information between principle&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/uvbpbehgaw/cover.png"/></item><item><title>Smoothie: Label Free Language Model Routing</title><link>https://deep-diver.github.io/neurips2024/posters/ppswhsgqrp/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/ppswhsgqrp/</guid><description>SMOOTHIE: Label-free LLM routing achieves up to 10% accuracy gains by using a latent variable model to estimate LLM quality without labeled data.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/ppswhsgqrp/cover.png"/></item><item><title>Spectral Adapter: Fine-Tuning in Spectral Space</title><link>https://deep-diver.github.io/neurips2024/posters/uoxuaogv6b/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/uoxuaogv6b/</guid><description>Spectral Adapter boosts parameter-efficient fine-tuning by incorporating pretrained weight matrices&amp;rsquo; spectral information, enhancing efficiency and multi-adapter fusion.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/uoxuaogv6b/cover.png"/></item><item><title>Stochastic Amortization: A Unified Approach to Accelerate Feature and Data Attribution</title><link>https://deep-diver.github.io/neurips2024/posters/zdwtn2hoie/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/zdwtn2hoie/</guid><description>Stochastic Amortization accelerates feature and data attribution by training amortized models using noisy, yet unbiased, labels, achieving order-of-magnitude speedups over existing methods.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/zdwtn2hoie/cover.png"/></item><item><title>Structured flexibility in recurrent neural networks via neuromodulation</title><link>https://deep-diver.github.io/neurips2024/posters/hbibqn3grd/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/hbibqn3grd/</guid><description>Neuromodulated RNNs (NM-RNNs) enhance RNN flexibility by dynamically scaling recurrent weights using a neuromodulatory subnetwork, achieving higher accuracy and generalizability on various tasks compa&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/hbibqn3grd/cover.png"/></item><item><title>SwitchHead: Accelerating Transformers with Mixture-of-Experts Attention</title><link>https://deep-diver.github.io/neurips2024/posters/80ssl69gaz/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/80ssl69gaz/</guid><description>SwitchHead: A novel MoE attention mechanism accelerates Transformers by significantly reducing computation and memory, matching baseline performance.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/80ssl69gaz/cover.png"/></item><item><title>Test-time Adaptation in Non-stationary Environments via Adaptive Representation Alignment</title><link>https://deep-diver.github.io/neurips2024/posters/0efuyvmrlv/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/0efuyvmrlv/</guid><description>Ada-ReAlign: a novel algorithm for continual test-time adaptation that leverages non-stationary representation learning to effectively align unlabeled data streams with source data, enhancing model ad&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/0efuyvmrlv/cover.png"/></item><item><title>TFG: Unified Training-Free Guidance for Diffusion Models</title><link>https://deep-diver.github.io/neurips2024/spotlight-others/n8ybgx98vc/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-others/n8ybgx98vc/</guid><description>TFG: A unified, training-free framework for boosting diffusion model performance by efficiently searching its algorithm-agnostic design space.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-others/n8ybgx98vc/cover.png"/></item><item><title>TrAct: Making First-layer Pre-Activations Trainable</title><link>https://deep-diver.github.io/neurips2024/posters/gccmzedgbo/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/gccmzedgbo/</guid><description>TrAct boosts vision model training by directly optimizing first-layer activations, leading to significant speedups (1.25x-4x) and improved accuracy.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/gccmzedgbo/cover.png"/></item><item><title>Truncated Variance Reduced Value Iteration</title><link>https://deep-diver.github.io/neurips2024/posters/biikum6plu/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/biikum6plu/</guid><description>Faster algorithms for solving discounted Markov Decision Processes (DMDPs) are introduced, achieving near-optimal sample and time complexities, especially in the sample setting and improving runtimes &amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/biikum6plu/cover.png"/></item><item><title>Universal Exact Compression of Differentially Private Mechanisms</title><link>https://deep-diver.github.io/neurips2024/posters/cggjt8eg8a/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/cggjt8eg8a/</guid><description>Poisson Private Representation (PPR) enables exact compression of any local differential privacy mechanism, achieving order-wise optimal trade-offs between communication, accuracy, and privacy.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/cggjt8eg8a/cover.png"/></item><item><title>Universal Neural Functionals</title><link>https://deep-diver.github.io/neurips2024/posters/w89fkkp2ao/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/w89fkkp2ao/</guid><description>Universal Neural Functionals (UNFs) automatically construct permutation-equivariant models for any weight space, improving learned optimizer performance and generalization.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/w89fkkp2ao/cover.png"/></item><item><title>Why are Visually-Grounded Language Models Bad at Image Classification?</title><link>https://deep-diver.github.io/neurips2024/posters/mwmmbg1vyg/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/mwmmbg1vyg/</guid><description>Visually-grounded Language Models (VLMs) surprisingly underperform in image classification. This study reveals that this is primarily due to a lack of sufficient classification data during VLM trainin&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/mwmmbg1vyg/cover.png"/></item></channel></rss>