<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>üè¢ University of Washington on NeurIPS 2024</title><link>https://deep-diver.github.io/neurips2024/tags/-university-of-washington/</link><description>Recent content in üè¢ University of Washington on NeurIPS 2024</description><generator>Hugo -- gohugo.io</generator><language>en</language><copyright>¬© 2025 AI Paper Reviewer</copyright><lastBuildDate>Thu, 26 Sep 2024 00:00:00 +0000</lastBuildDate><atom:link href="https://deep-diver.github.io/neurips2024/tags/-university-of-washington/index.xml" rel="self" type="application/rss+xml"/><item><title>A Near-optimal Algorithm for Learning Margin Halfspaces with Massart Noise</title><link>https://deep-diver.github.io/neurips2024/spotlight-others/4aewzkwb5z/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-others/4aewzkwb5z/</guid><description>Near-optimal algorithm achieves computationally efficient learning of margin halfspaces with Massart noise, nearly matching theoretical lower bounds.</description></item><item><title>A Unifying Normative Framework of Decision Confidence</title><link>https://deep-diver.github.io/neurips2024/posters/brvgfn3xfm/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/brvgfn3xfm/</guid><description>New normative framework for decision confidence models diverse tasks by incorporating rewards, priors, and uncertainty, outperforming existing methods.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/brvgfn3xfm/cover.png"/></item><item><title>AV-Cloud: Spatial Audio Rendering Through Audio-Visual Cloud Splatting</title><link>https://deep-diver.github.io/neurips2024/posters/yxorsms5wr/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/yxorsms5wr/</guid><description>AV-Cloud: Real-time, high-quality 3D spatial audio rendering synced with visuals, bypassing pre-rendered images for immersive virtual experiences.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/yxorsms5wr/cover.png"/></item><item><title>CLIPLoss and Norm-Based Data Selection Methods for Multimodal Contrastive Learning</title><link>https://deep-diver.github.io/neurips2024/spotlight-others/qvdc0ocx2n/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-others/qvdc0ocx2n/</guid><description>Boosting multimodal contrastive learning, this research introduces negCLIPLoss and NormSim, novel data selection methods surpassing existing techniques by improving data quality and task relevance. Th&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-others/qvdc0ocx2n/cover.png"/></item><item><title>Cryptographic Hardness of Score Estimation</title><link>https://deep-diver.github.io/neurips2024/posters/urqxbwm0md/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/urqxbwm0md/</guid><description>Score estimation, crucial for diffusion models, is computationally hard even with polynomial sample complexity unless strong distributional assumptions are made.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/urqxbwm0md/cover.png"/></item><item><title>Customized Multiple Clustering via Multi-Modal Subspace Proxy Learning</title><link>https://deep-diver.github.io/neurips2024/posters/xbuastqaez/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/xbuastqaez/</guid><description>Multi-Sub leverages multi-modal learning to achieve customized multiple clustering, aligning user-defined textual preferences with visual representations via a subspace proxy learning framework.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/xbuastqaez/cover.png"/></item><item><title>Data Mixture Inference Attack: BPE Tokenizers Reveal Training Data Compositions</title><link>https://deep-diver.github.io/neurips2024/posters/ehxyeimux0/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/ehxyeimux0/</guid><description>Researchers uncover hidden training data secrets of large language models by analyzing their byte-pair encoding tokenizers, revealing the proportions of different languages and domains.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/ehxyeimux0/cover.png"/></item><item><title>Deep Submodular Peripteral Networks</title><link>https://deep-diver.github.io/neurips2024/spotlight-others/tupcrqnvvm/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-others/tupcrqnvvm/</guid><description>Deep Submodular Peripteral Networks (DSPNs) learn submodular functions efficiently using graded pairwise comparisons, surpassing traditional methods and demonstrating superiority in experimental desig&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-others/tupcrqnvvm/cover.png"/></item><item><title>Discovering plasticity rules that organize and maintain neural circuits</title><link>https://deep-diver.github.io/neurips2024/posters/nw4twuepgx/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/nw4twuepgx/</guid><description>AI discovers robust, biologically-plausible plasticity rules that self-organize and maintain neural circuits&amp;rsquo; sequential activity, even with synaptic turnover.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/nw4twuepgx/cover.png"/></item><item><title>Distributional Successor Features Enable Zero-Shot Policy Optimization</title><link>https://deep-diver.github.io/neurips2024/posters/8iysmgzte4/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/8iysmgzte4/</guid><description>DiSPOs: a novel model for zero-shot policy optimization in reinforcement learning, enabling quick adaptation to new tasks by learning a distribution of successor features and avoiding compounding erro&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/8iysmgzte4/cover.png"/></item><item><title>Drago: Primal-Dual Coupled Variance Reduction for Faster Distributionally Robust Optimization</title><link>https://deep-diver.github.io/neurips2024/posters/ujk0xrntqz/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/ujk0xrntqz/</guid><description>DRAGO: A novel primal-dual algorithm delivers faster, state-of-the-art convergence for distributionally robust optimization.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/ujk0xrntqz/cover.png"/></item><item><title>From an Image to a Scene: Learning to Imagine the World from a Million 360¬∞ Videos</title><link>https://deep-diver.github.io/neurips2024/posters/otxotswcmb/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/otxotswcmb/</guid><description>ODIN, trained on a million 360¬∞ videos (360-1M), generates realistic novel views and reconstructs 3D scenes from single images.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/otxotswcmb/cover.png"/></item><item><title>How does Gradient Descent Learn Features --- A Local Analysis for Regularized Two-Layer Neural Networks</title><link>https://deep-diver.github.io/neurips2024/posters/xyw051zmun/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/xyw051zmun/</guid><description>Neural networks learn features effectively through gradient descent, not just at the beginning, but also at the end of training, even with carefully regularized objectives.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/xyw051zmun/cover.png"/></item><item><title>Initializing Services in Interactive ML Systems for Diverse Users</title><link>https://deep-diver.github.io/neurips2024/posters/hsjot2hydf/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/hsjot2hydf/</guid><description>Adaptively initializing multi-service ML systems for diverse users using minimal data, this paper introduces a randomized algorithm achieving near-optimal loss with provable guarantees.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/hsjot2hydf/cover.png"/></item><item><title>Is O(log N) practical? Near-Equivalence Between Delay Robustness and Bounded Regret in Bandits and RL</title><link>https://deep-diver.github.io/neurips2024/posters/hyjofwfw1p/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/hyjofwfw1p/</guid><description>Zero Graves-Lai constant ensures both bounded regret and delay robustness in online decision-making, particularly for linear models.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/hyjofwfw1p/cover.png"/></item><item><title>Large Scale Transfer Learning for Tabular Data via Language Modeling</title><link>https://deep-diver.github.io/neurips2024/posters/wh5blx5tz1/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/wh5blx5tz1/</guid><description>TABULA-8B, a novel language model for tabular prediction, achieves state-of-the-art zero-shot and few-shot performance across various benchmarks, exceeding existing methods by 5-15 percentage points.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/wh5blx5tz1/cover.png"/></item><item><title>Learning Optimal Tax Design in Nonatomic Congestion Games</title><link>https://deep-diver.github.io/neurips2024/posters/qdprhde3jb/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/qdprhde3jb/</guid><description>AI learns optimal taxes for congestion games, maximizing social welfare with limited feedback, via a novel algorithm.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/qdprhde3jb/cover.png"/></item><item><title>Learning to Cooperate with Humans using Generative Agents</title><link>https://deep-diver.github.io/neurips2024/posters/v4dxl3lsgx/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/v4dxl3lsgx/</guid><description>Generative Agent Modeling for Multi-agent Adaptation (GAMMA) improves human-AI cooperation by training AI agents against diverse partners generated from a latent model, enhancing zero-shot coordinatio&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/v4dxl3lsgx/cover.png"/></item><item><title>Learning to Price Homogeneous Data</title><link>https://deep-diver.github.io/neurips2024/posters/koytqns6sz/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/koytqns6sz/</guid><description>This paper develops efficient algorithms for pricing homogeneous data in online settings, achieving low regret using novel discretization schemes that scale well with data size and number of buyer typ&amp;hellip;</description></item><item><title>MAGNET: Improving the Multilingual Fairness of Language Models with Adaptive Gradient-Based Tokenization</title><link>https://deep-diver.github.io/neurips2024/posters/1e3mowhsix/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/1e3mowhsix/</guid><description>MAGNET, a novel adaptive gradient-based tokenization method, tackles multilingual language model bias by employing language-specific boundary predictors to achieve equitable segmentation across divers&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/1e3mowhsix/cover.png"/></item><item><title>MediQ: Question-Asking LLMs and a Benchmark for Reliable Interactive Clinical Reasoning</title><link>https://deep-diver.github.io/neurips2024/posters/w4pibq7bai/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/w4pibq7bai/</guid><description>MEDIQ benchmark revolutionizes LLM evaluation by shifting from static to interactive clinical reasoning, revealing LLMs&amp;rsquo; struggles with proactive information-seeking and highlighting the importance of&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/w4pibq7bai/cover.png"/></item><item><title>Meta-Diffu$B$: A Contextualized Sequence-to-Sequence Text Diffusion Model with Meta-Exploration</title><link>https://deep-diver.github.io/neurips2024/posters/ntwxvvixjm/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/ntwxvvixjm/</guid><description>Meta-DiffuB enhances sequence-to-sequence text diffusion models by using meta-exploration to learn a contextualized noise schedule, resulting in state-of-the-art performance.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/ntwxvvixjm/cover.png"/></item><item><title>Multilingual Diversity Improves Vision-Language Representations</title><link>https://deep-diver.github.io/neurips2024/spotlight-others/1wteqrecys/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-others/1wteqrecys/</guid><description>Boosting vision-language models: Multilingual data improves performance on English-centric benchmarks.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-others/1wteqrecys/cover.png"/></item><item><title>Nearly Minimax Optimal Submodular Maximization with Bandit Feedback</title><link>https://deep-diver.github.io/neurips2024/posters/vn0fwrimra/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/vn0fwrimra/</guid><description>This research establishes the first minimax optimal algorithm for submodular maximization with bandit feedback, achieving a regret bound matching the lower bound.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/vn0fwrimra/cover.png"/></item><item><title>Nearly Optimal Approximation of Matrix Functions by the Lanczos Method</title><link>https://deep-diver.github.io/neurips2024/spotlight-ai-theory/3s8v8qp9xv/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-ai-theory/3s8v8qp9xv/</guid><description>Lanczos-FA, a simple algorithm for approximating matrix functions, surprisingly outperforms newer methods; this paper proves its near-optimality for rational functions, explaining its practical succes&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-ai-theory/3s8v8qp9xv/cover.png"/></item><item><title>On the Complexity of Teaching a Family of Linear Behavior Cloning Learners</title><link>https://deep-diver.github.io/neurips2024/posters/4sar7irqmb/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/4sar7irqmb/</guid><description>A novel algorithm, TIE, optimally teaches a family of linear behavior cloning learners, achieving instance-optimal teaching dimension while providing efficient approximation for larger action spaces.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/4sar7irqmb/cover.png"/></item><item><title>Personalizing Reinforcement Learning from Human Feedback with Variational Preference Learning</title><link>https://deep-diver.github.io/neurips2024/spotlight-reinforcement-learning/grg6szbw9p/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-reinforcement-learning/grg6szbw9p/</guid><description>VPL: a novel multimodal RLHF personalizes AI by inferring user-specific latent preferences, enabling accurate reward modeling and improved policy alignment for diverse populations.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-reinforcement-learning/grg6szbw9p/cover.png"/></item><item><title>Query-Based Adversarial Prompt Generation</title><link>https://deep-diver.github.io/neurips2024/posters/jbf3eiyd2x/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/jbf3eiyd2x/</guid><description>Researchers developed a query-based attack that generates adversarial prompts, fooling language models into producing harmful outputs with significantly higher success rates than previous methods, eff&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/jbf3eiyd2x/cover.png"/></item><item><title>QUEST: Quality-Aware Metropolis-Hastings Sampling for Machine Translation</title><link>https://deep-diver.github.io/neurips2024/posters/dlnduwgtb4/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/dlnduwgtb4/</guid><description>QUEST, a novel Metropolis-Hastings sampling method, generates high-quality &amp;amp; diverse machine translations by using quality metrics as energy functions, overcoming limitations of likelihood-based and r&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/dlnduwgtb4/cover.png"/></item><item><title>Sample Complexity Reduction via Policy Difference Estimation in Tabular Reinforcement Learning</title><link>https://deep-diver.github.io/neurips2024/spotlight-reinforcement-learning/ryq0kuzvkl/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-reinforcement-learning/ryq0kuzvkl/</guid><description>This paper reveals that estimating only policy differences, while effective in bandits, is insufficient for tabular reinforcement learning. However, it introduces a novel algorithm achieving near-opti&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-reinforcement-learning/ryq0kuzvkl/cover.png"/></item><item><title>Scaling Retrieval-Based Language Models with a Trillion-Token Datastore</title><link>https://deep-diver.github.io/neurips2024/posters/iakhpz7qt3/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/iakhpz7qt3/</guid><description>Massive language models improve with bigger datastores at inference time. A 1.4 trillion-token datastore, MASSIVEDS, shows that retrieval-based LMs outperform larger, solely-trained models on knowled&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/iakhpz7qt3/cover.png"/></item><item><title>Self-Calibrating Conformal Prediction</title><link>https://deep-diver.github.io/neurips2024/posters/bj6hkt7qik/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/bj6hkt7qik/</guid><description>Self-Calibrating Conformal Prediction (SC-CP) marries model calibration and conformal prediction for more efficient and interpretable prediction intervals with prediction-conditional validity.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/bj6hkt7qik/cover.png"/></item><item><title>Smoothed Energy Guidance: Guiding Diffusion Models with Reduced Energy Curvature of Attention</title><link>https://deep-diver.github.io/neurips2024/posters/jk728xy8g7/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/jk728xy8g7/</guid><description>Smoothed Energy Guidance (SEG) improves unconditional image generation by reducing self-attention&amp;rsquo;s energy curvature, leading to higher-quality outputs with fewer artifacts.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/jk728xy8g7/cover.png"/></item><item><title>Superposed Decoding: Multiple Generations from a Single Autoregressive Inference Pass</title><link>https://deep-diver.github.io/neurips2024/posters/ksokkhm9i7/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/ksokkhm9i7/</guid><description>Generate multiple text drafts from a single language model pass with Superposed Decoding, significantly boosting efficiency!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/ksokkhm9i7/cover.png"/></item><item><title>Swift Sampler: Efficient Learning of Sampler by 10 Parameters</title><link>https://deep-diver.github.io/neurips2024/posters/mlhz8znoek/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/mlhz8znoek/</guid><description>Swift Sampler (SS) automates the learning of efficient data samplers for deep learning, achieving significant performance gains (e.g., 1.5% on ImageNet) with minimal computational cost using only 10 p&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/mlhz8znoek/cover.png"/></item><item><title>Tell What You Hear From What You See - Video to Audio Generation Through Text</title><link>https://deep-diver.github.io/neurips2024/posters/kr7en85mit/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/kr7en85mit/</guid><description>VATT: Text-guided video-to-audio generation, enabling refined audio control via text prompts and improved compatibility.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/kr7en85mit/cover.png"/></item><item><title>The Benefits of Balance: From Information Projections to Variance Reduction</title><link>https://deep-diver.github.io/neurips2024/posters/vjmmdffl0a/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/vjmmdffl0a/</guid><description>Data balancing in foundation models surprisingly reduces variance, improving model training and performance.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/vjmmdffl0a/cover.png"/></item><item><title>The Unmet Promise of Synthetic Training Images: Using Retrieved Real Images Performs Better</title><link>https://deep-diver.github.io/neurips2024/posters/fnoleqa9rx/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/fnoleqa9rx/</guid><description>Using real images retrieved from a generator&amp;rsquo;s training data outperforms using synthetic images generated by that same model for image classification.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/fnoleqa9rx/cover.png"/></item><item><title>Toward Global Convergence of Gradient EM for Over-Paramterized Gaussian Mixture Models</title><link>https://deep-diver.github.io/neurips2024/posters/zv9gyc3xgf/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/zv9gyc3xgf/</guid><description>Gradient EM for over-parameterized Gaussian Mixture Models globally converges with a sublinear rate, solving a longstanding open problem in machine learning.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/zv9gyc3xgf/cover.png"/></item><item><title>Understanding the Gains from Repeated Self-Distillation</title><link>https://deep-diver.github.io/neurips2024/posters/gmqakjcocb/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/gmqakjcocb/</guid><description>Repeated self-distillation significantly reduces excess risk in linear regression, achieving up to a &amp;rsquo;d&amp;rsquo; factor improvement over single-step methods.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/gmqakjcocb/cover.png"/></item><item><title>Uniform Last-Iterate Guarantee for Bandits and Reinforcement Learning</title><link>https://deep-diver.github.io/neurips2024/posters/j3w0axtehp/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/j3w0axtehp/</guid><description>This paper introduces the Uniform Last-Iterate (ULI) guarantee, a novel metric for evaluating reinforcement learning algorithms that considers both cumulative and instantaneous performance. Unlike ex&amp;hellip;</description></item><item><title>Unpacking DPO and PPO: Disentangling Best Practices for Learning from Preference Feedback</title><link>https://deep-diver.github.io/neurips2024/posters/jmbwtlazjw/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/jmbwtlazjw/</guid><description>This study disentangles best practices for learning from preference feedback in LLMs, revealing that data quality, algorithm choice, and reward model significantly impact performance.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/jmbwtlazjw/cover.png"/></item><item><title>Visual Sketchpad: Sketching as a Visual Chain of Thought for Multimodal Language Models</title><link>https://deep-diver.github.io/neurips2024/posters/gnsml1p5vr/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/gnsml1p5vr/</guid><description>Visual SKETCHPAD empowers multimodal language models (LLMs) with visual reasoning abilities by allowing them to generate intermediate sketches. This innovative framework substantially enhances LLM per&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/gnsml1p5vr/cover.png"/></item></channel></rss>