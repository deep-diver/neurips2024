<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Machine Learning on NeurIPS 2024</title><link>https://deep-diver.github.io/neurips2024/tags/machine-learning/</link><description>Recent content in Machine Learning on NeurIPS 2024</description><generator>Hugo -- gohugo.io</generator><language>en</language><copyright>Â© 2024 AI Paper Reviewer</copyright><lastBuildDate>Thu, 26 Sep 2024 00:00:00 +0000</lastBuildDate><atom:link href="https://deep-diver.github.io/neurips2024/tags/machine-learning/index.xml" rel="self" type="application/rss+xml"/><item><title>A Geometric View of Data Complexity: Efficient Local Intrinsic Dimension Estimation with Diffusion Models</title><link>https://deep-diver.github.io/neurips2024/spotlight/nd8q4a8awl/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight/nd8q4a8awl/</guid><description>Diffusion models power FLIPD, a fast, single-model LID estimator.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight/nd8q4a8awl/cover.png"/></item><item><title>A Near-optimal Algorithm for Learning Margin Halfspaces with Massart Noise</title><link>https://deep-diver.github.io/neurips2024/spotlight/4aewzkwb5z/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight/4aewzkwb5z/</guid><description>Near-optimal algorithm achieves computationally efficient learning of margin halfspaces with Massart noise, nearly matching theoretical lower bounds.</description></item><item><title>A Pairwise Pseudo-likelihood Approach for Matrix Completion with Informative Missingness</title><link>https://deep-diver.github.io/neurips2024/spotlight/zgn8dohpi6/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight/zgn8dohpi6/</guid><description>New method recovers low-rank matrices with informative missingness, offering robust, near-optimal performance.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight/zgn8dohpi6/cover.png"/></item><item><title>A Study of Plasticity Loss in On-Policy Deep Reinforcement Learning</title><link>https://deep-diver.github.io/neurips2024/spotlight/msuf8kpktf/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight/msuf8kpktf/</guid><description>On-policy deep RL agents suffer from plasticity loss, but this paper introduces &amp;lsquo;regenerative&amp;rsquo; methods that consistently mitigate this, improving performance in challenging environments.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight/msuf8kpktf/cover.png"/></item><item><title>A-FedPD: Aligning Dual-Drift is All Federated Primal-Dual Learning Needs</title><link>https://deep-diver.github.io/neurips2024/spotlight/h1imvi2iem/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight/h1imvi2iem/</guid><description>A-FedPD tackles federated learning&amp;rsquo;s &amp;lsquo;dual drift&amp;rsquo; problem by aligning global and local dual variables, resulting in faster convergence and enhanced stability for primal-dual methods.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight/h1imvi2iem/cover.png"/></item><item><title>Accelerating Diffusion Models with Parallel Sampling: Inference at Sub-Linear Time Complexity</title><link>https://deep-diver.github.io/neurips2024/spotlight/f9ndzhqtol/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight/f9ndzhqtol/</guid><description>Researchers achieve sub-linear time complexity for diffusion model inference using parallel sampling with poly-logarithmic time complexity.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight/f9ndzhqtol/cover.png"/></item><item><title>ACES: Generating a Diversity of Challenging Programming Puzzles with Autotelic Generative Models</title><link>https://deep-diver.github.io/neurips2024/spotlight/l1mmk39z7p/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight/l1mmk39z7p/</guid><description>Autotelic Code Search (ACES) generates diverse, challenging Python programming puzzles by iteratively using LLM-generated semantic descriptors and measuring puzzle difficulty via LLM solver success ra&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight/l1mmk39z7p/cover.png"/></item><item><title>Achieving Optimal Clustering in Gaussian Mixture Models with Anisotropic Covariance Structures</title><link>https://deep-diver.github.io/neurips2024/oral/ge8gzn8gtu/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/oral/ge8gzn8gtu/</guid><description>This research develops rate-optimal clustering algorithms for Gaussian Mixture Models with anisotropic covariance structures, bridging the gap between theoretical guarantees and practical efficiency.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/oral/ge8gzn8gtu/cover.png"/></item><item><title>Active Classification with Few Queries under Misspecification</title><link>https://deep-diver.github.io/neurips2024/spotlight/ma0993kzlq/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight/ma0993kzlq/</guid><description>Learning halfspaces efficiently under noise is cracked! A novel query language enables a polylog query algorithm for Massart noise, overcoming previous limitations.</description></item><item><title>Advancing Spiking Neural Networks for Sequential Modeling with Central Pattern Generators</title><link>https://deep-diver.github.io/neurips2024/spotlight/kqmyidwbog/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight/kqmyidwbog/</guid><description>Bio-inspired CPG-PE enhances spiking neural networks&amp;rsquo; sequential modeling by efficiently encoding position information, outperforming conventional methods across various tasks.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight/kqmyidwbog/cover.png"/></item><item><title>Adversarial Environment Design via Regret-Guided Diffusion Models</title><link>https://deep-diver.github.io/neurips2024/spotlight/eezclkwx6t/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight/eezclkwx6t/</guid><description>Regret-Guided Diffusion Models enhance unsupervised environment design by generating challenging, diverse training environments that improve agent robustness and zero-shot generalization.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight/eezclkwx6t/cover.png"/></item><item><title>Analysing Multi-Task Regression via Random Matrix Theory with Application to Time Series Forecasting</title><link>https://deep-diver.github.io/neurips2024/spotlight/ffw6rpz48z/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight/ffw6rpz48z/</guid><description>This paper presents a novel theoretical framework for multi-task regression using random matrix theory, offering precise performance estimations and a closed-form solution for optimal hyperparameter t&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight/ffw6rpz48z/cover.png"/></item><item><title>Any2Graph: Deep End-To-End Supervised Graph Prediction With An Optimal Transport Loss</title><link>https://deep-diver.github.io/neurips2024/spotlight/tpgagxpvcv/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight/tpgagxpvcv/</guid><description>Any2Graph: a novel deep learning framework using an Optimal Transport loss for accurate and efficient supervised graph prediction.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight/tpgagxpvcv/cover.png"/></item><item><title>Approximation-Aware Bayesian Optimization</title><link>https://deep-diver.github.io/neurips2024/spotlight/t7euv5dl5m/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight/t7euv5dl5m/</guid><description>Approximation-Aware Bayesian Optimization (AABO) boosts high-dimensional Bayesian optimization by jointly optimizing model approximation and data acquisition, achieving superior efficiency and perform&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight/t7euv5dl5m/cover.png"/></item><item><title>Assouad, Fano, and Le Cam with Interaction: A Unifying Lower Bound Framework and Characterization for Bandit Learnability</title><link>https://deep-diver.github.io/neurips2024/spotlight/hugd1anmrp/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight/hugd1anmrp/</guid><description>This paper presents a novel unified framework for deriving information-theoretic lower bounds for bandit learnability, unifying classical methods with interactive learning techniques and introducing a&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight/hugd1anmrp/cover.png"/></item><item><title>Bigger, Regularized, Optimistic: scaling for compute and sample efficient continuous control</title><link>https://deep-diver.github.io/neurips2024/spotlight/fu0xdh4aej/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight/fu0xdh4aej/</guid><description>BRO (Bigger, Regularized, Optimistic) achieves state-of-the-art sample efficiency in continuous control by scaling critic networks and using strong regularization with optimistic exploration.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight/fu0xdh4aej/cover.png"/></item><item><title>BMRS: Bayesian Model Reduction for Structured Pruning</title><link>https://deep-diver.github.io/neurips2024/spotlight/ktpg37dzh5/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight/ktpg37dzh5/</guid><description>BMRS: Bayesian Model Reduction for Structured Pruning offers a principled, threshold-free approach to neural network compression, achieving high accuracy and competitive efficiency.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight/ktpg37dzh5/cover.png"/></item><item><title>Brain-JEPA: Brain Dynamics Foundation Model with Gradient Positioning and Spatiotemporal Masking</title><link>https://deep-diver.github.io/neurips2024/spotlight/gtu2elsamo/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight/gtu2elsamo/</guid><description>Brain-JEPA: a novel brain dynamics foundation model leverages fMRI data via innovative gradient positioning and spatiotemporal masking to achieve state-of-the-art performance in diverse brain activity&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight/gtu2elsamo/cover.png"/></item><item><title>Breaking Long-Tailed Learning Bottlenecks: A Controllable Paradigm with Hypernetwork-Generated Diverse Experts</title><link>https://deep-diver.github.io/neurips2024/spotlight/wppnvpaeyv/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight/wppnvpaeyv/</guid><description>Controllable long-tailed learning achieved via hypernetwork-generated diverse experts, adapting to user preferences and distribution shifts.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight/wppnvpaeyv/cover.png"/></item><item><title>Can Learned Optimization Make Reinforcement Learning Less Difficult?</title><link>https://deep-diver.github.io/neurips2024/spotlight/ybxfwasa9z/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight/ybxfwasa9z/</guid><description>Learned optimizer OPEN tackles RL&amp;rsquo;s non-stationarity, plasticity loss, and exploration using meta-learning, significantly outperforming traditional and other learned optimizers.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight/ybxfwasa9z/cover.png"/></item><item><title>Cell ontology guided transcriptome foundation model</title><link>https://deep-diver.github.io/neurips2024/spotlight/aeynvtto7o/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight/aeynvtto7o/</guid><description>scCello: A Cell Ontology-Guided Transcriptome Foundation Model improves single-cell RNA sequencing analysis by incorporating cell lineage information, significantly boosting accuracy and generalizabil&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight/aeynvtto7o/cover.png"/></item><item><title>Cluster-wise Graph Transformer with Dual-granularity Kernelized Attention</title><link>https://deep-diver.github.io/neurips2024/spotlight/3j2nasmkkp/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight/3j2nasmkkp/</guid><description>Cluster-wise Graph Transformer (Cluster-GT) improves graph learning by using a novel Node-to-Cluster Attention mechanism that leverages multiple kernel learning to capture node and cluster-level infor&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight/3j2nasmkkp/cover.png"/></item><item><title>Conditioning non-linear and infinite-dimensional diffusion processes</title><link>https://deep-diver.github.io/neurips2024/spotlight/fv4an2oufm/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight/fv4an2oufm/</guid><description>Conditioning infinite-dimensional nonlinear diffusion processes is made possible, enabling analysis of complex data like organism shapes in evolutionary biology.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight/fv4an2oufm/cover.png"/></item><item><title>Connecting Joint-Embedding Predictive Architecture with Contrastive Self-supervised Learning</title><link>https://deep-diver.github.io/neurips2024/spotlight/jvqnjwij6m/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight/jvqnjwij6m/</guid><description>C-JEPA boosts self-supervised visual learning by integrating contrastive learning with a joint-embedding predictive architecture, enhancing stability and representation quality.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight/jvqnjwij6m/cover.png"/></item><item><title>Convolutional Differentiable Logic Gate Networks</title><link>https://deep-diver.github.io/neurips2024/oral/4bkefyuht4/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/oral/4bkefyuht4/</guid><description>Convolutional Differentiable Logic Gate Networks achieve state-of-the-art accuracy on CIFAR-10 with 29x fewer gates than existing models, demonstrating highly efficient deep learning inference.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/oral/4bkefyuht4/cover.png"/></item><item><title>Curvature Clues: Decoding Deep Learning Privacy with Input Loss Curvature</title><link>https://deep-diver.github.io/neurips2024/spotlight/zevdmq6mu5/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight/zevdmq6mu5/</guid><description>Deep learning privacy is enhanced by a new membership inference attack using input loss curvature, exceeding existing methods, especially on large datasets.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight/zevdmq6mu5/cover.png"/></item><item><title>CycleNet: Enhancing Time Series Forecasting through Modeling Periodic Patterns</title><link>https://deep-diver.github.io/neurips2024/spotlight/clbiqugj4w/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight/clbiqugj4w/</guid><description>CycleNet enhances long-term time series forecasting by explicitly modeling inherent periodic patterns using a novel Residual Cycle Forecasting technique, achieving state-of-the-art accuracy and effici&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight/clbiqugj4w/cover.png"/></item><item><title>DapperFL: Domain Adaptive Federated Learning with Model Fusion Pruning for Edge Devices</title><link>https://deep-diver.github.io/neurips2024/oral/pezt0xttae/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/oral/pezt0xttae/</guid><description>DapperFL enhances federated learning by introducing a model fusion pruning module and domain adaptive regularization to improve performance and reduce model size for heterogeneous edge devices.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/oral/pezt0xttae/cover.png"/></item><item><title>Deep Learning for Computing Convergence Rates of Markov Chains</title><link>https://deep-diver.github.io/neurips2024/spotlight/fqmsgk8c0b/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight/fqmsgk8c0b/</guid><description>Deep learning tackles Markov chain convergence rate analysis! Deep Contractive Drift Calculator (DCDC) provides sample-based bounds in Wasserstein distance, surpassing traditional methods&amp;rsquo; limitations&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight/fqmsgk8c0b/cover.png"/></item><item><title>Deep Submodular Peripteral Networks</title><link>https://deep-diver.github.io/neurips2024/spotlight/tupcrqnvvm/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight/tupcrqnvvm/</guid><description>Deep Submodular Peripteral Networks (DSPNs) learn submodular functions efficiently using graded pairwise comparisons, surpassing traditional methods and demonstrating superiority in experimental desig&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight/tupcrqnvvm/cover.png"/></item><item><title>DiffTORI: Differentiable Trajectory Optimization for Deep Reinforcement and Imitation Learning</title><link>https://deep-diver.github.io/neurips2024/spotlight/mwj57tchwx/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight/mwj57tchwx/</guid><description>DiffTORI leverages differentiable trajectory optimization for superior deep reinforcement and imitation learning, outperforming prior state-of-the-art methods on high-dimensional robotic tasks.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight/mwj57tchwx/cover.png"/></item><item><title>Diffusion for World Modeling: Visual Details Matter in Atari</title><link>https://deep-diver.github.io/neurips2024/spotlight/nadtwtodgc/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight/nadtwtodgc/</guid><description>DIAMOND, a novel reinforcement learning agent using a diffusion world model, achieves state-of-the-art performance on the Atari 100k benchmark by leveraging visual details often ignored by discrete la&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight/nadtwtodgc/cover.png"/></item><item><title>Diffusion Model with Cross Attention as an Inductive Bias for Disentanglement</title><link>https://deep-diver.github.io/neurips2024/spotlight/stapcuwm9q/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight/stapcuwm9q/</guid><description>Diffusion models with cross-attention: a powerful inductive bias for effortless disentanglement!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight/stapcuwm9q/cover.png"/></item><item><title>Diffusion Models With Learned Adaptive Noise</title><link>https://deep-diver.github.io/neurips2024/spotlight/loma99a4p8/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight/loma99a4p8/</guid><description>MuLAN, a novel learned diffusion process, achieves state-of-the-art density estimation by adaptively adding multivariate Gaussian noise at varying rates across an image, significantly reducing trainin&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight/loma99a4p8/cover.png"/></item><item><title>Disentangling the Roles of Distinct Cell Classes with Cell-Type Dynamical Systems</title><link>https://deep-diver.github.io/neurips2024/spotlight/9sp4oejtjb/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight/9sp4oejtjb/</guid><description>New Cell-Type Dynamical Systems (CTDS) model disentangles neural population dynamics by incorporating distinct cell types, improving prediction accuracy and biological interpretability.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight/9sp4oejtjb/cover.png"/></item><item><title>Distributed-Order Fractional Graph Operating Network</title><link>https://deep-diver.github.io/neurips2024/spotlight/keqfjkqiqm/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight/keqfjkqiqm/</guid><description>DRAGON: A novel GNN framework using distributed-order fractional calculus surpasses traditional methods by capturing complex graph dynamics with enhanced flexibility and performance.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight/keqfjkqiqm/cover.png"/></item><item><title>Doob's Lagrangian: A Sample-Efficient Variational Approach to Transition Path Sampling</title><link>https://deep-diver.github.io/neurips2024/spotlight/shjwt0n7kx/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight/shjwt0n7kx/</guid><description>Researchers developed a sample-efficient variational approach for transition path sampling using Doob&amp;rsquo;s h-transform, significantly reducing computational costs while accurately capturing transition pa&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight/shjwt0n7kx/cover.png"/></item><item><title>EigenVI: score-based variational inference with orthogonal function expansions</title><link>https://deep-diver.github.io/neurips2024/spotlight/thuf6zblpp/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight/thuf6zblpp/</guid><description>EigenVI: a novel score-based variational inference method using orthogonal function expansions, offers closed-form solutions by solving eigenvalue problems, outperforming existing Gaussian BBVI method&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight/thuf6zblpp/cover.png"/></item><item><title>Energy-Guided Continuous Entropic Barycenter Estimation for General Costs</title><link>https://deep-diver.github.io/neurips2024/spotlight/jzhfrloqdq/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight/jzhfrloqdq/</guid><description>New algorithm approximates continuous Entropic Optimal Transport (EOT) barycenters for any cost function, offering quality bounds and seamless EBM integration.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight/jzhfrloqdq/cover.png"/></item><item><title>Exclusively Penalized Q-learning for Offline Reinforcement Learning</title><link>https://deep-diver.github.io/neurips2024/spotlight/2bdsnxeqcw/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight/2bdsnxeqcw/</guid><description>EPQ, a novel offline RL algorithm, significantly reduces underestimation bias by selectively penalizing states prone to errors, improving performance over existing methods.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight/2bdsnxeqcw/cover.png"/></item><item><title>Expectile Regularization for Fast and Accurate Training of Neural Optimal Transport</title><link>https://deep-diver.github.io/neurips2024/spotlight/4da5vaphfb/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight/4da5vaphfb/</guid><description>ENOT, a new Neural Optimal Transport training method, achieves 3x quality and 10x speed improvements by using expectile regularization to stabilize the learning process.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight/4da5vaphfb/cover.png"/></item><item><title>Exploitation of a Latent Mechanism in Graph Contrastive Learning: Representation Scattering</title><link>https://deep-diver.github.io/neurips2024/oral/r8solcx62k/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/oral/r8solcx62k/</guid><description>SGRL, a novel graph contrastive learning framework, significantly boosts performance by leveraging the inherent &amp;lsquo;representation scattering&amp;rsquo; mechanism and integrating graph topology, outperforming exis&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/oral/r8solcx62k/cover.png"/></item><item><title>Extensive-Form Game Solving via Blackwell Approachability on Treeplexes</title><link>https://deep-diver.github.io/neurips2024/spotlight/8aa3dhlk5h/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight/8aa3dhlk5h/</guid><description>First algorithmic framework for Blackwell approachability on treeplexes, enabling stepsize-invariant EFG solvers with state-of-the-art convergence rates.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight/8aa3dhlk5h/cover.png"/></item><item><title>Fearless Stochasticity in Expectation Propagation</title><link>https://deep-diver.github.io/neurips2024/spotlight/3kdwoqs2x2/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight/3kdwoqs2x2/</guid><description>This paper introduces EP-Î· and EP-Î¼, novel EP variants remarkably robust to Monte Carlo noise, achieving improved speed and accuracy.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight/3kdwoqs2x2/cover.png"/></item><item><title>Flexible task abstractions emerge in linear networks with fast and bounded units</title><link>https://deep-diver.github.io/neurips2024/spotlight/abtpjl7vn6/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight/abtpjl7vn6/</guid><description>Linear gated neural networks with fast, bounded units self-organize into modular weight structures and unique gating representations, enabling flexible task switching and compositional generalization.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight/abtpjl7vn6/cover.png"/></item><item><title>Functional Bilevel Optimization for Machine Learning</title><link>https://deep-diver.github.io/neurips2024/spotlight/enlxhlwwff/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight/enlxhlwwff/</guid><description>Functional Bilevel Optimization tackles the ambiguity of using neural networks in bilevel optimization by minimizing the inner objective over a function space, leading to scalable &amp;amp; efficient algorith&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight/enlxhlwwff/cover.png"/></item><item><title>FuseFL: One-Shot Federated Learning through the Lens of Causality with Progressive Model Fusion</title><link>https://deep-diver.github.io/neurips2024/spotlight/e7fzooiekl/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight/e7fzooiekl/</guid><description>FuseFL achieves superior one-shot federated learning performance by leveraging a causal view of data heterogeneity and progressively fusing model blocks, significantly outperforming existing methods w&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight/e7fzooiekl/cover.png"/></item><item><title>Generalized Linear Bandits with Limited Adaptivity</title><link>https://deep-diver.github.io/neurips2024/spotlight/ftpdbqut4g/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight/ftpdbqut4g/</guid><description>This paper introduces two novel algorithms, achieving optimal regret in generalized linear contextual bandits despite limited policy updates, a significant advancement for real-world applications.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight/ftpdbqut4g/cover.png"/></item><item><title>Generalized Protein Pocket Generation with Prior-Informed Flow Matching</title><link>https://deep-diver.github.io/neurips2024/spotlight/wyvtj77kev/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight/wyvtj77kev/</guid><description>PocketFlow: a novel generative model designs high-affinity protein pockets using prior-informed flow matching, outperforming existing methods.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight/wyvtj77kev/cover.png"/></item><item><title>Geodesic Optimization for Predictive Shift Adaptation on EEG data</title><link>https://deep-diver.github.io/neurips2024/spotlight/qtypwxvnja/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight/qtypwxvnja/</guid><description>GOPSA: a novel geodesic optimization method significantly improves cross-site age prediction from EEG data by jointly handling shifts in data and predictive variables.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight/qtypwxvnja/cover.png"/></item><item><title>Goal Reduction with Loop-Removal Accelerates RL and Models Human Brain Activity in Goal-Directed Learning</title><link>https://deep-diver.github.io/neurips2024/spotlight/y0efjjeb4v/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight/y0efjjeb4v/</guid><description>Goal Reduction with Loop-Removal accelerates Reinforcement Learning (RL) and accurately models human brain activity during goal-directed learning by efficiently deriving subgoals from distant original&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight/y0efjjeb4v/cover.png"/></item><item><title>Gradients of Functions of Large Matrices</title><link>https://deep-diver.github.io/neurips2024/spotlight/rl4fxrgctw/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight/rl4fxrgctw/</guid><description>This research presents novel adjoint methods for efficiently differentiating Lanczos and Arnoldi iterations, unlocking accurate gradients for large-matrix functions in machine learning.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight/rl4fxrgctw/cover.png"/></item><item><title>Hardness of Learning Neural Networks under the Manifold Hypothesis</title><link>https://deep-diver.github.io/neurips2024/spotlight/dkkgkzmni7/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight/dkkgkzmni7/</guid><description>Neural network learnability under the manifold hypothesis is hard except for efficiently sampleable manifolds.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight/dkkgkzmni7/cover.png"/></item><item><title>Implicit Curriculum in Procgen Made Explicit</title><link>https://deep-diver.github.io/neurips2024/spotlight/nzb1fpxuu6/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight/nzb1fpxuu6/</guid><description>C-Procgen reveals implicit curriculum in Procgen&amp;rsquo;s multi-level training, showing learning shifts gradually from easy to hard contexts.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight/nzb1fpxuu6/cover.png"/></item><item><title>Improving Environment Novelty Quantification for Effective Unsupervised Environment Design</title><link>https://deep-diver.github.io/neurips2024/oral/udxpjko2f9/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/oral/udxpjko2f9/</guid><description>Boosting AI generalization: CENIE framework quantifies environment novelty via state-action coverage, enhancing unsupervised environment design for robust generalization.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/oral/udxpjko2f9/cover.png"/></item><item><title>Improving the Worst-Case Bidirectional Communication Complexity for Nonconvex Distributed Optimization under Function Similarity</title><link>https://deep-diver.github.io/neurips2024/spotlight/gkj5nbiou4/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight/gkj5nbiou4/</guid><description>MARINA-P and M3 algorithms drastically cut downlink and overall communication costs in nonconvex distributed optimization, scaling efficiently with the number of worker nodes.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight/gkj5nbiou4/cover.png"/></item><item><title>In-Context Learning with Transformers: Softmax Attention Adapts to Function Lipschitzness</title><link>https://deep-diver.github.io/neurips2024/spotlight/lfxiasylxb/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight/lfxiasylxb/</guid><description>Softmax attention in transformers adapts its attention window to function Lipschitzness and noise, enabling efficient in-context learning.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight/lfxiasylxb/cover.png"/></item><item><title>Is Behavior Cloning All You Need? Understanding Horizon in Imitation Learning</title><link>https://deep-diver.github.io/neurips2024/spotlight/8kpyjm4gt5/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight/8kpyjm4gt5/</guid><description>Offline imitation learning achieves surprisingly strong performance, matching online methods&amp;rsquo; efficiency under certain conditions, contradicting prior assumptions.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight/8kpyjm4gt5/cover.png"/></item><item><title>Kermut: Composite kernel regression for protein variant effects</title><link>https://deep-diver.github.io/neurips2024/spotlight/jm9atrvuii/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight/jm9atrvuii/</guid><description>Kermut: A novel Gaussian process regression model achieves state-of-the-art accuracy in predicting protein variant effects and provides reliable uncertainty estimates, crucial for protein engineering &amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight/jm9atrvuii/cover.png"/></item><item><title>Latent Diffusion for Neural Spiking Data</title><link>https://deep-diver.github.io/neurips2024/spotlight/zx6ceo1wtv/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight/zx6ceo1wtv/</guid><description>LDNS: a new generative model for neural spiking data, enabling high-fidelity sampling and low-dimensional latent inference, paving the way for simulating realistic brain activity.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight/zx6ceo1wtv/cover.png"/></item><item><title>Learning Formal Mathematics From Intrinsic Motivation</title><link>https://deep-diver.github.io/neurips2024/oral/unkltq8mbd/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/oral/unkltq8mbd/</guid><description>AI agent MINIMO learns to generate challenging mathematical conjectures and prove them, bootstrapping from axioms alone and self-improving in both conjecture generation and theorem proving.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/oral/unkltq8mbd/cover.png"/></item><item><title>Learning Noisy Halfspaces with a Margin: Massart is No Harder than Random</title><link>https://deep-diver.github.io/neurips2024/spotlight/enlubvb262/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight/enlubvb262/</guid><description>Proper learning of noisy halfspaces with margins is achievable with sample complexity matching random classification noise, defying prior expectations.</description></item><item><title>Linear Regression using Heterogeneous Data Batches</title><link>https://deep-diver.github.io/neurips2024/spotlight/4g2dn4kjk1/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight/4g2dn4kjk1/</guid><description>New algorithm efficiently solves linear regression with heterogeneous data batches, handling diverse input distributions and achieving high accuracy with fewer samples.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight/4g2dn4kjk1/cover.png"/></item><item><title>Logarithmic Smoothing for Pessimistic Off-Policy Evaluation, Selection and Learning</title><link>https://deep-diver.github.io/neurips2024/spotlight/zlclygerk8/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight/zlclygerk8/</guid><description>Logarithmic Smoothing enhances pessimistic offline contextual bandit algorithms by providing tighter concentration bounds for improved policy evaluation, selection and learning.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight/zlclygerk8/cover.png"/></item><item><title>Maximum Entropy Inverse Reinforcement Learning of Diffusion Models with Energy-Based Models</title><link>https://deep-diver.github.io/neurips2024/oral/v0ojalqy4e/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/oral/v0ojalqy4e/</guid><description>Boosting diffusion model sample quality, especially with few steps, is achieved via a novel maximum entropy inverse reinforcement learning approach, jointly training the model and an energy-based mode&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/oral/v0ojalqy4e/cover.png"/></item><item><title>Molecule Design by Latent Prompt Transformer</title><link>https://deep-diver.github.io/neurips2024/spotlight/dg3ti3c2b1/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight/dg3ti3c2b1/</guid><description>Latent Prompt Transformer (LPT) revolutionizes molecule design by unifying generation and optimization, achieving high efficiency in discovering novel molecules with desired properties.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight/dg3ti3c2b1/cover.png"/></item><item><title>Monte Carlo Tree Search based Space Transfer for Black Box Optimization</title><link>https://deep-diver.github.io/neurips2024/spotlight/t5ufifmdbq/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight/t5ufifmdbq/</guid><description>MCTS-transfer: Iteratively refining Bayesian optimization via Monte Carlo tree search for efficient black-box optimization using transfer learning.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight/t5ufifmdbq/cover.png"/></item><item><title>Neglected Hessian component explains mysteries in sharpness regularization</title><link>https://deep-diver.github.io/neurips2024/spotlight/m6pvpdin0y/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight/m6pvpdin0y/</guid><description>Deep learning&amp;rsquo;s mysteries surrounding sharpness regularization are solved by uncovering the crucial role of the neglected Hessian component, the Nonlinear Modeling Error (NME).</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight/m6pvpdin0y/cover.png"/></item><item><title>NeoRL: Efficient Exploration for Nonepisodic RL</title><link>https://deep-diver.github.io/neurips2024/spotlight/zwndgc13aw/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight/zwndgc13aw/</guid><description>NEORL: Novel nonepisodic RL algorithm guarantees optimal average cost with sublinear regret for nonlinear systems!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight/zwndgc13aw/cover.png"/></item><item><title>Neural Krylov Iteration for Accelerating Linear System Solving</title><link>https://deep-diver.github.io/neurips2024/spotlight/cqfe9eymdp/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight/cqfe9eymdp/</guid><description>Neural Krylov Iteration (NeurKItt) accelerates linear system solving by using a neural operator to predict invariant subspaces, drastically reducing iteration counts and computation time.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight/cqfe9eymdp/cover.png"/></item><item><title>Noisy Label Learning with Instance-Dependent Outliers: Identifiability via Crowd Wisdom</title><link>https://deep-diver.github.io/neurips2024/spotlight/htljptf7qm/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight/htljptf7qm/</guid><description>Crowd wisdom solves noisy label learning!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight/htljptf7qm/cover.png"/></item><item><title>Non-asymptotic Approximation Error Bounds of Parameterized Quantum Circuits</title><link>https://deep-diver.github.io/neurips2024/spotlight/xckii8nct3/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight/xckii8nct3/</guid><description>New non-asymptotic approximation error bounds show that parameterized quantum circuits can efficiently approximate complex functions, potentially surpassing classical neural networks.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight/xckii8nct3/cover.png"/></item><item><title>Non-asymptotic Global Convergence Analysis of BFGS with the Armijo-Wolfe Line Search</title><link>https://deep-diver.github.io/neurips2024/spotlight/mkzpn2t87c/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight/mkzpn2t87c/</guid><description>BFGS algorithm achieves global linear and superlinear convergence rates with inexact Armijo-Wolfe line search, even without precise Hessian knowledge.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight/mkzpn2t87c/cover.png"/></item><item><title>Non-Asymptotic Uncertainty Quantification in High-Dimensional Learning</title><link>https://deep-diver.github.io/neurips2024/spotlight/rqcmmsszvi/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight/rqcmmsszvi/</guid><description>Data-driven approach corrects confidence intervals in high-dimensional learning, improving accuracy for various models and bridging theory and practice.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight/rqcmmsszvi/cover.png"/></item><item><title>Non-convolutional graph neural networks.</title><link>https://deep-diver.github.io/neurips2024/spotlight/jdaqwysfoc/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight/jdaqwysfoc/</guid><description>RUM neural network, a novel non-convolutional GNN, overcomes limitations of conventional convolution-based models by using RNNs to merge topological and semantic features along random walks, achieving&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight/jdaqwysfoc/cover.png"/></item><item><title>Nonlinear dynamics of localization in neural receptive fields</title><link>https://deep-diver.github.io/neurips2024/spotlight/nw9jmfl99s/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight/nw9jmfl99s/</guid><description>Neural receptive fields&amp;rsquo; localization emerges from nonlinear learning dynamics driven by naturalistic data&amp;rsquo;s higher-order statistics, not just sparsity.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight/nw9jmfl99s/cover.png"/></item><item><title>Nonlocal Attention Operator: Materializing Hidden Knowledge Towards Interpretable Physics Discovery</title><link>https://deep-diver.github.io/neurips2024/spotlight/uskzeaj9zj/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight/uskzeaj9zj/</guid><description>New neural operator, Nonlocal Attention Operator (NAO), simultaneously learns forward and inverse physical models, improving interpretability and generalizability for physics discovery.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight/uskzeaj9zj/cover.png"/></item><item><title>Optimal deep learning of holomorphic operators between Banach spaces</title><link>https://deep-diver.github.io/neurips2024/spotlight/vblzen37i0/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight/vblzen37i0/</guid><description>Deep learning optimally learns holomorphic operators between Banach spaces, achieving near-optimal generalization bounds with problem-agnostic DNN architectures.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight/vblzen37i0/cover.png"/></item><item><title>Optimizing Automatic Differentiation with Deep Reinforcement Learning</title><link>https://deep-diver.github.io/neurips2024/spotlight/hvmi98a0ki/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight/hvmi98a0ki/</guid><description>Deep reinforcement learning optimizes automatic differentiation, achieving up to 33% improvement in Jacobian computation by finding efficient elimination orders.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight/hvmi98a0ki/cover.png"/></item><item><title>Overcoming Common Flaws in the Evaluation of Selective Classification Systems</title><link>https://deep-diver.github.io/neurips2024/spotlight/2tktdpgqnm/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight/2tktdpgqnm/</guid><description>Researchers developed a new evaluation metric, AUGRC, for selective classification systems that overcomes the limitations of existing metrics by providing a more holistic and interpretable assessment &amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight/2tktdpgqnm/cover.png"/></item><item><title>PACE: marrying the generalization of PArameter-efficient fine-tuning with Consistency rEgularization</title><link>https://deep-diver.github.io/neurips2024/spotlight/coulbphot1/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight/coulbphot1/</guid><description>PACE marries parameter-efficient fine-tuning with consistency regularization to significantly boost model generalization.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight/coulbphot1/cover.png"/></item><item><title>Parsimony or Capability? Decomposition Delivers Both in Long-term Time Series Forecasting</title><link>https://deep-diver.github.io/neurips2024/spotlight/wiehzsv15i/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight/wiehzsv15i/</guid><description>SSCNN, a novel decomposition-based model, achieves superior long-term time series forecasting accuracy using 99% fewer parameters than existing methods, proving that bigger isn&amp;rsquo;t always better.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight/wiehzsv15i/cover.png"/></item><item><title>Particle Semi-Implicit Variational Inference</title><link>https://deep-diver.github.io/neurips2024/spotlight/p3gmgkhmkm/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight/p3gmgkhmkm/</guid><description>Particle Variational Inference (PVI) revolutionizes semi-implicit variational inference by directly optimizing the ELBO using a novel particle approximation, improving efficiency and expressiveness ov&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight/p3gmgkhmkm/cover.png"/></item><item><title>Peri-midFormer: Periodic Pyramid Transformer for Time Series Analysis</title><link>https://deep-diver.github.io/neurips2024/spotlight/5iuxmvjvev/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight/5iuxmvjvev/</guid><description>Peri-midFormer uses a novel periodic pyramid transformer to effectively model complex periodic variations in time series, achieving state-of-the-art results in forecasting, imputation, classification,&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight/5iuxmvjvev/cover.png"/></item><item><title>Personalizing Reinforcement Learning from Human Feedback with Variational Preference Learning</title><link>https://deep-diver.github.io/neurips2024/spotlight/grg6szbw9p/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight/grg6szbw9p/</guid><description>VPL: a novel multimodal RLHF personalizes AI by inferring user-specific latent preferences, enabling accurate reward modeling and improved policy alignment for diverse populations.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight/grg6szbw9p/cover.png"/></item><item><title>Poisson Variational Autoencoder</title><link>https://deep-diver.github.io/neurips2024/spotlight/ektpecqglb/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight/ektpecqglb/</guid><description>Poisson Variational Autoencoder (P-VAE) improves deep learning by encoding inputs as discrete spike counts, enhancing biological realism and interpretability while avoiding posterior collapse and achi&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight/ektpecqglb/cover.png"/></item><item><title>Probabilistic Weather Forecasting with Hierarchical Graph Neural Networks</title><link>https://deep-diver.github.io/neurips2024/spotlight/wtizpqx121/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight/wtizpqx121/</guid><description>Graph-EFM: a novel probabilistic weather forecasting model using hierarchical graph neural networks that efficiently generates large ensembles for improved accuracy and uncertainty quantification.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight/wtizpqx121/cover.png"/></item><item><title>Probablistic Emulation of a Global Climate Model with Spherical DYffusion</title><link>https://deep-diver.github.io/neurips2024/spotlight/ib2ihijrth/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight/ib2ihijrth/</guid><description>Spherical DYffusion: a novel AI model generates accurate, physically consistent global climate ensemble simulations, surpassing existing methods in efficiency and skill.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight/ib2ihijrth/cover.png"/></item><item><title>Reconstruct and Match: Out-of-Distribution Robustness via Topological Homogeneity</title><link>https://deep-diver.github.io/neurips2024/spotlight/fkbmlfdbxm/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight/fkbmlfdbxm/</guid><description>Reconstruct &amp;amp; Match (REMA) enhances deep learning&amp;rsquo;s out-of-distribution robustness by leveraging object&amp;rsquo;s topological homogeneity, outperforming state-of-the-art methods.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight/fkbmlfdbxm/cover.png"/></item><item><title>Recursive PAC-Bayes: A Frequentist Approach to Sequential Prior Updates with No Information Loss</title><link>https://deep-diver.github.io/neurips2024/spotlight/pqt6vg2x5u/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight/pqt6vg2x5u/</guid><description>Recursive PAC-Bayes: A frequentist method enabling sequential prior updates without information loss, resulting in significantly tighter generalization bounds.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight/pqt6vg2x5u/cover.png"/></item><item><title>Reinforcement Learning Gradients as Vitamin for Online Finetuning Decision Transformers</title><link>https://deep-diver.github.io/neurips2024/spotlight/5l5bhyexyo/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight/5l5bhyexyo/</guid><description>Boost online finetuning of Decision Transformers by adding TD3 gradients, especially when pretrained with low-reward data.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight/5l5bhyexyo/cover.png"/></item><item><title>Reinforcement Learning Under Latent Dynamics: Toward Statistical and Algorithmic Modularity</title><link>https://deep-diver.github.io/neurips2024/oral/qf2uzady1n/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/oral/qf2uzady1n/</guid><description>This paper pioneers a modular framework for reinforcement learning, addressing the challenge of learning under complex observations and simpler latent dynamics, offering both statistical and algorithm&amp;hellip;</description></item><item><title>Reparameterization invariance in approximate Bayesian inference</title><link>https://deep-diver.github.io/neurips2024/spotlight/204yordhny/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight/204yordhny/</guid><description>Bayesian neural networks often underfit due to their lack of reparameterization invariance; this paper introduces a Riemannian diffusion process to improve posterior sampling and enhance predictive pe&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight/204yordhny/cover.png"/></item><item><title>Reproducibility of predictive networks for mouse visual cortex</title><link>https://deep-diver.github.io/neurips2024/spotlight/vxxj3xz1x8/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight/vxxj3xz1x8/</guid><description>Deep learning models for neural activity lack reproducibility; this paper introduces adaptive regularization and iterative feature pruning to improve embedding consistency and predictive performance.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight/vxxj3xz1x8/cover.png"/></item><item><title>Rethinking Exploration in Reinforcement Learning with Effective Metric-Based Exploration Bonus</title><link>https://deep-diver.github.io/neurips2024/spotlight/qpkwfltzki/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight/qpkwfltzki/</guid><description>Effective Metric-based Exploration Bonus (EME) enhances reinforcement learning exploration by using a robust metric for state discrepancy and a dynamically adjusted scaling factor based on reward mode&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight/qpkwfltzki/cover.png"/></item><item><title>Reverse Transition Kernel: A Flexible Framework to Accelerate Diffusion Inference</title><link>https://deep-diver.github.io/neurips2024/spotlight/c2xclze1ks/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight/c2xclze1ks/</guid><description>Reverse Transition Kernel (RTK) framework accelerates diffusion inference by enabling balanced subproblem decomposition, achieving superior convergence rates with RTK-MALA and RTK-ULD algorithms.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight/c2xclze1ks/cover.png"/></item><item><title>Sample Complexity Reduction via Policy Difference Estimation in Tabular Reinforcement Learning</title><link>https://deep-diver.github.io/neurips2024/spotlight/ryq0kuzvkl/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight/ryq0kuzvkl/</guid><description>This paper reveals that estimating only policy differences, while effective in bandits, is insufficient for tabular reinforcement learning. However, it introduces a novel algorithm achieving near-opti&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight/ryq0kuzvkl/cover.png"/></item><item><title>Scalable and Effective Arithmetic Tree Generation for Adder and Multiplier Designs</title><link>https://deep-diver.github.io/neurips2024/spotlight/5pnhgedg98/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight/5pnhgedg98/</guid><description>ArithTreeRL, a novel reinforcement learning approach, generates optimized arithmetic tree structures for adders and multipliers, significantly improving computational efficiency and reducing hardware &amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight/5pnhgedg98/cover.png"/></item><item><title>Scale Equivariant Graph Metanetworks</title><link>https://deep-diver.github.io/neurips2024/oral/8fxqn1tzm1/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/oral/8fxqn1tzm1/</guid><description>ScaleGMNs, a new framework, enhances neural network processing by incorporating scaling symmetries, boosting performance across various tasks and datasets.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/oral/8fxqn1tzm1/cover.png"/></item><item><title>Scaling Continuous Latent Variable Models as Probabilistic Integral Circuits</title><link>https://deep-diver.github.io/neurips2024/spotlight/ke40kfot2e/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight/ke40kfot2e/</guid><description>Researchers scaled continuous latent variable models by building DAG-shaped probabilistic integral circuits (PICs) and training them efficiently using tensorized architectures and neural functional sh&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight/ke40kfot2e/cover.png"/></item><item><title>Schrodinger Bridge Flow for Unpaired Data Translation</title><link>https://deep-diver.github.io/neurips2024/spotlight/1f32icjffa/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight/1f32icjffa/</guid><description>Accelerate unpaired data translation with SchrÃ¶dinger Bridge Flow, a novel algorithm solving optimal transport problems efficiently without repeatedly training models!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight/1f32icjffa/cover.png"/></item><item><title>Second-order forward-mode optimization of recurrent neural networks for neuroscience</title><link>https://deep-diver.github.io/neurips2024/spotlight/pox8jnqoo5/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight/pox8jnqoo5/</guid><description>SOFO: a novel second-order optimizer enables efficient and memory-friendly RNN training for neuroscience tasks, surpassing Adam&amp;rsquo;s performance, especially on long time horizons.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight/pox8jnqoo5/cover.png"/></item><item><title>Self-Consuming Generative Models with Curated Data Provably Optimize Human Preferences</title><link>https://deep-diver.github.io/neurips2024/spotlight/cyv0lkiaoh/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight/cyv0lkiaoh/</guid><description>Curated synthetic data provably optimizes human preferences in iterative generative model training, maximizing expected reward while mitigating variance.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight/cyv0lkiaoh/cover.png"/></item><item><title>Semi-supervised Multi-label Learning with Balanced Binary Angular Margin Loss</title><link>https://deep-diver.github.io/neurips2024/spotlight/aqcpvwwktk/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight/aqcpvwwktk/</guid><description>S2ML2-BBAM: A new semi-supervised multi-label learning method that balances feature angle distributions to improve accuracy and fairness.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight/aqcpvwwktk/cover.png"/></item><item><title>Semi-Supervised Sparse Gaussian Classification: Provable Benefits of Unlabeled Data</title><link>https://deep-diver.github.io/neurips2024/spotlight/dlctmeyq6y/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight/dlctmeyq6y/</guid><description>This study proves that combining labeled and unlabeled data significantly improves high-dimensional sparse Gaussian classification, offering a polynomial-time SSL algorithm that outperforms supervised&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight/dlctmeyq6y/cover.png"/></item><item><title>Small coresets via negative dependence: DPPs, linear statistics, and concentration</title><link>https://deep-diver.github.io/neurips2024/spotlight/jd3mshmttl/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight/jd3mshmttl/</guid><description>DPPs create smaller, more accurate coresets than existing methods, improving machine learning efficiency without sacrificing accuracy.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight/jd3mshmttl/cover.png"/></item><item><title>Span-Based Optimal Sample Complexity for Weakly Communicating and General Average Reward MDPs</title><link>https://deep-diver.github.io/neurips2024/oral/pgey8jq3qx/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/oral/pgey8jq3qx/</guid><description>This paper achieves minimax-optimal bounds for learning near-optimal policies in average-reward MDPs, addressing a long-standing open problem in reinforcement learning.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/oral/pgey8jq3qx/cover.png"/></item><item><title>Stabilized Proximal-Point Methods for Federated Optimization</title><link>https://deep-diver.github.io/neurips2024/spotlight/wuksyfszdt/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight/wuksyfszdt/</guid><description>S-DANE &amp;amp; ACC-S-DANE achieve best-known communication complexity for federated learning, improving local computation efficiency via stabilized proximal-point methods.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight/wuksyfszdt/cover.png"/></item><item><title>Statistical Efficiency of Distributional Temporal Difference Learning</title><link>https://deep-diver.github.io/neurips2024/oral/ewum5hrygh/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/oral/ewum5hrygh/</guid><description>Researchers achieve minimax optimal sample complexity bounds for distributional temporal difference learning, enhancing reinforcement learning algorithm efficiency.</description></item><item><title>Stochastic Taylor Derivative Estimator: Efficient amortization for arbitrary differential operators</title><link>https://deep-diver.github.io/neurips2024/oral/j2wi2rcg2u/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/oral/j2wi2rcg2u/</guid><description>Stochastic Taylor Derivative Estimator (STDE) drastically accelerates the optimization of neural networks involving high-dimensional, high-order differential operators by efficiently amortizing comput&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/oral/j2wi2rcg2u/cover.png"/></item><item><title>The Collusion of Memory and Nonlinearity in Stochastic Approximation With Constant Stepsize</title><link>https://deep-diver.github.io/neurips2024/spotlight/xul75cvhl5/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight/xul75cvhl5/</guid><description>Unlocking the mysteries of stochastic approximation with constant stepsize, this paper reveals how memory and nonlinearity interact to create bias, providing novel analysis and solutions for more accu&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight/xul75cvhl5/cover.png"/></item><item><title>The Power of Resets in Online Reinforcement Learning</title><link>https://deep-diver.github.io/neurips2024/spotlight/7saccaomgi/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight/7saccaomgi/</guid><description>Leveraging local simulator resets in online reinforcement learning dramatically improves sample efficiency, especially for high-dimensional problems with general function approximation.</description></item><item><title>The Road Less Scheduled</title><link>https://deep-diver.github.io/neurips2024/oral/0xenkkenui/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/oral/0xenkkenui/</guid><description>Revolutionizing machine learning, Schedule-Free optimization achieves state-of-the-art results without needing learning rate schedules, simplifying training and improving efficiency.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/oral/0xenkkenui/cover.png"/></item><item><title>The Sample-Communication Complexity Trade-off in Federated Q-Learning</title><link>https://deep-diver.github.io/neurips2024/oral/6yipvnkjuk/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/oral/6yipvnkjuk/</guid><description>Federated Q-learning achieves optimal sample &amp;amp; communication complexities simultaneously via Fed-DVR-Q, a novel algorithm.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/oral/6yipvnkjuk/cover.png"/></item><item><title>The Value of Reward Lookahead in Reinforcement Learning</title><link>https://deep-diver.github.io/neurips2024/spotlight/uryeu8mwz1/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight/uryeu8mwz1/</guid><description>Reinforcement learning agents can achieve significantly higher rewards by using advance knowledge of future rewards; this paper mathematically analyzes this advantage by computing the worst-case perfo&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight/uryeu8mwz1/cover.png"/></item><item><title>Thompson Sampling For Combinatorial Bandits: Polynomial Regret and Mismatched Sampling Paradox</title><link>https://deep-diver.github.io/neurips2024/spotlight/pgoubhydbr/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight/pgoubhydbr/</guid><description>A novel Thompson Sampling variant achieves polynomial regret for combinatorial bandits, solving a key limitation of existing methods and offering significantly improved performance.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight/pgoubhydbr/cover.png"/></item><item><title>Tolerant Algorithms for Learning with Arbitrary Covariate Shift</title><link>https://deep-diver.github.io/neurips2024/spotlight/lnnfwc2ah1/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight/lnnfwc2ah1/</guid><description>This paper introduces efficient algorithms for learning under arbitrary covariate shift, addressing limitations of prior approaches by enabling classifiers to abstain from predictions in high-shift sc&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight/lnnfwc2ah1/cover.png"/></item><item><title>Towards an Information Theoretic Framework of Context-Based Offline Meta-Reinforcement Learning</title><link>https://deep-diver.github.io/neurips2024/spotlight/qfuszvw9mx/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight/qfuszvw9mx/</guid><description>UNICORN: a unified framework reveals that existing offline meta-reinforcement learning algorithms optimize variations of mutual information, leading to improved generalization.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight/qfuszvw9mx/cover.png"/></item><item><title>Towards training digitally-tied analog blocks via hybrid gradient computation</title><link>https://deep-diver.github.io/neurips2024/spotlight/bmtn8kkrbq/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight/bmtn8kkrbq/</guid><description>Hybrid neural networks, combining digital feedforward and analog energy-based blocks, are trained end-to-end via a novel BP-EP gradient chaining algorithm, achieving state-of-the-art results on ImageN&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight/bmtn8kkrbq/cover.png"/></item><item><title>Towards Understanding Evolving Patterns in Sequential Data</title><link>https://deep-diver.github.io/neurips2024/spotlight/i2gvmvrgnk/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight/i2gvmvrgnk/</guid><description>EVORATE quantifies evolving patterns in sequential data, enabling better model selection and temporal analysis for improved machine learning.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight/i2gvmvrgnk/cover.png"/></item><item><title>Towards Universal Mesh Movement Networks</title><link>https://deep-diver.github.io/neurips2024/spotlight/lcalcnf2qe/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight/lcalcnf2qe/</guid><description>Universal Mesh Movement Network (UM2N) revolutionizes mesh movement for PDE solvers, enabling zero-shot adaptation to diverse problems and significantly accelerating simulations with improved accuracy&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight/lcalcnf2qe/cover.png"/></item><item><title>Unitary Convolutions for Learning on Graphs and Groups</title><link>https://deep-diver.github.io/neurips2024/spotlight/lg1veqjvuh/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight/lg1veqjvuh/</guid><description>Stable deep learning on graphs achieved using novel unitary group convolutions, preventing over-smoothing and enhancing model robustness.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight/lg1veqjvuh/cover.png"/></item><item><title>Variational Delayed Policy Optimization</title><link>https://deep-diver.github.io/neurips2024/spotlight/datndzhbqj/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight/datndzhbqj/</guid><description>VDPO: A novel framework for delayed reinforcement learning achieving 50% sample efficiency improvement without compromising performance.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight/datndzhbqj/cover.png"/></item></channel></rss>