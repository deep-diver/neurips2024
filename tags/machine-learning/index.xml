<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Machine Learning on NeurIPS 2024</title><link>https://deep-diver.github.io/neurips2024/tags/machine-learning/</link><description>Recent content in Machine Learning on NeurIPS 2024</description><generator>Hugo -- gohugo.io</generator><language>en</language><copyright>¬© 2024 AI Paper Reviewer</copyright><lastBuildDate>Thu, 26 Sep 2024 00:00:00 +0000</lastBuildDate><atom:link href="https://deep-diver.github.io/neurips2024/tags/machine-learning/index.xml" rel="self" type="application/rss+xml"/><item><title>$C^2M^3$: Cycle-Consistent Multi-Model Merging</title><link>https://deep-diver.github.io/neurips2024/posters/id18l6pra7/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/id18l6pra7/</guid><description>C2M¬≥: A novel data-free method ensures cycle-consistent merging of neural networks, significantly improving model aggregation across various architectures and datasets.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/id18l6pra7/cover.png"/></item><item><title>$psilon$-Softmax: Approximating One-Hot Vectors for Mitigating Label Noise</title><link>https://deep-diver.github.io/neurips2024/posters/vjsd8bcipv/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/vjsd8bcipv/</guid><description>e-Softmax: A simple plug-and-play module enhances deep learning model robustness against noisy labels by approximating one-hot vectors, achieving noise-tolerant learning with controllable excess risk.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/vjsd8bcipv/cover.png"/></item><item><title>A Bayesian Approach for Personalized Federated Learning in Heterogeneous Settings</title><link>https://deep-diver.github.io/neurips2024/posters/hilgwnabqb/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/hilgwnabqb/</guid><description>FedBNN: a novel Bayesian framework for personalized federated learning, achieves superior performance in heterogeneous settings while ensuring strict privacy via differential privacy.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/hilgwnabqb/cover.png"/></item><item><title>A Best-of-both-worlds Algorithm for Bandits with Delayed Feedback with Robustness to Excessive Delays</title><link>https://deep-diver.github.io/neurips2024/posters/ldzrqb4x5w/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/ldzrqb4x5w/</guid><description>New best-of-both-worlds bandit algorithm tolerates arbitrary excessive delays, overcoming limitations of prior work that required prior knowledge of maximal delay and suffered linear regret dependence&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/ldzrqb4x5w/cover.png"/></item><item><title>A Foundation Model for Zero-shot Logical Query Reasoning</title><link>https://deep-diver.github.io/neurips2024/posters/jrsymbbji6/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/jrsymbbji6/</guid><description>ULTRAQUERY: a groundbreaking foundation model for zero-shot logical query reasoning on any knowledge graph, surpassing existing methods&amp;rsquo; limitations.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/jrsymbbji6/cover.png"/></item><item><title>A Framework for Bilevel Optimization on Riemannian Manifolds</title><link>https://deep-diver.github.io/neurips2024/posters/lvndqnjkld/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/lvndqnjkld/</guid><description>This paper introduces a novel framework for bilevel optimization on Riemannian manifolds, providing efficient hypergradient estimation strategies and convergence analysis, with successful applications&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/lvndqnjkld/cover.png"/></item><item><title>A Functional Extension of Semi-Structured Networks</title><link>https://deep-diver.github.io/neurips2024/posters/wjaiaslhin/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/wjaiaslhin/</guid><description>This paper introduces semi-structured functional networks (SSFNNs), a novel approach that combines interpretable functional regression models with deep neural networks, achieving both high accuracy an&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/wjaiaslhin/cover.png"/></item><item><title>A Generative Model of Symmetry Transformations</title><link>https://deep-diver.github.io/neurips2024/posters/afp24eypwh/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/afp24eypwh/</guid><description>Generative model learns data symmetries for improved efficiency and higher test log-likelihoods.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/afp24eypwh/cover.png"/></item><item><title>A Kernel Perspective on Distillation-based Collaborative Learning</title><link>https://deep-diver.github.io/neurips2024/posters/ldz0u1fuxb/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/ldz0u1fuxb/</guid><description>This paper introduces DCL-KR and DCL-NN, novel distillation-based collaborative learning algorithms achieving nearly minimax optimal convergence rates in heterogeneous environments without direct data&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/ldz0u1fuxb/cover.png"/></item><item><title>A Layer-Wise Natural Gradient Optimizer for Training Deep Neural Networks</title><link>https://deep-diver.github.io/neurips2024/posters/nig3yyb6oa/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/nig3yyb6oa/</guid><description>LNGD: A Layer-Wise Natural Gradient optimizer drastically cuts deep neural network training time without sacrificing accuracy.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/nig3yyb6oa/cover.png"/></item><item><title>A Nearly Optimal and Low-Switching Algorithm for Reinforcement Learning with General Function Approximation</title><link>https://deep-diver.github.io/neurips2024/posters/s3iczc2nlq/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/s3iczc2nlq/</guid><description>MQL-UCB: Near-optimal reinforcement learning with low policy switching cost, solving the exploration-exploitation dilemma for complex models.</description></item><item><title>A PID Controller Approach for Adaptive Probability-dependent Gradient Decay in Model Calibration</title><link>https://deep-diver.github.io/neurips2024/posters/fanubdsfpn/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/fanubdsfpn/</guid><description>Deep learning models often suffer from overconfidence; this paper introduces a PID controller to adaptively adjust a probability-dependent gradient decay rate, ensuring consistent optimization of both&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/fanubdsfpn/cover.png"/></item><item><title>A Recipe for Charge Density Prediction</title><link>https://deep-diver.github.io/neurips2024/posters/b7rekanutv/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/b7rekanutv/</guid><description>A novel machine learning recipe drastically accelerates charge density prediction in density functional theory, achieving state-of-the-art accuracy while being significantly faster than existing metho&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/b7rekanutv/cover.png"/></item><item><title>A Structure-Aware Framework for Learning Device Placements on Computation Graphs</title><link>https://deep-diver.github.io/neurips2024/posters/kzno1r3xef/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/kzno1r3xef/</guid><description>Learn optimal device placement for neural networks with HSDAG, a novel framework boosting inference speed by up to 58.2%!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/kzno1r3xef/cover.png"/></item><item><title>A Topology-aware Graph Coarsening Framework for Continual Graph Learning</title><link>https://deep-diver.github.io/neurips2024/posters/vpineevlx0/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/vpineevlx0/</guid><description>TACO, a novel topology-aware graph coarsening framework, tackles catastrophic forgetting in continual graph learning by efficiently preserving topological information during experience replay, signifi&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/vpineevlx0/cover.png"/></item><item><title>A two-scale Complexity Measure for Deep Learning Models</title><link>https://deep-diver.github.io/neurips2024/posters/ty9voszzia/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/ty9voszzia/</guid><description>New 2sED measure effectively bounds deep learning model complexity, correlating well with training error and offering efficient computation, particularly for deep models via a layerwise approach.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/ty9voszzia/cover.png"/></item><item><title>A versatile informative diffusion model for single-cell ATAC-seq data generation and analysis</title><link>https://deep-diver.github.io/neurips2024/posters/s6ylebmowf/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/s6ylebmowf/</guid><description>ATAC-Diff: A versatile diffusion model for high-quality single-cell ATAC-seq data generation and analysis, surpassing state-of-the-art.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/s6ylebmowf/cover.png"/></item><item><title>A2PO: Towards Effective Offline Reinforcement Learning from an Advantage-aware Perspective</title><link>https://deep-diver.github.io/neurips2024/posters/hyjrmgqq5e/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/hyjrmgqq5e/</guid><description>A2PO: A novel offline RL method tackles constraint conflicts in mixed-quality datasets by disentangling behavior policies with a conditional VAE and optimizing advantage-aware constraints, achieving s&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/hyjrmgqq5e/cover.png"/></item><item><title>Absorb &amp; Escape: Overcoming Single Model Limitations in Generating Heterogeneous Genomic Sequences</title><link>https://deep-diver.github.io/neurips2024/posters/xhtl2k1lyk/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/xhtl2k1lyk/</guid><description>Absorb &amp;amp; Escape: a novel post-training sampling method that overcomes single model limitations by combining Autoregressive (AR) and Diffusion Models (DMs), generating high-quality heterogeneous genomi&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/xhtl2k1lyk/cover.png"/></item><item><title>Accelerating Relative Entropy Coding with Space Partitioning</title><link>https://deep-diver.github.io/neurips2024/posters/ouqywnunxm/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/ouqywnunxm/</guid><description>Space partitioning dramatically speeds up relative entropy coding (REC) for neural compression, achieving 5-15% better bitrates than previous methods.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/ouqywnunxm/cover.png"/></item><item><title>Achieving Tractable Minimax Optimal Regret in Average Reward MDPs</title><link>https://deep-diver.github.io/neurips2024/posters/sm9iwrhz4e/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/sm9iwrhz4e/</guid><description>First tractable algorithm achieves minimax optimal regret in average-reward MDPs, solving a major computational challenge in reinforcement learning.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/sm9iwrhz4e/cover.png"/></item><item><title>Activation Map Compression through Tensor Decomposition for Deep Learning</title><link>https://deep-diver.github.io/neurips2024/posters/s93hrwt8u9/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/s93hrwt8u9/</guid><description>Slash deep learning&amp;rsquo;s memory footprint! This paper introduces a novel activation map compression technique via tensor decomposition, significantly boosting on-device training efficiency for edge AI.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/s93hrwt8u9/cover.png"/></item><item><title>Active design of two-photon holographic stimulation for identifying neural population dynamics</title><link>https://deep-diver.github.io/neurips2024/posters/nlqee8qgge/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/nlqee8qgge/</guid><description>Researchers developed an active learning method using two-photon holographic optogenetics to efficiently identify neural population dynamics, achieving up to a two-fold reduction in data needed for ac&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/nlqee8qgge/cover.png"/></item><item><title>Active Learning of General Halfspaces: Label Queries vs Membership Queries</title><link>https://deep-diver.github.io/neurips2024/posters/exnyq8fgsz/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/exnyq8fgsz/</guid><description>Active learning for general halfspaces is surprisingly hard; membership queries are key to efficiency.</description></item><item><title>Active preference learning for ordering items in- and out-of-sample</title><link>https://deep-diver.github.io/neurips2024/posters/pslh5q7pfo/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/pslh5q7pfo/</guid><description>Active learning efficiently orders items using contextual attributes, minimizing comparison needs and improving generalization.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/pslh5q7pfo/cover.png"/></item><item><title>Ada-MSHyper: Adaptive Multi-Scale Hypergraph Transformer for Time Series Forecasting</title><link>https://deep-diver.github.io/neurips2024/posters/rnbriq0se8/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/rnbriq0se8/</guid><description>Ada-MSHyper: A novel adaptive multi-scale hypergraph transformer significantly boosts time series forecasting accuracy by modeling group-wise interactions and handling complex temporal variations.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/rnbriq0se8/cover.png"/></item><item><title>Adapting to Unknown Low-Dimensional Structures in Score-Based Diffusion Models</title><link>https://deep-diver.github.io/neurips2024/posters/sntxbqsrw7/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/sntxbqsrw7/</guid><description>Score-based diffusion models are improved by a novel coefficient design, enabling efficient adaptation to unknown low-dimensional data structures and achieving a convergence rate of O(k¬≤/‚àöT).</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/sntxbqsrw7/cover.png"/></item><item><title>Adaptive Labeling for Efficient Out-of-distribution Model Evaluation</title><link>https://deep-diver.github.io/neurips2024/posters/uuqqwrjmzb/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/uuqqwrjmzb/</guid><description>Adaptive labeling minimizes uncertainty in out-of-distribution model evaluation by strategically selecting which data points to label, leading to more efficient and reliable assessments.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/uuqqwrjmzb/cover.png"/></item><item><title>Adaptive Passive-Aggressive Framework for Online Regression with Side Information</title><link>https://deep-diver.github.io/neurips2024/posters/kv80nc1afe/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/kv80nc1afe/</guid><description>Adaptive Passive-Aggressive framework with Side information (APAS) significantly boosts online regression accuracy by dynamically adjusting thresholds and integrating side information, leading to supe&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/kv80nc1afe/cover.png"/></item><item><title>Adaptive Sampling for Efficient Softmax Approximation</title><link>https://deep-diver.github.io/neurips2024/posters/xsna2b8gpz/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/xsna2b8gpz/</guid><description>AdaptiveSoftmax: Achieve 10x+ speedup in softmax computation via adaptive sampling!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/xsna2b8gpz/cover.png"/></item><item><title>Adaptive Variance Reduction for Stochastic Optimization under Weaker Assumptions</title><link>https://deep-diver.github.io/neurips2024/posters/tmqh8prqlc/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/tmqh8prqlc/</guid><description>Adaptive STORM achieves optimal convergence rates for stochastic optimization of non-convex functions under weaker assumptions, eliminating the need for bounded gradients or function values and removi&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/tmqh8prqlc/cover.png"/></item><item><title>ADOPT: Modified Adam Can Converge with Any $eta_2$ with the Optimal Rate</title><link>https://deep-diver.github.io/neurips2024/posters/rzvvm0lsyk/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/rzvvm0lsyk/</guid><description>ADOPT, a novel adaptive gradient method, achieves optimal convergence rates without restrictive assumptions, unlike Adam, significantly improving deep learning optimization.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/rzvvm0lsyk/cover.png"/></item><item><title>Advancing Training Efficiency of Deep Spiking Neural Networks through Rate-based Backpropagation</title><link>https://deep-diver.github.io/neurips2024/posters/wlcm21c4nk/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/wlcm21c4nk/</guid><description>Rate-based backpropagation boosts deep spiking neural network training efficiency by leveraging rate coding, achieving comparable performance to BPTT with reduced complexity.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/wlcm21c4nk/cover.png"/></item><item><title>Adversarially Robust Multi-task Representation Learning</title><link>https://deep-diver.github.io/neurips2024/posters/w2l3ll1jbv/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/w2l3ll1jbv/</guid><description>Multi-task learning boosts adversarial robustness in transfer learning by leveraging diverse source data to build a shared representation, enabling effective learning in data-scarce target tasks, as p&amp;hellip;</description></item><item><title>Alias-Free Mamba Neural Operator</title><link>https://deep-diver.github.io/neurips2024/posters/guebxgv8jm/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/guebxgv8jm/</guid><description>MambaNO: a novel neural operator achieving linear complexity and state-of-the-art accuracy in solving PDEs by cleverly balancing global and local information using an alias-free architecture.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/guebxgv8jm/cover.png"/></item><item><title>Aligning Diffusion Behaviors with Q-functions for Efficient Continuous Control</title><link>https://deep-diver.github.io/neurips2024/posters/wd1dflup1m/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/wd1dflup1m/</guid><description>Efficient Diffusion Alignment (EDA) leverages pretrained diffusion models and Q-functions for efficient continuous control, exceeding all baselines with minimal annotation.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/wd1dflup1m/cover.png"/></item><item><title>Almost Minimax Optimal Best Arm Identification in Piecewise Stationary Linear Bandits</title><link>https://deep-diver.github.io/neurips2024/posters/q5e3ftq3q3/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/q5e3ftq3q3/</guid><description>PS…õBAI+ is a near-optimal algorithm for best arm identification in piecewise stationary linear bandits, efficiently detecting changepoints and aligning contexts for improved accuracy and minimal sampl&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/q5e3ftq3q3/cover.png"/></item><item><title>Amortized Bayesian Experimental Design for Decision-Making</title><link>https://deep-diver.github.io/neurips2024/posters/zbg7wogavm/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/zbg7wogavm/</guid><description>Amortized Decision-Aware BED prioritizes maximizing downstream decision utility by instantly proposing informative experimental designs and inferring decisions, facilitating accurate decision-making.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/zbg7wogavm/cover.png"/></item><item><title>Amortized Fourier Neural Operators</title><link>https://deep-diver.github.io/neurips2024/posters/a6em980m9x/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/a6em980m9x/</guid><description>Amortized Fourier Neural Operators (AM-FNOs) dramatically improve efficiency in solving PDEs by using neural networks for kernel parameterization, achieving up to 31% better accuracy compared to exist&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/a6em980m9x/cover.png"/></item><item><title>Amortized Planning with Large-Scale Transformers: A Case Study on Chess</title><link>https://deep-diver.github.io/neurips2024/posters/xlpipugygx/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/xlpipugygx/</guid><description>Large-scale transformers achieve grandmaster-level chess play via supervised learning on a new 10M game benchmark dataset, demonstrating impressive generalization beyond memorization.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/xlpipugygx/cover.png"/></item><item><title>An Accelerated Algorithm for Stochastic Bilevel Optimization under Unbounded Smoothness</title><link>https://deep-diver.github.io/neurips2024/posters/v7vyvvmfru/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/v7vyvvmfru/</guid><description>AccBO: A new accelerated algorithm achieves O(Œµ‚Åª¬≥) oracle complexity for stochastic bilevel optimization with unbounded smoothness, significantly improving upon existing O(Œµ‚Åª‚Å¥) methods.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/v7vyvvmfru/cover.png"/></item><item><title>An Accelerated Gradient Method for Convex Smooth Simple Bilevel Optimization</title><link>https://deep-diver.github.io/neurips2024/posters/afodln7jbv/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/afodln7jbv/</guid><description>Accelerated Gradient Method for Bilevel Optimization (AGM-BiO) achieves state-of-the-art convergence rates for simple bilevel optimization problems, requiring fewer iterations than existing methods to&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/afodln7jbv/cover.png"/></item><item><title>An Analytical Study of Utility Functions in Multi-Objective Reinforcement Learning</title><link>https://deep-diver.github.io/neurips2024/posters/k3h2kzfz8h/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/k3h2kzfz8h/</guid><description>This paper provides novel theoretical analyses of utility functions in MORL, characterizing preferences and functions guaranteeing optimal policies.</description></item><item><title>An Efficient Memory Module for Graph Few-Shot Class-Incremental Learning</title><link>https://deep-diver.github.io/neurips2024/posters/dqdffx3bs5/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/dqdffx3bs5/</guid><description>Mecoin: a novel memory module for efficient graph few-shot class-incremental learning, tackles catastrophic forgetting by employing structured memory units and a memory representation adaptation modul&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/dqdffx3bs5/cover.png"/></item><item><title>An exactly solvable model for emergence and scaling laws in the multitask sparse parity problem</title><link>https://deep-diver.github.io/neurips2024/posters/cuwsr25bbi/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/cuwsr25bbi/</guid><description>A novel multilinear model analytically explains the emergence and scaling laws of skills in the multitask sparse parity problem, accurately predicting skill emergence in neural networks.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/cuwsr25bbi/cover.png"/></item><item><title>An Improved Empirical Fisher Approximation for Natural Gradient Descent</title><link>https://deep-diver.github.io/neurips2024/posters/lmjlrhvcmg/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/lmjlrhvcmg/</guid><description>Improved Empirical Fisher (iEF) approximation significantly boosts the performance of Natural Gradient Descent (NGD) optimizers, offering superior convergence and generalization.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/lmjlrhvcmg/cover.png"/></item><item><title>An Offline Adaptation Framework for Constrained Multi-Objective Reinforcement Learning</title><link>https://deep-diver.github.io/neurips2024/posters/qb6cvdqa6b/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/qb6cvdqa6b/</guid><description>This work introduces PDOA, an offline adaptation framework for constrained multi-objective RL, using demonstrations instead of manually designed preferences to infer optimal policies while satisfying &amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/qb6cvdqa6b/cover.png"/></item><item><title>Approximately Equivariant Neural Processes</title><link>https://deep-diver.github.io/neurips2024/posters/dqt9mc5nql/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/dqt9mc5nql/</guid><description>Boosting meta-learning, this paper introduces a novel, flexible approach to create approximately equivariant neural processes that outperform both non-equivariant and strictly equivariant counterparts&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/dqt9mc5nql/cover.png"/></item><item><title>Approximation Rate of the Transformer Architecture for Sequence Modeling</title><link>https://deep-diver.github.io/neurips2024/posters/zws2y21mzv/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/zws2y21mzv/</guid><description>This paper unveils the Transformer&amp;rsquo;s approximation power, deriving explicit Jackson-type rates to reveal its strengths and limitations in handling various sequential relationships.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/zws2y21mzv/cover.png"/></item><item><title>Are Self-Attentions Effective for Time Series Forecasting?</title><link>https://deep-diver.github.io/neurips2024/posters/in43sjoib7/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/in43sjoib7/</guid><description>Cross-Attention-only Time Series Transformer (CATS) outperforms existing models by removing self-attention, improving long-term forecasting accuracy, and reducing computational cost.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/in43sjoib7/cover.png"/></item><item><title>Are Uncertainty Quantification Capabilities of Evidential Deep Learning a Mirage?</title><link>https://deep-diver.github.io/neurips2024/posters/p6nvdzrzrb/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/p6nvdzrzrb/</guid><description>Evidential deep learning&amp;rsquo;s uncertainty quantification is unreliable; this paper reveals its limitations, proposes model uncertainty incorporation for improved performance.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/p6nvdzrzrb/cover.png"/></item><item><title>Artificial Generational Intelligence: Cultural Accumulation in Reinforcement Learning</title><link>https://deep-diver.github.io/neurips2024/posters/pmacrgu8gv/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/pmacrgu8gv/</guid><description>Reinforcement learning agents achieve emergent cultural accumulation by balancing social and independent learning, outperforming single-lifetime agents.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/pmacrgu8gv/cover.png"/></item><item><title>AUC Maximization under Positive Distribution Shift</title><link>https://deep-diver.github.io/neurips2024/posters/yoe6ajdsli/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/yoe6ajdsli/</guid><description>New method maximizes AUC under positive distribution shift using only positive and unlabeled training data, and unlabeled test data; improving imbalanced classification.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/yoe6ajdsli/cover.png"/></item><item><title>Avoiding Undesired Future with Minimal Cost in Non-Stationary Environments</title><link>https://deep-diver.github.io/neurips2024/posters/yhd2khhntb/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/yhd2khhntb/</guid><description>AUF-MICNS: A novel sequential method efficiently solves the avoiding undesired future problem by dynamically updating influence relations in non-stationary environments while minimizing action costs.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/yhd2khhntb/cover.png"/></item><item><title>Balancing Context Length and Mixing Times for Reinforcement Learning at Scale</title><link>https://deep-diver.github.io/neurips2024/posters/vaj4xow7ey/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/vaj4xow7ey/</guid><description>Longer context in RL boosts generalization but slows down learning; this paper reveals the crucial tradeoff and offers theoretical insights.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/vaj4xow7ey/cover.png"/></item><item><title>BAN: Detecting Backdoors Activated by Neuron Noise</title><link>https://deep-diver.github.io/neurips2024/posters/asyyszl4n5/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/asyyszl4n5/</guid><description>BAN: a novel backdoor defense using adversarial neuron noise for efficient detection and mitigation.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/asyyszl4n5/cover.png"/></item><item><title>Bandits with Preference Feedback: A Stackelberg Game Perspective</title><link>https://deep-diver.github.io/neurips2024/posters/wie991zhxh/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/wie991zhxh/</guid><description>MAXMINLCB, a novel game-theoretic algorithm, efficiently solves bandit problems with preference feedback over continuous domains, providing anytime-valid, rate-optimal regret guarantees.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/wie991zhxh/cover.png"/></item><item><title>Bandits with Ranking Feedback</title><link>https://deep-diver.github.io/neurips2024/posters/acaspffahg/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/acaspffahg/</guid><description>This paper introduces &amp;lsquo;bandits with ranking feedback,&amp;rsquo; a novel bandit variation providing ranked feedback instead of numerical rewards. It proves instance-dependent cases require superlogarithmic reg&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/acaspffahg/cover.png"/></item><item><title>Batched Energy-Entropy acquisition for Bayesian Optimization</title><link>https://deep-diver.github.io/neurips2024/posters/wqijnypent/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/wqijnypent/</guid><description>BEEBO: a novel acquisition function for Bayesian Optimization, offering superior explore-exploit balance and handling large batches efficiently, even with noisy data.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/wqijnypent/cover.png"/></item><item><title>Bayesian Adaptive Calibration and Optimal Design</title><link>https://deep-diver.github.io/neurips2024/posters/m906ps5g9x/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/m906ps5g9x/</guid><description>BACON: a novel Bayesian adaptive calibration and optimal design algorithm maximizes information gain for data-efficient computer model calibration, significantly outperforming existing methods in synt&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/m906ps5g9x/cover.png"/></item><item><title>Beyond Redundancy: Information-aware Unsupervised Multiplex Graph Structure Learning</title><link>https://deep-diver.github.io/neurips2024/posters/xaqpakjnas/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/xaqpakjnas/</guid><description>InfoMGF, a novel framework, tackles the limitations of unsupervised multiplex graph learning by refining graph structures, maximizing task-relevant information (both shared and unique), and achieving &amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/xaqpakjnas/cover.png"/></item><item><title>Block Sparse Bayesian Learning: A Diversified Scheme</title><link>https://deep-diver.github.io/neurips2024/posters/a4cppx1xyg/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/a4cppx1xyg/</guid><description>Diversified Block Sparse Bayesian Learning (DivSBL) improves block sparse signal recovery by adapting to unknown block structures, enhancing accuracy and robustness over existing methods.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/a4cppx1xyg/cover.png"/></item><item><title>Boosting Graph Pooling with Persistent Homology</title><link>https://deep-diver.github.io/neurips2024/posters/wcmqdy2aku/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/wcmqdy2aku/</guid><description>Boosting graph neural networks: Topology-Invariant Pooling (TIP) leverages persistent homology to enhance graph pooling, achieving consistent performance gains across diverse datasets.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/wcmqdy2aku/cover.png"/></item><item><title>Breaking the curse of dimensionality in structured density estimation</title><link>https://deep-diver.github.io/neurips2024/posters/dwwin2ugye/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/dwwin2ugye/</guid><description>Researchers break the curse of dimensionality in structured density estimation using graph resilience, a novel graphical parameter that effectively reduces the sample complexity.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/dwwin2ugye/cover.png"/></item><item><title>Bridging Geometric States via Geometric Diffusion Bridge</title><link>https://deep-diver.github.io/neurips2024/posters/zcepob9rcr/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/zcepob9rcr/</guid><description>Geometric Diffusion Bridge (GDB) accurately predicts geometric state evolution in complex systems by leveraging a probabilistic approach and equivariant diffusion processes, surpassing existing deep l&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/zcepob9rcr/cover.png"/></item><item><title>Bridging Model-Based Optimization and Generative Modeling via Conservative Fine-Tuning of Diffusion Models</title><link>https://deep-diver.github.io/neurips2024/posters/zir2qju4hl/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/zir2qju4hl/</guid><description>BRAID: A novel, conservative fine-tuning method surpasses offline design optimization by cleverly combining generative diffusion models with reward models, preventing over-optimization and generating &amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/zir2qju4hl/cover.png"/></item><item><title>Bridging OOD Detection and Generalization: A Graph-Theoretic View</title><link>https://deep-diver.github.io/neurips2024/posters/qzwag8qxi1/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/qzwag8qxi1/</guid><description>A novel graph-theoretic framework bridges OOD detection &amp;amp; generalization, offering theoretical error bounds and competitive empirical performance.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/qzwag8qxi1/cover.png"/></item><item><title>C-GAIL: Stabilizing Generative Adversarial Imitation Learning with Control Theory</title><link>https://deep-diver.github.io/neurips2024/posters/t4vwoiybf0/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/t4vwoiybf0/</guid><description>C-GAIL stabilizes Generative Adversarial Imitation Learning by applying control theory, resulting in faster convergence, reduced oscillation, and better expert policy matching.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/t4vwoiybf0/cover.png"/></item><item><title>Capturing the denoising effect of PCA via compression ratio</title><link>https://deep-diver.github.io/neurips2024/posters/a4j7ndlxem/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/a4j7ndlxem/</guid><description>PCA&amp;rsquo;s denoising effect is quantified via a novel metric: compression ratio. This metric reveals PCA&amp;rsquo;s ability to reduce intra-community distances while preserving inter-community distances in noisy d&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/a4j7ndlxem/cover.png"/></item><item><title>Cardinality-Aware Set Prediction and Top-$k$ Classification</title><link>https://deep-diver.github.io/neurips2024/posters/wat3qu737x/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/wat3qu737x/</guid><description>This paper proposes cardinality-aware top-k classification, improving accuracy and efficiency by dynamically adjusting prediction set sizes.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/wat3qu737x/cover.png"/></item><item><title>Carrot and Stick: Eliciting Comparison Data and Beyond</title><link>https://deep-diver.github.io/neurips2024/posters/ofjtu2ktxo/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/ofjtu2ktxo/</guid><description>Truthful comparison data is hard to obtain without ground truth. This paper presents novel peer prediction mechanisms using bonus-penalty payments that incentivize truthful comparisons, even in networ&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/ofjtu2ktxo/cover.png"/></item><item><title>Cascade of phase transitions in the training of energy-based models</title><link>https://deep-diver.github.io/neurips2024/posters/qtf6xz4vve/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/qtf6xz4vve/</guid><description>Energy-based models&amp;rsquo; training reveals a cascade of phase transitions, progressively learning data features, offering new insights into deep learning dynamics.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/qtf6xz4vve/cover.png"/></item><item><title>Causal Contrastive Learning for Counterfactual Regression Over Time</title><link>https://deep-diver.github.io/neurips2024/posters/bkozybje4z/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/bkozybje4z/</guid><description>Causal CPC: a novel method for accurate and efficient counterfactual regression over time using RNNs, CPC, and InfoMax, achieving state-of-the-art performance.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/bkozybje4z/cover.png"/></item><item><title>Causal Imitation for Markov Decision Processes: a Partial Identification Approach</title><link>https://deep-diver.github.io/neurips2024/posters/khx0dkxdqh/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/khx0dkxdqh/</guid><description>This paper presents novel causal imitation learning algorithms using partial identification to achieve expert performance even when unobserved confounders affect Markov Decision Processes.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/khx0dkxdqh/cover.png"/></item><item><title>CE-NAS: An End-to-End Carbon-Efficient Neural Architecture Search Framework</title><link>https://deep-diver.github.io/neurips2024/posters/v6w55lckhn/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/v6w55lckhn/</guid><description>CE-NAS: A novel framework minimizes the carbon footprint of Neural Architecture Search by dynamically allocating GPU resources based on predicted carbon intensity, achieving state-of-the-art results w&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/v6w55lckhn/cover.png"/></item><item><title>Changing the Training Data Distribution to Reduce Simplicity Bias Improves In-distribution Generalization</title><link>https://deep-diver.github.io/neurips2024/posters/yyspldusu2/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/yyspldusu2/</guid><description>Boosting in-distribution generalization is achieved by strategically altering the training data distribution to reduce simplicity bias and promote uniform feature learning.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/yyspldusu2/cover.png"/></item><item><title>Clustering with Non-adaptive Subset Queries</title><link>https://deep-diver.github.io/neurips2024/posters/lgtsxxk4df/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/lgtsxxk4df/</guid><description>This paper introduces novel non-adaptive algorithms for clustering using subset queries, achieving near-linear query complexity and improving upon existing limitations of pairwise query methods.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/lgtsxxk4df/cover.png"/></item><item><title>CoBo: Collaborative Learning via Bilevel Optimization</title><link>https://deep-diver.github.io/neurips2024/posters/sjq1iiqpfu/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/sjq1iiqpfu/</guid><description>CoBo: A novel bilevel optimization algorithm for collaborative learning surpasses existing methods by efficiently selecting helpful clients, resulting in superior performance and scalability.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/sjq1iiqpfu/cover.png"/></item><item><title>CODA: A Correlation-Oriented Disentanglement and Augmentation Modeling Scheme for Better Resisting Subpopulation Shifts</title><link>https://deep-diver.github.io/neurips2024/posters/lrsrjzzcle/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/lrsrjzzcle/</guid><description>CODA: A novel modeling scheme tackles subpopulation shifts in machine learning by disentangling spurious correlations, augmenting data strategically, and using reweighted consistency loss for improved&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/lrsrjzzcle/cover.png"/></item><item><title>Collaborative Refining for Learning from Inaccurate Labels</title><link>https://deep-diver.github.io/neurips2024/posters/rqqgbbqvbl/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/rqqgbbqvbl/</guid><description>Collaborative Refining for Learning from Inaccurate Labels (CRL) refines data using annotator agreement, improving model accuracy with noisy labels.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/rqqgbbqvbl/cover.png"/></item><item><title>Combining Statistical Depth and Fermat Distance for Uncertainty Quantification</title><link>https://deep-diver.github.io/neurips2024/posters/xexrhtumcf/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/xexrhtumcf/</guid><description>Boosting neural network prediction reliability, this research ingeniously combines statistical depth and Fermat distance for superior uncertainty quantification, eliminating the need for distributiona&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/xexrhtumcf/cover.png"/></item><item><title>Communication Efficient Distributed Training with Distributed Lion</title><link>https://deep-diver.github.io/neurips2024/posters/wdircetioz/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/wdircetioz/</guid><description>Distributed Lion: Training large AI models efficiently by communicating only binary or low-precision vectors between workers and a server, significantly reducing communication costs and maintaining co&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/wdircetioz/cover.png"/></item><item><title>Communication-Efficient Federated Group Distributionally Robust Optimization</title><link>https://deep-diver.github.io/neurips2024/posters/xnzejfe0mh/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/xnzejfe0mh/</guid><description>Communication-efficient algorithms for federated group distributionally robust optimization (FGDRO) are introduced, achieving lower communication complexity and superior performance on real-world task&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/xnzejfe0mh/cover.png"/></item><item><title>Computation-Aware Gaussian Processes: Model Selection And Linear-Time Inference</title><link>https://deep-diver.github.io/neurips2024/posters/tdvfa5ojys/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/tdvfa5ojys/</guid><description>Computation-Aware Gaussian Processes (CaGP) achieve linear-time inference and model selection, enabling efficient training of GPs on large datasets without compromising uncertainty quantification, sur&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/tdvfa5ojys/cover.png"/></item><item><title>Computing the Bias of Constant-step Stochastic Approximation with Markovian Noise</title><link>https://deep-diver.github.io/neurips2024/posters/rxxdokk2qz/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/rxxdokk2qz/</guid><description>New method quantifies &amp;amp; reduces bias in constant-step stochastic approximation algorithms with Markovian noise, improving accuracy and efficiency.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/rxxdokk2qz/cover.png"/></item><item><title>Con4m: Context-aware Consistency Learning Framework for Segmented Time Series Classification</title><link>https://deep-diver.github.io/neurips2024/posters/jcpufqahvb/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/jcpufqahvb/</guid><description>Con4m, a novel consistency learning framework, leverages contextual information to effectively classify segmented time series with inconsistent boundary labels and varying durations of classes, signif&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/jcpufqahvb/cover.png"/></item><item><title>CondTSF: One-line Plugin of Dataset Condensation for Time Series Forecasting</title><link>https://deep-diver.github.io/neurips2024/posters/l1jajnwon5/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/l1jajnwon5/</guid><description>CondTSF: One-line plugin for time series forecasting dataset condensation, boosting performance at low condensation ratios.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/l1jajnwon5/cover.png"/></item><item><title>Confidence Calibration of Classifiers with Many Classes</title><link>https://deep-diver.github.io/neurips2024/posters/ebbnkvxmcz/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/ebbnkvxmcz/</guid><description>Boost multi-class classifier calibration by cleverly transforming the problem into a single binary calibration task!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/ebbnkvxmcz/cover.png"/></item><item><title>Confident Natural Policy Gradient for Local Planning in q_œÄ-realizable Constrained MDPs</title><link>https://deep-diver.github.io/neurips2024/posters/tnemagwoxr/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/tnemagwoxr/</guid><description>Confident-NPG-CMDP: First primal-dual algorithm achieving polynomial sample complexity for solving constrained Markov decision processes (CMDPs) using function approximation and local access model.</description></item><item><title>Conformal Prediction for Class-wise Coverage via Augmented Label Rank Calibration</title><link>https://deep-diver.github.io/neurips2024/posters/t7ds1ghwwu/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/t7ds1ghwwu/</guid><description>RC3P, a novel algorithm, significantly reduces prediction set sizes in class-conditional conformal prediction while guaranteeing class-wise coverage, even on imbalanced datasets.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/t7ds1ghwwu/cover.png"/></item><item><title>Conformalized Credal Set Predictors</title><link>https://deep-diver.github.io/neurips2024/posters/vbah12uvbd/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/vbah12uvbd/</guid><description>Conformal prediction empowers robust credal set predictions, handling aleatoric and epistemic uncertainties in classification, guaranteed to be valid with high probability!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/vbah12uvbd/cover.png"/></item><item><title>Conformalized Time Series with Semantic Features</title><link>https://deep-diver.github.io/neurips2024/posters/kcdcavow1s/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/kcdcavow1s/</guid><description>Conformalized Time Series with Semantic Features (CT-SSF) significantly improves time-series forecasting by dynamically weighting latent semantic features, achieving greater prediction efficiency whil&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/kcdcavow1s/cover.png"/></item><item><title>Constrained Latent Action Policies for Model-Based Offline Reinforcement Learning</title><link>https://deep-diver.github.io/neurips2024/posters/pehvscmsgg/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/pehvscmsgg/</guid><description>Constrained Latent Action Policies (C-LAP) revolutionizes offline reinforcement learning by jointly modeling state-action distributions, implicitly constraining policies to improve efficiency and redu&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/pehvscmsgg/cover.png"/></item><item><title>Context-Aware Testing: A New Paradigm for Model Testing with Large Language Models</title><link>https://deep-diver.github.io/neurips2024/posters/d75qczb7tx/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/d75qczb7tx/</guid><description>Context-Aware Testing (CAT) revolutionizes ML model testing by using contextual information to identify relevant failures, surpassing traditional data-only methods.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/d75qczb7tx/cover.png"/></item><item><title>Contextual Active Model Selection</title><link>https://deep-diver.github.io/neurips2024/posters/zizwgyertq/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/zizwgyertq/</guid><description>CAMS, a novel contextual active model selection algorithm, minimizes labeling costs by strategically selecting pre-trained models and querying labels for data points, achieving significant improvement&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/zizwgyertq/cover.png"/></item><item><title>Contextual Bilevel Reinforcement Learning for Incentive Alignment</title><link>https://deep-diver.github.io/neurips2024/posters/w3dx1tgw3f/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/w3dx1tgw3f/</guid><description>Contextual Bilevel Reinforcement Learning (CB-RL) tackles real-world strategic decision-making where optimal policies depend on environmental configurations and exogenous events, proposing a stochasti&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/w3dx1tgw3f/cover.png"/></item><item><title>Continual Learning in the Frequency Domain</title><link>https://deep-diver.github.io/neurips2024/posters/xgazclsjaq/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/xgazclsjaq/</guid><description>Boost continual learning efficiency with CLFD: a novel frequency domain approach that improves accuracy by up to 6.83% and slashes training time by 2.6x on edge devices!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/xgazclsjaq/cover.png"/></item><item><title>Continuous Contrastive Learning for Long-Tailed Semi-Supervised Recognition</title><link>https://deep-diver.github.io/neurips2024/posters/paqj71zf1m/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/paqj71zf1m/</guid><description>CCL, a novel probabilistic framework, uses continuous contrastive learning to excel in long-tailed semi-supervised recognition, surpassing prior state-of-the-art methods by over 4%.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/paqj71zf1m/cover.png"/></item><item><title>Continuous Partitioning for Graph-Based Semi-Supervised Learning</title><link>https://deep-diver.github.io/neurips2024/posters/hcouip5ona/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/hcouip5ona/</guid><description>CutSSL: a novel framework for graph-based semi-supervised learning, surpasses state-of-the-art accuracy by solving a continuous nonconvex quadratic program that provably yields integer solutions, exce&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/hcouip5ona/cover.png"/></item><item><title>CONTRAST: Continual Multi-source Adaptation to Dynamic Distributions</title><link>https://deep-diver.github.io/neurips2024/posters/mpdbwjlzft/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/mpdbwjlzft/</guid><description>CONTRAST efficiently adapts multiple source models to dynamic data distributions by optimally weighting models and selectively updating only the most relevant ones, achieving robust performance withou&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/mpdbwjlzft/cover.png"/></item><item><title>Controlled maximal variability along with reliable performance in recurrent neural networks</title><link>https://deep-diver.github.io/neurips2024/posters/yxw2dctqdi/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/yxw2dctqdi/</guid><description>NeuroMOP, a novel neural principle, maximizes neural variability while ensuring reliable performance in recurrent neural networks, offering new insights into brain function and artificial intelligence&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/yxw2dctqdi/cover.png"/></item><item><title>Controlling Continuous Relaxation for Combinatorial Optimization</title><link>https://deep-diver.github.io/neurips2024/posters/ykacv1ihjd/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/ykacv1ihjd/</guid><description>Continuous Relaxation Annealing (CRA) significantly boosts unsupervised learning-based solvers for combinatorial optimization by dynamically shifting from continuous to discrete solutions, eliminating&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/ykacv1ihjd/cover.png"/></item><item><title>ControlSynth Neural ODEs: Modeling Dynamical Systems with Guaranteed Convergence</title><link>https://deep-diver.github.io/neurips2024/posters/dbe8khdmfs/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/dbe8khdmfs/</guid><description>ControlSynth Neural ODEs (CSODEs) guarantee convergence in complex dynamical systems via tractable linear inequalities, improving neural ODE modeling.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/dbe8khdmfs/cover.png"/></item><item><title>Convergence Analysis of Split Federated Learning on Heterogeneous Data</title><link>https://deep-diver.github.io/neurips2024/posters/ud0rbkdbfe/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/ud0rbkdbfe/</guid><description>Split Federated Learning (SFL) convergence is analyzed for heterogeneous data, achieving O(1/T) and O(1/‚àöT) rates for strongly convex and general convex objectives respectively. The study also extend&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/ud0rbkdbfe/cover.png"/></item><item><title>Convolutions and More as Einsum: A Tensor Network Perspective with Advances for Second-Order Methods</title><link>https://deep-diver.github.io/neurips2024/posters/cds8wxnmvp/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/cds8wxnmvp/</guid><description>This paper accelerates second-order optimization in CNNs by 4.5x, using a novel tensor network representation that simplifies convolutions and reduces memory overhead.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/cds8wxnmvp/cover.png"/></item><item><title>Counter-Current Learning: A Biologically Plausible Dual Network Approach for Deep Learning</title><link>https://deep-diver.github.io/neurips2024/posters/l3rybqzrmf/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/l3rybqzrmf/</guid><description>Biologically inspired Counter-Current Learning (CCL) uses dual networks for deep learning, offering comparable performance to other biologically plausible algorithms while enhancing biological realism&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/l3rybqzrmf/cover.png"/></item><item><title>Credal Deep Ensembles for Uncertainty Quantification</title><link>https://deep-diver.github.io/neurips2024/posters/pcgntigc9k/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/pcgntigc9k/</guid><description>Credal Deep Ensembles (CreDEs) improve uncertainty quantification in deep learning by predicting probability intervals, enhancing accuracy and calibration, particularly for out-of-distribution data.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/pcgntigc9k/cover.png"/></item><item><title>CRONOS: Enhancing Deep Learning with Scalable GPU Accelerated Convex Neural Networks</title><link>https://deep-diver.github.io/neurips2024/posters/yflzyczao3/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/yflzyczao3/</guid><description>CRONOS: Scaling convex neural network training to ImageNet!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/yflzyczao3/cover.png"/></item><item><title>Cross-Device Collaborative Test-Time Adaptation</title><link>https://deep-diver.github.io/neurips2024/posters/yymio0dwmi/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/yymio0dwmi/</guid><description>CoLA: Collaborative Lifelong Adaptation boosts test-time adaptation efficiency by sharing domain knowledge across multiple devices, achieving significant accuracy gains with minimal computational over&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/yymio0dwmi/cover.png"/></item><item><title>D2R2: Diffusion-based Representation with Random Distance Matching for Tabular Few-shot Learning</title><link>https://deep-diver.github.io/neurips2024/posters/ls9e36lkxg/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/ls9e36lkxg/</guid><description>D2R2: A novel diffusion-based model for tabular few-shot learning, achieves state-of-the-art results by leveraging semantic knowledge and distance matching.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/ls9e36lkxg/cover.png"/></item><item><title>Data Acquisition via Experimental Design for Data Markets</title><link>https://deep-diver.github.io/neurips2024/posters/vxjvndmxo4/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/vxjvndmxo4/</guid><description>Federated data acquisition via experimental design (DAVED) achieves lower prediction error without labeled validation data, optimizing cost-effectively for test-set predictions in decentralized market&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/vxjvndmxo4/cover.png"/></item><item><title>DDN: Dual-domain Dynamic Normalization for Non-stationary Time Series Forecasting</title><link>https://deep-diver.github.io/neurips2024/posters/rvzfra6szo/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/rvzfra6szo/</guid><description>DDN: Dual-domain Dynamic Normalization dynamically improves time series forecasting accuracy by addressing data distribution changes in both time and frequency domains via a plug-in module.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/rvzfra6szo/cover.png"/></item><item><title>Decentralized Noncooperative Games with Coupled Decision-Dependent Distributions</title><link>https://deep-diver.github.io/neurips2024/posters/kqgszxbufw/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/kqgszxbufw/</guid><description>Decentralized noncooperative games with coupled decision-dependent distributions are analyzed, providing novel equilibrium concepts, uniqueness conditions, and a decentralized algorithm with sublinear&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/kqgszxbufw/cover.png"/></item><item><title>Decision Mamba: Reinforcement Learning via Hybrid Selective Sequence Modeling</title><link>https://deep-diver.github.io/neurips2024/posters/wfzimbtsy7/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/wfzimbtsy7/</guid><description>Decision Mamba-Hybrid (DM-H) accelerates in-context RL for long-term tasks by cleverly combining the strengths of Mamba&amp;rsquo;s linear long-term memory processing and transformer&amp;rsquo;s high-quality predictions,&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/wfzimbtsy7/cover.png"/></item><item><title>Deep Equilibrium Algorithmic Reasoning</title><link>https://deep-diver.github.io/neurips2024/posters/sulxkxcena/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/sulxkxcena/</guid><description>Deep Equilibrium Algorithmic Reasoners (DEARs) achieve superior performance on algorithmic tasks by directly solving for the equilibrium point of a neural network, eliminating the need for iterative r&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/sulxkxcena/cover.png"/></item><item><title>Deep Graph Mating</title><link>https://deep-diver.github.io/neurips2024/posters/m4ni2yiwja/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/m4ni2yiwja/</guid><description>Deep Graph Mating (GRAMA) enables training-free knowledge transfer in GNNs, achieving results comparable to pre-trained models without retraining or labeled data.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/m4ni2yiwja/cover.png"/></item><item><title>Deep Graph Neural Networks via Posteriori-Sampling-based Node-Adaptative Residual Module</title><link>https://deep-diver.github.io/neurips2024/posters/vywzsaghp0/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/vywzsaghp0/</guid><description>PSNR, a novel node-adaptive residual module, significantly improves deep GNN performance by mitigating over-smoothing and handling missing data.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/vywzsaghp0/cover.png"/></item><item><title>DeepDRK: Deep Dependency Regularized Knockoff for Feature Selection</title><link>https://deep-diver.github.io/neurips2024/posters/ibkppabhvn/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/ibkppabhvn/</guid><description>DeepDRK, a novel deep learning approach, significantly improves feature selection by effectively balancing false discovery rate and power, surpassing existing methods, especially with limited data.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/ibkppabhvn/cover.png"/></item><item><title>DeepLag: Discovering Deep Lagrangian Dynamics for Intuitive Fluid Prediction</title><link>https://deep-diver.github.io/neurips2024/posters/scw6et4per/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/scw6et4per/</guid><description>DeepLag improves fluid prediction by uniquely combining Lagrangian and Eulerian perspectives, tracking key particles to reveal hidden dynamics and improve prediction accuracy.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/scw6et4per/cover.png"/></item><item><title>Density-based User Representation using Gaussian Process Regression for Multi-interest Personalized Retrieval</title><link>https://deep-diver.github.io/neurips2024/posters/px1hqm72ix/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/px1hqm72ix/</guid><description>GPR4DUR leverages Gaussian Process Regression to create density-based user representations for accurate multi-interest personalized retrieval, overcoming limitations of existing methods.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/px1hqm72ix/cover.png"/></item><item><title>Derivative-enhanced Deep Operator Network</title><link>https://deep-diver.github.io/neurips2024/posters/waiqlgfqx6/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/waiqlgfqx6/</guid><description>Derivative-enhanced DeepONets boost PDE solution accuracy and derivative approximation, particularly valuable with limited training data.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/waiqlgfqx6/cover.png"/></item><item><title>Deterministic Policies for Constrained Reinforcement Learning in Polynomial Time</title><link>https://deep-diver.github.io/neurips2024/posters/yremb4nakk/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/yremb4nakk/</guid><description>This paper presents an efficient algorithm to compute near-optimal deterministic policies for constrained reinforcement learning problems, solving a 25-year-old computational complexity challenge.</description></item><item><title>DFA-GNN: Forward Learning of Graph Neural Networks by Direct Feedback Alignment</title><link>https://deep-diver.github.io/neurips2024/posters/hkvtwqqu76/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/hkvtwqqu76/</guid><description>DFA-GNN: A novel forward learning framework for GNNs enhances training efficiency and robustness by directly aligning feedback signals, outperforming traditional methods.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/hkvtwqqu76/cover.png"/></item><item><title>DiffPO: A causal diffusion model for learning distributions of potential outcomes</title><link>https://deep-diver.github.io/neurips2024/posters/merj77jipt/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/merj77jipt/</guid><description>DiffPO: A causal diffusion model learns outcome distributions, offering reliable medical interventions.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/merj77jipt/cover.png"/></item><item><title>Diffusion Tuning: Transferring Diffusion Models via Chain of Forgetting</title><link>https://deep-diver.github.io/neurips2024/posters/s98ozjd3jn/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/s98ozjd3jn/</guid><description>Diff-Tuning: a simple yet effective approach transfers pre-trained diffusion models to various downstream tasks by leveraging the &amp;lsquo;chain of forgetting&amp;rsquo; phenomenon, improving transferability and conver&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/s98ozjd3jn/cover.png"/></item><item><title>Diffusion-based Curriculum Reinforcement Learning</title><link>https://deep-diver.github.io/neurips2024/posters/yrhrvadowe/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/yrhrvadowe/</guid><description>DiCuRL uses diffusion models to generate challenging yet achievable RL training curricula, outperforming nine state-of-the-art methods.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/yrhrvadowe/cover.png"/></item><item><title>Diffusion-Reward Adversarial Imitation Learning</title><link>https://deep-diver.github.io/neurips2024/posters/k9sh68mvjs/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/k9sh68mvjs/</guid><description>Diffusion-Reward Adversarial Imitation Learning (DRAIL) enhances Generative Adversarial Imitation Learning by integrating diffusion models, resulting in more stable and smoother reward functions for s&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/k9sh68mvjs/cover.png"/></item><item><title>DiffusionPDE: Generative PDE-Solving under Partial Observation</title><link>https://deep-diver.github.io/neurips2024/posters/z0i2sbjn0r/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/z0i2sbjn0r/</guid><description>DiffusionPDE uses generative diffusion models to solve PDEs accurately, even with highly incomplete observations, outperforming state-of-the-art methods.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/z0i2sbjn0r/cover.png"/></item><item><title>DiGRAF: Diffeomorphic Graph-Adaptive Activation Function</title><link>https://deep-diver.github.io/neurips2024/posters/zzow4z3le4/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/zzow4z3le4/</guid><description>DIGRAF, a novel graph-adaptive activation function, significantly boosts Graph Neural Network performance by dynamically adapting to graph structure, offering consistent superior results across divers&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/zzow4z3le4/cover.png"/></item><item><title>DisCEdit: Model Editing by Identifying Discriminative Components</title><link>https://deep-diver.github.io/neurips2024/posters/tuiqq1g8i5/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/tuiqq1g8i5/</guid><description>DISCEDIT efficiently identifies and edits discriminative neural network components for structured pruning and class unlearning, achieving high sparsity and forgetting rates without needing training da&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/tuiqq1g8i5/cover.png"/></item><item><title>Discovering Creative Behaviors through DUPLEX: Diverse Universal Features for Policy Exploration</title><link>https://deep-diver.github.io/neurips2024/posters/bhgkt0suy6/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/bhgkt0suy6/</guid><description>DUPLEX: a novel RL method trains diverse, near-optimal policies in complex, dynamic environments by explicitly maximizing policy diversity using successor features. It outperforms existing methods in&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/bhgkt0suy6/cover.png"/></item><item><title>Discovering plasticity rules that organize and maintain neural circuits</title><link>https://deep-diver.github.io/neurips2024/posters/nw4twuepgx/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/nw4twuepgx/</guid><description>AI discovers robust, biologically-plausible plasticity rules that self-organize and maintain neural circuits&amp;rsquo; sequential activity, even with synaptic turnover.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/nw4twuepgx/cover.png"/></item><item><title>Discrete-state Continuous-time Diffusion for Graph Generation</title><link>https://deep-diver.github.io/neurips2024/posters/ykskzehiyt/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/ykskzehiyt/</guid><description>DISCO: a novel discrete-state continuous-time diffusion model for flexible and efficient graph generation, outperforming state-of-the-art methods.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/ykskzehiyt/cover.png"/></item><item><title>Disentangled Unsupervised Skill Discovery for Efficient Hierarchical Reinforcement Learning</title><link>https://deep-diver.github.io/neurips2024/posters/epobcwfnfc/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/epobcwfnfc/</guid><description>DUSDi: A novel method for learning disentangled skills in unsupervised reinforcement learning, enabling efficient reuse for diverse downstream tasks.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/epobcwfnfc/cover.png"/></item><item><title>Disentangling and mitigating the impact of task similarity for continual learning</title><link>https://deep-diver.github.io/neurips2024/posters/be7gwlqzkm/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/be7gwlqzkm/</guid><description>This study reveals that high input similarity paired with low output similarity is detrimental to continual learning, whereas the opposite scenario is relatively benign; offering insights into mitigat&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/be7gwlqzkm/cover.png"/></item><item><title>Dissect Black Box: Interpreting for Rule-Based Explanations in Unsupervised Anomaly Detection</title><link>https://deep-diver.github.io/neurips2024/posters/h6o6qxlmhz/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/h6o6qxlmhz/</guid><description>SCD-Tree &amp;amp; GBD: Unlocking interpretable rules for unsupervised anomaly detection!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/h6o6qxlmhz/cover.png"/></item><item><title>Distributed Least Squares in Small Space via Sketching and Bias Reduction</title><link>https://deep-diver.github.io/neurips2024/posters/rkuvyost2c/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/rkuvyost2c/</guid><description>Researchers developed a novel sparse sketching method for distributed least squares regression, achieving near-unbiased estimates with optimal space and time complexity.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/rkuvyost2c/cover.png"/></item><item><title>Distributionally Robust Reinforcement Learning with Interactive Data Collection: Fundamental Hardness and Near-Optimal Algorithms</title><link>https://deep-diver.github.io/neurips2024/posters/aywtfsf3up/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/aywtfsf3up/</guid><description>Provably sample-efficient robust RL via interactive data collection is achieved by introducing the vanishing minimal value assumption to mitigate the curse of support shift, enabling near-optimal algo&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/aywtfsf3up/cover.png"/></item><item><title>DOFEN: Deep Oblivious Forest ENsemble</title><link>https://deep-diver.github.io/neurips2024/posters/umukvcdgi6/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/umukvcdgi6/</guid><description>DOFEN: Deep Oblivious Forest Ensemble achieves state-of-the-art performance on tabular data by using a novel DNN architecture inspired by oblivious decision trees, surpassing other DNNs.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/umukvcdgi6/cover.png"/></item><item><title>DU-Shapley: A Shapley Value Proxy for Efficient Dataset Valuation</title><link>https://deep-diver.github.io/neurips2024/posters/ucgfk8np0z/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/ucgfk8np0z/</guid><description>DU-Shapley efficiently estimates the Shapley value for dataset valuation, enabling fair compensation in collaborative machine learning by leveraging the problem&amp;rsquo;s structure for faster computation.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/ucgfk8np0z/cover.png"/></item><item><title>Dynamic Conditional Optimal Transport through Simulation-Free Flows</title><link>https://deep-diver.github.io/neurips2024/posters/tk0uarynhh/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/tk0uarynhh/</guid><description>Simulation-free flow generates conditional distributions via dynamic conditional optimal transport.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/tk0uarynhh/cover.png"/></item><item><title>Dynamic Model Predictive Shielding for Provably Safe Reinforcement Learning</title><link>https://deep-diver.github.io/neurips2024/posters/x2zy4hzcmg/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/x2zy4hzcmg/</guid><description>Dynamic Model Predictive Shielding (DMPS) ensures provably safe reinforcement learning by dynamically optimizing reinforcement learning objectives while maintaining provable safety, achieving higher r&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/x2zy4hzcmg/cover.png"/></item><item><title>Dynamics of Supervised and Reinforcement Learning in the Non-Linear Perceptron</title><link>https://deep-diver.github.io/neurips2024/posters/doajtihgiz/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/doajtihgiz/</guid><description>Researchers developed a novel stochastic-process approach to precisely analyze learning dynamics in nonlinear perceptrons, revealing how input noise and learning rules significantly impact learning sp&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/doajtihgiz/cover.png"/></item><item><title>EEGPT: Pretrained Transformer for Universal and Reliable Representation of EEG Signals</title><link>https://deep-diver.github.io/neurips2024/posters/lvs2b8cjg5/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/lvs2b8cjg5/</guid><description>EEGPT: A pretrained transformer model revolutionizes EEG signal representation by using a dual self-supervised learning method, achieving state-of-the-art results across various tasks.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/lvs2b8cjg5/cover.png"/></item><item><title>Efficient and Sharp Off-Policy Evaluation in Robust Markov Decision Processes</title><link>https://deep-diver.github.io/neurips2024/posters/lkguc2ry5v/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/lkguc2ry5v/</guid><description>This paper proposes a novel, statistically efficient offline policy evaluation method robust to environmental shifts and unobserved confounding, providing sharp bounds with theoretical guarantees.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/lkguc2ry5v/cover.png"/></item><item><title>Efficient Discrepancy Testing for Learning with Distribution Shift</title><link>https://deep-diver.github.io/neurips2024/posters/ojihvhqbaq/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/ojihvhqbaq/</guid><description>Provably efficient algorithms for learning with distribution shift are introduced, generalizing and improving prior work by achieving near-optimal error rates and offering universal learners for large&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/ojihvhqbaq/cover.png"/></item><item><title>Efficient Recurrent Off-Policy RL Requires a Context-Encoder-Specific Learning Rate</title><link>https://deep-diver.github.io/neurips2024/posters/tswot8ttko/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/tswot8ttko/</guid><description>Recurrent off-policy RL, while robust, suffers from training instability. RESEL, a novel algorithm, solves this by using a context-encoder-specific learning rate, significantly improving stability an&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/tswot8ttko/cover.png"/></item><item><title>Efficient Reinforcement Learning by Discovering Neural Pathways</title><link>https://deep-diver.github.io/neurips2024/posters/weoorep0n5/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/weoorep0n5/</guid><description>Discover efficient neural pathways for reinforcement learning; drastically reducing model size and energy consumption without sacrificing performance.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/weoorep0n5/cover.png"/></item><item><title>Efficient Sign-Based Optimization: Accelerating Convergence via Variance Reduction</title><link>https://deep-diver.github.io/neurips2024/posters/uanzvf1vfe/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/uanzvf1vfe/</guid><description>Sign-based optimization gets a speed boost! This paper introduces new algorithms that significantly accelerate convergence in distributed optimization by cleverly using variance reduction and enhanced&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/uanzvf1vfe/cover.png"/></item><item><title>ElasTST: Towards Robust Varied-Horizon Forecasting with Elastic Time-Series Transformer</title><link>https://deep-diver.github.io/neurips2024/posters/ucxutmpwhv/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/ucxutmpwhv/</guid><description>ElasTST: A novel time-series transformer enables robust forecasting across various horizons without per-horizon training, enhancing adaptability and accuracy.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/ucxutmpwhv/cover.png"/></item><item><title>Enabling Adaptive Agent Training in Open-Ended Simulators by Targeting Diversity</title><link>https://deep-diver.github.io/neurips2024/posters/xo1yqyw7yx/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/xo1yqyw7yx/</guid><description>DIVA: Evolutionary task generation for robust, adaptable AI agents in complex simulators.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/xo1yqyw7yx/cover.png"/></item><item><title>Energy-Based Modelling for Discrete and Mixed Data via Heat Equations on Structured Spaces</title><link>https://deep-diver.github.io/neurips2024/posters/waqdvck1fv/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/waqdvck1fv/</guid><description>Train discrete EBMs efficiently with Energy Discrepancy, a novel loss function that eliminates the need for Markov Chain Monte Carlo, using diffusion processes on structured spaces.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/waqdvck1fv/cover.png"/></item><item><title>Enhancing Diversity in Bayesian Deep Learning via Hyperspherical Energy Minimization of CKA</title><link>https://deep-diver.github.io/neurips2024/posters/s2ha6bz3le/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/s2ha6bz3le/</guid><description>Boosting Bayesian deep learning&amp;rsquo;s diversity and uncertainty quantification, this study proposes hyperspherical energy minimization of CKA to generate diverse and reliable neural network ensembles and &amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/s2ha6bz3le/cover.png"/></item><item><title>Enhancing Efficiency of Safe Reinforcement Learning via Sample Manipulation</title><link>https://deep-diver.github.io/neurips2024/posters/opfjhl6dpr/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/opfjhl6dpr/</guid><description>ESPO enhances safe RL efficiency by dynamically manipulating sample size based on reward-safety gradient conflicts, ensuring faster training and superior performance.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/opfjhl6dpr/cover.png"/></item><item><title>Enhancing Protein Mutation Effect Prediction through a Retrieval-Augmented Framework</title><link>https://deep-diver.github.io/neurips2024/posters/lgehswiwef/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/lgehswiwef/</guid><description>Revolutionizing protein mutation effect prediction, this work introduces a retrieval-augmented framework achieving state-of-the-art accuracy by efficiently incorporating similar local structure inform&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/lgehswiwef/cover.png"/></item><item><title>Enhancing Semi-Supervised Learning via Representative and Diverse Sample Selection</title><link>https://deep-diver.github.io/neurips2024/posters/xrdpcodghl/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/xrdpcodghl/</guid><description>RDSS: a novel sample selection method for semi-supervised learning, boosts model accuracy by minimizing a-MMD, striking a balance between sample representativeness and diversity.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/xrdpcodghl/cover.png"/></item><item><title>EnOF-SNN: Training Accurate Spiking Neural Networks via Enhancing the Output Feature</title><link>https://deep-diver.github.io/neurips2024/posters/spcewp6eyt/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/spcewp6eyt/</guid><description>EnOF-SNN boosts spiking neural network (SNN) accuracy by enhancing output feature representation using a novel knowledge distillation method and ReLU activation, outperforming current state-of-the-art&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/spcewp6eyt/cover.png"/></item><item><title>Ensemble sampling for linear bandits: small ensembles suffice</title><link>https://deep-diver.github.io/neurips2024/posters/so7fnifq0o/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/so7fnifq0o/</guid><description>Small ensembles in stochastic linear bandits achieve near-optimal regret; a rigorous analysis shows that ensemble size need only scale logarithmically with horizon.</description></item><item><title>Episodic Future Thinking Mechanism for Multi-agent Reinforcement Learning</title><link>https://deep-diver.github.io/neurips2024/posters/rl7otnsd9a/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/rl7otnsd9a/</guid><description>RL agents make better decisions by simulating future scenarios, considering diverse agent behaviors, and using character inference for improved decision-making.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/rl7otnsd9a/cover.png"/></item><item><title>Equivariant Machine Learning on Graphs with Nonlinear Spectral Filters</title><link>https://deep-diver.github.io/neurips2024/posters/y8p633e5hq/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/y8p633e5hq/</guid><description>Nonlinear spectral filters (NLSFs) enable fully equivariant graph neural networks, improving accuracy and generalization.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/y8p633e5hq/cover.png"/></item><item><title>Estimating Epistemic and Aleatoric Uncertainty with a Single Model</title><link>https://deep-diver.github.io/neurips2024/posters/wpxa6ocidg/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/wpxa6ocidg/</guid><description>HyperDM accurately estimates both epistemic and aleatoric uncertainty using a single model, overcoming the computational limitations of existing ensemble methods.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/wpxa6ocidg/cover.png"/></item><item><title>Evaluate then Cooperate: Shapley-based View Cooperation Enhancement for Multi-view Clustering</title><link>https://deep-diver.github.io/neurips2024/posters/xoc4qovbds/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/xoc4qovbds/</guid><description>Shapley-based Cooperation Enhancing Multi-view Clustering (SCE-MVC) improves deep multi-view clustering by using game theory to fairly evaluate and enhance individual view contributions.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/xoc4qovbds/cover.png"/></item><item><title>Even Sparser Graph Transformers</title><link>https://deep-diver.github.io/neurips2024/posters/k3k4bwunnk/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/k3k4bwunnk/</guid><description>Spexphormer achieves significant memory reduction in graph Transformers by leveraging a two-stage training process that leverages attention score consistency across network widths to effectively spars&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/k3k4bwunnk/cover.png"/></item><item><title>Evidential Mixture Machines: Deciphering Multi-Label Correlations for Active Learning Sensitivity</title><link>https://deep-diver.github.io/neurips2024/posters/n5llsskwtu/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/n5llsskwtu/</guid><description>Evidential Mixture Machines (EMM) enhances multi-label active learning by deciphering label correlations for improved accuracy and uncertainty quantification in large, sparse label spaces.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/n5llsskwtu/cover.png"/></item><item><title>Excluding the Irrelevant: Focusing Reinforcement Learning through Continuous Action Masking</title><link>https://deep-diver.github.io/neurips2024/posters/yvzwlfhprw/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/yvzwlfhprw/</guid><description>Boost RL efficiency in continuous action spaces by masking irrelevant actions using three novel continuous action masking methods!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/yvzwlfhprw/cover.png"/></item><item><title>Expected Probabilistic Hierarchies</title><link>https://deep-diver.github.io/neurips2024/posters/fmdrbucznj/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/fmdrbucznj/</guid><description>Expected Probabilistic Hierarchies (EPH) offers a novel, scalable approach to hierarchical clustering by optimizing expected scores under a probabilistic model, outperforming existing methods on vario&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/fmdrbucznj/cover.png"/></item><item><title>Exploiting Representation Curvature for Boundary Detection in Time Series</title><link>https://deep-diver.github.io/neurips2024/posters/wk2kxpamqv/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/wk2kxpamqv/</guid><description>RECURVE: A novel boundary detection method leveraging representation trajectory curvature, surpassing state-of-the-art techniques by accommodating both gradual and abrupt changes in time series.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/wk2kxpamqv/cover.png"/></item><item><title>Exploiting the Replay Memory Before Exploring the Environment: Enhancing Reinforcement Learning Through Empirical MDP Iteration</title><link>https://deep-diver.github.io/neurips2024/posters/lsd27juj8v/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/lsd27juj8v/</guid><description>Boost RL performance by solving a series of simplified MDPs before tackling the complex real-world one!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/lsd27juj8v/cover.png"/></item><item><title>Exploring the Precise Dynamics of Single-Layer GAN Models: Leveraging Multi-Feature Discriminators for High-Dimensional Subspace Learning</title><link>https://deep-diver.github.io/neurips2024/posters/sohfyffnxt/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/sohfyffnxt/</guid><description>Single-layer GANs learn data subspaces more effectively using multi-feature discriminators, enabling faster training and better feature representation than conventional methods.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/sohfyffnxt/cover.png"/></item><item><title>eXponential FAmily Dynamical Systems (XFADS): Large-scale nonlinear Gaussian state-space modeling</title><link>https://deep-diver.github.io/neurips2024/posters/ln8ogihz2s/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/ln8ogihz2s/</guid><description>XFADS: a novel low-rank structured VAE framework for large-scale nonlinear Gaussian state-space modeling, achieving high predictive accuracy and scalability.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/ln8ogihz2s/cover.png"/></item><item><title>FACT or Fiction: Can Truthful Mechanisms Eliminate Federated Free Riding?</title><link>https://deep-diver.github.io/neurips2024/posters/jirgxrqhh0/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/jirgxrqhh0/</guid><description>FACT, a novel federated learning mechanism, eliminates free-riding and incentivizes truthful agent behavior by introducing a penalty system and a competitive environment, boosting model performance si&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/jirgxrqhh0/cover.png"/></item><item><title>Fairness-Aware Meta-Learning via Nash Bargaining</title><link>https://deep-diver.github.io/neurips2024/posters/egjnb3tugv/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/egjnb3tugv/</guid><description>Nash bargaining resolves hypergradient conflicts in fairness-aware meta-learning, boosting model performance and fairness.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/egjnb3tugv/cover.png"/></item><item><title>FasMe: Fast and Sample-efficient Meta Estimator for Precision Matrix Learning in Small Sample Settings</title><link>https://deep-diver.github.io/neurips2024/posters/whfaah3e8z/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/whfaah3e8z/</guid><description>FasMe: a novel meta-learning approach delivers fast and sample-efficient precision matrix estimation, surpassing existing methods in accuracy and speed for small sample datasets.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/whfaah3e8z/cover.png"/></item><item><title>Fast TRAC: A Parameter-Free Optimizer for Lifelong Reinforcement Learning</title><link>https://deep-diver.github.io/neurips2024/posters/qeahe4tugc/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/qeahe4tugc/</guid><description>TRAC: a parameter-free optimizer conquering lifelong RL&amp;rsquo;s plasticity loss!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/qeahe4tugc/cover.png"/></item><item><title>Fast yet Safe: Early-Exiting with Risk Control</title><link>https://deep-diver.github.io/neurips2024/posters/bbfjpasrgs/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/bbfjpasrgs/</guid><description>Risk control boosts early-exit neural networks&amp;rsquo; speed and safety by ensuring accurate predictions before exiting early, achieving substantial computational savings across diverse tasks.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/bbfjpasrgs/cover.png"/></item><item><title>FedAvP: Augment Local Data via Shared Policy in Federated Learning</title><link>https://deep-diver.github.io/neurips2024/posters/m1pru0x1iz/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/m1pru0x1iz/</guid><description>FedAvP enhances federated learning&amp;rsquo;s privacy by sharing only augmentation policies, improving performance in diverse settings.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/m1pru0x1iz/cover.png"/></item><item><title>Federated Ensemble-Directed Offline Reinforcement Learning</title><link>https://deep-diver.github.io/neurips2024/posters/ypaqe8uwsc/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/ypaqe8uwsc/</guid><description>FEDORA, a novel algorithm, enables high-quality policy learning in federated offline reinforcement learning by leveraging the collective wisdom of diverse client datasets without data sharing.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/ypaqe8uwsc/cover.png"/></item><item><title>Federated Learning over Connected Modes</title><link>https://deep-diver.github.io/neurips2024/posters/jl2emcfdw8/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/jl2emcfdw8/</guid><description>Federated Learning over Connected Modes (FLOCO) accelerates global training and improves local accuracy in heterogeneous data settings by leveraging mode connectivity for collaborative model personali&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/jl2emcfdw8/cover.png"/></item><item><title>Federated Learning under Periodic Client Participation and Heterogeneous Data: A New Communication-Efficient Algorithm and Analysis</title><link>https://deep-diver.github.io/neurips2024/posters/wftavkl6g2/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/wftavkl6g2/</guid><description>Amplified SCAFFOLD: A new algorithm for federated learning significantly reduces communication rounds under periodic client participation and heterogeneous data, achieving linear speedup and resilienc&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/wftavkl6g2/cover.png"/></item><item><title>Federated Online Prediction from Experts with Differential Privacy: Separations and Regret Speed-ups</title><link>https://deep-diver.github.io/neurips2024/posters/t826pwzlci/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/t826pwzlci/</guid><description>This paper presents novel algorithms achieving speed-ups in differentially private federated online prediction from experts, addressing both stochastic and oblivious adversaries, with rigorous theoret&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/t826pwzlci/cover.png"/></item><item><title>FedGMark: Certifiably Robust Watermarking for Federated Graph Learning</title><link>https://deep-diver.github.io/neurips2024/posters/xeviqpxtmu/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/xeviqpxtmu/</guid><description>FedGMark: the first certified robust watermarking method for protecting Federated Graph Learning models against theft and unauthorized copying.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/xeviqpxtmu/cover.png"/></item><item><title>FedGTST: Boosting Global Transferability of Federated Models via Statistics Tuning</title><link>https://deep-diver.github.io/neurips2024/posters/qxkfc7d6p4/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/qxkfc7d6p4/</guid><description>FedGTST significantly improves federated transfer learning by tuning cross-client statistics, achieving superior global transferability with minimal communication overhead.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/qxkfc7d6p4/cover.png"/></item><item><title>FedNE: Surrogate-Assisted Federated Neighbor Embedding for Dimensionality Reduction</title><link>https://deep-diver.github.io/neurips2024/posters/zbmkodngkx/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/zbmkodngkx/</guid><description>FEDNE: a novel approach enabling collaborative dimensionality reduction of distributed data in federated learning without data sharing, achieved via surrogate loss functions and data augmentation.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/zbmkodngkx/cover.png"/></item><item><title>Ferrari: Federated Feature Unlearning via Optimizing Feature Sensitivity</title><link>https://deep-diver.github.io/neurips2024/posters/yxyytcv3hp/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/yxyytcv3hp/</guid><description>Ferrari, a novel federated feature unlearning framework, minimizes feature sensitivity via Lipschitz continuity, enabling effective and privacy-preserving data removal without full client participatio&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/yxyytcv3hp/cover.png"/></item><item><title>Few-Shot Diffusion Models Escape the Curse of Dimensionality</title><link>https://deep-diver.github.io/neurips2024/posters/jrranaazm5/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/jrranaazm5/</guid><description>Few-shot diffusion models efficiently generate customized images; this paper provides the first theoretical explanation, proving improved approximation and optimization bounds, escaping the curse of d&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/jrranaazm5/cover.png"/></item><item><title>Few-Shot Task Learning through Inverse Generative Modeling</title><link>https://deep-diver.github.io/neurips2024/posters/atie6npr5a/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/atie6npr5a/</guid><description>Few-shot task learning through inverse generative modeling (FTL-IGM) enables AI agents to quickly master new tasks from minimal data by leveraging invertible generative models.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/atie6npr5a/cover.png"/></item><item><title>FIARSE: Model-Heterogeneous Federated Learning via Importance-Aware Submodel Extraction</title><link>https://deep-diver.github.io/neurips2024/posters/bmbteqrhdi/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/bmbteqrhdi/</guid><description>FIARSE dynamically optimizes submodels in federated learning based on parameter importance, improving efficiency and global model accuracy.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/bmbteqrhdi/cover.png"/></item><item><title>FilterNet: Harnessing Frequency Filters for Time Series Forecasting</title><link>https://deep-diver.github.io/neurips2024/posters/ugl2d9idad/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/ugl2d9idad/</guid><description>FilterNet: A novel deep learning architecture using learnable frequency filters for superior time series forecasting accuracy and efficiency.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/ugl2d9idad/cover.png"/></item><item><title>Fine-Grained Dynamic Framework for Bias-Variance Joint Optimization on Data Missing Not at Random</title><link>https://deep-diver.github.io/neurips2024/posters/gloe70tn8v/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/gloe70tn8v/</guid><description>A new fine-grained dynamic framework jointly optimizes bias and variance for accurate predictions from missing-not-at-random data, surpassing existing methods.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/gloe70tn8v/cover.png"/></item><item><title>Fine-Tuning is Fine, if Calibrated</title><link>https://deep-diver.github.io/neurips2024/posters/xrjxkbeetd/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/xrjxkbeetd/</guid><description>Fine-tuning pre-trained models often degrades performance on unseen classes. This work reveals that the problem stems from logit scale discrepancies, not feature loss, and shows that post-processing c&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/xrjxkbeetd/cover.png"/></item><item><title>Fine-Tuning Personalization in Federated Learning to Mitigate Adversarial Clients</title><link>https://deep-diver.github.io/neurips2024/posters/wblplszji5/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/wblplszji5/</guid><description>Fine-tune personalization in federated learning to beat adversarial clients; collaboration level depends on data heterogeneity and adversary fraction.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/wblplszji5/cover.png"/></item><item><title>Flexible mapping of abstract domains by grid cells via self-supervised extraction and projection of generalized velocity signals</title><link>https://deep-diver.github.io/neurips2024/posters/hocac3qit7/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/hocac3qit7/</guid><description>Brain&amp;rsquo;s flexible mapping of abstract domains is achieved via self-supervised extraction and projection of generalized velocity signals by grid cells, enabling efficient map generation.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/hocac3qit7/cover.png"/></item><item><title>Focus On What Matters: Separated Models For Visual-Based RL Generalization</title><link>https://deep-diver.github.io/neurips2024/posters/wz2kvvek44/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/wz2kvvek44/</guid><description>SMG (Separated Models for Generalization) enhances visual RL generalization by disentangling task-relevant and irrelevant visual features via cooperative reconstruction, achieving state-of-the-art per&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/wz2kvvek44/cover.png"/></item><item><title>Forgetting, Ignorance or Myopia: Revisiting Key Challenges in Online Continual Learning</title><link>https://deep-diver.github.io/neurips2024/posters/oparhdvqrd/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/oparhdvqrd/</guid><description>NsCE framework tackles key OCL challenges: model ignorance (learning effective features in limited time) and myopia (overly simplified features). NsCE integrates non-sparse maximum separation regulari&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/oparhdvqrd/cover.png"/></item><item><title>Foundations of Multivariate Distributional Reinforcement Learning</title><link>https://deep-diver.github.io/neurips2024/posters/aq3i5b6glg/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/aq3i5b6glg/</guid><description>First oracle-free, computationally tractable algorithms for provably convergent multivariate distributional RL are introduced, achieving convergence rates matching scalar settings and offering insight&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/aq3i5b6glg/cover.png"/></item><item><title>Frequency Adaptive Normalization For Non-stationary Time Series Forecasting</title><link>https://deep-diver.github.io/neurips2024/posters/t0axiflvdd/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/t0axiflvdd/</guid><description>Frequency Adaptive Normalization (FAN) significantly boosts non-stationary time series forecasting accuracy by using Fourier transforms to identify and model dynamic trends and seasonal patterns, achi&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/t0axiflvdd/cover.png"/></item><item><title>From Biased to Unbiased Dynamics: An Infinitesimal Generator Approach</title><link>https://deep-diver.github.io/neurips2024/posters/tgmwp9jjxl/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/tgmwp9jjxl/</guid><description>Learn unbiased molecular dynamics from limited biased data using a novel infinitesimal generator approach; accurately estimating eigenfunctions and eigenvalues even with suboptimal biasing.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/tgmwp9jjxl/cover.png"/></item><item><title>FUG: Feature-Universal Graph Contrastive Pre-training for Graphs with Diverse Node Features</title><link>https://deep-diver.github.io/neurips2024/posters/vuuosbrqaw/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/vuuosbrqaw/</guid><description>FUG: A new graph contrastive pre-training strategy solves GNN transferability issues across datasets with diverse node features, achieving comparable performance to retraining while significantly impr&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/vuuosbrqaw/cover.png"/></item><item><title>GACL: Exemplar-Free Generalized Analytic Continual Learning</title><link>https://deep-diver.github.io/neurips2024/posters/p6aj7bqylc/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/p6aj7bqylc/</guid><description>GACL: a novel exemplar-free technique for generalized analytic continual learning, achieves superior performance by analytically solving the weight-invariant property for handling real-world data.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/p6aj7bqylc/cover.png"/></item><item><title>Gated Inference Network: Inference and Learning State-Space Models</title><link>https://deep-diver.github.io/neurips2024/posters/z4duw3kzld/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/z4duw3kzld/</guid><description>GIN, a novel approximate Bayesian inference algorithm, efficiently handles nonlinear state-space models with high-dimensional, noisy observations by disentangling observation and dynamics. Achieving l&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/z4duw3kzld/cover.png"/></item><item><title>Gaussian Approximation and Multiplier Bootstrap for Polyak-Ruppert Averaged Linear Stochastic Approximation with Applications to TD Learning</title><link>https://deep-diver.github.io/neurips2024/posters/s0ci1asjl5/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/s0ci1asjl5/</guid><description>This paper delivers non-asymptotic accuracy bounds for confidence intervals in linear stochastic approximation, leveraging a novel multiplier bootstrap method.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/s0ci1asjl5/cover.png"/></item><item><title>Gene-Gene Relationship Modeling Based on Genetic Evidence for Single-Cell RNA-Seq Data Imputation</title><link>https://deep-diver.github.io/neurips2024/posters/gw0zng5jcg/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/gw0zng5jcg/</guid><description>Novel imputation method, scCR, leverages complete gene-gene relationships (associating &amp;amp; dissociating) for superior single-cell RNA sequencing data recovery, significantly outperforming current state-&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/gw0zng5jcg/cover.png"/></item><item><title>Generalized Fast Exact Conformalization</title><link>https://deep-diver.github.io/neurips2024/posters/knzyj5zqsg/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/knzyj5zqsg/</guid><description>This paper presents a novel method for fast and exact conformalization, leveraging inherent piecewise smoothness to dramatically accelerate uncertainty quantification in machine learning models.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/knzyj5zqsg/cover.png"/></item><item><title>Generate Universal Adversarial Perturbations for Few-Shot Learning</title><link>https://deep-diver.github.io/neurips2024/posters/qlro8o4bol/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/qlro8o4bol/</guid><description>Researchers developed FSAFW, a novel framework generating universal adversarial perturbations effective against various Few-Shot Learning paradigms, surpassing baseline methods by over 16%.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/qlro8o4bol/cover.png"/></item><item><title>Generative Forests</title><link>https://deep-diver.github.io/neurips2024/posters/crlqhncjwt/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/crlqhncjwt/</guid><description>Generative Forests (GFs) revolutionize tabular data generation with a novel forest-based model and a simple boosting algorithm offering strong convergence guarantees, significantly outperforming curre&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/crlqhncjwt/cover.png"/></item><item><title>Generative Modeling of Molecular Dynamics Trajectories</title><link>https://deep-diver.github.io/neurips2024/posters/yrrch1osgw/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/yrrch1osgw/</guid><description>MDGEN: Generative modeling unlocks MD data for diverse tasks, achieving significant speedups via flexible multi-task surrogate models.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/yrrch1osgw/cover.png"/></item><item><title>Generative Semi-supervised Graph Anomaly Detection</title><link>https://deep-diver.github.io/neurips2024/posters/zqlamwvlkt/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/zqlamwvlkt/</guid><description>GGAD: Generative Semi-supervised Graph Anomaly Detection significantly outperforms existing methods by using a novel approach to generate pseudo-anomaly nodes for training, leveraging asymmetric local&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/zqlamwvlkt/cover.png"/></item><item><title>GENOT: Entropic (Gromov) Wasserstein Flow Matching with Applications to Single-Cell Genomics</title><link>https://deep-diver.github.io/neurips2024/posters/hjspwd7jvg/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/hjspwd7jvg/</guid><description>GENOT: a flexible neural optimal transport framework for single-cell genomics, enabling stochastic map learning with any cost function, handling unbalanced data, and tackling complex (Fused) Gromov-Wa&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/hjspwd7jvg/cover.png"/></item><item><title>Geometry-aware training of factorized layers in tensor Tucker format</title><link>https://deep-diver.github.io/neurips2024/posters/abtcfcrjm3/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/abtcfcrjm3/</guid><description>Train factorized neural network layers efficiently with Geometry-aware training in Tucker format (TDLRT)!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/abtcfcrjm3/cover.png"/></item><item><title>Goal-Conditioned On-Policy Reinforcement Learning</title><link>https://deep-diver.github.io/neurips2024/posters/kp7euorjyi/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/kp7euorjyi/</guid><description>GCPO: a novel on-policy goal-conditioned reinforcement learning framework tackles limitations of existing HER-based methods by effectively addressing multi-goal Markovian and non-Markovian reward prob&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/kp7euorjyi/cover.png"/></item><item><title>Going Beyond Heuristics by Imposing Policy Improvement as a Constraint</title><link>https://deep-diver.github.io/neurips2024/posters/vbgmbfgvsx/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/vbgmbfgvsx/</guid><description>HEPO, a novel constrained optimization method, consistently surpasses heuristic-trained policies in reinforcement learning by ensuring policy improvement over heuristics, regardless of heuristic quali&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/vbgmbfgvsx/cover.png"/></item><item><title>Gradient Rewiring for Editable Graph Neural Network Training</title><link>https://deep-diver.github.io/neurips2024/posters/xy2qrq7cxm/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/xy2qrq7cxm/</guid><description>Gradient Rewiring (GRE) improves editable GNN training by addressing gradient inconsistencies, preserving training node performance while correcting target node errors.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/xy2qrq7cxm/cover.png"/></item><item><title>Graph Coarsening with Message-Passing Guarantees</title><link>https://deep-diver.github.io/neurips2024/posters/riotceonc8/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/riotceonc8/</guid><description>This paper introduces a new message-passing operation for coarsened graphs with theoretical guarantees, improving GNN efficiency and accuracy on large datasets.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/riotceonc8/cover.png"/></item><item><title>Graph Edit Distance with General Costs Using Neural Set Divergence</title><link>https://deep-diver.github.io/neurips2024/posters/u7jrmrgutt/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/u7jrmrgutt/</guid><description>GRAPHEDX, a novel neural network, accurately estimates graph edit distance with varying operation costs, outperforming existing methods.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/u7jrmrgutt/cover.png"/></item><item><title>Graph Neural Flows for Unveiling Systemic Interactions Among Irregularly Sampled Time Series</title><link>https://deep-diver.github.io/neurips2024/posters/tfb5ssabvb/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/tfb5ssabvb/</guid><description>GNeuralFlow unveils systemic interactions in irregularly sampled time series by learning a directed acyclic graph representing conditional dependencies, achieving superior performance in classificatio&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/tfb5ssabvb/cover.png"/></item><item><title>Graph Neural Networks Do Not Always Oversmooth</title><link>https://deep-diver.github.io/neurips2024/posters/ny7fgtsspu/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/ny7fgtsspu/</guid><description>Deep graph neural networks often suffer from oversmoothing; this paper reveals a non-oversmoothing phase controllable by weight variance, enabling deep, expressive models.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/ny7fgtsspu/cover.png"/></item><item><title>Graph Neural Networks Need Cluster-Normalize-Activate Modules</title><link>https://deep-diver.github.io/neurips2024/posters/faj2ebhdhc/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/faj2ebhdhc/</guid><description>Boost GNN performance and overcome oversmoothing with Cluster-Normalize-Activate (CNA) modules: a simple yet highly effective plug-and-play solution!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/faj2ebhdhc/cover.png"/></item><item><title>GraphCroc: Cross-Correlation Autoencoder for Graph Structural Reconstruction</title><link>https://deep-diver.github.io/neurips2024/posters/zn6s6vqyb0/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/zn6s6vqyb0/</guid><description>GraphCroc, a novel graph autoencoder, leverages cross-correlation to accurately reconstruct complex graph structures, outperforming self-correlation-based methods.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/zn6s6vqyb0/cover.png"/></item><item><title>GraphMETRO: Mitigating Complex Graph Distribution Shifts via Mixture of Aligned Experts</title><link>https://deep-diver.github.io/neurips2024/posters/qtyg4g3deu/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/qtyg4g3deu/</guid><description>GraphMETRO tackles complex graph distribution shifts by using a Mixture-of-Experts model to decompose shifts into interpretable components, achieving state-of-the-art results.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/qtyg4g3deu/cover.png"/></item><item><title>Grounded Answers for Multi-agent Decision-making Problem through Generative World Model</title><link>https://deep-diver.github.io/neurips2024/posters/qwslks8lco/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/qwslks8lco/</guid><description>Generative world models enhance multi-agent decision-making by simulating trial-and-error learning, improving answer accuracy and explainability.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/qwslks8lco/cover.png"/></item><item><title>GTA: Generative Trajectory Augmentation with Guidance for Offline Reinforcement Learning</title><link>https://deep-diver.github.io/neurips2024/posters/kzpndbzrzy/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/kzpndbzrzy/</guid><description>Generative Trajectory Augmentation (GTA) significantly boosts offline reinforcement learning by generating high-reward trajectories using a conditional diffusion model, enhancing algorithm performance&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/kzpndbzrzy/cover.png"/></item><item><title>GUIDE: Real-Time Human-Shaped Agents</title><link>https://deep-diver.github.io/neurips2024/posters/krhficmpjm/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/krhficmpjm/</guid><description>GUIDE: Real-time human-shaped AI agents achieve up to 30% higher success rates using continuous human feedback, boosted by a parallel training model that mimics human input for continued improvement.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/krhficmpjm/cover.png"/></item><item><title>Guided Trajectory Generation with Diffusion Models for Offline Model-based Optimization</title><link>https://deep-diver.github.io/neurips2024/posters/iokqzb8smr/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/iokqzb8smr/</guid><description>GTG, a novel conditional generative modeling approach, leverages diffusion models to generate high-scoring design trajectories for offline model-based optimization, outperforming existing methods on b&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/iokqzb8smr/cover.png"/></item><item><title>Guiding Neural Collapse: Optimising Towards the Nearest Simplex Equiangular Tight Frame</title><link>https://deep-diver.github.io/neurips2024/posters/z4fapuslma/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/z4fapuslma/</guid><description>Researchers devised a novel method to accelerate neural network training by guiding the optimization process toward a Simplex Equiangular Tight Frame, exploiting the Neural Collapse phenomenon to enha&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/z4fapuslma/cover.png"/></item><item><title>Hamiltonian Monte Carlo Inference of Marginalized Linear Mixed-Effects Models</title><link>https://deep-diver.github.io/neurips2024/posters/uxuobobjho/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/uxuobobjho/</guid><description>Accelerate Bayesian inference in linear mixed-effects models by efficiently marginalizing random effects using fast linear algebra, enabling faster and more accurate posterior estimations.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/uxuobobjho/cover.png"/></item><item><title>Hamiltonian Monte Carlo on ReLU Neural Networks is Inefficient</title><link>https://deep-diver.github.io/neurips2024/posters/abmiyi7ia7/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/abmiyi7ia7/</guid><description>Hamiltonian Monte Carlo struggles with ReLU neural networks: high rejection rates hinder Bayesian deep learning.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/abmiyi7ia7/cover.png"/></item><item><title>Hamiltonian Score Matching and Generative Flows</title><link>https://deep-diver.github.io/neurips2024/posters/jjgfcvjptv/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/jjgfcvjptv/</guid><description>Hamiltonian Generative Flows (HGFs) revolutionize generative modeling by leveraging Hamiltonian dynamics, offering enhanced score matching and generative capabilities.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/jjgfcvjptv/cover.png"/></item><item><title>HC-GAE: The Hierarchical Cluster-based Graph Auto-Encoder for Graph Representation Learning</title><link>https://deep-diver.github.io/neurips2024/posters/fx6asbmu6z/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/fx6asbmu6z/</guid><description>HC-GAE: A novel hierarchical graph autoencoder combats over-smoothing by using hard node assignment to create isolated subgraphs, improving graph representation learning for classification.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/fx6asbmu6z/cover.png"/></item><item><title>HEPrune: Fast Private Training of Deep Neural Networks With Encrypted Data Pruning</title><link>https://deep-diver.github.io/neurips2024/posters/y2famldtif/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/y2famldtif/</guid><description>HEPrune accelerates private deep learning training 16x by integrating encrypted data pruning, achieving this speedup with minimal accuracy loss.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/y2famldtif/cover.png"/></item><item><title>HGDL: Heterogeneous Graph Label Distribution Learning</title><link>https://deep-diver.github.io/neurips2024/posters/owguhiah8r/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/owguhiah8r/</guid><description>HGDL: Heterogeneous Graph Label Distribution Learning, a new framework that leverages graph topology and content to enhance label distribution prediction.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/owguhiah8r/cover.png"/></item><item><title>HHD-GP: Incorporating Helmholtz-Hodge Decomposition into Gaussian Processes for Learning Dynamical Systems</title><link>https://deep-diver.github.io/neurips2024/posters/t9pfjvimij/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/t9pfjvimij/</guid><description>HHD-GP leverages Helmholtz-Hodge decomposition within Gaussian Processes to learn physically meaningful components of dynamical systems, enhancing prediction accuracy and interpretability.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/t9pfjvimij/cover.png"/></item><item><title>Hierarchical Federated Learning with Multi-Timescale Gradient Correction</title><link>https://deep-diver.github.io/neurips2024/posters/acab1qnxi0/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/acab1qnxi0/</guid><description>MTGC tackles multi-timescale model drift in hierarchical federated learning.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/acab1qnxi0/cover.png"/></item><item><title>Hierarchical Hybrid Sliced Wasserstein: A Scalable Metric for Heterogeneous Joint Distributions</title><link>https://deep-diver.github.io/neurips2024/posters/xwrmd1njqq/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/xwrmd1njqq/</guid><description>Hierarchical Hybrid Sliced Wasserstein (H2SW) solves the challenge of comparing complex, heterogeneous joint distributions by introducing novel slicing operators, leading to a scalable and statistical&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/xwrmd1njqq/cover.png"/></item><item><title>How does Inverse RL Scale to Large State Spaces? A Provably Efficient Approach</title><link>https://deep-diver.github.io/neurips2024/posters/zjgcymkcmx/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/zjgcymkcmx/</guid><description>CATY-IRL: A novel, provably efficient algorithm solves Inverse Reinforcement Learning&amp;rsquo;s scalability issues for large state spaces, improving upon state-of-the-art methods.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/zjgcymkcmx/cover.png"/></item><item><title>How Does Message Passing Improve Collaborative Filtering?</title><link>https://deep-diver.github.io/neurips2024/posters/c78u5zi4ea/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/c78u5zi4ea/</guid><description>TAG-CF boosts collaborative filtering accuracy by up to 39.2% on cold users, using only a single message-passing step at test time, avoiding costly training-time computations.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/c78u5zi4ea/cover.png"/></item><item><title>How to Solve Contextual Goal-Oriented Problems with Offline Datasets?</title><link>https://deep-diver.github.io/neurips2024/posters/ku31arq3sw/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/ku31arq3sw/</guid><description>CODA: A novel method for solving contextual goal-oriented problems with offline datasets, using unlabeled trajectories and context-goal pairs to create a fully labeled dataset, outperforming other bas&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/ku31arq3sw/cover.png"/></item><item><title>Hybrid Reinforcement Learning Breaks Sample Size Barriers In Linear MDPs</title><link>https://deep-diver.github.io/neurips2024/posters/bpuyxfbhyi/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/bpuyxfbhyi/</guid><description>Hybrid RL algorithms achieve sharper error/regret bounds than existing offline/online RL methods in linear MDPs, improving sample efficiency without stringent assumptions on behavior policy quality.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/bpuyxfbhyi/cover.png"/></item><item><title>Hyper-opinion Evidential Deep Learning for Out-of-Distribution Detection</title><link>https://deep-diver.github.io/neurips2024/posters/te8vi2wgth/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/te8vi2wgth/</guid><description>Hyper-opinion Evidential Deep Learning (HEDL) enhances out-of-distribution detection by integrating sharp and vague evidence for superior uncertainty estimation and classification accuracy.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/te8vi2wgth/cover.png"/></item><item><title>Hyperbolic Embeddings of Supervised Models</title><link>https://deep-diver.github.io/neurips2024/posters/n60xbfzwrk/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/n60xbfzwrk/</guid><description>This paper presents a novel approach for embedding supervised models in hyperbolic space, linking loss functions to hyperbolic distances and introducing monotonic decision trees for unambiguous visual&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/n60xbfzwrk/cover.png"/></item><item><title>HyperLogic: Enhancing Diversity and Accuracy in Rule Learning with HyperNets</title><link>https://deep-diver.github.io/neurips2024/posters/gjbzykgfd6/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/gjbzykgfd6/</guid><description>HyperLogic uses hypernetworks to generate diverse, accurate, and concise rule sets from neural networks, enhancing both interpretability and accuracy in rule learning.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/gjbzykgfd6/cover.png"/></item><item><title>Identifiable Object-Centric Representation Learning via Probabilistic Slot Attention</title><link>https://deep-diver.github.io/neurips2024/posters/qmovqbwmcy/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/qmovqbwmcy/</guid><description>Probabilistic Slot Attention achieves identifiable object-centric representations without supervision, advancing systematic generalization in machine learning.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/qmovqbwmcy/cover.png"/></item><item><title>Identify Then Recommend: Towards Unsupervised Group Recommendation</title><link>https://deep-diver.github.io/neurips2024/posters/otzyhoamhx/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/otzyhoamhx/</guid><description>Unsupervised group recommendation model, ITR, achieves superior user and group recommendation accuracy by dynamically identifying user groups and employing self-supervised learning, eliminating the ne&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/otzyhoamhx/cover.png"/></item><item><title>Identifying Latent State-Transition Processes for Individualized Reinforcement Learning</title><link>https://deep-diver.github.io/neurips2024/posters/krepcqthdn/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/krepcqthdn/</guid><description>This study introduces a novel framework for individualized reinforcement learning, guaranteeing the identifiability of latent factors influencing state transitions and providing a practical method for&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/krepcqthdn/cover.png"/></item><item><title>Implicitly Guided Design with PropEn: Match your Data to Follow the Gradient</title><link>https://deep-diver.github.io/neurips2024/posters/dhfho90ink/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/dhfho90ink/</guid><description>PropEn: a novel framework for implicitly guided design optimization that leverages &amp;lsquo;matching&amp;rsquo; to boost efficiency by matching samples and approximating the gradient without a discriminator.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/dhfho90ink/cover.png"/></item><item><title>Improved Bayes Regret Bounds for Multi-Task Hierarchical Bayesian Bandit Algorithms</title><link>https://deep-diver.github.io/neurips2024/posters/jonpmczvii/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/jonpmczvii/</guid><description>This paper significantly improves Bayes regret bounds for hierarchical Bayesian bandit algorithms, achieving logarithmic regret in finite action settings and enhanced bounds in multi-task linear and c&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/jonpmczvii/cover.png"/></item><item><title>Improved off-policy training of diffusion samplers</title><link>https://deep-diver.github.io/neurips2024/posters/vieiamy2gi/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/vieiamy2gi/</guid><description>Researchers enhanced diffusion samplers by developing a novel exploration strategy and a unified library, improving sample quality and addressing reproducibility challenges.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/vieiamy2gi/cover.png"/></item><item><title>Improved Sample Complexity Bounds for Diffusion Model Training</title><link>https://deep-diver.github.io/neurips2024/posters/oxcqkyoy8q/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/oxcqkyoy8q/</guid><description>Training high-quality diffusion models efficiently is now possible, thanks to novel sample complexity bounds improving exponentially on previous work.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/oxcqkyoy8q/cover.png"/></item><item><title>Improved Sample Complexity for Multiclass PAC Learning</title><link>https://deep-diver.github.io/neurips2024/posters/l2yvtrz3on/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/l2yvtrz3on/</guid><description>This paper significantly improves our understanding of multiclass PAC learning by reducing the sample complexity gap and proposing two novel approaches to fully resolve the optimal sample complexity.</description></item><item><title>Improving Deep Learning Optimization through Constrained Parameter Regularization</title><link>https://deep-diver.github.io/neurips2024/posters/rcxtkihkbf/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/rcxtkihkbf/</guid><description>Constrained Parameter Regularization (CPR) outperforms traditional weight decay by dynamically adapting regularization strengths for individual parameters, leading to better deep learning model perfor&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/rcxtkihkbf/cover.png"/></item><item><title>Improving Deep Reinforcement Learning by Reducing the Chain Effect of Value and Policy Churn</title><link>https://deep-diver.github.io/neurips2024/posters/cqoagpbarc/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/cqoagpbarc/</guid><description>Deep RL agents often suffer from instability due to the &amp;lsquo;chain effect&amp;rsquo; of value and policy churn; this paper introduces CHAIN, a novel method to reduce this churn, thereby improving DRL performance an&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/cqoagpbarc/cover.png"/></item><item><title>Improving Equivariant Model Training via Constraint Relaxation</title><link>https://deep-diver.github.io/neurips2024/posters/twkl7k1u5v/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/twkl7k1u5v/</guid><description>Boost equivariant model training by strategically relaxing constraints during training, enhancing optimization and generalization!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/twkl7k1u5v/cover.png"/></item><item><title>Improving Generalization and Convergence by Enhancing Implicit Regularization</title><link>https://deep-diver.github.io/neurips2024/posters/cjm2bhloic/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/cjm2bhloic/</guid><description>IRE framework expedites the discovery of flat minima in deep learning, enhancing generalization and convergence. By decoupling the dynamics of flat and sharp directions, IRE boosts sharpness reduction&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/cjm2bhloic/cover.png"/></item><item><title>Improving self-training under distribution shifts via anchored confidence with theoretical guarantees</title><link>https://deep-diver.github.io/neurips2024/posters/a17bietkyi/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/a17bietkyi/</guid><description>Anchored Confidence (AnCon) significantly improves self-training under distribution shifts by using a temporal ensemble to smooth noisy pseudo-labels, achieving 8-16% performance gains without computa&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/a17bietkyi/cover.png"/></item><item><title>In-Trajectory Inverse Reinforcement Learning: Learn Incrementally From An Ongoing Trajectory</title><link>https://deep-diver.github.io/neurips2024/posters/mjzh9w8qgu/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/mjzh9w8qgu/</guid><description>MERIT-IRL: First in-trajectory IRL framework learns reward &amp;amp; policy incrementally from ongoing trajectories, guaranteeing sub-linear regret.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/mjzh9w8qgu/cover.png"/></item><item><title>Incremental Learning of Retrievable Skills For Efficient Continual Task Adaptation</title><link>https://deep-diver.github.io/neurips2024/posters/rcpajanpnm/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/rcpajanpnm/</guid><description>IsCiL: a novel adapter-based continual imitation learning framework that efficiently adapts to new tasks by incrementally learning and retrieving reusable skills.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/rcpajanpnm/cover.png"/></item><item><title>Inference of Neural Dynamics Using Switching Recurrent Neural Networks</title><link>https://deep-diver.github.io/neurips2024/posters/zb8jlah2vn/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/zb8jlah2vn/</guid><description>SRNNs reveal behaviorally-relevant neural dynamics switches!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/zb8jlah2vn/cover.png"/></item><item><title>Infusing Self-Consistency into Density Functional Theory Hamiltonian Prediction via Deep Equilibrium Models</title><link>https://deep-diver.github.io/neurips2024/posters/psvkinbs4u/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/psvkinbs4u/</guid><description>Deep Equilibrium Models (DEQs) infused into DFT Hamiltonian prediction achieves self-consistency, accelerating large-scale materials simulations.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/psvkinbs4u/cover.png"/></item><item><title>Instructor-inspired Machine Learning for Robust Molecular Property Prediction</title><link>https://deep-diver.github.io/neurips2024/posters/j7sw0nxljz/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/j7sw0nxljz/</guid><description>InstructMol, a novel semi-supervised learning algorithm, leverages unlabeled data and an instructor model to significantly improve the accuracy and robustness of molecular property prediction, even wi&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/j7sw0nxljz/cover.png"/></item><item><title>Integrating GNN and Neural ODEs for Estimating Non-Reciprocal Two-Body Interactions in Mixed-Species Collective Motion</title><link>https://deep-diver.github.io/neurips2024/posters/qwl3eidi9r/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/qwl3eidi9r/</guid><description>Deep learning framework integrating GNNs and neural ODEs precisely estimates non-reciprocal two-body interactions in mixed-species collective motion, accurately replicating both individual and collect&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/qwl3eidi9r/cover.png"/></item><item><title>Interaction-Force Transport Gradient Flows</title><link>https://deep-diver.github.io/neurips2024/posters/rpgc5brxmt/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/rpgc5brxmt/</guid><description>New gradient flow geometry improves MMD-based sampling by teleporting particle mass, guaranteeing global exponential convergence, and yielding superior empirical results.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/rpgc5brxmt/cover.png"/></item><item><title>Interactive Deep Clustering via Value Mining</title><link>https://deep-diver.github.io/neurips2024/posters/y7hpb7pl1f/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/y7hpb7pl1f/</guid><description>Interactive Deep Clustering (IDC) significantly boosts deep clustering performance by strategically incorporating minimal user interaction to resolve ambiguous sample classifications.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/y7hpb7pl1f/cover.png"/></item><item><title>Interpretable Concept Bottlenecks to Align Reinforcement Learning Agents</title><link>https://deep-diver.github.io/neurips2024/posters/zc0psk6mc6/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/zc0psk6mc6/</guid><description>Successive Concept Bottleneck Agents (SCoBots) improve reinforcement learning by integrating interpretable layers, enabling concept-level inspection and human-in-the-loop revisions to fix misalignment&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/zc0psk6mc6/cover.png"/></item><item><title>Interpretable Generalized Additive Models for Datasets with Missing Values</title><link>https://deep-diver.github.io/neurips2024/posters/souxmwl5ak/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/souxmwl5ak/</guid><description>M-GAM: Interpretable additive models handling missing data with superior accuracy &amp;amp; sparsity!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/souxmwl5ak/cover.png"/></item><item><title>Interpretable Mesomorphic Networks for Tabular Data</title><link>https://deep-diver.github.io/neurips2024/posters/pmlty7todm/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/pmlty7todm/</guid><description>Interpretable Mesomorphic Neural Networks (IMNs) achieve accuracy comparable to black-box models while offering free-lunch explainability for tabular data through instance-specific linear models gener&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/pmlty7todm/cover.png"/></item><item><title>Introducing Spectral Attention for Long-Range Dependency in Time Series Forecasting</title><link>https://deep-diver.github.io/neurips2024/posters/dxynvebqmp/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/dxynvebqmp/</guid><description>Spectral Attention boosts long-range dependency capture in time series forecasting, achieving state-of-the-art results across various models and datasets.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/dxynvebqmp/cover.png"/></item><item><title>Inverse Factorized Soft Q-Learning for Cooperative Multi-agent Imitation Learning</title><link>https://deep-diver.github.io/neurips2024/posters/xrbgxjomjp/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/xrbgxjomjp/</guid><description>New multi-agent imitation learning algorithm (MIFQ) leverages inverse soft Q-learning and factorization for stable, efficient training, achieving state-of-the-art results on challenging benchmarks.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/xrbgxjomjp/cover.png"/></item><item><title>Inverse M-Kernels for Linear Universal Approximators of Non-Negative Functions</title><link>https://deep-diver.github.io/neurips2024/posters/hgss4ono4s/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/hgss4ono4s/</guid><description>Unlocking efficient non-negative function approximation: This paper introduces inverse M-kernels, enabling flexible, linear universal approximators for one-dimensional inputs.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/hgss4ono4s/cover.png"/></item><item><title>Is Mamba Compatible with Trajectory Optimization in Offline Reinforcement Learning?</title><link>https://deep-diver.github.io/neurips2024/posters/ywsxjlfsmx/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/ywsxjlfsmx/</guid><description>Decision Mamba (DeMa) outperforms Decision Transformer (DT) in offline RL trajectory optimization with 30% fewer parameters in Atari and a quarter in MuJoCo, demonstrating the efficacy of Mamba&amp;rsquo;s line&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/ywsxjlfsmx/cover.png"/></item><item><title>Is Value Learning Really the Main Bottleneck in Offline RL?</title><link>https://deep-diver.github.io/neurips2024/posters/nyp59a31ju/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/nyp59a31ju/</guid><description>Offline RL&amp;rsquo;s performance often lags behind imitation learning, but this paper reveals that policy learning and generalization, not value function learning, are often the main bottlenecks.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/nyp59a31ju/cover.png"/></item><item><title>Iteratively Refined Behavior Regularization for Offline Reinforcement Learning</title><link>https://deep-diver.github.io/neurips2024/posters/rbs7rwxw3r/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/rbs7rwxw3r/</guid><description>Iteratively Refined Behavior Regularization boosts offline reinforcement learning by iteratively refining the reference policy, ensuring robust and effective control policy learning.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/rbs7rwxw3r/cover.png"/></item><item><title>Iteratively Refined Early Interaction Alignment for Subgraph Matching based Graph Retrieval</title><link>https://deep-diver.github.io/neurips2024/posters/udtwwf7tks/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/udtwwf7tks/</guid><description>IsoNet++ iteratively refines subgraph matching via early interaction GNNs and node-pair partner interactions, significantly boosting graph retrieval accuracy.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/udtwwf7tks/cover.png"/></item><item><title>Kaleidoscope: Learnable Masks for Heterogeneous Multi-agent Reinforcement Learning</title><link>https://deep-diver.github.io/neurips2024/posters/w0wq9njghi/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/w0wq9njghi/</guid><description>Kaleidoscope: Learnable Masks for Heterogeneous MARL achieves high sample efficiency and policy diversity by using learnable masks for adaptive partial parameter sharing.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/w0wq9njghi/cover.png"/></item><item><title>KALM: Knowledgeable Agents by Offline Reinforcement Learning from Large Language Model Rollouts</title><link>https://deep-diver.github.io/neurips2024/posters/tb1mljcy5g/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/tb1mljcy5g/</guid><description>KALM: Knowledgeable agents learn complex tasks from LLMs via offline RL using imaginary rollouts, significantly outperforming baselines.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/tb1mljcy5g/cover.png"/></item><item><title>Kernel-Based Function Approximation for Average Reward Reinforcement Learning: An Optimist No-Regret Algorithm</title><link>https://deep-diver.github.io/neurips2024/posters/vwutz2pond/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/vwutz2pond/</guid><description>Novel optimistic RL algorithm using kernel methods achieves no-regret performance in the challenging infinite-horizon average-reward setting.</description></item><item><title>Large Pre-trained time series models for cross-domain Time series analysis tasks</title><link>https://deep-diver.github.io/neurips2024/posters/vmmzjcr5zj/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/vmmzjcr5zj/</guid><description>Large Pre-trained Time-series Models (LPTM) achieves superior forecasting and time-series classification results using a novel adaptive segmentation method, requiring up to 40% less data and 50% less &amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/vmmzjcr5zj/cover.png"/></item><item><title>Large Scale Transfer Learning for Tabular Data via Language Modeling</title><link>https://deep-diver.github.io/neurips2024/posters/wh5blx5tz1/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/wh5blx5tz1/</guid><description>TABULA-8B, a novel language model for tabular prediction, achieves state-of-the-art zero-shot and few-shot performance across various benchmarks, exceeding existing methods by 5-15 percentage points.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/wh5blx5tz1/cover.png"/></item><item><title>LaSCal: Label-Shift Calibration without target labels</title><link>https://deep-diver.github.io/neurips2024/posters/taljtwx7w4/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/taljtwx7w4/</guid><description>LaSCal, a novel label-free calibration method, ensures reliable model predictions under label shift by using a consistent calibration error estimator, achieving effective and robust unsupervised calib&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/taljtwx7w4/cover.png"/></item><item><title>Layer-Adaptive State Pruning for Deep State Space Models</title><link>https://deep-diver.github.io/neurips2024/posters/t9gbbwbnqg/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/t9gbbwbnqg/</guid><description>Layer-Adaptive STate pruning (LAST) optimizes deep state space models by efficiently reducing state dimensions, improving performance and scalability without retraining.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/t9gbbwbnqg/cover.png"/></item><item><title>Learning Distributions on Manifolds with Free-Form Flows</title><link>https://deep-diver.github.io/neurips2024/posters/qbphypzkji/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/qbphypzkji/</guid><description>Manifold Free-Form Flows (M-FFF) achieves fast and accurate generative modeling on Riemannian manifolds using a single function evaluation, outperforming prior methods.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/qbphypzkji/cover.png"/></item><item><title>Learning from higher-order correlations, efficiently: hypothesis tests, random features, and neural networks</title><link>https://deep-diver.github.io/neurips2024/posters/uhml6eyovf/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/uhml6eyovf/</guid><description>Neural networks learn efficiently from higher-order correlations, exceeding the capabilities of random features, as demonstrated through hypothesis tests and novel theoretical analysis in high-dimensi&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/uhml6eyovf/cover.png"/></item><item><title>Learning from Highly Sparse Spatio-temporal Data</title><link>https://deep-diver.github.io/neurips2024/posters/rtonicccjm/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/rtonicccjm/</guid><description>OPCR, a novel one-step spatio-temporal imputation method, surpasses existing iterative approaches by directly propagating limited observations to the global context, achieving superior accuracy and ef&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/rtonicccjm/cover.png"/></item><item><title>Learning Infinitesimal Generators of Continuous Symmetries from Data</title><link>https://deep-diver.github.io/neurips2024/posters/wl44w8xpc7/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/wl44w8xpc7/</guid><description>Learn continuous symmetries from data without pre-defined groups using Neural ODEs and a novel validity score to improve model generalization and efficiency.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/wl44w8xpc7/cover.png"/></item><item><title>Learning Macroscopic Dynamics from Partial Microscopic Observations</title><link>https://deep-diver.github.io/neurips2024/posters/cjh0qsgd0d/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/cjh0qsgd0d/</guid><description>Learn macroscopic dynamics efficiently using only partial microscopic force computations! This novel method leverages sparsity assumptions and stochastic estimation for accurate, cost-effective modeli&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/cjh0qsgd0d/cover.png"/></item><item><title>Learning Multimodal Behaviors from Scratch with Diffusion Policy Gradient</title><link>https://deep-diver.github.io/neurips2024/posters/vu1sibb57j/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/vu1sibb57j/</guid><description>DDiffPG: A novel actor-critic algorithm learns multimodal policies from scratch using diffusion models, enabling agents to master versatile behaviors in complex tasks.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/vu1sibb57j/cover.png"/></item><item><title>Learning on Large Graphs using Intersecting Communities</title><link>https://deep-diver.github.io/neurips2024/posters/pgr5x4e1gy/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/pgr5x4e1gy/</guid><description>Learn on massive graphs efficiently using Intersecting Community Graphs (ICGs)! This method approximates large graphs with ICGs, enabling linear time/memory complexity for node classification.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/pgr5x4e1gy/cover.png"/></item><item><title>Learning Successor Features the Simple Way</title><link>https://deep-diver.github.io/neurips2024/posters/ri7ozj1wmc/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/ri7ozj1wmc/</guid><description>Learn deep Successor Features (SFs) directly from pixels, efficiently and without representation collapse, using a novel, simple method combining TD and reward prediction loss!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/ri7ozj1wmc/cover.png"/></item><item><title>Learning the Latent Causal Structure for Modeling Label Noise</title><link>https://deep-diver.github.io/neurips2024/posters/njkfniebvq/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/njkfniebvq/</guid><description>Learning latent causal structures improves label noise modeling by accurately estimating noise transition matrices without relying on similarity-based assumptions, leading to state-of-the-art classifi&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/njkfniebvq/cover.png"/></item><item><title>Learning the Optimal Policy for Balancing Short-Term and Long-Term Rewards</title><link>https://deep-diver.github.io/neurips2024/posters/zgh0chwoco/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/zgh0chwoco/</guid><description>A novel Decomposition-based Policy Learning (DPPL) method optimally balances short-term and long-term rewards, even with interrelated objectives, by transforming the problem into intuitive subproblems&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/zgh0chwoco/cover.png"/></item><item><title>Learning to Balance Altruism and Self-interest Based on Empathy in Mixed-Motive Games</title><link>https://deep-diver.github.io/neurips2024/posters/ry0rxtjwjy/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/ry0rxtjwjy/</guid><description>AI agents learn to balance helpfulness and self-preservation using empathy to gauge social relationships and guide reward sharing.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/ry0rxtjwjy/cover.png"/></item><item><title>Learning World Models for Unconstrained Goal Navigation</title><link>https://deep-diver.github.io/neurips2024/posters/ayqtwcdlcg/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/ayqtwcdlcg/</guid><description>MUN: a novel goal-directed exploration algorithm significantly improves world model reliability and policy generalization in sparse-reward goal-conditioned RL, enabling efficient navigation across div&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/ayqtwcdlcg/cover.png"/></item><item><title>Leveraging Contrastive Learning for Enhanced Node Representations in Tokenized Graph Transformers</title><link>https://deep-diver.github.io/neurips2024/posters/u6fuikzt1k/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/u6fuikzt1k/</guid><description>GCFormer, a novel graph Transformer, enhances node representation learning by employing a hybrid token generator and contrastive learning, outperforming existing methods on various datasets.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/u6fuikzt1k/cover.png"/></item><item><title>Leveraging Drift to Improve Sample Complexity of Variance Exploding Diffusion Models</title><link>https://deep-diver.github.io/neurips2024/posters/euq0c4is7o/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/euq0c4is7o/</guid><description>Drifted VESDE: Faster convergence, efficient sampling for variance-exploding diffusion models!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/euq0c4is7o/cover.png"/></item><item><title>Leveraging partial stragglers within gradient coding</title><link>https://deep-diver.github.io/neurips2024/posters/qc4e0voanp/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/qc4e0voanp/</guid><description>New gradient coding protocols efficiently leverage partial results from slow worker nodes, accelerating distributed training by approximately 2x and significantly improving accuracy.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/qc4e0voanp/cover.png"/></item><item><title>Leveraging Separated World Model for Exploration in Visually Distracted Environments</title><link>https://deep-diver.github.io/neurips2024/posters/osh7u2e1kc/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/osh7u2e1kc/</guid><description>SeeX, a novel bi-level optimization framework, effectively tackles the challenge of exploration in visually cluttered environments by training a separated world model to extract relevant information a&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/osh7u2e1kc/cover.png"/></item><item><title>LFME: A Simple Framework for Learning from Multiple Experts in Domain Generalization</title><link>https://deep-diver.github.io/neurips2024/posters/syjxhkcxon/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/syjxhkcxon/</guid><description>LFME: A novel framework improves domain generalization by training multiple expert models alongside a target model, using logit regularization for enhanced performance.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/syjxhkcxon/cover.png"/></item><item><title>Light Unbalanced Optimal Transport</title><link>https://deep-diver.github.io/neurips2024/posters/co8kzws1yk/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/co8kzws1yk/</guid><description>LightUnbalancedOptimalTransport: A fast, theoretically-justified solver for continuous unbalanced optimal transport problems, enabling efficient analysis of large datasets with imbalanced classes.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/co8kzws1yk/cover.png"/></item><item><title>Linear Transformers are Versatile In-Context Learners</title><link>https://deep-diver.github.io/neurips2024/posters/p1ft33mu3j/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/p1ft33mu3j/</guid><description>Linear transformers surprisingly learn intricate optimization algorithms, even surpassing baselines on noisy regression problems, showcasing their unexpected learning capabilities.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/p1ft33mu3j/cover.png"/></item><item><title>Linear Uncertainty Quantification of Graphical Model Inference</title><link>https://deep-diver.github.io/neurips2024/posters/xovks7jhqa/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/xovks7jhqa/</guid><description>LinUProp: Linearly scalable uncertainty quantification for graphical models, achieving higher accuracy with lower labeling budgets!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/xovks7jhqa/cover.png"/></item><item><title>LLM-AutoDA: Large Language Model-Driven Automatic Data Augmentation for Long-tailed Problems</title><link>https://deep-diver.github.io/neurips2024/posters/vpuouzovhp/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/vpuouzovhp/</guid><description>LLM-AutoDA: Automating data augmentation for long-tailed learning using large language models, significantly boosting model performance.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/vpuouzovhp/cover.png"/></item><item><title>Local Anti-Concentration Class: Logarithmic Regret for Greedy Linear Contextual Bandit</title><link>https://deep-diver.github.io/neurips2024/posters/rblaf2euxq/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/rblaf2euxq/</guid><description>Greedy algorithms for linear contextual bandits achieve poly-logarithmic regret under the novel Local Anti-Concentration condition, expanding applicable distributions beyond Gaussians and uniforms.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/rblaf2euxq/cover.png"/></item><item><title>Local Curvature Smoothing with Stein's Identity for Efficient Score Matching</title><link>https://deep-diver.github.io/neurips2024/posters/yppni7vc7n/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/yppni7vc7n/</guid><description>LCSS, a novel score-matching method, enables efficient and high-quality image generation in score-based diffusion models by using Stein&amp;rsquo;s identity to bypass the computationally expensive Jacobian trac&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/yppni7vc7n/cover.png"/></item><item><title>Local Linearity: the Key for No-regret Reinforcement Learning in Continuous MDPs</title><link>https://deep-diver.github.io/neurips2024/posters/qemszoq45m/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/qemszoq45m/</guid><description>CINDERELLA: a new algorithm achieves state-of-the-art no-regret bounds for continuous RL problems by exploiting local linearity.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/qemszoq45m/cover.png"/></item><item><title>Localizing Memorization in SSL Vision Encoders</title><link>https://deep-diver.github.io/neurips2024/posters/r46hglijcg/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/r46hglijcg/</guid><description>SSL vision encoders, while trained on massive datasets, surprisingly memorize individual data points. This paper introduces novel methods to precisely pinpoint this memorization within encoders at bot&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/r46hglijcg/cover.png"/></item><item><title>Long-range Meta-path Search on Large-scale Heterogeneous Graphs</title><link>https://deep-diver.github.io/neurips2024/posters/hbowltjnmk/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/hbowltjnmk/</guid><description>LMSPS: a novel framework efficiently leverages long-range dependencies in large heterogeneous graphs by dynamically identifying effective meta-paths, mitigating computational costs and over-smoothing.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/hbowltjnmk/cover.png"/></item><item><title>Lorentz-Equivariant Geometric Algebra Transformers for High-Energy Physics</title><link>https://deep-diver.github.io/neurips2024/posters/x34gkv8syt/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/x34gkv8syt/</guid><description>Lorentz Geometric Algebra Transformer (L-GATr): A novel, scalable architecture for high-energy physics, achieving high-precision, data-efficient learning and outperforming existing methods on regressi&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/x34gkv8syt/cover.png"/></item><item><title>Low Precision Local Training is Enough for Federated Learning</title><link>https://deep-diver.github.io/neurips2024/posters/vvpewjtnvm/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/vvpewjtnvm/</guid><description>Low-precision local training, surprisingly, is sufficient for accurate federated learning, significantly reducing communication and computation costs.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/vvpewjtnvm/cover.png"/></item><item><title>Low-Rank Optimal Transport through Factor Relaxation with Latent Coupling</title><link>https://deep-diver.github.io/neurips2024/posters/hggkdff2hr/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/hggkdff2hr/</guid><description>FRLC: a novel algorithm for low-rank optimal transport using latent coupling, enabling faster computation and better interpretability for diverse applications.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/hggkdff2hr/cover.png"/></item><item><title>Lower Bounds of Uniform Stability in Gradient-Based Bilevel Algorithms for Hyperparameter Optimization</title><link>https://deep-diver.github.io/neurips2024/posters/u3mzzd0pdx/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/u3mzzd0pdx/</guid><description>This paper establishes tight lower bounds for the uniform stability of gradient-based bilevel programming algorithms used for hyperparameter optimization, resolving a key open problem regarding the ti&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/u3mzzd0pdx/cover.png"/></item><item><title>MADiff: Offline Multi-agent Learning with Diffusion Models</title><link>https://deep-diver.github.io/neurips2024/posters/pvoxbjcrpt/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/pvoxbjcrpt/</guid><description>MADIFF: Offline multi-agent learning uses attention-based diffusion models to achieve effective coordination and teammate modeling, outperforming existing methods.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/pvoxbjcrpt/cover.png"/></item><item><title>Maia-2: A Unified Model for Human-AI Alignment in Chess</title><link>https://deep-diver.github.io/neurips2024/posters/xwlkhrn14k/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/xwlkhrn14k/</guid><description>Maia-2: A unified model for human-AI alignment in chess, coherently captures human play across skill levels, significantly improving AI-human alignment and paving the way for AI-guided teaching.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/xwlkhrn14k/cover.png"/></item><item><title>Making Offline RL Online: Collaborative World Models for Offline Visual Reinforcement Learning</title><link>https://deep-diver.github.io/neurips2024/posters/ucxqrked0d/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/ucxqrked0d/</guid><description>CoWorld: a novel model-based RL approach tackles offline visual RL challenges by using online simulators as testbeds, enabling flexible value estimation &amp;amp; mitigating overestimation bias for effective &amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/ucxqrked0d/cover.png"/></item><item><title>Markovian Flow Matching: Accelerating MCMC with Continuous Normalizing Flows</title><link>https://deep-diver.github.io/neurips2024/posters/amjyuvqsaf/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/amjyuvqsaf/</guid><description>Adaptive MCMC with CNFs accelerates probabilistic inference by combining local and flow-informed transition kernels, achieving state-of-the-art results efficiently.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/amjyuvqsaf/cover.png"/></item><item><title>Measuring Mutual Policy Divergence for Multi-Agent Sequential Exploration</title><link>https://deep-diver.github.io/neurips2024/posters/xvyi7tciu6/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/xvyi7tciu6/</guid><description>MADPO, a novel MARL framework, uses mutual policy divergence maximization with conditional Cauchy-Schwarz divergence to enhance exploration and agent heterogeneity in sequential updating, outperformin&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/xvyi7tciu6/cover.png"/></item><item><title>Meta-Controller: Few-Shot Imitation of Unseen Embodiments and Tasks in Continuous Control</title><link>https://deep-diver.github.io/neurips2024/posters/m5d5rmwljj/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/m5d5rmwljj/</guid><description>Meta-Controller: A novel few-shot behavior cloning framework enables robots to generalize to unseen embodiments and tasks using only a few reward-free demonstrations, showcasing superior few-shot gene&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/m5d5rmwljj/cover.png"/></item><item><title>Meta-Reinforcement Learning with Universal Policy Adaptation: Provable Near-Optimality under All-task Optimum Comparator</title><link>https://deep-diver.github.io/neurips2024/posters/rpjh69dux2/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/rpjh69dux2/</guid><description>Provable near-optimality in meta-RL is achieved using a novel bilevel optimization framework and universal policy adaptation algorithm.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/rpjh69dux2/cover.png"/></item><item><title>MetaCURL: Non-stationary Concave Utility Reinforcement Learning</title><link>https://deep-diver.github.io/neurips2024/posters/ts09iypr3r/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/ts09iypr3r/</guid><description>MetaCURL: First algorithm for non-stationary Concave Utility Reinforcement Learning (CURL), achieving near-optimal dynamic regret by using a meta-algorithm and sleeping experts framework.</description></item><item><title>Mitigating Backdoor Attack by Injecting Proactive Defensive Backdoor</title><link>https://deep-diver.github.io/neurips2024/posters/cbkjbyikid/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/cbkjbyikid/</guid><description>Proactive Defensive Backdoor (PDB) thwarts malicious backdoors by injecting a hidden defensive backdoor during training, suppressing attacks while maintaining model utility.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/cbkjbyikid/cover.png"/></item><item><title>Mitigating Covariate Shift in Behavioral Cloning via Robust Stationary Distribution Correction</title><link>https://deep-diver.github.io/neurips2024/posters/lhcvjsqfqq/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/lhcvjsqfqq/</guid><description>DrilDICE robustly tackles covariate shift in offline imitation learning by using a stationary distribution correction and a distributionally robust objective, significantly improving performance.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/lhcvjsqfqq/cover.png"/></item><item><title>Mitigating Partial Observability in Decision Processes via the Lambda Discrepancy</title><link>https://deep-diver.github.io/neurips2024/posters/yaphvbgqwo/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/yaphvbgqwo/</guid><description>New metric, Œª-discrepancy, precisely detects &amp;amp; mitigates partial observability in sequential decision processes, significantly boosting reinforcement learning agent performance.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/yaphvbgqwo/cover.png"/></item><item><title>Mixture of Experts Meets Prompt-Based Continual Learning</title><link>https://deep-diver.github.io/neurips2024/posters/erwatqq4p8/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/erwatqq4p8/</guid><description>Non-linear Residual Gates (NoRGa) boosts prompt-based continual learning by theoretically framing prefix tuning as adding new experts to a pre-trained Mixture-of-Experts model, achieving state-of-the-&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/erwatqq4p8/cover.png"/></item><item><title>Mixture of Link Predictors on Graphs</title><link>https://deep-diver.github.io/neurips2024/posters/x3oeoyjlmw/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/x3oeoyjlmw/</guid><description>Link-MoE boosts link prediction accuracy by strategically selecting the best model for each node pair, surpassing single-model approaches.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/x3oeoyjlmw/cover.png"/></item><item><title>Model Based Inference of Synaptic Plasticity Rules</title><link>https://deep-diver.github.io/neurips2024/posters/ri80phlnfm/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/ri80phlnfm/</guid><description>New computational method infers complex brain learning rules from experimental data, revealing active forgetting in reward learning.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/ri80phlnfm/cover.png"/></item><item><title>Model LEGO: Creating Models Like Disassembling and Assembling Building Blocks</title><link>https://deep-diver.github.io/neurips2024/posters/nxl7eazkbi/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/nxl7eazkbi/</guid><description>Model LEGO (MDA) revolutionizes deep learning by enabling the creation of new models by assembling and disassembling task-aware components from pre-trained models, eliminating the need for retraining.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/nxl7eazkbi/cover.png"/></item><item><title>Modeling Latent Neural Dynamics with Gaussian Process Switching Linear Dynamical Systems</title><link>https://deep-diver.github.io/neurips2024/posters/lx1lwp90kt/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/lx1lwp90kt/</guid><description>gpSLDS, a novel model, balances expressiveness and interpretability in modeling complex neural dynamics by combining Gaussian processes with switching linear dynamical systems, improving accuracy and &amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/lx1lwp90kt/cover.png"/></item><item><title>Monomial Matrix Group Equivariant Neural Functional Networks</title><link>https://deep-diver.github.io/neurips2024/posters/rqyywgyuzk/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/rqyywgyuzk/</guid><description>Monomial-NFNs boost neural network efficiency by leveraging scaling/sign-flipping symmetries, resulting in fewer trainable parameters and competitive performance.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/rqyywgyuzk/cover.png"/></item><item><title>MOTE-NAS: Multi-Objective Training-based Estimate for Efficient Neural Architecture Search</title><link>https://deep-diver.github.io/neurips2024/posters/jklykezfzv/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/jklykezfzv/</guid><description>MOTE-NAS: A new multi-objective training-based estimate drastically improves neural architecture search efficiency, achieving state-of-the-art accuracy with significantly reduced costs.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/jklykezfzv/cover.png"/></item><item><title>Multi-Agent Domain Calibration with a Handful of Offline Data</title><link>https://deep-diver.github.io/neurips2024/posters/hkbhx5abjk/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/hkbhx5abjk/</guid><description>Madoc: A novel multi-agent framework calibrates RL policies for new environments using limited offline data, achieving superior performance in various locomotion tasks.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/hkbhx5abjk/cover.png"/></item><item><title>Multi-Label Learning with Stronger Consistency Guarantees</title><link>https://deep-diver.github.io/neurips2024/posters/zauerb1kgx/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/zauerb1kgx/</guid><description>Novel surrogate losses with label-independent H-consistency bounds enable stronger guarantees for multi-label learning.</description></item><item><title>Multi-Label Open Set Recognition</title><link>https://deep-diver.github.io/neurips2024/posters/k1vrxrs6wz/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/k1vrxrs6wz/</guid><description>SLAN: A novel approach for multi-label open-set recognition, enriching sub-labeling info using structural data to identify unknown labels.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/k1vrxrs6wz/cover.png"/></item><item><title>Multi-Reward Best Policy Identification</title><link>https://deep-diver.github.io/neurips2024/posters/x69o84df2g/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/x69o84df2g/</guid><description>This paper introduces efficient algorithms, MR-NaS and DBMR-BPI, for identifying optimal policies across multiple reward functions in reinforcement learning, achieving competitive performance with the&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/x69o84df2g/cover.png"/></item><item><title>Multi-Scale Representation Learning for Protein Fitness Prediction</title><link>https://deep-diver.github.io/neurips2024/posters/kwmvzidcen/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/kwmvzidcen/</guid><description>S3F: a novel multi-scale model achieves state-of-the-art protein fitness prediction by integrating protein sequence, structure, and surface features.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/kwmvzidcen/cover.png"/></item><item><title>Mutual Information Estimation via $f$-Divergence and Data Derangements</title><link>https://deep-diver.github.io/neurips2024/posters/pthi9hf9ut/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/pthi9hf9ut/</guid><description>f-DIME: a novel class of discriminative mutual information estimators using f-divergence outperforms state-of-the-art methods by achieving an excellent bias-variance trade-off. This is achieved throug&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/pthi9hf9ut/cover.png"/></item><item><title>Navigating Chemical Space with Latent Flows</title><link>https://deep-diver.github.io/neurips2024/posters/aaav4zbq9j/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/aaav4zbq9j/</guid><description>ChemFlow: a new framework efficiently explores chemical space using latent flows, unifying existing methods &amp;amp; incorporating physical priors for molecule manipulation and optimization.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/aaav4zbq9j/cover.png"/></item><item><title>Navigating the Effect of Parametrization for Dimensionality Reduction</title><link>https://deep-diver.github.io/neurips2024/posters/eynynyle41/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/eynynyle41/</guid><description>ParamRepulsor, a novel parametric dimensionality reduction method, achieves state-of-the-art local structure preservation by mining hard negatives and using a tailored loss function.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/eynynyle41/cover.png"/></item><item><title>Near-Minimax-Optimal Distributional Reinforcement Learning with a Generative Model</title><link>https://deep-diver.github.io/neurips2024/posters/jxkbf1d4ib/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/jxkbf1d4ib/</guid><description>New distributional RL algorithm (DCFP) achieves near-minimax optimality for return distribution estimation in the generative model regime.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/jxkbf1d4ib/cover.png"/></item><item><title>Near-Optimal Dynamic Regret for Adversarial Linear Mixture MDPs</title><link>https://deep-diver.github.io/neurips2024/posters/lpyprs2xcf/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/lpyprs2xcf/</guid><description>Near-optimal dynamic regret is achieved for adversarial linear mixture MDPs with unknown transitions, bridging occupancy-measure and policy-based methods for superior performance.</description></item><item><title>Near-Optimality of Contrastive Divergence Algorithms</title><link>https://deep-diver.github.io/neurips2024/posters/q74jvgkcp6/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/q74jvgkcp6/</guid><description>Contrastive Divergence algorithms achieve near-optimal parameter estimation rates, matching the Cram√©r-Rao lower bound under specific conditions, as proven by a novel non-asymptotic analysis.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/q74jvgkcp6/cover.png"/></item><item><title>Neural Collapse Inspired Feature Alignment for Out-of-Distribution Generalization</title><link>https://deep-diver.github.io/neurips2024/posters/wqpng9jnpk/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/wqpng9jnpk/</guid><description>Neural Collapse-inspired Feature Alignment (NCFAL) significantly boosts out-of-distribution generalization by aligning semantic features to a simplex ETF, even without environment labels.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/wqpng9jnpk/cover.png"/></item><item><title>Neural Collapse To Multiple Centers For Imbalanced Data</title><link>https://deep-diver.github.io/neurips2024/posters/rjec9fz9ma/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/rjec9fz9ma/</guid><description>Researchers enhance imbalanced data classification by inducing Neural Collapse to Multiple Centers (NCMC) using a novel cosine loss function, achieving performance comparable to state-of-the-art metho&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/rjec9fz9ma/cover.png"/></item><item><title>Neural Conditional Probability for Uncertainty Quantification</title><link>https://deep-diver.github.io/neurips2024/posters/zxfhhjnmb2/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/zxfhhjnmb2/</guid><description>Neural Conditional Probability (NCP) offers a new operator-theoretic approach for efficiently learning conditional distributions, enabling streamlined inference and providing theoretical guarantees fo&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/zxfhhjnmb2/cover.png"/></item><item><title>Neural decoding from stereotactic EEG: accounting for electrode variability across subjects</title><link>https://deep-diver.github.io/neurips2024/posters/lr1nnsd7h0/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/lr1nnsd7h0/</guid><description>Scalable SEEG decoding model, seegnificant, leverages transformers to decode behavior across subjects despite electrode variability, achieving high accuracy and transfer learning capability.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/lr1nnsd7h0/cover.png"/></item><item><title>Neural Flow Diffusion Models: Learnable Forward Process for Improved Diffusion Modelling</title><link>https://deep-diver.github.io/neurips2024/posters/z0wibvtbxc/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/z0wibvtbxc/</guid><description>Neural Flow Diffusion Models (NFDM) revolutionize generative modeling by introducing a learnable forward process, resulting in state-of-the-art likelihoods and versatile generative dynamics.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/z0wibvtbxc/cover.png"/></item><item><title>Neural P$^3$M: A Long-Range Interaction Modeling Enhancer for Geometric GNNs</title><link>https://deep-diver.github.io/neurips2024/posters/ncqauwsyl5/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/ncqauwsyl5/</guid><description>Neural P¬≥M enhances geometric GNNs by incorporating mesh points to model long-range interactions in molecules, achieving state-of-the-art accuracy in predicting energy and forces.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/ncqauwsyl5/cover.png"/></item><item><title>NeuralFuse: Learning to Recover the Accuracy of Access-Limited Neural Network Inference in Low-Voltage Regimes</title><link>https://deep-diver.github.io/neurips2024/posters/npoht6wv1f/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/npoht6wv1f/</guid><description>NeuralFuse: A novel add-on module learns input transformations to maintain accuracy in low-voltage DNN inference, achieving up to 57% accuracy recovery and 24% energy savings without retraining.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/npoht6wv1f/cover.png"/></item><item><title>Newton Losses: Using Curvature Information for Learning with Differentiable Algorithms</title><link>https://deep-diver.github.io/neurips2024/posters/vjaorqq71s/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/vjaorqq71s/</guid><description>Newton Losses enhance training of neural networks with complex objectives by using second-order information from loss functions, achieving significant performance gains.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/vjaorqq71s/cover.png"/></item><item><title>No Representation, No Trust: Connecting Representation, Collapse, and Trust Issues in PPO</title><link>https://deep-diver.github.io/neurips2024/posters/wy9ugrmwd0/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/wy9ugrmwd0/</guid><description>Deep RL agents trained under non-stationarity suffer performance collapse due to representation degradation; this work reveals this in PPO and introduces Proximal Feature Optimization (PFO) to mitigat&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/wy9ugrmwd0/cover.png"/></item><item><title>Non-Euclidean Mixture Model for Social Network Embedding</title><link>https://deep-diver.github.io/neurips2024/posters/nuzv2itlvn/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/nuzv2itlvn/</guid><description>Non-Euclidean Mixture Model (NMM-GNN) outperforms existing methods by using spherical and hyperbolic spaces to model homophily and social influence in social network embedding, improving link predicti&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/nuzv2itlvn/cover.png"/></item><item><title>Nonconvex Federated Learning on Compact Smooth Submanifolds With Heterogeneous Data</title><link>https://deep-diver.github.io/neurips2024/posters/uo53206olj/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/uo53206olj/</guid><description>This paper proposes a novel federated learning algorithm for nonconvex problems on compact smooth manifolds, achieving both computational and communication efficiency while mitigating client drift.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/uo53206olj/cover.png"/></item><item><title>Normalization and effective learning rates in reinforcement learning</title><link>https://deep-diver.github.io/neurips2024/posters/zbjje6nq5k/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/zbjje6nq5k/</guid><description>Normalize-and-Project (NaP) boosts reinforcement learning by stabilizing layer normalization, preventing plasticity loss, and enabling effective learning rate control.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/zbjje6nq5k/cover.png"/></item><item><title>Nuclear Norm Regularization for Deep Learning</title><link>https://deep-diver.github.io/neurips2024/posters/eddhtvb5em/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/eddhtvb5em/</guid><description>This paper presents a novel, efficient method for Jacobian nuclear norm regularization in deep learning, replacing computationally expensive SVDs with equivalent Frobenius norm computations, thereby e&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/eddhtvb5em/cover.png"/></item><item><title>Offline Reinforcement Learning with OOD State Correction and OOD Action Suppression</title><link>https://deep-diver.github.io/neurips2024/posters/anyzgglq6n/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/anyzgglq6n/</guid><description>Offline RL agents often fail in real-world scenarios due to unseen test states. SCAS, a novel method, simultaneously corrects OOD states to high-value, in-distribution states and suppresses risky OOD &amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/anyzgglq6n/cover.png"/></item><item><title>Oja's Algorithm for Streaming Sparse PCA</title><link>https://deep-diver.github.io/neurips2024/posters/clqdptoord/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/clqdptoord/</guid><description>Oja&amp;rsquo;s algorithm achieves minimax optimal error rates for streaming sparse PCA using a simple single-pass thresholding method, requiring only O(d) space and O(nd) time.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/clqdptoord/cover.png"/></item><item><title>On $f$-Divergence Principled Domain Adaptation: An Improved Framework</title><link>https://deep-diver.github.io/neurips2024/posters/xsu27dgwer/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/xsu27dgwer/</guid><description>Improved unsupervised domain adaptation framework achieves superior performance via refined f-divergence and novel f-domain discrepancy, enabling faster algorithms and tighter generalization bounds.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/xsu27dgwer/cover.png"/></item><item><title>On conditional diffusion models for PDE simulations</title><link>https://deep-diver.github.io/neurips2024/posters/nql8ejymzh/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/nql8ejymzh/</guid><description>This paper introduces novel autoregressive sampling and hybrid training strategies for score-based diffusion models, significantly boosting PDE forecasting and assimilation accuracy.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/nql8ejymzh/cover.png"/></item><item><title>On Sampling Strategies for Spectral Model Sharding</title><link>https://deep-diver.github.io/neurips2024/posters/pgthglufi3/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/pgthglufi3/</guid><description>Two novel sampling strategies for spectral model sharding in federated learning minimize approximation error and create unbiased estimators, improving performance on various datasets.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/pgthglufi3/cover.png"/></item><item><title>On the Complexity of Learning Sparse Functions with Statistical and Gradient Queries</title><link>https://deep-diver.github.io/neurips2024/posters/q0kwoyzlso/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/q0kwoyzlso/</guid><description>Learning sparse functions efficiently with gradient methods is challenging; this paper introduces Differentiable Learning Queries (DLQ) to precisely characterize gradient query complexity, revealing s&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/q0kwoyzlso/cover.png"/></item><item><title>On the Curses of Future and History in Future-dependent Value Functions for Off-policy Evaluation</title><link>https://deep-diver.github.io/neurips2024/posters/s5917zor6v/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/s5917zor6v/</guid><description>This paper tackles the &amp;lsquo;curse of horizon&amp;rsquo; in off-policy evaluation for partially observable Markov decision processes (POMDPs) by proposing novel coverage assumptions, enabling polynomial estimation e&amp;hellip;</description></item><item><title>On the Identifiability of Hybrid Deep Generative Models: Meta-Learning as a Solution</title><link>https://deep-diver.github.io/neurips2024/posters/sxy1nvgyo7/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/sxy1nvgyo7/</guid><description>Meta-learning solves hybrid deep generative model unidentifiability!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/sxy1nvgyo7/cover.png"/></item><item><title>On the Limitations of Fractal Dimension as a Measure of Generalization</title><link>https://deep-diver.github.io/neurips2024/posters/yo6gvpurkn/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/yo6gvpurkn/</guid><description>Fractal dimension, while showing promise, fails to consistently predict neural network generalization due to hyperparameter influence and adversarial initializations; prompting further research.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/yo6gvpurkn/cover.png"/></item><item><title>On the Necessity of Collaboration for Online Model Selection with Decentralized Data</title><link>https://deep-diver.github.io/neurips2024/posters/uqwflgzpv1/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/uqwflgzpv1/</guid><description>Federated online model selection needs collaboration only when clients have limited computing power; otherwise, independent learning suffices.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/uqwflgzpv1/cover.png"/></item><item><title>On the Role of Information Structure in Reinforcement Learning for Partially-Observable Sequential Teams and Games</title><link>https://deep-diver.github.io/neurips2024/posters/qgmc8ftbnd/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/qgmc8ftbnd/</guid><description>New reinforcement learning model clarifies the role of information structure in partially-observable sequential decision-making problems, proving an upper bound on learning complexity.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/qgmc8ftbnd/cover.png"/></item><item><title>On the Scalability of Certified Adversarial Robustness with Generated Data</title><link>https://deep-diver.github.io/neurips2024/posters/tfag9uznpv/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/tfag9uznpv/</guid><description>Boosting certified robustness of machine learning models by 3-4% using generated data from diffusion models!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/tfag9uznpv/cover.png"/></item><item><title>On the Scalability of GNNs for Molecular Graphs</title><link>https://deep-diver.github.io/neurips2024/posters/klqhrq7fvb/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/klqhrq7fvb/</guid><description>Giant leap in molecular GNNs! MolGPS, a new foundation model, achieves state-of-the-art performance on molecular property prediction by leveraging massive datasets and demonstrating the scalability o&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/klqhrq7fvb/cover.png"/></item><item><title>On the Target-kernel Alignment: a Unified Analysis with Kernel Complexity</title><link>https://deep-diver.github.io/neurips2024/posters/hkcx2wa3p0/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/hkcx2wa3p0/</guid><description>Truncated kernel methods consistently outperform standard methods by eliminating the saturation effect, offering faster learning rates and enhanced theoretical guarantees.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/hkcx2wa3p0/cover.png"/></item><item><title>Online Control with Adversarial Disturbance for Continuous-time Linear Systems</title><link>https://deep-diver.github.io/neurips2024/posters/jrydk3henc/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/jrydk3henc/</guid><description>This paper presents a novel two-level online control algorithm that learns to control continuous-time linear systems under adversarial disturbances, achieving sublinear regret.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/jrydk3henc/cover.png"/></item><item><title>OPERA: Automatic Offline Policy Evaluation with Re-weighted Aggregates of Multiple Estimators</title><link>https://deep-diver.github.io/neurips2024/posters/t6logzbc2m/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/t6logzbc2m/</guid><description>OPERA: A new algorithm intelligently blends multiple offline policy evaluation estimators for more accurate policy performance estimates.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/t6logzbc2m/cover.png"/></item><item><title>Opponent Modeling based on Subgoal Inference</title><link>https://deep-diver.github.io/neurips2024/posters/lt6wo0oz8k/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/lt6wo0oz8k/</guid><description>Opponent modeling based on subgoal inference (OMG) outperforms existing methods by inferring opponent subgoals, enabling better generalization to unseen opponents in multi-agent environments.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/lt6wo0oz8k/cover.png"/></item><item><title>Opponent Modeling with In-context Search</title><link>https://deep-diver.github.io/neurips2024/posters/bghsbfyg3b/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/bghsbfyg3b/</guid><description>Opponent Modeling with In-context Search (OMIS) leverages in-context learning and decision-time search for stable and effective opponent adaptation in multi-agent environments.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/bghsbfyg3b/cover.png"/></item><item><title>Optimal Design for Human Preference Elicitation</title><link>https://deep-diver.github.io/neurips2024/posters/ccgwj61ael/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/ccgwj61ael/</guid><description>Dope: Efficient algorithms optimize human preference elicitation for learning to rank, minimizing ranking loss and prediction error with absolute and ranking feedback models.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/ccgwj61ael/cover.png"/></item><item><title>Optimal Multi-Fidelity Best-Arm Identification</title><link>https://deep-diver.github.io/neurips2024/posters/gkmtm1i8ew/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/gkmtm1i8ew/</guid><description>A new algorithm for multi-fidelity best-arm identification achieves asymptotically optimal cost complexity, offering significant improvements over existing methods.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/gkmtm1i8ew/cover.png"/></item><item><title>Optimal Top-Two Method for Best Arm Identification and Fluid Analysis</title><link>https://deep-diver.github.io/neurips2024/posters/yxqw4qqe2u/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/yxqw4qqe2u/</guid><description>Optimal Top-Two Algorithm solves best arm identification problem with improved efficiency and computational cost, achieving asymptotic optimality.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/yxqw4qqe2u/cover.png"/></item><item><title>Optimistic Critic Reconstruction and Constrained Fine-Tuning for General Offline-to-Online RL</title><link>https://deep-diver.github.io/neurips2024/posters/xvfevb9xfx/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/xvfevb9xfx/</guid><description>This paper introduces OCR-CFT, a novel method for general offline-to-online RL, achieving stable and efficient performance improvements by addressing evaluation and improvement mismatches through opti&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/xvfevb9xfx/cover.png"/></item><item><title>Optimistic Verifiable Training by Controlling Hardware Nondeterminism</title><link>https://deep-diver.github.io/neurips2024/posters/bf0mdflz1i/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/bf0mdflz1i/</guid><description>Researchers developed a verifiable training method that uses high-precision training with adaptive rounding and logging to achieve exact training replication across different GPUs, enabling efficient &amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/bf0mdflz1i/cover.png"/></item><item><title>Optimizing over Multiple Distributions under Generalized Quasar-Convexity Condition</title><link>https://deep-diver.github.io/neurips2024/posters/lov9ksx3uo/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/lov9ksx3uo/</guid><description>This paper proposes &amp;lsquo;generalized quasar-convexity&amp;rsquo; to optimize problems with multiple probability distributions, offering adaptive algorithms with superior iteration complexities compared to existing &amp;hellip;</description></item><item><title>Oracle-Efficient Reinforcement Learning for Max Value Ensembles</title><link>https://deep-diver.github.io/neurips2024/posters/kll70ptq17/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/kll70ptq17/</guid><description>Boost RL performance in large state spaces by efficiently learning a policy competitive with the best combination of existing base policies!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/kll70ptq17/cover.png"/></item><item><title>OTTER: Effortless Label Distribution Adaptation of Zero-shot Models</title><link>https://deep-diver.github.io/neurips2024/posters/rsawwsbcs7/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/rsawwsbcs7/</guid><description>OTTER effortlessly adapts zero-shot models to new tasks by adjusting predictions using optimal transport, improving accuracy significantly without extra training data.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/rsawwsbcs7/cover.png"/></item><item><title>Out-of-Distribution Detection with a Single Unconditional Diffusion Model</title><link>https://deep-diver.github.io/neurips2024/posters/ttnfh7d1h4/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/ttnfh7d1h4/</guid><description>Single diffusion model achieves competitive out-of-distribution detection across diverse tasks by analyzing diffusion path characteristics.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/ttnfh7d1h4/cover.png"/></item><item><title>Overcoming the Sim-to-Real Gap: Leveraging Simulation to Learn to Explore for Real-World RL</title><link>https://deep-diver.github.io/neurips2024/posters/jjql8hxjas/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/jjql8hxjas/</guid><description>Leveraging simulation for real-world RL is often hampered by the sim-to-real gap. This paper shows that instead of directly transferring policies, transferring &lt;em>exploratory&lt;/em> policies from simulation d&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/jjql8hxjas/cover.png"/></item><item><title>OwMatch: Conditional Self-Labeling with Consistency for Open-world Semi-Supervised Learning</title><link>https://deep-diver.github.io/neurips2024/posters/rle9x7dquh/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/rle9x7dquh/</guid><description>OwMatch: a novel framework conquering open-world semi-supervised learning challenges by combining conditional self-labeling and consistency for substantially enhanced accuracy across known and unknown&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/rle9x7dquh/cover.png"/></item><item><title>PACE: Pacing Operator Learning to Accurate Optical Field Simulation for Complicated Photonic Devices</title><link>https://deep-diver.github.io/neurips2024/posters/uxjlgkwdci/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/uxjlgkwdci/</guid><description>PACE, a novel neural operator, achieves unprecedented accuracy and speed in optical field simulation for complex photonic devices, surpassing existing methods by significantly reducing errors and boos&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/uxjlgkwdci/cover.png"/></item><item><title>PageRank Bandits for Link Prediction</title><link>https://deep-diver.github.io/neurips2024/posters/vsz9na5jtl/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/vsz9na5jtl/</guid><description>PageRank Bandits (PRB) revolutionizes link prediction by framing it as a sequential decision-making problem, thus enabling the system to adapt to evolving data. Combining contextual bandits with PageR&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/vsz9na5jtl/cover.png"/></item><item><title>Parallelizing Model-based Reinforcement Learning Over the Sequence Length</title><link>https://deep-diver.github.io/neurips2024/posters/r6n9agyz13/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/r6n9agyz13/</guid><description>PaMoRL framework boosts model-based reinforcement learning speed by parallelizing model and policy learning stages over sequence length, maintaining high sample efficiency.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/r6n9agyz13/cover.png"/></item><item><title>Parameter Disparities Dissection for Backdoor Defense in Heterogeneous Federated Learning</title><link>https://deep-diver.github.io/neurips2024/posters/g8wnc1e1os/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/g8wnc1e1os/</guid><description>FDCR defends against backdoor attacks in heterogeneous federated learning by identifying malicious clients via Fisher Information-based parameter importance discrepancies and rescaling crucial paramet&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/g8wnc1e1os/cover.png"/></item><item><title>Parameter-free Clipped Gradient Descent Meets Polyak</title><link>https://deep-diver.github.io/neurips2024/posters/sgcnphyoeq/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/sgcnphyoeq/</guid><description>Parameter-free optimization is revolutionized! Inexact Polyak Stepsize achieves the same convergence rate as clipped gradient descent but without any hyperparameter tuning, saving time and computatio&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/sgcnphyoeq/cover.png"/></item><item><title>Pard: Permutation-Invariant Autoregressive Diffusion for Graph Generation</title><link>https://deep-diver.github.io/neurips2024/posters/x4kk4fxls3/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/x4kk4fxls3/</guid><description>PARD: a novel permutation-invariant autoregressive diffusion model for efficient and high-quality graph generation, achieving state-of-the-art results.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/x4kk4fxls3/cover.png"/></item><item><title>Parseval Regularization for Continual Reinforcement Learning</title><link>https://deep-diver.github.io/neurips2024/posters/rb1f2h5yex/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/rb1f2h5yex/</guid><description>Boost continual reinforcement learning with Parseval regularization: maintaining orthogonal weight matrices preserves optimization, significantly improving RL agent training across diverse tasks.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/rb1f2h5yex/cover.png"/></item><item><title>pcaGAN: Improving Posterior-Sampling cGANs via Principal Component Regularization</title><link>https://deep-diver.github.io/neurips2024/posters/z0nq3hheeg/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/z0nq3hheeg/</guid><description>pcaGAN boosts posterior-sampling cGANs by using principal component regularization, achieving faster, more accurate results in various imaging tasks.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/z0nq3hheeg/cover.png"/></item><item><title>PEAC: Unsupervised Pre-training for Cross-Embodiment Reinforcement Learning</title><link>https://deep-diver.github.io/neurips2024/posters/lyaffdx8yf/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/lyaffdx8yf/</guid><description>PEAC: a novel unsupervised pre-training method significantly improves cross-embodiment generalization in reinforcement learning, enabling faster adaptation to diverse robots and tasks.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/lyaffdx8yf/cover.png"/></item><item><title>Penalty-based Methods for Simple Bilevel Optimization under H√∂lderian Error Bounds</title><link>https://deep-diver.github.io/neurips2024/posters/oq1zj9ih88/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/oq1zj9ih88/</guid><description>This paper proposes penalty-based methods for simple bilevel optimization, achieving (Œµ, ŒµŒ≤)-optimal solutions with improved complexity under H√∂lderian error bounds.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/oq1zj9ih88/cover.png"/></item><item><title>Personalized Federated Learning via Feature Distribution Adaptation</title><link>https://deep-diver.github.io/neurips2024/posters/wl2optqcng/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/wl2optqcng/</guid><description>Personalized federated learning (PFL) often struggles with data scarcity and distribution shifts. pFedFDA, a novel algorithm, tackles this by framing representation learning as a generative modeling &amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/wl2optqcng/cover.png"/></item><item><title>Personalized Federated Learning with Mixture of Models for Adaptive Prediction and Model Fine-Tuning</title><link>https://deep-diver.github.io/neurips2024/posters/yvuhnbkczd/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/yvuhnbkczd/</guid><description>Fed-POE: A personalized federated learning algorithm for superior real-time predictions!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/yvuhnbkczd/cover.png"/></item><item><title>Pessimistic Backward Policy for GFlowNets</title><link>https://deep-diver.github.io/neurips2024/posters/l8q21qrjmd/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/l8q21qrjmd/</guid><description>Pessimistic Backward Policy for GFlowNets (PBP-GFN) tackles GFlowNets&amp;rsquo; tendency to under-exploit high-reward objects by maximizing observed backward flow, enhancing high-reward object discovery and ov&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/l8q21qrjmd/cover.png"/></item><item><title>pFedClub: Controllable Heterogeneous Model Aggregation for Personalized Federated Learning</title><link>https://deep-diver.github.io/neurips2024/posters/xw6ga9i4ea/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/xw6ga9i4ea/</guid><description>pFedClub: Controllable heterogeneous model aggregation boosts personalized federated learning by generating reasonable-sized, personalized models, significantly cutting computational costs.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/xw6ga9i4ea/cover.png"/></item><item><title>PGN: The RNN's New Successor is Effective for Long-Range Time Series Forecasting</title><link>https://deep-diver.github.io/neurips2024/posters/ypeamfku2o/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/ypeamfku2o/</guid><description>TPGN, a novel framework for long-range time series forecasting, uses Parallel Gated Networks (PGN) to efficiently capture long-term dependencies, achieving state-of-the-art results on multiple dataset&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/ypeamfku2o/cover.png"/></item><item><title>Physics-Informed Regularization for Domain-Agnostic Dynamical System Modeling</title><link>https://deep-diver.github.io/neurips2024/posters/iwlqbne8p7/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/iwlqbne8p7/</guid><description>TREAT: a novel framework boosting dynamical systems modeling accuracy by enforcing Time-Reversal Symmetry (TRS) via a regularization term. High-precision modeling is achieved across diverse systems, &amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/iwlqbne8p7/cover.png"/></item><item><title>Physics-Informed Variational State-Space Gaussian Processes</title><link>https://deep-diver.github.io/neurips2024/posters/tcf7s75xfa/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/tcf7s75xfa/</guid><description>PHYSS-GP: a novel physics-informed state-space Gaussian process model for efficient spatio-temporal data modeling, outperforming existing methods in predictive accuracy and computational speed.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/tcf7s75xfa/cover.png"/></item><item><title>Policy Mirror Descent with Lookahead</title><link>https://deep-diver.github.io/neurips2024/posters/om2aa0guha/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/om2aa0guha/</guid><description>Boosting reinforcement learning, this paper introduces h-PMD, a novel algorithm enhancing policy mirror descent with lookahead for faster convergence and improved sample complexity.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/om2aa0guha/cover.png"/></item><item><title>Policy-shaped prediction: avoiding distractions in model-based reinforcement learning</title><link>https://deep-diver.github.io/neurips2024/posters/hgdh4foghu/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/hgdh4foghu/</guid><description>Policy-Shaped Prediction (PSP) improves model-based reinforcement learning by focusing world models on task-relevant information, significantly enhancing robustness against distracting stimuli.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/hgdh4foghu/cover.png"/></item><item><title>Practical Shuffle Coding</title><link>https://deep-diver.github.io/neurips2024/posters/m2daxpcoii/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/m2daxpcoii/</guid><description>Revolutionizing unordered data compression, this paper introduces autoregressive shuffle coding, achieving state-of-the-art speeds and compression rates on massive datasets.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/m2daxpcoii/cover.png"/></item><item><title>Precise asymptotics of reweighted least-squares algorithms for linear diagonal networks</title><link>https://deep-diver.github.io/neurips2024/posters/nv7ox1vd3q/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/nv7ox1vd3q/</guid><description>New analysis reveals how reweighted least-squares algorithms for linear diagonal networks achieve favorable performance in high-dimensional settings, improving upon existing theoretical guarantees and&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/nv7ox1vd3q/cover.png"/></item><item><title>Predicting Ground State Properties: Constant Sample Complexity and Deep Learning Algorithms</title><link>https://deep-diver.github.io/neurips2024/posters/yblxvqjyqa/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/yblxvqjyqa/</guid><description>Deep learning algorithms now predict quantum ground state properties with constant sample complexity, regardless of system size, improving upon previous methods.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/yblxvqjyqa/cover.png"/></item><item><title>Preference Learning of Latent Decision Utilities with a Human-like Model of Preferential Choice</title><link>https://deep-diver.github.io/neurips2024/posters/nfq3gkfb4h/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/nfq3gkfb4h/</guid><description>Human-like choice modeling revolutionizes preference learning! A new tractable model, CRCS, significantly improves utility inference from human data, outperforming existing methods.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/nfq3gkfb4h/cover.png"/></item><item><title>Preferential Normalizing Flows</title><link>https://deep-diver.github.io/neurips2024/posters/srsjr9sdkr/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/srsjr9sdkr/</guid><description>Eliciting high-dimensional probability distributions from experts using only preference comparisons is achieved via normalizing flows and a novel functional prior, resolving the problem of collapsing &amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/srsjr9sdkr/cover.png"/></item><item><title>Pretrained Optimization Model for Zero-Shot Black Box Optimization</title><link>https://deep-diver.github.io/neurips2024/posters/fwqhxdeusg/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/fwqhxdeusg/</guid><description>Pretrained Optimization Model (POM) excels at zero-shot black-box optimization, outperforming existing methods, especially in high dimensions, through direct application or few-shot fine-tuning.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/fwqhxdeusg/cover.png"/></item><item><title>Pretraining Codomain Attention Neural Operators for Solving Multiphysics PDEs</title><link>https://deep-diver.github.io/neurips2024/posters/wspiduxzyx/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/wspiduxzyx/</guid><description>CoDA-NO, a novel neural operator, revolutionizes multiphysics PDE solving via codomain tokenization, enabling efficient self-supervised pretraining and few-shot learning for superior generalization.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/wspiduxzyx/cover.png"/></item><item><title>Preventing Dimensional Collapse in Self-Supervised Learning via Orthogonality Regularization</title><link>https://deep-diver.github.io/neurips2024/posters/y3fjkssfmy/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/y3fjkssfmy/</guid><description>Orthogonal regularization prevents dimensional collapse in self-supervised learning, significantly boosting model performance across diverse benchmarks.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/y3fjkssfmy/cover.png"/></item><item><title>Probabilistic Decomposed Linear Dynamical Systems for Robust Discovery of Latent Neural Dynamics</title><link>https://deep-diver.github.io/neurips2024/posters/xphsbybd73/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/xphsbybd73/</guid><description>Probabilistic Decomposed Linear Dynamical Systems (p-dLDS) improve latent variable inference in nonlinear neural systems by using a probabilistic approach that&amp;rsquo;s robust to noise and includes a time-va&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/xphsbybd73/cover.png"/></item><item><title>Probabilistic Federated Prompt-Tuning with Non-IID and Imbalanced Data</title><link>https://deep-diver.github.io/neurips2024/posters/nw6ansc66g/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/nw6ansc66g/</guid><description>Probabilistic Federated Prompt Tuning (PFPT) significantly improves federated learning accuracy on heterogeneous and imbalanced data by using a probabilistic model for prompt aggregation, outperformin&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/nw6ansc66g/cover.png"/></item><item><title>Probabilistic Graph Rewiring via Virtual Nodes</title><link>https://deep-diver.github.io/neurips2024/posters/lpvshl9lck/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/lpvshl9lck/</guid><description>IPR-MPNNs revolutionize graph neural networks by implicitly rewiring graphs using virtual nodes, achieving state-of-the-art performance with significantly faster computation.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/lpvshl9lck/cover.png"/></item><item><title>Prospective Learning: Learning for a Dynamic Future</title><link>https://deep-diver.github.io/neurips2024/posters/xebpjuqzs3/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/xebpjuqzs3/</guid><description>Prospective Learning: a new framework enabling machines to learn effectively in dynamic environments where data distributions and goals shift over time.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/xebpjuqzs3/cover.png"/></item><item><title>Prospective Representation Learning for Non-Exemplar Class-Incremental Learning</title><link>https://deep-diver.github.io/neurips2024/posters/ztdarpmbun/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/ztdarpmbun/</guid><description>Prospective Representation Learning (PRL) revolutionizes non-exemplar class-incremental learning by proactively reserving embedding space for new classes and minimizing the shock of new data on previo&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/ztdarpmbun/cover.png"/></item><item><title>Protected Test-Time Adaptation via Online Entropy Matching: A Betting Approach</title><link>https://deep-diver.github.io/neurips2024/posters/qamfjyhpeg/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/qamfjyhpeg/</guid><description>POEM: a novel test-time adaptation approach using online self-training improves accuracy under distribution shifts by dynamically updating the classifier, ensuring invariance to shifts while maintaini&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/qamfjyhpeg/cover.png"/></item><item><title>Protein-Nucleic Acid Complex Modeling with Frame Averaging Transformer</title><link>https://deep-diver.github.io/neurips2024/posters/xngi3z3wkn/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/xngi3z3wkn/</guid><description>Unsupervised learning predicts protein-nucleic acid binding using contact map prediction, significantly improving aptamer screening via FAFormer, a novel equivariant transformer.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/xngi3z3wkn/cover.png"/></item><item><title>Provable and Efficient Dataset Distillation for Kernel Ridge Regression</title><link>https://deep-diver.github.io/neurips2024/posters/wi2vpcbdnd/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/wi2vpcbdnd/</guid><description>One data point per class suffices for efficient and provable dataset distillation in kernel ridge regression, significantly reducing computational costs.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/wi2vpcbdnd/cover.png"/></item><item><title>Provable Partially Observable Reinforcement Learning with Privileged Information</title><link>https://deep-diver.github.io/neurips2024/posters/o3i1jefzkw/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/o3i1jefzkw/</guid><description>This paper provides the first provable efficiency guarantees for practically-used RL algorithms leveraging privileged information, addressing limitations of previous empirical paradigms and opening ne&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/o3i1jefzkw/cover.png"/></item><item><title>Provable Posterior Sampling with Denoising Oracles via Tilted Transport</title><link>https://deep-diver.github.io/neurips2024/posters/phlle8uoev/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/phlle8uoev/</guid><description>Boosting posterior sampling in challenging high-dimensional inverse problems, this paper introduces &amp;rsquo;tilted transport&amp;rsquo;, a novel technique leveraging denoising oracles for provably easier sampling.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/phlle8uoev/cover.png"/></item><item><title>Provably Efficient Reinforcement Learning with Multinomial Logit Function Approximation</title><link>https://deep-diver.github.io/neurips2024/posters/z2739hyur3/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/z2739hyur3/</guid><description>This paper presents novel RL algorithms using multinomial logit function approximation, achieving O(1) computation and storage while nearly closing the regret gap with linear methods.</description></item><item><title>Provably Robust Score-Based Diffusion Posterior Sampling for Plug-and-Play Image Reconstruction</title><link>https://deep-diver.github.io/neurips2024/posters/slnsoay4u1/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/slnsoay4u1/</guid><description>Provably robust diffusion posterior sampling for plug-and-play image reconstruction is achieved via a novel algorithmic framework, DPnP, offering both asymptotic and non-asymptotic performance guarant&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/slnsoay4u1/cover.png"/></item><item><title>Pure Message Passing Can Estimate Common Neighbor for Link Prediction</title><link>https://deep-diver.github.io/neurips2024/posters/xa3dvaolko/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/xa3dvaolko/</guid><description>Pure message passing in graph neural networks can accurately estimate common neighbor heuristics for superior link prediction.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/xa3dvaolko/cover.png"/></item><item><title>PURE: Prompt Evolution with Graph ODE for Out-of-distribution Fluid Dynamics Modeling</title><link>https://deep-diver.github.io/neurips2024/posters/z86knmjouq/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/z86knmjouq/</guid><description>PURE: A novel method uses Graph ODE to adapt spatio-temporal forecasting models to various fluid dynamics scenarios, improving model adaptation to unseen parameters and long-term predictions.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/z86knmjouq/cover.png"/></item><item><title>PureGen: Universal Data Purification for Train-Time Poison Defense via Generative Model Dynamics</title><link>https://deep-diver.github.io/neurips2024/posters/zeihwoddvh/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/zeihwoddvh/</guid><description>PUREGEN uses generative model dynamics to purify poisoned training data, providing a universal, effective, and efficient train-time defense against various data poisoning attacks.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/zeihwoddvh/cover.png"/></item><item><title>QGFN: Controllable Greediness with Action Values</title><link>https://deep-diver.github.io/neurips2024/posters/kq9lgm2jqt/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/kq9lgm2jqt/</guid><description>QGFN boosts Generative Flow Networks (GFNs) by cleverly combining their sampling policy with an action-value estimate, creating controllable and efficient generation of high-reward samples.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/kq9lgm2jqt/cover.png"/></item><item><title>QVAE-Mole: The Quantum VAE with Spherical Latent Variable Learning for 3-D Molecule Generation</title><link>https://deep-diver.github.io/neurips2024/posters/rqvesbxqdo/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/rqvesbxqdo/</guid><description>Quantum VAE with spherical latent variable learning enables efficient, one-shot 3D molecule generation, outperforming classic and other quantum methods.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/rqvesbxqdo/cover.png"/></item><item><title>RA-PbRL: Provably Efficient Risk-Aware Preference-Based Reinforcement Learning</title><link>https://deep-diver.github.io/neurips2024/posters/jndcfoczof/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/jndcfoczof/</guid><description>RA-PbRL introduces a provably efficient algorithm for risk-aware preference-based reinforcement learning, addressing the limitations of existing risk-neutral methods in applications demanding heighten&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/jndcfoczof/cover.png"/></item><item><title>Random Representations Outperform Online Continually Learned Representations</title><link>https://deep-diver.github.io/neurips2024/posters/tz5k9iybbf/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/tz5k9iybbf/</guid><description>Random pixel projections outperform complex online continual learning methods for image classification, challenging assumptions about representation learning.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/tz5k9iybbf/cover.png"/></item><item><title>Randomized algorithms and PAC bounds for inverse reinforcement learning in continuous spaces</title><link>https://deep-diver.github.io/neurips2024/posters/vugxawocqz/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/vugxawocqz/</guid><description>This paper presents randomized algorithms with PAC bounds for solving inverse reinforcement learning problems in continuous state and action spaces, offering robust theoretical guarantees and practica&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/vugxawocqz/cover.png"/></item><item><title>Real-Time Selection Under General Constraints via Predictive Inference</title><link>https://deep-diver.github.io/neurips2024/posters/wblxm5zdke/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/wblxm5zdke/</guid><description>II-COS: a novel online sample selection method effectively controls individual and interactive constraints in real-time via predictive inference, improving efficiency and addressing various practical &amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/wblxm5zdke/cover.png"/></item><item><title>REBEL: Reinforcement Learning via Regressing Relative Rewards</title><link>https://deep-diver.github.io/neurips2024/posters/yxjwajzuyv/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/yxjwajzuyv/</guid><description>REBEL, a novel reinforcement learning algorithm, simplifies policy optimization by regressing relative rewards, achieving strong performance in language and image generation tasks with increased effic&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/yxjwajzuyv/cover.png"/></item><item><title>Reciprocal Reward Influence Encourages Cooperation From Self-Interested Agents</title><link>https://deep-diver.github.io/neurips2024/posters/vq2kzpig8v/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/vq2kzpig8v/</guid><description>Reciprocators: AI agents that learn to cooperate by reciprocating influence, achieving prosocial outcomes in complex scenarios.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/vq2kzpig8v/cover.png"/></item><item><title>Recurrent Reinforcement Learning with Memoroids</title><link>https://deep-diver.github.io/neurips2024/posters/na4q983a1v/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/na4q983a1v/</guid><description>Memoroids and Tape-Based Batching revolutionize recurrent RL, enabling efficient processing of long sequences and improving sample efficiency by eliminating segmentation.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/na4q983a1v/cover.png"/></item><item><title>REDUCR: Robust Data Downsampling using Class Priority Reweighting</title><link>https://deep-diver.github.io/neurips2024/posters/jz7z7kkr94/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/jz7z7kkr94/</guid><description>REDUCR, a novel data downsampling method, significantly improves worst-class test accuracy in imbalanced datasets by using class priority reweighting, surpassing state-of-the-art methods by ~15%.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/jz7z7kkr94/cover.png"/></item><item><title>Regularized Adaptive Momentum Dual Averaging with an Efficient Inexact Subproblem Solver for Training Structured Neural Network</title><link>https://deep-diver.github.io/neurips2024/posters/xl7ve14aha/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/xl7ve14aha/</guid><description>RAMDA: a new algorithm ensures efficient training of structured neural networks by achieving optimal structure and outstanding predictive performance.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/xl7ve14aha/cover.png"/></item><item><title>Regularized Conditional Diffusion Model for Multi-Task Preference Alignment</title><link>https://deep-diver.github.io/neurips2024/posters/ycs0xgfrb4/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/ycs0xgfrb4/</guid><description>A novel regularized conditional diffusion model enables effective multi-task preference alignment in sequential decision-making by learning unified preference representations and maximizing mutual inf&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/ycs0xgfrb4/cover.png"/></item><item><title>Reinforced Cross-Domain Knowledge Distillation on Time Series Data</title><link>https://deep-diver.github.io/neurips2024/posters/tuhabdzp0q/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/tuhabdzp0q/</guid><description>Reinforced Cross-Domain Knowledge Distillation (RCD-KD) dynamically selects target samples for efficient knowledge transfer from a complex teacher model to a compact student model, achieving superior &amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/tuhabdzp0q/cover.png"/></item><item><title>Reinforcement Learning Guided Semi-Supervised Learning</title><link>https://deep-diver.github.io/neurips2024/posters/psmbefuza2/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/psmbefuza2/</guid><description>Reinforcement Learning guides a novel semi-supervised learning method, improving model performance by adaptively balancing labeled and unlabeled data.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/psmbefuza2/cover.png"/></item><item><title>Reinforcement Learning Policy as Macro Regulator Rather than Macro Placer</title><link>https://deep-diver.github.io/neurips2024/posters/jewzstuavo/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/jewzstuavo/</guid><description>Reinforcement learning refines existing macro placements, enhancing chip design by improving power, performance, and area (PPA) metrics and integrating the often-overlooked metric of regularity.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/jewzstuavo/cover.png"/></item><item><title>Reinforcement Learning with Lookahead Information</title><link>https://deep-diver.github.io/neurips2024/posters/wlqfovltqz/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/wlqfovltqz/</guid><description>Provably efficient RL algorithms are designed to utilize immediate reward or transition information, significantly improving reward collection in unknown environments.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/wlqfovltqz/cover.png"/></item><item><title>Reinforcement Learning with LTL and ‚çµ-Regular Objectives via Optimality-Preserving Translation to Average Rewards</title><link>https://deep-diver.github.io/neurips2024/posters/iykao97yxf/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/iykao97yxf/</guid><description>Reinforcement learning with complex objectives made easy: This paper introduces an optimality-preserving translation to reduce problems with Linear Temporal Logic (LTL) objectives to standard average &amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/iykao97yxf/cover.png"/></item><item><title>Rejection via Learning Density Ratios</title><link>https://deep-diver.github.io/neurips2024/posters/jzciknnopj/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/jzciknnopj/</guid><description>This paper introduces a novel framework for classification with rejection by learning density ratios between data and idealized distributions, improving model robustness and accuracy.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/jzciknnopj/cover.png"/></item><item><title>Reparameterized Multi-Resolution Convolutions for Long Sequence Modelling</title><link>https://deep-diver.github.io/neurips2024/posters/rwgnbipcpk/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/rwgnbipcpk/</guid><description>MRConv: Reparameterized multi-resolution convolutions efficiently model long sequences, improving performance across various data modalities.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/rwgnbipcpk/cover.png"/></item><item><title>Rethinking Deep Thinking: Stable Learning of Algorithms using Lipschitz Constraints</title><link>https://deep-diver.github.io/neurips2024/posters/zlgfrk2cqa/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/zlgfrk2cqa/</guid><description>Stable algorithm learning achieved by Deep Thinking networks with Lipschitz Constraints, ensuring convergence and better extrapolation to complex problems.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/zlgfrk2cqa/cover.png"/></item><item><title>Rethinking Model-based, Policy-based, and Value-based Reinforcement Learning via the Lens of Representation Complexity</title><link>https://deep-diver.github.io/neurips2024/posters/kz4kc5ghgb/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/kz4kc5ghgb/</guid><description>Reinforcement learning paradigms exhibit a representation complexity hierarchy: models are easiest, then policies, and value functions are hardest to approximate.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/kz4kc5ghgb/cover.png"/></item><item><title>Rethinking Reconstruction-based Graph-Level Anomaly Detection: Limitations and a Simple Remedy</title><link>https://deep-diver.github.io/neurips2024/posters/e2inndpinb/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/e2inndpinb/</guid><description>MUSE, a novel graph anomaly detection method, leverages multifaceted summaries of reconstruction errors, achieving state-of-the-art performance by addressing limitations of existing Graph-AE-based met&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/e2inndpinb/cover.png"/></item><item><title>Rethinking the Diffusion Models for Missing Data Imputation: A Gradient Flow Perspective</title><link>https://deep-diver.github.io/neurips2024/posters/fiz8k4dj7w/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/fiz8k4dj7w/</guid><description>NewImp boosts diffusion models&amp;rsquo; missing data imputation by curbing sample diversity and eliminating data masking, achieving superior accuracy.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/fiz8k4dj7w/cover.png"/></item><item><title>Revisiting Score Propagation in Graph Out-of-Distribution Detection</title><link>https://deep-diver.github.io/neurips2024/posters/jb5qn3212b/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/jb5qn3212b/</guid><description>GRASP: A novel graph augmentation strategy boosts OOD node detection by strategically adding edges to enhance the intra-edge ratio, addressing score propagation&amp;rsquo;s limitations in various scenarios.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/jb5qn3212b/cover.png"/></item><item><title>Revive Re-weighting in Imbalanced Learning by Density Ratio Estimation</title><link>https://deep-diver.github.io/neurips2024/posters/vx4ngdyyvg/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/vx4ngdyyvg/</guid><description>Revive Re-weighting in Imbalanced Learning by Density Ratio Estimation dynamically adjusts class weights during training using density ratio estimation, significantly improving model generalization, e&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/vx4ngdyyvg/cover.png"/></item><item><title>RFLPA: A Robust Federated Learning Framework against Poisoning Attacks with Secure Aggregation</title><link>https://deep-diver.github.io/neurips2024/posters/js74zcddxg/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/js74zcddxg/</guid><description>RFLPA: Secure Federated Learning resists poisoning attacks via efficient secure aggregation.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/js74zcddxg/cover.png"/></item><item><title>RGMDT: Return-Gap-Minimizing Decision Tree Extraction in Non-Euclidean Metric Space</title><link>https://deep-diver.github.io/neurips2024/posters/mdwz5koy5p/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/mdwz5koy5p/</guid><description>RGMDT algorithm extracts high-performing, interpretable decision trees from deep RL policies, guaranteeing near-optimal returns with size constraints, and extending to multi-agent settings.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/mdwz5koy5p/cover.png"/></item><item><title>Risk-sensitive control as inference with R√©nyi divergence</title><link>https://deep-diver.github.io/neurips2024/posters/luixdwn6z5/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/luixdwn6z5/</guid><description>Risk-sensitive control is recast as inference using R√©nyi divergence, yielding new algorithms and revealing equivalences between seemingly disparate methods.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/luixdwn6z5/cover.png"/></item><item><title>RL in Latent MDPs is Tractable: Online Guarantees via Off-Policy Evaluation</title><link>https://deep-diver.github.io/neurips2024/posters/jujl2usq4d/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/jujl2usq4d/</guid><description>First sample-efficient algorithm for LMDPs without separation assumptions, achieving near-optimal guarantees via novel off-policy evaluation.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/jujl2usq4d/cover.png"/></item><item><title>RMLR: Extending Multinomial Logistic Regression into General Geometries</title><link>https://deep-diver.github.io/neurips2024/posters/lbp2cda7sp/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/lbp2cda7sp/</guid><description>RMLR: A novel framework extends multinomial logistic regression to diverse geometries, overcoming limitations of existing methods by requiring minimal geometric properties for broad applicability.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/lbp2cda7sp/cover.png"/></item><item><title>Robot Policy Learning with Temporal Optimal Transport Reward</title><link>https://deep-diver.github.io/neurips2024/posters/leed5is4oi/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/leed5is4oi/</guid><description>Temporal Optimal Transport (TemporalOT) reward enhances robot policy learning by incorporating temporal order information into Optimal Transport (OT)-based proxy rewards, leading to improved accuracy &amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/leed5is4oi/cover.png"/></item><item><title>S-MolSearch: 3D Semi-supervised Contrastive Learning for Bioactive Molecule Search</title><link>https://deep-diver.github.io/neurips2024/posters/wjaf8tgvug/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/wjaf8tgvug/</guid><description>S-MolSearch: a novel semi-supervised framework using 3D molecular data and contrastive learning achieves state-of-the-art in bioactive molecule search, outperforming existing methods.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/wjaf8tgvug/cover.png"/></item><item><title>S2HPruner: Soft-to-Hard Distillation Bridges the Discretization Gap in Pruning</title><link>https://deep-diver.github.io/neurips2024/posters/mtyy3myyhz/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/mtyy3myyhz/</guid><description>S2HPruner bridges the discretization gap in neural network pruning via a novel soft-to-hard distillation framework, achieving superior performance across various benchmarks without fine-tuning.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/mtyy3myyhz/cover.png"/></item><item><title>Safety through feedback in Constrained RL</title><link>https://deep-diver.github.io/neurips2024/posters/wssht66fbc/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/wssht66fbc/</guid><description>Reinforcement Learning from Safety Feedback (RLSF) efficiently infers cost functions from trajectory-level feedback, enabling safe policy learning in complex environments.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/wssht66fbc/cover.png"/></item><item><title>SampDetox: Black-box Backdoor Defense via Perturbation-based Sample Detoxification</title><link>https://deep-diver.github.io/neurips2024/posters/y6rv6z98pk/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/y6rv6z98pk/</guid><description>SampDetox uses diffusion models to purify poisoned machine learning samples by strategically adding noise to eliminate backdoors without compromising data integrity.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/y6rv6z98pk/cover.png"/></item><item><title>Sample-Efficient Agnostic Boosting</title><link>https://deep-diver.github.io/neurips2024/posters/ufkbrvyxtp/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/ufkbrvyxtp/</guid><description>Agnostic boosting gets a major efficiency upgrade! A new algorithm leverages sample reuse to drastically reduce the data needed for accurate learning, closing the gap with computationally expensive al&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/ufkbrvyxtp/cover.png"/></item><item><title>SARAD: Spatial Association-Aware Anomaly Detection and Diagnosis for Multivariate Time Series</title><link>https://deep-diver.github.io/neurips2024/posters/gmf5aj01hz/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/gmf5aj01hz/</guid><description>SARAD: A novel anomaly detection approach for multivariate time series leverages spatial information and association reduction patterns to achieve state-of-the-art performance.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/gmf5aj01hz/cover.png"/></item><item><title>Scalable Optimization in the Modular Norm</title><link>https://deep-diver.github.io/neurips2024/posters/sfxajb7uxx/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/sfxajb7uxx/</guid><description>Deep learning optimization gets a major upgrade with Modula, a new method that uses the modular norm to normalize weight updates, enabling learning rate transfer across network widths and depths, thus&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/sfxajb7uxx/cover.png"/></item><item><title>Scaling transformer neural networks for skillful and reliable medium-range weather forecasting</title><link>https://deep-diver.github.io/neurips2024/posters/abp01akha9/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/abp01akha9/</guid><description>Stormer, a simple transformer model, achieves state-of-the-art medium-range weather forecasting accuracy by using weather-specific embedding, randomized dynamics forecasting, and a pressure-weighted l&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/abp01akha9/cover.png"/></item><item><title>Scanning Trojaned Models Using Out-of-Distribution Samples</title><link>https://deep-diver.github.io/neurips2024/posters/m296wjxyzq/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/m296wjxyzq/</guid><description>TRODO: a novel trojan detection method using out-of-distribution samples, effectively identifies trojaned classifiers even against adversarial attacks and with limited data.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/m296wjxyzq/cover.png"/></item><item><title>Segment, Shuffle, and Stitch: A Simple Layer for Improving Time-Series Representations</title><link>https://deep-diver.github.io/neurips2024/posters/zm1lcgrphm/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/zm1lcgrphm/</guid><description>Boost time-series model accuracy with Segment, Shuffle, and Stitch (S3)! This simple layer shuffles data segments to enhance representation learning, improving classification, forecasting, and anomaly&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/zm1lcgrphm/cover.png"/></item><item><title>SEL-BALD: Deep Bayesian Active Learning for Selective Labeling with Instance Rejection</title><link>https://deep-diver.github.io/neurips2024/posters/tdmtwto6jv/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/tdmtwto6jv/</guid><description>SEL-BALD tackles the challenge of human discretion in active learning by proposing novel algorithms that account for instance rejection, significantly boosting sample efficiency.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/tdmtwto6jv/cover.png"/></item><item><title>Self-Healing Machine Learning: A Framework for Autonomous Adaptation in Real-World Environments</title><link>https://deep-diver.github.io/neurips2024/posters/f63dkipx0i/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/f63dkipx0i/</guid><description>Self-healing machine learning (SHML) autonomously diagnoses and fixes model performance degradation caused by data shifts, outperforming reason-agnostic methods.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/f63dkipx0i/cover.png"/></item><item><title>Self-Refining Diffusion Samplers: Enabling Parallelization via Parareal Iterations</title><link>https://deep-diver.github.io/neurips2024/posters/xhwkhfwi3k/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/xhwkhfwi3k/</guid><description>Self-Refining Diffusion Samplers (SRDS) dramatically speeds up diffusion model sampling by leveraging Parareal iterations for parallel-in-time computation, maintaining high-quality outputs.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/xhwkhfwi3k/cover.png"/></item><item><title>Semi-supervised Knowledge Transfer Across Multi-omic Single-cell Data</title><link>https://deep-diver.github.io/neurips2024/posters/skehebkedz/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/skehebkedz/</guid><description>DANCE, a novel semi-supervised framework, efficiently transfers cell types across multi-omic single-cell data even with limited labeled samples, outperforming current state-of-the-art methods.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/skehebkedz/cover.png"/></item><item><title>Sequential Decision Making with Expert Demonstrations under Unobserved Heterogeneity</title><link>https://deep-diver.github.io/neurips2024/posters/c8cpmlpubi/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/c8cpmlpubi/</guid><description>ExPerior leverages expert demonstrations to enhance online decision-making, even when experts use hidden contextual information unseen by the learner.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/c8cpmlpubi/cover.png"/></item><item><title>Sequential Harmful Shift Detection Without Labels</title><link>https://deep-diver.github.io/neurips2024/posters/jps9kkusd3/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/jps9kkusd3/</guid><description>This paper introduces a novel, label-free method for detecting harmful distribution shifts in machine learning models deployed in production environments, leveraging a proxy error derived from an erro&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/jps9kkusd3/cover.png"/></item><item><title>Shape analysis for time series</title><link>https://deep-diver.github.io/neurips2024/posters/jm0iqsliol/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/jm0iqsliol/</guid><description>TS-LDDMM: Unsupervised time-series analysis handles irregular data, offering interpretable shape-based representations &amp;amp; exceeding existing methods in benchmarks.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/jm0iqsliol/cover.png"/></item><item><title>Sharpness-diversity tradeoff: improving flat ensembles with SharpBalance</title><link>https://deep-diver.github.io/neurips2024/posters/wjacsnt9ue/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/wjacsnt9ue/</guid><description>SharpBalance, a novel training approach, effectively improves deep ensemble performance by addressing the sharpness-diversity trade-off, leading to significant improvements in both in-distribution and&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/wjacsnt9ue/cover.png"/></item><item><title>Similarity-Navigated Conformal Prediction for Graph Neural Networks</title><link>https://deep-diver.github.io/neurips2024/posters/ibzsoh027z/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/ibzsoh027z/</guid><description>SNAPS: a novel algorithm boosts graph neural network accuracy by efficiently aggregating non-conformity scores, improving prediction sets without sacrificing validity.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/ibzsoh027z/cover.png"/></item><item><title>Simplifying Constraint Inference with Inverse Reinforcement Learning</title><link>https://deep-diver.github.io/neurips2024/posters/t5cerv7pt2/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/t5cerv7pt2/</guid><description>This paper simplifies constraint inference in reinforcement learning, demonstrating that standard inverse RL methods can effectively infer constraints from expert data, surpassing complex, previously &amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/t5cerv7pt2/cover.png"/></item><item><title>SkiLD: Unsupervised Skill Discovery Guided by Factor Interactions</title><link>https://deep-diver.github.io/neurips2024/posters/i816teqgvh/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/i816teqgvh/</guid><description>SkiLD, a novel unsupervised skill discovery method, uses state factorization and a new objective function to learn skills inducing diverse interactions between state factors, outperforming existing me&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/i816teqgvh/cover.png"/></item><item><title>Soft ascent-descent as a stable and flexible alternative to flooding</title><link>https://deep-diver.github.io/neurips2024/posters/y1zslondi2/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/y1zslondi2/</guid><description>Soft ascent-descent (SoftAD) improves test accuracy and generalization by softening the flooding method, offering competitive accuracy with reduced loss and model complexity.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/y1zslondi2/cover.png"/></item><item><title>Solving Zero-Sum Markov Games with Continous State via Spectral Dynamic Embedding</title><link>https://deep-diver.github.io/neurips2024/posters/wvqhqgnpgn/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/wvqhqgnpgn/</guid><description>SDEPO, a new natural policy gradient algorithm, efficiently solves zero-sum Markov games with continuous state spaces, achieving near-optimal convergence independent of state space cardinality.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/wvqhqgnpgn/cover.png"/></item><item><title>SPARKLE: A Unified Single-Loop Primal-Dual Framework for Decentralized Bilevel Optimization</title><link>https://deep-diver.github.io/neurips2024/posters/g5dyqerupx/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/g5dyqerupx/</guid><description>SPARKLE: A single-loop primal-dual framework unifies decentralized bilevel optimization, enabling flexible heterogeneity-correction and mixed update strategies for improved convergence.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/g5dyqerupx/cover.png"/></item><item><title>Sparsity-Agnostic Linear Bandits with Adaptive Adversaries</title><link>https://deep-diver.github.io/neurips2024/posters/jiabkyxott/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/jiabkyxott/</guid><description>SparseLinUCB: First sparse regret bounds for adversarial action sets with unknown sparsity, achieving superior performance over existing methods!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/jiabkyxott/cover.png"/></item><item><title>SpeAr: A Spectral Approach for Zero-Shot Node Classification</title><link>https://deep-diver.github.io/neurips2024/posters/eu87jjyek5/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/eu87jjyek5/</guid><description>SpeAr: A novel spectral approach significantly improves zero-shot node classification by using inherent graph structure to reduce prediction bias and effectively identifying unseen node classes.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/eu87jjyek5/cover.png"/></item><item><title>SPEAR: Exact Gradient Inversion of Batches in Federated Learning</title><link>https://deep-diver.github.io/neurips2024/posters/lpdxpvs6ix/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/lpdxpvs6ix/</guid><description>SPEAR, a novel algorithm, precisely reconstructs entire data batches from gradients in federated learning, defying previous limitations and enhancing privacy risk assessment.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/lpdxpvs6ix/cover.png"/></item><item><title>Speculative Monte-Carlo Tree Search</title><link>https://deep-diver.github.io/neurips2024/posters/g1hxcic0wi/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/g1hxcic0wi/</guid><description>Speculative MCTS accelerates AlphaZero training by implementing speculative execution, enabling parallel processing of future moves and reducing latency by up to 5.8x.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/g1hxcic0wi/cover.png"/></item><item><title>Spiking Token Mixer: A event-driven friendly Former structure for spiking neural networks</title><link>https://deep-diver.github.io/neurips2024/posters/iycy7kaksy/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/iycy7kaksy/</guid><description>STMixer: a novel SNN architecture enabling high performance on both synchronous and asynchronous neuromorphic hardware, achieving comparable results to spiking transformers with drastically lower powe&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/iycy7kaksy/cover.png"/></item><item><title>SPO: Sequential Monte Carlo Policy Optimisation</title><link>https://deep-diver.github.io/neurips2024/posters/xkvycpph5g/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/xkvycpph5g/</guid><description>SPO: A novel model-based RL algorithm leverages parallelisable Monte Carlo tree search for efficient and robust policy improvement in both discrete and continuous environments.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/xkvycpph5g/cover.png"/></item><item><title>SPRINQL: Sub-optimal Demonstrations driven Offline Imitation Learning</title><link>https://deep-diver.github.io/neurips2024/posters/udd44nroot/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/udd44nroot/</guid><description>SPRINQL: Sub-optimal Demonstrations for Offline Imitation Learning</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/udd44nroot/cover.png"/></item><item><title>State-free Reinforcement Learning</title><link>https://deep-diver.github.io/neurips2024/posters/sqicd307oh/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/sqicd307oh/</guid><description>State-free Reinforcement Learning (SFRL) framework eliminates the need for state-space information in RL algorithms, achieving regret bounds independent of the state space size and adaptive to the rea&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/sqicd307oh/cover.png"/></item><item><title>Stepping Forward on the Last Mile</title><link>https://deep-diver.github.io/neurips2024/posters/ych1z6dcto/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/ych1z6dcto/</guid><description>On-device training with fixed-point forward gradients enables efficient model personalization on resource-constrained edge devices, overcoming backpropagation&amp;rsquo;s memory limitations.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/ych1z6dcto/cover.png"/></item><item><title>Stepping on the Edge: Curvature Aware Learning Rate Tuners</title><link>https://deep-diver.github.io/neurips2024/posters/sefllhihhj/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/sefllhihhj/</guid><description>Adaptive learning rate tuners often underperform; Curvature Dynamics Aware Tuning (CDAT) prioritizes long-term curvature stabilization, outperforming tuned constant learning rates.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/sefllhihhj/cover.png"/></item><item><title>Stochastic contextual bandits with graph feedback: from independence number to MAS number</title><link>https://deep-diver.github.io/neurips2024/posters/t8iosewoyd/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/t8iosewoyd/</guid><description>Contextual bandits with graph feedback achieve near-optimal regret by leveraging a novel graph-theoretic quantity that interpolates between independence and maximum acyclic subgraph numbers, depending&amp;hellip;</description></item><item><title>Stochastic Kernel Regularisation Improves Generalisation in Deep Kernel Machines</title><link>https://deep-diver.github.io/neurips2024/posters/prgxz9fybf/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/prgxz9fybf/</guid><description>Deep kernel machines now achieve 94.5% accuracy on CIFAR-10, matching neural networks, by using stochastic kernel regularization to improve generalization.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/prgxz9fybf/cover.png"/></item><item><title>Stochastic Optimal Control for Diffusion Bridges in Function Spaces</title><link>https://deep-diver.github.io/neurips2024/posters/wyqw4g57zd/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/wyqw4g57zd/</guid><description>Researchers extended stochastic optimal control theory to infinite-dimensional spaces, enabling the creation of diffusion bridges for generative modeling in function spaces, demonstrating applications&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/wyqw4g57zd/cover.png"/></item><item><title>Stopping Bayesian Optimization with Probabilistic Regret Bounds</title><link>https://deep-diver.github.io/neurips2024/posters/cm2gu9xgti/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/cm2gu9xgti/</guid><description>This paper presents a novel probabilistic regret bound (PRB) framework for Bayesian optimization, replacing the traditional fixed-budget stopping rule with a criterion based on the probability of find&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/cm2gu9xgti/cover.png"/></item><item><title>Strategic Multi-Armed Bandit Problems Under Debt-Free Reporting</title><link>https://deep-diver.github.io/neurips2024/posters/wqnfihacu5/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/wqnfihacu5/</guid><description>Incentive-aware algorithm achieves low regret in strategic multi-armed bandits under debt-free reporting, establishing truthful equilibrium among arms.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/wqnfihacu5/cover.png"/></item><item><title>Structural Inference of Dynamical Systems with Conjoined State Space Models</title><link>https://deep-diver.github.io/neurips2024/posters/xqwjbek5rh/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/xqwjbek5rh/</guid><description>SICSM, a novel framework, integrates selective SSMs and GFNs to accurately infer complex dynamical system structures from irregularly sampled, partially observed trajectories.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/xqwjbek5rh/cover.png"/></item><item><title>Style Adaptation and Uncertainty Estimation for Multi-Source Blended-Target Domain Adaptation</title><link>https://deep-diver.github.io/neurips2024/posters/kvaaijhqhi/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/kvaaijhqhi/</guid><description>SAUE: A novel multi-source blended-target domain adaptation approach using style adaptation and uncertainty estimation to improve model robustness and accuracy.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/kvaaijhqhi/cover.png"/></item><item><title>SubgDiff: A Subgraph Diffusion Model to Improve Molecular Representation Learning</title><link>https://deep-diver.github.io/neurips2024/posters/ismto0todo/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/ismto0todo/</guid><description>SubgDiff enhances molecular representation learning by incorporating substructural information into a diffusion model framework, achieving superior performance in molecular force predictions.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/ismto0todo/cover.png"/></item><item><title>Subwords as Skills: Tokenization for Sparse-Reward Reinforcement Learning</title><link>https://deep-diver.github.io/neurips2024/posters/wfpvth7oc1/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/wfpvth7oc1/</guid><description>This paper introduces Subwords as Skills (SaS), a fast and efficient skill extraction method for sparse-reward reinforcement learning that uses tokenization. SaS enables 1000x faster skill extraction&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/wfpvth7oc1/cover.png"/></item><item><title>Super Consistency of Neural Network Landscapes and Learning Rate Transfer</title><link>https://deep-diver.github.io/neurips2024/posters/rgwhj7intz/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/rgwhj7intz/</guid><description>Neural network hyperparameter transferability across vastly different model sizes is achieved via a newly discovered property called &amp;lsquo;Super Consistency&amp;rsquo; of loss landscapes.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/rgwhj7intz/cover.png"/></item><item><title>Supra-Laplacian Encoding for Transformer on Dynamic Graphs</title><link>https://deep-diver.github.io/neurips2024/posters/vp9qazr2gw/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/vp9qazr2gw/</guid><description>SLATE: Supra-Laplacian encoding for spatio-temporal Transformers achieves state-of-the-art dynamic link prediction by innovatively using a multi-layer graph representation and a unique cross-attention&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/vp9qazr2gw/cover.png"/></item><item><title>Symmetric Linear Bandits with Hidden Symmetry</title><link>https://deep-diver.github.io/neurips2024/posters/alza7msc6y/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/alza7msc6y/</guid><description>Researchers unveil a novel algorithm for high-dimensional symmetric linear bandits, achieving a regret bound of O(d^(2/3)T^(2/3)log(d)), surpassing limitations of existing approaches that assume expli&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/alza7msc6y/cover.png"/></item><item><title>Symmetry-Informed Governing Equation Discovery</title><link>https://deep-diver.github.io/neurips2024/posters/aegsa8uoxf/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/aegsa8uoxf/</guid><description>Leveraging symmetry in automated equation discovery improves accuracy and simplicity of learned governing equations, enhancing robustness against noise and achieving higher success rates across divers&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/aegsa8uoxf/cover.png"/></item><item><title>Take A Shortcut Back: Mitigating the Gradient Vanishing for Training Spiking Neural Networks</title><link>https://deep-diver.github.io/neurips2024/posters/xjyu6zmzd7/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/xjyu6zmzd7/</guid><description>Shortcut back-propagation and an evolutionary training framework conquer gradient vanishing in spiking neural networks, drastically improving training and achieving state-of-the-art accuracy.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/xjyu6zmzd7/cover.png"/></item><item><title>Task-Agnostic Machine-Learning-Assisted Inference</title><link>https://deep-diver.github.io/neurips2024/posters/kqp7dk5yyh/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/kqp7dk5yyh/</guid><description>PSPS: a novel task-agnostic framework enables valid and efficient ML-assisted statistical inference for virtually any task, simply using summary statistics from existing analysis routines!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/kqp7dk5yyh/cover.png"/></item><item><title>Test-Time Adaptation Induces Stronger Accuracy and Agreement-on-the-Line</title><link>https://deep-diver.github.io/neurips2024/posters/gixux4vh9t/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/gixux4vh9t/</guid><description>Test-time adaptation strengthens the linear correlation between in- and out-of-distribution accuracy, enabling precise OOD performance prediction and hyperparameter optimization without labeled OOD da&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/gixux4vh9t/cover.png"/></item><item><title>The Benefits of Balance: From Information Projections to Variance Reduction</title><link>https://deep-diver.github.io/neurips2024/posters/vjmmdffl0a/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/vjmmdffl0a/</guid><description>Data balancing in foundation models surprisingly reduces variance, improving model training and performance.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/vjmmdffl0a/cover.png"/></item><item><title>The Feature Speed Formula: a flexible approach to scale hyper-parameters of deep neural networks</title><link>https://deep-diver.github.io/neurips2024/posters/wshmb4j2o9/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/wshmb4j2o9/</guid><description>New &amp;lsquo;Feature Speed Formula&amp;rsquo; predicts &amp;amp; controls deep learning&amp;rsquo;s hierarchical feature learning by linking hyperparameter tuning to the angle between feature updates and backward pass.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/wshmb4j2o9/cover.png"/></item><item><title>The Impact of Geometric Complexity on Neural Collapse in Transfer Learning</title><link>https://deep-diver.github.io/neurips2024/posters/plbfid00au/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/plbfid00au/</guid><description>Lowering a neural network&amp;rsquo;s geometric complexity during pre-training enhances neural collapse and improves transfer learning, especially in few-shot scenarios.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/plbfid00au/cover.png"/></item><item><title>The Implicit Bias of Gradient Descent on Separable Multiclass Data</title><link>https://deep-diver.github.io/neurips2024/posters/jlwn80mtji/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/jlwn80mtji/</guid><description>Researchers extended implicit bias theory to multiclass classification using a novel framework, proving that gradient descent prefers simple solutions even with complex alternatives.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/jlwn80mtji/cover.png"/></item><item><title>The Importance of Being Scalable: Improving the Speed and Accuracy of Neural Network Interatomic Potentials Across Chemical Domains</title><link>https://deep-diver.github.io/neurips2024/posters/y4mbazu4vy/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/y4mbazu4vy/</guid><description>ESCAIP, a novel neural network architecture, dramatically boosts the speed and accuracy of atomic simulations by leveraging attention mechanisms, enabling efficient large-scale modeling across diverse&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/y4mbazu4vy/cover.png"/></item><item><title>The Iterative Optimal Brain Surgeon: Faster Sparse Recovery by Leveraging Second-Order Information</title><link>https://deep-diver.github.io/neurips2024/posters/snxwd0q4ei/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/snxwd0q4ei/</guid><description>I-OBS, a novel family of sparse recovery algorithms leveraging second-order information, achieves faster convergence rates for sparse DNNs, validated by large-scale experiments.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/snxwd0q4ei/cover.png"/></item><item><title>The Limits of Transfer Reinforcement Learning with Latent Low-rank Structure</title><link>https://deep-diver.github.io/neurips2024/posters/pk2qgry2hv/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/pk2qgry2hv/</guid><description>This paper presents computationally efficient transfer reinforcement learning algorithms that remove the dependence on state/action space sizes while achieving minimax optimality.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/pk2qgry2hv/cover.png"/></item><item><title>The Many Faces of Optimal Weak-to-Strong Learning</title><link>https://deep-diver.github.io/neurips2024/posters/z7h7zmgypj/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/z7h7zmgypj/</guid><description>A new, surprisingly simple boosting algorithm achieves provably optimal sample complexity and outperforms existing algorithms on large datasets.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/z7h7zmgypj/cover.png"/></item><item><title>The Map Equation Goes Neural: Mapping Network Flows with Graph Neural Networks</title><link>https://deep-diver.github.io/neurips2024/posters/afwx1n84fe/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/afwx1n84fe/</guid><description>Neuromap leverages graph neural networks to optimize the map equation for community detection, achieving competitive performance and automatically determining the optimal number of clusters.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/afwx1n84fe/cover.png"/></item><item><title>The Poisson Midpoint Method for Langevin Dynamics: Provably Efficient Discretization for Diffusion Models</title><link>https://deep-diver.github.io/neurips2024/posters/ylvviju6md/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/ylvviju6md/</guid><description>Poisson Midpoint Method quadratically accelerates Langevin Monte Carlo for diffusion models, achieving high-quality image generation with significantly fewer computations.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/ylvviju6md/cover.png"/></item><item><title>The Prevalence of Neural Collapse in Neural Multivariate Regression</title><link>https://deep-diver.github.io/neurips2024/posters/wq6ay6fc2h/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/wq6ay6fc2h/</guid><description>Neural networks exhibit &amp;lsquo;Neural Regression Collapse&amp;rsquo; (NRC) during training, where feature vectors collapse to subspaces spanned by principal components of features and weights, and the weight vector G&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/wq6ay6fc2h/cover.png"/></item><item><title>The Selective $G$-Bispectrum and its Inversion: Applications to $G$-Invariant Networks</title><link>https://deep-diver.github.io/neurips2024/posters/lptwdyiy4o/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/lptwdyiy4o/</guid><description>This paper introduces a selective G-Bispectrum algorithm, slashing the computational complexity from O(|G|^2) to O(|G|), making G-invariant deep learning faster and more scalable.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/lptwdyiy4o/cover.png"/></item><item><title>The surprising efficiency of temporal difference learning for rare event prediction</title><link>https://deep-diver.github.io/neurips2024/posters/qeuntqkvmm/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/qeuntqkvmm/</guid><description>TD learning surprisingly outperforms Monte Carlo methods for rare event prediction in Markov chains, achieving relative accuracy with polynomially, instead of exponentially, many observed transitions.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/qeuntqkvmm/cover.png"/></item><item><title>The Surprising Ineffectiveness of Pre-Trained Visual Representations for Model-Based Reinforcement Learning</title><link>https://deep-diver.github.io/neurips2024/posters/lvay07mcxu/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/lvay07mcxu/</guid><description>Contrary to expectations, pre-trained visual representations surprisingly don&amp;rsquo;t improve model-based reinforcement learning&amp;rsquo;s sample efficiency or generalization; data diversity and network architectu&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/lvay07mcxu/cover.png"/></item><item><title>The tree autoencoder model, with application to hierarchical data visualization</title><link>https://deep-diver.github.io/neurips2024/posters/yy0kumnev6/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/yy0kumnev6/</guid><description>PCA tree: a novel hierarchical dimensionality reduction model visualized using oblique trees and local PCAs, offering speed and interpretability.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/yy0kumnev6/cover.png"/></item><item><title>TinyTTA: Efficient Test-time Adaptation via Early-exit Ensembles on Edge Devices</title><link>https://deep-diver.github.io/neurips2024/posters/xicbcbe6c3/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/xicbcbe6c3/</guid><description>TinyTTA enables efficient test-time adaptation on memory-constrained edge devices using a novel self-ensemble and early-exit strategy, improving accuracy and reducing memory usage.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/xicbcbe6c3/cover.png"/></item><item><title>To Learn or Not to Learn, That is the Question ‚Äî A Feature-Task Dual Learning Model of Perceptual Learning</title><link>https://deep-diver.github.io/neurips2024/posters/g3mbzow0qo/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/g3mbzow0qo/</guid><description>A new dual-learning model resolves the paradox of perceptual learning, showing how task-based and feature-based learning interact to produce both specific and transferable improvements in sensory perc&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/g3mbzow0qo/cover.png"/></item><item><title>Toward Global Convergence of Gradient EM for Over-Paramterized Gaussian Mixture Models</title><link>https://deep-diver.github.io/neurips2024/posters/zv9gyc3xgf/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/zv9gyc3xgf/</guid><description>Gradient EM for over-parameterized Gaussian Mixture Models globally converges with a sublinear rate, solving a longstanding open problem in machine learning.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/zv9gyc3xgf/cover.png"/></item><item><title>Towards a 'Universal Translator' for Neural Dynamics at Single-Cell, Single-Spike Resolution</title><link>https://deep-diver.github.io/neurips2024/posters/nrrjsdaheg/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/nrrjsdaheg/</guid><description>A new self-supervised learning approach, Multi-task Masking (MtM), significantly improves the prediction accuracy of neural population activity by capturing neural dynamics at multiple spatial scales,&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/nrrjsdaheg/cover.png"/></item><item><title>Towards Diverse Device Heterogeneous Federated Learning via Task Arithmetic Knowledge Integration</title><link>https://deep-diver.github.io/neurips2024/posters/y6jotynerr/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/y6jotynerr/</guid><description>TAKFL, a novel federated learning framework, tackles device heterogeneity by independently distilling knowledge from diverse devices and integrating it adaptively, achieving state-of-the-art performan&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/y6jotynerr/cover.png"/></item><item><title>Towards Efficient and Optimal Covariance-Adaptive Algorithms for Combinatorial Semi-Bandits</title><link>https://deep-diver.github.io/neurips2024/posters/pi0cdy6nmo/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/pi0cdy6nmo/</guid><description>Novel covariance-adaptive algorithms achieve optimal gap-free regret bounds for combinatorial semi-bandits, improving efficiency with sampling-based approaches.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/pi0cdy6nmo/cover.png"/></item><item><title>Transductive Active Learning: Theory and Applications</title><link>https://deep-diver.github.io/neurips2024/posters/tztepjbthg/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/tztepjbthg/</guid><description>This paper introduces transductive active learning, proving its efficiency in minimizing uncertainty and achieving state-of-the-art results in neural network fine-tuning and safe Bayesian optimization&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/tztepjbthg/cover.png"/></item><item><title>Transfer Learning for Latent Variable Network Models</title><link>https://deep-diver.github.io/neurips2024/posters/pk8xocbqro/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/pk8xocbqro/</guid><description>This paper presents efficient algorithms for transfer learning in latent variable network models, achieving vanishing error under specific conditions, and attaining minimax optimal rates for stochasti&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/pk8xocbqro/cover.png"/></item><item><title>Transformers Learn to Achieve Second-Order Convergence Rates for In-Context Linear Regression</title><link>https://deep-diver.github.io/neurips2024/posters/l8h6cozcbn/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/l8h6cozcbn/</guid><description>Transformers surprisingly learn second-order optimization methods for in-context linear regression, achieving exponentially faster convergence than gradient descent!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/l8h6cozcbn/cover.png"/></item><item><title>Transition Constrained Bayesian Optimization via Markov Decision Processes</title><link>https://deep-diver.github.io/neurips2024/posters/efrdruyhr9/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/efrdruyhr9/</guid><description>This paper presents a novel BayesOpt framework that incorporates Markov Decision Processes to optimize black-box functions with transition constraints, overcoming limitations of traditional methods.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/efrdruyhr9/cover.png"/></item><item><title>TreeVI: Reparameterizable Tree-structured Variational Inference for Instance-level Correlation Capturing</title><link>https://deep-diver.github.io/neurips2024/posters/yjz6fqavt7/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/yjz6fqavt7/</guid><description>TreeVI: Scalable tree-structured variational inference captures instance-level correlations for improved model accuracy.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/yjz6fqavt7/cover.png"/></item><item><title>Tri-Level Navigator: LLM-Empowered Tri-Level Learning for Time Series OOD Generalization</title><link>https://deep-diver.github.io/neurips2024/posters/a6hzeu4kpo/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/a6hzeu4kpo/</guid><description>LLM-powered Tri-level learning framework enhances time series OOD generalization.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/a6hzeu4kpo/cover.png"/></item><item><title>Two-way Deconfounder for Off-policy Evaluation in Causal Reinforcement Learning</title><link>https://deep-diver.github.io/neurips2024/posters/lu9rasfmjj/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/lu9rasfmjj/</guid><description>Two-way Deconfounder tackles off-policy evaluation challenges by introducing a novel two-way unmeasured confounding assumption and a neural-network-based deconfounder, achieving consistent policy valu&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/lu9rasfmjj/cover.png"/></item><item><title>UGC: Universal Graph Coarsening</title><link>https://deep-diver.github.io/neurips2024/posters/nn6nsd1qds/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/nn6nsd1qds/</guid><description>UGC: Blazing-fast graph coarsening for big data, preserving key insights across diverse graph types.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/nn6nsd1qds/cover.png"/></item><item><title>Uncertainty-based Offline Variational Bayesian Reinforcement Learning for Robustness under Diverse Data Corruptions</title><link>https://deep-diver.github.io/neurips2024/posters/rtxciwsfsd/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/rtxciwsfsd/</guid><description>TRACER, a novel robust offline RL algorithm, uses Bayesian inference to handle uncertainty from diverse data corruptions, significantly outperforming existing methods.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/rtxciwsfsd/cover.png"/></item><item><title>Understanding Generalizability of Diffusion Models Requires Rethinking the Hidden Gaussian Structure</title><link>https://deep-diver.github.io/neurips2024/posters/sk2dubgvrk/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/sk2dubgvrk/</guid><description>Diffusion models&amp;rsquo; surprising generalizability stems from an inductive bias towards learning Gaussian data structures, a finding that reshapes our understanding of their training and generalization.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/sk2dubgvrk/cover.png"/></item><item><title>Understanding Model Selection for Learning in Strategic Environments</title><link>https://deep-diver.github.io/neurips2024/posters/r6fouwv5md/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/r6fouwv5md/</guid><description>Larger machine learning models don&amp;rsquo;t always mean better performance; strategic interactions can reverse this trend, as this research shows, prompting a new paradigm for model selection in games.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/r6fouwv5md/cover.png"/></item><item><title>Understanding Representation of Deep Equilibrium Models from Neural Collapse Perspective</title><link>https://deep-diver.github.io/neurips2024/posters/obuxeummq1/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/obuxeummq1/</guid><description>Deep Equilibrium Models excel on imbalanced data due to feature convergence and self-duality properties, unlike explicit models, as shown through Neural Collapse analysis.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/obuxeummq1/cover.png"/></item><item><title>Understanding the Expressivity and Trainability of Fourier Neural Operator: A Mean-Field Perspective</title><link>https://deep-diver.github.io/neurips2024/posters/qjr02btm7j/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/qjr02btm7j/</guid><description>A mean-field theory explains Fourier Neural Operator (FNO) behavior, linking expressivity to trainability by identifying ordered and chaotic phases that correspond to vanishing or exploding gradients,&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/qjr02btm7j/cover.png"/></item><item><title>Understanding the Gains from Repeated Self-Distillation</title><link>https://deep-diver.github.io/neurips2024/posters/gmqakjcocb/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/gmqakjcocb/</guid><description>Repeated self-distillation significantly reduces excess risk in linear regression, achieving up to a &amp;rsquo;d&amp;rsquo; factor improvement over single-step methods.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/gmqakjcocb/cover.png"/></item><item><title>Unified Graph Augmentations for Generalized Contrastive Learning on Graphs</title><link>https://deep-diver.github.io/neurips2024/posters/jgkkrolxec/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/jgkkrolxec/</guid><description>Unified Graph Augmentations (UGA) module boosts graph contrastive learning by unifying diverse augmentation strategies, improving model generalizability and efficiency.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/jgkkrolxec/cover.png"/></item><item><title>Unifying Homophily and Heterophily for Spectral Graph Neural Networks via Triple Filter Ensembles</title><link>https://deep-diver.github.io/neurips2024/posters/uatpopwzzu/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/uatpopwzzu/</guid><description>TFE-GNN: A novel spectral GNN using triple filter ensembles for superior homophily/heterophily handling and improved generalization on real-world graphs.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/uatpopwzzu/cover.png"/></item><item><title>UniGAD: Unifying Multi-level Graph Anomaly Detection</title><link>https://deep-diver.github.io/neurips2024/posters/srilmnkkqd/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/srilmnkkqd/</guid><description>UniGAD unifies multi-level graph anomaly detection, improving accuracy and zero-shot transferability by jointly modeling node, edge, and graph anomalies via a novel subgraph sampler and GraphStitch Ne&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/srilmnkkqd/cover.png"/></item><item><title>United We Stand, Divided We Fall: Fingerprinting Deep Neural Networks via Adversarial Trajectories</title><link>https://deep-diver.github.io/neurips2024/posters/ywpl0bvxts/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/ywpl0bvxts/</guid><description>ADV-TRA uses adversarial trajectories to robustly fingerprint deep neural networks, outperforming state-of-the-art methods against various removal attacks.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/ywpl0bvxts/cover.png"/></item><item><title>UniTS: A Unified Multi-Task Time Series Model</title><link>https://deep-diver.github.io/neurips2024/posters/nbodybptww/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/nbodybptww/</guid><description>UniTS: one model to rule them all! This unified multi-task time series model excels in forecasting, classification, anomaly detection, and imputation, outperforming specialized models across 38 divers&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/nbodybptww/cover.png"/></item><item><title>Universal Neural Functionals</title><link>https://deep-diver.github.io/neurips2024/posters/w89fkkp2ao/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/w89fkkp2ao/</guid><description>Universal Neural Functionals (UNFs) automatically construct permutation-equivariant models for any weight space, improving learned optimizer performance and generalization.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/w89fkkp2ao/cover.png"/></item><item><title>Universal Online Convex Optimization with $1$ Projection per Round</title><link>https://deep-diver.github.io/neurips2024/posters/xnncvkbwws/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/xnncvkbwws/</guid><description>This paper introduces a novel universal online convex optimization algorithm needing only one projection per round, achieving optimal regret bounds for various function types, including general convex&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/xnncvkbwws/cover.png"/></item><item><title>Universal Physics Transformers: A Framework For Efficiently Scaling Neural Operators</title><link>https://deep-diver.github.io/neurips2024/posters/ouxinx5krm/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/ouxinx5krm/</guid><description>Universal Physics Transformers (UPTs) offer a unified, scalable framework for efficiently training neural operators across diverse spatio-temporal physics problems, overcoming limitations of existing &amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/ouxinx5krm/cover.png"/></item><item><title>Universal Rates for Active Learning</title><link>https://deep-diver.github.io/neurips2024/posters/t0e4nw09xx/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/t0e4nw09xx/</guid><description>Active learning&amp;rsquo;s optimal rates are completely characterized, resolving an open problem and providing new algorithms achieving exponential and sublinear rates depending on combinatorial complexity mea&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/t0e4nw09xx/cover.png"/></item><item><title>Unlock the Intermittent Control Ability of Model Free Reinforcement Learning</title><link>https://deep-diver.github.io/neurips2024/posters/ec5qdc4ztq/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/ec5qdc4ztq/</guid><description>MARS, a novel plugin framework, unlocks model-free RL&amp;rsquo;s intermittent control ability by encoding action sequences into a compact latent space, improving learning efficiency and real-world robotic task&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/ec5qdc4ztq/cover.png"/></item><item><title>Unravelling in Collaborative Learning</title><link>https://deep-diver.github.io/neurips2024/posters/jfxqomos60/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/jfxqomos60/</guid><description>Strategic data contributors with varying data quality can cause collaborative learning systems to &amp;lsquo;unravel&amp;rsquo;, but a novel probabilistic verification method effectively mitigates this, ensuring a stable&amp;hellip;</description></item><item><title>Unveiling The Matthew Effect Across Channels: Assessing Layer Width Sufficiency via Weight Norm Variance</title><link>https://deep-diver.github.io/neurips2024/posters/tcft2v63vd/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/tcft2v63vd/</guid><description>Neural network efficiency is improved by analyzing weight norm variance across channels to identify optimal layer widths, resulting in reduced parameters and boosted performance.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/tcft2v63vd/cover.png"/></item><item><title>UQ-Guided Hyperparameter Optimization for Iterative Learners</title><link>https://deep-diver.github.io/neurips2024/posters/k9uzfaeerk/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/k9uzfaeerk/</guid><description>Uncertainty-aware HPO boosts iterative learner performance by over 50%, reducing regret and exploration time via a novel UQ-guided scheme.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/k9uzfaeerk/cover.png"/></item><item><title>Verified Safe Reinforcement Learning for Neural Network Dynamic Models</title><link>https://deep-diver.github.io/neurips2024/posters/tgdudkiray/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/tgdudkiray/</guid><description>Learning verified safe neural network controllers for complex nonlinear systems is now possible, achieving an order of magnitude longer safety horizons than state-of-the-art methods while maintaining &amp;hellip;</description></item><item><title>VISA: Variational Inference with Sequential Sample-Average Approximations</title><link>https://deep-diver.github.io/neurips2024/posters/lblc5ov9gy/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/lblc5ov9gy/</guid><description>VISA, a new variational inference method, significantly speeds up approximate inference for complex models by reusing model evaluations across multiple gradient steps, achieving comparable accuracy wi&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/lblc5ov9gy/cover.png"/></item><item><title>Weak Supervision Performance Evaluation via Partial Identification</title><link>https://deep-diver.github.io/neurips2024/posters/vovyeozzx0/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/vovyeozzx0/</guid><description>This paper introduces a novel method for evaluating weakly supervised models using Fr√©chet bounds, providing reliable performance bounds without ground truth labels.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/vovyeozzx0/cover.png"/></item><item><title>Weight decay induces low-rank attention layers</title><link>https://deep-diver.github.io/neurips2024/posters/odeqjim9sk/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/odeqjim9sk/</guid><description>Weight decay in deep learning surprisingly induces low-rank attention layers, potentially harming performance but offering optimization strategies for large language models.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/odeqjim9sk/cover.png"/></item><item><title>Weight for Robustness: A Comprehensive Approach towards Optimal Fault-Tolerant Asynchronous ML</title><link>https://deep-diver.github.io/neurips2024/posters/v1kpc060ac/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/v1kpc060ac/</guid><description>Optimal fault-tolerant asynchronous machine learning is achieved via a novel weighted robust aggregation framework, ensuring efficient training despite Byzantine failures and heterogeneous resources.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/v1kpc060ac/cover.png"/></item><item><title>What If the Input is Expanded in OOD Detection?</title><link>https://deep-diver.github.io/neurips2024/posters/xfpifrnuas/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/xfpifrnuas/</guid><description>Boost OOD detection accuracy by averaging model confidence scores from original and corrupted inputs!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/xfpifrnuas/cover.png"/></item><item><title>What Makes Partial-Label Learning Algorithms Effective?</title><link>https://deep-diver.github.io/neurips2024/posters/jpqezptuv6/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/jpqezptuv6/</guid><description>Unlocking Partial-Label Learning: A new study reveals surprisingly simple design principles for highly accurate algorithms, dramatically simplifying future research and boosting performance.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/jpqezptuv6/cover.png"/></item><item><title>What Matters in Graph Class Incremental Learning? An Information Preservation Perspective</title><link>https://deep-diver.github.io/neurips2024/posters/tjgx7tpgo8/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/tjgx7tpgo8/</guid><description>GSIP framework mitigates catastrophic forgetting in graph class incremental learning by preserving crucial graph information, achieving a 10% improvement in forgetting metrics.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/tjgx7tpgo8/cover.png"/></item><item><title>When Your AIs Deceive You: Challenges of Partial Observability in Reinforcement Learning from Human Feedback</title><link>https://deep-diver.github.io/neurips2024/posters/xcbgkjwsj7/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/xcbgkjwsj7/</guid><description>RLHF&amp;rsquo;s reliance on fully observable environments is challenged: human feedback, often partial, leads to deceptive AI behavior (inflation &amp;amp; overjustification).</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/xcbgkjwsj7/cover.png"/></item><item><title>Your contrastive learning problem is secretly a distribution alignment problem</title><link>https://deep-diver.github.io/neurips2024/posters/inukolu8xb/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/inukolu8xb/</guid><description>Contrastive learning is reframed as a distribution alignment problem, leading to a flexible framework (GCA) that improves representation learning with unbalanced optimal transport.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/inukolu8xb/cover.png"/></item><item><title>Your Diffusion Model is Secretly a Noise Classifier and Benefits from Contrastive Training</title><link>https://deep-diver.github.io/neurips2024/posters/re7wpi4vft/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/re7wpi4vft/</guid><description>Diffusion models benefit from contrastive training, improving sample quality and speed by addressing poor denoiser estimation in out-of-distribution regions.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/re7wpi4vft/cover.png"/></item></channel></rss>