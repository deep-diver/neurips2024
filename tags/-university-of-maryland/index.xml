<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>üè¢ University of Maryland on NeurIPS 2024</title><link>https://deep-diver.github.io/neurips2024/tags/-university-of-maryland/</link><description>Recent content in üè¢ University of Maryland on NeurIPS 2024</description><generator>Hugo -- gohugo.io</generator><language>en</language><copyright>¬© 2025 AI Paper Reviewer</copyright><lastBuildDate>Thu, 26 Sep 2024 00:00:00 +0000</lastBuildDate><atom:link href="https://deep-diver.github.io/neurips2024/tags/-university-of-maryland/index.xml" rel="self" type="application/rss+xml"/><item><title>Ad Auctions for LLMs via Retrieval Augmented Generation</title><link>https://deep-diver.github.io/neurips2024/posters/ujo8v7ixmr/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/ujo8v7ixmr/</guid><description>This paper introduces segment auctions, maximizing logarithmic social welfare, for integrating ads into LLM outputs via Retrieval Augmented Generation, balancing ad revenue and output quality.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/ujo8v7ixmr/cover.png"/></item><item><title>Be like a Goldfish, Don't Memorize! Mitigating Memorization in Generative LLMs</title><link>https://deep-diver.github.io/neurips2024/posters/dylsyafmws/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/dylsyafmws/</guid><description>Goldfish Loss: A novel training method for LLMs dramatically reduces memorization without impacting performance, addressing key safety, privacy, and copyright concerns.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/dylsyafmws/cover.png"/></item><item><title>Boosting Sample Efficiency and Generalization in Multi-agent Reinforcement Learning via Equivariance</title><link>https://deep-diver.github.io/neurips2024/posters/mqiet1vfov/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/mqiet1vfov/</guid><description>Equivariant Graph Neural Networks boost multi-agent reinforcement learning by improving sample efficiency and generalization, overcoming inherent exploration biases.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/mqiet1vfov/cover.png"/></item><item><title>Differentiable Quantum Computing for Large-scale Linear Control</title><link>https://deep-diver.github.io/neurips2024/posters/ghqw3xlavd/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/ghqw3xlavd/</guid><description>Quantum algorithm achieves super-quadratic speedup for large-scale linear control, offering a novel approach to address the computational challenges of optimizing complex dynamical systems.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/ghqw3xlavd/cover.png"/></item><item><title>DMesh: A Differentiable Mesh Representation</title><link>https://deep-diver.github.io/neurips2024/posters/io1qkqcvik/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/io1qkqcvik/</guid><description>DMesh: A novel differentiable mesh representation enabling efficient gradient-based optimization for diverse 3D shape applications.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/io1qkqcvik/cover.png"/></item><item><title>Dueling over Dessert, Mastering the Art of Repeated Cake Cutting</title><link>https://deep-diver.github.io/neurips2024/posters/mftvnzhsht/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/mftvnzhsht/</guid><description>Repeated cake-cutting game reveals that strategic players can exploit myopic opponents, but equitable outcomes are achievable through specific strategies.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/mftvnzhsht/cover.png"/></item><item><title>Estimating Epistemic and Aleatoric Uncertainty with a Single Model</title><link>https://deep-diver.github.io/neurips2024/posters/wpxa6ocidg/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/wpxa6ocidg/</guid><description>HyperDM accurately estimates both epistemic and aleatoric uncertainty using a single model, overcoming the computational limitations of existing ensemble methods.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/wpxa6ocidg/cover.png"/></item><item><title>FACT or Fiction: Can Truthful Mechanisms Eliminate Federated Free Riding?</title><link>https://deep-diver.github.io/neurips2024/posters/jirgxrqhh0/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/jirgxrqhh0/</guid><description>FACT, a novel federated learning mechanism, eliminates free-riding and incentivizes truthful agent behavior by introducing a penalty system and a competitive environment, boosting model performance si&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/jirgxrqhh0/cover.png"/></item><item><title>Fairness and Efficiency in Online Class Matching</title><link>https://deep-diver.github.io/neurips2024/posters/kmaxn7hf6d/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/kmaxn7hf6d/</guid><description>First non-wasteful algorithm achieving 1/2-approximation for class envy-freeness, class proportionality, and utilitarian social welfare in online class matching.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/kmaxn7hf6d/cover.png"/></item><item><title>FLoRA: Federated Fine-Tuning Large Language Models with Heterogeneous Low-Rank Adaptations</title><link>https://deep-diver.github.io/neurips2024/posters/tccorxxnjq/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/tccorxxnjq/</guid><description>FLORA enables efficient &amp;amp; private federated fine-tuning of LLMs via novel stacking-based heterogeneous low-rank adaptation, surpassing existing methods.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/tccorxxnjq/cover.png"/></item><item><title>Inevitable Trade-off between Watermark Strength and Speculative Sampling Efficiency for Language Models</title><link>https://deep-diver.github.io/neurips2024/posters/6ykmbuiisg/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/6ykmbuiisg/</guid><description>Injecting watermarks into LLM outputs while speeding up generation is impossible; this paper proves this trade-off and offers methods prioritizing either watermark strength or speed.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/6ykmbuiisg/cover.png"/></item><item><title>Loki: Low-rank Keys for Efficient Sparse Attention</title><link>https://deep-diver.github.io/neurips2024/posters/raabeiv71j/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/raabeiv71j/</guid><description>Loki: Low-rank Keys for Efficient Sparse Attention accelerates attention mechanisms in LLMs by exploiting the low-dimensionality of key vectors. It dynamically selects key tokens based on approximate&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/raabeiv71j/cover.png"/></item><item><title>Model Reconstruction Using Counterfactual Explanations: A Perspective From Polytope Theory</title><link>https://deep-diver.github.io/neurips2024/posters/9uoldxbylm/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/9uoldxbylm/</guid><description>Counterfactual Clamping Attack (CCA) improves model reconstruction using counterfactual explanations by leveraging decision boundary proximity, offering theoretical guarantees and enhanced fidelity.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/9uoldxbylm/cover.png"/></item><item><title>QUEEN: QUantized Efficient ENcoding for Streaming Free-viewpoint Videos</title><link>https://deep-diver.github.io/neurips2024/posters/7xhwe7vh4s/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/7xhwe7vh4s/</guid><description>QUEEN: A novel framework for quantized and efficient streaming of free-viewpoint videos achieving high compression, quality, and speed.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/7xhwe7vh4s/cover.png"/></item><item><title>SHED: Shapley-Based Automated Dataset Refinement for Instruction Fine-Tuning</title><link>https://deep-diver.github.io/neurips2024/posters/gqou8prgwq/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/gqou8prgwq/</guid><description>SHED, a Shapley value-based framework, efficiently refines instruction-tuning datasets for LLMs, producing high-performing subsets, only 10% of original size, that transfer well across different model&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/gqou8prgwq/cover.png"/></item><item><title>Temporally Consistent Atmospheric Turbulence Mitigation with Neural Representations</title><link>https://deep-diver.github.io/neurips2024/posters/yurca4wi2l/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/yurca4wi2l/</guid><description>ConVRT: A novel framework restores turbulence-distorted videos by decoupling spatial and temporal information in a neural representation, achieving temporally consistent mitigation.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/yurca4wi2l/cover.png"/></item><item><title>Transformers Can Do Arithmetic with the Right Embeddings</title><link>https://deep-diver.github.io/neurips2024/posters/aiynlwxudo/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/aiynlwxudo/</guid><description>Researchers enhanced transformer performance on arithmetic tasks by introducing Abacus Embeddings, which encode each digit&amp;rsquo;s position, enabling improved generalization and unlocking multi-step reasoni&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/aiynlwxudo/cover.png"/></item><item><title>Why Warmup the Learning Rate? Underlying Mechanisms and Improvements</title><link>https://deep-diver.github.io/neurips2024/posters/nvl4samz5c/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/nvl4samz5c/</guid><description>Deep learning&amp;rsquo;s learning rate warmup improves performance by allowing larger learning rates, pushing networks to better-conditioned loss landscape areas.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/nvl4samz5c/cover.png"/></item></channel></rss>