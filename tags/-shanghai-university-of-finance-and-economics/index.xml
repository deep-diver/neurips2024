<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>üè¢ Shanghai University of Finance and Economics on NeurIPS 2024</title><link>https://deep-diver.github.io/neurips2024/tags/-shanghai-university-of-finance-and-economics/</link><description>Recent content in üè¢ Shanghai University of Finance and Economics on NeurIPS 2024</description><generator>Hugo -- gohugo.io</generator><language>en</language><copyright>¬© 2024 AI Paper Reviewer</copyright><lastBuildDate>Thu, 26 Sep 2024 00:00:00 +0000</lastBuildDate><atom:link href="https://deep-diver.github.io/neurips2024/tags/-shanghai-university-of-finance-and-economics/index.xml" rel="self" type="application/rss+xml"/><item><title>Cherry on Top: Parameter Heterogeneity and Quantization in Large Language Models</title><link>https://deep-diver.github.io/neurips2024/posters/qaiklacrkj/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/qaiklacrkj/</guid><description>CherryQ, a novel quantization method, leverages parameter heterogeneity in LLMs to achieve superior performance by selectively quantizing less critical parameters while preserving essential ones.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/qaiklacrkj/cover.png"/></item><item><title>Faster Accelerated First-order Methods for Convex Optimization with Strongly Convex Function Constraints</title><link>https://deep-diver.github.io/neurips2024/posters/pg380vlyru/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/pg380vlyru/</guid><description>Faster primal-dual algorithms achieve order-optimal complexity for convex optimization with strongly convex constraints, improving convergence rates and solving large-scale problems efficiently.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/pg380vlyru/cover.png"/></item><item><title>Safe and Sparse Newton Method for Entropic-Regularized Optimal Transport</title><link>https://deep-diver.github.io/neurips2024/posters/nmmiyjw7xg/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/nmmiyjw7xg/</guid><description>A novel safe &amp;amp; sparse Newton method (SSNS) for entropic-regularized optimal transport boasts strict error control, avoids singularity, needs no hyperparameter tuning, and offers rigorous convergence a&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/nmmiyjw7xg/cover.png"/></item><item><title>Two-way Deconfounder for Off-policy Evaluation in Causal Reinforcement Learning</title><link>https://deep-diver.github.io/neurips2024/posters/lu9rasfmjj/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/lu9rasfmjj/</guid><description>Two-way Deconfounder tackles off-policy evaluation challenges by introducing a novel two-way unmeasured confounding assumption and a neural-network-based deconfounder, achieving consistent policy valu&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/lu9rasfmjj/cover.png"/></item></channel></rss>