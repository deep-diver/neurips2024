<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Computer Vision on NeurIPS 2024</title><link>https://deep-diver.github.io/neurips2024/tags/computer-vision/</link><description>Recent content in Computer Vision on NeurIPS 2024</description><generator>Hugo -- gohugo.io</generator><language>en</language><copyright>© 2024 AI Paper Reviewer</copyright><lastBuildDate>Thu, 26 Sep 2024 00:00:00 +0000</lastBuildDate><atom:link href="https://deep-diver.github.io/neurips2024/tags/computer-vision/index.xml" rel="self" type="application/rss+xml"/><item><title>$ ext{ID}^3$: Identity-Preserving-yet-Diversified Diffusion Models for Synthetic Face Recognition</title><link>https://deep-diver.github.io/neurips2024/posters/x4hmnqs6ie/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/x4hmnqs6ie/</guid><description>ID³: A novel diffusion model generates diverse, identity-preserving synthetic face datasets for accurate and privacy-preserving face recognition, exceeding current state-of-the-art methods.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/x4hmnqs6ie/cover.png"/></item><item><title>$SE(3)$ Equivariant Ray Embeddings for Implicit Multi-View Depth Estimation</title><link>https://deep-diver.github.io/neurips2024/posters/yrujqowocs/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/yrujqowocs/</guid><description>SE(3)-equivariant ray embeddings in Perceiver IO achieve state-of-the-art implicit multi-view depth estimation, surpassing methods that rely on data augmentation for approximate equivariance.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/yrujqowocs/cover.png"/></item><item><title>3D Equivariant Pose Regression via Direct Wigner-D Harmonics Prediction</title><link>https://deep-diver.github.io/neurips2024/posters/nw8cxonvep/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/nw8cxonvep/</guid><description>3D pose estimation is revolutionized by a novel SO(3)-equivariant network directly predicting Wigner-D harmonics, achieving state-of-the-art accuracy and efficiency.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/nw8cxonvep/cover.png"/></item><item><title>3D Gaussian Rendering Can Be Sparser: Efficient Rendering via Learned Fragment Pruning</title><link>https://deep-diver.github.io/neurips2024/posters/ivqzbulfol/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/ivqzbulfol/</guid><description>Learned fragment pruning accelerates 3D Gaussian splatting rendering by selectively removing fragments, achieving up to 1.71x speedup on edge GPUs and 0.16 PSNR improvement.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/ivqzbulfol/cover.png"/></item><item><title>3DET-Mamba: Causal Sequence Modelling for End-to-End 3D Object Detection</title><link>https://deep-diver.github.io/neurips2024/posters/ioleslc80f/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/ioleslc80f/</guid><description>3DET-Mamba: A novel end-to-end 3D object detector leveraging the Mamba state space model for efficient and accurate object detection in complex indoor scenes, outperforming previous 3DETR models.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/ioleslc80f/cover.png"/></item><item><title>4Diffusion: Multi-view Video Diffusion Model for 4D Generation</title><link>https://deep-diver.github.io/neurips2024/posters/sfk7ampyhx/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/sfk7ampyhx/</guid><description>4Diffusion generates high-quality, temporally consistent 4D content from monocular videos using a unified multi-view diffusion model and novel loss functions.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/sfk7ampyhx/cover.png"/></item><item><title>4Real: Towards Photorealistic 4D Scene Generation via Video Diffusion Models</title><link>https://deep-diver.github.io/neurips2024/posters/so1arpwvlk/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/so1arpwvlk/</guid><description>4Real: Photorealistic 4D scene generation from text prompts using video diffusion models, exceeding object-centric approaches for higher realism and efficiency.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/so1arpwvlk/cover.png"/></item><item><title>A Consistency-Aware Spot-Guided Transformer for Versatile and Hierarchical Point Cloud Registration</title><link>https://deep-diver.github.io/neurips2024/posters/btllwaorfs/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/btllwaorfs/</guid><description>CAST: a novel consistency-aware spot-guided Transformer achieves state-of-the-art accuracy and efficiency in point cloud registration.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/btllwaorfs/cover.png"/></item><item><title>A Label is Worth A Thousand Images in Dataset Distillation</title><link>https://deep-diver.github.io/neurips2024/posters/onmnr0nj2e/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/onmnr0nj2e/</guid><description>Soft labels, not sophisticated data synthesis, are the key to successful dataset distillation, significantly improving data-efficient learning and challenging existing methods.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/onmnr0nj2e/cover.png"/></item><item><title>A Motion-aware Spatio-temporal Graph for Video Salient Object Ranking</title><link>https://deep-diver.github.io/neurips2024/posters/vubtacqn44/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/vubtacqn44/</guid><description>A novel motion-aware spatio-temporal graph model surpasses existing methods in video salient object ranking by jointly optimizing multi-scale spatial and temporal features, thus accurately prioritizin&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/vubtacqn44/cover.png"/></item><item><title>A robust inlier identification algorithm for point cloud registration via l_0-minimization</title><link>https://deep-diver.github.io/neurips2024/posters/bjrbalodrj/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/bjrbalodrj/</guid><description>This paper introduces a novel, robust inlier identification algorithm for point cloud registration that leverages lo-minimization.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/bjrbalodrj/cover.png"/></item><item><title>A Simple yet Universal Framework for Depth Completion</title><link>https://deep-diver.github.io/neurips2024/posters/y4thp5jilp/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/y4thp5jilp/</guid><description>UniDC framework achieves universal depth completion across various sensors and scenes using minimal labeled data, leveraging a foundation model and hyperbolic embedding for enhanced generalization.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/y4thp5jilp/cover.png"/></item><item><title>A Unified Framework for 3D Scene Understanding</title><link>https://deep-diver.github.io/neurips2024/posters/de1btyyc9a/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/de1btyyc9a/</guid><description>UniSeg3D: One model to rule them all! This unified framework masters six 3D segmentation tasks (panoptic, semantic, instance, interactive, referring, and open-vocabulary) simultaneously, outperforming&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/de1btyyc9a/cover.png"/></item><item><title>Accelerating Augmentation Invariance Pretraining</title><link>https://deep-diver.github.io/neurips2024/posters/wh9ssqlcng/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/wh9ssqlcng/</guid><description>Boost Vision Transformer pretraining speed by 4x with novel sequence compression techniques!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/wh9ssqlcng/cover.png"/></item><item><title>ACFun: Abstract-Concrete Fusion Facial Stylization</title><link>https://deep-diver.github.io/neurips2024/posters/d2vk206haj/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/d2vk206haj/</guid><description>ACFun: A novel facial stylization method fusing abstract &amp;amp; concrete features for high-quality, artistically pleasing results from only one style &amp;amp; one face image.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/d2vk206haj/cover.png"/></item><item><title>ActAnywhere: Subject-Aware Video Background Generation</title><link>https://deep-diver.github.io/neurips2024/posters/ntlfrew59a/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/ntlfrew59a/</guid><description>ActAnywhere, a novel video diffusion model, seamlessly integrates foreground subjects into new backgrounds by generating realistic video backgrounds tailored to subject motion, significantly reducing &amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/ntlfrew59a/cover.png"/></item><item><title>Action Imitation in Common Action Space for Customized Action Image Synthesis</title><link>https://deep-diver.github.io/neurips2024/posters/h2e4g2yiwr/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/h2e4g2yiwr/</guid><description>TwinAct: Decoupling actions and actors for customizable text-guided action image generation.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/h2e4g2yiwr/cover.png"/></item><item><title>Activating Self-Attention for Multi-Scene Absolute Pose Regression</title><link>https://deep-diver.github.io/neurips2024/posters/rm24uugzg8/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/rm24uugzg8/</guid><description>Boosting Multi-Scene Pose Regression: Novel methods activate transformer self-attention, significantly improving camera pose estimation accuracy and efficiency.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/rm24uugzg8/cover.png"/></item><item><title>AdanCA: Neural Cellular Automata As Adaptors For More Robust Vision Transformer</title><link>https://deep-diver.github.io/neurips2024/posters/bqh1sgvrog/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/bqh1sgvrog/</guid><description>Boosting Vision Transformer robustness against attacks &amp;amp; noisy data, AdaNCA uses Neural Cellular Automata as plug-and-play adaptors between ViT layers, achieving significant accuracy improvement with &amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/bqh1sgvrog/cover.png"/></item><item><title>AdaPKC: PeakConv with Adaptive Peak Receptive Field for Radar Semantic Segmentation</title><link>https://deep-diver.github.io/neurips2024/posters/olcpadfry3/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/olcpadfry3/</guid><description>AdaPKC upgrades PeakConv for superior radar semantic segmentation by dynamically adjusting its receptive field, outperforming current state-of-the-art methods.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/olcpadfry3/cover.png"/></item><item><title>Adapting Diffusion Models for Improved Prompt Compliance and Controllable Image Synthesis</title><link>https://deep-diver.github.io/neurips2024/posters/sntv8ac3u2/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/sntv8ac3u2/</guid><description>FG-DMs revolutionize image synthesis by jointly modeling image and condition distributions, achieving higher object recall and enabling flexible editing.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/sntv8ac3u2/cover.png"/></item><item><title>Adaptive Domain Learning for Cross-domain Image Denoising</title><link>https://deep-diver.github.io/neurips2024/posters/gott78aqk4/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/gott78aqk4/</guid><description>Adaptive Domain Learning (ADL) efficiently trains a cross-domain RAW image denoising model using limited target data and existing source data by intelligently discarding harmful source data and levera&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/gott78aqk4/cover.png"/></item><item><title>Adaptive Important Region Selection with Reinforced Hierarchical Search for Dense Object Detection</title><link>https://deep-diver.github.io/neurips2024/posters/f8mrwxlnrz/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/f8mrwxlnrz/</guid><description>AIRS framework, guided by Evidential Q-learning, dynamically balances exploration and exploitation to achieve superior dense object detection accuracy by adaptively selecting important regions.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/f8mrwxlnrz/cover.png"/></item><item><title>AdjointDEIS: Efficient Gradients for Diffusion Models</title><link>https://deep-diver.github.io/neurips2024/posters/falcxvroex/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/falcxvroex/</guid><description>AdjointDEIS: Efficient gradients for diffusion models via bespoke ODE solvers, simplifying backpropagation and improving guided generation.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/falcxvroex/cover.png"/></item><item><title>AdvAD: Exploring Non-Parametric Diffusion for Imperceptible Adversarial Attacks</title><link>https://deep-diver.github.io/neurips2024/posters/s8pxz7cvht/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/s8pxz7cvht/</guid><description>AdvAD: A non-parametric diffusion process crafts imperceptible adversarial examples by subtly guiding an initial noise towards a target distribution, achieving high attack success rates with minimal p&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/s8pxz7cvht/cover.png"/></item><item><title>Adversarial Schrödinger Bridge Matching</title><link>https://deep-diver.github.io/neurips2024/posters/l3knnigicu/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/l3knnigicu/</guid><description>Accelerate Schrödinger Bridge Matching with Discrete-time IMF using only a few steps, achieving comparable results to existing hundred-step methods via D-GAN implementation.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/l3knnigicu/cover.png"/></item><item><title>AirSketch: Generative Motion to Sketch</title><link>https://deep-diver.github.io/neurips2024/posters/ttlcbekaj6/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/ttlcbekaj6/</guid><description>AirSketch generates aesthetically pleasing sketches directly from noisy hand-motion tracking data using a self-supervised controllable diffusion model, eliminating the need for expensive AR/VR equipme&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/ttlcbekaj6/cover.png"/></item><item><title>An Image is Worth 32 Tokens for Reconstruction and Generation</title><link>https://deep-diver.github.io/neurips2024/posters/toxoqprzpl/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/toxoqprzpl/</guid><description>Image generation gets a speed boost with TiTok, a novel 1D image tokenizer that uses just 32 tokens for high-quality image reconstruction and generation, achieving up to 410x faster processing than st&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/toxoqprzpl/cover.png"/></item><item><title>Animate3D: Animating Any 3D Model with Multi-view Video Diffusion</title><link>https://deep-diver.github.io/neurips2024/posters/hb6kacfimn/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/hb6kacfimn/</guid><description>Animate3D animates any 3D model using multi-view video diffusion, achieving superior spatiotemporal consistency and straightforward mesh animation.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/hb6kacfimn/cover.png"/></item><item><title>Applying Guidance in a Limited Interval Improves Sample and Distribution Quality in Diffusion Models</title><link>https://deep-diver.github.io/neurips2024/posters/naihvny15t/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/naihvny15t/</guid><description>Boosting image generation: Applying guidance selectively during diffusion model sampling drastically enhances image quality and inference speed, achieving state-of-the-art results.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/naihvny15t/cover.png"/></item><item><title>Are nuclear masks all you need for improved out-of-domain generalisation? A closer look at cancer classification in histopathology</title><link>https://deep-diver.github.io/neurips2024/posters/bmwcbnykuh/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/bmwcbnykuh/</guid><description>Focusing on nuclear morphology improves out-of-domain generalization in cancer classification from histopathology images by leveraging nuclear segmentation masks during training.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/bmwcbnykuh/cover.png"/></item><item><title>AsCAN: Asymmetric Convolution-Attention Networks for Efficient Recognition and Generation</title><link>https://deep-diver.github.io/neurips2024/posters/r0escj6qsl/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/r0escj6qsl/</guid><description>AsCAN, a novel hybrid architecture, achieves superior efficiency and performance in image recognition and generation by asymmetrically combining convolutional and transformer blocks.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/r0escj6qsl/cover.png"/></item><item><title>Assembly Fuzzy Representation on Hypergraph for Open-Set 3D Object Retrieval</title><link>https://deep-diver.github.io/neurips2024/posters/xocaurlvm9/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/xocaurlvm9/</guid><description>Hypergraph-Based Assembly Fuzzy Representation (HAFR) excels at open-set 3D object retrieval by using part-level shapes and fuzzy representations to overcome challenges posed by unseen object categori&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/xocaurlvm9/cover.png"/></item><item><title>Attack-Resilient Image Watermarking Using Stable Diffusion</title><link>https://deep-diver.github.io/neurips2024/posters/e6krsoughj/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/e6krsoughj/</guid><description>ZoDiac: a novel image watermarking framework leveraging pre-trained stable diffusion models for robust, invisible watermarks resistant to state-of-the-art attacks.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/e6krsoughj/cover.png"/></item><item><title>Attention Temperature Matters in ViT-Based Cross-Domain Few-Shot Learning</title><link>https://deep-diver.github.io/neurips2024/posters/o8m4rm5mbk/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/o8m4rm5mbk/</guid><description>Boosting Vision Transformer&amp;rsquo;s transferability in cross-domain few-shot learning is achieved by a simple yet effective method: strategically adjusting attention temperature to remedy ineffective target&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/o8m4rm5mbk/cover.png"/></item><item><title>AUCSeg: AUC-oriented Pixel-level Long-tail Semantic Segmentation</title><link>https://deep-diver.github.io/neurips2024/posters/ekk26cw5tb/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/ekk26cw5tb/</guid><description>AUCSeg tackles pixel-level long-tail semantic segmentation by introducing an AUC-oriented loss function and a Tail-Classes Memory Bank to efficiently manage memory and improve performance on imbalance&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/ekk26cw5tb/cover.png"/></item><item><title>Be Confident in What You Know: Bayesian Parameter Efficient Fine-Tuning of Vision Foundation Models</title><link>https://deep-diver.github.io/neurips2024/posters/loqck0qruu/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/loqck0qruu/</guid><description>Bayesian-PEFT boosts vision model accuracy and confidence in few-shot learning by integrating Bayesian components into PEFT, solving the underconfidence problem.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/loqck0qruu/cover.png"/></item><item><title>Beyond Accuracy: Tracking more like Human via Visual Search</title><link>https://deep-diver.github.io/neurips2024/posters/lezaeimfoc/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/lezaeimfoc/</guid><description>CPDTrack: Human-like Visual Search Boosts Object Tracking!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/lezaeimfoc/cover.png"/></item><item><title>Beyond Euclidean: Dual-Space Representation Learning for Weakly Supervised Video Violence Detection</title><link>https://deep-diver.github.io/neurips2024/posters/tbpv0qfnho/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/tbpv0qfnho/</guid><description>Beyond Euclidean spaces, Dual-Space Representation Learning (DSRL) enhances weakly supervised video violence detection by cleverly integrating Euclidean and hyperbolic geometries for superior discrimi&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/tbpv0qfnho/cover.png"/></item><item><title>Bidirectional Recurrence for Cardiac Motion Tracking with Gaussian Process Latent Coding</title><link>https://deep-diver.github.io/neurips2024/posters/ctifk7b9ju/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/ctifk7b9ju/</guid><description>GPTrack: A novel unsupervised framework enhances cardiac motion tracking by using sequential Gaussian processes and bidirectional recurrence, improving accuracy and efficiency.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/ctifk7b9ju/cover.png"/></item><item><title>BiDM: Pushing the Limit of Quantization for Diffusion Models</title><link>https://deep-diver.github.io/neurips2024/posters/owaitgb8lj/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/owaitgb8lj/</guid><description>BiDM achieves full 1-bit quantization in diffusion models, significantly improving storage and speed without sacrificing image quality, setting a new state-of-the-art.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/owaitgb8lj/cover.png"/></item><item><title>Binarized Diffusion Model for Image Super-Resolution</title><link>https://deep-diver.github.io/neurips2024/posters/yxpfrlmir2/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/yxpfrlmir2/</guid><description>BI-DiffSR, a novel binarized diffusion model, achieves high-quality image super-resolution with significantly reduced memory and computational costs, outperforming existing methods.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/yxpfrlmir2/cover.png"/></item><item><title>Binocular-Guided 3D Gaussian Splatting with View Consistency for Sparse View Synthesis</title><link>https://deep-diver.github.io/neurips2024/posters/otettmiymz/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/otettmiymz/</guid><description>Binocular-guided 3D Gaussian splatting with self-supervision generates high-quality novel views from sparse inputs without external priors, significantly outperforming state-of-the-art methods.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/otettmiymz/cover.png"/></item><item><title>Biologically-Inspired Learning Model for Instructed Vision</title><link>https://deep-diver.github.io/neurips2024/posters/gjxeircnao/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/gjxeircnao/</guid><description>Biologically-inspired AI model integrates learning &amp;amp; visual guidance via a novel &amp;lsquo;Counter-Hebb&amp;rsquo; learning mechanism, achieving competitive performance on multi-task learning benchmarks.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/gjxeircnao/cover.png"/></item><item><title>bit2bit: 1-bit quanta video reconstruction via self-supervised photon prediction</title><link>https://deep-diver.github.io/neurips2024/posters/htlfnbyfon/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/htlfnbyfon/</guid><description>bit2bit reconstructs high-quality videos from sparse, binary quanta image sensor data using self-supervised photon location prediction, significantly improving resolution and usability.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/htlfnbyfon/cover.png"/></item><item><title>BLAST: Block-Level Adaptive Structured Matrices for Efficient Deep Neural Network Inference</title><link>https://deep-diver.github.io/neurips2024/posters/n0ars0ddot/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/n0ars0ddot/</guid><description>BLAST matrix learns efficient weight structures for faster deep learning inference, achieving significant compression and performance gains on various models.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/n0ars0ddot/cover.png"/></item><item><title>Blind Image Restoration via Fast Diffusion Inversion</title><link>https://deep-diver.github.io/neurips2024/posters/hfsjlbrkkj/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/hfsjlbrkkj/</guid><description>BIRD: a novel blind image restoration method jointly optimizes degradation model parameters and the restored image, ensuring realistic outputs via fast diffusion inversion and achieving state-of-the-a&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/hfsjlbrkkj/cover.png"/></item><item><title>BOLD: Boolean Logic Deep Learning</title><link>https://deep-diver.github.io/neurips2024/posters/do9wpzopjk/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/do9wpzopjk/</guid><description>Boolean Logic Deep Learning (BOLD) revolutionizes deep learning by enabling training with Boolean weights and activations, achieving state-of-the-art accuracy with drastically reduced energy consumpti&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/do9wpzopjk/cover.png"/></item><item><title>Boosting the Transferability of Adversarial Attack on Vision Transformer with Adaptive Token Tuning</title><link>https://deep-diver.github.io/neurips2024/posters/snz7tptch6/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/snz7tptch6/</guid><description>Boosting vision transformer adversarial attack transferability, this paper introduces Adaptive Token Tuning (ATT), improving attack success rate by 10.1% over existing methods.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/snz7tptch6/cover.png"/></item><item><title>Bootstrapping Top-down Information for Self-modulating Slot Attention</title><link>https://deep-diver.github.io/neurips2024/posters/52ptsraqqm/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/52ptsraqqm/</guid><description>This paper introduces a novel object-centric learning (OCL) framework that enhances slot attention with a self-modulating top-down pathway, significantly improving object representation and achieving &amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/52ptsraqqm/cover.png"/></item><item><title>BrainBits: How Much of the Brain are Generative Reconstruction Methods Using?</title><link>https://deep-diver.github.io/neurips2024/posters/kaauvi4kpb/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/kaauvi4kpb/</guid><description>BrainBits reveals that surprisingly little brain information is needed for high-fidelity image &amp;amp; text reconstruction, highlighting the dominance of generative model priors over neural signal extractio&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/kaauvi4kpb/cover.png"/></item><item><title>Bridging the Divide: Reconsidering Softmax and Linear Attention</title><link>https://deep-diver.github.io/neurips2024/posters/rsigfzqapl/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/rsigfzqapl/</guid><description>InLine attention, a novel method, bridges the performance gap between softmax and linear attention by incorporating injectivity and local modeling, achieving superior performance while maintaining lin&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/rsigfzqapl/cover.png"/></item><item><title>Can Simple Averaging Defeat Modern Watermarks?</title><link>https://deep-diver.github.io/neurips2024/posters/x2g7la7av9/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/x2g7la7av9/</guid><description>Simple averaging of watermarked images reveals hidden patterns, enabling watermark removal and forgery, thus highlighting the vulnerability of content-agnostic watermarking methods.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/x2g7la7av9/cover.png"/></item><item><title>Can We Leave Deepfake Data Behind in Training Deepfake Detector?</title><link>https://deep-diver.github.io/neurips2024/posters/vh9yepleyd/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/vh9yepleyd/</guid><description>ProDet: Deepfake detection enhanced by progressively organizing blendfake and deepfake data in the latent space, improving generalization and robustness.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/vh9yepleyd/cover.png"/></item><item><title>CemiFace: Center-based Semi-hard Synthetic Face Generation for Face Recognition</title><link>https://deep-diver.github.io/neurips2024/posters/ykqnxko1cj/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/ykqnxko1cj/</guid><description>CemiFace: Generating high-quality synthetic facial data for robust face recognition, while addressing privacy concerns.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/ykqnxko1cj/cover.png"/></item><item><title>CHASE: Learning Convex Hull Adaptive Shift for Skeleton-based Multi-Entity Action Recognition</title><link>https://deep-diver.github.io/neurips2024/posters/whe4c4flbe/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/whe4c4flbe/</guid><description>CHASE: A novel method for skeleton-based multi-entity action recognition that cleverly adapts skeleton positions to minimize data bias and boost accuracy.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/whe4c4flbe/cover.png"/></item><item><title>Classification Diffusion Models: Revitalizing Density Ratio Estimation</title><link>https://deep-diver.github.io/neurips2024/posters/d99ycfonwk/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/d99ycfonwk/</guid><description>Classification Diffusion Models (CDMs) revolutionize density ratio estimation by integrating the strengths of diffusion models and classifiers, achieving state-of-the-art image generation and likeliho&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/d99ycfonwk/cover.png"/></item><item><title>Cloud Object Detector Adaptation by Integrating Different Source Knowledge</title><link>https://deep-diver.github.io/neurips2024/posters/s8sejerttg/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/s8sejerttg/</guid><description>COIN: A novel method for Cloud Object Detector Adaptation that integrates knowledge from cloud models and CLIP to train highly accurate target detectors, achieving state-of-the-art performance.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/s8sejerttg/cover.png"/></item><item><title>CNCA: Toward Customizable and Natural Generation of Adversarial Camouflage for Vehicle Detectors</title><link>https://deep-diver.github.io/neurips2024/posters/axnzg82izv/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/axnzg82izv/</guid><description>Researchers developed CNCA, a novel method that generates realistic and customizable adversarial camouflage for vehicle detectors by leveraging a pre-trained diffusion model, surpassing existing metho&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/axnzg82izv/cover.png"/></item><item><title>Coarse-to-Fine Concept Bottleneck Models</title><link>https://deep-diver.github.io/neurips2024/posters/rmdntnffou/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/rmdntnffou/</guid><description>Hierarchical concept bottleneck models boost interpretability and accuracy in visual classification by uncovering both high-level and low-level concepts.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/rmdntnffou/cover.png"/></item><item><title>Coherent 3D Scene Diffusion From a Single RGB Image</title><link>https://deep-diver.github.io/neurips2024/posters/lckadnvzst/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/lckadnvzst/</guid><description>Coherent 3D scenes are diffused from a single RGB image using a novel image-conditioned 3D scene diffusion model, surpassing state-of-the-art methods.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/lckadnvzst/cover.png"/></item><item><title>ColJailBreak: Collaborative Generation and Editing for Jailbreaking Text-to-Image Deep Generation</title><link>https://deep-diver.github.io/neurips2024/posters/egizetmate/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/egizetmate/</guid><description>ColJailBreak cleverly circumvents AI safety filters by first generating safe images and then subtly injecting unsafe content using image editing.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/egizetmate/cover.png"/></item><item><title>Collaborative Video Diffusion: Consistent Multi-video Generation with Camera Control</title><link>https://deep-diver.github.io/neurips2024/posters/arhjlyiy2j/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/arhjlyiy2j/</guid><description>Collaborative Video Diffusion (CVD) generates multiple consistent videos from various camera angles using a novel cross-video synchronization module, significantly improving consistency compared to ex&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/arhjlyiy2j/cover.png"/></item><item><title>Color-Oriented Redundancy Reduction in Dataset Distillation</title><link>https://deep-diver.github.io/neurips2024/posters/yfqwyxisj7/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/yfqwyxisj7/</guid><description>AutoPalette: a new framework minimizing color redundancy in dataset distillation, resulting in more efficient model training with comparable performance.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/yfqwyxisj7/cover.png"/></item><item><title>Conditional Controllable Image Fusion</title><link>https://deep-diver.github.io/neurips2024/posters/rss4o7csqe/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/rss4o7csqe/</guid><description>Conditional Controllable Fusion (CCF) achieves training-free, adaptable image fusion by dynamically injecting fusion conditions into a pre-trained denoising diffusion model.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/rss4o7csqe/cover.png"/></item><item><title>Consistency Purification: Effective and Efficient Diffusion Purification towards Certified Robustness</title><link>https://deep-diver.github.io/neurips2024/posters/tlwoxftjvh/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/tlwoxftjvh/</guid><description>Consistency Purification boosts certified robustness by efficiently purifying noisy images using a one-step generative model, achieving state-of-the-art results while maintaining semantic alignment.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/tlwoxftjvh/cover.png"/></item><item><title>Constrained Diffusion with Trust Sampling</title><link>https://deep-diver.github.io/neurips2024/posters/djub9xrozi/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/djub9xrozi/</guid><description>Trust Sampling enhances guided diffusion by iteratively optimizing constrained generation at each step, improving efficiency and accuracy in image and 3D motion generation.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/djub9xrozi/cover.png"/></item><item><title>Constructing Semantics-Aware Adversarial Examples with Probabilistic Perspective</title><link>https://deep-diver.github.io/neurips2024/posters/wbe0qcbwji/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/wbe0qcbwji/</guid><description>Researchers developed semantics-aware adversarial examples using a probabilistic approach, achieving higher success rates in bypassing defenses while remaining undetectable to humans.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/wbe0qcbwji/cover.png"/></item><item><title>ContextGS : Compact 3D Gaussian Splatting with Anchor Level Context Model</title><link>https://deep-diver.github.io/neurips2024/posters/w2qgsml2uu/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/w2qgsml2uu/</guid><description>ContextGS: Revolutionizing 3D scene compression with an anchor-level autoregressive model, achieving 15x size reduction in 3D Gaussian Splatting while boosting rendering quality.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/w2qgsml2uu/cover.png"/></item><item><title>Continuous Spatiotemporal Events Decoupling through Spike-based Bayesian Computation</title><link>https://deep-diver.github.io/neurips2024/posters/znihpznqhh/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/znihpznqhh/</guid><description>Spiking neural network effectively segments mixed-motion event streams via spike-based Bayesian computation, achieving efficient real-time motion decoupling.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/znihpznqhh/cover.png"/></item><item><title>Contrastive-Equivariant Self-Supervised Learning Improves Alignment with Primate Visual Area IT</title><link>https://deep-diver.github.io/neurips2024/posters/aims8gpp5q/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/aims8gpp5q/</guid><description>Self-supervised learning models can now better predict primate IT neural responses by preserving structured variability to input transformations, improving alignment with biological visual perception.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/aims8gpp5q/cover.png"/></item><item><title>Cooperative Hardware-Prompt Learning for Snapshot Compressive Imaging</title><link>https://deep-diver.github.io/neurips2024/posters/zxswidyw3a/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/zxswidyw3a/</guid><description>Federated Hardware-Prompt Learning (FedHP) enables robust cross-hardware SCI training by aligning inconsistent data distributions using a hardware-conditioned prompter, outperforming existing FL metho&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/zxswidyw3a/cover.png"/></item><item><title>CosAE: Learnable Fourier Series for Image Restoration</title><link>https://deep-diver.github.io/neurips2024/posters/d0s29c5gvl/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/d0s29c5gvl/</guid><description>CosAE: a novel autoencoder using learnable Fourier series achieves state-of-the-art image restoration by encoding frequency coefficients in its narrow bottleneck, preserving fine details even with ext&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/d0s29c5gvl/cover.png"/></item><item><title>COSMIC: Compress Satellite Image Efficiently via Diffusion Compensation</title><link>https://deep-diver.github.io/neurips2024/posters/itbkmrequz/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/itbkmrequz/</guid><description>COSMIC efficiently compresses satellite images via a lightweight encoder and diffusion compensation, enabling practical onboard processing and high compression ratios.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/itbkmrequz/cover.png"/></item><item><title>CoSW: Conditional Sample Weighting for Smoke Segmentation with Label Noise</title><link>https://deep-diver.github.io/neurips2024/posters/rrryqmn6dv/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/rrryqmn6dv/</guid><description>CoSW: a novel conditional sample weighting method for robust smoke segmentation, achieves state-of-the-art results by handling inconsistent noisy labels through a multi-prototype framework.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/rrryqmn6dv/cover.png"/></item><item><title>CountGD: Multi-Modal Open-World Counting</title><link>https://deep-diver.github.io/neurips2024/posters/eug64osgde/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/eug64osgde/</guid><description>COUNTGD: A new multi-modal model counts objects in images using text or visual examples, significantly improving open-world counting accuracy.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/eug64osgde/cover.png"/></item><item><title>CRAYM: Neural Field Optimization via Camera RAY Matching</title><link>https://deep-diver.github.io/neurips2024/posters/wk0z49myyi/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/wk0z49myyi/</guid><description>CRAYM: Neural field optimization via camera RAY matching enhances 3D reconstruction by using camera rays, not pixels, improving both novel view synthesis and geometry.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/wk0z49myyi/cover.png"/></item><item><title>Cross-Modality Perturbation Synergy Attack for Person Re-identification</title><link>https://deep-diver.github.io/neurips2024/posters/lond7acejy/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/lond7acejy/</guid><description>Cross-Modality Perturbation Synergy (CMPS) attack: A novel universal perturbation method for cross-modality person re-identification, effectively misleading ReID models by leveraging gradients from di&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/lond7acejy/cover.png"/></item><item><title>Cross-Scale Self-Supervised Blind Image Deblurring via Implicit Neural Representation</title><link>https://deep-diver.github.io/neurips2024/posters/cfez7mfufd/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/cfez7mfufd/</guid><description>Self-supervised blind image deblurring (BID) breakthrough! A novel cross-scale consistency loss and progressive training scheme using implicit neural representations achieves superior performance wit&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/cfez7mfufd/cover.png"/></item><item><title>Cross-video Identity Correlating for Person Re-identification Pre-training</title><link>https://deep-diver.github.io/neurips2024/posters/qcinh3o9q6/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/qcinh3o9q6/</guid><description>Cross-video Identity-cOrrelating pre-training (CION) revolutionizes person re-identification by leveraging identity correlation across videos for superior model pre-training, achieving state-of-the-ar&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/qcinh3o9q6/cover.png"/></item><item><title>CryoGEM: Physics-Informed Generative Cryo-Electron Microscopy</title><link>https://deep-diver.github.io/neurips2024/posters/edozifvwmi/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/edozifvwmi/</guid><description>CryoGEM: Physics-informed generative model creates realistic synthetic cryo-EM datasets, boosting particle picking and pose estimation accuracy for higher-resolution protein structure determination.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/edozifvwmi/cover.png"/></item><item><title>Ctrl-X: Controlling Structure and Appearance for Text-To-Image Generation Without Guidance</title><link>https://deep-diver.github.io/neurips2024/posters/zulwewqop9/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/zulwewqop9/</guid><description>Ctrl-X: Zero-shot text-to-image generation with training-free structure &amp;amp; appearance control!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/zulwewqop9/cover.png"/></item><item><title>Curriculum Fine-tuning of Vision Foundation Model for Medical Image Classification Under Label Noise</title><link>https://deep-diver.github.io/neurips2024/posters/vyux8j5kk2/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/vyux8j5kk2/</guid><description>CUFIT: a novel curriculum fine-tuning paradigm significantly improves medical image classification accuracy despite noisy labels by leveraging pre-trained Vision Foundation Models.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/vyux8j5kk2/cover.png"/></item><item><title>CYCLO: Cyclic Graph Transformer Approach to Multi-Object Relationship Modeling in Aerial Videos</title><link>https://deep-diver.github.io/neurips2024/posters/zg4zs0l2ih/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/zg4zs0l2ih/</guid><description>CYCLO: A novel cyclic graph transformer excels at multi-object relationship modeling in aerial videos.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/zg4zs0l2ih/cover.png"/></item><item><title>DA-Ada: Learning Domain-Aware Adapter for Domain Adaptive Object Detection</title><link>https://deep-diver.github.io/neurips2024/posters/hkewwaqmck/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/hkewwaqmck/</guid><description>DA-Ada enhances domain adaptive object detection by using a novel domain-aware adapter that leverages both domain-invariant and domain-specific knowledge for improved accuracy and generalization acros&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/hkewwaqmck/cover.png"/></item><item><title>DC-Gaussian: Improving 3D Gaussian Splatting for Reflective Dash Cam Videos</title><link>https://deep-diver.github.io/neurips2024/posters/ja20bpfapa/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/ja20bpfapa/</guid><description>DC-Gaussian: A novel method generates high-fidelity novel views from dashcam videos by addressing common windshield obstructions (reflections, occlusions) using adaptive image decomposition, illumina&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/ja20bpfapa/cover.png"/></item><item><title>DDR: Exploiting Deep Degradation Response as Flexible Image Descriptor</title><link>https://deep-diver.github.io/neurips2024/posters/rxlo4zv3wb/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/rxlo4zv3wb/</guid><description>Deep Degradation Response (DDR) uses image deep feature changes under degradation to create a flexible image descriptor, excelling in blind image quality assessment and unsupervised image restoration.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/rxlo4zv3wb/cover.png"/></item><item><title>Dealing with Synthetic Data Contamination in Online Continual Learning</title><link>https://deep-diver.github.io/neurips2024/posters/lc8gemv97y/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/lc8gemv97y/</guid><description>AI-generated images contaminate online continual learning datasets, hindering performance. A new method, ESRM, leverages entropy and real/synthetic similarity maximization to select high-quality data&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/lc8gemv97y/cover.png"/></item><item><title>DeBaRA: Denoising-Based 3D Room Arrangement Generation</title><link>https://deep-diver.github.io/neurips2024/posters/rajrj6wkj2/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/rajrj6wkj2/</guid><description>DeBaRA: a novel denoising-based model generates realistic &amp;amp; controllable 3D room layouts, surpassing existing methods.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/rajrj6wkj2/cover.png"/></item><item><title>Decomposing and Interpreting Image Representations via Text in ViTs Beyond CLIP</title><link>https://deep-diver.github.io/neurips2024/posters/vhh7ontfvv/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/vhh7ontfvv/</guid><description>This paper presents a general framework for interpreting Vision Transformer (ViT) components, mapping their contributions to CLIP space for textual interpretation, and introduces a scoring function fo&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/vhh7ontfvv/cover.png"/></item><item><title>Decoupled Kullback-Leibler Divergence Loss</title><link>https://deep-diver.github.io/neurips2024/posters/bnzzedw9cm/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/bnzzedw9cm/</guid><description>Improved Kullback-Leibler (IKL) divergence loss achieves state-of-the-art adversarial robustness and competitive knowledge distillation performance by addressing KL loss&amp;rsquo;s limitations.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/bnzzedw9cm/cover.png"/></item><item><title>Decoupling Semantic Similarity from Spatial Alignment for Neural Networks.</title><link>https://deep-diver.github.io/neurips2024/posters/ypfgct147z/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/ypfgct147z/</guid><description>Researchers developed semantic RSMs, a novel approach to measure semantic similarity in neural networks, improving image retrieval and aligning network representations with predicted class probabiliti&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/ypfgct147z/cover.png"/></item><item><title>Defensive Unlearning with Adversarial Training for Robust Concept Erasure in Diffusion Models</title><link>https://deep-diver.github.io/neurips2024/posters/dkpmfiydrf/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/dkpmfiydrf/</guid><description>AdvUnlearn enhances diffusion model robustness against adversarial attacks during concept erasure by integrating adversarial training, improving the trade-off between robustness and model utility.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/dkpmfiydrf/cover.png"/></item><item><title>Demystify Mamba in Vision: A Linear Attention Perspective</title><link>https://deep-diver.github.io/neurips2024/posters/lvj1r88kak/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/lvj1r88kak/</guid><description>Vision&amp;rsquo;s Mamba model demystified: Researchers unveil its surprising link to linear attention, improving efficiency and accuracy through design enhancements.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/lvj1r88kak/cover.png"/></item><item><title>Depth Anything V2</title><link>https://deep-diver.github.io/neurips2024/posters/cfti3glj1x/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/cfti3glj1x/</guid><description>Depth Anything V2 drastically improves monocular depth estimation by using synthetic training data, scaling up the teacher model, and employing pseudo-labeled real images. It outperforms previous met&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/cfti3glj1x/cover.png"/></item><item><title>Depth Anywhere: Enhancing 360 Monocular Depth Estimation via Perspective Distillation and Unlabeled Data Augmentation</title><link>https://deep-diver.github.io/neurips2024/posters/vzoybrqj4o/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/vzoybrqj4o/</guid><description>Depth Anywhere enhances 360-degree monocular depth estimation by cleverly using perspective models to label unlabeled 360-degree data, significantly improving accuracy.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/vzoybrqj4o/cover.png"/></item><item><title>DeTrack: In-model Latent Denoising Learning for Visual Object Tracking</title><link>https://deep-diver.github.io/neurips2024/posters/zjjunf0olj/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/zjjunf0olj/</guid><description>DeTrack revolutionizes visual object tracking with an in-model latent denoising learning process, achieving real-time speed and state-of-the-art accuracy.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/zjjunf0olj/cover.png"/></item><item><title>DEX: Data Channel Extension for Efficient CNN Inference on Tiny AI Accelerators</title><link>https://deep-diver.github.io/neurips2024/posters/ftqjwzqz10/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/ftqjwzqz10/</guid><description>DEX boosts CNN accuracy on tiny AI accelerators by 3.5%p, utilizing unused memory and processors to extend input channels without increasing latency.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/ftqjwzqz10/cover.png"/></item><item><title>DI-MaskDINO: A Joint Object Detection and Instance Segmentation Model</title><link>https://deep-diver.github.io/neurips2024/posters/srqxkspjlw/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/srqxkspjlw/</guid><description>DI-MaskDINO: Novel model significantly boosts object detection &amp;amp; instance segmentation accuracy by addressing performance imbalance using a De-Imbalance module and Balance-Aware Tokens Optimization.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/srqxkspjlw/cover.png"/></item><item><title>DiffuBox: Refining 3D Object Detection with Point Diffusion</title><link>https://deep-diver.github.io/neurips2024/posters/j2wootkbx0/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/j2wootkbx0/</guid><description>DiffuBox refines 3D object detection using a novel diffusion-based approach, significantly improving accuracy across various domains by refining bounding boxes based on surrounding LiDAR point clouds.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/j2wootkbx0/cover.png"/></item><item><title>DiffuLT: Diffusion for Long-tail Recognition Without External Knowledge</title><link>https://deep-diver.github.io/neurips2024/posters/kcsj9fgnkr/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/kcsj9fgnkr/</guid><description>DiffuLT uses a novel diffusion model to generate balanced training data from imbalanced datasets, achieving state-of-the-art results in long-tailed image recognition without external knowledge.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/kcsj9fgnkr/cover.png"/></item><item><title>Diffusion4D: Fast Spatial-temporal Consistent 4D generation via Video Diffusion Models</title><link>https://deep-diver.github.io/neurips2024/posters/grrefkwees/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/grrefkwees/</guid><description>Diffusion4D: Fast, consistent 4D content generation via a novel 4D-aware video diffusion model, surpassing existing methods in efficiency and 4D geometry consistency.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/grrefkwees/cover.png"/></item><item><title>DiffusionBlend: Learning 3D Image Prior through Position-aware Diffusion Score Blending for 3D Computed Tomography Reconstruction</title><link>https://deep-diver.github.io/neurips2024/posters/h3kv6sdtwo/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/h3kv6sdtwo/</guid><description>DiffusionBlend++ learns a 3D image prior via position-aware diffusion score blending, achieving state-of-the-art 3D CT reconstruction with superior efficiency.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/h3kv6sdtwo/cover.png"/></item><item><title>DiMSUM: Diffusion Mamba - A Scalable and Unified Spatial-Frequency Method for Image Generation</title><link>https://deep-diver.github.io/neurips2024/posters/kqblzsixkm/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/kqblzsixkm/</guid><description>DiMSUM: A novel diffusion model boosts image generation by unifying spatial and frequency information, achieving superior results and faster training.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/kqblzsixkm/cover.png"/></item><item><title>DINTR: Tracking via Diffusion-based Interpolation</title><link>https://deep-diver.github.io/neurips2024/posters/gagwqhobig/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/gagwqhobig/</guid><description>DINTR: A novel diffusion-based object tracker surpasses existing methods by using efficient interpolation, achieving superior performance across diverse benchmarks.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/gagwqhobig/cover.png"/></item><item><title>DiP-GO: A Diffusion Pruner via Few-step Gradient Optimization</title><link>https://deep-diver.github.io/neurips2024/posters/sbsarj475e/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/sbsarj475e/</guid><description>DiP-GO: A novel pruning method accelerates diffusion models via few-step gradient optimization, achieving a 4.4x speedup on Stable Diffusion 1.5 without accuracy loss.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/sbsarj475e/cover.png"/></item><item><title>Direct Consistency Optimization for Robust Customization of Text-to-Image Diffusion models</title><link>https://deep-diver.github.io/neurips2024/posters/vazkrbcgxt/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/vazkrbcgxt/</guid><description>Boosting personalized image generation! Direct Consistency Optimization (DCO) fine-tunes text-to-image models, ensuring subject consistency and prompt fidelity, even when merging separately customized&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/vazkrbcgxt/cover.png"/></item><item><title>Direct3D: Scalable Image-to-3D Generation via 3D Latent Diffusion Transformer</title><link>https://deep-diver.github.io/neurips2024/posters/vcogjbizul/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/vcogjbizul/</guid><description>Direct3D: Revolutionizing image-to-3D generation with a scalable, native 3D diffusion model achieving state-of-the-art quality.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/vcogjbizul/cover.png"/></item><item><title>DisC-GS: Discontinuity-aware Gaussian Splatting</title><link>https://deep-diver.github.io/neurips2024/posters/scbmemtsh5/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/scbmemtsh5/</guid><description>DisC-GS enhances Gaussian Splatting for real-time novel view synthesis by accurately rendering image discontinuities and boundaries, improving visual quality.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/scbmemtsh5/cover.png"/></item><item><title>Distribution Guidance Network for Weakly Supervised Point Cloud Semantic Segmentation</title><link>https://deep-diver.github.io/neurips2024/posters/jj2peazpwk/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/jj2peazpwk/</guid><description>DGNet enhances weakly supervised point cloud segmentation by aligning feature embeddings to a mixture of von Mises-Fisher distributions, achieving state-of-the-art performance.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/jj2peazpwk/cover.png"/></item><item><title>DiTFastAttn: Attention Compression for Diffusion Transformer Models</title><link>https://deep-diver.github.io/neurips2024/posters/51hqpkqy3t/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/51hqpkqy3t/</guid><description>DiTFastAttn: A post-training compression method drastically speeds up diffusion transformer models by cleverly reducing redundancy in attention calculations, leading to up to a 1.8x speedup at high re&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/51hqpkqy3t/cover.png"/></item><item><title>DMesh: A Differentiable Mesh Representation</title><link>https://deep-diver.github.io/neurips2024/posters/io1qkqcvik/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/io1qkqcvik/</guid><description>DMesh: A novel differentiable mesh representation enabling efficient gradient-based optimization for diverse 3D shape applications.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/io1qkqcvik/cover.png"/></item><item><title>DN-4DGS: Denoised Deformable Network with Temporal-Spatial Aggregation for Dynamic Scene Rendering</title><link>https://deep-diver.github.io/neurips2024/posters/qqsynx5s83/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/qqsynx5s83/</guid><description>DN-4DGS: Real-time dynamic scene rendering is revolutionized by a denoised deformable network with temporal-spatial aggregation, achieving state-of-the-art quality.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/qqsynx5s83/cover.png"/></item><item><title>Does Video-Text Pretraining Help Open-Vocabulary Online Action Detection?</title><link>https://deep-diver.github.io/neurips2024/posters/pwzb2v2b6r/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/pwzb2v2b6r/</guid><description>Zero-shot online action detection gets a boost! OV-OAD leverages vision-language models and text supervision to achieve impressive performance on various benchmarks without relying on manual annotati&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/pwzb2v2b6r/cover.png"/></item><item><title>DomainGallery: Few-shot Domain-driven Image Generation by Attribute-centric Finetuning</title><link>https://deep-diver.github.io/neurips2024/posters/zmmj1z8vee/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/zmmj1z8vee/</guid><description>DomainGallery: Few-shot domain-driven image generation via attribute-centric finetuning, solving key issues of previous works by introducing attribute erasure, disentanglement, regularization, and enh&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/zmmj1z8vee/cover.png"/></item><item><title>Doubly Hierarchical Geometric Representations for Strand-based Human Hairstyle Generation</title><link>https://deep-diver.github.io/neurips2024/posters/h34jvnpo1c/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/h34jvnpo1c/</guid><description>Doubly hierarchical geometric representations enable realistic human hairstyle generation by separating low and high-frequency details in hair strands, resulting in high-quality, detailed virtual hair&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/h34jvnpo1c/cover.png"/></item><item><title>DRACO: A Denoising-Reconstruction Autoencoder for Cryo-EM</title><link>https://deep-diver.github.io/neurips2024/posters/u1mnglyn74/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/u1mnglyn74/</guid><description>DRACO, a denoising-reconstruction autoencoder, revolutionizes cryo-EM by leveraging a large-scale dataset and hybrid training for superior image denoising and downstream task performance.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/u1mnglyn74/cover.png"/></item><item><title>DreamScene4D: Dynamic Multi-Object Scene Generation from Monocular Videos</title><link>https://deep-diver.github.io/neurips2024/posters/ylivhhfwq2/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/ylivhhfwq2/</guid><description>DreamScene4D generates realistic 3D dynamic multi-object scenes from monocular videos via novel view synthesis, addressing limitations of existing methods with a novel decompose-recompose approach.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/ylivhhfwq2/cover.png"/></item><item><title>DRIP: Unleashing Diffusion Priors for Joint Foreground and Alpha Prediction in Image Matting</title><link>https://deep-diver.github.io/neurips2024/posters/jz5zmen9he/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/jz5zmen9he/</guid><description>DRIP: A novel image matting method using pre-trained latent diffusion models achieves state-of-the-art performance by jointly predicting foreground and alpha values, significantly improving accuracy a&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/jz5zmen9he/cover.png"/></item><item><title>Dual Encoder GAN Inversion for High-Fidelity 3D Head Reconstruction from Single Images</title><link>https://deep-diver.github.io/neurips2024/posters/sldx451mjc/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/sldx451mjc/</guid><description>Dual encoder GAN inversion achieves high-fidelity 3D head reconstruction from single images by cleverly combining outputs from encoders specialized for visible and invisible regions, surpassing existi&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/sldx451mjc/cover.png"/></item><item><title>Dual-frame Fluid Motion Estimation with Test-time Optimization and Zero-divergence Loss</title><link>https://deep-diver.github.io/neurips2024/posters/wobhjs9gqu/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/wobhjs9gqu/</guid><description>Self-supervised dual-frame fluid motion estimation achieves superior accuracy with 99% less training data, using a novel zero-divergence loss and dynamic velocimetry enhancement.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/wobhjs9gqu/cover.png"/></item><item><title>Dynamic Tuning Towards Parameter and Inference Efficiency for ViT Adaptation</title><link>https://deep-diver.github.io/neurips2024/posters/e0sq6wshjv/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/e0sq6wshjv/</guid><description>Dynamic Tuning (DyT) significantly boosts Vision Transformer (ViT) adaptation by dynamically skipping less important tokens during inference, achieving superior performance with 71% fewer FLOPs than e&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/e0sq6wshjv/cover.png"/></item><item><title>E2ENet: Dynamic Sparse Feature Fusion for Accurate and Efficient 3D Medical Image Segmentation</title><link>https://deep-diver.github.io/neurips2024/posters/xp8qhdmeb4/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/xp8qhdmeb4/</guid><description>E2ENet: A novel 3D medical image segmentation model boasts high accuracy and efficiency by dynamically fusing multi-scale features and using restricted depth-shift 3D convolutions, significantly outp&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/xp8qhdmeb4/cover.png"/></item><item><title>ECMamba: Consolidating Selective State Space Model with Retinex Guidance for Efficient Multiple Exposure Correction</title><link>https://deep-diver.github.io/neurips2024/posters/mzsvm58fpg/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/mzsvm58fpg/</guid><description>ECMamba: A novel dual-branch framework efficiently corrects multiple exposure images by integrating Retinex theory and an innovative 2D selective state-space layer, achieving state-of-the-art performa&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/mzsvm58fpg/cover.png"/></item><item><title>EEG2Video: Towards Decoding Dynamic Visual Perception from EEG Signals</title><link>https://deep-diver.github.io/neurips2024/posters/rfsfrn9ofd/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/rfsfrn9ofd/</guid><description>EEG2Video reconstructs dynamic videos from EEG signals, achieving 79.8% accuracy in semantic classification and 0.256 SSIM in video reconstruction.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/rfsfrn9ofd/cover.png"/></item><item><title>Efficient Adaptation of Pre-trained Vision Transformer via Householder Transformation</title><link>https://deep-diver.github.io/neurips2024/posters/botjmacaci/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/botjmacaci/</guid><description>Boosting Vision Transformer adaptation! Householder Transformation-based Adaptor (HTA) outperforms existing methods by dynamically adjusting adaptation matrix ranks across layers, improving efficiency&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/botjmacaci/cover.png"/></item><item><title>EfficientCAPER: An End-to-End Framework for Fast and Robust Category-Level Articulated Object Pose Estimation</title><link>https://deep-diver.github.io/neurips2024/posters/lbxsp79ocd/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/lbxsp79ocd/</guid><description>EfficientCAPER: A novel end-to-end framework achieves fast &amp;amp; robust category-level articulated object pose estimation by using a joint-centric approach, eliminating post-processing optimization and en&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/lbxsp79ocd/cover.png"/></item><item><title>EgoChoir: Capturing 3D Human-Object Interaction Regions from Egocentric Views</title><link>https://deep-diver.github.io/neurips2024/posters/ea4oxkimp7/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/ea4oxkimp7/</guid><description>EgoChoir: a novel framework harmonizes visual appearance, head motion, and 3D objects to accurately estimate 3D human contact and object affordance from egocentric videos, surpassing existing methods.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/ea4oxkimp7/cover.png"/></item><item><title>Elucidating the Design Space of Dataset Condensation</title><link>https://deep-diver.github.io/neurips2024/posters/az1sllsmdr/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/az1sllsmdr/</guid><description>Elucidating Dataset Condensation (EDC) achieves state-of-the-art accuracy in dataset condensation by implementing soft category-aware matching and a smoothing learning rate schedule, improving model t&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/az1sllsmdr/cover.png"/></item><item><title>EM Distillation for One-step Diffusion Models</title><link>https://deep-diver.github.io/neurips2024/posters/rafvvthuxd/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/rafvvthuxd/</guid><description>EM Distillation (EMD) efficiently trains one-step diffusion models by using an Expectation-Maximization approach, achieving state-of-the-art image generation quality and outperforming existing methods&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/rafvvthuxd/cover.png"/></item><item><title>ENAT: Rethinking Spatial-temporal Interactions in Token-based Image Synthesis</title><link>https://deep-diver.github.io/neurips2024/posters/phsyfytehr/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/phsyfytehr/</guid><description>EfficientNAT: a novel approach to token-based image synthesis boosts performance and slashes computational costs by cleverly disentangling and optimizing spatial-temporal interactions between image to&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/phsyfytehr/cover.png"/></item><item><title>Enhancing Consistency-Based Image Generation via Adversarialy-Trained Classification and Energy-Based Discrimination</title><link>https://deep-diver.github.io/neurips2024/posters/ubvcpamdgk/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/ubvcpamdgk/</guid><description>This paper introduces a novel post-processing technique that significantly boosts the perceptual quality of images generated by consistency models using a joint classifier-discriminator adversarially &amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/ubvcpamdgk/cover.png"/></item><item><title>EnsIR: An Ensemble Algorithm for Image Restoration via Gaussian Mixture Models</title><link>https://deep-diver.github.io/neurips2024/posters/s1moh2paca/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/s1moh2paca/</guid><description>EnsIR: Training-free image restoration ensemble via Gaussian mixture models, boosting accuracy efficiently.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/s1moh2paca/cover.png"/></item><item><title>Epipolar-Free 3D Gaussian Splatting for Generalizable Novel View Synthesis</title><link>https://deep-diver.github.io/neurips2024/posters/io6tcljewa/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/io6tcljewa/</guid><description>eFreeSplat: a novel, epipolar-free 3D Gaussian splatting model for generalizable novel view synthesis, surpassing state-of-the-art methods by achieving superior geometry reconstruction and novel view &amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/io6tcljewa/cover.png"/></item><item><title>Era3D: High-Resolution Multiview Diffusion using Efficient Row-wise Attention</title><link>https://deep-diver.github.io/neurips2024/posters/xdcjayyitp/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/xdcjayyitp/</guid><description>Era3D: High-resolution multiview diffusion using efficient row-wise attention, generates high-quality multiview images from single views, overcoming prior limitations.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/xdcjayyitp/cover.png"/></item><item><title>Expanding Sparse Tuning for Low Memory Usage</title><link>https://deep-diver.github.io/neurips2024/posters/abzyngwfpn/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/abzyngwfpn/</guid><description>SNELL: Sparse tuning with kerNElized LoRA achieves state-of-the-art parameter-efficient fine-tuning performance with drastically reduced memory usage.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/abzyngwfpn/cover.png"/></item><item><title>Exploring DCN-like architecture for fast image generation with arbitrary resolution</title><link>https://deep-diver.github.io/neurips2024/posters/e57b7bfa2b/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/e57b7bfa2b/</guid><description>FlowDCN: A purely convolutional generative model achieves state-of-the-art image generation speed and quality at arbitrary resolutions, surpassing transformer-based models.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/e57b7bfa2b/cover.png"/></item><item><title>Exploring Low-Dimensional Subspace in Diffusion Models for Controllable Image Editing</title><link>https://deep-diver.github.io/neurips2024/posters/50aoefb2km/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/50aoefb2km/</guid><description>LOCO Edit achieves precise, localized image editing in diffusion models via a single-step, training-free method leveraging low-dimensional semantic subspaces.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/50aoefb2km/cover.png"/></item><item><title>Exploring Token Pruning in Vision State Space Models</title><link>https://deep-diver.github.io/neurips2024/posters/ewign0fcdx/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/ewign0fcdx/</guid><description>This paper introduces a novel token pruning method for vision state space models, achieving significant computational reduction with minimal performance impact, addressing the limitations of directly &amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/ewign0fcdx/cover.png"/></item><item><title>Extending Video Masked Autoencoders to 128 frames</title><link>https://deep-diver.github.io/neurips2024/posters/bfrnplwchg/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/bfrnplwchg/</guid><description>Long-video masked autoencoders (LVMAE) achieve state-of-the-art performance by using an adaptive masking strategy that prioritizes important video tokens, enabling efficient training on 128 frames.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/bfrnplwchg/cover.png"/></item><item><title>F-OAL: Forward-only Online Analytic Learning with Fast Training and Low Memory Footprint in Class Incremental Learning</title><link>https://deep-diver.github.io/neurips2024/posters/rgedfs3emy/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/rgedfs3emy/</guid><description>F-OAL: Forward-only Online Analytic Learning achieves high accuracy and low memory usage in online class incremental learning by using a frozen encoder and recursive least squares to update a linear &amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/rgedfs3emy/cover.png"/></item><item><title>Face2QR: A Unified Framework for Aesthetic, Face-Preserving, and Scannable QR Code Generation</title><link>https://deep-diver.github.io/neurips2024/posters/rvbabl7duu/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/rvbabl7duu/</guid><description>Face2QR: A unified framework generates aesthetically pleasing, scannable QR codes that faithfully preserve facial features, solving the conflict between aesthetics, identity, and scannability.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/rvbabl7duu/cover.png"/></item><item><title>FashionR2R: Texture-preserving Rendered-to-Real Image Translation with Diffusion Models</title><link>https://deep-diver.github.io/neurips2024/posters/qaenr5j172/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/qaenr5j172/</guid><description>FashionR2R leverages diffusion models to realistically translate rendered fashion images into photorealistic counterparts, enhancing realism and preserving fine-grained clothing textures.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/qaenr5j172/cover.png"/></item><item><title>Fast Encoder-Based 3D from Casual Videos via Point Track Processing</title><link>https://deep-diver.github.io/neurips2024/posters/bqgaheaeqy/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/bqgaheaeqy/</guid><description>TRACKSTO4D: Fast &amp;amp; accurate 3D reconstruction from casual videos using 2D point tracks, drastically reducing runtime by up to 95% while matching state-of-the-art accuracy.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/bqgaheaeqy/cover.png"/></item><item><title>Feature-Level Adversarial Attacks and Ranking Disruption for Visible-Infrared Person Re-identification</title><link>https://deep-diver.github.io/neurips2024/posters/ranct2xkyi/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/ranct2xkyi/</guid><description>New feature-level adversarial attacks disrupt visible-infrared person re-identification (VIReID) systems by cleverly aligning and manipulating features to cause incorrect ranking results.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/ranct2xkyi/cover.png"/></item><item><title>Fetch and Forge: Efficient Dataset Condensation for Object Detection</title><link>https://deep-diver.github.io/neurips2024/posters/m8melyzuwp/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/m8melyzuwp/</guid><description>DCOD, a novel two-stage framework (Fetch &amp;amp; Forge), efficiently condenses object detection datasets, achieving comparable performance to full datasets at extremely low compression rates, significantly &amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/m8melyzuwp/cover.png"/></item><item><title>FewViewGS: Gaussian Splatting with Few View Matching and Multi-stage Training</title><link>https://deep-diver.github.io/neurips2024/posters/lihe9iumii/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/lihe9iumii/</guid><description>FewViewGS: A novel method for high-quality novel view synthesis from sparse images using a multi-stage training scheme and a new locality-preserving regularization for 3D Gaussians.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/lihe9iumii/cover.png"/></item><item><title>FFAM: Feature Factorization Activation Map for Explanation of 3D Detectors</title><link>https://deep-diver.github.io/neurips2024/posters/rpzwsdjc4n/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/rpzwsdjc4n/</guid><description>FFAM uses feature factorization and gradient weighting to produce high-quality visual explanations for 3D object detectors, improving model interpretability and trust.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/rpzwsdjc4n/cover.png"/></item><item><title>FIFO-Diffusion: Generating Infinite Videos from Text without Training</title><link>https://deep-diver.github.io/neurips2024/posters/uikhna4wam/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/uikhna4wam/</guid><description>FIFO-Diffusion generates infinitely long, high-quality videos from text prompts using a pretrained model, solving the challenge of long video generation without retraining.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/uikhna4wam/cover.png"/></item><item><title>Finding NeMo: Localizing Neurons Responsible For Memorization in Diffusion Models</title><link>https://deep-diver.github.io/neurips2024/posters/yaekmfzyjm/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/yaekmfzyjm/</guid><description>NEMO pinpoints &amp;amp; deactivates neurons memorizing training data in diffusion models, boosting privacy &amp;amp; image diversity.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/yaekmfzyjm/cover.png"/></item><item><title>Flatten Anything: Unsupervised Neural Surface Parameterization</title><link>https://deep-diver.github.io/neurips2024/posters/eneqgc9agr/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/eneqgc9agr/</guid><description>Flatten Anything Model (FAM) revolutionizes neural surface parameterization with unsupervised learning, handling complex topologies and unstructured data fully automatically.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/eneqgc9agr/cover.png"/></item><item><title>Flaws can be Applause: Unleashing Potential of Segmenting Ambiguous Objects in SAM</title><link>https://deep-diver.github.io/neurips2024/posters/vjsnssfo95/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/vjsnssfo95/</guid><description>A-SAM: Turning SAM&amp;rsquo;s inherent ambiguity into an advantage for controllable, diverse, and convincing ambiguous object segmentation.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/vjsnssfo95/cover.png"/></item><item><title>Flow Snapshot Neurons in Action: Deep Neural Networks Generalize to Biological Motion Perception</title><link>https://deep-diver.github.io/neurips2024/posters/btuhzsavsk/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/btuhzsavsk/</guid><description>Deep neural networks finally match human biological motion perception capabilities by leveraging patch-level optical flows and innovative neuron designs, achieving a 29% accuracy improvement.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/btuhzsavsk/cover.png"/></item><item><title>Fourier-enhanced Implicit Neural Fusion Network for Multispectral and Hyperspectral Image Fusion</title><link>https://deep-diver.github.io/neurips2024/posters/cscowtrop9/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/cscowtrop9/</guid><description>FeINFN: a novel Fourier-enhanced Implicit Neural Fusion Network, achieves state-of-the-art hyperspectral image fusion by innovatively combining spatial and frequency information in both the spatial an&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/cscowtrop9/cover.png"/></item><item><title>FreeLong: Training-Free Long Video Generation with SpectralBlend Temporal Attention</title><link>https://deep-diver.github.io/neurips2024/posters/x9fga52oov/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/x9fga52oov/</guid><description>FreeLong: Generate high-fidelity long videos without retraining using spectral blending of global and local video features!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/x9fga52oov/cover.png"/></item><item><title>FreeSplat: Generalizable 3D Gaussian Splatting Towards Free View Synthesis of Indoor Scenes</title><link>https://deep-diver.github.io/neurips2024/posters/ml01xyp698/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/ml01xyp698/</guid><description>FreeSplat achieves state-of-the-art novel view synthesis by accurately localizing 3D Gaussians from long image sequences, overcoming limitations of prior methods confined to narrow-range interpolation&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/ml01xyp698/cover.png"/></item><item><title>From Chaos to Clarity: 3DGS in the Dark</title><link>https://deep-diver.github.io/neurips2024/posters/lwhe7pmk7c/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/lwhe7pmk7c/</guid><description>Researchers developed a self-supervised learning framework to create high-dynamic-range 3D Gaussian Splatting (3DGS) models from noisy raw images, significantly improving reconstruction quality and sp&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/lwhe7pmk7c/cover.png"/></item><item><title>From Transparent to Opaque: Rethinking Neural Implicit Surfaces with $lpha$-NeuS</title><link>https://deep-diver.github.io/neurips2024/posters/pojt9rwijj/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/pojt9rwijj/</guid><description>α-NeuS: A novel method for neural implicit surface reconstruction that accurately reconstructs both transparent and opaque objects simultaneously by leveraging the unique properties of distance fields&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/pojt9rwijj/cover.png"/></item><item><title>From Trojan Horses to Castle Walls: Unveiling Bilateral Data Poisoning Effects in Diffusion Models</title><link>https://deep-diver.github.io/neurips2024/posters/yixzzc5qdi/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/yixzzc5qdi/</guid><description>Diffusion models, while excelling in image generation, are vulnerable to data poisoning. This paper demonstrates a BadNets-like attack&amp;rsquo;s effectiveness against diffusion models, causing image misalign&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/yixzzc5qdi/cover.png"/></item><item><title>Frozen-DETR: Enhancing DETR with Image Understanding from Frozen Foundation Models</title><link>https://deep-diver.github.io/neurips2024/posters/erqdc72vyi/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/erqdc72vyi/</guid><description>Frozen-DETR boosts object detection accuracy by integrating frozen foundation models as feature enhancers, achieving significant performance gains without the computational cost of fine-tuning.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/erqdc72vyi/cover.png"/></item><item><title>Full-Distance Evasion of Pedestrian Detectors in the Physical World</title><link>https://deep-diver.github.io/neurips2024/posters/lwywzklsvg/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/lwywzklsvg/</guid><description>Researchers developed Full Distance Attack (FDA) to generate adversarial patterns effective against pedestrian detectors across all distances, resolving the appearance gap issue between simulated and &amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/lwywzklsvg/cover.png"/></item><item><title>GaussianCube: A Structured and Explicit Radiance Representation for 3D Generative Modeling</title><link>https://deep-diver.github.io/neurips2024/posters/dg2f1rvem5/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/dg2f1rvem5/</guid><description>GaussianCube revolutionizes 3D generative modeling with a structured, explicit radiance representation, achieving state-of-the-art results using significantly fewer parameters.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/dg2f1rvem5/cover.png"/></item><item><title>GaussianMarker: Uncertainty-Aware Copyright Protection of 3D Gaussian Splatting</title><link>https://deep-diver.github.io/neurips2024/posters/wcxhbay8b3/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/wcxhbay8b3/</guid><description>GaussianMarker: A novel uncertainty-aware watermarking method ensures robust copyright protection for 3D Gaussian Splatting assets, invisibly embedding messages into model parameters and extractable &amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/wcxhbay8b3/cover.png"/></item><item><title>General Articulated Objects Manipulation in Real Images via Part-Aware Diffusion Process</title><link>https://deep-diver.github.io/neurips2024/posters/wrd9lcbvxn/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/wrd9lcbvxn/</guid><description>Part-Aware Diffusion Model (PA-Diffusion) enables precise and efficient manipulation of articulated objects in real images by using abstract 3D models and dynamic feature maps, overcoming limitations &amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/wrd9lcbvxn/cover.png"/></item><item><title>Generalizable Implicit Motion Modeling for Video Frame Interpolation</title><link>https://deep-diver.github.io/neurips2024/posters/zlpjlqsr2v/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/zlpjlqsr2v/</guid><description>Generalizable Implicit Motion Modeling (GIMM) revolutionizes video frame interpolation by accurately predicting optical flows at any timestep, surpassing existing methods and achieving state-of-the-ar&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/zlpjlqsr2v/cover.png"/></item><item><title>GenRec: Unifying Video Generation and Recognition with Diffusion Models</title><link>https://deep-diver.github.io/neurips2024/posters/ydfzp7qmzp/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/ydfzp7qmzp/</guid><description>GenRec: One diffusion model to rule both video generation and recognition!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/ydfzp7qmzp/cover.png"/></item><item><title>GenWarp: Single Image to Novel Views with Semantic-Preserving Generative Warping</title><link>https://deep-diver.github.io/neurips2024/posters/rljisjmmkw/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/rljisjmmkw/</guid><description>GenWarp generates high-quality novel image views from a single input image by using a semantic-preserving generative warping framework, outperforming existing methods.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/rljisjmmkw/cover.png"/></item><item><title>GeoLRM: Geometry-Aware Large Reconstruction Model for High-Quality 3D Gaussian Generation</title><link>https://deep-diver.github.io/neurips2024/posters/em5d7zmeka/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/em5d7zmeka/</guid><description>GeoLRM: Generate stunning 3D models from just 21 images using a novel geometry-aware transformer, surpassing existing methods in efficiency and quality!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/em5d7zmeka/cover.png"/></item><item><title>Geometric Analysis of Nonlinear Manifold Clustering</title><link>https://deep-diver.github.io/neurips2024/posters/nbqhtbvnfr/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/nbqhtbvnfr/</guid><description>Guaranteed Manifold Clustering: Novel method provides geometric conditions ensuring accurate data grouping from nonlinear manifolds, showing competitive performance on CIFAR datasets.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/nbqhtbvnfr/cover.png"/></item><item><title>GeoNLF: Geometry guided Pose-Free Neural LiDAR Fields</title><link>https://deep-diver.github.io/neurips2024/posters/v3y785tn7b/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/v3y785tn7b/</guid><description>GeoNLF: Geometry-guided Pose-free Neural LiDAR Fields revolutionizes LiDAR point cloud processing by cleverly combining neural and geometric optimization for superior novel view synthesis and multi-vi&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/v3y785tn7b/cover.png"/></item><item><title>Goal Conditioned Reinforcement Learning for Photo Finishing Tuning</title><link>https://deep-diver.github.io/neurips2024/posters/4kvhi2uxre/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/4kvhi2uxre/</guid><description>This paper introduces a goal-conditioned reinforcement learning approach that efficiently tunes photo finishing pipelines, achieving high-quality results in fewer iterations than optimization-based me&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/4kvhi2uxre/cover.png"/></item><item><title>Gradient-free Decoder Inversion in Latent Diffusion Models</title><link>https://deep-diver.github.io/neurips2024/posters/nbqvjkos6s/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/nbqvjkos6s/</guid><description>This paper introduces a novel gradient-free decoder inversion method for latent diffusion models, improving efficiency and memory usage compared to existing gradient-based methods. The method is theo&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/nbqvjkos6s/cover.png"/></item><item><title>GraphMorph: Tubular Structure Extraction by Morphing Predicted Graphs</title><link>https://deep-diver.github.io/neurips2024/posters/hw5qwicctl/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/hw5qwicctl/</guid><description>GraphMorph: revolutionizing tubular structure extraction by morphing predicted graphs for superior topological accuracy.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/hw5qwicctl/cover.png"/></item><item><title>Grid4D: 4D Decomposed Hash Encoding for High-fidelity Dynamic Gaussian Splatting</title><link>https://deep-diver.github.io/neurips2024/posters/eyfyc19god/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/eyfyc19god/</guid><description>Grid4D: A novel 4D decomposed hash encoding boosts high-fidelity dynamic Gaussian splatting, surpassing state-of-the-art models in visual quality and rendering speed.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/eyfyc19god/cover.png"/></item><item><title>GSDF: 3DGS Meets SDF for Improved Neural Rendering and Reconstruction</title><link>https://deep-diver.github.io/neurips2024/posters/r6v7ejanuk/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/r6v7ejanuk/</guid><description>GSDF: A novel dual-branch neural scene representation elegantly resolves the rendering-reconstruction trade-off by synergistically combining 3D Gaussian Splatting and Signed Distance Fields via mutual&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/r6v7ejanuk/cover.png"/></item><item><title>GSGAN: Adversarial Learning for Hierarchical Generation of 3D Gaussian Splats</title><link>https://deep-diver.github.io/neurips2024/posters/sfafdcvnbw/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/sfafdcvnbw/</guid><description>GSGAN introduces a hierarchical 3D Gaussian representation for faster, high-quality 3D model generation in GANs, achieving 100x speed improvement over existing methods.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/sfafdcvnbw/cover.png"/></item><item><title>GVKF: Gaussian Voxel Kernel Functions for Highly Efficient Surface Reconstruction in Open Scenes</title><link>https://deep-diver.github.io/neurips2024/posters/dqd0dnrjxk/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/dqd0dnrjxk/</guid><description>GVKF: A novel method achieves highly efficient and accurate 3D surface reconstruction in open scenes by integrating fast 3D Gaussian splatting with continuous scene representation using kernel regres&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/dqd0dnrjxk/cover.png"/></item><item><title>HairFastGAN: Realistic and Robust Hair Transfer with a Fast Encoder-Based Approach</title><link>https://deep-diver.github.io/neurips2024/posters/sgvzyv2iqn/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/sgvzyv2iqn/</guid><description>HairFastGAN achieves realistic and robust hairstyle transfer in near real-time using a novel encoder-based approach, significantly outperforming optimization-based methods.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/sgvzyv2iqn/cover.png"/></item><item><title>Happy: A Debiased Learning Framework for Continual Generalized Category Discovery</title><link>https://deep-diver.github.io/neurips2024/posters/hduczimkfo/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/hduczimkfo/</guid><description>Happy: a novel debiased learning framework, excels at continually discovering new categories from unlabeled data while retaining knowledge of previously learned ones, overcoming existing bias issues a&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/hduczimkfo/cover.png"/></item><item><title>Harnessing small projectors and multiple views for efficient vision pretraining</title><link>https://deep-diver.github.io/neurips2024/posters/y5dpsjzpra/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/y5dpsjzpra/</guid><description>Boost self-supervised visual learning: This paper introduces theoretical insights and practical recommendations to significantly improve SSL&amp;rsquo;s efficiency and reduce data needs.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/y5dpsjzpra/cover.png"/></item><item><title>HDR-GS: Efficient High Dynamic Range Novel View Synthesis at 1000x Speed via Gaussian Splatting</title><link>https://deep-diver.github.io/neurips2024/posters/hkmccfrykt/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/hkmccfrykt/</guid><description>HDR-GS: 1000x faster HDR novel view synthesis via Gaussian splatting!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/hkmccfrykt/cover.png"/></item><item><title>HiCo: Hierarchical Controllable Diffusion Model for Layout-to-image Generation</title><link>https://deep-diver.github.io/neurips2024/posters/i9qprjuahv/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/i9qprjuahv/</guid><description>HiCo: Hierarchical Controllable Diffusion Model achieves superior layout-to-image generation by disentangling spatial layouts through a multi-branch network structure, resulting in high-quality images&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/i9qprjuahv/cover.png"/></item><item><title>HiCoM: Hierarchical Coherent Motion for Dynamic Streamable Scenes with 3D Gaussian Splatting</title><link>https://deep-diver.github.io/neurips2024/posters/de4vwe4rbz/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/de4vwe4rbz/</guid><description>HiCoM, a novel framework, achieves high-fidelity streamable dynamic scene reconstruction by using a hierarchical coherent motion mechanism and parallel processing to significantly reduce training time&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/de4vwe4rbz/cover.png"/></item><item><title>Hierarchical Selective Classification</title><link>https://deep-diver.github.io/neurips2024/posters/wzof7y66xs/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/wzof7y66xs/</guid><description>Hierarchical Selective Classification (HSC) improves deep learning model reliability for risk-sensitive tasks by leveraging hierarchical class relationships to provide more informative predictions eve&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/wzof7y66xs/cover.png"/></item><item><title>High-Resolution Image Harmonization with Adaptive-Interval Color Transformation</title><link>https://deep-diver.github.io/neurips2024/posters/jxghewtxs8/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/jxghewtxs8/</guid><description>AICT: Adaptive-Interval Color Transformation harmonizes high-resolution images by predicting pixel-wise color changes, adaptively adjusting sampling intervals to capture local variations, and using a &amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/jxghewtxs8/cover.png"/></item><item><title>Historical Test-time Prompt Tuning for Vision Foundation Models</title><link>https://deep-diver.github.io/neurips2024/posters/b1zntgthgw/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/b1zntgthgw/</guid><description>HisTPT: Historical Test-Time Prompt Tuning memorizes past learning, enabling robust online prompt adaptation for vision models, overcoming performance degradation in continuously changing data streams&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/b1zntgthgw/cover.png"/></item><item><title>Hollowed Net for On-Device Personalization of Text-to-Image Diffusion Models</title><link>https://deep-diver.github.io/neurips2024/posters/pa8jsrdonu/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/pa8jsrdonu/</guid><description>Hollowed Net efficiently personalizes text-to-image diffusion models on-device by temporarily removing deep U-Net layers during training, drastically reducing memory usage without sacrificing performa&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/pa8jsrdonu/cover.png"/></item><item><title>How to Use Diffusion Priors under Sparse Views?</title><link>https://deep-diver.github.io/neurips2024/posters/i6bbclcymr/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/i6bbclcymr/</guid><description>Inline Prior Guided Score Matching (IPSM) improves sparse-view 3D reconstruction by leveraging visual inline priors from pose relationships to rectify rendered image distribution and effectively guide&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/i6bbclcymr/cover.png"/></item><item><title>HumanSplat: Generalizable Single-Image Human Gaussian Splatting with Structure Priors</title><link>https://deep-diver.github.io/neurips2024/posters/jbaug7o8yv/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/jbaug7o8yv/</guid><description>HumanSplat: single image-based 3D human reconstruction using Gaussian Splatting with structural priors, achieving state-of-the-art quality and speed.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/jbaug7o8yv/cover.png"/></item><item><title>Hybrid Mamba for Few-Shot Segmentation</title><link>https://deep-diver.github.io/neurips2024/posters/qe2bkecebc/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/qe2bkecebc/</guid><description>Hybrid Mamba Network (HMNet) boosts few-shot segmentation accuracy by efficiently fusing support and query features using a novel hybrid Mamba architecture, significantly outperforming current state-o&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/qe2bkecebc/cover.png"/></item><item><title>HydraViT: Stacking Heads for a Scalable ViT</title><link>https://deep-diver.github.io/neurips2024/posters/kk0eaunc58/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/kk0eaunc58/</guid><description>HydraViT: Stacking attention heads creates a scalable Vision Transformer, adapting to diverse hardware by dynamically selecting subnetworks during inference, improving accuracy and efficiency.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/kk0eaunc58/cover.png"/></item><item><title>ID-to-3D: Expressive ID-guided 3D Heads via Score Distillation Sampling</title><link>https://deep-diver.github.io/neurips2024/posters/sluzpdmdfg/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/sluzpdmdfg/</guid><description>ID-to-3D: Generate expressive, identity-consistent 3D human heads from just a few in-the-wild images using score distillation sampling and 2D diffusion models.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/sluzpdmdfg/cover.png"/></item><item><title>Identifying and Solving Conditional Image Leakage in Image-to-Video Diffusion Model</title><link>https://deep-diver.github.io/neurips2024/posters/o9lkiv1qpc/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/o9lkiv1qpc/</guid><description>Researchers solve the conditional image leakage problem in image-to-video diffusion models by proposing a new inference strategy and a time-dependent noise distribution for training. This yields video&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/o9lkiv1qpc/cover.png"/></item><item><title>Identity Decoupling for Multi-Subject Personalization of Text-to-Image Models</title><link>https://deep-diver.github.io/neurips2024/posters/teepvpdarf/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/teepvpdarf/</guid><description>MuDI: a novel framework for multi-subject image personalization, effectively decoupling identities to prevent mixing using segmented subjects and a new evaluation metric.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/teepvpdarf/cover.png"/></item><item><title>IllumiNeRF: 3D Relighting Without Inverse Rendering</title><link>https://deep-diver.github.io/neurips2024/posters/k6m3y6qnsj/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/k6m3y6qnsj/</guid><description>IllumiNeRF: Relightable 3D reconstruction without inverse rendering using image diffusion and NeRF.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/k6m3y6qnsj/cover.png"/></item><item><title>Image Reconstruction Via Autoencoding Sequential Deep Image Prior</title><link>https://deep-diver.github.io/neurips2024/posters/k1eg2abzne/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/k1eg2abzne/</guid><description>aSeqDIP: A new unsupervised image reconstruction method using sequential deep image priors, achieving competitive performance with fewer data needs and faster runtimes.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/k1eg2abzne/cover.png"/></item><item><title>Image Understanding Makes for A Good Tokenizer for Image Generation</title><link>https://deep-diver.github.io/neurips2024/posters/rmmgu49lwn/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/rmmgu49lwn/</guid><description>Leveraging image understanding models for image tokenizer training dramatically boosts image generation quality, achieving state-of-the-art results.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/rmmgu49lwn/cover.png"/></item><item><title>ImOV3D: Learning Open Vocabulary Point Clouds 3D Object Detection from Only 2D Images</title><link>https://deep-diver.github.io/neurips2024/posters/rco9frp8aj/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/rco9frp8aj/</guid><description>ImOV3D: Revolutionizing open-vocabulary 3D object detection by learning from 2D images alone!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/rco9frp8aj/cover.png"/></item><item><title>Improving Robustness of 3D Point Cloud Recognition from a Fourier Perspective</title><link>https://deep-diver.github.io/neurips2024/posters/4jn7kwphsd/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/4jn7kwphsd/</guid><description>Boosting 3D point cloud recognition robustness, Frequency Adversarial Training (FAT) leverages frequency-domain adversarial examples to improve model resilience against corruptions, achieving state-of&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/4jn7kwphsd/cover.png"/></item><item><title>Improving Viewpoint-Independent Object-Centric Representations through Active Viewpoint Selection</title><link>https://deep-diver.github.io/neurips2024/posters/tjiw1olacd/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/tjiw1olacd/</guid><description>Active Viewpoint Selection (AVS) significantly improves viewpoint-independent object-centric representations by actively selecting the most informative viewpoints for each scene, leading to better seg&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/tjiw1olacd/cover.png"/></item><item><title>In Pursuit of Causal Label Correlations for Multi-label Image Recognition</title><link>https://deep-diver.github.io/neurips2024/posters/ybhbespwys/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/ybhbespwys/</guid><description>This research leverages causal intervention to identify and utilize genuine label correlations in multi-label image recognition, mitigating contextual bias for improved accuracy.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/ybhbespwys/cover.png"/></item><item><title>In-Context Symmetries: Self-Supervised Learning through Contextual World Models</title><link>https://deep-diver.github.io/neurips2024/posters/etpah4xsun/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/etpah4xsun/</guid><description>CONTEXTSSL: A novel self-supervised learning algorithm that adapts to task-specific symmetries by using context, achieving significant performance gains over existing methods.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/etpah4xsun/cover.png"/></item><item><title>In-N-Out: Lifting 2D Diffusion Prior for 3D Object Removal via Tuning-Free Latents Alignment</title><link>https://deep-diver.github.io/neurips2024/posters/gffaydu9mm/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/gffaydu9mm/</guid><description>In-N-Out: Lifting 2D Diffusion Priors for 3D Object Removal via Tuning-Free Latents Alignment enhances 3D scene reconstruction by aligning 2D diffusion model latents for consistent multi-view inpainti&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/gffaydu9mm/cover.png"/></item><item><title>Incorporating Test-Time Optimization into Training with Dual Networks for Human Mesh Recovery</title><link>https://deep-diver.github.io/neurips2024/posters/ugqx9tgyum/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/ugqx9tgyum/</guid><description>Meta-learning enhances human mesh recovery by unifying training and test-time objectives, significantly improving accuracy and generalization.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/ugqx9tgyum/cover.png"/></item><item><title>Inferring Neural Signed Distance Functions by Overfitting on Single Noisy Point Clouds through Finetuning Data-Driven based Priors</title><link>https://deep-diver.github.io/neurips2024/posters/hgqs1b4ecy/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/hgqs1b4ecy/</guid><description>This research presents LocalN2NM, a novel method for inferring neural signed distance functions (SDF) from single, noisy point clouds by finetuning data-driven priors, achieving faster inference and b&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/hgqs1b4ecy/cover.png"/></item><item><title>Infinite-Dimensional Feature Interaction</title><link>https://deep-diver.github.io/neurips2024/posters/xo9ghdmk76/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/xo9ghdmk76/</guid><description>InfiNet achieves state-of-the-art results by enabling feature interaction in an infinite-dimensional space using RBF kernels, surpassing models limited to finite-dimensional interactions.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/xo9ghdmk76/cover.png"/></item><item><title>Integrating Deep Metric Learning with Coreset for Active Learning in 3D Segmentation</title><link>https://deep-diver.github.io/neurips2024/posters/uyqjpycmbu/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/uyqjpycmbu/</guid><description>Deep metric learning and Coreset integration enables efficient slice-based active learning for 3D medical segmentation, surpassing existing methods in performance with low annotation budgets.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/uyqjpycmbu/cover.png"/></item><item><title>Interpretable Image Classification with Adaptive Prototype-based Vision Transformers</title><link>https://deep-diver.github.io/neurips2024/posters/hjhpcjfbfg/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/hjhpcjfbfg/</guid><description>ProtoViT: a novel interpretable image classification method using Vision Transformers and adaptive prototypes, achieving higher accuracy and providing clear explanations.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/hjhpcjfbfg/cover.png"/></item><item><title>Interpreting the Weight Space of Customized Diffusion Models</title><link>https://deep-diver.github.io/neurips2024/posters/dao2bfzmfy/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/dao2bfzmfy/</guid><description>Researchers model a manifold of customized diffusion models as a subspace of weights, enabling controllable creation of new models via sampling, editing, and inversion from a single image.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/dao2bfzmfy/cover.png"/></item><item><title>Invertible Consistency Distillation for Text-Guided Image Editing in Around 7 Steps</title><link>https://deep-diver.github.io/neurips2024/posters/b1xphc7mqb/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/b1xphc7mqb/</guid><description>Invertible Consistency Distillation (iCD) achieves high-quality image editing in ~7 steps by enabling both fast editing and strong generation using a generalized distillation framework and dynamic cla&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/b1xphc7mqb/cover.png"/></item><item><title>Is Multiple Object Tracking a Matter of Specialization?</title><link>https://deep-diver.github.io/neurips2024/posters/aujnnniiim/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/aujnnniiim/</guid><description>PASTA: A novel modular framework boosts MOT tracker generalization by using parameter-efficient fine-tuning and avoiding negative interference through specialized modules for various scenario attribut&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/aujnnniiim/cover.png"/></item><item><title>Key-Grid: Unsupervised 3D Keypoints Detection using Grid Heatmap Features</title><link>https://deep-diver.github.io/neurips2024/posters/4pcu9c8lex/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/4pcu9c8lex/</guid><description>Key-Grid: An unsupervised 3D keypoint detector achieving state-of-the-art semantic consistency and accuracy for both rigid and deformable objects using novel grid heatmap features.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/4pcu9c8lex/cover.png"/></item><item><title>KOALA: Empirical Lessons Toward Memory-Efficient and Fast Diffusion Models for Text-to-Image Synthesis</title><link>https://deep-diver.github.io/neurips2024/posters/kndubpwv9b/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/kndubpwv9b/</guid><description>KOALA: New efficient text-to-image diffusion models achieving 4x speed and 69% size reduction of SDXL, generating 1024px images on consumer GPUs with 8GB VRAM.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/kndubpwv9b/cover.png"/></item><item><title>L4GM: Large 4D Gaussian Reconstruction Model</title><link>https://deep-diver.github.io/neurips2024/posters/psptj26lbp/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/psptj26lbp/</guid><description>L4GM: The first 4D model generating high-quality animated 3D objects from single-view videos in a single feed-forward pass.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/psptj26lbp/cover.png"/></item><item><title>Large Spatial Model: End-to-end Unposed Images to Semantic 3D</title><link>https://deep-diver.github.io/neurips2024/posters/ybhpzl7eyt/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/ybhpzl7eyt/</guid><description>Large Spatial Model (LSM) achieves real-time semantic 3D reconstruction from just two unposed images, unifying multiple 3D vision tasks in a single feed-forward pass.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/ybhpzl7eyt/cover.png"/></item><item><title>Latent Representation Matters: Human-like Sketches in One-shot Drawing Tasks</title><link>https://deep-diver.github.io/neurips2024/posters/tzrpvlxevu/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/tzrpvlxevu/</guid><description>AI now draws almost as well as humans, thanks to novel latent diffusion model regularizations that mimic human cognitive biases.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/tzrpvlxevu/cover.png"/></item><item><title>Learning 3D Equivariant Implicit Function with Patch-Level Pose-Invariant Representation</title><link>https://deep-diver.github.io/neurips2024/posters/axs1pwma8i/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/axs1pwma8i/</guid><description>3D surface reconstruction revolutionized: PEIF leverages patch-level pose-invariant representations and 3D patch-level equivariance for state-of-the-art accuracy, even with varied poses and datasets!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/axs1pwma8i/cover.png"/></item><item><title>Learning 3D Garment Animation from Trajectories of A Piece of Cloth</title><link>https://deep-diver.github.io/neurips2024/posters/yefx5nqmr7/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/yefx5nqmr7/</guid><description>Animates diverse garments realistically from a single cloth&amp;rsquo;s trajectory using a disentangled learning approach and Energy Unit Network (EUNet).</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/yefx5nqmr7/cover.png"/></item><item><title>Learning Bregman Divergences with Application to Robustness</title><link>https://deep-diver.github.io/neurips2024/posters/yuckudjae0/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/yuckudjae0/</guid><description>Learned Bregman divergences significantly improve image corruption robustness in adversarial training.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/yuckudjae0/cover.png"/></item><item><title>Learning Commonality, Divergence and Variety for Unsupervised Visible-Infrared Person Re-identification</title><link>https://deep-diver.github.io/neurips2024/posters/qqsgwpmdfu/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/qqsgwpmdfu/</guid><description>Progressive Contrastive Learning with Hard &amp;amp; Dynamic Prototypes (PCLHD) revolutionizes unsupervised visible-infrared person re-identification by effectively capturing data commonality, divergence, and&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/qqsgwpmdfu/cover.png"/></item><item><title>Learning De-Biased Representations for Remote-Sensing Imagery</title><link>https://deep-diver.github.io/neurips2024/posters/mwn1bbd5dq/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/mwn1bbd5dq/</guid><description>DebLoRA: A novel unsupervised learning approach debiases LoRA for remote sensing imagery, boosting minor class performance without sacrificing major class accuracy.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/mwn1bbd5dq/cover.png"/></item><item><title>Learning Frequency-Adapted Vision Foundation Model for Domain Generalized Semantic Segmentation</title><link>https://deep-diver.github.io/neurips2024/posters/b7hmploqr8/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/b7hmploqr8/</guid><description>FADA: a novel frequency-adapted learning scheme boosts domain-generalized semantic segmentation by decoupling style and content using Haar wavelets, achieving state-of-the-art results.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/b7hmploqr8/cover.png"/></item><item><title>Learning from Offline Foundation Features with Tensor Augmentations</title><link>https://deep-diver.github.io/neurips2024/posters/vvd3iokpmj/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/vvd3iokpmj/</guid><description>LOFF-TA leverages offline foundation model features and tensor augmentations for efficient, resource-light training, achieving up to 37x faster training and 26x less GPU memory usage.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/vvd3iokpmj/cover.png"/></item><item><title>Learning Group Actions on Latent Representations</title><link>https://deep-diver.github.io/neurips2024/posters/hgntcy4eep/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/hgntcy4eep/</guid><description>This paper proposes a novel method to model group actions within autoencoders by learning these actions in the latent space, enhancing model versatility and improving performance in various real-world&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/hgntcy4eep/cover.png"/></item><item><title>Learning Image Priors Through Patch-Based Diffusion Models for Solving Inverse Problems</title><link>https://deep-diver.github.io/neurips2024/posters/hgnxhhz6ss/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/hgnxhhz6ss/</guid><description>PaDIS: Patch-based diffusion inverse solver learns efficient image priors from image patches, enabling high-resolution inverse problem solutions with reduced computational costs and data needs.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/hgnxhhz6ss/cover.png"/></item><item><title>Learning Interaction-aware 3D Gaussian Splatting for One-shot Hand Avatars</title><link>https://deep-diver.github.io/neurips2024/posters/bxpa7sn5zq/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/bxpa7sn5zq/</guid><description>Create animatable interacting hand avatars from a single image using a novel two-stage interaction-aware 3D Gaussian splatting framework!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/bxpa7sn5zq/cover.png"/></item><item><title>Learning Optimal Lattice Vector Quantizers for End-to-end Neural Image Compression</title><link>https://deep-diver.github.io/neurips2024/posters/dlr4h7uj4h/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/dlr4h7uj4h/</guid><description>Learned optimal lattice vector quantization (OLVQ) drastically boosts neural image compression efficiency by adapting quantizer structures to latent feature distributions, achieving significant rate-d&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/dlr4h7uj4h/cover.png"/></item><item><title>Learning Structured Representations with Hyperbolic Embeddings</title><link>https://deep-diver.github.io/neurips2024/posters/wbtmn8sz2b/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/wbtmn8sz2b/</guid><description>HypStructure boosts representation learning by embedding label hierarchies into hyperbolic space, improving accuracy and interpretability.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/wbtmn8sz2b/cover.png"/></item><item><title>Learning to be Smooth: An End-to-End Differentiable Particle Smoother</title><link>https://deep-diver.github.io/neurips2024/posters/wdmhbqcoqw/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/wdmhbqcoqw/</guid><description>Learned Mixture Density Particle Smoother (MDPS) surpasses state-of-the-art for accurate, differentiable city-scale vehicle localization.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/wdmhbqcoqw/cover.png"/></item><item><title>Learning to Edit Visual Programs with Self-Supervision</title><link>https://deep-diver.github.io/neurips2024/posters/uziwqrzjep/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/uziwqrzjep/</guid><description>AI learns to edit visual programs more accurately using a self-supervised method that combines one-shot program generation with iterative local edits, significantly boosting performance, especially wi&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/uziwqrzjep/cover.png"/></item><item><title>Learning Truncated Causal History Model for Video Restoration</title><link>https://deep-diver.github.io/neurips2024/posters/cugf2hancs/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/cugf2hancs/</guid><description>TURTLE: a novel video restoration framework that learns a truncated causal history model for efficient and high-performing video restoration, achieving state-of-the-art results on various benchmark ta&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/cugf2hancs/cover.png"/></item><item><title>Learning-to-Cache: Accelerating Diffusion Transformer via Layer Caching</title><link>https://deep-diver.github.io/neurips2024/posters/zupomzmnro/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/zupomzmnro/</guid><description>Learning-to-Cache (L2C) dramatically accelerates diffusion transformers by intelligently caching layer computations, achieving significant speedups with minimal performance loss.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/zupomzmnro/cover.png"/></item><item><title>Linearly Decomposing and Recomposing Vision Transformers for Diverse-Scale Models</title><link>https://deep-diver.github.io/neurips2024/posters/yhd0yzc8yd/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/yhd0yzc8yd/</guid><description>Linearly decompose &amp;amp; recompose Vision Transformers to create diverse-scale models efficiently, reducing computational costs &amp;amp; improving flexibility for various applications.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/yhd0yzc8yd/cover.png"/></item><item><title>LinNet: Linear Network for Efficient Point Cloud Representation Learning</title><link>https://deep-diver.github.io/neurips2024/posters/ehfcxpdsrw/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/ehfcxpdsrw/</guid><description>LinNet: A linear-time point cloud network achieving 10x speedup over PointNeXt, with state-of-the-art accuracy on various benchmarks.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/ehfcxpdsrw/cover.png"/></item><item><title>LiteVAE: Lightweight and Efficient Variational Autoencoders for Latent Diffusion Models</title><link>https://deep-diver.github.io/neurips2024/posters/mtabl8kuzq/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/mtabl8kuzq/</guid><description>LiteVAE: A new autoencoder design for latent diffusion models boosts efficiency sixfold without sacrificing image quality, achieving faster training and lower memory needs via the 2D discrete wavelet &amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/mtabl8kuzq/cover.png"/></item><item><title>LoCo: Learning 3D Location-Consistent Image Features with a Memory-Efficient Ranking Loss</title><link>https://deep-diver.github.io/neurips2024/posters/l6iczoxafi/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/l6iczoxafi/</guid><description>LoCo: Memory-efficient location-consistent image features learned via a novel ranking loss, enabling three orders of magnitude memory improvement and outperforming state-of-the-art.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/l6iczoxafi/cover.png"/></item><item><title>LoD-Loc: Aerial Visual Localization using LoD 3D Map with Neural Wireframe Alignment</title><link>https://deep-diver.github.io/neurips2024/posters/pqlkliexyj/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/pqlkliexyj/</guid><description>LoD-Loc: A novel aerial visual localization method uses lightweight LoD 3D maps &amp;amp; neural wireframe alignment for accurate and efficient 6-DoF pose estimation, surpassing state-of-the-art methods.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/pqlkliexyj/cover.png"/></item><item><title>Long-Range Feedback Spiking Network Captures Dynamic and Static Representations of the Visual Cortex under Movie Stimuli</title><link>https://deep-diver.github.io/neurips2024/posters/bxdok3uak6/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/bxdok3uak6/</guid><description>Long-range feedback spiking network (LoRaFB-SNet) surpasses other models in capturing dynamic and static visual cortical representations under movie stimuli, advancing our understanding of visual syst&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/bxdok3uak6/cover.png"/></item><item><title>Long-tailed Object Detection Pretraining: Dynamic Rebalancing Contrastive Learning with Dual Reconstruction</title><link>https://deep-diver.github.io/neurips2024/posters/mgz3jux9ws/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/mgz3jux9ws/</guid><description>Dynamic Rebalancing Contrastive Learning with Dual Reconstruction (2DRCL) pre-training significantly boosts object detection accuracy, especially for underrepresented classes.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/mgz3jux9ws/cover.png"/></item><item><title>Long-Tailed Out-of-Distribution Detection via Normalized Outlier Distribution Adaptation</title><link>https://deep-diver.github.io/neurips2024/posters/ceswi7mmly/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/ceswi7mmly/</guid><description>AdaptOD: a novel approach for robust OOD detection in long-tailed recognition, dynamically adapting outlier distributions to true OOD distributions using a dual-normalized energy loss for improved acc&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/ceswi7mmly/cover.png"/></item><item><title>LookHere: Vision Transformers with Directed Attention Generalize and Extrapolate</title><link>https://deep-diver.github.io/neurips2024/posters/o7dogbzeyp/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/o7dogbzeyp/</guid><description>LookHere: Vision Transformers excel at high-resolution image classification by using 2D attention masks to direct attention heads, improving generalization and extrapolation.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/o7dogbzeyp/cover.png"/></item><item><title>LP-3DGS: Learning to Prune 3D Gaussian Splatting</title><link>https://deep-diver.github.io/neurips2024/posters/kzj9p7vpns/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/kzj9p7vpns/</guid><description>LP-3DGS learns to optimally prune 3D Gaussian splatting, achieving significant efficiency gains without compromising rendering quality via a trainable binary mask and the Gumbel-Sigmoid method.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/kzj9p7vpns/cover.png"/></item><item><title>LuSh-NeRF: Lighting up and Sharpening NeRFs for Low-light Scenes</title><link>https://deep-diver.github.io/neurips2024/posters/ccmhle6n6u/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/ccmhle6n6u/</guid><description>LuSh-NeRF: A novel model reconstructs sharp, bright NeRFs from hand-held low-light photos by sequentially modeling and removing noise and blur, outperforming existing methods.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/ccmhle6n6u/cover.png"/></item><item><title>MambaLLIE: Implicit Retinex-Aware Low Light Enhancement with Global-then-Local State Space</title><link>https://deep-diver.github.io/neurips2024/posters/l6xvqzm72i/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/l6xvqzm72i/</guid><description>MambaLLIE: a novel implicit Retinex-aware low-light enhancer using a global-then-local state space, significantly outperforms existing CNN and Transformer-based methods.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/l6xvqzm72i/cover.png"/></item><item><title>ManiPose: Manifold-Constrained Multi-Hypothesis 3D Human Pose Estimation</title><link>https://deep-diver.github.io/neurips2024/posters/xxy8d4rnsb/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/xxy8d4rnsb/</guid><description>ManiPose: Manifold-constrained multi-hypothesis model solves 3D human pose estimation&amp;rsquo;s depth ambiguity, outperforming state-of-the-art models in pose consistency.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/xxy8d4rnsb/cover.png"/></item><item><title>Masked Pre-training Enables Universal Zero-shot Denoiser</title><link>https://deep-diver.github.io/neurips2024/posters/ofgtscasbr/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/ofgtscasbr/</guid><description>Masked Pre-training empowers a universal, fast zero-shot image denoiser!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/ofgtscasbr/cover.png"/></item><item><title>MaskFactory: Towards High-quality Synthetic Data Generation for Dichotomous Image Segmentation</title><link>https://deep-diver.github.io/neurips2024/posters/im5i289eqt/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/im5i289eqt/</guid><description>MaskFactory generates high-quality synthetic data for dichotomous image segmentation, improving model training efficiency and accuracy.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/im5i289eqt/cover.png"/></item><item><title>MC-DiT: Contextual Enhancement via Clean-to-Clean Reconstruction for Masked Diffusion Models</title><link>https://deep-diver.github.io/neurips2024/posters/y9shkrdnrt/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/y9shkrdnrt/</guid><description>MC-DiT: A novel training paradigm for masked diffusion models achieving state-of-the-art image generation by leveraging clean-to-clean reconstruction.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/y9shkrdnrt/cover.png"/></item><item><title>Measuring Dejavu Memorization Efficiently</title><link>https://deep-diver.github.io/neurips2024/posters/v8rrfnbj43/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/v8rrfnbj43/</guid><description>New method efficiently measures how well AI models memorize training data, revealing that open-source models memorize less than expected.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/v8rrfnbj43/cover.png"/></item><item><title>Measuring Per-Unit Interpretability at Scale Without Humans</title><link>https://deep-diver.github.io/neurips2024/posters/oyyesvz6dx/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/oyyesvz6dx/</guid><description>New scalable method measures per-unit interpretability in vision DNNs without human evaluation, revealing anti-correlation between model performance and interpretability.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/oyyesvz6dx/cover.png"/></item><item><title>Meta 3D AssetGen: Text-to-Mesh Generation with High-Quality Geometry, Texture, and PBR Materials</title><link>https://deep-diver.github.io/neurips2024/posters/m3bisggqnb/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/m3bisggqnb/</guid><description>Meta 3D AssetGen: High-quality text-to-mesh generation with realistic PBR materials and lighting, exceeding prior methods in speed and accuracy.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/m3bisggqnb/cover.png"/></item><item><title>MetaUAS: Universal Anomaly Segmentation with One-Prompt Meta-Learning</title><link>https://deep-diver.github.io/neurips2024/posters/4jegynumhb/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/4jegynumhb/</guid><description>MetaUAS achieves universal visual anomaly segmentation using only one normal image prompt via a pure vision model, surpassing previous zero-shot, few-shot, and full-shot methods.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/4jegynumhb/cover.png"/></item><item><title>MIDGArD: Modular Interpretable Diffusion over Graphs for Articulated Designs</title><link>https://deep-diver.github.io/neurips2024/posters/re2jpcnzka/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/re2jpcnzka/</guid><description>MIDGARD: Generate high-quality, simulatable 3D articulated assets with enhanced control and interpretability using a novel diffusion-based framework.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/re2jpcnzka/cover.png"/></item><item><title>MimicTalk: Mimicking a personalized and expressive 3D talking face in minutes</title><link>https://deep-diver.github.io/neurips2024/posters/gjezl0bamb/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/gjezl0bamb/</guid><description>MimicTalk generates realistic, expressive talking videos in minutes using a pre-trained model adapted to individual identities.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/gjezl0bamb/cover.png"/></item><item><title>Mind the Gap Between Prototypes and Images in Cross-domain Finetuning</title><link>https://deep-diver.github.io/neurips2024/posters/jwlik3kkwq/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/jwlik3kkwq/</guid><description>CoPA improves cross-domain few-shot learning by adapting separate transformations for prototype and image embeddings, significantly enhancing performance and revealing better representation clusters.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/jwlik3kkwq/cover.png"/></item><item><title>Mitigating Biases in Blackbox Feature Extractors for Image Classification Tasks</title><link>https://deep-diver.github.io/neurips2024/posters/hwo1mnluol/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/hwo1mnluol/</guid><description>Researchers propose a simple yet effective clustering-based adaptive margin loss to mitigate biases inherited by black-box feature extractors in image classification tasks.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/hwo1mnluol/cover.png"/></item><item><title>Mixture of Adversarial LoRAs: Boosting Robust Generalization in Meta-Tuning</title><link>https://deep-diver.github.io/neurips2024/posters/hxgdbamyyr/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/hxgdbamyyr/</guid><description>Boosting Robust Few-Shot Learning with Adversarial Meta-Tuning!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/hxgdbamyyr/cover.png"/></item><item><title>MoE Jetpack: From Dense Checkpoints to Adaptive Mixture of Experts for Vision Tasks</title><link>https://deep-diver.github.io/neurips2024/posters/q8z04xhddl/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/q8z04xhddl/</guid><description>MoE Jetpack efficiently transforms readily available dense checkpoints into high-performing MoE models, drastically accelerating convergence and improving accuracy.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/q8z04xhddl/cover.png"/></item><item><title>MonoMAE: Enhancing Monocular 3D Detection through Depth-Aware Masked Autoencoders</title><link>https://deep-diver.github.io/neurips2024/posters/wik6bwuxje/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/wik6bwuxje/</guid><description>MonoMAE enhances monocular 3D object detection by using depth-aware masked autoencoders to effectively handle object occlusions, achieving superior performance on both occluded and non-occluded object&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/wik6bwuxje/cover.png"/></item><item><title>MoTE: Reconciling Generalization with Specialization for Visual-Language to Video Knowledge Transfer</title><link>https://deep-diver.github.io/neurips2024/posters/vpeq2bzss0/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/vpeq2bzss0/</guid><description>MoTE: A novel framework harmonizes generalization and specialization for visual-language video knowledge transfer, achieving state-of-the-art results.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/vpeq2bzss0/cover.png"/></item><item><title>Motion Graph Unleashed: A Novel Approach to Video Prediction</title><link>https://deep-diver.github.io/neurips2024/posters/4ztp4pujog/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/4ztp4pujog/</guid><description>Motion Graph unleashes efficient and accurate video prediction by transforming video frames into interconnected graph nodes, capturing complex motion patterns with minimal computational cost.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/4ztp4pujog/cover.png"/></item><item><title>MotionCraft: Physics-Based Zero-Shot Video Generation</title><link>https://deep-diver.github.io/neurips2024/posters/lvcwa24dxb/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/lvcwa24dxb/</guid><description>MotionCraft: Physics-based zero-shot video generation creates realistic videos with complex motion dynamics by cleverly warping the noise latent space of an image diffusion model using optical flow fr&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/lvcwa24dxb/cover.png"/></item><item><title>Multi-scale Consistency for Robust 3D Registration via Hierarchical Sinkhorn Tree</title><link>https://deep-diver.github.io/neurips2024/posters/sfpxuqzdpi/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/sfpxuqzdpi/</guid><description>Hierarchical Sinkhorn Tree (HST) robustly retrieves accurate 3D point cloud correspondences using multi-scale consistency, outperforming state-of-the-art methods.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/sfpxuqzdpi/cover.png"/></item><item><title>Multi-Scale VMamba: Hierarchy in Hierarchy Visual State Space Model</title><link>https://deep-diver.github.io/neurips2024/posters/r70juopdcm/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/r70juopdcm/</guid><description>MSVMamba: A novel multi-scale vision model leveraging state-space models, achieves high accuracy in image classification and object detection while maintaining linear complexity, solving the long-rang&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/r70juopdcm/cover.png"/></item><item><title>Multi-times Monte Carlo Rendering for Inter-reflection Reconstruction</title><link>https://deep-diver.github.io/neurips2024/posters/tlugoshy30/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/tlugoshy30/</guid><description>Ref-MC2 reconstructs high-fidelity 3D objects with inter-reflections by using a novel multi-times Monte Carlo sampling strategy, achieving superior performance in accuracy and efficiency.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/tlugoshy30/cover.png"/></item><item><title>MultiPull: Detailing Signed Distance Functions by Pulling Multi-Level Queries at Multi-Step</title><link>https://deep-diver.github.io/neurips2024/posters/xxe8ml1bco/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/xxe8ml1bco/</guid><description>MultiPull: a novel method reconstructing detailed 3D surfaces from raw point clouds using multi-step optimization of multi-level features, significantly improving accuracy and detail.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/xxe8ml1bco/cover.png"/></item><item><title>Multistep Distillation of Diffusion Models via Moment Matching</title><link>https://deep-diver.github.io/neurips2024/posters/c62d2ns3ko/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/c62d2ns3ko/</guid><description>New method distills slow diffusion models into fast, few-step models by matching data expectations, achieving state-of-the-art results on ImageNet.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/c62d2ns3ko/cover.png"/></item><item><title>MV2Cyl: Reconstructing 3D Extrusion Cylinders from Multi-View Images</title><link>https://deep-diver.github.io/neurips2024/posters/jdf2zxi8ax/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/jdf2zxi8ax/</guid><description>MV2Cyl: A novel method reconstructs 3D extrusion cylinder CAD models directly from multi-view images, surpassing accuracy of methods using raw 3D geometry.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/jdf2zxi8ax/cover.png"/></item><item><title>MVGamba: Unify 3D Content Generation as State Space Sequence Modeling</title><link>https://deep-diver.github.io/neurips2024/posters/aprsvxrwxt/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/aprsvxrwxt/</guid><description>MVGamba: A unified, feed-forward 3D content generation model achieving state-of-the-art quality and speed using an RNN-like state space model for efficient multi-view Gaussian reconstruction.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/aprsvxrwxt/cover.png"/></item><item><title>MVInpainter: Learning Multi-View Consistent Inpainting to Bridge 2D and 3D Editing</title><link>https://deep-diver.github.io/neurips2024/posters/xiscpcmuse/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/xiscpcmuse/</guid><description>MVInpainter: Pose-free multi-view consistent inpainting bridges 2D and 3D editing by simplifying 3D editing to a multi-view 2D inpainting task.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/xiscpcmuse/cover.png"/></item><item><title>MVSplat360: Feed-Forward 360 Scene Synthesis from Sparse Views</title><link>https://deep-diver.github.io/neurips2024/posters/b0owokmwhz/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/b0owokmwhz/</guid><description>MVSplat360: Generating stunning 360° views from just a few images!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/b0owokmwhz/cover.png"/></item><item><title>NaRCan: Natural Refined Canonical Image with Integration of Diffusion Prior for Video Editing</title><link>https://deep-diver.github.io/neurips2024/posters/bcr2nlm1qw/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/bcr2nlm1qw/</guid><description>NaRCan: High-quality video editing via diffusion priors and hybrid deformation fields.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/bcr2nlm1qw/cover.png"/></item><item><title>NeuMA: Neural Material Adaptor for Visual Grounding of Intrinsic Dynamics</title><link>https://deep-diver.github.io/neurips2024/posters/avwb40qxzh/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/avwb40qxzh/</guid><description>NeuMA: a novel neural material adaptor corrects existing physical models, accurately learning complex dynamics from visual observations.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/avwb40qxzh/cover.png"/></item><item><title>Neural Concept Binder</title><link>https://deep-diver.github.io/neurips2024/posters/yppzyflbys/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/yppzyflbys/</guid><description>The Neural Concept Binder (NCB) framework learns expressive, inspectable, and revisable visual concepts unsupervised, integrating both continuous and discrete representations for seamless use in neura&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/yppzyflbys/cover.png"/></item><item><title>Neural Experts: Mixture of Experts for Implicit Neural Representations</title><link>https://deep-diver.github.io/neurips2024/posters/wwguwyhpay/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/wwguwyhpay/</guid><description>Boosting implicit neural representations, Neural Experts uses a Mixture of Experts architecture to achieve faster, more accurate, and memory-efficient signal reconstruction across various tasks.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/wwguwyhpay/cover.png"/></item><item><title>Neural Gaffer: Relighting Any Object via Diffusion</title><link>https://deep-diver.github.io/neurips2024/posters/zv2gdszb5a/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/zv2gdszb5a/</guid><description>Neural Gaffer: Relighting any object via diffusion using a single image and an environment map to produce high-quality, realistic relit images.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/zv2gdszb5a/cover.png"/></item><item><title>Neural Isometries: Taming Transformations for Equivariant ML</title><link>https://deep-diver.github.io/neurips2024/posters/kcabcehqwv/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/kcabcehqwv/</guid><description>Neural Isometries learns a latent space where geometric relationships in the observation space are represented as isometries in the latent space, enabling efficient handling of complex symmetries and &amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/kcabcehqwv/cover.png"/></item><item><title>Neural Localizer Fields for Continuous 3D Human Pose and Shape Estimation</title><link>https://deep-diver.github.io/neurips2024/posters/rrtjcbcheh/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/rrtjcbcheh/</guid><description>Neural Localizer Fields (NLF) revolutionizes 3D human pose and shape estimation by learning a continuous field of point localizer functions, enabling flexible training on diverse data and on-the-fly p&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/rrtjcbcheh/cover.png"/></item><item><title>Neural Signed Distance Function Inference through Splatting 3D Gaussians Pulled on Zero-Level Set</title><link>https://deep-diver.github.io/neurips2024/posters/r6tndxikns/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/r6tndxikns/</guid><description>Neural SDF inference is revolutionized by dynamically aligning 3D Gaussians to a neural SDF&amp;rsquo;s zero-level set, enabling accurate, smooth 3D surface reconstruction.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/r6tndxikns/cover.png"/></item><item><title>NeuRodin: A Two-stage Framework for High-Fidelity Neural Surface Reconstruction</title><link>https://deep-diver.github.io/neurips2024/posters/hvgagu4tkk/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/hvgagu4tkk/</guid><description>NeuRodin: A two-stage neural framework achieves high-fidelity 3D surface reconstruction from posed RGB images by innovatively addressing limitations in SDF-based methods, resulting in superior reconst&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/hvgagu4tkk/cover.png"/></item><item><title>NeuroGauss4D-PCI: 4D Neural Fields and Gaussian Deformation Fields for Point Cloud Interpolation</title><link>https://deep-diver.github.io/neurips2024/posters/lkdckv31t7/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/lkdckv31t7/</guid><description>NeuroGauss4D-PCI masters complex point cloud interpolation using 4D neural fields and Gaussian deformation fields, achieving superior accuracy in dynamic scenes.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/lkdckv31t7/cover.png"/></item><item><title>No Train, all Gain: Self-Supervised Gradients Improve Deep Frozen Representations</title><link>https://deep-diver.github.io/neurips2024/posters/prbsez8rnv/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/prbsez8rnv/</guid><description>Self-supervised gradients boost frozen deep learning model performance!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/prbsez8rnv/cover.png"/></item><item><title>Normal-GS: 3D Gaussian Splatting with Normal-Involved Rendering</title><link>https://deep-diver.github.io/neurips2024/posters/kngls5h6l1/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/kngls5h6l1/</guid><description>Normal-GS improves 3D Gaussian Splatting by integrating normal vectors into the rendering pipeline, achieving near state-of-the-art visual quality with accurate surface normals in real-time.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/kngls5h6l1/cover.png"/></item><item><title>NVRC: Neural Video Representation Compression</title><link>https://deep-diver.github.io/neurips2024/posters/i29aimdm4u/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/i29aimdm4u/</guid><description>NVRC: A novel end-to-end neural video codec achieves 23% coding gain over VVC VTM by optimizing representation compression.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/i29aimdm4u/cover.png"/></item><item><title>Object segmentation from common fate: Motion energy processing enables human-like zero-shot generalization to random dot stimuli</title><link>https://deep-diver.github.io/neurips2024/posters/po7iqkkt5b/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/po7iqkkt5b/</guid><description>Neuroscience-inspired motion energy processing enables human-like zero-shot generalization in figure-ground segmentation, outperforming deep learning models on random dot stimuli.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/po7iqkkt5b/cover.png"/></item><item><title>OccFusion: Rendering Occluded Humans with Generative Diffusion Priors</title><link>https://deep-diver.github.io/neurips2024/posters/czwphz5vgz/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/czwphz5vgz/</guid><description>OccFusion: High-fidelity human rendering from videos, even with occlusions, using 3D Gaussian splatting and 2D diffusion priors.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/czwphz5vgz/cover.png"/></item><item><title>ODGEN: Domain-specific Object Detection Data Generation with Diffusion Models</title><link>https://deep-diver.github.io/neurips2024/posters/kttk65vkvd/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/kttk65vkvd/</guid><description>ODGEN: Boosting object detection accuracy by generating high-quality synthetic images using diffusion models conditioned on bounding boxes and text descriptions.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/kttk65vkvd/cover.png"/></item><item><title>ODGS: 3D Scene Reconstruction from Omnidirectional Images with 3D Gaussian Splattings</title><link>https://deep-diver.github.io/neurips2024/posters/covjsqmnod/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/covjsqmnod/</guid><description>ODGS: Lightning-fast 3D scene reconstruction from single omnidirectional images using 3D Gaussian splatting, achieving 100x speedup over NeRF-based methods.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/covjsqmnod/cover.png"/></item><item><title>On improved Conditioning Mechanisms and Pre-training Strategies for Diffusion Models</title><link>https://deep-diver.github.io/neurips2024/posters/b3rzzralhk/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/b3rzzralhk/</guid><description>Researchers achieve state-of-the-art image generation by disentangling semantic and control metadata in diffusion models and optimizing pre-training across resolutions.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/b3rzzralhk/cover.png"/></item><item><title>On the Surprising Effectiveness of Attention Transfer for Vision Transformers</title><link>https://deep-diver.github.io/neurips2024/posters/5dwqmoce1n/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/5dwqmoce1n/</guid><description>Vision Transformers achieve surprisingly high accuracy by transferring only pre-training attention maps, challenging the conventional belief that feature learning is crucial.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/5dwqmoce1n/cover.png"/></item><item><title>One for All: Multi-Domain Joint Training for Point Cloud Based 3D Object Detection</title><link>https://deep-diver.github.io/neurips2024/posters/ndoehx1acq/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/ndoehx1acq/</guid><description>OneDet3D: A universal 3D object detector trained jointly on diverse indoor/outdoor datasets, achieving one-for-all performance across domains and categories.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/ndoehx1acq/cover.png"/></item><item><title>One-Step Diffusion Distillation through Score Implicit Matching</title><link>https://deep-diver.github.io/neurips2024/posters/ogk236hsjm/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/ogk236hsjm/</guid><description>Score Implicit Matching (SIM) revolutionizes diffusion model distillation by creating high-quality, single-step generators from complex, multi-step models, achieving comparable performance and enablin&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/ogk236hsjm/cover.png"/></item><item><title>One-Step Effective Diffusion Network for Real-World Image Super-Resolution</title><link>https://deep-diver.github.io/neurips2024/posters/tptxnprvur/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/tptxnprvur/</guid><description>OSEDiff: One-step diffusion network for real-world image super-resolution, achieving comparable or better results than multi-step methods with significantly reduced computational cost and improved ima&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/tptxnprvur/cover.png"/></item><item><title>One-to-Normal: Anomaly Personalization for Few-shot Anomaly Detection</title><link>https://deep-diver.github.io/neurips2024/posters/tizw3l2uan/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/tizw3l2uan/</guid><description>One-to-Normal: Anomaly personalization boosts few-shot anomaly detection accuracy by transforming query images to match normal data, enabling precise, robust comparisons and flexible integration with &amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/tizw3l2uan/cover.png"/></item><item><title>OPEL: Optimal Transport Guided ProcedurE Learning</title><link>https://deep-diver.github.io/neurips2024/posters/leqd3bj4ly/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/leqd3bj4ly/</guid><description>OPEL: a novel optimal transport framework for procedure learning, significantly outperforms SOTA methods by aligning similar video frames and relaxing strict temporal assumptions.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/leqd3bj4ly/cover.png"/></item><item><title>Open-Vocabulary Object Detection via Language Hierarchy</title><link>https://deep-diver.github.io/neurips2024/posters/tnq0hxh3o1/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/tnq0hxh3o1/</guid><description>Language Hierarchical Self-training (LHST) enhances weakly-supervised object detection by integrating language hierarchy, mitigating label mismatch, and improving generalization across diverse dataset&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/tnq0hxh3o1/cover.png"/></item><item><title>OpenDlign: Open-World Point Cloud Understanding with Depth-Aligned Images</title><link>https://deep-diver.github.io/neurips2024/posters/igcatq4n1r/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/igcatq4n1r/</guid><description>OpenDlign uses novel depth-aligned images from a diffusion model to boost open-world 3D understanding, achieving significant performance gains on diverse benchmarks.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/igcatq4n1r/cover.png"/></item><item><title>Optical Diffusion Models for Image Generation</title><link>https://deep-diver.github.io/neurips2024/posters/ry3rdqv0tq/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/ry3rdqv0tq/</guid><description>Researchers created an energy-efficient optical system for generating images using light propagation, drastically reducing the latency and energy consumption of diffusion models.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/ry3rdqv0tq/cover.png"/></item><item><title>Optimal-state Dynamics Estimation for Physics-based Human Motion Capture from Videos</title><link>https://deep-diver.github.io/neurips2024/posters/rkot8ramrr/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/rkot8ramrr/</guid><description>OSDCap: Online optimal-state dynamics estimation selectively incorporates physics models with kinematic observations to achieve highly accurate, physically-plausible human motion capture from videos.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/rkot8ramrr/cover.png"/></item><item><title>OPUS: Occupancy Prediction Using a Sparse Set</title><link>https://deep-diver.github.io/neurips2024/posters/zyr0srqrdd/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/zyr0srqrdd/</guid><description>OPUS: a novel, real-time occupancy prediction framework using a sparse set prediction paradigm, outperforms state-of-the-art methods on Occ3D-nuScenes.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/zyr0srqrdd/cover.png"/></item><item><title>PaGoDA: Progressive Growing of a One-Step Generator from a Low-Resolution Diffusion Teacher</title><link>https://deep-diver.github.io/neurips2024/posters/h5zygf68kh/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/h5zygf68kh/</guid><description>PaGoDA: Train high-resolution image generators efficiently by progressively growing a one-step generator from a low-resolution diffusion model. This innovative pipeline drastically cuts training cost&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/h5zygf68kh/cover.png"/></item><item><title>Parameter Efficient Adaptation for Image Restoration with Heterogeneous Mixture-of-Experts</title><link>https://deep-diver.github.io/neurips2024/posters/r7w68z5iqf/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/r7w68z5iqf/</guid><description>AdaptIR: A novel parameter-efficient method for generalized image restoration using a heterogeneous Mixture-of-Experts (MoE) architecture that achieves superior performance and generalization.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/r7w68z5iqf/cover.png"/></item><item><title>Pedestrian-Centric 3D Pre-collision Pose and Shape Estimation from Dashcam Perspective</title><link>https://deep-diver.github.io/neurips2024/posters/ldvfayzg35/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/ldvfayzg35/</guid><description>New Pedestrian-Vehicle Collision Pose dataset (PVCP) and Pose Estimation Network (PPSENet) improve pedestrian pre-collision pose estimation from dashcam video.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/ldvfayzg35/cover.png"/></item><item><title>Phased Consistency Models</title><link>https://deep-diver.github.io/neurips2024/posters/mtbmkqyqgs/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/mtbmkqyqgs/</guid><description>Phased Consistency Models (PCMs) revolutionize diffusion model generation by overcoming LCM limitations, achieving superior speed and quality in image and video generation.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/mtbmkqyqgs/cover.png"/></item><item><title>PhyRecon: Physically Plausible Neural Scene Reconstruction</title><link>https://deep-diver.github.io/neurips2024/posters/qre9qpq4ya/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/qre9qpq4ya/</guid><description>PHYRECON: A novel neural scene reconstruction method uses differentiable rendering and physics simulation for physically plausible 3D models.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/qre9qpq4ya/cover.png"/></item><item><title>Physics-Constrained Comprehensive Optical Neural Networks</title><link>https://deep-diver.github.io/neurips2024/posters/qhuxu2ilig/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/qhuxu2ilig/</guid><description>Physics-constrained learning significantly boosts optical neural network accuracy by addressing systematic physical errors, achieving state-of-the-art results on image classification tasks.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/qhuxu2ilig/cover.png"/></item><item><title>PLIP: Language-Image Pre-training for Person Representation Learning</title><link>https://deep-diver.github.io/neurips2024/posters/e49qqjxcwq/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/e49qqjxcwq/</guid><description>PLIP: Novel language-image pre-training framework excels at person representation learning, surpassing existing methods on various downstream tasks thanks to its three pretext tasks and large-scale SY&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/e49qqjxcwq/cover.png"/></item><item><title>Point-PRC: A Prompt Learning Based Regulation Framework for Generalizable Point Cloud Analysis</title><link>https://deep-diver.github.io/neurips2024/posters/g7lyp11erv/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/g7lyp11erv/</guid><description>Point-PRC improves generalizable 3D point cloud analysis by regulating prompt learning to harmonize task-specific and general knowledge within large 3D models.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/g7lyp11erv/cover.png"/></item><item><title>PointMamba: A Simple State Space Model for Point Cloud Analysis</title><link>https://deep-diver.github.io/neurips2024/posters/kc37srxvan/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/kc37srxvan/</guid><description>PointMamba: A linear-complexity state space model achieving superior performance in point cloud analysis, reducing computational cost significantly.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/kc37srxvan/cover.png"/></item><item><title>Polyhedral Complex Derivation from Piecewise Trilinear Networks</title><link>https://deep-diver.github.io/neurips2024/posters/xz4xsutgrb/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/xz4xsutgrb/</guid><description>This paper presents a novel method for analytically extracting meshes from neural implicit surface networks using trilinear interpolation, offering theoretical insights and practical efficiency.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/xz4xsutgrb/cover.png"/></item><item><title>PPLNs: Parametric Piecewise Linear Networks for Event-Based Temporal Modeling and Beyond</title><link>https://deep-diver.github.io/neurips2024/posters/s8wfxyt4dy/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/s8wfxyt4dy/</guid><description>Parametric Piecewise Linear Networks (PPLNs) achieve state-of-the-art results in event-based and frame-based computer vision tasks by mimicking biological neural principles.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/s8wfxyt4dy/cover.png"/></item><item><title>PrefPaint: Aligning Image Inpainting Diffusion Model with Human Preference</title><link>https://deep-diver.github.io/neurips2024/posters/fvrcsk4eom/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/fvrcsk4eom/</guid><description>PrefPaint: Aligning image inpainting diffusion models with human preferences using reinforcement learning, resulting in significantly improved visual appeal.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/fvrcsk4eom/cover.png"/></item><item><title>Principled Probabilistic Imaging using Diffusion Models as Plug-and-Play Priors</title><link>https://deep-diver.github.io/neurips2024/posters/xq9hqf7vnv/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/xq9hqf7vnv/</guid><description>Principled Probabilistic Imaging uses diffusion models as plug-and-play priors for accurate posterior sampling in inverse problems, surpassing existing methods.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/xq9hqf7vnv/cover.png"/></item><item><title>ProEdit: Simple Progression is All You Need for High-Quality 3D Scene Editing</title><link>https://deep-diver.github.io/neurips2024/posters/ic869bbmc5/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/ic869bbmc5/</guid><description>ProEdit: High-quality 3D scene editing via progressive subtask decomposition.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/ic869bbmc5/cover.png"/></item><item><title>Progressive Exploration-Conformal Learning for Sparsely Annotated Object Detection in Aerial Images</title><link>https://deep-diver.github.io/neurips2024/posters/jzog9gvof6/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/jzog9gvof6/</guid><description>Progressive Exploration-Conformal Learning (PECL) revolutionizes sparsely annotated object detection in aerial images by adaptively selecting high-quality pseudo-labels, overcoming limitations of exis&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/jzog9gvof6/cover.png"/></item><item><title>Prompt-Agnostic Adversarial Perturbation for Customized Diffusion Models</title><link>https://deep-diver.github.io/neurips2024/posters/omhpejygdx/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/omhpejygdx/</guid><description>Prompt-Agnostic Adversarial Perturbation (PAP) defends customized diffusion models against image tampering, achieving superior generalization over prompt-specific methods.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/omhpejygdx/cover.png"/></item><item><title>Prototypical Hash Encoding for On-the-Fly Fine-Grained Category Discovery</title><link>https://deep-diver.github.io/neurips2024/posters/seyxqfgt0q/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/seyxqfgt0q/</guid><description>Prototypical Hash Encoding (PHE) significantly boosts on-the-fly fine-grained category discovery by using multiple prototypes per category to generate highly discriminative hash codes, thus resolving &amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/seyxqfgt0q/cover.png"/></item><item><title>ProvNeRF: Modeling per Point Provenance in NeRFs as a Stochastic Field</title><link>https://deep-diver.github.io/neurips2024/posters/k5pa3sk2jb/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/k5pa3sk2jb/</guid><description>ProvNeRF enhances NeRF reconstruction by modeling per-point provenance as a stochastic field, improving novel view synthesis and uncertainty estimation, particularly in sparse, unconstrained view sett&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/k5pa3sk2jb/cover.png"/></item><item><title>Prune and Repaint: Content-Aware Image Retargeting for any Ratio</title><link>https://deep-diver.github.io/neurips2024/posters/qwi6esgbjb/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/qwi6esgbjb/</guid><description>Prune and Repaint: A new content-aware method for superior image retargeting across any aspect ratio, preserving key features and avoiding artifacts.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/qwi6esgbjb/cover.png"/></item><item><title>Quality-Improved and Property-Preserved Polarimetric Imaging via Complementarily Fusing</title><link>https://deep-diver.github.io/neurips2024/posters/mok4yd8jfd/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/mok4yd8jfd/</guid><description>This paper introduces a novel three-phase neural network framework that significantly enhances the quality of polarimetric images by complementarily fusing degraded noisy and blurry snapshots, preserv&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/mok4yd8jfd/cover.png"/></item><item><title>RAMP: Boosting Adversarial Robustness Against Multiple $l_p$ Perturbations for Universal Robustness</title><link>https://deep-diver.github.io/neurips2024/posters/u1z3hwz4vj/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/u1z3hwz4vj/</guid><description>RAMP: A novel training framework significantly boosts DNN robustness against diverse adversarial attacks by mitigating accuracy-robustness tradeoffs and improving generalization.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/u1z3hwz4vj/cover.png"/></item><item><title>RAW: A Robust and Agile Plug-and-Play Watermark Framework for AI-Generated Images with Provable Guarantees</title><link>https://deep-diver.github.io/neurips2024/posters/ogaechzbku/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/ogaechzbku/</guid><description>RAW: A novel watermark framework ensures the authenticity of AI-generated images by embedding learnable watermarks directly into the image data, providing provable guarantees even under adversarial at&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/ogaechzbku/cover.png"/></item><item><title>Real-time Core-Periphery Guided ViT with Smart Data Layout Selection on Mobile Devices</title><link>https://deep-diver.github.io/neurips2024/posters/ld7ziamhbf/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/ld7ziamhbf/</guid><description>ECP-ViT: Real-time Vision Transformer on Mobile Devices via Core-Periphery Attention and Smart Data Layout.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/ld7ziamhbf/cover.png"/></item><item><title>Real-time Stereo-based 3D Object Detection for Streaming Perception</title><link>https://deep-diver.github.io/neurips2024/posters/iphb5rc3za/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/iphb5rc3za/</guid><description>StreamDSGN: a real-time stereo 3D object detection framework significantly boosts streaming perception accuracy by leveraging historical information, a feature-flow fusion method, and a motion consist&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/iphb5rc3za/cover.png"/></item><item><title>RealCompo: Balancing Realism and Compositionality Improves Text-to-Image Diffusion Models</title><link>https://deep-diver.github.io/neurips2024/posters/r8mfn3rhd5/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/r8mfn3rhd5/</guid><description>RealCompo: A novel training-free framework dynamically balances realism and compositionality in text-to-image generation, achieving state-of-the-art results.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/r8mfn3rhd5/cover.png"/></item><item><title>Reconstructing the Image Stitching Pipeline: Integrating Fusion and Rectangling into a Unified Inpainting Model</title><link>https://deep-diver.github.io/neurips2024/posters/zviypzh9wq/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/zviypzh9wq/</guid><description>SRStitcher revolutionizes image stitching by integrating fusion and rectangling into a unified inpainting model, eliminating model training and achieving superior performance and stability.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/zviypzh9wq/cover.png"/></item><item><title>Reconstruction of Manipulated Garment with Guided Deformation Prior</title><link>https://deep-diver.github.io/neurips2024/posters/a2ccaxtb4i/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/a2ccaxtb4i/</guid><description>Researchers developed a novel method for reconstructing the 3D shape of manipulated garments, achieving superior accuracy compared to existing techniques, particularly for complex, non-rigid deformati&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/a2ccaxtb4i/cover.png"/></item><item><title>Recovering Complete Actions for Cross-dataset Skeleton Action Recognition</title><link>https://deep-diver.github.io/neurips2024/posters/oe7mfqfk1m/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/oe7mfqfk1m/</guid><description>Boost skeleton action recognition accuracy across datasets by recovering complete actions and resampling; outperforms existing methods.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/oe7mfqfk1m/cover.png"/></item><item><title>RectifID: Personalizing Rectified Flow with Anchored Classifier Guidance</title><link>https://deep-diver.github.io/neurips2024/posters/kkrj1vcqag/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/kkrj1vcqag/</guid><description>RectifID personalizes image generation by cleverly guiding a diffusion model using off-the-shelf classifiers, achieving identity preservation without needing extra training data.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/kkrj1vcqag/cover.png"/></item><item><title>Recurrent Complex-Weighted Autoencoders for Unsupervised Object Discovery</title><link>https://deep-diver.github.io/neurips2024/posters/zfbqnl1ais/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/zfbqnl1ais/</guid><description>SynCx, a novel recurrent autoencoder with complex weights, surpasses state-of-the-art models in unsupervised object discovery by iteratively refining phase relationships to achieve robust object bindi&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/zfbqnl1ais/cover.png"/></item><item><title>ReF-LDM: A Latent Diffusion Model for Reference-based Face Image Restoration</title><link>https://deep-diver.github.io/neurips2024/posters/qy4spbhqzi/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/qy4spbhqzi/</guid><description>ReF-LDM uses reference images to improve the accuracy of face image restoration, achieving high-quality results faithful to the subject&amp;rsquo;s true appearance.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/qy4spbhqzi/cover.png"/></item><item><title>ReFIR: Grounding Large Restoration Models with Retrieval Augmentation</title><link>https://deep-diver.github.io/neurips2024/posters/ifkmfuxqdh/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/ifkmfuxqdh/</guid><description>ReFIR enhances Large Restoration Models&amp;rsquo; accuracy by incorporating retrieved images as external knowledge, mitigating hallucination without retraining.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/ifkmfuxqdh/cover.png"/></item><item><title>ReGS: Reference-based Controllable Scene Stylization with Gaussian Splatting</title><link>https://deep-diver.github.io/neurips2024/posters/ynjr0rw6fr/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/ynjr0rw6fr/</guid><description>ReGS: Real-time reference-based 3D scene stylization using Gaussian Splatting for high-fidelity texture editing and free-view navigation.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/ynjr0rw6fr/cover.png"/></item><item><title>Relationship Prompt Learning is Enough for Open-Vocabulary Semantic Segmentation</title><link>https://deep-diver.github.io/neurips2024/posters/pkcchncbzg/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/pkcchncbzg/</guid><description>Relationship Prompt Network (RPN) achieves state-of-the-art open-vocabulary semantic segmentation using only prompt learning and a Vision-Language Model (VLM), eliminating the need for expensive segme&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/pkcchncbzg/cover.png"/></item><item><title>Remix-DiT: Mixing Diffusion Transformers for Multi-Expert Denoising</title><link>https://deep-diver.github.io/neurips2024/posters/vo5longado/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/vo5longado/</guid><description>Remix-DiT: Boosting diffusion model image generation quality by cleverly mixing smaller basis models into numerous specialized denoisers, improving efficiency and lowering costs!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/vo5longado/cover.png"/></item><item><title>Resfusion: Denoising Diffusion Probabilistic Models for Image Restoration Based on Prior Residual Noise</title><link>https://deep-diver.github.io/neurips2024/posters/jripbxwis8/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/jripbxwis8/</guid><description>Resfusion, a novel framework, accelerates image restoration by integrating residual noise into the diffusion process, achieving superior results with fewer steps.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/jripbxwis8/cover.png"/></item><item><title>RestoreAgent: Autonomous Image Restoration Agent via Multimodal Large Language Models</title><link>https://deep-diver.github.io/neurips2024/posters/xgp5ynlzwf/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/xgp5ynlzwf/</guid><description>RestoreAgent, an AI-powered image restoration agent, autonomously identifies and corrects multiple image degradations, exceeding human expert performance.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/xgp5ynlzwf/cover.png"/></item><item><title>Rethinking Decoders for Transformer-based Semantic Segmentation: Compression is All You Need</title><link>https://deep-diver.github.io/neurips2024/posters/ihjopnnzb9/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/ihjopnnzb9/</guid><description>DEPICT: A new white-box decoder for Transformer-based semantic segmentation, achieving better performance with fewer parameters by leveraging the principle of compression and connecting Transformer de&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/ihjopnnzb9/cover.png"/></item><item><title>Rethinking Imbalance in Image Super-Resolution for Efficient Inference</title><link>https://deep-diver.github.io/neurips2024/posters/fyyrzbwtnz/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/fyyrzbwtnz/</guid><description>WBSR: A novel framework for efficient image super-resolution that tackles data and model imbalances for superior performance and approximately a 34% reduction in computational cost.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/fyyrzbwtnz/cover.png"/></item><item><title>Rethinking No-reference Image Exposure Assessment from Holism to Pixel: Models, Datasets and Benchmarks</title><link>https://deep-diver.github.io/neurips2024/posters/zvrqeopioq/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/zvrqeopioq/</guid><description>Revolutionizing image exposure assessment, Pixel-level IEA Network (P-IEANet) achieves state-of-the-art performance with a novel pixel-level approach, a new dataset (IEA40K), and a benchmark of 19 met&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/zvrqeopioq/cover.png"/></item><item><title>Rethinking Score Distillation as a Bridge Between Image Distributions</title><link>https://deep-diver.github.io/neurips2024/posters/i8pkicj9km/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/i8pkicj9km/</guid><description>Researchers enhanced image generation by improving score distillation sampling via a novel Schrödinger Bridge framework, improving realism without computational overhead.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/i8pkicj9km/cover.png"/></item><item><title>ReVideo: Remake a Video with Motion and Content Control</title><link>https://deep-diver.github.io/neurips2024/posters/xujbzr6b1t/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/xujbzr6b1t/</guid><description>ReVideo enables precise local video editing by independently controlling content and motion, overcoming limitations of existing methods and paving the way for advanced video manipulation.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/xujbzr6b1t/cover.png"/></item><item><title>Revisiting the Integration of Convolution and Attention for Vision Backbone</title><link>https://deep-diver.github.io/neurips2024/posters/ttuxtv2yra/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/ttuxtv2yra/</guid><description>GLMix: A novel vision backbone efficiently integrates convolutions and multi-head self-attention at different granularities, achieving state-of-the-art performance while addressing scalability issues.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/ttuxtv2yra/cover.png"/></item><item><title>RLE: A Unified Perspective of Data Augmentation for Cross-Spectral Re-Identification</title><link>https://deep-diver.github.io/neurips2024/posters/ok6jssxzfj/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/ok6jssxzfj/</guid><description>RLE: A novel data augmentation strategy unifying cross-spectral re-ID, significantly boosting model performance by mimicking local linear transformations.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/ok6jssxzfj/cover.png"/></item><item><title>ROBIN: Robust and Invisible Watermarks for Diffusion Models with Adversarial Optimization</title><link>https://deep-diver.github.io/neurips2024/posters/rvoxlfvnlx/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/rvoxlfvnlx/</guid><description>ROBIN: A novel watermarking method for diffusion models that actively conceals robust watermarks using adversarial optimization, enabling strong, imperceptible, and verifiable image authentication.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/rvoxlfvnlx/cover.png"/></item><item><title>RobIR: Robust Inverse Rendering for High-Illumination Scenes</title><link>https://deep-diver.github.io/neurips2024/posters/y7oxy5pq4j/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/y7oxy5pq4j/</guid><description>RobIR: Robust inverse rendering in high-illumination scenes using ACES tone mapping and regularized visibility estimation for accurate BRDF reconstruction.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/y7oxy5pq4j/cover.png"/></item><item><title>Robust Fine-tuning of Zero-shot Models via Variance Reduction</title><link>https://deep-diver.github.io/neurips2024/posters/vitulzvpdu/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/vitulzvpdu/</guid><description>Variance Reduction Fine-tuning (VRF) simultaneously boosts in-distribution and out-of-distribution accuracy in fine-tuned zero-shot models, overcoming the ID-OOD trade-off.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/vitulzvpdu/cover.png"/></item><item><title>RTify: Aligning Deep Neural Networks with Human Behavioral Decisions</title><link>https://deep-diver.github.io/neurips2024/posters/ntjeoxlwyv/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/ntjeoxlwyv/</guid><description>RTify: A novel framework aligns deep neural networks&amp;rsquo; dynamics with human reaction times for improved visual decision-making models.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/ntjeoxlwyv/cover.png"/></item><item><title>Samba: Severity-aware Recurrent Modeling for Cross-domain Medical Image Grading</title><link>https://deep-diver.github.io/neurips2024/posters/aiexn5103e/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/aiexn5103e/</guid><description>Samba: a novel severity-aware recurrent model, tackles cross-domain medical image grading by sequentially encoding image patches and recalibrating states using EM, significantly improving accuracy.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/aiexn5103e/cover.png"/></item><item><title>Scaling the Codebook Size of VQ-GAN to 100,000 with a Utilization Rate of 99%</title><link>https://deep-diver.github.io/neurips2024/posters/rbu10yvkk6/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/rbu10yvkk6/</guid><description>VQGAN-LC massively scales VQGAN&amp;rsquo;s codebook to 100,000 entries while maintaining a 99% utilization rate, significantly boosting image generation and downstream task performance.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/rbu10yvkk6/cover.png"/></item><item><title>Scaling White-Box Transformers for Vision</title><link>https://deep-diver.github.io/neurips2024/posters/wkwgedn19x/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/wkwgedn19x/</guid><description>CRATE-a: A new white-box vision transformer architecture achieves 85.1% ImageNet accuracy by strategically scaling model size and datasets, outperforming prior white-box models and preserving interpre&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/wkwgedn19x/cover.png"/></item><item><title>Schedule Your Edit: A Simple yet Effective Diffusion Noise Schedule for Image Editing</title><link>https://deep-diver.github.io/neurips2024/posters/yu6cdt7q9z/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/yu6cdt7q9z/</guid><description>Logistic Schedule: A novel noise schedule revolutionizes image editing by improving DDIM inversion, enhancing content preservation and edit fidelity without model retraining!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/yu6cdt7q9z/cover.png"/></item><item><title>SCube: Instant Large-Scale Scene Reconstruction using VoxSplats</title><link>https://deep-diver.github.io/neurips2024/posters/tlxgzq5wzl/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/tlxgzq5wzl/</guid><description>SCube: Instant large-scale 3D scene reconstruction from sparse images using VoxSplats, a novel 3D Gaussian splat representation.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/tlxgzq5wzl/cover.png"/></item><item><title>Segment Any Change</title><link>https://deep-diver.github.io/neurips2024/posters/d7x9grmd7l/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/d7x9grmd7l/</guid><description>AnyChange achieves zero-shot image change detection by adapting the Segment Anything Model (SAM) via a training-free bitemporal latent matching method, significantly outperforming previous state-of-th&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/d7x9grmd7l/cover.png"/></item><item><title>Segment Anything without Supervision</title><link>https://deep-diver.github.io/neurips2024/posters/agqldloxxy/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/agqldloxxy/</guid><description>Unsupervised SAM (UnSAM) achieves competitive image segmentation results without human annotation, surpassing previous unsupervised methods and even improving supervised SAM&amp;rsquo;s accuracy.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/agqldloxxy/cover.png"/></item><item><title>Self-Distilled Depth Refinement with Noisy Poisson Fusion</title><link>https://deep-diver.github.io/neurips2024/posters/nequ0ica0s/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/nequ0ica0s/</guid><description>Self-Distilled Depth Refinement (SDDR) tackles noisy depth maps via a novel noisy Poisson fusion approach, achieving significant improvements in depth accuracy and edge quality.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/nequ0ica0s/cover.png"/></item><item><title>Semantic Feature Learning for Universal Unsupervised Cross-Domain Retrieval</title><link>https://deep-diver.github.io/neurips2024/posters/zzvqzrxsao/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/zzvqzrxsao/</guid><description>Universal Unsupervised Cross-Domain Retrieval (U2CDR) framework learns semantic features to enable accurate retrieval even when category spaces differ across domains.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/zzvqzrxsao/cover.png"/></item><item><title>SF-V: Single Forward Video Generation Model</title><link>https://deep-diver.github.io/neurips2024/posters/pvgaemm3mw/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/pvgaemm3mw/</guid><description>Researchers developed SF-V, a single-step image-to-video generation model, achieving a 23x speedup compared to existing models without sacrificing quality, paving the way for real-time video synthesis&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/pvgaemm3mw/cover.png"/></item><item><title>SfPUEL: Shape from Polarization under Unknown Environment Light</title><link>https://deep-diver.github.io/neurips2024/posters/skeopn3q5y/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/skeopn3q5y/</guid><description>SfPUEL: A novel end-to-end SfP method achieves robust single-shot surface normal estimation under diverse lighting, integrating PS priors and material segmentation.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/skeopn3q5y/cover.png"/></item><item><title>Sharing Key Semantics in Transformer Makes Efficient Image Restoration</title><link>https://deep-diver.github.io/neurips2024/posters/pebp89l4v6/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/pebp89l4v6/</guid><description>SemanIR boosts image restoration efficiency by cleverly sharing key semantic information within Transformer layers, achieving state-of-the-art results across multiple tasks.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/pebp89l4v6/cover.png"/></item><item><title>ShowMaker: Creating High-Fidelity 2D Human Video via Fine-Grained Diffusion Modeling</title><link>https://deep-diver.github.io/neurips2024/posters/lpxdg0hk4h/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/lpxdg0hk4h/</guid><description>ShowMaker: Generating high-fidelity 2D human conversational videos using fine-grained diffusion modeling and 2D key points.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/lpxdg0hk4h/cover.png"/></item><item><title>Simple and Fast Distillation of Diffusion Models</title><link>https://deep-diver.github.io/neurips2024/posters/ao0fizqrxa/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/ao0fizqrxa/</guid><description>Simple and Fast Distillation (SFD) drastically accelerates diffusion model training by 1000x, achieving state-of-the-art results in few-step image generation with minimal fine-tuning.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/ao0fizqrxa/cover.png"/></item><item><title>Single Image Reflection Separation via Dual-Stream Interactive Transformers</title><link>https://deep-diver.github.io/neurips2024/posters/shwtw8uv8l/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/shwtw8uv8l/</guid><description>Dual-Stream Interactive Transformers (DSIT) revolutionizes single image reflection separation by using a novel dual-attention mechanism that captures inter- and intra-layer correlations, significantly&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/shwtw8uv8l/cover.png"/></item><item><title>Slicing Vision Transformer for Flexibile Inference</title><link>https://deep-diver.github.io/neurips2024/posters/zjnsbgl4ua/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/zjnsbgl4ua/</guid><description>Scala: One-shot training enables flexible ViT inference!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/zjnsbgl4ua/cover.png"/></item><item><title>SlimSAM: 0.1% Data Makes Segment Anything Slim</title><link>https://deep-diver.github.io/neurips2024/posters/zg84y6a7ge/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/zg84y6a7ge/</guid><description>SlimSAM achieves near original SAM performance using 0.1% of its training data by employing a novel alternate slimming framework and disturbed Taylor pruning, significantly advancing data-efficient mo&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/zg84y6a7ge/cover.png"/></item><item><title>Slot State Space Models</title><link>https://deep-diver.github.io/neurips2024/posters/bjv1t4xnjw/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/bjv1t4xnjw/</guid><description>SlotSSMs: a novel framework for modular sequence modeling, achieving significant performance gains by incorporating independent mechanisms and sparse interactions into State Space Models.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/bjv1t4xnjw/cover.png"/></item><item><title>Smoothed Energy Guidance: Guiding Diffusion Models with Reduced Energy Curvature of Attention</title><link>https://deep-diver.github.io/neurips2024/posters/jk728xy8g7/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/jk728xy8g7/</guid><description>Smoothed Energy Guidance (SEG) improves unconditional image generation by reducing self-attention&amp;rsquo;s energy curvature, leading to higher-quality outputs with fewer artifacts.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/jk728xy8g7/cover.png"/></item><item><title>Soft Tensor Product Representations for Fully Continuous, Compositional Visual Representations</title><link>https://deep-diver.github.io/neurips2024/posters/oevsxvdush/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/oevsxvdush/</guid><description>Soft Tensor Product Representations (Soft TPRs) revolutionize compositional visual representation learning by seamlessly blending continuous vector spaces and compositional structures, leading to supe&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/oevsxvdush/cover.png"/></item><item><title>SOI: Scaling Down Computational Complexity by Estimating Partial States of the Model</title><link>https://deep-diver.github.io/neurips2024/posters/sz7jj9kqay/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/sz7jj9kqay/</guid><description>Scattered Online Inference (SOI) drastically cuts down ANN computational complexity by leveraging data continuity and prediction seasonality, enabling faster real-time inference on low-power devices.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/sz7jj9kqay/cover.png"/></item><item><title>Sparse-view Pose Estimation and Reconstruction via Analysis by Generative Synthesis</title><link>https://deep-diver.github.io/neurips2024/posters/wgpmdyjgsg/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/wgpmdyjgsg/</guid><description>SparseAGS: High-fidelity 3D reconstruction &amp;amp; camera pose estimation from sparse views via generative synthesis.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/wgpmdyjgsg/cover.png"/></item><item><title>Spatio-Temporal Interactive Learning for Efficient Image Reconstruction of Spiking Cameras</title><link>https://deep-diver.github.io/neurips2024/posters/s4zqnmywcm/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/s4zqnmywcm/</guid><description>STIR: A novel spatio-temporal network reconstructs high-quality images from spiking camera data by jointly refining motion and intensity information for efficient and accurate high-speed imaging.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/s4zqnmywcm/cover.png"/></item><item><title>SpeechForensics: Audio-Visual Speech Representation Learning for Face Forgery Detection</title><link>https://deep-diver.github.io/neurips2024/posters/zss0megtsh/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/zss0megtsh/</guid><description>SpeechForensics leverages audio-visual speech representation learning to achieve superior face forgery detection, outperforming state-of-the-art methods in cross-dataset generalization and robustness.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/zss0megtsh/cover.png"/></item><item><title>SpelsNet: Surface Primitive Elements Segmentation by B-Rep Graph Structure Supervision</title><link>https://deep-diver.github.io/neurips2024/posters/ad3pztuqiq/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/ad3pztuqiq/</guid><description>SpelsNet, a novel neural architecture, achieves accurate 3D point cloud segmentation into surface primitives by incorporating B-Rep graph structure supervision, leading to topologically consistent res&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/ad3pztuqiq/cover.png"/></item><item><title>Spherical Frustum Sparse Convolution Network for LiDAR Point Cloud Semantic Segmentation</title><link>https://deep-diver.github.io/neurips2024/posters/lqdcdqievd/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/lqdcdqievd/</guid><description>SFCNet, a novel spherical frustum sparse convolution network, tackles LiDAR point cloud semantic segmentation by eliminating quantized information loss, leading to superior performance, especially for&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/lqdcdqievd/cover.png"/></item><item><title>Spiking Neural Network as Adaptive Event Stream Slicer</title><link>https://deep-diver.github.io/neurips2024/posters/ccnw4mvixo/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/ccnw4mvixo/</guid><description>SpikeSlicer: An adaptive event stream slicer using a spiking neural network (SNN) to efficiently split events for improved downstream processing in object tracking and recognition.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/ccnw4mvixo/cover.png"/></item><item><title>Spiking Transformer with Experts Mixture</title><link>https://deep-diver.github.io/neurips2024/posters/wcieety3ag/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/wcieety3ag/</guid><description>Spiking Experts Mixture Mechanism (SEMM) boosts Spiking Transformers by integrating Mixture-of-Experts for efficient, sparse conditional computation, achieving significant performance improvements on &amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/wcieety3ag/cover.png"/></item><item><title>Splatter a Video: Video Gaussian Representation for Versatile Processing</title><link>https://deep-diver.github.io/neurips2024/posters/bzuqtvdxv0/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/bzuqtvdxv0/</guid><description>Researchers introduce Video Gaussian Representation (VGR) for versatile video processing, embedding videos into explicit 3D Gaussians for intuitive motion and appearance modeling.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/bzuqtvdxv0/cover.png"/></item><item><title>SSA-Seg: Semantic and Spatial Adaptive Pixel-level Classifier for Semantic Segmentation</title><link>https://deep-diver.github.io/neurips2024/posters/rzzo23pqfl/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/rzzo23pqfl/</guid><description>SSA-Seg improves semantic segmentation by adapting pixel-level classifiers to the test image&amp;rsquo;s semantic and spatial features, achieving state-of-the-art performance with minimal extra computational co&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/rzzo23pqfl/cover.png"/></item><item><title>SSDiff: Spatial-spectral Integrated Diffusion Model for Remote Sensing Pansharpening</title><link>https://deep-diver.github.io/neurips2024/posters/qmvydwvrx7/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/qmvydwvrx7/</guid><description>SSDiff: A novel spatial-spectral integrated diffusion model for superior remote sensing pansharpening.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/qmvydwvrx7/cover.png"/></item><item><title>Stability and Generalizability in SDE Diffusion Models with Measure-Preserving Dynamics</title><link>https://deep-diver.github.io/neurips2024/posters/vtjvta41d0/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/vtjvta41d0/</guid><description>D³GM, a novel score-based diffusion model, enhances stability &amp;amp; generalizability in solving inverse problems by leveraging measure-preserving dynamics, enabling robust image reconstruction across dive&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/vtjvta41d0/cover.png"/></item><item><title>Stabilize the Latent Space for Image Autoregressive Modeling: A Unified Perspective</title><link>https://deep-diver.github.io/neurips2024/posters/waq5x4qc3w/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/waq5x4qc3w/</guid><description>DiGIT stabilizes image autoregressive models&amp;rsquo; latent space using a novel discrete tokenizer from self-supervised learning, achieving state-of-the-art image generation.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/waq5x4qc3w/cover.png"/></item><item><title>Stable-Pose: Leveraging Transformers for Pose-Guided Text-to-Image Generation</title><link>https://deep-diver.github.io/neurips2024/posters/iwntinpxft/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/iwntinpxft/</guid><description>Stable-Pose: Precise human pose guidance for text-to-image synthesis.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/iwntinpxft/cover.png"/></item><item><title>START: A Generalized State Space Model with Saliency-Driven Token-Aware Transformation</title><link>https://deep-diver.github.io/neurips2024/posters/madgq1hh3l/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/madgq1hh3l/</guid><description>START, a novel SSM-based architecture with saliency-driven token-aware transformation, achieves state-of-the-art domain generalization performance with efficient linear complexity.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/madgq1hh3l/cover.png"/></item><item><title>Suppress Content Shift: Better Diffusion Features via Off-the-Shelf Generation Techniques</title><link>https://deep-diver.github.io/neurips2024/posters/qvqldeslwa/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/qvqldeslwa/</guid><description>Boosting diffusion model features: This paper introduces GATE, a novel method to suppress &amp;lsquo;content shift&amp;rsquo; in diffusion features, improving their quality via off-the-shelf generation techniques.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/qvqldeslwa/cover.png"/></item><item><title>SyncVIS: Synchronized Video Instance Segmentation</title><link>https://deep-diver.github.io/neurips2024/posters/ttpvhsqtkf/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/ttpvhsqtkf/</guid><description>SyncVIS: A new framework for video instance segmentation achieves state-of-the-art results by synchronously modeling video and frame-level information, overcoming limitations of asynchronous approache&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/ttpvhsqtkf/cover.png"/></item><item><title>Taming Diffusion Prior for Image Super-Resolution with Domain Shift SDEs</title><link>https://deep-diver.github.io/neurips2024/posters/u7oktt4zye/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/u7oktt4zye/</guid><description>DoSSR: A novel SR model boosts efficiency by 5-7x, achieving state-of-the-art performance with only 5 sampling steps by cleverly integrating a domain shift equation into pretrained diffusion models.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/u7oktt4zye/cover.png"/></item><item><title>TAPTRv2: Attention-based Position Update Improves Tracking Any Point</title><link>https://deep-diver.github.io/neurips2024/posters/cx2o6xz03h/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/cx2o6xz03h/</guid><description>TAPTRv2 enhances point tracking by introducing an attention-based position update, eliminating cost-volume reliance for improved accuracy and efficiency.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/cx2o6xz03h/cover.png"/></item><item><title>TARP-VP: Towards Evaluation of Transferred Adversarial Robustness and Privacy on Label Mapping Visual Prompting Models</title><link>https://deep-diver.github.io/neurips2024/posters/fevuebbejb/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/fevuebbejb/</guid><description>TARP-VP reveals a surprising lack of trade-off between adversarial robustness and privacy for label mapping visual prompting models, showing that transferred adversarial training significantly improve&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/fevuebbejb/cover.png"/></item><item><title>TARSS-Net: Temporal-Aware Radar Semantic Segmentation Network</title><link>https://deep-diver.github.io/neurips2024/posters/5aelrxb9sq/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/5aelrxb9sq/</guid><description>TARSS-Net: A novel temporal-aware radar semantic segmentation network uses a data-driven approach to aggregate temporal information, enhancing accuracy and performance.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/5aelrxb9sq/cover.png"/></item><item><title>Template-free Articulated Gaussian Splatting for Real-time Reposable Dynamic View Synthesis</title><link>https://deep-diver.github.io/neurips2024/posters/vcgev6m5m2/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/vcgev6m5m2/</guid><description>This research introduces a template-free articulated Gaussian splatting method for real-time dynamic view synthesis, automatically discovering object skeletons from videos to enable reposing.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/vcgev6m5m2/cover.png"/></item><item><title>Temporally Consistent Atmospheric Turbulence Mitigation with Neural Representations</title><link>https://deep-diver.github.io/neurips2024/posters/yurca4wi2l/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/yurca4wi2l/</guid><description>ConVRT: A novel framework restores turbulence-distorted videos by decoupling spatial and temporal information in a neural representation, achieving temporally consistent mitigation.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/yurca4wi2l/cover.png"/></item><item><title>Tensor-Based Synchronization and the Low-Rankness of the Block Trifocal Tensor</title><link>https://deep-diver.github.io/neurips2024/posters/dt7n4f2bbp/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/dt7n4f2bbp/</guid><description>Low-rank block trifocal tensor unlocks accurate, efficient camera pose synchronization.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/dt7n4f2bbp/cover.png"/></item><item><title>The GAN is dead; long live the GAN! A Modern GAN Baseline</title><link>https://deep-diver.github.io/neurips2024/posters/ortn9hpp7v/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/ortn9hpp7v/</guid><description>R3GAN, a minimalist GAN baseline, surpasses state-of-the-art models by using a novel regularized relativistic GAN loss and modern architectures, proving GANs can be trained efficiently without relying&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/ortn9hpp7v/cover.png"/></item><item><title>Time-Varying LoRA: Towards Effective Cross-Domain Fine-Tuning of Diffusion Models</title><link>https://deep-diver.github.io/neurips2024/posters/sgodu2mx9t/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/sgodu2mx9t/</guid><description>Terra, a novel time-varying low-rank adapter, enables effective cross-domain fine-tuning of diffusion models by creating a continuous parameter manifold, facilitating efficient knowledge sharing and g&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/sgodu2mx9t/cover.png"/></item><item><title>TinyLUT: Tiny Look-Up Table for Efficient Image Restoration at the Edge</title><link>https://deep-diver.github.io/neurips2024/posters/tn0xnyplt6/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/tn0xnyplt6/</guid><description>TinyLUT achieves 10x lower memory consumption and superior accuracy in image restoration on edge devices using innovative separable mapping and dynamic discretization of LUTs.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/tn0xnyplt6/cover.png"/></item><item><title>To Err Like Human: Affective Bias-Inspired Measures for Visual Emotion Recognition Evaluation</title><link>https://deep-diver.github.io/neurips2024/posters/nlslbjgl7f/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/nlslbjgl7f/</guid><description>This paper introduces novel metrics for visual emotion recognition evaluation, considering the psychological distance between emotions to better reflect human perception, improving the assessment of m&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/nlslbjgl7f/cover.png"/></item><item><title>TopoFR: A Closer Look at Topology Alignment on Face Recognition</title><link>https://deep-diver.github.io/neurips2024/posters/kvax5tys2p/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/kvax5tys2p/</guid><description>TopoFR enhances face recognition by aligning topological structures between input and latent spaces. Using persistent homology, it preserves crucial data structure info, overcoming overfitting. A har&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/kvax5tys2p/cover.png"/></item><item><title>Toward Approaches to Scalability in 3D Human Pose Estimation</title><link>https://deep-diver.github.io/neurips2024/posters/xse8qmgnym/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/xse8qmgnym/</guid><description>Boosting 3D human pose estimation: Biomechanical Pose Generator and Binary Depth Coordinates enhance accuracy and scalability.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/xse8qmgnym/cover.png"/></item><item><title>Toward Dynamic Non-Line-of-Sight Imaging with Mamba Enforced Temporal Consistency</title><link>https://deep-diver.github.io/neurips2024/posters/qicjomiw3l/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/qicjomiw3l/</guid><description>Dynamic NLOS imaging gets a speed boost! New ST-Mamba method leverages temporal consistency across frames for high-resolution video reconstruction, overcoming speed limitations of traditional methods.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/qicjomiw3l/cover.png"/></item><item><title>Toward Real Ultra Image Segmentation: Leveraging Surrounding Context to Cultivate General Segmentation Model</title><link>https://deep-diver.github.io/neurips2024/posters/nu4lvlmwrt/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/nu4lvlmwrt/</guid><description>SGNet cultivates general segmentation models for ultra images by integrating surrounding context, achieving significant performance improvements across various datasets.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/nu4lvlmwrt/cover.png"/></item><item><title>Towards Combating Frequency Simplicity-biased Learning for Domain Generalization</title><link>https://deep-diver.github.io/neurips2024/posters/vmildbkcjm/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/vmildbkcjm/</guid><description>This paper introduces novel data augmentation modules that dynamically adjust the frequency characteristics of datasets, preventing neural networks from over-relying on simple frequency-based shortcut&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/vmildbkcjm/cover.png"/></item><item><title>Towards Flexible 3D Perception: Object-Centric Occupancy Completion Augments 3D Object Detection</title><link>https://deep-diver.github.io/neurips2024/posters/yktqnqtepd/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/yktqnqtepd/</guid><description>Object-centric occupancy completion boosts 3D object detection accuracy by using temporal information from long sequences to precisely reconstruct object shapes, particularly for incomplete or distant&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/yktqnqtepd/cover.png"/></item><item><title>Towards Learning Group-Equivariant Features for Domain Adaptive 3D Detection</title><link>https://deep-diver.github.io/neurips2024/posters/yetirxhsh1/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/yetirxhsh1/</guid><description>GroupEXP-DA boosts domain adaptive 3D object detection by using a grouping-exploration strategy to reduce bias in pseudo-label collection and account for multiple factors affecting object perception i&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/yetirxhsh1/cover.png"/></item><item><title>Towards Multi-Domain Learning for Generalizable Video Anomaly Detection</title><link>https://deep-diver.github.io/neurips2024/posters/yweqkcmimh/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/yweqkcmimh/</guid><description>Researchers propose Multi-Domain learning for Video Anomaly Detection (MDVAD) to create generalizable models handling conflicting abnormality criteria across diverse datasets, improving accuracy and a&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/yweqkcmimh/cover.png"/></item><item><title>Towards Open-Vocabulary Semantic Segmentation Without Semantic Labels</title><link>https://deep-diver.github.io/neurips2024/posters/arhxruc2bi/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/arhxruc2bi/</guid><description>PixelCLIP: Open-vocabulary semantic segmentation without pixel-level labels! Leveraging unlabeled image masks from Vision Foundation Models and an online clustering algorithm, PixelCLIP achieves imp&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/arhxruc2bi/cover.png"/></item><item><title>Towards Unsupervised Model Selection for Domain Adaptive Object Detection</title><link>https://deep-diver.github.io/neurips2024/posters/gya94o5gmq/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/gya94o5gmq/</guid><description>Unsupervised model selection for domain adaptive object detection is achieved via a new Detection Adaptation Score (DAS), effectively selecting optimal models without target labels by leveraging the f&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/gya94o5gmq/cover.png"/></item><item><title>TPC: Test-time Procrustes Calibration for Diffusion-based Human Image Animation</title><link>https://deep-diver.github.io/neurips2024/posters/h6nse8awct/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/h6nse8awct/</guid><description>Boosting diffusion-based human image animation, Test-time Procrustes Calibration (TPC) ensures high-quality outputs by aligning reference and target images, overcoming common compositional misalignmen&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/h6nse8awct/cover.png"/></item><item><title>TrAct: Making First-layer Pre-Activations Trainable</title><link>https://deep-diver.github.io/neurips2024/posters/gccmzedgbo/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/gccmzedgbo/</guid><description>TrAct boosts vision model training by directly optimizing first-layer activations, leading to significant speedups (1.25x-4x) and improved accuracy.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/gccmzedgbo/cover.png"/></item><item><title>Training-Free Adaptive Diffusion with Bounded Difference Approximation Strategy</title><link>https://deep-diver.github.io/neurips2024/posters/cs63ytj49a/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/cs63ytj49a/</guid><description>AdaptiveDiffusion accelerates diffusion model inference by adaptively skipping noise prediction steps, achieving 2-5x speedup without quality loss.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/cs63ytj49a/cover.png"/></item><item><title>Transferable Adversarial Attacks on SAM and Its Downstream Models</title><link>https://deep-diver.github.io/neurips2024/posters/ydjojeiwo9/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/ydjojeiwo9/</guid><description>UMI-GRAT: A universal meta-initialized and gradient robust adversarial attack effectively exploits vulnerabilities in the Segment Anything Model (SAM) and its fine-tuned downstream models, even withou&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/ydjojeiwo9/cover.png"/></item><item><title>Transforming Vision Transformer: Towards Efficient Multi-Task Asynchronous Learner</title><link>https://deep-diver.github.io/neurips2024/posters/vwf6zvx5s2/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/vwf6zvx5s2/</guid><description>Efficient Multi-Task Learning (EMTAL) transforms pre-trained Vision Transformers into efficient multi-task learners by using a MoEfied LoRA structure, a Quality Retaining optimization, and a router fa&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/vwf6zvx5s2/cover.png"/></item><item><title>Typicalness-Aware Learning for Failure Detection</title><link>https://deep-diver.github.io/neurips2024/posters/sdweigpah9/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/sdweigpah9/</guid><description>Typicalness-Aware Learning (TAL) improves failure detection by dynamically adjusting prediction confidence based on sample typicality, mitigating overconfidence and achieving significant performance g&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/sdweigpah9/cover.png"/></item><item><title>U-DiTs: Downsample Tokens in U-Shaped Diffusion Transformers</title><link>https://deep-diver.github.io/neurips2024/posters/srws2wxns7/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/srws2wxns7/</guid><description>U-DiT: Revolutionizing diffusion transformers with a U-Net design and token downsampling for superior image generation and drastically reduced computation cost.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/srws2wxns7/cover.png"/></item><item><title>UDON: Universal Dynamic Online distillatioN for generic image representations</title><link>https://deep-diver.github.io/neurips2024/posters/iquxhrcna0/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/iquxhrcna0/</guid><description>UDON: a novel multi-teacher online distillation method creates highly efficient universal image embeddings by dynamically transferring domain-specific knowledge and adapting to imbalanced data.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/iquxhrcna0/cover.png"/></item><item><title>UltraPixel: Advancing Ultra High-Resolution Image Synthesis to New Peaks</title><link>https://deep-diver.github.io/neurips2024/posters/vojcpdlw53/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/vojcpdlw53/</guid><description>UltraPixel generates high-quality images at various resolutions (1K-6K) efficiently using cascade diffusion models, achieving state-of-the-art performance.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/vojcpdlw53/cover.png"/></item><item><title>Understanding Hallucinations in Diffusion Models through Mode Interpolation</title><link>https://deep-diver.github.io/neurips2024/posters/antnhbkw4t/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/antnhbkw4t/</guid><description>Diffusion models generate unrealistic images by smoothly interpolating between data modes; this paper identifies this &amp;lsquo;mode interpolation&amp;rsquo; failure and proposes a metric to detect and reduce it.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/antnhbkw4t/cover.png"/></item><item><title>Understanding Multi-Granularity for Open-Vocabulary Part Segmentation</title><link>https://deep-diver.github.io/neurips2024/posters/he6zxu0n3c/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/he6zxu0n3c/</guid><description>PartCLIPSeg, a novel framework, leverages generalized parts and object-level contexts to achieve significant improvements in open-vocabulary part segmentation, outperforming state-of-the-art methods.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/he6zxu0n3c/cover.png"/></item><item><title>UniFL: Improve Latent Diffusion Model via Unified Feedback Learning</title><link>https://deep-diver.github.io/neurips2024/posters/sy2smstdob/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/sy2smstdob/</guid><description>UniFL: Unified Feedback Learning revolutionizes latent diffusion models by improving image quality, aesthetics, and inference speed through a unified feedback learning framework, surpassing existing m&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/sy2smstdob/cover.png"/></item><item><title>Unlearnable 3D Point Clouds: Class-wise Transformation Is All You Need</title><link>https://deep-diver.github.io/neurips2024/posters/seefza7vmq/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/seefza7vmq/</guid><description>New unlearnable framework secures 3D point cloud data by using class-wise transformations, enabling authorized training while preventing unauthorized access.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/seefza7vmq/cover.png"/></item><item><title>Unsupervised Homography Estimation on Multimodal Image Pair via Alternating Optimization</title><link>https://deep-diver.github.io/neurips2024/posters/zkhyrxlwqh/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/zkhyrxlwqh/</guid><description>AltO: a novel unsupervised learning framework for accurately estimating homography from multimodal image pairs, achieving performance comparable to supervised methods.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/zkhyrxlwqh/cover.png"/></item><item><title>Unsupervised Modality Adaptation with Text-to-Image Diffusion Models for Semantic Segmentation</title><link>https://deep-diver.github.io/neurips2024/posters/5bwwgyvgwr/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/5bwwgyvgwr/</guid><description>Modality Adaptation with Diffusion Models (MADM) achieves state-of-the-art semantic segmentation by using pre-trained text-to-image diffusion models to enhance cross-modality capabilities and generate&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/5bwwgyvgwr/cover.png"/></item><item><title>Unsupervised Object Detection with Theoretical Guarantees</title><link>https://deep-diver.github.io/neurips2024/posters/x33owjqyh0/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/x33owjqyh0/</guid><description>First unsupervised object detection method with theoretical guarantees to recover true object positions, up to quantifiable small shifts!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/x33owjqyh0/cover.png"/></item><item><title>Upping the Game: How 2D U-Net Skip Connections Flip 3D Segmentation</title><link>https://deep-diver.github.io/neurips2024/posters/qi1scdeqjp/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/qi1scdeqjp/</guid><description>Boosting 3D medical image segmentation, a novel U-shaped Connection (uC) integrates 2D U-Net skip connections into 3D CNNs, improving axial-slice plane feature extraction, surpassing state-of-the-art &amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/qi1scdeqjp/cover.png"/></item><item><title>UPS: Unified Projection Sharing for Lightweight Single-Image Super-resolution and Beyond</title><link>https://deep-diver.github.io/neurips2024/posters/tacb2bfzcm/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/tacb2bfzcm/</guid><description>UPS: A novel algorithm for lightweight single-image super-resolution, decoupling feature extraction and similarity modeling for enhanced efficiency and robustness.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/tacb2bfzcm/cover.png"/></item><item><title>UV-free Texture Generation with Denoising and Geodesic Heat Diffusion</title><link>https://deep-diver.github.io/neurips2024/posters/cb1md0rvqf/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/cb1md0rvqf/</guid><description>UV3-TeD generates high-quality 3D textures directly on object surfaces using a novel diffusion probabilistic model, eliminating UV-mapping limitations.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/cb1md0rvqf/cover.png"/></item><item><title>VCR-GauS: View Consistent Depth-Normal Regularizer for Gaussian Surface Reconstruction</title><link>https://deep-diver.github.io/neurips2024/posters/axnjx20ssl/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/axnjx20ssl/</guid><description>VCR-GauS: Novel view-consistent depth-normal regularizer for superior, real-time 3D surface reconstruction using Gaussian splatting.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/axnjx20ssl/cover.png"/></item><item><title>VFIMamba: Video Frame Interpolation with State Space Models</title><link>https://deep-diver.github.io/neurips2024/posters/4s5usbusus/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/4s5usbusus/</guid><description>VFIMamba uses state-space models for efficient and dynamic video frame interpolation, achieving state-of-the-art results by introducing a novel Mixed-SSM Block and curriculum learning.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/4s5usbusus/cover.png"/></item><item><title>Video Diffusion Models are Training-free Motion Interpreter and Controller</title><link>https://deep-diver.github.io/neurips2024/posters/zvq4bn75kn/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/zvq4bn75kn/</guid><description>Training-free video motion control achieved via novel Motion Feature (MOFT) extraction from existing video diffusion models, offering architecture-agnostic insights and high performance.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/zvq4bn75kn/cover.png"/></item><item><title>Video Token Merging for Long Video Understanding</title><link>https://deep-diver.github.io/neurips2024/posters/wdurabdrbs/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/wdurabdrbs/</guid><description>Researchers boost long-form video understanding efficiency by 6.89x and reduce memory usage by 84% using a novel learnable video token merging algorithm.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/wdurabdrbs/cover.png"/></item><item><title>Virtual Scanning: Unsupervised Non-line-of-sight Imaging from Irregularly Undersampled Transients</title><link>https://deep-diver.github.io/neurips2024/posters/r4ibzrsf5d/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/r4ibzrsf5d/</guid><description>Unsupervised learning framework enables high-fidelity non-line-of-sight (NLOS) imaging from irregularly undersampled transients, surpassing state-of-the-art methods in speed and robustness.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/r4ibzrsf5d/cover.png"/></item><item><title>Visual Data Diagnosis and Debiasing with Concept Graphs</title><link>https://deep-diver.github.io/neurips2024/posters/xngsx3wcu9/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/xngsx3wcu9/</guid><description>CONBIAS tackles dataset bias by representing visual data as concept graphs, diagnosing imbalances via clique analysis, and debiasing through targeted data augmentation for improved model generalizatio&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/xngsx3wcu9/cover.png"/></item><item><title>Visual Decoding and Reconstruction via EEG Embeddings with Guided Diffusion</title><link>https://deep-diver.github.io/neurips2024/posters/rxkcroc8qp/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/rxkcroc8qp/</guid><description>Researchers developed a novel zero-shot EEG-based framework for visual reconstruction using a tailored brain encoder and a two-stage image generation strategy, achieving state-of-the-art performance i&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/rxkcroc8qp/cover.png"/></item><item><title>Visual Fourier Prompt Tuning</title><link>https://deep-diver.github.io/neurips2024/posters/nkhel4n0ju/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/nkhel4n0ju/</guid><description>Visual Fourier Prompt Tuning (VFPT) leverages the Fast Fourier Transform to seamlessly integrate spatial and frequency information for superior parameter-efficient vision model fine-tuning, even with &amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/nkhel4n0ju/cover.png"/></item><item><title>Visual Pinwheel Center Act as Geometric Saliency Detector</title><link>https://deep-diver.github.io/neurips2024/posters/lpkcoml66w/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/lpkcoml66w/</guid><description>Visual pinwheel centers in the cortex act as efficient geometric saliency detectors, responding faster and stronger to complex spatial textures than other structures.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/lpkcoml66w/cover.png"/></item><item><title>Vivid-ZOO: Multi-View Video Generation with Diffusion Model</title><link>https://deep-diver.github.io/neurips2024/posters/bpoahf8ocx/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/bpoahf8ocx/</guid><description>Vivid-ZOO: Generating high-quality multi-view videos from text using a novel diffusion model.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/bpoahf8ocx/cover.png"/></item><item><title>VLG-CBM: Training Concept Bottleneck Models with Vision-Language Guidance</title><link>https://deep-diver.github.io/neurips2024/posters/jm2ak3sdjd/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/jm2ak3sdjd/</guid><description>VLG-CBM enhances concept bottleneck models with vision-language guidance for faithful interpretability and improved accuracy.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/jm2ak3sdjd/cover.png"/></item><item><title>VQ-Map: Bird's-Eye-View Map Layout Estimation in Tokenized Discrete Space via Vector Quantization</title><link>https://deep-diver.github.io/neurips2024/posters/bkuxygbw2y/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/bkuxygbw2y/</guid><description>VQ-Map leverages vector quantization to estimate bird&amp;rsquo;s-eye-view maps with unprecedented accuracy, setting new benchmarks.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/bkuxygbw2y/cover.png"/></item><item><title>Warped Diffusion: Solving Video Inverse Problems with Image Diffusion Models</title><link>https://deep-diver.github.io/neurips2024/posters/lh94zpv8cu/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/lh94zpv8cu/</guid><description>Warped Diffusion cleverly adapts image diffusion models for video inverse problems, solving flickering and temporal inconsistency issues by viewing video frames as continuous warping transformations a&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/lh94zpv8cu/cover.png"/></item><item><title>Web-Scale Visual Entity Recognition: An LLM-Driven Data Approach</title><link>https://deep-diver.github.io/neurips2024/posters/vikufblow1/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/vikufblow1/</guid><description>LLM-powered data curation boosts web-scale visual entity recognition!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/vikufblow1/cover.png"/></item><item><title>What Variables Affect Out-of-Distribution Generalization in Pretrained Models?</title><link>https://deep-diver.github.io/neurips2024/posters/poxgdfeb7q/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/poxgdfeb7q/</guid><description>High-resolution datasets with diverse classes significantly improve the transferability of pretrained DNNs by reducing representation compression and mitigating the &amp;rsquo;tunnel effect.'</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/poxgdfeb7q/cover.png"/></item><item><title>Where's Waldo: Diffusion Features For Personalized Segmentation and Retrieval</title><link>https://deep-diver.github.io/neurips2024/posters/lgxeix75sc/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/lgxeix75sc/</guid><description>Unlocking personalized image retrieval and segmentation, a novel approach uses pre-trained text-to-image diffusion models to surpass supervised methods, addressing limitations of existing self-supervi&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/lgxeix75sc/cover.png"/></item><item><title>Wild-GS: Real-Time Novel View Synthesis from Unconstrained Photo Collections</title><link>https://deep-diver.github.io/neurips2024/posters/ss7l98dvvd/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/ss7l98dvvd/</guid><description>Wild-GS achieves real-time novel view synthesis from unconstrained photos by efficiently adapting 3D Gaussian Splatting, significantly improving speed and quality over existing methods.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/ss7l98dvvd/cover.png"/></item><item><title>YOLOv10: Real-Time End-to-End Object Detection</title><link>https://deep-diver.github.io/neurips2024/posters/tz83nyb71l/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/tz83nyb71l/</guid><description>YOLOv10: Real-time object detection achieves state-of-the-art speed and accuracy by eliminating NMS post-processing and holistically optimizing model architecture for efficiency and accuracy.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/tz83nyb71l/cover.png"/></item><item><title>Zero-shot Generalizable Incremental Learning for Vision-Language Object Detection</title><link>https://deep-diver.github.io/neurips2024/posters/znqhm0a35e/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/znqhm0a35e/</guid><description>ZiRa achieves zero-shot generalizable incremental learning for vision-language object detection by using a memory-efficient dual-branch architecture and zero-interference loss, significantly boosting &amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/znqhm0a35e/cover.png"/></item><item><title>Zero-shot Image Editing with Reference Imitation</title><link>https://deep-diver.github.io/neurips2024/posters/lzv0u6uhb6/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/lzv0u6uhb6/</guid><description>MimicBrush: a novel image editing approach using reference imitation for intuitive zero-shot edits.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/lzv0u6uhb6/cover.png"/></item><item><title>Zero-Shot Scene Reconstruction from Single Images with Deep Prior Assembly</title><link>https://deep-diver.github.io/neurips2024/posters/sotk84ewb7/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/sotk84ewb7/</guid><description>Zero-shot 3D scene reconstruction from single images is achieved by assembling diverse deep priors from large models, eliminating the need for 3D/2D training data and achieving superior performance.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/sotk84ewb7/cover.png"/></item><item><title>ZOPP: A Framework of Zero-shot Offboard Panoptic Perception for Autonomous Driving</title><link>https://deep-diver.github.io/neurips2024/posters/4jxaca2nya/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/4jxaca2nya/</guid><description>ZOPP: A groundbreaking framework for zero-shot offboard panoptic perception in autonomous driving, enabling high-quality 3D scene understanding without human labeling.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/4jxaca2nya/cover.png"/></item></channel></rss>