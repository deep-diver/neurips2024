<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Computer Vision on NeurIPS 2024</title><link>https://deep-diver.github.io/neurips2024/tags/computer-vision/</link><description>Recent content in Computer Vision on NeurIPS 2024</description><generator>Hugo -- gohugo.io</generator><language>en</language><copyright>© 2024 AI Paper Reviewer</copyright><lastBuildDate>Thu, 26 Sep 2024 00:00:00 +0000</lastBuildDate><atom:link href="https://deep-diver.github.io/neurips2024/tags/computer-vision/index.xml" rel="self" type="application/rss+xml"/><item><title>$ ext{ID}^3$: Identity-Preserving-yet-Diversified Diffusion Models for Synthetic Face Recognition</title><link>https://deep-diver.github.io/neurips2024/posters/x4hmnqs6ie/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/x4hmnqs6ie/</guid><description>ID³: A novel diffusion model generates diverse, identity-preserving synthetic face datasets for accurate and privacy-preserving face recognition, exceeding current state-of-the-art methods.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/x4hmnqs6ie/cover.png"/></item><item><title>$SE(3)$ Equivariant Ray Embeddings for Implicit Multi-View Depth Estimation</title><link>https://deep-diver.github.io/neurips2024/posters/yrujqowocs/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/yrujqowocs/</guid><description>SE(3)-equivariant ray embeddings in Perceiver IO achieve state-of-the-art implicit multi-view depth estimation, surpassing methods that rely on data augmentation for approximate equivariance.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/yrujqowocs/cover.png"/></item><item><title>3D Equivariant Pose Regression via Direct Wigner-D Harmonics Prediction</title><link>https://deep-diver.github.io/neurips2024/posters/nw8cxonvep/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/nw8cxonvep/</guid><description>3D pose estimation is revolutionized by a novel SO(3)-equivariant network directly predicting Wigner-D harmonics, achieving state-of-the-art accuracy and efficiency.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/nw8cxonvep/cover.png"/></item><item><title>A Consistency-Aware Spot-Guided Transformer for Versatile and Hierarchical Point Cloud Registration</title><link>https://deep-diver.github.io/neurips2024/posters/btllwaorfs/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/btllwaorfs/</guid><description>CAST: a novel consistency-aware spot-guided Transformer achieves state-of-the-art accuracy and efficiency in point cloud registration.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/btllwaorfs/cover.png"/></item><item><title>A Unified Framework for 3D Scene Understanding</title><link>https://deep-diver.github.io/neurips2024/posters/de1btyyc9a/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/de1btyyc9a/</guid><description>UniSeg3D: One model to rule them all! This unified framework masters six 3D segmentation tasks (panoptic, semantic, instance, interactive, referring, and open-vocabulary) simultaneously, outperforming&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/de1btyyc9a/cover.png"/></item><item><title>Activating Self-Attention for Multi-Scene Absolute Pose Regression</title><link>https://deep-diver.github.io/neurips2024/posters/rm24uugzg8/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/rm24uugzg8/</guid><description>Boosting Multi-Scene Pose Regression: Novel methods activate transformer self-attention, significantly improving camera pose estimation accuracy and efficiency.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/rm24uugzg8/cover.png"/></item><item><title>Adapting Diffusion Models for Improved Prompt Compliance and Controllable Image Synthesis</title><link>https://deep-diver.github.io/neurips2024/posters/sntv8ac3u2/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/sntv8ac3u2/</guid><description>FG-DMs revolutionize image synthesis by jointly modeling image and condition distributions, achieving higher object recall and enabling flexible editing.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/sntv8ac3u2/cover.png"/></item><item><title>An Image is Worth 32 Tokens for Reconstruction and Generation</title><link>https://deep-diver.github.io/neurips2024/posters/toxoqprzpl/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/toxoqprzpl/</guid><description>Image generation gets a speed boost with TiTok, a novel 1D image tokenizer that uses just 32 tokens for high-quality image reconstruction and generation, achieving up to 410x faster processing than st&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/toxoqprzpl/cover.png"/></item><item><title>Applying Guidance in a Limited Interval Improves Sample and Distribution Quality in Diffusion Models</title><link>https://deep-diver.github.io/neurips2024/posters/naihvny15t/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/naihvny15t/</guid><description>Boosting image generation: Applying guidance selectively during diffusion model sampling drastically enhances image quality and inference speed, achieving state-of-the-art results.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/naihvny15t/cover.png"/></item><item><title>Assembly Fuzzy Representation on Hypergraph for Open-Set 3D Object Retrieval</title><link>https://deep-diver.github.io/neurips2024/posters/xocaurlvm9/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/xocaurlvm9/</guid><description>Hypergraph-Based Assembly Fuzzy Representation (HAFR) excels at open-set 3D object retrieval by using part-level shapes and fuzzy representations to overcome challenges posed by unseen object categori&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/xocaurlvm9/cover.png"/></item><item><title>Binarized Diffusion Model for Image Super-Resolution</title><link>https://deep-diver.github.io/neurips2024/posters/yxpfrlmir2/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/yxpfrlmir2/</guid><description>BI-DiffSR, a novel binarized diffusion model, achieves high-quality image super-resolution with significantly reduced memory and computational costs, outperforming existing methods.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/yxpfrlmir2/cover.png"/></item><item><title>Binocular-Guided 3D Gaussian Splatting with View Consistency for Sparse View Synthesis</title><link>https://deep-diver.github.io/neurips2024/posters/otettmiymz/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/otettmiymz/</guid><description>Binocular-guided 3D Gaussian splatting with self-supervision generates high-quality novel views from sparse inputs without external priors, significantly outperforming state-of-the-art methods.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/otettmiymz/cover.png"/></item><item><title>Can We Leave Deepfake Data Behind in Training Deepfake Detector?</title><link>https://deep-diver.github.io/neurips2024/posters/vh9yepleyd/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/vh9yepleyd/</guid><description>ProDet: Deepfake detection enhanced by progressively organizing blendfake and deepfake data in the latent space, improving generalization and robustness.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/vh9yepleyd/cover.png"/></item><item><title>CemiFace: Center-based Semi-hard Synthetic Face Generation for Face Recognition</title><link>https://deep-diver.github.io/neurips2024/posters/ykqnxko1cj/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/ykqnxko1cj/</guid><description>CemiFace: Generating high-quality synthetic facial data for robust face recognition, while addressing privacy concerns.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/ykqnxko1cj/cover.png"/></item><item><title>Classification Diffusion Models: Revitalizing Density Ratio Estimation</title><link>https://deep-diver.github.io/neurips2024/posters/d99ycfonwk/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/d99ycfonwk/</guid><description>Classification Diffusion Models (CDMs) revolutionize density ratio estimation by integrating the strengths of diffusion models and classifiers, achieving state-of-the-art image generation and likeliho&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/d99ycfonwk/cover.png"/></item><item><title>Color-Oriented Redundancy Reduction in Dataset Distillation</title><link>https://deep-diver.github.io/neurips2024/posters/yfqwyxisj7/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/yfqwyxisj7/</guid><description>AutoPalette: a new framework minimizing color redundancy in dataset distillation, resulting in more efficient model training with comparable performance.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/yfqwyxisj7/cover.png"/></item><item><title>Consistency Purification: Effective and Efficient Diffusion Purification towards Certified Robustness</title><link>https://deep-diver.github.io/neurips2024/posters/tlwoxftjvh/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/tlwoxftjvh/</guid><description>Consistency Purification boosts certified robustness by efficiently purifying noisy images using a one-step generative model, achieving state-of-the-art results while maintaining semantic alignment.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/tlwoxftjvh/cover.png"/></item><item><title>Constrained Diffusion with Trust Sampling</title><link>https://deep-diver.github.io/neurips2024/posters/djub9xrozi/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/djub9xrozi/</guid><description>Trust Sampling enhances guided diffusion by iteratively optimizing constrained generation at each step, improving efficiency and accuracy in image and 3D motion generation.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/djub9xrozi/cover.png"/></item><item><title>Constructing Semantics-Aware Adversarial Examples with Probabilistic Perspective</title><link>https://deep-diver.github.io/neurips2024/posters/wbe0qcbwji/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/wbe0qcbwji/</guid><description>Researchers developed semantics-aware adversarial examples using a probabilistic approach, achieving higher success rates in bypassing defenses while remaining undetectable to humans.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/wbe0qcbwji/cover.png"/></item><item><title>Continuous Spatiotemporal Events Decoupling through Spike-based Bayesian Computation</title><link>https://deep-diver.github.io/neurips2024/posters/znihpznqhh/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/znihpznqhh/</guid><description>Spiking neural network effectively segments mixed-motion event streams via spike-based Bayesian computation, achieving efficient real-time motion decoupling.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/znihpznqhh/cover.png"/></item><item><title>Cooperative Hardware-Prompt Learning for Snapshot Compressive Imaging</title><link>https://deep-diver.github.io/neurips2024/posters/zxswidyw3a/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/zxswidyw3a/</guid><description>Federated Hardware-Prompt Learning (FedHP) enables robust cross-hardware SCI training by aligning inconsistent data distributions using a hardware-conditioned prompter, outperforming existing FL metho&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/zxswidyw3a/cover.png"/></item><item><title>CRAYM: Neural Field Optimization via Camera RAY Matching</title><link>https://deep-diver.github.io/neurips2024/posters/wk0z49myyi/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/wk0z49myyi/</guid><description>CRAYM: Neural field optimization via camera RAY matching enhances 3D reconstruction by using camera rays, not pixels, improving both novel view synthesis and geometry.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/wk0z49myyi/cover.png"/></item><item><title>Decoupled Kullback-Leibler Divergence Loss</title><link>https://deep-diver.github.io/neurips2024/posters/bnzzedw9cm/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/bnzzedw9cm/</guid><description>Improved Kullback-Leibler (IKL) divergence loss achieves state-of-the-art adversarial robustness and competitive knowledge distillation performance by addressing KL loss&amp;rsquo;s limitations.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/bnzzedw9cm/cover.png"/></item><item><title>Decoupling Semantic Similarity from Spatial Alignment for Neural Networks.</title><link>https://deep-diver.github.io/neurips2024/posters/ypfgct147z/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/ypfgct147z/</guid><description>Researchers developed semantic RSMs, a novel approach to measure semantic similarity in neural networks, improving image retrieval and aligning network representations with predicted class probabiliti&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/ypfgct147z/cover.png"/></item><item><title>Defensive Unlearning with Adversarial Training for Robust Concept Erasure in Diffusion Models</title><link>https://deep-diver.github.io/neurips2024/posters/dkpmfiydrf/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/dkpmfiydrf/</guid><description>AdvUnlearn enhances diffusion model robustness against adversarial attacks during concept erasure by integrating adversarial training, improving the trade-off between robustness and model utility.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/dkpmfiydrf/cover.png"/></item><item><title>Depth Anything V2</title><link>https://deep-diver.github.io/neurips2024/posters/cfti3glj1x/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/cfti3glj1x/</guid><description>Depth Anything V2 drastically improves monocular depth estimation by using synthetic training data, scaling up the teacher model, and employing pseudo-labeled real images. It outperforms previous met&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/cfti3glj1x/cover.png"/></item><item><title>Dynamic Tuning Towards Parameter and Inference Efficiency for ViT Adaptation</title><link>https://deep-diver.github.io/neurips2024/posters/e0sq6wshjv/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/e0sq6wshjv/</guid><description>Dynamic Tuning (DyT) significantly boosts Vision Transformer (ViT) adaptation by dynamically skipping less important tokens during inference, achieving superior performance with 71% fewer FLOPs than e&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/e0sq6wshjv/cover.png"/></item><item><title>EM Distillation for One-step Diffusion Models</title><link>https://deep-diver.github.io/neurips2024/posters/rafvvthuxd/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/rafvvthuxd/</guid><description>EM Distillation (EMD) efficiently trains one-step diffusion models by using an Expectation-Maximization approach, achieving state-of-the-art image generation quality and outperforming existing methods&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/rafvvthuxd/cover.png"/></item><item><title>Exploring Token Pruning in Vision State Space Models</title><link>https://deep-diver.github.io/neurips2024/posters/ewign0fcdx/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/ewign0fcdx/</guid><description>This paper introduces a novel token pruning method for vision state space models, achieving significant computational reduction with minimal performance impact, addressing the limitations of directly &amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/ewign0fcdx/cover.png"/></item><item><title>Extending Video Masked Autoencoders to 128 frames</title><link>https://deep-diver.github.io/neurips2024/posters/bfrnplwchg/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/bfrnplwchg/</guid><description>Long-video masked autoencoders (LVMAE) achieve state-of-the-art performance by using an adaptive masking strategy that prioritizes important video tokens, enabling efficient training on 128 frames.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/bfrnplwchg/cover.png"/></item><item><title>Fast Encoder-Based 3D from Casual Videos via Point Track Processing</title><link>https://deep-diver.github.io/neurips2024/posters/bqgaheaeqy/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/bqgaheaeqy/</guid><description>TRACKSTO4D: Fast &amp;amp; accurate 3D reconstruction from casual videos using 2D point tracks, drastically reducing runtime by up to 95% while matching state-of-the-art accuracy.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/bqgaheaeqy/cover.png"/></item><item><title>Flatten Anything: Unsupervised Neural Surface Parameterization</title><link>https://deep-diver.github.io/neurips2024/posters/eneqgc9agr/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/eneqgc9agr/</guid><description>Flatten Anything Model (FAM) revolutionizes neural surface parameterization with unsupervised learning, handling complex topologies and unstructured data fully automatically.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/eneqgc9agr/cover.png"/></item><item><title>Flow Snapshot Neurons in Action: Deep Neural Networks Generalize to Biological Motion Perception</title><link>https://deep-diver.github.io/neurips2024/posters/btuhzsavsk/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/btuhzsavsk/</guid><description>Deep neural networks finally match human biological motion perception capabilities by leveraging patch-level optical flows and innovative neuron designs, achieving a 29% accuracy improvement.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/btuhzsavsk/cover.png"/></item><item><title>From Trojan Horses to Castle Walls: Unveiling Bilateral Data Poisoning Effects in Diffusion Models</title><link>https://deep-diver.github.io/neurips2024/posters/yixzzc5qdi/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/yixzzc5qdi/</guid><description>Diffusion models, while excelling in image generation, are vulnerable to data poisoning. This paper demonstrates a BadNets-like attack&amp;rsquo;s effectiveness against diffusion models, causing image misalign&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/yixzzc5qdi/cover.png"/></item><item><title>GaussianMarker: Uncertainty-Aware Copyright Protection of 3D Gaussian Splatting</title><link>https://deep-diver.github.io/neurips2024/posters/wcxhbay8b3/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/wcxhbay8b3/</guid><description>GaussianMarker: A novel uncertainty-aware watermarking method ensures robust copyright protection for 3D Gaussian Splatting assets, invisibly embedding messages into model parameters and extractable &amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/wcxhbay8b3/cover.png"/></item><item><title>Gradient-free Decoder Inversion in Latent Diffusion Models</title><link>https://deep-diver.github.io/neurips2024/posters/nbqvjkos6s/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/nbqvjkos6s/</guid><description>This paper introduces a novel gradient-free decoder inversion method for latent diffusion models, improving efficiency and memory usage compared to existing gradient-based methods. The method is theo&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/nbqvjkos6s/cover.png"/></item><item><title>Hierarchical Selective Classification</title><link>https://deep-diver.github.io/neurips2024/posters/wzof7y66xs/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/wzof7y66xs/</guid><description>Hierarchical Selective Classification (HSC) improves deep learning model reliability for risk-sensitive tasks by leveraging hierarchical class relationships to provide more informative predictions eve&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/wzof7y66xs/cover.png"/></item><item><title>Identifying and Solving Conditional Image Leakage in Image-to-Video Diffusion Model</title><link>https://deep-diver.github.io/neurips2024/posters/o9lkiv1qpc/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/o9lkiv1qpc/</guid><description>Researchers solve the conditional image leakage problem in image-to-video diffusion models by proposing a new inference strategy and a time-dependent noise distribution for training. This yields video&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/o9lkiv1qpc/cover.png"/></item><item><title>In Pursuit of Causal Label Correlations for Multi-label Image Recognition</title><link>https://deep-diver.github.io/neurips2024/posters/ybhbespwys/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/ybhbespwys/</guid><description>This research leverages causal intervention to identify and utilize genuine label correlations in multi-label image recognition, mitigating contextual bias for improved accuracy.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/ybhbespwys/cover.png"/></item><item><title>Incorporating Test-Time Optimization into Training with Dual Networks for Human Mesh Recovery</title><link>https://deep-diver.github.io/neurips2024/posters/ugqx9tgyum/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/ugqx9tgyum/</guid><description>Meta-learning enhances human mesh recovery by unifying training and test-time objectives, significantly improving accuracy and generalization.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/ugqx9tgyum/cover.png"/></item><item><title>Infinite-Dimensional Feature Interaction</title><link>https://deep-diver.github.io/neurips2024/posters/xo9ghdmk76/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/xo9ghdmk76/</guid><description>InfiNet achieves state-of-the-art results by enabling feature interaction in an infinite-dimensional space using RBF kernels, surpassing models limited to finite-dimensional interactions.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/xo9ghdmk76/cover.png"/></item><item><title>Integrating Deep Metric Learning with Coreset for Active Learning in 3D Segmentation</title><link>https://deep-diver.github.io/neurips2024/posters/uyqjpycmbu/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/uyqjpycmbu/</guid><description>Deep metric learning and Coreset integration enables efficient slice-based active learning for 3D medical segmentation, surpassing existing methods in performance with low annotation budgets.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/uyqjpycmbu/cover.png"/></item><item><title>Large Spatial Model: End-to-end Unposed Images to Semantic 3D</title><link>https://deep-diver.github.io/neurips2024/posters/ybhpzl7eyt/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/ybhpzl7eyt/</guid><description>Large Spatial Model (LSM) achieves real-time semantic 3D reconstruction from just two unposed images, unifying multiple 3D vision tasks in a single feed-forward pass.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/ybhpzl7eyt/cover.png"/></item><item><title>Latent Representation Matters: Human-like Sketches in One-shot Drawing Tasks</title><link>https://deep-diver.github.io/neurips2024/posters/tzrpvlxevu/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/tzrpvlxevu/</guid><description>AI now draws almost as well as humans, thanks to novel latent diffusion model regularizations that mimic human cognitive biases.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/tzrpvlxevu/cover.png"/></item><item><title>Learning 3D Garment Animation from Trajectories of A Piece of Cloth</title><link>https://deep-diver.github.io/neurips2024/posters/yefx5nqmr7/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/yefx5nqmr7/</guid><description>Animates diverse garments realistically from a single cloth&amp;rsquo;s trajectory using a disentangled learning approach and Energy Unit Network (EUNet).</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/yefx5nqmr7/cover.png"/></item><item><title>Learning Bregman Divergences with Application to Robustness</title><link>https://deep-diver.github.io/neurips2024/posters/yuckudjae0/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/yuckudjae0/</guid><description>Learned Bregman divergences significantly improve image corruption robustness in adversarial training.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/yuckudjae0/cover.png"/></item><item><title>Learning Optimal Lattice Vector Quantizers for End-to-end Neural Image Compression</title><link>https://deep-diver.github.io/neurips2024/posters/dlr4h7uj4h/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/dlr4h7uj4h/</guid><description>Learned optimal lattice vector quantization (OLVQ) drastically boosts neural image compression efficiency by adapting quantizer structures to latent feature distributions, achieving significant rate-d&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/dlr4h7uj4h/cover.png"/></item><item><title>Learning to Edit Visual Programs with Self-Supervision</title><link>https://deep-diver.github.io/neurips2024/posters/uziwqrzjep/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/uziwqrzjep/</guid><description>AI learns to edit visual programs more accurately using a self-supervised method that combines one-shot program generation with iterative local edits, significantly boosting performance, especially wi&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/uziwqrzjep/cover.png"/></item><item><title>Learning Truncated Causal History Model for Video Restoration</title><link>https://deep-diver.github.io/neurips2024/posters/cugf2hancs/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/cugf2hancs/</guid><description>TURTLE: a novel video restoration framework that learns a truncated causal history model for efficient and high-performing video restoration, achieving state-of-the-art results on various benchmark ta&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/cugf2hancs/cover.png"/></item><item><title>Long-Range Feedback Spiking Network Captures Dynamic and Static Representations of the Visual Cortex under Movie Stimuli</title><link>https://deep-diver.github.io/neurips2024/posters/bxdok3uak6/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/bxdok3uak6/</guid><description>Long-range feedback spiking network (LoRaFB-SNet) surpasses other models in capturing dynamic and static visual cortical representations under movie stimuli, advancing our understanding of visual syst&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/bxdok3uak6/cover.png"/></item><item><title>Long-Tailed Out-of-Distribution Detection via Normalized Outlier Distribution Adaptation</title><link>https://deep-diver.github.io/neurips2024/posters/ceswi7mmly/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/ceswi7mmly/</guid><description>AdaptOD: a novel approach for robust OOD detection in long-tailed recognition, dynamically adapting outlier distributions to true OOD distributions using a dual-normalized energy loss for improved acc&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/ceswi7mmly/cover.png"/></item><item><title>ManiPose: Manifold-Constrained Multi-Hypothesis 3D Human Pose Estimation</title><link>https://deep-diver.github.io/neurips2024/posters/xxy8d4rnsb/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/xxy8d4rnsb/</guid><description>ManiPose: Manifold-constrained multi-hypothesis model solves 3D human pose estimation&amp;rsquo;s depth ambiguity, outperforming state-of-the-art models in pose consistency.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/xxy8d4rnsb/cover.png"/></item><item><title>Masked Pre-training Enables Universal Zero-shot Denoiser</title><link>https://deep-diver.github.io/neurips2024/posters/ofgtscasbr/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/ofgtscasbr/</guid><description>Masked Pre-training empowers a universal, fast zero-shot image denoiser!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/ofgtscasbr/cover.png"/></item><item><title>MC-DiT: Contextual Enhancement via Clean-to-Clean Reconstruction for Masked Diffusion Models</title><link>https://deep-diver.github.io/neurips2024/posters/y9shkrdnrt/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/y9shkrdnrt/</guid><description>MC-DiT: A novel training paradigm for masked diffusion models achieving state-of-the-art image generation by leveraging clean-to-clean reconstruction.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/y9shkrdnrt/cover.png"/></item><item><title>MonoMAE: Enhancing Monocular 3D Detection through Depth-Aware Masked Autoencoders</title><link>https://deep-diver.github.io/neurips2024/posters/wik6bwuxje/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/wik6bwuxje/</guid><description>MonoMAE enhances monocular 3D object detection by using depth-aware masked autoencoders to effectively handle object occlusions, achieving superior performance on both occluded and non-occluded object&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/wik6bwuxje/cover.png"/></item><item><title>Neural Concept Binder</title><link>https://deep-diver.github.io/neurips2024/posters/yppzyflbys/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/yppzyflbys/</guid><description>The Neural Concept Binder (NCB) framework learns expressive, inspectable, and revisable visual concepts unsupervised, integrating both continuous and discrete representations for seamless use in neura&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/yppzyflbys/cover.png"/></item><item><title>Neural Experts: Mixture of Experts for Implicit Neural Representations</title><link>https://deep-diver.github.io/neurips2024/posters/wwguwyhpay/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/wwguwyhpay/</guid><description>Boosting implicit neural representations, Neural Experts uses a Mixture of Experts architecture to achieve faster, more accurate, and memory-efficient signal reconstruction across various tasks.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/wwguwyhpay/cover.png"/></item><item><title>Neural Gaffer: Relighting Any Object via Diffusion</title><link>https://deep-diver.github.io/neurips2024/posters/zv2gdszb5a/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/zv2gdszb5a/</guid><description>Neural Gaffer: Relighting any object via diffusion using a single image and an environment map to produce high-quality, realistic relit images.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/zv2gdszb5a/cover.png"/></item><item><title>Neural Signed Distance Function Inference through Splatting 3D Gaussians Pulled on Zero-Level Set</title><link>https://deep-diver.github.io/neurips2024/posters/r6tndxikns/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/r6tndxikns/</guid><description>Neural SDF inference is revolutionized by dynamically aligning 3D Gaussians to a neural SDF&amp;rsquo;s zero-level set, enabling accurate, smooth 3D surface reconstruction.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/r6tndxikns/cover.png"/></item><item><title>One for All: Multi-Domain Joint Training for Point Cloud Based 3D Object Detection</title><link>https://deep-diver.github.io/neurips2024/posters/ndoehx1acq/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/ndoehx1acq/</guid><description>OneDet3D: A universal 3D object detector trained jointly on diverse indoor/outdoor datasets, achieving one-for-all performance across domains and categories.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/ndoehx1acq/cover.png"/></item><item><title>One-Step Diffusion Distillation through Score Implicit Matching</title><link>https://deep-diver.github.io/neurips2024/posters/ogk236hsjm/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/ogk236hsjm/</guid><description>Score Implicit Matching (SIM) revolutionizes diffusion model distillation by creating high-quality, single-step generators from complex, multi-step models, achieving comparable performance and enablin&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/ogk236hsjm/cover.png"/></item><item><title>Prompt-Agnostic Adversarial Perturbation for Customized Diffusion Models</title><link>https://deep-diver.github.io/neurips2024/posters/omhpejygdx/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/omhpejygdx/</guid><description>Prompt-Agnostic Adversarial Perturbation (PAP) defends customized diffusion models against image tampering, achieving superior generalization over prompt-specific methods.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/omhpejygdx/cover.png"/></item><item><title>Prototypical Hash Encoding for On-the-Fly Fine-Grained Category Discovery</title><link>https://deep-diver.github.io/neurips2024/posters/seyxqfgt0q/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/seyxqfgt0q/</guid><description>Prototypical Hash Encoding (PHE) significantly boosts on-the-fly fine-grained category discovery by using multiple prototypes per category to generate highly discriminative hash codes, thus resolving &amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/seyxqfgt0q/cover.png"/></item><item><title>Prune and Repaint: Content-Aware Image Retargeting for any Ratio</title><link>https://deep-diver.github.io/neurips2024/posters/qwi6esgbjb/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/qwi6esgbjb/</guid><description>Prune and Repaint: A new content-aware method for superior image retargeting across any aspect ratio, preserving key features and avoiding artifacts.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/qwi6esgbjb/cover.png"/></item><item><title>Recovering Complete Actions for Cross-dataset Skeleton Action Recognition</title><link>https://deep-diver.github.io/neurips2024/posters/oe7mfqfk1m/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/oe7mfqfk1m/</guid><description>Boost skeleton action recognition accuracy across datasets by recovering complete actions and resampling; outperforms existing methods.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/oe7mfqfk1m/cover.png"/></item><item><title>ReGS: Reference-based Controllable Scene Stylization with Gaussian Splatting</title><link>https://deep-diver.github.io/neurips2024/posters/ynjr0rw6fr/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/ynjr0rw6fr/</guid><description>ReGS: Real-time reference-based 3D scene stylization using Gaussian Splatting for high-fidelity texture editing and free-view navigation.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/ynjr0rw6fr/cover.png"/></item><item><title>RestoreAgent: Autonomous Image Restoration Agent via Multimodal Large Language Models</title><link>https://deep-diver.github.io/neurips2024/posters/xgp5ynlzwf/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/xgp5ynlzwf/</guid><description>RestoreAgent, an AI-powered image restoration agent, autonomously identifies and corrects multiple image degradations, exceeding human expert performance.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/xgp5ynlzwf/cover.png"/></item><item><title>Rethinking No-reference Image Exposure Assessment from Holism to Pixel: Models, Datasets and Benchmarks</title><link>https://deep-diver.github.io/neurips2024/posters/zvrqeopioq/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/zvrqeopioq/</guid><description>Revolutionizing image exposure assessment, Pixel-level IEA Network (P-IEANet) achieves state-of-the-art performance with a novel pixel-level approach, a new dataset (IEA40K), and a benchmark of 19 met&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/zvrqeopioq/cover.png"/></item><item><title>ReVideo: Remake a Video with Motion and Content Control</title><link>https://deep-diver.github.io/neurips2024/posters/xujbzr6b1t/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/xujbzr6b1t/</guid><description>ReVideo enables precise local video editing by independently controlling content and motion, overcoming limitations of existing methods and paving the way for advanced video manipulation.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/xujbzr6b1t/cover.png"/></item><item><title>Revisiting the Integration of Convolution and Attention for Vision Backbone</title><link>https://deep-diver.github.io/neurips2024/posters/ttuxtv2yra/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/ttuxtv2yra/</guid><description>GLMix: A novel vision backbone efficiently integrates convolutions and multi-head self-attention at different granularities, achieving state-of-the-art performance while addressing scalability issues.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/ttuxtv2yra/cover.png"/></item><item><title>RobIR: Robust Inverse Rendering for High-Illumination Scenes</title><link>https://deep-diver.github.io/neurips2024/posters/y7oxy5pq4j/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/y7oxy5pq4j/</guid><description>RobIR: Robust inverse rendering in high-illumination scenes using ACES tone mapping and regularized visibility estimation for accurate BRDF reconstruction.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/y7oxy5pq4j/cover.png"/></item><item><title>Scaling White-Box Transformers for Vision</title><link>https://deep-diver.github.io/neurips2024/posters/wkwgedn19x/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/wkwgedn19x/</guid><description>CRATE-a: A new white-box vision transformer architecture achieves 85.1% ImageNet accuracy by strategically scaling model size and datasets, outperforming prior white-box models and preserving interpre&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/wkwgedn19x/cover.png"/></item><item><title>Self-Distilled Depth Refinement with Noisy Poisson Fusion</title><link>https://deep-diver.github.io/neurips2024/posters/nequ0ica0s/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/nequ0ica0s/</guid><description>Self-Distilled Depth Refinement (SDDR) tackles noisy depth maps via a novel noisy Poisson fusion approach, achieving significant improvements in depth accuracy and edge quality.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/nequ0ica0s/cover.png"/></item><item><title>Semantic Feature Learning for Universal Unsupervised Cross-Domain Retrieval</title><link>https://deep-diver.github.io/neurips2024/posters/zzvqzrxsao/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/zzvqzrxsao/</guid><description>Universal Unsupervised Cross-Domain Retrieval (U2CDR) framework learns semantic features to enable accurate retrieval even when category spaces differ across domains.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/zzvqzrxsao/cover.png"/></item><item><title>Sharing Key Semantics in Transformer Makes Efficient Image Restoration</title><link>https://deep-diver.github.io/neurips2024/posters/pebp89l4v6/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/pebp89l4v6/</guid><description>SemanIR boosts image restoration efficiency by cleverly sharing key semantic information within Transformer layers, achieving state-of-the-art results across multiple tasks.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/pebp89l4v6/cover.png"/></item><item><title>Slicing Vision Transformer for Flexibile Inference</title><link>https://deep-diver.github.io/neurips2024/posters/zjnsbgl4ua/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/zjnsbgl4ua/</guid><description>Scala: One-shot training enables flexible ViT inference!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/zjnsbgl4ua/cover.png"/></item><item><title>Sparse-view Pose Estimation and Reconstruction via Analysis by Generative Synthesis</title><link>https://deep-diver.github.io/neurips2024/posters/wgpmdyjgsg/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/wgpmdyjgsg/</guid><description>SparseAGS: High-fidelity 3D reconstruction &amp;amp; camera pose estimation from sparse views via generative synthesis.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/wgpmdyjgsg/cover.png"/></item><item><title>Splatter a Video: Video Gaussian Representation for Versatile Processing</title><link>https://deep-diver.github.io/neurips2024/posters/bzuqtvdxv0/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/bzuqtvdxv0/</guid><description>Researchers introduce Video Gaussian Representation (VGR) for versatile video processing, embedding videos into explicit 3D Gaussians for intuitive motion and appearance modeling.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/bzuqtvdxv0/cover.png"/></item><item><title>Stabilize the Latent Space for Image Autoregressive Modeling: A Unified Perspective</title><link>https://deep-diver.github.io/neurips2024/posters/waq5x4qc3w/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/waq5x4qc3w/</guid><description>DiGIT stabilizes image autoregressive models&amp;rsquo; latent space using a novel discrete tokenizer from self-supervised learning, achieving state-of-the-art image generation.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/waq5x4qc3w/cover.png"/></item><item><title>Taming Diffusion Prior for Image Super-Resolution with Domain Shift SDEs</title><link>https://deep-diver.github.io/neurips2024/posters/u7oktt4zye/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/u7oktt4zye/</guid><description>DoSSR: A novel SR model boosts efficiency by 5-7x, achieving state-of-the-art performance with only 5 sampling steps by cleverly integrating a domain shift equation into pretrained diffusion models.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/u7oktt4zye/cover.png"/></item><item><title>Temporally Consistent Atmospheric Turbulence Mitigation with Neural Representations</title><link>https://deep-diver.github.io/neurips2024/posters/yurca4wi2l/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/yurca4wi2l/</guid><description>ConVRT: A novel framework restores turbulence-distorted videos by decoupling spatial and temporal information in a neural representation, achieving temporally consistent mitigation.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/yurca4wi2l/cover.png"/></item><item><title>Toward Approaches to Scalability in 3D Human Pose Estimation</title><link>https://deep-diver.github.io/neurips2024/posters/xse8qmgnym/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/xse8qmgnym/</guid><description>Boosting 3D human pose estimation: Biomechanical Pose Generator and Binary Depth Coordinates enhance accuracy and scalability.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/xse8qmgnym/cover.png"/></item><item><title>Towards Flexible 3D Perception: Object-Centric Occupancy Completion Augments 3D Object Detection</title><link>https://deep-diver.github.io/neurips2024/posters/yktqnqtepd/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/yktqnqtepd/</guid><description>Object-centric occupancy completion boosts 3D object detection accuracy by using temporal information from long sequences to precisely reconstruct object shapes, particularly for incomplete or distant&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/yktqnqtepd/cover.png"/></item><item><title>Towards Multi-Domain Learning for Generalizable Video Anomaly Detection</title><link>https://deep-diver.github.io/neurips2024/posters/yweqkcmimh/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/yweqkcmimh/</guid><description>Researchers propose Multi-Domain learning for Video Anomaly Detection (MDVAD) to create generalizable models handling conflicting abnormality criteria across diverse datasets, improving accuracy and a&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/yweqkcmimh/cover.png"/></item><item><title>Training-Free Adaptive Diffusion with Bounded Difference Approximation Strategy</title><link>https://deep-diver.github.io/neurips2024/posters/cs63ytj49a/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/cs63ytj49a/</guid><description>AdaptiveDiffusion accelerates diffusion model inference by adaptively skipping noise prediction steps, achieving 2-5x speedup without quality loss.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/cs63ytj49a/cover.png"/></item><item><title>Transferable Adversarial Attacks on SAM and Its Downstream Models</title><link>https://deep-diver.github.io/neurips2024/posters/ydjojeiwo9/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/ydjojeiwo9/</guid><description>UMI-GRAT: A universal meta-initialized and gradient robust adversarial attack effectively exploits vulnerabilities in the Segment Anything Model (SAM) and its fine-tuned downstream models, even withou&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/ydjojeiwo9/cover.png"/></item><item><title>Unsupervised Homography Estimation on Multimodal Image Pair via Alternating Optimization</title><link>https://deep-diver.github.io/neurips2024/posters/zkhyrxlwqh/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/zkhyrxlwqh/</guid><description>AltO: a novel unsupervised learning framework for accurately estimating homography from multimodal image pairs, achieving performance comparable to supervised methods.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/zkhyrxlwqh/cover.png"/></item><item><title>Unsupervised Object Detection with Theoretical Guarantees</title><link>https://deep-diver.github.io/neurips2024/posters/x33owjqyh0/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/x33owjqyh0/</guid><description>First unsupervised object detection method with theoretical guarantees to recover true object positions, up to quantifiable small shifts!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/x33owjqyh0/cover.png"/></item><item><title>Video Token Merging for Long Video Understanding</title><link>https://deep-diver.github.io/neurips2024/posters/wdurabdrbs/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/wdurabdrbs/</guid><description>Researchers boost long-form video understanding efficiency by 6.89x and reduce memory usage by 84% using a novel learnable video token merging algorithm.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/wdurabdrbs/cover.png"/></item><item><title>Visual Fourier Prompt Tuning</title><link>https://deep-diver.github.io/neurips2024/posters/nkhel4n0ju/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/nkhel4n0ju/</guid><description>Visual Fourier Prompt Tuning (VFPT) leverages the Fast Fourier Transform to seamlessly integrate spatial and frequency information for superior parameter-efficient vision model fine-tuning, even with &amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/nkhel4n0ju/cover.png"/></item><item><title>What Variables Affect Out-of-Distribution Generalization in Pretrained Models?</title><link>https://deep-diver.github.io/neurips2024/posters/poxgdfeb7q/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/poxgdfeb7q/</guid><description>High-resolution datasets with diverse classes significantly improve the transferability of pretrained DNNs by reducing representation compression and mitigating the &amp;rsquo;tunnel effect.'</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/poxgdfeb7q/cover.png"/></item></channel></rss>