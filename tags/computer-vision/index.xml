<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Computer Vision on NeurIPS 2024</title><link>https://deep-diver.github.io/neurips2024/tags/computer-vision/</link><description>Recent content in Computer Vision on NeurIPS 2024</description><generator>Hugo -- gohugo.io</generator><language>en</language><copyright>Â© 2024 AI Paper Reviewer</copyright><lastBuildDate>Thu, 26 Sep 2024 00:00:00 +0000</lastBuildDate><atom:link href="https://deep-diver.github.io/neurips2024/tags/computer-vision/index.xml" rel="self" type="application/rss+xml"/><item><title>Bayesian-guided Label Mapping for Visual Reprogramming</title><link>https://deep-diver.github.io/neurips2024/oral/135ekqdorr/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/oral/135ekqdorr/</guid><description>Bayesian-guided Label Mapping (BLM) enhances visual reprogramming!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/oral/135ekqdorr/cover.png"/></item><item><title>CAT3D: Create Anything in 3D with Multi-View Diffusion Models</title><link>https://deep-diver.github.io/neurips2024/oral/tfzlfrl9ks/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/oral/tfzlfrl9ks/</guid><description>CAT3D: Generate high-quality 3D scenes from as little as one image using a novel multi-view diffusion model, outperforming existing methods in speed and quality.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/oral/tfzlfrl9ks/cover.png"/></item><item><title>DenoiseRep: Denoising Model for Representation Learning</title><link>https://deep-diver.github.io/neurips2024/oral/oycu0baus6/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/oral/oycu0baus6/</guid><description>DenoiseRep: A novel denoising model enhances feature discrimination in computer vision tasks by integrating feature extraction and denoising within a single backbone, achieving impressive improvements&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/oral/oycu0baus6/cover.png"/></item><item><title>E2E-MFD: Towards End-to-End Synchronous Multimodal Fusion Detection</title><link>https://deep-diver.github.io/neurips2024/oral/47loymzxep/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/oral/47loymzxep/</guid><description>E2E-MFD: A novel end-to-end multimodal fusion detection algorithm achieves state-of-the-art performance by synchronously optimizing image fusion and object detection.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/oral/47loymzxep/cover.png"/></item><item><title>Flipped Classroom: Aligning Teacher Attention with Student in Generalized Category Discovery</title><link>https://deep-diver.github.io/neurips2024/oral/c4nbtynyqg/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/oral/c4nbtynyqg/</guid><description>FlipClass dynamically updates the teacher model in a teacher-student framework to align with the student&amp;rsquo;s attention, resolving learning inconsistencies and significantly improving generalized categor&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/oral/c4nbtynyqg/cover.png"/></item><item><title>GIC: Gaussian-Informed Continuum for Physical Property Identification and Simulation</title><link>https://deep-diver.github.io/neurips2024/oral/ssctcq2mh2/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/oral/ssctcq2mh2/</guid><description>GIC: Novel hybrid framework leverages 3D Gaussian representation for accurate physical property estimation from visual observations, achieving state-of-the-art performance.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/oral/ssctcq2mh2/cover.png"/></item><item><title>Guiding a Diffusion Model with a Bad Version of Itself</title><link>https://deep-diver.github.io/neurips2024/oral/bg6fvpvs3s/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/oral/bg6fvpvs3s/</guid><description>Boost image quality in diffusion models without reducing variation using Autoguidance: guide a high-quality model with a less-trained version of itself!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/oral/bg6fvpvs3s/cover.png"/></item><item><title>Improved Distribution Matching Distillation for Fast Image Synthesis</title><link>https://deep-diver.github.io/neurips2024/oral/tqukgcdant/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/oral/tqukgcdant/</guid><description>DMD2 dramatically speeds up image generation by cleverly distilling expensive diffusion models, achieving state-of-the-art results without sacrificing quality.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/oral/tqukgcdant/cover.png"/></item><item><title>MeshFormer : High-Quality Mesh Generation with 3D-Guided Reconstruction Model</title><link>https://deep-diver.github.io/neurips2024/oral/x7pjddod6z/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/oral/x7pjddod6z/</guid><description>MeshFormer: High-quality 3D mesh generation from sparse views in seconds, using transformers and 3D convolutions.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/oral/x7pjddod6z/cover.png"/></item><item><title>NeuroClips: Towards High-fidelity and Smooth fMRI-to-Video Reconstruction</title><link>https://deep-diver.github.io/neurips2024/oral/8qu52fl1dt/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/oral/8qu52fl1dt/</guid><description>NeuroClips: groundbreaking fMRI-to-video reconstruction, achieving high-fidelity smooth video up to 6s at 8FPS by decoding both high-level semantics and low-level perception flows.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/oral/8qu52fl1dt/cover.png"/></item><item><title>Return of Unconditional Generation: A Self-supervised Representation Generation Method</title><link>https://deep-diver.github.io/neurips2024/oral/clta4jfbml/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/oral/clta4jfbml/</guid><description>Revolutionizing image generation, Representation-Conditioned Generation (RCG) achieves state-of-the-art results in unconditional image synthesis by leveraging self-supervised representations to condit&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/oral/clta4jfbml/cover.png"/></item><item><title>Stylus: Automatic Adapter Selection for Diffusion Models</title><link>https://deep-diver.github.io/neurips2024/oral/3odq2tgspp/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/oral/3odq2tgspp/</guid><description>Stylus: an automatic adapter selection system for diffusion models, boosts image quality and diversity by intelligently composing task-specific adapters based on prompt keywords.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/oral/3odq2tgspp/cover.png"/></item><item><title>Visual Autoregressive Modeling: Scalable Image Generation via Next-Scale Prediction</title><link>https://deep-diver.github.io/neurips2024/oral/gojl67cfs8/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/oral/gojl67cfs8/</guid><description>Visual Autoregressive Modeling (VAR) revolutionizes image generation by using a coarse-to-fine &amp;rsquo;next-scale prediction&amp;rsquo;, outperforming diffusion models and exhibiting scaling laws similar to LLMs.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/oral/gojl67cfs8/cover.png"/></item></channel></rss>