<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Computer Vision on NeurIPS 2024</title><link>https://deep-diver.github.io/neurips2024/tags/computer-vision/</link><description>Recent content in Computer Vision on NeurIPS 2024</description><generator>Hugo -- gohugo.io</generator><language>en</language><copyright>Â© 2024 AI Paper Reviewer</copyright><lastBuildDate>Thu, 26 Sep 2024 00:00:00 +0000</lastBuildDate><atom:link href="https://deep-diver.github.io/neurips2024/tags/computer-vision/index.xml" rel="self" type="application/rss+xml"/><item><title>3D Gaussian Splatting as Markov Chain Monte Carlo</title><link>https://deep-diver.github.io/neurips2024/spotlight/ucst4gk6ix/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight/ucst4gk6ix/</guid><description>Researchers rethink 3D Gaussian Splatting as MCMC sampling, improving rendering quality and Gaussian control via a novel relocation strategy.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight/ucst4gk6ix/cover.png"/></item><item><title>3DGS-Enhancer: Enhancing Unbounded 3D Gaussian Splatting with View-consistent 2D Diffusion Priors</title><link>https://deep-diver.github.io/neurips2024/spotlight/p4s6fupcbg/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight/p4s6fupcbg/</guid><description>3DGS-Enhancer boosts unbounded 3D Gaussian splatting, generating high-fidelity novel views even with sparse input data using view-consistent 2D diffusion priors.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight/p4s6fupcbg/cover.png"/></item><item><title>A Textbook Remedy for Domain Shifts: Knowledge Priors for Medical Image Analysis</title><link>https://deep-diver.github.io/neurips2024/spotlight/strpbhrvt3/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight/strpbhrvt3/</guid><description>KnoBo enhances deep learning models for medical image analysis by incorporating knowledge priors from medical textbooks, boosting out-of-domain performance by up to 32.4%.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight/strpbhrvt3/cover.png"/></item><item><title>Adaptive Randomized Smoothing: Certified Adversarial Robustness for Multi-Step Defences</title><link>https://deep-diver.github.io/neurips2024/spotlight/mn4nt01teo/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight/mn4nt01teo/</guid><description>Adaptive Randomized Smoothing certifies deep learning model predictions against adversarial attacks by cleverly combining randomized smoothing with adaptive, multi-step input masking for improved accu&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight/mn4nt01teo/cover.png"/></item><item><title>Association of Objects May Engender Stereotypes: Mitigating Association-Engendered Stereotypes in Text-to-Image Generation</title><link>https://deep-diver.github.io/neurips2024/spotlight/shyqxpnblb/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight/shyqxpnblb/</guid><description>New framework, MAS, effectively mitigates stereotypes in text-to-image generation by aligning the probability distribution of generated images to stereotype-free distributions.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight/shyqxpnblb/cover.png"/></item><item><title>Autoregressive Image Generation without Vector Quantization</title><link>https://deep-diver.github.io/neurips2024/spotlight/vnbif0gmkb/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight/vnbif0gmkb/</guid><description>Autoregressive image generation is revolutionized by eliminating vector quantization, achieving strong results with increased speed using a novel diffusion procedure.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight/vnbif0gmkb/cover.png"/></item><item><title>Bayesian-guided Label Mapping for Visual Reprogramming</title><link>https://deep-diver.github.io/neurips2024/oral/135ekqdorr/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/oral/135ekqdorr/</guid><description>Bayesian-guided Label Mapping (BLM) enhances visual reprogramming!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/oral/135ekqdorr/cover.png"/></item><item><title>Bridge the Points: Graph-based Few-shot Segment Anything Semantically</title><link>https://deep-diver.github.io/neurips2024/spotlight/jyyps5vipj/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight/jyyps5vipj/</guid><description>GF-SAM: A novel graph-based few-shot semantic segmentation method leverages SAM&amp;rsquo;s power efficiently via positive-negative prompt alignment and mask clustering for superior accuracy and speed.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight/jyyps5vipj/cover.png"/></item><item><title>CAT3D: Create Anything in 3D with Multi-View Diffusion Models</title><link>https://deep-diver.github.io/neurips2024/oral/tfzlfrl9ks/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/oral/tfzlfrl9ks/</guid><description>CAT3D: Generate high-quality 3D scenes from as little as one image using a novel multi-view diffusion model, outperforming existing methods in speed and quality.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/oral/tfzlfrl9ks/cover.png"/></item><item><title>Context and Geometry Aware Voxel Transformer for Semantic Scene Completion</title><link>https://deep-diver.github.io/neurips2024/spotlight/9bu627mtfs/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight/9bu627mtfs/</guid><description>CGFormer: a novel voxel transformer boosting semantic scene completion accuracy by using context-aware queries and 3D deformable attention, outperforming existing methods on SemanticKITTI and SSCBench&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight/9bu627mtfs/cover.png"/></item><item><title>DenoiseRep: Denoising Model for Representation Learning</title><link>https://deep-diver.github.io/neurips2024/oral/oycu0baus6/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/oral/oycu0baus6/</guid><description>DenoiseRep: A novel denoising model enhances feature discrimination in computer vision tasks by integrating feature extraction and denoising within a single backbone, achieving impressive improvements&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/oral/oycu0baus6/cover.png"/></item><item><title>DeSparsify: Adversarial Attack Against Token Sparsification Mechanisms</title><link>https://deep-diver.github.io/neurips2024/spotlight/d4yrz3s7ul/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight/d4yrz3s7ul/</guid><description>DeSparsify: A stealthy adversarial attack exhausts vision transformer resources by exploiting token sparsification mechanisms&amp;rsquo; dynamic nature, highlighting the need for improved resource management i&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight/d4yrz3s7ul/cover.png"/></item><item><title>Differentiable Task Graph Learning: Procedural Activity Representation and Online Mistake Detection from Egocentric Videos</title><link>https://deep-diver.github.io/neurips2024/spotlight/2hvgvb4awq/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight/2hvgvb4awq/</guid><description>This paper introduces a novel differentiable framework for learning task graphs from video demonstrations of procedural activities. By directly optimizing the weights of a task graph&amp;rsquo;s edges, the mod&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight/2hvgvb4awq/cover.png"/></item><item><title>DiffSF: Diffusion Models for Scene Flow Estimation</title><link>https://deep-diver.github.io/neurips2024/spotlight/nieufguq9x/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight/nieufguq9x/</guid><description>DiffSF boosts scene flow estimation accuracy and reliability by cleverly combining transformer networks with denoising diffusion models, offering state-of-the-art results and uncertainty quantificatio&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight/nieufguq9x/cover.png"/></item><item><title>Diffusion Priors for Variational Likelihood Estimation and Image Denoising</title><link>https://deep-diver.github.io/neurips2024/spotlight/oukw8cuiuy/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight/oukw8cuiuy/</guid><description>Adaptive likelihood estimation and MAP inference during reverse diffusion tackles real-world image noise.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight/oukw8cuiuy/cover.png"/></item><item><title>Dissecting Query-Key Interaction in Vision Transformers</title><link>https://deep-diver.github.io/neurips2024/spotlight/diktpsgk4f/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight/diktpsgk4f/</guid><description>Vision transformers&amp;rsquo; self-attention mechanism is dissected revealing how early layers focus on similar features for perceptual grouping while later layers integrate dissimilar features for contextuali&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight/diktpsgk4f/cover.png"/></item><item><title>Diversity-Driven Synthesis: Enhancing Dataset Distillation through Directed Weight Adjustment</title><link>https://deep-diver.github.io/neurips2024/spotlight/uwsadhllyc/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight/uwsadhllyc/</guid><description>Boosting dataset distillation, a new method, Diversity-Driven Synthesis, uses directed weight adjustment to create diverse, representative synthetic datasets, improving model performance while reducin&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight/uwsadhllyc/cover.png"/></item><item><title>Don't Look Twice: Faster Video Transformers with Run-Length Tokenization</title><link>https://deep-diver.github.io/neurips2024/spotlight/b1ggjw00ni/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight/b1ggjw00ni/</guid><description>Run-Length Tokenization (RLT) dramatically speeds up video transformer training and inference by efficiently removing redundant video tokens, matching baseline model performance with significant time &amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight/b1ggjw00ni/cover.png"/></item><item><title>Dynamic 3D Gaussian Fields for Urban Areas</title><link>https://deep-diver.github.io/neurips2024/spotlight/xzxxnhndxu/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight/xzxxnhndxu/</guid><description>4DGF, a novel neural scene representation, achieves interactive-speed novel view synthesis for large-scale dynamic urban areas by efficiently combining 3D Gaussians and neural fields.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight/xzxxnhndxu/cover.png"/></item><item><title>E2E-MFD: Towards End-to-End Synchronous Multimodal Fusion Detection</title><link>https://deep-diver.github.io/neurips2024/oral/47loymzxep/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/oral/47loymzxep/</guid><description>E2E-MFD: A novel end-to-end multimodal fusion detection algorithm achieves state-of-the-art performance by synchronously optimizing image fusion and object detection.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/oral/47loymzxep/cover.png"/></item><item><title>EMR-Merging: Tuning-Free High-Performance Model Merging</title><link>https://deep-diver.github.io/neurips2024/spotlight/lydjzx3dyu/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight/lydjzx3dyu/</guid><description>EMR-MERGING: A tuning-free model merging technique achieves high performance by electing a unified model and generating lightweight task-specific modulators, eliminating the need for additional data &amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight/lydjzx3dyu/cover.png"/></item><item><title>Flipped Classroom: Aligning Teacher Attention with Student in Generalized Category Discovery</title><link>https://deep-diver.github.io/neurips2024/oral/c4nbtynyqg/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/oral/c4nbtynyqg/</guid><description>FlipClass dynamically updates the teacher model in a teacher-student framework to align with the student&amp;rsquo;s attention, resolving learning inconsistencies and significantly improving generalized categor&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/oral/c4nbtynyqg/cover.png"/></item><item><title>FuseAnyPart: Diffusion-Driven Facial Parts Swapping via Multiple Reference Images</title><link>https://deep-diver.github.io/neurips2024/spotlight/x2umdvcmmo/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight/x2umdvcmmo/</guid><description>FuseAnyPart: Swap facial parts seamlessly using multiple reference images via diffusion, achieving high-fidelity results.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight/x2umdvcmmo/cover.png"/></item><item><title>GIC: Gaussian-Informed Continuum for Physical Property Identification and Simulation</title><link>https://deep-diver.github.io/neurips2024/oral/ssctcq2mh2/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/oral/ssctcq2mh2/</guid><description>GIC: Novel hybrid framework leverages 3D Gaussian representation for accurate physical property estimation from visual observations, achieving state-of-the-art performance.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/oral/ssctcq2mh2/cover.png"/></item><item><title>Guiding a Diffusion Model with a Bad Version of Itself</title><link>https://deep-diver.github.io/neurips2024/oral/bg6fvpvs3s/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/oral/bg6fvpvs3s/</guid><description>Boost image quality in diffusion models without reducing variation using Autoguidance: guide a high-quality model with a less-trained version of itself!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/oral/bg6fvpvs3s/cover.png"/></item><item><title>Improved Distribution Matching Distillation for Fast Image Synthesis</title><link>https://deep-diver.github.io/neurips2024/oral/tqukgcdant/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/oral/tqukgcdant/</guid><description>DMD2 dramatically speeds up image generation by cleverly distilling expensive diffusion models, achieving state-of-the-art results without sacrificing quality.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/oral/tqukgcdant/cover.png"/></item><item><title>Improving robustness to corruptions with multiplicative weight perturbations</title><link>https://deep-diver.github.io/neurips2024/spotlight/m8dy0zusb1/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight/m8dy0zusb1/</guid><description>Boost DNN robustness to corruptions without sacrificing clean image accuracy using Data Augmentation via Multiplicative Perturbations (DAMP)!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight/m8dy0zusb1/cover.png"/></item><item><title>Interpret Your Decision: Logical Reasoning Regularization for Generalization in Visual Classification</title><link>https://deep-diver.github.io/neurips2024/spotlight/woiqqi5byv/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight/woiqqi5byv/</guid><description>This paper introduces L-Reg, a novel logical regularization technique, to improve generalization in visual classification. L-Reg effectively reduces model complexity and improves interpretability by f&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight/woiqqi5byv/cover.png"/></item><item><title>Latent Intrinsics Emerge from Training to Relight</title><link>https://deep-diver.github.io/neurips2024/spotlight/ltndg0ezf9/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight/ltndg0ezf9/</guid><description>A novel data-driven relighting model achieves state-of-the-art accuracy by learning latent intrinsic and extrinsic scene properties, even recovering albedo without explicit supervision.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight/ltndg0ezf9/cover.png"/></item><item><title>Learning Segmentation from Point Trajectories</title><link>https://deep-diver.github.io/neurips2024/spotlight/vt2qke1oax/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight/vt2qke1oax/</guid><description>This paper introduces a novel unsupervised video object segmentation method using long-term point trajectories and optical flow, outperforming prior art by effectively combining sparse, long-term moti&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight/vt2qke1oax/cover.png"/></item><item><title>LightGaussian: Unbounded 3D Gaussian Compression with 15x Reduction and 200+ FPS</title><link>https://deep-diver.github.io/neurips2024/spotlight/6aeidnrtn2/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight/6aeidnrtn2/</guid><description>LightGaussian achieves 15x compression of 3D Gaussian scene representations, boosting rendering speed to 200+ FPS while maintaining visual quality, solving storage and efficiency issues in real-time n&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight/6aeidnrtn2/cover.png"/></item><item><title>MambaTree: Tree Topology is All You Need in State Space Model</title><link>https://deep-diver.github.io/neurips2024/spotlight/w8rfsakr4m/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight/w8rfsakr4m/</guid><description>MambaTree: A novel tree-topology-based state space model surpasses existing methods by dynamically generating input-aware topologies for enhanced long-range dependencies in vision and language.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight/w8rfsakr4m/cover.png"/></item><item><title>MECD: Unlocking Multi-Event Causal Discovery in Video Reasoning</title><link>https://deep-diver.github.io/neurips2024/spotlight/f8asoovlep/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight/f8asoovlep/</guid><description>MECD: A new task and dataset unlocks multi-event causal discovery in videos, enabling a novel framework that outperforms existing models by efficiently identifying causal relationships between chronol&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight/f8asoovlep/cover.png"/></item><item><title>Memorize What Matters: Emergent Scene Decomposition from Multitraverse</title><link>https://deep-diver.github.io/neurips2024/spotlight/6qr3932rwe/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight/6qr3932rwe/</guid><description>3D Gaussian Mapping (3DGM) achieves self-supervised camera-only 3D scene decomposition by leveraging multi-traverse driving data, memorizing permanent structures while filtering out transient objects.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight/6qr3932rwe/cover.png"/></item><item><title>MeshFormer : High-Quality Mesh Generation with 3D-Guided Reconstruction Model</title><link>https://deep-diver.github.io/neurips2024/oral/x7pjddod6z/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/oral/x7pjddod6z/</guid><description>MeshFormer: High-quality 3D mesh generation from sparse views in seconds, using transformers and 3D convolutions.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/oral/x7pjddod6z/cover.png"/></item><item><title>Moving Off-the-Grid: Scene-Grounded Video Representations</title><link>https://deep-diver.github.io/neurips2024/spotlight/rjspdvduaw/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight/rjspdvduaw/</guid><description>MooG: Self-supervised video model learns off-the-grid representations, enabling consistent scene element tracking even with motion; outperforming grid-based baselines on various vision tasks.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight/rjspdvduaw/cover.png"/></item><item><title>Multistable Shape from Shading Emerges from Patch Diffusion</title><link>https://deep-diver.github.io/neurips2024/spotlight/bhsfbjs6j9/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight/bhsfbjs6j9/</guid><description>A novel diffusion model reconstructs multimodal shape distributions from shading, mirroring human multistable perception.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight/bhsfbjs6j9/cover.png"/></item><item><title>Neural Assets: 3D-Aware Multi-Object Scene Synthesis with Image Diffusion Models</title><link>https://deep-diver.github.io/neurips2024/spotlight/ednslswqij/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight/ednslswqij/</guid><description>Neural Assets enables intuitive 3D multi-object scene editing via image diffusion models by using per-object representations to control individual object poses, achieving state-of-the-art results.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight/ednslswqij/cover.png"/></item><item><title>NeuroClips: Towards High-fidelity and Smooth fMRI-to-Video Reconstruction</title><link>https://deep-diver.github.io/neurips2024/oral/8qu52fl1dt/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/oral/8qu52fl1dt/</guid><description>NeuroClips: groundbreaking fMRI-to-video reconstruction, achieving high-fidelity smooth video up to 6s at 8FPS by decoding both high-level semantics and low-level perception flows.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/oral/8qu52fl1dt/cover.png"/></item><item><title>Not All Diffusion Model Activations Have Been Evaluated as Discriminative Features</title><link>https://deep-diver.github.io/neurips2024/spotlight/7uqvfzw6mo/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight/7uqvfzw6mo/</guid><description>Unlocking superior discriminative features from diffusion models, this research reveals key activation properties for effective feature selection, surpassing state-of-the-art methods.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight/7uqvfzw6mo/cover.png"/></item><item><title>On the Use of Anchoring for Training Vision Models</title><link>https://deep-diver.github.io/neurips2024/spotlight/xymhwyizop/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight/xymhwyizop/</guid><description>Boosting vision model training: A new anchored training protocol with a simple regularizer significantly enhances generalization and safety, surpassing standard methods.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight/xymhwyizop/cover.png"/></item><item><title>Parallel Backpropagation for Shared-Feature Visualization</title><link>https://deep-diver.github.io/neurips2024/spotlight/oqzcsb6fbl/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight/oqzcsb6fbl/</guid><description>Researchers visualized shared visual features driving responses of body-selective neurons to non-body objects, revealing object parts resembling macaque body parts, thus explaining neural preferences.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight/oqzcsb6fbl/cover.png"/></item><item><title>Parameter-Inverted Image Pyramid Networks</title><link>https://deep-diver.github.io/neurips2024/spotlight/nkzlqrgg45/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight/nkzlqrgg45/</guid><description>Parameter-Inverted Image Pyramid Networks (PIIP) boost image pyramid efficiency by using smaller models for higher-resolution images and larger models for lower-resolution ones, achieving superior per&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight/nkzlqrgg45/cover.png"/></item><item><title>PCP-MAE: Learning to Predict Centers for Point Masked Autoencoders</title><link>https://deep-diver.github.io/neurips2024/spotlight/i1xjk5a0x8/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight/i1xjk5a0x8/</guid><description>PCP-MAE enhances point cloud self-supervised learning by cleverly predicting masked patch centers, leading to superior 3D object classification and scene segmentation.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight/i1xjk5a0x8/cover.png"/></item><item><title>Physically Compatible 3D Object Modeling from a Single Image</title><link>https://deep-diver.github.io/neurips2024/spotlight/k29iv0xrbf/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight/k29iv0xrbf/</guid><description>Single image to physically compatible 3D objects: A new framework ensures 3D models maintain stability and mirror real-world equilibrium states, advancing realism in dynamic simulations and 3D printi&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight/k29iv0xrbf/cover.png"/></item><item><title>Provable Benefit of Cutout and CutMix for Feature Learning</title><link>https://deep-diver.github.io/neurips2024/spotlight/8on9diuh5v/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight/8on9diuh5v/</guid><description>CutMix and Cutout data augmentation methods provably improve feature learning by enabling the network to learn rarer features and noise vectors more effectively.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight/8on9diuh5v/cover.png"/></item><item><title>QKFormer: Hierarchical Spiking Transformer using Q-K Attention</title><link>https://deep-diver.github.io/neurips2024/spotlight/avd7dpiooc/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight/avd7dpiooc/</guid><description>QKFormer: A groundbreaking spiking transformer achieving 85.65% ImageNet accuracy using a linear-complexity, energy-efficient Q-K attention mechanism.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight/avd7dpiooc/cover.png"/></item><item><title>Real-world Image Dehazing with Coherence-based Pseudo Labeling and Cooperative Unfolding Network</title><link>https://deep-diver.github.io/neurips2024/spotlight/i6tbncje2f/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight/i6tbncje2f/</guid><description>CORUN-Colabator: a novel cooperative unfolding network and coherence-based label generator achieves state-of-the-art real-world image dehazing by effectively integrating physical knowledge and generat&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight/i6tbncje2f/cover.png"/></item><item><title>Recurrent neural network dynamical systems for biological vision</title><link>https://deep-diver.github.io/neurips2024/spotlight/zz94albmok/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight/zz94albmok/</guid><description>CordsNet: a hybrid CNN-RNN architecture enabling biologically realistic, robust image recognition through continuous-time recurrent dynamics.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight/zz94albmok/cover.png"/></item><item><title>ResAD: A Simple Framework for Class Generalizable Anomaly Detection</title><link>https://deep-diver.github.io/neurips2024/spotlight/znijzualxg/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight/znijzualxg/</guid><description>ResAD, a novel framework, tackles class-generalizable anomaly detection by learning residual feature distributions, achieving remarkable results on diverse datasets without retraining.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight/znijzualxg/cover.png"/></item><item><title>Rethinking 3D Convolution in $ll_p$-norm Space</title><link>https://deep-diver.github.io/neurips2024/spotlight/kmxdv4blhn/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight/kmxdv4blhn/</guid><description>L1-norm based 3D convolution achieves competitive performance with lower energy consumption and latency compared to traditional methods, as proven through universal approximation theorem and experimen&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight/kmxdv4blhn/cover.png"/></item><item><title>Return of Unconditional Generation: A Self-supervised Representation Generation Method</title><link>https://deep-diver.github.io/neurips2024/oral/clta4jfbml/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/oral/clta4jfbml/</guid><description>Revolutionizing image generation, Representation-Conditioned Generation (RCG) achieves state-of-the-art results in unconditional image synthesis by leveraging self-supervised representations to condit&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/oral/clta4jfbml/cover.png"/></item><item><title>SA3DIP: Segment Any 3D Instance with Potential 3D Priors</title><link>https://deep-diver.github.io/neurips2024/spotlight/3ui4cer4iz/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight/3ui4cer4iz/</guid><description>SA3DIP boosts 3D instance segmentation accuracy by cleverly using 3D spatial and textural cues alongside 2D multi-view masks, overcoming limitations of previous methods.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight/3ui4cer4iz/cover.png"/></item><item><title>Saliency-driven Experience Replay for Continual Learning</title><link>https://deep-diver.github.io/neurips2024/spotlight/8kkbxzn0km/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight/8kkbxzn0km/</guid><description>Boosting AI&amp;rsquo;s continual learning via saliency-driven experience replay, achieving up to 20% accuracy improvement.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight/8kkbxzn0km/cover.png"/></item><item><title>SARDet-100K: Towards Open-Source Benchmark and ToolKit for Large-Scale SAR Object Detection</title><link>https://deep-diver.github.io/neurips2024/spotlight/abuqmkdvkw/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight/abuqmkdvkw/</guid><description>SARDet-100K: A new benchmark dataset and open-source toolkit revolutionizes large-scale SAR object detection.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight/abuqmkdvkw/cover.png"/></item><item><title>Scene Graph Disentanglement and Composition for Generalizable Complex Image Generation</title><link>https://deep-diver.github.io/neurips2024/spotlight/zgn0ywy2he/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight/zgn0ywy2he/</guid><description>DisCo: a novel framework for generalizable complex image generation using scene graph disentanglement and composition, achieving superior performance over existing methods.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight/zgn0ywy2he/cover.png"/></item><item><title>SegVol: Universal and Interactive Volumetric Medical Image Segmentation</title><link>https://deep-diver.github.io/neurips2024/spotlight/105zuvpdyw/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight/105zuvpdyw/</guid><description>SegVol: A universal, interactive 3D medical image segmentation model achieving state-of-the-art performance across diverse anatomical categories.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight/105zuvpdyw/cover.png"/></item><item><title>Slight Corruption in Pre-training Data Makes Better Diffusion Models</title><link>https://deep-diver.github.io/neurips2024/spotlight/vfpxybqmsu/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight/vfpxybqmsu/</guid><description>Slightly corrupting pre-training data significantly improves diffusion models&amp;rsquo; image generation quality, diversity, and fidelity.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight/vfpxybqmsu/cover.png"/></item><item><title>SpikeReveal: Unlocking Temporal Sequences from Real Blurry Inputs with Spike Streams</title><link>https://deep-diver.github.io/neurips2024/spotlight/9fyat8hppv/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight/9fyat8hppv/</guid><description>SpikeReveal: Self-supervised learning unlocks sharp video sequences from blurry, real-world spike camera data, overcoming limitations of prior supervised approaches.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight/9fyat8hppv/cover.png"/></item><item><title>StoryDiffusion: Consistent Self-Attention for Long-Range Image and Video Generation</title><link>https://deep-diver.github.io/neurips2024/spotlight/vfqzxhinfu/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight/vfqzxhinfu/</guid><description>StoryDiffusion enhances long-range image &amp;amp; video generation by introducing a simple yet effective self-attention mechanism and a semantic motion predictor, achieving high content consistency without t&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight/vfqzxhinfu/cover.png"/></item><item><title>Stylus: Automatic Adapter Selection for Diffusion Models</title><link>https://deep-diver.github.io/neurips2024/oral/3odq2tgspp/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/oral/3odq2tgspp/</guid><description>Stylus: an automatic adapter selection system for diffusion models, boosts image quality and diversity by intelligently composing task-specific adapters based on prompt keywords.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/oral/3odq2tgspp/cover.png"/></item><item><title>Tetrahedron Splatting for 3D Generation</title><link>https://deep-diver.github.io/neurips2024/spotlight/qvsp1uk7b5/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight/qvsp1uk7b5/</guid><description>TeT-Splatting: a novel 3D representation enabling fast convergence, real-time rendering, and precise mesh extraction for high-fidelity 3D generation.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight/qvsp1uk7b5/cover.png"/></item><item><title>TextCtrl: Diffusion-based Scene Text Editing with Prior Guidance Control</title><link>https://deep-diver.github.io/neurips2024/spotlight/sqvns9hwjt/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight/sqvns9hwjt/</guid><description>TextCtrl: a novel diffusion-based scene text editing method using prior guidance control, achieving superior style fidelity and accuracy with a new real-world benchmark dataset, ScenePair.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight/sqvns9hwjt/cover.png"/></item><item><title>TrackIME: Enhanced Video Point Tracking via Instance Motion Estimation</title><link>https://deep-diver.github.io/neurips2024/spotlight/ekhqbgvl3g/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight/ekhqbgvl3g/</guid><description>TrackIME enhances video point tracking by cleverly pruning the search space, resulting in improved accuracy and efficiency.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight/ekhqbgvl3g/cover.png"/></item><item><title>Unified Gradient-Based Machine Unlearning with Remain Geometry Enhancement</title><link>https://deep-diver.github.io/neurips2024/spotlight/dhedf5epbt/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight/dhedf5epbt/</guid><description>Enhance deep neural network privacy and trustworthiness with unified gradient-based machine unlearning, leveraging remain geometry for efficient forgetting and performance preservation.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight/dhedf5epbt/cover.png"/></item><item><title>Visual Autoregressive Modeling: Scalable Image Generation via Next-Scale Prediction</title><link>https://deep-diver.github.io/neurips2024/oral/gojl67cfs8/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/oral/gojl67cfs8/</guid><description>Visual Autoregressive Modeling (VAR) revolutionizes image generation by using a coarse-to-fine &amp;rsquo;next-scale prediction&amp;rsquo;, outperforming diffusion models and exhibiting scaling laws similar to LLMs.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/oral/gojl67cfs8/cover.png"/></item><item><title>VMamba: Visual State Space Model</title><link>https://deep-diver.github.io/neurips2024/spotlight/zgtlqqr1k7/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight/zgtlqqr1k7/</guid><description>VMamba: a vision backbone achieving linear time complexity using Visual State Space (VSS) blocks and 2D Selective Scan (SS2D) for efficient visual representation.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight/zgtlqqr1k7/cover.png"/></item><item><title>Voxel Mamba: Group-Free State Space Models for Point Cloud based 3D Object Detection</title><link>https://deep-diver.github.io/neurips2024/spotlight/ghyhvsctdh/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight/ghyhvsctdh/</guid><description>Voxel Mamba: a group-free 3D object detection method using state space models, achieving higher accuracy and efficiency by overcoming limitations of serialization-based Transformers.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight/ghyhvsctdh/cover.png"/></item><item><title>X-Ray: A Sequential 3D Representation For Generation</title><link>https://deep-diver.github.io/neurips2024/spotlight/36tmv15dpo/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight/36tmv15dpo/</guid><description>X-Ray: A novel 3D representation generating complete object surfaces from a single image!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight/36tmv15dpo/cover.png"/></item></channel></rss>