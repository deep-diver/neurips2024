<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>üè¢ Tsinghua University on NeurIPS 2024</title><link>https://deep-diver.github.io/neurips2024/tags/-tsinghua-university/</link><description>Recent content in üè¢ Tsinghua University on NeurIPS 2024</description><generator>Hugo -- gohugo.io</generator><language>en</language><copyright>¬© 2024 AI Paper Reviewer</copyright><lastBuildDate>Thu, 26 Sep 2024 00:00:00 +0000</lastBuildDate><atom:link href="https://deep-diver.github.io/neurips2024/tags/-tsinghua-university/index.xml" rel="self" type="application/rss+xml"/><item><title>Co-occurrence is not Factual Association in Language Models</title><link>https://deep-diver.github.io/neurips2024/spotlight-large-language-models/xabstwautr/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-large-language-models/xabstwautr/</guid><description>Language models struggle to learn facts; this study reveals they prioritize word co-occurrence over true factual associations, proposing new training strategies for improved factual knowledge generali&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-large-language-models/xabstwautr/cover.png"/></item><item><title>CooHOI: Learning Cooperative Human-Object Interaction with Manipulated Object Dynamics</title><link>https://deep-diver.github.io/neurips2024/spotlight-others/iyzytmd3jd/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-others/iyzytmd3jd/</guid><description>CooHOI: A two-phase learning framework enables physically simulated characters to perform cooperative object transportation tasks naturally and efficiently, overcoming the limitations of existing meth&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-others/iyzytmd3jd/cover.png"/></item><item><title>DuQuant: Distributing Outliers via Dual Transformation Makes Stronger Quantized LLMs</title><link>https://deep-diver.github.io/neurips2024/oral-large-language-models/mp8u2pcmqz/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/oral-large-language-models/mp8u2pcmqz/</guid><description>DuQuant: Dual transformations distribute outliers for stronger quantized LLMs.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/oral-large-language-models/mp8u2pcmqz/cover.png"/></item><item><title>GenArtist: Multimodal LLM as an Agent for Unified Image Generation and Editing</title><link>https://deep-diver.github.io/neurips2024/spotlight-others/ur00bnk1v2/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-others/ur00bnk1v2/</guid><description>GenArtist uses a multimodal large language model as an AI agent to unify image generation and editing, achieving state-of-the-art performance by decomposing complex tasks and leveraging a comprehensiv&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-others/ur00bnk1v2/cover.png"/></item><item><title>Not All Tokens Are What You Need for Pretraining</title><link>https://deep-diver.github.io/neurips2024/oral-large-language-models/0nmzbwqaaj/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/oral-large-language-models/0nmzbwqaaj/</guid><description>RHO-1, a novel language model, uses selective pretraining focusing on high-value tokens, achieving state-of-the-art results with significantly less data than existing models.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/oral-large-language-models/0nmzbwqaaj/cover.png"/></item><item><title>Parameter-Inverted Image Pyramid Networks</title><link>https://deep-diver.github.io/neurips2024/spotlight-others/nkzlqrgg45/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-others/nkzlqrgg45/</guid><description>Parameter-Inverted Image Pyramid Networks (PIIP) boost image pyramid efficiency by using smaller models for higher-resolution images and larger models for lower-resolution ones, achieving superior per&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-others/nkzlqrgg45/cover.png"/></item><item><title>Real-world Image Dehazing with Coherence-based Pseudo Labeling and Cooperative Unfolding Network</title><link>https://deep-diver.github.io/neurips2024/spotlight-others/i6tbncje2f/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-others/i6tbncje2f/</guid><description>CORUN-Colabator: a novel cooperative unfolding network and coherence-based label generator achieves state-of-the-art real-world image dehazing by effectively integrating physical knowledge and generat&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-others/i6tbncje2f/cover.png"/></item><item><title>Skinned Motion Retargeting with Dense Geometric Interaction Perception</title><link>https://deep-diver.github.io/neurips2024/spotlight-others/v1bim8wesl/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-others/v1bim8wesl/</guid><description>MeshRet: A novel retargeting framework that uses dense geometric interaction modeling for realistic, artifact-free skinned character animation.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-others/v1bim8wesl/cover.png"/></item><item><title>Training Compute-Optimal Protein Language Models</title><link>https://deep-diver.github.io/neurips2024/spotlight-large-language-models/uczi8gsfd4/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-large-language-models/uczi8gsfd4/</guid><description>Compute-optimal protein language models are trained efficiently using scaling laws derived from a massive dataset, improving performance while optimizing compute budgets.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-large-language-models/uczi8gsfd4/cover.png"/></item><item><title>You Only Cache Once: Decoder-Decoder Architectures for Language Models</title><link>https://deep-diver.github.io/neurips2024/oral-large-language-models/25ioxw576r/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/oral-large-language-models/25ioxw576r/</guid><description>YOCO: A decoder-decoder architecture for LLMs dramatically reduces memory usage and improves inference speed by caching key-value pairs only once.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/oral-large-language-models/25ioxw576r/cover.png"/></item></channel></rss>