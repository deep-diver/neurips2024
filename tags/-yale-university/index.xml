<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>üè¢ Yale University on NeurIPS 2024</title><link>https://deep-diver.github.io/neurips2024/tags/-yale-university/</link><description>Recent content in üè¢ Yale University on NeurIPS 2024</description><generator>Hugo -- gohugo.io</generator><language>en</language><copyright>¬© 2024 AI Paper Reviewer</copyright><lastBuildDate>Thu, 26 Sep 2024 00:00:00 +0000</lastBuildDate><atom:link href="https://deep-diver.github.io/neurips2024/tags/-yale-university/index.xml" rel="self" type="application/rss+xml"/><item><title>Inference of Neural Dynamics Using Switching Recurrent Neural Networks</title><link>https://deep-diver.github.io/neurips2024/posters/zb8jlah2vn/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/zb8jlah2vn/</guid><description>SRNNs reveal behaviorally-relevant neural dynamics switches!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/zb8jlah2vn/cover.png"/></item><item><title>Injecting Undetectable Backdoors in Obfuscated Neural Networks and Language Models</title><link>https://deep-diver.github.io/neurips2024/posters/kyvbzkcono/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/kyvbzkcono/</guid><description>Researchers developed a novel method to inject undetectable backdoors into obfuscated neural networks and language models, even with white-box access, posing significant security risks.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/kyvbzkcono/cover.png"/></item><item><title>Nonlinear dynamics of localization in neural receptive fields</title><link>https://deep-diver.github.io/neurips2024/spotlight-others/nw9jmfl99s/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-others/nw9jmfl99s/</guid><description>Neural receptive fields&amp;rsquo; localization emerges from nonlinear learning dynamics driven by naturalistic data&amp;rsquo;s higher-order statistics, not just sparsity.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-others/nw9jmfl99s/cover.png"/></item><item><title>On the Role of Information Structure in Reinforcement Learning for Partially-Observable Sequential Teams and Games</title><link>https://deep-diver.github.io/neurips2024/posters/qgmc8ftbnd/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/qgmc8ftbnd/</guid><description>New reinforcement learning model clarifies the role of information structure in partially-observable sequential decision-making problems, proving an upper bound on learning complexity.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/qgmc8ftbnd/cover.png"/></item><item><title>Provable Partially Observable Reinforcement Learning with Privileged Information</title><link>https://deep-diver.github.io/neurips2024/posters/o3i1jefzkw/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/o3i1jefzkw/</guid><description>This paper provides the first provable efficiency guarantees for practically-used RL algorithms leveraging privileged information, addressing limitations of previous empirical paradigms and opening ne&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/o3i1jefzkw/cover.png"/></item><item><title>RSA: Resolving Scale Ambiguities in Monocular Depth Estimators through Language Descriptions</title><link>https://deep-diver.github.io/neurips2024/posters/vh7gcadhao/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/vh7gcadhao/</guid><description>RSA: Language unlocks metric depth from single images!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/vh7gcadhao/cover.png"/></item><item><title>Solving Inverse Problems via Diffusion Optimal Control</title><link>https://deep-diver.github.io/neurips2024/posters/wqlc4g1gn3/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/wqlc4g1gn3/</guid><description>Revolutionizing inverse problem solving, this paper introduces diffusion optimal control, a novel framework converting signal recovery into a discrete optimal control problem, surpassing limitations o&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/wqlc4g1gn3/cover.png"/></item><item><title>Transformation-Invariant Learning and Theoretical Guarantees for OOD Generalization</title><link>https://deep-diver.github.io/neurips2024/posters/u2gzfxrlan/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/u2gzfxrlan/</guid><description>This paper introduces a novel theoretical framework for robust machine learning under distribution shifts, offering learning rules and guarantees, highlighting the game-theoretic viewpoint of distribu&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/u2gzfxrlan/cover.png"/></item><item><title>Tree of Attacks: Jailbreaking Black-Box LLMs Automatically</title><link>https://deep-diver.github.io/neurips2024/posters/som3vngoh5/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/som3vngoh5/</guid><description>TAP: automated jailbreaking of black-box LLMs with high success rates, using fewer queries than previous methods.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/som3vngoh5/cover.png"/></item><item><title>Unveiling Induction Heads: Provable Training Dynamics and Feature Learning in Transformers</title><link>https://deep-diver.github.io/neurips2024/posters/4fn2res0ma/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/4fn2res0ma/</guid><description>Transformers learn complex tasks surprisingly well through in-context learning, but the mechanism remains unclear. This paper proves that a two-layer transformer trained on n-gram Markov chain data co&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/4fn2res0ma/cover.png"/></item></channel></rss>