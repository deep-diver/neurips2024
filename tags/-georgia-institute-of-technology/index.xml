<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>üè¢ Georgia Institute of Technology on NeurIPS 2024</title><link>https://deep-diver.github.io/neurips2024/tags/-georgia-institute-of-technology/</link><description>Recent content in üè¢ Georgia Institute of Technology on NeurIPS 2024</description><generator>Hugo -- gohugo.io</generator><language>en</language><copyright>¬© 2024 AI Paper Reviewer</copyright><lastBuildDate>Thu, 26 Sep 2024 00:00:00 +0000</lastBuildDate><atom:link href="https://deep-diver.github.io/neurips2024/tags/-georgia-institute-of-technology/index.xml" rel="self" type="application/rss+xml"/><item><title>3D Gaussian Rendering Can Be Sparser: Efficient Rendering via Learned Fragment Pruning</title><link>https://deep-diver.github.io/neurips2024/posters/ivqzbulfol/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/ivqzbulfol/</guid><description>Learned fragment pruning accelerates 3D Gaussian splatting rendering by selectively removing fragments, achieving up to 1.71x speedup on edge GPUs and 0.16 PSNR improvement.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/ivqzbulfol/cover.png"/></item><item><title>A Separation in Heavy-Tailed Sampling: Gaussian vs. Stable Oracles for Proximal Samplers</title><link>https://deep-diver.github.io/neurips2024/posters/zuwlghgxtq/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/zuwlghgxtq/</guid><description>Stable oracles outperform Gaussian oracles in high-accuracy heavy-tailed sampling, overcoming limitations of Gaussian-based proximal samplers.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/zuwlghgxtq/cover.png"/></item><item><title>Derivative-enhanced Deep Operator Network</title><link>https://deep-diver.github.io/neurips2024/posters/waiqlgfqx6/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/waiqlgfqx6/</guid><description>Derivative-enhanced DeepONets boost PDE solution accuracy and derivative approximation, particularly valuable with limited training data.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/waiqlgfqx6/cover.png"/></item><item><title>Differentially Private Graph Diffusion with Applications in Personalized PageRanks</title><link>https://deep-diver.github.io/neurips2024/posters/aon7bwybiq/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/aon7bwybiq/</guid><description>This paper introduces a novel differentially private graph diffusion framework ensuring edge-level privacy, significantly improving utility-privacy trade-offs for personalized PageRank computation.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/aon7bwybiq/cover.png"/></item><item><title>Langevin Unlearning: A New Perspective of Noisy Gradient Descent for Machine Unlearning</title><link>https://deep-diver.github.io/neurips2024/spotlight-ai-theory/3lkuc8rbyv/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-ai-theory/3lkuc8rbyv/</guid><description>Langevin unlearning offers a novel, privacy-preserving machine unlearning framework based on noisy gradient descent, handling both convex and non-convex problems efficiently.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-ai-theory/3lkuc8rbyv/cover.png"/></item><item><title>Large Pre-trained time series models for cross-domain Time series analysis tasks</title><link>https://deep-diver.github.io/neurips2024/posters/vmmzjcr5zj/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/vmmzjcr5zj/</guid><description>Large Pre-trained Time-series Models (LPTM) achieves superior forecasting and time-series classification results using a novel adaptive segmentation method, requiring up to 40% less data and 50% less &amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/vmmzjcr5zj/cover.png"/></item><item><title>Learning Spatially-Aware Language and Audio Embeddings</title><link>https://deep-diver.github.io/neurips2024/posters/wddvjzvvbr/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/wddvjzvvbr/</guid><description>ELSA: a new model that learns spatially aware language and audio embeddings, achieving state-of-the-art performance in semantic retrieval and 3D sound source localization.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/wddvjzvvbr/cover.png"/></item><item><title>Lisa: Lazy Safety Alignment for Large Language Models against Harmful Fine-tuning Attack</title><link>https://deep-diver.github.io/neurips2024/posters/rpchapuxlc/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/rpchapuxlc/</guid><description>Lisa: a novel lazy safety alignment method safeguards LLMs against harmful fine-tuning attacks by introducing a proximal term to constrain model drift, significantly improving alignment performance.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/rpchapuxlc/cover.png"/></item><item><title>Precise asymptotics of reweighted least-squares algorithms for linear diagonal networks</title><link>https://deep-diver.github.io/neurips2024/posters/nv7ox1vd3q/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/nv7ox1vd3q/</guid><description>New analysis reveals how reweighted least-squares algorithms for linear diagonal networks achieve favorable performance in high-dimensional settings, improving upon existing theoretical guarantees and&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/nv7ox1vd3q/cover.png"/></item><item><title>Provable Acceleration of Nesterov's Accelerated Gradient for Asymmetric Matrix Factorization and Linear Neural Networks</title><link>https://deep-diver.github.io/neurips2024/posters/x44oawaq7b/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/x44oawaq7b/</guid><description>This paper proves Nesterov&amp;rsquo;s Accelerated Gradient achieves faster convergence for rectangular matrix factorization and linear neural networks, using a novel unbalanced initialization.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/x44oawaq7b/cover.png"/></item><item><title>Semi-supervised Knowledge Transfer Across Multi-omic Single-cell Data</title><link>https://deep-diver.github.io/neurips2024/posters/skehebkedz/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/skehebkedz/</guid><description>DANCE, a novel semi-supervised framework, efficiently transfers cell types across multi-omic single-cell data even with limited labeled samples, outperforming current state-of-the-art methods.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/skehebkedz/cover.png"/></item><item><title>Vaccine: Perturbation-aware Alignment for Large Language Models against Harmful Fine-tuning Attack</title><link>https://deep-diver.github.io/neurips2024/posters/lpxdzkiant/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/lpxdzkiant/</guid><description>Vaccine: a novel technique safeguards LLMs against harmful fine-tuning attacks by creating invariant hidden embeddings.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/lpxdzkiant/cover.png"/></item><item><title>Zeroth-Order Sampling Methods for Non-Log-Concave Distributions: Alleviating Metastability by Denoising Diffusion</title><link>https://deep-diver.github.io/neurips2024/posters/x3aljulsw5/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/x3aljulsw5/</guid><description>Zeroth-Order Diffusion Monte Carlo (ZOD-MC) efficiently samples from non-log-concave distributions using only zeroth-order queries, overcoming metastability issues and outperforming state-of-the-art s&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/x3aljulsw5/cover.png"/></item></channel></rss>