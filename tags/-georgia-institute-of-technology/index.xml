<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>üè¢ Georgia Institute of Technology on NeurIPS 2024</title><link>https://deep-diver.github.io/neurips2024/tags/-georgia-institute-of-technology/</link><description>Recent content in üè¢ Georgia Institute of Technology on NeurIPS 2024</description><generator>Hugo -- gohugo.io</generator><language>en</language><copyright>¬© 2024 AI Paper Reviewer</copyright><lastBuildDate>Thu, 26 Sep 2024 00:00:00 +0000</lastBuildDate><atom:link href="https://deep-diver.github.io/neurips2024/tags/-georgia-institute-of-technology/index.xml" rel="self" type="application/rss+xml"/><item><title>3D Gaussian Rendering Can Be Sparser: Efficient Rendering via Learned Fragment Pruning</title><link>https://deep-diver.github.io/neurips2024/posters/ivqzbulfol/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/ivqzbulfol/</guid><description>Learned fragment pruning accelerates 3D Gaussian splatting rendering by selectively removing fragments, achieving up to 1.71x speedup on edge GPUs and 0.16 PSNR improvement.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/ivqzbulfol/cover.png"/></item><item><title>A Separation in Heavy-Tailed Sampling: Gaussian vs. Stable Oracles for Proximal Samplers</title><link>https://deep-diver.github.io/neurips2024/posters/zuwlghgxtq/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/zuwlghgxtq/</guid><description>Stable oracles outperform Gaussian oracles in high-accuracy heavy-tailed sampling, overcoming limitations of Gaussian-based proximal samplers.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/zuwlghgxtq/cover.png"/></item><item><title>Adaptive Preference Scaling for Reinforcement Learning with Human Feedback</title><link>https://deep-diver.github.io/neurips2024/posters/gnafrzrhpf/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/gnafrzrhpf/</guid><description>Adaptive Preference Scaling boosts Reinforcement Learning from Human Feedback by using a novel loss function that adapts to varying preference strengths, resulting in improved policy performance and s&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/gnafrzrhpf/cover.png"/></item><item><title>AmoebaLLM: Constructing Any-Shape Large Language Models for Efficient and Instant Deployment</title><link>https://deep-diver.github.io/neurips2024/posters/g0yxfmp87g/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/g0yxfmp87g/</guid><description>AmoebaLLM: Instantly create optimally-sized LLMs for any platform!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/g0yxfmp87g/cover.png"/></item><item><title>Certified Machine Unlearning via Noisy Stochastic Gradient Descent</title><link>https://deep-diver.github.io/neurips2024/posters/h3k2nxu5bj/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/h3k2nxu5bj/</guid><description>This paper introduces a novel machine unlearning method using projected noisy stochastic gradient descent, providing the first approximate unlearning guarantee under convexity, significantly improving&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/h3k2nxu5bj/cover.png"/></item><item><title>Derivative-enhanced Deep Operator Network</title><link>https://deep-diver.github.io/neurips2024/posters/waiqlgfqx6/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/waiqlgfqx6/</guid><description>Derivative-enhanced DeepONets boost PDE solution accuracy and derivative approximation, particularly valuable with limited training data.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/waiqlgfqx6/cover.png"/></item><item><title>Differentially Private Graph Diffusion with Applications in Personalized PageRanks</title><link>https://deep-diver.github.io/neurips2024/posters/aon7bwybiq/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/aon7bwybiq/</guid><description>This paper introduces a novel differentially private graph diffusion framework ensuring edge-level privacy, significantly improving utility-privacy trade-offs for personalized PageRank computation.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/aon7bwybiq/cover.png"/></item><item><title>Diffusion Policy Attacker: Crafting Adversarial Attacks for Diffusion-based Policies</title><link>https://deep-diver.github.io/neurips2024/posters/1l5vaniok5/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/1l5vaniok5/</guid><description>DP-Attacker unveils diffusion-based policy vulnerabilities by crafting effective adversarial attacks, significantly impacting robot safety and paving the way for more robust AI.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/1l5vaniok5/cover.png"/></item><item><title>Exploring Behavior-Relevant and Disentangled Neural Dynamics with Generative Diffusion Models</title><link>https://deep-diver.github.io/neurips2024/posters/jl0esbfbav/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/jl0esbfbav/</guid><description>BeNeDiff uses generative diffusion models to disentangle and interpret neural dynamics linked to specific behaviors, providing interpretable quantifications of behavior in multi-brain region datasets.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/jl0esbfbav/cover.png"/></item><item><title>High-dimensional (Group) Adversarial Training in Linear Regression</title><link>https://deep-diver.github.io/neurips2024/posters/tsb4dvtchx/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/tsb4dvtchx/</guid><description>Adversarial training achieves minimax-optimal prediction error in high-dimensional linear regression under l‚àû-perturbation, improving upon existing methods.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/tsb4dvtchx/cover.png"/></item><item><title>HYDRA: Model Factorization Framework for Black-Box LLM Personalization</title><link>https://deep-diver.github.io/neurips2024/posters/ckgngkmhyp/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/ckgngkmhyp/</guid><description>HYDRA, a novel model factorization framework, significantly improves black-box LLM personalization by capturing both user-specific behavior and shared knowledge, achieving a 9.01% average relative imp&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/ckgngkmhyp/cover.png"/></item><item><title>Langevin Unlearning: A New Perspective of Noisy Gradient Descent for Machine Unlearning</title><link>https://deep-diver.github.io/neurips2024/spotlight-ai-theory/3lkuc8rbyv/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-ai-theory/3lkuc8rbyv/</guid><description>Langevin unlearning offers a novel, privacy-preserving machine unlearning framework based on noisy gradient descent, handling both convex and non-convex problems efficiently.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-ai-theory/3lkuc8rbyv/cover.png"/></item><item><title>Large Pre-trained time series models for cross-domain Time series analysis tasks</title><link>https://deep-diver.github.io/neurips2024/posters/vmmzjcr5zj/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/vmmzjcr5zj/</guid><description>Large Pre-trained Time-series Models (LPTM) achieves superior forecasting and time-series classification results using a novel adaptive segmentation method, requiring up to 40% less data and 50% less &amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/vmmzjcr5zj/cover.png"/></item><item><title>Learning Spatially-Aware Language and Audio Embeddings</title><link>https://deep-diver.github.io/neurips2024/posters/wddvjzvvbr/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/wddvjzvvbr/</guid><description>ELSA: a new model that learns spatially aware language and audio embeddings, achieving state-of-the-art performance in semantic retrieval and 3D sound source localization.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/wddvjzvvbr/cover.png"/></item><item><title>Lisa: Lazy Safety Alignment for Large Language Models against Harmful Fine-tuning Attack</title><link>https://deep-diver.github.io/neurips2024/posters/rpchapuxlc/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/rpchapuxlc/</guid><description>Lisa: a novel lazy safety alignment method safeguards LLMs against harmful fine-tuning attacks by introducing a proximal term to constrain model drift, significantly improving alignment performance.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/rpchapuxlc/cover.png"/></item><item><title>Online Relational Inference for Evolving Multi-agent Interacting Systems</title><link>https://deep-diver.github.io/neurips2024/posters/mio8odrzto/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/mio8odrzto/</guid><description>ORI: a novel online relational inference framework efficiently identifies hidden interaction graphs in evolving multi-agent systems using streaming data and real-time adaptation.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/mio8odrzto/cover.png"/></item><item><title>Precise asymptotics of reweighted least-squares algorithms for linear diagonal networks</title><link>https://deep-diver.github.io/neurips2024/posters/nv7ox1vd3q/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/nv7ox1vd3q/</guid><description>New analysis reveals how reweighted least-squares algorithms for linear diagonal networks achieve favorable performance in high-dimensional settings, improving upon existing theoretical guarantees and&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/nv7ox1vd3q/cover.png"/></item><item><title>Provable Acceleration of Nesterov's Accelerated Gradient for Asymmetric Matrix Factorization and Linear Neural Networks</title><link>https://deep-diver.github.io/neurips2024/posters/x44oawaq7b/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/x44oawaq7b/</guid><description>This paper proves Nesterov&amp;rsquo;s Accelerated Gradient achieves faster convergence for rectangular matrix factorization and linear neural networks, using a novel unbalanced initialization.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/x44oawaq7b/cover.png"/></item><item><title>Quantitative Convergences of Lie Group Momentum Optimizers</title><link>https://deep-diver.github.io/neurips2024/posters/2hqhwd7wdb/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/2hqhwd7wdb/</guid><description>Accelerated Lie group optimization achieved via a novel momentum algorithm (Lie NAG-SC) with proven convergence rates, surpassing existing methods in efficiency.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/2hqhwd7wdb/cover.png"/></item><item><title>Rethinking Weight Decay for Robust Fine-Tuning of Foundation Models</title><link>https://deep-diver.github.io/neurips2024/posters/4neqdbz8eg/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/4neqdbz8eg/</guid><description>Selective Projection Decay (SPD) enhances robust fine-tuning of foundation models by selectively applying weight decay, improving generalization and out-of-distribution robustness.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/4neqdbz8eg/cover.png"/></item><item><title>Semi-supervised Knowledge Transfer Across Multi-omic Single-cell Data</title><link>https://deep-diver.github.io/neurips2024/posters/skehebkedz/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/skehebkedz/</guid><description>DANCE, a novel semi-supervised framework, efficiently transfers cell types across multi-omic single-cell data even with limited labeled samples, outperforming current state-of-the-art methods.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/skehebkedz/cover.png"/></item><item><title>Understanding Scaling Laws with Statistical and Approximation Theory for Transformer Neural Networks on Intrinsically Low-dimensional Data</title><link>https://deep-diver.github.io/neurips2024/posters/n2wypmpifa/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/n2wypmpifa/</guid><description>Deep learning scaling laws are explained by novel approximation and estimation theories for transformers on low-dimensional data, resolving discrepancies between theory and practice.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/n2wypmpifa/cover.png"/></item><item><title>Vaccine: Perturbation-aware Alignment for Large Language Models against Harmful Fine-tuning Attack</title><link>https://deep-diver.github.io/neurips2024/posters/lpxdzkiant/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/lpxdzkiant/</guid><description>Vaccine: a novel technique safeguards LLMs against harmful fine-tuning attacks by creating invariant hidden embeddings.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/lpxdzkiant/cover.png"/></item><item><title>Zeroth-Order Sampling Methods for Non-Log-Concave Distributions: Alleviating Metastability by Denoising Diffusion</title><link>https://deep-diver.github.io/neurips2024/posters/x3aljulsw5/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/x3aljulsw5/</guid><description>Zeroth-Order Diffusion Monte Carlo (ZOD-MC) efficiently samples from non-log-concave distributions using only zeroth-order queries, overcoming metastability issues and outperforming state-of-the-art s&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/x3aljulsw5/cover.png"/></item></channel></rss>