<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>üè¢ City University of Hong Kong on NeurIPS 2024</title><link>https://deep-diver.github.io/neurips2024/tags/-city-university-of-hong-kong/</link><description>Recent content in üè¢ City University of Hong Kong on NeurIPS 2024</description><generator>Hugo -- gohugo.io</generator><language>en</language><copyright>¬© 2024 AI Paper Reviewer</copyright><lastBuildDate>Thu, 26 Sep 2024 00:00:00 +0000</lastBuildDate><atom:link href="https://deep-diver.github.io/neurips2024/tags/-city-university-of-hong-kong/index.xml" rel="self" type="application/rss+xml"/><item><title>A versatile informative diffusion model for single-cell ATAC-seq data generation and analysis</title><link>https://deep-diver.github.io/neurips2024/posters/s6ylebmowf/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/s6ylebmowf/</guid><description>ATAC-Diff: A versatile diffusion model for high-quality single-cell ATAC-seq data generation and analysis, surpassing state-of-the-art.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/s6ylebmowf/cover.png"/></item><item><title>Adaptive Image Quality Assessment via Teaching Large Multimodal Model to Compare</title><link>https://deep-diver.github.io/neurips2024/spotlight-others/mhtoyh5taj/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-others/mhtoyh5taj/</guid><description>Compare2Score: A novel IQA model teaches large multimodal models to translate comparative image quality judgments into continuous quality scores, significantly outperforming existing methods.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-others/mhtoyh5taj/cover.png"/></item><item><title>CODA: A Correlation-Oriented Disentanglement and Augmentation Modeling Scheme for Better Resisting Subpopulation Shifts</title><link>https://deep-diver.github.io/neurips2024/posters/lrsrjzzcle/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/lrsrjzzcle/</guid><description>CODA: A novel modeling scheme tackles subpopulation shifts in machine learning by disentangling spurious correlations, augmenting data strategically, and using reweighted consistency loss for improved&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/lrsrjzzcle/cover.png"/></item><item><title>LLM-ESR: Large Language Models Enhancement for Long-tailed Sequential Recommendation</title><link>https://deep-diver.github.io/neurips2024/spotlight-others/xojbzsyivs/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-others/xojbzsyivs/</guid><description>LLM-ESR enhances sequential recommendation by integrating semantic information from LLMs, significantly improving performance on long-tail users and items.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-others/xojbzsyivs/cover.png"/></item><item><title>Multi-Scale VMamba: Hierarchy in Hierarchy Visual State Space Model</title><link>https://deep-diver.github.io/neurips2024/posters/r70juopdcm/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/r70juopdcm/</guid><description>MSVMamba: A novel multi-scale vision model leveraging state-space models, achieves high accuracy in image classification and object detection while maintaining linear complexity, solving the long-rang&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/r70juopdcm/cover.png"/></item><item><title>PrefPaint: Aligning Image Inpainting Diffusion Model with Human Preference</title><link>https://deep-diver.github.io/neurips2024/posters/fvrcsk4eom/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/fvrcsk4eom/</guid><description>PrefPaint: Aligning image inpainting diffusion models with human preferences using reinforcement learning, resulting in significantly improved visual appeal.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/fvrcsk4eom/cover.png"/></item><item><title>Revisiting the Integration of Convolution and Attention for Vision Backbone</title><link>https://deep-diver.github.io/neurips2024/posters/ttuxtv2yra/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/ttuxtv2yra/</guid><description>GLMix: A novel vision backbone efficiently integrates convolutions and multi-head self-attention at different granularities, achieving state-of-the-art performance while addressing scalability issues.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/ttuxtv2yra/cover.png"/></item></channel></rss>