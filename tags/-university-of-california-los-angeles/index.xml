<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>üè¢ University of California, Los Angeles on NeurIPS 2024</title><link>https://deep-diver.github.io/neurips2024/tags/-university-of-california-los-angeles/</link><description>Recent content in üè¢ University of California, Los Angeles on NeurIPS 2024</description><generator>Hugo -- gohugo.io</generator><language>en</language><copyright>¬© 2025 AI Paper Reviewer</copyright><lastBuildDate>Thu, 26 Sep 2024 00:00:00 +0000</lastBuildDate><atom:link href="https://deep-diver.github.io/neurips2024/tags/-university-of-california-los-angeles/index.xml" rel="self" type="application/rss+xml"/><item><title>Benign overfitting in leaky ReLU networks with moderate input dimension</title><link>https://deep-diver.github.io/neurips2024/spotlight-ai-theory/88tzdgypt6/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-ai-theory/88tzdgypt6/</guid><description>Leaky ReLU networks exhibit benign overfitting under surprisingly relaxed conditions: input dimension only needs to linearly scale with sample size, challenging prior assumptions in the field.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-ai-theory/88tzdgypt6/cover.png"/></item><item><title>How does PDE order affect the convergence of PINNs?</title><link>https://deep-diver.github.io/neurips2024/posters/8k6ul0hgtc/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/8k6ul0hgtc/</guid><description>Higher-order PDEs hinder Physics-Informed Neural Network (PINN) convergence; this paper provides theoretical explanation and proposes variable splitting for improved accuracy.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/8k6ul0hgtc/cover.png"/></item><item><title>Identifying Causal Effects Under Functional Dependencies</title><link>https://deep-diver.github.io/neurips2024/spotlight-ai-theory/oisuwqsvkd/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-ai-theory/oisuwqsvkd/</guid><description>Unlocking identifiability of causal effects: This paper leverages functional dependencies in causal graphs to improve identifiability, leading to fewer needed variables in observational data.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-ai-theory/oisuwqsvkd/cover.png"/></item><item><title>Molecule Design by Latent Prompt Transformer</title><link>https://deep-diver.github.io/neurips2024/spotlight-others/dg3ti3c2b1/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-others/dg3ti3c2b1/</guid><description>Latent Prompt Transformer (LPT) revolutionizes molecule design by unifying generation and optimization, achieving high efficiency in discovering novel molecules with desired properties.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-others/dg3ti3c2b1/cover.png"/></item><item><title>Statistical Estimation in the Spiked Tensor Model via the Quantum Approximate Optimization Algorithm</title><link>https://deep-diver.github.io/neurips2024/spotlight-ai-theory/wtlvxdzhmp/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-ai-theory/wtlvxdzhmp/</guid><description>Quantum Approximate Optimization Algorithm (QAOA) achieves weak recovery in spiked tensor models matching classical methods, but with potential constant factor advantages for certain parameters.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-ai-theory/wtlvxdzhmp/cover.png"/></item><item><title>The Star Geometry of Critic-Based Regularizer Learning</title><link>https://deep-diver.github.io/neurips2024/posters/2gqecbhxvy/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/2gqecbhxvy/</guid><description>Star geometry reveals optimal data-driven regularizers!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/2gqecbhxvy/cover.png"/></item><item><title>Theoretical and Empirical Insights into the Origins of Degree Bias in Graph Neural Networks</title><link>https://deep-diver.github.io/neurips2024/posters/1maaewthcz/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/1maaewthcz/</guid><description>Researchers unveil the origins of degree bias in Graph Neural Networks (GNNs), proving high-degree nodes&amp;rsquo; lower misclassification probability and proposing methods to alleviate this bias for fairer GN&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/1maaewthcz/cover.png"/></item></channel></rss>