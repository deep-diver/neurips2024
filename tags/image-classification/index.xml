<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Image Classification on NeurIPS 2024</title><link>https://deep-diver.github.io/neurips2024/tags/image-classification/</link><description>Recent content in Image Classification on NeurIPS 2024</description><generator>Hugo -- gohugo.io</generator><language>en</language><copyright>Â© 2024 AI Paper Reviewer</copyright><lastBuildDate>Thu, 26 Sep 2024 00:00:00 +0000</lastBuildDate><atom:link href="https://deep-diver.github.io/neurips2024/tags/image-classification/index.xml" rel="self" type="application/rss+xml"/><item><title>A Label is Worth A Thousand Images in Dataset Distillation</title><link>https://deep-diver.github.io/neurips2024/posters/onmnr0nj2e/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/onmnr0nj2e/</guid><description>Soft labels, not sophisticated data synthesis, are the key to successful dataset distillation, significantly improving data-efficient learning and challenging existing methods.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/onmnr0nj2e/cover.png"/></item><item><title>A Textbook Remedy for Domain Shifts: Knowledge Priors for Medical Image Analysis</title><link>https://deep-diver.github.io/neurips2024/spotlight-others/strpbhrvt3/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-others/strpbhrvt3/</guid><description>KnoBo enhances deep learning models for medical image analysis by incorporating knowledge priors from medical textbooks, boosting out-of-domain performance by up to 32.4%.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-others/strpbhrvt3/cover.png"/></item><item><title>AdanCA: Neural Cellular Automata As Adaptors For More Robust Vision Transformer</title><link>https://deep-diver.github.io/neurips2024/posters/bqh1sgvrog/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/bqh1sgvrog/</guid><description>Boosting Vision Transformer robustness against attacks &amp;amp; noisy data, AdaNCA uses Neural Cellular Automata as plug-and-play adaptors between ViT layers, achieving significant accuracy improvement with &amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/bqh1sgvrog/cover.png"/></item><item><title>Adaptive Randomized Smoothing: Certified Adversarial Robustness for Multi-Step Defences</title><link>https://deep-diver.github.io/neurips2024/spotlight-others/mn4nt01teo/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-others/mn4nt01teo/</guid><description>Adaptive Randomized Smoothing certifies deep learning model predictions against adversarial attacks by cleverly combining randomized smoothing with adaptive, multi-step input masking for improved accu&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-others/mn4nt01teo/cover.png"/></item><item><title>Are Large-scale Soft Labels Necessary for Large-scale Dataset Distillation?</title><link>https://deep-diver.github.io/neurips2024/posters/12a1rt1l87/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/12a1rt1l87/</guid><description>Large-scale dataset distillation can be achieved with significantly less soft labels by using class-wise supervision during image synthesis, enabling simple random label pruning and enhancing model ac&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/12a1rt1l87/cover.png"/></item><item><title>Are nuclear masks all you need for improved out-of-domain generalisation? A closer look at cancer classification in histopathology</title><link>https://deep-diver.github.io/neurips2024/posters/bmwcbnykuh/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/bmwcbnykuh/</guid><description>Focusing on nuclear morphology improves out-of-domain generalization in cancer classification from histopathology images by leveraging nuclear segmentation masks during training.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/bmwcbnykuh/cover.png"/></item><item><title>Biologically-Inspired Learning Model for Instructed Vision</title><link>https://deep-diver.github.io/neurips2024/posters/gjxeircnao/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/gjxeircnao/</guid><description>Biologically-inspired AI model integrates learning &amp;amp; visual guidance via a novel &amp;lsquo;Counter-Hebb&amp;rsquo; learning mechanism, achieving competitive performance on multi-task learning benchmarks.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/gjxeircnao/cover.png"/></item><item><title>BOLD: Boolean Logic Deep Learning</title><link>https://deep-diver.github.io/neurips2024/posters/do9wpzopjk/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/do9wpzopjk/</guid><description>Boolean Logic Deep Learning (BOLD) revolutionizes deep learning by enabling training with Boolean weights and activations, achieving state-of-the-art accuracy with drastically reduced energy consumpti&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/do9wpzopjk/cover.png"/></item><item><title>Bridging the Divide: Reconsidering Softmax and Linear Attention</title><link>https://deep-diver.github.io/neurips2024/posters/rsigfzqapl/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/rsigfzqapl/</guid><description>InLine attention, a novel method, bridges the performance gap between softmax and linear attention by incorporating injectivity and local modeling, achieving superior performance while maintaining lin&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/rsigfzqapl/cover.png"/></item><item><title>Coarse-to-Fine Concept Bottleneck Models</title><link>https://deep-diver.github.io/neurips2024/posters/rmdntnffou/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/rmdntnffou/</guid><description>Hierarchical concept bottleneck models boost interpretability and accuracy in visual classification by uncovering both high-level and low-level concepts.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/rmdntnffou/cover.png"/></item><item><title>Constructing Semantics-Aware Adversarial Examples with Probabilistic Perspective</title><link>https://deep-diver.github.io/neurips2024/posters/wbe0qcbwji/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/wbe0qcbwji/</guid><description>Researchers developed semantics-aware adversarial examples using a probabilistic approach, achieving higher success rates in bypassing defenses while remaining undetectable to humans.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/wbe0qcbwji/cover.png"/></item><item><title>Curriculum Fine-tuning of Vision Foundation Model for Medical Image Classification Under Label Noise</title><link>https://deep-diver.github.io/neurips2024/posters/vyux8j5kk2/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/vyux8j5kk2/</guid><description>CUFIT: a novel curriculum fine-tuning paradigm significantly improves medical image classification accuracy despite noisy labels by leveraging pre-trained Vision Foundation Models.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/vyux8j5kk2/cover.png"/></item><item><title>Decoupled Kullback-Leibler Divergence Loss</title><link>https://deep-diver.github.io/neurips2024/posters/bnzzedw9cm/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/bnzzedw9cm/</guid><description>Improved Kullback-Leibler (IKL) divergence loss achieves state-of-the-art adversarial robustness and competitive knowledge distillation performance by addressing KL loss&amp;rsquo;s limitations.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/bnzzedw9cm/cover.png"/></item><item><title>Demystify Mamba in Vision: A Linear Attention Perspective</title><link>https://deep-diver.github.io/neurips2024/posters/lvj1r88kak/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/lvj1r88kak/</guid><description>Vision&amp;rsquo;s Mamba model demystified: Researchers unveil its surprising link to linear attention, improving efficiency and accuracy through design enhancements.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/lvj1r88kak/cover.png"/></item><item><title>DenoiseRep: Denoising Model for Representation Learning</title><link>https://deep-diver.github.io/neurips2024/oral-others/oycu0baus6/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/oral-others/oycu0baus6/</guid><description>DenoiseRep: A novel denoising model enhances feature discrimination in computer vision tasks by integrating feature extraction and denoising within a single backbone, achieving impressive improvements&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/oral-others/oycu0baus6/cover.png"/></item><item><title>DeSparsify: Adversarial Attack Against Token Sparsification Mechanisms</title><link>https://deep-diver.github.io/neurips2024/spotlight-others/d4yrz3s7ul/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-others/d4yrz3s7ul/</guid><description>DeSparsify: A stealthy adversarial attack exhausts vision transformer resources by exploiting token sparsification mechanisms&amp;rsquo; dynamic nature, highlighting the need for improved resource management i&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-others/d4yrz3s7ul/cover.png"/></item><item><title>DEX: Data Channel Extension for Efficient CNN Inference on Tiny AI Accelerators</title><link>https://deep-diver.github.io/neurips2024/posters/ftqjwzqz10/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/ftqjwzqz10/</guid><description>DEX boosts CNN accuracy on tiny AI accelerators by 3.5%p, utilizing unused memory and processors to extend input channels without increasing latency.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/ftqjwzqz10/cover.png"/></item><item><title>DiffuLT: Diffusion for Long-tail Recognition Without External Knowledge</title><link>https://deep-diver.github.io/neurips2024/posters/kcsj9fgnkr/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/kcsj9fgnkr/</guid><description>DiffuLT uses a novel diffusion model to generate balanced training data from imbalanced datasets, achieving state-of-the-art results in long-tailed image recognition without external knowledge.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/kcsj9fgnkr/cover.png"/></item><item><title>Diversity-Driven Synthesis: Enhancing Dataset Distillation through Directed Weight Adjustment</title><link>https://deep-diver.github.io/neurips2024/spotlight-others/uwsadhllyc/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-others/uwsadhllyc/</guid><description>Boosting dataset distillation, a new method, Diversity-Driven Synthesis, uses directed weight adjustment to create diverse, representative synthetic datasets, improving model performance while reducin&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-others/uwsadhllyc/cover.png"/></item><item><title>Dynamic Tuning Towards Parameter and Inference Efficiency for ViT Adaptation</title><link>https://deep-diver.github.io/neurips2024/posters/e0sq6wshjv/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/e0sq6wshjv/</guid><description>Dynamic Tuning (DyT) significantly boosts Vision Transformer (ViT) adaptation by dynamically skipping less important tokens during inference, achieving superior performance with 71% fewer FLOPs than e&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/e0sq6wshjv/cover.png"/></item><item><title>Efficient Adaptation of Pre-trained Vision Transformer via Householder Transformation</title><link>https://deep-diver.github.io/neurips2024/posters/botjmacaci/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/botjmacaci/</guid><description>Boosting Vision Transformer adaptation! Householder Transformation-based Adaptor (HTA) outperforms existing methods by dynamically adjusting adaptation matrix ranks across layers, improving efficiency&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/botjmacaci/cover.png"/></item><item><title>Elucidating the Design Space of Dataset Condensation</title><link>https://deep-diver.github.io/neurips2024/posters/az1sllsmdr/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/az1sllsmdr/</guid><description>Elucidating Dataset Condensation (EDC) achieves state-of-the-art accuracy in dataset condensation by implementing soft category-aware matching and a smoothing learning rate schedule, improving model t&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/az1sllsmdr/cover.png"/></item><item><title>EMR-Merging: Tuning-Free High-Performance Model Merging</title><link>https://deep-diver.github.io/neurips2024/spotlight-others/lydjzx3dyu/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-others/lydjzx3dyu/</guid><description>EMR-MERGING: A tuning-free model merging technique achieves high performance by electing a unified model and generating lightweight task-specific modulators, eliminating the need for additional data &amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-others/lydjzx3dyu/cover.png"/></item><item><title>Exploring Token Pruning in Vision State Space Models</title><link>https://deep-diver.github.io/neurips2024/posters/ewign0fcdx/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/ewign0fcdx/</guid><description>This paper introduces a novel token pruning method for vision state space models, achieving significant computational reduction with minimal performance impact, addressing the limitations of directly &amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/ewign0fcdx/cover.png"/></item><item><title>F-OAL: Forward-only Online Analytic Learning with Fast Training and Low Memory Footprint in Class Incremental Learning</title><link>https://deep-diver.github.io/neurips2024/posters/rgedfs3emy/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/rgedfs3emy/</guid><description>F-OAL: Forward-only Online Analytic Learning achieves high accuracy and low memory usage in online class incremental learning by using a frozen encoder and recursive least squares to update a linear &amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/rgedfs3emy/cover.png"/></item><item><title>Flipped Classroom: Aligning Teacher Attention with Student in Generalized Category Discovery</title><link>https://deep-diver.github.io/neurips2024/oral-others/c4nbtynyqg/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/oral-others/c4nbtynyqg/</guid><description>FlipClass dynamically updates the teacher model in a teacher-student framework to align with the student&amp;rsquo;s attention, resolving learning inconsistencies and significantly improving generalized categor&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/oral-others/c4nbtynyqg/cover.png"/></item><item><title>Geometric Analysis of Nonlinear Manifold Clustering</title><link>https://deep-diver.github.io/neurips2024/posters/nbqhtbvnfr/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/nbqhtbvnfr/</guid><description>Guaranteed Manifold Clustering: Novel method provides geometric conditions ensuring accurate data grouping from nonlinear manifolds, showing competitive performance on CIFAR datasets.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/nbqhtbvnfr/cover.png"/></item><item><title>Happy: A Debiased Learning Framework for Continual Generalized Category Discovery</title><link>https://deep-diver.github.io/neurips2024/posters/hduczimkfo/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/hduczimkfo/</guid><description>Happy: a novel debiased learning framework, excels at continually discovering new categories from unlabeled data while retaining knowledge of previously learned ones, overcoming existing bias issues a&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/hduczimkfo/cover.png"/></item><item><title>Hierarchical Selective Classification</title><link>https://deep-diver.github.io/neurips2024/posters/wzof7y66xs/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/wzof7y66xs/</guid><description>Hierarchical Selective Classification (HSC) improves deep learning model reliability for risk-sensitive tasks by leveraging hierarchical class relationships to provide more informative predictions eve&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/wzof7y66xs/cover.png"/></item><item><title>HydraViT: Stacking Heads for a Scalable ViT</title><link>https://deep-diver.github.io/neurips2024/posters/kk0eaunc58/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/kk0eaunc58/</guid><description>HydraViT: Stacking attention heads creates a scalable Vision Transformer, adapting to diverse hardware by dynamically selecting subnetworks during inference, improving accuracy and efficiency.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/kk0eaunc58/cover.png"/></item><item><title>Improving robustness to corruptions with multiplicative weight perturbations</title><link>https://deep-diver.github.io/neurips2024/spotlight-others/m8dy0zusb1/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-others/m8dy0zusb1/</guid><description>Boost DNN robustness to corruptions without sacrificing clean image accuracy using Data Augmentation via Multiplicative Perturbations (DAMP)!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-others/m8dy0zusb1/cover.png"/></item><item><title>In Pursuit of Causal Label Correlations for Multi-label Image Recognition</title><link>https://deep-diver.github.io/neurips2024/posters/ybhbespwys/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/ybhbespwys/</guid><description>This research leverages causal intervention to identify and utilize genuine label correlations in multi-label image recognition, mitigating contextual bias for improved accuracy.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/ybhbespwys/cover.png"/></item><item><title>Infinite-Dimensional Feature Interaction</title><link>https://deep-diver.github.io/neurips2024/posters/xo9ghdmk76/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/xo9ghdmk76/</guid><description>InfiNet achieves state-of-the-art results by enabling feature interaction in an infinite-dimensional space using RBF kernels, surpassing models limited to finite-dimensional interactions.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/xo9ghdmk76/cover.png"/></item><item><title>Interpret Your Decision: Logical Reasoning Regularization for Generalization in Visual Classification</title><link>https://deep-diver.github.io/neurips2024/spotlight-others/woiqqi5byv/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-others/woiqqi5byv/</guid><description>This paper introduces L-Reg, a novel logical regularization technique, to improve generalization in visual classification. L-Reg effectively reduces model complexity and improves interpretability by f&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-others/woiqqi5byv/cover.png"/></item><item><title>Interpretable Image Classification with Adaptive Prototype-based Vision Transformers</title><link>https://deep-diver.github.io/neurips2024/posters/hjhpcjfbfg/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/hjhpcjfbfg/</guid><description>ProtoViT: a novel interpretable image classification method using Vision Transformers and adaptive prototypes, achieving higher accuracy and providing clear explanations.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/hjhpcjfbfg/cover.png"/></item><item><title>Learning Bregman Divergences with Application to Robustness</title><link>https://deep-diver.github.io/neurips2024/posters/yuckudjae0/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/yuckudjae0/</guid><description>Learned Bregman divergences significantly improve image corruption robustness in adversarial training.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/yuckudjae0/cover.png"/></item><item><title>Learning from Offline Foundation Features with Tensor Augmentations</title><link>https://deep-diver.github.io/neurips2024/posters/vvd3iokpmj/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/vvd3iokpmj/</guid><description>LOFF-TA leverages offline foundation model features and tensor augmentations for efficient, resource-light training, achieving up to 37x faster training and 26x less GPU memory usage.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/vvd3iokpmj/cover.png"/></item><item><title>Linearly Decomposing and Recomposing Vision Transformers for Diverse-Scale Models</title><link>https://deep-diver.github.io/neurips2024/posters/yhd0yzc8yd/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/yhd0yzc8yd/</guid><description>Linearly decompose &amp;amp; recompose Vision Transformers to create diverse-scale models efficiently, reducing computational costs &amp;amp; improving flexibility for various applications.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/yhd0yzc8yd/cover.png"/></item><item><title>LookHere: Vision Transformers with Directed Attention Generalize and Extrapolate</title><link>https://deep-diver.github.io/neurips2024/posters/o7dogbzeyp/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/o7dogbzeyp/</guid><description>LookHere: Vision Transformers excel at high-resolution image classification by using 2D attention masks to direct attention heads, improving generalization and extrapolation.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/o7dogbzeyp/cover.png"/></item><item><title>MambaTree: Tree Topology is All You Need in State Space Model</title><link>https://deep-diver.github.io/neurips2024/spotlight-others/w8rfsakr4m/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-others/w8rfsakr4m/</guid><description>MambaTree: A novel tree-topology-based state space model surpasses existing methods by dynamically generating input-aware topologies for enhanced long-range dependencies in vision and language.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-others/w8rfsakr4m/cover.png"/></item><item><title>Mitigating Biases in Blackbox Feature Extractors for Image Classification Tasks</title><link>https://deep-diver.github.io/neurips2024/posters/hwo1mnluol/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/hwo1mnluol/</guid><description>Researchers propose a simple yet effective clustering-based adaptive margin loss to mitigate biases inherited by black-box feature extractors in image classification tasks.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/hwo1mnluol/cover.png"/></item><item><title>MoE Jetpack: From Dense Checkpoints to Adaptive Mixture of Experts for Vision Tasks</title><link>https://deep-diver.github.io/neurips2024/posters/q8z04xhddl/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/q8z04xhddl/</guid><description>MoE Jetpack efficiently transforms readily available dense checkpoints into high-performing MoE models, drastically accelerating convergence and improving accuracy.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/q8z04xhddl/cover.png"/></item><item><title>Multi-Scale VMamba: Hierarchy in Hierarchy Visual State Space Model</title><link>https://deep-diver.github.io/neurips2024/posters/r70juopdcm/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/r70juopdcm/</guid><description>MSVMamba: A novel multi-scale vision model leveraging state-space models, achieves high accuracy in image classification and object detection while maintaining linear complexity, solving the long-rang&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/r70juopdcm/cover.png"/></item><item><title>No Train, all Gain: Self-Supervised Gradients Improve Deep Frozen Representations</title><link>https://deep-diver.github.io/neurips2024/posters/prbsez8rnv/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/prbsez8rnv/</guid><description>Self-supervised gradients boost frozen deep learning model performance!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/prbsez8rnv/cover.png"/></item><item><title>Not Just Object, But State: Compositional Incremental Learning without Forgetting</title><link>https://deep-diver.github.io/neurips2024/posters/2lrzhbtdta/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/2lrzhbtdta/</guid><description>CompILer: A novel prompt-based incremental learner mastering state-object compositions without forgetting, achieving state-of-the-art performance.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/2lrzhbtdta/cover.png"/></item><item><title>On the Surprising Effectiveness of Attention Transfer for Vision Transformers</title><link>https://deep-diver.github.io/neurips2024/posters/5dwqmoce1n/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/5dwqmoce1n/</guid><description>Vision Transformers achieve surprisingly high accuracy by transferring only pre-training attention maps, challenging the conventional belief that feature learning is crucial.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/5dwqmoce1n/cover.png"/></item><item><title>On the Use of Anchoring for Training Vision Models</title><link>https://deep-diver.github.io/neurips2024/spotlight-others/xymhwyizop/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-others/xymhwyizop/</guid><description>Boosting vision model training: A new anchored training protocol with a simple regularizer significantly enhances generalization and safety, surpassing standard methods.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-others/xymhwyizop/cover.png"/></item><item><title>Physics-Constrained Comprehensive Optical Neural Networks</title><link>https://deep-diver.github.io/neurips2024/posters/qhuxu2ilig/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/qhuxu2ilig/</guid><description>Physics-constrained learning significantly boosts optical neural network accuracy by addressing systematic physical errors, achieving state-of-the-art results on image classification tasks.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/qhuxu2ilig/cover.png"/></item><item><title>Prototypical Hash Encoding for On-the-Fly Fine-Grained Category Discovery</title><link>https://deep-diver.github.io/neurips2024/posters/seyxqfgt0q/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/seyxqfgt0q/</guid><description>Prototypical Hash Encoding (PHE) significantly boosts on-the-fly fine-grained category discovery by using multiple prototypes per category to generate highly discriminative hash codes, thus resolving &amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/seyxqfgt0q/cover.png"/></item><item><title>Provable Benefit of Cutout and CutMix for Feature Learning</title><link>https://deep-diver.github.io/neurips2024/spotlight-others/8on9diuh5v/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-others/8on9diuh5v/</guid><description>CutMix and Cutout data augmentation methods provably improve feature learning by enabling the network to learn rarer features and noise vectors more effectively.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-others/8on9diuh5v/cover.png"/></item><item><title>QKFormer: Hierarchical Spiking Transformer using Q-K Attention</title><link>https://deep-diver.github.io/neurips2024/spotlight-others/avd7dpiooc/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-others/avd7dpiooc/</guid><description>QKFormer: A groundbreaking spiking transformer achieving 85.65% ImageNet accuracy using a linear-complexity, energy-efficient Q-K attention mechanism.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-others/avd7dpiooc/cover.png"/></item><item><title>RAMP: Boosting Adversarial Robustness Against Multiple $l_p$ Perturbations for Universal Robustness</title><link>https://deep-diver.github.io/neurips2024/posters/u1z3hwz4vj/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/u1z3hwz4vj/</guid><description>RAMP: A novel training framework significantly boosts DNN robustness against diverse adversarial attacks by mitigating accuracy-robustness tradeoffs and improving generalization.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/u1z3hwz4vj/cover.png"/></item><item><title>Real-time Core-Periphery Guided ViT with Smart Data Layout Selection on Mobile Devices</title><link>https://deep-diver.github.io/neurips2024/posters/ld7ziamhbf/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/ld7ziamhbf/</guid><description>ECP-ViT: Real-time Vision Transformer on Mobile Devices via Core-Periphery Attention and Smart Data Layout.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/ld7ziamhbf/cover.png"/></item><item><title>Recurrent neural network dynamical systems for biological vision</title><link>https://deep-diver.github.io/neurips2024/spotlight-others/zz94albmok/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-others/zz94albmok/</guid><description>CordsNet: a hybrid CNN-RNN architecture enabling biologically realistic, robust image recognition through continuous-time recurrent dynamics.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-others/zz94albmok/cover.png"/></item><item><title>Revisiting the Integration of Convolution and Attention for Vision Backbone</title><link>https://deep-diver.github.io/neurips2024/posters/ttuxtv2yra/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/ttuxtv2yra/</guid><description>GLMix: A novel vision backbone efficiently integrates convolutions and multi-head self-attention at different granularities, achieving state-of-the-art performance while addressing scalability issues.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/ttuxtv2yra/cover.png"/></item><item><title>RTify: Aligning Deep Neural Networks with Human Behavioral Decisions</title><link>https://deep-diver.github.io/neurips2024/posters/ntjeoxlwyv/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/ntjeoxlwyv/</guid><description>RTify: A novel framework aligns deep neural networks&amp;rsquo; dynamics with human reaction times for improved visual decision-making models.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/ntjeoxlwyv/cover.png"/></item><item><title>Saliency-driven Experience Replay for Continual Learning</title><link>https://deep-diver.github.io/neurips2024/spotlight-others/8kkbxzn0km/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-others/8kkbxzn0km/</guid><description>Boosting AI&amp;rsquo;s continual learning via saliency-driven experience replay, achieving up to 20% accuracy improvement.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-others/8kkbxzn0km/cover.png"/></item><item><title>Samba: Severity-aware Recurrent Modeling for Cross-domain Medical Image Grading</title><link>https://deep-diver.github.io/neurips2024/posters/aiexn5103e/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/aiexn5103e/</guid><description>Samba: a novel severity-aware recurrent model, tackles cross-domain medical image grading by sequentially encoding image patches and recalibrating states using EM, significantly improving accuracy.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/aiexn5103e/cover.png"/></item><item><title>Scaling White-Box Transformers for Vision</title><link>https://deep-diver.github.io/neurips2024/posters/wkwgedn19x/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/wkwgedn19x/</guid><description>CRATE-a: A new white-box vision transformer architecture achieves 85.1% ImageNet accuracy by strategically scaling model size and datasets, outperforming prior white-box models and preserving interpre&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/wkwgedn19x/cover.png"/></item><item><title>Slicing Vision Transformer for Flexibile Inference</title><link>https://deep-diver.github.io/neurips2024/posters/zjnsbgl4ua/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/zjnsbgl4ua/</guid><description>Scala: One-shot training enables flexible ViT inference!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/zjnsbgl4ua/cover.png"/></item><item><title>Spiking Transformer with Experts Mixture</title><link>https://deep-diver.github.io/neurips2024/posters/wcieety3ag/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/wcieety3ag/</guid><description>Spiking Experts Mixture Mechanism (SEMM) boosts Spiking Transformers by integrating Mixture-of-Experts for efficient, sparse conditional computation, achieving significant performance improvements on &amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/wcieety3ag/cover.png"/></item><item><title>TARP-VP: Towards Evaluation of Transferred Adversarial Robustness and Privacy on Label Mapping Visual Prompting Models</title><link>https://deep-diver.github.io/neurips2024/posters/fevuebbejb/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/fevuebbejb/</guid><description>TARP-VP reveals a surprising lack of trade-off between adversarial robustness and privacy for label mapping visual prompting models, showing that transferred adversarial training significantly improve&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/fevuebbejb/cover.png"/></item><item><title>To Err Like Human: Affective Bias-Inspired Measures for Visual Emotion Recognition Evaluation</title><link>https://deep-diver.github.io/neurips2024/posters/nlslbjgl7f/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/nlslbjgl7f/</guid><description>This paper introduces novel metrics for visual emotion recognition evaluation, considering the psychological distance between emotions to better reflect human perception, improving the assessment of m&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/nlslbjgl7f/cover.png"/></item><item><title>TrAct: Making First-layer Pre-Activations Trainable</title><link>https://deep-diver.github.io/neurips2024/posters/gccmzedgbo/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/gccmzedgbo/</guid><description>TrAct boosts vision model training by directly optimizing first-layer activations, leading to significant speedups (1.25x-4x) and improved accuracy.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/gccmzedgbo/cover.png"/></item><item><title>Vision Transformer Neural Architecture Search for Out-of-Distribution Generalization: Benchmark and Insights</title><link>https://deep-diver.github.io/neurips2024/posters/2aiwiike0s/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/2aiwiike0s/</guid><description>OoD-ViT-NAS: a new benchmark reveals how ViT architecture impacts out-of-distribution generalization, highlighting the importance of embedding dimension and challenging the reliance on in-distribution&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/2aiwiike0s/cover.png"/></item><item><title>Visual Data Diagnosis and Debiasing with Concept Graphs</title><link>https://deep-diver.github.io/neurips2024/posters/xngsx3wcu9/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/xngsx3wcu9/</guid><description>CONBIAS tackles dataset bias by representing visual data as concept graphs, diagnosing imbalances via clique analysis, and debiasing through targeted data augmentation for improved model generalizatio&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/xngsx3wcu9/cover.png"/></item><item><title>Visual Fourier Prompt Tuning</title><link>https://deep-diver.github.io/neurips2024/posters/nkhel4n0ju/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/nkhel4n0ju/</guid><description>Visual Fourier Prompt Tuning (VFPT) leverages the Fast Fourier Transform to seamlessly integrate spatial and frequency information for superior parameter-efficient vision model fine-tuning, even with &amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/nkhel4n0ju/cover.png"/></item><item><title>Visual Pinwheel Center Act as Geometric Saliency Detector</title><link>https://deep-diver.github.io/neurips2024/posters/lpkcoml66w/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/lpkcoml66w/</guid><description>Visual pinwheel centers in the cortex act as efficient geometric saliency detectors, responding faster and stronger to complex spatial textures than other structures.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/lpkcoml66w/cover.png"/></item><item><title>VMamba: Visual State Space Model</title><link>https://deep-diver.github.io/neurips2024/spotlight-others/zgtlqqr1k7/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-others/zgtlqqr1k7/</guid><description>VMamba: a vision backbone achieving linear time complexity using Visual State Space (VSS) blocks and 2D Selective Scan (SS2D) for efficient visual representation.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-others/zgtlqqr1k7/cover.png"/></item><item><title>Wasserstein Distance Rivals Kullback-Leibler Divergence for Knowledge Distillation</title><link>https://deep-diver.github.io/neurips2024/posters/1qfdcaxn6k/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/1qfdcaxn6k/</guid><description>Wasserstein Distance-based Knowledge Distillation (WKD) rivals KL-divergence by leveraging rich category interrelations and handling non-overlapping distributions, significantly boosting performance i&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/1qfdcaxn6k/cover.png"/></item></channel></rss>