<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Optimization on NeurIPS 2024</title><link>https://deep-diver.github.io/neurips2024/tags/optimization/</link><description>Recent content in Optimization on NeurIPS 2024</description><generator>Hugo -- gohugo.io</generator><language>en</language><copyright>Â© 2024 AI Paper Reviewer</copyright><lastBuildDate>Thu, 26 Sep 2024 00:00:00 +0000</lastBuildDate><atom:link href="https://deep-diver.github.io/neurips2024/tags/optimization/index.xml" rel="self" type="application/rss+xml"/><item><title>4+3 Phases of Compute-Optimal Neural Scaling Laws</title><link>https://deep-diver.github.io/neurips2024/spotlight/avsxwicpak/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight/avsxwicpak/</guid><description>Researchers discovered four distinct compute-optimal phases for training neural networks, offering new predictions for resource-efficient large model training.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight/avsxwicpak/cover.png"/></item><item><title>A Neural Network Approach for Efficiently Answering Most Probable Explanation Queries in Probabilistic Models</title><link>https://deep-diver.github.io/neurips2024/spotlight/ufppf9ghzp/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight/ufppf9ghzp/</guid><description>A novel neural network efficiently answers arbitrary Most Probable Explanation (MPE) queries in large probabilistic models, eliminating the need for slow inference algorithms.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight/ufppf9ghzp/cover.png"/></item><item><title>Approximating the Top Eigenvector in Random Order Streams</title><link>https://deep-diver.github.io/neurips2024/spotlight/gitgmieinf/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight/gitgmieinf/</guid><description>Random-order stream data necessitates efficient top eigenvector approximation; this paper presents novel algorithms with improved space complexity, achieving near-optimal bounds.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight/gitgmieinf/cover.png"/></item><item><title>Approximation-Aware Bayesian Optimization</title><link>https://deep-diver.github.io/neurips2024/spotlight/t7euv5dl5m/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight/t7euv5dl5m/</guid><description>Approximation-Aware Bayesian Optimization (AABO) boosts high-dimensional Bayesian optimization by jointly optimizing model approximation and data acquisition, achieving superior efficiency and perform&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight/t7euv5dl5m/cover.png"/></item><item><title>Are Graph Neural Networks Optimal Approximation Algorithms?</title><link>https://deep-diver.github.io/neurips2024/spotlight/sxrblm9ams/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight/sxrblm9ams/</guid><description>Graph Neural Networks (GNNs) learn optimal approximation algorithms for combinatorial optimization problems, achieving high-quality solutions for Max-Cut, Min-Vertex-Cover, and Max-3-SAT, while also p&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight/sxrblm9ams/cover.png"/></item><item><title>Axioms for AI Alignment from Human Feedback</title><link>https://deep-diver.github.io/neurips2024/spotlight/cmbjkpruvw/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight/cmbjkpruvw/</guid><description>This paper revolutionizes AI alignment by applying social choice theory axioms to RLHF, exposing flaws in existing methods and proposing novel, axiomatically guaranteed reward learning rules.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight/cmbjkpruvw/cover.png"/></item><item><title>Barely Random Algorithms and Collective Metrical Task Systems</title><link>https://deep-diver.github.io/neurips2024/spotlight/oajhfvrtbq/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight/oajhfvrtbq/</guid><description>Randomness-efficient algorithms are developed for online decision making, requiring only 2log n random bits and achieving near-optimal competitiveness for metrical task systems.</description></item><item><title>Energy-Guided Continuous Entropic Barycenter Estimation for General Costs</title><link>https://deep-diver.github.io/neurips2024/spotlight/jzhfrloqdq/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight/jzhfrloqdq/</guid><description>New algorithm approximates continuous Entropic Optimal Transport (EOT) barycenters for any cost function, offering quality bounds and seamless EBM integration.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight/jzhfrloqdq/cover.png"/></item><item><title>Expectile Regularization for Fast and Accurate Training of Neural Optimal Transport</title><link>https://deep-diver.github.io/neurips2024/spotlight/4da5vaphfb/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight/4da5vaphfb/</guid><description>ENOT, a new Neural Optimal Transport training method, achieves 3x quality and 10x speed improvements by using expectile regularization to stabilize the learning process.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight/4da5vaphfb/cover.png"/></item><item><title>Exploring Jacobian Inexactness in Second-Order Methods for Variational Inequalities: Lower Bounds, Optimal Algorithms and Quasi-Newton Approximations</title><link>https://deep-diver.github.io/neurips2024/spotlight/uvfdaefr9x/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight/uvfdaefr9x/</guid><description>VIJI, a novel second-order algorithm, achieves optimal convergence rates for variational inequalities even with inexact Jacobian information, bridging the gap between theory and practice in machine le&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight/uvfdaefr9x/cover.png"/></item><item><title>Get rich quick: exact solutions reveal how unbalanced initializations promote rapid feature learning</title><link>https://deep-diver.github.io/neurips2024/spotlight/enm94i7r3a/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight/enm94i7r3a/</guid><description>Unbalanced initializations dramatically accelerate neural network feature learning by modifying the geometry of learning trajectories, enabling faster feature extraction and improved generalization.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight/enm94i7r3a/cover.png"/></item><item><title>Identifying Equivalent Training Dynamics</title><link>https://deep-diver.github.io/neurips2024/spotlight/boyvesx7pk/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight/boyvesx7pk/</guid><description>New framework uses Koopman operator theory to identify equivalent training dynamics in deep neural networks, enabling quantitative comparison of different architectures and optimization methods.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight/boyvesx7pk/cover.png"/></item><item><title>Learning diffusion at lightspeed</title><link>https://deep-diver.github.io/neurips2024/oral/y10avdrfnk/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/oral/y10avdrfnk/</guid><description>JKOnet* learns diffusion processes at unprecedented speed and accuracy by directly minimizing a simple quadratic loss function, bypassing complex bilevel optimization problems.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/oral/y10avdrfnk/cover.png"/></item><item><title>Learning Generalized Linear Programming Value Functions</title><link>https://deep-diver.github.io/neurips2024/spotlight/vxijl0ioid/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight/vxijl0ioid/</guid><description>Learn optimal LP values faster with a novel neural network method!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight/vxijl0ioid/cover.png"/></item><item><title>Learning Social Welfare Functions</title><link>https://deep-diver.github.io/neurips2024/spotlight/7o6ktaar8n/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight/7o6ktaar8n/</guid><description>Learning social welfare functions from past decisions is possible! This paper shows how to efficiently learn power mean functions, a widely used family, using both cardinal and pairwise welfare compar&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight/7o6ktaar8n/cover.png"/></item><item><title>Learning to Mitigate Externalities: the Coase Theorem with Hindsight Rationality</title><link>https://deep-diver.github.io/neurips2024/spotlight/omyzrkacme/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight/omyzrkacme/</guid><description>Economists learn to resolve externalities efficiently even when players lack perfect information, maximizing social welfare by leveraging bargaining and online learning.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight/omyzrkacme/cover.png"/></item><item><title>Learning to Solve Quadratic Unconstrained Binary Optimization in a Classification Way</title><link>https://deep-diver.github.io/neurips2024/spotlight/p43obiwjfw/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight/p43obiwjfw/</guid><description>Researchers developed Value Classification Model (VCM), a neural solver that swiftly solves quadratic unconstrained binary optimization (QUBO) problems by directly generating solutions using a classif&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight/p43obiwjfw/cover.png"/></item><item><title>Mean-Field Langevin Dynamics for Signed Measures via a Bilevel Approach</title><link>https://deep-diver.github.io/neurips2024/spotlight/oo7hy9kmk6/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight/oo7hy9kmk6/</guid><description>This paper presents a novel bilevel approach to extend mean-field Langevin dynamics to solve convex optimization problems over signed measures, achieving stronger guarantees and faster convergence rat&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight/oo7hy9kmk6/cover.png"/></item><item><title>Mechanism design augmented with output advice</title><link>https://deep-diver.github.io/neurips2024/spotlight/ajgks7qozm/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight/ajgks7qozm/</guid><description>Mechanism design enhanced with output advice improves approximation guarantees by using imperfect predictions of the output, not agent types, offering robust, practical solutions.</description></item><item><title>Metric Transforms and Low Rank Representations of Kernels for Fast Attention</title><link>https://deep-diver.github.io/neurips2024/spotlight/k9pxsryuwg/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight/k9pxsryuwg/</guid><description>Researchers unveil novel linear-algebraic tools revealing the limits of fast attention, classifying positive definite kernels for Manhattan distance, and fully characterizing metric transforms for Man&amp;hellip;</description></item><item><title>Minimum Entropy Coupling with Bottleneck</title><link>https://deep-diver.github.io/neurips2024/spotlight/ylmym7shde/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight/ylmym7shde/</guid><description>A novel lossy compression framework, Minimum Entropy Coupling with Bottleneck (MEC-B), extends existing methods by integrating a bottleneck for controlled stochasticity, enhancing performance in scen&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight/ylmym7shde/cover.png"/></item><item><title>Mirror and Preconditioned Gradient Descent in Wasserstein Space</title><link>https://deep-diver.github.io/neurips2024/spotlight/n12b6wva55/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight/n12b6wva55/</guid><description>This paper presents novel mirror and preconditioned gradient descent algorithms for optimizing functionals over Wasserstein space, offering improved convergence and efficiency for various machine lear&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight/n12b6wva55/cover.png"/></item><item><title>Multiclass Transductive Online Learning</title><link>https://deep-diver.github.io/neurips2024/spotlight/3erevfwalz/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight/3erevfwalz/</guid><description>Unbounded label spaces conquered! New algorithm achieves optimal mistake bounds in multiclass transductive online learning.</description></item><item><title>Nearly Optimal Approximation of Matrix Functions by the Lanczos Method</title><link>https://deep-diver.github.io/neurips2024/spotlight/3s8v8qp9xv/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight/3s8v8qp9xv/</guid><description>Lanczos-FA, a simple algorithm for approximating matrix functions, surprisingly outperforms newer methods; this paper proves its near-optimality for rational functions, explaining its practical succes&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight/3s8v8qp9xv/cover.png"/></item><item><title>Neural Pfaffians: Solving Many Many-Electron SchrÃ¶dinger Equations</title><link>https://deep-diver.github.io/neurips2024/oral/hrknicwm3e/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/oral/hrknicwm3e/</guid><description>Neural Pfaffians revolutionize many-electron SchrÃ¶dinger equation solutions by using fully learnable neural wave functions based on Pfaffians, achieving unprecedented accuracy and generalizability acr&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/oral/hrknicwm3e/cover.png"/></item><item><title>No-regret Learning in Harmonic Games: Extrapolation in the Face of Conflicting Interests</title><link>https://deep-diver.github.io/neurips2024/spotlight/hw9s9vy5gz/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight/hw9s9vy5gz/</guid><description>Extrapolated FTRL ensures Nash equilibrium convergence in harmonic games, defying standard no-regret learning limitations.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight/hw9s9vy5gz/cover.png"/></item><item><title>Non-asymptotic Global Convergence Analysis of BFGS with the Armijo-Wolfe Line Search</title><link>https://deep-diver.github.io/neurips2024/spotlight/mkzpn2t87c/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight/mkzpn2t87c/</guid><description>BFGS algorithm achieves global linear and superlinear convergence rates with inexact Armijo-Wolfe line search, even without precise Hessian knowledge.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight/mkzpn2t87c/cover.png"/></item><item><title>Online Bayesian Persuasion Without a Clue</title><link>https://deep-diver.github.io/neurips2024/spotlight/xnpvz8e1ty/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight/xnpvz8e1ty/</guid><description>Researchers developed a novel online Bayesian persuasion algorithm that achieves sublinear regret without prior knowledge of the receiver or the state distribution, providing tight theoretical guarant&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight/xnpvz8e1ty/cover.png"/></item><item><title>Online Convex Optimisation: The Optimal Switching Regret for all Segmentations Simultaneously</title><link>https://deep-diver.github.io/neurips2024/spotlight/u6xxyud3ro/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight/u6xxyud3ro/</guid><description>Algorithm RESET achieves optimal switching regret simultaneously across all segmentations, offering efficiency and parameter-free operation.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight/u6xxyud3ro/cover.png"/></item><item><title>Optimal Algorithms for Online Convex Optimization with Adversarial Constraints</title><link>https://deep-diver.github.io/neurips2024/spotlight/txffvjmnby/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight/txffvjmnby/</guid><description>Optimal algorithms for online convex optimization with adversarial constraints are developed, achieving O(âT) regret and Ã(âT) constraint violationâa breakthrough in the field.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight/txffvjmnby/cover.png"/></item><item><title>Optimal Parallelization of Boosting</title><link>https://deep-diver.github.io/neurips2024/oral/rtz4df9if1/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/oral/rtz4df9if1/</guid><description>This paper closes the performance gap in parallel boosting algorithms by presenting improved lower bounds and a novel algorithm matching these bounds, settling the parallel complexity of sample-optima&amp;hellip;</description></item><item><title>Optimization Algorithm Design via Electric Circuits</title><link>https://deep-diver.github.io/neurips2024/spotlight/9jmt1eer9p/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight/9jmt1eer9p/</guid><description>Design provably convergent optimization algorithms swiftly using electric circuit analogies; a novel methodology automating discretization for diverse algorithms.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight/9jmt1eer9p/cover.png"/></item><item><title>Paths to Equilibrium in Games</title><link>https://deep-diver.github.io/neurips2024/spotlight/lxxiiinmuf/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight/lxxiiinmuf/</guid><description>In n-player games, a satisficing path always exists leading from any initial strategy profile to a Nash equilibrium by allowing unsatisfied players to explore suboptimal strategies.</description></item><item><title>Principled Bayesian Optimization in Collaboration with Human Experts</title><link>https://deep-diver.github.io/neurips2024/spotlight/idn9sikgly/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight/idn9sikgly/</guid><description>COBOL: a novel Bayesian Optimization algorithm leverages human expert advice via binary labels, achieving both fast convergence and robustness to noisy input, while guaranteeing minimal expert effort.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight/idn9sikgly/cover.png"/></item><item><title>Reliable Learning of Halfspaces under Gaussian Marginals</title><link>https://deep-diver.github.io/neurips2024/spotlight/0lb8vzt1db/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight/0lb8vzt1db/</guid><description>New algorithm reliably learns Gaussian halfspaces with significantly improved sample and computational complexity compared to existing methods, offering strong computational separation from standard a&amp;hellip;</description></item><item><title>Sample Complexity of Posted Pricing for a Single Item</title><link>https://deep-diver.github.io/neurips2024/spotlight/ek1tyhcb3w/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight/ek1tyhcb3w/</guid><description>This paper reveals how many buyer samples are needed to set near-optimal posted prices for a single item, resolving a fundamental problem in online markets and offering both theoretical and practical &amp;hellip;</description></item><item><title>Small coresets via negative dependence: DPPs, linear statistics, and concentration</title><link>https://deep-diver.github.io/neurips2024/spotlight/jd3mshmttl/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight/jd3mshmttl/</guid><description>DPPs create smaller, more accurate coresets than existing methods, improving machine learning efficiency without sacrificing accuracy.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight/jd3mshmttl/cover.png"/></item><item><title>Statistical Estimation in the Spiked Tensor Model via the Quantum Approximate Optimization Algorithm</title><link>https://deep-diver.github.io/neurips2024/spotlight/wtlvxdzhmp/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight/wtlvxdzhmp/</guid><description>Quantum Approximate Optimization Algorithm (QAOA) achieves weak recovery in spiked tensor models matching classical methods, but with potential constant factor advantages for certain parameters.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight/wtlvxdzhmp/cover.png"/></item><item><title>Symmetries in Overparametrized Neural Networks: A Mean Field View</title><link>https://deep-diver.github.io/neurips2024/spotlight/l86glqncuj/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight/l86glqncuj/</guid><description>Overparametrized neural networks&amp;rsquo; learning dynamics are analyzed under data symmetries using mean-field theory, revealing that data augmentation, feature averaging, and equivariant architectures asymp&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight/l86glqncuj/cover.png"/></item><item><title>The Road Less Scheduled</title><link>https://deep-diver.github.io/neurips2024/oral/0xenkkenui/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/oral/0xenkkenui/</guid><description>Revolutionizing machine learning, Schedule-Free optimization achieves state-of-the-art results without needing learning rate schedules, simplifying training and improving efficiency.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/oral/0xenkkenui/cover.png"/></item><item><title>Validating Climate Models with Spherical Convolutional Wasserstein Distance</title><link>https://deep-diver.github.io/neurips2024/spotlight/mmsffib6pi/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight/mmsffib6pi/</guid><description>Researchers developed Spherical Convolutional Wasserstein Distance (SCWD) to more accurately validate climate models by considering spatial variability and local distributional differences.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight/mmsffib6pi/cover.png"/></item><item><title>What type of inference is planning?</title><link>https://deep-diver.github.io/neurips2024/spotlight/txsrgrzicz/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight/txsrgrzicz/</guid><description>Planning is redefined as a distinct inference type within a variational framework, enabling efficient approximate planning in complex environments.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight/txsrgrzicz/cover.png"/></item><item><title>When Is Inductive Inference Possible?</title><link>https://deep-diver.github.io/neurips2024/spotlight/2agcshccuv/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight/2agcshccuv/</guid><description>This paper provides a tight characterization of inductive inference, proving it&amp;rsquo;s possible if and only if the hypothesis class is a countable union of online learnable classes, resolving a long-standi&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight/2agcshccuv/cover.png"/></item></channel></rss>