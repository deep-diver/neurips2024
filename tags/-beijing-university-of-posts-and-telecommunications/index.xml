<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>üè¢ Beijing University of Posts and Telecommunications on NeurIPS 2024</title><link>https://deep-diver.github.io/neurips2024/tags/-beijing-university-of-posts-and-telecommunications/</link><description>Recent content in üè¢ Beijing University of Posts and Telecommunications on NeurIPS 2024</description><generator>Hugo -- gohugo.io</generator><language>en</language><copyright>¬© 2024 AI Paper Reviewer</copyright><lastBuildDate>Thu, 26 Sep 2024 00:00:00 +0000</lastBuildDate><atom:link href="https://deep-diver.github.io/neurips2024/tags/-beijing-university-of-posts-and-telecommunications/index.xml" rel="self" type="application/rss+xml"/><item><title>Animal-Bench: Benchmarking Multimodal Video Models for Animal-centric Video Understanding</title><link>https://deep-diver.github.io/neurips2024/posters/dexm7d1h6e/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/dexm7d1h6e/</guid><description>Animal-Bench, a new benchmark, comprehensively evaluates multimodal video models for animal-centric video understanding, featuring 13 diverse tasks across 7 animal categories and 819 species.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/dexm7d1h6e/cover.png"/></item><item><title>LT-Defense: Searching-free Backdoor Defense via Exploiting the Long-tailed Effect</title><link>https://deep-diver.github.io/neurips2024/posters/jdcmwf06c6/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/jdcmwf06c6/</guid><description>LT-Defense: a searching-free backdoor defense for language models leveraging the long-tailed effect of poisoned data. It achieves 98% accuracy across 1440 models with less than 1% time cost of existin&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/jdcmwf06c6/cover.png"/></item><item><title>Lumina-Next : Making Lumina-T2X Stronger and Faster with Next-DiT</title><link>https://deep-diver.github.io/neurips2024/posters/ieydf9tz2u/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/ieydf9tz2u/</guid><description>Lumina-Next supercharges image generation: faster, more efficient, and better resolution with new architecture and sampling techniques.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/ieydf9tz2u/cover.png"/></item><item><title>Physics-Constrained Comprehensive Optical Neural Networks</title><link>https://deep-diver.github.io/neurips2024/posters/qhuxu2ilig/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/qhuxu2ilig/</guid><description>Physics-constrained learning significantly boosts optical neural network accuracy by addressing systematic physical errors, achieving state-of-the-art results on image classification tasks.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/qhuxu2ilig/cover.png"/></item><item><title>Rethinking Decoders for Transformer-based Semantic Segmentation: Compression is All You Need</title><link>https://deep-diver.github.io/neurips2024/posters/ihjopnnzb9/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/ihjopnnzb9/</guid><description>DEPICT: A new white-box decoder for Transformer-based semantic segmentation, achieving better performance with fewer parameters by leveraging the principle of compression and connecting Transformer de&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/ihjopnnzb9/cover.png"/></item><item><title>Rethinking No-reference Image Exposure Assessment from Holism to Pixel: Models, Datasets and Benchmarks</title><link>https://deep-diver.github.io/neurips2024/posters/zvrqeopioq/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/zvrqeopioq/</guid><description>Revolutionizing image exposure assessment, Pixel-level IEA Network (P-IEANet) achieves state-of-the-art performance with a novel pixel-level approach, a new dataset (IEA40K), and a benchmark of 19 met&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/zvrqeopioq/cover.png"/></item></channel></rss>