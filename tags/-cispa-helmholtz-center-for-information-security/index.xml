<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>üè¢ CISPA Helmholtz Center for Information Security on NeurIPS 2024</title><link>https://deep-diver.github.io/neurips2024/tags/-cispa-helmholtz-center-for-information-security/</link><description>Recent content in üè¢ CISPA Helmholtz Center for Information Security on NeurIPS 2024</description><generator>Hugo -- gohugo.io</generator><language>en</language><copyright>¬© 2024 AI Paper Reviewer</copyright><lastBuildDate>Thu, 26 Sep 2024 00:00:00 +0000</lastBuildDate><atom:link href="https://deep-diver.github.io/neurips2024/tags/-cispa-helmholtz-center-for-information-security/index.xml" rel="self" type="application/rss+xml"/><item><title>Causal Discovery from Event Sequences by Local Cause-Effect Attribution</title><link>https://deep-diver.github.io/neurips2024/posters/y9zirxshzj/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/y9zirxshzj/</guid><description>CASCADE algorithm unveils hidden causal structures in event sequences by minimizing description length, surpassing existing Granger causality-based methods.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/y9zirxshzj/cover.png"/></item><item><title>Language Models as Zero-shot Lossless Gradient Compressors: Towards General Neural Parameter Prior Models</title><link>https://deep-diver.github.io/neurips2024/posters/77kcjzvpoa/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/77kcjzvpoa/</guid><description>Large language models (LLMs) achieve lossless gradient compression, surpassing existing methods by up to 17.2%, thereby advancing distributed learning efficiency.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/77kcjzvpoa/cover.png"/></item><item><title>Learning Better Representations From Less Data For Propositional Satisfiability</title><link>https://deep-diver.github.io/neurips2024/spotlight-ai-theory/vmshnv8cvs/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-ai-theory/vmshnv8cvs/</guid><description>NeuRes, a novel neuro-symbolic approach, achieves superior SAT solving accuracy using significantly less training data than existing methods by combining certificate-driven learning with expert iterat&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-ai-theory/vmshnv8cvs/cover.png"/></item><item><title>Open LLMs are Necessary for Current Private Adaptations and Outperform their Closed Alternatives</title><link>https://deep-diver.github.io/neurips2024/posters/jf40h5prw0/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/jf40h5prw0/</guid><description>Open LLMs outperform closed alternatives for private data adaptation, offering superior privacy, performance, and lower costs.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/jf40h5prw0/cover.png"/></item></channel></rss>