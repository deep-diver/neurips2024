<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>üè¢ Nanjing University on NeurIPS 2024</title><link>https://deep-diver.github.io/neurips2024/tags/-nanjing-university/</link><description>Recent content in üè¢ Nanjing University on NeurIPS 2024</description><generator>Hugo -- gohugo.io</generator><language>en</language><copyright>¬© 2024 AI Paper Reviewer</copyright><lastBuildDate>Thu, 26 Sep 2024 00:00:00 +0000</lastBuildDate><atom:link href="https://deep-diver.github.io/neurips2024/tags/-nanjing-university/index.xml" rel="self" type="application/rss+xml"/><item><title>A Simple and Optimal Approach for Universal Online Learning with Gradient Variations</title><link>https://deep-diver.github.io/neurips2024/posters/yo5dvychzr/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/yo5dvychzr/</guid><description>A novel universal online learning algorithm achieves optimal gradient-variation regret across diverse function curvatures, boasting efficiency with only one gradient query per round.</description></item><item><title>Adaptive Variance Reduction for Stochastic Optimization under Weaker Assumptions</title><link>https://deep-diver.github.io/neurips2024/posters/tmqh8prqlc/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/tmqh8prqlc/</guid><description>Adaptive STORM achieves optimal convergence rates for stochastic optimization of non-convex functions under weaker assumptions, eliminating the need for bounded gradients or function values and removi&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/tmqh8prqlc/cover.png"/></item><item><title>EASI: Evolutionary Adversarial Simulator Identification for Sim-to-Real Transfer</title><link>https://deep-diver.github.io/neurips2024/posters/dqigggdoma/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/dqigggdoma/</guid><description>EASI: Evolutionary Adversarial Simulator Identification bridges the reality gap in robotics by using GAN and ES to find optimal simulator parameters, enabling seamless sim-to-real transfer with minima&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/dqigggdoma/cover.png"/></item><item><title>Efficient Recurrent Off-Policy RL Requires a Context-Encoder-Specific Learning Rate</title><link>https://deep-diver.github.io/neurips2024/posters/tswot8ttko/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/tswot8ttko/</guid><description>Recurrent off-policy RL, while robust, suffers from training instability. RESEL, a novel algorithm, solves this by using a context-encoder-specific learning rate, significantly improving stability an&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/tswot8ttko/cover.png"/></item><item><title>Exploring and Exploiting the Asymmetric Valley of Deep Neural Networks</title><link>https://deep-diver.github.io/neurips2024/posters/cw0ovwekku/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/cw0ovwekku/</guid><description>Deep neural network training reveals asymmetric loss valleys, impacting model fusion and federated learning; sign consistency between noise and convergence is key.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/cw0ovwekku/cover.png"/></item><item><title>Exploring DCN-like architecture for fast image generation with arbitrary resolution</title><link>https://deep-diver.github.io/neurips2024/posters/e57b7bfa2b/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/e57b7bfa2b/</guid><description>FlowDCN: A purely convolutional generative model achieves state-of-the-art image generation speed and quality at arbitrary resolutions, surpassing transformer-based models.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/e57b7bfa2b/cover.png"/></item><item><title>Monte Carlo Tree Search based Space Transfer for Black Box Optimization</title><link>https://deep-diver.github.io/neurips2024/spotlight-others/t5ufifmdbq/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-others/t5ufifmdbq/</guid><description>MCTS-transfer: Iteratively refining Bayesian optimization via Monte Carlo tree search for efficient black-box optimization using transfer learning.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-others/t5ufifmdbq/cover.png"/></item><item><title>Neuro-Symbolic Data Generation for Math Reasoning</title><link>https://deep-diver.github.io/neurips2024/posters/cicmzglyzw/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/cicmzglyzw/</guid><description>Neuro-symbolic framework generates high-quality mathematical datasets, enhancing LLMs&amp;rsquo; mathematical reasoning capabilities and surpassing state-of-the-art counterparts.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/cicmzglyzw/cover.png"/></item><item><title>On the Ability of Developers' Training Data Preservation of Learnware</title><link>https://deep-diver.github.io/neurips2024/posters/wsqdjhpuhn/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/wsqdjhpuhn/</guid><description>Learnware systems enable model reuse; this paper proves RKME specifications protect developers&amp;rsquo; training data while enabling effective model identification.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/wsqdjhpuhn/cover.png"/></item><item><title>Policy Learning from Tutorial Books via Understanding, Rehearsing and Introspecting</title><link>https://deep-diver.github.io/neurips2024/oral-large-language-models/ddak3nsqqm/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/oral-large-language-models/ddak3nsqqm/</guid><description>Researchers developed Policy Learning from tutorial Books (PLfB), a novel method that trains AI agents using knowledge from tutorial books instead of relying solely on real-world data.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/oral-large-language-models/ddak3nsqqm/cover.png"/></item><item><title>Reinforcement Learning Policy as Macro Regulator Rather than Macro Placer</title><link>https://deep-diver.github.io/neurips2024/posters/jewzstuavo/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/jewzstuavo/</guid><description>Reinforcement learning refines existing macro placements, enhancing chip design by improving power, performance, and area (PPA) metrics and integrating the often-overlooked metric of regularity.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/jewzstuavo/cover.png"/></item><item><title>SCaR: Refining Skill Chaining for Long-Horizon Robotic Manipulation via Dual Regularization</title><link>https://deep-diver.github.io/neurips2024/posters/rnxjc4vtvi/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/rnxjc4vtvi/</guid><description>SCaR refines skill chaining for long-horizon robotic manipulation via dual regularization, achieving higher success rates and robustness.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/rnxjc4vtvi/cover.png"/></item><item><title>START: A Generalized State Space Model with Saliency-Driven Token-Aware Transformation</title><link>https://deep-diver.github.io/neurips2024/posters/madgq1hh3l/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/madgq1hh3l/</guid><description>START, a novel SSM-based architecture with saliency-driven token-aware transformation, achieves state-of-the-art domain generalization performance with efficient linear complexity.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/madgq1hh3l/cover.png"/></item><item><title>Universal Online Convex Optimization with $1$ Projection per Round</title><link>https://deep-diver.github.io/neurips2024/posters/xnncvkbwws/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/xnncvkbwws/</guid><description>This paper introduces a novel universal online convex optimization algorithm needing only one projection per round, achieving optimal regret bounds for various function types, including general convex&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/xnncvkbwws/cover.png"/></item></channel></rss>