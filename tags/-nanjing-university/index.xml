<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>üè¢ Nanjing University on NeurIPS 2024</title><link>https://deep-diver.github.io/neurips2024/tags/-nanjing-university/</link><description>Recent content in üè¢ Nanjing University on NeurIPS 2024</description><generator>Hugo -- gohugo.io</generator><language>en</language><copyright>¬© 2025 AI Paper Reviewer</copyright><lastBuildDate>Thu, 26 Sep 2024 00:00:00 +0000</lastBuildDate><atom:link href="https://deep-diver.github.io/neurips2024/tags/-nanjing-university/index.xml" rel="self" type="application/rss+xml"/><item><title>A Simple and Optimal Approach for Universal Online Learning with Gradient Variations</title><link>https://deep-diver.github.io/neurips2024/posters/yo5dvychzr/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/yo5dvychzr/</guid><description>A novel universal online learning algorithm achieves optimal gradient-variation regret across diverse function curvatures, boasting efficiency with only one gradient query per round.</description></item><item><title>Adaptive Variance Reduction for Stochastic Optimization under Weaker Assumptions</title><link>https://deep-diver.github.io/neurips2024/posters/tmqh8prqlc/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/tmqh8prqlc/</guid><description>Adaptive STORM achieves optimal convergence rates for stochastic optimization of non-convex functions under weaker assumptions, eliminating the need for bounded gradients or function values and removi&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/tmqh8prqlc/cover.png"/></item><item><title>All-in-One Image Coding for Joint Human-Machine Vision with Multi-Path Aggregation</title><link>https://deep-diver.github.io/neurips2024/posters/7vsx6pxaoh/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/7vsx6pxaoh/</guid><description>Multi-Path Aggregation (MPA) achieves comparable performance to state-of-the-art methods in multi-task image coding, by unifying feature representations with a novel all-in-one architecture and a two-&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/7vsx6pxaoh/cover.png"/></item><item><title>EASI: Evolutionary Adversarial Simulator Identification for Sim-to-Real Transfer</title><link>https://deep-diver.github.io/neurips2024/posters/dqigggdoma/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/dqigggdoma/</guid><description>EASI: Evolutionary Adversarial Simulator Identification bridges the reality gap in robotics by using GAN and ES to find optimal simulator parameters, enabling seamless sim-to-real transfer with minima&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/dqigggdoma/cover.png"/></item><item><title>Efficient Recurrent Off-Policy RL Requires a Context-Encoder-Specific Learning Rate</title><link>https://deep-diver.github.io/neurips2024/posters/tswot8ttko/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/tswot8ttko/</guid><description>Recurrent off-policy RL, while robust, suffers from training instability. RESEL, a novel algorithm, solves this by using a context-encoder-specific learning rate, significantly improving stability an&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/tswot8ttko/cover.png"/></item><item><title>Exploring and Exploiting the Asymmetric Valley of Deep Neural Networks</title><link>https://deep-diver.github.io/neurips2024/posters/cw0ovwekku/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/cw0ovwekku/</guid><description>Deep neural network training reveals asymmetric loss valleys, impacting model fusion and federated learning; sign consistency between noise and convergence is key.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/cw0ovwekku/cover.png"/></item><item><title>Exploring DCN-like architecture for fast image generation with arbitrary resolution</title><link>https://deep-diver.github.io/neurips2024/posters/e57b7bfa2b/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/e57b7bfa2b/</guid><description>FlowDCN: A purely convolutional generative model achieves state-of-the-art image generation speed and quality at arbitrary resolutions, surpassing transformer-based models.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/e57b7bfa2b/cover.png"/></item><item><title>IODA: Instance-Guided One-shot Domain Adaptation for Super-Resolution</title><link>https://deep-diver.github.io/neurips2024/posters/qbvt3ocqxb/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/qbvt3ocqxb/</guid><description>IODA achieves efficient one-shot domain adaptation for super-resolution using a novel instance-guided strategy and image-level domain alignment, significantly improving performance with limited target&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/qbvt3ocqxb/cover.png"/></item><item><title>Meta-DT: Offline Meta-RL as Conditional Sequence Modeling with World Model Disentanglement</title><link>https://deep-diver.github.io/neurips2024/posters/u9mzodokzu/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/u9mzodokzu/</guid><description>Meta-DT: Offline meta-RL masters unseen tasks via conditional sequence modeling and world model disentanglement, showcasing superior few-shot and zero-shot generalization.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/u9mzodokzu/cover.png"/></item><item><title>Monte Carlo Tree Search based Space Transfer for Black Box Optimization</title><link>https://deep-diver.github.io/neurips2024/spotlight-others/t5ufifmdbq/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-others/t5ufifmdbq/</guid><description>MCTS-transfer: Iteratively refining Bayesian optimization via Monte Carlo tree search for efficient black-box optimization using transfer learning.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-others/t5ufifmdbq/cover.png"/></item><item><title>Neuro-Symbolic Data Generation for Math Reasoning</title><link>https://deep-diver.github.io/neurips2024/posters/cicmzglyzw/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/cicmzglyzw/</guid><description>Neuro-symbolic framework generates high-quality mathematical datasets, enhancing LLMs&amp;rsquo; mathematical reasoning capabilities and surpassing state-of-the-art counterparts.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/cicmzglyzw/cover.png"/></item><item><title>On the Ability of Developers' Training Data Preservation of Learnware</title><link>https://deep-diver.github.io/neurips2024/posters/wsqdjhpuhn/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/wsqdjhpuhn/</guid><description>Learnware systems enable model reuse; this paper proves RKME specifications protect developers&amp;rsquo; training data while enabling effective model identification.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/wsqdjhpuhn/cover.png"/></item><item><title>Online Composite Optimization Between Stochastic and Adversarial Environments</title><link>https://deep-diver.github.io/neurips2024/posters/mbeb5akmmk/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/mbeb5akmmk/</guid><description>Researchers achieve optimal regret bounds in online composite optimization under stochastic and adversarial settings using a novel optimistic composite mirror descent algorithm and a universal strateg&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/mbeb5akmmk/cover.png"/></item><item><title>Policy Learning from Tutorial Books via Understanding, Rehearsing and Introspecting</title><link>https://deep-diver.github.io/neurips2024/oral-large-language-models/ddak3nsqqm/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/oral-large-language-models/ddak3nsqqm/</guid><description>Researchers developed Policy Learning from tutorial Books (PLfB), a novel method that trains AI agents using knowledge from tutorial books instead of relying solely on real-world data.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/oral-large-language-models/ddak3nsqqm/cover.png"/></item><item><title>Prism: A Framework for Decoupling and Assessing the Capabilities of VLMs</title><link>https://deep-diver.github.io/neurips2024/posters/qlnxpvvwlx/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/qlnxpvvwlx/</guid><description>Prism: a novel framework disentangles perception and reasoning in Vision-Language Models (VLMs) for improved model assessment and efficient VLM development.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/qlnxpvvwlx/cover.png"/></item><item><title>Reinforcement Learning Policy as Macro Regulator Rather than Macro Placer</title><link>https://deep-diver.github.io/neurips2024/posters/jewzstuavo/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/jewzstuavo/</guid><description>Reinforcement learning refines existing macro placements, enhancing chip design by improving power, performance, and area (PPA) metrics and integrating the often-overlooked metric of regularity.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/jewzstuavo/cover.png"/></item><item><title>SCaR: Refining Skill Chaining for Long-Horizon Robotic Manipulation via Dual Regularization</title><link>https://deep-diver.github.io/neurips2024/posters/rnxjc4vtvi/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/rnxjc4vtvi/</guid><description>SCaR refines skill chaining for long-horizon robotic manipulation via dual regularization, achieving higher success rates and robustness.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/rnxjc4vtvi/cover.png"/></item><item><title>SOFTS: Efficient Multivariate Time Series Forecasting with Series-Core Fusion</title><link>https://deep-diver.github.io/neurips2024/posters/89aui5l1ua/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/89aui5l1ua/</guid><description>SOFTS: An efficient MLP-based model for multivariate time series forecasting using a novel STAR module for efficient channel interaction.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/89aui5l1ua/cover.png"/></item><item><title>START: A Generalized State Space Model with Saliency-Driven Token-Aware Transformation</title><link>https://deep-diver.github.io/neurips2024/posters/madgq1hh3l/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/madgq1hh3l/</guid><description>START, a novel SSM-based architecture with saliency-driven token-aware transformation, achieves state-of-the-art domain generalization performance with efficient linear complexity.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/madgq1hh3l/cover.png"/></item><item><title>Universal Online Convex Optimization with $1$ Projection per Round</title><link>https://deep-diver.github.io/neurips2024/posters/xnncvkbwws/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/xnncvkbwws/</guid><description>This paper introduces a novel universal online convex optimization algorithm needing only one projection per round, achieving optimal regret bounds for various function types, including general convex&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/xnncvkbwws/cover.png"/></item></channel></rss>