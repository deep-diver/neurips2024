<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>üè¢ Huazhong University of Science and Technology on NeurIPS 2024</title><link>https://deep-diver.github.io/neurips2024/tags/-huazhong-university-of-science-and-technology/</link><description>Recent content in üè¢ Huazhong University of Science and Technology on NeurIPS 2024</description><generator>Hugo -- gohugo.io</generator><language>en</language><copyright>¬© 2024 AI Paper Reviewer</copyright><lastBuildDate>Thu, 26 Sep 2024 00:00:00 +0000</lastBuildDate><atom:link href="https://deep-diver.github.io/neurips2024/tags/-huazhong-university-of-science-and-technology/index.xml" rel="self" type="application/rss+xml"/><item><title>A Unified Framework for 3D Scene Understanding</title><link>https://deep-diver.github.io/neurips2024/posters/de1btyyc9a/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/de1btyyc9a/</guid><description>UniSeg3D: One model to rule them all! This unified framework masters six 3D segmentation tasks (panoptic, semantic, instance, interactive, referring, and open-vocabulary) simultaneously, outperforming&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/de1btyyc9a/cover.png"/></item><item><title>Accelerating Nash Equilibrium Convergence in Monte Carlo Settings Through Counterfactual Value Based Fictitious Play</title><link>https://deep-diver.github.io/neurips2024/posters/efd9n5zdfc/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/efd9n5zdfc/</guid><description>MCCFVFP, a novel Monte Carlo-based algorithm, accelerates Nash equilibrium convergence in large-scale games by combining CFR&amp;rsquo;s counterfactual value calculations with fictitious play&amp;rsquo;s best response st&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/efd9n5zdfc/cover.png"/></item><item><title>Diffusion Priors for Variational Likelihood Estimation and Image Denoising</title><link>https://deep-diver.github.io/neurips2024/spotlight-others/oukw8cuiuy/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-others/oukw8cuiuy/</guid><description>Adaptive likelihood estimation and MAP inference during reverse diffusion tackles real-world image noise.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-others/oukw8cuiuy/cover.png"/></item><item><title>Is the MMI Criterion Necessary for Interpretability? Degenerating Non-causal Features to Plain Noise for Self-Rationalization</title><link>https://deep-diver.github.io/neurips2024/posters/eaqcvzx30k/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/eaqcvzx30k/</guid><description>New criterion maximizes remaining discrepancy after rationale removal, treating spurious features as noise, improving rationale extraction.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/eaqcvzx30k/cover.png"/></item><item><title>Leveraging Contrastive Learning for Enhanced Node Representations in Tokenized Graph Transformers</title><link>https://deep-diver.github.io/neurips2024/posters/u6fuikzt1k/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/u6fuikzt1k/</guid><description>GCFormer, a novel graph Transformer, enhances node representation learning by employing a hybrid token generator and contrastive learning, outperforming existing methods on various datasets.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/u6fuikzt1k/cover.png"/></item><item><title>Self-Distilled Depth Refinement with Noisy Poisson Fusion</title><link>https://deep-diver.github.io/neurips2024/posters/nequ0ica0s/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/nequ0ica0s/</guid><description>Self-Distilled Depth Refinement (SDDR) tackles noisy depth maps via a novel noisy Poisson fusion approach, achieving significant improvements in depth accuracy and edge quality.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/nequ0ica0s/cover.png"/></item></channel></rss>