<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Few-Shot Learning on NeurIPS 2024</title><link>https://deep-diver.github.io/neurips2024/tags/few-shot-learning/</link><description>Recent content in Few-Shot Learning on NeurIPS 2024</description><generator>Hugo -- gohugo.io</generator><language>en</language><copyright>Â© 2024 AI Paper Reviewer</copyright><lastBuildDate>Thu, 26 Sep 2024 00:00:00 +0000</lastBuildDate><atom:link href="https://deep-diver.github.io/neurips2024/tags/few-shot-learning/index.xml" rel="self" type="application/rss+xml"/><item><title>An Efficient Memory Module for Graph Few-Shot Class-Incremental Learning</title><link>https://deep-diver.github.io/neurips2024/posters/dqdffx3bs5/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/dqdffx3bs5/</guid><description>Mecoin: a novel memory module for efficient graph few-shot class-incremental learning, tackles catastrophic forgetting by employing structured memory units and a memory representation adaptation modul&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/dqdffx3bs5/cover.png"/></item><item><title>Attention Temperature Matters in ViT-Based Cross-Domain Few-Shot Learning</title><link>https://deep-diver.github.io/neurips2024/posters/o8m4rm5mbk/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/o8m4rm5mbk/</guid><description>Boosting Vision Transformer&amp;rsquo;s transferability in cross-domain few-shot learning is achieved by a simple yet effective method: strategically adjusting attention temperature to remedy ineffective target&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/o8m4rm5mbk/cover.png"/></item><item><title>Be Confident in What You Know: Bayesian Parameter Efficient Fine-Tuning of Vision Foundation Models</title><link>https://deep-diver.github.io/neurips2024/posters/loqck0qruu/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/loqck0qruu/</guid><description>Bayesian-PEFT boosts vision model accuracy and confidence in few-shot learning by integrating Bayesian components into PEFT, solving the underconfidence problem.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/loqck0qruu/cover.png"/></item><item><title>Breaking Long-Tailed Learning Bottlenecks: A Controllable Paradigm with Hypernetwork-Generated Diverse Experts</title><link>https://deep-diver.github.io/neurips2024/spotlight-others/wppnvpaeyv/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-others/wppnvpaeyv/</guid><description>Controllable long-tailed learning achieved via hypernetwork-generated diverse experts, adapting to user preferences and distribution shifts.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-others/wppnvpaeyv/cover.png"/></item><item><title>D2R2: Diffusion-based Representation with Random Distance Matching for Tabular Few-shot Learning</title><link>https://deep-diver.github.io/neurips2024/posters/ls9e36lkxg/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/ls9e36lkxg/</guid><description>D2R2: A novel diffusion-based model for tabular few-shot learning, achieves state-of-the-art results by leveraging semantic knowledge and distance matching.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/ls9e36lkxg/cover.png"/></item><item><title>Few-Shot Diffusion Models Escape the Curse of Dimensionality</title><link>https://deep-diver.github.io/neurips2024/posters/jrranaazm5/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/jrranaazm5/</guid><description>Few-shot diffusion models efficiently generate customized images; this paper provides the first theoretical explanation, proving improved approximation and optimization bounds, escaping the curse of d&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/jrranaazm5/cover.png"/></item><item><title>Few-Shot Task Learning through Inverse Generative Modeling</title><link>https://deep-diver.github.io/neurips2024/posters/atie6npr5a/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/atie6npr5a/</guid><description>Few-shot task learning through inverse generative modeling (FTL-IGM) enables AI agents to quickly master new tasks from minimal data by leveraging invertible generative models.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/atie6npr5a/cover.png"/></item><item><title>Generate Universal Adversarial Perturbations for Few-Shot Learning</title><link>https://deep-diver.github.io/neurips2024/posters/qlro8o4bol/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/qlro8o4bol/</guid><description>Researchers developed FSAFW, a novel framework generating universal adversarial perturbations effective against various Few-Shot Learning paradigms, surpassing baseline methods by over 16%.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/qlro8o4bol/cover.png"/></item><item><title>Mind the Gap Between Prototypes and Images in Cross-domain Finetuning</title><link>https://deep-diver.github.io/neurips2024/posters/jwlik3kkwq/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/jwlik3kkwq/</guid><description>CoPA improves cross-domain few-shot learning by adapting separate transformations for prototype and image embeddings, significantly enhancing performance and revealing better representation clusters.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/jwlik3kkwq/cover.png"/></item><item><title>OTTER: Effortless Label Distribution Adaptation of Zero-shot Models</title><link>https://deep-diver.github.io/neurips2024/posters/rsawwsbcs7/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/rsawwsbcs7/</guid><description>OTTER effortlessly adapts zero-shot models to new tasks by adjusting predictions using optimal transport, improving accuracy significantly without extra training data.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/rsawwsbcs7/cover.png"/></item><item><title>Pretraining Codomain Attention Neural Operators for Solving Multiphysics PDEs</title><link>https://deep-diver.github.io/neurips2024/posters/wspiduxzyx/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/wspiduxzyx/</guid><description>CoDA-NO, a novel neural operator, revolutionizes multiphysics PDE solving via codomain tokenization, enabling efficient self-supervised pretraining and few-shot learning for superior generalization.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/wspiduxzyx/cover.png"/></item><item><title>Prospective Representation Learning for Non-Exemplar Class-Incremental Learning</title><link>https://deep-diver.github.io/neurips2024/posters/ztdarpmbun/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/ztdarpmbun/</guid><description>Prospective Representation Learning (PRL) revolutionizes non-exemplar class-incremental learning by proactively reserving embedding space for new classes and minimizing the shock of new data on previo&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/ztdarpmbun/cover.png"/></item><item><title>Stepping Forward on the Last Mile</title><link>https://deep-diver.github.io/neurips2024/posters/ych1z6dcto/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/ych1z6dcto/</guid><description>On-device training with fixed-point forward gradients enables efficient model personalization on resource-constrained edge devices, overcoming backpropagation&amp;rsquo;s memory limitations.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/ych1z6dcto/cover.png"/></item><item><title>Test-Time Adaptation Induces Stronger Accuracy and Agreement-on-the-Line</title><link>https://deep-diver.github.io/neurips2024/posters/gixux4vh9t/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/gixux4vh9t/</guid><description>Test-time adaptation strengthens the linear correlation between in- and out-of-distribution accuracy, enabling precise OOD performance prediction and hyperparameter optimization without labeled OOD da&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/gixux4vh9t/cover.png"/></item><item><title>Transformers Learn to Achieve Second-Order Convergence Rates for In-Context Linear Regression</title><link>https://deep-diver.github.io/neurips2024/posters/l8h6cozcbn/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/l8h6cozcbn/</guid><description>Transformers surprisingly learn second-order optimization methods for in-context linear regression, achieving exponentially faster convergence than gradient descent!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/l8h6cozcbn/cover.png"/></item><item><title>Tri-Level Navigator: LLM-Empowered Tri-Level Learning for Time Series OOD Generalization</title><link>https://deep-diver.github.io/neurips2024/posters/a6hzeu4kpo/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/a6hzeu4kpo/</guid><description>LLM-powered Tri-level learning framework enhances time series OOD generalization.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/a6hzeu4kpo/cover.png"/></item></channel></rss>