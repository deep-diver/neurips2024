<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>üè¢ University of Chinese Academy of Sciences on NeurIPS 2024</title><link>https://deep-diver.github.io/neurips2024/tags/-university-of-chinese-academy-of-sciences/</link><description>Recent content in üè¢ University of Chinese Academy of Sciences on NeurIPS 2024</description><generator>Hugo -- gohugo.io</generator><language>en</language><copyright>¬© 2024 AI Paper Reviewer</copyright><lastBuildDate>Thu, 26 Sep 2024 00:00:00 +0000</lastBuildDate><atom:link href="https://deep-diver.github.io/neurips2024/tags/-university-of-chinese-academy-of-sciences/index.xml" rel="self" type="application/rss+xml"/><item><title>Generative Retrieval Meets Multi-Graded Relevance</title><link>https://deep-diver.github.io/neurips2024/spotlight-others/2xtkeyjfjb/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-others/2xtkeyjfjb/</guid><description>GR2, a novel framework, extends generative retrieval to handle multi-graded relevance, addressing limitations of existing binary-relevance approaches by enhancing docid distinctness and implementing m&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-others/2xtkeyjfjb/cover.png"/></item><item><title>Rethinking 3D Convolution in $ll_p$-norm Space</title><link>https://deep-diver.github.io/neurips2024/spotlight-others/kmxdv4blhn/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-others/kmxdv4blhn/</guid><description>L1-norm based 3D convolution achieves competitive performance with lower energy consumption and latency compared to traditional methods, as proven through universal approximation theorem and experimen&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-others/kmxdv4blhn/cover.png"/></item><item><title>VMamba: Visual State Space Model</title><link>https://deep-diver.github.io/neurips2024/spotlight-others/zgtlqqr1k7/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-others/zgtlqqr1k7/</guid><description>VMamba: a vision backbone achieving linear time complexity using Visual State Space (VSS) blocks and 2D Selective Scan (SS2D) for efficient visual representation.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-others/zgtlqqr1k7/cover.png"/></item></channel></rss>