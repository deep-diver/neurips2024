<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>üè¢ University of Chinese Academy of Sciences on NeurIPS 2024</title><link>https://deep-diver.github.io/neurips2024/tags/-university-of-chinese-academy-of-sciences/</link><description>Recent content in üè¢ University of Chinese Academy of Sciences on NeurIPS 2024</description><generator>Hugo -- gohugo.io</generator><language>en</language><copyright>¬© 2024 AI Paper Reviewer</copyright><lastBuildDate>Thu, 26 Sep 2024 00:00:00 +0000</lastBuildDate><atom:link href="https://deep-diver.github.io/neurips2024/tags/-university-of-chinese-academy-of-sciences/index.xml" rel="self" type="application/rss+xml"/><item><title>Dual-frame Fluid Motion Estimation with Test-time Optimization and Zero-divergence Loss</title><link>https://deep-diver.github.io/neurips2024/posters/wobhjs9gqu/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/wobhjs9gqu/</guid><description>Self-supervised dual-frame fluid motion estimation achieves superior accuracy with 99% less training data, using a novel zero-divergence loss and dynamic velocimetry enhancement.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/wobhjs9gqu/cover.png"/></item><item><title>Evaluation of Text-to-Video Generation Models: A Dynamics Perspective</title><link>https://deep-diver.github.io/neurips2024/posters/tmx1aumkl6/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/tmx1aumkl6/</guid><description>DEVIL: a novel text-to-video evaluation protocol focusing on video dynamics, resulting in more realistic video generation.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/tmx1aumkl6/cover.png"/></item><item><title>Generative Retrieval Meets Multi-Graded Relevance</title><link>https://deep-diver.github.io/neurips2024/spotlight-others/2xtkeyjfjb/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-others/2xtkeyjfjb/</guid><description>GR2, a novel framework, extends generative retrieval to handle multi-graded relevance, addressing limitations of existing binary-relevance approaches by enhancing docid distinctness and implementing m&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-others/2xtkeyjfjb/cover.png"/></item><item><title>Rethinking 3D Convolution in $ll_p$-norm Space</title><link>https://deep-diver.github.io/neurips2024/spotlight-others/kmxdv4blhn/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-others/kmxdv4blhn/</guid><description>L1-norm based 3D convolution achieves competitive performance with lower energy consumption and latency compared to traditional methods, as proven through universal approximation theorem and experimen&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-others/kmxdv4blhn/cover.png"/></item><item><title>Trajectory Diffusion for ObjectGoal Navigation</title><link>https://deep-diver.github.io/neurips2024/posters/1gpy0hsv2w/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/1gpy0hsv2w/</guid><description>Trajectory Diffusion (T-Diff) significantly improves object goal navigation by learning sequential planning through trajectory diffusion, resulting in more accurate and efficient navigation.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/1gpy0hsv2w/cover.png"/></item><item><title>VMamba: Visual State Space Model</title><link>https://deep-diver.github.io/neurips2024/spotlight-others/zgtlqqr1k7/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-others/zgtlqqr1k7/</guid><description>VMamba: a vision backbone achieving linear time complexity using Visual State Space (VSS) blocks and 2D Selective Scan (SS2D) for efficient visual representation.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-others/zgtlqqr1k7/cover.png"/></item></channel></rss>