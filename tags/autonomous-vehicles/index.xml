<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Autonomous Vehicles on NeurIPS 2024</title><link>https://deep-diver.github.io/neurips2024/tags/autonomous-vehicles/</link><description>Recent content in Autonomous Vehicles on NeurIPS 2024</description><generator>Hugo -- gohugo.io</generator><language>en</language><copyright>Â© 2024 AI Paper Reviewer</copyright><lastBuildDate>Thu, 26 Sep 2024 00:00:00 +0000</lastBuildDate><atom:link href="https://deep-diver.github.io/neurips2024/tags/autonomous-vehicles/index.xml" rel="self" type="application/rss+xml"/><item><title>Continuously Learning, Adapting, and Improving: A Dual-Process Approach to Autonomous Driving</title><link>https://deep-diver.github.io/neurips2024/posters/y9huwsngrj/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/y9huwsngrj/</guid><description>LeapAD, a novel autonomous driving paradigm, uses a dual-process architecture mirroring human cognition to achieve continuous learning and improved adaptability. Employing a VLM for efficient scene u&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/y9huwsngrj/cover.png"/></item><item><title>Is Your LiDAR Placement Optimized for 3D Scene Understanding?</title><link>https://deep-diver.github.io/neurips2024/spotlight-others/79q206xswc/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-others/79q206xswc/</guid><description>Place3D optimizes LiDAR placement for superior 3D scene understanding.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-others/79q206xswc/cover.png"/></item><item><title>LiT: Unifying LiDAR 'Languages' with LiDAR Translator</title><link>https://deep-diver.github.io/neurips2024/posters/wcx04wn34u/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/wcx04wn34u/</guid><description>LiDAR Translator (LiT) unifies diverse LiDAR data through a novel data-driven translation framework, enabling zero-shot and multi-domain joint learning, thus improving autonomous driving systems.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/wcx04wn34u/cover.png"/></item><item><title>Motion Forecasting in Continuous Driving</title><link>https://deep-diver.github.io/neurips2024/spotlight-others/4mxzxyhmun/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-others/4mxzxyhmun/</guid><description>RealMotion: a novel motion forecasting framework for continuous driving that outperforms existing methods by accumulating historical scene information and sequentially refining predictions, achieving &amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-others/4mxzxyhmun/cover.png"/></item><item><title>On-Road Object Importance Estimation: A New Dataset and A Model with Multi-Fold Top-Down Guidance</title><link>https://deep-diver.github.io/neurips2024/posters/xvtmc9ovx3/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/xvtmc9ovx3/</guid><description>New large-scale dataset and model boost on-road object importance estimation accuracy by 23.1%!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/xvtmc9ovx3/cover.png"/></item><item><title>RCDN: Towards Robust Camera-Insensitivity Collaborative Perception via Dynamic Feature-based 3D Neural Modeling</title><link>https://deep-diver.github.io/neurips2024/posters/xvveszovjo/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/xvveszovjo/</guid><description>RCDN: Robust, camera-insensitive collaborative perception via dynamic 3D neural modeling, overcoming camera failures for high-performance autonomous systems.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/xvveszovjo/cover.png"/></item><item><title>Unveiling the Hidden: Online Vectorized HD Map Construction with Clip-Level Token Interaction and Propagation</title><link>https://deep-diver.github.io/neurips2024/posters/z4evwh484m/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/z4evwh484m/</guid><description>MapUnveiler: a novel paradigm for online vectorized HD map construction that leverages clip-level token interaction and propagation to unveil hidden map elements and achieve state-of-the-art performan&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/z4evwh484m/cover.png"/></item></channel></rss>