<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Autonomous Vehicles on NeurIPS 2024</title><link>https://deep-diver.github.io/neurips2024/tags/autonomous-vehicles/</link><description>Recent content in Autonomous Vehicles on NeurIPS 2024</description><generator>Hugo -- gohugo.io</generator><language>en</language><copyright>Â© 2024 AI Paper Reviewer</copyright><lastBuildDate>Thu, 26 Sep 2024 00:00:00 +0000</lastBuildDate><atom:link href="https://deep-diver.github.io/neurips2024/tags/autonomous-vehicles/index.xml" rel="self" type="application/rss+xml"/><item><title>AlterMOMA: Fusion Redundancy Pruning for Camera-LiDAR Fusion Models with Alternative Modality Masking</title><link>https://deep-diver.github.io/neurips2024/posters/ujwiltnrap/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/ujwiltnrap/</guid><description>AlterMOMA: A novel pruning framework significantly improves camera-LiDAR fusion models by identifying and removing redundant parameters through an alternative modality masking technique, achieving sta&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/ujwiltnrap/cover.png"/></item><item><title>Beware of Road Markings: A New Adversarial Patch Attack to Monocular Depth Estimation</title><link>https://deep-diver.github.io/neurips2024/posters/sath8evs2y/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/sath8evs2y/</guid><description>Researchers developed AdvRM, a new adversarial patch attack against monocular depth estimation models, which effectively camouflages patches as road markings to mislead depth predictions for any obsta&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/sath8evs2y/cover.png"/></item><item><title>Continuously Learning, Adapting, and Improving: A Dual-Process Approach to Autonomous Driving</title><link>https://deep-diver.github.io/neurips2024/posters/y9huwsngrj/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/y9huwsngrj/</guid><description>LeapAD, a novel autonomous driving paradigm, uses a dual-process architecture mirroring human cognition to achieve continuous learning and improved adaptability. Employing a VLM for efficient scene u&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/y9huwsngrj/cover.png"/></item><item><title>DeMo: Decoupling Motion Forecasting into Directional Intentions and Dynamic States</title><link>https://deep-diver.github.io/neurips2024/posters/rbtnrsixsn/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/rbtnrsixsn/</guid><description>DeMo: Decoupling motion forecasting into directional intentions and dynamic states for improved autonomous driving.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/rbtnrsixsn/cover.png"/></item><item><title>Is Your LiDAR Placement Optimized for 3D Scene Understanding?</title><link>https://deep-diver.github.io/neurips2024/spotlight-others/79q206xswc/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-others/79q206xswc/</guid><description>Place3D optimizes LiDAR placement for superior 3D scene understanding.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-others/79q206xswc/cover.png"/></item><item><title>LaKD: Length-agnostic Knowledge Distillation for Trajectory Prediction with Any Length Observations</title><link>https://deep-diver.github.io/neurips2024/posters/fc2sv2sq8j/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/fc2sv2sq8j/</guid><description>LaKD: a novel length-agnostic knowledge distillation framework enables accurate trajectory prediction regardless of observation length, overcoming limitations of existing methods.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/fc2sv2sq8j/cover.png"/></item><item><title>LiT: Unifying LiDAR 'Languages' with LiDAR Translator</title><link>https://deep-diver.github.io/neurips2024/posters/wcx04wn34u/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/wcx04wn34u/</guid><description>LiDAR Translator (LiT) unifies diverse LiDAR data through a novel data-driven translation framework, enabling zero-shot and multi-domain joint learning, thus improving autonomous driving systems.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/wcx04wn34u/cover.png"/></item><item><title>Motion Forecasting in Continuous Driving</title><link>https://deep-diver.github.io/neurips2024/spotlight-others/4mxzxyhmun/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-others/4mxzxyhmun/</guid><description>RealMotion: a novel motion forecasting framework for continuous driving that outperforms existing methods by accumulating historical scene information and sequentially refining predictions, achieving &amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-others/4mxzxyhmun/cover.png"/></item><item><title>On-Road Object Importance Estimation: A New Dataset and A Model with Multi-Fold Top-Down Guidance</title><link>https://deep-diver.github.io/neurips2024/posters/xvtmc9ovx3/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/xvtmc9ovx3/</guid><description>New large-scale dataset and model boost on-road object importance estimation accuracy by 23.1%!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/xvtmc9ovx3/cover.png"/></item><item><title>RCDN: Towards Robust Camera-Insensitivity Collaborative Perception via Dynamic Feature-based 3D Neural Modeling</title><link>https://deep-diver.github.io/neurips2024/posters/xvveszovjo/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/xvveszovjo/</guid><description>RCDN: Robust, camera-insensitive collaborative perception via dynamic 3D neural modeling, overcoming camera failures for high-performance autonomous systems.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/xvveszovjo/cover.png"/></item><item><title>SceneDiffuser: Efficient and Controllable Driving Simulation Initialization and Rollout</title><link>https://deep-diver.github.io/neurips2024/posters/a4qt29levh/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/a4qt29levh/</guid><description>SceneDiffuser: a scene-level diffusion model revolutionizes driving simulation by uniting scene initialization and rollout, enabling efficient and controllable closed-loop traffic generation.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/a4qt29levh/cover.png"/></item><item><title>Unveiling the Hidden: Online Vectorized HD Map Construction with Clip-Level Token Interaction and Propagation</title><link>https://deep-diver.github.io/neurips2024/posters/z4evwh484m/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/z4evwh484m/</guid><description>MapUnveiler: a novel paradigm for online vectorized HD map construction that leverages clip-level token interaction and propagation to unveil hidden map elements and achieve state-of-the-art performan&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/z4evwh484m/cover.png"/></item><item><title>VeXKD: The Versatile Integration of Cross-Modal Fusion and Knowledge Distillation for 3D Perception</title><link>https://deep-diver.github.io/neurips2024/posters/s5cob5kqsd/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/s5cob5kqsd/</guid><description>VeXKD: A versatile framework boosts 3D perception by cleverly combining cross-modal fusion and knowledge distillation, improving single-modal student model accuracy without extra inference time.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/s5cob5kqsd/cover.png"/></item></channel></rss>