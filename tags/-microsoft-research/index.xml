<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>üè¢ Microsoft Research on NeurIPS 2024</title><link>https://deep-diver.github.io/neurips2024/tags/-microsoft-research/</link><description>Recent content in üè¢ Microsoft Research on NeurIPS 2024</description><generator>Hugo -- gohugo.io</generator><language>en</language><copyright>¬© 2024 AI Paper Reviewer</copyright><lastBuildDate>Thu, 26 Sep 2024 00:00:00 +0000</lastBuildDate><atom:link href="https://deep-diver.github.io/neurips2024/tags/-microsoft-research/index.xml" rel="self" type="application/rss+xml"/><item><title>A Bayesian Approach to Data Point Selection</title><link>https://deep-diver.github.io/neurips2024/posters/9f5toxkomc/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/9f5toxkomc/</guid><description>BADS: a novel Bayesian approach to data point selection efficiently optimizes deep learning models by jointly inferring instance weights and model parameters using stochastic gradient Langevin dynamic&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/9f5toxkomc/cover.png"/></item><item><title>A Study of Plasticity Loss in On-Policy Deep Reinforcement Learning</title><link>https://deep-diver.github.io/neurips2024/spotlight-reinforcement-learning/msuf8kpktf/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-reinforcement-learning/msuf8kpktf/</guid><description>On-policy deep RL agents suffer from plasticity loss, but this paper introduces &amp;lsquo;regenerative&amp;rsquo; methods that consistently mitigate this, improving performance in challenging environments.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-reinforcement-learning/msuf8kpktf/cover.png"/></item><item><title>Accuracy is Not All You Need</title><link>https://deep-diver.github.io/neurips2024/posters/qvg7j29sta/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/qvg7j29sta/</guid><description>LLM compression accuracy hides crucial behavioral changes; use % flips and KL-divergence for better evaluation.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/qvg7j29sta/cover.png"/></item><item><title>Adam with model exponential moving average is effective for nonconvex optimization</title><link>https://deep-diver.github.io/neurips2024/posters/v416yloquu/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/v416yloquu/</guid><description>Clipped Adam with EMA achieves optimal convergence rates for smooth and non-smooth nonconvex optimization, particularly when scales vary across different coordinates.</description></item><item><title>Advancing Spiking Neural Networks for Sequential Modeling with Central Pattern Generators</title><link>https://deep-diver.github.io/neurips2024/spotlight-others/kqmyidwbog/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-others/kqmyidwbog/</guid><description>Bio-inspired CPG-PE enhances spiking neural networks&amp;rsquo; sequential modeling by efficiently encoding position information, outperforming conventional methods across various tasks.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-others/kqmyidwbog/cover.png"/></item><item><title>Aligning LLM Agents by Learning Latent Preference from User Edits</title><link>https://deep-diver.github.io/neurips2024/posters/dlyngpcuwa/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/dlyngpcuwa/</guid><description>PRELUDE, a novel framework, leverages user edits of LLM outputs to learn latent preferences, improving agent alignment and minimizing edit costs. CIPHER, its efficient algorithm, infers preferences f&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/dlyngpcuwa/cover.png"/></item><item><title>ALPINE: Unveiling The Planning Capability of Autoregressive Learning in Language Models</title><link>https://deep-diver.github.io/neurips2024/posters/wfbzusv14e/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/wfbzusv14e/</guid><description>ALPINE reveals how Transformer-based LLMs learn planning by embedding graph information into their weights, but also highlights their inability to handle transitive relationships.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/wfbzusv14e/cover.png"/></item><item><title>Boosting Text-to-Video Generative Model with MLLMs Feedback</title><link>https://deep-diver.github.io/neurips2024/posters/3ivnixhy16/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/3ivnixhy16/</guid><description>MLLMs enhance text-to-video generation by providing 135k fine-grained video preferences, creating VIDEOPREFER, and a novel reward model, VIDEORM, boosting video quality and alignment.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/3ivnixhy16/cover.png"/></item><item><title>Can large language models explore in-context?</title><link>https://deep-diver.github.io/neurips2024/posters/owpzhvqiux/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/owpzhvqiux/</guid><description>LLMs struggle with in-context exploration, needing substantial prompt engineering or training interventions to effectively explore multi-armed bandit environments.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/owpzhvqiux/cover.png"/></item><item><title>Compositional 3D-aware Video Generation with LLM Director</title><link>https://deep-diver.github.io/neurips2024/posters/oqdy2efrja/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/oqdy2efrja/</guid><description>LLM-directed compositional 3D-aware video generation (C3V) achieves high-fidelity video generation with diverse motion and flexible concept control by decomposing prompts, generating 3D concepts, and &amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/oqdy2efrja/cover.png"/></item><item><title>CultureLLM: Incorporating Cultural Differences into Large Language Models</title><link>https://deep-diver.github.io/neurips2024/posters/sisbokqmbl/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/sisbokqmbl/</guid><description>CultureLLM, a new approach, effectively incorporates cultural nuances into LLMs using semantic data augmentation, significantly outperforming existing models.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/sisbokqmbl/cover.png"/></item><item><title>CulturePark: Boosting Cross-cultural Understanding in Large Language Models</title><link>https://deep-diver.github.io/neurips2024/posters/bifhhf2rod/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/bifhhf2rod/</guid><description>CulturePark, a novel multi-agent communication framework, generates high-quality cross-cultural data to fine-tune LLMs, significantly reducing cultural bias and boosting cross-cultural understanding.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/bifhhf2rod/cover.png"/></item><item><title>DeepStack: Deeply Stacking Visual Tokens is Surprisingly Simple and Effective for LMMs</title><link>https://deep-diver.github.io/neurips2024/posters/fxdpdzhtdv/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/fxdpdzhtdv/</guid><description>DeepStack: Stacking visual tokens boosts LMMs efficiency and performance!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/fxdpdzhtdv/cover.png"/></item><item><title>Diffusion Model with Cross Attention as an Inductive Bias for Disentanglement</title><link>https://deep-diver.github.io/neurips2024/spotlight-others/stapcuwm9q/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-others/stapcuwm9q/</guid><description>Diffusion models with cross-attention: a powerful inductive bias for effortless disentanglement!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-others/stapcuwm9q/cover.png"/></item><item><title>Does Reasoning Emerge? Examining the Probabilities of Causation in Large Language Models</title><link>https://deep-diver.github.io/neurips2024/posters/b1ylcyjazk/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/b1ylcyjazk/</guid><description>LLMs&amp;rsquo; reasoning abilities are assessed via a novel framework that leverages probabilities of causation, revealing that while capable, their understanding of causality falls short of human-level reason&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/b1ylcyjazk/cover.png"/></item><item><title>EEG2Video: Towards Decoding Dynamic Visual Perception from EEG Signals</title><link>https://deep-diver.github.io/neurips2024/posters/rfsfrn9ofd/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/rfsfrn9ofd/</guid><description>EEG2Video reconstructs dynamic videos from EEG signals, achieving 79.8% accuracy in semantic classification and 0.256 SSIM in video reconstruction.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/rfsfrn9ofd/cover.png"/></item><item><title>ElasTST: Towards Robust Varied-Horizon Forecasting with Elastic Time-Series Transformer</title><link>https://deep-diver.github.io/neurips2024/posters/ucxutmpwhv/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/ucxutmpwhv/</guid><description>ElasTST: A novel time-series transformer enables robust forecasting across various horizons without per-horizon training, enhancing adaptability and accuracy.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/ucxutmpwhv/cover.png"/></item><item><title>How to Solve Contextual Goal-Oriented Problems with Offline Datasets?</title><link>https://deep-diver.github.io/neurips2024/posters/ku31arq3sw/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/ku31arq3sw/</guid><description>CODA: A novel method for solving contextual goal-oriented problems with offline datasets, using unlabeled trajectories and context-goal pairs to create a fully labeled dataset, outperforming other bas&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/ku31arq3sw/cover.png"/></item><item><title>Improving Context-Aware Preference Modeling for Language Models</title><link>https://deep-diver.github.io/neurips2024/posters/52r4xjyzjg/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/52r4xjyzjg/</guid><description>Context-aware preference modeling improves language model alignment by resolving ambiguity through a two-step process: context selection followed by context-specific preference evaluation. The approa&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/52r4xjyzjg/cover.png"/></item><item><title>Infusing Self-Consistency into Density Functional Theory Hamiltonian Prediction via Deep Equilibrium Models</title><link>https://deep-diver.github.io/neurips2024/posters/psvkinbs4u/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/psvkinbs4u/</guid><description>Deep Equilibrium Models (DEQs) infused into DFT Hamiltonian prediction achieves self-consistency, accelerating large-scale materials simulations.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/psvkinbs4u/cover.png"/></item><item><title>Is A Picture Worth A Thousand Words? Delving Into Spatial Reasoning for Vision Language Models</title><link>https://deep-diver.github.io/neurips2024/posters/cvasru8leo/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/cvasru8leo/</guid><description>SpatialEval benchmark reveals that current vision-language models struggle with spatial reasoning, highlighting the need for improved multimodal models that effectively integrate visual and textual in&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/cvasru8leo/cover.png"/></item><item><title>Is Behavior Cloning All You Need? Understanding Horizon in Imitation Learning</title><link>https://deep-diver.github.io/neurips2024/spotlight-reinforcement-learning/8kpyjm4gt5/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-reinforcement-learning/8kpyjm4gt5/</guid><description>Offline imitation learning achieves surprisingly strong performance, matching online methods&amp;rsquo; efficiency under certain conditions, contradicting prior assumptions.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-reinforcement-learning/8kpyjm4gt5/cover.png"/></item><item><title>Mind's Eye of LLMs: Visualization-of-Thought Elicits Spatial Reasoning in Large Language Models</title><link>https://deep-diver.github.io/neurips2024/posters/cej1mypgww/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/cej1mypgww/</guid><description>LLMs&amp;rsquo; spatial reasoning abilities are boosted by visualizing their thought processes via &amp;lsquo;Visualization-of-Thought&amp;rsquo; prompting, significantly improving performance on navigation and tiling tasks.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/cej1mypgww/cover.png"/></item><item><title>Multi-Head Mixture-of-Experts</title><link>https://deep-diver.github.io/neurips2024/posters/dyz8gjzjtx/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/dyz8gjzjtx/</guid><description>Multi-Head Mixture-of-Experts (MH-MoE) drastically boosts large language model efficiency by activating almost all expert networks, achieving superior performance compared to existing Sparse Mixture-o&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/dyz8gjzjtx/cover.png"/></item><item><title>Multimodal Large Language Models Make Text-to-Image Generative Models Align Better</title><link>https://deep-diver.github.io/neurips2024/posters/irxypm9ipw/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/irxypm9ipw/</guid><description>AI-generated preference data improves text-to-image alignment.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/irxypm9ipw/cover.png"/></item><item><title>Online Estimation via Offline Estimation: An Information-Theoretic Framework</title><link>https://deep-diver.github.io/neurips2024/posters/sks7x4i8bh/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/sks7x4i8bh/</guid><description>This paper introduces a novel information-theoretic framework, showing how to convert offline into online estimation algorithms efficiently, impacting interactive decision-making.</description></item><item><title>Physical Consistency Bridges Heterogeneous Data in Molecular Multi-Task Learning</title><link>https://deep-diver.github.io/neurips2024/posters/gnf9tavqgc/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/gnf9tavqgc/</guid><description>Physically consistent multi-task learning bridges heterogeneous molecular data by directly leveraging physical laws to improve predictions, enhancing accuracy beyond the limitations of individual data&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/gnf9tavqgc/cover.png"/></item><item><title>Policy Improvement using Language Feedback Models</title><link>https://deep-diver.github.io/neurips2024/posters/fvgcwcwpjw/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/fvgcwcwpjw/</guid><description>Boosting AI instruction following, Language Feedback Models (LFMs) leverage Large Language Models (LLMs) to identify desirable behaviors from visual trajectories, significantly improving task completi&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/fvgcwcwpjw/cover.png"/></item><item><title>Predictor-Corrector Enhanced Transformers with Exponential Moving Average Coefficient Learning</title><link>https://deep-diver.github.io/neurips2024/posters/ur9f4hnipn/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/ur9f4hnipn/</guid><description>PCformer boosts Transformer performance by using a predictor-corrector learning framework and exponential moving average coefficient learning for high-order prediction, achieving state-of-the-art resu&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/ur9f4hnipn/cover.png"/></item><item><title>Protecting Your LLMs with Information Bottleneck</title><link>https://deep-diver.github.io/neurips2024/posters/u9shp64fjv/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/u9shp64fjv/</guid><description>IBProtector shields LLMs from harmful outputs via prompt compression, selectively preserving essential information using a trainable extractor.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/u9shp64fjv/cover.png"/></item><item><title>Scaling the Codebook Size of VQ-GAN to 100,000 with a Utilization Rate of 99%</title><link>https://deep-diver.github.io/neurips2024/posters/rbu10yvkk6/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/rbu10yvkk6/</guid><description>VQGAN-LC massively scales VQGAN&amp;rsquo;s codebook to 100,000 entries while maintaining a 99% utilization rate, significantly boosting image generation and downstream task performance.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/rbu10yvkk6/cover.png"/></item><item><title>Slot-VLM: Object-Event Slots for Video-Language Modeling</title><link>https://deep-diver.github.io/neurips2024/posters/7hb03vgcjk/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/7hb03vgcjk/</guid><description>Slot-VLM generates semantically decomposed video tokens using an Object-Event Slots module, improving video-language model performance.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/7hb03vgcjk/cover.png"/></item><item><title>Towards Editing Time Series</title><link>https://deep-diver.github.io/neurips2024/posters/qu5ntwztxa/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/qu5ntwztxa/</guid><description>TEdit: a novel diffusion model edits existing time series to meet specified attribute targets, preserving other properties, solving limitations of prior synthesis methods.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/qu5ntwztxa/cover.png"/></item><item><title>Towards Flexible Visual Relationship Segmentation</title><link>https://deep-diver.github.io/neurips2024/posters/kjkp2ecjt7/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/kjkp2ecjt7/</guid><description>FleVRS: One unified model masters standard, promptable, and open-vocabulary visual relationship segmentation, outperforming existing methods.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/kjkp2ecjt7/cover.png"/></item><item><title>Trace is the Next AutoDiff: Generative Optimization with Rich Feedback, Execution Traces, and LLMs</title><link>https://deep-diver.github.io/neurips2024/posters/rys2dmn9td/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/rys2dmn9td/</guid><description>Trace: Automating AI workflow design with LLMs.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/rys2dmn9td/cover.png"/></item><item><title>Understanding and Improving Training-free Loss-based Diffusion Guidance</title><link>https://deep-diver.github.io/neurips2024/posters/eu80dguocs/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/eu80dguocs/</guid><description>Training-free guidance revolutionizes diffusion models by enabling zero-shot conditional generation, but suffers from misaligned gradients and slow convergence. This paper provides theoretical analysi&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/eu80dguocs/cover.png"/></item><item><title>Understanding Information Storage and Transfer in Multi-Modal Large Language Models</title><link>https://deep-diver.github.io/neurips2024/posters/s63dtq0mwa/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/s63dtq0mwa/</guid><description>Researchers unveil how multi-modal LLMs process information, revealing that early layers are key for storage, and introduce MULTEDIT, a model-editing algorithm for correcting errors and inserting new &amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/s63dtq0mwa/cover.png"/></item><item><title>VASA-1: Lifelike Audio-Driven Talking Faces Generated in Real Time</title><link>https://deep-diver.github.io/neurips2024/oral-others/5zscse0k41/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/oral-others/5zscse0k41/</guid><description>VASA-1: Real-time, lifelike talking faces generated from a single image and audio!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/oral-others/5zscse0k41/cover.png"/></item></channel></rss>