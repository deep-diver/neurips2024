<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>üè¢ Harbin Institute of Technology on NeurIPS 2024</title><link>https://deep-diver.github.io/neurips2024/tags/-harbin-institute-of-technology/</link><description>Recent content in üè¢ Harbin Institute of Technology on NeurIPS 2024</description><generator>Hugo -- gohugo.io</generator><language>en</language><copyright>¬© 2024 AI Paper Reviewer</copyright><lastBuildDate>Thu, 26 Sep 2024 00:00:00 +0000</lastBuildDate><atom:link href="https://deep-diver.github.io/neurips2024/tags/-harbin-institute-of-technology/index.xml" rel="self" type="application/rss+xml"/><item><title>Divide-and-Conquer Meets Consensus: Unleashing the Power of Functions in Code Generation</title><link>https://deep-diver.github.io/neurips2024/oral-large-language-models/cfqaaningw/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/oral-large-language-models/cfqaaningw/</guid><description>FUNCODER: a novel code generation framework that uses a divide-and-conquer approach with functional consensus to generate code that meets complex requirements.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/oral-large-language-models/cfqaaningw/cover.png"/></item><item><title>EEGPT: Pretrained Transformer for Universal and Reliable Representation of EEG Signals</title><link>https://deep-diver.github.io/neurips2024/posters/lvs2b8cjg5/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/lvs2b8cjg5/</guid><description>EEGPT: A pretrained transformer model revolutionizes EEG signal representation by using a dual self-supervised learning method, achieving state-of-the-art results across various tasks.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/lvs2b8cjg5/cover.png"/></item><item><title>Ensemble Learning for Heterogeneous Large Language Models with Deep Parallel Collaboration</title><link>https://deep-diver.github.io/neurips2024/spotlight-large-language-models/7araaduk6d/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-large-language-models/7araaduk6d/</guid><description>DEEPEN: a training-free LLM ensemble framework fusing probability distributions in a relative space to overcome vocabulary misalignment, improving performance consistently across benchmarks.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-large-language-models/7araaduk6d/cover.png"/></item><item><title>High-Resolution Image Harmonization with Adaptive-Interval Color Transformation</title><link>https://deep-diver.github.io/neurips2024/posters/jxghewtxs8/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/jxghewtxs8/</guid><description>AICT: Adaptive-Interval Color Transformation harmonizes high-resolution images by predicting pixel-wise color changes, adaptively adjusting sampling intervals to capture local variations, and using a &amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/jxghewtxs8/cover.png"/></item><item><title>LG-VQ: Language-Guided Codebook Learning</title><link>https://deep-diver.github.io/neurips2024/posters/va4s3kn4qe/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/va4s3kn4qe/</guid><description>LG-VQ: A novel language-guided codebook learning framework boosts multi-modal performance.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/va4s3kn4qe/cover.png"/></item><item><title>Meaningful Learning: Enhancing Abstract Reasoning in Large Language Models via Generic Fact Guidance</title><link>https://deep-diver.github.io/neurips2024/posters/tihifqgoyc/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/tihifqgoyc/</guid><description>Boosting LLMs&amp;rsquo; abstract reasoning via &amp;lsquo;Meaningful Learning&amp;rsquo;: A new dataset and learning paradigm significantly enhance LLMs&amp;rsquo; capacity for abstract reasoning, moving beyond simple memorization.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/tihifqgoyc/cover.png"/></item><item><title>MoGU: A Framework for Enhancing Safety of LLMs While Preserving Their Usability</title><link>https://deep-diver.github.io/neurips2024/posters/srfbgijb53/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/srfbgijb53/</guid><description>MoGU: A framework dynamically balances safety and usability in LLMs by routing benign and malicious instructions to different LLM variants, leading to safer, more useful responses.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/srfbgijb53/cover.png"/></item><item><title>Rethinking Imbalance in Image Super-Resolution for Efficient Inference</title><link>https://deep-diver.github.io/neurips2024/posters/fyyrzbwtnz/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/fyyrzbwtnz/</guid><description>WBSR: A novel framework for efficient image super-resolution that tackles data and model imbalances for superior performance and approximately a 34% reduction in computational cost.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/fyyrzbwtnz/cover.png"/></item><item><title>Toward a Stable, Fair, and Comprehensive Evaluation of Object Hallucination in Large Vision-Language Models</title><link>https://deep-diver.github.io/neurips2024/posters/yql5tutdah/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/yql5tutdah/</guid><description>LeHaCE: a novel framework for evaluating object hallucination in LVLMs, improving evaluation stability and fairness by accounting for instruction-induced image description length variations.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/yql5tutdah/cover.png"/></item></channel></rss>