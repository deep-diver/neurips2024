<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>üè¢ Harbin Institute of Technology on NeurIPS 2024</title><link>https://deep-diver.github.io/neurips2024/tags/-harbin-institute-of-technology/</link><description>Recent content in üè¢ Harbin Institute of Technology on NeurIPS 2024</description><generator>Hugo -- gohugo.io</generator><language>en</language><copyright>¬© 2024 AI Paper Reviewer</copyright><lastBuildDate>Thu, 26 Sep 2024 00:00:00 +0000</lastBuildDate><atom:link href="https://deep-diver.github.io/neurips2024/tags/-harbin-institute-of-technology/index.xml" rel="self" type="application/rss+xml"/><item><title>Divide-and-Conquer Meets Consensus: Unleashing the Power of Functions in Code Generation</title><link>https://deep-diver.github.io/neurips2024/oral-large-language-models/cfqaaningw/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/oral-large-language-models/cfqaaningw/</guid><description>FUNCODER: a novel code generation framework that uses a divide-and-conquer approach with functional consensus to generate code that meets complex requirements.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/oral-large-language-models/cfqaaningw/cover.png"/></item><item><title>Ensemble Learning for Heterogeneous Large Language Models with Deep Parallel Collaboration</title><link>https://deep-diver.github.io/neurips2024/spotlight-large-language-models/7araaduk6d/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-large-language-models/7araaduk6d/</guid><description>DEEPEN: a training-free LLM ensemble framework fusing probability distributions in a relative space to overcome vocabulary misalignment, improving performance consistently across benchmarks.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-large-language-models/7araaduk6d/cover.png"/></item><item><title>LG-VQ: Language-Guided Codebook Learning</title><link>https://deep-diver.github.io/neurips2024/posters/va4s3kn4qe/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/va4s3kn4qe/</guid><description>LG-VQ: A novel language-guided codebook learning framework boosts multi-modal performance.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/va4s3kn4qe/cover.png"/></item><item><title>Toward a Stable, Fair, and Comprehensive Evaluation of Object Hallucination in Large Vision-Language Models</title><link>https://deep-diver.github.io/neurips2024/posters/yql5tutdah/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/yql5tutdah/</guid><description>LeHaCE: a novel framework for evaluating object hallucination in LVLMs, improving evaluation stability and fairness by accounting for instruction-induced image description length variations.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/yql5tutdah/cover.png"/></item></channel></rss>