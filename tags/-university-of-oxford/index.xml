<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>üè¢ University of Oxford on NeurIPS 2024</title><link>https://deep-diver.github.io/neurips2024/tags/-university-of-oxford/</link><description>Recent content in üè¢ University of Oxford on NeurIPS 2024</description><generator>Hugo -- gohugo.io</generator><language>en</language><copyright>¬© 2025 AI Paper Reviewer</copyright><lastBuildDate>Thu, 26 Sep 2024 00:00:00 +0000</lastBuildDate><atom:link href="https://deep-diver.github.io/neurips2024/tags/-university-of-oxford/index.xml" rel="self" type="application/rss+xml"/><item><title>A General Protocol to Probe Large Vision Models for 3D Physical Understanding</title><link>https://deep-diver.github.io/neurips2024/posters/0hrrneaqfp/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/0hrrneaqfp/</guid><description>Researchers developed a lightweight protocol to probe large vision models&amp;rsquo; 3D physical understanding by training classifiers on model features for various scene properties (geometry, material, lightin&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/0hrrneaqfp/cover.png"/></item><item><title>Adam on Local Time: Addressing Nonstationarity in RL with Relative Adam Timesteps</title><link>https://deep-diver.github.io/neurips2024/posters/biaqubaug7/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/biaqubaug7/</guid><description>Adam-Rel: A novel optimizer for RL, dramatically improves performance by resetting Adam&amp;rsquo;s timestep to 0 after target network updates, preventing large, suboptimal changes.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/biaqubaug7/cover.png"/></item><item><title>Almost Surely Asymptotically Constant Graph Neural Networks</title><link>https://deep-diver.github.io/neurips2024/posters/dn68qdftry/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/dn68qdftry/</guid><description>Many graph neural networks (GNNs) surprisingly converge to constant outputs with increasing graph size, limiting their expressiveness.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/dn68qdftry/cover.png"/></item><item><title>Amortized Active Causal Induction with Deep Reinforcement Learning</title><link>https://deep-diver.github.io/neurips2024/posters/7axy27kdnh/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/7axy27kdnh/</guid><description>CAASL: An amortized active intervention design policy trained via reinforcement learning, enabling adaptive, real-time causal graph inference without likelihood access.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/7axy27kdnh/cover.png"/></item><item><title>An exactly solvable model for emergence and scaling laws in the multitask sparse parity problem</title><link>https://deep-diver.github.io/neurips2024/posters/cuwsr25bbi/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/cuwsr25bbi/</guid><description>A novel multilinear model analytically explains the emergence and scaling laws of skills in the multitask sparse parity problem, accurately predicting skill emergence in neural networks.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/cuwsr25bbi/cover.png"/></item><item><title>Artificial Generational Intelligence: Cultural Accumulation in Reinforcement Learning</title><link>https://deep-diver.github.io/neurips2024/posters/pmacrgu8gv/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/pmacrgu8gv/</guid><description>Reinforcement learning agents achieve emergent cultural accumulation by balancing social and independent learning, outperforming single-lifetime agents.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/pmacrgu8gv/cover.png"/></item><item><title>BAM! Just Like That: Simple and Efficient Parameter Upcycling for Mixture of Experts</title><link>https://deep-diver.github.io/neurips2024/posters/bdrwqtrfyi/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/bdrwqtrfyi/</guid><description>BAM! Efficiently upcycles pre-trained models into powerful Mixture-of-Experts (MoE) models, achieving state-of-the-art performance with reduced computational costs.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/bdrwqtrfyi/cover.png"/></item><item><title>Bayesian Optimization of Functions over Node Subsets in Graphs</title><link>https://deep-diver.github.io/neurips2024/posters/kxjgi1krbi/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/kxjgi1krbi/</guid><description>GraphComBO efficiently optimizes functions defined on node subsets within graphs using Bayesian Optimization. It tackles challenges posed by combinatorial complexity and computationally expensive fun&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/kxjgi1krbi/cover.png"/></item><item><title>Can Large Language Model Agents Simulate Human Trust Behavior?</title><link>https://deep-diver.github.io/neurips2024/posters/ceowahuqic/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/ceowahuqic/</guid><description>LLM agents surprisingly exhibit human-like trust behavior, especially GPT-4, paving the way for simulating complex human interactions in various applications.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/ceowahuqic/cover.png"/></item><item><title>Can Learned Optimization Make Reinforcement Learning Less Difficult?</title><link>https://deep-diver.github.io/neurips2024/spotlight-reinforcement-learning/ybxfwasa9z/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-reinforcement-learning/ybxfwasa9z/</guid><description>Learned optimizer OPEN tackles RL&amp;rsquo;s non-stationarity, plasticity loss, and exploration using meta-learning, significantly outperforming traditional and other learned optimizers.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-reinforcement-learning/ybxfwasa9z/cover.png"/></item><item><title>CountGD: Multi-Modal Open-World Counting</title><link>https://deep-diver.github.io/neurips2024/posters/eug64osgde/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/eug64osgde/</guid><description>COUNTGD: A new multi-modal model counts objects in images using text or visual examples, significantly improving open-world counting accuracy.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/eug64osgde/cover.png"/></item><item><title>Deep Bayesian Active Learning for Preference Modeling in Large Language Models</title><link>https://deep-diver.github.io/neurips2024/posters/tadtt9ughn/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/tadtt9ughn/</guid><description>BAL-PM, a novel active learning approach, drastically reduces human feedback in LLM preference modeling by leveraging both model uncertainty and prompt distribution diversity, achieving 33%-68% fewer &amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/tadtt9ughn/cover.png"/></item><item><title>Direct3D: Scalable Image-to-3D Generation via 3D Latent Diffusion Transformer</title><link>https://deep-diver.github.io/neurips2024/posters/vcogjbizul/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/vcogjbizul/</guid><description>Direct3D: Revolutionizing image-to-3D generation with a scalable, native 3D diffusion model achieving state-of-the-art quality.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/vcogjbizul/cover.png"/></item><item><title>Ensemble sampling for linear bandits: small ensembles suffice</title><link>https://deep-diver.github.io/neurips2024/posters/so7fnifq0o/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/so7fnifq0o/</guid><description>Small ensembles in stochastic linear bandits achieve near-optimal regret; a rigorous analysis shows that ensemble size need only scale logarithmically with horizon.</description></item><item><title>FilterNet: Harnessing Frequency Filters for Time Series Forecasting</title><link>https://deep-diver.github.io/neurips2024/posters/ugl2d9idad/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/ugl2d9idad/</guid><description>FilterNet: A novel deep learning architecture using learnable frequency filters for superior time series forecasting accuracy and efficiency.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/ugl2d9idad/cover.png"/></item><item><title>G2D: From Global to Dense Radiography Representation Learning via Vision-Language Pre-training</title><link>https://deep-diver.github.io/neurips2024/posters/zsxbgjj7oo/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/zsxbgjj7oo/</guid><description>G2D: a novel medical VLP framework achieves superior performance in medical image analysis by simultaneously learning global and dense visual features using image-text pairs without extra annotations.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/zsxbgjj7oo/cover.png"/></item><item><title>Improved learning rates in multi-unit uniform price auctions</title><link>https://deep-diver.github.io/neurips2024/posters/un7nxleh9d/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/un7nxleh9d/</guid><description>New modeling of bid space in multi-unit uniform price auctions achieves regret of √ï(K4/3T2/3) under bandit feedback, improving over prior work and closing the gap with discriminatory pricing.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/un7nxleh9d/cover.png"/></item><item><title>Interpreting Learned Feedback Patterns in Large Language Models</title><link>https://deep-diver.github.io/neurips2024/posters/xuongr1byy/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/xuongr1byy/</guid><description>Researchers developed methods to measure and interpret the divergence between learned feedback patterns (LFPs) in LLMs and human preferences, helping minimize discrepancies between LLM behavior and tr&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/xuongr1byy/cover.png"/></item><item><title>Interventionally Consistent Surrogates for Complex Simulation Models</title><link>https://deep-diver.github.io/neurips2024/posters/uttjgmdtfo/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/uttjgmdtfo/</guid><description>This paper introduces a novel framework for creating interventionally consistent surrogate models for complex simulations, addressing computational limitations and ensuring accurate policy evaluation.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/uttjgmdtfo/cover.png"/></item><item><title>Label Delay in Online Continual Learning</title><link>https://deep-diver.github.io/neurips2024/posters/m5canuui0z/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/m5canuui0z/</guid><description>Bridging the accuracy gap in online continual learning caused by label delays, a new framework with Importance Weighted Memory Sampling prioritizes relevant memory samples, significantly outperforming&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/m5canuui0z/cover.png"/></item><item><title>Language Models as Hierarchy Encoders</title><link>https://deep-diver.github.io/neurips2024/posters/gjmyvwzje1/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/gjmyvwzje1/</guid><description>Language models struggle with hierarchical information. This work introduces Hierarchy Transformer Encoders (HITs), a novel method to retrain transformer encoders using hyperbolic geometry and special&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/gjmyvwzje1/cover.png"/></item><item><title>Learning on Large Graphs using Intersecting Communities</title><link>https://deep-diver.github.io/neurips2024/posters/pgr5x4e1gy/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/pgr5x4e1gy/</guid><description>Learn on massive graphs efficiently using Intersecting Community Graphs (ICGs)! This method approximates large graphs with ICGs, enabling linear time/memory complexity for node classification.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/pgr5x4e1gy/cover.png"/></item><item><title>Learning Segmentation from Point Trajectories</title><link>https://deep-diver.github.io/neurips2024/spotlight-others/vt2qke1oax/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-others/vt2qke1oax/</guid><description>This paper introduces a novel unsupervised video object segmentation method using long-term point trajectories and optical flow, outperforming prior art by effectively combining sparse, long-term moti&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-others/vt2qke1oax/cover.png"/></item><item><title>LoCo: Learning 3D Location-Consistent Image Features with a Memory-Efficient Ranking Loss</title><link>https://deep-diver.github.io/neurips2024/posters/l6iczoxafi/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/l6iczoxafi/</guid><description>LoCo: Memory-efficient location-consistent image features learned via a novel ranking loss, enabling three orders of magnitude memory improvement and outperforming state-of-the-art.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/l6iczoxafi/cover.png"/></item><item><title>Marginal Causal Flows for Validation and Inference</title><link>https://deep-diver.github.io/neurips2024/posters/zjremskvyh/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/zjremskvyh/</guid><description>Frugal Flows: Generate realistic causal benchmarks with exact marginal causal effects, enabling robust causal method validation.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/zjremskvyh/cover.png"/></item><item><title>Metric Flow Matching for Smooth Interpolations on the Data Manifold</title><link>https://deep-diver.github.io/neurips2024/posters/fe3rqif4nx/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/fe3rqif4nx/</guid><description>METRIC FLOW MATCHING (MFM) generates smooth interpolations on data manifolds by minimizing kinetic energy, outperforming Euclidean methods and achieving state-of-the-art results in single-cell traject&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/fe3rqif4nx/cover.png"/></item><item><title>No 'Zero-Shot' Without Exponential Data: Pretraining Concept Frequency Determines Multimodal Model Performance</title><link>https://deep-diver.github.io/neurips2024/posters/9vbgjxlzig/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/9vbgjxlzig/</guid><description>Multimodal models&amp;rsquo; impressive &amp;lsquo;zero-shot&amp;rsquo; performance hinges on the frequency of concepts in their training data, not inherent generalization ability; exponentially more data is needed for linear impr&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/9vbgjxlzig/cover.png"/></item><item><title>No Regrets: Investigating and Improving Regret Approximations for Curriculum Discovery</title><link>https://deep-diver.github.io/neurips2024/posters/ieeizltbts/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/ieeizltbts/</guid><description>AI agents learn better with well-designed training environments. This paper reveals flaws in current environment-selection methods and introduces Sampling for Learnability (SFL), a new approach that &amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/ieeizltbts/cover.png"/></item><item><title>No-regret Learning in Harmonic Games: Extrapolation in the Face of Conflicting Interests</title><link>https://deep-diver.github.io/neurips2024/spotlight-ai-theory/hw9s9vy5gz/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-ai-theory/hw9s9vy5gz/</guid><description>Extrapolated FTRL ensures Nash equilibrium convergence in harmonic games, defying standard no-regret learning limitations.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-ai-theory/hw9s9vy5gz/cover.png"/></item><item><title>On the Limitations of Fractal Dimension as a Measure of Generalization</title><link>https://deep-diver.github.io/neurips2024/posters/yo6gvpurkn/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/yo6gvpurkn/</guid><description>Fractal dimension, while showing promise, fails to consistently predict neural network generalization due to hyperparameter influence and adversarial initializations; prompting further research.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/yo6gvpurkn/cover.png"/></item><item><title>Once Read is Enough: Domain-specific Pretraining-free Language Models with Cluster-guided Sparse Experts for Long-tail Domain Knowledge</title><link>https://deep-diver.github.io/neurips2024/posters/manhbkpiw6/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/manhbkpiw6/</guid><description>This research introduces Cluster-guided Sparse Experts (CSE), enabling pretrained language models to effectively learn long-tail domain knowledge without domain-specific pretraining, thus achieving su&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/manhbkpiw6/cover.png"/></item><item><title>OxonFair: A Flexible Toolkit for Algorithmic Fairness</title><link>https://deep-diver.github.io/neurips2024/posters/ztwl4ubnxv/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/ztwl4ubnxv/</guid><description>OxonFair: a new open-source toolkit for enforcing fairness in binary classification, supporting NLP, Computer Vision, and tabular data, optimizing any fairness metric, and minimizing performance degra&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/ztwl4ubnxv/cover.png"/></item><item><title>Pre-trained Text-to-Image Diffusion Models Are Versatile Representation Learners for Control</title><link>https://deep-diver.github.io/neurips2024/spotlight-others/ky07a73f3y/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-others/ky07a73f3y/</guid><description>Pre-trained text-to-image diffusion models create highly effective, versatile representations for embodied AI control, surpassing previous methods.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-others/ky07a73f3y/cover.png"/></item><item><title>Principled Bayesian Optimization in Collaboration with Human Experts</title><link>https://deep-diver.github.io/neurips2024/spotlight-ai-theory/idn9sikgly/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-ai-theory/idn9sikgly/</guid><description>COBOL: a novel Bayesian Optimization algorithm leverages human expert advice via binary labels, achieving both fast convergence and robustness to noisy input, while guaranteeing minimal expert effort.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-ai-theory/idn9sikgly/cover.png"/></item><item><title>Random Representations Outperform Online Continually Learned Representations</title><link>https://deep-diver.github.io/neurips2024/posters/tz5k9iybbf/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/tz5k9iybbf/</guid><description>Random pixel projections outperform complex online continual learning methods for image classification, challenging assumptions about representation learning.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/tz5k9iybbf/cover.png"/></item><item><title>Rough Transformers: Lightweight Continuous-Time Sequence Modelling with Path Signatures</title><link>https://deep-diver.github.io/neurips2024/posters/gxwmhzevmh/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/gxwmhzevmh/</guid><description>Rough Transformers: A lightweight continuous-time sequence modeling approach using path signatures to significantly reduce computational costs, improving efficiency and accuracy, particularly for long&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/gxwmhzevmh/cover.png"/></item><item><title>Score-Optimal Diffusion Schedules</title><link>https://deep-diver.github.io/neurips2024/posters/0rl5vwozru/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/0rl5vwozru/</guid><description>Researchers developed a novel algorithm to automatically find optimal schedules for denoising diffusion models (DDMs), significantly improving sample quality and efficiency without manual parameter tu&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/0rl5vwozru/cover.png"/></item><item><title>Separations in the Representational Capabilities of Transformers and Recurrent Architectures</title><link>https://deep-diver.github.io/neurips2024/posters/6hujod3wtj/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/6hujod3wtj/</guid><description>Transformers and RNNs show contrasting representational capabilities: Transformers excel at tasks requiring associative recall, while RNNs are better suited for hierarchical language processing. This &amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/6hujod3wtj/cover.png"/></item><item><title>Sequence-Augmented SE(3)-Flow Matching For Conditional Protein Generation</title><link>https://deep-diver.github.io/neurips2024/posters/paywtpbpyz/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/paywtpbpyz/</guid><description>Sequence-augmented SE(3)-Flow model, FOLDFLOW-2, excels at generating diverse, designable protein structures, surpassing existing methods in unconditional and conditional design tasks.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/paywtpbpyz/cover.png"/></item><item><title>Set-based Neural Network Encoding Without Weight Tying</title><link>https://deep-diver.github.io/neurips2024/posters/i3me9bcscy/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/i3me9bcscy/</guid><description>Set-based Neural Network Encoder (SNE) efficiently encodes neural network weights for property prediction, eliminating the need for architecture-specific models and improving generalization across dat&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/i3me9bcscy/cover.png"/></item><item><title>SpatialPIN: Enhancing Spatial Reasoning Capabilities of Vision-Language Models through Prompting and Interacting 3D Priors</title><link>https://deep-diver.github.io/neurips2024/posters/ythj8o6scb/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/ythj8o6scb/</guid><description>SpatialPIN boosts vision-language models&amp;rsquo; spatial reasoning by cleverly combining prompting techniques with 3D foundation models, achieving zero-shot performance on various spatial tasks.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/ythj8o6scb/cover.png"/></item><item><title>Stability and Generalizability in SDE Diffusion Models with Measure-Preserving Dynamics</title><link>https://deep-diver.github.io/neurips2024/posters/vtjvta41d0/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/vtjvta41d0/</guid><description>D¬≥GM, a novel score-based diffusion model, enhances stability &amp;amp; generalizability in solving inverse problems by leveraging measure-preserving dynamics, enabling robust image reconstruction across dive&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/vtjvta41d0/cover.png"/></item><item><title>The Edge-of-Reach Problem in Offline Model-Based Reinforcement Learning</title><link>https://deep-diver.github.io/neurips2024/posters/3dn1hina6o/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/3dn1hina6o/</guid><description>Offline model-based RL methods fail as dynamics models improve; this paper reveals the &amp;rsquo;edge-of-reach&amp;rsquo; problem causing this and introduces RAVL, a simple solution ensuring robust performance.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/3dn1hina6o/cover.png"/></item><item><title>Towards Learning Group-Equivariant Features for Domain Adaptive 3D Detection</title><link>https://deep-diver.github.io/neurips2024/posters/yetirxhsh1/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/yetirxhsh1/</guid><description>GroupEXP-DA boosts domain adaptive 3D object detection by using a grouping-exploration strategy to reduce bias in pseudo-label collection and account for multiple factors affecting object perception i&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/yetirxhsh1/cover.png"/></item><item><title>Transformers need glasses! Information over-squashing in language tasks</title><link>https://deep-diver.github.io/neurips2024/posters/93hce8vtye/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/93hce8vtye/</guid><description>Large language models (LLMs) suffer from information loss due to representational collapse and over-squashing, causing failures in simple tasks; this paper provides theoretical analysis and practical &amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/93hce8vtye/cover.png"/></item><item><title>Universal In-Context Approximation By Prompting Fully Recurrent Models</title><link>https://deep-diver.github.io/neurips2024/posters/gproasyzk5/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/gproasyzk5/</guid><description>Fully recurrent neural networks can be universal in-context approximators, achieving the same capabilities as transformer models by cleverly using prompts.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/gproasyzk5/cover.png"/></item><item><title>Unsupervised Object Detection with Theoretical Guarantees</title><link>https://deep-diver.github.io/neurips2024/posters/x33owjqyh0/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/x33owjqyh0/</guid><description>First unsupervised object detection method with theoretical guarantees to recover true object positions, up to quantifiable small shifts!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/x33owjqyh0/cover.png"/></item><item><title>What Makes and Breaks Safety Fine-tuning? A Mechanistic Study</title><link>https://deep-diver.github.io/neurips2024/posters/jeflv4nrlh/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/jeflv4nrlh/</guid><description>Safety fine-tuning for LLMs is shown to minimally transform weights, clustering inputs based on safety, but is easily bypassed by adversarial attacks.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/jeflv4nrlh/cover.png"/></item></channel></rss>