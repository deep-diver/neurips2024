<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>üè¢ Rice University on NeurIPS 2024</title><link>https://deep-diver.github.io/neurips2024/tags/-rice-university/</link><description>Recent content in üè¢ Rice University on NeurIPS 2024</description><generator>Hugo -- gohugo.io</generator><language>en</language><copyright>¬© 2024 AI Paper Reviewer</copyright><lastBuildDate>Thu, 26 Sep 2024 00:00:00 +0000</lastBuildDate><atom:link href="https://deep-diver.github.io/neurips2024/tags/-rice-university/index.xml" rel="self" type="application/rss+xml"/><item><title>Fair GLASSO: Estimating Fair Graphical Models with Unbiased Statistical Behavior</title><link>https://deep-diver.github.io/neurips2024/posters/a3cauwmxnv/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/a3cauwmxnv/</guid><description>Fair GLASSO ensures fair Gaussian graphical models by introducing novel bias metrics and a penalized maximum likelihood estimator to mitigate group biases in data.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/a3cauwmxnv/cover.png"/></item><item><title>Learning Transferable Features for Implicit Neural Representations</title><link>https://deep-diver.github.io/neurips2024/posters/abydkpdb8p/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/abydkpdb8p/</guid><description>STRAINER: A new framework enabling faster, higher-quality INR fitting by leveraging transferable features across similar signals, significantly boosting INR performance.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/abydkpdb8p/cover.png"/></item><item><title>NoMAD-Attention: Efficient LLM Inference on CPUs Through Multiply-add-free Attention</title><link>https://deep-diver.github.io/neurips2024/posters/4xdxvqhsbz/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/4xdxvqhsbz/</guid><description>NoMAD-Attention achieves up to 2x speedup in 4-bit quantized LLaMA inference on CPUs by replacing computationally expensive multiply-add operations with ultra-low-latency in-register lookups.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/4xdxvqhsbz/cover.png"/></item><item><title>Optimal Algorithms for Augmented Testing of Discrete Distributions</title><link>https://deep-diver.github.io/neurips2024/posters/talmacqk9s/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/talmacqk9s/</guid><description>Leveraging predictions, this research presents novel algorithms for uniformity, identity, and closeness testing of discrete distributions, achieving information-theoretically optimal sample complexity&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/talmacqk9s/cover.png"/></item><item><title>Optimal Hypothesis Selection in (Almost) Linear Time</title><link>https://deep-diver.github.io/neurips2024/posters/skv26jtefz/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/skv26jtefz/</guid><description>This paper presents the first almost linear-time algorithm achieving the optimal accuracy parameter for hypothesis selection, solving a decades-long open problem.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/skv26jtefz/cover.png"/></item><item><title>Prompt Tuning Strikes Back: Customizing Foundation Models with Low-Rank Prompt Adaptation</title><link>https://deep-diver.github.io/neurips2024/posters/symhgilvcv/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/symhgilvcv/</guid><description>LoPA: a novel parameter-efficient fine-tuning method matches state-of-the-art performance while requiring no server-side adapters, improving upon traditional prompt tuning.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/symhgilvcv/cover.png"/></item><item><title>SpaceByte: Towards Deleting Tokenization from Large Language Modeling</title><link>https://deep-diver.github.io/neurips2024/posters/kee4iup20i/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/kee4iup20i/</guid><description>SpaceByte: A novel byte-level decoder architecture achieving near-tokenized-model performance without tokenization!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/kee4iup20i/cover.png"/></item><item><title>SS1: Accelerating Inference with Fast and Expressive Sketch Structured Transform</title><link>https://deep-diver.github.io/neurips2024/posters/nrgyogu7zp/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/nrgyogu7zp/</guid><description>SS1: A novel GPU-friendly operator accelerates deep learning inference by leveraging structured parameter sharing, achieving superior quality-efficiency tradeoffs compared to existing methods.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/nrgyogu7zp/cover.png"/></item></channel></rss>