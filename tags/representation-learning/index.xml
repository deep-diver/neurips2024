<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Representation Learning on NeurIPS 2024</title><link>https://deep-diver.github.io/neurips2024/tags/representation-learning/</link><description>Recent content in Representation Learning on NeurIPS 2024</description><generator>Hugo -- gohugo.io</generator><language>en</language><copyright>Â© 2025 AI Paper Reviewer</copyright><lastBuildDate>Thu, 26 Sep 2024 00:00:00 +0000</lastBuildDate><atom:link href="https://deep-diver.github.io/neurips2024/tags/representation-learning/index.xml" rel="self" type="application/rss+xml"/><item><title>A Walsh Hadamard Derived Linear Vector Symbolic Architecture</title><link>https://deep-diver.github.io/neurips2024/posters/p3hnrpewme/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/p3hnrpewme/</guid><description>Hadamard-derived Linear Binding (HLB): A novel, efficient vector symbolic architecture surpassing existing methods in classical AI tasks and deep learning applications.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/p3hnrpewme/cover.png"/></item><item><title>An In-depth Investigation of Sparse Rate Reduction in Transformer-like Models</title><link>https://deep-diver.github.io/neurips2024/posters/cac74vumwx/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/cac74vumwx/</guid><description>Deep learning model interpretability improved via Sparse Rate Reduction (SRR), showing improved generalization and offering principled model design.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/cac74vumwx/cover.png"/></item><item><title>Approximating mutual information of high-dimensional variables using learned representations</title><link>https://deep-diver.github.io/neurips2024/spotlight-ai-theory/hn05dqxyll/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-ai-theory/hn05dqxyll/</guid><description>Latent Mutual Information (LMI) approximation accurately estimates mutual information in high-dimensional data using low-dimensional learned representations, solving a critical problem in various scie&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-ai-theory/hn05dqxyll/cover.png"/></item><item><title>Are High-Degree Representations Really Unnecessary in Equivariant Graph Neural Networks?</title><link>https://deep-diver.github.io/neurips2024/posters/m0ncnvugyn/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/m0ncnvugyn/</guid><description>High-degree representations significantly boost the expressiveness of E(3)-equivariant GNNs, overcoming limitations of lower-degree models on symmetric structures, as demonstrated theoretically and em&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/m0ncnvugyn/cover.png"/></item><item><title>Binding in hippocampal-entorhinal circuits enables compositionality in cognitive maps</title><link>https://deep-diver.github.io/neurips2024/posters/jo6t4rej32/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/jo6t4rej32/</guid><description>A novel model reveals how hippocampal-entorhinal circuits use compositional coding and modular attractor networks to enable robust and flexible spatial representation, advancing our understanding of c&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/jo6t4rej32/cover.png"/></item><item><title>Bisimulation Metrics are Optimal Transport Distances, and Can be Computed Efficiently</title><link>https://deep-diver.github.io/neurips2024/posters/csjvsnvtbg/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/csjvsnvtbg/</guid><description>Bisimulation metrics and optimal transport distances are equivalent and can be computed efficiently using a novel Sinkhorn Value Iteration algorithm.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/csjvsnvtbg/cover.png"/></item><item><title>Can Transformers Smell Like Humans?</title><link>https://deep-diver.github.io/neurips2024/spotlight-ai-theory/3f8i9glbzu/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-ai-theory/3f8i9glbzu/</guid><description>Pre-trained transformer models can predict human smell perception by encoding odorant chemical structures, aligning with expert labels, continuous ratings, and similarity assessments.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-ai-theory/3f8i9glbzu/cover.png"/></item><item><title>Causal Temporal Representation Learning with Nonstationary Sparse Transition</title><link>https://deep-diver.github.io/neurips2024/posters/j709rtaud1/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/j709rtaud1/</guid><description>CtrlNS: A novel framework for causal temporal representation learning tackles the challenge of nonstationary time series by leveraging sparse transition assumptions, achieving improved accuracy in ide&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/j709rtaud1/cover.png"/></item><item><title>Class Distribution Shifts in Zero-Shot Learning: Learning Robust Representations</title><link>https://deep-diver.github.io/neurips2024/posters/yuqubgiobg/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/yuqubgiobg/</guid><description>Zero-shot learning models often fail in real-world scenarios due to unseen class distribution shifts. This work introduces a novel algorithm that learns robust representations by creating synthetic d&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/yuqubgiobg/cover.png"/></item><item><title>Community Detection Guarantees using Embeddings Learned by Node2Vec</title><link>https://deep-diver.github.io/neurips2024/posters/cnpr4e2hcq/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/cnpr4e2hcq/</guid><description>Node2Vec, a popular network embedding method, is proven to consistently recover community structure in stochastic block models, paving the way for more reliable unsupervised community detection.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/cnpr4e2hcq/cover.png"/></item><item><title>Decoupling Semantic Similarity from Spatial Alignment for Neural Networks.</title><link>https://deep-diver.github.io/neurips2024/posters/ypfgct147z/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/ypfgct147z/</guid><description>Researchers developed semantic RSMs, a novel approach to measure semantic similarity in neural networks, improving image retrieval and aligning network representations with predicted class probabiliti&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/ypfgct147z/cover.png"/></item><item><title>DECRL: A Deep Evolutionary Clustering Jointed Temporal Knowledge Graph Representation Learning Approach</title><link>https://deep-diver.github.io/neurips2024/posters/v42zfm2gxw/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/v42zfm2gxw/</guid><description>DECRL: A novel deep learning approach for temporal knowledge graph representation learning, capturing high-order correlation evolution and outperforming existing methods.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/v42zfm2gxw/cover.png"/></item><item><title>Diffusion Model with Cross Attention as an Inductive Bias for Disentanglement</title><link>https://deep-diver.github.io/neurips2024/spotlight-others/stapcuwm9q/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-others/stapcuwm9q/</guid><description>Diffusion models with cross-attention: a powerful inductive bias for effortless disentanglement!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-others/stapcuwm9q/cover.png"/></item><item><title>Discrete Dictionary-based Decomposition Layer for Structured Representation Learning</title><link>https://deep-diver.github.io/neurips2024/posters/njuclfbosx/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/njuclfbosx/</guid><description>Boosting structured representation learning, a novel Discrete Dictionary-based Decomposition (D3) layer significantly improves systematic generalization in TPR-based models by efficiently decomposing &amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/njuclfbosx/cover.png"/></item><item><title>Disentangling Interpretable Factors with Supervised Independent Subspace Principal Component Analysis</title><link>https://deep-diver.github.io/neurips2024/posters/afnsmlye5k/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/afnsmlye5k/</guid><description>Supervised Independent Subspace PCA (sisPCA) disentangles interpretable factors in high-dimensional data by leveraging supervision to maximize subspace dependence on target variables while minimizing &amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/afnsmlye5k/cover.png"/></item><item><title>Divide-and-Conquer Predictive Coding: a structured Bayesian inference algorithm</title><link>https://deep-diver.github.io/neurips2024/posters/dxwiacvkwu/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/dxwiacvkwu/</guid><description>Divide-and-conquer predictive coding (DCPC) revolutionizes structured Bayesian inference by achieving superior performance in high-dimensional problems while remaining biologically plausible.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/dxwiacvkwu/cover.png"/></item><item><title>DropEdge not Foolproof: Effective Augmentation Method for Signed Graph Neural Networks</title><link>https://deep-diver.github.io/neurips2024/posters/cde2zbpioj/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/cde2zbpioj/</guid><description>SGA: A novel framework boosts Signed Graph Neural Network performance by addressing graph sparsity and unbalanced triangles, achieving up to 26.2% F1-micro improvement.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/cde2zbpioj/cover.png"/></item><item><title>Embedding Dimension of Contrastive Learning and $k$-Nearest Neighbors</title><link>https://deep-diver.github.io/neurips2024/posters/h0qu4mofly/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/h0qu4mofly/</guid><description>Discover optimal embedding dimensions for contrastive learning &amp;amp; k-NN using graph arboricity; achieve efficient model design &amp;amp; performance.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/h0qu4mofly/cover.png"/></item><item><title>Emergence of Hidden Capabilities: Exploring Learning Dynamics in Concept Space</title><link>https://deep-diver.github.io/neurips2024/spotlight-ai-theory/owuect6btl/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-ai-theory/owuect6btl/</guid><description>Generative models learn hidden capabilities suddenly during training, which can be explained and predicted using a novel &amp;lsquo;concept space&amp;rsquo; framework that analyzes learning dynamics and concept signal.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-ai-theory/owuect6btl/cover.png"/></item><item><title>Enhancing Graph Transformers with Hierarchical Distance Structural Encoding</title><link>https://deep-diver.github.io/neurips2024/posters/u4kldrgoph/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/u4kldrgoph/</guid><description>Hierarchical Distance Structural Encoding (HDSE) empowers graph transformers to better capture hierarchical graph structures, leading to improved performance in graph classification and regression tas&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/u4kldrgoph/cover.png"/></item><item><title>Enriching Disentanglement: From Logical Definitions to Quantitative Metrics</title><link>https://deep-diver.github.io/neurips2024/posters/tvq3xckwbb/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/tvq3xckwbb/</guid><description>This paper presents a novel approach to deriving theoretically grounded disentanglement metrics by linking logical definitions to quantitative measures, offering strong theoretical guarantees and easi&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/tvq3xckwbb/cover.png"/></item><item><title>Evaluating alignment between humans and neural network representations in image-based learning tasks</title><link>https://deep-diver.github.io/neurips2024/posters/8i6px5w1rf/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/8i6px5w1rf/</guid><description>Pretrained neural networks surprisingly capture fundamental aspects of human cognition, enabling generalization in image-based learning tasks, as demonstrated by aligning neural network representation&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/8i6px5w1rf/cover.png"/></item><item><title>Exploring Consistency in Graph Representations: from Graph Kernels to Graph Neural Networks</title><link>https://deep-diver.github.io/neurips2024/posters/dg0ho4m11k/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/dg0ho4m11k/</guid><description>Boost GNN graph classification accuracy by enforcing consistency in learned representations across layers using a novel loss function!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/dg0ho4m11k/cover.png"/></item><item><title>Exploring the Precise Dynamics of Single-Layer GAN Models: Leveraging Multi-Feature Discriminators for High-Dimensional Subspace Learning</title><link>https://deep-diver.github.io/neurips2024/posters/sohfyffnxt/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/sohfyffnxt/</guid><description>Single-layer GANs learn data subspaces more effectively using multi-feature discriminators, enabling faster training and better feature representation than conventional methods.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/sohfyffnxt/cover.png"/></item><item><title>From Causal to Concept-Based Representation Learning</title><link>https://deep-diver.github.io/neurips2024/posters/r5nev2shtj/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/r5nev2shtj/</guid><description>This paper introduces a novel geometric approach to concept-based representation learning, provably recovering interpretable concepts from diverse data without strict causal assumptions or many interv&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/r5nev2shtj/cover.png"/></item><item><title>Gated Inference Network: Inference and Learning State-Space Models</title><link>https://deep-diver.github.io/neurips2024/posters/z4duw3kzld/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/z4duw3kzld/</guid><description>GIN, a novel approximate Bayesian inference algorithm, efficiently handles nonlinear state-space models with high-dimensional, noisy observations by disentangling observation and dynamics. Achieving l&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/z4duw3kzld/cover.png"/></item><item><title>Generalization Analysis for Label-Specific Representation Learning</title><link>https://deep-diver.github.io/neurips2024/spotlight-ai-theory/dtpiuxdjhy/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-ai-theory/dtpiuxdjhy/</guid><description>Researchers derived tighter generalization bounds for label-specific representation learning (LSRL) methods, improving understanding of LSRL&amp;rsquo;s success and offering guidance for future algorithm develo&amp;hellip;</description></item><item><title>Global Distortions from Local Rewards: Neural Coding Strategies in Path-Integrating Neural Systems</title><link>https://deep-diver.github.io/neurips2024/posters/938eyyewtq/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/938eyyewtq/</guid><description>Reward-driven distortions in grid cell patterns are global, not local, preserving path integration while encoding environmental landmarks in spatial navigation.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/938eyyewtq/cover.png"/></item><item><title>Graph-based Unsupervised Disentangled Representation Learning via Multimodal Large Language Models</title><link>https://deep-diver.github.io/neurips2024/posters/a1wf2n967t/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/a1wf2n967t/</guid><description>GEM, a novel framework, uses a bidirectional graph and MLLMs to achieve fine-grained, relation-aware disentanglement in unsupervised representation learning, surpassing existing methods.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/a1wf2n967t/cover.png"/></item><item><title>Graphcode: Learning from multiparameter persistent homology using graph neural networks</title><link>https://deep-diver.github.io/neurips2024/posters/o23xftnhwr/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/o23xftnhwr/</guid><description>Graphcodes efficiently summarize complex datasets&amp;rsquo; topological properties using graph neural networks, enhancing machine learning accuracy.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/o23xftnhwr/cover.png"/></item><item><title>GraphCroc: Cross-Correlation Autoencoder for Graph Structural Reconstruction</title><link>https://deep-diver.github.io/neurips2024/posters/zn6s6vqyb0/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/zn6s6vqyb0/</guid><description>GraphCroc, a novel graph autoencoder, leverages cross-correlation to accurately reconstruct complex graph structures, outperforming self-correlation-based methods.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/zn6s6vqyb0/cover.png"/></item><item><title>HC-GAE: The Hierarchical Cluster-based Graph Auto-Encoder for Graph Representation Learning</title><link>https://deep-diver.github.io/neurips2024/posters/fx6asbmu6z/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/fx6asbmu6z/</guid><description>HC-GAE: A novel hierarchical graph autoencoder combats over-smoothing by using hard node assignment to create isolated subgraphs, improving graph representation learning for classification.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/fx6asbmu6z/cover.png"/></item><item><title>How Does Message Passing Improve Collaborative Filtering?</title><link>https://deep-diver.github.io/neurips2024/posters/c78u5zi4ea/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/c78u5zi4ea/</guid><description>TAG-CF boosts collaborative filtering accuracy by up to 39.2% on cold users, using only a single message-passing step at test time, avoiding costly training-time computations.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/c78u5zi4ea/cover.png"/></item><item><title>Hyperbolic Embeddings of Supervised Models</title><link>https://deep-diver.github.io/neurips2024/posters/n60xbfzwrk/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/n60xbfzwrk/</guid><description>This paper presents a novel approach for embedding supervised models in hyperbolic space, linking loss functions to hyperbolic distances and introducing monotonic decision trees for unambiguous visual&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/n60xbfzwrk/cover.png"/></item><item><title>Identifiable Object-Centric Representation Learning via Probabilistic Slot Attention</title><link>https://deep-diver.github.io/neurips2024/posters/qmovqbwmcy/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/qmovqbwmcy/</guid><description>Probabilistic Slot Attention achieves identifiable object-centric representations without supervision, advancing systematic generalization in machine learning.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/qmovqbwmcy/cover.png"/></item><item><title>Identifying General Mechanism Shifts in Linear Causal Representations</title><link>https://deep-diver.github.io/neurips2024/posters/jwaxhcytv1/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/jwaxhcytv1/</guid><description>Researchers can now pinpoint the sources of data shifts in complex linear causal systems using a new algorithm, even with limited perfect interventions, opening exciting possibilities for causal disco&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/jwaxhcytv1/cover.png"/></item><item><title>Inference via Interpolation: Contrastive Representations Provably Enable Planning and Inference</title><link>https://deep-diver.github.io/neurips2024/posters/pocs4jq7cv/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/pocs4jq7cv/</guid><description>Contrastive learning enables efficient probabilistic inference in high-dimensional time series by creating Gaussian representations that form a Gauss-Markov chain, allowing for closed-form solutions t&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/pocs4jq7cv/cover.png"/></item><item><title>Latent Functional Maps: a spectral framework for representation alignment</title><link>https://deep-diver.github.io/neurips2024/posters/mfvkedj4zw/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/mfvkedj4zw/</guid><description>Latent Functional Maps (LFM) offers a novel spectral framework for comparing, aligning, and transferring neural network representations, boosting downstream task performance and interpretability.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/mfvkedj4zw/cover.png"/></item><item><title>Learning Better Representations From Less Data For Propositional Satisfiability</title><link>https://deep-diver.github.io/neurips2024/spotlight-ai-theory/vmshnv8cvs/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-ai-theory/vmshnv8cvs/</guid><description>NeuRes, a novel neuro-symbolic approach, achieves superior SAT solving accuracy using significantly less training data than existing methods by combining certificate-driven learning with expert iterat&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-ai-theory/vmshnv8cvs/cover.png"/></item><item><title>Learning Complete Protein Representation by Dynamically Coupling of Sequence and Structure</title><link>https://deep-diver.github.io/neurips2024/posters/0e5uoajxo1/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/0e5uoajxo1/</guid><description>CoupleNet dynamically links protein sequences and structures for improved representations, surpassing state-of-the-art methods in function prediction, particularly for uncommon proteins.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/0e5uoajxo1/cover.png"/></item><item><title>Learning diverse causally emergent representations from time series data</title><link>https://deep-diver.github.io/neurips2024/posters/z6relfqv6w/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/z6relfqv6w/</guid><description>AI learns emergent system features from time-series data using a novel differentiable architecture maximizing causal emergence, outperforming pure mutual information maximization.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/z6relfqv6w/cover.png"/></item><item><title>Learning Human-like Representations to Enable Learning Human Values</title><link>https://deep-diver.github.io/neurips2024/posters/sqapqmbqip/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/sqapqmbqip/</guid><description>Aligning AI&amp;rsquo;s world representation with humans enables faster, safer learning of human values, improving both exploration and generalization.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/sqapqmbqip/cover.png"/></item><item><title>Learning Identifiable Factorized Causal Representations of Cellular Responses</title><link>https://deep-diver.github.io/neurips2024/posters/ahlabdhmqh/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/ahlabdhmqh/</guid><description>FCR, a novel method, reveals causal structure in single-cell perturbation data by learning disentangled cellular representations specific to covariates, treatments, and their interactions, outperformi&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/ahlabdhmqh/cover.png"/></item><item><title>Learning Linear Causal Representations from General Environments: Identifiability and Intrinsic Ambiguity</title><link>https://deep-diver.github.io/neurips2024/spotlight-ai-theory/db99jjwx3h/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-ai-theory/db99jjwx3h/</guid><description>LiNGCREL, a novel algorithm, provably recovers linear causal representations from diverse environments, achieving identifiability despite intrinsic ambiguities, thus advancing causal AI.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-ai-theory/db99jjwx3h/cover.png"/></item><item><title>Learning Partitions from Context</title><link>https://deep-diver.github.io/neurips2024/posters/prsgf5vdd0/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/prsgf5vdd0/</guid><description>Learning hidden structures from sparse interactions in data is computationally hard but can be achieved with sufficient samples using gradient-based methods; This is shown by analyzing the gradient dy&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/prsgf5vdd0/cover.png"/></item><item><title>Learning Place Cell Representations and Context-Dependent Remapping</title><link>https://deep-diver.github.io/neurips2024/posters/7eshfpqjno/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/7eshfpqjno/</guid><description>Neural networks learn place cell-like representations and context-dependent remapping using a novel similarity-based objective function, providing insights into hippocampal encoding.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/7eshfpqjno/cover.png"/></item><item><title>Learning Representations for Hierarchies with Minimal Support</title><link>https://deep-diver.github.io/neurips2024/posters/hfs800rezk/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/hfs800rezk/</guid><description>Learn graph representations efficiently by identifying the minimal data needed to uniquely define a graph&amp;rsquo;s structure, achieving robust performance with fewer resources.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/hfs800rezk/cover.png"/></item><item><title>Learning Structure-Aware Representations of Dependent Types</title><link>https://deep-diver.github.io/neurips2024/posters/e397soezh8/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/e397soezh8/</guid><description>This research pioneers the integration of machine learning with the dependently-typed programming language Agda, introducing a novel dataset and neural architecture for faithful program representation&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/e397soezh8/cover.png"/></item><item><title>Learning Structured Representations with Hyperbolic Embeddings</title><link>https://deep-diver.github.io/neurips2024/posters/wbtmn8sz2b/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/wbtmn8sz2b/</guid><description>HypStructure boosts representation learning by embedding label hierarchies into hyperbolic space, improving accuracy and interpretability.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/wbtmn8sz2b/cover.png"/></item><item><title>Learning to Shape In-distribution Feature Space for Out-of-distribution Detection</title><link>https://deep-diver.github.io/neurips2024/posters/1du3mmp5yn/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/1du3mmp5yn/</guid><description>Deterministically shaping in-distribution feature space solves OOD detection&amp;rsquo;s distributional assumption challenge, leading to superior performance.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/1du3mmp5yn/cover.png"/></item><item><title>Leveraging Contrastive Learning for Enhanced Node Representations in Tokenized Graph Transformers</title><link>https://deep-diver.github.io/neurips2024/posters/u6fuikzt1k/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/u6fuikzt1k/</guid><description>GCFormer, a novel graph Transformer, enhances node representation learning by employing a hybrid token generator and contrastive learning, outperforming existing methods on various datasets.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/u6fuikzt1k/cover.png"/></item><item><title>Logical characterizations of recurrent graph neural networks with reals and floats</title><link>https://deep-diver.github.io/neurips2024/posters/atdcnwqg5n/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/atdcnwqg5n/</guid><description>Recurrent Graph Neural Networks (GNNs) with real and floating-point numbers are precisely characterized by rule-based and infinitary modal logics, respectively, enabling a deeper understanding of thei&amp;hellip;</description></item><item><title>Long-range Meta-path Search on Large-scale Heterogeneous Graphs</title><link>https://deep-diver.github.io/neurips2024/posters/hbowltjnmk/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/hbowltjnmk/</guid><description>LMSPS: a novel framework efficiently leverages long-range dependencies in large heterogeneous graphs by dynamically identifying effective meta-paths, mitigating computational costs and over-smoothing.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/hbowltjnmk/cover.png"/></item><item><title>Marrying Causal Representation Learning with Dynamical Systems for Science</title><link>https://deep-diver.github.io/neurips2024/posters/mwhrxkz4mq/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/mwhrxkz4mq/</guid><description>This study marries causal representation learning with dynamical systems to enable parameter identification in real-world scientific data, unlocking downstream causal analysis for various applications&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/mwhrxkz4mq/cover.png"/></item><item><title>MatrixNet: Learning over symmetry groups using learned group representations</title><link>https://deep-diver.github.io/neurips2024/posters/b8jwgzraxg/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/b8jwgzraxg/</guid><description>MatrixNet learns efficient group representations for improved deep learning on symmetry groups, achieving higher sample efficiency and generalization than existing methods.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/b8jwgzraxg/cover.png"/></item><item><title>Measuring Dejavu Memorization Efficiently</title><link>https://deep-diver.github.io/neurips2024/posters/v8rrfnbj43/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/v8rrfnbj43/</guid><description>New method efficiently measures how well AI models memorize training data, revealing that open-source models memorize less than expected.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/v8rrfnbj43/cover.png"/></item><item><title>Metric Space Magnitude for Evaluating the Diversity of Latent Representations</title><link>https://deep-diver.github.io/neurips2024/posters/glgzzafssh/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/glgzzafssh/</guid><description>Novel metric space magnitude measures rigorously quantify the diversity of latent representations across multiple scales, showing superior performance in detecting mode collapse and characterizing emb&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/glgzzafssh/cover.png"/></item><item><title>Multi-Scale Representation Learning for Protein Fitness Prediction</title><link>https://deep-diver.github.io/neurips2024/posters/kwmvzidcen/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/kwmvzidcen/</guid><description>S3F: a novel multi-scale model achieves state-of-the-art protein fitness prediction by integrating protein sequence, structure, and surface features.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/kwmvzidcen/cover.png"/></item><item><title>Mutual Information Estimation via Normalizing Flows</title><link>https://deep-diver.github.io/neurips2024/posters/jiqxslvdls/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/jiqxslvdls/</guid><description>Researchers introduce a novel approach to mutual information (MI) estimation using normalizing flows, providing accurate estimates even in high dimensions.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/jiqxslvdls/cover.png"/></item><item><title>Neural Persistence Dynamics</title><link>https://deep-diver.github.io/neurips2024/posters/rcnzrfikx6/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/rcnzrfikx6/</guid><description>Neural Persistence Dynamics learns collective behavior from topological features, accurately predicting parameters of governing equations without tracking individual entities.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/rcnzrfikx6/cover.png"/></item><item><title>Non-Euclidean Mixture Model for Social Network Embedding</title><link>https://deep-diver.github.io/neurips2024/posters/nuzv2itlvn/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/nuzv2itlvn/</guid><description>Non-Euclidean Mixture Model (NMM-GNN) outperforms existing methods by using spherical and hyperbolic spaces to model homophily and social influence in social network embedding, improving link predicti&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/nuzv2itlvn/cover.png"/></item><item><title>Not so griddy: Internal representations of RNNs path integrating more than one agent</title><link>https://deep-diver.github.io/neurips2024/posters/dsmswubn8f/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/dsmswubn8f/</guid><description>RNNs trained on dual-agent path integration develop distinct internal representations compared to single-agent models, exhibiting weaker grid cell responses and enhanced border/band cell activity, wit&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/dsmswubn8f/cover.png"/></item><item><title>On Affine Homotopy between Language Encoders</title><link>https://deep-diver.github.io/neurips2024/posters/ftpowiawuz/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/ftpowiawuz/</guid><description>This paper introduces a novel notion of intrinsic similarity between language encoders, based on affine homotopy, and demonstrates its strong correlation with extrinsic similarity (downstream task per&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/ftpowiawuz/cover.png"/></item><item><title>On the Impact of Feature Heterophily on Link Prediction with Graph Neural Networks</title><link>https://deep-diver.github.io/neurips2024/posters/3lzhatxua9/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/3lzhatxua9/</guid><description>Graph Neural Networks (GNNs) struggle with heterophilic link prediction; this paper introduces formal definitions, theoretical analysis, improved designs, and real-world benchmarks to address this cha&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/3lzhatxua9/cover.png"/></item><item><title>On the Role of Attention Masks and LayerNorm in Transformers</title><link>https://deep-diver.github.io/neurips2024/posters/lih6ocdppg/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/lih6ocdppg/</guid><description>Transformers&amp;rsquo; self-attention mechanism, while powerful, suffers from rank collapse with increasing depth. This paper reveals that while masked attention still leads to exponential collapse, sparse att&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/lih6ocdppg/cover.png"/></item><item><title>PLIP: Language-Image Pre-training for Person Representation Learning</title><link>https://deep-diver.github.io/neurips2024/posters/e49qqjxcwq/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/e49qqjxcwq/</guid><description>PLIP: Novel language-image pre-training framework excels at person representation learning, surpassing existing methods on various downstream tasks thanks to its three pretext tasks and large-scale SY&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/e49qqjxcwq/cover.png"/></item><item><title>Poseidon: Efficient Foundation Models for PDEs</title><link>https://deep-diver.github.io/neurips2024/posters/jc1vkk3uxk/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/jc1vkk3uxk/</guid><description>POSEIDON: a novel foundation model for PDEs achieves significant gains in accuracy and sample efficiency, generalizing well to unseen physics.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/jc1vkk3uxk/cover.png"/></item><item><title>Preventing Model Collapse in Deep Canonical Correlation Analysis by Noise Regularization</title><link>https://deep-diver.github.io/neurips2024/posters/hsrs6yyuuk/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/hsrs6yyuuk/</guid><description>Noise Regularization rescues Deep Canonical Correlation Analysis from model collapse!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/hsrs6yyuuk/cover.png"/></item><item><title>ProtGO: Function-Guided Protein Modeling for Unified Representation Learning</title><link>https://deep-diver.github.io/neurips2024/posters/0ouutv92yf/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/0ouutv92yf/</guid><description>ProtGO: A novel unified framework integrating protein sequence, structure &amp;amp; function for superior representation learning, significantly outperforming current methods.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/0ouutv92yf/cover.png"/></item><item><title>Provably Optimal Memory Capacity for Modern Hopfield Models: Transformer-Compatible Dense Associative Memories as Spherical Codes</title><link>https://deep-diver.github.io/neurips2024/posters/4urew4ez6s/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/4urew4ez6s/</guid><description>Researchers achieve provably optimal memory capacity in transformer-compatible Hopfield models by framing the problem as an optimal spherical code arrangement, resulting in a novel sublinear time algo&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/4urew4ez6s/cover.png"/></item><item><title>Pure Message Passing Can Estimate Common Neighbor for Link Prediction</title><link>https://deep-diver.github.io/neurips2024/posters/xa3dvaolko/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/xa3dvaolko/</guid><description>Pure message passing in graph neural networks can accurately estimate common neighbor heuristics for superior link prediction.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/xa3dvaolko/cover.png"/></item><item><title>Random Representations Outperform Online Continually Learned Representations</title><link>https://deep-diver.github.io/neurips2024/posters/tz5k9iybbf/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/tz5k9iybbf/</guid><description>Random pixel projections outperform complex online continual learning methods for image classification, challenging assumptions about representation learning.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/tz5k9iybbf/cover.png"/></item><item><title>Rethinking Reconstruction-based Graph-Level Anomaly Detection: Limitations and a Simple Remedy</title><link>https://deep-diver.github.io/neurips2024/posters/e2inndpinb/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/e2inndpinb/</guid><description>MUSE, a novel graph anomaly detection method, leverages multifaceted summaries of reconstruction errors, achieving state-of-the-art performance by addressing limitations of existing Graph-AE-based met&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/e2inndpinb/cover.png"/></item><item><title>Revisiting K-mer Profile for Effective and Scalable Genome Representation Learning</title><link>https://deep-diver.github.io/neurips2024/spotlight-ai-theory/ehsd856ltb/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-ai-theory/ehsd856ltb/</guid><description>This paper proposes a lightweight and scalable k-mer based model for metagenomic binning, achieving comparable performance to computationally expensive genome foundation models while significantly imp&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-ai-theory/ehsd856ltb/cover.png"/></item><item><title>Sample Complexity of Interventional Causal Representation Learning</title><link>https://deep-diver.github.io/neurips2024/posters/xl9aaxl0u6/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/xl9aaxl0u6/</guid><description>First finite-sample analysis of interventional causal representation learning shows that surprisingly few samples suffice for accurate graph and latent variable recovery.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/xl9aaxl0u6/cover.png"/></item><item><title>Schur Nets: exploiting local structure for equivariance in higher order graph neural networks</title><link>https://deep-diver.github.io/neurips2024/posters/hrnsvflpgt/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/hrnsvflpgt/</guid><description>Schur Nets boost higher-order GNNs by efficiently exploiting local graph structure for automorphism equivariance, achieving improved performance without the computational burden of traditional methods&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/hrnsvflpgt/cover.png"/></item><item><title>Segment, Shuffle, and Stitch: A Simple Layer for Improving Time-Series Representations</title><link>https://deep-diver.github.io/neurips2024/posters/zm1lcgrphm/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/zm1lcgrphm/</guid><description>Boost time-series model accuracy with Segment, Shuffle, and Stitch (S3)! This simple layer shuffles data segments to enhance representation learning, improving classification, forecasting, and anomaly&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/zm1lcgrphm/cover.png"/></item><item><title>Sequential Signal Mixing Aggregation for Message Passing Graph Neural Networks</title><link>https://deep-diver.github.io/neurips2024/posters/arokfufiqs/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/arokfufiqs/</guid><description>Sequential Signal Mixing Aggregation (SSMA) boosts message-passing graph neural network performance by effectively mixing neighbor features, achieving state-of-the-art results across various benchmark&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/arokfufiqs/cover.png"/></item><item><title>Shape analysis for time series</title><link>https://deep-diver.github.io/neurips2024/posters/jm0iqsliol/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/jm0iqsliol/</guid><description>TS-LDDMM: Unsupervised time-series analysis handles irregular data, offering interpretable shape-based representations &amp;amp; exceeding existing methods in benchmarks.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/jm0iqsliol/cover.png"/></item><item><title>Soft Tensor Product Representations for Fully Continuous, Compositional Visual Representations</title><link>https://deep-diver.github.io/neurips2024/posters/oevsxvdush/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/oevsxvdush/</guid><description>Soft Tensor Product Representations (Soft TPRs) revolutionize compositional visual representation learning by seamlessly blending continuous vector spaces and compositional structures, leading to supe&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/oevsxvdush/cover.png"/></item><item><title>Spectral Graph Pruning Against Over-Squashing and Over-Smoothing</title><link>https://deep-diver.github.io/neurips2024/posters/emkrwjy2de/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/emkrwjy2de/</guid><description>Spectral graph pruning simultaneously mitigates over-squashing and over-smoothing in GNNs via edge deletion, improving generalization.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/emkrwjy2de/cover.png"/></item><item><title>Structured flexibility in recurrent neural networks via neuromodulation</title><link>https://deep-diver.github.io/neurips2024/posters/hbibqn3grd/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/hbibqn3grd/</guid><description>Neuromodulated RNNs (NM-RNNs) enhance RNN flexibility by dynamically scaling recurrent weights using a neuromodulatory subnetwork, achieving higher accuracy and generalizability on various tasks compa&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/hbibqn3grd/cover.png"/></item><item><title>SubgDiff: A Subgraph Diffusion Model to Improve Molecular Representation Learning</title><link>https://deep-diver.github.io/neurips2024/posters/ismto0todo/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/ismto0todo/</guid><description>SubgDiff enhances molecular representation learning by incorporating substructural information into a diffusion model framework, achieving superior performance in molecular force predictions.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/ismto0todo/cover.png"/></item><item><title>Temporal Graph Neural Tangent Kernel with Graphon-Guaranteed</title><link>https://deep-diver.github.io/neurips2024/posters/266nh7klsv/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/266nh7klsv/</guid><description>Temp-GÂ³NTK: a novel temporal graph neural tangent kernel guarantees convergence to graphon NTK, offering superior performance in temporal graph classification and node-level tasks.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/266nh7klsv/cover.png"/></item><item><title>Test-time Adaptation in Non-stationary Environments via Adaptive Representation Alignment</title><link>https://deep-diver.github.io/neurips2024/posters/0efuyvmrlv/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/0efuyvmrlv/</guid><description>Ada-ReAlign: a novel algorithm for continual test-time adaptation that leverages non-stationary representation learning to effectively align unlabeled data streams with source data, enhancing model ad&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/0efuyvmrlv/cover.png"/></item><item><title>The motion planning neural circuit in goal-directed navigation as Lie group operator search</title><link>https://deep-diver.github.io/neurips2024/posters/qz7bfmwizk/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/qz7bfmwizk/</guid><description>Neural circuits for goal-directed navigation are modeled as Lie group operator searches, implemented by a two-layer feedforward circuit mimicking Drosophila&amp;rsquo;s navigation system.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/qz7bfmwizk/cover.png"/></item><item><title>Towards Stable Representations for Protein Interface Prediction</title><link>https://deep-diver.github.io/neurips2024/posters/oewbklrrzu/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/oewbklrrzu/</guid><description>ATProt: Adversarial training makes protein interface prediction robust to flexibility!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/oewbklrrzu/cover.png"/></item><item><title>Trading Place for Space: Increasing Location Resolution Reduces Contextual Capacity in Hippocampal Codes</title><link>https://deep-diver.github.io/neurips2024/oral-ai-theory/reik4szmjt/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/oral-ai-theory/reik4szmjt/</guid><description>Boosting hippocampal spatial resolution surprisingly shrinks its contextual memory capacity, revealing a crucial trade-off between precision and context storage.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/oral-ai-theory/reik4szmjt/cover.png"/></item><item><title>Transferring disentangled representations: bridging the gap between synthetic and real images</title><link>https://deep-diver.github.io/neurips2024/posters/hfztzgwpxi/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/hfztzgwpxi/</guid><description>This paper bridges the gap between synthetic and real image disentanglement by proposing a novel transfer learning approach. The method leverages weakly supervised learning on synthetic data to train&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/hfztzgwpxi/cover.png"/></item><item><title>Wasserstein convergence of Cech persistence diagrams for samplings of submanifolds</title><link>https://deep-diver.github.io/neurips2024/posters/zehccykknh/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/zehccykknh/</guid><description>This paper proves that Äech persistence diagrams converge to the true underlying shape precisely when using Wasserstein distances with p &amp;gt; m, where m is the submanifold dimension, significantly advanc&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/zehccykknh/cover.png"/></item><item><title>Weisfeiler and Leman Go Loopy: A New Hierarchy for Graph Representational Learning</title><link>https://deep-diver.github.io/neurips2024/oral-ai-theory/9o2svnehor/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/oral-ai-theory/9o2svnehor/</guid><description>This paper introduces r-lWL, a new graph isomorphism test hierarchy that surpasses the limitations of the Weisfeiler-Leman test by counting cycles up to length r+2, and its GNN counterpart, r-lMPNN, w&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/oral-ai-theory/9o2svnehor/cover.png"/></item><item><title>What do Graph Neural Networks learn? Insights from Tropical Geometry</title><link>https://deep-diver.github.io/neurips2024/posters/oy2x0xfx0u/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/oy2x0xfx0u/</guid><description>Using tropical geometry, researchers reveal that ReLU-activated message-passing GNNs learn continuous piecewise linear functions, highlighting their expressivity limits and paving the way for enhanced&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/oy2x0xfx0u/cover.png"/></item><item><title>What Is Missing For Graph Homophily? Disentangling Graph Homophily For Graph Neural Networks</title><link>https://deep-diver.github.io/neurips2024/posters/gmdgef8xxu/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/gmdgef8xxu/</guid><description>Tri-Hom disentangles graph homophily into label, structural, and feature aspects, providing a more comprehensive and accurate metric for predicting GNN performance.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/gmdgef8xxu/cover.png"/></item><item><title>What Variables Affect Out-of-Distribution Generalization in Pretrained Models?</title><link>https://deep-diver.github.io/neurips2024/posters/poxgdfeb7q/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/poxgdfeb7q/</guid><description>High-resolution datasets with diverse classes significantly improve the transferability of pretrained DNNs by reducing representation compression and mitigating the &amp;rsquo;tunnel effect.'</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/poxgdfeb7q/cover.png"/></item><item><title>When does perceptual alignment benefit vision representations?</title><link>https://deep-diver.github.io/neurips2024/posters/nmlnmlymz4/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/nmlnmlymz4/</guid><description>Aligning vision models to human perceptual similarity judgments significantly boosts performance in diverse vision tasks like counting and segmentation, but surprisingly reduces performance in natural&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/nmlnmlymz4/cover.png"/></item><item><title>When is an Embedding Model More Promising than Another?</title><link>https://deep-diver.github.io/neurips2024/posters/vqfz7itgcl/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/vqfz7itgcl/</guid><description>This paper introduces a novel, task-agnostic method for ranking embedding models using information sufficiency, a concept derived from communication theory and statistical experiments comparison, demo&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/vqfz7itgcl/cover.png"/></item><item><title>Zipfian Whitening</title><link>https://deep-diver.github.io/neurips2024/posters/pasjxzmjb7/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/pasjxzmjb7/</guid><description>Zipfian Whitening: Weighting PCA whitening by word frequency dramatically improves NLP task performance, surpassing established baselines and providing a theoretical framework for existing methods.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/pasjxzmjb7/cover.png"/></item></channel></rss>