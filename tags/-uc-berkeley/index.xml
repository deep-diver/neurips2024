<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>üè¢ UC Berkeley on NeurIPS 2024</title><link>https://deep-diver.github.io/neurips2024/tags/-uc-berkeley/</link><description>Recent content in üè¢ UC Berkeley on NeurIPS 2024</description><generator>Hugo -- gohugo.io</generator><language>en</language><copyright>¬© 2025 AI Paper Reviewer</copyright><lastBuildDate>Thu, 26 Sep 2024 00:00:00 +0000</lastBuildDate><atom:link href="https://deep-diver.github.io/neurips2024/tags/-uc-berkeley/index.xml" rel="self" type="application/rss+xml"/><item><title>Active design of two-photon holographic stimulation for identifying neural population dynamics</title><link>https://deep-diver.github.io/neurips2024/posters/nlqee8qgge/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/nlqee8qgge/</guid><description>Researchers developed an active learning method using two-photon holographic optogenetics to efficiently identify neural population dynamics, achieving up to a two-fold reduction in data needed for ac&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/nlqee8qgge/cover.png"/></item><item><title>Approaching Human-Level Forecasting with Language Models</title><link>https://deep-diver.github.io/neurips2024/posters/flcdw7npry/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/flcdw7npry/</guid><description>Language models (LMs) can now forecast future events as accurately as expert human forecasters! This groundbreaking research unveils a retrieval-augmented LM system surpassing human forecasters in spe&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/flcdw7npry/cover.png"/></item><item><title>Binding in hippocampal-entorhinal circuits enables compositionality in cognitive maps</title><link>https://deep-diver.github.io/neurips2024/posters/jo6t4rej32/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/jo6t4rej32/</guid><description>A novel model reveals how hippocampal-entorhinal circuits use compositional coding and modular attractor networks to enable robust and flexible spatial representation, advancing our understanding of c&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/jo6t4rej32/cover.png"/></item><item><title>Compositional Automata Embeddings for Goal-Conditioned Reinforcement Learning</title><link>https://deep-diver.github.io/neurips2024/posters/6kdzhgrdhg/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/6kdzhgrdhg/</guid><description>Goal-conditioned RL gets a temporal upgrade with compositional DFAs (cDFAs), enabling zero-shot generalization and faster policy specialization via novel graph neural network embeddings and reach-avoi&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/6kdzhgrdhg/cover.png"/></item><item><title>Computational Aspects of Bayesian Persuasion under Approximate Best Response</title><link>https://deep-diver.github.io/neurips2024/posters/9b0iokn3up/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/9b0iokn3up/</guid><description>This paper presents efficient algorithms for Bayesian persuasion under approximate best response, offering polynomial-time solutions for specific cases and a quasi-polynomial-time approximation scheme&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/9b0iokn3up/cover.png"/></item><item><title>Connecting the Dots: LLMs can Infer and Verbalize Latent Structure from Disparate Training Data</title><link>https://deep-diver.github.io/neurips2024/posters/7fokmz6u8n/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/7fokmz6u8n/</guid><description>LLMs surprisingly infer censored knowledge from implicit training data hints, posing safety challenges.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/7fokmz6u8n/cover.png"/></item><item><title>Crafting Interpretable Embeddings for Language Neuroscience by Asking LLMs Questions</title><link>https://deep-diver.github.io/neurips2024/posters/mxmvwwybwe/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/mxmvwwybwe/</guid><description>LLM-based text embeddings are powerful but lack interpretability. This paper introduces QA-Emb, a novel method that uses an LLM to answer yes/no questions about a text, thereby producing an interpreta&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/mxmvwwybwe/cover.png"/></item><item><title>Designing Cell-Type-Specific Promoter Sequences Using Conservative Model-Based Optimization</title><link>https://deep-diver.github.io/neurips2024/posters/f8dwfflkyg/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/f8dwfflkyg/</guid><description>Researchers developed a data-efficient method using conservative model-based optimization to design cell-type-specific promoters for gene therapy, significantly improving cell-type specificity.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/f8dwfflkyg/cover.png"/></item><item><title>DigiRL: Training In-The-Wild Device-Control Agents with Autonomous Reinforcement Learning</title><link>https://deep-diver.github.io/neurips2024/posters/4xtvxmszpo/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/4xtvxmszpo/</guid><description>DigiRL: Autonomous RL trains robust in-the-wild device-control agents by offline-to-online RL, surpassing prior methods.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/4xtvxmszpo/cover.png"/></item><item><title>Dimension-free Private Mean Estimation for Anisotropic Distributions</title><link>https://deep-diver.github.io/neurips2024/posters/krwqcaia7z/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/krwqcaia7z/</guid><description>Dimension-free private mean estimation is achieved for anisotropic data, breaking the curse of dimensionality in privacy-preserving high-dimensional analysis.</description></item><item><title>Enhancing Efficiency of Safe Reinforcement Learning via Sample Manipulation</title><link>https://deep-diver.github.io/neurips2024/posters/opfjhl6dpr/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/opfjhl6dpr/</guid><description>ESPO enhances safe RL efficiency by dynamically manipulating sample size based on reward-safety gradient conflicts, ensuring faster training and superior performance.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/opfjhl6dpr/cover.png"/></item><item><title>Evaluating the design space of diffusion-based generative models</title><link>https://deep-diver.github.io/neurips2024/posters/9cmorofb75/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/9cmorofb75/</guid><description>This paper provides the first complete error analysis for diffusion models, theoretically justifying optimal training and sampling strategies and design choices for enhanced generative capabilities.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/9cmorofb75/cover.png"/></item><item><title>Evidence of Learned Look-Ahead in a Chess-Playing Neural Network</title><link>https://deep-diver.github.io/neurips2024/posters/8zg9so4ttv/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/8zg9so4ttv/</guid><description>Chess AI Leela Zero surprisingly uses learned look-ahead, internally representing future optimal moves, significantly improving its strategic decision-making.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/8zg9so4ttv/cover.png"/></item><item><title>Explaining Datasets in Words: Statistical Models with Natural Language Parameters</title><link>https://deep-diver.github.io/neurips2024/posters/u5bkogwwzw/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/u5bkogwwzw/</guid><description>This paper introduces a model-agnostic algorithm that uses natural language predicates to make statistical model parameters directly interpretable, significantly improving explainability.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/u5bkogwwzw/cover.png"/></item><item><title>Fair Allocation in Dynamic Mechanism Design</title><link>https://deep-diver.github.io/neurips2024/posters/beungps83o/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/beungps83o/</guid><description>This paper presents optimal fair mechanisms for dynamic auction design, maximizing seller revenue while guaranteeing minimum allocations to multiple buyer groups.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/beungps83o/cover.png"/></item><item><title>Fine-Tuning Large Vision-Language Models as Decision-Making Agents via Reinforcement Learning</title><link>https://deep-diver.github.io/neurips2024/posters/nbjmmf2izu/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/nbjmmf2izu/</guid><description>This paper presents a novel RL framework that fine-tunes large vision-language models (VLMs) to become effective decision-making agents. By incorporating chain-of-thought reasoning, the framework enab&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/nbjmmf2izu/cover.png"/></item><item><title>Gorilla: Large Language Model Connected with Massive APIs</title><link>https://deep-diver.github.io/neurips2024/posters/tbrnc6yemy/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/tbrnc6yemy/</guid><description>Gorilla: a fine-tuned LLaMA model surpasses GPT-4 in generating accurate API calls by using Retriever Aware Training (RAT) to adapt to changing APIs and reduce hallucinations.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/tbrnc6yemy/cover.png"/></item><item><title>How many classifiers do we need?</title><link>https://deep-diver.github.io/neurips2024/posters/m5dykarvn8/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/m5dykarvn8/</guid><description>Boost ensemble accuracy by predicting performance with fewer classifiers using a novel polarization law and refined error bounds.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/m5dykarvn8/cover.png"/></item><item><title>Immiscible Diffusion: Accelerating Diffusion Training with Noise Assignment</title><link>https://deep-diver.github.io/neurips2024/posters/kk23omge9g/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/kk23omge9g/</guid><description>Immiscible Diffusion boosts diffusion model training efficiency up to 3x by cleverly assigning noise to images, preventing the mixing of data in noise space and thus improving optimization.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/kk23omge9g/cover.png"/></item><item><title>In-Context Learning of a Linear Transformer Block: Benefits of the MLP Component and One-Step GD Initialization</title><link>https://deep-diver.github.io/neurips2024/posters/thou1rkdpz/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/thou1rkdpz/</guid><description>Linear Transformer Blocks (LTBs) achieve near-optimal in-context learning (ICL) for linear regression by effectively implementing one-step gradient descent with learnable initialization, a significant&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/thou1rkdpz/cover.png"/></item><item><title>Interpreting the Weight Space of Customized Diffusion Models</title><link>https://deep-diver.github.io/neurips2024/posters/dao2bfzmfy/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/dao2bfzmfy/</guid><description>Researchers model a manifold of customized diffusion models as a subspace of weights, enabling controllable creation of new models via sampling, editing, and inversion from a single image.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/dao2bfzmfy/cover.png"/></item><item><title>Is Knowledge Power? On the (Im)possibility of Learning from Strategic Interactions</title><link>https://deep-diver.github.io/neurips2024/posters/dlm6z1rrjv/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/dlm6z1rrjv/</guid><description>In strategic settings, repeated interactions alone may not enable uninformed players to achieve optimal outcomes, highlighting the persistent impact of information asymmetry.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/dlm6z1rrjv/cover.png"/></item><item><title>Is Value Learning Really the Main Bottleneck in Offline RL?</title><link>https://deep-diver.github.io/neurips2024/posters/nyp59a31ju/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/nyp59a31ju/</guid><description>Offline RL&amp;rsquo;s performance often lags behind imitation learning, but this paper reveals that policy learning and generalization, not value function learning, are often the main bottlenecks.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/nyp59a31ju/cover.png"/></item><item><title>KVQuant: Towards 10 Million Context Length LLM Inference with KV Cache Quantization</title><link>https://deep-diver.github.io/neurips2024/posters/0lxotew9du/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/0lxotew9du/</guid><description>KVQuant achieves &amp;lt;0.1 perplexity degradation with 3-bit quantization in LLMs by using per-channel key quantization, pre-RoPE quantization, and non-uniform quantization, enabling 10M context length inf&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/0lxotew9du/cover.png"/></item><item><title>Large Stepsize Gradient Descent for Non-Homogeneous Two-Layer Networks: Margin Improvement and Fast Optimization</title><link>https://deep-diver.github.io/neurips2024/posters/chloluhnai/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/chloluhnai/</guid><description>Large stepsize GD on non-homogeneous neural networks shows monotonic risk reduction after an initial oscillating phase, demonstrating implicit bias and optimization gains.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/chloluhnai/cover.png"/></item><item><title>Latent Learning Progress Drives Autonomous Goal Selection in Human Reinforcement Learning</title><link>https://deep-diver.github.io/neurips2024/posters/gbqzn9hiuc/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/gbqzn9hiuc/</guid><description>Humans autonomously select goals based on both observed and latent learning progress, impacting goal-conditioned policy learning.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/gbqzn9hiuc/cover.png"/></item><item><title>Learning to Assist Humans without Inferring Rewards</title><link>https://deep-diver.github.io/neurips2024/posters/wcnjmb7cv1/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/wcnjmb7cv1/</guid><description>AI agents trained with Empowerment via Successor Representations (ESR) empower humans by maximizing their control over environmental outcomes, eliminating the need for human intention inference, unlik&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/wcnjmb7cv1/cover.png"/></item><item><title>Learning to Understand: Identifying Interactions via the M√∂bius Transform</title><link>https://deep-diver.github.io/neurips2024/posters/glgexu1zg4/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/glgexu1zg4/</guid><description>Unlocking complex models&amp;rsquo; secrets: New algorithm identifies input interactions using the M√∂bius Transform, boosting interpretability with surprising speed and accuracy.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/glgexu1zg4/cover.png"/></item><item><title>Med-Real2Sim: Non-Invasive Medical Digital Twins using Physics-Informed Self-Supervised Learning</title><link>https://deep-diver.github.io/neurips2024/posters/xcuxjqqysd/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/xcuxjqqysd/</guid><description>Med-Real2Sim uses physics-informed self-supervised learning to build non-invasive medical digital twins, enabling in-silico clinical trials and unsupervised disease detection.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/xcuxjqqysd/cover.png"/></item><item><title>Mitigating Partial Observability in Decision Processes via the Lambda Discrepancy</title><link>https://deep-diver.github.io/neurips2024/posters/yaphvbgqwo/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/yaphvbgqwo/</guid><description>New metric, Œª-discrepancy, precisely detects &amp;amp; mitigates partial observability in sequential decision processes, significantly boosting reinforcement learning agent performance.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/yaphvbgqwo/cover.png"/></item><item><title>Mutli-Armed Bandits with Network Interference</title><link>https://deep-diver.github.io/neurips2024/posters/zxzovvoiil/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/zxzovvoiil/</guid><description>New algorithms conquer regret in multi-armed bandits challenged by network interference, achieving provably low regret with both known and unknown network structures.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/zxzovvoiil/cover.png"/></item><item><title>On Socially Fair Low-Rank Approximation and Column Subset Selection</title><link>https://deep-diver.github.io/neurips2024/posters/eo1qev952p/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/eo1qev952p/</guid><description>This paper reveals the surprising computational hardness of achieving fairness in low-rank approximation while offering efficient approximation algorithms.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/eo1qev952p/cover.png"/></item><item><title>Rethinking Score Distillation as a Bridge Between Image Distributions</title><link>https://deep-diver.github.io/neurips2024/posters/i8pkicj9km/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/i8pkicj9km/</guid><description>Researchers enhanced image generation by improving score distillation sampling via a novel Schr√∂dinger Bridge framework, improving realism without computational overhead.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/i8pkicj9km/cover.png"/></item><item><title>Scaling Laws in Linear Regression: Compute, Parameters, and Data</title><link>https://deep-diver.github.io/neurips2024/posters/ph7sdeanxp/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/ph7sdeanxp/</guid><description>Deep learning&amp;rsquo;s neural scaling laws defy conventional wisdom; this paper uses infinite-dimensional linear regression to theoretically explain this phenomenon, showing that implicit regularization of S&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/ph7sdeanxp/cover.png"/></item><item><title>Secret Collusion among AI Agents: Multi-Agent Deception via Steganography</title><link>https://deep-diver.github.io/neurips2024/posters/bnnsqhzj88/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/bnnsqhzj88/</guid><description>AI agents can secretly collude using steganography, hiding their interactions from oversight. This research formalizes this threat, analyzes LLMs&amp;rsquo; capabilities, and proposes mitigation strategies.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/bnnsqhzj88/cover.png"/></item><item><title>Segment Anything without Supervision</title><link>https://deep-diver.github.io/neurips2024/posters/agqldloxxy/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/agqldloxxy/</guid><description>Unsupervised SAM (UnSAM) achieves competitive image segmentation results without human annotation, surpassing previous unsupervised methods and even improving supervised SAM&amp;rsquo;s accuracy.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/agqldloxxy/cover.png"/></item><item><title>SGLang: Efficient Execution of Structured Language Model Programs</title><link>https://deep-diver.github.io/neurips2024/posters/vqkakqibpq/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/vqkakqibpq/</guid><description>SGLang: A new system boosts LLM program execution speed by up to 6.4x, simplifying complex LLM application programming.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/vqkakqibpq/cover.png"/></item><item><title>SSDM: Scalable Speech Dysfluency Modeling</title><link>https://deep-diver.github.io/neurips2024/posters/ixehb4ncvy/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/ixehb4ncvy/</guid><description>SSDM: Scalable Speech Dysfluency Modeling tackles challenges in speech dysfluency analysis by using articulatory gestures for scalable alignment, a connectionist subsequence aligner for efficient dysf&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/ixehb4ncvy/cover.png"/></item><item><title>Synthetic Programming Elicitation for Text-to-Code in Very Low-Resource Programming and Formal Languages</title><link>https://deep-diver.github.io/neurips2024/posters/kqpzfiwviu/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/kqpzfiwviu/</guid><description>LLMs struggle with very low-resource programming languages. SPEAC, a novel synthetic programming elicitation and compilation approach, uses an intermediate language to enable LLMs to generate syntact&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/kqpzfiwviu/cover.png"/></item><item><title>The Impact of Initialization on LoRA Finetuning Dynamics</title><link>https://deep-diver.github.io/neurips2024/posters/sn3uryritk/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/sn3uryritk/</guid><description>LoRA&amp;rsquo;s initialization significantly impacts finetuning; initializing matrix A randomly and B to zero yields better performance than vice-versa due to enabling larger learning rates.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/sn3uryritk/cover.png"/></item><item><title>The Importance of Being Scalable: Improving the Speed and Accuracy of Neural Network Interatomic Potentials Across Chemical Domains</title><link>https://deep-diver.github.io/neurips2024/posters/y4mbazu4vy/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/y4mbazu4vy/</guid><description>ESCAIP, a novel neural network architecture, dramatically boosts the speed and accuracy of atomic simulations by leveraging attention mechanisms, enabling efficient large-scale modeling across diverse&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/y4mbazu4vy/cover.png"/></item><item><title>Towards a Theoretical Understanding of the 'Reversal Curse' via Training Dynamics</title><link>https://deep-diver.github.io/neurips2024/posters/qowf3lo6m7/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/qowf3lo6m7/</guid><description>LLMs struggle with simple logical reasoning due to the &amp;lsquo;reversal curse.&amp;rsquo; This paper reveals that weight asymmetry during training is the culprit, offering a new theoretical perspective and potential s&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/qowf3lo6m7/cover.png"/></item><item><title>Truthfulness of Calibration Measures</title><link>https://deep-diver.github.io/neurips2024/posters/cda8hftygc/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/cda8hftygc/</guid><description>Researchers developed Subsampled Smooth Calibration Error (SSCE), a new truthful calibration measure for sequential prediction, solving the problem of existing measures being easily gamed.</description></item><item><title>Ultrafast classical phylogenetic method beats large protein language models on variant effect prediction</title><link>https://deep-diver.github.io/neurips2024/posters/h7menkyb2j/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/h7menkyb2j/</guid><description>A revolutionary ultrafast phylogenetic method outperforms protein language models in variant effect prediction by efficiently estimating amino acid substitution rates from massive datasets.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/h7menkyb2j/cover.png"/></item><item><title>Using Surrogates in Covariate-adjusted Response-adaptive Randomization Experiments with Delayed Outcomes</title><link>https://deep-diver.github.io/neurips2024/posters/fotmgw8w5t/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/fotmgw8w5t/</guid><description>Boosting clinical trial efficiency, this research introduces a covariate-adjusted response-adaptive randomization (CARA) design that effectively leverages surrogate outcomes to handle delayed primary &amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/fotmgw8w5t/cover.png"/></item><item><title>Verified Code Transpilation with LLMs</title><link>https://deep-diver.github.io/neurips2024/posters/spwe9slrfg/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/spwe9slrfg/</guid><description>LLMLIFT: An LLM-powered approach builds verified lifting tools for DSLs, outperforming prior symbolic methods in benchmark transpilation and requiring less development effort.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/spwe9slrfg/cover.png"/></item><item><title>Warm-starting Push-Relabel</title><link>https://deep-diver.github.io/neurips2024/posters/yyy5lze547/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/yyy5lze547/</guid><description>This research introduces the first theoretical guarantees for warm-starting the celebrated Push-Relabel network flow algorithm, improving its speed using a predicted flow, while maintaining worst-case&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/yyy5lze547/cover.png"/></item></channel></rss>