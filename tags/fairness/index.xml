<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Fairness on NeurIPS 2024</title><link>https://deep-diver.github.io/neurips2024/tags/fairness/</link><description>Recent content in Fairness on NeurIPS 2024</description><generator>Hugo -- gohugo.io</generator><language>en</language><copyright>© 2024 AI Paper Reviewer</copyright><lastBuildDate>Thu, 26 Sep 2024 00:00:00 +0000</lastBuildDate><atom:link href="https://deep-diver.github.io/neurips2024/tags/fairness/index.xml" rel="self" type="application/rss+xml"/><item><title>A Closer Look at AUROC and AUPRC under Class Imbalance</title><link>https://deep-diver.github.io/neurips2024/posters/s3hva808gk/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/s3hva808gk/</guid><description>Debunking a common myth, this paper proves that AUPRC is not superior to AUROC for imbalanced datasets, and in fact, can worsen algorithmic bias.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/s3hva808gk/cover.png"/></item><item><title>A Simple Remedy for Dataset Bias via Self-Influence: A Mislabeled Sample Perspective</title><link>https://deep-diver.github.io/neurips2024/posters/zvrrpnqhfw/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/zvrrpnqhfw/</guid><description>This paper introduces Bias-Conditioned Self-Influence (BCSI) for precise bias-conflicting sample detection and model rectification, enhancing fairness in machine learning.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/zvrrpnqhfw/cover.png"/></item><item><title>Are Your Models Still Fair? Fairness Attacks on Graph Neural Networks via Node Injections</title><link>https://deep-diver.github.io/neurips2024/posters/luqrikguru/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/luqrikguru/</guid><description>Node Injection-based Fairness Attack (NIFA) reveals GNNs&amp;rsquo; vulnerability to realistic fairness attacks by injecting a small percentage of nodes, significantly undermining fairness even in fairness-awar&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/luqrikguru/cover.png"/></item><item><title>Bias in Motion: Theoretical Insights into the Dynamics of Bias in SGD Training</title><link>https://deep-diver.github.io/neurips2024/posters/quylbzwttv/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/quylbzwttv/</guid><description>AI systems acquire bias during training, impacting accuracy across sub-populations. This research unveils bias&amp;rsquo;s dynamic nature, revealing how classifier preferences shift over time, influenced by dat&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/quylbzwttv/cover.png"/></item><item><title>Dueling over Dessert, Mastering the Art of Repeated Cake Cutting</title><link>https://deep-diver.github.io/neurips2024/posters/mftvnzhsht/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/mftvnzhsht/</guid><description>Repeated cake-cutting game reveals that strategic players can exploit myopic opponents, but equitable outcomes are achievable through specific strategies.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/mftvnzhsht/cover.png"/></item><item><title>Fair Allocation in Dynamic Mechanism Design</title><link>https://deep-diver.github.io/neurips2024/posters/beungps83o/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/beungps83o/</guid><description>This paper presents optimal fair mechanisms for dynamic auction design, maximizing seller revenue while guaranteeing minimum allocations to multiple buyer groups.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/beungps83o/cover.png"/></item><item><title>Fair Bilevel Neural Network (FairBiNN): On Balancing fairness and accuracy via Stackelberg Equilibrium</title><link>https://deep-diver.github.io/neurips2024/posters/e2r4wnhhgq/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/e2r4wnhhgq/</guid><description>FairBiNN, a novel bilevel neural network, achieves Pareto optimal solutions by simultaneously optimizing for accuracy and fairness, outperforming existing methods.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/e2r4wnhhgq/cover.png"/></item><item><title>Fair GLASSO: Estimating Fair Graphical Models with Unbiased Statistical Behavior</title><link>https://deep-diver.github.io/neurips2024/posters/a3cauwmxnv/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/a3cauwmxnv/</guid><description>Fair GLASSO ensures fair Gaussian graphical models by introducing novel bias metrics and a penalized maximum likelihood estimator to mitigate group biases in data.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/a3cauwmxnv/cover.png"/></item><item><title>Fair Secretaries with Unfair Predictions</title><link>https://deep-diver.github.io/neurips2024/posters/dxxj4s06yl/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/dxxj4s06yl/</guid><description>Fair algorithms can leverage biased predictions to improve performance while guaranteeing fairness for all candidates.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/dxxj4s06yl/cover.png"/></item><item><title>Fair Wasserstein Coresets</title><link>https://deep-diver.github.io/neurips2024/posters/ylcej2xiw5/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/ylcej2xiw5/</guid><description>Fair Wasserstein Coresets (FWC) efficiently generates fair, representative subsets of large datasets for downstream machine learning tasks, improving fairness and utility.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/ylcej2xiw5/cover.png"/></item><item><title>Fairness in Social Influence Maximization via Optimal Transport</title><link>https://deep-diver.github.io/neurips2024/posters/axw8xvqpkf/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/axw8xvqpkf/</guid><description>Fairness in social influence maximization is achieved via optimal transport, optimizing both outreach and a new &amp;lsquo;mutual fairness&amp;rsquo; metric that considers variability in outreach scenarios.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/axw8xvqpkf/cover.png"/></item><item><title>Fairness without Harm: An Influence-Guided Active Sampling Approach</title><link>https://deep-diver.github.io/neurips2024/posters/yyjojvbccd/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/yyjojvbccd/</guid><description>FairnessWithoutHarm achieves fairer ML models without sacrificing accuracy by using an influence-guided active sampling method that doesn&amp;rsquo;t require sensitive training data.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/yyjojvbccd/cover.png"/></item><item><title>Fairness-Aware Estimation of Graphical Models</title><link>https://deep-diver.github.io/neurips2024/posters/wvws8gowyr/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/wvws8gowyr/</guid><description>Fairness-aware estimation of graphical models (GMs) tackles bias in GM estimations by integrating graph disparity error and a tailored loss function into multi-objective optimization, effectively miti&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/wvws8gowyr/cover.png"/></item><item><title>Group-wise oracle-efficient algorithms for online multi-group learning</title><link>https://deep-diver.github.io/neurips2024/posters/klsyhjllx5/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/klsyhjllx5/</guid><description>Oracle-efficient algorithms conquer online multi-group learning, achieving sublinear regret even with massive, overlapping groups, paving the way for fair and efficient large-scale online systems.</description></item><item><title>Honor Among Bandits: No-Regret Learning for Online Fair Division</title><link>https://deep-diver.github.io/neurips2024/spotlight-ai-theory/ocqbc0edjj/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-ai-theory/ocqbc0edjj/</guid><description>Online fair division algorithm achieves Õ(T²/³) regret while guaranteeing envy-freeness or proportionality in expectation, a result proven tight.</description></item><item><title>Interpolating Item and User Fairness in Multi-Sided Recommendations</title><link>https://deep-diver.github.io/neurips2024/posters/taog1hdvgy/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/taog1hdvgy/</guid><description>Problem (FAIR) framework and FORM algorithm achieve flexible multi-stakeholder fairness in online recommendation systems, balancing platform revenue with user and item fairness.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/taog1hdvgy/cover.png"/></item><item><title>Mind the Gap: A Causal Perspective on Bias Amplification in Prediction &amp; Decision-Making</title><link>https://deep-diver.github.io/neurips2024/posters/axyl24yhjn/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/axyl24yhjn/</guid><description>AI bias amplification in decision-making is uncovered, showing how fair prediction scores can become discriminatory after thresholding, urging stronger regulatory oversight.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/axyl24yhjn/cover.png"/></item><item><title>Mind the Graph When Balancing Data for Fairness or Robustness</title><link>https://deep-diver.github.io/neurips2024/posters/lqr22jm5l3/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/lqr22jm5l3/</guid><description>Data balancing in machine learning can hurt fairness and robustness; this paper reveals when and why, offering solutions for safer AI.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/lqr22jm5l3/cover.png"/></item><item><title>Monoculture in Matching Markets</title><link>https://deep-diver.github.io/neurips2024/posters/p5yezhumss/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/p5yezhumss/</guid><description>Algorithmic monoculture harms applicant selection and market efficiency; this paper introduces a model to analyze its effects in two-sided matching markets.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/p5yezhumss/cover.png"/></item><item><title>OxonFair: A Flexible Toolkit for Algorithmic Fairness</title><link>https://deep-diver.github.io/neurips2024/posters/ztwl4ubnxv/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/ztwl4ubnxv/</guid><description>OxonFair: a new open-source toolkit for enforcing fairness in binary classification, supporting NLP, Computer Vision, and tabular data, optimizing any fairness metric, and minimizing performance degra&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/ztwl4ubnxv/cover.png"/></item><item><title>Parameterized Approximation Schemes for Fair-Range Clustering</title><link>https://deep-diver.github.io/neurips2024/posters/zzgbudspzj/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/zzgbudspzj/</guid><description>First parameterized approximation schemes for fair-range k-median &amp;amp; k-means in Euclidean spaces are presented, offering faster (1+ε)-approximation algorithms.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/zzgbudspzj/cover.png"/></item><item><title>Plant-and-Steal: Truthful Fair Allocations via Predictions</title><link>https://deep-diver.github.io/neurips2024/posters/afb97f8qsf/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/afb97f8qsf/</guid><description>Learning-augmented mechanisms for fair allocation achieve constant-factor approximation with accurate predictions and near-optimal approximation even with inaccurate ones.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/afb97f8qsf/cover.png"/></item><item><title>Policy Aggregation</title><link>https://deep-diver.github.io/neurips2024/posters/ybiuvixjth/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/ybiuvixjth/</guid><description>This paper introduces efficient algorithms that leverage social choice theory to aggregate multiple individual preferences, resulting in a desirable collective AI policy.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/ybiuvixjth/cover.png"/></item><item><title>Proportional Fairness in Clustering: A Social Choice Perspective</title><link>https://deep-diver.github.io/neurips2024/posters/kslx5pfpos/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/kslx5pfpos/</guid><description>This paper reveals the surprising connection between individual and proportional fairness in clustering, showing that any approximation to one directly implies an approximation to the other, enabling &amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/kslx5pfpos/cover.png"/></item><item><title>RashomonGB: Analyzing the Rashomon Effect and Mitigating Predictive Multiplicity in Gradient Boosting</title><link>https://deep-diver.github.io/neurips2024/posters/zpw6nmhvku/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/zpw6nmhvku/</guid><description>RashomonGB tackles predictive multiplicity in gradient boosting by introducing a novel inference technique to efficiently identify and mitigate conflicting model predictions, improving model selection&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/zpw6nmhvku/cover.png"/></item><item><title>SureMap: Simultaneous mean estimation for single-task and multi-task disaggregated evaluation</title><link>https://deep-diver.github.io/neurips2024/posters/atnt3fuvbg/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/atnt3fuvbg/</guid><description>SureMap, a new method, significantly boosts accuracy in single and multi-task disaggregated evaluations of AI models using limited data by transforming the problem into Gaussian mean estimation and cl&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/atnt3fuvbg/cover.png"/></item><item><title>The Group Robustness is in the Details: Revisiting Finetuning under Spurious Correlations</title><link>https://deep-diver.github.io/neurips2024/posters/ehziwahj06/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/ehziwahj06/</guid><description>Finetuning&amp;rsquo;s impact on worst-group accuracy is surprisingly nuanced, with common class-balancing methods sometimes hurting performance; a novel mixture method consistently outperforms others.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/ehziwahj06/cover.png"/></item><item><title>User-item fairness tradeoffs in recommendations</title><link>https://deep-diver.github.io/neurips2024/posters/zozjms3jts/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/zozjms3jts/</guid><description>Recommendation systems must balance user satisfaction with fair item exposure. This research provides a theoretical model and empirical validation showing that user preference diversity can significan&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/zozjms3jts/cover.png"/></item></channel></rss>