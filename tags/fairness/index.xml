<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Fairness on NeurIPS 2024</title><link>https://deep-diver.github.io/neurips2024/tags/fairness/</link><description>Recent content in Fairness on NeurIPS 2024</description><generator>Hugo -- gohugo.io</generator><language>en</language><copyright>Â© 2025 AI Paper Reviewer</copyright><lastBuildDate>Thu, 26 Sep 2024 00:00:00 +0000</lastBuildDate><atom:link href="https://deep-diver.github.io/neurips2024/tags/fairness/index.xml" rel="self" type="application/rss+xml"/><item><title>A Closer Look at AUROC and AUPRC under Class Imbalance</title><link>https://deep-diver.github.io/neurips2024/posters/s3hva808gk/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/s3hva808gk/</guid><description>Debunking a common myth, this paper proves that AUPRC is not superior to AUROC for imbalanced datasets, and in fact, can worsen algorithmic bias.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/s3hva808gk/cover.png"/></item><item><title>A Simple Remedy for Dataset Bias via Self-Influence: A Mislabeled Sample Perspective</title><link>https://deep-diver.github.io/neurips2024/posters/zvrrpnqhfw/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/zvrrpnqhfw/</guid><description>This paper introduces Bias-Conditioned Self-Influence (BCSI) for precise bias-conflicting sample detection and model rectification, enhancing fairness in machine learning.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/zvrrpnqhfw/cover.png"/></item><item><title>A Unifying Post-Processing Framework for Multi-Objective Learn-to-Defer Problems</title><link>https://deep-diver.github.io/neurips2024/posters/mtsi1eddbh/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/mtsi1eddbh/</guid><description>A novel post-processing framework, based on a d-dimensional generalization of the Neyman-Pearson lemma, optimally solves multi-objective learn-to-defer problems under various constraints, improving co&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/mtsi1eddbh/cover.png"/></item><item><title>Achievable Fairness on Your Data With Utility Guarantees</title><link>https://deep-diver.github.io/neurips2024/posters/gtemizlzmr/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/gtemizlzmr/</guid><description>This paper introduces a computationally efficient method to approximate the optimal accuracy-fairness trade-off curve for various datasets, providing rigorous statistical guarantees and quantifying un&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/gtemizlzmr/cover.png"/></item><item><title>Are Your Models Still Fair? Fairness Attacks on Graph Neural Networks via Node Injections</title><link>https://deep-diver.github.io/neurips2024/posters/luqrikguru/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/luqrikguru/</guid><description>Node Injection-based Fairness Attack (NIFA) reveals GNNs&amp;rsquo; vulnerability to realistic fairness attacks by injecting a small percentage of nodes, significantly undermining fairness even in fairness-awar&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/luqrikguru/cover.png"/></item><item><title>Automating Data Annotation under Strategic Human Agents: Risks and Potential Solutions</title><link>https://deep-diver.github.io/neurips2024/posters/2ujlv3kpgo/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/2ujlv3kpgo/</guid><description>AI models retraining with model-annotated data incorporating human strategic responses can lead to unexpected outcomes, potentially reducing the proportion of agents with positive labels over time, wh&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/2ujlv3kpgo/cover.png"/></item><item><title>Bias in Motion: Theoretical Insights into the Dynamics of Bias in SGD Training</title><link>https://deep-diver.github.io/neurips2024/posters/quylbzwttv/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/quylbzwttv/</guid><description>AI systems acquire bias during training, impacting accuracy across sub-populations. This research unveils bias&amp;rsquo;s dynamic nature, revealing how classifier preferences shift over time, influenced by dat&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/quylbzwttv/cover.png"/></item><item><title>Building a stable classifier with the inflated argmax</title><link>https://deep-diver.github.io/neurips2024/posters/m7znxntzsp/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/m7znxntzsp/</guid><description>Boost classifier stability with the novel inflated argmax, guaranteeing reliable multiclass classification without distributional assumptions!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/m7znxntzsp/cover.png"/></item><item><title>Conformal Classification with Equalized Coverage for Adaptively Selected Groups</title><link>https://deep-diver.github.io/neurips2024/posters/3pwhkxk1sc/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/3pwhkxk1sc/</guid><description>This paper introduces AFCP, a novel conformal inference method that generates prediction sets with valid coverage conditional on adaptively selected features, achieving a practical balance between eff&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/3pwhkxk1sc/cover.png"/></item><item><title>Counterfactual Fairness by Combining Factual and Counterfactual Predictions</title><link>https://deep-diver.github.io/neurips2024/posters/j0itri0uin/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/j0itri0uin/</guid><description>This paper proposes a novel method to achieve optimal counterfactual fairness in machine learning models while minimizing predictive performance degradation.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/j0itri0uin/cover.png"/></item><item><title>DeNetDM: Debiasing by Network Depth Modulation</title><link>https://deep-diver.github.io/neurips2024/posters/0dta21q83c/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/0dta21q83c/</guid><description>DeNetDM uses network depth modulation to automatically debiase image classifiers without bias annotations or data augmentation, improving accuracy by 5%.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/0dta21q83c/cover.png"/></item><item><title>Dueling over Dessert, Mastering the Art of Repeated Cake Cutting</title><link>https://deep-diver.github.io/neurips2024/posters/mftvnzhsht/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/mftvnzhsht/</guid><description>Repeated cake-cutting game reveals that strategic players can exploit myopic opponents, but equitable outcomes are achievable through specific strategies.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/mftvnzhsht/cover.png"/></item><item><title>Enhancing Robustness of Last Layer Two-Stage Fair Model Corrections</title><link>https://deep-diver.github.io/neurips2024/posters/chnj3w4hfg/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/chnj3w4hfg/</guid><description>Boosting fair machine learning&amp;rsquo;s robustness against noisy labels, this work introduces a novel label-spreading method, achieving state-of-the-art worst-group accuracy.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/chnj3w4hfg/cover.png"/></item><item><title>Fair Allocation in Dynamic Mechanism Design</title><link>https://deep-diver.github.io/neurips2024/posters/beungps83o/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/beungps83o/</guid><description>This paper presents optimal fair mechanisms for dynamic auction design, maximizing seller revenue while guaranteeing minimum allocations to multiple buyer groups.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/beungps83o/cover.png"/></item><item><title>Fair and Welfare-Efficient Constrained Multi-Matchings under Uncertainty</title><link>https://deep-diver.github.io/neurips2024/posters/6kthdqfgma/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/6kthdqfgma/</guid><description>This paper presents novel, scalable algorithms for fair and efficient constrained resource allocation under uncertainty using robust and CVaR optimization.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/6kthdqfgma/cover.png"/></item><item><title>Fair Bilevel Neural Network (FairBiNN): On Balancing fairness and accuracy via Stackelberg Equilibrium</title><link>https://deep-diver.github.io/neurips2024/posters/e2r4wnhhgq/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/e2r4wnhhgq/</guid><description>FairBiNN, a novel bilevel neural network, achieves Pareto optimal solutions by simultaneously optimizing for accuracy and fairness, outperforming existing methods.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/e2r4wnhhgq/cover.png"/></item><item><title>Fair GLASSO: Estimating Fair Graphical Models with Unbiased Statistical Behavior</title><link>https://deep-diver.github.io/neurips2024/posters/a3cauwmxnv/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/a3cauwmxnv/</guid><description>Fair GLASSO ensures fair Gaussian graphical models by introducing novel bias metrics and a penalized maximum likelihood estimator to mitigate group biases in data.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/a3cauwmxnv/cover.png"/></item><item><title>Fair Online Bilateral Trade</title><link>https://deep-diver.github.io/neurips2024/posters/i90ypqplgl/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/i90ypqplgl/</guid><description>This paper proposes a novel online bilateral trading algorithm maximizing the &lt;em>fair&lt;/em> gain from trade and provides tight regret bounds under various settings.</description></item><item><title>Fair Secretaries with Unfair Predictions</title><link>https://deep-diver.github.io/neurips2024/posters/dxxj4s06yl/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/dxxj4s06yl/</guid><description>Fair algorithms can leverage biased predictions to improve performance while guaranteeing fairness for all candidates.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/dxxj4s06yl/cover.png"/></item><item><title>Fair Wasserstein Coresets</title><link>https://deep-diver.github.io/neurips2024/posters/ylcej2xiw5/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/ylcej2xiw5/</guid><description>Fair Wasserstein Coresets (FWC) efficiently generates fair, representative subsets of large datasets for downstream machine learning tasks, improving fairness and utility.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/ylcej2xiw5/cover.png"/></item><item><title>Fairness and Efficiency in Online Class Matching</title><link>https://deep-diver.github.io/neurips2024/posters/kmaxn7hf6d/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/kmaxn7hf6d/</guid><description>First non-wasteful algorithm achieving 1/2-approximation for class envy-freeness, class proportionality, and utilitarian social welfare in online class matching.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/kmaxn7hf6d/cover.png"/></item><item><title>Fairness in Social Influence Maximization via Optimal Transport</title><link>https://deep-diver.github.io/neurips2024/posters/axw8xvqpkf/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/axw8xvqpkf/</guid><description>Fairness in social influence maximization is achieved via optimal transport, optimizing both outreach and a new &amp;lsquo;mutual fairness&amp;rsquo; metric that considers variability in outreach scenarios.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/axw8xvqpkf/cover.png"/></item><item><title>Fairness without Harm: An Influence-Guided Active Sampling Approach</title><link>https://deep-diver.github.io/neurips2024/posters/yyjojvbccd/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/yyjojvbccd/</guid><description>FairnessWithoutHarm achieves fairer ML models without sacrificing accuracy by using an influence-guided active sampling method that doesn&amp;rsquo;t require sensitive training data.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/yyjojvbccd/cover.png"/></item><item><title>Fairness-Aware Estimation of Graphical Models</title><link>https://deep-diver.github.io/neurips2024/posters/wvws8gowyr/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/wvws8gowyr/</guid><description>Fairness-aware estimation of graphical models (GMs) tackles bias in GM estimations by integrating graph disparity error and a tailored loss function into multi-objective optimization, effectively miti&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/wvws8gowyr/cover.png"/></item><item><title>FairWire: Fair Graph Generation</title><link>https://deep-diver.github.io/neurips2024/posters/v0jvwcqlje/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/v0jvwcqlje/</guid><description>FairWire tackles structural bias in graph machine learning, proposing a novel fairness regularizer and a fair graph generation framework for unbiased link prediction and graph generation.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/v0jvwcqlje/cover.png"/></item><item><title>Group-wise oracle-efficient algorithms for online multi-group learning</title><link>https://deep-diver.github.io/neurips2024/posters/klsyhjllx5/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/klsyhjllx5/</guid><description>Oracle-efficient algorithms conquer online multi-group learning, achieving sublinear regret even with massive, overlapping groups, paving the way for fair and efficient large-scale online systems.</description></item><item><title>Honor Among Bandits: No-Regret Learning for Online Fair Division</title><link>https://deep-diver.github.io/neurips2024/spotlight-ai-theory/ocqbc0edjj/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-ai-theory/ocqbc0edjj/</guid><description>Online fair division algorithm achieves Ã(TÂ²/Â³) regret while guaranteeing envy-freeness or proportionality in expectation, a result proven tight.</description></item><item><title>Interpolating Item and User Fairness in Multi-Sided Recommendations</title><link>https://deep-diver.github.io/neurips2024/posters/taog1hdvgy/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/taog1hdvgy/</guid><description>Problem (FAIR) framework and FORM algorithm achieve flexible multi-stakeholder fairness in online recommendation systems, balancing platform revenue with user and item fairness.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/taog1hdvgy/cover.png"/></item><item><title>Localized Adaptive Risk Control</title><link>https://deep-diver.github.io/neurips2024/posters/fogjgrozu1/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/fogjgrozu1/</guid><description>Localized Adaptive Risk Control (L-ARC) improves fairness and reliability of online prediction by providing localized statistical risk guarantees, surpassing existing methods in high-stakes applicatio&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/fogjgrozu1/cover.png"/></item><item><title>Mind the Gap: A Causal Perspective on Bias Amplification in Prediction &amp; Decision-Making</title><link>https://deep-diver.github.io/neurips2024/posters/axyl24yhjn/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/axyl24yhjn/</guid><description>AI bias amplification in decision-making is uncovered, showing how fair prediction scores can become discriminatory after thresholding, urging stronger regulatory oversight.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/axyl24yhjn/cover.png"/></item><item><title>Mind the Graph When Balancing Data for Fairness or Robustness</title><link>https://deep-diver.github.io/neurips2024/posters/lqr22jm5l3/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/lqr22jm5l3/</guid><description>Data balancing in machine learning can hurt fairness and robustness; this paper reveals when and why, offering solutions for safer AI.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/lqr22jm5l3/cover.png"/></item><item><title>Mitigating Spurious Correlations via Disagreement Probability</title><link>https://deep-diver.github.io/neurips2024/posters/obujbhbx8o/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/obujbhbx8o/</guid><description>DPR, a novel bias mitigation method, robustly improves model performance by leveraging disagreement probability without needing bias labels, achieving state-of-the-art results.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/obujbhbx8o/cover.png"/></item><item><title>Monoculture in Matching Markets</title><link>https://deep-diver.github.io/neurips2024/posters/p5yezhumss/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/p5yezhumss/</guid><description>Algorithmic monoculture harms applicant selection and market efficiency; this paper introduces a model to analyze its effects in two-sided matching markets.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/p5yezhumss/cover.png"/></item><item><title>Multi-Group Proportional Representation in Retrieval</title><link>https://deep-diver.github.io/neurips2024/posters/brzyhvhvsg/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/brzyhvhvsg/</guid><description>Multi-group Proportional Representation (MPR) tackles skewed search results by measuring representation across intersectional groups, improving fairness in image retrieval.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/brzyhvhvsg/cover.png"/></item><item><title>No-Regret Learning for Fair Multi-Agent Social Welfare Optimization</title><link>https://deep-diver.github.io/neurips2024/posters/15jm9v7wco/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/15jm9v7wco/</guid><description>This paper solves the open problem of achieving no-regret learning in online multi-agent Nash social welfare maximization.</description></item><item><title>On Socially Fair Low-Rank Approximation and Column Subset Selection</title><link>https://deep-diver.github.io/neurips2024/posters/eo1qev952p/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/eo1qev952p/</guid><description>This paper reveals the surprising computational hardness of achieving fairness in low-rank approximation while offering efficient approximation algorithms.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/eo1qev952p/cover.png"/></item><item><title>OxonFair: A Flexible Toolkit for Algorithmic Fairness</title><link>https://deep-diver.github.io/neurips2024/posters/ztwl4ubnxv/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/ztwl4ubnxv/</guid><description>OxonFair: a new open-source toolkit for enforcing fairness in binary classification, supporting NLP, Computer Vision, and tabular data, optimizing any fairness metric, and minimizing performance degra&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/ztwl4ubnxv/cover.png"/></item><item><title>Parameterized Approximation Schemes for Fair-Range Clustering</title><link>https://deep-diver.github.io/neurips2024/posters/zzgbudspzj/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/zzgbudspzj/</guid><description>First parameterized approximation schemes for fair-range k-median &amp;amp; k-means in Euclidean spaces are presented, offering faster (1+Îµ)-approximation algorithms.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/zzgbudspzj/cover.png"/></item><item><title>Plant-and-Steal: Truthful Fair Allocations via Predictions</title><link>https://deep-diver.github.io/neurips2024/posters/afb97f8qsf/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/afb97f8qsf/</guid><description>Learning-augmented mechanisms for fair allocation achieve constant-factor approximation with accurate predictions and near-optimal approximation even with inaccurate ones.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/afb97f8qsf/cover.png"/></item><item><title>Policy Aggregation</title><link>https://deep-diver.github.io/neurips2024/posters/ybiuvixjth/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/ybiuvixjth/</guid><description>This paper introduces efficient algorithms that leverage social choice theory to aggregate multiple individual preferences, resulting in a desirable collective AI policy.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/ybiuvixjth/cover.png"/></item><item><title>Promoting Fairness Among Dynamic Agents in Online-Matching Markets under Known Stationary Arrival Distributions</title><link>https://deep-diver.github.io/neurips2024/posters/0c3blhwjsy/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/0c3blhwjsy/</guid><description>This paper presents novel algorithms for online matching markets that prioritize fairness among dynamic agents, achieving asymptotic optimality in various scenarios and offering extensions to group-le&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/0c3blhwjsy/cover.png"/></item><item><title>Proportional Fairness in Clustering: A Social Choice Perspective</title><link>https://deep-diver.github.io/neurips2024/posters/kslx5pfpos/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/kslx5pfpos/</guid><description>This paper reveals the surprising connection between individual and proportional fairness in clustering, showing that any approximation to one directly implies an approximation to the other, enabling &amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/kslx5pfpos/cover.png"/></item><item><title>Proportional Fairness in Non-Centroid Clustering</title><link>https://deep-diver.github.io/neurips2024/posters/actjv6wect/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/actjv6wect/</guid><description>This paper introduces proportionally fair non-centroid clustering, achieving fairness guarantees via novel algorithms and auditing methods, demonstrating significant improvements over traditional meth&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/actjv6wect/cover.png"/></item><item><title>RashomonGB: Analyzing the Rashomon Effect and Mitigating Predictive Multiplicity in Gradient Boosting</title><link>https://deep-diver.github.io/neurips2024/posters/zpw6nmhvku/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/zpw6nmhvku/</guid><description>RashomonGB tackles predictive multiplicity in gradient boosting by introducing a novel inference technique to efficiently identify and mitigate conflicting model predictions, improving model selection&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/zpw6nmhvku/cover.png"/></item><item><title>Regression under demographic parity constraints via unlabeled post-processing</title><link>https://deep-diver.github.io/neurips2024/posters/utbjd5lgnc/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/utbjd5lgnc/</guid><description>Ensuring fair regression predictions without using sensitive attributes? This paper presents a novel post-processing algorithm, achieving demographic parity with strong theoretical guarantees and comp&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/utbjd5lgnc/cover.png"/></item><item><title>SureMap: Simultaneous mean estimation for single-task and multi-task disaggregated evaluation</title><link>https://deep-diver.github.io/neurips2024/posters/atnt3fuvbg/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/atnt3fuvbg/</guid><description>SureMap, a new method, significantly boosts accuracy in single and multi-task disaggregated evaluations of AI models using limited data by transforming the problem into Gaussian mean estimation and cl&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/atnt3fuvbg/cover.png"/></item><item><title>The Fairness-Quality Tradeoff in Clustering</title><link>https://deep-diver.github.io/neurips2024/posters/bui2xeca7w/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/bui2xeca7w/</guid><description>Novel algorithms trace the optimal balance between clustering quality and fairness, revealing all non-dominated solutions for various objectives.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/bui2xeca7w/cover.png"/></item><item><title>The Group Robustness is in the Details: Revisiting Finetuning under Spurious Correlations</title><link>https://deep-diver.github.io/neurips2024/posters/ehziwahj06/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/ehziwahj06/</guid><description>Finetuning&amp;rsquo;s impact on worst-group accuracy is surprisingly nuanced, with common class-balancing methods sometimes hurting performance; a novel mixture method consistently outperforms others.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/ehziwahj06/cover.png"/></item><item><title>Theoretical and Empirical Insights into the Origins of Degree Bias in Graph Neural Networks</title><link>https://deep-diver.github.io/neurips2024/posters/1maaewthcz/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/1maaewthcz/</guid><description>Researchers unveil the origins of degree bias in Graph Neural Networks (GNNs), proving high-degree nodes&amp;rsquo; lower misclassification probability and proposing methods to alleviate this bias for fairer GN&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/1maaewthcz/cover.png"/></item><item><title>Towards Harmless Rawlsian Fairness Regardless of Demographic Prior</title><link>https://deep-diver.github.io/neurips2024/posters/7u5mwus3rw/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/7u5mwus3rw/</guid><description>VFair achieves harmless Rawlsian fairness in regression tasks without relying on sensitive demographic data by minimizing the variance of training losses.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/7u5mwus3rw/cover.png"/></item><item><title>User-item fairness tradeoffs in recommendations</title><link>https://deep-diver.github.io/neurips2024/posters/zozjms3jts/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/zozjms3jts/</guid><description>Recommendation systems must balance user satisfaction with fair item exposure. This research provides a theoretical model and empirical validation showing that user preference diversity can significan&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/zozjms3jts/cover.png"/></item><item><title>Wasserstein Distributionally Robust Optimization through the Lens of Structural Causal Models and Individual Fairness</title><link>https://deep-diver.github.io/neurips2024/posters/piozfx9whu/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/piozfx9whu/</guid><description>This paper introduces Causally Fair DRO, a novel framework for robust optimization that addresses individual fairness concerns by incorporating causal structures and sensitive attributes, providing th&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/piozfx9whu/cover.png"/></item><item><title>When is Multicalibration Post-Processing Necessary?</title><link>https://deep-diver.github.io/neurips2024/posters/oonojmx3wh/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/oonojmx3wh/</guid><description>Multicalibration post-processing isn&amp;rsquo;t always necessary; models often implicitly achieve it, especially calibrated ones. For uncalibrated models, though, it significantly improves fairness.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/oonojmx3wh/cover.png"/></item></channel></rss>