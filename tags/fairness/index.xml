<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Fairness on NeurIPS 2024</title><link>https://deep-diver.github.io/neurips2024/tags/fairness/</link><description>Recent content in Fairness on NeurIPS 2024</description><generator>Hugo -- gohugo.io</generator><language>en</language><copyright>© 2024 AI Paper Reviewer</copyright><lastBuildDate>Thu, 26 Sep 2024 00:00:00 +0000</lastBuildDate><atom:link href="https://deep-diver.github.io/neurips2024/tags/fairness/index.xml" rel="self" type="application/rss+xml"/><item><title>Fair Allocation in Dynamic Mechanism Design</title><link>https://deep-diver.github.io/neurips2024/posters/beungps83o/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/beungps83o/</guid><description>This paper presents optimal fair mechanisms for dynamic auction design, maximizing seller revenue while guaranteeing minimum allocations to multiple buyer groups.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/beungps83o/cover.png"/></item><item><title>Fair Secretaries with Unfair Predictions</title><link>https://deep-diver.github.io/neurips2024/posters/dxxj4s06yl/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/dxxj4s06yl/</guid><description>Fair algorithms can leverage biased predictions to improve performance while guaranteeing fairness for all candidates.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/dxxj4s06yl/cover.png"/></item><item><title>Fair Wasserstein Coresets</title><link>https://deep-diver.github.io/neurips2024/posters/ylcej2xiw5/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/ylcej2xiw5/</guid><description>Fair Wasserstein Coresets (FWC) efficiently generates fair, representative subsets of large datasets for downstream machine learning tasks, improving fairness and utility.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/ylcej2xiw5/cover.png"/></item><item><title>Honor Among Bandits: No-Regret Learning for Online Fair Division</title><link>https://deep-diver.github.io/neurips2024/spotlight-ai-theory/ocqbc0edjj/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-ai-theory/ocqbc0edjj/</guid><description>Online fair division algorithm achieves Õ(T²/³) regret while guaranteeing envy-freeness or proportionality in expectation, a result proven tight.</description></item><item><title>Interpolating Item and User Fairness in Multi-Sided Recommendations</title><link>https://deep-diver.github.io/neurips2024/posters/taog1hdvgy/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/taog1hdvgy/</guid><description>Problem (FAIR) framework and FORM algorithm achieve flexible multi-stakeholder fairness in online recommendation systems, balancing platform revenue with user and item fairness.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/taog1hdvgy/cover.png"/></item><item><title>OxonFair: A Flexible Toolkit for Algorithmic Fairness</title><link>https://deep-diver.github.io/neurips2024/posters/ztwl4ubnxv/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/ztwl4ubnxv/</guid><description>OxonFair: a new open-source toolkit for enforcing fairness in binary classification, supporting NLP, Computer Vision, and tabular data, optimizing any fairness metric, and minimizing performance degra&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/ztwl4ubnxv/cover.png"/></item><item><title>Policy Aggregation</title><link>https://deep-diver.github.io/neurips2024/posters/ybiuvixjth/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/ybiuvixjth/</guid><description>This paper introduces efficient algorithms that leverage social choice theory to aggregate multiple individual preferences, resulting in a desirable collective AI policy.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/ybiuvixjth/cover.png"/></item><item><title>RashomonGB: Analyzing the Rashomon Effect and Mitigating Predictive Multiplicity in Gradient Boosting</title><link>https://deep-diver.github.io/neurips2024/posters/zpw6nmhvku/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/zpw6nmhvku/</guid><description>RashomonGB tackles predictive multiplicity in gradient boosting by introducing a novel inference technique to efficiently identify and mitigate conflicting model predictions, improving model selection&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/zpw6nmhvku/cover.png"/></item><item><title>The Group Robustness is in the Details: Revisiting Finetuning under Spurious Correlations</title><link>https://deep-diver.github.io/neurips2024/posters/ehziwahj06/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/ehziwahj06/</guid><description>Finetuning&amp;rsquo;s impact on worst-group accuracy is surprisingly nuanced, with common class-balancing methods sometimes hurting performance; a novel mixture method consistently outperforms others.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/ehziwahj06/cover.png"/></item></channel></rss>