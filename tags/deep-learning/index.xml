<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Deep Learning on NeurIPS 2024</title><link>https://deep-diver.github.io/neurips2024/tags/deep-learning/</link><description>Recent content in Deep Learning on NeurIPS 2024</description><generator>Hugo -- gohugo.io</generator><language>en</language><copyright>© 2024 AI Paper Reviewer</copyright><lastBuildDate>Thu, 26 Sep 2024 00:00:00 +0000</lastBuildDate><atom:link href="https://deep-diver.github.io/neurips2024/tags/deep-learning/index.xml" rel="self" type="application/rss+xml"/><item><title>A Geometric View of Data Complexity: Efficient Local Intrinsic Dimension Estimation with Diffusion Models</title><link>https://deep-diver.github.io/neurips2024/spotlight/nd8q4a8awl/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight/nd8q4a8awl/</guid><description>Diffusion models power FLIPD, a fast, single-model LID estimator.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight/nd8q4a8awl/cover.png"/></item><item><title>A Near-optimal Algorithm for Learning Margin Halfspaces with Massart Noise</title><link>https://deep-diver.github.io/neurips2024/spotlight/4aewzkwb5z/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight/4aewzkwb5z/</guid><description>Near-optimal algorithm achieves computationally efficient learning of margin halfspaces with Massart noise, nearly matching theoretical lower bounds.</description></item><item><title>Accelerating Diffusion Models with Parallel Sampling: Inference at Sub-Linear Time Complexity</title><link>https://deep-diver.github.io/neurips2024/spotlight/f9ndzhqtol/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight/f9ndzhqtol/</guid><description>Researchers achieve sub-linear time complexity for diffusion model inference using parallel sampling with poly-logarithmic time complexity.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight/f9ndzhqtol/cover.png"/></item><item><title>ACES: Generating a Diversity of Challenging Programming Puzzles with Autotelic Generative Models</title><link>https://deep-diver.github.io/neurips2024/spotlight/l1mmk39z7p/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight/l1mmk39z7p/</guid><description>Autotelic Code Search (ACES) generates diverse, challenging Python programming puzzles by iteratively using LLM-generated semantic descriptors and measuring puzzle difficulty via LLM solver success ra&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight/l1mmk39z7p/cover.png"/></item><item><title>Advancing Spiking Neural Networks for Sequential Modeling with Central Pattern Generators</title><link>https://deep-diver.github.io/neurips2024/spotlight/kqmyidwbog/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight/kqmyidwbog/</guid><description>Bio-inspired CPG-PE enhances spiking neural networks&amp;rsquo; sequential modeling by efficiently encoding position information, outperforming conventional methods across various tasks.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight/kqmyidwbog/cover.png"/></item><item><title>Analysing Multi-Task Regression via Random Matrix Theory with Application to Time Series Forecasting</title><link>https://deep-diver.github.io/neurips2024/spotlight/ffw6rpz48z/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight/ffw6rpz48z/</guid><description>This paper presents a novel theoretical framework for multi-task regression using random matrix theory, offering precise performance estimations and a closed-form solution for optimal hyperparameter t&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight/ffw6rpz48z/cover.png"/></item><item><title>Any2Graph: Deep End-To-End Supervised Graph Prediction With An Optimal Transport Loss</title><link>https://deep-diver.github.io/neurips2024/spotlight/tpgagxpvcv/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight/tpgagxpvcv/</guid><description>Any2Graph: a novel deep learning framework using an Optimal Transport loss for accurate and efficient supervised graph prediction.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight/tpgagxpvcv/cover.png"/></item><item><title>BMRS: Bayesian Model Reduction for Structured Pruning</title><link>https://deep-diver.github.io/neurips2024/spotlight/ktpg37dzh5/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight/ktpg37dzh5/</guid><description>BMRS: Bayesian Model Reduction for Structured Pruning offers a principled, threshold-free approach to neural network compression, achieving high accuracy and competitive efficiency.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight/ktpg37dzh5/cover.png"/></item><item><title>Cluster-wise Graph Transformer with Dual-granularity Kernelized Attention</title><link>https://deep-diver.github.io/neurips2024/spotlight/3j2nasmkkp/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight/3j2nasmkkp/</guid><description>Cluster-wise Graph Transformer (Cluster-GT) improves graph learning by using a novel Node-to-Cluster Attention mechanism that leverages multiple kernel learning to capture node and cluster-level infor&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight/3j2nasmkkp/cover.png"/></item><item><title>Conditioning non-linear and infinite-dimensional diffusion processes</title><link>https://deep-diver.github.io/neurips2024/spotlight/fv4an2oufm/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight/fv4an2oufm/</guid><description>Conditioning infinite-dimensional nonlinear diffusion processes is made possible, enabling analysis of complex data like organism shapes in evolutionary biology.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight/fv4an2oufm/cover.png"/></item><item><title>Convolutional Differentiable Logic Gate Networks</title><link>https://deep-diver.github.io/neurips2024/oral/4bkefyuht4/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/oral/4bkefyuht4/</guid><description>Convolutional Differentiable Logic Gate Networks achieve state-of-the-art accuracy on CIFAR-10 with 29x fewer gates than existing models, demonstrating highly efficient deep learning inference.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/oral/4bkefyuht4/cover.png"/></item><item><title>Curvature Clues: Decoding Deep Learning Privacy with Input Loss Curvature</title><link>https://deep-diver.github.io/neurips2024/spotlight/zevdmq6mu5/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight/zevdmq6mu5/</guid><description>Deep learning privacy is enhanced by a new membership inference attack using input loss curvature, exceeding existing methods, especially on large datasets.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight/zevdmq6mu5/cover.png"/></item><item><title>CycleNet: Enhancing Time Series Forecasting through Modeling Periodic Patterns</title><link>https://deep-diver.github.io/neurips2024/spotlight/clbiqugj4w/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight/clbiqugj4w/</guid><description>CycleNet enhances long-term time series forecasting by explicitly modeling inherent periodic patterns using a novel Residual Cycle Forecasting technique, achieving state-of-the-art accuracy and effici&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight/clbiqugj4w/cover.png"/></item><item><title>Deep Learning for Computing Convergence Rates of Markov Chains</title><link>https://deep-diver.github.io/neurips2024/spotlight/fqmsgk8c0b/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight/fqmsgk8c0b/</guid><description>Deep learning tackles Markov chain convergence rate analysis! Deep Contractive Drift Calculator (DCDC) provides sample-based bounds in Wasserstein distance, surpassing traditional methods&amp;rsquo; limitations&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight/fqmsgk8c0b/cover.png"/></item><item><title>Deep Submodular Peripteral Networks</title><link>https://deep-diver.github.io/neurips2024/spotlight/tupcrqnvvm/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight/tupcrqnvvm/</guid><description>Deep Submodular Peripteral Networks (DSPNs) learn submodular functions efficiently using graded pairwise comparisons, surpassing traditional methods and demonstrating superiority in experimental desig&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight/tupcrqnvvm/cover.png"/></item><item><title>Diffusion Models With Learned Adaptive Noise</title><link>https://deep-diver.github.io/neurips2024/spotlight/loma99a4p8/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight/loma99a4p8/</guid><description>MuLAN, a novel learned diffusion process, achieves state-of-the-art density estimation by adaptively adding multivariate Gaussian noise at varying rates across an image, significantly reducing trainin&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight/loma99a4p8/cover.png"/></item><item><title>Disentangling the Roles of Distinct Cell Classes with Cell-Type Dynamical Systems</title><link>https://deep-diver.github.io/neurips2024/spotlight/9sp4oejtjb/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight/9sp4oejtjb/</guid><description>New Cell-Type Dynamical Systems (CTDS) model disentangles neural population dynamics by incorporating distinct cell types, improving prediction accuracy and biological interpretability.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight/9sp4oejtjb/cover.png"/></item><item><title>Distributed-Order Fractional Graph Operating Network</title><link>https://deep-diver.github.io/neurips2024/spotlight/keqfjkqiqm/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight/keqfjkqiqm/</guid><description>DRAGON: A novel GNN framework using distributed-order fractional calculus surpasses traditional methods by capturing complex graph dynamics with enhanced flexibility and performance.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight/keqfjkqiqm/cover.png"/></item><item><title>Doob's Lagrangian: A Sample-Efficient Variational Approach to Transition Path Sampling</title><link>https://deep-diver.github.io/neurips2024/spotlight/shjwt0n7kx/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight/shjwt0n7kx/</guid><description>Researchers developed a sample-efficient variational approach for transition path sampling using Doob&amp;rsquo;s h-transform, significantly reducing computational costs while accurately capturing transition pa&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight/shjwt0n7kx/cover.png"/></item><item><title>Fearless Stochasticity in Expectation Propagation</title><link>https://deep-diver.github.io/neurips2024/spotlight/3kdwoqs2x2/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight/3kdwoqs2x2/</guid><description>This paper introduces EP-η and EP-μ, novel EP variants remarkably robust to Monte Carlo noise, achieving improved speed and accuracy.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight/3kdwoqs2x2/cover.png"/></item><item><title>Flexible task abstractions emerge in linear networks with fast and bounded units</title><link>https://deep-diver.github.io/neurips2024/spotlight/abtpjl7vn6/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight/abtpjl7vn6/</guid><description>Linear gated neural networks with fast, bounded units self-organize into modular weight structures and unique gating representations, enabling flexible task switching and compositional generalization.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight/abtpjl7vn6/cover.png"/></item><item><title>Generalized Protein Pocket Generation with Prior-Informed Flow Matching</title><link>https://deep-diver.github.io/neurips2024/spotlight/wyvtj77kev/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight/wyvtj77kev/</guid><description>PocketFlow: a novel generative model designs high-affinity protein pockets using prior-informed flow matching, outperforming existing methods.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight/wyvtj77kev/cover.png"/></item><item><title>Gradients of Functions of Large Matrices</title><link>https://deep-diver.github.io/neurips2024/spotlight/rl4fxrgctw/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight/rl4fxrgctw/</guid><description>This research presents novel adjoint methods for efficiently differentiating Lanczos and Arnoldi iterations, unlocking accurate gradients for large-matrix functions in machine learning.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight/rl4fxrgctw/cover.png"/></item><item><title>Hardness of Learning Neural Networks under the Manifold Hypothesis</title><link>https://deep-diver.github.io/neurips2024/spotlight/dkkgkzmni7/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight/dkkgkzmni7/</guid><description>Neural network learnability under the manifold hypothesis is hard except for efficiently sampleable manifolds.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight/dkkgkzmni7/cover.png"/></item><item><title>Kermut: Composite kernel regression for protein variant effects</title><link>https://deep-diver.github.io/neurips2024/spotlight/jm9atrvuii/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight/jm9atrvuii/</guid><description>Kermut: A novel Gaussian process regression model achieves state-of-the-art accuracy in predicting protein variant effects and provides reliable uncertainty estimates, crucial for protein engineering &amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight/jm9atrvuii/cover.png"/></item><item><title>Latent Diffusion for Neural Spiking Data</title><link>https://deep-diver.github.io/neurips2024/spotlight/zx6ceo1wtv/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight/zx6ceo1wtv/</guid><description>LDNS: a new generative model for neural spiking data, enabling high-fidelity sampling and low-dimensional latent inference, paving the way for simulating realistic brain activity.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight/zx6ceo1wtv/cover.png"/></item><item><title>Molecule Design by Latent Prompt Transformer</title><link>https://deep-diver.github.io/neurips2024/spotlight/dg3ti3c2b1/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight/dg3ti3c2b1/</guid><description>Latent Prompt Transformer (LPT) revolutionizes molecule design by unifying generation and optimization, achieving high efficiency in discovering novel molecules with desired properties.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight/dg3ti3c2b1/cover.png"/></item><item><title>Neglected Hessian component explains mysteries in sharpness regularization</title><link>https://deep-diver.github.io/neurips2024/spotlight/m6pvpdin0y/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight/m6pvpdin0y/</guid><description>Deep learning&amp;rsquo;s mysteries surrounding sharpness regularization are solved by uncovering the crucial role of the neglected Hessian component, the Nonlinear Modeling Error (NME).</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight/m6pvpdin0y/cover.png"/></item><item><title>Neural Krylov Iteration for Accelerating Linear System Solving</title><link>https://deep-diver.github.io/neurips2024/spotlight/cqfe9eymdp/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight/cqfe9eymdp/</guid><description>Neural Krylov Iteration (NeurKItt) accelerates linear system solving by using a neural operator to predict invariant subspaces, drastically reducing iteration counts and computation time.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight/cqfe9eymdp/cover.png"/></item><item><title>Noisy Label Learning with Instance-Dependent Outliers: Identifiability via Crowd Wisdom</title><link>https://deep-diver.github.io/neurips2024/spotlight/htljptf7qm/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight/htljptf7qm/</guid><description>Crowd wisdom solves noisy label learning!</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight/htljptf7qm/cover.png"/></item><item><title>Non-asymptotic Approximation Error Bounds of Parameterized Quantum Circuits</title><link>https://deep-diver.github.io/neurips2024/spotlight/xckii8nct3/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight/xckii8nct3/</guid><description>New non-asymptotic approximation error bounds show that parameterized quantum circuits can efficiently approximate complex functions, potentially surpassing classical neural networks.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight/xckii8nct3/cover.png"/></item><item><title>Non-Asymptotic Uncertainty Quantification in High-Dimensional Learning</title><link>https://deep-diver.github.io/neurips2024/spotlight/rqcmmsszvi/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight/rqcmmsszvi/</guid><description>Data-driven approach corrects confidence intervals in high-dimensional learning, improving accuracy for various models and bridging theory and practice.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight/rqcmmsszvi/cover.png"/></item><item><title>Nonlocal Attention Operator: Materializing Hidden Knowledge Towards Interpretable Physics Discovery</title><link>https://deep-diver.github.io/neurips2024/spotlight/uskzeaj9zj/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight/uskzeaj9zj/</guid><description>New neural operator, Nonlocal Attention Operator (NAO), simultaneously learns forward and inverse physical models, improving interpretability and generalizability for physics discovery.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight/uskzeaj9zj/cover.png"/></item><item><title>Optimal deep learning of holomorphic operators between Banach spaces</title><link>https://deep-diver.github.io/neurips2024/spotlight/vblzen37i0/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight/vblzen37i0/</guid><description>Deep learning optimally learns holomorphic operators between Banach spaces, achieving near-optimal generalization bounds with problem-agnostic DNN architectures.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight/vblzen37i0/cover.png"/></item><item><title>Overcoming Common Flaws in the Evaluation of Selective Classification Systems</title><link>https://deep-diver.github.io/neurips2024/spotlight/2tktdpgqnm/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight/2tktdpgqnm/</guid><description>Researchers developed a new evaluation metric, AUGRC, for selective classification systems that overcomes the limitations of existing metrics by providing a more holistic and interpretable assessment &amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight/2tktdpgqnm/cover.png"/></item><item><title>PACE: marrying the generalization of PArameter-efficient fine-tuning with Consistency rEgularization</title><link>https://deep-diver.github.io/neurips2024/spotlight/coulbphot1/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight/coulbphot1/</guid><description>PACE marries parameter-efficient fine-tuning with consistency regularization to significantly boost model generalization.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight/coulbphot1/cover.png"/></item><item><title>Parsimony or Capability? Decomposition Delivers Both in Long-term Time Series Forecasting</title><link>https://deep-diver.github.io/neurips2024/spotlight/wiehzsv15i/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight/wiehzsv15i/</guid><description>SSCNN, a novel decomposition-based model, achieves superior long-term time series forecasting accuracy using 99% fewer parameters than existing methods, proving that bigger isn&amp;rsquo;t always better.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight/wiehzsv15i/cover.png"/></item><item><title>Particle Semi-Implicit Variational Inference</title><link>https://deep-diver.github.io/neurips2024/spotlight/p3gmgkhmkm/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight/p3gmgkhmkm/</guid><description>Particle Variational Inference (PVI) revolutionizes semi-implicit variational inference by directly optimizing the ELBO using a novel particle approximation, improving efficiency and expressiveness ov&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight/p3gmgkhmkm/cover.png"/></item><item><title>Peri-midFormer: Periodic Pyramid Transformer for Time Series Analysis</title><link>https://deep-diver.github.io/neurips2024/spotlight/5iuxmvjvev/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight/5iuxmvjvev/</guid><description>Peri-midFormer uses a novel periodic pyramid transformer to effectively model complex periodic variations in time series, achieving state-of-the-art results in forecasting, imputation, classification,&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight/5iuxmvjvev/cover.png"/></item><item><title>Poisson Variational Autoencoder</title><link>https://deep-diver.github.io/neurips2024/spotlight/ektpecqglb/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight/ektpecqglb/</guid><description>Poisson Variational Autoencoder (P-VAE) improves deep learning by encoding inputs as discrete spike counts, enhancing biological realism and interpretability while avoiding posterior collapse and achi&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight/ektpecqglb/cover.png"/></item><item><title>Probabilistic Weather Forecasting with Hierarchical Graph Neural Networks</title><link>https://deep-diver.github.io/neurips2024/spotlight/wtizpqx121/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight/wtizpqx121/</guid><description>Graph-EFM: a novel probabilistic weather forecasting model using hierarchical graph neural networks that efficiently generates large ensembles for improved accuracy and uncertainty quantification.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight/wtizpqx121/cover.png"/></item><item><title>Probablistic Emulation of a Global Climate Model with Spherical DYffusion</title><link>https://deep-diver.github.io/neurips2024/spotlight/ib2ihijrth/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight/ib2ihijrth/</guid><description>Spherical DYffusion: a novel AI model generates accurate, physically consistent global climate ensemble simulations, surpassing existing methods in efficiency and skill.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight/ib2ihijrth/cover.png"/></item><item><title>Reconstruct and Match: Out-of-Distribution Robustness via Topological Homogeneity</title><link>https://deep-diver.github.io/neurips2024/spotlight/fkbmlfdbxm/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight/fkbmlfdbxm/</guid><description>Reconstruct &amp;amp; Match (REMA) enhances deep learning&amp;rsquo;s out-of-distribution robustness by leveraging object&amp;rsquo;s topological homogeneity, outperforming state-of-the-art methods.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight/fkbmlfdbxm/cover.png"/></item><item><title>Recursive PAC-Bayes: A Frequentist Approach to Sequential Prior Updates with No Information Loss</title><link>https://deep-diver.github.io/neurips2024/spotlight/pqt6vg2x5u/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight/pqt6vg2x5u/</guid><description>Recursive PAC-Bayes: A frequentist method enabling sequential prior updates without information loss, resulting in significantly tighter generalization bounds.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight/pqt6vg2x5u/cover.png"/></item><item><title>Reparameterization invariance in approximate Bayesian inference</title><link>https://deep-diver.github.io/neurips2024/spotlight/204yordhny/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight/204yordhny/</guid><description>Bayesian neural networks often underfit due to their lack of reparameterization invariance; this paper introduces a Riemannian diffusion process to improve posterior sampling and enhance predictive pe&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight/204yordhny/cover.png"/></item><item><title>Reproducibility of predictive networks for mouse visual cortex</title><link>https://deep-diver.github.io/neurips2024/spotlight/vxxj3xz1x8/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight/vxxj3xz1x8/</guid><description>Deep learning models for neural activity lack reproducibility; this paper introduces adaptive regularization and iterative feature pruning to improve embedding consistency and predictive performance.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight/vxxj3xz1x8/cover.png"/></item><item><title>Reverse Transition Kernel: A Flexible Framework to Accelerate Diffusion Inference</title><link>https://deep-diver.github.io/neurips2024/spotlight/c2xclze1ks/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight/c2xclze1ks/</guid><description>Reverse Transition Kernel (RTK) framework accelerates diffusion inference by enabling balanced subproblem decomposition, achieving superior convergence rates with RTK-MALA and RTK-ULD algorithms.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight/c2xclze1ks/cover.png"/></item><item><title>Scale Equivariant Graph Metanetworks</title><link>https://deep-diver.github.io/neurips2024/oral/8fxqn1tzm1/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/oral/8fxqn1tzm1/</guid><description>ScaleGMNs, a new framework, enhances neural network processing by incorporating scaling symmetries, boosting performance across various tasks and datasets.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/oral/8fxqn1tzm1/cover.png"/></item><item><title>Scaling Continuous Latent Variable Models as Probabilistic Integral Circuits</title><link>https://deep-diver.github.io/neurips2024/spotlight/ke40kfot2e/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight/ke40kfot2e/</guid><description>Researchers scaled continuous latent variable models by building DAG-shaped probabilistic integral circuits (PICs) and training them efficiently using tensorized architectures and neural functional sh&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight/ke40kfot2e/cover.png"/></item><item><title>Second-order forward-mode optimization of recurrent neural networks for neuroscience</title><link>https://deep-diver.github.io/neurips2024/spotlight/pox8jnqoo5/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight/pox8jnqoo5/</guid><description>SOFO: a novel second-order optimizer enables efficient and memory-friendly RNN training for neuroscience tasks, surpassing Adam&amp;rsquo;s performance, especially on long time horizons.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight/pox8jnqoo5/cover.png"/></item><item><title>Stochastic Taylor Derivative Estimator: Efficient amortization for arbitrary differential operators</title><link>https://deep-diver.github.io/neurips2024/oral/j2wi2rcg2u/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/oral/j2wi2rcg2u/</guid><description>Stochastic Taylor Derivative Estimator (STDE) drastically accelerates the optimization of neural networks involving high-dimensional, high-order differential operators by efficiently amortizing comput&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/oral/j2wi2rcg2u/cover.png"/></item><item><title>Tolerant Algorithms for Learning with Arbitrary Covariate Shift</title><link>https://deep-diver.github.io/neurips2024/spotlight/lnnfwc2ah1/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight/lnnfwc2ah1/</guid><description>This paper introduces efficient algorithms for learning under arbitrary covariate shift, addressing limitations of prior approaches by enabling classifiers to abstain from predictions in high-shift sc&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight/lnnfwc2ah1/cover.png"/></item><item><title>Towards training digitally-tied analog blocks via hybrid gradient computation</title><link>https://deep-diver.github.io/neurips2024/spotlight/bmtn8kkrbq/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight/bmtn8kkrbq/</guid><description>Hybrid neural networks, combining digital feedforward and analog energy-based blocks, are trained end-to-end via a novel BP-EP gradient chaining algorithm, achieving state-of-the-art results on ImageN&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight/bmtn8kkrbq/cover.png"/></item><item><title>Towards Understanding Evolving Patterns in Sequential Data</title><link>https://deep-diver.github.io/neurips2024/spotlight/i2gvmvrgnk/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight/i2gvmvrgnk/</guid><description>EVORATE quantifies evolving patterns in sequential data, enabling better model selection and temporal analysis for improved machine learning.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight/i2gvmvrgnk/cover.png"/></item><item><title>Towards Universal Mesh Movement Networks</title><link>https://deep-diver.github.io/neurips2024/spotlight/lcalcnf2qe/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight/lcalcnf2qe/</guid><description>Universal Mesh Movement Network (UM2N) revolutionizes mesh movement for PDE solvers, enabling zero-shot adaptation to diverse problems and significantly accelerating simulations with improved accuracy&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight/lcalcnf2qe/cover.png"/></item><item><title>Unitary Convolutions for Learning on Graphs and Groups</title><link>https://deep-diver.github.io/neurips2024/spotlight/lg1veqjvuh/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight/lg1veqjvuh/</guid><description>Stable deep learning on graphs achieved using novel unitary group convolutions, preventing over-smoothing and enhancing model robustness.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight/lg1veqjvuh/cover.png"/></item></channel></rss>