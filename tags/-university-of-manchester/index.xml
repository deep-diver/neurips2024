<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>üè¢ University of Manchester on NeurIPS 2024</title><link>https://deep-diver.github.io/neurips2024/tags/-university-of-manchester/</link><description>Recent content in üè¢ University of Manchester on NeurIPS 2024</description><generator>Hugo -- gohugo.io</generator><language>en</language><copyright>¬© 2025 AI Paper Reviewer</copyright><lastBuildDate>Thu, 26 Sep 2024 00:00:00 +0000</lastBuildDate><atom:link href="https://deep-diver.github.io/neurips2024/tags/-university-of-manchester/index.xml" rel="self" type="application/rss+xml"/><item><title>Aligning Individual and Collective Objectives in Multi-Agent Cooperation</title><link>https://deep-diver.github.io/neurips2024/posters/2yshebrrol/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/2yshebrrol/</guid><description>AI agents learn to cooperate effectively even when individual and group goals clash using the new Altruistic Gradient Adjustment (AgA) algorithm.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/2yshebrrol/cover.png"/></item><item><title>Credal Learning Theory</title><link>https://deep-diver.github.io/neurips2024/posters/ah5kwussln/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/ah5kwussln/</guid><description>Credal Learning Theory uses convex sets of probabilities to model data distribution variability, providing theoretical risk bounds for machine learning models in dynamic environments.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/ah5kwussln/cover.png"/></item><item><title>Diffusion Twigs with Loop Guidance for Conditional Graph Generation</title><link>https://deep-diver.github.io/neurips2024/posters/fvocjaaylx/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/fvocjaaylx/</guid><description>Twigs: a novel score-based diffusion framework using multiple co-evolving flows and loop guidance for superior conditional graph generation.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/fvocjaaylx/cover.png"/></item><item><title>Graph Neural Flows for Unveiling Systemic Interactions Among Irregularly Sampled Time Series</title><link>https://deep-diver.github.io/neurips2024/posters/tfb5ssabvb/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/tfb5ssabvb/</guid><description>GNeuralFlow unveils systemic interactions in irregularly sampled time series by learning a directed acyclic graph representing conditional dependencies, achieving superior performance in classificatio&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/tfb5ssabvb/cover.png"/></item><item><title>MetaAligner: Towards Generalizable Multi-Objective Alignment of Language Models</title><link>https://deep-diver.github.io/neurips2024/posters/divb5c0qff/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/divb5c0qff/</guid><description>MetaAligner: a novel, policy-agnostic, and generalizable method for efficiently aligning LLMs to multiple objectives, even unseen ones, achieving significant and balanced improvements while saving up &amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/divb5c0qff/cover.png"/></item></channel></rss>