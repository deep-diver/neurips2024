<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Cross-Modal Retrieval on NeurIPS 2024</title><link>https://deep-diver.github.io/neurips2024/tags/cross-modal-retrieval/</link><description>Recent content in Cross-Modal Retrieval on NeurIPS 2024</description><generator>Hugo -- gohugo.io</generator><language>en</language><copyright>Â© 2025 AI Paper Reviewer</copyright><lastBuildDate>Thu, 26 Sep 2024 00:00:00 +0000</lastBuildDate><atom:link href="https://deep-diver.github.io/neurips2024/tags/cross-modal-retrieval/index.xml" rel="self" type="application/rss+xml"/><item><title>An End-To-End Graph Attention Network Hashing for Cross-Modal Retrieval</title><link>https://deep-diver.github.io/neurips2024/posters/q4qucn2ioc/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/q4qucn2ioc/</guid><description>EGATH: End-to-End Graph Attention Network Hashing revolutionizes cross-modal retrieval by combining CLIP, transformers, and graph attention networks for superior semantic understanding and hash code g&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/q4qucn2ioc/cover.png"/></item><item><title>Diffusion-Inspired Truncated Sampler for Text-Video Retrieval</title><link>https://deep-diver.github.io/neurips2024/posters/srqua0atrz/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/srqua0atrz/</guid><description>Diffusion-Inspired Truncated Sampler (DITS) revolutionizes text-video retrieval by progressively aligning embeddings and enhancing CLIP embedding space structure, achieving state-of-the-art results.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/srqua0atrz/cover.png"/></item><item><title>Empowering Visible-Infrared Person Re-Identification with Large Foundation Models</title><link>https://deep-diver.github.io/neurips2024/posters/qqlmonei5k/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/qqlmonei5k/</guid><description>Large foundation models empower visible-infrared person re-identification by enriching infrared image representations with automatically generated textual descriptions, significantly improving cross-m&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/qqlmonei5k/cover.png"/></item><item><title>Exploiting Descriptive Completeness Prior for Cross Modal Hashing with Incomplete Labels</title><link>https://deep-diver.github.io/neurips2024/posters/ferj6wqshv/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/ferj6wqshv/</guid><description>PCRIL, a novel prompt contrastive recovery approach, significantly boosts cross-modal hashing accuracy, especially when dealing with incomplete labels by progressively identifying promising positive c&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/ferj6wqshv/cover.png"/></item><item><title>How Molecules Impact Cells: Unlocking Contrastive PhenoMolecular Retrieval</title><link>https://deep-diver.github.io/neurips2024/posters/lqblsgeogm/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/lqblsgeogm/</guid><description>MolPhenix, a novel multi-modal model, drastically improves zero-shot molecular retrieval by leveraging a pre-trained phenomics model and a novel similarity-aware loss, achieving an 8.1x improvement ov&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/lqblsgeogm/cover.png"/></item><item><title>Identifiable Shared Component Analysis of Unpaired Multimodal Mixtures</title><link>https://deep-diver.github.io/neurips2024/posters/ivcx2cjwct/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/ivcx2cjwct/</guid><description>Unaligned multimodal mixtures&amp;rsquo; shared components are identifiable under mild conditions using a distribution-matching approach, relaxing assumptions of existing methods.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/ivcx2cjwct/cover.png"/></item><item><title>NeuroBOLT: Resting-state EEG-to-fMRI Synthesis with Multi-dimensional Feature Mapping</title><link>https://deep-diver.github.io/neurips2024/posters/y6qhvtfg77/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/y6qhvtfg77/</guid><description>NeuroBOLT: Resting-state EEG-to-fMRI synthesis using multi-dimensional feature mapping.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/y6qhvtfg77/cover.png"/></item><item><title>Semantic Feature Learning for Universal Unsupervised Cross-Domain Retrieval</title><link>https://deep-diver.github.io/neurips2024/posters/zzvqzrxsao/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/zzvqzrxsao/</guid><description>Universal Unsupervised Cross-Domain Retrieval (U2CDR) framework learns semantic features to enable accurate retrieval even when category spaces differ across domains.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/zzvqzrxsao/cover.png"/></item></channel></rss>