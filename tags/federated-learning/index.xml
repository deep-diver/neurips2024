<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Federated Learning on NeurIPS 2024</title><link>https://deep-diver.github.io/neurips2024/tags/federated-learning/</link><description>Recent content in Federated Learning on NeurIPS 2024</description><generator>Hugo -- gohugo.io</generator><language>en</language><copyright>Â© 2024 AI Paper Reviewer</copyright><lastBuildDate>Thu, 26 Sep 2024 00:00:00 +0000</lastBuildDate><atom:link href="https://deep-diver.github.io/neurips2024/tags/federated-learning/index.xml" rel="self" type="application/rss+xml"/><item><title>A-FedPD: Aligning Dual-Drift is All Federated Primal-Dual Learning Needs</title><link>https://deep-diver.github.io/neurips2024/spotlight/h1imvi2iem/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight/h1imvi2iem/</guid><description>A-FedPD tackles federated learning&amp;rsquo;s &amp;lsquo;dual drift&amp;rsquo; problem by aligning global and local dual variables, resulting in faster convergence and enhanced stability for primal-dual methods.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight/h1imvi2iem/cover.png"/></item><item><title>DapperFL: Domain Adaptive Federated Learning with Model Fusion Pruning for Edge Devices</title><link>https://deep-diver.github.io/neurips2024/oral/pezt0xttae/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/oral/pezt0xttae/</guid><description>DapperFL enhances federated learning by introducing a model fusion pruning module and domain adaptive regularization to improve performance and reduce model size for heterogeneous edge devices.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/oral/pezt0xttae/cover.png"/></item><item><title>FuseFL: One-Shot Federated Learning through the Lens of Causality with Progressive Model Fusion</title><link>https://deep-diver.github.io/neurips2024/spotlight/e7fzooiekl/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight/e7fzooiekl/</guid><description>FuseFL achieves superior one-shot federated learning performance by leveraging a causal view of data heterogeneity and progressively fusing model blocks, significantly outperforming existing methods w&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight/e7fzooiekl/cover.png"/></item><item><title>Improving the Worst-Case Bidirectional Communication Complexity for Nonconvex Distributed Optimization under Function Similarity</title><link>https://deep-diver.github.io/neurips2024/spotlight/gkj5nbiou4/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight/gkj5nbiou4/</guid><description>MARINA-P and M3 algorithms drastically cut downlink and overall communication costs in nonconvex distributed optimization, scaling efficiently with the number of worker nodes.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight/gkj5nbiou4/cover.png"/></item><item><title>Stabilized Proximal-Point Methods for Federated Optimization</title><link>https://deep-diver.github.io/neurips2024/spotlight/wuksyfszdt/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight/wuksyfszdt/</guid><description>S-DANE &amp;amp; ACC-S-DANE achieve best-known communication complexity for federated learning, improving local computation efficiency via stabilized proximal-point methods.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight/wuksyfszdt/cover.png"/></item></channel></rss>