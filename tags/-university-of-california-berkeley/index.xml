<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>üè¢ University of California, Berkeley on NeurIPS 2024</title><link>https://deep-diver.github.io/neurips2024/tags/-university-of-california-berkeley/</link><description>Recent content in üè¢ University of California, Berkeley on NeurIPS 2024</description><generator>Hugo -- gohugo.io</generator><language>en</language><copyright>¬© 2024 AI Paper Reviewer</copyright><lastBuildDate>Thu, 26 Sep 2024 00:00:00 +0000</lastBuildDate><atom:link href="https://deep-diver.github.io/neurips2024/tags/-university-of-california-berkeley/index.xml" rel="self" type="application/rss+xml"/><item><title>An Analysis of Tokenization: Transformers under Markov Data</title><link>https://deep-diver.github.io/neurips2024/spotlight-large-language-models/wm9jzq7rce/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-large-language-models/wm9jzq7rce/</guid><description>Tokenization&amp;rsquo;s crucial role in transformer language models is revealed: Transformers struggle on simple Markov data &lt;em>without&lt;/em> tokenization, but achieve near-optimal performance &lt;em>with&lt;/em> appropriate tok&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-large-language-models/wm9jzq7rce/cover.png"/></item><item><title>BPQP: A Differentiable Convex Optimization Framework for Efficient End-to-End Learning</title><link>https://deep-diver.github.io/neurips2024/spotlight-others/vkky3uv7vi/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-others/vkky3uv7vi/</guid><description>BPQP: A new differentiable convex optimization framework accelerates end-to-end learning by an order of magnitude, achieving significant efficiency gains over existing methods.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-others/vkky3uv7vi/cover.png"/></item><item><title>Humanoid Locomotion as Next Token Prediction</title><link>https://deep-diver.github.io/neurips2024/spotlight-others/grmczqgtla/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-others/grmczqgtla/</guid><description>Humanoid robots now walk in San Francisco zero-shot, thanks to a novel &amp;rsquo;next token prediction&amp;rsquo; approach trained on diverse sensorimotor data, enabling real-world generalization and data efficiency.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-others/grmczqgtla/cover.png"/></item><item><title>Learning to Mitigate Externalities: the Coase Theorem with Hindsight Rationality</title><link>https://deep-diver.github.io/neurips2024/spotlight-ai-theory/omyzrkacme/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-ai-theory/omyzrkacme/</guid><description>Economists learn to resolve externalities efficiently even when players lack perfect information, maximizing social welfare by leveraging bargaining and online learning.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-ai-theory/omyzrkacme/cover.png"/></item><item><title>Metric Transforms and Low Rank Representations of Kernels for Fast Attention</title><link>https://deep-diver.github.io/neurips2024/spotlight-ai-theory/k9pxsryuwg/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-ai-theory/k9pxsryuwg/</guid><description>Researchers unveil novel linear-algebraic tools revealing the limits of fast attention, classifying positive definite kernels for Manhattan distance, and fully characterizing metric transforms for Man&amp;hellip;</description></item><item><title>Overcoming the Sim-to-Real Gap: Leveraging Simulation to Learn to Explore for Real-World RL</title><link>https://deep-diver.github.io/neurips2024/posters/jjql8hxjas/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/jjql8hxjas/</guid><description>Leveraging simulation for real-world RL is often hampered by the sim-to-real gap. This paper shows that instead of directly transferring policies, transferring &lt;em>exploratory&lt;/em> policies from simulation d&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/jjql8hxjas/cover.png"/></item><item><title>Poisson Variational Autoencoder</title><link>https://deep-diver.github.io/neurips2024/spotlight-others/ektpecqglb/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-others/ektpecqglb/</guid><description>Poisson Variational Autoencoder (P-VAE) improves deep learning by encoding inputs as discrete spike counts, enhancing biological realism and interpretability while avoiding posterior collapse and achi&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-others/ektpecqglb/cover.png"/></item><item><title>Pretrained Transformer Efficiently Learns Low-Dimensional Target Functions In-Context</title><link>https://deep-diver.github.io/neurips2024/posters/uhcg5y6fdb/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/posters/uhcg5y6fdb/</guid><description>Pretrained transformers surprisingly learn low-dimensional nonlinear functions efficiently from few in-context examples, outperforming baseline algorithms.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/posters/uhcg5y6fdb/cover.png"/></item><item><title>Stylus: Automatic Adapter Selection for Diffusion Models</title><link>https://deep-diver.github.io/neurips2024/oral-image-generation/3odq2tgspp/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/oral-image-generation/3odq2tgspp/</guid><description>Stylus: an automatic adapter selection system for diffusion models, boosts image quality and diversity by intelligently composing task-specific adapters based on prompt keywords.</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/oral-image-generation/3odq2tgspp/cover.png"/></item><item><title>Toxicity Detection for Free</title><link>https://deep-diver.github.io/neurips2024/spotlight-large-language-models/5a27ee8lxx/</link><pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><guid>https://deep-diver.github.io/neurips2024/spotlight-large-language-models/5a27ee8lxx/</guid><description>Moderation Using LLM Introspection (MULI) leverages the first response token&amp;rsquo;s logits from LLMs to create a highly accurate toxicity detector, surpassing state-of-the-art methods with minimal overhead&amp;hellip;</description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://deep-diver.github.io/neurips2024/spotlight-large-language-models/5a27ee8lxx/cover.png"/></item></channel></rss>