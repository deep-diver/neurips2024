[{"figure_path": "tQukGCDaNT/figures/figures_1_1.jpg", "caption": "Figure 1: 1024\u00d71024 samples produced by our 4-step generator distilled from SDXL. Please zoom in for details.", "description": "This figure showcases the high-quality images generated by a 4-step generator that was created using the DMD2 method. The generator was trained by distilling a larger, more complex model (SDXL). The images are 1024x1024 pixels in resolution.  The caption encourages viewers to zoom in to appreciate the fine details of the generated images, demonstrating the high fidelity achieved by the DMD2 technique.", "section": "Improved Distribution Matching Distillation"}, {"figure_path": "tQukGCDaNT/figures/figures_3_1.jpg", "caption": "Figure 2: 1024\u00d71024 samples produced by our 4-step generator distilled from SDXL. Please zoom in for details.", "description": "This figure showcases the high-quality 1024x1024 images generated by a 4-step generator, trained using the DMD2 method. The images demonstrate the model's ability to produce diverse and detailed outputs, showcasing its ability to capture various artistic styles and subject matter.  The caption encourages viewers to zoom in to appreciate the fine details within each image.", "section": "Experiments"}, {"figure_path": "tQukGCDaNT/figures/figures_5_1.jpg", "caption": "Figure 3: Our method distills a costly diffusion model (gray, right) into a one- or multi-step generator (red, left). Our training alternates between 2 steps: 1. optimizing the generator using the gradient of an implicit distribution matching objective (red arrow) and a GAN loss (green), and 2. training a score function (blue) to model the distribution of \u201cfake\u201d samples produced by the generator, as well as a GAN discriminator (green) to discriminate between fake samples and real images. The student generator can be a one-step or a multi-step model, as shown here, with an intermediate step input.", "description": "This figure illustrates the DMD2 method, which improves upon the original DMD method.  The core idea is to train a more efficient generator (the student) to mimic the output distribution of a more computationally expensive diffusion model (the teacher). This is done in two steps: (1) training the generator using a combination of distribution matching and GAN losses; and (2) training a score function and GAN discriminator to improve the estimation of the generated sample distribution and enhance the overall training stability.", "section": "Improved Distribution Matching Distillation"}, {"figure_path": "tQukGCDaNT/figures/figures_6_1.jpg", "caption": "Figure 4: Most multi-step distillation methods simulate intermediate steps using forward diffusion during training (left). This creates a mismatch with the inputs the model sees during inference. Our proposed solution (right) remedies the problem by simulating the inference-time backward process during training.", "description": "This figure illustrates the problem of training-inference mismatch in multi-step diffusion models and proposes a solution. The left side shows the traditional approach where the training uses forward diffusion, resulting in a domain gap between training and inference. The right side shows the proposed solution using backward simulation during training which aligns the training and inference inputs, thereby reducing the domain gap and improving performance.", "section": "4.5 Multi-step generator simulation to avoid training/inference mismatch"}, {"figure_path": "tQukGCDaNT/figures/figures_8_1.jpg", "caption": "Figure 5: User study comparing our distilled model with its teacher and competing distillation baselines [23,27,31]. All distilled models use 4 sampling steps, the teacher uses 50. Our model achieves the best performance for both image quality and prompt alignment.", "description": "This figure presents the results of a user study comparing the image quality and prompt alignment of the proposed DMD2 model against several competing distillation methods and the original teacher model.  The study reveals that DMD2 achieves superior performance compared to all the alternatives across both metrics, even though it uses fewer sampling steps than the original teacher model.", "section": "5 Experiments"}, {"figure_path": "tQukGCDaNT/figures/figures_9_1.jpg", "caption": "Figure 6: Visual comparison between our model, the SDXL teacher, and selected competing methods [23, 27, 31]. All distilled models use 4 sampling steps while the teacher model uses 50 sampling steps with classifier-free guidance. All images are generated using identical noise and text prompts. Our model produces images with superior realism and text alignment. (Zoom in for details.) More comparisons are available in Appendix Figure 10.", "description": "This figure compares images generated by the proposed method (DMD2), three other state-of-the-art diffusion models, and the teacher model (SDXL).  All models used the same text prompts and noise inputs.  The comparison highlights the superior realism and text alignment of DMD2, even though it uses only 4 sampling steps compared to the teacher model's 50.", "section": "5 Experiments"}, {"figure_path": "tQukGCDaNT/figures/figures_17_1.jpg", "caption": "Figure 7: SDXL Qualitative Ablations. All images are generated using identical noise and text prompts. Removing the distribution matching objective significantly degrades aesthetic quality and text alignment. Omitting the GAN loss results in oversaturated and overly smoothed images. The baseline without backward simulation produces images of lower quality.", "description": "This figure shows an ablation study on the SDXL model, comparing the impact of removing different components of the proposed DMD2 method (distribution matching, GAN loss, and backward simulation).  Each set of images was generated using the same noise and text prompts.  The results visually demonstrate that each of these components is crucial for maintaining high-quality image generation with good aesthetic qualities and proper alignment to the given text prompts.", "section": "5.3 Ablation Studies"}, {"figure_path": "tQukGCDaNT/figures/figures_17_2.jpg", "caption": "Figure 1: 1024\u00d71024 samples produced by our 4-step generator distilled from SDXL. Please zoom in for details.", "description": "This figure showcases the high-quality images generated by a 4-step generator trained using the proposed DMD2 method. The generator is distilled from the state-of-the-art SDXL diffusion model, demonstrating significant efficiency gains while maintaining exceptional visual quality.  The caption encourages viewers to zoom in to appreciate the detail in the generated images.", "section": "Improved Distribution Matching Distillation"}, {"figure_path": "tQukGCDaNT/figures/figures_17_3.jpg", "caption": "Figure 6: Visual comparison between our model, the SDXL teacher, and selected competing methods [23, 27, 31]. All distilled models use 4 sampling steps while the teacher model uses 50 sampling steps with classifier-free guidance. All images are generated using identical noise and text prompts. Our model produces images with superior realism and text alignment. (Zoom in for details.) More comparisons are available in Appendix Figure 10.", "description": "This figure compares image generation results from the authors' model (DMD2), competing methods, and the teacher model (SDXL).  All models were given the same prompts and noise, but the authors' model used only 4 sampling steps while the teacher model used 50 steps, demonstrating significant efficiency gains. The image quality and text alignment of the DMD2 model are highlighted as superior.", "section": "5.2 Text-to-Image Synthesis"}, {"figure_path": "tQukGCDaNT/figures/figures_17_4.jpg", "caption": "Figure 6: Visual comparison between our model, the SDXL teacher, and selected competing methods [23, 27, 31]. All distilled models use 4 sampling steps while the teacher model uses 50 sampling steps with classifier-free guidance. All images are generated using identical noise and text prompts. Our model produces images with superior realism and text alignment. (Zoom in for details.) More comparisons are available in Appendix Figure 10.", "description": "This figure compares image generation results from four different methods: the authors' proposed DMD2 model, three other state-of-the-art competing methods, and the original SDXL teacher model. All models were prompted with the same text and noise input.  The images demonstrate that the proposed DMD2 model produces images of superior quality and better alignment with the text prompt.", "section": "5 Experiments"}, {"figure_path": "tQukGCDaNT/figures/figures_17_5.jpg", "caption": "Figure 7: SDXL Qualitative Ablations. All images are generated using identical noise and text prompts. Removing the distribution matching objective significantly degrades aesthetic quality and text alignment. Omitting the GAN loss results in oversaturated and overly smoothed images. The baseline without backward simulation produces images of lower quality.", "description": "This figure shows the ablation study results for SDXL model. Four images are generated with the same prompt using four different training methods. The first one is the full DMD2 model, and the other three omit one component of the DMD2: distribution matching, GAN, and backward simulation. By comparing the images, one can observe that each component contributes to the image quality, demonstrating the effectiveness of the full DMD2 method.", "section": "5.3 Ablation Studies"}, {"figure_path": "tQukGCDaNT/figures/figures_18_1.jpg", "caption": "Figure 8: Visualization of pixel brightness variations throughout training. The baseline approach, which naively removes the regression loss from the original DMD [22], suffers from significant training instability, leading to fluctuating general image statistics like the overall pixel brightness. In contrast, our two time-scale update rule, which optimizes the fake diffusion model five times per generator update, significantly stabilizes training and enhances sample quality.", "description": "The figure shows the pixel brightness variation during the training process.  The baseline method (without the regression loss) shows significant instability, while the proposed method (with a two timescales update rule) displays stable and enhanced training.", "section": "4.2 Stabilizing pure distribution matching with a Two Time-scale Update Rule"}, {"figure_path": "tQukGCDaNT/figures/figures_18_2.jpg", "caption": "Figure 9: Visualization of FID score progression during training. Naively removing the regression loss leads to training instability (red line). A two time-scale update rule with five fake diffusion critic updates per generator update stabilizes training and is more effective than using a larger number of fake diffusion updates or an asynchronous learning rate where the fake diffusion model uses a learning rate 5 times larger than the generator. The model trained with our two time-scale update rule (green) also converges significantly faster than the original DMD method with a regression loss (dark blue), even though TTUR performs less number of the generator weight updates.", "description": "This figure shows the FID score (a metric measuring the quality of generated images) over training time for different training strategies.  The baseline (red) shows instability when the regression loss is removed, while the proposed two timescales update rule (green) is more stable and converges faster.  It also shows the benefit of the two timescales approach over other strategies, even if those other strategies might use more updates.  The y-axis represents FID score. The x-axis represents training time (in hours).", "section": "5.3 Ablation Studies"}, {"figure_path": "tQukGCDaNT/figures/figures_19_1.jpg", "caption": "Figure 10: Additional visual comparison between our model, the SDXL teacher, and selected competing methods [23,27,31]. All distilled models use 4 sampling steps while the teacher model uses 50 sampling steps with classifier-free guidance. All images are generated using identical noise and text prompts. Our model produces images with superior realism and text alignment. Please zoom in for details.", "description": "This figure compares images generated by the proposed DMD2 model, several other methods, and the teacher SDXL model for various prompts.  The key takeaway is that DMD2 produces images of comparable or higher quality to the teacher model with significantly fewer sampling steps, showcasing its effectiveness in distillation.", "section": "Experiments"}, {"figure_path": "tQukGCDaNT/figures/figures_20_1.jpg", "caption": "Figure 11: Additional 1024\u00d71024 samples produced by our 1-step generator distilled from SDXL. Please zoom in for details.", "description": "This figure shows a grid of 12 diverse 1024x1024 images generated by a single-step generator trained using the DMD2 method. The images demonstrate the model's ability to generate high-resolution images with a wide range of styles, subject matters, and artistic techniques.  The caption encourages viewers to zoom in to better appreciate the detail in each image. The variety showcased suggests successful distillation of a complex teacher model into a significantly faster, single-step generator.", "section": "5 Experiments"}, {"figure_path": "tQukGCDaNT/figures/figures_21_1.jpg", "caption": "Figure 1: 1024\u00d71024 samples produced by our 4-step generator distilled from SDXL. Please zoom in for details.", "description": "This figure displays a collection of 1024x1024 images generated by a 4-step generator, which is a model trained using a novel distillation technique.  The images are diverse and showcase a wide range of subjects, demonstrating the quality and capabilities of the generator.", "section": "Improved Distribution Matching Distillation"}, {"figure_path": "tQukGCDaNT/figures/figures_23_1.jpg", "caption": "Figure 3: Our method distills a costly diffusion model (gray, right) into a one- or multi-step generator (red, left). Our training alternates between 2 steps: 1. optimizing the generator using the gradient of an implicit distribution matching objective (red arrow) and a GAN loss (green), and 2. training a score function (blue) to model the distribution of \u201cfake\u201d samples produced by the generator, as well as a GAN discriminator (green) to discriminate between fake samples and real images. The student generator can be a one-step or a multi-step model, as shown here, with an intermediate step input.", "description": "This figure illustrates the DMD2 method, showing how a costly diffusion model is distilled into a more efficient one- or multi-step generator.  The training process involves two alternating steps: optimizing the generator with a distribution matching objective and a GAN loss, and training a score function and GAN discriminator to improve the quality and stability of the generated images. The generator can be either a one-step or a multi-step model.", "section": "Improved Distribution Matching Distillation"}]