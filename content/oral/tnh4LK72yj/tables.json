[{"figure_path": "tnh4LK72yj/tables/tables_7_1.jpg", "caption": "Table 1: Performance comparison on three datasets. Best results are bold and the second best are underlined.", "description": "This table presents a comparison of the performance of various models on three different datasets (NYC, SIP, and Chicago).  The models are evaluated using two metrics: Mean Absolute Error (MAE) and Mean Absolute Percentage Error (MAPE). Lower values for both metrics indicate better performance.  Each dataset has multiple tasks, and the results for each task are shown separately for each model. The table highlights the best and second-best performing models for each task and dataset.", "section": "5.2 Performance Comparison"}, {"figure_path": "tnh4LK72yj/tables/tables_7_2.jpg", "caption": "Table 2: Performance against data sparsity.", "description": "This table presents the results of experiments conducted to evaluate the robustness of different models (GWNET, STEP, PromptST, and CMuST) under data sparsity conditions.  The performance is measured using MAE and MAPE metrics. Data sparsity is simulated in three ways: reducing the number of spatial nodes (25% and 50%), and increasing the time interval between observations (2 times and 4 times). The results show how well each model maintains performance when data is limited or less frequently sampled.", "section": "5.2 Performance Comparison"}, {"figure_path": "tnh4LK72yj/tables/tables_16_1.jpg", "caption": "Table 1: Performance comparison on three datasets. Best results are bold and the second best are underlined.", "description": "This table presents a comparison of the performance of various spatiotemporal forecasting models (DCRNN, AGCRNN, GWNET, STGCN, GMAN, ASTGCN, STTN, MTGNN, STEP, PromptST, and CMuST) on three different datasets: NYC, SIP, and Chicago.  Each dataset includes multiple tasks, and the table shows the Mean Absolute Error (MAE) and Mean Absolute Percentage Error (MAPE) for each model on each task.  The results highlight the superior performance of the proposed CMuST model compared to existing state-of-the-art methods.", "section": "5.2 Performance Comparison"}, {"figure_path": "tnh4LK72yj/tables/tables_16_2.jpg", "caption": "Table 1: Performance comparison on three datasets. Best results are bold and the second best are underlined.", "description": "This table presents a comparison of the proposed CMuST model's performance against several other state-of-the-art models on three different datasets (NYC, SIP, and Chicago).  The performance metrics used are Mean Absolute Error (MAE) and Mean Absolute Percentage Error (MAPE). Lower values indicate better performance. Each dataset contains multiple tasks, and the table shows the results for each task and each model, highlighting the best and second-best performing models.", "section": "5.2 Performance Comparison"}, {"figure_path": "tnh4LK72yj/tables/tables_16_3.jpg", "caption": "Table 1: Performance comparison on three datasets. Best results are bold and the second best are underlined.", "description": "This table presents a comparison of the performance of various models on three different datasets (NYC, SIP, and Chicago).  The models are evaluated based on two metrics: Mean Absolute Error (MAE) and Mean Absolute Percentage Error (MAPE).  Lower values indicate better performance.  The table allows for a direct comparison of the predictive accuracy of different spatiotemporal forecasting models across multiple datasets, highlighting the relative strengths and weaknesses of each model in different contexts.", "section": "5.2 Performance Comparison"}, {"figure_path": "tnh4LK72yj/tables/tables_17_1.jpg", "caption": "Table 1: Performance comparison on three datasets. Best results are bold and the second best are underlined.", "description": "This table presents a comparison of the performance of different spatiotemporal forecasting methods on three datasets (NYC, SIP, and Chicago).  Each dataset has multiple tasks (e.g., crowd flow prediction, taxi trip prediction, risk assessment). The table shows the Mean Absolute Error (MAE) and Mean Absolute Percentage Error (MAPE) for each model and task.  Lower values of MAE and MAPE indicate better performance.  The best and second-best results for each task are highlighted.", "section": "5.2 Performance Comparison"}]