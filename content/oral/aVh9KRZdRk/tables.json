[{"figure_path": "aVh9KRZdRk/tables/tables_3_1.jpg", "caption": "Generalization There are two notions of generalization in this setup. (i) In-distribution: Generalization to unseen input vectors (xi, yi), but on task vector (at, bt) the model has seen during pre-training. (ii) Out-of-distribution: Generalization to task vectors the model has not seen during pre-training. To clearly separate these regimes, we split the task vectors into in-distribution (i.d.) set Ti.d. := {(a, b)}i.d. and out-of-distribution (o.o.d.) set To.o.d. := {(a,b)}o.o.d.. Similarly, we split the input vectors into train and test sets: Xtrain := {(Xi, Yi)}train, Xtest := {(Xi, Yi)}test. This results in four distinct sets of sequences constructed from those sets; we name them Sidin, Stedt, Sood and Sosed. The set Strain is used for pre-training, while the other three sets are used for evaluations.", "description": "This table shows the four distinct phases of generalization observed in the model's performance.  It distinguishes between in-distribution (i.d.) and out-of-distribution (o.o.d.) generalization, based on whether the model has seen the task vector during pre-training.  Each phase is characterized by its performance on four different sequence sets: in-distribution training, in-distribution testing, out-of-distribution training, and out-of-distribution testing. The symbols (\u2611, \u2715) indicate whether the model performs well or poorly in each phase.", "section": "4 Emergence of In-Context Learning and Task Composition"}]