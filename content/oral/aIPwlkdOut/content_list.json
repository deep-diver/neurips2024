[{"type": "text", "text": "Enhancing Preference-based Linear Bandits via Human Response Time ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Shen Li1\u2217 Yuyang Zhang2 \u2217 Zhaolin Ren2 Claire Liang1 Na Li2 Julie A. Shah1 ", "page_idx": 0}, {"type": "text", "text": "1Massachusetts Institute of Technology 2Harvard University {shenli,cyl48}@mit.edu, julie_a_shah@csail.mit.edu {yuyangzhang,zhaolinren}@g.harvard.edu, nali@seas.harvard.edu ", "page_idx": 0}, {"type": "text", "text": "Abstract ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Interactive preference learning systems present humans with queries as pairs of options; humans then select their preferred choice, allowing the system to infer preferences from these binary choices. While binary choice feedback is simple and widely used, it offers limited information about preference strength. To address this, we leverage human response times, which inversely correlate with preference strength, as complementary information. We introduce a computationally efficient method based on the EZ-diffusion model, combining choices and response times to estimate the underlying human utility function. Theoretical and empirical comparisons with traditional choice-only estimators show that for queries where humans have strong preferences (i.e., \u201ceasy\u201d queries), response times provide valuable complementary information and enhance utility estimates. We integrate this estimator into preference-based linear bandits for fixed-budget best-arm identification. Simulations on three real-world datasets demonstrate that incorporating response times significantly accelerates preference learning. ", "page_idx": 0}, {"type": "text", "text": "1 Introduction ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Interactive preference learning from human binary choices is essential in systems like recommender systems [9, 21, 32, 56], assistive robots [54, 65], and fine-tuning of large language models [5, 43, 46, 47, 59]. This process is often framed as a preference-based bandit problem [7, 31], where the system repeatedly presents pairs of options, the human selects their preferred option, and the system infers preferences based on these choices. Choices feedback is widely used for its simplicity and low cognitive burden on users [37, 72, 74]. However, while binary choices capture preferences, they offer limited insight into preference strength [77]. To address this, researchers have incorporated additional human explicit feedback, such as ratings [50, 58], labels [74], and slider bars [5, 72], but these approaches tend to complicate the interface and increase users\u2019 cognitive load [36, 37]. ", "page_idx": 0}, {"type": "text", "text": "In this paper, we propose leveraging human implicit feedback, specifically response times, to provide additional insights into preference strength. Unlike explicit feedback, response time is unobtrusive and effortless to measure [17], offering valuable information that complements binary choices [2, 16]. For instance, consider an online retailer that repeatedly presents users with a binary query, whether to purchase or skip a recommended product [35]. Since most users skip products most of the time [33], the probability of skipping becomes nearly 1 for most items. This lack of variation in choices makes it difficult to assess how much a user likes or dislikes any specific product, limiting the system\u2019s ability to accurately infer their preferences. Response time can help overcome this limitation. Psychological research shows an inverse relationship between response time and preference strength [17]: users who strongly prefer to skip a product tend to do so quickly, while longer response times can indicate weaker preferences. Thus, even when choices appear similar, response time can uncover subtle differences in preference strength, helping to accelerate preference learning. ", "page_idx": 0}, {"type": "text", "text": "", "page_idx": 1}, {"type": "text", "text": "Leveraging response times for preference learning presents notable challenges. Psychological research has extensively studied the relationship between human choices and response times [17, 19] using complex models like Drift-Diffusion Models [51] and Race Models [12, 66]. While these models align with both behavioral and neurobiological evidence [70], they rely on computationally intensive methods, such as hierarchical Bayesian inference [71] and maximum likelihood estimation (MLE) [52], to estimate the underlying human utility functions from both human choices and response times, making them impractical for real-time interactive systems. Although faster estimators exist [8, 28, 30, 67, 68], they typically estimate the utility functions for a single pair of options, without aggregating data across multiple pairs. This limits their ability to leverage structures like linear utility functions, which are critical both in preference learning with large option spaces [21, 24, 41, 54, 56] and in cognitive models for human multi-attribute decision-making [26, 64, 76]. ", "page_idx": 1}, {"type": "text", "text": "To address these challenges, we propose a computationally efficient method for estimating linear human utility functions by incorporating both choices and response times, based on the differencebased EZ diffusion model [8, 67]. Our method leverages response times to transform binary choice signals into continuous signals, framing utility estimation as a linear regression that aggregates data across multiple pairs. We compare our estimator to traditional logistic regression methods that rely solely on choices [3, 31]. Our theoretical and empirical analyses show that for binary queries with strong preferences (i.e., \u201ceasy\u201d queries), choices alone provide limited information, while response times offer valuable insights into preference strength, significantly enhancing utility estimates. Thus, incorporating response times makes easy queries more informative. ", "page_idx": 1}, {"type": "text", "text": "Our linear-regression-based estimator integrates seamlessly into algorithms for preference-based bandits with linear human utility functions [3, 31], enabling interactive learning systems to leverage response times for faster learning. We specifically integrated our estimator into the Generalized Successive Elimination algorithm [3] for fixed-budget best-arm identification [29, 34]. Simulations using three real-world datasets [16, 39, 57] consistently show that incorporating response times significantly reduces identification errors, compared to traditional methods that rely solely on choices. To the best of our knowledge, this is the first work to integrate response times into bandit (and RL). ", "page_idx": 1}, {"type": "text", "text": "Section 2 introduces the preference-based linear bandit problem and the difference-based EZ diffusion model. Section 3 presents our utility estimator, incorporating both choices and response times, and offers a theoretical comparison to the choice-only estimator. Section 4 integrates both estimators into the Generalized Successive Elimination algorithm. Section 5 presents empirical results for estimation and bandit learning. Section 6 discusses the limitations of our approach. Appendix B reviews response time models, parameter estimation techniques, and their connection to preference-based RL. ", "page_idx": 1}, {"type": "text", "text": "Nomenclature: We use $[n]$ to denote the set $\\{1,\\ldots,n\\}$ . For a scalar random variable $x$ , $\\mathbb{E}\\left[x\\right]$ and $\\mathbb{V}\\left[x\\right]$ denote its expectation and variance, respectively. The function $\\operatorname{sgn}(x)$ denotes the sign of $x$ . ", "page_idx": 1}, {"type": "text", "text": "2 Problem setting and preliminaries ", "text_level": 1, "page_idx": 1}, {"type": "text", "text": "Preference-based bandits with a linear utility function. The learner is given a finite set of options (or \u201carms\u201d), each represented by a feature vector in $\\mathcal{Z}\\subset\\mathbb{R}^{d}$ , and a finite set of binary queries, where each query is the difference between two arms, denoted by $\\mathcal{X}\\subset\\mathbb{R}^{d}$ . For instance, if the learner can query any pair of arms, the query space is $\\mathcal{X}=\\{z-z^{\\prime}\\colon z,z^{\\prime}\\in\\mathcal{Z}\\}$ . In the online retailer example from section 1, the query space is $\\mathcal{X}=\\{z-z_{\\mathrm{skip}}\\colon z\\in\\mathcal{Z}\\}$ , where $z$ represents purchasing a product and $z_{\\mathrm{skip}}$ represents skipping (often set as 0). For each arm $z\\in{\\mathcal{Z}}$ , the human utility is assumed to be linear in the feature space, defined as $u_{z}:=z^{\\top}\\theta^{*}$ , where $\\theta^{*}\\in\\mathbb{R}^{d}$ represents the human\u2019s preference parameters. For any query $x\\in\\mathscr{X}$ , the utility difference is then defined as $u_{x}:=x^{\\top}\\theta^{*}$ . ", "page_idx": 1}, {"type": "text", "text": "Given a query $x:=z_{1}-z_{2}\\in\\mathcal{X}$ , we model human choices and response times using the differencebased EZ-Diffusion Model (dEZDM) [8, 67], integrated with our linear utility structure. (See appendix B.1 for a comparison with other models.) This model interprets human decision-making as a stochastic process in which evidence accumulates over time to compare two options. As shown in fig. 1a, after receiving a query $x$ , the human first spends a fixed amount of non-decision time, denoted by $t_{\\mathrm{nondec}}\\,>\\,0$ , to perceive and encode the query. Then, evidence $E_{x}$ accumulates over time following a Brownian motion with drift $x^{\\top}\\theta^{*}$ and two symmetric absorbing barriers, $a>0$ and $-a$ . Specifically, at time $t_{\\mathrm{nondec}}+\\tau$ where $\\tau\\geq0$ , the evidence is $E_{x,\\tau}=\\boldsymbol{x}^{\\top}\\boldsymbol{\\theta}^{*}\\cdot\\boldsymbol{\\tau}+\\boldsymbol{B}(\\tau)$ , where $B(\\bar{\\tau})\\sim\\mathcal{N}(\\bar{0},\\tau)$ is standard Brownian motion. This process continues until the evidence reaches either the upper barrier $a$ or lower barrier $-a$ , at which point a decision is made. The random stopping time, $t_{x}:=\\operatorname*{min}\\left\\{\\tau>0\\colon E_{x,\\tau}\\in\\{a,-a\\}\\right\\}$ , represents the decision time. If $E_{x,t_{x}}=a$ , the human chooses $z_{1}$ ; if $E_{x,t_{x}}=-a$ , they choose $z_{2}$ . The choice is represented by the random variable $c_{x}$ , where $c_{x}=1$ if $z_{1}$ is chosen, and $-1$ if $z_{2}$ is chosen. The total response time, $t_{\\mathrm{RT},x}$ , is the sum of the non-decision time and the decision time: $t_{\\mathrm{RT},x}=t_{\\mathrm{nondec}}+t_{x}$ . The choice probability, expected choice, choice variance, and expected decision time are given as follows [48, eq. (A.16) and (A.17)]: ", "page_idx": 1}, {"type": "text", "text": "", "page_idx": 2}, {"type": "equation", "text": "$$\n\\forall x\\in{\\mathcal{X}}\\colon\\mathbb{P}\\left[c_{x}=1\\right]={\\frac{1}{1+\\exp(-2a x^{\\top}\\theta^{*})}},\\ \\ \\mathbb{E}\\left[c_{x}\\right]=\\operatorname{tanh}(a x^{\\top}\\theta^{*})\n$$", "text_format": "latex", "page_idx": 2}, {"type": "equation", "text": "$$\n\\mathbb{V}\\left[c_{x}\\right]=1-\\operatorname{tanh}^{2}(a x^{\\top}\\theta^{*}),\\ \\ \\mathbb{E}\\left[t_{x}\\right]=\\left\\{{\\frac{a}{x^{\\top}\\theta^{*}}}\\operatorname{tanh}(a x^{\\top}\\theta^{*})\\quad{\\mathrm{if~}}x^{\\top}\\theta^{*}\\neq0\\right.\\quad.\n$$", "text_format": "latex", "page_idx": 2}, {"type": "text", "text": "This choice probability matches that of the Bradley and Terry [10] model. If the learner relies solely on choices, then our bandit problem reduces to the transductive linear logistic bandit problem [31]. ", "page_idx": 2}, {"type": "text", "text": "Figures 1b and 1c illustrate the roles of the parameters $x^{\\top}\\theta^{*}$ and $a$ . First, the absolute drift (or the absolute utility difference), $|x^{\\top}\\theta^{*}|$ , represents the query\u2019s easiness [40]. A higher $|x^{\\top}\\theta^{*}|$ corresponds to an easier query, resulting in shorter decision times and more consistent choices. In contrast, when $|x^{\\top}\\theta^{*}|$ is low (close to 0), the query becomes harder, leading to longer decision times and less consistent choices. Second, the barrier $a$ represents the human\u2019s conservativeness in decisionmaking [40]. A higher $a$ requires more evidence to reach a decision, leading to longer decision times and more consistent choices, while a lower $a$ results in quicker, but less consistent, choices. ", "page_idx": 2}, {"type": "image", "img_path": "aIPwlkdOut/tmp/ebaeebb90fcd2ad86c61903fc034d3da4e0a6098783e60a4ee1cadfeefe9f9fa.jpg", "img_caption": ["Figure 1: (a) depicts the human decision-making process for a binary query $x\\in\\mathscr{X}$ , where the human selects between two arms. The human first spends a fixed non-decision time $t_{\\mathrm{nondec}}$ encoding the query. Then, the human\u2019s evidence accumulates according to a Brownian motion with drift $\\bar{x}^{\\top}\\theta^{*}$ . When the evidence reaches the upper barrier $a$ or lower barrier $-a$ , the human makes a choice, denoted by $c_{x}=1$ or $c_{x}=-1$ , respectively. The random stopping time of the accumulation process is the decision time $t_{x}$ , and the total response time is $t_{\\mathrm{RT},x}=t_{\\mathrm{nondec}}+t_{x}$ . (b) and (c) plot the expected choice $\\mathbb{E}[c_{x}]$ and the expected decision time $\\mathbb{E}[t_{x}]$ , with shaded regions representing one standard deviation, plotted as functions of the utility difference $x^{\\top}\\theta^{*}$ for two barrier values $a$ . "], "img_footnote": [], "page_idx": 2}, {"type": "text", "text": "We adopt the common assumption that $t_{\\mathrm{nondec}}$ is constant across all queries for a given human [16, 76] and further assume that $t_{\\mathrm{nondec}}$ is known to the learner. This assumption enables the learner to perfectly recover $t_{x}$ from the observed $t_{\\mathrm{RT},x}$ . In section 5.2, we empirically show that even when $t_{\\mathrm{nondec}}$ is unknown, its impact on the performance of our method that relies on decision times is negligible. ", "page_idx": 2}, {"type": "text", "text": "Learning objective: Best-arm identification with a fixed budget. We focus on the fixed-budget best-arm identification problem [29, 34]. The learner is provided with a total interaction time budget $B>0$ , an arm space $\\mathcal{Z}$ , a query space $\\mathcal{X}$ , and a non-decision time $t_{\\mathrm{nondec}}$ . Both the human\u2019s preference vector $\\theta^{*}$ and the decision barrier $a$ are unknown. In each episode $s\\in\\mathbb{N}$ , the learner selects a query $x_{s}\\in\\mathcal{X}$ , receives human feedback $(c_{x_{s},s},t_{x_{s},s})$ generated by the dEZDM, and consumes $t_{\\mathrm{RT},x_{s},s}$ time. When the cumulative interaction time exceeds the budget $B$ at some episode $S$ , i.e., $\\begin{array}{r}{\\sum_{s=1}^{S}t_{\\mathrm{RT},x_{s},s}>B}\\end{array}$ , the learner must stop and recommend an arm $\\widehat{z}\\in\\mathcal{Z}$ . The goal is to recommend the unique best arm $\\boldsymbol{z}^{*}:=\\arg\\operatorname*{max}_{\\boldsymbol{z}\\in\\mathcal{Z}}\\boldsymbol{z}^{\\intercal}\\boldsymbol{\\theta}^{*}$ , minimizing the erro r  probability $\\mathbb{P}\\left[\\widehat{z}\\neq z^{*}\\right]$ . ", "page_idx": 2}, {"type": "text", "text": "To solve this problem, we use the Generalized Successive Elimination (GSE) alg orithm [1, 3, 75]. This algorithm divides the total budget $B$ evenly into multiple phases. In each phase $s$ , it strategically samples queries till this phase\u2019s allocated budget is exhausted, collecting both human choices and response times. It then computes an estimate $\\widehat{\\theta}_{s}^{\"}$ of the true preference vector $\\theta^{*}$ and eliminates arms with low estimated utilities based on $\\widehat{\\theta}_{s}$ . The   key to improving estimation is effectively leveraging decision times to gain additional insi g hts into preference strength, complementing the information provided by choices. In section 3, we introduce this estimator and compare it theoretically to the traditional choice-only estimator. section 4 details the integration of both estimators into GSE. ", "page_idx": 2}, {"type": "text", "text": "", "page_idx": 3}, {"type": "text", "text": "3 Utility estimation ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "This section addresses the problem of estimating human preference $\\theta^{*}$ from a fixed dataset, denoted by $\\left\\{x,c_{x,s_{x,i}},t_{x,s_{x,i}}\\right\\}_{x\\in\\mathcal{X}_{\\mathrm{sample}},i\\in[n_{x}]}$ . Here, $\\chi_{\\mathrm{sample}}$ denotes the set of queries in the dataset, $n_{x}$ denotes the number of samples for each query $x\\in\\mathcal{X}_{\\mathrm{sample}}$ , and $s_{x,i}$ denotes the episode when $x$ is sampled for the $i$ -th time. Samples from the same query $x$ are i.i.d., while samples from different queries are independent. Section 3.1 introduces a new estimator, the \u201cchoice-decision-time estimator,\u201d which uses both choices and decision times, in contrast to the commonly used \u201cchoice-only estimator\u201d that only uses choices [3, 31]. Sections 3.2 and 3.3 theoretically compares these estimators, analyzing both asymptotic and non-asymptotic performance and highlighting the advantages of incorporating decision times. Section 5.1 presents empirical results that validate our theoretical insights. ", "page_idx": 3}, {"type": "text", "text": "3.1 Choice-decision-time estimator and choice-only estimator ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "The choice-decision-time estimator is based on the following relationship between human utilities, choices, and decision times, derived from eq. (1): ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\forall x\\in\\mathcal{X}\\colon x^{\\top}\\frac{\\theta^{*}}{a}=\\frac{\\mathbb{E}\\left[c_{x}\\right]}{\\mathbb{E}\\left[t_{x}\\right]}.\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "Intuitively, when a human provides consistent choices (i.e., large $|\\mathbb{E}[c_{x}]|)$ and makes decisions quickly (i.e., small $\\mathbb{E}[t_{x}])$ , it suggests that the query is easy and the preference is strong (i.e., large $|x^{\\top}\\theta^{*}|)$ . This relationship reframes the estimation of $\\theta^{*}$ as a linear regression problem. Accordingly, the choice-decision-time estimator calculates the empirical means of both choices and decision times, aggregates the ratios across all sampled queries, and applies ordinary least squares (OLS) to estimate $\\theta^{*}/a$ . Since the ranking of arm utilities based on $\\theta^{*}/a$ is identical to that based on $\\theta^{*}$ , estimating $\\theta^{*}/a$ is sufficient for identifying the best arm. This estimate of $\\theta^{*}/a$ , denoted by $\\widehat{\\theta}_{\\mathrm{CH,DT}}$ , is given by: ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\widehat{\\theta}_{\\mathrm{CH,DT}}:=\\left(\\sum_{x\\in\\mathcal{X}_{\\mathrm{sample}}}n_{x}\\:x x^{\\top}\\right)^{-1}\\sum_{x\\in\\mathcal{X}_{\\mathrm{sample}}}n_{x}\\:x\\:\\frac{\\sum_{i=1}^{n_{x}}c_{x,s_{x,i}}}{\\sum_{i=1}^{n_{x}}t_{x,s_{x,i}}}.\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "In contrast, the choice-only estimator is based on eq. (1), which shows that for each query $x\\in\\mathscr{X}$ , the random variable $(c_{x}+1)/2$ follows a Bernoulli distribution with mean $1/[1+\\exp(-x^{\\top}\\cdot2a\\theta^{*})]$ . Similar to the choice-decision-time estimator, the parameter $2a$ does not impact the ranking of arms, so estimating $2a\\theta^{*}$ is sufficient for best-arm identification. This estimation is formulated as a logistic regression problem [3, 31], with MLE providing the following estimate of $2a\\theta^{*}$ , denoted by $\\widehat{\\theta}_{\\mathrm{CH}}^{-}$ : ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\widehat{\\theta}_{\\mathrm{CH}}:=\\arg\\operatorname*{max}_{\\theta\\in\\mathbb{R}^{d}}\\sum_{x\\in\\mathcal{X}_{\\mathrm{sample}}}\\sum_{i=1}^{n_{x}}\\log\\mu(c_{x,s_{x,i}}\\,x^{\\top}\\theta),\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "where $\\mu(y):=1/[1+\\exp(-y)]$ is the standard logistic function. While this MLE lacks a closed-form solution, it can be efficiently solved using optimization methods like Newton\u2019s algorithm [25, 44]. ", "page_idx": 3}, {"type": "text", "text": "3.2 Asymptotic normality of the two estimators ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "The choice-decision-time estimator from eq. (3) satisfies the following asymptotic normality result: Theorem 3.1 (Asymptotic normality of\u03b8CH,DT). Given an i.i.d. dataset x, cx,sx,i, tx,sx,i i\u2208[n] for each $x\\in\\mathcal{X}_{s a m p l e}$ , where $\\begin{array}{r}{\\sum_{x\\in\\mathcal{X}_{s a m p l e}}x x^{\\top}\\succ0,}\\end{array}$ , and assuming that the datasets for different $x\\in\\mathcal{X}_{s a m p l e}$ are independent, then, f or any vector $\\boldsymbol{y}\\in\\mathbb{R}^{d}$ , as $n\\to\\infty$ , the following holds: ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\sqrt{n}\\,y^{\\top}\\left(\\widehat{\\theta}_{C H,D T,n}-\\theta^{*}/a\\right)\\xrightarrow{D}\\mathcal{N}(0,\\zeta^{2}/a^{2}).\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "Here, the asymptotic variance depends on a problem-specific constant, $\\zeta^{2}$ , with an upper bounded: ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\zeta^{2}\\leq\\|y\\|_{\\left(\\sum_{x\\in\\mathcal{X}_{s a m p l e}}\\left[\\operatorname*{min}_{x^{\\prime}\\in\\mathcal{X}_{s a m p l e}}\\mathbb{E}[t_{x^{\\prime}}]\\right]\\cdot x x^{\\top}\\right)^{2}}^{2}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "The proof is provided in appendix C.2. The asymptotic variance upper bound shows that all sampled queries are weighted by a common factor $\\operatorname*{min}_{x^{\\prime}\\in\\mathcal{X}_{\\mathrm{sample}}}\\mathbb{E}\\left[t_{x^{\\prime}}\\right]$ , which is the smallest expected decision time among all the sampled queries. This weight represents the amount of information provided by each query\u2019s choices and decision times to the estimation of $\\theta^{*}$ . A larger weight indicates that every query provides more information, leading to lower variance and better estimates. ", "page_idx": 4}, {"type": "text", "text": "In contrast, the choice-only estimator from eq. (4) has the following asymptotic normality result, as derived from Fahrmeir and Kaufmann [23, corollary 1]: ", "page_idx": 4}, {"type": "text", "text": "Theorem 3.2 (Asymptotic normality of $\\widehat{\\theta}_{\\mathrm{CH}})$ ). Given an i.i.d. dataset $\\left\\{x,c_{x,s_{x,i}},t_{x,s_{x,i}}\\right\\}_{i\\in[n]}$ for each $x\\in\\mathcal{X}_{s a m p l e}$ , where $\\begin{array}{r}{\\sum_{x\\in\\mathcal{X}_{s a m p l e}}x x^{\\top}\\succ0,}\\end{array}$ , and assuming that the datasets for different $x\\in\\mathcal{X}_{s a m p l e}$ are independent, then, for any vector $\\boldsymbol{y}\\in\\mathbb{R}^{d}$ , as $n\\to\\infty$ , the following holds: ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\sqrt{n}y^{\\top}\\left(\\widehat{\\theta}_{C H,n}-2a\\theta^{*}\\right)\\xrightarrow{D}\\mathcal{N}\\left(0,4a^{2}\\left\\lVert y\\right\\rVert_{\\left(\\sum_{x\\in\\mathcal{X}_{s a m p l e}}\\left[a^{2}\\Psi\\left[c_{x}\\right]\\right]\\cdot x x^{\\top}\\right)^{-1}}^{2}\\right).}\\end{array}\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "This asymptotic variance shows that each sampled query $x$ is weighted by its own factor $a^{2}\\,\\mathbb{V}\\left[c_{x}\\right]$ , representing the amount of information the query\u2019s choices contribute to estimating $\\theta^{*}$ . A larger weight indicates that the query contributes more information, leading to better estimates. ", "page_idx": 4}, {"type": "text", "text": "The weights in both theorems highlight the different contributions of choices and decision times to estimating $\\theta^{*}$ . In the choice-only estimator (theorem 3.2), each query is weighted by $a^{2}\\,\\mathbb{V}\\left[c_{x}\\right]$ , which is a function of the utility difference $x^{\\top}\\theta^{*}$ for a fixed barrier $a$ . As shown in the dashed or solid gray curve in fig. 2a, as queries become easier (i.e., as $|x^{\\top}\\theta^{*}|$ increases), the weight quickly decays to zero, indicating that choices from easy queries provide much less information than harder queries. Intuitively, for easy queries, humans consistently choose the same option, making it difficult for the learner to gauge whether their preference for that option is moderate or strong. Thus, choices from easy queries provide limited information about preference strength, contributing minimally to estimating $\\theta^{*}$ . This intuition aligns with the online retailer example in section 1. ", "page_idx": 4}, {"type": "text", "text": "In the choice-decision-time estimator (theorem 3.1), each query is weighted by $\\operatorname*{min}_{x^{\\prime}\\in\\mathcal{X}_{\\mathrm{sample}}}\\mathbb{E}\\left[t_{x^{\\prime}}\\right]$ . The orange curves in fig. 2a show $\\mathbb{E}\\left[t_{x}\\right]$ , but not the $\\mathbf{\\dot{\\omega}}_{\\mathrm{min}},$ operator for clarity. For each query $x\\,\\in\\,\\mathcal{X}_{\\mathrm{sample}}$ , comparing the orange and gray curves reveals that $\\mathbb{E}\\left[t_{x}\\right]$ is generally higher than the choice-only weight, $a^{2}\\,\\mathbb{V}\\left[c_{x}\\right]$ . However, the choice-decision-time estimator\u2019s actual weight, $\\operatorname*{min}_{x^{\\prime}\\in\\mathcal{X}_{\\mathrm{sample}}}\\mathbb{E}\\left[t_{x^{\\prime}}\\right]$ , can vary with $\\chi_{\\mathrm{sample}}$ , and may be either larger or smaller than $a^{2}\\,\\mathbb{V}\\left[c_{x}\\right]$ . For example, when most queries are hard, the choice-decision-time estimator\u2019s weight may be smaller than some of the choice-only estimator\u2019s weights, suggesting that decision times do not always enhance estimation. However, when most queries are easy, the choice-only estimator\u2019s weights are close to zero, while the choice-decision-time estimator\u2019s weight remains large. This demonstrates that incorporating decision times makes easy queries more informative, enhancing estimation. ", "page_idx": 4}, {"type": "text", "text": "Additionally, as the barrier $a$ increases, all curves shift upward. Intuitively, a higher barrier, indicating greater conservativeness in human decision-making, leads to longer decision times and more consistent choices, as discussed in fig. 1, providing more information for utility estimation. ", "page_idx": 4}, {"type": "text", "text": "3.3 Non-asymptotic concentration of the two estimators for utility difference estimation ", "text_level": 1, "page_idx": 4}, {"type": "text", "text": "In this section, we focus on the simpler problem of estimating the utility difference for a single query, without aggregating data from multiple queries. Comparing the non-asymptotic concentration bounds of both estimators, in this case, provides insights similar to those discussed in section 3.2. Extending this non-asymptotic analysis to the full estimation of the preference vector $\\theta^{*}$ is left for future work. ", "page_idx": 4}, {"type": "text", "text": "Given a query $x\\,\\in\\,{\\mathcal{X}}$ , the task is to estimate the utility difference $u_{x}\\,:=\\,x^{\\top}\\theta^{*}$ using the i.i.d. dataset $\\{(c_{x,s_{x,i}},t_{x,s_{x,i}})\\}_{i\\in[n_{x}]}$ . Applying the choice-decision-time estimator from eq. (3), we get the following estimate (for details, see appendix C.3.1), which estimates $u_{x}/a$ rather than $u_{x}$ : ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\widehat{u}_{x,\\mathrm{CH},\\mathrm{DT}}:=\\frac{\\sum_{i=1}^{n_{x}}c_{x,s_{x,i}}}{\\sum_{i=1}^{n_{x}}t_{x,s_{x,i}}}.\n$$", "text_format": "latex", "page_idx": 4}, {"type": "image", "img_path": "aIPwlkdOut/tmp/7af5003bb4b1bac6852414447916ae14e824136bc58ddd77c7f62e556c5bfc14.jpg", "img_caption": ["(a) $\\mathbb{E}\\left[t_{x}\\right]$ and $a^{2}\\,\\mathbb{V}\\left[c_{x}\\right]$ in asymptotic variances (b) Weights in non-asymptotic concentration bounds "], "img_footnote": [], "page_idx": 5}, {"type": "text", "text": "Figure 2: This figure presents the key terms from our theoretical analyses, illustrating the different contributions of choices and decision times for utility estimation. These terms are functions of the utility difference $x^{\\top}\\theta^{*}$ and are plotted for two barrier values $a$ . (a) compares the terms $\\mathbb{E}\\left[t_{x}\\right]$ and $a^{2}\\,\\mathbb{V}\\,[c_{x}]$ in the asymptotic variances for the choice-decision-time estimator (orange, theorem 3.1) and the choice-only estimator (gray, theorem 3.2), respectively. This comparison shows that incorporating decision times makes easy queries more informative. Additionally, higher barrier values $a$ lead to more conservative decision-making, increasing informativeness for both choices and decision times. (b) compares the weights in the non-asymptotic concentration bounds (theorems 3.3 and 3.4), showing similar trends, though these terms may not be optimal due to proof techniques. ", "page_idx": 5}, {"type": "text", "text": "In contrast, applying the choice-only estimator from eq. (4), we get the following estimate (for details, see appendix C.3.2), which estimates $2a u_{x}$ rather than $u_{x}$ : ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\widehat{u}_{x,\\mathrm{CH}}:=\\mu^{-1}\\left(\\frac{1}{n_{x}}\\sum_{i=1}^{n_{x}}\\frac{c_{x,s_{x,i}}+1}{2}\\right),\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "where $(c_{x,s_{x,i}}+1)/2$ is the binary choice coded as 0 or 1, and $\\mu^{-1}(p):=\\log{(p/(1-p))}$ is the logit function (inverse of $\\mu$ introduced in eq. (4)). ", "page_idx": 5}, {"type": "text", "text": "Notably, the choice-only estimator in eq. (6) aligns with the EZ-diffusion model\u2019s drift estimator [67, eq. (5)]. Moreover, the estimators in Xiang Chiong et al. [73, eq. (6)] and Berlinghieri et al. [8, eq. (7)] combine elements of both estimators from eqs. (5) and (6). In section 5, we demonstrate that both estimators from Wagenmakers et al. [67, eq. (5)] and Xiang Chiong et al. [73, eq. (6)] are outperformed by our proposed estimator in eq. (3) for the full bandit problem. ", "page_idx": 5}, {"type": "text", "text": "Assuming the utility difference $u_{x}\\neq0$ , the choice-decision-time estimator in eq. (5) satisfies the following non-asymptotic concentration bound, proven in appendix C.3.1: ", "page_idx": 5}, {"type": "text", "text": "Theorem 3.3 (Non-asymptotic concentration of $\\widehat{u}_{x,\\mathrm{CH},\\mathrm{DT}})$ . For each query $x\\in\\textbf{\\textit{x}}$ with $u_{x}\\ne\\ 0,$ , given an i.i.d. dataset $\\left\\{\\left(c_{x,s_{x,i}},t_{x,s_{x,i}}\\right)\\right\\}_{i\\in[n_{x}]},$ for any $\\epsilon\\mathrm{~\\ensuremath~{~>~0~}~}$ satisfying $\\textup{\\epsilon}\\leq$ $\\operatorname*{min}\\left\\{|u_{x}|/(\\sqrt{2}a),\\big(1+\\sqrt{2}\\big)\\,a|u_{x}|/\\mathbb{E}\\left[t_{x}\\right]\\right\\}$ , the following holds: ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\begin{array}{c}{{\\mathbb{P}\\left(\\left|\\widehat{u}_{x,C H,D T}-\\frac{u_{x}}{a}\\right|>\\epsilon\\right)\\leq4\\exp\\left(-\\left[m_{C H,D T}^{n o n-a s y m}\\left(x^{\\top}\\theta^{*}\\right)\\right]^{2}\\,n_{x}\\,\\left[\\epsilon\\cdot a\\right]^{2}\\right),}}\\\\ {{\\nu_{C H,D T}^{n o n-a s y m}\\left(x^{\\top}\\theta^{*}\\right):=\\mathbb{E}\\left[t_{x}\\right]\\,/\\,\\left[\\left(2+2\\sqrt{2}\\right)a\\right]\\!.}}\\end{array}\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "In contrast, the choice-only estimator in eq. (6) has the following non-asymptotic concentration result, adapted from Jun et al. [31, theorem $5]^{2}$ : ", "page_idx": 5}, {"type": "text", "text": "Theorem 3.4 (Non-asymptotic concentration of $\\widehat{u}_{x,\\mathrm{CH}})$ ). For each query $x\\in\\mathscr{X}$ , given an i.i.d. dataset $\\left\\{c_{x,s_{x,i}}\\right\\}_{i\\in[n_{x}]},$ , for any positive $\\epsilon<0.3,$ , if $\\begin{array}{r}{\\mathrm{~}^{c}n_{x}\\geq1/\\dot{\\mu}(2a u_{x})\\cdot\\operatorname*{max}\\{3^{2}\\log(6e)/\\epsilon^{2},64\\log(3)/(1-\\epsilon)\\}}\\end{array}$ $\\epsilon^{2}/0.3^{2})\\}$ , the following holds: ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\mathbb{P}\\left(\\left|\\widehat{u}_{x,C H}-2a u_{x}\\right|>\\epsilon\\right)\\leq6\\exp\\left(-\\left[m_{C H}^{n o n-a s y m}\\left(x^{\\top}\\theta^{*}\\right)\\right]^{2}\\,n_{x}\\,\\left[\\epsilon/(2a)\\right]^{2}\\right),\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "where mCH $m_{C H}^{n o n-a s y m}\\left(x^{\\top}\\theta^{*}\\right):=a\\,\\sqrt{\\mathbb{V}\\left[c_{x}\\right]}\\,/\\,2.4.$ ", "page_idx": 5}, {"type": "text", "text": "2In Jun et al. [31, theorem 5], we let $x_{1}=\\cdot\\cdot\\cdot=x_{t}=1$ and $t_{\\mathrm{eff}}=d=1$ . ", "page_idx": 5}, {"type": "text", "text": "The weights mnCoHn,-DasTy m(\u00b7) and mnCoHn- asym(\u00b7) from theorems 3.3 and 3.4, respectively, are functions of the utility difference $x^{\\top}\\theta^{*}$ for a fixed barrier $a$ . These weights determine how quickly the estimation error decays as the dataset size $n_{x}$ grows, with larger weights indicating better estimation. While these weights may not be optimal due to our proof techniques, they still reveal the different contributions oFfi gcuhroei c2ebs  caonmd pdaerceiss itohen  twiemiegsh ttso  feosrt ithmea tcihnog $u_{x}$ ,d seicmisiiloarn -ttoi moeu re satsiymmatpotro t(iocr aanngaley, )n  a3n.2d. $m_{\\mathrm{CH,DT}}^{\\mathrm{non-asym}}(\\cdot)_{.}^{\\cdot}$ the choice-only estimator (gray, mnCoHn-asym(\u00b7)). As shown, for hard queries, the choice-decisiontime estimator\u2019s weights may be smaller. However, for easy queries, the choice-only estimator\u2019s weights are close to zero, while the choice-decision-time estimator\u2019s weight remains relatively large, reinforcing that decision times enhance estimation by making easy queries more informative. ", "page_idx": 6}, {"type": "text", "text": "In summary, both our asymptotic (section 3.2) and non-asymptotic (section 3.3) analyses show that the choice-decision-time estimator extracts more information from easy queries, while the choice-only estimator might perform better when most queries are hard. This aligns with the empirical findings of Clithero [16] and will be further supported by our empirical results in section 5.1. To illustrate, consider a teacher trying to identify the top student through two-choice questions. If the questions are easy and all students answer correctly, identifying the top performer is challenging. The teacher can either: (1) ask harder questions to gain more information from choices, or (2) keep the questions easy but use response times (i.e., how quickly students finish) to reveal additional insights. ", "page_idx": 6}, {"type": "text", "text": "In fixed-budget best-arm identification, our choice-decision-time estimator\u2019s ability to extract more information from easy queries is crucial. A bandit learner like GSE [3] strategically samples queries, updates its estimate of $\\theta^{*}$ , and eliminates lower-utility arms. Unlike the choice-only estimator, our approach extracts more information from easy queries, which take less time (i.e., fewer resources) to answer, providing better \u2018bang per buck\u2019 (information per resource) [4]. Moreover, since the learner doesn\u2019t know $\\theta^{*}$ in advance, it cannot selectively sample only hard queries to exploit the strengths of the choice-only estimator. Next, we will integrate both estimators into a bandit learning algorithm. ", "page_idx": 6}, {"type": "text", "text": "4 Interactive learning algorithm ", "text_level": 1, "page_idx": 6}, {"type": "text", "text": "We introduce the Generalized Successive Elimination (GSE) algorithm [1, 3, 75] for fixed-budget best-arm identification in preference-based linear bandits, and outline the key options for each GSE component, which we empirically compare in section 5. ", "page_idx": 6}, {"type": "text", "text": "The pseudo-code for GSE is shown in algorithm 1. The algorithm uses a hyperparameter $\\eta$ to control the number of phases, the budget allocation per phase, and the number of arms eliminated in each phase. GSE divides the total budget $B$ evenly into phases and reserves a buffer, sized by another hyperparameter $B_{\\mathrm{buff}}$ , to prevent over-consuming resources within each phase (line 4). In each phase, GSE computes an experimental design, a probability distribution $\\lambda$ over the query space to determine which queries to sample. We consider two designs: the transductive design [24], $\\lambda_{\\mathrm{trans}}$ (line 5), and the hard-query design [31], $\\lambda_{\\mathrm{hard}}$ (line 6). Both designs minimize the worst-case variance of utility differences between the surviving arms. The transductive design treats all queries equally to achieve this, while the hard-query design focuses more on sampling hard queries to leverage the choice-only estimator\u2019s advantage in extracting information from hard queries, as discussed in section 3. GSE then randomly samples queries according to the design $\\lambda_{s}$ (line 7). After the phase\u2019s budget is exhausted, GSE estimates $\\theta^{*}$ using either the choice-decision-time estimator $\\widehat{\\theta}_{\\mathrm{CH,DT}}$ (line 8) or the choice-only estimator $\\widehat{\\theta}_{\\mathrm{CH}}$ (line 9). Arms with low estimated utilities are elimin a ted, and this process repeats phase-by-phas e  until only one arm remains in $\\mathcal{Z}_{S+1}$ , which GSE then recommends. ", "page_idx": 6}, {"type": "text", "text": "The key difference between algorithm 1 and previous GSE algorithms [1, 3, 75] is that, in our setting, queries consume random response times, which are unknown to the learner. Prior work assumes fixed resource consumption per query and uses deterministic rounding methods [3, 24] to pre-allocate queries to be sampled. This approach is unsuitable for our case with random resource usage. Instead, we adopt a random sampling procedure [13, 61] in line 7 to allocate queries based on the design. The random resource usage also necessitates careful tuning of both the elimination parameter $\\eta$ , to balance data collection and arm elimination, and the buffer size $\\boldsymbol{B}_{\\mathrm{buff}}$ , to prevent over-consuming resources during each phase. In our empirical study (section 5.2), we manually tune both parameters. Our results show that the choice of $\\eta$ impacts performance, unlike prior studies, which typically set $\\eta=2$ by default [3, section 3]. Further theoretical analysis is needed to fully understand the algorithm\u2019s behavior and optimize both the elimination parameter and the buffer size. ", "page_idx": 6}, {"type": "text", "text": "1: Input: Arm space $\\mathcal{Z}$ , query space $\\mathcal{X}$ , non-decision time $t_{\\mathrm{nondec}}$ , and total budget $B$ .   \n2: Hyperparameters: Elimination parameter $\\eta$ and buffer size $B_{\\mathrm{buff}}$ .   \n3: Initialization: $\\mathcal{Z}_{1}\\gets\\mathcal{Z}$ , $s\\gets1$ .   \n4: for each phase $s=1,\\ldots,S:=\\left\\lceil\\log_{\\eta}|\\mathcal{Z}|\\right\\rceil$ with the budget $\\begin{array}{r}{B_{s}:=\\frac{B}{S}-B_{\\mathrm{buff}}\\,\\mathrm{~.~}}\\end{array}$ do   \n5: Design 1. $\\begin{array}{r}{\\lambda_{s}:=\\lambda_{\\mathrm{trans},s}\\gets\\arg\\operatorname*{min}_{\\lambda\\in\\mathbb{A}^{|\\mathcal{X}|}}\\operatorname*{max}_{z\\neq z^{\\prime}\\in\\mathcal{Z}_{s}}\\|z-z^{\\prime}\\|_{(\\setminus\\mathrm{~\\lambda~}_{\\lambda-r\\mathcal{X}}\\top)^{-1}}^{2}.}\\end{array}$   \n\u2225( x\u2208X \u03bbxxx\u22a4)\u22121   \n6: Design 2. \u03bbs := \u03bbhard,s \u2190arg min\u03bb\u2208\u25b2|X| maxz\u0338=z\u2032\u2208Zs \u2225z \u2212z\u2032\u2225(2 x\u2208X \u00b5\u02d9(x\u22a4\u03b8 s\u22121) \u03bbxxx\u22a4)\u22121.   \n7: Sample queries $x_{j}\\sim\\lambda_{s}$ and stop at $J_{s}$ if $\\begin{array}{r}{\\sum_{j=1}^{J_{s}-1}t_{\\mathrm{RT},x_{j},j}\\le B_{s}}\\end{array}$ and $\\begin{array}{r}{\\sum_{j=1}^{J_{s}}t_{\\mathrm{RT},x_{j},j}>B_{s}}\\end{array}$ .   \n8: Estimate 1. $\\widehat{\\theta}_{s}:=\\widehat{\\theta}_{\\mathrm{CH,DT},s}\\gets$ apply eq. (3 ) to all the $J_{s}$ samples.   \n9: Estimate 2. $\\widehat{\\theta}_{s}:=\\widehat{\\theta}_{\\mathrm{CH},s}\\gets:$ apply eq. (4) to all the $J_{s}$ samples.   \n10: Update $\\mathcal{Z}_{s+1}\\leftarrow\\mathrm{Top-}\\left\\lceil\\frac{|\\mathcal{Z}_{s}|}{\\eta}\\right\\rceil$ arms in $\\mathcal{Z}_{s}$ , ranked by the estimated utility $z^{\\top}{\\widehat{\\theta}}_{s}$ .   \n11: end for   \n12: Output: the single one $\\widehat{z}\\in\\mathcal{Z}_{S+1}$ . ", "page_idx": 7}, {"type": "text", "text": "5 Empirical results ", "text_level": 1, "page_idx": 7}, {"type": "text", "text": "This section empirically compares the GSE variations introduced in section 4: (1) $(\\lambda_{\\mathrm{trans}},\\widehat{\\theta}_{\\mathrm{CH,DT}})$ : Transductive design with the choice-decision-time estimator. (2) $(\\lambda_{\\mathrm{trans}},\\widehat{\\theta}_{\\mathrm{CH}})$ : Transductiv e  design with the choice-only estimator. (3) $(\\lambda_{\\mathrm{hard}},\\widehat{\\theta}_{\\mathrm{CH}})$ : Hard-query design with  t he choice-only estimator. ", "page_idx": 7}, {"type": "text", "text": "5.1 Estimation performance on synthetic data ", "text_level": 1, "page_idx": 7}, {"type": "text", "text": "We benchmark the estimation performance of these GSE variations using the \u201csphere\u201d synthetic problem from the linear bandit literature [20, 42, 61]. In this problem, the arm space $\\mathcal{Z}\\subset\\{z\\in$ $\\mathbb{R}^{5}\\colon\\|z\\|_{2}=1\\}$ contains 10 randomly generated arms. To define the true preference vector $\\theta^{*}$ , we select the two arms $z$ and $z^{\\prime}$ that are closest in direction, i.e., $(z,z^{\\prime})\\in\\arg\\operatorname*{max}_{z,z^{\\prime}\\in\\mathcal{Z}}z^{\\top}z^{\\prime}$ , and set $\\theta^{*}=z+0.01(z^{\\prime}-z)$ . In this way, $z$ is the best arm. The query space is $\\mathcal{X}:=\\{\\boldsymbol{z}-\\boldsymbol{z}^{\\prime}\\colon\\boldsymbol{z}\\in\\mathcal{Z}\\}$ . ", "page_idx": 7}, {"type": "text", "text": "Estimation performance, as discussed in section 3, depends on the utility difference $x^{\\top}\\theta^{*}$ and the barrier $a$ . To adjust the utility differences, we scale each query by scaling each arm $z$ to $c_{\\mathcal{Z}}\\cdot z$ . We vary $a$ over a range of typical values from the psychology literature [16, 71]. For each $(c_{\\mathcal{Z}},a)$ pair, the system generates 10 random problem instances and runs 200 repeated simulations per instance. In each simulation, the GSE variations sample 50 queries without considering the response time budget and then compute $\\widehat{\\theta}$ . Performance is measured by $\\mathbb{P}[\\arg\\operatorname*{max}_{z\\in{\\mathcal{Z}}}z^{\\top}\\widehat{\\theta}\\neq z^{*}]$ , reflecting the best-arm identification goal  d iscussed in section 2. To focus purely on estimati on, we allow $\\lambda_{\\mathrm{hard}}$ access to the true $\\theta^{*}$ , enabling it to perfectly compute the weights $\\dot{\\mu}(\\dot{\\boldsymbol{x}}^{\\intercal}\\boldsymbol{\\theta}^{*})$ used in line 6 of algorithm 1. ", "page_idx": 7}, {"type": "text", "text": "As shown in fig. 3a, when fixing the barrier $a$ and examining the vertical line, we observe that the choice-only estimator with the transductive design performs well for small $c_{\\mathcal{Z}}$ (hard queries). However, as $c_{\\mathcal{Z}}$ increases and queries become easier, performance declines, even though larger $c_{\\mathcal{Z}}$ generally makes best-arm identification easier. This decline, illustrated by the dark curved band, aligns with the insights from section 3, that choices from easy queries provide limited information. ", "page_idx": 7}, {"type": "text", "text": "In Figure 3b, for moderate $c_{\\mathcal{Z}}$ , the choice-only estimator with the hard-query design outperforms the transductive design (fig. 3a), showing that focusing on harder queries improves estimation. The lower dark band in fig. 3b compared to fig. 3a shows that focusing on hard queries improves estimation when most queries are easy. However, as $c_{\\mathcal{Z}}$ becomes too large, performance declines, likely because many weights $\\dot{\\mu}(x^{\\top}\\theta^{*})$ approach zero, preventing informative queries from being sampled. This advantage of the hard-query design relies on perfect knowledge of $\\theta^{*}$ and the same resource consumption across all queries. In practice, where $\\theta^{*}$ is unknown and hard queries require longer response times, the hard-query design can be outperformed by the transductive design, as shown in the next section. ", "page_idx": 7}, {"type": "text", "text": "In contrast, fig. 3c shows that the choice-decision-time estimator consistently outperforms the choiceonly estimators in both the transductive and hard-query designs. The choice-decision-time estimator\u2019s performance improves as $c_{\\mathcal{Z}}$ increases (i.e., queries become easier), confirming the theoretical insights from section 3 that incorporating decision times make easy queries more informative. Performance also improves with a higher barrier $a$ , supporting the insights discussed at the end of section 3.2. ", "page_idx": 7}, {"type": "image", "img_path": "aIPwlkdOut/tmp/8434824605ccf18480c9d95388e89c58f7f3cf8dc5cd7c26779370c3b6308e46.jpg", "img_caption": ["Figure 3: Three heatmaps show the estimation error probabilities, $\\mathbb{P}[\\arg\\operatorname*{max}_{z\\in{\\mathcal{Z}}}z^{\\top}\\widehat{\\theta}\\neq z^{*}]$ , for the three GSE variations as functions of the arm scaling factor $c_{\\mathcal{Z}}$ and barrier $a$ . Darker  colors indicate better estimation performance. In (a) and (b), the choice-only estimator $\\widehat{\\theta}_{\\mathrm{CH}}$ with both the transductive design $(\\lambda_{\\mathrm{trans}})$ and the hard-query design $(\\lambda_{\\mathrm{hard}})$ struggles as $c_{\\mathcal{Z}}$ increas e s (i.e., queries become easier), suggesting that choices from easy queries provide limited information. In contrast, in (c), the choicedecision-time estimator $\\widehat{\\theta}_{\\mathrm{CH,DT}}$ with transductive design $(\\lambda_{\\mathrm{trans}})$ consistently achieves better estimation across all $c_{\\mathcal{Z}}$ values, in d icating that decision times make easy queries more informative. "], "img_footnote": [], "page_idx": 8}, {"type": "text", "text": "", "page_idx": 8}, {"type": "text", "text": "5.2 Fixed-budget best-arm identification performance on real datasets ", "text_level": 1, "page_idx": 8}, {"type": "text", "text": "This section compares the bandit performance of six GSE variations. The first three are as previously defined: $(\\lambda_{\\mathrm{trans}},\\bar{\\widehat{\\theta}}_{\\mathrm{CH,DT}})$ , $(\\lambda_{\\mathrm{trans}},\\widehat{\\theta_{\\mathrm{CH}}})$ , and $(\\lambda_{\\mathrm{hard}},\\widehat{\\theta}_{\\mathrm{CH}})$ . ", "page_idx": 8}, {"type": "text", "text": "The 4th GSE variation, $(\\lambda_{\\mathrm{trans}},\\widehat{\\theta}_{\\mathrm{CH},\\mathbb{R}\\mathbb{T}})$ , evaluates the performance of the choice-decision-time estimator when the non-decision tim e $t_{\\mathrm{nondec}}$ is unknown. The estimator, $\\widehat{\\theta}_{\\mathrm{CH,\\mathbb{R}\\mathbb{T}}}$ , is identical to the original choice-decision-time estimator from Eq. (3), but with response tim e s used in place of decision times. ", "page_idx": 8}, {"type": "text", "text": "The 5th GSE variation, $(\\lambda_{\\mathrm{trans}},\\widehat{\\theta}_{\\mathrm{CH,logit}})$ , is based on Wagenmakers et al. [67, eq. (5)], which states that $x^{\\top}\\cdot(2a\\theta^{*})=\\mu^{-1}(\\mathbb{P}[c_{x}=1])$ , where $\\mu^{-1}(p):=\\log\\left(p/\\left(1-p\\right)\\right)$ . By incorporating our linear utility structure, we obtain the following choice-only estimator $\\widehat{\\theta}_{\\mathrm{CH,logit}}$ : ", "page_idx": 8}, {"type": "equation", "text": "$$\n\\widehat{\\theta}_{\\mathrm{CH,logit}}:=\\left(\\sum_{x\\in\\mathcal{X}_{\\mathrm{sample}}}n_{x}\\:x x^{\\top}\\right)^{-1}\\sum_{x\\in\\mathcal{X}_{\\mathrm{sample}}}n_{x}\\:x\\cdot\\mu^{-1}\\left(\\widehat{\\mathfrak{C}}_{x}\\right),\n$$", "text_format": "latex", "page_idx": 8}, {"type": "text", "text": "where $\\begin{array}{r}{\\widehat{\\mathfrak{C}}_{x}:=\\frac{1}{n_{x}}\\sum_{i=1}^{n_{x}}\\frac{1}{2}\\left(c_{x,s_{x,i}}+1\\right)}\\end{array}$ is the empirical mean of the binary choices coded as 0 or 1. ", "page_idx": 8}, {"type": "text", "text": "The 6th GSE variation, $(\\lambda_{\\mathrm{trans}},\\widehat{\\theta}_{\\mathrm{CH,DT,logit}})$ , is based on Xiang Chiong et al. [73, eq. (6)], which states that $x^{\\top}\\theta^{*}=\\operatorname{sgn}\\left(c_{x}\\right)\\sqrt{\\mathbb{E}\\left[c_{x}\\right]/\\mathbb{E}\\left[t_{x}\\right]\\cdot0.5\\,\\mu^{-1}\\left(\\mathbb{P}\\left[c_{x}=1\\right]\\right)}.$ . This identity forms the foundation of the estimator in Berlinghieri et al. [8, eq. (7)]. By incorporating our linear utility structure, we obtain the following choice-decision-time estimator $\\widehat{\\theta}_{\\mathrm{CH,DT,logit}}^{\\mathrm{~\\,~}}$ : ", "page_idx": 8}, {"type": "equation", "text": "$$\n\\widehat{\\theta}_{\\mathrm{CH,DT,logit}}:=\\left(\\sum_{x\\in\\mathcal{X}_{\\mathrm{sample}}}n_{x}\\;x x^{\\top}\\right)^{-1}\\sum_{x\\in\\mathcal{X}_{\\mathrm{sample}}}n_{x}\\;x\\cdot\\mathrm{sgn}\\left(c_{x}\\right)\\sqrt{\\frac{\\mathbb{E}\\left[c_{x}\\right]}{\\mathbb{E}\\left[t_{x}\\right]}\\cdot\\frac{1}{2}\\;\\mu^{-1}\\left(\\widehat{\\mathfrak{C}}_{x}\\right)}.\n$$", "text_format": "latex", "page_idx": 8}, {"type": "text", "text": "We evaluate the six GSE variations by simulating their performance on bandit instances constructed from three real-world datasets of human choices and response times. The first dataset, food-risk with choices (-1 or 1) [57], contains choices and response times from 42 participants answering queries comparing two sets of food items. For each participant, we identified the dEZDM parameters and built a bandit instance with $\\mathcal{Z}\\subset\\mathbb{R}^{5}$ , where $|\\dot{\\mathcal{Z}}|\\in[\\bar{3}1,95]$ , and $\\mathcal{X}:=\\{\\boldsymbol{z}-\\boldsymbol{z}^{\\prime}\\colon\\boldsymbol{z}\\in\\bar{\\mathcal{Z}}\\}$ . The second ", "page_idx": 8}, {"type": "image", "img_path": "aIPwlkdOut/tmp/7d92b5cc952791eb1588c4a0124fca54c974c03e6d56c529e17fc8acf0143df5.jpg", "img_caption": ["(a) Food-risk, (-1 or 1) choices [57].(b) Snack, (yes or no) choices [16]. (c) Snack, (-1 or 1) choices [39]. "], "img_footnote": [], "page_idx": 9}, {"type": "text", "text": "Figure 4: This figure shows violin plots (with overlaid box plots) for datasets (a), (b), and (c), showing the distribution of best-arm identification error probabilities, $\\mathbb{P}\\left[\\widehat{z}\\neq z^{*}\\right]$ , for all bandit instances across six GSE variations and two budgets. The box plots follow the c onvention of the matplotlib Python package. For each GSE variation and budget, the horizontal line in the middle of the box represents the median of the error probabilities across all bandit instances. Each error probability is averaged over 300 repeated simulations under different random seeds. The box\u2019s upper and lower borders represent the third and first quartiles, respectively, with whiskers extending to the farthest points within $1.5\\times$ the interquartile range. Flier points indicate outliers beyond the whiskers. ", "page_idx": 9}, {"type": "text", "text": "dataset, snack with choices (yes or no) [16], contains choices and response times from 31 participants comparing one snack item to a fixed reference snack. For each participant, we built a bandit instance with $\\mathcal{Z}\\subset\\mathbb{R}^{17}$ , where $|\\mathcal{Z}|=17$ , and $\\mathcal{X}:=\\left\\{z-\\mathbf{0}\\colon z\\in\\mathcal{Z}\\right\\}$ . The third dataset, snack with choices (-1 or 1) [39], contains choices and response times from 39 participants comparing two snack items. For each participant, we built a bandit instance with $\\mathcal{Z}\\subset\\mathbb{R}^{2\\bar{1}}$ , $|\\mathcal{Z}|=21$ , and $\\overline{{\\mathcal{X}}}:=\\overline{{\\{\\boldsymbol{z}-\\boldsymbol{z}^{\\prime}\\colon\\boldsymbol{z}\\in\\mathcal{Z}\\}}}$ Details on data processing, tuning the elimination parameter $\\eta$ and buffer size $B_{\\mathrm{buff}}$ as defined in algorithm 1, and experimental procedures are provided in appendix $\\mathrm{D}$ . ", "page_idx": 9}, {"type": "text", "text": "Key results for the three domains are shown in fig. 4, with full results in appendix D. First, $(\\lambda_{\\mathrm{trans}},\\widehat{\\theta}_{\\mathrm{CH,DT}})$ consistently outperforms $(\\lambda_{\\mathrm{trans}},\\widehat{\\theta}_{\\mathrm{CH}})$ , demonstrating the benefit of incorporating decisio  n times. Second, both of these GSE varia t ions outperform $(\\lambda_{\\mathrm{hard}},\\widehat{\\theta}_{\\mathrm{CH}})$ , which, as discussed in section 5.1, suffers from (1) relying on\u03b8 for query selection, which is  p rone to estimation errors, and (2) favoring hard queries with long e r response times, reducing the total number of queries sampled within a fixed budget. Third, $(\\lambda_{\\mathrm{{trans}}},\\widehat{\\theta}_{\\mathrm{{CH},\\mathrm{{DT}}}})$ performs similarly to $(\\lambda_{\\mathrm{trans}},\\widehat{\\theta}_{\\mathrm{CH},\\mathbb{R}\\mathbb{T}})$ , indicating that not knowing the non-decision time   has minimal impact. Finally, $(\\lambda_{\\mathrm{trans}},\\widehat{\\theta}_{\\mathrm{CH,logit}})$ [67] and $(\\lambda_{\\mathrm{trans}},\\widehat{\\theta}_{\\mathrm{CH,DT,logit}})$ [73] do not perform as consistently well as $(\\lambda_{\\mathrm{trans}},\\widehat{\\theta}_{\\mathrm{CH,DT}})$ , und e rscoring the effectivene s s of our proposed choice-decision-time estimator from eq. (3) . ", "page_idx": 9}, {"type": "text", "text": "6 Conclusion and future work ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "This work leverages human response times to enhance fixed-budget best-arm identification in preference-based linear bandits. We proposed a utility estimator that incorporates both choices and response times. Our theoretical and empirical analyses show that response times make easy queries more informative. When integrated into a bandit algorithm, incorporating response times consistently improved performance across simulations based on three real-world datasets. ", "page_idx": 9}, {"type": "text", "text": "A limitation of this work is that reliable response time data requires participants to stay focused [45], which can be challenging in crowdsourcing environments. Future work could incorporate eye movements into the DDM framework, as in attentional DDMs [26, 38, 39, 57, 76], to detect attention lapses and fliter unreliable data. Additionally, while response times are effective for easy queries, they may be less so for hard ones. Future research could develop algorithms that adaptively decide when to incorporate response times. Another direction is to remove the assumption of known non-decision times by estimating them from data, with approaches like those proposed by Wagenmakers et al. [67]. ", "page_idx": 9}, {"type": "text", "text": "References ", "text_level": 1, "page_idx": 10}, {"type": "text", "text": "[1] A. Alieva, A. Cutkosky, and A. Das. Robust pure exploration in linear bandits with limited budget. In M. Meila and T. Zhang, editors, Proceedings of the 38th International Conference on Machine Learning, volume 139 of Proceedings of Machine Learning Research, pages 187\u2013 195. PMLR, 18\u201324 Jul 2021. URL https://proceedings.mlr.press/v139/alieva21a. html. [2] C. Al\u00f3s-Ferrer, E. Fehr, and N. Netzer. Time will tell: Recovering preferences when choices are noisy. Journal of Political Economy, 129(6):1828\u20131877, 2021. doi: 10.1086/713732. URL https://doi.org/10.1086/713732. [3] M. Azizi, B. Kveton, and M. Ghavamzadeh. Fixed-budget best-arm identification in structured bandits. In L. D. Raedt, editor, Proceedings of the Thirty-First International Joint Conference on Artificial Intelligence, IJCAI-22, pages 2798\u20132804. International Joint Conferences on Artificial Intelligence Organization, 7 2022. doi: 10.24963/ijcai.2022/388. URL https: //doi.org/10.24963/ijcai.2022/388. Main Track.   \n[4] A. Badanidiyuru, R. Kleinberg, and A. Slivkins. Bandits with knapsacks. Journal of the ACM (JACM), 65(3):1\u201355, 2018.   \n[5] Y. Bai, A. Jones, K. Ndousse, A. Askell, A. Chen, N. DasSarma, D. Drain, S. Fort, D. Ganguli, T. Henighan, N. Joseph, S. Kadavath, J. Kernion, T. Conerly, S. El-Showk, N. Elhage, Z. HatfieldDodds, D. Hernandez, T. Hume, S. Johnston, S. Kravec, L. Lovitt, N. Nanda, C. Olsson, D. Amodei, T. Brown, J. Clark, S. McCandlish, C. Olah, B. Mann, and J. Kaplan. Training a helpful and harmless assistant with reinforcement learning from human feedback, 2022. URL https://arxiv.org/abs/2204.05862.   \n[6] C. Baldassi, S. Cerreia-Vioglio, F. Maccheroni, M. Marinacci, and M. Pirazzini. A behavioral characterization of the drift diffusion model and its multialternative extension for choice under time pressure. Management Science, 66(11):5075\u20135093, 2020. doi: 10.1287/mnsc.2019.3475. URL https://doi.org/10.1287/mnsc.2019.3475.   \n[7] V. Bengs, R. Busa-Fekete, A. E. Mesaoudi-Paul, and E. H\u00fcllermeier. Preference-based online learning with dueling bandits: A survey. Journal of Machine Learning Research, 22(7):1\u2013108, 2021. URL http://jmlr.org/papers/v22/18-546.html.   \n[8] R. Berlinghieri, I. Krajbich, F. Maccheroni, M. Marinacci, and M. Pirazzini. Measuring utility with diffusion models. Science Advances, 9(34):eadf1665, 2023. doi: 10.1126/sciadv.adf1665. URL https://www.science.org/doi/abs/10.1126/sciadv.adf1665.   \n[9] V. Bogina, T. Kuflik, D. Jannach, M. Bielikova, M. Kompan, and C. Trattner. Considering temporal aspects in recommender systems: a survey. User Modeling and User-Adapted Interaction, 33(1):81\u2013119, 2023. doi: 10.1007/s11257-022-09335-w. URL https://doi. org/10.1007/s11257-022-09335-w.   \n[10] R. A. Bradley and M. E. Terry. Rank analysis of incomplete block designs: I. the method of paired comparisons. Biometrika, 39(3/4):324\u2013345, 1952. ISSN 00063444, 14643510. URL http://www.jstor.org/stable/2334029.   \n[11] S. Brown and A. Heathcote. A ballistic model of choice response time. Psychological review, 112(1):117, 2005.   \n[12] S. D. Brown and A. Heathcote. The simplest complete model of choice response time: Linear ballistic accumulation. Cognitive Psychology, 57(3):153\u2013178, 2008. ISSN 0010-0285. doi: https://doi.org/10.1016/j.cogpsych.2007.12.002. URL https://www.sciencedirect.com/ science/article/pii/S0010028507000722.   \n[13] R. Camilleri, K. Jamieson, and J. Katz-Samuels. High-dimensional experimental design and kernel bandits. In M. Meila and T. Zhang, editors, Proceedings of the 38th International Conference on Machine Learning, volume 139 of Proceedings of Machine Learning Research, pages 1227\u20131237. PMLR, 18\u201324 Jul 2021. URL https://proceedings.mlr.press/v139/ camilleri21a.html.   \n[14] S. C. Castro, D. L. Strayer, D. Matzke, and A. Heathcote. Cognitive workload measurement and modeling under divided attention. Journal of experimental psychology: human perception and performance, 45(6):826, 2019.   \n[15] W. Chu, L. Li, L. Reyzin, and R. Schapire. Contextual bandits with linear payoff functions. In G. Gordon, D. Dunson, and M. Dud\u00edk, editors, Proceedings of the Fourteenth International Conference on Artificial Intelligence and Statistics, volume 15 of Proceedings of Machine Learning Research, pages 208\u2013214, Fort Lauderdale, FL, USA, 11\u201313 Apr 2011. PMLR. URL https://proceedings.mlr.press/v15/chu11a.html.   \n[16] J. A. Clithero. Improving out-of-sample predictions using response times and a model of the decision process. Journal of Economic Behavior & Organization, 148:344\u2013375, 2018. ISSN 0167-2681. doi: https://doi.org/10.1016/j.jebo.2018.02.007. URL https: //www.sciencedirect.com/science/article/pii/S0167268118300398.   \n[17] J. A. Clithero. Response times in economics: Looking through the lens of sequential sampling models. Journal of Economic Psychology, 69:61\u201386, 2018. ISSN 0167-4870. doi: https: //doi.org/10.1016/j.joep.2018.09.008. URL https://www.sciencedirect.com/science/ article/pii/S0167487016306444.   \n[18] D. R. Cox. The theory of stochastic processes. Routledge, 2017.   \n[19] P. De Boeck and M. Jeon. An overview of models for response times and processes in cognitive tests. Frontiers in Psychology, 10, 2019. ISSN 1664-1078. doi: 10.3389/fpsyg. 2019.00102. URL https://www.frontiersin.org/journals/psychology/articles/ 10.3389/fpsyg.2019.00102.   \n[20] R. Degenne, P. Menard, X. Shang, and M. Valko. Gamification of pure exploration for linear bandits. In H. D. III and A. Singh, editors, Proceedings of the 37th International Conference on Machine Learning, volume 119 of Proceedings of Machine Learning Research, pages 2432\u20132442. PMLR, 13\u201318 Jul 2020. URL https://proceedings.mlr.press/v119/ degenne20a.html.   \n[21] Y. Deldjoo, M. Schedl, and P. Knees. Content-driven music recommendation: Evolution, state of the art, and challenges. Computer Science Review, 51:100618, 2024. ISSN 1574-0137. doi: https://doi.org/10.1016/j.cosrev.2024.100618. URL https://www.sciencedirect.com/ science/article/pii/S1574013724000029.   \n[22] J. Drugowitsch. Fast and accurate monte carlo sampling of first-passage times from wiener diffusion models. Scientific reports, 6(1):20490, 2016.   \n[23] L. Fahrmeir and H. Kaufmann. Consistency and asymptotic normality of the maximum likelihood estimator in generalized linear models. The Annals of Statistics, 13(1):342\u2013368, 1985. ISSN 00905364, 21688966. URL http://www.jstor.org/stable/2241164.   \n[24] T. Fiez, L. Jain, K. G. Jamieson, and L. Ratliff. Sequential experimental design for transductive linear bandits. In H. Wallach, H. Larochelle, A. Beygelzimer, F. d'Alch\u00e9-Buc, E. Fox, and R. Garnett, editors, Advances in Neural Information Processing Systems, volume 32. Curran Associates, Inc., 2019. URL https://proceedings.neurips.cc/paper%5Ffiles/paper/ 2019/file/8ba6c657b03fc7c8dd4dff8e45defcd2-Paper.pdf.   \n[25] S. Filippi, O. Cappe, A. Garivier, and C. Szepesv\u00e1ri. Parametric bandits: The generalized linear case. In J. Lafferty, C. Williams, J. Shawe-Taylor, R. Zemel, and A. Culotta, editors, Advances in Neural Information Processing Systems, volume 23. Curran Associates, Inc., 2010. URL https://proceedings.neurips.cc/paper%5Ffiles/paper/2010/file/ c2626d850c80ea07e7511bbae4c76f4b-Paper.pdf.   \n[26] G. Fisher. An attentional drift diffusion model over binary-attribute choice. Cognition, 168: 34\u201345, 2017. ISSN 0010-0277. doi: https://doi.org/10.1016/j.cognition.2017.06.007. URL https://www.sciencedirect.com/science/article/pii/S0010027717301695.   \n[27] D. Fudenberg, P. Strack, and T. Strzalecki. Speed, accuracy, and the optimal timing of choices. American Economic Review, 108(12):3651\u201384, December 2018. doi: 10.1257/aer.20150742. URL https://www.aeaweb.org/articles?id $=\\mathtt{10}$ .1257/aer.20150742.   \n[28] D. Fudenberg, W. Newey, P. Strack, and T. Strzalecki. Testing the drift-diffusion model. Proceedings of the National Academy of Sciences, 117(52):33141\u201333148, 2020. doi: 10.1073/ pnas.2011446117. URL https://www.pnas.org/doi/abs/10.1073/pnas.2011446117.   \n[29] V. Gabillon, M. Ghavamzadeh, and A. Lazaric. Best arm identification: A unified approach to fixed budget and fixed confidence. In F. Pereira, C. Burges, L. Bottou, and K. Weinberger, editors, Advances in Neural Information Processing Systems, volume 25. Curran As", "page_idx": 10}, {"type": "text", "text": "", "page_idx": 11}, {"type": "text", "text": "sociates, Inc., 2012. URL https://proceedings.neurips.cc/paper%5Ffiles/paper/ 2012/file/8b0d268963dd0cfb808aac48a549829f-Paper.pdf. ", "page_idx": 12}, {"type": "text", "text": "[30] R. P. Grasman, E.-J. Wagenmakers, and H. L. van der Maas. On the mean and variance of response times under the diffusion model with an application to parameter estimation. Journal of Mathematical Psychology, 53(2):55\u201368, 2009. ISSN 0022-2496. doi: https://doi.org/ 10.1016/j.jmp.2009.01.006. URL https://www.sciencedirect.com/science/article/ pii/S0022249609000066.   \n[31] K.-S. Jun, L. Jain, B. Mason, and H. Nassif. Improved confidence bounds for the linear logistic model and applications to bandits. In M. Meila and T. Zhang, editors, Proceedings of the 38th International Conference on Machine Learning, volume 139 of Proceedings of Machine Learning Research, pages 5148\u20135157. PMLR, 18\u201324 Jul 2021. URL https://proceedings. mlr.press/v139/jun21a.html.   \n[32] M. Karimi, D. Jannach, and M. Jugovac. News recommender systems \u2013 survey and roads ahead. Information Processing & Management, 54(6):1203\u20131227, 2018. ISSN 0306-4573. doi: https://doi.org/10.1016/j.ipm.2018.04.008. URL https://www.sciencedirect.com/ science/article/pii/S030645731730153X.   \n[33] N. Karpov and Q. Zhang. Instance-sensitive algorithms for pure exploration in multinomial logit bandit. Proceedings of the AAAI Conference on Artificial Intelligence, 36(7):7096\u20137103, Jun. 2022. doi: 10.1609/aaai.v36i7.20669. URL https://ojs.aaai.org/index.php/AAAI/ article/view/20669.   \n[34] E. Kaufmann, O. Capp\u00e9, and A. Garivier. On the complexity of best-arm identification in multi-armed bandit models. Journal of Machine Learning Research, 17(1):1\u201342, 2016. URL http://jmlr.org/papers/v17/kaufman16a.html.   \n[35] A. Konovalov and I. Krajbich. Revealed strength of preference: Inference from response times. Judgment and Decision Making, 14(4):381\u2013394, 2019. doi: 10.1017/S1930297500006082.   \n[36] P. Koppol, H. Admoni, and R. Simmons. Iterative interactive reward learning. In Participatory Approaches to Machine Learning, International Conference on Machine Learning Workshop, 2020.   \n[37] P. Koppol, H. Admoni, and R. Simmons. Interaction considerations in learning from humans. In Z.-H. Zhou, editor, Proceedings of the Thirtieth International Joint Conference on Artificial Intelligence, IJCAI-21, pages 283\u2013291. International Joint Conferences on Artificial Intelligence Organization, 8 2021. doi: 10.24963/ijcai.2021/40. URL https://doi.org/10.24963/ ijcai.2021/40. Main Track.   \n[38] I. Krajbich. Accounting for attention in sequential sampling models of decision making. Current Opinion in Psychology, 29:6\u201311, 2019. ISSN 2352-250X. doi: https://doi.org/10.1016/ j.copsyc.2018.10.008. URL https://www.sciencedirect.com/science/article/pii/ S2352250X18301866. Attention & Perception.   \n[39] I. Krajbich, C. Armel, and A. Rangel. Visual fixations and the computation and comparison of value in simple choice. Nature Neuroscience, 13(10):1292\u20131298, 2010. doi: 10.1038/nn.2635. URL https://doi.org/10.1038/nn.2635.   \n[40] V. Lerche, A. Voss, and M. Nagler. How many trials are required for parameter estimation in diffusion modeling? a comparison of different optimization criteria. Behavior Research Methods, 49(2):513\u2013537, 2017. doi: 10.3758/s13428-016-0740-2. URL https://doi.org/ 10.3758/s13428-016-0740-2.   \n[41] L. Li, W. Chu, J. Langford, and R. E. Schapire. A contextual-bandit approach to personalized news article recommendation. In Proceedings of the 19th International Conference on World Wide Web, WWW \u201910, page 661\u2013670, New York, NY, USA, 2010. Association for Computing Machinery. ISBN 9781605587998. doi: 10.1145/1772690.1772758. URL https://doi.org/ 10.1145/1772690.1772758.   \n[42] Z. Li, K. Jamieson, and L. Jain. Optimal exploration is no harder than Thompson sampling. In S. Dasgupta, S. Mandt, and Y. Li, editors, Proceedings of The 27th International Conference on Artificial Intelligence and Statistics, volume 238 of Proceedings of Machine Learning Research, pages 1684\u20131692. PMLR, 02\u201304 May 2024. URL https://proceedings.mlr. press/v238/li24h.html.   \n[43] J. Menick, M. Trebacz, V. Mikulik, J. Aslanides, F. Song, M. Chadwick, M. Glaese, S. Young, L. Campbell-Gillingham, G. Irving, et al. Teaching language models to support answers with verified quotes. arXiv preprint arXiv:2203.11147, 2022.   \n[44] T. P. Minka. A comparison of numerical optimizers for logistic regression. Unpublished draft, 2003. URL https://tminka.github.io/papers/logreg/minka-logreg.pdf.   \n[45] C. E. Myers, A. Interian, and A. A. Moustafa. A practical introduction to using the drift diffusion model of decision-making in cognitive psychology, neuroscience, and health sciences. Frontiers in Psychology, 13, 2022. ISSN 1664-1078. doi: 10.3389/fpsyg.2022. 1039172. URL https://www.frontiersin.org/journals/psychology/articles/10. 3389/fpsyg.2022.1039172.   \n[46] R. Nakano, J. Hilton, S. Balaji, J. Wu, L. Ouyang, C. Kim, C. Hesse, S. Jain, V. Kosaraju, W. Saunders, et al. Webgpt: Browser-assisted question-answering with human feedback. arXiv preprint arXiv:2112.09332, 2021.   \n[47] L. Ouyang, J. Wu, X. Jiang, D. Almeida, C. Wainwright, P. Mishkin, C. Zhang, S. Agarwal, K. Slama, A. Ray, J. Schulman, J. Hilton, F. Kelton, L. Miller, M. Simens, A. Askell, P. Welinder, P. F. Christiano, J. Leike, and R. Lowe. Training language models to follow instructions with human feedback. In S. Koyejo, S. Mohamed, A. Agarwal, D. Belgrave, K. Cho, and A. Oh, editors, Advances in Neural Information Processing Systems, volume 35, pages 27730\u201327744. Curran Associates, Inc., 2022. URL https://proceedings.neurips.cc/paper%5Ffiles/ paper/2022/file/b1efde53be364a73914f58805a001731-Paper-Conference.pdf.   \n[48] J. Palmer, A. C. Huk, and M. N. Shadlen. The effect of stimulus strength on the speed and accuracy of a perceptual decision. Journal of Vision, 5(5):1\u20131, 05 2005. ISSN 1534-7362. doi: 10.1167/5.5.1. URL https://doi.org/10.1167/5.5.1.   \n[49] M. L. Pedersen, M. J. Frank, and G. Biele. The drift diffusion model as the choice rule in reinforcement learning. Psychonomic Bulletin & Review, 24(4):1234\u20131251, 2017. doi: 10.3758/s13423-016-1199-y. URL https://doi.org/10.3758/s13423-016-1199-y.   \n[50] M. P\u00e9rez-Ortiz, A. Mikhailiuk, E. Zerman, V. Hulusic, G. Valenzise, and R. K. Mantiuk. From pairwise comparisons and rating to a unified quality scale. IEEE Transactions on Image Processing, 29:1139\u20131151, 2020. doi: 10.1109/TIP.2019.2936103.   \n[51] R. Ratcliff and G. McKoon. The Diffusion Decision Model: Theory and Data for TwoChoice Decision Tasks. Neural Computation, 20(4):873\u2013922, 04 2008. ISSN 0899-7667. doi: 10.1162/neco.2008.12-06-420. URL https://doi.org/10.1162/neco.2008.12-06-420.   \n[52] R. Ratcliff and F. Tuerlinckx. Estimating parameters of the diffusion model: Approaches to dealing with contaminant reaction times and parameter variability. Psychonomic Bulletin & Review, 9(3):438\u2013481, 2002. doi: 10.3758/BF03196302. URL https://doi.org/10.3758/ BF03196302.   \n[53] R. Ratcliff, P. L. Smith, S. D. Brown, and G. McKoon. Diffusion decision model: Current issues and history. Trends in Cognitive Sciences, 20(4):260\u2013281, 2016. ISSN 1364-6613. doi: https://doi.org/10.1016/j.tics.2016.01.007. URL https://www.sciencedirect.com/ science/article/pii/S1364661316000255.   \n[54] D. Sadigh, A. Dragan, S. Sastry, and S. Seshia. Active preference-based learning of reward functions. In Proceedings of Robotics: Science and Systems, Cambridge, Massachusetts, July 2017. doi: 10.15607/RSS.2017.XIII.053.   \n[55] M. Shvartsman, B. Letham, E. Bakshy, and S. L. Keeley. Response time improves gaussian process models for perception and preferences. In The 40th Conference on Uncertainty in Artificial Intelligence, 2024.   \n[56] N. Silva, H. Werneck, T. Silva, A. C. Pereira, and L. Rocha. Multi-armed bandits in recommendation systems: A survey of the state-of-the-art and future directions. Expert Systems with Applications, 197:116669, 2022. ISSN 0957-4174. doi: https://doi.org/10.1016/j.eswa.2022.116669. URL https://www.sciencedirect.com/science/article/pii/S0957417422001543.   \n[57] S. M. Smith and I. Krajbich. Attention and choice across domains. Journal of Experimental Psychology: General, 147(12):1810, 2018.   \n[58] T. Somers, N. R. Lawrance, and G. A. Hollinger. Efficient learning of trajectory preferences using combined ratings and rankings. In Robotics: Science and Systems Conference Workshop on Mathematical Models, Algorithms, and Human-Robot Interaction, 2017.   \n[59] N. Stiennon, L. Ouyang, J. Wu, D. Ziegler, R. Lowe, C. Voss, A. Radford, D. Amodei, and P. F. Christiano. Learning to summarize with human feedback. In H. Larochelle, M. Ranzato, R. Hadsell, M. Balcan, and H. Lin, editors, Advances in Neural Information Processing Systems, volume 33, pages 3008\u20133021. Curran Associates, Inc., 2020. URL https://proceedings.neurips.cc/paper%5Ffiles/paper/2020/file/ 1f89885d556929e98d3ef9b86448f951-Paper.pdf.   \n[60] T. Strzalecki. Stochastic Choice Theory. Econometric Society Monographs. Cambridge University Press, 2025. URL https://scholar.harvard.edu/sites/scholar.harvard. edu/files/tomasz/files/manuscript_01.pdf.   \n[61] C. Tao, S. Blanco, and Y. Zhou. Best arm identification in linear bandits with linear dimension dependency. In J. Dy and A. Krause, editors, Proceedings of the 35th International Conference on Machine Learning, volume 80 of Proceedings of Machine Learning Research, pages 4877\u20134886. PMLR, 10\u201315 Jul 2018. URL https://proceedings.mlr.press/v80/tao18a.html.   \n[62] A. W. Thomas, F. Molter, I. Krajbich, H. R. Heekeren, and P. N. C. Mohr. Gaze bias differences capture individual choice behaviour. Nature Human Behaviour, 3(6):625\u2013635, 2019. doi: 10.1038/s41562-019-0584-8. URL https://doi.org/10.1038/s41562-019-0584-8.   \n[63] A. Tirinzoni and R. Degenne. On elimination strategies for bandit fixed-confidence identification. In S. Koyejo, S. Mohamed, A. Agarwal, D. Belgrave, K. Cho, and A. Oh, editors, Advances in Neural Information Processing Systems, volume 35, pages 18586\u201318598. Curran Associates, Inc., 2022. URL https://proceedings.neurips.cc/paper%5Ffiles/ paper/2022/file/760564ebba4797d0dcf1678e96e8cbcb-Paper-Conference.pdf.   \n[64] J. S. Trueblood, S. D. Brown, and A. Heathcote. The multiattribute linear ballistic accumulator model of context effects in multialternative choice. Psychological review, 121(2):179, 2014.   \n[65] M. Tucker, E. Novoseller, C. Kann, Y. Sui, Y. Yue, J. W. Burdick, and A. D. Ames. Preferencebased learning for exoskeleton gait optimization. In 2020 IEEE International Conference on Robotics and Automation (ICRA), pages 2351\u20132357, 2020. doi: 10.1109/ICRA40945.2020. 9196661.   \n[66] M. Usher and J. L. McClelland. The time course of perceptual choice: the leaky, competing accumulator model. Psychological review, 108(3):550, 2001.   \n[67] E.-J. Wagenmakers, H. L. J. Van Der Maas, and R. P. P. P. Grasman. An ez-diffusion model for response time and accuracy. Psychonomic Bulletin & Review, 14(1):3\u201322, 2007. doi: 10.3758/BF03194023. URL https://doi.org/10.3758/BF03194023.   \n[68] E.-J. Wagenmakers, H. L. J. van der Maas, C. V. Dolan, and R. P. P. P. Grasman. Ez does it! extensions of the ez-diffusion model. Psychonomic Bulletin & Review, 15(6):1229\u20131235, 2008. doi: 10.3758/PBR.15.6.1229. URL https://doi.org/10.3758/PBR.15.6.1229.   \n[69] M. J. Wainwright. High-dimensional statistics: A non-asymptotic viewpoint, volume 48. Cambridge university press, 2019.   \n[70] R. Webb. The (neural) dynamics of stochastic choice. Management Science, 65(1):230\u2013255, 2019. doi: 10.1287/mnsc.2017.2931. URL https://doi.org/10.1287/mnsc.2017.2931.   \n[71] T. V. Wiecki, I. Sofer, and M. J. Frank. Hddm: Hierarchical bayesian estimation of the drift-diffusion model in python. Frontiers in Neuroinformatics, 7, 2013. ISSN 1662- 5196. doi: 10.3389/fninf.2013.00014. URL https://www.frontiersin.org/journals/ neuroinformatics/articles/10.3389/fninf.2013.00014.   \n[72] N. Wilde, E. Biyik, D. Sadigh, and S. L. Smith. Learning reward functions from scale feedback. In A. Faust, D. Hsu, and G. Neumann, editors, Proceedings of the 5th Conference on Robot Learning, volume 164 of Proceedings of Machine Learning Research, pages 353\u2013362. PMLR, 08\u201311 Nov 2022. URL https://proceedings.mlr.press/v164/wilde22a.html.   \n[73] K. Xiang Chiong, M. Shum, R. Webb, and R. Chen. Combining choice and response time data: A drift-diffusion model of mobile advertisements. Management Science, 70(2):1238\u20131257, 2024. doi: 10.1287/mnsc.2023.4738. URL https://doi.org/10.1287/mnsc.2023.4738.   \n[74] Y. Xu, H. Zhang, K. Miller, A. Singh, and A. Dubrawski. Noise-tolerant interactive learning using pairwise comparisons. In I. Guyon, U. V. Luxburg, S. Bengio, H. Wallach, R. Fergus, S. Vishwanathan, and R. Garnett, editors, Advances in Neural Information Processing Systems, volume 30. Curran Associates, Inc., 2017. URL https://proceedings.neurips.cc/paper% 5Ffiles/paper/2017/file/e11943a6031a0e6114ae69c257617980-Paper.pdf.   \n[75] J. Yang and V. Tan. Minimax optimal fixed-budget best arm identification in linear bandits. In S. Koyejo, S. Mohamed, A. Agarwal, D. Belgrave, K. Cho, and A. Oh, editors, Advances in Neural Information Processing Systems, volume 35, pages 12253\u201312266. Curran Associates, Inc., 2022. URL https://proceedings.neurips.cc/paper%5Ffiles/ paper/2022/file/4f9342b74c3bb63f6e030d8263082ab6-Paper-Conference.pdf.   \n[76] X. Yang and I. Krajbich. A dynamic computational model of gaze and choice in multi-attribute decisions. Psychological Review, 130(1):52, 2023.   \n[77] H. Yu, R. M. Aronson, K. H. Allen, and E. S. Short. From \u201cthumbs up\u201d to \u201c10 out of $10^{\\circ}$ : Reconsidering scalar feedback in interactive reinforcement learning. In 2023 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), pages 4121\u20134128, 2023. doi: 10.1109/IROS55552.2023.10342458.   \n[78] C. Zhang, C. Kemp, and N. Lipovetzky. Goal recognition with timing information. Proceedings of the International Conference on Automated Planning and Scheduling, 33(1):443\u2013451, Jul. 2023. doi: 10.1609/icaps.v33i1.27224. URL https://ojs.aaai.org/index.php/ICAPS/ article/view/27224.   \n[79] C. Zhang, C. Kemp, and N. Lipovetzky. Human goal recognition as bayesian inference: Investigating the impact of actions, timing, and goal solvability. In Proceedings of the $23r d$ International Conference on Autonomous Agents and Multiagent Systems, AAMAS \u201924, page 2066\u20132074, Richland, SC, 2024. International Foundation for Autonomous Agents and Multiagent Systems. ISBN 9798400704864. ", "page_idx": 12}, {"type": "text", "text": "", "page_idx": 13}, {"type": "text", "text": "", "page_idx": 14}, {"type": "text", "text": "", "page_idx": 15}, {"type": "text", "text": "A Broader impacts ", "text_level": 1, "page_idx": 16}, {"type": "text", "text": "Incorporating human response times in human-interactive AI systems provides significant benefits, such as efficiently eliciting user preferences, reducing cognitive loads on users, and improving accessibility for users with disabilities and various cognitive abilities. These benefits can greatly improve recommendation systems, assistive robots, online shopping platforms, and fine-tuning for large language models. However, using human response times also raises concerns about privacy, manipulation, and bias against individuals with slower response times. Governments and law enforcement should work together to mitigate these negative consequences by establishing ethical standards and regulations. Businesses should always obtain user consent before recording response times. ", "page_idx": 16}, {"type": "text", "text": "B Literature review ", "text_level": 1, "page_idx": 17}, {"type": "text", "text": "B.1 Bounded accumulation models for choices and response times ", "text_level": 1, "page_idx": 17}, {"type": "text", "text": "Bounded Accumulation Models (BAMs) describe human decision-making using an accumulator (or sampling rule) and a stopping rule [70]. In binary choice tasks, such as two-alternative forced choice tasks, a widely used BAM is the drift-diffusion model (DDM) [51], which models decisions as Brownian motion with fixed boundaries. To capture differences in human response times for correct and incorrect answers, Ratcliff and McKoon [51] allows drift, starting point, and non-decision time to vary across trials. Wagenmakers et al. [67] later introduced the EZ-diffusion model (EZDM), a simplified version of DDM with closed-form solutions for choice and response time moments, making parameter estimation easier and more robust. EZDM assumes deterministic drift, starting point, and non-decision time, fixed across trials, with the starting point equidistant from the boundaries. Berlinghieri et al. [8] specialized EZDM to the difference-based EZDM (dEZDM), where the drift represents the utility difference between two options. For binary queries with arms $z_{1}$ and $z_{2}$ , the drift is modeled as $u_{z_{1}}-u_{z_{2}}$ , where $u_{z_{1}}$ and $u_{z_{2}}$ are the utilities of $z_{1}$ and $z_{2}$ . ", "page_idx": 17}, {"type": "text", "text": "As discussed in section 2, we impose a linear utility structure on the dEZDM, where each arm\u2019s utility is given by $u_{z}=z^{\\top}\\theta^{*}$ , with $\\theta^{*}$ denotes the human preference vector. This approach is supported by both bandit and psychology literature. In bandits, linear utility models scale efficiently with a large number of arms [15, 41]. In psychology, linear combinations of attributes are commonly used in multi-attribute decision-making models [26, 64, 76]. The standard dEZDM in [8, Definition 1] is a special case of our dEZDM with a linear utility structure, where arms correspond to the standard basis vectors in Euclidean space $\\mathbb{R}^{d}$ . This mirrors the relationship between multi-armed bandits and linear bandits. ", "page_idx": 17}, {"type": "text", "text": "Similarly to our approach, Shvartsman et al. [55] parameterize the human utility function as a Gaussian process and propose a moment-matching Bayesian inference method that uses both choices and response times to estimate latent utilities. Unlike our work, their focus is solely on estimation and does not address bandit optimization. Integrating their estimation techniques into bandit optimization presents an interesting avenue for future research. ", "page_idx": 17}, {"type": "text", "text": "Another widely used BAM is the race model [11, 66], which naturally extends to queries with more than two options. In race models, each option has its own accumulator, and the decision ends when any accumulator reaches its barrier. BAMs can also model human attention during decision-making. For example, the attentional-DDM [38, 39, 76] jointly models choices, response times, and eye movements across different options or attributes. Similarly, Thomas et al. [62] introduce the gazeweighted linear accumulator model to study gaze bias at the trial level. To incorporate learning effects, Pedersen et al. [49] combine reinforcement learning (RL) with DDM, where the human adjusts the drift through RL. In contrast, our work uses RL for AI decision-making when interacting with humans. BAMs also connect to Bayesian RL models of human cognition. For example, Fudenberg et al. [27] propose a model where humans balance decision accuracy and time cost, showing it is equivalent to a DDM with time-decaying boundaries. Neurophysiological evidence supports BAMs. For instance, EEG recordings demonstrate that neurons exhibit accumulation processes and decision thresholds [70]. Additionally, diffusion processes have been used to model neural firing rates [53]. ", "page_idx": 17}, {"type": "text", "text": "B.2 Parameter estimation for bounded accumulation models ", "text_level": 1, "page_idx": 17}, {"type": "text", "text": "BAMs often lack closed-form density functions, so hierarchical Bayesian inference is commonly used for parameter estimation [71]. While flexible, these methods are computationally intensive, making them impractical for real-time applications in online learning systems. Faster estimators [8, 67, 73] usually estimate parameters for individual option pairs without leveraging data across pairs. To address this, we propose a computationally efficient method for estimating linear human utility functions, which we integrate into bandit learning. In section 5.2, we empirically show that our estimator outperforms those from prior work [67, 73]. ", "page_idx": 17}, {"type": "text", "text": "In practice, using response time data requires pre-processing and model ftiting, as outlined by Myers et al. [45]. Additionally, Al\u00f3s-Ferrer et al. [2], Baldassi et al. [6], Fudenberg et al. [28] propose statistical tests to assess the suitability of various DDM extensions for a given dataset. ", "page_idx": 17}, {"type": "text", "text": "B.3 Uses of response times ", "text_level": 1, "page_idx": 18}, {"type": "text", "text": "Response times serve multiple purposes, as highlighted by Clithero [17]. A primary use is improving choice prediction. For instance, Clithero [16] showed that DDM predicts choice probabilities more accurately than the logit model, with parameters estimated through Bayesian Markov chain Monte Carlo. Similarly, Al\u00f3s-Ferrer et al. [2] demonstrated that response times enhance the identifiability of human preferences compared to using choices alone. ", "page_idx": 18}, {"type": "text", "text": "Response times also shed light on human decision-making processes. Castro et al. [14] applied DDM analysis to explore how cognitive workload, induced by secondary tasks, influences decision-making. Analyzing response times has been a long-standing method in cognitive testing to assess mental capabilities [19]. Additionally, Zhang et al. [78, 79] introduced a framework that uses human planning time to infer their intended goals. ", "page_idx": 18}, {"type": "text", "text": "Response times can also enhance AI decision-making. In dueling bandits and preference-based RL [7], human choice models are commonly used for preference elicitation. One such model, the random utility model, can be derived from certain BAMs [2]. For example, as discussed after eq. (1), both the Bradley-Terry model [10] and dEZDM [8, 67] yield logistic choice probabilities in the form $\\mathbb{P}[z_{1}\\succ z_{2}]=\\bar{\\sigma}_{l o g i s t i c}(u_{z_{1}}-u_{z_{2}})=1/\\left(1+\\exp\\left(-(\\dot{u}_{z_{1}}-\\dot{u_{z_{2}}})\\right)\\right)$ ), where $u_{z_{1}}$ and $u_{z_{2}}$ denote the utilities of $z_{1}$ and $z_{2}$ [7, section 3.2]. Our work leverages this connection between random utility models and choice-response-time models to estimate human utilities using both choices and response times. ", "page_idx": 18}, {"type": "text", "text": "We hypothesize that the insight that response times make easy queries more informative extends beyond the dEZDM and the specific link function $\\sigma_{l o g i s t i c}$ . Many psychological models capture both choices and response times but lack closed-form choice distributions. In these cases, choice probability is often expressed as $\\mathbb{P}[z_{1}\\,\\succ\\,z_{2}]\\,=\\,\\sigma^{\\dagger}(u_{z_{1}},u_{z_{2}})$ , where $\\sigma^{\\dagger}$ is a potentially complex function of $u_{z_{1}}$ and $u_{z_{2}}$ without a closed form. If we fix $u_{z_{2}}$ and vary only $u_{z_{1}}$ , the function $\\sigma^{\\dagger}(\\cdot,u_{z_{2}})$ is known as a psychometric function, which typically exhibits an ${\\bf\\nabla}^{\\bullet}{\\bf S}^{\\bullet}$ shape [60, above fig. 1.1]. As preference strength becomes extreme, $\\sigma^{\\dagger}$ flattens, providing less information, similar to the green curves in figs. 1b and 1c. In such cases, we conjecture that response times can offer valuable complementary information. ", "page_idx": 18}, {"type": "text", "text": "If we further assume the choice probability depends only on the utility difference, $u_{z_{1}}-u_{z_{2}}$ , we obtain ${\\mathbb P}[z_{1}\\succ z_{2}]=\\sigma^{\\ddag}(u_{z_{1}}-u_{z_{2}})$ . This link function, $\\sigma^{\\ddag}$ , is commonly used in preference-based RL [7, section 3.2], where it is assumed to be strictly monotonic and bounded within $[0,1]$ , again reflecting the \u201c $\\mathbf{\\nabla}\\mathbf{S}^{\\bullet}$ -shaped behavior. As the absolute value of the utility difference grows large, $\\sigma^{\\ddag}(u_{z_{1}}-u_{z_{2}})$ flattens, providing less information. We conjecture that response times can offer valuable complementary information. ", "page_idx": 18}, {"type": "text", "text": "In summary, BAMs, like DDMs and race models, offer a strong theoretical framework for understanding human decision-making, supported by both behavioral and neurophysiological evidence. These models have been widely applied to choice prediction and the study of human cognitive processes. Our work connects BAMs with bandit algorithms by introducing a computationally efficient estimator for online preference learning. Future research could explore other BAM variants to further examine the benefits of incorporating response times. ", "page_idx": 18}, {"type": "text", "text": "C Proofs ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "C.1 Parameters of the difference-based EZ-Diffusion Model (dEZDM) [8, 67] ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "Given a human preference vector $\\theta^{*}$ , for each query $x\\in\\mathscr{X}$ , the utility difference is defined as $u_{x}:=$ $x^{\\top}\\theta^{*}$ . In the dEZDM model (introduced in section 2), with barrier $a$ , according to Wagenmakers et al. [67, eq. (4), (6), and (9)], the human choice $c_{x}$ has the following properties: ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\mathbb{P}\\left(c_{x}=1\\right)=\\frac{1}{1+\\exp\\left(-2a u_{x}\\right)},\\quad\\mathbb{P}\\left(c_{x}=-1\\right)=\\frac{\\exp\\left(-2a u_{x}\\right)}{1+\\exp\\left(-2a u_{x}\\right)}.\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "Thus, the expected choice is $\\mathbb{E}\\left[c_{x}\\right]=\\operatorname{tanh}(a u_{x})$ , and the choice variance is $\\mathbb{V}\\left[c_{x}\\right]=1\\!-\\!\\operatorname{tanh}(a u_{x})^{2}$ (restating eq. (1)). ", "page_idx": 19}, {"type": "text", "text": "The human decision time $t_{x}$ has the following properties: ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{E}\\left[t_{x}\\right]=\\left\\{\\frac{a}{u_{x}}\\operatorname{tanh}(a u_{x})\\quad\\mathrm{if}\\;u_{x}\\neq0\\quad\\quad\\mathrm{(restating~eq.~(1))},}\\\\ &{\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\mathrm{if}\\;u_{x}=0\\quad\\quad\\quad\\mathrm{(restating~eq.~(1))},}\\\\ &{\\mathbb{V}\\left[t_{x}\\right]=\\left\\{\\frac{a}{u_{x}\\,^{3}}\\frac{\\exp(4a u_{x})-1-4a u_{x}\\exp(2a u_{x})}{\\left(\\exp(2a u_{x})+1\\right)^{2}}\\quad\\mathrm{if}\\;u_{x}\\neq0\\quad\\right.}\\\\ &{\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\left.2a^{4}/3\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\mathrm{if}\\;u_{x}=0\\quad.}\\end{array}\\right.}\\end{array}\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "From this, we obtain the following key relationship: ", "page_idx": 19}, {"type": "equation", "text": "$$\n{\\frac{\\mathbb{E}\\left[c_{x}\\right]}{\\mathbb{E}\\left[t_{x}\\right]}}={\\frac{u_{x}}{a}}=x^{\\top}\\left({\\frac{1}{a}}\\theta^{*}\\right)\\quad{\\mathrm{(restating~eq.~}}(2){\\mathrm{)}}.\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "All these parameters depend solely on the utility difference $u_{x}:=x^{\\top}\\theta^{*}$ and the barrier $a$ . ", "page_idx": 19}, {"type": "text", "text": "C.2 Asymptotic normality of the choice-decision-time estimator for estimating the human preference vector $\\theta^{*}$ ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "We now present the proof of the asymptotic normality result for the choice-decision-time estimator, $\\widehat{\\theta}_{\\mathrm{CH,DT}}$ , as stated in theorem 3.1, which is restated as follows: ", "page_idx": 19}, {"type": "text", "text": "T heorem 3.1 (Asymptotic normality of $\\widehat{\\theta}_{\\mathrm{CH,DT}})$ ). Given an i.i.d. dataset $\\left\\{x,c_{x,s_{x,i}},t_{x,s_{x,i}}\\right\\}_{i\\in[n]}$ for each $x\\in\\mathcal{X}_{s a m p l e}$ , where $\\begin{array}{r}{\\sum_{x\\in\\mathcal{X}_{s a m p l e}}x x^{\\top}\\succ0,}\\end{array}$ , and assuming that the datasets for different $x\\in\\mathcal{X}_{s a m p l e}$ are independent, then, f or any vector $\\boldsymbol{y}\\in\\mathbb{R}^{d}$ , as $n\\to\\infty$ , the following holds: ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\sqrt{n}\\,y^{\\top}\\left(\\widehat{\\theta}_{C H,D T,n}-\\theta^{*}/a\\right)\\xrightarrow{D}\\mathcal{N}(0,\\zeta^{2}/a^{2}).\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "Here, the asymptotic variance depends on a problem-specific constant, $\\zeta^{2}$ , with an upper bounded: ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\zeta^{2}\\leq\\|y\\|_{\\left(\\sum_{x\\in\\mathcal{X}_{s a m p l e}}\\left[\\operatorname*{min}_{x^{\\prime}\\in\\mathcal{X}_{s a m p l e}}\\mathbb{E}[t_{x^{\\prime}}]\\right]\\cdot x x^{\\top}\\right)^{2}}^{2}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "Proof. To simplify notation, we define: ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\widehat{\\mathcal{C}}_{x}=\\frac{1}{n}\\sum_{i=1}^{n}c_{x,s_{x,i}},\\quad\\mathcal{C}_{x}=\\mathbb{E}\\left[c_{x}\\right],\\quad\\widehat{\\mathcal{T}}_{x}=\\frac{1}{n}\\sum_{i=1}^{n}t_{x,s_{x,i}},\\quad\\mathcal{T}_{x}=\\mathbb{E}\\left[t_{x}\\right].\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "For brevity, we abbreviate $\\chi_{\\mathrm{sample}}$ as $\\mathcal{X}$ and $\\widehat{\\theta}_{\\mathrm{CH,DT},n}$ as $\\widehat{\\theta}$ . The estimator $\\widehat{\\theta}$ can be expressed as: ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\widehat{\\theta}=\\left(\\sum_{x^{\\prime}\\in\\mathcal{X}}n x^{\\prime}x^{\\prime}\\top\\right)^{-1}\\sum_{x\\in\\mathcal{X}}n x\\,\\frac{\\widehat{\\mathcal{C}}_{x}}{\\widehat{\\mathcal{T}}_{x}}\\qquad\\mathrm{(restating~eq.~(3))}.\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "We rewrite $\\theta^{*}/a$ as: ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\theta^{*}/a=\\left(\\displaystyle\\sum_{x^{\\prime}\\in\\mathcal{X}}n x^{\\prime}x^{\\prime}^{\\top}\\right)^{-1}\\displaystyle\\sum_{x\\in\\mathcal{X}}n x x^{\\top}\\,\\frac{\\theta^{*}}{a}}\\\\ &{\\qquad=\\,\\left(\\displaystyle\\sum_{x^{\\prime}\\in\\mathcal{X}}n x^{\\prime}x^{\\prime\\top}\\right)^{-1}\\displaystyle\\sum_{x\\in\\mathcal{X}}n x\\,\\frac{\\mathcal{C}_{x}}{\\mathcal{T}_{x}}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "Therefore, for any vector $\\boldsymbol{y}\\in\\mathbb{R}^{d}$ , we have: ", "page_idx": 20}, {"type": "equation", "text": "$$\ny^{\\top}\\left(\\widehat{\\theta}-\\frac{\\theta^{*}}{a}\\right)=y^{\\top}\\left(\\sum_{x^{\\prime}\\in\\mathcal{X}}n x^{\\prime}x^{\\prime^{\\top}}\\right)^{-1}\\sum_{x\\in\\mathcal{X}}n x\\left(\\frac{\\widehat{c}_{x}}{\\widehat{T}_{x}}-\\frac{\\mathcal{C}_{x}}{T_{x}}\\right)=:\\sum_{x\\in\\mathcal{X}}\\xi_{x}\\left(\\frac{\\widehat{c}_{x}}{\\widehat{T}_{x}}-\\frac{\\mathcal{C}_{x}}{T_{x}}\\right),\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "where $\\xi_{x}$ is defined as $\\begin{array}{r}{\\xi_{x}:=y^{\\top}\\left(\\sum_{x^{\\prime}\\in\\mathcal{X}}n x^{\\prime}x^{\\prime\\top}\\right)^{-1}n x}\\end{array}$ . In eq. (9), the only random variables are ${\\widehat{\\mathcal{C}}}_{x}$ and $\\widehat{\\mathcal{T}}_{x}$ . For simplicity, for any $x_{i}\\in\\mathcal{X}:=\\{x_{1},\\cdot\\cdot\\cdot,x_{|\\mathcal{X}|}\\}$ , we slighly abuse the notation and use $\\xi_{i},\\,c_{i},\\,t_{i},\\,\\mathcal{C}_{i},\\,\\mathcal{T}_{i},\\,\\widehat{\\mathcal{C}_{i}}$ and $\\widehat{\\mathcal{T}}_{i}$ denote $\\xi_{x_{i}},c_{x_{i}},t_{x_{i}},\\mathcal{C}_{x_{i}},T_{x_{i}},\\hat{\\mathcal{C}_{x_{i}}},$ , and $\\widehat{\\mathcal{T}}_{x_{i}}$ , respectively. By applying the multidimension al  centr a l limit theorem, we have: ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\sqrt{n}\\left[\\begin{array}{l}{\\widehat{C}_{1}-{C}_{1}}\\\\ {\\widehat{T}_{1}-{C}_{1}}\\\\ {\\vdots}\\\\ {\\widehat{C}_{\\left|x\\right|}-{C}_{\\left|x\\right|}}\\\\ {\\widehat{T}_{\\left|x\\right|}-{C}_{\\left|x\\right|}}\\end{array}\\right]\\xrightarrow{D}{\\mathcal{N}}\\left(0,\\left[\\begin{array}{l l l l}{\\nabla\\left[c_{1}\\right]}&{\\cos\\left[c_{1},t_{1}\\right]}&&\\\\ {\\cot\\left[t_{1},c_{1}\\right]}&&{\\mathbb{V}\\left[t_{1}\\right]}&\\\\ &{\\ddots}&&\\\\ &&{\\mathbb{V}\\left[c_{\\left|x\\right|}\\right]}&{\\cos\\left[c_{\\left|X\\right|},t_{\\left|X\\right|}\\right]}\\end{array}\\right]\\right)}\\\\ &{\\quad\\quad\\times\\left(0,\\mathrm{diag}\\left[\\mathbb{V}\\left[c_{1}\\right],\\mathbb{V}\\left[t_{1}\\right],\\cdots,\\mathbb{V}\\left[c_{\\left|X\\right|}\\right],\\mathbb{V}\\left[t_{\\left|X\\right|}\\right]\\right)\\right).}\\end{array}\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "In the first line of eq. (10), the block-diagonal structure of the covariance matrix emerges because $(\\widehat{\\mathcal{C}}_{i},\\widehat{\\mathcal{T}}_{i})_{i\\in[|\\mathcal{X}_{-}|]}$ are independent of each other. For any fixed $x_{i}$ , to derive the second line of eq. (10), w  e  u se the fact that: ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{E}\\left[t_{i}c_{i}\\right]=\\mathbb{P}\\left(c_{i}=1\\right)\\mathbb{E}\\left[1\\cdot t_{i}|c_{i}=1\\right]+\\mathbb{P}\\left(c_{i}=-1\\right)\\mathbb{E}\\left[-1\\cdot t_{i}|c_{i}=-1\\right]}\\\\ &{\\qquad\\stackrel{(i)}{=}\\left(\\mathbb{P}\\left(c_{i}=1\\right)-\\mathbb{P}\\left(c_{i}=-1\\right)\\right)\\mathbb{E}\\left[t_{i}|c_{i}=1\\right]}\\\\ &{\\qquad\\quad=\\mathbb{E}\\left[c_{i}\\right]\\mathbb{E}\\left[t_{i}\\right],}\\end{array}\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "where $(i)$ is because $\\mathbb{E}\\left[t_{i}|c_{i}=1\\right]=\\mathbb{E}\\left[t_{i}|c_{i}=-1\\right]$ [48, eq. (A.7) and (A.9)]. Therefore, eq. (11) implies that $\\operatorname{cov}(c_{i},t_{i})\\stackrel{}{=}0^{\\frac{1}{2}}$ 3, which justifies the second line of eq. (10). ", "page_idx": 20}, {"type": "text", "text": "Now, let us define the function $\\begin{array}{r}{g(c_{1},t_{1},\\cdot\\cdot\\cdot\\ ,c_{|X|},t_{|X|}):=\\sum_{i\\in[|X|]}\\xi_{i}\\ c_{i}/t_{i}}\\end{array}$ . The gradient of $g$ is: ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\nabla g|_{\\left(c_{1},t_{1},\\cdots,c_{|x|},t_{|x|}\\right)}=\\left[\\xi_{1}/t_{1}\\quad-\\xi_{1}c_{1}/t_{1}^{2}\\quad\\cdot\\cdot\\cdot\\quad\\xi_{|x|}/t_{|x|}\\quad-\\xi_{|x|}c_{|x|}/t_{|x|}^{2}\\right]^{\\top}.\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "Using the multivariate delta method, we obtain: ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\quad\\sqrt{n}\\displaystyle\\sum_{i\\in[1]}\\xi_{i}\\left(\\frac{\\hat{C}_{i}}{\\hat{T}_{i}}-\\frac{c_{i}}{\\hat{T}_{i}}\\right)}\\\\ &{=\\sqrt{n}\\left(g\\left(\\hat{C}_{i},\\hat{T}_{i},\\cdots,\\hat{C}_{\\hat{\\mathcal{N}}_{i}},\\hat{T}_{\\hat{\\mathcal{N}}_{i}}\\right)-g\\left(c_{1},\\hat{T}_{i},\\cdots,c_{\\mathcal{N}_{i}},\\hat{T}_{\\mathcal{N}_{i}}\\right)\\right)}\\\\ &{\\xrightarrow{D}\\displaystyle\\sum_{i\\in\\mathcal{N}_{i}}\\left(0,\\nabla g^{\\mathcal{T}}|_{(c_{1},\\cdots,c_{i},c_{i},T_{\\mathcal{N}_{i}})}\\left[\\begin{array}{c c c}{\\nabla[c_{1}]}&&\\\\ &{\\ddots}&\\\\ &&{\\nabla\\left[c_{\\mathcal{N}_{i}}\\right]}&\\\\ &&\\end{array}\\right]\\nabla g|_{(c_{1},\\cdots,c_{\\mathcal{N}_{i}}]}\\right)}\\\\ &{=N\\left(0,\\displaystyle\\sum_{i\\in[1,1]}\\xi_{i}^{2}\\left(\\frac{1}{\\hat{T}_{i}^{\\mathcal{N}_{i}}}(\\nabla c_{i})+\\frac{C_{i}^{2}}{\\hat{T}_{i}^{\\mathcal{N}_{i}}}(\\ell_{i})\\right)\\right)}\\\\ &{=\\Delta V\\left(0,\\frac{1}{\\alpha^{2}}\\displaystyle\\sum_{i\\in[1,1]}\\xi_{i}^{2}\\left(\\frac{a^{2}}{\\hat{T}_{i}^{\\mathcal{N}_{i}}}(c_{i})+\\frac{a^{2}c_{i}^{2}}{\\hat{T}_{i}^{4}}\\nabla(\\iota_{i})\\right)\\right)}\\end{array}\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "By applying the identities outlined in appendix C.1, we can establish the following identity: ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\forall i\\in[|\\mathcal{X}|]\\colon\\frac{a^{2}}{T_{i}^{2}}\\mathbb{V}(c_{i})+\\frac{a^{2}\\mathcal{C}_{i}^{2}}{T_{i}^{4}}\\mathbb{V}(t_{i})=\\frac{1}{T_{i}}.\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "Substituting this identity into eq. (13), we obtain: ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\sqrt{n}\\sum_{i\\in[|\\mathcal{X}|]}\\xi_{i}\\left(\\frac{\\widehat{\\mathcal{C}_{i}}}{\\widehat{\\mathcal{T}_{i}}}-\\frac{\\mathcal{C}_{i}}{\\mathcal{T}_{i}}\\right)\\overset{D}{\\longrightarrow}\\mathcal{N}\\left(0,\\frac{1}{a^{2}}\\sum_{i\\in[|\\mathcal{X}|]}\\xi_{i}^{2}\\frac{1}{\\mathcal{T}_{i}}\\right).\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "Finally, the asymptotic variance can be upper bounded as follows: ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\quad\\frac{1}{\\alpha^{2}}\\underset{i\\in[\\kappa]\\times1\\atop i\\in[\\kappa]}{\\sum}\\xi_{i}^{2}\\frac{1}{\\mathcal{T}_{i}}}\\\\ &{\\leq\\frac{1}{\\alpha^{2}}\\frac{1}{\\operatorname*{min}_{i\\in[\\kappa]}\\{\\mathcal{T}_{i}\\}}\\underset{\\tau_{i}\\in[\\kappa]}{\\sum}\\xi_{i}^{2}}\\\\ &{=\\frac{1}{\\alpha^{2}}\\frac{1}{\\operatorname*{min}_{i\\in[\\kappa]}\\{\\mathcal{T}_{i}\\}}\\cdot\\left(\\underset{\\tau_{i}\\in\\mathcal{K}}{\\sum}\\left(\\underset{w\\in\\mathcal{K}}{\\sum}w\\tau^{\\prime}\\tau^{\\tau}\\right)^{-1}n^{2}x x^{\\tau}\\left(\\underset{w\\in\\mathcal{K}}{\\sum}n x^{\\tau}x^{\\tau}\\right)^{-1}y\\right)}\\\\ &{=\\frac{1}{\\alpha^{2}}\\frac{1}{\\operatorname*{min}_{i\\in[\\kappa]}\\{\\mathcal{T}_{i}\\}}\\cdot y^{\\tau}\\left(\\underset{w\\in\\mathcal{K}}{\\sum}x^{\\tau}x^{\\tau}\\right)^{-1}y}\\\\ &{=\\frac{1}{\\alpha^{2}}\\frac{y^{\\tau}}{\\operatorname*{min}_{i\\in[\\kappa]}\\{\\mathcal{T}_{i}\\}}\\left[\\underset{\\tau_{i}\\in[\\kappa]}{\\sum}\\left(\\underset{w\\in\\mathcal{K}}{\\sum}x^{\\tau}\\right)^{-1}y\\right.}\\\\ &{\\left.=\\frac{1}{\\alpha^{2}}y^{\\tau}\\left(\\underset{w\\in\\mathcal{K}}{\\sum}\\left[\\underset{w\\in\\mathcal{K}}{\\operatorname*{min}_{i\\in[\\kappa]}\\{\\mathcal{T}_{i}\\}}x^{\\tau}\\tau^{\\tau}\\right)^{-1}y\\right.}\\\\ &{=\\frac{1}{\\alpha^{2}}\\left.\\|y\\|_{\\mathcal{L}\\times\\mathcal{L}}^{2}\\mathrm{exs}[\\underset{w\\in\\mathcal{K}}{\\operatorname*{min}_{i\\in[\\kappa]}\\{\\mathcal{T}_{i}\\}}x^{\\tau}\\tau^{\\tau}]^{-1}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "C.3 Non-asymptotic concentration of the two estimators for estimating the utility difference $u_{x}$ given a query $x$ ", "text_level": 1, "page_idx": 22}, {"type": "text", "text": "C.3.1 The choice-decision-time estimator ", "text_level": 1, "page_idx": 22}, {"type": "text", "text": "Section 3.3 focuses on the problem of estimating the utility difference for a single query. Given a query $x\\in\\mathscr{X}$ , the objective is to estimate the utility difference $u_{x}:=x^{\\top}\\theta^{*}$ using an i.i.d. dataset, denoted by (cx,sx,i, tx,sx,i) i\u2208[n ]. ", "page_idx": 22}, {"type": "text", "text": "We begin by applying the choice-decision-time estimator from eq. (3), which is derived by solving the following least squares problem: ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\widehat{\\theta}_{\\mathrm{CH,DT}}=\\arg\\operatorname*{min}_{\\theta\\in\\mathbb{R}^{d}}\\sum_{x\\in\\mathcal{X}_{\\mathrm{sample}}}\\left(x^{\\top}\\theta-\\frac{\\sum_{i\\in[n_{x}]}c_{x,s_{x,i}}}{\\sum_{i\\in[n_{x}]}t_{x,s_{x,i}}}\\right)^{2}.\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "Similarly, the utility difference for a single query is estimated as the solution to the following least squares problem, yielding the estimate: ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\widehat{u}_{x,\\mathrm{CH},\\mathrm{DT}}=\\underset{u\\in\\mathbb{R}}{\\arg\\operatorname*{min}}\\left(u-\\frac{\\sum_{i\\in[n_{x}]}c_{x,s_{x,i}}}{\\sum_{i\\in[n_{x}]}t_{x,s_{x,i}}}\\right)^{2}=\\frac{\\sum_{i\\in[n_{x}]}c_{x,s_{x,i}}}{\\sum_{i\\in[n_{x}]}t_{x,s_{x,i}}}\\quad(\\mathrm{restating~eq.}\\ (5)),\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "The resulting estimate, $\\widehat{u}_{x,\\mathrm{CH},\\mathrm{DT}}$ , approximates $u_{x}/a$ rather than $u_{x}$ . However, since the ranking of arm utilities is preser v ed between $u_{x}/a$ and $u_{x}$ , estimating $u_{x}/a$ is sufficient for the purpose of best-arm identification. ", "page_idx": 22}, {"type": "text", "text": "For the case where the utility difference $u_{x}\\neq0$ , the non-asymptotic concentration inequality for this estimator is presented in theorem 3.3. To prove this, we first introduce lemma C.1, which demonstrates that for any given query $x$ , the decision time is a sub-exponential random variable. ", "page_idx": 22}, {"type": "text", "text": "To simplify notation, we define: ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\widehat{\\mathcal{C}}_{x}=\\frac{1}{n_{x}}\\sum_{i=1}^{n_{x}}c_{x,s_{x,i}},\\quad\\mathcal{C}_{x}=\\mathbb{E}\\left[c_{x}\\right],\\quad\\widehat{\\mathcal{T}}_{x}=\\frac{1}{n_{x}}\\sum_{i=1}^{n_{x}}t_{x,s_{x,i}},\\quad\\mathcal{T}_{x}=\\mathbb{E}\\left[t_{x}\\right],\\quad\\widehat{u}_{x,\\mathrm{CHJT}}=\\frac{\\widehat{\\mathcal{C}}_{x}}{\\widehat{\\mathcal{T}}_{x}}.\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "Lemma C.1. If $u_{x}\\neq0$ , then $(t_{x}-\\tau_{x})$ is sub-exponential $S E\\left(\\nu_{x}^{2},\\alpha_{x}\\right)$ , where $\\nu_{x}=\\sqrt{2}a/|u_{x}|$ and $\\alpha_{x}=2/u_{x}^{2}$ . ", "page_idx": 22}, {"type": "text", "text": "Proof. For simplicity, we will omit the subscript $x$ throughout the proof and assume, without loss of generality, that $u>0$ . ", "page_idx": 22}, {"type": "text", "text": "Our objective is to establish the following inequality, which holds for all $s\\in(-u^{2}/2,u^{2}/2)$ : ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\mathbb{E}\\left(\\exp\\left(s\\left(t-\\mathcal{T}\\right)\\right)\\right)\\leq\\exp\\left(\\frac{2a^{2}/u^{2}}{2}s^{2}\\right).\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "This implies that $(t-\\tau)$ is sub-exponential SE $\\left(\\nu^{2},\\alpha\\right)$ , as defined by Wainwright [69, Definition 2.7]. ", "page_idx": 22}, {"type": "text", "text": "Step 1: Transform eq. (18) into a more manageable inequality (eq. (24)). ", "text_level": 1, "page_idx": 22}, {"type": "text", "text": "Using Cox [18, eq. (128)], with $\\Delta:=u^{2}-2s$ , $\\theta_{1}:=-u-\\sqrt{\\Delta}$ and $\\theta_{2}:=-u+\\sqrt{\\Delta}$ , we have4: ", "page_idx": 23}, {"type": "equation", "text": "$$\n{\\begin{array}{r l}{\\mathbb{E}\\left(\\exp\\left(x t\\right)\\right)={\\frac{\\exp\\left(a\\theta_{1}\\right)-\\exp\\left(2a\\theta_{2}+a\\theta_{1}\\right)}{\\exp\\left(2a\\theta_{1}\\right)-\\exp\\left(2a\\theta_{2}\\right)}}-{\\frac{\\exp\\left(a\\theta_{2}\\right)-\\exp\\left(2a\\theta_{1}+a\\theta_{2}\\right)}{\\exp\\left(2a\\theta_{1}\\right)-\\exp\\left(2a\\theta_{2}\\right)}}}\\\\ {={\\frac{\\exp\\left(a\\theta_{1}\\right)\\left[1+\\exp\\left(a\\theta_{1}+a\\theta_{2}\\right)\\right]}{\\exp\\left(2a\\theta_{1}\\right)-\\exp\\left(2a\\theta_{2}\\right)}}-{\\frac{\\exp\\left(a\\theta_{2}\\right)\\left[1+\\exp\\left(a\\theta_{2}+a\\theta_{1}\\right)\\right]}{\\exp\\left(2a\\theta_{1}\\right)-\\exp\\left(2a\\theta_{2}\\right)}}}\\\\ {={\\frac{\\exp\\left(a\\theta_{1}\\right)-\\exp\\left(a\\theta_{2}\\right)\\left[1+\\exp\\left(a\\theta_{2}+a\\theta_{1}\\right)\\right]}{\\exp\\left(2a\\theta_{1}\\right)-\\exp\\left(2a\\theta_{2}\\right)}}}\\\\ {={\\frac{1+\\exp\\left(a\\theta_{2}+a\\theta_{1}\\right)}{\\exp\\left(a\\theta_{1}\\right)+\\exp\\left(a\\theta_{2}\\right)}}}\\\\ {={\\frac{1+\\exp\\left(a\\theta_{2}+a\\theta_{1}\\right)}{\\exp\\left(a\\theta_{1}\\right)+\\exp\\left(a\\theta_{2}\\right)}}}\\\\ {={\\frac{\\exp\\left(-a\\theta\\right)+\\exp\\left(a\\theta\\right)}{\\exp\\left(-a\\theta\\right)+\\exp\\left(a\\theta\\right)}}}\\\\ {={\\frac{\\exp\\left(-a\\psi\\right)}{\\exp\\left(-a\\psi\\right)}}+\\exp\\left(a\\psi\\overline{{\\Delta}}\\right)}\\\\ {={\\frac{N}{2}}.}\\end{array}}\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "In the last line, we define $N=2\\cosh(a u)$ and $D(s)=2\\cosh(a\\sqrt{\\Delta})$ . Thus, we arrive at: ", "page_idx": 23}, {"type": "equation", "text": "$$\n\\mathbb{E}\\left(\\exp\\left(s\\cdot(t-\\mathcal{T})\\right)\\right)=\\frac{N}{D(s)}\\cdot\\frac{1}{\\exp\\left(s\\cdot\\mathcal{T}\\right)}=\\frac{N}{\\exp\\left(s a\\operatorname{tanh}(a u)/u\\right)D(s)}.\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "To prove the original inequality in eq. (18), it is now sufficient to show: ", "page_idx": 23}, {"type": "equation", "text": "$$\nD(s)\\cdot\\exp\\left({\\frac{a}{u}}\\operatorname{tanh}(a u)s+{\\frac{a^{2}}{u^{2}}}s^{2}\\right)\\geq N.\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "For $s=0$ , the inequality holds trivially, as: ", "page_idx": 23}, {"type": "equation", "text": "$$\nD(0)\\cdot1=2\\cosh(a u)=N.\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "For $s\\neq0$ , taking the derivative of the left-hand side of eq. (21) yields: ", "page_idx": 23}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\displaystyle\\frac{\\mathrm{d}}{\\mathrm{d}s}\\left(D(s)\\cdot\\exp\\left(\\frac{a}{u}\\operatorname{tanh}(a u)s+\\frac{a^{2}}{u^{2}}s^{2}\\right)\\right)}\\\\ &{=\\displaystyle\\exp\\left(\\frac{a}{u}\\operatorname{tanh}(a u)s+\\frac{a^{2}}{u^{2}}s^{2}\\right)\\cdot\\left(-\\frac{2a}{\\sqrt{\\Delta}}\\sinh\\left(a\\sqrt{\\Delta}\\right)+2\\cosh\\left(a\\sqrt{\\Delta}\\right)\\cdot\\left(\\frac{a}{u}\\operatorname{tanh}(a u)+2\\frac{a^{2}}{u^{2}}s\\right)\\right)}\\\\ &{=2\\exp\\left(\\frac{a}{u}\\operatorname{tanh}(a u)s+\\frac{a^{2}}{u^{2}}s^{2}\\right)\\cosh\\left(a\\sqrt{\\Delta}\\right)\\cdot\\left(-\\frac{a}{\\sqrt{\\Delta}}\\operatorname{tanh}\\left(a\\sqrt{\\Delta}\\right)+\\frac{a}{u}\\operatorname{tanh}(a u)+2\\frac{a^{2}}{u^{2}}s\\right).}\\end{array}\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "In step 2, we will prove the following inequality: ", "page_idx": 23}, {"type": "equation", "text": "$$\n-\\frac{a}{\\sqrt{\\Delta}}\\operatorname{tanh}\\left(a\\sqrt{\\Delta}\\right)+\\frac{a}{u}\\operatorname{tanh}(a u)+2\\frac{a^{2}}{u^{2}}s\\left\\{\\begin{array}{l l}{\\ge0,}&{\\forall s\\ge0,}\\\\ {<0,}&{\\forall s<0,}\\end{array}\\right.\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "Equation (24) implies that $\\begin{array}{r}{D(s)\\cdot\\exp\\left({\\frac{a}{u}\\operatorname{tanh}(a u)s+\\frac{a^{2}}{u^{2}}s^{2}}\\right)\\geq N}\\end{array}$ , which finishes the proof. ", "page_idx": 23}, {"type": "text", "text": "Step 2. Prove eq. (24). ", "text_level": 1, "page_idx": 23}, {"type": "text", "text": "For $s\\geq0$ , the following holds: ", "page_idx": 24}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\quad-\\frac{a}{\\sqrt{\\Delta}}\\operatorname{tanh}\\left(a\\sqrt{\\Delta}\\right)+\\frac{a}{u}\\operatorname{tanh}(a u)+2\\frac{a^{2}}{u^{2}}s}\\\\ &{\\stackrel{{(i)}}{\\geq}a\\operatorname{tanh}\\left(a\\sqrt{\\Delta}\\right)\\left(\\frac{1}{u}-\\frac{1}{\\sqrt{\\Delta}}\\right)+2\\frac{a^{2}}{u^{2}}s}\\\\ &{=a\\operatorname{tanh}\\left(a\\sqrt{\\Delta}\\right)\\frac{-2s}{u\\sqrt{\\Delta}}\\frac{1}{\\sqrt{\\Delta}\\left(\\sqrt{\\Delta}+u\\right)}+2\\frac{a^{2}}{u^{2}}s}\\\\ &{=-2s\\cdot\\frac{a^{2}}{u}\\cdot\\frac{\\operatorname{tanh}\\left(a\\sqrt{\\Delta}\\right)}{a\\sqrt{\\Delta}+u}+\\frac{\\operatorname{tanh}\\left(a\\sqrt{\\Delta}\\right)}{a\\sqrt{\\Delta}}+2\\frac{a^{2}}{u^{2}}s}\\\\ &{\\stackrel{{(i i)}}{\\geq}-2s\\frac{a^{2}}{u^{2}}\\cdot1+2\\frac{a^{2}}{u^{2}}s}\\\\ &{=0.}\\end{array}\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "Here, $(i)$ follows from $\\operatorname{tanh}(a u)~\\geq~\\operatorname{tanh}(a{\\sqrt{\\Delta}})~=~\\operatorname{tanh}(a{\\sqrt{u^{2}-2s}})$ and $(i i)$ follows from $\\operatorname{tanh}(x)/x\\leq1$ . ", "page_idx": 24}, {"type": "text", "text": "For $s<0$ , the following holds: ", "page_idx": 24}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathrm{~\\\\\\\\\\}-\\frac{a}{\\sqrt{\\Delta}}\\operatorname{tanh}\\left(a\\sqrt{\\Delta}\\right)+\\frac{a}{u}\\operatorname{tanh}(a u)+2\\frac{a^{2}}{u^{2}}s}\\\\ &{\\stackrel{{(i)}}{\\leq}a\\operatorname{tanh}\\left(a\\sqrt{\\Delta}\\right)\\left(\\frac{1}{u}-\\frac{1}{\\sqrt{\\Delta}}\\right)+2\\frac{a^{2}}{u^{2}}s}\\\\ &{=\\,-\\,2s\\cdot\\frac{a^{2}}{u\\,\\left(\\sqrt{\\Delta}+u\\right)}\\cdot\\frac{\\operatorname{tanh}\\left(a\\sqrt{\\Delta}\\right)}{a\\sqrt{\\Delta}}+2\\frac{a^{2}}{u^{2}}s}\\\\ &{\\stackrel{{(i i)}}{\\leq}-2s\\frac{a^{2}}{u^{2}}\\cdot1+2\\frac{a^{2}}{u^{2}}s}\\\\ &{=\\,0.}\\end{array}\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "Here, $(i)$ follows from $\\operatorname{tanh}(a u)~\\leq~\\operatorname{tanh}(a{\\sqrt{\\Delta}})~=~\\operatorname{tanh}(a{\\sqrt{u^{2}-2s}})$ and $(i i)$ follows from $\\operatorname{tanh}(x)/x\\leq1$ . ", "page_idx": 24}, {"type": "text", "text": "By combining both cases, we conclude that the inequality in eq. (24) holds, which completes Step 2 and proves the desired result. \u53e3 ", "page_idx": 24}, {"type": "text", "text": "Next, we prove theorem 3.3, which provides the non-asymptotic concentration inequality for the estimator from eq. (5), restated as follows: ", "page_idx": 24}, {"type": "text", "text": "Theorem 3.3 (Non-asymptotic concentration of $\\widehat{u}_{x,\\mathrm{CH},\\mathrm{DT}})$ . For each query $x\\in\\textbf{\\textit{x}}$ with $u_{x}\\quad\\neq\\ \\ 0,$ , given an i.i.d. dataset $\\left\\{\\left(c_{x,s_{x,i}},t_{x,s_{x,i}}\\right)\\right\\}_{i\\in[n_{x}]},$ for any $\\epsilon\\mathrm{~\\ensuremath~{~>~0~}~}$ satisfying $\\textup{\\epsilon}\\leq$ $\\operatorname*{min}\\left\\{|u_{x}|/(\\sqrt{2}a),\\big(1+\\sqrt{2}\\big)\\,a|u_{x}|/\\mathbb{E}\\left[t_{x}\\right]\\right\\}$ , the following holds: ", "page_idx": 24}, {"type": "equation", "text": "$$\n\\begin{array}{c}{\\displaystyle\\mathbb{P}\\left(\\left|\\widehat{u}_{x,C H,D T}-\\frac{u_{x}}{a}\\right|>\\epsilon\\right)\\leq4\\exp\\left(-\\left[m_{C H,D T}^{n o n\\cdot a s y m}\\left(x^{\\top}\\theta^{*}\\right)\\right]^{2}\\,n_{x}\\,\\left[\\epsilon\\cdot a\\right]^{2}\\right),}\\\\ {\\displaystyle\\imath_{C H,D T}^{n o n\\cdot a s y m}\\left(x^{\\top}\\theta^{*}\\right):=\\mathbb{E}\\left[t_{x}\\right]\\,/\\,\\left[\\left(2+2\\sqrt{2}\\right)a\\right]\\!.}\\end{array}\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "Proof. For clarity, we will omit the subscripts $x$ throughout this proof. Based on lemma C.1, we define the constants $\\nu:=\\sqrt{2}a/|u|$ and $\\alpha:=2/u^{2}$ . ", "page_idx": 24}, {"type": "text", "text": "We begin by introducing $\\epsilon_{\\mathcal{C}}:=\\mathcal{T}/\\left(\\sqrt{2}+\\sqrt{2}\\nu|\\mathcal{C}|/\\mathcal{T}\\right)\\cdot\\epsilon$ and $\\epsilon_{T}:=\\nu\\epsilon_{C}$ . From the identities provided in appendix C.1, we know that $\\nu|\\mathcal{C}|/\\mathcal{T}=\\sqrt{2}a/|\\boldsymbol{u}|\\cdot|\\boldsymbol{u}|/a=\\sqrt{2}$ . This allows us to simplify the constants $\\epsilon_{\\mathcal{C}}$ and $\\epsilon_{T}$ as: ", "page_idx": 24}, {"type": "equation", "text": "$$\n\\epsilon_{C}=\\frac{\\mathcal{T}}{\\sqrt{2}\\left(\\sqrt{2}+1\\right)}\\epsilon\\quad\\mathrm{and}\\quad\\epsilon_{\\mathcal{T}}=\\frac{\\nu\\mathcal{T}}{\\sqrt{2}\\left(\\sqrt{2}+1\\right)}\\epsilon.\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "For any $\\epsilon$ satisfying the following condition: ", "page_idx": 25}, {"type": "equation", "text": "$$\n\\epsilon\\leq\\operatorname*{min}\\left\\{\\frac{1}{\\nu},\\frac{\\sqrt{2}(1+\\sqrt{2})\\nu}{\\alpha T}\\right\\},\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "we observe that $\\epsilon_{\\mathcal{T}}<\\operatorname*{min}{\\left\\{\\mathcal{T}(1-1/\\sqrt{2}),\\nu^{2}/\\alpha\\right\\}}$ . We can now apply lemma C.2 to derive the following: ", "page_idx": 25}, {"type": "equation", "text": "$$\n\\mathbb{P}\\left(\\left|\\widehat{\\mathcal{T}}-\\mathcal{T}\\right|>\\epsilon_{\\mathcal{T}}\\right)\\leq2\\exp\\left(-\\frac{n\\epsilon_{\\mathcal{T}}^{2}}{2\\nu^{2}}\\right).\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "Thus, by combining the results, we conclude: ", "page_idx": 25}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{P}\\left(\\left|\\left(\\frac{\\hat{C}}{\\hat{T}}-\\frac{c}{T}\\right|>\\epsilon\\right)=\\mathbb{P}\\left(\\left|\\frac{\\hat{C}}{\\hat{T}}-\\frac{c}{T}\\right|>\\sqrt{2}\\frac{\\epsilon c+\\epsilon_{T}\\cdot|C|/T}{T}\\right)}\\\\ &{\\quad\\quad\\quad\\quad\\quad\\quad\\overset{(i)}{\\leq}\\mathbb{P}\\left(\\left|\\hat{\\mathcal{L}}-C\\right|>\\epsilon c\\right)+\\mathbb{P}\\left(\\left|\\hat{T}-T\\right|>\\epsilon_{T}\\right)}\\\\ &{\\quad\\quad\\quad\\quad\\quad\\overset{(i i)}{\\leq}2\\exp\\left(-\\frac{n\\epsilon_{T}^{2}}{2}\\right)+2\\exp\\left(-\\frac{n\\epsilon_{T}^{2}}{2\\nu^{2}}\\right)}\\\\ &{\\quad\\quad\\quad\\quad\\quad\\overset{(i i i)}{=}4\\exp\\left(-\\frac{n\\epsilon_{T}^{2}}{2}\\right)}\\\\ &{\\quad\\quad\\quad\\quad=4\\exp\\left(-\\frac{T^{2}}{4}\\right)^{2}}\\end{array}\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "Here, $(i)$ follows from lemma C.3, $(i i)$ uses lemma C.2 and eq. (29), and $(i i i)$ follows from eq. (27). ", "page_idx": 25}, {"type": "text", "text": "Supporting Details ", "text_level": 1, "page_idx": 25}, {"type": "text", "text": "Lemma C.2. For each query $x$ with $u_{x}\\ne0_{\\!\\;}$ , and constants $\\epsilon_{\\mathscr{C}}\\;>\\;0$ and $\\epsilon_{T}\\,\\in\\,(0,\\nu_{x}^{2}/\\alpha_{x}]$ , the following inequalities hold: ", "page_idx": 25}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathbb{P}\\left(\\left|\\widehat{\\mathcal{C}}_{x}-\\mathcal{C}_{x}\\right|\\geq\\epsilon c\\right)\\leq2\\exp\\left(-\\frac{n\\epsilon_{C}^{2}}{2}\\right),\\quad\\mathbb{P}\\left(\\left|\\widehat{\\mathcal{T}}_{x}-\\mathcal{T}_{x}\\right|\\geq\\epsilon_{T}\\right)\\leq2\\exp\\left(-\\frac{n\\epsilon_{T}^{2}}{2\\nu_{x}^{2}}\\right).}\\end{array}\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "Here, the constants are $\\nu_{x}:=\\sqrt{2}a/|u_{x}|$ and $\\alpha_{x}:=2/u_{x}^{2}$ . ", "page_idx": 25}, {"type": "text", "text": "Proof. Since $c_{x}\\in\\{-1,1\\}$ , by applying Hoeffding\u2019s inequality [69, proposition 2.5], we obtain: ", "page_idx": 25}, {"type": "equation", "text": "$$\n\\mathbb{P}\\left(\\left|\\widehat{C}_{x}-\\mathcal{C}_{x}\\right|\\geq\\epsilon_{\\mathcal{C}}\\right)\\leq2\\exp\\left(-\\frac{n\\epsilon_{\\mathcal{C}}^{2}}{2}\\right).\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "From lemma C.1, we know that $t_{x}$ is sub-exponential $S E(\\nu_{x}^{2},\\alpha_{x})$ . By applying Wainwright [69, proposition 2.9 and eq. (2.18)], we obtain: ", "page_idx": 25}, {"type": "equation", "text": "$$\n\\mathbb{P}\\left(\\left\\lvert\\widehat{\\mathcal{T}}_{x}-\\mathcal{T}_{x}\\right\\rvert\\geq\\epsilon_{\\mathcal{T}}\\right)\\leq2\\exp\\left(-\\frac{n\\epsilon_{\\mathcal{T}}^{2}}{2\\nu_{x}^{2}}\\right),\\quad\\forall\\epsilon_{\\mathcal{T}}\\in(0,\\nu_{x}^{2}/\\alpha_{x}].\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "Lemma C.3. Consider constants ${\\mathcal{C}}\\in\\mathbb{R}_{}$ , $\\tau>0,$ , $\\epsilon_{\\mathscr{C}}>0,$ , and $\\epsilon_{\\mathcal{T}}\\in\\left(0,(1-1/\\sqrt{2})\\mathcal{T}\\right)$ . For any $\\widehat{\\mathcal{C}}\\in[\\mathcal{C}-\\epsilon_{\\mathcal{C}},\\mathcal{C}+\\epsilon_{\\mathcal{C}}]$ and $\\widehat{\\mathcal{T}}\\in[\\mathcal{T}-\\epsilon_{T},\\mathcal{T}+\\epsilon_{T}]$ , the following inequality holds ", "page_idx": 25}, {"type": "equation", "text": "$$\n\\left|\\frac{\\widehat{c}}{\\widehat{T}}-\\frac{\\mathcal{C}}{\\mathcal{T}}\\right|\\leq\\sqrt{2}\\frac{\\epsilon\\mathcal{C}+\\epsilon\\mathcal{T}\\cdot|\\mathcal{C}|/\\mathcal{T}}{T}.\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "Proof. The maximum value of $|\\hat{c}/\\hat{T}-\\mathcal{C}/\\mathcal{T}|$ is attained at the extremum of $\\widehat{\\mathcal{C}}/\\widehat{\\mathcal{T}}$ . Since $\\widehat{\\mathcal{C}}/\\widehat{\\mathcal{T}}$ is linear in $\\widehat{\\mathcal{C}}_{}$ , the extremum of $\\widehat{\\mathcal{C}}/\\widehat{\\mathcal{T}}$ is at t ain ed at $C^{*}\\in\\{\\mathcal{C}-\\epsilon_{\\mathcal{C}},\\mathcal{C}+\\epsilon_{\\mathcal{C}}\\}$ for any $\\widehat{\\mathcal{T}}\\in[\\mathcal{T}-\\epsilon_{\\mathcal{T}},\\mathcal{T}+\\epsilon_{\\mathcal{T}}]>0$ . Gi v en that $\\widehat{\\tau}>0$ , th e  ex tremum of $C^{*}/\\widehat{\\mathcal{T}}$ is attained at $T^{*}\\in\\{T-\\epsilon_{T},T+\\epsilon_{T}\\}$ . Therefore, the extremum  o f $\\widehat{\\mathcal{C}}/\\widehat{\\mathcal{T}}$ lies in the set: ", "page_idx": 26}, {"type": "equation", "text": "$$\n\\operatorname*{max}_{\\hat{\\mathcal{T}}\\in[\\mathcal{C}-\\epsilon_{c},\\mathcal{C}+\\epsilon_{c}]}\\;\\frac{\\hat{\\mathcal{C}}}{\\hat{\\mathcal{T}}}\\in\\left\\{\\frac{\\mathcal{C}-\\epsilon_{c}}{\\mathcal{T}-\\epsilon_{\\mathcal{T}}},\\quad\\frac{\\mathcal{C}-\\epsilon_{c}}{\\mathcal{T}+\\epsilon_{\\mathcal{T}}},\\quad\\frac{\\mathcal{C}+\\epsilon_{c}}{\\mathcal{T}-\\epsilon_{\\mathcal{T}}},\\quad\\frac{\\mathcal{C}+\\epsilon_{c}}{\\mathcal{T}+\\epsilon_{\\mathcal{T}}}\\right\\}.\n$$", "text_format": "latex", "page_idx": 26}, {"type": "text", "text": "For any combination $(s c,s\\tau)\\in\\{\\pm1\\}\\times\\{\\pm1\\}$ , and using the function $\\epsilon_{T}\\leq(1-1/\\sqrt{2})T$ , we have: ", "page_idx": 26}, {"type": "equation", "text": "$$\n\\left|\\frac{\\mathcal{C}+s\\varsigma\\epsilon\\varsigma}{T+s\\tau\\epsilon\\tau}-\\frac{\\mathcal{C}}{T}\\right|=\\left|\\frac{s\\varsigma\\epsilon\\varsigma T-s\\gamma\\epsilon\\gamma\\mathcal{C}}{T\\left(T+s\\gamma\\epsilon\\gamma\\right)}\\right|\\leq\\frac{\\epsilon\\varsigma T+\\epsilon\\gamma|\\mathcal{C}|}{T\\left(T-\\epsilon\\gamma\\right)}\\leq\\sqrt{2}\\frac{\\epsilon\\varsigma T+\\epsilon\\gamma|\\mathcal{C}|}{T^{2}}.\n$$", "text_format": "latex", "page_idx": 26}, {"type": "text", "text": "By combining these results, we conclude that: ", "page_idx": 26}, {"type": "equation", "text": "$$\n\\operatorname*{max}_{\\hat{\\mathcal{C}}\\in[\\mathcal{C}-\\epsilon_{c},\\mathcal{C}+\\epsilon_{c}]}\\left|\\frac{\\widehat{\\mathcal{C}}}{\\widehat{\\mathcal{T}}}-\\frac{\\mathcal{C}}{\\mathcal{T}}\\right|=\\operatorname*{max}_{\\substack{(s_{c},s_{T})\\in\\{\\pm1\\}\\times\\{\\pm1\\}}}\\left|\\frac{\\mathcal{C}+s_{C}\\epsilon_{C}}{\\mathcal{T}+s_{T}\\epsilon_{T}}-\\frac{\\mathcal{C}}{\\mathcal{T}}\\right|\\leq\\sqrt{2}\\frac{\\epsilon_{C}+\\epsilon_{T}|\\mathcal{C}|/\\mathcal{T}}{\\mathcal{T}}.\n$$", "text_format": "latex", "page_idx": 26}, {"type": "text", "text": "C.3.2 The choice-only estimator ", "text_level": 1, "page_idx": 26}, {"type": "text", "text": "We now apply the logistic-regression-based choice-only estimator from eq. (4) to estimate the utility difference for a single query. Recall that for each query $x\\in\\mathscr{X}$ , the human choice $c_{x}\\in\\{-1,1\\}$ . We define the binary-encoded choice as $e_{x}:=\\left(c_{x}+\\bar{1}\\right)/\\bar{2}\\in\\{0,1\\}$ . We reformulate the MLE in eq. (4) into a utility difference estimation problem for a single query, leading to the following optimization problem: ", "page_idx": 26}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\widehat{u}_{x,\\mathrm{CH}}=\\underset{u\\in\\mathbb{R}}{\\arg\\operatorname*{max}}\\displaystyle\\sum_{i\\in[n_{x}]}\\log\\mu(c_{x,s_{x,i}}\\,u)}\\\\ &{\\qquad=\\underset{u\\in\\mathbb{R}}{\\arg\\operatorname*{max}}\\displaystyle\\sum_{i\\in[n_{x}]}\\log\\Big[(\\mu(u))^{e_{x,s_{x,i}}}\\cdot(\\mu(-u))^{1-e_{x,s_{x,i}}}\\Big]\\,.}\\end{array}\n$$", "text_format": "latex", "page_idx": 26}, {"type": "text", "text": "The first-order optimality condition provides the optimal solution: ", "page_idx": 26}, {"type": "equation", "text": "$$\n\\widehat{u}_{x,\\mathrm{CH}}=\\mu^{-1}\\left(\\frac{1}{n_{x}}\\sum_{i\\in[n_{x}]}e_{x,s_{x,i}}\\right)\\quad\\mathrm{(restating~eq.~}(6)),\n$$", "text_format": "latex", "page_idx": 26}, {"type": "text", "text": "where $\\mu^{-1}(p):=\\log{(p/(1-p))}$ is the logit function (also known as the log-odds), defined as the inverse of the function $\\mu(\\cdot)$ introduced in eq. (4). ", "page_idx": 26}, {"type": "text", "text": "The resulting estimate, $\\widehat{u}_{x,\\mathrm{CH}}$ , from eq. (6) gives an estimate of $2a u_{x}$ , not $u_{x}$ . However, since the ranking of arm utilities   based on $2a u_{x}$ is the same as that based on the true $u_{x}$ , estimating $2a u_{x}$ suffices for identifying the best arm. ", "page_idx": 26}, {"type": "text", "text": "The non-asymptotic concentration inequality for this estimator is stated in theorem 3.4. This result is directly adapted from Jun et al. [31, theorem 5], by letting $x_{1}=\\cdot\\cdot\\cdot=x_{t}=1$ and $t_{\\mathrm{eff}}=d=1$ . ", "page_idx": 26}, {"type": "text", "text": "D Experiment details ", "text_level": 1, "page_idx": 27}, {"type": "text", "text": "Our empirical experiments (Sec. 5) were conducted on a MacBook Pro (M3 Pro, Nov 2023) with 36 GB of memory. ", "page_idx": 27}, {"type": "text", "text": "Our implementation of algorithm 1 is done in Julia, building on the implementation of Tirinzoni and Degenne [63], where the transductive and hard-query designs are solved using the Frank\u2013Wolfe algorithm [24]. Their implementation is available at https://github.com/AndreaTirinzoni/ bandit-elimination. The simulation and Bayesian inference for DDM are implemented using the Julia package SequentialSamplingModels. $\\mathrm{j}2$ at https://itsdfish.github.io/ SequentialSamplingModels.jl/dev/#SequentialSamplingModels. $\\mathrm{j}2$ . ", "page_idx": 27}, {"type": "text", "text": "For a query $x\\in\\mathscr{X}$ , the estimators from Wagenmakers et al. [67] and Xiang Chiong et al. [73], anawhere \u00b5\u22121(\u00b7) is the logit function and p := 1/nx \u00b7 in=x1 cx,sx,i + 1 /2 represents the em p\u2212irical lyzed in section 3.3 and benchmarked in section 5.2, require calculating $\\mu^{-\\overline{{1}}}(p):=\\log{(p/(1-p))}$ , undefined, we follow Wagenmakers et al. [67, the discussion below fig. 6] and approximate $p$ as $1-1/(2n_{x})$ when $p=1$ and $1/(2n_{x})$ when $p=0$ . ", "page_idx": 27}, {"type": "text", "text": "D.1 Processing the food-risk dataset with choices (-1 or 1) [57] ", "text_level": 1, "page_idx": 28}, {"type": "text", "text": "We accessed the food-risk dataset with choices (-1 or 1) [57] through Yang and Krajbich [76]\u2019s repository $(\\mathrm{https}\\,{:}//\\mathrm{osf}\\,\\cdot\\,\\mathrm{i}\\,\\circ/\\mathrm{d}7\\,\\mathsf{s}6\\,\\mathsf{c}/)$ . This dataset includes the choices and response times of 42 participants, each responding to between 60 and 200 queries. Each query compares two arms, with each arm containing two food items. By selecting an arm, participants had an equal chance of receiving either food item, hence the name \u201cfood risk\u201d (or \u201cfood-gamble\u201d) task. Additionally, participants\u2019 eye movements were tracked during the experiment. Yang and Krajbich [76] modeled each participant\u2019s choices, response times, and eye movements using the attentional DDM [39], where the drift for each query is a linear combination of the participant\u2019s ratings of the four food items in the query, with the weights adjusting based on their eye movements. The ratings, $\\in$ $\\{-10,-9,\\ldots,0,\\dot{\\ldots},9,10\\}$ , were collected before the participants interacted with the binary queries. ", "page_idx": 28}, {"type": "text", "text": "In our work, for each participant, we define each arm\u2019s feature vector as the participant\u2019s ratings of the two corresponding food items, augmented with second-order polynomials. We fti each participant\u2019s data to a difference-based EZ-diffusion model [8, 67] with a linear utility structure, as introduced in section 2. For each participant, using Bayesian inference with non-informative priors [16], we estimated the preference vector $\\theta^{*}\\in\\mathbb{R}^{5}$ , non-decision time $t_{\\mathrm{nondec}}$ , and barrier $a$ . Across participants, the barrier $a$ ranged from 0.715 to 2.467, with a mean of 1.437, and $t_{\\mathrm{nondec}}$ ranged from 0.206 to 1.917 seconds, with a mean of 0.746 seconds. This procedure generated one bandit instance per participant, with a preference vector $\\theta^{*}\\in\\mathbb{R}^{5}$ , an arm space $\\mathcal{Z}\\ \\breve{\\subset}\\ \\mathbb{R}^{5}$ where $|\\mathcal{Z}|\\in[31,95]$ , and a query space $\\mathcal{X}:=\\bar{\\{\\boldsymbol{z}-\\boldsymbol{z}^{\\prime}\\colon\\boldsymbol{z}\\in\\mathcal{Z}\\}}$ . Then, we used the ftited models to simulate human feedback for bandit experiments. ", "page_idx": 28}, {"type": "text", "text": "For each bandit instance, we benchmarked six GSE variations (introduced in section 5.2): $(\\lambda_{\\mathrm{trans}},\\widehat{\\theta}_{\\mathrm{CH,DT}})$ , $(\\lambda_{\\mathrm{trans}},\\widehat{\\theta}_{\\mathrm{CH},\\mathbb{R}\\mathbb{T}})$ , $(\\lambda_{\\mathrm{trans}},\\widehat{\\theta}_{\\mathrm{CH}})$ , $(\\lambda_{\\mathrm{hard}},\\widehat{\\theta}_{\\mathrm{CH}})$ , $(\\lambda_{\\mathrm{trans}},\\widehat{\\theta}_{\\mathrm{CH,logit}})$ , and $(\\lambda_{\\mathrm{{trans}}},\\widehat{\\theta}_{\\mathrm{{CH},\\mathrm{{DT},\\mathrm{{logit}}}}})$ . For ea c h GSE variation ,  we ran 300 rep e ated simulat i ons under dif f erent random seeds,  w ith human choices and response times sampled from the dEZDM with the identified parameters. Since each bandit instance contains a different number of arms, rather than tuning the elimination parameter $\\eta$ in algorithm 1 for each instance, we set $\\eta=2$ , following the convention in previous bandit research, e.g., Azizi et al. [3, section 3]. We manually tuned the buffer size $B_{\\mathrm{buff}}$ in algorithm 1 to 20, 30, or 50 seconds based on empirical performance, ensuring the budget was not exceeded in each phase. The full results are shown in fig. 5, with selected results highlighted in fig. 4a. ", "page_idx": 28}, {"type": "image", "img_path": "aIPwlkdOut/tmp/fb8b5807f438fb96f75d7d8a37ff0e9e7ca955a6020762f7e2ab73751e9a0e52.jpg", "img_caption": ["Figure 5: A violin plot overlaid with a box plot showing the best-arm identification error probability, $\\mathbb{P}\\left[\\widehat{z}\\neq z^{*}\\right]$ , as a function of budget for each GSE variation, simulated using the food-risk dataset with cho ices (-1 or 1) [57], as described in appendix D.1. The box plots follow the convention of the matplotlib Python package. For each GSE variation and budget, the horizontal line in the middle of the box represents the median of the error probabilities across all bandit instances. Each error probability is averaged over 300 repeated simulations under different random seeds. The box\u2019s upper and lower borders represent the third and first quartiles, respectively, with whiskers extending to the farthest points within $1.5\\times$ the interquartile range. Flier points indicate outliers beyond the whiskers. "], "img_footnote": [], "page_idx": 28}, {"type": "text", "text": "D.2 Processing the snack dataset with choices (yes or no) [16] ", "text_level": 1, "page_idx": 29}, {"type": "text", "text": "We accessed the snack dataset with choices (yes or no) [16] through the supplementary material provided by Al\u00f3s-Ferrer et al. [2] at https://www.journals.uchicago.edu/doi/abs/10.1086/ 713732. This dataset consists of training and testing data. The training data was collected from a \u201cYN\u201d task, where 31 participants provided binary feedback (\u201cYes\u201d or \u201cNo\u201d) and response times for queries comparing each of the 17 snack items to a fixed reference snack, with each query repeated 10 times. The reference snack, assigned a utility of 0, remained fixed throughout the experiment. The testing data was collected using a two-alternative forced-choice task, where participants provided binary choices and response times for queries comparing two snack items, with each query repeated once. Clithero [16] fit a difference-based EZ-diffusion model [8, 67] to the training data using Bayesian inference with non-informative priors, without imposing a linear utility structure, and tested the model using the testing data. ", "page_idx": 29}, {"type": "text", "text": "In our work, we fit each participant\u2019s training data to a difference-based EZ-diffusion model with a linear utility structure, as described in section 2, and used the fitted model to simulate human feedback for bandit experiments. We preprocessed the data by removing outliers, following Clithero [16, footnote 22], excluding trials with response times below $200\\;\\mathrm{ms}$ or greater than five standard deviations above the mean. After cleaning, the number of trials per participant ranged from 167 to 170. Since the dataset does not provide feature vectors for the 17 non-reference snack items, we used one-hot encoding to represent each snack item as a feature vector in $\\mathbb{R}^{17}$ . This allowed us to construct a bandit instance for each participant with a preference vector $\\theta^{*}\\in\\mathbb{R}^{17}$ , an arm space $\\mathcal{Z}\\subset\\mathbb{R}^{17}$ with $|\\mathcal{Z}|=17$ , and a query space $\\bar{\\boldsymbol{\\chi}}:=\\{\\boldsymbol{z}-\\bar{\\mathbf{0}_{:}}\\,\\boldsymbol{z}\\in\\mathcal{Z}\\}$ to represent comparisons with the reference snack. We applied Bayesian inference with non-informative priors [16] to estimate each participant\u2019s preference vector $\\theta^{*}$ , non-decision time $t_{\\mathrm{nondec}}$ , and barrier $a$ . Across participants, the barrier $a$ ranged from 0.759 to 1.399, with a mean of 1.1, and $t_{\\mathrm{nondec}}$ ranged from 0.139 to 0.485 seconds, with a mean of 0.367 seconds. ", "page_idx": 29}, {"type": "text", "text": "For each of the six GSE variations (introduced in section 5.2): $(\\lambda_{\\mathrm{trans}},\\widehat{\\theta}_{\\mathrm{CH,DT}})$ , $(\\lambda_{\\mathrm{trans}},\\widehat{\\theta}_{\\mathrm{CH},\\mathbb{R}\\mathbb{T}})$ , $(\\lambda_{\\mathrm{trans}},\\widehat{\\theta}_{\\mathrm{CH}})$ , $(\\lambda_{\\mathrm{hard}},\\widehat{\\theta}_{\\mathrm{CH}})$ , $(\\lambda_{\\mathrm{trans}},\\widehat{\\theta}_{\\mathrm{CH,logit}})$ , and $(\\lambda_{\\mathrm{trans}},\\widehat{\\theta}_{\\mathrm{CH,DT,logit}})$ , we tuned t h e elimination p a rameter $\\eta$ in al g orithm 1 usi n g the follow i ng procedure: We c o nsidered $\\dot{\\eta}\\in\\{2,3,4,5,6,7,8,9\\}$ , resulting in the number of phase $:=\\left\\lceil\\log_{\\eta}|\\mathcal{Z}|\\right\\rceil=\\left\\lceil\\log_{\\eta}(17)\\right\\rceil$ (line 4 of algorithm 1) being $\\{5,3,3,2,2,2,2,2\\}$ , respectively. We excluded $\\eta\\,>\\,\\lceil17/2\\rceil\\,=\\,9$ , as those cases also result in 2 phases, the same as $\\eta\\,\\in\\,\\{5,6,7,8,9\\}$ . Then, for each $\\eta$ , for each of the 31 bandit instances, and for each budget $\\in\\{50,75,100,125,150,200,250,300\\}$ seconds, we ran 50 repeated simulations per GSE variation under different random seeds, sampling human feedback from the ftited dEZDM. We then aggregated the results into a single best-arm identification error probability for each GSE variation, $\\eta$ , bandit instance, and budget. These error probabilities were compiled into violin and box plots, as shown in fig. 6. ", "page_idx": 29}, {"type": "text", "text": "For each GSE variation, we selected the $\\eta$ that minimized the median error probability, as shown in the box plots in fig. 6. If multiple $\\eta$ values yielded the same median, we used the third quartile, and if necessary, the first quartile, to break ties. Based on this approach, we selected: $\\eta=6$ for $(\\lambda_{\\mathrm{trans}},\\widehat{\\theta}_{\\mathrm{CH,DT}})$ , $\\eta=6$ for $\\overline{{(\\lambda_{\\mathrm{trans}},\\widehat{\\theta}_{\\mathrm{CH},\\mathbb{R}}\\mathbb{T}}})$ , $\\eta=9$ for $(\\lambda_{\\mathrm{trans}},\\widehat{\\theta}_{\\mathrm{CH}})$ , $\\eta=9$ for $(\\lambda_{\\mathrm{hard}},\\widehat{\\theta}_{\\mathrm{CH}})$ , $\\eta=9$ for $(\\lambda_{\\mathrm{trans}},\\widehat{\\theta}_{\\mathrm{CH,logit}})$ , and $\\eta=5$ for $(\\lambda_{\\mathrm{trans}},\\widehat{\\theta}_{\\mathrm{CH,DT,logit}})$ . ", "page_idx": 29}, {"type": "text", "text": "After tuning $\\eta$ , we manually set the buffer size $B_{\\mathrm{buff}}$ in algorithm 1 to 10 seconds based on empirical results, ensuring the budget was not exceeded in any phase. We then benchmarked each GSE variation on all 31 bandit instances using its own manually tuned $\\eta$ and $B_{\\mathrm{buff}}$ . Each variation was evaluated over 300 repeated simulations with different random seeds, where human choices and response times were sampled from the dEZDM with the identified parameters. The full results are shown in fig. 7, with selected results presented in fig. 4b. ", "page_idx": 29}, {"type": "image", "img_path": "aIPwlkdOut/tmp/3038ca5acffae9edb6f87e112380fe3138dcf8998d0afa9c810ab05ba58e77f6.jpg", "img_caption": ["Figure 6: Violin plots overlaid with box plots, used for tuning the elimination parameter $\\eta$ in algorithm 1 for each GSE variation, simulated based on the snack dataset with choices (yes or no) [16], as discussed in appendix D.2. Each plot shows the best-arm identification error probability, $\\mathbb{P}\\left[\\widehat{z}\\neq z^{*}\\right]$ , as a function of $\\eta$ . The box plots follow the convention of the matplotlib Python pac kage. The horizontal line in each box represents the median of the error probabilities across all bandit instances and budgets. Each error probability is averaged over 50 repeated simulations under different random seeds. The top and bottom borders of the box represent the third and first quartiles, respectively, while the whiskers extend to the farthest points within $1.5\\times$ the interquartile range. Flier points are the outliers past the end of the whiskers. "], "img_footnote": [], "page_idx": 30}, {"type": "image", "img_path": "aIPwlkdOut/tmp/e0c40765f826f2accb268e866454909c08a5af3b39bf1a4913bb64f6786afdcd.jpg", "img_caption": ["Figure 7: A violin plot overlaid with a box plot showing the best-arm identification error probability, $\\mathbb{P}\\left[\\widehat{z}\\neq z^{*}\\right]$ , as a function of budget for each GSE variation, simulated using the snack dataset with cho ices (yes or no) [16], as described in appendix D.2. The box plots follow the convention of the matplotlib Python package. For each GSE variation and budget, the horizontal line in the middle of the box represents the median of the error probabilities across all bandit instances. Each error probability is averaged over 300 repeated simulations under different random seeds. The box\u2019s upper and lower borders represent the third and first quartiles, respectively, with whiskers extending to the farthest points within $1.5\\times$ the interquartile range. Flier points indicate outliers beyond the whiskers. "], "img_footnote": [], "page_idx": 31}, {"type": "text", "text": "D.3 Processing the snack dataset with choices (-1 or 1) [39] ", "text_level": 1, "page_idx": 32}, {"type": "text", "text": "We accessed the snack dataset with choices (-1 or 1) [39] via Fudenberg et al. [27]\u2019s replication package at https://www.aeaweb.org/articles?id $_{\\cdot}{=}10$ .1257/aer.20150742. This dataset contains choices and response times from 39 participants, each responding to between 49 and 100 queries comparing two snack items. Participants\u2019 eye movements were tracked during the experiment. Krajbich et al. [39] modeled each participant\u2019s choices, response times, and eye movements using the attentional DDM, where the drift for each query is a linear combination of the participant\u2019s ratings of both snack items in the query, with the weights influenced by their eye movements. The ratings, $\\in\\{-10,-9,\\ldots,0,\\ldots,9,\\bar{1}0\\}$ , were collected before participants interacted with the binary queries. ", "page_idx": 32}, {"type": "text", "text": "In our work, to avoid creating trivial bandit problems by encoding snack items as 1-dimensional vectors (as done in appendix D.1), we defined the feature vector for each snack item with a participant rating $r_{z}\\in\\{-10,-9,\\ldots,0,\\ldots,9,10\\}$ as a one-hot vector in $\\mathbb{R}^{21}$ , where the $(r_{z}+11)$ -th element is 1 and the rest are 0. The preference vector $\\theta^{*}$ is structured as $\\beta^{*}\\!\\cdot\\![-10,-9,\\dots,0,\\dots,9,10]^{\\top}\\in\\mathbb{R}^{21}$ , where $\\beta^{*}$ is participant-specific and unknown to the learner. This ensures that, for each arm $z$ , the participant\u2019s utility is $u_{z}\\dot{:}=z^{\\top}\\theta^{*}=r_{z}\\beta^{*}$ . In this way, each participant\u2019s data generated a bandit instance with a preference vector $\\theta^{*}\\in\\mathbb{R}^{21}$ , a set of arms $\\mathcal{Z}\\subset\\mathring{\\mathbb{R}}^{21}$ with $|\\mathcal{Z}|=21$ , and a query space $\\mathcal{X}:=\\{\\boldsymbol{z}-\\boldsymbol{z^{\\prime}}\\colon\\bar{\\boldsymbol{z}}\\in\\mathcal{Z}\\}$ . ", "page_idx": 32}, {"type": "text", "text": "We fti each participant\u2019s data to a difference-based EZ-diffusion model [8, 67] using the linear utility structure described above. For each participant, using Bayesian inference with non-informative priors [16], we estimated the preference vector $\\theta^{*}$ (or equivalently, the parameter $\\beta^{*}$ ), non-decision time $t_{\\mathrm{nondec}}$ , and barrier $a$ . Across participants, the barrier $a$ ranged from 0.75 to 2.192 with a mean of 1.335, and $t_{\\mathrm{nondec}}$ ranged from 0.387 to 1.22 seconds with a mean of 0.641 seconds. We then used these ftited models to simulate human feedback for bandit experiments, assuming the learner did not know the underlying structure $\\theta^{*}=\\beta^{*}\\cdot[-10,-9,\\dotsc,0,\\dotsc,9,10]^{\\top}$ . ", "page_idx": 32}, {"type": "text", "text": "For each of the following GSE variations (introduced in section 5.2): $(\\lambda_{\\mathrm{trans}},\\widehat{\\theta}_{\\mathrm{CH,DT}})$ , $(\\lambda_{\\mathrm{trans}},\\widehat{\\theta}_{\\mathrm{CH},\\mathbb{R}\\mathbb{T}})$ , $(\\lambda_{\\mathrm{trans}},\\widehat{\\theta}_{\\mathrm{CH}})$ , $(\\lambda_{\\mathrm{hard}},\\widehat{\\theta}_{\\mathrm{CH}})$ , $(\\lambda_{\\mathrm{trans}},\\widehat{\\theta}_{\\mathrm{CH,logit}})$ , and $(\\lambda_{\\mathrm{trans}},\\widehat{\\theta}_{\\mathrm{CH,DT,logit}})$ , we tuned t h e elimination p a rameter $\\eta$ in al g orithm 1 u s ing the follo  wing procedure: W e  considered $\\eta\\,\\in\\,\\{2,3,4,5,6,7,8,9,10,11\\}$ , which resulted in the number of phases $:=\\lceil\\log_{\\eta}|\\mathcal{Z}|\\rceil=\\lceil\\log_{\\eta}(17)\\rceil$ (line 4 of algorithm 1) being $\\{5,3,3,2,2,2,2,2,2,2\\}$ , respectively. We excluded cases where $\\eta>\\lceil21/2\\rceil=11$ , as these result in 2 phases, identical to when $\\eta\\,\\in\\,\\{5,6,7,8,9,10,11\\}$ . Then, for each $\\eta$ , for each of the 39 bandit instances, and for each budget $\\in\\{150,200,250,300,350,400,450,500\\}$ seconds, we ran 50 repeated simulations per GSE variation under different random seeds, sampling human feedback from the fitted dEZDM. We then aggregated the results into a single best-arm identification error probability for each GSE variation, $\\eta$ , bandit instance, and budget. These error probabilities were compiled into violin and box plots, as shown in fig. 8. ", "page_idx": 32}, {"type": "text", "text": "For each GSE variation, we selected the $\\eta$ that minimized the median error probability, as shown in the box plots in fig. 8. If multiple $\\eta$ values yielded the same median, we used the third quartile, and if necessary, the first quartile, to break ties. Based on this approach, we selected: $\\eta=4$ for $(\\lambda_{\\mathrm{trans}},\\widehat{\\theta}_{\\mathrm{CH,DT}})$ , $\\eta=4$ for $(\\lambda_{\\mathrm{trans}},\\widehat{\\theta}_{\\mathrm{CH},\\mathbb{R}\\mathbb{T}})$ , $\\eta=4$ for $(\\lambda_{\\mathrm{trans}},\\widehat{\\theta}_{\\mathrm{CH}})$ , $\\eta=2$ for $(\\lambda_{\\mathrm{hard}},\\widehat{\\theta}_{\\mathrm{CH}})$ , $\\eta=5$ for $(\\lambda_{\\mathrm{trans}},\\widehat{\\theta}_{\\mathrm{CH,logit}})$ , and $\\eta=5$ for $(\\lambda_{\\mathrm{trans}},\\widehat{\\theta}_{\\mathrm{CH,DT,logit}})$ . ", "page_idx": 32}, {"type": "text", "text": "After tuning $\\eta$ , we manually set the buffer size $B_{\\mathrm{buff}}$ in algorithm 1 to 20 seconds based on empirical results, ensuring the budget was not exceeded in any phase. We then benchmarked each GSE variation on all 39 bandit instances using its own manually tuned $\\eta$ . Each variation was evaluated over 300 repeated simulations with different random seeds, where human choices and response times were sampled from the dEZDM with the identified parameters. The full results are shown in fig. 9, with selected results presented in fig. 4c. ", "page_idx": 32}, {"type": "image", "img_path": "aIPwlkdOut/tmp/f24c731e7ec918e19d6eba727d67e02c45c4385266a143e1f78d3974906590f2.jpg", "img_caption": ["Figure 8: Violin plots overlaid with box plots, used for tuning the elimination parameter $\\eta$ in algorithm 1 for each GSE variation, simulated based on the snack dataset with choices (-1 or 1) [39], as discussed in appendix D.3. Each plot shows the best-arm identification error probability, $\\mathbb{P}\\left[\\widehat{z}\\neq z^{*}\\right]$ , as a function of $\\eta$ . The box plots follow the convention of the matplotlib Python packag e. The horizontal line in each box represents the median of the error probabilities across all bandit instances and budgets. Each error probability is averaged over 50 repeated simulations under different random seeds. The top and bottom borders of the box represent the third and first quartiles, respectively, while the whiskers extend to the farthest points within $1.5\\times$ the interquartile range. Flier points are the outliers past the end of the whiskers. "], "img_footnote": [], "page_idx": 33}, {"type": "image", "img_path": "aIPwlkdOut/tmp/2efbf32d5c5b36ffd64f4fb81da04cd0ec2f4c6c6d241dac2b7f765b657e8bb3.jpg", "img_caption": ["Figure 9: A violin plot overlaid with a box plot showing the best-arm identification error probability, $\\mathbb{P}\\left[\\widehat{z}\\neq z^{*}\\right]$ , as a function of budget for each GSE variation, simulated using the snack dataset with cho ices $^{-1}$ or 1) [39], as described in appendix D.3. The box plots follow the convention of the matplotlib Python package. For each GSE variation and budget, the horizontal line in the middle of the box represents the median of the error probabilities across all bandit instances. Each error probability is averaged over 300 repeated simulations under different random seeds. The box\u2019s upper and lower borders represent the third and first quartiles, respectively, with whiskers extending to the farthest points within $1.5\\times$ the interquartile range. Flier points indicate outliers beyond the whiskers. "], "img_footnote": [], "page_idx": 34}, {"type": "text", "text": "NeurIPS Paper Checklist ", "text_level": 1, "page_idx": 35}, {"type": "text", "text": "1. Claims ", "text_level": 1, "page_idx": 35}, {"type": "text", "text": "Question: Do the main claims made in the abstract and introduction accurately reflect the paper\u2019s contributions and scope? ", "page_idx": 35}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 35}, {"type": "text", "text": "Justification: The main claim in the abstract and introduction is the benefti of incorporating response times in preference learning, which is the key contribution and scope. ", "page_idx": 35}, {"type": "text", "text": "Guidelines: ", "page_idx": 35}, {"type": "text", "text": "\u2022 The answer NA means that the abstract and introduction do not include the claims made in the paper.   \n\u2022 The abstract and/or introduction should clearly state the claims made, including the contributions made in the paper and important assumptions and limitations. A No or NA answer to this question will not be perceived well by the reviewers.   \n\u2022 The claims made should match theoretical and experimental results, and reflect how much the results can be expected to generalize to other settings.   \n\u2022 It is fine to include aspirational goals as motivation as long as it is clear that these goals are not attained by the paper. ", "page_idx": 35}, {"type": "text", "text": "2. Limitations ", "text_level": 1, "page_idx": 35}, {"type": "text", "text": "Question: Does the paper discuss the limitations of the work performed by the authors? ", "page_idx": 35}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 35}, {"type": "text", "text": "Justification: section 6 contains discussions about limitations. ", "page_idx": 35}, {"type": "text", "text": "Guidelines: ", "page_idx": 35}, {"type": "text", "text": "\u2022 The answer NA means that the paper has no limitation while the answer No means that the paper has limitations, but those are not discussed in the paper.   \n\u2022 The authors are encouraged to create a separate \"Limitations\" section in their paper.   \n\u2022 The paper should point out any strong assumptions and how robust the results are to violations of these assumptions (e.g., independence assumptions, noiseless settings, model well-specification, asymptotic approximations only holding locally). The authors should reflect on how these assumptions might be violated in practice and what the implications would be.   \n\u2022 The authors should reflect on the scope of the claims made, e.g., if the approach was only tested on a few datasets or with a few runs. In general, empirical results often depend on implicit assumptions, which should be articulated.   \n\u2022 The authors should reflect on the factors that influence the performance of the approach. For example, a facial recognition algorithm may perform poorly when image resolution is low or images are taken in low lighting. Or a speech-to-text system might not be used reliably to provide closed captions for online lectures because it fails to handle technical jargon.   \n\u2022 The authors should discuss the computational efficiency of the proposed algorithms and how they scale with dataset size.   \n\u2022 If applicable, the authors should discuss possible limitations of their approach to address problems of privacy and fairness.   \n\u2022 While the authors might fear that complete honesty about limitations might be used by reviewers as grounds for rejection, a worse outcome might be that reviewers discover limitations that aren\u2019t acknowledged in the paper. The authors should use their best judgment and recognize that individual actions in favor of transparency play an important role in developing norms that preserve the integrity of the community. Reviewers will be specifically instructed to not penalize honesty concerning limitations. ", "page_idx": 35}, {"type": "text", "text": "3. Theory Assumptions and Proofs ", "text_level": 1, "page_idx": 35}, {"type": "text", "text": "Question: For each theoretical result, does the paper provide the full set of assumptions and a complete (and correct) proof? ", "page_idx": 35}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 35}, {"type": "text", "text": "Justification: Our assumptions are stated in our theorems, and our proofs are in the appendix. Guidelines: ", "page_idx": 36}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include theoretical results.   \n\u2022 All the theorems, formulas, and proofs in the paper should be numbered and crossreferenced.   \n\u2022 All assumptions should be clearly stated or referenced in the statement of any theorems.   \n\u2022 The proofs can either appear in the main paper or the supplemental material, but if they appear in the supplemental material, the authors are encouraged to provide a short proof sketch to provide intuition.   \n\u2022 Inversely, any informal proof provided in the core of the paper should be complemented by formal proofs provided in appendix or supplemental material.   \n\u2022 Theorems and Lemmas that the proof relies upon should be properly referenced. ", "page_idx": 36}, {"type": "text", "text": "4. Experimental Result Reproducibility ", "text_level": 1, "page_idx": 36}, {"type": "text", "text": "Question: Does the paper fully disclose all the information needed to reproduce the main experimental results of the paper to the extent that it affects the main claims and/or conclusions of the paper (regardless of whether the code and data are provided or not)? ", "page_idx": 36}, {"type": "text", "text": "Answer:[Yes] ", "text_level": 1, "page_idx": 36}, {"type": "text", "text": "Justification: We state our full algorithm algorithm 1 in section 4 and the implementation details in appendix D. We also provide the detailed procedures that we have taken to convert several datasets to bandit instances in section 5 and appendix D. ", "page_idx": 36}, {"type": "text", "text": "Guidelines: ", "page_idx": 36}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 If the paper includes experiments, a No answer to this question will not be perceived well by the reviewers: Making the paper reproducible is important, regardless of whether the code and data are provided or not.   \n\u2022 If the contribution is a dataset and/or model, the authors should describe the steps taken to make their results reproducible or verifiable.   \n\u2022 Depending on the contribution, reproducibility can be accomplished in various ways. For example, if the contribution is a novel architecture, describing the architecture fully might suffice, or if the contribution is a specific model and empirical evaluation, it may be necessary to either make it possible for others to replicate the model with the same dataset, or provide access to the model. In general. releasing code and data is often one good way to accomplish this, but reproducibility can also be provided via detailed instructions for how to replicate the results, access to a hosted model (e.g., in the case of a large language model), releasing of a model checkpoint, or other means that are appropriate to the research performed.   \n\u2022 While NeurIPS does not require releasing code, the conference does require all submissions to provide some reasonable avenue for reproducibility, which may depend on the nature of the contribution. For example (a) If the contribution is primarily a new algorithm, the paper should make it clear how to reproduce that algorithm. (b) If the contribution is primarily a new model architecture, the paper should describe the architecture clearly and fully. (c) If the contribution is a new model (e.g., a large language model), then there should either be a way to access this model for reproducing the results or a way to reproduce the model (e.g., with an open-source dataset or instructions for how to construct the dataset). (d) We recognize that reproducibility may be tricky in some cases, in which case authors are welcome to describe the particular way they provide for reproducibility. In the case of closed-source models, it may be that access to the model is limited in some way (e.g., to registered users), but it should be possible for other researchers to have some path to reproducing or verifying the results. ", "page_idx": 36}, {"type": "text", "text": "5. Open access to data and code ", "text_level": 1, "page_idx": 36}, {"type": "text", "text": "Question: Does the paper provide open access to the data and code, with sufficient instructions to faithfully reproduce the main experimental results, as described in supplemental material? ", "page_idx": 37}, {"type": "text", "text": "Answer: [No] ", "page_idx": 37}, {"type": "text", "text": "Justification: We plan to release our code later after we receive approvals from the funding agency. ", "page_idx": 37}, {"type": "text", "text": "Guidelines: ", "page_idx": 37}, {"type": "text", "text": "\u2022 The answer NA means that paper does not include experiments requiring code.   \n\u2022 Please see the NeurIPS code and data submission guidelines (https://nips.cc/ public/guides/CodeSubmissionPolicy) for more details.   \n\u2022 While we encourage the release of code and data, we understand that this might not be possible, so \u201cNo\u201d is an acceptable answer. Papers cannot be rejected simply for not including code, unless this is central to the contribution (e.g., for a new open-source benchmark).   \n\u2022 The instructions should contain the exact command and environment needed to run to reproduce the results. See the NeurIPS code and data submission guidelines (https: //nips.cc/public/guides/CodeSubmissionPolicy) for more details.   \n\u2022 The authors should provide instructions on data access and preparation, including how to access the raw data, preprocessed data, intermediate data, and generated data, etc.   \n\u2022 The authors should provide scripts to reproduce all experimental results for the new proposed method and baselines. If only a subset of experiments are reproducible, they should state which ones are omitted from the script and why.   \n\u2022 At submission time, to preserve anonymity, the authors should release anonymized versions (if applicable).   \n\u2022 Providing as much information as possible in supplemental material (appended to the paper) is recommended, but including URLs to data and code is permitted. ", "page_idx": 37}, {"type": "text", "text": "6. Experimental Setting/Details ", "text_level": 1, "page_idx": 37}, {"type": "text", "text": "Question: Does the paper specify all the training and test details (e.g., data splits, hyperparameters, how they were chosen, type of optimizer, etc.) necessary to understand the results? ", "page_idx": 37}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 37}, {"type": "text", "text": "Justification: We state our full algorithm algorithm 1 in section 4 and the implementation details in appendix D. We also provide the detailed procedures that we have taken to convert several datasets to bandit instances in section 5 and appendix D. ", "page_idx": 37}, {"type": "text", "text": "Guidelines: ", "page_idx": 37}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments. \u2022 The experimental setting should be presented in the core of the paper to a level of detail that is necessary to appreciate the results and make sense of them. \u2022 The full details can be provided either with the code, in appendix, or as supplemental material. ", "page_idx": 37}, {"type": "text", "text": "7. Experiment Statistical Significance ", "text_level": 1, "page_idx": 37}, {"type": "text", "text": "Question: Does the paper report error bars suitably and correctly defined or other appropriate information about the statistical significance of the experiments? ", "page_idx": 37}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 37}, {"type": "text", "text": "Justification: The plots of our key empirical result about bandit learning (fig. 4) uses violin and box plots to illustrate the randomness in the result. ", "page_idx": 37}, {"type": "text", "text": "Guidelines: ", "page_idx": 37}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments. \u2022 The authors should answer \"Yes\" if the results are accompanied by error bars, confidence intervals, or statistical significance tests, at least for the experiments that support the main claims of the paper. ", "page_idx": 37}, {"type": "text", "text": "\u2022 The factors of variability that the error bars are capturing should be clearly stated (for example, train/test split, initialization, random drawing of some parameter, or overall run with given experimental conditions).   \n\u2022 The method for calculating the error bars should be explained (closed form formula, call to a library function, bootstrap, etc.)   \n\u2022 The assumptions made should be given (e.g., Normally distributed errors).   \n\u2022 It should be clear whether the error bar is the standard deviation or the standard error of the mean.   \n\u2022 It is OK to report 1-sigma error bars, but one should state it. The authors should preferably report a 2-sigma error bar than state that they have a $96\\%$ CI, if the hypothesis of Normality of errors is not verified.   \n\u2022 For asymmetric distributions, the authors should be careful not to show in tables or figures symmetric error bars that would yield results that are out of range (e.g. negative error rates).   \n\u2022 If error bars are reported in tables or plots, The authors should explain in the text how they were calculated and reference the corresponding figures or tables in the text. ", "page_idx": 38}, {"type": "text", "text": "8. Experiments Compute Resources ", "text_level": 1, "page_idx": 38}, {"type": "text", "text": "Question: For each experiment, does the paper provide sufficient information on the computer resources (type of compute workers, memory, time of execution) needed to reproduce the experiments? ", "page_idx": 38}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 38}, {"type": "text", "text": "Justification: We provide our computation resource in appendix D. ", "page_idx": 38}, {"type": "text", "text": "Guidelines: ", "page_idx": 38}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 The paper should indicate the type of compute workers CPU or GPU, internal cluster, or cloud provider, including relevant memory and storage.   \n\u2022 The paper should provide the amount of compute required for each of the individual experimental runs as well as estimate the total compute.   \n\u2022 The paper should disclose whether the full research project required more compute than the experiments reported in the paper (e.g., preliminary or failed experiments that didn\u2019t make it into the paper). ", "page_idx": 38}, {"type": "text", "text": "9. Code Of Ethics ", "text_level": 1, "page_idx": 38}, {"type": "text", "text": "Question: Does the research conducted in the paper conform, in every respect, with the NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines? ", "page_idx": 38}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 38}, {"type": "text", "text": "Justification: We have reviewed the ethics guide and have been following it throughout. Guidelines: ", "page_idx": 38}, {"type": "text", "text": "\u2022 The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics.   \n\u2022 If the authors answer No, they should explain the special circumstances that require a deviation from the Code of Ethics.   \n\u2022 The authors should make sure to preserve anonymity (e.g., if there is a special consideration due to laws or regulations in their jurisdiction). ", "page_idx": 38}, {"type": "text", "text": "10. Broader Impacts ", "text_level": 1, "page_idx": 38}, {"type": "text", "text": "Question: Does the paper discuss both potential positive societal impacts and negative societal impacts of the work performed? ", "page_idx": 38}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 38}, {"type": "text", "text": "Justification: We provide a discussion about societal impacts in appendix A. Guidelines: ", "page_idx": 38}, {"type": "text", "text": "\u2022 The answer NA means that there is no societal impact of the work performed. \u2022 If the authors answer NA or No, they should explain why their work has no societal impact or why the paper does not address societal impact. ", "page_idx": 38}, {"type": "text", "text": "\u2022 Examples of negative societal impacts include potential malicious or unintended uses (e.g., disinformation, generating fake profiles, surveillance), fairness considerations (e.g., deployment of technologies that could make decisions that unfairly impact specific groups), privacy considerations, and security considerations.   \n\u2022 The conference expects that many papers will be foundational research and not tied to particular applications, let alone deployments. However, if there is a direct path to any negative applications, the authors should point it out. For example, it is legitimate to point out that an improvement in the quality of generative models could be used to generate deepfakes for disinformation. On the other hand, it is not needed to point out that a generic algorithm for optimizing neural networks could enable people to train models that generate Deepfakes faster.   \n\u2022 The authors should consider possible harms that could arise when the technology is being used as intended and functioning correctly, harms that could arise when the technology is being used as intended but gives incorrect results, and harms following from (intentional or unintentional) misuse of the technology.   \n\u2022 If there are negative societal impacts, the authors could also discuss possible mitigation strategies (e.g., gated release of models, providing defenses in addition to attacks, mechanisms for monitoring misuse, mechanisms to monitor how a system learns from feedback over time, improving the efficiency and accessibility of ML). ", "page_idx": 39}, {"type": "text", "text": "11. Safeguards ", "text_level": 1, "page_idx": 39}, {"type": "text", "text": "Question: Does the paper describe safeguards that have been put in place for responsible release of data or models that have a high risk for misuse (e.g., pretrained language models, image generators, or scraped datasets)? ", "page_idx": 39}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 39}, {"type": "text", "text": "Justification: Our paper does not release data or models, but proposes an estimation method for interactive learning. We have discussed the potential societal impact in appendix A. ", "page_idx": 39}, {"type": "text", "text": "Guidelines: ", "page_idx": 39}, {"type": "text", "text": "\u2022 The answer NA means that the paper poses no such risks.   \n\u2022 Released models that have a high risk for misuse or dual-use should be released with necessary safeguards to allow for controlled use of the model, for example by requiring that users adhere to usage guidelines or restrictions to access the model or implementing safety filters.   \n\u2022 Datasets that have been scraped from the Internet could pose safety risks. The authors should describe how they avoided releasing unsafe images.   \n\u2022 We recognize that providing effective safeguards is challenging, and many papers do not require this, but we encourage authors to take this into account and make a best faith effort. ", "page_idx": 39}, {"type": "text", "text": "12. Licenses for existing assets ", "text_level": 1, "page_idx": 39}, {"type": "text", "text": "Question: Are the creators or original owners of assets (e.g., code, data, models), used in the paper, properly credited and are the license and terms of use explicitly mentioned and properly respected? ", "page_idx": 39}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 39}, {"type": "text", "text": "Justification: For open-sourced codes in appendix D and datasets used in section 5, we have cited their original paper or source link. ", "page_idx": 39}, {"type": "text", "text": "Guidelines: ", "page_idx": 39}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not use existing assets.   \n\u2022 The authors should cite the original paper that produced the code package or dataset.   \n\u2022 The authors should state which version of the asset is used and, if possible, include a URL.   \n\u2022 The name of the license (e.g., CC-BY 4.0) should be included for each asset.   \n\u2022 For scraped data from a particular source (e.g., website), the copyright and terms of service of that source should be provided.   \n\u2022 If assets are released, the license, copyright information, and terms of use in the package should be provided. For popular datasets, paperswithcode.com/datasets has curated licenses for some datasets. Their licensing guide can help determine the license of a dataset.   \n\u2022 For existing datasets that are re-packaged, both the original license and the license of the derived asset (if it has changed) should be provided.   \n\u2022 If this information is not available online, the authors are encouraged to reach out to the asset\u2019s creators. ", "page_idx": 39}, {"type": "text", "text": "", "page_idx": 40}, {"type": "text", "text": "13. New Assets ", "text_level": 1, "page_idx": 40}, {"type": "text", "text": "Question: Are new assets introduced in the paper well documented and is the documentation provided alongside the assets? ", "page_idx": 40}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 40}, {"type": "text", "text": "Justification: This paper does not release new assets. ", "page_idx": 40}, {"type": "text", "text": "Guidelines: ", "page_idx": 40}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not release new assets.   \n\u2022 Researchers should communicate the details of the dataset/code/model as part of their submissions via structured templates. This includes details about training, license, limitations, etc.   \n\u2022 The paper should discuss whether and how consent was obtained from people whose asset is used.   \n\u2022 At submission time, remember to anonymize your assets (if applicable). You can either create an anonymized URL or include an anonymized zip file. ", "page_idx": 40}, {"type": "text", "text": "14. Crowdsourcing and Research with Human Subjects ", "text_level": 1, "page_idx": 40}, {"type": "text", "text": "Question: For crowdsourcing experiments and research with human subjects, does the paper include the full text of instructions given to participants and screenshots, if applicable, as well as details about compensation (if any)? ", "page_idx": 40}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 40}, {"type": "text", "text": "Justification: This paper does not have crowdsourcing or research with human with subjects. Guidelines: ", "page_idx": 40}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u2022 Including this information in the supplemental material is fine, but if the main contribution of the paper involves human subjects, then as much detail as possible should be included in the main paper.   \n\u2022 According to the NeurIPS Code of Ethics, workers involved in data collection, curation, or other labor should be paid at least the minimum wage in the country of the data collector. ", "page_idx": 40}, {"type": "text", "text": "15. Institutional Review Board (IRB) Approvals or Equivalent for Research with Human Subjects ", "text_level": 1, "page_idx": 40}, {"type": "text", "text": "Question: Does the paper describe potential risks incurred by study participants, whether such risks were disclosed to the subjects, and whether Institutional Review Board (IRB) approvals (or an equivalent approval/review based on the requirements of your country or institution) were obtained? ", "page_idx": 40}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 40}, {"type": "text", "text": "Justification: This paper does not have crowdsourcing or research with human with subjects. Guidelines: ", "page_idx": 40}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u2022 Depending on the country in which research is conducted, IRB approval (or equivalent) may be required for any human subjects research. If you obtained IRB approval, you should clearly state this in the paper.   \n\u2022 We recognize that the procedures for this may vary significantly between institutions and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the guidelines for their institution.   \n\u2022 For initial submissions, do not include any information that would break anonymity (if applicable), such as the institution conducting the review. ", "page_idx": 40}, {"type": "text", "text": "", "page_idx": 41}]