[{"figure_path": "qEpi8uWX3N/tables/tables_2_1.jpg", "caption": "Table 1: Performance on instruction tuning with Dolly-15K [8] and evaluated with MMLU [16] with different ranks. For LoRA (Split) decomposes high-rank LoRA modules into smaller, equivalent low-rank components (r\u00d7n). n is the number of LoRAs, r denotes the rank of each LoRA.", "description": "This table presents the performance of different LoRA configurations on the instruction tuning task using Dolly-15K and evaluated using MMLU. It shows the impact of varying the rank (r) and number (n) of LoRA modules on the final performance.  The 'LoRA (Split)' configurations demonstrate that splitting a high-rank LoRA into multiple smaller LoRAs can improve performance.", "section": "2.3 Observations"}, {"figure_path": "qEpi8uWX3N/tables/tables_5_1.jpg", "caption": "Table 2: Comparative performance of different tuning schemes across multiple benchmarks on a single domain. 8-shot for GSM8K, zero-shot for others. #B refers to the average B matrix number.", "description": "This table compares the performance of several parameter-efficient fine-tuning (PEFT) methods and full fine-tuning on a single domain across various benchmarks (MMLU, Medical, Law, HumanEval, GSM8K).  It shows the performance improvements achieved by different approaches (LoRA, AdaLoRA, HydraLoRA, etc.) in terms of percentage parameter usage, the number of A and B matrices, and the performance on each benchmark. Note that some benchmarks used 8-shot learning while others used zero-shot learning.", "section": "4.2 Overall Performance"}, {"figure_path": "qEpi8uWX3N/tables/tables_6_1.jpg", "caption": "Table 3: Comparative performance of different tuning schemes, including base model (Base), LoRA tuning (LORA), LoraHub learning, multi-LoRA tuning with MoE inference (LORA MOE) and our proposed HydraLoRA learning across mix-task domain on the BBH benchmark with LLaMA2-7B, LLaMA2-13B as the base LLM (3-shot).", "description": "This table compares the performance of several parameter-efficient fine-tuning (PEFT) methods, including HydraLoRA, across multiple tasks on a mixed-domain benchmark (BBH).  It evaluates performance using the base LLMs LLaMA2-7B and LLaMA2-13B with 3-shot settings. The metrics include overall performance, the number of A and B matrices used during training and inference, and the percentage of parameters tuned.", "section": "4 Experiments"}, {"figure_path": "qEpi8uWX3N/tables/tables_17_1.jpg", "caption": "Table 2: Comparative performance of different tuning schemes across multiple benchmarks on a single domain. 8-shot for GSM8K, zero-shot for others. #B refers to the average B matrix number.", "description": "This table compares the performance of HydraLoRA against other parameter-efficient fine-tuning (PEFT) methods and full fine-tuning on several downstream tasks within a single domain.  The metrics evaluated include performance on the MMLU, Medical, Law, and HumanEval benchmarks, as well as P@1 and P@10 on GSM8K.  The number of trainable parameters (#Params) for each method is also shown, along with the number of A and B matrices used in HydraLoRA.", "section": "4.2 Overall Performance"}]