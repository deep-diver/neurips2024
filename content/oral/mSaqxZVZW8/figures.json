[{"figure_path": "mSaqxZVZW8/figures/figures_4_1.jpg", "caption": "Figure 1: An illustration of how SeeA* overcomes the A* search's limitation. (a) An example of the search tree is guided by the true optimal value f*(n) = g(n) +h*(n). Values on the edge denote the cost of each step. (b) On the same example, the A* search is trapped in a suboptimal branch misled by the unreliable heuristics, i.e., f(n) = g(n) + h(n). (d) When the candidate set does not contain the node nt with the best f value, n\u00bd will be selected and explored, where n\u00bd \u2260 n.", "description": "This figure illustrates how SeeA* addresses the limitations of the A* search algorithm, particularly when dealing with inaccurate heuristic estimations. Subfigure (a) shows an optimal search path using the exact cost function f*(n). Subfigure (b) shows that A* search might get trapped in a suboptimal branch due to inaccurate cost estimations provided by f(n). Subfigures (c) and (d) demonstrates that SeeA* avoids this by selectively sampling nodes and expanding the node with the best heuristic value within this sample.  SeeA* may choose a node different from the best node in the entire open set (O), which enables exploration of other promising branches. ", "section": "4 Method"}, {"figure_path": "mSaqxZVZW8/figures/figures_16_1.jpg", "caption": "Figure 2: Set of selected candidate nodes D obtained by (a) uniform sampling strategy; (b) clustering sampling strategy.", "description": "This figure compares two different sampling strategies used in the SeeA* algorithm: uniform sampling and clustering sampling.  The uniform sampling strategy randomly selects candidate nodes from the open set, while the clustering sampling strategy first groups the open nodes into clusters and then samples nodes from each cluster. This is done to improve exploration by ensuring nodes from a wider range of potential solutions are selected for consideration in the next expansion step. The figure visually shows how the two strategies differ in selecting the next node for expansion, highlighting that the clustering method promotes more diverse exploration.", "section": "4.1.2 Clustering sampling strategy"}, {"figure_path": "mSaqxZVZW8/figures/figures_19_1.jpg", "caption": "Figure 3: Example for the monotonicity of P(f(n) \u2264 f(n')|f*(n'), \u03c3).", "description": "This figure illustrates the monotonicity of the probability P(f(n) \u2264 f(n')|f*(n'), \u03c3) concerning the prediction error \u03c3. The plot shows two curves representing the probability for different values of \u03c3 (1.0 and 3.0). The x-axis represents the true cost f*(n'), and the y-axis represents the probability P(f(n) \u2264 f(n')).  The figure demonstrates how, for a given true cost f*(n'), the probability P(f(n) \u2264 f(n')) changes with the level of prediction error \u03c3.  The arrows highlight that the probability is not always monotonically decreasing with \u03c3, but the overall trend supports the claim made in Corollary 4.2.", "section": "Efficiency of SeeA* search"}, {"figure_path": "mSaqxZVZW8/figures/figures_22_1.jpg", "caption": "Figure 4: The process involves transforming the representation of the chemical retrosynthetic route into the search tree representation used in this paper. (a) is the real chemical retrosynthetic route, in which the reverse reaction decomposes the input product molecule into several reactant molecules; (b) is the corresponding search tree representation, and each node in the tree contains all molecules decomposed from the target molecule along the traverse reaction path from the root to this node.", "description": "This figure illustrates how chemical retrosynthetic routes are transformed into a search tree representation used in the paper's algorithm. Part (a) shows a real retrosynthetic route where a molecule is broken down into its constituent reactants through reverse reactions. Part (b) displays the equivalent search tree where each node encapsulates all molecules resulting from the decomposition of the target molecule along a specific reaction path.  This transformation is crucial for applying the SeeA* search algorithm.", "section": "Search tree representation in retrosynthesis planning"}, {"figure_path": "mSaqxZVZW8/figures/figures_24_1.jpg", "caption": "Figure 5: An example of the logic synthesis problem. The design of the hardware is represented by an and-inverter graph. After a series of transformations, a more refined AIG is obtained, while maintaining the same function as the original AIG. While preserving the input and output relationship, the number and connectivity of intermediate nodes are optimized. Post-technology mapping and final evaluation are conducted with the ABC package.", "description": "This figure illustrates the logic synthesis process. It starts with a hardware design represented as an And-Inverter Graph (AIG), which is then optimized through a series of transformations.  The goal is to reduce the area-delay product (ADP) while maintaining the functionality.  The figure shows the initial AIG, the sequence of transformations, the post-technology mapping stage using an ABC library, the final optimized AIG, and the evaluation process to determine the ADP reduction.", "section": "Introduction of the MCNC dataset"}, {"figure_path": "mSaqxZVZW8/figures/figures_26_1.jpg", "caption": "Figure 6: Training loss of the value estimator for the logic synthesis problem.", "description": "This figure shows the mean squared error (MSE) loss during the training of the value estimator used in the logic synthesis experiments. The x-axis represents the training update steps, and the y-axis represents the MSE loss. The plot shows a sharp decrease in MSE at the beginning of training, indicating the model is learning effectively. Then, the MSE loss fluctuates around a low value, suggesting that the model has converged to a good solution.", "section": "5.4 The impact of the hyperparameters on the performance"}, {"figure_path": "mSaqxZVZW8/figures/figures_27_1.jpg", "caption": "Figure 7: The search tree of A* search when solving logic synthesis problem for alu4.", "description": "This figure shows the search tree generated by the A* algorithm when solving the logic synthesis problem for the alu4 circuit. The tree visually represents the nodes expanded during the search process, highlighting the path chosen by the A* algorithm. It demonstrates how the A* algorithm might get stuck in a suboptimal branch, lacking exploration capabilities, and focusing on nodes with seemingly minimal cost according to the heuristic function.  The percentages at the bottom indicate the proportion of times each action was selected during the search.", "section": "K An example of different search algorithms to solve logic synthesis"}, {"figure_path": "mSaqxZVZW8/figures/figures_28_1.jpg", "caption": "Figure 9: The search tree of SeeA* search when solving logic synthesis problem for alu4.", "description": "This figure shows a comparison of the search tree generated by the SeeA* algorithm with different sampling strategies against other search algorithms like A* and MCTS for solving a logic synthesis problem.  The figure highlights how SeeA* balances exploration and exploitation, expanding a moderate number of branches to avoid getting trapped in local optima like A*, but also avoiding excessive exploration across irrelevant branches like MCTS. The percentage values below each node represent the proportion of times that node was expanded during the search process.", "section": "K An example of different search algorithms to solve logic synthesis"}, {"figure_path": "mSaqxZVZW8/figures/figures_28_2.jpg", "caption": "Figure 9: The search tree of SeeA* search when solving logic synthesis problem for alu4.", "description": "The figure shows the search tree generated by SeeA* when solving the logic synthesis problem for the alu4 circuit.  SeeA* balances exploration and exploitation, avoiding getting stuck in a suboptimal branch like A*, but also avoiding excessive exploration like MCTS. The nodes are color-coded to indicate whether they were expanded or not, and percentages show the proportion of times each node was selected as the next node to expand. The tree demonstrates SeeA*'s capacity to explore alternative branches effectively, finding a better solution than A* and with fewer node expansions than MCTS.", "section": "K An example of different search algorithms to solve logic synthesis"}, {"figure_path": "mSaqxZVZW8/figures/figures_29_1.jpg", "caption": "Figure 6: Training loss of the value estimator for the logic synthesis problem.", "description": "This figure shows the training loss curve of the value estimator used in the logic synthesis task. The x-axis represents the number of updates during training, and the y-axis represents the mean squared error (MSE) loss. The curve starts at a high MSE and gradually decreases as the training progresses, indicating that the model is learning effectively to estimate the value of different actions in the logic synthesis process.", "section": "5.4 The impact of the hyperparameters on the performance"}, {"figure_path": "mSaqxZVZW8/figures/figures_30_1.jpg", "caption": "Figure 11: Success rate and average solution length on the USPTO benchmark with different candidate set sizes K in uniform sampling strategy.", "description": "This figure shows the success rate and average solution length for retrosynthetic planning on the USPTO benchmark dataset using the SeeA* algorithm with a uniform sampling strategy.  The x-axis represents the candidate set size (K), which is a hyperparameter controlling the exploration-exploitation balance.  The green line shows the success rate, indicating that the algorithm performs better with moderate K values, not too small and not too large. The orange line shows the average solution length, which also shows a trend of shorter lengths in the same moderate range of K values, suggesting that an appropriate balance between exploration and exploitation is crucial for efficiency.", "section": "O Investigations on the hyperparameters"}, {"figure_path": "mSaqxZVZW8/figures/figures_30_2.jpg", "caption": "Figure 12: Success rate and average solution length on the USPTO benchmark with different number of clusters in clustering sampling strategy (K = 50).", "description": "This figure shows the impact of the number of clusters (Nc) on the performance of the SeeA* algorithm with the clustering sampling strategy.  The x-axis represents the number of clusters used in the sampling process. The y-axis shows two metrics: success rate (green line) and average solution length (orange dashed line).  The results suggest that a moderate number of clusters leads to the best performance, with both high success rate and short solution lengths.  Too few clusters may not provide sufficient exploration, while too many clusters might introduce excessive noise, reducing performance.", "section": "Investigations on the hyperparameters"}, {"figure_path": "mSaqxZVZW8/figures/figures_31_1.jpg", "caption": "Figure 13: Success rate and average solution length on the USPTO benchmark with different c<sub>b</sub> in UCT-like sampling strategy (K = 50).", "description": "This figure shows the success rate and average solution length on the USPTO benchmark using the UCT-like sampling strategy in SeeA*.  The x-axis represents the hyperparameter c<sub>b</sub> which controls the balance between exploration and exploitation. The y-axis on the left shows the success rate, while the y-axis on the right shows the average solution length.  The results indicate an optimal range for c<sub>b</sub>, where increasing or decreasing it beyond this range negatively impacts performance.", "section": "5.4 The impact of the hyperparameters on the performance"}, {"figure_path": "mSaqxZVZW8/figures/figures_31_2.jpg", "caption": "Figure 14: Average solution length and average number of node expansions tested on the Sokoban game with different candidate set sizes K in uniform sampling strategy.", "description": "This figure shows the results of an experiment comparing the average solution length and the number of node expansions required by SeeA* in solving the Sokoban game. The experiment used uniform sampling to select candidate nodes, varying the size (K) of the candidate set. As the size of the candidate set increases, the average solution length decreases and the average number of node expansions increases. The figure demonstrates the trade-off between exploration (larger K) and exploitation (smaller K) in the SeeA* algorithm.", "section": "5.3 Results on Sokoban and path finding"}, {"figure_path": "mSaqxZVZW8/figures/figures_33_1.jpg", "caption": "Figure 15: (a) An example of the difference of expansion probability for each node for \u025b-Greedy and SeeA* (Uniform sampling strategy is employed and the candidate size K = 3). (b) Expanded probability calculation for SeeA*. There are ten possible combinations of the candidate sets, and each combination occurs with equal probability.", "description": "This figure compares the node expansion probabilities of three search algorithms: A*, \u03b5-Greedy, and SeeA*.  It shows how the probability of expanding a node changes based on its heuristic value and the algorithm used.  A* deterministically expands the node with the lowest heuristic value. \u03b5-Greedy randomly explores other nodes with a small probability. SeeA*, using a uniform sampling strategy, creates a subset of nodes and expands the one with the lowest heuristic value in the subset. The figure illustrates how SeeA* balances exploitation (favoring the best node) and exploration (considering other nodes).", "section": "P Comparison between \u025b-Greedy and SeeA*"}, {"figure_path": "mSaqxZVZW8/figures/figures_33_2.jpg", "caption": "Figure 2: Set of selected candidate nodes D obtained by (a) uniform sampling strategy; (b) clustering sampling strategy.", "description": "This figure illustrates two different sampling strategies used in the SeeA* algorithm to select candidate nodes for expansion.  (a) shows the uniform sampling, where nodes are randomly selected from the open set.  This results in a relatively even distribution of selected nodes across the search space but may miss promising areas. (b) shows the clustering sampling strategy, where the open nodes are first grouped into clusters, and then nodes are sampled from each cluster. This strategy ensures that all clusters are represented in the candidate set, improving the chance of selecting promising nodes, even if they are not the top candidates in the open set overall. The clustering strategy helps to balance exploration (exploring different areas of the search space) and exploitation (focusing on nodes with the best heuristic values).", "section": "4.1 SeeA* search algorithm"}]