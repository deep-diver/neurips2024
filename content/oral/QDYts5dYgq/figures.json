[{"figure_path": "QDYts5dYgq/figures/figures_1_1.jpg", "caption": "Figure 1: Overview of SDF-Sim pipeline. SDFs parameterized by MLPs are learned for each object to implicitly represent the object shape and the distance field. A GNN-based simulator uses learned SDFs to predict object dynamics for the next simulation step.", "description": "This figure shows a schematic overview of the SDF-Sim pipeline. It starts with objects represented as learned signed distance functions (SDFs).  Each SDF is parameterized by a multi-layer perceptron (MLP) that implicitly defines the object's shape and distance field. These SDFs are then fed into a graph neural network (GNN)-based simulator, which predicts the object's dynamics (position, rotation, etc.) for the next simulation step, showing how the SDF representation allows the model to predict the next timestep given the current SDFs and object states.", "section": "1 Introduction"}, {"figure_path": "QDYts5dYgq/figures/figures_2_1.jpg", "caption": "Figure 2: Example of rollouts from SDF-Sim scaled to large simulations, all simulated for 200 steps. (Top) 300 shoes (object from Movi-C), with 851k nodes, falling onto the floor (Middle) 270 knots from Movi-B, 384k nodes (Bottom) 380 objects from Movi-C, 1.1M nodes. See simulation videos on https://sites.google.com/view/sdf-sim.", "description": "This figure showcases three large-scale simulations produced by SDF-Sim, each with a different set of objects and a high number of nodes. The top panel shows 300 shoes falling onto a floor; the middle panel displays 270 knots in a similar setting; and the bottom panel presents 380 diverse objects.  These simulations demonstrate SDF-Sim's scalability to extremely large scenes (up to 1.1 million nodes), a significant advancement compared to previous learned simulators which struggle at far fewer nodes.  The provided URL links to videos showing these simulations.", "section": "Results"}, {"figure_path": "QDYts5dYgq/figures/figures_2_2.jpg", "caption": "Figure 3: Simulating assets extracted from vision. (a) We extract the SDF from the images of a real-world scene with a garden table [7]. (b) We simulate a virtual shoe object falling onto a vase and a table using SDF-Sim. SDF-Sim is able to predict realistic dynamics, even for the collision of the shoe with the intricate shape of the vase (frames 50-70). See section 4.4 for details and the video on the website.", "description": "This figure shows the application of SDF-Sim to real-world scenes by extracting SDFs from images.  Panel (a) displays a real-world scene with a garden table, which was used to extract the SDFs. Panel (b) shows the simulation results, demonstrating how the learned SDF-Sim model accurately simulates a shoe falling onto a vase and a table, even capturing complex interactions with the vase's shape.", "section": "4 Simulating real-world scenes from vision"}, {"figure_path": "QDYts5dYgq/figures/figures_3_1.jpg", "caption": "Figure 4: Construction of graph edges in SDF-Sim.", "description": "The figure illustrates the construction of graph edges in the SDF-Sim architecture.  It shows how intra-object edges connect surface nodes to the object's center node, while inter-object (collision) edges connect surface nodes of different objects if they are within a certain distance threshold, as determined by the SDF.  Edge features, which include distances and relative positions, are also detailed.  This efficient graph construction avoids the quadratic complexity of traditional mesh-based methods for collision detection, making SDF-Sim scalable to large scenes.", "section": "3 SDF-Sim"}, {"figure_path": "QDYts5dYgq/figures/figures_5_1.jpg", "caption": "Figure 5: Comparison of the last frames of rollouts predicted on Movi-C. See more frames in Figure S9 and on the website.", "description": "This figure compares the last frames of simulations generated by FIGNet*, a state-of-the-art learned simulator based on mesh, and SDF-Sim, a novel learned simulator using SDFs, against the ground truth.  It highlights the accuracy of SDF-Sim in predicting the final state of a scene, demonstrating its ability to capture complex dynamics involving multiple objects.", "section": "4 Results"}, {"figure_path": "QDYts5dYgq/figures/figures_6_1.jpg", "caption": "Figure 6: Accuracy, memory and runtime comparisons between the SDF-Sim model and the mesh-based baselines on the Movi-B/C benchmarks. On Movi-C, most baselines except FIGNet* run out of memory and are not shown. As \u201cPeak Memory\u201d we report the peak memory used by the model per single step of the simulation. DPI, MGN-Large-Radius and MGN results were reported by [4]. See Tables 3 and 4 for the exact numbers.", "description": "This figure compares the performance of SDF-Sim with several mesh-based baselines (DPI, MGN, MGN-Large-Radius, FIGNet, FIGNet*) on the Movi-B and Movi-C benchmark datasets.  It shows the number of graph edges, peak memory usage, runtime per step, translation error, and rotation error for each method.  The results highlight that SDF-Sim achieves comparable accuracy with significantly reduced memory consumption and faster runtime, especially on the larger Movi-C dataset where many baselines run out of memory.", "section": "4 Results"}, {"figure_path": "QDYts5dYgq/figures/figures_6_2.jpg", "caption": "Figure 7: Large-scale simulation of Spheres-in-Bowl, simulated for 200 timesteps. Left: the final step of SDF-Sim rollout on the scene with 512 spheres. Right: number of edges and runtime w.r.t. the number of spheres in the simulation (max 512). In complex simulations with lots of contacts, FIGNet and FIGNet* generate an excessive number of collision edges, quickly exceeding GPU memory (end of the orange and blue lines). SDF-Sim generates an order-of-magnitude fewer collision edges, and can easily simulate scenes with 100s of objects without running out of memory.", "description": "This figure demonstrates the scalability of SDF-Sim compared to other methods (FIGNet and FIGNet*) for large-scale simulations.  The left panel shows a simulation with 512 spheres. The right panel plots the number of edges and runtime against the number of spheres. It highlights that SDF-Sim uses significantly fewer edges and has much faster runtime, especially as the number of spheres (and hence complexity) increases, allowing it to handle large-scale simulations where other methods fail due to memory limitations.", "section": "Results"}, {"figure_path": "QDYts5dYgq/figures/figures_7_1.jpg", "caption": "Figure 8: Accuracy metrics w.r.t. simulation time step for Spheres-in-Bowl simulation shown in Figure 7. (a) Penetration metrics. (b) Rollout RMSE. Both metrics are averaged over simulation runs with up to 140 spheres, the maximum for which all baselines could be run.", "description": "This figure shows the accuracy of different methods in simulating the Spheres-in-Bowl scene.  The left panel shows average penetration depth over time, while the right panel shows the root mean square error (RMSE) of the rollout compared to the ground truth.  The results are averaged over simulations with up to 140 spheres, reflecting the scalability limitations of some methods.", "section": "4 Results"}, {"figure_path": "QDYts5dYgq/figures/figures_8_1.jpg", "caption": "Figure 9: Ablation on learned SDF model sizes: 8 layer MLPs with layer sizes of 32, 64, or 128 hidden units. (a, b) Translation and rotation error for SDF-Sim trained on Movi-B with different SDF sizes. (c) Mean squared error of the predicted SDF estimates near the surface. (d) Visualisations of the cow shape from Movi-B with different SDF sizes. (e) A cross-section of the learned SDF field for the Movi-B cow shape.", "description": "This figure shows an ablation study on the impact of learned SDF model size on the performance of SDF-Sim.  It includes plots showing translation and rotation error for different SDF layer sizes, the mean squared error of predicted SDF estimates near the surface, visualizations of a cow shape reconstructed with different SDF sizes, and a cross-section of a learned SDF heatmap.", "section": "4.5 Ablation of learned SDF quality"}, {"figure_path": "QDYts5dYgq/figures/figures_13_1.jpg", "caption": "Figure 6: Accuracy, memory and runtime comparisons between the SDF-Sim model and the mesh-based baselines on the Movi-B/C benchmarks. On Movi-C, most baselines except FIGNet* run out of memory and are not shown. As \u201cPeak Memory\u201d we report the peak memory used by the model per single step of the simulation. DPI, MGN-Large-Radius and MGN results were reported by [4]. See Tables 3 and 4 for the exact numbers.", "description": "This figure compares the performance of SDF-Sim against other methods (DPI, MGN, MGN-Large-Radius, FIGNet, FIGNet*) on the Movi-B and Movi-C benchmarks in terms of accuracy (translation and rotation error), memory usage (peak memory), and runtime (per step).  It highlights that SDF-Sim achieves competitive accuracy while using significantly less memory and runtime, especially on the larger Movi-C dataset where many baselines run out of memory.  The y-axis scales are different for each metric to better present the results.", "section": "4 Results"}, {"figure_path": "QDYts5dYgq/figures/figures_13_2.jpg", "caption": "Figure 10: Distribution of mesh sizes used in Movi-C (930 objects).", "description": "This figure shows the distribution of the number of nodes and triangles in the meshes used for training SDFs (left) and simulation (right) for the Movi-C dataset from the Kubric benchmark.  The plots reveal that the meshes used for training are significantly larger and more complex, with a longer tail in the distribution, compared to the meshes used in the simulation itself. This difference is important because the complexity of the meshes directly influences the computational cost of traditional physics simulation and the memory usage of learned simulators like FIGNet. The SDF-Sim approach, which leverages implicit shape representations (SDFs), avoids this computational bottleneck.", "section": "A Datasets and custom simulations"}, {"figure_path": "QDYts5dYgq/figures/figures_18_1.jpg", "caption": "Figure S1: Additional metrics on SDF quality\n(a-c) Metrics computed across learned SDF models of different sizes for different objects in Movi-B.\nEach black marker denotes a different Movi-B shape. For each metric, loss decreases as we increase\nthe size of the model.\n(a) MSE between the projected surface points predicted from the learned SDFs and the true closest\npoint on the surface.\n(b) MSE between the signed distance outputted by the learned SDF and the true signed distance.\n(c) MSE between the gradient of the learned SDF and the gradient of the ground truth SDF function.\n(d-f) SDF evaluation metrics as a function of distance from the object surface. SDF\nerror, projection error and the gradient errors remain constant up to distance 0.2 from the object\nsurface and start to increase afterwards. Generally all errors remain low in comparison to the object\nsize of 0.5 meter.\n(d) Error as distance between the learned SDF projected surface point and the true closest surface\npoint, plotted as a function of signed distance from the surface.\n(e) Error as the absolute difference in magnitude between the learned SDF prediction and ground\ntruth SDF, plotted as a function of signed distance from the surface.\n(f) Error as the cosine distance between the gradient of learned SDF and the ground truth SDF\ngradient.", "description": "Figure S1 presents additional metrics evaluating the quality of learned Signed Distance Functions (SDFs) used in SDF-Sim.  The figure shows mean squared error (MSE) analyses for projection, SDF, and gradient values, comparing different SDF model sizes (32, 64, and 128 layers).  It also provides visualizations demonstrating how these errors relate to the distance from an object's surface. The results indicate that larger SDF models generally lead to improved accuracy, with errors remaining relatively low even near the object's surface, despite increasing slightly with greater distances. ", "section": "D Additional results"}, {"figure_path": "QDYts5dYgq/figures/figures_19_1.jpg", "caption": "Figure S2: Runtime per simulation step w.r.t. the total number of nodes in the scene. The runtime evaluations were performed on the Movi-C test set on Nvidia A100 GPU. FIGNet baseline runs OOM on Movi-C and is not shown here.", "description": "This figure shows the runtime per simulation step plotted against the total number of nodes in the scene's graph for both SDF-Sim and FIGNet*.  The results demonstrate that SDF-Sim consistently exhibits faster runtime compared to FIGNet*, especially as the number of nodes increases.  The experiment was conducted using an Nvidia A100 GPU, and FIGNet ran out of memory (OOM) on the Movi-C dataset and is therefore excluded from the comparison.", "section": "D.3 Runtime versus number of nodes in simulation graph"}, {"figure_path": "QDYts5dYgq/figures/figures_19_2.jpg", "caption": "Figure 7: Large-scale simulation of Spheres-in-Bowl, simulated for 200 timesteps. Left: the final step of SDF-Sim rollout on the scene with 512 spheres. Right: number of edges and runtime w.r.t. the number of spheres in the simulation (max 512). In complex simulations with lots of contacts, FIGNet and FIGNet* generate an excessive number of collision edges, quickly exceeding GPU memory (end of the orange and blue lines). SDF-Sim generates an order-of-magnitude fewer collision edges, and can easily simulate scenes with 100s of objects without running out of memory.", "description": "This figure demonstrates the scalability of SDF-Sim compared to other methods (FIGNet, FIGNet*).  The left panel shows a simulation with 512 spheres; the right shows how the number of edges and runtime scale with the number of spheres. SDF-Sim handles significantly more spheres and edges without running out of memory, unlike the other methods.", "section": "4 Results"}, {"figure_path": "QDYts5dYgq/figures/figures_20_1.jpg", "caption": "Figure S4: Memory footprint of storing the mesh versus storing the SDF weights w.r.t. the number of mesh nodes, evaluated on 930 objects from Movi-C.", "description": "This figure compares the memory usage of storing mesh data versus storing the parameters of learned signed distance functions (SDFs).  It shows that the memory footprint of meshes increases linearly with the number of nodes in the mesh, whereas the memory usage of SDFs remains relatively constant regardless of mesh complexity.  A circle highlights that an SDF model requires roughly the same memory as a mesh with ~15,000 nodes. This demonstrates the compactness of SDF representations for objects compared to traditional mesh representations.", "section": "D.5 Memory of the SDF versus a mesh"}, {"figure_path": "QDYts5dYgq/figures/figures_20_2.jpg", "caption": "Figure S5: Penetration and Rollout RMSE on Spheres-In-Bowl simulation. Bullet simulation is used as a ground-truth. This plot extends Figure 8 with an additional Bullet-perturbed baseline, where we add a tiny amount of gaussian noise to the initial states in Bullet simulation. (Left) SDF-Sim has smaller penetrations than Bullet, presumably because Bullet is optimized for speed instead. (Right) Both SDF-Sim and Bullet-perturbed eventually diverge from the original simulation, and the error of SDF-Sim is higher than Bullet-perturbed (as expected), but lower than FIGNet*. ", "description": "This figure compares the penetration and rollout RMSE for different simulators on the Spheres-in-Bowl dataset.  It shows that SDF-Sim has lower penetration than the Bullet simulator (optimized for speed).  Although the rollout error in SDF-Sim is higher than a perturbed Bullet simulation, it is lower than that of other learned simulators like FIGNet*.", "section": "D.6 Penetration and error comparison to Bullet"}, {"figure_path": "QDYts5dYgq/figures/figures_21_1.jpg", "caption": "Figure S6: Shoe object from Movi-C, with vertices shown in green: (a) the original high-resolution mesh for rendering, (b) collision mesh for simulation, (c) nodes sampled on a grid and projected to the learned SDF). We can achieve favorable tradeoffs between error (d) and node count (e) by varying the dimensions K of the sample grid (orange bars). The green bar represents SDF-Sim that uses the nodes from the original Movi-C collision mesh, as used elsewhere in the paper.", "description": "This figure shows a comparison of different node sampling strategies for representing a shoe object from the Movi-C dataset in the SDF-Sim model.  It compares using the original high-resolution mesh, a simplified collision mesh used for simulation, and a new method of sampling nodes directly from the learned SDF. The results demonstrate that sampling from the learned SDF offers a favorable trade-off between accuracy (translation RMSE) and the number of nodes required, leading to potentially significant computational savings.  The original mesh is shown for context, illustrating its high complexity compared to the alternative approaches.", "section": "D.7 Re-sampling object surface nodes using an SDF"}, {"figure_path": "QDYts5dYgq/figures/figures_23_1.jpg", "caption": "Figure S7: (a) Learned SDF reconstructions for randomly chosen Movi-C shapes. For visualisation purposes, we convert the object surface defined by a learned SDF: {y : fe(y) = 0} into a mesh using Marching Cubes and show this mesh here. (b) Corresponding ground-truth meshes.", "description": "This figure shows a comparison between learned SDF reconstructions and ground truth meshes for a selection of objects from the Movi-C dataset.  The left column (a) displays 3D models generated from learned Signed Distance Functions (SDFs). The right column (b) shows the original, ground truth meshes used to train the SDFs. The visual similarity highlights the effectiveness of the learned SDFs in representing object shapes.", "section": "E Learned SDF visualisations"}, {"figure_path": "QDYts5dYgq/figures/figures_24_1.jpg", "caption": "Figure S8: (a) Learned SDFs for Movi-B visualized at different points during training. (b) Learned SDFs for Movi-B visualized for different MLP sizes (different number of units per layer, all MLPs have 8 layers). For visualisation purposes in both figures, we convert the object surface defined by a learned SDF: {y : fe(y) = 0} into a mesh using Marching Cubes.", "description": "This figure shows the learned signed distance functions (SDFs) for different training iterations and model sizes.  The left side (a) demonstrates how the learned SDFs improve in accuracy with more training steps (4000, 40000, and 400000 iterations). The right side (b) displays the impact of model size (MLP layers with 32, 64, or 128 units) on the final SDF representation.  Each row represents a different object, illustrating the effect of training duration and model complexity on the resulting 3D shape representation.  The visualization uses Marching Cubes to convert the implicit SDF representation into a mesh for better understanding.", "section": "E Learned SDF visualisations"}, {"figure_path": "QDYts5dYgq/figures/figures_25_1.jpg", "caption": "Figure S9: Rollout comparisons between baselines and SDF-Sim on Kubric Movi-C.", "description": "This figure shows a comparison of simulation rollouts between the baselines (FIGNet*) and SDF-Sim on the Kubric Movi-C dataset.  It visually demonstrates the differences in the predicted object trajectories and how they compare to the ground truth. Each row represents a different method (ground truth, FIGNet*, SDF-Sim), with multiple columns showing the simulation progression over time for several different scenes within the dataset.", "section": "F Rollout Examples"}, {"figure_path": "QDYts5dYgq/figures/figures_26_1.jpg", "caption": "Figure S9: Rollout comparisons between baselines and SDF-Sim on Kubric Movi-C.", "description": "This figure compares the simulation results of three different methods: Ground truth, FIGNet*, and SDF-Sim, on the Kubric Movi-C dataset. Each row represents a different method, and each column shows the simulation at different timesteps.  This allows for a visual comparison of the accuracy of each method in predicting the motion of objects in a complex scene.", "section": "F Rollout Examples"}, {"figure_path": "QDYts5dYgq/figures/figures_27_1.jpg", "caption": "Figure S9: Rollout comparisons between baselines and SDF-Sim on Kubric Movi-C.", "description": "This figure shows a comparison of the simulation results between SDF-Sim and the baseline methods (FIGNet and FIGNet*) on the Kubric Movi-C dataset.  The figure displays several rollouts showing the movement of multiple objects over time. It visually compares the accuracy of the different methods in predicting the motion of the objects.", "section": "F Rollout Examples"}]