[{"figure_path": "pGEY8JQ3qx/tables/tables_2_1.jpg", "caption": "Table 1: Algorithms and sample complexity bounds for average reward MDPs with S states and A actions. The goal is finding an \u025b-optimal policy under a generative model. Here H := ||h*||span is the span of the optimal bias, Tunif is a uniform upper bound on mixing times of all policies, and D is the MDP diameter, with the relationships H < 8Tunif and H < D. B is the transient time parameter.", "description": "This table compares existing algorithms and their sample complexities for solving average reward Markov Decision Processes (MDPs) under a generative model.  It shows different methods used, their associated sample complexity bounds (expressed in terms of the number of states S, actions A, and other relevant parameters), and any assumptions required (such as uniform mixing times or weak communication).  The table also highlights the minimax optimality or suboptimality of these bounds, helping to situate the authors' contributions within the existing literature.  Key parameters include the span of the optimal bias function (H), the diameter of the MDP (D), a uniform mixing time bound (Tunif), and a new parameter introduced by the authors, B (transient time).", "section": "1.1 Comparison with related work on average-reward MDPs"}, {"figure_path": "pGEY8JQ3qx/tables/tables_6_1.jpg", "caption": "Table 1: Algorithms and sample complexity bounds for average reward MDPs with S states and A actions. The goal is finding an \u025b-optimal policy under a generative model. Here H := ||h*||span is the span of the optimal bias, Tunif is a uniform upper bound on mixing times of all policies, and D is the MDP diameter, with the relationships H < 8Tunif and H < D. B is the transient time parameter.", "description": "This table summarizes existing sample complexity results for average reward Markov Decision Processes (MDPs).  It compares different algorithms and their sample complexities using various parameters like diameter (D), uniform mixing time (Tunif), span of the optimal bias (H), and a new transient time parameter (B). The table highlights the assumptions made by each algorithm (e.g., uniform mixing times) and indicates whether the bound is minimax optimal.", "section": "1.1 Comparison with related work on average-reward MDPs"}]