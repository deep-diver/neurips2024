[{"figure_path": "3Odq2tGSpp/tables/tables_7_1.jpg", "caption": "Figure 10: Refiner's impact on End2End performance. Without a refiner, Stylus performs worse than SD v1.5 due to the poor quality of author-provided descriptions. Annotating adapters with GPT-40 significantly improves adapter descriptions and achieves higher CLIP/FID scores than Stylus's default refiner VLM, Gemini-Ultra.", "description": "This table presents the impact of different refiner models on the end-to-end performance of Stylus.  It compares the CLIP and FID scores for three scenarios: using no refiner, using a Gemini-Ultra refiner, and using a GPT-40 refiner. The scores are compared to the baseline Stable Diffusion v1.5 model.  The results demonstrate that using a better refiner (GPT-40) leads to significantly better results compared to using a weaker one (Gemini-Ultra) or no refiner at all.  The use of a strong refiner significantly improves the quality of adapter descriptions, leading to better overall performance.", "section": "4.3 Ablations"}, {"figure_path": "3Odq2tGSpp/tables/tables_19_1.jpg", "caption": "Table 1: Full prompt for the refiner VLM to generate better adapter descriptions.", "description": "This table displays the full prompt used for the vision-language model (VLM) in the refiner stage of the Stylus algorithm. The prompt guides the VLM to generate improved descriptions of adapters by categorizing the adapter's task and explaining how it modifies images within that context. The prompt is designed to encourage the VLM to provide structured and high-quality responses by decomposing the task into multiple steps.  This is done through a chain-of-thought approach, and provides examples to the model.", "section": "3.1 Refiner"}]