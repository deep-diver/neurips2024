[{"figure_path": "Oo7dlLgqQX/figures/figures_1_1.jpg", "caption": "Figure 1: We prompt language models with questions from the American Community Survey (ACS). We systematically compare models' survey responses to those of the U.S. Census.", "description": "This figure illustrates the methodology used in the paper.  The American Community Survey (ACS) is used as a benchmark to evaluate the responses of large language models (LLMs). The process starts with a question from the ACS, which is then given to a sample of the American population and the aggregate responses are collected.  The same question is also posed to an LLM to elicit its response. Finally, the figure asks whether the distribution of the LLM's responses is comparable to that of the human population. This comparison is central to the paper's analysis of the models' alignment to the human responses.", "section": "1 Introduction"}, {"figure_path": "Oo7dlLgqQX/figures/figures_4_1.jpg", "caption": "Figure 2: Entropy of base models' responses across the ACS questions for naive prompting. Entropy of models' responses (\u25c6) tends to increase log-linearly with model size, irrespective of the underlying response entropy observed in the U.S. census (-).", "description": "This figure displays the entropy of language model responses to the American Community Survey (ACS) questions.  The x-axis represents the model size, and the y-axis shows the entropy of the responses.  Each point represents a model's response to a question.  The figure demonstrates that the entropy of model responses generally increases with model size, following a roughly logarithmic trend. This increase in entropy is consistent across all questions, even though the entropy of human responses to the same questions varies substantially. The figure highlights a significant difference between the entropy of language model responses and the entropy of the corresponding U.S. Census data, implying that there might be systematic biases affecting model responses.", "section": "Systematic biases in models' survey responses"}, {"figure_path": "Oo7dlLgqQX/figures/figures_4_2.jpg", "caption": "Figure 2: Entropy of base models' responses across the ACS questions for naive prompting. Entropy of models' responses (\u25c6) tends to increase log-linearly with model size, irrespective of the underlying response entropy observed in the U.S. census (-).", "description": "This figure shows the entropy of language models' responses to the American Community Survey (ACS) questions.  The top panel (a) displays the entropy for five example questions, demonstrating that the entropy tends to increase with model size. The bottom panel (b) shows this trend across all ACS questions, with model size on the x-axis and normalized response entropy on the y-axis. This figure highlights the substantial differences in entropy between the models and the U.S. census data, indicating that model responses are not reflecting the true distribution of responses in the human population.  The models generally show much higher entropy, which suggests that the models are producing responses that are more uniform rather than reflecting the nuances found in the census data.", "section": "Systematic biases in models' survey responses"}, {"figure_path": "Oo7dlLgqQX/figures/figures_5_1.jpg", "caption": "Figure 3: A-bias of in model responses across ACS questions. Each dot corresponds to one of the 25 questions. Models are ordered by size. As a reference, the extreme points illustrate A-bias for a model that always answers 'A' and a model that never answers 'A'. All models suffer from substantial A-bias.", "description": "This figure shows the A-bias of various language models across 25 questions from the American Community Survey (ACS).  A-bias measures the tendency of a model to select the answer option labeled 'A', regardless of the question's content. Each dot represents a model's A-bias for a single question.  The models are ordered by their size (number of parameters). The figure highlights that all models exhibit a significant A-bias, indicating a systematic bias towards selecting option 'A'. This bias is not related to the questions' meaning, but rather to the position and labeling of answer choices.", "section": "Systematic biases in models' survey responses"}, {"figure_path": "Oo7dlLgqQX/figures/figures_6_1.jpg", "caption": "Figure 4: Entropy of model responses after adjustment. (top) Illustration of how adjustment is performed. We average models' responses over all possible answer orderings. (bottom) Entropy of models' responses after adjustment. Entropy of base models' responses is close to 1 (i.e., uniform). Instruction tuned-models exhibit substantially higher variations in entropy across questions.", "description": "The figure shows the entropy of model responses to the ACS questions after adjusting for ordering bias by averaging responses across all possible answer orderings. The top panel illustrates the adjustment process. The bottom panel shows that after adjustment, base models exhibit nearly uniform entropy across questions, while instruction-tuned models show substantially higher variance in entropy across questions.", "section": "4 Inspecting adjusted responses"}, {"figure_path": "Oo7dlLgqQX/figures/figures_7_1.jpg", "caption": "Figure 5: Divergence between adjusted model responses and different baselines: the overall U.S. census (x), individual U.S. states (), and a uniform baseline (\u2605). Smaller means more similar. Model responses are by far more similar to the uniform baseline than to any human reference population.", "description": "This figure displays the KL divergence between adjusted model responses and three different baselines: the overall US census, individual US states, and a uniform distribution.  The smaller the KL divergence, the more similar the model's response distribution is to the baseline.  The key finding is that across all models, the adjusted responses are far more similar to the uniform baseline than to any human population (US census or individual states). This highlights the significant difference between model and human response distributions, even when adjusting for systematic biases.", "section": "Inspecting adjusted responses"}, {"figure_path": "Oo7dlLgqQX/figures/figures_8_1.jpg", "caption": "Figure 6: Alignment of models with different census subgroups. All models tend to exhibit similar relative alignment, and the divergence metric decreases with the entropy of the subgroups' responses.", "description": "This figure shows the KL divergence between models' adjusted responses and different census subgroups (U.S. states) plotted against the entropy of the subgroups' responses.  The results reveal a strong negative correlation between the KL divergence and the entropy of the subgroups. This suggests that models are more similar to subgroups with higher entropy (more uniform responses) regardless of model architecture or training methods. This finding indicates that simple entropy, rather than specific demographic features, primarily accounts for alignment.", "section": "4 Inspecting adjusted responses"}, {"figure_path": "Oo7dlLgqQX/figures/figures_9_1.jpg", "caption": "Figure 6: Alignment of models with different census subgroups. All models tend to exhibit similar relative alignment, and the divergence metric decreases with the entropy of the subgroups' responses. Taken together our findings imply that the survey-derived alignment measure is more informative of differences in the reference populations rather than the language models is aims to evaluate. Model particularities, such as the pre-training data used, instruction tuning or the use of reinforcement learning with human feedback, seem to have little impact on which population is best represented.", "description": "This figure shows the relationship between the alignment of language models with different demographic subgroups and the entropy of those subgroups' responses.  The plots display the Kullback-Leibler (KL) divergence between model responses and various reference populations (overall U.S. census, individual states) for both unadjusted and adjusted model responses.  The main observation is that the model's alignment with a subgroup is strongly correlated with the entropy of that subgroup's responses, regardless of model size or training method (instruction tuning or RLHF). This suggests that alignment scores primarily reflect the entropy of the reference population rather than genuine model alignment with specific demographic characteristics.", "section": "4 Inspecting adjusted responses"}, {"figure_path": "Oo7dlLgqQX/figures/figures_15_1.jpg", "caption": "Figure 8: Normalized entropy of survey responses for individual questions (without adjustment).", "description": "This figure shows the normalized entropy of language models' responses to individual questions from the American Community Survey (ACS) without adjusting for response biases.  The x-axis represents model size, and the y-axis represents the normalized entropy of responses, which ranges from 0 to 1 (0 being completely deterministic and 1 being completely uniform). Each plot corresponds to a different ACS question. The green lines indicate the entropy of the human responses obtained from the U.S. Census, and the orange lines represent the uniform distribution (expected value of entropy if responses were random).  The plot shows that the entropy of responses differs substantially across questions, even when the questions are presented independently to the model, and the difference increases with model size.", "section": "3 Systematic biases in models' survey responses"}, {"figure_path": "Oo7dlLgqQX/figures/figures_15_2.jpg", "caption": "Figure 3: A-bias of in model responses across ACS questions. Each dot corresponds to one of the 25 questions. Models are ordered by size. As a reference, the extreme points illustrate A-bias for a model that always answers 'A' and a model that never answers 'A'. All models suffer from substantial A-bias.", "description": "This figure shows the A-bias (the tendency of a model to pick the answer choice labeled \"A\") for each question and model. Models are ordered by size.  The chart illustrates that all models exhibit substantial A-bias, indicating a systematic bias towards selecting the option labeled with 'A', regardless of the actual question or model size. This highlights a significant limitation in using survey responses directly from LLMs as a reliable representation of human opinions. ", "section": "3 Systematic biases in models' survey responses"}, {"figure_path": "Oo7dlLgqQX/figures/figures_16_1.jpg", "caption": "Figure 2: Entropy of base models' responses across the ACS questions for naive prompting. Entropy of models' responses (\u25c6) tends to increase log-linearly with model size, irrespective of the underlying response entropy observed in the U.S. census (-).", "description": "This figure displays two subfigures. Subfigure (a) shows the entropy of responses for five example questions from the American Community Survey (ACS) for different language models.  The x-axis represents the model size, and the y-axis represents the normalized entropy of the model responses.  The plot shows that the entropy tends to increase with model size, regardless of the inherent variability in responses for each question in the U.S. census data. Subfigure (b) extends this analysis to all ACS questions, showing the same trend of increasing entropy with model size, again highlighting a difference between model responses and the U.S. census distribution.", "section": "Systematic biases in models' survey responses"}, {"figure_path": "Oo7dlLgqQX/figures/figures_16_2.jpg", "caption": "Figure 2: Entropy of base models' responses across the ACS questions for naive prompting. Entropy of models' responses (\u25c6) tends to increase log-linearly with model size, irrespective of the underlying response entropy observed in the U.S. census (-).", "description": "This figure shows the entropy of language model responses to questions from the American Community Survey (ACS) when prompted in a naive way (without modifications to the prompt or answer order). The top panel shows entropy for five example questions. The bottom panel shows the entropy across all 25 questions for various models of different sizes. The plot highlights that entropy of model responses increases with model size, a trend that is independent of the actual distribution of answers in the US census data. This suggests that other factors (biases) play a larger role than the models' knowledge about human demographics when considering entropy.", "section": "Systematic biases in models' survey responses"}, {"figure_path": "Oo7dlLgqQX/figures/figures_17_1.jpg", "caption": "Figure 2: Entropy of base models' responses across the ACS questions for naive prompting. Entropy of models' responses (\u25c6) tends to increase log-linearly with model size, irrespective of the underlying response entropy observed in the U.S. census (-).", "description": "This figure shows the entropy of language models' responses to questions from the American Community Survey (ACS) when prompted without any randomization of answer order.  The top panel (a) displays the entropy for five specific ACS questions, demonstrating that the entropy increases with the model size for each question. The bottom panel (b) shows the entropy across all ACS questions, again demonstrating a log-linear increase in entropy with model size.  The U.S. census data is included as a baseline for comparison, revealing that the variability in entropy across the ACS questions is significantly lower for the language models than in the human population represented by the census data.", "section": "Systematic biases in models' survey responses"}, {"figure_path": "Oo7dlLgqQX/figures/figures_17_2.jpg", "caption": "Figure 3: A-bias of in model responses across ACS questions. Each dot corresponds to one of the 25 questions. Models are ordered by size. As a reference, the extreme points illustrate A-bias for a model that always answers 'A' and a model that never answers 'A'. All models suffer from substantial A-bias.", "description": "This figure shows the A-bias (the tendency of models to pick answer choice A) for different language models across 25 questions from the American Community Survey.  Each dot represents a model's A-bias for a single question, with models ordered by size. The extreme values (always answering A and never answering A) illustrate the range of possible A-biases. The figure demonstrates that all language models show a substantial A-bias.", "section": "Systematic biases in models' survey responses"}, {"figure_path": "Oo7dlLgqQX/figures/figures_19_1.jpg", "caption": "Figure 2: Entropy of base models' responses across the ACS questions for naive prompting. Entropy of models' responses (\u25c6) tends to increase log-linearly with model size, irrespective of the underlying response entropy observed in the U.S. census (-).", "description": "This figure displays two subfigures showing the entropy of the language models' responses to the American Community Survey (ACS) questions. Subfigure (a) shows the entropy for five specific questions across different model sizes, while subfigure (b) presents the entropy for all ACS questions ordered by model size.  The key finding is that the entropy of models' responses tends to increase log-linearly with model size, a trend that holds regardless of the inherent entropy present in the corresponding U.S. Census data. This suggests a potential systematic bias in the models' responses rather than a true reflection of the underlying data.", "section": "Systematic biases in models' survey responses"}, {"figure_path": "Oo7dlLgqQX/figures/figures_20_1.jpg", "caption": "Figure 2: Entropy of base models' responses across the ACS questions for naive prompting. Entropy of models' responses (\u25c6) tends to increase log-linearly with model size, irrespective of the underlying response entropy observed in the U.S. census (-).", "description": "This figure shows the entropy of language models' responses to American Community Survey (ACS) questions, plotted against the models' size (number of parameters).  The left panel (a) displays the entropy for five specific ACS questions across a range of model sizes. The right panel (b) shows the overall entropy across all ACS questions for various model sizes, highlighting the increase in entropy with model size. The figure also includes the entropy of the U.S. census responses as a reference, demonstrating that models' responses, even larger ones, exhibit higher variability than those found in actual human responses.", "section": "3 Systematic biases in models' survey responses"}, {"figure_path": "Oo7dlLgqQX/figures/figures_20_2.jpg", "caption": "Figure 16: The discriminator test performed on datasets generated using the 2016 ANES survey questionnaire (with choice randomization).", "description": "This figure displays the accuracy of a discriminator model in distinguishing between datasets of survey responses generated by various language models and responses from the 2016 American National Election Studies (ANES) survey.  The responses were generated using an interview-style prompting method with randomized choice ordering. High accuracy indicates significant differences between model-generated responses and human responses from the ANES dataset. The x-axis lists various language models, and the y-axis represents the accuracy of the discriminator in percentages.", "section": "Sequential sampling of responses"}, {"figure_path": "Oo7dlLgqQX/figures/figures_21_1.jpg", "caption": "Figure 17: Methodology and prompt template used to sequentially sample models' responses to entire survey questionnaires. We provide the answers to previous questions in context when prompting subsequent questions. The output is a tabular dataset of responses.", "description": "This figure illustrates the methodology used in the paper for sequentially sampling model responses to survey questions.  The process begins by asking a single question from the survey. The responses from the model are sampled, and the answer is recorded. This answer, along with the original question, is then included in the next prompt as context. This continues until the entire survey is completed. The result is a tabular dataset containing the models' responses to all questions in the survey.", "section": "F Sequential sampling of responses"}]