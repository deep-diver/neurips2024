[{"figure_path": "clTa4JFBML/tables/tables_5_1.jpg", "caption": "Table 1: RCG significantly improves the unconditional generation performance of current generative models, evaluated on ImageNet 256x256. All numbers are reported under the unconditional generation setting.", "description": "This table shows the improvement in unconditional image generation achieved by using the Representation-Conditioned Generation (RCG) framework.  It compares the Fr\u00e9chet Inception Distance (FID) and Inception Score (IS) for several different image generation models (LDM-8, ADM, DiT-XL/2, MAGE-B, MAGE-L) both with and without RCG. Lower FID scores indicate better image fidelity and higher IS scores indicate higher image diversity and quality.  The table highlights the significant reduction in FID achieved with RCG across all models, demonstrating its effectiveness in enhancing unconditional image generation.", "section": "4.1 Observations"}, {"figure_path": "clTa4JFBML/tables/tables_6_1.jpg", "caption": "Table 2: RCG largely improves the state-of-the-art in unconditional image generation on ImageNet 256x256. All numbers are reported under the unconditional generation setting. Following common practice, we report the number of parameters used during generation. \u2020 denotes semi-parametric methods which require ground-truth ImageNet images during generation.", "description": "This table compares the performance of RCG with other state-of-the-art unconditional image generation models on the ImageNet 256x256 dataset.  It shows that RCG significantly improves the FID (Frechet Inception Distance) and IS (Inception Score), key metrics for evaluating the quality and diversity of generated images.  The table highlights the significant reduction in FID achieved by RCG compared to previous methods, indicating a substantial improvement in image generation quality.  It also shows the number of parameters used by each model.", "section": "4 Experiments"}, {"figure_path": "clTa4JFBML/tables/tables_7_1.jpg", "caption": "Table 1: RCG significantly improves the unconditional generation performance of current generative models, evaluated on ImageNet 256\u00d7256. All numbers are reported under the unconditional generation setting.", "description": "This table presents a comparison of the unconditional image generation performance of several generative models, both with and without the proposed Representation-Conditioned Generation (RCG) method. The models compared include LDM-8, ADM, DiT-XL/2, and MAGE-L.  The performance is measured by FID (Frechet Inception Distance) and IS (Inception Score), common metrics for evaluating the quality and diversity of generated images.  Lower FID values and higher IS values indicate better performance. The table demonstrates that RCG significantly improves the FID and IS scores of all the models tested, showing its effectiveness in enhancing unconditional image generation.", "section": "4.1 Observations"}, {"figure_path": "clTa4JFBML/tables/tables_7_2.jpg", "caption": "Table 1: RCG significantly improves the unconditional generation performance of current generative models, evaluated on ImageNet 256\u00d7256. All numbers are reported under the unconditional generation setting.", "description": "This table compares the Fr\u00e9chet Inception Distance (FID) and Inception Score (IS) for unconditional image generation using several different generative models, both with and without the Representation-Conditioned Generation (RCG) framework proposed in the paper.  It demonstrates that RCG significantly improves the FID (lower is better) and IS (higher is better) scores across different models, highlighting the effectiveness of the RCG method for improving unconditional image generation.", "section": "4.1 Observations"}, {"figure_path": "clTa4JFBML/tables/tables_14_1.jpg", "caption": "Table 1: RCG significantly improves the unconditional generation performance of current generative models, evaluated on ImageNet 256x256. All numbers are reported under the unconditional generation setting.", "description": "This table presents a comparison of the unconditional image generation performance (measured by FID and IS) of several state-of-the-art generative models, both with and without the RCG framework. The results demonstrate that RCG consistently improves the performance of various generative models, regardless of their specific architecture, on the challenging ImageNet 256x256 dataset. The improvement in FID indicates a substantial increase in the quality and fidelity of the generated images, while the improved IS suggests a greater diversity of generated samples.", "section": "4.1 Observations"}, {"figure_path": "clTa4JFBML/tables/tables_14_2.jpg", "caption": "Table 1: RCG significantly improves the unconditional generation performance of current generative models, evaluated on ImageNet 256x256. All numbers are reported under the unconditional generation setting.", "description": "This table presents a comparison of the unconditional image generation performance (measured by FID and IS) of several generative models (LDM-8, ADM, DiT-XL/2, and MAGE-L) both with and without the proposed RCG framework. The results demonstrate that RCG consistently enhances the quality of unconditional image generation across different models, significantly reducing the FID scores.", "section": "4.1 Observations"}, {"figure_path": "clTa4JFBML/tables/tables_15_1.jpg", "caption": "Table 7: Distribution mapping ablation experiments. The default encoder is MoCo v3 ViT-B with 256 projection dimension. Default settings are marked in gray.", "description": "This table presents an ablation study on the image encoder component of the RCG framework.  It compares the performance (FID and IS scores) of the RCG model using different pre-trained encoders: MoCo v3, DINO, iBOT, and a supervised DeiT model.  The table also explores the impact of the projection dimension of the image representation on the model's performance.", "section": "B Additional Quantitative Results"}, {"figure_path": "clTa4JFBML/tables/tables_15_2.jpg", "caption": "Table 1: RCG significantly improves the unconditional generation performance of current generative models, evaluated on ImageNet 256x256. All numbers are reported under the unconditional generation setting.", "description": "This table presents a comparison of the unconditional image generation performance (measured by FID and IS) of four different generative models (LDM-8, ADM, DiT-XL/2, and MAGE-L) with and without the proposed RCG framework.  It demonstrates that RCG consistently improves the FID scores of all models, signifying a substantial enhancement in image generation quality. The improvement is substantial in all cases.", "section": "4.1 Observations"}, {"figure_path": "clTa4JFBML/tables/tables_15_3.jpg", "caption": "Table 1: RCG significantly improves the unconditional generation performance of current generative models, evaluated on ImageNet 256\u00d7256. All numbers are reported under the unconditional generation setting.", "description": "This table compares the FID and IS scores for unconditional image generation using four different image generator models (LDM-8, ADM, DiT-XL/2, and MAGE-L) with and without the RCG framework. The results demonstrate that RCG consistently improves the unconditional image generation quality regardless of the specific image generator used, significantly reducing the FID scores and increasing the IS scores.  The numbers in parentheses show the amount of improvement by RCG.", "section": "4.1 Observations"}, {"figure_path": "clTa4JFBML/tables/tables_16_1.jpg", "caption": "Table 10: CIFAR-10 and iNaturalist results. RCG consistently improves unconditional image generation performance on different datasets.", "description": "This table presents the FID scores achieved by different methods on CIFAR-10 and iNaturalist 2021 datasets.  The baseline represents the FID of unconditional image generation using the respective original model. The \"w/ RCG\" column shows the FID after applying the Representation-Conditioned Generation (RCG) method proposed in the paper.  The \"w/ class labels\" column indicates the FID obtained using the models with class labels as conditioning.", "section": "4.1 Observations"}, {"figure_path": "clTa4JFBML/tables/tables_17_1.jpg", "caption": "Table 1: RCG significantly improves the unconditional generation performance of current generative models, evaluated on ImageNet 256x256. All numbers are reported under the unconditional generation setting.", "description": "This table presents a comparison of the unconditional image generation performance (measured by FID and IS) of several generative models on ImageNet 256x256, both with and without the proposed Representation-Conditioned Generation (RCG) method.  It demonstrates that RCG significantly improves FID scores across different image generators, indicating its effectiveness in enhancing unconditional image generation quality.", "section": "4.1 Observations"}, {"figure_path": "clTa4JFBML/tables/tables_17_2.jpg", "caption": "Table 1: RCG significantly improves the unconditional generation performance of current generative models, evaluated on ImageNet 256\u00d7256. All numbers are reported under the unconditional generation setting.", "description": "This table presents a comparison of the unconditional image generation performance (measured by FID and IS) of four different generative models (LDM-8, ADM, DiT-XL/2, and MAGE-L) with and without the proposed Representation-Conditioned Generation (RCG) framework.  It demonstrates the substantial improvement in FID scores achieved by incorporating RCG across all four models, highlighting RCG's effectiveness in enhancing unconditional image generation quality.", "section": "4.1 Observations"}]