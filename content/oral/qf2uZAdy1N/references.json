{"references": [{"fullname_first_author": "Philip Amortila", "paper_title": "Mitigating Covariate Shift in Misspecified Regression With Applications to Reinforcement Learning", "publication_date": "2024", "reason": "This paper provides a crucial technical tool, the GOLF algorithm, used to establish the main positive result on statistical modularity for pushforward-coverable MDPs."}, {"fullname_first_author": "Simon Du", "paper_title": "Provably Efficient RL With Rich Observations via Latent State Decoding", "publication_date": "2019", "reason": "This foundational paper introduces the Block MDP framework, which this paper extends to a broader setting of general latent dynamics."}, {"fullname_first_author": "Akshay Krishnamurthy", "paper_title": "PAC Reinforcement Learning With Rich Observations", "publication_date": "2016", "reason": "This paper initiates the study of sample-efficient reinforcement learning under rich observations, providing the initial theoretical foundation upon which this paper builds."}, {"fullname_first_author": "Dylan J Foster", "paper_title": "Foundations of Reinforcement Learning and Interactive Decision Making", "publication_date": "2023", "reason": "This paper provides a valuable theoretical framework for understanding the statistical complexity of reinforcement learning, which is essential for analyzing the latent-dynamics problem."}, {"fullname_first_author": "Tengyang Xie", "paper_title": "The Role of Coverage in Online Reinforcement Learning", "publication_date": "2023", "reason": "This paper introduces the key notion of pushforward coverability, a critical structural condition that enables statistical tractability in the general latent-dynamics setting."}]}