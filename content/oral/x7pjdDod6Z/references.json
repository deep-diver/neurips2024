{"references": [{"fullname_first_author": "Ben Mildenhall", "paper_title": "Nerf: Representing scenes as neural radiance fields for view synthesis", "publication_date": "2020-00-00", "reason": "This foundational paper introduces NeRFs, a core concept that many of the techniques in this paper build upon."}, {"fullname_first_author": "Angel X Chang", "paper_title": "Shapenet: An information-rich 3d model repository", "publication_date": "2015-00-00", "reason": "This paper introduces ShapeNet, a large-scale 3D model dataset that many open-world 3D reconstruction methods are trained on."}, {"fullname_first_author": "Aditya Ramesh", "paper_title": "Zero-shot text-to-image generation", "publication_date": "2021-00-00", "reason": "This paper introduces a method for generating images from text prompts, which is a key component in the text-to-3D pipeline."}, {"fullname_first_author": "Matt Deitke", "paper_title": "Objaverse: A universe of annotated 3d objects", "publication_date": "2022-00-00", "reason": "This paper introduces Objaverse, a large-scale dataset of 3D objects that this paper uses for training and evaluation."}, {"fullname_first_author": "Ben Poole", "paper_title": "Dreamfusion: Text-to-3d using 2d diffusion", "publication_date": "2023-00-00", "reason": "This paper demonstrates that 2D diffusion models can be used to generate 3D objects from text prompts, a key idea that this paper also explores."}]}