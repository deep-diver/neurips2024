[{"figure_path": "SSCtCq2MH2/figures/figures_3_1.jpg", "caption": "Figure 1: Overview. (a) Continuum Generation: Given a series of multi-view images capturing a moving object, the motion-factorized dynamic 3D Gaussian network is trained to reconstruct the dynamic object as 3D Gaussian point sets across different time states. From the reconstructed results, we employ a coarse-to-fine strategy to generate density fields to recover the continuums and extract object surfaces. The continuum is endowed with Gaussian attributes to allow mask rendering. (b) Identification: The MPM simulates the trajectory with the initial continuum P(0) and the physical parameters \u0398. The simulated object surfaces and the rendered masks are then compared against the previously extracted surfaces (colored in blue) and the corresponding masks from the dataset. The differences are quantified to guide the parameter estimation process. (c) Simulation: Digital twin demonstrations are displayed. Simulated objects (colored by stress increasing from blue to red), characterized by the properties estimated from observation, exhibit behavior consistent with real-world objects.", "description": "This figure provides a high-level overview of the proposed pipeline, which consists of three main modules: Continuum Generation, Identification, and Simulation.  The Continuum Generation module uses a motion-factorized dynamic 3D Gaussian network to reconstruct the object's shape over time from multiple views and generates a continuum representation. The Identification module uses Material Point Method (MPM) simulation to estimate physical properties by comparing simulated and observed object shapes and masks. Finally, the Simulation module demonstrates the use of the estimated properties for realistic object behavior simulation, particularly showcasing a digital twin application in robotic grasping.", "section": "4 Method"}, {"figure_path": "SSCtCq2MH2/figures/figures_4_1.jpg", "caption": "Figure 2: The pipeline of the proposed dynamic 3D Gaussian network. The motion network backbone consists of 8 fully connected (FC) layers. The output of the motion block is fed to Nm heads to generate motion residuals. The coefficient network contains 4 FC layers.", "description": "This figure illustrates the architecture of the dynamic 3D Gaussian network, a key component of the proposed method. It shows how the network processes input data (time and initial Gaussian parameters) to generate updated Gaussian parameters for dynamic scene reconstruction. The network is composed of two main parts: a motion network and a coefficient network. The motion network decomposes the object's motion into multiple motion bases, and the coefficient network maps canonical positions and time to corresponding motion coefficients. These components are combined to produce updated Gaussian parameters for each point in the object at each time step, enabling accurate and efficient dynamic scene reconstruction.", "section": "4.2 Motion-factorized Dynamic 3D Gaussian Network"}, {"figure_path": "SSCtCq2MH2/figures/figures_5_1.jpg", "caption": "Figure 1: Overview. (a) Continuum Generation: Given a series of multi-view images capturing a moving object, the motion-factorized dynamic 3D Gaussian network is trained to reconstruct the dynamic object as 3D Gaussian point sets across different time states. From the reconstructed results, we employ a coarse-to-fine strategy to generate density fields to recover the continuums and extract object surfaces. The continuum is endowed with Gaussian attributes to allow mask rendering. (b) Identification: The MPM simulates the trajectory with the initial continuum P(0) and the physical parameters \u0398. The simulated object surfaces and the rendered masks are then compared against the previously extracted surfaces (colored in blue) and the corresponding masks from the dataset. The differences are quantified to guide the parameter estimation process. (c) Simulation: Digital twin demonstrations are displayed. Simulated objects (colored by stress increasing from blue to red), characterized by the properties estimated from observation, exhibit behavior consistent with real-world objects.", "description": "This figure provides a high-level overview of the proposed pipeline for physical property identification and simulation.  It shows three main stages: \n(a) Continuum Generation:  Reconstruction of a dynamic object from multiple views using a motion-factorized dynamic 3D Gaussian network, generating density fields, and extracting surfaces. Gaussian attributes are added for mask rendering during simulation. \n(b) Identification:  MPM simulation using the initial continuum and physical parameters, comparing simulated results (surfaces and masks) to extracted ground truth for parameter estimation. \n(c) Simulation:  Illustrative simulation results of the digital twin showing behavior consistent with real-world objects.", "section": "4 Method"}, {"figure_path": "SSCtCq2MH2/figures/figures_7_1.jpg", "caption": "Figure 1: Overview. (a) Continuum Generation: Given a series of multi-view images capturing a moving object, the motion-factorized dynamic 3D Gaussian network is trained to reconstruct the dynamic object as 3D Gaussian point sets across different time states. From the reconstructed results, we employ a coarse-to-fine strategy to generate density fields to recover the continuums and extract object surfaces. The continuum is endowed with Gaussian attributes to allow mask rendering. (b) Identification: The MPM simulates the trajectory with the initial continuum P(0) and the physical parameters \u0398. The simulated object surfaces and the rendered masks are then compared against the previously extracted surfaces (colored in blue) and the corresponding masks from the dataset. The differences are quantified to guide the parameter estimation process. (c) Simulation: Digital twin demonstrations are displayed. Simulated objects (colored by stress increasing from blue to red), characterized by the properties estimated from observation, exhibit behavior consistent with real-world objects.", "description": "This figure provides a high-level overview of the proposed pipeline for physical property identification and simulation.  It shows three main stages: 1) Continuum generation: reconstructing the object's shape and generating a continuum representation using a motion-factorized dynamic 3D Gaussian network and a coarse-to-fine filling strategy. 2) Identification: using the Material Point Method (MPM) to simulate the object's motion and comparing it to the observations to estimate physical parameters. 3) Simulation: showcasing the ability of the pipeline to simulate realistic object behavior based on the estimated parameters. The figure is divided into three subfigures to illustrate these three steps.", "section": "4 Method"}, {"figure_path": "SSCtCq2MH2/figures/figures_9_1.jpg", "caption": "Figure 1: Overview. (a) Continuum Generation: Given a series of multi-view images capturing a moving object, the motion-factorized dynamic 3D Gaussian network is trained to reconstruct the dynamic object as 3D Gaussian point sets across different time states. From the reconstructed results, we employ a coarse-to-fine strategy to generate density fields to recover the continuums and extract object surfaces. The continuum is endowed with Gaussian attributes to allow mask rendering. (b) Identification: The MPM simulates the trajectory with the initial continuum P(0) and the physical parameters \u0398. The simulated object surfaces and the rendered masks are then compared against the previously extracted surfaces (colored in blue) and the corresponding masks from the dataset. The differences are quantified to guide the parameter estimation process. (c) Simulation: Digital twin demonstrations are displayed. Simulated objects (colored by stress increasing from blue to red), characterized by the properties estimated from observation, exhibit behavior consistent with real-world objects.", "description": "This figure provides a high-level overview of the proposed pipeline for physical property identification and simulation using Gaussian-informed continuums. It shows three main modules: continuum generation from multi-view images using a motion-factorized dynamic 3D Gaussian network; physical property identification by comparing simulated and observed object surfaces and masks; and simulation demonstrating the effectiveness of the estimated properties in a digital twin setting.", "section": "4 Method"}, {"figure_path": "SSCtCq2MH2/figures/figures_15_1.jpg", "caption": "Figure 7: Visualization of Coarse-to-fine Filling. (a)-(d) are the filling results by our method with different times of upsampling operations. (e) visualize the point clouds recovered by PAC-NeRF. (f) shows the ground-truth shapes.", "description": "This figure shows a comparison of the coarse-to-fine filling strategy used in the proposed method with different numbers of upsampling steps (a-d), along with the results from PAC-NeRF (e) and the ground truth shapes (f).  The images visually demonstrate how the iterative upsampling and smoothing operations refine the density field, resulting in more accurate shape representations compared to PAC-NeRF, which tends to recover overly large shapes.", "section": "4.3 Gaussian-informed Continnum Generation"}, {"figure_path": "SSCtCq2MH2/figures/figures_17_1.jpg", "caption": "Figure 1: Overview. (a) Continuum Generation: Given a series of multi-view images capturing a moving object, the motion-factorized dynamic 3D Gaussian network is trained to reconstruct the dynamic object as 3D Gaussian point sets across different time states. From the reconstructed results, we employ a coarse-to-fine strategy to generate density fields to recover the continuums and extract object surfaces. The continuum is endowed with Gaussian attributes to allow mask rendering. (b) Identification: The MPM simulates the trajectory with the initial continuum P(0) and the physical parameters \u0398. The simulated object surfaces and the rendered masks are then compared against the previously extracted surfaces (colored in blue) and the corresponding masks from the dataset. The differences are quantified to guide the parameter estimation process. (c) Simulation: Digital twin demonstrations are displayed. Simulated objects (colored by stress increasing from blue to red), characterized by the properties estimated from observation, exhibit behavior consistent with real-world objects.", "description": "This figure provides a high-level overview of the proposed pipeline for physical property identification and simulation. It illustrates the three main modules: continuum generation using a motion-factorized dynamic 3D Gaussian network, physical property identification by comparing simulated and observed object shapes and masks, and simulation for digital twin demonstrations. The process starts with multi-view video capture, then proceeds to continuum generation, physical parameter identification and finally simulation with the estimated parameters.", "section": "4 Method"}, {"figure_path": "SSCtCq2MH2/figures/figures_18_1.jpg", "caption": "Figure 5: Real-world application. Left: Identification and future state simulation. Right: Grasping simulation. The stress on the simulated object is indicated by blue (low) to red (high). The gripper widths from top to bottom are set to 6cm, 4.5cm, and 3.5cm, respectively.", "description": "This figure shows a real-world application of the proposed method. The left side demonstrates the identification and future state simulation, where the object's physical properties are first identified, and then used to simulate its future behavior.  The right side depicts a robotic grasping simulation, showing how the estimated properties and simulation results are used to perform realistic grasps with different gripper widths (6cm, 4.5cm, and 3.5cm). The color of the simulated object indicates the stress level, with blue representing low stress and red representing high stress.", "section": "5.3 Real-world Application: Digital Twins in Robotic Grasping Scenario"}]