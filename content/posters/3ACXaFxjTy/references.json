{"references": [{"fullname_first_author": "Prafulla Dhariwal", "paper_title": "Diffusion models beat gans on image synthesis", "publication_date": "2021-12-01", "reason": "This paper is foundational to the field of diffusion models, demonstrating their superior performance over GANs in image synthesis, making it highly influential to the current work."}, {"fullname_first_author": "Robin Rombach", "paper_title": "High-resolution image synthesis with latent diffusion models", "publication_date": "2022-06-01", "reason": "This paper introduces Latent Diffusion Models (LDMs), a key advancement upon diffusion models that significantly improves efficiency and resolution, directly impacting the current study's methodology."}, {"fullname_first_author": "Alexander Kirillov", "paper_title": "Segment anything", "publication_date": "2023-07-01", "reason": "The Segment Anything Model (SAM) is a crucial foundation model for few-shot semantic segmentation, a direct antecedent to the current work, whose methodology is adapted and extended here."}, {"fullname_first_author": "Alec Radford", "paper_title": "Learning transferable visual models from natural language supervision", "publication_date": "2021-07-01", "reason": "CLIP, introduced in this paper, provides a powerful mechanism for connecting image and text features, directly utilized in the current work for cross-modal interaction and information fusion."}, {"fullname_first_author": "Yang Liu", "paper_title": "Matcher: Segment anything with one shot using all-purpose feature matching", "publication_date": "2024-01-01", "reason": "This is a concurrent work directly related to the current paper, addressing the same problem of few-shot semantic segmentation using a similar approach, providing a strong comparative benchmark."}]}