[{"figure_path": "f70e6YYFHF/tables/tables_5_1.jpg", "caption": "Table 1: Exact match accuracy of different training paradigms on (Top) the retrieval task and (Bottom) relationship task. Due to the non-reciprocal nature of the relationship, a model that swaps the subject and object will make errors (e.g., inferring B is A's child from A being B's child). Shown in the bottom row. Entity reversal without a delimiter is marked with a*. Maximum values are bold.", "description": "This table presents the results of experiments comparing different training methods (AR, AR with reversed sequences, MLM, and MLM-U) on two tasks: a simple retrieval task and a more complex relationship task. The retrieval task involves retrieving a key given a value or vice versa. The relationship task involves understanding asymmetric relationships between entities. The table shows that MLM-U, a factorization-agnostic method, significantly outperforms other methods on both tasks, especially in cases involving backward retrieval or understanding asymmetric relationships.", "section": "3.1 Controlled Experiments in Factorization-Agnostic Training"}, {"figure_path": "f70e6YYFHF/tables/tables_5_2.jpg", "caption": "Table 1: Exact match accuracy of different training paradigms on (Top) the retrieval task and (Bottom) relationship task. Due to the non-reciprocal nature of the relationship, a model that swaps the subject and object will make errors (e.g., inferring B is A's child from A being B's child). Shown in the bottom row. Entity reversal without a delimiter is marked with a*. Maximum values are bold.", "description": "This table presents the results of experiments evaluating different training methods on two tasks: a simple retrieval task and a more complex relationship task.  The retrieval task tests the model's ability to retrieve information given a key and value, in both forward and reverse order.  The relationship task tests whether the model understands non-reciprocal relationships\u2014that is, relationships that don't work both ways. The table compares standard autoregressive (AR) training, AR training with reversed sequences, masked language modeling (MLM), and a novel uniform-rate MLM (MLM-U). The results highlight the superior performance of MLM-U in handling non-reciprocal relationships, illustrating its ability to resolve the 'reversal curse'.", "section": "3.1 Controlled Experiments in Factorization-Agnostic Training"}, {"figure_path": "f70e6YYFHF/tables/tables_6_1.jpg", "caption": "Table 3: Wikireversal task exact match QA accuracies. MLM-U, MLM and AR are are 100M parameter models trained from scratch.", "description": "This table shows the accuracy of different models (Mistral 7B, MLM, MLM-U, and AR) on a question answering task using the WikiReversal dataset.  The WikiReversal dataset consists of passages and corresponding forward and backward questions extracted from Wikipedia articles.  The table shows that MLM-U performs significantly better on the backward questions, demonstrating its robustness to the reversal curse.", "section": "3.2 Wikipedia Knowledge Graph Reversal"}, {"figure_path": "f70e6YYFHF/tables/tables_7_1.jpg", "caption": "Figure 5: Star Graph Task: Illustration and Performance Comparison. The illustration shows the \"Clever Hans\" failure mode with teacher-forced AR ((Bachmann & Nagarajan, 2024) adapted).", "description": "This table presents the results of a simple path-finding task designed to test the planning capabilities of language models.  The task involves predicting the sequence of nodes along a path leading to a specified final node, given a symbolic representation of the graph. The table compares the performance of standard autoregressive (AR) training, AR with reversed sequences, and MLM-U (Uniform Rate Masked Language Modeling) which is factorization-agnostic.  The results show that MLM-U significantly outperforms the other methods, demonstrating its ability to perform planning tasks effectively.", "section": "4 On the Importance of Future Predictions for Planning"}, {"figure_path": "f70e6YYFHF/tables/tables_14_1.jpg", "caption": "Table 4: Summary of qualitative results, formatted as (forward)/(backward). Stargraph only has one direction.", "description": "This table summarizes the performance of different training methods (MLM, MLM-U, AR, AR with reversed sequences, AR with reversed entities) across various tasks (Retrieval, Relationship, BioS, Wiki, Stargraph). Each cell represents whether the method successfully performed the task in the forward and backward directions, indicated by \u2713 (success) and X (failure). The ~ symbol in the Wiki task indicates that MLM-U's performance was not strong enough to declare success or failure unequivocally.  The table highlights the strengths and weaknesses of each method in different scenarios, showcasing the effects of training objective and data characteristics on the ability to retrieve information in various directions.", "section": "3 Experiments"}, {"figure_path": "f70e6YYFHF/tables/tables_14_2.jpg", "caption": "Table 5: Retrieval Task forward and backward per token accuracy of different training paradigms.", "description": "This table presents the per-token accuracy results for a retrieval task, broken down by training method (AR, AR with reversed sequences, MLM with various masking rates, MLM-U, and PLM).  It shows the accuracy for both forward (predicting the value given the key) and backward (predicting the key given the value) directions. The results highlight the differences in performance between various training methods.  Specifically, it shows how MLM-U and PLM achieve near-perfect accuracy in both directions, whereas others struggle with the backward direction.", "section": "3.1 Controlled Experiments in Factorization-Agnostic Training"}, {"figure_path": "f70e6YYFHF/tables/tables_14_3.jpg", "caption": "Table 6: BioS exact match accuracy for property retrieval in the backward direction (birth date to full name) and in the forward direction (full name to birthdate).", "description": "This table presents the results of the BioS experiment, focusing on the accuracy of property retrieval in both forward and backward directions.  The forward direction involves predicting the full name given the birthdate, while the backward direction predicts the birthdate given the full name. Different training methods (AR, AR w/reverse, MLM variants, PLM, and MLM-U) are compared to assess their effectiveness in handling both directions of the task. The table shows that MLM-U achieves the best performance, with the autoregressive methods (AR) failing completely in the backward direction.", "section": "3.1 Controlled Experiments in Factorization-Agnostic Training"}, {"figure_path": "f70e6YYFHF/tables/tables_15_1.jpg", "caption": "Table 1: Exact match accuracy of different training paradigms on (Top) the retrieval task and (Bottom) relationship task. Due to the non-reciprocal nature of the relationship, a model that swaps the subject and object will make errors (e.g., inferring B is A's child from A being B's child). Shown in the bottom row. Entity reversal without a delimiter is marked with a*. Maximum values are bold.", "description": "This table presents the results of experiments comparing different training methods (Autoregressive (AR), AR with reversed sequences, Masked Language Modeling (MLM) with different masking rates, and Uniform-Rate MLM (MLM-U)) on two tasks: a simple retrieval task and a relationship task.  The retrieval task evaluates the models' ability to retrieve information regardless of the order it was presented during training, while the relationship task assesses the models' understanding of asymmetric relationships. The results showcase the effectiveness of MLM-U in handling both symmetric and asymmetric relationships, while AR and reversed sequence AR training methods exhibit limitations, particularly in handling asymmetric relationships.", "section": "3.1 Controlled Experiments in Factorization-Agnostic Training"}, {"figure_path": "f70e6YYFHF/tables/tables_15_2.jpg", "caption": "Table 3: Wikireversal task exact match QA accuracies. MLM-U, MLM and AR are are 100M parameter models trained from scratch.", "description": "This table presents the results of a question-answering task on the WikiReversal dataset.  The task involves answering questions about factual knowledge in both forward and backward directions.  Three different model training objectives are compared: MLM-U (uniform-rate masked language modeling), MLM (standard masked language modeling), and AR (autoregressive).  Mistral 7B is included as a larger pretrained model, finetuned on the dataset. The table shows that MLM-U significantly outperforms other models, especially in answering backward questions which test the model's ability to retrieve information based on later rather than prior context.  This demonstrates that factorization-agnostic training is better at knowledge retrieval compared to the common left-to-right training used in most LLMs.", "section": "3.2 Wikipedia Knowledge Graph Reversal"}, {"figure_path": "f70e6YYFHF/tables/tables_17_1.jpg", "caption": "Table 9: Examples from Wikireversal", "description": "This table presents example passages from the Wikireversal dataset, along with their corresponding forward and backward questions.  The forward questions query the tail of a relation triple, while the backward questions query the head. This illustrates the challenge of the reversal curse, where the model struggles to answer questions when the information is presented in a different order than during training.", "section": "3.2 Wikipedia Knowledge Graph Reversal"}, {"figure_path": "f70e6YYFHF/tables/tables_18_1.jpg", "caption": "Table 10: Relations in Wikireversal", "description": "This table lists the different relations present in the WikiReversal dataset and their respective counts.  The relations represent connections between entities in the dataset, such as \"birthPlace\" linking a person to their birthplace. The counts indicate how many times each relation appears in the dataset.", "section": "3.2 Wikipedia Knowledge Graph Reversal"}]