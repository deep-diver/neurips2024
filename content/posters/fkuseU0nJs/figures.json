[{"figure_path": "fkuseU0nJs/figures/figures_3_1.jpg", "caption": "Figure 1: Depiction of the proposed active learning-integrated method. Demonstrates the high-level ASNPE pipeline. Samples \u03b8i are drawn from sequentially updated proposal distributions p(\u03b8), filtered according to the acquisition function \u03b1(\u03b81:N, p(\u03c6|D)), and run through the simulator p(x|\u03b8) to generate B pairs (\u03b8i, xi) for training the approximate posterior q\u03c6. The learned posterior is then conditioned by the target observation x\u2080, producing the next round\u2019s proposal p(\u03b8) = q\u03c6(\u03b8|x\u2080).", "description": "This figure shows a high-level overview of the Active Sequential Neural Posterior Estimation (ASNPE) method. It illustrates how samples are drawn from a proposal distribution, filtered based on an acquisition function, and then used to train a neural density estimator to approximate the posterior distribution. The updated posterior is then used to generate a new proposal distribution for the next iteration.", "section": "Methodology"}, {"figure_path": "fkuseU0nJs/figures/figures_6_1.jpg", "caption": "Figure 1: Depiction of the proposed active learning-integrated method. Demonstrates the high-level ASNPE pipeline. Samples \u03b8\u2081 are drawn from sequentially updated proposal distributions p(0), filtered according to the acquisition function \u03b1(01:N, p($|D)), and run through the simulator p(x|0) to generate B pairs (\u03b8i, xi) for training the approximate posterior q4. The learned posterior is then conditioned by the target observation xo, producing the next round's proposal p(0) = q\u00a2(0|xo).", "description": "This figure shows a high-level overview of the Active Sequential Neural Posterior Estimation (ASNPE) pipeline.  It illustrates how samples are actively selected based on an acquisition function, simulated using a model, and then used to train a neural density estimator to approximate the posterior distribution. The updated posterior is then used to guide the selection of subsequent samples, creating a sequential process.", "section": "Methodology"}, {"figure_path": "fkuseU0nJs/figures/figures_7_1.jpg", "caption": "Figure 3: Plots of the (averaged) calibration horizons for each of the evaluated methods on the Prior I, Hours 5:00-6:00, Congestion level A scenario. (a) RMSN(E) scores reached throughout the 128 sample simulation horizon for each evaluated method, averaged over five repeated trials (mean line plotted) and with error bars calculated as bootstrapped 95% confidence intervals. (b) The same scores shown in (a), but instead plotted against the wallclock time passed before the score was reached (for each method\u2019s single best run). Note that the full 128-sample method trajectories are included, and the variability in line lengths demonstrates both 1) the impact of NPE-based methods\u2019 ability to run simulations in parallel, and 2) noisiness in simulation runtimes due to the variable inputs explored by each method. See Appendix E for all scenario plots.", "description": "This figure compares different methods for calibrating origin-destination matrices in a traffic simulation model. It shows the root mean squared normalized error (RMSNE) achieved by each method over a simulation horizon of 128 samples. Subplot (a) shows the RMSNE as a function of the number of simulation samples, while subplot (b) shows the RMSNE as a function of wall-clock time. The figure demonstrates that the proposed ASNPE method achieves lower RMSNE scores than other methods, both in terms of the number of samples and wall-clock time, especially when using NPE-based methods that allow for parallelization.", "section": "4.1 Experimental setup"}, {"figure_path": "fkuseU0nJs/figures/figures_14_1.jpg", "caption": "Figure 3: Plots of the (averaged) calibration horizons for each of the evaluated methods on the Prior I, Hours 5:00-6:00, Congestion level A scenario. (a) RMSNE scores reached throughout the 128 sample simulation horizon for each evaluated method, averaged over five repeated trials (mean line plotted) and with error bars calculated as bootstrapped 95% confidence intervals. (b) The same scores shown in (a), but instead plotted against the wallclock time passed before the score was reached (for each method\u2019s single best run). Note that the full 128-sample method trajectories are included, and the variability in line lengths demonstrates both 1) the impact of NPE-based methods\u2019 ability to run simulations in parallel, and 2) noisiness in simulation runtimes due to the variable inputs explored by each method. See Appendix E for all scenario plots.", "description": "This figure compares the performance of different OD calibration methods across two metrics: RMSNE score and wall-clock time.  It shows that ASNPE achieves lower RMSNE scores and faster convergence compared to other methods, highlighting its efficiency in a parallel computing environment.  The plots are broken down by different prior settings and congestion levels to showcase the method's robustness and effectiveness under varying conditions.", "section": "4.1 Experimental setup"}, {"figure_path": "fkuseU0nJs/figures/figures_15_1.jpg", "caption": "Figure 1: Depiction of the proposed active learning-integrated method. Demonstrates the high-level ASNPE pipeline. Samples \u03b8i are drawn from sequentially updated proposal distributions p(\u03b8), filtered according to the acquisition function \u03b1(\u03b81:N, p(\u03c6|D)), and run through the simulator p(x|\u03b8) to generate B pairs (\u03b8i, xi) for training the approximate posterior q\u03c6. The learned posterior is then conditioned by the target observation x\u2080, producing the next round\u2019s proposal p(\u03b8) = q\u03c6(\u03b8|x\u2080).", "description": "This figure shows a high-level overview of the Active Sequential Neural Posterior Estimation (ASNPE) method.  It illustrates how samples are drawn from sequentially updated proposal distributions, filtered based on an acquisition function, and passed through a simulator to generate data for training a neural density estimator. The trained estimator then conditions on the target observation to produce the next round's proposal distribution.  The process iteratively refines the posterior estimation.", "section": "Methodology"}, {"figure_path": "fkuseU0nJs/figures/figures_15_2.jpg", "caption": "Figure 1: Depiction of the proposed active learning-integrated method. Demonstrates the high-level ASNPE pipeline. Samples \u03b8\u1d62 are drawn from sequentially updated proposal distributions p(\u03b8), filtered according to the acquisition function \u03b1(\u03b8\u2081,N, p(\u03c6|D)), and run through the simulator p(x|\u03b8) to generate B pairs (\u03b8\u1d62, x\u1d62) for training the approximate posterior q\u03c6. The learned posterior is then conditioned by the target observation x\u2080, producing the next round's proposal p(\u03b8) = q\u03c6(\u03b8|x\u2080).", "description": "This figure shows a high-level overview of the ASNPE (Active Sequential Neural Posterior Estimation) pipeline.  It illustrates how samples are actively selected based on an acquisition function, then simulated to improve the accuracy of the posterior estimation. The process iteratively refines the proposal distribution to focus on more informative parameter regions.", "section": "Methodology"}, {"figure_path": "fkuseU0nJs/figures/figures_17_1.jpg", "caption": "Figure 1: Depiction of the proposed active learning-integrated method. Demonstrates the high-level ASNPE pipeline. Samples \u03b8i are drawn from sequentially updated proposal distributions p(\u03b8), filtered according to the acquisition function \u03b1(\u03b81:N, p(\u03c6|D)), and run through the simulator p(x|\u03b8) to generate B pairs (\u03b8i, xi) for training the approximate posterior q\u03c6. The learned posterior is then conditioned by the target observation xo, producing the next round\u2019s proposal p(\u03b8) = q\u03c6(\u03b8|xo).", "description": "This figure is a flowchart showing the steps involved in the proposed active sequential neural posterior estimation (ASNPE) method.  It illustrates how the algorithm iteratively refines the posterior distribution by actively selecting informative samples, simulating them using the model, and updating the neural density estimator (NDE). The key steps are: 1) drawing samples from a proposal distribution, 2) filtering samples based on an acquisition function, 3) simulating the filtered samples, 4) training the NDE using the generated data, 5) updating the proposal distribution based on the NDE, and iterating steps 1-5. This active sampling approach is designed to improve sample efficiency, especially for high-dimensional problems.", "section": "Methodology"}, {"figure_path": "fkuseU0nJs/figures/figures_18_1.jpg", "caption": "Figure 3: Plots of the (averaged) calibration horizons for each of the evaluated methods on the Prior I, Hours 5:00-6:00, Congestion level A scenario. (a) RMSN(E) scores reached throughout the 128 sample simulation horizon for each evaluated method, averaged over five repeated trials (mean line plotted) and with error bars calculated as bootstrapped 95% confidence intervals. (b) The same scores shown in (a), but instead plotted against the wallclock time passed before the score was reached (for each method\u2019s single best run). Note that the full 128-sample method trajectories are included, and the variability in line lengths demonstrates both 1) the impact of NPE-based methods\u2019 ability to run simulations in parallel, and 2) noisiness in simulation runtimes due to the variable inputs explored by each method. See Appendix E for all scenario plots.", "description": "This figure compares the performance of different OD calibration methods (SPSA, PC-SPSA, MC-ABC, SNPE, ASNPE) across 128 simulation samples.  It shows the root mean squared normalized error (RMSNE) achieved over time, both in terms of the number of simulation samples and the wall-clock time taken. The plots illustrate the impact of parallel processing capabilities of NPE-based methods (SNPE and ASNPE) and the variability in simulation runtimes, providing insights into the trade-offs between sample efficiency and computational cost.", "section": "Experimental results"}, {"figure_path": "fkuseU0nJs/figures/figures_18_2.jpg", "caption": "Figure 3: Plots of the (averaged) calibration horizons for each of the evaluated methods on the Prior I, Hours 5:00-6:00, Congestion level A scenario. (a) RMSN(E) scores reached throughout the 128 sample simulation horizon for each evaluated method, averaged over five repeated trials (mean line plotted) and with error bars calculated as bootstrapped 95% confidence intervals. (b) The same scores shown in (a), but instead plotted against the wallclock time passed before the score was reached (for each method\u2019s single best run). Note that the full 128-sample method trajectories are included, and the variability in line lengths demonstrates both 1) the impact of NPE-based methods\u2019 ability to run simulations in parallel, and 2) noisiness in simulation runtimes due to the variable inputs explored by each method. See Appendix E for all scenario plots.", "description": "This figure compares the performance of different OD calibration methods (MC-ABC, SPSA, PC-SPSA, SNPE, and ASNPE) in terms of root mean squared normalized error (RMSNE) achieved within a simulation horizon of 128 samples. Subplot (a) shows the RMSNE scores as a function of the number of simulation samples, while subplot (b) shows the same scores as a function of wall-clock time. The variability in line lengths highlights the parallel processing capabilities of NPE-based methods and the noise in simulation times due to varying input parameters.", "section": "Experimental results"}, {"figure_path": "fkuseU0nJs/figures/figures_19_1.jpg", "caption": "Figure 3: Plots of the (averaged) calibration horizons for each of the evaluated methods on the Prior I, Hours 5:00-6:00, Congestion level A scenario. (a) RMSN(E) scores reached throughout the 128 sample simulation horizon for each evaluated method, averaged over five repeated trials (mean line plotted) and with error bars calculated as bootstrapped 95% confidence intervals. (b) The same scores shown in (a), but instead plotted against the wallclock time passed before the score was reached (for each method's single best run). Note that the full 128-sample method trajectories are included, and the variability in line lengths demonstrates both 1) the impact of NPE-based methods\u2019 ability to run simulations in parallel, and 2) noisiness in simulation runtimes due to the variable inputs explored by each method. See Appendix E for all scenario plots.", "description": "This figure compares the performance of different OD calibration methods (SPSA, PC-SPSA, MC-ABC, SNPE, ASNPE) in terms of RMSNE scores achieved within a 128-sample simulation budget for a specific scenario (Prior 1, Hours 5:00-6:00, Congestion level A). Subplot (a) shows RMSNE scores over the number of simulation samples, while subplot (b) shows the same scores against wall-clock time, highlighting the impact of parallelization and simulation runtime variability. Error bars represent bootstrapped 95% confidence intervals.", "section": "Experimental results"}, {"figure_path": "fkuseU0nJs/figures/figures_20_1.jpg", "caption": "Figure 1: Depiction of the proposed active learning-integrated method. Demonstrates the high-level ASNPE pipeline. Samples \u03b8i are drawn from sequentially updated proposal distributions p(\u03b8), filtered according to the acquisition function \u03b1(\u03b81:N, p(\u03c6|D)), and run through the simulator p(x|\u03b8) to generate B pairs (\u03b8i, xi) for training the approximate posterior q\u03c6. The learned posterior is then conditioned by the target observation x\u2080, producing the next round's proposal p(\u03b8) = q\u03c6(\u03b8|x\u2080).", "description": "This figure shows a high-level overview of the Active Sequential Neural Posterior Estimation (ASNPE) pipeline. It illustrates how samples are drawn from sequentially updated proposal distributions, filtered using an acquisition function, and passed through a simulator to generate pairs for posterior estimation. The process iteratively refines the posterior approximation using active learning.", "section": "3 Methodology"}, {"figure_path": "fkuseU0nJs/figures/figures_21_1.jpg", "caption": "Figure 12: Pairwise density plots of a 20-dimensional slice of the final approximate posterior p(\u03b8) (\u03b8) = q\u03c6(\u03b8|xo) produced by ASNPE on the Prior I, Hours 5:00-6:00, Congestion level A scenario.", "description": "This figure shows pairwise density plots visualizing the 20-dimensional final approximate posterior generated by the ASNPE method.  It specifically visualizes the results for the first scenario from the experimental setup (Prior I, Hours 5:00-6:00, Congestion level A). Each plot shows the relationship between two dimensions of the posterior distribution, providing insights into the correlations and the overall shape of the posterior.", "section": "4.1 Experimental setup"}, {"figure_path": "fkuseU0nJs/figures/figures_22_1.jpg", "caption": "Figure 12: Pairwise density plots of a 20-dimensional slice of the final approximate posterior p(R)(\u03b8) = q\u03c6(\u03b8|x0) produced by ASNPE on the Prior I, Hours 5:00-6:00, Congestion level A scenario.", "description": "This figure shows pairwise density plots visualizing the relationships between 20 dimensions of the posterior distribution generated by the ASNPE method. Each plot shows the marginal distribution of a pair of dimensions, with the density represented by color intensity. The red crosses indicate the observed data point (x0), which serves as a reference point for evaluating how well the model captures the underlying distribution.", "section": "4.1 Experimental setup"}]