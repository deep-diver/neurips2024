[{"type": "text", "text": "Hyper-opinion Evidential Deep Learning for Out-of-Distribution Detection ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Jingen Qu ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Yufei Chen\u2217", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "School of Computer Science and Technology Tongji University, Shanghai, China newcity@tongji.edu.cn ", "page_idx": 0}, {"type": "text", "text": "School of Computer Science and Technology Tongji University, Shanghai, China yufeichen@tongji.edu.cn ", "page_idx": 0}, {"type": "text", "text": "Xiaodong Yue ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Wei Fu ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Artificial Intelligence Institute Shanghai University, Shanghai, China. yswantfly@shu.edu.cn ", "page_idx": 0}, {"type": "text", "text": "School of Computer Science and Technology Tongji University, Shanghai, China cs_fuwei@outlook.com ", "page_idx": 0}, {"type": "text", "text": "Qiguang Huang School of Computer Science and Technology Tongji University, Shanghai, China 1753543@tongji.edu.cn ", "page_idx": 0}, {"type": "text", "text": "Abstract ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Evidential Deep Learning (EDL), grounded in Evidence Theory and Subjective Logic (SL), provides a robust framework to estimate uncertainty for out-ofdistribution (OOD) detection alongside traditional classification probabilities. However, the EDL framework is constrained by its focus on evidence that supports only single categories, neglecting the other collective evidences that could corroborate multiple in-distribution categories. This limitation leads to a diminished estimation of uncertainty and a subsequent decline in OOD detection performance. Additionally, EDL encounters the vanishing gradient problem within its fullyconnected layers, further degrading classification accuracy. To address these issues, we introduce hyper-domain and propose Hyper-opinion Evidential Deep Learning (HEDL). HEDL extends the evidence modeling paradigm by explicitly integrating sharp evidence, which supports a singular category, with vague evidence that accommodates multiple potential categories. Additionally, we propose a novel opinion projection mechanism that translates hyper-opinion into multinomialopinion, which is then optimized within the EDL framework to ensure precise classification and refined uncertainty estimation. HEDL integrates evidences across various categories to yield a holistic evidentiary foundation for achieving superior OOD detection. Furthermore, our proposed opinion projection method effectively mitigates the vanishing gradient issue, ensuring classification accuracy without additional model complexity. Extensive experiments over many datasets demonstrate our proposed method outperforms existing OOD detection methods. ", "page_idx": 0}, {"type": "text", "text": "1 Introduction ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Deep Learning (DL) models have been widely adopted in many real-world applications[25, 57, 64, 15]. However, these models are trained under the implicit assumption that the training and test data are drawn from the same distribution[70], leading to overconfident predictions[45]. Thus when a DL model encounters an input that differs from its training data, it may be overconfident with wrong prediction, bringing rise to the out-of-distribution (OOD) problem. The resolution of the OOD problem is of utmost importance, and researchers have devoted significant attention to studying the intricacies of OOD detection[5, 16, 19, 30, 31, 43]. ", "page_idx": 0}, {"type": "text", "text": "", "page_idx": 1}, {"type": "text", "text": "To address OOD problem, a variety of methods have been developed in DL[12, 4, 51]. Some researchers apply post-processors to the base classifier to generate an uncertainty score for OOD detection. These post-hoc methods only take effect at inference phase and are easy to use, but rely on the performance of the pretrained model. Others propose training methods that involve training-time regularization, which require more computational resources. To train an uncertainty-aware model without additional computation, a recent search leverages Evidence Theory and Subjective Logic (SL) with DNNs[54], called Evidential Deep Learning (EDL)[55, 24, 54, 7]. EDL offers uncertainty estimation in neural networks which represents the degree of \u2018unknown\u2019 in opinion. It modifies the existing DL structure slightly and allows neural network to quantify the uncertainty for OOD detection with a well-defined theory framework. Evidential models have been extended to many areas such as open set recognition[2], classification[35, 32, 22, 36, 33], multi-view learning[72, 68, 23, 34]. ", "page_idx": 1}, {"type": "text", "text": "The EDL models face several challenges, with one primary issue arising from the theoretical framework. The evidence in multinomialopinion in EDL exclusively supports singleton sets, which contains only one category. In other words, EDL only captures the evidence which supports single category and rejects others. As a result, EDL is unable to effectively leverage vague evidence, such as features supporting a composite set containing multiple categories. As Figure 1 shows, EDL suffers from performance degradation in the face of ambiguous samples. ", "page_idx": 1}, {"type": "text", "text": "In addition, the parameters of fully-connected layer in EDL models are facing vanishing gradient problem when number of category in datasets rises[49]. Vanishing gradient in EDL leads to failure in classification of several categories. To mitigate this problem, Pandey et al.[49] introduce regularization techniques. However, these efforts yield unsatisfactory results in real world OOD detection tasks. ", "page_idx": 1}, {"type": "text", "text": "To train an evidential model maintaining classification accuracy and providing reliable uncertainty estimation for OOD detection, we incorporate EDL with hyper-opinion and propose Hyper-opinion Evidential Deep Learning (HEDL). While EDL is built upon multinomial", "page_idx": 1}, {"type": "image", "img_path": "Te8vI2wGTh/tmp/2a2c940690fe40cc0deb2e17cd8b6d6897e6f27f29935085e64c746b1da3103f.jpg", "img_caption": ["Figure 1: Belief and uncertainty masses across varying levels of In-distribution sample vagueness. As sample gets vaguer, EDL tends to extract a minimal quantity of sharp evidence, results in elevated uncertainty estimation. HEDL demonstrates the capability to extract vague evidence as sample vagueness increases, thereby maintaining lower uncertainty levels. "], "img_footnote": [], "page_idx": 1}, {"type": "text", "text": "opinion in a basic domain, hyper-opinion represents the opinion in the hyper-domain, which includes the basic domain and the composite sets. Through the concepts of composite set, HEDL is able to learn from vague evidence ignored by EDL. HEDL provides an effective mechanism for quantifying evidence that supports composite sets, thereby enhancing the differentiation of OOD data and classification accuracy. Our major contributions can be summarized as follows: ", "page_idx": 1}, {"type": "text", "text": "\u2022 We introduce an evidential representation within the hyper-domain, which integrates sharp evidence that supports a singular category, with vague evidence that accommodates multiple potential categories, to establish a more comprehensive and accurate evidentiary foundation. ", "page_idx": 1}, {"type": "text", "text": "\u2022 We develop a hyper-opinion framework within the hyper-domain and propose a novel opinion projection. This method transfers hyper-opinion to multinomial-opinion, allocating evidence to each category precisely and mitigating the vanishing gradient problem, while preserving computational efficiency. ", "page_idx": 1}, {"type": "image", "img_path": "Te8vI2wGTh/tmp/d3f5f3fab49ce53ee38b52ac1107984d9308aa5b5053bd7edb29d3af85fd8b83.jpg", "img_caption": [], "img_footnote": [], "page_idx": 2}, {"type": "text", "text": "Figure 2: Framework of HEDL. HEDL framework is composed of three integral components. The first part transfers the extracted features to evidence and models them with in hyper-opinion framework. Subsequently, the second component projects the hyper-opinion to multinomial-opinion. Ultimately, the framework optimizes the opinion to attain precise classification and to furnish robust uncertainty estimations for OOD detection. ", "page_idx": 2}, {"type": "text", "text": "\u2022 Our proposed Hyper-opinion Evidential Deep Learning (HEDL) procures more exhaustive evidence, which refines the precision of uncertainty estimation, and consequently enhances the performance of OOD detection while maintaing ID classification accuracy. \u2022 We carry out experiments over multiple challenging datasets to validate the OOD detection in HEDL outperforms existing OOD detection methods. ", "page_idx": 2}, {"type": "text", "text": "2 Related Work ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "2.1 Uncertainty based OOD Detection ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "Accurately quantifying predictive uncertainty in DL models is crucial for recognizing out-ofdistribution (OOD) samples. Traditional softmax-based models provide confidence estimation through class posteriors, which are inversely correlated with predictive uncertainty[16]. Several methods applicable to pre-trained classifiers that output class posteriors using softmax have been proposed[3, 14, 53, 37, 60, 18], including Out-of-Distribution Detector for Neural Networks[31] and Mahalanobis Distance[30]. Besides, deep ensemble is a technique developed for uncertainty quantification[29], which constructs an ensemble of neural networks and measures uncertainty based on the agreement/disagreement across the ensemble components[13]. However, this approach significantly increases the scale of model parameters, leading to high computational and storage complexity. Alternatively, neural networks based on Bayesian statistics called Bayesian neural networks[12, 4, 42] is raised to to quantify different uncertainties in Bayesian formalism. Bayesian methods normally apply approximation to address the intractability issue in marginalization of latent variables. And as such methods require sampling for uncertainty quantification, leading to expensive computations. A recent research effort has summarized OOD detection methods and established an OOD benchmark [69]. ", "page_idx": 2}, {"type": "text", "text": "2.2 Evidential Deep Learning ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "EDL introduces a conjugate higher-order evidential prior for the likelihood distribution that enables the model to capture the evidence vacuity as predictive uncertainty. The training of an EDL model can be regarded as an evidence-collecting process. Researches on multiple applications with EDL have been done, e.g., Dirichlet prior is introduced over the multinomial likelihood for evidential classification[2, 73, 11], evidential models for regression[1, 48], adversarial robustness[27] and calibration[63]. Most existing methods built upon EDL are trained on evidential losses conjunct with regularization of the evidence to guide the evidence vacuity, i.e., uncertainty, behavior[47, 56]. Some EDL models combine with the idea of outlier exposure[17] that provides access of OOD data to guide the evidence learning process of EDL models[40, 41]. ", "page_idx": 2}, {"type": "text", "text": "In this work, we focus on evidential models for classification and OOD detection, and consider settings where no extra regularization and OOD data are used during model training to make the proposed approach more broadly applicable to practical real-world situations. ", "page_idx": 2}, {"type": "text", "text": "3 Proposed Method ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "Our method\u2019s framework is depicted in Figure 2, which operates under the assumption of no prior information. ", "page_idx": 3}, {"type": "text", "text": "3.1 Hyper-opinion Belief ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "Subjective Logic (SL) is a theory of uncertain reasoning based on probability theory and belief theory in a domain $\\mathbb{X}$ , which represents the set of exclusive possible states of a variable situation. It introduces the concepts of belief mass and uncertainty mass to describe the degree of belief and uncertainty about an event. ", "page_idx": 3}, {"type": "text", "text": "Traditional EDL is built upon multinomial-opinion within domain $\\mathbb{X}$ in SL and domain $\\mathbb{X}$ is a limited portion of hyper-domain $\\mathcal{R}(\\mathbb{X})$ , where $\\mathcal{P}(\\mathbb{X})$ is the powerset of $\\mathbb{X}$ . ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\mathcal{R}(\\mathbb{X})=\\mathcal{P}(\\mathbb{X})/\\{\\{\\mathbb{X}\\},\\{\\emptyset\\}\\}.\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "Let us consider a domain $\\mathbb{X}$ with cardinality of $K$ , SL provides a belief mass $b_{k}$ representing the belief degree and a base rate $a_{k}$ representing the prior information for each singleton $k=1,...,K$ and an overall uncertainty mass of $u$ . The three compose a multinomial-opinion $\\pmb{\\omega}=(\\pmb{b},u,\\pmb{a})$ , belief mass and uncertainty mass sum up to one, eg., ", "page_idx": 3}, {"type": "equation", "text": "$$\nu+\\sum_{k=1}^{K}b_{k}=1,\\quad u\\geq0\\quad a n d\\quad b_{k}\\geq0\\quad f o r\\quad k=1,...,K.\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "Our method models the evidence in hyper-domain $\\mathcal{R}(\\mathbb{X})$ with hyper-opinion, which provides a belief mass $b_{x}^{H},x\\in\\mathcal{R}(\\mathbb{X})$ , representing the belief degree of set $x$ . Along with ${\\pmb a}^{H}$ and $u$ , the three compose a hyper-opinion $\\pmb{\\omega}^{H}=(\\pmb{b}^{H},u,\\pmb{a}^{H})$ and the hypernomial belief mass distribution also follows the additivity requirement: ", "page_idx": 3}, {"type": "equation", "text": "$$\nu+\\sum_{x\\in\\mathcal{R}(\\mathbb{X})}b_{x}^{H}=1.\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "Hyper opinion allows belief mass to be divided into two types called sharp belief mass and vague belief mass. Belief mass that only supports a specific singleton is called sharp belief mass, eg., $k\\in\\mathbb{X}$ , it discriminates between this and other singletons. EDL built upon the multinomial-opinion only offers sharp belief mass estimation. Considers a domain $\\mathbb{X}$ of ${\\bf K}$ mutually exclusive singletons, for each singleton $k=1,...,K$ , sharp belief mass is ", "page_idx": 3}, {"type": "equation", "text": "$$\nb_{k}^{\\mathrm{S}}=b_{k}^{H}\\;,\\forall k\\in\\mathbb{X}.\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "Belief mass assigned to a composite set $x\\in{\\mathcal{C}}(\\mathbb{X})$ , where $\\mathcal{C}(\\mathbb{X})=\\mathcal{R}(\\mathbb{X})/\\mathbb{X}$ , represents vague belief mass because it expresses cognitive vagueness. It supports the truth of multiple singletons in $\\mathbb{X}$ simultaneously. Vague belief mass can be allocated to a singleton $k$ as ", "page_idx": 3}, {"type": "equation", "text": "$$\nb_{k}^{\\mathrm{V}}=\\sum_{x\\in\\mathcal{C}(\\mathbb{X})}a(k|x)b_{x}^{H},\\quad a(k|x)=\\frac{a_{k}}{\\sum_{i\\in x}{a_{i}}},\\quad\\forall k\\in\\mathbb{X},\\forall x\\in\\mathcal{C}(\\mathbb{X}),\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "where $a(k|x)$ is relative base rate. When no prior information is available, $a(k|x)$ can be simplified to ", "page_idx": 3}, {"type": "equation", "text": "$$\na(k|x)=\\frac{1}{|x|},\\quad\\forall k\\in\\mathbb{X},\\forall x\\in\\mathcal{C}(\\mathbb{X}),\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "where $|x|$ is the cardinality of $x$ . Then in hyper-opinion, a belief mass $b_{x}^{H}$ for a set $x$ is computed using the evidence for the set. Let $e_{x}^{H}\\geq0$ be the evidence derived for the set $x$ , then the belief $b_{x}^{H}$ and the uncertainty $u$ are computed as ", "page_idx": 3}, {"type": "equation", "text": "$$\nb_{x}^{H}=\\frac{e_{x}^{H}}{S}\\quad\\mathrm{and}\\quad u=\\frac{K W_{p r i o r}}{S},\\quad S=\\sum_{x\\in\\mathcal{R}(\\mathbb{X})}e_{x}^{H}+K W_{p r i o r}.\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "By introducing hyper-opinion, vague beliefs that assigned to composite sets can be take into consideration, which better measure comprehensive evidence and estimate uncertainty more accurately. ", "page_idx": 3}, {"type": "text", "text": "In practice, we activate the features extracted by the neural network as evidence in hyper-domain, and build them within hyper-opinion to distinguish sharp belief and vague belief. This allows the model to maintain its vagueness among similar in-distribution categories, thereby ensuring that the uncertainty remains low. ", "page_idx": 3}, {"type": "text", "text": "3.2 Opinion Projection ", "text_level": 1, "page_idx": 4}, {"type": "text", "text": "A projection from hyper-opinion to multinomial-opinion is needed to realize the projected probability of each singleton. Therefore we introduce a novel opinion projection implementation that projects belief mass from hyper-opinion into multinomial-opinion, with $b_{k}^{\\mathrm{V}}$ and $b_{k}^{\\bar{\\mathrm{S}}}$ that can be calculated by Eq. 4 and Eq. 5, following ", "page_idx": 4}, {"type": "equation", "text": "$$\nb_{k}=b_{k}^{\\mathrm{V}}+b_{k}^{\\mathrm{S}},\\forall k\\in\\mathbb{X}.\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "We activate the features extracted by neural network for ascertaining non-negative evidence within the hyper-domain. After associate evidence with belief in hyper-opinion, we determine the set each belief mass supports as mentioned in section 3.1, and project the belief mass from hyper-opinion to multinomial-opinion. ", "page_idx": 4}, {"type": "text", "text": "Specifically, we apply a unit step activation function to the parameters of the fully connected layer, eg., Heaviside function ", "page_idx": 4}, {"type": "equation", "text": "$$\nH(x)={\\binom{1,x>0}{0,e l s e.}}\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "It offers an access to a matrix $W^{S}=H(W)$ , where $W$ corresponds to the weight matrix of the fully connected layer. $W^{S}$ represents the information of set each belief mass supports. ", "page_idx": 4}, {"type": "text", "text": "Assume there are $K$ singletons and $N$ belief masses supporting different sets, it offers a matrix $W_{N,K}^{S}$ . For a belief mass $\\bar{b}_{x}^{H}$ supporting set $x$ , $W_{x}^{S}$ is a vector that contains information about which singletons belong to the set $x$ . ", "page_idx": 4}, {"type": "text", "text": "Once the set each belief mass supports has been identified, projecting hyper-opinion to multinomialopinion is straightforward. For each belief mass within the hyper-opinion, we can compute its relative base rate to each singleton, and allocate belief mass accordingly. For a singleton $k$ , its total projected multinomial-opinion belief mass is ", "page_idx": 4}, {"type": "equation", "text": "$$\nb_{k}=\\sum_{x\\in\\mathcal{R}(\\mathbb{X}}(b_{x}^{H}W_{x,k}^{p}),\n$$", "text_format": "latex", "page_idx": 4}, {"type": "equation", "text": "$$\nW_{x,k}^{p}=\\frac{a_{k}H(W_{x,k})}{\\sum_{i=1}^{K}(a_{i}H(W_{x,i}))}=\\frac{a_{k}W_{x,k}^{S}}{\\sum_{i=1}^{K}(a_{i}W_{x,i}^{S})},\\quad k\\in\\mathbb{X},x\\in\\mathbb{R}(\\mathbb{X}),\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "where $\\textbf{\\em a}$ is the base rate. Without any prior information, Eq. 11 can be simplied to ", "page_idx": 4}, {"type": "equation", "text": "$$\nW_{x,k}^{p}=\\frac{W_{x,k}^{S}}{\\sum_{i=1}^{K}W_{x,i}^{S}},\\quad k\\in\\mathbb{X},x\\in\\mathcal{R}(\\mathbb{X}).\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "To date, we have successfully delineated the process of projecting belief mass from a hyper-opinion to a multinomial-opinion within a neural network framework. In practical terms, this projection is executed by applying a linear transformation to the output of the fully connected layer. This transformation facilitates the allocation of belief mass to the respective singletons in the multinomialopinion. Consequently, the incremental computational complexity associated with our method is constant as O(1). ", "page_idx": 4}, {"type": "equation", "text": "$$\nb=\\pmb{o}\\cdot\\boldsymbol{G}(\\boldsymbol{W},\\pmb{b}^{H}),\\quad\\boldsymbol{G}(\\boldsymbol{W},\\pmb{b}^{H})=\\frac{\\boldsymbol{W}^{p}\\pmb{b}^{H}}{\\boldsymbol{W}\\pmb{b}^{H}},\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "where $^o$ is the output of fully-connected layer and $W,W^{p},\\pmb{b}^{H}$ are all detached variables, making $G(W,\\pmb{b}^{H})$ a constant during one training epoch. ", "page_idx": 4}, {"type": "text", "text": "The output after opinion projection represents the projected multinomial-opinion in EDL, which has the equivalent meaning in EDL and can be optimized with the same techniques. We used an example to show why the uncertainty estimation of HEDL outperforms EDL in Appendix A. ", "page_idx": 4}, {"type": "text", "text": "3.3 Multinomial-opinion Optimization ", "text_level": 1, "page_idx": 4}, {"type": "text", "text": "By building evidence within hyper-domain and projecting hyper-opinion belief mass into multinomialopinion belief mass, we construct a flow that can be optimized in multinomial-opinion framework to obtain the comprehensive evidence and accurate uncertainty estimation for OOD detection, which is similar to traditional EDL. ", "page_idx": 4}, {"type": "text", "text": "As the sum of evidence $\\sum_{x\\in\\mathcal{R}(\\mathbb{X})}e_{x}^{H}$ and uncertainty $u$ remain the same during the projection, we can pass the belief mass in the form of evidence to simplify the calculation. Therefore the projected probability distribution derived from the projected multinomial-opinion can correspond to an expected probability distribution derived from a Dirichlet distribution parameterized by $_{\\alpha}$ ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\begin{array}{l}{\\omega=\\left(b,u,\\pmb{a}\\right)\\leftrightarrow D i r\\left(P\\left|\\alpha\\right.\\right),}\\\\ {\\alpha_{k}=e_{k}+a_{k}W_{p r i o r}=b_{k}S+a_{k}W_{p r i o r}.}\\end{array}}\\end{array}\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "The Dirichlet distribution is a probability density function (pdf) for possible values of the probability mass function (pmf) $P$ and is given by: ", "page_idx": 5}, {"type": "equation", "text": "$$\nD i r\\left(P\\left|\\alpha\\right.\\right)=\\frac{1}{B(\\pmb{\\alpha})}\\prod_{i}^{K}p_{i}^{\\alpha_{i}-1}.\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "In projected multinomial-opinion, the expected probability for the $k^{t h}$ singleton calculation is ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\hat{p}_{k}=\\frac{\\alpha_{k}}{S},\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "which allows to be optimized by the loss function defined in EDL ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\mathcal{L}_{i}(\\boldsymbol{\\Theta})=\\int\\left[\\sum_{j=1}^{K}-y_{i j}\\log(p_{i j})\\right]\\frac{1}{B(\\alpha_{i})}\\prod_{j=1}^{K}p_{i j}^{\\alpha_{i j}-1}d\\mathbf{p}_{i}=\\sum_{j=1}^{K}y_{i j}\\Big(\\psi(S_{i})-\\psi(\\alpha_{i j})\\Big),\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "where $\\psi(\\cdot)$ is the digamma function, $y_{i}$ is a one-hot vector encoding the ground-truth class of observation $x_{i}$ with $y_{i j}=1$ and $y_{i k}=0$ for all $k\\neq j$ , and $\\alpha_{i}$ be the parameters of the Dirichlet density on the predictors. ", "page_idx": 5}, {"type": "text", "text": "At this point, we have established the complete framework of HEDL, spanning all stages ranging from input processing to classification and uncertainty estimation. Our method objective has the following proposition in the Appendix B. ", "page_idx": 5}, {"type": "text", "text": "By establishing the framework of HEDL, we comprehensively extract the sharp and vague evidence each sample contains and allocate preciously, thereby enabling accurate classification. Moreover, comprehensive evidence contributes to improved uncertainty estimation and subsequently enhances the performance of OOD detection. ", "page_idx": 5}, {"type": "text", "text": "4 Experiment ", "text_level": 1, "page_idx": 5}, {"type": "text", "text": "In this section, we describe our experimental setup and demonstrate the effectiveness of our method on a wide range of OOD evaluation benchmarks and the most widely used metric AUROC is adopted[52, 21, 10, 37]. We also conduct an ablation analysis that leads to an improved understanding of our approach. ", "page_idx": 5}, {"type": "text", "text": "4.1 Setup", "text_level": 1, "page_idx": 5}, {"type": "text", "text": "In-distribution Datasets. We use the CIFAR-10[28], CIFAR-100[28], Flower-102[46] and CUB200-2011[65] as ID data. ", "page_idx": 5}, {"type": "text", "text": "Out-of-distribution Datasets. For the OOD test datasets, we use three common benchmarks[69]: SVHN[44], Textures[6], Places365[74], that are used in Openood-benchmark[69]. There is no overlapping between ID datasets and OOD datasets. ", "page_idx": 5}, {"type": "text", "text": "Evaluation Metrics. We measure the following metrics: 1) FPR95 measures the false positive rate (FPR) when the true positive rate (TPR) is equal to $95\\%$ . Lower scores indicate better performance. 2) AUROC measures the area under the Receiver Operating Characteristic (ROC) curve, which displays the relationship between TPR and FPR. The area under the ROC curve can be interpreted as the probability that a positive ID example will have a higher detection score than a negative OOD example. 3) AUPR measures the area under the Precision-Recall (PR) curve. The PR curve is created by plotting precision versus recall. AUROC is the most common metric[52, 21, 10, 37] and we use AUROC as the main metric for OOD detection performance while accuracy measures performance of detecting ID samples. Our goal is to detect more OOD samples while maintaining ID classification performance. ", "page_idx": 5}, {"type": "table", "img_path": "Te8vI2wGTh/tmp/d76c6753da3617a16048f1d31bc522553fd84796a41d8d1503bcfa39a1c4ced8.jpg", "table_caption": ["Table 1: Comparison of OOD detection performance between HEDL and other baselines with CIFAR10 and CIFAR-100 as ID dataset. All values are percentages. $\\uparrow$ indicates larger values are better, and $\\downarrow$ indicates smaller values are better. The bold are superior results. "], "table_footnote": [], "page_idx": 6}, {"type": "text", "text": "Implementation Details. We follow the experiment settings outlined in OpenOOD[69]. We use ResNet-18[15] for CIFAR-10 and CIFAR-100. For more intricate datasets that are not included in OpenOOD[69], such as fine-grained datasets Flower-102 and CUB-200-2011, we employ ResNet34[15] for enhanced feature representation. All experiments are implemented with PyTorch[50] and carried out with NVIDIA GeForce RTX 3090 GPU. We use the standard data split for all datasets, and the number of training epochs is 100, the initial learning rate is 0.0001 with AdamW[39], and the batch size is 128. At test time, all images are resized to $224\\times224$ . For HEDL model, we first train the feature extractor with softmax layer for 90 epochs and then train in HEDL framework for 10 epochs. HEDL does not introduce any additional hyperparameters, thereby eliminating the need for extensive hyperparameter tuning, and $W_{p r i o r}$ is set to 1 for HEDL. ", "page_idx": 6}, {"type": "text", "text": "Baseline Methods. We compare our method with several classical and state-of-the-art OOD detection methods. Specifically, we compare our method with post-hoc inference methods and training methods. From MSP[16] to GEN[38] are post-hoc inference methods, which affect OOD detection performance only and do not change model accuracy. The others are training methods. We excluded methods that required auxiliary OOD data due to the practical real-world situations consideration. We leverage selected experimental results from OpenOOD[69] to demonstrate the effectiveness of our approach. ", "page_idx": 6}, {"type": "text", "text": "Table 2: Ablation experiment results on Flower-102 and CUB-200-2011. Results show that EDL fails to extract evidence fully. HEDL without projection can extract comprehensive evidence to distinguish ID and OOD samples but fails to classify ID categories. HEDL can further assign evidence correctly and obtain accurate classification. ", "page_idx": 7}, {"type": "table", "img_path": "Te8vI2wGTh/tmp/4e5f77f551342a9f453080f0dcb44789e6fee8f242de7f9126947a2bb1452c12.jpg", "table_caption": [], "table_footnote": [], "page_idx": 7}, {"type": "text", "text": "4.2 OOD Detection Results ", "text_level": 1, "page_idx": 7}, {"type": "text", "text": "The comparative results on CIFAR-10 and CIFAR-100 are detailed in Table 1, and the results on Flower-102 and CUB-200-2011 are shown in Appendix C. For each model, we utilize three OOD datasets, thereby aiming to achieve more realistic and generalized outcomes. We reveal a common challenge: when confronted with more complex data scenarios, training methods struggle to maintain both accuracy and OOD detection capabilities simultaneously. However, HEDL consistently achieves better OOD detection performance than existing state-of-the-art OOD detection methods while preserving the accuracy of ID classification, even under complex data scenarios. Notably, HEDL accomplishes this enhancement without additional regularization strategies or hyperparameters, indicating strong generalization ability on different datasets, it also avoids incurring higher computational costs. The experimental training time analysis of HEDL can be found in Appendix D. ", "page_idx": 7}, {"type": "text", "text": "4.3 Gradient Analysis ", "text_level": 1, "page_idx": 7}, {"type": "text", "text": "The gradient norms of fully-connected layer parameters over EDL and HEDL during training is shown in Figure 3, alongside the final accuracy for each category. The sum of these gradient norms has been normalized for comparative analysis. It is observed that the gradient norms for several parameters within the fullyconnected layer of the EDL model remain zero throughout the training process, which correlates with a significantly lower final accuracy for these categories. This outcome is indicative of the vanishing gradient problem. Conversely, HEDL does not experience this issue, demonstrating that our proposed method effectively circumvents the challenge of vanishing gradients within the fully-connected layer. ", "page_idx": 7}, {"type": "image", "img_path": "Te8vI2wGTh/tmp/cc01e0fbeb7e60dbbf663c471da65f966e8a79d7d83db0f16242502476505e11.jpg", "img_caption": ["Figure 3: The sum of gradient norms within the fully-connected layer for each category in CIFAR100 throughout the training process. "], "img_footnote": [], "page_idx": 7}, {"type": "text", "text": "4.4 Ablation Study ", "text_level": 1, "page_idx": 7}, {"type": "text", "text": "EDL suffers from a notable decline in both ID accuracy and OOD detection when facing a proportional rise in the volume of vague evidence. In contrast, HEDL demonstrates the capability to consistently extract comprehensive evidence and maintain its performance regardless of the dataset scale. ", "page_idx": 7}, {"type": "text", "text": "We investigate the performance of our method with ablation experiments on two challenging finegrained datasets. The fine-grained datasets contain more vagueness among categories and can better prove the effectiveness of our methods. We conducte ablation experiments on the effects of hyperopinion and opinion projection, respectively. Note that opinion projection can only be built upon hyper-opinion. ", "page_idx": 7}, {"type": "text", "text": "Figure 4 illustrates the uncertainty distribution of ID and OOD samples across different datasets for EDL, HEDL without opinion projection, and HEDL itself. Notably, on the latter three more complex datasets, the approaches based on hyper-opinion exhibits a distinct performance advantage. It is also ", "page_idx": 7}, {"type": "image", "img_path": "Te8vI2wGTh/tmp/cdc12836b95b2b8b7cfe2f374c33ef6bf75cd9c445f8be19aec499a9266cd0cb.jpg", "img_caption": ["(a) CIFAR-10, the overlap between ID and OOD is $20\\%$ , $23\\%$ , and $18\\%$ for EDL, HEDL w/o projection, and HEDL, respectively. "], "img_footnote": [], "page_idx": 8}, {"type": "image", "img_path": "Te8vI2wGTh/tmp/111139b4bc4bbfacbd37dddc96f600966b3c7f97f9aada57fba8659a1c1b4184.jpg", "img_caption": ["(b) CIFAR-100, the overlap between ID and OOD is $62\\%$ , $45\\%$ , and $41\\%$ for EDL, HEDL w/o projection, and HEDL, respectively. "], "img_footnote": [], "page_idx": 8}, {"type": "image", "img_path": "Te8vI2wGTh/tmp/12f2c5942f918c2892611e628d31dffbfa3655dcec57914e170c79da2172d304.jpg", "img_caption": ["(c) Flower-102, the overlap between ID and OOD is $71\\%$ , $26\\%$ , and $29\\%$ for EDL, HEDL w/o projection, and HEDL, respectively. "], "img_footnote": [], "page_idx": 8}, {"type": "image", "img_path": "Te8vI2wGTh/tmp/df9335061249d7545f8eebaaf99e88531f124fe1f169fc3e34075a0571d591c5.jpg", "img_caption": ["(d) CUB-200-2011, the overlap between ID and OOD is $50\\%$ , $20\\%$ , and $17\\%$ for EDL, HEDL w/o projection, and HEDL, respectively. "], "img_footnote": [], "page_idx": 8}, {"type": "text", "text": "Figure 4: The normalized density distribution of normalized uncertainty for ID and OOD samples across differing datasets. ", "page_idx": 8}, {"type": "text", "text": "worth observing that, in these datasets, instances of ID data with maximum uncertainty are present in the EDL model. This phenomenon can be attributed to the failure of extracting evidence of those categories due to the vanishing gradient problem. ", "page_idx": 8}, {"type": "text", "text": "Table 2 shows that evidence built on hyper-opinion can be considered comprehensively, leading to accurate uncertainty estimation and above baseline OOD detection performance. But without the correct projection from hyper-opinion to multinomial-opinion, vague evidence can not be assigned precisely, leading to inaccurate classification. ", "page_idx": 8}, {"type": "text", "text": "5 Conclusion ", "text_level": 1, "page_idx": 8}, {"type": "text", "text": "In this paper, we propose Hyper-opinion Evidential Deep Learning (HEDL), a novel approach designed to generate precise uncertainty estimation for Out-of-Distribution (OOD) detection. Our method encapsulates a comprehensive representation of evidence within hyper-opinion, which allows model to preserve its vagueness among In-Distribution categories to reject OOD data. ", "page_idx": 8}, {"type": "text", "text": "Additionally, by projecting hyper-opinion to multinomial-opinion, HEDL circumvents the vanishing gradient problem encountered in the fully-connected layers of traditional EDL. This projection is optimized within an established framework, yielding accurate and reliable evidence. Notably, our method accomplishes superior OOD detection performance while simultaneously upholding classification accuracy without incurring additional computational complexity. Extensive experimental results across numerous datasets substantiate the efficacy of the proposed Hyper-opinion Evidential Deep Learning. ", "page_idx": 8}, {"type": "text", "text": "", "page_idx": 9}, {"type": "text", "text": "Limitations and societal impact. Our proposed HEDL method achieves best performance by transfering learning on pre-trained models. In future work, it is necessary to reduce the dependence on pre-trained models and explore alternative approaches. This work aims to improve the safety of deep learning models, which tends to benefit a wide range of applications of AI in social life. ", "page_idx": 9}, {"type": "text", "text": "Acknowledgments and Disclosure of Funding ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "This work was supported by the National Natural Science Foundation of China (No. 62173252, 62476165). ", "page_idx": 9}, {"type": "text", "text": "References ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "[1] Alexander Amini, Wilko Schwarting, Ava Soleimany, and Daniela Rus. Deep evidential regression. Advances in Neural Information Processing Systems, 33:14927\u201314937, 2020.   \n[2] Wentao Bao, Qi Yu, and Yu Kong. Evidential deep learning for open set action recognition. In Proceedings of the IEEE/CVF International Conference on Computer Vision, pages 13349\u2013 13358, 2021.   \n[3] Abhijit Bendale and Terrance E Boult. Towards open set deep networks. In Proceedings of the IEEE conference on computer vision and pattern recognition, pages 1563\u20131572, 2016.   \n[4] Charles Blundell, Julien Cornebise, Koray Kavukcuoglu, and Daan Wierstra. Weight uncertainty in neural network. In International conference on machine learning, pages 1613\u20131622. PMLR, 2015.   \n[5] Jiefeng Chen, Yixuan Li, Xi Wu, Yingyu Liang, and Somesh Jha. Informative outlier matters: Robustifying out-of-distribution detection using outlier mining. 2020.   \n[6] Mircea Cimpoi, Subhransu Maji, Iasonas Kokkinos, Sammy Mohamed, and Andrea Vedaldi. Describing textures in the wild. In Proceedings of the IEEE conference on computer vision and pattern recognition, pages 3606\u20133613, 2014.   \n[7] Danruo Deng, Guangyong Chen, Yang Yu, Furui Liu, and Pheng-Ann Heng. Uncertainty estimation by fisher information-based evidential deep learning. arXiv preprint arXiv:2303.02045, 2023.   \n[8] Andrija Djurisic, Nebojsa Bozanic, Arjun Ashok, and Rosanne Liu. Extremely simple activation shaping for out-of-distribution detection. In International Conference on Learning Representations, 2022.   \n[9] Xuefeng Du, Zhaoning Wang, Mu Cai, and Yixuan Li. Vos: Learning what you don\u2019t know by virtual outlier synthesis. In International Conference on Learning Representations, 2021.   \n[10] Stanislav Fort, Jie Ren, and Balaji Lakshminarayanan. Exploring the limits of out-of-distribution detection. Advances in Neural Information Processing Systems, 34:7068\u20137081, 2021.   \n[11] Wei Fu, Yufei Chen, Wei Liu, Xiaodong Yue, and Chao Ma. Evidence reconciled neural network for out-of-distribution detection in medical images. In International Conference on Medical Image Computing and Computer-Assisted Intervention, pages 305\u2013315. Springer, 2023.   \n[12] Yarin Gal and Zoubin Ghahramani. Dropout as a bayesian approximation: Representing model uncertainty in deep learning. In international conference on machine learning, pages 1050\u20131059. PMLR, 2016.   \n[13] Mudasir A Ganaie, Minghui Hu, AK Malik, M Tanveer, and PN Suganthan. Ensemble deep learning: A review. Engineering Applications of Artificial Intelligence, 115:105151, 2022.   \n[14] Chuan Guo, Geoff Pleiss, Yu Sun, and Kilian Q Weinberger. On calibration of modern neural networks. In International conference on machine learning, pages 1321\u20131330. PMLR, 2017.   \n[15] Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep residual learning for image recognition. In Proceedings of the IEEE conference on computer vision and pattern recognition, pages 770\u2013778, 2016.   \n[16] Dan Hendrycks and Kevin Gimpel. A baseline for detecting misclassified and out-of-distribution examples in neural networks. In International Conference on Learning Representations, 2016.   \n[17] Dan Hendrycks, Mantas Mazeika, and Thomas Dietterich. Deep anomaly detection with outlier exposure. In International Conference on Learning Representations, 2018.   \n[18] Dan Hendrycks, Steven Basart, Mantas Mazeika, Andy Zou, Joseph Kwon, Mohammadreza Mostajabi, Jacob Steinhardt, and Dawn Song. Scaling out-of-distribution detection for realworld settings. In International Conference on Machine Learning, pages 8759\u20138773. PMLR, 2022.   \n[19] Yen-Chang Hsu, Yilin Shen, Hongxia Jin, and Zsolt Kira. Generalized odin: Detecting outof-distribution image without learning from out-of-distribution data. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 10951\u201310960, 2020.   \n[20] Rui Huang and Yixuan Li. Mos: Towards scaling out-of-distribution detection for large semantic space. 2021 ieee. In CVF Conference on Computer Vision and Pattern Recognition $(C V P R)\\,p p$ , pages 8706\u20138715, 2021.   \n[21] Rui Huang, Andrew Geng, and Yixuan Li. On the importance of gradients for detecting distributional shifts in the wild. Advances in Neural Information Processing Systems, 34: 677\u2013689, 2021.   \n[22] Bingbing Jiang, Chenglong Zhang, Yan Zhong, Yi Liu, Yingwei Zhang, Xingyu Wu, and Weiguo Sheng. Adaptive collaborative fusion for multi-view semi-supervised classification. Information Fusion, 96:37\u201350, 2023.   \n[23] Bingbing Jiang, Xingyu Wu, Xiren Zhou, Anthony G Cohn, Yi Liu, Weiguo Sheng, and Huanhuan Chen. Semi-supervised multi-view feature selection with adaptive graph learning. IEEE Transactions on Neural Networks and Learning Systems, 35(3):3615\u20133629, 2024.   \n[24] Audun J\u00f8sang. Subjective logic, volume 3. Springer, 2016.   \n[25] Uday Kamath, John Liu, and James Whitaker. Deep learning for NLP and speech recognition, volume 84. Springer, 2019.   \n[26] Shu Kong and Deva Ramanan. Opengan: Open-set recognition via open data generation. In Proceedings of the IEEE/CVF International Conference on Computer Vision, pages 813\u2013822, 2021.   \n[27] Anna-Kathrin Kopetzki, Bertrand Charpentier, Daniel Z\u00fcgner, Sandhya Giri, and Stephan G\u00fcnnemann. Evaluating robustness of predictive uncertainty estimation: Are dirichlet-based models reliable? In International Conference on Machine Learning, pages 5707\u20135718. PMLR, 2021.   \n[28] Alex Krizhevsky, Geoffrey Hinton, et al. Learning multiple layers of features from tiny images. 2009.   \n[29] Balaji Lakshminarayanan, Alexander Pritzel, and Charles Blundell. Simple and scalable predictive uncertainty estimation using deep ensembles. Advances in neural information processing systems, 30, 2017.   \n[30] Kimin Lee, Kibok Lee, Honglak Lee, and Jinwoo Shin. A simple unified framework for detecting out-of-distribution samples and adversarial attacks. Advances in neural information processing systems, 31, 2018.   \n[31] Shiyu Liang, Yixuan Li, and R Srikant. Enhancing the reliability of out-of-distribution image detection in neural networks. In International Conference on Learning Representations, 2018.   \n[32] Xinyan Liang, Yuhua Qian, Qian Guo, Honghong Cheng, and Jiye Liang. Af: An associationbased fusion method for multi-modal classification. IEEE Transactions on Pattern Analysis and Machine Intelligence, 44(12):9236\u20139254, 2021.   \n[33] Xinyan Liang, Pinhan Fu, Qian Guo, Keyin Zheng, and Yuhua Qian. Dc-nas: Divide-andconquer neural architecture search for multi-modal classification. In Proceedings of the AAAI Conference on Artificial Intelligence, volume 38, pages 13754\u201313762, 2024.   \n[34] Wei Liu, Xiaodong Yue, Yufei Chen, and Thierry Denoeux. Trusted multi-view deep learning with opinion aggregation. In Proceedings of the AAAI Conference on Artificial Intelligence, volume 36, pages 7585\u20137593, 2022.   \n[35] Wei Liu, Yufei Chen, Xiaodong Yue, Changqing Zhang, and Shaorong Xie. Safe multi-view deep classification. In Proceedings of the AAAI Conference on Artificial Intelligence, volume 37, pages 8870\u20138878, 2023.   \n[36] Wei Liu, Yufei Chen, and Xiaodong Yue. Building trust in decision with conformalized multi-view deep classification. In ACM Multimedia 2024, 2024.   \n[37] Weitang Liu, Xiaoyun Wang, John Owens, and Yixuan Li. Energy-based out-of-distribution detection. Advances in neural information processing systems, 33:21464\u201321475, 2020.   \n[38] Xixi Liu, Yaroslava Lochman, and Christopher Zach. Gen: Pushing the limits of softmax-based out-of-distribution detection. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 23946\u201323955, 2023.   \n[39] Ilya Loshchilov and Frank Hutter. Decoupled weight decay regularization. In International Conference on Learning Representations, 2018.   \n[40] Andrey Malinin and Mark Gales. Predictive uncertainty estimation via prior networks. Advances in neural information processing systems, 31, 2018.   \n[41] Andrey Malinin and Mark Gales. Reverse kl-divergence training of prior networks: Improved uncertainty and adversarial robustness. Advances in Neural Information Processing Systems, 32, 2019.   \n[42] Aryan Mobiny, Pengyu Yuan, Supratik K Moulik, Naveen Garg, Carol C Wu, and Hien Van Nguyen. Dropconnect is effective in modeling uncertainty of bayesian deep networks. Scientific reports, 11(1):5458, 2021.   \n[43] Sina Mohseni, Mandar Pitale, JBS Yadawa, and Zhangyang Wang. Self-supervised learning for generalizable out-of-distribution detection. In Proceedings of the AAAI Conference on Artificial Intelligence, volume 34, pages 5216\u20135223, 2020.   \n[44] Yuval Netzer, Tao Wang, Adam Coates, Alessandro Bissacco, Bo Wu, and Andrew Y Ng. Reading digits in natural images with unsupervised feature learning. 2011.   \n[45] Anh Nguyen, Jason Yosinski, and Jeff Clune. Deep neural networks are easily fooled: High confidence predictions for unrecognizable images. In Proceedings of the IEEE conference on computer vision and pattern recognition, pages 427\u2013436, 2015.   \n[46] Maria-Elena Nilsback and Andrew Zisserman. Automated flower classification over a large number of classes. In 2008 Sixth Indian conference on computer vision, graphics & image processing, pages 722\u2013729. IEEE, 2008.   \n[47] Deep Shankar Pandey and Qi Yu. Multidimensional belief quantification for label-efficient meta-learning. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 14391\u201314400, 2022.   \n[48] Deep Shankar Pandey and Qi Yu. Evidential conditional neural processes. In Proceedings of the AAAI Conference on Artificial Intelligence, volume 37, pages 9389\u20139397, 2023.   \n[49] Deep Shankar Pandey and Qi Yu. Learn to accumulate evidence from all training samples: theory and practice. In International Conference on Machine Learning, pages 26963\u201326989. PMLR, 2023.   \n[50] Adam Paszke, Sam Gross, Francisco Massa, Adam Lerer, James Bradbury, Gregory Chanan, Trevor Killeen, Zeming Lin, Natalia Gimelshein, Luca Antiga, et al. Pytorch: An imperative style, high-performance deep learning library. Advances in neural information processing systems, 32, 2019.   \n[51] Tim Pearce, Felix Leibfried, and Alexandra Brintrup. Uncertainty in neural networks: Approximately bayesian ensembling. In International conference on artificial intelligence and statistics, pages 234\u2013244. PMLR, 2020.   \n[52] Jie Ren, Peter J Liu, Emily Fertig, Jasper Snoek, Ryan Poplin, Mark Depristo, Joshua Dillon, and Balaji Lakshminarayanan. Likelihood ratios for out-of-distribution detection. Advances in neural information processing systems, 32, 2019.   \n[53] Chandramouli Shama Sastry and Sageev Oore. Detecting out-of-distribution examples with gram matrices. In International Conference on Machine Learning, pages 8491\u20138501. PMLR, 2020.   \n[54] Murat Sensoy, Lance Kaplan, and Melih Kandemir. Evidential deep learning to quantify classification uncertainty. Advances in neural information processing systems, 31, 2018.   \n[55] Glenn Shafer. A mathematical theory of evidence, volume 42. Princeton university press, 1976.   \n[56] Weishi Shi, Xujiang Zhao, Feng Chen, and Qi Yu. Multifaceted uncertainty estimation for labelefficient deep learning. Advances in neural information processing systems, 33:17247\u201317257, 2020.   \n[57] Shashi Pal Singh, Ajai Kumar, Hemant Darbari, Lenali Singh, Anshika Rastogi, and Shikha Jain. Machine translation using deep learning: An overview. In 2017 international conference on computer, communications and electronics (comptelix), pages 162\u2013167. IEEE, 2017.   \n[58] Yue Song, Nicu Sebe, and Wei Wang. Rankfeat: Rank-1 feature removal for out-of-distribution detection. Advances in Neural Information Processing Systems, 35:17885\u201317898, 2022.   \n[59] Yiyou Sun and Yixuan Li. Dice: Leveraging sparsification for out-of-distribution detection. In European Conference on Computer Vision, pages 691\u2013708. Springer, 2022.   \n[60] Yiyou Sun, Chuan Guo, and Yixuan Li. React: Out-of-distribution detection with rectified activations. Advances in Neural Information Processing Systems, 34:144\u2013157, 2021.   \n[61] Yiyou Sun, Yifei Ming, Xiaojin Zhu, and Yixuan Li. Out-of-distribution detection with deep nearest neighbors. In International Conference on Machine Learning, pages 20827\u201320840. PMLR, 2022.   \n[62] Jihoon Tack, Sangwoo Mo, Jongheon Jeong, and Jinwoo Shin. Csi: Novelty detection via contrastive learning on distributionally shifted instances. Advances in neural information processing systems, 33:11839\u201311852, 2020.   \n[63] Christian Tomani and Florian Buettner. Towards trustworthy predictions from deep neural networks with fast adversarial calibration. In Proceedings of the AAAI Conference on Artificial Intelligence, volume 35, pages 9886\u20139896, 2021.   \n[64] Athanasios Voulodimos, Nikolaos Doulamis, Anastasios Doulamis, Eftychios Protopapadakis, et al. Deep learning for computer vision: A brief review. Computational intelligence and neuroscience, 2018, 2018.   \n[65] Catherine Wah, Steve Branson, Peter Welinder, Pietro Perona, and Serge Belongie. The caltech-ucsd birds-200-2011 dataset. 2011.   \n[66] Haoqi Wang, Zhizhong Li, Litong Feng, and Wayne Zhang. Vim: Out-of-distribution with virtual-logit matching. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition, pages 4921\u20134930, 2022.   \n[67] Hongxin Wei, Renchunzi Xie, Hao Cheng, Lei Feng, Bo An, and Yixuan Li. Mitigating neural network overconfidence with logit normalization. In International Conference on Machine Learning, pages 23631\u201323644. PMLR, 2022.   \n[68] Cai Xu, Jiajun Si, Ziyu Guan, Wei Zhao, Yue Wu, and Xiyue Gao. Reliable conflictive multiview learning. In Proceedings of the AAAI Conference on Artificial Intelligence, volume 38, pages 16129\u201316137, 2024.   \n[69] Jingkang Yang, Pengyun Wang, Dejian Zou, Zitang Zhou, Kunyuan Ding, Wenxuan Peng, Haoqi Wang, Guangyao Chen, Bo Li, Yiyou Sun, et al. Openood: Benchmarking generalized out-ofdistribution detection. Advances in Neural Information Processing Systems, 35:32598\u201332611, 2022.   \n[70] Nanyang Ye, Kaican Li, Haoyue Bai, Runpeng Yu, Lanqing Hong, Fengwei Zhou, Zhenguo Li, and Jun Zhu. Ood-bench: Quantifying and understanding two dimensions of out-of-distribution generalization. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 7947\u20137958, 2022.   \n[71] Jinsong Zhang, Qiang Fu, Xu Chen, Lun Du, Zelin Li, Gang Wang, Shi Han, Dongmei Zhang, et al. Out-of-distribution detection based on in-distribution data patterns memorization with modern hopfield energy. In The Eleventh International Conference on Learning Representations, 2022.   \n[72] Qingyang Zhang, Yake Wei, Zongbo Han, Huazhu Fu, Xi Peng, Cheng Deng, Qinghua Hu, Cai Xu, Jie Wen, Di Hu, et al. Multimodal fusion on low-quality data: A comprehensive survey. arXiv preprint arXiv:2404.18947, 2024.   \n[73] Xujiang Zhao, Feng Chen, Shu Hu, and Jin-Hee Cho. Uncertainty aware semi-supervised learning on graph data. Advances in Neural Information Processing Systems, 33:12827\u201312836, 2020.   \n[74] Bolei Zhou, Agata Lapedriza, Aditya Khosla, Aude Oliva, and Antonio Torralba. Places: A 10 million image database for scene recognition. IEEE transactions on pattern analysis and machine intelligence, 40(6):1452\u20131464, 2017. ", "page_idx": 9}, {"type": "text", "text": "", "page_idx": 10}, {"type": "text", "text": "", "page_idx": 11}, {"type": "text", "text": "", "page_idx": 12}, {"type": "text", "text": "", "page_idx": 13}, {"type": "text", "text": "A An Example within EDL and HEDL ", "text_level": 1, "page_idx": 14}, {"type": "image", "img_path": "Te8vI2wGTh/tmp/8fec5843d79c63f4eb9b5bb59eb7a013b8ec0f5cabbd9a55b7b5baaebd13a581.jpg", "img_caption": ["Figure 5: Example of an image been classified by EDL and HEDL. When confronted with vague samples, HEDL leverages the incorporation of vague evidence, which culminates in enhanced accuracy for classification and more precise uncertainty estimations, thereby fortifying OOD detection capabilities. "], "img_footnote": [], "page_idx": 14}, {"type": "text", "text": "A sample displaying the classification process of EDL and HEDL is shown in Figure 5, EDL tends to ignore or diminish the amount of vague evidence to get sharper belief mass. The loss of evidence leads to increased uncertainty and potential misclassification. In contrast, HEDL framework reserves the vague evidence, thereby achieving improved estimations of uncertainty and more accurate classification results. Notice that when there is no evidence supporting a set $x$ , then $e_{x}^{H}=0$ . ", "page_idx": 14}, {"type": "text", "text": "B Gradient Vanishing Analysis ", "text_level": 1, "page_idx": 14}, {"type": "text", "text": "Proposition 1. By building evidence on hyper-opinion and then projecting to multinomial-opinion, we avoid the vanishing gradient problem in fully-connected layer in traditional EDL. ", "page_idx": 14}, {"type": "text", "text": "Proof 1. Consider the neural network forward propagation in EDL ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\begin{array}{r l r}&{\\displaystyle o_{k}=W z+b i a s,}&\\\\ &{\\displaystyle e_{k}=R e L U(o_{k}),}&\\\\ &{\\displaystyle\\alpha_{k}=e_{k}+\\frac{W_{p r i o r}}{K},}&\\\\ &{\\displaystyle\\mathcal{L}_{i}(\\Theta)=\\sum_{j=1}^{K}y_{i j}\\Big(\\psi(S_{i})-\\psi(\\alpha_{i j})\\Big),}&\\end{array}\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "where bias stands for the bias of the fully-connected layer, $_{z}$ represents the feature extracted by the neural network. We can write expressions for all partial derivatives as follows: ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\frac{\\partial o_{k}}{\\partial W}=z,\\quad\\frac{\\partial\\alpha_{k}}{\\partial e_{k}}=1,\n$$", "text_format": "latex", "page_idx": 14}, {"type": "equation", "text": "$$\n\\frac{\\partial\\mathcal{L}}{\\partial\\alpha_{k}}=\\left(\\frac{1}{S^{2}}+\\sum_{i=1}^{\\infty}\\frac{1}{(i+S)^{2}}-\\frac{y_{k}}{\\alpha_{g t}^{2}}-\\sum_{i=1}^{\\infty}\\frac{y_{k}}{(i+\\alpha_{g t})^{2}}\\right),\n$$", "text_format": "latex", "page_idx": 14}, {"type": "equation", "text": "$$\n\\frac{\\partial e_{k}}{\\partial o_{k}}=\\left\\{{0\\:\\:\\:\\:\\:\\:\\:\\:\\:\\mathrm{if}\\:\\:\\:\\:\\:o_{k}\\leq0}\\right.\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "Therefore by the chain rule, we can calculatethe the gradient w.r.t. $W$ as: ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\frac{\\partial\\mathcal{L}}{\\partial W}=\\frac{\\partial\\mathcal{L}}{\\partial\\alpha_{k}}\\frac{\\partial\\alpha_{k}}{\\partial e_{k}}\\frac{\\partial e_{k}}{\\partial o_{k}}\\frac{\\partial o_{k}}{\\partial W}=\\frac{\\partial\\mathcal{L}}{\\partial\\alpha_{k}}\\frac{\\partial e_{k}}{\\partial o_{k}}z,\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "Obviously when exists $o_{k}\\leq0,\\forall k\\in\\mathbb{X}$ , vanishing gradient problem is unavoidable in traditional EDL. To ensure that proposed HEDL is not associate with similar problem, considering the forward propagation of HEDL: ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\begin{array}{l}{{\\displaystyle o_{k}=W z+b i a s,}}\\\\ {{\\displaystyle e_{k}=o_{k}G(W,b^{H}),}}\\\\ {{\\displaystyle\\alpha_{k}=e_{k}+\\frac{W_{p r i o r}}{K},}}\\end{array}\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "where $G(W,\\pmb{b}^{H})$ can be calculated by Eq. 7 and Eq. 13, and the gradient w.r.t. $W$ is calculated by chain rule: ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\frac{\\partial\\mathcal{L}}{\\partial W}=\\frac{\\partial\\mathcal{L}}{\\partial\\alpha_{k}}\\frac{\\partial\\alpha_{k}}{\\partial e_{k}}\\frac{\\partial e_{k}}{\\partial o_{k}}\\frac{\\partial o_{k}}{\\partial W},\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "where\u2202\u03b1k , \u2202ekk , \u2202Wk are known items that won\u2019t cause vanishing gradient problem. Consider ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\frac{\\partial e_{k}}{\\partial o_{k}}=\\frac{\\partial o_{k}G(\\boldsymbol{W},\\boldsymbol{b}^{H})}{\\partial o_{k}}=G(\\boldsymbol{W},\\boldsymbol{b}^{H}),\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "where $W,\\pmb{b}^{H}$ are all detached variables that are irrelevant variables in this partial derivative item, implying that $G(W,b^{H})$ remains constant during the backward process. ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\frac{\\partial\\mathcal{L}}{\\partial W}=\\frac{\\partial\\mathcal{L}}{\\partial\\alpha_{k}}G(W,\\pmb{b}^{H})\\pmb{z}.\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "Consequently, the opinion projection successfully circumvents the vanishing gradient problem in the fully-connected layer. ", "page_idx": 15}, {"type": "text", "text": "C Experiment Results on Flower-102 and CUB-200-2011 ", "text_level": 1, "page_idx": 15}, {"type": "text", "text": "Table 3 details the comparative results on two fine-grained datasets Flower-102 and CUB-200-2011. On more complex fine-grained datasets, HEDL consistently demonstrates superior performance in OOD detection. ", "page_idx": 15}, {"type": "table", "img_path": "Te8vI2wGTh/tmp/b059a4b2cd926830df949674460b361c184b8b397688bf68f52b7bb2d916775d.jpg", "table_caption": ["Table 3: Comparison of OOD detection performance between HEDL and other baselines with Flower102 and CUB-200-2011 as ID dataset. "], "table_footnote": [], "page_idx": 15}, {"type": "text", "text": "D Experiment Analysis of Computational Complexity ", "text_level": 1, "page_idx": 16}, {"type": "text", "text": "Table 4 presents the average training time per epoch of EDL and HEDL compared with MSP on different datasets, all under identical training conditions. The results indicate that the implementation of HEDL does not incur additional computational complexity. ", "page_idx": 16}, {"type": "table", "img_path": "Te8vI2wGTh/tmp/798927e003ce4f7be90b0d4a70c2ef5da216a3950c36526322cca06f7bd9f1a8.jpg", "table_caption": ["Table 4: Average training time per epoch of EDL and HEDL compared with MSP on different datasets, $^+$ indicates more time, and - indicates less time. "], "table_footnote": [], "page_idx": 16}, {"type": "text", "text": "NeurIPS Paper Checklist ", "text_level": 1, "page_idx": 17}, {"type": "text", "text": "1. Claims ", "text_level": 1, "page_idx": 17}, {"type": "text", "text": "Question: Do the main claims made in the abstract and introduction accurately reflect the paper\u2019s contributions and scope? ", "page_idx": 17}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 17}, {"type": "text", "text": "Justification: Our abstract and introduction provide a comprehensive overview of the contributions, the scope, and the method of our paper. ", "page_idx": 17}, {"type": "text", "text": "Guidelines: ", "page_idx": 17}, {"type": "text", "text": "\u2022 The answer NA means that the abstract and introduction do not include the claims made in the paper.   \n\u2022 The abstract and/or introduction should clearly state the claims made, including the contributions made in the paper and important assumptions and limitations. A No or NA answer to this question will not be perceived well by the reviewers.   \n\u2022 The claims made should match theoretical and experimental results, and reflect how much the results can be expected to generalize to other settings.   \n\u2022 It is fine to include aspirational goals as motivation as long as it is clear that these goals are not attained by the paper. ", "page_idx": 17}, {"type": "text", "text": "2. Limitations ", "text_level": 1, "page_idx": 17}, {"type": "text", "text": "Question: Does the paper discuss the limitations of the work performed by the authors? ", "page_idx": 17}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 17}, {"type": "text", "text": "Justification: We discuss the limitation of the proposed method in the paper, namely that the best performance of our method depends on the performance of the pre-trained model we adapted. ", "page_idx": 17}, {"type": "text", "text": "Guidelines: ", "text_level": 1, "page_idx": 17}, {"type": "text", "text": "\u2022 The answer NA means that the paper has no limitation while the answer No means that the paper has limitations, but those are not discussed in the paper.   \n\u2022 The authors are encouraged to create a separate \"Limitations\" section in their paper.   \n\u2022 The paper should point out any strong assumptions and how robust the results are to violations of these assumptions (e.g., independence assumptions, noiseless settings, model well-specification, asymptotic approximations only holding locally). The authors should reflect on how these assumptions might be violated in practice and what the implications would be.   \n\u2022 The authors should reflect on the scope of the claims made, e.g., if the approach was only tested on a few datasets or with a few runs. In general, empirical results often depend on implicit assumptions, which should be articulated.   \n\u2022 The authors should reflect on the factors that influence the performance of the approach. For example, a facial recognition algorithm may perform poorly when image resolution is low or images are taken in low lighting. Or a speech-to-text system might not be used reliably to provide closed captions for online lectures because it fails to handle technical jargon.   \n\u2022 The authors should discuss the computational efficiency of the proposed algorithms and how they scale with dataset size.   \n\u2022 If applicable, the authors should discuss possible limitations of their approach to address problems of privacy and fairness.   \n\u2022 While the authors might fear that complete honesty about limitations might be used by reviewers as grounds for rejection, a worse outcome might be that reviewers discover limitations that aren\u2019t acknowledged in the paper. The authors should use their best judgment and recognize that individual actions in favor of transparency play an important role in developing norms that preserve the integrity of the community. Reviewers will be specifically instructed to not penalize honesty concerning limitations. ", "page_idx": 17}, {"type": "text", "text": "3. Theory Assumptions and Proofs ", "text_level": 1, "page_idx": 17}, {"type": "text", "text": "Question: For each theoretical result, does the paper provide the full set of assumptions and a complete (and correct) proof? ", "page_idx": 17}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 18}, {"type": "text", "text": "Justification: We provide a complete and correct proof for the theoretical results in the paper. Guidelines: ", "page_idx": 18}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include theoretical results.   \n\u2022 All the theorems, formulas, and proofs in the paper should be numbered and crossreferenced.   \n\u2022 All assumptions should be clearly stated or referenced in the statement of any theorems.   \n\u2022 The proofs can either appear in the main paper or the supplemental material, but if they appear in the supplemental material, the authors are encouraged to provide a short proof sketch to provide intuition.   \n\u2022 Inversely, any informal proof provided in the core of the paper should be complemented by formal proofs provided in appendix or supplemental material.   \n\u2022 Theorems and Lemmas that the proof relies upon should be properly referenced. ", "page_idx": 18}, {"type": "text", "text": "4. Experimental Result Reproducibility ", "text_level": 1, "page_idx": 18}, {"type": "text", "text": "Question: Does the paper fully disclose all the information needed to reproduce the main experimental results of the paper to the extent that it affects the main claims and/or conclusions of the paper (regardless of whether the code and data are provided or not)? ", "page_idx": 18}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 18}, {"type": "text", "text": "Justification: This paper fully discloses all the information needed to reproduce the main experimental results, including the theoretical and practical implementation, and training details. ", "page_idx": 18}, {"type": "text", "text": "Guidelines: ", "page_idx": 18}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 If the paper includes experiments, a No answer to this question will not be perceived well by the reviewers: Making the paper reproducible is important, regardless of whether the code and data are provided or not.   \n\u2022 If the contribution is a dataset and/or model, the authors should describe the steps taken to make their results reproducible or verifiable.   \n\u2022 Depending on the contribution, reproducibility can be accomplished in various ways. For example, if the contribution is a novel architecture, describing the architecture fully might suffice, or if the contribution is a specific model and empirical evaluation, it may be necessary to either make it possible for others to replicate the model with the same dataset, or provide access to the model. In general. releasing code and data is often one good way to accomplish this, but reproducibility can also be provided via detailed instructions for how to replicate the results, access to a hosted model (e.g., in the case of a large language model), releasing of a model checkpoint, or other means that are appropriate to the research performed.   \n\u2022 While NeurIPS does not require releasing code, the conference does require all submissions to provide some reasonable avenue for reproducibility, which may depend on the nature of the contribution. For example (a) If the contribution is primarily a new algorithm, the paper should make it clear how to reproduce that algorithm. (b) If the contribution is primarily a new model architecture, the paper should describe the architecture clearly and fully. (c) If the contribution is a new model (e.g., a large language model), then there should either be a way to access this model for reproducing the results or a way to reproduce the model (e.g., with an open-source dataset or instructions for how to construct the dataset). (d) We recognize that reproducibility may be tricky in some cases, in which case authors are welcome to describe the particular way they provide for reproducibility. In the case of closed-source models, it may be that access to the model is limited in some way (e.g., to registered users), but it should be possible for other researchers to have some path to reproducing or verifying the results. ", "page_idx": 18}, {"type": "text", "text": "5. Open access to data and code ", "text_level": 1, "page_idx": 18}, {"type": "text", "text": "Question: Does the paper provide open access to the data and code, with sufficient instructions to faithfully reproduce the main experimental results, as described in supplemental material? ", "page_idx": 19}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 19}, {"type": "text", "text": "Justification: The code of this paper is included in the supplementary material. ", "page_idx": 19}, {"type": "text", "text": "Guidelines: ", "page_idx": 19}, {"type": "text", "text": "\u2022 The answer NA means that paper does not include experiments requiring code.   \n\u2022 Please see the NeurIPS code and data submission guidelines (https://nips.cc/ public/guides/CodeSubmissionPolicy) for more details.   \n\u2022 While we encourage the release of code and data, we understand that this might not be possible, so \u201cNo\u201d is an acceptable answer. Papers cannot be rejected simply for not including code, unless this is central to the contribution (e.g., for a new open-source benchmark).   \n\u2022 The instructions should contain the exact command and environment needed to run to reproduce the results. See the NeurIPS code and data submission guidelines (https: //nips.cc/public/guides/CodeSubmissionPolicy) for more details.   \n\u2022 The authors should provide instructions on data access and preparation, including how to access the raw data, preprocessed data, intermediate data, and generated data, etc.   \n\u2022 The authors should provide scripts to reproduce all experimental results for the new proposed method and baselines. If only a subset of experiments are reproducible, they should state which ones are omitted from the script and why.   \n\u2022 At submission time, to preserve anonymity, the authors should release anonymized versions (if applicable).   \n\u2022 Providing as much information as possible in supplemental material (appended to the paper) is recommended, but including URLs to data and code is permitted. ", "page_idx": 19}, {"type": "text", "text": "6. Experimental Setting/Details ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "Question: Does the paper specify all the training and test details (e.g., data splits, hyperparameters, how they were chosen, type of optimizer, etc.) necessary to understand the results? ", "page_idx": 19}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 19}, {"type": "text", "text": "Justification: This paper specifies all the training and test details necessary to understand the results. ", "page_idx": 19}, {"type": "text", "text": "Guidelines: ", "page_idx": 19}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments. \u2022 The experimental setting should be presented in the core of the paper to a level of detail that is necessary to appreciate the results and make sense of them. \u2022 The full details can be provided either with the code, in appendix, or as supplemental material. ", "page_idx": 19}, {"type": "text", "text": "7. Experiment Statistical Significance ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "Question: Does the paper report error bars suitably and correctly defined or other appropriate information about the statistical significance of the experiments? ", "page_idx": 19}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 19}, {"type": "text", "text": "Justification: This paper presents a series of replicable experiments conducted across multiple datasets, proving the statistical significance of the experiments of our proposed method. ", "page_idx": 19}, {"type": "text", "text": "Guidelines: ", "page_idx": 19}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments. \u2022 The authors should answer \"Yes\" if the results are accompanied by error bars, confidence intervals, or statistical significance tests, at least for the experiments that support the main claims of the paper. ", "page_idx": 19}, {"type": "text", "text": "\u2022 The factors of variability that the error bars are capturing should be clearly stated (for example, train/test split, initialization, random drawing of some parameter, or overall run with given experimental conditions).   \n\u2022 The method for calculating the error bars should be explained (closed form formula, call to a library function, bootstrap, etc.)   \n\u2022 The assumptions made should be given (e.g., Normally distributed errors).   \n\u2022 It should be clear whether the error bar is the standard deviation or the standard error of the mean.   \n\u2022 It is OK to report 1-sigma error bars, but one should state it. The authors should preferably report a 2-sigma error bar than state that they have a $96\\%$ CI, if the hypothesis of Normality of errors is not verified.   \n\u2022 For asymmetric distributions, the authors should be careful not to show in tables or figures symmetric error bars that would yield results that are out of range (e.g. negative error rates).   \n\u2022 If error bars are reported in tables or plots, The authors should explain in the text how they were calculated and reference the corresponding figures or tables in the text. ", "page_idx": 20}, {"type": "text", "text": "8. Experiments Compute Resources ", "text_level": 1, "page_idx": 20}, {"type": "text", "text": "Question: For each experiment, does the paper provide sufficient information on the computer resources (type of compute workers, memory, time of execution) needed to reproduce the experiments? ", "page_idx": 20}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 20}, {"type": "text", "text": "Justification: This paper provides sufficient information on the computer resources needed to reproduce the experiments. ", "page_idx": 20}, {"type": "text", "text": "Guidelines: ", "page_idx": 20}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 The paper should indicate the type of compute workers CPU or GPU, internal cluster, or cloud provider, including relevant memory and storage.   \n\u2022 The paper should provide the amount of compute required for each of the individual experimental runs as well as estimate the total compute.   \n\u2022 The paper should disclose whether the full research project required more compute than the experiments reported in the paper (e.g., preliminary or failed experiments that didn\u2019t make it into the paper). ", "page_idx": 20}, {"type": "text", "text": "9. Code Of Ethics ", "text_level": 1, "page_idx": 20}, {"type": "text", "text": "Question: Does the research conducted in the paper conform, in every respect, with the NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines? ", "page_idx": 20}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 20}, {"type": "text", "text": "Justification: ", "page_idx": 20}, {"type": "text", "text": "Guidelines: The research conducted in the paper conform, in every respect, with the NeurIPS Code of Ethics. ", "page_idx": 20}, {"type": "text", "text": "\u2022 The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics.   \n\u2022 If the authors answer No, they should explain the special circumstances that require a deviation from the Code of Ethics.   \n\u2022 The authors should make sure to preserve anonymity (e.g., if there is a special consideration due to laws or regulations in their jurisdiction). ", "page_idx": 20}, {"type": "text", "text": "10. Broader Impacts ", "text_level": 1, "page_idx": 20}, {"type": "text", "text": "Question: Does the paper discuss both potential positive societal impacts and negative societal impacts of the work performed? ", "page_idx": 20}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 20}, {"type": "text", "text": "Justification: This paper discusses the positive societal impacts of the work performed. Guidelines: ", "page_idx": 20}, {"type": "text", "text": "\u2022 The answer NA means that there is no societal impact of the work performed. ", "page_idx": 20}, {"type": "text", "text": "\u2022 If the authors answer NA or No, they should explain why their work has no societal impact or why the paper does not address societal impact.   \n\u2022 Examples of negative societal impacts include potential malicious or unintended uses (e.g., disinformation, generating fake profiles, surveillance), fairness considerations (e.g., deployment of technologies that could make decisions that unfairly impact specific groups), privacy considerations, and security considerations.   \n\u2022 The conference expects that many papers will be foundational research and not tied to particular applications, let alone deployments. However, if there is a direct path to any negative applications, the authors should point it out. For example, it is legitimate to point out that an improvement in the quality of generative models could be used to generate deepfakes for disinformation. On the other hand, it is not needed to point out that a generic algorithm for optimizing neural networks could enable people to train models that generate Deepfakes faster.   \n\u2022 The authors should consider possible harms that could arise when the technology is being used as intended and functioning correctly, harms that could arise when the technology is being used as intended but gives incorrect results, and harms following from (intentional or unintentional) misuse of the technology.   \n\u2022 If there are negative societal impacts, the authors could also discuss possible mitigation strategies (e.g., gated release of models, providing defenses in addition to attacks, mechanisms for monitoring misuse, mechanisms to monitor how a system learns from feedback over time, improving the efficiency and accessibility of ML). ", "page_idx": 21}, {"type": "text", "text": "11. Safeguards ", "text_level": 1, "page_idx": 21}, {"type": "text", "text": "Question: Does the paper describe safeguards that have been put in place for responsible release of data or models that have a high risk for misuse (e.g., pretrained language models, image generators, or scraped datasets)? ", "page_idx": 21}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 21}, {"type": "text", "text": "Justification: This paper poses no such risks. Guidelines: ", "page_idx": 21}, {"type": "text", "text": "\u2022 The answer NA means that the paper poses no such risks.   \n\u2022 Released models that have a high risk for misuse or dual-use should be released with necessary safeguards to allow for controlled use of the model, for example by requiring that users adhere to usage guidelines or restrictions to access the model or implementing safety filters.   \n\u2022 Datasets that have been scraped from the Internet could pose safety risks. The authors should describe how they avoided releasing unsafe images.   \n\u2022 We recognize that providing effective safeguards is challenging, and many papers do not require this, but we encourage authors to take this into account and make a best faith effort. ", "page_idx": 21}, {"type": "text", "text": "12. Licenses for existing assets ", "text_level": 1, "page_idx": 21}, {"type": "text", "text": "Question: Are the creators or original owners of assets (e.g., code, data, models), used in the paper, properly credited and are the license and terms of use explicitly mentioned and properly respected? ", "page_idx": 21}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 21}, {"type": "text", "text": "Justification: The creators of the data and models we used in this paper are properly credited and are the license and terms of use explicitly mentioned and properly respected. ", "page_idx": 21}, {"type": "text", "text": "Guidelines: ", "page_idx": 21}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not use existing assets.   \n\u2022 The authors should cite the original paper that produced the code package or dataset.   \n\u2022 The authors should state which version of the asset is used and, if possible, include a URL.   \n\u2022 The name of the license (e.g., CC-BY 4.0) should be included for each asset.   \n\u2022 For scraped data from a particular source (e.g., website), the copyright and terms of service of that source should be provided.   \n\u2022 If assets are released, the license, copyright information, and terms of use in the package should be provided. For popular datasets, paperswithcode.com/datasets has curated licenses for some datasets. Their licensing guide can help determine the license of a dataset.   \n\u2022 For existing datasets that are re-packaged, both the original license and the license of the derived asset (if it has changed) should be provided.   \n\u2022 If this information is not available online, the authors are encouraged to reach out to the asset\u2019s creators. ", "page_idx": 21}, {"type": "text", "text": "", "page_idx": 22}, {"type": "text", "text": "13. New Assets ", "text_level": 1, "page_idx": 22}, {"type": "text", "text": "Question: Are new assets introduced in the paper well documented and is the documentation provided alongside the assets? ", "page_idx": 22}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 22}, {"type": "text", "text": "Justification: We provide the details of our code as part of our submissions via structured templates, along with documentation. ", "page_idx": 22}, {"type": "text", "text": "Guidelines: ", "page_idx": 22}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not release new assets.   \n\u2022 Researchers should communicate the details of the dataset/code/model as part of their submissions via structured templates. This includes details about training, license, limitations, etc.   \n\u2022 The paper should discuss whether and how consent was obtained from people whose asset is used.   \n\u2022 At submission time, remember to anonymize your assets (if applicable). You can either create an anonymized URL or include an anonymized zip file. ", "page_idx": 22}, {"type": "text", "text": "14. Crowdsourcing and Research with Human Subjects ", "text_level": 1, "page_idx": 22}, {"type": "text", "text": "Question: For crowdsourcing experiments and research with human subjects, does the paper include the full text of instructions given to participants and screenshots, if applicable, as well as details about compensation (if any)? ", "page_idx": 22}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 22}, {"type": "text", "text": "Justification: This paper does not involve crowdsourcing nor research with human subjects. Guidelines: ", "page_idx": 22}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u2022 Including this information in the supplemental material is fine, but if the main contribution of the paper involves human subjects, then as much detail as possible should be included in the main paper.   \n\u2022 According to the NeurIPS Code of Ethics, workers involved in data collection, curation, or other labor should be paid at least the minimum wage in the country of the data collector. ", "page_idx": 22}, {"type": "text", "text": "15. Institutional Review Board (IRB) Approvals or Equivalent for Research with Human Subjects ", "text_level": 1, "page_idx": 22}, {"type": "text", "text": "Question: Does the paper describe potential risks incurred by study participants, whether such risks were disclosed to the subjects, and whether Institutional Review Board (IRB) approvals (or an equivalent approval/review based on the requirements of your country or institution) were obtained? ", "page_idx": 22}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 22}, {"type": "text", "text": "Justification: This paper does not involve crowdsourcing nor research with human subjects. Guidelines: ", "page_idx": 22}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u2022 Depending on the country in which research is conducted, IRB approval (or equivalent) may be required for any human subjects research. If you obtained IRB approval, you should clearly state this in the paper.   \n\u2022 We recognize that the procedures for this may vary significantly between institutions and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the guidelines for their institution.   \n\u2022 For initial submissions, do not include any information that would break anonymity (if applicable), such as the institution conducting the review. ", "page_idx": 22}, {"type": "text", "text": "", "page_idx": 23}]