[{"figure_path": "Te8vI2wGTh/tables/tables_6_1.jpg", "caption": "Table 1: Comparison of OOD detection performance between HEDL and other baselines with CIFAR-10 and CIFAR-100 as ID dataset. All values are percentages. \u2191 indicates larger values are better, and \u2193 indicates smaller values are better. The bold are superior results.", "description": "This table presents a comparison of the out-of-distribution (OOD) detection performance of the proposed Hyper-opinion Evidential Deep Learning (HEDL) method against several other baseline methods.  The comparison uses CIFAR-10 and CIFAR-100 datasets as in-distribution (ID) datasets and evaluates performance using three different OOD datasets (SVHN, Textures, and Place365).  The metrics used for evaluation are FPR95 (False Positive Rate at 95% True Positive Rate), AUPR (Area Under the Precision-Recall curve), AUROC (Area Under the Receiver Operating Characteristic curve), and the classification accuracy (Acc).  Higher values for AUPR and AUROC indicate better performance, while a lower value for FPR95 indicates better performance.  The bold numbers indicate that HEDL outperforms other methods.", "section": "4.2 OOD Detection Results"}, {"figure_path": "Te8vI2wGTh/tables/tables_7_1.jpg", "caption": "Table 1: Comparison of OOD detection performance between HEDL and other baselines with CIFAR-10 and CIFAR-100 as ID dataset. All values are percentages. \u2191 indicates larger values are better, and \u2193 indicates smaller values are better. The bold are superior results.", "description": "This table compares the out-of-distribution (OOD) detection performance of the proposed Hyper-opinion Evidential Deep Learning (HEDL) method against several other baseline methods.  The evaluation is performed using CIFAR-10 and CIFAR-100 datasets as in-distribution (ID) data, and three other common OOD benchmark datasets (SVHN, Textures, Places365) as out-of-distribution data. The metrics used for comparison include the False Positive Rate at 95% True Positive Rate (FPR95), Area Under the Precision-Recall curve (AUPR), Area Under the Receiver Operating Characteristic curve (AUROC), and the accuracy of in-distribution classification. Higher AUPR and AUROC values, and lower FPR95 values indicate better performance.  The table highlights HEDL's superior performance across all metrics.", "section": "4.2 OOD Detection Results"}, {"figure_path": "Te8vI2wGTh/tables/tables_15_1.jpg", "caption": "Table 1: Comparison of OOD detection performance between HEDL and other baselines with CIFAR-10 and CIFAR-100 as ID dataset. All values are percentages. \u2191 indicates larger values are better, and \u2193 indicates smaller values are better. The bold are superior results.", "description": "This table compares the out-of-distribution (OOD) detection performance of the proposed Hyper-opinion Evidential Deep Learning (HEDL) method against several other baseline methods.  The evaluation is performed using CIFAR-10 and CIFAR-100 as in-distribution (ID) datasets, and three common OOD benchmark datasets (SVHN, Textures, Places365). The metrics used for comparison include FPR95 (False Positive Rate at 95% True Positive Rate), AUPR (Area Under the Precision-Recall curve), AUROC (Area Under the Receiver Operating Characteristic curve), and accuracy (classification accuracy on ID samples).  Higher AUPR and AUROC values are better, while lower FPR95 values indicate better performance.  The bold values highlight the superior performance achieved by HEDL.", "section": "4.2 OOD Detection Results"}, {"figure_path": "Te8vI2wGTh/tables/tables_16_1.jpg", "caption": "Table 1: Comparison of OOD detection performance between HEDL and other baselines with CIFAR-10 and CIFAR-100 as ID dataset. All values are percentages. \u2191 indicates larger values are better, and \u2193 indicates smaller values are better. The bold are superior results.", "description": "This table compares the out-of-distribution (OOD) detection performance of the proposed Hyper-opinion Evidential Deep Learning (HEDL) method with several other baseline methods on the CIFAR-10 and CIFAR-100 datasets.  The performance is measured using three metrics: FPR95 (False Positive Rate at 95% True Positive Rate), AUPR (Area Under the Precision-Recall curve), and AUROC (Area Under the Receiver Operating Characteristic curve).  Lower FPR95 values are better, while higher AUPR and AUROC values are better.  The table also shows the accuracy of ID (In-Distribution) classification for each method.  The results are presented as percentages.  The best results for each metric are shown in bold.", "section": "4 Experiment"}]