[{"figure_path": "6FTlHaxCpR/tables/tables_7_1.jpg", "caption": "Table 1: Quantitative comparison on NeRF-DS dataset per-scene. We highlight the best and the second best results in each scene. NeRF-DS and HyperNeRF employ MS-SSIM and LPIPS with the AlexNet [75], while other methods and ours use SSIM and LPIPS with the VGG [76] network.", "description": "This table presents a quantitative comparison of different methods on the NeRF-DS dataset for dynamic scene reconstruction.  It shows the PSNR, SSIM, and LPIPS scores for each scene and method, highlighting the best and second-best performing methods.  Note that different metrics and network backbones were used for HyperNeRF and the other methods.", "section": "5.2 Results"}, {"figure_path": "6FTlHaxCpR/tables/tables_7_2.jpg", "caption": "Table 2: Quantitative comparison on HyperNeRF's vrig dataset per-scene.", "description": "This table presents a quantitative comparison of different methods on the HyperNeRF's vrig dataset.  It shows the PSNR and SSIM scores for each method across four different scenes within the dataset.  Higher PSNR and SSIM values indicate better performance in terms of image quality and similarity to the ground truth.", "section": "5.2 Results"}, {"figure_path": "6FTlHaxCpR/tables/tables_7_3.jpg", "caption": "Table 3: Ablations on the key components of our proposed framework.", "description": "This table presents the ablation study results, comparing the performance of the proposed MotionGS framework with different components.  It shows the impact of adding optical flow guidance, using motion flow instead of optical flow, and finally incorporating camera pose refinement. The metrics used for evaluation are PSNR, SSIM, and LPIPS.", "section": "5.3 Ablation Study"}, {"figure_path": "6FTlHaxCpR/tables/tables_15_1.jpg", "caption": "Table 4: Training time comparison across different models.", "description": "This table presents a comparison of the training time required for different models, including the baseline and the proposed methods with and without pose refinement, across various scenes from the NeRF-DS dataset. The results showcase the computational efficiency of the models and provide insights into the impact of model components (like pose refinement) on training time.", "section": "5.2 Results"}, {"figure_path": "6FTlHaxCpR/tables/tables_15_2.jpg", "caption": "Table 5: Max GPU memory usage comparison across different models.", "description": "This table compares the maximum GPU memory usage (in GB) required by the baseline method and the proposed MotionGS method for each scene in the NeRF-DS dataset.  It provides insights into the computational cost and resource requirements of both approaches for different scene complexities.", "section": "5.2 Results"}, {"figure_path": "6FTlHaxCpR/tables/tables_15_3.jpg", "caption": "Table 6: FPS, number of 3D Gaussians and storage on the NeRF-DS dataset per scene.", "description": "This table presents a quantitative evaluation of the MotionGS model on the NeRF-DS dataset.  It shows the frames per second (FPS), the number of 3D Gaussians used in the model's representation, and the total storage required for each scene in the dataset.  This allows for a comparison of the model's efficiency and performance across different scene complexities.", "section": "5.2 Results"}, {"figure_path": "6FTlHaxCpR/tables/tables_16_1.jpg", "caption": "Table 7: Ablations on other choices of our proposed framework. For fair comparison, we do not activate the proposed camera pose refinement module during training.", "description": "This table presents ablation studies on different components of the MotionGS framework.  It shows the impact of removing the motion mask, using different depth estimation methods, different optical flow networks, a self-supervised flow supervision loss, and varying the weight of the flow loss. The results highlight the importance of each component in achieving optimal performance.", "section": "5.3 Ablation Study"}]