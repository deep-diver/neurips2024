{"references": [{"fullname_first_author": "Ben Mildenhall", "paper_title": "Nerf: Representing scenes as neural radiance fields for view synthesis", "publication_date": "2021-01-01", "reason": "This paper introduced the foundational Neural Radiance Fields (NeRF) method, which is the basis for many subsequent dynamic scene reconstruction techniques, including the method presented in this paper."}, {"fullname_first_author": "Albert Pumarola", "paper_title": "D-nerf: Neural radiance fields for dynamic scenes", "publication_date": "2021-01-01", "reason": "This paper extended NeRF to handle dynamic scenes, directly addressing the challenge of reconstructing time-varying 3D scenes, a key problem the current paper tackles."}, {"fullname_first_author": "Bernhard Kerbl", "paper_title": "3d gaussian splatting for real-time radiance field rendering", "publication_date": "2023-01-01", "reason": "This paper introduced 3D Gaussian Splatting (3DGS), a highly efficient and effective representation for static scenes that serves as the foundation for the current paper's dynamic extension."}, {"fullname_first_author": "Jonathon Luiten", "paper_title": "Dynamic 3d gaussians: Tracking by persistent dynamic view synthesis", "publication_date": "2023-01-01", "reason": "This paper extended the 3D Gaussian Splatting method to dynamic scenes, providing a direct predecessor to the current work, which addresses and improves upon some of its limitations."}, {"fullname_first_author": "Ziyi Yang", "paper_title": "Deformable 3d gaussians for high-fidelity monocular dynamic scene reconstruction", "publication_date": "2023-01-01", "reason": "This paper is another close predecessor that uses deformable 3D Gaussians for dynamic scene reconstruction; the current paper builds on this work, adding explicit motion guidance for improved accuracy and robustness."}]}