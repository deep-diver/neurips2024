{"references": [{"fullname_first_author": "Qizhang Li", "paper_title": "Improving adversarial transferability via intermediate-level perturbation decay", "publication_date": "2023", "reason": "This paper introduces a novel perspective on improving the transferability of adversarial examples by reducing the gradient from residual modules, which is directly relevant to the core method of this paper."}, {"fullname_first_author": "Yiwen Guo", "paper_title": "Backpropagating linearly improves transferability of adversarial examples", "publication_date": "2020", "reason": "This paper presents a strategy that addresses the gap between the input gradients and the effects of token replacements by using the linear backpropagation technique which is used in this paper."}, {"fullname_first_author": "Qian Huang", "paper_title": "Enhancing adversarial example transferability with an intermediate level attack", "publication_date": "2019", "reason": "This paper introduces the intermediate level attack (ILA) which is used as an inspiration for this paper's proposed method."}, {"fullname_first_author": "Chuan Guo", "paper_title": "Gradient-based adversarial attacks against text transformers", "publication_date": "2021", "reason": "This paper introduces the Greedy Coordinate Gradient (GCG) attack which is used as a strong baseline and a representative example to analyze previous gradient-based attacks against LLMs in this paper."}, {"fullname_first_author": "Andy Zou", "paper_title": "Universal and transferable adversarial attacks on aligned language models", "publication_date": "2023", "reason": "This paper introduces AdvBench, a benchmark dataset used in this paper for evaluating the effectiveness of the proposed method."}]}