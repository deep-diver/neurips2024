[{"figure_path": "bqGAheAeQY/tables/tables_6_1.jpg", "caption": "Table 1: Pet evaluation. Top: Baseline method results for structure or camera estimation (or both). Bottom: Our results with several configurations. (C),(D), or (CD) respectively indicate the object categories in the training set: cats, dogs, or both. BA and FT respectively indicate a post-processing of Bundle Adjustment or fine-tuning.", "description": "The table presents a quantitative comparison of the proposed TRACKSTO4D method against several baseline methods for 3D reconstruction from video.  The top section shows results from existing methods. The bottom section presents results for TRACKSTO4D under various training configurations (trained on only cats, only dogs, or both) and with or without post-processing steps such as Bundle Adjustment (BA) and fine-tuning (FT).  Metrics include Absolute Relative error (Abs Rel),  percentage of points with \u03b4 < 1.25, 2, and 3, Absolute Trajectory Error (ATE), Relative Pose Error Translation (RPETrans), Relative Pose Error Rotation (RPERot), and inference time. Lower values for Abs Rel, ATE, RPETrans, and RPERot, and higher values for \u03b4 metrics are better.", "section": "3 Experiments"}, {"figure_path": "bqGAheAeQY/tables/tables_6_2.jpg", "caption": "Table 2: Out-of-training-domain evaluation. Evaluation metrics on monocular videos from [62]. The table has the same structure as Tab. 1.", "description": "This table presents the quantitative results of TRACKSTO4D on videos from the Nvidia Dynamic Scenes Dataset [62], which are different from the training data (Common Pets Dataset [44]).  It compares the performance of TRACKSTO4D against several baselines using metrics such as Absolute Relative error, percentage of points with depth error less than 1.25, 1.25^2, and 1.25^3 times the ground truth depth, Absolute Translation Error (ATE), Relative Pose Error (Translation and Rotation), and inference time. Different training configurations of TRACKSTO4D (trained on cats, dogs, or both) are evaluated, along with optional Bundle Adjustment and Fine-tuning.", "section": "Experiments"}, {"figure_path": "bqGAheAeQY/tables/tables_7_1.jpg", "caption": "Table 3: Ablation study. The contribution of different parts from our method. See details in the text.", "description": "This ablation study analyzes the impact of different components of the proposed TRACKSTO4D model on its performance.  It systematically removes or modifies parts of the architecture (e.g., using different attention mechanisms, removing specific loss terms, altering the number of basis elements) and evaluates the resulting effect on key metrics such as Absolute Relative Error (Abs Rel), percentage of points with depth error less than 1.25, 1.25^2, 1.25^3, reprojection error, absolute trajectory error (ATE), relative pose translation and rotation error (RPE Trans, RPE Rot). This allows researchers to understand the contribution of each component and to identify the most crucial parts of the model's design.", "section": "3 Experiments"}, {"figure_path": "bqGAheAeQY/tables/tables_16_1.jpg", "caption": "Table 4: Tracking Error. The table demonstrates our point track error handling and contains four row sections. 1. Ours: our results when evaluating on the original CoTracker point tracks from the pet test set. 2. \u03c3 = 1, 5, 10: our results using the original CoTracker point tracks with added Gaussian noise with corresponding standard deviation in pixels. 3. 10,20,50% outliers: our results using the original CoTracker point tracks where respectively 10,20,50 percent of the tracks are replaced with uniformly sampled pixels. 4. 10,20,50% occlusions: same as the outlier setup, but the outlier points are marked as occluded by setting o = 0 (defined in Sec. 2), which improves outlier handling. Overall we see that our method can robustly handle the noisy CoTracker inputs, and can further tolerate a significant level of synthetically added noise.", "description": "This table presents an ablation study on the robustness of the proposed method to noisy and incomplete point track data.  It shows the effect of adding Gaussian noise, replacing tracks with outliers, and simulating occlusions on the accuracy of the method. The results demonstrate that the model is robust to a significant level of noise and missing data.", "section": "Supplementary results"}, {"figure_path": "bqGAheAeQY/tables/tables_16_2.jpg", "caption": "Table 5: TAPIR point tracks. Comparison of using our method with TAPIR [11] point tracks as input at inference time versus using CoTracker [20], which was used for training our method, on the pet test set. As can be seen, our method is robust to the point tracks obtained by TAPIR, and the results are further improved when applying test time finetuning (FT).", "description": "This table compares the performance of the proposed method using point tracks from two different tracking methods: CoTracker and TAPIR.  It shows that the method is robust to the choice of tracking method, and that performance improves further with fine-tuning.", "section": "A Supplementary results"}, {"figure_path": "bqGAheAeQY/tables/tables_17_1.jpg", "caption": "Table 1: Pet evaluation. Top: Baseline method results for structure or camera estimation (or both). Bottom: Our results with several configurations. (C),(D), or (CD) respectively indicate the object categories in the training set: cats, dogs, or both. BA and FT respectively indicate a post-processing of Bundle Adjustment or fine-tuning.", "description": "This table presents a quantitative comparison of different methods for 3D reconstruction and camera pose estimation using casual videos of cats and dogs.  The top section shows results from baseline methods, while the bottom section details the performance of the proposed TRACKSTO4D method under various configurations.  Different training configurations are compared, including training only on cats (C), only on dogs (D), or on both (CD).  Post-processing techniques such as Bundle Adjustment (BA) and fine-tuning (FT) are also evaluated.", "section": "3 Experiments"}, {"figure_path": "bqGAheAeQY/tables/tables_17_2.jpg", "caption": "Table 7: Comparisons with Marigold. Comparison with the Marigold depth prediction method [21] on the pet test set. As can be seen, our depth accuracy is much higher.", "description": "This table compares the depth accuracy of the proposed method (TRACKSTO4D) with the Marigold method on the pet test set.  It shows metrics such as Absolute Relative error, percentage of points with depth error less than 1.25, 1.25^2, and 1.25^3.  The results demonstrate that TRACKSTO4D achieves significantly higher depth accuracy compared to Marigold.", "section": "Experiments"}, {"figure_path": "bqGAheAeQY/tables/tables_18_1.jpg", "caption": "Table 8: Tracking Grid Size Effect Quantitative evaluation of the effect of reducing the number of sampled point tracks at inference time on our model that was trained on cats (C). We measure the camera pose accuracy and the running time. We also mention the point tracks extraction time in parenthesis (e.g. +8.6 seconds) which is performed by [20] as a preprocess. As can be seen, our method can handle a smaller number of points but the accuracy slightly drops with fewer sampled points", "description": "This table shows the effect of reducing the number of point tracks used as input to the model at inference time.  The experiment was run using the model trained on the 'cat' category.  It shows the camera pose accuracy (ATE, RPE Trans, RPE Rot) and inference time for different grid sizes (number of points).  Inference time excludes the point track extraction time, which is noted separately in parentheses.", "section": "Experiments"}, {"figure_path": "bqGAheAeQY/tables/tables_18_2.jpg", "caption": "Table 1: Pet evaluation. Top: Baseline method results for structure or camera estimation (or both). Bottom: Our results with several configurations. (C),(D), or (CD) respectively indicate the object categories in the training set: cats, dogs, or both. BA and FT respectively indicate a post-processing of Bundle Adjustment or fine-tuning.", "description": "This table presents a comparison of different methods for 3D reconstruction and camera pose estimation from casual videos of pets. The top section shows baseline methods' results, while the bottom section presents the results obtained by the proposed TRACKSTO4D method using various configurations (training only on cats, only on dogs, or on both; with or without Bundle Adjustment and fine-tuning).  The metrics used are Absolute Relative Error (Abs Rel), percentage of points with depth error less than a given threshold (\u03b4 < 1.25, \u03b4 < 1.25\u00b2, \u03b4 < 1.25\u00b3), and camera pose errors (ATE, RPETrans, RPERot).  The table also includes the inference time.", "section": "3 Experiments"}, {"figure_path": "bqGAheAeQY/tables/tables_19_1.jpg", "caption": "Table 1: Pet evaluation. Top: Baseline method results for structure or camera estimation (or both). Bottom: Our results with several configurations. (C),(D), or (CD) respectively indicate the object categories in the training set: cats, dogs, or both. BA and FT respectively indicate a post-processing of Bundle Adjustment or fine-tuning.", "description": "This table presents a comparison of the TRACKSTO4D model's performance against several baseline methods on a pet video dataset.  The top section shows results from existing methods for structure and/or camera estimation. The bottom section details the TRACKSTO4D results under different configurations (training only on cats, dogs, or both; with or without bundle adjustment post-processing; and with or without fine-tuning).  Metrics include absolute relative error, delta thresholds, average translational error, and reprojection error.", "section": "Experiments"}, {"figure_path": "bqGAheAeQY/tables/tables_20_1.jpg", "caption": "Table 1: Pet evaluation. Top: Baseline method results for structure or camera estimation (or both). Bottom: Our results with several configurations. (C),(D), or (CD) respectively indicate the object categories in the training set: cats, dogs, or both. BA and FT respectively indicate a post-processing of Bundle Adjustment or fine-tuning.", "description": "This table presents a quantitative comparison of the proposed TRACKSTO4D method against several baseline methods for 3D structure and camera pose estimation on a dataset of casual pet videos.  The top section shows results from baseline methods, while the bottom section details the performance of TRACKSTO4D under various configurations (training only on cats, dogs, or both; with and without bundle adjustment and fine-tuning). The metrics used for comparison include Absolute Relative error, percentage of points with depth error less than a certain threshold (\u03b4 < 1.25, \u03b4 < 1.25^2, \u03b4 < 1.25^3), and others.", "section": "3 Experiments"}, {"figure_path": "bqGAheAeQY/tables/tables_21_1.jpg", "caption": "Table 1: Pet evaluation. Top: Baseline method results for structure or camera estimation (or both). Bottom: Our results with several configurations. (C),(D), or (CD) respectively indicate the object categories in the training set: cats, dogs, or both. BA and FT respectively indicate a post-processing of Bundle Adjustment or fine-tuning.", "description": "This table presents a quantitative comparison of the proposed TRACKSTO4D method against several baseline methods for 3D structure and camera pose estimation.  The top section shows results from existing methods. The bottom section shows results for TRACKSTO4D under various configurations, indicating whether training data included cats, dogs, or both; whether Bundle Adjustment (BA) or fine-tuning (FT) post-processing was applied.  Metrics include Absolute Relative error (Abs Rel), percentage of points with less than a certain depth error (\u03b4), Average Translation Error (ATE), and Relative Pose Errors (RPE).  Lower values for Abs Rel and ATE are better, while higher values for \u03b4 are better.", "section": "Experiments"}, {"figure_path": "bqGAheAeQY/tables/tables_21_2.jpg", "caption": "Table 1: Pet evaluation. Top: Baseline method results for structure or camera estimation (or both). Bottom: Our results with several configurations. (C),(D), or (CD) respectively indicate the object categories in the training set: cats, dogs, or both. BA and FT respectively indicate a post-processing of Bundle Adjustment or fine-tuning.", "description": "This table presents a quantitative comparison of different methods for 3D structure and camera pose estimation using casual pet videos. The top section shows baseline methods' performance metrics, while the bottom section displays the proposed TRACKSTO4D method's performance under various configurations (training on cats only, dogs only, or both; with or without bundle adjustment; and with or without fine-tuning).  Metrics include Absolute Relative error (Abs Rel), percentage of points with depth error less than 1.25, 2.5, and 3 times the ground truth depth (\u03b4<1.25, \u03b4<2.5, \u03b4<3), Average Translation Error (ATE), Relative Pose Error Translation (RPETrans), and Relative Pose Error Rotation (RPERot).  Inference Time is also reported.", "section": "3 Experiments"}, {"figure_path": "bqGAheAeQY/tables/tables_22_1.jpg", "caption": "Table 1: Pet evaluation. Top: Baseline method results for structure or camera estimation (or both). Bottom: Our results with several configurations. (C),(D), or (CD) respectively indicate the object categories in the training set: cats, dogs, or both. BA and FT respectively indicate a post-processing of Bundle Adjustment or fine-tuning.", "description": "This table presents a comparison of the proposed TRACKSTO4D model against several baseline methods for 3D structure and camera pose estimation using casual videos of cats and dogs.  The top section shows baseline results, while the bottom section presents results for TRACKSTO4D under various configurations, including training on cats only, dogs only, or both, and with or without post-processing steps such as bundle adjustment (BA) and fine-tuning (FT).  Metrics include Absolute Relative error, percentage of points with depth error less than 1.25, ATE, and RPE.", "section": "Experiments"}, {"figure_path": "bqGAheAeQY/tables/tables_22_2.jpg", "caption": "Table 2: Out-of-training-domain evaluation. Evaluation metrics on monocular videos from [62]. The table has the same structure as Tab. 1.", "description": "This table presents the quantitative results of the TRACKSTO4D model on videos from the Nvidia Dynamic Scenes Dataset [62], which are outside the training data distribution (out-of-domain).  The metrics used are identical to those in Table 1 (Abs Rel, \u03b4<1.25, ATE, RPETrans, RPERot, Time). The table shows how well the model generalizes to unseen video categories.", "section": "Experiments"}, {"figure_path": "bqGAheAeQY/tables/tables_23_1.jpg", "caption": "Table 2: Out-of-training-domain evaluation. Evaluation metrics on monocular videos from [62]. The table has the same structure as Tab. 1.", "description": "This table presents the quantitative results of TRACKSTO4D on videos from the Nvidia Dynamic Scenes Dataset [62], which contains dynamic scenes with various motion profiles and object types.  The results demonstrate the generalization capability of TRACKSTO4D to unseen data, comparing metrics (Absolute Relative error, etc.) against baseline methods. The structure of this table is identical to Table 1.", "section": "Experiments"}]