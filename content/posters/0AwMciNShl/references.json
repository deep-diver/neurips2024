{"references": [{"fullname_first_author": "Alec Radford", "paper_title": "Learning transferable visual models from natural language supervision", "publication_date": "2021-MM-DD", "reason": "This paper introduces CLIP, a model that significantly impacts text-to-image and text-to-video generation evaluation, providing a crucial benchmark for assessing model performance against human perception."}, {"fullname_first_author": "Jonathan Ho", "paper_title": "Imagen Video: High definition video generation with diffusion models", "publication_date": "2022-MM-DD", "reason": "This paper introduces Imagen Video, a high-definition video generation model based on diffusion models, significantly advancing the state-of-the-art in text-to-video generation and influencing evaluation methodologies."}, {"fullname_first_author": "Ziqi Huang", "paper_title": "VBench: Comprehensive benchmark suite for video generative models", "publication_date": "2023-MM-DD", "reason": "This paper presents VBench, a comprehensive benchmark suite that provides a standardized evaluation framework for various video generation models, aiding in the development and improvement of evaluation protocols."}, {"fullname_first_author": "Yuanxin Liu", "paper_title": "FETV: A benchmark for fine-grained evaluation of open-domain text-to-video generation", "publication_date": "2023-MM-DD", "reason": "This paper introduces FETV, a benchmark designed for the fine-grained evaluation of text-to-video generation, offering more nuanced metrics and detailed insights compared to prior benchmarks."}, {"fullname_first_author": "Haoxin Chen", "paper_title": "Videocrafter: Open diffusion models for high-quality video generation", "publication_date": "2023-MM-DD", "reason": "This paper introduces Videocrafter, an open-source diffusion model for high-quality video generation, which has had a substantial impact on the field and is frequently used as a benchmark in recent studies."}]}