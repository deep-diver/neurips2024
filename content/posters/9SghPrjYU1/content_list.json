[{"type": "text", "text": "Minimax Optimal and Computationally Efficient Algorithms for Distributionally Robust Offline Reinforcement Learning ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Zhishuai Liu Duke University zhishuai.liu@duke.edu ", "page_idx": 0}, {"type": "text", "text": "Pan Xu Duke University pan.xu@duke.edu ", "page_idx": 0}, {"type": "text", "text": "Abstract ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Distributionally robust offline reinforcement learning (RL), which seeks robust policy training against environment perturbation by modeling dynamics uncertainty, calls for function approximations when facing large state-action spaces. However, the consideration of dynamics uncertainty introduces essential nonlinearity and computational burden, posing unique challenges for analyzing and practically employing function approximation. Focusing on a basic setting where the nominal model and perturbed models are linearly parameterized, we propose minimax optimal and computationally efficient algorithms realizing function approximation and initiate the study on instance-dependent suboptimality analysis in the context of robust offline RL. Our results uncover that function approximation in robust offline RL is essentially distinct from and probably harder than that in standard offline RL. Our algorithms and theoretical results crucially depend on a novel function approximation mechanism incorporating variance information, a new procedure of suboptimality and estimation uncertainty decomposition, a quantification of the robust value function shrinkage, and a meticulously designed family of hard instances, which might be of independent interest. ", "page_idx": 0}, {"type": "text", "text": "1 Introduction ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Offline reinforcement learning (RL) [17, 18], which aims to learn an optimal policy achieving maximum expected cumulative reward from a pre-collected dataset, plays an important role in critical domains where online exploration is infeasible due to high cost or ethical issues, such as precision medicine [49, 11, 22, 21] and autonomous driving [32, 43]. The foundational assumption of offline RL [18, 15, 53] is that the offline dataset is collected from the same environment where learned policies are intended to be deployed. However, this assumption can be violated in practice due to temporal changes in dynamics. In such cases, standard offline RL could face catastrophic failures [10, 31, 64]. To address this issue, the robust offine RL [28, 30] focuses on robust policy training against the environment perturbation, which serves as a promising solution. Existing empirical successes of robust offline RL rely heavily on expressive function approximations [37, 36, 25, 45, 63, 16], as the omnipresence of applications featuring large state and action spaces necessitates powerful function representations to enhance generalization capability of decision-making in RL. ", "page_idx": 0}, {"type": "text", "text": "To theoretically understand robust offline RL with function approximation, the distributionally robust Markov decision process (DRMDP) [39, 30, 13] provides an established framework. In stark contrast to the standard MDP, DRMDP specifically tackles the model uncertainty by forming an uncertainty set around the nominal model, and takes a max-min formulation aiming to maximize the value function corresponding to a policy, uniformly across all perturbed models in the uncertainty set [55, 52, 57, 35, 41, 59, 40]. The core of DRMDPs lies in achieving an amenable combination of uncertainty set design and corresponding techniques to solve the inner optimization over the uncertainty set. However, this consideration of model uncertainty introduces fundamental challenges to function approximation in terms of computational and statistical efficiency, particularly given the need to maximally exploit essential information in the offline dataset. For instance, in cases where the state and action spaces are large, the commonly used $(s,a)$ -rectangular uncertainty set can make the inner optimization computationally intractable for function approximation [66]. Additionally, the distribution shifts, arising from the mismatch between the behavior policy and the target policy, as well as the mismatch between the nominal model and perturbed models, complicate the statistical analysis [41, 4]. Several recent works attempt to conquer these challenges. Panaganti et al. [35] studied the $(s,a)$ -rectangularity, and their algorithm may suffer from the above mentioned computational issue. Additionally,the $(s,a)$ -rectangular uncertainty set may contain transitions that would never happen in reality, and thus leads to conservative policies; Blanchet et al. [4] proposed a novel double pessimism principle, while their algorithm requires strong oracles, which is not practically implementable. Meanwhile, a line of works study function approximation in the online setting [44, 38, 51, 3, 20] or with a simulator [66], which are not applicable to ofline RL. Thus, the following question arises: ", "page_idx": 0}, {"type": "text", "text": "", "page_idx": 1}, {"type": "text", "text": "Is it possible to design a computationally effcient and minimax optimal algorithm for robust offlineRLwith function approximation? ", "text_level": 1, "page_idx": 1}, {"type": "text", "text": "To answer the above question, we focus on a basic setting of $d$ -rectangularlinearDRMDP,where the nominal model is a standard linear MDP, and all perturbed models are parameterized in a linearly structured uncertainty set. We provide the first instance-dependent suboptimality analysis in the DRMDP literature with function approximation, which offers insights into the problem's intrinsic characteristics and challenges. Concretely, our contributions are summarized as follows. ", "page_idx": 1}, {"type": "text", "text": "\u00b7 We propose a computationally efficient algorithm, Distributionally Robust Pessimistic Value Iteration (DRPV1), based on the pessimism principle [15, 53, 41] with a new function approximation mechanism explicitly devised for $d$ -rectangular linear DRMDPs. We show that DRPVI achieves the following instance-dependent upper bound on the suboptimality gap: ", "page_idx": 1}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\beta_{1}\\cdot\\operatorname*{sup}_{P\\in{\\mathscr{U}}^{\\rho}(P^{0})}\\sum_{h=1}^{H}{\\mathbb{E}}^{\\pi^{\\star},P}\\big[\\sum_{i=1}^{d}\\|\\phi_{i}(s_{h},a_{h})\\mathbf{1}_{i}\\|_{\\Lambda_{h}^{-1}}|s_{1}=s\\big]^{1},}\\end{array}\n$$", "text_format": "latex", "page_idx": 1}, {"type": "text", "text": "This bound resembles those established in offline RL within standard linear MDPs [15, 62, 54]. However, there are two significant differences in our results. First, our bound depends on the supremum over the uncertainty set of transition kernels instead of one single transition kernel. Second, our result relies on a diagonal-based normalization, instead of the Mahalanobis norm of the featurevector, $\\|\\phi(s_{h},a_{h})\\|_{\\mathbf{A}_{h}^{-1}}$ . See Table 1 for a clearer comparison. These two distinctions are unique to DRMDPs with function approximation, which we discuss in more details in Section 4. Moreover, our analysis provides a novel pipeline for studying instance-dependent upper bounds of computationally efficient algorithms under $d$ -rectangular linear DRMDPs. ", "page_idx": 1}, {"type": "text", "text": "\u00b7 We improve DRPVI by incorporating variance information into the new function approximation mechanism, resulting in the VA-DRPVI algorithm, which achieves a smaller upper bound: ", "page_idx": 1}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\beta_{2}\\cdot\\operatorname*{sup}_{P\\in\\mathcal{U}^{\\rho}(P^{0})}\\sum_{h=1}^{H}\\mathbb{E}^{\\pi^{\\star},P}\\big[\\sum_{i=1}^{d}\\|\\phi_{i}(s_{h},a_{h})\\mathbf{1}_{i}\\|_{\\Sigma_{h}^{\\star-1}}|s_{1}=s\\big]^{2}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 1}, {"type": "text", "text": "This improves the result of DRPVI due to the fact that $\\Sigma_{h}^{\\star-1}\\preceq H^{2}\\Lambda_{h}^{-1}$ by definition [60, 54]. Furthermore, when the uncertainty level $\\rho=O(1)$ , we show that the robust value function attains a Range Shrinkage property, leading to an improvement in the upper bound by an order of $H$ .This explicit improvement is new in variance-aware algorithms, and is unique to DRMDPs. ", "page_idx": 1}, {"type": "text", "text": "\u00b7 We further establish an information-theoretic lower bound. We prove that the upper bound of VA-DRPVI matches the information-theoretic lower bound up to $\\beta_{2}$ , which implies that VA-DRPVI is near-optimal in the sense of information theory. Importantly, both DRPVI and VA-DRPVI are computationally efficient and do not suffer from the high computational burden, as discussed above in settings with the $(s,a)$ -rectangular uncertainty set, due to a decoupling property of the $d$ -rectangular uncertainty set (see Remark 4.1 for more details). Thus, we confirm that, for robust offline RL with function approximation, both the computational efficiency and minimax optimality are achievable under the setting of $d$ -rectangular linear DRMDPs. ", "page_idx": 1}, {"type": "table", "img_path": "9SghPrjYU1/tmp/64af41897be6b26e628dafe539736f154094bedc1b151c57d90461f4b505f3ed.jpg", "table_caption": ["Table 1: Summary of instance-dependent results in offline RL with linear function approximation. $\\Lambda_{h}$ and $\\Sigma_{h}^{\\star}$ are the empirical covariance matrix defined in (4.3) and (5.5) respectively. Note that $\\pi^{\\star}$ means the optimal policy in standard MDPs and the optimal robust policy in DRMDPs. The definitionof $\\Sigma_{h}^{\\star}$ also depends on the corresponding definition of $\\pi^{\\star}$ "], "table_footnote": [], "page_idx": 2}, {"type": "text", "text": "Our algorithm design and theoretical analysis draw inspiration from two crucial ideas proposed in standard linear MDPs: the reference-advantage decomposition [54] and the variance-weighted ridge regression [65]. However, the unique challenges in DRMDPs necessitate novel treatments that go far beyond a combination of existing techniques. Specifically, existing analysis of standard linear MDPs highly relies on the linear dependency of the Bellman equation on the (nominal) transition kernel. This linear dependency is disrupted by the consideration of model uncertainty, which induces essential nonlinearity that significantly complicates the statistical analysis of estimation error. To obtain our instance-dependent upper bounds, we establish a new theoretical analysis pipeline. This pipeline starts with a nontrivial decomposition of the suboptimality, and employs a new uncertainty decomposition that transforms the estimation uncertainty over all perturbed models to estimation uncertainty under the nominal model. ", "page_idx": 2}, {"type": "text", "text": "The information-theoretic lower bound in our paper is the first of its kind in the linear DRMDP setting, which could be of independent interest to the community. Previous lower bounds, which are based on the commonly used Assouad's method and established under the standard linear MDP, do not consider model uncertainty. In particular, one prerequisite for applying Assouad's method is switching the initial minimax objective to a minimax risk in terms of Hamming distance. The intertwining of this prerequisite with the nonlinearity induced by the model uncertainty makes the analysis significantly more challenging. To this end, we construct a novel family of hard instances, carefully designed to (1) mitigate the nonlinearity caused by the model uncertainty, (2) fulfil the prerequisite for Assouad's method, and (3) be concise enough to admit matrix analysis. ", "page_idx": 2}, {"type": "text", "text": "Notations: We denote $\\Delta(S)$ as the set of probability measures over some set $\\boldsymbol{S}$ . For any number $H\\,\\in\\,\\mathbb{Z}_{+}$ , we denote $[H]$ as the set of $\\{1,2,\\cdot\\cdot\\cdot,H\\}$ . For any function $V\\,:\\,\\mathcal{S}\\,\\rightarrow\\,\\mathbb{R}$ ,we denote $[\\mathbb{P}_{h}V](s,a)\\,=\\,\\mathbb{E}_{s^{\\prime}\\sim P_{h}(\\cdot\\,|s,a)}[V(s^{\\prime})]$ as the expectation of $V$ with respect to the transition kernel $P_{h}$ \uff0c $[\\mathrm{Var}_{h}V](s,a)\\,=\\,[\\mathbb{P}_{h}V^{2}](s,a)\\,-\\,([\\mathbb{P}_{h}V](s,a))^{2}$ as the variance of $V$ \uff0c $[\\mathbb{V}_{h}V](s,a)\\,=$ $\\operatorname*{max}\\{1,[\\mathrm{Var}_{h}\\,V](s,a)\\}$ as the truncated variance of $V$ , and $[V(s)]_{\\alpha}=\\operatorname*{min}\\{V(s),\\alpha\\}$ , given a scalar $\\alpha>0$ , as the truncated value of $V$ . For a vector $\\textbf{\\em x}$ , we denote $x_{j}$ as its $j$ -th entry. And we denote $[x_{i}]_{i\\in[d]}$ as a vector with the $i$ -th entry being $x_{i}$ . For a matrix $A$ ,denote $\\lambda_{i}(A)$ as the $i$ -th eigenvalue of $A$ . For two matrices $A$ and $B$ , we denote $A\\preceq B$ as the fact that $B-A$ is a positive semidefinite matrix. For any function $f:S\\to\\mathbb{R}$ , we denote $\\|f\\|_{\\infty}={\\mathrm{sup}}_{s\\in S}f(s)$ . Given $P,Q\\in\\Delta(S)$ , the total variation divergence of $P$ and $Q$ is defined as $\\begin{array}{r}{D(P||Q)=1/2\\int_{S}|P(s)-Q(s)|d s}\\end{array}$ ", "page_idx": 2}, {"type": "text", "text": "2 Most Related Work ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "DRMDPs. The DRMDP framework has been extensively studied under different settings. The works of [55, 52, 61, 26, 12] assumed precise knowledge of the environment and formulated the DRMDP as classic planning problems. The works of [67, 57, 33, 56, 42, 58] assumed access to a generative model and studied the sample complexities of DRMDPs. The works of [35, 41, 4] studied the offine setting assuming access to only an offline dataset, and established sample complexities under data coverage or concentrability assumptions. The works of [51, 3, 8, 19, 20] studied the online setting where the agent can actively interact with the nominal environment to learn the robust policy. ", "page_idx": 2}, {"type": "text", "text": "DRMDPs with linear function approximation.  Tamar et al. [44], Badrinath and Kalathil [3] proposed to use linear function approximation to solve DRMDPs with large state and action spaces and established asymptotic convergence guarantees. Zhou et al. [66] studied the natural ActorCritic with function approximation, assuming access to a simulator. Their function approximation mechanisms depend on two novel uncertainty sets, one based on double sampling and the other on an integral probability metric. Ma et al. [24] first combined the linear MDP with the $d$ -rectangular uncertainty set [12], and proposed the setting dubbed as the $d$ -rectangular linear DRMDP, which naturally admits linear representations of the robust Q-functions3. Panaganti et al. [34] leverages the $d$ -rectangular linear DRMDP framework to address the distribution shift problem in offline linear MDPs. Blanchet et al. [4] studied the offline $d$ -rectangular linear DRMDP setting, for which the provable efficiency is established under a double pessimism principle. Liu and $\\mathrm{Xu}$ [20] then studied the online $d$ -rectangular linear DRMDP setting and pointed out that the intrinsic nonlinearity of DRMDPs might pose additional challenges for linear function approximation. After the release of our work, a concurrent study [48] emerged, which independently investigated offline DRMDPs with linear function approximation. Their algorithms attained the same instance-dependent suboptimalities as our proposed algorithms DRPVI and VA-DRPVI. Their algorithm DROP also achieved the same order of worst-case suboptimality, ${\\tilde{O}}(d H^{2}/{\\sqrt{K}})$ , as our DRPVI. However, we further demonstrated that our algorithm VA-DRPVI can strictly improve this result to $\\tilde{O}(d H\\operatorname*{min}\\{1/\\rho,H\\}/\\sqrt{K})$ . Moreover, we introduced a novel hard instance and established the first information-theoretic lower bound for offline DRMDPs with linear function approximation. We also note that there is a line of works [4, 35] studied general function approximation under DRMDPs with the commonly studied $(s,a)$ -rectangularity uncertainty sets, where no further structure is applied except the rectangularity. ", "page_idx": 3}, {"type": "text", "text": "3 Problem Formulation ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "In this section, we provide the preliminary of $d$ -rectangular linear DRMDPs, and describe the dataset as well as the learning goal in offine reinforcement learning. ", "page_idx": 3}, {"type": "text", "text": "Standard MDPs. We start with the standard MDP, which constitutes the basic of DRMDPs. A finite horizon Markov decision process is denoted by $\\mathrm{MDP}({\\cal S},\\mathcal{A},{\\cal H},{\\cal P},r)$ \uff0cwhere $\\boldsymbol{S}$ and $\\boldsymbol{\\mathcal{A}}$ are the state and action spaces, $H\\ \\in\\ \\mathbb{Z}_{+}$ is the horizon length, $P~=~\\{P_{h}\\}_{h=1}^{H}$ denotes the set of probability transition keels, $r\\,=\\,\\{r_{h}\\}_{h=1}^{H}$ denotes the reward functions, More specifcally for any $(h,s,\\stackrel{.}{a})\\;\\in\\;[H]\\,\\times\\,\\mathcal{S}\\,\\times\\,\\mathcal{A}$ , the transition kernel $P_{h}(\\cdot|s,a)$ is a probability function over the state space $\\boldsymbol{S}$ , and the reward function $r_{h}:\\mathcal{S}\\times\\mathcal{A}\\to[0,1]$ is assumed to be deterministic for simplicitAequeneof deterministi policieisdentdas $\\stackrel{\\triangledown}{\\boldsymbol{\\pi}}=\\{\\pi_{h}\\}_{h=1}^{H}$ where $\\pi_{h}:{\\mathcal{S}}\\rightarrow A$ .sn the policy for step $h\\in[H]$ . Given any policy $\\pi$ and transition $P$ , for all $(\\hat{s},a,h)\\in\\mathcal{S}\\times\\mathcal{A}\\times[H]$ the corresponding value function $\\begin{array}{r}{V_{h}^{\\pi,P}(s)\\;:=\\;\\mathbb{E}^{\\pi,P}\\big[\\sum_{t=h}^{H}r_{t}(s_{t},a_{t})\\big|s_{h}\\;=\\;s\\big]}\\end{array}$ [\u2265t=h rt(st, at)|sh = s] and Q-function $\\begin{array}{r}{Q_{h}^{\\pi,P}(s,a):=\\mathbb{E}^{\\pi,P}\\big[\\sum_{t=h}^{H}r_{t}(s_{t},a_{t})\\big|s_{h}=s,a_{h}=a\\big]}\\end{array}$ characterize theexectedcumulative was starting from step $h$ , and both of them are bounded in $[0,H]$ ", "page_idx": 3}, {"type": "text", "text": "Distributionally robust MDPs. A finite horizon distributionally robust Markov decision process is denoted by L $\\begin{array}{r l}\\end{array},\\begin{array}{r l}\\end{array},\\begin{array}{r l}\\end{array},\\begin{array}{r l}\\end{array},$ where $P^{0}=\\{P_{h}^{0}\\}_{h=1}^{H}$ iste set of nominal transion kernels, and $\\mathcal{U}^{\\rho}(P^{0})=\\otimes_{h\\in[H]}\\mathcal{U}_{h}^{\\rho}(P_{h}^{0})$ is the uncertainty set of transitions, where each $\\mathcal{U}_{h}^{\\rho}(P_{h}^{0})$ .s usually defined as a ball centered at $P^{0}$ with radius/uncertainty level $\\rho\\geq0$ based on some probability divergence measures [13, 57, 56]. To account for the model uncertainty, the robust value function $\\begin{array}{r}{V_{h}^{\\pi,\\rho}(s)\\,:=\\,\\operatorname*{inf}_{P\\in{\\mathcal{U}}^{\\rho}(P^{0})}V_{h}^{\\pi,P}(s),\\,\\forall(h,s)\\,\\in\\,[H]\\,\\times\\,S}\\end{array}$ is defined as the value function under the worst possible transition kernel within the uncertainty set $\\mathcal{U}^{\\rho}(P^{0})$ . Similarly, the robust Q-function is defined as $Q_{h}^{\\pi,\\rho}(s,a)=\\operatorname*{inf}_{P\\in\\mathcal{U}^{\\rho}(P^{0})}Q_{h}^{\\pi,P}(s,a)$ for any $(h,s,a)\\in[H]\\times{\\mathcal{S}}\\times{\\mathcal{A}}$ . Further, we define the optimal robust value function and the optimal robust Q-function as ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\begin{array}{r}{V_{h}^{\\star,\\rho}(s)=\\operatorname*{sup}_{\\pi\\in\\Pi}V_{h}^{\\pi,\\rho}(s),\\quad Q_{h}^{\\star,\\rho}(s,a)=\\operatorname*{sup}_{\\pi\\in\\Pi}Q_{h}^{\\pi,\\rho}(s,a),\\quad\\forall(h,s,a)\\in[H]\\times\\mathcal{S}\\times\\mathcal{A}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "Where $\\Pi$ $\\pi^{\\star}=\\{\\pi_{h}^{\\star}\\}_{h=1}^{H}$ is dehinedasthe poliey that achieves the optimal robust value function: $\\pi_{h}^{\\star}(s)=\\arg\\operatorname*{sup}_{\\pi\\in\\Pi}\\ddot{V}_{h}^{\\pi,\\rho}(s),\\forall(h,s)\\in[H]\\times{\\cal S}.$ ", "page_idx": 4}, {"type": "text", "text": "$d$ -rectangular linear DRMDPs.A $d$ -rectangular linear DRMDP is a DRMDP where the nominal environment is a special case of linear MDP with a simplex feature space [14, Example 2.2] and the uncertainty set $\\bar{\\mathcal{U}_{h}^{\\rho}}(P_{h}^{0})$ is defined based on the linear structure of the nominal transition kernel $P_{h}^{0}$ In particular, we make the following assumption about the nominal environment. ", "page_idx": 4}, {"type": "text", "text": "Assumption 3.1. Let $\\phi:S\\!\\times\\!A\\to\\mathbb{R}^{d}$ be astate-ation feature mappingsuch that $\\textstyle\\sum_{i=1}^{d}\\phi_{i}(s,a)=1$ $\\phi_{i}(s,a)~\\geq~0$ , for any $(i,s,a)\\ \\in\\ [d]\\ \\times\\ S\\ \\times\\ A$ For any. $(h,s,a)~\\in~[\\overline{{H}}]^{\\sim}\\times\\mathcal{S}\\,\\times\\,\\mathcal{A}$ \u3001the reward function and the nominal transition kernels have a linear representation: $r_{h}(s,a)\\;\\;=\\;\\;$ $\\langle\\phi(s,a),\\theta_{h}\\rangle$ , and $P_{h}^{0}(\\cdot|s,a)=\\langle\\phi(s,a),\\pmb{\\mu}_{h}^{0}(\\cdot)\\rangle$ , where $\\|\\pmb{\\theta}_{h}\\|_{2}\\leq\\sqrt{d}$ and $\\pmb{\\mu}_{h}^{0}=(\\mu_{h,1}^{0},\\dots,\\mu_{h,d}^{0})^{\\top}$ are unknown probability measures over $\\boldsymbol{S}$ ", "page_idx": 4}, {"type": "text", "text": "With notations in Assumption 3.1, we define the factor uncertainty sets as $\\mathcal{U}_{h,i}^{\\rho}(\\mu_{h,i}^{0})=\\{\\mu:\\mu\\in$ $\\Delta(S),D(\\mu||\\mu_{h,i}^{0})\\leq\\rho\\},\\forall(h,i)\\in[H]\\times[d]$ ,where $D(\\cdot||\\cdot)$ is specified as the total variation (TV) divergence in this work. The uncertainty set is defined as $\\begin{array}{r}{\\mathcal{U}_{h}^{\\rho}(P_{h}^{0})\\,=\\,\\otimes_{(s,a)\\in S\\times A}\\mathcal{U}_{h}^{\\rho}(s,a;\\pmb{\\mu}_{h}^{0})}\\end{array}$ where $\\begin{array}{r}{\\mathcal{U}_{h}^{\\rho}(s,a;\\mu_{h}^{0})=\\{\\sum_{i=1}^{d}\\phi_{i}(s,a)\\mu_{h,i}(\\cdot):\\mu_{h,i}(\\cdot)\\in\\mathcal{U}_{h,i}^{\\rho}(\\mu_{h,i}^{0}),\\forall i\\in[d]\\}}\\end{array}$ A notable eature of this desig is tht thefetor uncertity sets $\\{\\mathcal{U}_{h,i}^{\\rho}(\\mu_{h,i}^{0})\\}_{h,i=1}^{H,d}$ aredecufmtstan pair $(s,a)$ and also independent with each other. As demonstrated later, this decoupling property results in a computationally efficient regime for function approximation. ", "page_idx": 4}, {"type": "text", "text": "Robust Bellman equation.Under the setting of $d$ -rectangular linear DRMDPs, it is proved that the robust value function and the robust Q-function satisfy the robust Bellman equations [20]: ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{Q_{h}^{\\pi,\\rho}(s,a)=r_{h}(s,a)+\\operatorname*{inf}_{P_{h}(\\cdot\\vert s,a)\\in\\mathcal{U}_{h}^{\\rho}(s,a;\\mu_{h}^{0})}[\\mathbb{P}_{h}V_{h+1}^{\\pi,\\rho}](s,a),}\\\\ &{\\quad V_{h}^{\\pi,\\rho}(s)=\\mathbb{E}_{a\\sim\\pi_{h}(\\cdot\\vert s)}\\bigl[Q_{h}^{\\pi,\\rho}(s,a)\\bigr],}\\end{array}\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "and the optimal robust policy $\\pi^{\\star}$ is deterministic. Thus, we can restrict the policy class $\\Pi$ to the deterministic one. This leads to the robust Bellman optimality equations: ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{Q_{h}^{\\star,\\rho}(s,a)=r_{h}(s,a)+\\operatorname*{inf}_{P_{h}(\\cdot\\vert s,a)\\in\\mathcal{U}_{h}^{\\rho}(s,a;\\mu_{h}^{0})}[\\mathbb{P}_{h}V_{h+1}^{\\star,\\rho}](s,a),}\\\\ &{\\quad V_{h}^{\\star,\\rho}(s)=\\operatorname*{max}_{a\\in\\mathcal{A}}Q_{h}^{\\star}(s,a).}\\end{array}\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "Offline Dataset and the Learning Goal. Let $\\mathcal{D}$ denote an offline dataset consisting of $K$ i.i.d trajectories generated from the nominal environment $\\mathrm{MDP}(S,{\\mathcal{A}},H,P^{0},r)$ by a behavior policy $\\pi^{b^{\\cdot}}=\\;\\{\\pi_{h}^{b}\\}_{h=1}^{\\bar{H}}$ In conerete,for ach $\\tau\\ \\in\\ [K]$ the trajctory $\\{(s_{h}^{\\tau},a_{h}^{\\tau},r_{h}^{\\tau})\\}_{h=1}^{H}$ satsfies that $a_{h}^{\\tau}\\,\\sim\\,\\pi_{h}^{b}(\\cdot|s_{h}^{\\tau}).$ \uff0c\u4e00 $r_{h}^{\\tau}\\,=\\,r_{h}\\big(s_{h}^{\\tau},a_{h}^{\\tau}\\big)$ and $s_{h+1}^{\\tau}\\,\\sim\\,P_{h}^{0}(\\cdot|s_{h}^{\\tau},a_{h}^{\\tau})$ for any $\\textit{h}\\in[H]$ The goal of the robust offline RL is to learn the optimal robust policy $\\pi^{\\star}$ using the offine dataset . We define the suboptimality gap between any policy $\\hat{\\pi}$ and the optimal robust policy $\\pi^{\\star}$ as ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\mathrm{SubOpt}(\\hat{\\pi},s_{1},\\rho):=V_{1}^{\\star,\\rho}(s_{1})-V_{1}^{\\hat{\\pi},\\rho}(s_{1}).\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "Then the goal of an algorithm in distributionally robust offline reinforcement learning is to learn a robustpolicy $\\hat{\\pi}$ that minimizes the suboptimality gap $\\mathrm{SubOpt}(\\hat{\\pi},s,\\rho)$ ,for any $s\\in S$ ", "page_idx": 4}, {"type": "text", "text": "4  Warmup: Robust Pessimistic Value Iteration ", "text_level": 1, "page_idx": 4}, {"type": "text", "text": "In this section, we first propose a simple algorithm in Algorithm 1 as a warm start, and provide an instance-dependent upper bound on its suboptimality gap in Theorem 4.4. ", "page_idx": 4}, {"type": "text", "text": "The optimal robust Bellman equation (3.2) implies that the optimal robust policy $\\pi^{\\star}$ is greedy with respect to the optimal robust Q-function. Therefore, it suffices to estimate $\\bar{Q}_{h}^{\\star,\\rho}$ to approximate $\\pi^{\\star}$ To this end, we estimate the optimal robust Q-function by iteratively performing an empirical version of the optimal robust Bellman equation similar to (3.2). In concrete, given the estimators at step $h+1$ denoted by $\\widehat{Q}_{h+1}(s,a)$ and $\\widehat V_{h+1}(s)=\\operatorname*{max}_{a\\in{\\cal A}}\\widehat Q_{h+1}(s,a)$ , Liu and $\\mathrm{Xu}$ [20] show that applying one step backward induction similar to (3.2) leads to ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\begin{array}{r}{Q_{h}(s,a)=r_{h}(s,a)+\\operatorname*{inf}_{P_{h}(\\cdot\\vert s,a)\\in\\mathcal{U}_{h}^{\\rho}(s,a;\\mu_{h}^{0})}\\left[\\mathbb{P}_{h}\\widehat{V}_{h+1}\\right](s,a)=\\langle\\phi(s,a),\\theta_{h}+\\nu_{h}^{\\rho}\\rangle,}\\end{array}\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "where $\\begin{array}{r}{\\nu_{h,i}^{\\rho}\\;:=\\;\\operatorname*{max}_{\\alpha\\in[0,H]}\\{z_{h,i}(\\alpha)\\,-\\,\\rho(\\alpha-\\operatorname*{min}_{s^{\\prime}}[\\widehat{V}_{h+1}(s^{\\prime})]_{\\alpha})\\},\\;z_{h,i}(\\alpha)\\;:=\\;\\mathbb{E}^{\\mu_{h,i}^{0}}[\\widehat{V}_{h+1}(s^{\\prime})],}\\end{array}$ $\\forall i\\in[d]$ \uff0c $[\\widehat{V}_{h+1}(s^{\\prime})]_{\\alpha}\\;=\\;\\operatorname*{min}\\{\\widehat{V}_{h+1}(s^{\\prime}),\\alpha\\}$ , and $\\alpha$ is a dual variable stemming from the dual formulation (see Proposition H.1). To estimate $Q_{h}(s,a)$ , it suffices to estimate vectors $z_{h}(\\alpha)=$ $[z_{h,1}(\\alpha),\\ldots,z_{h,d}(\\alpha)]$ and $\\nu_{h}^{\\rho}$ as follows. ", "page_idx": 5}, {"type": "text", "text": "\u00b7 Estimate $z_{h}(\\alpha)$ : note that $[\\mathbb{P}_{h}^{0}[V_{h+1}]_{\\alpha}](s,a)=\\langle\\phi(s,a),z_{h}(\\alpha)\\rangle$ by Assumption 3.1, where the expectation is taken with respect to the nominal kernel $P_{h}^{0}(\\cdot|s,a)$ . Given the estimator $\\widehat{V}_{h+1}(s)$ , it is natural to estimate $z_{h}(\\alpha)$ by solving the following ridge regression on the offine dataset $\\mathcal{D}$ ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\hat{z}_{h}(\\alpha)=\\operatorname*{argmin}_{z\\in\\mathbb{R}^{d}}\\sum_{\\tau=1}^{K}\\big(\\big[\\widehat{V}_{h+1}(s_{h+1}^{\\tau})\\big]_{\\alpha}-\\phi_{h}^{\\tau\\top}z\\big)^{2}+\\lambda\\|z\\|_{2}^{2}}\\\\ &{\\qquad={\\mathbf{A}}_{h}^{-1}\\big[\\sum_{\\tau=1}^{K}\\phi_{h}^{\\tau}[\\widehat{V}_{h+1}(s_{h+1}^{\\tau})]_{\\alpha}\\big],}\\end{array}\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "where $\\lambda>0$ \uff0c $\\phi_{h}^{\\tau}$ is a shorthand notation for $\\phi(s_{h}^{\\tau},a_{h}^{\\tau})$ , and $\\mathbf{\\Delta}\\Lambda_{h}$ is the covariance matrix: ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathbf{A}_{h}=\\sum_{\\tau=1}^{K}\\phi_{h}^{\\tau}(\\phi_{h}^{\\tau})^{\\top}+\\lambda\\mathbf{I}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "\u00b7Estimate $\\hat{\\pmb{\\nu}}_{h}^{\\rho}$ : based on $\\hat{z}_{h,i}(\\alpha)$ , we can estimate $\\hat{\\nu}_{h,i}^{\\rho}$ as follows. ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\hat{\\nu}_{h,i}^{\\rho}=\\operatorname*{max}_{\\alpha\\in[0,H]}\\{\\hat{z}_{h,i}(\\alpha)-\\rho(\\alpha-\\operatorname*{min}_{s^{\\prime}}[\\widehat{V}_{h+1}^{\\rho}(s^{\\prime})]_{\\alpha}\\},\\forall i\\in[d].}\\end{array}\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "After these two steps, we immediately obtain the estimated robust Q-function at step $h$ ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\widehat{Q}_{h}(s,a)=\\langle\\phi(s,a),\\pmb{\\theta}_{h}+\\hat{\\pmb{\\nu}}_{h}^{\\rho}\\rangle.\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "Note that these estimations are constructed based on an offline dataset $\\mathcal{D}$ , which is known to cause distributional shift. We propose to incorporate a penalty term in the estimator (4.5) following the pessimism principle in the face of uncertainty [15, 53, 41]. ", "page_idx": 5}, {"type": "text", "text": "Algorithm 1 Distributionally Robust Pessimistic Value Iteration (DRPVI)   \nRequire: Input dataset $\\mathcal{D}$ and parameter $\\beta_{1};\\,\\widehat{V}_{H+1}^{\\rho}(\\cdot)=0$ $h=H,\\cdots\\,,1$ $\\begin{array}{r}{\\mathbf{A}_{h}\\leftarrow\\sum_{\\tau=1}^{K}\\phi_{h}^{\\tau}\\phi_{h}^{\\tau\\top}+\\lambda I}\\end{array}$ $i=1,\\cdots,d$   \n4: Update $\\hat{\\nu}_{h,i}^{\\rho}$ according to (4.4)   \n5: end for   \n6: $\\begin{array}{r l}&{\\overset{\\mathrm{sum~sen}}{\\Gamma_{h}}}\\\\ &{\\overset{\\mathrm{f}}{\\cap}(\\cdot,\\cdot)\\leftarrow\\beta_{1}\\sum_{i=1}^{d}\\big\\|\\phi_{i}(\\cdot,\\cdot)\\mathbf{1}_{i}\\big\\|_{\\mathbf{A}_{h}^{-1}}}\\\\ &{\\overset{\\mathrm{f}}{\\hat{Q}_{h}^{\\rho}}(\\cdot,\\cdot)\\leftarrow\\big\\{\\phi(\\cdot,\\cdot)^{\\top}(\\theta_{h}+\\hat{\\nu}_{h}^{\\rho})-\\Gamma_{h}(\\cdot,\\cdot)\\big\\}_{[0,H-h+1]}}\\\\ &{\\overset{\\mathrm{f}}{\\pi}_{h}(\\cdot|\\cdot)\\leftarrow\\mathrm{argmax}_{\\pi_{h}}\\,\\langle\\widehat{Q}_{h}^{\\rho}(\\cdot,\\cdot),\\pi_{h}(\\cdot|\\cdot)\\rangle_{A},\\mathrm{and}\\,\\widehat{V}_{h}^{\\rho}(\\cdot)\\leftarrow\\langle\\widehat{Q}_{h}^{\\rho}(\\cdot,\\cdot),\\hat{\\pi}_{h}(\\cdot|\\cdot)\\rangle_{A}}\\end{array}$   \n7:   \n8:   \n9: end for ", "page_idx": 5}, {"type": "text", "text": "Remark 4.1. In Algorithm 1, the pessimism is achieved by subtracting a robust penalty term, $\\begin{array}{r}{\\sum_{i=1}^{d}\\left|\\left|\\phi_{i}(\\cdot,\\cdot)\\mathbf{1}_{i}\\right|\\right|_{\\mathbf{A}_{h}^{-1}}}\\end{array}$ from the robust Q-funetion estimation, which is derived from bounding the robust estimation uncertainty arising from $d$ ridge regressions. In particular, at step $h\\in[H]$ , denoting $\\alpha_{i}^{\\star}\\,=\\,\\operatorname*{argmax}_{[0,H]}\\,\\bigl\\{\\widehat{z}_{h,i}(\\alpha)\\,-\\,\\rho\\bigl(\\alpha\\,-\\,\\operatorname*{min}_{s^{\\prime}}\\,\\bigl[\\widehat{V}_{h+1}^{\\rho}(s^{\\prime})\\bigr]_{\\alpha}\\bigr)\\bigr\\},\\forall i\\,\\in\\,[d]$ we solve $d$ separate ridge regressions to obtain different coordinates of $\\hat{\\pmb{\\nu}}_{h}^{\\rho}$ . This design is tailored for the $d_{\\cdot}$ -rectangular linear DRMDP, as we will see, leading to a distinct instance-dependent upper bound in Theorem 4.4. ", "page_idx": 5}, {"type": "text", "text": "Remark 4.2. Notably, to solve the optimization problem with respect to $\\alpha\\in[0,H]$ in (4.4), one will repeatedly invoke the closed form solution (4.2) for different values of $\\alpha$ . Moreover, the optimization is decoupled from the state-action pair, due to the decoupling property of $d$ -rectangular uncertainty set. Similar algorithm designs have also appeared in [24] for Kullback-Leibler divergence based linear DRMDPs and in [2O] for online linear DRMDPs. As for the computational tractability, we note that the minimization over $\\alpha$ in (4.4) has been implemented in [20] using the minimize function in the Nelder-Mead method [29] in the Python module scipy.optimize. The minimization over the state space is avoided under a \u201cfail-state\u2032 assumption, common in applications such as robotics and healthcare (see Assumption 4.1 and Remark 4.2 in their paper). Without this assumption, we can also use the Nelder-Mead method to solve it. Thus, Algorithm 1 is in general computationally tractable. ", "page_idx": 5}, {"type": "text", "text": "Before presenting the theoretical guarantee of DRPVI, we make the following data coverage assumption, which is standard for ofline linear MDPs [50, 9, 60, 54]. ", "page_idx": 6}, {"type": "text", "text": "Assumption 4.3. We assume $\\begin{array}{r}{\\kappa\\;:=\\;\\operatorname*{min}_{h\\in[H]}\\,\\lambda_{\\operatorname*{min}}\\big(\\mathbb{E}^{\\pi^{b},P^{0}}[\\phi(s_{h},a_{h})\\phi(s_{h},a_{h})^{\\top}]\\big)\\;>\\;0}\\end{array}$ for the behavior policy $\\pi^{b}$ and the nominal transition kernel $P^{0}$ ", "page_idx": 6}, {"type": "text", "text": "Assumption 4.3 requires the behavior policy to sufficiently explore the state-action space under the nominal environment. Indeed, it implicitly assumes that the nominal and perturbed environments share the same state-action space, and that the full information of this space is accessible through the nominal environment and the behavior policy $\\pi^{b}$ . Assumption 4.3 rules out cases where new states emerge in perturbed environments that can never be queried under the nominal environment as a result of the distribution shift. Now we present the theoretical guarantee for Algorithm 1. ", "page_idx": 6}, {"type": "text", "text": "Theorem 4.4. Under Assumptions 3.1 and 4.3 $\\forall K>\\operatorname*{max}\\{512\\log(2d H^{2}/\\delta)/\\kappa^{2},20449d^{2}H^{2}/\\kappa\\}$ and $\\delta\\in(0,1)$ , if we set $\\lambda=1$ and $\\beta_{1}=\\tilde{O}(\\sqrt{d}H)$ in Algorithm 1, then with probability at least $1-\\delta,\\forall s\\in S$ , the suboptimality of DRPVI satisfies ", "page_idx": 6}, {"type": "equation", "text": "$$\n\\mathrm{SubOpt}(\\hat{\\pi},s,\\rho)\\leq\\beta_{1}\\cdot\\operatorname*{sup}_{P\\in\\mathcal{U}^{\\rho}(P^{0})}\\sum_{h=1}^{H}\\mathbb{E}^{\\pi^{\\star},P}\\bigg[\\sum_{i=1}^{d}\\|\\phi_{i}(s_{h},a_{h})\\mathbf{1}_{i}\\|_{\\mathbf{A}_{h}^{-1}}\\big|s_{1}=s\\bigg],\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "where $\\Lambda_{h}$ is the empirical covariance matrix defined in (4.3) ", "page_idx": 6}, {"type": "text", "text": "The result in Theorem 4.4 resembles existing instance-dependent bounds for standard linear MDPs [15, 54] (see Table 1 for a detailed comparison). However, there are two major distinctions between these results. First, our result depends on the weighted sum of diagonal elements $\\begin{array}{r}{\\sum_{i=1}^{d}\\|\\phi_{i}(s_{h},a_{h})\\mathbf{1}_{i}\\|_{\\mathbf{A}_{h}^{-1}}}\\end{array}$ dubbed as the $d$ -rectangular robust estimation error, instead of the Mahalanobis norm of the feature vector $\\|\\phi(s_{h},a_{h})\\|_{\\mathbf{A}_{h}^{-1}}$ . As discussed in Remark 4.1, this term primarily arises due to the necessity to solve $d$ distinct ridge regressions in each step, which presents a unique challenge in our analysis. Second, we consider the supremum expectation of $d$ -rectangular robust estimation error with respect to all transition kernels in the uncertainty set, which measures the worst case coverage of the covariance matrix $\\Lambda_{h}$ under the optimal robust policy $\\pi^{\\star}$ ", "page_idx": 6}, {"type": "text", "text": "To connect with existing literature [4], we further show that under Assumption 4.3, the instancedependent suboptimality bound can be simplified as follows. ", "page_idx": 6}, {"type": "text", "text": "Corollary 4.5. Under the same assumptions and settings as Theorem 4.4, with probability at least $1-\\delta$ for all $s\\in S$ , the suboptimality of DRPVI satisfies $\\mathrm{SubOpt}(\\hat{\\pi},s,\\rho)=\\tilde{O}(\\bar{\\sqrt{d}}H^{2}/(\\bar{\\sqrt{\\kappa\\cdot K}}))$ ", "page_idx": 6}, {"type": "text", "text": "Remark 4.6. Since $\\|\\phi(\\cdot,\\cdot)\\|_{2}\\leq1$ by Assumption 3.1, the coverage parameter $\\kappa$ is trivially upper bounded by $1/d$ Assuming that $\\kappa=c^{\\dagger}/d$ for a constant $0<c^{\\dagger}<1$ , then we have $\\mathrm{SubOpt}(\\hat{\\pi},s,\\rho)=$ $\\tilde{O}(d H^{2}/(c^{\\dagger}\\cdot\\sqrt{K}))$ . This bound improves the state-of-the-art, [4, Theorem 6.3], by $O(d)$ ", "page_idx": 6}, {"type": "text", "text": "5  Distributionally Robust Variance-Aware Pessimistic Value Iteration ", "text_level": 1, "page_idx": 6}, {"type": "text", "text": "The instance-dependent bound in Theorem 4.4 has an explicit dependency on $H$ , which arises from the fact that $Q_{h}^{\\rho}(s,a)\\in[0,H]$ forany $(h,\\rho)\\in[H]\\times(0,1]$ and the Hoeffding-type self-normalized concentration inequality used in our analysis. We will show in this section that the range of any robust value function could be much smaller under a refined analysis. Consequently, we can leverage variance information to improve Algorithm 1 and achieve a strengthened upper bound. ", "page_idx": 6}, {"type": "text", "text": "Intuition  In the robust Bellman equation (3.1), the worst-case transition kernel would put as much $V_{h+1}^{\\pi,\\rho}(s)$ denoted by $s_{\\mathrm{min}}$ value functions, and thus shrinks its range. To see this, we define $\\check{\\mu}_{h,i}=(1-\\rho)\\mu_{h,i}^{0}+\\rho\\delta_{s_{\\mathrm{min}}}$ , where $\\delta_{s_{\\mathrm{min}}}$ is the Dirac measure at $s_{\\mathrm{min}}$ and we assume $V_{h+1}^{\\pi,\\rho}(s_{\\mathrm{min}})=0$ for any $(\\pi,h)\\in\\Pi\\times[H]$ just for illustration. It is easy to verify that $\\check{\\mu}_{h,i}\\in\\mathcal{U}_{h,i}^{\\rho}(\\mu_{h,i}^{0})$ and is indeed the worst-case factor kernel. Then by (3.1) we have $V_{h}^{\\pi,\\rho}(s)=\\mathbb{E}_{a\\sim\\pi}[r_{h}(s,a)+(1-\\rho)[\\mathbb{P}_{h}^{0}V_{h+1}^{\\pi,\\rho}](s,a)]$ , which immediately implies $\\begin{array}{r}{\\operatorname*{max}_{s\\in S}V_{h}^{\\pi,\\rho}(s)\\leq1+(1-\\rho)\\operatorname*{max}_{s^{\\prime}\\in S}V_{h+1}^{\\pi,\\rho}(s^{\\prime})}\\end{array}$ . This justifes our conjecture that the range of the robust value functions shrinks over stage. We dub this phenomenon as Range Shrinkage and summarize it in the following lemma, with a more formal proof postponed to Appendix G.5. ", "page_idx": 6}, {"type": "text", "text": "Require: Input dataset $\\mathcal{D}$ \uff0c $\\mathcal{D}^{\\prime}$ and $\\beta_{2}$ $\\widehat V_{H+1}^{\\rho}(\\cdot)=0$   \n1: Run Algorithm 1 using dataset $\\mathcal{D}^{\\prime}$ to get $\\{\\widehat V_{h}^{'\\rho}\\}_{h\\in[H]}$   \n2: for $h=H,\\cdots\\,,1$ do   \n3: Construct variance estimator $\\widehat{\\sigma}_{h}^{2}(\\cdot,\\cdot;\\alpha)$ using $\\mathcal{D}^{\\prime}$ by (5.2) and (5.3)   \n4: $\\begin{array}{r l}&{\\Sigma_{h}(\\alpha)=\\sum_{\\tau=1}^{K}\\phi_{h}^{\\tau}\\phi_{h}^{\\tau\\top}/\\widehat{\\sigma}_{h}^{2}(s_{h}^{\\tau},a_{h}^{\\tau};\\alpha)+\\lambda\\mathbf{I}}\\\\ &{\\widehat{z}_{h}(\\alpha)=\\Sigma_{h}^{-1}(\\alpha)\\Big(\\sum_{\\tau=1}^{K}\\phi_{h}^{\\tau}\\big[\\widehat{V}_{h+1}^{\\rho}(s_{h+1}^{\\tau})\\big]_{\\alpha}/\\widehat{\\sigma}_{h}^{2}(s_{h}^{\\tau},a_{h}^{\\tau};\\alpha)\\Big)}\\\\ &{\\alpha_{i}=\\operatorname{argmax}_{\\alpha\\in[0,H]}\\{\\widehat{z}_{h,i}(\\alpha)-\\rho(\\alpha-\\operatorname*{min}_{\\upsilon^{\\prime}}[\\widehat{V}_{h+1}^{\\rho}(s^{\\tau})]_{\\alpha})\\},\\ \\forall i\\in[d]}\\\\ &{\\widehat{\\nu}_{h,i}^{\\rho}=\\widehat{z}_{h,i}(\\alpha_{i})-\\rho(\\alpha_{i}-\\operatorname*{min}_{\\upsilon^{\\prime}}[\\widehat{V}_{h+1}^{\\rho}(s^{\\tau})]_{\\alpha_{i}}),\\ \\forall i\\in[d]}\\\\ &{\\Gamma_{h}(\\cdot,\\cdot)\\leftarrow\\beta_{2}\\sum_{i=1}^{d}\\|\\phi_{i}(\\cdot,\\cdot)\\mathbf{1}_{i}\\|_{\\mathbf{Z}_{h}^{-1}(\\alpha_{i})}}\\\\ &{\\widehat{Q}_{h}^{\\rho}(\\cdot,\\cdot)=\\{\\phi(\\cdot,\\cdot)^{\\top}(\\theta_{h}+\\hat{\\nu}_{h}^{\\rho})-\\Gamma_{h}(\\cdot,\\cdot)\\}_{[0,H-h+1]}}\\\\ &{\\widehat{\\pi}_{h}(\\cdot)\\leftarrow\\operatorname{argmax}_{\\pi_{h}}\\langle\\widehat{Q}_{h}^{\\rho}(\\cdot,\\cdot),\\pi_{h}(\\cdot\\cdot)\\rangle_{\\alpha},\\widehat{V}_{h}^{\\rho}(\\cdot)\\leftarrow\\langle\\widehat{Q}_{h}^{\\rho}(\\cdot,\\cdot),\\widehat{\\pi}_{h}(\\cdot\\vert\\cdot)\\rangle_{\\mathscr{A}}}\\end{array}$   \n5:   \n6:   \n7:   \n8:   \n9:   \n10:   \n11\u00b7 end for ", "page_idx": 7}, {"type": "text", "text": "Lemma 5.1 (Range Shrinkage). For any $(\\rho,\\pi,h)\\in(0,1]\\times\\Pi\\times[H]$ we have ", "page_idx": 7}, {"type": "equation", "text": "$$\n\\operatorname*{max}_{s\\in\\mathcal{S}}V_{h}^{\\pi,\\rho}(s)-\\operatorname*{min}_{s\\in\\mathcal{S}}V_{h}^{\\pi,\\rho}(s)\\leq\\frac{1-(1-\\rho)^{H-h+1}}{\\rho}.\n$$", "text_format": "latex", "page_idx": 7}, {"type": "text", "text": "This phenomenon only appears in DRMDPs since the range of value function is generally. $[0,H]$ in standard MDPs. A similar phenomenon is first observed in infinite horizon tabular DRMDPs [42, Lemma 7]. One important implication of Lemma 5.1 is that the conditional variance of any value function shrinks accordingly. In particular, when $\\rho=O(1)$ , the range of any robust value function would shrink to constant order, which leads to constant order conditional variances. This motivates us to leverage the variance information in both algorithm design and theoretical analysis. Inspired by the variance-weighted ridge regression in standard linear MDPs [65, 27, 60, 54], we propose to improve the vanilla ridge regression in (4.2) by incorporating variance weights. To this end, we first propose an appropriate variance estimator, whose form is specifically motivated by our theoretical analysis framework, to quantify the variance information. ", "page_idx": 7}, {"type": "text", "text": "Variance estimation  We first run Algorithm 1 using an offline dataset $\\mathcal{D}^{\\prime}$ that is independent of $\\mathcal{D}$ to obtain estimators of the optimal robust value functions $\\{\\widehat V_{h}^{'\\rho}\\}_{h\\in[H]}$ . By Assumption 3.1, the variance of $\\big[\\widehat{V}_{h+1}^{'\\rho}\\big]_{\\alpha}$ under the nominal environment is $[\\mathrm{Var}_{h}[\\widehat{V}_{h+1}^{'\\rho}]_{\\alpha}](s,\\dot{a})=[\\mathbb{P}_{h}^{0}[\\widehat{V}_{h+1}^{'\\rho}]_{\\alpha}^{2}](s,a)-$ $([\\mathbb{P}_{h}^{0}[\\widehat{V}_{h+1}^{'\\rho}]_{\\alpha}](s,a))^{2}\\nonumber=\\langle\\phi(s,a),z_{h,2}\\rangle-(\\langle\\phi(s,a),z_{h,1}\\rangle)^{2}$ Westimate $z_{h,1}$ and $z_{h,2}$ via ridge regression similarly as in (4.2): ", "page_idx": 7}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\widetilde{z}_{h,2}(\\alpha)=\\operatorname*{argmin}_{z\\in\\mathbb{R}^{d}}\\sum_{\\tau=1}^{K}\\left(\\big[\\widehat{V}_{h+1}^{'\\rho}(s_{h+1}^{\\tau})\\big]_{\\alpha}^{2}-\\phi_{h}^{\\tau\\top}z\\right)^{2}+\\lambda\\|z\\|_{2}^{2},}\\\\ {\\widetilde{z}_{h,1}(\\alpha)=\\operatorname*{argmin}_{z\\in\\mathbb{R}^{d}}\\sum_{\\tau=1}^{K}\\big(\\big[\\widehat{V}_{h+1}^{'\\rho}(s_{h+1}^{\\tau})\\big]_{\\alpha}-\\phi_{h}^{\\tau\\top}z\\big)^{2}+\\lambda\\|z\\|_{2}^{2}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 7}, {"type": "text", "text": "We then construct the following truncated variance estimator ", "page_idx": 7}, {"type": "equation", "text": "$$\n\\widehat{\\sigma}_{h}^{2}(s,a;\\alpha):=\\operatorname*{max}\\bigg\\{1,\\big[\\phi(s,a)^{\\top}\\tilde{z}_{h,2}(\\alpha)\\big]_{[0,H^{2}]}-\\big[\\phi(s,a)^{\\top}\\tilde{z}_{h,1}(\\alpha)\\big]_{[0,H]}^{2}-\\tilde{O}\\bigg(\\frac{d H^{3}}{\\sqrt{K}\\kappa}\\bigg)\\bigg\\},\n$$", "text_format": "latex", "page_idx": 7}, {"type": "text", "text": "where the last term is a penalty to achieve pessimistic estimations of conditional variances. ", "page_idx": 7}, {"type": "text", "text": "Variance-Aware Function Approximation Mechanism Similar to the two-step estimation proce. dure of Algorithm 1, we first estimate $z_{h}(\\alpha)$ by the following variance-weighted ridge regression under the nominal environment: ", "page_idx": 7}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\hat{z}_{h}(\\alpha)=\\underset{z\\in\\mathbb{R}^{d}}{\\mathrm{argmin}}\\sum_{\\tau=1}^{K}\\frac{\\left(\\big[\\widehat{V}_{h+1}^{\\rho}(s_{h+1}^{\\tau})\\big]_{\\alpha}-\\phi_{h}^{\\tau\\top}z\\right)^{2}}{\\widehat{\\sigma}_{h}^{2}(s_{h}^{\\tau},a_{h}^{\\tau};\\alpha)}+\\lambda\\|z\\|_{2}^{2}}\\\\ &{\\quad\\quad\\quad=\\sum_{h}^{-1}(\\alpha)\\Bigg[\\underset{\\tau=1}{\\overset{K}{\\sum}}\\frac{\\phi_{h}^{\\tau}[\\widehat{V}_{h+1}^{\\rho}(s_{h+1}^{\\tau})]_{\\alpha}}{\\widehat{\\sigma}_{h}^{2}(s_{h}^{\\tau},a_{h}^{\\tau};\\alpha)}\\Bigg],}\\end{array}\n$$", "text_format": "latex", "page_idx": 7}, {"type": "text", "text": "whereZh(a)=K=1 $\\begin{array}{r}{\\pmb{\\Sigma}_{h}(\\alpha)=\\sum_{\\tau=1}^{K}\\phi_{h}^{\\tau}\\phi_{h}^{\\tau\\top}/\\widehat\\sigma_{h}^{2}(s_{h}^{\\tau},a_{h}^{\\tau};\\alpha)+\\lambda\\mathbf{I}}\\end{array}$ is the empirical variance-weighted covariance matrix, which can be deemed as an estimator of the following variance-weighted covariance matrix ", "page_idx": 8}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\pmb{\\Sigma}_{h}^{\\star}=\\sum_{\\tau=1}^{K}\\phi_{h}^{\\tau}\\phi_{h}^{\\tau\\top}/[\\mathbb{V}_{h}V_{h+1}^{\\star,\\rho}](s_{h}^{\\tau},a_{h}^{\\tau})+\\lambda\\mathbf{I}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 8}, {"type": "text", "text": "In the second step, we estimate $\\nu_{h,i}^{\\rho},\\forall i\\in[d]$ in the same way as (4.4). We then add a pessimism penalty based on $\\Sigma_{h}(\\alpha)$ . We present the full algorithm details in Algorithm 2. ", "page_idx": 8}, {"type": "text", "text": "Theorem 5.2. Under Assumptions 3.1 and 4.3, for $K>\\operatorname*{max}\\{\\tilde{O}(d^{2}H^{6}/\\kappa),\\tilde{O}(H^{4}/\\kappa^{2})\\}$ and $\\delta\\in$ $(0,1)$ , if we set $\\lambda=1/H^{2}$ and $\\beta_{2}=\\tilde{O}(\\sqrt{d})$ in Algorithm 2, then with probability at least $1-\\delta$ , the suboptimality of VA-DRPVI satisfies ", "page_idx": 8}, {"type": "equation", "text": "$$\n\\mathrm{SubOpt}(\\hat{\\pi},s,\\rho)\\le\\beta_{2}\\cdot\\operatorname*{sup}_{P\\in\\mathcal{U}^{\\rho}(P^{0})}\\sum_{h=1}^{H}\\mathbb{E}^{\\pi^{\\star},P}\\bigg[\\sum_{i=1}^{d}\\|\\phi_{i}(s_{h},a_{h})\\mathbf{1}_{i}\\|_{\\mathbf{\\Sigma}_{h}^{\\star-1}}\\big|s_{1}=s\\bigg],\n$$", "text_format": "latex", "page_idx": 8}, {"type": "text", "text": "where $\\Sigma_{h}^{\\star}$ is the population variance-weighted covariance matrix defined as in (5.5) ", "page_idx": 8}, {"type": "text", "text": "Note that the bound in Theorem 5.2 does not explicitly depend on. $H$ anymore compared with that in Theorem 4.4. A naive observation is that $[\\mathbb{V}_{h}V_{h+1}^{\\bar{\\star},\\rho}](s,a)\\in[1,H^{2}]$ . By comparing the definitions in (4.3 and (5.5), we have $\\Sigma_{h}^{\\star-1}\\preceq H^{2}\\Lambda_{h}^{-1}$ . Thus the upper bound of Algorithm 2 is never worse than that of Algorithm 1. This improvement brought by variance information is similar to that in standard linear MDPs [54, Theorem 2]. However, thanks to the range shrinkage phenomenon, we can further show that VA-DRPVI is strictly better than DRPVI when the uncertainty level is of constant order. ", "page_idx": 8}, {"type": "text", "text": "Corollary 5.3. Under the same assumptions and settings as Theorem 5.2, given the uncertainty level $\\rho$ , we have with probability at least $1-\\delta$ ,for all $s\\in S$ , the suboptimality of VA-DRPVI satisfies ", "page_idx": 8}, {"type": "equation", "text": "$$\n\\mathrm{SubOpt}(\\hat{\\pi},s,\\rho)\\leq\\beta_{2}\\cdot\\frac{(1-(1-\\rho)^{H})}{\\rho}\\cdot\\operatorname*{sup}_{P\\in\\mathcal{U}^{\\rho}(P^{0})}\\sum_{h=1}^{H}\\mathbb{E}^{\\pi^{\\star},P}\\left[\\sum_{i=1}^{d}\\|\\phi_{i}(s_{h},a_{h})\\mathbf{1}_{i}\\|_{\\mathbf{A}_{h}^{-1}}|s_{1}=s\\right].\n$$", "text_format": "latex", "page_idx": 8}, {"type": "text", "text": "Remark 5.4. Note that $(1-(1-\\rho)^{H})/\\rho=\\Theta(\\operatorname*{min}\\{1/\\rho,H\\})$ . When $\\rho=O(1)$ , the suboptimality of Algorithm 2 is strictly smaller than that of Algorithm 1 by $H$ . With a similar argument as in Remark 4.6, if we assume there exist a constant $0\\bar{<}c^{\\dagger}<1$ , such that $\\kappa=c^{\\dagger}/d$ in Assumption 4.3, then the instance-dependent upper bound can be simplifed to $\\tilde{O}(d H\\operatorname*{min}\\{1/\\rho,H\\}/(c^{\\dagger}\\cdot\\sqrt{K}))$ \uff0c which improves the state-of-the-art [4, Theorem 6.3] by $O(d H)$ when $\\rho=O(1)$ ", "page_idx": 8}, {"type": "text", "text": "6  Information-Theoretic Lower Bound ", "text_level": 1, "page_idx": 8}, {"type": "text", "text": "For a matrix $\\mathbf{A}\\in\\mathbb{R}^{d\\times d}$ and a state $s\\in S$ , we define function $\\Phi(\\cdot,\\cdot):\\mathbb{R}^{d\\times d}\\times S\\rightarrow\\mathbb{R}$ as follows. ", "page_idx": 8}, {"type": "equation", "text": "$$\n\\Phi(\\mathbf{A},s)=\\operatorname*{sup}_{P\\in\\mathcal{U}^{\\rho}(P^{0})}\\sum_{h=1}^{H}\\mathbb{E}^{\\pi^{\\star},P}\\bigg[\\sum_{i=1}^{d}\\|\\phi_{i}(s_{h},a_{h})\\mathbf{1}_{i}\\|_{\\mathbf{A}}\\|_{s_{1}}=s\\bigg].\n$$", "text_format": "latex", "page_idx": 8}, {"type": "text", "text": "It can be seen our upper bounds in previous sections primarily depend on quantities such as $\\Phi({\\bf A}_{h}^{-1},s)$ and $\\Phi(\\Sigma_{h}^{\\star-1},s)$ . Roughly speaking, these quantities characterize the discrepancy between the (weighted) covariance matrix of the ofline dataset and the state action pairs generated from the transition probability in the uncertainty set. Hence we call $\\Phi(\\cdot,\\cdot)$ the uncertainty function. ", "page_idx": 8}, {"type": "text", "text": "We now establish an information-theoretic lower bound to show that the uncertainty function is unavoidable for $d$ -rectangular linear DRMDPs. Let $\\mathcal{M}$ be a class of DRMDPs and we define $\\operatorname{SubOpt}(M,{\\hat{\\pi}},s,\\rho)$ as the suboptimality gap specific to one DRMDP instance $M\\in\\mathcal{M}$ ", "page_idx": 8}, {"type": "text", "text": "Theorem 6.1. Given uncertainty level $\\rho\\in\\left(0,3/4\\right]$ , dimension $d$ , horizon length $H$ and sample size $K>\\tilde{O}(d^{6})$ , there exists a class of $d$ -rectangular linear DRMDPs $\\mathcal{M}$ and an offline dataset $\\mathcal{D}$ of size $K$ such that for all $s\\in S$ , with probability at least $1-\\delta$ $\\operatorname*{inf}_{\\hat{\\pi}}\\operatorname{sup}_{M\\in\\mathcal{M}}$ $_1\\operatorname{SubOpt}(M,\\hat{\\pi},s,\\rho)\\geq$ $c\\cdot\\Phi(\\Sigma_{h}^{\\star-1},s)$ , where $c$ is a universal constant. ", "page_idx": 8}, {"type": "text", "text": "Theorem 6.1 shows that the uncertainty function $\\Phi(\\Sigma_{h}^{\\star-1},s)$ is intrinsic to the information-theoretic lower bound, and thus is inevitable. It is noteworthy that the lower bound in Theorem 6.1 aligns with the upper bound in Theorem 5.2 up to a factor of $\\beta_{2}$ , which implies that VA-DRPVI is minimax optimal in the sense of information theory, but with a small gap of $\\tilde{O}(\\sqrt{d})$ . Consequently, we affirm that, in the context of robust offline reinforcement learning with function approximation, both the computational efficiency and minimax optimality are achievable under the setting of $d$ -rectangular linear DRMDPs with TV uncertainty sets. Moreover, Theorem 6.1 also suggests that achieving a good robust policy necessitates the worst case coverage of the offline dataset over the entire uncertainty set of transition models, which is significantly different from standard linear MDPs where a good coverage under the nominal model is enough [15, 60, 54]. Such a distinction indicates that learning in linear DRMDPs may be more challenging in comparison to standard linear MDPs. ", "page_idx": 8}, {"type": "text", "text": "", "page_idx": 9}, {"type": "text", "text": "Further, we highlight that the hard instances we constructed also satisfy Assumption 4.3. It remains an interesting direction to explore what would happen if the nominal and perturbed environments don't share exactly the same state-action space. We conjecture that since there could be absolutely new states emerging in perturbed environments that can never be explored in the nominal environment, the policy learned merely using data collected from the nominal environment could be arbitrarily bad. ", "page_idx": 9}, {"type": "text", "text": "Challenges and novelties in construction of hard instances  Existing tight lower bound analysis in standard linear MDPs [62, 60, 54] generally depends on the Assouad's method and a family of hard instances indexed by $\\pmb{\\xi}\\in\\{-1,1\\}^{d\\bar{H}}$ . However, they do not consider model uncertainty, which largely hinders the derivation of explicit formulas for the robust value functions. Further, one prerequisite of the Assouad's method is switching the initial minimax suboptimality $\\operatorname*{inf}_{\\hat{\\pi}}\\operatorname*{max}_{M\\in\\mathcal{M}}\\operatorname{SubOpt}(\\hat{\\pi},s,\\rho)$ to a risk of the form $\\operatorname*{inf}_{\\pmb{\\xi}^{\\prime}}\\operatorname*{max}_{\\pmb{\\xi}}D_{H}(\\pmb{\\xi},\\pmb{\\xi}^{\\prime})$ ,where $D_{H}(\\cdot,\\cdot)$ is the Hamming distance. The model uncertainty significantly complicates this procedure, as the nonlinearity involved disrupts the linear dependency between the value function and the index $\\xi$ . At the core of Theorem 6.1 is a novel class of hard instances $\\mathcal{M}$ . At a high-level, the hard instances should (1) fulfill the $d\\!\\cdot$ -rectangular linear DRMDP conditions, (2) mitigate the nonlinearity caused by model uncertainty, (3) achieve the prerequisite for Assouad's method, and (4) be concise enough to admit matrix analysis. We postpone details on the construction of hard instances and the proof of Theorem 6.1 to Appendix F. ", "page_idx": 9}, {"type": "text", "text": "As a side product of Theorem 6.1, we show in the following corollary an information-theoretic lower bound in terms of the instance-dependent uncertainty function $\\Phi({\\bf A}_{h}^{-1},s)$ in Theorem 4.4. ", "page_idx": 9}, {"type": "text", "text": "Corollary 6.2. Under the same setting in Theorem 6.1, the class of hard instances $\\mathcal{M}$ and offline  dataset $\\mathcal{D}$ in Theorem 6.1 also suggests that, with probability at least $1\\ -\\ \\delta$ $\\operatorname*{inf}_{\\hat{\\pi}}\\operatorname{sup}_{M\\in\\mathcal{M}}\\operatorname{SubOpt}(\\hat{\\pi},s,\\rho)\\geq c\\cdot\\Phi(\\Lambda_{h}^{-1},s)$ where $c$ is a universal constant. ", "page_idx": 9}, {"type": "text", "text": "This implies that the uncertainty function $\\Phi({\\bf A}_{h}^{-1},s)$ in Theorem 4.4 also arises from the informationtheoretic lower bound. We note the lower bound in Corollary 6.2 matches the upper bound in Theorem $4.4~\\mathrm{up}$ to $\\beta_{1}$ , thus DRPVI is also minimax optimal in the sense of information theory, but with a larger gap of $\\tilde{O}(\\sqrt{d}H)$ . Moreover, the only difference between Theorem 6.1 and Corollary 6.2 is the covariance matrix. Due to the fact that $\\mathbf{A}_{h}^{-1}\\preceq\\boldsymbol{\\Sigma}_{h}^{\\star,-1}$ , the information-theoretic lower bound in Theorem 6.1 is indeed tighter than that in Corollary 6.2. ", "page_idx": 9}, {"type": "text", "text": "7 Conclusions ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "We studied robust offline RL with function approximation under the setting of $d$ -rectangularlinear DRMDPs with TV uncertainty sets. We first proposed the DRPVI algorithm and built up a theoretical analysis pipeline to establish the first instance-dependent upper bound on the suboptimality gap in the context of robust offline RL. We then showed an interesting range shrinkage phenomenon specific to DRMDPs, and we proposed the VA-DRPVI algorithm, which leverages the conditional variance information of the optimal robust value function. Based on the analysis pipeline built above, we show that the upper bound of VA-DRPVI achieves sharp dependence on the horizon length $H$ .In addition, we found that an uncertainty function consisting of two crucial quantities-a supremum over uncertainty set and a diagonal-based normalization-appears in all upper bounds. We further established an information-theoretic lower bound to prove that the uncertainty function is unavoidable for robust offline RL under the setting of $d$ -rectangular linear DRMDPs. ", "page_idx": 9}, {"type": "text", "text": "It remains an interesting future research question whether the computational and provable efficiency can be achieved in other settings for robust offline RL with function approximation. Another interesting future direction is to explore the unique challenges of applying general function approximation techniques in standard offline RL [6] to DRMDPs. ", "page_idx": 9}, {"type": "text", "text": "Acknowledgments ", "text_level": 1, "page_idx": 10}, {"type": "text", "text": "We would like to thank the anonymous reviewers for their helpful comments. ZL and PX was supported in part by the National Science Foundation (DMS-2323112) and the Whitehead Scholars Program at the Duke University School of Medicine. The views and conclusions in this paper are those of the authors and should not be interpreted as representing any funding agency. ", "page_idx": 10}, {"type": "text", "text": "References ", "text_level": 1, "page_idx": 10}, {"type": "text", "text": "[1]  Yasin Abbasi-Yadkori, David Pal, and Csaba Szepesvari. Improved algorithms for linear stochastic bandits. Advances in neural information processing systems, 24, 2011. (p. 46.) [2] Alekh Agarwal, Yuda Song, Wen Sun, Kaiwen Wang, Mengdi Wang, and Xuezhou Zhang. Provable benefits of representational transfer in reinforcement learning. In The Thirty Sixth Annual Conference on Learning Theory, pages 2114-2187. PMLR, 2023. (p. 16.) [3]  Kishan Panaganti Badrinath and Dileep Kalathil. Robust reinforcement learning using least squares policy iteration with provable performance guarantees. In International Conference on Machine Learning, pages 51i-520. PMLR, 2021. (pp. 2, 3, and 4.) [4] Jose Blanchet, Miao Lu, Tong Zhang, and Han Zhong. Double pessimism is provably efficient for distributionally robust offine reinforcement learning: Generic algorithm and robust partial coverage. arXiv preprint arXiv:2305.09659, 2023. (pp. 2, 3, 4, 7, and 9.) [5]  Avinandan Bose, Simon Shaolei Du, and Maryam Fazel. Offine multi-task transfer rl with representational penalization. arXiv preprint arXiv:2402.12570, 2024. (p. 16.) [6]  Jinglin Chen and Nan Jiang.  Information-theoretic considerations in batch reinforcement learning. In International Conference on Machine Learning, pages 1042-1051. PMLR, 2019. (p. 10.) [7] Yuan Cheng, Songtao Feng, Jing Yang, Hong Zhang, and Yingbin Liang. Provable benefit of multitask representation learning in reinforcement learning. Advances in Neural Information Processing Systems, 35:31741-31754, 2022. (p. 16.) [8]  Jing Dong, Jingwei Li, Baoxiang Wang, and Jingzhao Zhang. Online policy optimization for robust mdp. arXiv preprint arXiv:2209.13841, 2022. (p. 3.) [9]  Yaqi Duan, Zeyu Jia, and Mengdi Wang. Minimax-optimal off-policy evaluation with linear function approximation. In International Conference on Machine Learning, pages 2701-2709. PMLR, 2020. (p. 7.) [10] Jesse Farebrother, Marlos C Machado, and Michael Bowling. Generalization and regularization in dqn. arXiv preprint arXiv:1810.00123, 2018. (p. 1.) [11] Omer Gottesman, Fredrik Johansson, Matthieu Komorowski, Aldo Faisal, David Sontag, Finale Doshi- Velez, and Leo Anthony Celi. Guidelines for reinforcement learning in healthcare. Nature medicine, 25(1):16-18, 2019. (p. 1.) [12]  Vineet Goyal and Julien Grand-Clement. Robust markov decision processes: Beyond rectangularity. Mathematics of Operations Research, 48(1):203-226, 2023. (pp. 3 and 4.) [13]  Garud N Iyengar. Robust dynamic programming. Mathematics of Operations Research, 30(2):   \n257-280, 2005. (pp. 1 and 4.) [14]  Chi Jin, Zhuoran Yang, Zhaoran Wang, and Michael I Jordan. Provably effcient reinforcement learning with linear function approximation. In Conference on Learning Theory, pages 2137-   \n2143. PMLR, 2020. (pp. 5 and 43.) [15]  Ying Jin, Zhuoran Yang, and Zhaoran Wang. Is pessimism provably effcient for offine rl? In International Conference on Machine Learning, pages 5084-5096. PMLR, 2021. (pp. 1, 2, 3, 6,   \n7, 10, 16, 17,27, and 28.)   \n[16] Yufei Kuang, Miao Lu, Jie Wang, Qi Zhou, Bin Li, and Houqiang Li. Learning robust policy against disturbance in transition dynamics via state-conservative policy optimization. In Proceedings of the AAAl Conference on Artificial Intelligence, volume 36, pages 7247-7254, 2022. (p. 1.)   \n[17] Sascha Lange, Thomas Gabel, and Martin Riedmiller. Batch reinforcement learning. In Reinforcement learning: State-of-the-art, pages 45-73. Springer, 2012. (p. 1.)   \n[18] Sergey Levine, Aviral Kumar, George Tucker, and Justin Fu. Ofline reinforcement learning: Tutorial, review, and perspectives on open problems. arXiv preprint arXiv:2005.01643, 2020. (p. 1.)   \n[19] Zhipeng Liang, Xiaoteng Ma, Jose Blanchet, Jun Yang, Jiheng Zhang, and Zhengyuan Zhou. Single-trajectory distributionally robust reinforcement learning. In Forty-first International Conference on Machine Learning. (p. 3.)   \n[20]  Zhishuai Liu and Pan Xu. Distributionally robust off-dynamics reinforcement learning: Provable efficiency with linear function approximation. In International Conference on Artificial Intelligence and Statistics, pages 2719-2727. PMLR, 2024. (Pp. 2, 3, 4, 5, 6, 17, and 43.)   \n[21] Zhishuai Liu, Zishu Zhan, Cunjie Lin, and Baqun Zhang. Estimation in optimal treatment regimes based on mean residual lifetimes with right-censored data. Biometrical Journal, 65(8): 2200340, 2023. (p. 1.)   \n[22] Zhishuai Liu, Zishu Zhan, Jian Liu, Danhui Yi, Cunjie Lin, and Yufei Yang. On estimation of optimal dynamic treatment regimes with multiple treatments for survival data-with application to colorectal cancer study. arXiv preprint arXiv:2310.05049, 2023. (p. 1.)   \n[23] Rui Lu, Andrew Zhao, Simon S Du, and Gao Huang. Provable general function class representation learning in multitask bandits and mdp. Advances in Neural Information Processing Systems, 35:11507-11519, 2022. (p. 16.)   \n[24] Xiaoteng Ma, Zhipeng Liang, Li Xia, Jiheng Zhang, Jose Blanchet, Mingwen Liu, Qianchuan Zhao, and Zhengyuan Zhou. Distributionally robust offine reinforcement learning with linear function approximation. arXiv preprint arXiv:2209.06620, 2022. (pp. 4 and 6.)   \n[25]  Ajay Mandlekar, Yuke Zhu, Animesh Garg, Li Fei-Fei, and Silvio Savarese. Adversarially robust policy learning: Active construction of physically-plausible perturbations. In 2017 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS),pages 3932-3939. IEEE, 2017. (p. 1.)   \n[26]  Shie Mannor, Ofir Mebel, and Huan Xu. Robust mdps with k-rectangular uncertainty. Mathematics of Operations Research, 41(4):1484-1509, 2016. (p. 3.)   \n[27] Yifei Min, Tianhao Wang, Dongruo Zhou, and Quanquan Gu.  Variance-aware off-policy evaluation with linear function approximation. Advances in neural information processing systems, 34:7598-7610, 2021. (pp. 8 and 46.)   \n[28] Jun Morimoto and Kenji Doya. Robust reinforcement learning. Neural computation, 17(2): 335-359, 2005. (p.1.)   \n[29]  John A Nelder and Roger Mead. A simplex method for function minimization. The computer journal, 7(4):308-313, 1965. (p. 6.)   \n[30]  Arnab Nilim and Laurent El Ghaoui. Robust control of markov decision processes with uncertain transition matrices. Operations Research, 53(5):780-798, 2005. (p. 1.)   \n[31] Charles Packer, Katelyn Gao, Jernej Kos, Philipp Krahenbuhl, Vladlen Koltun, and Dawn Song. Assessing generalization in deep reinforcement learning. arXiv preprint arXiv:1810.12282, 2018. (p. 1.)   \n[32]  Yunpeng Pan, Ching-An Cheng, Kamil Saigol, Keuntak Lee, Xinyan Yan, Evangelos Theodorou, and Byron Boots. Agile autonomous driving using end-to-end deep imitation learning. In Robotics: science and systems, 2018. (p. 1.) [33]  Kishan Panaganti and Dileep Kalathil. Sample complexity of robust reinforcement learning with a generative model. InInternational Conference on Artificial Intelligence and Statistics, pages 9582-9602. PMLR, 2022. (p. 3.) [34] Kishan Panaganti, Zaiyan Xu, Dileep Kalathil, and Mohammad Ghavamzadeh. Bridging distributionally robust learning and offine rl: An approach to mitigate distribution shift and partial data coverage. In ICML 2024 Workshop: Foundations of Reinforcement Learning and Control-Connections and Perspectives. (p. 4.) [35] Kishan Panaganti, Zaiyan Xu, Dileep Kalathil, and Mohammad Ghavamzadeh. Robust reinforcement learning using offine data. Advances in neural information processing systems, 35:   \n32211-32224, 2022. (pp. 1, 2, 3, and 4.) [36]  Anay Pattanaik, Zhenyi Tang, Shuijing Liu, Gautham Bommannan, and Girish Chowdhary. Robust deep reinforcement learning with adversarial attacks. In Proceedings of the 17th International Conference on Autonomous Agents and MuliAgent Systems, pages 2040-2042,   \n2018. (p. 1.) [37] Lerrel Pinto, James Davidson, Rahul Sukthankar, and Abhinav Gupta. Robust adversarial reinforcement learning. In International Conference on Machine Learning, pages 2817-2826. PMLR, 2017. (p. 1.) [38]  Aurko Roy, Huan Xu, and Sebastian Pokutta. Reinforcement learning under model mismatch. Advances in neural information processing systems, 30, 2017. (p. 2.) [39] Jay K Satia and Roy E Lave Jr. Markovian decision processes with uncertain transition probabilities. Operations Research, 21(3):728-740, 1973. (p. 1.) [40]  Yi Shen, Pan Xu, and Michael Zavlanos. Wasserstein distributionally robust policy evaluation and learning for contextual bandits. Transactions on Machine Learning Research, 2024. ISSN   \n2835-8856. URL https: //openreview.net/forum?id $=$ Nmp jDHWIvg. Featured Certification. (p. 1.) [41]  Laixi Shi and Yuejie Chi. Distributionally robust model-based offine reinforcement learning with near-optimal sample complexity. Journal of Machine Learning Research, 25(200): 1-91,   \n2024. (pp. 1, 2, 3, and 6.) [42] Laixi Shi, Gen Li, Yuting Wei, Yuxin Chen, Matthieu Geist, and Yuejie Chi. The curious price of distributional robustness in reinforcement learning with a generative model. Advances in Neural Information Processing Systems, 36, 2024. (pp. 3, 8, and 40.) [43] Pei Sun, Henrik Kretzschmar, Xerxes Dotiwalla, Aurelien Chouard, Vijaysai Patnaik, Paul Tsui, James Guo, Yin Zhou, Yuning Chai, Benjamin Caine, et al. Scalability in perception for autonomous driving: Waymo open dataset. In Proceedings of the IEEE/CVF conference on computer vision and pattern rec0gnition, pages 2446-2454, 2020. (p. 1.) [44]  Aviv Tamar, Shie Mannor, and Huan Xu. Scaling up robust mdps using function approximation. In International conference on machine learning, pages 181-189. PMLR, 2014. (Ppp. 2 and 4.) [45] Chen Tessler, Yonathan Efroni, and Shie Mannor. Action robust reinforcement learning and applications in continuous control. In International Conference on Machine Learning, pages   \n6215-6224. PMLR, 2019. (p. 1.) [46]  Alexandre B. Tsybakov. Introduction to Nonparametric Estimation. Springer, New York, 2009. (p. 37.) [47] Roman Vershynin. High-dimensional probability: An introduction with applications in data science, volume 47. Cambridge university press, 2018. (p. 28.) [48] He Wang, Laixi Shi, and Yuejie Chi. Sample complexity of offine distributionally robust linear markov decision processes. arXiv preprint arXiv:2403.12946, 2024. (p. 4.)   \n[49] Lu Wang, Wei Zhang, Xiaofeng He, and Hongyuan Zha. Supervised reinforcement learning with recurrent neural network for dynamic treatment recommendation. In Proceedings of the 24thACMSIGKDD international conference on knowledge discovery & data mining,pages 2447-2456, 2018. (p. 1.)   \n[50] Ruosong Wang, Dean Foster, and Sham M Kakade. What are the statistical limits of offline rl with linear function approximation? In International Conference on Learning Representations, 2021. (p. 7.)   \n[51]  Yue Wang and Shaofeng Zou. Online robust reinforcement learning with model uncertainty. Advances in Neural Information Processing Systems, 34:7193-7206, 2021. (pp. 2 and 3.)   \n[52] Wolfram Wiesemann, Daniel Kuhn, and Berc Rustem. Robust markov decision processes. Mathematics of Operations Research, 38(1):153-183, 2013. (pp. 1 and 3.)   \n[53] Tengyang Xie, Ching-An Cheng, Nan Jiang, Paul Mineiro, and Alekh Agarwal. Bellmanconsistent pessimism for offine reinforcement learning. Advances in neural information processing systems, 34:6683-6694, 2021. (pp. 1, 2, 6, and 16.)   \n[54]  Wei Xiong, Han Zhong, Chengshuai Shi, Cong Shen, Liwei Wang, and Tong Zhang. Nearly minimax optimal offine reinforcement learning with linear function approximation: Singleagent mdp and markov game. In International Conference on Learning Representations (ICLR), 2023. (pp. 2, 3, 7, 8, 9, 10, 16, 28, and 32.)   \n[55] Huan Xu and Shie Mannor. The robustness-performance tradeoff in markov decision processes. Advances in Neural Information Processing Systems, 19, 2006. (pp. 1 and 3.)   \n[56] Zaiyan Xu, Kishan Panaganti, and Dileep Kalathil. Improved sample complexity bounds for distributionally robust reinforcement learning. In International Conference on Arificial Intelligence and Statistics, pages 9728-9754. PMLR, 2023. (pp. 3 and 4.)   \n[57]  Wenhao Yang, Liangyu Zhang, and Zhihua Zhang. Toward theoretical understandings of robust markov decision processes: Sample complexity and asymptotics. The Annals of Statistics, 50 (6):3223-3248, 2022. (pp. 1, 3, and 4.)   \n[58]  Wenhao Yang, Han Wang, Tadashi Kozuno, Scot M Jordan, and Zhihua Zhang. Robust markov decision processes without model estimation. arXiv preprint arXiv:2302.01248, 2023. (p. 3.)   \n[59] Zhouhao Yang, Yihong Guo, Pan Xu, Anqi Liu, and Animashree Anandkumar. Distributionally robust policy gradient for offine contextual bandits. InInternational Conference on Artificial Intelligence and Statistics, pages 6443-6462. PMLR, 2023. (p. 1.)   \n[60] Ming Yin, Yaqi Duan, Mengdi Wang, and Yu-Xiang Wang. Near-optimal offine reinforcement learning with linear representation: Leveraging variance information with pessimism. arXiv preprint arXiv:2203.05804, 2022. (pp. 2, 7, 8, 10, and 16.)   \n[61] Pengqian Yu and Huan Xu. Distributionally robust counterpart in markov decision processes. IEEE Transactions on Automatic Control, 61(9):2538-2543, 2015. (p. 3.)   \n[62]  Andrea Zanette, Martin J Wainwright, and Emma Brunskill. Provable benefits of actor-critic methodsforoffine reinforcement learning. Advances inneural information processing systems, 34:13626-13640, 2021. (pp. 2, 10, and 16.)   \n[63] Huan Zhang, Hongge Chen, Chaowei Xiao, Bo Li, Mingyan Liu, Duane Boning, and ChoJui Hsieh. Robust deep reinforcement learning against adversarial perturbations on state observations. Advances in Neural Information Processing Systems, 33:21024-21037, 2020. (p. 1.)   \n[64] Wenshuai Zhao, Jorge Pena Queralta, and Tomi Westerlund. Sim-to-real transfer in deep reinforcement learning for robotics: a survey. In 2020 IEEE symposium series on computational intelligence (SSCI), pages 737-744. IEEE, 2020. (p. 1.)   \n[65] Dongruo Zhou, Quanquan Gu, and Csaba Szepesvari. Nearly minimax optimal reinforcement learning for linear mixture markov decision processes. In Conference on Learning Theory, pages 4532-4576. PMLR, 2021. (Pp. 3, 8, and 46.)   \n[66] Ruida Zhou, Tao Liu, Min Cheng, Dileep Kalathil, PR Kumar, and Chao Tian. Natural actorcritic for robust reinforcement learning with function approximation. Advances in neural information processing systems, 36, 2024. (pp. 2 and 4.)   \n[67] Zhengqing Zhou, Zhengyuan Zhou, Qinxun Bai, Linhai Qiu, Jose Blanchet, and Peter Glynn. Finite-sample regret bound for distributionally robust offine tabular reinforcement learning. In International Conference on Artificial Intelligence and Statistics, pages 3331-3339. PMLR, 2021. (p. 3.) ", "page_idx": 10}, {"type": "text", "text": "", "page_idx": 11}, {"type": "text", "text": "", "page_idx": 12}, {"type": "text", "text": "", "page_idx": 13}, {"type": "text", "text": "", "page_idx": 14}, {"type": "text", "text": "AAdditional Related Work ", "text_level": 1, "page_idx": 15}, {"type": "text", "text": "Offline Linear MDPs. Our work focuses on the offline linear MDP setting where the nominal transition kernel, from which the offline dataset is collected, admits the linear MDP structure. Numerous works have studied the provable efficiency and statistical limits of algorithms under this setting [15, 62, 53, 60, 54]. The most relevant study to ours is the recent work of [54], which established the minimax optimality of offline linear MDPs. At the core of their analysis is an advantage-reference technique designed for offline RL under linear function approximation, together with a variance aware pessimism-based algorithm. However, the offline linear MDP setting still remains understudied in the context of DRMDPs. ", "page_idx": 15}, {"type": "text", "text": "Transfer-Learning in Low Rank MDPs. Besides the distributionally robust perspective to solve the planning problem in a nearly unknown target environment, another line of work focuses on transfer learning in low-rank MDPs [7, 23, 2, 5]. Specifically, the problem setup assumes that the agent has access to information of several source tasks. The agent learns a common representation from the source domains and then leverages the learned representation to learn a policy performing well in the target tasks with limited information. This setting is in stark contrast to DRMDPs, where the agent only has access to the information of a single source domain, without any available information of the target domain, assuming the same task is being performed. This motivates the pessimistic principle of the distributionally robust perspective. Among the aforementioned works, Bose et al. [5] studied the ofline multi-task RL, which is the most closely related to our setting. In particular, they investigate the representation transfer error in their Theorem 1, stating that the learned representation can lead to a transition kernel that is close to the target kernel in terms of the TV divergence. Note that the uncertainty is induced by the representation estimation error, which is different from our setting assuming that the uncertainty comes from perturbations on underlying factor distributions. Nevertheless, this work provides evidence that TV divergence is a reasonable measure to quantify the uncertainty in transition kernels and motivates a future research direction in learning robust policies that are robust to the uncertainty induced by the representation estimation error. ", "page_idx": 15}, {"type": "text", "text": "B A More Computationally Efficient Variant of VA-DRPVI ", "text_level": 1, "page_idx": 15}, {"type": "text", "text": "In this section, we propose a modified version of Algorithm 2, which reduces the computation cost in the ridge regressions for variance estimation and achieves the same theoretical guarantees. ", "page_idx": 15}, {"type": "text", "text": "Variance Estimator. In Section 5, we estimate the variance of the truncated robust value function $\\widehat{[V_{h+1}^{'\\rho}]}_{\\alpha}$ Thus, for different $\\alpha$ , we need to establish different variance estimators, which signifcantly increases the computational burden. The theoretical analysis of Algorithm 2 suggests that it suffices to estimate the the variance of $\\widehat V_{h+1}^{'\\rho}$ , instead of the truncated one. In particular, we know $\\begin{array}{r}{[\\mathrm{Var}_{h}\\,\\widehat{V}_{h+1}^{\\prime\\,\\rho}](s,a)=[\\mathbb{P}_{h}^{0}(\\widehat{V}_{h+1}^{\\prime\\,\\rho})^{2}](s,a)-([\\mathbb{P}_{h}^{0}\\widehat{V}_{h+1}^{\\prime\\,\\rho}](s,a))^{2}=\\langle\\phi(s,a),z_{h,2}\\rangle-(\\langle\\phi(s,a),z_{h,1}\\rangle)^{2}}\\end{array}$ Then we estimate $z_{h,1}$ and $z_{h,2}$ viaridgeregression: ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\begin{array}{l l}{{\\displaystyle\\tilde{z}_{h,2}=\\operatorname*{argmin}_{z\\in\\mathbb{R}^{d}}\\sum_{\\tau=1}^{K}\\left(\\left(\\widehat{V}_{h+1}^{'\\rho}\\big(s_{h+1}^{\\tau}\\big)\\right)^{2}-\\phi_{h}^{\\tau\\top}z\\right)^{2}+\\lambda\\|z\\|_{2}^{2}},}\\\\ {{\\displaystyle\\tilde{z}_{h,1}=\\operatorname*{argmin}_{z\\in\\mathbb{R}^{d}}\\sum_{\\tau=1}^{K}\\left(\\widehat{V}_{h+1}^{'\\rho}\\big(s_{h+1}^{\\tau}\\big)-\\phi_{h}^{\\tau\\top}z\\right)^{2}+\\lambda\\|z\\|_{2}^{2}}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "We construct the following truncated variance estimator: ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\widehat{\\sigma}_{h}^{2}(s,a):=\\operatorname*{max}\\Big\\{1,\\big[\\phi(s,a)^{\\top}\\tilde{z}_{h,2}\\big]_{[0,H^{2}]}-\\big[\\phi(s,a)^{\\top}\\tilde{z}_{h,1}\\big]_{[0,H]}^{2}-\\tilde{O}\\Big(\\frac{d H^{3}}{\\sqrt{K\\kappa}}\\Big)\\Big\\}.\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "The modified variance-aware algorithm is presented in Algorithm 3 and the theoretical guarantee is presented in Theorem B.1. ", "page_idx": 15}, {"type": "text", "text": "Theorem B.1. Under Assumptions 3.1 and 4.3, for $K>\\operatorname*{max}\\{\\tilde{O}(d^{2}H^{6}/\\kappa),\\tilde{O}(H^{4}/\\kappa^{2})\\}$ and $\\delta\\in$ $(0,1)$ , if we set $\\lambda=1/H^{2}$ and $\\beta_{2}=\\tilde{O}(\\sqrt{d})$ in Algorithm 3, then with probability at least $1-\\delta$ ,for ", "page_idx": 15}, {"type": "text", "text": "Require: Input dataset $\\mathcal{D}$ $\\mathcal{D}^{\\prime}$ and $\\beta_{2}$ .\uff0c $\\widehat V_{H+1}^{\\rho}(\\cdot)=0$   \n1: Run Algorithm 1 using dataset $\\mathcal{D}^{\\prime}$ to get $\\{\\widehat V_{h}^{'\\rho}\\}_{h\\in[H]}$   \n2: for $h=H,\\cdots\\,,1$ do   \n3: Construct variance estimator $\\widehat{\\sigma}_{h}^{2}(\\cdot,\\cdot)$ using $\\mathcal{D}^{\\prime}$ by (B.1) and (B.2)   \n4: $\\begin{array}{r l}&{\\Sigma_{h}=\\sum_{\\tau=1}^{K}\\phi_{h}^{\\tau}\\phi_{h}^{\\tau\\top}/\\hat{\\sigma}_{h}^{2}(s_{h}^{\\top},a_{h}^{\\top})+\\lambda\\mathbf{I}}\\\\ &{\\hat{z}_{h}(\\alpha)=\\Sigma_{h}^{-1}\\Big(\\sum_{\\tau=1}^{K}\\phi_{h}^{\\tau}\\big[\\widehat{V}_{h+1}^{\\rho}(s_{h+1}^{\\tau})\\big]_{\\alpha}/\\widehat{\\sigma}_{h}^{2}(s_{h}^{\\tau},a_{h}^{\\tau})\\Big)}\\\\ &{\\alpha_{i}=\\operatorname{argmax}_{\\alpha\\in[0,H]}\\{\\hat{z}_{h,i}(\\alpha)-\\rho(\\alpha-\\operatorname*{min}_{\\upsilon^{\\prime}}[\\widehat{V}_{h+1}^{\\rho}(s^{\\tau})]_{\\alpha})\\},\\ \\forall i\\in[d]}\\\\ &{\\hat{\\nu}_{h,i}^{\\rho}=\\hat{z}_{h,i}(\\alpha_{i})-\\rho(\\alpha_{i}-\\operatorname*{min}_{\\upsilon^{\\prime}}[\\widehat{V}_{h+1}^{\\rho}(s^{\\prime})]_{\\alpha_{i}}),\\ \\forall i\\in[d]}\\\\ &{\\Gamma_{h}(\\cdot,\\cdot)\\leftarrow\\beta_{2}\\sum_{i=1}^{d}\\lVert\\phi_{i}(\\cdot,\\cdot)\\mathbf{1}_{i}\\rVert_{\\mathbf{L}_{h}^{-1}}}\\\\ &{\\hat{Q}_{h}^{p}(\\cdot,\\cdot)=\\{\\phi(\\cdot,\\cdot)^{\\top}(\\theta_{h}+\\hat{\\nu}_{h}^{\\rho})-\\Gamma_{h}(\\cdot,\\cdot)\\}_{[0,H-h+1]}}\\\\ &{\\hat{\\pi}_{h}(\\cdot)\\leftarrow\\operatorname{argmax}_{\\pi_{h}}\\langle\\widehat{Q}_{h}^{\\rho}(\\cdot,\\cdot),\\pi_{h}(\\cdot\\cdot)\\rangle_{\\alpha},\\widehat{V}_{h}^{\\rho}(\\cdot)\\leftarrow\\langle\\widehat{Q}_{h}^{\\rho}(\\cdot,\\cdot),\\hat{\\pi}_{h}(\\cdot\\vert\\cdot)\\rangle_{\\mathscr{A}}}\\end{array}$   \n5:   \n6:   \n7:   \n8:   \n9:   \n10:   \n11.ondfow ", "page_idx": 16}, {"type": "text", "text": "all $s\\in S$ , the suboptimality of VA-DRPVI satisfies ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\mathrm{SubOpt}(\\hat{\\pi},s,\\rho)\\le\\beta_{2}\\cdot\\operatorname*{sup}_{P\\in\\mathcal{U}^{\\rho}(P^{0})}\\sum_{h=1}^{H}\\mathbb{E}^{\\pi^{\\star},P}\\Big[\\sum_{i=1}^{d}\\|\\phi_{i}(s_{h},a_{h})\\mathbf{1}_{i}\\|_{\\mathbf{\\Sigma}_{h}^{\\star-1}}|s_{1}=s\\Big],\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "Wwhere $\\begin{array}{r}{\\pmb{\\Sigma}_{h}^{\\star}=\\sum_{\\tau=1}^{K}\\phi_{h}^{\\tau}\\phi_{h}^{\\tau\\top}/[\\mathbb{V}_{h}V_{h+1}^{\\star}](s_{h}^{\\tau},a_{h}^{\\tau})+\\lambda\\mathbf{I}.}\\end{array}$", "page_idx": 16}, {"type": "text", "text": "Remark B.2. The computation cost of Algorithm 3 is much smaller than Algorithm 2, as the variance estimators are not related to $\\alpha$ anymore. Notably, Algorithm 3 shares the same upper bound as Algorithm 2. According to Theorem 6.1, we know the modified algorithm is also minimax optimal. ", "page_idx": 16}, {"type": "text", "text": "C Experiments ", "text_level": 1, "page_idx": 16}, {"type": "text", "text": "We conduct numerical experiments to illustrate the performances of our proposed algorithms, DRPVI and VA-DRPVI, and compare it with the their non-robust counterpart, PEVI [15]. All numerical experiments were conducted on a MacBook Pro with a 2.6 GHz 6-Core Intel CPU. The implementation of our DRPVI algorithm is available at https : //github. com/panxulab/Offline-Linear- DRMDP. ", "page_idx": 16}, {"type": "text", "text": "Construction of the simulated linear MDP We leverage the simulated linear MDP setting proposed by Liu and $\\mathrm{Xu}$ [20] and modify it as an offline RL problem. In particular, the source and target linear MDP environment are shown in Figure 1(a) and Figure 1(b). The state space is set to be $S=\\{x_{1},\\cdots\\,,x_{5}\\}$ and the action space is to be $\\mathcal{A}=\\left\\{-1,1\\right\\}^{\\breve{4}}\\subset\\mathbb{R}^{\\dot{4}}$ . At each episode, the state always starts with $x_{1}$ , and then transits to $x_{2},x_{4},x_{5}$ with probability defined in the figures. $x_{2}$ is an intermediate state, and it can transit to $x_{3},x_{4},x_{5}$ with probability defined on the lines. Moreover, Both $x_{4}$ and $x_{5}$ are absorbing states. $x_{4}$ $\\left(x_{5}\\right)$ is the fail state (goal state), and the reward starting from which is always O (1). The reward functions and transition probabilities are designed to depend on the hyperparameter $\\pmb{\\xi}\\in\\mathbb{R}^{4}$ as shown in the figure. The target environment is constructed by only perturbing the transition probability at $x_{1}$ of the source environment, and the extend of perturbation is controlled by the hyperparameter $q\\,\\in\\,(0,1)$ . We refer more details on the construction of the simulated linear DRMDP to the Supplementary A.1 of [20]. ", "page_idx": 16}, {"type": "text", "text": "Implementation We simply use the random policy that chooses actions uniformly at random at any $(s,a,h)\\ \\in\\ S\\times A\\times[H]$ to collect offline dataset. The offline dataset containing 100 trajectories collected by the behavior policy from the source environment. We conduct ablation study by setting the hyperpameter $\\pmb{\\xi}=\\sqrt{(1/\\lVert\\pmb{\\xi}\\rVert_{1},1/\\lVert\\pmb{\\xi}\\rVert_{1},1/\\lVert\\pmb{\\xi}\\rVert_{1},1/\\lVert\\pmb{\\xi}\\rVert_{1},1/\\lVert\\pmb{\\xi}\\rVert_{1})^{\\top}}$ and consider different choices of $\\|\\pmb{\\xi}\\|_{1}\\in\\{0.1,0.2,0.3\\}$ . Following [20], we use heterogeneous uncertainty level for our two algorithms. Specifically, we set $\\rho_{1,4}=0.5$ and $\\rho_{h,i}=0$ for all other cases. The experiment results are shown in Figure 2. ", "page_idx": 16}, {"type": "text", "text": "Figure 2 shows the performances of the learned policies of three algorithms. We conclude that both of our proposed algorithms are robust to environmental perturbation compared to the non-robust PEVI. ", "page_idx": 16}, {"type": "image", "img_path": "9SghPrjYU1/tmp/b6f23ffb14a872c81542ca2fd0db184bfb466179b70f951690cc8b29b81ca3b9.jpg", "img_caption": [], "img_footnote": [], "page_idx": 17}, {"type": "text", "text": "Figure 1: The source and the target linear MDP environments. The value on each arrow represents the transition probability. For the source MDP, there are five states and three steps, with the initial Statebeing $x_{1}$ ,the fail statebeing $x_{4}$ ,and $x_{5}$ being an absorbing state with reward 1. The target MDP on the right is obtained by perturbing the transition probability at the first step of the source MDP, with others remaining the same. ", "page_idx": 17}, {"type": "text", "text": "Furthermore, VA-DRPVIslightly outperforms DRPVI in most settings. These numerical results are consistent with our theoretical findings. ", "page_idx": 17}, {"type": "text", "text": "D Proof of Theorem 4.4 ", "text_level": 1, "page_idx": 17}, {"type": "text", "text": "Our analysis mainly deals with the challenges induced by the model uncertainty, $\\operatorname*{inf}_{P\\in\\mathcal{U}^{\\rho}(P^{0})}$ and the need to maximally exploit the information in the offline dataset. More specifically, the proof of Theorem 4.4 mainly constitutes of two steps. ", "page_idx": 17}, {"type": "text", "text": "Step 1: suboptimality decomposition. We first decompose the suboptimality gap in the following lemma to connect it with the estimation error, the full proof of which can be found in Appendix G.1. Lemma D.1 (Suboptimality Decomposition for DRMDP). If the following holds ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\Big|\\operatorname*{inf}_{\\substack{P_{h}(\\cdot\\,|s,a)\\in\\mathcal{U}_{h}^{\\rho}(s,a;\\mu_{h,i}^{0})}}[\\mathbb{P}_{h}\\widehat{V}_{h+1}^{\\rho}](s,a)-\\phi(s,a)\\widehat{\\nu}_{h}^{\\rho}\\Big|\\leq\\Gamma_{h}(s,a),\\forall(s,a,h)\\in\\mathcal{S}\\times\\mathcal{A}\\times[H],\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "then we have $\\begin{array}{r}{\\mathrm{SubOpt}(\\hat{\\pi},s,\\rho)\\leq2\\operatorname*{sup}_{P\\in{\\mathcal U}^{\\rho}(P^{0})}\\sum_{h=1}^{H}\\mathbb{E}^{\\pi^{\\star},P}\\left[\\Gamma_{h}(s_{h},a_{h})|s_{1}=s\\right].}\\end{array}$ ", "page_idx": 17}, {"type": "text", "text": "The main challenge in deriving Lemma D.1 lies in the dependency of the robust Bellman equation (3.1) on the nominal kernel $\\bar{P^{0}}$ , which is not linear and does not even have an explicit form. It should be noted that the term $\\vert\\operatorname*{inf}_{P_{h}(\\cdot\\vert s,a)\\in\\mathcal{U}_{h}^{\\rho}(s,a;\\mu_{h,i}^{0})}[\\mathbb{P}_{h}\\widehat{V}_{h+1}^{\\rho}](s,a)-\\phi(s,a)^{\\top}\\hat{\\pmb{\\nu}_{h}^{\\rho}}\\vert^{2}$ in condition (D.1) stands for the estimation error of the estimated robust $\\mathrm{^Q}$ -function in (4.5), which we refer to as the robust estimation uncertainty. Lemma D.1 shows that under the condition that the robust estimation uncertainty is bounded by $\\Gamma_{h}(s,a)$ , the suboptimality gap can be upper bounded in terms of $\\Gamma_{h}(s,a)$ . To conclude the proof, it remains to derive $\\Gamma_{h}(s,a)$ and then substitute it back into the result in Lemma D.1. ", "page_idx": 17}, {"type": "text", "text": "Step 2: bounding the robust estimation uncertainty.  We now bound the robust estimation uncertainty in Lemma D.1 by the following result, the full proof of which can be found in Appendix G.2. ", "page_idx": 17}, {"type": "image", "img_path": "9SghPrjYU1/tmp/44aeac93a17071f896df180c27da1942d71a1b76766ff809845141e856d2e151.jpg", "img_caption": ["Figure 2: Simulation results under different source domains. The $x$ -axis represents the perturbation level corresponding to different target environments. $\\rho_{1,4}$ is the input uncertainty level for our VA-DRPVI algorithm. $\\|\\xi\\|_{1}$ is the hyperparameter of the linear DRMDP environment. "], "img_footnote": [], "page_idx": 18}, {"type": "text", "text": "Lemma D.2 (Robust Estimation Uncertainty Bound). For any sufficiently large sample size $K$ satisfying $K\\,>\\,\\mathrm{max}\\{512\\,\\mathrm{log}(2d H^{2}/\\delta)/\\kappa^{2},\\dot{2}0449d^{2}H^{2}/\\kappa\\}$ , and any fixed $\\delta\\,\\in\\,(0,1)$ , if we set $\\lambda=1$ in Algorithm 1, then with probability at least $1-\\delta$ , for all $(s,a,h)\\in\\mathcal{S}\\times\\mathcal{A}\\times[\\dot{H}]$ , we have ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\Big|\\operatorname*{inf}_{\\substack{P_{h}(\\cdot|s,a)\\in\\mathcal{U}_{h}^{\\rho}(s,a;\\mu_{h,i}^{0})}}[\\mathbb{P}_{h}\\widehat{V}_{h+1}^{\\rho}](s,a)-\\phi(s,a)^{\\top}\\hat{\\nu}_{h}^{\\rho}\\Big|\\leq\\Gamma_{h}(s,a),\n$$", "text_format": "latex", "page_idx": 18}, {"type": "equation", "text": "$$\n\\begin{array}{r}{:\\Gamma_{h}(s,a)=4\\sqrt{d}H\\sqrt{\\iota}\\sum_{i=1}^{d}\\|\\phi_{i}(s,a)\\mathbf{1}_{i}\\|_{\\mathbf{A}_{h}^{-1}}\\,\\mathrm{and}\\,\\iota=\\log(2d H^{2}K/\\delta).}\\end{array}\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "$\\Gamma_{h}(s,a)$ provides an explicit bound for the robust estimation uncertainty, which also serves as the penalty term in Line 6 of Algorithm 1. The main challenge of deriving Lemma D.2 lies in inferring the worst-case behavior using information merely from the nominal environment. Our idea is to first transform the robust estimation uncertainty to the estimation uncertainty of ridge regressions (4.2) on the nominal model $P^{0}$ , where the samples are collected and statistical control is available. We then adopt a reference-advantage decomposition technique, which is new in the linear DRMDP literature, to further decompose the estimation uncertainty on the nominal model into the reference uncertainty and the advantage uncertainty. The remaining proof is to bound the reference uncertainty and advantage uncertainty respectively using concentration and union bound arguments under an induction framework to address the temporal dependency. We highlight that all these arguments are specifically designed for the unique problem of DRMDP, which is novel and nontrivial. ", "page_idx": 18}, {"type": "text", "text": "E Proof of the Suboptimality Upper Bounds ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "In this section, we prove the main results in Corollary 4.5, Remark 4.6, Theorem 5.2, and Corollary 5.3, which give out the instance-dependent upper bounds of the proposed algorithms. Before the proof, we introduce some useful notations. For any function $f:S\\bar{\\rightarrow}\\,[0,H-\\bar{1}]$ ,define ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\overbrace{\\operatorname*{inf}}^{\\substack{\\mathrm{inf}}}}\\\\ {P_{h}(\\cdot|s,a)\\overbrace{\\mathscr{\\mathscr{U}}_{h}^{\\rho}(s,a;\\pmb{\\mu}_{h,i}^{0})}^{\\substack{\\prime}}}\\end{array}\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "where for each $i\\in[d]$ , we have ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\displaystyle\\hat{\\nu}_{h,i}^{\\rho}(f)=\\operatorname*{max}_{\\alpha\\in[0,H]}\\left\\{\\hat{\\mathbb{E}}^{\\mu_{h,i}^{0}}[f(s)]_{\\alpha}-\\rho(\\alpha-\\operatorname*{min}_{s^{\\prime}\\in S}[f(s^{\\prime})]_{\\alpha})\\right\\},}\\\\ &{\\displaystyle\\hat{\\mathbb{E}}^{\\mu_{h,i}^{0}}[f(s)]_{\\alpha}=\\Big[\\Lambda_{h}^{-1}\\displaystyle\\sum_{\\tau=1}^{K}\\phi_{h}^{\\tau}[f(s_{h+1}^{\\tau})]_{\\alpha}\\Big]_{i}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "E.1Proof of Corollary 4.5 ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "The proof of Corollary 4.5 is straightforward given our result in Theorem 4.4. ", "page_idx": 19}, {"type": "text", "text": "Proof. Define $\\tilde{\\mathbf{A}}_{h}=\\mathbb{E}^{\\pi^{b},P^{0}}[\\phi(s_{h},a_{h})\\phi(s_{h},a_{h})^{\\top}],\\forall h\\in[H]$ By Assumptio 4.3, we have $\\tilde{\\Lambda}_{h}\\succeq$ $\\kappa\\cdot\\mathbf{I}$ We further bound (6.1) as follows, ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\underset{P\\in\\mathbb{R}^{n}(r)\\times\\frac{1}{\\sqrt{n}}}{\\operatorname*{sup}}\\frac{\\tilde{F}}{\\sqrt{n}}\\mathbb{E}^{*,r}\\left[\\frac{\\tilde{F}}{\\sqrt{n}}\\int_{(\\hat{\\theta}_{n}(h_{\\theta},a_{n}))_{*}}^{r}\\mathrm{l}_{\\theta_{n}^{**}}-s\\right]}\\\\ &{\\leq\\underset{P\\in\\mathbb{R}^{n}(r)\\times\\frac{1}{\\sqrt{n}}}{\\operatorname*{sup}}\\frac{2}{\\sqrt{n}}\\mathbb{E}^{*,r}\\left[\\frac{\\tilde{F}}{\\sqrt{n}}\\sum_{i=1}^{r}|\\theta_{n}(s_{i},a_{n})|_{*}|_{\\mathcal{X}_{\\theta}^{*}}|_{\\mathcal{X}_{\\theta}^{*}}\\right]\\sin=s\\right]}\\\\ &{=\\underset{P\\in\\mathbb{R}^{n}(r)\\times\\frac{1}{\\sqrt{n}}}{\\operatorname*{sup}}\\frac{2}{\\sqrt{n}}\\mathbb{E}^{*,r}\\left[\\frac{\\tilde{F}}{\\sqrt{n}}\\sum_{i=1}^{r}|\\theta_{n}(s_{i},a_{n})\\sqrt{1\\sqrt{n}\\cdot\\frac{1}{n}}|_{\\theta_{n}}-s\\right]}\\\\ &{\\leq\\underset{P\\in\\mathbb{R}^{n}(r)\\times\\frac{1}{\\sqrt{n}}}{\\operatorname*{sup}}\\frac{2}{\\sqrt{n}}\\mathbb{E}^{*,r}\\left[\\frac{\\tilde{F}}{\\sqrt{n}\\cdot\\frac{1}{n}}\\int_{\\theta_{n}}(s_{i},a_{n})\\sqrt{\\lambda_{n}(\\hat{\\theta}_{n}^{*})}\\left(\\lambda_{n}^{*}\\right)|_{\\mathbb{R}^{*}}=s\\right]}\\\\ &{=\\underset{P\\in\\mathbb{R}^{n}(r)\\times\\frac{1}{\\sqrt{n}}}{\\operatorname*{sup}}\\frac{2}{\\sqrt{n}}\\mathbb{E}^{*,r}\\left[\\frac{\\tilde{F}}{\\sqrt{n}}\\sum_{i=1}^{r}\\theta_{n}(s_{i},a_{n})\\sqrt{\\frac{1}{\\sqrt{n}\\cdot\\frac{1}{n}}}|_{\\theta_{n}}|_{\\mathcal{X}_{\\theta}^{*}}=s\\right]}\\\\ &{\\leq\\underset{P\\in\\mathbb{R}^{n}(r)\\times\\frac{1}{\\sqrt{n}}}{\\operatorname*{sup} \n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "where (E.2) is due to Lemma I.3, (E.3) is due to the fact that for any matrix $\\pmb{A}$ $\\lambda_{\\operatorname*{min}}\\leq A_{i i}\\leq\\lambda_{\\operatorname*{max}}$ where $\\pmb{A}_{i i}$ is the $i$ -th diagonal element of $\\pmb{A}$ . (E.3) holds due to Assumption 4.3 and the fact that $\\begin{array}{r}{\\sum_{i=1}^{d}\\phi_{i}(s,a)=1}\\end{array}$ . We conclude the proof by invoking Theorem 4.4. \u53e3 ", "page_idx": 19}, {"type": "text", "text": "E.2Proof of Theorem 5.2 ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "The proof idea is similar to that of Theorem 4.4, except that we additionally analyze the variance estimation and apply the Bernstein-type self-normalized concentration inequality to bound the reference uncertainty, which is the dominant term. We start from analyzing the estimation error of conditional variances in the following lemma. ", "page_idx": 19}, {"type": "text", "text": "Lemma E.1. Under Assumptions 3.1 and 4.3, when $K\\ge\\tilde{O}(H^{4}/\\kappa^{2})$ , then with probability at least $1-\\delta$ , for all $(s,a,h)\\in S\\times A\\times[H]$ and any fixed $\\alpha$ ,wehave ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\big[\\mathbb{V}_{h}[V_{h+1}^{\\star,\\rho}]_{\\alpha}\\big](s,a)-\\tilde{O}\\Big(\\frac{d H^{3}}{\\sqrt{K\\kappa}}\\Big)\\leq\\widehat{\\sigma}_{h}^{2}(s,a;\\alpha)\\leq\\big[\\mathbb{V}_{h}[V_{h+1}^{\\star,\\rho}]_{\\alpha}\\big](s,a).\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "The following lemma bounds the estimation error by reference-advantage decomposition. ", "page_idx": 20}, {"type": "text", "text": "Lemma E.2 (Variance-Aware Reference-Advantage Decomposition). There exist $\\{\\alpha_{i}\\}_{i\\in[d]}$ ,where $\\alpha_{i}\\in[0,H],\\forall i\\in[d]$ ,such that ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\begin{array}{l}{\\displaystyle\\frac{\\mathrm{inf}}{\\gamma_{k}(\\cdot;\\boldsymbol{\\alpha})\\mathrm{i}\\xi_{k}^{\\prime}(s,\\cdot)}[\\![\\hat{\\boldsymbol{\\it x}}_{k}\\hat{\\mathcal{V}}_{k+1}^{\\prime}](s,\\cdot)-\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\mathrm{inf}(\\cdot)\\xi_{k}^{\\prime}(s,\\cdot)\\xi_{k}^{\\prime\\prime})[\\![\\hat{\\boldsymbol{\\it x}}_{k}(\\hat{\\mathcal{V}}_{k+1}^{\\prime})(s,a)]\\!]}\\\\ {\\displaystyle\\vdots\\left.\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\n$$", "text_format": "latex", "page_idx": 20}, {"type": "equation", "text": "$$\n+\\sum_{i=1}^{d}\\|\\phi_{i}(s,a)\\mathbf{1}_{i}\\|_{\\Sigma_{h}^{-1}(\\alpha_{i})}\\Big\\|\\sum_{\\tau=1}^{K}\\frac{\\phi_{h}^{\\tau}\\eta_{h}^{\\tau}([\\widehat{V}_{h+1}^{\\rho}(s)]_{\\alpha_{i}}-[V_{h+1}^{\\star,\\rho}(s)]_{\\alpha_{i}})}{\\widehat{\\sigma}_{h}^{2}(s_{h}^{\\tau},a_{h}^{\\tau};\\alpha_{i})}\\Big\\|_{\\Sigma_{h}^{-1}(\\alpha_{i})},\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "Now we are ready to prove Theorem 5.2 ", "page_idx": 20}, {"type": "text", "text": "Proof of Theorem 5.2. To prove this theorem, we bound the estimation error by $\\Gamma_{h}(s,a)$ ,then invoke Lemma D.1 to get the result. First, we bound terms i-iv in Lemma E.2 to deduce $\\Gamma_{h}(s,a)$ at each step $h\\in[H]$ ,respectively. ", "page_idx": 20}, {"type": "text", "text": "Bound i and i: We set $\\lambda=1/H^{2}$ to ensure that for all $(s,a,h)\\in\\mathcal{S}\\times\\mathcal{A}\\times[H].$ we have ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\mathrm{i}+\\operatorname{iii}\\le\\sqrt{\\lambda}\\sqrt{d}H\\sum_{i=1}^{d}\\|\\phi_{i}(s,a)\\mathbf{1}_{i}\\|_{\\mathbf{\\Sigma}_{h}^{-1}(\\alpha_{i})}=\\sqrt{d}\\sum_{i=1}^{d}\\|\\phi_{i}(s,a)\\mathbf{1}_{i}\\|_{\\mathbf{\\Sigma}_{h}^{-1}(\\alpha_{i})}.\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "Bound ii: For all $(s,a,\\alpha)\\in\\mathcal{S}\\times\\mathcal{A}\\times[0,H]$ by definitionwe have $\\widehat{\\sigma}_{h}(s,a;\\alpha)\\geq1$ .Thus, for all $(h,\\tau,i)\\,\\in\\,[H]\\,\\times\\,[K]\\,\\times\\,[d]$ we have $\\vert\\eta_{h}^{\\tau}([\\dot{V}_{h+1}^{\\star,\\dot{\\rho}}]_{\\alpha_{i}})/\\widehat\\sigma_{h}(s_{h}^{\\tau},a_{h}^{\\tau},\\alpha_{i})\\vert\\le H$ Note that $V_{H+1}^{\\star,\\rho}$ independent of $\\mathcal{D}$ , we can directly apply Bernstein-type self-normalized concentration inequality Lemma I.2 and a union bound to obtain the upper bound. In concrete, we define the filtration $\\mathcal{F}_{\\tau-1,h}=\\sigma(\\{(s_{h}^{j},a_{h}^{j})\\}_{j=1}^{\\tau}\\cup\\{s_{h+1}^{j}\\}_{j=1}^{\\tau-1})$ Since $V_{h+1}^{\\star,\\rho}$ and $\\widehat{\\sigma}_{h}(s,a;\\alpha)$ are independent of $\\mathcal{D}$ thus $\\eta_{h}^{\\tau}([V_{h+1}^{\\star,\\rho}]_{\\alpha_{i}})/\\widehat{\\sigma}_{h}(s_{h}^{\\tau},a_{h}^{\\tau},\\alpha_{i})$ is mean-zero conditioned on the filtration $\\mathcal{F}_{\\tau-1,h}$ . Further, we have ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\begin{array}{r l r}{\\mathbb{E}\\Big[\\Big(\\frac{\\eta_{h}^{\\eta}\\big(\\vert V_{h+1}^{*}\\vert\\big)_{\\alpha_{i}}}{\\tilde{\\sigma}_{h}(s_{h}^{\\eta},a_{h}^{\\eta};\\alpha_{i})}\\Big)^{2}\\Big\\vert\\mathcal{F}_{\\tau-1,h}\\Big]=\\frac{\\big[\\mathrm{Var}\\big\\vert V_{h+1}^{*}\\big]_{\\alpha_{i}}\\big\\vert\\big(s_{h}^{\\eta},a_{h}^{\\tau}\\big)}{\\tilde{\\sigma}_{h}^{2}(s_{h}^{\\tau},a_{h}^{\\tau};\\alpha_{i})}}&{\\mathrm{~(~E~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~}\\mathrm{~~~~~~~~~~~~}\\mathrm{~~~~~~~~}\\mathrm{~~~~~~}\\mathrm{~~~~~}\\mathrm{~~~~}\\mathrm{~~~~}\\mathrm{~~~)~}}\\\\ &{\\leq\\frac{\\big[\\mathbb{V}\\big\\vert V_{h+1}^{*}\\big]_{\\alpha_{i}}\\big\\vert\\big(s_{h}^{\\eta},a_{h}^{\\tau}\\big)}{\\tilde{\\sigma}_{h}^{2}(s_{h}^{\\tau},a_{h}^{\\tau};\\alpha_{i})}}&{}\\\\ &{=\\frac{\\big[\\mathbb{V}\\big\\vert V_{h+1}^{*}\\big,\\mu\\big\\vert\\big(s_{h}^{\\eta},a_{h}^{\\tau}\\big)-\\tilde{\\sigma}(d H^{3}/\\sqrt{K\\kappa})}{\\tilde{\\sigma}_{h}^{2}(s_{h}^{\\tau},a_{h}^{\\tau};\\alpha_{i})}+\\frac{\\tilde{O}(d H^{3}/\\sqrt{K\\kappa})}{\\tilde{\\sigma}_{h}^{2}(s_{h}^{\\tau},a_{h}^{\\tau};\\alpha_{i})}}&{}\\\\ &{\\leq1+\\frac{\\tilde{O}(d H^{3}/\\sqrt{K\\kappa})}{\\tilde{\\sigma}_{h}^{2}(s_{h}^{\\tau},a_{h}^{\\tau};\\\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "where (E.6) holds by the fact that $\\widehat{\\sigma}_{h}^{2}(\\cdot,\\cdot;\\cdot)$ is independent of $\\mathcal{D}$ and $(s_{h}^{\\tau},a_{h}^{\\tau})$ is $\\mathcal{F}_{\\tau-1,h}$ measurable. (E.7) holds by Lemma E.1, and (E.8) holds by setting $K\\geq\\tilde{\\Omega}(d^{2}H^{6}/\\dot{\\kappa})$ such that $\\widehat{\\sigma}_{h}^{2}(s_{h}^{\\tau},a_{h}^{\\tau};\\alpha_{i})-$ $\\tilde{O}(d H^{3}/\\sqrt{K\\kappa})\\geq1-\\tilde{O}(d H^{3}/\\sqrt{K\\kappa})\\geq1/2$ . Further, by (E.8), our choice of $K$ also ensures that $\\mathbb{E}\\big[\\big(\\eta_{h}^{\\tau}([V_{h+1}^{\\star,\\rho}]_{\\alpha_{i}})\\big)^{2}|\\mathcal{F}_{\\tau-1,h}\\big]=O(1)$ . Then by Lemma I.2, we have ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\left\\|\\sum_{\\tau=1}^{K}\\frac{\\phi_{h}^{\\tau}\\eta_{h}^{\\tau}([V_{h+1}^{\\star,\\rho}]_{\\alpha_{i}})}{\\widehat{\\sigma}_{h}^{2}(s_{h}^{\\tau},a_{h}^{\\tau};\\alpha_{i})}\\right\\|_{\\Sigma_{h}^{-1}(\\alpha_{i})}\\leq\\tilde{O}(\\sqrt{d}).\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "This implies ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\mathrm{ii}\\leq\\tilde{O}(\\sqrt{d})\\sum_{i=1}^{d}\\|\\phi_{i}(s,a)\\mathbf{1}_{i}\\|_{\\Sigma_{h}^{-1}(\\alpha_{i})}.\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "Boundiv: Following the same induction analysis procedure, we have $\\begin{array}{r}{\\|[\\widehat{V}_{h+1}^{\\rho}]_{\\alpha_{i}}-[V_{h+1}^{\\star,\\rho}]_{\\alpha_{i}}\\|\\le}\\end{array}$ $\\tilde{O}(\\sqrt{d}H^{2}/\\sqrt{K\\kappa})$ . Then, using standard $\\epsilon$ -covering number argument and Lemma I.1, we have ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\mathrm{iv}\\leq\\tilde{O}\\Big(\\frac{d^{3/2}H^{2}}{\\sqrt{K\\kappa}}\\Big)\\sum_{i=1}^{d}\\|\\phi_{i}(s,a)\\mathbf{1}_{i}\\|_{\\Sigma_{h}^{-1}(\\alpha_{i})}.\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "To make it non-dominant, we require $K\\geq\\tilde{\\Omega}(d^{2}H^{4}/\\kappa)$ . By Lemma E.1, for any $\\alpha\\in[0,H]$ we have ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\widehat{\\sigma}_{h}^{2}(s_{h}^{\\tau},a_{h}^{\\tau};\\alpha)\\leq[\\mathbb{V}_{h}[V_{h+1}^{\\star,\\rho}]_{\\alpha}](s_{h}^{\\tau},a_{h}^{\\tau})\\leq[\\mathbb{V}_{h}V_{h+1}^{\\star,\\rho}](s_{h}^{\\tau},a_{h}^{\\tau}),\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "this implies that ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\bigg(\\sum_{\\tau=1}^{K}\\frac{\\phi_{h}^{\\tau}\\phi_{h}^{\\tau\\top}}{\\widehat{\\sigma}_{h}^{2}(s_{h}^{\\tau},a_{h}^{\\tau};\\alpha_{i})}+\\lambda\\mathbf{I}\\bigg)^{-1}\\preceq\\bigg(\\sum_{\\tau=1}^{K}\\frac{\\phi_{h}^{\\tau}\\phi_{h}^{\\tau\\top}}{[\\mathbb{V}_{h}V_{h+1}^{\\star,\\rho}](s_{h}^{\\tau},a_{h}^{\\tau})}+\\lambda\\mathbf{I}\\bigg)^{-1}:=\\sum_{h}^{\\kappa-1}.\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "Combining (E.5), (E.9) and (E.10), we have ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\displaystyle\\min_{P_{h}(\\cdot\\,|s,a)\\in\\mathcal{U}_{h}^{p}(s,a;\\pmb{\\mu}_{h,i}^{0})}[\\mathbb{P}_{h}\\widehat{V}_{h+1}^{\\rho}](s,a)-\\widehat{\\operatorname*{inf}_{P_{h}(\\cdot\\,|s,a)\\in\\mathcal{U}_{h}^{p}(s,a;\\pmb{\\mu}_{h,i}^{0})}}[\\mathbb{P}_{h}\\widehat{V}_{h+1}^{\\rho}](s,a)\\big|}\\\\ &{\\displaystyle\\leq\\tilde{O}(\\sqrt{d})\\sum_{i=1}^{d}\\|\\phi_{i}(s,a)\\mathbf{1}_{i}\\|_{\\mathbf{Z}_{h}^{\\star-1}}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "Define $\\begin{array}{r}{\\Gamma_{h}(s,a)=\\tilde{O}(\\sqrt{d})\\sum_{i=1}^{d}\\|\\phi_{i}(s,a)\\mathbf{1}_{i}\\|_{\\Sigma_{h}^{\\star-1}}}\\end{array}$ , we concludes the proof by invoking Lemma D.1. ", "page_idx": 21}, {"type": "text", "text": "E.3 Proof of Corollary 5.3 ", "text_level": 1, "page_idx": 21}, {"type": "text", "text": "In this section, we prove Corollary 5.3. We start with an interesting phenomenon, we call \u2018range shrinkage', stated in the following lemma. ", "page_idx": 21}, {"type": "text", "text": "Lemma E.3 (Range Shrinkage). For any $(\\rho,\\pi,h)\\in(0,1]\\times\\Pi\\times[H]$ wehave ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\operatorname*{max}_{s\\in\\mathcal{S}}V_{h}^{\\pi,\\rho}(s)-\\operatorname*{min}_{s\\in\\mathcal{S}}V_{h}^{\\pi,\\rho}(s)\\leq\\frac{1-(1-\\rho)^{H-h+1}}{\\rho}.\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "Proof of Corollary 5.3. By the fact that the variance of a random variable can be upper bounded by the square of its range and Lemma E.3, for all $(s,a,h)\\in S\\times A\\times[H]$ ,wehave ", "page_idx": 21}, {"type": "equation", "text": "$$\n[\\mathbb{V}V_{h+1}^{\\star}](s,a)\\le\\Big(\\frac{1-(1-\\rho)^{H-h+1}}{\\rho}\\Big)^{2}\\le\\Big(\\frac{1-(1-\\rho)^{H}}{\\rho}\\Big)^{2}.\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "Then we have ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\sum_{\\tau=1}^{K}\\frac{\\phi_{h}^{\\tau}\\phi_{h}^{\\tau\\top}}{[\\mathbb{V}_{h}V_{h+1}^{\\star}](s_{h}^{\\tau},a_{h}^{\\tau})}+\\frac{1}{H^{2}}{\\bf I}\\succeq\\sum_{\\tau=1}^{K}\\frac{\\phi_{h}^{\\tau}\\phi_{h}^{\\tau\\top}}{(\\frac{1-(1-\\rho)^{H}}{\\rho})^{2}}+\\frac{1}{H^{2}}{\\bf I}.\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "Thus we have ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\boldsymbol{\\Sigma}_{h}^{\\star-1}=\\Bigl(\\sum_{\\tau=1}^{K}\\frac{\\phi_{h}^{\\tau}\\phi_{h}^{\\tau\\top}}{[\\boldsymbol{\\nabla}_{h}\\boldsymbol{V}_{h+1}^{\\star}](s_{h}^{\\tau},a_{h}^{\\tau})}+\\frac{1}{H^{2}}\\mathbf{I}\\Bigr)^{-1}\\preceq\\Bigl(\\frac{1-(1-\\rho)^{H}}{\\rho}\\Bigr)^{2}\\Bigl(\\sum_{\\tau=1}^{K}\\phi_{h}^{\\tau}\\phi_{h}^{\\tau\\top}+\\frac{1}{H^{2}}\\mathbf{I}\\Bigr)^{-1}.\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "By Theorem 5.2, we have ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathrm{SubOpt}(\\hat{\\pi},s,\\rho)\\leq\\tilde{O}(\\sqrt{d})\\cdot\\underset{P\\in\\mathcal{U}^{\\rho}(P^{0})}{\\operatorname*{sup}}\\underset{h=1}{\\overset{H}{\\sum}}\\mathbb{E}^{\\pi^{*},P}\\Big[\\underset{i=1}{\\overset{d}{\\sum}}\\|\\phi_{i}(s_{h},a_{h})\\mathbf{1}_{i}\\|_{\\mathbf{\\Sigma}_{\\hat{h}}^{\\star-1}}\\big|s_{1}=s\\Big]}\\\\ &{\\qquad\\qquad\\qquad\\leq\\tilde{O}(\\sqrt{d})\\cdot\\frac{1-\\big(1-\\rho\\big)^{H}}{\\rho}\\underset{P\\in\\mathcal{U}^{\\rho}(P^{0})}{\\operatorname*{sup}}\\underset{h=1}{\\overset{H}{\\sum}}\\mathbb{E}^{\\pi^{*},P}\\Big[\\underset{i=1}{\\overset{d}{\\sum}}\\|\\phi_{i}(s_{h},a_{h})\\mathbf{1}_{i}\\|_{\\mathbf{\\Sigma}_{h}^{-1}}\\big|s_{1}=s\\Big].}\\end{array}\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "This concludes the proof. ", "page_idx": 22}, {"type": "text", "text": "F  Proof of the Information-Theoretic Lower Bound ", "text_level": 1, "page_idx": 22}, {"type": "text", "text": "In this section, we prove the information-theoretic lower bound. We first introduce the construction of hard instances in Appendix F.1, then we prove Theorem 6.1 in Appendix F.2, and prove Corollary 6.2 in Appendix F.3. ", "page_idx": 22}, {"type": "text", "text": "F.1  Construction of Hard Instances ", "text_level": 1, "page_idx": 22}, {"type": "text", "text": "We design a family of $d$ -rectangular linear DRMDPs parameterized by a Boolean vector $\\xi\\;=$ $\\{\\pmb{\\xi}_{h}\\}_{h\\in[H]}$ , where $\\dot{\\xi_{h}}\\in\\{-1,1\\}^{d}$ . For a given $\\xi$ and uncertainty level $\\rho\\in\\left(0,3/4\\right]$ , the corresponding $d_{\\cdot}$ -rectangular linear DRMDP $M_{\\xi}^{\\rho}$ has the following structure. The state space $S=\\{x_{1},x_{2}\\}$ and the action space ${\\cal A}=\\{0,1\\}^{d}$ . The initial state distribution $\\mu_{0}$ is defined as ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\mu_{0}(x_{1})=\\frac{d+1}{d+2}\\quad\\mathrm{and}\\quad\\mu_{0}(x_{2})=\\frac{1}{d+2}.\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "The feature mapping $\\phi:S\\times A\\rightarrow\\mathbb{R}^{d+2}$ is defined as ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\begin{array}{l}{\\phi(x_{1},a)^{\\top}=\\Big(\\frac{a_{1}}{d},\\frac{a_{2}}{d},\\cdot\\cdot\\cdot,\\frac{a_{d}}{d},1-\\displaystyle\\sum_{i=1}^{d}\\frac{a_{i}}{d},0\\Big)}\\\\ {\\phi(x_{2},a)^{\\top}=\\big(0,0,\\cdot\\cdot\\cdot\\mathrm{~,~}0,0,1\\big),}\\end{array}\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "which satisfies $\\phi_{i}(s,a)\\geq0$ and $\\begin{array}{r}{\\sum_{i=1}^{d}\\phi_{i}(s,a)=1}\\end{array}$ The factor distributions $\\{\\mu_{h}\\}_{h\\in[H]}$ are defined as ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mu_{h}^{\\top}=\\big(\\underbrace{\\delta_{x_{1}},\\delta_{x_{1},}\\!\\cdot\\!\\cdot\\!\\cdot\\!\\cdot,\\delta_{x1},\\delta_{x_{1}}}_{d+1},\\delta_{x_{2}}\\big),\\forall h\\in[H],}\\end{array}\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "so the transition is homogeneous and does not depend on action but only on state. The reward parameters $\\{\\pmb{\\theta}_{h}\\}_{h\\in[H]}$ are defined as ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\pmb{\\theta}_{h}^{\\top}=\\delta\\cdot\\Big(\\frac{\\xi_{h1}+1}{2},\\frac{\\xi_{h2}+1}{2},\\cdot\\cdot\\cdot\\thinspace,\\frac{\\xi_{h d}+1}{2},\\frac{1}{2},0\\Big),\\forall h\\in[H],\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "where $\\delta$ is a parameter to control the differences among instances, which is to be determined later.  The reward $r_{h}$ is generated from the normal distribution $r_{h}\\,\\sim\\,\\mathcal{N}(r_{h}(s_{h},a_{h}),1)$ ,where $\\boldsymbol{r}_{h}(s,a)=\\boldsymbol{\\phi}(s,a)^{\\top}\\mathbf{\\theta}_{h}$ Note that ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\gimel_{h}(x_{1},a)=\\phi(x_{1},a)^{\\top}\\theta_{h}={\\frac{\\delta}{2d}}{\\big(}\\langle\\xi_{h},a\\rangle+d{\\big)}\\geq0\\quad{\\mathrm{and}}\\quad r_{h}(x_{2},a)=\\phi(x_{2},a)^{\\top}\\theta_{h}=0,\\,\\forall a\\in{\\mathcal{A}},\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "whichmeansthat $x_{2}$ is a worst state in terms of the mean reward. Thus, the worst case transition kernel should have the highest possible transition probability to $x_{2}$ . This construction is pivotal in achieving a concise expression of robust value function. Further, we only consider model uncertainty ", "page_idx": 22}, {"type": "image", "img_path": "9SghPrjYU1/tmp/cee3780a52c135570aacdd79e84928ce930d13cf2a10815da9b08dc914116ebd.jpg", "img_caption": [], "img_footnote": [], "page_idx": 23}, {"type": "text", "text": "Figure 3: The nominal environment and the worst case environment. The value on each arrow represents the transition probability. The MDP has two states and $H$ steps.For the nominal environment, both $x_{1}$ and $x_{2}$ are absorbing states, which means that the state will always stay at the initial state in the nominal environment. The worst case environment on the right is obtained by perturbing the transition probability at the first step of the nominal environment, with others remain the same. ", "page_idx": 23}, {"type": "text", "text": "in the first step. By the fact that $x_{2}$ is the worse state, we know the worst case factor distribution for the first step is ", "page_idx": 23}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\check{\\mu}_{1}^{\\intercal}=\\left((1-\\rho)\\delta_{x_{1}}+\\rho\\delta_{x_{2}},(1-\\rho)\\delta_{x_{1}}+\\rho\\delta_{x_{2}},\\cdots,(1-\\rho)\\delta_{x_{1}}+\\rho\\delta_{x_{2}},(1-\\rho)\\delta_{x_{1}}+\\rho\\delta_{x_{2}},\\delta_{x_{2}}\\right).}\\end{array}\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "We illustrate the designed $d$ -rectangular linear DRMDP $M_{\\xi}^{\\rho}$ in Figure 3(a) and Figure 3(b) ", "page_idx": 23}, {"type": "text", "text": "Finally, we design the procedure for collecting the offline dataset. We assume the $K$ trajectories are collected by a behavior policy $\\pi^{b}=\\{\\pi_{h}^{b}\\}_{h\\in[H]}$ defined as ", "page_idx": 23}, {"type": "equation", "text": "$$\n\\pi_{h}^{b}\\sim\\operatorname{Unif}\\bigl(\\{e_{1},\\cdot\\cdot\\cdot,e_{d},\\mathbf{0}\\}\\bigr),\\forall h\\in[H],\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "where $\\{e_{i}\\}_{i\\in[d]}$ are the canonical basis vectors in $\\mathbb{R}^{d}$ The initial state is generated according to $\\mu_{0}$ It is straightforward to check that the constructed hard instances satisfy Assumption 4.3. We denote the offline dataset as $\\mathcal{D}$ ", "page_idx": 23}, {"type": "text", "text": "F.2Proof of Theorem 6.1 ", "text_level": 1, "page_idx": 23}, {"type": "text", "text": "With this family of hard instances, we are ready to prove the information-theoretic lower bound. First, we define some notations. For any $\\pmb{\\xi}\\in\\{-\\dot{1},1\\}^{\\dot{d}H}$ , let $\\mathbb{Q}_{\\xi}$ denote the distribution of dataset $\\mathcal{D}$ collected from the MDP $M_{\\xi}$ . Denote the family of parameters as $\\Omega=\\{-1,1\\}^{d H}$ and the family of hard instances as $\\mathcal{M}=\\{M_{\\xi}:\\xi\\in\\Omega\\}$ ", "page_idx": 23}, {"type": "text", "text": "Proof of Theorem 6.1. The proof constitutes three steps. In the first step, we lower bound the minimax suboptimality gap by testing error in the following Lemma F.1, the full proof of which can be found inAppendixG.6. ", "page_idx": 23}, {"type": "text", "text": "Lemma F.1 (Reduction to testing). For the given family of $d$ -rectangular linear DRMDPs, we have ", "page_idx": 23}, {"type": "equation", "text": "$$\n\\operatorname*{nf}_{\\hat{\\pi}}\\ \\operatorname*{sup}_{M\\in\\mathcal{M}}{\\operatorname{Sub}}\\mathrm{Opt}(\\hat{\\pi},x_{1},\\rho)\\geq(1-\\rho)\\cdot\\frac{\\delta d H}{8d}\\cdot\\operatorname*{min}_{\\stackrel{\\xi,\\xi^{\\prime}\\in\\Omega}{D_{H}(\\xi,\\xi^{\\prime})=1}}\\operatorname*{inf}_{\\psi}\\left[\\mathbb{Q}_{\\xi}(\\psi(\\mathcal{D})\\neq\\xi)+\\mathbb{Q}_{\\xi^{\\prime}}(\\psi(\\mathcal{D})\\neq\\xi^{\\prime})\\right],\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "where for fixed indices $\\xi$ and $\\xi^{\\prime}$ \uff0c $\\psi$ is any test function taking value in $\\{\\pmb{\\xi},\\pmb{\\xi}^{\\prime}\\}$ ", "page_idx": 23}, {"type": "text", "text": "In the second step, we lower bound the testing error on the right hand side of (F.1) in the following Lemma F.2, the full proof of which can be found in Appendix G.7. ", "page_idx": 23}, {"type": "text", "text": "Lemma F.2 (Lower bound on testing error). For the given family of $d$ -rectangular linear DRMDPs, let $\\delta=d^{3/2}/\\sqrt{2K}$ then we have ", "page_idx": 23}, {"type": "equation", "text": "$$\n\\operatorname*{min}_{\\pmb{\\xi},\\pmb{\\xi}^{\\prime}}\\operatorname*{inf}_{\\pmb{\\psi}}\\left[\\mathbb{Q}_{\\pmb{\\xi}}(\\psi(\\mathcal{D})\\neq\\pmb{\\xi})+\\mathbb{Q}_{\\pmb{\\xi}^{\\prime}}(\\psi(\\mathcal{D})\\neq\\pmb{\\xi}^{\\prime})\\right]\\geq\\frac{1}{2}.\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "By Lemma F.1 and Lemma F.2, we have ", "text_level": 1, "page_idx": 23}, {"type": "equation", "text": "$$\n\\operatorname*{inf}_{\\hat{\\pi}}\\ \\operatorname*{sup}_{M\\in\\mathcal{M}}\\operatorname{SubOpt}(\\hat{\\pi},x_{1},\\rho)\\geq\\frac{d^{3/2}H}{128\\sqrt{K}}.\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "In the last step, we upper bound the uncertainty function $\\Phi(\\Sigma_{h}^{\\star},s)$ in the following Lemma F.3, the full proof of which can be found in Appendix G.8. ", "page_idx": 23}, {"type": "text", "text": "Lemma F.3. For all $M_{\\xi}\\in\\mathcal{M}$ , when $K\\geq\\tilde{O}(d^{4})$ , then with probability at least $1-\\delta$ , we have ", "page_idx": 24}, {"type": "equation", "text": "$$\n\\operatorname*{sup}_{P\\in\\mathcal{U}^{\\rho}(P^{0})}\\sum_{h=1}^{H}\\mathbb{E}^{\\pi^{\\star},P}\\Big[\\sum_{i=1}^{d}\\|\\phi_{i}(s_{h},a_{h})\\mathbf{1}_{i}\\|_{\\mathbf{\\Sigma}_{h}^{\\star-1}}\\big|s_{1}=x_{1}\\Big]\\le\\frac{4d^{3/2}H}{\\sqrt{K}}.\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "By Lemma F.3 and (F.2), we know that with probability at least $1-\\delta$ , there exist a universal constant $c$ suchthat ", "page_idx": 24}, {"type": "equation", "text": "$$\n\\operatorname*{inf}_{\\hat{\\pi}}\\ \\operatorname*{sup}_{M\\in\\mathcal{M}}{\\sf S u b O p t}(\\hat{\\pi},x_{1},\\rho)\\geq c\\cdot\\operatorname*{sup}_{P\\in\\mathcal{U}^{\\rho}(P^{0})}\\sum_{h=1}^{H}\\mathbb{E}^{\\pi^{\\star},P}\\Big[\\sum_{i=1}^{d}\\|\\phi_{i}(s_{h},a_{h})\\mathbf{1}_{i}\\|_{\\mathbf{\\Sigma}_{h}^{\\star-1}}|s_{1}=x_{1}\\Big].\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "This concludes the proof. ", "page_idx": 24}, {"type": "text", "text": "F.3Proof of Corollary 6.2 ", "text_level": 1, "page_idx": 24}, {"type": "text", "text": "Proof. The result in Corollary 6.2 directly follows from the fact shown in (G.38): for the constructed hard instances, we have $\\Sigma_{h}^{\\star}=\\Lambda_{h}$ . Thus, we complete the proof by directly substituting $\\Sigma_{h}^{\\star}$ in the result of Theorem 6.1 by $\\Lambda_{h}$ \u53e3 ", "page_idx": 24}, {"type": "text", "text": "GProof of Technical Lemmas ", "text_level": 1, "page_idx": 24}, {"type": "text", "text": "G.1 Proof of Lemma D.1 ", "text_level": 1, "page_idx": 24}, {"type": "text", "text": "Proof. First, we decompose $\\mathrm{SubOpt}(\\hat{\\pi},s,\\rho)$ as follows ", "page_idx": 24}, {"type": "equation", "text": "$$\n\\mathrm{SubOpt}(\\hat{\\pi},s,\\rho)=\\underbrace{V_{1}^{\\pi^{\\star},\\rho}(s)-\\widehat{V}_{1}^{\\rho}(s)}_{\\mathrm{I}}+\\underbrace{\\widehat{V}_{1}^{\\rho}(s)-V_{1}^{\\hat{\\pi},\\rho}(s)}_{\\mathrm{II}},\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "then we bound term I and term II, respectively. ", "page_idx": 24}, {"type": "text", "text": "Bounding term I: Note that ", "text_level": 1, "page_idx": 24}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{V_{h}^{\\pi^{*},\\rho}(s)-\\widehat V_{h}^{\\rho}(s)=Q_{h}^{\\pi^{*},\\rho}(s,\\pi_{h}^{\\star}(s))-\\widehat Q_{h}^{\\rho}(s,\\widehat\\pi_{h}(s))}\\\\ &{\\quad\\quad\\quad\\quad\\quad\\quad=Q_{h}^{\\pi^{\\star},\\rho}(s,\\pi_{h}^{\\star}(s))-\\widehat Q_{h}^{\\rho}(s,\\pi_{h}^{\\star}(s))+\\widehat Q_{h}^{\\rho}(s,\\pi_{h}^{\\star}(s))-\\widehat Q_{h}^{\\rho}(s,\\widehat\\pi_{h}(s))}\\\\ &{\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\leq Q_{h}^{\\pi^{\\star},\\rho}(s,\\pi_{h}^{\\star}(s))-\\widehat Q_{h}^{\\rho}(s,\\pi_{h}^{\\star}(s)).}\\end{array}\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "Here (G.1) holds by the fact that $\\hat{\\pi}_{h}(s)$ is the greedy policy corresponding to $\\widehat{Q}_{h}^{\\rho}(s,a)$ , which leads $\\widehat{Q}_{h}^{\\rho}(s,\\pi_{h}^{\\star}(s))-\\widehat{Q}_{h}^{\\rho}(s,\\widehat{\\pi}_{h}(s))\\leq0$ . Further, by the robust Bellman equation (3.1), we have ", "page_idx": 24}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathcal{J}_{h}^{\\pi^{*},\\rho}(s,\\pi_{h}^{*}(s))-\\widehat{Q}_{h}^{\\rho}(s,\\pi_{h}^{*}(s))}\\\\ &{=r_{h}(s,\\pi_{h}^{*}(s))+\\underset{P_{h}(\\cdot\\vert s,a)\\in\\mathcal{U}_{h}^{f}(s,a;\\mu_{h,i}^{0})}{\\operatorname*{inf}}[\\mathbb{P}_{h}V_{h+1}^{\\pi^{*},\\rho}](s,\\pi_{h}^{*}(s))-\\widehat{Q}_{h}^{\\rho}(s,\\pi_{h}^{*}(s))}\\\\ &{=r_{h}(s,\\pi_{h}^{*}(s))+\\underset{P_{h}(\\cdot\\vert s,a)\\in\\mathcal{U}_{h}^{f}(s,a;\\mu_{h,i}^{0})}{\\operatorname*{inf}}[\\mathbb{P}_{h}V_{h+1}^{\\pi^{*},\\rho}](s,\\pi_{h}^{*}(s))-r_{h}(s,\\pi_{h}^{*}(s))}\\\\ &{\\quad-\\underset{P_{h}(\\cdot\\vert s,a)\\in\\mathcal{U}_{h}^{f}(s,a;\\mu_{h,i}^{0})}{\\operatorname*{inf}}[\\mathbb{P}_{h}\\widehat{V}_{h+1}^{\\rho}](s,\\pi_{h}^{*}(s))+r_{h}(s,\\pi_{h}^{*}(s))+\\underset{P_{h}(\\cdot\\vert s,a)\\in\\mathcal{U}_{h}^{f}(s,a;\\mu_{h,i}^{0})}{\\operatorname*{inf}}[\\mathbb{P}_{h}\\widehat{V}_{h+1}^{\\rho}](s,\\pi_{h}^{*}(s))}\\\\ &{\\quad-\\underset{P_{h}(\\cdot\\vert s,a)\\in\\mathcal{U}_{h}^{f}(s,a;\\mu_{h,i}^{0})}{\\operatorname*{inf}}[\\mathbb{P}_{h}\\widehat{V}_{h+1}^{\\rho}](s,\\pi_{h}^{*}(s))+r_{h}(s,\\pi_{h}^{*}(s))+\\underset{P_{h}(\\cdot\\vert s,a)\\in\\mathcal{U}_{h}^{f}(s,a;\\mu_{h,i}^{0})}{\\operatorname*{inf}}[\\mathbb{P}_{h}\\widehat{V}_{h+1}^{\\rho}](s,\\pi_{h}^{*}(s))}\\\\ &{\\quad-\\widehat\n$$- Qh(s, \u03c0T(s). ", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "To proceed, we define the robust Bellman update error as follows ", "page_idx": 24}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\zeta_{h}^{\\rho}(s,a)=r_{h}(s,a)+\\underset{P_{h}(\\cdot\\vert s,a)\\in\\mathcal{U}_{h}^{\\rho}(s,a;\\mu_{h,i}^{0})}{\\operatorname*{inf}}[\\mathbb{P}_{h}\\widehat{V}_{h+1}^{\\rho}](s,a)-\\widehat{Q}_{h}^{\\rho}(s,a),}\\end{array}\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "and denote the worst case transition kernel with respect to the estimated robust value function as $\\widehat{P}=\\{\\widehat{P}_{h}\\}_{h\\in[H]}$ where $\\begin{array}{r}{\\widehat{P}_{h}(\\cdot|s,a)=\\arg\\operatorname*{inf}_{P_{h}(\\cdot|s,a)\\in{\\cal U}_{h}^{\\rho}(s,a;\\mu_{h,i}^{0})}[\\mathbb{P}_{h}\\widehat{V}_{h+1}^{\\rho}](s,a),\\forall(s,a)\\in\\mathcal{S}\\times\\mathcal{A}.}\\end{array}$ Thenwehave ", "page_idx": 24}, {"type": "equation", "text": "$$\nQ_{h}^{\\pi^{\\star},\\rho}(s,\\pi_{h}^{\\star}(s))-\\widehat{Q}_{h}^{\\rho}(s,\\pi_{h}^{\\star}(s))\n$$", "text_format": "latex", "page_idx": 24}, {"type": "equation", "text": "$$\n\\begin{array}{r l r}&{=}&{\\operatorname*{inf}_{\\substack{P_{h}(\\cdot\\,|s,a)\\in\\mathcal{U}_{h}^{\\ell}(s,a;\\mu_{h,i}^{0})}}[\\mathbb{P}_{h}V_{h+1}^{\\pi^{*},\\rho}](s,\\pi_{h}^{*}(s))-\\operatorname*{inf}_{\\substack{P_{h}(\\cdot\\,|s,a)\\in\\mathcal{U}_{h}^{\\ell}(s,a;\\mu_{h,i}^{0})}}[\\mathbb{P}_{h}\\hat{V}_{h+1}^{\\rho}](s,\\pi_{h}^{*}(s))+\\zeta_{h}^{\\rho}(s,\\pi_{h}^{*}(s))}\\\\ &{\\leq}&{\\big[\\mathbb{\\hat{P}}_{h}(V_{h+1}^{\\pi^{*},\\rho}-\\hat{V}_{h+1}^{\\rho})\\big](s,\\pi_{h}^{\\star}(s))+\\zeta_{h}^{\\rho}(s,\\pi_{h}^{\\star}(s)).}&{\\mathrm{(G.2)}}\\end{array}\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "Combining (G.1) and (G.2), we have for any $h\\in[H]$ \uff0c ", "page_idx": 25}, {"type": "equation", "text": "$$\n\\begin{array}{r}{V_{h}^{\\pi^{\\star},\\rho}(s)-\\widehat{V}_{h}^{\\rho}(s)\\leq\\big[\\widehat{\\mathbb{P}}_{h}(V_{h+1}^{\\pi^{\\star},\\rho}-\\widehat{V}_{h+1}^{\\rho})\\big](s,\\pi_{h}^{\\star}(s))+\\zeta_{h}^{\\rho}(s,\\pi_{h}^{\\star}(s)).}\\end{array}\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "Recursively applying (G.3), we have ", "page_idx": 25}, {"type": "equation", "text": "$$\nV_{1}^{\\pi^{\\star},\\rho}(s)-\\widehat{V}_{1}^{\\rho}(s)\\leq\\sum_{h=1}^{H}\\mathbb{E}^{\\pi^{\\star},\\widehat{P}}\\left[\\zeta_{h}^{\\rho}(s_{h},a_{h})\\vert s_{1}=s\\right].\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "Bounding term I:  Note that $\\widehat{V}_{h}^{\\rho}(s)-V_{h}^{\\hat{\\pi},\\rho}(s)=\\widehat{Q}_{h}^{\\rho}(s,\\hat{\\pi}_{h}(s))-Q_{h}^{\\hat{\\pi},\\rho}(s,\\hat{\\pi}_{h}(s))$ by the robust Bellman equation (3.1), we have ", "page_idx": 25}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\hat{\\gamma}_{h}^{\\rho}(s)-V_{h}^{\\hat{\\pi},\\rho}(s)}\\\\ &{=\\hat{Q}_{h}^{\\rho}(s,\\hat{\\pi}_{h}(s))-r_{h}(s,\\hat{\\pi}_{h}(s))-\\operatorname*{inf}_{\\substack{P_{h}(\\cdot\\vert s,a)\\in{\\mathcal U}_{h}^{\\rho}(s,a;\\mu_{h,i}^{0})}}[{\\mathbb P}_{h}\\widehat{V}_{h+1}^{\\rho}](s,\\hat{\\pi}_{h}(s))}\\\\ &{\\quad+\\operatorname*{inf}_{\\substack{P_{h}(\\cdot\\vert s,a)\\in{\\mathcal U}_{h}^{\\rho}(s,a;\\mu_{h,i}^{0})}}[{\\mathbb P}_{h}\\widehat{V}_{h+1}^{\\rho}](s,\\hat{\\pi}_{h}(s))-\\operatorname*{inf}_{\\substack{P_{h}(\\cdot\\vert s,a)\\in{\\mathcal U}_{h}^{\\rho}(s,a;\\mu_{h,i}^{0})}}[{\\mathbb P}_{h}V_{h+1}^{\\hat{\\pi},\\rho}](s,\\hat{\\pi}_{h}(s))}\\\\ &{=-\\zeta_{h}^{\\rho}(s,\\hat{\\pi}_{h}(s))+\\operatorname*{inf}_{\\substack{P_{h}(\\cdot\\vert s,a)\\in{\\mathcal U}_{h}^{\\rho}(s,a;\\mu_{h,i}^{0})}}[{\\mathbb P}_{h}\\widehat{V}_{h+1}^{\\rho}](s,\\hat{\\pi}_{h}(s))-\\operatorname*{inf}_{\\substack{P_{h}(\\cdot\\vert s,a)\\in{\\mathcal U}_{h}^{\\rho}(s,a;\\mu_{h,i}^{0})}}[{\\mathbb P}_{h}V_{h+1}^{\\hat{\\pi},\\rho}](s,\\hat{\\pi}_{h}(s))}\\end{array}\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "To proceed, we denote the worst case transition kernel with respect to the robust value function of $\\hat{\\pi}$ $P^{\\hat{\\pi}}=\\{P_{h}^{\\hat{\\pi}}\\}_{h\\in[H]}$ Where $\\begin{array}{r}{P_{h}^{\\hat{\\pi}}(\\cdot|s,a)=\\arg\\operatorname*{inf}_{P_{h}(\\cdot|s,a)\\in\\mathcal{U}_{h}^{\\rho}(s,a;\\mu_{h,i}^{0})}[\\mathbb{P}_{h}V_{h+1}^{\\hat{\\pi},\\rho}](s,a),}\\end{array}$ then we have ", "page_idx": 25}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\widehat{V}_{h}^{\\rho}(s)-V_{h}^{\\hat{\\pi},\\rho}(s)\\leq-\\zeta_{h}^{\\rho}(s,\\hat{\\pi}_{h}(s))+\\big[\\mathbb{P}_{h}^{\\hat{\\pi}}(\\widehat{V}_{h+1}^{\\rho}-V_{h+1}^{\\hat{\\pi},\\rho})\\big](s,\\hat{\\pi}_{h}(s)).}\\end{array}\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "Applying (G.5) recursively, we have ", "page_idx": 25}, {"type": "equation", "text": "$$\n\\widehat{V}_{1}^{\\rho}(s)-V_{1}^{\\hat{\\pi},\\rho}(s)\\leq\\sum_{h=1}^{H}\\mathbb{E}^{\\hat{\\pi},P^{\\hat{\\pi}}}\\big[-\\zeta_{h}^{\\rho}(s_{h},a_{h})\\vert s_{1}=s\\big].\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "Now it remains to bound the robust Bellman error $\\zeta_{h}^{\\rho}(\\cdot,\\cdot)$ . In particular, we aim to show that for all $(s,a,h)\\in\\mathcal{S}\\times\\mathcal{A}\\times[H]$ ", "page_idx": 25}, {"type": "equation", "text": "$$\n0\\leq\\zeta_{h}^{\\rho}(s,a)\\leq2\\Gamma_{h}(s,a).\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "Note that $\\begin{array}{r}{\\zeta_{h}^{\\rho}(s,a)=r_{h}(s,a)+\\operatorname*{inf}_{P_{h}(\\cdot\\vert s,a)\\in\\mathcal{U}_{h}^{\\rho}(s,a;\\mu_{h,i}^{0})}[\\mathbb{P}_{h}\\widehat{V}_{h+1}^{\\rho}](s,a)-\\widehat{Q}_{h}^{\\rho}(s,a)}\\end{array}$ . Recall the deinition of $\\widehat{Q}_{h}^{\\rho}(s,a)$ in Algorithm 1 and the notation in (E.1), and we have ", "page_idx": 25}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\zeta_{h}^{\\rho}(s,a)=r_{h}(s,a)+\\operatorname*{inf}_{\\substack{P_{h}(\\cdot\\,|s,a)\\in\\mathcal{U}_{h}^{\\rho}(s,a;\\mu_{h,i}^{0})}}[\\mathbb{P}_{h}\\widehat{V}_{h+1}^{\\rho}](s,a)}\\\\ &{\\qquad\\qquad-\\operatorname*{max}\\Big\\{r_{h}(s,a)+\\underset{P_{h}(\\cdot\\,|s,a)\\in\\mathcal{U}_{h}^{\\rho}(s,a;\\mu_{h,i}^{0})}{\\widehat{\\mathrm{inf}}}[\\mathbb{P}_{h}\\widehat{V}_{h+1}^{\\rho}](s,a)-\\Gamma_{h}(s,a),0\\Big\\}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "If $r_{h}(s,a)+\\widehat{\\mathrm{inf}}_{P_{h}(\\cdot\\vert s,a)\\in{\\cal U}_{h}^{\\rho}(s,a;{\\pmb\\mu}_{h,i}^{0})}[\\mathbb{P}_{h}\\widehat{V}_{h+1}^{\\rho}](s,a)\\,-\\,\\Gamma_{h}(s,a)\\,\\leq\\,0$ then $\\zeta_{h}^{\\rho}(s,a)\\,=\\,r_{h}(s,a)\\,+$ $\\operatorname*{inf}_{P_{h}(\\cdot|s,a)\\in\\mathcal{U}_{h}^{\\rho}(s,a;{\\pmb\\mu}_{h,i}^{0})}[\\mathbb{P}_{h}\\widehat{V}_{h+1}^{\\rho}](s,a)\\geq0$ . If rh(s, a) inf r:(-1s,a)eug(s,gu\u03bcrh. [IPh Vh+1](s, a) $\\Gamma_{h}(s,a)>0$ , then we have $\\zeta_{h}^{\\rho}(s,a)=r_{h}(s,a)+\\operatorname*{inf}_{P_{h}(\\cdot\\vert s,a)\\in\\mathcal{U}_{h}^{\\rho}(s,a;\\pmb{\\mu}_{h,i}^{0})}[\\mathbb{P}_{h}\\widehat{V}_{h}]$ +1](s,a)-rh(s,a)- $\\begin{array}{r}{\\widehat{\\operatorname*{inf}}_{P_{h}(\\cdot|s,a)\\in\\mathcal{U}_{h}^{\\rho}(s,a;\\mu_{h,i}^{0})}[\\mathbb{P}_{h}\\widehat{V}_{h+1}^{\\rho}](s,a)+\\Gamma_{h}(s,a)\\geq-\\Gamma_{h}(s,a)+\\Gamma_{h}(s,a)=0,}\\end{array}$ where we used the condition in (D.1). In conclusion, we have $\\zeta_{h}^{\\rho}(s,a)\\geq0$ ", "page_idx": 25}, {"type": "text", "text": "On the other hand, we always have ", "page_idx": 25}, {"type": "equation", "text": "$$\n\\zeta_{h}^{\\rho}(s,a)\\leq\\operatorname*{inf}_{\\substack{P_{h}(\\cdot\\vert s,a)\\in\\mathcal{U}_{h}^{\\rho}(s,a;\\mu_{h,i}^{0})}}[\\mathbb{P}_{h}\\widehat{V}_{h+1}^{\\rho}](s,a)-\\widehat{\\operatorname*{inf}_{\\substack{P_{h}(\\cdot\\vert s,a)\\in\\mathcal{U}_{h}^{\\rho}(s,a;\\mu_{h,i}^{0})}}}[\\mathbb{P}_{h}\\widehat{V}_{h+1}^{\\rho}](s,a)+\\Gamma_{h}(s,a)\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "Thus, for all $(s,a,h)\\in S\\times A\\times[H]$ , we have ", "page_idx": 26}, {"type": "equation", "text": "$$\n0\\leq\\zeta_{h}^{\\rho}(s,a)\\leq2\\Gamma_{h}(s,a).\n$$", "text_format": "latex", "page_idx": 26}, {"type": "text", "text": "Combining (G.4), (G.6) and (G.7), we have ", "page_idx": 26}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathrm{SubOpt}(\\hat{\\pi},s,\\rho)\\leq\\displaystyle\\sum_{h=1}^{H}\\mathbb{E}^{\\pi^{*},\\hat{P}}\\big[\\zeta_{h}(s_{h},a_{h})\\big|s_{1}=s\\big]+\\displaystyle\\sum_{h=1}^{H}\\mathbb{E}^{\\hat{\\pi}_{*},P^{\\#}}\\big[-\\zeta_{h}^{\\rho}(s_{h},a_{h})\\big|s_{1}=s\\big]}\\\\ &{\\leq\\displaystyle\\sum_{h=1}^{H}\\mathbb{E}^{\\pi^{*},\\hat{P}}\\big[\\zeta_{h}^{\\rho}(s_{h},a_{h})\\big|s_{1}=s\\big]}\\\\ &{\\leq\\displaystyle\\operatorname*{sup}_{P\\in{\\mathcal U}^{\\prime}(P)}\\sum_{h=1}^{H}\\mathbb{E}^{\\pi^{*},P}\\big[\\zeta_{h}^{\\rho}(s_{h},a_{h})\\big|s_{1}=s\\big]}\\\\ &{\\leq2\\operatorname*{sup}_{P\\in{\\mathcal U}^{\\prime}(P)}\\sum_{h=1}^{H}\\mathbb{E}^{\\pi^{*},P}\\big[\\Gamma_{h}(s_{h},a_{h})\\big|s_{1}=s\\big].}\\end{array}\n$$", "text_format": "latex", "page_idx": 26}, {"type": "text", "text": "This concludes the proof. ", "page_idx": 26}, {"type": "text", "text": "G.2 Proof of Lemma D.2 ", "text_level": 1, "page_idx": 26}, {"type": "text", "text": "In this section, we prove Lemma D.2. Before the proof, we first present several auxiliary lemmas. ", "page_idx": 26}, {"type": "text", "text": "Lemma G.1 (Reference-Advantage Decomposition). There exist real values $\\{\\alpha_{i}\\}_{i\\in[d]}$ ,where $\\alpha_{i}\\in$ $[0,H],\\forall i\\in[d]$ ,such that ", "page_idx": 26}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\underset{P_{h}(\\cdot\\vert s,a)\\in\\mathbb{H}_{h}^{\\ell}(s,a)\\mathbb{H}_{h}^{\\ell}(s,a)}{\\operatorname*{inf}}\\vert\\mathbb{P}_{h}\\hat{V}_{h+1}^{\\rho}\\vert(s,a)-\\underset{P_{h}(\\cdot\\vert s,a)\\in\\mathbb{H}_{h}^{\\rho}(s,a;\\mu_{h,i}^{0})}{\\operatorname*{inf}}\\vert\\mathbb{P}_{h}\\hat{V}_{h+1}^{\\rho}\\vert(s,a)\\Big\\vert}\\\\ &{\\leq\\underset{\\bar{\\pi}=1}{\\underbrace{\\lambda\\sum_{i=1}^{d}\\|\\phi_{i}(s,a)\\mathbf{1}_{i}\\|_{\\mathbf{A}_{h}^{-1}}\\|\\mathbb{E}^{\\mu_{h}^{0}}[V_{h+1}^{\\star,\\rho}(s)]_{\\alpha_{i}}\\|_{\\mathbf{A}_{h}^{-1}}}}+\\underset{\\bar{\\xi}=1}{\\underbrace{\\sum_{i=1}^{d}\\|\\phi_{i}(s,a)\\mathbf{1}_{i}\\|_{\\mathbf{A}_{h}^{-1}}\\big\\|\\sum_{\\tau=1}^{K}\\phi_{h}^{\\tau}\\eta_{h}^{\\tau}([V_{h+1}^{\\star,\\rho}]_{\\alpha_{i}})\\big\\vert_{\\mathbf{A}_{h}^{-1}}}}}\\\\ &{\\quad+\\underset{\\bar{\\pi}=1}{\\underbrace{\\lambda\\sum_{i=1}^{d}\\|\\phi_{i}(s,a)\\mathbf{1}_{i}\\|_{\\mathbf{A}_{h}^{-1}}\\|\\mathbb{E}^{\\mu_{h}^{0}}[[\\hat{V}_{h+1}^{\\rho}(s)]_{\\alpha_{i}}-[V_{h+1}^{\\star,\\rho}(s)]_{\\alpha_{i}}]\\big\\|_{\\mathbf{A}_{h}^{-1}}}}}\\\\ &{\\quad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\kappa\\qquad\\qquad\\mathrm{ind}}\\end{array}\n$$", "text_format": "latex", "page_idx": 26}, {"type": "equation", "text": "$$\n+\\sum_{i=1}^{d}\\|\\phi_{i}(s,a)\\mathbf{1}_{i}\\|_{\\mathbf{A}_{h}^{-1}}\\Big\\|\\sum_{\\tau=1}^{K}\\phi_{h}^{\\tau}\\eta_{h}^{\\tau}([\\widehat{V}_{h+1}^{\\rho}(s)]_{\\alpha_{i}}-[V_{h+1}^{\\star,\\rho}(s)]_{\\alpha_{i}})\\Big\\|_{\\mathbf{A}_{h}^{-1}},\n$$", "text_format": "latex", "page_idx": 26}, {"type": "text", "text": "where $\\eta_{h}^{\\tau}([f]_{\\alpha_{i}})=\\left([\\mathbb{P}_{h}^{0}[f]_{\\alpha_{i}}](s_{h}^{\\tau},a_{h}^{\\tau})-[f(s_{h+1}^{\\tau})]_{\\alpha_{i}}\\right)$ , for any function $f:S\\to[0,H-1]$ ", "page_idx": 26}, {"type": "text", "text": "Lemma G.2 (Bound of Weights). For any $h\\in[H]$ , denote the weight ${\\pmb w}_{h}^{\\rho}={\\pmb\\theta}_{h}+\\hat{\\pmb\\nu}_{h}^{\\rho}$ in Algorithm 1, then $w_{h}^{\\rho}$ satisfies ", "page_idx": 26}, {"type": "equation", "text": "$$\n\\|\\pmb{w}_{h}^{\\rho}\\|_{2}\\leq2H\\sqrt{d K/\\lambda}.\n$$", "text_format": "latex", "page_idx": 26}, {"type": "text", "text": "Lemma G.3. [15, Lemma B.2] Let $f:S\\to[0,R-1]$ be any fixed function. For any $\\delta\\in(0,1)$ \uff0c wehave ", "page_idx": 26}, {"type": "equation", "text": "$$\n\\mathbb{P}\\bigg(\\Big\\|\\sum_{\\tau=1}^{K}\\phi_{h}^{\\tau}\\cdot\\eta_{h}^{\\tau}(f)\\Big\\|_{\\Lambda_{h}^{-1}}^{2}\\geq R^{2}\\Big(2\\log\\Big(\\frac{1}{\\delta}\\Big)+d\\log\\Big(1+\\frac{K}{\\lambda}\\Big)\\Big)\\Big)\\leq\\delta.\n$$", "text_format": "latex", "page_idx": 26}, {"type": "text", "text": "Lemma G.4 (Covering number of function class $\\nu_{h}$ ). For any $h\\in[H]$ , let $\\nu_{h}$ denote a class of functions mapping from $\\boldsymbol{S}$ to $\\mathbb{R}$ with the following parametric form ", "page_idx": 26}, {"type": "equation", "text": "$$\n\\mathcal{V}_{h}(s)=\\operatorname*{max}_{a\\in A}\\Big\\{\\phi(s,a)^{\\top}\\pmb\\theta-\\beta\\sum_{i=1}^{d}\\sqrt{\\phi_{i}(s,a)\\mathbf{1}_{i}^{\\top}\\mathbf{\\Sigma}\\mathbf{\\Sigma}_{h}^{-1}\\phi_{i}(s,a)\\mathbf{1}_{i}}\\Big\\}_{[0,H-h+1]},\n$$", "text_format": "latex", "page_idx": 26}, {"type": "text", "text": "where the parameters $(\\pmb{\\theta},\\beta,\\pmb{\\Sigma}_{h})$ satisfy $\\|\\pmb{\\theta}\\|\\leq L,\\beta\\in[0,B]$ $\\lambda_{\\operatorname*{min}}(\\Sigma_{h})\\geq\\lambda$ Assume $\\left\\|\\phi(s,a)\\right\\|\\leq$ 1 for all (s,a) pairs, and let $\\tilde{\\mathcal{N}}_{h}(\\epsilon)$ be the $\\epsilon$ -covering number of $\\mathcal{V}$ with respect to the distance $\\mathrm{dist}(V_{1},V_{2})=\\mathrm{sup}_{x}\\,|V_{1}(x)-V_{2}(x)|$ . Then ", "page_idx": 27}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\log\\mathcal{N}_{h}(\\epsilon)\\leq d\\log(1+4L/\\epsilon)+d^{2}\\log\\left[1+8d^{1/2}B^{2}/(\\lambda\\epsilon^{2})\\right].}\\end{array}\n$$", "text_format": "latex", "page_idx": 27}, {"type": "text", "text": "Lemma G.5. [47, Covering number of an interval] Denote the $\\epsilon$ -covering number of the closed interval $[a,b]$ for some real number $b>a$ with respect to the distance metric $d(\\alpha_{1},\\alpha_{2})=|\\alpha_{1}-\\alpha_{2}|$ as $\\mathcal{N}_{\\epsilon}([a,b])$ . Then we have $\\mathcal{N}_{\\epsilon}([a,b])\\leq3(b-a)/\\epsilon$ ", "page_idx": 27}, {"type": "text", "text": "ProofofLemma $D.2$ . To prove this lemma, we bound terms i-iv in Lemma G.1 at each step $h\\in[H]$ respectively. To deal with the temporal dependency, we follow the induction procedure proposed in [54] and make essential adjustments to adapt to the robust setting. ", "page_idx": 27}, {"type": "text", "text": "The base case. We start from the last step $H$ . By the fact that any robust value function is upper bounded by $H$ , then with $\\lambda=1$ ,for all $(s,a)\\in S\\times A$ wehave ", "page_idx": 27}, {"type": "equation", "text": "$$\n\\mathrm{i}+\\mathrm{iii}\\leq2H\\sum_{i=1}^{d}\\|\\phi_{i}(s,a)\\mathbf{1}_{i}\\|_{\\mathbf{A}_{h}^{-1}}.\n$$", "text_format": "latex", "page_idx": 27}, {"type": "text", "text": "Next, we bound term i.Note that $V_{H+1}^{\\star,\\rho}$ is independent of $\\mathcal{D}$ we can diretly apply Hoeffding-type self-normalized concentration inequality Lemma I.1 and a union bound to obtain the upper bound. Inndtln $\\dot{\\mathcal{F}_{\\tau-1,h}}\\;=\\;\\sigma(\\{(s_{h}^{j},a_{h}^{j})\\}_{j=1}^{\\tau}\\cup\\{s_{h+1}^{j}\\}_{j=1}^{\\tau-1})$ .Since $V_{H+1}^{\\star,\\rho}$ independent of $\\mathcal{D}$ and is upper bounded by $H$ , thus we have $\\eta_{H}^{\\tau}([V_{H+1}^{\\star,\\rho}]_{\\alpha_{i}})|\\mathcal{F}_{\\tau-1,H}$ is mean zero, i.e., $\\mathbb{E}[\\eta_{H}^{\\tau}([V_{H+1}^{\\star,\\rho}]_{\\alpha_{i}})|\\mathcal{F}_{\\tau-1,H}]=0$ and $H$ -subGaussian. By Lemma I.1, for any fixed index $i\\in[d]$ with probability at least $1-\\delta/2d H^{2}$ , we have ", "page_idx": 27}, {"type": "equation", "text": "$$\n\\Big\\|\\sum_{\\tau=1}^{K}\\phi_{H}^{\\tau}\\eta_{H}^{\\tau}\\big([V_{H+1}^{\\star,\\rho}]_{\\alpha_{i}}\\big)\\Big\\|_{\\Lambda_{h}^{-1}}^{2}\\le2H^{2}\\log\\Big(\\frac{2d H^{2}\\operatorname*{det}(\\mathbf{A}_{h})^{1/2}}{\\delta\\operatorname*{det}(\\lambda\\mathbf{I})^{1/2}}\\Big).\n$$", "text_format": "latex", "page_idx": 27}, {"type": "text", "text": "By the proof of Lemma B.2 in [15], we know $\\operatorname*{det}(\\mathbf{A}_{h})\\leq(\\lambda+K)^{d}$ Thus, we have ", "page_idx": 27}, {"type": "equation", "text": "$$\n\\Big\\|\\sum_{\\tau=1}^{K}\\phi_{H}^{\\tau}\\eta_{H}^{\\tau}\\big([V_{H+1}^{\\star,\\rho}]_{\\alpha_{i}}\\big)\\Big\\|_{\\Lambda_{h}^{-1}}^{2}\\le2H^{2}\\Big(\\frac{d}{2}\\log\\frac{\\lambda+K}{\\lambda}+\\log\\frac{2d H^{2}}{\\delta}\\Big)\\le d H^{2}\\log\\frac{2d H^{2}K}{\\delta}.\n$$", "text_format": "latex", "page_idx": 27}, {"type": "text", "text": "Then by a union bound over $i\\in[d]$ , with probability at least $1-\\delta/2H^{2}$ , we have ", "page_idx": 27}, {"type": "equation", "text": "$$\n\\ddot{\\mathrm{ii}}\\leq\\sqrt{d}H\\sqrt{\\iota}\\sum_{i=1}^{d}\\|\\phi_{i}(s,a)\\mathbf{1}_{i}\\|_{\\mathbf{A}_{h}^{-1}},\n$$", "text_format": "latex", "page_idx": 27}, {"type": "text", "text": "Wwhere $\\iota=\\log(2d H^{2}K/\\delta)\\geq1$ Gials forthe term iy by onstution we have $V_{H+1}^{\\star,\\rho}=\\widehat{V}_{H+1}^{\\rho}=0$ with probability 1. Thus, we trivially have ", "page_idx": 27}, {"type": "equation", "text": "$$\n\\mathrm{iv}\\leq\\sqrt{d}H\\sqrt{\\iota}\\sum_{i=1}^{d}\\|\\phi_{i}(s,a)\\mathbf{1}_{i}\\|_{\\mathbf{A}_{h}^{-1}}.\n$$", "text_format": "latex", "page_idx": 27}, {"type": "text", "text": "Combining (G.8), (G.9) and (G.10), for all $(s,a)\\in S\\times A$ , with probability at least $1-\\delta/2H^{2}$ we have ", "page_idx": 27}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\Bigm\\lvert\\operatorname*{inf}_{P_{H}(\\cdot\\vert s,a)\\in\\mathcal{U}_{H}^{\\rho}(s,a;\\mu_{H,i}^{0})}\\bigl[\\mathbb{P}_{H}\\widehat{V}_{H+1}^{\\rho}](s,a)-\\widehat{\\operatorname*{inf}_{P_{H}(\\cdot\\vert s,a)\\in\\mathcal{U}_{H}^{\\rho}(s,a;\\mu_{H,i}^{0})}}\\bigl[\\mathbb{P}_{H}\\widehat{V}_{H+1}^{\\rho}](s,a)\\Big\\rvert}\\\\ &{\\leq4\\sqrt{d}H\\sqrt{l}\\displaystyle\\sum_{i=1}^{d}\\|\\phi_{i}(s,a)\\mathbf{1}_{i}\\|_{\\mathbf{A}_{h}^{-1}}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 27}, {"type": "text", "text": "Thus, we define $\\begin{array}{r}{\\Gamma_{H}(s,a)\\::=\\:4\\sqrt{d}H\\sqrt{\\iota}\\sum_{i=1}^{d}\\|\\phi_{i}(s,a)\\mathbf{1}_{i}\\|_{\\mathbf{\\Lambda}_{h}^{-1}}}\\end{array}$ . By the definition of $\\widehat{Q}_{H}^{\\rho}(s,a)$ in Algorithm 1, we have ", "page_idx": 27}, {"type": "equation", "text": "$$\n\\widehat{Q}_{H}^{\\rho}(s,a)=\\left\\{r_{H}(s,a)-\\Gamma_{H}(s,a)\\right\\}_{[0,1]}\\leq r_{H}(s,a)=Q_{H}^{\\star,\\rho}(s,a),\n$$", "text_format": "latex", "page_idx": 27}, {"type": "text", "text": "which implies that a pessimistic estimation is achieved at step $H$ ,i.e., $V_{H}^{\\star,\\rho}(s)\\geq\\widehat{V}_{H}^{\\rho}(s),\\forall s\\in\\mathcal{S}.$ Next, we study $V_{H}^{\\star,\\rho}(s)-\\widehat V_{H}^{\\rho}(s)$ . The intuition is that given the estimation error bound in (G.11), with suficient data, the difference between $V_{H}^{\\star,\\rho}(s)$ and $\\widehat{V}_{H}^{\\rho}(s)$ should be small Specifically, we have ", "page_idx": 28}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{V_{H}^{\\star,\\rho}(s)-\\widehat{V}_{H}^{\\rho}(s)=Q_{H}^{\\star,\\rho}(s,\\pi_{H}^{\\star}(s))-\\widehat{Q}_{H}^{\\rho}(s,\\pi_{H}^{\\star}(s))+\\widehat{Q}_{H}^{\\rho}(s,\\pi_{H}^{\\star}(s))-\\widehat{Q}_{H}^{\\rho}(s,\\widehat{\\pi}(s))}\\\\ &{\\qquad\\qquad\\qquad\\leq r_{H}(s,\\pi_{H}^{\\star}(s))+\\operatorname*{inf}_{\\substack{P_{H}(\\cdot\\vert s,a)\\in\\mathcal{U}_{H}^{\\rho}(s,a;\\mu_{H,i}^{0})}}[\\mathbb{P}_{H}\\widehat{V}_{H+1}^{\\rho}](s,a)-}\\\\ &{\\qquad\\qquad\\qquad r_{H}(s,\\pi_{H}^{\\star}(s))-\\operatorname*{inf}_{\\substack{P_{H}(\\cdot\\vert s,a)\\in\\mathcal{U}_{H}^{\\rho}(s,a;\\mu_{H,i}^{0})}}[\\mathbb{P}_{H}\\widehat{V}_{H+1}^{\\rho}](s,a)+\\Gamma_{H}(s,\\pi_{H}^{\\star}(s))}\\end{array}\n$$", "text_format": "latex", "page_idx": 28}, {"type": "equation", "text": "$$\n\\leq2\\Gamma_{H}{\\bigl(}s,\\pi_{H}^{\\star}(s){\\bigr)},\n$$", "text_format": "latex", "page_idx": 28}, {"type": "text", "text": "where (G.12) holds by the robust Bellman equation (3.1) and the fact that $\\widehat{Q}_{H}^{\\rho}(s,\\pi_{H}^{\\star}(s))\\:-\\:$ $\\widehat{Q}_{H}^{\\rho}(s,\\widehat{\\pi}(s))\\,\\leq\\,0$ . Then we bound the pessimism term $\\Gamma_{H}(s,a)$ in terms of the sample size $K$ By Lemma I.3, when $K\\geq\\operatorname*{max}\\{512\\log(2d H^{2}/\\delta)/\\kappa^{2},4/\\kappa\\}$ with probability at least $1-\\delta/2H^{2}$ \uff0c we have ", "page_idx": 28}, {"type": "equation", "text": "$$\n2\\Gamma_{H}(s,a)=8\\sqrt{d}H\\sqrt{l}\\sum_{i=1}^{d}\\|\\phi_{i}(s,a)\\mathbf{1}_{i}\\|_{\\mathbf{A}_{h}^{-1}}\\leq\\frac{16\\sqrt{d}H\\sqrt{l}}{\\sqrt{K}}\\sum_{i=1}^{d}\\phi_{i}(s,a)\\big(\\tilde{\\mathbf{A}}_{H}^{-1}\\big)_{i i}^{1/2},\n$$", "text_format": "latex", "page_idx": 28}, {"type": "text", "text": "Where $\\tilde{\\mathbf{A}}_{H}=\\mathbb{E}^{\\pi^{b},P^{0}}[\\phi(s_{H},a_{H})\\phi(s_{H},a_{H})^{\\top}]$ Note that forany positivedfinite matrix $A$ we know $\\lambda_{\\operatorname*{min}}(A)\\leq A_{i i}\\leq\\lambda_{\\operatorname*{max}}^{\\cdot}(A)$ . Thus, by Assumption 4.3, we have ", "page_idx": 28}, {"type": "equation", "text": "$$\n2\\Gamma_{H}(s,a)\\leq\\frac{16\\sqrt{d}H\\cdot1\\sqrt{\\iota}}{\\sqrt{K\\kappa}}:=R_{H}.\n$$", "text_format": "latex", "page_idx": 28}, {"type": "text", "text": "To summarize, we define the event ", "page_idx": 28}, {"type": "equation", "text": "$$\n\\mathcal{E}_{H}=\\{0\\leq V_{H}^{\\star,\\rho}(s)-\\widehat{V}_{H}^{\\rho}(s)\\leq R_{H},\\forall s\\in\\mathcal{S}\\}.\n$$", "text_format": "latex", "page_idx": 28}, {"type": "text", "text": "Then by a union bound over (G.11) and (G.13), we know $\\mathcal{E}_{H}$ holds with probability at least $1-\\delta_{H}=$ $1-\\delta/\\dot{H}^{2}$ . This concludes the proof of the base case. ", "page_idx": 28}, {"type": "text", "text": "Inductive Hypothesis.  Suppose with probability at least $1-\\delta_{h+1}$ ,wehave ", "page_idx": 28}, {"type": "equation", "text": "$$\n\\begin{array}{r l r}&{\\Bigm\\lvert\\operatorname*{inf}_{P_{h+1}(\\cdot\\vert s,a)\\in\\mathcal{U}_{h+1}^{\\rho}(s,a;\\mu_{h+1,i}^{0})}\\lVert\\mathcal{P}_{h+1}\\widehat{V}_{h+2}^{\\rho}\\bigr\\rvert(s,a)-\\underset{P_{h+1}(\\cdot\\vert s,a)\\in\\mathcal{U}_{h+1}^{\\rho}(s,a;\\mu_{h+1,i}^{0})}{\\widehat{\\operatorname*{inf}}}\\big[\\mathbb{P}_{h+1}\\widehat{V}_{h+2}^{\\rho}\\bigr](s,a)\\Bigm\\rvert}\\\\ &{\\leq4\\sqrt{d}H\\sqrt{l}\\underset{i=1}{\\overset{d}{\\sum}}\\lVert\\phi_{i}(s,a)\\mathbf{1}_{i}\\rVert_{\\Lambda_{h+1}^{-1}}:=\\Gamma_{h+1}(s,a),}&{(\\mathrm{G.1}-\\mathrm{G.~})}\\end{array}\n$$", "text_format": "latex", "page_idx": 28}, {"type": "text", "text": "and ", "page_idx": 28}, {"type": "equation", "text": "$$\n\\mathcal{E}_{h+1}=\\big\\{0\\leq V_{h+1}^{\\star}(s)-\\widehat{V}_{h+1}(s)\\leq R_{h+1}:=\\frac{16\\sqrt{d}H(H-h)\\sqrt{\\iota}}{\\sqrt{K\\kappa}},\\forall s\\in\\mathcal{S}\\big\\}.\n$$", "text_format": "latex", "page_idx": 28}, {"type": "text", "text": "Inductive Step. Next, we establish the result for step $h$ . First, terms i, i and i at step $h$ canbe similarly bounded as in the base case, i.e., we have ", "page_idx": 28}, {"type": "equation", "text": "$$\n\\mathrm{i+ii+iii}\\le3\\sqrt{d}H\\sqrt{\\iota}\\sum_{i=1}^{d}\\|\\phi_{i}(s,a)\\mathbf{1}_{i}\\|_{\\mathbf{A}_{h}^{-1}},\n$$", "text_format": "latex", "page_idx": 28}, {"type": "text", "text": "with probability at least $1-\\delta/3H^{2}$ . It remains to bound the term iv and ensure it is non-dominating. Here, we ned toda with the temporl dependeney, as $[\\widehat{V}_{h+1}^{\\rho}(s)]_{\\alpha}-[V_{h+1}^{\\star,\\rho}(s)]_{\\alpha}$ iscorelate to $\\{(s_{h}^{\\tau},a_{h}^{\\tau},s_{h+1}^{\\tau})\\}_{\\tau=1}^{K}$ , thus we need a uniform concentration argument. Consider the function class ", "page_idx": 28}, {"type": "text", "text": "where $\\begin{array}{r}{V_{h}(s;\\theta,\\beta,\\Sigma)=\\operatorname*{max}_{a\\in A}\\{\\phi(s,a)^{\\top}\\theta-\\beta\\sum_{i=1}^{d}\\sqrt{\\phi_{i}(s,a)\\mathbf{1}_{i}^{\\top}\\Sigma^{-1}\\phi_{i}(s,a)\\mathbf{1}_{i}}\\}_{[0,H-h+1]}.}\\end{array}$ For simplicity, we denote $f_{\\alpha_{i}}(s):=[\\widehat{V}_{h+1}^{\\rho}(s)]_{\\alpha_{i}}-[V_{h+1}^{\\star,\\rho}(s)]_{\\alpha_{i}}$ , then $f_{\\alpha_{i}}\\in\\mathcal{F}_{h+1}(\\alpha_{i})$ , where ", "page_idx": 29}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathcal{F}_{h+1}(\\alpha):=\\big\\{[\\widehat{V}_{h+1}^{\\rho}(s)]_{\\alpha}-[V_{h+1}^{\\star,\\rho}(s)]_{\\alpha}:\\widehat{V}_{h+1}^{\\rho}(s)\\in\\mathcal{V}_{h+1}(D_{0},B_{0},\\lambda)\\big\\}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 29}, {"type": "text", "text": "Note that for any fixed $\\alpha$ , the covering number of ${\\mathcal{F}}_{h+1}(\\alpha)$ is the same as that of $\\mathcal{V}_{h}(D_{0},B_{0},\\lambda)$ By Lemma G.2, we have $D_{0}=H\\sqrt{K d/\\lambda}$ . By the induction assumption (G.14), we have $B_{0}=$ $4\\sqrt{d}H\\sqrt{\\iota}$ . Denote the $\\epsilon$ -covering of the interval $[0,H]$ with respect to the distance $\\mathrm{dist}(\\alpha_{1},\\alpha_{2})=$ $|\\alpha_{1}-\\alpha_{2}|$ as $\\mathcal{N}_{[0,H]}(\\epsilon)$ , and its $\\epsilon$ -covering number as $|\\mathcal{N}_{[0,H]}(\\epsilon)|$ . For each $\\alpha\\in[0,H]$ , we can find $\\alpha_{\\epsilon}\\,\\in\\,\\mathcal{N}_{[0,H]}(\\epsilon)$ such that $|\\alpha-\\alpha_{\\epsilon}|\\,\\le\\,\\epsilon$ . For any fixed $\\alpha\\,\\in\\,[0,H]$ , we denote the $\\epsilon$ -covering of ${\\mathcal{F}}_{h+1}(\\alpha)$ with respect to the distance $\\operatorname{dist}(f_{1},f_{2})\\,=\\,\\operatorname*{sup}_{x}|f_{1}(x)-f_{2}(x)|$ as $\\mathcal{N}_{h+1}(\\epsilon)$ (short for $\\mathcal{N}_{h+1}(\\epsilon;D,B,\\lambda))$ and its $\\epsilon$ -covering number as $|\\mathcal{N}_{h+1}(\\epsilon)|$ . For each $f_{\\alpha}\\in\\mathcal{F}_{h+1}(\\alpha)$ , we can find $f_{\\alpha}^{\\epsilon}\\in\\mathcal{N}_{h+1}(\\epsilon)$ such that $\\mathrm{sup}_{s}\\,|f_{\\alpha}(s)-f_{\\alpha}^{\\epsilon}(s)|\\leq\\dot{\\epsilon}$ It follows that ", "page_idx": 29}, {"type": "equation", "text": "$$\n\\begin{array}{l}{\\displaystyle\\Big|\\displaystyle\\Big|\\sum_{k=1}^{K}\\phi_{h}^{\\tau}\\eta_{h}^{\\tau}(f_{\\alpha_{i}})\\Big|\\Big|_{\\Lambda_{h}^{-1}}^{2}\\cdot\\mathbb{1}\\left\\{||f_{\\alpha_{i}}||_{\\infty}\\le R_{h+1}\\right\\}}\\\\ {\\displaystyle\\le2\\Big|\\displaystyle\\sum_{\\tau=1}^{K}\\phi_{h}^{\\tau}\\eta_{h}^{\\tau}(f_{\\alpha_{i}})\\Big|\\displaystyle\\Big|_{\\Lambda_{h}^{-1}}^{2}\\cdot\\mathbb{1}\\left\\{||f_{\\alpha_{i\\epsilon}}||_{\\infty}\\le R_{h+1}+\\epsilon\\right\\}+2\\Big|\\displaystyle\\sum_{k=1}^{K}\\phi_{h}^{\\tau}\\big(\\eta_{h}^{\\tau}(f_{\\alpha_{i}})-\\eta_{h}^{\\tau}(f_{\\alpha_{i\\epsilon}})\\big)\\Big|\\displaystyle\\Big|_{\\Lambda_{h}^{-1}}^{2}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 29}, {"type": "text", "text": "Note that ", "page_idx": 29}, {"type": "equation", "text": "$$\n2\\Big|\\Big|\\sum_{k=1}^{K}\\phi_{h}^{\\tau}\\big(\\eta_{h}^{\\tau}(f_{\\alpha_{i}})-\\eta_{h}^{\\tau}(f_{\\alpha_{i\\epsilon}})\\big)\\Big|\\Big|_{\\Lambda_{h}^{-1}}^{2}\\le2\\epsilon^{2}\\sum_{\\tau,\\tau^{\\prime}=1}^{K}\\big|\\phi_{h}^{\\tau}\\Lambda_{h}^{-1}\\phi_{h}^{\\tau^{\\prime}}\\big|\\le2\\epsilon^{2}K^{2}/\\lambda.\n$$", "text_format": "latex", "page_idx": 29}, {"type": "text", "text": "Then we have ", "page_idx": 29}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\Big|\\displaystyle\\Big|\\displaystyle\\sum_{k=1}^{K}\\phi_{h}^{\\tau}\\eta_{h}^{\\tau}(f_{\\alpha_{i}})\\Big|\\displaystyle\\Big|_{\\Lambda_{h}^{-1}}^{2}\\cdot\\mathbf{I}\\Big\\{\\|f_{\\alpha_{i}}\\|_{\\infty}\\leq R_{h+1}\\Big\\}}\\\\ &{\\leq4\\Big\\|\\displaystyle\\sum_{\\tau=1}^{K}\\phi_{h}^{\\tau}\\eta_{h}^{\\tau}(f_{\\alpha_{i}}^{\\epsilon})\\Big\\|_{\\Lambda_{h}^{-1}}^{2}\\cdot\\mathbf{I\\{\\|f_{\\alpha_{i}}^{\\epsilon}\\|_{\\infty}\\leq R_{h+1}+2\\epsilon\\}}}\\\\ &{\\quad+4\\Big\\|\\displaystyle\\sum_{k=1}^{K}\\phi_{h}^{\\tau}(\\eta_{h}^{\\tau}(f_{\\alpha_{i}})-\\eta_{h}^{\\tau}(f_{\\alpha_{i}}^{\\epsilon}))\\Big\\|_{\\Lambda_{h}^{-1}}^{2}+\\displaystyle\\frac{2\\epsilon^{2}K^{2}}{\\lambda}}\\\\ &{\\leq4\\Big\\|\\displaystyle\\sum_{\\tau=1}^{K}\\phi_{h}^{\\tau}\\eta_{h}^{\\tau}(f_{\\alpha_{i}}^{\\epsilon})\\Big\\|_{\\Lambda_{h}^{-1}}^{2}\\cdot\\mathbf{I\\{\\|f_{\\alpha_{i}}^{\\epsilon}\\|_{\\infty}\\leq R_{h+1}+2\\epsilon\\}}+\\displaystyle\\frac{6\\epsilon^{2}K^{2}}{\\lambda},}\\end{array}\n$$", "text_format": "latex", "page_idx": 29}, {"type": "text", "text": "where the last inequality holds by the fact that ", "page_idx": 29}, {"type": "equation", "text": "$$\n4\\bigg|\\bigg|\\sum_{k=1}^{K}\\phi_{h}^{\\tau}\\big(\\eta_{h}^{\\tau}(f_{\\alpha_{i\\epsilon}})-\\eta_{h}^{\\tau}(f_{\\alpha_{i\\epsilon}}^{\\epsilon})\\big)\\bigg|\\bigg|_{\\Lambda_{h}^{-1}}^{2}\\le4\\epsilon^{2}\\sum_{\\tau,\\tau^{\\prime}=1}^{K}\\big|\\phi_{h}^{\\tau}\\Lambda_{h}^{-1}\\phi_{h}^{\\tau^{\\prime}}\\big|\\le4\\epsilon^{2}K^{2}/\\lambda.\n$$", "text_format": "latex", "page_idx": 29}, {"type": "text", "text": "With a union bound over $\\mathcal{N}_{h+1}(\\epsilon)$ and $\\mathcal{N}_{[0,H]}(\\epsilon)$ and by Lemma G.3, we have ", "page_idx": 29}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{P}\\Bigg\\{\\underset{\\alpha_{i_{\\epsilon}}\\in\\mathcal{N}_{[0,H]}(\\epsilon)}{\\operatorname*{sup}}\\Big\\|\\sum_{\\tau=1}^{K}\\phi_{h}^{\\tau}\\eta_{h}^{\\tau}(f_{\\alpha_{i\\epsilon}}^{\\epsilon})\\Big\\|_{\\Lambda_{h}^{-1}}^{2}\\cdot\\mathbb{1}\\left\\{\\|f_{\\alpha_{i_{\\epsilon}}}^{\\epsilon}\\|_{\\infty}\\leq R_{h+1}+2\\epsilon\\right\\}}\\\\ &{\\quad\\times\\left(R_{h+1}+2\\epsilon\\right)^{2}\\!\\left(2\\log\\frac{3d H^{2}|\\mathcal{N}_{h+1}(\\epsilon)||\\mathcal{N}_{[0,H]}(\\epsilon)|}{\\delta}+d\\log\\Big(1+\\frac{K}{\\lambda}\\Big)\\right)\\Bigg\\}\\leq\\frac{\\delta}{3d H^{2}}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 29}, {"type": "text", "text": "Then with probability at least $1-\\delta/3d H^{2}$ , for all $f_{\\alpha_{i}}\\in\\mathcal{F}_{h+1}(\\alpha_{i})$ , we have ", "page_idx": 29}, {"type": "equation", "text": "$$\n\\Big\\|\\sum_{k=1}^{K}\\phi_{h}^{\\tau}\\eta_{h}^{\\tau}(f_{\\alpha_{i}})\\Big\\|_{\\mathbf{A}_{h}^{-1}}^{2}\\cdot\\mathbb{1}\\left\\{\\|f_{\\alpha_{i}}\\|_{\\infty}\\leq R_{h+1}\\right\\}\n$$", "text_format": "latex", "page_idx": 29}, {"type": "equation", "text": "$$\n\\leq4\\operatorname*{inf}_{\\epsilon>0}\\Big\\{\\big(R_{h+1}+2\\epsilon\\big)^{2}\\Big(2\\log\\Big(\\frac{3d H^{2}|\\mathcal{N}_{h+1}(\\epsilon)||\\mathcal{N}_{[0,H]}(\\epsilon)|}{\\delta}\\Big)+d\\log\\Big(1+\\frac{K}{\\lambda}\\Big)\\Big)+\\frac{6\\epsilon^{2}K^{2}}{\\lambda}\\Big\\}.\n$$", "text_format": "latex", "page_idx": 30}, {"type": "text", "text": "By Lemma G.4 and Lemma G.5 together with $D_{0}=H\\sqrt{K d/\\lambda}$ and $B_{0}=4\\sqrt{d}H\\sqrt{\\iota}$ setting $\\epsilon=$ $d^{3/2}H^{2}/(K^{3/2}\\sqrt{\\kappa})$ and $K\\geq\\sqrt{d}H/(32\\sqrt{\\kappa}\\iota)$ , we have $\\log|\\mathcal{N}_{h+1}(\\epsilon)|\\le2d^{2}\\log(512K^{3}\\iota/d^{3/2}H^{2})$ Thus, we have ", "page_idx": 30}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\Big\\|\\displaystyle\\sum_{k=1}^{K}\\phi_{h}^{\\tau}\\eta_{h}^{\\tau}(f_{\\alpha_{i}})\\Big\\|_{\\Lambda_{h}^{-1}}^{2}\\cdot\\mathbb{1}\\left\\{\\|f_{\\alpha_{i}}\\|_{\\infty}\\leq R_{h+1}\\right\\}\\leq\\displaystyle\\frac{512d H^{4}\\iota}{K\\kappa}\\Big(2\\log\\displaystyle\\frac{2d H^{2}}{\\delta}+4d^{2}\\log\\displaystyle\\frac{512K^{3}\\iota}{d^{3/2}H^{2}}\\Big)}&{}\\\\ {\\leq\\displaystyle\\frac{20480d^{3}H^{4}\\iota^{2}}{K\\kappa}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 30}, {"type": "text", "text": "Then, with a union bound over $i\\in[d]$ , we have ", "page_idx": 30}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{P}\\bigg(\\underset{i\\in[d]}{\\operatorname*{sup}}\\bigg|\\bigg|\\sum_{\\tau=1}^{K}\\phi_{h}^{\\tau}\\eta_{h}^{\\tau}\\big([\\widehat{V}_{h+1}^{\\rho}]_{\\alpha_{i}}-[V_{h+1}^{\\star,\\rho}]_{\\alpha_{i}}\\big)\\bigg|_{\\boldsymbol{\\Lambda}_{h}^{-1}}>\\frac{143d^{3/2}H^{2}l}{\\sqrt{K\\kappa}}\\bigg)}\\\\ &{\\leq\\mathbb{P}\\bigg(\\underset{i\\in[d]}{\\operatorname*{sup}}\\bigg|\\bigg|\\sum_{\\tau=1}^{K}\\phi_{h}^{\\tau}\\eta_{h}^{\\tau}\\big([\\widehat{V}_{h+1}^{\\rho}]_{\\alpha_{i}}-[V_{h+1}^{\\star,\\rho}]_{\\alpha_{i}}\\big)\\bigg|_{\\boldsymbol{\\Lambda}_{h}^{-1}}\\,\\mathbb{I}\\,\\big\\{\\big\\|[\\widehat{V}_{h+1}^{\\rho}]_{\\alpha_{i}}-[V_{h+1}^{\\star,\\rho}]_{\\alpha_{i}}\\big\\|_{\\infty}\\leq R_{h+1}\\big\\}}\\\\ &{\\quad>\\frac{143d^{3/2}H^{2}l}{\\sqrt{K\\kappa}}\\bigg)+\\mathbb{P}\\big(\\mathbb{I}\\,\\big\\{\\big\\|[\\widehat{V}_{h+1}^{\\rho}]_{\\alpha_{i}}-[V_{h+1}^{\\star,\\rho}]_{\\alpha_{i}}\\big\\|_{\\infty}>R_{h+1}\\big\\}\\big)}\\\\ &{\\leq\\frac{\\delta}{3H^{2}}+\\delta_{h+1},}\\end{array}\n$$", "text_format": "latex", "page_idx": 30}, {"type": "text", "text": "which implies with probability at least $1-\\delta/3H^{2}-\\delta_{h+1}$ , the term iv at step $h$ can be bounded as ", "page_idx": 30}, {"type": "equation", "text": "$$\n\\mathrm{iv}\\leq\\frac{143d^{3/2}H^{2}\\iota}{\\sqrt{K\\kappa}}\\sum_{i=1}^{d}\\|\\phi_{i}(s,a)\\mathbf{1}_{i}\\|_{\\mathbf{\\Lambda}_{h}^{-1}}.\n$$", "text_format": "latex", "page_idx": 30}, {"type": "text", "text": "Then by a union bound over (G.16) and (G.17),if $K>20449d^{2}H^{2}/\\kappa$ , then with probability at least $1-2\\delta\\dot{/}3H^{2}-\\delta_{h+1}$ wehave ", "page_idx": 30}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\Big|\\operatorname*{inf}_{P_{h}(\\cdot|s,a)\\in\\mathcal{U}_{h}^{\\rho}(s,a;\\mu_{h,i}^{0})}[\\mathbb{P}_{h}\\widehat{V}_{h+1}^{\\rho}](s,a)-\\underset{P_{h}(\\cdot|s,a)\\in\\mathcal{U}_{h}^{\\rho}(s,a;\\mu_{h,i}^{0})}{\\widehat{\\operatorname*{inf}}}[\\mathbb{P}_{h}\\widehat{V}_{h+1}^{\\rho}](s,a)\\Big|}\\\\ &{\\leq4\\sqrt{d}H\\sqrt{\\iota}\\displaystyle\\sum_{i=1}^{d}\\|\\phi_{i}(s,a)\\mathbf{1}_{i}\\|_{\\mathbf{A}_{h}^{-1}}:=\\Gamma_{h}(s,a).}\\end{array}\n$$", "text_format": "latex", "page_idx": 30}, {"type": "text", "text": "Further, when $K>\\operatorname*{max}\\{512\\log(3H^{2}/\\delta)/\\kappa^{2},4/\\kappa\\}$ , by Lemma I.3, with probability at least $1-$ $\\delta/3H^{2}$ ,we have ", "page_idx": 30}, {"type": "equation", "text": "$$\n\\Gamma_{h}(s,a)\\leq4\\sqrt{d}H\\sqrt{\\iota}\\sum_{i=1}^{d}\\|\\phi_{i}(s,a)\\mathbf{1}_{i}\\|_{\\mathbf{\\Lambda}_{h}^{-1}}\\leq\\frac{8\\sqrt{d}H\\sqrt{\\iota}}{\\sqrt{K\\kappa}}.\n$$", "text_format": "latex", "page_idx": 30}, {"type": "text", "text": "Then by a union bound over (G.18) and (G.19), under the event $\\mathcal{E}_{h+1}$ , with probability at least $1-\\delta/{\\dot{H}}^{2}-\\delta_{h+1}$ wehave ", "page_idx": 30}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{V_{h}^{\\star,\\rho}(s)-\\widehat{V}_{h}^{\\rho}(s)}\\\\ &{=Q_{h}^{\\star,\\rho}(s,\\pi^{\\star}(s))-\\widehat{Q}_{h}^{\\rho}(s,\\pi^{\\star}(s))+\\widehat{Q}_{h}^{\\rho}(s,\\pi^{\\star}(s))-\\widehat{Q}_{h}^{\\rho}(s,\\widehat{\\pi}(s))}\\\\ &{\\le_{\\smallskip\\widehat{P}_{h}(\\cdot\\vert s,a)\\in\\mathcal{U}_{h}^{\\ell}(s,a;\\mu_{h,i}^{\\sf*})}\\vert\\mathbb{D}_{h}V_{h+1}^{\\star,\\rho}\\vert(s,\\pi^{\\star}(s))-\\underbrace{\\widehat{\\mathrm{inf}}}_{\\smallskip\\displaystyle{P}_{h}(\\cdot\\vert s,a)\\in\\mathcal{U}_{h}^{\\ell}(s,a;\\mu_{h,i}^{\\sf*})}\\vert\\mathbb{P}_{h}\\widehat{V}_{h+1}^{\\rho}\\vert(s,a)+\\Gamma_{h}(s,\\pi^{\\star}(s))}\\\\ &{=\\operatorname*{inf}_{\\small{P}_{h}(\\cdot\\vert s,a)\\in\\mathcal{U}_{h}^{\\ell}(s,a;\\mu_{h,i}^{\\sf*})}\\vert\\mathbb{P}_{h}V_{h+1}^{\\star,\\rho}\\vert(s,\\pi^{\\star}(s))-\\underbrace{\\operatorname*{inf}_{h}^{\\dagger}(s,a;\\mu_{h,i}^{\\sf*})}_{\\smallskip\\displaystyle{P}_{h}(\\cdot\\vert s,a)\\in\\mathcal{U}_{h}^{\\ell}(s,a;\\mu_{h,i}^{\\sf*})}\\vert\\mathbb{P}_{h}\\widehat{V}_{h+1}^{\\rho}\\vert(s,\\pi^{\\star}(s))}\\\\ &{\\quad+\\underbrace{\\operatorname*{inf}}_{\\smallskip\\widehat{P}_{h}(\\cdot\\vert s,a)\\in\\mathcal{U}_{h}^{\\ell}(s,a;\\mu_{h,i}^{\\sf*})}\\vert\\mathbb{P}_{h}\\widehat{V}_{h+1}^{\\rho}\\vert(s,\\pi^{\\star}(s))-\\underbrace{\\operatorname*{inf}_{h}^{\\prime}\\widehat{\\mathrm{inf}}}_{\\smallskip\\displaystyle{P}_{h}(\\cdot\\vert s,a)\\in\\mathcal{U}_{h}^{\\ell}(s,a;\\mu_{h,i}^{\\sf*})}\\vert\\mathbb{P}_{h}\\widehat{V}_{h+1}^{\\rho}\\vert(s,a)+\\Gamma_{h \n$$", "text_format": "latex", "page_idx": 30}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\leq\\frac{16\\sqrt{d}H(H-h)\\sqrt{\\iota}}{\\sqrt{K\\kappa}}+\\frac{16\\sqrt{d}H\\sqrt{\\iota}}{\\sqrt{K\\kappa}}}\\\\ &{=\\frac{16\\sqrt{d}H(H-h+1)\\sqrt{\\iota}}{\\sqrt{K\\kappa}}:=R_{h},}\\end{array}\n$$", "text_format": "latex", "page_idx": 31}, {"type": "text", "text": "where (G.20) holds by the following argument ", "page_idx": 31}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\underset{P_{h}(\\cdot\\,\\vert s,a)\\in\\mathcal{U}_{h}^{\\rho}(s,a;\\mu_{h,i}^{0})}{\\operatorname*{inf}}[\\mathbb{P}_{h}V_{h+1}^{\\star,\\rho}](s,\\pi^{\\star}(s))-\\underset{P_{h}(\\cdot\\,\\vert s,a)\\in\\mathcal{U}_{h}^{\\rho}(s,a;\\mu_{h,i}^{0})}{\\operatorname*{inf}}[\\mathbb{P}_{h}\\widehat{V}_{h+1}^{\\rho}](s,\\pi^{\\star}(s))}\\\\ &{\\leq[\\widehat{\\mathbb{P}}_{h}V_{h+1}^{\\star,\\rho}](s,\\pi^{\\star}(s))-[\\widehat{\\mathbb{P}}_{h}\\widehat{V}_{h+1}^{\\rho}](s,\\pi^{\\star}(s))}\\\\ &{\\leq\\underset{s}{\\operatorname*{sup}}\\,\\vert{V}_{h+1}^{\\star,\\rho}(s)-\\widehat{V}_{h+1}^{\\rho}(s)\\vert}\\\\ &{\\leq R_{h+1},}\\end{array}\n$$", "text_format": "latex", "page_idx": 31}, {"type": "text", "text": "Wwhere $\\begin{array}{r}{\\hat{P}_{h}(\\cdot|s,a)=\\arg\\operatorname*{inf}_{P_{h}(\\cdot|s,a)\\in{\\mathcal U}_{h}^{\\rho}(s,a;{\\mu_{h,i}^{0}})}[{\\mathbb P}_{h}\\widehat V_{h+1}^{\\rho}](s,a),\\forall(s,a)\\in\\mathcal{S}\\times\\mathcal{A}}\\end{array}$ and (G.21) is due to the induction assumption (G.15). Finally, denote ", "page_idx": 31}, {"type": "equation", "text": "$$\n\\mathcal{E}_{h}=\\{0\\leq V_{h+1}^{\\star,\\rho}(s)-\\widehat{V}_{h+1}^{\\rho}(s)\\leq R_{h},\\forall s\\in\\mathcal{S}\\},\n$$", "text_format": "latex", "page_idx": 31}, {"type": "text", "text": "then we have $P(\\mathcal{E}_{h})\\leq\\delta_{h+1}+\\delta/H^{2}:=\\delta_{h}$ ", "page_idx": 31}, {"type": "text", "text": "Generalization. By induction and a union bound over $h\\in[H]$ ,setting ", "page_idx": 31}, {"type": "equation", "text": "$$\n\\Gamma_{h}(s,a)=4\\sqrt{d}H\\sqrt{\\imath}\\sum_{i=1}^{d}\\|\\phi_{i}(s,a)\\mathbf{1}_{i}\\|_{\\mathbf{\\Lambda}_{h}^{-1}},\n$$", "text_format": "latex", "page_idx": 31}, {"type": "text", "text": "then with probability at least $1-(\\delta/H^{2}+2\\delta/H^{2}+\\cdot\\cdot+H\\delta/H^{2})=1-d H(H+1)\\delta/2H^{2}>1-\\delta,$ for all $(s,a,h)\\in\\mathcal{S}\\times\\mathcal{A}\\times[H]$ wehave ", "page_idx": 31}, {"type": "equation", "text": "$$\n\\frac{\\operatorname*{inf}}{P_{h}(\\cdot|s,a)\\in{\\cal U}_{h}^{\\rho}(s,a;\\mu_{h,i}^{0})}\\big[\\mathbb{P}_{h}\\widehat{V}_{h+1}^{\\rho}|(s,a)-\\widehat{\\operatorname*{inf}_{\\substack{P_{h}(\\cdot|s,a)\\in{\\cal U}_{h}^{\\rho}(s,a;\\mu_{h,i}^{0})}}}[\\mathbb{P}_{h}\\widehat{V}_{h+1}^{\\rho}](s,a)\\big|\\leq\\Gamma_{h}(s,a).\n$$", "text_format": "latex", "page_idx": 31}, {"type": "text", "text": "This concludes the proof. ", "page_idx": 31}, {"type": "text", "text": "G.3Proof of Lemma E.1 ", "text_level": 1, "page_idx": 31}, {"type": "text", "text": "Proof. Note that the conditional variance estimation does not involve any element of model uncertainty, and thus the proof follows from Lemma 5 of [54]. Recall that we estimate $[\\mathbb{V}_{h}[V_{h+1}^{\\rho}]_{\\alpha}](s,a)$ basedon $\\mathcal{D}^{\\prime}$ as ", "page_idx": 31}, {"type": "equation", "text": "$$\n\\hat{\\sigma}_{h}^{2}(s,a;\\alpha)=\\operatorname*{max}\\Big\\{1,\\big[\\phi(s,a)^{\\top}\\tilde{\\beta}_{h,2}(\\alpha)\\big]_{[0,H^{2}]}-\\big[\\phi(s,a)^{\\top}\\tilde{\\beta}_{h,1}(\\alpha)\\big]_{[0,H]}^{2}-\\tilde{O}\\Big(\\frac{\\sqrt{d}H^{3}}{\\sqrt{K\\kappa}}\\Big)\\Big\\}.\n$$", "text_format": "latex", "page_idx": 31}, {"type": "text", "text": "Note that ", "page_idx": 31}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\big[\\phi(s,a)^{\\top}\\tilde{\\beta}_{h,2}(\\alpha)\\big]_{[0,H^{2}]}-\\big[\\phi(s,a)^{\\top}\\tilde{\\beta}_{h,1}(\\alpha)\\big]_{[0,H]}^{2}-\\big[\\mathbb{P}_{h}[\\widehat{V}_{h+1}^{'\\rho}]_{\\alpha}^{2}\\big](s,a)-\\big([\\mathbb{P}_{h}[\\widehat{V}_{h+1}^{'\\rho}]_{\\alpha}](s,a)\\big)^{2}\\Big|}\\\\ &{\\leq\\Big|\\big[\\phi(s,a)^{\\top}\\tilde{\\beta}_{h,2}(\\alpha)\\big]_{[0,H^{2}]}-\\big[\\mathbb{P}_{h}[\\widehat{V}_{h+1}^{'\\rho}]_{\\alpha}^{2}\\big](s,a)\\Big|+\\Big|\\big[\\phi(s,a)^{\\top}\\tilde{\\beta}_{h,1}(\\alpha)\\big]_{[0,H]}^{2}-\\big([\\mathbb{P}_{h}[\\widehat{V}_{h+1}^{'\\rho}]_{\\alpha}](s,a)\\big)^{2}}\\\\ &{\\leq\\underbrace{\\Big|\\phi(s,a)^{\\top}\\tilde{\\beta}_{h,2}(\\alpha)-[\\mathbb{P}_{h}[\\widehat{V}_{h+1}^{'\\rho}]_{\\alpha}^{2}](s,a)\\Big|}_{\\mathrm{i}}+2H\\underbrace{\\Big|\\phi(s,a)^{\\top}\\tilde{\\beta}_{h,1}(\\alpha)-[\\mathbb{P}_{h}[\\widehat{V}_{h+1}^{'\\rho}]_{\\alpha}]\\Big|}_{\\mathrm{ii}}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 31}, {"type": "text", "text": "Note that thetimtirnibthcefreularereresnwithte $[\\widehat{V}_{h+1}^{'\\rho}(s)]_{\\alpha}^{2}$ and $[\\widehat{V}_{h+1}^{'\\rho}(s)]_{\\alpha}$ , respectively. Thus,the analysis is standard and for simplicity we omit the details here and focus on the results: with probability at least $1-\\delta/2$ , we have $\\begin{array}{r l r}&{}&{\\Big|\\big[\\phi(s,a)^{\\top}\\tilde{\\beta}_{h,2}(\\alpha)\\big]_{[0,H^{2}]}-\\big[\\phi(s,a)^{\\top}\\tilde{\\beta}_{h,1}(\\alpha)\\big]_{[0,H]}^{2}-[{\\mathbb{P}}_{h}[\\widehat{V}_{h+1}^{\\prime\\prime}]_{\\alpha}^{2}](s,a)-([{\\mathbb{P}}_{h}[\\widehat{V}_{h+1}^{\\prime\\prime}]_{\\alpha}](s,a))^{2}\\Big|}\\\\ &{}&{\\textit{z-\\beta}(d H^{2}\\setminus\\mathrm{~\\alpha~})}\\end{array}$ (G.22) ", "page_idx": 31}, {"type": "text", "text": "Then by Theorem 4.4 and Lemma 1.3, for all $(s,a,h)\\,\\in\\,{\\mathcal{S}}\\times{\\mathcal{A}}\\times[H]$ , with probability at least $1-\\delta/{\\dot{2}}$ ,wehave ", "page_idx": 32}, {"type": "equation", "text": "$$\n\\begin{array}{r l r}&{\\vert\\left\\vert\\mathrm{Var}_{h}[\\widehat{V}_{h+1}^{\\prime\\prime}]_{\\alpha}\\right\\vert(s,a)-\\left\\lbrack\\mathrm{Var}_{h}[V_{h+1}^{\\star,\\rho}]_{\\alpha}\\right\\rbrack(s,a)\\big\\vert}&\\\\ &{\\leq\\left\\vert\\left\\lbrack\\mathbb{P}_{h}[\\widehat{V}_{h+1}^{\\prime\\prime}]_{\\alpha}^{2}\\right\\rbrack(s,a)-\\left\\lbrack\\mathbb{P}_{h}[V_{h+1}^{\\star,\\rho}]_{\\alpha}^{2}\\right\\rbrack(s,a)\\big\\vert+\\big\\vert\\left(\\left\\lbrack\\mathbb{P}_{h}[\\widehat{V}_{h+1}^{\\prime\\prime}]_{\\alpha}\\right\\rbrack(s,a)\\right)^{2}-\\left(\\left\\lbrack\\mathbb{P}_{h}[V_{h+1}^{\\star,\\rho}]_{\\alpha}\\right\\rbrack(s,a)\\right)^{2}\\big\\vert}&\\\\ &{\\leq2H\\left\\vert\\left\\lbrack\\mathbb{P}_{h}([\\widehat{V}_{h+1}^{\\rho}]_{\\alpha}-[V_{h+1}^{\\star,\\rho}]_{\\alpha})\\right\\rbrack(s,a)\\big\\vert+2H\\left\\lbrack\\mathbb{P}_{h}\\left([V_{h+1}^{\\star,\\rho}]_{\\alpha}-[V_{h+1}^{\\star,\\rho}]_{\\alpha}\\right)\\right\\rbrack(s,a)\\big\\vert}&\\\\ &{\\leq\\tilde{O}\\Big(\\frac{\\sqrt{d}H^{3}}{\\sqrt{K\\kappa}}\\Big).}&{\\mathrm{(G.2~}}\\end{array}\n$$", "text_format": "latex", "page_idx": 32}, {"type": "text", "text": "By (G.22) and (G.23) and a union bound, we know that with probability at least $1-\\delta$ wehave ", "page_idx": 32}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\Big|\\big[\\phi(s,a)^{\\top}\\tilde{\\beta}_{h,2}(\\alpha)\\big]_{[0,H^{2}]}-\\big[\\phi(s,a)^{\\top}\\tilde{\\beta}_{h,1}(\\alpha)\\big]_{[0,H]}^{2}-[\\mathrm{Var}_{h}[V_{h+1}^{\\star,\\rho}]_{\\alpha}](s,a)\\Big|}\\\\ &{\\leq\\Big|\\big[\\phi(s,a)^{\\top}\\tilde{\\beta}_{h,2}(\\alpha)\\big]_{[0,H^{2}]}-\\big[\\phi(s,a)^{\\top}\\tilde{\\beta}_{h,1}(\\alpha)\\big]_{[0,H]}^{2}-[\\mathrm{Var}_{h}[\\widehat{V}_{h+1}^{\\prime}]_{\\alpha}](s,a)\\Big|}\\\\ &{\\quad+\\left|[\\mathrm{Var}_{h}[\\widehat{V}_{h+1}^{\\prime\\rho}]_{\\alpha}](s,a)-[\\mathrm{Var}_{h}[V_{h+1}^{\\star,\\rho}]_{\\alpha}](s,a)\\right|}\\\\ &{\\leq\\tilde{O}\\Big(\\frac{d H^{3}}{\\sqrt{K\\kappa}}\\Big),}\\end{array}\n$$", "text_format": "latex", "page_idx": 32}, {"type": "text", "text": "which implies that ", "page_idx": 32}, {"type": "equation", "text": "$$\n\\bigl[\\phi(s,a)^{\\top}\\tilde{\\beta}_{h,2}(\\alpha)\\bigr]_{[0,H^{2}]}-\\bigl[\\phi(s,a)^{\\top}\\tilde{\\beta}_{h,1}(\\alpha)\\bigr]_{[0,H]}^{2}-\\tilde{O}\\Bigl(\\frac{d H^{3}}{\\sqrt{K\\kappa}}\\Bigr)\\leq[\\mathrm{Var}_{h}[V_{h+1}^{\\star,\\rho}]_{\\alpha}](s,a).\n$$", "text_format": "latex", "page_idx": 32}, {"type": "text", "text": "By the fact that the operator $\\operatorname*{min}\\{1,\\cdot\\}$ is order preserving, thus we have ", "page_idx": 32}, {"type": "equation", "text": "$$\n\\widehat{\\sigma}_{h}^{2}(s,a;\\alpha)\\leq[\\mathbb{V}_{h}[V_{h+1}^{\\star,\\rho}]_{\\alpha}](s,a).\n$$", "text_format": "latex", "page_idx": 32}, {"type": "text", "text": "Further, by the fact that the operator $\\operatorname*{min}\\{1,\\cdot\\}$ is a contraction map, (G.22) and (G.23), we have ", "page_idx": 32}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\widetilde{\\sigma}_{h}^{2}(s,a;\\alpha)-\\left[\\Psi_{h}[V_{h+1}^{\\star,p}]_{\\alpha}\\right](s,a)\\big|}\\\\ &{\\leq\\big|\\widehat{\\sigma}_{h}^{2}(s,a;\\alpha)-\\left[\\Psi_{h}[\\widehat{V}_{h+1}^{\\prime}]_{\\alpha}\\right](s,a)\\big|+\\big|\\left[\\Psi_{h}[\\widehat{V}_{h+1}^{\\prime}]_{\\alpha}\\right](s,a)-\\left[\\Psi_{h}[V_{h+1}^{\\star,\\rho}]_{\\alpha}\\right](s,a)\\big|}\\\\ &{\\leq\\Big|\\left[\\phi(s,a)^{\\top}\\widetilde{\\beta}_{h,2}(\\alpha)\\right]_{[0,H^{2}]}-\\left[\\phi(s,a)^{\\top}\\widetilde{\\beta}_{h,1}(\\alpha)\\right]_{[0,H]}^{2}-\\tilde{O}\\Big(\\frac{d H^{3}}{\\sqrt{K}}\\Big)-\\left[\\mathrm{Var}_{h}[\\widehat{V}_{h+1}^{\\prime}]_{\\alpha}\\right](s,a)\\Big|}\\\\ &{\\quad+\\left|\\left[\\mathrm{Var}_{h}[\\widehat{V}_{h+1}^{\\prime}]_{\\alpha}\\right](s,a)-\\left[\\mathrm{Var}_{h}[V_{h+1}^{\\star,\\rho}]_{\\alpha}\\right](s,a)\\right|}\\\\ &{\\leq\\tilde{\\mathcal{O}}\\Big(\\frac{d H^{2}}{\\sqrt{K}}\\Big)+\\tilde{\\mathcal{O}}\\Big(\\frac{d H^{3}}{\\sqrt{K}\\kappa}\\Big)+\\tilde{\\mathcal{O}}\\Big(\\frac{\\sqrt{d H^{3}}}{\\sqrt{K}\\kappa}\\Big)}\\\\ &{=\\tilde{\\mathcal{O}}\\Big(\\frac{d H^{3}}{\\sqrt{K}\\kappa}\\Big).}\\end{array}\n$$", "text_format": "latex", "page_idx": 32}, {"type": "text", "text": "This concludes the proof. ", "page_idx": 32}, {"type": "text", "text": "G.4 Proof of Lemma E.2 ", "text_level": 1, "page_idx": 32}, {"type": "text", "text": "Proof. Note that the reference-advantage decomposition is exactly the same as that in the proof of Lemma G.1, thus we have ", "page_idx": 32}, {"type": "text", "text": "$\\begin{array}{r l}&{\\underset{P_{h}(\\cdot\\,|s,a)\\in\\mathcal{U}_{h}^{\\rho}(s,a;\\mu_{h,i}^{0})}{\\operatorname*{inf}}[\\mathbb{P}_{h}\\widehat{V}_{h+1}^{\\rho}](s,a)-\\underset{P_{h}(\\cdot\\,|s,a)\\in\\mathcal{U}_{h}^{\\rho}(s,a;\\mu_{h,i}^{0})}{\\widehat{\\operatorname*{inf}}}[\\mathbb{P}_{h}\\widehat{V}_{h+1}^{\\rho}](s,a)}\\\\ &{\\leq\\displaystyle\\sum_{i=1}^{d}\\phi_{i}(s,a)\\mathbf{1}_{i}^{\\top}\\big(\\mathbb{E}^{\\mu_{h}^{0}}[V_{h+1}^{\\star,\\rho}(s)]_{\\alpha_{i}}-\\widehat{\\mathbb{E}}^{\\mu_{h}^{0}}[V_{h+1}^{\\star,\\rho}(s)]_{\\alpha_{i}}\\big)}\\end{array}$ reference uncertainty $+\\sum_{i=1}^{d}\\phi_{i}(s,a)\\mathbf{1}_{i}^{\\top}\\left(\\mathbb{E}^{\\mu_{h}^{o}}[[\\widehat{V}_{h+1}^{\\rho}(s)]_{\\alpha_{i}}-[V_{h+1}^{\\star,\\rho}(s)]_{\\alpha_{i}}\\right]-\\widehat{\\mathbb{E}}^{\\mu_{h}^{o}}[[\\widehat{V}_{h+1}^{\\rho}(s)]_{\\alpha_{i}}-[V_{h+1}^{\\star,\\rho}(s)]_{\\alpha_{i}}]\\right).$ ", "page_idx": 32}, {"type": "text", "text": "Next, we further decompose the reference uncertainty and the advantage uncertainty, respectively. ", "page_idx": 32}, {"type": "text", "text": "The Reference Uncertainty. Specifically, we have ", "page_idx": 33}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\frac{\\partial}{\\partial t}\\phi_{i}(s,a)_{1}^{\\top}\\left(\\mathbb{E}^{\\mu_{2}^{\\mu}}[V_{k+1}^{*,\\mu}(s)]_{\\mu_{1}}-\\widehat{\\mathbb{E}}^{\\mu_{2}^{\\mu}}[V_{k+1}^{*,\\mu}(s)]_{\\mu_{1}}\\right)}\\\\ &{=\\displaystyle\\sum_{i=1}^{d}\\phi_{i}(s,a)_{1}^{\\top}\\Big[\\left(\\mathbb{E}^{\\mu_{2}^{\\mu}}[V_{k+1}^{*,\\mu}(s)]_{\\mu_{1}}-\\Sigma_{k}^{\\mathbb{E}}(\\alpha_{1})\\sum_{r=1}^{D}\\frac{\\phi_{k}^{r}[P_{k}^{\\mu}|V_{k+1}^{*,\\mu}]_{\\mu_{1}}\\right)\\left(s_{k}^{r},a\\right)_{1}^{\\top}}{\\partial t_{1}^{\\beta}\\left(s,t^{*},\\alpha_{1}^{*}\\right)}}\\\\ &{\\quad+\\displaystyle\\sum_{i=1}^{d}\\left(\\alpha_{1}\\right)_{1}^{\\top}\\displaystyle\\sum_{s=1}^{d}\\phi_{i}^{r}\\frac{\\mathbb{E}^{\\mu_{2}^{\\mu}}[P_{k+1}^{*,\\mu}]_{\\mu_{1}}\\left[\\mathcal{S}_{\\mu_{2}}^{\\mu}(s)]_{\\mu_{2}}}{\\partial t_{1}^{\\beta}\\left(s,t^{*},\\alpha_{1}^{*}\\right)}-\\Sigma_{k}^{\\mathbb{E}}(\\alpha_{1})\\displaystyle\\sum_{r=1}^{d}\\frac{\\phi_{k}^{r}[P_{k+1}^{*,\\mu}(s)]_{\\mu_{1}}}{\\partial t_{1}^{\\beta}\\left(s,t^{*},\\alpha_{1}^{*}\\right)}}\\\\ &{=\\displaystyle\\lambda_{1}^{\\sum{d}}\\phi_{i}(s,a)_{1}^{\\top}\\Sigma_{k}^{-1}(\\alpha_{1})\\mathbb{E}^{\\mu_{2}^{\\mu}}[V_{k+1}^{*,\\mu}(s)]_{\\mu_{1}}+\\displaystyle\\sum_{s=1}^{d}\\phi_{i}(s,a)_{1}^{\\top}\\Sigma_{k}^{-1}(\\alpha_{1})\\displaystyle\\sum_{r=1}^{d}\\frac \n$$", "text_format": "latex", "page_idx": 33}, {"type": "text", "text": "The Advantage Uncertainty. Similar to the argument in decomposing the reference uncertainty, wehave ", "page_idx": 33}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\displaystyle\\sum_{i=1}^{d}\\phi_{i}(s,a)\\mathbf{1}_{i}^{\\top}\\big(\\mathbb{E}^{\\mu_{h}^{o}}[[\\widehat{V}_{h+1}^{\\rho}(s)]_{\\alpha_{i}}-[V_{h+1}^{\\star,\\rho}(s)]_{\\alpha_{i}}\\big]-\\widehat{\\mathbb{E}}^{\\mu_{h}^{o}}[[\\widehat{V}_{h+1}^{\\rho}(s)]_{\\alpha_{i}}-[V_{h+1}^{\\star,\\rho}(s)]_{\\alpha_{i}}\\big]\\big)}\\\\ &{\\leq\\displaystyle\\lambda\\sum_{i=1}^{d}\\|\\phi_{i}(s,a)\\mathbf{1}_{i}\\|_{\\Sigma_{h}^{-1}(\\alpha_{i})}\\Big\\|\\mathbb{E}^{\\mu_{h}^{o}}\\big[[\\widehat{V}_{h+1}^{\\rho}(s)]_{\\alpha_{i}}-[V_{h+1}^{\\star,\\rho}(s)]_{\\alpha_{i}}\\big]\\Big\\|_{\\Sigma_{h}^{-1}(\\alpha_{i})}}\\end{array}\n$$", "text_format": "latex", "page_idx": 33}, {"type": "equation", "text": "$$\n+\\sum_{i=1}^{d}\\|\\phi_{i}(s,a)\\mathbf{1}_{i}\\|_{\\Sigma_{h}^{-1}(\\alpha_{i})}\\Big\\|\\sum_{\\tau=1}^{K}\\frac{\\phi_{h}^{\\tau}\\eta_{h}^{\\tau}([\\widehat{V}_{h+1}^{\\rho}(s)]_{\\alpha_{i}}-[V_{h+1}^{\\star,\\rho}(s)]_{\\alpha_{i}})}{\\widehat{\\sigma}_{h}^{2}(s_{h}^{\\tau},a_{h}^{\\tau};\\alpha_{i})}\\Big\\|_{\\Sigma_{h}^{-1}(\\alpha_{i})}\\,.\n$$", "text_format": "latex", "page_idx": 33}, {"type": "text", "text": "Put terms i-iv together, we have ", "page_idx": 33}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\underset{\\gamma_{k}(\\cdot\\vert s,\\cdot)\\in\\mathbb{R}_{n}^{\\ell}(s,\\cdot)}{\\underbrace{\\mathrm{inf}}}[\\mathcal{\\mathbf{p}}_{k}\\hat{V}_{k+1}^{\\rho}](s,a)-\\underset{\\gamma_{k}(\\cdot\\vert s,a)\\in\\mathbb{R}_{n}^{\\ell}(s,\\cdot)}{\\underbrace{\\mathrm{inf}}}[\\hat{\\mathbf{p}}_{k}\\hat{V}_{k+1}^{\\rho}](s,a)}\\\\ &{\\leq\\underset{\\varepsilon=1}{\\underbrace{\\lambda\\sum_{i=1}^{d}\\|\\phi_{i}(s,a)\\mathbf{1}_{i}\\|_{\\mathbf{Z}_{h}^{-1}(\\alpha_{i})}\\|\\mathbb{E}^{\\rho_{k}^{\\rho_{\\varepsilon}}}\\{V_{k+1}^{\\rho,\\rho}(s)\\}_{\\alpha}\\|_{\\mathbf{Z}_{h}^{-1}(\\alpha_{i})}}}}\\\\ &{\\quad+\\underset{\\varepsilon=1}{\\underbrace{\\sum_{i=1}^{d}\\|\\phi_{i}(s,a)\\mathbf{1}_{i}\\|_{\\mathbf{Z}_{h}^{-1}(\\alpha_{i})}\\Big\\Vert\\sum_{r=1}^{K}\\frac{\\phi_{r}^{\\lambda}\\eta_{i}^{\\mathrm{in}}\\eta_{r}^{\\mathrm{in}}\\left\\{\\!\\!\\left[V_{k+1}^{\\rho,\\rho}(\\mathbf{l}_{i}^{\\star}\\!\\!-\\!\\!\\rho_{i})\\!\\right]_{\\alpha}\\!\\right\\}_{\\alpha}^{-1}(\\alpha_{i})}}}\\\\ &{\\quad+\\underset{\\varepsilon=1}{\\underbrace{\\lambda\\sum_{i=1}^{d}\\|\\phi_{i}(s,a)\\mathbf{1}_{i}\\|_{\\mathbf{Z}_{h}^{-1}(\\alpha_{i})}\\left\\|\\mathbb{E}^{\\rho_{k}^{\\theta_{\\varepsilon}}}\\left[\\hat{V}_{h+1}^{\\rho}(s)\\right]_{\\alpha}-\\left[V_{h+1}^{\\rho,\\rho}(s)\\right]_{\\alpha}\\right\\|_{\\mathbf{Z}_{h}^{-1}(\\alpha_{i})}}}}\\end{array}\n$$", "text_format": "latex", "page_idx": 33}, {"type": "equation", "text": "$$\n+\\sum_{i=1}^{d}\\|\\phi_{i}(s,a)\\mathbf{1}_{i}\\|_{\\Sigma_{h}^{-1}(\\alpha_{i})}\\Big\\|\\sum_{\\tau=1}^{K}\\frac{\\phi_{h}^{\\tau}\\eta_{h}^{\\tau}([\\widehat{V}_{h+1}^{\\rho}(s)]_{\\alpha_{i}}-[V_{h+1}^{\\star,\\rho}(s)]_{\\alpha_{i}})}{\\widehat{\\sigma}_{h}^{2}(s_{h}^{\\tau},a_{h}^{\\tau};\\alpha_{i})}\\Big\\|_{\\Sigma_{h}^{-1}(\\alpha_{i})}\\,.\n$$", "text_format": "latex", "page_idx": 33}, {"type": "text", "text": "By similar argument as Lemma G.1, we know there exist $\\{\\tilde{\\alpha}_{i}\\}_{i\\in[d]}$ such that ", "page_idx": 34}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{P_{\\mathrm{c}}(\\cdot,\\vert\\omega_{i})\\mathrm{id}_{4\\Gamma}^{\\mathrm{\\ell}}(\\omega,\\omega_{i}^{\\mathrm{o}},\\vert\\overline{{P}}_{k}^{\\prime}\\vert)(\\boldsymbol{s},\\boldsymbol{a})-\\underset{P_{k}\\in\\{s_{0}\\},\\forall\\overline{{\\omega}}}{\\prod}\\frac{\\sqrt{n}\\overline{{F}}_{k}^{\\prime}}{n+\\mathbf{1}(s)\\overline{{G}}_{k}^{\\prime}(\\omega,\\omega_{k}^{\\prime})}\\frac{\\left\\vert\\overline{{P}}_{k}^{\\prime}\\overline{{\\nu}}_{k}^{\\prime}\\right\\vert(\\boldsymbol{s},\\boldsymbol{a})\\right\\vert}{\\left\\vert\\mathbf{S}_{k}^{\\prime}\\right\\vert(\\boldsymbol{s},\\boldsymbol{a})}}\\\\ &{\\leq\\underset{\\omega=1}{\\overset{,}{\\sum}}\\left\\vert\\left\\vert\\Theta_{i}(s,\\omega_{i})\\right\\vert\\mathrm{i}\\mathrm{j}\\mathrm{S}_{k}^{\\prime}(\\boldsymbol{a}_{i k})\\right\\vert\\mathrm{E}_{k}^{\\prime\\prime}(\\boldsymbol{s},\\boldsymbol{a})\\left\\vert\\right\\vert_{s,1}^{2}\\mathrm{i}\\mathrm{),}}\\\\ &{\\ \\ \\ \\ \\ \\ \\ \\ \\frac{4}{\\sqrt{n}}\\left\\vert\\left\\vert\\phi_{i}(s,\\omega_{i})\\mathrm{I}_{\\Omega_{k}^{\\prime}}\\frac{1}{n+\\binom{\\lambda_{0}}{\\Gamma_{\\omega}}}\\right\\vert\\sum_{\\underline{{v}}=1}^{\\infty}\\frac{\\phi_{i}^{\\nu}\\overline{{v}}_{k}^{\\prime}(\\overline{{V}}_{k}^{\\prime}+\\mathbf{1}_{i k}^{\\prime})\\left\\vert\\mathbf{a}\\right\\vert}{\\phi_{i}^{\\lambda}\\overline{{v}}_{k}^{\\prime}(\\overline{{V}}_{k}^{\\prime},\\vec{a})\\left\\vert\\right\\vert_{s,1}^{2}}\\mathrm{i}\\right\\vert}\\\\ &{\\ \\ \\ \\ \\ \\ \\ \\ \\frac{4}{\\sqrt{n}}\\left\\vert\\phi_{i}(s,\\omega_{i})\\mathrm{I}_{\\Omega_{k}^{\\prime}}\\frac{1}{n+\\binom{\\lambda_{0}}{\\Gamma_{\\omega}}}\\right\\vert\\left\\vert\\phi_{i}^{\\varepsilon\\varepsilon}\\right\\vert\\left(\\widehat{V}_{k+1}^{\\prime}(s)\\right)\\mathrm{i}\\alpha_{i}-\\left[V_{k+1}^{\\prime\\prime}(s) \n$$", "text_format": "latex", "page_idx": 34}, {"type": "text", "text": "This concludes the proof. ", "page_idx": 34}, {"type": "text", "text": "G.5Proof of Lemma E.3 ", "text_level": 1, "page_idx": 34}, {"type": "text", "text": "Proof. By the robust bellman equation (3.1), we know ", "page_idx": 34}, {"type": "equation", "text": "$$\nV_{h}^{\\pi,\\rho}(s)=\\mathbb{E}_{a\\sim\\pi(\\cdot|s)}\\Big[r(s,a)+\\operatorname*{inf}_{\\substack{P_{h}(\\cdot|s,a)\\in\\mathcal{U}_{h}^{\\rho}(s,a;\\mu_{h}^{0})}}[\\mathbb{P}_{h}V_{h+1}^{\\pi,\\rho}](s,a)\\Big].\n$$", "text_format": "latex", "page_idx": 34}, {"type": "text", "text": "Then, we can trivially bound $\\operatorname*{max}_{s\\in\\mathcal{S}}V_{h}^{\\pi,\\rho}(s)$ as ", "page_idx": 34}, {"type": "equation", "text": "$$\n\\operatorname*{max}_{s\\in S}V_{h}^{\\pi,\\rho}(s)\\leq\\operatorname*{max}_{s,a}\\Big(1+\\operatorname*{inf}_{P_{h}(\\cdot\\vert s,a)\\in\\mathcal{U}_{h}^{\\rho}(s,a;\\mu_{h}^{0})}[\\mathbb{P}_{h}V_{h+1}^{\\pi,\\rho}](s,a)\\Big).\n$$", "text_format": "latex", "page_idx": 34}, {"type": "text", "text": "Further, by the definition of the $d$ -rectangular uncertainty set, we have ", "page_idx": 34}, {"type": "equation", "text": "$$\n\\operatorname*{inf}_{P_{h}(\\cdot\\,|s,a)\\in{\\mathscr U}_{h}^{\\rho}(s,a;\\mu_{h}^{0})}[{\\mathbb P}_{h}V_{h+1}^{\\pi,\\rho}](s,a)=\\sum_{i=1}^{d}\\phi_{i}(s,a)\\operatorname*{inf}_{\\mu_{h,i}\\in{\\mathscr U}_{h,i}^{\\rho}(\\mu_{h,i}^{0})}{\\mathbb E}_{s\\sim\\mu_{h,i}}[V_{h+1}^{\\pi,\\rho}(s)].\n$$", "text_format": "latex", "page_idx": 34}, {"type": "text", "text": "Denoting $s_{\\mathrm{max}}\\,=\\,\\mathrm{argmax}_{s\\in S}\\,V_{h+1}^{\\pi,\\rho}(s)$ and $s_{\\mathrm{min}}\\,=\\,\\mathrm{argmin}_{s\\in S}\\,V_{h+1}^{\\pi,\\rho}(s)$ , and for all $i\\,\\in\\,[d]$ we construct a distribution $\\check{\\mu}_{h,i}=(1-\\rho)\\mu_{h,i}+\\rho\\delta_{s_{\\mathrm{min}}}$ , where $\\delta_{x}$ is the Dirac Delta distribution with mass on $x$ . Note that $\\check{\\mu}_{h,i}\\in\\mathcal{U}_{h,i}^{\\rho}(\\mu_{h,i}^{0})$ , thus we have ", "page_idx": 34}, {"type": "equation", "text": "$$\n\\operatorname*{inf}_{\\substack{\\mu_{h,i}\\in\\mathcal{U}_{h,i}^{\\circ}(\\mu_{h,i}^{0})}}\\mathbb{E}_{s\\sim\\mu_{h,i}}[V_{h+1}^{\\pi,\\rho}(s)]\\leq\\mathbb{E}_{s\\sim\\tilde{\\mu}_{h,i}}[V_{h+1}^{\\pi,\\rho}(s)]\\leq(1-\\rho)\\operatorname*{max}_{s\\in\\mathcal{S}}V_{h+1}^{\\pi,\\rho}(s)+\\rho\\operatorname*{min}_{s}V_{h+1}^{\\pi,\\rho}(s).\n$$", "text_format": "latex", "page_idx": 34}, {"type": "text", "text": "Combining (G.25), (G.26) and (G.27), we have ", "page_idx": 34}, {"type": "equation", "text": "$$\n\\operatorname*{max}_{s\\in S}V_{h}^{\\pi,\\rho}(s)\\leq(1-\\rho)\\operatorname*{max}_{s\\in S}V_{h+1}^{\\pi,\\rho}(s)+\\rho\\operatorname*{min}_{s\\in S}V_{h+1}^{\\pi,\\rho}(s)+1.\n$$", "text_format": "latex", "page_idx": 34}, {"type": "text", "text": "On the other hand, by (G.24), we can trivially bound $\\operatorname*{min}_{s}V_{h}^{\\pi,\\rho}(s)$ as ", "page_idx": 34}, {"type": "equation", "text": "$$\n\\operatorname*{min}_{s}V_{h}^{\\pi,\\rho}(s)\\geq\\operatorname*{min}_{s,a}\\operatorname*{inf}_{P_{h}(\\cdot\\vert s,a)\\in\\mathcal{U}_{h}^{\\rho}(s,a;\\mu_{h}^{0})}[\\mathbb{P}_{h}V_{h+1}^{\\pi,\\rho}](s,a).\n$$", "text_format": "latex", "page_idx": 34}, {"type": "text", "text": "By the fact that ", "page_idx": 34}, {"type": "equation", "text": "$$\n\\operatorname*{inf}_{\\substack{\\mu_{h,i}\\in\\mathcal{U}_{h,i}^{\\rho}(\\mu_{h,i}^{0})}}\\mathbb{E}_{s\\sim\\mu_{h,i}}[V_{h+1}^{\\pi,\\rho}(s)]\\ge\\operatorname*{min}_{s\\in S}V_{h+1}^{\\pi,\\rho}(s),\n$$", "text_format": "latex", "page_idx": 34}, {"type": "text", "text": "combining (G.26), (G.29) and (G.30), we have ", "page_idx": 35}, {"type": "equation", "text": "$$\n\\operatorname*{min}_{s}V_{h}^{\\pi,\\rho}(s)\\geq\\operatorname*{min}_{s\\in S}V_{h+1}^{\\pi,\\rho}(s).\n$$", "text_format": "latex", "page_idx": 35}, {"type": "text", "text": "For any $h\\in[H]$ , by (G.28) and (G.31), we have ", "page_idx": 35}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\underset{s\\in S}{\\mathrm{max}}\\,V_{h}^{\\pi,\\rho}(s)-\\underset{s\\in S}{\\mathrm{min}}\\,V_{h}^{\\pi,\\rho}(s)}\\\\ &{\\leq1+(1-\\rho)\\underset{s\\in S}{\\mathrm{max}}\\,V_{h+1}^{\\pi,\\rho}(s)-\\underset{s\\in S}{\\mathrm{min}}\\,V_{h+1}^{\\pi,\\rho}(s)+\\rho\\underset{s\\in S}{\\mathrm{min}}\\,V_{h+1}^{\\pi,\\rho}(s)}\\\\ &{=1+(1-\\rho)\\big[\\underset{s\\in S}{\\mathrm{max}}\\,V_{h+1}^{\\pi,\\rho}(s)-\\underset{s\\in S}{\\mathrm{min}}\\,V_{h+1}^{\\pi,\\rho}(s)\\big].}\\end{array}\n$$", "text_format": "latex", "page_idx": 35}, {"type": "text", "text": "For step $H$ by the denition of the value function, we have $0\\leq V_{H}^{\\pi,\\rho}(s)\\leq1,\\forall s\\in\\mathcal{S}$ Applying (G.32) with $h=H-1$ leads to $\\begin{array}{r}{\\operatorname*{max}_{s\\in S}V_{H-1}^{\\pi,\\rho}(s)-\\operatorname*{min}_{s\\in S}V_{H-1}^{\\pi,\\rho}\\binom{s}{s}\\leq1+(1-\\rho)\\cdot1}\\end{array}$ . We finish the proof by recursively applying (G.32). \u53e3 ", "page_idx": 35}, {"type": "text", "text": "G.6Proof of Lemma F.1 ", "text_level": 1, "page_idx": 35}, {"type": "text", "text": "Proof. The proof of Lemma F.1 consists of the following two steps: ", "page_idx": 35}, {"type": "text", "text": "Step 1: lower bound the suboptimality by Hamming distance.For any $\\pmb{\\xi}\\in\\{-1,1\\}^{d H}$ ,denote $V_{\\xi}^{\\star,\\bar{\\rho}}(s)$ as the otimal robust valuefunction for theMDP instane $M_{\\xi}$ For any function $\\pi$ denote $\\bar{V_{\\xi}^{\\pi,\\rho}}$ as the robust valftioorepndinaply $\\pi$ Then by definition, we have ", "page_idx": 35}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{V_{\\xi}^{\\star,\\rho}(x_{1})=\\underset{\\pi}{\\operatorname*{max}}\\ \\underset{P\\in\\mathcal{U}^{\\rho}(P^{0})}{\\operatorname*{inf}}\\mathbb{E}^{\\pi,P}\\big[r_{1}(s_{1},a_{1})+\\cdot\\cdot\\cdot+r_{H}(s_{H},a_{H})\\big|s_{1}=x_{1}\\big],}\\\\ &{V_{\\xi}^{\\pi,\\rho}(x_{1})=\\underset{P\\in\\mathcal{U}^{\\rho}(P^{0})}{\\operatorname*{inf}}\\mathbb{E}^{\\pi,P}\\big[r_{1}(s_{1},a_{1})+\\cdot\\cdot\\cdot+r_{H}(s_{H},a_{H})\\big|s_{1}=x_{1}\\big].}\\end{array}\n$$", "text_format": "latex", "page_idx": 35}, {"type": "text", "text": "For any given $\\xi$ , the optimal action at step $h$ is ", "page_idx": 35}, {"type": "equation", "text": "$$\na_{h}^{\\star}=((1+\\xi_{h1})/2,\\cdot\\cdot\\cdot\\ ,(1+\\xi_{h d})/2).\n$$", "text_format": "latex", "page_idx": 35}, {"type": "text", "text": "The worst case transition at the first step is known as ", "page_idx": 35}, {"type": "equation", "text": "$$\n\\mathbb{P}_{1}(x_{1}|x_{1},a)=(1-\\rho),\\;\\mathbb{P}_{1}(x_{2}|x_{1},a)=\\rho,\\;\\mathbb{P}_{1}(x_{2}|x_{2},a)=1,\\;\\forall a\\in\\mathcal{A},\n$$", "text_format": "latex", "page_idx": 35}, {"type": "text", "text": "and from the second step on, the state always stays at $s_{2}$ . With these facts in mind, we have ", "page_idx": 35}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{V_{\\xi}^{\\star,\\rho}(x_{1})}\\\\ &{=\\delta\\Big\\{\\Big[\\displaystyle\\frac12+\\sum_{i=1}^{d}\\displaystyle\\frac{1+\\xi_{1i}}{4d}\\Big]+(1-\\rho)\\Big[\\displaystyle\\frac12+\\sum_{i=1}^{d}\\displaystyle\\frac{1+\\xi_{2i}}{4d}\\Big]+\\cdots+(1-\\rho)\\Big[\\displaystyle\\frac12+\\sum_{i=1}^{d}\\displaystyle\\frac{1+\\xi_{H i}}{4d}\\Big]\\Big\\}}\\\\ &{=\\displaystyle\\frac{\\delta}{2d}\\Big\\{\\Big[d+\\sum_{i=1}^{d}\\displaystyle\\frac{1+\\xi_{1i}}{2}\\Big]+(1-\\rho)\\Big[d+\\sum_{i=1}^{d}\\displaystyle\\frac{1+\\xi_{2i}}{2}\\Big]+\\cdots+(1-\\rho)\\Big[d+\\sum_{i=1}^{d}\\displaystyle\\frac{1+\\xi_{H i}}{2}\\Big]\\Big\\},}\\end{array}\n$$", "text_format": "latex", "page_idx": 35}, {"type": "text", "text": "and ", "page_idx": 35}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\lefteqn{V_{\\xi}^{\\pi,\\rho}(x_{1})}}\\\\ &{=\\frac{\\delta}{2d}\\mathbb{E}^{\\pi}\\Bigl\\{\\Bigl[d+\\displaystyle\\sum_{i=1}^{d}\\xi_{1i}a_{1i}\\Bigr]+(1-\\rho)\\Bigl[d+\\displaystyle\\sum_{i=1}^{d}\\xi_{2i}a_{2i}\\Bigr]\\cdots+(1-\\rho)\\Bigl[d+\\displaystyle\\sum_{i=1}^{d}\\xi_{H i}a_{H i}\\Bigr]\\Bigr\\}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 35}, {"type": "text", "text": "Then we have ", "page_idx": 35}, {"type": "equation", "text": "$$\n\\begin{array}{l l}{{V_{\\xi}^{\\star,\\rho}(x_{1})-V_{\\xi}^{\\pi,\\rho}(x_{1})}}\\\\ {{\\displaystyle}}\\\\ {{\\displaystyle}}\\\\ {{=\\frac{\\delta}{2d}\\Big\\{\\Big[\\displaystyle\\sum_{i=1}^{d}\\displaystyle\\frac{1+\\xi_{1i}}{2}-\\xi_{1i}\\mathbb{E}^{\\pi}a_{1i}\\Big]+(1-\\rho)\\displaystyle\\sum_{h=2}^{H}\\sum_{i=1}^{d}\\Big(\\displaystyle\\frac{1+\\xi_{h i}}{2}-\\xi_{h i}\\mathbb{E}^{\\pi}a_{h i}\\Big)\\Big\\}}}\\\\ {{\\displaystyle}}\\\\ {{\\displaystyle}}\\\\ {{\\displaystyle}}\\end{\\ge\\frac{\\delta}{2d}(1-\\rho)\\sum_{h=1}^{H}\\sum_{i=1}^{d}\\Big(\\displaystyle\\frac{1+\\xi_{h i}}{2}-\\xi_{h i}\\mathbb{E}^{\\pi}a_{h i}\\Big)}}\\end{array}\n$$", "text_format": "latex", "page_idx": 35}, {"type": "equation", "text": "$$\n\\begin{array}{l}{\\displaystyle=\\frac{\\delta}{2d}(1-\\rho)\\sum_{h=1}^{H}\\sum_{i=1}^{d}\\left(\\frac{1}{2}+\\xi_{h i}\\mathbb{E}^{\\pi}\\Big(\\frac{1}{2}-a_{h i}\\Big)\\right)}\\\\ {\\displaystyle=\\frac{\\delta}{4d}(1-\\rho)\\sum_{h=1}^{H}\\sum_{i=1}^{d}(1-\\xi_{h i}\\mathbb{E}^{\\pi}(2a_{h i}-1)).}\\end{array}\n$$", "text_format": "latex", "page_idx": 36}, {"type": "text", "text": "Note that for any $(h,i)\\in[H]\\times[d]$ , by design we have $1=\\xi_{h i}^{2}$ , thus ", "page_idx": 36}, {"type": "equation", "text": "$$\n\\begin{array}{r l r}{\\lefteqn{\\frac{\\delta}{4d}(1-\\rho)\\sum_{h=1}^{H}\\sum_{i=1}^{d}(1-\\xi_{h i}\\mathbb{E}^{\\pi}(2a_{h i}-1))=\\frac{\\delta}{4d}(1-\\rho)\\sum_{h=1}^{H}\\sum_{i=1}^{d}(\\xi_{h i}-\\mathbb{E}^{\\pi}(2a_{h i}-1))\\xi_{h i}}}\\\\ &{}&\\\\ &{}&{=\\frac{\\delta}{4d}(1-\\rho)\\sum_{h=1}^{H}\\sum_{i=1}^{d}|\\xi_{h i}-\\mathbb{E}^{\\pi}(2a_{h i}-1)|,~~~}\\end{array}\n$$", "text_format": "latex", "page_idx": 36}, {"type": "text", "text": "where (G.34) holds due to the fact that $\\mathbb{E}^{\\pi}(2a_{h i}-1)\\in[-1,1]$ . To continue, we have ", "page_idx": 36}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\displaystyle\\frac{\\delta}{4d}(1-\\rho)\\displaystyle\\sum_{h=1}^{H}\\sum_{i=1}^{d}|\\xi_{h i}-\\mathbb{E}^{\\pi}(2a_{h i}-1)|}\\\\ &{\\displaystyle\\geq\\frac{\\delta}{4d}(1-\\rho)\\displaystyle\\sum_{h=1}^{H}\\sum_{i=1}^{d}|\\xi_{h i}-\\mathbb{E}^{\\pi}(2a_{h i}-1)|\\,\\mathbb{I}\\left\\{\\xi_{h i}\\neq\\mathrm{sign}(\\mathbb{E}^{\\pi}(2a_{h,i}-1))\\right\\}}\\\\ &{\\displaystyle\\geq\\frac{\\delta}{4d}(1-\\rho)\\displaystyle\\sum_{h=1}^{H}\\sum_{i=1}^{d}\\mathbb{I}\\left\\{\\xi_{h i}\\neq\\mathrm{sign}(\\mathbb{E}^{\\pi}(2a_{h,i}-1))\\right\\}}\\\\ &{\\displaystyle\\geq\\frac{\\delta}{4d}(1-\\rho)D_{H}(\\xi,\\xi^{\\pi}),}\\end{array}\n$$", "text_format": "latex", "page_idx": 36}, {"type": "text", "text": "where $D_{H}(\\cdot,\\cdot)$ is the Hamming distance, $\\pmb{\\xi}^{\\pi}=\\{\\pmb{\\xi}_{h}^{\\pi}\\}_{h\\in[H]}$ ,and $\\xi_{h i}^{\\pi}:=\\mathrm{sign}(\\mathbb{E}^{\\pi}(2a_{h i}-1)),\\forall i\\in[d]$ Combining (G.33), (G.34), (G.35) and the definition of the suboptimality gap, we have ", "page_idx": 36}, {"type": "equation", "text": "$$\n\\operatorname{SupOpt}(M_{\\pmb{\\xi}},x_{1},\\pi,\\rho)\\geq\\frac{\\delta}{4d}(1-\\rho)D_{H}(\\pmb{\\xi},\\pmb{\\xi}^{\\pi}).\n$$", "text_format": "latex", "page_idx": 36}, {"type": "text", "text": "Step 2: lower bound the hamming distance by testing error. Applying Assouad's method [46, Lemma 2.12], we have ", "page_idx": 36}, {"type": "equation", "text": "$$\n\\operatorname*{inf}_{\\pi}\\operatorname*{sup}_{\\xi\\in\\Omega}\\mathbb{E}_{\\xi}\\big[D_{H}(\\pmb{\\xi},\\pmb{\\xi}^{\\prime})\\big]\\geq\\frac{d H}{2}\\operatorname*{min}_{\\pmb{\\xi},\\pmb{\\xi}^{\\prime}\\in\\Omega\\atop D_{H}(\\pmb{\\xi},\\pmb{\\xi}^{\\prime})=1}\\operatorname*{inf}_{\\psi}\\Big[\\mathbb{Q}_{\\pmb{\\xi}}(\\psi(\\mathcal{D})\\neq\\pmb{\\xi})+\\mathbb{Q}_{\\pmb{\\xi}^{\\prime}}(\\psi(\\mathcal{D})\\neq\\pmb{\\xi}^{\\prime})\\Big],\n$$", "text_format": "latex", "page_idx": 36}, {"type": "text", "text": "where $\\operatorname{inf}_{\\psi}$ denotes the infimum over all test functions taking values in $\\{\\pmb{\\xi},\\pmb{\\xi}^{\\prime}\\}$ .We conclude the proof by combining (G.36) and (G.37). \u53e3 ", "page_idx": 36}, {"type": "text", "text": "G.7Proof of Lemma F.2 ", "text_level": 1, "page_idx": 36}, {"type": "text", "text": "Proof. By the Theorem 2.12 in [46], we lower bound the testing error as follows ", "page_idx": 36}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\underset{\\pmb{\\xi},\\pmb{\\xi}^{\\prime}:D_{H}(\\pmb{\\xi},\\pmb{\\xi}^{\\prime})=1}{\\operatorname*{min}}\\underset{\\psi}{\\arg}\\left[\\mathbb{Q}_{\\pmb{\\xi}}(\\psi(\\mathcal{D})\\neq\\pmb{\\xi})+\\mathbb{Q}_{\\pmb{\\xi}^{\\prime}}(\\psi(\\mathcal{D})\\neq\\pmb{\\xi}^{\\prime})\\right]}\\\\ &{\\geq1-\\Big(\\frac{1}{2}\\underset{\\pmb{\\xi},\\pmb{\\xi}^{\\prime}:D_{H}(\\pmb{\\xi},\\pmb{\\xi}^{\\prime})=1}{\\operatorname*{max}}D_{\\mathrm{KL}}\\big(\\mathbb{Q}_{\\pmb{\\xi}}||\\mathbb{Q}_{\\pmb{\\xi}^{\\prime}}\\big)\\Big)^{1/2},}\\end{array}\n$$", "text_format": "latex", "page_idx": 36}, {"type": "text", "text": "where $D_{\\mathrm{KL}}(\\cdot||\\cdot)$ is the Kullback-Leibler divergence. Then it remains to bound $D_{\\mathrm{KL}}\\big(\\mathbb{Q}_{\\pmb{\\xi}}||\\mathbb{Q}_{\\pmb{\\xi}^{\\prime}}\\big)$ According to the definition of $\\mathbb{Q}_{\\pmb{\\xi}}(\\mathcal{D})$ ,wehave ", "page_idx": 36}, {"type": "equation", "text": "$$\n\\mathbb{Q}_{\\xi}(\\mathcal{D})=\\prod_{k=1}^{K}\\prod_{h=1}^{H}\\pi_{h}^{b}\\big(a_{h}^{k}|s_{h}^{k}\\big)P_{h}\\big(s_{h+1}^{k}|s_{h}^{k},a_{h}^{k}\\big)R\\big(s_{h}^{k},a_{h}^{k};r_{h}^{k}\\big),\n$$", "text_format": "latex", "page_idx": 36}, {"type": "text", "text": "where $R(s_{h}^{k},a_{h}^{k};r_{h}^{k})$ is the density function of $\\mathcal{N}(r_{h}(s_{h}^{k},a_{h}^{k}),1)$ at $r_{h}^{k}$ Note that the difference between the two distribution $\\mathbb{Q}_{\\pmb{\\xi}}(\\mathcal{D})$ and $\\mathbb{Q}_{\\pmb{\\xi}^{\\prime}}(\\mathcal{D})$ lies only in the reward distribution corresponding to the indexwhere $\\xi$ and $\\xi^{\\prime}$ differ. Then, by the chain rule of Kullback-Leibler divergence, we have ", "page_idx": 37}, {"type": "equation", "text": "$$\nD_{\\mathrm{KL}}\\bigl(\\mathbb{Q}_{\\xi}(\\mathcal{D})\\vert\\vert\\mathbb{Q}_{\\xi^{\\prime}}(\\mathcal{D})\\bigr)=\\sum_{k=1}^{\\frac{K}{d+2}}D_{\\mathrm{KL}}\\Bigl(\\mathcal{N}\\Bigl(\\frac{d+1}{2d}\\delta,1\\Bigr)\\Bigr\\vert\\Bigr\\vert\\mathcal{N}\\Bigl(\\frac{d-1}{2d}\\delta,1\\Bigr)\\Bigr)=\\frac{K}{d+2}\\frac{\\delta^{2}}{d^{2}}.\n$$", "text_format": "latex", "page_idx": 37}, {"type": "text", "text": "Then by our choice of $\\delta$ , we have ", "page_idx": 37}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\underset{\\boldsymbol{\\xi},\\boldsymbol{\\xi}^{\\prime}:D_{H}(\\boldsymbol{\\xi},\\boldsymbol{\\xi}^{\\prime})=1}{\\operatorname*{min}}\\operatorname*{inf}_{\\boldsymbol{\\psi}}\\left[\\mathbb{Q}_{\\boldsymbol{\\xi}}(\\boldsymbol{\\psi}(\\mathcal{D})\\neq\\boldsymbol{\\xi})+\\mathbb{Q}_{\\boldsymbol{\\xi}^{\\prime}}(\\boldsymbol{\\psi}(\\mathcal{D})\\neq\\boldsymbol{\\xi}^{\\prime})\\right]\\ge1-\\left(\\frac{K\\delta^{2}}{2(d+2)d^{2}}\\right)^{1/2}}&{}\\\\ {\\ge1-\\left(\\frac{K\\delta^{2}}{2d^{3}}\\right)^{1/2}}&{}\\\\ {=\\frac{1}{2}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 37}, {"type": "text", "text": "This completes the proof. ", "page_idx": 37}, {"type": "text", "text": "G.8Proof of Lemma F.3 ", "text_level": 1, "page_idx": 37}, {"type": "text", "text": "Proof. Recall that ", "page_idx": 37}, {"type": "equation", "text": "$$\n\\Sigma_{h}^{\\star-1}=\\sum_{k=1}^{K}\\frac{\\phi_{h}^{\\tau}\\phi_{h}^{\\tau\\top}}{[\\mathbb{V}_{h}V_{h}^{\\star,\\rho}](s_{h}^{\\tau},a_{h}^{\\tau})}+\\lambda I.\n$$", "text_format": "latex", "page_idx": 37}, {"type": "text", "text": "We first show that with sufficiently large $K$ the clipped conditional variances of the optimal robust value functions are always 1. Note that $V_{h}^{\\star,\\rho}(x_{2})=\\bar{0},\\forall h\\in[H]$ ,and ", "page_idx": 37}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{V_{H}^{\\star,\\rho}(x_{1})=\\displaystyle\\frac{\\delta}{2d}\\Big(\\sum_{i=1}^{d}\\frac{1+\\xi_{H i}}{2}+d\\Big)\\le\\delta,}\\\\ &{V_{H-1}^{\\star,\\rho}(x_{1})=\\displaystyle\\frac{\\delta}{2d}\\Big(\\sum_{i=1}^{d}\\frac{1+\\xi_{H-1i}}{2}+d\\Big)+V_{H}^{\\star,\\rho}(x_{1})\\le2\\delta,}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\qquad\\quad\\cdot\\ .}\\end{array}\n$$", "text_format": "latex", "page_idx": 37}, {"type": "equation", "text": "$$\nV_{2}^{\\star,\\rho}(x_{1})=\\frac{\\delta}{2d}\\Big(\\sum_{i=1}^{d}\\frac{1+\\xi_{2i}}{2}+d\\Big)+V_{3}^{\\star,\\rho}(x_{1})\\le(H-1)\\cdot\\delta.\n$$", "text_format": "latex", "page_idx": 37}, {"type": "text", "text": "Then, when $K\\geq\\Omega(H^{2}d^{3})$ , we have ", "page_idx": 37}, {"type": "equation", "text": "$$\n\\big[\\operatorname{Var}_{1}V_{2}^{\\star,\\rho}\\big](x_{1},a)=\\big[\\mathbb{P}_{1}^{0}(V_{2}^{\\star,\\rho})^{2}\\big](x_{1},a)-\\big(\\big[\\mathbb{P}_{1}^{0}(V_{2}^{\\star,\\rho})^{2}\\big](x_{1},a)\\big)^{2}\\le(1-\\rho)\\rho H^{2}\\delta^{2}\\le1,\n$$", "text_format": "latex", "page_idx": 37}, {"type": "text", "text": "and by design we have, ", "page_idx": 37}, {"type": "equation", "text": "$$\n[\\mathrm{Var}_{1}\\,V_{2}^{\\star,\\rho}](x_{2},a)=0\\ \\mathrm{and}\\,[\\mathrm{Var}_{h}\\,V_{h+1}^{\\star,\\rho}](s,a)=0,\\forall(s,a,h)\\in\\mathcal{S}\\times\\mathcal{A}\\times[H]/\\{1\\}.\n$$", "text_format": "latex", "page_idx": 37}, {"type": "text", "text": "Thus, we have $[\\mathbb{V}_{h}V_{h}^{\\star,\\rho}](s_{h}^{\\tau},a_{h}^{\\tau})=1$ , which implies ", "page_idx": 37}, {"type": "equation", "text": "$$\n\\Sigma_{h}^{\\star}=\\mathbf{A}_{h}.\n$$", "text_format": "latex", "page_idx": 37}, {"type": "text", "text": "Define ", "page_idx": 37}, {"type": "equation", "text": "$$\n\\tilde{\\mathbf{A}}_{h}=\\mathbb{E}^{\\pi^{b},P^{0}}[\\phi(s_{h},a_{h})\\phi(s_{h},a_{h})^{\\top}],\n$$", "text_format": "latex", "page_idx": 37}, {"type": "text", "text": "then by definition we have ", "page_idx": 37}, {"type": "equation", "text": "$$\n\\mathfrak{L}_{h}=\\frac{1}{d+2}\\left[\\begin{array}{c c c c c c c}{\\frac{1}{d^{2}}}&{0}&{\\cdots}&{0}&{\\frac{1}{d}(1-\\frac{1}{d})}&{0}\\\\ {0}&{0}&{\\cdots}&{0}&{0}&{0}\\\\ {\\vdots}&{\\vdots}&{\\vdots}&{\\vdots}&{\\vdots}\\\\ {0}&{0}&{\\cdots}&{0}&{0}&{0}\\\\ {\\frac{1}{d}(1-\\frac{1}{d})}&{0}&{\\cdots}&{0}&{(1-\\frac{1}{d})^{2}}&{0}\\\\ {0}&{0}&{\\cdots}&{0}&{0}&{0}\\end{array}\\right]+\\frac{1}{d+2}\\left[\\begin{array}{c c c c c c c}{0}&{0}&{\\cdots}&{0}&{0}\\\\ {0}&{\\frac{1}{d^{2}}}&{\\cdots}&{0}&{\\frac{1}{d}(1-\\frac{1}{d})}&{0}\\\\ {\\vdots}&{\\vdots}&{\\vdots}&{\\vdots}&{\\vdots}\\\\ {0}&{0}&{\\cdots}&{0}&{0}\\\\ {0}&{\\frac{1}{d}(1-\\frac{1}{d})}&{\\cdots}&{0}&{(1-\\frac{1}{d})^{2}}&{0}\\\\ {0}&{0}&{\\cdots}&{0}&{0}\\end{array}\\right]\\left[\\begin{array}{c}{0}\\\\ {0}\\\\ {\\frac{1}{d^{3}}}\\\\ {0}\\\\ {0}\\\\ {0}\\\\ {0}\\end{array}\\right].\n$$", "text_format": "latex", "page_idx": 37}, {"type": "text", "text": "", "page_idx": 37}, {"type": "equation", "text": "$$\n+\\cdot\\cdot\\cdot+{\\frac{1}{d+2}}\\left[{\\begin{array}{c c c c c c}{0}&{0}&{\\cdot\\cdot\\cdot}&{0}&{0}&{0}\\\\ {0}&{0}&{\\cdot\\cdot\\cdot}&{0}&{0}&{0}\\\\ {\\vdots}&{\\vdots}&{\\vdots}&{\\vdots}&{\\vdots}\\\\ {0}&{0}&{\\cdot\\cdot}&{{\\frac{1}{d^{2}}}}&{{\\frac{1}{d}}(1-{\\frac{1}{d}})}&{0}\\\\ {0}&{0}&{\\cdot\\cdot\\cdot}&{{\\frac{1}{d}}(1-{\\frac{1}{d}})}&{(1-{\\frac{1}{d}})^{2}}&{0}\\\\ {0}&{0}&{\\cdot\\cdot\\cdot}&{0}&{0}&{0}\\end{array}}\\right]+{\\frac{1}{d+2}}\\left[{\\begin{array}{c c c c c c}{0}&{0}&{\\cdot\\cdot\\cdot}&{0}&{0}&{0}\\\\ {0}&{0}&{\\cdot\\cdot\\cdot}&{0}&{0}&{0}\\\\ {\\vdots}&{\\vdots}&{\\vdots}&{\\vdots}&{\\vdots}\\\\ {0}&{0}&{\\cdot\\cdot}&{0}&{0}&{0}\\\\ {0}&{0}&{\\cdot\\cdot\\cdot}&{0}&{1}&{0}\\\\ {0}&{0}&{\\cdot\\cdot\\cdot}&{0}&{0}&{0}\\end{array}}\\right]\n$$", "text_format": "latex", "page_idx": 38}, {"type": "equation", "text": "$$\n+\\,\\frac{1}{d+2}\\left[\\begin{array}{l l l l l l}{0}&{0}&{\\cdots}&{0}&{0}&{0}\\\\ {0}&{0}&{\\cdots}&{0}&{0}&{0}\\\\ {\\vdots}&{\\vdots}&&{\\vdots}&{\\vdots}&{\\vdots}\\\\ {0}&{0}&{\\cdots}&{0}&{0}&{0}\\\\ {0}&{0}&{\\cdots}&{0}&{0}&{0}\\\\ {0}&{0}&{\\cdots}&{0}&{0}&{1}\\end{array}\\right]\n$$", "text_format": "latex", "page_idx": 38}, {"type": "equation", "text": "$$\n=\\frac d{d+2}\\left[\\begin{array}{c c c c c c}{\\frac1{d^{3}}}&{0}&{\\cdots\\cdot}&{0}&{\\frac1{d^{2}}(1-\\frac1d)}&{0}\\\\ {0}&{\\frac1{d^{3}}}&{\\cdots\\cdot}&{0}&{\\frac1{d^{2}}(1-\\frac1d)}&{0}\\\\ {\\vdots}&{\\vdots}&&{\\vdots}&{\\vdots}&{\\vdots}\\\\ {0}&{0}&{\\cdots\\cdot}&{\\frac1{d^{3}}}&{\\frac1{d^{2}}(1-\\frac1d)}&{0}\\\\ {\\frac1{d^{2}}(1-\\frac1d)}&{\\frac1{d^{2}}(1-\\frac1d)}&{\\cdots}&{\\frac1{d^{2}}(1-\\frac1d)}&{(1-\\frac1d)^{2}+\\frac1d}&{0}\\\\ {0}&{0}&{\\cdots}&{0}&{0}&{\\frac1{d}}\\end{array}\\right].\n$$", "text_format": "latex", "page_idx": 38}, {"type": "text", "text": "Denote ", "page_idx": 38}, {"type": "equation", "text": "$$\nD=\\left[\\begin{array}{c c c c c c}{\\frac{1}{d^{3}}}&{0}&{\\cdots\\cdot}&{0}&{\\frac{1}{d^{2}}(1-\\frac{1}{d})}\\\\ {0}&{\\frac{1}{d^{3}}}&{\\cdots\\cdot}&{0}&{\\frac{1}{d^{2}}(1-\\frac{1}{d})}\\\\ {\\vdots}&{\\vdots}&&{\\vdots}&{\\vdots}\\\\ {0}&{0}&{\\cdots}&{\\frac{1}{d^{3}}}&{\\frac{1}{d^{2}}(1-\\frac{1}{d})}\\\\ {\\frac{1}{d^{2}}(1-\\frac{1}{d})}&{\\frac{1}{d^{2}}(1-\\frac{1}{d})}&{\\cdots}&{\\frac{1}{d^{2}}(1-\\frac{1}{d})}&{(1-\\frac{1}{d})^{2}+\\frac{1}{d}}\\end{array}\\right],\n$$", "text_format": "latex", "page_idx": 38}, {"type": "text", "text": "then by Gaussian elimination, we have ", "page_idx": 38}, {"type": "equation", "text": "$$\nD^{-1}=\\left[\\begin{array}{c c c c c}{2d^{3}-2d^{2}+d}&{d^{3}-2d^{2}+d}&{\\cdot\\cdot\\cdot}&{d^{3}-2d^{2}+d}&{d-d^{2}}\\\\ {d^{3}-2d^{2}+d}&{2d^{3}-2d^{2}+d}&{\\cdot\\cdot}&{d^{3}-2d^{2}+d}&{d-d^{2}}\\\\ {\\vdots}&{\\vdots}&{\\vdots}&{\\vdots}&{\\vdots}\\\\ {d^{3}-2d^{2}+d}&{d^{3}-2d^{2}+d}&{\\cdot\\cdot}&{2d^{3}-2d^{2}+d}&{d-d^{2}}\\\\ {d-d^{2}}&{d-d^{2}}&{\\cdot\\cdot}&{d-d^{2}}&{d}\\end{array}\\right].\n$$", "text_format": "latex", "page_idx": 38}, {"type": "text", "text": "Note that ", "page_idx": 38}, {"type": "equation", "text": "$$\n\\tilde{\\Lambda}_{h}=\\frac{d}{d+2}\\left[\\!\\!\\begin{array}{c c}{{D}}&{{0}}\\\\ {{0}}&{{\\frac{1}{d}}}\\end{array}\\!\\!\\right],\n$$", "text_format": "latex", "page_idx": 38}, {"type": "text", "text": "then we have ", "page_idx": 38}, {"type": "equation", "text": "$$\n\\tilde{\\bf A}_{h}^{-1}={\\frac{d+2}{d}}\\left[D^{-1}\\quad0\\right].\n$$", "text_format": "latex", "page_idx": 38}, {"type": "text", "text": "Note that $\\lambda_{\\mathrm{min}}(D)=O(1/d^{3})$ thus $\\|\\tilde{\\mathbf{A}}_{h}^{-1}\\|=O(d^{3})$ . Then when $K>\\tilde{O}(d^{6})$ , for any $(s,a,i,h)\\in$ $S\\times{\\mathcal{A}}\\times[d]\\times[H]$ , with probability at least $1-\\delta$ , we have ", "page_idx": 38}, {"type": "equation", "text": "$$\n\\|\\phi_{i}(s,a)\\mathbf{1}_{i}\\|_{\\mathbf{A}_{h}^{-1}}\\leq\\frac{2}{\\sqrt{K}}\\|\\phi_{i}(s,a)\\mathbf{1}_{i}\\|_{\\tilde{\\mathbf{A}}_{h}^{-1}}.\n$$", "text_format": "latex", "page_idx": 38}, {"type": "text", "text": "With this in mind, we have ", "page_idx": 38}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\displaystyle\\operatorname*{sup}_{P\\in\\mathcal{U}^{\\rho}(P^{0})}\\sum_{h=1}^{H}\\mathbb{E}^{\\pi^{\\star},P}\\Big[\\displaystyle\\sum_{i=1}^{d}\\|\\phi_{i}(s,a)\\mathbf{1}_{i}\\|_{\\Sigma_{h}^{\\star-1}}\\big|s_{1}=x_{1}\\Big]}\\\\ &{=\\displaystyle\\operatorname*{sup}_{P\\in\\mathcal{U}^{\\rho}(P^{0})}\\sum_{h=1}^{H}\\mathbb{E}^{\\pi^{\\star},P}\\Big[\\displaystyle\\sum_{i=1}^{d}\\|\\phi_{i}(s_{h},a_{h})\\mathbf{1}_{i}\\|_{\\Lambda_{h}^{-1}}\\big|s_{1}=x_{1}\\Big]}\\end{array}\n$$", "text_format": "latex", "page_idx": 38}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\leq\\underset{P\\in\\mathcal{U}^{\\rho}(P^{0})}{\\operatorname*{sup}}\\sum_{h=1}^{H}\\mathbb{E}^{\\pi^{\\star},P}\\Big[\\frac{2}{\\sqrt{K}}\\sum_{i=1}^{d}\\|\\phi_{i}(s_{h},a_{h})\\mathbf{1}_{i}\\|_{\\tilde{\\Lambda}_{h}^{-1}}|s_{1}=x_{1}\\Big]}\\\\ &{=\\underset{P\\in\\mathcal{U}^{\\rho}(P^{0})}{\\operatorname*{sup}}\\underset{h=1}{\\overset{H}{\\sum}}\\mathbb{E}^{\\pi^{\\star},P}\\Big[\\frac{2}{\\sqrt{K}}\\sum_{i=1}^{d}\\phi_{i}(s_{h},a_{h})\\big(\\tilde{\\Lambda}_{h}^{-1}\\big)_{i i}^{1/2}|s_{1}=x_{1}\\Big]}\\\\ &{\\leq\\frac{4H d^{3/2}}{\\sqrt{K}},}\\end{array}\n$$", "text_format": "latex", "page_idx": 39}, {"type": "text", "text": "where (G.40) is due to (G.39). This concludes the proof. ", "page_idx": 39}, {"type": "text", "text": "H  Proof of Supporting Lemmas ", "text_level": 1, "page_idx": 39}, {"type": "text", "text": "H.1 Proof of Lemma G.1 ", "text_level": 1, "page_idx": 39}, {"type": "text", "text": "To prove Lemma G.1, we need the following proposition on the dual formulation under the TV uncertaintyset. ", "page_idx": 39}, {"type": "text", "text": "Proposition H.1. (Strong duality for TV [42, Lemma 4]). Given any probability measure $\\mu^{0}$ over $\\boldsymbol{S}$ , a fixed uncertainty level $\\rho$ the uncertainty set $\\mathcal{U}^{\\rho}(\\mu^{0})=\\{\\mu:\\mu\\in\\bar{\\Delta(S)},D_{T V}\\backslash(\\mu||\\mu^{0})\\leq\\rho\\}$ , and any function $V:S\\rightarrow[0,H]$ , we obtain ", "page_idx": 39}, {"type": "equation", "text": "$$\n\\operatorname*{inf}_{\\mu\\in\\mathcal{U}^{\\rho}(\\mu^{0})}\\mathbb{E}_{s\\sim\\mu}V(s)=\\operatorname*{max}_{\\alpha\\in[V_{\\operatorname*{min}},V_{\\operatorname*{max}}]}\\big\\{\\mathbb{E}_{s\\sim\\mu^{0}}[V(s)]_{\\alpha}-\\rho\\big(\\alpha-\\operatorname*{min}_{s^{\\prime}}[V(s^{\\prime})]_{\\alpha}\\big)\\big\\},\n$$", "text_format": "latex", "page_idx": 39}, {"type": "text", "text": "where $[V(s)]_{\\alpha}=\\operatorname*{min}\\{V(s),\\alpha\\}$ \uff0c $V_{\\mathrm{min}}=\\operatorname*{min}_{s}V(s)$ and $V_{\\mathrm{max}}=\\operatorname*{max}_{s}V(s)$ Notably, the range of $\\alpha$ can be relaxed to $[0,H]$ without impacting the optimization. ", "page_idx": 39}, {"type": "text", "text": "Proof of Lemma G.1. By Assumption 3.1 and Proposition H.1, we have ", "page_idx": 39}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\underset{P_{h}(\\cdot\\vert s,a)\\in\\mathcal{U}_{h}^{\\rho}(s,a;\\mu_{h,i}^{0})}{\\operatorname*{inf}}[\\mathbb{P}_{h}\\widehat{V}_{h+1}^{\\rho}](s,a)-\\underset{P_{h}(\\cdot\\vert s,a)\\in\\mathcal{U}_{h}^{\\rho}(s,a;\\mu_{h,i}^{0})}{\\operatorname*{inf}}[\\mathbb{P}_{h}\\widehat{V}_{h+1}^{\\rho}](s,a)}\\\\ &{=\\displaystyle\\sum_{i=1}^{d}\\phi_{i}(s,a)\\Big[\\underset{\\alpha\\in[0,H]}{\\operatorname*{max}}\\{\\mathbb{E}^{\\mu_{h,i}^{0}}[\\widehat{V}_{h+1}^{\\rho}(s)]_{\\alpha}-\\rho(\\alpha-\\underset{s^{\\prime}}{\\operatorname*{min}}[\\widehat{V}_{h+1}^{\\rho}(s^{\\prime})]_{\\alpha})\\}}\\\\ &{\\quad-\\underset{\\alpha\\in[0,H]}{\\operatorname*{max}}\\{\\widehat{\\mathbb{E}}^{\\mu_{h,i}^{0}}[\\widehat{V}_{h+1}^{\\rho}(s)]_{\\alpha}-\\rho(\\alpha-\\underset{s^{\\prime}}{\\operatorname*{min}}[\\widehat{V}_{h+1}^{\\rho}(s^{\\prime})]_{\\alpha})\\}\\Big].}\\end{array}\n$$", "text_format": "latex", "page_idx": 39}, {"type": "text", "text": "Denote $\\begin{array}{r}{\\alpha_{i}=\\operatorname*{argmax}_{\\alpha\\in[0,H]}\\{\\mathbb{E}^{\\mu_{h,i}^{0}}[\\widehat{V}_{h+1}^{\\rho}(s)]_{\\alpha}-\\rho(\\alpha-\\operatorname*{min}_{s^{\\prime}}[\\widehat{V}_{h+1}^{\\rho}(s^{\\prime})]_{\\alpha})\\}}\\end{array}$ then we have ", "page_idx": 39}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\underset{P_{h}(\\cdot\\,|s,a)\\in\\mathcal{U}_{h}^{p}(s,a;\\mu_{h,i}^{0})}{\\operatorname*{inf}}[\\mathbb{P}_{h}\\widehat{V}_{h+1}^{\\rho}](s,a)-\\underset{P_{h}(\\cdot\\,|s,a)\\in\\mathcal{U}_{h}^{p}(s,a;\\mu_{h,i}^{0})}{\\operatorname*{inf}}[\\mathbb{P}_{h}\\widehat{V}_{h+1}^{\\rho}](s,a)}\\\\ &{\\leq\\underset{i=1}{\\overset{d}{\\sum}}\\phi_{i}(s,a)\\big(\\mathbb{E}^{\\mu_{h,i}^{0}}[\\widehat{V}_{h+1}^{\\rho}(s)]_{\\alpha_{i}}-\\widehat{\\mathbb{E}}^{\\mu_{h,i}^{0}}[\\widehat{V}_{h+1}^{\\rho}(s)]_{\\alpha_{i}}\\big)}\\\\ &{=\\underset{i=1}{\\overset{d}{\\sum}}\\phi_{i}(s,a)\\big[\\mathbf{1}_{i}^{\\top}\\mathbb{E}^{\\mu_{h}^{0}}[\\widehat{V}_{h+1}^{\\rho}(s)]_{\\alpha_{i}}-\\mathbf{1}_{i}^{\\top}\\widehat{\\mathbb{E}}^{\\mu_{h}^{0}}[\\widehat{V}_{h+1}^{\\rho}(s)]_{\\alpha_{i}}\\big].}\\end{array}\n$$", "text_format": "latex", "page_idx": 39}, {"type": "text", "text": "Here we do reference-advantage decomposition by using the optimal robust value function as the reference function. Specifically, we have ", "page_idx": 39}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\underset{P_{h}(\\cdot\\vert s,a)\\in\\mathcal{U}_{h}^{\\rho}(s,a;\\mu_{h,i}^{0})}{\\operatorname*{inf}}[\\mathbb{P}_{h}\\widehat{V}_{h+1}^{\\rho}](s,a)-\\underset{P_{h}(\\cdot\\vert s,a)\\in\\mathcal{U}_{h}^{\\rho}(s,a;\\mu_{h,i}^{0})}{\\widehat{\\operatorname*{inf}}}[\\mathbb{P}_{h}\\widehat{V}_{h+1}^{\\rho}](s,a)}\\\\ &{\\leq\\underset{i=1}{\\overset{d}{\\sum}}\\phi_{i}(s,a)\\big[\\mathbf{1}_{i}^{\\top}\\big(\\mathbb{E}^{\\mu_{h}^{0}}[[\\widehat{V}_{h+1}^{\\rho}(s)]_{\\alpha_{i}}-[V_{h+1}^{\\star,\\rho}(s)]_{\\alpha_{i}}+[V_{h+1}^{\\star,\\rho}(s)]_{\\alpha_{i}}\\big)\\big)}\\\\ &{\\quad-\\mathbf{1}_{i}^{\\top}\\big(\\widehat{\\mathbb{E}}^{\\mu_{h}^{0}}[[\\widehat{V}_{h+1}^{\\rho}(s)]_{\\alpha_{i}}-[V_{h+1}^{\\star,\\rho}(s)]_{\\alpha_{i}}+[V_{h+1}^{\\star,\\rho}(s)]_{\\alpha_{i}}\\big)\\big)\\big]}\\end{array}\n$$", "text_format": "latex", "page_idx": 39}, {"type": "image", "img_path": "9SghPrjYU1/tmp/55d04063d28a51633be2d66bbd37fb3866b418771c8ed44293a915979aca12be.jpg", "img_caption": [], "img_footnote": [], "page_idx": 40}, {"type": "text", "text": "advantage uncertainty ", "page_idx": 40}, {"type": "text", "text": "(H.2) ", "page_idx": 40}, {"type": "text", "text": "The Reference Uncertainty. First, we bound the reference uncertainty. Specifically, we have ", "page_idx": 40}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\lefteqn{\\sum_{i=1}^{d}\\phi_{i}(s,a)\\mathbf1_{i}^{\\top}\\left(\\mathbb{E}^{\\mu_{\\delta}^{0}}|V_{h+1}^{*,\\rho}(s)|\\right)_{a_{i}}-\\mathbb{E}^{\\mu_{\\delta}^{0}}|V_{h+1}^{*,\\rho}(s)|_{a_{i}})}\\quad}&{}\\\\ &{=\\sum_{i=1}^{d}\\phi_{i}(s,a)\\mathbf1_{i}^{\\top}\\left(\\mathbb{E}^{\\mu_{\\delta}^{0}}|V_{h+1}^{*,\\rho}(s)|_{a_{i}}-\\Lambda_{h}^{-1}\\displaystyle\\sum_{r=1}^{K}\\phi_{h}^{\\prime}\\left[\\mathbb{D}_{h}^{0}|V_{h+1}^{*,\\rho}|_{a_{i}}\\right](s_{h}^{\\top},a_{h}^{\\top})\\right.}\\\\ &{\\left.\\quad+\\Lambda_{h}^{-1}\\displaystyle\\sum_{\\tau=1}^{K}\\phi_{h}^{\\prime}\\left[\\mathbb{D}_{h}^{0}|V_{h+1}^{*,\\rho}|_{a_{i}}\\right](s_{h}^{\\tau},a_{h}^{\\tau})-\\Lambda_{h}^{-1}\\displaystyle\\sum_{r=1}^{K}\\phi_{h}^{\\prime}|V_{h+1}^{*,\\rho}(s_{h+1}^{\\tau})|_{a_{i}}\\right)}\\\\ &{=\\displaystyle\\sum_{i=1}^{d}\\phi_{i}(s,a)\\mathbf1_{i}^{\\top}\\left(\\mathbb{E}^{\\mu_{\\delta}^{0}}|V_{h+1}^{*,\\rho}(s)|_{a_{i}}-\\Lambda_{h}^{-1}\\displaystyle\\sum_{\\tau=1}^{K}\\phi_{h}^{\\prime}\\phi_{h}^{\\top}\\mathbb{E}^{\\mu_{\\delta}^{0}}|V_{h+1}^{*,\\rho}(s)|_{a_{i}}\\right.}\\\\ &{\\left.\\quad+\\Lambda_{h}^{-1}\\displaystyle\\sum_{\\tau=1}^{K}\\phi_{h}^{\\prime}\\left(\\mathbb{D}_{h}^{0}|V_{h+1}^{*,\\rho}|_{a_{i}}\\right)(s_{h}^{\\tau},a_{h}^{\\tau})-[V_{h+1}^{*,\\rho}(s_{h+1}^{\\tau})]_{a_{i \n$$", "text_format": "latex", "page_idx": 40}, {"type": "text", "text": "For any function $f:S\\to[0,H-1]$ ,we define $\\eta_{h}^{\\tau}([f]_{\\alpha_{i}})=\\left([\\mathbb{P}_{h}^{0}[f]_{\\alpha_{i}}](s_{h}^{\\tau},a_{h}^{\\tau})-[f(s_{h+1}^{\\tau})]_{\\alpha_{i}}\\right)$ Then, we have ", "page_idx": 40}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\displaystyle\\sum_{i=1}^{d}\\phi_{i}(s,a)\\mathbf{1}_{i}^{\\top}\\left(\\mathbb{E}^{\\mu_{h}^{0}}[V_{h+1}^{\\star,\\rho}(s)]_{\\alpha_{i}}-\\widehat{\\mathbb{E}}^{\\mu_{h}^{0}}[V_{h+1}^{\\star,\\rho}(s)]_{\\alpha_{i}}\\right)}\\\\ {\\displaystyle=\\lambda\\sum_{i=1}^{d}\\phi_{i}(s,a)\\mathbf{1}_{i}^{\\top}\\mathbf{A}_{h}^{-1}\\mathbb{E}^{\\mu_{h}^{0}}[V_{h+1}^{\\star,\\rho}(s)]_{\\alpha_{i}}+\\displaystyle\\sum_{i=1}^{d}\\phi_{i}(s,a)\\mathbf{1}_{i}^{\\top}\\mathbf{A}_{h}^{-1}\\displaystyle\\sum_{\\tau=1}^{K}\\phi_{h}^{\\tau}\\eta_{h}^{\\tau}([V_{h+1}^{\\star,\\rho}]_{\\alpha_{i}})}\\\\ {\\displaystyle\\leq\\lambda\\displaystyle\\sum_{i=1}^{d}\\|\\phi_{i}(s,a)\\mathbf{1}_{i}\\|_{\\mathbf{A}_{h}^{-1}}\\|\\mathbb{E}^{\\mu_{h}^{0}}[V_{h+1}^{\\star,\\rho}(s)]_{\\alpha_{i}}\\|_{\\mathbf{A}_{h}^{-1}}+\\displaystyle\\sum_{i=1}^{d}\\|\\phi_{i}(s,a)\\mathbf{1}_{i}\\|_{\\mathbf{A}_{h}^{-1}}\\Big\\|\\displaystyle\\sum_{\\tau=1}^{K}\\phi_{h}^{\\tau}\\eta_{h}^{\\tau}([V_{h+1}^{\\star,\\rho}]_{\\alpha_{i}})\\Big\\|_{\\mathbf{A}_{h}^{-1}}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 40}, {"type": "text", "text": "The Advantage Uncertainty.  Next, we bound the advantage uncertainty. By similar argument in bounding the reference uncertainty, we have ", "page_idx": 40}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\displaystyle\\sum_{i=1}^{d}\\phi_{i}(s,a)\\mathbf{1}_{i}^{\\top}\\big(\\mathbb{E}^{\\mu_{h}^{o}}[[\\widehat{V}_{h+1}^{\\rho}(s)]_{\\alpha_{i}}-[V_{h+1}^{\\star,\\rho}(s)]_{\\alpha_{i}}\\big]-\\widehat{\\mathbb{E}}^{\\mu_{h}^{o}}[[\\widehat{V}_{h+1}^{\\rho}(s)]_{\\alpha_{i}}-[V_{h+1}^{\\star,\\rho}(s)]_{\\alpha_{i}}\\big]\\big)}\\\\ &{\\displaystyle\\leq\\lambda\\displaystyle\\sum_{i=1}^{d}\\|\\phi_{i}(s,a)\\mathbf{1}_{i}\\|_{\\mathbf{A}_{h}^{-1}}\\Big\\|\\mathbb{E}^{\\mu_{h}^{o}}\\big[[\\widehat{V}_{h+1}^{\\rho}(s)]_{\\alpha_{i}}-[V_{h+1}^{\\star,\\rho}(s)]_{\\alpha_{i}}\\big]\\Big\\|_{\\mathbf{A}_{h}^{-1}}}\\end{array}\n$$", "text_format": "latex", "page_idx": 40}, {"type": "equation", "text": "$$\n+\\sum_{i=1}^{d}\\|\\phi_{i}(s,a)\\mathbf{1}_{i}\\|_{\\mathbf{A}_{h}^{-1}}\\Big\\|\\sum_{\\tau=1}^{K}\\phi_{h}^{\\tau}\\eta_{h}^{\\tau}([\\widehat{V}_{h+1}^{\\rho}(s)]_{\\alpha_{i}}-[V_{h+1}^{\\star,\\rho}(s)]_{\\alpha_{i}})\\Big\\|_{\\mathbf{A}_{h}^{-1}}\\,.\n$$", "text_format": "latex", "page_idx": 40}, {"type": "text", "text": "Combining (H.2), (H.3) and (H.4), we have ", "page_idx": 41}, {"type": "equation", "text": "$$\n\\begin{array}{l}{\\displaystyle\\mathcal{P}_{h}(\\cdot\\vert s,a)\\vert\\!\\!\\!\\!\\!}&{\\displaystyle\\operatorname*{inf}_{\\substack{(h,\\ldots,a)\\in[d_{h,i}]\\,\\Lambda_{h}^{\\prime}\\,\\vert\\!\\!\\!\\!}_{h}}\\left\\vert\\mathbb{P}_{h}(\\hat{V}_{h+1}^{\\rho})\\vert(s,a)-\\operatorname*{inf}_{\\substack{P_{h}(\\cdot\\vert s,a)\\in[d_{h,i}^{\\rho}(s,a)]\\,\\Lambda_{h}^{\\prime}\\,\\vert\\!\\!\\!}_{h}}\\left\\vert\\mathbb{P}_{h}(\\hat{V}_{h+1}^{\\rho})\\right\\vert(s,a)\\right.}\\\\ {\\displaystyle}&{\\leq\\underbrace{\\lambda\\!\\!\\!\\!\\sum_{i=1}^{d}\\left\\Vert\\phi_{i}(s,a)\\mathbf{1}_{i}\\right\\Vert_{\\Lambda_{h}^{-1}}\\left\\Vert\\mathbb{E}^{\\mu_{h}^{\\rho}}[V_{h+1}^{\\star,\\rho}(s)]_{\\alpha_{i}}\\right\\Vert_{\\Lambda_{h}^{-1}}}_{\\substack{\\mathrm{if~}}}+\\underbrace{\\!\\!\\!\\!\\sum_{i=1}^{d}\\left\\Vert\\phi_{i}(s,a)\\mathbf{1}_{i}\\right\\Vert_{\\Lambda_{h}^{-1}}\\left\\Vert\\!\\!\\!\\!\\sum_{\\tau=1}^{K}\\phi_{h}^{\\tau}\\eta_{h}^{\\tau}\\!\\!\\left([V_{h+1}^{\\star,\\rho}]_{\\alpha_{i}}\\right)\\right\\Vert_{\\Lambda_{h}^{-1}}}_{\\substack{\\mathrm{if~}}}}\\\\ &{\\displaystyle\\left.+\\underbrace{\\lambda\\!\\!\\!\\sum_{i=1}^{d}\\left\\Vert\\phi_{i}(s,a)\\mathbf{1}_{i}\\right\\Vert_{\\Lambda_{h}^{-1}}\\left\\Vert\\mathbb{E}^{\\mu_{h}^{0}}[[\\hat{V}_{h+1}^{\\rho}(s)]_{\\alpha_{i}}-[V_{h+1}^{\\star,\\rho}(s)]_{\\alpha_{i}}]\\right\\Vert_{\\Lambda_{h}^{-1}}}_{\\substack{\\mathrm{if~}}}}\\\\ &{\\displaystyle+\\sum_{i=1}^{d}\\left\\Vert\\phi_{i}(s,a)\\mathbf{1}_{i}\\right\\Vert_{\\Lambda_{h}^{-1}}\\left\\Vert\\sum_{i=1}^{K}\\phi_{h}^{\\tau}\\eta_{h}^{\\tau}[(\\hat{V}_{h+ \n$$", "text_format": "latex", "page_idx": 41}, {"type": "text", "text": "On the other hand, we can similarly deduce ", "text_level": 1, "page_idx": 41}, {"type": "text", "text": "$\\begin{array}{r l}&{\\underset{\\hbar}{\\mathrm{inf~}}\\underset{(s,a)\\in\\mathcal{U}_{h}^{\\ell}(s,a;\\mu_{h,i}^{0})}{\\mathrm{inf~}}[\\mathbb{P}_{h}\\widehat{V}_{h+1}^{\\rho}](s,a)-\\underset{P_{h}(\\cdot\\vert s,a)\\in\\mathcal{U}_{h}^{\\ell}(s,a;\\mu_{h,i}^{0})}{\\mathrm{inf~}}[\\mathbb{P}_{h}\\widehat{V}_{h+1}^{\\rho}](s,a)}\\\\ &{\\leq\\underset{\\substack{i=1}}{\\underbrace{\\lambda\\sum_{i=1}^{d}\\left\\Vert\\phi_{i}(s,a)\\mathbf{1}_{i}\\right\\Vert_{\\mathbf{A}_{h}^{-1}}\\left\\Vert\\mathbb{E}^{\\mu_{h}^{0}}[V_{h+1}^{\\star,\\rho}(s)]_{\\alpha_{i}^{\\prime}}\\right\\Vert_{\\mathbf{A}_{h}^{-1}}}+\\underset{\\substack{i=1}}{\\overset{d}{\\underbrace{\\sum_{i=1}^{d}\\left\\Vert\\phi_{i}(s,a)\\mathbf{1}_{i}\\right\\Vert_{\\mathbf{A}_{h}^{-1}}\\right\\Vert_{\\tau=1}^{K}\\left\\Vert\\sum_{\\tau=1}^{K}\\phi_{h}^{\\tau}\\eta_{h}^{\\tau}\\left([V_{h+1}^{\\star,\\rho}]_{\\alpha_{i}^{\\prime}}\\right)\\right\\Vert_{\\mathbf{A}_{h}^{-1}}}}}}\\\\ &{\\quad+\\underset{\\substack{i=1}}{\\underbrace{\\lambda\\sum_{i=1}^{d}\\left\\Vert\\phi_{i}(s,a)\\mathbf{1}_{i}\\right\\Vert_{\\mathbf{A}_{h}^{-1}}\\left\\Vert\\mathbb{E}^{\\mu_{h}^{0}}[[\\widehat{V}_{h+1}^{\\rho}(s)]_{\\alpha_{i}^{\\prime}}-[{V}_{h+1}^{\\star,\\rho}(s)]_{\\alpha_{i}^{\\prime}}]\\right\\Vert_{\\mathbf{A}_{h}^{-1}}}}}\\end{array}$   \niii   \n$+\\sum_{i=1}^{d}\\|\\phi_{i}(s,a)\\mathbf{1}_{i}\\|_{\\mathbf{A}_{h}^{-1}}\\Big\\|\\sum_{\\tau=1}^{K}\\phi_{h}^{\\tau}\\eta_{h}^{\\tau}([\\widehat{V}_{h+1}^{\\rho}(s)]_{\\alpha_{i}^{\\prime}}-[V_{h+1}^{\\star,\\rho}(s)]_{\\alpha_{i}^{\\prime}})\\Big\\|_{\\mathbf{A}_{h}^{-1}},$   \niv ", "page_idx": 41}, {"type": "text", "text": "where $\\begin{array}{r}{\\alpha_{i}^{\\prime}=\\operatorname*{argmax}_{\\alpha\\in[0,H]}\\{\\widehat{\\mathbb{E}}^{\\mu_{h,i}^{0}}[\\widehat{V}_{h+1}^{\\rho}(s)]_{\\alpha}-\\rho(\\alpha-\\operatorname*{min}_{s^{\\prime}}[\\widehat{V}_{h+1}^{\\rho}(s^{\\prime})]_{\\alpha})\\}}\\end{array}$ . Then for all $i\\,\\in\\,[d]$ there exist $\\tilde{\\alpha}_{i}\\in\\{\\alpha_{i},\\alpha_{i}^{\\prime}\\}$ , such that ", "page_idx": 41}, {"type": "image", "img_path": "9SghPrjYU1/tmp/50e29aec2f02847457b19a08a3120a1068f7956ea2bd404aa0a59f0cc3a2b597.jpg", "img_caption": [], "img_footnote": [], "page_idx": 41}, {"type": "text", "text": "This concludes the proof. ", "page_idx": 41}, {"type": "text", "text": "H.2 Proof of Lemma G.2 ", "text_level": 1, "page_idx": 41}, {"type": "text", "text": "The proof of Lemma G.2 will use the following fact. ", "page_idx": 41}, {"type": "text", "text": "Lemma H.2. [14, Lemma D.1] Let $\\begin{array}{r}{\\mathbf{\\Lambda}_{t}=\\lambda\\mathbf{I}+\\sum_{i=1}^{t}\\phi_{i}\\phi_{i}^{\\top}}\\end{array}$ ,where $\\phi_{i}\\in\\mathbb{R}^{d}$ and $\\lambda>0$ .Then: ", "page_idx": 42}, {"type": "equation", "text": "$$\n\\sum_{i=1}^{t}\\phi_{i}^{\\top}(\\mathbf{A}_{t})^{-1}\\phi_{i}\\leq d.\n$$", "text_format": "latex", "page_idx": 42}, {"type": "text", "text": "Proof of Lemma G.2. The proof of Lemma G.2 is similar to that of Lemma E.1 in [20]. Denote $\\begin{array}{r}{\\alpha_{i}=\\mathrm{argmax}_{\\alpha\\in[0,H]}\\big\\{\\hat{z}_{h,i}(\\alpha)-\\rho(\\alpha-\\operatorname*{min}_{s^{\\prime}}[\\widehat{V}_{h+1}^{\\rho}(s^{\\prime})]_{\\alpha})\\big\\},i\\in[d]}\\end{array}$ For anyvector $\\pmb{v}\\in\\mathbb{R}^{d}$ wehave ", "page_idx": 42}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\left|\\displaystyle v^{\\top}w_{h}^{\\rho}\\right|=\\left|v^{\\top}\\theta_{h}+v^{\\top}\\Big[\\operatorname*{max}_{\\alpha\\in[0,H]}\\{\\hat{z}_{h,i}(\\alpha)-\\rho(\\alpha-\\operatorname*{min}_{s^{\\prime}}[\\hat{V}_{h+1}^{\\rho}(s^{\\prime})]_{\\alpha})\\}\\right]_{i\\in[d]}\\right|}\\\\ &{\\qquad\\qquad\\leq\\left|v^{\\top}\\theta_{h}\\right|+\\left|v^{\\top}\\Big[\\operatorname*{max}_{\\alpha\\in[0,H]}\\{\\hat{z}_{h,i}(\\alpha)-\\rho(\\alpha-\\operatorname*{min}_{s^{\\prime}}[\\hat{V}_{h+1}^{\\rho}(s^{\\prime})]_{\\alpha})\\}\\right]_{i\\in[d]}\\right|}\\\\ &{\\qquad\\qquad\\leq\\sqrt{d}\\|v\\|_{2}+H\\|v\\|_{1}+\\left|v^{\\top}\\left[\\mathbf{1}_{i}^{\\top}\\left(\\mathbf{A}_{h}^{-1}\\displaystyle\\sum_{\\tau=1}^{K}\\phi_{h}^{\\tau}[\\operatorname*{max}_{\\alpha}\\hat{Q}_{h+1}^{\\rho}(s_{h+1}^{\\tau},a)]_{\\alpha_{i}}\\right)\\right]_{i\\in[d]}\\right|}\\\\ &{\\qquad\\qquad\\leq\\sqrt{d}\\|v\\|_{2}+H\\sqrt{d}\\|v\\|_{2}+\\sqrt{\\left[\\displaystyle\\sum_{\\tau=1}^{K}v^{\\top}\\mathbf{A}_{h}^{-1}v\\right]\\left[\\displaystyle\\sum_{\\tau=1}^{K}(\\phi_{h}^{\\tau})^{\\top}\\mathbf{A}_{h}^{-1}\\phi_{h}^{\\tau}\\right]}\\cdot H}\\\\ &{\\qquad\\qquad\\leq2H\\|v\\|_{2}\\sqrt{d K/\\lambda}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 42}, {"type": "text", "text": "We note that the term $\\begin{array}{r}{\\big[\\big(\\mathbf{A}_{h}^{-1}\\sum_{\\tau=1}^{K}\\phi_{h}^{\\tau}[\\operatorname*{max}_{a}\\widehat{Q}_{h+1}^{\\rho}(s_{h+1}^{\\tau},a)]_{\\alpha_{i}}\\big)_{i}\\big]_{i\\in[d]}}\\end{array}$ in (H.5) is constructed by first taking out the $i$ -th coordinate of the ridge solution vector, $\\begin{array}{r}{\\mathbf{A}_{h}^{-1}\\sum_{\\tau=1}^{K}\\widehat{\\phi}_{h}^{\\tau}[\\operatorname*{max}_{a}\\widehat{Q}_{h+1}^{\\rho}(s_{h+1}^{\\tau},a)]_{\\alpha_{i}}\\in}\\end{array}$ $\\mathbb{R}^{d}$ \uff0c $\\forall i\\in[d]$ , and then concatenating all $d$ values into a vector. Inequality (H.5) is due to the fact that $\\rho\\leq1$ , (H.6) is due to the fact that ${\\widehat{Q}}_{h+1}^{\\rho}\\leq H$ and (H.7) is due to Lemma H.2 with $t=K$ and the fact that the minimum eigenvalue of $\\Lambda_{h}$ is lower bounded by $\\lambda$ .The remainder of the proof follows from the fact that $\\begin{array}{r}{\\|\\pmb{w}_{h}^{\\rho}\\|_{2}^{-}=\\operatorname*{max}_{\\pmb{v}:\\|\\pmb{v}\\|_{2}=1}|\\pmb{v}^{\\top}\\pmb{w}_{h}^{\\rho}|}\\end{array}$ ", "page_idx": 42}, {"type": "text", "text": "H.3 Proof of Lemma G.4 ", "text_level": 1, "page_idx": 42}, {"type": "text", "text": "The proof of Lemma G.4 will use the following fact. ", "page_idx": 42}, {"type": "text", "text": "Lemma H.3. [14, Covering Number of Euclidean Ball] For any $\\epsilon>0$ ,the $\\epsilon$ -covering number of the Euclidean ball in $\\mathbb{R}^{d}$ with radius $R>0$ is upper bounded by $(\\dot{1}+2R/\\epsilon)^{d}$ ", "page_idx": 42}, {"type": "text", "text": "Proof of Lemma G.4. The proof is similar to the proof of Lemma E.3 in [20]. Denote $A=\\beta^{2}\\Sigma_{h}^{-1}$ sowehave ", "page_idx": 42}, {"type": "equation", "text": "$$\n\\mathcal{V}_{h}(\\cdot)=\\operatorname*{max}_{a\\in A}\\Big\\{\\phi(s,a)^{\\top}\\pmb\\theta-\\sum_{i=1}^{d}\\sqrt{\\phi_{i}(s,a)\\mathbf{1}_{i}^{\\top}A\\phi_{i}(s,a)\\mathbf{1}_{i}}\\Big\\}_{[0,H-h+1]},\n$$", "text_format": "latex", "page_idx": 42}, {"type": "text", "text": "for $\\|\\pmb{\\theta}\\|\\leq L,\\|\\pmb{A}\\|\\leq B^{2}\\lambda^{-1}$ . For any two functions $V_{1},V_{2}\\in\\mathcal{V}$ , let them take the form in (H.8) with parameters $(\\pmb{\\theta}_{1},\\mathbf{A}_{1})$ and $(\\pmb{\\theta}_{2},\\pmb{A}_{2})$ , respectively. Then since both $\\{\\cdot\\}_{[0,H-h+1]}$ and $\\mathrm{max}_{a}$ are contraction maps, we have ", "page_idx": 42}, {"type": "equation", "text": "$$\n\\begin{array}{l}{\\displaystyle\\mathrm{dist}(V_{1},V_{2})\\leq\\operatorname*{sup}_{x,a}\\left\\vert\\left[\\theta_{1}^{\\top}\\phi(x,a)-\\sum_{i=1}^{d}\\sqrt{\\phi_{i}(x,a)\\mathbf{1}_{i}^{\\top}A_{1}\\phi_{i}(x,a)\\mathbf{1}_{i}}\\right]\\right.}\\\\ {\\displaystyle\\qquad\\qquad\\left.-\\left[\\theta_{2}^{\\top}\\phi(x,a)-\\sum_{i=1}^{d}\\sqrt{\\phi_{i}(x,a)\\mathbf{1}_{i}^{\\top}A_{2}\\phi_{i}(x,a)\\mathbf{1}_{i}}\\right]\\right\\vert}\\\\ {\\displaystyle\\qquad\\leq\\operatorname*{sup}_{\\phi:\\|\\phi\\|\\leq1}\\left\\vert\\left[\\theta_{1}^{\\top}\\phi-\\sum_{i=1}^{d}\\sqrt{\\phi_{i}\\mathbf{1}_{i}^{\\top}A_{1}\\phi_{i}\\mathbf{1}_{i}}\\right]-\\left[\\theta_{2}^{\\top}\\phi-\\sum_{i=1}^{d}\\sqrt{\\phi_{i}\\mathbf{1}_{i}^{\\top}A_{2}\\phi_{i}\\mathbf{1}_{i}}\\right]\\right\\vert}\\\\ {\\displaystyle\\qquad\\leq\\operatorname*{sup}_{\\phi:\\|\\phi\\|\\leq1}\\left\\vert(\\theta_{1}-\\theta_{2})^{\\top}\\phi\\right\\vert+\\operatorname*{sup}_{\\phi:\\|\\phi\\|\\leq1}\\sum_{i=1}^{d}\\sqrt{\\phi_{i}\\mathbf{1}_{i}^{\\top}(A_{1}-A_{2})\\phi_{i}\\mathbf{1}_{i}}\\right\\vert}\\end{array}\n$$", "text_format": "latex", "page_idx": 42}, {"type": "equation", "text": "$$\n\\begin{array}{l}{\\leq\\|\\pmb{\\theta}_{1}-\\pmb{\\theta}_{2}\\|+\\sqrt{\\|\\pmb{A}_{1}-\\pmb{A}_{2}\\|}\\operatorname*{sup}_{\\phi:\\|\\phi\\|\\leq1}\\sum_{i=1}^{d}\\|\\phi_{i}\\pmb{1}_{i}\\|}\\\\ {\\leq\\|\\pmb{\\theta}_{1}-\\pmb{\\theta}_{2}\\|+\\sqrt{\\|\\pmb{A}_{1}-\\pmb{A}_{2}\\|_{F}},}\\end{array}\n$$", "text_format": "latex", "page_idx": 43}, {"type": "text", "text": "where (H.9) follows from triangular inequlaity and the fact that $|{\\sqrt{x}}-{\\sqrt{y}}|\\leq{\\sqrt{|x-y|}},\\,\\forall x,y\\geq0$ For matrices, $\\|\\cdot\\|$ and $\\|\\cdot\\|_{F}$ denote the matrix operator norm and Frobenius norm respectively. ", "page_idx": 43}, {"type": "text", "text": "Let $\\mathcal{C}_{\\theta}$ be an $\\epsilon/2$ -cover of $\\{\\pmb{\\theta}\\in\\mathbb{R}^{d}|\\|\\pmb{\\theta}\\|_{2}\\leq L\\}$ with respect to the 2-norm, and $\\mathcal{C}_{A}$ be an $\\epsilon^{2}/4$ -cover of $\\{A\\in\\mathbb{R}^{d\\times d}|\\|A\\|_{F}\\leq d^{1/2}B^{2}\\lambda^{-1}\\}$ with respect to the Frobenius norm. By Lemma H.3, we know: ", "page_idx": 43}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\vert\\mathcal{C}_{\\theta}\\vert\\le\\big(1+4L/\\epsilon\\big)^{d},\\quad\\vert\\mathcal{C}_{A}\\vert\\le\\big[1+8d^{1/2}B^{2}/(\\lambda\\epsilon^{2})\\big]^{d^{2}}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 43}, {"type": "text", "text": "By (H.10), for any $V_{1}\\in\\mathcal{V}$ , there exists $\\theta_{2}\\in\\mathcal{C}_{\\theta}$ and $A_{2}\\in{\\mathcal{C}}_{A}$ such that $V_{2}$ parametrized by $(\\pmb{\\theta}_{2},A_{2})$ satisfies $\\mathrm{dist}(V_{1},V_{2})\\le\\epsilon$ . Hence, it holds that $\\mathcal{N}_{\\epsilon}\\leq|\\mathcal{C}_{\\theta}|\\cdot|\\mathcal{C}_{A}|$ , which leads to ", "page_idx": 43}, {"type": "equation", "text": "$$\n\\log\\mathcal{N}_{\\epsilon}\\leq\\log|\\mathcal{C}_{\\mathbf{w}}|+\\log|\\mathcal{C}_{A}|\\leq d\\log(1+4L/\\epsilon)+d^{2}\\log\\left[1+8d^{1/2}B^{2}/(\\lambda\\epsilon^{2})\\right].\n$$", "text_format": "latex", "page_idx": 43}, {"type": "text", "text": "This concludes the proof. ", "page_idx": 43}, {"type": "text", "text": "H.4 Proof of Theorem B.1 ", "text_level": 1, "page_idx": 43}, {"type": "text", "text": "In this section, we give the proof of Theorem B.1, which largely follows the proof of Theorem 5.2, only with minor modifications of the argument of the variance estimation. ", "page_idx": 43}, {"type": "text", "text": "The following lemma bounds the estimation error by reference-advantage decomposition. ", "page_idx": 43}, {"type": "text", "text": "Lemma H.4 (Modified Variance-Aware Reference-Advantage Decomposition). There exist $\\{\\alpha_{i}\\}_{i\\in[d]}$ ,where $\\alpha_{i}\\in[0,H],\\forall i\\in[d]$ ,suchthat ", "page_idx": 43}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{P_{h}(\\cdot\\vert s,a)\\underset{s=1}{\\overset{\\mathrm{inf}}{\\sum}}(\\mathscr{G}_{h}^{\\widehat{V}_{h+1}^{\\rho}}(s,a)_{h,i})\\vert\\mathbb{P}_{h}(\\widehat{V}_{h+1}^{\\rho}(s)\\vert(s,a)-\\underset{P_{h}(\\cdot\\vert s,a)\\leq\\mu_{h,i}^{\\widehat{V}_{h+1}^{\\rho}}(s,a)_{h,i}^{\\rho}}{\\widehat{\\operatorname{in}(s,a)}}\\vert\\mathbb{P}_{h}\\hat{V}_{h+1}^{\\rho}\\vert(s,a)\\vert}\\\\ &{\\leq\\underset{s=1}{\\overset{\\mathrm{in}}{\\sum}}\\vert\\vert\\phi_{i}(s,a)\\mathbf{1}_{i}\\vert\\vert\\underline{{\\mathbf{g}}_{h}^{\\widehat{\\mathbf{u}}^{\\rho}}}\\vert\\vert\\mathbb{E}_{h+1}^{\\mu}\\vert\\vert\\mathbb{E}_{h}^{\\mu}\\vert\\vert_{\\infty}+\\underset{s=1}{\\overset{\\mathrm{in}}{\\sum}}\\vert\\vert\\phi_{i}(s,a)\\mathbf{1}_{i}\\vert\\vert\\underline{{\\mathbf{g}}_{h-1}^{\\lambda}}\\vert\\vert\\displaystyle\\sum_{\\tau=1}^{K}\\frac{\\phi_{h}^{s}\\eta_{h}^{T}\\vert(\\vert\\mathbf{V}_{h+1}^{\\star\\rho}\\vert)_{\\alpha+1}}{\\widehat{\\phi}_{h}^{\\lambda}(s,h_{h}^{\\tau})}\\vert\\Big\\vert\\_{\\mathbf{E}_{h}^{-1}}}\\\\ &{\\quad+\\underset{s=1}{\\overset{\\mathrm{in}}{\\sum}}\\vert\\vert\\phi_{i}(s,a)\\mathbf{1}_{i}\\vert\\vert_{\\mathbf{E}_{h}^{-1}}\\vert\\vert\\mathbb{E}_{h}^{\\mu}\\vert\\vert\\hat{V}_{h+1}^{\\rho}(s)\\vert_{\\alpha+1}-\\vert\\nabla_{h+1}^{*,\\rho}(s)\\vert_{\\alpha,i}\\vert\\Big\\vert_{\\mathbf{E}_{h}^{-1}}}\\\\ &{\\quad+\\underset{i=1}{\\overset{\\mathrm{in}}{\\sum}}\\vert\\vert\\phi_{i}(s,a)\\mathbf{1}_{i}\\vert\\vert_{\\mathbf{E}_{h}^{-1}}\\vert\\vert\\displaystyle\\sum_{\\tau=1}^{K}\\frac{\\phi_{h}^{s}\\eta_{h}^{T}\\vert\\langle\\overline{{V}}_{h+1}^{\\rho}\n$$", "text_format": "latex", "page_idx": 43}, {"type": "text", "text": "where $\\eta_{h}^{\\tau}([f]_{\\alpha_{i}})=\\left([\\mathbb{P}_{h}^{0}[f]_{\\alpha_{i}}](s_{h}^{\\tau},a_{h}^{\\tau})-[f(s_{h+1}^{\\tau})]_{\\alpha_{i}}\\right)$ , for any function $f:S\\to[0,H-1]$ ", "page_idx": 43}, {"type": "text", "text": "Proof of Theorem B.1. To prove this theorem, we bound the estimation error by $\\Gamma_{h}(s,a)$ ,then invoke Lemma D.1 to get the results. First, we bound terms i-iv in Lemma H.4 at each step $\\textit{h}\\in[H]$ respectively to deduce $\\Gamma_{h}(s,a)$ ", "page_idx": 43}, {"type": "text", "text": "Bound i and ii: We set $\\lambda=1/H^{2}$ to ensure that for all $(s,a,h)\\in S\\times A\\times[H]$ ,we have ", "page_idx": 43}, {"type": "equation", "text": "$$\n\\mathrm{i}+\\mathrm{iii}\\le\\sqrt\\lambda\\sqrt{d}H\\sum_{i=1}^{d}\\|\\phi_{i}(s,a)\\mathbf1_{i}\\|_{\\Sigma_{h}^{-1}}=\\sqrt d\\sum_{i=1}^{d}\\|\\phi_{i}(s,a)\\mathbf1_{i}\\|_{\\Sigma_{h}^{-1}}.\n$$", "text_format": "latex", "page_idx": 43}, {"type": "text", "text": "Bound i:For all $(s,a,\\alpha)\\,\\in\\,{\\cal S}\\,\\times\\,{\\cal A}\\,\\times\\,[0,H]$ . by definition we have $\\widehat{\\sigma}_{h}(s,a)\\,\\geq\\,1$ .Thus, for alli $(h,\\tau,i)\\,\\in\\,[H]\\,\\times\\,[K]\\,\\times\\,[d]$ we have $\\bar{\\eta}_{h}^{\\tau}([\\bar{V}_{h+1}^{\\star,\\rho^{*}}]_{\\alpha_{i}})/\\widehat{\\sigma}_{h}(s_{h}^{\\tau},a_{h}^{\\tau})\\;\\le\\;H$ Note that $V_{H+1}^{\\star,\\rho}$ is independent of $\\mathcal{D}$ , we can directly apply Bernstein-type self-normalized concentration inequality ", "page_idx": 43}, {"type": "text", "text": "Lemma I.2 and a union bound to obtain the upper bound. In concrete, we define the filtration $\\mathcal{F}_{\\tau-1,h}\\,=\\,\\sigma(\\{(s_{h}^{j},a_{h}^{j})\\}_{j=1}^{\\tau}\\cup\\{s_{h+1}^{j}\\}_{j=1}^{\\tau-1})$ .Since $V_{h+1}^{\\star,\\rho}$ and $\\widehat{\\sigma}_{h}(s,a)$ are independent of $\\mathcal{D}$ thus $\\eta_{h}^{\\tau}([V_{h+1}^{\\star,\\rho}]_{\\alpha_{i}})/\\widehat{\\sigma}_{h}(s_{h}^{\\tau},a_{h}^{\\tau})$ is meanzeroconditioned on thefitration $\\mathcal{F}_{\\tau-1,h}$ . By Lemma E.1 with $\\alpha=H$ , we have ", "page_idx": 44}, {"type": "equation", "text": "$$\n\\big[\\mathbb{V}_{h}V_{h+1}^{\\star,\\rho}\\big](s,a)-\\tilde{O}\\Big(\\frac{d H^{3}}{\\sqrt{K\\kappa}}\\Big)\\leq\\widehat{\\sigma}_{h}^{2}(s,a)\\leq\\big[\\mathbb{V}_{h}V_{h+1}^{\\star,\\rho}\\big](s,a),\n$$", "text_format": "latex", "page_idx": 44}, {"type": "text", "text": "thus, for any $\\alpha_{i}\\in[0,H]$ , we have ", "page_idx": 44}, {"type": "equation", "text": "$$\n\\big[\\mathbb{V}_{h}[V_{h+1}^{\\star,\\rho}]_{\\alpha i}\\big](s,a)-\\tilde{O}\\Big(\\frac{d H^{3}}{\\sqrt{K\\kappa}}\\Big)\\leq\\big[\\mathbb{V}_{h}V_{h+1}^{\\star,\\rho}\\big](s,a)-\\tilde{O}\\Big(\\frac{d H^{3}}{\\sqrt{K\\kappa}}\\Big)\\leq\\widehat{\\sigma}_{h}^{2}(s,a).\n$$", "text_format": "latex", "page_idx": 44}, {"type": "text", "text": "Further, we have ", "page_idx": 44}, {"type": "equation", "text": "$$\n\\begin{array}{r l r}{\\mathbb{E}\\Big[\\Big(\\frac{\\eta_{h}^{T}\\big([\\hat{V}_{h+1}^{*}]_{\\alpha_{h}}\\big)}{\\hat{\\sigma}_{h}(s_{h}^{*},a_{h}^{*})}\\Big)^{2}\\Big|\\mathcal{F}_{\\tau-1,h}\\Big]=\\frac{\\big[\\mathrm{Var}\\big(V_{h+1}^{*}\\big)_{\\alpha_{h}}\\big](s_{h}^{*},a_{h}^{*})}{\\hat{\\sigma}_{h}^{2}(s_{h}^{*},a_{h}^{*})}}&{\\mathrm{~(H.~}}\\\\ &{\\leq\\frac{\\big[\\mathbb{V}\\big[{V}_{h+1}^{*}\\big]_{\\alpha_{h}}\\big](s_{h}^{*},a_{h}^{*})}{\\hat{\\sigma}_{h}^{2}(s_{h}^{*},a_{h}^{*})}}&{}\\\\ &{=\\frac{\\big[\\mathbb{V}\\big[{V}_{h+1}^{*}\\big]_{\\alpha_{h}}\\big]\\big(s_{h}^{*},a_{h}^{*}\\big)-\\tilde{O}(d H^{3}/\\sqrt{K\\kappa})}{\\hat{\\sigma}_{h}^{2}(s_{h}^{*},a_{h}^{*})}+\\frac{\\tilde{O}(d H^{3}/\\sqrt{K\\kappa})}{\\hat{\\sigma}_{h}^{2}(s_{h}^{*},a_{h}^{*})}}&{}\\\\ &{\\leq1+\\frac{\\tilde{O}(d H^{3})\\sqrt{K\\kappa}}{\\hat{\\sigma}_{h}^{2}(s_{h}^{*},a_{h}^{*})-\\tilde{O}(d H^{3}/\\sqrt{K\\kappa})}}&{\\mathrm{~(H.~}}\\\\ &{\\leq1+2\\tilde{O}\\Big(\\frac{d H^{3}}{\\sqrt{K\\kappa}}\\Big),}&{\\mathrm{~(H.~}}\\end{array}\n$$", "text_format": "latex", "page_idx": 44}, {"type": "text", "text": "where (H.14) holds by the fact that $\\widehat{\\sigma}_{h}^{2}(\\cdot,\\cdot)$ is independent of $\\mathcal{D}$ and $(s_{h}^{\\tau},a_{h}^{\\tau})$ .s $\\mathcal{F}_{\\tau-1,h}$ measurable. (H.15) holds by (H.13), and (H.16) holds by setting $K\\;\\geq\\;\\tilde{\\Omega}(d^{2}H^{6}/\\kappa)$ such that $\\widehat{\\sigma}_{h}^{2}(s_{h}^{\\tau},a_{h}^{\\tau})\\;-$ $\\tilde{O}(d H^{3}/\\sqrt{K\\kappa})\\geq1-\\tilde{O}(d H^{3}/\\sqrt{K\\kappa})\\geq1/2$ . Further, by (H.16), our choice of $K$ also ensures that $\\mathbb{E}\\big[\\big(\\eta_{h}^{\\tau}([V_{h+1}^{\\star,\\rho}]_{\\alpha_{i}})\\big)^{2}|\\mathcal{F}_{\\tau-1,h}\\big]=O(1)$ . Then by Lemma I.2, we have ", "page_idx": 44}, {"type": "equation", "text": "$$\n\\Big\\|\\sum_{\\tau=1}^{K}\\frac{\\phi_{h}^{\\tau}\\eta_{h}^{\\tau}\\big([V_{h+1}^{\\star,\\rho}]_{\\alpha_{i}}\\big)}{\\widehat{\\sigma}_{h}^{2}\\big(s_{h}^{\\tau},a_{h}^{\\tau}\\big)}\\Big\\|_{\\Sigma_{h}^{-1}}\\leq\\tilde{O}(\\sqrt{d}).\n$$", "text_format": "latex", "page_idx": 44}, {"type": "text", "text": "This implies ", "page_idx": 44}, {"type": "equation", "text": "$$\n\\mathrm{ii}\\leq\\tilde{O}(\\sqrt{d})\\sum_{i=1}^{d}\\|\\phi_{i}(s,a)\\mathbf{1}_{i}\\|_{\\Sigma_{h}^{-1}}.\n$$", "text_format": "latex", "page_idx": 44}, {"type": "text", "text": "Boundiv: Following the same induction analysis procedure, we know that $\\|[\\widehat{V}_{h+1}^{\\rho}]_{\\alpha_{i}}-[V_{h+1}^{\\star,\\rho}]_{\\alpha_{i}}\\|\\le$ $\\tilde{O}(\\sqrt{d}H^{2}/\\sqrt{K\\kappa})$ . Using standard $\\epsilon$ -covering number argument and Lemma I.1, we have ", "page_idx": 44}, {"type": "equation", "text": "$$\n\\operatorname{iv}\\leq\\tilde{O}\\Big(\\frac{d^{3/2}H^{2}}{\\sqrt{K\\kappa}}\\Big)\\sum_{i=1}^{d}\\|\\phi_{i}(s,a)\\mathbf{1}_{i}\\|_{\\Sigma_{h}^{-1}}.\n$$", "text_format": "latex", "page_idx": 44}, {"type": "text", "text": "To make it non-dominant, we require $K\\;\\geq\\;\\tilde{\\Omega}(d^{2}H^{4}/\\kappa)$ .By (H.12), we have $\\widehat{\\sigma}_{h}^{2}(s_{h}^{\\tau},a_{h}^{\\tau})\\ \\leq$ $[\\mathbb{V}_{h}V_{h+1}^{\\star}](s_{h}^{\\tau},a_{h}^{\\tau})$ ,which implies that ", "page_idx": 44}, {"type": "equation", "text": "$$\n\\Big(\\sum_{\\tau=1}^{K}\\frac{\\phi_{h}^{\\tau}\\phi_{h}^{\\tau\\top}}{\\widehat{\\sigma}_{h}^{2}(s_{h}^{\\tau},a_{h}^{\\tau})}+\\lambda I\\Big)^{-1}\\preceq\\Big(\\sum_{\\tau=1}^{K}\\frac{\\phi_{h}^{\\tau}\\phi_{h}^{\\tau\\top}}{[\\mathbb{V}_{h}V_{h+1}^{\\star}](s_{h}^{\\tau},a_{h}^{\\tau})}+\\lambda I\\Big)^{-1}.\n$$", "text_format": "latex", "page_idx": 44}, {"type": "text", "text": "Combining (H.11), (H.17) and (H.18), we have ", "page_idx": 44}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\displaystyle\\min_{P_{h}(\\cdot\\,|s,a)\\in\\mathcal{U}_{h}^{\\rho}(s,a;\\mu_{h,i}^{0})}[\\mathbb{P}_{h}\\widehat{V}_{h+1}^{\\rho}](s,a)-\\widehat{\\operatorname*{inf}_{P_{h}(\\cdot\\,|s,a)\\in\\mathcal{U}_{h}^{\\rho}(s,a;\\mu_{h,i}^{0})}}[\\mathbb{P}_{h}\\widehat{V}_{h+1}^{\\rho}](s,a)\\Big|}\\\\ &{\\leq\\tilde{O}(\\sqrt{d})\\displaystyle\\sum_{i=1}^{d}\\|\\phi_{i}(s,a)\\mathbf{1}_{i}\\|_{\\Sigma_{h}^{\\star-1}}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 44}, {"type": "text", "text": "Define $\\begin{array}{r}{\\Gamma_{h}(s,a)=\\tilde{O}(\\sqrt{d})\\sum_{i=1}^{d}\\|\\phi_{i}(s,a)\\mathbf{1}_{i}\\|_{\\Sigma_{h}^{\\star-1}}}\\end{array}$ , we concludes the proof by invoking Lemma D.1. ", "page_idx": 44}, {"type": "text", "text": "Auxiliary Lemmas ", "text_level": 1, "page_idx": 45}, {"type": "text", "text": "Lemma I.1 (Concentration of Self-Normalized Processes). [1, Theorem 1] Let $\\{\\epsilon_{t}\\}_{t=1}^{\\infty}$ be a realvalued stochastic process with corresponding filtration $\\{\\mathcal{F}_{t}\\}_{t=0}^{\\infty}$ . Let $\\epsilon_{t}|\\mathcal{F}_{t-1}$ be mean-zero and $\\sigma$ -subGaussian; i.e. $\\mathbb{E}[\\epsilon_{t}|\\mathcal{F}_{t-1}]=0$ ,and ", "page_idx": 45}, {"type": "equation", "text": "$$\n\\forall\\lambda\\in\\mathbb{R},\\quad\\mathbb{E}[e^{\\lambda\\epsilon_{t}}|\\mathcal{F}_{t-1}]\\leq e^{\\lambda^{2}\\sigma^{2}/2}.\n$$", "text_format": "latex", "page_idx": 45}, {"type": "text", "text": "Let $\\{\\phi_{t}\\}_{t=1}^{\\infty}$ be an $\\mathbb{R}^{d}$ -valued stochastic process where $\\phi_{t}$ .s $\\mathcal{F}_{t-1}$ measurable. Assume $\\Lambda_{0}$ is a $d\\times d$ positive definite matrix, and let $\\begin{array}{r}{\\mathbf{A}_{t}=\\mathbf{A}_{0}+\\sum_{s=1}^{t}\\phi_{s}\\boldsymbol{\\phi}_{s}^{\\top}}\\end{array}$ . Then for any $\\delta>0$ , with probability at least $1-\\delta$ , we have for all $t\\geq0$ ", "page_idx": 45}, {"type": "equation", "text": "$$\n\\bigg\\|\\sum_{s=1}^{t}\\phi_{s}\\epsilon_{s}\\bigg\\|_{\\Lambda_{t}^{-1}}^{2}\\leq2\\sigma^{2}\\log\\bigg[\\frac{\\operatorname*{det}(\\Lambda_{t})^{1/2}\\operatorname*{det}(\\Lambda_{0})^{-1/2}}{\\delta}\\bigg].\n$$", "text_format": "latex", "page_idx": 45}, {"type": "text", "text": "Lemma I.2 (Bernstein inequality for self-normalized martingales). [65, Theorem 2] Let $\\{\\eta_{t}\\}_{t=1}^{\\infty}$ be a real-valued stochastic process. Let $\\{\\mathcal{F}_{t}\\}_{t=0}^{\\infty}$ be a filtration, such that $\\eta_{t}$ is $\\mathcal{F}_{t}$ -measurable. Assume $\\eta_{t}$ also satisfies ", "page_idx": 45}, {"type": "equation", "text": "$$\n|\\eta_{t}|\\leq R,\\mathbb{E}[\\eta_{t}|\\mathcal{F}_{t-1}]=0,\\mathbb{E}[\\eta_{t}^{2}|\\mathcal{F}_{t-1}]\\leq\\sigma^{2}.\n$$", "text_format": "latex", "page_idx": 45}, {"type": "text", "text": "Let $\\{{\\pmb x}_{t}\\}_{t=1}^{\\infty}$ be an $\\mathbb{R}^{d}$ -valued stochastic process where $\\pmb{x}_{t}$ .s $\\mathcal{F}_{t-1}$ measurable and $\\|\\pmb{x}_{t}\\|\\leq L$ . Let $\\begin{array}{r}{\\mathbf{A}_{t}=\\lambda\\mathbf{I}_{d}+\\sum_{s=1}^{t}{x_{s}}\\mathbf{x}_{s}^{\\top}}\\end{array}$ Then for any $\\delta>0$ , with probability at least $1-\\delta$ for all $t>0$ \uff0c ", "page_idx": 45}, {"type": "equation", "text": "$$\n\\bigg\\|\\sum_{s=1}^{t}x_{s}\\eta_{s}\\bigg\\|_{\\Lambda_{t}^{-1}}\\leq8\\sigma\\sqrt{d\\log\\Big(1+\\frac{t L^{2}}{\\lambda d}\\Big)\\cdot\\log\\Big(\\frac{4t^{2}}{\\delta}\\Big)}+4R\\log\\Big(\\frac{4t^{2}}{\\delta}\\Big).\n$$", "text_format": "latex", "page_idx": 45}, {"type": "text", "text": "Lemma I.3. [27, Lemma H.5] Let $\\phi:S\\times A\\rightarrow\\mathbb{R}^{d}$ satisfying $\\left\\|\\phi(x,a)\\right\\|\\leq C$ for all $(x,a)\\in S\\times A$ For any $K>0$ and $\\lambda>0$ , define $\\begin{array}{r}{\\overline{{\\mathbb{G}}}_{K}=\\sum_{k=1}^{K}\\phi(x_{k},a_{k})\\phi(x_{k},a_{k})^{\\top}+\\lambda\\mathbf{I}_{d}}\\end{array}$ where $(x_{k},a_{k})$ 's are i.i.d. samples from some distribution $\\nu$ over $s\\times A$ . Let $\\mathbb{G}=\\mathbb{E}_{v}[\\phi(x,a)\\phi(x,a)^{\\top}]$ . Then, for any $\\delta\\in(0,1)$ , if $K$ satisfies that ", "page_idx": 45}, {"type": "equation", "text": "$$\nK\\geq\\operatorname*{max}\\Big\\{512C^{4}\\big\\|(\\mathbb{G}^{-1}\\big\\|^{2}\\log\\Big(\\frac{2d}{\\delta}\\Big),4\\lambda\\big\\|(\\mathbb{G}^{-1}\\big\\|\\Big\\},\n$$", "text_format": "latex", "page_idx": 45}, {"type": "text", "text": "then with probability at least $1-\\delta$ , it holds simultaneously for all $u\\in\\mathbb{R}^{d}$ that ", "page_idx": 45}, {"type": "equation", "text": "$$\n\\|u\\|_{\\overline{{\\mathbb{G}}}_{K}^{-1}}\\leq\\frac{2}{\\sqrt{K}}\\|u\\|_{\\mathbb{G}^{-1}}.\n$$", "text_format": "latex", "page_idx": 45}, {"type": "text", "text": "NeurIPS Paper Checklist ", "text_level": 1, "page_idx": 46}, {"type": "text", "text": "1. Claims ", "text_level": 1, "page_idx": 46}, {"type": "text", "text": "Question: Do the main claims made in the abstract and introduction accurately refect the paper's contributions and scope? ", "page_idx": 46}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 46}, {"type": "text", "text": "Justification: We accurately summarize the paper's contributions and scope in the abstract and introduction (Section 1). ", "page_idx": 46}, {"type": "text", "text": "Guidelines: ", "page_idx": 46}, {"type": "text", "text": "\u00b7 The answer NA means that the abstract and introduction do not include the claims made in the paper.   \n\u00b7 The abstract and/or introduction should clearly state the claims made, including the contributions made in the paper and important assumptions and limitations. A No or NA answer to this question will not be perceived well by the reviewers.   \n\u00b7 The claims made should match theoretical and experimental results, and reflect how much the results can be expected to generalize to other settings.   \n\u00b7 It is fine to include aspirational goals as motivation as long as it is clear that these goals are not attained by the paper. ", "page_idx": 46}, {"type": "text", "text": "2. Limitations ", "text_level": 1, "page_idx": 46}, {"type": "text", "text": "Question: Does the paper discuss the limitations of the work performed by the authors? ", "page_idx": 46}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 46}, {"type": "text", "text": "Justification: In Section 6, we claim that there are small gaps between the upper bounds in Theorem 4.4 and Theorem 5.2 and lower bound in Theorem 6.1. The computation tractability is discussed in Remark 4.2 in Section 4. The assumptions are formally stated in Assumption 3.1 and Assumption 4.3. ", "page_idx": 46}, {"type": "text", "text": "Guidelines: ", "text_level": 1, "page_idx": 46}, {"type": "text", "text": "\u00b7 The answer NA means that the paper has no limitation while the answer No means that the paper has limitations, but those are not discussed in the paper.   \n\u00b7 The authors are encouraged to create a separate \"Limitations\" section in their paper.   \n\u00b7 The paper should point out any strong assumptions and how robust the results are to violations of these assumptions (e.g., independence assumptions, noiseless settings, model well-specification, asymptotic approximations only holding locally). The authors should refect on how these assumptions might be violated in practice and what the implications would be.   \n\u00b7 The authors should reflect on the scope of the claims made, e.g., if the approach was only tested on a few datasets or with a few runs. In general, empirical results often depend on implicit assumptions, which should be articulated.   \n\u00b7 The authors should refect on the factors that influence the performance of the approach. For example, a facial recognition algorithm may perform poorly when image resolution is low or images are taken in low lighting. Or a speech-to-text system might not be used reliably to provide closed captions for online lectures because it fails to handle technical jargon.   \n\u00b7 The authors should discuss the computational efficiency of the proposed algorithms and how they scale with dataset size.   \n\u00b7 If applicable, the authors should discuss possible limitations of their approach to address problems of privacy and fairness.   \n\u00b7 While the authors might fear that complete honesty about limitations might be used by reviewers as grounds for rejection, a worse outcome might be that reviewers discover limitations that aren't acknowledged in the paper. The authors should use their best judgment and recognize that individual actions in favor of transparency play an important role in developing norms that preserve the integrity of the community. Reviewers will be specifically instructed to not penalize honesty concerning limitations. ", "page_idx": 46}, {"type": "text", "text": "3. Theory Assumptions and Proofs ", "text_level": 1, "page_idx": 46}, {"type": "text", "text": "Question: For each theoretical result, does the paper provide the full set of assumptions and a complete (and correct) proof? ", "page_idx": 47}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 47}, {"type": "text", "text": "Justification: The assumptions are formally stated in Assumption 3.1 and Assumption 4.3.   \nComplete proofs are provided in the appendix. ", "page_idx": 47}, {"type": "text", "text": "Guidelines: ", "page_idx": 47}, {"type": "text", "text": "\u00b7 The answer NA means that the paper does not include theoretical results.   \n\u00b7 All the theorems, formulas, and proofs in the paper should be numbered and crossreferenced.   \n\u00b7 All assumptions should be clearly stated or referenced in the statement of any theorems.   \n\u00b7 The proofs can either appear in the main paper or the supplemental material, but if they appear in the supplemental material, the authors are encouraged to provide a short proof sketch to provide intuition.   \n\u00b7 Inversely, any informal proof provided in the core of the paper should be complemented by formal proofs provided in appendix or supplemental material.   \n\u00b7 Theorems and Lemmas that the proof relies upon should be properly referenced. ", "page_idx": 47}, {"type": "text", "text": "4. Experimental Result Reproducibility ", "text_level": 1, "page_idx": 47}, {"type": "text", "text": "Question: Does the paper fully disclose all the information needed to reproduce the main experimental results of the paper to the extent that it affects the main claims and/or conclusions of the paper (regardless of whether the code and data are provided or not)? ", "page_idx": 47}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 47}, {"type": "text", "text": "Justification: The code of our implementation is available at https : //github.com/ panxulab/Offline-Linear-DRMDP. ", "page_idx": 47}, {"type": "text", "text": "Guidelines: ", "text_level": 1, "page_idx": 47}, {"type": "text", "text": "\u00b7 The answer NA means that the paper does not include experiments.   \n\u00b7 If the paper includes experiments, a No answer to this question will not be perceived well by the reviewers: Making the paper reproducible is important, regardless of whether the code and data are provided or not.   \n\u00b7 If the contribution is a dataset and/or model, the authors should describe the steps taken to make their results reproducible or verifiable.   \n\u00b7 Depending on the contribution, reproducibility can be accomplished in various ways. For example, if the contribution is a novel architecture, describing the architecture fully might suffice, or if the contribution is a specific model and empirical evaluation, it may be necessary to either make it possible for others to replicate the model with the same dataset, or provide access to the model. In general. releasing code and data is often one good way to accomplish this, but reproducibility can also be provided via detailed instructions for how to replicate the results, access to a hosted model (e.g., in the case of a large language model), releasing of a model checkpoint, or other means that are appropriate to the research performed.   \n\u00b7 While NeurIPS does not require releasing code, the conference does require all submissions to provide some reasonable avenue for reproducibility, which may depend on the nature of the contribution. For example (a) If the contribution is primarily a new algorithm, the paper should make it clear how to reproduce that algorithm. (b) If the contribution is primarily a new model architecture, the paper should describe the architecture clearly and fully. () If the contribution is a new model (e.g., a large language model), then there should either be a way to access this model for reproducing the results or a way to reproduce the model (e.g., with an open-source dataset or instructions for how to construct the dataset). (d) We recognize that reproducibility may be tricky in some cases, in which case authors are welcome to describe the particular way they provide for reproducibility. In the case of closed-source models, it may be that access to the model is limited in some way (e.g., to registered users), but it should be possible for other researchers to have some path to reproducing or verifying the results. ", "page_idx": 47}, {"type": "text", "text": "5. Open access to data and code ", "text_level": 1, "page_idx": 48}, {"type": "text", "text": "Question: Does the paper provide open access to the data and code, with sufficient instructions to faithfully reproduce the main experimental results, as described in supplemental material? ", "page_idx": 48}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 48}, {"type": "text", "text": "Justification: The code of our implementation is available at https ://github.com/ panxulab/Offline-Linear-DRMDP. ", "page_idx": 48}, {"type": "text", "text": "Guidelines: ", "page_idx": 48}, {"type": "text", "text": "\u00b7 The answer NA means that paper does not include experiments requiring code.   \n\u00b7 Please see the NeurIPS code and data submission guidelines (https: //nips.cc/ public/guides/CodeSubmissionPolicy) for more details.   \n\u00b7 While we encourage the release of code and data, we understand that this might not be possible, so \u201cNo\" is an acceptable answer. Papers cannot be rejected simply for not including code, unless this is central to the contribution (e.g., for a new open-source benchmark).   \n\u00b7 The instructions should contain the exact command and environment needed to run to reproduce the results. See the NeurIPS code and data submission guidelines (https : / /nips.cc/public/guides/CodeSubmissionPolicy) for more details.   \n\u00b7 The authors should provide instructions on data access and preparation, including how to access the raw data, preprocessed data, intermediate data, and generated data, etc.   \n\u00b7 The authors should provide scripts to reproduce all experimental results for the new proposed method and baselines. If only a subset of experiments are reproducible, they should state which ones are omitted from the script and why.   \n\u00b7 At submission time, to preserve anonymity, the authors should release anonymized versions (if applicable).   \n\u00b7 Providing as much information as possible in supplemental material (appended to the paper) is recommended, but including URLs to data and code is permitted. ", "page_idx": 48}, {"type": "text", "text": "6. Experimental Setting/Details ", "text_level": 1, "page_idx": 48}, {"type": "text", "text": "Question: Does the paper specify all the training and test details (e.g., data splits, hyperparameters, how they were chosen, type of optimizer, etc.) necessary to understand the results? ", "page_idx": 48}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 48}, {"type": "text", "text": "Justification: The code of our implementation is available at https: //github. com/ panxulab/Offline- Linear-DRMDP. ", "page_idx": 48}, {"type": "text", "text": "Guidelines: ", "page_idx": 48}, {"type": "text", "text": "\u00b7 The answer NA means that the paper does not include experiments. \u00b7 The experimental setting should be presented in the core of the paper to a level of detail that is necessary to appreciate the results and make sense of them. \u00b7 The full details can be provided either with the code, in appendix, or as supplemental material. ", "page_idx": 48}, {"type": "text", "text": "7. Experiment Statistical Significance ", "text_level": 1, "page_idx": 48}, {"type": "text", "text": "Question: Does the paper report error bars suitably and correctly defined or other appropriate information about the statistical significance of the experiments? ", "page_idx": 48}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 48}, {"type": "text", "text": "Justification: Not applicable to our experiments. ", "page_idx": 48}, {"type": "text", "text": "Guidelines: ", "page_idx": 48}, {"type": "text", "text": "\u00b7 The answer NA means that the paper does not include experiments. \u00b7 The authors should answer \"Yes\" if the results are accompanied by error bars, confidence intervals, or statistical significance tests, at least for the experiments that support the main claims of the paper. ", "page_idx": 48}, {"type": "text", "text": "\u00b7 The factors of variability that the error bars are capturing should be clearly stated (for example, train/test split, initialization, random drawing of some parameter, or overall run with given experimental conditions).   \n\u00b7 The method for calculating the error bars should be explained (closed form formula, call to a library function, bootstrap, etc.)   \n\u00b7 The assumptions made should be given (e.g., Normally distributed errors).   \n\u00b7 It should be clear whether the error bar is the standard deviation or the standard error of the mean.   \n\u00b7 It is OK to report 1-sigma error bars, but one should state it. The authors should preferably report a 2-sigma error bar than state that they have a $96\\%$ CI, if the hypothesis of Normality of errors is not verified.   \n\u00b7 For asymmetric distributions, the authors should be careful not to show in tables or figures symmetric error bars that would yield results that are out of range (e.g. negative error rates).   \n\u00b7 If error bars are reported in tables or plots, The authors should explain in the text how they were calculated and reference the corresponding figures or tables in the text. ", "page_idx": 49}, {"type": "text", "text": "8. Experiments Compute Resources ", "text_level": 1, "page_idx": 49}, {"type": "text", "text": "Question: For each experiment, does the paper provide sufficient information on the computer resources (type of compute workers, memory, time of execution) needed to reproduce the experiments? ", "page_idx": 49}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 49}, {"type": "text", "text": "Justification: All information is provided in the experiment section and the code of our implementation is available at https : //github. com/panxulab/Offline-Linear-DRMDP. ", "page_idx": 49}, {"type": "text", "text": "Guidelines: ", "page_idx": 49}, {"type": "text", "text": "\u00b7 The answer NA means that the paper does not include experiments.   \n\u00b7 The paper should indicate the type of compute workers CPU or GPU, internal cluster, or cloud provider, including relevant memory and storage.   \n\u00b7 The paper should provide the amount of compute required for each of the individual experimental runs as well as estimate the total compute.   \n\u00b7 The paper should disclose whether the full research project required more compute than the experiments reported in the paper (e.g., preliminary or failed experiments that didn't make it into the paper). ", "page_idx": 49}, {"type": "text", "text": "9. Code Of Ethics ", "text_level": 1, "page_idx": 49}, {"type": "text", "text": "Question: Does the research conducted in the paper conform, in every respect, with the NeurIPS Code of Ethics https: //neurips.cc/public/EthicsGuidelines? ", "page_idx": 49}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 49}, {"type": "text", "text": "Justification: the authors had reviewed the NeurIPs Code of Ethics and confirm that the research conducted in the paper conform, in every respect, with the NeurIPs Code of Ethics. Guidelines: ", "page_idx": 49}, {"type": "text", "text": "\u00b7 The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics.   \n\u00b7 If the authors answer No, they should explain the special circumstances that require a deviation from the Code of Ethics.   \n\u00b7 The authors should make sure to preserve anonymity (e.g., if there is a special consideration due to laws or regulations in their jurisdiction). ", "page_idx": 49}, {"type": "text", "text": "10. Broader Impacts ", "text_level": 1, "page_idx": 49}, {"type": "text", "text": "Question: Does the paper discuss both potential positive societal impacts and negative societal impacts of the work performed? ", "page_idx": 49}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 49}, {"type": "text", "text": "Justification: this work focuses on the theoretical side of robust RL, and methods in this paper do not lead to a direct path to any negative applications. ", "page_idx": 49}, {"type": "text", "text": "Guidelines: ", "page_idx": 49}, {"type": "text", "text": "\u00b7 The answer NA means that there is no societal impact of the work performed.   \n\u00b7 If the authors answer NA or No, they should explain why their work has no societal impact or why the paper does not address societal impact.   \n\u00b7 Examples of negative societal impacts include potential malicious or unintended uses (e.g., disinformation, generating fake profiles, surveillance), fairness considerations (e.g., deployment of technologies that could make decisions that unfairly impact specific groups), privacy considerations, and security considerations.   \n\u00b7 The conference expects that many papers will be foundational research and not tied to particular applications, let alone deployments. However, if there is a direct path to any negative applications, the authors should point it out. For example, it is legitimate to point out that an improvement in the quality of generative models could be used to generate deepfakes for disinformation. On the other hand, it is not needed to point out that a generic algorithm for optimizing neural networks could enable people to train models that generate Deepfakes faster.   \n\u00b7 The authors should consider possible harms that could arise when the technology is being used as intended and functioning correctly, harms that could arise when the technology is being used as intended but gives incorrect results, and harms following from (intentional or unintentional) misuse of the technology.   \n\u00b7 If there are negative societal impacts, the authors could also discuss possible mitigation strategies (e.g., gated release of models, providing defenses in addition to attacks, mechanisms for monitoring misuse, mechanisms to monitor how a system learns from feedback over time, improving the efficiency and accessibility of ML). ", "page_idx": 50}, {"type": "text", "text": "11. Safeguards ", "text_level": 1, "page_idx": 50}, {"type": "text", "text": "Question: Does the paper describe safeguards that have been put in place for responsible release of data or models that have a high risk for misuse (e.g., pretrained language models, image generators, or scraped datasets)? ", "page_idx": 50}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 50}, {"type": "text", "text": "Justification: the paper poses no such risks. Guidelines: ", "page_idx": 50}, {"type": "text", "text": "\u00b7 The answer NA means that the paper poses no such risks.   \n\u00b7 Released models that have a high risk for misuse or dual-use should be released with necessary safeguards to allow for controlled use of the model, for example by requiring that users adhere to usage guidelines or restrictions to access the model or implementing safetyfilters.   \n\u00b7 Datasets that have been scraped from the Internet could pose safety risks. The authors should describe how they avoided releasing unsafe images.   \n\u00b7 We recognize that providing effective safeguards is challenging, and many papers do not require this, but we encourage authors to take this into account and make a best faith effort. ", "page_idx": 50}, {"type": "text", "text": "12. Licenses for existing assets ", "text_level": 1, "page_idx": 50}, {"type": "text", "text": "Question: Are the creators or original owners of assets (e.g., code, data, models), used in the paper, properly credited and are the license and terms of use explicitly mentioned and properlyrespected? ", "page_idx": 50}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 50}, {"type": "text", "text": "Justification: the paper does not use existing assets. Guidelines: ", "page_idx": 50}, {"type": "text", "text": "\u00b7 The answer NA means that the paper does not use existing assets.   \n\u00b7 The authors should cite the original paper that produced the code package or dataset.   \n\u00b7 The authors should state which version of the asset is used and, if possible, include a URL.   \n\u00b7 The name of the license (e.g., CC-BY 4.0) should be included for each asset.   \n\u00b7 For scraped data from a particular source (e.g., website), the copyright and terms of service of that source should be provided.   \n\u00b7 If assets are released, the license, copyright information, and terms of use in the package should be provided. For popular datasets, paperswithcode . com/datasets has curated licenses for some datasets. Their licensing guide can help determine the license of a dataset.   \n\u00b7 For existing datasets that are re-packaged, both the original license and the license of the derived asset (if it has changed) should be provided.   \n\u00b7 If this information is not available online, the authors are encouraged to reach out to the asset's creators. ", "page_idx": 50}, {"type": "text", "text": "", "page_idx": 51}, {"type": "text", "text": "13. New Assets ", "text_level": 1, "page_idx": 51}, {"type": "text", "text": "Question: Are new assets introduced in the paper well documented and is the documentation provided alongside the assets? ", "page_idx": 51}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 51}, {"type": "text", "text": "Justification: the paper does not release new assets. ", "page_idx": 51}, {"type": "text", "text": "Guidelines: ", "page_idx": 51}, {"type": "text", "text": "\u00b7 The answer NA means that the paper does not release new assets.   \n\u00b7 Researchers should communicate the details of the dataset/code/model as part of their submissions via structured templates. This includes details about training, license, limitations, etc.   \n\u00b7 The paper should discuss whether and how consent was obtained from people whose assetisused.   \n\u00b7 At submission time, remember to anonymize your assets (if applicable). You can either create an anonymized URL or include an anonymized zip file. ", "page_idx": 51}, {"type": "text", "text": "14. Crowdsourcing and Research with Human Subjects ", "text_level": 1, "page_idx": 51}, {"type": "text", "text": "Question: For crowdsourcing experiments and research with human subjects, does the paper include the full text of instructions given to participants and screenshots, if applicable, as well as details about compensation (if any)? ", "page_idx": 51}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 51}, {"type": "text", "text": "Justification: the paper does not involve crowdsourcing nor research with human subjects. Guidelines: ", "page_idx": 51}, {"type": "text", "text": "\u00b7 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u00b7 Including this information in the supplemental material is fine, but if the main contribution of the paper involves human subjects, then as much detail as possible should be included in the main paper.   \n\u00b7 According to the NeurIPS Code of Ethics, workers involved in data collection, curation, or other labor should be paid at least the minimum wage in the country of the data collector. ", "page_idx": 51}, {"type": "text", "text": "15. Institutional Review Board (IRB) Approvals or Equivalent for Research with Human Subjects ", "text_level": 1, "page_idx": 51}, {"type": "text", "text": "Question: Does the paper describe potential risks incurred by study participants, whether such risks were disclosed to the subjects, and whether Institutional Review Board (IRB) approvals (or an equivalent approval/review based on the requirements of your country or institution)were obtained? ", "page_idx": 51}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 51}, {"type": "text", "text": "Justification: the paper does not involve crowdsourcing nor research with human subjects. Guidelines: ", "page_idx": 51}, {"type": "text", "text": "\u00b7 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u00b7 Depending on the country in which research is conducted, IRB approval (or equivalent) may be required for any human subjects research. If you obtained IRB approval, you should clearly state this in the paper.   \n\u00b7 We recognize that the procedures for this may vary significantly between institutions and locations, and we expect authors to adhere to the NeurIPs Code of Ethics and the guidelines for their institution.   \n\u00b7 For initial submissions, do not include any information that would break anonymity (if applicable), such as the institution conducting the review. ", "page_idx": 51}, {"type": "text", "text": "", "page_idx": 52}]