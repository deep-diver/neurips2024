[{"figure_path": "AO5MjDuHpr/tables/tables_6_1.jpg", "caption": "Table 2: Few shot classification results with 16 shots.", "description": "This table presents the results of few-shot image classification experiments conducted using 16 shots per class.  It compares the performance of several different methods, including CLIP, CoOp, Co-CoOp, MaPLe, PSRC and TAP, across eleven diverse datasets. Each dataset's results are broken down by base and novel class accuracy, and the harmonic mean of these two.  The table allows for a direct comparison of performance between different methods on varied image classification tasks.", "section": "4 Experiments"}, {"figure_path": "AO5MjDuHpr/tables/tables_7_1.jpg", "caption": "Table 5: Effects of the number of experts.", "description": "This table presents the ablation study on the impact of varying the number of expert tokens used in the TAP model.  It shows the base accuracy, novel accuracy, and harmonic mean (HM) across different numbers of attributes (1-8), comparing against the proposed TAP model's performance (Our). The results demonstrate the effect of attribute granularity on performance in base-to-novel generalization.", "section": "4.3 Ablation Study"}, {"figure_path": "AO5MjDuHpr/tables/tables_8_1.jpg", "caption": "Table 6: Design choice of the pooling layer.", "description": "This table presents the ablation study on different pooling methods used in the TAP model.  It compares the performance of three pooling methods: Attention Max Pooling, Average Pooling, and the proposed Vision-Conditional Pooling (VCP). The performance is measured using Base Accuracy, Novel Accuracy, and Harmonic Mean (HM) across 11 datasets.  The results demonstrate that VCP significantly outperforms the other two methods, highlighting its effectiveness in selecting the most relevant descriptions for image classification.", "section": "4.4 Visualization"}]