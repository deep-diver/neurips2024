[{"figure_path": "lS9e36lkxG/figures/figures_4_1.jpg", "caption": "Figure 1: The diagram depicts the training process of the embedding space. Specifically, after a noise perturbation, each instance undergoes mapping via an embedding function z\u03b8. The embedding is then incorporated into a conditional diffusion model for noise prediction. The parameters of the noise model \u03b5\u03c6 and the embedding function z\u03b8 are concurrently optimized using the reconstruction loss. Additionally, the instance is subjected to mapping through a random linear projection into an alternate metric space. Two distinct Random projections are generated for numerical and categorical features, respectively. We align the distances in the embedding space and the random projection space using the RDM loss to ensure that the embedding function effectively preserves distance information, which is beneficial for downstream classification tasks.", "description": "This figure illustrates the training process of the embedding space in the D2R2 model.  It shows how numerical and categorical features are processed, undergoing noise perturbation and random projection before feeding into a conditional diffusion model for noise prediction. The model's parameters are optimized using reconstruction and random distance matching (RDM) loss to preserve distance information in the embedding space, which is crucial for effective downstream classification.", "section": "4.1 Diffusion-based representation Learning"}, {"figure_path": "lS9e36lkxG/figures/figures_6_1.jpg", "caption": "Figure 2: An illustration of the rationale behind instance-wise prototype. (a): In 2-shot scenarios, shapes represent the ground-truth classes in the embedding space, while the gray-colored objects await classification. (b): If the embedding of the circle class is not unimodal, averaging the prototypes leads to erroneous center suggestions and fails to classify the embeddings. (c): Considering instance-wise prototypes, each prototype contributes to the classification of nearby embeddings without generating erroneous centers.", "description": "This figure illustrates the difference between using center-wise prototypes and instance-wise prototypes in a 2-shot classification scenario.  Center-wise prototypes, which average embeddings of all support samples for a class, fail to handle multimodality in embeddings and lead to inaccurate classification when clusters within a single class are not well-separated. Instance-wise prototypes, on the other hand, leverage the weighted average of query embeddings and support embeddings to iteratively refine prototypes and are more robust to such multimodal situations, significantly improving classification accuracy.", "section": "4.3 Instance-wise iterative prototype"}, {"figure_path": "lS9e36lkxG/figures/figures_9_1.jpg", "caption": "Figure 3: The t-SNE visualizations depict the D2R2 representations, with point clouds illustrating the embeddings of 1000 randomly selected samples, color-coded based on their respective class labels. We observe that the embeddings exhibit multimodal patterns. For instance, in the dna dataset, the red class is distributed in both the bottom right corner and the top left corner.", "description": "This figure shows t-SNE visualizations of the D2R2 embeddings for four datasets: Optdigits, Karkunen, Dna, and Income. Each point represents a randomly selected sample, and the color indicates its class label.  The visualizations reveal that the embeddings often exhibit multimodality, meaning that samples from the same class are not clustered tightly together but rather spread across multiple distinct regions in the embedding space. This multimodality is particularly evident in the 'dna' dataset, where points of the red class appear in two separate clusters.", "section": "5.3 Ablation study"}]