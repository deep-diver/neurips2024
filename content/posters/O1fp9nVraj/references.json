{"references": [{"fullname_first_author": "G. Irving", "paper_title": "AI safety via debate", "publication_date": "2018-05-00", "reason": "This paper introduces the core concept of using debate as a scalable oversight method for AI safety, which is the central focus of the current paper."}, {"fullname_first_author": "P. Christiano", "paper_title": "Supervising strong learners by amplifying weak experts", "publication_date": "2018-10-00", "reason": "This paper lays the groundwork for scalable oversight, a key concept motivating the research on debate as a scalable oversight mechanism."}, {"fullname_first_author": "A. Khan", "paper_title": "Debating with more persuasive LLMs leads to more truthful answers", "publication_date": "2024-02-00", "reason": "This paper is the closest prior work to the current study, also using LLMs in debate for scalable oversight, but focusing on a single task with information asymmetry."}, {"fullname_first_author": "S. R. Bowman", "paper_title": "Measuring progress on scalable oversight for large language models", "publication_date": "2022-11-00", "reason": "This paper provides a framework for evaluating scalable oversight methods, which the current paper uses to structure its experimental evaluation."}, {"fullname_first_author": "J. Michael", "paper_title": "Debate helps supervise unreliable experts", "publication_date": "2023-11-00", "reason": "This paper is a recent and relevant study that explores the use of debate for scalable oversight, providing a comparison point for the current study's findings."}]}