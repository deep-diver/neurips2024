{"references": [{"fullname_first_author": "Nicolas Carion", "paper_title": "End-to-end object detection with transformers", "publication_date": "2020-00-00", "reason": "This paper introduces a novel end-to-end object detection method using transformers, a crucial building block for the EZ-HOI framework."}, {"fullname_first_author": "Alec Radford", "paper_title": "Learning transferable visual models from natural language supervision", "publication_date": "2021-00-00", "reason": "CLIP, introduced in this paper, is a foundational vision-language model that EZ-HOI leverages and adapts for zero-shot HOI detection."}, {"fullname_first_author": "Yu-Wei Chao", "paper_title": "Learning to detect human-object interactions", "publication_date": "2018-00-00", "reason": "The HICO-DET dataset, introduced in this paper, is the primary benchmark dataset used for evaluating EZ-HOI's performance."}, {"fullname_first_author": "Georgia Gkioxari", "paper_title": "Detecting and recognizing human-object interactions", "publication_date": "2018-00-00", "reason": "This paper presents a pioneering approach to HOI detection, which EZ-HOI builds upon and improves with its novel prompt-learning framework."}, {"fullname_first_author": "Zhi Hou", "paper_title": "Visual compositional learning for human-object interaction detection", "publication_date": "2020-00-00", "reason": "This paper proposes a visual compositional learning method for HOI detection that is relevant to and contrasted against the EZ-HOI's approach."}]}