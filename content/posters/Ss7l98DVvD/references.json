{"references": [{"fullname_first_author": "Ben Mildenhall", "paper_title": "Nerf: Representing scenes as neural radiance fields for view synthesis", "publication_date": "2021-00-00", "reason": "This paper introduces Neural Radiance Fields (NeRF), a foundational technique for novel view synthesis that Wild-GS builds upon and improves."}, {"fullname_first_author": "Ricardo Martin-Brualla", "paper_title": "Nerf in the wild: Neural radiance fields for unconstrained photo collections", "publication_date": "2021-00-00", "reason": "This paper addresses the challenges of applying NeRF to unconstrained real-world photos, a problem that Wild-GS directly tackles and improves upon."}, {"fullname_first_author": "Eric R Chan", "paper_title": "Efficient geometry-aware 3d generative adversarial networks", "publication_date": "2022-00-00", "reason": "This paper introduces the triplane representation, a key component of Wild-GS's approach to efficiently encoding and leveraging appearance information from reference images."}, {"fullname_first_author": "Bernhard Kerbl", "paper_title": "3d gaussian splatting for real-time radiance field rendering", "publication_date": "2023-00-00", "reason": "This paper introduces 3D Gaussian Splatting (3DGS), the core rendering technique that Wild-GS adapts and extends for handling real-world, unconstrained photo collections."}, {"fullname_first_author": "Xingyu Chen", "paper_title": "Hallucinated neural radiance fields in the wild", "publication_date": "2022-00-00", "reason": "This paper is another important reference addressing novel view synthesis from in-the-wild images that Wild-GS uses for comparison and builds upon."}]}