{"references": [{"fullname_first_author": "B. Amos", "paper_title": "Input convex neural networks", "publication_date": "2017-08-06", "reason": "This paper introduces input convex neural networks (ICNNs), a fundamental building block for the proposed bi-Lipschitz neural network architecture."}, {"fullname_first_author": "Y. Gal", "paper_title": "Dropout as a Bayesian approximation: Representing model uncertainty in deep learning", "publication_date": "2016-06-20", "reason": "This paper is highly relevant to the uncertainty estimation section, providing a baseline method for comparison and context for the proposed DUQ+BLNN approach."}, {"fullname_first_author": "B. Lakshminarayanan", "paper_title": "Simple and scalable predictive uncertainty estimation using deep ensembles", "publication_date": "2017-00-00", "reason": "The deep ensemble method is used as a key comparison technique in the paper's uncertainty estimation experiments, highlighting the advantages of the proposed approach."}, {"fullname_first_author": "J. Behrmann", "paper_title": "Invertible residual networks", "publication_date": "2019-06-09", "reason": "Invertible residual networks are a significant prior work in the field of bi-Lipschitz neural networks, and the paper explicitly builds upon this foundation, comparing its approach to i-ResNet."}, {"fullname_first_author": "Y. Kinoshita", "paper_title": "Controlling posterior collapse by an inverse Lipschitz constraint on the decoder network", "publication_date": "2023-07-23", "reason": "This paper introduces a key concept of inverse Lipschitzness, which directly informs the design and theoretical foundation of the proposed bi-Lipschitz neural network."}]}