[{"figure_path": "yxOrSmS5wR/tables/tables_7_1.jpg", "caption": "Table 1: Comparison of AV-Cloud with state-of-the-art methods. For each metric, the top1 value is highlighted in bold, the second best is underlined, lower is better.", "description": "This table compares the performance of the proposed AV-Cloud model against several state-of-the-art baselines across two datasets, RWAVS and Replay-NVAS.  The metrics used evaluate various aspects of spatial audio reconstruction quality, including magnitude spectrogram distance, left-right energy ratio error, energy envelope error, reverberation time error, and deep perceptual audio metric. The table also shows the number of parameters, frames per second (FPS) achieved, and whether pre-rendered images were used for each method.  Lower values indicate better performance for all metrics except FPS, for which higher values are preferred. The results demonstrate that AV-Cloud outperforms the baselines across most metrics.", "section": "4.2 Comparison with Baselines"}, {"figure_path": "yxOrSmS5wR/tables/tables_8_1.jpg", "caption": "Table 2: Ablations on RWAVS validation set.", "description": "This ablation study analyzes the impact of different components of the AV-Cloud model on its performance using the RWAVS validation set.  It compares the full AV-Cloud model to versions where key modules (AVCS, Time Filters, Audio Embedding, RGB features, and the two-mask structure) or layers (Conv2D layers) are removed or altered.  The results show the contribution of each component to the overall accuracy, highlighting the importance of the AVCS module, the two-mask design and the Time Filters in achieving the optimal performance. The lower the value for each metric the better.", "section": "4.3 Ablation Studies"}, {"figure_path": "yxOrSmS5wR/tables/tables_8_2.jpg", "caption": "Table 3: Human Study for In-the-Wild Experiments. AV-Cloud is preferred over the other two methods by a large margin.", "description": "This table presents the results of a human study comparing AV-Cloud's performance to two other methods (NAF and AVNeRF) in real-world scenarios.  Participants viewed videos with spatial audio rendered by each method and selected the video whose sound best matched the visual perspective. AV-Cloud significantly outperformed the other two methods, demonstrating its effectiveness in producing realistic and synchronized audio-visual experiences.", "section": "4 Experiments"}, {"figure_path": "yxOrSmS5wR/tables/tables_14_1.jpg", "caption": "Table 1: Comparison of AV-Cloud with state-of-the-art methods. For each metric, the top1 value is highlighted in bold, the second best is underlined, lower is better.", "description": "This table compares the performance of the proposed AV-Cloud method against several state-of-the-art baselines on two real-world datasets, RWAVS and Replay-NVAS.  The metrics used assess various aspects of audio reconstruction quality, including magnitude spectrogram distance, left-right energy ratio error, energy envelope error, reverberation time error, and deep perceptual audio metric.  The table also shows the number of parameters and inference speed (FPS) for each method. Lower values generally indicate better performance for each metric.  Different variants of the AV-Cloud model are also included for comparison.", "section": "4.2 Comparison with Baselines"}, {"figure_path": "yxOrSmS5wR/tables/tables_15_1.jpg", "caption": "Table 5: Ablation studies of Spherical Harmonics (SH) degree on RWAVS validation set.", "description": "This table presents the ablation study results on the RWAVS validation set, focusing on the impact of varying the Spherical Harmonics (SH) degree in the Time Filters component of the Spatial Audio Render Head (SARH).  It shows the model performance metrics (MAG, LRE, ENV, RTE, DPAM) for different SH degrees (1, 2, and 3), indicating how changes in the SH degree affect the accuracy of spatial audio rendering.", "section": "4.3 Ablation Studies"}, {"figure_path": "yxOrSmS5wR/tables/tables_15_2.jpg", "caption": "Table 6: Robustness analysis of Audio-Visual Anchor density on RWAVS validation set.", "description": "This table presents the results of an ablation study on the impact of varying the number of Audio-Visual Anchors on the performance of the AV-Cloud model.  The study varied the number of anchors (N) from 64 to 512 and measured the performance using five metrics: Magnitude Spectrogram Distance (MAG), Left-Right Energy Ratio Error (LRE), Energy Envelope Error (ENV), RT60 Error (RTE), and Deep Perceptual Audio Metric (DPAM).  The results show that increasing the number of anchors from 64 to 256 improves performance on several metrics, but further increasing the number of anchors does not yield consistent improvements.", "section": "4. Experiments"}]