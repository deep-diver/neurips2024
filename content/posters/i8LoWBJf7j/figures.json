[{"figure_path": "i8LoWBJf7j/figures/figures_7_1.jpg", "caption": "Figure 1: Unrolling of GTV-based signal interpolation algorithm.", "description": "This figure illustrates the proposed deep algorithm unrolling approach.  Part (a) shows the overall architecture, where multiple ADMM blocks are chained together, interspersed with graph learning modules. Each ADMM block refines the signal estimate iteratively, using a learned graph to guide the interpolation process.  The graph learning modules dynamically adjust the graph structure based on the current signal estimate. Part (b) zooms into a single ADMM block and shows the internal workings of each block. The block receives an input signal and employs a conjugate gradient algorithm, (CG), to iteratively update the main variables in an alternating direction method of multipliers (ADMM) framework. Part (c) shows a single ADMM layer. The variables z, x, q, q, and \u03bc are updated iteratively within each ADMM block using equations (17) through (22) from the paper. The process starts with a set of observed samples (y) and a learned graph, and then iterative updates yield the final interpolated signal (x*). The whole network is trained end-to-end using backpropagation.", "section": "5.3 Deep Algorithm Unrolling"}, {"figure_path": "i8LoWBJf7j/figures/figures_8_1.jpg", "caption": "Figure 1: Unrolling of GTV-based signal interpolation algorithm.", "description": "This figure illustrates the unrolling of the GTV-based signal interpolation algorithm.  Panel (a) shows the overall architecture, depicting the sequential application of ADMM blocks and graph learning modules. Each ADMM block (b) comprises multiple ADMM layers, which iteratively update variables through conjugate gradient (CG) steps and thresholding operations, guided by a learned graph. The graph learning module (c) learns the graph structure from data by using shallow CNNs to extract features, calculate Mahalanobis distances, and create normalized edge weights, reflecting the relationships between data points. The process repeats over 'T' iterations to produce the final interpolated signal.", "section": "5.3 Deep Algorithm Unrolling"}, {"figure_path": "i8LoWBJf7j/figures/figures_16_1.jpg", "caption": "Figure 1: Unrolling of GTV-based signal interpolation algorithm.", "description": "This figure illustrates the unrolling of the GTV-based signal interpolation algorithm.  Part (a) shows the overall architecture, where multiple ADMM blocks are sequentially stacked to represent the iterative nature of the algorithm. Each ADMM block contains several ADMM layers, as detailed in part (b), which process the input signal iteratively.  Part (c) shows the details of an individual ADMM layer. The graph learning module updates the graph structure at each step of the algorithm, and backpropagation optimizes the network parameters to improve performance. The whole network is built by stacking these ADMM and graph learning blocks in order to reconstruct the signal with higher precision. ", "section": "5.3 Deep Algorithm Unrolling"}, {"figure_path": "i8LoWBJf7j/figures/figures_17_1.jpg", "caption": "Figure 4: Visual demosaicking results for image Urban062.", "description": "This figure shows visual comparisons of demosaicking results for the image Urban100: image062.png.  The results from the proposed methods (uGTV and uGLR) are compared to the iterative GTV method (iGTV) and the baseline methods RST-B and RST-S. The red box in the left image highlights the area being zoomed in on for the detailed comparisons.", "section": "6.2 Experimental Results"}]