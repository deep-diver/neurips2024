{"references": [{"fullname_first_author": "Chuan Guo", "paper_title": "Generating diverse and natural 3d human motions from text", "publication_date": "2022-06-01", "reason": "This paper provides the large-scale motion skeleton data used for simulating motion time series in the UniMTS model, a crucial foundation for the model's pre-training."}, {"fullname_first_author": "Alec Radford", "paper_title": "Learning transferable visual models from natural language supervision", "publication_date": "2021-07-01", "reason": "The CLIP model from this paper is used for encoding text descriptions of motion activities, providing semantic information crucial for contrastive learning in UniMTS."}, {"fullname_first_author": "Ranak Roy Chowdhury", "paper_title": "Tarnet: Task-aware reconstruction for time-series transformer", "publication_date": "2022-08-01", "reason": "The TARNet model, proposed by the same research group, is used as a comparison baseline in the experimental section. It showcases the state-of-the-art performance achieved by UniMTS."}, {"fullname_first_author": "George Zerveas", "paper_title": "A transformer-based framework for multivariate time series representation learning", "publication_date": "2021-08-01", "reason": "This paper provides another time series representation learning method used as a comparison baseline, highlighting the novelty and effectiveness of UniMTS\u2019s approach."}, {"fullname_first_author": "Francisco Javier Ord\u00f3\u00f1ez", "paper_title": "Deep convolutional and lstm recurrent neural networks for multimodal wearable activity recognition", "publication_date": "2016-01-01", "reason": "This paper is one of the earliest works in deep learning for activity recognition from wearable sensors and serves as a comparison baseline, showing the superior performance of UniMTS."}]}