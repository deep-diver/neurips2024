{"importance": "This paper is crucial for researchers working with large vision-language models (LVLMs). It introduces a novel benchmark, **ConBench**, for evaluating the consistency of LVLMs, a critical aspect often overlooked in previous research. The findings highlight significant consistency issues in existing LVLMs and propose a practical method for improvement. This work will **accelerate research** in this critical area, helping build more reliable and trustworthy multimodal AI systems.", "summary": "ConBench: Unveiling Inconsistency in Large Vision-Language Models", "takeaways": ["LVLMs show inconsistency across different prompt types.", "ConBench, a new benchmark, reveals this inconsistency and its correlation with prompt size and model type.", "A trigger-based method improves LVLMs' consistency without retraining."], "tldr": "Large vision-language models (LVLMs) are rapidly advancing, but a critical issue\u2014their inconsistency in answering the same question phrased differently\u2014has been largely ignored.  This paper tackles this problem by introducing ConBench, a new benchmark designed to specifically assess this consistency across different prompt types.  ConBench evaluates LVLMs on various visual question answering tasks, revealing a significant gap between their performance on simple prompts and complex, more open-ended ones.\nThe researchers found that larger solution spaces lead to lower accuracy, and there's a positive correlation between the discriminative and generative consistency of LVLMs.  Closed-source models generally outperform open-source ones regarding consistency. To address this inconsistency, they propose a trigger-based diagnostic refinement, which boosts caption quality in several LVLMs without retraining. This novel benchmark and refinement method **significantly contribute** to the development of more robust and reliable LVLMs.", "affiliation": "Peking University", "categories": {"main_category": "Multimodal Learning", "sub_category": "Vision-Language Models"}, "podcast_path": "tu1oC7zHGW/podcast.wav"}