[{"type": "text", "text": "Spectral Graph Pruning Against Over-Squashing and Over-Smoothing ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Adarsh Jamadandi\u22171,2 Celia Rubio-Madrigal\u22172 adarsh.jam@gmail.com celia.rubio-madrigal@cispa.de ", "page_idx": 0}, {"type": "text", "text": "Rebekka Burkholz2 burkholz@cispa.de ", "page_idx": 0}, {"type": "text", "text": "1Universit\u00e4t des Saarlandes 2CISPA Helmholtz Center for Information Security ", "page_idx": 0}, {"type": "text", "text": "Abstract ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Message Passing Graph Neural Networks are known to suffer from two problems that are sometimes believed to be diametrically opposed: over-squashing and over-smoothing. The former results from topological bottlenecks that hamper the information flow from distant nodes and are mitigated by spectral gap maximization, primarily, by means of edge additions. However, such additions often promote oversmoothing that renders nodes of different classes less distinguishable. Inspired by the Braess phenomenon, we argue that deleting edges can address over-squashing and over-smoothing simultaneously. This insight explains how edge deletions can improve generalization, thus connecting spectral gap optimization to a seemingly disconnected objective of reducing computational resources by pruning graphs for lottery tickets. To this end, we propose a computationally effective spectral gap optimization framework to add or delete edges and demonstrate its effectiveness on the long range graph benchmark and on larger heterophilous datasets. ", "page_idx": 0}, {"type": "text", "text": "1 Introduction ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Graphs are ubiquitous data structures that can model data from diverse fields ranging from chemistry (Reiser et al., 2022), biology (Bongini et al., 2023) to even high-energy physics (Shlomi et al., 2021). This has led to the development of deep learning techniques for graphs, commonly referred to as Graph Neural Networks (GNNs). The most popular GNNs follow the message-passing paradigm (Gori et al., 2005; Scarselli et al., 2009; Gilmer et al., 2017; Bronstein et al., 2021), where arbitrary differentiable functions, parameterized by neural networks, are used to diffuse information on the graph, consequently learning a graph-level representation. This representation can then be used for various downstream tasks like node classification, link prediction, and graph classification. Different types of GNNs (Kipf & Welling, 2017; Hamilton et al., 2017; Veli\u02c7ckovi\u00b4c et al., 2018; Xu et al., 2019; Bodnar et al., 2021a,b; Bevilacqua et al., 2022), all tackling a variety of problems in various domains have been proposed with varied degree of success. Despite their widespread use, GNNs have a number of inherent problems. These include limited expressivity, (Leman, 1968; Morris et al., 2019), over-smoothing (Li et al., 2019; NT & Maehara, 2019; Oono & Suzuki, 2020; Zhou et al., 2021), and over-squashing (Alon & Yahav, 2021; Topping et al., 2022). ", "page_idx": 0}, {"type": "text", "text": "The phenomenon of over-squashing, first studied heuristically by Alon & Yahav (2021) and later theoretically formalized by Topping et al. (2022), is caused by the presence of structural bottlenecks in the graph. These bottlenecks can be attributed to the first non-zero eigenvalue of the normalized graph Laplacian, also known as the spectral gap. The smaller the gap, the more susceptible a graph is to oversquashing. Recent work has explored rewiring the input graph to address these bottlenecks (Topping et al., 2022; Arnaiz-Rodr\u00edguez et al., 2022; Giraldo et al., 2023; Nguyen et al., 2023; Karhadkar et al., 2023), but suggest there has to be a trade-off between over-squashing and over-smoothing (Keriven, 2022). Instead, we propose to leverage the Braess paradox (Braess, 1968; Eldan et al., 2017) that posits certain edge deletions can maximize the spectral gap. We propose to approximate the spectral change in a computationally efficient manner by leveraging Matrix Perturbation Theory (Stewart & Sun, 1990). Our proposed framework allows us to jointly address the problem of over-squashing, by increasing the spectral gap, and over-smoothing, by slowing down the rate of smoothing. We find that our method is especially effective in heterophilic graph settings, where we delete edges between nodes of different labels, thus preventing unnecessary aggregation. We empirically show that our proposed method outperforms other graph rewiring methods on node classification and graph classification tasks. We also show that spectral gap based edge deletions can help identify graph lottery tickets (GLTs) (Frankle & Carbin, 2019), that is, sparse sub-networks that can match the performance of dense networks. ", "page_idx": 0}, {"type": "text", "text": "", "page_idx": 1}, {"type": "text", "text": "1.1 Contributions ", "text_level": 1, "page_idx": 1}, {"type": "text", "text": ". Inspired by the Braess phenomenon, we prove that, contrary to common assumptions, oversmoothing and over-squashing are not necessarily diametrically opposed. By deriving a minimal example, we show that both can be mitigated by spectral based edge deletions.   \n2. Leveraging matrix perturbation theory, we propose a Greedy graph pruning algorithm (PROXYDELETE) that maximizes the spectral gap in a computationally efficient way. Similarly, our algorithm can also be utilized to add edges in a joint framework. We compare this approach with a novel graph rewiring scheme based on Eldan\u2019s criterion (Eldan et al.,   \n2017) that provides guarantees for edge deletions and a stopping criterion for pruning, but is computationally less efficient.   \n3. Our results connect literature on three seemingly disconnected topics: over-smoothing, over-squashing, and graph lottery tickets, which explain observed improvements in generalization performance by graph pruning. Utilizing this insight, we demonstrate that graph sparsification based on our proxy spectral gap update can perform better than or on par with a contemporary baseline (Chen et al., 2021) that takes additional node features and labels into account. This highlights the feasibility of finding winning subgraphs at initialization. ", "page_idx": 1}, {"type": "text", "text": "2 Related work ", "text_level": 1, "page_idx": 1}, {"type": "text", "text": "Over-squashing. Alon & Yahav (2021); Topping et al. (2022) have observed that over-squashing, where information from distant nodes are not propagated due to topological bottlenecks in the graph, hampers the performance of GNNs. A promising line of work that attempts to alleviate this issue is graph rewiring. This task aims to modify the edge structure of the graph either by adding or deleting edges. Gasteiger et al. (2019) propose to add edges according to graph diffusion kernel, such as personalized PageRank, to rely less on messages from only one-hop neighbors, thus alleviating over-squashing. Topping et al. (2022) propose Stochastic Discrete Ricci Flow (SDRF) to rewire the graph based on curvature. Banerjee et al. (2022) resort to measuring the spectral expansion with respect to the number of rewired edges and propose a random edge flip algorithm that transforms the given input graph into an Expander graph. Contrarily, Deac et al. (2022) show that negatively curved edges might be inevitable for building scalable GNNs without bottlenecks and advocate the use of Expander graphs for message passing. Arnaiz-Rodr\u00edguez et al. (2022) introduces two new intermediate layers called CT-LAYER and GAP-LAYER, which can be interspersed between GNN layers. The layers perform edge re-weighting (which minimizes the gap) and introduce additional parameters. Karhadkar et al. (2023) propose FoSR, a graph rewiring algorithm that sequentially adds edges to maximize the first-order approximation of the spectral gap. A recent work by Black et al. (2023) explores the idea of characterizing over-squashing through the lens of effective resistance (Chandra et al., 1996). Giovanni et al. (2023) provide a comprehensive account of over-squashing and studies the interplay of depth, width and the topology of the graph. ", "page_idx": 1}, {"type": "text", "text": "Over-smoothing. It is a known fact that increasing network depth (He et al., 2016) often leads to better performance in the case of deep neural networks. However, naively stacking GNN layers often seems to harm generalization. And one of the reasons is over-smoothing (Li et al., 2019; Oono & Suzuki, 2020; NT & Maehara, 2019; Zhou et al., 2021; Rusch et al., 2023a), where repeated aggregation leads to node features, in particular nodes with different labels, becoming indistinguishable. Current graph rewiring strategies, such as FoSR (Karhadkar et al., 2023), which rely on iteratively adding edges based on spectral expansion, may help mitigate over-squashing but also increase the smoothing induced by message passing. Curvature based methods such as Nguyen et al. (2023); Giraldo et al. (2023) aim to optimize the degree of smoothing by graph rewiring, as they assume that over-smoothing is the result of too much information propagation, while over-squashing is caused by too little. Within this framework, they assume that edge deletions always reduce the spectral gap. In contrast, we show and exploit that some deletions can also increase it. Furthermore, we rely on a different, well established concept of over-smoothing (Keriven, 2022) that also takes node features into account and is therefore not diametrically opposed to over-squashing. As we show, over-smoothing and over-squashing can be mitigated jointly. Moreover, we propose a computationally efficient approach to achieve this with spectral rewiring. In contrast to our proposal, curvature based methods (Nguyen et al., 2023; Giraldo et al., 2023) do not scale well to large graphs. For instance, Nguyen et al. (2023) propose a batch Ollivier-Ricci (BORF) curvature based rewiring approach to add and delete edges, which solves optimal transport problems and runs in cubic time. ", "page_idx": 1}, {"type": "text", "text": "", "page_idx": 2}, {"type": "text", "text": "Graph sparsification and lottery tickets. Most GNNs perform recursive aggregations of neighborhood information. This operation becomes computationally expensive when the graphs are large and dense. A possible solution for this is to extract a subset of the graph which is representative of the dense graph, either in terms of their node distribution (Eden et al., 2018) or graph spectrum (Adhikari et al., 2017). Zheng et al. (2020); Li et al. (2020) formulate graph sparsification as an optimization problem by resorting to learning surrogates and ADMM respectively. With the primary aim to reduce the computational resource requirements of GNNs, a line of work that transfers the lottery ticket hypothesis (LTH) by Frankle & Carbin (2019) to GNNs (Chen et al., 2021; Hui et al., 2023), prunes the model weights in addition to the adjacency matrix. The resulting winning graph lottery ticket (GLT) can match or surpass the performance of the original dense model. While our theoretical understanding of GLTs is primarily centered around their existence (Ferbach et al., 2022; Burkholz et al., 2022; Burkholz, 2022b,a), our insights inspired by the Braess paradox add a complementary lens to our understanding of how generalization can be improved, namely by reducing over-squashing and over-smoothing with graph pruning. So far, the spectral gap has only been employed to maintain a sufficient degree of connectivity of bipartite graphs that are associated with classic feed-forward neural network architectures (Pal et al., 2022; Hoang et al., 2023). We highlight that the spectral gap can also be employed as a pruning at initialization technique (Frankle et al., 2021) that does not take node features into account and can achieve computational resource savings while reducing the generalization error, which is in line with observations for random pruning of CNNs (Gadhikar et al., 2023; Gadhikar & Burkholz, 2024). ", "page_idx": 2}, {"type": "text", "text": "3 Theoretical insights into spectral rewiring ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "To prove our claim that over-smoothing and over-squashing can both be alleviated jointly, we provide a minimal example as illustrated in Figure 1. Utilizing the Braess paradox, we achieve this by the deletion of an edge. In contrast, an edge addition that addresses over-squashing still causes over-smoothing, yet less drastically than another edge addition that worsens over-squashing. ", "page_idx": 2}, {"type": "text", "text": "Reducing over-squashing via the spectral gap. From a spectral perspective, bottlenecks, which hamper the information flow by over-squashing, can be characterized by the spectral gap of the (symmetric) normalized graph Laplacian $\\mathcal{L}_{\\mathcal{G}}$ , where $\\mathcal{G}\\,=\\,(\\mathcal{V},\\mathcal{E})$ . The Laplacian of the graph is $\\mathcal{L}=D-A$ , where $A$ is the adjacency matrix and $D$ the diagonal degree matrix. The symmetric normalized graph Laplacian is defined as $\\mathcal{L}_{\\mathcal{G}}=D^{-1/2}\\mathcal{L}D^{-1/2}$ . Let $\\{\\lambda_{0}<\\lambda_{1}<\\lambda_{2},...\\lambda_{n}\\}$ be the eigenvalues of $\\mathcal{L}_{\\mathcal{G}}$ arranged in ascending order and let $\\lambda_{1}(\\mathcal{L}_{\\mathcal{G}})$ be the first non-zero eigenvalue of the normalized graph Laplacian, which is also called the spectral gap of the graph. For a graph where distant network components are connected only by a few bridging edges, all the information has to be propagated via these edges. The information flow through edges is encoded by the Cheeger (1971) constant $\\begin{array}{r}{h_{S}=\\operatorname*{min}_{S\\subset V}\\frac{\\left|\\partial S\\right|}{\\operatorname*{min}\\left\\{V o l\\left(S\\right),V o l\\left(S\\backslash V\\right)\\right\\}}}\\end{array}$ where $\\partial S=\\{(u,v):u\\in S,v\\in\\mathcal{V}\\backslash S\\}$ and $\\textstyle V o l(S)=\\sum_{u\\in S}d_{u}$ , being $d_{u}$ the degree of the node $u$ . The spectral gap is bounded by the Cheeger inequality $\\begin{array}{r}{2h_{\\mathcal{G}}\\geq\\lambda_{1}\\geq\\frac{h_{\\mathcal{G}}^{2}}{2}}\\end{array}$ , which motivates it as a measure of over-squashing. ", "page_idx": 2}, {"type": "image", "img_path": "EMkrwJY2de/tmp/dfd22464266f30afd1ab84df1cea7c6dd3c76ee951cbf21042fa3b20af088428.jpg", "img_caption": ["Figure 1: Braess\u2019 paradox. We derive a simple example where deleting an edge from $\\mathcal{G}$ to obtain $g^{-}$ yields a higher spectral gap. Alternatively, we add a single edge to the base graph to either increase $(\\mathcal{G}^{+})$ or to decrease $(\\widetilde{\\mathcal{G}^{+}})$ the spectral gap. The relationship between the four graphs is highlighted by arrows when an edge is added/deleted. "], "img_footnote": [], "page_idx": 3}, {"type": "text", "text": "Braess\u2019 paradox. Braess (1968) found a counter-intuitive result for road networks: even if all travelers behave selfishly, the removal of a road can still improve each of their individual travel times. That is, there is a violation of monotonicity in the traffic flow with respect to the number of edges of a network. For instance, Chung & Young (2010) has shown that Braess\u2019 paradox occurs with high probability in Erdo\u02dds-R\u00e9nyi random graphs, and Chung et al. (2012) have confirmed it for a large class of Expander graphs. The paradox can be analogously applied to related graph properties such as the spectral gap of the normalized Laplacian. Eldan et al. (2017) have studied how the spectral gap of a random graph changes after edge additions or deletions, proving a strictly positive occurrence of the paradox for typical instances of ER graphs. This result inspires us to develop an algorithm for rewiring a graph by specifically eliminating edges that increase this quantity, which we can expect to carry out with high confidence in real-world graphs. Their Lemma 3.2 (when reversed) states a sufficient condition that guarantees a spectral gap increase in response to a deletion of an edge. ", "page_idx": 3}, {"type": "text", "text": "Lemma 3.1. Eldan et al. (2017): Let $\\mathcal{G}=(\\mathcal{V},\\mathcal{E})$ be a finite graph, with $f$ denoting the eigenvector and $\\lambda_{1}(\\mathcal{L}_{\\mathcal{G}})$ the eigenvalue corresponding to the spectral gap. Let $\\{u,v\\}\\not\\in\\mathcal{V}$ be two vertices that are not connected by an edge. Denote $\\hat{\\mathcal{G}}=(\\nu,\\hat{\\mathcal{E}})$ , the new graph obtained after adding an edge between $\\{u,v\\}$ , i.e., $\\hat{\\mathcal{E}}:=\\mathcal{E}\\cup\\{u,v\\}$ . Denote with $\\mathcal{P}_{f}:=\\langle f,\\hat{f}_{0}\\rangle$ the projection of $f$ onto the top eigenvector of $\\hat{\\mathcal G}$ . Define $g\\left(u,v,\\mathcal{L}_{\\mathcal{G}}\\right):=$ ", "page_idx": 3}, {"type": "equation", "text": "$$\n-\\mathcal{P}_{f}^{2}\\lambda_{1}(\\mathcal{L}_{\\mathcal{G}})-2(1-\\lambda_{1}(\\mathcal{L}_{\\mathcal{G}}))\\left(\\frac{\\sqrt{d_{u}+1}-\\sqrt{d_{u}}}{\\sqrt{d_{u}+1}}f_{u}^{2}\\right.\\left.+\\frac{\\sqrt{d_{v}+1}-\\sqrt{d_{v}}}{\\sqrt{d_{v}+1}}f_{v}^{2}\\right)+\\frac{2f_{u}f_{v}}{\\sqrt{d_{u}+1}\\sqrt{d_{v}+1}}.\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "As a showcase example of the Braess phenomenon, let us analyze the behaviour of the spectral gap in terms of an edge perturbation on the ring graph of $n$ nodes $R_{n}$ . We consider the ring $R_{8}$ as $g^{-}$ , the deletion of an edge from graph $\\mathcal{G}$ in Figure 1. ", "page_idx": 3}, {"type": "text", "text": "Proposition 3.2. The spectral gap of $\\mathcal{G}$ increases with the deletion of edge $\\{0,3\\}$ , i.e., $\\lambda_{1}(\\mathcal{L}_{\\mathcal{G}^{-}})>$ $\\lambda_{1}(\\mathcal{L}_{\\mathcal{G}})$ . It also increases with the addition of edge $\\{0,5\\}$ or decreases with the addition of edge $\\{4,7\\}$ , i.e., $\\lambda_{1}({\\mathcal{L}}_{\\mathcal{G}^{+}})>\\lambda_{1}({\\mathcal{L}}_{\\mathcal{G}})$ and $\\lambda_{1}(\\mathcal{L}_{\\widetilde{\\mathcal{G}}^{+}})<\\lambda_{1}(\\mathcal{L}_{\\mathcal{G}})$ . ", "page_idx": 3}, {"type": "text", "text": "We leverage Eldan\u2019s Lemma 3.1 in Appendix A.1 and apply the spectral graph proxies in our derivations starting from an explicit spectral analysis of the ring graph. While these derivations demonstrate that we can reduce over-squashing (i.e., increase the spectral gap) by edge deletions, we show next that edge deletions can also alleviate over-smoothing. ", "page_idx": 3}, {"type": "text", "text": "Slowing detrimental over-smoothing. For GNNs with mean aggregation, increasing the spectral gap usually promotes smoothing and thus leads to higher node feature similarity. Equating a high node feature similarity with over-smoothing would thus imply a trade-off between over-smoothing and over-squashing. Methods by Giraldo et al. (2023); Nguyen et al. (2023) seek to find the right amount of smoothing by adding edges to increase the gap and deleting edges to decrease it. Contrarily, we argue that deleting edges can also increase the gap while adding edges could decrease it, as our previous analysis demonstrates. Thus, both edge deletions and additions allow to control which node features are aggregated, while mitigating over-squashing. Such node features are central to a more nuanced concept of over-smoothing that acknowledges that increasing the similarity of nodes that share the same label, while keeping nodes with different labels distinguishable, aids the learning task. ", "page_idx": 3}, {"type": "image", "img_path": "EMkrwJY2de/tmp/f04a08907f8137e5457d1143d66c217ae5afde998c5c56e722438751cb7a7a18.jpg", "img_caption": ["Figure 2: We plot the MSE vs order of smoothing for our four synthetic graphs (2(a)), and for a real heterophilic dataset with the result of different rewiring algorithms to it: FoSR (Karhadkar et al., 2023) and PROXYADD for adding (200 edges), and our PROXYDELETE for deleting edges (5 edges) (2(b)). We find that deleting edges helps reduce over-smoothing, while still mitigating over-squashing via the spectral gap increase. ", "(a) Smoothing test for graphs in Figure 1. "], "img_footnote": [], "page_idx": 4}, {"type": "image", "img_path": "EMkrwJY2de/tmp/871c5d01423fe0fc9814b1bf2bbe161e5ced0c37a8421e482a6ebab0c33e4b6f.jpg", "img_caption": ["(b) Smoothing test for the Texas dataset. "], "img_footnote": [], "page_idx": 4}, {"type": "text", "text": "", "page_idx": 4}, {"type": "text", "text": "To measure over-smoothing, we adopt the Linear GNN test bed proposed by Keriven (2022), which uses a linear ridge regression (LRR) setup with mean squared error (MSE) as the loss. We assign two classes to nodes according to their color in Figure 1, and one-dimensional features that are drawn independently from normal distributions $\\mathcal{N}(1,\\bar{1})$ and $\\mathcal{N}(-1,1)$ , respectively. Figure 2(a) compares how our exemplary graphs (see Figure 1) influence over-smoothing in this setting. While adding edges can accelerate the rate of smoothing, pruning strikingly aids in reducing over-smoothing \u2014and still reduces over-squashing by increasing the spectral gap. Note that the real world heterophilic graph example shows a similar trend and highlights the utility of the spectral pruning algorithm PROXYDELETE, which we describe in the next section, over edge additions by the strong baseline FoSR. Additional real world examples along with cosine distance between nodes of different labels before and after spectral pruning and plots for Dirichlet energy can be found in Appendix D. ", "page_idx": 4}, {"type": "text", "text": "In the following, we discuss and analyze rigorously the reasons for this finding. Consider again the ring graph $g^{-}$ , which has an inter-class edge pruned from our base graph $\\mathcal{G}$ ; this avoids a problematic aggregation step and in this way mitigates over-smoothing. Instead of deleting an edge, we could also add an edge arriving at $\\mathcal{G}^{+}$ , which would lead to a higher spectral gap than the edge deletion. Yet, it adds an edge between nodes with different labels and therefore leads to over-smoothing. We also prove this relationship rigorously for one step of mean aggregation. ", "page_idx": 4}, {"type": "text", "text": "Proposition 3.3. As more edges are added (from $g^{-}$ to $\\mathcal{G}$ , or from $\\mathcal{G}$ to $\\mathcal{G}^{+}\\,o r\\,\\widetilde{\\mathcal{G}^{+}}$ ), the average value over same-class node representations after a mean aggregation round becomes less informative. ", "page_idx": 4}, {"type": "text", "text": "The proof is presented in Appendix A.2. We argue that similar situations arise particularly in heterophilic learning tasks, where spectral gap optimization would frequently delete inter-class edges but also add inter-class edges. Thus, mostly edge deletions can mitigate over-squashing and over-smoothing simultaneously. ", "page_idx": 4}, {"type": "text", "text": "Clearly, this argument relies on the specific distribution of labels. Other scenarios are analyzed in Appendix B to also highlight potential limitations of spectral rewiring that does not take node labels into account. ", "page_idx": 4}, {"type": "text", "text": "Following this argument, however, we could ask if the learning task only depends on the label distribution. The following proposition highlights why spectral gap optimization is justified beyond label distribution considerations. ", "page_idx": 4}, {"type": "text", "text": "Proposition 3.4. After one round of mean aggregation, the node features of $\\mathcal{G}^{+}$ are more informative compared to $\\widetilde{\\mathcal{G}^{+}}$ . ", "page_idx": 4}, {"type": "text", "text": "Note that $\\widetilde{\\mathcal{G}^{+}}$ decreases the spectral gap, while $\\mathcal{G}^{+}$ increases it relative to $\\mathcal{G}$ . However, the label configuration of $\\widetilde{\\mathcal{G}^{+}}$ seems more advantageous because, for the changed nodes, the number of neighbors of the  same class label remains in the majority in contrast to $\\mathcal{G}^{+}$ . Still, the spectral gap increase seems to aid the learning task compared to the spectral gap decrease. ", "page_idx": 5}, {"type": "text", "text": "4 Braess-inspired graph rewiring ", "text_level": 1, "page_idx": 5}, {"type": "text", "text": "We introduce two algorithmic approaches to perform spectral rewiring. Our main proposal is computationally more efficient and more effective in spectral gap approximation than baselines, as we also showcase in Table 14. The other approach based on Eldan\u2019s Lemma is also analyzed, as it provides theoretical guarantees for edge deletions. However, it does not scale well to larger graphs. ", "page_idx": 5}, {"type": "text", "text": "Greedy approach to modify edges. Evaluating all potential subsets of edges that we could add or delete is computationally infeasible due to the combinatorially exploding number of possible candidates. Therefore, we resort to a Greedy approach, in which we add or delete a single edge iteratively. In every iteration, we rank candidate edges according to a proxy of the spectral gap change that would be induced by the considered rewiring operation, as described next. ", "page_idx": 5}, {"type": "text", "text": "4.1 Graph rewiring with Proxy spectral gap updates ", "text_level": 1, "page_idx": 5}, {"type": "text", "text": "Update of eigenvalues and eigenvectors. Calculating the eigenvalues for every normalized graph Laplacian obtained by the inclusion or exclusion of a single edge would be a highly costly method. The ability to use the spectral gap directly as a criterion to rank edges requires a formula to efficiently estimate it for one edge filp. For this we resort to Matrix Perturbation Theory (Stewart & Sun, 1990; von Luxburg, 2007) to capture the change in eigenvalues and eigenvectors approximately. Our update scheme is similar to the proposal by Bojchevski & G\u00fcnnemann (2019) in the context of adversarial flips. The change in the eigenvalue and eigenvector for a single edge flip $(u,v)$ is given by ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\dot{\\lambda}\\approx\\lambda+\\Delta w_{u,v}((f_{u}-f_{v})^{2}-\\lambda(f_{u}^{2}+f_{v}^{2})),}\\end{array}\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "where $\\lambda$ is the initial eigenvalue; $\\{f_{u},f_{v}\\}$ are entries of the leading eigenvector, $\\Delta w_{u,v}=1$ if we add an edge and $\\Delta w_{u,v}=-1$ if we delete an edge. Note that this proxy is only used to rank edges efficiently. After adding/deleting the top $M$ edges (where $M=1$ in our experiments), we update the eigenvector and the spectral gap by performing a few steps of power iteration. To this end, we initialize the function eigsh of the scipy sparse library in Python, which is based on the Implicitly Restarted Lanczos Method (Lehoucq et al., 1998), with our current estimate of the leading eigenvector. Both our resulting algorithms, PROXYDELETE for deleting edges and PROXYADD for adding edges, are detailed in Appendix C. ", "page_idx": 5}, {"type": "text", "text": "Time Complexity of PROXYDELETE. The algorithm runs in $\\mathcal{O}\\left(N\\cdot\\left(\\lvert\\mathcal{E}\\rvert+s(\\mathcal{G})\\right)\\right)$ where $N$ is the number of edges to delete, and $s(\\mathcal{G})$ denotes the complexity of the algorithm that updates the leading eigenvector and eigenvalue at the end of every iteration. In our setting, this requires a constant number of power method iterations, which is of complexity $s(\\mathcal{G})=O(\\vert\\mathcal{E}\\vert)$ . Note that, because we choose to only delete one edge, the ranking does not need to be sorted to obtain its maximum. By having an $\\mathcal{O}(1)$ proxy measure to score candidate edges, we are able to improve the overall runtime complexity from the original $O\\left(N\\cdot\\lvert\\mathcal{E}\\rvert\\cdot s(\\mathcal{G})\\right)$ . Furthermore, even though this does not impact the asymptotic complexity, deleting edges instead of adding them makes every iteration run on a gradually smaller graph, which can further induce computational savings for the downstream task. ", "page_idx": 5}, {"type": "text", "text": "Time Complexity of PROXYADD. The run time analysis consists of the same elements as the edge deletion algorithm. The key distinction is that the ranking is conducted on the complement of the graph\u2019s edges, $\\bar{\\mathcal E}$ . Since the set of missing edges is usually larger than the existing edges in real world settings, to save computational overhead, it is possible to only sample a constant amount of edges. See Section F for empirical runtimes. ", "page_idx": 5}, {"type": "text", "text": "4.2 Graph rewiring with Eldan\u2019s criterion ", "text_level": 1, "page_idx": 5}, {"type": "text", "text": "Lemma 3.1 states a sufficient condition for the Braess paradox. It naturally defines a scoring function of edges to rank them according to their potential to maximize the spectral gap based on the function $g$ . However, the computation of this ranking is significantly more expensive than other considered algorithms, as each scoring operation needs access to the leading eigenvector of the perturbed graph with an added or deleted edge. In case of edge deletions, we also need to approximate the spectral gap similar to our Proxy algorithms. As the involved projection $\\mathcal{P}_{f}$ is a dot product of eigenvectors, it requires $\\mathcal{O}(|\\mathcal{V}|)$ operations. Even though this algorithm does not scale well to large graphs without focusing on a small random subset of candidate edges, we still consider it as baseline, as it defines a more conservative criterion to assess when we should stop deleting edges. The precise algorithms are stated in Appendix C. ", "page_idx": 5}, {"type": "image", "img_path": "EMkrwJY2de/tmp/15698177cd5a0b5457e2b2db96b06130e72b7077023fffff41ec1abce5f0aa10.jpg", "img_caption": ["Figure 3: We instantiate a toy ER graph with 30 nodes and 58 edges. We compare FoSR (Karhadkar et al., 2023), our proxy spectral gap based methods, and our Eldan\u2019s criterion based edge methods. "], "img_footnote": [], "page_idx": 6}, {"type": "table", "img_path": "EMkrwJY2de/tmp/24840cb91520eac23ffaa2e4d4e2441bd54b1fc17af0158e1304ebf4dc4e2fa5.jpg", "table_caption": ["Table 1: Results on Long Range Graph Benchmark datasets. "], "table_footnote": [], "page_idx": 6}, {"type": "text", "text": "", "page_idx": 6}, {"type": "text", "text": "4.3 Approximation quality ", "text_level": 1, "page_idx": 6}, {"type": "text", "text": "To check whether the proposed edge modification algorithms are indeed effective in the spectral gap expansion, we conduct experiments on an Erd\u00f6s-R\u00e9nyi (ER) graph with $(|\\mathcal{V}|,|\\mathcal{E}|)=(30,58)$ in Figure 3. Our ideal baseline that scores each candidate with the correct spectral gap change would usually be computationally too expensive, because each edge scoring requires $O(|\\mathcal{E}|)$ computations. For our small synthetic test bed, we still compute it to assess the approximation quality of the proposed algorithms, and of the competitive baseline FoSR (Karhadkar et al., 2023). For both edge additions (Figure 3(a)) and deletions (Figure 3(b)), we observe that the Proxy method outlined in Algorithm 1 usually leads to a better spectral expansion approximation. In addition, we report the spectral gaps that different methods obtain on real world data in Table 16 in the Appendix, which highlights that our proposals are consistently most effective in increasing the spectral gap. ", "page_idx": 6}, {"type": "text", "text": "5 Experiments ", "text_level": 1, "page_idx": 6}, {"type": "text", "text": "5.1 Long Range Graph Benchmark ", "text_level": 1, "page_idx": 6}, {"type": "text", "text": "The Long Range Graph Benchmark (LRGB) was introduced by Dwivedi et al. (2023) specifically to create a test bed for over-squashing. We compare our proposed PROXYADD and PROXYDELETE methods with DRew (Gutteridge et al., 2023), a recently proposed strong baseline for addressing over-squashing using a GCN as our backbone architecture in Table 1. We adopt the experimental setting of T\u00f6nshoff et al. (2023), we adopt DRew baseline results from the original paper. We evaluate on the following datasets and tasks: 1) PascalVOC-SP - Semantic image segmentation as a node classification task operating on superpixel graphs. 2) Peptides-func - Peptides modeled as molecular ", "page_idx": 6}, {"type": "table", "img_path": "EMkrwJY2de/tmp/0943bde7107858f6018009479e47ca2357cd9ad82b5ebd1507622dd49e1cbb4e.jpg", "table_caption": ["Table 2: Node classification on Roman-Empire dataset. "], "table_footnote": [], "page_idx": 7}, {"type": "table", "img_path": "EMkrwJY2de/tmp/b00152995dedb825f4077d3a8afd55db8994fa518e291c2bb12a60edc76ca03c.jpg", "table_caption": ["Table 3: Node classification on Amazon-Ratings. Table 4: Node classification on Minesweeper. "], "table_footnote": [], "page_idx": 7}, {"type": "text", "text": "graphs. The task is graph classification. 3) Peptides-struct - Peptides modeled as molecular graphs.   \nThe task is to predict various molecular properties, hence a graph regression task. ", "page_idx": 7}, {"type": "text", "text": "The top performance is highlighted in bold. Evidently, our proposed rewiring methods outperform DRew (Gutteridge et al., 2023) and FoSR (Karhadkar et al., 2023) on PascalVOC and Peptides-struct, and achieves comparable performance on Peptides-func. ", "page_idx": 7}, {"type": "text", "text": "In addition, Table 10 in the appendix compares different rewiring strategies for node classification on other commonly used datasets and graph classification (\u00a7E.2) for adding edges, since FoSR (Karhadkar et al., 2023) was primarily tested on this task. ", "page_idx": 7}, {"type": "text", "text": "Node classification on large heterophilic datasets. Platonov et al. (2023) point out that most progress on heterophilic datasets is unreliable since many of the used datasets have drawbacks, including duplicate nodes in Chameleon and Squirrel datasets, which lead to train-test data leakage. The sizes of the small graph sizes also lead to high variance in the obtained accuracies. Consequently, we also test our proposed algorithms on 3/5 of their newly introduced larger datasets and use GCN (Kipf & Welling, 2017) and GAT (Veli\u02c7ckovi\u00b4c et al., 2018) as our backbone architectures. As a higher depth potentially increases over-smoothing, we also analyze how our methods fares with varied number of layers. To that end, we adopt the code base and experimental setup of Platonov et al. (2023); the datasets are divided into 50/25/25 split for train/test/validation respectively. The test accuracy is reported as an average over 10 runs. To facilitate training deeper models, skip connections and layer normalization are employed. We compare FoSR (Karhadkar et al., 2023) and our proposals based on the Eldan criterion as well as PROXYADD and PROXYDELETE in Tables 2,3,4. The top performance is highlighted in bold. Evidently, for increasing depth, even though the GNN performance should degrade because of over-smoothing, we achieve a significant boost in accuracy compared to baselines, which we attribute to the fact that our methods delete inter-class edges \u2014thus slowing down detrimental smoothing. ", "page_idx": 7}, {"type": "table", "img_path": "EMkrwJY2de/tmp/7fbfec8f30dad31832f103939688d16ba6c48d6fd73ba87d5ecb878ffad18aef.jpg", "table_caption": ["Table 5: Pruning for lottery tickets comparing UGS to our ELDANDELETE pruning and our PROXYDELETE pruning. We report Graph Sparsity (GS), Weight Sparsity (WS), and Accuracy (Acc). "], "table_footnote": [], "page_idx": 8}, {"type": "text", "text": "Pruning for graph lottery tickets. In Sections $\\S3$ and $\\S5$ , we have shown that graph pruning can improve generalization, mitigate over-squashing and also help slow down the rate of smoothing. Can we also use our insights to find lottery tickets (Frankle & Carbin, 2019)? ", "page_idx": 8}, {"type": "text", "text": "To what degree is graph pruning feature data dependent? The first extension of the Lottery Ticket Hypothesis to GNNs, called Unified Graph Sparsification (UGS) (Chen et al., 2021), prunes connections in the adjacency matrix and model weights that are deemed less important for a prediction task. Note that UGS relies on information that is obtained in computationally intensive prune-train cycles that take into account the data and the associated masks. In the context of GNNs, the input graph plays a central role in determining a model\u2019s performance at a downstream task. Naively pruning the adjacency matrix without characterizing what constitutes important edges is a pitfall we would want to avoid (Hui et al., 2023), yet resorting to expensive train-prune-rewind cycles to identify importance is also undesirable. This brings forth the questions: To what extent does the pruning criterion need to depend on the data? Is it possible to formulate a data/feature agnostic pruning criterion that optimizes a more general underlying principle to find lottery tickets? Morcos et al. (2019) and Chen et al. (2020) show, in the context of computer vision and natural language processing respectively, that lottery tickets can have universal properties that can even provably (Burkholz et al., 2022) transfer to related tasks. ", "page_idx": 8}, {"type": "text", "text": "Lottery tickets that rely on the spectral gap. However, even specialized structures need to maintain and promote information flow through their connections. This fact has inspired works like Pal et al. (2022); Hoang et al. (2023) to analyze how well lottery ticket pruning algorithms maintain the Ramanujan graph property of bipartite graphs, which is intrinsically related to the Cheeger constant and thus the spectral gap. They have further shown that rejecting pruning steps that would destroy a proxy of this property can positively impact the training process. ", "page_idx": 8}, {"type": "text", "text": "In the context of GNNs, we show that we can base the graph pruning decision even entirely on the spectral gap, but rely on a computationally cheaper approach to obtain a proxy. By replacing the magnitude pruning criterion for the graph with the Eldan criterion and PROXYDELETE to prune edges, in principle, we can avoid the need for additional data features and labels. This has the advantage that we could also prune the graph at initialization and thus benefit from the computational savings from the start. We use our proposed methods to prune the graph at initialization to the requisite sparsity level and then feed it to the GNN where the weights are pruned in an iterative manner. Our results are presented in Table 18, where we compare IMP based UGS (Chen et al., 2021) with our methods for different graph and weight sparsity levels. Note that, even though our method does not take any feature information into account and prunes purely based on the graph structure, our results are comparable. For datasets like Pubmed, we even slightly outperform the baseline. Table 5 shows results for jointly pruning the graph and parameter weights, which leads to better results due to potential positive effects of overparameterization on training (Gadhikar & Burkholz, 2024). ", "page_idx": 8}, {"type": "text", "text": "Stopping criterion. The advantage of using spectral gap based pruning (especially the Eldan criterion) is patent: It helps identify problematic edges that cause information bottlenecks and provides a framework to prune those edges. Unlike UGS, our proposed framework also has the advantage that we can couple the overall pruning scheme with a stopping criterion that follows naturally from our setup. We stop pruning the input graph when no available edges satisfy our criterion anymore. ", "page_idx": 8}, {"type": "text", "text": "6 Conclusion ", "text_level": 1, "page_idx": 8}, {"type": "text", "text": "Our work connects two seemingly distinct branches of the literature on GNNs: rewiring graphs to mitigate over-squashing and pruning graphs for lottery tickets to save computational resources. ", "page_idx": 8}, {"type": "text", "text": "Contributing to the first branch, we highlight that, contrary to the standard rewiring practice, not only adding but also pruning edges can increase the spectral gap of a graph exploiting the Braess paradox. By providing a minimal example, we prove that this way it is possible to address oversquashing and over-smoothing simultaneously. Experiments on large-scale heterophilic graphs confirm the practical utility of this insight. Contributing to the second branch, these results explain how pruning graphs moderately can improve the generalization performance of GNNs, in particular for heterophilic learning tasks. To utilize these insights, we have proposed a computationally efficient graph rewiring framework, which also induces a competitive approach to prune graphs for lottery tickets at initialization. ", "page_idx": 9}, {"type": "text", "text": "Acknowledgments and Disclosure of Funding ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "We gratefully acknowledge funding from the European Research Council (ERC) under the Horizon Europe Framework Programme (HORIZON) for proposal number 101116395 SPARSE-ML. ", "page_idx": 9}, {"type": "text", "text": "References ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "Adhikari, B., Zhang, Y., Bharadwaj, A., and Prakash, B. A. Condensing temporal networks using propagation. In SDM, pp. 417\u2013425. SIAM, 2017. ISBN 978-1-61197-497-3. ", "page_idx": 9}, {"type": "text", "text": "Alon, U. and Yahav, E. On the bottleneck of graph neural networks and its practical implications. In International Conference on Learning Representations, 2021. URL https://openreview.net/ forum?id $\\equiv$ i80OPhOCVH2.   \nArnaiz-Rodr\u00edguez, A., Begga, A., Escolano, F., and Oliver, N. Diffwire: Inductive graph rewiring via the lov\u00e1sz bound, 2022. URL https://arxiv.org/abs/2206.07369.   \nAzabou, M., Ganesh, V., Thakoor, S., Lin, C.-H., Sathidevi, L., Liu, R., Valko, M., Veli\u02c7ckovi\u00b4c, P., and Dyer, E. Half-hop: A graph upsampling approach for slowing down message passing. In International Conference on Machine Learning, 08 2023.   \nBa, J. L., Kiros, J. R., and Hinton, G. E. Layer normalization, 2016. URL https://arxiv.org/ abs/1607.06450.   \nBanerjee, P. K., Karhadkar, K., Wang, Y. G., Alon, U., and Mont\u00fafar, G. Oversquashing in gnns through the lens of information contraction and graph expansion. In 2022 58th Annual Allerton Conference on Communication, Control, and Computing (Allerton), pp. 1\u20138. IEEE Press, 2022. doi: 10.1109/Allerton49937.2022.9929363. URL https://doi.org/10.1109/ Allerton49937.2022.9929363.   \nBattaglia, P. W., Hamrick, J. B., Bapst, V., Sanchez-Gonzalez, A., Zambaldi, V., Malinowski, M., Tacchetti, A., Raposo, D., Santoro, A., Faulkner, R., et al. Relational inductive biases, deep learning, and graph networks. arXiv preprint arXiv:1806.01261, 2018.   \nBevilacqua, B., Frasca, F., Lim, D., Srinivasan, B., Cai, C., Balamurugan, G., Bronstein, M. M., and Maron, H. Equivariant subgraph aggregation networks. In International Conference on Learning Representations, 2022. URL https://openreview.net/forum?id $\\equiv$ dFbKQaRk15w.   \nBlack, M., Wan, Z., Nayyeri, A., and Wang, Y. Understanding oversquashing in gnns through the lens of effective resistance. In Proceedings of the 40th International Conference on Machine Learning, ICML\u201923. JMLR.org, 2023.   \nBodnar, C., Frasca, F., Otter, N., Wang, Y. G., Li\u00f2, P., Montufar, G., and Bronstein, M. M. Weisfeiler and lehman go cellular: CW networks. In Beygelzimer, A., Dauphin, Y., Liang, P., and Vaughan, J. W. (eds.), Advances in Neural Information Processing Systems, 2021a. URL https://openreview.net/forum?id=uVPZCMVtsSG.   \nBodnar, C., Frasca, F., Wang, Y. G., Otter, N., Montufar, G., Li\u00f2, P., and Bronstein, M. M. Weisfeiler and lehman go topological: Message passing simplicial networks. In ICLR 2021 Workshop on Geometrical and Topological Representation Learning, 2021b. URL https://openreview. net/forum?id=RZgbB-O3w6Z.   \nBojchevski, A. and G\u00fcnnemann, S. Adversarial attacks on node embeddings via graph poisoning. In Proceedings of the 36th International Conference on Machine Learning, ICML, Proceedings of Machine Learning Research. PMLR, 2019.   \nBongini, P., Pancino, N., Scarselli, F., and Bianchini, M. Biognn: How graph neural networks can solve biological problems. In Artificial Intelligence and Machine Learning for Healthcare, pp. 211\u2013231. Springer, 2023.   \nBraess, D. \u00dcber ein paradoxon aus der verkehrsplanung. Unternehmensforschung, 12:258\u2013268, 1968.   \nBronstein, M. M., Bruna, J., Cohen, T., and Velickovic, P. Geometric deep learning: Grids, groups, graphs, geodesics, and gauges. CoRR, abs/2104.13478, 2021. URL https://arxiv.org/abs/ 2104.13478.   \nBurkholz, R. Convolutional and residual networks provably contain lottery tickets. In International Conference on Machine Learning, 2022a.   \nBurkholz, R. Most activation functions can win the lottery without excessive depth. In Advances in Neural Information Processing Systems, 2022b.   \nBurkholz, R., Laha, N., Mukherjee, R., and Gotovos, A. On the existence of universal lottery tickets. In International Conference on Learning Representations, 2022.   \nChandra, A. K., Raghavan, P., Ruzzo, W. L., Smolensky, R., and Tiwari, P. The electrical resistance of a graph captures its commute and cover times. computational complexity, 6(4):312\u2013340, 1996. doi: 10.1007/BF01270385. URL https://doi.org/10.1007/BF01270385.   \nCheeger, J. A Lower Bound for the Smallest Eigenvalue of the Laplacian, pp. 195\u2013200. Princeton University Press, Princeton, 1971. ISBN 9781400869312. doi: doi:10.1515/9781400869312-013. URL https://doi.org/10.1515/9781400869312-013.   \nChen, J., Ma, T., and Xiao, C. FastGCN: Fast learning with graph convolutional networks via importance sampling. In International Conference on Learning Representations, 2018. URL https://openreview.net/forum?id $\\equiv$ rytstxWAW.   \nChen, T., Frankle, J., Chang, S., Liu, S., Zhang, Y., Wang, Z., and Carbin, M. The lottery ticket hypothesis for pre-trained bert networks. In Proceedings of the 34th International Conference on Neural Information Processing Systems, NIPS \u201920, Red Hook, NY, USA, 2020. Curran Associates Inc. ISBN 9781713829546.   \nChen, T., Sui, Y., Chen, X., Zhang, A., and Wang, Z. A unified lottery ticket hypothesis for graph neural networks. In International Conference on Machine Learning, 2021.   \nChung, F. and Young, S. J. Braess\u2019s paradox in large sparse graphs. In Internet and Network Economics. Springer Berlin Heidelberg, 2010.   \nChung, F., Young, S. J., and Zhao, W. Braess\u2019s paradox in expanders. Random Structures & Algorithms, 41(4):451\u2013468, 2012. doi: https://doi.org/10.1002/rsa.20457. URL https: //onlinelibrary.wiley.com/doi/abs/10.1002/rsa.20457.   \nDeac, A., Lackenby, M., and Velic\u02c7kovic\u00b4, P. Expander graph propagation. In The First Learning on Graphs Conference, 2022. URL https://openreview.net/forum?id $\\cdot$ IKevTLt3rT.   \nDwivedi, V. P., Ramp\u00e1\u0161ek, L., Galkin, M., Parviz, A., Wolf, G., Luu, A. T., and Beaini, D. Long range graph benchmark, 2023.   \nEden, T., Jain, S., Pinar, A., Ron, D., and Seshadhri, C. Provable and practical approximations for the degree distribution using sublinear graph samples. In Proceedings of the 2018 World Wide Web Conference, WWW \u201918, pp. 449\u2013458, Republic and Canton of Geneva, CHE, 2018. International World Wide Web Conferences Steering Committee. ISBN 9781450356398. doi: 10.1145/3178876.3186111. URL https://doi.org/10.1145/3178876.3186111.   \nEldan, R., R\u00e1cz, M. Z., and Schramm, T. Braess\u2019s paradox for the spectral gap in random graphs and delocalization of eigenvectors. Random Structures & Algorithms, 50, 2017.   \nFerbach, D., Tsirigotis, C., Gidel, G., and Avishek, B. A general framework for proving the equivariant strong lottery ticket hypothesis, 2022.   \nFrankle, J. and Carbin, M. The lottery ticket hypothesis: Finding sparse, trainable neural networks. In International Conference on Learning Representations, 2019. URL https://openreview. net/forum?id=rJl-b3RcF7.   \nFrankle, J., Dziugaite, G. K., Roy, D., and Carbin, M. Pruning neural networks at initialization: Why are we missing the mark? In International Conference on Learning Representations, 2021.   \nGadhikar, A. H. and Burkholz, R. Masks, signs, and learning rate rewinding. In International Conference on Learning Representations, 2024.   \nGadhikar, A. H., Mukherjee, S., and Burkholz, R. Why random pruning is all we need to start sparse. In International Conference on Machine Learning, 2023.   \nGasteiger, J., Wei\u00dfenberger, S., and G\u00fcnnemann, S. Diffusion improves graph learning. In Conference on Neural Information Processing Systems (NeurIPS), 2019.   \nGilmer, J., Schoenholz, S. S., Riley, P. F., Vinyals, O., and Dahl, G. E. Neural message passing for quantum chemistry. In Proceedings of the 34th International Conference on Machine Learning - Volume 70, ICML\u201917, pp. 1263\u20131272. JMLR.org, 2017.   \nGiovanni, F. D., Giusti, L., Barbero, F., Luise, G., Lio\u2019, P., and Bronstein, M. On over-squashing in message passing neural networks: The impact of width, depth, and topology, 2023.   \nGiraldo, J. H., Skianis, K., Bouwmans, T., and Malliaros, F. D. On the trade-off between oversmoothing and over-squashing in deep graph neural networks. In Proceedings of the 32nd ACM International Conference on Information and Knowledge Management, CIKM \u201923, pp. 566\u2013576, New York, NY, USA, 2023. Association for Computing Machinery. ISBN 9798400701245. doi: 10.1145/3583780.3614997. URL https://doi.org/10.1145/3583780.3614997.   \nGori, M., Monfardini, G., and Scarselli, F. A new model for learning in graph domains. In Proceedings. 2005 IEEE International Joint Conference on Neural Networks, 2005., volume 2, pp. 729\u2013734 vol. 2, 2005. doi: 10.1109/IJCNN.2005.1555942.   \nGray, R. M. Toeplitz and Circulant Matrices: A Review. Foundations and Trends in Communications and Information Theory, 2(3):155\u2013239, 2005. doi: 10.1561/0100000006.   \nGutteridge, B., Dong, X., Bronstein, M. M., and Di Giovanni, F. DRew: Dynamically rewired message passing with delay. In International Conference on Machine Learning, pp. 12252\u201312267. PMLR, 2023.   \nHamilton, W. L., Ying, Z., and Leskovec, J. Inductive Representation Learning on Large Graphs. In NIPS, pp. 1024\u20131034, 2017.   \nHe, K., Zhang, X., Ren, S., and Sun, J. Deep residual learning for image recognition. In 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pp. 770\u2013778, 2016. doi: 10.1109/CVPR.2016.90.   \nHoang, D. N., Liu, S., Marculescu, R., and Wang, Z. Revisiting Pruning At Initialization Through The Lens of Ramanujan Graph. In The Eleventh International Conference on Learning Representations, 2023. URL https://openreview.net/forum?id=uVcDssQff_.   \nHui, B., Yan, D., Ma, X., and Ku, W.-S. Rethinking graph lottery tickets: Graph sparsity matters. In The Eleventh International Conference on Learning Representations, 2023. URL https: //openreview.net/forum?id=fjh7UGQgOB.   \nKarhadkar, K., Banerjee, P. K., and Montufar, G. FoSR: First-order spectral rewiring for addressing oversquashing in GNNs. In The Eleventh International Conference on Learning Representations, 2023. URL https://openreview.net/forum?id=3YjQfCLdrzz.   \nKeriven, N. Not too little, not too much: a theoretical analysis of graph (over)smoothing. In The First Learning on Graphs Conference, 2022. URL https://openreview.net/forum?id= KQNsbAmJEug.   \nKipf, T. N. and Welling, M. Semi-Supervised Classification with Graph Convolutional Networks. In ICLR, 2017.   \nLehoucq, R. B., Sorensen, D. C., and Yang, C. ARPACK Users\u2019 Guide: Solution of Large Scale Eigenvalue Problems by Implicitly Restarted Arnoldi Methods. SIAM, 1998.   \nLeman, A. The reduction of a graph to canonical form and the algebra which appears therein. 1968.   \nLi, G., M\u00fcller, M., Thabet, A., and Ghanem, B. Deepgcns: Can gcns go as deep as cnns? In The IEEE International Conference on Computer Vision (ICCV), 2019.   \nLi, J., Zhang, T., Tian, H., Jin, S., Fardad, M., and Zafarani, R. Sgcn: A graph sparsifier based on graph convolutional networks. In Advances in Knowledge Discovery and Data Mining: 24th Pacific-Asia Conference, PAKDD 2020, Singapore, May 11\u201314, 2020, Proceedings, Part I, pp. 275\u2013287, Berlin, Heidelberg, 2020. Springer-Verlag. ISBN 978-3-030-47425-6. doi: 10.1007/ 978-3-030-47426-3_22. URL https://doi.org/10.1007/978-3-030-47426-3_22.   \nMcCallum, A. K., Nigam, K., Rennie, J., and Seymore, K. Automating the construction of internet portals with machine learning. Information Retrieval, 3(2):127\u2013163, 2000. doi: 10.1023/A: 1009953814988. URL https://doi.org/10.1023/A:1009953814988.   \nMorcos, A. S., Yu, H., Paganini, M., and Tian, Y. One ticket to win them all: generalizing lottery ticket initializations across datasets and optimizers. Curran Associates Inc., Red Hook, NY, USA, 2019.   \nMorris, C., Ritzert, M., Fey, M., Hamilton, W. L., Lenssen, J. E., Rattan, G., and Grohe, M. Weisfeiler and leman go neural: Higher-order graph neural networks. Proceedings of the AAAI Conference on Artificial Intelligence, 33(01):4602\u20134609, Jul. 2019. doi: 10.1609/aaai.v33i01.33014602. URL https://ojs.aaai.org/index.php/AAAI/article/view/4384.   \nNamata, G., London, B., Getoor, L., and Huang, B. Query-driven active surveying for collective classification. 2012.   \nNguyen, K., Nong, H., Nguyen, V., Ho, N., Osher, S., and Nguyen, T. Revisiting over-smoothing and over-squashing using ollivier-ricci curvature, 2023.   \nNT, H. and Maehara, T. Revisiting graph neural networks: All we have is low-pass filters. ArXiv, abs/1905.09550, 2019.   \nOono, K. and Suzuki, T. Graph neural networks exponentially lose expressive power for node classification. In International Conference on Learning Representations, 2020.   \nPal, B., Biswas, A., Kolay, S., Mitra, P., and Basu, B. A study on the ramanujan graph property of winning lottery tickets. In Chaudhuri, K., Jegelka, S., Song, L., Szepesvari, C., Niu, G., and Sabato, S. (eds.), Proceedings of the 39th International Conference on Machine Learning, volume 162 of Proceedings of Machine Learning Research, pp. 17186\u201317201. PMLR, 17\u201323 Jul 2022. URL https://proceedings.mlr.press/v162/pal22a.html.   \nPlatonov, O., Kuznedelev, D., Diskin, M., Babenko, A., and Prokhorenkova, L. A critical look at evaluation of gnns under heterophily: Are we really making progress? In The Eleventh International Conference on Learning Representations, 2023.   \nReiser, P., Neubert, M., Eberhard, A., Torresi, L., Zhou, C., Shao, C., Metni, H., van Hoesel, C., Schopmans, H., Sommer, T., and Friederich, P. Graph neural networks for materials science and chemistry. Communications Materials, 3(1):93, 2022. doi: 10.1038/s43246-022-00315-6. URL https://doi.org/10.1038/s43246-022-00315-6.   \nRoth, A. and Liebig, T. Rank collapse causes over-smoothing and over-correlation in graph neural networks. In The Second Learning on Graphs Conference, 2023. URL https://openreview. net/forum?id=9aIDdGm7a6.   \nRusch, T. K., Bronstein, M. M., and Mishra, S. A survey on oversmoothing in graph neural networks, 2023a.   \nRusch, T. K., Chamberlain, B. P., Mahoney, M. W., Bronstein, M. M., and Mishra, S. Gradient gating for deep multi-rate learning on graphs. In The Eleventh International Conference on Learning Representations, 2023b. URL https://openreview.net/forum?id $\\cdot$ JpRExTbl1-.   \nSalez, J. Sparse expanders have negative curvature. Geometric and Functional Analysis, 32(6): 1486\u20131513, September 2022. ISSN 1420-8970. doi: 10.1007/s00039-022-00618-3. URL http://dx.doi.org/10.1007/s00039-022-00618-3.   \nScarselli, F., Gori, M., Tsoi, A. C., Hagenbuchner, M., and Monfardini, G. The graph neural network model. IEEE Transactions on Neural Networks, 20(1):61\u201380, 2009. doi: 10.1109/TNN.2008. 2005605.   \nSen, P., Namata, G., Bilgic, M., Getoor, L., Galligher, B., and Eliassi-Rad, T. Collective classification in network data. AI Magazine, 29(3):93, Sep. 2008. doi: 10.1609/aimag.v29i3.2157. URL https://ojs.aaai.org/index.php/aimagazine/article/view/2157.   \nShlomi, J., Battaglia, P., and Vlimant, J.-R. Graph neural networks in particle physics. Machine Learning: Science and Technology, 2(2):021001, jan 2021. doi: 10.1088/2632-2153/abbf9a. URL https://doi.org/10.1088/2632-2153/abbf9a.   \nStewart, G. and Sun, J. Matrix Perturbation Theory. Computer Science and Scientific Computing. Elsevier Science, 1990. ISBN 9780126702309. URL https://books.google.de/books?id= l78PAQAAMAAJ.   \nTopping, J., Giovanni, F. D., Chamberlain, B. P., Dong, X., and Bronstein, M. M. Understanding over-squashing and bottlenecks on graphs via curvature. In International Conference on Learning Representations, 2022. URL https://openreview.net/forum?id $\\cdot^{=}$ 7UmjRGzp-A.   \nT\u00f6nshoff, J., Ritzert, M., Rosenbluth, E., and Grohe, M. Where did the gap go? reassessing the long-range graph benchmark, 2023.   \nVeli\u02c7ckovi\u00b4c, P., Cucurull, G., Casanova, A., Romero, A., Li\u00f2, P., and Bengio, Y. Graph Attention Networks. In ICLR, 2018.   \nvon Luxburg, U. A tutorial on spectral clustering. Statistics and Computing, 17(4):395\u2013416, 2007. doi: 10.1007/s11222-007-9033-z. URL https://doi.org/10.1007/s11222-007-9033-z.   \nXu, K., Hu, W., Leskovec, J., and Jegelka, S. How powerful are graph neural networks? In International Conference on Learning Representations, 2019. URL https://openreview.net/ forum?id $\\equiv$ ryGs6iA5Km.   \nZheng, C., Zong, B., Cheng, W., Song, D., Ni, J., Yu, W., Chen, H., and Wang, W. Robust graph representation learning via neural sparsification. In III, H. D. and Singh, A. (eds.), Proceedings of the 37th International Conference on Machine Learning, volume 119 of Proceedings of Machine Learning Research, pp. 11458\u201311468. PMLR, 13\u201318 Jul 2020. URL https://proceedings. mlr.press/v119/zheng20d.html.   \nZhou, K., Huang, X., Zha, D., Chen, R., Li, L., Choi, S.-H., and Hu, X. Dirichlet energy constrained learning for deep graph neural networks. Advances in neural information processing systems, 2021. ", "page_idx": 9}, {"type": "text", "text": "", "page_idx": 10}, {"type": "text", "text": "", "page_idx": 11}, {"type": "text", "text": "", "page_idx": 12}, {"type": "text", "text": "", "page_idx": 13}, {"type": "text", "text": "A Proofs ", "text_level": 1, "page_idx": 14}, {"type": "text", "text": "A.1 Proof of Proposition 3.2 ", "text_level": 1, "page_idx": 14}, {"type": "text", "text": "Spectral analysis for general $n$ . ", "text_level": 1, "page_idx": 14}, {"type": "text", "text": "For all $n$ , the (normalized) Laplacian matrix of $R_{n}$ is circulant: all rows consist of the same elements, and each row is shifted to the right with respect to the previous one. The first row of $\\mathcal{L}(R_{n})$ is $r_{n}\\,=\\,\\left(1,-{\\textstyle{\\frac{1}{2}}},0,\\dots,0,-{\\textstyle{\\frac{1}{2}}}\\right)$ . All circulant matrices satisfy that their eigenvectors are made up of powers of the $n$ th-roots of unity, and that its eigenvalues are the DFT of the matrix\u2019s first row (Gray, 2005). With this we easily obtain that its spectral gap is ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\lambda_{1}=\\sum_{k=0}^{n-1}r_{n}(k)\\cdot e^{-i2\\pi{\\frac{k}{n}}}=1-{\\frac{1}{2}}\\left(e^{-i2\\pi{\\frac{1}{n}}}+e^{-i2\\pi{\\frac{-1}{n}}}\\right)=1-\\cos\\left({\\frac{2\\pi}{n}}\\right).\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "As stated before, one possible set of eigenvectors is $\\begin{array}{r}{\\omega_{j}(k)~=~\\exp\\left(i\\frac{2\\pi j k}{n}\\right)}\\end{array}$ . Because their conjugates and their linear combinations are also eigenvectors, we can get real eigenvectors as $\\begin{array}{r}{x_{j}(\\bar{k})=\\frac{\\omega_{j}(k)-\\omega-{_j}(k)}{2i}=\\sin\\frac{2\\pi j k}{n}}\\end{array}$ . Alternatively, we can get $\\begin{array}{r}{y_{j}(k)=\\frac{\\omega_{j}(k)\\bar{+}\\omega_{-j}(k)}{2}=\\cos\\frac{2\\pi j k}{n}}\\end{array}$ ", "page_idx": 14}, {"type": "text", "text": "We only need to focus on the (pair of) eigenvectors for $j=1$ . Note that they are orthogonal to each other. Because they are both eigenvectors with the same eigenvalue $\\lambda_{1}$ , all linear combinations of them will also be eigenvectors with eigenvalue $\\lambda_{1}$ . This multiplicity lets us choose any of these vectors to fulfill Eldan\u2019s criterion. A limitation of our algorithm is that, in cases of multiplicity, we can only choose one of them, potentially giving that edge a disadvantage \u2014the Lemma holds as long as there exists one that fulfills it, but not necessarily the one we have chosen. ", "page_idx": 14}, {"type": "text", "text": "The norms of $x_{1}$ and $y_{1}$ are $\\sqrt{\\frac{n}{2}}$ . Therefore, the norm of any linear combination of them is $\\begin{array}{r}{\\|\\mu x_{1}+\\nu y_{1}\\|=\\sqrt{\\frac{n}{2}}\\sqrt{\\mu^{2}+\\nu^{2}}}\\end{array}$ . We denote the normalized linear combination of $x_{1}$ and $y_{1}$ as ", "page_idx": 14}, {"type": "equation", "text": "$$\nf_{1}^{(\\mu,\\nu)}=\\frac{\\sqrt{2}(\\mu x_{1}+\\nu y_{1})}{\\sqrt{n(\\mu^{2}+\\nu^{2})}}\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "Our choice will be \u00b5 = 3, \u03bd = 1, i.e., f 1(3,1)= (3x\u221a15+ny1). ", "page_idx": 14}, {"type": "text", "text": "Elements of the criterion for general $n$ . As per Eldan et al. (2017), the first eigenvector of the new graph\u2019s normalized Laplacian is $\\hat{f}_{0}=\\hat{D}^{\\frac{1}{2}}\\mathbb{1}/\\sqrt{\\sum\\hat{d}_{i}}$ . In our case: $\\begin{array}{r}{\\hat{f}_{0}(k)=\\frac{\\sqrt{3}}{\\sqrt{2(n+1)}}}\\end{array}$ 3 if k \u2208{u, v}, and\u221a 2 $\\textstyle{\\frac{\\sqrt{2}}{\\sqrt{2(n+1)}}}$ if $k\\notin\\{u,v\\}$ . With it we calculate the projection, dependent on the eigenvector $f_{1}$ : ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathcal{P}_{f_{1}}=\\displaystyle\\sum_{k=0}^{n-1}f_{1}(k)\\hat{f}_{0}(k)=\\displaystyle\\sum_{k=0,\\ k\\neq u,v}^{n-1}\\frac{\\sqrt{2}}{\\sqrt{2(n+1)}}f_{1}(k)+\\frac{\\sqrt{3}}{\\sqrt{2(n+1)}}\\left(f_{1}(u)+f_{1}(v)\\right)}\\\\ &{\\quad=\\displaystyle\\frac{\\sqrt{3}-\\sqrt{2}}{\\sqrt{2(n+1)}}\\left(f_{1}(u)+f_{1}(v)\\right).}\\end{array}\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "We also have, for all n, u and v, that du\u221a+1\u2212 du = dv\u221a+1\u2212 dv = 3\u221a\u2212 2 . We can update the criterion with these considerations: $g(u,v,R_{n})=$ ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{=-\\mathcal{P}_{f_{1}}^{2}\\lambda_{1}-2(1-\\lambda_{1})\\left(\\displaystyle\\frac{\\sqrt{d_{u}+1}-\\sqrt{d_{u}}}{\\sqrt{d_{u}+1}}f_{1}(u)^{2}\\right.\\left.+\\displaystyle\\frac{\\sqrt{d_{v}+1}-\\sqrt{d_{v}}}{\\sqrt{d_{v}+1}}f_{1}(v)^{2}\\right)+\\displaystyle\\frac{2f_{1}(u)f_{1}(v)}{\\sqrt{d_{u}+1}\\sqrt{d_{v}+1}}f_{1}(u)^{2}\\right)}\\\\ &{=-\\left(\\displaystyle\\frac{\\sqrt{3}-\\sqrt{2}}{\\sqrt{2(n+1)}}\\right)^{2}\\left(1-\\cos\\left(\\displaystyle\\frac{2\\pi}{n}\\right)\\right)\\left(f_{1}(u)+f_{1}(v)\\right)^{2}}\\\\ &{\\phantom{=-}-2\\cos\\left(\\displaystyle\\frac{2\\pi}{n}\\right)\\left(1-\\sqrt{\\frac{2}{3}}\\right)\\left(f_{1}(u)^{2}+f_{1}(v)^{2}\\right)+\\displaystyle\\frac{2f_{1}(u)f_{1}(v)}{3}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "Case $n\\,=\\,8$ , $\\left(u,v\\right)=\\left\\{0,3\\right\\}$ . We choose $\\begin{array}{r}{f_{1}\\,:=\\,f_{1}^{(3,1)}\\,=\\,\\frac{(3x_{1}+y_{1})}{\\sqrt{40}}}\\end{array}$ . We have $\\begin{array}{r}{f_{1}(0)\\,=\\,\\frac{1}{2\\sqrt{10}}}\\end{array}$ and $\\textstyle f_{1}(3)={\\frac{1}{2{\\sqrt{5}}}}$ . Then: ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\begin{array}{c}{{\\left(f_{1}(u)+f_{1}(v)\\right)^{2}=\\displaystyle\\left(\\frac{1}{2\\sqrt{10}}+\\frac{1}{2\\sqrt{5}}\\right)^{2}=\\frac{3+2\\sqrt{2}}{40}}}\\\\ {{\\left(f_{1}(u)^{2}+f_{1}(v)^{2}\\right)=\\displaystyle\\left(\\frac{1}{2\\sqrt{10}}\\right)^{2}+\\left(\\frac{1}{2\\sqrt{5}}\\right)^{2}=\\frac{3}{40}}}\\\\ {{f_{1}(u)f_{1}(v)=\\displaystyle\\frac{1}{2\\sqrt{10}}\\frac{1}{2\\sqrt{5}}=\\frac{\\sqrt{2}}{40}}}\\end{array}\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "Finally, Eldan\u2019s criterion for $n=8$ , $\\left(u,v\\right)=\\left\\{0,3\\right\\}$ , and our choice of $f_{1}$ is $g(0,3,R_{8})=$ ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{=-\\left(\\displaystyle\\frac{\\sqrt{3}-\\sqrt{2}}{\\sqrt{18}}\\right)^{2}\\left(1-\\cos\\left(\\frac{\\pi}{4}\\right)\\right)\\left(f_{1}(u)+f_{1}(v)\\right)^{2}-2\\cos\\left(\\frac{\\pi}{4}\\right)\\left(1-\\sqrt{\\frac{2}{3}}\\right)\\left(f_{1}(u)^{2}+f_{1}(v)^{2}\\right)}\\\\ &{\\quad+\\displaystyle\\frac{2f_{1}(u)f_{1}(v)}{3}=-\\left(\\displaystyle\\frac{\\sqrt{3}-\\sqrt{2}}{\\sqrt{18}}\\right)^{2}\\left(1-\\displaystyle\\frac{\\sqrt{2}}{2}\\right)\\displaystyle\\frac{3+2\\sqrt{2}}{40}-\\sqrt{2}\\left(1-\\sqrt{\\frac{2}{3}}\\right)\\displaystyle\\frac{3}{40}+\\frac{2}{3}\\displaystyle\\frac{\\sqrt{2}}{40}}\\\\ &{\\approx-0.0002395-0.0194635+0.0235702\\approx0.0038672>0.}\\end{array}\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "In Table 6 we check Eldan\u2019s criterion computationally for all examples; we also check whether both our proxy estimates truthfully indicate the sign of the real spectral gap difference. Eldan\u2019s criterion $g(u,v,\\cdot)$ is calculated from the sparser graph\u2019s spectral properties, as well as $\\Delta$ PROXYADD \u2014estimating the spectral gap\u2019s difference when that edge is added. Meanwhile, $\\Delta$ PROXYDELETE is calculated from the denser graph and tries to estimate the spectral gap of the pruned one. ", "page_idx": 15}, {"type": "text", "text": "When $g(u,v,\\cdot)>0$ , it theoretically guarantees that $\\Delta\\lambda_{1}<0$ , i.e., that the addition of said edge is NOT desired. This holds in our table for the first and third rows, where the addition of each edge lowers the spectral gap. Our proxy values reflect it in both directions: $\\Delta$ PROXYADD is negative because the edge should not be added, and $\\Delta$ PROXYDELETE is positive because the edge should be pruned. ", "page_idx": 15}, {"type": "text", "text": "Note that, because of the aforementioned multiplicity of the ring\u2019s eigenvectors, if we choose another $f_{1}$ for the first row, Eldan\u2019s criterion might not be satisfied. For example, using the eigenvectors given by the library function np.linalg.eigh, the criterion yields a value of $\\approx-0.005904$ . ", "page_idx": 15}, {"type": "text", "text": "The second row shows an example of an edge that is desirable to be added. In this case, it is guaranteed that Eldan\u2019s criterion is negative. Our proxy values are again accurately descriptive of reality: \u2206PROXYADD is positive and \u2206PROXYDELETE is negative. ", "page_idx": 15}, {"type": "table", "img_path": "EMkrwJY2de/tmp/f17777d00e113cea5610c103a57be5d5e08cd80c269d06e1c56b64e4d895fb78.jpg", "table_caption": ["Table 6: Computationally calculated criteria for the toy graph examples "], "table_footnote": [], "page_idx": 15}, {"type": "text", "text": "A.2 Proof of Propositions 3.3 and 3.4 ", "text_level": 1, "page_idx": 15}, {"type": "text", "text": "We choose one-dimensional features to follow normal distributions dependent on their class: $X_{i}\\sim$ ${\\mathcal{N}}(1,1)$ for class $(+)$ , and $X_{i}\\sim\\mathcal{N}(-1,1)$ for class $(-)$ . After one round of mean aggregation, class $(+)$ nodes with two intra-class neighbors will still have an expected mean value of 1, because they will aggregate three features that follow the same distribution: from themselves and the two neighbors. However, nodes like $X_{2}$ , which have one neighbor of each class, will have a lower expected value: $\\begin{array}{r}{\\frac{2-1}{3}=\\frac{1}{3}}\\end{array}$ . In general, if a (class $(+))$ ) node has $p$ same-class neighbors and $q$ different-class neighbors, their representation after an aggregation round will follow a normal distribution $\\begin{array}{r}{\\mathcal{N}(\\frac{1+p-q}{1+p+q},\\frac{1}{1+p+q})}\\end{array}$ ", "page_idx": 15}, {"type": "text", "text": "The smaller its expected mean is, the more it deviates from the original mean, and the less informative it gets. In Table 7 we show the expected values of each configuration dependent on the neighbors\u2019 classes as they appear on our four considered graphs. The class $(-)$ configurations are omitted because they are the same as the ones shown but with the opposite sign. ", "page_idx": 16}, {"type": "image", "img_path": "EMkrwJY2de/tmp/d482a309b6a1ec0deb550d6d95429048901781341b298cbad2f93852ecb7d55b.jpg", "img_caption": ["Figure 4: Neighboring configurations on each of the four graphs from Figure 1. "], "img_footnote": [], "page_idx": 16}, {"type": "text", "text": "Now we consider again the four graphs from Figure 1. In Figure 4 we specify which nodes have which configuration from the set {A, B, C, D, E} as named in Table 7. We arbitrarily choose orange nodes to be the negative class. After one round of mean aggregation on each of them, we can estimate the amount of class information remaining on the two classes by averaging the corresponding node representations of each node per class \u2014that is, we average the four expected means for purple nodes and the four expected means for orange nodes. We calculate these values in Table 8. As we intended to prove, they tend towards non-informative zero for both classes as the number of edges increases, and they follow the same order as the smoothing rate curves plotted in Figure 2(a). Proposition 3.3 is proved because values tend to zero \u2014so both classes\u2019 averages get closer together\u2014 from $g^{-}$ to $\\mathcal{G}$ , and from $\\mathcal{G}$ to both $\\mathcal{G}^{+}$ and $\\widetilde{\\mathcal{G}^{+}}$ . Proposition 3.4 is proved because the values from $\\mathcal{G}^{+}$ are more informative/further apart than the values from $\\widetilde{\\mathcal{G}^{+}}$ . \u53e3 ", "page_idx": 16}, {"type": "text", "text": "B How other label configurations affect the rings\u2019 smoothing rates ", "text_level": 1, "page_idx": 16}, {"type": "text", "text": "In Figure 5 we show how different configuration of labels for our example graphs affect their smoothing rate tests. In particular, we will analyze the result when added edges are intra-class instead of inter-class, as well as when the label distribution actively goes against the graph structure. ", "page_idx": 16}, {"type": "text", "text": "As a first modification (Figure 5(c)), we rotate the labels so that edge $\\{0,3\\}$ is now intra-class; this makes edge $\\{4,7\\}$ from $\\widetilde{\\mathcal{G}^{+}}$ intra-class, too. It is reflected in its smoothing rate plot in two main ways. First, the distance between graph $g^{-}$ and $\\mathcal{G}$ is not as wide, because the extra intra-edge in $\\mathcal{G}$ does not cause as much smoothing as the inter-class edge from the original configuration does. Second, graph $\\widetilde{\\mathcal{G}^{+}}$ is now the least smoothed. This might be because the two edges aid in isolating the flow of inform ation between the two, very distinct classes; note that this graph also has the smallest spectral gap, so the configuration of labels and the graph structure work towards the same goal. ", "page_idx": 16}, {"type": "table", "img_path": "EMkrwJY2de/tmp/deb70f70a1fbde4b4a7adbe5d3b156282c570a560e9021e8e2362a8403598e27.jpg", "table_caption": ["Table 8: Neighboring configurations for each graph, and their average value after a round of mean aggregation. "], "table_footnote": [], "page_idx": 17}, {"type": "image", "img_path": "EMkrwJY2de/tmp/5156aa98cefadc35aa95837142eb143ca23d3ba2985e0dce2e7c1da90038283d.jpg", "img_caption": ["Figure 5: Different configurations of labels/features for the example graphs of Figure 1, as well as their respective smoothing rate tests akin to Figure 2(a). Figure 5(a) is the original configuration, for direct comparison. Figure 5(c) rotates the labels and achieves more intra-class edges. Figure 5(e) achieves the same amount of intra-class edges but separates nodes with the same labels. Figure $5(\\mathrm{g)}$ alternates between classes and is a worse configuration to learn. "], "img_footnote": [], "page_idx": 17}, {"type": "text", "text": "As a second modification (Figure 5(e)), we alternate classes two by two nodes at a time. This makes $\\{0,3\\}$ and $\\{4,7\\}$ intra-class again, so it is directly comparable to the previous disposition. However, the edges in $\\bar{g^{+}}$ are not dividing the two classes so distinctively. This makes its smoothing occur more quickl y than before, now on par with the base graph. We consider this phenomenon to be directly related to its lower spectral gap. Another relevant aspect of this graph is that, still, the pruned graph ${\\dot{g}}^{-}$ smooths less than $\\mathcal{G}$ , even when the pruned edge is intra-class, and even if the spectral gap has increased; it is another instance of both mitigating over-smoothing and over-squashing. ", "page_idx": 17}, {"type": "text", "text": "Lastly (Figure $5(\\mathrm{g})$ ), we propose a configuration that is actively counterproductive to the structure of the ring, by alternating nodes of different classes one by one. As much as the spectral gap increases with the deletion of edge $\\{0,3\\}$ , the ring $g^{-}$ is a worse structure for the right kind of information to flow, and worse to avoid getting dissipated in this particular case. This unveils the ultimate limitation of not taking into account the task in a rewiring method, which is a trade-off to assume. ", "page_idx": 17}, {"type": "text", "text": "C Algorithms ", "text_level": 1, "page_idx": 18}, {"type": "text", "text": "Here we include the corresponding algorithms: PROXYDELETE (1), PROXYADD (2), ELDANADD (3), and ELDANDELETE (4). ", "page_idx": 18}, {"type": "text", "text": "Algorithm 1 Proxy Spectral Gap based Greedy Graph Sparsification (PROXYDELETE)   \nRequire: Graph $\\mathcal{G}=(\\mathcal{V},\\mathcal{E})$ , num. edges to prune $N$ , spectral gap $\\lambda_{1}(\\mathcal{L}_{\\mathcal{G}})$ , second eigenvector $f$ . repeat for $(u,v)\\in\\mathcal{E}$ do Consider $\\hat{\\mathcal{G}}=\\mathcal{G}\\setminus(u,v)$ . Calculate proxy value for the spectral gap of $\\hat{\\mathcal G}$ based on Eq. (1): $\\lambda_{1}(\\mathcal{L}_{\\hat{G}})\\approx\\lambda_{1}(\\mathcal{L}_{\\mathcal{G}})-((f_{u}-f_{v}^{*})^{2}-\\lambda_{1}^{*}(\\mathcal{L}_{\\mathcal{G}})\\cdot(f_{u}^{2}+f_{v}^{2}))$ end for Find the edge that maximizes the proxy: $(u^{-},v^{-})=\\operatorname{argmax}\\lambda_{1}(\\mathcal{L}_{\\hat{G}})$ . Update graph edges: $\\mathcal{E}=\\mathcal{E}\\setminus{(u^{-},v^{-})}$ . $(u,v){\\in}\\mathcal{E}$ Update degrees: $d_{u^{-}}=d_{u^{-}}-1,d_{v^{-}}=d_{v^{-}}-1$ Update eigenvectors and eigenvalues of $\\mathcal{G}$ accordingly. until $N$ edges deleted. Output : Sparse graph $\\hat{\\mathcal{G}}=(\\nu,\\hat{\\mathcal{E}})$ . ", "page_idx": 18}, {"type": "text", "text": "Algorithm 2 Proxy Spectral Gap based Greedy Graph Addition (PROXYADD) ", "page_idx": 18}, {"type": "text", "text": "Require: Graph $\\mathcal{G}=(\\mathcal{V},\\mathcal{E})$ , num. edges to add $N$ , spectral gap $\\lambda_{1}(\\mathcal{L}_{\\mathcal{G}})$ , second eigenvector $f$ of $\\mathcal{G}$ . repeat for $(u,v)\\in\\bar{\\mathcal{E}}$ do Consider $\\hat{\\mathcal{G}}=\\mathcal{G}\\cup(u,v)$ . Calculate proxy value for the spectral gap of $\\hat{\\mathcal G}$ based on Eq. (1): $\\lambda_{1}(\\mathcal{L}_{\\hat{G}})\\approx\\dot{\\lambda}_{1}(\\dot{\\mathcal{L}}_{\\mathcal{G}})+((f_{u}-\\dot{f_{v}})^{2}-\\dot{\\lambda_{1}}(\\dot{\\mathcal{L}}_{\\mathcal{G}})\\cdot(f_{u}^{2}+f_{v}^{2}))$ end for Find the edge that maximizes the proxy: $(u^{+},v^{+})=\\operatorname*{argmax}_{-}\\lambda_{1}(\\mathcal{L}_{\\hat{\\mathcal{G}}})$ . Update graph edges: $\\mathcal{E}=\\mathcal{E}\\cup(u^{+},v^{+})$ . (u,v)\u2208E\u00af Update degrees: $d_{u^{+}}=d_{u^{+}}+1,d_{v^{+}}=d_{v^{+}}+1$ Update eigenvectors and eigenvalues of $\\mathcal{G}$ accordingly. until $N$ edges added. Output : Denser graph $\\hat{\\mathcal{G}}=(\\mathcal{V},\\hat{\\mathcal{E}})$ . ", "page_idx": 18}, {"type": "text", "text": "Algorithm 3 Eldan based Greedy Graph Addition (ELDANADD) ", "page_idx": 18}, {"type": "text", "text": "Require: Graph $\\mathcal{G}=(\\mathcal{V},\\mathcal{E})$ , num. edges to add $N$ , spectral gap $\\lambda_{1}(\\mathcal{L}_{\\mathcal{G}})$ , top eigenvector $f$ of $\\mathcal{G}$ . repeat for edge $\\mathbf{\\boldsymbol{s}}(\\boldsymbol{u},\\boldsymbol{v})\\in\\bar{\\mathcal{E}}$ do Consider $\\hat{\\mathcal{G}}=\\mathcal{G}\\cup(u,v)$ . Compute projection $\\mathcal{P}_{f}^{2}=\\langle f,\\hat{f}_{0}\\rangle$ . Compute Eldan\u2019s criterion $g(u,v,\\mathcal{L}_{\\mathcal{G}})$ . end for Find the edge that minimizes the criterion: $\\left(u^{+},v^{+}\\right)=\\underset{(u,v)\\in\\bar{\\mathcal{E}}}{\\mathrm{argmax}}-g(u,v,\\mathcal{L}_{\\mathcal{G}}).$ . $\\mathcal{E}=\\mathcal{E}\\cup(u^{+},v^{+})$ . Update degrees $d_{u^{+}}=d_{u^{+}}+1,d_{v^{+}}=d_{v^{+}}+1$ Update eigenvectors and eigenvalues of $\\mathcal{G}$ accordingly. until $N$ edges added. Output : Denser graph $\\hat{\\mathcal{G}}=(\\mathcal{V},\\hat{\\mathcal{E}})$ . ", "page_idx": 18}, {"type": "text", "text": "Algorithm 4 Eldan based Greedy Graph Sparsification (ELDANDELETE) ", "page_idx": 19}, {"type": "text", "text": "Require: Graph $\\mathcal{G}=(\\mathcal{V},\\mathcal{E})$ , num. edges to prune $N$ , spectral gap $\\lambda_{1}(\\mathcal{L}_{\\mathcal{G}})$ , top eigenvector $f$ of $\\mathcal{G}$ . repeat for edge ${\\mathfrak{s}}(u,v)\\in{\\mathcal{E}}$ do Consider $\\hat{\\mathcal{G}}=\\mathcal{G}\\setminus(u,v)$ . {Note that the denser graph is the original $\\mathcal{G}$ , so we require approximations of $\\hat{f}$ and $\\lambda_{1}(\\mathcal{L}_{\\hat{G}})$ from the sparser $\\hat{\\mathcal G}$ .} Estimate eigenvector $\\hat{f}$ from $f$ based on the power iteration method. Estimate corresponding eigenvalue $\\lambda_{1}(\\mathcal{L}_{\\hat{G}})$ based on Eq. (1). Compute projection $\\mathcal{P}_{f}^{2}=\\langle\\hat{f},f_{0}\\rangle$ . Compute Eldan\u2019s criterion $g(u,v,\\mathcal{L}_{\\hat{\\mathcal{G}}})$ . end for Find the edge that maximizes the criterion: $(u^{-},v^{-})=\\operatorname*{argmax}_{\\mathbf{\\alpha}}g(u,v,\\mathcal{L}_{\\hat{\\mathcal{G}}})$ $\\hat{\\mathcal{E}}=\\hat{\\mathcal{E}}\\setminus(u^{-},v^{-})$ . $(u,v){\\in}\\mathcal{E}$ Update degrees $d_{u^{-}}=d_{u^{-}}-1,d_{v^{-}}=d_{v^{-}}-1$ Update eigenvectors and eigenvalues of $\\mathcal{G}$ accordingly. until $N$ edges deleted. Output : Sparse graph $\\hat{\\mathcal{G}}=(\\nu,\\hat{\\mathcal{E}})$ . ", "page_idx": 19}, {"type": "text", "text": "D Spectral pruning can slow down the rate of smoothing ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "In section $\\S3$ we have demonstrated the possibility of addressing both over-squashing and oversmoothing via spectral gap based pruning in a simple toy graph setting. Below we present the results on real-world graphs, where spectral pruning can help slow down the rate of smoothing. We adopt the same Linear GNN setup (Keriven, 2022). In Figure 6, we present two homophilic datasets (Cora and Citeseer) and two heterophilic graphs (Texas and Chameleon). For each of these experiments we add edges using FoSR (Karhadkar et al., 2023) and PROXYADD and delete edges using our proposed PROXYDELETE method. FoSR, which optimizes the spectral gap by adding edges, aids in mitigating over-squashing but inevitably leads to accelerating the smoothing rate. Conversely, if we delete edges using our PROXYDELETE method, the rate of smoothing is slowed down. It is also evident that our pruning method is more effective in heterophilous graph settings. This is likely due to the deletion of edges between nodes with different labels, thus preventing detrimental smoothing. We substantiate this by measuring the distance between nodes that have different labels, which should stay distinguishable. That is, our method deletes edges between nodes of different labels thus preventing unnecessary aggregation. We report the cosine distance for heterophilic graphs in Table 9 before training, after training on the original graph, and after training on the pruned graph. From the table it is clear that pruning edges increases the distance between nodes of different labels. Another popular metric in the literature to measure over-smoothing is Dirichlet energy, which can only measure the degree of smoothing, but not whether it is helpful for a learning task. To keep up with the trend, we plot the Dirichlet energy vs. Layers (Roth & Liebig, 2023) in Figure 7 on Cora and Texas. It is clear from the figure that our method slows down the decay of Dirichlet energy. Note that, since our method works purely on the graph topology, it cannot improve the Dirichlet energy like specialised methods (Zhou et al., 2021; Roth & Liebig, 2023; Rusch et al., 2023b). ", "page_idx": 19}, {"type": "text", "text": "In a recent work by Azabou et al. (2023), the authors also show similar experiments by introducing additional nodes to slow down the rate of message passing and thus slowing down the rate of smoothing. We achieve a similar effect just by pruning edges instead of introducing additional nodes. ", "page_idx": 19}, {"type": "text", "text": "E Additional results ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "E.1 Node classification. ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "We perform semi-supervised node classification on the following datasets: Cora (McCallum et al., 2000), Citeseer (Sen et al., 2008) and Pubmed (Namata et al., 2012). We report results on Chameleon, ", "page_idx": 19}, {"type": "image", "img_path": "EMkrwJY2de/tmp/d2ce9095e992dc0ad657a6d2ba2913a2af2a8826e839104f412f438b9642afe4.jpg", "img_caption": ["Figure 6: We show on real-world graphs that spectral pruning can not only mitigate over-squashing by improving the spectral gap but also slows down the rate of smoothing, thus effectively preventing over-smoothing as well. "], "img_footnote": [], "page_idx": 20}, {"type": "table", "img_path": "EMkrwJY2de/tmp/55d7dbf8b43c303afb39b54231ec68dd5688494d2b243171d37ed2cfa1383775.jpg", "table_caption": ["Table 9: Cosine distance between nodes of different labels before and after deleting edges using PROXYDELETE. "], "table_footnote": [], "page_idx": 20}, {"type": "text", "text": "Squirrel, Actor and the WebKB datasets consisting of Cornell, Wisconsin and Texas. Our baselines include GCN (Kipf & Welling, 2017) without any modifications to the original graph, DIGL by Gasteiger et al. (2019), SDRF by Topping et al. (2022), and FoSR by Karhadkar et al. (2023). We adopt the public implementations available and tune the hyperparameters to improve the performance if possible. Our results are presented in Table 10. We compare GCN with no edge modifications, GCN+DIGL, $\\mathrm{GCN+SDRF}$ , GCN+FoSR, GCN $+$ RandomDelete, $\\mathrm{GCN+}$ ELDANDELETE where we delete the edges, GCN $^+$ ELDANADD where we add the edges according to the criterion from Lemma 3.1 and PROXYADD and PROXYDELETE which use Equation (1) to optimize the spectral gap directly. The results for $\\operatorname{GCN+BORF}$ (Nguyen et al., 2023) are taken from the paper directly, hence NA for some datasets. The top performance is highlighted in bold. $\\scriptstyle\\mathrm{GCN+FoSR}$ outperforms all methods on Cora, Citeseer and Pubmed, which are homophilic. Yet, GCN $^+$ PROXYADD is more effective in increasing the spectral gap (see Table 16). On the remaining six datasets, our proposed methods both with edge deletions and additions outperform FoSR and SDRF, while outperforming all other baselines on all datasets. For training details and hyperparameters, please refer to the Appendix 19. ", "page_idx": 20}, {"type": "text", "text": "E.2 Graph classification with GCN and R-GCN ", "text_level": 1, "page_idx": 20}, {"type": "text", "text": "We conduct experiments on graph classification with a GCN (Kipf & Welling, 2017) and R-GCN (Battaglia et al., 2018) backbone to demonstrate the effectiveness of our proposed rewiring algorithms. ", "page_idx": 20}, {"type": "image", "img_path": "EMkrwJY2de/tmp/26a0e4bd22fa236d1141fadc007a1db21a78b847675cd0eef025ce4a984aa49b.jpg", "img_caption": ["Figure 7: We measure the Dirichlet energy and plot it for increasing depth on a homophilic dataset, Cora and a heterophilic dataset, Texas. For increasing depth, we can see PROXYDELMAX slows the decay of Dirichlet energy. "], "img_footnote": [], "page_idx": 21}, {"type": "table", "img_path": "EMkrwJY2de/tmp/1a89aa2484111de7b3dfdd3932b1ecacd904dd1a211daf60e824d56b23913e4c.jpg", "table_caption": ["Table 10: We compare the performance of GCN augmented with different graph rewiring methods on node classification. "], "table_footnote": [], "page_idx": 21}, {"type": "text", "text": "Our experimental setting is the same as that of FoSR by Karhadkar et al. (2023), with the difference being we tune our hyperparameters on 10 random splits instead of 100. The final test accuracy is averaged over 5 random splits of data. We compare our results with FoSR by Karhadkar et al. (2023). For the IMDB-BINARY, REDDIT-BINARY and COLLAB datasets there are no node features available and have to be created. For fair comparison we run FoSR on these datasets. For ENZYMES and MUTAG the results are taken from the values reported in the paper. The results are reported in Table 11 and 12. From the tables it is clear that our proposed algorithms are effective in increasing the generalization performance even for graph classification tasks. ", "page_idx": 21}, {"type": "table", "img_path": "EMkrwJY2de/tmp/7294ba779d2ba5c388b43f2e62436e519d5d44e8ac76a76d1c0a367bcbcd505d.jpg", "table_caption": ["Table 11: Graph classification with GCN comparing FoSR, ELDANADD and PROXYADD. "], "table_footnote": [], "page_idx": 21}, {"type": "table", "img_path": "EMkrwJY2de/tmp/c4932941fa2ada9203dacb4488162699a95024a3c0515eb0d6b8d5150d76e18f.jpg", "table_caption": ["Table 12: Graph classification with R-GCN comparing FoSR, ELDANADD and PROXYADD. "], "table_footnote": [], "page_idx": 21}, {"type": "text", "text": "E.3 Node classification using Relational-GCN ", "text_level": 1, "page_idx": 21}, {"type": "text", "text": "In Table 13 we compare FoSR (Karhadkar et al., 2023) and our proposed methods that use Eldan\u2019s criterion for adding edges and the PROXYADD method with a Relational-GCN backbone on 9 datasets. ", "page_idx": 21}, {"type": "text", "text": "We adopt the experimental setup and code base of (Karhadkar et al., 2023), with the exception of averaging over 10 random splits of data instead of 100. ", "page_idx": 22}, {"type": "table", "img_path": "EMkrwJY2de/tmp/f961b3a1db6413b13d22f13dc1249b6f1c49337f6a0bda8e495141044617d8b9.jpg", "table_caption": ["Table 13: Node classification using Relational-GCNs comparing FoSR, Eldan\u2019s criterion and PROXYADD. "], "table_footnote": [], "page_idx": 22}, {"type": "text", "text": "F Update period, empirical runtimes and spectral gap comparisons ", "text_level": 1, "page_idx": 22}, {"type": "text", "text": "In $\\S4.1$ , we have discussed the time complexity analysis of our proposed algorithms. Recall, that our algorithm has a hyperparameter $M$ , the number of edges to delete after ranking the edges using our proxy. For edge additions, the candidate edges that can be added are large, thus we can resort to sampling a constant set of edges to speed up the process. All of our experiments in $\\S5$ were conducted with $M=1$ . However, it is possible to further reduce the overall runtimes by tuning the value of $M$ , that is, how many edges we can modify before we have to recalculate the proxy to rank the edges again. This is shown in Table 15, where we compare our algorithms with $M=1$ and $M=10$ , for 50 edge modifications. It is clear that although $M=1$ leads to better spectral gap improvement, $M=10$ is also a valid updating period which induces enough spectral gap change while simultaneously bringing down the runtime (also presented in Table 14) considerably, especially for large graphs. To further evaluate the trade-off between the update period and its effect on GNN test accuracy, we use PROXYADD and PROXYDELETE with different $M$ updates on Cora and Texas datasets to modify 50 and 20 edges respectively. This is shown in Figure 8. Although a more frequent update points to better test accuracy, update periods with $\\lbrace5,10\\rbrace$ also yield competitive results. Thus reinforcing the fact that our proposed methods can be computationally efficient and can help in improving the generalization. In Table 16 we report the spectral gap changes induced by FoSR (Karhadkar et al., 2023), our proposed Eldan criterion based addition and deletions and also the Proxy versions of addition and deletions. In Table 17 we provide the runtimes for large heterophilic datasets (Platonov et al., 2023). ", "page_idx": 22}, {"type": "image", "img_path": "EMkrwJY2de/tmp/53d9bcfddd5abe2964f2fc15e315ef30088f0af228d682b48c3217b28d60032b.jpg", "img_caption": ["Figure 8: We investigate the trade-off between how frequently we need to update the ranking criterion vs. the test accuracy for GCN on Cora and Texas for node classification. "], "img_footnote": [], "page_idx": 22}, {"type": "table", "img_path": "EMkrwJY2de/tmp/c66537256f3ad89e7423d8b2f965f81746e4aaa3177e8f2e46ee37cb4b68c4b2.jpg", "table_caption": ["Table 14: Runtimes for 50 edge modifications in seconds. "], "table_footnote": [], "page_idx": 22}, {"type": "text", "text": "Table 15: Empirical runtime (RT) comparisons with different update periods for the criterion for 50 edges. We also report the spectral gap before (SG.B) and after rewiring (SG.A). ", "page_idx": 23}, {"type": "table", "img_path": "EMkrwJY2de/tmp/a5f3e0254f5eeaa43acdaf20a31a8012e0594f58156d946314e897f42380fb25.jpg", "table_caption": [], "table_footnote": [], "page_idx": 23}, {"type": "text", "text": "Table 16: We compare the spectral gap improvements of different rewiring methods for 50 edge modifications. From the table it is evident that our proposed PROXYADD and PROXYDELETE methods improve the spectral gap much better than FoSR. ", "page_idx": 23}, {"type": "table", "img_path": "EMkrwJY2de/tmp/b4ccff09b4c3f9c7237fa383733086b4f781c2418a05cc3ae169a81473189138.jpg", "table_caption": [], "table_footnote": [], "page_idx": 23}, {"type": "table", "img_path": "EMkrwJY2de/tmp/f62da20fc044100068f48d597121e5123dbb0209e80f060b81ba3dbdfcce841b.jpg", "table_caption": ["Table 17: Spectral gap changes and empirical runtimes for Large Heterophilic Datasets. "], "table_footnote": [], "page_idx": 23}, {"type": "text", "text": "G Pruning at initialization for graph lottery tickets ", "text_level": 1, "page_idx": 23}, {"type": "text", "text": "In Table 18, we present the results for Pruning at Initialization for finding graph lottery tickets. We first prune the input graph to the required sparsity level and then the weights are iteratively pruned by magnitude similar to the approach proposed by (Chen et al., 2021). From the table it is clear that, at least for moderate graph sparsity (GS) levels for Cora dataset, that is around $\\mathrm{GS}=18.75\\%$ , our proposed ELDANDELETE-UGS and PROXYDELETE attain comparable performance to UGS. On Pubmed for different graph sparsity levels we outperform UGS. Meanwhile, our method fails to identify winning tickets for Citeseer. We use the public implementation by the authors (Chen et al., 2021) for all our lottery ticket experiments. For all experiments we report the test accuracy on node classification averaged over 3 runs. Except for Pubmed which could only be averaged over 2 runs. ", "page_idx": 23}, {"type": "table", "img_path": "EMkrwJY2de/tmp/0172d1250b976c31735c8473477b6a873e9d8fad7cf0497d8e0f8a3b08b6d5e1.jpg", "table_caption": ["Table 18: We perform pruning at initialization to find graph lottery tickets. We compare UGS with our proposed methods for varying graph sparsity (GS) and weight sparsity (WS) levels. "], "table_footnote": [], "page_idx": 23}, {"type": "text", "text": "H Training details and hyperparameters ", "text_level": 1, "page_idx": 24}, {"type": "text", "text": "We instantiate a 2-layered GCN (Kipf & Welling, 2017) for semi-supervised node classification, the Planetoid datasets (Cora, Citeseer and Pubmed) are available as pytorch geometric datasets. For the WebKB datasets we use the updated ones given by Platonov et al. (2023). We use a 60/20/20 split for training/testing/validation respectively for all datasets. We perform extensive hyperparameter tuning on the validation set and finally report test accuracy averaged over 10 splits of the data (Chen et al., 2018). We use the largest connected component wherever available. The same experimental settings hold for other baselines DIGL, SDRF and FoSR. For node classification using R-GCNs, we also use a 3 layered GCN, this is highlighted in Table 20 with other hyperparameters. For graph classification, we use the same experimental setup as (Karhadkar et al., 2023), we use a 4-layered GCN and R-GCN versions. For the larger heterophilic datasets, we use the experimental setup given by the authors (Platonov et al., 2023). We set the learning rate to $\\{3e\\mathrm{~-~}3,3e\\mathrm{~-~}4\\}$ , dropout to 0.32, and the hidden dimension size to 512. For GATs, the attention heads are set to 8. The datasets are split into $50\\%/25\\%/25\\%$ for train, test and validation respectively. We tune our edge modification algorithms on the validation set. The final test accuracy is reported as averaged over 10 random splits run for 1000 steps. Skip connections and normalization (Ba et al., 2016) is used to facilitate training deeper models. We use PyTorch Geometric and DGL library for our experiments. All experiments were done on 2 V100 GPUs. Our code https://github.com/RelationalML/SpectralPruningBraess is available. ", "page_idx": 24}, {"type": "table", "img_path": "EMkrwJY2de/tmp/20056ffc7fd204c2b73cefc312a3750fa2113ee8c4d88ebc144a16f550e7e29f.jpg", "table_caption": ["Table 19: Hyperparameters for $\\scriptstyle\\mathrm{GCN+our}$ proposed rewiring algorithms. "], "table_footnote": [], "page_idx": 24}, {"type": "table", "img_path": "EMkrwJY2de/tmp/ebc931f6464c0888d2c4053c0cd24309035b0fa9f2c24cc8e60418577ae949d3.jpg", "table_caption": ["Table 20: Hyperparameters for R-GCN+PROXYADD on node classification "], "table_footnote": [], "page_idx": 24}, {"type": "table", "img_path": "EMkrwJY2de/tmp/182ef2bf4820f1bce2cbf042f7c4b04c3d866dba36e5a6b865606ee8c2ddd602.jpg", "table_caption": ["Table 21: Hyperparameters for graph classifica- Table 22: Hyperparameters for graph classification with $\\mathrm{GCN+}$ EldanAdd tion with GCN $^+$ PROXYADD "], "table_footnote": [], "page_idx": 24}, {"type": "table", "img_path": "EMkrwJY2de/tmp/50f787789c9013c2c76326a18a7608c69edebd7a94dbeecca3ee4fdac9df316c.jpg", "table_caption": ["Table 23: Hyperparameters for SDRF. "], "table_footnote": [], "page_idx": 25}, {"type": "table", "img_path": "EMkrwJY2de/tmp/bc56fdf1adb448aef0e2523c6694acd367c55ad21d2096c5d73c835776304fe2.jpg", "table_caption": ["Table 24: Hyperparameters for FoSR. "], "table_footnote": [], "page_idx": 25}, {"type": "table", "img_path": "EMkrwJY2de/tmp/bd4567ce95340f550583bce6dc3950d94f26ad6f6136caaec948350c2dc336a5.jpg", "table_caption": ["Table 25: Hyperparameters for DIGL. "], "table_footnote": [], "page_idx": 25}, {"type": "table", "img_path": "EMkrwJY2de/tmp/cedc898d2108defaf6d6b3e666d584bff641b2fa8be16f86836ffd86650f5733.jpg", "table_caption": ["Table 26: Hyperparameters for graph classification with R-GCN+EldanAdd "], "table_footnote": [], "page_idx": 25}, {"type": "table", "img_path": "EMkrwJY2de/tmp/7cc710e1f0cedf19f8bcd1b2ce682d59d155b4ae824e4a65f44f615c22f7822c.jpg", "table_caption": ["Table 27: Hyperparameters for graph classification with R-GCN $^+$ PROXYADD "], "table_footnote": [], "page_idx": 25}, {"type": "text", "text": "NeurIPS Paper Checklist ", "text_level": 1, "page_idx": 26}, {"type": "text", "text": "1. Claims ", "text_level": 1, "page_idx": 26}, {"type": "text", "text": "Question: Do the main claims made in the abstract and introduction accurately reflect the paper\u2019s contributions and scope? ", "page_idx": 26}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 26}, {"type": "text", "text": "Justification: We provide both theoretical and experimental proof to substantiate claims made in the abstract and introduction. ", "page_idx": 26}, {"type": "text", "text": "Guidelines: ", "page_idx": 26}, {"type": "text", "text": "\u2022 The answer NA means that the abstract and introduction do not include the claims made in the paper.   \n\u2022 The abstract and/or introduction should clearly state the claims made, including the contributions made in the paper and important assumptions and limitations. A No or NA answer to this question will not be perceived well by the reviewers.   \n\u2022 The claims made should match theoretical and experimental results, and reflect how much the results can be expected to generalize to other settings.   \n\u2022 It is fine to include aspirational goals as motivation as long as it is clear that these goals are not attained by the paper. ", "page_idx": 26}, {"type": "text", "text": "2. Limitations ", "text_level": 1, "page_idx": 26}, {"type": "text", "text": "Question: Does the paper discuss the limitations of the work performed by the authors? ", "page_idx": 26}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 26}, {"type": "text", "text": "Justification: We discuss computational efficiency of our proposed algorithms and its approximation quality. ", "page_idx": 26}, {"type": "text", "text": "Guidelines: ", "text_level": 1, "page_idx": 26}, {"type": "text", "text": "\u2022 The answer NA means that the paper has no limitation while the answer No means that the paper has limitations, but those are not discussed in the paper.   \n\u2022 The authors are encouraged to create a separate \"Limitations\" section in their paper.   \n\u2022 The paper should point out any strong assumptions and how robust the results are to violations of these assumptions (e.g., independence assumptions, noiseless settings, model well-specification, asymptotic approximations only holding locally). The authors should reflect on how these assumptions might be violated in practice and what the implications would be.   \n\u2022 The authors should reflect on the scope of the claims made, e.g., if the approach was only tested on a few datasets or with a few runs. In general, empirical results often depend on implicit assumptions, which should be articulated.   \n\u2022 The authors should reflect on the factors that influence the performance of the approach. For example, a facial recognition algorithm may perform poorly when image resolution is low or images are taken in low lighting. Or a speech-to-text system might not be used reliably to provide closed captions for online lectures because it fails to handle technical jargon.   \n\u2022 The authors should discuss the computational efficiency of the proposed algorithms and how they scale with dataset size.   \n\u2022 If applicable, the authors should discuss possible limitations of their approach to address problems of privacy and fairness.   \n\u2022 While the authors might fear that complete honesty about limitations might be used by reviewers as grounds for rejection, a worse outcome might be that reviewers discover limitations that aren\u2019t acknowledged in the paper. The authors should use their best judgment and recognize that individual actions in favor of transparency play an important role in developing norms that preserve the integrity of the community. Reviewers will be specifically instructed to not penalize honesty concerning limitations. ", "page_idx": 26}, {"type": "text", "text": "3. Theory Assumptions and Proofs ", "text_level": 1, "page_idx": 26}, {"type": "text", "text": "Question: For each theoretical result, does the paper provide the full set of assumptions and a complete (and correct) proof? ", "page_idx": 26}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 27}, {"type": "text", "text": "Justification: Informal proofs provided in the main paper. Formal proofs provided in the appendix. ", "page_idx": 27}, {"type": "text", "text": "Guidelines: ", "page_idx": 27}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include theoretical results.   \n\u2022 All the theorems, formulas, and proofs in the paper should be numbered and crossreferenced.   \n\u2022 All assumptions should be clearly stated or referenced in the statement of any theorems.   \n\u2022 The proofs can either appear in the main paper or the supplemental material, but if they appear in the supplemental material, the authors are encouraged to provide a short proof sketch to provide intuition.   \n\u2022 Inversely, any informal proof provided in the core of the paper should be complemented by formal proofs provided in appendix or supplemental material.   \n\u2022 Theorems and Lemmas that the proof relies upon should be properly referenced. ", "page_idx": 27}, {"type": "text", "text": "4. Experimental Result Reproducibility ", "text_level": 1, "page_idx": 27}, {"type": "text", "text": "Question: Does the paper fully disclose all the information needed to reproduce the main experimental results of the paper to the extent that it affects the main claims and/or conclusions of the paper (regardless of whether the code and data are provided or not)? ", "page_idx": 27}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 27}, {"type": "text", "text": "Justification: We provide all the hyperparameters and our code base to reproduce the results reported in the paper. ", "page_idx": 27}, {"type": "text", "text": "Guidelines: ", "page_idx": 27}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 If the paper includes experiments, a No answer to this question will not be perceived well by the reviewers: Making the paper reproducible is important, regardless of whether the code and data are provided or not.   \n\u2022 If the contribution is a dataset and/or model, the authors should describe the steps taken to make their results reproducible or verifiable.   \n\u2022 Depending on the contribution, reproducibility can be accomplished in various ways. For example, if the contribution is a novel architecture, describing the architecture fully might suffice, or if the contribution is a specific model and empirical evaluation, it may be necessary to either make it possible for others to replicate the model with the same dataset, or provide access to the model. In general. releasing code and data is often one good way to accomplish this, but reproducibility can also be provided via detailed instructions for how to replicate the results, access to a hosted model (e.g., in the case of a large language model), releasing of a model checkpoint, or other means that are appropriate to the research performed.   \n\u2022 While NeurIPS does not require releasing code, the conference does require all submissions to provide some reasonable avenue for reproducibility, which may depend on the nature of the contribution. For example (a) If the contribution is primarily a new algorithm, the paper should make it clear how to reproduce that algorithm. (b) If the contribution is primarily a new model architecture, the paper should describe the architecture clearly and fully. (c) If the contribution is a new model (e.g., a large language model), then there should either be a way to access this model for reproducing the results or a way to reproduce the model (e.g., with an open-source dataset or instructions for how to construct the dataset). (d) We recognize that reproducibility may be tricky in some cases, in which case authors are welcome to describe the particular way they provide for reproducibility. In the case of closed-source models, it may be that access to the model is limited in some way (e.g., to registered users), but it should be possible for other researchers to have some path to reproducing or verifying the results. ", "page_idx": 27}, {"type": "text", "text": "5. Open access to data and code ", "text_level": 1, "page_idx": 27}, {"type": "text", "text": "Question: Does the paper provide open access to the data and code, with sufficient instructions to faithfully reproduce the main experimental results, as described in supplemental material? ", "page_idx": 28}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 28}, {"type": "text", "text": "Justification: We provide the code base with the instructions to reproduce our results. Guidelines: ", "page_idx": 28}, {"type": "text", "text": "\u2022 The answer NA means that paper does not include experiments requiring code.   \n\u2022 Please see the NeurIPS code and data submission guidelines (https://nips.cc/ public/guides/CodeSubmissionPolicy) for more details.   \n\u2022 While we encourage the release of code and data, we understand that this might not be possible, so \u201cNo\u201d is an acceptable answer. Papers cannot be rejected simply for not including code, unless this is central to the contribution (e.g., for a new open-source benchmark).   \n\u2022 The instructions should contain the exact command and environment needed to run to reproduce the results. See the NeurIPS code and data submission guidelines (https: //nips.cc/public/guides/CodeSubmissionPolicy) for more details.   \n\u2022 The authors should provide instructions on data access and preparation, including how to access the raw data, preprocessed data, intermediate data, and generated data, etc.   \n\u2022 The authors should provide scripts to reproduce all experimental results for the new proposed method and baselines. If only a subset of experiments are reproducible, they should state which ones are omitted from the script and why.   \n\u2022 At submission time, to preserve anonymity, the authors should release anonymized versions (if applicable).   \n\u2022 Providing as much information as possible in supplemental material (appended to the paper) is recommended, but including URLs to data and code is permitted. ", "page_idx": 28}, {"type": "text", "text": "6. Experimental Setting/Details ", "text_level": 1, "page_idx": 28}, {"type": "text", "text": "Question: Does the paper specify all the training and test details (e.g., data splits, hyperparameters, how they were chosen, type of optimizer, etc.) necessary to understand the results? ", "page_idx": 28}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 28}, {"type": "text", "text": "Justification: Yes in the appendix. Guidelines: ", "page_idx": 28}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments. \u2022 The experimental setting should be presented in the core of the paper to a level of detail that is necessary to appreciate the results and make sense of them. \u2022 The full details can be provided either with the code, in appendix, or as supplemental material. ", "page_idx": 28}, {"type": "text", "text": "7. Experiment Statistical Significance ", "text_level": 1, "page_idx": 28}, {"type": "text", "text": "Question: Does the paper report error bars suitably and correctly defined or other appropriate information about the statistical significance of the experiments? ", "page_idx": 28}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 28}, {"type": "text", "text": "Justification: We provide confidence intervals for all the experiments conducted. Guidelines: ", "page_idx": 28}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 The authors should answer \"Yes\" if the results are accompanied by error bars, confidence intervals, or statistical significance tests, at least for the experiments that support the main claims of the paper.   \n\u2022 The factors of variability that the error bars are capturing should be clearly stated (for example, train/test split, initialization, random drawing of some parameter, or overall run with given experimental conditions).   \n\u2022 The method for calculating the error bars should be explained (closed form formula, call to a library function, bootstrap, etc.)   \n\u2022 The assumptions made should be given (e.g., Normally distributed errors).   \n\u2022 It should be clear whether the error bar is the standard deviation or the standard error of the mean.   \n\u2022 It is OK to report 1-sigma error bars, but one should state it. The authors should preferably report a 2-sigma error bar than state that they have a $96\\%$ CI, if the hypothesis of Normality of errors is not verified.   \n\u2022 For asymmetric distributions, the authors should be careful not to show in tables or figures symmetric error bars that would yield results that are out of range (e.g. negative error rates).   \n\u2022 If error bars are reported in tables or plots, The authors should explain in the text how they were calculated and reference the corresponding figures or tables in the text. ", "page_idx": 28}, {"type": "text", "text": "", "page_idx": 29}, {"type": "text", "text": "8. Experiments Compute Resources ", "text_level": 1, "page_idx": 29}, {"type": "text", "text": "Question: For each experiment, does the paper provide sufficient information on the computer resources (type of compute workers, memory, time of execution) needed to reproduce the experiments? ", "page_idx": 29}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 29}, {"type": "text", "text": "Justification: Discussed as part of the training details in the appendix. ", "page_idx": 29}, {"type": "text", "text": "Guidelines: ", "page_idx": 29}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 The paper should indicate the type of compute workers CPU or GPU, internal cluster, or cloud provider, including relevant memory and storage.   \n\u2022 The paper should provide the amount of compute required for each of the individual experimental runs as well as estimate the total compute.   \n\u2022 The paper should disclose whether the full research project required more compute than the experiments reported in the paper (e.g., preliminary or failed experiments that didn\u2019t make it into the paper). ", "page_idx": 29}, {"type": "text", "text": "9. Code Of Ethics ", "text_level": 1, "page_idx": 29}, {"type": "text", "text": "Question: Does the research conducted in the paper conform, in every respect, with the NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines? ", "page_idx": 29}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 29}, {"type": "text", "text": "Justification: [NA] ", "page_idx": 29}, {"type": "text", "text": "Guidelines: ", "page_idx": 29}, {"type": "text", "text": "\u2022 The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics.   \n\u2022 If the authors answer No, they should explain the special circumstances that require a deviation from the Code of Ethics.   \n\u2022 The authors should make sure to preserve anonymity (e.g., if there is a special consideration due to laws or regulations in their jurisdiction). ", "page_idx": 29}, {"type": "text", "text": "10. Broader Impacts ", "text_level": 1, "page_idx": 29}, {"type": "text", "text": "Question: Does the paper discuss both potential positive societal impacts and negative societal impacts of the work performed? ", "page_idx": 29}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 29}, {"type": "text", "text": "Justification: Our work deals mainly with understanding the constituent factors affecting the generalization performance of graph neural networks. Although GNNs themselves have broad range of applications, our method itself doesn\u2019t have societal impact as such. ", "page_idx": 29}, {"type": "text", "text": "Guidelines: ", "page_idx": 29}, {"type": "text", "text": "\u2022 The answer NA means that there is no societal impact of the work performed.   \n\u2022 If the authors answer NA or No, they should explain why their work has no societal impact or why the paper does not address societal impact.   \n\u2022 Examples of negative societal impacts include potential malicious or unintended uses (e.g., disinformation, generating fake profiles, surveillance), fairness considerations (e.g., deployment of technologies that could make decisions that unfairly impact specific groups), privacy considerations, and security considerations.   \n\u2022 The conference expects that many papers will be foundational research and not tied to particular applications, let alone deployments. However, if there is a direct path to any negative applications, the authors should point it out. For example, it is legitimate to point out that an improvement in the quality of generative models could be used to generate deepfakes for disinformation. On the other hand, it is not needed to point out that a generic algorithm for optimizing neural networks could enable people to train models that generate Deepfakes faster.   \n\u2022 The authors should consider possible harms that could arise when the technology is being used as intended and functioning correctly, harms that could arise when the technology is being used as intended but gives incorrect results, and harms following from (intentional or unintentional) misuse of the technology.   \n\u2022 If there are negative societal impacts, the authors could also discuss possible mitigation strategies (e.g., gated release of models, providing defenses in addition to attacks, mechanisms for monitoring misuse, mechanisms to monitor how a system learns from feedback over time, improving the efficiency and accessibility of ML). ", "page_idx": 29}, {"type": "text", "text": "", "page_idx": 30}, {"type": "text", "text": "11. Safeguards ", "text_level": 1, "page_idx": 30}, {"type": "text", "text": "Question: Does the paper describe safeguards that have been put in place for responsible release of data or models that have a high risk for misuse (e.g., pretrained language models, image generators, or scraped datasets)? ", "page_idx": 30}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 30}, {"type": "text", "text": "Justification: No such risks. ", "page_idx": 30}, {"type": "text", "text": "Guidelines: ", "page_idx": 30}, {"type": "text", "text": "\u2022 The answer NA means that the paper poses no such risks.   \n\u2022 Released models that have a high risk for misuse or dual-use should be released with necessary safeguards to allow for controlled use of the model, for example by requiring that users adhere to usage guidelines or restrictions to access the model or implementing safety filters.   \n\u2022 Datasets that have been scraped from the Internet could pose safety risks. The authors should describe how they avoided releasing unsafe images.   \n\u2022 We recognize that providing effective safeguards is challenging, and many papers do not require this, but we encourage authors to take this into account and make a best faith effort. ", "page_idx": 30}, {"type": "text", "text": "12. Licenses for existing assets ", "text_level": 1, "page_idx": 30}, {"type": "text", "text": "Question: Are the creators or original owners of assets (e.g., code, data, models), used in the paper, properly credited and are the license and terms of use explicitly mentioned and properly respected? ", "page_idx": 30}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 30}, {"type": "text", "text": "Justification: All codes and datasets used are properly attributed. ", "page_idx": 30}, {"type": "text", "text": "Guidelines: ", "page_idx": 30}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not use existing assets.   \n\u2022 The authors should cite the original paper that produced the code package or dataset.   \n\u2022 The authors should state which version of the asset is used and, if possible, include a URL.   \n\u2022 The name of the license (e.g., CC-BY 4.0) should be included for each asset.   \n\u2022 For scraped data from a particular source (e.g., website), the copyright and terms of service of that source should be provided.   \n\u2022 If assets are released, the license, copyright information, and terms of use in the package should be provided. For popular datasets, paperswithcode.com/datasets has curated licenses for some datasets. Their licensing guide can help determine the license of a dataset.   \n\u2022 For existing datasets that are re-packaged, both the original license and the license of the derived asset (if it has changed) should be provided. ", "page_idx": 30}, {"type": "text", "text": "\u2022 If this information is not available online, the authors are encouraged to reach out to the asset\u2019s creators. ", "page_idx": 31}, {"type": "text", "text": "13. New Assets ", "text_level": 1, "page_idx": 31}, {"type": "text", "text": "Question: Are new assets introduced in the paper well documented and is the documentation provided alongside the assets? ", "page_idx": 31}, {"type": "text", "text": "Answer: [NA]   \nJustification: No new assets released. Guidelines:   \n\u2022 The answer NA means that the paper does not release new assets.   \n\u2022 Researchers should communicate the details of the dataset/code/model as part of their submissions via structured templates. This includes details about training, license, limitations, etc.   \n\u2022 The paper should discuss whether and how consent was obtained from people whose asset is used.   \n\u2022 At submission time, remember to anonymize your assets (if applicable). You can either create an anonymized URL or include an anonymized zip file. ", "page_idx": 31}, {"type": "text", "text": "", "page_idx": 31}, {"type": "text", "text": "14. Crowdsourcing and Research with Human Subjects ", "text_level": 1, "page_idx": 31}, {"type": "text", "text": "Question: For crowdsourcing experiments and research with human subjects, does the paper include the full text of instructions given to participants and screenshots, if applicable, as well as details about compensation (if any)? ", "page_idx": 31}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 31}, {"type": "text", "text": "Justification: No crowdsourcing or human subjects. ", "page_idx": 31}, {"type": "text", "text": "Guidelines: ", "page_idx": 31}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u2022 Including this information in the supplemental material is fine, but if the main contribution of the paper involves human subjects, then as much detail as possible should be included in the main paper.   \n\u2022 According to the NeurIPS Code of Ethics, workers involved in data collection, curation, or other labor should be paid at least the minimum wage in the country of the data collector. ", "page_idx": 31}, {"type": "text", "text": "15. Institutional Review Board (IRB) Approvals or Equivalent for Research with Human Subjects ", "text_level": 1, "page_idx": 31}, {"type": "text", "text": "Question: Does the paper describe potential risks incurred by study participants, whether such risks were disclosed to the subjects, and whether Institutional Review Board (IRB) approvals (or an equivalent approval/review based on the requirements of your country or institution) were obtained? ", "page_idx": 31}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 31}, {"type": "text", "text": "Justification: Not applicable. ", "page_idx": 31}, {"type": "text", "text": "Guidelines: ", "page_idx": 31}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u2022 Depending on the country in which research is conducted, IRB approval (or equivalent) may be required for any human subjects research. If you obtained IRB approval, you should clearly state this in the paper.   \n\u2022 We recognize that the procedures for this may vary significantly between institutions and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the guidelines for their institution.   \n\u2022 For initial submissions, do not include any information that would break anonymity (if applicable), such as the institution conducting the review. ", "page_idx": 31}]