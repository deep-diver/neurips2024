[{"figure_path": "2jjfRm2R6D/figures/figures_6_1.jpg", "caption": "Figure 1: The Isabelle and Lean4 validation loss and token accuracy of various models fine-tuned on different data regimes, represented by curves of different colours: Green is Isabelle data only; Orange is the mixture of Isabelle and Lean4 data; and Purple is Lean4 data only. Fine-tuning on both languages yields lower validation loss at the end of the training than fine-tuning on one.", "description": "This figure shows the training curves for three different fine-tuning regimes on two language models (Isabelle and Lean4).  The x-axis represents the number of training steps, while the y-axis shows both the validation loss and token accuracy.  The three regimes are: fine-tuning on Isabelle data only (green), fine-tuning on a mixture of Isabelle and Lean4 data (orange), and fine-tuning on Lean4 data only (purple). The results indicate that fine-tuning on both languages leads to lower validation loss and comparable token accuracy compared to fine-tuning on a single language.", "section": "5 Results"}, {"figure_path": "2jjfRm2R6D/figures/figures_7_1.jpg", "caption": "Figure 2: The effort level it takes to correct 100 model-generated formalisations into acceptable forms in Isabelle (top) and Lean4 (bottom) with LLaMA (left) and Mistral (right). The blue bars represent the models that are not fine-tuned; the green bars represent models fine-tuned on Isabelle data only; the purple bars represent models fine-tuned on Lean4 data only; and the orange bars represent models fine-tuned on both Isabelle and Lean4 data. Generally, the models fine-tuned on both languages produce outputs that require less effort to correct than models fine-tuned on one.", "description": "This figure shows the effort required to correct 100 model-generated formalizations in Isabelle and Lean4 for four different model training scenarios: no fine-tuning, fine-tuning on Isabelle only, fine-tuning on Lean4 only, and fine-tuning on both Isabelle and Lean4.  The results are displayed using bar charts, separated by model (LLaMA and Mistral) and formal language (Isabelle and Lean4).  The chart demonstrates that models fine-tuned on both languages generally require less effort to correct.", "section": "5 Results"}, {"figure_path": "2jjfRm2R6D/figures/figures_14_1.jpg", "caption": "Figure 1: The Isabelle and Lean4 validation loss and token accuracy of various models fine-tuned on different data regimes, represented by curves of different colours: Green is Isabelle data only; Orange is the mixture of Isabelle and Lean4 data; and Purple is Lean4 data only. Fine-tuning on both languages yields lower validation loss at the end of the training than fine-tuning on one.", "description": "This figure shows the training curves for LLaMA model fine-tuned on different datasets: only Isabelle data, only Lean4 data, and both Isabelle and Lean4 data.  The plots show both training loss and token accuracy. The results indicate that fine-tuning with data from multiple formal languages leads to lower validation loss and higher accuracy compared to using data from a single formal language.", "section": "5 Results"}, {"figure_path": "2jjfRm2R6D/figures/figures_15_1.jpg", "caption": "Figure 1: The Isabelle and Lean4 validation loss and token accuracy of various models fine-tuned on different data regimes, represented by curves of different colours: Green is Isabelle data only; Orange is the mixture of Isabelle and Lean4 data; and Purple is Lean4 data only. Fine-tuning on both languages yields lower validation loss at the end of the training than fine-tuning on one.", "description": "This figure shows the training curves of three models fine-tuned on different datasets. The x-axis represents the training steps, while the y-axis shows the loss and token accuracy on the Isabelle and Lean4 validation sets. The results indicate that fine-tuning on both Isabelle and Lean4 datasets yields lower validation loss and higher accuracy than fine-tuning on only one dataset.", "section": "5 Results"}, {"figure_path": "2jjfRm2R6D/figures/figures_16_1.jpg", "caption": "Figure 1: The Isabelle and Lean4 validation loss and token accuracy of various models fine-tuned on different data regimes, represented by curves of different colours: Green is Isabelle data only; Orange is the mixture of Isabelle and Lean4 data; and Purple is Lean4 data only. Fine-tuning on both languages yields lower validation loss at the end of the training than fine-tuning on one.", "description": "The figure shows the training curves for three different fine-tuning regimes on two language models. The x-axis represents the training steps, while the y-axis represents both the validation loss and token accuracy. The three regimes are: fine-tuning on Isabelle data only (green), fine-tuning on both Isabelle and Lean4 data (orange), and fine-tuning on Lean4 data only (purple).  The results indicate that fine-tuning on multiple languages leads to lower validation loss and higher accuracy compared to single-language fine-tuning.", "section": "5 Results"}]