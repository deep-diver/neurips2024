[{"figure_path": "bCqIx5Q8qX/figures/figures_2_1.jpg", "caption": "Figure 1: Examples of images from the ImageNet dataset that AutoAttack fails to attack while MALT succeeds. The top row shows an APGD attack on the target class with the highest logit, and the bottom row shows an APGD attack on the class which MALT finds and succeeds, corresponding to the (a) 18th and (b) 52nd classes with the highest logits. The images are shown before and after the attack, and the change in logits is presented in the middle column.", "description": "This figure demonstrates two examples where AutoAttack fails to find an adversarial example, while MALT succeeds.  For each example, the top row shows the result of a standard APGD attack targeting the class with the highest confidence score (logit). The bottom row shows the results of an APGD attack targeting a different class, identified by MALT. The middle column shows a graph of the confidence scores for various classes as the perturbation is applied step-by-step, highlighting how MALT's targeting choice leads to a successful attack where AutoAttack failed.  This demonstrates MALT's ability to identify more effective target classes for adversarial attacks.", "section": "3 MALT \u2013 Mesoscopic Almost Linearity Targeting"}, {"figure_path": "bCqIx5Q8qX/figures/figures_6_1.jpg", "caption": "Figure 2: Measurement of mesoscopic almost linearity experimentally when taking a step v away from test image x0 for CIFAR100 and ImageNet. The results are averaged over all the images in the test set, where (a) random step; and (b) Direction of the gradient (adversarial step).", "description": "This figure empirically studies mesoscopic almost linearity in neural networks.  It shows plots of two measures (\u03b1 and \u03b1_part) against the step number (1 to 100), representing the change in gradient norm when moving from a data point towards an adversarial example.  Two different scenarios are presented: (a) taking random steps and (b) taking steps in the direction of the gradient (adversarial steps). The plots show results for CIFAR100 and ImageNet datasets, comparing how the gradient norm changes for both random and adversarial perturbations at the mesoscopic scale.", "section": "4.2 Empirical local linearity"}, {"figure_path": "bCqIx5Q8qX/figures/figures_7_1.jpg", "caption": "Figure 3: Empirical mesoscopic almost linearity: demonstrating the logits changes from an image x0 to its adversarial example. In the third row, we plot the model\u2019s output logits changes, and in the bottom row are the results of the linear approximation of the model at x0.", "description": "This figure empirically demonstrates the concept of mesoscopic almost linearity.  It shows how the logits (model's confidence scores for each class) change as a small adversarial perturbation is gradually added to an image.  The top row displays the original and perturbed images. The middle row shows the change in logits from the original image to the adversarially perturbed one. The bottom row depicts the change in logits predicted by a linear approximation of the model at the original image. The close resemblance between the model's actual changes and those predicted by the linear approximation supports the hypothesis of mesoscopic almost linearity, indicating that neural networks behave almost linearly at an intermediate scale around data points.", "section": "4 Mesoscopic Almost Linearity in Neural Networks"}, {"figure_path": "bCqIx5Q8qX/figures/figures_8_1.jpg", "caption": "Figure 4: Comparing targeting methods for Liu et al. [2023] SOTA model: The number of successful attacks for each target order by two targeting methods: In blue, we use MALT targeting and APGD, and in orange, we compare to APGD with top logits targeting performed in AutoAttack.", "description": "This figure compares the performance of two targeting methods for adversarial attacks: MALT and naive targeting.  The x-axis represents the rank order of the target class (1 being the highest-ranked class, and >3 indicating ranks 4 and above), while the y-axis shows the number of successful attacks achieved.  The bars show that MALT targeting significantly outperforms naive targeting in terms of the number of successful attacks for the top-ranked targets (ranks 1-3).  Naive targeting, by contrast, has more successful attacks when the targets are in lower rankings.", "section": "5.1 Targeting analysis"}, {"figure_path": "bCqIx5Q8qX/figures/figures_12_1.jpg", "caption": "Figure 1: Examples of images from the ImageNet dataset that AutoAttack fails to attack while MALT succeeds. The top row shows an APGD attack on the target class with the highest logit, and the bottom row shows an APGD attack on the class which MALT finds and succeeds, corresponding to the (a) 18th and (b) 52nd classes with the highest logits. The images are shown before and after the attack, and the change in logits is presented in the middle column.", "description": "This figure shows two examples where the state-of-the-art adversarial attack, AutoAttack, fails to find an adversarial example, while the proposed method, MALT, succeeds.  For each example, the top row shows the result of using the APGD attack on the target class selected by AutoAttack (based on confidence scores). The bottom row shows the result of using APGD on a different target class identified by MALT. The middle column for each example depicts the change in the confidence scores for all classes as the perturbation progresses from the original image to the adversarial example.  MALT's success highlights its ability to identify effective target classes that are missed by the conventional approach.", "section": "3 MALT \u2013 Mesoscopic Almost Linearity Targeting"}, {"figure_path": "bCqIx5Q8qX/figures/figures_13_1.jpg", "caption": "Figure 5: Additional examples of images from the ImageNet dataset that AutoAttack fails to attack while MALT succeeds. The top row shows an APGD attack on the target class with the highest logit, and the bottom row shows an APGD attack on the class that MALT finds and succeeds. (a) and (b) examples from Swin-L [Liu et al., 2023] network. (c) through (e) are from ConvNext-L [Liu et al., 2023] network. The images are shown before and after the attack, and the change in logits is presented in the middle column.", "description": "This figure shows five examples where AutoAttack fails to generate an adversarial example, while MALT succeeds. Each example shows an image and its corresponding adversarial example generated using AutoAttack's APGD attack and MALT's APGD attack. For each example, the top row illustrates the attack on the class with the highest predicted probability according to the model, while the bottom row shows the successful attack using the target class selected by MALT. The middle column displays the change in logit values during each attack, highlighting how MALT's target selection improves the success rate of the APGD attack.", "section": "3 MALT \u2013 Mesoscopic Almost Linearity Targeting"}, {"figure_path": "bCqIx5Q8qX/figures/figures_13_2.jpg", "caption": "Figure 5: Additional examples of images from the ImageNet dataset that AutoAttack fails to attack while MALT succeeds. The top row shows an APGD attack on the target class with the highest logit, and the bottom row shows an APGD attack on the class that MALT finds and succeeds. (a) and (b) examples from Swin-L [Liu et al., 2023] network. (c) through (e) are from ConvNext-L [Liu et al., 2023] network. The images are shown before and after the attack, and the change in logits is presented in the middle column.", "description": "This figure shows five examples where AutoAttack fails to generate adversarial examples, while MALT succeeds. Each example shows two APGD attacks. The top row shows an APGD attack on the target class with the highest logit, while the bottom row shows an APGD attack targeting the class selected by the MALT algorithm.  The middle column graphically displays the change in logits (network's confidence levels for each class) over the course of the attack.  The images are shown before and after the attack. This demonstrates MALT's effectiveness in finding successful targets that traditional methods miss.", "section": "3 MALT \u2013 Mesoscopic Almost Linearity Targeting"}, {"figure_path": "bCqIx5Q8qX/figures/figures_14_1.jpg", "caption": "Figure 5: Additional examples of images from the ImageNet dataset that AutoAttack fails to attack while MALT succeeds. The top row shows an APGD attack on the target class with the highest logit, and the bottom row shows an APGD attack on the class that MALT finds and succeeds. (a) and (b) examples from Swin-L [Liu et al., 2023] network. (c) through (e) are from ConvNext-L [Liu et al., 2023] network. The images are shown before and after the attack, and the change in logits is presented in the middle column.", "description": "This figure shows additional examples where the proposed MALT attack successfully finds adversarial examples while the state-of-the-art AutoAttack fails.  Each example shows two attacks: a naive APGD attack targeting the highest confidence class and a MALT-guided APGD attack.  The graphs illustrate the change in class confidences during the attack, highlighting MALT's ability to target less obvious classes.", "section": "3 MALT \u2013 Mesoscopic Almost Linearity Targeting"}]