[{"figure_path": "preo49P1VY/tables/tables_3_1.jpg", "caption": "Table 1: Categorization of existing methods as matrix mixers. L denotes input sequence length.", "description": "This table categorizes various existing sequence models based on their underlying matrix mixer structures. It shows the type of matrix used (e.g., dense, low-rank, Toeplitz), the computational complexity of the matrix multiplication, whether the matrix is sequence aligned (meaning the matrix parameters are data-dependent), and specific examples of models that utilize each type of matrix.  The table highlights the key properties that affect the efficiency and expressiveness of different sequence models.", "section": "2 The Matrix Mixer Framework: Bridging Sequence Mixers and Structured Matrices"}, {"figure_path": "preo49P1VY/tables/tables_5_1.jpg", "caption": "Table 2: Matrix mixer ablations. A systematic empirical study of matrix mixers on the GLUE benchmark by controlling for the architecture and varying only the matrix parameterization. Sequence-aligned matrices dynamically parameterize via input projections, becoming data-dependent (DD) that significantly increases performance. Most DD variants achieve competitive GLUE scores.", "description": "This table presents the results of an ablation study comparing various matrix mixer types on the GLUE benchmark.  The study controls for architectural differences, focusing solely on the impact of different matrix parameterizations.  Key findings highlight the significant performance boost achieved by using sequence-aligned matrices (which dynamically adjust parameters based on input projections), making them data-dependent.", "section": "4 Experiments"}, {"figure_path": "preo49P1VY/tables/tables_7_1.jpg", "caption": "Table 2: Matrix mixer ablations. A systematic empirical study of matrix mixers on the GLUE benchmark by controlling for the architecture and varying only the matrix parameterization. Sequence-aligned matrices dynamically parameterize via input projections, becoming data-dependent (DD) that significantly increases performance. Most DD variants achieve competitive GLUE scores.", "description": "This table presents the results of an ablation study comparing various matrix mixer types on the GLUE benchmark.  The study controls for architectural differences, varying only the matrix parameterization to isolate its impact on performance.  The results show that sequence-aligned matrices, which dynamically adapt their parameters based on input data, significantly improve performance compared to their data-independent counterparts.", "section": "4 Experiments"}, {"figure_path": "preo49P1VY/tables/tables_8_1.jpg", "caption": "Table 3: Performance of various approaches that extend Mamba to a bidirectional model. We compare our quasiseparable matrix mixer to element-wise addition (Add), the Hadamard product (Mult), and concatenation (Concat) variants.", "description": "This table compares different methods for extending the Mamba model to handle bidirectional sequences.  It contrasts the performance of a quasiseparable matrix mixer (the proposed Hydra model) against three simpler approaches: element-wise addition, Hadamard product, and concatenation. The comparison is done in terms of cross-entropy loss (Lce) during pretraining on the C4 dataset and the average GLUE score achieved after fine-tuning.", "section": "4.1.2 Ablating Approaches for Bidirectionality"}, {"figure_path": "preo49P1VY/tables/tables_9_1.jpg", "caption": "Table 4: GLUE Results. Evaluation of various sequence models that can be formulated as matrix mixers. For maximum performance, all models are trained using established recipes [32, 13].", "description": "This table presents the GLUE benchmark results for various sequence models, including BERT, MLP-Mixer, FNet, M2, and the proposed Hydra model.  All models were trained using established training recipes for optimal performance. The table shows the performance metrics (accuracy and cross-entropy loss) for each model on the different GLUE subtasks and the overall GLUE average score.", "section": "4.2 Evaluation Results of Hydra"}, {"figure_path": "preo49P1VY/tables/tables_9_2.jpg", "caption": "Table 5: Top 1 & 5 image classification accuracies evaluated on the ImageNet-1K benchmark. We also report accuracies using the common model ensembling technique: Exponential Moving Average (EMA) weights. (Top) Reported from literature [27, 31]. (Bottom): Our unidirectional and bidirectional Mamba results.", "description": "This table presents the top-1 and top-5 accuracies achieved by different models on the ImageNet-1K image classification benchmark.  It compares the performance of Hydra against several other state-of-the-art models, including ViT-B, S4-ViT-B, Hyena-ViT-B, and Mamba-ViT-B.  Results are shown with and without exponential moving average (EMA) ensembling for a more comprehensive comparison.", "section": "4.2.2 Image Classification"}, {"figure_path": "preo49P1VY/tables/tables_16_1.jpg", "caption": "Table 2: Matrix mixer ablations. A systematic empirical study of matrix mixers on the GLUE benchmark by controlling for the architecture and varying only the matrix parameterization. Sequence-aligned matrices dynamically parameterize via input projections, becoming data-dependent (DD) that significantly increases performance. Most DD variants achieve competitive GLUE scores.", "description": "This table presents the results of an ablation study comparing various matrix mixer architectures on the GLUE benchmark. The study controls for architectural differences, focusing solely on the impact of different matrix parameterizations.  The results show that sequence-aligned matrices, which dynamically adjust their parameters based on the input, significantly improve performance.", "section": "4 Experiments"}, {"figure_path": "preo49P1VY/tables/tables_16_2.jpg", "caption": "Table 2: Matrix mixer ablations. A systematic empirical study of matrix mixers on the GLUE benchmark by controlling for the architecture and varying only the matrix parameterization. Sequence-aligned matrices dynamically parameterize via input projections, becoming data-dependent (DD) that significantly increases performance. Most DD variants achieve competitive GLUE scores.", "description": "This table presents the results of an ablation study comparing different types of matrix mixers on the GLUE benchmark. The study controls for architectural differences to isolate the impact of the matrix parameterization. The results show that sequence-aligned matrices, which dynamically adjust their parameters based on the input data, significantly improve performance compared to their data-independent counterparts.  Most of the data-dependent variants achieve competitive GLUE scores.", "section": "4 Experiments"}, {"figure_path": "preo49P1VY/tables/tables_17_1.jpg", "caption": "Table 2: Matrix mixer ablations. A systematic empirical study of matrix mixers on the GLUE benchmark by controlling for the architecture and varying only the matrix parameterization. Sequence-aligned matrices dynamically parameterize via input projections, becoming data-dependent (DD) that significantly increases performance. Most DD variants achieve competitive GLUE scores.", "description": "This table presents the results of an ablation study on various matrix mixer architectures for natural language understanding. The study controls for architectural differences and isolates the impact of the matrix parameterization on the GLUE benchmark.  It highlights the benefit of sequence alignment, a key property in dynamically parameterizing matrix mixers, resulting in improved performance.  The table shows different matrix types, their parameter counts, and their performance across various GLUE sub-tasks.", "section": "4 Experiments"}, {"figure_path": "preo49P1VY/tables/tables_17_2.jpg", "caption": "Table 2: Matrix mixer ablations. A systematic empirical study of matrix mixers on the GLUE benchmark by controlling for the architecture and varying only the matrix parameterization. Sequence-aligned matrices dynamically parameterize via input projections, becoming data-dependent (DD) that significantly increases performance. Most DD variants achieve competitive GLUE scores.", "description": "This table presents the results of an ablation study comparing different types of matrix mixers used in a sequence model on the GLUE benchmark.  The study controls for architectural differences, varying only the matrix parameterization. The results show that sequence-aligned matrices, which dynamically adjust their parameters based on the input, significantly outperform non-sequence-aligned matrices.  The table also highlights the generally competitive GLUE scores achieved by most of the data-dependent variants.", "section": "4 Experiments"}]