[{"figure_path": "merJ77Jipt/tables/tables_1_1.jpg", "caption": "Table 1: Overview of key methods for CATE estimation (and predicting POs). UQ refers to whether the methods allow for uncertainty quantification of POs. Bias addressing refers to whether the methods address the selection bias. Orthogonal refers to whether it is robustness (i.e., Neyman-orthogonality wrt. nuisance functions). POs are the target refers to whether the methods are originally designed for the task of predicting POs.", "description": "This table provides a comparison of several key methods for conditional average treatment effect (CATE) estimation and potential outcome (PO) prediction.  It shows whether each method allows for uncertainty quantification (UQ), addresses selection bias, uses an orthogonal approach, and whether the method is designed specifically for PO prediction. Key limitations of each method are also listed.", "section": "2 Related Work"}, {"figure_path": "merJ77Jipt/tables/tables_5_1.jpg", "caption": "Table 1: Overview of key methods for CATE estimation (and predicting POs). UQ refers to whether the methods allow for uncertainty quantification of POs. Bias addressing refers to whether the methods address the selection bias. Orthogonal refers to whether it is robustness (i.e., Neyman-orthogonality wrt. nuisance functions). POs are the target refers to whether the methods are originally designed for the task of predicting POs.", "description": "This table compares various methods for estimating Conditional Average Treatment Effects (CATE) and predicting potential outcomes (POs).  It highlights key differences between the methods in terms of their ability to quantify uncertainty in POs, address selection bias, and utilize orthogonal properties for robustness. It also indicates whether each method was originally designed for PO prediction or primarily focuses on CATE estimation.  The table is useful in understanding the strengths and limitations of existing approaches and motivating the need for a new method that addresses shortcomings, such as uncertainty quantification and selection bias.", "section": "2 Related Work"}, {"figure_path": "merJ77Jipt/tables/tables_7_1.jpg", "caption": "Table 2: Results showing in- & out-of-sample empirical Wasserstein distance (i.e., Win and Wout) for two potential outcomes (i.e., a = 0 and a = 1) on the synthetic dataset. Reported: mean \u00b1 standard deviation over ten-fold train-test splits.", "description": "This table presents the in-sample and out-of-sample Wasserstein distances (W1 metric) for two different potential outcomes (a=0 and a=1) across multiple methods.  Lower values indicate better performance in learning the distribution of potential outcomes. The results are averaged over 10 train-test splits on a synthetic dataset.", "section": "6.1 Learning distributions of POs"}, {"figure_path": "merJ77Jipt/tables/tables_8_1.jpg", "caption": "Table 3: Results for uncertainty estimation of the two potential outcomes (i.e., a = 0 and a = 1). Reported: mean \u00b1 standard deviation over ten-fold train-test splits.", "description": "This table presents the results of evaluating the uncertainty estimation of the two potential outcomes (a=0 and a=1) using different methods. The results are reported as the mean \u00b1 standard deviation over ten-fold train-test splits.  The table shows the empirical coverage of 95% and 99% prediction intervals (PIs) generated by each model.  Higher values indicate better uncertainty quantification.", "section": "6.2 Learning predictive intervals of POs"}, {"figure_path": "merJ77Jipt/tables/tables_8_2.jpg", "caption": "Table 4: Results for point estimation of POs benchmarked using the in- & out-of-sample RMSE for the two potential outcomes (i.e., a = 0 and a = 1) on the synthetic dataset. Reported: mean \u00b1 standard deviation over ten-fold train-test splits.", "description": "This table presents the results of point estimation for potential outcomes (POs) using different methods.  It compares the root mean squared error (RMSE) for both in-sample and out-of-sample predictions on a synthetic dataset. The RMSE is calculated for each of the two potential outcomes (a=0 and a=1), which correspond to different treatments. Lower RMSE values indicate better performance. The results are averaged across ten-fold train-test splits and reported with standard deviations.", "section": "6.3 Point estimates of POs"}, {"figure_path": "merJ77Jipt/tables/tables_8_3.jpg", "caption": "Table 2: Results showing in- & out-of-sample empirical Wasserstein distance (i.e., Win and Wout) for two potential outcomes (i.e., a = 0 and a = 1) on the synthetic dataset. Reported: mean \u00b1 standard deviation over ten-fold train-test splits.", "description": "This table presents the performance comparison of different methods for learning the distributions of potential outcomes (POs) using the Wasserstein distance metric.  The table shows the in-sample (Win) and out-of-sample (Wout) Wasserstein distances for predicting potential outcomes under treatment (a=1) and control (a=0) conditions. The results are averaged over ten different train-test splits of the synthetic dataset, providing a robust evaluation of the methods' performance.", "section": "6.1 Learning distributions of POs"}]