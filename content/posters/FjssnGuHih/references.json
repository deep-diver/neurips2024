{"references": [{"fullname_first_author": "Kfir Aberman", "paper_title": "Deep saliency prior for reducing visual distraction", "publication_date": "2022-00-00", "reason": "This paper introduces a novel deep saliency prior for reducing visual distraction, which is directly relevant to the core task of the UniAR model."}, {"fullname_first_author": "Zoya Bylinskii", "paper_title": "Learning visual importance for graphic designs and data visualizations", "publication_date": "2017-00-00", "reason": "This paper explores predicting visual importance across diverse visual content, a key aspect that UniAR aims to unify."}, {"fullname_first_author": "Souradeep Chakraborty", "paper_title": "Predicting visual attention in graphic design documents", "publication_date": "2022-00-00", "reason": "This paper focuses on predicting attention in graphic designs, a specific task that UniAR addresses and achieves state-of-the-art performance on."}, {"fullname_first_author": "Camilo Fosco", "paper_title": "Predicting visual importance across graphic design types", "publication_date": "2020-00-00", "reason": "This paper tackles the prediction of visual importance in graphic design, providing a benchmark and methods that UniAR builds upon."}, {"fullname_first_author": "Tilke Judd", "paper_title": "Learning to predict where humans look", "publication_date": "2009-00-00", "reason": "This seminal work on predicting human fixations provides a foundation for the study of visual attention which UniAR aims to model across different visual content types."}]}