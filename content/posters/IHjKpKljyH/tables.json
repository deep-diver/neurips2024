[{"figure_path": "IHjKpKljyH/tables/tables_8_1.jpg", "caption": "Table 1: Experiment 4: RMSE and MMD between the ground-truth image vs. 100 draws from the approximators trained on 2000 and 60000 training images, aggregated over 100 test images. For MMD, we draw one denoised sample per test image and calculate the MMD between the denoised samples and the original images. Time per draw.", "description": "This table presents a quantitative comparison of the performance of CMPE and FMPE on the Fashion MNIST Bayesian denoising task.  It shows the RMSE (Root Mean Squared Error), MMD (Maximum Mean Discrepancy), and time per sample for both models using two different neural network architectures (a na\u00efve architecture and a U-Net architecture) and two different training set sizes (2000 and 60000 images).  Lower RMSE and MMD values indicate better performance, and shorter time per sample indicates faster inference.", "section": "4.4 Experiment 4: Bayesian denoising"}, {"figure_path": "IHjKpKljyH/tables/tables_9_1.jpg", "caption": "Table 2: Experiment 5. RMSE, ECE, and sampling time are computed for 2000 posterior samples, aggregated over 400 unseen test instances. Max ECE denotes the worst-case marginal calibration error across all 7 model parameters.", "description": "This table presents the results of Experiment 5, comparing different methods on a complex multi-scale model of 2D tumor spheroid growth.  It shows the Root Mean Squared Error (RMSE), Expected Calibration Error (ECE), and sampling time for each method.  Lower RMSE and ECE values indicate better accuracy and calibration, respectively, while lower time indicates faster inference. The \"Max ECE\" column shows the worst marginal calibration error across all 7 parameters of the model.", "section": "4.5 Experiment 5: Tumor spheroid growth"}, {"figure_path": "IHjKpKljyH/tables/tables_15_1.jpg", "caption": "Table 3: Design choices: Table and values adapted to our notation from Song and Dhariwal [46, Table 1].", "description": "This table details all functions and parameters required for training the consistency model.  It specifies the loss metric, discretization scheme, noise schedule, weighting function, skip connections, and various parameters used in the training process.  The values are largely adopted from Song and Dhariwal [46], with some modifications noted in the paper's text.", "section": "3.3 Optimization objective"}, {"figure_path": "IHjKpKljyH/tables/tables_18_1.jpg", "caption": "Table 4: Wall-clock training times on the benchmark tasks. M denotes the available simulation budget for the neural network training stage.", "description": "This table shows the training times for four different methods (ACF, NSF, FMPE, CMPE) across three benchmark tasks (Gaussian Mixture, Two Moons, Inverse Kinematics) and various simulation budget sizes (M). The training times are measured on a consumer-grade CPU and are not directly comparable across algorithms due to differences in training procedures and stopping criteria. The table highlights that while CMPE requires slightly longer training time than FMPE, its significantly faster inference speed makes it more suitable for real-time applications.", "section": "C.4 Unstandardized wall-clock times"}]