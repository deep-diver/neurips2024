[{"figure_path": "IHjKpKljyH/figures/figures_1_1.jpg", "caption": "Figure 1: Experiments 1-3. 1000 posterior draws for one unseen test instance per task, as well as sampling time in milliseconds. All amortized neural approximators were trained with a small budget of M = 1024 simulations. The bottom row shows the posterior predictive distribution in the kinematics task, and the pink cross-hair indicates the true end location x of the robot arm. Across all benchmarks, CMPE (Ours) yields the best trade-off between fast sampling speed and high accuracy. ACF: affine coupling flow, NSF: neural spline flow, FMPE: flow matching posterior estimation, CMPE: consistency model posterior estimation (Ours), K# denotes K sampling steps during inference.", "description": "This figure presents a comparison of different posterior estimation methods (ACF, NSF, FMPE, CMPE) on three benchmark tasks: Gaussian Mixture Model (GMM), Two Moons, and Inverse Kinematics.  For each method and task, 1000 posterior samples are drawn for a single unseen test instance.  The sampling time (in milliseconds) is shown for each method. The bottom row visualizes the posterior predictive distribution for the inverse kinematics task, highlighting the true value with a pink crosshair.  The results demonstrate that CMPE achieves the best balance between accuracy and sampling speed.", "section": "Experiments"}, {"figure_path": "IHjKpKljyH/figures/figures_7_1.jpg", "caption": "Figure 2: C2ST score of 4000 approximate posterior draws vs. reference posterior (lower is better) for J = 100 unseen test examples. (a) CMPE (Ours) outperforms all other methods through both faster and more accurate inference on the GMM benchmark (mean\u00b1SD). (b) CMPE (Ours) with 10 sampling steps shows superior performance up to a training budget of 4096 instances on the Two Moons benchmark (mean\u00b1SE).", "description": "This figure compares the performance of CMPE against other methods (ACF, NSF, FMPE) on two benchmark tasks: Gaussian Mixture Model and Two Moons.  The x-axis represents the sampling speed, and the y-axis shows the C2ST score, a measure of how well the approximated posterior matches the true posterior distribution (lower is better).  Panel (a) shows CMPE outperforming other methods on the Gaussian Mixture Model, demonstrating both speed and accuracy improvements. Panel (b) shows CMPE with 10 sampling steps maintaining a performance edge on the Two Moons benchmark up to a training budget of 4096 simulations, indicating its efficiency in low-data settings.", "section": "4 Empirical evaluation"}, {"figure_path": "IHjKpKljyH/figures/figures_7_2.jpg", "caption": "Figure 1: Experiments 1\u20133. 1000 posterior draws for one unseen test instance per task, as well as sampling time in milliseconds. All amortized neural approximators were trained with a small budget of  M = 1024 simulations. The bottom row shows the posterior predictive distribution in the kinematics task, and the pink cross-hair indicates the true end location x of the robot arm. Across all benchmarks, CMPE (Ours) yields the best trade-off between fast sampling speed and high accuracy. ACF: affine coupling flow, NSF: neural spline flow, FMPE: flow matching posterior estimation, CMPE: consistency model posterior estimation (Ours), K# denotes K sampling steps during inference.", "description": "This figure compares different methods for posterior estimation on three benchmark tasks: Gaussian Mixture Model, Two Moons, and Inverse Kinematics.  The results show the posterior predictive distributions obtained by each method, along with their sampling times. CMPE is shown to be faster and more accurate than other methods. ", "section": "Experiments"}, {"figure_path": "IHjKpKljyH/figures/figures_8_1.jpg", "caption": "Figure 3: Experiment 4. CMPE denoising results on Fashion MNIST (U-Net backbone, K = 2 sampling steps, 60000 training images). First row: Original image (target parameters \u03b8). Second row: Blurred image (observations x). Third and fourth row: Means and standard deviations of the approximate posteriors. Note: For standard deviations, darker regions indicate larger variability in the outputs. Adapted from [49]. More in Appendix C.6.", "description": "This figure shows the results of the Bayesian denoising experiment using CMPE on the Fashion MNIST dataset.  It compares the original images (ground truth) to their blurred versions (observations) and then presents the mean and standard deviation of the posterior distribution estimated using CMPE. Darker shades in the standard deviation plots represent higher variability in the model's predictions.", "section": "4.4 Experiment 4: Bayesian denoising"}, {"figure_path": "IHjKpKljyH/figures/figures_17_1.jpg", "caption": "Figure 1: Experiments 1\u20133. 1000 posterior draws for one unseen test instance per task, as well as sampling time in milliseconds. All amortized neural approximators were trained with a small budget of M = 1024 simulations. The bottom row shows the posterior predictive distribution in the kinematics task, and the pink cross-hair indicates the true end location x of the robot arm. Across all benchmarks, CMPE (Ours) yields the best trade-off between fast sampling speed and high accuracy. ACF: affine coupling flow, NSF: neural spline flow, FMPE: flow matching posterior estimation, CMPE: consistency model posterior estimation (Ours), K# denotes K sampling steps during inference.", "description": "This figure compares the performance of different posterior estimation methods (ACF, NSF, FMPE, CMPE) on three benchmark tasks (Gaussian Mixture Model, Two Moons, and Inverse Kinematics).  Each method's posterior predictive distribution is visualized, along with the sampling time. CMPE consistently shows superior performance in terms of both accuracy and speed, especially for fewer sampling steps.", "section": "1 Introduction"}, {"figure_path": "IHjKpKljyH/figures/figures_17_2.jpg", "caption": "Figure 2: C2ST score of 4000 approximate posterior draws vs. reference posterior (lower is better) for J = 100 unseen test examples. (a) CMPE (Ours) outperforms all other methods through both faster and more accurate inference on the GMM benchmark (mean\u00b1SD). (b) CMPE (Ours) with 10 sampling steps shows superior performance up to a training budget of 4096 instances on the Two Moons benchmark (mean\u00b1SE).", "description": "The figure shows the C2ST score (lower is better) for Gaussian Mixture Model and Two Moons benchmarks as a function of the simulation budget. CMPE consistently outperforms other methods in both speed and accuracy, especially for smaller training budgets.", "section": "4 Empirical evaluation"}, {"figure_path": "IHjKpKljyH/figures/figures_19_1.jpg", "caption": "Figure 5: Experiment 1-3. C2ST score of 4000 approximate posterior draws vs. reference posterior (lower is better), we report mean\u00b1SE over J = 100 unseen test examples at different numbers of inference steps. The minimum C2ST value is achieved around 10-20 inference steps for every benchmark, after which the value increases again.", "description": "The figure shows the C2ST score for three different benchmarks (Two Moons, GMM, Inverse Kinematics) as a function of the number of sampling steps used during inference with CMPE.  The C2ST score, measuring the accuracy of the posterior approximation, shows a U-shaped curve for all benchmarks.  The optimal number of sampling steps is around 10-20 for all three experiments, indicating a sweet spot for balancing speed and accuracy.", "section": "C.5 Empirical evaluation of optimal number of inference steps"}, {"figure_path": "IHjKpKljyH/figures/figures_20_1.jpg", "caption": "Figure 6: Experiment 5. Posterior draws for two parameters of the tumor growth model. Cross-hair and pink star indicate the ground-truth parameter that we aim to recover for one fixed data set x. The gray region depicts the prior distribution. CMPE (Ours) shows no visible bias even for two-step inference, but an improved sharpness when we increase the number of sampling steps to 30. In contrast, FMPE with 30 sampling steps (comparable speed to CMPE) yields a biased posterior. The posterior of FMPE with 1000 inference steps visibly improves but is orders of magnitude slower than CMPE with 30 steps.", "description": "This figure compares the performance of CMPE and FMPE on a complex tumor growth model.  The plots show the posterior distributions for two parameters (log division depth and log division rate). CMPE shows accurate and unbiased estimations using only 30 sampling steps, which is significantly faster than FMPE, even when FMPE uses 1000 sampling steps. While the 1000-step FMPE eventually produces a better result, CMPE's speed advantage is quite significant.", "section": "4.5 Experiment 5: Tumor spheroid growth"}, {"figure_path": "IHjKpKljyH/figures/figures_21_1.jpg", "caption": "Figure 7: Calibration plots for Experiment 5. The gray envelopes represent the 95% confidence bands for sufficient calibration. Inference times refers to the wall-clock time (in seconds) required to draw 2000 posterior samples. We emphasize the best performance for each metric in green, and the worst performance for each metric in darkred.", "description": "This figure shows the calibration plots for each of the methods used in Experiment 5 (Tumor Spheroid Growth). The plots show the ranked probability scores against the fractional rank statistics.  The shaded area represents the 95% confidence interval for perfect calibration. The inference times (in seconds) required to draw 2000 posterior samples are also provided for each method.  Green indicates the best performance, while dark red represents the worst for each metric.", "section": "4 Empirical evaluation"}, {"figure_path": "IHjKpKljyH/figures/figures_21_2.jpg", "caption": "Figure 7: Calibration plots for Experiment 5. The gray envelopes represent the 95% confidence bands for sufficient calibration. Inference times refers to the wall-clock time (in seconds) required to draw 2000 posterior samples. We emphasize the best performance for each metric in green, and the worst performance for each metric in darkred.", "description": "This figure presents calibration plots for Experiment 5, evaluating the performance of four different methods (ACF, NSF, FMPE, CMPE) in estimating the posterior distribution of a complex tumor spheroid growth model.  Each plot shows the rank-frequency distribution (ECDF) for each parameter, comparing the posterior samples generated by each method against the true posterior. The gray shaded area represents the 95% confidence interval for perfect calibration, and green/darkred indicate best/worst performance per metric.  Inference times (in seconds) for generating 2000 posterior samples are also provided, highlighting CMPE's speed advantage.", "section": "4 Empirical evaluation"}, {"figure_path": "IHjKpKljyH/figures/figures_21_3.jpg", "caption": "Figure 7: Calibration plots for Experiment 5. The gray envelopes represent the 95% confidence bands for sufficient calibration. Inference times refers to the wall-clock time (in seconds) required to draw 2000 posterior samples. We emphasize the best performance for each metric in green, and the worst performance for each metric in darkred.", "description": "This figure displays calibration plots for each of the five methods compared in Experiment 5 of the paper. The gray shaded areas represent the 95% confidence intervals for proper calibration.  The plots show the fractional rank statistic which is a measure of the accuracy of the calibration. The inference time, in seconds, for obtaining 2000 posterior samples is also given.  The best performing method for each metric is highlighted in green, while the worst-performing is in dark red.  The goal of the experiment is to evaluate the methods on a complex, computationally-expensive scientific simulator, comparing both accuracy, calibration and inference speed.", "section": "4 Empirical evaluation"}, {"figure_path": "IHjKpKljyH/figures/figures_21_4.jpg", "caption": "Figure 7: Calibration plots for Experiment 5. The gray envelopes represent the 95% confidence bands for sufficient calibration. Inference times refers to the wall-clock time (in seconds) required to draw 2000 posterior samples. We emphasize the best performance for each metric in green, and the worst performance for each metric in darkred.", "description": "This figure presents calibration plots for Experiment 5, which involved a complex multi-scale model of 2D tumor spheroid growth.  The plots show the results from different methods: Affine Coupling Flow (ACF), Neural Spline Flow (NSF), Flow Matching (FMPE) with 30 and 1000 steps, and Consistency Model Posterior Estimation (CMPE) with 2 and 30 steps. The gray shaded areas represent 95% confidence intervals for proper calibration.  The inference times (wall-clock time in seconds) needed to generate 2000 posterior samples for each method are also shown. Green indicates the best performance, while dark red shows the worst performance. The figure highlights CMPE's faster inference compared to other methods.", "section": "4 Empirical evaluation"}, {"figure_path": "IHjKpKljyH/figures/figures_21_5.jpg", "caption": "Figure 7: Calibration plots for Experiment 5. The gray envelopes represent the 95% confidence bands for sufficient calibration. Inference times refers to the wall-clock time (in seconds) required to draw 2000 posterior samples. We emphasize the best performance for each metric in green, and the worst performance for each metric in darkred.", "description": "This figure displays calibration plots obtained from Experiment 5, evaluating the performance of four methods: Affine Coupling Flow, Neural Spline Flow, Flow Matching (with 30 and 1000 steps), and Consistency Model (with 2 and 30 steps).  Each method's calibration is visually assessed using rank ECDFs and 95% confidence bands, showing the discrepancy between the model's predicted uncertainty and actual uncertainty.  Inference times (in seconds) for drawing 2000 samples are also indicated.  The figure helps to compare the calibration accuracy and efficiency of the different methods, highlighting CMPE's superior performance.", "section": "4 Empirical evaluation"}, {"figure_path": "IHjKpKljyH/figures/figures_21_6.jpg", "caption": "Figure 7: Calibration plots for Experiment 5. The gray envelopes represent the 95% confidence bands for sufficient calibration. Inference times refers to the wall-clock time (in seconds) required to draw 2000 posterior samples. We emphasize the best performance for each metric in green, and the worst performance for each metric in darkred.", "description": "This figure displays calibration plots for five different methods used in Experiment 5 of the paper, which focuses on a complex multi-scale model of 2D tumor spheroid growth.  The plots show the calibration of uncertainty estimates for each method using rank histograms.  The gray shaded regions indicate 95% confidence intervals for perfect calibration.  The best performing method (lowest RMSE and ECE) for each metric is highlighted in green, while the worst is shown in dark red.  Inference time for each method is also reported, illustrating the relative speed of each.", "section": "4 Empirical evaluation"}, {"figure_path": "IHjKpKljyH/figures/figures_22_1.jpg", "caption": "Figure 8: Pairplot of univariate and bivariate posterior draws obtained from CMPE (ours) and FMPE. FMPE clearly outperforms CMPE in this application, where the latter shows pathologically underexpressive posteriors that do not capture the nuances with acceptable detail (see text for details and hypotheses).", "description": "This figure shows a pairplot of the univariate and bivariate posterior distributions obtained using both CMPE and FMPE methods. The plot reveals that FMPE significantly outperforms CMPE in capturing the nuances of the posterior distribution. The CMPE posteriors appear underexpressive and lack the detail present in the FMPE posteriors.  This suggests a limitation of CMPE in certain applications where fine-grained details are crucial.", "section": "C.8 Experiment 6"}, {"figure_path": "IHjKpKljyH/figures/figures_23_1.jpg", "caption": "Figure 9: CMPE - U-Net architecture - 2000 training images. CMPE denoising results from each class of Fashion MNIST obtained using a U-Net architecture and two-step sampling. A small training set of 2000 images was used.", "description": "This figure shows the results of applying the CMPE model with a U-Net architecture to the Fashion MNIST dataset.  The model was trained on only 2000 images. Each row shows a different class from the Fashion MNIST dataset. The leftmost column displays the ground truth image (Param. \u03b8), followed by the noisy observation (Obs. x), and then five different samples generated by the model (Sample). This illustrates the model's ability to denoise images, even with a limited training set.", "section": "4.4 Experiment 4: Bayesian denoising"}, {"figure_path": "IHjKpKljyH/figures/figures_24_1.jpg", "caption": "Figure 9: CMPE - U-Net architecture - 2000 training images. CMPE denoising results from each class of Fashion MNIST obtained using a U-Net architecture and two-step sampling. A small training set of 2000 images was used.", "description": "This figure displays the results of applying the CMPE model with a U-Net architecture to the Fashion MNIST dataset for image denoising.  It shows the original images (Param. \u03b8), the noisy input images (Obs. x), and five samples generated by CMPE for each class, illustrating the model's ability to reconstruct the original image from a noisy version. The experiment used a limited training dataset of 2000 images.", "section": "4.4 Experiment 4: Bayesian denoising"}, {"figure_path": "IHjKpKljyH/figures/figures_25_1.jpg", "caption": "Figure 9: CMPE - U-Net architecture - 2000 training images. CMPE denoising results from each class of Fashion MNIST obtained using a U-Net architecture and two-step sampling. A small training set of 2000 images was used.", "description": "This figure shows the results of applying the CMPE method with a U-Net architecture to the Fashion MNIST dataset for image denoising.  The experiment used a small training set of 2000 images and a two-step sampling process. Each row represents a different class from the Fashion MNIST dataset, showing the original image (Param. \u03b8), the noisy observation (Obs. x), and several samples generated by CMPE. The samples demonstrate the model's ability to reconstruct the original image from the noisy input.", "section": "4.4 Experiment 4: Bayesian denoising"}, {"figure_path": "IHjKpKljyH/figures/figures_26_1.jpg", "caption": "Figure 9: CMPE - U-Net architecture - 2000 training images. CMPE denoising results from each class of Fashion MNIST obtained using a U-Net architecture and two-step sampling. A small training set of 2000 images was used.", "description": "This figure shows the results of applying the CMPE method with a U-Net architecture and two-step sampling on the Fashion MNIST dataset.  The dataset consists of images from 10 different clothing categories, each with a blurred version representing noisy observations.  The figure displays, for each category, the original image (Param. \u03b8), the noisy observation (Obs. x), and five denoised samples generated by CMPE.  The experiment used a small training set of only 2000 images.", "section": "4.4 Experiment 4: Bayesian denoising"}, {"figure_path": "IHjKpKljyH/figures/figures_27_1.jpg", "caption": "Figure 9: CMPE - U-Net architecture - 2000 training images. CMPE denoising results from each class of Fashion MNIST obtained using a U-Net architecture and two-step sampling. A small training set of 2000 images was used.", "description": "This figure shows the results of applying the CMPE method with a U-Net architecture to the Fashion MNIST dataset for image denoising.  A small training set of 2000 images was used. For each class of clothing in the dataset, the figure displays the true image (Param. \u03b8), the blurred noisy image (Obs. x), and 5 denoised samples generated by the model (Sample). This allows visualization of the model's ability to reconstruct the original image from noisy data.", "section": "4.4 Experiment 4: Bayesian denoising"}, {"figure_path": "IHjKpKljyH/figures/figures_28_1.jpg", "caption": "Figure 9: CMPE - U-Net architecture - 2000 training images. CMPE denoising results from each class of Fashion MNIST obtained using a U-Net architecture and two-step sampling. A small training set of 2000 images was used.", "description": "This figure shows the results of applying the CMPE method with a U-Net architecture to the Fashion MNIST dataset for image denoising.  A small training set of 2000 images was used.  The figure displays the true parameter (original image), the noisy observation (blurred image), and multiple samples from the posterior distribution generated by CMPE for each class of clothing in the dataset. This demonstrates the model's ability to reconstruct the original images from the noisy input.", "section": "Experiment 4: Bayesian denoising"}, {"figure_path": "IHjKpKljyH/figures/figures_29_1.jpg", "caption": "Figure 9: CMPE - U-Net architecture - 2000 training images. CMPE denoising results from each class of Fashion MNIST obtained using a U-Net architecture and two-step sampling. A small training set of 2000 images was used.", "description": "This figure shows the results of using the CMPE method with a U-Net architecture on the Fashion MNIST dataset.  The experiment used a small training set of 2000 images and employed a two-step sampling process during inference. Each row presents a different class from Fashion MNIST, displaying the original parameter (\u03b8), the noisy observation (x), and several posterior samples generated by CMPE.  This illustrates the model's ability to reconstruct images from noisy input.", "section": "4.4 Experiment 4: Bayesian denoising"}, {"figure_path": "IHjKpKljyH/figures/figures_30_1.jpg", "caption": "Figure 9: CMPE - U-Net architecture - 2000 training images. CMPE denoising results from each class of Fashion MNIST obtained using a U-Net architecture and two-step sampling. A small training set of 2000 images was used.", "description": "This figure shows the results of applying the CMPE method with a U-Net architecture to the Fashion MNIST dataset for image denoising.  The experiment used a small training set of 2000 images and employed two-step sampling. For each class in the dataset, the figure displays the original image (Param. \u03b8), the blurry observed image (Obs. x), and five samples generated by CMPE to illustrate the quality of the denoised images.", "section": "4.4 Experiment 4: Bayesian denoising"}]