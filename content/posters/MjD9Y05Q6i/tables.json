[{"figure_path": "MjD9Y05Q6i/tables/tables_6_1.jpg", "caption": "Table 1: The comprehensive evaluation of concept accuracy (%) for different CAVs on the Broden dataset. The results are on nine backbones pre-trained on ImageNet (Note that Res denotes ResNet, Dense denotes DenseNet) averaged over 4 runs with different seeds. Bold font denotes the best result.", "description": "This table presents a comprehensive comparison of concept accuracy scores for various CAV methods on the Broden dataset.  The evaluation is performed across nine different neural network architectures (ResNet-18, ResNet-34, ResNet-50, DenseNet-121, DenseNet-169, VGG-13, VGG-19, ViT-B, ViT-L), each pre-trained on ImageNet.  The results are averaged over four independent runs with different random seeds to ensure reliability. The highest accuracy for each architecture is highlighted in bold.", "section": "4.1.2 Experiment Results"}, {"figure_path": "MjD9Y05Q6i/tables/tables_6_2.jpg", "caption": "Table 2: The comprehensive evaluation of concept-to-class accuracy for different CAVs on the Broden dataset averaged over 4 runs with different seeds.", "description": "This table presents the concept-to-class accuracy results for various CAV methods on the Broden dataset.  Concept-to-class accuracy measures how well the CAV aligns with its semantically related class.  The table shows the performance of different CAV methods (Original CAV, Text-to-Concept, OA-TCAV, and the proposed LG-CAV with different modules added).  Results are averaged over four runs with different random seeds for each of nine different network architectures (ResNet-18, ResNet-34, ResNet-50, DenseNet-121, DenseNet-169, VGG-13, VGG-19, ViT-B, ViT-L).  Higher scores indicate better performance.", "section": "4.1.2 Experiment Results"}, {"figure_path": "MjD9Y05Q6i/tables/tables_7_1.jpg", "caption": "Table 3: The comprehensive evaluation of accuracy (%) on selected classes (40 classes) of ImageNet averaged over 4 runs with different seeds.", "description": "This table presents the accuracy results of different methods on a subset of 40 classes from the ImageNet dataset.  The methods compared include the original model, HiBug, and the proposed LG-CAV method.  The accuracy is averaged over four runs, each with a different random seed to assess the robustness and reliability of the results.  The table shows the performance of these methods across nine different model architectures (ResNet-18, ResNet-34, ResNet-50, DenseNet-121, DenseNet-169, VGG-13, VGG-19, ViT-B, and ViT-L).", "section": "4.2.2 Experiment Results"}, {"figure_path": "MjD9Y05Q6i/tables/tables_7_2.jpg", "caption": "Table 4: The comprehensive evaluation of accuracy (%) for different methods on ImageNet (note that KD denotes knowledge distillation) averaged over 4 runs with different seeds.", "description": "This table compares the accuracy of different model correction methods on the ImageNet dataset.  It shows the accuracy for ResNet-18, ResNet-34, ResNet-50, DenseNet-121, DenseNet-169, VGG-13, VGG-19, ViT-B, and ViT-L. The methods compared include the original model, Concept Distillation, Knowledge Distillation, Label-free CBM, and the proposed LG-CAV method.  The results are averaged over four runs with different random seeds to show the robustness and reliability of the results. ", "section": "4.2 Experiment Results"}, {"figure_path": "MjD9Y05Q6i/tables/tables_14_1.jpg", "caption": "Table 5: The averaged Recall@100 (%) of LG-CAVs on ImageNet-40. Random CAV denotes the randomly initialized CAV. Bold font denotes the best result.", "description": "This table presents the Recall@100 for different CAV methods on the ImageNet-40 dataset.  Recall@100 measures how well a CAV can identify the top 100 images most relevant to its concept from a set of test images.  The results are shown for nine different network architectures (ResNets, DenseNets, VGGs, and Vision Transformers). A randomly initialized CAV serves as a baseline.  Bold type indicates the best result for each architecture.", "section": "4.1.2 Experiment Results"}, {"figure_path": "MjD9Y05Q6i/tables/tables_14_2.jpg", "caption": "Table 6: The evaluation of accuracy (%) for different concept-based methods on the CUB-200-2011 dataset over five backbones. The results of PCBM & Trustworthy CBM & Label-free CBM are from their original paper.", "description": "This table compares the performance of different concept-based methods (including the proposed LG-CAV) on the CUB-200-2011 dataset.  The accuracy is measured across five different ResNet backbones (Res-10, Res-12, Res-14, Res-16, Res-18).  Results for PCBM, PCBM-h, and Trustworthy CBM are taken from the original papers, allowing for a direct comparison with the LG-CAV's performance.", "section": "4.2.2 Experiment Results"}, {"figure_path": "MjD9Y05Q6i/tables/tables_14_3.jpg", "caption": "Table 7: The comprehensive evaluation of accuracy (%) on selected classes (40 classes) of ImageNet averaged over 4 runs with different seeds.", "description": "This table presents the accuracy results achieved by the proposed LG-CAV method and compares it with the original CAV method's performance.  The results are averaged over four independent runs with different random seeds to ensure robustness. The accuracy is evaluated across 40 selected classes from the ImageNet dataset, and the performance is measured across nine different backbone architectures (ResNet-18, ResNet-34, ResNet-50, DenseNet-121, DenseNet-169, VGG-13, VGG-19, ViT-B, and ViT-L).", "section": "4.2.2 Experiment Results"}, {"figure_path": "MjD9Y05Q6i/tables/tables_15_1.jpg", "caption": "Table 8: The comprehensive evaluation of TCAV score (%) for different CAVs on the Broden dataset. Bold font denotes the best result.", "description": "This table presents a comparison of TCAV scores for various CAV methods on the Broden dataset.  TCAV (Testing with Concept Activation Vectors) score measures how well a CAV represents its associated concept.  The table shows the performance of the original CAV method and the improved LG-CAV method (with Gaussian alignment (GA), concept ensemble (CE), and deviation sample reweighting (DSR) modules) across nine different neural network backbones (ResNet-18, ResNet-34, ResNet-50, Dense-121, Dense-169, VGG-13, VGG-19, ViT-B, ViT-L).  Higher scores indicate better concept representation.", "section": "B.5 Additional Ablation Study"}, {"figure_path": "MjD9Y05Q6i/tables/tables_15_2.jpg", "caption": "Table 9: The comprehensive evaluation of concept accuracy (%) with different CLIP models in four target backbones (ResNet18, DenseNet121, VGG13, and ViT-B/16) on Broden.", "description": "This table shows the concept accuracy results of LG-CAV using different CLIP models (RN50x16, ViT-L/14, ViT-B/16, and ViT-B/32) as backbones.  The accuracy is measured across four different target models (ResNet18, DenseNet121, VGG13, and ViT-B/16) using the Broden dataset. The results demonstrate the impact of the choice of CLIP model on the performance of LG-CAV.", "section": "B.5.1 Different VL Models"}, {"figure_path": "MjD9Y05Q6i/tables/tables_15_3.jpg", "caption": "Table 10: The comprehensive evaluation of concept-to-class accuracy with different CLIP models in four target backbones (ResNet18, DenseNet121, VGG13, and ViT-B/16) on Broden.", "description": "This table shows the concept-to-class accuracy results for different CLIP models (RN50x16, ViT-L/14, ViT-B/16, and ViT-B/32) across four different backbones (ResNet18, DenseNet121, VGG13, and ViT-B/16) on the Broden dataset.  The concept-to-class accuracy metric assesses how well the CAV's align with the strongly semantic-related class. Higher values indicate better alignment and therefore higher quality CAVs.", "section": "B.5.1 Different VL Models"}, {"figure_path": "MjD9Y05Q6i/tables/tables_16_1.jpg", "caption": "Table 11: The comprehensive evaluation of concept accuracy (%) with different VL models in four target backbones (ResNet18, DenseNet121, VGG13, and ViT-B/16) on Broden. These VL models all adopt ViT-L/14 as backbones.", "description": "This table shows the concept accuracy results for different vision-language models (VLMs) used in training LG-CAV. The accuracy is evaluated across four different backbones (ResNet18, DenseNet121, VGG-13, and ViT-B/16) on the Broden dataset.  Each row represents a different VLM used (CLIP, EVA-CLIP, LaCLIP, and CLIPA). The original CAV results are also included for comparison.", "section": "B.5.1 Different VL Models"}, {"figure_path": "MjD9Y05Q6i/tables/tables_16_2.jpg", "caption": "Table 10: The comprehensive evaluation of concept-to-class accuracy (%) with different CLIP models in four target backbones (ResNet18, DenseNet121, VGG13, and ViT-B/16) on Broden.", "description": "This table presents the concept-to-class accuracy results for various CAV methods on the Broden dataset.  Different CLIP models (RN50x16, ViT-L/14, ViT-B/16, ViT-B/32) were used, and the results are broken down by four different backbones (ResNet18, DenseNet121, VGG13, ViT-B/16). The concept-to-class accuracy metric evaluates how well the CAV correlates with its strongly related class, assessing the quality of the CAV in identifying semantically similar classes.", "section": "B.5.1 Different VL Models"}, {"figure_path": "MjD9Y05Q6i/tables/tables_16_3.jpg", "caption": "Table 13: The comprehensive evaluation of concept accuracy (%) for intermediate features in three backbones (ResNet18, DenseNet121, and ViT-B/16) of the target model on the Broden dataset. Bold font denotes the best result.", "description": "This table presents the concept accuracy results for different configurations of the LG-CAV model. The concept accuracy is evaluated on the Broden dataset using three different backbones: ResNet18, DenseNet121, and ViT-B/16.  The table compares the performance of the original CAV method against several variations of the LG-CAV method, each incorporating additional modules (GA, CE, DSR).  Higher values indicate better performance. The bold values indicate the best-performing configuration for each backbone.", "section": "B.5.3 CAV Quality on Intermediate Features"}, {"figure_path": "MjD9Y05Q6i/tables/tables_17_1.jpg", "caption": "Table 14: The comprehensive evaluation of concept-to-class accuracy for intermediate features in three backbones (ResNet18, DenseNet121, and ViT-B/16) on Broden. Bold font denotes the best result.", "description": "This table presents the concept-to-class accuracy results for different CAV methods on the Broden dataset, specifically focusing on the performance using intermediate features from three different backbones (ResNet18, DenseNet121, and ViT-B/16).  The table compares the performance of the original CAV method against the LG-CAV method with different modules (GA, CE, and DSR).  The bold font highlights the best-performing method for each backbone.", "section": "B.5.3 CAV Quality on Intermediate Features"}, {"figure_path": "MjD9Y05Q6i/tables/tables_17_2.jpg", "caption": "Table 1: The comprehensive evaluation of concept accuracy (%) for different CAVs on the Broden dataset. The results are on nine backbones pre-trained on ImageNet (Note that Res denotes ResNet, Dense denotes DenseNet) averaged over 4 runs with different seeds. Bold font denotes the best result.", "description": "This table presents the concept accuracy results for different CAV methods on the Broden dataset.  Concept accuracy measures how well a CAV represents its corresponding concept. The results are broken down by nine different ImageNet pre-trained backbones (ResNet-18, ResNet-34, ResNet-50, DenseNet-121, DenseNet-169, VGG-13, VGG-19, ViT-B, ViT-L), with the best result for each backbone highlighted in bold. The experiment was run four times with different random seeds, and the average is reported.", "section": "4.1.2 Experiment Results"}, {"figure_path": "MjD9Y05Q6i/tables/tables_18_1.jpg", "caption": "Table 2: The comprehensive evaluation of concept-to-class accuracy for different CAVs on the Broden dataset averaged over 4 runs with different seeds.", "description": "This table presents a comparison of concept-to-class accuracy across various CAV (Concept Activation Vector) methods on the Broden dataset.  The results are averaged over four independent runs with different random seeds to ensure statistical robustness.  Concept-to-class accuracy measures how well a CAV's representation of a concept aligns with its strongly semantically related class, offering a measure of the CAV's quality.  The table shows that the proposed LG-CAV method significantly outperforms existing CAV methods across multiple different neural network architectures.", "section": "4.1.2 Experiment Results"}, {"figure_path": "MjD9Y05Q6i/tables/tables_18_2.jpg", "caption": "Table 4: The comprehensive evaluation of accuracy (%) for different methods on ImageNet (note that KD denotes knowledge distillation) averaged over 4 runs with different seeds.", "description": "This table presents a comprehensive evaluation of the accuracy achieved by different methods on the ImageNet dataset.  The methods compared include the original model, Concept Distillation, Knowledge Distillation, Label-free CBM, and the proposed LG-CAV method.  The results are averaged over four runs using different random seeds, providing a measure of robustness and reliability.  The table highlights the performance improvements obtained by the LG-CAV approach compared to existing state-of-the-art methods.", "section": "4.2 Experiment Results"}, {"figure_path": "MjD9Y05Q6i/tables/tables_19_1.jpg", "caption": "Table 1: The comprehensive evaluation of concept accuracy (%) for different CAVs on the Broden dataset. The results are on nine backbones pre-trained on ImageNet (Note that Res denotes ResNet, Dense denotes DenseNet) averaged over 4 runs with different seeds. Bold font denotes the best result.", "description": "This table presents a comprehensive comparison of concept accuracy across various CAV (Concept Activation Vector) methods on the Broden dataset.  The evaluation considers nine different pre-trained ImageNet backbones (ResNet, DenseNet, VGG, ViT).  Results are averaged over four runs with varying random seeds to ensure reliability, with the best performing method highlighted in bold font.", "section": "4.1.2 Experiment Results"}, {"figure_path": "MjD9Y05Q6i/tables/tables_20_1.jpg", "caption": "Table 1: The comprehensive evaluation of concept accuracy (%) for different CAVs on the Broden dataset. The results are on nine backbones pre-trained on ImageNet (Note that Res denotes ResNet, Dense denotes DenseNet) averaged over 4 runs with different seeds. Bold font denotes the best result.", "description": "This table presents a comparison of concept accuracy scores for different CAV (Concept Activation Vector) methods on the Broden dataset.  The evaluation was performed across nine different neural network architectures (ResNet18, ResNet34, ResNet50, DenseNet121, DenseNet169, VGG13, VGG19, ViT-B, ViT-L) pre-trained on ImageNet.  The results are averaged across four independent runs to ensure robustness. The best performing method for each architecture is highlighted in bold.", "section": "4.1.2 Experiment Results"}]