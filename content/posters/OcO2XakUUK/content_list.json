[{"type": "text", "text": "Realizable H-Consistent and Bayes-Consistent Loss Functions for Learning to Defer ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Anqi Mao Mehryar Mohri Yutao Zhong Courant Institute Google Research & CIMS Courant Institute New York, NY 10012 New York, NY 10011 New York, NY 10012 aqmao@cims.nyu.edu mohri@google.com yutao@cims.nyu.edu ", "page_idx": 0}, {"type": "text", "text": "Abstract ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "We present a comprehensive study of surrogate loss functions for learning to defer. We introduce a broad family of surrogate losses, parameterized by a non-increasing function $\\Psi$ , and establish their realizable $\\mathcal{H}$ -consistency under mild conditions. For cost functions based on classification error, we further show that these loss functions admit $\\mathcal{H}$ -consistency bounds when the hypothesis set is symmetric and complete, a property satisfied by common neural network and linear function hypothesis sets. Our results also resolve an open question raised in previous work [Mozannar et al., 2023] by proving the realizable $\\mathcal{H}$ -consistency and Bayes-consistency of a specific surrogate loss. Furthermore, we identify choices of $\\Psi$ that lead to $\\mathcal{H}$ -consistent surrogate losses for any general cost function, thus achieving Bayesconsistency, realizable $\\mathcal{H}$ -consistency, and $\\mathcal{H}$ -consistency bounds simultaneously. We also investigate the relationship between $\\mathcal{H}$ -consistency bounds and realizable $\\mathcal{H}$ -consistency in learning to defer, highlighting key differences from standard classification. Finally, we empirically evaluate our proposed surrogate losses and compare them with existing baselines. ", "page_idx": 0}, {"type": "text", "text": "1 Introduction ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "In many practical scenarios, combining expert insights with established models can yield significant enhancements. These experts can be human domain specialists or more complex, albeit resourceintensive, models. For example, modern language and dialogue models are prone to producing hallucinations or inaccurate information. The quality of their responses can be significantly enhanced by delegating uncertain predictions to more specialized or advanced pre-trained models. This problem is particularly crucial for large language models (LLMs), as noted in [Wei et al., 2022, Bubeck et al., 2023]. The same principle applies to other generative systems, like those for images or videos, and to learning models in diverse applications such as image classification, annotation, and speech recognition. Thus, the task of learning to defer (L2D) with experts has become increasingly critical across a wide array of applications. ", "page_idx": 0}, {"type": "text", "text": "Directly optimizing the deferral loss function, which is the target loss in L2D, is computationally intractable for many choices of the hypothesis set. Therefore, a common approach is to optimize a surrogate loss that facilitates the optimization of the deferral loss function. Recent work in L2D has proposed several surrogate losses [Mozannar and Sontag, 2020, Verma and Nalisnick, 2022, Mozannar et al., 2023, Mao et al., 2024a] and studied their consistency guarantees, including Bayes-consistency, realizable $\\mathcal{H}$ -consistency, and $\\mathcal{H}$ -consistency bounds (see definitions in Section 3.2). In particular, Mozannar and Sontag [2020] proposed the first Bayes-consistent surrogate loss by generalizing the cross-entropy loss for L2D. Verma and Nalisnick [2022] proposed an alternative Bayes-consistent surrogate loss by generalizing the one-versus-all loss for L2D. Mozannar et al. [2023] showed that these surrogate losses are not realizable $\\mathcal{H}$ -consistent. They proposed an alternative surrogate loss that is realizable $\\mathcal{H}$ -consistent, but they were unable to prove or disprove whether the proposed surrogate loss is Bayes-consistent. All the surrogate losses mentioned above and their consistency guarantees hold only for cost functions based on classification error. Mao et al. [2024a] generalized the surrogate loss in [Mozannar and Sontag, 2020] to incorporate general cost functions and any multi-class surrogate losses. They provided $\\mathcal{H}$ -consistency bounds for the novel family of surrogate losses, offering a stronger guarantee than Bayes-consistency. ", "page_idx": 0}, {"type": "text", "text": "", "page_idx": 1}, {"type": "text", "text": "However, none of these surrogate losses satisfies all these guarantees simultaneously. In particular, a recent AISTATS notable award paper by Mozannar et al. [2023] left open the problem of finding surrogate losses that are both Bayes-consistent and realizable $\\mathcal{H}$ -consistent when the cost function for the expert is its classification error. The problem becomes even more challenging when considering more general and realistic cost functions. ", "page_idx": 1}, {"type": "text", "text": "We present a comprehensive analysis of surrogate loss functions for L2D. Our contributions address the limitations of previous approaches and provide a unified framework for designing surrogate losses with strong theoretical guarantees. In Section 4, we first introduce a broad family of surrogate losses for L2D, derived from first principles (Section 4.1). This family is parameterized by a non-increasing function $\\Psi$ , which provides some flexibility in tailoring the loss function to specific requirements. We establish that under mild conditions on $\\Psi$ , these surrogate losses achieve realizable $\\mathcal{H}$ -consistency, a key guarantee for many applications (Section 4.2). ", "page_idx": 1}, {"type": "text", "text": "Next, for cost functions based on classification error, we further establish that our surrogate loss functions admit $\\mathcal{H}$ -consistency bounds when the hypothesis set is symmetric and complete (Section 4.3). This result holds for commonly used neural network and linear function hypothesis sets, further strengthening the applicability of our results. Additionally, our results resolve an open question raised by Mozannar et al. [2023] by proving the realizable $\\mathcal{H}$ -consistency and Bayes-consistency of their proposed surrogate loss, which the authors had left as an open question (Section 4.4). ", "page_idx": 1}, {"type": "text", "text": "In Section 4.3, we further identify specific choices of $\\Psi$ , such as the one corresponding to the mean absolute error loss, that lead to $\\mathcal{H}$ -consistent surrogate losses for any general cost function. These loss functions are adapted to general cost functions and benefti from Bayes-consistency (Section 4.4), realizable $\\mathcal{H}$ -consistency, and H-consistency bounds simultaneously. ", "page_idx": 1}, {"type": "text", "text": "In Section 5, we also study the relationship between $\\mathcal{H}$ -consistency bounds and realizable $\\mathcal{H}.$ - consistency in the context of L2D, highlighting key distinctions from the standard classification setting. Finally, we further report the results of experiments with our new surrogate losses and their comparison with the baselines in different settings (Section 6). ", "page_idx": 1}, {"type": "text", "text": "We discuss the related work in Section 2 and then begin with the preliminaries in Section 3. ", "page_idx": 1}, {"type": "text", "text": "2 Related work ", "text_level": 1, "page_idx": 1}, {"type": "text", "text": "The approach of single-stage learning to defer, where a predictor and a deferral function are trained together, was pioneered by Cortes, DeSalvo, and Mohri [2016a,b, 2023] and further developed in subsequent studies on abstention, where the cost is constant [Charoenphakdee et al., 2021, Cao et al., 2022, Li et al., 2023, Cheng et al., 2023, Mao et al., 2024c,b, Mohri et al., 2024] and on deferral, where the cost can vary depending on the instance and the label [Mozannar and Sontag, 2020, Verma and Nalisnick, 2022, Mozannar et al., 2023, Verma et al., 2023, Cao et al., 2023, Mao et al., 2023a, 2024a]. In this approach, the deferral function determines whether to defer to an expert for each input. This approach has been shown to be superior to confidence-based approaches, where the decision to abstain or defer is based solely on the magnitude of the predictor\u2019s value [Chow, 1957, 1970, Bartlett and Wegkamp, 2008, Yuan and Wegkamp, 2010, 2011, Ramaswamy et al., 2018, Ni et al., 2019, Jitkrittum et al., 2023]; and to selective classification approaches, where the selection rate is fixed and a cost function modeled by an expert cannot be taken into account [El-Yaniv et al., 2010, El-Yaniv and Wiener, 2012, Wiener and El-Yaniv, 2011, 2012, 2015, Geifman and El-Yaniv, 2017, 2019, Acar et al., 2020, Gangrade et al., 2021, Zaoui et al., 2020, Jiang et al., 2020, Shah et al., 2022]. ", "page_idx": 1}, {"type": "text", "text": "Madras et al. [2018] initiated the learning to defer (L2D) problem scenario, which integrates human expert decisions into the cost function. This approach has been further explored in subsequent studies [Raghu et al., 2019, Wilder et al., 2021, Pradier et al., 2021]. Mozannar and Sontag [2020] introduced the first Bayes-consistent surrogate loss for L2D, which was further refined in [Raman and Yee, 2021, Liu et al., 2022]. Verma and Nalisnick [2022] proposed an alternative Bayes-consistent surrogate loss, the one-versus-all loss, which was later examined within a broader family of loss functions [Charusaie et al., 2022]. Cao et al. [2023] proposed an asymmetric softmax function, which can induce a valid probability estimator for learning to defer. Mozannar et al. [2023] showed that the surrogate losses in [Mozannar and Sontag, 2020, Verma and Nalisnick, 2022] are not realizable $\\mathcal{H}$ -consistent. They proposed an alternative surrogate loss that is realizable $\\mathcal{H}$ -consistent, but they were unable to prove or disprove whether the proposed surrogate loss is Bayes-consistent. All the surrogate losses mentioned above and their consistency guarantees hold only for cost functions based on classification error. Mao et al. [2024a] generalized the surrogate loss in [Mozannar and Sontag, 2020] to incorporate general cost functions and any multi-class surrogate losses. They provided $\\mathcal{H}$ -consistency bounds for the novel family of surrogate losses, offering a stronger guarantee than Bayes-consistency. ", "page_idx": 1}, {"type": "text", "text": "", "page_idx": 2}, {"type": "text", "text": "Additional studies have focused on post-hoc methods, with Okati et al. [2021] suggesting an alternative optimization technique between the predictor and rejector, and Narasimhan et al. [2022] offering corrections for underfitting surrogate losses [Liu et al., 2024], and Charusaie and Samadi [2024] providing a unifying post-processing framework for multi-objective L2D based on a generalization of the Neyman-Pearson Lemma [Neyman and Pearson, 1933]. The L2D framework or variations thereof have found applications in diverse scenarios, spanning regression, reinforcement learning, and human-in-the-loop systems, among others [De et al., 2020, 2021, Straitouri et al., 2021, Zhao et al., 2021, Joshi et al., 2021, Gao et al., 2021, Mozannar et al., 2022, Hemmer et al., 2023, Chen et al., 2024, Palomba et al., 2024]. More recently, the problem of learning to defer with multiple experts has been analyzed in several publications [Hemmer et al., 2022, Keswani et al., 2021, Kerrigan et al., 2021, Straitouri et al., 2022, Benz and Rodriguez, 2022, Verma et al., 2023, Mao et al., 2023a, 2024a,g, Tailor et al., 2024]. Meanwhile, Mao et al. [2023a] also proposed a two-stage learning to defer framework. They introduced two-stage surrogate losses that are both Bayes-consistent and realizable $\\mathcal{H}$ -consistent with constant costs. However, realizable $\\mathcal{H}$ -consistency does not hold for cost functions based on classification error. As with [Mozannar and Sontag, 2020, Verma and Nalisnick, 2022, Mozannar et al., 2023], our work focuses on the single-stage and single-expert setting, and we plan to explore a similar approach in a multi-expert/two-stage setting in the future. ", "page_idx": 2}, {"type": "text", "text": "3 Preliminaries ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "We start with the definitions and notations used in the learning-to-defer scenario considered in this paper. We will then introduce consistency guarantees, including Bayes consistency, Realizable $\\mathcal{H}$ -consistency, and $\\mathcal{H}$ -consistency bounds. Finally, we will review existing consistent surrogate losses for L2D. ", "page_idx": 2}, {"type": "text", "text": "3.1 Learning to defer: problem setup ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "Let $\\mathcal{X}$ be an input space and $\\mathcal{Y}\\,=\\,\\left[n\\right]\\,:=\\,\\left\\{1,\\ldots,n\\right\\}$ be the label space in the standard multi-class classification setting. We study the learning to defer (L2D) scenario, where a learner can either predict a label from $\\mathcal{Y}$ or defer to an expert. ", "page_idx": 2}, {"type": "text", "text": "To model this, we introduce an augmented label space $\\overline{{y}}\\ =\\ \\{1,\\ldots,n,n+1\\}$ , where the label $n+1$ corresponds to deferral. An expert is a fixed predictor $g\\colon\\mathcal{X}\\times\\mathcal{Y}\\ \\to\\ \\mathbb{R}$ . The goal of L2D is to select a predictor $h$ out of a hypothesis set $\\mathcal{H}$ of functions mapping from $\\mathcal{X}\\times\\overline{{\\mathcal{Y}}}$ to $\\mathbb{R}$ with small expected deferral loss. Let $\\mathsf{h}(x)$ denote the prediction of $h$ on input $x\\,\\in\\,\\mathcal X$ , defined as $\\mathsf{h}(x)=\\mathrm{argmax}_{y\\in\\overline{{y}}}\\,h(x,y)$ , that is the label in the augmented label space $\\overline{{y}}$ with the highest score, with an arbitrary but fixed deterministic strategy for breaking ties. Then, the deferral loss function $\\mathsf{L}_{\\mathrm{def}}$ is defined as follows: ", "page_idx": 2}, {"type": "equation", "text": "$$\n\\forall(x,y)\\in\\mathcal{X}\\times\\mathcal{Y},\\quad\\mathsf{L}_{\\mathrm{def}}(h,x,y)=\\boldsymbol{1}_{\\mathsf{h}(x)\\neq y}\\boldsymbol{1}_{\\mathsf{h}(x)\\in[n]}+c(x,y)\\boldsymbol{1}_{\\mathsf{h}(x)=n+1},\n$$", "text_format": "latex", "page_idx": 2}, {"type": "text", "text": "where $c(x,y)$ is the the cost of deferring on input $x$ with true label $y$ . If the deferral option is selected, that is $\\mathsf{h}(x)=n+1$ , the deferral cost $c(x,y)$ is incurred. Otherwise, the prediction of $h$ is within the standard label space, $\\mathsf{h}(x)\\,\\in\\,[n]$ , and the loss incurred coincides with the standard zero-one classification loss, 1h(x)\u2260y. ", "page_idx": 2}, {"type": "text", "text": "The choice of the cost function $c$ is flexible. For example, the cost can be defined as the expert\u2019s classification error: $c(x,y)=1_{\\mathbf{g}(x)\\neq y}$ , as in previous work [Mozannar and Sontag, 2020, Verma and Nalisnick, 2022, Mozannar et al., 2023]. Here, $\\mathbf{g}(x)=\\operatorname{argmax}_{y\\in[n]}{g(x,y)}$ is the prediction made by the expert $g$ . More generally, it can incorporate the inference cost for the expert [Mao et al., 2024a]: $c(x,y)=\\alpha\\mathbf{1}_{\\mathbf{g}(x)\\neq y}+\\beta$ , with $\\alpha,\\beta>0$ . We assume, without loss of generality, that the cost is bounded by $1\\colon0\\leq c(x,y)\\leq1$ , which can be achieved through normalization in practice. ", "page_idx": 2}, {"type": "text", "text": "", "page_idx": 3}, {"type": "text", "text": "3.2 Consistency guarantees ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "Directly optimizing the deferral loss function, which is the target loss in L2D, is generally computationally intractable for complex hypothesis sets $\\mathcal{H}$ . Therefore, a common approach is to optimize a surrogate loss that facilitates the optimization of the deferral loss function. A natural learning guarantee for such surrogate losses is Bayes-consistency [Zhang, 2004a, Bartlett et al., 2006, Zhang, 2004b, Tewari and Bartlett, 2007, Steinwart, 2007]: ", "page_idx": 3}, {"type": "text", "text": "Definition 3.1 (Bayes-consistency). A surrogate loss L is Bayes-consistent with respect to $\\mathsf{L}_{\\mathrm{def}}$ , if minimizing the surrogate loss over the family of all measurable functions leads to the minimization of the deferral loss: ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\operatorname*{lim}_{n\\to+\\infty}\\mathcal{E}_{\\mathsf{L}}\\big(h_{n}\\big)-\\mathcal{E}_{\\mathsf{L}}^{*}\\big(\\mathcal{H}_{\\mathrm{all}}\\big)=0\\implies\\operatorname*{lim}_{n\\to+\\infty}\\mathcal{E}_{\\mathsf{L}_{\\mathrm{def}}}\\big(h_{n}\\big)-\\mathcal{E}_{\\mathsf{L}_{\\mathrm{def}}}^{*}\\big(\\mathcal{H}_{\\mathrm{all}}\\big)=0.\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "Here, given a distribution $\\mathcal{D}$ over $\\mathcal{X}\\times\\mathcal{Y}$ and a loss function $\\mathsf{L}\\colon\\mathcal{H}\\times\\mathcal{X}\\times\\mathcal{Y}\\rightarrow\\mathbb{R}$ , we denote by $\\mathcal{E}_{\\sf L}(h)$ the generalization error of a hypothesis $h\\in\\mathcal{H}$ , $\\mathcal{E}_{\\mathsf{L}}(h)=\\mathbb{E}_{(x,y)\\sim\\mathcal{D}}[\\mathsf{L}(h,x,y)]$ , and by $\\mathcal{E}_{\\mathsf{L}}^{*}(\\mathcal{H})$ the best-in-class generalization error, $\\mathscr{E}_{\\mathsf{L}}^{*}(\\mathcal{H})\\;=\\;\\operatorname*{inf}_{h\\in\\mathcal{H}}\\mathscr{E}_{\\mathsf{L}}(h)$ . Bayes-consistency assumes that the optimization occurs over the family of all measurable functions, $\\mathcal{H}_{\\mathrm{all}}$ . However, in practice, the hypothesis set of interest is typically a restricted one, such as a family of neural networks. Therefore, a hypothesis-dependent learning guarantee, such as $\\mathcal{H}$ -consistency bounds [Awasthi et al., 2022a,b] (see also [Awasthi et al., 2021a,b, 2023, 2024, Mao et al., 2023b,e,f, Zheng et al., 2023, Mao et al., 2023c,d, 2024h,e,d,f, Cortes et al., 2024]) and realizable $\\mathcal{H}$ -consistency [Long and Servedio, 2013, Zhang and Agarwal, 2020], is more informative and relevant. Realizable $\\mathcal{H}$ -consistency, defined as follows, requires that a minimizer of the surrogate loss over the given hypothesis set $\\mathcal{H}$ also minimizes the target loss, provided that the underlying distribution is realizable. ", "page_idx": 3}, {"type": "text", "text": "Definition 3.2 (Realizable $\\mathcal{H}$ -consistency). A surrogate loss L is realizable $\\mathcal{H}$ -consistent with respect to $\\mathsf{L}_{\\mathrm{def}}$ , if for any distribution over which there exists a predictor $h^{*}\\in\\mathcal{H}$ achieving zero deferral loss, $\\mathcal{E}_{\\mathrm{L}_{\\mathrm{def}}}\\left(h^{*}\\right)=0$ , minimizing the surrogate loss also leads to a zero-error solution: ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\hat{h}\\in\\underset{h\\in\\mathcal{H}}{\\operatorname{argmin}}\\,\\pounds_{\\mathsf{L}}(h)\\implies\\pounds_{\\mathsf{L}_{\\mathrm{def}}}(\\hat{h})=0.\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "Note that realizable $\\mathcal{H}$ -consistency does not imply Bayes-consistency, even if we set $\\mathcal{H}=\\mathcal{H}_{\\mathrm{all}}$ in Definition 3.2, since Bayes-consistency requires that the relationship holds for all distributions, not just realizable ones. $\\mathcal{H}$ -consistency bounds, on the other hand, always imply Bayes-consistency. Given a hypothesis set $\\mathcal{H}$ , a surrogate loss L admits an $\\mathcal{H}$ -consistency bound, if for some nondecreasing concave function $\\Gamma\\!:\\!\\mathbb{R}_{+}\\to\\mathbb{R}_{+}$ with $\\Gamma(0)=0$ , a bound of the following form holds for any hypothesis $h\\in\\mathcal{H}$ and any distribution: ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\mathcal{E}_{\\mathsf{L}_{\\mathrm{def}}}\\left(h\\right)-\\mathcal{E}_{\\mathsf{L}_{\\mathrm{def}}}^{*}\\left(\\mathcal{K}\\right)+\\mathcal{M}_{\\mathsf{L}_{\\mathrm{def}}}\\left(\\mathcal{K}\\right)\\le\\Gamma\\big(\\mathcal{E}_{\\mathsf{L}}\\big(h\\big)-\\mathcal{E}_{\\mathsf{L}}^{*}(\\mathcal{K})+\\mathcal{M}_{\\mathsf{L}}\\big(\\mathcal{K}\\big)\\big),\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "where $\\mathcal{M}_{\\sf L}(\\mathcal{H})$ is the minimizability gap, defined as the difference between the best-in-class generalization error and the expected pointwise infimum loss: $\\begin{array}{r}{\\mathfrak{M}_{\\mathsf{L}}(\\mathcal{H})=\\mathcal{E}_{\\mathsf{L}}^{*}(\\mathcal{H})\\!-\\!\\mathbb{E}_{x}\\!\\left[\\operatorname*{inf}_{h\\in\\mathcal{H}}\\mathbb{E}_{y|x}[\\mathsf{L}(h,x,y)]\\right]}\\end{array}$ The minimizability gap can be upper-bounded by the approximation error and vanishes when $\\mathcal{H}=\\mathcal{H}_{\\mathrm{all}}$ [Awasthi et al., 2022a,b]. Thus, an $\\mathcal{H}$ -consistency bound implies Bayes-consistency. The relationship between the two hypothesis-dependent learning guarantees\u2014realizable $\\mathcal{H}$ -consistency and $\\mathcal{H}$ -consistency bounds\u2014depends on the target loss adopted in the specific learning scenario. In Section 5, we will demonstrate that in the standard multi-class classification setting, an $\\mathcal{H}$ -consistency bound is a stronger notion than realizable $\\mathcal{H}$ -consistency. However, in L2D, these guarantees do not imply one another. ", "page_idx": 3}, {"type": "text", "text": "3.3 Existing surrogate losses ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "Here, we will review several consistent surrogate losses used in L2D. For convenience, we use $\\widetilde c(x,y)=1_{\\mathbf{g}(x)\\neq y}$ to denote the cost when it specifically represents the expert\u2019s classification error, and use $c(x,y)$ when it represents a general cost function. ", "page_idx": 3}, {"type": "text", "text": "Mozannar and Sontag [2020] proposed the first Bayes-consistent surrogate loss by generalizing the cross-entropy loss for L2D, with cost functions based on classification error, which is defined as ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathsf{L}_{\\mathrm{CE}}(h,x,y)=-\\log\\!\\left(\\frac{e^{h(x,y)}}{\\sum_{y^{\\prime}\\in\\overline{{y}}}e^{h(x,y^{\\prime})}}\\right)-\\left(1-\\widetilde{c}(x,y)\\right)\\log\\!\\left(\\frac{e^{h(x,n+1)}}{\\sum_{y^{\\prime}\\in\\overline{{y}}}e^{h(x,y^{\\prime})}}\\right).}\\end{array}\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "Verma and Nalisnick [2022] proposed an alternative one-vs-all surrogates loss with cost functions based on expert\u2019s classification error, that is Bayes-consistent as well: ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\displaystyle\\cdot\\mathrm{ova}\\!\\left(h,x,y\\right)=\\Phi\\!\\left(h(x,y)\\right)\\!+\\!\\sum_{y^{\\prime}\\in\\overline{{y}}\\atop y^{\\prime}\\neq y}\\Phi\\!\\left(-h(x,y^{\\prime})\\right)+(1-\\widetilde{c}(x,y))\\big[\\Phi\\!\\left(h(x,n+1)\\right)\\!-\\!\\Phi\\!\\left(-h(x,n+1)\\right)\\!\\right]\\!,\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "where $\\Phi$ is a strictly proper binary composite loss [Reid and Williamson, 2010], such as the logistic loss $t\\mapsto\\log(1+e^{-\\dot{t}})$ . $\\mathsf{L_{C E}}$ and $\\mathsf{L}_{\\mathrm{OvA}}$ are not realizable $\\mathcal{H}$ -consistent. Instead, Mozannar et al. [2023] proposed the following loss function that is realizable $\\mathcal{H}$ -consistent when $\\mathcal{H}$ is closed under scaling: ", "page_idx": 4}, {"type": "equation", "text": "$$\n{\\mathsf{L}}_{\\mathrm{RS}}\\bigl(h,x,y\\bigr)=-2\\log\\left(\\frac{e^{h(x,y)}+\\bigl(1-\\widetilde{c}(x,y)\\bigr)e^{h(x,n+1)}}{\\sum_{y^{\\prime}\\in\\overline{{\\mathsf{J}}}}e^{h(x,y^{\\prime})}}\\right).\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "However, they were unable to prove or disprove whether the surrogate loss $\\mathsf{L}_{\\mathrm{RS}}$ is Bayes-consistent. ", "page_idx": 4}, {"type": "text", "text": "All the surrogate losses mentioned above and their consistency guarantees hold only for cost functions based on the classification error: c\u0303(x,y) = 1g(x)\u2260y. Mao et al. [2024a] generalized the surrogate loss $\\mathsf{L_{C E}}$ to incorporate general cost functions and any multi-class surrogate losses: ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\mathsf{L}_{\\mathrm{general}}(h,x,y)=\\ell(h,x,y)+(1-c(x,y))\\ell(h,x,n+1).\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "Here, $\\ell$ is a Bayes-consistent surrogate loss for the multi-class zero-one loss over the augmented label set $\\overline{{y}}$ . In particular, $\\ell$ can be chosen as a comp-sum loss [Mao et al., 2023f], for example, the generalized cross entropy loss (see Section 4.1). As shown by Mao et al. [2024a], Lgeneral benefits from $\\mathcal{H}$ -consistency bounds, which implies its Bayes-consistency. ", "page_idx": 4}, {"type": "text", "text": "4 Novel surrogate losses ", "text_level": 1, "page_idx": 4}, {"type": "text", "text": "In this section, we introduce a new family of surrogate losses for L2D that benefit from Bayesconsistency, realizable $\\mathcal{H}$ -consistency and $\\mathcal{H}$ -consistency bounds, starting from first principles. ", "page_idx": 4}, {"type": "text", "text": "4.1 Derivation from first principles ", "text_level": 1, "page_idx": 4}, {"type": "text", "text": "Observe that for any $(x,y)\\in\\mathcal{X}\\times\\mathcal{Y}$ , we have $\\mathtt{l}_{\\mathsf{h}(x)={n+1}}\\,=\\,\\mathtt{l}_{\\mathsf{h}(x)\\neq y}\\mathtt{l}_{\\mathsf{h}(x)={n+1}}$ , since $\\mathsf{h}(x)\\,=\\,n+1$ implies $\\mathsf{h}(x)\\neq y$ . Thus, using additionally $\\mathtt{l}_{\\mathsf{h}(x)\\in[n]}=\\mathtt{l}_{\\mathsf{h}(x)\\neq n+1}$ , the deferral loss can be rewritten as follows for all $(x,y)\\in\\mathcal{X}\\times\\mathcal{Y}$ : ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathsf{L}_{\\mathrm{def}}\\bigl(h,x,y\\bigr)=\\mathsf{1}_{\\mathsf{h}(x)\\neq y}\\mathsf{1}_{\\mathsf{h}(x)\\in[n]}+c\\bigl(x,y\\bigr)\\mathsf{1}_{\\mathsf{h}(x)=n+1}}\\\\ &{\\qquad\\qquad\\qquad=\\mathsf{1}_{\\mathsf{h}(x)\\neq y}\\mathsf{1}_{\\mathsf{h}(x)\\neq n+1}+c\\bigl(x,y\\bigr)\\mathsf{1}_{\\mathsf{h}(x)\\neq y}\\mathsf{1}_{\\mathsf{h}(x)=n+1}}\\\\ &{\\qquad\\qquad=\\mathsf{1}_{\\mathsf{h}(x)\\neq y}\\mathsf{1}_{\\mathsf{h}(x)\\neq n+1}+c\\bigl(x,y\\bigr)\\mathsf{1}_{\\mathsf{h}(x)\\neq y}\\bigl(1-\\mathsf{1}_{\\mathsf{h}(x)\\neq n+1}\\bigr)}\\\\ &{\\qquad\\qquad=c\\bigl(x,y\\bigr)\\mathsf{1}_{\\mathsf{h}(x)\\neq y}+\\bigl(1-c\\bigl(x,y\\bigr)\\bigr)\\mathsf{1}_{\\mathsf{h}(x)\\neq y\\wedge\\mathsf{h}(x)\\neq n+1}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "Next, we will derive the new surrogate losses for L2D by replacing the indicator functions in (2) with smooth loss functions. The first indicator function $1_{\\mathsf{h}(x)\\neq y}$ is just the multi-class zero-one loss. Thus, a natural choice is to replace it with a surrogate loss in standard multi-class classification. We will specifically consider the family of comp-sum losses [Mao et al., 2023f], defined as follows for any $(\\dot{h},x,y)\\in\\dot{\\mathcal{H}}\\times\\mathcal{X}\\times\\mathcal{Y}$ : ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\ell_{\\mathrm{comp}}(h,x,y)=\\Psi\\left(\\frac{e^{h(x,y)}}{\\sum_{y^{\\prime}\\in\\overline{{\\mathbb{J}}}}e^{h(x,y^{\\prime})}}\\right),\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "where $\\Psi\\!\\!:[0,1]\\rightarrow\\mathbb{R}_{+}\\cup\\left\\{+\\infty\\right\\}$ is a non-increasing function. For example, by taking $\\Psi(t)=-\\log(t)$ , ${\\textstyle\\frac{1}{q}}\\!\\left(1-t^{q}\\right)$ with $q\\in(0,1)$ , $1-t$ , we obtain the logistic loss [Verhulst, 1838, 1845, Berkson, 1944, ", "page_idx": 4}, {"type": "table", "img_path": "OcO2XakUUK/tmp/9c05323b3aadee04ef6ffbfb716089ec0b77bdb7f1da1a27c70acafcc5e4102a.jpg", "table_caption": ["Table 1: A new family of surrogate losses LRL2D for L2D. "], "table_footnote": [], "page_idx": 5}, {"type": "text", "text": "1951], the generalized cross entropy loss [Zhang and Sabuncu, 2018], and the mean absolute error loss [Ghosh et al., 2017], respectively: ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathrm{Logistic~loss:}\\qquad\\qquad\\qquad\\ell_{\\mathrm{log}}(h,x,y)=-\\log\\left[\\frac{e^{h(x,y)}}{\\sum_{y^{\\prime}\\in\\overline{{y}}}e^{h(x,y^{\\prime})}}\\right]}\\\\ &{\\mathrm{Generalized~cross~entropy~loss:}\\;\\;\\ell_{\\mathrm{gce}}(h,x,y)=\\frac{1}{q}\\left[1-\\left[\\frac{e^{h(x,y)}}{\\sum_{y^{\\prime}\\in\\overline{{y}}}e^{h(x,y^{\\prime})}}\\right]^{q}\\right]}\\\\ &{\\mathrm{Mean~absolute~error~loss:}\\qquad\\ell_{\\mathrm{mae}}(h,x,y)=1-\\frac{e^{h(x,y)}}{\\sum_{y^{\\prime}\\in\\overline{{y}}}e^{h(x,y^{\\prime})}}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "For any $(h,x,y)\\in\\operatorname{\\mathrm{\\mathcal{H}}}\\times\\operatorname{\\mathrm{\\mathcal{X}}}\\times\\operatorname{\\overline{{y}}}$ , the confidence margin $\\rho_{h}(x,y)$ is defined by $\\rho_{h}(x,y)=h(x,y)\\,-\\,$ $\\operatorname*{max}_{y^{\\prime}\\in\\overline{{y}},y^{\\prime}\\neq y}h(x,y^{\\prime})$ . Thus, the second indicator function $1_{\\mathsf{h}(x)\\neq y\\wedge\\mathsf{h}(x)\\neq n+1}$ can be expressed as follows in terms of the confidence margin: ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\boldsymbol{1}_{\\mathfrak{h}(x)\\ne y\\wedge\\mathfrak{h}(x)\\ne n+1}=\\boldsymbol{1}_{\\left(h(x,y)\\leq\\operatorname*{max}_{y^{\\prime}\\in\\overline{{y}},\\,y^{\\prime}\\neq y}\\,h(x,y^{\\prime})\\right)\\wedge\\left(h(x,n+1)\\leq\\operatorname*{max}_{y^{\\prime}\\in\\overline{{y}},\\,y^{\\prime}\\neq n+1}h(x,y^{\\prime})\\right)}}\\\\ &{\\qquad\\qquad\\qquad\\qquad=\\boldsymbol{1}_{(\\rho_{h}(x,y)\\leq0)\\wedge(\\rho_{h}(x,n+1)\\leq0)}}\\\\ &{\\qquad\\qquad\\qquad=\\boldsymbol{1}_{\\operatorname*{max}\\{\\rho_{h}(x,y),\\rho_{h}(x,n+1)\\}\\leq0}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "Note that the first indicator function can also be written in terms of margin: $\\mathtt{l}_{\\mathsf{h}(x)\\neq y}\\,=\\,1_{\\rho_{h}(x,y)\\leq0}.$ Unlike the first indicator function, which presses $h(x,y)$ to be the largest score among $\\overline{{y}}$ , that is the margin $\\rho_{h}(x,y)$ to be positive, the second indicator function only enforces $h(x,y)$ or $h(x,n+1)$ to be the largest score among $\\overline{{y}}$ , that is the maximum of two margins, $\\operatorname*{max}\\{\\rho_{h}(x,y),\\rho_{h}(x,n+1)\\}$ , to be positive. This condition can be further strengthened by requiring the sum of two margins, $\\rho_{h}(x,y)+\\rho_{h}(x,n+1)$ , to be positive. In view of this observation, we adopt the following modified comp-sum surrogate loss for the second indicator function: ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\widetilde{\\ell}_{\\mathrm{comp}}(h,x,y)=\\Psi\\left(\\frac{e^{h(x,y)}+e^{h(x,n+1)}}{\\sum_{y^{\\prime}\\in\\overline{{\\mathfrak{y}}}}e^{h(x,y^{\\prime})}}\\right),\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "where $\\Psi\\!\\!:[0,1]\\rightarrow\\mathbb{R}_{+}\\cup\\left\\{+\\infty\\right\\}$ is a non-increasing function. In other words, $\\widetilde{\\ell}_{\\mathrm{comp}}$ replaces the term $e^{h(x,y)}$ in the softmax function in $\\ell_{\\mathrm{comp}}$ with the sum $e^{h(x,y)}+e^{h(x,n+1)}$ . The effect is to encourage the sum of the two margins, $\\rho_{h}(x,y)+\\rho_{h}(x,n+1)$ , to be positive, rather than just the single margin $\\rho_{h}(x,y)$ . Following this principle, we derive the following expression for a new family of surrogate losses, LRL2D, dubbed realizable $L2D$ : ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\operatorname{L}_{\\mathrm{RL2D}}(h,x,y)=c(x,y)\\ell_{\\mathrm{comp}}(h,x,y)+(1-c(x,y))\\widetilde{\\ell}_{\\mathrm{comp}}(h,x,y).\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "For the choices of $\\Psi(t)=-\\log(t),\\,\\textstyle{\\frac{1}{q}}\\big(1-t^{q}\\big)$ with $q\\in(0,1)$ and $1-t$ , we obtain the new surrogate losses for L2D in Table 1. In the next sections, we will prove both realizable $\\mathcal{H}$ -consistency guarantees and $\\mathcal{H}$ -consistency bounds for this family of surrogate losses, which imply their excess error bounds and Bayes-consistency as well. ", "page_idx": 5}, {"type": "text", "text": "4.2 Realizable $\\mathcal{H}$ -consistency ", "text_level": 1, "page_idx": 5}, {"type": "text", "text": "Here, we show that LRL2D is realizable $\\mathcal{H}$ -consistent with respect to $\\mathsf{L}_{\\mathrm{def}}$ . We say that a hypothesis set $\\mathcal{H}$ is closed under scaling if, $h\\in\\mathcal{H}\\implies\\alpha h\\in\\mathcal{H}$ for any $\\alpha\\in\\mathbb{R}$ . ", "page_idx": 5}, {"type": "text", "text": "Theorem 4.1. Assume that $\\mathcal{H}$ is closed under scaling. Suppose that $\\Psi$ is non-increasing, $\\Psi\\!\\left({\\frac{2}{3}}\\right)>0$ and $\\textstyle\\operatorname*{lim}_{t\\to1}\\Psi(t)=0$ . Then, the surrogate loss LRL2D is realizable $\\mathcal{H}$ -consistent with respect to $\\mathsf{L}_{\\mathrm{def}}$ . ", "page_idx": 6}, {"type": "text", "text": "The proof, detailed in Appendix A, begins by establishing an upper bound on the deferral loss in terms of the comp-sum loss: $\\begin{array}{r}{\\mathsf{L}_{\\mathrm{def}}\\le\\frac{\\mathsf{L}_{\\mathrm{RL2D}}}{\\Psi\\left(\\frac{2}{3}\\right)}}\\end{array}$ . Letting $\\hat{h}$ be the minimizer of $\\mathsf{L}_{\\mathrm{RL2D}}$ and $\\alpha$ be any real number, we then show that ELdef(\u02c6h) \u2264\u03a8(1 2 )E $\\begin{array}{r}{\\mathcal{E}_{\\mathrm{L}_{\\mathrm{def}}}(\\hat{h})\\leq\\frac{1}{\\Psi\\left(\\frac{2}{3}\\right)}\\mathcal{E}_{\\mathrm{L}_{\\mathrm{RL2D}}}\\left(\\alpha h^{*}\\right)}\\end{array}$ . The generalization error is then split by conditioning on whether $h^{*}(x)$ is the deferral class $(n+1)$ or not. Finally, we demonstrate that each conditional term converges to zero as $\\alpha$ tends to $+\\infty$ , and apply the monotone convergence theorem to complete the proof. ", "page_idx": 6}, {"type": "text", "text": "4.3 $\\mathcal{H}$ -Consistency bounds ", "text_level": 1, "page_idx": 6}, {"type": "text", "text": "Here, we show that LRL2D admits an $\\mathcal{H}$ -consistency bound with respect to $\\mathsf{L}_{\\mathrm{def}}$ , which implies its Bayes-consistency as well. We say that a hypothesis set is symmetric if there exists a family $\\mathcal{F}$ of functions $f$ mapping from $\\mathcal{X}$ to $\\mathbb{R}$ such that $\\{[h(x,1),\\ldots,h(x,n+1)]\\colon h\\in\\mathcal{H}\\}\\ =$ $\\{[f_{1}(x),\\ldots,f_{n+1}(x)];f_{1},\\ldots,\\bar{f}_{n+1}\\in\\mathcal{F}\\}$ , for any $x\\in\\mathcal{X}$ . We say that a hypothesis set $\\mathcal{H}$ is complete if for any $(x,y)\\in\\,\\mathcal{X}\\times\\mathcal{Y}$ , the set of scores generated by it spans across the real numbers: $\\left\\{h(x,y)\\mid h\\in{\\dot{\\mathcal{H}}}\\right\\}={\\dot{\\mathbb{R}}}$ . Common neural network and linear function hypothesis sets are all symmetric and complete. We first consider the case where the cost is expert\u2019s classification error. ", "page_idx": 6}, {"type": "text", "text": "Theorem 4.2. Assume that $\\mathcal{H}$ is symmetric and complete and that $c(x,y)=1_{\\mathbf{g}(x)\\neq y}$ . Then, for all $h\\in\\mathcal{H}$ and any distribution, the following $\\mathcal{H}$ -consistency bound holds: ", "page_idx": 6}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathcal{E}_{\\boldsymbol{\\mathrm{L}}_{\\mathrm{def}}}\\left(h\\right)-\\mathcal{E}_{\\boldsymbol{\\mathrm{L}}_{\\mathrm{def}}}\\left(\\mathcal{K}\\right)+\\mathcal{M}_{\\boldsymbol{\\mathrm{L}}_{\\mathrm{def}}}\\left(\\mathcal{K}\\right)\\leq\\Gamma\\big(\\mathcal{E}_{\\boldsymbol{\\mathrm{L}}_{\\mathrm{RL2D}}}\\left(h\\right)-\\mathcal{E}_{\\boldsymbol{\\mathrm{L}}_{\\mathrm{RL2D}}}\\left(\\mathcal{K}\\right)+\\mathcal{M}_{\\boldsymbol{\\mathrm{L}}_{\\mathrm{RL2D}}}\\left(\\mathcal{K}\\right)\\big),}\\end{array}\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "where $\\Gamma(t)=\\sqrt{2t}$ when $\\Psi(t)=-\\log(t)$ and $\\Gamma(t)=\\sqrt{2(n+1)^{q}t}$ when $\\begin{array}{r}{\\Psi(t)=\\frac{1}{q}(1-t^{q})}\\end{array}$ with $q\\in$ $(0,1)$ . ", "page_idx": 6}, {"type": "text", "text": "The proof, detailed in Appendix B.3 and B.4, establishes strong consistency guarantees for our new surrogate loss LRL2D (Theorem 4.2). We first introduce $y_{\\mathrm{max}}=\\operatorname{argmax}_{y\\in\\bigvee}p(x,y)$ , the label with the highest conditional probability. We then show that for any hypothesis $\\boldsymbol{h}$ and input $x$ , if $y_{\\mathrm{max}}$ is not the predicted label $h_{\\mathrm{max}}$ , the conditional error of $h$ is lower bounded by a modified hypothesis $\\overline{h}$ (obtained by swapping the scores of $y_{\\mathrm{max}}$ and $h_{\\mathrm{max}}$ ). Next, for hypotheses where $y_{\\mathrm{{max}}}=h_{\\mathrm{{max}}}$ , we lower bound their conditional regret in terms of the conditional regret of the deferral loss using a new hypothesis $h_{\\mu}$ . This proof is novel and significantly different from existing approaches for establishing $\\mathcal{H}$ -consistency bounds in either the standard or deferral settings [Mao et al., 2023f, 2024a]. ", "page_idx": 6}, {"type": "text", "text": "The next result further shows that when $\\Psi(t)=1-t$ , our surrogate losses benefti from $\\mathcal{H}$ -consistency bounds for any general cost function. ", "page_idx": 6}, {"type": "text", "text": "Theorem 4.3. Assume that $\\mathcal{H}$ is symmetric and complete. Suppose that $\\Psi(t)=1-t$ . Then, for all $h\\in\\mathcal{H}$ and any distribution, the following $\\mathcal{H}$ -consistency bounds hold: ", "page_idx": 6}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathcal{E}_{\\mathrm{L}_{\\mathrm{def}}}(h)-\\mathcal{E}_{\\mathrm{L}_{\\mathrm{def}}}(\\mathcal{K})+\\mathcal{M}_{\\mathrm{L}_{\\mathrm{def}}}(\\mathcal{K})\\leq(n+1)\\big(\\mathcal{E}_{\\mathrm{L}_{\\mathrm{RL2D}}}(h)-\\mathcal{E}_{\\mathrm{L}_{\\mathrm{RL2D}}}(\\mathcal{K})+\\mathcal{M}_{\\mathrm{L}_{\\mathrm{RL2D}}}(\\mathcal{K})\\big).}\\end{array}\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "The proof is included in Appendix B.2. Theorem 4.2 provides stronger consistency guarantees for our new surrogate loss $\\mathsf{L}_{\\mathrm{RL2D}}$ with $\\Psi(t)=1-t$ since it holds for any general cost function. The proof idea is similar to that of Theorem 4.2, albeit with more cases to analyze due to the general cost function. This occurs when lower bounding the conditional regret of a hypothesis $h$ , which satisfies $y_{\\mathrm{{max}}}=h_{\\mathrm{{max}}}$ , in terms of the conditional regret of the deferral loss by introducing a new hypothesis $h_{\\mu}$ . The additional cases necessitate a more stringent condition for the guarantee, such that the functions $\\Psi(t)=-\\log(t)$ and $\\begin{array}{r}{\\Psi(t)=\\frac{1}{q}\\left(1-t^{q}\\right)}\\end{array}$ do not apply. ", "page_idx": 6}, {"type": "text", "text": "4.4 Excess error bounds and Bayes-consistency ", "text_level": 1, "page_idx": 6}, {"type": "text", "text": "For the family of all measurable functions $\\mathcal{H}=\\mathcal{H}_{\\mathrm{all}}$ , the minimizability gaps vanish. In this case, Theorems 4.2 and 4.3 imply the following excess error bounds and Bayes-consistency guarantees. ", "page_idx": 6}, {"type": "text", "text": "Corollary 4.4. Suppose that $c(x,y)=1_{\\mathbf{g}(x)\\neq y}$ . For all $h\\in\\mathcal{H}_{\\mathrm{all}}$ and any distribution, the following excess error bounds hold: ", "page_idx": 6}, {"type": "equation", "text": "$$\n\\mathcal{E}_{\\sf L_{\\mathrm{def}}}\\left(h\\right)-\\mathcal{E}_{\\sf L_{\\mathrm{def}}}\\left(\\mathcal{H}_{\\mathrm{all}}\\right)\\leq\\Gamma\\big(\\mathcal{E}_{\\sf L_{\\mathrm{RL2D}}}\\left(h\\right)-\\mathcal{E}_{\\sf L_{\\mathrm{RL2D}}}\\left(\\mathcal{H}_{\\mathrm{all}}\\right)\\big),\n$$", "text_format": "latex", "page_idx": 6}, {"type": "table", "img_path": "OcO2XakUUK/tmp/20db91a738ec08a218a3814929d44f5b4aa874e4ca8bf855d872763b4672587b.jpg", "table_caption": ["Table 2: Consistency properties of existing surrogate losses and ours in the case of $c(x,y)=1_{\\mathbf{g}(x)\\neq y}$ "], "table_footnote": ["where $\\Gamma(t)=\\sqrt{2t}$ when $\\Psi(t)=-\\log(t)$ and $\\Gamma(t)=\\sqrt{2(n+1)^{q}t}$ when $\\begin{array}{r}{\\Psi(t)=\\frac{1}{q}(1-t^{q})}\\end{array}$ with $q\\in$ $(0,1)$ . Furthermore, the surrogate loss LRL2D is Bayes-consistent with respect to $\\mathsf{L}_{\\mathrm{def}}$ in these cases. "], "page_idx": 7}, {"type": "text", "text": "Corollary 4.5. Suppose that $\\Psi(t)=1-t$ . For all $h\\in\\mathcal{H}_{\\mathrm{all}}$ and any distribution, the following excess error bounds hold: ", "page_idx": 7}, {"type": "equation", "text": "$$\n\\mathcal{E}_{\\mathrm{L}_{\\mathrm{def}}}\\left(h\\right)-\\mathcal{E}_{\\mathrm{L}_{\\mathrm{def}}}\\left(\\mathcal{K}_{\\mathrm{all}}\\right)\\leq\\left(n+1\\right)\\!\\big(\\mathcal{E}_{\\mathrm{L}_{\\mathrm{RL2D}}}\\big(h\\big)-\\mathcal{E}_{\\mathrm{L}_{\\mathrm{RL2D}}}\\big(\\mathcal{K}_{\\mathrm{all}}\\big)\\big).\n$$", "text_format": "latex", "page_idx": 7}, {"type": "text", "text": "Furthermore, the surrogate loss LRL2D is Bayes-consistent with respect to $\\mathsf{L}_{\\mathrm{def}}$ in this case. ", "page_idx": 7}, {"type": "text", "text": "Therefore, Theorem 4.1 and Corollary 4.4 show that LRL2D is both realizable $\\mathcal{H}$ -consistent and Bayes-consistent with respect to $\\mathsf{L}_{\\mathrm{def}}$ . This solves the open problem raised by Mozannar et al. [2023]. ", "page_idx": 7}, {"type": "text", "text": "In particular, for cost functions based on classification error, $c(x,y)=1_{\\mathbf{g}(x)\\neq y}$ , our surrogate loss LRL2D with $\\Psi(t)=-\\log(t)$ coincides with the surrogate loss ${\\mathsf{L}}_{\\mathrm{RS}}$ in [Mozannar et al., 2023], modulo a constant. This affirmatively answers the question of whether their surrogate loss is Bayes-consistent when $c(x,y)=1_{\\mathbf{g}(x)\\neq y}$ . However, their surrogate loss cannot be shown to be Bayes-consistent for a general cost function. In contrast, our surrogate losses $\\mathsf{L}_{\\mathrm{RL2D}}$ with $\\Psi(t)=1-t$ are adaptable to general cost functions and benefit from both $\\mathcal{H}$ -consistency bounds and realizable $\\mathcal{H}$ -consistency guarantees. We also provide a more general family of comp-sum loss functions with $\\begin{array}{r}{\\Psi(t)=\\frac{1}{q}\\left(1-t^{q}\\right)}\\end{array}$ that benefit from both $\\mathcal{H}$ -consistency bounds and realizable $\\mathcal{H}$ -consistency when $c(x,y)=1_{\\mathbf{g}(x)\\neq y}$ . ", "page_idx": 7}, {"type": "text", "text": "4.5 Summary ", "text_level": 1, "page_idx": 7}, {"type": "text", "text": "Here, we summarize the consistency properties of existing surrogate losses and ours. As mentioned earlier, most surrogate losses proposed in previous work, except for $\\mathsf{L}_{\\mathrm{general}}$ , are analyzed under the condition $c(x,y)=1_{\\mathbf{g}(x)\\neq y}$ . This naturally leads to a summary of these surrogate losses in this context, as presented in Table 1. Additionally, we provide analyses and the consistency properties of our surrogate loss, LRL2D, with general cost functions. ", "page_idx": 7}, {"type": "text", "text": "More specifically, our surrogate losses LRL2D satisfying Theorem 4.1 perform better in realizable scenarios than the surrogate losses $\\mathsf{L_{C E}}$ , LOVA, and $\\mathsf{L}_{\\mathrm{general}}$ from prior work, as ours are realizable $\\mathcal{H}$ - consistent while theirs are not. This will be illustrated by our experiment results in the realizable case (Figure 1a). Our surrogate losses LRL2D satisfying Theorem 4.2 and Corollary 4.4 are comparable to the surrogate losses in prior work in non-realizable scenarios when the cost is the expert\u2019s classification error, as all of them are Bayes-consistent and supported by $\\mathrm{H}\\cdot$ -consistency bounds. This is demonstrated by our experiment in the non-realizable case with the cost function being the expert\u2019s classification error (Table 3). Our surrogate losses LRL2D satisfying Theorem 4.3 and Corollary 4.5 are superior to the surrogate loss ${\\mathsf{L}}_{\\mathrm{RS}}$ in non-realizable scenarios with general cost functions, as ours are supported by $\\mathrm{H}$ -consistency bounds and Bayes-consistency while theirs are not. This is evidenced by our experiment in the non-realizable case with general cost functions (Figure 1b). ", "page_idx": 7}, {"type": "text", "text": "5 Relationship between $\\mathcal{H}$ -consistency bounds and realizable $\\mathcal{H}$ -consistency ", "text_level": 1, "page_idx": 7}, {"type": "text", "text": "Here, we discuss the relationship between $\\mathcal{H}$ -consistency bounds and realizable $\\mathcal{H}$ -consistency. First, realizable $\\mathcal{H}$ -consistency does not imply $\\mathcal{H}$ -consistency bounds, since $\\mathcal{H}$ -consistency bounds require that the relationship holds for all distributions, not just realizable ones. Moreover, $\\mathcal{H}$ -consistency bounds provide non-asymptotic guarantees, while realizable $\\mathcal{H}$ -consistency provides only asymptotic guarantees. Second, $\\mathcal{H}$ -consistency bounds imply realizable $\\mathcal{H}$ -consistency in the standard multi-class classification setting. This is because minimizability gaps vanish under the realizable assumption in standard case. In particular, for comp-sum losses, the following holds (see Appendix C for proof). ", "page_idx": 7}, {"type": "table", "img_path": "OcO2XakUUK/tmp/0a8ddbe6bcee187714f97714716ea7be492dd36f847c685b8f142b453d238f1b.jpg", "table_caption": ["Table 3: Comparison of system accuracy, accepted accuracy and coverage; mean $\\pm$ standard deviation over three runs. Realizable L2D outperforms or is comparable to baselines in all the settings. "], "table_footnote": ["Theorem 5.1. Assume that there exists a zero error solution $h^{*}\\in\\mathcal{H}$ with $\\mathcal{E}_{\\ell_{0-1}}(h^{*})=0$ and $\\mathcal{H}$ is closed under scaling. Assume that $\\textstyle\\operatorname*{lim}_{t\\to1}\\Psi(t)=0$ . Then, the minimizability gap of comp-sum loss $\\ell_{\\mathrm{comp}}$ vanishes: $\\mathcal{M}_{\\ell_{\\mathrm{comp}}}(\\mathcal{H})=0$ . "], "page_idx": 8}, {"type": "text", "text": "However, in the deferral setting, this relationship no longer holds: $\\mathcal{H}$ -consistency bounds cannot imply realizable $\\mathcal{H}$ -consistency. In particular, Mao et al. [2023f] showed that $\\mathsf{L_{C E}}$ benefits from $\\mathcal{H}$ - consistency bounds, while Mozannar et al. [2023] showed that it is not realizable $\\mathcal{H}$ -consistent. The loss function in [Madras et al., 2018] is not Bayes-consistent, and thus does not have $\\mathcal{H}$ -consistency bound guarantees, but is actually realizable $\\mathcal{H}$ -consistent [Mozannar et al., 2023]. ", "page_idx": 8}, {"type": "text", "text": "6 Experiments ", "text_level": 1, "page_idx": 8}, {"type": "text", "text": "In this section, we empirically evaluate our proposed surrogate losses and compare them with existing baselines. ", "page_idx": 8}, {"type": "text", "text": "Experimental settings. We follow the setting of Mozannar et al. [2023] and conduct experiments on a synthetic dataset: Mixture-of-Gaussians [Mozannar et al., 2023], and three real-world datasets: CIFAR-10H [Battleday et al., 2020], HateSpeech [Davidson et al., 2017], and COMPASS [Dressel and Farid, 2018]. For these three datasets, we adopt the same model class as that in [Mozannar et al., 2023, Table 1]. Each dataset is randomly split into $70\\%$ , $10\\%$ , and $20\\%$ for training, validation, and testing, respectively. For the Mixture-of-Gaussians, we adopt the exact realizable setting from [Mozannar et al., 2023, Section 7.2], which is realizable by linear functions: there exists a linear hypothesis $h^{*}\\in\\mathcal{H}$ achieving zero deferral loss, $\\mathcal{E}_{\\mathrm{L}_{\\mathrm{def}}}(h^{*})=\\dot{0}$ . ", "page_idx": 8}, {"type": "text", "text": "As with [Mozannar et al., 2023], we choose the cost function to be the expert\u2019s classification error: $c(x,y)\\;=\\;1_{\\mathbf{g}(x)\\neq y}$ . We compare our surrogate to four baselines as described in Section 3.3: the cross-entropy surrogate $\\mathsf{L_{C E}}$ from [Mozannar and Sontag, 2020], the one-vs-all surrogate ${\\mathsf{L}}_{\\mathrm{OvA}}$ from [Mozannar and Sontag, 2020], the realizable surrogate ${\\mathsf{L}}_{\\mathrm{RS}}$ from [Mozannar et al., 2023], and the general surrogate $\\mathsf{L}_{\\mathrm{general}}$ from [Mao et al., 2024a]. For ${\\mathsf{L}}_{\\mathrm{OvA}}$ , we choose $\\Phi$ as the logistic loss, following [Verma and Nalisnick, 2022]. For $\\mathsf{L}_{\\mathrm{general}}$ , we choose $\\ell$ as the generalized cross entropy loss with $q\\,=\\,0.7$ , following [Mao et al., 2024a]. For our Realizable L2D surrogate LRL2D, we consider two choices: $\\ell$ as the generalized cross entropy loss with $q=0.7$ , following [Zhang and Sabuncu, 2018, Mao et al., 2024a], and $\\ell$ as the mean absolute error loss $\\mathit{\\Pi}_{q}=1\\;\\;\\;$ ). Among these, $\\mathsf{L_{C E}}$ , ${\\mathsf{L}}_{\\mathrm{OvA}}$ and $\\mathsf{L}_{\\mathrm{general}}$ are Bayes-consistent but not realizable $\\mathcal{H}$ -consistent; $\\mathsf{L}_{\\mathrm{RS}}$ , LRL2D with $q=0.7$ and LRL2D with $q=1$ are both Bayes-consistent and realizable $\\mathcal{H}$ -consistent, as shown in Sections 4.2 and 4.4. Note that in this case, ${\\mathsf{L}}_{\\mathrm{RS}}$ is a special case of $\\mathsf{L}_{\\mathrm{RL2D}}$ when $\\Psi$ is chosen as $t\\mapsto-\\log(t)$ . We use the same optimizer, learning rate, and number of epochs as chosen in [Mozannar et al., 2023], and we select the model that achieves the highest system accuracy, that is average $\\left[1-\\mathsf{L}_{\\mathrm{def}}(h,x,y)\\right]$ , on a validation set. ", "page_idx": 8}, {"type": "image", "img_path": "OcO2XakUUK/tmp/b3d3bfe557f815132c6b221fd79e99a8d4c316a4a9acc0a80916c99397efe0bc.jpg", "img_caption": ["(a) Comparison of system accuracy versus training sam-(b) Comparison of system accuracy versus coverage on ple size on a realizable synthetic dataset. the HateSpeech dataset with general cost functions. "], "img_footnote": [], "page_idx": 9}, {"type": "text", "text": "Figure 1: Results for the realizable case and the non-realizable case with general cost functions. ", "page_idx": 9}, {"type": "text", "text": "Evaluation. For the three real-world datasets, we report the system accuracy, that is average value of $\\left[1-\\mathsf{L}_{\\mathrm{def}}(h,x,y)\\right]$ on the test data. For completeness, we also include the accepted accuracy, that is the average value of $\\left[1_{\\mathsf{h}(x)\\neq y}1_{\\mathsf{h}(x)\\in[n]}\\right]$ . This metric considers only incorrect predictions $(\\mathsf{h}(x)\\neq y)$ and measures the fraction of those where the system\u2019s output $(\\mathsf{h}(x))$ falls within the valid range of possible outputs $([n])$ . We also report the coverage, that is the average value of ${\\bigl[}1_{\\mathsf{h}(x)\\in[n]}{\\bigr]}$ on the test set, or the fraction of test instances where the system\u2019s prediction falls within the valid range $([n])$ . For each metric, we average results over three runs and report the mean accuracy along with the standard deviation for both our proposed methods and the baseline approaches. For the realizable Mixture-of-Gaussians, we plot the system accuracy of various methods on a held-out test dataset consisting of 5,000 points as we increase the size of the training data. ", "page_idx": 9}, {"type": "text", "text": "Results. Table 3 shows that for the real-world datasets, LRL2D with $q=0.7$ , and LRL2D with $q=1$ either outperform or are comparable to the best baseline in terms of system accuracy on each dataset. This performance is supported by our $\\mathcal{H}$ -consistency bounds and Bayes-consistency results for our Realizable L2D surrogate with respect to the deferral loss $\\mathsf{L}_{\\mathrm{def}}$ , as shown in Sections 4.3 and 4.4. Table 3 also shows that LRL2D achieves reasonable coverage and acceptable accuracy. The system accuracy, coverage, and standard deviations of the baselines match those in [Mozannar et al., 2023]. Moreover, LRS, LRL2D with $q=0.7$ , and $\\mathsf{L}_{\\mathrm{RL2D}}$ with $q=1$ perform differently across various datasets: LRL2D with $q=0.7$ outperforms the others on HateSpeech and CIFAR-10H, while LRL2D with $q=1$ outperforms the others on COMPASS. Note that in this case, $\\mathsf{L}_{\\mathrm{RS}}$ is a special case of LRL2D when $\\Psi$ is chosen as $t\\mapsto-\\log(t)$ . These results show that Realizable L2D can benefti from the flexibility in the choice of $\\Psi$ . ", "page_idx": 9}, {"type": "text", "text": "Figure 1a shows system accuracy versus training samples on the realizable Mixture-of-Gaussians distribution. Our surrogate loss LRL2D with $q=0.7$ and $q=1$ are realizable $\\mathcal{H}$ -consistent, while $\\mathsf{L_{C E}}$ , LOVA and $\\mathsf{L}_{\\mathrm{general}}$ are not. This verifies our theory. ", "page_idx": 9}, {"type": "text", "text": "Figure 1b shows system accuracy versus coverage on the HateSpeech dataset by varying $\\beta$ in the general cost functions $c(x,y)=\\mathbf{1}_{\\mathbf{g}(x)\\neq y}+\\beta$ . As $\\beta$ increases, deferral algorithms yield solutions with higher coverage and decreased system accuracy. This is because $\\beta$ controls the trade-off between expert\u2019s inference cost and accuracy. LRL2D with $q=1$ performs comparably to the surrogate loss Lgeneral, as both are supported by $\\mathcal{H}$ -consistency bounds and Bayes-consistency with general cost functions. Our surrogate loss LRL2D with $q=1$ outperforms $\\mathsf{L}_{\\mathrm{RS}}$ because the latter does not benefit from Bayes-consistency with general cost functions. ", "page_idx": 9}, {"type": "text", "text": "7 Conclusion ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "We introduced a broad family of surrogate losses and algorithms for learning to defer, parameterized by a non-increasing function. We established their realizable $\\mathcal{H}$ -consistency properties under mild conditions and proved that several of these surrogate losses benefit from $\\mathcal{H}$ -consistency bounds for cost functions based on classification error and general cost functions, which also imply their Bayes-consistency. This research not only resolves an open question posed in previous work but also lays the groundwork for comparing various consistency notions in learning to defer and standard classification. Looking forward, our approach offers a promising avenue for analyzing multi-expert and two-stage settings. ", "page_idx": 9}, {"type": "text", "text": "References ", "text_level": 1, "page_idx": 10}, {"type": "text", "text": "D. A. E. Acar, A. Gangrade, and V. Saligrama. Budget learning via bracketing. In International Conference on Artificial Intelligence and Statistics, pages 4109\u20134119, 2020.   \nP. Awasthi, N. Frank, A. Mao, M. Mohri, and Y. Zhong. Calibration and consistency of adversarial surrogate losses. Advances in Neural Information Processing Systems, pages 9804\u20139815, 2021a.   \nP. Awasthi, A. Mao, M. Mohri, and Y. Zhong. A finer calibration analysis for adversarial robustness. arXiv preprint arXiv:2105.01550, 2021b.   \nP. Awasthi, A. Mao, M. Mohri, and Y. Zhong. $\\mathcal{H}$ -consistency bounds for surrogate loss minimizers. In International Conference on Machine Learning, 2022a.   \nP. Awasthi, A. Mao, M. Mohri, and Y. Zhong. Multi-class $\\mathcal{H}$ -consistency bounds. In Advances in neural information processing systems, 2022b.   \nP. Awasthi, A. Mao, M. Mohri, and Y. Zhong. Theoretically grounded loss functions and algorithms for adversarial robustness. In International Conference on Artificial Intelligence and Statistics, pages 10077\u201310094, 2023.   \nP. Awasthi, A. Mao, M. Mohri, and Y. Zhong. DC-programming for neural network optimizations. Journal of Global Optimization, 2024.   \nP. L. Bartlett and M. H. Wegkamp. Classification with a reject option using a hinge loss. Journal of Machine Learning Research, 9(8), 2008.   \nP. L. Bartlett, M. I. Jordan, and J. D. McAuliffe. Convexity, classification, and risk bounds. Journal of the American Statistical Association, 101(473):138\u2013156, 2006.   \nR. M. Battleday, J. C. Peterson, and T. L. Grifftihs. Capturing human categorization of natural images by combining deep networks and cognitive models. Nature communications, 11(1):5418, 2020.   \nN. L. C. Benz and M. G. Rodriguez. Counterfactual inference of second opinions. In Uncertainty in Artificial Intelligence, pages 453\u2013463, 2022.   \nJ. Berkson. Application of the logistic function to bio-assay. Journal of the American Statistical Association, 39:357\u2014-365, 1944.   \nJ. Berkson. Why I prefer logits to probits. Biometrics, 7(4):327\u2014-339, 1951.   \nS. Bubeck, V. Chandrasekaran, R. Eldan, J. Gehrke, E. Horvitz, E. Kamar, P. Lee, Y. T. Lee, Y. Li, S. Lundberg, et al. Sparks of artificial general intelligence: Early experiments with gpt-4. arXiv preprint arXiv:2303.12712, 2023.   \nY. Cao, T. Cai, L. Feng, L. Gu, J. Gu, B. An, G. Niu, and M. Sugiyama. Generalizing consistent multi-class classification with rejection to be compatible with arbitrary losses. In Advances in neural information processing systems, 2022.   \nY. Cao, H. Mozannar, L. Feng, H. Wei, and B. An. In defense of softmax parametrization for calibrated and consistent learning to defer. In Advances in Neural Information Processing Systems, 2023.   \nN. Charoenphakdee, Z. Cui, Y. Zhang, and M. Sugiyama. Classification with rejection based on cost-sensitive classification. In International Conference on Machine Learning, pages 1507\u20131517, 2021.   \nM.-A. Charusaie and S. Samadi. A unifying post-processing framework for multi-objective learn-todefer problems. arXiv preprint arXiv:2407.12710, 2024.   \nM.-A. Charusaie, H. Mozannar, D. Sontag, and S. Samadi. Sample efficient learning of predictors that complement humans. In International Conference on Machine Learning, pages 2972\u20133005, 2022.   \nG. Chen, X. Li, C. Sun, and H. Wang. Learning to make adherence-aware advice. In International Conference on Learning Representations, 2024.   \nX. Cheng, Y. Cao, H. Wang, H. Wei, B. An, and L. Feng. Regression with cost-based rejection. In Advances in Neural Information Processing Systems, 2023.   \nC. Chow. An optimum character recognition system using decision function. IEEE T. C., 1957.   \nC. Chow. On optimum recognition error and reject tradeoff. IEEE Transactions on information theory, 16(1):41\u201346, 1970.   \nC. Cortes, G. DeSalvo, and M. Mohri. Learning with rejection. In International Conference on Algorithmic Learning Theory, pages 67\u201382, 2016a.   \nC. Cortes, G. DeSalvo, and M. Mohri. Boosting with abstention. In Advances in Neural Information Processing Systems, pages 1660\u20131668, 2016b.   \nC. Cortes, G. DeSalvo, and M. Mohri. Theory and algorithms for learning with rejection in binary classification. Annals of Mathematics and Artificial Intelligence, pages 1\u201339, 2023.   \nC. Cortes, A. Mao, C. Mohri, M. Mohri, and Y. Zhong. Cardinality-aware set prediction and top- $k$ classification. In Advances in neural information processing systems, 2024.   \nT. Davidson, D. Warmsley, M. Macy, and I. Weber. Automated hate speech detection and the problem of offensive language. In Proceedings of the international AAAI conference on web and social media, volume 11, pages 512\u2013515, 2017.   \nA. De, P. Koley, N. Ganguly, and M. Gomez-Rodriguez. Regression under human assistance. In Proceedings of the AAAI Conference on Artificial Intelligence, pages 2611\u20132620, 2020.   \nA. De, N. Okati, A. Zarezade, and M. G. Rodriguez. Classification under human assistance. In Proceedings of the AAAI Conference on Artificial Intelligence, pages 5905\u20135913, 2021.   \nJ. Dressel and H. Farid. The accuracy, fairness, and limits of predicting recidivism. Science advances, 4(1):eaao5580, 2018.   \nR. El-Yaniv and Y. Wiener. Active learning via perfect selective classification. Journal of Machine Learning Research, 13(2), 2012.   \nR. El-Yaniv et al. On the foundations of noise-free selective classification. Journal of Machine Learning Research, 11(5), 2010.   \nA. Gangrade, A. Kag, and V. Saligrama. Selective classification via one-sided prediction. In International Conference on Artificial Intelligence and Statistics, pages 2179\u20132187, 2021.   \nR. Gao, M. Saar-Tsechansky, M. De-Arteaga, L. Han, M. K. Lee, and M. Lease. Human-ai collaboration with bandit feedback. arXiv preprint arXiv:2105.10614, 2021.   \nY. Geifman and R. El-Yaniv. Selective classification for deep neural networks. In Advances in neural information processing systems, 2017.   \nY. Geifman and R. El-Yaniv. Selectivenet: A deep neural network with an integrated reject option. In International conference on machine learning, pages 2151\u20132159, 2019.   \nA. Ghosh, H. Kumar, and P. S. Sastry. Robust loss functions under label noise for deep neural networks. In Proceedings of the AAAI conference on artificial intelligence, 2017.   \nP. Hemmer, S. Schellhammer, M. V\u00f6ssing, J. Jakubik, and G. Satzger. Forming effective human-ai teams: Building machine learning models that complement the capabilities of multiple experts. arXiv preprint arXiv:2206.07948, 2022.   \nP. Hemmer, L. Thede, M. V\u00f6ssing, J. Jakubik, and N. K\u00fchl. Learning to defer with limited expert predictions. arXiv preprint arXiv:2304.07306, 2023.   \nW. Jiang, Y. Zhao, and Z. Wang. Risk-controlled selective prediction for regression deep neural network models. In 2020 International Joint Conference on Neural Networks (IJCNN), pages 1\u20138, 2020.   \nW. Jitkrittum, N. Gupta, A. K. Menon, H. Narasimhan, A. Rawat, and S. Kumar. When does confidence-based cascade deferral suffice? In Advances in Neural Information Processing Systems, 2023.   \nS. Joshi, S. Parbhoo, and F. Doshi-Velez. Pre-emptive learning-to-defer for sequential medical decision-making under uncertainty. arXiv preprint arXiv:2109.06312, 2021.   \nG. Kerrigan, P. Smyth, and M. Steyvers. Combining human predictions with model probabilities via confusion matrices and calibration. Advances in Neural Information Processing Systems, 34: 4421\u20134434, 2021.   \nV. Keswani, M. Lease, and K. Kenthapadi. Towards unbiased and accurate deferral to multiple experts. In Proceedings of the 2021 AAAI/ACM Conference on AI, Ethics, and Society, pages 154\u2013165, 2021.   \nX. Li, S. Liu, C. Sun, and H. Wang. When no-rejection learning is optimal for regression with rejection. arXiv preprint arXiv:2307.02932, 2023.   \nJ. Liu, B. Gallego, and S. Barbieri. Incorporating uncertainty in learning to defer algorithms for safe computer-aided diagnosis. Scientific reports, 12(1):1762, 2022.   \nS. Liu, Y. Cao, Q. Zhang, L. Feng, and B. An. Mitigating underfitting in learning to defer with consistent losses. In International Conference on Artificial Intelligence and Statistics, pages 4816\u20134824, 2024.   \nP. Long and R. Servedio. Consistency versus realizable H-consistency for multiclass classification. In International Conference on Machine Learning, pages 801\u2013809, 2013.   \nD. Madras, E. Creager, T. Pitassi, and R. Zemel. Learning adversarially fair and transferable representations. arXiv preprint arXiv:1802.06309, 2018.   \nA. Mao, C. Mohri, M. Mohri, and Y. Zhong. Two-stage learning to defer with multiple experts. In Advances in neural information processing systems, 2023a.   \nA. Mao, M. Mohri, and Y. Zhong. H-consistency bounds: Characterization and extensions. In Advances in Neural Information Processing Systems, 2023b.   \nA. Mao, M. Mohri, and Y. Zhong. H-consistency bounds for pairwise misranking loss surrogates. In International conference on Machine learning, 2023c.   \nA. Mao, M. Mohri, and Y. Zhong. Ranking with abstention. In ICML 2023 Workshop The Many Facets of Preference-Based Learning, 2023d.   \nA. Mao, M. Mohri, and Y. Zhong. Structured prediction with stronger consistency guarantees. In Advances in Neural Information Processing Systems, 2023e.   \nA. Mao, M. Mohri, and Y. Zhong. Cross-entropy loss functions: Theoretical analysis and applications. In International Conference on Machine Learning, 2023f.   \nA. Mao, M. Mohri, and Y. Zhong. Principled approaches for learning to defer with multiple experts. In International Symposium on Artificial Intelligence and Mathematics, 2024a.   \nA. Mao, M. Mohri, and Y. Zhong. Predictor-rejector multi-class abstention: Theoretical analysis and algorithms. In International Conference on Algorithmic Learning Theory, pages 822\u2013867, 2024b.   \nA. Mao, M. Mohri, and Y. Zhong. Theoretically grounded loss functions and algorithms for scorebased multi-class abstention. In International Conference on Artificial Intelligence and Statistics, pages 4753\u20134761, 2024c.   \nA. Mao, M. Mohri, and Y. Zhong. Enhanced $H$ -consistency bounds. arXiv preprint arXiv:2407.13722, 2024d.   \nA. Mao, M. Mohri, and Y. Zhong. $H$ -consistency guarantees for regression. In International Conference on Machine Learning, pages 34712\u201334737, 2024e.   \nA. Mao, M. Mohri, and Y. Zhong. Multi-label learning with stronger consistency guarantees. In Advances in neural information processing systems, 2024f.   \nA. Mao, M. Mohri, and Y. Zhong. Regression with multi-expert deferral. In International Conference on Machine Learning, pages 34738\u201334759, 2024g.   \nA. Mao, M. Mohri, and Y. Zhong. A universal growth rate for learning with smooth surrogate losses. In Advances in neural information processing systems, 2024h.   \nC. Mohri, D. Andor, E. Choi, M. Collins, A. Mao, and Y. Zhong. Learning to reject with a fixed predictor: Application to decontextualization. In International Conference on Learning Representations, 2024.   \nM. Mohri, A. Rostamizadeh, and A. Talwalkar. Foundations of Machine Learning. MIT Press, second edition, 2018.   \nH. Mozannar and D. Sontag. Consistent estimators for learning to defer to an expert. In International Conference on Machine Learning, pages 7076\u20137087, 2020.   \nH. Mozannar, A. Satyanarayan, and D. Sontag. Teaching humans when to defer to a classifier via exemplars. In Proceedings of the AAAI Conference on Artificial Intelligence, pages 5323\u20135331, 2022.   \nH. Mozannar, H. Lang, D. Wei, P. Sattigeri, S. Das, and D. Sontag. Who should predict? exact algorithms for learning to defer to humans. In International Conference on Artificial Intelligence and Statistics, pages 10520\u201310545, 2023.   \nH. Narasimhan, W. Jitkrittum, A. K. Menon, A. S. Rawat, and S. Kumar. Post-hoc estimators for learning to defer to an expert. In Advances in Neural Information Processing Systems, pages 29292\u201329304, 2022.   \nJ. Neyman and E. S. Pearson. Ix. on the problem of the most efficient tests of statistical hypotheses. Philosophical Transactions of the Royal Society of London. Series A, Containing Papers of a Mathematical or Physical Character, 231(694-706):289\u2013337, 1933.   \nC. Ni, N. Charoenphakdee, J. Honda, and M. Sugiyama. On the calibration of multiclass classification with rejection. In Advances in Neural Information Processing Systems, pages 2582\u20132592, 2019.   \nN. Okati, A. De, and M. Rodriguez. Differentiable learning under triage. Advances in Neural Information Processing Systems, 34:9140\u20139151, 2021.   \nF. Palomba, A. Pugnana, J. M. Alvarez, and S. Ruggieri. A causal framework for evaluating deferring systems. arXiv preprint arXiv:2405.18902, 2024.   \nM. F. Pradier, J. Zazo, S. Parbhoo, R. H. Perlis, M. Zazzi, and F. Doshi-Velez. Preferential mixtureof-experts: Interpretable models that rely on human expertise as much as possible. AMIA Summits on Translational Science Proceedings, 2021:525, 2021.   \nM. Raghu, K. Blumer, G. Corrado, J. Kleinberg, Z. Obermeyer, and S. Mullainathan. The algorithmic automation problem: Prediction, triage, and human effort. arXiv preprint arXiv:1903.12220, 2019.   \nN. Raman and M. Yee. Improving learning-to-defer algorithms through fine-tuning. arXiv preprint arXiv:2112.10768, 2021.   \nH. G. Ramaswamy, A. Tewari, and S. Agarwal. Consistent algorithms for multiclass classification with an abstain option. Electronic Journal of Statistics, 12(1):530\u2013554, 2018.   \nM. D. Reid and R. C. Williamson. Composite binary losses. The Journal of Machine Learning Research, 11:2387\u20132422, 2010.   \nA. Shah, Y. Bu, J. K. Lee, S. Das, R. Panda, P. Sattigeri, and G. W. Wornell. Selective regression under fairness criteria. In International Conference on Machine Learning, pages 19598\u201319615, 2022.   \nI. Steinwart. How to compare different loss functions and their risks. Constructive Approximation, 26(2):225\u2013287, 2007.   \nE. Straitouri, A. Singla, V. B. Meresht, and M. Gomez-Rodriguez. Reinforcement learning under algorithmic triage. arXiv preprint arXiv:2109.11328, 2021.   \nE. Straitouri, L. Wang, N. Okati, and M. G. Rodriguez. Provably improving expert predictions with conformal prediction. arXiv preprint arXiv:2201.12006, 2022.   \nD. Tailor, A. Patra, R. Verma, P. Manggala, and E. Nalisnick. Learning to defer to a population: A meta-learning approach. In International Conference on Artificial Intelligence and Statistics, pages 3475\u20133483, 2024.   \nA. Tewari and P. L. Bartlett. On the consistency of multiclass classification methods. Journal of Machine Learning Research, 8(36):1007\u20131025, 2007.   \nP. F. Verhulst. Notice sur la loi que la population suit dans son accroissement. Correspondance math\u00e9matique et physique, 10:113\u2014-121, 1838.   \nP. F. Verhulst. Recherches math\u00e9matiques sur la loi d\u2019accroissement de la population. Nouveaux M\u00e9moires de l\u2019Acad\u00e9mie Royale des Sciences et Belles-Lettres de Bruxelles, 18:1\u2014-42, 1845.   \nR. Verma and E. Nalisnick. Calibrated learning to defer with one-vs-all classifiers. In International Conference on Machine Learning, pages 22184\u201322202, 2022.   \nR. Verma, D. Barrej\u00f3n, and E. Nalisnick. Learning to defer to multiple experts: Consistent surrogate losses, confidence calibration, and conformal ensembles. In International Conference on Artificial Intelligence and Statistics, pages 11415\u201311434, 2023.   \nJ. Wei, Y. Tay, R. Bommasani, C. Raffel, B. Zoph, S. Borgeaud, D. Yogatama, M. Bosma, D. Zhou, D. Metzler, E. H. Chi, T. Hashimoto, O. Vinyals, P. Liang, J. Dean, and W. Fedus. Emergent abilities of large language models. CoRR, abs/2206.07682, 2022.   \nY. Wiener and R. El-Yaniv. Agnostic selective classification. In Advances in neural information processing systems, 2011.   \nY. Wiener and R. El-Yaniv. Pointwise tracking the optimal regression function. Advances in Neural Information Processing Systems, 25, 2012.   \nY. Wiener and R. El-Yaniv. Agnostic pointwise-competitive selective classification. Journal of Artificial Intelligence Research, 52:171\u2013201, 2015.   \nB. Wilder, E. Horvitz, and E. Kamar. Learning to complement humans. In International Joint Conferences on Artificial Intelligence, pages 1526\u20131533, 2021.   \nM. Yuan and M. Wegkamp. Classification methods with reject option based on convex risk minimization. Journal of Machine Learning Research, 11(1), 2010.   \nM. Yuan and M. Wegkamp. SVMs with a reject option. In Bernoulli, 2011.   \nA. Zaoui, C. Denis, and M. Hebiri. Regression with reject option and application to knn. In Advances in Neural Information Processing Systems, pages 20073\u201320082, 2020.   \nM. Zhang and S. Agarwal. Bayes consistency vs. H-consistency: The interplay between surrogate loss functions and the scoring function class. In Advances in Neural Information Processing Systems, 2020.   \nT. Zhang. Statistical behavior and consistency of classification methods based on convex risk minimization. The Annals of Statistics, 32(1):56\u201385, 2004a.   \nT. Zhang. Statistical analysis of some multi-category large margin classification methods. Journal of Machine Learning Research, 5(Oct):1225\u20131251, 2004b.   \nZ. Zhang and M. Sabuncu. Generalized cross entropy loss for training deep neural networks with noisy labels. In Advances in neural information processing systems, 2018. ", "page_idx": 10}, {"type": "text", "text": "", "page_idx": 11}, {"type": "text", "text": "", "page_idx": 12}, {"type": "text", "text": "", "page_idx": 13}, {"type": "text", "text": "", "page_idx": 14}, {"type": "text", "text": "J. Zhao, M. Agrawal, P. Razavi, and D. Sontag. Directing human attention in event localization for clinical timeline creation. In Machine Learning for Healthcare Conference, pages 80\u2013102, 2021. C. Zheng, G. Wu, F. Bao, Y. Cao, C. Li, and J. Zhu. Revisiting discriminative vs. generative classifiers: Theory and implications. In International Conference on Machine Learning, pages 42420\u201342477, 2023. ", "page_idx": 15}, {"type": "text", "text": "Contents of Appendix ", "text_level": 1, "page_idx": 16}, {"type": "text", "text": "A Proof of realizable $\\mathcal{H}$ -consistency 18 ", "page_idx": 16}, {"type": "text", "text": "B Proof of $\\mathcal{H}$ -consistency bounds 19 ", "page_idx": 16}, {"type": "text", "text": "B.1 Auxiliary lemma 19   \nB.2 $\\Psi(t)=1-t$ 20   \nB.3 $\\Psi(t)=-\\log(t)$ 23   \nB.4 $\\begin{array}{r}{\\Psi(t)=\\frac{1}{q}(1-t^{q})}\\end{array}$ 26 ", "page_idx": 16}, {"type": "text", "text": "C Proof of Theorem 5.1 28 ", "page_idx": 16}, {"type": "text", "text": "D Future work 28 ", "page_idx": 16}, {"type": "text", "text": "A Proof of realizable $\\mathcal{H}$ -consistency ", "text_level": 1, "page_idx": 17}, {"type": "text", "text": "Theorem 4.1. Assume that $\\mathcal{H}$ is closed under scaling. Suppose that $\\Psi$ is non-increasing, $\\Psi\\!\\left({\\frac{2}{3}}\\right)>0$ and $\\textstyle\\operatorname*{lim}_{t\\to1}\\Psi(t)=0$ . Then, the surrogate loss LRL2D is realizable $\\mathcal{H}$ -consistent with respect to $\\mathsf{L}_{\\mathrm{def}}$ . ", "page_idx": 17}, {"type": "text", "text": "Proof. We first prove that for every $(h,x,y)\\in\\mathcal{H}\\times\\mathcal{X}\\times\\mathcal{Y}$ , the following inequality holds: ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\mathsf{L}_{\\mathrm{def}}(h,x,y)\\leq\\frac{\\mathsf{L}_{\\mathrm{RL2D}}(h,x,y)}{\\Psi\\big(\\frac{2}{3}\\big)}.\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "We will analyze case by case. ", "page_idx": 17}, {"type": "text", "text": "Case I: If $\\mathsf{h}(x)\\in[n]$ (deferral does not occur): ", "page_idx": 17}, {"type": "text", "text": "(a) If $1_{\\mathsf{h}(x)\\neq y}=1$ , then we must have ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathrm{L_{\\mathrm{def}}}(h,x,y)=1,\\quad\\frac{e^{h(x,y)}}{\\sum_{y^{\\prime}\\in\\overline{{\\mathbb{Y}}}}e^{h(x,y^{\\prime})}}\\leq\\frac{1}{2},\\quad\\frac{e^{h(x,y)}+e^{h(x,n+1)}}{\\sum_{y^{\\prime}\\in\\overline{{\\mathbb{Y}}}}e^{h(x,y^{\\prime})}}\\leq\\frac{2}{3}}\\\\ &{\\implies\\mathsf{L_{\\mathrm{RL2D}}}(h,x,y)\\geq c(x,y)\\Psi\\Big(\\frac{1}{2}\\Big)+(1-c(x,y))\\Psi\\Big(\\frac{2}{3}\\Big)\\geq\\Psi\\Big(\\frac{2}{3}\\Big)\\mathsf{L_{\\mathrm{def}}}(h,x,y).}\\end{array}\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "(b) If $1_{\\mathsf{h}(x)\\neq y}=0$ , then we must have ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathsf{L}_{\\mathrm{RL2D}}(h,x,y)\\geq0=\\mathsf{L}_{\\mathrm{def}}(h,x,y).}\\end{array}\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "2. Case $\\mathbf{II}$ : If $\\mathsf{h}(x)=n+1$ (deferral occurs): then we must have ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\begin{array}{l l}{\\mathrm{L}_{\\operatorname*{def}}(h,x,y)=c(x,y),}&{\\frac{e^{h(x,y)}}{\\sum_{y^{\\prime}\\in\\overline{{\\mathbb{J}}}}e^{h(x,y^{\\prime})}}\\leq\\frac{1}{2}}\\\\ {\\implies\\mathsf{L}_{\\mathrm{RL2D}}(h,x,y)\\geq c(x,y)\\Psi\\Big(\\frac{1}{2}\\Big)\\geq\\Psi\\Big(\\frac{2}{3}\\Big)\\,\\mathsf{L}_{\\operatorname*{def}}(h,x,y).}\\end{array}\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "This concludes that $\\begin{array}{r}{\\lfloor\\scriptscriptstyle\\mathrm{Lef}\\left(h,x,y\\right)\\;\\leq\\;\\frac{\\lfloor\\scriptscriptstyle\\mathrm{LeL2D}\\left(h,x,y\\right)}{\\Psi\\left(\\frac{2}{3}\\right)}}\\end{array}$ . Next, we prove that LRL2D is realizable $\\mathcal{H}.$ consistent under the assumptions. Consider a distribution and an expert under which there exists a zero error solution $h^{*}\\,\\in\\,\\mathcal{H}$ with $\\mathcal{E}_{\\mathrm{L}_{\\mathrm{def}}}(h^{*})\\,=\\,0$ . Let $\\hat{h}$ be the minimizer of the surrogate loss: $\\hat{h}\\in\\mathop{\\mathrm{argmin}}_{h\\in\\mathcal{H}}\\mathcal{E}_{\\mathrm{L}_{\\mathrm{RL2D}}}(h)$ . Let $\\alpha$ be any real number. Then, the following inequality holds: ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\begin{array}{r}{(\\mathsf{L}_{\\mathrm{def}}\\leq\\frac{1}{\\Psi\\left(\\frac{2}{3}\\right)}\\mathsf{L}_{\\mathrm{RL2D}})}\\end{array}\n$$", "text_format": "latex", "page_idx": 17}, {"type": "equation", "text": "$$\n\\begin{array}{r l r}{\\lefteqn{\\mathcal{E}_{\\mathrm{L}_{\\mathrm{def}}}(\\hat{h})\\leq\\frac{1}{\\Psi\\left(\\frac{2}{3}\\right)}\\mathcal{E}_{\\mathrm{L}_{\\mathrm{RL2D}}}(\\hat{h})}}&{}&{\\quad{\\mathrm{(L)}}}\\\\ &{}&{\\leq\\frac{1}{\\Psi\\left(\\frac{2}{3}\\right)}\\mathcal{E}_{\\mathrm{L}_{\\mathrm{RL2D}}}(\\alpha h^{*})\\qquad\\mathrm{(}\\hat{h}\\in\\mathrm{argmin}_{h\\in\\mathcal{H}}\\,\\mathcal{E}_{\\mathrm{L}_{\\mathrm{RL2D}}}(h)\\mathrm{~and~}\\mathcal{H}\\mathrm{~is~clo}}\\\\ &{}&{=\\frac{1}{\\Psi\\left(\\frac{2}{3}\\right)}\\mathbb{E}[\\mathrm{L}_{\\mathrm{RL2D}}(\\alpha h^{*},x,y)\\left|\\,\\mathsf{h}^{*}(x)=n+1]\\mathbb{P}(\\mathsf{h}^{*}(x)=n+1)\\qquad\\qquad}\\\\ &{}&{\\quad+\\,\\frac{1}{\\Psi\\left(\\frac{2}{3}\\right)}\\mathbb{E}[\\mathrm{L}_{\\mathrm{RL2D}}(\\alpha h^{*},x,y)\\left|\\,\\mathsf{h}^{*}(x)\\in[n]]\\mathbb{P}(\\mathsf{h}^{*}(x)\\in[n]).}\\end{array}\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "For the first term conditional on $\\mathsf{h}^{*}(x)=n+1$ , we must have $h^{\\ast}(x,n+1)>\\operatorname*{max}_{y\\in\\mathbb{y}}h^{\\ast}(x,y)$ and $c(x,y)=0$ since the data is realizable. Therefore, ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\displaystyle\\operatorname*{lim}_{\\alpha\\to+\\infty}\\mathbb{E}[\\mathsf{L}_{\\mathrm{RL2D}}(\\alpha h^{*},x,y)\\mid\\mathsf{h}^{*}(x)=n+1]\\mathbb{P}(\\mathsf{h}^{*}(x)=n+1)}\\\\ &{=\\displaystyle\\operatorname*{lim}_{\\alpha\\to+\\infty}\\mathbb{E}\\Bigg[\\Psi\\Bigg(\\frac{e^{\\alpha h^{*}(x,y)}+e^{\\alpha h^{*}(x,n+1)}}{\\sum_{y^{\\prime}\\in\\overline{{y}}}e^{\\alpha h^{*}(x,y^{\\prime})}}\\Bigg)\\mid\\mathsf{h}^{*}(x)=n+1\\Bigg]\\mathbb{P}(\\mathsf{h}^{*}(x)=n+1)}\\\\ &{=\\mathbb{E}[0\\mid\\mathsf{h}^{*}(x)=n+1]\\mathbb{P}(\\mathsf{h}^{*}(x)=n+1)\\quad(\\operatorname*{lim}_{t\\to1}\\Psi(t)=0\\mathrm{~and~monotone~cons~})}\\\\ &{=0.}\\end{array}\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "onvergence theorem) ", "page_idx": 17}, {"type": "text", "text": "For the second term conditional on $\\mathsf{h}^{*}(x)\\,\\in\\,[n]$ , we must have $h^{\\ast}(x,y)>\\operatorname*{max}_{y^{\\prime}\\in\\overline{{{y}}},y^{\\prime}\\neq y}h(x,y^{\\prime})$ since the data is realizable. Therefore, ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\underset{\\alpha\\to+\\infty}{\\operatorname*{lim}}\\mathbb{E}\\big[\\mathrm{L}_{\\mathrm{RL2D}}\\big(\\alpha h^{*},x,y\\big)\\bigm|\\mathfrak{h}^{*}\\big(x)\\in[n]\\big]\\mathbb{P}\\big(\\mathfrak{h}^{*}\\big(x)\\in[n]\\big)}\\\\ &{=\\underset{\\alpha\\to+\\infty}{\\operatorname*{lim}}\\mathbb{E}\\Bigg[c\\big(x,y\\big)\\Psi\\Bigg(\\frac{e^{\\alpha h^{*}}(x,y)}{\\sum_{y^{\\prime}\\in\\overline{{\\mathfrak{g}}}}e^{\\alpha h^{*}(x,y^{\\prime})}}\\Bigg)}\\\\ &{\\qquad+\\left(1-c(x,y)\\right)\\Psi\\Bigg(\\frac{e^{\\alpha h^{*}(x,y)}+e^{\\alpha h^{*}(x,n+1)}}{\\sum_{y^{\\prime}\\in\\overline{{\\mathfrak{g}}}}e^{\\alpha h^{*}(x,y^{\\prime})}}\\Bigg)\\mid\\mathfrak{h}^{*}\\big(x)\\in[n]\\Bigg]\\mathbb{P}\\big(\\mathfrak{h}^{*}(x)\\in[n]\\big)}\\end{array}\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "Combining the two analyses, we conclude that $\\mathcal{E}_{\\mathrm{L}_{\\mathrm{def}}}(\\hat{h})=0$ and thus $\\mathsf{L}_{\\mathrm{RL2D}}$ is realizable $\\mathcal{H}$ -consistent with respect to $\\mathsf{L}_{\\mathrm{def}}$ . \u53e3 ", "page_idx": 18}, {"type": "text", "text": "B Proof of $\\mathcal{H}$ -consistency bounds ", "text_level": 1, "page_idx": 18}, {"type": "text", "text": "Before delving into the proof, we first establish some essential notation and definitions. Let L represent a deferral surrogate loss and $\\mathcal{H}$ denote a hypothesis set. We define the conditional error as $\\mathcal{\\ C}_{\\mathsf{L}}(h,x)=\\mathbb{E}_{y\\mid x}[\\mathsf{L}(h,x,y)]$ , the best-in-class conditional error as $\\begin{array}{r}{\\mathbb{\\ell}_{\\mathsf{L}}^{*}(\\mathcal{H},x)=\\operatorname*{inf}_{h\\in\\mathcal{H}}\\mathbb{\\ell}_{\\mathsf{L}}(h,x)}\\end{array}$ , and the conditional regret as $\\begin{array}{r}{\\Delta\\mathcal{C}_{\\mathrm{L},\\mathcal{K}}(h,x)=\\mathcal{C}_{\\mathrm{L}}(h,x)-\\mathcal{C}_{\\mathrm{L}}^{*}(\\mathcal{K},x)}\\end{array}$ . We proceed to present a general theorem demonstrating that, to establish $\\mathcal{H}$ -consistency bounds (1) with a concave function $\\Gamma$ , it suffices to lower bound the conditional regret of the surrogate loss by that of the deferral loss, using the same function $\\Gamma$ . ", "page_idx": 18}, {"type": "text", "text": "Theorem B.1. If the following holds for all $h\\in\\mathcal{H}$ and $x\\in\\mathcal X$ , for some concave function $\\Gamma$ : ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\Delta\\mathcal{C}_{\\mathrm{L}_{\\mathrm{def}},\\mathcal{H}}(h,x)\\le\\Gamma\\big(\\Delta\\mathcal{C}_{\\mathrm{L},\\mathcal{H}}(h,x)\\big),}\\end{array}\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "then, for all hypotheses $h\\in\\mathcal{H}$ and for any distribution, ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\mathcal{E}_{\\mathsf{L}_{\\mathrm{def}}}\\left(h\\right)-\\mathcal{E}_{\\mathsf{L}_{\\mathrm{def}}}^{*}\\left(\\mathcal{K}\\right)+\\mathcal{M}_{\\mathsf{L}_{\\mathrm{def}}}\\left(\\mathcal{K}\\right)\\le\\Gamma\\big(\\mathcal{E}_{\\mathsf{L}}\\big(h\\big)-\\mathcal{E}_{\\mathsf{L}}^{*}(\\mathcal{K})+\\mathcal{M}_{\\mathsf{L}}\\big(\\mathcal{K}\\big)\\big).\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "Proof. We can express the expectations of the conditional regrets for $\\mathsf{L}_{\\mathrm{def}}$ and $\\mathsf{L}$ as follows: ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{E}\\big[\\Delta\\mathcal{C}_{\\mathsf{L}_{\\mathrm{def}},\\mathcal{K}}(h,x)\\big]=\\mathcal{E}_{\\mathsf{L}_{\\mathrm{def}}}\\!\\left(h\\right)-\\mathcal{E}_{\\mathsf{L}_{\\mathrm{def}}}^{*}\\!\\left(\\mathcal{K}\\right)+\\mathcal{M}_{\\mathsf{L}_{\\mathrm{def}}}\\!\\left(\\mathcal{K}\\right)}\\\\ &{\\quad\\mathbb{E}\\big[\\Delta\\mathcal{C}_{\\mathsf{L},\\mathcal{K}}(h,x)\\big]=\\mathcal{E}_{\\mathsf{L}}\\!\\left(h\\right)-\\mathcal{E}_{\\mathsf{L}}^{*}\\!\\left(\\mathcal{K}\\right)+\\mathfrak{M}_{\\mathsf{L}}\\!\\left(\\mathcal{K}\\right)\\!.}\\end{array}\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "Then, by using (4) and taking the expectation, we obtain: ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\mathcal{E}_{\\mathrm{L}_{\\mathrm{def}}}(h)-\\mathcal{E}_{\\mathrm{L}_{\\mathrm{def}}}^{*}(\\mathcal{K})+\\mathcal{M}_{\\mathrm{L}_{\\mathrm{def}}}(\\mathcal{K})=\\mathbb{E}\\big[\\Delta\\mathcal{C}_{\\mathrm{L}_{\\mathrm{def}},\\mathcal{K}}(h,x)\\big]}&{}\\\\ {\\leq\\frac{\\mathbb{E}}{x}[\\Gamma(\\Delta\\mathcal{C}_{\\mathrm{L},\\mathcal{K}}(h,x))]}&{}\\\\ {\\leq\\Gamma\\bigg(\\frac{\\mathbb{E}}{x}[\\Delta\\mathcal{C}_{\\mathrm{L},\\mathcal{K}}(h,x)]\\bigg)}&{}\\\\ {=\\Gamma\\big(\\mathcal{E}_{\\mathrm{L}}(h)-\\mathcal{E}_{\\mathrm{L}}^{*}(\\mathcal{K})+\\mathcal{M}_{\\mathrm{L}}(\\mathcal{K})\\big).}\\end{array}\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "Thus, the proof is complete. ", "page_idx": 18}, {"type": "text", "text": "Next, to prove $\\mathcal{H}$ -consistency bounds using Theorem B.1, we will characterize the conditional regret of the deferral loss $\\mathsf{L}_{\\mathrm{def}}$ in the following section. ", "page_idx": 18}, {"type": "text", "text": "B.1 Auxiliary lemma ", "text_level": 1, "page_idx": 18}, {"type": "text", "text": "To simplify the presentation, we introduce the following notation. For any $y\\in\\mathcal{Y}$ , define $p(x,y)=$ $\\mathbb{P}(Y\\,=\\,y\\mid X\\,=\\,x)$ as the conditional probability that $Y\\,=\\,y$ given $X\\,=\\,x$ . For brevity, we will omit the dependency on $x$ in our notation. We denote by $h_{y}\\,=\\,h(x,y)$ for any $y\\in{\\overline{{\\mathfrak{Y}}}}$ . We also denote by $p_{y}=p(x,y)$ and $q_{y}=p(x,y)c(x,y)$ for any $y\\in\\big y$ , and $\\begin{array}{r}{p_{n+1}=\\sum_{y\\in\\mathbb{Y}}p(x,y)(1-c(x,y))}\\end{array}$ . ", "page_idx": 18}, {"type": "text", "text": "Note that $p(x,y)\\big(1-c(x,y)\\big)\\,=\\,p_{y}\\,-\\,q_{y}$ , $\\forall y\\,\\in\\,\\mathcal{Y}$ . Let $p_{\\mathsf{h}}\\,=\\,p_{\\mathsf{h}(x)}\\,=\\,\\left\\{p_{\\mathsf{h}(x)}\\quad\\mathsf{h}(x)\\,\\in\\,[n]\\right.\\qquad}$ Let .. $y_{\\mathrm{{max}}}\\,=\\,\\mathrm{argmax}_{y\\in\\big y}\\;p_{y}$ and $h_{\\mathrm{max}}\\,=\\,\\mathrm{argmax}_{y\\in\\big y}\\,h_{y}$ . Note that both $y_{\\mathrm{max}}$ and $h_{\\mathrm{max}}$ are in the label space $\\mathcal{Y}$ , while $\\mathsf{h}(x)$ is in the augmented label space $\\overline{{y}}$ . We characterize the conditional regret of the deferral loss $\\mathsf{L}_{\\mathrm{def}}$ as follows. ", "page_idx": 19}, {"type": "text", "text": "Lemma B.2. Assume that $\\mathcal{H}$ is symmetric and complete. Then, the conditional regret of the deferral loss $\\mathsf{L}_{\\mathrm{def}}$ can be expressed as follows: $\\Delta\\mathcal{C}_{\\mathrm{L_{def}},\\mathcal{K}}(h,x)=\\operatorname*{max}\\{p_{y_{\\operatorname*{max}}},p_{n+1}\\}-p_{\\mathsf{h}}$ . ", "page_idx": 19}, {"type": "text", "text": "Proof. We can write the conditional error of the deferral loss as follows: ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathcal{C}_{\\mathrm{L}_{\\mathrm{def}}}({h},{x})}\\\\ &{=\\displaystyle\\sum_{y\\in\\mathcal{Y}}p({x},{y})\\mathsf{L}_{\\mathrm{def}}({h},{x},{y})}\\\\ &{=\\displaystyle\\sum_{y\\in\\mathcal{Y}}p({x},{y})\\mathbf{1}_{\\mathsf{h}(x)\\neq y}\\mathbf{1}_{\\mathsf{h}(x)\\in[n]}+\\displaystyle\\sum_{y\\in\\mathcal{Y}}p(x,y)c(x,y)\\mathbf{1}_{\\mathsf{h}(x)=n+1}}\\\\ &{=\\big(1-p_{\\mathsf{h}(x)}\\big)\\mathbf{1}_{\\mathsf{h}(x)\\in[n]}+\\big(1-p_{n+1}\\big)\\mathbf{1}_{\\mathsf{h}(x)=n+1}}\\\\ &{=1-p_{\\mathsf{h}}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "Since $\\mathcal{H}$ is symmetric and complete, for any $x\\in\\mathcal{X},\\,\\,\\{{\\mathsf{h}}(x)\\colon h\\in\\mathcal{H}\\}\\,=\\,\\overline{{y}}$ . Then, the best-in-class conditional error of $\\mathsf{L}_{\\mathrm{def}}$ can be expressed as follows: ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\mathcal{C}_{\\mathsf{L}_{\\mathrm{def}}}^{*}\\left(\\mathcal{H},x\\right)=\\operatorname*{inf}_{h\\in\\mathcal{H}}\\mathcal{C}_{\\mathsf{L}_{\\mathrm{def}}}\\left(h,x\\right)=1-\\operatorname*{max}\\{p_{n+1},p_{y_{\\mathrm{max}}}\\}\n$$", "text_format": "latex", "page_idx": 19}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\Delta\\mathfrak{C}_{\\mathrm{L_{\\operatorname*{def}}},\\mathcal{K}}(h,x)=\\mathfrak{C}_{\\mathrm{L_{\\operatorname*{def}}}}(h,x)-\\mathfrak{C}_{\\mathrm{L_{\\operatorname*{def}}}}^{*}(\\mathcal{K},x)=\\operatorname*{max}\\{p_{y_{\\operatorname*{max}}},p_{n+1}\\}-p_{\\mathrm{h}}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "Next, we will present the proofs separately in the following sections, by lower bounding the conditional regret of the surrogate loss $\\mathsf{L}$ by that of the deferral loss $\\mathsf{L}_{\\mathrm{def}}$ using Lemma B.2. ", "page_idx": 19}, {"type": "text", "text": "B.2 $\\Psi(t)=1-t$ ", "page_idx": 19}, {"type": "text", "text": "Theorem B.3. Assume that $\\mathcal{H}$ is symmetric and complete. Then, for all $h\\in\\mathcal{H}$ and any distribution, the following $\\mathcal{H}$ -consistency bound holds: ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathcal{E}_{\\mathsf{L}_{\\mathrm{def}}}\\left(h\\right)-\\mathcal{E}_{\\mathsf{L}_{\\mathrm{def}}}\\left(\\mathcal{K}\\right)+\\mathcal{M}_{\\mathsf{L}_{\\mathrm{def}}}\\left(\\mathcal{K}\\right)\\le n\\big(\\mathcal{E}_{\\mathsf{L}_{\\mathrm{RL2D}}}\\left(h\\right)-\\mathcal{E}_{\\mathsf{L}_{\\mathrm{RL2D}}}\\left(\\mathcal{K}\\right)+\\mathcal{M}_{\\mathsf{L}_{\\mathrm{RL2D}}}\\left(\\mathcal{K}\\right)\\big).}\\end{array}\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "Proof. We can write the conditional error of the surrogate loss as follows: ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathcal{C}_{\\mathrm{L_{RL2D}}}(h,x)}\\\\ &{=\\displaystyle\\sum_{y\\in\\mathfrak{Y}}p(x,y)\\mathrm{L_{RL2D}}(h,x,y)}\\\\ &{=\\displaystyle\\sum_{y\\in\\mathfrak{Y}}p(x,y)c(x,y)\\left(1-\\frac{e^{h(x,y)}}{\\sum_{y^{\\prime}\\in\\overline{{\\mathfrak{Y}}}}e^{h(x,y^{\\prime})}}\\right)+\\sum_{y\\in\\mathfrak{Y}}p(x,y)(1-c(x,y))\\left(1-\\frac{e^{h(x,y)}+e^{h(x,n+1)}}{\\sum_{y^{\\prime}\\in\\overline{{\\mathfrak{Y}}}}e^{h(x,y^{\\prime})}}\\right)}\\\\ &{=\\displaystyle\\sum_{y\\in\\mathfrak{Y}}q_{y}\\left(1-\\frac{e^{h_{y}}}{\\sum_{y^{\\prime}\\in\\overline{{\\mathfrak{Y}}}}e^{h_{y^{\\prime}}}}\\right)+\\sum_{y\\in\\mathfrak{Y}}(p_{y}-q_{y})\\left(1-\\frac{e^{h_{y}}+e^{h_{n+1}}}{\\sum_{y^{\\prime}\\in\\overline{{\\mathfrak{Y}}}}e^{h_{y^{\\prime}}}}\\right).}\\end{array}\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "By Lemma B.2, the conditional regret of the deferral loss can be expressed as ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\Delta\\mathcal{C}_{\\mathrm{L_{\\mathrm{def}}},\\mathcal{K}}(h,x)=\\operatorname*{max}\\{p_{y_{\\mathrm{max}}},p_{n+1}\\}-p_{\\mathsf{h}}.\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "Next, we will show that the conditional regret of the surrogate loss can be lower bounded as follows: ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\Delta\\mathcal{C}_{\\mathrm{L}_{\\mathrm{RL2D}},\\mathcal{H}}(h,x)=\\mathcal{C}_{\\mathrm{L}_{\\mathrm{RL2D}}}(h)-\\mathcal{C}_{\\mathrm{L}_{\\mathrm{RL2D}}}^{*}(\\mathcal{H})\\geq\\frac{1}{n+1}\\big(\\Delta\\mathcal{C}_{\\mathrm{L}_{\\mathrm{def}},\\mathcal{H}}(h,x)\\big).\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "We first prove that for any hypothesis $h$ and $x\\in\\mathcal X$ , if $y_{\\mathrm{{max}}}\\neq h_{\\mathrm{{max}}}$ , then the conditional error of $h$ can be lower bounded by that of $\\overline{{h}}$ , which satisfies that $\\overline{{h}}(x,y)=\\left\\{\\begin{array}{l l}{h_{h_{\\mathrm{max}}}}&{y=y_{\\mathrm{max}}}\\\\ {h_{y_{\\mathrm{max}}}}&{y=h_{\\mathrm{max}}}\\\\ {h_{y}}&{\\mathrm{otherwise}}\\end{array}\\right.$ . Indeed, . ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\Theta_{\\mathrm{L}_{\\mathrm{trans}}}(h)-\\Theta_{\\mathrm{L}_{\\mathrm{trans}}}(\\overline{{h}})=q_{\\mathrm{bnos}}\\Bigg(1-\\frac{e^{h_{\\mathrm{trans}}}}{\\sum_{y^{\\prime}=\\overline{{y}}}e^{h_{\\mathrm{tr}}^{\\prime}}}\\Bigg)+(p_{\\{y_{\\mathrm{max}}}}-q_{\\mathrm{bnos}})\\Bigg(1-\\frac{e^{h_{\\mathrm{trans}}}}{\\sum_{y^{\\prime}=\\overline{{y}}}e^{h_{\\mathrm{tr}}^{\\prime}}}\\Bigg)}\\\\ {+\\,q_{\\mathrm{bnos}}\\Bigg(1-\\frac{e^{h_{\\mathrm{max}}}}{\\sum_{y^{\\prime}=\\overline{{y}}}e^{h_{\\mathrm{tr}}^{\\prime}}}\\Bigg)+(p_{\\{h_{\\mathrm{max}}}}-q_{\\mathrm{bnos}})\\Bigg(1-\\frac{e^{h_{\\mathrm{bnos}}}+e^{h_{\\mathrm{mis}}}}{\\sum_{y^{\\prime}=\\overline{{y}}}e^{h_{\\mathrm{tr}}^{\\prime}}}\\Bigg)}\\\\ {-\\,q_{\\mathrm{bnos}}\\Bigg(1-\\frac{e^{h_{\\mathrm{bnos}}}}{\\sum_{y^{\\prime}=\\overline{{y}}}e^{h_{\\mathrm{tr}}^{\\prime}}}\\Bigg)-(p_{\\{y_{\\mathrm{max}}}}-q_{\\mathrm{bnos}})\\Bigg(1-\\frac{e^{h_{\\mathrm{bnos}}}+e^{h_{\\mathrm{mis}}}}{\\sum_{y^{\\prime}=\\overline{{y}}}e^{h_{\\mathrm{tr}}^{\\prime}}}\\Bigg)}\\\\ {-\\,q_{\\mathrm{bnos}}\\Bigg(1-\\frac{e^{h_{\\mathrm{bnos}}}}{\\sum_{y^{\\prime}=\\overline{{y}}}e^{h_{\\mathrm{tr}}^{\\prime}}}\\Bigg)-(p_{\\{h_{\\mathrm{max}}}}-q_{\\mathrm{bnos}})\\Bigg(1-\\frac{e^{h_{\\mathrm{bnos}}}+e^{h_{\\mathrm{mis}}}}{\\sum_{y^{\\prime}=\\overline{{y}}}e^{h_{\\mathrm{tr}}^{\\prime}}}\\Bigg)}\\\\ {=\\frac{1}{\\sum_{y^{\\prime}=\\overline{{y}}}e^{h_{\\mathrm{tr}}^{\\prime}}}(p_{\\mathrm{b n o s\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "Therefore, we only need to lower bound the conditional regret of hypothesis $h$ satisfying $y_{\\mathrm{{max}}}=h_{\\mathrm{{max}}}$ . Next, we will analyze case by case. Note that when $\\bar{(p_{y_{\\mathrm{max}}}-p_{n+1}^{-})}\\bar{(h_{y_{\\mathrm{max}}}-h_{n+1}^{-})}\\bar{>}\\;0$ , we have $\\Delta\\mathcal{C}_{\\mathrm{L}_{\\mathrm{def}},\\mathcal{H}}(h,x)=\\operatorname*{max}\\{p_{y_{\\mathrm{max}}}\\}-p_{n+1}\\}-p_{\\mathsf{h}}=0$ . ", "page_idx": 20}, {"type": "text", "text": "1. Case I: If $p_{y_{\\mathrm{max}}}-p_{n+1}\\geq0$ and $h_{y_{\\mathrm{max}}}-h_{n+1}\\leq0$ : we define a new hypothesis $h_{\\mu}$ such $\\left\\lceil\\log\\left(e^{h_{n+1}}+\\mu\\right)\\right\\rceil\\ \\ \\ \\ y=y_{\\mathrm{max}}$ that $h_{\\mu}(x,y)\\;=\\;\\{\\log\\bigl(e^{h_{y_{\\mathrm{max}}}}-\\mu\\bigr)\\:\\:\\:\\:y=n+1\\}}\\\\ {\\qquad h(x,y)\\qquad\\:\\:\\:\\mathrm{otherwise}}\\end{array}$ , where $e^{h_{y\\mathrm{max}}}\\;\\geq\\;\\mu\\;\\geq\\;0$ . Then, we can . lower bound the conditional regret of LRL2D by using $\\Delta\\mathcal{C}_{\\mathrm{L_{RL2D}},\\mathcal{H}}(h,x)\\,\\geq\\,\\mathcal{C}_{\\mathrm{L_{RL2D}}}(h)\\;-$ $\\mathcal{C}_{\\mathrm{L_{\\mathrm{RL2D}}}}^{*}(h_{\\mu})$ for any $e^{h_{y_{\\mathrm{max}}}}\\geq\\mu\\geq0$ : ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\Delta U_{n+1,n}\\Delta(n,\\xi)}\\\\ &{\\mathcal{Z}_{n\\_n\\_n\\_n\\_i,d}}\\\\ &{\\mathcal{Z}_{n\\_n\\_n\\_n\\_i,d}}\\\\ &{\\mathcal{Z}_{n\\_n\\_n\\_n\\_i,d}}\\\\ &{\\mathcal{Z}_{n\\_n\\_n\\_i,d}}\\\\ &{\\mathcal{Z}_{n\\_n\\_n\\_i,d}}\\\\ &{\\mathcal{Z}_{n\\_i,d,i}}\\\\ &{\\mathcal{Z}_{n\\_i,d,i}}\\\\ &{\\mathcal{Z}_{n\\_i,d,i}}\\\\ &{\\Bigg\\{\\frac{\\hat{Z}_{n\\_i,d}}{2\\sqrt{n_{1}\\!+\\!\\mu_{0}^{2}}\\sqrt{n_{1}\\!+\\!\\mu_{0}^{2}}}\\Bigg\\}\\Bigg(\\eta_{n\\_i}\\Bigg(1\\!\\!-\\!\\frac{\\hat{Z}_{n\\_i}+\\hat{Z}_{n\\_i}}{\\sum_{p\\_{1}\\in\\partial\\mathcal{N}_{-1}}\\!\\!\\!-\\!\\mu_{0}^{2}}\\Bigg)\\Bigg)}\\\\ &{\\quad\\quad\\times\\frac{\\hat{Z}_{n\\_i}}{\\sqrt{n_{1}\\!+\\!\\mu_{0}^{2}}\\sqrt{n_{1}\\!+\\!\\mu_{0}^{2}}}\\Bigg[\\!\\Bigg(\\eta\\!\\!-\\!\\frac{\\hat{Z}_{n\\_i}}{\\sqrt{n_{1}\\!+\\!\\mu_{0}^{2}}\\sqrt{n_{1}\\!+\\!\\mu_{0}^{2}}}\\Bigg)\\!\\Bigg]}\\\\ &{\\quad\\quad\\times\\frac{\\hat{Z}_{n\\_i}}{\\sqrt{n_{1}\\!+\\!\\mu_{0}^{2}}\\sqrt{n_{1}\\!+\\!\\mu_{0}^{2}}}\\Bigg[\\!\\Bigg(\\eta\\!\\!-\\!\\frac{\\hat{Z}_{n\\_i}}{\\sqrt{n_{1}\\!+\\!\\mu_{0}^{2}}\\sqrt{n_{1}\\!+\\!\\mu_{0}^{2}}}\\Bigg)\\!\\Bigg(1\\!\\!-\\!\\frac{\\hat{Z}_{n\\_i}+\\hat{Z}_{n\\_i}}{\\sqrt{n_{1}\\!+\\!\\mu_{0}^{2}}\\sqrt{n_{1}\\!+\\!\\mu_{0}^{2}}}\\Bigg)\\!\\Bigg]}\\\\ &{\\quad\\quad\\sim\\eta_{n\\_{1}}\\!\\Bigg(1\\!\\!-\\!\\frac{\\hat{Z}_{n\\_i}}{\\sqrt{n_{1}\\!+\\!\\mu_{0}^{2}}\\sqrt \n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "2. Case II: If $p_{y_{\\mathrm{max}}}-p_{n+1}\\leq0$ and $h_{y_{\\mathrm{max}}}-h_{n+1}\\geq0$ : we define a new hypothesis $h_{\\mu}$ such that $h_{\\mu}(x,y)=\\left\\{\\log\\bigl(e^{h_{n+1}}-\\mu\\bigr)\\right.$ $y=y_{\\mathrm{max}}$ $y=n+1$ , where $e^{h_{n+1}}\\geq\\mu\\geq0$ . Then, we can lower bound otherwise. the conditional regret of LRL2D by using $\\Delta\\mathcal{C}_{\\mathrm{L_{RL2D}},\\mathcal{H}}(h,x)\\ge\\mathcal{C}_{\\mathrm{L_{RL2D}}}(h)-\\mathcal{C}_{\\mathrm{L_{RL2D}}}^{*}(h_{\\mu})$ for any $e^{h_{n+1}}\\geq\\mu\\geq0$ : ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\Delta U_{n+\\mathrm{ind},n}\\simeq\\Delta(n,\\tau)}\\\\ &{\\sum_{\\tau,\\tau^{n}\\neq0}^{\\infty}\\left(R_{n+\\mathrm{ind}}\\simeq\\hat{l}_{n+\\mathrm{ond}}(h_{n})\\right)}\\\\ &{\\geq\\frac{1}{C\\sqrt{n!n!n!}}\\left(\\Theta(\\omega_{n+\\mathrm{ind}}(h-\\frac{\\hat{l}_{n+\\mathrm{ind}}}{2C\\sqrt{n!n!n!}}+\\hat{l}_{0}))\\right)}\\\\ &{\\geq\\frac{1}{C\\sqrt{n!n!n!}}\\left(\\Theta(\\omega_{n}^{-1}\\left(1-\\frac{\\hat{l}_{n+\\mathrm{ind}}}{2C\\sqrt{n!n!n!}}\\right)^{-1}(\\theta_{1}-\\frac{\\hat{l}_{n+\\mathrm{ind}}}{2C\\sqrt{n!n!n!}})\\right)\\left(1-\\frac{\\hat{l}_{n+\\mathrm{ind}}}{\\sum_{j\\in\\mathcal{N}}c^{j}(\\sqrt{n!n!n!}}\\right)^{-1}\\right.}\\\\ &{\\left.\\quad+\\frac{1}{\\mathrm{ind}}\\sum_{\\tau\\in\\mathcal{N}_{n}\\cap\\mathcal{N}_{n}}\\left(b-\\frac{\\hat{l}_{n}\\sqrt{n!n!}}{2C\\sqrt{n!n!n!}}+\\hat{l}_{0}\\sqrt{n!n!n!}\\right)\\right.}\\\\ &{\\qquad\\left.-\\eta\\log\\frac{1}{C}\\sqrt{n!n!n!\\left(1-\\frac{\\hat{l}_{n}\\sqrt{n!n!}}{2C\\sqrt{n!n!n!}}+\\hat{l}_{0}\\sqrt{n!n!n!}\\right)\\left(1-\\frac{\\hat{l}_{n+\\mathrm{ind}}}{\\sum_{j\\in\\mathcal{N}}c^{j}(\\sqrt{n!n!n!})}\\right)}\\right)}\\\\ &{\\geq\\frac{1}{C\\sqrt{n!n!n!n!}}\\left(b-\\frac{1}{C\\sqrt{n!n!n!}}\\left(b-\\frac{\\hat{l}_{n}\\sqrt{n!n!}-(b-\\omega_{n}+\\frac{\\hat{l}_{n}\\sqrt{n!n!}}{2C})}{\\sum_{j\\in\\mathcal{N}}c^{j}(\\sqrt{n!n!n!})}+\\left(b-\\frac{\\hat{l}_{n+\\mathrm{ind}}}{2C\\sqrt{n!n!n!}}+b\\frac{(\\hat{l}_{n}\\sqrt{n!n!}-(b-\\omega_{n}+\\frac{\\hat{l}_{n}\\sqrt{n!n}}))}{\\sum_\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "This proves the inequality (6). By Theorem B.1, we complete the proof. ", "page_idx": 21}, {"type": "text", "text": "Theorem B.4. Assume that $\\mathcal{H}$ is symmetric and complete. Assume that $c(x,y)=1_{\\mathbf{g}(x)\\neq y}$ . Then, for all $h\\in\\mathcal{H}$ and any distribution, the following $\\mathcal{H}$ -consistency bound holds: ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathcal{E}_{\\mathrm{L}_{\\mathrm{def}}}\\left(h\\right)-\\mathcal{E}_{\\mathrm{L}_{\\mathrm{def}}}\\left(\\mathcal{K}\\right)+\\mathcal{M}_{\\mathrm{L}_{\\mathrm{def}}}\\left(\\mathcal{K}\\right)\\leq2\\sqrt{\\mathcal{E}_{\\mathrm{L}_{\\mathrm{RL2D}}}\\left(h\\right)-\\mathcal{E}_{\\mathrm{L}_{\\mathrm{RL2D}}}\\left(\\mathcal{K}\\right)+\\mathcal{M}_{\\mathrm{L}_{\\mathrm{RL2D}}}\\left(\\mathcal{K}\\right)}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "Proof. We can write the conditional error of the surrogate loss as follows: ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathrm{L}_{\\mathrm{RL2D}}(n,x)}\\\\ &{=\\displaystyle\\sum_{y\\in\\mathfrak{Y}}p(x,y)\\mathrm{L}_{\\mathrm{RL2D}}(h,x,y)}\\\\ &{=-\\displaystyle\\sum_{y\\in\\mathfrak{Y}}p(x,y)c(x,y)\\log\\left(\\frac{e^{h(x,y)}}{\\sum_{y^{\\prime}\\in\\overline{{\\mathfrak{Y}}}}e^{h(x,y^{\\prime})}}\\right)-\\sum_{y\\in\\mathfrak{Y}}p(x,y)(1-c(x,y))\\log\\left(\\frac{e^{h(x,y)}+e^{h(x,n+1)}}{\\sum_{y^{\\prime}\\in\\overline{{\\mathfrak{Y}}}}e^{h(x,y^{\\prime})}}\\right)}\\\\ &{=-\\displaystyle\\sum_{y\\in\\mathfrak{Y}}q_{y}\\log\\left(\\frac{e^{h_{y}}}{\\sum_{y^{\\prime}\\in\\overline{{\\mathfrak{Y}}}}e^{h_{y^{\\prime}}}}\\right)-\\sum_{y\\in\\mathfrak{Y}}\\left(p_{y}-q_{y}\\right)\\log\\left(\\frac{e^{h_{y}}+e^{h_{n+1}}}{\\sum_{y^{\\prime}\\in\\overline{{\\mathfrak{Y}}}}e^{h_{y^{\\prime}}}}\\right).}\\end{array}\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "By Lemma B.2, the conditional regret of the deferral loss can be expressed as ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\Delta\\mathcal{C}_{\\mathrm{L_{\\mathrm{def}}},\\mathcal{K}}(h,x)=\\operatorname*{max}\\{p_{y_{\\mathrm{max}}},p_{n+1}\\}-p_{\\mathsf{h}}.\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "Next, we will show that the conditional regret of the surrogate loss can be lower bounded as follows: ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\Delta\\mathcal{C}_{\\mathrm{L}_{\\mathrm{RL2D}},\\mathcal{K}}(h,x)=\\mathcal{C}_{\\mathrm{L}_{\\mathrm{RL2D}}}(h)-\\mathcal{C}_{\\mathrm{L}_{\\mathrm{RL2D}}}^{*}(\\mathcal{K})\\geq\\frac{1}{2}\\big(\\Delta\\mathcal{C}_{\\mathrm{L}_{\\mathrm{deff}},\\mathcal{K}}(h,x)\\big)^{2}.\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "We first consider the case where $\\mathbf{g}(x)\\neq y_{\\mathrm{max}}$ . Otherwise, it would be straightforward to see that the bound holds. In the case where $\\mathsf{g}(x)\\neq y_{\\mathrm{max}}$ , we have $q_{y_{\\mathrm{{max}}}}=p_{y_{\\mathrm{{max}}}}$ . We first prove that for any hypothesis $h$ and $x\\in\\mathcal X$ , if $y_{\\mathrm{{max}}}\\neq h_{\\mathrm{{max}}}$ , then the conditional error of $h$ can be lower bounded by that ", "page_idx": 22}, {"type": "text", "text": "of $\\overline{h}$ , which satisfies that $\\overline{{h}}(x,y)=\\left\\{\\begin{array}{l l}{h_{h_{\\mathrm{max}}}}&{y=y_{\\mathrm{max}}}\\\\ {h_{y_{\\mathrm{max}}}}&{y=h_{\\mathrm{max}}}\\\\ {h_{y}}&{\\mathrm{otherwise}}\\end{array}\\right.$ . Indeed, . ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\lefteqn{\\mathrm{\\Sigma}^{-1}(\\mathrm{Re},\\mathrm{\\Sigma}^{*})^{(\\mathrm{i})}\\setminus\\mathrm{\\Sigma}^{-1}\\mathrm{\\Sigma}^{+1}(x,\\mathrm{fl})^{(\\mathrm{i})}}}\\\\ {=-q_{\\mathrm{bas.}}\\log\\left(\\frac{e^{\\mathrm{\\Sigma}^{\\mathrm{b}}}\\mathrm{Re}n_{\\mathrm{s}}}{\\sum_{j\\in\\mathcal{F}}e^{\\mathrm{i}}}\\right)-\\left(p_{\\mathrm{bas.}}-q_{\\mathrm{bas.}}\\right)\\log\\left(\\frac{e^{\\mathrm{\\Sigma}^{\\mathrm{b}}}\\mathrm{Re}n_{\\mathrm{s}}+e^{\\mathrm{\\Sigma}^{\\mathrm{b}}}\\mathrm{I}}{\\sum_{j\\in\\mathcal{F}}e^{\\mathrm{i}}}\\right)}\\\\ &{-\\ \\eta_{\\mathrm{bas.}}\\log\\left(\\frac{e^{\\mathrm{\\Sigma}^{\\mathrm{b}}}\\mathrm{Re}n_{\\mathrm{s}}}{\\sum_{j\\in\\mathcal{F}}e^{\\mathrm{i}}}\\right)-\\left(p_{\\mathrm{bas.}}-q_{\\mathrm{bas.}}\\right)\\log\\left(\\frac{e^{\\mathrm{\\Sigma}^{\\mathrm{b}}}\\mathrm{Ren_{\\mathrm{s}}}+e^{\\mathrm{\\Sigma}^{\\mathrm{b}}}\\mathrm{I}}{\\sum_{j\\in\\mathcal{F}}e^{\\mathrm{i}}}\\right)}\\\\ &{+\\ \\eta_{\\mathrm{bas.}}\\log\\left(\\frac{e^{\\mathrm{\\Sigma}^{\\mathrm{b}}}\\mathrm{Ren_{\\mathrm{s}}}}{\\sum_{j\\in\\mathcal{F}}e^{\\mathrm{i}}}\\right)+\\left(p_{\\mathrm{bas.}}-q_{\\mathrm{bas.}}\\right)\\log\\left(\\frac{e^{\\mathrm{\\Sigma}^{\\mathrm{b}}}\\mathrm{Ren_{\\mathrm{s}}}+e^{\\mathrm{\\Sigma}^{\\mathrm{b}}}\\mathrm{I}}{\\sum_{j\\in\\mathcal{F}}e^{\\mathrm{i}}}\\right)}\\\\ &{+\\ \\eta_{\\mathrm{bas.}}\\log\\left(\\frac{e^{\\mathrm{\\Sigma}^{\\mathrm{b}}}\\mathrm{Ren_{\\mathrm{s}}}}{\\sum_{j\\in\\mathcal{F}}e^{\\mathrm{i}}}\\right)+\\left(p_{\\mathrm{bas.}}-q_{\\mathrm{bas.}}\\right)\\log\\left(\\frac{e^{\\mathrm{\\Sigma}^{\\mathrm{b}}}\\mathrm{Ren_{\\mathrm{s}}}+e^{\\mathrm{\\Sigma}^{\\mathrm{b}}}\\mathrm{I}}{\\sum_{j \n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "Therefore, we only need to lower bound the conditional regret of hypothesis $h$ satisfying $y_{\\mathrm{{max}}}=h_{\\mathrm{{max}}}$   \nSince $c(x,y)\\,=\\,1_{\\mathbf{g}(x)\\neq y}$ , we have $p_{y_{\\mathrm{max}}}\\,\\geq\\,p_{n+1}\\,=\\,p_{\\mathsf{g}(x)}$ . Note that when $(p_{y_{\\mathrm{{max}}}}-p_{n+1})(h_{y_{\\mathrm{{max}}}}-$   \n$h_{n+1})>0$ , we have $\\Delta\\mathcal{C}_{\\mathrm{L}_{\\mathrm{def}},\\mathcal{H}}(h,x)=\\operatorname*{max}\\{p_{y_{\\mathrm{max}}},p_{n+1}\\}-p_{\\mathsf{h}}=0$ . When $h_{y_{\\mathrm{max}}}\\!-\\!h_{n+1}\\leq0$ , we define $\\left(\\log\\left(e^{h_{n+1}}+\\mu\\right)\\right.$ y = ymax   \na new hypothesis $h_{\\mu}$ such that $h_{\\mu}(x,y)=\\left\\{\\log\\!\\left(e^{h_{y_{\\operatorname*{max}}}}-\\bar{\\mu}\\right)\\right.$ $y=n+1$ , where $e^{h_{y_{\\mathrm{max}}}}-e^{h_{n+1}}\\leq$ otherwise. ", "page_idx": 22}, {"type": "text", "text": "$\\mu\\leq e^{h_{y_{\\mathrm{max}}}}$ . Then, we can lower bound the conditional regret of LRL2D by using $\\Delta\\mathcal{C}_{\\mathrm{L_{RL2D}},\\mathcal{H}}(h,x)\\geq$ $\\mathcal{C}_{\\mathrm{L}_{\\mathrm{RL2D}}}(h)-\\mathcal{C}_{\\mathrm{L}_{\\mathrm{RL2D}}}^{*}(h_{\\mu})$ for any $e^{h_{y_{\\mathrm{max}}}}-e^{h_{n+1}}\\leq\\mu\\leq e^{h_{y_{\\mathrm{max}}}}$ : ", "page_idx": 23}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\Delta\\xi_{\\operatorname*{max}}\\Delta\\xi_{\\operatorname*{max}}\\left(h_{,t}\\right)}\\\\ &{=\\xi_{\\operatorname*{max}}\\frac{\\mu_{0}}{\\nu\\omega_{0}^{2}},\\qquad\\qquad\\qquad\\big(\\ell_{\\operatorname*{max}}h_{,t}\\big(\\Delta\\xi_{\\operatorname*{max}}^{\\star}-\\ell_{\\operatorname*{max}}\\big)h_{,t}\\big)}\\\\ &{\\overset{}{\\sum}\\xi_{\\operatorname*{max}}\\frac{\\mu_{0}}{\\nu\\omega_{0}^{2}},\\qquad\\qquad\\qquad\\Bigg(\\sqrt{\\mu_{0}}\\ln\\omega_{0}^{2}\\sqrt{\\frac{\\mu_{0}\\nu_{-t}}{\\sum_{p=0}^{N_{\\ell}}\\Delta\\xi_{\\operatorname*{max}}^{\\star}}}\\Bigg)-(\\eta_{\\infty}-\\Psi_{0-\\infty})\\ln\\omega_{0}^{2}\\Bigg(\\frac{\\sqrt{\\mu_{0}}\\ln\\omega_{0}^{2}}{\\sum_{p=0}^{N_{\\ell}}\\Delta\\xi_{\\operatorname*{max}}^{\\star}}\\Bigg)}\\\\ &{\\overset{}{\\sum}\\xi_{\\operatorname*{max}}\\frac{\\mu_{0}}{\\nu\\omega_{0}^{2}},\\qquad\\Bigg(\\eta_{\\infty}-\\Psi_{0-\\infty}\\Big)\\ln\\Bigg(\\frac{\\sqrt{\\mu_{0}}\\Delta\\xi_{\\operatorname*{max}}^{\\star}}{\\sum_{p=0}^{N_{\\ell}}\\Delta\\xi_{\\operatorname*{max}}^{\\star}}\\Bigg),}\\\\ &{\\quad-\\underbrace{\\mu_{0}\\sqrt{\\mu_{0}}\\ln\\omega_{0}^{2}}_{\\nu\\in\\mathcal{N}_{0}}\\Bigg(\\eta_{\\infty}-\\Psi_{0-\\infty}\\Big)\\ln\\Bigg(\\frac{\\sqrt{\\mu_{0}}\\Delta\\xi_{\\operatorname*{max}}^{\\star}}{\\sum_{p=0}^{N_{\\ell}}\\Delta\\xi_{\\operatorname*{max}}^{\\star}}\\Bigg)}\\\\ &{\\qquad+\\underbrace{\\mu_{0}\\sqrt{\\mu_{0}}\\ln\\omega_{0}^{2}}_{\\nu\\in\\mathcal{N}_{0}}+\\beta_{\\operatorname*{max}}-\\underbrace{\\mu_{0}\\sqrt{\\mu_{0}}\\ln\\omega_{0}^{2}}_{\\nu\\in\\mathcal{N}_{0}}\\Bigg(\\frac{\\sqrt{\\mu_{0}}\\Delta\\xi_{\\operatorname*{max}}^{\\star}}{\\sum_{p\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "By differentiating with respect to $\\mu$ , we obtain that ", "page_idx": 23}, {"type": "equation", "text": "$$\n\\mu=\\frac{q_{y_{\\mathrm{max}}}e^{h_{y_{\\mathrm{max}}}}-\\left(p_{n+1}-\\left(p_{y_{\\mathrm{max}}}-q_{y_{\\mathrm{max}}}\\right)\\right)e^{h_{n+1}}}{q_{y_{\\mathrm{max}}}+\\left(p_{n+1}-\\left(p_{y_{\\mathrm{max}}}-q_{y_{\\mathrm{max}}}\\right)\\right)}\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "achieves the maximum. Plugging it into the expression, we have ", "page_idx": 23}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\Delta\\mathcal{C}_{\\mathrm{L_{RL2D}},\\mathcal{K}}(h,x)}\\\\ &{\\geq q_{y_{\\operatorname*{max}}}\\log\\Biggl[\\frac{\\left[e^{h_{y_{\\operatorname*{max}}}}+e^{h_{n+1}}\\right]q_{y_{\\operatorname*{max}}}}{e^{h_{y_{\\operatorname*{max}}}}\\left[q_{y_{\\operatorname*{max}}}+\\left(p_{n+1}-\\left(p_{y_{\\operatorname*{max}}}-q_{y_{\\operatorname*{max}}}\\right)\\right)\\right]}\\Biggr]}\\\\ &{\\qquad+\\left(p_{n+1}-\\left(p_{y_{\\operatorname*{max}}}-q_{y_{\\operatorname*{max}}}\\right)\\right)\\log\\Biggl[\\frac{\\left[e^{h_{y_{\\operatorname*{max}}}}+e^{h_{n+1}}\\right]\\left(p_{n+1}-\\left(p_{y_{\\operatorname*{max}}}-q_{y_{\\operatorname*{max}}}\\right)\\right)}{e^{h_{n+1}}\\left[q_{y_{\\operatorname*{max}}}+\\left(p_{n+1}-\\left(p_{y_{\\operatorname*{max}}}-q_{y_{\\operatorname*{max}}}\\right)\\right)\\right]}\\Biggr].}\\end{array}\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "This can be further lower bounded by taking the minimum over $h\\in\\mathcal{H}$ , where the minimum is attained when $e^{h_{y_{\\mathrm{max}}}}=e^{h_{n+1}}$ Therefore, ", "page_idx": 23}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\lefteqn{\\Delta\\mathcal{C}_{\\mathrm{L}_{\\mathrm{RL2D}},\\mathcal{H}}(h,x)}\\quad}&{}\\\\ &{\\geq q_{y_{\\operatorname*{max}}}\\log\\biggl[\\frac{2q_{y_{\\operatorname*{max}}}}{q_{y_{\\operatorname*{max}}}+\\left(p_{n+1}-\\left(p_{y_{\\operatorname*{max}}}-q_{y_{\\operatorname*{max}}}\\right)\\right)}\\biggr]}\\\\ &{\\quad\\quad+\\left(p_{n+1}-\\left(p_{y_{\\operatorname*{max}}}-q_{y_{\\operatorname*{max}}}\\right)\\right)\\log\\biggl[\\frac{2(p_{n+1}-\\left(p_{y_{\\operatorname*{max}}}-q_{y_{\\operatorname*{max}}}\\right))}{q_{y_{\\operatorname*{max}}}+\\left(p_{n+1}-\\left(p_{y_{\\operatorname*{max}}}-q_{y_{\\operatorname*{max}}}\\right)\\right)}\\biggr].}\\end{array}\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "By applying Pinsker\u2019s inequality [Mohri et al., 2018, Proposition E.7], we obtain ", "page_idx": 24}, {"type": "equation", "text": "$$\n\\begin{array}{r l r}{\\lefteqn{\\Delta\\mathbb{C}_{\\mathrm{LR20},\\infty}(h,x)}}\\\\ &{\\geq\\left[q_{\\mathrm{{ymax}}}+p_{n+1}-\\left(p_{y_{\\mathrm{max}}}-q_{y_{\\mathrm{max}}}\\right)\\right]}\\\\ &{}&{\\times\\frac{1}{2}\\Bigg[\\Bigg|\\frac{q_{y_{\\mathrm{max}}}}{q_{y_{\\mathrm{max}}}+p_{n+1}-\\left(p_{y_{\\mathrm{max}}}-q_{y_{\\mathrm{max}}}\\right)}-\\frac{1}{2}\\Bigg|+\\Bigg|\\frac{p_{n+1}-\\left(p_{y_{\\mathrm{max}}}-q_{y_{\\mathrm{max}}}\\right)}{q_{y_{\\mathrm{max}}}+p_{n+1}-\\left(p_{y_{\\mathrm{max}}}-q_{y_{\\mathrm{max}}}\\right)}-\\frac{1}{2}\\Bigg|\\Bigg]^{2}}\\\\ &{\\geq\\frac{1}{2}\\frac{\\left(p_{y_{\\mathrm{max}}}-p_{n+1}\\right)^{2}}{q_{y_{\\mathrm{max}}}+p_{n+1}-\\left(p_{y_{\\mathrm{max}}}-q_{y_{\\mathrm{max}}}\\right)}}\\\\ &{\\geq\\frac{1}{2}(p_{y_{\\mathrm{max}}}-p_{n+1})^{2}}&{\\mathrm{(}q_{y_{\\mathrm{max}}}+p_{n+1}-\\left(p_{y_{\\mathrm{max}}}-q_{y_{\\mathrm{max}}}\\right)\\leq}\\\\ &{=\\frac{1}{2}(\\Delta\\mathbb{C}_{\\mathrm{Leq},\\mathcal{R}}(h,x))^{2}}&{\\mathrm{(by~the~assumption~}p_{y_{\\mathrm{max}}}\\geq p_{n+1}\\mathrm{~and~}h_{y_{\\mathrm{max}}}\\leq h_{n+1}\\mathrm{~and~}\\Vert\\mathcal{F}_{1}\\mathrm{)}}\\end{array}\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "This proves the inequality (7). In the case where $\\mathsf{g}(x)=y_{\\mathrm{max}}$ , we have $p_{n+1}=p_{y_{\\mathrm{max}}}$ . By Lemma B.2, the conditional regret of the deferral loss can be expressed as $\\Delta\\mathcal{C}_{\\mathrm{L}_{\\mathrm{def}},\\mathcal{H}}(h,x)=p_{n+1}-p_{\\mathsf{h}}$ . If $\\mathsf{h}(x)=$ $n\\!+\\!1$ , then we have $\\Delta\\mathcal{C}_{\\mathrm{L}_{\\mathrm{def}},\\mathcal{H}}(h,x)=0$ . Otherwise, when $\\mathsf{h}(x)\\neq\\bar{n}+1$ , we can proceed in the similar way as above, by defining a new hypothesis $h_{\\mu}$ such that $h_{\\mu}(x,y)={\\left\\{\\begin{array}{l l}{\\log\\!{\\left(e^{h_{n+1}}+\\mu\\right)}}&{y={\\mathsf{h}}(x)}\\\\ {\\log\\!{\\left(e^{h_{\\mathsf{h}(x)}}-\\mu\\right)}}&{y=n+1}\\\\ {h(x,y)}&{{\\mathrm{otherwis}}}\\end{array}\\right.}$ e Then, we can lower bound the conditional regret of LRL2D by using $\\Delta\\mathcal{C}_{\\mathrm{L_{RL2D}},\\mathcal{K}}(h,x)\\geq\\mathcal{C}_{\\mathrm{L_{RL2D}}}(h)-$ $\\mathcal{C}_{\\mathrm{L}_{\\mathrm{RL2D}}}^{*}(h_{\\mu})$ , by applying the same derivation as above, modulo replacing $y_{\\mathrm{max}}$ with $\\mathsf{h}(x)$ . This leads to the inequality (7) as well. By Theorem B.1, we complete the proof. ", "page_idx": 24}, {"type": "text", "text": "B.4 $\\begin{array}{r}{\\Psi(t)=\\frac{1}{q}(1-t^{q})}\\end{array}$ ", "page_idx": 25}, {"type": "text", "text": "Theorem B.5. Assume that $\\mathcal{H}$ is symmetric and complete. Assume that $c(x,y)=1_{\\mathbf{g}(x)\\neq y}$ . Then, for all $h\\in\\mathcal{H}$ and any distribution, the following $\\mathcal{H}$ -consistency bound holds: ", "page_idx": 25}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathcal E_{\\mathrm{L}_{\\mathrm{def}}}(h)-\\mathcal E_{\\mathrm{L}_{\\mathrm{def}}}(\\mathcal K)+\\mathcal M_{\\mathrm{L}_{\\mathrm{def}}}(\\mathcal K)\\leq2\\sqrt{(n+1)^{\\alpha}\\big(\\mathcal E_{\\mathrm{L}_{\\mathrm{RL},\\mathrm{2D}}}(h)-\\mathcal E_{\\mathrm{L}_{\\mathrm{RL},\\mathrm{2D}}}(\\mathcal K)+\\mathcal M_{\\mathrm{L}_{\\mathrm{RL},\\mathrm{2D}}}(\\mathcal K)\\big)}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "Proof. We can write the conditional error of the surrogate loss as follows: ", "page_idx": 25}, {"type": "equation", "text": "$$\n\\begin{array}{l}{\\mathcal{C}_{\\mathrm{L_{RL2D}}}(h,x)=\\displaystyle\\sum_{y\\in\\mathfrak{H}}p(x,y)\\mathrm{L_{RL2D}}(h,x,y)}\\\\ {\\quad=\\displaystyle\\frac{1}{q}\\sum_{y\\in\\mathfrak{H}}p(x,y)c(x,y)\\Bigg(1-\\left(\\frac{e^{h(x,y)}}{\\sum_{y^{\\prime}\\in\\mathfrak{H}}e^{h(x,y^{\\prime})}}\\right)^{q}\\Bigg)}\\\\ {\\displaystyle\\qquad\\qquad+\\frac{1}{q}\\sum_{y\\in\\mathfrak{H}}p(x,y)(1-c(x,y))\\Bigg(1-\\left(\\frac{e^{h(x,y)}+e^{h(x,n+1)}}{\\sum_{y^{\\prime}\\in\\mathfrak{H}}e^{h(x,y^{\\prime})}}\\right)^{q}\\Bigg)}\\\\ {\\displaystyle=\\frac{1}{q}\\sum_{y\\in\\mathfrak{H}}q_{y}\\Bigg(1-\\left(\\frac{e^{h_{y}}}{\\sum_{y^{\\prime}\\in\\mathfrak{H}}e^{h_{y^{\\prime}}}}\\right)^{q}\\Bigg)+\\frac{1}{q}\\sum_{y\\in\\mathfrak{H}}\\left(p_{y}-q_{y}\\right)\\Bigg(1-\\left(\\frac{e^{h_{y}}+e^{h_{n+1}}}{\\sum_{y^{\\prime}\\in\\mathfrak{H}}e^{h_{y^{\\prime}}}}\\right)^{q}\\Bigg).}\\end{array}\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "By Lemma B.2, the conditional regret of the deferral loss can be expressed as ", "page_idx": 25}, {"type": "equation", "text": "$$\n\\Delta\\mathcal{C}_{\\mathrm{L_{\\mathrm{def}}},\\mathcal{K}}(h,x)=\\operatorname*{max}\\{p_{y_{\\mathrm{max}}},p_{n+1}\\}-p_{\\mathsf{h}}.\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "Next, we will show that the conditional regret of the surrogate loss can be lower bounded as follows: ", "page_idx": 25}, {"type": "equation", "text": "$$\n\\Delta\\mathcal{C}_{\\mathrm{L}_{\\mathrm{RL2D}},\\mathcal{H}}(h,x)=\\mathcal{C}_{\\mathrm{L}_{\\mathrm{RL2D}}}(h)-\\mathcal{C}_{\\mathrm{L}_{\\mathrm{RL2D}}}^{*}(\\mathcal{H})\\geq\\frac{1}{2(n+1)^{q}}\\big(\\Delta\\mathcal{C}_{\\mathrm{L}_{\\mathrm{deff}},\\mathcal{H}}(h,x)\\big)^{2}.\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "We first consider the case where $\\mathbf{g}(x)\\neq y_{\\mathrm{max}}$ . Otherwise, it would be straightforward to see that the bound holds. In the case where $\\mathsf{g}(x)\\neq y_{\\mathrm{max}}$ , we have $q_{y_{\\mathrm{max}}}=p_{y_{\\mathrm{max}}}$ . We first prove that for any hypothesis $h$ and $x\\in\\mathcal X$ , if $y_{\\mathrm{{max}}}\\neq h_{\\mathrm{{max}}}$ , then the conditional error of $h$ can be lower bounded by that ", "page_idx": 25}, {"type": "text", "text": "of $\\overline{h}$ , which satisfies that $\\overline{{h}}(x,y)=\\left\\{\\begin{array}{l l}{h_{h_{\\mathrm{max}}}}&{y=y_{\\mathrm{max}}}\\\\ {h_{y_{\\mathrm{max}}}}&{y=h_{\\mathrm{max}}\\ \\ .\\ \\mathrm{Inde}}\\\\ {h_{y}}&{\\mathrm{otherwise}.}\\end{array}\\right.$ ed, ", "page_idx": 25}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathrm{\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\}\\mathrm{\\\\\\\\\\\\\\\\\\}\\mathrm{\\\\\\\\\\\\\\\\\\}}\\\\ &{=\\eta_{\\mathrm{shous}}\\left(-\\left(\\frac{e^{\\eta_{\\mathrm{shous}}}}{\\sum_{j\\in\\mathcal{G}}e^{j_{\\mathrm{shous}}}}\\right)^{\\prime}\\right)+(\\eta_{\\mathrm{shous}}-\\eta_{\\mathrm{shous}})\\Bigg(1-\\left(\\frac{e^{\\eta_{\\mathrm{shous}}}+e^{\\eta_{\\mathrm{shous}}}}{\\sum_{j\\in\\mathcal{G}}e^{j_{\\mathrm{shous}}}}\\right)^{\\prime}\\Bigg)}\\\\ &{\\qquad+\\eta_{\\mathrm{shous}}\\left(1-\\left(\\frac{e^{\\eta_{\\mathrm{shous}}}}{\\sum_{j\\in\\mathcal{G}}e^{j_{\\mathrm{shous}}}}\\right)^{\\prime}\\right)+(\\eta_{\\mathrm{shous}}-\\eta_{\\mathrm{shous}})\\Bigg(1-\\left(\\frac{e^{\\eta_{\\mathrm{shous}}}+e^{\\eta_{\\mathrm{shous}}}}{\\sum_{j\\in\\mathcal{G}}e^{j_{\\mathrm{shous}}}}\\right)^{\\prime}\\Bigg)}\\\\ &{\\qquad-\\eta_{\\mathrm{shous}}\\left(1-\\left(\\frac{e^{\\eta_{\\mathrm{shous}}}}{\\sum_{j\\in\\mathcal{G}}e^{j_{\\mathrm{shous}}}}\\right)^{\\prime}\\right)-(\\eta_{\\mathrm{shous}}-\\eta_{\\mathrm{shous}})\\Bigg(1-\\left(\\frac{e^{\\eta_{\\mathrm{shous}}}+e^{\\eta_{\\mathrm{shous}}}}{\\sum_{j\\in\\mathcal{G}}e^{j_{\\mathrm{shous}}}}\\right)^{\\prime}\\Bigg)}\\\\ &{\\qquad-\\eta_{\\mathrm{shous}}\\Bigg(1-\\left(\\frac{e^{\\eta_{\\mathrm{shous}}}}{\\sum_{j\\in\\mathcal{G}}e^{j_{\\mathrm{shous}}}}\\right)^{\\prime}\\Bigg)+(\\eta_{\\mathrm{shous}}-\\eta_{\\mathrm{shous}})\\Bigg(1-\\left(\\frac{e^{\\eta_{\\mathrm{shous}}}+e^{\\eta_{\\mathrm{shous}}}}{\\sum_{j\\in\\mathcal{G}}e^{j_{\\mathrm{shous}}}}\\right)^{\\prime}\\Bigg)}\\\\ &{\\qquad=\\eta_{\\mathrm{shous}}-\\eta\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "Therefore, we only need to lower bound the conditional regret of hypothesis $h$ satisfying $y_{\\mathrm{{max}}}=h_{\\mathrm{{max}}}$ . Since $c(x,y)\\,=\\,\\dot{1}_{\\mathtt{g}(x)\\neq y}$ , we have $p_{y_{\\mathrm{max}}}\\,\\geq\\,p_{n+1}\\,=\\,p_{\\mathsf{g}(x)}$ . Note that when $(p_{y_{\\mathrm{{max}}}}-p_{n+1})(h_{y_{\\mathrm{{max}}}}-$ $h_{n+1})\\,>\\,0$ , we have $\\Delta\\mathcal{C}_{\\mathrm{L}_{\\mathrm{def}},\\mathcal{H}}(h,x)\\,=\\,\\mathrm{max}\\{p_{y_{\\mathrm{max}}},p_{n+1}\\}\\,-\\,p_{\\mathsf{h}}\\,=\\,0$ . When $h_{y_{\\mathrm{max}}}-h_{n+1}\\leq0$ , we define a new hypothesis $h_{\\mu}$ such that $h_{\\mu}(x,y)\\,=\\,\\left\\{\\log\\bigl(e^{\\iota_{y_{\\mathrm{max}}}}-\\mu\\bigr)\\right.\\qquad}\\\\ {\\qquad\\left.h(x,y)\\right.}$ $\\left(\\log\\left(e^{h_{n+1}}+\\mu\\right)\\right.$ y = n + 1 , where ehymax \u2212 $y=y_{\\mathrm{max}}$ otherwise. $e^{h_{n+1}}\\leq\\mu\\leq\\,e^{h_{y_{\\mathrm{max}}}}$ . Then, we can lower bound the conditional regret of hypothesis $h$ by using $\\Delta\\mathcal{C}_{\\mathrm{L_{RL2D}},\\mathcal{H}}(h,x)\\ge\\mathcal{C}_{\\mathrm{L_{RL2D}}}(h)-\\mathcal{C}_{\\mathrm{L_{RL2D}}}^{*}(h_{\\mu})$ for any $e^{h_{y\\mathrm{max}}}-e^{h_{n+1}}\\overset{\\smile}{\\leq}\\mu\\leq e^{h_{y\\mathrm{max}}^{\\star}}$ : ", "page_idx": 26}, {"type": "text", "text": "$\\Delta\\mathcal{C}_{\\mathrm{L_{RL2D}},\\mathcal{H}}(h,x)$ ", "page_idx": 26}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\mathbb{E}_{t}\\sim\\operatorname*{max}_{0}\\theta(x,t)}&{=\\operatorname*{max}_{0}\\theta\\left(x_{0}(\\theta+\\sqrt{\\frac{\\theta^{\\star}(x_{0}-x_{0})}{\\sum_{p=0}^{N}D_{p}(x,t)}})\\right)}\\\\ &{\\ t\\frac{\\sqrt{D}}{\\theta^{\\star}},\\quad\\operatorname*{max}_{0\\le t\\le0}\\theta\\left(\\operatorname*{max}_{0}\\theta\\left(1-\\left(\\frac{\\theta^{\\star}(x_{0}-x_{0}^{\\star})}{\\sum_{p=0}^{N}D_{p}(x,t)}\\right)\\right)+\\left(\\theta_{\\operatorname*{max}}-\\theta_{\\operatorname*{max}}\\right)\\left(1-\\left(\\frac{\\theta^{\\star}(x_{0}-x_{0}^{\\star})}{\\sum_{p=0}^{N}D_{p}(x,t)}\\right)\\right)\\right)}\\\\ &{\\quad\\times\\operatorname*{max}_{0\\le t\\le0}\\theta\\left(1-\\left(\\theta^{\\star}(x_{0}+x_{0}^{\\star})\\right)\\right)}\\\\ &{=\\operatorname*{max}_{0}\\left(1-\\left(\\frac{\\theta^{\\star}(x_{0}+x_{0}^{\\star})}{\\sum_{p=0}^{N}D_{p}(x,t)}\\right)-\\left(\\theta_{\\operatorname*{max}}-\\theta_{\\operatorname*{max}}\\right)\\left(1-\\left(\\frac{\\theta^{\\star}(x_{0}+x_{0}^{\\star})}{\\sum_{p=0}^{N}D_{p}(x,t)}\\right)\\right)^{\\top}\\right.}\\\\ &{\\quad-\\left.\\gamma\\Theta_{\\theta}\\left(1-\\frac{\\theta^{\\star}(x_{0}+x_{0}^{\\star})}{\\sum_{p=0}^{N}D_{p}(x,t)}\\right)\\right)-\\left(\\theta_{\\operatorname*{max}}-\\theta_{\\operatorname*{max}}\\right)\\left(1-\\left(\\frac{\\theta^{\\star}(x_{0}-x_{0}^{\\star})}{\\sum_{p=0}^{N}D_{p}(x,t)}\\right)\\right)}\\\\ &{\\ t\\frac{\\sqrt{D}}{\\theta^{\\star}},\\quad\\operatorname*{max}_{0\\le t\\le0}\\theta\\left(1-\\left(\\frac{\\theta^{\\star}(x_{0}-x_{0}^{\\star})}{\\sum_{p=0}^{N}D_{p}(x,t)}\\right)\\right),\\quad\\gamma\\Theta_{\\\n$$", "text_format": "latex", "page_idx": 26}, {"type": "text", "text": "By differentiating with respect to $\\mu$ , we obtain that ", "page_idx": 26}, {"type": "equation", "text": "$$\n\\mu=\\frac{\\left(p_{n+1}-\\left(p_{y_{\\operatorname*{max}}}-q_{y_{\\operatorname*{max}}}\\right)\\right)^{\\frac{1}{q-1}}}{\\left(q_{y_{\\operatorname*{max}}}\\right)^{\\frac{1}{q-1}}+\\left(p_{n+1}-\\left(p_{y_{\\operatorname*{max}}}-q_{y_{\\operatorname*{max}}}\\right)\\right)^{\\frac{1}{q-1}}}e^{h_{n+1}}\n$$", "text_format": "latex", "page_idx": 26}, {"type": "text", "text": "achieves the maximum. Plugging it into the expression, we have ", "page_idx": 26}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\Delta\\mathcal{C}_{\\mathrm{Leax},2\\nu}(h,x)}\\\\ &{\\geq\\frac{1}{q}\\Bigg(-Q_{y_{\\mathrm{max}}}\\Bigg(\\frac{e^{h_{\\mathrm{max}}}}{\\sum_{y^{\\ast}\\in\\overline{{\\mathbb{V}}}}e^{h_{y^{\\ast}}}}\\Bigg)^{q}-\\left(p_{n+1}-\\left(p_{y_{\\mathrm{max}}}-q_{y_{\\mathrm{max}}}\\right)\\right)\\Bigg(\\frac{e^{h_{n+1}}}{\\sum_{y^{\\ast}\\in\\overline{{\\mathbb{V}}}}e^{h_{y^{\\ast}}}}\\Bigg)^{q}}\\\\ &{\\qquad+\\,q_{y_{\\mathrm{max}}}\\Bigg[\\frac{\\left[e^{h_{\\mathrm{max}}}+e^{h_{n+1}}\\right]\\left(p_{n+1}-\\left(p_{y_{\\mathrm{max}}}-q_{y_{\\mathrm{max}}}\\right)\\right)^{\\frac{1}{q-1}}}{\\sum_{y^{\\ast}\\in\\overline{{\\mathbb{V}}}}e^{h_{y^{\\ast}}}\\bigg[q_{y_{\\mathrm{max}}}^{\\frac{1}{q_{\\mathrm{max}}}}+\\left(p_{n+1}-\\left(p_{y_{\\mathrm{max}}}-q_{y_{\\mathrm{max}}}\\right)\\right)^{\\frac{1}{q-1}}\\bigg]}\\Bigg]^{q}}\\\\ &{\\qquad+\\left(p_{n+1}-\\left(p_{y_{\\mathrm{max}}}-q_{y_{\\mathrm{max}}}\\right)\\right)\\Bigg[\\frac{\\left[e^{h_{\\mathrm{max}}}+e^{h_{n+1}}\\right]q_{y_{\\mathrm{max}}}^{\\frac{1}{q-1}}}{\\sum_{y^{\\ast}\\in\\overline{{\\mathbb{V}}}}e^{h_{y^{\\ast}}}\\left[q_{y_{\\mathrm{max}}}^{\\frac{1}{q-1}}+\\left(p_{n+1}-\\left(p_{y_{\\mathrm{max}}}-q_{y_{\\mathrm{max}}}\\right)\\right)^{\\frac{1}{q-1}}\\right]}\\Bigg]^{q}\\Bigg)}\\end{array}\n$$", "text_format": "latex", "page_idx": 26}, {"type": "text", "text": "This can be further lower bounded by taking the minimum over $h\\in\\mathcal{H}$ , where the minimum is attained when $e^{h_{n+1}}=e^{h_{y_{\\mathrm{max}}}}=e^{h_{y}}$ for all $y\\in\\mathcal{Y}$ . Therefore, ", "page_idx": 27}, {"type": "equation", "text": "$$\n\\Delta\\mathcal{C}_{\\mathrm{L_{RL2D}},\\mathcal{H}}(h,x)\\geq\\frac{2}{(n+1)^{q}}\\left(\\left[\\frac{q_{y_{\\operatorname*{max}}}^{\\frac{1}{1-q}}+(p_{n+1}-(p_{y_{\\operatorname*{max}}}-q_{y_{\\operatorname*{max}}}))^{\\frac{1}{1-q}}}{2}\\right]^{1-q}-\\frac{p_{n+1}-p_{y_{\\operatorname*{max}}}}{2}\\right)\n$$", "text_format": "latex", "page_idx": 27}, {"type": "equation", "text": "$$\n\\begin{array}{r l r}{\\lefteqn{\\geq\\frac{1}{2(n+1)^{q}}(p_{y_{\\operatorname*{max}}}-p_{n+1})^{2}}}\\\\ &{}&{\\displaystyle(q_{y_{\\operatorname*{max}}}+(p_{n+1}-(p_{y_{\\operatorname*{max}}}-q_{y_{\\operatorname*{max}}}))\\leq1\\mathrm{~and~by~analyzing~the~Taylor~expansion})}\\\\ &{}&{\\displaystyle=\\frac{1}{2(n+1)^{q}}(\\Delta\\mathcal{C}_{\\mathrm{L_{def}},\\mathcal{K}}(h,x))^{2}}&{(p_{y_{\\operatorname*{max}}}\\geq p_{n+1}\\mathrm{~and~}h_{y_{\\operatorname*{max}}}\\leq h_{n+1})}\\end{array}\n$$", "text_format": "latex", "page_idx": 27}, {"type": "text", "text": "This proves the inequality (8). In the case where $\\mathsf{g}(x)=y_{\\mathrm{max}}$ , we have $p_{n+1}=p_{y_{\\mathrm{max}}}$ . By Lemma B.2, the conditional regret of the deferral loss can be expressed as $\\Delta\\mathcal{C}_{\\mathrm{L}_{\\mathrm{def}},\\mathcal{H}}(h,x)=\\dot{p}_{n+1}-p_{\\mathsf{h}}$ . If $\\mathsf{h}(x)=$ $n\\!+\\!1$ , then we have $\\Delta\\mathcal{C}_{\\mathrm{L}_{\\mathrm{def}},\\mathcal{H}}(h,x)=0$ . Otherwise, when $\\mathsf{h}(x)\\neq\\bar{n}+1$ , we can proceed in the similar way as above, by defining a new hypothesis $h_{\\mu}$ such that $h_{\\mu}(x,y)={\\left\\{\\begin{array}{l l}{\\log\\!{\\left(e^{h_{n+1}}+\\mu\\right)}}&{y={\\mathsf{h}}(x)}\\\\ {\\log\\!{\\left(e^{h_{{\\mathsf{h}}(x)}}-\\mu\\right)}}&{y=n+1}\\end{array}\\right.}$ . \u23aa\u23aah(x,y) otherwise Then, we can lower bound the conditional regret of $\\mathsf{L}_{\\mathrm{RL2D}}$ by using $\\Delta\\mathcal{C}_{\\mathrm{LRL2D},\\mathcal{K}}(h,x)\\geq\\mathcal{C}_{\\mathrm{LRL2D}}(h)-$ $\\mathcal{C}_{\\mathrm{L_{\\mathrm{RL2D}}}}^{*}(h_{\\mu})$ a, lbityy  a(p8p) laysi nwg etlhl.e  sBay mTe hdeeorrievamt ioBn. 1a, s waeb ocvoem, pmleotdeu tlho er epprloaocfi.ng $y_{\\mathrm{max}}$ with $\\mathsf{h}(x)$ . This leads ", "page_idx": 27}, {"type": "text", "text": "C Proof of Theorem 5.1 ", "text_level": 1, "page_idx": 27}, {"type": "text", "text": "Theorem 5.1. Assume that there exists a zero error solution $h^{*}\\in\\mathcal{H}$ with $\\mathcal{E}_{\\ell_{0-1}}(h^{*})=0$ and $\\mathcal{H}$ is closed under scaling. Assume that $\\textstyle\\operatorname*{lim}_{t\\to1}\\Psi(t)=0$ . Then, the minimizability gap of comp-sum loss $\\ell_{\\mathrm{comp}}$ vanishes: $\\mathcal{M}_{\\ell_{\\mathrm{comp}}}(\\mathcal{H})=0$ . ", "page_idx": 27}, {"type": "text", "text": "Proof. By definition and the Lebesgue dominated convergence theorem, we have ", "page_idx": 27}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathcal{N}_{\\ell_{\\mathrm{comp}}}(\\mathcal{H})\\leq\\mathcal{E}_{\\ell_{\\mathrm{comp}}}^{*}(\\mathcal{H})\\leq\\underset{\\alpha\\rightarrow+\\infty}{\\operatorname*{lim}}\\mathbb{E}\\bigg[\\Psi\\bigg(\\frac{e^{\\alpha h^{*}(x,y)}}{\\sum_{y^{\\prime}\\in\\mathcal{Y}}e^{\\alpha h^{*}(x,y^{\\prime})}}\\bigg)\\bigg]=0.}\\end{array}\n$$", "text_format": "latex", "page_idx": 27}, {"type": "text", "text": "This completes the proof. ", "page_idx": 27}, {"type": "text", "text": "D Future work ", "text_level": 1, "page_idx": 27}, {"type": "text", "text": "While we presented a comprehensive study of surrogate loss functions for learning to defer, our work focused on the standard single-expert and single-stage setting, aligning with previous work [Mozannar et al., 2023]. However, an interesting direction is to extend our approach to multi-expert [Verma et al., 2023] and two-stage settings [Mao et al., 2023a], which we have left for future work. ", "page_idx": 27}, {"type": "text", "text": "NeurIPS Paper Checklist ", "text_level": 1, "page_idx": 28}, {"type": "text", "text": "1. Claims ", "text_level": 1, "page_idx": 28}, {"type": "text", "text": "Question: Do the main claims made in the abstract and introduction accurately reflect the paper\u2019s contributions and scope? ", "page_idx": 28}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 28}, {"type": "text", "text": "Justification: See Section 1. ", "page_idx": 28}, {"type": "text", "text": "Guidelines: ", "page_idx": 28}, {"type": "text", "text": "\u2022 The answer NA means that the abstract and introduction do not include the claims made in the paper.   \n\u2022 The abstract and/or introduction should clearly state the claims made, including the contributions made in the paper and important assumptions and limitations. A No or NA answer to this question will not be perceived well by the reviewers.   \n\u2022 The claims made should match theoretical and experimental results, and reflect how much the results can be expected to generalize to other settings.   \n\u2022 It is fine to include aspirational goals as motivation as long as it is clear that these goals are not attained by the paper. ", "page_idx": 28}, {"type": "text", "text": "2. Limitations ", "text_level": 1, "page_idx": 28}, {"type": "text", "text": "Question: Does the paper discuss the limitations of the work performed by the authors? ", "page_idx": 28}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 28}, {"type": "text", "text": "Justification: See Appendix D. ", "page_idx": 28}, {"type": "text", "text": "Guidelines: ", "page_idx": 28}, {"type": "text", "text": "\u2022 The answer NA means that the paper has no limitation while the answer No means that the paper has limitations, but those are not discussed in the paper.   \n\u2022 The authors are encouraged to create a separate \"Limitations\" section in their paper.   \n\u2022 The paper should point out any strong assumptions and how robust the results are to violations of these assumptions (e.g., independence assumptions, noiseless settings, model well-specification, asymptotic approximations only holding locally). The authors should reflect on how these assumptions might be violated in practice and what the implications would be.   \n\u2022 The authors should reflect on the scope of the claims made, e.g., if the approach was only tested on a few datasets or with a few runs. In general, empirical results often depend on implicit assumptions, which should be articulated.   \n\u2022 The authors should reflect on the factors that influence the performance of the approach. For example, a facial recognition algorithm may perform poorly when image resolution is low or images are taken in low lighting. Or a speech-to-text system might not be used reliably to provide closed captions for online lectures because it fails to handle technical jargon.   \n\u2022 The authors should discuss the computational efficiency of the proposed algorithms and how they scale with dataset size.   \n\u2022 If applicable, the authors should discuss possible limitations of their approach to address problems of privacy and fairness.   \n\u2022 While the authors might fear that complete honesty about limitations might be used by reviewers as grounds for rejection, a worse outcome might be that reviewers discover limitations that aren\u2019t acknowledged in the paper. The authors should use their best judgment and recognize that individual actions in favor of transparency play an important role in developing norms that preserve the integrity of the community. Reviewers will be specifically instructed to not penalize honesty concerning limitations. ", "page_idx": 28}, {"type": "text", "text": "3. Theory Assumptions and Proofs ", "text_level": 1, "page_idx": 28}, {"type": "text", "text": "Question: For each theoretical result, does the paper provide the full set of assumptions and a complete (and correct) proof? ", "page_idx": 28}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 28}, {"type": "text", "text": "Justification: See Section 4, Section 5, Appendix A, Appendix B and Appendix C. Guidelines: ", "page_idx": 29}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include theoretical results.   \n\u2022 All the theorems, formulas, and proofs in the paper should be numbered and crossreferenced.   \n\u2022 All assumptions should be clearly stated or referenced in the statement of any theorems.   \n\u2022 The proofs can either appear in the main paper or the supplemental material, but if they appear in the supplemental material, the authors are encouraged to provide a short proof sketch to provide intuition.   \n\u2022 Inversely, any informal proof provided in the core of the paper should be complemented by formal proofs provided in appendix or supplemental material.   \n\u2022 Theorems and Lemmas that the proof relies upon should be properly referenced. ", "page_idx": 29}, {"type": "text", "text": "4. Experimental Result Reproducibility ", "text_level": 1, "page_idx": 29}, {"type": "text", "text": "Question: Does the paper fully disclose all the information needed to reproduce the main experimental results of the paper to the extent that it affects the main claims and/or conclusions of the paper (regardless of whether the code and data are provided or not)? ", "page_idx": 29}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 29}, {"type": "text", "text": "Justification: See Section 6. ", "page_idx": 29}, {"type": "text", "text": "Guidelines: ", "page_idx": 29}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 If the paper includes experiments, a No answer to this question will not be perceived well by the reviewers: Making the paper reproducible is important, regardless of whether the code and data are provided or not.   \n\u2022 If the contribution is a dataset and/or model, the authors should describe the steps taken to make their results reproducible or verifiable.   \n\u2022 Depending on the contribution, reproducibility can be accomplished in various ways. For example, if the contribution is a novel architecture, describing the architecture fully might suffice, or if the contribution is a specific model and empirical evaluation, it may be necessary to either make it possible for others to replicate the model with the same dataset, or provide access to the model. In general. releasing code and data is often one good way to accomplish this, but reproducibility can also be provided via detailed instructions for how to replicate the results, access to a hosted model (e.g., in the case of a large language model), releasing of a model checkpoint, or other means that are appropriate to the research performed.   \n\u2022 While NeurIPS does not require releasing code, the conference does require all submissions to provide some reasonable avenue for reproducibility, which may depend on the nature of the contribution. For example (a) If the contribution is primarily a new algorithm, the paper should make it clear how to reproduce that algorithm. (b) If the contribution is primarily a new model architecture, the paper should describe the architecture clearly and fully. (c) If the contribution is a new model (e.g., a large language model), then there should either be a way to access this model for reproducing the results or a way to reproduce the model (e.g., with an open-source dataset or instructions for how to construct the dataset). (d) We recognize that reproducibility may be tricky in some cases, in which case authors are welcome to describe the particular way they provide for reproducibility. In the case of closed-source models, it may be that access to the model is limited in some way (e.g., to registered users), but it should be possible for other researchers to have some path to reproducing or verifying the results. ", "page_idx": 29}, {"type": "text", "text": "5. Open access to data and code ", "text_level": 1, "page_idx": 29}, {"type": "text", "text": "Question: Does the paper provide open access to the data and code, with sufficient instructions to faithfully reproduce the main experimental results, as described in supplemental material? ", "page_idx": 29}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 30}, {"type": "text", "text": "Justification: See Section 6. Guidelines: ", "page_idx": 30}, {"type": "text", "text": "\u2022 The answer NA means that paper does not include experiments requiring code.   \n\u2022 Please see the NeurIPS code and data submission guidelines (https://nips.cc/ public/guides/CodeSubmissionPolicy) for more details.   \n\u2022 While we encourage the release of code and data, we understand that this might not be possible, so \u201cNo\u201d is an acceptable answer. Papers cannot be rejected simply for not including code, unless this is central to the contribution (e.g., for a new open-source benchmark).   \n\u2022 The instructions should contain the exact command and environment needed to run to reproduce the results. See the NeurIPS code and data submission guidelines (https: //nips.cc/public/guides/CodeSubmissionPolicy) for more details.   \n\u2022 The authors should provide instructions on data access and preparation, including how to access the raw data, preprocessed data, intermediate data, and generated data, etc.   \n\u2022 The authors should provide scripts to reproduce all experimental results for the new proposed method and baselines. If only a subset of experiments are reproducible, they should state which ones are omitted from the script and why.   \n\u2022 At submission time, to preserve anonymity, the authors should release anonymized versions (if applicable).   \n\u2022 Providing as much information as possible in supplemental material (appended to the paper) is recommended, but including URLs to data and code is permitted. ", "page_idx": 30}, {"type": "text", "text": "6. Experimental Setting/Details ", "text_level": 1, "page_idx": 30}, {"type": "text", "text": "Question: Does the paper specify all the training and test details (e.g., data splits, hyperparameters, how they were chosen, type of optimizer, etc.) necessary to understand the results? ", "page_idx": 30}, {"type": "text", "text": "Answer: [Yes]   \nJustification: See Section 6. Guidelines: ", "page_idx": 30}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments. \u2022 The experimental setting should be presented in the core of the paper to a level of detail that is necessary to appreciate the results and make sense of them. \u2022 The full details can be provided either with the code, in appendix, or as supplemental material. ", "page_idx": 30}, {"type": "text", "text": "7. Experiment Statistical Significance ", "text_level": 1, "page_idx": 30}, {"type": "text", "text": "Question: Does the paper report error bars suitably and correctly defined or other appropriate information about the statistical significance of the experiments? ", "page_idx": 30}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 30}, {"type": "text", "text": "Justification: See Table 3. Guidelines: ", "page_idx": 30}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 The authors should answer \"Yes\" if the results are accompanied by error bars, confidence intervals, or statistical significance tests, at least for the experiments that support the main claims of the paper.   \n\u2022 The factors of variability that the error bars are capturing should be clearly stated (for example, train/test split, initialization, random drawing of some parameter, or overall run with given experimental conditions).   \n\u2022 The method for calculating the error bars should be explained (closed form formula, call to a library function, bootstrap, etc.)   \n\u2022 The assumptions made should be given (e.g., Normally distributed errors).   \n\u2022 It should be clear whether the error bar is the standard deviation or the standard error of the mean.   \n\u2022 It is OK to report 1-sigma error bars, but one should state it. The authors should preferably report a 2-sigma error bar than state that they have a $96\\%$ CI, if the hypothesis of Normality of errors is not verified.   \n\u2022 For asymmetric distributions, the authors should be careful not to show in tables or figures symmetric error bars that would yield results that are out of range (e.g. negative error rates).   \n\u2022 If error bars are reported in tables or plots, The authors should explain in the text how they were calculated and reference the corresponding figures or tables in the text. ", "page_idx": 30}, {"type": "text", "text": "", "page_idx": 31}, {"type": "text", "text": "8. Experiments Compute Resources ", "text_level": 1, "page_idx": 31}, {"type": "text", "text": "Question: For each experiment, does the paper provide sufficient information on the computer resources (type of compute workers, memory, time of execution) needed to reproduce the experiments? ", "page_idx": 31}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 31}, {"type": "text", "text": "Justification: For each model training, we use an Nvidia A100 GPU. ", "page_idx": 31}, {"type": "text", "text": "Guidelines: ", "page_idx": 31}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 The paper should indicate the type of compute workers CPU or GPU, internal cluster, or cloud provider, including relevant memory and storage.   \n\u2022 The paper should provide the amount of compute required for each of the individual experimental runs as well as estimate the total compute.   \n\u2022 The paper should disclose whether the full research project required more compute than the experiments reported in the paper (e.g., preliminary or failed experiments that didn\u2019t make it into the paper). ", "page_idx": 31}, {"type": "text", "text": "9. Code Of Ethics ", "text_level": 1, "page_idx": 31}, {"type": "text", "text": "Question: Does the research conducted in the paper conform, in every respect, with the NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines? ", "page_idx": 31}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 31}, {"type": "text", "text": "Justification: The authors have reviewed the NeurIPS Code of Ethics. ", "page_idx": 31}, {"type": "text", "text": "Guidelines: ", "page_idx": 31}, {"type": "text", "text": "\u2022 The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics.   \n\u2022 If the authors answer No, they should explain the special circumstances that require a deviation from the Code of Ethics.   \n\u2022 The authors should make sure to preserve anonymity (e.g., if there is a special consideration due to laws or regulations in their jurisdiction). ", "page_idx": 31}, {"type": "text", "text": "10. Broader Impacts ", "text_level": 1, "page_idx": 31}, {"type": "text", "text": "Question: Does the paper discuss both potential positive societal impacts and negative societal impacts of the work performed? ", "page_idx": 31}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 31}, {"type": "text", "text": "Justification: The machine learning community has started to address the fairness implications of involving downstream decision-makers. This represents a broader impact for any learning to defer (L2D) methods. ", "page_idx": 31}, {"type": "text", "text": "Guidelines: ", "page_idx": 31}, {"type": "text", "text": "\u2022 The answer NA means that there is no societal impact of the work performed.   \n\u2022 If the authors answer NA or No, they should explain why their work has no societal impact or why the paper does not address societal impact.   \n\u2022 Examples of negative societal impacts include potential malicious or unintended uses (e.g., disinformation, generating fake profiles, surveillance), fairness considerations (e.g., deployment of technologies that could make decisions that unfairly impact specific groups), privacy considerations, and security considerations.   \n\u2022 The conference expects that many papers will be foundational research and not tied to particular applications, let alone deployments. However, if there is a direct path to any negative applications, the authors should point it out. For example, it is legitimate to point out that an improvement in the quality of generative models could be used to generate deepfakes for disinformation. On the other hand, it is not needed to point out that a generic algorithm for optimizing neural networks could enable people to train models that generate Deepfakes faster.   \n\u2022 The authors should consider possible harms that could arise when the technology is being used as intended and functioning correctly, harms that could arise when the technology is being used as intended but gives incorrect results, and harms following from (intentional or unintentional) misuse of the technology.   \n\u2022 If there are negative societal impacts, the authors could also discuss possible mitigation strategies (e.g., gated release of models, providing defenses in addition to attacks, mechanisms for monitoring misuse, mechanisms to monitor how a system learns from feedback over time, improving the efficiency and accessibility of ML). ", "page_idx": 31}, {"type": "text", "text": "", "page_idx": 32}, {"type": "text", "text": "11. Safeguards ", "text_level": 1, "page_idx": 32}, {"type": "text", "text": "Question: Does the paper describe safeguards that have been put in place for responsible release of data or models that have a high risk for misuse (e.g., pretrained language models, image generators, or scraped datasets)? ", "page_idx": 32}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 32}, {"type": "text", "text": "Justification: The paper poses no such risks. ", "page_idx": 32}, {"type": "text", "text": "Guidelines: ", "page_idx": 32}, {"type": "text", "text": "\u2022 The answer NA means that the paper poses no such risks.   \n\u2022 Released models that have a high risk for misuse or dual-use should be released with necessary safeguards to allow for controlled use of the model, for example by requiring that users adhere to usage guidelines or restrictions to access the model or implementing safety filters.   \n\u2022 Datasets that have been scraped from the Internet could pose safety risks. The authors should describe how they avoided releasing unsafe images.   \n\u2022 We recognize that providing effective safeguards is challenging, and many papers do not require this, but we encourage authors to take this into account and make a best faith effort. ", "page_idx": 32}, {"type": "text", "text": "12. Licenses for existing assets ", "text_level": 1, "page_idx": 32}, {"type": "text", "text": "Question: Are the creators or original owners of assets (e.g., code, data, models), used in the paper, properly credited and are the license and terms of use explicitly mentioned and properly respected? ", "page_idx": 32}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 32}, {"type": "text", "text": "Justification: See Section 6. ", "page_idx": 32}, {"type": "text", "text": "Guidelines: ", "page_idx": 32}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not use existing assets.   \n\u2022 The authors should cite the original paper that produced the code package or dataset.   \n\u2022 The authors should state which version of the asset is used and, if possible, include a URL.   \n\u2022 The name of the license (e.g., CC-BY 4.0) should be included for each asset.   \n\u2022 For scraped data from a particular source (e.g., website), the copyright and terms of service of that source should be provided.   \n\u2022 If assets are released, the license, copyright information, and terms of use in the package should be provided. For popular datasets, paperswithcode.com/datasets has curated licenses for some datasets. Their licensing guide can help determine the license of a dataset.   \n\u2022 For existing datasets that are re-packaged, both the original license and the license of the derived asset (if it has changed) should be provided. ", "page_idx": 32}, {"type": "text", "text": "\u2022 If this information is not available online, the authors are encouraged to reach out to the asset\u2019s creators. ", "page_idx": 33}, {"type": "text", "text": "13. New Assets ", "text_level": 1, "page_idx": 33}, {"type": "text", "text": "Question: Are new assets introduced in the paper well documented and is the documentation provided alongside the assets? ", "page_idx": 33}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 33}, {"type": "text", "text": "Justification: The paper does not release new assets. ", "page_idx": 33}, {"type": "text", "text": "Guidelines: ", "page_idx": 33}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not release new assets.   \n\u2022 Researchers should communicate the details of the dataset/code/model as part of their submissions via structured templates. This includes details about training, license, limitations, etc.   \n\u2022 The paper should discuss whether and how consent was obtained from people whose asset is used.   \n\u2022 At submission time, remember to anonymize your assets (if applicable). You can either create an anonymized URL or include an anonymized zip file. ", "page_idx": 33}, {"type": "text", "text": "14. Crowdsourcing and Research with Human Subjects ", "text_level": 1, "page_idx": 33}, {"type": "text", "text": "Question: For crowdsourcing experiments and research with human subjects, does the paper include the full text of instructions given to participants and screenshots, if applicable, as well as details about compensation (if any)? ", "page_idx": 33}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 33}, {"type": "text", "text": "Justification: The paper does not involve crowdsourcing nor research with human subjects. Guidelines: ", "page_idx": 33}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u2022 Including this information in the supplemental material is fine, but if the main contribution of the paper involves human subjects, then as much detail as possible should be included in the main paper.   \n\u2022 According to the NeurIPS Code of Ethics, workers involved in data collection, curation, or other labor should be paid at least the minimum wage in the country of the data collector. ", "page_idx": 33}, {"type": "text", "text": "15. Institutional Review Board (IRB) Approvals or Equivalent for Research with Human Subjects ", "text_level": 1, "page_idx": 33}, {"type": "text", "text": "Question: Does the paper describe potential risks incurred by study participants, whether such risks were disclosed to the subjects, and whether Institutional Review Board (IRB) approvals (or an equivalent approval/review based on the requirements of your country or institution) were obtained? ", "page_idx": 33}, {"type": "text", "text": "Answer: [NA] ", "text_level": 1, "page_idx": 33}, {"type": "text", "text": "Justification: The paper does not involve crowdsourcing nor research with human subjects. Guidelines: ", "page_idx": 33}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u2022 Depending on the country in which research is conducted, IRB approval (or equivalent) may be required for any human subjects research. If you obtained IRB approval, you should clearly state this in the paper.   \n\u2022 We recognize that the procedures for this may vary significantly between institutions and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the guidelines for their institution.   \n\u2022 For initial submissions, do not include any information that would break anonymity (if applicable), such as the institution conducting the review. ", "page_idx": 33}]