[{"figure_path": "R8mfn3rHd5/figures/figures_1_1.jpg", "caption": "Figure 1: Motivations of RealCompo. (a) and (c) The realism and aesthetic quality of generated images become poor as more layout is incorporated. (b) Even if layout is incorporated only in the early denoising stages, the control of text alone still fails to alleviate the poor realism issue. More results are shown in Appendix B.", "description": "This figure demonstrates the trade-off between realism and compositionality in text-to-image generation.  Subfigure (a) and (c) show that incorporating more layout information into the generation process leads to a decline in the realism and aesthetic quality of the generated images. Subfigure (b) shows that even if layout is only incorporated in the early stages of the generation process, the generated images still suffer from a lack of realism when solely controlled by text in the later stages. This illustrates the limitations of current text-to-image models in handling compositional generation and motivates the proposed RealCompo framework.", "section": "1 Introduction"}, {"figure_path": "R8mfn3rHd5/figures/figures_3_1.jpg", "caption": "Figure 2: An overview of RealCompo framework for text-to-image generation. We first use LLMs or transfer function to obtain the corresponding layout. Next, the balancer dynamically updates the influence of two models, which enhances realism by focusing on contours and colors in the fidelity branch, and improves compositionality by manipulating object positions in the spatial-aware branch.", "description": "This figure illustrates the RealCompo framework, a text-to-image generation method.  It starts with a text prompt that's processed by LLMs (Large Language Models) to generate a scene layout.  The core of the framework is a dynamic balancer that combines two types of diffusion models: a fidelity-focused model (like Stable Diffusion) prioritizing realism and a spatial-aware model (like GLIGEN) focusing on composition. The balancer adjusts the influence of each model during the denoising process using cross-attention maps, achieving a balance between realism and compositionality. The resulting image benefits from both models' strengths: realistic details from the fidelity branch and accurate object placement from the spatial branch.", "section": "3 Method"}, {"figure_path": "R8mfn3rHd5/figures/figures_5_1.jpg", "caption": "Figure 3: Extend RealCompo to keypoint- and segmentation-based image generation.", "description": "This figure shows example images generated by extending the RealCompo framework to handle keypoint and segmentation maps as spatial-aware conditions in addition to layout.  The top row shows a prompt about a girl dancing, along with the keypoint map input, the ControlNet output, and the RealCompo output.  The bottom row shows the same for another prompt involving a group of four friends. The middle row shows an example relating to a prompt involving astronauts on the moon.  The improved realism and compositionality of RealCompo are highlighted by comparing its output with the results from SDXL and ControlNet.", "section": "3 Method"}, {"figure_path": "R8mfn3rHd5/figures/figures_5_2.jpg", "caption": "Figure 4: RealCompo constructed on ControlNet.", "description": "This figure illustrates the architecture of RealCompo, which uses ControlNet to incorporate spatial-aware conditions into a text-to-image diffusion model. ControlNet is shown as a separate block within the overall architecture, receiving spatial-aware information (such as layout, keypoints, or segmentation maps) as input. The output of ControlNet is combined with the output of the fidelity-aware (T2I) branch using a novel balancer in RealCompo to produce the final balanced noise used to generate the image.  The figure shows how the fidelity and spatial-aware branches of RealCompo are combined using ControlNet, highlighting the key components and their interactions within the overall framework.", "section": "3 Method"}, {"figure_path": "R8mfn3rHd5/figures/figures_6_1.jpg", "caption": "Figure 5: Qualitative comparison between our RealCompo and the outstanding text-to-image model Stable Diffusion v1.5 [41], as well as the layout-to-image models, GLIGEN [27] and LMD+ [28]. Colored text denotes the advantages of RealCompo in generated images.", "description": "This figure compares the image generation results of RealCompo with three other models (Stable Diffusion v1.5, GLIGEN, and LMD+) across four different image prompts.  Each prompt depicts a scene with multiple objects and complex spatial relationships. The colored text highlights where RealCompo's output surpasses the other models in terms of realism and accurate representation of the scene, demonstrating its strength in handling compositional generation.", "section": "4.2 Main Results"}, {"figure_path": "R8mfn3rHd5/figures/figures_7_1.jpg", "caption": "Figure 6: Results of user study.", "description": "The figure shows the results of a user study comparing the realism, compositionality, and overall quality of images generated by three different methods: a T2I model, a spatial-aware model, and RealCompo.  RealCompo shows significant improvement over the other two methods across all three aspects, highlighting its success in balancing both realism and composition.", "section": "4 Experiments"}, {"figure_path": "R8mfn3rHd5/figures/figures_8_1.jpg", "caption": "Figure 8: Extend RealCompo to stylized compositional generation.", "description": "This figure demonstrates the flexibility of RealCompo in handling stylized compositional generation. Two examples are shown.  The top row uses the `Coloring Page Diffusion` style, and shows the results of four different methods: a simple layout, results from the `InstantStyle` model, results from the `LMD` model, and results from the RealCompo model. The bottom row uses the `CuteYukiMix` style, and shows the same comparison between the four methods.  RealCompo successfully integrates the style with compositionality in both examples.", "section": "4 Experiments"}, {"figure_path": "R8mfn3rHd5/figures/figures_9_1.jpg", "caption": "Figure 9: Ablation study on the significance of the dynamic balancer and qualitative comparison of RealCompo's generalization to different models. We demonstrate that dynamic balancer is important to compositional generation and RealCompo has strong generalization and generality to different models, achieving a remarkable level of both fidelity and precision in aligning with text prompts.", "description": "This figure presents an ablation study and qualitative comparison to demonstrate the importance of the dynamic balancer in RealCompo and its generalization ability across different models.  It shows that the dynamic balancer significantly improves compositional generation, and that RealCompo consistently performs well with various combinations of T2I and L2I models, exhibiting high fidelity and alignment with text prompts.", "section": "4.3 Ablation Study"}, {"figure_path": "R8mfn3rHd5/figures/figures_16_1.jpg", "caption": "Figure 1: Motivations of RealCompo. (a) and (c) The realism and aesthetic quality of generated images become poor as more layout is incorporated. (b) Even if layout is incorporated only in the early denoising stages, the control of text alone still fails to alleviate the poor realism issue. More results are shown in Appendix B.", "description": "This figure demonstrates the limitations of existing text-to-image models and layout-to-image models.  Subfigure (a) and (c) show how incorporating layout information progressively degrades the realism and aesthetic quality of generated images. Subfigure (b) shows that even limiting layout input to only the early denoising stages fails to prevent realism degradation when using only text-based control for the later stages, motivating the development of RealCompo which balances both realism and compositionality.", "section": "1 Introduction"}, {"figure_path": "R8mfn3rHd5/figures/figures_16_2.jpg", "caption": "Figure 11: A more intuitive and clearer example to showcase our discoveries and motivation, using InstanceDiffusion [53].", "description": "This figure demonstrates the impact of layout density (controlled by parameter \u03b2) and layout injection time (controlled by parameter t\u2080) on the realism of images generated using the InstanceDiffusion model.  As \u03b2 and t\u2080 increase, the realism of the generated images decreases, showing a decline in image quality and the appearance of unrealistic details.  This highlights the trade-off between realism and compositionality during the image generation process. The images show a scene with a robin, dog, cat and a waterfall. The layout describes the location of each animal, and the increase in \u03b2 and t\u2080 causes the animals to be placed less naturally and realistically within the scene.", "section": "Motivations of RealCompo"}, {"figure_path": "R8mfn3rHd5/figures/figures_17_1.jpg", "caption": "Figure 2: An overview of RealCompo framework for text-to-image generation. We first use LLMs or transfer function to obtain the corresponding layout. Next, the balancer dynamically updates the influence of two models, which enhances realism by focusing on contours and colors in the fidelity branch, and improves compositionality by manipulating object positions in the spatial-aware branch.", "description": "This figure presents a high-level overview of the RealCompo framework's architecture. It starts with a text prompt that's fed into an LLM to generate a scene layout.  Then, the core of the system is the dynamic balancer. This component integrates a fidelity-focused model (like Stable Diffusion) and a spatial-awareness model (like GLIGEN). The balancer continuously adjusts the influence of these two models during the denoising process to balance realism (handled by the fidelity model, which focuses on contours and colors) and compositionality (handled by the spatial model, that focuses on object positions). The output is a generated image.", "section": "3 Method"}, {"figure_path": "R8mfn3rHd5/figures/figures_20_1.jpg", "caption": "Figure 13: Changes of gradient magnitude in Eq. 7 across all denoising process for the T2I and L2I models of RealCompo v3 and v4.", "description": "This figure visualizes the gradient magnitude changes during the denoising process for two versions of RealCompo (v3 and v4) using both text-to-image (T2I) and layout-to-image (L2I) models.  It shows how the gradient magnitudes fluctuate differently across denoising steps for each model and combination.  These variations likely stem from differences in the models' functionalities and their interplay during the generation process.  The fluctuating gradients in the early stages of RealCompo v4 suggest less stable balancing between the model components than v3.", "section": "C.4 Gradient Analysis"}, {"figure_path": "R8mfn3rHd5/figures/figures_21_1.jpg", "caption": "Figure 14: More generation results about layout-based RealCompo.", "description": "This figure shows a comparison of image generation results using different models: SD1.5, GLIGEN, LMD+, and the proposed RealCompo. Each row shows a different prompt and the corresponding generated images. The layout is provided to the models to guide object arrangement. The figure demonstrates RealCompo's improved realism and compositionality compared to the other methods. ", "section": "D More Generation Results"}, {"figure_path": "R8mfn3rHd5/figures/figures_22_1.jpg", "caption": "Figure 3: Extend RealCompo to keypoint- and segmentation-based image generation.", "description": "This figure shows three examples of images generated using RealCompo with different spatial-aware conditions. The first row shows a keypoint-based image generation of Leonardo from Teenage Mutant Ninja Turtles in a cinematic action pose, demonstrating that RealCompo successfully incorporates keypoint information to generate a realistic and dynamic image. The second row shows an image generation of Elsa and Anna from Frozen, again showing that RealCompo successfully incorporates keypoint information to generate a realistic image consistent with the prompt. The third row shows an image generation of two astronauts on the moon, showcasing the ability of RealCompo to handle complex scenes and multiple objects, accurately positioning the objects based on the prompt. Overall, this figure highlights the versatility and effectiveness of RealCompo in generating high-quality, compositionally accurate images across various spatial-aware conditions.", "section": "3 Method"}, {"figure_path": "R8mfn3rHd5/figures/figures_22_2.jpg", "caption": "Figure 15: More generation results about keypoint-based RealCompo.", "description": "This figure shows three examples of images generated using the keypoint-based RealCompo method.  The leftmost column displays the keypoints used as input. The next column presents the images generated by ControlNet, a method that uses keypoints for image generation.  The rightmost column shows the images generated by the RealCompo method.  The results demonstrate the ability of RealCompo to improve the realism and quality of the images generated using keypoints compared to ControlNet.", "section": "4 Experiments"}, {"figure_path": "R8mfn3rHd5/figures/figures_22_3.jpg", "caption": "Figure 15: More generation results about keypoint-based RealCompo.", "description": "This figure showcases three examples of images generated using RealCompo with keypoint-based spatial-aware conditions.  The leftmost column shows the keypoint map used as input. The middle column displays images generated using only the ControlNet model with keypoints. The rightmost column presents images generated using the proposed RealCompo framework which combines a fidelity-aware diffusion model (SDXL) and the ControlNet model, aiming to balance realism and compositionality. The examples highlight that RealCompo better leverages the spatial information from the keypoints to generate more realistic and compositionally accurate images, especially for complex scenes involving multiple characters and actions.", "section": "4 Experiments"}, {"figure_path": "R8mfn3rHd5/figures/figures_22_4.jpg", "caption": "Figure 3: Extend RealCompo to keypoint- and segmentation-based image generation.", "description": "This figure shows a comparison of images generated by three different models: SDXL (a fidelity-aware model), ControlNet (a spatial-aware model), and RealCompo (the proposed model). Each row represents a different prompt. For each prompt, the three models produce different images, highlighting their strengths and weaknesses. RealCompo often demonstrates superior results by combining the strengths of the other two models, balancing realism with compositionality.", "section": "3.3 Extend RealCompo to any Spatial-Aware Conditions in a General Form"}]