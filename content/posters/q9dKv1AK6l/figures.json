[{"figure_path": "q9dKv1AK6l/figures/figures_8_1.jpg", "caption": "Figure 1: Log sub-optimality gap, log(r(a*) - \u03c0\u03b8r), plotted against the logarithm of time, log t, in a 4-action problem with various learning rates, \u03b7. Each subplot shows a run with a specific learning rate. The curves in a subplot correspond to 10 different random seeds. Theory predicts that essentially all seeds will lead to a curve converging to zero (-\u221e in these plots). For a discussion of the results, see the text.", "description": "This figure visualizes the convergence of the stochastic gradient bandit algorithm across different learning rates (\u03b7 = 1, 10, 100, 1000) in a 4-action bandit problem.  Each subplot displays 10 independent runs, each represented by a separate curve, showing the log sub-optimality gap (log(r(a*) - \u03c0\u03b8r)) over time (log(t)).  The y-axis represents the log sub-optimality gap, indicating how far the current policy's expected reward is from the optimal reward. The x-axis shows the log of the number of iterations.  The plots illustrate the algorithm's convergence to the optimal policy even with large learning rates, though higher learning rates show more variance and potentially slower convergence in the initial stages.", "section": "Simulation Study"}, {"figure_path": "q9dKv1AK6l/figures/figures_28_1.jpg", "caption": "Figure 1: Log sub-optimality gap, log (r(a*) \u2013 \u03c0\u03c1r), plotted against the logarithm of time, log t, in a 4-action problem with various learning rates, \u03b7. Each subplot shows a run with a specific learning rate. The curves in a subplot correspond to 10 different random seeds. Theory predicts that essentially all seeds will lead to a curve converging to zero (-\u221e in these plots). For a discussion of the results, see the text.", "description": "This figure visualizes the log sub-optimality gap against the logarithm of time for a 4-action bandit problem with different learning rates (\u03b7 = 1, 10, 100, 1000). Each subplot displays 10 independent runs with different random seeds.  The results demonstrate the convergence of the stochastic gradient bandit algorithm to the optimal policy, even with large learning rates, as predicted by the theory.  While smaller learning rates lead to faster initial convergence, larger rates sometimes show slower initial progress before rapidly converging to optimality.", "section": "Simulation Study"}]