[{"figure_path": "bxH6T1w1FW/tables/tables_7_1.jpg", "caption": "Table 1: Image Denoising [PSNR\u2191/SSIM\u2191]. The denoising quality of each network is averaged across images from Set5 [44], BSD100 [36], Urban100 [45], and Manga109 [46]. The SNA module is quantitatively superior to NA, even when NA's attention scales are learned with a deep network. However, NA is over 20 times faster than SNA and consumes 13 times less memory. A major contribution of NA is efficiency, while the code for this paper's proposed SNA module has not been optimized. Time and memory usage are reported for a single image of size 128 \u00d7 128.", "description": "This table presents quantitative results comparing the performance of different attention mechanisms (SNA, H-SNA, and NA) on Gaussian denoising tasks.  It shows Peak Signal-to-Noise Ratio (PSNR) and Structural Similarity Index (SSIM) scores for various noise levels (\u03c3).  The table highlights that SNA generally achieves better denoising quality but at a higher computational cost compared to NA.  The time and memory usage are also provided for each model.", "section": "5.2 Gaussian Denoising"}, {"figure_path": "bxH6T1w1FW/tables/tables_8_1.jpg", "caption": "Table 2: Supervised Superpixel Training Impacts Denoiser Quality. This table compares the denoising quality of SNA networks trained with both a denoising loss term and an SSN loss term, Lfinal = LDeno + Lssn. The SSN Label \u201cNone\u201d indicates only a denoising loss is used. Pixel labels marginally improve the denoising quality, suggesting a cooperative relationship between these optimization problems. Segmentation labels degrade the denoising, suggesting the best superpixels for boundary adherence are not the best superpixels for image denoising. Time and memory usage are reported for a single 128 \u00d7 128 image.", "description": "This table shows the results of training SNA networks with different loss functions.  It compares denoising performance (PSNR/SSIM) when only using a denoising loss, when adding a pixel-level supervised loss, and when adding a segmentation-level supervised loss. The results show that adding a pixel-level loss slightly improves denoising, while adding a segmentation-level loss significantly degrades performance, suggesting a trade-off between boundary accuracy and denoising quality.  Computational cost (time and memory usage) is also provided.", "section": "5.3 Inspecting the Learned Superpixel Probabilities"}, {"figure_path": "bxH6T1w1FW/tables/tables_8_2.jpg", "caption": "Table 3: Evaluating Superpixel Quality. Training an SNA attention module on denoising learns superpixel probabilities with comparable quality to explicitly training superpixels. The ASA and BR metrics evaluate the ML superpixel estimate. The PSNR and SSIM metrics evaluate the quality of the superpixel pooled image.", "description": "This table compares the quality of superpixels learned by training a soft superpixel neighborhood attention (SNA) module for image denoising with the quality of superpixels learned using a supervised training method.  It evaluates both the accuracy of the maximum likelihood superpixel estimate (using Achievable Segmentation Accuracy (ASA) and Boundary Recall (BR)) and the quality of the resulting image after superpixel pooling (using Peak Signal-to-Noise Ratio (PSNR) and Structural Similarity Index (SSIM)).  The comparison helps to determine whether learning superpixels for denoising produces superpixels that are similarly effective for other tasks (like supervised superpixel segmentation).", "section": "5.3 Inspecting the Learned Superpixel Probabilities"}, {"figure_path": "bxH6T1w1FW/tables/tables_9_1.jpg", "caption": "Table 1: Image Denoising [PSNR\u2191/SSIM\u2191]. The denoising quality of each network is averaged across images from Set5 [44], BSD100 [36], Urban100 [45], and Manga109 [46]. The SNA module is quantitatively superior to NA, even when NA's attention scales are learned with a deep network. However, NA is over 20 times faster than SNA and consumes 13 times less memory. A major contribution of NA is efficiency, while the code for this paper's proposed SNA module has not been optimized. Time and memory usage are reported for a single image of size 128 \u00d7 128.", "description": "This table compares the denoising performance of different attention mechanisms (SNA and NA) under various conditions (learning attention scale or not, using SLIC superpixels or not) across four benchmark image datasets.  It shows that SNA generally outperforms NA in terms of PSNR and SSIM, although NA is significantly faster and more memory-efficient.", "section": "5.2 Gaussian Denoising"}, {"figure_path": "bxH6T1w1FW/tables/tables_15_1.jpg", "caption": "Table 1: Image Denoising [PSNR\u2191/SSIM\u2191]. The denoising quality of each network is averaged across images from Set5 [44], BSD100 [36], Urban100 [45], and Manga109 [46]. The SNA module is quantitatively superior to NA, even when NA's attention scales are learned with a deep network. However, NA is over 20 times faster than SNA and consumes 13 times less memory. A major contribution of NA is efficiency, while the code for this paper's proposed SNA module has not been optimized. Time and memory usage are reported for a single image of size 128 \u00d7 128.", "description": "This table presents a quantitative comparison of different attention mechanisms for image denoising.  It shows the Peak Signal-to-Noise Ratio (PSNR) and Structural Similarity Index (SSIM) scores for various noise levels (\u03c3).  The results demonstrate that the proposed Soft Superpixel Neighborhood Attention (SNA) significantly outperforms standard Neighborhood Attention (NA), especially at higher noise levels. However, it highlights the computational cost and memory usage of SNA, emphasizing the efficiency advantage of NA.", "section": "5.2 Gaussian Denoising"}]