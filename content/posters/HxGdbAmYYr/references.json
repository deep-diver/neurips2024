{"references": [{"fullname_first_author": "Mathilde Caron", "paper_title": "Emerging properties in self-supervised vision transformers", "publication_date": "2021-10-10", "reason": "This paper introduces the DINO method for self-supervised pre-training of vision transformers, which serves as the foundation for the current work's experimental setup."}, {"fullname_first_author": "Eleni Triantafillou", "paper_title": "Meta-dataset: A dataset of datasets for learning to learn from few examples", "publication_date": "2020-01-01", "reason": "This paper introduces the Meta-Dataset benchmark, which is a crucial dataset used for evaluating the model's generalization capabilities across various domains."}, {"fullname_first_author": "Shell Xu Hu", "paper_title": "Pushing the limits of simple pipelines for few-shot learning: External data and fine-tuning make a difference", "publication_date": "2022-06-01", "reason": "This paper introduces the PMF method, which is the baseline meta-tuning method used in the paper for comparison and is a strong baseline for few-shot learning."}, {"fullname_first_author": "Edward J Hu", "paper_title": "Lora: Low-rank adaptation of large language models", "publication_date": "2021-06-01", "reason": "This paper introduces the LoRA method, which is the core parameter-efficient fine-tuning approach used in the paper for constructing the robust LoRAPool."}, {"fullname_first_author": "Yuqian Fu", "paper_title": "StyleAdv: Meta style adversarial training for cross-domain few-shot learning", "publication_date": "2023-01-01", "reason": "This paper introduces the StyleAdv method, which is a state-of-the-art adversarial few-shot learning method compared to in the paper for evaluating the model's adversarial robustness."}]}