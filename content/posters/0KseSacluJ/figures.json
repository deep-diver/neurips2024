[{"figure_path": "0KseSacluJ/figures/figures_1_1.jpg", "caption": "Figure 1: CoFie is a local geometry-aware shape representation. (Left) CoFie divides a shape into non-overlapping local patches, where each local patch is represented by an MLP-based Signed Distance Function. (Right) CoFie introduces Coordinate Field, which attaches a coordinate frame to each local patch. It transforms local patches from the world coordinate system to an aligned coordinate system, reducing shape complexity.", "description": "CoFie, a novel local geometry-aware neural surface representation, divides a shape into local patches. Each patch uses an MLP-based Signed Distance Function (SDF) for representation.  The key innovation is the Coordinate Field, which assigns a learnable coordinate frame to each patch. This transforms the patches from the world coordinate system into an aligned system, significantly reducing their spatial complexity and making them easier to represent with the MLPs.", "section": "1 Introduction"}, {"figure_path": "0KseSacluJ/figures/figures_6_1.jpg", "caption": "Figure 3: Diveristy and quality of meshes that CoFie can represent. The results include both novel instances from ShapeNet training categories (top left), instances from ShapeNet unseen categories (bottom left), and real shapes from the Thingi dataset (right). We visualize the shapes with surface normal to better show their geometry. Please see the appendix for comparisons with ground-truth.", "description": "This figure showcases the variety and quality of 3D shapes that the CoFie model can generate.  It displays examples from three different sources: novel shapes from ShapeNet's training categories, shapes from unseen ShapeNet categories, and real-world shapes from the Thingi dataset.  The use of surface normals in the visualization helps to highlight the details and quality of the generated meshes.  A more detailed comparison with ground truth is available in the appendix of the paper.", "section": "5 Experiment"}, {"figure_path": "0KseSacluJ/figures/figures_7_1.jpg", "caption": "Figure 4: Trade-off between accuracy and model size (notified by the radius of circles).", "description": "This figure shows the trade-off between the accuracy (measured by Chamfer distance) and model size (measured by latent code length) of CoFie and DeepLS on ShapeNet unseen categories.  The size of the circles represents the latent code length, while the y-axis indicates the Chamfer distance, a measure of shape error.  CoFie consistently outperforms DeepLS across all latent code lengths, demonstrating superior performance even with significantly fewer parameters.  The dashed lines represent the average performance of each method.", "section": "5.1 Experimental Results"}, {"figure_path": "0KseSacluJ/figures/figures_7_2.jpg", "caption": "Figure 6: Compare with the generalizable methods DeepSDF and DeepLS on ShapeNet shapes. We show two images for each method, one for the overall shape quality, and a zoom-in detail check.", "description": "This figure compares the performance of CoFie against two other generalizable methods (DeepSDF and DeepLS) on ShapeNet shapes.  For each shape, two views are shown: one providing a general overview of the shape and the second showing a zoomed-in portion to highlight details.  The comparison visually demonstrates CoFie's ability to better capture fine details compared to the other two methods.", "section": "5.1 Experimental Results"}, {"figure_path": "0KseSacluJ/figures/figures_17_1.jpg", "caption": "Figure 6: Compare with the generalizable methods DeepSDF and DeepLS on ShapeNet shapes. We show two images for each method, one for the overall shape quality, and a zoom-in detail check.", "description": "This figure compares the performance of CoFie against two other generalizable neural implicit surface representation methods, DeepSDF and DeepLS, on a set of ShapeNet shapes. For each shape and method, two views are shown: one providing an overall view of the shape and its quality, and another showing a zoomed-in view for more detailed analysis of specific regions. This visual comparison allows for a direct assessment of CoFie's ability to represent fine geometric details in comparison to existing approaches.", "section": "5.1 Experimental Results"}, {"figure_path": "0KseSacluJ/figures/figures_18_1.jpg", "caption": "Figure 7: Compare with the shape-specific method NGLOD on Thingi shapes. We show two images for each method, one for the overall shape quality, and a zoom-in detail check.", "description": "This figure compares the performance of CoFie against NGLOD, a shape-specific method, on the Thingi dataset of real-world shapes.  For each shape (a rabbit, Venus de Milo statue, winged angel statue, and a lion head), it shows two views: one highlighting the overall reconstruction quality and a zoomed-in view to showcase the level of detail achieved. The comparison visually demonstrates CoFie's ability to model complex geometries while using a single, shared MLP.  This highlights CoFie's generalizability, a key advantage over shape-specific methods.", "section": "5.1 Experimental Results"}, {"figure_path": "0KseSacluJ/figures/figures_18_2.jpg", "caption": "Figure 8: Analysis of the failure case. CoFie still struggles to represent extremely detailed geometry parts.", "description": "This figure shows a comparison between the model's reconstruction (CoFie) and the ground truth for a complex chandelier model.  The left side displays two views of the model generated by CoFie, highlighting areas where fine details, such as the intricate curvatures of the chandelier arms and the delicate structures of the light fixtures, were not accurately captured. The right side presents two views of the ground truth model, showcasing the level of detail that CoFie struggled to replicate. This illustrates a limitation of the CoFie model in representing extremely detailed geometry.", "section": "5 Experiment"}]