[{"figure_path": "MQIET1VfoV/tables/tables_9_1.jpg", "caption": "Table 1: Generalization Win Rate in SMACv2. Note that E2GN2 retains high performance, while GNN and MLP lose performance when generalizing", "description": "This table presents the generalization performance of three different neural network architectures (E2GN2, GNN, and MLP) on the StarCraft Multi-Agent Challenge (SMACv2) environment.  The agents were trained under a specific map initialization called \"Surrounded Left\", and then tested on three different initializations: \"Surrounded Left\" (the same as training), \"Surrounded Right\" (a mirrored version of the training initialization), and \"Surrounded All\" (the standard SMACv2 initialization). The table shows the win rate (with standard error) achieved by each model under each testing scenario.  The results highlight that E2GN2 maintains consistently high performance across all test conditions, showcasing its strong generalization capabilities, in contrast to GNN and MLP, which exhibit significant performance degradation when tested on different map initializations.", "section": "5.3 Generalization"}, {"figure_path": "MQIET1VfoV/tables/tables_9_2.jpg", "caption": "Table 2: Generalization Win Rate: Testing RL agents ability to scale to different numbers of agents (originally trained with 5 agents)", "description": "This table demonstrates the generalization ability and scalability of E2GN2 and GNN models trained on Starcraft Multi-Agent Challenge (SMACv2) with 5 agents. The win rates are tested with different numbers of agents (4, 6, 7, and 8) while keeping the same training configuration, showing the performance consistency across varying numbers of agents.  This highlights the scalability and robustness of the models.", "section": "5.3 Generalization"}, {"figure_path": "MQIET1VfoV/tables/tables_14_1.jpg", "caption": "Table 1: Generalization Win Rate in SMACv2. Note that E2GN2 retains high performance, while GNN and MLP lose performance when generalizing", "description": "This table presents the generalization performance of three different neural network architectures (E2GN2, GNN, and MLP) on the StarCraft Multi-Agent Challenge (SMACv2) environment.  The models were trained using a \"Surrounded Left\" initialization and then tested on three different scenarios: \"Surrounded Right\", where the agent positions are mirrored horizontally, \"Surrounded All\", using the standard initialization; and the training scenario itself (\"Surrounded Left\").  The win rate, which represents the frequency with which agents achieve victory, is reported for each model under each testing condition. The table highlights the superior generalization performance of E2GN2 compared to GNN and MLP, showing that E2GN2 maintains its performance under various conditions while the others demonstrate a significant drop in performance when tested under different initial conditions.", "section": "5.3 Generalization"}, {"figure_path": "MQIET1VfoV/tables/tables_14_2.jpg", "caption": "Table 1: Generalization Win Rate in SMACv2. Note that E2GN2 retains high performance, while GNN and MLP lose performance when generalizing", "description": "This table presents the generalization performance of E2GN2, GNN, and MLP models on the StarCraft Multi-Agent Challenge (SMACv2) benchmark.  The models were trained using the \"Surrounded Left\" initialization, where agents are positioned on the left side of the map. Then, their generalization capabilities were evaluated on three different test scenarios: \"Surrounded Right\" (agents on the right), \"Surrounded All\" (agents randomly distributed), and the original training configuration.  The table displays the win rates achieved by each model in each test scenario, demonstrating E2GN2's superior generalization ability compared to GNN and MLP, which experience significant performance drops in the test scenarios.", "section": "5.3 Generalization"}, {"figure_path": "MQIET1VfoV/tables/tables_18_1.jpg", "caption": "Table 1: Generalization Win Rate in SMACv2. Note that E2GN2 retains high performance, while GNN and MLP lose performance when generalizing", "description": "This table presents the generalization performance of three different neural network architectures (E2GN2, GNN, and MLP) on the StarCraft Multi-Agent Challenge (SMACv2) environment.  The agents were trained using a specific initial agent configuration (\"Surrounded Left\") and tested on three different configurations: \"Surrounded Right\", \"Surrounded All\", and the training configuration. The win rate, a measure of agent success, is reported for each network and testing configuration, across three different unit types (Terran, Protoss, and Zerg).  The table highlights that E2GN2 demonstrates significantly better generalization than GNN and MLP, maintaining high win rates across all testing configurations.", "section": "5.3 Generalization"}]