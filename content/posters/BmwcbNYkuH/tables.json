[{"figure_path": "BmwcbNYkuH/tables/tables_5_1.jpg", "caption": "Table 1: Out-of-domain accuracy on CAMELYON17. The column name indicates the centre used to train models. The best accuracy for each column is in bold face and the second best in italics. Method \"Ours-no-l2-A\" is shorthand for \"Ours-no-l2-Aug\" and refers to our approach without l2-regularisation. Method \"Ours-MO-Aug\" refers to our approach with masks only, that is, neither using l2-regularisation nor using mask-times-input augmentation of H&E images with 50% probability during training. A paired t-test for \"L2D-Aug\" versus \"Ours-Aug\" yields a p-value of 210-5.", "description": "This table presents the out-of-domain accuracy results for the CAMELYON17 dataset.  The accuracy of models trained on each of the five centers is tested on the other four centers (out-of-domain). The table compares the performance of the proposed method against several baseline methods, with and without data augmentation, highlighting the improvement in out-of-domain generalisation achieved by the proposed method.", "section": "4 Experiments"}, {"figure_path": "BmwcbNYkuH/tables/tables_6_1.jpg", "caption": "Table 1: Out-of-domain accuracy on CAMELYON17. The column name indicates the centre used to train models. The best accuracy for each column is in bold face and the second best in italics. Method \"Ours-no-l2-A\" is shorthand for \"Ours-no-l2-Aug\" and refers to our approach without l2-regularisation. Method \"Ours-MO-Aug\" refers to our approach with masks only, that is, neither using l2-regularisation nor using mask-times-input augmentation of H&E images with 50% probability during training. A paired t-test for \"L2D-Aug\" versus \"Ours-Aug\" yields a p-value of 2\u00b710\u22125.", "description": "This table presents the out-of-domain accuracy results for the CAMELYON17 dataset.  The models were trained on one of five centers and tested on the remaining four. The table compares the performance of the proposed method against several baselines, including different data augmentation and stain normalization techniques.  The results show the average accuracy and standard deviation across ten trials for each method and center.  Statistical significance is noted for the comparison of the proposed method against one specific baseline.", "section": "4 Experiments"}, {"figure_path": "BmwcbNYkuH/tables/tables_6_2.jpg", "caption": "Table 1: Out-of-domain accuracy on CAMELYON17. The column name indicates the centre used to train models. The best accuracy for each column is in bold face and the second best in italics. Method \"Ours-no-l2-A\" is shorthand for \"Ours-no-l2-Aug\" and refers to our approach without l2-regularisation. Method \"Ours-MO-Aug\" refers to our approach with masks only, that is, neither using l2-regularisation nor using mask-times-input augmentation of H&E images with 50% probability during training. A paired t-test for \"L2D-Aug\" versus \"Ours-Aug\" yields a p-value of 2\u00b710-5.", "description": "This table presents the out-of-domain accuracy results on the CAMELYON17 dataset.  The dataset is split into five centers, each serving as a separate training domain. The table compares the performance of several methods (ERM, Macenko, HoVerNet, RandSNA, RSC, L2D, Ours, and their augmentations) across these five centers.  The \"Ours\" method represents the proposed method from the paper, with variants showing effects of regularization and data augmentation.  The average accuracy across all five centers is shown for each method, allowing for a comparison of generalization performance.", "section": "4.1 Datasets"}, {"figure_path": "BmwcbNYkuH/tables/tables_15_1.jpg", "caption": "Table 1: Out-of-domain accuracy on CAMELYON17. The column name indicates the centre used to train models. The best accuracy for each column is in bold face and the second best in italics. Method \"Ours-no-l2-A\" is shorthand for \"Ours-no-l2-Aug\" and refers to our approach without l2-regularisation. Method \"Ours-MO-Aug\" refers to our approach with masks only, that is, neither using l2-regularisation nor using mask-times-input augmentation of H&E images with 50% probability during training. A paired t-test for \"L2D-Aug\" versus \"Ours-Aug\" yields a p-value of 2\u00b710-5.", "description": "This table presents the out-of-domain accuracy results for the CAMELYON17 dataset.  The models were trained on one of five medical centers (each considered a different domain) and tested on the remaining four.  The table compares the performance of the proposed method against several baselines, including stain normalization and data augmentation techniques.  The results show the average accuracy across the four test domains for each training domain, indicating the generalizability of each model.", "section": "4 Experiments"}, {"figure_path": "BmwcbNYkuH/tables/tables_15_2.jpg", "caption": "Table 1: Out-of-domain accuracy on CAMELYON17. The column name indicates the centre used to train models. The best accuracy for each column is in bold face and the second best in italics. Method \"Ours-no-l2-A\" is shorthand for \"Ours-no-l2-Aug\" and refers to our approach without l2-regularisation. Method \"Ours-MO-Aug\" refers to our approach with masks only, that is, neither using l2-regularisation nor using mask-times-input augmentation of H&E images with 50% probability during training. A paired t-test for \"L2D-Aug\" versus \"Ours-Aug\" yields a p-value of 2\u00b710\u22125.", "description": "This table presents the out-of-domain accuracy results on the CAMELYON17 dataset.  The dataset is split into five centers, each serving as a separate training domain. The table shows the performance of various methods (including the proposed method) on each of the test centers (out-of-domain). The best and second-best performing methods are highlighted for each center.  Statistical significance is noted between the proposed method and a key baseline (L2D-Aug).  Variations of the proposed method are included for ablation study.", "section": "4.1 Datasets"}, {"figure_path": "BmwcbNYkuH/tables/tables_15_3.jpg", "caption": "Table 1: Out-of-domain accuracy on CAMELYON17. The column name indicates the centre used to train models. The best accuracy for each column is in bold face and the second best in italics. Method \"Ours-no-l2-A\" is shorthand for \"Ours-no-l2-Aug\" and refers to our approach without l2-regularisation. Method \"Ours-MO-Aug\" refers to our approach with masks only, that is, neither using l2-regularisation nor using mask-times-input augmentation of H&E images with 50% probability during training. A paired t-test for \"L2D-Aug\" versus \"Ours-Aug\" yields a p-value of 210-5.", "description": "This table presents the out-of-domain accuracy results on the CAMELYON17 dataset.  The dataset is split into five centers, each serving as a separate training domain. The table shows the performance of different methods, including the proposed method, on each test domain.  The best performing method is highlighted in bold for each center. The average accuracy across all centers is also shown.  A statistical significance test is mentioned, indicating a high significance between the proposed method and one of the baselines.", "section": "4 Experiments"}, {"figure_path": "BmwcbNYkuH/tables/tables_16_1.jpg", "caption": "Table 1: Out-of-domain accuracy on CAMELYON17. The column name indicates the centre used to train models. The best accuracy for each column is in bold face and the second best in italics. Method \"Ours-no-l2-A\" is shorthand for \"Ours-no-l2-Aug\" and refers to our approach without l2-regularisation. Method \"Ours-MO-Aug\" refers to our approach with masks only, that is, neither using l2-regularisation nor using mask-times-input augmentation of H&E images with 50% probability during training. A paired t-test for \"L2D-Aug\" versus \"Ours-Aug\" yields a p-value of 2\u00b710\u22125.", "description": "This table presents the out-of-domain accuracy results on the CAMELYON17 dataset.  The models were trained on data from one of five different medical centers (Centre 0-4) and tested on data from the remaining four centers.  The table compares the performance of several methods, including the proposed method, across these different centers.  The best and second-best accuracies are highlighted for each centre.  A statistical significance test is also reported comparing the proposed method with a baseline method.", "section": "4.1 Datasets"}, {"figure_path": "BmwcbNYkuH/tables/tables_16_2.jpg", "caption": "Table 1: Out-of-domain accuracy on CAMELYON17. The column name indicates the centre used to train models. The best accuracy for each column is in bold face and the second best in italics. Method \"Ours-no-l2-A\" is shorthand for \"Ours-no-l2-Aug\" and refers to our approach without l2-regularisation. Method \"Ours-MO-Aug\" refers to our approach with masks only, that is, neither using l2-regularisation nor using mask-times-input augmentation of H&E images with 50% probability during training. A paired t-test for \"L2D-Aug\" versus \"Ours-Aug\" yields a p-value of 2\u00b710\u22125.", "description": "This table presents the out-of-domain accuracy results on the CAMELYON17 dataset.  The dataset is split into five centers (domains), and the table shows the performance of several methods trained on each center when tested on the other four centers.  The methods include several baselines (ERM, Macenko, HoVerNet, RandSNA, RSC, L2D) and the proposed method.  The results are shown with and without data augmentation.  The table highlights the best performing method for each center and provides a statistical comparison between the proposed method and L2D with augmentation.", "section": "4 Experiments"}, {"figure_path": "BmwcbNYkuH/tables/tables_16_3.jpg", "caption": "Table 1: Out-of-domain accuracy on CAMELYON17. The column name indicates the centre used to train models. The best accuracy for each column is in bold face and the second best in italics. Method \"Ours-no-l2-A\" is shorthand for \"Ours-no-l2-Aug\" and refers to our approach without l2-regularisation. Method \"Ours-MO-Aug\" refers to our approach with masks only, that is, neither using l2-regularisation nor using mask-times-input augmentation of H&E images with 50% probability during training. A paired t-test for \"L2D-Aug\" versus \"Ours-Aug\" yields a p-value of 210-5.", "description": "This table shows the out-of-domain accuracy results on the CAMELYON17 dataset.  The models were trained on one of five centers and tested on the remaining four.  The table compares the performance of the proposed method against several baseline methods, including ERM (Empirical Risk Minimization), Macenko stain normalization, HoVerNet, RandSNA, RSC, and L2D.  The results are presented with and without data augmentation, highlighting the impact of the proposed method on improving out-of-domain generalization.", "section": "4 Experiments"}, {"figure_path": "BmwcbNYkuH/tables/tables_17_1.jpg", "caption": "Table 1: Out-of-domain accuracy on CAMELYON17. The column name indicates the centre used to train models. The best accuracy for each column is in bold face and the second best in italics. Method \"Ours-no-l2-A\" is shorthand for \"Ours-no-l2-Aug\" and refers to our approach without l2-regularisation. Method \"Ours-MO-Aug\" refers to our approach with masks only, that is, neither using l2-regularisation nor using mask-times-input augmentation of H&E images with 50% probability during training. A paired t-test for \"L2D-Aug\" versus \"Ours-Aug\" yields a p-value of 210-5.", "description": "This table presents the out-of-domain accuracy results for the CAMELYON17 dataset.  The results are broken down by the training center (Centre-0 through Centre-4) for various methods, including baselines (ERM, Macenko, HoverNet, RandSNA, RSC, L2D) and the proposed method (Ours).  Augmented versions of the methods are also included. The table highlights the superior performance of the proposed method, particularly when augmented data is used, and showcases its statistical significance (p-value).", "section": "4.1 Datasets"}, {"figure_path": "BmwcbNYkuH/tables/tables_17_2.jpg", "caption": "Table 1: Out-of-domain accuracy on CAMELYON17. The column name indicates the centre used to train models. The best accuracy for each column is in bold face and the second best in italics. Method \"Ours-no-l2-A\" is shorthand for \"Ours-no-l2-Aug\" and refers to our approach without l2-regularisation. Method \"Ours-MO-Aug\" refers to our approach with masks only, that is, neither using l2-regularisation nor using mask-times-input augmentation of H&E images with 50% probability during training. A paired t-test for \"L2D-Aug\" versus \"Ours-Aug\" yields a p-value of 2\u00b710\u22125.", "description": "This table presents the out-of-domain accuracy results for the CAMELYON17 dataset.  The models were trained on one of five centers (Centre 0-4) and then tested on the remaining four centers.  The table compares the proposed method (\"Ours\") against several baselines (ERM, Macenko, HoverNet, RandSNA, RSC, L2D), both with and without data augmentation.  The results show the average accuracy across the four test centers and highlight the superior performance of the proposed method, particularly when data augmentation is used.", "section": "4 Experiments"}, {"figure_path": "BmwcbNYkuH/tables/tables_17_3.jpg", "caption": "Table 1: Out-of-domain accuracy on CAMELYON17. The column name indicates the centre used to train models. The best accuracy for each column is in bold face and the second best in italics. Method \"Ours-no-l2-A\" is shorthand for \"Ours-no-l2-Aug\" and refers to our approach without l2-regularisation. Method \"Ours-MO-Aug\" refers to our approach with masks only, that is, neither using l2-regularisation nor using mask-times-input augmentation of H&E images with 50% probability during training. A paired t-test for \"L2D-Aug\" versus \"Ours-Aug\" yields a p-value of 2\u00b710\u22125.", "description": "This table presents the out-of-domain accuracy results for the CAMELYON17 dataset.  The dataset is split into five centers, each used to train a model, and then tested on the remaining four centers.  The table compares the performance of different methods, including the proposed method, various baselines, and augmented versions, demonstrating the superior out-of-domain generalization capability of the proposed method. The statistical significance of the difference between the proposed method and a key baseline (L2D-Aug) is also noted. ", "section": "4 Experiments"}, {"figure_path": "BmwcbNYkuH/tables/tables_18_1.jpg", "caption": "Table 1: Out-of-domain accuracy on CAMELYON17. The column name indicates the centre used to train models. The best accuracy for each column is in bold face and the second best in italics. Method \"Ours-no-l2-A\" is shorthand for \"Ours-no-l2-Aug\" and refers to our approach without l2-regularisation. Method \"Ours-MO-Aug\" refers to our approach with masks only, that is, neither using l2-regularisation nor using mask-times-input augmentation of H&E images with 50% probability during training. A paired t-test for \"L2D-Aug\" versus \"Ours-Aug\" yields a p-value of 210-5.", "description": "This table presents the out-of-domain accuracy results on the CAMELYON17 dataset.  It compares the performance of the proposed method against several baseline methods across five different centers (considered as separate domains). The table shows the average accuracy and standard deviation for each method in each center, highlighting the best and second-best performing methods.  The statistical significance of the difference between the proposed method and L2D-Aug is noted, indicating a strong improvement in out-of-domain generalization by the proposed method.", "section": "4 Experiments"}, {"figure_path": "BmwcbNYkuH/tables/tables_18_2.jpg", "caption": "Table 1: Out-of-domain accuracy on CAMELYON17. The column name indicates the centre used to train models. The best accuracy for each column is in bold face and the second best in italics. Method \"Ours-no-l2-A\" is shorthand for \"Ours-no-l2-Aug\" and refers to our approach without l2-regularisation. Method \"Ours-MO-Aug\" refers to our approach with masks only, that is, neither using l2-regularisation nor using mask-times-input augmentation of H&E images with 50% probability during training. A paired t-test for \"L2D-Aug\" versus \"Ours-Aug\" yields a p-value of 2\u00b710-5.", "description": "This table presents the out-of-domain accuracy results on the CAMELYON17 dataset.  The dataset is split into five centers, each treated as a separate domain.  The table shows the performance of various methods (ERM, Macenko, HoVerNet, RandSNA, RSC, L2D, and the proposed 'Ours' method) for each center when trained on a single center and tested on the others (out-of-domain).  The best and second-best results for each center are highlighted. Several variations of the proposed method are included, illustrating the impact of different components and data augmentation strategies.  Statistical significance between L2D-Aug and Ours-Aug is noted.", "section": "4 Experiments"}, {"figure_path": "BmwcbNYkuH/tables/tables_18_3.jpg", "caption": "Table 1: Out-of-domain accuracy on CAMELYON17. The column name indicates the centre used to train models. The best accuracy for each column is in bold face and the second best in italics. Method \"Ours-no-l2-A\" is shorthand for \"Ours-no-l2-Aug\" and refers to our approach without l2-regularisation. Method \"Ours-MO-Aug\" refers to our approach with masks only, that is, neither using l2-regularisation nor using mask-times-input augmentation of H&E images with 50% probability during training. A paired t-test for \"L2D-Aug\" versus \"Ours-Aug\" yields a p-value of 2 \u00b7 10\u22125.", "description": "This table shows the out-of-domain accuracy results on the CAMELYON17 dataset.  The dataset is split into five centers, each treated as a separate domain. The table presents the classification accuracy of different models trained on each center and tested on the other four centers (out-of-domain). It compares several methods including ERM (Empirical Risk Minimization), Macenko stain normalization, HoVerNet, RandStainNA, RSC, L2D, and the proposed method (\"Ours\").  Different variations of the proposed method are also included. The average accuracy across all centers is reported, along with statistical significance (p-value) of the difference between L2D-Aug and Ours-Aug.", "section": "4 Experiments"}, {"figure_path": "BmwcbNYkuH/tables/tables_19_1.jpg", "caption": "Table 1: Out-of-domain accuracy on CAMELYON17. The column name indicates the centre used to train models. The best accuracy for each column is in bold face and the second best in italics. Method \"Ours-no-l2-A\" is shorthand for \"Ours-no-l2-Aug\" and refers to our approach without l2-regularisation. Method \"Ours-MO-Aug\" refers to our approach with masks only, that is, neither using l2-regularisation nor using mask-times-input augmentation of H&E images with 50% probability during training. A paired t-test for \"L2D-Aug\" versus \"Ours-Aug\" yields a p-value of 2\u00b710\u22125.", "description": "This table presents the out-of-domain accuracy results on the CAMELYON17 dataset.  The models were trained on one of five centers (Centre 0-4) and tested on the remaining four centers. The table shows the average accuracy and standard deviation across ten models trained per center and method.  Different domain generalization methods (ERM, Macenko, HoVerNet, RandSNA, RSC, L2D, Ours) are compared, both with and without data augmentation. The \"Ours\" method refers to the proposed approach in the paper, which uses nuclear segmentation masks during training. The table highlights the significantly better performance of the proposed method, especially when combined with augmentation, demonstrating its enhanced out-of-domain generalization capabilities.", "section": "4 Experiments"}, {"figure_path": "BmwcbNYkuH/tables/tables_19_2.jpg", "caption": "Table 1: Out-of-domain accuracy on CAMELYON17. The column name indicates the centre used to train models. The best accuracy for each column is in bold face and the second best in italics. Method \"Ours-no-l2-A\" is shorthand for \"Ours-no-l2-Aug\" and refers to our approach without l2-regularisation. Method \"Ours-MO-Aug\" refers to our approach with masks only, that is, neither using l2-regularisation nor using mask-times-input augmentation of H&E images with 50% probability during training. A paired t-test for \"L2D-Aug\" versus \"Ours-Aug\" yields a p-value of 2\u00b710\u22125.", "description": "This table presents the out-of-domain accuracy results on the CAMELYON17 dataset.  Each column represents a different training center (domain), and each row shows the performance of a different method.  The best and second-best accuracies are highlighted in bold and italics, respectively.  The table also includes results for variations of the proposed method ('Ours') to analyze the impact of specific components.  Statistical significance testing (paired t-test) is reported for the comparison between \"L2D-Aug\" and \"Ours-Aug\".", "section": "4 Experiments"}, {"figure_path": "BmwcbNYkuH/tables/tables_19_3.jpg", "caption": "Table 1: Out-of-domain accuracy on CAMELYON17. The column name indicates the centre used to train models. The best accuracy for each column is in bold face and the second best in italics. Method \"Ours-no-l2-A\" is shorthand for \"Ours-no-l2-Aug\" and refers to our approach without l2-regularisation. Method \"Ours-MO-Aug\" refers to our approach with masks only, that is, neither using l2-regularisation nor using mask-times-input augmentation of H&E images with 50% probability during training. A paired t-test for \"L2D-Aug\" versus \"Ours-Aug\" yields a p-value of 2\u00b710\u22125.", "description": "This table presents the out-of-domain accuracy results for the CAMELYON17 dataset.  The model is trained on one of the five centers and tested on the other four. The best performing method is compared with several baselines. Note that the table highlights the impact of using augmentation and the proposed regularization technique.", "section": "4 Experiments"}, {"figure_path": "BmwcbNYkuH/tables/tables_20_1.jpg", "caption": "Table 1: Out-of-domain accuracy on CAMELYON17. The column name indicates the centre used to train models. The best accuracy for each column is in bold face and the second best in italics. Method \"Ours-no-l2-A\" is shorthand for \"Ours-no-l2-Aug\" and refers to our approach without l2-regularisation. Method \"Ours-MO-Aug\" refers to our approach with masks only, that is, neither using l2-regularisation nor using mask-times-input augmentation of H&E images with 50% probability during training. A paired t-test for \"L2D-Aug\" versus \"Ours-Aug\" yields a p-value of 2 \u00b7 10\u22125.", "description": "This table presents the out-of-domain accuracy results for the CAMELYON17 dataset.  The dataset is split into five centers, each acting as a different domain. Models are trained on a single center and tested on the remaining four.  The table compares the performance of several methods, including the proposed method ('Ours'), highlighting the improvement in out-of-domain generalization achieved using different data augmentation techniques and regularization strategies.  Statistical significance (p-value) between the proposed method and a key comparison method (L2D-Aug) is also reported.", "section": "4.1 Datasets"}, {"figure_path": "BmwcbNYkuH/tables/tables_20_2.jpg", "caption": "Table 1: Out-of-domain accuracy on CAMELYON17. The column name indicates the centre used to train models. The best accuracy for each column is in bold face and the second best in italics. Method \"Ours-no-l2-A\" is shorthand for \"Ours-no-l2-Aug\" and refers to our approach without l2-regularisation. Method \"Ours-MO-Aug\" refers to our approach with masks only, that is, neither using l2-regularisation nor using mask-times-input augmentation of H&E images with 50% probability during training. A paired t-test for \"L2D-Aug\" versus \"Ours-Aug\" yields a p-value of 2\u00b710\u22125.", "description": "This table presents the out-of-domain accuracy results for the CAMELYON17 dataset.  The dataset is split into five centres, each serving as a separate training domain. The table shows the accuracy of models trained on one centre when tested on the other four centres (out-of-domain). Multiple methods are compared, including a baseline (ERM), stain normalization methods, and existing single-domain generalization methods.  The proposed method (\"Ours\") and its variations (with and without regularization, and with different data augmentation strategies) are also evaluated, demonstrating improved out-of-domain generalization performance compared to other approaches. The statistical significance of the difference between the proposed method and L2D-Aug is also highlighted. ", "section": "4 Experiments"}, {"figure_path": "BmwcbNYkuH/tables/tables_20_3.jpg", "caption": "Table 1: Out-of-domain accuracy on CAMELYON17. The column name indicates the centre used to train models. The best accuracy for each column is in bold face and the second best in italics. Method \"Ours-no-l2-A\" is shorthand for \"Ours-no-l2-Aug\" and refers to our approach without l2-regularisation. Method \"Ours-MO-Aug\" refers to our approach with masks only, that is, neither using l2-regularisation nor using mask-times-input augmentation of H&E images with 50% probability during training. A paired t-test for \"L2D-Aug\" versus \"Ours-Aug\" yields a p-value of 2 \u00b7 10\u22125.", "description": "This table presents the out-of-domain accuracy results on the CAMELYON17 dataset.  The dataset is split into five centers, each treated as a separate domain.  The table shows the accuracy of models trained on each center when tested on the other four centers.  The results are compared across different methods: ERM (Empirical Risk Minimization), Macenko stain normalization, HoVerNet, RandSNA (Random Stain Normalization and Augmentation), RSC (Representation Self-Challenging), L2D (Learning to Diversify), and the proposed \"Ours\" method.  Variations of the proposed method are also included (e.g., without l2-regularization or mask-only).  The table highlights the best and second-best performing methods for each center, and statistically significant differences (p<0.00002) between L2D-Aug and Ours-Aug are reported.", "section": "4. Experiments"}, {"figure_path": "BmwcbNYkuH/tables/tables_21_1.jpg", "caption": "Table 1: Out-of-domain accuracy on CAMELYON17. The column name indicates the centre used to train models. The best accuracy for each column is in bold face and the second best in italics. Method \"Ours-no-l2-A\" is shorthand for \"Ours-no-l2-Aug\" and refers to our approach without l2-regularisation. Method \"Ours-MO-Aug\" refers to our approach with masks only, that is, neither using l2-regularisation nor using mask-times-input augmentation of H&E images with 50% probability during training. A paired t-test for \"L2D-Aug\" versus \"Ours-Aug\" yields a p-value of 2 \u00b7 10\u22125.", "description": "This table shows the out-of-domain accuracy results on the CAMELYON17 dataset.  The dataset is split into five centers, and each center's data is used to train a model, which is then tested on the data from the other four centers (out-of-domain). The table compares several methods, including the proposed method, stain normalization, and data augmentation techniques, showing the average accuracy across all five test centers. The best performing method for each center is highlighted in bold, indicating the superior generalisation capabilities of the proposed method.", "section": "4 Experiments"}, {"figure_path": "BmwcbNYkuH/tables/tables_21_2.jpg", "caption": "Table 1: Out-of-domain accuracy on CAMELYON17. The column name indicates the centre used to train models. The best accuracy for each column is in bold face and the second best in italics. Method \"Ours-no-l2-A\" is shorthand for \"Ours-no-l2-Aug\" and refers to our approach without l2-regularisation. Method \"Ours-MO-Aug\" refers to our approach with masks only, that is, neither using l2-regularisation nor using mask-times-input augmentation of H&E images with 50% probability during training. A paired t-test for \"L2D-Aug\" versus \"Ours-Aug\" yields a p-value of 2\u00b710\u22125.", "description": "This table presents the out-of-domain accuracy results on the CAMELYON17 dataset.  The dataset is split into five centers, each treated as a separate domain. Models are trained on a single center and tested on the other four centers. The table compares the performance of several methods, including the proposed method,  across the different centers.  The \"Ours\" method shows consistently high accuracy compared to baselines and other techniques.  The augmented versions of methods are marked with \"-Aug\".", "section": "4 Experiments"}, {"figure_path": "BmwcbNYkuH/tables/tables_21_3.jpg", "caption": "Table 1: Out-of-domain accuracy on CAMELYON17. The column name indicates the centre used to train models. The best accuracy for each column is in bold face and the second best in italics. Method \"Ours-no-l2-A\" is shorthand for \"Ours-no-l2-Aug\" and refers to our approach without l2-regularisation. Method \"Ours-MO-Aug\" refers to our approach with masks only, that is, neither using l2-regularisation nor using mask-times-input augmentation of H&E images with 50% probability during training. A paired t-test for \"L2D-Aug\" versus \"Ours-Aug\" yields a p-value of 2\u00b710\u22125.", "description": "This table presents the out-of-domain accuracy results on the CAMELYON17 dataset.  The dataset is split into five centers (columns), each serving as a training domain. The model trained on one center is then evaluated on the remaining four centers. The best and second-best accuracies are highlighted for comparison. Different methods, including baselines and the proposed method (Ours), are compared with and without data augmentation.", "section": "4 Experiments"}, {"figure_path": "BmwcbNYkuH/tables/tables_22_1.jpg", "caption": "Table 1: Out-of-domain accuracy on CAMELYON17. The column name indicates the centre used to train models. The best accuracy for each column is in bold face and the second best in italics. Method \"Ours-no-l2-A\" is shorthand for \"Ours-no-l2-Aug\" and refers to our approach without l2-regularisation. Method \"Ours-MO-Aug\" refers to our approach with masks only, that is, neither using l2-regularisation nor using mask-times-input augmentation of H&E images with 50% probability during training. A paired t-test for \"L2D-Aug\" versus \"Ours-Aug\" yields a p-value of 2\u00b710\u22125.", "description": "This table presents the out-of-domain accuracy results for the CAMELYON17 dataset.  The models were trained on one of five different medical centers (each considered a separate domain), and then tested on the remaining four centers.  The table shows the average accuracy and standard deviation across ten models for each training center and method.  It compares the proposed method's performance against several established single-domain generalization methods.", "section": "4 Experiments"}, {"figure_path": "BmwcbNYkuH/tables/tables_22_2.jpg", "caption": "Table 1: Out-of-domain accuracy on CAMELYON17. The column name indicates the centre used to train models. The best accuracy for each column is in bold face and the second best in italics. Method \"Ours-no-l2-A\" is shorthand for \"Ours-no-l2-Aug\" and refers to our approach without l2-regularisation. Method \"Ours-MO-Aug\" refers to our approach with masks only, that is, neither using l2-regularisation nor using mask-times-input augmentation of H&E images with 50% probability during training. A paired t-test for \"L2D-Aug\" versus \"Ours-Aug\" yields a p-value of 2\u00b710\u22125.", "description": "This table presents the out-of-domain accuracy results on the CAMELYON17 dataset.  The dataset is split into five centers, each treated as a separate domain.  Models trained on one center are tested on the other four. The table shows the performance of several methods including the proposed method. The best and second-best accuracies for each center are highlighted, and the average accuracy across centers is also shown.  The table also compares results with and without data augmentation and with and without the use of l2-regularization.  Statistical significance is noted.", "section": "4 Experiments"}, {"figure_path": "BmwcbNYkuH/tables/tables_22_3.jpg", "caption": "Table 1: Out-of-domain accuracy on CAMELYON17. The column name indicates the centre used to train models. The best accuracy for each column is in bold face and the second best in italics. Method \"Ours-no-l2-A\" is shorthand for \"Ours-no-l2-Aug\" and refers to our approach without l2-regularisation. Method \"Ours-MO-Aug\" refers to our approach with masks only, that is, neither using l2-regularisation nor using mask-times-input augmentation of H&E images with 50% probability during training. A paired t-test for \"L2D-Aug\" versus \"Ours-Aug\" yields a p-value of 2\u00b710\u22125.", "description": "This table presents the out-of-domain accuracy results on the CAMELYON17 dataset.  The dataset is split into five centers, each serving as a training domain.  Models trained on one center are then tested on the remaining four centers to evaluate out-of-domain generalization performance. The table compares various methods, including the proposed method and several baselines, showing the mean accuracy and standard deviation across ten trials.  The best-performing method for each center is highlighted.", "section": "4 Experiments"}, {"figure_path": "BmwcbNYkuH/tables/tables_22_4.jpg", "caption": "Table 26: Accuracy when combining L2D or RSC with the proposed method on CAMELYON17. The best accuracy for each column is in bold face and the second best in italics. \"+Ours\" results are an average of five models for each combination of medical centre and method instead of an average of ten models. All results are using photometric augmentations described in 4.3 even though \"-Aug\" is omitted from the name in the table.", "description": "This table shows the results of combining two single-domain generalization methods (L2D and RSC) with the proposed method on the CAMELYON17 dataset.  The best performing method for each center is highlighted. The table demonstrates the impact of combining different methods on the overall accuracy.  The use of photometric augmentations is consistent across all experiments.", "section": "5 Ablation Study and Discussion"}, {"figure_path": "BmwcbNYkuH/tables/tables_23_1.jpg", "caption": "Table 1: Out-of-domain accuracy on CAMELYON17. The column name indicates the centre used to train models. The best accuracy for each column is in bold face and the second best in italics. Method \"Ours-no-l2-A\" is shorthand for \"Ours-no-l2-Aug\" and refers to our approach without l2-regularisation. Method \"Ours-MO-Aug\" refers to our approach with masks only, that is, neither using l2-regularisation nor using mask-times-input augmentation of H&E images with 50% probability during training. A paired t-test for \"L2D-Aug\" versus \"Ours-Aug\" yields a p-value of 2\u00b710\u22125.", "description": "This table presents the out-of-domain accuracy results for the CAMELYON17 dataset.  The dataset is split into five centers, each serving as a training domain. For each center, multiple models are trained using different methods (ERM, Macenko, HoVerNet, RandSNA, RSC, L2D, and the proposed \"Ours\" method), and their performance is evaluated on the remaining four centers as out-of-domain datasets.  The table highlights the best and second-best performing methods for each center and provides the average accuracy across all centers. The effect of data augmentation on the performance is also shown by comparing methods with and without augmentation ('-Aug'). Statistical significance between the proposed 'Ours' and L2D methods is noted.", "section": "4 Experiments"}, {"figure_path": "BmwcbNYkuH/tables/tables_23_2.jpg", "caption": "Table 29: Accuracy when using a ViT-Tiny [60], comparing the baseline against the proposed method on CAMELYON17. The best accuracy for each column is in bold face and the second best in italics. All results are using photometric augmentations described in 4.3 even though \"-Aug\" is omitted from the name in the table. 'AwoC4' is 'Average without Centre-4'. 'RSNA' refers to RandStainNA [24].", "description": "This table compares the performance of different methods for out-of-domain generalization on the CAMELYON17 dataset using a ViT-Tiny model.  It includes results for ERM, RandStainNA (RSNA), DDCA, L2D, and the proposed method.  The table shows the accuracy for each of the five centers in CAMELYON17, the average accuracy across all centers, and the average accuracy excluding Center 4. Photometric augmentations were used for all methods.", "section": "4 Experiments"}, {"figure_path": "BmwcbNYkuH/tables/tables_23_3.jpg", "caption": "Table 31: Accuracy when using a ViT-Tiny [60], comparing the baseline against the proposed method on Ocelot. The best accuracy for each column is in bold face and the second best in italics. All results are using photometric augmentations described in 4.3 even though \"-Aug\" is omitted from the name in the table. 'AwoC4' is 'Average without Centre-4'. 'RSNA' refers to RandStainNA [24].", "description": "This table presents the results of an experiment comparing different methods for out-of-domain generalization using a ViT-Tiny model on the Ocelot dataset. The methods compared include ERM, RSNA, DDCA, L2D and the proposed method. The table shows the accuracy for each method on five different centers (Centre-0 to Centre-4), the average accuracy across all centers, and the average accuracy excluding Centre-4.", "section": "4 Experiments"}]