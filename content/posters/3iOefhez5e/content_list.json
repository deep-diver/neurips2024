[{"type": "text", "text": "Low Degree Hardness for Broadcasting on Trees ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Han Huang   \nDepartment of Mathematics   \nUniversity of Missouri   \nColumbia, MO 65203   \nhhuang@missouri.edu   \nElchanan Mossel   \nDepartment of Mathematics   \nMIT   \nCambridge, MA 02139   \nelmos@mit.edu ", "page_idx": 0}, {"type": "text", "text": "", "page_idx": 0}, {"type": "text", "text": "Abstract ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "We study the low-degree hardness of broadcasting on trees. Broadcasting on trees has been extensively studied in statistical physics, in computational biology in relation to phylogenetic reconstruction and in statistics and computer science in the context of block model inference, and as a simple data model for algorithms that may require depth for inference. ", "page_idx": 0}, {"type": "text", "text": "The inference of the root can be carried by celebrated Belief Propagation (BP) algorithm which achieves Bayes-optimal performance. Recent works indicated that this algorithm in fact requires high level of complexity. Moitra, Mossel and Sandon constructed a chain for which estimating the root better than random (for a typical input) is $N C1$ complete. Kohler and Mossel constructed chains such that for trees With $N$ leaves, recovering the root better than random requires a polynomial of degree $N^{\\Omega(1)}$ . Both works above asked if such complexity bounds hold in general below the celebrated Kesten-Stigum bound. ", "page_idx": 0}, {"type": "text", "text": "In this work, we prove that this is indeed the case for low degree polynomials. We show that for the broadcast problem using any Markov chain on trees with $N$ leaves, below the Kesten Stigum bound, any ${\\cal O}(\\log N)$ degree polynomial has vanishing correlation with the root. ", "page_idx": 0}, {"type": "text", "text": "Our result is one of the first low-degree lower bound that is proved in a setting that is not based or easily reduced to a product measure. ", "page_idx": 0}, {"type": "text", "text": "1 Introduction ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Understanding the computational complexity inference problems of random instances has been extensively studies in different research areas including statistics, cryptography, computational complexity, computational learning theory and statistical physics. The emerging field of research is mainly devoted to the study of computational-to-statistical gaps. ([3, 41, 24]) ", "page_idx": 0}, {"type": "text", "text": "Recently, low-degree polynomials have emerged as a popular tool for predicting computationalto-statistical gaps, especially in the context of the Bayesian framework. Our work follows [23] in studying the polynomial hardness of broadcasting on trees. ", "page_idx": 0}, {"type": "text", "text": "A very exciting line of work, including [19, 18, 25, 4, 15, 26, 17, 9, 40] recently showed that the \"low-degree heuristic\u201d\u2019 can be used to predict computational-statistical gaps for a variety of problems such as recovery in general stochastic block models, sparse PCA, tensor PCA, the planted clique problem, certification in the zero-temperature Sherrington-Kirkpatrick model, the planted sparse vector problem, and for finding solutions in random $k$ SATproblems. ", "page_idx": 0}, {"type": "text", "text": "Interestingly, it was observed that the predictions from this method often agree with predictions from statistical physics heuristics based on the replica and cavity methods which are closely related to the analysis of BP/AMP fixed points, see e.g. [12, 13, 28]). ", "page_idx": 0}, {"type": "text", "text": "It is often argued that low-degree polynomials algorithms are relatively easy to use (e.g. compared to proving SOS lower bounds), and that low degree polynomials capture the power of the \\*\u201clocal algorithms\" framework used in e.g. [16, 10] as well as algorithms which incorporate global information, such as spectral methods or a constant number of iterations of Approximate Message Passing [29]. ", "page_idx": 1}, {"type": "text", "text": "In this work, we continue to study the power of low-degree polynomials for the (average case) broadcast on trees problem. In broadcasting on trees the goal is to estimate the value of the Markov process at the root given its value at the leaves and the goal is to do so for arbitrarily deep trees. Two key parameters of the model are the arity of the tree $d$ and the magnitude of the second eigenvalue $\\lambda$ of the broadcast chain. ", "page_idx": 1}, {"type": "text", "text": "A fundamental result in this area [22] is that when $d|\\lambda|^{2}>1$ nontrivial reconstruction of the root is possible by counting the number of the leaves of different types, an algorithm that could be described as a linear function of the leave values. In contrast, when $\\overline{{d|}}\\lambda|^{2}<1$ , such linear estimators have no mutual information with the root (but more complex statistics of the leaves may) [30, 36]. ", "page_idx": 1}, {"type": "text", "text": "This threshold $d|\\lambda|^{2}=1$ is known as the Kesten-Stigum threshold. A series of works showed that the KS threshold is the information theory threshold for non-trivial root inference for some specific channels, including the binary symmetric channel [6, 14, 21, 20] and binary channels that are close to symmetric [8], as well as $3\\times3$ symmetric channels for large $d$ [39]. ", "page_idx": 1}, {"type": "text", "text": "While the Kesten-Stigum bound is easy to compute, it turns out that in many cases, it is not the information-theoretic threshold for root recovery. This was first established in [30] for symmetric channels with sufficiently many states, specifically when $q\\geq C$ for some large constant $C$ . Later it was shown for symmetric channels with $q\\geq5$ states in [39]. Recently, the results [37] provide more information about the case of $q=3$ and $q=4$ . Many of the finer results in this area prove predictions from statistical physics. The connection between the broadcast problems and phase transitions in statistical physics was made in [27], and more recent predictions include [5, 2, 38]. Moreover, the information-theoretic threshold may depend on the specific structure of the channel rather than solely on $d$ and $\\lambda$ . Notably, [30] also showed that there exists channels where non-trivial predictions of the root are achievable even when $|\\lambda|=0$ ", "page_idx": 1}, {"type": "text", "text": "Much of the interest in Kesten-Stigum threshold comes from the fundamental role it plays in problems, such as algorithmic recovery in the stochastic block model [11, 33, 7, 35, 1] and phylogenetic reconstruction [31]. Count statistics can be viewed as degree 1 polynomials of the leaves, which begs the question of what information more general polynomials can extract from the leaves. See [32, 34] for surveys on the topic. ", "page_idx": 1}, {"type": "text", "text": "In [23] it was shown that $\\lambda=0$ even polynomials of degree $N^{c}$ , where $N=d^{\\ell}$ is the number of leaves of for a $d$ -arytreeof depth $\\ell$ , for a small $c>0$ are not able to correlate with the root label (as $\\ell$ tends to $\\infty$ ), whereas computationally efficient reconstruction is generally possible as long as $d$ is a sufficiently large constant [30]. ", "page_idx": 1}, {"type": "text", "text": "The main motivation of [23] was to prove that low degree polynomials fail below the Kesten Stigum bound: \u201cIt is natural to wonder if the Kesten-Stigum threshold $d|\\lambda|^{2}=1$ is sharp for low-degree polynomial reconstruction, analogous to how it is sharp for robust reconstruction.\" However the main result of [23] only established this in the very special case of $\\lambda=0$ . This problem is also stated in the ICM 2022 paper and talk on the broadcast process [34]: \u201c The authors of [23] ask if a similar phenomenon holds through the non-linear regime. For example, is it true that polynomials of bounded degree have vanishing correlation with $X_{0}$ in the regime where $d\\lambda^{2}<1?$ \" The main results of this paper prove that this is indeed the case. We proceed with formal definitions and statement of the main result. ", "page_idx": 1}, {"type": "text", "text": "1.1  Definitions and Main Result ", "text_level": 1, "page_idx": 1}, {"type": "text", "text": "Rooted Tree ", "text_level": 1, "page_idx": 1}, {"type": "text", "text": "Recall that every rooted tree $T$ inherently defines a partial order relation among its vertices: For a pair of distinct vertices, $u$ is said to be an ancestor of $v$ (and $v$ a descendant of $u$ ), denoted as $v<u$ in this paper, if $u$ is contained in the unique path from $v$ to the root $\\rho$ . Specifically, if $v$ and $u$ are directly connected by an edge, we also refer to $v$ as a child vertex of $u$ (and $u$ as the parent vertex of $v$ ).By $v\\leq u$ we mean that $v$ is either a descendant of $u$ or $v=u$ . In general, if $v<u$ and the path distance between them is $k$ \uff0c $v$ is referred to as a $k$ th-descendant of $u$ (and $u$ as the $k$ th ancestor of $v$ ", "page_idx": 1}, {"type": "text", "text": "For a nonnegative integer $k$ , the $k$ th layer of the tree refers to the set of $k$ th descendants of theroot $\\rho$ (The root here is considered at the Oth layer of the tree.) The depth of the tree is defined as the largest non-negative integer $\\ell$ for which the Cth layer is not empty, and we denote the $\\ell$ th layer by $L$ ", "page_idx": 2}, {"type": "text", "text": "The height of a vertex $u$ is defined as ", "page_idx": 2}, {"type": "equation", "text": "$$\n\\mathrm{h}(u)=\\ell-\\mathrm{\\the\\layer\\of\\}u.\n$$", "text_format": "latex", "page_idx": 2}, {"type": "text", "text": "In particular, when $L$ is the set of leaves, then $\\mathrm{h}(u)$ is simply the distance from $u$ to $L$ . In this paper, we may abuse the notation by writing $x\\in T$ or $S\\subseteq T$ to mean that $x$ is a vertex or $S$ is a subset of vertices in the tree $T$ ", "page_idx": 2}, {"type": "text", "text": "The standard rooted $d$ -ary tree with depth $\\ell$ is a tree where each vertex $u\\not\\in L$ has exactly $d$ children vertices. Let us start by defining the type of trees we will be investigating in this paper, which is a slight generalization of $d$ -ary tree. ", "page_idx": 2}, {"type": "image", "img_path": "3iOefhez5e/tmp/91817ae2987cadf041fd4c9ca39bf6b8872d03f896ddde613c4cebe15370c005.jpg", "img_caption": ["Figure 1: An example of a binary rooted tree of depth 5 is shown. The vertex $u$ is at the 3rd layer and $\\mathrm{h}(u)=2$ . Further, the following relationships hold: $v<u$ and $v$ is a child of $u$ $s\\in L$ is a 2nd descendant of $u,\\,w$ is the parent of $u$ , and $t$ is the 2nd ancestor of $u$ "], "img_footnote": [], "page_idx": 2}, {"type": "text", "text": "Definition 1.1. A rooted tree $T$ with root $\\rho$ has degree dominated by $d\\geq1$ with parameter $R\\geq1$ if for every vertex u and positive integer $k$ , the number of kth descendants of u is at most $R d^{k}$ ", "page_idx": 2}, {"type": "text", "text": "With the above definition, a $d_{\\cdot}$ -ary rooted tree has degree dominated by $d\\geq1$ with parameter $R=1$ Further, a typical realization of a Galton- Watson tree of Poisson type with average degree $d$ and of depth $\\ell$ (a random tree in which each vertex $u\\not\\in L$ has on average $d$ children vertices) has a degree dominated by $d\\geq1$ with parameter $R\\simeq\\log(\\ell)$ ", "page_idx": 2}, {"type": "text", "text": "Broadcasting Process on Rooted Trees ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "Next, we will define the broadcasting process on a rooted tree $T$ with root $\\rho$ . Consider a $q\\times q$ ergodic transition matrix $M$ , where $q\\geq2$ . Recall that every eigenvalue of a transition matrix $M$ has an absolute value at most 1. Let $0\\leq\\lambda\\leq1$ represent the second largest absolute value among the eigenvalues of $M$ . Additionally, we define the stationary distribution of $M$ as $\\pi$ ", "page_idx": 2}, {"type": "text", "text": "The broadcasting process $X=(X_{v})_{v\\in T}$ , with state space $[q]:=\\{1,2,\\dots,q\\}$ and transition matrix $M$ , can be formally described as follows: We initialize the value of $X_{\\rho}$ according to some initial distribution $\\nu$ . As we reveal the values layer by layer, when the value $X_{u}$ is revealed, the value $X_{v}$ for any child vertex $v$ of $u$ is independently distributed according to a specific row of $M$ depending on the value of $X_{u}$ ", "page_idx": 2}, {"type": "equation", "text": "$$\n{\\mathbb P}\\{X_{v}=t\\,|\\,X_{u}=s\\}=M_{s t}.\n$$", "text_format": "latex", "page_idx": 2}, {"type": "text", "text": "In other words, each vertex's value depends only on its parent vertex's value. The definition of the process is given below: ", "page_idx": 2}, {"type": "text", "text": "Definition 1.2 (Broadcasting Process on Tree). Let $q\\geq2$ be a positive integer. For any rooted tree $T$ with root $\\rho$ and a $q\\times q$ ergodic transition matrix $M$ the broadcasting process $X=(X_{v})_{v\\in T}$ with state space $[q]$ ,according to transition matrix $M$ with an initial distribution $\\nu$ for $X_{\\rho}$ ,is a random process with joint distribution given by: ", "page_idx": 2}, {"type": "equation", "text": "$$\n\\forall x=(x_{v})_{v\\in T}\\in[q]^{T},\\ \\ \\mathbb{P}\\{X=x\\}=\\nu(x_{\\rho})\\prod_{(v,u)}M_{x_{u},x_{v}},\n$$", "text_format": "latex", "page_idx": 2}, {"type": "text", "text": "where the product is taken over all pairs $(v,u)$ suchthat $v$ is a child vertex of $u$ ", "page_idx": 3}, {"type": "text", "text": "For a subset of vertices $A\\subset T$ let usdenote ", "page_idx": 3}, {"type": "equation", "text": "$$\nX_{A}=(X_{v})_{v\\in A}\\,.\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "If the tree is just a path, then the process reduces to a Markov chain. If we assume $\\nu=\\pi$ , then $X_{v}\\sim\\pi$ for every $v\\in T$ as $(X_{v})_{v\\in P}$ for every downward path of $T$ forms a Markov Chain with transition matrix $M$ . Further, let us make a remark about the Markov property of the process. ", "page_idx": 3}, {"type": "text", "text": "Remark 1.3 (Markov Property). The broadcasting process establishes a Markov Random Field on tree $T$ : Given any three disjoint subsets $A,B$ , and $C$ of $T$ , if every path from a vertex in $A$ to a vertex in $C$ passes through a vertex in $B$ , then the random variables $X_{A}$ and $X_{C}$ are conditionally independent given $X_{B}$ ", "page_idx": 3}, {"type": "text", "text": "Polynomials of $x_{L}$ and the Main Result ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "Definition 1.4. Let $x\\in[q]^{T}$ For $u\\in T$ let $\\boldsymbol{x}_{\\le u}=(x_{v})_{v\\le u}$ . For subset $U\\subseteq T_{i}$ let $x_{U}=(x_{u})_{u\\in U}$ ", "page_idx": 3}, {"type": "text", "text": "The next definition is about the notion of degrees for functions with variables $x_{L}=(x_{v})_{v\\in L}$ . This is the generalization of degree of a polynomial. ", "page_idx": 3}, {"type": "text", "text": "Definition 1.5 (Efron-Stein Degree). A function $f$ with variables $x_{L}$ has Efron-Stein degree at most $k$ if it can be expressed as ", "page_idx": 3}, {"type": "equation", "text": "$$\nf=\\sum_{\\alpha}f_{\\alpha},\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "where the summation is over a finite set of indices $\\alpha$ and each $f_{\\alpha}$ is a function of the variable $x_{S}$ for some $S\\subseteq L$ with $|S|\\le k$ ", "page_idx": 3}, {"type": "text", "text": "Now, we could properly formulate the main result of the paper: ", "page_idx": 3}, {"type": "text", "text": "Theorem 1.6. Let $T$ be a rooted tree with root $\\rho$ of depth $\\ell$ and has degree dominated by $d\\geq1$ with parameter $R\\geq1$ :Consider the broadcasting process on $T$ with a $q\\times q$ transition matrix $M$ and $X_{\\rho}\\sim\\pi$ Iff $M$ is ergodic and $d\\lambda^{2}<1$ ,then there exists a constant $c>0$ which depends on $M$ and dXsuch that the following holds: Foranyfunction f(xL) of Efron-Steindegree Clog(R), we have ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\mathrm{Var}({\\mathbb E}\\big[f(X_{L})\\,\\big|\\,X_{\\rho}\\big])\\leq(\\operatorname*{max}\\{d\\lambda^{2},\\lambda\\})^{\\ell/4}\\mathrm{Var}(f(X_{L})).\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "Remark 1.7. Given that $d\\lambda^{2}<1$ implies $\\lambda^{2}<1$ , and $\\lambda<1$ if and only if $\\lambda^{2}<1$ , we can infer that $\\lambda<1$ from the given conditions. Consequently, the term $\\operatorname*{max}\\{d\\lambda^{2},\\dot{\\lambda}\\}<1$ followsfrom the assumptions of the theorem. Therefore, the R.H.S. of the inequality decays exponentially with the depth of the tree. ", "page_idx": 3}, {"type": "text", "text": "Follows from the theorem and propteries of conditonal expectation, we have the following corollary. ", "page_idx": 3}, {"type": "text", "text": "Corollary 1.8.With the same setting as in Theorem 1.6, for any function $f(\\boldsymbol{x}_{L})$ ofEfron-Steindegree $\\leq c{\\frac{\\ell}{1+\\log(R)}}$ andanyfunction $g(x_{\\rho})$ of theroot value,their correlation satisfies ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\mathrm{Corr}(f(X_{L}),g(X_{\\rho})):=\\frac{\\mathbb{E}\\big[(f(X_{L})-\\mathbb{E}f(X_{L}))(g(X_{\\rho})-\\mathbb{E}g(X_{\\rho}))\\big]}{\\sqrt{\\mathrm{Var}(f(X_{L})}\\sqrt{\\mathrm{Var}(g(X_{\\rho}))}}\\leq(\\operatorname*{max}\\{d\\lambda^{2},\\lambda\\})^{\\ell/8}.\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "The proof of the theorem is based on recursion on a notion of fractal capacity of functions. Indeed, the main result is optimal in the fractal sense (Theorem 1.16), as we will later demonstrate that all functions with fractal capacity up to a level proportional to $\\ell$ exhibit vanishing_correlation with the root, whereas all functions of the leaves have fractal capacity at most $\\ell+1$ .Let usintroducethe necessary definitions and notations to introduce both the fractal capacity and the proof overview. ", "page_idx": 3}, {"type": "text", "text": "1.2Fractal Capacity and Proof Overview ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "To provide a clearer illustration, we establish a correspondence between the vertices of $T$ andwords of varying lengths from O to $\\ell$ with vertices at the $k$ th layer represented as words of length $k$ We denote the root $\\rho$ as the empty word (). For each vertex $u$ , represented by the word $(b_{1},b_{2},\\ldots,b_{k})$ \uff0c we define $d_{u}$ as the number of children vertices of $u$ , and we identify these children vertices as $(b_{1},b_{2},\\ldots,b_{k},i)$ with $i\\in[d_{u}]:=\\{1,2,\\ldots,d_{u}\\}$ . Notice that $v$ is a descendant of $u$ is equivalent to $u$ is a prefix of $v$ . For brevity, for each $u=(b_{1},\\ldots,b_{k})\\in T$ and $i\\in[d_{u}]$ , let ", "page_idx": 3}, {"type": "text", "text": "", "page_idx": 4}, {"type": "equation", "text": "$$\nu_{i}:=(u,i)=(b_{1},\\ldots,b_{k},i).\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "For $I\\subseteq[d_{u}]$ , let ", "page_idx": 4}, {"type": "equation", "text": "$$\nu_{I}=\\{u_{i}\\}_{i\\in I}.\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "Furthermore, we denote the parent vertex of $u$ as ${\\mathfrak{p}}(u)\\,=\\,(b_{1},\\dotsc,b_{k-1})$ and the set of children vertices of u as c(u) = u[du] \u00b7 ", "page_idx": 4}, {"type": "image", "img_path": "3iOefhez5e/tmp/bf9b4a563bd6b285ac9e30a97c8b69258b38e10255fdaff4b5ff9c7595f3bf12.jpg", "img_caption": ["Figure 2: In the these figures, we present the vertices as words and adapt the notations $u_{1},u_{2}$ etc., for the descendants of $u$ . For the right figure, if $S=\\{u_{21},u_{22},u_{32}\\}$ , then $\\rho(S)=u$ $I(S)=\\{2,3\\}$ \uff0c and $S_{2}=\\{u_{21},u_{22}\\}$ \uff0c $S_{3}=\\{u_{32}\\}$ . Further, $S_{1}\\in A_{3}$ \uff0c $S_{2}\\in A_{2}$ , and $S_{3}\\in A_{1}$ "], "img_footnote": [], "page_idx": 4}, {"type": "text", "text": "Definition 1.9. For a non-empty subset $S\\subseteq L$ we introduce the notation $\\rho(S)$ to represent the nearest common ancestor of the vertices in $S$ ,meaningthat $\\rho(S)$ is thevertex with smallest height that is an ancestor of all vertices in $S$ ", "page_idx": 4}, {"type": "text", "text": "Here we consider the case when $|S|>1$ Notice that $\\rho(S)$ is not at the lth layer $L$ For each child $\\rho(S)_{i}$ of $\\rho(S)$ for $i\\in\\left[d_{\\rho(S)}\\right]$ ,we define the set $S_{i}$ as ", "page_idx": 4}, {"type": "equation", "text": "$$\nS_{i}=S\\cap\\{v\\in L:v\\leq\\rho(S)_{i}\\},\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "which is the collection of vertices in $S$ that are descendants of $\\rho(S)_{i}$ .Let ", "page_idx": 4}, {"type": "equation", "text": "$$\nI(S)=\\{i\\in[d_{\\rho(S)}]\\,:\\,S_{i}\\neq\\emptyset\\}.\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "Then, $S$ can be expressed as the disjoint union of the sets $S_{i}$ for $i\\in I(S)$ ", "page_idx": 4}, {"type": "equation", "text": "$$\nS=\\sqcup_{i\\in I(S)}S_{i}.\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "We call the above disjoint union the branch decomposition of $S$ andeach $S_{i}$ for $i\\in I(S)$ abranch partof $S$ ", "page_idx": 4}, {"type": "text", "text": "The branch decomposition is a key concept in the proof, and we define the fractal capacity according to the number of iterations to decompose $S$ intosingletons. ", "page_idx": 4}, {"type": "text", "text": "Definition 1.10. Let ", "page_idx": 4}, {"type": "equation", "text": "$$\n{\\cal A}_{1}:=\\Big\\{\\{u\\}\\,:\\,u\\in{\\cal L}\\Big\\}\\subseteq{\\bf2}^{L}\\backslash\\{\\emptyset\\},\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "be the collection of singletons of $L$ We say a subcollection $A\\subseteq\\mathbf{2}^{L}\\backslash\\{\\varnothing\\}$ is closed under decomposition with base $\\mathcal{A}_{1}$ if for every $S\\in{\\mathcal{A}}\\backslash A_{1}$ , we have $S_{i}\\in A$ for $i\\in I(S)$ ", "page_idx": 4}, {"type": "text", "text": "Definition 1.11. For any $A\\subseteq\\mathbf{2}^{L}\\backslash\\{\\varnothing\\}$ let ", "page_idx": 4}, {"type": "equation", "text": "$$\nB(A)\\subseteq\\mathbf{2}^{L}\\backslash\\{\\varnothing\\}\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "be a new subcollection defined according to the following rules: ", "page_idx": 4}, {"type": "text", "text": "For any $S\\in\\mathbf{2}^{L}\\backslash\\{\\varnothing\\}$ $S\\in{\\mathfrak{B}}$ if and only if one of the following two conditions holds ", "page_idx": 4}, {"type": "text", "text": "1. $S\\in A_{1}$ ", "page_idx": 5}, {"type": "text", "text": "For example, $B({\\mathcal{A}})$ contains sets of size $\\leq2$ ", "page_idx": 5}, {"type": "text", "text": "Lemma 1.12. If ${\\mathcal{A}}_{1}\\subseteq{\\mathcal{A}}\\subseteq{\\mathbf{2}}^{L}\\backslash\\{\\emptyset\\}$ is a subcollection closed under decomposition with base $\\mathcal{A}_{1}$ then the collection $B=B({\\mathcal{A}})$ contains $\\boldsymbol{\\mathcal{A}}$ and it is also closed under decomposition with base $\\mathcal{A}_{1}$ ", "page_idx": 5}, {"type": "text", "text": "Proof. To show ${\\mathcal{A}}\\subseteq B$ ,it issufficient toshow $\\mathcal{A}\\backslash A_{1}\\subseteq B$ . For any $S\\in{\\mathcal{A}}\\backslash A_{1}$ , because $\\boldsymbol{\\mathcal{A}}$ is closed underdecomposition, $S_{i}\\in A$ for $i\\in I(S)$ . Hence, $S\\in{\\mathfrak{B}}$ followsfrom the definition of $\\boldsymbol{\\mathrm{\\Delta}}\\boldsymbol{\\mathrm{\\Omega}}_{\\boldsymbol{B}}$ . Now, for $S\\in B\\backslash A_{1}$ , each $S_{i}$ with $i\\in I(S)$ is contained in ${\\mathcal{A}}\\subseteq{\\mathcal{B}}$ which in turn implies $\\boldsymbol{\\mathrm{\\Delta}}\\boldsymbol{\\mathrm{\\Omega}}_{\\boldsymbol{B}}$ is closed under decomposition. \u53e3 ", "page_idx": 5}, {"type": "text", "text": "Now, we define recursively that ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathcal{A}_{k}=\\mathcal{B}(\\mathcal{A}_{k-1}),}\\end{array}\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "forpositiveinteger $k\\geq2$ . Observe the following two facts: Consider any non-singleton set $S\\subseteq L$ and $S_{i}$ with $i\\in I(S)$ . First, $S\\in{\\mathcal{A}}_{k}\\Rightarrow S_{i}\\in{\\mathcal{A}}_{k-1}$ by the definition of $\\mathcal{A}_{k}$ . Second, $\\rho(S)>\\rho(S_{i})$ by the definition of branch decomposition. Given these two facts, we can prove inductively that ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\mathrm{h}(\\rho(S))=k\\Rightarrow S\\in{\\mathcal{A}}_{k+1}.\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "Since that there are only $\\ell$ layers of the tree, we conclude that every non-emptyset of $S\\subseteq L$ is in $\\mathcal{A}_{\\ell+1}$ . Therefore, together with Lemma 1.12, we have the following chain of subcollections: ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\{\\{u\\}:\\,u\\in L\\}={\\mathcal{A}}_{1}\\subseteq{\\mathcal{A}}_{2}\\subseteq\\cdot\\cdot\\cdot\\subseteq{\\mathcal{A}}_{\\ell+1}=\\mathbf{2}^{L}\\backslash\\{\\varnothing\\}.\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "Definition 1.13 (Fractal Capacity). For any non-empty subset $S\\subseteq L$ we define the fractal capacity of $S$ as thesmallest $k$ suchthat $S\\in\\mathcal A_{k}$ ", "page_idx": 5}, {"type": "text", "text": "We introduce the notion of fractal capacity, borrowing terminology from fractal geometry. The recursive nature of our definition on subsets of trees mirrors the self-similar complexity found in fractal structures. This recursive and inherently intricate structure motivates our choice of the term fractal capacity, capturing the fractal-like properties that emerge in the collections $(\\mathcal{A}_{k})_{k\\in[l+1]}$ ", "page_idx": 5}, {"type": "text", "text": "Definition 1.14. Given a collection $A\\subseteq\\,\\mathbf{2}^{L}\\backslash\\{\\varnothing\\}$ \uff1aA function $f\\ :\\ [q]^{T}\\ \\rightarrow\\ \\mathbb{R}$ is called an $\\boldsymbol{\\mathcal{A}}$ polynomial if we can express ", "page_idx": 5}, {"type": "equation", "text": "$$\nf(x)=\\sum_{S\\in A}f_{S}(x_{S})\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "where eachfs is a function of $x_{S}=(x_{v})_{v\\in S}$ Afunction $f:[q]^{T}\\rightarrow\\mathbb{R}$ hasfractal capacity $\\leq k\\,i f$ it isa $\\mathcal{A}_{k}$ -polynomial. ", "page_idx": 5}, {"type": "text", "text": "Remark 1.15. It is not hard to verify that $\\mathcal{A}_{k}$ contains all non-empty subsets $S\\subseteq L$ with $\\vert S\\vert\\le k$ Thus, for any function $f$ with variables $x_{L}$ \uff0c ", "page_idx": 5}, {"type": "text", "text": "On the other hand, it is worth to remark that for the $d\\!.$ -ary tree of depth $\\ell\\geq k$ , there exists $S\\in{\\mathcal{A}}_{k}$ with $\\vert S\\vert=d^{k-1}$ . (Namely, taking $S=\\{v\\in L:v<u\\}$ for some $u$ with $\\mathrm{h}(u)=k-1.$ ) Thus, an $\\mathcal{A}_{k}$ -polynomial could have an Efron-Stein degree exponential in $k$ ", "page_idx": 5}, {"type": "text", "text": "The main result of the paper in terms of the fractal capacity is the following: ", "page_idx": 5}, {"type": "text", "text": "Theorem 1.16.With the same setting_as in Theorem 1.6, there exists a constant $c\\,>\\,0$ which dependson $M$ and $d\\lambda^{2}$ such that the following holds: For any function $f(\\boldsymbol{x}_{L})$ with fractal capacity $\\begin{array}{r}{\\leq c\\frac{\\ell}{1+\\log(R)}}\\end{array}$ we have ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\mathrm{Var}(\\mathbb{E}\\big[f(X_{L})\\,\\big|\\,X_{\\rho}\\big])\\leq(\\operatorname*{max}\\{d\\lambda^{2},\\lambda\\})^{\\ell/4}\\mathrm{Var}(f(X_{L})).\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "Indeed, Theorem 1.6 is a direct consequence of Theorem 1.16, as $\\mathcal{A}_{k}$ -polynomials contains all polynomials of Efron-Stein degree $\\leq k$ . Further, in terms of fractal capacity, the theorem is optimal because the correlation decay persists up to an order proportional to $\\ell$ , while a fractal capacity $\\le\\ell$ includes all functions of the leaves. ", "page_idx": 5}, {"type": "text", "text": "Overview of the Proof Idea: For illustration, let us consider the case where $T$ is a binary tree of depth $\\ell$ with $M=\\left[{\\frac{\\frac{1+\\lambda}{2}}{\\frac{1-\\lambda}{2}}}\\quad{\\frac{\\frac{1-\\lambda}{2}}{\\frac{1+\\lambda}{2}}}\\right]$ , such matrix has eigenvalues $\\lambda$ and 1. Here we assume $2\\lambda^{2}<1$ ", "page_idx": 6}, {"type": "text", "text": "We recall that for this binary symmetric broadcasting process, it is information-theoretically impossible to recover the root label from the leaves below the KS bound. This implies that all polynomials of $X_{L}$ have vanishing correlation with $X_{\\rho}$ . Still, we use this simple process to illustrate the proof idea as our arguments for low-degree polynomials generalize to general broadcasting processes below the Kesten-Stigum threshold, including cases where it is information theoretically possible to estimate the root from the leaves non-trivially (in such cases there exist functions $f$ sothat lim i $\\operatorname{nf}_{\\ell\\to\\infty}\\operatorname{Corr}(f(X_{L}),X_{\\rho})>0)$ ", "page_idx": 6}, {"type": "text", "text": "Now, let us consider degree-1 polynomials. Suppose $f$ is a $\\mathcal{A}_{1}$ -polynomial (equivalently, of EfronStein degree 1), we can express it in the form ", "page_idx": 6}, {"type": "equation", "text": "$$\nf(x_{L})=\\sum_{u\\in L}f_{u}(x_{u}),\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "where each $f_{u}$ is a function of $x_{u}$ . Given our focus on the variance, we may assume $\\mathbb{E}f_{u}(X_{u})=0$ for each $u~\\in~L$ . Then, our goal is to prove $\\mathbb{E}\\big[\\big(\\mathbb{E}[f(X_{L})\\,\\vert\\,X_{\\rho}]\\big)^{2}\\big]$ is negligible comparing to $\\mathbb{E}\\big[(f(X_{L}))^{2}\\big]$ . Following from the Cauchy-Schwarz inequality that ", "page_idx": 6}, {"type": "equation", "text": "$$\n(\\sum_{i\\in[m]}a_{i})^{2}=(\\sum_{i\\in[m]}1\\cdot a_{i})^{2}\\leq m\\sum_{i\\in[k]}a_{i}^{2},\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "we have ", "page_idx": 6}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{E}\\big[\\big(\\mathbb{E}[f(X_{L})\\,|\\,X_{\\rho}]\\big)^{2}\\big]\\leq\\!|L|\\displaystyle\\sum_{u\\in L}\\mathbb{E}\\big[\\big(\\mathbb{E}[f_{u}(X_{u})\\,|\\,X_{\\rho}]\\big)^{2}\\big]}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\lesssim2^{\\ell}\\displaystyle\\sum_{u\\in L}\\lambda^{2\\ell}\\mathbb{E}\\big[(f_{u}(X_{u}))^{2}\\big]=(2\\lambda^{2})^{\\ell}\\displaystyle\\sum_{u\\in L}\\mathbb{E}\\big[(f_{u}(X_{u}))^{2}\\big],}\\end{array}\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "where the second inequality is derived from the variance decay property of in a Markov Chain. Thus, if we can establish $\\begin{array}{r}{\\sum_{u\\in L}\\dot{\\mathbb{E}}\\big[(f_{u}(X_{u}))^{2}\\big]}\\end{array}$ is at the same order as $\\mathbb{E}\\big[(f(\\mathbf{\\dot{X}}_{L}))^{2}\\big]$ , the proof is complete. Noticethat ", "page_idx": 6}, {"type": "equation", "text": "$$\n\\mathbb{E}\\big[(f(X_{L}))^{2}\\big]=\\sum_{u,v\\in L}\\mathbb{E}[f_{u}(X_{u})f_{v}(X_{v})]=\\sum_{u\\in L}\\mathbb{E}\\big[(f_{u}(X_{u}))^{2}\\big]+\\sum_{u\\neq v\\in L}\\mathbb{E}[f_{u}(X_{u})f_{v}(X_{v})].\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "Thus, the goal here is to show ", "page_idx": 6}, {"type": "equation", "text": "$$\n\\Big|\\sum_{u\\neq v\\in L}\\mathbb{E}[f_{u}(X_{u})f_{v}(X_{v})]\\Big|<c\\sum_{u\\in L}\\mathbb{E}\\big[(f_{u}(X_{u}))^{2}\\big],\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "for some constant $c\\in(0,1)$ , which in turn implies the desired result: ", "page_idx": 6}, {"type": "equation", "text": "$$\n\\mathbb{E}\\big[\\big(\\mathbb{E}[f(X_{L})\\,|\\,X_{\\rho}]\\big)^{2}\\big]\\lesssim(2\\lambda^{2})^{\\ell}\\sum_{u\\in\\cal L}\\mathbb{E}\\big[(f_{u}(X_{u}))^{2}\\big]\\lesssim(2\\lambda^{2})^{\\ell}{\\frac{1}{1-c}}\\mathbb{E}\\big[(f(X_{L}))^{2}\\big].\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "Roughly speaking, (4) holds if for most pairs $u$ and $v$ Within $L$ , the correlation between $f_{u}(X_{u})$ and $f_{v}(\\bar{X}_{v})$ is sufficiently small, which is the case for degree-1 polynomials. ", "page_idx": 6}, {"type": "text", "text": "Now, let us take a closer look. Fix any two vertices $u$ and $v$ in $L$ ,with $w$ as their nearest common ancestor. Suppose $u\\leq w_{1}$ and $v\\leq w_{2}$ . Let $X_{\\not\\le w_{1}}=(X_{u^{\\prime}})_{u^{\\prime}\\not\\le w_{1}}$ .We have ", "page_idx": 6}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\left|\\mathbb{E}[f_{u}(X_{u})f_{v}(X_{v})]\\right|=\\!\\!\\left|\\mathbb{E}[\\mathbb{E}[f_{u}(X_{u})\\,|\\,X_{\\underline{{\\mathcal{L}}}w_{1}}]f_{v}(X_{v})]\\right|}\\\\ &{\\qquad\\qquad\\qquad\\le\\!\\sqrt{\\mathbb{E}[(\\mathbb{E}[f_{u}(X_{u})\\,|\\,X_{\\underline{{\\mathcal{L}}}w_{1}}])^{2}]}\\cdot\\sqrt{\\mathbb{E}[(f_{v}(X_{v}))^{2}]}}\\\\ &{\\qquad\\qquad\\qquad\\lesssim\\!\\lambda^{\\mathrm{h}(w)}\\sqrt{\\mathbb{E}[(f_{u}(X_{u}))^{2}]}\\sqrt{\\mathbb{E}[(f_{v}(X_{v}))^{2}]},}\\end{array}\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "where the last inequality follows from the variance decay of the Markov Chain for length $\\operatorname{h}(w)$ .The above inequality implies that the correlation between $f_{u}(X_{u})$ and $f_{v}(X_{v})$ is at most of order $\\lambda^{\\mathrm{h}(w)}$ ", "page_idx": 6}, {"type": "text", "text": "The above bound can be improved to $\\lambda^{2k}$ by also taking the conditional expectation $\\mathbb{E}[f_{v}(X_{v})\\mid X_{\\mathbb{Z}w_{2}}]$ into account, which requires the Markov Property that $X_{u}$ and $X_{v}$ are independent conditioned on $X_{w}$ . From here, one can properly arrange the terms and apply Cauchy-Schwarz inequality to show (4) holds. ", "page_idx": 7}, {"type": "text", "text": "Our proof of the main theorem tries to generalize the argument above to low degree polynomials. Let us summarize it by the following five pieces of descriptions. ", "page_idx": 7}, {"type": "text", "text": "1. Bounding Covariance: First, we generalized the idea on how (5) works for degree-1 polynomials Suppose $f_{\\alpha}$ and $f_{\\beta}$ are two functions so that the following holds. ", "page_idx": 7}, {"type": "text", "text": "1. $f_{\\alpha}(x_{S})$ is a function of $x_{S}$ for some set $S\\subseteq L$ such that ", "page_idx": 7}, {"type": "equation", "text": "$$\n\\mathbb{E}[(\\mathbb{E}[f_{\\alpha}(X_{S})\\,|\\,X_{\\mathcal{Z}w^{\\prime}}])^{2}]\\ll(\\mathbb{E}(f_{\\alpha}(X_{S}))^{2},\n$$", "text_format": "latex", "page_idx": 7}, {"type": "text", "text": "whereweuse $a\\ll b$ to indicate $a$ is much smaller than $b$ .We keep this not precise to avoid technical details, but expect that the ratio is exponentially small in $\\mathrm{h}(w^{\\prime})$ ", "page_idx": 7}, {"type": "text", "text": "2. $f_{\\beta}(x_{S^{\\prime}})$ is a function of $x_{S^{\\prime}}$ With $S^{\\prime}\\subseteq L$ satisfying $S^{\\prime}\\cap\\{v^{\\prime}:v^{\\prime}\\leq w^{\\prime}\\}=\\varnothing.$ ", "page_idx": 7}, {"type": "text", "text": "Then, following the same derivation as shown in (5) we have ", "page_idx": 7}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\left|\\mathbb{E}[f_{\\alpha}(X_{S})f_{\\beta}(X_{S^{\\prime}})]\\right|=\\left|\\mathbb{E}\\big[\\mathbb{E}[f_{\\alpha}(X_{S})\\,|\\,X_{\\mathcal{L}^{w^{\\prime}}}]f_{\\beta}(X_{S^{\\prime}})\\big]\\right|\\ll\\sqrt{\\mathbb{E}[(f_{\\alpha}(X_{S}))^{2}]}\\sqrt{\\mathbb{E}[(f_{\\beta}(X_{S^{\\prime}}))^{2}]}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 7}, {"type": "text", "text": "(See Figure 3 for an illustration.) ", "page_idx": 7}, {"type": "image", "img_path": "3iOefhez5e/tmp/5a5dfcf2c17b432ceef7345db61f84f1c9263977692ea1f11ea0d88477b39585.jpg", "img_caption": [], "img_footnote": [], "page_idx": 7}, {"type": "text", "text": "Figure 3: In the left figure, the purple dots represent the corresponding input variables for $f_{\\alpha}$ , and the yellow dots represent the corresponding input variables for $f_{\\beta}$ . In the right figure, the purple dots represent the corresponding input variables for $\\mathbb{E}[f_{\\alpha}(X)\\,|\\,X_{\\not\\leq w_{1}}]$ and the variables do not involve $x_{v}$ for vertex $v$ not illustrated due to the Markov property. ", "page_idx": 7}, {"type": "text", "text": "II. Choosing a good decomposition of the function: In essence, our proof strategy for any given function $f(\\boldsymbol{x}_{L})$ with $\\mathbb{E}f(X_{L})\\,=\\,0$ revolves around decomposing $f(\\boldsymbol x_{L})$ into a sum of functions $f_{\\alpha}({\\boldsymbol{x}}_{L})$ for $\\alpha$ in some index set $\\mathcal{T}$ , such that ", "page_idx": 7}, {"type": "text", "text": "1. $|{\\mathcal{T}}|\\lesssim2^{\\ell}$   \n2. For each $\\alpha$ $\\mathbb{E}f_{\\alpha}(X_{L})=0$ and $\\mathbb{E}[(\\mathbb{E}[f_{\\alpha}(X_{L})\\,|\\,X_{\\rho}]^{2}]\\ll\\mathbb{E}[(f_{\\alpha}(X_{L}))^{2}],$   \n3. Whenever $\\alpha\\neq\\beta$ , we can find $w\\in T$ so that $f_{\\alpha}$ and $f_{\\beta}$ satisfy the covariance bound in I. (Possibly with a switch of the roles of $\\alpha$ and $\\beta$ ", "page_idx": 7}, {"type": "text", "text": "Let us remark that while we are writing $f_{\\alpha}({\\boldsymbol{x}}_{L})$ , it does not mean that $f_{\\alpha}$ depends on every leave variables. ", "page_idx": 7}, {"type": "text", "text": "If this is the case, then we could follow the argument in the degree 1 case to show that desired result holds. ", "page_idx": 7}, {"type": "text", "text": "II.From $\\mathcal{A}_{k}$ polynomialsto $\\boldsymbol{A}_{k+1}$ polynomials: The proof of the main theorem builds on $\\mathbf{I}$ and II and advancing through a recursion on the fractal capacity of the function. This recursive approach relies on the following property: ", "page_idx": 7}, {"type": "text", "text": "Suppose we have shown the second moment decay $\\mathcal{A}_{k}$ -polynomials with mean O in the following sense: For every $\\mathcal{A}_{k}$ -polynomial $f(x_{S})$ with mean O and variable $x_{S}$ where $S\\subseteq\\{v\\in L:v\\leq\\rho^{\\prime}\\}$ for some vertex $\\rho^{\\prime}$ \uff0c ", "page_idx": 7}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathbb{E}[(\\mathbb{E}[f(X_{L})\\,|\\,X_{\\rho^{\\prime}}])^{2}]\\leq(2\\lambda^{2})^{\\mathrm{h}(\\rho^{\\prime})-\\mathrm{h}_{\\mathcal{A}_{k}}}\\mathbb{E}[(f(X_{L}))^{2}],}\\end{array}\n$$", "text_format": "latex", "page_idx": 7}, {"type": "text", "text": "where $\\mathrm{h}_{\\mathcal{A}_{k}}$ is some penalty constant depending on $\\mathcal{A}_{k}$ . (The bigger the value $\\mathrm{h}_{\\mathcal{A}_{k}}$ , the weaker the second moment decay.) ", "page_idx": 8}, {"type": "text", "text": "Consider a specific type of $\\boldsymbol{A}_{k+1}$ -polynomials. Fix a pivot vertex $w$ with $\\operatorname{h}(w)$ large enough, let $x_{\\le w_{i}}=(x_{v})_{v\\le w_{i}}$ for $i\\in$ [2]. Let $g$ be a function of the form ", "page_idx": 8}, {"type": "equation", "text": "$$\ng(x)=g(x_{\\leq w_{1}},x_{\\leq w_{2}})=\\sum_{\\alpha\\in\\mathcal{I}}g_{\\alpha,1}(x_{\\leq w_{1}})\\cdot g_{\\alpha,2}(x_{\\leq w_{2}}),\n$$", "text_format": "latex", "page_idx": 8}, {"type": "text", "text": "where $\\mathcal{I}$ is a finite index set and every $g_{\\alpha,i}$ is an $\\mathcal{A}_{k}$ -polynomial whose variables are $x_{\\leq w_{i}}$ (more precisely, its variables are $x_{S^{\\prime}}$ where $S^{\\prime}\\subseteq\\{v\\in L:v\\leq w_{i}\\})$ and $\\mathbb{E}g_{\\alpha,i}(X_{\\leq w_{i}})=0$ Then, the function $g(x)$ is a $\\mathcal{A}_{k+1}$ -polynomial with variable $x_{S}$ for $S\\subseteq\\{v\\in L:v\\leq w\\}$ ", "page_idx": 8}, {"type": "text", "text": "Observe that, if we fix $x_{\\leq w_{2}}$ , then $x_{\\le w_{1}}\\mapsto g(x_{\\le w_{1}},x_{\\le w_{2}})$ is an $\\mathcal{A}_{k}$ -polynomial with variable $x_{S^{\\prime}}$ for $S^{\\prime}\\subseteq\\{v\\in L:v\\leq\\bar{w}_{1}\\}$ and mean O. This allows us to apply the assumption for $\\mathcal{A}_{k}$ polynomials to show ", "page_idx": 8}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathbb{E}[(\\mathbb{E}[g(X_{\\leq w_{1}},x_{\\leq w_{2}})\\,|\\,X_{\\not\\leq w_{1}}])^{2}]\\lesssim(d\\lambda^{2})^{\\mathrm{h}(w)-\\mathrm{h}_{A_{k}}}\\mathbb{E}[(g(X_{\\leq w_{1}},x_{\\leq w_{2}}))^{2}].}\\end{array}\n$$", "text_format": "latex", "page_idx": 8}, {"type": "text", "text": "Clearly, the same inequality holds with the roles of $x_{\\le w_{1}}$ and $x_{\\le w_{2}}$ switched. ", "page_idx": 8}, {"type": "text", "text": "Base on this, one key step in the paper is to show $g$ satisfies ", "page_idx": 8}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathbb{E}[(\\mathbb{E}[g(X_{\\leq w_{1}},X_{\\leq w_{2}})\\,|\\,X_{\\not\\leq w_{i}}])^{2}]\\lesssim(d\\lambda^{2})^{\\mathrm{h}(w)-\\mathrm{h}_{A_{k}}}\\mathbb{E}[(g(X_{\\leq w_{1}},X_{\\leq w_{2}}))^{2}]\\,\\mathrm{for}\\;i\\in[2].}\\end{array}\n$$", "text_format": "latex", "page_idx": 8}, {"type": "text", "text": "This inequality is immediate if $X_{\\leq w_{1}}$ and $X_{\\leq w_{2}}$ are independent, which is not the case in the broadcasting process. One of the main technical challenges in the proof is to show that the inequality holds when $X_{\\leq w_{1}}$ and $X_{\\leq w_{2}}$ are conditionally independent given $X_{w}$ by the Markov Property. It turns out to impose a significant technical challenge when some entries of $M$ can be 0. ", "page_idx": 8}, {"type": "text", "text": "Observe that (7) not only implies $g$ satisfies the desired second moment decay for $\\mathbf{II}(2)$ , but also $\\mathbf{I}(1)$ with $w^{\\prime}$ to be either $w_{1}$ or $w_{2}$ . Indeed, these two properties will also hold for ${\\tilde{g}}(x):=g(x)-\\mathbb{E}g(X)$ the normalized $g$ with mean O, due to $(\\mathbb{E}g(X))^{2}$ is negligible comparing to $\\mathbb{E}g(X)^{2}$ ", "page_idx": 8}, {"type": "text", "text": "IV. A closer look at the decomposition: ", "text_level": 1, "page_idx": 8}, {"type": "text", "text": "Consider any $\\boldsymbol{A}_{k+1}$ -polynomial $f$ of variable $x_{S}$ for $S\\subseteq\\{v\\in L:v\\leq\\rho^{\\prime}\\}$ for some vertex $\\rho^{\\prime}$ Before we proceed to the discussion of the decomposition, we remark that one cannot simply express $f$ in the form of $\\tilde{g}$ described above with any pivot vertex $w$ ", "page_idx": 8}, {"type": "text", "text": "Let us give an example to illustrate why: Consider two functions $f_{1},f_{2}$ , where $f_{i}$ is a function of $x_{S^{\\prime}}$ with $S^{\\prime}\\subseteq\\{v\\in\\bar{L}:v\\leq\\rho_{i}^{\\prime}\\}$ and $S^{\\dot{\\prime}}\\in\\mathcal{A}_{k+1}\\backslash\\mathcal{A}_{k}$ . Let $f=f_{1}+f_{2}$ . Then one can justify that $f$ cannot be expressed in the form of $\\tilde{g}$ with any pivot $w$ by using the property \"if we fix $x_{\\leq w_{2}}$ , then $x_{x\\leq w_{1}}\\mapsto g(x_{\\leq w_{1}},x_{\\leq w_{2}})$ is a $\\mathcal{A}_{k}$ -polynomial\" discucssed in $\\mathbf{III}$ to derive a contradiction. ", "page_idx": 8}, {"type": "text", "text": "Thewaywedecompose $f$ is to express it as a sum of functions of the form $\\tilde{g}(x)$ in IlI. While the actual decomposition requires a bit more adjustment, it follows from the idea to decompose $f$ in the form ", "page_idx": 8}, {"type": "equation", "text": "$$\nf=\\sum_{w\\in{\\mathcal{Z}}}f_{w},\n$$", "text_format": "latex", "page_idx": 8}, {"type": "text", "text": "where the index set $\\mathcal{T}$ is the set of vertices of $T$ with height slightly greater than $\\mathrm{h}_{\\mathcal{A}_{k}}$ (to ensure correlation decay). Each $f_{w}$ is a function with variable $x_{S}$ for $S\\sp{\\sp{\\bullet}\\subset}\\{u\\in L:u\\leq w\\}$ satisfies the description of ${\\tilde{g}}(x)$ in I\u2162I. ", "page_idx": 8}, {"type": "text", "text": "Observe that this decomposition satisfies the description in $\\mathbf{II}$ ", "page_idx": 8}, {"type": "text", "text": "\u00b7 The size of $\\mathcal{T}$ is bounded by $2^{\\ell}+2^{\\ell-1}+\\cdot\\cdot\\cdot1\\leq2^{\\ell+1}$   \n\u00b7 The second moment decay property of $f_{w}$ follows from III.   \n\u00b7 Finally, consider $u,v\\in{\\mathcal{T}}$ If $v\\,<\\,u$ say $v\\leq u_{1}$ , then $f_{u}$ and $f_{v}$ satisies the covariance bound condition stated in $\\mathbf{I}$ with $f_{\\alpha}\\;=\\;f_{u},~f_{\\beta}\\;=\\;f_{2}$ , and $w^{\\prime}\\;=\\;u_{2}$ . The case when $u<v$ is similar. When $u$ and $v$ are not comparable, then following the Markov Property, $\\mathbb{E}[f_{u}(X)f_{v}(X)]=\\mathbb{E}\\mathbb{E}[f_{u}(X)\\,|\\,X_{\\neq w}]\\mathbb{E}[f_{v}(\\bar{X})\\,|\\,X_{\\neq w}]$ with $w$ being the nearest common ancestor of $u$ and $v$ and $X_{\\not\\prec w}=(\\dot{X}_{w^{\\prime}})_{w^{\\prime}\\not\\prec w}$ , which makes it easier to show the covariance bound. (See Figure 4 for an illustration.) ", "page_idx": 8}, {"type": "image", "img_path": "3iOefhez5e/tmp/d3a07a06803cc1c4c65e836fd3a9e2a7c6bc750b45a437466a71c1ac44ea4a54.jpg", "img_caption": [], "img_footnote": [], "page_idx": 9}, {"type": "text", "text": "Figure 4: In both figures, the purple dots represent the corresponding input variables for $f_{u}$ , and the yellow dots represent the corresponding input variables for $f_{v}$ . In the left figure, we have $v\\leq u_{1}<u$ In the right figure, we have $u$ and $v$ are incomparable and $w$ is the nearest common ancestor. ", "page_idx": 9}, {"type": "text", "text": "With this desirable decomposition, one could try to apply some argument similar to the degree-1 case to show the second moment decay (6) for mean 0 $\\mathcal{A}_{k+1}$ -polynomials with a slightly bigger penalty constant $\\mathrm{h}_{{A_{k+1}}}$ than $\\mathrm{h}_{\\mathcal{A}_{k}}$ ", "page_idx": 9}, {"type": "text", "text": "V. Overview on the induction Given the decomposition of $f$ as described in IV, together with the second moment assumption (6) on $\\mathcal{A}_{k}$ -polynomials described in $\\mathbf{III}$ the proof of the main theorem proceeds by induction. The goal is to show that the penalty constant $\\mathrm{h}_{\\mathcal{A}_{k}}$ associated with $\\mathcal{A}_{k}$ , which appeared (6), satisfies the following recursive inequality: ", "page_idx": 9}, {"type": "equation", "text": "$$\n{\\mathrm{h}}_{A_{k+1}}\\leq{\\mathrm{h}}_{A_{k}}+C,{\\mathrm{~and~h}}_{A_{1}}\\leq C\n$$", "text_format": "latex", "page_idx": 9}, {"type": "text", "text": "for some constant $C$ depending on $M$ and $d\\lambda^{2}$ . If true, by taking $k$ to be proportional to $\\ell/C$ , then the theorem follows. The proof of the theorem requires a careful analysis of the covariance and variance decay to demonstrate that it resembles the behavior observed in the degree-1 case, in order to capture the Kesten-Stigum bound. ", "page_idx": 9}, {"type": "text", "text": "Comparison to other work in low-degree polynomials While some high-level ideas align with previous work in low degree polynomials mentioned fore, our approach focuses on establishing lowdegree lower bounds in a setting where direct comparisons are challenging due to structural differences. Specifically, our work addresses the broadcasting process on trees, where the underlying structures are highly correlated and do not naturally lend themselves to a product measure representation, presenting unique technical challenges not encountered in more independent setups. ", "page_idx": 9}, {"type": "text", "text": "Acknowledgments ", "text_level": 1, "page_idx": 10}, {"type": "text", "text": "Han Huang was supported by Elchanan Mossel's Vannevar Bush Faculty Fellowship ONR-NO0014- 20-1-2826 and by Elchanan Mossel's Simons Investigator award (622132). Elchanan Mossel was partially supported by Bush Faculty Fellowship ONR-N00014-20-1-2826, Simons Investigator award (622132), ARO MURI W911NF1910217 and NSF award CCF 1918421. ", "page_idx": 10}, {"type": "text", "text": "References ", "text_level": 1, "page_idx": 10}, {"type": "text", "text": "[1]  Emmanuel Abbe. Community detection and stochastic block models: recent developments. The Journal of Machine Learning Research, 18(1):6446-6531, 2017.   \n[2] Emmanuel Abbe and Colin Sandon. Proof of the achievability conjectures for the general stochastic block model. Communications on Pure and Applied Mathematics, 71(7):1334-1406, 2018. [3]  Afonso Bandeira, Amelia Perry, and Alexander S. Wein. Notes on computational-to-statistical gaps: predictions using statistical physics. Port. Math., 75(2), 2018.   \n[4]  Afonso S Bandeira, Dmitriy Kunisky, and Alexander S Wein. Computational hardness of certifying bounds on constrained pca problems. In ITCS, 2020.   \n[5]  Jess Banks, Cristopher Moore, Joe Neeman, and Praneeth Netrapalli. Information-theoretic thresholds for community detection in sparse networks. In Conference on Learning Theory, pages 383-416. PMLR, 2016.   \n[6] P. M. Bleher, J. Ruiz, and V. A. Zagrebnov. On the purity of the limiting Gibbs state for the Ising model on the Bethe lattice. J. Statist. Phys., 79(1-2):473-482, 1995.   \n[7] Charles Bordenave, Marc Lelarge, and Laurent Massouli\u00e9. Non-backtracking spectrum of random graphs: community detection and non-regular ramanujan graphs. In Foundations of Computer Science (FOCS), 2015 IEEE 56th Annual Symposium on, pages 1347-1357. IEEE, 2015.   \n[8]  C. Borgs, J. Chayes, E. Mossel, and S. Roch. The kesten-stigum reconstruction bound is tight for roughly symmetric binary channels. In Proceedings of IEEE FOCS 2006, pages 518-530, 2006.   \n[9]  Guy Bresler and Brice Huang. The algorithmic phase transition of random $k$ -sat for low degree polynomials. In FOCS, 2021.   \n[10] Wei-Kuo Chen, David Gamarnik, Dmitry Panchenko, and Mustazee Rahman. Suboptimality of local algorithms for a class of max-cut problems. The Annals of Probability, 47(3):1587-1618, 2019.   \n[11]  A. Decelle, F. Krzakala, C. Moore, and L. Zdeborova. Asymptotic analysis of the stochastic block model for modular networks and its algorithmic applications. Physics Review $E$ 84:066106, Dec 2011.   \n[12]  Aurelien Decelle, Florent Krzakala, Cristopher Moore, and Lenka Zdeborova. Asymptotic analysis of the stochastic block model for modular networks and its algorithmic applications. Physical Review E, 84(6):066106, 2011.   \n[13]  Yash Deshpande and Andrea Montanari. Finding hidden cliques of size $\\sqrt{N/e}$ in nearly linear time. Foundations of Computational Mathematics, 15(4):1069-1128, 2015.   \n[14] W. S. Evans, C. Kenyon, Yuval Y. Peres, and L. J. Schulman. Broadcasting on trees and the Ising model. Ann. Appl. Probab., 10(2):410-433, 2000.   \n[15] David Gamarnik, Aukosh Jagannath, and Alexander S Wein. Low-degree hardness of random optimization problems. In 2020 IEEE 61st Annual Symposium on Foundations of Computer Science (FOCS), pages 131-140. IEEE, 2020.   \n[16]  David Gamarnik and Madhu Sudan. Limits of local algorithms over sparse random graphs. In Proceedings of the 5th conference on Innovations in theoretical computer science, pages 369-376, 2014.   \n[17] Justin Holmgren and Alexander S Wein. Counterexamples to the low-degree conjecture. In ITCS, 2020.   \n[18]  Samuel Hopkins. Statistical inference and the sum of squares method. PhD thesis, Cornell University, 2018.   \n[19]  Samuel Hopkins and David Steurer. Efcient bayesian estimation from few samples: community detection and related problems. In 2017 IEEE 58th Annual Symposium on Foundations of Computer Science (FOCS), pages 379-390. IEEE, 2017.   \n[20] D. Ioffe. Extremality of the disordered state for the Ising model on general trees. In Trees (Versailles, 1995), volume 40 of Progr. Probab., pages 3-14. Birkhauser, Basel, 1996.   \n[21] D. Ioffe. On the extremality of the disordered state for the Ising model on the Bethe lattice. Lett. Math. Phys., 37(2):137-143, 1996.   \n[22] Harry Kesten and Bernt P Stigum.  Additional limit theorems for indecomposable multidimensional galton-watson processes. The Annals of Mathematical Statistics, 37(6):1463-1481, 1966.   \n[23] Frederic Koehler and Elchanan Mossel. Reconstruction on trees and low-degree polynomials. Advances in Neural Information Processing Systems, 35:18942-18954, 2022.   \n[24] D. Kunisky, A.S. Wein, and A.S. Bandeira. Notes on computational hardness of hypothesis testing: Predictions using the low-degree likelihood ratio. Mathematical Analysis, its Applications and Computation. ISAAC 2019. Springer Proceedings in Mathematics and Statistics, 385, 2022.   \n[25] Dmitriy Kunisky, Alexander S Wein, and Afonso S Bandeira. Notes on computational hardness of hypothesis testing: Predictions using the low-degree likelihood ratio. arXiv preprint arXiv:1907.11636, 2019.   \n[26]  Cheng Mao and Alexander S Wein. Optimal spectral recovery of a planted vector in a subspace. arXiv preprint arXiv:2105.15081, 2021.   \n[27] M. Mezard and A. Montanari. Reconstruction on trees and the spin glass transition. Journal of Statistical Physics, 124:1317-1350, 2006.   \n[28] Sidhanth Mohanty, Siqi Liu, and Prasad Raghavendra. On statistical inference when fixed points of belief propagation are unstable. In IEEE 62st Annual Symposium on Foundations of Computer Science (FOCS), 2021.   \n[29]  AndreaMontanari and Alexander S.Wein. Equivalence of approximate message passing and low-degree polynomials in rank-one matrix estimation. Probability Theory and Related Fields, 2024.   \n[30] E. Mossel. Reconstruction on tres: beating the second eigenvalue. Ann. Appl. Probab., 11(1):285-300, 2001.   \n[31] E. Mossel. Phase transitions in phylogeny. Trans. Amer. Math. Soc., 356(6):2379-2404 (electronic), 2004.   \n[32] E. Mossel. Survey: Information fow on trees. In J. Nestril and P. Winkler, editors, Graphs, Morphisms and Statistical Physics. DIMACS series in discrete mathematics and theoretical computer science, pages 155-170. 2004.   \n[33] E. Mossel, J. Neeman, and A. Sly. Reconstruction and estimation in the planted partition model. Probability Theory and Related Fields, (3-4):431-461, 2015. The Arxiv version of this paper is titled Stochastic Block Models and Reconstruction.   \n[34] Elchanan Mossel. Combinatorial statistics and the sciences. In International Congress of Mathematicians: 2022 July 6-14, volume 6, chapter 5553, pages 1-20. 2023.   \n[35] Elchanan Mossel, Joe Neeman, and Allan Sly. A proof of the block model threshold conjecture. Combinatorica, 38(3):665-708, 2018.   \n[36]  Elchanan Mossel and Yuval Peres. Information flow on trees. The Annals of Applied Probability, 13(3):817-844, 2003.   \n[37]  Elchanan Mossel, Allan Sly, and Youngtak Sohn. Exact phase transitions for stochastic block models and reconstruction on trees. In STOC 2023: Proceedings of the 55th Annual ACM Symposium on Theory of Computing, pages 96-102, 2023.   \n[38] Federico Ricci-Tersenghi, Guilhem Semerjian, and Lenka Zdeborova. Typology of phase transitions in bayesian inference problems. Physical Review E, 99(4):042109, 2019.   \n[39]  A. Sly. Reconstruction of random colourings. Comm. Math. Phys., 288, 2009.   \n[40]  Alexander S Wein. Optimal low-degree hardness of maximum independent set. arXiv preprint arXiv:2010.06563, 2020.   \n[41]  Lenka Zdeborova and Florent Krzakala. Statistical physics of inference: Thresholds and algorithms. Advances in Physics, 65(5), 2016. ", "page_idx": 10}, {"type": "text", "text": "", "page_idx": 11}, {"type": "text", "text": "", "page_idx": 12}, {"type": "text", "text": "Appendix ", "text_level": 1, "page_idx": 13}, {"type": "text", "text": "Overview ", "text_level": 1, "page_idx": 13}, {"type": "text", "text": "\u00b7 In Section A, we give additional notations and basic tools.   \n\u00b7 In Section B, we formulate the main theorem we want to prove as an induction statement.   \n\u00b7 In Section C, we discuss the case for degree 1 polynomial, which prove the base case of the induction in the theorem, and the results for degree 1 polynomial will be used in the inductive step.   \n\u00b7 In Section D, we give a procedure to decompose $\\boldsymbol{\\mathrm{\\Delta}}\\boldsymbol{\\mathrm{\\Omega}}_{\\boldsymbol{B}}$ polynomial $f$ for a given collection $\\boldsymbol{\\mathrm{\\Delta}}\\boldsymbol{\\mathrm{\\Omega}}^{\\beta}$   \n\u00b7 In Section E and F, we derive the proof of Theorem B.6, the inductive step for proving Theorem B.1.   \n\u00b7 In Section G and H, we derive the main result in the general case.   \n\u00b7 In Section I, we provide a proof of Proposition C.3, which is one technical obstacle for getting our main result from Theorem B.1 to the general setting (Theorem 1.6). It is postponed to this section due to the proof is essentially a result about Markov Chain.   \n\u00b7 In Section J, we provided some standard result for decay of Markov Chain. ", "page_idx": 13}, {"type": "text", "text": "A  Additional Notations and Tools ", "text_level": 1, "page_idx": 13}, {"type": "text", "text": "Let us begin with the proof of Remark 1.15 which shows $\\mathcal{A}_{k}$ contains all non-empty subsets of $L$ of size $\\leq k$ ", "page_idx": 13}, {"type": "text", "text": "Proof of Remark 1.15. The proof will be carried out by induction on $k$ . The base case with $k=1$ follows from the definition $\\mathbf{\\dot{\\mathcal{A}}_{1}}:=\\left\\{\\{v\\}:\\,v\\in L\\right\\}$ . Suppose the claim holds up to some positive integer $k$ . Let $\\varnothing\\neq S\\subseteq L$ of size $\\vert S\\vert\\le k+1$ If $|S|\\leq k$ , then $S\\in{\\mathcal{A}}_{k}\\subseteq{\\mathcal{B}}({\\mathcal{A}}_{k})={\\mathcal{A}}_{k+1}$ In the case $|S|=k+1\\geq2$ , we first observe that $\\rho(S)$ is not a leave. Consider the branch decomposition of $S$ (See Definition 1.9): ", "page_idx": 13}, {"type": "equation", "text": "$$\nS=\\sqcup_{i\\in I(S)}S_{i}.\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "Because $|I(S)|\\,>\\,1$ , for each $i\\,\\in\\,I(S)$ we have $|S_{i}|\\,<\\,|S|\\,=\\,k+1$ .Therefore, $S_{i}\\,\\in\\,A_{k}$ for $i\\in I(S)$ , which in turn implies $S\\in{\\dot{B}}({\\mathcal{A}}_{k})={\\mathcal{A}}_{k+1}$ . Therefore, the claim follows. ", "page_idx": 13}, {"type": "text", "text": "Now, to show the second statement. For every node $w$ , let $S_{w}=\\{v\\in L:v\\leq w\\}$ Observe that if $w$ is $k-1$ layers above $L$ then $S_{w}$ are the $(k-1)$ th descendants of $w$ , which has size $|S_{w}|=d^{k-1}$ ", "page_idx": 13}, {"type": "text", "text": "We claim that for $w$ which are $k-1$ layers above $L$ , then $S_{w}\\in A_{k}$ . Let us prove the claim by induction. First, it is clear that for $w\\in L$ $S_{w}=\\{w\\}\\in\\mathcal{A}_{1}$ . Suppose the statement holds up to $k$ Take any $w$ which is $k$ layer above $L$ . Then, the branch decomposition of $\\begin{array}{r}{S_{w}=\\sqcup_{i\\in[d]}S_{w_{i}}}\\end{array}$ With each $w_{i}$ is $k-1$ layer above $L$ , we have $S_{w_{i}}\\in A_{k}$ . Hence, $S_{w}\\in A_{k+1}$ due to $\\mathcal{A}_{k+1}=\\mathcal{B}(\\mathcal{A}_{k})$ ", "page_idx": 13}, {"type": "text", "text": "A.1  Additional notations ", "text_level": 1, "page_idx": 13}, {"type": "text", "text": "For any positive integer $n$ , let $[n]$ denote the set of positive integers from 1 to $n$ , inclusive: $[n]=$ $1,2,\\ldots,n$ . For integers $a$ and $b$ where $a<b$ , let $[a,b]=\\{a,a+1,\\dots,b\\}$ ", "page_idx": 13}, {"type": "text", "text": "Additional Notation for Trees ", "text_level": 1, "page_idx": 13}, {"type": "text", "text": "For $u\\in T$ ,we define ", "page_idx": 13}, {"type": "equation", "text": "$$\nL_{k}(u)\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "to be the set of $k$ th descendants of $u$ . For brevity, let $L_{k}:=L_{k}(\\rho)$ . Further, for $h\\in[0,\\mathrm{h}(u)]$ , let ", "page_idx": 13}, {"type": "equation", "text": "$$\nD_{h}(u)=\\{v\\in T:v\\leq u{\\mathrm{~and~h}}(v)=h\\},\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "namely the set of descendants of $u$ which has height $h$ . Observe that ", "page_idx": 13}, {"type": "equation", "text": "$$\nD_{k}(u)=L_{\\mathrm{h}(u)-k}(u).\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "Last, let ", "page_idx": 14}, {"type": "text", "text": "be the induced subgraph of $T$ with vertex set $\\{v\\in T:v\\leq u\\}$ and $L_{u}=T_{u}\\cap L$ It is worth noting that $T_{u}$ can be seen as a rooted tree with root $u$ and $\\mathrm{h}(u)$ layers, and the $\\mathrm{h}(u)$ th layer is $L_{u}$ ", "page_idx": 14}, {"type": "text", "text": "Additional Notation for collection $A\\subseteq2^{L}\\setminus\\{\\varnothing\\}$ ", "page_idx": 14}, {"type": "text", "text": "Definition A.1. For a given collection of of subsets $A\\subseteq\\mathbf{2}^{L}\\backslash\\{\\varnothing\\}$ we define the following subcollections: For each $u\\in T$ let $\\mathcal{A}_{u}:=\\{S\\in\\mathcal{A}\\,:\\,\\rho(S)=u\\}$ \uff0c $\\dot{A}_{\\leq u}:=\\{S\\in\\mathcal{A}:\\,\\rho(S)\\leq u\\}$ and $A_{<u}:=\\{S\\in\\mathcal{A}:\\,\\rho(S)<u\\}$ ", "page_idx": 14}, {"type": "text", "text": "Notation for Conditional Expectation ", "text_level": 1, "page_idx": 14}, {"type": "text", "text": "Definition A.2. Recall that an antichain $U\\subseteq T$ is a collection of vertices such that no two vertices in $U$ arecomparableunderthe $\\leq$ relation.For $x\\in[q]^{T}$ ,wecandecompose $x$ intheform ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\boldsymbol{x}=(x_{<U},x_{U},x_{\\Xi U}),\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "where ", "page_idx": 14}, {"type": "equation", "text": "$$\nx_{<U}=(x_{v}\\,:\\,\\exists u\\in U\\;s.t.\\;v\\leq u),\\;a n d\\,x_{\\Xi U}=(x_{v}\\,:\\,\\forall u\\in U,v\\not\\leq u)\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "(See Figure 5 for an illustration.) ", "page_idx": 14}, {"type": "image", "img_path": "3iOefhez5e/tmp/ef71c94d71c11b646968b217bc2ccaa251e011f138ff543322827aafec3e0f8c.jpg", "img_caption": [], "img_footnote": [], "page_idx": 14}, {"type": "text", "text": "Figure 5: In this figure, the purple dots represent the set $U$ . The yellow dots represent the vertices corresponding to the variables $x_{<U}$ , and the green dots represent the vertices corresponding to the variables &U. ", "page_idx": 14}, {"type": "text", "text": "Definition A.3. [Conditional Expectation] ", "page_idx": 14}, {"type": "text", "text": "For each antichain $U\\subseteq T$ and $f:[q]^{T}\\rightarrow\\mathbb{R}$ let ", "page_idx": 14}, {"type": "equation", "text": "$$\n(\\mathbb{E}_{U}f)(x):=\\mathbb{E}\\Big[f(X)\\,\\Big|\\,X_{U}=x_{U},\\,X_{\\mathcal{Z}U}=x_{\\mathcal{Z}U}\\Big].\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "To rephrase it, the function $(\\mathbb{E}_{U}f)(x)$ represents the expected value of $f(X)$ condition on $X_{v}=x_{v}$ for all vertices $v$ that are not descendents of any $u\\in U$ . In the case when $U=\\{u\\}$ , we will abuse the notation and denote $\\mathbb{E}_{u}$ as $\\mathbb{E}_{\\{u\\}}$ for $u\\in T$ . Futher, for any $\\mathrm{h}\\in[0,\\ell]$ , we set ", "page_idx": 14}, {"type": "equation", "text": "$$\n(\\mathbb{E}_{\\mathrm{h}}f)(x):=\\mathbb{E}\\Big[f(X)\\,\\Big|\\,\\forall v\\in T\\,\\,\\mathrm{with}\\,\\mathrm{h}(v)\\geq\\mathrm{h},\\,X_{v}=x_{v}\\Big].\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "Remark A.4 (Conditional Expectation and the Markov Property). Suppose $f$ is a function of $x_{L}$ and $U$ an antichain of $T$ .Let ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\tilde{L}=\\{v\\in L\\,:\\,\\exists u\\in U\\mathrm{~s.t.~}v\\leq u\\}\\mathrm{~and~}L^{\\prime}=L\\,\\backslash\\,\\tilde{L}.\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "We remark that by the Markov Property, ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\mathbb{E}_{U}f(x)=\\mathbb{E}_{U}f(x_{U},x_{L^{\\prime}})\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "is a function of $x_{U}$ and $x_{L^{\\prime}}$ . To see that, by the Markov Property, $x_{<U}$ and $x_{\\ensuremath{\\mathbb{Z}}U}$ are independent conditioned on $x_{U}$ . Thus, ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{(\\mathbb{E}_{U}f)(x_{U},x_{\\Xi U})=\\!\\mathbb{E}\\Big[f(X_{\\tilde{L}},X_{L^{\\prime}})\\,\\Big|\\,X_{U}=x_{U},X_{\\Xi U}=x_{\\Xi U}\\Big]}\\\\ &{\\qquad\\qquad\\qquad\\quad=\\!\\mathbb{E}\\Big[f(X_{\\tilde{L}},x_{L^{\\prime}})\\,\\Big|\\,X_{U}=x_{U}\\Big],}\\end{array}\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "which implies $\\mathbb{E}_{U}f$ is a function of $x_{U}$ and $x_{L^{\\prime}}$ . (See Figure 6 for an illustration.) ", "page_idx": 14}, {"type": "image", "img_path": "3iOefhez5e/tmp/55290a90baff93b06a5d949ea602bebaac8e1cafd88995e27eeafeb55b667689.jpg", "img_caption": [], "img_footnote": [], "page_idx": 15}, {"type": "text", "text": "Figure 6:  The purple dots represent the set $U$ . In the left figure, the yellow dots represent the vertices corresponding to the variables of $f$ . In the right figure, the yellow dots represent the vertices corresponding to the variable of $\\mathbb{E}_{U}f$ ", "page_idx": 15}, {"type": "text", "text": "A.2 Basis Functions on $[q]^{L}$ and some decay properties ", "text_level": 1, "page_idx": 15}, {"type": "text", "text": "The following lemma is a well-known statement from Markov-Chain. Let us formulate it using the Broadcasting Process. (For completeness, we include a proof of this lemma in Section J.) ", "page_idx": 15}, {"type": "text", "text": "Lemma A.5. Suppose $M$ is irreducible and aperiodic, then there exists $C=C(M)>1$ so that the following hold: For any $u\\in T$ and $k\\in\\mathbb{N}$ so that $\\mathfrak{p}^{k}(u)=\\mathfrak{p}\\circ\\mathfrak{p}\\circ\\dots\\mathfrak{p}(u),$ the kth ancester of $u$ 1.timnn ", "page_idx": 15}, {"type": "text", "text": "exists. For every function a with variable $x_{u}$ ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\operatorname{Var}\\Big[(\\mathbb{E}_{\\mathfrak{p}^{k}(u)}a)(X_{\\mathfrak{p}^{k}(u)})\\Big]\\leq C k^{2q}\\lambda^{2k}\\operatorname{Var}\\big[a(X_{u})\\big]\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "and ", "page_idx": 15}, {"type": "equation", "text": "$$\nC^{-1}\\left(\\operatorname*{max}_{\\theta\\in[q]}\\left|a(\\theta)-\\mathbb{E}a(X_{u})\\right|\\right)^{2}\\leq\\operatorname{Var}_{Y\\sim\\pi}a(Y)\\leq C\\left(\\operatorname*{max}_{\\theta\\in[q]}\\left|a(\\theta)-\\mathbb{E}a(X_{u})\\right|\\right)^{2}.\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "And from the above two inequalities, adjusting the constant $C$ if necessary, we also have ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\operatorname*{max}_{\\theta\\in[q]}\\big|\\big(\\mathbb{E}_{\\mathfrak{p}^{k}(u)}a\\big)(\\theta)-\\mathbb{E}a(X_{u})\\big|\\leq C k^{q}\\lambda^{k}\\operatorname*{max}_{\\theta\\in[q]}\\big|a(\\theta)-\\mathbb{E}a(X_{u})\\big|.\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "In this paper, we will fix a basis for the space of functions from $[q]$ to $\\mathbb{R}$ for a Markov chain $M$ ", "page_idx": 15}, {"type": "text", "text": "Definition A.6. For a given $q\\times q$ ergodic and irreducible transition matrix $M$ . we fix a basis $\\{\\phi_{i}\\}_{i\\in[0,q-1]}$ for the space of functions from $[q]$ to $\\mathbb{R}$ such that $\\phi_{0}$ is the constant function 1 and $\\phi_{i}$ for $i\\in[q-1]$ are functions such that ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\mathbb{E}_{Y\\sim\\pi}\\phi_{i}(Y)=0\\quad a n d\\quad\\mathbb{E}_{Y\\sim\\pi}\\phi_{i}^{2}(Y)=1.\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "Definition A.7. Suppose a given $\\ell$ layer rooted tree $T$ and $q\\times q$ transition matrix described in Lemma A.5 have been given. For $\\sigma\\in[0,q-1]^{L}$ ,let ", "page_idx": 15}, {"type": "equation", "text": "$$\nS(\\sigma)=\\{v:\\sigma(v)\\neq0\\}\\subseteq L,\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "the set of vertices in $L$ in which $\\sigma$ is non-zero. Let $|\\sigma|=|S(\\sigma)|$ .When $|\\sigma|\\geq1$ ,we define ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\rho(\\sigma)=\\rho(S(\\sigma)).\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "And when $|\\sigma|\\geq2$ we define ", "page_idx": 15}, {"type": "equation", "text": "$$\nI(\\sigma):=I(S(\\sigma)).\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "Further, let ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\phi_{\\sigma}(x):=\\prod_{v\\in L}\\phi_{\\sigma(v)}(x_{v})=\\prod_{v\\in S(\\sigma)}\\phi_{\\sigma(v)}(x_{v}).\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "and ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\tilde{\\phi}_{\\sigma}(x):=\\phi_{\\sigma}(x)-\\mathbb{E}\\phi_{\\sigma}(X).\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "Remark A.8. We remark that \u03a6\u3002(z) is a function with variables  S(t)- ", "page_idx": 15}, {"type": "text", "text": "The fact that $\\phi_{0},\\phi_{1},\\ldots,\\phi_{q-1}$ forms a basis implies that: ", "page_idx": 15}, {"type": "text", "text": "Fact A.9. Every function $f:[q]^{U}\\to\\mathbb{R}$ can be expressed uniquely in the form ", "page_idx": 16}, {"type": "equation", "text": "$$\nf(x)=\\sum_{\\sigma:S(\\sigma)\\subseteq U}c_{\\sigma}\\phi_{\\sigma}(x).\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "Remark A.10. With the above representation, the Efron-Stein degree of function $f$ equalsto the largest magnitude of $|\\sigma|$ among those $\\sigma$ such that $c_{\\sigma}\\neq0$ ", "page_idx": 16}, {"type": "text", "text": "Definition A.11. Given a tree $T$ and a $q\\times q$ ergodic transition matrix $M$ let $\\{\\phi_{i}\\}_{i\\in[q-1]}$ be the functions described in Lemma A.5. For a collection of subsets $A\\subseteq\\mathbf{2}^{L}\\backslash\\{\\varnothing\\}$ ,let ", "page_idx": 16}, {"type": "equation", "text": "$$\n{\\mathcal{F}}(A):=\\{\\sigma\\in[0,q-1]^{L}~:~S(\\sigma)\\in A\\}.\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "For any $\\sigma\\in{\\mathcal{F}}(A)$ with $|\\sigma|>1$ let ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\psi_{\\sigma}(x):=\\prod_{i\\in I(\\sigma)}\\tilde{\\phi}_{P_{i}\\sigma}(x),\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "where, for each $i\\in I(\\sigma)$ $P_{i}\\sigma$ is the restriction of $\\sigma$ to $S(\\sigma)_{i}$ ", "page_idx": 16}, {"type": "equation", "text": "$$\n(P_{i}\\sigma)(v)=\\sigma(v)\\mathbf{1}(v\\in S(\\sigma)_{i})\\,f o r\\,v\\in L.\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "B   The overall inductive argument ", "text_level": 1, "page_idx": 16}, {"type": "text", "text": "Here we present the version of the theorem with additional assumption on the transition matrix $M$ that ", "page_idx": 16}, {"type": "equation", "text": "$$\nc_{M}:=\\operatorname*{min}_{i,j\\in[q]}M_{i j}>0.\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "Theorem B.1. Given the rooted tree $T$ andthetransitionmatrix $M$ describedinTheorem1.6,and under the aditional assumption that $c_{M}=\\operatorname*{min}_{i,j\\in[q]}M_{i j}>0,$ there exists $c>0$ dependent on $M$ and $d\\lambda^{2}$ (and implicitly on $c_{M}$ as well) so that the following holds: For any function $f$ of the leaves with fractal capacity \u2264 Clog(dR); ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\mathrm{Var}(\\mathbb{E}\\big[f(X_{L})\\,\\big|\\,X_{\\rho}\\big])\\leq(\\operatorname*{max}\\{d\\lambda^{2},\\lambda\\})^{\\ell/4}\\mathrm{Var}(f(X_{L})).\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "We will first derive the version mentioned above, as it substantially reduces the technical complexity without compromising the structural integrity of the proof in the general setting where $c_{M}$ might be 0. ", "page_idx": 16}, {"type": "text", "text": "The proof of Theorem 1.6 will be carried out by induction on $\\mathcal{A}_{k}$ -polynomials. Let us introduce the necessary notations to outline this induction process. ", "page_idx": 16}, {"type": "text", "text": "Definition B.2. Let $\\varepsilon>0$ betheconstant such that ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\operatorname*{max}\\{d\\lambda^{2},\\lambda\\}=\\exp(-1.1\\varepsilon).\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "The constant $\\varepsilon$ is introduced to improve the readability of the paper. Intuitively, we aim to define $d\\lambda^{2}=\\exp(-\\varepsilon)$ , but we relax this definition slightly so that inequalities like the following hold when $\\ell$ is sufficiently large: ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\mathrm{poly}(\\ell)(d\\lambda^{2})^{\\ell}\\leq\\exp(-\\varepsilon\\ell).\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "Assumption B.3. We say that $\\boldsymbol{\\mathcal{A}}$ satisfies assumption B.3 with parameters $(\\mathrm{h}^{\\ast},c^{\\ast})$ where $\\mathrm{h}^{*}>0$ and $0<c^{*}<1$ ,if ", "page_idx": 16}, {"type": "equation", "text": "$$\n{\\mathcal{A}}_{1}\\subseteq{\\mathcal{A}}\\subseteq{\\mathbf{2}}^{L}\\backslash\\{\\emptyset\\}\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "is closed under decomposition, and morever, ", "text_level": 1, "page_idx": 16}, {"type": "text", "text": "1. For any $v\\in T$ with $\\operatorname{h}(v)\\geq\\operatorname{h}^{*}$ and a $\\boldsymbol{\\mathcal{A}}_{\\le v}$ -polynomial $f$ ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\mathrm{Var}\\big[(\\mathbb{E}_{v}f)(X)\\big]\\leq\\exp\\big(-\\varepsilon(\\mathrm{h}(v)-\\mathrm{h}^{*}\\big)\\big)\\mathrm{Var}\\big[f(X)\\big].\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "2. For any $v\\in T\\setminus\\{\\rho\\}$ with $\\operatorname{h}(v)\\geq\\operatorname{h}^{*}$ and a $\\scriptstyle A_{\\le v}$ -polynomial $f$ with $\\mathbb{E}f(X)=0$ ", "page_idx": 17}, {"type": "equation", "text": "$$\nc^{*}\\mathbb{E}\\left[(\\mathbb{E}_{v}f^{2})(X_{v})\\right]\\leq\\mathbb{E}[(\\mathbb{E}_{v}f^{2})(X_{v})\\,|\\,X_{\\mathfrak{p}(v)}=\\theta]\\leq\\frac{1}{c^{*}}\\mathbb{E}\\left[(\\mathbb{E}_{v}f^{2})(X_{v})\\right],\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "for all $\\theta\\in[q]$ ", "page_idx": 17}, {"type": "text", "text": "The inequality (15) bears a resemblance to the inequality we aim to prove in Theorem B.1. The second inequality, (16), will later be seen as a crucial step proving the inductive phase of our proof. Indeed, in the case where $c_{M}>0$ , the condition (16) can be easily satisfied by appropriately choosing $c^{*}$ ", "page_idx": 17}, {"type": "text", "text": "Lemma B.4. For any given ${\\mathcal{A}}_{1}\\subseteq{\\mathcal{A}}\\subseteq{\\mathbf{2}}^{L}\\backslash\\{\\emptyset\\}$ which is closed under decomposition. If it satisfies (15)with a given parameter $\\mathrm{h^{*}}$ and $c_{M}>0$ then $\\boldsymbol{\\mathcal{A}}$ satisfies Assumption $B.3$ with parameter $\\mathrm{h^{*}}$ and ", "page_idx": 17}, {"type": "equation", "text": "$$\nc^{\\ast}:=\\operatorname*{min}\\left\\{c_{M},\\frac{1}{\\operatorname*{min}_{j}\\pi(j)}\\right\\}>0.\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "In other words, we can choose $c^{*}$ with no dependence on either $\\mathrm{h^{*}}$ or $\\boldsymbol{\\mathcal{A}}$ ", "page_idx": 17}, {"type": "text", "text": "Proof. Consider an arbitrary function $f$ with variables $(x_{u}\\,:\\,u\\leq v)$ for some $v\\in T\\backslash\\{\\rho\\}$ ", "page_idx": 17}, {"type": "text", "text": "Let $g(x):=(\\mathbb{E}_{v}f^{2})(x)$ By the Markov Property, $(\\mathbb{E}_{v}f^{2})(x)$ is a function of $x_{v}$ , which in turn implies $g(x)\\,=\\,g(x_{v})$ .Now, for any $\\theta\\:\\in\\:[q]$ , fix an index $j_{0}\\,\\in\\,[q]$ such that $g(j_{0})\\,\\geq\\,\\mathbb{E}g(X_{v})$ Relying on $g$ is a non-negative function, ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\mathbb{E}[g(X_{v})\\,|\\,X_{\\mathfrak{p}(v)}=\\theta]=\\sum_{j\\in[q]}M_{\\theta j}g(j)\\geq M_{\\theta j_{0}}g(j_{0})\\geq c_{M}\\mathbb{E}g(X_{j}).\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "By unraveling the definition of $g$ , we can satisfy the first inequality of (16) as long as $c^{*}<c_{M}$ .The proforth econdinequaliyfolosimila logic uing thecodiion $c^{*}\\leq\\frac{1}{\\operatorname*{min}_{j}\\pi(j)}$ andthe trival inequality $\\operatorname*{max}_{i,j}M_{i j}\\leq1$ \u53e3 ", "page_idx": 17}, {"type": "text", "text": "Given this notation, the proof of Theorem B.1 proceeds by induction, with the base case and inductive articulated in the subsequent two statements. ", "page_idx": 17}, {"type": "text", "text": "Proposition B.5. Given the rooted tree $T$ and the transition matrix $M$ described in Theorem 1.6, and under the additional assumption that $c_{M}=\\operatorname*{min}_{i,j\\in[q]}M_{i j}>0$ There exists $C=C(M,\\varepsilon)\\geq1$ so that the following holds: ", "page_idx": 17}, {"type": "text", "text": "$F i x\\,\\rho^{\\prime}\\in T$ and $0\\leq m\\leq\\mathrm{h}(\\rho^{\\prime})$ if $f(x)$ is a degree 1 polynomials of variables $(x_{v}\\,:\\,v\\in D_{m}(\\rho^{\\prime}))$ \uff0c then ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\mathrm{Var}\\big[(\\mathbb{E}_{\\rho^{\\prime}}f)(X)\\big]\\leq\\exp\\Big(-\\varepsilon\\big(\\mathrm{h}(\\rho^{\\prime})-m-C(\\mathrm{log}(R)+1)\\big)\\Big)\\mathrm{Var}\\big[f(X)\\big].\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "Theorem B.6. Given the rooted tree $T$ and the transitionmatrix $M$ describedinTheorem1.6,and under the additional assumption that $c_{M}=\\operatorname*{min}_{i,j\\in[q]}M_{i j}>0$ Suppose $\\boldsymbol{\\mathcal{A}}$ is a collection of subsets satisfying Assumption $B.3$ with parameters $(\\mathrm{h}^{\\ast},\\,c^{\\ast})$ .Then, there exists $C=C(M,d,c^{*})\\geq1$ such that $B=B({\\mathcal{A}})$ satisfies Assumption $B.3$ with parameters $\\left(\\mathrm{h}^{\\ast}+C(\\log(R)+1),\\,c^{\\ast}\\right)$ ", "page_idx": 17}, {"type": "text", "text": "Let us derive the proof of Theorem B.1 based on the above two statements. ", "page_idx": 17}, {"type": "text", "text": "Proof of Theorem B.1. We apply Proposition B.5 and Lemma B.4 to get $\\mathcal{A}_{1}$ satisfies Assumption B.3 withparameter $\\operatorname{h}^{*}=C_{B.5}(\\log(R)+1)$ ,where $C_{B.5}=C(M,d)$ is the constant introduced in the Proposition and ", "page_idx": 17}, {"type": "equation", "text": "$$\nc^{*}=\\operatorname*{min}\\left\\{c_{M},\\frac{1}{\\operatorname*{min}_{j}\\pi(j)}\\right\\}>0.\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "Then, by applying Theorem B.6 inductively on the chain $\\mathcal{A}_{k}$ , we can conclude that $\\mathcal{A}_{k}$ satisfies Assumption B.3 with parameter $\\operatorname{h}^{*}=C(\\log(R)+1)k$ and the same $c^{*}$ described above, provided that $C\\,\\bar{=}\\,C(M,d,c^{*})$ is the maximum of the constants $C$ described in Proposition B.5 and Theorem B.6. In other words, for any $\\mathcal{A}_{k}$ -polynomial $f$ \uff0c ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\operatorname{Var}{\\big[}(\\mathbb{E}_{\\rho}f)(X){\\big]}\\leq\\exp{\\big(}-\\varepsilon(\\ell-C(\\log(R)+1)k){\\big)}\\operatorname{Var}{\\big[}f(X){\\big]}.\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "The theorem folows by choosing $\\begin{array}{r}{k=\\frac{1}{2C(\\log(R)+1)}\\ell}\\end{array}$ ", "page_idx": 17}, {"type": "text", "text": "C  Variance Decomposition and Variance Estimate for degree 1 polynomials ", "text_level": 1, "page_idx": 18}, {"type": "text", "text": "To describe the goal of this section, let us begin with the variance decomposition of degree 1 polynomials in a slight generalized form. Essentially, the following statement is a direct consequence of the conditional variance formula. We will state the main results first and provide the proof later in thissection. ", "page_idx": 18}, {"type": "text", "text": "Lemma C.1. Fi $\\mathrm{\\Delta}\\mathfrak{r}\\,\\rho^{\\prime}\\in T$ and $0\\leq k\\leq\\mathrm{h}(\\rho^{\\prime})$ , consider a function $g:[q]^{T}\\rightarrow\\mathbb{R}$ of the form ", "page_idx": 18}, {"type": "equation", "text": "$$\ng(x)=\\sum_{v\\in D_{k}(\\rho^{\\prime})}g_{v}(x)\\quad w h e r e\\quad g_{v}(x)=g_{v}(x_{\\leq v}).\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "For $w\\in T_{\\rho^{\\prime}}\\backslash\\{\\rho^{\\prime}\\}$ with $\\mathrm{h}(w)\\geq k+1,$ let ", "page_idx": 18}, {"type": "equation", "text": "$$\ng_{w}(x):=\\sum_{v\\in D_{k}(w)}g_{v}(x).\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "Then, ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathrm{{Var}}[g(X)]=\\!{\\mathrm{Var}}\\big[(\\mathbb{E}_{\\rho^{\\prime}}g)(X_{\\rho^{\\prime}})\\big]+\\!\\!\\!\\sum_{w\\in T_{\\rho^{\\prime}}\\setminus\\{\\rho^{\\prime}\\}:\\mathrm{h}(w)\\geq k}\\!\\!\\!\\!\\mathbb{E}{\\mathrm{Var}}\\big[(\\mathbb{E}_{w}g_{w})(X_{w})\\bigm|X_{\\mathfrak{p}(w)}\\big]}\\\\ &{\\qquad\\qquad+\\displaystyle\\sum_{v\\in D_{k}(\\rho^{\\prime})}\\mathbb{E}{\\mathrm{Var}}\\big[g_{v}(X)\\bigm|X_{v}\\big].}\\end{array}\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "Our goal is to show that when $d\\lambda^{2}<1$ $\\operatorname{Var}[g(X)]$ is of the same order as $\\begin{array}{r}{\\sum_{v\\in D_{k}(\\rho^{\\prime})}\\operatorname{Var}[g_{v}(X)]}\\end{array}$ based on the above lemma. ", "page_idx": 18}, {"type": "text", "text": "Lemma C.2. Suppose the transition matrix $M$ satisfies $d\\lambda^{2}<1$ and the tree $T$ has growthfactor $R$ Then, there exists a constant $C=C(M,\\varepsilon)\\geq1$ so that the following holds. Let $\\rho^{\\prime}\\in T$ $l^{\\prime}:=\\mathrm{h}(\\rho^{\\prime})$ \uff0c and $k\\in[0,l^{\\prime}]$ . Consider a function of the form $\\begin{array}{r}{g(x)=\\sum_{v\\in D_{k}(\\rho^{\\prime})}\\bar{g}_{v}(x_{v})}\\end{array}$ . Then, ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\operatorname{Var}[g(X)]\\leq C R\\sum_{v\\in D_{k}(\\rho^{\\prime})}\\operatorname{Var}[g_{v}(X_{v})].\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "The opposite bound does not depend on $d\\lambda^{2}\\leq1$ . However, the proof in the general case where $c_{M}=0$ is not straight-forward. We state it in full generality but will defer the general proof and prove it here in the simpler case where $c_{M}>0$ ", "page_idx": 18}, {"type": "text", "text": "Proposition C.3. There exists a constant $C=C(M,d)\\geq1$ so that the following holds. Let $\\rho^{\\prime}\\in T$ and $k\\,\\in\\,[0,\\mathrm{h}(\\rho^{\\prime})]$ .For any degree-1 function $g$ with variables $(x_{v}\\;:\\;v\\,\\in\\;D_{k}(\\rho^{\\prime}))$ . There exists functions $\\bar{g}_{v}(x)=\\bar{g}_{v}(x_{v})$ for $v\\in D_{k}(\\rho^{\\prime})$ so that the following holds: ", "page_idx": 18}, {"type": "text", "text": "\u4e00 $\\begin{array}{r}{g(X)=\\sum_{v\\in D_{k}(\\rho^{\\prime})}g_{v}(X_{u})}\\end{array}$ almost surely. They may not agree as functions from $[q]^{T}~t o$ R.) ", "page_idx": 18}, {"type": "text", "text": "2. For any $u\\in T_{\\rho^{\\prime}}$ with $\\operatorname{h}(u)\\geq k$ ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\sum_{v\\in D_{k}(u)}\\mathrm{Var}[g_{v}(X_{v})]\\leq C R^{3}\\mathrm{Var}\\big[\\sum_{v\\in D_{k}(u)}g_{v}(X_{v})\\big].\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "In particular, taking $u=\\rho^{\\prime}$ we have ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\sum_{v\\in D_{k}(\\rho^{\\prime})}\\mathrm{Var}[g_{v}(X_{v})]\\leq C R^{3}\\mathrm{Var}[g(X)].\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "We postpone the proof of Proposition in full generality in Appendix I, due to the technical complexity of the proof and the fact that the proof is about properties of a Markov Chain. Instead, a statement of the proposition and its proof in the case where $c_{M}>0$ is provided in this section. ", "page_idx": 18}, {"type": "text", "text": "Now, the purpose of this section is twofold. ", "page_idx": 18}, {"type": "text", "text": "\u00b7 First, it is the derivation of the variance related estimates: Lemma C.1, Lemma C.2, and Proposition C.3 with the additional assumption that $c_{M}>0$ .Additionally, we summarise the estimates into a single statements, as stated in Lemma C.7. \u00b7 Second, it is the derivation of the base case of the induction, Proposition B.5. ", "page_idx": 18}, {"type": "text", "text": "C.1  Variance Decomposition and Estimates ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "Before we proceed to the proof of Lemma C.1, let us remark on the following consequence of the lemma. ", "page_idx": 19}, {"type": "text", "text": "Remark C.4. For any $g$ described in Lemma C.1, if we define $\\begin{array}{r c l c l}{h(x)}&{:=}&{(\\mathbb{E}_{k}g)(x)}&{=}&{}\\end{array}$ $\\begin{array}{r}{\\sum_{v\\in D_{k}(\\rho^{\\prime})}(\\mathbb{E}_{v}g_{v})(x_{v})}\\end{array}$ and $h_{v}(x)\\,:=\\,(\\mathbb{E}_{v}g_{v})(x_{v})$ , then by applying the lemma to both $g$ and $h$ we conclude that ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\mathrm{Var}[g(X)]=\\mathrm{Var}[(\\mathbb{E}_{k}g)(X)]+\\sum_{v\\in D_{k}(\\rho^{\\prime})}\\mathbb{E}\\mathrm{Var}\\big[g_{v}(X)\\,\\big|\\,X_{v}\\big].\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "Proof of Lemma $C.I$ . First, for $v\\in T_{\\rho^{\\prime}}\\backslash\\{\\rho^{\\prime}\\}$ with $\\operatorname{h}(v)\\geq k$ ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\tilde{g}_{v}(x):=g_{v}(x)-\\mathbb{E}g_{v}(X).\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "Notice the following holds: ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\tilde{g}(x):=g(x)-\\mathbb{E}g(X)=\\sum_{v\\in D_{k}(\\rho^{\\prime})}\\tilde{g}_{v}(x).\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "Let us start decomposing the variance of $g$ ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathrm{\\lambda}\\mathrm{[ar[}g(X)\\vert=\\mathrm{Var}[\\tilde{g}(X)]=\\displaystyle\\sum_{v,v^{\\prime}\\in D_{k}(\\rho^{\\prime})}\\mathbb{E}\\big[\\tilde{g}_{v}(X)\\tilde{g}_{v^{\\prime}}(X)\\big]}\\\\ &{\\qquad\\qquad\\qquad\\qquad=\\displaystyle\\sum_{w\\in T_{\\rho^{\\prime}}\\setminus\\mathrm{h}(w)>k\\;v,v^{\\prime}\\in D_{k}(\\rho^{\\prime}):\\;\\rho(v,v^{\\prime})=w}\\mathbb{E}\\big[\\tilde{g}_{v}(X)\\tilde{g}_{v^{\\prime}}(X)\\big]+\\sum_{v\\in D_{k}(\\rho^{\\prime})}\\mathbb{E}\\big[\\tilde{g}_{v}^{2}(X)\\big]}\\end{array}\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "By the Markov Property and rearrangement of the terms, for each $w\\in T_{\\rho^{\\prime}}$ With $\\mathrm{h}(w)>k$ ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\underset{v,v^{\\prime}\\in D_{k}(\\rho^{\\prime}):\\,\\rho(v,v^{\\prime})=w}{\\sum\\substack{\\mathbb{E}\\big[\\tilde{g}_{v}(X)\\tilde{g}_{v^{\\prime}}(X)\\big]}}}\\\\ &{=\\underset{v,v^{\\prime}\\in D_{k}(\\rho^{\\prime}):\\,\\rho(v,v^{\\prime})=w}{\\sum\\substack{\\mathbb{E}\\big[(\\mathbb{E}_{w}\\tilde{g}_{v})(X)(\\mathbb{E}_{w}\\tilde{g}_{v^{\\prime}})(X)\\big]}}}\\\\ &{=\\underset{v,v^{\\prime}\\in D_{k}(w)}{\\sum\\,\\substack{\\mathbb{E}\\big[(\\mathbb{E}_{w}\\tilde{g}_{v})(X)(\\mathbb{E}_{w}\\tilde{g}_{v^{\\prime}})(X)\\big]\\,-\\,\\sum\\,\\substack{v,v^{\\prime}\\in D_{k}(w):\\rho(v,v^{\\prime})<w}}}\\mathbb{E}\\big[(\\mathbb{E}_{w}\\tilde{g}_{v})(X)(\\mathbb{E}_{w}\\tilde{g}_{v^{\\prime}})(X)\\big]}\\\\ &{=\\!\\mathbb{E}\\big[(\\mathbb{E}_{w}\\tilde{g}_{w})^{2}(X)\\big]-\\underset{w^{\\prime}\\in\\mathfrak{C}(w)}{\\sum\\,\\mathbb{E}\\big[(\\mathbb{E}_{w}\\tilde{g}_{w^{\\prime}})^{2}(X)\\big]}}\\end{array}\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "Hence, ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathrm{Var}[g(X)]}\\\\ &{=\\displaystyle\\sum_{w\\in\\cal{T}_{r}^{*}\\sim h(w)>k}\\Big(\\mathbb{E}\\big[(\\mathbb{E}_{w}\\tilde{g}_{w})^{2}(X)\\big]-\\displaystyle\\sum_{w^{\\prime}\\in\\{w\\}}\\mathbb{E}\\big[(\\mathbb{E}_{w}\\tilde{g}_{w^{\\prime}})^{2}(X)\\big]\\Big)+\\sum_{v\\in\\cal{D}_{k}}\\mathbb{E}\\big[\\tilde{g}_{v}^{2}(X)\\big]}\\\\ &{=\\displaystyle\\sum_{w\\in\\cal{F}_{r}^{*}\\sim h(w)>k}\\mathbb{E}\\big[(\\mathbb{E}_{w}\\tilde{g}_{w})^{2}(X)\\big]-\\displaystyle\\sum_{w^{\\prime}\\in\\cal{F}_{r}^{*}\\setminus\\{v^{\\prime}\\}\\setminus\\{w^{\\prime}\\}\\ge k}\\mathbb{E}\\big[(\\mathbb{E}_{p(w^{\\prime})}\\tilde{g}_{w^{\\prime}})^{2}(X)\\big]+\\displaystyle\\sum_{v\\in\\cal{D}_{k}(\\rho^{\\prime})}\\mathbb{E}\\big[\\tilde{g}_{v}^{2}(X)\\big]}\\\\ &{=\\mathbb{E}\\big[(\\mathbb{E}_{\\rho^{\\prime}}\\tilde{g}_{\\rho^{\\prime}})^{2}(X)\\big]+\\displaystyle\\sum_{w\\in\\cal{T}_{r}^{*}\\setminus\\{v^{\\prime}\\}\\setminus\\{w\\}>k}\\mathbb{E}\\big[(\\mathbb{E}_{w}\\tilde{g}_{w})^{2}(X)-(\\mathbb{E}_{p(w)}\\tilde{g}_{w})^{2}(X)\\big]}\\\\ &{\\quad+\\displaystyle\\sum_{v\\in\\cal{D}_{k}(\\rho^{\\prime})}\\Big(\\mathbb{E}\\big[\\tilde{g}_{v}^{2}(X)\\big]\\underbrace{-\\mathbb{E}\\big[(\\mathbb{E}_{v}\\tilde{g}_{v})^{2}(X)\\big]}_{=0}+\\mathbb{E}\\big[(\\mathbb{E}_{v}\\tilde{g}_{v})^{2}(X)\\big]-\\mathbb{E}\\big(\\mathbb{E}_{p(v)}\\tilde{g}_{v}\\big)^{2}(X)\\Big)}\\\\ &{=\\!\\mathbb{E}\\big[(\\mathbb{E}_{\\rho^{\\prime}}\\tilde{g}_{v})^{2}(X)\\big]+\\!\\!\\!\\!\\sum_{w\\in\\cal{T}_{r}^{*}\\setminus\\{v^{\\prime} \n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "Next, let us show the proof of Lemma C.2. ", "page_idx": 20}, {"type": "text", "text": "Proof of LemmaC.2.Let $C_{0}\\,=\\,C_{0}(M,d)$ denote the constant introduced in the statement of the Lemma. Its precise value will be determined along the proof. Without lose of generality, we may assume both $\\mathbb{E}g(X)\\,=\\,0$ and $\\mathbb{E}g_{v}(X_{v})\\,=\\,0$ for $\\bar{v}\\,\\in\\,\\bar{D}_{k}(\\rho^{\\prime})$ , and the variance of each function is simply its the second moment. For brevity, let $\\tau_{u}\\;:=\\;(\\mathbb{E}(g_{u}(X))^{2})^{1/2}$ for $u\\;\\in\\;D_{k}(\\rho^{\\prime})$ and $\\ell^{\\prime}:=\\mathrm{h}(\\rho^{\\prime})$ ", "page_idx": 20}, {"type": "text", "text": "By (8) from Lemma A.5, for $s\\in[l^{\\prime}-k]$ \uff0c ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathbb{E}\\left[(\\mathbb{E}_{\\mathfrak{p}^{s}(u)}g_{u})^{2}(X_{\\mathfrak{p}^{s}(u)})\\right]\\le C_{A.5}s^{2q}\\lambda^{2s}\\tau_{u}^{2},}\\end{array}\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "where $C_{A.5}\\geq1$ is the constant introduced in the Lemma. In particular, if $\\rho(u,u^{\\prime})\\,=\\,{\\mathfrak{p}}^{s}(u)$ for $u,u^{\\prime}\\in D_{k}(\\rho^{\\prime})$ , then ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{|\\mathbb{E}g_{u}(X)g_{u^{\\prime}}(X)|=\\!\\left|\\mathbb{E}\\big[(\\mathbb{E}_{\\mathfrak{p}^{s}(u)}g_{u})(X_{\\mathfrak{p}^{s}(u)})(\\mathbb{E}_{\\mathfrak{p}^{s}(u)}g_{u^{\\prime}})(X_{\\mathfrak{p}^{s}(u)})\\big]\\right|}\\\\ &{\\qquad\\qquad\\qquad\\leq\\!\\left(\\mathbb{E}\\big[(\\mathbb{E}_{\\mathfrak{p}^{s}(u)}g_{u})^{2}(X_{\\mathfrak{p}^{s}(u)})\\big]\\right)^{1/2}\\cdot\\left(\\mathbb{E}\\big[(\\mathbb{E}_{\\mathfrak{p}^{s}(u)}g_{u^{\\prime}})^{2}(X_{\\mathfrak{p}^{s}(u)})\\big]\\right)^{1/2}}\\\\ &{\\qquad\\qquad\\qquad\\leq\\!C_{A,5}s^{2q}\\lambda^{2s}\\tau_{u}\\tau_{u^{\\prime}}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "Then, ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\lefteqn{\\mathbb{E}(g(X))^{2}\\leq\\sum_{u,u^{\\prime}\\in D_{k}(\\rho^{\\prime})}|\\mathbb{E}g_{u}(X)g_{u^{\\prime}}(X)|}}\\\\ &{=\\displaystyle\\sum_{s\\in[l^{\\prime}-k]}\\sum_{v\\in D_{k+s}(\\rho^{\\prime})}\\sum_{u,u^{\\prime}}C_{A.5}s^{2q}\\lambda^{2s}\\tau_{u}\\tau_{u^{\\prime}},}\\end{array}\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "where the sum $\\sum_{u,u^{\\prime}}$ is taken over all ordered pairs $(u,u^{\\prime})$ With $u,u^{\\prime}\\in D_{k}(v)$ With $\\rho(u,u^{\\prime})=v$ By relaxing the constraint of the summation we have ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{E}(g(X))^{2}\\leq\\displaystyle\\sum_{s\\in[l^{\\prime}-k]}\\displaystyle\\sum_{v\\in D_{k+s}(\\rho^{\\prime})}\\displaystyle\\sum_{u,u^{\\prime}\\in D_{k}(v)}C_{A,5}s^{2q}\\lambda^{2s}\\tau_{u}\\tau_{u^{\\prime}}}\\\\ &{\\qquad=\\displaystyle\\sum_{s\\in[l^{\\prime}-k]}\\displaystyle\\sum_{v\\in D_{k+s}(\\rho^{\\prime})}C_{A,5}s^{2q}\\lambda^{2s}\\Big(\\displaystyle\\sum_{u\\in D_{k}(v)}\\tau_{u}\\Big)^{2}}\\\\ &{\\qquad\\leq\\displaystyle\\sum_{s\\in[l^{\\prime}-k]}\\displaystyle\\sum_{v\\in D_{k+s}(\\rho^{\\prime})}C_{A,5}s^{2q}\\lambda^{2s}R d^{s}\\sum_{u\\in D_{k}(v)}\\tau_{u}^{2}}\\\\ &{\\qquad=\\!\\Big(\\displaystyle\\sum_{s\\in[l^{\\prime}-k]}C_{A,5}s^{2q}\\lambda^{2s}R d^{s}\\Big)\\displaystyle\\sum_{u\\in D_{k}(\\rho^{\\prime})}\\tau_{u}^{2}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "Next, ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\sum_{s=1}^{\\infty}C_{A.5}s^{2q}\\lambda^{2s}R d^{s}\\leq\\sum_{s=1}^{\\infty}R C_{A.5}s^{2q}\\exp(-1.1\\varepsilon s):=C_{0}R.\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "Hence, $C_{0}$ depends on $\\varepsilon,\\,q$ , and $C_{A.5}$ . It is a constant which is determined by $M$ and $\\varepsilon$ ", "page_idx": 20}, {"type": "text", "text": "Let us formulate Proposition C.3 under the additional assumption that $c_{M}=\\operatorname*{min}_{i,j\\in[q]}M_{i j}>0$ Indeed, in this case, the bound does not depend on $R$ ", "page_idx": 20}, {"type": "text", "text": "Proposition C.5. Suppose the transition matrix $M$ satisfies $c_{M}~>~0$ There exists aconstant $C\\bar{=}\\;C(M,\\varepsilon)\\geq1$ so that the following holds: Let $\\rho^{\\prime}\\in T$ $l^{\\prime}:=\\mathrm{h}(\\rho^{\\prime})$ and $k\\,\\in\\,[0,l^{\\prime}]$ . For any function $g=[q]^{T}\\rightarrow\\mathbb{R}$ of the form ", "page_idx": 20}, {"type": "equation", "text": "$$\ng(x)=\\sum_{v\\in D_{k}(\\rho^{\\prime})}g_{v}(x_{v}).\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "The following holds: For any $u\\in T_{\\rho^{\\prime}}$ with $\\operatorname{h}(u)\\geq k$ ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\sum_{v\\in D_{k}(u)}\\operatorname{Var}[g_{v}(X_{v})]\\leq C\\mathrm{Var}\\big[\\sum_{v\\in D_{k}(u)}g_{v}(X_{v})\\big].\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "In particular, taking $u=\\rho^{\\prime}$ we have ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\sum_{v\\in D_{k}(\\rho^{\\prime})}\\mathrm{Var}[g_{v}(X_{v})]\\leq C\\mathrm{Var}[g(X)].\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "The proof of the Proposition relies on the following immediate consequence of $c_{M}>0$ ", "page_idx": 21}, {"type": "text", "text": "Lemma C.6. Suppose $M$ is a $q\\times q$ ergodic transition matrix with $\\begin{array}{r}{c_{M}=\\operatorname*{min}_{i,j\\in[q]}M_{i j}>0.}\\end{array}$ There exists $C=C(M)\\geq1$ so that the following holds. For any $u\\in T\\backslash\\{\\rho\\}$ and a function $h(x)=h(x_{u})$ ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\mathbb{E}\\mathrm{Var}[h(X_{u})\\,|\\,X_{\\mathfrak{p}(u)}]\\geq\\frac{1}{C(M)}\\mathrm{Var}[h(X_{u})].\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "Proof Let $\\theta_{1}=\\mathrm{argmin}_{\\theta\\in[q]}h(\\theta)$ and $\\theta_{2}=\\operatorname{argmax}_{\\theta\\in[q]}h(\\theta)$ . In the case of a tie, we may choose any of the minimizers or maximizers.) First, we have ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\mathrm{Var}[h(X_{u})]\\leq(h(\\theta_{2})-h(\\theta_{1}))^{2}.\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "Next, for any $\\beta\\in[q]$ , we have ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\operatorname*{max}\\big\\{|\\mathbb{E}[h(X_{u})\\,|\\,X_{\\mathfrak{p}(u)}=\\beta]-h(\\theta_{1})|,\\,|\\mathbb{E}[h(X_{u})\\,|\\,X_{\\mathfrak{p}(u)}=\\beta]-h(\\theta_{2})|\\big\\}\\geq\\frac{1}{2}|h(\\theta_{2})-h(\\theta_{1})|.\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "Let $i\\in\\{1,2\\}$ be the index such that $\\begin{array}{r}{|\\mathbb{E}[h(X_{u})\\,|\\,X_{\\mathfrak{p}(u)}=\\beta]-h(\\theta_{i})|\\geq\\frac{1}{2}|h(\\theta_{2})-h(\\theta_{1})|}\\end{array}$ ,andwe will use this together with $c_{M}>0$ to give a lower bound on the conditional variance: ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathrm{Var}[h(X_{u})\\,|\\,X_{\\mathfrak{p}(u)}=\\beta]\\geq\\big(\\mathbb{E}[h(X_{u})\\,|\\,X_{\\mathfrak{p}(u)}=\\beta]-h(\\theta_{i})\\big)^{2}\\mathbb{P}\\{X_{u}=\\theta_{i}\\,|\\,X_{\\mathfrak{p}(u)}=\\beta\\}}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\geq\\frac{1}{4}(h(\\theta_{2})-h(\\theta_{1}))^{2}c_{M}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "Since it holds for every $\\beta\\in[q]$ , we conclude that ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\mathbb{E}\\mathrm{Var}[h(X_{u})\\,|\\,X_{\\mathfrak{p}(u)}]\\geq\\frac{1}{4}(h(\\theta_{2})-h(\\theta_{1}))^{2}c_{M}\\geq\\frac{c_{M}}{4}\\mathrm{Var}[h(X_{u})].\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "Proof of Proposition C.5. We adapt the notation from Lemma C.1. For $w\\le\\rho^{\\prime}$ with $\\mathrm{h}(w)>k$ ,let ", "page_idx": 21}, {"type": "equation", "text": "$$\ng_{w}(x):=\\sum_{u\\in D_{k}(w)}g_{u}(x).\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "Now, we apply Lemma C.1 and Lemma C.6 to get ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathrm{Var}[g(X)]=\\mathrm{Var}\\big[(\\mathbb{E}_{\\rho^{\\prime}}g_{\\rho^{\\prime}})(X_{\\rho^{\\prime}})\\big]+\\underset{w\\in T_{\\rho^{\\prime}}\\backslash\\{\\rho^{\\prime}\\}:\\mathrm{h}(w)\\geq k}{\\sum}\\mathbb{E}\\mathrm{Var}\\big[(\\mathbb{E}_{w}g_{w})(X_{w})\\big|\\,X_{\\mathrm{p}(w)}\\big]}\\\\ &{\\qquad\\qquad+\\underset{v\\in D_{k}(\\rho^{\\prime})}{\\sum}\\mathbb{E}\\mathrm{Var}\\big[g_{v}(X)\\,\\big|\\,X_{v}\\big]}\\\\ &{\\geq\\underset{u\\in D_{k}(\\rho^{\\prime})}{\\sum}\\mathbb{E}\\mathrm{Var}\\big[(\\mathbb{E}_{u}g_{u})(X_{u})\\,\\big|\\,X_{\\mathrm{p}(u)}\\big]}\\\\ &{\\geq\\underset{G_{C,6}}{\\sum}\\underset{u\\in D_{k}(\\rho^{\\prime})}{\\sum}\\mathrm{Var}[g_{u}(X_{u})],}\\end{array}\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "where we used the fact that all the terms are non-negative, the first inequality is obtained by looking at the second terms for the summands with $h(w)=k$ and $C_{C.6}$ isthe $M$ -dependent constant introduced in Lemma C.6. ", "page_idx": 21}, {"type": "text", "text": "Lemma C.7. Suppose $d\\lambda^{2}~<~1$ and the growth factor is at most $R$ There exists a constant $C=C(M,d)\\geq\\bar{1}$ so that the following holds. Fix $\\rho^{\\prime}\\in T$ and $0\\leq m\\leq\\mathrm{h}(\\rho^{\\prime})$ if $f_{m}(x)$ is a function in the form ", "page_idx": 22}, {"type": "equation", "text": "$$\nf_{m}(x)=\\sum_{v\\in D_{m}(\\rho^{\\prime})}f_{v}(x_{\\leq v}).\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "with ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\mathbb{E}f_{m}(X)=0.\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "Then, there exists $\\bar{f}_{v}(x_{\\le v})$ for $v\\;\\in\\;D_{m}(\\rho^{\\prime})$ suchthatheir sum $\\begin{array}{r}{\\bar{f}_{m}(x)\\,=\\,\\sum_{v\\in D_{m}(\\rho^{\\prime})}\\bar{f}_{v}(x_{\\le v})}\\end{array}$ satisfies ", "page_idx": 22}, {"type": "text", "text": "and for $u\\le\\rho^{\\prime}$ with $\\operatorname{h}(u)\\geq m$ ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\frac{1}{C R^{3}}\\sum_{v\\in D_{m}(u)}\\mathbb{E}\\bar{f}_{v}^{2}(X)\\le\\mathbb{E}\\Big(\\sum_{v\\in D_{m}(u)}\\bar{f}_{v}(X)\\Big)^{2}\\le C R\\sum_{v\\in D_{m}(u)}\\mathbb{E}\\bar{f}_{v}^{2}(X).\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "The statement of the lemma using $\\bar{f}_{m}$ and $\\bar{f}_{b}$ covers also the case $c_{M}=0$ . We will prove the Lemma by using either Proposition C.3 or Proposition C.5 with the assumption $c_{M}>0$ . In the later case, it suffice to simply take $f_{v}(\\boldsymbol{x}_{\\le v})=\\bar{f}_{v}(\\bar{\\boldsymbol{x}}_{\\le v})$ ", "page_idx": 22}, {"type": "text", "text": "Remark C.8. Note that the lemma implies the following: For any $u\\le\\rho^{\\prime}$ With $\\operatorname{h}(u)\\geq m$ , let ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\bar{f}_{m,u}(x):=\\sum_{v\\in D_{m}(u)}\\bar{f}_{v}(x).\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "Then, for any given $m\\leq k<k^{\\prime}\\leq\\mathrm{h}(\\rho^{\\prime})$ and $u\\in D_{k^{\\prime}}(\\rho^{\\prime})$ , we have ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\mathbb{E}\\bar{f}_{m,u}^{2}(X)\\leq C R\\sum_{v\\in D_{m}(u)}\\mathbb{E}\\bar{f}_{v}^{2}(X)=C R\\sum_{w\\in D_{k}(u)}\\sum_{v\\in D_{m}(w)}\\mathbb{E}\\bar{f}_{v}^{2}(X)\\leq C^{2}R^{4}\\sum_{w\\in D_{k}(u)}\\bar{f}_{m,w}^{2}(X),\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "where the first inequality follows from the second inequality of (24) and the second inequality follows from the first inequality of (24). ", "page_idx": 22}, {"type": "text", "text": "Proof of Lemma C.7. Let ", "page_idx": 22}, {"type": "equation", "text": "$$\nh(x):=(\\mathbb{E}_{m}f_{m})(x)=\\sum_{v\\in D_{m}(\\rho^{\\prime})}(\\mathbb{E}_{v}f_{v})(x_{v}).\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "Note that $h$ is a degree one function of the variables $(x_{v}\\;:\\;v\\,\\in\\;D_{m}(\\rho^{\\prime}))$ . Thus, we could apply Proposition C.3 to show the existence of 1-variable functions $h_{v}(x_{v})$ for $v\\in D_{m}(\\rho^{\\prime})$ such that ", "page_idx": 22}, {"type": "equation", "text": "$$\nh(X)=\\sum_{v\\in D_{m}(\\rho^{\\prime})}h_{v}(X_{v})\\quad{\\mathrm{almost~surely}}\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "and for any $u\\in T(\\rho^{\\prime})$ with $\\operatorname{h}(u)\\geq m$ ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\sum_{v\\in D_{m}(u)}\\mathrm{Var}[h_{v}(X_{v})]\\leq C_{C.3}R^{3}\\mathrm{Var}\\big[\\sum_{v\\in D_{m}(u)}h_{v}(X_{v})\\big],\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "where $C_{C.3}\\geq1$ is the constant introduced in Proposition C.3 ", "page_idx": 22}, {"type": "text", "text": "Since $\\mathbb{E}h(X)=\\mathbb{E}(\\mathbb{E}_{m}f_{m})(X)=0$ , we may also assume that ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\mathbb{E}h_{v}(X)=0\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "for $v\\in D_{m}(\\rho^{\\prime})$ , as a constant shift of the functions will not affect (26) and (27). Now, consider the following functions: For $v\\in D_{m}(\\rho^{\\prime})$ ,let ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\bar{f}_{v}(\\boldsymbol{x}_{\\le v})=f_{v}(\\boldsymbol{x}_{\\le v})-\\mathbb{E}f_{v}(\\boldsymbol{X}_{\\le v})+h_{v}(\\boldsymbol{x}_{v})\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "and ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\bar{f}_{m}(x)=\\sum_{v\\in D_{m}(\\rho^{\\prime})}\\bar{f}_{v}(x).\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "First, since $\\bar{f}_{v}(x_{\\le v})$ is defined as the sum of three terms with mean O, we have $\\mathbb{E}\\bar{f}_{v}(X_{\\leq v})=0$ Second, ", "page_idx": 23}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\bar{f}_{m}(X)=\\displaystyle\\sum_{v\\in D_{m}(\\rho^{\\prime})}\\Big(f_{v}(X_{\\leq v})-(\\mathbb{E}_{v}f_{v})(X_{v})+h_{v}(X_{v})\\Big)}\\\\ &{\\qquad\\quad=f_{m}(X)-h(X)+\\displaystyle\\sum_{v\\in D_{m}(\\rho^{\\prime})}h_{v}(X_{v})}\\\\ &{\\qquad\\quad=f_{m}(X).}\\end{array}\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "By Remark C.4, ", "page_idx": 23}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\lefteqn{\\mathrm{\\lceil{\\sum_{\\tau\\inD_{m}(u)}}\\bar{f}_{v}(X)\\rceil}=\\mathrm{Var}\\Big[\\Big(\\mathbb{E}_{m}\\sum_{v\\in D_{m}(u)}\\bar{f}_{v}\\big)(X)\\Big]+\\sum_{v\\in D_{m}(u)}\\mathbb{E}\\mathrm{Var}[\\bar{f}_{v}(X)\\,|\\,X_{v}]}}\\\\ &{=\\mathrm{Var}\\Big[\\sum_{v\\in D_{m}(u)}\\big(\\mathbb{E}_{v}\\bar{f}_{v}\\big)(X)\\Big]+\\sum_{v\\in D_{m}(u)}\\mathbb{E}\\mathrm{Var}[f_{v}(X)-\\big(\\mathbb{E}_{v}f_{v}\\big)(X_{v})+h_{v}(X_{v})}\\\\ &{=\\mathrm{Var}\\Big[\\sum_{v\\in D_{m}(u)}h_{v}(X)\\Big]+\\sum_{v\\in D_{m}(u)}\\mathbb{E}\\mathrm{Var}[f_{v}(X)\\,|\\,X_{v}]}\\qquad\\qquad\\qquad\\quad(28)}\\end{array}\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "To estimate the lower bound, we rely on own choice of $h_{v}$ . By (27) we have ", "page_idx": 23}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\lefteqn{(28)\\geq\\!\\!\\!\\frac{1}{C_{C,3}R^{3}}\\sum_{v\\in D_{m}(u)}\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!}&{\\mathrm{sur}\\big[h_{v}(X)]+\\sum_{v\\in D_{m}(u)}\\mathbb{E}\\mathrm{Var}[f_{v}(X)\\,|\\,X_{v}]}\\\\ &{\\geq\\!\\!\\!\\!\\!\\frac{1}{C_{C,3}R^{3}}\\sum_{v\\in D_{m}(u)}\\Big(\\mathrm{Var}\\big[h_{v}(X)\\big]+\\mathbb{E}\\mathrm{Var}[f_{v}(X)\\,|\\,X_{v}]\\Big)}\\\\ &{=\\!\\!\\!\\!\\frac{1}{C_{C,3}R^{3}}\\sum_{v\\in D_{m}(u)}\\Big(\\mathrm{Var}\\big[(\\mathbb{E}_{v}\\bar{f}_{v})(X_{v})\\big]+\\mathbb{E}\\mathrm{Var}[\\bar{f}_{v}(X)\\,|\\,X_{v}]\\Big)}\\\\ &{=\\!\\!\\!\\!\\frac{1}{C_{C,3}R^{3}}\\sum_{v\\in D_{m}(u)}\\mathrm{Var}[\\bar{f}_{v}(X)].}\\end{array}\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "As for the upper bound, we can apply Lemma C.2 and repeat the same derivation as above to get ", "page_idx": 23}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{(28)\\leq\\!C_{C.2}R\\displaystyle\\sum_{v\\in D_{m}(u)}\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\mathrm{Var}[h_{v}(X)]+\\displaystyle\\sum_{v\\in D_{m}(u)}\\!\\!\\!\\!\\!\\!\\mathbb{E}\\mathrm{Var}[f_{v}(X)\\,|\\,X_{v}]}\\\\ &{\\qquad\\leq\\!C_{C.2}R\\displaystyle\\sum_{v\\in D_{m}(u)}\\!\\!\\!\\!\\!\\!\\!\\!\\!\\mathrm{Var}[\\bar{f}_{v}(X)].}\\end{array}\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "Therefore, by taking the constant $C$ stated in the lemma to be the maximum of $C_{C.3}$ and $C_{C.2}$ ,the proof follows. ", "page_idx": 23}, {"type": "text", "text": "C.2 Proof of the base Case of Proposition B.5 ", "text_level": 1, "page_idx": 23}, {"type": "text", "text": "We now prove the base case of Proposition B.5: ", "page_idx": 23}, {"type": "text", "text": "Lemma C.9. There exists a constant $C=C(M,d)\\geq1$ so that the following holds. For any degree 1 function $f$ with variables $(x_{u}\\,:u\\in D_{k}(\\rho^{\\prime}))$ for some $\\rho^{\\prime}\\in T$ with $k\\le\\mathrm{h}(\\rho^{\\prime})$ ", "page_idx": 23}, {"type": "equation", "text": "$$\n\\mathrm{{Var}}\\big[\\mathbb{E}\\big[f(X)\\,|\\,X_{\\rho^{\\prime}}\\big]\\big]\\leq C R^{4}(\\mathrm{h}^{\\prime})^{2q}(d\\lambda^{2})^{\\mathrm{h}^{\\prime}}\\mathrm{{Var}}[f(X)].\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "where $\\mathrm{h}^{\\prime}=\\mathrm{h}(\\rho^{\\prime})-k$ ", "page_idx": 23}, {"type": "text", "text": "Proof. Let $f_{u}$ for $u\\in D_{k}(\\rho^{\\prime})$ be the functions from Proposition C.3 so that ", "page_idx": 23}, {"type": "equation", "text": "$$\nf(X)=\\sum_{u\\in D_{k}(\\rho^{\\prime})}f_{u}(X_{u}){\\mathrm{~almost~surely.}}\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "We can assume $\\mathbb{E}f(X)=0$ and $\\mathbb{E}f_{u}(X)=0$ for every $u\\in D_{k}(\\rho^{\\prime})$ without affecting (30). From Proposition C.3, we have ", "page_idx": 24}, {"type": "equation", "text": "$$\n\\sum_{u\\in D_{k}(\\rho^{\\prime})}\\mathbb{E}[f_{u}^{2}(X)]\\leq C_{C.3}R^{3}\\mathbb{E}[f^{2}(X)],\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "where $C_{C.3}$ denotes the constant $C$ introduced in the Proposition. ", "page_idx": 24}, {"type": "text", "text": "We could apply Lemma A.5 to get ", "page_idx": 24}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\Xi\\bigl[(\\mathbb{E}_{\\rho^{\\prime}}f)^{2}(X_{\\rho^{\\prime}})\\bigr]\\leq\\mathopen{}\\mathclose\\bgroup\\left|D_{k}(\\rho^{\\prime})\\aftergroup\\egroup\\right|\\leq\\underset{v\\in D_{k}(\\rho^{\\prime})}{\\sum}\\bigl[(\\mathbb{E}_{\\rho^{\\prime}}f_{v})^{2}(X_{\\rho^{\\prime}})\\bigr]}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\leq\\mathopen{}\\mathclose\\bgroup\\left|D_{k}(\\rho^{\\prime})\\aftergroup\\egroup\\right|C_{A,5}\\mathbf{h}^{\\prime2q}\\lambda^{2\\Lambda^{\\prime}}\\underset{u\\in D_{k}(\\rho^{\\prime})}{\\sum}\\mathbb{E}[f_{u}^{2}(X)]\\leq C_{C,3}C_{A,5}R^{4}(\\mathbf{h}^{\\prime})^{2q}(d\\lambda^{2})^{\\mathrm{h}^{\\prime}}\\mathbb{E}[f^{2}(X)]}\\end{array}\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "where $C_{A.5}$ denotes the constant $C$ stated in the Lemma. ", "page_idx": 24}, {"type": "text", "text": "Proof of the Base Case Proposition B.5. Given $\\rho^{\\prime}\\in T$ and $0\\leq m\\leq\\mathrm{h}(\\rho^{\\prime})$ described in the Proposition. Let $\\mathrm{h}^{\\prime}=\\mathrm{h}(\\rho^{\\prime})-m$ . By Lemma C.9, any function $\\begin{array}{r}{f(x)=\\sum_{v\\in D_{m}(\\rho^{\\prime})}f_{v}(x_{v})}\\end{array}$ satisfies ", "page_idx": 24}, {"type": "equation", "text": "$$\n\\mathrm{Var}\\big[(\\mathbb{E}_{\\rho^{\\prime}}f)(X)\\big]\\leq C_{C.9}R^{4}(\\mathrm{h}^{\\prime})^{q}(d\\lambda^{2})^{\\mathrm{h}^{\\prime}}\\mathrm{Var}[f(X)],\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "where $C_{C.9}$ denotes the $M$ -dependent constant introduced in the Lemma. With ", "page_idx": 24}, {"type": "equation", "text": "$$\nC_{C.9}R^{4}(\\mathrm{h}^{\\prime})^{q}(d\\lambda^{2})^{\\mathrm{h}^{\\prime}}\\leq C_{C.9}R^{4}(\\mathrm{h}^{\\prime})^{q}\\exp(-1.1\\varepsilon\\mathrm{h}^{\\prime})\\leq\\exp\\big(-\\varepsilon(\\mathrm{h}^{\\prime}-C_{1}(\\log(R)+1))\\big),\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "for some $C_{1}\\geq1$ which depends on $M,d$ ", "page_idx": 24}, {"type": "text", "text": "D  Decomposition of Polynomials ", "text_level": 1, "page_idx": 24}, {"type": "text", "text": "In this section we study the representation of functions in terms of $\\phi_{\\sigma}$ and $\\psi_{\\sigma}$ . Roughly speaking $\\psi_{\\sigma}$ are \u201cmore orthogonal\" than the $\\phi_{\\sigma}$ . More formally we will show that under appropriate conditioning expections of $\\psi_{\\sigma}$ factorize. Thus some of the effort in the proof and particularly in this section is devoted to relating the $\\phi$ and $\\psi$ representations and bounding moments of such representations. ", "page_idx": 24}, {"type": "text", "text": "Lemma D.1. Assuming $d\\lambda^{2}<1$ and growthfactor of $R,$ there exists $C=C(M,d)\\geq1$ so that the following holds. Let $A_{1}\\subseteq\\,B\\subseteq\\,{\\mathbf{2}}^{L}\\backslash\\{\\varnothing\\}$ be a collection of subsets which is closed under decomposition. Fix a positive integer $k_{1}$ and $\\bar{\\rho^{\\prime}}\\in T$ with $l^{\\prime}:=\\mathrm{h}(\\dot{\\rho}^{\\prime})>k_{1}$ .For every function $f$ of the form ", "page_idx": 24}, {"type": "equation", "text": "$$\nf(x)=\\sum_{\\sigma:\\sigma\\neq0\\in\\mathcal{F}(\\mathcal{B}_{\\leq\\rho^{\\prime}})}c_{\\sigma}\\phi_{\\sigma}(x)\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "with ", "page_idx": 24}, {"type": "equation", "text": "$$\n\\mathbb{E}f(X)=0,\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "here exists a decomposition of $f$ ", "page_idx": 24}, {"type": "equation", "text": "$$\nf(X)=\\sum_{u\\leq\\rho^{\\prime}:\\,\\operatorname{h}(u)\\geq k}\\tilde{f}_{u}(X)\\;a l m o s t\\,s u r e l y,\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "where, for each $u\\le\\rho^{\\prime}$ with $\\operatorname{h}(u)\\geq k_{1}$ , we have a function $f_{u}(x)=f_{u}(x_{\\leq u})$ and ", "page_idx": 24}, {"type": "text", "text": "1. For $u\\in T_{\\rho^{\\prime}}$ with $\\mathrm{h}(u)>k_{1}$ $f_{u}(x)$ is a linear combination of $\\psi_{\\sigma}(x)$ with $\\sigma\\in\\mathcal{F}(\\boldsymbol{B}_{u})$ and $\\tilde{f}_{u}(x)=f_{u}(x)-\\mathbb{E}f_{u}(X)$   \n2. For $w\\le\\rho^{\\prime}$ with $\\operatorname{h}(w)\\geq k_{1}$ we have $\\frac{1}{C R^{3}}\\mathbb{E}\\Big[\\sum_{u\\in D_{k_{1}}(w)}f_{u}^{2}(X)\\Big]\\leq\\mathbb{E}(\\sum_{u\\in D_{k_{1}}(w)}f_{u}(X))^{2}\\leq C R\\mathbb{E}\\Big[\\sum_{v\\in D_{k_{1}}(w)}f_{u}^{2}(X)\\Big].$ ", "page_idx": 24}, {"type": "text", "text": "We may group the $f_{u}$ according to $\\mathrm{h}(u)$ and define for $k_{1}\\leq k\\leq\\mathrm{h}(\\rho^{\\prime})$ ", "page_idx": 25}, {"type": "equation", "text": "$$\nf_{k}(x):=\\sum_{u\\in D_{k}(\\rho^{\\prime})}\\tilde{f}_{u}(x).\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "In other words, ", "page_idx": 25}, {"type": "equation", "text": "$$\nf(X)=\\sum_{k\\in[k_{1},\\mathrm{h}(\\rho^{\\prime})]}f_{k}(X)\\,a l m o s t\\,s u r e l y.\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "To prove the main lemma, let us begin by comparing $\\phi_{\\sigma}(x)$ and $\\psi_{\\sigma}(x)$ (See Definition A.11). ", "page_idx": 25}, {"type": "text", "text": "Lemma D.2. For $\\sigma\\in\\mathcal{F}(\\mathcal{B}_{u}).$ $\\phi_{\\sigma}(x)$ can be expressed in the form ", "page_idx": 25}, {"type": "equation", "text": "$$\n\\phi_{\\sigma}(x)=\\prod_{i\\in I(\\sigma)}\\psi_{P_{i}\\sigma}(x)-a_{\\subset,\\sigma}(x)-a_{<,\\sigma}(x)-a_{c,\\sigma},\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "where: ", "page_idx": 25}, {"type": "text", "text": "$\\scriptstyle a_{\\subset,\\sigma}(x)$ is a linear combination of $\\phi_{\\sigma^{\\prime}}({\\boldsymbol{x}})$ for $\\sigma^{\\prime}\\,\\in\\,{\\mathcal{F}}({\\mathcal{B}}_{u})$ such that $I(\\sigma^{\\prime})$ is a proper subset of $I(\\sigma)$   \n$\\boldsymbol{a}_{<,\\sigma}(\\boldsymbol{x})$ is a linear combination of $\\phi_{\\sigma^{\\prime}}(x)$ for $\\sigma^{\\prime}\\in\\mathcal{F}(\\mathcal{B}_{<\\mathfrak{u}})$ (recall that $\\;B_{<u}=\\{S\\in B\\;:$ $\\rho(S)<u\\}.$ ),and ", "page_idx": 25}, {"type": "text", "text": "$a_{c,\\sigma}$ is a constant. ", "page_idx": 25}, {"type": "text", "text": "Proof. Fix $\\sigma\\in{\\mathcal{F}}(B)$ and let $u=\\rho(S)$ and $S=S(\\sigma)$ . Recall that $P_{i}\\sigma\\in[0,q-1]^{T}$ is the projection f $\\sigma$ 0 $S_{i}$ We can alsodecompose the function $\\phi_{\\sigma}$ according to $\\{P_{i}\\sigma\\}_{i\\in I(\\sigma)}$ ", "page_idx": 25}, {"type": "equation", "text": "$$\n\\phi_{\\sigma}(x)=\\prod_{i\\in I(S)}\\phi_{P_{i}\\sigma}(x).\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "Before we proceed, let us note that by Lemma 1.12 and the definition of $\\boldsymbol{\\mathrm{\\Delta}}\\boldsymbol{\\mathrm{\\Omega}}_{\\boldsymbol{B}}$ wehave $P_{i}\\sigma\\in\\mathcal{F}(\\mathcal{B}_{\\leq u_{i}})$ Now, let us expand the function $\\psi_{\\sigma}$ according to its definition: ", "page_idx": 25}, {"type": "equation", "text": "$$\n\\prod_{i\\in I(S)}\\psi_{P_{i}\\sigma}(x)=\\prod_{i\\in I(S)}\\left(\\phi_{P_{i}\\sigma}(x)-\\mathbb{E}\\phi_{P_{i}\\sigma}(X)\\right)=\\sum_{I_{1},I_{2}}\\left(\\prod_{i\\in I_{1}}\\phi_{P_{i}\\sigma}(x)\\right)\\Big(\\prod_{i\\in I_{2}}(-\\mathbb{E}\\phi_{P_{i}\\sigma}(X))\\Big),\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "where the summation is taken over all possible partition $I_{1}\\sqcup I_{2}=I(\\sigma)$ . Next, we can group the summands into four types based on $\\left|{I_{1}}\\right|$ and $\\left|{I_{2}}\\right|$ ", "page_idx": 25}, {"type": "text", "text": "Type 1 $|I_{1}|=|I(\\sigma)|$ . The summand is simply $\\phi_{\\sigma}(x)$ ", "page_idx": 25}, {"type": "text", "text": "Type 2 $2\\leq|I_{1}|\\leq|I(\\sigma)|-1$ ", "page_idx": 25}, {"type": "text", "text": "Each summand is a constant multiple of $\\phi_{\\sigma^{\\prime}}(x)$ where $\\sigma^{\\prime}$ is the projection of $\\sigma$ to the indices $\\sqcup_{i\\in I_{1}}S_{i}$ . Clearly, $\\textstyle S(\\sigma^{\\prime})\\,=\\,\\sqcup_{i\\in I_{1}}\\!\\!\\!\\!S_{i}$ .With $|I_{1}|\\,\\geq\\,2$ , we have $\\rho(\\sigma^{\\prime})\\,=\\,u$ Further, each $S_{i}\\in A_{\\leq u_{i}}$ for $i\\in I(\\sigma)$ , it follows that $S(\\sigma^{\\prime})\\in B_{u}$ , which in turn implies $\\sigma^{\\prime}\\in\\mathcal{F}(\\mathcal{B}_{u})$ ", "page_idx": 25}, {"type": "text", "text": "Type 3 $|I_{1}|=1$ . Each summand is a constant multiple of $\\phi_{P_{i}\\sigma}(x)$ ; where $i$ is the element in $I_{1}$ Notice that $P_{i}\\sigma\\in\\mathcal{F}(A_{<u})\\subset\\mathcal{F}(\\mathcal{B}_{<u})$ where the inclusion follows from Lemma 1.12. We denote the sum of summands of this type as $\\scriptstyle a_{<,\\sigma}(x)$ ", "page_idx": 25}, {"type": "text", "text": "Type 4 $|I_{1}|=0$ There is only one summand, which is a constant. We denote this constant by $a_{c,P_{i}\\sigma}$ ", "page_idx": 25}, {"type": "text", "text": "With this decomposition, (32) follows. ", "page_idx": 25}, {"type": "text", "text": "Given the expressions for $\\psi_{\\sigma}(x)$ in terms $\\phi_{\\sigma}(x)$ and vice-versa, for any given $u\\in T\\backslash L$ , we can convert a linear combination of $\\phi_{\\sigma}(x)$ with $\\sigma\\in\\mathcal{F}(\\mathcal{B}_{u})$ to that of $\\psi_{\\sigma}(x)$ with $\\sigma\\in\\mathcal{F}(\\mathcal{B}_{u})$ ", "page_idx": 25}, {"type": "text", "text": "Lemma D.3. For $u\\in T\\backslash L,$ .consider any function of the form ", "page_idx": 26}, {"type": "equation", "text": "$$\np_{u}(x)=\\sum_{\\sigma\\in\\mathcal{F}(\\mathcal{B}_{u})}c_{\\sigma}\\phi_{\\sigma}(x).\n$$", "text_format": "latex", "page_idx": 26}, {"type": "text", "text": "Then there exists a decomposition ", "page_idx": 26}, {"type": "equation", "text": "$$\np_{u}(x)=\\tilde{f}_{u}(x)+p_{<,u}(x)+c_{u},\n$$", "text_format": "latex", "page_idx": 26}, {"type": "text", "text": "where: ", "page_idx": 26}, {"type": "text", "text": "\u00b7 $\\tilde{f}_{u}(x)=f_{u}(x)-\\mathbb{E}f_{u}(X)$ and $f_{u}(x)$ is a linear combination of $\\psi_{\\sigma}(x)$ for $\\sigma\\in\\mathcal{F}(\\mathcal{B}_{u}).$ $p_{<,u}(x)$ is a linear combination of $\\phi_{\\sigma}(x)$ with $\\sigma\\in{\\mathcal{F}}({\\mathcal{B}}_{<u})$ ,and $c_{u}$ is a constant. ", "page_idx": 26}, {"type": "text", "text": "Proof. The decomposition is constructed through recursion on the following expression: ", "page_idx": 26}, {"type": "equation", "text": "$$\nr(p_{u}):=\\mathrm{argmax}\\{|I(\\sigma)|:\\sigma\\in\\mathcal{F}(\\mathcal{B}_{u}),\\,c_{\\sigma}\\neq0\\}.\n$$", "text_format": "latex", "page_idx": 26}, {"type": "text", "text": "Suppose $r(p_{u})=2$ . Then the statement of simply follows from Lemma D.2. ", "page_idx": 26}, {"type": "text", "text": "Suppose the statement of the lemma holds whenever $r(p_{u})\\,\\le\\,r$ for $2\\,\\leq\\,r\\,<\\,R d$ . Consider any function $p_{u}$ with $r(p_{u})=r+1$ ", "page_idx": 26}, {"type": "equation", "text": "$$\n\\mathscr{o}_{u}(x)=\\sum_{\\substack{\\sigma\\in\\mathcal{F}(B_{u})\\,:\\,|I(\\sigma)|\\leq r+1}}c_{\\sigma}\\phi_{\\sigma}(x)=\\sum_{\\substack{\\sigma\\in\\mathcal{F}(B_{u})\\,:\\,|I(\\sigma)|=r+1}}c_{\\sigma}\\phi_{\\sigma}(x)+\\sum_{\\substack{\\sigma\\in\\mathcal{F}(B_{u})\\,:\\,|I(\\sigma)|\\leq r}}c_{\\sigma}\\phi_{\\sigma}(x)\\,.\n$$", "text_format": "latex", "page_idx": 26}, {"type": "text", "text": "According to the decomposition of $\\phi_{\\sigma}(x)$ in Lemma D.2, let ", "page_idx": 26}, {"type": "equation", "text": "$$\n\\begin{array}{c}{\\displaystyle f_{u,r+1}(x):=\\sum_{\\substack{\\sigma\\in\\mathcal{F}(\\mathcal{B}_{u})\\,:\\,|I(\\sigma)|=r+1}}c_{\\sigma}\\psi_{\\sigma}(x)}\\\\ {\\displaystyle p_{*,u,r+1}(x):=\\sum_{\\substack{\\sigma\\in\\mathcal{F}(\\mathcal{B}_{u})\\,:\\,|I(\\sigma)|=r+1}}c_{\\sigma}a_{*,\\sigma}(x)}\\end{array}\n$$", "text_format": "latex", "page_idx": 26}, {"type": "text", "text": "where $^*$ can be $\\subset,\\,<$ or $c$ . Then, ", "page_idx": 26}, {"type": "equation", "text": "$$\np_{u,r+1}(x)=f_{u,r+1}(x)+p_{C,u,r+1}(x)+p_{<,u,r+1}(x)+p_{c,u,r+1}(x).\n$$", "text_format": "latex", "page_idx": 26}, {"type": "text", "text": "Observe that $p_{u,\\leq r}(x)+p_{\\subset,u,r+1}(x)$ is a linear combination of $\\phi_{\\sigma}(x)$ With $\\sigma\\in\\mathcal{F}(\\mathcal{B}_{u})$ and $|I(\\sigma)|\\leq$ $r$ . Thus, by the inductive assumption, the summation can be expressed in the form ", "page_idx": 26}, {"type": "equation", "text": "$$\np_{u,\\le r}(x)+p_{\\subset,u,r+1}(x)=\\tilde{f}_{u}^{\\prime}(x)+p_{<,u}^{\\prime}(x)+c_{u}^{\\prime}.\n$$", "text_format": "latex", "page_idx": 26}, {"type": "text", "text": "Finally, let ", "page_idx": 26}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\qquad f_{u}(x)=f_{u}^{\\prime}(x)+f_{u,r+1}(x),}\\\\ &{p_{<,u}(x)=p_{<,u}^{\\prime}(x)+p_{<,u,r+1}(x),}\\\\ &{\\qquad c_{u}=c_{u}^{\\prime}+p_{c,u}^{\\prime}+\\mathbb{E}\\big[f_{u,r+1}(X)\\big],}\\end{array}\n$$", "text_format": "latex", "page_idx": 26}, {"type": "text", "text": "and we have ", "page_idx": 26}, {"type": "equation", "text": "$$\n\\begin{array}{c}{{p_{u}(x)=f_{u,r+1}(x)+p_{<,u,r+1}(x)+p_{c,u,r+1}(x)+\\tilde{f}_{u}^{\\prime}(x)+p_{<,u}^{\\prime}(x)+c_{u}^{\\prime}}}\\\\ {{{}}}\\\\ {{=\\tilde{f}_{u}(x)+p_{<,u}(x)+c_{u}.}}\\end{array}\n$$", "text_format": "latex", "page_idx": 26}, {"type": "text", "text": "Proof of Lemma $D.I$ . We will construct $f_{u}(x)$ for $u$ starting from top layer $\\left.u=\\rho^{\\prime}\\right.$ ) to bottom layer. For $k\\in[k_{1},l^{\\prime}-1]$ , when $f_{u}(x)$ is constructed for $u\\in T_{\\rho^{\\prime}}$ with $\\mathrm{h}(u)>k$ , we define ", "page_idx": 27}, {"type": "equation", "text": "$$\nf_{\\leq k}(x)=f(x)-\\sum_{u\\,:\\,\\mathrm{h}(u)>k+1}\\tilde{f}_{u}(x),\n$$", "text_format": "latex", "page_idx": 27}, {"type": "text", "text": "where $\\tilde{f}_{u}(x)=f_{u}(x)-\\mathbb{E}f_{u}(X)$ Without lose of generality, let $f_{\\leq l^{\\prime}}(x)=f(x)$ ", "page_idx": 27}, {"type": "text", "text": "Fix $k\\,\\in\\,[k_{1}+1,l^{\\prime}]$ . For the induction step, suppose $\\{f_{u}(x)\\}_{u\\in T_{\\rho^{\\prime}}:\\;\\mathrm{h}(u)>k}\\;\\{f_{\\leq s}(x)\\}_{s\\in[k,l^{\\prime}]}$ have been constructed such that $f_{\\leq k}(x)$ can be expressed in the form ", "page_idx": 27}, {"type": "equation", "text": "$$\nf_{\\leq k}(x)=c^{\\prime}+\\sum_{\\substack{\\sigma\\in\\mathcal{F}(B)\\,:\\,k_{1}<\\ln(\\rho(\\sigma))\\leq k}}c_{\\sigma}^{\\prime}\\phi_{\\sigma}(x)+\\sum_{\\substack{\\sigma\\in\\mathcal{F}(\\mathbf{2}^{L})\\,:\\,\\operatorname{h}(\\rho(\\sigma))\\leq k_{1}}}c_{\\sigma}^{\\prime}\\phi_{\\sigma}(x).\n$$", "text_format": "latex", "page_idx": 27}, {"type": "text", "text": "Clearly, this holds when $k=l^{\\prime}$ ", "page_idx": 27}, {"type": "text", "text": "For each $u$ with $\\operatorname{h}(u)\\,=\\,k$ let $\\begin{array}{r}{p_{u}(x)\\,=\\,\\sum_{\\sigma\\in\\mathcal{F}(\\mathcal{B}_{u})}c_{\\sigma}^{\\prime}\\phi_{\\sigma}(x)}\\end{array}$ , and define $\\tilde{f}_{u}(x),p_{<,u}(x)$ , and $c_{u}$ according to Lemma D.3. Then, ", "page_idx": 27}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{f_{\\leq k-1}(x)=f_{\\leq k}(x)-\\displaystyle\\sum_{u:\\,\\mathrm{h}(u)=k_{1}}\\tilde{f}_{u}(x)}\\\\ &{\\qquad=c^{\\prime}+\\displaystyle\\sum_{\\substack{\\sigma\\in\\mathcal{F}(B):\\,k_{1}<\\mathrm{h}(\\rho(\\sigma))\\leq k-1}}c_{\\sigma}^{\\prime}\\phi_{\\sigma}(x)+\\displaystyle\\sum_{\\substack{\\sigma\\in\\mathcal{F}(\\mathbf{2}^{L}):\\,\\mathrm{h}(\\rho(\\sigma))\\leq k_{1}}}c_{\\sigma}^{\\prime}\\phi_{\\sigma}(x)}\\\\ &{\\qquad+\\displaystyle\\sum_{u:\\,\\mathrm{h}(u)=k}(p_{<,u}(x)+c_{u}).}\\end{array}\n$$", "text_format": "latex", "page_idx": 27}, {"type": "text", "text": "Recall from Lemma D.3 that $p_{<,u}(x)$ is a linear combination of $\\phi_{\\sigma}(x)$ with $\\sigma\\,\\in\\,{\\mathcal{F}}({\\mathcal{B}}_{<u})$ , the function $f_{\\leq k-1}(x)$ satisfies (36) as well (with $k$ been replaced by $k-1)$ ", "page_idx": 27}, {"type": "text", "text": "Once the induction terminated at layer $k_{1}$ , we obtain ", "page_idx": 27}, {"type": "equation", "text": "$$\nf_{k_{1}}(x)=c+\\sum_{u\\in D_{k_{1}}(\\rho^{\\prime})}\\sum_{\\sigma\\in\\mathcal{F}(2^{L_{u}}\\backslash\\{\\varnothing\\})}c_{\\sigma}\\phi_{\\sigma}(x).\n$$", "text_format": "latex", "page_idx": 27}, {"type": "text", "text": "Now, observe that for $k_{1}<k\\le\\mathrm{h}(\\rho^{\\prime})$ , we have $f_{k}(x)$ is defined as the sum of $\\tilde{f}_{u}$ for $u\\in D_{k}(\\rho^{\\prime})$ \uff0c which are functions of mean O. Together with the assumption that $\\mathbb{E}f(X)=0$ , we have ", "page_idx": 27}, {"type": "equation", "text": "$$\n\\mathbb{E}f_{k_{1}}(X)=\\mathbb{E}f(X)-\\sum_{k=k_{1}+1}^{\\mathrm{h}(\\rho^{\\prime})}\\mathbb{E}f_{k}(X)=0.\n$$", "text_format": "latex", "page_idx": 27}, {"type": "text", "text": "Notice that $f_{k_{1}}$ satisfies the assumption of the function stated in Lemma C.7 with $m\\,=\\,k_{1}$ . By replacing $f_{k_{1}}$ by $\\bar{f}_{k_{1}}$ and $f_{u}$ by $\\bar{f}_{u}$ for each $u\\in D_{k_{1}}(\\rho^{\\prime})$ , the second statement follows while the third statement of the Lemma remains true. Hence, the proof is completed. \u53e3 ", "page_idx": 27}, {"type": "text", "text": "E  Induction Step 1: Decay of $f_{u}$ ", "text_level": 1, "page_idx": 27}, {"type": "text", "text": "The goal this section and next section is to prove Theorem B.6. Let us restate the theorem here. ", "page_idx": 27}, {"type": "text", "text": "Theorem. Given the rooted tree $T$ and the transition matrix $M$ described in Theorem 1.6, and under the additional assumption that $c_{M}=\\operatorname*{min}_{i,j\\in[q]}M_{i j}>0$ Suppose $\\boldsymbol{\\mathcal{A}}$ is a collection of subsets satisfying Assumption B.3with parameters $\\mathrm{h^{*}}$ and $c^{*}$ .Then, there exists $C=C(M,d,c^{*})\\geq1$ such that $B=B({\\mathcal{A}})$ satisfies Assumption B.3 with parameters $\\mathrm{h}^{*}+C(\\log(R)+1)$ and $c^{*}$ ", "page_idx": 27}, {"type": "text", "text": "In this and the following section, we will fix a collection $\\boldsymbol{\\mathcal{A}}$ that meets Assumption B.3 with some parameters $l^{*}$ and $c^{*}$ . Additionally, we abbreviate ", "page_idx": 27}, {"type": "equation", "text": "$$\nB=B({\\mathcal{A}}).\n$$", "text_format": "latex", "page_idx": 27}, {"type": "text", "text": "Further, we will fix $\\rho^{\\prime}\\in T$ and a function $f$ described in the Assumption B.3, and assume ", "page_idx": 28}, {"type": "equation", "text": "$$\n\\mathbb{E}f(X)=0.\n$$", "text_format": "latex", "page_idx": 28}, {"type": "text", "text": "The proof is grounded in the decomposition of $f$ as described in Lemma D.1, which splits $f$ into summation of $f_{k}$ and subsequently into summations of $\\tilde{f}_{u}$ . Accordingly, this section is devoted to derive the variance decay properties of $f_{u}$ stated as Proposition E.1 below. The proposition will be used to derive variance decay properties of $f_{k}$ , and toward the proof of Theorem B.6 in next section. ", "page_idx": 28}, {"type": "text", "text": "Proposition E.1. There exists $C\\,=\\,C(M,c^{*})\\,\\geq\\,1$ so that the following holds. For any $u\\,\\in\\,T$ consider a function $f_{u}$ of the form ", "page_idx": 28}, {"type": "equation", "text": "$$\nf_{u}(x)=\\sum_{0\\neq\\sigma\\in\\mathcal{F}(\\mathcal{B}_{u})}c_{\\sigma}\\psi_{\\sigma}(x).\n$$", "text_format": "latex", "page_idx": 28}, {"type": "text", "text": "Then, for $\\theta\\:\\in\\:[q]$ we have the following bounds on $(\\mathbb{E}_{u}f_{u})(x)$ (recall that that by the Markov Property, $({\\mathbb E}_{u}f_{u})(x)$ is a function of $x_{u}$ ", "page_idx": 28}, {"type": "equation", "text": "$$\n(\\mathbb{E}_{u}f_{u})^{2}(\\theta)\\leq\\exp(-2\\varepsilon(\\mathrm{h}(u)-C(\\log(R)+1)-\\mathrm{h}^{\\ast}))(\\mathbb{E}_{u}f_{u}^{2})(\\theta)\n$$", "text_format": "latex", "page_idx": 28}, {"type": "text", "text": "and ", "page_idx": 28}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathbb{E}\\big[(\\mathbb{E}_{u}\\tilde{f}_{u})^{2}(X_{u})\\big]\\leq\\exp(-2\\varepsilon(\\mathrm{h}(u)-C(\\log(R)+1)-\\mathrm{h}^{\\ast}))\\mathbb{E}\\tilde{f}_{u}^{2}(X).}\\end{array}\n$$", "text_format": "latex", "page_idx": 28}, {"type": "text", "text": "Additionally for any function $a(x)$ having inputs involving only $(x_{v}\\,:\\,v\\in T_{u_{i}})$ for some $i\\in[d_{u}]$ ", "page_idx": 28}, {"type": "equation", "text": "$$\n\\mathbb{E}\\big[\\vert\\tilde{f}_{u}(X)a(X)\\vert\\big]\\leq\\exp\\Big(-\\frac{\\varepsilon}{2}(\\mathrm{h}(u)-C(\\log(R)+1)-\\mathrm{h}^{*})\\Big)(\\mathbb{E}\\tilde{f}_{u}^{2}(X))^{1/2}(\\mathbb{E}a^{2}(X))^{1/2}.\n$$", "text_format": "latex", "page_idx": 28}, {"type": "text", "text": "Remark E.2. The statement of the Proposition E.1 is exactly the statement of Theorem B.6 restricted to functions all of whose non-zero $c_{\\sigma}$ have $\\rho(\\sigma)=\\rho^{\\prime}$ . Thus in some sense in this section we prove the Theorem for the most complex terms. And in the next section we will control the correlations between different terms. ", "page_idx": 28}, {"type": "text", "text": "This is an analogue in our setting to the classical fact in Fourier analysis that high amplitude functions have sharp decay under noise. ", "page_idx": 28}, {"type": "text", "text": "Remark E.3. We remark that the proposition holds immediately whenever $\\vert d_{u}\\vert\\le1$ since $B_{u}=\\emptyset$ ", "page_idx": 28}, {"type": "text", "text": "Before we proceed further, we need to decompose $f_{u}(x)$ ", "page_idx": 28}, {"type": "text", "text": "Definition E.4. For $u\\in T\\backslash L$ and $\\begin{array}{r}{f_{u}(x)=\\sum_{\\sigma\\in\\mathcal{F}(\\mathcal{B}_{u})}c_{\\sigma}\\psi_{\\sigma}(x)}\\end{array}$ let ", "page_idx": 28}, {"type": "equation", "text": "$$\n\\begin{array}{l l}{f_{u,I}(x):=\\sum_{\\substack{\\sigma\\in\\mathcal{F}(\\mathcal{B}_{u})\\,:\\,I(\\sigma)=I}}{c_{\\sigma}\\psi_{\\sigma}(x)},}&{a n d}\\\\ {\\tilde{f}_{u,I}(x):=f_{u,I}(x)-\\mathbb{E}f_{u,I}(X)}&{}\\end{array}\n$$", "text_format": "latex", "page_idx": 28}, {"type": "text", "text": "for each $I\\subseteq[d_{u}]$ with $|I|\\ge2$ ", "page_idx": 28}, {"type": "text", "text": "Given the above definition, we have ", "page_idx": 28}, {"type": "equation", "text": "$$\nf_{u}(x)=\\sum_{I\\subseteq[d_{u}]:|I|\\geq2}f_{u,I}(x).\n$$", "text_format": "latex", "page_idx": 28}, {"type": "text", "text": "PropositionE.5.Thereexists $C=C(M,c^{*})\\geq1$ so that thefollowingholds.For any $u\\in T\\setminus L$ and $\\bar{I}\\subseteq[d_{u}]$ With $|I|\\ge2$ Considerafunctionof theform ", "page_idx": 28}, {"type": "equation", "text": "$$\na(x)=\\sum_{\\substack{\\sigma\\in\\mathcal{F}(\\mathcal{B}_{u})\\,:I(\\sigma)=I}}c_{\\sigma}\\psi_{\\sigma}(x).\n$$", "text_format": "latex", "page_idx": 28}, {"type": "text", "text": "Then, for $I^{\\prime}\\subseteq I$ let ", "page_idx": 28}, {"type": "equation", "text": "$$\nU=T\\setminus(\\bigcup_{i\\in I^{\\prime}}T_{u_{i}}),\n$$", "text_format": "latex", "page_idx": 28}, {"type": "text", "text": "and we have ", "page_idx": 28}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\big((\\mathbb{E}_{U}a)(x)\\big)^{2}\\leq\\exp\\big(-\\varepsilon|I^{\\prime}|(\\mathrm{h}(u)-C-\\mathrm{h}^{*})\\big)(\\mathbb{E}_{U}a^{2})(x).}\\end{array}\n$$", "text_format": "latex", "page_idx": 28}, {"type": "text", "text": "Roughly speaking the proposition states that under the decay of correlation in Assumption B.3, for functions all of whose coefficient $c_{\\sigma}$ have $S(\\sigma)=I$ for some large set $I$ we get a variance decay of the form $\\exp(-\\epsilon|I|\\mathrm{h}(u))$ . For later applications the statement is more general allowing to condition on some of the subtrees. This is an analogue in our setting to the classical fact in Fourier analysis that high amplitude functions have sharp decay under noise. ", "page_idx": 29}, {"type": "text", "text": "Proof. We fix $u\\in T\\backslash L$ and $I\\subseteq[d_{u}]$ . Without lose of generality, we assume $I^{\\prime}=[s]$ ", "page_idx": 29}, {"type": "text", "text": "Let $C_{0}=C_{0}(M,c^{*})$ denote the constant described in the statement of the Proposition. The precise valueof $C_{0}$ will be determined during the proof. ", "page_idx": 29}, {"type": "text", "text": "For brevity, we introduce some notations that are only used in this proof. ", "page_idx": 29}, {"type": "text", "text": "I. Decomposition of $x\\in[q]^{T}$ : Consider the representation of $x$ as ", "page_idx": 29}, {"type": "equation", "text": "$$\n\\boldsymbol{x}=(x_{u},x_{0},x_{1},\\ldots,x_{s}),\n$$", "text_format": "latex", "page_idx": 29}, {"type": "text", "text": "Further, let ", "page_idx": 29}, {"type": "equation", "text": "$$\nx_{\\le k}=(x_{0},x_{1},\\ldots,x_{k}).\n$$", "text_format": "latex", "page_idx": 29}, {"type": "text", "text": "For $k\\in[0,s]$ ", "page_idx": 29}, {"type": "equation", "text": "$$\na_{\\leq k}(x_{\\leq k}):=\\mathbb{E}\\Big[a(X)\\,\\Big|\\,X_{u}=x_{u}\\mathrm{~and~}X_{\\leq k}=x_{\\leq k}\\Big].\n$$", "text_format": "latex", "page_idx": 29}, {"type": "text", "text": "Before we proceed to the proof, observe that applying Jenson's inequality on conditional expectation, we can form a chain of inequalities ", "page_idx": 29}, {"type": "equation", "text": "$$\n\\begin{array}{r}{(\\mathbb{E}_{U}a)^{2}(x)=(\\mathbb{E}_{U}a_{\\leq0}^{2})(x)\\leq(\\mathbb{E}_{U}a_{\\leq1}^{2})(x)\\leq(\\mathbb{E}_{U}a_{\\leq2}^{2})(x)\\leq\\ldots\\leq(\\mathbb{E}_{U}a_{\\leq s}^{2})(x)=(\\mathbb{E}_{U}a^{2})(x).}\\end{array}\n$$", "text_format": "latex", "page_idx": 29}, {"type": "text", "text": "$\\mathrm{h}(u)\\leq C_{0}+\\mathrm{h}^{*}$ , then the statement of the Proposition is weaker than the inequality $(\\mathbb{E}_{U}a)^{2}(x)\\leq$ $(\\mathbb{E}_{U}\\mathring{a}^{2})(x)$ stated above. So the lemma follows immediately in that case. From now on we assume ", "page_idx": 29}, {"type": "equation", "text": "$$\n\\mathrm{h}(u)>C_{0}+\\mathrm{h}^{\\ast}.\n$$", "text_format": "latex", "page_idx": 29}, {"type": "text", "text": "We will improve each inequality in the above chain by leveraging the assumption (15) ", "page_idx": 29}, {"type": "text", "text": "Given the definition of $a(x)$ ", "page_idx": 29}, {"type": "equation", "text": "$$\na(x)=\\sum_{\\sigma}c_{\\sigma}\\prod_{i\\in I\\setminus[s]}\\tilde{\\phi}_{P_{i}\\sigma}(x_{0})\\prod_{i\\in[s]}\\tilde{\\phi}_{P_{i}\\sigma}(x_{i})\n$$", "text_format": "latex", "page_idx": 29}, {"type": "text", "text": "By the Markov Property, the random variables $(X_{i}|X_{u}=x_{u})_{i\\in[0,s]}$ are independent. This gives rise to: ", "page_idx": 29}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{a_{\\le k}(x)=\\!\\mathbb{E}\\Big[\\displaystyle\\sum_{\\sigma}c_{\\sigma}\\!\\prod_{i\\in I\\backslash[s]}\\tilde{\\phi}_{P_{i}\\sigma}(X_{0})\\displaystyle\\prod_{i\\in[s]}\\tilde{\\phi}_{P_{i}\\sigma}(X_{i})\\Big|\\,X_{u}=x_{u}\\mathrm{~and~}X_{\\le k}=x_{\\le k}\\Big]}\\\\ &{\\quad\\quad\\quad=\\displaystyle\\sum_{\\sigma}c_{\\sigma}\\prod_{i\\in I\\backslash[s]}\\tilde{\\phi}_{P_{i}\\sigma}(x_{0})\\displaystyle\\prod_{i\\in[k]}\\tilde{\\phi}_{P_{i}\\sigma}(x_{k})\\quad\\displaystyle\\prod_{i\\in[k+1,s]}(\\mathbb{E}_{u}\\tilde{\\phi}_{P_{i}\\sigma})(x_{u}).}\\end{array}\n$$", "text_format": "latex", "page_idx": 29}, {"type": "text", "text": "Now, fix $k\\in[s]$ and express $a_{\\le k}(x)=a_{\\le k}(x_{u},x_{\\le k-1},x_{k})$ .An essence of this proof is that the mapping: ", "page_idx": 29}, {"type": "equation", "text": "$$\ny_{k}\\mapsto a{\\leq}k\\big(x_{u},x_{\\leq k-1},y_{k}\\big)\n$$", "text_format": "latex", "page_idx": 29}, {"type": "text", "text": "is a linear combination of $\\tilde{\\phi}_{\\sigma}(y_{k})$ With $\\sigma\\in\\mathcal{F}(\\mathcal{A}_{u_{k}})$ and the coefficients are functions of $(x_{u},x_{\\leq k-1})$ which gives us room to apply the inductive assumption, or (15) from Assumption B.3. ", "page_idx": 29}, {"type": "text", "text": "To aid our analysis, we introduce $Y_{k}$ , an independent copy of $X_{k}$ . By (15), we have ", "page_idx": 30}, {"type": "equation", "text": "$$\n{\\ensuremath{\\mathbb E}}\\Big[\\big({\\ensuremath{\\mathbb E}}[a_{\\le k}(x_{u},x_{\\le k-1},Y_{k})|Y_{u}]\\big)^{2}\\Big]\\le\\exp(-\\varepsilon(\\mathrm{h}(u)-\\mathrm{h}^{*})){\\ensuremath{\\mathbb E}}_{Y_{k}}\\big[a_{\\le k}^{2}(x_{u},x_{\\le k-1},Y_{k})\\big].\n$$", "text_format": "latex", "page_idx": 30}, {"type": "text", "text": "The reason we introduce $Y_{k}$ is that the L.H.S. and R.H.S. of the above inequality are not related to (any moments of) conditional expectation of $a(X)$ . However, it can still be used with some adjustment, relying on (16) from Assumption B.3. ", "page_idx": 30}, {"type": "text", "text": "Given the assumption on $C_{0}$ being greater than or equal to 1, we have ", "page_idx": 30}, {"type": "equation", "text": "$$\n\\mathrm{h}(u_{k})=\\mathrm{h}(u)-1\\stackrel{(43)}{\\geq}\\mathrm{h}^{*}+C_{0}-1\\geq\\mathrm{h}^{*}.\n$$", "text_format": "latex", "page_idx": 30}, {"type": "text", "text": "Applying (16) to our function $y_{k}\\mapsto a{\\leq}k\\big(x_{u},x_{\\leq k-1},y_{k}\\big)$ we get ", "page_idx": 30}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{E}_{Y_{k}}\\big[a_{\\le k}^{2}(x_{u},x_{\\le k-1},Y_{k})\\big]\\le\\!\\frac{1}{c^{*}}\\operatorname*{min}_{\\theta\\in[q]}\\mathbb{E}_{Y_{k}}\\big[a_{\\le k}^{2}(x_{u},x_{\\le k-1},Y_{k})\\big|Y_{u}=\\theta\\big]}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\qquad\\le\\!\\frac{1}{c^{*}}\\mathbb{E}_{Y_{k}}\\big[a_{\\le k}^{2}(x_{u},x_{\\le k-1},Y_{k})\\big|Y_{u}=x_{u}\\big].}\\end{array}\n$$", "text_format": "latex", "page_idx": 30}, {"type": "text", "text": "On the other hand, ", "page_idx": 30}, {"type": "equation", "text": "$$\n\\pi(x_{u})\\big(\\mathbb{E}_{Y_{k}}[a_{\\le k}(x_{u},x_{\\le k-1},Y_{k})|Y_{u}=x_{u}]\\big)^{2}\\le\\mathbb{E}\\Big[\\big(\\mathbb{E}_{Y_{k}}[a_{\\le k}(x_{u},x_{\\le k-1},Y_{k})|Y_{u}]\\big)^{2}\\Big].\n$$", "text_format": "latex", "page_idx": 30}, {"type": "text", "text": "Combining the above expression, (44), and (45), we conclude that ", "page_idx": 30}, {"type": "equation", "text": "$$\n\\mathbb{E}\\big[a_{\\le k}(x_{u},x_{\\le k-1},Y_{k})\\bigm|Y_{u}=x_{u}\\big]\\big)^{2}\\le\\frac{1}{c^{\\ast}\\pi(x_{u})}\\exp(-\\varepsilon(\\mathtt{h}(u)-\\mathtt{h}^{\\ast}))\\mathbb{E}_{Y_{k}}\\big[a_{\\le k}^{2}(x_{u},x_{\\le k-1},Y_{k})\\bigm|Y_{u}=x_{u}\\big]\n$$", "text_format": "latex", "page_idx": 30}, {"type": "text", "text": "Notice that the expression inside the square in L.H.S. is ", "page_idx": 30}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\quad\\mathbb{E}\\big[a_{\\leq k}(x_{u},x_{\\leq k-1},Y_{k})\\,\\big|\\,Y_{u}=x_{u}\\big]}\\\\ &{=\\!\\mathbb{E}\\big[a_{\\leq k}(x_{u},x_{\\leq k-1},X_{k})\\,\\big|\\,X_{u}=x_{u}\\big]}\\\\ &{=\\!\\mathbb{E}\\big[a_{\\leq k}(X_{u},X_{\\leq k-1},X_{k})\\,\\big|\\,X_{u}=x_{u},X_{\\leq k-1}=x_{\\leq k-1}\\big]}\\\\ &{=\\!a_{\\leq k-1}(x).}\\end{array}\n$$", "text_format": "latex", "page_idx": 30}, {"type": "text", "text": "Similarly, ", "page_idx": 30}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{E}_{Y_{k}}\\big[a_{\\le k}^{2}(x_{u},x_{\\le k-1},Y_{k})\\bigm|Y_{u}=x_{u}\\big]=\\mathbb{E}\\big[a_{\\le k}^{2}(x_{u},x_{\\le k-1},X_{k})\\bigm|X_{u}=x_{u}\\big]}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad=\\mathbb{E}\\big[a_{\\le k}^{2}(X_{u},X_{\\le k-1},X_{k})\\bigm|X_{u}=x_{u},X_{\\le k-1}=x_{\\le k-1}\\big]}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad=a_{\\le k-1}^{2}(x).}\\end{array}\n$$", "text_format": "latex", "page_idx": 30}, {"type": "text", "text": "By imposing the first assumption on $C_{0}$ that ", "page_idx": 30}, {"type": "equation", "text": "$$\nC_{0}\\geq\\frac{1}{\\varepsilon}\\log\\Big(\\frac{1}{c^{*}\\operatorname*{min}_{j\\in[q]}\\pi(j)}\\Big),\n$$", "text_format": "latex", "page_idx": 30}, {"type": "text", "text": "it follows from (46) that ", "page_idx": 30}, {"type": "equation", "text": "$$\na_{\\leq k-1}^{2}(x)\\leq\\exp(-\\varepsilon(\\mathrm{h}(u)-C_{0}-\\mathrm{h}^{\\ast}))\\mathbb{E}\\big[a_{\\leq k}^{2}(X)\\,\\big|\\,X_{u}=x_{u}\\,\\mathfrak{s}_{u}\\,\\mathfrak{s}_{u}\\big]\n$$", "text_format": "latex", "page_idx": 30}, {"type": "text", "text": "By taking Conditional Expectation on both sides, ", "page_idx": 30}, {"type": "equation", "text": "$$\n\\begin{array}{r}{(\\mathbb{E}_{U}a_{\\leq k-1}^{2})(x)\\leq\\exp(-\\varepsilon(\\ln(u)-C_{0}-\\ln^{*}))\\big(\\mathbb{E}_{U}a_{\\leq k}^{2}\\big)(x).}\\end{array}\n$$", "text_format": "latex", "page_idx": 30}, {"type": "text", "text": "Finally, we apply this inequality consecutively for $k\\in[s]$ we obtain ", "page_idx": 30}, {"type": "equation", "text": "$$\n\\begin{array}{r}{(\\mathbb{E}_{U}a)^{2}(x)\\leq\\exp(-\\varepsilon|I^{\\prime}|(\\mathrm{h}(u)-C_{0}-\\mathrm{h}^{\\ast}))(\\mathbb{E}_{U}a^{2})(x).}\\end{array}\n$$", "text_format": "latex", "page_idx": 30}, {"type": "text", "text": "Corollary E.6. Fix $u\\in T\\backslash L$ and afunction $f_{u}(x)$ following the form described in Definition E.4. If $I,J\\subseteq[d_{u}]$ are subsets of $[d_{u}]$ of size at least 2,then for every $\\theta\\in[q]$ ", "page_idx": 31}, {"type": "equation", "text": "$$\n\\begin{array}{r}{|(\\mathbb{E}_{u}f_{u,I})(\\theta)|\\le\\exp\\Big(-\\frac{\\varepsilon|I|}{2}(\\mathrm{h}(u)-C-\\mathrm{h}^{*}\\Big)\\sqrt{(\\mathbb{E}_{u}f_{u,I}^{2})(\\theta)}\\,\\Big.\\,\\Big.}\\\\ {\\vert(\\mathbb{E}_{u}f_{u,I}\\cdot f_{u,I})(\\theta)\\vert\\le\\exp\\Big(-\\frac{\\varepsilon|I\\Delta J|}{2}(\\mathrm{h}(u)-C-\\mathrm{h}^{*})\\Big)\\sqrt{(\\mathbb{E}_{u}f_{u,I}^{2})(\\theta)}\\cdot\\sqrt{(\\mathbb{E}_{u}f_{u,J}^{2})(\\theta)},}\\end{array}\n$$", "text_format": "latex", "page_idx": 31}, {"type": "text", "text": "(48) where $C=C(M,c^{*})$ is the constant introduced in Proposition $E.5;$ and $I\\Delta J:=(I\\setminus J)\\cup(J\\setminus I)$ Proof For the first statement, it follows from Proposition E.5 with $a(x)=f_{u,I}(x)$ and $I=I^{\\prime}$ To prove the second statement, we begin by noting that the inputs of $f_{u,I}(x)$ and $f_{u,J}(x)$ do not include $\\left(x_{v}\\,:\\,v\\in\\bigcup_{i\\in J\\setminus I}T_{u_{i}}\\right)$ and $\\left(x_{v}\\,:\\,v\\in\\bigcup_{i\\in I\\setminus J}T_{u_{i}}\\right)$ ,respectively. Thus, we can aly the Markov Property and that fact that if $Y,Z,W$ are ind pendent then: ", "page_idx": 31}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathbb{E}[g(Y,Z)h(Z,W)]=\\mathbb{E}[\\mathbb{E}[g(Y,Z)h(Z,W)\\vert Z]]=\\mathbb{E}[\\mathbb{E}[g(Y,Z)\\vert Z]h(Z,W)]}\\end{array}\n$$", "text_format": "latex", "page_idx": 31}, {"type": "text", "text": "and this in turn becomes: ", "page_idx": 31}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathbb{E}[\\mathbb{E}[g(Y,Z)|Z]h(Z,W)|W]=\\mathbb{E}[\\mathbb{E}[g(Y,Z)|Z]\\mathbb{E}[h(Z,W)|W]],}\\end{array}\n$$", "text_format": "latex", "page_idx": 31}, {"type": "text", "text": "to obtain ", "page_idx": 31}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\quad\\left(\\mathbb{E}_{u}f_{u,I}f_{u,J}\\right)(x)}\\\\ &{=\\!\\mathbb{E}\\!\\left[\\mathbb{E}\\!\\left[f_{u,I}(X)\\Bigm|X_{v}:v\\notin\\bigcup_{i\\in I\\setminus J}T_{u_{i}}\\right]\\cdot\\mathbb{E}\\!\\left[f_{u,J}(X)\\Bigm|X_{v}:v\\notin\\bigcup_{i\\in J\\setminus I}T_{u_{i}}\\right]\\Bigm|X_{v}=x_{v}:v\\neq u\\right].}\\end{array}\n$$", "text_format": "latex", "page_idx": 31}, {"type": "text", "text": "In terms of absolute value, by Proposition E.5 we have ", "page_idx": 31}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\quad\\Vert\\mathbb{E}_{\\mathbb{E}}\\Vert_{L^{2}}\\Vert(x_{t}),I(x)\\Vert}\\\\ &{\\leq\\Vert\\mathbb{E}\\Vert\\Big[\\mathbb{E}_{\\mathbb{H}}\\Vert(X_{t})(X_{t})(X_{t})\\Big]\\,N_{t}:=\\eta\\underbrace{\\Vert\\mathbf{J}_{t}\\Vert}_{\\Phi_{t}\\Vert\\leq\\eta,(X_{t})}\\Vert\\Big\\vert\\,X_{t}-\\alpha_{t}:=\\eta\\underbrace{\\Vert\\mathbf{J}_{t}\\Vert}_{\\Phi_{t}}}\\\\ &{=\\mathbb{E}\\bigg[\\bigg\\vert\\mathbb{E}\\Big[\\int_{u_{t}}(X_{t})\\Big\\vert\\,N_{t}:=\\psi\\underbrace{\\mathbf{J}_{t}\\Vert}_{\\Phi_{t}\\Vert\\leq\\eta,(X_{t})}\\Big\\vert\\,\\bigg\\vert\\mathbb{E}\\Big[\\int_{u_{t}}(X_{t})\\Big\\vert\\,X_{t}:=\\psi\\underbrace{d\\big\\vert}_{\\delta\\leq t}\\Big\\vert\\,\\bigg\\vert\\,X_{t}\\bigg]\\bigg\\vert\\,\\bigg\\vert X_{t}_{t}-\\alpha_{t}:=\\psi\\underbrace{d\\big\\vert}_{\\delta\\leq t}\\bigg]}\\\\ &{\\leq\\mathbb{E}\\bigg[\\bigg\\vert\\exp(-\\vert t/X_{t}/(\\Vert u_{t})-C-h\\rangle)\\cdot\\mathbb{E}\\Big[\\int_{u_{t}}(X_{t})\\Big\\vert\\,X_{t}:=\\psi\\underbrace{d\\big\\vert}_{\\delta\\leq t}\\bigg\\vert\\,\\prod_{t}_{\\ell}\\bigg]}\\\\ &{\\qquad\\qquad\\cdot\\sqrt{\\log(-\\vert t/X_{t}\\vert/\\Vert(u_{t})-C-h^{*})}\\cdot\\mathbb{E}\\Big[\\int_{u_{t}}(X_{t})\\Big\\vert\\,X_{t}:=\\psi\\underbrace{d\\big\\vert}_{\\delta\\leq t}\\bigg\\vert\\,\\prod_{t}_{\\ell}\\bigg]\\bigg\\vert X_{t}=x_{t}:=\\psi\\underbrace{d\\big\\vert}_{\\delta\\leq t}}\\\\ &{\\leq\\exp\\bigg(-\\frac{\\varepsilon}{2}\\vert t\\vert\\Delta_{t}\\vert(u_{t})-C-h^{*}\\rangle\\bigg)\\sqrt{\\mathbb{E}\\big[\\mathbb{E}\\big[\\int_{u_{t}}(X_{t})\\big\\vert\\,X_{t}:=\\psi\\underbrace{d\\big\\vert}_{\\delta\\leq t}\\big\\vert\\,\\prod_{t}_{\\ell}\\big]\\bigg\\vert X_{t}=x_{t}:=\\psi\\underbrace{d\\big\\vert}_{\\delta\\leq t}}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\cdot\\sqrt{ \n$$", "text_format": "latex", "page_idx": 31}, {"type": "text", "text": "where the second to last inequality follows from Holder's inequality. ", "page_idx": 31}, {"type": "text", "text": "Corollary E.7. There exists $C=C(M,d,c^{*})\\geq1$ so that the following holds. 1f $u\\in T\\backslash L$ with $\\mathrm{h}(u)\\geq\\mathrm{h}^{\\ast}+C(1+\\log(R))$ , then for any $f_{u}(x)$ in the form as described in Definition $E.4$ ", "page_idx": 31}, {"type": "equation", "text": "$$\n\\forall\\theta\\in[q],\\ \\frac{1}{2}\\cdot\\sum_{I\\subset[d_{u}]:\\,|I|\\geq2}(\\mathbb{E}_{u}f_{u,I}^{2})(\\theta)\\leq(\\mathbb{E}_{u}f_{u}^{2})(\\theta).\n$$", "text_format": "latex", "page_idx": 31}, {"type": "text", "text": "Proof.Let $C_{0}=C_{0}(M,d,c^{*})$ denote the constant introduced in the statement of the Lemma. Its value will be determined along the proof. ", "page_idx": 32}, {"type": "text", "text": "The statement of the Corollary is trivial when $d_{u}<2$ since in that case $\\boldsymbol{B}_{u}=\\boldsymbol{\\emptyset}$ , implying $f_{u}=0$ From now on, we assume $d_{u}\\ge2$ ", "page_idx": 32}, {"type": "text", "text": "First, ", "page_idx": 32}, {"type": "equation", "text": "$$\n(\\mathbb{E}_{u}f_{u}^{2})(x)-\\sum_{I\\in[d_{u}]:\\,|I|\\geq2}(\\mathbb{E}_{u}f_{u,I}^{2})(x)=\\sum_{\\{I,J\\}}2(\\mathbb{E}_{u}f_{u,I}\\cdot f_{u,J})(x)\n$$", "text_format": "latex", "page_idx": 32}, {"type": "text", "text": "where $\\sum_{\\{I,J\\}}$ refersto thesumveallordedais $\\{I,J\\}$ with $I$ and $J$ being distinct subsets of $[d_{u}]$ of size at least 2. ", "page_idx": 32}, {"type": "text", "text": "We can apply (48) to estimate the absolute value of the difference. ", "page_idx": 32}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\Bigm\\lvert\\sum_{\\{I,J\\}}2(\\mathbb{E}_{u}f_{u,I}\\cdot f_{u,J})(x)\\Bigm\\rvert}\\\\ &{\\le\\displaystyle\\sum_{\\{I,J\\}}2\\exp\\Big(-\\frac{\\varepsilon\\lvert I\\Delta J\\rvert}{2}(\\mathrm{h}(u)-C_{E.5}-\\mathrm{h}^{*})\\Big)\\sqrt{(\\mathbb{E}_{u}f_{u,I}^{2})(x)}\\cdot\\sqrt{(\\mathbb{E}_{u}f_{u,J}^{2})(x)},}\\end{array}\n$$", "text_format": "latex", "page_idx": 32}, {"type": "text", "text": "where the constant $C_{E.5}$ is the constant $C_{E.5}$ introduced in Proposition E.5. By $2|a b|\\leq a^{2}+b^{2}$ for $a,b\\in\\mathbb{R}$ ", "page_idx": 32}, {"type": "equation", "text": "$$\n2\\sqrt{(\\mathbb{E}_{u}f_{u,I}^{2})(x)}\\cdot\\sqrt{(\\mathbb{E}_{u}f_{u,J}^{2})(x)}\\le(\\mathbb{E}_{u}f_{u,I}^{2})(x)+(\\mathbb{E}_{u}f_{u,J}^{2})(x).\n$$", "text_format": "latex", "page_idx": 32}, {"type": "text", "text": "Hence, ", "page_idx": 32}, {"type": "equation", "text": "$$\n(50)\\leq\\sum_{I\\subset[d_{u}]:\\,|I|\\geq2}\\bigl(\\mathbb{E}_{u}f_{u,I}^{2}\\bigr)(x)\\Big(\\sum_{J\\subset[d_{u}]:\\,I\\neq J}\\exp\\Big(-\\frac{\\varepsilon|I\\Delta J|}{2}\\bigl(\\mathrm{h}(u)-C_{E.5}-\\mathrm{h}^{*}\\bigr)\\Big)\\Big).\n$$", "text_format": "latex", "page_idx": 32}, {"type": "text", "text": "With $\\begin{array}{r}{|\\{J\\subseteq[d_{u}]\\,:\\,|I\\Delta J|=i\\}|={\\binom{d_{u}}{i}}\\leq d_{u}^{i},}\\end{array}$ ", "page_idx": 32}, {"type": "equation", "text": "$$\n\\sum_{\\substack{C[d_{u}]\\,:\\,I\\neq J}}\\exp\\Big(-\\frac{\\varepsilon|I\\Delta J|}{2}(\\mathbf{h}(u)-C_{E.5}-\\mathbf{h}^{*})\\Big)\\leq\\sum_{i=1}^{\\infty}d_{u}^{i}\\exp\\Big(-\\frac{\\varepsilon i}{2}(\\mathbf{h}(u)-C_{E.5}-\\mathbf{h}^{*})\\Big)\\leq1/4,\n$$", "text_format": "latex", "page_idx": 32}, {"type": "text", "text": "provided that $\\begin{array}{r}{\\mathrm{h}(u)-C_{E.5}-\\frac{\\log(d_{u})}{\\varepsilon}-\\mathrm{h}^{\\ast}\\geq\\frac{16}{\\varepsilon}.}\\end{array}$ ", "page_idx": 32}, {"type": "text", "text": "Now, we impose the first assumption on $C_{0}$ that ", "page_idx": 32}, {"type": "equation", "text": "$$\nC_{0}\\geq C_{E.5}+\\frac{\\log(d)}{\\varepsilon}+\\frac{1}{\\varepsilon}+\\frac{16}{\\varepsilon},\n$$", "text_format": "latex", "page_idx": 32}, {"type": "text", "text": "then ", "page_idx": 32}, {"type": "equation", "text": "$$\n\\operatorname{h}(u)\\geq\\operatorname{h}^{*}+C_{0}(\\log(R)+1)\\geq C_{E.5}+{\\frac{\\log(d_{u})}{\\varepsilon}}+{\\frac{16}{\\varepsilon}}+\\operatorname{h}^{*}.\n$$", "text_format": "latex", "page_idx": 32}, {"type": "text", "text": "Hence, ", "page_idx": 32}, {"type": "equation", "text": "$$\n\\Big|(\\mathbb{E}_{u}f_{u}^{2})(x)-\\sum_{I\\in[d]:\\,|I|\\geq2}(\\mathbb{E}_{u}f_{u,I}^{2})(x)\\Big|\\leq\\!\\frac{1}{4}\\sum_{I\\in[d]:\\,|I|\\geq2}(\\mathbb{E}_{u}f_{u,I}^{2})(x)\n$$", "text_format": "latex", "page_idx": 32}, {"type": "text", "text": "and the proof follows. ", "page_idx": 32}, {"type": "text", "text": "ProofofPropositionE.1.Let $C_{0}=C_{0}(M,d,c^{*})$ denote the constant introduced in the statement of the Proposition. Its precise value will be determined along the proof. From Remark E.3, it is sufficient to consider the case when $\\vert d_{u}\\vert\\ge2$ . Further, it suffices to prove in the case when ", "page_idx": 32}, {"type": "equation", "text": "$$\n\\mathrm{h}(u)\\geq\\mathrm{h}^{*}+C_{0}(\\log(R)+1),\n$$", "text_format": "latex", "page_idx": 32}, {"type": "text", "text": "since otherwise the statements follow from either Cauchy-Schwarz or Jenson's inequality. ", "page_idx": 33}, {"type": "text", "text": "Part I: Derivation of (37) and (38). ", "text_level": 1, "page_idx": 33}, {"type": "text", "text": "First, by (47), ", "page_idx": 33}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{(\\mathbb{E}_{u}f_{u})^{2}(\\theta))=\\!\\Big(\\displaystyle\\sum_{I\\subseteq[d_{u}]:\\,|I|\\geq2}(\\mathbb{E}_{u}f_{u,I})(\\theta)\\Big)^{2}}\\\\ &{\\qquad\\le\\!\\left(\\displaystyle\\sum_{I\\subseteq[d_{u}]:\\,|I|\\geq2}\\exp\\Big(-\\frac{\\varepsilon|I|}{2}(\\mathrm{h}(u)-C_{E.5}-\\mathrm{h}^{*})\\Big)\\cdot\\sqrt{(\\mathbb{E}_{u}f_{u,I}^{2})(\\theta)}\\right)^{2}}\\\\ &{\\qquad\\le\\!\\Big(\\displaystyle\\sum_{I\\subseteq[d_{u}]:\\,|I|\\geq2}\\exp\\Big(-\\varepsilon|I|(\\mathrm{h}(u)-C_{E.5}-\\mathrm{h}^{*})\\Big)\\Big)\\cdot\\Big(\\displaystyle\\sum_{I\\subseteq[d_{u}]:\\,|I|\\geq2}(\\mathbb{E}_{u}f_{u,I}^{2})(\\theta)\\Big),}\\end{array}\n$$", "text_format": "latex", "page_idx": 33}, {"type": "text", "text": "where we applied Cauchy-Schwarz inequality in the last inequality; the constant $C_{E.5}$ is the constant $C$ introduced in Proposition E.5. ", "page_idx": 33}, {"type": "text", "text": "With the coarse estimate ", "page_idx": 33}, {"type": "equation", "text": "$$\n{\\big|}\\{I\\subseteq[d_{u}]:|I|=t\\}{\\big|}={\\binom{d_{u}}{i}}\\leq d_{u}^{t}\\leq(R d)^{t},\n$$", "text_format": "latex", "page_idx": 33}, {"type": "text", "text": "we have ", "page_idx": 33}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\quad\\Big(\\underset{I\\subseteq[d_{u}]:|I|\\geq2}{\\sum}\\exp\\Big(-\\varepsilon|I|(\\ln(u)-C_{E.5}-\\mathrm{h}^{*})\\Big)\\Big)}\\\\ &{\\leq\\underset{t=2}{\\sum}\\exp\\bigg(-\\varepsilon t\\Big(\\mathrm{h}(u)-C_{E.5}-\\frac{\\log(R)+\\log(d)}{\\varepsilon}-\\mathrm{h}^{*}\\Big)\\bigg).}\\end{array}\n$$", "text_format": "latex", "page_idx": 33}, {"type": "text", "text": "The geometric series above is finite if $\\mathrm{h}(u)$ is large enough, and this can be achieved by imposing assumption of $C_{0}$ and relying on (53). Now, let us impose the first assumption on $C_{0}$ ", "page_idx": 33}, {"type": "equation", "text": "$$\nC_{0}\\geq C_{E.5}+(2+2\\log(d)+100)/\\varepsilon.\n$$", "text_format": "latex", "page_idx": 33}, {"type": "text", "text": "Then, by (53) we have ", "page_idx": 33}, {"type": "equation", "text": "$$\n\\mathrm{h}(u)\\geq\\mathrm{h}^{*}+C_{0}(\\log(R)+1)\\geq\\mathrm{h}^{*}+C_{E.5}+2\\frac{\\log(R)+\\log(d)}{\\varepsilon}+\\frac{100}{\\varepsilon},\n$$", "text_format": "latex", "page_idx": 33}, {"type": "text", "text": "which in term implies the R.H.S. of (55) is ", "page_idx": 33}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\frac{\\exp\\bigg(-2\\varepsilon\\big(\\mathbf{h}(u)-C_{E,5}-\\frac{\\log(R)+\\log(d)}{\\varepsilon}-\\mathbf{h}^{*}\\big)\\bigg)}{1-\\exp\\bigg(-\\varepsilon\\Big(\\mathbf{h}(u)-C_{E,5}-\\frac{\\log(R)+\\log(d)}{\\varepsilon}-\\mathbf{h}^{*}\\Big)\\bigg)}}\\\\ &{\\leq\\frac{\\exp\\bigg(-2\\varepsilon\\big(\\mathbf{h}(u)-C_{E,5}-\\frac{\\log(R)+\\log(d)}{\\varepsilon}-\\mathbf{h}^{*}\\big)\\bigg)}{1-e^{-100}}}\\\\ &{\\leq2\\exp\\bigg(-2\\varepsilon\\Big(\\mathbf{h}(u)-C_{E,5}-\\frac{\\log(R)+\\log(d)}{\\varepsilon}-\\mathbf{h}^{*}\\Big)\\bigg)}\\\\ &{=\\frac{1}{4}\\exp\\bigg(-2\\varepsilon\\Big(\\mathbf{h}(u)-C_{E,5}-\\frac{\\log(R)+\\log(d)}{\\varepsilon}-\\mathbf{h}^{*}-\\frac{\\log(8)}{2\\varepsilon}\\Big)\\bigg)}\\\\ &{\\leq\\frac{1}{4}\\exp\\bigg(-2\\varepsilon\\big(\\mathbf{h}(u)-C_{0}(\\log(R)+1)-\\mathbf{h}^{*}\\big)\\bigg)}\\end{array}\n$$", "text_format": "latex", "page_idx": 33}, {"type": "text", "text": "Substituting the above estimate into (54), together with (49) we have ", "page_idx": 33}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{(\\mathbb{E}_{u}f_{u})^{2}(\\theta)\\le\\displaystyle\\frac{1}{4}\\exp\\Big(-2\\varepsilon\\big(\\mathrm{h}(u)-C_{0}(\\log(R)+1)-\\mathrm{h}^{*}\\big)\\Big)\\cdot\\Big(\\sum_{I\\subseteq[d_{u}]:|I|\\ge2}(\\mathbb{E}_{u}f_{u,I}^{2})(\\theta)\\Big)}\\\\ &{\\qquad\\qquad\\qquad\\le\\displaystyle\\frac{1}{2}\\exp\\Big(-2\\varepsilon\\big(\\mathrm{h}(u)-C_{0}(\\log(R)+1)-\\mathrm{h}^{*}\\big)\\Big)(\\mathbb{E}_{u}f_{u}^{2})(\\theta).}\\end{array}\n$$", "text_format": "latex", "page_idx": 33}, {"type": "text", "text": "Therefore, we have derived an inequality which is slightly stronger than (37). ", "page_idx": 34}, {"type": "text", "text": "To derive (38), let us first show $\\mathbb{E}f_{u}(X)$ is relatively small using (57) and Jesnon's inequality: ", "page_idx": 34}, {"type": "equation", "text": "$$\n\\begin{array}{r l r}&{}&{\\big(\\mathbb{E}[f_{u}(X)]\\big)^{2}\\leq\\mathbb{E}\\big[(\\mathbb{E}_{u}f_{u})^{2}(X)\\big]\\leq\\frac{1}{2}\\exp\\Big(-2\\varepsilon\\big(\\mathbf{h}(u)-C_{0}(\\log(R)+1)-\\mathbf{h}^{*}\\big)\\Big)\\mathbb{E}\\big[f_{u}^{2}(X)\\big]}\\\\ &{}&{\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\leq\\frac{1}{2}\\mathbb{E}\\big[f_{u}^{2}(X)\\big].}\\end{array}\n$$", "text_format": "latex", "page_idx": 34}, {"type": "text", "text": "Thus, the variance and the second moment of $f_{u}(X)$ are the same up to a factor of 2: ", "page_idx": 34}, {"type": "equation", "text": "$$\n\\mathbb{E}\\big[\\tilde{f}_{u}^{2}(X)\\big]=\\mathbb{E}\\big[f_{u}^{2}(X)\\big]-\\big(\\mathbb{E}[f_{u}(X)]\\big)^{2}\\geq\\frac{1}{2}\\mathbb{E}\\big[f_{u}^{2}(X)\\big].\n$$", "text_format": "latex", "page_idx": 34}, {"type": "text", "text": "We conclude that ", "page_idx": 34}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{E}\\big[(\\mathbb{E}_{u}\\tilde{f}_{u})^{2}(X)\\big]\\leq\\!\\mathbb{E}\\big[(\\mathbb{E}_{u}f_{u})^{2}(X)\\big]}\\\\ &{\\phantom{\\leq}\\leq\\!\\frac{1}{2}\\exp\\Big(-2\\varepsilon\\big(\\mathrm{h}(u)-C_{0}(\\log(R)+1)-\\mathrm{h}^{*}\\big)\\Big)\\mathbb{E}\\big[f_{u}^{2}(X)\\big]}\\\\ &{\\phantom{\\leq}\\leq\\exp(-2\\varepsilon(\\mathrm{h}(u)-C_{0}(1+\\log(R))-\\mathrm{h}^{*}))\\mathbb{E}\\big[\\tilde{f}_{u}^{2}(X)\\big].}\\end{array}\n$$", "text_format": "latex", "page_idx": 34}, {"type": "text", "text": "Therefore, we complete the proof of (38). ", "page_idx": 34}, {"type": "text", "text": "Part II: Derivation of (39). ", "text_level": 1, "page_idx": 34}, {"type": "text", "text": "It remains to show (39) and the proof is similar. Fix $I\\subset[d_{u}]$ with $|I|\\ge2$ , let $I^{\\prime}=I\\backslash\\{i\\}$ and we represent $x\\in[q]^{T}$ as $(x_{0},x_{1})$ , where ", "page_idx": 34}, {"type": "equation", "text": "$$\nx_{0}:=\\!\\left(x_{v}\\,:\\,v\\not\\in\\bigcup_{j\\in I^{\\prime}}T_{u_{j}}\\right)\\qquad\\qquad{\\mathrm{and}}\\qquad\\qquad x_{1}:=\\!\\left(x_{v}\\,:\\,v\\in\\bigcup_{j\\in I^{\\prime}}T_{u_{j}}\\right).\n$$", "text_format": "latex", "page_idx": 34}, {"type": "text", "text": "With this notation, we have $a(x)=a(x_{0})$ . Thus, ", "page_idx": 34}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\mathbb{E}\\big[\\vert\\tilde{f}_{u,I}(X)a(X)\\vert\\big]=\\mathbb{E}\\Big[\\big\\vert\\mathbb{E}\\big[\\tilde{f}_{u,I}(X)\\,\\big\\vert\\,X_{0}\\big]\\cdot a(X_{0})\\big\\vert\\Big]}&{}\\\\ {\\quad\\leqslant\\sqrt{\\mathbb{E}\\Big[\\big(\\mathbb{E}\\big[\\tilde{f}_{u,I}(X)\\,\\big\\vert\\,X_{0}\\big]\\big)^{2}\\Big]}\\cdot\\sqrt{\\mathbb{E}\\big[a^{2}(X_{0})\\big]}}&{}\\\\ {\\quad\\leqslant\\sqrt{\\mathbb{E}\\Big[\\big(\\mathbb{E}\\big[f_{u,I}(X)\\,\\big\\vert\\,X_{0}\\big]\\big)^{2}\\Big]}\\cdot\\sqrt{\\mathbb{E}\\big[a^{2}(X_{0})\\big]}}&{}\\\\ {\\quad\\leqslant\\exp\\Big(-\\frac{\\varepsilon}{2}\\vert I\\vert\\cdot\\{i\\}\\vert\\big(\\mathrm{h}(u)-C_{E.5}-\\mathrm{h}^{\\ast}\\big)\\Big)\\sqrt{\\mathbb{E}\\big[f_{u,I}^{2}(X)\\big]}\\cdot\\sqrt{\\mathbb{E}\\big[a^{2}(X)\\big]},}&{}\\end{array}\n$$", "text_format": "latex", "page_idx": 34}, {"type": "text", "text": "where the last inequality follows from Proposition E.5. Hence, ", "page_idx": 34}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{E}\\big[|\\tilde{f}_{n}(X)a(X)|\\big]}\\\\ &{\\stackrel{\\leq}\\sum_{I\\subseteq[d_{u}]:\\,|I|\\geq2}\\exp\\Big(-\\frac{\\varepsilon}{2}|I\\setminus\\{i\\}|(\\mathrm{h}(u)-C_{E.5}-\\mathrm{h}^{*})\\Big)\\sqrt{\\mathbb{E}\\big[f_{u,I}^{2}(X)\\big]}\\cdot\\sqrt{\\mathbb{E}\\big[a^{2}(X)\\big]}}\\\\ &{\\stackrel{\\leq}\\exp\\Big(\\underset{I\\subseteq[d_{u}]:\\,|I|\\geq2}{\\sum}\\exp\\big(-\\varepsilon|I\\setminus\\{i\\}|(\\mathrm{h}(u)-C_{E.5}-\\mathrm{h}^{*})\\big)\\Big)^{1/2}\\cdot\\sqrt{\\underset{I\\subseteq[d_{u}]:\\,|I|\\geq2}{\\sum}\\mathbb{E}\\big[f_{u,I}^{2}(X)\\big]}\\cdot\\sqrt{\\mathbb{E}\\big[a^{2}(X)\\big]}}\\end{array}\n$$", "text_format": "latex", "page_idx": 34}, {"type": "text", "text": "Next, we impose the second assumption on $C_{0}$ that ", "page_idx": 34}, {"type": "equation", "text": "$$\nC_{0}\\geq C_{E.7},\n$$", "text_format": "latex", "page_idx": 34}, {"type": "text", "text": "where $C_{E.7}$ is the constant introduced in Corollary E.7. Together our assumption $\\mathrm{h}(u)\\,\\geq\\,\\mathrm{h}^{\\ast}\\,+\\,$ $C_{0}(\\log(R)+1)$ at the beginning of the proof, we can apply the Corollary and (58) to get ", "page_idx": 34}, {"type": "equation", "text": "$$\n\\sum_{I\\subseteq[d_{u}]:\\,|I|\\geq2}\\mathbb{E}f_{u,I}^{2}(X)\\leq2\\mathbb{E}(f_{u}(X))^{2}\\leq4\\mathbb{E}(\\tilde{f}_{u}(X))^{2}.\n$$", "text_format": "latex", "page_idx": 34}, {"type": "text", "text": "Repeating the same argument as in the proof of (38) and relying on the assumption (56) of $C_{0}$ ", "page_idx": 35}, {"type": "equation", "text": "$$\n\\begin{array}{r l r}{\\lefteqn{\\sum_{\\stackrel{\\mathrm{S}}{=}[d_{u}]:\\vert I\\vert\\geq2}\\exp(-\\varepsilon\\vert I\\backslash\\{i\\}\\vert(\\mathrm{h}(u)-C_{E,5}-\\mathrm{h}^{*}))\\leq\\sum_{t=1}^{\\infty}\\exp\\bigg(-\\varepsilon t\\Big(\\mathrm{h}(u)-C_{E,5}-\\mathrm{h}^{*}-2\\frac{\\log(R d)}{\\varepsilon}\\Big)}}\\\\ &{}&{\\leq\\frac{1}{4}\\exp\\bigg(-\\varepsilon\\Big(\\mathrm{h}(u)-C_{0}(\\log(R)+1)-\\mathrm{h}^{*}\\bigg)\\bigg).}\\end{array}\n$$", "text_format": "latex", "page_idx": 35}, {"type": "text", "text": "Therefore, combining (60), (61), and (59) we get ", "page_idx": 35}, {"type": "equation", "text": "$$\n\\mathbb{E}\\big[\\vert\\tilde{f}_{u}(X)a(X)\\vert\\big]\\leq\\exp\\Big(-\\frac{\\varepsilon}{2}\\big(\\mathrm{h}(u)-C_{0}(\\log(R)+1)-\\mathrm{h}^{*}\\big)\\Big)\\cdot\\sqrt{\\mathbb{E}\\big[\\tilde{f}_{u}^{2}(X)\\big]}\\cdot\\sqrt{\\mathbb{E}\\big[a^{2}(X)\\big]}.\n$$", "text_format": "latex", "page_idx": 35}, {"type": "text", "text": "F  Induction Step 2: Decay of $f_{k}$ and the proof of Theorem B.6 ", "text_level": 1, "page_idx": 35}, {"type": "text", "text": "As a continuation of the inductive step, we adapt the notation introduced in the previous section. Building on the properties of an single component $f_{u}$ from Proposition E.1, our objective is to deduce variance and covariance decay of $f_{k}$ , which is stated in Proposition F.1 below. Once it is established, wewill be ready to proveTheoremB.6. ", "page_idx": 35}, {"type": "text", "text": "F.1Properties of $f_{k}$ ", "text_level": 1, "page_idx": 35}, {"type": "text", "text": "The main goal of this subsection is to derive the following Proposition ", "page_idx": 35}, {"type": "text", "text": "Proposition F.1. There exists $C=C(M,d,c^{*})\\geq1$ so that the following holds. For any $\\rho^{\\prime}\\in T$ satisfying ", "page_idx": 35}, {"type": "equation", "text": "$$\n\\mathrm{h}(\\rho^{\\prime})\\geq\\mathrm{h}^{\\ast}+C(1+\\log(R)).\n$$", "text_format": "latex", "page_idx": 35}, {"type": "text", "text": "Fix a positive integer $k_{1}$ such that ", "page_idx": 35}, {"type": "equation", "text": "$$\n\\mathrm{h}(\\rho^{\\prime})\\geq k_{1}\\geq\\mathrm{h}^{\\ast}+C(1+\\log(R)).\n$$", "text_format": "latex", "page_idx": 35}, {"type": "text", "text": "Consider a function ", "page_idx": 35}, {"type": "equation", "text": "$$\nf(x)=\\!c+\\sum_{\\sigma\\in{\\mathcal F}({\\mathcal B}_{\\leq\\rho^{\\prime}})}c_{\\sigma}\\phi_{\\sigma}(x)\n$$", "text_format": "latex", "page_idx": 35}, {"type": "text", "text": "with $\\mathbb{E}f(X)=0$ We decompose $f$ according to Lemma $D.I$ with the given $k_{1}$ . Then, the following holds: ", "page_idx": 35}, {"type": "equation", "text": "$$\n\\mathbb{E}\\big[(\\mathbb{E}_{\\rho^{\\prime}}f_{k})^{2}(X_{\\rho^{\\prime}})\\big]\\leq\\exp\\Big(-\\varepsilon\\big(\\mathrm{h}(\\rho^{\\prime})+k-C(\\log(R)+1)-2\\mathrm{h}^{*}\\big)\\Big)\\mathbb{E}f_{k}^{2}(X),\n$$", "text_format": "latex", "page_idx": 35}, {"type": "text", "text": "\u00b7 for $k=k_{1}$ \uff0c", "page_idx": 35}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathbb{E}\\big[(\\mathbb{E}_{\\rho^{\\prime}}f_{k_{1}})^{2}(X_{\\rho^{\\prime}})\\big]\\leq\\exp\\Big(-\\varepsilon\\big(\\mathrm{h}(\\rho^{\\prime})-k-C(\\log(R)+1)\\big)\\Big)\\mathbb{E}f_{k_{1}}^{2}(X),\\,a n d}\\end{array}\n$$", "text_format": "latex", "page_idx": 35}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\left|\\mathbb{E}\\big[f_{k}(X)f_{m}(X)\\big]\\right|\\leq\\exp\\Big(-\\frac{\\varepsilon}{2}\\big(k-C(\\log(R)+1)-\\mathrm{h}^{*}\\big)\\Big)\\sqrt{\\mathbb{E}\\big[f_{k}^{2}(X)\\big]\\mathbb{E}\\big[f_{m}^{2}(X)\\big]},}\\end{array}\n$$", "text_format": "latex", "page_idx": 35}, {"type": "text", "text": "Before we prove the Proposition, let us prove the following second moment bounds for the partial sums of $\\tilde{f}_{u}$ ", "page_idx": 36}, {"type": "text", "text": "Lemma F.2. There exists a constant $C=C(M,d,c^{*})\\geq1$ so that the following holds. Consider the same description as stated in Proposition $F.I$ and $k_{1}\\geq\\mathrm{h}^{*}+C(\\log(R)+1)$ . Let $(h,k)$ be a pair of integers satisfying $k_{1}<h\\leq k\\leq l^{\\prime}$ .For $u\\in D_{k}(\\rho^{\\prime})$ ,let ", "page_idx": 36}, {"type": "equation", "text": "$$\nf_{h,u}(x)=\\sum_{v\\in D_{h}(u)}\\tilde{f}_{v}(x).\n$$", "text_format": "latex", "page_idx": 36}, {"type": "text", "text": "In other words, ", "page_idx": 36}, {"type": "equation", "text": "$$\nf_{h}(x)=\\sum_{u\\in D_{k}(\\rho^{\\prime})}f_{h,u}(x).\n$$", "text_format": "latex", "page_idx": 36}, {"type": "text", "text": "The following holds: First, for $u\\in D_{k}(\\rho^{\\prime})$ ", "page_idx": 36}, {"type": "equation", "text": "$$\n\\frac{1}{2}\\sum_{v\\in D_{h}(u)}\\mathbb{E}\\tilde{f}_{v}^{2}(X)\\le\\mathbb{E}f_{h,u}^{2}(X)\\le2\\sum_{v\\in D_{h}(u)}\\mathbb{E}\\tilde{f}_{v}^{2}(X).\n$$", "text_format": "latex", "page_idx": 36}, {"type": "text", "text": "Second, ", "page_idx": 36}, {"type": "equation", "text": "$$\n\\frac{1}{4}\\sum_{u\\in L_{k}(\\rho^{\\prime})}\\mathbb{E}f_{h,u}^{2}(X)\\leq\\mathbb{E}f_{h}^{2}(X)\\leq4\\sum_{u\\in L_{k}(\\rho^{\\prime})}\\mathbb{E}f_{h,u}^{2}(X).\n$$", "text_format": "latex", "page_idx": 36}, {"type": "text", "text": "Proof. Let $C_{0}=C_{0}(M,d,\\varepsilon^{\\prime})$ denote the constant introduced in the statement of the Lemma. Its precise value will be determined along the proof. ", "page_idx": 36}, {"type": "text", "text": "Let us fix $u\\in D_{k}(\\rho^{\\prime})$ . Consider the following conditional expectation of $f_{h,u}(x)$ ", "page_idx": 36}, {"type": "equation", "text": "$$\n(\\mathbb{E}_{h}f_{h,u})(x)=\\mathbb{E}\\big[f_{h,u}(X)\\,\\big|\\,X_{v}=x_{v}\\,:\\,\\mathrm{h}(v)\\ge h\\big]=\\sum_{v\\in D_{h}(\\rho^{\\prime})}(\\mathbb{E}_{v}\\tilde{f}_{v})(x_{v}).\n$$", "text_format": "latex", "page_idx": 36}, {"type": "text", "text": "Comparing the second moments of $\\begin{array}{r}{f_{h,u}(x)=\\sum_{v\\in D_{h}(u)}\\tilde{f}_{v}(x)}\\end{array}$ and $\\begin{array}{r}{\\sum_{v\\in D_{h}(u)}(\\mathbb{E}_{v}\\tilde{f}_{v})(x_{v})}\\end{array}$ we get ", "page_idx": 36}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\mathbb{\\xi}\\Big[\\Big(\\displaystyle\\sum_{v\\in D_{h}(u)}\\tilde{f}_{v}(X)\\Big)^{2}\\Big]=\\displaystyle\\sum_{v\\in D_{h}(u)}\\mathbb{E}\\big[\\tilde{f}_{v}^{2}(X)\\big]+\\displaystyle\\sum_{v,v^{\\prime}\\in D_{h}(u):\\,v\\neq v^{\\prime}}\\mathbb{E}\\big[\\tilde{f}_{v}(X)\\tilde{f}_{v^{\\prime}}(X)\\big]}&{}\\\\ {=\\displaystyle\\sum_{v\\in D_{h}(u)}\\mathbb{E}\\big[\\tilde{f}_{v}^{2}(X)\\big]+\\displaystyle\\sum_{(v,v^{\\prime})\\in(D_{h}(u))^{2}:\\,v\\neq v^{\\prime}}\\mathbb{E}\\bigg[\\mathbb{E}\\Big[(\\mathbb{E}_{v}\\tilde{f}_{v})(X)(\\mathbb{E}_{v^{\\prime}}\\tilde{f}_{v^{\\prime}})(X)\\Big\\vert\\,\\Big.\\Big.}&{}\\\\ {\\displaystyle\\left.\\left.-\\mathbb{E}\\Big[\\Big(\\displaystyle\\sum_{v\\in D_{h}(u)}(\\mathbb{E}_{v}\\tilde{f}_{v})(X)\\Big)^{2}\\Big]+\\displaystyle\\sum_{v\\in D_{h}(u)}\\Big(\\mathbb{E}\\big[\\tilde{f}_{v}^{2}(X)\\big]-\\mathbb{E}\\big[(\\mathbb{E}_{v}\\tilde{f}_{v})^{2}(X)\\big]\\Big)\\right.\\right.}&{}\\\\ {\\displaystyle\\left.\\left.\\geq\\displaystyle\\sum_{v\\in D_{h}(u)}\\Big(1-\\exp\\Big(-\\varepsilon\\big(h-C_{E,1}(1+\\log(R))-\\mathrm{h}^{*}\\big)\\Big)\\Big)\\mathbb{E}\\big[\\tilde{f}_{v}^{2}(X)\\big],\\right.}&{}\\end{array}\n$$", "text_format": "latex", "page_idx": 36}, {"type": "text", "text": "where the last inequality follow from Proposition E.1 and $C_{E,1}$ is the constant $C$ introduced in Proposition E.1. ", "page_idx": 36}, {"type": "text", "text": "Here we impose the first assumption on $C_{0}$ ", "page_idx": 36}, {"type": "equation", "text": "$$\nC_{0}>10\\operatorname*{max}\\{\\varepsilon^{-1},C_{E.1}\\}.\n$$", "text_format": "latex", "page_idx": 36}, {"type": "text", "text": "Then, due to $k_{1}\\geq\\mathrm{h}^{\\ast}+C_{0}(\\log(R)+1)$ we have ", "page_idx": 36}, {"type": "text", "text": "$\\operatorname{xp}(-\\varepsilon(h-C_{E.1}(1+\\log(R))-\\ h^{*})))\\leq\\exp(-\\varepsilon(k_{1}-C_{E.1}(1+\\log(R))-\\ h^{*})))\\leq\\exp(-\\varepsilon\\cdot0.9C_{0})\\leq1$ /2, and thus (65) can be simplified to ", "page_idx": 36}, {"type": "equation", "text": "$$\n\\mathbb{E}\\big[f_{h,u}^{2}(X)\\big]\\ge\\!\\frac{1}{2}\\sum_{v\\in D_{h}(u)}\\mathbb{E}\\big[\\tilde{f}_{v}^{2}(X)\\big].\n$$", "text_format": "latex", "page_idx": 36}, {"type": "text", "text": "With the lower bound been established, the upper bound can also be derived in the same fashion. Let us first recycle the first three lines of (65): ", "page_idx": 37}, {"type": "equation", "text": "$$\n\\begin{array}{r l r}{\\lefteqn{\\mathbb{E}\\Big[\\Big(\\sum_{v\\in D_{h}(u)}\\tilde{f}_{v}(X)\\Big)^{2}\\Big]=\\!\\mathbb{E}\\Big(\\sum_{v\\in D_{h}(u)}(\\mathbb{E}_{v}\\tilde{f}_{v})(X)\\Big)^{2}+\\!\\!\\!\\!\\sum_{v\\in D_{h}(u)}\\mathbb{E}(\\tilde{f}_{v}(X))^{2}-\\mathbb{E}(\\mathbb{E}_{v}\\tilde{f}_{v})^{2}(X)}\\\\ &{}&{\\le\\!\\mathbb{E}\\Big(\\sum_{v\\in D_{h}(u)}(\\mathbb{E}_{v}\\tilde{f}_{v})(X)\\Big)^{2}+\\!\\!\\!\\!\\sum_{v\\in D_{h}(u)}\\mathbb{E}(\\tilde{f}_{v}(X))^{2}.\\ \\ \\ \\ \\ }\\end{array}\n$$", "text_format": "latex", "page_idx": 37}, {"type": "text", "text": "Notice that we can apply Lemma C.2 for the first summand in the above expression. ", "page_idx": 37}, {"type": "equation", "text": "$$\n\\mathbb{E}\\Big(\\sum_{v\\in D_{h}(u)}(\\mathbb{E}_{v}\\tilde{f}_{v})(X)\\Big)^{2}=\\mathbb{E}\\Big(\\sum_{v\\in D_{h}(u)}(\\mathbb{E}_{v}\\tilde{f}_{v})(X_{v})\\Big)^{2}\\leq C_{C.2}R\\sum_{v\\in D_{h}(u)}(\\mathbb{E}_{v}\\tilde{f}_{v})^{2}(X_{v})\n$$", "text_format": "latex", "page_idx": 37}, {"type": "text", "text": "where $C_{C.2}$ is the constant introduced in Lemma C.2. Again, applying the estimate from Proposition E.1 wehave ", "page_idx": 37}, {"type": "equation", "text": "$$\n\\Im_{C.2}R\\sum_{v\\in D_{h}(u)}(\\mathbb{E}_{v}\\tilde{f}_{v})^{2}(X_{v})\\le C_{C.2}R\\exp\\Big(-2\\ensuremath{\\varepsilon}\\big(h-C_{E.1}(1+\\log(R))-\\mathbf{h}^{*}\\big)\\Big)\\sum_{v\\in D_{h}(u)}\\mathbb{E}\\tilde{f}_{v}^{2}(X).\n$$", "text_format": "latex", "page_idx": 37}, {"type": "text", "text": "Here we impose the second assumption on $C_{0}$ that ", "page_idx": 37}, {"type": "equation", "text": "$$\nC_{0}\\geq C_{E.1}+\\frac{1+\\log(C_{C.2})}{2\\varepsilon}.\n$$", "text_format": "latex", "page_idx": 37}, {"type": "text", "text": "Then, relying on $h>k_{1}\\geq\\mathrm{h}^{*}+C_{0}(\\log(R)+1)$ ", "page_idx": 37}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\quad C_{C.2}R\\exp\\Big(-2\\varepsilon\\big(h-C_{E.1}(1+\\log(R))-\\mathrm{h}^{*}\\big)\\Big)}\\\\ &{\\leq\\exp\\Big(-2\\varepsilon\\Big(h-C_{E.1}\\big(1+\\log(R)\\big)-\\mathrm{h}^{*}-\\frac{\\log\\left(C_{C.2}\\right)+\\log(R)}{2\\varepsilon}\\Big)\\Big)}\\\\ &{\\leq1,}\\end{array}\n$$", "text_format": "latex", "page_idx": 37}, {"type": "text", "text": "which in turn implies ", "page_idx": 37}, {"type": "equation", "text": "$$\n\\mathbb{E}(f_{h,u}(X))^{2}\\leq2\\sum_{v\\in D_{h}(u)}\\mathbb{E}(\\tilde{f}_{v}(X))^{2}.\n$$", "text_format": "latex", "page_idx": 37}, {"type": "text", "text": "Now it remains to show the second statement. Notice that $f_{h}=f_{h,\\rho^{\\prime}}$ , we immediately have ", "page_idx": 37}, {"type": "equation", "text": "$$\n\\frac{1}{2}\\sum_{v\\in D_{h}(\\rho^{\\prime})}\\mathbb{E}\\tilde{f}_{v}^{2}(X)\\le\\mathbb{E}f_{h}^{2}(X)\\le2\\sum_{v\\in D_{h}(\\rho^{\\prime})}\\mathbb{E}\\tilde{f}_{v}^{2}(X)\n$$", "text_format": "latex", "page_idx": 37}, {"type": "text", "text": "Together with ", "page_idx": 37}, {"type": "equation", "text": "$$\n\\frac{1}{2}\\sum_{u\\in D_{k}(\\rho^{\\prime})}\\mathbb{E}f_{k,u}^{2}(X)\\le\\sum_{v\\in D_{h}(\\rho^{\\prime})}\\mathbb{E}\\tilde{f}_{v}^{2}(X)\\le2\\sum_{u\\in D_{k}(\\rho^{\\prime})}\\mathbb{E}f_{k,u}^{2}(X),\n$$", "text_format": "latex", "page_idx": 37}, {"type": "text", "text": "the second statement of the lemma follows. ", "page_idx": 37}, {"type": "text", "text": "ProofofProposition $F.l$ .Let $C_{0}=C_{0}(M,d,c^{*})$ denote the constant introduced in the statement of the Lemma. Its precise value will be determined along the proof. Let us make the first assumption On $C_{0}$ that ", "page_idx": 37}, {"type": "equation", "text": "$$\nC_{0}\\geq C_{F.2},\n$$", "text_format": "latex", "page_idx": 37}, {"type": "text", "text": "where $C_{F,2}$ is the constant introduced in Lemma F.2. Now, we could apply the statements of the Lemma. ", "page_idx": 37}, {"type": "text", "text": "Part 1: Derivation of (62). ", "text_level": 1, "page_idx": 37}, {"type": "text", "text": "Fix $k\\in[k_{1}+1,l^{\\prime}]$ . Applying Lemma F.2 with the parameters $h$ and $k$ in the Lemma setting to be $k$ ", "page_idx": 38}, {"type": "equation", "text": "$$\n\\mathbb{E}(f_{k}(\\boldsymbol{X}))^{2}\\geq\\frac{1}{2}\\sum_{u\\in D_{k}(\\rho^{\\prime})}\\mathbb{E}(\\tilde{f}_{u}(\\boldsymbol{X}))^{2}.\n$$", "text_format": "latex", "page_idx": 38}, {"type": "text", "text": "The next step is to compare the sum of $\\mathbb{E}\\tilde{f}_{u}^{2}(X)$ with $\\mathbb{E}\\big[(\\mathbb{E}_{\\rho^{\\prime}}f_{k})^{2}(X_{\\rho^{\\prime}})\\big]$ . By Jenson's inequality, ", "page_idx": 38}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\mathbb{E}\\big[(\\mathbb{E}_{\\rho^{\\prime}}f_{k})^{2}(X_{\\rho^{\\prime}})\\big]=\\mathbb{E}\\Big[\\Big(\\sum_{u\\in D_{k}(\\rho^{\\prime})}(\\mathbb{E}_{\\rho^{\\prime}}{\\tilde{f}}_{u})(X_{\\rho^{\\prime}})\\Big)^{2}\\Big]}&{}\\\\ {\\le\\!\\mathbb{E}\\Big[|D_{k}(\\rho^{\\prime})|\\!\\sum_{u\\in D_{k}(\\rho^{\\prime})}(\\mathbb{E}_{\\rho^{\\prime}}{\\tilde{f}}_{u})^{2}(X_{\\rho^{\\prime}})\\Big]}&{}\\\\ {=\\!|D_{k}(\\rho^{\\prime})|\\!\\sum_{u\\in D_{k}(\\rho^{\\prime})}\\mathbb{E}\\big[(\\mathbb{E}_{\\rho^{\\prime}}{\\tilde{f}}_{u})^{2}(X_{\\rho^{\\prime}})\\big].}&{}\\end{array}\n$$", "text_format": "latex", "page_idx": 38}, {"type": "text", "text": "For each summand, we can apply (8) from Lemma A.5 to get the following estimate. ", "page_idx": 38}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathbb{E}\\bigl[(\\mathbb{E}_{\\rho^{\\prime}}\\tilde{f}_{u})^{2}(X_{\\rho^{\\prime}})\\bigr]\\leq\\!C_{A.5}(l^{\\prime}-k)^{2q}\\lambda^{2(l^{\\prime}-k)}\\mathbb{E}\\bigl[(\\mathbb{E}_{u}\\tilde{f}_{u})^{2}(X_{u})\\bigr]}\\end{array}\n$$", "text_format": "latex", "page_idx": 38}, {"type": "text", "text": "where $C_{A.5}$ is the constant introduced in the Lemma. Together with $|D_{k}(\\rho^{\\prime})|\\leq R d^{l^{\\prime}-k}$ from the assumption on $T$ and $d\\lambda^{2}\\leq\\exp(-1.1\\varepsilon)$ from the definiton of $\\varepsilon$ ", "page_idx": 38}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\mathbb{E}\\big[(\\mathbb{E}_{\\rho^{\\prime}}f_{k})^{2}(X_{\\rho^{\\prime}})\\big]\\leq\\!C_{A.5}(l^{\\prime}-k)^{2q}R\\exp(-1.1\\varepsilon(l^{\\prime}-k))\\underset{u\\in D_{k}(\\rho^{\\prime})}{\\sum}\\mathbb{E}\\big[(\\mathbb{E}_{u}\\tilde{f}_{u})^{2}(X_{u})\\big]}&{}\\\\ {\\leq\\!\\frac{1}{2}\\exp\\Big(-\\varepsilon\\Big(l^{\\prime}-C^{\\prime}(1+\\log(R))-k\\Big)\\Big)\\underset{u\\in D_{k}(\\rho^{\\prime})}{\\sum}\\mathbb{E}\\big[(\\mathbb{E}_{u}\\tilde{f}_{u})^{2}(X_{u})\\big]}&{}\\end{array}\n$$", "text_format": "latex", "page_idx": 38}, {"type": "text", "text": "where we set ", "page_idx": 38}, {"type": "equation", "text": "$$\nC^{\\prime}=1+\\log\\left(1+2C_{A.5}\\operatorname*{max}_{n\\in\\mathbb{N}}n^{2q}\\exp(-0.1\\varepsilon n)\\right)<+\\infty.\n$$", "text_format": "latex", "page_idx": 38}, {"type": "text", "text": "By Proposition E.1 we have ", "page_idx": 38}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathbb{E}\\big[(\\mathbb{E}_{u}\\tilde{f}_{u})^{2}(X)\\big]\\leq\\exp(-2\\varepsilon(k-C_{E.1}(1+\\log(R))-\\mathrm{h}^{*}))\\mathbb{E}(\\tilde{f}_{u}(X))^{2},}\\end{array}\n$$", "text_format": "latex", "page_idx": 38}, {"type": "text", "text": "where $C_{E,1}$ is the constant $C$ introduced in the Proposition. Substituting this inequality into (69), together with (68) from first step, ", "page_idx": 38}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\Xi\\big[(\\mathbb{E}_{\\rho^{\\prime}}f_{k})^{2}(X_{\\rho^{\\prime}})\\big]\\leq\\displaystyle\\frac{1}{2}\\exp\\Big(-\\varepsilon\\Big(l^{\\prime}+k-(C^{\\prime}+C_{E.1})(\\log(R)+1)-2\\mathrm{h}^{*}\\Big)\\Big)\\sum_{u\\in D_{k}(\\rho^{\\prime})}\\mathbb{E}(\\tilde{f}_{u}(X))^{2}}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\le\\exp(-\\varepsilon(l^{\\prime}+k-(C^{\\prime}+C_{E.1})(\\log(R)+1)-2\\mathrm{h}^{*}))\\mathbb{E}(f_{k}(X))^{2}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 38}, {"type": "text", "text": "Now, we impose the second assumption on $C_{0}$ that ", "page_idx": 38}, {"type": "equation", "text": "$$\nC_{0}\\geq(C^{\\prime}+C_{E.1}),\n$$", "text_format": "latex", "page_idx": 38}, {"type": "text", "text": "we finished the proof of (62). ", "page_idx": 38}, {"type": "text", "text": "Part 2: Derivation of (63). ", "text_level": 1, "page_idx": 38}, {"type": "text", "text": "Let us consider ", "page_idx": 38}, {"type": "equation", "text": "$$\nh_{k_{1}}(x):=(\\mathbb{E}_{k_{1}}f_{k_{1}})(x)=\\mathbb{E}\\bigl[f_{k_{1}}(X)\\,\\big|\\,X_{u}=x_{u}\\,:\\,u\\in D_{k_{1}}(\\rho^{\\prime})\\bigr].\n$$", "text_format": "latex", "page_idx": 38}, {"type": "text", "text": "In other words, we may view $h_{k_{1}}(x)$ as a linear function with variables $x_{u}$ for $u\\in D_{k_{1}}(\\rho^{\\prime})$ with $\\mathbb{E}h_{k_{1}}(X)=\\mathbb{E}f_{k_{1}}(X)\\stackrel{.}{=}0$ . Then, ", "page_idx": 38}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{E}\\big[(\\mathbb{E}_{\\rho^{\\prime}}f_{k_{1}})^{2}(X_{\\rho^{\\prime}})\\big]=\\mathbb{E}\\big[(\\mathbb{E}_{\\rho^{\\prime}}h_{k_{1}})^{2}(X_{\\rho^{\\prime}})\\big]\\leq\\exp\\big(-\\varepsilon(\\mathrm{h}(\\rho^{\\prime})-k_{1}-C_{B.5})\\big)\\mathbb{E}h_{k_{1}}^{2}(X)}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\leq\\exp\\big(-\\varepsilon(\\mathrm{h}(\\rho^{\\prime})-k_{1}-C_{B.5})\\big)\\mathbb{E}f_{k_{1}}^{2}(X)}\\end{array}\n$$", "text_format": "latex", "page_idx": 38}, {"type": "text", "text": "The first inequality follows from Proposition B.5. The second inequality follows from Jensen's inequality. Here we impose the third assumption on $C_{0}$ that ", "page_idx": 39}, {"type": "equation", "text": "$$\nC_{0}\\geq C_{B.5},\n$$", "text_format": "latex", "page_idx": 39}, {"type": "text", "text": "the derivation of (63) follows. ", "page_idx": 39}, {"type": "text", "text": "Part 3: Derivation of (64) ", "text_level": 1, "page_idx": 39}, {"type": "text", "text": "For $w\\le\\rho^{\\prime}$ with $m\\leq\\mathrm{h}(w)\\leq k$ , let ", "page_idx": 39}, {"type": "equation", "text": "$$\nf_{m,w}(x)=\\sum_{v\\in D_{k}(w)}\\tilde{f}_{v}(x).\n$$", "text_format": "latex", "page_idx": 39}, {"type": "text", "text": "Let us make a remark that either by second property of $f$ from Lemma D.1 when $m=k_{1}$ or by Lemma F.2 in the case when $m>k_{1}$ , we have the following: For $w\\le\\rho^{\\prime}$ and $m\\leq k^{\\prime}\\leq\\mathrm{h}(w)$ ", "page_idx": 39}, {"type": "equation", "text": "$$\n\\Big(\\sum_{u\\in D_{k^{\\prime}}(w)}\\mathbb{E}f_{m,u}^{2}(X)\\Big)^{1/2}\\leq C_{D.1}R^{2}\\big(\\mathbb{E}f_{m,w}^{2}(X)\\big)^{1/2}.\n$$", "text_format": "latex", "page_idx": 39}, {"type": "text", "text": "With this notation, ", "page_idx": 39}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\quad\\displaystyle\\mathbb{E}f_{k}(X)f_{m}(X)}\\\\ &{=\\displaystyle\\sum_{u\\in D_{k}(\\rho^{\\prime})}\\mathbb{E}\\tilde{f}_{u}(X)f_{m,u}(X)+\\sum_{u,u^{\\prime}\\in D_{k}(\\rho^{\\prime}):\\,u\\neq u^{\\prime}}\\mathbb{E}\\tilde{f}_{u}(X)f_{m,u^{\\prime}}(X)}\\\\ &{=\\displaystyle\\sum_{u\\in D_{k}(\\rho^{\\prime})}\\mathbb{E}\\tilde{f}_{u}(X)f_{m,u}(X)+\\sum_{u,u^{\\prime}\\in D_{k}(\\rho^{\\prime}):\\,u\\neq u^{\\prime}}\\mathbb{E}\\biggl[\\mathbb{E}\\bigl[(\\mathbb{E}_{u}\\tilde{f}_{u})(X)(\\mathbb{E}_{u^{\\prime}}f_{m,u^{\\prime}})(X)\\,\\Big|\\,X_{\\mathbb{P}(u,u^{\\prime})}\\bigr]\\biggr]}\\\\ &{=\\!\\!\\mathbb{E}\\biggl[\\biggl(\\sum_{u\\in D_{k}(\\rho^{\\prime})}\\underbrace{(\\mathbb{E}_{u}\\tilde{f}_{u})(X)}_{u\\in D_{k}(\\rho^{\\prime})}\\biggr(\\underbrace{\\mathbb{E}_{u}f_{m,u}}_{u\\in D_{k}(\\rho^{\\prime})}(\\mathbb{E}_{u}f_{m,u})(X)\\bigr)\\biggr]+\\sum_{u\\in D_{k}(\\rho^{\\prime})}\\mathbb{E}\\tilde{f}_{u}(X)f_{m,u}(X)}\\end{array}~(7)}\\\\ &{\\quad\\displaystyle-\\sum_{u\\in D_{k}(\\rho^{\\prime})}\\mathbb{E}\\biggl[(\\mathbb{E}_{u}\\tilde{f}_{u})(X)(\\mathbb{E}_{u}f_{m,u})(X)\\biggr].}\\end{array}\n$$", "text_format": "latex", "page_idx": 39}, {"type": "text", "text": "We will estimate the three summands individually. ", "page_idx": 39}, {"type": "text", "text": "Part 3.1: Estimating first summand of (72) First, we apply Cauchy-Schwarz inequality, ", "page_idx": 39}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\bigg|\\mathbb{E}\\Big[\\big(\\sum_{u\\in D_{k}(\\rho^{\\prime})}(\\mathbb{E}_{u}\\tilde{f}_{u})(X)\\big)\\big(\\sum_{u\\in D_{k}(\\rho^{\\prime})}(\\mathbb{E}_{u}f_{m,u})(X)\\big)\\Big]\\bigg|=\\biggr|\\mathbb{E}\\Big[(\\mathbb{E}_{k}f_{k})(X)(\\mathbb{E}_{k}f_{m})(X)\\Big]\\bigg|}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\leq\\sqrt{\\mathbb{E}\\big[(\\mathbb{E}_{k}f_{k})^{2}(X)\\big]}\\sqrt{\\mathbb{E}\\big[(\\mathbb{E}_{k}f_{m})^{2}(X)\\big]}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 39}, {"type": "text", "text": "Now, combining (70) and (68), we have ", "page_idx": 39}, {"type": "equation", "text": "$$\n\\sqrt{\\mathbb{E}\\big[(\\mathbb{E}_{k}f_{k})^{2}(X)\\big]}\\leq\\sqrt{2}\\exp\\big(-\\varepsilon\\big(k-C_{E.1}(1+\\log(R))-\\mathrm{h}^{*}\\big)\\big)(\\mathbb{E}f_{k}^{2}(X))^{1/2}.\n$$", "text_format": "latex", "page_idx": 39}, {"type": "text", "text": "By setting ", "page_idx": 39}, {"type": "equation", "text": "$$\nC_{1}=C_{E.1}+\\frac{1}{\\varepsilon}\\Big(\\frac{1}{2}\\log(2)+\\log(2C_{D.1})+2\\Big),\n$$", "text_format": "latex", "page_idx": 39}, {"type": "text", "text": "we can conclude that ", "page_idx": 39}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\quad\\biggl|\\mathbb{E}\\Bigl[(\\underset{u\\in D_{k}(\\rho^{\\prime})}{\\sum}(\\mathbb{E}_{u}\\tilde{f}_{u})(X))(\\underset{u\\in D_{k}(\\rho^{\\prime})}{\\sum}(\\mathbb{E}_{u}f_{m,u})(X))\\Bigr]\\biggr|}\\\\ &{\\leq\\exp(-\\varepsilon(k-C_{1}(\\log(R)+1)-\\mathrm{h}^{*}))\\sqrt{\\mathbb{E}f_{k}^{2}(X)\\mathbb{E}f_{m}^{2}(X)},}\\end{array}\n$$", "text_format": "latex", "page_idx": 39}, {"type": "text", "text": "Part 3.2: Estimating second summand of (72) For the second summand of (72), we begin with the estimatefor each $u\\in D_{k}(\\rho^{\\prime})$ ", "page_idx": 39}, {"type": "equation", "text": "$$\n\\mathbb{E}|\\tilde{f}_{u}(X)f_{m,u}(X)|\\le\\sum_{i\\in[d_{u}]}\\mathbb{E}|\\tilde{f}_{u}(X)f_{m,u_{i}}(X)|.\n$$", "text_format": "latex", "page_idx": 39}, {"type": "text", "text": "Since for each $i\\in[d_{u}]$ wehave $f_{m,u_{i}}(x)=f_{m,u_{i}}(x_{\\le u_{i}})$ , we apply (39) from Proposition E.1 to $\\tilde{f}_{u}$ and $a(x)=f_{m,u_{i}}(\\dot{x})$ to get ", "page_idx": 40}, {"type": "equation", "text": "$$\n|\\tilde{f}_{u}(X)f_{m,u_{i}}(X)|\\leq\\sum_{i\\in[d_{u}]}\\exp\\Big(-\\frac{\\varepsilon}{2}\\big(k-C_{E.1}(\\log(R)+1)-\\mathrm{h}^{*}\\big)\\Big)(\\mathbb{E}\\tilde{f}_{u}^{2}(X))^{1/2}(\\mathbb{E}f_{m,u_{i}}^{2}(X))^{1/2},\n$$", "text_format": "latex", "page_idx": 40}, {"type": "text", "text": "Where $C_{E,1}$ is the constant introduced in the Proposition. Applying Jensen's inequality and (71) with $w=u$ and $k^{\\prime}=k-1$ ", "page_idx": 40}, {"type": "equation", "text": "$$\n\\sum_{i\\in[d_{u}]}(\\mathbb{E}f_{m,u_{i}}^{2}(X))^{1/2}\\leq d_{u}^{1/2}\\Big(\\sum_{i\\in[d_{u}]}\\mathbb{E}f_{m,u_{i}}^{2}(X)\\Big)^{1/2}\\leq(R d)^{1/2}C_{D.1}R^{2}\\big(\\mathbb{E}f_{m,u}^{2}(X)\\big)^{1/2}.\n$$", "text_format": "latex", "page_idx": 40}, {"type": "text", "text": "Hence, ", "page_idx": 40}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{E}|\\tilde{f}_{u}(X)f_{m,u}(X)|\\leq(R d)^{1/2}C_{D,1}R^{2}\\exp\\Big(-\\frac{\\varepsilon}{2}\\big(k-C_{E,1}(\\log(R)+1)-\\mathbf{h}^{*}\\big)\\Big)(\\mathbb{E}\\tilde{f}_{u}^{2}(X))^{1/2}\\big(\\mathbb{E}f_{m}^{2}(X)-\\tilde{f}_{u}(X)\\big)}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\leq\\exp\\Big(-\\frac{\\varepsilon}{2}\\big(k-C_{2}(\\log(R)+1)-\\mathbf{h}^{*}\\big)\\Big)(\\mathbb{E}\\tilde{f}_{u}^{2}(X))^{1/2}(\\mathbb{E}f_{m,u}^{2}(X))^{1/2},\\ (76)}\\end{array}\n$$", "text_format": "latex", "page_idx": 40}, {"type": "text", "text": "where ", "page_idx": 40}, {"type": "equation", "text": "$$\nC_{2}=\\frac{2}{\\varepsilon}\\Big(\\frac{3}{2}+\\frac{1}{2}\\log(d)+\\log(C_{D.1})\\Big)+C_{E.1}.\n$$", "text_format": "latex", "page_idx": 40}, {"type": "text", "text": "Now, returning to the summation, we apply (76) and Cauchy-Schwarz inequality to get ", "page_idx": 40}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\quad\\Bigm\\lvert\\sum_{u\\in D_{k}(\\rho^{\\prime})}\\mathbb{E}\\tilde{f}_{u}(X)f_{m,u}(X)\\Bigm\\rvert}\\\\ &{\\le\\sum_{u\\in D_{k}(\\rho^{\\prime})}\\exp\\Big(-\\frac{\\varepsilon}{2}(k-C_{2}(\\log(R)+1)-\\ h^{*})\\Big)(\\mathbb{E}\\tilde{f}_{u}^{2}(X))^{1/2}(\\mathbb{E}f_{m,u}^{2}(X))^{1/2}}\\\\ &{\\le\\exp\\Big(-\\frac{\\varepsilon}{2}(k-C_{2}(\\log(R)+1)-\\ h^{*})\\Big)\\Bigm(\\underset{u\\in D_{k}(\\rho^{\\prime})}{\\sum_{u\\in D_{k}(\\rho^{\\prime})}}\\mathbb{E}\\tilde{f}_{u}^{2}(X)\\Bigm)^{1/2}\\Bigm(\\underset{u\\in D_{k}(\\rho^{\\prime})}{\\sum_{u\\in D_{k}(\\rho^{\\prime})}}\\mathbb{E}f_{m,u}^{2}(X)\\Big)^{1/2}}\\\\ &{\\le2C_{D_{1}R}2\\exp\\Big(-\\frac{\\varepsilon}{2}(k-C_{2}(\\log(R)+1)-\\ h^{*})\\Big)\\Bigm(\\mathbb{E}f_{k}^{2}(X)\\Bigm)^{1/2}(\\mathbb{E}f_{m}^{2}(X))^{1/2}}\\\\ &{\\le\\exp\\Big(-\\frac{\\varepsilon}{2}(k-C_{3}(\\log(R)+1)-\\ h^{*})\\Big)\\sqrt{\\mathbb{E}f_{k}^{2}(X)\\mathbb{E}f_{m}^{2}(X)}.\\qquad\\qquad\\qquad\\qquad\\qquad()}\\end{array}\n$$", "text_format": "latex", "page_idx": 40}, {"type": "text", "text": "In the derivation above, we applied Lemma F.2 for the term $\\begin{array}{r}{\\biggr(\\sum_{u\\in D_{k}(\\rho^{\\prime})}\\mathbb{E}\\tilde{f}_{u}^{2}(X)\\biggr)^{1/2}}\\end{array}$ and (71) for the term $\\begin{array}{r}{\\Big(\\sum_{u\\in D_{k}(\\rho^{\\prime})}\\mathbb{E}f_{m,u}^{2}(X)\\Big)^{1/2}}\\end{array}$ in the secont to last inequality. The constant $C_{2}$ in the last inequality is defined as ", "page_idx": 40}, {"type": "equation", "text": "$$\nC_{3}=\\frac{2}{\\varepsilon}(\\log(2C_{D.1})+2)+C_{2}.\n$$", "text_format": "latex", "page_idx": 40}, {"type": "text", "text": "Part 3.3: Estimating third summand of (72) It remains to bound the third summand, it can be reduced to the upper bound for first summand. Applying the Cauchy-Schwarz inequality and Holder's inequalitywehave ", "page_idx": 40}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\Big|\\displaystyle\\sum_{u\\in D_{k}(\\rho^{\\prime})}\\mathbb{E}\\Big[(\\mathbb{E}_{u}\\tilde{f}_{u})(X)(\\mathbb{E}_{u}f_{m,u})(X)\\Big]\\Big|}\\\\ &{\\le\\mathbb{E}\\Big[\\displaystyle\\sum_{u\\in D_{k}(\\rho^{\\prime})}\\big(\\mathbb{E}_{u}\\tilde{f}_{u})(X)(\\mathbb{E}_{u}f_{m,u})(X)\\Big]\\Big|}\\\\ &{\\le\\mathbb{E}\\Big[\\Big(\\displaystyle\\sum_{u\\in D_{k}(\\rho^{\\prime})}\\big(\\mathbb{E}_{u}\\tilde{f}_{u}\\big)^{2}(X)\\Big)^{1/2}\\Big(\\displaystyle\\sum_{u\\in D_{k}(\\rho^{\\prime})}\\big(\\mathbb{E}_{u}f_{m,u})^{2}(X)\\big)^{1/2}\\Big]}\\\\ &{\\le\\Big(\\mathbb{E}\\displaystyle\\sum_{u\\in D_{k}(\\rho^{\\prime})}\\big(\\mathbb{E}_{u}\\tilde{f}_{u})^{2}(X)\\Big)^{1/2}\\Big(\\mathbb{E}\\displaystyle\\sum_{u\\in D_{k}(\\rho^{\\prime})}\\big(\\mathbb{E}_{u}f_{m,u})^{2}(X)\\Big)^{1/2}}\\\\ &{\\le\\sqrt{2}\\exp\\big(-\\varepsilon\\big(k-C_{E,1}(1+\\log(R))-\\mathbf{h}^{*}\\big)\\big)\\cdot C_{D,1}R^{2}\\sqrt{\\mathbb{E}f_{k}^{2}(X)\\mathbb{E}f_{m}^{2}(X)}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 40}, {"type": "text", "text": "where in the last inequality we applied (74) and (71). ", "page_idx": 41}, {"type": "text", "text": "By setting ", "page_idx": 41}, {"type": "equation", "text": "$$\nC_{4}=\\frac{1}{\\varepsilon}\\Big(\\frac{1}{2}\\log(2)+\\log(C_{D.1})+2\\Big),\n$$", "text_format": "latex", "page_idx": 41}, {"type": "text", "text": "we conclude that ", "page_idx": 41}, {"type": "equation", "text": "$$\n\\Big|\\sum_{u\\in D_{k}(\\rho^{\\prime})}\\mathbb{E}\\Big[(\\mathbb{E}_{u}\\tilde{f}_{u})(X)(\\mathbb{E}_{u}f_{m,u})(X)\\Big]\\Big|\\leq\\exp\\big(-\\varepsilon\\big(k-C_{4}(1+\\log(R))-\\mathrm{h}^{*}\\big)\\big)\\sqrt{\\mathbb{E}f_{k}^{2}(X)\\mathbb{E}f_{m}^{2}}\n$$", "text_format": "latex", "page_idx": 41}, {"type": "text", "text": "Now, combining the three estimates of the summands (75), (77), and (78) for (72) we conclude that ", "page_idx": 41}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{|\\mathbb{E}f_{k}(X)f_{m}(X)|\\leq\\exp\\Big(-\\frac{\\varepsilon}{2}\\big(k-C_{5}(\\log(R)+1)-\\mathrm{h}^{*})\\Big)\\sqrt{\\mathbb{E}f_{k}^{2}(X)\\mathbb{E}f_{m}^{2}(X)},}\\\\ &{\\qquad\\qquad\\qquad\\qquad C_{5}:=\\frac{2}{\\varepsilon}\\log(3)+\\operatorname*{max}\\{C_{1},C_{3},C_{4}\\}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 41}, {"type": "text", "text": "where ", "page_idx": 41}, {"type": "text", "text": "Now we impose the forth assumption on $C_{0}$ that ", "page_idx": 41}, {"type": "equation", "text": "$$\nC_{0}\\geq C_{5},\n$$", "text_format": "latex", "page_idx": 41}, {"type": "text", "text": "and (64) follows. ", "page_idx": 41}, {"type": "text", "text": "F.2Proof of Theorem B.6 ", "text_level": 1, "page_idx": 41}, {"type": "text", "text": "Let $C_{0}=C_{0}(M,d,c^{*})$ denote the constant introduced in the statement of the Lemma. Its precise value will be determined along the proof. ", "page_idx": 41}, {"type": "text", "text": "Let $k_{1}$ be a positive integer with the precise value to be determined later. Here we impose our first assumption on $k_{1}$ that ", "page_idx": 41}, {"type": "equation", "text": "$$\nk_{1}\\geq C_{F.1}(\\log(R)+1)+\\mathrm{h}^{*}\n$$", "text_format": "latex", "page_idx": 41}, {"type": "text", "text": "where $C_{F,1}$ is a constant that appears in Proposition F.1. ", "page_idx": 41}, {"type": "text", "text": "Now, let us consider a function $f$ described in the Theorem. Without lose of generality, we may assume $\\mathbb{E}f(X)=0$ . Then, it is equivalent to estimate the second moments. ", "page_idx": 41}, {"type": "text", "text": "Further, let us assume $\\operatorname{h}(\\rho^{\\prime})\\geq k_{1}$ and the decomposition of $f$ according to Lemma D.1: ", "page_idx": 41}, {"type": "equation", "text": "$$\nf(x)=\\sum_{k\\in[k_{1},\\mathrm{h}(\\rho^{\\prime})]}f_{k}(X).\n$$", "text_format": "latex", "page_idx": 41}, {"type": "text", "text": "Our first goal is to show ", "page_idx": 41}, {"type": "equation", "text": "$$\n\\mathbb{E}f(X)^{2}\\simeq\\sum_{k\\in[k_{1},\\mathrm{h}(\\rho^{\\prime})]}f_{k}^{2}(X),\n$$", "text_format": "latex", "page_idx": 41}, {"type": "text", "text": "by showing $\\mathbb{E}f_{k}(X)f_{m}(X)$ is insignificant whenever $k\\neq m$ ", "page_idx": 41}, {"type": "text", "text": "For $k_{1}\\leq m<k$ , by Propostion F.1, ", "page_idx": 41}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{2\\vert\\mathbb{E}f_{k}(X)f_{m}(X)\\vert\\leq2\\exp\\Big(-\\frac{\\varepsilon}{2}\\big(k-C_{F.1}(\\log(R)+1)-\\mathrm{h}^{*}\\big)\\Big)(\\mathbb{E}f_{k}^{2}(X))^{1/2}(\\mathbb{E}f_{m}^{2}(X))^{1/2}}\\\\ &{\\qquad\\qquad\\qquad\\leq\\exp\\Big(-\\frac{\\varepsilon}{2}\\big(k-C_{F.1}(\\log(R)+1)-\\mathrm{h}^{*}\\big)\\Big)\\mathbb{E}f_{k}^{2}(X)}\\\\ &{\\qquad\\qquad\\qquad+\\exp\\Big(-\\frac{\\varepsilon}{2}\\big(k-C_{F.1}(\\log(R)+1)-\\mathrm{h}^{*}\\big)\\Big)\\mathbb{E}f_{m}^{2}(X).}\\end{array}\n$$", "text_format": "latex", "page_idx": 41}, {"type": "text", "text": "Applying the above inequality to bound the second moment of $f(X)$ weget ", "page_idx": 41}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{E}f^{2}(X)=\\mathbb{E}\\displaystyle\\sum_{k,m\\in[k_{1},\\ln(\\rho^{\\prime})]}\\mathbb{E}f_{k}(X)f_{m}(X)}\\\\ &{\\qquad\\quad\\geq\\displaystyle\\sum_{k\\in[k_{1},\\ln(\\rho^{\\prime})]}\\mathbb{E}f_{k}^{2}(X)\\cdot\\Big(1-\\displaystyle\\sum_{s\\in[k_{1},\\ln(\\rho^{\\prime})]}\\exp\\Big(-\\frac{\\varepsilon}{2}\\big(s-C_{F\\cdot1}(\\log(R)+1)-\\ln^{*}\\big)\\Big)\\Big).}\\end{array}\n$$", "text_format": "latex", "page_idx": 41}, {"type": "text", "text": "Notice that there exists $t_{0}$ which depends on $\\varepsilon$ so that ", "page_idx": 42}, {"type": "equation", "text": "$$\n\\sum_{t=t_{0}}^{\\infty}\\exp\\Big(-\\frac{\\varepsilon}{2}t\\Big)\\leq\\frac{1}{2}.\n$$", "text_format": "latex", "page_idx": 42}, {"type": "text", "text": "By setting ", "page_idx": 42}, {"type": "equation", "text": "$$\nk_{1}:=\\lceil\\mathrm{h}^{*}+C_{F.1}(\\log(R)+1)+t_{0}\\rceil,\n$$", "text_format": "latex", "page_idx": 42}, {"type": "text", "text": "we get ", "page_idx": 42}, {"type": "equation", "text": "$$\n\\mathbb{E}f^{2}(X)\\geq\\frac{1}{2}\\sum_{k\\in[k_{1},\\mathbf{h}(\\rho^{\\prime})]}\\mathbb{E}f_{k}^{2}(X).\n$$", "text_format": "latex", "page_idx": 42}, {"type": "text", "text": "Our second goal is comparing $\\mathbb{E}\\big[(\\mathbb{E}_{\\rho^{\\prime}}f_{k})^{2}(X_{\\rho^{\\prime}})\\big]$ and $\\textstyle\\sum_{k\\in[k_{1},\\infty]}\\mathbb{E}f_{k}^{2}(X)$ . Starting with the variance and $\\ell_{\\infty}$ norm comparison from Lemma A.5, ", "page_idx": 42}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{E}\\big[(\\mathbb{E}_{\\rho^{\\prime}}f)^{2}(X_{\\rho^{\\prime}})\\big]\\leq\\!\\mathbb{E}\\Big[\\Big(\\sum_{k\\in[k_{1},\\mathbf{h}(\\rho^{\\prime})]}\\underset{\\theta_{k}\\in[q]}{\\mathrm{max}}\\,\\,\\big|(\\mathbb{E}_{\\rho^{\\prime}}f_{k})(\\theta_{k})\\big|\\Big)^{2}\\Big]}\\\\ &{\\qquad\\qquad\\qquad\\qquad=\\!\\Big(\\underset{k\\in[k_{1},\\mathbf{h}(\\rho^{\\prime})]}{\\sum}\\underset{\\theta_{k}\\in[q]}{\\mathrm{max}}\\,\\,\\big|(\\mathbb{E}_{\\rho^{\\prime}}f_{k})(\\theta_{k})\\big|\\Big)^{2}}\\\\ &{\\qquad\\qquad\\qquad\\leq C_{A.5}\\Big(\\underset{k\\in[k_{1},\\mathbf{h}(\\rho^{\\prime})]}{\\sum}\\,\\sqrt{\\mathbb{E}(\\mathbb{E}_{\\rho^{\\prime}}f_{k})^{2}(X_{\\rho})}\\Big)^{2},}\\end{array}\n$$", "text_format": "latex", "page_idx": 42}, {"type": "text", "text": "where $C_{A.5}$ is the constant introduced in the Lemma. ", "page_idx": 42}, {"type": "text", "text": "By (62), from Proposition F.1, for $k\\in[k_{1}+1,\\mathrm{h}(\\rho^{\\prime})]$ ", "page_idx": 42}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathbb{E}\\big[(\\mathbb{E}_{\\rho^{\\prime}}f_{k})^{2}(X_{\\rho^{\\prime}})\\big]\\leq\\exp\\big(-\\varepsilon(k-\\mathrm{h}^{\\ast})\\big)\\cdot\\exp\\Big(-\\varepsilon(\\mathrm{h}(\\rho^{\\prime})-C_{F^{\\bot}}(\\log(R)+1)-\\mathrm{h}^{\\ast})\\Big)\\mathbb{E}f_{k}^{2}(X)}\\end{array}\n$$", "text_format": "latex", "page_idx": 42}, {"type": "text", "text": "And for $k=k_{1}=\\lceil\\mathrm{h}^{*}+C_{F.1}(\\log(R)+1)+t_{0}\\rceil$ , we apply (63) to get ", "page_idx": 42}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{E}\\big[(\\mathbb{E}_{\\rho^{\\prime}}f_{k_{1}})^{2}(X_{\\rho^{\\prime}})\\big]\\leq\\exp\\big(-\\varepsilon(\\mathrm{h}(\\rho^{\\prime})-k_{1}-C_{F.1}(\\log(R)+1))\\big)\\mathbb{E}f_{k_{1}}^{2}(X)}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\leq\\exp\\big(-\\varepsilon(-t_{0}-1)\\big)}\\\\ &{\\qquad\\qquad\\qquad\\cdot\\exp\\Big(-\\varepsilon(\\mathrm{h}(\\rho^{\\prime})-2C_{F.1}(\\log(R)+1)-\\mathrm{h}^{*})\\Big)\\mathbb{E}f_{k_{1}}^{2}(X).}\\end{array}\n$$", "text_format": "latex", "page_idx": 42}, {"type": "text", "text": "Substituting these estimate and by Cauchy-Schwarz inequality we have ", "page_idx": 42}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{E}\\big[(\\mathbb{E}_{\\rho^{\\prime}}f)^{2}(X_{\\rho^{\\prime}})\\big]\\leq C_{A.5}\\exp\\Big(-\\varepsilon(\\mathrm{h}(\\rho^{\\prime})-2C_{F.1}(\\log(R)+1)-\\mathrm{h}^{*})\\Big)}\\\\ &{\\qquad\\qquad\\qquad\\cdot\\underbrace{\\Big(\\exp(\\varepsilon(t_{0}+1))+\\displaystyle\\sum_{t=0}^{\\infty}\\exp(-\\varepsilon t)\\Big)}_{:=C_{1}}\\cdot\\sum_{k\\in[k_{1},\\mathrm{h}(\\rho^{\\prime})]}\\mathbb{E}f_{k}^{2}(X)}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\qquad\\cdot\\subset_{A}}\\\\ &{\\qquad\\qquad\\qquad\\leq C_{A.5}C_{1}2\\exp\\Big(-\\varepsilon(\\mathrm{h}(\\rho^{\\prime})-2C_{F.1}(\\log(R)+1)-\\mathrm{h}^{*})\\Big)\\mathbb{E}f^{2}(X).}\\end{array}\n$$", "text_format": "latex", "page_idx": 42}, {"type": "text", "text": "Now, by taking ", "page_idx": 42}, {"type": "equation", "text": "$$\nC_{0}\\ge\\operatorname*{max}\\Big\\{2C_{F.1}+\\frac{1}{\\varepsilon}\\log(C_{A.5}C_{1}2)\\,,\\,C_{F.1}+t_{0}+1\\Big\\},\n$$", "text_format": "latex", "page_idx": 42}, {"type": "text", "text": "we conclude that ", "page_idx": 42}, {"type": "equation", "text": "$$\n\\ensuremath{\\mathbb{E}}\\big[(\\ensuremath{{\\mathbb{E}}}_{\\rho^{\\prime}}f)^{2}(X_{\\rho^{\\prime}})\\big]\\le\\exp\\Big(-\\varepsilon\\big(\\ensuremath{{\\mathrm{h}}}(\\rho^{\\prime})-C_{0}(\\ensuremath{{\\mathrm{log}}}(R)+1)-\\ensuremath{{\\mathrm{h}}}^{*}\\big)\\Big)\\ensuremath{{\\mathbb{E}}}f^{2}(X).\n$$", "text_format": "latex", "page_idx": 42}, {"type": "text", "text": "It remains to show the case when $\\mathrm{h}(\\rho^{\\prime})\\leq k_{1}$ . From the assumption that $C_{0}\\geq C_{F.1}+t_{0}+1$ and $k_{1}\\leq\\mathrm{h}^{*}+C_{F.1}(\\log(R)+1)+t_{0}+1$ ,we have ", "page_idx": 42}, {"type": "equation", "text": "$$\n\\exp\\Big(-\\varepsilon(\\mathrm{h}(\\rho^{\\prime})-C_{0}(\\log(R)+1)-\\mathrm{h}^{*}\\Big)\\geq1.\n$$", "text_format": "latex", "page_idx": 42}, {"type": "text", "text": "Hence, the statement follows directly from Jensen's inequality. ", "page_idx": 42}, {"type": "text", "text": "G General Case: Base Case ", "text_level": 1, "page_idx": 43}, {"type": "text", "text": "Now, we want to establish Theorem 1.6, which does not rely on the assumption $c_{M}>0$ .Let us first establish analogues of Assumption B.3 (the inductive assumption), Proposition B.5 (the base case), and Theorem B.1 (the inductive step) in the general case. ", "page_idx": 43}, {"type": "text", "text": "Assumption G.1. By stating that $\\boldsymbol{\\mathcal{A}}$ satisfies this assumption with given parameter $\\mathrm{h}^{\\circ}$ ,wemean ${\\mathcal{A}}_{1}\\subseteq{\\bar{\\mathcal{A}}}\\subseteq{\\mathbf{2}}^{L}\\backslash\\{\\varnothing\\}$ is closed under decomposition, and the following holds: ", "page_idx": 43}, {"type": "text", "text": "For every $u\\in T$ and any $\\mathcal{A}_{\\leq u}$ -polynomials functions $f$ and $g$ , we have ", "page_idx": 43}, {"type": "equation", "text": "$$\n\\mathrm{Var}\\big[(\\mathbb{E}_{u}f)(X)\\big]\\leq\\exp(-\\varepsilon(\\mathrm{h}(u)-\\mathrm{h}^{\\circ}))\\mathrm{Var}\\big[f(X)\\big].\n$$", "text_format": "latex", "page_idx": 43}, {"type": "text", "text": "Further, suppose $\\mathbb{E}f=\\mathbb{E}g=0$ and $\\operatorname{h}(u)\\geq\\operatorname{h}^{\\circ}$ . Notice that by the Markov Property, $(\\mathbb{E}_{u}f g)(x)$ \uff0c $(\\mathbb{E}_{u}f^{2})(x)$ , and $(\\mathbb{E}_{u}g^{2})(x)$ are functions of $x_{u}$ . Then, ", "page_idx": 43}, {"type": "equation", "text": "$$\n\\operatorname*{max}_{\\theta\\in[q]}|(\\mathbb{E}_{u}f g)(\\theta)-\\mathbb{E}f g|\\leq\\exp\\Big(-\\frac{\\varepsilon}{2}(\\mathrm{h}(u)-\\mathrm{h}^{\\circ})\\Big)\\sqrt{\\operatorname*{min}_{\\theta}(\\mathbb{E}_{u}f^{2})(\\theta)\\operatorname*{min}_{\\theta^{\\prime}}(\\mathbb{E}_{u}g^{2})(\\theta)}.\n$$", "text_format": "latex", "page_idx": 43}, {"type": "text", "text": "The main difference of this assumption and Assumption B.3 is the difference of (82) and (16). ", "page_idx": 43}, {"type": "text", "text": "Proposition G.2.Consider the rooted tree $T$ and transition matrix $M$ describedinTheorem1.6. There exists $C\\,=\\,C(M,d)\\,\\geq\\,1$ such that $\\mathcal{A}_{1}$ satisfies Assumption $G.l$ with some parameter $\\mathrm{h}^{\\circ}$ satisfying ", "page_idx": 43}, {"type": "equation", "text": "$$\n\\mathrm{h}^{\\circ}\\leq C(\\log(R)+1).\n$$", "text_format": "latex", "page_idx": 43}, {"type": "text", "text": "Theorem G.3. Consider the rooted tree $T$ and transition matrix $M$ described in Theorem 1.6. There exists $C=C(M,d)>1$ so that the following holds. Suppose $\\boldsymbol{\\mathcal{A}}$ satisfies Assumption G.1 with some parameter $\\mathrm{h}^{\\circ}$ . Let $B=B({\\mathcal{A}})$ (see Definition $I.I l,$ .Then, $\\boldsymbol{\\mathrm{\\Delta}}\\boldsymbol{\\mathrm{\\Omega}}^{\\beta}$ satisfies Assumption $G.l$ with parameter ", "page_idx": 43}, {"type": "equation", "text": "$$\n\\mathrm{h}^{\\circ}+C(\\log(R)+1).\n$$", "text_format": "latex", "page_idx": 43}, {"type": "text", "text": "Proof of Theorem 1.6. The proof of Theorem 1.6 is analogous to that of Theorem B.1, employing a similar strategy by leveraging Proposition G.2 and Theorem G.3 in the former, and Proposition B.5 and Theorem B.6 in the latter. ", "page_idx": 43}, {"type": "text", "text": "In this section we will prove the Base Case Proposition G.2. ", "page_idx": 43}, {"type": "text", "text": "Lemma G.4. There exists a constant $C=C(M,\\varepsilon)\\geq1$ so such that for any $\\rho^{\\prime}\\in T$ and $0\\leq m\\leq$ $\\mathrm{h}(\\rho^{\\prime})$ ", "page_idx": 43}, {"type": "text", "text": "Consider two degree 1 polynomials $f$ and $g$ with variables $(x_{u}\\,:\\,u\\in D_{m}(\\rho^{\\prime}))$ .Suppose ", "page_idx": 43}, {"type": "equation", "text": "$$\nf(X)=\\sum_{u\\in D_{m}(\\rho^{\\prime})}f_{u}(X)\\;a l m o s t\\;s u r e l y,\n$$", "text_format": "latex", "page_idx": 43}, {"type": "text", "text": "where $f_{u}(x)=f_{u}(x_{u})$ and $\\mathbb{E}[f_{u}(X)]=0,$ . and we assume the same conditions for the polynomial $g$ and $g_{u}$ .Then, ", "page_idx": 43}, {"type": "equation", "text": "$$\n\\operatorname*{max}_{\\theta\\in[q]}\\big|(\\mathbb{E}_{\\rho^{\\prime}}f g)(\\theta)-\\mathbb{E}f g\\big|\\leq C R\\exp(-\\varepsilon(\\mathrm{h}(\\rho^{\\prime})-m))\\sqrt{\\sum_{u\\in D_{m}(\\rho^{\\prime})}\\mathbb{E}f_{u}^{2}(X)}\\sqrt{\\sum_{u\\in D_{m}(\\rho^{\\prime})}\\mathbb{E}g_{u}^{2}(X)}.\n$$", "text_format": "latex", "page_idx": 43}, {"type": "text", "text": "Proof.Let $C_{0}=C_{0}(M,d)$ denote the constant introduced in the statement of the Lemma. Its value will be determined along the proof. ", "page_idx": 43}, {"type": "text", "text": "First of all, ", "page_idx": 43}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\underset{\\theta\\in[q]}{\\operatorname*{max}}\\left|(\\mathbb{E}_{\\rho^{\\prime}}f g)(\\theta)-\\mathbb{E}f g\\right|=\\underset{\\theta\\in[q]}{\\operatorname*{max}}\\left|\\underset{u,v\\in D_{m}(\\rho^{\\prime})}{\\sum}\\left((\\mathbb{E}_{\\rho^{\\prime}}f_{u}g_{v})(\\theta)-\\mathbb{E}f_{u}g_{v}\\right|\\right)}\\\\ &{\\qquad\\qquad\\qquad\\leq\\underset{u,v\\in D_{m}(\\rho^{\\prime})}{\\sum}\\underset{\\theta\\in[q]}{\\operatorname*{max}}\\left|(\\mathbb{E}_{\\rho^{\\prime}}f_{u}g_{v})(\\theta)-\\mathbb{E}f_{u}g_{v}\\right|.}\\end{array}\n$$", "text_format": "latex", "page_idx": 43}, {"type": "text", "text": "Our proof will be carried out by estimating each summand. Fix any pair $u,v\\in D_{m}(\\rho^{\\prime})$ and consider ", "page_idx": 44}, {"type": "equation", "text": "$$\n\\Vert(\\mathbb{E}_{\\rho^{\\prime}}f_{u}g_{v})-\\mathbb{E}f_{u}g_{v}\\Vert_{\\infty}=\\operatorname*{max}_{\\theta}\\left\\vert\\mathbb{E}_{\\rho^{\\prime}}\\left[f_{u}(X)g_{v}(X)-\\mathbb{E}f_{u}g_{v}\\;\\middle\\vert\\;X_{\\rho^{\\prime}}=\\theta\\right]\\right\\vert.\n$$", "text_format": "latex", "page_idx": 44}, {"type": "text", "text": "Let $w=\\rho(u,v)$ . Since $f_{u}$ and $g_{v}$ are functions of $x_{\\le w}$ , relying on the Markov Property we know the function $(\\mathbb{E}_{w}f_{u}\\cdot g_{v})(x)$ is a function of $x_{w}$ with expected value $\\mathbb{E}f_{u}(X)g_{v}(X)$ With ", "page_idx": 44}, {"type": "equation", "text": "$$\n(\\mathbb{E}_{\\rho^{\\prime}}f_{u}g_{v})(x_{\\rho^{\\prime}})=\\mathbb{E}\\big[(\\mathbb{E}_{w}f_{u}g_{v})(X_{w})\\,\\big|\\,X_{\\rho^{\\prime}}=x_{\\rho^{\\prime}}\\big],\n$$", "text_format": "latex", "page_idx": 44}, {"type": "text", "text": "applying (10) from Lemma A.5, ", "page_idx": 44}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\|(\\mathbb{E}_{\\rho^{\\prime}}f_{u}g_{v})-\\mathbb{E}f_{u}g_{v}\\|_{\\infty}\\leq\\!C_{A,5}(\\mathrm{h}(\\rho^{\\prime})-\\mathrm{h}(w))^{q}\\lambda^{\\mathrm{h}(\\rho^{\\prime})-\\mathrm{h}(w)}\\|(\\mathbb{E}_{w}f_{u}g_{v})(\\theta)-\\mathbb{E}f_{u}g_{v}\\|_{\\infty},}\\end{array}\n$$", "text_format": "latex", "page_idx": 44}, {"type": "text", "text": "where $C_{A.5}$ is the $M$ -dependent constant introduced in the Lemma. ", "page_idx": 44}, {"type": "text", "text": "Next, we will estimate $\\left\\|(\\mathbb{E}_{w}f_{u}g_{v})(\\theta)-\\mathbb{E}f_{u}g_{v}\\right\\|_{\\infty}$ . In the case $u\\ne v$ , there exists $i\\neq j$ such that $u\\leq w_{i}$ and $v\\leq w_{j}$ ; which in turn implies that $(\\overrightharpoon{X}_{\\leq u}\\,|\\,X_{w}=x_{w})$ and $(X_{\\leq v}\\mid X_{w}=x_{w})$ are jointly independent by the Markov Property. Thus, ", "page_idx": 44}, {"type": "equation", "text": "$$\n\\begin{array}{r}{(\\mathbb{E}_{w}f_{u}g_{v})(\\theta)=(\\mathbb{E}_{w}f_{u})(\\theta)(\\mathbb{E}_{w}g_{v})(\\theta),}\\end{array}\n$$", "text_format": "latex", "page_idx": 44}, {"type": "text", "text": "which implies ", "page_idx": 44}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\underset{\\theta\\in[q]}{\\operatorname*{max}}|(\\mathbb{E}_{w}f_{u}g_{v})(\\theta)|\\leq\\underset{\\theta\\in[q]}{\\operatorname*{max}}|(\\mathbb{E}_{w}f_{u})(\\theta)|\\cdot\\underset{\\theta\\in[q]}{\\operatorname*{max}}|(\\mathbb{E}_{w}g_{v})(\\theta)|}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\leq C_{A.5}^{3}(\\mathrm{h}(w)-m)^{2q}\\lambda^{2(\\mathrm{h}(w)-m)}\\sqrt{\\mathbb{E}f_{u}^{2}(X)\\mathbb{E}g_{v}^{2}(X)},}\\end{array}\n$$", "text_format": "latex", "page_idx": 44}, {"type": "text", "text": "where we applied (10) and (9) from Lemma A.5 in the last inequality. If $u\\,=\\,v$ , then the same estimate follows immediately without relying on (10). ", "page_idx": 44}, {"type": "text", "text": "Now, we convert the above estimate to that of $\\|(\\mathbb{E}_{w}f_{u}g_{v})(\\theta)-\\mathbb{E}f_{u}g_{v}\\|_{\\infty}$ , which relies on the simple bound that $\\begin{array}{r}{|\\mathbb{E}f_{u}(X)g_{v}(X)|\\leq\\operatorname*{max}_{\\theta\\in[q]}|(\\mathbb{E}_{w}f_{u}g_{v})(\\theta)|}\\end{array}$ Thus, ", "page_idx": 44}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\left\\|(\\mathbb{E}_{w}f_{u}g_{v})(\\theta)-\\mathbb{E}f_{u}g_{v}\\right\\|_{\\infty}\\leq2\\underset{\\theta\\in[q]}{\\operatorname*{max}}|(\\mathbb{E}_{w}f_{u}g_{v})(\\theta)|}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\leq2C_{A.5}^{3}(\\mathrm{h}(w)-m)^{2q}\\lambda^{2(\\mathrm{h}(w)-m)}\\sqrt{\\mathbb{E}f_{u}^{2}(X)\\mathbb{E}g_{v}^{2}(X)}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 44}, {"type": "text", "text": "Together we conclude that for a pair $u,v\\in D_{m}(\\rho^{\\prime})$ with $w=\\rho(u,v)$ \uff0c ", "page_idx": 44}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\|(\\mathbb{E}_{\\rho^{\\prime}}f_{u}g_{v})-\\mathbb{E}f_{u}g_{v}\\|_{\\infty}\\leq2C_{A,5}^{4}(\\mathrm{h}(w)-m)^{2q}(\\mathrm{h}(\\rho^{\\prime})-\\mathrm{h}(w))^{q}\\lambda^{\\mathrm{h}(\\rho^{\\prime})+\\mathrm{h}(w)-2m}\\sqrt{\\mathbb{E}f_{u}^{2}(X)g_{v}^{2}(X)}}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\leq2C_{A,5}^{4}(\\mathrm{h}(\\rho^{\\prime})-m)^{3q}\\lambda^{\\mathrm{h}(\\rho^{\\prime})+\\mathrm{h}(w)-2m}\\sqrt{\\mathbb{E}f_{u}^{2}(X)g_{v}^{2}(X)}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 44}, {"type": "text", "text": "Relying on this estimate, we are ready to bound the $l_{\\infty}$ -norm of $(\\mathbb{E}_{\\rho^{\\prime}}f g)(x_{\\rho^{\\prime}})-\\mathbb{E}f g$ ", "page_idx": 44}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\underset{\\theta\\in[\\pi]}{\\operatorname*{max}}\\big\\vert(\\mathbb{E}_{\\rho^{\\prime}}f g)(\\theta)-\\mathbb{E}f g\\big\\vert}\\\\ &{\\le\\underset{u,v\\in\\mathcal{D}_{m}(\\rho^{\\prime})}{\\sum}\\underset{\\theta\\in[\\pi]}{\\operatorname*{max}}\\big\\vert(\\mathbb{E}_{\\rho^{\\prime}}f_{u}g_{v})(\\theta)-\\mathbb{E}f_{u}g_{v}\\big\\vert}\\\\ &{=\\underset{k\\in[m,\\Lambda(\\rho^{\\prime})]}{\\sum}\\underset{w\\in D_{k}(\\rho^{\\prime})}{\\sum}\\underset{u,v\\colon\\rho(u,v)=w}{\\sum}\\underset{\\theta\\in[q]}{\\operatorname*{max}}\\big\\vert(\\mathbb{E}_{\\rho}f_{u}g_{v})(\\theta)-\\mathbb{E}f_{u}g_{v}\\big\\vert}\\\\ &{\\le\\underset{k\\in[m,\\Lambda(\\rho^{\\prime})]}{\\sum}\\underset{w\\in D_{k}(\\rho^{\\prime})}{\\sum}\\underset{u,v\\colon\\rho(u,v)=w}{\\sum}2C_{A,5}^{4}(\\mathrm{h}(\\rho^{\\prime})-m)^{3q}\\lambda^{\\mathrm{h}(\\rho^{\\prime})+k-2m}\\sqrt{\\mathbb{E}f_{u}^{2}(X)g_{v}^{2}(X)}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 44}, {"type": "text", "text": "Next, relaxing the condition $\\rho(u,v)=w$ in the summation, ", "page_idx": 44}, {"type": "equation", "text": "$$\n\\begin{array}{c}{{\\^\\ast)\\leq\\displaystyle\\sum_{k\\in[m,\\mathrm{h}(\\rho^{\\prime})]}\\displaystyle\\sum_{w\\in D_{k}(\\rho^{\\prime})}\\displaystyle\\sum_{u,v\\in D_{m}(w)}2C_{A,5}^{4}(\\mathrm{h}(\\rho^{\\prime})-m)^{3q}\\lambda^{\\mathrm{h}(\\rho^{\\prime})+k-2m}\\sqrt{\\mathbb{E}f_{u}^{2}(X)g_{v}^{2}(X)}}}\\\\ {{=\\displaystyle\\sum_{k\\in[m,\\mathrm{h}(\\rho^{\\prime})]}\\displaystyle\\sum_{w\\in D_{k}(\\rho^{\\prime})}2C_{A,5}^{4}(\\mathrm{h}(\\rho^{\\prime})-m)^{3q}\\lambda^{\\mathrm{h}(\\rho^{\\prime})+k-2m}\\big(\\displaystyle\\sum_{u\\in D_{m}(w)}\\sqrt{\\mathbb{E}f_{u}^{2}(X)}\\big)\\big(\\sum_{u\\in D_{m}(w)}\\sqrt{\\mathbb{E}g_{u}^{2}(X)}\\big)}}\\end{array}\n$$", "text_format": "latex", "page_idx": 44}, {"type": "text", "text": "$\\begin{array}{r}{\\sum_{i\\in[n]}\\frac{|t_{i}|}{n}\\,\\leq\\,\\sqrt{\\sum_{i\\in[n]}\\frac{|t_{i}|^{2}}{n}}}\\end{array}$ [a follows from Jenson's inequality applying to the function $t\\mapsto t^{2}$ and the uniform measure on $[n]$ . Now apply this inequality to the collection $\\{\\sqrt{\\mathbb{E}f_{u}^{2}(X)}\\}$ and $\\{\\sqrt{\\mathbb{E}g_{u}^{2}(X)}\\}$ respectively, together with $|D_{m}(w)|\\leq R d^{\\mathrm{h}(w)-m}$ , from our tree asscumption, we have ", "page_idx": 45}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\lefteqn{\\binom{*}{6}\\leq\\sum_{k\\in[m,1(\\rho^{\\prime})]}\\sum_{\\stackrel{\\scriptstyle\\sum\\sigma^{\\prime}\\colon\\{\\kappa\\}\\leq m}}\\sum_{\\stackrel{\\scriptstyle\\sum\\sigma^{\\prime}\\colon\\{\\kappa\\}}{4}}2C_{A,\\xi}^{4}\\mathrm{{R}}(\\rho^{\\prime})-m)^{3q}\\lambda^{\\mathrm{h}(\\rho^{\\prime})+k-2m}R d^{k-m}}}\\\\ &{\\quad\\cdot\\sqrt{\\sum_{\\stackrel{\\scriptstyle\\sum\\sigma\\leq m}{4},\\atop\\scriptstyle k\\in[m,n(\\rho^{\\prime})]}\\mathbb{E}f_{a,\\xi}^{2}(x)}\\sqrt{\\sum_{\\stackrel{\\scriptstyle\\sum\\sigma_{n}=\\{\\infty}}{u}}\\mathbb{E}g_{n}^{2}(X)}}\\\\ &{\\leq\\sum_{k\\in[m,\\hbar(\\rho^{\\prime})]}2C_{A,\\xi}^{4}\\mathrm{{S}}(\\mathrm{h}(\\rho^{\\prime})-m)^{3q}\\lambda^{\\mathrm{h}(\\rho^{\\prime})+k-2m}R d^{k-m}}\\\\ &{\\quad\\quad\\quad\\cdot\\sqrt{\\sum_{\\stackrel{\\scriptstyle\\sum\\sigma^{\\prime}\\colon\\{\\kappa\\}=m}}\\sum_{k\\in[2m,\\infty)}\\mathbb{E}f_{n}^{2}(X)}\\cdot\\sqrt{\\sum_{\\stackrel{\\scriptstyle\\sum\\sigma^{\\prime}\\colon\\{\\kappa\\}}{u}}\\sum_{\\stackrel{\\scriptstyle\\sum\\sigma_{n}=\\{\\infty}}{u}}\\mathbb{E}g_{n}^{2}(X)}}\\\\ &{=\\sum_{k\\in[m,\\hbar(\\rho^{\\prime})]}2C_{A,\\xi}^{4}(\\mathrm{h}(\\rho^{\\prime})-m)^{3q}\\lambda^{\\mathrm{h}(\\rho^{\\prime})+k-2m}R d^{k-m}\\sqrt{\\sum_{\\stackrel{\\scriptstyle\\sum\\sigma_{n}=\\{\\infty}}{u}}\\mathbb{E}f_{a}^{2}(X)}\\sqrt{\\sum_{\\stackrel{\\scriptstyle\\sum\\sigma_{n}=\\{\\infty}}{u}}\\mathbb{E}g_{n}^{2}(X)}}\\end{array}\n$$", "text_format": "latex", "page_idx": 45}, {"type": "text", "text": "where the last inequality follows from Cauchy-Schwarz inequality. Finally ", "page_idx": 45}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\quad\\underset{k\\in[m,\\mathtt{h}(\\rho^{\\prime})]}{\\sum}2C_{A,5}^{4}(\\mathrm{h}(\\rho^{\\prime})-m)^{3q}\\lambda^{\\mathrm{h}(\\rho^{\\prime})+k-2m}R d^{k-m}}\\\\ &{\\leq2C_{A,5}^{4}R(\\mathrm{h}(\\rho^{\\prime})-m)^{3q}\\cdot(\\mathrm{h}(\\rho^{\\prime})-m)\\lambda^{h(\\rho^{\\prime})-m}\\underset{k\\in[m,h(\\rho^{\\prime})]}{\\operatorname*{max}}\\lambda^{k-m}d^{k-m}}\\\\ &{=2C_{A,5}^{4}R(\\mathrm{h}(\\rho^{\\prime})-m)^{3q}\\cdot(\\mathrm{h}(\\rho^{\\prime})-m)\\big(\\operatorname*{max}\\{d\\lambda^{2},\\,\\lambda\\}\\big)^{\\mathrm{h}(\\rho^{\\prime})-m}}\\\\ &{=2C_{A,5}^{4}R(\\mathrm{h}(\\rho^{\\prime})-m)^{3q+1}\\exp(-1.1\\varepsilon(\\mathrm{h}(\\rho^{\\prime})-m))}\\\\ &{\\leq C_{0}R\\exp(-\\varepsilon(\\mathrm{h}(\\rho^{\\prime})-m)),}\\end{array}\n$$", "text_format": "latex", "page_idx": 45}, {"type": "text", "text": "where ", "page_idx": 45}, {"type": "equation", "text": "$$\nC_{0}=2C_{A.5}^{4}\\operatorname*{max}_{n\\in\\mathbb{N}}n^{3q+1}\\exp(-0.1\\varepsilon n)<+\\infty\n$$", "text_format": "latex", "page_idx": 45}, {"type": "text", "text": "is a constant depending on $M$ and $\\varepsilon$ . Combining the above estimate with (85) we conclude that ", "page_idx": 45}, {"type": "equation", "text": "$$\n\\operatorname*{nax}_{\\forall\\in[q]}\\big|(\\mathbb{E}_{\\rho^{\\prime}}f g)(\\theta)-\\mathbb{E}f g\\big|\\leq C_{0}R\\exp\\big(-\\varepsilon(\\mathrm{h}(\\rho^{\\prime})-m)\\big)\\sqrt{\\sum_{u\\in D_{m}(\\rho^{\\prime})}\\mathbb{E}f_{u}^{2}(X)}\\sqrt{\\sum_{u\\in D_{m}(\\rho^{\\prime})}\\mathbb{E}g_{u}^{2}(X)},\n$$", "text_format": "latex", "page_idx": 45}, {"type": "text", "text": "and the lemma follows. ", "page_idx": 45}, {"type": "text", "text": "The statement of Lemma G.4 together with Proposition C.3 implies the following: ", "page_idx": 45}, {"type": "text", "text": "Corollary G.5. There exists a constant $C=C(M,\\varepsilon)\\geq1$ so that the following holds. For $\\rho^{\\prime}\\in T$ and $0\\leq m\\leq\\mathrm{h}(\\rho^{\\prime}).$ considertwo degree1 polynomials $f$ and $g$ withvariables $(x_{u}\\,:\\,u\\in D_{m}(\\rho^{\\prime}))$ with $\\mathbb{E}f(X)=\\mathbb{E}g(X)=0$ Notice that by the Markov Property, $(\\mathbb{E}_{\\rho^{\\prime}}f g)(x)$ is a function of $x_{\\rho^{\\prime}}$ Then, ", "page_idx": 45}, {"type": "equation", "text": "$$\n\\operatorname*{max}_{\\theta\\in[q]}\\left|(\\mathbb{E}_{\\rho^{\\prime}}f g)(\\theta)-\\mathbb{E}f g\\right|\\leq C R^{4}\\exp(-\\varepsilon(\\mathrm{h}(\\rho^{\\prime})-m))\\sqrt{\\mathbb{E}f^{2}(X)}\\sqrt{\\mathbb{E}g^{2}(X)}.\n$$", "text_format": "latex", "page_idx": 45}, {"type": "text", "text": "Remark G.6. By taking the degree 1 polynomial $f=g$ with the assumption that $\\mathbb{E}f(X)=0$ we get ", "page_idx": 45}, {"type": "equation", "text": "$$\n\\natural\\big[(\\mathbb{E}_{\\rho^{\\prime}}f^{2})(X)-\\mathbb{E}f^{2}(X)\\big]^{2}\\leq\\left(\\operatorname*{max}_{\\theta\\in[q]}\\big|(\\mathbb{E}_{\\rho^{\\prime}}f g)(\\theta)-\\mathbb{E}f g\\big|\\right)^{2}\\leq C^{2}R^{6}\\exp(-2\\varepsilon\\mathrm{h}(\\rho^{\\prime}))(\\mathbb{E}f^{2}(X))^{2}.\n$$", "text_format": "latex", "page_idx": 45}, {"type": "text", "text": "In other words, if $\\mathrm{h}(\\rho^{\\prime})$ is sufficiently large, $(\\mathbb{E}_{\\rho^{\\prime}}f^{2})(X_{\\rho^{\\prime}})$ is almost the same as $\\mathbb{E}f^{2}(X)$ with a small fuctuation. Let us state this as a seperate lemma. ", "page_idx": 45}, {"type": "text", "text": "Lemma G.7. There exists $C=C(M,d)$ so that the following holds. For $\\rho^{\\prime}\\in T$ with ", "page_idx": 46}, {"type": "equation", "text": "$$\n\\mathrm{h}(\\rho^{\\prime})\\geq\\frac{C(\\log(R)+1)}{\\varepsilon},\n$$", "text_format": "latex", "page_idx": 46}, {"type": "text", "text": "any degree 1 polynomial $f$ of variables $(x_{u}:u\\in L_{\\rho^{\\prime}})$ with $\\mathbb{E}f(X)=0$ satisfies ", "page_idx": 46}, {"type": "equation", "text": "$$\n\\operatorname*{max}_{\\theta\\in[q]}(\\mathbb{E}_{\\rho^{\\prime}}f^{2})(\\theta)\\leq2\\operatorname*{min}_{\\theta\\in[q]}(\\mathbb{E}_{\\rho^{\\prime}}f^{2})(\\theta).\n$$", "text_format": "latex", "page_idx": 46}, {"type": "text", "text": "Proof. By Corollary G.5, for every $\\theta\\in[q]$ ", "page_idx": 46}, {"type": "equation", "text": "$$\n\\big|(\\mathbb{E}_{\\rho^{\\prime}}f^{2})(\\theta)-\\mathbb{E}f^{2}(X)\\big|\\leq C_{G.5}R^{4}\\exp(-\\varepsilon\\mathrm{h}(\\rho^{\\prime}))\\mathbb{E}f^{2}(X).\n$$", "text_format": "latex", "page_idx": 46}, {"type": "text", "text": "where $C_{G.5}$ is the constant introduced in Lemma G.5. Now, we set the constant described in the lemma as ", "page_idx": 46}, {"type": "equation", "text": "$$\nC=\\frac{1}{\\varepsilon}\\Big(\\log(4C_{G.5})+4\\Big),\n$$", "text_format": "latex", "page_idx": 46}, {"type": "text", "text": "which implies ", "page_idx": 46}, {"type": "equation", "text": "$$\nC_{G.4}R\\exp(-\\varepsilon\\mathrm{h}(\\rho^{\\prime}))\\leq\\frac14\\exp\\big(-\\varepsilon(\\mathrm{h}(\\rho^{\\prime})-C(\\log(R)+1))\\big).\n$$", "text_format": "latex", "page_idx": 46}, {"type": "text", "text": "Then, with $\\mathrm{h}(\\rho^{\\prime})\\geq C(\\log(R)+1)$ ", "page_idx": 46}, {"type": "equation", "text": "$$\n|(\\mathbb{E}_{\\rho^{\\prime}}f^{2})(\\theta)-\\mathbb{E}f^{2}(X)|\\leq\\frac{1}{4}\\mathbb{E}f^{2}(X),\n$$", "text_format": "latex", "page_idx": 46}, {"type": "text", "text": "which in term implies ", "page_idx": 46}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\frac{\\operatorname*{max}_{\\theta\\in[q]}(\\mathbb{E}_{\\rho^{\\prime}}f^{2})(\\theta)}{\\operatorname*{min}_{\\theta\\in[q]}(\\mathbb{E}_{\\rho^{\\prime}}f^{2})(\\theta)}\\leq\\frac{\\frac{5}{4}\\mathbb{E}f^{2}(X)}{\\frac{3}{4}\\mathbb{E}f^{2}(X)}<2.}\\end{array}\n$$", "text_format": "latex", "page_idx": 46}, {"type": "text", "text": "ProofofProposition $G.2$ Let $C_{0}$ denote the constant introduced in the statement of the Proposition.   \nIts precise value will be determined along the proof. ", "page_idx": 46}, {"type": "text", "text": "Let $\\rho^{\\prime}\\,\\in\\,T$ with ${\\mathrm{h}}^{\\prime}:={\\mathrm{\\h}}(\\rho^{\\prime})$ .By Lemma C.9, any degree-1 polynomial $f(x)$ with variables $(x_{u}:u\\in L_{\\rho^{\\prime}})$ ) satisfies ", "page_idx": 46}, {"type": "equation", "text": "$$\n\\mathrm{Var}\\big[(\\mathbb{E}_{\\rho^{\\prime}}f)(X)\\big]\\leq C_{C.9}R^{4}(\\mathrm{h}^{\\prime})^{2q}(d\\lambda^{2})^{\\mathrm{h}^{\\prime}}\\mathrm{Var}[f(X)],\n$$", "text_format": "latex", "page_idx": 46}, {"type": "text", "text": "where $C_{C.9}$ denotes the $M$ -dependent constant introduced in the Lemma. For the term in front of $\\operatorname{Var}[f(X)]$ ", "page_idx": 46}, {"type": "equation", "text": "$$\nC_{C,9}R^{4}(\\mathrm{h}^{\\prime})^{2q}(d\\lambda^{2})^{\\mathrm{h}^{\\prime}}\\leq C_{C,9}R^{4}(\\mathrm{h}^{\\prime})^{2q}\\exp(-1.1\\varepsilon\\mathrm{h}^{\\prime})\\leq\\exp\\big(-\\varepsilon\\big(\\mathrm{h}^{\\prime}-C_{1}(\\log(R)+1)\\big)\\big),\n$$", "text_format": "latex", "page_idx": 46}, {"type": "text", "text": "where ", "page_idx": 46}, {"type": "equation", "text": "$$\nC_{1}:=\\frac{1}{\\varepsilon}\\Big(\\log(C_{C.9})+4+\\operatorname*{max}_{n\\in\\mathbb{N}}n^{2q}\\exp(-0.1\\varepsilon q)\\Big).\n$$", "text_format": "latex", "page_idx": 46}, {"type": "text", "text": "Thus, if we impose the first assumption on $C_{0}$ that ", "page_idx": 46}, {"type": "equation", "text": "$$\nC_{0}\\geq C_{1},\n$$", "text_format": "latex", "page_idx": 46}, {"type": "text", "text": "then the first condition (81) in Assumption G.1 holds for $\\mathcal{A}_{1}$ if we take $\\mathrm{h}^{\\circ}\\geq C_{0}(1+\\log(R))$ ", "page_idx": 46}, {"type": "text", "text": "It remains to establish (82). Let $f,g$ be two degree-1 polynomials in the variables $(x_{u}\\,:u\\in L_{\\rho^{\\prime}}$ satisfying $\\mathbb{E}f(X)=\\mathbb{E}g(X)=0$ . First, by Corollary G.5, ", "page_idx": 46}, {"type": "equation", "text": "$$\n\\operatorname*{max}_{\\theta\\in[q]}|(\\mathbb{E}_{\\rho^{\\prime}}f g)(\\theta)-\\mathbb{E}f g|\\leq C_{G.5}R^{4}\\exp(-\\varepsilon\\mathrm{h}(\\rho^{\\prime}))\\sqrt{\\mathbb{E}f^{2}(X)}\\sqrt{\\mathbb{E}g^{2}(X)},\n$$", "text_format": "latex", "page_idx": 46}, {"type": "text", "text": "where $C_{G.5}$ is the constant introduced in Corollary G.5. Next, we would like to apply Lemma G.7. Assuming ", "page_idx": 46}, {"type": "equation", "text": "$$\n\\mathrm{h}(u)\\geq\\frac{C_{G.7}(\\log(R)+1)}{\\varepsilon}\n$$", "text_format": "latex", "page_idx": 46}, {"type": "text", "text": "where $C_{G.7}$ is the constant introduced in the Lemma, we can apply the lemma to get ", "page_idx": 47}, {"type": "equation", "text": "$$\n\\mathbb{E}f^{2}(X)\\leq2\\operatorname*{min}_{\\theta}(\\mathbb{E}_{\\rho^{\\prime}}f^{2})(\\theta)\n$$", "text_format": "latex", "page_idx": 47}, {"type": "text", "text": "and the same holds for $g$ . Together we may conclude that ", "page_idx": 47}, {"type": "equation", "text": "$$\n\\operatorname*{max}_{\\theta\\in[q]}|(\\mathbb{E}_{\\rho^{\\prime}}f g)(\\theta)-\\mathbb{E}f g|\\leq2C_{G.5}R^{4}\\exp(-\\varepsilon\\mathrm{h}(\\rho^{\\prime}))\\sqrt{\\operatorname*{min}_{\\theta}(\\mathbb{E}_{\\rho^{\\prime}}f^{2})(\\theta)\\operatorname*{min}_{\\theta}(\\mathbb{E}_{\\rho^{\\prime}}g^{2})(\\theta)}\n$$", "text_format": "latex", "page_idx": 47}, {"type": "text", "text": "Now, we impose the second assumption on $C_{0}$ that ", "page_idx": 47}, {"type": "equation", "text": "$$\nC_{0}\\geq\\operatorname*{max}\\Big\\{\\frac{1}{\\varepsilon}\\Big(\\log(2C_{G.5})+4\\Big),\\,\\frac{C_{G.7}}{\\varepsilon}\\Big\\}.\n$$", "text_format": "latex", "page_idx": 47}, {"type": "text", "text": "Then, we conclude that ", "page_idx": 47}, {"type": "equation", "text": "$$\n\\operatorname*{nax}_{\\substack{\\ell\\in[q]}}|(\\mathbb{E}_{u}f g)(\\theta)-\\mathbb{E}f g|\\le\\exp\\Big(-\\varepsilon\\big(\\mathrm{h}(\\rho^{\\prime})-C_{0}(\\log(R)+1)\\big)\\Big)\\sqrt{\\operatorname*{min}_{\\theta}(\\mathbb{E}_{u}f^{2})(\\theta)\\operatorname*{min}_{\\theta}(\\mathbb{E}_{u}g^{2})(\\theta)}\n$$", "text_format": "latex", "page_idx": 47}, {"type": "text", "text": "provided that ", "page_idx": 47}, {"type": "equation", "text": "$$\n\\mathrm{h}(\\rho^{\\prime})\\geq C_{0}(\\log(R)+1).\n$$", "text_format": "latex", "page_idx": 47}, {"type": "text", "text": "Therefore, we can conclude that $\\mathcal{A}_{1}$ satisfies Assumption G.1 with ", "page_idx": 47}, {"type": "equation", "text": "$$\n\\operatorname{h}^{\\circ}=C_{0}(\\log(R)+1).\n$$", "text_format": "latex", "page_idx": 47}, {"type": "text", "text": "H  Inductive Step in General Case ", "text_level": 1, "page_idx": 47}, {"type": "text", "text": "The goal in this section is to prove Theorem G.3. Let us restate the theorem here: ", "page_idx": 47}, {"type": "text", "text": "Theorem. Consider the rooted tree $T$ and transition matrix $M$ described in Theorem 1.6. There exists $C=C(M,d)>1$ so that the following holds. Suppose $\\boldsymbol{\\mathcal{A}}$ satisfies Assumption G.1 with some parameter $\\mathrm{h}^{\\circ}$ . Let $B=B({\\mathcal{A}})$ (see Definition $I.I l,$ .Then, $\\boldsymbol{\\mathrm{\\Delta}}\\boldsymbol{\\mathrm{\\Omega}}^{\\beta}$ satisfies Assumption G.1 with parameter ", "page_idx": 47}, {"type": "equation", "text": "$$\n\\mathrm{h}^{\\circ}+C(\\log(R)+1).\n$$", "text_format": "latex", "page_idx": 47}, {"type": "text", "text": "In this section, we fix a subcollection $\\boldsymbol{\\mathcal{A}}$ satisfying Assumption G.1 with a given parameter $\\mathrm{h}^{\\circ}$ and let $B=B({\\mathcal{A}})$ ", "page_idx": 47}, {"type": "text", "text": "We begin with the following lemma, which allows us to recycle some of the results from the case $c_{M}>0$ ", "page_idx": 47}, {"type": "text", "text": "Lemma H.1. Suppose $\\boldsymbol{\\mathcal{A}}$ satisfies Assumption G.1 with parameter $\\mathrm{h}^{\\circ}$ . Then, then $\\boldsymbol{\\mathcal{A}}$ satisfies AssumptionB.3 with $\\mathrm{h}^{\\ast}=\\mathrm{h}^{\\circ}+\\frac{2}{\\varepsilon}\\log(2)$ and $\\begin{array}{r}{c^{*}=\\frac{1}{2}}\\end{array}$ ", "page_idx": 47}, {"type": "text", "text": "Proof. Let $f$ be a $\\boldsymbol{\\mathcal{A}}_{\\le v}$ -polynomial. If we set $\\mathrm{h^{*}}\\geq\\mathrm{h}^{\\circ}$ , then (15) follows immediately from (81). Now, we assume that $\\mathbb{E}f(X)=0$ and $\\operatorname{h}(v)\\geq\\operatorname{h}^{\\circ}$ . We could apply (82) with $g=f$ to get ", "page_idx": 47}, {"type": "equation", "text": "$$\n\\operatorname*{max}_{\\theta\\in[q]}\\big|(\\mathbb{E}_{v}f^{2})(\\theta)-\\mathbb{E}f^{2}(X)\\big|\\leq\\exp\\Big(-\\frac{\\varepsilon}{2}(\\mathrm{h}(v)-\\mathrm{h}^{\\circ})\\Big)\\mathbb{E}f^{2}(X).\n$$", "text_format": "latex", "page_idx": 47}, {"type": "text", "text": "f $\\begin{array}{r}{\\exp\\Big(-\\frac{\\varepsilon}{2}(\\mathrm{h}(v)-\\mathrm{h}^{\\circ})\\Big)\\leq\\frac{1}{2}}\\end{array}$ , or equivalently, ", "page_idx": 47}, {"type": "equation", "text": "$$\n\\mathrm{h}(v)\\geq\\mathrm{h}^{\\circ}+\\frac{2}{\\varepsilon}\\log(2),\n$$", "text_format": "latex", "page_idx": 47}, {"type": "text", "text": "then, for every $\\theta\\in[q]$ \uff0c ", "page_idx": 47}, {"type": "equation", "text": "$$\n\\frac{1}{2}\\mathbb{E}h^{2}(X)\\leq(\\mathbb{E}_{v}h^{2})(\\theta)\\leq\\frac{3}{2}\\mathbb{E}h^{2}(X).\n$$", "text_format": "latex", "page_idx": 47}, {"type": "text", "text": "Therefore, if we set $\\mathrm{h}^{\\ast}\\geq\\mathrm{h}^{\\circ}+\\frac{2}{\\varepsilon}\\log(2)$ and $\\begin{array}{r}{c^{*}=\\frac{1}{2}}\\end{array}$ , both (15) and (16) hold. ", "page_idx": 47}, {"type": "text", "text": "In the remainning of this section, we set ", "page_idx": 48}, {"type": "equation", "text": "$$\n\\mathrm{h}^{*}=\\mathrm{h}^{\\circ}+\\frac{2}{\\varepsilon}\\log(2)\\;\\mathrm{and}\\;c^{*}=\\frac{1}{2},\n$$", "text_format": "latex", "page_idx": 48}, {"type": "text", "text": "and we will rely on the fact that $\\boldsymbol{\\mathcal{A}}$ satisfies Assumption B.3 with these two parameters. In particular, we could apply Theorem B.6 to show the existence of $C_{B.6}\\,=\\,C(M,\\bar{\\varepsilon_{,}}1/2)$ such that for any $\\boldsymbol{B}_{\\le v}$ -polynomial $f$ ", "page_idx": 48}, {"type": "equation", "text": "$$\n\\operatorname{Var}\\big[(\\mathbb{E}_{v}f)(X)\\big]\\leq\\exp\\Big(-\\varepsilon\\big(\\mathrm{h}(v)-\\mathrm{h}^{\\circ}+C_{B.6}(\\log(R)+1)\\big)\\Big)\\operatorname{Var}\\big[f(X)\\big].\n$$", "text_format": "latex", "page_idx": 48}, {"type": "text", "text": "Therefore, to establish Theorem G.3, it remains to show the existence of $C=C(M,d)$ so that any $\\boldsymbol{\\beta}_{\\leq v}$ -polynomials $f$ and $g$ with $\\mathrm{h}(v)\\geq\\mathrm{h}^{\\circ}+C(\\log(R)+1)$ and $\\mathbb{E}f(X)=\\mathbb{E}g(X)=0$ satisfy $\\operatorname*{max}_{\\varepsilon[q]}|(\\mathbb{E}_{v}f g)(\\theta)-\\mathbb{E}f g|\\leq\\exp\\Big(-\\frac{\\varepsilon}{2}(\\mathrm{h}(v)-\\mathrm{h}^{\\circ}-C(\\log(R)+1))\\Big)\\sqrt{\\operatorname*{min}_{\\theta}(\\mathbb{E}_{v}f^{2})(\\theta)\\operatorname*{min}_{\\theta^{\\prime}}(\\mathbb{E}_{v}g^{2})(\\theta-\\mathrm{h}^{\\circ})}$ ", "page_idx": 48}, {"type": "text", "text": "To establish the above inequality, the higher level structure is essentially the same as that for deriving Theorem B.6. We again decompose $f$ and $g$ according to Lemma D.1. To the proof of the theorem, similarly it contains three steps: ", "page_idx": 48}, {"type": "text", "text": "1. Establish properties of $\\tilde{f}_{u}$ and $\\tilde{g}_{u}$ , see Proposition H.2.   \n2. Estalbish properties of $f_{k}$ and $g_{k}$ , see Proposition H.6.   \n3.Establish Theorem G.3. ", "page_idx": 48}, {"type": "text", "text": "H.1   Properties of $f_{u}$ ", "text_level": 1, "page_idx": 48}, {"type": "text", "text": "The main goal we want to prove in this subsection is the following Proposition. ", "page_idx": 48}, {"type": "text", "text": "Proposition H.2. There exsits $C=C(M,d)\\geq1$ so that the following holds. For a given $u\\in T\\backslash L$ with ", "page_idx": 48}, {"type": "equation", "text": "$$\n\\mathrm{h}(u)\\geq\\mathrm{h}^{\\circ}+C(\\log(R)+1),\n$$", "text_format": "latex", "page_idx": 48}, {"type": "text", "text": "suppose $f_{u}$ and $g_{u}$ are two functions which are linear combination of $\\psi_{\\sigma}(x)$ with $\\sigma\\in\\mathcal{F}(\\boldsymbol{B}_{u})$ . Then, for any $\\theta,\\theta^{\\prime}\\in[q]$ \uff0c ", "page_idx": 48}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\quad\\left|\\big(\\mathbb{E}_{u}f_{u}g_{u}\\big)(\\theta)-\\big(\\mathbb{E}_{u}f_{u}g_{u})(\\theta^{\\prime})\\big|\\right.}\\\\ &{\\le\\exp\\Big(-\\frac{\\varepsilon}{2}(\\mathrm{h}(u)-C(\\log(R)+1)-\\mathrm{h}^{\\circ})\\Big)\\sqrt{\\underset{\\theta}{\\operatorname*{min}}(\\mathbb{E}_{u}f_{u}^{2})(\\theta)\\operatorname*{min}(\\mathbb{E}_{u}g_{u}^{2})(\\theta)}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 48}, {"type": "text", "text": "With a minor modification to our approach, we are able to obtain an analogous result wherein $f_{u}$ and $g_{u}$ are substituted by $\\tilde{f}_{u}$ and $\\tilde{g}_{u}$ ,respectively: ", "page_idx": 48}, {"type": "text", "text": "Corollary H.3. There exsits $C=C(M,d)\\geq1$ so that the following holds. For a given $u\\in T\\backslash L$ with ", "page_idx": 48}, {"type": "equation", "text": "$$\n\\mathrm{h}(u)\\geq\\mathrm{h}^{\\circ}+C(\\log(R)+1),\n$$", "text_format": "latex", "page_idx": 48}, {"type": "text", "text": "suppose $f_{u}$ and $g_{u}$ are two functions which are linear combination of $\\psi_{\\mathbf{S}}(x)$ with $\\mathbf{S}\\in\\mathcal{F}(\\mathcal{B}_{u})$ . Then, for any $\\theta,\\theta^{\\prime}\\in[q]$ \uff0c ", "page_idx": 48}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\quad\\left|(\\mathbb{E}_{u}\\tilde{f}_{u}\\tilde{g}_{u})(\\theta)-(\\mathbb{E}_{u}\\tilde{f}_{u}\\tilde{g}_{u})(\\theta^{\\prime})\\right|}\\\\ &{\\le\\exp\\Big(-\\frac{\\varepsilon}{2}(\\mathrm{h}(u)-C(\\log(R)+1)-\\mathrm{h}^{\\circ})\\Big)\\sqrt{\\underset{\\theta}{\\operatorname*{min}}(\\mathbb{E}_{u}\\tilde{f}_{u}^{2})(\\theta)\\operatorname*{min}(\\mathbb{E}_{u}\\tilde{g}_{u}^{2})(\\theta)}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 48}, {"type": "text", "text": "Let us prove Corollary first. ", "page_idx": 48}, {"type": "text", "text": "Proof. Let $C_{0}$ denote the constant introduced in the Corollary. Its value will be dervied during the proof. ", "page_idx": 48}, {"type": "text", "text": "From the identity ", "page_idx": 48}, {"type": "equation", "text": "$$\n\\tilde{f}_{u}(x)\\tilde{g}_{u}(x)=f_{u}(x)g_{u}(x)-f_{u}(x)\\mathbb{E}g_{u}(X)-\\mathbb{E}f_{u}(X)g_{u}(x)+\\mathbb{E}f_{u}(X)\\mathbb{E}g_{u}(X),\n$$", "text_format": "latex", "page_idx": 48}, {"type": "text", "text": "it follows that ", "page_idx": 49}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{(\\mathbb{E}_{u}\\tilde{f}_{u}\\tilde{g}_{u})(\\theta)-(\\mathbb{E}_{u}\\tilde{f}_{u}\\tilde{g}_{u})(\\theta^{\\prime})\\big|\\le\\!\\big|(\\mathbb{E}_{u}f_{u}g_{u})(\\theta)-(\\mathbb{E}_{u}f_{u}g_{u})(\\theta^{\\prime})\\big|+|\\mathbb{E}g_{u}(X)|\\big|(\\mathbb{E}_{u}f_{u})(\\theta)-(\\mathbb{E}_{u}f_{u})(\\theta^{\\prime})}&{}\\\\ {+\\,|\\mathbb{E}f_{u}(X)|\\big|(\\mathbb{E}_{u}g_{u})(\\theta)-(\\mathbb{E}_{u}g_{u})(\\theta^{\\prime})\\big|}&{}\\\\ {\\le\\!\\big|(\\mathbb{E}_{u}f_{u}g_{u})(\\theta)-(\\mathbb{E}_{u}f_{u}g_{u})(\\theta^{\\prime})\\big|+4\\operatorname*{max}_{\\theta^{\\prime}}|\\mathbb{E}_{u}f_{u}(\\theta)|\\operatorname*{max}|\\mathbb{E}_{u}g_{u}(\\theta)|.}\\end{array}\n$$", "text_format": "latex", "page_idx": 49}, {"type": "text", "text": "First, we apply Propostion E.1 with the fact that $\\boldsymbol{\\mathcal{A}}$ satisfies Assumption G.1 with parameter $\\mathrm{h^{*}}=$ h\u00b0+ 2log(2) and c\\* = , ", "page_idx": 49}, {"type": "equation", "text": "$$\n\\operatorname*{max}_{\\theta^{\\prime}}(\\mathbb{E}_{u}f_{u})^{2}(\\theta)\\leq\\exp(-2\\varepsilon(\\mathrm{h}(u)-C_{E.1}(\\log(R)+1)-\\mathrm{h}^{*}))\\operatorname*{max}_{\\theta^{\\prime}}(\\mathbb{E}_{u}f_{u}^{2})(\\theta^{\\prime})\n$$", "text_format": "latex", "page_idx": 49}, {"type": "text", "text": "where $C_{E.1}=C(M,d,\\frac{1}{2})$ is the constant introduced in the Proposition. ", "page_idx": 49}, {"type": "text", "text": "Second, applying Proposition H.2 with $f_{u}=g_{u}$ we have ", "page_idx": 49}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\quad\\vert\\operatorname*{max}_{\\theta}(\\mathbb{E}_{u}f_{u}^{2})(\\theta)-\\operatorname*{min}_{\\theta^{\\prime}}(\\mathbb{E}_{u}f_{u}^{2})(\\theta^{\\prime})\\vert}\\\\ &{\\le\\exp\\Big(-\\frac{\\varepsilon}{2}(\\mathrm{h}(u)-C_{H.2}(\\log(R)+1)-\\mathrm{h}^{\\circ})\\Big)\\operatorname*{min}_{\\theta}(\\mathbb{E}_{u}f_{u}^{2})(\\theta)}\\end{array}\n$$", "text_format": "latex", "page_idx": 49}, {"type": "text", "text": "where $C_{H,2}$ is the constant introduced in Proposition H.2. ", "page_idx": 49}, {"type": "text", "text": "Let us impose the first assumption that $C_{0}\\geq C_{H.2}$ . Then, with $\\mathrm{h}(u)\\geq\\mathrm{h}^{\\circ}+C_{0}(\\log(R)+1)$ we can conclude that ", "page_idx": 49}, {"type": "equation", "text": "$$\n\\operatorname*{max}_{\\theta^{\\prime}}(\\mathbb{E}_{u}f_{u}^{2})(\\theta^{\\prime})\\leq2\\operatorname*{min}_{\\theta^{\\prime}}(\\mathbb{E}_{u}f_{u}^{2})(\\theta^{\\prime}).\n$$", "text_format": "latex", "page_idx": 49}, {"type": "text", "text": "Clearly, the same derivation also holds for $g_{u}$ Therefore, we conclude that ", "page_idx": 49}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\quad\\big|\\big(\\mathbb{E}_{u}\\tilde{f}_{u}\\tilde{g}_{u}\\big)(\\theta)-\\big(\\mathbb{E}_{u}\\tilde{f}_{u}\\tilde{g}_{u})(\\theta^{\\prime})\\big|}\\\\ &{\\le\\big|(\\mathbb{E}_{u}f_{u}g_{u})(\\theta)-\\big(\\mathbb{E}_{u}f_{u}g_{u})(\\theta^{\\prime})\\big|}\\\\ &{\\quad+8\\exp(-2\\varepsilon(\\mathrm{h}(u)-C_{1}(\\mathrm{log}(R)+1)-\\mathrm{h}^{*})\\big)\\sqrt{\\operatorname*{min}(\\mathbb{E}_{u}f_{u}^{2})(\\theta)\\operatorname*{min}(\\mathbb{E}_{u}g_{u}^{2})(\\theta)}}\\\\ &{\\le\\exp\\Big(-\\frac{\\varepsilon}{2}\\big(\\mathrm{h}(u)-C_{H.2}(\\mathrm{log}(R)+1)-\\mathrm{h}^{*})\\Big)\\sqrt{\\operatorname*{min}(\\mathbb{E}_{u}f_{u}^{2})(\\theta)\\operatorname*{min}(\\mathbb{E}_{u}g_{u}^{2})(\\theta)}}\\\\ &{\\quad+8\\exp\\Big(-2\\varepsilon\\Big(\\mathrm{h}(u)-C_{E.1}(\\mathrm{log}(R)+1)-\\mathrm{h}^{*}-\\frac{2}{\\varepsilon}\\log(2)\\Big)\\Big)\\sqrt{\\operatorname*{min}(\\mathbb{E}_{u}f_{u}^{2})(\\theta)\\operatorname*{min}(\\mathbb{E}_{u}g_{u}^{2})(\\theta)}}\\\\ &{\\le\\exp\\Big(-\\frac{\\varepsilon}{2}(\\mathrm{h}(u)-C_{0}(\\mathrm{log}(R)+1)-\\mathrm{h}^{*})\\Big)\\sqrt{\\operatorname*{min}(\\mathbb{E}_{u}f_{u}^{2})(\\theta)\\operatorname*{min}(\\mathbb{E}_{u}g_{u}^{2})(\\theta)},}\\end{array}\n$$", "text_format": "latex", "page_idx": 49}, {"type": "text", "text": "where the last inequality follows by imposing the second assumption on $C_{0}$ that ", "page_idx": 49}, {"type": "equation", "text": "$$\nC_{0}\\geq\\frac{2}{\\varepsilon}\\log(2)+\\operatorname*{max}\\Big\\{C_{H.2},C_{E.1}+\\frac{2}{\\varepsilon}\\log(2)+\\frac{1}{2\\varepsilon}\\log(8)\\Big\\}.\n$$", "text_format": "latex", "page_idx": 49}, {"type": "text", "text": "This completes the proof of the Corollary. ", "page_idx": 49}, {"type": "text", "text": "The main technical part for proving Proposition H.2 is the following: ", "page_idx": 49}, {"type": "text", "text": "Lemma H.4. For any $u\\in T$ With $\\begin{array}{r}{\\exp\\big(-\\frac{\\varepsilon}{2}(\\mathrm{h}(u)-\\mathrm{h}^{\\circ})\\big)\\leq\\frac{1}{4R d}}\\end{array}$ thefllowing holds: Let $I\\subset[d_{u}]$ be a subset of size at least 2. For any $a(x)$ and $b(x)$ which are linear combinations of $\\psi_{\\sigma}(x)$ with $\\sigma\\in B_{u}$ satisfying $I(\\sigma)=I$ we have ", "page_idx": 49}, {"type": "equation", "text": "$$\n\\operatorname*{max}_{\\theta^{\\prime}\\in[q]}\\big|(\\mathbb{E}_{u}a b)(\\theta)-(\\mathbb{E}_{u}a b)(\\theta^{\\prime})\\big|\\leq4d R\\exp\\Big(-\\frac{\\varepsilon}{2}(\\mathrm{h}(u)-\\mathrm{h}^{\\circ})\\Big)\\sqrt{\\operatorname*{min}_{\\theta}(\\mathbb{E}_{u}a^{2})(\\theta)\\cdot\\operatorname*{min}_{\\theta}(\\mathbb{E}_{u}b^{2})(\\theta)}.\n$$", "text_format": "latex", "page_idx": 49}, {"type": "text", "text": "Remark H.5. From the assumption that $\\mathrm{h}(u)$ satisfies ", "page_idx": 49}, {"type": "equation", "text": "$$\n4d R\\exp\\Big(-\\frac{\\varepsilon}{2}(\\ensuremath{\\mathrm{h}}(u)-\\ensuremath{\\mathrm{h}}^{\\circ})\\Big)\\leq1\\Leftrightarrow\\ensuremath{\\mathrm{h}}(u)\\geq\\ensuremath{\\mathrm{h}}^{\\circ}+\\frac{2}{\\varepsilon}\\log(4d R).\n$$", "text_format": "latex", "page_idx": 49}, {"type": "text", "text": "By taking $a(x)=b(x)$ we have ", "page_idx": 49}, {"type": "equation", "text": "$$\n\\operatorname*{max}_{\\theta}(\\mathbb{E}_{u}a^{2})(\\theta)\\le2\\operatorname*{min}_{\\theta}(\\mathbb{E}_{u}a^{2})(\\theta).\n$$", "text_format": "latex", "page_idx": 49}, {"type": "text", "text": "Proof.Let $u,a(x)$ ,and $b(x)$ be the vertex and functions described in the Lemma. Let us introduce some notations for the ease of expressing the calculation later. For brevity, let ", "page_idx": 50}, {"type": "equation", "text": "$$\n\\delta=\\exp\\Big(-\\frac{\\varepsilon}{2}\\big(\\mathrm{h}(u)-\\mathrm{h}^{\\circ}\\big)\\Big).\n$$", "text_format": "latex", "page_idx": 50}, {"type": "text", "text": "For $x\\in[q]^{T}$ , let ", "page_idx": 50}, {"type": "equation", "text": "$$\nx_{u,I}=(x_{u_{i}})_{i\\in I}.\n$$", "text_format": "latex", "page_idx": 50}, {"type": "text", "text": "For any given function $h(x)$ with variables in $(x_{v}\\,:\\,v\\in\\bigcup_{i\\in I}T_{u_{i}})$ , we define ", "page_idx": 50}, {"type": "equation", "text": "$$\n(\\mathbb{E}_{u,I}h)(x):=\\mathbb{E}\\Big[h(X)\\,\\Big|\\,\\forall v\\notin\\bigcup_{i\\in I}\\{w<u_{i}\\},\\,X_{v}=x_{v}\\Big].\n$$", "text_format": "latex", "page_idx": 50}, {"type": "text", "text": "Observe that ", "page_idx": 50}, {"type": "equation", "text": "$$\n(\\mathbb{E}_{u,I}a)(x),\\,(\\mathbb{E}_{u,I}b)(x),\\,\\mathrm{and}\\,\\,(\\mathbb{E}_{u,I}a b)(x)\n$$", "text_format": "latex", "page_idx": 50}, {"type": "text", "text": "are functions with input $x_{u,I}$ . This is due to the fact that $a$ and $b$ -and consequently $a b-$ are functions of variables $\\textstyle(x_{v}\\,:\\,x_{v}\\in\\bigcup_{i\\in I}L_{u_{i}})$ and Markov Property. ", "page_idx": 50}, {"type": "text", "text": "Claim: The function $x_{u,I}\\mapsto(\\mathbb{E}_{u,I}a b)(x_{u,I})$ is Lipschitz continuous with respect to the Hamming Distance with Lipschitz constant ", "page_idx": 50}, {"type": "equation", "text": "$$\n2\\delta\\sqrt{\\underset{x_{u,I}}{\\mathrm{max}}(\\mathbb{E}_{u,I}a^{2})(x_{u,I})}\\sqrt{\\underset{x_{u,I}}{\\mathrm{max}}(\\mathbb{E}_{u,I}b^{2})(x_{u,I})}.\n$$", "text_format": "latex", "page_idx": 50}, {"type": "text", "text": "We begin with the proof of the claim. Fix an index $i_{0}\\in I$ . Without lose of generality, we assume $I=[k]$ and $i_{0}=1$ For $x\\in[q]^{T}$ , let ", "page_idx": 50}, {"type": "equation", "text": "$$\nx_{i}=x_{\\leq u_{i}}\n$$", "text_format": "latex", "page_idx": 50}, {"type": "text", "text": "for $i\\leq[d_{u}]$ , and set ", "page_idx": 50}, {"type": "equation", "text": "$$\nx_{0}=(x_{2},\\ldots,x_{k}).\n$$", "text_format": "latex", "page_idx": 50}, {"type": "text", "text": "With this notation above, we can express ", "page_idx": 50}, {"type": "equation", "text": "$$\n\\begin{array}{r}{a(x)=\\!a(x_{0},x_{1})\\qquad\\qquad\\qquad\\mathrm{and}\\qquad\\qquad\\qquad b(x)=\\!b(x_{0},x_{1}).}\\end{array}\n$$", "text_format": "latex", "page_idx": 50}, {"type": "text", "text": "Fix any value of $x_{0}$ , the function ", "page_idx": 50}, {"type": "equation", "text": "$$\nx_{1}\\mapsto a(x_{0},x_{1})\n$$", "text_format": "latex", "page_idx": 50}, {"type": "text", "text": "is a linear combination of $\\tilde{\\phi}_{\\sigma_{1}}(x_{1})$ with $\\sigma_{1}\\in\\mathcal{F}(\\mathcal{A}_{\\leq u})$ . Notably, this implies that $\\mathbb{E}a(x_{0},X_{1})=0$ The same properties hold for the function $x_{1}\\mapsto b(\\Bar{x_{0}},x_{1})$ ", "page_idx": 50}, {"type": "text", "text": "Now, given the assumption $\\begin{array}{r}{\\exp\\big(-\\frac{\\varepsilon}{2}(\\mathrm{h}(u)-\\mathrm{h}^{\\circ})\\big)\\,\\le\\,\\frac{1}{4R d}}\\end{array}$ implies $\\operatorname{h}(u)\\geq\\operatorname{h}^{\\circ}$ , we can apply (82) from Assumption G.1 to get that ", "page_idx": 50}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\underset{\\theta,\\theta^{\\prime}\\in[q]}{\\operatorname*{max}}\\left|\\mathbb{E}\\big[a(x_{0},X_{1})b(x_{0},X_{1})\\bigm|X_{u_{1}}=\\theta_{1}\\big]-\\mathbb{E}\\big[a(x_{0},X_{1})b(x_{0},X_{1})\\bigm|X_{u_{1}}=\\theta_{2}\\big]\\right|}\\\\ &{\\le2\\underset{\\theta\\in[q]}{\\operatorname*{max}}\\left|\\mathbb{E}\\big[a(x_{0},X_{1})b(x_{0},X_{1})\\bigm|X_{u_{1}}=\\theta_{1}\\big]-\\mathbb{E}a(x_{0},X_{1})b(x_{0},X_{1})\\right|}\\\\ &{\\le2\\delta\\sqrt{\\underset{\\theta}{\\operatorname*{min}}\\mathbb{E}\\big[a^{2}(x_{0},X_{1})\\bigm|X_{u_{1}}=\\theta\\big]\\underset{\\theta}{\\operatorname*{min}}\\mathbb{E}\\big[b^{2}(x_{0},X_{1})\\bigm|X_{u_{1}}=\\theta\\big]}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 50}, {"type": "text", "text": "For any $x\\in[q]^{T}$ , let $x_{u_{0}}=(x_{u_{2}},x_{u_{3}},.~.~.~,x_{u_{d_{u}}})$ .By the Markov Property, for any $\\theta\\in[q]$ \uff0c ", "page_idx": 50}, {"type": "equation", "text": "$$\n\\begin{array}{l}{{(X_{0}\\,|\\,X_{u_{0}}=x_{u_{0}},X_{u_{1}}=\\theta)=(X_{0}\\,|\\,X_{u_{0}}=x_{u_{0}})}}\\\\ {{(X_{1}\\,|\\,X_{u_{0}}=x_{u_{0}},X_{u_{1}}=\\theta)=(X_{u_{1}}\\,|\\,X_{u_{1}}=\\theta)}}\\end{array}\n$$", "text_format": "latex", "page_idx": 50}, {"type": "text", "text": "are jointly independent. Hence, ", "page_idx": 50}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\quad\\mathbb{E}\\big[a(X_{0},X_{1})b(X_{0},X_{1})\\,\\big|\\,X_{u_{0}}=x_{u_{0}},X_{u_{1}}=\\theta\\big]}\\\\ &{=\\!\\!\\mathbb{E}\\big[a(Y_{0},X_{1})b(Y_{0},X_{1})\\,\\big|\\,X_{u_{1}}=\\theta\\big]}\\end{array}\n$$", "text_format": "latex", "page_idx": 50}, {"type": "text", "text": "where $Y_{0}$ is an independent copy of $\\left(X_{0}\\,|\\,X_{u_{0}}=x_{u_{0}}\\right)$ . We have ", "page_idx": 51}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\left|\\mathbb{E}\\big[a(X_{0},X_{1})b(X_{0},X_{1})\\bigm|X_{u_{0}}=x_{u_{0}},X_{u_{1}}=\\theta\\big]-\\mathbb{E}\\big[a(X_{0},X_{1})b(X_{0},X_{1})\\bigm|X_{u_{0}}=x_{u_{0}},X_{u_{1}}=\\theta^{\\prime}\\big]\\right.}\\\\ &{\\left|\\mathbb{E}_{Y_{0}}\\Big[\\mathbb{E}_{X_{1}}[a(Y_{0},X_{1})b(Y_{0},X_{1})\\bigm|X_{u_{1}}=\\theta\\big]-\\mathbb{E}_{X_{1}}[a(Y_{0},X_{1})b(Y_{0},X_{1})\\bigm|X_{u_{1}}=\\theta^{\\prime}\\big]\\right]\\right|}\\\\ &{\\left.\\leq\\mathbb{E}_{Y_{0}}\\Big[\\big|\\mathbb{E}_{X_{1}}[a(Y_{0},X_{1})b(Y_{0},X_{1})\\bigm|X_{u_{1}}=\\theta\\big]-\\mathbb{E}_{X_{1}}[a(Y_{0},X_{1})b(Y_{0},X_{1})\\bigm|X_{u_{1}}=\\theta^{\\prime}\\big]\\right|\\Big]}\\\\ &{\\leq2\\delta\\mathbb{E}_{Y_{0}}\\Big[\\big(\\underset{\\theta}{\\operatorname*{min}}\\mathbb{E}_{X_{1}}[a^{2}(Y_{0},X_{1})\\bigm|X_{u_{1}}=\\theta\\big]\\big)^{1/2}\\cdot\\big(\\underset{\\theta^{\\prime}}{\\operatorname*{min}}\\mathbb{E}_{X_{1}}[b^{2}(Y_{0},X_{1})\\bigm|X_{u_{1}}=\\theta^{\\prime}\\big]\\big)^{1/2}\\Big]}\\\\ &{\\leq2\\delta\\big(\\mathbb{E}_{Y_{0}}\\big[\\underset{\\theta}{\\operatorname*{min}}\\mathbb{E}_{X_{1}}[a^{2}(Y_{0},X_{1})\\bigm|X_{u_{1}}=\\theta\\big]\\big)^{1/2}\\cdot\\big(\\mathbb{E}_{Y_{0}}\\big[\\underset{\\theta^{\\prime}}{\\operatorname*{min}}\\mathbb{E}_{X_{1}}[b^{2}(Y_{0},X_{1})\\bigm|X_{u_{1}}=\\theta^ \n$$", "text_format": "latex", "page_idx": 51}, {"type": "text", "text": "where the last inequality follows from Holder's inequality. Further, ", "page_idx": 51}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{E}_{Y_{0}}\\big[\\underset{\\theta}{\\operatorname*{min}}\\,\\mathbb{E}_{X_{1}}[a^{2}(Y_{0},X_{1})\\,|\\,X_{u_{1}}=\\theta]\\big]\\leq\\underset{\\theta}{\\operatorname*{min}}\\,\\mathbb{E}_{Y_{0}}\\big[\\mathbb{E}_{X_{1}}[a^{2}(Y_{0},X_{1})\\,|\\,X_{u_{1}}=\\theta]\\big]}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\qquad=\\underset{\\theta}{\\operatorname*{min}}\\,\\mathbb{E}\\big[a^{2}(X)\\,\\big|\\,X_{u_{0}}=x_{u_{0}},X_{u_{1}}=\\theta\\big]}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\qquad\\leq\\underset{x_{u,I}}{\\operatorname*{max}}(\\mathbb{E}_{u,I}a^{2})(x_{u,I}).}\\end{array}\n$$", "text_format": "latex", "page_idx": 51}, {"type": "text", "text": "Applying the same derivation to $b$ weget ", "page_idx": 51}, {"type": "equation", "text": "$$\n\\mathbb{E}_{Y_{0}}\\big[\\operatorname*{min}_{\\theta}\\mathbb{E}_{X_{1}}[b^{2}(Y_{0},X_{1})\\,|\\,X_{u_{1}}=\\theta]\\big]\\leq\\operatorname*{max}_{x_{u,I}}(\\mathbb{E}_{u,I}b^{2})(x_{u,I}).\n$$", "text_format": "latex", "page_idx": 51}, {"type": "text", "text": "Therefore, our claim (89) follows: For any $\\theta,\\theta^{\\prime}\\in[q]$ ", "page_idx": 51}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\quad\\left|\\mathbb{E}\\!\\left[a(X)b(X)\\,\\middle|\\,X_{u_{0}}=x_{u_{0}},x_{u_{1}}=\\theta\\right]-\\mathbb{E}\\!\\left[a(X)b(X)\\,\\middle|\\,X_{u_{0}}=x_{u_{0}},x_{u_{1}}=\\theta^{\\prime}\\right]\\right|}\\\\ &{\\le\\!2\\delta\\sqrt{\\underset{x_{u,I}}{\\operatorname*{max}}(\\mathbb{E}a^{2})(x_{u,I})\\underset{x_{u,I}}{\\operatorname*{max}}(\\mathbb{E}b^{2})(x_{u,I})}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 51}, {"type": "text", "text": "With the Lipschitz continuity been established, essentially the lemma follows when $\\delta$ is sufficiently small. Let us proceed with the remaining argument. Let ", "page_idx": 51}, {"type": "equation", "text": "$$\n\\begin{array}{r}{x_{u,I}^{\\prime}=\\!\\operatorname*{argmin}_{x_{u,I}}(\\mathbb{E}_{u,I}a^{2})(x_{u,I})\\qquad\\mathrm{~and~}\\qquad x_{u,I}^{\\prime\\prime}=\\!\\operatorname*{argmax}_{x_{u,I}}(\\mathbb{E}_{u,I}a^{2})(x_{u,I}).}\\end{array}\n$$", "text_format": "latex", "page_idx": 51}, {"type": "text", "text": "Applying (89) with the assumption $a(x)=b(x)$ and the fact $|I|\\leq d_{u}$ ", "page_idx": 51}, {"type": "equation", "text": "$$\n\\begin{array}{r}{(\\mathbb{E}_{u,I}a^{2})(x_{u,I}^{\\prime\\prime})-(\\mathbb{E}_{u,I}a^{2})(x_{u,I}^{\\prime})\\leq2d_{u}\\delta(\\mathbb{E}_{u,I}a^{2})(a_{u,I}^{\\prime\\prime}),}\\end{array}\n$$", "text_format": "latex", "page_idx": 51}, {"type": "text", "text": "and hence ", "page_idx": 51}, {"type": "equation", "text": "$$\n\\operatorname*{max}_{x_{u,I}}(\\mathbb{E}_{u,I}a^{2})(x_{u,I})\\le\\frac{1}{1-2d_{u}\\delta}\\operatorname*{min}_{x_{u,I}}(\\mathbb{E}_{u,I}a^{2})(x_{u,I})\\le\\frac{1}{1-2d_{u}\\delta}\\operatorname*{min}_{s}(\\mathbb{E}_{u}a^{2})(s),\n$$", "text_format": "latex", "page_idx": 51}, {"type": "text", "text": "provided that $2d_{u}\\delta<1$ ", "page_idx": 51}, {"type": "text", "text": "Again, the same derivation also holds for $b$ . Combining (89) and (90) we conclude that for any 0,\u03b8/ \u2208 [a], ", "page_idx": 51}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{|(\\mathbb{E}_{u}a b)(\\theta)-(\\mathbb{E}_{u}a b)(\\theta^{\\prime})|\\leq|\\operatorname*{max}_{x_{u,I}}(\\mathbb{E}_{u}a b)(x_{u,I})-\\operatorname*{min}_{x_{u,I}^{\\prime}}(\\mathbb{E}_{u}a b)(x_{u,I}^{\\prime})|}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\leq\\cfrac{2d_{u}\\delta}{1-2d_{u}\\delta}\\sqrt{\\underset{\\theta}{\\operatorname*{min}}(\\mathbb{E}_{u}a^{2})(\\theta)\\underset{\\theta^{\\prime}}{\\operatorname*{min}}(\\mathbb{E}_{u}b^{2})(\\theta^{\\prime})}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 51}, {"type": "text", "text": "With our assumption on the tree $T$ that $d_{u}\\leq R d$ , our assumption ", "page_idx": 51}, {"type": "equation", "text": "$$\n\\delta=\\exp\\left(-\\frac{\\varepsilon}{2}(\\mathrm{h}(u)-\\mathrm{h}^{\\circ})\\right)\\leq\\frac{1}{4R d},\n$$", "text_format": "latex", "page_idx": 51}, {"type": "text", "text": "implies that ", "page_idx": 51}, {"type": "equation", "text": "$$\n\\frac{2d_{u}\\delta}{1-2d_{u}\\delta}\\leq4R d\\delta.\n$$", "text_format": "latex", "page_idx": 51}, {"type": "text", "text": "We conclude that ", "page_idx": 51}, {"type": "equation", "text": "$$\n\\begin{array}{r}{|(\\mathbb{E}_{u}a b)(\\theta)-(\\mathbb{E}_{u}a b)(\\theta^{\\prime})|\\leq4R d\\exp\\left(\\frac{\\varepsilon}{2}(\\mathrm{h}(u)-\\mathrm{h}^{\\circ})\\right)\\sqrt{\\underset{\\theta}{\\operatorname*{min}}(\\mathbb{E}_{u}a^{2})(\\theta)\\underset{\\theta^{\\prime}}{\\operatorname*{min}}(\\mathbb{E}_{u}b^{2})(\\theta^{\\prime})}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 51}, {"type": "text", "text": "Proof ofProposition $H.2$ Let $C_{0}=C_{0}(M,d)$ denote the constant introduced in the statement of the Proposition. Recall the decomposition of $f_{u}$ into $f_{u,I}$ from Definition E.4, consider the decomposition ", "page_idx": 52}, {"type": "equation", "text": "$$\nf_{u}(x)=\\sum_{I\\subseteq[d_{u}]:\\,|I|\\geq2}f_{u,I}(x){\\mathrm{~and~}}g_{u}(x)=\\sum_{I\\subseteq[d_{u}]:\\,|I|\\geq2}g_{u,I}(x).\n$$", "text_format": "latex", "page_idx": 52}, {"type": "text", "text": "The proof of the Proposition will proceed by bounding summands in the formula below: ", "page_idx": 52}, {"type": "equation", "text": "$$\n\\big|(\\mathbb{E}_{u}f_{u}g_{u})(\\theta)-(\\mathbb{E}_{u}f_{u}g_{u})(\\theta^{\\prime})\\big|\\le\\sum_{I,J\\subseteq[d_{u}]:\\,|I|,|J|\\ge2}\\big|(\\mathbb{E}_{u}f_{u,I}g_{u,J})(\\theta)-(\\mathbb{E}_{u}f_{u,I}g_{u,J})(\\theta^{\\prime})\\big|.\n$$", "text_format": "latex", "page_idx": 52}, {"type": "text", "text": "Estimate of summands in (91): For any $I,J\\subseteq[d_{u}]$ with $|I|,|J|\\ge2$ , we have two cases to consider: First, we consider the case $\\overline{{I}}\\neq J$ . Notice that, by Lemma H.1, $\\boldsymbol{\\mathcal{A}}$ satisfies Assumption B.3 with parameters $\\begin{array}{r}{(\\mathrm{h}^{\\circ}+\\frac{2}{\\varepsilon}\\log(2),\\,\\frac{1}{2})}\\end{array}$ . This allows us to invoke Corollary E.6, yielding ", "page_idx": 52}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\quad\\big|(\\mathbb{E}_{u}f_{u,I}g_{u,J})(\\theta)-(\\mathbb{E}_{u}f_{u,I}g_{u,J})(\\theta^{\\prime})\\big|}\\\\ &{\\le2\\operatorname*{max}|(\\mathbb{E}_{u}f_{u,I}g_{u,J})(\\theta)|}\\\\ &{\\le2\\exp\\Big(-\\frac{\\varepsilon|I\\Delta J|}{2}(\\mathrm{h}(u)-C_{E.6}-\\mathrm{h}^{\\circ}-\\frac{2}{\\varepsilon}\\log(2))\\Big)\\big(\\operatorname*{max}_{\\theta\\in[q]}(\\mathbb{E}_{u}f_{u,I}^{2})(\\theta)\\big)^{1/2}\\cdot\\big(\\underset{\\theta\\in[q]}{\\operatorname*{max}}(\\mathbb{E}_{u}g_{u,J}^{2})(\\theta)\\big)^{1/2}}\\end{array}\n$$", "text_format": "latex", "page_idx": 52}, {"type": "text", "text": "where $C_{E.6}=C_{E.6}(M,d,\\frac{1}{2})$ is the constant introduced in the Corollary. ", "page_idx": 52}, {"type": "text", "text": "Let us impose the first assumption on $C_{0}$ that ", "page_idx": 52}, {"type": "equation", "text": "$$\nC_{0}\\geq\\frac{2}{\\varepsilon}(1+\\log(4d)),\n$$", "text_format": "latex", "page_idx": 52}, {"type": "text", "text": "which implies that $\\begin{array}{r}{\\mathrm{h}(u)\\geq\\mathrm{h}^{\\circ}+C_{0}(\\log(R)+1)\\geq\\mathrm{h}^{\\circ}+\\frac{2}{\\varepsilon}\\log(4d R)}\\end{array}$ . With this assumption, we could apply the remark (88) of Lemma H.4 to get ", "page_idx": 52}, {"type": "equation", "text": "$$\n\\big(\\operatorname*{max}_{\\theta\\in[q]}(\\mathbb{E}_{u}f_{u,I}^{2})(\\theta)\\big)^{1/2}\\leq2\\big(\\operatorname*{min}_{\\theta}(\\mathbb{E}_{u}f_{u,I}^{2})(\\theta)\\big)^{1/2}\n$$", "text_format": "latex", "page_idx": 52}, {"type": "text", "text": "and the same holds for $g_{u,J}$ . Hence, for $I\\ne J$ we have ", "page_idx": 52}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\quad\\big|(\\mathbb{E}_{u}f_{u,I}g_{u,J})(\\theta)-(\\mathbb{E}_{u}f_{u,I}g_{u,J})(\\theta^{\\prime})\\big|}\\\\ &{\\le4\\exp\\Big(-\\frac{\\varepsilon|I\\Delta J|}{2}(\\mathtt{h}(u)-C_{E.6}-\\mathtt{h}^{\\circ}+\\frac{2}{\\varepsilon}\\log(2))\\Big)\\big(\\underset{\\theta\\in[q]}{\\operatorname*{min}}(\\mathbb{E}_{u}f_{u,I}^{2})(\\theta)\\big)^{1/2}\\cdot\\big(\\underset{\\theta\\in[q]}{\\operatorname*{min}}(\\mathbb{E}_{u}g_{u,J}^{2})(\\theta)\\big)^{1/2}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 52}, {"type": "text", "text": "Second, we consider the case $I=J$ . Here we simply apply Lemma H.4, yielding ", "page_idx": 52}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\quad\\big|(\\mathbb{E}_{u}f_{u,I}g_{u,I})(\\theta)-(\\mathbb{E}_{u}f_{u,I}g_{u,I})(\\theta^{\\prime})\\big|}\\\\ &{\\le4R d\\exp\\Big(-\\frac{\\varepsilon}{2}(\\mathrm{h}(u)-\\mathrm{h}^{\\circ})\\Big)\\big(\\operatorname*{min}_{\\theta\\in[q]}(\\mathbb{E}_{u}f_{u,I}^{2})(\\theta)\\big)^{1/2}\\cdot\\big(\\operatorname*{min}_{\\theta\\in[q]}(\\mathbb{E}_{u}g_{u,J}^{2})(\\theta)\\big)^{1/2}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 52}, {"type": "text", "text": "Let us unify the above two estimates by introducing ", "page_idx": 52}, {"type": "equation", "text": "$$\nC_{1}=\\operatorname*{max}\\Big\\{C_{E.6}+\\frac{2}{\\varepsilon}\\log(2)+\\frac{2}{\\varepsilon}\\log(8),\\,\\frac{2}{\\varepsilon}(1+\\log(24d))\\Big\\}.\n$$", "text_format": "latex", "page_idx": 52}, {"type": "text", "text": "Then, ", "page_idx": 52}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\big|\\big(\\mathbb{E}_{u}f_{u,I}g_{u,J})(\\theta)-\\big(\\mathbb{E}_{u}f_{u,I}g_{u,J})(\\theta^{\\prime})\\big|}\\\\ &{\\overset{\\le}\\underbrace{\\frac{1}{6}\\exp\\Big(-\\frac{\\varepsilon}{2}\\operatorname*{max}\\{|I\\Delta J|,1\\}(\\mathrm{h}(u)-C_{1}(\\log(R)+1)-\\mathrm{h}^{\\circ})\\Big)}_{:=a_{I,J}}\\underbrace{\\big(\\operatorname*{min}(\\mathbb{E}_{u}f_{u,I}^{2})(\\theta)\\big)^{1/2}}_{:=\\alpha_{I}}\\cdot\\underbrace{\\big(\\operatorname*{min}(\\mathbb{E}_{u}g_{u,I}^{2})(\\theta)\\big)^{2}}_{:=\\beta\\in[q]},}\\end{array}\n$$", "text_format": "latex", "page_idx": 52}, {"type": "text", "text": "for every pair $I,J\\subseteq[d_{u}]$ with $|I|\\ge2$ and $|J|\\ge2$ ", "page_idx": 52}, {"type": "text", "text": "Using this inequality, (91) becomes ", "page_idx": 53}, {"type": "equation", "text": "$$\n\\bigl|(\\mathbb{E}_{u}f_{u}g_{u})(\\theta)-(\\mathbb{E}_{u}f_{u}g_{u})(\\theta^{\\prime})\\bigr|\\leq\\sum_{I,J\\subseteq[d_{u}]:|I|,|J|\\geq2}a_{I,J}\\alpha_{I}\\beta_{J}=\\vec{\\alpha}^{\\top}A\\vec{\\beta}\\leq\\|\\vec{\\alpha}\\|\\cdot\\|A\\|\\cdot\\|\\vec{\\beta}\\|\n$$", "text_format": "latex", "page_idx": 53}, {"type": "text", "text": "Where $\\vec{\\alpha}=(\\alpha_{I})_{I\\subseteq[d_{u}]:|I|\\geq2}$ $\\vec{\\beta}=(\\beta)_{I\\subseteq[d_{u}]:|I|\\geq2}$ and $A=(a_{I,J})_{I,J\\subseteq[d_{u}]:|I|,|J|\\geq2}$ Further, $\\|\\vec{\\alpha}\\|$ and $\\lVert\\vec{\\beta}\\rVert$ are the $\\ell_{2}$ norms of $\\vec{\\alpha}$ and $\\vec{\\beta}$ , respectively, and $\\|A\\|$ is the operator norm of $A$ ", "page_idx": 53}, {"type": "text", "text": "Estimate of operator norm of $A$ : Notice that $A$ is a symmetric matrix. Thus, we can fix a unit vector $\\vec{\\gamma}$ satisfying $\\overline{{{\\|A\\|=\\vec{\\gamma}^{\\top}A\\vec{\\gamma}}}}$ . For each pair $I,J\\subseteq[d_{u}]$ with $|I|\\ge2$ and $|J|\\ge2$ , since $a_{I,J}\\geq0$ ", "page_idx": 53}, {"type": "equation", "text": "$$\n\\gamma_{I}a_{I,J}\\gamma_{J}\\leq\\frac{a_{I,J}}{2}\\gamma_{I}^{2}+\\frac{a_{I,J}}{2}\\gamma_{J}^{2},\n$$", "text_format": "latex", "page_idx": 53}, {"type": "text", "text": "and thus, ", "page_idx": 53}, {"type": "equation", "text": "$$\n\\|A\\|=\\sum_{\\substack{I,J\\subseteq[d_{u}]\\,:|I|,|J|\\geq2}}a_{I,J}\\gamma_{I}\\gamma_{J}\\leq\\sum_{\\substack{I\\subseteq[d_{u}]\\,:|I|\\geq2}}\\gamma_{I}^{2}\\Big(\\sum_{\\substack{J\\subseteq[d_{u}]\\,:|J|\\geq2}}a_{I,J}\\Big).\n$$", "text_format": "latex", "page_idx": 53}, {"type": "text", "text": "For each $I\\subseteq[d_{u}]$ with $\\left|I\\right|\\geq2$ , the number of $J\\subseteq[d_{u}]$ with $\\vert I\\Delta J\\vert\\,=\\,k$ is bounded above by $d_{u}^{k-1}\\leq(R d)^{k}$ Then, with the given estimate of $\\boldsymbol{a}_{I,J}$ in (92), ", "page_idx": 53}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\lefteqn{\\sum_{J\\subseteq[d_{u}]:|J|\\geq2}a_{I,J}\\leq\\frac{1}{6}\\exp\\Big(-\\frac{\\varepsilon}{2}(\\mathrm{h}(u)-C_{1}(\\log(R)+1)-\\mathrm{h}^{\\circ})\\Big)}}\\\\ &{\\qquad\\qquad\\qquad\\qquad+\\sum_{t\\geq1}\\frac{1}{6}(R d)^{t}\\exp\\Big(-\\frac{\\varepsilon}{2}t(\\mathrm{h}(u)-C_{1}(\\log(R)+1)-\\mathrm{h}^{\\circ})\\Big).}\\end{array}\n$$", "text_format": "latex", "page_idx": 53}, {"type": "text", "text": "Now, we impose the second assumption on $C_{0}$ that ", "page_idx": 53}, {"type": "equation", "text": "$$\nC_{0}\\geq C_{1}+\\frac{2}{\\varepsilon}\\Big(1+\\log(2d)\\Big).\n$$", "text_format": "latex", "page_idx": 53}, {"type": "text", "text": "With the assumption that $\\mathrm{h}(u)\\geq\\mathrm{h}^{\\circ}+C_{0}(\\log(R)+1)$ , the geometric sum in (96) has a decay rate smaller than $1/2$ .Therefore, ", "page_idx": 53}, {"type": "equation", "text": "$$\n\\sum_{J\\subseteq[d_{u}]:|J|\\geq2}a_{I,J}\\leq\\frac{1}{2}\\exp\\Big(-\\frac{\\varepsilon}{2}(\\mathrm{h}(u)-C_{2}(\\log(R)+1)-\\mathrm{h}^{\\circ})\\Big),\n$$", "text_format": "latex", "page_idx": 53}, {"type": "text", "text": "where ", "page_idx": 53}, {"type": "equation", "text": "$$\nC_{2}=C_{1}+\\frac{2}{\\varepsilon}\\Big(1+\\log(d)\\Big).\n$$", "text_format": "latex", "page_idx": 53}, {"type": "text", "text": "Now applying the above estimate,together with $\\begin{array}{r}{\\sum_{I\\subseteq[d_{u}]:|I|\\geq2}\\gamma_{I}^{2}\\;=\\;1}\\end{array}$ , to (95), we obtain the following bound: ", "page_idx": 53}, {"type": "equation", "text": "$$\n\\|A\\|\\leq{\\frac{1}{2}}\\exp{\\Big(}-{\\frac{\\varepsilon}{2}}(\\mathrm{h}(u)-C_{1}(\\log(R)+1)-\\mathrm{h}^{\\circ}){\\Big)}.\n$$", "text_format": "latex", "page_idx": 53}, {"type": "text", "text": "Comparison of $\\begin{array}{r}{\\sum_{I}\\operatorname*{min}_{\\theta\\in[q]}(\\mathbb{E}_{u}f_{u,I}^{2})(\\theta)}\\end{array}$ and $\\operatorname*{min}_{\\theta\\in[q]}(\\mathbb{E}_{u}f_{u}^{2})(\\theta)$ (and the same for $g$ : Here is the last step toward the proof of the Proposition. Returning to (94), we have ", "page_idx": 53}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\quad\\big|(\\mathbb{E}_{u}f_{u}g_{u})(\\theta)-(\\mathbb{E}_{u}f_{u}g_{u})(\\theta^{\\prime})\\big|}\\\\ &{\\le\\displaystyle\\frac{1}{2}\\exp\\Big(-\\frac{\\varepsilon}{2}(\\mathrm{h}(u)-C_{1}(\\log(R)+1)-\\mathrm{h}^{\\circ})\\Big)\\cdot\\sqrt{\\sum_{I}\\operatorname*{min}_{\\theta\\in[q]}(\\mathbb{E}_{u}f_{u,I}^{2})(\\theta)}\\cdot\\sqrt{\\sum_{I}\\operatorname*{min}_{\\theta\\in[q]}(\\mathbb{E}_{u}g_{u,I}^{2})(\\theta)}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 53}, {"type": "text", "text": "Let us impose the third assumption on $C_{0}$ that ", "page_idx": 53}, {"type": "equation", "text": "$$\nC_{0}\\geq C_{E.7}+\\frac{2}{\\varepsilon}\\log(2)\n$$", "text_format": "latex", "page_idx": 53}, {"type": "text", "text": "where $C_{E.7}$ introduced in Corollary E.7. Recall that we have $\\mathrm{h}^{\\ast}=\\mathrm{h}^{\\circ}+\\frac{2}{\\varepsilon}\\log(2)$ from (87). We can invoke this Corollary to yield: ", "page_idx": 54}, {"type": "equation", "text": "$$\n\\forall\\theta\\in[q],\\,\\sqrt{\\sum_{I}(\\mathbb{E}_{u}f_{u,I}^{2})(\\theta)}\\leq\\sqrt{2\\mathbb{E}f_{u}^{2}(\\theta)}.\n$$", "text_format": "latex", "page_idx": 54}, {"type": "text", "text": "Let $\\theta_{0}\\in[q]$ be the value minimizing $\\theta\\mapsto\\sqrt{\\mathbb{E}f_{u}^{2}(\\theta)}$ . Then, ", "page_idx": 54}, {"type": "equation", "text": "$$\n\\operatorname*{min}_{\\theta\\in[q]}\\sqrt{2\\mathbb{E}f_{u}^{2}(\\theta)}=\\sqrt{2\\mathbb{E}f_{u}^{2}(\\theta_{0})}\\ge\\sqrt{\\sum_{I}(\\mathbb{E}_{u}f_{u,I}^{2})(\\theta_{0})}\\ge\\sqrt{\\sum_{I}\\operatorname*{min}_{\\theta\\in[q]}(\\mathbb{E}_{u}f_{u,I}^{2})(\\theta)}.\n$$", "text_format": "latex", "page_idx": 54}, {"type": "text", "text": "Clearly, the same derivation also holds for $g_{u}$ . Together we conclude that ", "page_idx": 54}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\quad\\big|(\\mathbb{E}_{u}f_{u}g_{u})(\\theta)-(\\mathbb{E}_{u}f_{u}g_{u})(\\theta^{\\prime})\\big|}\\\\ &{\\leq\\exp\\Big(-\\frac{\\varepsilon}{2}(\\mathrm{h}(u)-C_{2}(\\log(R)+1)-\\mathrm{h}^{\\circ})\\Big)\\big(\\underset{\\theta\\in[q]}{\\operatorname*{min}}(\\mathbb{E}_{u}f_{u}^{2})(\\theta)\\big)^{1/2}\\big(\\underset{\\theta\\in[q]}{\\operatorname*{min}}(\\mathbb{E}_{u}g_{u}^{2})(\\theta)\\big)^{1/2}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 54}, {"type": "text", "text": "Finally, if we impose the forth assumption on $C_{0}$ that ", "page_idx": 54}, {"type": "equation", "text": "$$\nC_{0}\\geq C_{2},\n$$", "text_format": "latex", "page_idx": 54}, {"type": "text", "text": "then the Proposition follows. ", "page_idx": 54}, {"type": "text", "text": "H.2  Properties of $f_{k}$ : Products ", "text_level": 1, "page_idx": 54}, {"type": "text", "text": "The goal of this subsection is to establish the following. ", "page_idx": 54}, {"type": "text", "text": "Proposition H.6. There exists $C\\,=\\,C(M,d)\\,\\geq\\,1$ so that the following holds. For any $\\rho^{\\prime}\\,\\in\\,T$ satisfying ", "page_idx": 54}, {"type": "equation", "text": "$$\n\\mathrm{h}(\\rho^{\\prime})\\geq\\mathrm{h}^{\\circ}+C(\\log(R)+1)\n$$", "text_format": "latex", "page_idx": 54}, {"type": "text", "text": "and a positive integer $\\mathrm{h}^{\\circ}+C(\\log(R)+1)\\leq k_{1}\\leq\\mathrm{h}(\\rho^{\\prime})$ Consider a function $f$ and $g$ are $B_{\\le\\rho^{\\prime}}$ polynomialswith $\\mathbb{E}f(X)=\\mathbb{E}g(X)=0$ .We decompose $f$ and $g$ according to Lemma $D.I$ with the given $k_{1}$ . Then, the following holds: For $k_{1}\\leq m,k\\leq\\mathrm{h}(\\rho^{\\prime}),$ ", "page_idx": 54}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\colon I f\\operatorname*{max}\\{m,k\\}>k_{1},}\\\\ &{\\quad\\operatorname*{max}_{\\theta,\\theta^{\\prime}\\in[q]}\\big|(\\mathbb{E}_{\\rho^{\\prime}}f_{k}g_{m})(\\theta)-(\\mathbb{E}_{\\rho^{\\prime}}f_{k}g_{m})(\\theta^{\\prime})\\big|}\\\\ &{\\le\\exp\\Big(-\\frac{\\varepsilon}{2}(2\\mathrm{h}(\\rho^{\\prime})-\\operatorname*{max}\\{k,m\\}-C(\\log(R)+1)-\\mathrm{h}^{\\circ})\\Big)(\\mathbb{E}f_{k}^{2}(X))^{1/2}(\\mathbb{E}g_{m}^{2}(X))^{1/2}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 54}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\underset{\\theta,\\theta^{\\prime}\\in[q]}{\\operatorname*{max}}\\big|(\\mathbb{E}_{\\rho^{\\prime}}f_{k}g_{m})(\\theta)-(\\mathbb{E}_{\\rho^{\\prime}}f_{k}g_{m})(\\theta^{\\prime})\\big|}\\\\ &{\\qquad\\leq\\exp\\Big(-\\frac{\\varepsilon}{2}(2\\mathrm{h}(\\rho^{\\prime})-2k_{1}-C(\\log(R)+1))\\Big)(\\mathbb{E}f_{k}^{2}(X))^{1/2}(\\mathbb{E}g_{m}^{2}(X))^{1/2}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 54}, {"type": "text", "text": "The proof mirrors the structure used in Proposition F.1. In this case, we rely on both Proposition E.1 and Proposition H.2. Through this subsection, let ", "page_idx": 54}, {"type": "equation", "text": "$$\nC^{\\circ}=C^{\\circ}(M,d)\n$$", "text_format": "latex", "page_idx": 54}, {"type": "text", "text": "be the constant described in the Proposition. The functions $f,\\,g$ ,and $k_{1}$ are as introduced in the Proposition. ", "page_idx": 54}, {"type": "text", "text": "Assuming without lose of generality that $m\\leq k$ , we apply the reasoning from (72) in Proposition F.1, yielding ", "page_idx": 55}, {"type": "equation", "text": "$$\n\\begin{array}{l}{\\displaystyle\\bigl(\\mathbb{E}_{\\rho^{\\prime}}f_{k}g_{m}\\bigr)(\\theta)}\\\\ {\\displaystyle=\\mathbb{E}\\biggl[\\biggl(\\sum_{u\\in D_{k}(\\rho^{\\prime})}^{}(\\mathbb{E}_{u}\\tilde{f}_{u})(X)\\biggr)\\biggl(\\sum_{u\\in D_{k}(\\rho^{\\prime})}(\\mathbb{E}_{u}g_{m,u})(X)\\biggr)\\biggr|\\;X_{\\rho^{\\prime}}=\\theta\\biggr]+\\sum_{u\\in D_{k}(\\rho^{\\prime})}(\\mathbb{E}_{\\rho^{\\prime}}\\tilde{f}_{u}g_{m,u})(\\theta)}\\\\ {\\displaystyle\\quad-\\sum_{u\\in D_{k}(\\rho^{\\prime})}\\mathbb{E}\\biggl[(\\mathbb{E}_{u}\\tilde{f}_{u})(X_{u})(\\mathbb{E}_{u}g_{m,u})(X_{u})\\biggr|\\;X_{\\rho^{\\prime}}=\\theta\\biggr],}\\end{array}\n$$", "text_format": "latex", "page_idx": 55}, {"type": "text", "text": "and hence, ", "page_idx": 55}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\quad(\\mathbb{E}_{\\rho^{\\prime}}f_{k}g_{m})(\\theta)-(\\mathbb{E}_{\\rho^{\\prime}}f_{k}g_{m})(\\theta^{\\prime})}\\\\ &{=\\bigl(\\mathbb{E}_{\\rho^{\\prime}}(\\mathbb{E}_{k}f_{k})(\\mathbb{E}_{k}g_{m})\\bigr)(\\theta)-\\bigl(\\mathbb{E}_{\\rho^{\\prime}}(\\mathbb{E}_{k}f_{k})(\\mathbb{E}_{k}g_{m})\\bigr)(\\theta^{\\prime})}\\\\ &{\\quad+\\displaystyle\\sum_{u\\in D_{k}(\\rho^{\\prime})}\\big((\\mathbb{E}_{\\rho^{\\prime}}\\tilde{f}_{u}g_{m,u})(\\theta)-(\\mathbb{E}_{\\rho^{\\prime}}\\tilde{f}_{u}g_{m,u})(\\theta^{\\prime})\\big)}\\\\ &{\\quad-\\Big(\\displaystyle\\sum_{u\\in D_{k}(\\rho^{\\prime})}\\big((\\mathbb{E}_{\\rho^{\\prime}}\\big(\\mathbb{E}_{u}\\tilde{f}_{u})(\\mathbb{E}_{u}g_{m,u})\\big)(\\theta)-\\big((\\mathbb{E}_{\\rho^{\\prime}}\\big(\\mathbb{E}_{u}\\tilde{f}_{u})(\\mathbb{E}_{u}g_{m,u})\\big)(\\theta^{\\prime})\\Big).}\\end{array}\n$$", "text_format": "latex", "page_idx": 55}, {"type": "text", "text": "Similar to the derivation of (64) from Proposition F.1. The proof is dedicated into estimating the above three summands. ", "page_idx": 55}, {"type": "text", "text": "We begin with the following estimate: ", "page_idx": 55}, {"type": "text", "text": "Lemma H.7. There exists a constant $C=C(M,d)$ so that the following holds. Suppose $C^{\\circ}\\ge C_{H.2}$ where $C_{H,2}$ is the constant introduced in Proposition $H.2$ Then, the following holds: For $u\\in D_{k}(\\rho^{\\prime})$ \uff0c ", "page_idx": 55}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\underset{\\theta,\\theta^{\\prime}\\in[q]}{\\operatorname*{max}}\\left|(\\mathbb{E}_{\\rho^{\\prime}}\\tilde{f}_{u}g_{m,u})(\\theta)-\\mathbb{E}_{\\rho^{\\prime}}\\tilde{f}_{u}g_{m,u})(\\theta^{\\prime})\\right|}\\\\ &{\\le\\exp\\Big(-\\frac{\\varepsilon}{2}(2\\mathrm{h}(\\rho^{\\prime})-k-C(\\log(R)+1)-\\mathrm{h}^{\\circ})\\Big)(\\mathbb{E}\\tilde{f}_{u}^{2}(X))^{1/2}(\\mathbb{E}g_{m,u}^{2}(X))^{1/2};}\\end{array}\n$$", "text_format": "latex", "page_idx": 55}, {"type": "text", "text": "2.i $f k=m=k_{1}$ ,then ", "page_idx": 55}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\underset{\\theta,\\theta^{\\prime}\\in[q]}{\\mathrm{max}}\\left\\vert(\\mathbb{E}_{\\rho^{\\prime}}\\tilde{f}_{u}g_{m,u})(\\theta)-\\mathbb{E}_{\\rho^{\\prime}}\\tilde{f}_{u}g_{m,u})(\\theta^{\\prime})\\right\\vert}\\\\ &{\\leq\\exp\\Big(-\\frac{\\varepsilon}{2}(2\\mathrm{h}(\\rho^{\\prime})-2k-C)\\Big)(\\mathbb{E}\\tilde{f}_{u}^{2}(X))^{1/2}(\\mathbb{E}g_{m,u}^{2}(X))^{1/2}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 55}, {"type": "text", "text": "Proof. Step 1. Bound $\\mathbb{E}|\\tilde{f}_{u}(X)g_{m,u}(X)-\\mathbb{E}\\tilde{f}_{u}g_{m,u}|$ from above: By Holder's inequality. ", "page_idx": 55}, {"type": "equation", "text": "$$\n\\begin{array}{r l r}{\\lefteqn{\\underbrace{\\mathrm{Var}\\big[(\\mathbb{E}_{u}\\tilde{f}_{u}g_{m,u})(X_{u})\\big]}_{\\ell_{2}-\\mathrm{norm}}\\leq\\underbrace{\\mathrm{max}\\,\\big|(\\mathbb{E}_{u}\\tilde{f}_{u}g_{m,u})(\\theta)-\\mathbb{E}\\tilde{f}_{u}g_{m,u}\\big|}_{\\ell_{\\infty}-\\mathrm{norm}}\\cdot\\underbrace{\\mathbb{E}\\big|(\\mathbb{E}_{u}\\tilde{f}_{u}g_{m,u})(X_{u})-\\mathbb{E}\\tilde{f}_{u}g_{m,u}\\big|}_{\\ell_{1}-\\mathrm{norm}}}\\\\ &{}&{\\qquad\\qquad\\le\\sqrt{C_{A,5}\\mathrm{Var}\\big[(\\mathbb{E}_{u}\\tilde{f}_{u}g_{m,u})(X_{u})\\big]}\\cdot\\mathbb{E}|\\tilde{f}_{u}(X)g_{m,u}(X)-\\mathbb{E}\\tilde{f}_{u}g_{m,u}|}\\\\ &{\\Leftrightarrow}&{\\sqrt{\\mathrm{Var}\\big[(\\mathbb{E}_{u}\\tilde{f}_{u}g_{m,u})(X_{u})\\big]}\\leq\\!\\sqrt{C_{A,5}}\\mathbb{E}|\\tilde{f}_{u}(X)g_{m,u}(X)-\\mathbb{E}\\tilde{f}_{u}g_{m,u}|,~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~(98)}\\end{array}\n$$", "text_format": "latex", "page_idx": 55}, {"type": "text", "text": "where we applied (9) from Lemma A.5 with $C_{A.5}$ is the constant introduced in the Lemma. Further, relying on (98), together with (9) and (8) from the Lemma A.5, we have ", "page_idx": 55}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\underset{\\theta,\\theta^{\\prime}\\in[q]}{\\operatorname*{max}}\\left|(\\mathbb{E}_{\\rho^{\\prime}}\\tilde{f}_{u}g_{m,u})(\\theta)-\\mathbb{E}_{\\rho^{\\prime}}\\tilde{f}_{u}g_{m,u})(\\theta^{\\prime})\\right|}\\\\ &{\\le\\!2\\underset{\\theta\\in[q]}{\\operatorname*{max}}\\left|(\\mathbb{E}_{\\rho^{\\prime}}\\tilde{f}_{u}g_{m,u})(\\theta)-\\mathbb{E}\\tilde{f}_{u}g_{m,u}\\right|}\\\\ &{\\le\\!2C_{A.5}(\\mathrm{h}(\\rho^{\\prime})-k)^{q}\\lambda^{\\mathrm{h}(\\rho^{\\prime})-k}\\underset{\\theta\\in[q]}{\\operatorname*{max}}\\big|(\\mathbb{E}_{u}\\tilde{f}_{u}g_{m,u})(\\theta)-\\mathbb{E}\\tilde{f}_{u}g_{m,u}\\big|}\\\\ &{\\le\\!2C_{A.5}^{2}(\\mathrm{h}(\\rho^{\\prime})-k)^{q}\\lambda^{\\mathrm{h}(\\rho^{\\prime})-k}\\sqrt{C_{A.5}}\\mathbb{E}|\\tilde{f}_{u}(X)g_{m,u}(X)-\\mathbb{E}\\tilde{f}_{u}g_{m,u}|}\\\\ &{=\\!C_{1}\\exp(-\\varepsilon(\\mathrm{h}(\\rho^{\\prime})-k))\\mathbb{E}|\\tilde{f}_{u}(X)g_{m,u}(X)-\\mathbb{E}\\tilde{f}_{u}g_{m,u}|,}\\end{array}\n$$", "text_format": "latex", "page_idx": 55}, {"type": "text", "text": "where ", "page_idx": 56}, {"type": "equation", "text": "$$\nC_{1}=2C_{A.5}^{5/2}\\cdot\\operatorname*{max}_{n\\in\\mathbb{N}}n^{q}\\exp(-0.1\\varepsilon n).\n$$", "text_format": "latex", "page_idx": 56}, {"type": "text", "text": "Case 1: $m<k$ Here we can simply recycle the estimate from (76): ", "page_idx": 56}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathfrak{L}|\\tilde{f}_{u}(X)g_{m,u}(X)-\\mathbb{E}\\tilde{f}_{u}g_{m,u}|\\leq2\\mathbb{E}|\\tilde{f}_{u}(X)g_{m,u}(X)|}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\leq\\exp\\Big(-\\frac{\\varepsilon}{2}\\big(k-C_{2}(\\log(R)+1)-\\mathbf{h}^{\\circ}\\big)\\Big)(\\mathbb{E}\\tilde{f}_{u}^{2}(X))^{1/2}(\\mathbb{E}g_{m,u}^{2}(X))^{1}}\\end{array}\n$$", "text_format": "latex", "page_idx": 56}, {"type": "text", "text": "where ", "page_idx": 56}, {"type": "equation", "text": "$$\nC_{2}=\\frac{2}{\\varepsilon}\\Big(\\frac{3}{2}+\\frac{1}{2}\\log(d)+\\log(C_{D.1})\\Big)+C_{E.1}+2\\cdot\\frac{2}{\\varepsilon}\\log(2),\n$$", "text_format": "latex", "page_idx": 56}, {"type": "text", "text": "where $C_{D,1}$ is the constant introduced in Lemma D.1 and $C_{E,1}$ is the constant introduced in Proposition E.1. ", "page_idx": 56}, {"type": "equation", "text": "$$\n\\operatorname{Case}2\\colon k_{1}<m=k.\n$$", "text_format": "latex", "page_idx": 56}, {"type": "text", "text": "This is the case where we need Proposition H.2. With the assumption that $C^{\\circ}\\,\\ge\\,C_{H.2}$ ,where $C_{H.2}\\geq1$ is the constant introduced in the Proposition, we have ", "page_idx": 56}, {"type": "equation", "text": "$$\nm=k>k_{1}\\geq\\mathrm{h}^{\\circ}+C^{\\circ}(\\log(R)+1)\\geq\\mathrm{h}^{\\circ}+C_{H,2}(\\log(R)+1),\n$$", "text_format": "latex", "page_idx": 56}, {"type": "text", "text": "so that we could apply the Proposition to get ", "page_idx": 56}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\quad\\mathbb{E}|\\tilde{f}_{u}(X)g_{m,u}(X)-\\mathbb{E}\\tilde{f}_{u}g_{m,u}|}\\\\ &{\\leq\\underset{\\theta,\\theta^{\\prime}}{\\operatorname*{max}}\\left|(\\mathbb{E}_{u}f_{u}g_{u})(\\theta)-(\\mathbb{E}_{u}f_{u}g_{u})(\\theta^{\\prime})\\right|}\\\\ &{\\leq\\exp\\Big(-\\frac{\\varepsilon}{2}(k-C_{H.2}(\\log(R)+1)-\\ h^{\\circ})\\Big)(\\mathbb{E}\\tilde{f}_{u}^{2}(X))^{1/2}(\\mathbb{E}g_{m,u}^{2}(X))^{1/2}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 56}, {"type": "text", "text": "Case 3 $:k_{1}=m=k$ The last case is straightforward: ", "page_idx": 56}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathbb{E}|\\tilde{f}_{u}(X)g_{m,u}(X)-\\mathbb{E}\\tilde{f}_{u}g_{m,u}|\\leq2\\mathbb{E}|\\tilde{f}_{u}(X)g_{m,u}(X)|\\leq2\\sqrt{\\mathbb{E}\\tilde{f}_{u}^{2}(X)}\\sqrt{\\mathbb{E}g_{m,u}^{2}(X)}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 56}, {"type": "text", "text": "By taking $C_{3}=\\operatorname*{max}\\{C_{2},C_{H.2}\\}\\!+\\!\\frac{2}{\\varepsilon}\\log(C_{1})$ , the statement of the Lemma follows with $C=C_{3}$ .\u53e3 ", "page_idx": 56}, {"type": "text", "text": "As an analogue of the above Lemma, we also have ", "page_idx": 56}, {"type": "text", "text": "Lemma H.8. There exists a constant $C=C(M,d)$ so that the following holds. Suppose $C^{\\circ}\\ge C_{H.2}$ is the constant introduced in Proposition $H.2$ Then, the following holds: For $u\\in D_{k}(\\rho^{\\prime})$ \uff0c ", "page_idx": 56}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\underset{\\theta,\\theta^{\\prime}\\in[q]}{\\operatorname*{max}}\\big|\\big(\\mathbb{E}_{\\rho^{\\prime}}\\big(\\mathbb{E}_{u}\\tilde{f}_{u}\\big)(\\mathbb{E}_{u}g_{m,u})\\big)(\\theta)-\\big((\\mathbb{E}_{\\rho^{\\prime}}\\big(\\mathbb{E}_{u}\\tilde{f}_{u}\\big)(\\mathbb{E}_{u}g_{m,u})\\big)(\\theta^{\\prime})\\big|}\\\\ &{\\leq\\exp\\Big(-\\frac{\\varepsilon}{2}(2\\mathrm{h}(\\rho^{\\prime})-k-C(\\log(R)+1)-\\mathrm{h}^{\\circ})\\Big)(\\mathbb{E}\\tilde{f}_{u}^{2}(X))^{1/2}(\\mathbb{E}g_{m,u}^{2}(X))^{1/2}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 56}, {"type": "text", "text": "2. $i f k=m=k_{1}$ ,then ", "page_idx": 56}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\quad\\big|\\big(\\mathbb{E}_{\\rho^{\\prime}}\\big(\\mathbb{E}_{u}\\tilde{f}_{u}\\big)\\big(\\mathbb{E}_{u}g_{m,u}\\big)\\big)(\\theta)-\\big(\\big(\\mathbb{E}_{\\rho^{\\prime}}\\big(\\mathbb{E}_{u}\\tilde{f}_{u}\\big)\\big(\\mathbb{E}_{u}g_{m,u}\\big)\\big)(\\theta^{\\prime})\\big|}\\\\ &{\\le\\exp\\Big(-\\frac{\\varepsilon}{2}(2\\mathrm{h}(\\rho^{\\prime})-2k-C)\\Big)(\\mathbb{E}\\tilde{f}_{u}^{2}(X))^{1/2}(\\mathbb{E}g_{m,u}^{2}(X))^{1/2}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 56}, {"type": "text", "text": "Since the proof is simpler and the structure is the same as that for Lemma H.7, we will outline a sketch proof in this case. ", "page_idx": 56}, {"type": "text", "text": "Proof. Let $a_{u}(x_{u})=(\\mathbb{E}_{u}\\tilde{f}_{u})(x_{u})$ and $b_{u}=(\\mathbb{E}_{u}g_{m,u})(x_{u})$ Repeating the first step of the proof of Lemma H.7, we have ", "page_idx": 57}, {"type": "equation", "text": "$$\n\\operatorname*{max}_{\\theta,\\theta^{\\prime}\\in[q]}\\big|\\big(\\mathbb{E}_{\\rho^{\\prime}}a_{u}b_{u}\\big)(\\theta)-\\mathbb{E}_{\\rho^{\\prime}}a_{u}b_{u}\\big)(\\theta^{\\prime})\\big|\\leq\\!C_{1}\\exp(-\\varepsilon(\\mathrm{h}(\\rho^{\\prime})-k))\\mathbb{E}\\!\\big|a_{u}(X)b_{u}(X)-\\mathbb{E}a_{u}b_{u}\\big|,\n$$", "text_format": "latex", "page_idx": 57}, {"type": "text", "text": "with ", "page_idx": 57}, {"type": "equation", "text": "$$\nC_{1}:=2C_{A.5}^{5/2}\\cdot\\operatorname*{max}_{n\\in\\mathbb{N}}n^{q}\\exp(-0.1\\varepsilon n),\n$$", "text_format": "latex", "page_idx": 57}, {"type": "text", "text": "which is exactly the same constant stated in Lemma H.7. Next, ", "page_idx": 57}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\sharp|a_{u}(X)b_{u}(X)-{\\mathbb{E}}a_{u}b_{u}|\\leq2{\\mathbb{E}}|a_{u}(X)b_{u}(X)|\\leq2\\sqrt{{\\mathbb{E}}a_{u}^{2}(X)}\\sqrt{{\\mathbb{E}}b_{u}^{2}(X)}\\leq2\\sqrt{{\\mathbb{E}}a_{u}^{2}(X)}\\sqrt{{\\mathbb{E}}g_{m,u}^{2}(X)}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 57}, {"type": "text", "text": "If $k>k_{1}$ , we could apply (38) from Proposition E.1 to $\\tilde{f}_{u}$ , and get ", "page_idx": 57}, {"type": "equation", "text": "$$\n\\sqrt{\\mathbb{E}a_{u}^{2}(X)}\\leq\\exp\\Big(-2\\varepsilon(k-C_{E.1}(\\log(R)+1)\\underbrace{-\\mathrm{h}^{\\circ}-\\frac{2}{\\varepsilon}\\log(2))}_{-\\mathrm{h}^{*}}\\Big)\\sqrt{\\mathbb{E}\\tilde{f}_{u}^{2}(X)}.\n$$", "text_format": "latex", "page_idx": 57}, {"type": "text", "text": "Indeed, this tail bound is stronger than what we got from Lemma H.7. The remainning part involves combining these estimates with a suitable constant $C$ so that the lemma holds. Given the argument was already presented in the proof of Lemma H.7, we will omit these details. \u53e3 ", "page_idx": 57}, {"type": "text", "text": "Before bounding the summands in (97), let us bound $\\begin{array}{r}{\\sum_{u\\in D_{k}(\\rho^{\\prime})}\\mathbb{E}\\tilde{f}_{u}^{2}(X)}\\end{array}$ and $\\textstyle\\sum_{u\\in D_{k}(\\rho^{\\prime})}\\mathbb{E}g_{m,u}^{2}(X)$ from above by $\\mathbb{E}f_{k}^{2}(X)$ and $\\mathbb{E}g_{m}^{2}(X)$ ,respectively. ", "page_idx": 57}, {"type": "text", "text": "Lemma H.9. Suppose ", "text_level": 1, "page_idx": 57}, {"type": "equation", "text": "$$\nC^{\\circ}\\ge C_{F.2}+\\frac{2}{\\varepsilon}\\log(2),\n$$", "text_format": "latex", "page_idx": 57}, {"type": "text", "text": "where $C_{F,2}$ is theconstant introduced in Lemma $F.2$ .Then, ", "page_idx": 57}, {"type": "equation", "text": "$$\n\\sum_{u\\in D_{k}(\\rho^{\\prime})}\\mathbb{E}g_{m,u}^{2}(X)\\leq\\operatorname*{max}\\left\\{4,C_{D.1}^{2}R^{4}\\right\\}\\cdot\\mathbb{E}g_{m}^{2}(X),\n$$", "text_format": "latex", "page_idx": 57}, {"type": "text", "text": "and ", "page_idx": 57}, {"type": "equation", "text": "$$\n\\sum_{u\\in D_{k}(\\rho^{\\prime})}\\mathbb{E}\\tilde{f}_{u}^{2}(X)\\le\\operatorname*{max}\\left\\{4,C_{D.1}^{2}R^{4}\\right\\}\\cdot\\mathbb{E}f_{k}^{2}(X).\n$$", "text_format": "latex", "page_idx": 57}, {"type": "text", "text": "Proof. Given that $C^{\\circ}\\ge C_{F.2}+\\textstyle{\\frac{2}{\\varepsilon}}\\log(2)$ , we have ", "page_idx": 57}, {"type": "equation", "text": "$$\nk_{1}\\geq\\mathrm{h}^{\\circ}+C^{\\circ}(\\log(R)+1)>\\mathrm{h}^{\\circ}+{\\frac{2}{\\varepsilon}}\\log(2)+C_{F.2}(\\log(R)+1)=\\mathrm{h}^{*}+C_{F.2}(\\log(R)+1),\n$$", "text_format": "latex", "page_idx": 57}, {"type": "text", "text": "and thus we could apply Lemma F.2. When $m>k_{1}$ , the lemma yields ", "page_idx": 57}, {"type": "equation", "text": "$$\n\\sum_{\\substack{\\leqslant D_{k}(\\rho^{\\prime})}}\\mathbb{E}g_{m,u}^{2}(X)=\\sum_{u\\in D_{k}(\\rho^{\\prime})}\\mathbb{E}\\Big[\\Big(\\sum_{v\\in D_{m}(u)}\\tilde{g}_{v}(X)\\Big)^{2}\\Big]\\leq\\sum_{u\\in D_{k}(\\rho^{\\prime})}\\sum_{v\\in D_{m}(u)}2\\mathbb{E}\\tilde{g}_{v}^{2}(X)\\leq4\\mathbb{E}g_{m}^{2}(X).\n$$", "text_format": "latex", "page_idx": 57}, {"type": "text", "text": "And in the case when $m=k_{1}$ , we use the same derivation with Lemma F.2 been replaced by (31) in Lemma D.1 to get ", "page_idx": 57}, {"type": "equation", "text": "$$\n\\sum_{u\\in D_{k}(\\rho^{\\prime})}\\mathbb{E}g_{m,u}^{2}(X)\\leq C_{D.1}R^{3}\\cdot C_{D.1}R\\mathbb{E}g_{m}^{2}(X).\n$$", "text_format": "latex", "page_idx": 57}, {"type": "text", "text": "Clearly,the same derivation alsoholds for the comparison of $\\sum_{u\\in D_{k}(\\rho^{\\prime})}\\mathbb{E}\\tilde{f}_{u}^{2}(X)$ and $\\mathbb{E}f_{k}^{2}(X)$ ", "page_idx": 57}, {"type": "text", "text": "Now, relying on the above two lemmas, we will estimate the second and third summand of (97): ", "page_idx": 57}, {"type": "text", "text": "Corollary H.10. There exists a constant $C=C(M,d)\\geq1$ so that the following holds. Suppose ", "page_idx": 57}, {"type": "equation", "text": "$$\nC^{\\circ}\\ge\\operatorname*{max}\\Big\\{C_{H.2},C_{F.2}+\\frac{2}{\\varepsilon}\\log(2)\\Big\\},\n$$", "text_format": "latex", "page_idx": 57}, {"type": "text", "text": "where the constants are introduced in Proposition $H.2$ andLemma $F.2$ ,respectively. Then, ", "page_idx": 57}, {"type": "text", "text": "1. $i f k>k_{1}$ ,then ", "page_idx": 58}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\quad\\displaystyle\\prod_{u\\in D_{k}(\\rho^{\\prime})}\\big((\\mathbb{E}_{\\rho^{\\prime}}\\tilde{f}_{u}g_{m,u})(\\theta)-(\\mathbb{E}_{\\rho^{\\prime}}\\tilde{f}_{u}g_{m,u})(\\theta^{\\prime})\\big)}\\\\ &{\\quad-\\Big(\\displaystyle\\sum_{u\\in D_{k}(\\rho^{\\prime})}\\big((\\mathbb{E}_{\\rho^{\\prime}}\\big(\\mathbb{E}_{u}\\tilde{f}_{u})(\\mathbb{E}_{u}g_{m,u})\\big)(\\theta)-\\big((\\mathbb{E}_{\\rho^{\\prime}}\\big(\\mathbb{E}_{u}\\tilde{f}_{u})(\\mathbb{E}_{u}g_{m,u})\\big)(\\theta^{\\prime})\\big)\\Big)\\Big|}\\\\ &{\\le\\exp\\Big(-\\displaystyle\\frac{\\varepsilon}{2}(2\\mathrm{h}(\\rho^{\\prime})-k-C(\\log(R)+1)-\\mathrm{h}^{\\circ})\\Big)(\\mathbb{E}f_{k}^{2}(X))^{1/2}(\\mathbb{E}g_{m}^{2}(X))^{1/2}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 58}, {"type": "text", "text": "2. $i f k=m=k_{1}$ then the above term abovecan bebounded by ", "page_idx": 58}, {"type": "equation", "text": "$$\n\\exp\\Big(-\\frac{\\varepsilon}{2}(2\\mathrm{h}(\\rho^{\\prime})-2k-C)\\Big)(\\mathbb{E}f_{k}^{2}(X))^{1/2}(\\mathbb{E}g_{m}^{2}(X))^{1/2}.\n$$", "text_format": "latex", "page_idx": 58}, {"type": "text", "text": "Proof.Let $C_{1}$ be the maximum of the two constants introduced in Lemma H.7 and Lemma H.8. For convenience,let ", "page_idx": 58}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{U:=\\biggr|\\sum_{u\\in D_{k}(\\rho^{\\prime})}\\left((\\mathbb{E}_{\\rho^{\\prime}}\\tilde{f}_{u}g_{m,u})(\\theta)-(\\mathbb{E}_{\\rho^{\\prime}}\\tilde{f}_{u}g_{m,u})(\\theta^{\\prime})\\right)}\\\\ &{\\qquad-\\left(\\underset{u\\in D_{k}(\\rho^{\\prime})}{\\sum}\\left((\\mathbb{E}_{\\rho^{\\prime}}(\\mathbb{E}_{u}\\tilde{f}_{u})(\\mathbb{E}_{u}g_{m,u})\\right)(\\theta)-\\left((\\mathbb{E}_{\\rho^{\\prime}}(\\mathbb{E}_{u}\\tilde{f}_{u})(\\mathbb{E}_{u}g_{m,u})\\right)(\\theta^{\\prime})\\right)\\biggr|.}\\end{array}\n$$", "text_format": "latex", "page_idx": 58}, {"type": "text", "text": "By the two lemmas together with the triangle inequality, in the case when $k>k_{1}$ ,wehave ", "page_idx": 58}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{7\\le\\displaystyle\\sum_{u\\in D_{k}(\\rho^{\\prime})}2\\exp\\Big(-\\frac{\\varepsilon}{2}(2\\mathrm{h}(\\rho^{\\prime})-k-C_{1}(\\log(R)+1)-\\mathrm{h}^{\\circ})\\Big)(\\mathbb{E}\\tilde{f}_{u}^{2}(X))^{1/2}(\\mathbb{E}g_{m,u}^{2}(X))^{1/2}}\\\\ &{\\le2\\exp\\Big(-\\frac{\\varepsilon}{2}(2\\mathrm{h}(\\rho^{\\prime})-k-C_{1}(\\log(R)+1)-\\mathrm{h}^{\\circ})\\Big)\\sqrt{\\displaystyle\\sum_{u\\in D_{k}(\\rho^{\\prime})}\\mathbb{E}\\tilde{f}_{u}^{2}(X)}\\sqrt{\\displaystyle\\sum_{u\\in D_{k}(\\rho^{\\prime})}\\mathbb{E}g_{m,u}^{2}(X)}}\\\\ &{\\le2\\operatorname*{max}\\Big\\{4,C_{D,1}^{2}R^{4}\\Big\\}\\sqrt{\\mathbb{E}f_{k}^{2}(X)}\\sqrt{\\mathbb{E}g_{m}^{2}(X)},}\\end{array}\n$$", "text_format": "latex", "page_idx": 58}, {"type": "text", "text": "where the last inequality follows from Lemma H.9. Similarly, when $k=m=k_{1}$ ,wehave ", "page_idx": 58}, {"type": "equation", "text": "$$\nU\\leq2\\exp\\Big(-\\frac{\\varepsilon}{2}(2\\mathrm{h}(\\rho^{\\prime})-2k-C_{1})\\Big)\\sqrt{\\sum_{u\\in D_{k}(\\rho^{\\prime})}\\mathbb{E}\\tilde{f}_{u}^{2}(X)}\\sqrt{\\sum_{u\\in D_{k}(\\rho^{\\prime})}\\mathbb{E}g_{m,u}^{2}(X)}.\n$$", "text_format": "latex", "page_idx": 58}, {"type": "text", "text": "By setting ", "page_idx": 58}, {"type": "equation", "text": "$$\nC=\\frac{2}{\\varepsilon}\\left(C_{1}+\\log(4)+\\log(C_{D.1}^{2})\\right),\n$$", "text_format": "latex", "page_idx": 58}, {"type": "text", "text": "the corollary follows. ", "page_idx": 58}, {"type": "text", "text": "It remains to estimate the first summand of (97): ", "page_idx": 58}, {"type": "text", "text": "Lemma H.11. There exists a constant $C=C(M,d)\\geq1$ so that the following holds. Suppose ", "page_idx": 58}, {"type": "equation", "text": "$$\nC^{\\circ}\\ge C_{F.2}+\\frac{2}{\\varepsilon}\\log(2)\n$$", "text_format": "latex", "page_idx": 58}, {"type": "text", "text": "where $C_{F,2}$ is the constant introduced in Lemma $F.2$ Then, ", "page_idx": 58}, {"type": "text", "text": "1.f $k>k_{1}$ ,then ", "page_idx": 58}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\underset{\\theta,\\theta^{\\prime}\\in[q]}{\\operatorname*{max}}\\Big|\\big(\\mathbb{E}_{\\rho^{\\prime}}(\\mathbb{E}_{k}f_{k})(\\mathbb{E}_{k}g_{m})\\big)(\\theta)-\\big(\\mathbb{E}_{\\rho^{\\prime}}(\\mathbb{E}_{k}f_{k})(\\mathbb{E}_{k}g_{m})\\big)(\\theta^{\\prime})\\Big|}\\\\ &{\\leq\\exp\\Big(-\\varepsilon(\\mathrm{h}(\\rho^{\\prime})-C(\\log(R)+1)-\\mathrm{h}^{\\circ})\\Big)\\sqrt{\\mathbb{E}f_{k}^{2}(X)}\\sqrt{\\mathbb{E}g_{m}^{2}(X)}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 58}, {"type": "text", "text": "2.f $k=m=k_{1}$ , then the above term is bounded by ", "page_idx": 58}, {"type": "equation", "text": "$$\n\\exp(-\\varepsilon(\\mathrm{h}(\\rho^{\\prime})-k_{1}-C(\\log(R)+1)))\\sqrt{\\mathbb{E}f_{k}^{2}(X)}\\sqrt{\\mathbb{E}g_{m}^{2}(X)}.\n$$", "text_format": "latex", "page_idx": 58}, {"type": "text", "text": "Proof. Observe that both $\\begin{array}{r l r}{(\\mathbb{E}_{k}f_{k})(x)}&{{}=}&{\\sum_{u\\in D_{k}(\\rho^{\\prime})}(\\mathbb{E}_{u}\\tilde{f}_{u})(x_{u})}\\end{array}$ and $\\begin{array}{r l}{(\\mathbb{E}_{k}g_{m})(x)}&{{}=}\\end{array}$ $\\begin{array}{r}{\\sum_{u\\in D_{k}(\\rho^{\\prime})}(\\mathbb{E}_{k}g_{m,u})(x_{u})}\\end{array}$ are both degree-1 polynomials with variables $(x_{u}\\ :\\ u\\in\\ D_{k}(\\rho^{\\prime}))$ satisfying ", "page_idx": 59}, {"type": "equation", "text": "$$\n\\mathbb{E}(\\mathbb{E}_{k}g_{m})(X)=\\mathbb{E}(\\mathbb{E}_{k}f_{k})=0.\n$$", "text_format": "latex", "page_idx": 59}, {"type": "text", "text": "This allows us to apply Lemma G.4, yielding ", "page_idx": 59}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\underset{\\theta,\\theta^{\\prime}\\in[q]}{\\operatorname*{max}}\\left|\\left(\\mathbb{E}_{\\rho^{\\prime}}(\\mathbb{E}_{k}f_{k})(\\mathbb{E}_{k}g_{m})\\right)(\\theta)-\\left(\\mathbb{E}_{\\rho^{\\prime}}(\\mathbb{E}_{k}f_{k})(\\mathbb{E}_{k}g_{m})\\right)(\\theta^{\\prime})\\right|}\\\\ &{\\le2\\operatorname*{max}\\left|\\left(\\mathbb{E}_{\\rho^{\\prime}}(\\mathbb{E}_{k}f_{k})(\\mathbb{E}_{k}g_{m})\\right)(\\theta)-\\mathbb{E}\\bigl(\\mathbb{E}_{k}f_{k})(\\mathbb{E}_{k}g_{m})\\bigr)\\right|}\\\\ &{\\le2C_{G,4}R\\exp(-\\varepsilon(\\mathrm{h}(\\rho^{\\prime})-k))\\sqrt{\\underset{u\\in D_{k}(\\rho^{\\prime})}{\\sum}\\mathbb{E}\\bigl[(\\mathbb{E}_{u}\\tilde{f}_{u})^{2}(X)\\bigr]}\\sqrt{\\underset{u\\in D_{k}(\\rho^{\\prime})}{\\sum}\\mathbb{E}\\bigl[(\\mathbb{E}_{u}g_{m,u})^{2}(X)\\bigr]},}\\end{array}\n$$", "text_format": "latex", "page_idx": 59}, {"type": "text", "text": "where $C_{G.4}\\geq1$ is the constant introduced in Lemma G.4. Next, we apply Lemma H.9 (which is why we need the assumption on $C^{\\circ}$ ) to get ", "page_idx": 59}, {"type": "equation", "text": "$$\n\\sqrt{\\sum_{u\\in D_{k}(\\rho^{\\prime})}\\mathbb{E}\\big[(\\mathbb{E}_{u}g_{m,u})^{2}(X)\\big]}\\leq\\sqrt{\\sum_{u\\in D_{k}(\\rho^{\\prime})}\\mathbb{E}g_{m,u}^{2}(X)}\\leq\\sqrt{\\operatorname*{max}\\left\\{4,C_{D.1}^{2}R^{4}\\right\\}\\cdot\\mathbb{E}g_{m}^{2}(X)}.\n$$", "text_format": "latex", "page_idx": 59}, {"type": "text", "text": "As for $\\begin{array}{r}{\\sqrt{\\sum_{u\\in D_{k}(\\rho^{\\prime})}\\mathbb{E}\\big[(\\mathbb{E}_{u}\\tilde{f}_{u})^{2}(X)\\big]}}\\end{array}$ $k=m=k_{1}$ thweanpplytesameerivatog ", "page_idx": 59}, {"type": "equation", "text": "$$\n\\sqrt{\\sum_{u\\in D_{k}(\\rho^{\\prime})}\\mathbb{E}\\big[(\\mathbb{E}_{u}\\tilde{f}_{u})^{2}(X)\\big]}\\leq\\sqrt{\\operatorname*{max}\\left\\{4,C_{D.1}^{2}R^{4}\\right\\}\\cdot\\mathbb{E}f_{k}^{2}(X)}.\n$$", "text_format": "latex", "page_idx": 59}, {"type": "text", "text": "This leads to ", "page_idx": 59}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\underset{\\theta,\\theta^{\\prime}\\in[q]}{\\operatorname*{max}}\\left|\\left(\\mathbb{E}_{\\rho^{\\prime}}(\\mathbb{E}_{k}f_{k})(\\mathbb{E}_{k}g_{m})\\right)(\\theta)-\\left(\\mathbb{E}_{\\rho^{\\prime}}(\\mathbb{E}_{k}f_{k})(\\mathbb{E}_{k}g_{m})\\right)(\\theta^{\\prime})\\right|}\\\\ &{\\le2C_{G.4}\\operatorname*{max}\\left\\{4,C_{D.1}^{2}R^{4}\\right\\}\\exp(-\\varepsilon(\\mathrm{h}(\\rho^{\\prime})-k))\\sqrt{\\mathbb{E}f_{k}^{2}(X)}\\sqrt{\\mathbb{E}g_{m}^{2}(X)}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 59}, {"type": "text", "text": "If $k>k_{1}$ , then we can apply Proposition E.1 and Lemma H.9 to get ", "page_idx": 59}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\quad\\sqrt{\\underset{u\\in D_{k}(\\rho^{\\prime})}{\\sum_{u\\in D_{k}(\\rho^{\\prime})}}\\mathbb{E}\\big[(\\mathbb{E}_{u}\\tilde{f}_{u})^{2}(X)\\big]}}\\\\ &{\\leq\\exp\\Big(-\\varepsilon(k-C_{E.1}(\\log(R)+1)-\\mathrm{h}^{\\circ}-\\frac{2}{\\varepsilon}\\log(2))\\Big)\\sqrt{\\underset{u\\in D_{k}(\\rho^{\\prime})}{\\sum_{u\\in D_{k}(\\rho^{\\prime})}}\\mathbb{E}\\tilde{f}_{u}^{2}(X)}}\\\\ &{\\leq\\sqrt{\\operatorname*{max}\\big\\{4,C_{D.1}^{2}R^{4}\\big\\}}\\exp\\Big(-\\varepsilon(k-C_{E.1}(\\log(R)+1)-\\mathrm{h}^{\\circ}-\\frac{2}{\\varepsilon}\\log(2))\\Big)\\sqrt{\\mathbb{E}f_{k}^{2}(X)}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 59}, {"type": "text", "text": "In this case, we have ", "page_idx": 59}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\underset{\\theta,\\theta^{\\prime}\\in[q]}{\\operatorname*{max}}\\left|\\left(\\mathbb{E}_{\\rho^{\\prime}}(\\mathbb{E}_{k}f_{k})(\\mathbb{E}_{k}g_{m})\\right)(\\theta)-\\left(\\mathbb{E}_{\\rho^{\\prime}}(\\mathbb{E}_{k}f_{k})(\\mathbb{E}_{k}g_{m})\\right)(\\theta^{\\prime})\\right|}\\\\ &{\\le2C_{G,4}\\operatorname*{max}\\left\\{4,C_{D,1}^{2}R^{4}\\right\\}\\exp\\Big(-\\varepsilon(\\mathrm{h}(\\rho^{\\prime})-C_{E.1}(\\log(R)+1)-\\mathrm{h}^{\\circ}-\\frac2\\varepsilon\\log(2))\\Big)\\sqrt{\\mathbb{E}f_{k}^{2}(X)}\\sqrt{\\mathbb{E}g_{m}^{2}(R)}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 59}, {"type": "text", "text": "By taking ", "page_idx": 59}, {"type": "equation", "text": "$$\nC=C_{E.1}+\\frac{2}{\\varepsilon}\\log(2)+\\frac{1}{\\varepsilon}\\Big(\\log(2C_{G.4})+\\log(C_{D.1}^{2})+4\\Big),\n$$", "text_format": "latex", "page_idx": 59}, {"type": "text", "text": "both statements of the lemma follows. ", "page_idx": 59}, {"type": "text", "text": "Proof of Proposition H.6. Without lose of generality, it is suffcient to prove the case when $m\\leq k$ First, we impose the first assumption that ", "page_idx": 59}, {"type": "equation", "text": "$$\nC^{\\circ}\\ge\\operatorname*{max}\\left\\{C_{H.2},\\,C_{F.2}+\\frac{2}{\\varepsilon}\\log(2)\\right\\},\n$$", "text_format": "latex", "page_idx": 59}, {"type": "text", "text": "where the constants are introduced in Proposition H.2 and Lemma F.2, respectively. This allows us to apply Corollary H.10 and Lemma H.11. For simplicity, let ", "page_idx": 60}, {"type": "equation", "text": "$$\nC_{1}:=\\operatorname*{max}\\{C_{H.10},\\,C_{H.11}\\}.\n$$", "text_format": "latex", "page_idx": 60}, {"type": "text", "text": "Then, combining the Corollary and the Lemma to the estimate (97) we can conclude that: For $k_{1}\\leq m\\leq k$ With $k>k_{1}$ ", "page_idx": 60}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\underset{\\theta,\\theta^{\\prime}\\in[q]}{\\operatorname*{max}}\\left|(\\mathbb{E}_{\\rho^{\\prime}}f_{k}g_{m})(\\theta)-(\\mathbb{E}_{\\rho^{\\prime}}f_{k}g_{m})(\\theta^{\\prime})\\right|}\\\\ &{\\le2\\exp\\Big(-\\frac{\\varepsilon}{2}(2\\mathrm{h}(\\rho^{\\prime})-k-C_{1}(\\log(R)+1)-\\mathrm{h}^{\\circ})\\Big)(\\mathbb{E}f_{k}^{2}(X))^{1/2}(\\mathbb{E}g_{m}^{2}(X))^{1/2},}\\end{array}\n$$", "text_format": "latex", "page_idx": 60}, {"type": "text", "text": "and in the case where $k=m=k_{1}$ , the above term is bounded by ", "page_idx": 60}, {"type": "equation", "text": "$$\n2\\exp\\Big(-\\frac{\\varepsilon}{2}(2\\mathrm{h}(\\rho^{\\prime})-2k-C_{1}(\\log(R)+1))\\Big)(\\mathbb{E}f_{k}^{2}(X))^{1/2}(\\mathbb{E}g_{m}^{2}(X))^{1/2}.\n$$", "text_format": "latex", "page_idx": 60}, {"type": "text", "text": "Then, the proof of the proposition follows by making the second assumption on $C^{\\circ}$ that ", "page_idx": 60}, {"type": "equation", "text": "$$\nC^{\\circ}\\geq C_{1}+\\frac{2}{\\varepsilon}\\log(2).\n$$", "text_format": "latex", "page_idx": 60}, {"type": "text", "text": "H.3Proof of Theorem G.3 ", "text_level": 1, "page_idx": 60}, {"type": "text", "text": "Proof. Now we are ready to establish the main theorem. As usual, let $C_{0}=C_{0}(M,d)$ denote the constant introduced in the statement of the Theorem. The value of $C_{0}$ will be determined as the proof proceeds. ", "page_idx": 60}, {"type": "text", "text": "Applying Theorem B.6 with $\\boldsymbol{\\mathcal{A}}$ and $\\mathrm{h}^{\\ast}=\\mathrm{h}^{\\circ}+\\frac{2}{\\varepsilon}\\log(2)$ and $c^{*}=1/2$ , we conclude that ", "page_idx": 60}, {"type": "equation", "text": "$$\n\\mathrm{Var}\\big[(\\mathbb{E}_{\\rho^{\\prime}}f)(X)\\big]\\leq\\exp\\big(-\\varepsilon(\\mathrm{h}(\\rho^{\\prime})-C_{B.6}(\\log(R)+1)-\\mathrm{h}^{*}\\big)\\mathrm{Var}\\big[f(X)\\big].\n$$", "text_format": "latex", "page_idx": 60}, {"type": "text", "text": "for any $B_{\\le\\rho^{\\prime}}$ -polynomial $f$ where $C_{B.6}=C(M,d,1/2)$ is the constant introduced by the theorem. We impose the first assumption on $C_{0}$ that ", "page_idx": 60}, {"type": "equation", "text": "$$\nC_{0}\\geq C_{B.6}+\\frac{2}{\\varepsilon}\\log(2),\n$$", "text_format": "latex", "page_idx": 60}, {"type": "text", "text": "and conclude that ", "page_idx": 60}, {"type": "equation", "text": "$$\n\\mathrm{Var}\\big[(\\mathbb{E}_{\\rho^{\\prime}}f)(X)\\big]\\leq\\exp\\big(-\\varepsilon(\\mathrm{h}(\\rho^{\\prime})-C_{0}(\\log(R)+1)-\\mathrm{h}^{\\circ}\\big)\\mathrm{Var}\\big[f(X)\\big]\\big.\n$$", "text_format": "latex", "page_idx": 60}, {"type": "text", "text": "Now, it remains to show that with the suitable choice of $C_{0}$ , for any $\\rho^{\\prime}$ with $\\mathrm{h}(\\rho^{\\prime})\\geq\\mathrm{h}^{\\circ}\\!+\\!C_{0}(\\log(R)\\!+$ 1) and any two $B_{\\le\\rho^{\\prime}}$ -polynomials $f$ and $g$ we have ", "page_idx": 60}, {"type": "equation", "text": "$$\n\\operatorname*{nax}_{\\varepsilon[q]}|(\\mathbb{E}_{\\rho^{\\prime}}f g)(\\theta)-\\mathbb{E}f g|\\leq\\exp\\left(-\\frac{\\varepsilon}{2}(\\mathrm{h}(\\rho^{\\prime})\\!-\\!\\mathrm{h}^{\\circ}\\!-\\!C_{0}(\\log(R)\\!+\\!1))\\right)\\sqrt{\\operatorname*{min}_{\\theta}(\\mathbb{E}_{\\rho^{\\prime}}f^{2})(\\theta)\\operatorname*{min}_{\\theta^{\\prime}}(\\mathbb{E}_{\\rho^{\\prime}}g^{2})(\\theta)}.\n$$", "text_format": "latex", "page_idx": 60}, {"type": "text", "text": "Let ", "page_idx": 60}, {"type": "equation", "text": "$$\nC_{1}:=\\operatorname*{max}\\Big\\{C_{H.6},\\frac{2}{\\varepsilon}\\log(2)+C_{F.1}+t_{0}\\Big\\},\n$$", "text_format": "latex", "page_idx": 60}, {"type": "text", "text": "where ", "page_idx": 60}, {"type": "text", "text": "\u00b7 $t_{0}$ is the constant such that $\\begin{array}{r}{\\sum_{t=t_{0}}^{\\infty}\\exp\\Big(-\\frac{\\varepsilon}{2}t\\Big)\\le\\frac{1}{2}}\\end{array}$ ", "page_idx": 60}, {"type": "text", "text": "$C_{H.6}$ is the constant introduced in Proposition H.6, and $C_{F.1}=C(M,d,1/2)$ is the constant introduced in Proposition F.1. ", "page_idx": 60}, {"type": "text", "text": "Next, let ", "page_idx": 61}, {"type": "equation", "text": "$$\nk_{1}=\\lceil\\mathrm{h}^{\\circ}+C_{1}(\\log(R)+1)\\rceil\\,.\n$$", "text_format": "latex", "page_idx": 61}, {"type": "text", "text": "The chocie of $C_{1}$ and $k_{1}$ allow us to apply Proposition H.6 and Proposition F.1 toward both $f$ and $g$ Next, we impose the second assumption on $C_{0}$ that ", "page_idx": 61}, {"type": "equation", "text": "$$\nC_{0}\\geq2C_{1}+2.\n$$", "text_format": "latex", "page_idx": 61}, {"type": "text", "text": "This assumption implies that there is a gap between $h(\\rho^{\\prime})$ and $k_{1}$ , which is necessary for the proof. ", "page_idx": 61}, {"type": "text", "text": "Now, we fix such $\\rho^{\\prime}$ and consider two $B_{\\le\\rho^{\\prime}}$ -polynomial $f$ and $g$ with $\\mathbb{E}f(X)=\\mathbb{E}g(X)=0$ Further, consider the decomposition of $f$ and $g$ according to Lemma D.1 with the above chosen $k_{1}$ ", "page_idx": 61}, {"type": "text", "text": "First, by our choice of $C_{1}$ , we have ", "page_idx": 61}, {"type": "equation", "text": "$$\nk_{1}\\geq\\underbrace{\\lceil\\log+\\frac{2}{\\varepsilon}\\log(2)}_{=\\mathbf{h}^{*}}+C_{F.1}(\\log(R)+1)+t_{0}\\rceil.\n$$", "text_format": "latex", "page_idx": 61}, {"type": "text", "text": "This assumption allow us to recycle the partial step in the proof of Theorem B.6 to obtain (80): ", "page_idx": 61}, {"type": "equation", "text": "$$\n\\sum_{k\\in[k_{1},\\mathrm{h}(\\rho^{\\prime})]}\\mathbb{E}f_{k}^{2}(X)\\leq2\\mathbb{E}f^{2}(X)\\quad\\mathrm{~and~}\\quad\\sum_{k\\in[k_{1},\\mathrm{h}(\\rho^{\\prime})]}\\mathbb{E}g_{k}^{2}(X)\\leq2\\mathbb{E}g^{2}(X).\n$$", "text_format": "latex", "page_idx": 61}, {"type": "text", "text": "Second, with our assumption that $k_{1}\\geq\\lceil\\mathrm{h}^{\\circ}+C_{H.6}(\\log(R)+1)\\rceil$ , we can apply Proposition H.6 to get ", "page_idx": 61}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\underset{\\theta,\\theta^{\\prime}\\in[q]}{\\operatorname*{max}}\\left|(\\mathbb{E}_{\\rho^{\\prime}}f g)(\\theta)-(\\mathbb{E}_{\\rho^{\\prime}}f g)(\\theta^{\\prime})\\right|\\leq\\underset{m,k\\in[k_{1},\\mathrm{h}(\\rho^{\\prime})]}{\\sum}\\underset{\\theta,\\theta^{\\prime}\\in[q]}{\\operatorname*{max}}\\left|(\\mathbb{E}_{\\rho^{\\prime}}f_{k}g_{m})(\\theta)-(\\mathbb{E}_{\\rho^{\\prime}}f_{k}g_{m})(\\theta^{\\prime})\\right|}\\\\ &{\\leq\\underset{m,k\\in[k_{1},\\mathrm{h}(\\rho^{\\prime})]}{\\sum}a_{k m}\\alpha_{k}\\beta_{m}=\\vec{\\alpha}^{\\top}A\\vec{\\beta}\\leq\\|\\vec{\\alpha}\\|\\|A\\|\\|\\vec{\\beta}\\|,}\\end{array}\n$$", "text_format": "latex", "page_idx": 61}, {"type": "text", "text": "where ${\\vec{\\alpha}}=\\left(\\alpha_{k_{1}},\\alpha_{k_{2}},\\ldots,\\alpha_{\\mathrm{h}(\\rho^{\\prime})}\\right)$ with $\\alpha_{k}\\,=\\,\\sqrt{\\mathbb{E}f_{k}^{2}(X)},$ $\\vec{\\beta}=(\\beta_{k_{1}},\\beta_{k_{2}},\\ldots,\\beta_{\\mathrm{h}(\\rho^{\\prime})})$ with $\\beta_{m}=$ $\\sqrt{\\mathbb{E}g_{m}^{2}(X)}$ , and $A=(a_{k m})_{k,m\\in[k_{1},\\mathrm{h}(\\rho^{\\prime})]}$ with ", "page_idx": 61}, {"type": "equation", "text": "$$\n\\iota_{k m}:=\\left\\{\\begin{array}{l l}{\\exp\\Big(-\\frac{\\varepsilon}{2}(\\mathrm{h}(\\rho^{\\prime})+\\mathrm{h}(\\rho^{\\prime})-\\operatorname*{max}\\{k,m\\}-C_{H.6}(\\log(R)+1)-\\mathrm{h}^{\\circ})\\Big)}&{\\operatorname*{max}\\{k,m\\}>k_{1}}\\\\ {\\exp\\Big(-\\frac{\\varepsilon}{2}(\\mathrm{h}(\\rho^{\\prime})+\\mathrm{h}(\\rho^{\\prime})-2k_{1}-C_{H.6}(\\log(R)+1))\\Big)}&{k=m=k_{1}.}\\end{array}\\right.\n$$", "text_format": "latex", "page_idx": 61}, {"type": "text", "text": "Together with (103), we have ", "page_idx": 61}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\|\\vec{\\alpha}\\|\\|A\\|\\|\\vec{\\beta}\\|\\le2\\|A\\|\\sqrt{\\mathbb{E}f^{2}(X)}\\sqrt{\\mathbb{E}g^{2}(X)}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 61}, {"type": "text", "text": "The next goal is to bound $\\|A\\|$ from above. Notice the fact that the matrix $A$ is symmetric implies there exists a unit vector $\\vec{\\gamma}$ such that $\\|A\\|=\\vec{\\gamma}^{\\top}A\\vec{\\gamma}$ . Now we fix such vector $\\vec{\\gamma}$ . Relying on the fact that $a_{k m}\\geq0$ \uff0c ", "page_idx": 61}, {"type": "equation", "text": "$$\nA\\|=\\sum_{k,m\\in[k_{1},\\hbar(\\rho^{\\prime})]}a_{k m}\\gamma_{k}\\gamma_{m}\\leq\\sum_{k,m\\in[k_{1},\\hbar(\\rho^{\\prime})]}\\frac{a_{k m}}{2}(\\gamma_{k}^{2}+\\gamma_{m}^{2})=\\sum_{m\\in[k_{1},\\hbar(\\rho^{\\prime})]}\\gamma_{m}^{2}\\Big(\\sum_{k\\in[k_{1},\\hbar(\\rho^{\\prime})]}a_{k m}\\Big).\n$$", "text_format": "latex", "page_idx": 61}, {"type": "text", "text": "Clearly, from the definition of $a_{k m}$ , the term $\\begin{array}{r}{\\sum_{k\\in[k_{1},\\mathrm{h}(\\rho^{\\prime})]}a_{k m}}\\end{array}$ is maximized when $m=k_{1}$ ", "page_idx": 61}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\displaystyle\\sum_{k\\in[k_{1},\\mathrm{h}(\\rho^{\\prime})]}a_{k k_{1}}=\\exp\\Big(-\\frac{\\varepsilon}{2}(\\mathrm{h}(\\rho^{\\prime})+\\mathrm{h}(\\rho^{\\prime})-2k_{1}-C_{H,6}(\\log(R)+1))\\Big)}&{}\\\\ {\\displaystyle+\\sum_{k\\in[k_{1},\\mathrm{h}(\\rho^{\\prime})]}\\exp\\Big(-\\frac{\\varepsilon}{2}(\\mathrm{h}(\\rho^{\\prime})+\\mathrm{h}(\\rho^{\\prime})-k-C_{H,6}(\\log(R)+1)-\\mathrm{h}^{\\circ})\\Big)}&{}\\\\ {\\displaystyle}&{=\\exp\\Big(-\\frac{\\varepsilon}{2}(\\mathrm{h}(\\rho^{\\prime})-C_{H,6}(\\log(R)+1)-\\mathrm{h}^{\\circ})\\Big)\\cdot}\\\\ {\\displaystyle}&{\\quad\\cdot\\left(\\exp\\Big(-\\frac{\\varepsilon}{2}(\\mathrm{h}(\\rho^{\\prime})-2k_{1}+\\mathrm{h}^{\\circ})\\Big)+\\displaystyle\\sum_{k\\in[k_{1},\\mathrm{h}(\\rho^{\\prime})]}\\exp\\Big(-\\frac{\\varepsilon}{2}(\\mathrm{h}(\\rho^{\\prime})-k)\\Big)\\right).}\\end{array}\n$$", "text_format": "latex", "page_idx": 61}, {"type": "text", "text": "First, ", "page_idx": 62}, {"type": "equation", "text": "$$\n\\sum_{k\\in[k_{1},\\mathrm{h}(\\rho^{\\prime})]}\\exp\\Big(-\\frac{\\varepsilon}{2}(\\mathrm{h}(\\rho^{\\prime})-k)\\Big)\\leq\\frac{1}{1-\\exp(-\\varepsilon/2)}\\leq\\frac{4}{\\varepsilon}.\n$$", "text_format": "latex", "page_idx": 62}, {"type": "text", "text": "Second, ", "page_idx": 62}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\exp\\Big(-\\frac{\\varepsilon}{2}(\\mathtt{h}(\\rho^{\\prime})-2k_{1}+\\mathtt{h}^{\\circ})\\Big)\\leq\\exp\\Big(-\\frac{\\varepsilon}{2}\\Big(C_{0}(\\log(R)+1)+\\mathtt{h}^{\\circ}-2(\\mathtt{h}^{\\circ}+C_{1}(\\log(R)+1)+1)}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\qquad\\le\\exp\\Big(-\\frac{\\varepsilon}{2}(C_{0}-2C_{1}-2)(\\log(R)+1)\\Big)\\le1,}\\end{array}\n$$", "text_format": "latex", "page_idx": 62}, {"type": "text", "text": "which in turn implies that ", "page_idx": 62}, {"type": "equation", "text": "$$\n\\left(\\exp\\Big(-\\frac{\\varepsilon}{2}(\\ h(\\rho^{\\prime})-2k_{1}+\\ h^{\\circ})\\Big)+\\sum_{k\\in[k_{1},\\ h(\\rho^{\\prime})]}\\exp\\Big(-\\frac{\\varepsilon}{2}(\\ h(\\rho^{\\prime})-k)\\Big)\\right)\\leq\\frac{5}{\\varepsilon}.\n$$", "text_format": "latex", "page_idx": 62}, {"type": "text", "text": "Hence, we conclude that ", "page_idx": 62}, {"type": "equation", "text": "$$\n\\|A\\|\\leq\\frac{5}{\\varepsilon}\\exp\\Big(-\\frac{\\varepsilon}{2}(\\mathrm{h}(\\rho^{\\prime})-C_{H.6}(\\log(R)+1)-\\mathrm{h}^{\\circ})\\Big).\n$$", "text_format": "latex", "page_idx": 62}, {"type": "text", "text": "Together we conclude that when $\\mathrm{h}(\\rho)\\geq\\mathrm{h}^{\\circ}+C_{1}(\\log(R)+1)$ , any two $B_{\\le\\rho^{\\prime}}$ -polynomials $f$ and $g$ with $\\mathbb{E}f(X)=\\mathbb{E}g(X)=0$ satisfies ", "page_idx": 62}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\underset{\\theta,\\theta^{\\prime}\\in[q]}{\\operatorname*{max}}\\left|(\\mathbb{E}_{\\rho^{\\prime}}f g)(\\theta)-(\\mathbb{E}_{\\rho^{\\prime}}f g)(\\theta^{\\prime})\\right|}\\\\ &{\\le\\!\\frac{10}{\\varepsilon}\\exp\\Big(-\\frac{\\varepsilon}{2}(\\mathrm{h}(\\rho^{\\prime})-C_{H.6}(\\log(R)+1)-\\mathrm{h}^{\\circ})\\Big)\\sqrt{\\mathbb{E}f^{2}(X)}\\sqrt{\\mathbb{E}g^{2}(X)}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 62}, {"type": "text", "text": "Now, we impose the third assumption on $C_{0}$ that ", "page_idx": 62}, {"type": "equation", "text": "$$\nC_{0}\\geq C_{H.6}+\\frac{2}{\\varepsilon}\\log(20/\\varepsilon),\n$$", "text_format": "latex", "page_idx": 62}, {"type": "text", "text": "then ", "page_idx": 62}, {"type": "equation", "text": "$$\n\\frac{10}{\\varepsilon}\\exp\\bigg(-\\frac{\\varepsilon}{2}(\\mathrm{h}(\\rho^{\\prime})-C_{H.6}(\\log(R)+1)-\\mathrm{h}^{\\circ})\\bigg)\\leq\\frac{10}{\\varepsilon}\\exp\\bigg(-\\frac{\\varepsilon}{2}(C_{0}-C_{H.6})(\\log(R)+1)\\bigg)\\leq1/2.\n$$", "text_format": "latex", "page_idx": 62}, {"type": "text", "text": "Next, we apply (104) to the special case that $f=g$ ", "page_idx": 62}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{\\bar{c}}f^{2}(X)-\\underset{\\theta\\in[q]}{\\operatorname*{min}}(\\mathbb{E}_{\\rho^{\\prime}}f^{2})(\\theta)\\leq\\underset{\\theta,\\theta^{\\prime}\\in[q]}{\\operatorname*{max}}\\left|(\\mathbb{E}_{\\rho^{\\prime}}f g)(\\theta)-(\\mathbb{E}_{\\rho^{\\prime}}f g)(\\theta^{\\prime})\\right|\\leq\\underset{\\theta\\in[q]}{\\frac{1}{2}}\\mathbb{E}f^{2}(X)}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\Rightarrow\\mathbb{E}f^{2}(X)\\leq2\\underset{\\theta\\in[q]}{\\operatorname*{min}}(\\mathbb{E}_{\\rho^{\\prime}}f^{2})(\\theta)}\\end{array}\n$$", "text_format": "latex", "page_idx": 62}, {"type": "text", "text": "Clearly, the same statemnet holds for $g$ as well. Substituting these estimates back to (104), we can conclude that when $\\mathrm{h}(\\rho)\\,\\geq\\,\\mathrm{h}^{\\circ}+{\\bar{C}}_{0}(\\log(R)+1)$ , any two $B_{\\le\\rho^{\\prime}}$ -polynomials $f$ and $g$ with $\\mathbb{E}f(X)=\\mathbb{E}g(X)=0$ satisfies ", "page_idx": 62}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\underset{\\theta,\\theta^{\\prime}\\in[q]}{\\operatorname*{max}}\\left|(\\mathbb{E}_{\\rho^{\\prime}}f g)(\\theta)-(\\mathbb{E}_{\\rho^{\\prime}}f g)(\\theta^{\\prime})\\right|}\\\\ &{\\le\\frac{20}{\\varepsilon}\\exp\\Big(-\\frac{\\varepsilon}{2}(\\mathrm{h}(\\rho^{\\prime})-C_{H.6}(\\log(R)+1)-\\mathrm{h}^{\\circ})\\Big)\\sqrt{\\underset{\\theta\\in[q]}{\\operatorname*{min}}(\\mathbb{E}_{\\rho^{\\prime}}f^{2})(\\theta)}\\sqrt{\\underset{\\theta\\in[q]}{\\operatorname*{min}}(\\mathbb{E}_{\\rho^{\\prime}}g^{2})(\\theta)}}\\\\ &{\\le\\exp\\Big(-\\frac{\\varepsilon}{2}(\\mathrm{h}(\\rho^{\\prime})-C_{0}(\\log(R)+1)-\\mathrm{h}^{\\circ})\\Big)\\sqrt{\\underset{\\theta\\in[q]}{\\operatorname*{min}}(\\mathbb{E}_{\\rho^{\\prime}}f^{2})(\\theta)}\\sqrt{\\underset{\\theta\\in[q]}{\\operatorname*{min}}(\\mathbb{E}_{\\rho^{\\prime}}g^{2})(\\theta)}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 62}, {"type": "text", "text": "Therefore, the theorem follows. ", "page_idx": 62}, {"type": "text", "text": "1   Variance Estimate for degree 1 polynomial ", "text_level": 1, "page_idx": 63}, {"type": "text", "text": "This section is dedicated to prove Proposition C.3. Let us restate it here: ", "page_idx": 63}, {"type": "text", "text": "Proposition I.1. There exists a constant $C=C(M,d)\\geq1$ so that the following holds: Fix $\\rho^{\\prime}\\in T$ and $0\\leq k\\leq\\mathrm{h}(\\rho^{\\prime})$ then for any degree 1 function $f$ with variables $(x_{u}\\,:\\,u\\in D_{k}(\\rho^{\\prime}))$ . There exists functions $f_{u}(x)=f_{u}(x_{u})$ for $u\\in D_{k}(\\rho^{\\prime})$ so that the following holds: ", "page_idx": 63}, {"type": "text", "text": "\u4e00 $\\begin{array}{r}{f(X)=\\sum_{u\\in D_{k}(\\rho^{\\prime})}f_{u}(X_{u})}\\end{array}$ almost surely. (They may not agree as functions from $[q]^{T}$ to R.) ", "page_idx": 63}, {"type": "text", "text": "2. For any $v\\in T_{\\rho^{\\prime}}$ with $\\operatorname{h}(u)\\geq k$ ", "page_idx": 63}, {"type": "equation", "text": "$$\n\\sum_{u\\in D_{k}(v)}\\mathrm{Var}[f_{u}(X_{u})]\\leq C R^{3}\\mathrm{Var}\\big[\\sum_{u\\in D_{k}(v)}f_{u}(X_{u})\\big].\n$$", "text_format": "latex", "page_idx": 63}, {"type": "text", "text": "Example I.2. Suppose $u,v\\in{\\mathfrak{c}}(\\rho^{\\prime})$ for $u,v,\\rho^{\\prime}\\in T$ and consider ", "page_idx": 63}, {"type": "equation", "text": "$$\nM={\\frac{1}{2}}\\left[\\!\\!{\\begin{array}{l l l l}{1}&{0}&{1}&{0}\\\\ {0}&{1}&{0}&{1}\\\\ {1}&{0}&{1}&{0}\\\\ {0}&{1}&{0}&{1}\\end{array}}\\!\\!\\right].\n$$", "text_format": "latex", "page_idx": 63}, {"type": "text", "text": "Let us consider the function $f(x)=f_{u}(x)+f_{v}(x)$ where ", "page_idx": 63}, {"type": "equation", "text": "$$\nf_{u}(x)=\\mathbf{1}_{1,3}(x_{u})={\\left\\{\\begin{array}{l l}{1}&{{\\mathrm{~if~}}x_{u}\\in\\{1,3\\},}\\\\ {0}&{{\\mathrm{otherwise.}}}\\end{array}\\right.}\n$$", "text_format": "latex", "page_idx": 63}, {"type": "text", "text": "and $f_{v}(x)=-\\mathbf{1}_{1,3}(x_{v})$ ", "page_idx": 63}, {"type": "text", "text": "Condition on $X_{\\rho^{\\prime}}\\in\\{1,3\\}$ \uff0c $f(X_{u})+f(X_{v})=1-1=0$ condition on $X_{\\rho^{\\prime}}\\in\\{1,3\\}$ and condition on $X_{\\rho^{\\prime}}\\in\\{2,4\\}$ \uff0c $f(X_{u})+f(X_{v})=0-0=0$ . Put it differntly, $\\mathrm{Var}[f(X)]=0$ since $f(X)=0$ almost surely. However, observe that $\\pi$ is the uniform measure on [4], which implies ", "page_idx": 63}, {"type": "equation", "text": "$$\n\\mathrm{Var}[f_{u}(X_{u})]=\\mathrm{Var}[f_{v}(X_{v})]=\\frac{1}{4}>0.\n$$", "text_format": "latex", "page_idx": 63}, {"type": "text", "text": "Therefore, it is not true that (23) holds for the standard (Efron-Stein) decomposition of $f(x)\\,=$ $\\begin{array}{r}{\\sum_{v\\in D_{k}(\\rho^{\\prime})}f_{v}(x_{v})}\\end{array}$ ", "page_idx": 63}, {"type": "text", "text": "Let us make a simple observation to give the insight for the construction. If $f(X_{u})$ is a function of $X_{\\mathfrak{p}(u)}$ , then for each $i\\in[q]$ , the function $f$ must take the same value for all possible outcomes of $X_{u}$ conditioned on $X_{{\\mathfrak{p}}(u)}=i$ . In other words, the values of $f$ are constant on the set ", "page_idx": 63}, {"type": "equation", "text": "$$\nS_{i}=\\operatorname*{supp}(\\operatorname{row}_{i}(M))\n$$", "text_format": "latex", "page_idx": 63}, {"type": "text", "text": "for every $i\\in[q]$ . Now, let us consider the case where $f(X_{u})$ is a function of $X_{{\\mathfrak{p}}^{r}(u)}$ . This can be reformulated as follows: for $k\\in[0,r\\!-\\!1],\\mathbb{E}\\big[f(X_{u})\\bigm|X_{\\mathfrak{p}^{k}(u)}\\big]$ is a function of $X_{{\\mathfrak{p}}^{k+1}(u)}$ . Equivalently, the values of $M^{k}f$ are constant on the set $S_{i}$ for every $i\\in[q]$ ", "page_idx": 63}, {"type": "text", "text": "Therefore, it is evident that the construction of the basis should primarily revolve around the sets $\\{S_{i}\\}_{i\\in[q]}$ and their interaction with $M$ ", "page_idx": 63}, {"type": "text", "text": "Following from this discussion, the proof of the Proposition I.1 is divided into the following steps: ", "page_idx": 63}, {"type": "text", "text": "Step 1 (Section I.1): We try to give a precise description of when $f(X_{u})$ is a function of $X_{{\\mathfrak{p}}^{k}(u)}$ for some $\\overline{{k\\in\\mathbb{N}}}$ . To this end, we introduce the following notation. ", "page_idx": 63}, {"type": "text", "text": "Definition I3.We define the following partial order relation $\\leq$ on the collection of all partitions of $[q]$ : Specifically, for two partitions $\\mathbf{P}$ and $\\mathbf{P}^{\\prime}$ , we say that $\\mathbf{P}\\leq\\mathbf{P}^{\\prime}\\,i f\\mathbf{P}^{\\prime}$ is finer than or equal to $\\mathbf{P}$ ", "page_idx": 63}, {"type": "text", "text": "Further, there exists $r\\in\\mathbb{N}$ such that $\\mathbf{P}^{t,0}$ for $t\\geq r$ is the trivial partition. ", "page_idx": 63}, {"type": "text", "text": "Lemma I.4. There exists a chain of paritions ", "page_idx": 63}, {"type": "equation", "text": "$$\n\\mathbf{P}^{0,0}\\ge\\mathbf{P}^{1,0}\\ge\\mathbf{P}^{2,0}\\cdot\\cdot\\cdot\\ge\\mathbf{P}^{r,0}\\ge.\\;.\\;.\n$$", "text_format": "latex", "page_idx": 63}, {"type": "text", "text": "A function $f:[q]\\mapsto\\mathbb{R}$ satisfies that $f(X_{u})$ is a function of $X_{{\\mathfrak{p}}^{r}(u)}$ for some $r\\in\\mathbb N$ if and only if $f$ . a linear combination of ${\\bf1}_{P}$ for $P\\in\\mathbf{P}^{r,0}$ ", "page_idx": 63}, {"type": "text", "text": "(The double index for the partitions is due to a technical reason, which will be clear in the construction of thepartitions.) ", "page_idx": 64}, {"type": "text", "text": "Step 2 (Section I.2): Next, we try to extract a basis of functions according to the partitions fro the previous step, along with suitable quantitative estimates: ", "page_idx": 64}, {"type": "text", "text": "Proposition I.5. Let M be an ergodic and irreducible transition matrix defined on the state space [q].We canconstruct ", "page_idx": 64}, {"type": "text", "text": "\u00b7 a basis of functions from $[q]$ to $\\mathbb{R}$ denotedas ", "page_idx": 64}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathopen{}\\mathclose\\bgroup\\left\\{\\xi_{w}\\aftergroup\\egroup\\right\\}_{w\\in\\mathsf{W},}}\\end{array}\n$$", "text_format": "latex", "page_idx": 64}, {"type": "text", "text": "where W is a set of size $q$ ", "page_idx": 64}, {"type": "text", "text": "\u00b7 a function ", "page_idx": 64}, {"type": "equation", "text": "$$\nr:\\mathsf{W}\\to\\mathbb{N}\\cup\\{0\\},\n$$", "text_format": "latex", "page_idx": 64}, {"type": "text", "text": "\u00b7 and a constant $C>1$ (which depends on $M$ ", "page_idx": 64}, {"type": "text", "text": "so that the following holds: ", "page_idx": 64}, {"type": "text", "text": "1. Let ", "page_idx": 64}, {"type": "equation", "text": "$$\nr_{0}:=\\operatorname*{max}_{\\mathsf{w}\\in\\mathsf{W}}r(\\mathsf{w}).\n$$", "text_format": "latex", "page_idx": 64}, {"type": "text", "text": "There exists unique $\\mathsf{w}_{0}\\in\\mathsf{W}$ such that $r(\\mathsf{w}_{0})=r_{0}$ .Moreover, $\\xi_{\\mathsf{w}_{0}}\\equiv1$ ", "page_idx": 64}, {"type": "text", "text": "2. For each $\\mathsf{w}\\neq\\mathsf{w}_{0}$ $\\xi_{\\mathsf{w}}(X_{u})$ is a function of $X_{v}$ where $v={\\mathfrak{p}}^{r(\\mathsf{w})}(u)$ and $\\mathbb{E}\\xi_{\\mathsf{w}}(X_{u})=0$ ", "page_idx": 64}, {"type": "equation", "text": "$$\n\\mathrm{Var}\\big[\\sum_{\\mathsf{w}}c_{\\mathsf{w}}\\xi_{\\mathsf{w}}(X_{u})\\big]\\leq C\\big(\\underset{\\mathsf{w}:\\,r(\\mathsf{w})\\neq r_{0}}{\\operatorname*{max}}|c_{\\mathsf{w}}|\\big)^{2}.\n$$", "text_format": "latex", "page_idx": 64}, {"type": "text", "text": "4. For any $0\\leq r^{\\prime}<r_{0}$ such that $\\{\\mathsf{w}\\in\\mathsf{W}\\,:\\,r(\\mathsf{w})=r^{\\prime}\\}$ is not empty, ", "page_idx": 64}, {"type": "equation", "text": "$$\n\\mathbb{E}\\mathrm{Var}\\Big[\\mathbb{E}\\big[\\sum_{\\substack{\\mathbf{w}:\\,r(\\mathbf{w})=r^{\\prime}}}c_{\\mathbf{w}}\\xi_{\\mathbf{w}}(X_{u})\\,|X_{v}\\big]\\,\\Big|\\,X_{\\mathfrak{p}(v)}\\Big]\\geq\\frac{1}{C}\\big(\\operatorname*{max}_{\\substack{\\mathbf{w}:\\,r(\\mathbf{w})=r^{\\prime}}}|c_{\\mathbf{w}}|\\big)^{2}.\n$$", "text_format": "latex", "page_idx": 64}, {"type": "text", "text": "5. For any $0\\leq r^{\\prime}<r_{0}$ such that $\\{\\mathsf{w}\\in\\mathsf{W}\\,:\\,r(\\mathsf{w})<r^{\\prime}\\}$ is not empty, ", "page_idx": 64}, {"type": "equation", "text": "$$\n\\mathbb{E}\\mathrm{Var}\\Big[\\mathbb{E}\\big[\\sum_{\\substack{\\mathbf{w}:\\,r(\\mathbf{w})<r^{\\prime}}}c_{\\mathsf{w}}\\xi_{\\mathsf{w}}(X_{u})\\,|X_{v}\\big]\\,\\Big|\\,X_{\\mathfrak{p}(v)}\\Big]\\leq C\\big(\\operatorname*{max}_{\\substack{\\mathbf{w}:\\,r(\\mathbf{w})<r^{\\prime}}}|c_{\\mathsf{w}}|\\big)^{2}.\n$$", "text_format": "latex", "page_idx": 64}, {"type": "text", "text": "Remark I.6. For $\\mathsf{w}\\in\\mathsf{W}$ and $l\\in[r(\\mathsf{w})]$ , let ", "page_idx": 64}, {"type": "equation", "text": "$$\n\\xi_{\\mathsf{w}}^{(l)}:=M^{l}\\xi_{\\mathsf{w}},\n$$", "text_format": "latex", "page_idx": 64}, {"type": "text", "text": "where we treated $\\xi$ as an vector in $\\mathbb{R}^{[q]}$ . Equivalently, ", "page_idx": 64}, {"type": "equation", "text": "$$\n\\xi^{(l)}(\\theta)=\\mathbb{E}\\big[\\xi(X_{u})\\,|\\,X_{v}=\\theta\\big]\n$$", "text_format": "latex", "page_idx": 64}, {"type": "text", "text": "where $u,v\\in T$ are vertices such that $v={\\mathfrak{p}}^{l}(u)$ ", "page_idx": 64}, {"type": "text", "text": "Step 3 (Section I.3): Finally, we will use the basis from the previous step to decompose degree-1 polynomials to prove Proposition I.1. ", "page_idx": 64}, {"type": "text", "text": "1.1   Partitions of $[q]$ ", "text_level": 1, "page_idx": 64}, {"type": "text", "text": "Let us begin with the following observation. ", "page_idx": 64}, {"type": "text", "text": "Lemma I.7. Suppose $\\{O_{\\alpha}\\}_{\\alpha\\in I}$ is a collection of non-empty subsets of $[q]$ .Then, there exists a unique partition $\\mathbf{P}$ of $[q]$ that satisfies the following 2 conditions: ", "page_idx": 64}, {"type": "text", "text": "1. For each $\\alpha\\in I$ and $P\\in\\mathbf{P}$ either $O_{\\alpha}\\in P$ or $O_{\\alpha}\\cap P=\\varnothing$ ", "page_idx": 64}, {"type": "text", "text": "2. For any other partition $\\mathbf{P}^{\\prime}$ that also satisfies the above property, $\\mathbf{P}^{\\prime}\\leq\\mathbf{P}$ ", "page_idx": 65}, {"type": "text", "text": "Proof. The proof can be carried out by constructing the partition $\\mathbf{P}$ ", "page_idx": 65}, {"type": "text", "text": "Withou feeraltywemaya thlon $\\{O_{\\alpha}\\}_{\\alpha\\in I}$ contains $\\{\\{\\theta\\}\\}_{\\theta\\in[q]}$ since for a singleton $\\{\\theta\\}$ and a set $P$ , it is always true that either $\\{\\theta\\}\\subseteq P$ or $\\{\\theta\\}\\cap P=\\emptyset$ . Consequently, we may assume ", "page_idx": 65}, {"type": "equation", "text": "$$\n\\bigcup_{\\alpha\\in I}O_{\\alpha}=[q].\n$$", "text_format": "latex", "page_idx": 65}, {"type": "text", "text": "First, we define an equivalence relation $\\simeq$ on $\\{O_{\\alpha}\\}_{\\alpha\\in I}$ as follows: For any $\\alpha,\\alpha^{\\prime}\\in I$ ,we denote ${\\cal O}_{\\alpha}\\,\\simeq\\,{\\cal O}_{\\alpha^{\\prime}}$ if there exists a chain $\\left(\\alpha_{1},\\alpha_{2},\\ldots,\\alpha_{l}\\right)$ such that $O_{\\alpha_{i-1}}\\cap O_{\\alpha_{i}}\\neq\\emptyset$ for $i\\,\\in\\,[l]$ . Let $I_{1},\\ldots,I_{k_{0}}\\subseteq I$ be the partition of $I$ such that $\\{O_{\\alpha}\\}_{\\alpha\\in I_{k}}$ for $k\\in[k_{0}]$ form the equivalence classes of the relation. Now, let $\\mathbf{P}:=\\{P_{1},...,P_{k_{0}}\\}$ , where ", "page_idx": 65}, {"type": "equation", "text": "$$\nP_{k}:=\\cup_{\\alpha\\in I_{k}}O_{k}.\n$$", "text_format": "latex", "page_idx": 65}, {"type": "text", "text": "Claim 1: For every $\\alpha\\in I$ and $k\\in[k_{0}]$ , either $O_{\\alpha}\\subseteq P_{k}$ or $O_{\\alpha}\\cap P_{k}=\\emptyset$ ", "page_idx": 65}, {"type": "text", "text": "To prove this claim, consider any $\\alpha$ and $k$ described above. Suppose $O_{\\alpha}\\cap P_{k}\\neq\\emptyset$ . Let $\\theta\\in O_{\\alpha}\\cap P_{k}$ and pick an index $\\alpha^{\\prime}\\in I_{k}$ such that $\\theta\\,\\in\\,{\\cal O}_{\\alpha^{\\prime}}$ . Such an index exists because $\\textstyle P_{k}=\\bigcup_{\\alpha^{\\prime\\prime}\\in I_{k}}O_{\\alpha^{\\prime\\prime}}$ Then, we have $O_{\\alpha}\\cap O_{\\alpha^{\\prime}}\\neq\\emptyset$ , implying $\\alpha\\in I_{k}$ . Consequently, $O_{\\alpha}\\subseteq P_{k}$ . Therefore, the claim is proven. ", "page_idx": 65}, {"type": "text", "text": "Claim 2: P is a partition of $[q]$ ", "page_idx": 65}, {"type": "text", "text": "We need to verify three properties: ", "page_idx": 65}, {"type": "equation", "text": "$$\n1.\\ \\cup_{k\\in[k_{0}]}P_{k}=[q],\n$$", "text_format": "latex", "page_idx": 65}, {"type": "text", "text": "First, for each $\\theta\\in[q]$ , by (107), there exists $\\alpha\\in I$ such that $\\theta\\in O_{\\alpha}$ . Then, $\\theta\\in O_{\\alpha}\\in P_{k}$ where $k$ is the index such that $\\alpha\\in I_{k}$ . Hence, we conclude that $\\textstyle\\bigcup_{k\\in[k_{0}]}P_{k}=[q]$ ", "page_idx": 65}, {"type": "text", "text": "Second, for each $k\\in[k_{0}]$ , let $\\alpha\\in I_{k}$ . We have $0\\not=O_{\\alpha}\\subseteq P_{k}$ . Thus, $P_{k}$ is not an empty set. ", "page_idx": 65}, {"type": "text", "text": "Finally, for any distinct $k,k^{\\prime}\\in[k_{0}]$ , suppose $\\theta\\in P_{k}\\cap P_{k^{\\prime}}$ . By (107), let $\\alpha\\in I$ be the index so that $\\theta\\in O_{\\alpha}$ . Hence, both ${\\cal O}_{\\alpha}\\cap P_{k}$ and $O_{\\alpha}\\cap P_{k^{\\prime}}$ . In particular, it is necessary that $\\alpha\\in I_{k}$ and $\\alpha\\in I_{k^{\\prime}}$ which forces $k=k^{\\prime}$ , leading to a contradiction. Therefore, $P_{k}\\cap P_{k^{\\prime}}=\\emptyset$ whenever $k\\neq k^{\\prime}$ . Hence, the claim follows. ", "page_idx": 65}, {"type": "text", "text": "Claim 3: $\\mathbf{P}^{\\prime}\\leq\\mathbf{P}$ for any $\\mathbf{P}^{\\prime}$ described in the statement. ", "page_idx": 65}, {"type": "text", "text": "To prove the claim, it suffices to show that for any $P^{\\prime}\\in\\mathbf{P}^{\\prime}$ and $P_{k}\\in\\mathbf{P}$ with $k\\in[k_{0}]$ ,if $P^{\\prime}\\cap P_{k}\\neq\\emptyset$ then $P_{k}\\subseteq P^{\\prime}$ ", "page_idx": 65}, {"type": "text", "text": "Let us consider an arbitrary pair of $P^{\\prime}\\in\\mathbf{P}^{\\prime}$ and $P_{k}\\in\\mathbf{P}$ and assume that $P^{\\prime}\\cap P_{k}\\neq\\emptyset$ . There exists an index $\\alpha$ such that $O_{\\alpha}\\cap\\mathbf{\\bar{\\calP}}^{\\prime}\\cap P_{k}\\neq\\emptyset$ . Based on the assumptions regarding $\\mathbf{P}$ and $\\mathbf{P}^{\\prime}$ , we have $\\alpha\\in I_{k}$ and $O_{\\alpha}\\subseteq P^{\\prime}$ ", "page_idx": 65}, {"type": "text", "text": "For every other $\\alpha^{\\prime}\\in I_{k}$ , there exists a chain $(\\alpha=\\alpha_{0},\\alpha_{1},\\ldots,\\alpha_{l_{0}}=\\alpha^{\\prime})$ such that $O_{\\alpha_{l-1}}\\cap O_{\\alpha_{l}}\\neq\\varnothing$ for $l\\in[\\dot{l}_{0}]$ . Observe that if $O_{\\alpha_{l-1}}\\subseteq P^{\\prime}$ , then $O_{\\alpha_{l}}\\subseteq P^{\\prime}$ , due to $O_{\\alpha_{l}}\\cap P^{\\prime}\\supseteq O_{\\alpha_{l}}\\cap O_{\\alpha_{l-1}}\\neq\\emptyset$ With $O_{0}\\subseteq P^{\\prime}$ as our starting point, we can apply this observation repeatedly to conclude that ${\\cal O}_{\\alpha^{\\prime}}\\subset{\\cal P}^{\\prime}$ Since the argument works for every $\\alpha^{\\prime}\\in I_{k}$ , we conclude that $\\textstyle P_{k}=\\bigcup_{\\alpha^{\\prime\\prime}\\in I_{k}}O_{\\alpha^{\\prime\\prime}}\\subseteq P^{\\prime}$ ", "page_idx": 65}, {"type": "text", "text": "Definition I8. For any given collection of subsets $\\{O_{\\alpha}\\}_{\\alpha\\in I}$ of $[q]$ let $\\mathbf{P}(\\{O_{\\alpha}\\}_{\\alpha\\in I})$ denote the partition $\\mathbf{P}$ defined in Lemma I.7. ", "page_idx": 65}, {"type": "text", "text": "For any given partition $\\mathbf{Q}$ of $[q]$ ,let ", "page_idx": 66}, {"type": "equation", "text": "$$\n\\mathbf{P}_{\\mathrm{SC}}(\\mathbf{Q}):=\\mathbf{P}\\left(\\{Q\\}_{Q\\in\\mathbf{Q}}\\cup\\{S_{i}\\}_{i\\in[q]}\\right).\n$$", "text_format": "latex", "page_idx": 66}, {"type": "text", "text": "Remark I.9. Clearly, $\\mathbf P_{\\mathrm{SC}}(\\mathbf Q)\\leq\\mathbf Q$ ", "page_idx": 66}, {"type": "text", "text": "Definition I.10. Let ", "page_idx": 66}, {"type": "text", "text": "and ", "page_idx": 66}, {"type": "equation", "text": "$$\n\\begin{array}{c}{{{\\bf P}^{0,0}=\\{\\{1\\},\\{2\\},\\dots,\\{q\\}\\}}}\\\\ {{{\\bf P}^{1,0}={\\bf P}_{S C}({\\bf P}^{0,0}).}}\\end{array}\n$$", "text_format": "latex", "page_idx": 66}, {"type": "text", "text": "Let us remark that $\\mathbf{P}^{1,0}$ is the finest partition of $[q]$ so that each part $P\\in\\mathbf{P}^{1,0}$ either contains $S_{i}$ or disjoint from $S_{i}$ for $i\\in[q]$ ", "page_idx": 66}, {"type": "text", "text": "We use double indices for indexing the partitions because constructing such a chain of partitions requires the creation of multiple partitions along the way, as we will illustrate shortly. ", "page_idx": 66}, {"type": "text", "text": "To proceed, let us begin with a simple observation. ", "page_idx": 66}, {"type": "text", "text": "Lemma I.11. If $P\\in\\mathbf{P}^{1,0}$ ,then ", "page_idx": 66}, {"type": "equation", "text": "$$\nM\\mathbf{1}_{P}=\\mathbf{1}_{Q}\n$$", "text_format": "latex", "page_idx": 66}, {"type": "text", "text": "where ", "page_idx": 66}, {"type": "equation", "text": "$$\nQ=\\{i\\in[q]\\,:\\,S_{i}\\subseteq P\\}.\n$$", "text_format": "latex", "page_idx": 66}, {"type": "text", "text": "Suppose $\\mathbf{P}^{1,0}=\\{P_{1},P_{2},\\ldots,P_{k_{0}}\\}$ Then, the collection $\\mathbf{Q}:=\\{Q_{1},Q_{2},\\ldots,Q_{k_{0}}\\}$ where ", "page_idx": 66}, {"type": "equation", "text": "$$\nM\\mathbf{1}_{P_{i}}=\\mathbf{1}_{Q_{i}}\n$$", "text_format": "latex", "page_idx": 66}, {"type": "text", "text": "is also a partition provided that $M$ is irreducible. ", "page_idx": 66}, {"type": "text", "text": "Proof. For $i$ with $S_{i}\\cap P=\\emptyset$ it is immediate that $(M\\mathbf{1}_{P})_{i}=0$ . Conversely, when $S_{i}\\cap P\\neq\\emptyset$ , it is necessary that $S_{i}\\subseteq P$ Consequently, $\\begin{array}{r}{(M\\mathbf{1}_{P})_{i}=\\sum_{j\\in[q]}M_{i j}=1}\\end{array}$ ", "page_idx": 66}, {"type": "text", "text": "To establish that $\\mathbf{Q}$ is a partition, we need to demonstrate the following three conditions: ", "page_idx": 66}, {"type": "text", "text": "1. $Q_{k}\\cap Q_{k^{\\prime}}=\\emptyset$ for all distinct $k,k^{\\prime}\\in[k_{0}]$   \n2. $\\textstyle\\bigcup_{k\\in[k]}Q_{k}=[q]$   \n3. $Q_{k}\\neq\\emptyset$ for all $k\\in[k_{0}]$ ", "page_idx": 66}, {"type": "text", "text": "For the first condition, suppose there exists $i\\in Q_{k}\\cap Q_{k^{\\prime}}$ for some distinct $k$ and $k^{\\prime}$ . By definition, $S_{i}\\subseteq P_{k}$ and $S_{i}\\subseteq P_{k^{\\prime}}$ , which is a contradiction. Hence, $Q_{k}\\cap Q_{k^{\\prime}}=\\emptyset$ ", "page_idx": 66}, {"type": "text", "text": "For the second condition, for every $i\\in[q]$ , we know that $S_{i}\\subseteq P_{k}$ for some $k$ . Consequently, $i\\in Q_{k}$ ensuring $\\textstyle\\bigcup_{\\alpha\\in[k]}Q_{k}=[q]$ ", "page_idx": 66}, {"type": "text", "text": "For the third condition, if we assume $Q_{k}=\\emptyset$ , implying that no $i\\in[q]$ satisfies $S_{i}\\subseteq P_{k}$ , then $M$ is not irreducible, since the states in $P_{k}$ cannot be reached. \u53e3 ", "page_idx": 66}, {"type": "text", "text": "Definition I.12. Let $\\mathbf{P}^{1,1}=\\mathbf{Q}$ where $\\mathbf{Q}$ is the partition described in Lemma 1.11. ", "page_idx": 66}, {"type": "text", "text": "Lemma I.13. If $P$ is a finite union of parts in $\\mathbf{P}^{1,0}$ ,then ", "page_idx": 66}, {"type": "equation", "text": "$$\nM\\mathbf{1}_{P}=\\mathbf{1}_{Q}\n$$", "text_format": "latex", "page_idx": 66}, {"type": "text", "text": "where $Q$ is a finite union of parts in $\\mathbf{P}^{1,1}$ . The above map induces a bijection between subsets of $[q]$ that are finiteunion of parts of $\\mathbf{P}^{1,0}$ and subsets of $[q]$ that are finite union of parts of $\\mathbf{P}^{1,1}$ , in which preserve the inclusion relation is preserved. ", "page_idx": 66}, {"type": "text", "text": "Proof. Let us express $\\mathbf{P}^{1,0}\\,=\\,\\{P_{1},P_{2},...\\,,P_{[k_{0}]}\\}$ and $\\mathbf{P}^{1,1}\\,=\\,\\{Q_{1},Q_{2},\\dots,Q_{k_{0}}\\}$ where $\\mathbf{1}_{Q_{k}}=$ M1Pk: ", "page_idx": 66}, {"type": "text", "text": "For each $I\\subseteq[k_{0}]$ , let $\\textstyle P_{I}=\\bigcup_{k\\in I}P_{k}$ and $\\textstyle Q_{I}=\\bigcup_{k\\in I}Q_{k}$ . Since $\\begin{array}{r}{{\\bf1}_{P_{I}}\\,=\\,\\sum_{k\\in I}{\\bf1}_{P_{k}}}\\end{array}$ and ${\\bf1}_{Q_{I}}\\;=\\;$ $\\sum_{k\\in I}\\mathbf{1}_{Q_{k}}$ , clearly we have ", "page_idx": 66}, {"type": "equation", "text": "$$\n\\mathbf{1}_{Q_{I}}=M\\mathbf{1}_{P_{I}}.\n$$", "text_format": "latex", "page_idx": 66}, {"type": "text", "text": "Since naturally both finite union of parts of $P$ and of $Q$ are identified with a subset $I\\subset[k_{0}]$ in the above way, the statement of the lemma follows. ", "page_idx": 66}, {"type": "text", "text": "An immediate consequence is the following. ", "page_idx": 67}, {"type": "text", "text": "Corollary I.14. The transition matrix $M$ induces a bijection between partitions that are $\\leq{\\bf P}^{1,0}$ and partitions that are $\\leq{\\bf P}^{1,1}$ .For convenience, we adopt the following definitions: ", "page_idx": 67}, {"type": "text", "text": "1. For any partition $\\mathbf{P}$ such that $\\mathbf{P}\\leq\\mathbf{P}^{1,0}$ ,define ", "page_idx": 67}, {"type": "equation", "text": "$$\nM\\mathbf{P}:=\\{Q\\,:\\,\\exists P\\in\\mathbf{P}\\,s u c h\\,t h a t\\,\\mathbf{1}_{Q}=M\\mathbf{1}_{P}\\}\\leq\\mathbf{P}^{1,1}.\n$$", "text_format": "latex", "page_idx": 67}, {"type": "text", "text": "2. Given any $\\mathbf{P}\\leq\\mathbf{P}^{1,0}$ and for each $P\\in\\mathbf{P}$ let $M P$ represent a part in MP where ", "page_idx": 67}, {"type": "equation", "text": "$$\n{\\mathbf{1}}_{M P}=M{\\mathbf{1}}_{P}.\n$$", "text_format": "latex", "page_idx": 67}, {"type": "text", "text": "Next, we will build a collection of partitions $\\mathbf{P}^{r,s}$ for $r\\geq0$ and $0\\leq s\\leq r$ starting with ${\\bf P}^{0,0}={\\bf\\Phi}$ $\\{\\{1\\},\\{2\\},\\ldots,\\{q\\}\\}$ and establishing the relationship illustrated by the diagram below. ", "page_idx": 67}, {"type": "equation", "text": "$$\n\\begin{array}{c c c c c c c c c c c c c c c c}{\\mathbf{P}^{0,0}}&{\\stackrel{>}{S C}}&{\\mathbf{P}^{1,0}}&{\\geq}&{\\mathbf{P}^{2,0}}&{\\geq}&{\\mathbf{P}^{3,0}}&{\\geq}&{\\mathbf{P}^{4,0}}&{\\cdots}&\\\\ &&{\\vdots}&&{\\vdots}&&{\\vdots}&&{\\vdots}&&\\\\ &&{\\mathbf{P}^{1,1}}&{\\stackrel{>}{S C}}&{\\mathbf{P}^{2,1}}&{\\geq}&{\\mathbf{P}^{3,1}}&{\\geq}&{\\mathbf{P}^{4,1}}&{\\cdots}&\\\\ &&&{\\vdots}&&{\\vdots}&&{\\vdots}&&\\\\ &&&{\\mathbf{P}^{2,2}}&{\\stackrel{>}{S C}}&{\\mathbf{P}^{3,2}}&{\\geq}&{\\mathbf{P}^{4,2}}&{\\cdots}&&\\\\ &&&&{\\vdots}&&&{\\vdots}&&\\\\ &&&&{\\mathbf{P}^{3,3}}&{\\stackrel{>}{S C}}&{\\mathbf{P}^{4,3}}&{\\cdots}&&&\\\\ &&&&&{\\vdots}&&&\\\\ &&&&&&{\\mathbf{P}^{4,4}}&{\\cdots}&&&\\\\ &&&&&&&{\\ddots}&&\\end{array}\n$$", "text_format": "latex", "page_idx": 67}, {"type": "text", "text": "( In the above diagram, $\\mathbf{P}\\to\\mathbf{Q}$ indicates that $\\mathbf{Q}=M\\mathbf{P};\\mathbf{Q}\\succeq_{S C}\\mathbf{P}$ indicates $\\mathbf{P}=\\mathbf{P}_{\\mathrm{SC}}(\\mathbf{Q})$ ", "page_idx": 67}, {"type": "text", "text": "Indeed, the initial definition of $\\mathbf{P}^{0,0}$ and the relation diagram determine the collection of partitions completely. Let us summarise it as a statement: ", "page_idx": 67}, {"type": "text", "text": "Lemma L5.There exists a unique collection of partitions $\\{\\mathbf{P}^{r,s}\\}_{r\\geq s\\geq0}$ that satisies the following properties: For $0\\leq s<r$ ", "page_idx": 67}, {"type": "text", "text": "${\\cal I}.\\mathrm{{\\bf~P}}^{0,0}=\\big\\{\\{1\\},\\{2\\},\\ldots,\\{q\\}\\big\\}.$   \n2. Pr,s \u2264P1,0.   \n3. ${\\bf P}^{r,s+1}=M{\\bf P}^{r,s}$   \n4. $\\mathbf{P}^{r+1,s}\\leq\\mathbf{P}^{r,s}$   \n5. $\\mathbf P^{r+1,r}=\\mathbf P_{\\mathrm{SC}}(\\mathbf P^{r,r})$ ", "page_idx": 67}, {"type": "text", "text": "Proof of Lemma I.15. The proof is proceeded by induction. We assume that $\\mathbf{P}^{r,s}$ is constructed and uniquely determined for $0\\leq r<r_{0}$ and $0\\leq s\\leq r$ for some $r_{0}\\geq0$ so that it satisfies the properties described in the lemma. ", "page_idx": 67}, {"type": "text", "text": "We will define the partitions in the next column $\\{\\mathbf{P}^{r_{0},s}\\}_{s\\in[0,r_{0}]}$ by starting with ${\\bf P}^{r_{0},r_{0}-1}\\;=\\;$ $\\mathbf{P}_{\\mathrm{SC}}(\\mathbf{P}^{r_{0}-1,r_{0}-1})$ ", "page_idx": 67}, {"type": "text", "text": "Besides constructing the rest of partitions, we also need to show that these partitions satisfy the following list of conditions ( let us denote it as List A): For $s\\in[0,r_{0},-1]$ ", "page_idx": 67}, {"type": "text", "text": "1. $\\mathbf{P}^{r_{0},s}\\leq\\mathbf{P}^{1,0}$   \n2. $\\mathbf{P}^{r_{0},s}\\leq\\mathbf{P}^{r_{0}-1,s}$ for $s\\in[0,r_{0}-1]$   \n3. ${\\bf P}^{r_{0},s+1}=M{\\bf P}^{r_{0},s}$ ", "page_idx": 67}, {"type": "text", "text": "By definition of the map $\\mathbf{P}_{\\mathrm{SC}}$ , the first and second condition in the list are satisfied for $s=r_{0}-1$ Relying on $\\mathbf{P}^{r_{0},r_{0}-1}\\leq\\mathbf{\\dot{P}}^{1,0}$ , we can define ${\\bf P}^{r_{0},r_{0}}=M{\\bf P}^{r_{0},r_{0}-1}$ . Hence, the third condition in the list is also satisfied for $s=r_{0}-1$ ", "page_idx": 68}, {"type": "text", "text": "It remains to construct $\\mathbf{P}^{r_{0},s}$ for $s\\in[0,r_{0}-2]$ and they satisfy those 3 conditions in the list. This can be proceeded inductively starting from $s=r_{0}-2$ ", "page_idx": 68}, {"type": "text", "text": "Claim: For $s\\in[0,r_{0}-2]$ if $\\mathbf{P}^{r_{0},s+1}\\leq\\mathbf{P}^{r_{0}-1,s+1}$ , then there exists a unique partition $\\mathbf{P}^{r_{0},s}$ which satisfies the conditions in List A for $s$ ", "page_idx": 68}, {"type": "text", "text": "Suppose the Claim holds. With $\\mathbf{P}^{r_{0},r_{0}-1}\\leq\\mathbf{P}^{r_{0}-1,r_{0}-1}$ we could apply the claim repeatedly and the lemma follows. The rest of the proof is to show the claim holds. ", "page_idx": 68}, {"type": "text", "text": "Let us assume $\\mathbf{P}^{r_{0},s+1}\\,\\leq\\,\\mathbf{P}^{r_{0}-1,s+1}$ for some $s\\,\\in\\,[0,r_{0}\\,-\\,2]$ . First, from our assumption on $\\{\\mathbf{P}^{r,s}\\}$ for $0\\leq s\\leq r_{0}-1$ \uff0c ${\\bf P}^{r_{0}-1,s+1}=M{\\bf P}^{r_{0}-1,s}$ By Corollary I.14, $\\mathbf{P}^{r_{0}-1,s+1}\\leq\\mathbf{P}^{1,\\mathtt{l}}$ Since $\\ensuremath{\\mathbf{\\dot{P}}}^{r_{0},s+1}\\leq\\ensuremath{\\mathbf{P}}^{r_{0}-1,s+1}$ , we conclude that $\\mathbf{P}^{r_{0},s+1}\\leq\\mathbf{P}^{1,\\dot{1}}$ ", "page_idx": 68}, {"type": "text", "text": "Applying Corollary I.14 again, we know there exists an unique partition $\\mathbf{P}\\leq\\mathbf{P}^{1,0}$ so that ${\\bf P}^{r_{0},s+1}=$ $M\\mathbf{P}$ Weset $\\mathbf{P}^{r_{0},s}:=\\mathbf{P}$ In particular, the choice of $\\mathbf{P}^{r_{0},s}$ is unique in order to satisfy the first and third condition from the list. ", "page_idx": 68}, {"type": "text", "text": "It remains to show that $\\mathbf{P}^{r_{0},s}$ also satisfies the second condition in List A. Notice that from Corollary 1.14, the induced map of $M$ on partitions preserves $\\leq$ relation. Hence, $\\mathbf{P}^{r_{0},s+1}\\leq\\mathbf{P}^{r_{0}-1,s+1}$ implies $\\mathbf{P}^{r_{0}-1,s}\\leq\\mathbf{P}^{r_{0}-1,s}$ . Therefore, the claim holds. ", "page_idx": 68}, {"type": "text", "text": "Proof of Lemma I.4. We start with the proof on the $\\Rightarrow{}$ implication. Suppose $f$ is a function satisfied the first condition described in the lemma. ", "page_idx": 68}, {"type": "text", "text": "Since $f(X_{u})$ is a function of $X_{{\\mathfrak{p}}^{r}(u)}$ , this is equivalent to ", "page_idx": 68}, {"type": "equation", "text": "$$\n0=\\mathbb{E}\\Big[\\mathrm{Var}\\big[f(X_{u})\\,\\Big|\\,X_{{\\mathfrak{p}}^{r}(u)}\\big]\\Big].\n$$", "text_format": "latex", "page_idx": 68}, {"type": "text", "text": "Relying on the identity $\\operatorname{Var}[Y]=\\mathbb{E}\\operatorname{Var}[Y\\mid Z]+\\operatorname{Var}\\left[\\mathbb{E}[Y\\mid Z]\\right]$ and $(X_{\\mathfrak{p}^{r}(u)},X_{\\mathfrak{p}^{r-1}(u)},\\,\\cdot\\,\\cdot\\,,X_{u})$ .s a Markov Chain, ", "page_idx": 68}, {"type": "equation", "text": "$$\n\\mathbb{E}\\Big[\\mathrm{Var}\\big[f(X_{u})\\,\\Big|\\,X_{\\mathfrak{p}^{r}(u)}\\big]\\Big]=\\sum_{s=1}^{r}\\mathbb{E}\\Big[\\mathrm{Var}\\big[f(X_{u})\\,\\big|\\,X_{\\mathfrak{p}^{s}(u)}\\big]\\Big].\n$$", "text_format": "latex", "page_idx": 68}, {"type": "text", "text": "Hence, $\\mathbb{E}\\Big[\\mathrm{Var}\\big[f(X_{u})\\,\\big|\\,X_{\\mathfrak{p}^{s}(u)}\\big]\\Big]\\ =\\ 0$ for $s~\\in~[r]$ , which in turn implies $\\mathbb{E}\\big[f(X_{u})\\bigm|X_{{\\mathfrak{p}}^{s-1}(u)}\\big]$ conditioned on $X_{{\\mathfrak{p}}^{s}(u)}$ is a constant function for each $s\\in[r]$ . Equivalently, $M^{s-1}f$ takes the same value for all elements in each $S_{i}$ for $i\\in[q]$ ", "page_idx": 68}, {"type": "text", "text": "Claim: For $s\\;\\in\\;[r]$ ,if $f$ can expressed in the form $\\begin{array}{r}{f\\,=\\,\\sum_{P\\in\\mathbf{P}^{s-1,0}}c_{s-1,P}\\mathbf{1}_{P}}\\end{array}$ , then it can be expressed in the form $\\begin{array}{r}{f=\\sum_{P\\in\\mathbf{P}^{s,0}}c_{s,P}\\mathbf{1}_{P}}\\end{array}$ \uff1a ", "page_idx": 68}, {"type": "text", "text": "Clearly, if the claim holds, then we can apply it repeatedly to draw the conclusion that $f$ is a linear combinationof ${\\bf1}_{P}$ for $P\\in\\mathbf{P}^{r,0}$ ", "page_idx": 68}, {"type": "text", "text": "Now, we fix $s\\in[r]$ and assume $\\begin{array}{r}{f=\\sum_{P\\in\\mathbf{P}^{s-1,0}}c_{s-1,P}\\mathbf{1}_{P}.}\\end{array}$ Then, ", "page_idx": 68}, {"type": "equation", "text": "$$\n\\mathbb{E}\\big[f(X_{u})\\,\\big|\\,X_{\\mathfrak{p}^{s-1}(u)}=a\\big]=(M^{s-1}f)(a)=\\sum_{\\substack{P\\in\\mathbb{P}^{s-1,0}}}c_{s-1,P}M^{s-1}\\mathbf{1}_{P}=\\sum_{P\\in\\mathbb{P}^{s-1,0}}c_{s-1,P}\\mathbf{1}_{P^{s-1}(P)}.\n$$", "text_format": "latex", "page_idx": 68}, {"type": "text", "text": "where for each $P\\in\\mathbf{P}^{s-1,0}$ \uff0c $P^{s-1}\\,\\in\\,\\mathbf{P}^{s-1,s-1}$ is the corresponding part such that $M^{s-1}\\mathbf{1}_{P}=$ ${\\bf1}_{P^{s-1}}$ . In other words, $M^{s-1}f$ is a linear combination of ${\\bf1}_{P}$ for $P\\in\\mathbf{\\bar{P}}^{s-1,s-1}$ ", "page_idx": 68}, {"type": "text", "text": "Because $M^{s-1}f$ takes the same value not only for all elements in each $S_{i}$ for $i\\in[q]$ , but also for all elements in each $P$ for $P\\in\\mathbf{P}^{s-1,s-1}$ , it implies $M^{s-1}f$ takes the same value for all elements in each P' E Psc(Ps-1,s-1) = Ps,s-1. ", "page_idx": 68}, {"type": "text", "text": "Together with the fact that the induced map of $M$ on partitions preserves $\\leq$ relation, we conclude that $c_{s-1,P_{1}}=c_{s-1,P_{2}}$ for $P_{1},P_{2}\\in P^{s-1,0}$ whenever $P_{1}$ and $P_{2}$ are both contained in some $P\\in\\mathbf{P}^{s,0}$ ", "page_idx": 68}, {"type": "text", "text": "Equivalently, within each $P\\in\\mathbf{P}^{s,0}$ \uff0c $f$ is a constant function. Hence, we can express $f$ as a linear combination of ${\\bf1}_{P}$ for $P\\in\\mathbf{P}^{s,0}$ \uff1a ", "page_idx": 69}, {"type": "text", "text": "For the $\\Leftarrow$ implication, suppose $f$ is a linear combination of ${\\bf1}_{P}$ with $P\\in\\mathbf{P}^{r,0}$ ", "page_idx": 69}, {"type": "text", "text": "What we need to show isfor $s\\in[0,r-1],$ $M^{s}f$ takes the same values for all elements in each $S_{i}$ for $i\\in[q]$ . From the chain $\\mathbf{P}^{r,0}\\;{\\stackrel{\\rightharpoonup}{\\to}}\\;\\mathbf{P}^{r,1}\\;{\\stackrel{\\rightharpoonup}{\\to}}\\;\\cdots\\;\\rightarrow\\;\\mathbf{P}^{r,r}$ and by (108),for $s\\in[0,r-1]$ \uff0c $M^{s}f$ is a linearcombination of ${\\bf1}_{P}$ with $P\\in\\mathbf{P}^{r,s}$ ", "page_idx": 69}, {"type": "text", "text": "Since $\\mathbf P^{s+1,s}\\,=\\,\\mathbf P_{\\mathrm{SC}}(b P^{s,s})\\,\\le\\,\\mathbf P^{1,0}$ and $\\mathbf{P}^{s+1,s}\\;\\geq\\;\\cdot\\cdot\\;\\geq\\;\\mathbf{P}^{r,s}$ , we have $\\ensuremath{\\mathbf{P}}^{r,s}\\,\\leq\\,\\ensuremath{\\mathbf{P}}^{1,0}$ , which implies $M^{s}f$ takes the same values for all elements in each $S_{i}$ for $i\\in[q]$ . Therefore, the proof is completed. ", "page_idx": 69}, {"type": "text", "text": "Now, it remains to prove the second statement of the lemma. ", "page_idx": 69}, {"type": "text", "text": "First, if there exists $r\\,\\in\\,\\mathbb{N}$ such that $\\mathbf{P}^{r,0}$ is trivial. Then $\\mathbf{P}^{t,0}$ is also trivial for $t\\ >\\ r$ since $\\mathbf{P}^{t,0}\\leq\\mathbf{P}^{r,0}$ . Hence, it is enough to show the existence of $r$ such that $\\mathbf{P}^{r,0}$ is trivial. $\\mathbf{P}^{r,0}$ is trivial. ", "page_idx": 69}, {"type": "text", "text": "From the assumption on $M$ , we knew that the stationary distribution $\\pi$ of $M$ satisfies $\\operatorname*{min}_{i\\in[q]_{-}}\\pi(i)>$ 0 and $M^{r}$ converges entry-wise to the matrix whose row is identically $\\pi$ . Therefore, for sufficiently large $r$ $\\mathrm{min}_{i,j\\in[q]}\\overline{{(M^{r})_{i j}}}>0$ ", "page_idx": 69}, {"type": "text", "text": "Now , lt us fix such $r$ and assume $\\mathbf{P}^{r,0}$ is nt rial Letus expres $\\mathbf{P}^{r,s}=\\{P_{1}^{r,s},\\ldots,P_{k_{r}}^{r,s}\\}$ with for $s\\in[0,r]$ and $k_{r}\\geq2$ where the index is assiged so that $P_{k}^{r,s}=M P_{k}^{r,s-1}$ for $s\\in[r]$ and $k\\in[k_{r}]$ First, ", "page_idx": 69}, {"type": "equation", "text": "$$\n\\mathbf{1}_{P_{1}^{r,r}}=M^{r}\\mathbf{1}_{P_{1}^{r,0}}.\n$$", "text_format": "latex", "page_idx": 69}, {"type": "text", "text": "With $\\mathbf{1}_{P_{1}^{r,0}}$ is non-negative and not zero, every component of $M^{r}\\mathbf{1}_{P_{1}^{r,0}}$ is non-zero. This forces $P_{1}^{r,r}=\\bar{[}q]$ which contradictsto the assumption that ${\\mathbf{P}}^{r,r}$ is non-trivial. ", "page_idx": 69}, {"type": "text", "text": "1.2  A basis of functions from $[q]\\mapsto\\mathbb{R}$ according to the partition ", "text_level": 1, "page_idx": 69}, {"type": "text", "text": "From now on, let $r_{0}$ be the smallest non-negative integer such that $\\mathbf{P}^{r,0}$ is trivial. Consider the collection ", "page_idx": 69}, {"type": "equation", "text": "$$\n\\left\\{(P,s)\\,:\\,s\\in[0,r_{0}],P\\in{\\bf P}^{s,0}\\right\\}\n$$", "text_format": "latex", "page_idx": 69}, {"type": "text", "text": "We will establish an identification between elements of the set described above and words whose alphabet consists of non-negative integers. This identification is constructed through induction, following these steps: ", "page_idx": 69}, {"type": "text", "text": "\u00b7 First, we identify $([q],r_{0})$ with the word (1).   \n\u00b7 Assuming that elements in $\\{(P,s+1):P\\in\\mathbf{P}^{s+1,0}\\}$ have already been identified with unique words, we proceed as follows: For each $(P,s+1)$ , suppose there are $k$ pairs of $(P^{\\prime},s)$ such that $P^{\\prime}\\subseteq P$ . We identify these $k$ pairs with the words $\\left(\\mathsf{w},\\mathsf{i}\\right)$ for $\\mathsf{i}\\in[0,k-1]$ in any order of preference. For each $\\bar{(P^{\\prime},s)}$ , due to $\\mathbf{P}^{s,0}$ is a finer than or equal to $\\mathbf{P}^{s+1,0}$ there exists an unique pair $(P,s+1)$ so that $P^{\\prime}\\subseteq P$ . This guarantees the above procedure assigns each $(P^{\\prime},s)$ a unique word. ", "page_idx": 69}, {"type": "text", "text": "We denote the set of words described above as $\\widetilde{\\mathsf{W}}$ , and we adopt the notation $\\mathsf{w}\\sim(P,s)$ to indicate that $(P,s)$ is associated with the word w. For a given $\\mathsf{w}\\in\\widetilde{\\mathsf{W}}$ , we represent the corresponding pair as $(P_{\\mathsf{w}},r(\\mathsf{w}))$ , where $r(\\mathsf{w})=r_{0}+1-\\mathrm{len}(\\mathsf{w})$ ", "page_idx": 69}, {"type": "text", "text": "Now, let us make the following observations ", "page_idx": 69}, {"type": "text", "text": "1. If $\\mathsf{w}\\in\\widetilde{\\mathsf{W}}$ is a word with $\\mathrm{len}(\\mathsf{w})<r_{0}+1$ , then $(\\mathsf{w},0)\\in\\widetilde{\\mathsf{W}}$   \n2. Each $(P,s)$ corresponds to a word of length $r_{0}+1-s$   \n3. Suppose w, $\\mathsf{w}^{\\prime}\\in\\widetilde{\\mathsf{W}}$ such that w is a prefix of $\\mathsf{w}^{\\prime}$ . Then, $P_{\\mathsf{w}^{\\prime}}\\subseteq P_{\\mathsf{w}}$ ", "page_idx": 69}, {"type": "text", "text": "Let $T_{\\widetilde{\\mathsf{W}}}$ be the tree defined on W using the prefix relation. In this tree, edges are drawn from $w^{\\prime}$ to $w$ $r(\\mathsf{w}^{\\prime})=r(\\mathsf{w})+1$ and $P_{\\mathsf{w}}\\subseteq P_{\\mathsf{w^{\\prime}}}$ . Now, we will select $q$ parts from these elements $(P,s)$ based on their corresponding words. ", "page_idx": 70}, {"type": "text", "text": "Lemma I.16. Let $\\mathsf{W}\\subseteq\\widetilde{\\mathsf{W}}$ be the subcollection of words which end with a positive integer Then, $|\\mathsf{W}|=q$ ", "page_idx": 70}, {"type": "text", "text": "$q$ wordsin $\\widetilde{\\mathsf{W}}$ withlength $r+1$ sice $\\mathbf{P}^{0,0}=\\left\\{\\{i\\}\\right\\}_{i\\in[q]}$ $q$ parts. For each $i\\in[q]$ , let $\\mathsf{w}_{i}^{\\prime}$ be the word corresponding to $(\\{i\\},0)$ and let $\\mathsf{w}_{i}$ be the longest word ending with a positive integer so that is either a prefix of equals to $\\mathsf{w}_{i}^{\\prime}$ . This is well-defined since every word in W is a word starting with 1. ", "page_idx": 70}, {"type": "text", "text": "The proof of the lemma follows if we can show the following claim: $\\mathsf{W1},\\mathsf{W2},\\dotsc,\\mathsf{W}_{q}$ are distinct and are all words which ends with a positive integer. ", "page_idx": 70}, {"type": "text", "text": "To prove the claim, we begin by showing $\\mathsf{w}_{i}\\neq\\mathsf{w}_{j}$ whenever $i\\neq j$ . Suppose $\\mathsf{w}_{i}=\\mathsf{w}_{j}$ for some distinct pair of $i,j\\in[q]$ . Let $\\tilde{\\mathsf{W}}$ be the longest prefix of $\\mathsf{w}_{1}^{\\prime},\\mathsf{w}_{2}^{\\prime}$ , necessarily we have $\\mathsf{w}_{i}\\,=\\,\\mathsf{w}_{j}$ is either a prefix of $\\tilde{\\mathsf{W}}$ or W itself. Further, the length of $\\tilde{\\mathsf{W}}$ is less equal than $r$ , since otherwise it implies $\\mathsf{w}_{i}^{\\prime}=\\mathsf{w}_{j}^{\\prime}$ , which is a contradiction. ", "page_idx": 70}, {"type": "text", "text": "Now, let $(\\Tilde{\\boldsymbol{\\mathsf{w}}},\\boldsymbol{\\mathsf{e}}_{i})$ and $(\\Tilde{\\mathsf{w}},\\mathsf{e}_{j})$ be the two words which are prefix of $\\mathsf{w}_{i}^{\\prime}$ and $\\mathsf{w}_{j}^{\\prime}$ , respectively. From the definition that $\\tilde{\\mathsf{w}}$ is the longest common prefix, $\\mathsf{e}_{i}$ and $\\mathsf{e}_{j}$ are distinct non-negative integers. Since $\\boldsymbol{\\mathsf{W}}_{i}$ is a prefix of $(\\mathsf{w},\\mathsf{e}_{i})$ , it is necessary that ${\\sf e}_{i}=0$ , otherwise it violates the definition of $\\boldsymbol{\\mathsf{W}}_{i}$ . For the same reason, ${\\sf e}_{j}=0$ . Therefore, we reach a contradiction. ", "page_idx": 70}, {"type": "text", "text": "The remaining part to prove the claim is to show that $\\{\\mathsf{w}_{i}\\}_{i\\in[q]}$ are all the words in W ending with a positive integer. Suppose w is a word in which ends with a positive integer. If $\\mathsf{l e n}(\\mathsf{w})<r+1$ we can keep fill O until its length is $r+1$ and denote the resulting word by $\\mathsf{w}^{\\prime}$ . Observe that $\\mathsf{w}^{\\prime}\\in\\widetilde{\\mathsf{W}}$ Together with the length of $\\mathsf{w}^{\\prime}$ is $r+1$ , necessarily $\\mathsf{w}^{\\prime}=\\mathsf{w}_{i}^{\\prime}$ for some $i$ . Recall the definition of $\\mathsf{w}_{i}$ \uff0c we conclude $\\mathsf{w}=\\mathsf{w}_{i}$ . Therefore, the claim follows. ", "page_idx": 70}, {"type": "text", "text": "Lemma I.17. For any given $0\\,\\leq\\,r^{\\prime}\\,<\\,r$ ,suppose $\\mathsf{W}_{r^{\\prime}}:=\\{\\mathsf{w}\\in\\mathsf{W}\\ :\\ r(\\mathsf{w})=r^{\\prime}\\}$ is non-empty. Consider a linear combination $\\sum_{\\mathsf{w}\\in\\mathsf{W}_{r^{\\prime}}}\\,c_{\\mathsf{w}}\\mathbf{1}_{P_{\\mathsf{w}}}$ If it can be expressed as a linear combination of ${\\bf1}_{P}$ for $P\\in\\mathbf{P}^{r^{\\prime}+1,0}$ ,then $c_{\\mathsf{w}}$ are identically 0. ", "page_idx": 70}, {"type": "text", "text": "Proof. Let $\\mathsf{W}_{1},\\ldots,\\mathsf{W}_{k_{0}}$ be the words with $r(\\mathsf{w}_{k})=r^{\\prime}+1$ and corresponding to each part of $\\mathbf{P}^{r^{\\prime}+1,0}$ Then, the words that corresponds to pairs of the form $(P,r^{\\prime})$ with $P\\in\\mathbf{P}^{r^{\\prime},0}$ are ", "page_idx": 70}, {"type": "equation", "text": "$$\n\\left\\{\\left(\\mathsf{w}_{k},\\mathsf{t}\\right)\\right\\}_{k\\in[k_{0}],\\mathsf{t}\\in[0,\\mathsf{t}_{k}]}\n$$", "text_format": "latex", "page_idx": 70}, {"type": "text", "text": "where $\\mathtt{t}_{k}$ are non-negative integers. Now, we express ", "page_idx": 70}, {"type": "equation", "text": "$$\n\\sum_{\\mathbf{w}\\in\\mathbf{W}_{r^{\\prime}}}c_{\\mathbf{w}}\\mathbf{1}_{P_{\\mathrm{w}}}=\\sum_{k\\in[k_{0}]}\\sum_{\\mathbf{t}\\in[\\mathbf{t}_{k}]}c_{(\\mathbf{w}_{k},\\mathbf{t})}\\,\\mathbf{1}_{P_{(\\mathbf{w}_{k},\\mathbf{t})}}\\,.\n$$", "text_format": "latex", "page_idx": 70}, {"type": "text", "text": "For each $k\\in[k_{0}]$ and any $\\theta\\in P_{\\mathsf{w}_{k}}$ , we have ", "page_idx": 70}, {"type": "equation", "text": "$$\n\\sum_{k^{\\prime}\\in[k_{0}]}\\sum_{\\mathfrak{t}\\in[\\mathfrak{t}_{k^{\\prime}}]}c_{(\\mathfrak{w}_{k^{\\prime}},\\mathfrak{t})}\\mathbf{1}_{P_{(\\mathfrak{w}_{k^{\\prime}},\\mathfrak{t})}}(\\theta)=\\sum_{\\mathfrak{t}\\in[\\mathfrak{t}_{k}]}c_{(\\mathfrak{w}_{k},\\mathfrak{t})}\\mathbf{1}_{P_{(\\mathfrak{w}_{k},\\mathfrak{t})}}(\\theta).\n$$", "text_format": "latex", "page_idx": 70}, {"type": "text", "text": "Therefore, $\\sum_{\\mathsf{w}\\in\\mathsf{W}_{r^{\\prime}}}\\,c_{\\mathsf{w}}\\mathbf{1}_{P_{\\mathsf{w}}}$ canbexpressed as $\\textstyle\\sum_{k\\in[k_{0}]}c_{\\mathsf{w}_{k}}\\mathbf{1}_{P_{\\mathsf{w}_{k}}}$ ifand olyif $\\begin{array}{r}{\\sum_{\\mathbf{t}\\in[\\mathbf{t}_{k}]}c_{(\\mathbf{w},\\mathbf{t})}\\mathbf{1}_{P_{(\\mathbf{w},\\mathbf{t})}}}\\end{array}$ is a constant on Pwk \\* ", "page_idx": 70}, {"type": "text", "text": "For each $k\\in[k_{0}]$ , let $\\theta\\in P_{(\\mathsf{w}_{k},0)}$ , then we have ", "page_idx": 70}, {"type": "equation", "text": "$$\n\\sum_{k^{\\prime}\\in[k_{0}]}\\sum_{\\mathfrak{t}\\in[\\mathfrak{t}_{k^{\\prime}}]}c_{(\\mathfrak{w}_{k^{\\prime}},\\mathfrak{t})}\\mathbf{1}_{P_{(\\mathfrak{w}_{k^{\\prime}},\\mathfrak{t})}}(\\theta)=\\sum_{\\mathfrak{t}\\in[\\mathfrak{t}_{k}]}c_{(\\mathfrak{w}_{k},\\mathfrak{t})}\\mathbf{1}_{P_{(\\mathfrak{w}_{k},\\mathfrak{t})}}(\\theta)=0,\n$$", "text_format": "latex", "page_idx": 70}, {"type": "text", "text": "which forces $c_{(\\mathsf{w}_{k},\\mathsf{t})}=0$ for every $\\mathfrak{t}>0$ (if it exists). Therefore, the proof is complete. ", "page_idx": 70}, {"type": "text", "text": "Definition I.18. Let $\\mathfrak{B}:=\\{\\xi_{\\mathsf{w}}\\}_{\\mathsf{w}\\in\\mathsf{W}}$ be a collection of q functions from $[q]$ to $\\mathbb{R}$ defined as follows: ", "page_idx": 70}, {"type": "text", "text": "1. If $\\mathsf{w}=(1)$ \uff0c $\\xi_{\\mathsf{w}}=\\mathbf{1}_{P_{\\mathsf{w}}}=1$  \n2. $U\\mathsf{W}\\neq(1)$ \uff0c", "page_idx": 71}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\xi_{\\mathsf{w}}(\\theta):=\\mathbf{1}_{P_{\\mathrm{w}}}(\\theta)-\\mathbb{E}_{Y\\sim\\pi}\\mathbf{1}_{P_{\\mathrm{w}}}(Y).}\\end{array}\n$$", "text_format": "latex", "page_idx": 71}, {"type": "text", "text": "Remark I.19. The remaining goal in this subsection is to show that $\\mathfrak{B}$ is the desired basis described in Proposition I.5. We also remark that the first two properties stated in Proposition I.5 are already satisfied with this construction: $\\mathrm{argmax}_{\\mathsf{w}\\in\\mathsf{W}}r(\\mathsf{w})=(1)$ with $\\xi_{(1)}=\\mathbf{1}_{[q]}=1$ $\\xi_{\\mathsf{W}}(X_{u})$ is a function of $X_{v}$ where $v={\\mathfrak{p}}^{r(\\mathsf{w})}(u)$ ", "page_idx": 71}, {"type": "text", "text": "Lemma I.20. The collection $\\mathfrak{B}$ forms a linear basis for functions from [q] to $\\mathbb{R}$ ", "page_idx": 71}, {"type": "text", "text": "Proof. Since there are exactly $q$ functions, our goal is to show ", "page_idx": 71}, {"type": "equation", "text": "$$\n\\mathbb{R}^{[q]}=\\operatorname{span}(\\{\\xi_{\\mathsf{w}}\\}_{\\mathsf{w}\\in\\mathsf{W}}),\n$$", "text_format": "latex", "page_idx": 71}, {"type": "text", "text": "and the R.H.S. is the same as $\\operatorname{span}(\\{\\mathbf{1}_{P_{w}}\\}_{\\mathbf{w}\\in\\mathsf{W}})$ . It suffices to show for each $i\\in[q],\\,{\\mathbf1}_{\\{i\\}}$ can be expressed as a linear combination of ${\\bf1}_{P_{w}}$ with $\\mathsf{w}\\in\\mathsf{W}$ ", "page_idx": 71}, {"type": "text", "text": "To prove this statement, we will use induction, showing that for $s$ from $r_{0}$ to 0, each ${\\bf1}_{P}$ with $P\\in\\mathbf{P}^{s,0}$ can be expressed as a linear combination of of ${\\bf1}_{P_{w}}$ with $\\mathsf{w}\\in\\mathsf{W}$ Since $\\mathbf{P}^{0,0}=\\left\\{\\{1\\},\\ldots,\\{q\\}\\right\\}$ , the proof follows once we establish this inductive statement. ", "page_idx": 71}, {"type": "text", "text": "First, when $s=r$ ince $\\mathbf{1}_{[q]}$ is the only part in $\\mathbf{P}^{r_{0},0}$ and $[q]=P_{(1)}$ , the statement holds for $s=r_{0}$ ", "page_idx": 71}, {"type": "text", "text": "Now, suppose the inductive hypothesis holds for $s\\!+\\!1$ with $s<r_{0}$ . Pick any $P\\in\\mathbf{P}^{s,0}$ , let $\\boldsymbol{\\mathsf{w}}=\\left(\\mathsf{w}^{\\prime},\\mathsf{t}\\right)$ be the word associate with $(P,s)$ . If $\\mathtt{t}=0$ , then ", "page_idx": 71}, {"type": "equation", "text": "$$\n\\mathbf{1}_{P}=\\mathbf{1}_{P_{w^{\\prime}}}-\\sum_{P^{\\prime\\prime}}\\mathbf{1}_{P^{\\prime\\prime}}\n$$", "text_format": "latex", "page_idx": 71}, {"type": "text", "text": "where the sum is taken over all parts $P^{\\prime\\prime}\\in\\mathbf{P}^{s,0}\\backslash\\{P\\}$ contained in $P_{\\mathsf{w^{\\prime}}}$ . Each $P^{\\prime\\prime}$ in the summation (if it exists) must corresponds to a word of the form $(\\bar{\\mathsf{w^{\\prime}}},\\mathsf{t^{\\prime\\prime}})$ with $\\sf t^{\\prime\\prime}>0$ , or equivalently $(\\mathsf{w}^{\\prime},\\mathsf{t}^{\\prime\\prime})\\in\\mathsf{W}$ From the induction hypothesis, $\\mathbf{1}_{P_{\\mathrm{w^{\\prime}}}}$ is a linear combination of ${\\bf1}_{P_{w}}$ with $\\textsf{w}\\in\\textsf{W}$ .Therefore, we conclude that ${\\bf1}_{P}$ is also a linear combination of ${\\bf1}_{P_{w}}$ with $\\textsf{w}\\in\\textsf{W}$ . If $\\mathrm{~t~}>\\mathrm{~0~}$ , then $\\textsf{w}\\in\\textsf{W}$ , and the same conclusion follows immediately. With no restriction on the choice of $P$ , the induction hypothesis holds for $s$ as well. ", "page_idx": 71}, {"type": "text", "text": "Therefore, the lemma follows from induction. ", "page_idx": 71}, {"type": "text", "text": "Lemma I.21. For any given $0\\,\\leq\\,r^{\\prime}\\,<\\,r$ suppose $\\mathsf{W}_{r^{\\prime}}:=\\{\\mathsf{w}\\in\\mathsf{W}\\ :\\ r(\\mathsf{w})=r^{\\prime}\\}$ is non-empty. Then, there exists a constant $C\\geq1$ (which could depends on $M$ ) such that the following holds: Let $u,v\\in T$ be two vertices such that $v={\\mathfrak{p}}^{r^{\\prime}}(u)$ .We have ", "page_idx": 71}, {"type": "equation", "text": "$$\n\\mathbb{E}\\mathrm{Var}\\Big[\\mathbb{E}\\big[\\sum_{\\mathsf{w}\\in\\mathsf{W}_{r^{\\prime}}}c_{\\mathsf{w}}\\xi_{\\mathsf{w}}(X_{u})\\,\\big|\\,X_{v}\\big]\\,\\Big|\\,X_{\\mathsf{p}(v)}\\Big]\\geq\\frac{1}{C}\\big(\\operatorname*{max}_{\\mathsf{w}\\in\\mathsf{W}_{r^{\\prime}}}|c_{\\mathsf{w}}|\\big)^{2}.\n$$", "text_format": "latex", "page_idx": 71}, {"type": "text", "text": "Proof. First, both sides of (109) scale by a factor $h^{2}$ if every term $c_{\\mathsf{w}}$ is multiplied by $h\\in\\mathbb{R}$ .Hence, it suffices to establish the inequality in the case ", "page_idx": 71}, {"type": "equation", "text": "$$\n\\operatorname*{max}_{\\mathsf{w}\\in\\mathsf{W}_{r^{\\prime}}}|c_{\\mathsf{w}}|=1.\n$$", "text_format": "latex", "page_idx": 71}, {"type": "text", "text": "Given this, consider the set $\\begin{array}{r}{\\big\\{(c_{\\mathsf{w}})_{\\mathsf{w}\\in\\mathsf{W}_{r^{\\prime}}}\\,:\\,\\operatorname*{max}_{\\mathsf{w}\\in\\mathsf{W}_{r^{\\prime}}}|c_{\\mathsf{w}}|=1\\big\\}\\subseteq\\mathbb{R}^{\\mathsf{W}_{r^{\\prime}}}}\\end{array}$ . It is compact set and ", "page_idx": 71}, {"type": "equation", "text": "$$\n\\mathbb{E}\\mathrm{Var}\\Big[\\mathbb{E}\\big[\\sum_{\\mathfrak{w}\\in\\mathsf{W}_{r^{\\prime}}}c_{\\mathsf{w}}\\xi_{\\mathsf{w}}(X_{u})\\,\\big|\\,X_{v}\\big]\\,\\Big|\\,X_{\\mathfrak{p}(v)}\\Big]\n$$", "text_format": "latex", "page_idx": 71}, {"type": "text", "text": "is continuous in $(c_{\\mathsf{w}})_{\\mathsf{w}\\in\\mathsf{W}_{r^{\\prime}}}$ (it is a polynomial of $c_{w}$ ). By a compact argument one can estalbish the existence of $C\\geq1$ described in the lemma if for every $(c_{\\mathsf{w}})_{\\mathsf{w}\\in\\mathsf{W}_{r^{\\prime}}}$ with $\\mathrm{max}_{\\mathsf{w}\\in\\mathsf{W}_{r^{\\prime}}}\\left|c_{\\mathsf{w}}\\right|=1$ ", "page_idx": 71}, {"type": "equation", "text": "$$\n\\mathbb{E}\\mathrm{Var}\\Big[\\mathbb{E}\\big[\\sum_{\\mathbf{w}\\in\\mathsf{W}_{r^{\\prime}}}c_{\\mathsf{w}}\\xi_{\\mathbf{w}}(X_{u})\\,\\big|\\,X_{v}\\big]\\,\\Big|\\,X_{\\mathsf{p}(v)}\\Big]>0.\n$$", "text_format": "latex", "page_idx": 71}, {"type": "text", "text": "We can simplify this by observing that ", "page_idx": 72}, {"type": "equation", "text": "$$\n\\sum_{\\mathsf{w}\\in\\mathsf{W}_{r^{\\prime}}}c_{\\mathsf{w}}\\xi_{\\mathsf{w}}=\\sum_{\\mathsf{w}\\in\\mathsf{W}_{r^{\\prime}}}c_{\\mathsf{w}}\\mathbf{1}_{P_{\\mathsf{w}}}+\\mathrm{constant},\n$$", "text_format": "latex", "page_idx": 72}, {"type": "text", "text": "and hence, ", "page_idx": 72}, {"type": "text", "text": "$\\begin{array}{r l r}{\\lefteqn{\\mathbb{E}\\mathrm{Var}\\Big[\\mathbb{E}\\big[\\sum_{\\mathbf{w}\\in\\mathsf{W}_{r^{\\prime}}}c_{\\mathsf{w}}\\xi_{\\mathsf{w}}(X_{u})\\,\\big|\\,X_{v}\\big]\\,\\Big|\\,X_{\\mathsf{p}(v)}\\Big]=\\mathbb{E}\\mathrm{Var}\\Big[\\mathbb{E}\\big[\\sum_{\\mathbf{w}\\in\\mathsf{W}_{r^{\\prime}}}c_{\\mathsf{w}}\\mathbf{1}_{P_{\\mathsf{w}}}(X_{u})\\,\\big|\\,X_{v}\\big]\\,\\Big|\\,X_{\\mathsf{p}(v)}\\Big]}}\\\\ &{}&{\\;\\;\\;\\;\\;\\;\\;\\;=\\mathbb{E}\\mathrm{Var}\\Big[\\sum_{\\mathbf{w}\\in\\mathsf{W}_{r^{\\prime}}}c_{\\mathsf{w}}\\mathbf{1}_{P_{\\mathsf{w}}}(X_{u})\\,\\Big|\\,X_{\\mathsf{p}(v)}\\Big],\\,\\,\\,}\\end{array}$ (111 where the second equalityfollows from that $\\textstyle\\sum_{\\mathsf{w}\\in\\mathsf{W}_{r^{\\prime}}}c_{\\mathsf{w}}\\mathbf{1}_{P_{\\mathsf{w}}}(X_{u})$ is a function of $X_{v}$ by Lemma I.4. Moreover, t show $\\begin{array}{r}{\\mathbb{E}\\mathrm{Var}\\Big[\\sum_{\\mathbf{w}\\in\\mathsf{W}_{r^{\\prime}}}c_{\\mathbf{w}}\\mathbf{1}_{P_{\\mathbf{w}}}(X_{u})\\Bigm|X_{\\mathfrak{p}(v)}\\Big]>0.}\\end{array}$ thisis the same as showing $\\sum_{\\mathsf{w}\\in\\mathsf{W}_{r^{\\prime}}}c_{\\mathsf{w}}\\mathbf{1}_{P_{\\mathsf{w}}}(X_{u})$ ", "page_idx": 72}, {"type": "text", "text": "is not a function of $X_{{\\mathfrak{p}}(v)}$ . By Lemma I.4, this is equivalent to show $\\sum_{\\mathsf{w}\\in\\mathsf{W}_{r^{\\prime}}}c_{\\mathsf{w}}\\mathbf{1}_{P_{\\mathsf{w}}}$ is not alinear combination of ${\\bf1}_{P}$ for $P\\,\\in\\,\\mathbf{P}^{r^{\\prime}+1}$ , which was proven in Lemma I.17. Therefore, the proof is complete. ", "page_idx": 72}, {"type": "text", "text": "Lemma I.22. For any given $0\\leq\\,r^{\\prime}<\\,r_{\\!}$ suppose $\\mathsf{W}_{<r^{\\prime}}:=\\{\\mathsf{w}\\in\\mathsf{W}\\,:\\,r(\\mathsf{w})<r^{\\prime}\\}$ is non-empty. Then, there exists $C\\geq1$ so that the following holds: Let $u,v\\in T$ be two nodes such that $v={\\mathfrak{p}}^{r^{\\prime}}(u)$ We have ", "page_idx": 72}, {"type": "equation", "text": "$$\n\\mathbb{E}\\mathrm{Var}\\Big[\\mathbb{E}\\big[\\sum_{\\mathfrak{w}\\in\\mathbb{W}_{<r^{\\prime}}}c_{\\mathfrak{w}}\\xi_{\\mathfrak{w}}(X_{u})\\,\\big|\\,X_{v}\\big]\\,\\Big|\\,X_{\\mathfrak{p}(v)}\\Big]\\leq C\\big(\\operatorname*{max}_{\\mathfrak{w}\\in\\mathbb{W}_{<r^{\\prime}}}|c_{\\mathfrak{w}}|\\big)^{2}.\n$$", "text_format": "latex", "page_idx": 72}, {"type": "text", "text": "Proof. The proof is more straightforward compared to the arguments presented in the proof of Lemma 1.21. First, both sides of (112) scale by a factor $h^{2}$ if wescaled each $c_{\\mathsf{w}}$ by $h\\in\\mathbb{R}$ .Therefore, it suffices to establish the inequality when ", "page_idx": 72}, {"type": "equation", "text": "$$\n\\mathbb{E}\\mathrm{Var}\\Big[\\mathbb{E}\\big[\\sum_{\\mathfrak{w}\\in\\mathsf{W}_{<r^{\\prime}}}c_{\\mathfrak{w}}\\xi_{\\mathfrak{w}}(X_{u})\\,\\big|\\,X_{v}\\big]\\,\\Big|\\,X_{\\mathfrak{p}(v)}\\Big]=1.\n$$", "text_format": "latex", "page_idx": 72}, {"type": "text", "text": "If there is no $(c_{\\mathsf{w}})_{\\mathsf{w}\\in\\mathsf{W}_{<r^{\\prime}}}$ satisfying the above condition, then the proof is completed. Now we assume this set is not empty. Notice that $\\begin{array}{r}{\\mathbb{E}\\mathrm{Var}\\Big[\\mathbb{E}\\big[\\sum_{\\mathfrak{w}\\in\\mathsf{W}_{<r^{\\prime}}}c_{\\mathsf{w}}\\xi_{\\mathsf{w}}(X_{u})\\,\\big|\\,X_{v}\\big]\\,\\Big|\\,X_{\\mathfrak{p}(v)}\\Big]}\\end{array}$ is a continuous function of $(c_{\\mathsf{w}})_{\\mathsf{w}\\in\\mathsf{W}_{<r^{\\prime}}}$ which takes value 0 when $(c_{\\mathsf{w}})_{\\mathsf{w}\\in\\mathsf{W}_{<r^{\\prime}}}\\,=\\,\\vec{0}$ . Thus, there is an open ball $B\\subseteq\\mathbb{R}^{\\mathsf{W}_{<r^{\\prime}}}$ centered at $\\vec{0}$ such that for $(c_{\\mathsf{w}})_{\\mathsf{w}\\in\\mathsf{W}_{r^{\\prime}}}\\in B$ ", "page_idx": 72}, {"type": "equation", "text": "$$\n\\mathbb{E}\\mathrm{Var}\\Big[\\mathbb{E}\\big[\\sum_{\\mathfrak{w}\\in\\mathsf{W}_{<r^{\\prime}}}c_{\\mathfrak{w}}\\xi_{\\mathfrak{w}}(X_{u})\\,\\big|\\,X_{v}\\big]\\,\\Big|\\,X_{\\mathfrak{p}(v)}\\Big]<1.\n$$", "text_format": "latex", "page_idx": 72}, {"type": "text", "text": "On the other hand, by choosing $C$ sufficiently large, the set ", "page_idx": 72}, {"type": "equation", "text": "$$\n\\Big\\{(c_{\\mathsf{w}})_{\\mathsf{w}\\in\\mathsf{W}_{r^{\\prime}}}\\,:\\,(\\operatorname*{max}_{\\mathsf{w}\\in\\mathsf{W}_{<r^{\\prime}}}|c_{\\mathsf{w}}|)^{2}\\leq1/C\\Big\\},\n$$", "text_format": "latex", "page_idx": 72}, {"type": "text", "text": "which is the cube of side length $2/C^{1/2}$ centered at $\\vec{0}$ , is contained in $B$ .Therefore, the lemma follows. \u53e3 ", "page_idx": 72}, {"type": "text", "text": "Proof of Proposition I.5. From Remark I1.19 and Lemma I.20, it remains to show $\\mathfrak{B}$ satisfies the last 3 properties stated in the Proposition. ", "page_idx": 72}, {"type": "text", "text": "As for the third property, otice that the varian f $\\textstyle\\sum_{\\mathsf{w}\\in\\mathsf{W}}c_{\\mathsf{w}}\\xi_{w}(X_{u})$ is not zero as long as $c_{\\mathsf{w}}$ are not identically O for $\\mathsf{w}\\neq\\mathsf{w}_{0}$ . Following the same arguments in the proof of Lemma I.21, the property follows if $C\\geq1$ is sufficiently large. ", "page_idx": 72}, {"type": "text", "text": "The last two follows by applying Lemma I.21 and Lemma I.22 to every $0\\leq r^{\\prime}<r$ and choosing the constant $C$ can be chosen to be the maximum of those constants $C$ from the two lemmas. ", "page_idx": 72}, {"type": "text", "text": "1.3  Proof of Proposition I.1 ", "text_level": 1, "page_idx": 73}, {"type": "text", "text": "In this subsection, we consider soley degree 1 polynomial of the leave values. ", "page_idx": 73}, {"type": "text", "text": "Definition I.23. For any given $\\rho^{\\prime}\\in T$ and a degree-1 polynomial $f$ of $\\{x_{u}\\}_{u\\in L_{\\rho^{\\prime}}}$ , the function can be expressed uniquely in the form ", "page_idx": 73}, {"type": "equation", "text": "$$\nf(x)=\\sum_{\\substack{\\mathsf{w}\\in\\mathsf{W},\\,u\\in L_{\\rho^{\\prime}}}}c_{\\mathsf{w},u}\\xi_{\\mathsf{w}}(x_{u})\n$$", "text_format": "latex", "page_idx": 73}, {"type": "text", "text": "where $\\{\\xi_{w}\\}_{w\\in\\mathsf{W}}$ is the basis introduced in Proposition 1.5. ", "page_idx": 73}, {"type": "text", "text": "For $u\\,\\in\\,T_{\\rho^{\\prime}}$ ,let $\\begin{array}{r}{f_{u}(x)\\,:=\\,\\sum_{\\mathsf{w}\\in\\mathsf{W}\\,,\\,v\\in L_{u}}c_{\\mathsf{w},v}\\xi_{\\mathsf{w}}(x_{v})}\\end{array}$ .Observe that from this definition, for each $0\\leq l\\leq r$ ", "page_idx": 73}, {"type": "equation", "text": "$$\nf(x)=\\sum_{u\\in T_{\\rho^{\\prime}}:\\,\\operatorname{h}(u)=l}f_{u}(x).\n$$", "text_format": "latex", "page_idx": 73}, {"type": "text", "text": "Further, for $u\\in T_{\\rho^{\\prime}}\\backslash L_{\\rho^{\\prime}}$ , let ", "page_idx": 73}, {"type": "equation", "text": "$$\nc_{\\mathsf{w},u}:=\\sum_{v\\in L_{u}}c_{\\mathsf{w},v}.\n$$", "text_format": "latex", "page_idx": 73}, {"type": "text", "text": "Remark I.24. From the definition above, for each $\\rho^{\\prime}\\in T$ and degree-1 polynomial $f$ of variables $\\{x_{u}\\}_{u\\in L_{\\rho^{\\prime}}}$ ,wehave ", "page_idx": 73}, {"type": "equation", "text": "$$\n\\forall u\\in T_{\\rho^{\\prime}},\\,\\forall x\\in\\mathbb{R}^{q},\\,\\,(\\mathbb{E}_{u}f_{u})(x)=\\sum_{\\mathsf{w}}c_{\\mathsf{w},u}\\xi_{\\mathsf{w}}^{(l)}(x_{u}),\n$$", "text_format": "latex", "page_idx": 73}, {"type": "text", "text": "where $\\xi_{\\mathsf{w}}^{(l)}(\\theta)$ is introduced in Remark 1.6. ", "page_idx": 73}, {"type": "text", "text": "Proposition I.25. There exists a constant $C=C(M,d)\\geq1$ so that the following holds: Suppose ", "page_idx": 73}, {"type": "equation", "text": "$$\nf(x)=\\sum_{u\\in L_{\\rho^{\\prime}},\\,\\mathsf{w}\\in\\mathsf{W}}c_{\\mathsf{w},u}\\xi(x_{u})\n$$", "text_format": "latex", "page_idx": 73}, {"type": "text", "text": "where $\\rho^{\\prime}\\in T$ is a node satisfying $\\mathrm{h}(\\rho^{\\prime})\\leq r_{0}$ and ", "page_idx": 73}, {"type": "equation", "text": "$$\nc_{\\mathsf{w},u}=c_{\\mathsf{w},v}\n$$", "text_format": "latex", "page_idx": 73}, {"type": "text", "text": "for $u,v\\in L_{\\rho^{\\prime}}$ satisfying $\\operatorname{h}(\\rho(u,v))\\leq r(\\mathsf{w}).$ where $\\rho(u,v)$ is the lowest common ancestor of u and $v$ Then, ", "page_idx": 73}, {"type": "equation", "text": "$$\n\\sum_{u\\in L_{\\rho^{\\prime}}}{\\mathrm{Var}}[f_{u}(X)]\\leq C R^{3}\\mathbb{E}{\\mathrm{Var}}[f(X)\\,|\\,X_{\\rho^{\\prime}}]\n$$", "text_format": "latex", "page_idx": 73}, {"type": "text", "text": "If Proposition I.25 is proven, then Proposition I.1 follows as a corollary: ", "page_idx": 73}, {"type": "text", "text": "Proof of Proposition I.1. Reduction to $\\mathrm{h}(\\rho^{\\prime})\\leq r_{0}$ : Without loss of generality, it is sufficient to consider degree 1 functions of $L$ , rather than degree 1 functions of variables in $D_{k}(u)$ for some $u$ in the tree and $0\\leq k\\leq\\mathrm{h}(u)$ ", "page_idx": 73}, {"type": "text", "text": "Recall that ", "page_idx": 73}, {"type": "equation", "text": "$$\nD_{r_{0}}(\\rho)=\\{w\\in T:\\,\\operatorname{h}(w)=r_{0}\\}.\n$$", "text_format": "latex", "page_idx": 73}, {"type": "text", "text": "We know that we can express $\\begin{array}{r}{f(x)=\\sum_{w\\in D_{r_{0}}(\\rho)}f_{w}(x)}\\end{array}$ so that eachfthem isadegree-1 polynmial with variables $\\{x_{u}\\}_{u\\in L_{w}}$ ", "page_idx": 73}, {"type": "text", "text": "Together with the variance decomposition for degree-1 polynomials (See Lemma C.1) ", "page_idx": 73}, {"type": "equation", "text": "$$\n\\operatorname{Var}[f(X)]\\geq\\sum_{w\\in D_{r_{0}}(\\rho)}\\mathbb{E}\\mathrm{Var}[f_{w}(X_{w})\\,|\\,X_{w}],\n$$", "text_format": "latex", "page_idx": 73}, {"type": "text", "text": "it suffces to prove the same statement for degree-1 polynomials of $x_{u}$ with $u\\in L_{\\rho^{\\prime}}$ for $\\rho^{\\prime}$ satisfying $\\mathrm{h}(\\rho^{\\prime})\\leq r_{0}$ ", "page_idx": 73}, {"type": "text", "text": "Now, we fx such $\\rho^{\\prime}$ and consider ", "page_idx": 74}, {"type": "equation", "text": "$$\nf(x)=\\sum_{\\mathsf{w},\\boldsymbol{u}\\in L_{\\rho^{\\prime}}}c_{\\mathsf{w},\\boldsymbol{u}}\\xi_{\\mathsf{w}}(x_{\\boldsymbol{u}}).\n$$", "text_format": "latex", "page_idx": 74}, {"type": "text", "text": "Averaging the Coeficients: For each $\\textsf{w}\\in\\textsf{W}$ and for each $u\\,\\in\\,D_{r(\\mathsf{w})}(\\rho^{\\prime})$ ,weknow that for any ${\\overline{{v_{1},v_{2}\\in L_{u}}}}$ ", "page_idx": 74}, {"type": "equation", "text": "$$\n\\xi_{\\mathsf{w}}(X_{v_{1}})=\\xi_{\\mathsf{w}}(X_{v_{2}})\n$$", "text_format": "latex", "page_idx": 74}, {"type": "text", "text": "almost surely. As a consequcne, we have ", "page_idx": 74}, {"type": "equation", "text": "$$\n\\sum_{v\\in L_{u}}c_{\\mathsf{w},v}\\xi_{\\mathsf{w}}(X_{v})=\\sum_{v\\in L_{u}}\\frac{\\sum_{v\\in L_{u}}c_{\\mathsf{w},v}}{|L_{u}|}\\xi_{\\mathsf{w}}(X_{v})\n$$", "text_format": "latex", "page_idx": 74}, {"type": "text", "text": "almost surely. Now, we repeat this averaging process for each $\\mathsf{w}\\in\\mathsf{W}$ and for each $u\\in D_{r(\\mathsf{w})}(\\rho^{\\prime})$ We denote the resulting function by $\\tilde{f}$ .While $\\tilde{f}$ and $f$ may not be the same function, ${\\tilde{f}}(X)=f(X)$ almost surely. On the other hand, $\\tilde{f}$ is a function which satisfies the condition in Proposition I.25. Following from the proposition, we have ", "page_idx": 74}, {"type": "equation", "text": "$$\n\\sum_{u\\in L}\\mathbb{E}{\\mathrm{Var}}[{\\tilde{f}}_{u}(X)]\\leq C R^{3}\\mathbb{E}{\\mathrm{Var}}[{\\tilde{f}}(X)\\,|\\,X_{\\rho^{\\prime}}]=C R^{3}{\\mathrm{Var}}[f(X)\\,|\\,X_{\\rho^{\\prime}}].\n$$", "text_format": "latex", "page_idx": 74}, {"type": "text", "text": "The proof is complete. ", "page_idx": 74}, {"type": "text", "text": "Let us begin with an intermediate step toward the proof of the Proposition I.25. ", "page_idx": 74}, {"type": "text", "text": "Lemma I.26. Suppose $f$ is a function described in Definition 1.23. For any given $1\\leq l<r$ such that $\\mathsf{W}_{l}:=\\{\\mathsf{w}\\in\\mathsf{W}\\,:\\,r(\\mathsf{w})=l\\}$ is non-empty. Let $u\\in T_{\\rho^{\\prime}}$ with $\\mathrm{h}(u)=r(\\mathsf{w})$ suppose ", "page_idx": 74}, {"type": "equation", "text": "$$\nt=\\operatorname*{max}_{\\mathsf{w}\\in\\mathsf{W}_{l}}\\left|c_{\\mathsf{w},u}\\right|>0.\n$$", "text_format": "latex", "page_idx": 74}, {"type": "text", "text": "Then one of the following statement holds: ", "page_idx": 74}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\operatorname*{max}_{\\mathsf{w}\\in\\mathsf{W}_{<l}}|c_{\\mathsf{w},u}|\\geq\\frac{\\sqrt{\\pi_{\\operatorname*{min}}}}{2C_{0}}t.}\\end{array}\n$$", "text_format": "latex", "page_idx": 74}, {"type": "text", "text": "Here, $C_{0}\\geq1$ is the constant $C$ described in Proposition 1.5 and $\\pi_{\\mathrm{min}}:=\\operatorname*{min}_{\\theta\\in[q]}\\pi(\\theta)$ ", "page_idx": 74}, {"type": "text", "text": "Further, in the case when $l=0$ then we simply have $\\begin{array}{r}{\\mathbb{E}\\mathrm{Var}\\big[(\\mathbb{E}_{u}f_{u})(X_{u})\\,|\\,X_{\\mathfrak{p}(u)}\\big]\\geq\\frac{1}{C_{0}}t^{2}.}\\end{array}$ ", "page_idx": 74}, {"type": "text", "text": "Proof. We decompose $(\\mathbb{E}_{u}f_{u})(x)$ into three components: ", "page_idx": 74}, {"type": "equation", "text": "$$\n(\\mathbb{E}_{u}f_{u})(x)=\\sum_{\\substack{\\mathbf{w}:r(\\mathbf{w})<l}}c_{w,u}\\xi_{w}^{(l)}(x_{u})+\\sum_{\\substack{\\mathbf{w}:r(\\mathbf{w})=l}}c_{w,u}\\xi_{w}^{(l)}(x_{u})+\\sum_{\\substack{\\mathbf{w}:r(\\mathbf{w})>l}}c_{w,u}\\xi_{w}^{(l)}(x_{u}),\n$$", "text_format": "latex", "page_idx": 74}, {"type": "text", "text": "where $\\xi_{\\mathsf{w}}^{(l)}$ is introduced in Remark I.6. ", "page_idx": 74}, {"type": "text", "text": "For each w with $r(\\mathsf{w})>l,\\xi_{w}^{(l)}(X_{u})$ is a function of $X_{v}$ with $v={\\mathfrak{p}}^{r(\\mathsf{w})-l}(u)$ . Hence, the last component $\\begin{array}{r}{\\sum_{\\mathsf{w}:r(\\mathsf{w})>l}c_{w,u}\\xi_{w}^{(l)}(x_{u})}\\end{array}$ is a constant function whenever we condition on $X_{\\mathfrak{p}(u)}$ . Consequently, ", "page_idx": 74}, {"type": "equation", "text": "$$\n\\mathbb{E}\\mathrm{Var}\\big[(\\mathbb{E}_{u}f_{u})(X_{u})\\,|\\,X_{\\mathfrak{p}(u)}\\big]=\\mathbb{E}\\mathrm{Var}\\Big[\\sum_{\\mathbf{w}:\\boldsymbol{r}(\\mathbf{w})<l}c_{w,u}\\xi_{w}^{(l)}(X_{u})+\\sum_{\\mathbf{w}:\\boldsymbol{r}(\\mathbf{w})=l}c_{w,u}\\xi_{w}^{(l)}(X_{u})\\,\\Big|\\,X_{\\mathfrak{p}(u)}\\Big].\n$$", "text_format": "latex", "page_idx": 74}, {"type": "text", "text": "From Proposition 1.5, we know that ", "page_idx": 74}, {"type": "equation", "text": "$$\n\\mathbb{E}\\mathrm{Var}\\Big[\\sum_{\\substack{\\mathbf{w}\\,:\\,r(\\mathbf{w})=l}}c_{w,u}\\xi_{w}^{(l)}(X_{u})\\,\\Big|\\,X_{\\mathbf{p}(u)}\\Big]\\geq\\frac{t^{2}}{C_{0}},\n$$", "text_format": "latex", "page_idx": 74}, {"type": "text", "text": "where the constant $C_{0}$ is the constant $C$ stated in the Proposition. Intuitively, from (115) it should be clear tha if the R H.S. of (114) is small,then $\\begin{array}{r}{\\mathbb{E}\\mathrm{Var}\\Big[\\sum_{\\mathbb{w}:r(\\mathbb{w})<l}c_{w,u}\\xi_{w}^{(l)}(\\dot{X}_{u})\\,\\Big|\\,X_{\\mathbb{p}(u)}\\Big]}\\end{array}$ canot be small. Let us derive this with a coarse estimate. ", "page_idx": 75}, {"type": "text", "text": "By (115), we know there exists $\\theta\\in[q]$ such that ", "page_idx": 75}, {"type": "equation", "text": "$$\n\\mathrm{Var}\\Big[\\sum_{\\mathfrak{w}:r(\\mathfrak{w})=l}c_{\\mathfrak{w},\\mathfrak{u}}\\xi_{\\mathfrak{w}}^{(l)}(X_{\\mathfrak{u}})\\,\\Big|\\,X_{\\mathfrak{p}(\\mathfrak{u})}=\\theta\\Big]\\geq\\frac{t^{2}}{C_{0}}.\n$$", "text_format": "latex", "page_idx": 75}, {"type": "text", "text": "Now, suppose $\\begin{array}{r}{\\mathrm{Var}\\Big[\\sum_{\\mathbf{w}:r(\\mathbf{w})<l}c_{w,u}\\xi_{w}^{(l)}(X_{u})\\Bigm|X_{\\mathfrak{p}(u)}=\\theta\\Big]<\\frac{t^{2}}{4C_{0}}}\\end{array}$ We could apply triangle inequl. ity to get ", "page_idx": 75}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\sqrt{\\mathrm{Var}\\Big[\\displaystyle\\sum_{\\mathbf{w}:\\boldsymbol{r}(\\mathbf{w})<l}c_{w,u}\\xi_{w}^{(l)}(X_{u})+\\displaystyle\\sum_{\\mathbf{w}:\\boldsymbol{r}(\\mathbf{w})=l}c_{w,u}\\xi_{w}^{(l)}(X_{u})\\Big\\vert\\,X_{\\mathfrak{p}(u)}=\\theta\\Big]}}\\\\ &{\\ge\\!\\sqrt{\\mathrm{Var}\\Big[\\displaystyle\\sum_{\\mathbf{w}:\\boldsymbol{r}(\\mathbf{w})=l}c_{w,u}\\xi_{w}^{(l)}(X_{u})\\,\\Big\\vert\\,X_{\\mathfrak{p}(u)}=\\theta\\Big]}-\\sqrt{\\mathrm{Var}\\Big[\\displaystyle\\sum_{\\mathbf{w}:\\boldsymbol{r}(\\mathbf{w})<l}c_{w,u}\\xi_{w}^{(l)}(X_{u})\\,\\Big\\vert\\,X_{\\mathfrak{p}(u)}=\\theta\\Big]}}\\\\ &{\\ge\\!\\frac{t}{2C_{0}^{1/2}},}\\end{array}\n$$", "text_format": "latex", "page_idx": 75}, {"type": "text", "text": "and together with (114), ", "page_idx": 75}, {"type": "equation", "text": "$$\n\\mathbb{E V a r}\\big[(\\mathbb{E}_{u}f_{u})(X_{u})\\,|\\,X_{\\mathfrak{p}(u)}\\big]\\geq\\!\\pi(\\theta)\\mathrm{Var}\\Big[\\sum_{\\mathfrak{w}:\\,\\tau(\\mathfrak{w})<l}c_{w,u}\\xi_{w}^{(l)}(X_{u})+\\sum_{\\mathfrak{w}:\\,\\tau(\\mathfrak{w})=l}c_{w,u}\\xi_{w}^{(l)}(X_{u})\\,\\Big|\\,X_{\\mathfrak{p}(u)}\\Big]\n$$", "text_format": "latex", "page_idx": 75}, {"type": "text", "text": "Consider th opposiecae where $\\begin{array}{r}{\\mathrm{Var}\\Big[\\sum_{\\mathbf{w}:r(\\mathbf{w})<l}c_{w,u}\\xi_{w}^{(l)}(X_{u})\\Bigm|X_{\\mathfrak{p}(u)}=\\theta\\Big]\\geq\\frac{t^{2}}{4C_{0}}}\\end{array}$ Firs, ", "page_idx": 75}, {"type": "equation", "text": "$$\n\\mathbb{E}\\mathrm{Var}\\Big[\\sum_{\\mathbf{w}:r(\\mathbf{w})<l}c_{w,u}\\xi_{w}^{(l)}(X_{u})\\,\\Big|\\,X_{\\mathfrak{p}(u)}=\\theta\\Big]\\geq\\frac{\\pi_{\\operatorname*{min}}}{4C_{0}}t^{2}.\n$$", "text_format": "latex", "page_idx": 75}, {"type": "text", "text": "By applying the 4th property stated in Proposition 1.5, we conclude that ", "page_idx": 75}, {"type": "equation", "text": "$$\n\\operatorname*{max}_{\\mathsf{w}:r(\\mathsf{w})<l}|c_{\\mathsf{w},u}|\\geq\\frac{\\sqrt{\\pi_{\\operatorname*{min}}}}{2C_{0}}t.\n$$", "text_format": "latex", "page_idx": 75}, {"type": "text", "text": "In the case when $l~=~0$ .The argument is simpler, which follows directly from (114) and the Proposition I.5. ", "page_idx": 75}, {"type": "text", "text": "Proof of Proposition I.25. Let $t_{0}=\\mathrm{max}_{\\mathsf{w},u\\in L_{\\rho^{\\prime}}}\\left|c_{\\mathsf{w},u}\\right|$ and let $\\mathsf{w}^{\\prime}\\in\\mathsf{W}$ and $u^{\\prime}\\in L_{\\rho^{\\prime}}$ be the pair such that $t_{0}=|c_{\\mathsf{w}^{\\prime},u^{\\prime}}|$ . Further, let $l_{0}=r(\\boldsymbol{\\mathbf{w}}^{\\prime})$ and $u_{0}={\\mathfrak{p}}^{l}(u^{\\prime})$ ", "page_idx": 75}, {"type": "text", "text": "If $l_{0}>0$ , then we have ", "page_idx": 75}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\|c_{\\mathsf{w}^{\\prime},u_{0}}\\|=\\displaystyle\\sum_{v\\in L_{u}}\\left|c_{\\mathsf{w}^{\\prime},v}\\right|\\ge|c_{\\mathsf{w}^{\\prime},u^{\\prime}}|=t_{0},}\\end{array}\n$$", "text_format": "latex", "page_idx": 75}, {"type": "text", "text": "where the first equality follows from the assumptions of the coefficients. We will try to construct a sequence of triples $(l_{k},t_{k},u_{k})$ indexed by $k$ such that $(l_{k})_{k\\geq0}$ is strictly decreasing such that $\\mathsf{W}_{l_{k}}\\neq\\emptyset,\\,\\mathrm{h}(u_{k})=l_{k}.$ and $t_{k}=\\mathrm{max}_{\\mathsf{w}\\in\\mathsf{W}_{l_{k}}}\\left|C_{\\mathsf{w},u_{k}}\\right|$ ", "page_idx": 75}, {"type": "text", "text": "Supposewehavea triple $(l_{k},t_{k},u_{k})$ such that $l_{k}~\\geq~0,~\\mathrm{h}(u_{k})~=~l_{k},~\\mathsf{W}_{l_{k}}~\\neq~\\emptyset$ .and $t_{k}~=$ $\\mathrm{max}_{\\mathsf{w}\\in\\mathsf{W}_{l_{k}}}\\left|c_{\\mathsf{w},u_{k}}\\right|$ for some index $k\\geq0$ ", "page_idx": 75}, {"type": "text", "text": "We apply Lemma I.26 to get ", "page_idx": 75}, {"type": "text", "text": "2. $\\begin{array}{r}{\\operatorname*{max}_{\\mathbf{w}\\in\\mathsf{W}_{<\\ell_{k}}}|c_{\\mathbf{w},u_{k}}|\\geq\\frac{\\sqrt{\\pi_{\\operatorname*{min}}}}{2C_{0}}t_{k}}\\end{array}$ tk. (This case cannot happen if lk = 0.) ", "text_level": 1, "page_idx": 76}, {"type": "text", "text": "If the first case is true, then we terminate the proces of fnding next triple $(\\ell_{k+1},t_{k+1},u_{k+1})$ ", "page_idx": 76}, {"type": "text", "text": "If the second case is true, let $\\mathsf{w}^{\\prime\\prime}\\in\\mathsf{W}$ be the vertex such that $\\big|C_{\\mathsf{W}^{\\prime\\prime},u_{k}}\\big|=\\operatorname*{max}_{\\mathsf{W}\\in\\mathsf{W}_{<\\ell_{k}}}\\left|C_{\\mathsf{W},u_{k}}\\right|$ and set $\\ell_{k+1}=r(w^{\\prime\\prime})$ . Since ", "page_idx": 76}, {"type": "equation", "text": "$$\nc_{\\mathsf{w},u_{k}}=\\sum_{u\\in D_{\\ell_{k+1}}(u_{k})}c_{\\mathsf{w},u},\n$$", "text_format": "latex", "page_idx": 76}, {"type": "text", "text": "we have ", "page_idx": 76}, {"type": "equation", "text": "$$\nt_{k+1}:=\\operatorname*{max}_{\\substack{u\\in T_{u_{k}}:\\,\\mathrm{h}(u)=\\ell_{k+1}}}|c_{\\mathsf{w},u}|\\ge\\frac{1}{R d^{\\ell_{k}-\\ell_{k+1}}}|c_{\\mathsf{w},u_{k}}|=\\frac{1}{R d^{\\ell_{k}-\\ell_{k+1}}}t_{k}.\n$$", "text_format": "latex", "page_idx": 76}, {"type": "text", "text": "Further, let $u_{k+1}=\\operatorname{argmax}_{u\\in T_{u_{k}}:\\,\\mathrm{h}(u)=\\ell_{k+1}}\\big|C_{\\mathsf{w},u}\\big|.$ ", "page_idx": 76}, {"type": "text", "text": "In this way, we produce a new triple satisfying the same assumption as $(l_{k},t_{k},u_{k})$ described above. Since $l_{0}\\;>\\;l_{1}\\;>\\;l_{2}\\ldots$ is a monotone decreasing chain of non-negative number, it means this argument must terminated in $r_{0}$ steps. Now, suppose it terminates at the $k$ -th step, resulting a triple $(l_{k},t_{k},u_{k})$ , and ", "page_idx": 76}, {"type": "equation", "text": "$$\n\\mathbb{E}\\mathrm{Var}\\big[\\big(\\mathbb{E}_{u_{k}}f_{u_{k}}\\big)(X_{u_{k}})\\,\\big|\\,X_{\\mathfrak{p}(u_{k})}\\big]\\geq\\frac{\\pi_{\\operatorname*{min}}}{2C_{0}}t_{k}^{2}\\stackrel{(116)}{\\geq}\\frac{\\pi_{\\operatorname*{min}}}{2C_{0}}\\big(\\frac{\\sqrt{\\pi_{\\operatorname*{min}}}}{2C_{0}}R d\\big)^{-2r_{0}}t_{0}^{2}.\n$$", "text_format": "latex", "page_idx": 76}, {"type": "text", "text": "On the other hand, from Proposition I.5, ", "page_idx": 76}, {"type": "equation", "text": "$$\n\\sum_{u\\in L_{\\rho^{\\prime}}}\\mathrm{Var}[f_{u}(X_{u})]\\leq C R d^{r_{0}}t_{0}^{2}.\n$$", "text_format": "latex", "page_idx": 76}, {"type": "text", "text": "Therefore, we conclude that ", "page_idx": 76}, {"type": "equation", "text": "$$\n\\sum_{u\\in L_{\\rho^{\\prime}}}{\\mathrm{Var}}[f_{u}(X_{u})]\\leq C(M,d)R^{2r_{0}+1}{\\mathbb{E}}{\\mathrm{Var}}\\big[f(X)\\,|\\,X_{\\rho^{\\prime}}\\big].\n$$", "text_format": "latex", "page_idx": 76}, {"type": "text", "text": "JProperties of Markov Chains and Galton- Watson Tree ", "text_level": 1, "page_idx": 76}, {"type": "text", "text": "J.0.1 Proof of Lemma A.5 ", "text_level": 1, "page_idx": 76}, {"type": "text", "text": "Recall that real Jordon Canonical form of $M$ isa $q\\ \\times\\ q$ diagonal  block  matrix $\\textbf{J}=$ $\\mathrm{diag}(\\mathbf{J}_{0},\\mathbf{J}_{1},\\ldots,\\mathbf{J}_{s_{1}})$ for some $s_{1}\\leq q$ ", "page_idx": 76}, {"type": "text", "text": "Since $M$ is ergodic, the eigenspace corresponds to eigenvalue 1 is 1-dimensional. Thus, We may assume $\\mathbf{J}_{0}=\\left[1\\right]$ is the unique Jordan block corresponds to eigenvalue 1. ", "page_idx": 76}, {"type": "text", "text": "For each $s~\\in~[1,s_{1}]$ \uff0c $\\mathbf{J}_{s}$ is either a $m_{s}\\;\\times\\;m_{s}$ matrix of the form Js = $\\lambda_{s\\perp}$ ", "page_idx": 76}, {"type": "text", "text": "for some $\\lambda_{s}~\\in~\\mathbb{R}$ satisfying $|\\lambda_{s}|\\ \\leq\\ \\lambda$ ; or a $J_{s}$ is a $2m_{s}\\,\\times\\,2m_{s}$ matrix of the form ${\\bf J}_{s}~=~$ $\\Gamma\\lambda_{s}R_{s}$ $I_{2}$ 1 ", "page_idx": 76}, {"type": "text", "text": "trix in $\\mathbb{R}^{2}$ with parameter $\\theta_{s}\\,\\in\\,(0,2\\pi)$ . In the later case, it corresponds to the conjugate pair of eigenvalues $\\lambda_{s}(\\bar{\\cos}(\\theta_{s})\\pm\\mathbf{i}\\sin(\\theta_{s}))$ ", "page_idx": 76}, {"type": "text", "text": "According to Jordon Decomposition, there exists an invertible matrix $P$ such that $M=P\\mathbf{J}P^{-1}$ ", "page_idx": 77}, {"type": "text", "text": "For $i\\in[1,q-1]$ , let $\\phi_{i}$ be the $i+1$ th column of $P$ .Because $P$ is invertible, $\\{\\phi_{i}\\}_{i\\in[q]}$ form a linear basis of functions from $[q]$ to $\\mathbb{R}$ ", "page_idx": 77}, {"type": "text", "text": "Since $\\pi$ is a left-eigenvector of $M$ with eigenvalue 1, we have ", "page_idx": 77}, {"type": "equation", "text": "$$\n\\mathbb{E}_{Y\\sim\\pi}\\phi_{i}(Y)=\\pi^{\\top}\\phi_{i}=0,\n$$", "text_format": "latex", "page_idx": 77}, {"type": "text", "text": "because $\\phi_{i}$ is a sum of up to two generalized eigenvectors with eigenvalues not equal to 1. ", "page_idx": 77}, {"type": "text", "text": "(A generalized eigenvector $v$ with eigenvalue $\\lambda^{\\prime}$ of $M$ is a vector which satisfies $(M-\\lambda^{\\prime})^{k}v={\\vec{0}}$ for some positive integer $k$ . Whenever $\\lambda^{\\prime}\\neq1$ \uff0c ", "page_idx": 77}, {"type": "equation", "text": "$$\n\\pi^{\\top}v=(\\frac{1}{(1-\\lambda^{\\prime})^{k}}\\pi^{\\top}(M-\\lambda^{\\prime})^{k})v=\\frac{1}{(1-\\lambda^{\\prime})^{k}}\\pi^{\\top}\\cdot\\vec{0}=0.\n$$", "text_format": "latex", "page_idx": 77}, {"type": "text", "text": "If index $i$ corresponds to $\\mathbf{J}_{s}$ which associated with a real eigenvalue, then $\\phi_{i}$ is a generalized eigenvector with eigenvalue $\\lambda_{s}$ ; And if $\\mathbf{J}_{s}$ associates with a complex conjugate pair or eigenvalues, then $\\phi_{i}$ is a sum of two generalized eigenvectors with eigenvalues $\\lambda_{s}\\bar{(\\cos(\\theta_{s})+\\mathbf{i}\\sin(\\theta_{s}))}$ and $\\lambda_{s}(\\cos(\\theta_{s})\\,-\\,{\\bf i}\\sin(\\theta_{s}))$ , respectively. \uff09 As a consequence, every function $f\\,:\\,[q]\\,\\mapsto\\,\\mathbb{R}$ can be uniquely decomposed in the form ", "page_idx": 77}, {"type": "equation", "text": "$$\nf=\\mathbb{E}f+\\sum_{i\\in[q-1]}\\delta_{i}\\phi_{i}.\n$$", "text_format": "latex", "page_idx": 77}, {"type": "text", "text": "With this unique decomposition, let us define a semi-norm ", "page_idx": 77}, {"type": "equation", "text": "$$\n\\|f\\|_{M}=\\operatorname*{max}_{i\\in[q-1]}|\\delta_{i}|.\n$$", "text_format": "latex", "page_idx": 77}, {"type": "text", "text": "Lemma J.1. There exists $C>0$ so that for every $f:[q]\\to\\mathbb{R},$ ", "page_idx": 77}, {"type": "equation", "text": "$$\n\\begin{array}{r}{C^{-1}\\|f\\|_{M}^{2}\\leq\\mathrm{Var}_{Y\\sim\\pi}(f(Y))\\leq C\\|f\\|_{M}^{2}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 77}, {"type": "text", "text": "Proof. Without lose of generality, let $\\textstyle f=\\sum_{i\\in[2,q]}\\delta_{i}\\phi_{i}$ , since both $\\|f\\|_{M}$ and $\\operatorname{Var}_{Y\\sim\\pi}(f(Y))$ are invariant under a constant shift. ", "page_idx": 77}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\|f\\|_{M}=\\|\\vec{\\delta}\\|_{\\infty}\\qquad\\qquad\\mathrm{~and~}\\qquad\\qquad\\operatorname{Var}_{Y\\sim\\pi}(f(Y))=\\vec{\\delta}^{\\top}P^{\\top}D_{\\pi}P\\vec{\\delta}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 77}, {"type": "text", "text": "Let $s_{\\mathrm{max}}$ and $s_{\\mathrm{min}}$ be the maximum and minimum singular value of $P^{\\top}D_{\\pi}P$ , respectively. Together with $q^{-1/2}\\|\\vec{\\delta}\\|_{2}\\leq\\|\\vec{\\delta}\\|_{\\infty}\\leq\\|\\vec{\\delta}\\|_{2}$ wehave ", "page_idx": 77}, {"type": "equation", "text": "$$\ns_{\\operatorname*{min}}^{2}q^{-1}\\|f\\|_{M}^{2}\\leq s_{\\operatorname*{min}}^{2}q^{-1}\\|\\vec{\\delta}\\|_{2}^{2}\\leq\\operatorname{Var}_{Y\\sim\\pi}(f(Y))\\leq s_{\\operatorname*{max}}^{2}\\|\\vec{\\delta}\\|_{2}^{2}\\leq s_{\\operatorname*{max}}^{2}\\|f\\|_{M}^{2}.\n$$", "text_format": "latex", "page_idx": 77}, {"type": "text", "text": "If $s_{\\operatorname*{min}}>0$ , then we can complete the proof by taking $C=\\operatorname*{max}\\{s_{\\operatorname*{max}}^{2},q/s_{\\operatorname*{min}}^{2}\\}$ It remains to show that $s_{\\operatorname*{min}}>0$ , or equvialently $P^{\\top}D_{\\pi}P$ is invertible. Because $M$ is ergodic, each entry of $\\pi$ is positive, and thus $D_{\\pi}$ is invertible. Hence, $P^{\\top}D_{\\pi}P$ is invertible because it is a product of three invertible matrices. ", "page_idx": 77}, {"type": "text", "text": "Lemma J.2. There exists $C>0$ so that for every $f:[q]\\to\\mathbb{R},$ ", "page_idx": 77}, {"type": "equation", "text": "$$\nC^{-1}\\|f\\|_{M}\\leq\\|f-\\mathbb{E}_{Y\\sim\\pi}f(Y)\\|_{\\infty}\\leq C\\|f\\|_{M}.\n$$", "text_format": "latex", "page_idx": 77}, {"type": "text", "text": "Proof. This simply follows from both $\\|f\\|_{M}$ and $\\|f\\!-\\!\\mathbb{E}f\\|_{\\infty}$ are both norms on the finite dimensional space $\\{f:[q]\\stackrel{*}{\\to}\\mathbb{R}\\,:\\,\\mathbb{E}_{Y\\sim\\pi}f(Y)=\\dot{0}\\}$ \u53e3 ", "page_idx": 77}, {"type": "text", "text": "Lemma J.3. There exists $C\\geq1$ depending on $M$ such that For any function $f:[q]\\mapsto\\mathbb{R}$ and $k\\in\\mathbb{N}$ ", "page_idx": 77}, {"type": "equation", "text": "$$\n\\|M^{k}f\\|_{M}\\leq C k^{q}\\lambda^{k}\\|f\\|_{M}.\n$$", "text_format": "latex", "page_idx": 77}, {"type": "text", "text": "Remark J.4. Notice that $M^{k}f$ can be interpreted as ", "page_idx": 78}, {"type": "equation", "text": "$$\n\\mathbb{E}\\big[f(X_{u})\\,\\big|\\,X_{\\mathfrak{p}^{k}(u)}=i\\big]=(M^{k}f)(i),\n$$", "text_format": "latex", "page_idx": 78}, {"type": "text", "text": "for every $u\\in T$ where ${\\mathfrak{p}}^{k}(u)$ is well-defined. ", "page_idx": 78}, {"type": "text", "text": "Proof. ", "page_idx": 78}, {"type": "equation", "text": "$$\n\\|M^{k}f\\|_{M}=\\|P\\mathbf{J}^{k}(\\sum_{i\\in[q]}\\delta_{i}e_{i})\\|_{M}=\\|\\mathbf{J}^{k}(\\sum_{i\\in[2,q]}\\delta_{i}e_{i})\\|_{\\infty}.\\leq q\\operatorname*{max}_{i\\in[2,q]}\\|\\delta_{i}\\|\\operatorname*{max}_{i,j\\in[2,q]}|\\mathbf{J}_{i j}^{k}|.\n$$", "text_format": "latex", "page_idx": 78}, {"type": "text", "text": "Notice that $\\mathbf{J}^{k}$ is the diagonal block matrix whose blocks $\\mathbf{J}_{s}^{k}$ for $s\\,\\in\\,[s_{1}]$ . The block $\\mathbf{J}_{s}^{k}$ can be computed directly: In the case when $\\mathbf{J}_{s}$ corresponds to a complex conjugate pair of eigenvalues, ", "page_idx": 78}, {"type": "equation", "text": "$$\n\\mathbf{J}_{s}^{k}=\\left[\\begin{array}{c c c c c}{\\lambda_{s}^{k}R_{s}^{k}}&{\\binom{k}{1}\\lambda_{s}^{k-1}R_{s}^{k-1}}&{\\ldots}&{\\binom{k}{m_{s}-1}\\lambda_{s}^{k-m_{s}+1}R_{s}^{k-m_{s}+1}}&\\\\ &{\\lambda_{s}^{k}R_{s}^{k}}&{\\ddots}&&{\\vdots}\\\\ &&{\\ddots}&&{\\binom{k}{1}\\lambda_{s}^{k-1}R_{s}^{k-1}}&\\\\ &&&{\\lambda_{s}^{k}R_{s}^{k},}&\\end{array}\\right]\n$$", "text_format": "latex", "page_idx": 78}, {"type": "text", "text": "where we treat $\\textstyle{\\binom{k}{r}}=0$ \u00fc $r\\,>\\,k$ . It can be verified directly by induction, relying on the identity $\\textstyle{\\binom{k}{r-1}}+{\\binom{k}{r}}={\\binom{\\dot{k}+1}{r}}$ . Further, removing the $R_{s}$ terms in the above equation we obtain the formula for $\\mathbf{J}_{s}^{k}$ when $\\mathbf{J}_{s}$ corresponds to a real eigenvalue. ", "page_idx": 78}, {"type": "text", "text": "Therefore, with ${\\binom{k}{q}}\\leq k^{q}$ \uff0c $|\\lambda_{s}^{r}|\\le\\lambda^{r}$ , and $\\operatorname*{max}_{i,j}R_{s\\,i j}^{r}\\ <1$ for $r\\geq1$ , we obtain the bound ", "page_idx": 78}, {"type": "equation", "text": "$$\n\\operatorname*{max}_{s\\in[2,q]}\\operatorname*{max}_{i,j\\in[q]}|(\\mathbf{J_{s}}^{k})_{i j}|\\leq C^{\\prime}k^{q}\\lambda^{k},\n$$", "text_format": "latex", "page_idx": 78}, {"type": "text", "text": "where $C^{\\prime}$ is a constant which depends on $q$ and $\\lambda$ ", "page_idx": 78}, {"type": "text", "text": "Now we substitute the above bound into (122) to get ", "page_idx": 78}, {"type": "equation", "text": "$$\n\\|M^{k}f\\|_{M}\\leq q C^{\\prime}k^{q}\\lambda^{k}\\|f\\|_{M}.\n$$", "text_format": "latex", "page_idx": 78}, {"type": "text", "text": "The proof is completed by taking $C=q C^{\\prime}$ ", "page_idx": 78}, {"type": "text", "text": "Proof of Lemma A.5. The proof of Lemma A.5 follows from the $\\Vert\\cdot\\Vert_{M}$ decay from Lemma J.3 and that both $\\operatorname{Var}[f]$ and $\\|f-\\mathbb{E}f\\|_{\\infty}$ are comparable to $\\|f\\|_{M}$ within a constant multiplicative factor (Lemma J.1 and Lemma J.2). \u53e3 ", "page_idx": 78}, {"type": "text", "text": "NeurIPS Paper Checklist ", "text_level": 1, "page_idx": 79}, {"type": "text", "text": "The checklist is designed to encourage best practices for responsible machine learning research, addressing issues of reproducibility, transparency, research ethics, and societal impact. Do not remove the checklist: The papers not including the checklist will be desk rejected. The checklist should follow the references and follow the (optional) supplemental material. The checklist does NOT count towards the page limit. ", "page_idx": 79}, {"type": "text", "text": "Please read the checklist guidelines carefully for information on how to answer these questions. For each question in the checklist: ", "page_idx": 79}, {"type": "text", "text": "\u00b7 You should answer [Yes] , [No] , or [NA] .   \n\u00b7 [NA]  means either that the question is Not Applicable for that particular paper or the relevant information is Not Available.   \n\u00b7 Please provide a short (1-2 sentence) justification right after your answer (even for NA). ", "page_idx": 79}, {"type": "text", "text": "The checklist answers are an integral part of your paper submission. They are visible to the reviewers, area chairs, senior area chairs, and ethics reviewers. You will be asked to also include it (after eventual revisions) with the final version of your paper, and its final version will be published with thepaper. ", "page_idx": 79}, {"type": "text", "text": "The reviewers of your paper will be asked to use the checklist as one of the factors in their evaluation. While \"[Yes] \" is generally preferable to \"[No] \", it is perfectly acceptable to answer \"[No] \" provided a proper justification is given (e.g., \"error bars are not reported because it would be too computationally expensive\" or \"we were unable to find the license for the dataset we used\"). In general, answering \"[No] \" or \"[NA] \" is not grounds for rejection. While the questions are phrased in a binary way, we acknowledge that the true answer is often more nuanced, so please just use your best judgment and write a justification to elaborate. All supporting evidence can appear either in the main paper or the supplemental material, provided in appendix. If you answer [Yes] to a question, in the justification please point to the section(s) where related material for the question can be found. ", "page_idx": 79}, {"type": "text", "text": "IMPORTANT, please: ", "page_idx": 79}, {"type": "text", "text": "\u00b7 Delete this instruction block, but keep the section heading \u201cNeurIPS paper checklist\", \u00b7 Keep the checklist subsection headings, questions/answers and guidelines below. . Do not modify the questions and only use the provided macros for your answers. ", "page_idx": 79}, {"type": "text", "text": "1. Claims ", "text_level": 1, "page_idx": 79}, {"type": "text", "text": "Question: Do the main claims made in the abstract and introduction accurately reflect the paper's contributions and scope? ", "page_idx": 79}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 79}, {"type": "text", "text": "Justification: The main claim in the abstract and introduction is Theorem 1.6. The appendix is dedicated to the proof of the theorem. ", "page_idx": 79}, {"type": "text", "text": "2. Limitations ", "text_level": 1, "page_idx": 79}, {"type": "text", "text": "Question: Does the paper discuss the limitations of the work performed by the authors? Answer: [Yes] ", "page_idx": 79}, {"type": "text", "text": "Justification: The result is a theoretical result which justifies low degree hardness for the tree reconstruction model. This is a first indication that Kesten-Stigum bound appears to be the computational-statistical barrier for the problem. In terms of the limitation, the paper does not recover the same result as shown in the paper of Kohler and Moseel [23], where they only deal with the case $\\lambda=0$ ", "page_idx": 79}, {"type": "text", "text": "3. Theory Assumptions and Proofs ", "text_level": 1, "page_idx": 79}, {"type": "text", "text": "Question: For each theoretical result, does the paper provide the full set of assumptions and a complete (and correct) proof? ", "page_idx": 79}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 79}, {"type": "text", "text": "Justification: The paper provides a full set of assumptions and the appendix is dedicated to the complete proof for Theorem 1.6. ", "page_idx": 80}, {"type": "text", "text": "4. Experimental Result Reproducibility ", "text_level": 1, "page_idx": 80}, {"type": "text", "text": "Question: Does the paper fully disclose all the information needed to reproduce the main experimental results of the paper to the extent that it affects the main claims and/or conclusions of the paper (regardless of whether the code and data are provided or not)? Answer:[NA] ", "page_idx": 80}, {"type": "text", "text": "Justification: The result in the paper is a theoretical result. The paper does not include any experimental results. ", "page_idx": 80}, {"type": "text", "text": "5. Open access to data and code ", "text_level": 1, "page_idx": 80}, {"type": "text", "text": "Question: Does the paper provide open access to the data and code, with sufficient instructions to faithfully reproduce the main experimental results, as described in supplemental material? ", "page_idx": 80}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 80}, {"type": "text", "text": "Justification: The result in the paper is a theoretical result. The paper does not include any experimental results. ", "page_idx": 80}, {"type": "text", "text": "6. Experimental Setting/Details ", "text_level": 1, "page_idx": 80}, {"type": "text", "text": "Question: Does the paper specify all the training and test details (e.g., data splits, hyperparameters, how they were chosen, type of optimizer, etc.) necessary to understand the results? ", "page_idx": 80}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 80}, {"type": "text", "text": "Justification: The result in the paper is a theoretical result. The paper does not include any experimental results. ", "page_idx": 80}, {"type": "text", "text": "7. Experiment Statistical Significance ", "text_level": 1, "page_idx": 80}, {"type": "text", "text": "Question: Does the paper report error bars suitably and correctly defined or other appropriate information about the statistical significance of the experiments? ", "page_idx": 80}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 80}, {"type": "text", "text": "Justification: The result in the paper is a theoretical result. The paper does not include any experimental results. ", "page_idx": 80}, {"type": "text", "text": "8. Experiments Compute Resources ", "text_level": 1, "page_idx": 80}, {"type": "text", "text": "Question: For each experiment, does the paper provide sufficient information on the computer resources (type of compute workers, memory, time of execution) needed to reproduce theexperiments? ", "page_idx": 80}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 80}, {"type": "text", "text": "Justification: The result in the paper is a theoretical result. The paper does not include any experimental results. ", "page_idx": 80}, {"type": "text", "text": "9. Code Of Ethics ", "text_level": 1, "page_idx": 80}, {"type": "text", "text": "Question: Does the research conducted in the paper conform, in every respect, with the NeurIPS Code of Ethics https: //neurips.cc/public/EthicsGuidelines? ", "page_idx": 80}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 80}, {"type": "text", "text": "Justification: The research conducted in the paper conforms with the NeurIPS Code of Ethics. ", "page_idx": 80}, {"type": "text", "text": "10. Broader Impacts ", "text_level": 1, "page_idx": 80}, {"type": "text", "text": "Question: Does the paper discuss both potential positive societal impacts and negative societal impacts of the work performed? ", "page_idx": 80}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 80}, {"type": "text", "text": "Justification: The result of the paper is a theoretical result, which suggests a previous known bound (Kesten-Stigum) is likely a statistical-computational bound for the tree reconstruction model. It is an generic result that suggest it is hard to design an efficient algorithm for the problem below the Kesten-Stigum bound. On the other hand, the result does not have any direct societal impact. ", "page_idx": 80}, {"type": "text", "text": "11. Safeguards ", "text_level": 1, "page_idx": 81}, {"type": "text", "text": "Question: Does the paper describe safeguards that have been put in place for responsible release of data or models that have a high risk for misuse (e.g., pretrained language models, image generators, or scraped datasets)? ", "page_idx": 81}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 81}, {"type": "text", "text": "Justification: The result in the paper is a theoretical result. The paper does not process and realease any data or models. ", "page_idx": 81}, {"type": "text", "text": "12. Licenses for existing assets ", "text_level": 1, "page_idx": 81}, {"type": "text", "text": "Question: Are the creators or original owners of assets (e.g., code, data, models), used in the paper, properly credited and are the license and terms of use explicitly mentioned and properlyrespected? ", "page_idx": 81}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 81}, {"type": "text", "text": "Justification: The paper does not use existing assets. ", "page_idx": 81}, {"type": "text", "text": "13. New Assets ", "text_level": 1, "page_idx": 81}, {"type": "text", "text": "Question: Are new assets introduced in the paper well documented and is the documentation provided alongside the assets? ", "page_idx": 81}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 81}, {"type": "text", "text": "Justification: The paper does not release new assets. ", "page_idx": 81}, {"type": "text", "text": "14. Crowdsourcing and Research with Human Subjects ", "text_level": 1, "page_idx": 81}, {"type": "text", "text": "Question: For crowdsourcing experiments and research with human subjects, does the paper include the full text of instructions given to participants and screenshots, if applicable, as well as details about compensation (if any)? ", "page_idx": 81}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 81}, {"type": "text", "text": "Justification: The paper does not involve crowdsourcing nor research with human subjects. ", "page_idx": 81}, {"type": "text", "text": "15. Institutional Review Board (IRB) Approvals or Equivalent for Research with Human Subjects ", "page_idx": 81}, {"type": "text", "text": "Question: Does the paper describe potential risks incurred by study participants, whether such risks were disclosed to the subjects, and whether Institutional Review Board (IRB) approvals (or an equivalent approval/review based on the requirements of your country or institution)were obtained? ", "page_idx": 81}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 81}, {"type": "text", "text": "Justification: The paper does not involve crowdsourcing nor research with human subjects. ", "page_idx": 81}]