[{"figure_path": "ACCqGLviig/tables/tables_1_1.jpg", "caption": "Table 1: Comparison on ImageNet-R. Results on \u201c5-task\u201d, \u201c10-task\u201d, and \u201c20-task\u201d settings are included. Backbones are pre-trained on ImageNet-1K. \u2191 denotes larger values are better. See \u00a75.2.", "description": "This table presents a comparison of different continual learning methods on the ImageNet-R dataset.  The results are broken down into three settings: 5 tasks, 10 tasks, and 20 tasks.  All models used a backbone pre-trained on ImageNet-1K.  The table shows the final average accuracy (FAA) and cumulative average accuracy (CAA) for each method.  Higher values for FAA and CAA indicate better performance.  Section 5.2 provides further details.", "section": "5 Experiment"}, {"figure_path": "ACCqGLviig/tables/tables_6_1.jpg", "caption": "Table 1: Comparison on ImageNet-R. Results on \u201c5-task\u201d, \u201c10-task\u201d, and \u201c20-task\u201d settings are included. Backbones are pre-trained on ImageNet-1K. \u2191 denotes larger values are better. See \u00a75.2.", "description": "This table presents a comparison of the proposed VQ-Prompt method against several baseline and state-of-the-art continual learning methods on the ImageNet-R dataset under three different task settings (5, 10, and 20 tasks).  The results are shown in terms of Final Average Accuracy (FAA) and Cumulative Average Accuracy (CAA), which measure the overall accuracy and the average accuracy across all tasks, respectively.  The backbone network for all methods is pre-trained on ImageNet-1K.", "section": "5 Experiment"}, {"figure_path": "ACCqGLviig/tables/tables_6_2.jpg", "caption": "Table 1: Comparison on ImageNet-R. Results on \u201c5-task\u201d, \u201c10-task\u201d, and \u201c20-task\u201d settings are included. Backbones are pre-trained on ImageNet-1K. \u2191 denotes larger values are better. See \u00a75.2.", "description": "This table presents a comparison of various continual learning methods on the ImageNet-R dataset, using three different task settings (5, 10, and 20 tasks).  The performance is measured using Final Average Accuracy (FAA) and Cumulative Average Accuracy (CAA).  The backbone network for all methods was pre-trained on ImageNet-1K. Higher FAA and CAA values indicate better performance.", "section": "5 Experiment"}, {"figure_path": "ACCqGLviig/tables/tables_7_1.jpg", "caption": "Table 4: Results on 10-task ImageNet-R with different self-supervised pre-training paradigms.", "description": "This table compares the performance of different continual learning methods (DualPrompt, CODA-Prompt, HiDe-Prompt, and VQ-Prompt) on the 10-task ImageNet-R dataset.  The key difference is the type of self-supervised pre-training used for the backbone: iBOT-1K and DINO-1K. The table shows the Final Average Accuracy (FAA) and Cumulative Average Accuracy (CAA) for each method, highlighting the impact of different pre-training strategies on continual learning performance.", "section": "5 Experiment"}, {"figure_path": "ACCqGLviig/tables/tables_8_1.jpg", "caption": "Table 5: Effectiveness of classifier bias mitigation. Results for \"5-task\", \"10-task\", and \"20-task\" settings on ImageNet-R are included. \"C.B.M.\" denotes \"Classifier Bias Mitigation\". Backbones are pre-trained on ImageNet-1K. \u2191 denotes larger values are better. See \u00a75.3 for details.", "description": "This table presents the results of an ablation study on the impact of classifier bias mitigation (CBM) on the performance of different continual learning methods (L2P++, EvoPrompt, and VQ-Prompt) across three different task settings (5-task, 10-task, and 20-task) on the ImageNet-R dataset.  The table shows the final average accuracy (FAA) and cumulative average accuracy (CAA), indicating the overall performance and the ability of the model to retain knowledge of previously learned tasks.  The results demonstrate whether incorporating CBM improves the performance of these continual learning methods, particularly in terms of mitigating catastrophic forgetting.", "section": "5 Experiment"}, {"figure_path": "ACCqGLviig/tables/tables_14_1.jpg", "caption": "Table 1: Comparison on ImageNet-R. Results on \u201c5-task\u201d, \u201c10-task\u201d, and \u201c20-task\u201d settings are included. Backbones are pre-trained on ImageNet-1K. \u2191 denotes larger values are better. See \u00a75.2.", "description": "This table presents a comparison of different continual learning methods on the ImageNet-R dataset, broken down into 5, 10, and 20-task incremental learning settings.  The models use backbones pre-trained on ImageNet-1K.  The table shows the final average accuracy (FAA) and cumulative average accuracy (CAA) for each method, allowing for comparison of overall performance and learning capacity with less forgetting.  Higher values are better for both FAA and CAA.", "section": "5 Experiment"}, {"figure_path": "ACCqGLviig/tables/tables_14_2.jpg", "caption": "Table 7: Results evaluated using the FAA metric on the ImageNet-A and VTAB datasets. Backbones are pre-trained on ImageNet-1K. Larger values are better.", "description": "This table presents the Final Average Accuracy (FAA) results on the ImageNet-A and VTAB datasets for the proposed VQ-Prompt method and HiDe-Prompt baseline. The backbones used in both cases were pre-trained on ImageNet-1K, ensuring a fair comparison between the methods. The higher FAA values indicate better performance. VQ-Prompt outperforms HiDe-Prompt on both datasets.", "section": "5.2 Comparison Results"}]