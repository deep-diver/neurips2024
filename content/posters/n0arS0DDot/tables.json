[{"figure_path": "n0arS0DDot/tables/tables_3_1.jpg", "caption": "Table 2: Performance comparison for compressing the weight matrices of a diffusion model followed by re-training. FID and IS scores were computed with respect to a validation dataset. CR stands for Compression Ratio.", "description": "This table compares the performance of compressing a diffusion model's weight matrices using different methods and then retraining it.  It shows the Fr\u00e9chet Inception Distance (FID) and Inception Score (IS) which are common metrics for assessing the quality of generated images. A lower FID score and a higher IS score are better, indicating that the generated images are more realistic and diverse, respectively. The compression ratio (CR) indicates how much smaller the compressed model is than the original model. The results indicate that using the BLAST matrix for compression resulted in better image quality compared to low-rank approximation after retraining.", "section": "4.2 Compression and Re-training"}, {"figure_path": "n0arS0DDot/tables/tables_6_1.jpg", "caption": "Table 1: ImageNet validation accuracy and relative FLOPs of ViT-Base trained from scratch models with different structured weight matrices. The image and the patch sizes are 224 \u00d7 224 and 16 \u00d7 16, respectively. BLAST3 indicates the BLAST matrix with 3 \u00d7 3 number of blocks.", "description": "This table presents the ImageNet validation accuracy and the relative FLOPs (floating point operations) for different models of Vision Transformers (ViT-Base) trained from scratch using various weight matrix structures.  The comparison includes a dense ViT-Base model as a baseline, along with models using low-rank, Monarch, Gaudi-GBLR, and BLAST weight matrices. The table shows the efficiency gains (reduction in FLOPs) achieved by using structured matrices compared to the dense model, while maintaining or improving accuracy.", "section": "4.1 Training from Scratch"}, {"figure_path": "n0arS0DDot/tables/tables_7_1.jpg", "caption": "Table 2: Performance comparison for compressing the weight matrices of a diffusion model followed by re-training. FID and IS scores were computed with respect to a validation dataset. CR stands for Compression Ratio.", "description": "This table compares the performance of compressing a diffusion model's weight matrices using low-rank and BLAST methods.  The comparison is based on the Fr\u00e9chet Inception Distance (FID), the standard FID (sFID), and the Inception Score (IS) after retraining.  A lower FID and sFID indicate better image quality, while a higher IS indicates better image diversity and quality.  The Compression Ratio (CR) shows the percentage reduction in model size.", "section": "4.2 Compression and Re-training"}, {"figure_path": "n0arS0DDot/tables/tables_8_1.jpg", "caption": "Table 3: Zero-shot performance of LLaMA-7B after compression and retraining. Avg. 0-Shot Accuracy stands for the average accuracy of the zero-shot classification task. CR denotes compression ratio. Bold indicates the best performance under the same compression ratio. BLAST indicates the BLAST matrix with b \u00d7 b number of blocks.", "description": "This table presents the results of compressing and retraining the Llama-7B language model using different methods.  It compares the performance (WikiText-2 perplexity and average zero-shot accuracy across several tasks) of the original model with models compressed using Low-Rank, Monarch, Block-Diagonal, and BLAST matrices, at compression ratios of 20% and 50%.  The table also indicates whether re-training was performed after compression.  The best performing methods (lowest perplexity, highest accuracy) for each compression ratio are highlighted.", "section": "4.2 Compression and Re-training"}, {"figure_path": "n0arS0DDot/tables/tables_8_2.jpg", "caption": "Table 2: Performance comparison for compressing the weight matrices of a diffusion model followed by re-training. FID and IS scores were computed with respect to a validation dataset. CR stands for Compression Ratio.", "description": "This table compares the performance of compressing a diffusion model's weight matrices using different methods (Low-Rank and BLAST9) and retraining.  It shows the Fr\u00e9chet Inception Distance (FID),  the  improved FID (sFID), and the Inception Score (IS) for each method, comparing them against the uncompressed original model.  The Compression Ratio (CR) indicates the percentage of weight parameters removed by each compression method.", "section": "4.2 Compression and Re-training"}, {"figure_path": "n0arS0DDot/tables/tables_21_1.jpg", "caption": "Table 1: ImageNet validation accuracy and relative FLOPs of ViT-Base trained from scratch models with different structured weight matrices. The image and the patch sizes are 224 \u00d7 224 and 16 \u00d7 16, respectively. BLAST3 indicates the BLAST matrix with 3 \u00d7 3 number of blocks.", "description": "This table presents the ImageNet validation accuracy and the relative floating point operations (FLOPs) of Vision Transformer Base (ViT-B) models trained from scratch using different structured weight matrices.  It compares the performance of the standard dense ViT-Base model against models using low-rank, Monarch, Gaudi-GBLR, and BLAST matrices.  The relative FLOPs are calculated with respect to the standard dense model (100%).  The table helps demonstrate the efficiency gains of using structured matrices, especially the proposed BLAST matrix, in terms of reducing computational cost without significant loss of accuracy.", "section": "4.1 Training from Scratch"}, {"figure_path": "n0arS0DDot/tables/tables_21_2.jpg", "caption": "Table 6: Hyperparameters used in re-training.", "description": "This table lists the hyperparameters used for re-training the models after compression.  It includes the dataset used (ImageNet and SlimPajama), the model (ViT-B and Llama-7B), the number of epochs and steps, the weight decay, the batch size, warmup steps and start epoch, the learning rate scheduler, the initial learning rate and minimum learning rate, dropout rate, droppath rate, and the number of blocks (b) used for the BLAST matrix.", "section": "3.2 Compressing Weights via BLAST Factorization"}, {"figure_path": "n0arS0DDot/tables/tables_21_3.jpg", "caption": "Table 7: Hyperparameters used for the BLAST9-compressed DiT-XL/2 with 50% compression ratio. m, n: size of the original matrix, b: number of row/column partitions, r: BLAST rank parameter, Layer Indices: indices of layers that the BLAST matrix replaces the weight.", "description": "This table lists the hyperparameters used for compressing the DiT-XL/2 model using the BLAST9 matrix with a 50% compression ratio. It specifies the size of the original matrices (m, n), the number of blocks (b), the rank (r), and the layer indices where the BLAST matrix replaces the original weights.  These hyperparameters are crucial for replicating the compression and retraining experiments reported in the paper.", "section": "C.3 Compression and Re-training"}, {"figure_path": "n0arS0DDot/tables/tables_22_1.jpg", "caption": "Table 7: Hyperparameters used for the BLAST9-compressed DiT-XL/2 with 20% compression ratio. m, n: size of the original matrix, b: number of row/column partitions, r: BLAST rank parameter, Layer Indices: indices of layers that the BLAST matrix replaces the weight.", "description": "This table details the hyperparameters used for compressing the DiT-XL/2 model using the BLAST9 method with a 20% compression ratio. It shows the dimensions (m, n) of the original weight matrices, the number of blocks (b), the rank (r) of the BLAST matrices, and the indices of the layers where the BLAST matrices replace the original weight matrices.", "section": "C.3 Compression and Re-training"}, {"figure_path": "n0arS0DDot/tables/tables_22_2.jpg", "caption": "Table 2: Performance comparison for compressing the weight matrices of a diffusion model followed by re-training. FID and IS scores were computed with respect to a validation dataset. CR stands for Compression Ratio.", "description": "This table compares the performance of different methods for compressing the weight matrices of a diffusion model.  The compression ratio (CR), Fr\u00e9chet Inception Distance (FID),  sFID, and Inception Score (IS) are reported. Lower FID and sFID values indicate better image quality, while a higher IS suggests better image diversity.  The table helps to evaluate the effectiveness of BLAST in compressing the model while maintaining high image quality.", "section": "4.2 Compression and Re-training"}, {"figure_path": "n0arS0DDot/tables/tables_22_3.jpg", "caption": "Table 2: Performance comparison for compressing the weight matrices of a diffusion model followed by re-training. FID and IS scores were computed with respect to a validation dataset. CR stands for Compression Ratio.", "description": "This table compares the performance of compressing a diffusion model's weights using different methods, specifically focusing on the Fr\u00e9chet Inception Distance (FID) and Inception Score (IS) metrics, which evaluate the quality of generated images.  The compression ratio (CR) indicates the percentage reduction in model parameters.  The table helps quantify how different compression techniques affect the quality of the generated images after retraining.", "section": "4.2 Compression and Re-training"}, {"figure_path": "n0arS0DDot/tables/tables_23_1.jpg", "caption": "Table 2: Performance comparison for compressing the weight matrices of a diffusion model followed by re-training. FID and IS scores were computed with respect to a validation dataset. CR stands for Compression Ratio.", "description": "This table compares the performance of compressing the weight matrices of a diffusion model using different methods followed by retraining.  It shows the Fr\u00e9chet Inception Distance (FID),  the modified Fr\u00e9chet Inception Distance (sFID), and the Inception Score (IS) metrics for the original model and models compressed using low-rank and BLAST matrices with different compression ratios. Lower FID and sFID scores, and a higher IS score indicate better image generation quality.", "section": "4.2 Compression and Re-training"}, {"figure_path": "n0arS0DDot/tables/tables_25_1.jpg", "caption": "Table 2: Performance comparison for compressing the weight matrices of a diffusion model followed by re-training. FID and IS scores were computed with respect to a validation dataset. CR stands for Compression Ratio.", "description": "This table compares the performance of compressing a diffusion model's weight matrices using different methods, specifically focusing on the FID (Fr\u00e9chet Inception Distance) and IS (Inception Score) metrics.  The compression ratio (CR) is also shown.  Lower FID and higher IS values indicate better image quality after compression and re-training.", "section": "4.2 Compression and Re-training"}, {"figure_path": "n0arS0DDot/tables/tables_25_2.jpg", "caption": "Table 2: Performance comparison for compressing the weight matrices of a diffusion model followed by re-training. FID and IS scores were computed with respect to a validation dataset. CR stands for Compression Ratio.", "description": "This table compares the performance of compressing a diffusion model's weight matrices using different methods.  It shows the Fr\u00e9chet Inception Distance (FID), the improved Fr\u00e9chet Inception Distance (sFID), and the Inception Score (IS) for the original model and models compressed by 50% using different techniques, specifically Low-Rank and BLAST.  A lower FID and sFID indicate better image quality, while a higher IS reflects more diverse and higher-quality generated images. The compression ratio is also provided.", "section": "4.2 Compression and Re-training"}]