[{"type": "text", "text": "Beyond accuracy: understanding the performance of LLMs on exams designed for humans ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Anonymous Author(s) ", "page_idx": 0}, {"type": "text", "text": "Abstract ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "1 Many recent studies of LLM performance have focused on the ability of LLMs   \n2 to achieve outcomes comparable to humans on academic and professional exams.   \n3 However, it is not clear whether such studies shed light on the extent to which   \n4 models show reasoning ability, and there is controversy about the significance and   \n5 implications of such results. We seek to look more deeply into the question of   \n6 how and whether the performance of LLMs on exams designed for humans re  \n7 flects true aptitude inherent in LLMs. We do so by making use of the tools of   \n8 psychometrics which are designed to perform meaningful measurement in test   \n9 taking. We leverage a unique dataset that captures the detailed performance of   \n10 over 5M students across 8 college-entrance exams given over a span of two years   \n11 in Brazil. With respect to the evaluation of LLM abilities, we show that the tools   \n12 of Item Response Theory (IRT) provide a more informative evaluation of model   \n13 performance than the usual accuracy metrics employed in previous studies. Dig  \n14 ging deeper, we show that the modeling framework of IRT, by explicitly modeling   \n15 the difficulty levels of questions, allows us to quantitatively distinguish between   \n16 LLMs that answer questions in \u201chuman-like\u201d patterns versus LLMs that do not.   \n17 We also show how to quantitatively identify cases in which exam results are not   \n18 reliable measurements of an LLM\u2019s ability. Using the tools of IRT we can also   \n19 identify specific questions that appear to be either much easier, or much harder,   \n20 for machines than for humans, and we give some reasons for those differences.   \n21 Overall, our study shows that the conventional focus on accuracy as the primary   \n22 performance metric for LLM studies does not allow us to deeply understand the   \n23 true capabilities of LLMs and compare them to that of humans. Thus, we claim   \n24 that psychometric modeling should play a larger role in the evaluation of LLM   \n25 capabilities on exams designed for humans. ", "page_idx": 0}, {"type": "text", "text": "26 1 Introduction ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "27 Large Language Models (LLMs) have demonstrated an impressive ability in performing well on ex  \n28 aminations designed for humans [25, 30], such as the US bar exam [27], the US Medical Licensing   \n29 Exam [21], and many others [45, 53]. This yields controversy in how researchers should interpret   \n30 such results, raising two kinds of criticisms of those apparent successes. The first is the potential for   \n31 publicly-given exams (and answers) to leak into models\u2019 training data. The second, and more fun  \n32 damental, issue is the notion of construct validity [44]. Most exams given to humans are intended to   \n33 measure a construct, e.g., legal analysis ability, medical analysis ability, etc. However, the reliability   \n34 of these exams in measuring the relevant construct for non-humans is usually ignored, and exams   \n35 that are valid in one context may not generalize across different groups, settings or tasks [24].   \n36 Formalizing the notion of construct validity in general is challenging. Since the 1950s, the field   \n37 of psychometrics has been grappling with how to design examinations that validly measure human   \n38 abilities along specific dimensions. The primary tool developed has been Item Response Theory   \n39 (IRT) [10], which has been employed in psychology, medicine, and especially in educational test  \n40 ing. IRT formalizes the unobserved construct as a continuous latent variable, and models stochastic   \n41 responses of humans to questions as a logistic regression conditional on that latent variable.   \n42 In this paper, we demonstrate how IRT can help shed light on whether LLMs are in fact show  \n43 ing human-like performance on exams intended for humans. As a case study, we use one of the   \n44 largest university-entrance exams in the world, a dataset comprising the performance of over 5 mil  \n45 lion Brazilian students on eight multiple-choice exams administered over two years. Each exam   \n46 was prepared and fitted to an IRT model by educational testing experts, giving us an unparalleled   \n47 opportunity to examine the performance of LLMs in detail.   \n48 Our results show that the LLMs we study reveal performance patterns that are consistent with ex  \n49 pected human behavior in many cases. Nonetheless, we also frequently observe significant deviation   \n50 from human-like behavior. We demonstrate how to use the tools of IRT to quantitatively distinguish   \n51 between human-like and non-human-like behavior. We then explore the differences between mod  \n52 els and exam types that correlate with differences in response patterns. Lastly, we use the tools of   \n53 IRT and psychometrics to identify cases where exams are not producing reliable estimates of LLM   \n54 ability and understand why this happens. This occurs because exams are in some cases too difficult   \n55 for the models, and in other cases too easy for them and as such they cannot properly measure the   \n56 ability of certain LLMs.   \n57 Moving beyond conclusions about current models, the broader contribution of our study is to demon  \n58 strate the power of IRT as a framework for evaluating LLMs. For example, in Classical Test Theory   \n59 (CTT), no attempt is made to assess the difficulty of individual questions, in-line with majority of in   \n60 standard LLM benchmarks that pursues accuracy [8, 43, 16, 4]. In contrast, as we will show below,   \n61 IRT simultaneously measures both test takers and exam questions (on the same scale). In doing so,   \n62 IRT allows one to distinguish between test takers with similar CTT (accuracy) scores, but differing   \n63 levels of true ability, by inspecting the pattern of correct or incorrect answers given. Moreover, we   \n64 deploy a broader set of tools (e.g., goodness-of-fit, Fisher information, discrimination index) which   \n65 enable us to evaluate which are the cases in which fitting the IRT model to the LLMs response   \n66 patterns gives us reliable estimates of the models\u2019 ability. Thus, we believe that the methods of our   \n67 study represent a valuable step beyond the use of simple accuracy for assessing whether both current   \n68 and future LLMs show human-like response patterns. ", "page_idx": 0}, {"type": "text", "text": "", "page_idx": 0}, {"type": "text", "text": "", "page_idx": 1}, {"type": "text", "text": "", "page_idx": 1}, {"type": "text", "text": "", "page_idx": 1}, {"type": "text", "text": "", "page_idx": 1}, {"type": "text", "text": "69 2 Related Work ", "text_level": 1, "page_idx": 1}, {"type": "text", "text": "70 Our study connects a number of research areas, spanning benchmarking LLMs, the applications of   \n71 item response theory, and the evaluation of LLMs using exams designed for humans.   \n72 Benchmarking LLMs. The most common strategy to evaluate LLMs is through traditional large  \n73 scale NLP benchmarks [46, 40, 11, 18, 16, 19, 4]. Conventionally, benchmark evaluation relies on   \n74 some notion of accuracy \u2013 the number of correct answers \u2013 as a proxy for ability [8, 43]. A key   \n75 distinction of our study is to draw attention to the limitations of the use of accuracy alone [34] for   \n76 evaluating the performance of LLMs on benchmarks in understanding the similarity between the   \n77 performance of models versus humans.   \n78 LLMs and Exams Designed for Humans. Many attempts to evaluate LLMs use exams designed   \n79 for humans, e.g., at college-entrance [1, 26] or college-level [14, 37, 47, 13, 41, 53]. These exams   \n80 also generally use accuracy as a metric of ability; one focus of our work is on how to use IRT   \n81 analysis to determine when such exams in fact perform meaningful measurement.   \n82 The Brazilian nationwide college-entrance exams we use in this work (ENEM), detailed in Sec  \n83 tion 4.1, were used in previous efforts to evaluate NLP models [38, 39, 26]. However, those studies   \n84 only used accuracy and did not make use of the IRT models associated with the exam, which is a   \n85 central aspect our work.   \n86 IRT in Machine Learning. Work in psychometrics (i.e., the measurement of human cognitive   \n87 abilities), detailed in Section 3, has shown that using accuracy as a exam score may not reflect the   \n88 true underlying abilities of individuals [15]. As a result, IRT has been advocated for use in machine   \n89 learning (ML) as an improved tool for benchmarking. The authors in [33] show that it is possible to   \n90 produce rankings of NLP models which are more reliable and stable using IRT than accuracy. Item   \n91 response theory has also been shown to help in spotting noisy questions, identifying overfitting,   \n92 selecting features, and designing better benchmarks for ML [29, 35, 20, 54, 22]. However, there is   \n93 a critical difference between the previous uses of IRT in ML and our work. Previous work uses IRT   \n94 by training an IRT model on the results of ML models solving question-answering or classification   \n95 questions. Our method is different: we leverage the fact that we have access to an IRT model trained   \n96 on human responses, and we do not retrain on model responses. We take this approach because   \n97 a central goal of our study is to explore whether LLMs are in fact following response patterns as   \n98 exhibited by human test takers.   \n99 Finally, we note that [42] shares some goals with our work. The investigation seeks to understand   \n100 whether LLMs show human-like response biases in surveys. We also look at the question of whether   \n101 LLMs show human-like response patterns, but we study the question along different dimensions:   \n102 (a) patterns of correct and incorrect answers in exams; and (b) the ways in which LLMs choose   \n103 incorrect answers. Additionally, Xia et al. [51] recognize that accuracy as a single metric does not   \n104 capture errors LLMs can make in intermediate steps when solving mathematical tasks, and they   \n105 systematically study those errors. ", "page_idx": 1}, {"type": "text", "text": "", "page_idx": 1}, {"type": "text", "text": "", "page_idx": 1}, {"type": "text", "text": "", "page_idx": 1}, {"type": "text", "text": "", "page_idx": 1}, {"type": "text", "text": "", "page_idx": 2}, {"type": "text", "text": "", "page_idx": 2}, {"type": "text", "text": "106 3 Background ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "107 In this section, we give some background of the tools we use from psychometrics. ", "page_idx": 2}, {"type": "text", "text": "108 Classical Test Theory (CTT): CTT [2] evaluates test takers based on the fraction of questions   \n109 they answer correctly. We call this score accuracy or CTT score of the test taker and we use these   \n110 two terms interchangeably. Inadequately, CTT does not differentiate between difficult and easy   \n111 questions, nor does it take into consideration the patterns of correct answers. For example, the CTT   \n112 score does not penalize a test taker who answers correctly difficult questions, but answers wrongly   \n113 easy ones \u2013 despite the fact that such a pattern might be indicative of randomness or cheating.   \n114 Item Response Theory (IRT): IRT [12, 5] is a model used extensively in psychometrics to measure   \n115 the ability level of the test takers and evaluate the difficulty of the test questions (which are referred   \n116 to as items in psychometrics). IRT takes into consideration the difficulty of the questions when eval  \n117 uating test-taker\u2019s performance and also makes use of the pattern of correct and incorrect responses   \n118 on the exam. The model associates with every test taker $j$ a parameter $\\theta_{j}$ , which corresponds to the   \n119 ability of $j$ . The two-parameter IRT model (2PL) associates every question $i$ with two parameters   \n120 $\\phi_{i}=(\\alpha_{i},\\beta_{i})$ . The model assumes that a test taker with ability $\\theta_{j}$ answers question $i$ associated with   \n121 $\\phi_{i}$ correctly with probability given by the logistic function: ", "page_idx": 2}, {"type": "text", "text": "", "page_idx": 2}, {"type": "equation", "text": "$$\np_{i j}=\\frac{e^{\\alpha_{i}(\\theta_{j}-\\beta_{i})}}{1+e^{\\alpha_{i}(\\theta_{j}-\\beta_{i})}}.\n$$", "text_format": "latex", "page_idx": 2}, {"type": "text", "text": "122 Parameter $\\alpha_{i}$ is the discrimination parameter and $\\beta_{i}$ is the difficulty of question $i$ . Note that the   \n123 ability $\\theta_{j}$ and the difficulty level $\\beta_{i}$ are in the same scale; after all, the difference $(\\theta_{j}-\\beta_{i})$ directly   \n124 affects $p_{i j}$ . For fixed $\\alpha_{i}$ , the difficulty parameter $\\beta_{i}$ is the value (on the ability scale) for which   \n125 $p_{i j}~=~0.5$ . Parameter $\\alpha_{i}$ characterizes how well question $i$ can differentiate among test takers   \n126 located at different points of the ability continuum; $\\alpha_{i}$ is proportional to the slope of $\\bar{p}_{i j}=p_{i}(\\theta_{j})$   \n127 at the point where $p_{i j}\\,=\\,0.5$ \u2013 the steeper the slope, the higher the discriminatory power of $i$ . All   \n128 the parameters of this model take values in $\\left(-\\infty,+\\infty\\right)$ . Note that any set of questions comprising   \n129 an exam spans a certain range of $\\beta_{i}$ values; such a set is not appropriate to assess test takers with   \n130 abilities outside this range.   \n131 The 3-Parameter IRT model (3PL for short) is an extension of the above model that also incorporates   \n132 a pseudo-guessing parameter $\\gamma_{i}$ . Thus, in 3PL every question $i$ is associated with three parameters   \n133 $\\Phi_{i}=(\\alpha_{i},\\beta_{i},\\gamma_{i})$ ; $\\alpha_{i}$ and $\\beta_{i}$ are the same as before. Intuitively, $\\gamma_{i}$ is the probability of answering   \n134 correctly based on random guess with $\\gamma_{i}\\in[0,1]$ . Thus, the probability of a test taker with ability $\\theta_{j}$   \n135 to answer question $i$ correctly is: $P_{i j}=\\gamma_{i}+(1-\\gamma_{i})p_{i j}$ .   \n136 Given test-taker responses, the parameters of the model can be estimated using Bayesian meth  \n137 ods [5]. In our case, the ENEM dataset came with a set of questions for which the parameters   \n138 $(\\alpha_{i},\\beta_{i},\\gamma_{i})$ had already been fitted by education experts [17]. Therefore, for each one of the LLMs   \n139 we considered, we only need to compute their ability parameters \u2013 given their response patterns.   \n140 Intuitively, large values of $\\theta$ correspond to test takers with high ability levels and vice versa. High   \n141 ability value $\\theta$ of an LLM implies better performance.   \n142 Although the ability levels of test takers can be used as a measure of their performance, one should   \n143 also know if the test takers are consistent with the model, e.g., they should answer easy questions   \n144 correctly if they answer difficult questions correctly. One index that enables us to evaluate the   \n145 consistency of the test takers with the model is the $l_{z}$ index [12]. Intuitively, the $l_{z}$ index is based   \n146 on the standardization of a test-taker\u2019s log-likelihood function given their theta values. Assume a   \n147 set of $I$ questions and test taker $j$ with ability $\\theta_{j}$ and response vector $\\mathbf{r}_{j}$ such that $\\mathbf{r}_{j}(i)=1$ (resp.   \n148 $\\mathbf{r}_{j}(i)\\;=\\;0)$ if $j$ answered question $i$ correctly (resp. wrongly). Then, the log-likelihood of $j$ is   \n149 simply: $\\begin{array}{r}{L_{j}\\;=\\;\\sum_{i\\in I}\\left[{\\bf r}_{j}(i)\\ln P_{i j}+(1-{\\bf r}_{j}(i))\\ln(1-P_{i j})\\right].}\\end{array}$ . To standardize $L_{j}$ we need both its   \n150 mean $(\\mathbb{E}[L_{j}])$ and variance $(\\mathrm{Var}(L_{j}))$ . Then, the $l_{z}$ score is computed as: ", "page_idx": 2}, {"type": "text", "text": "", "page_idx": 2}, {"type": "text", "text": "", "page_idx": 2}, {"type": "text", "text": "", "page_idx": 3}, {"type": "equation", "text": "$$\nl_{z}(j)=\\frac{L_{j}-\\mathbb{E}[L_{j}]}{\\sqrt{\\operatorname{Var}(L_{j})}}.\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "151 In a well-designed test, the $l_{z}$ scores are expected to have a unit normal distribution \u2013 this is the   \n152 case for humans taking the ENEM test (see for example Figure 3). In general, $l_{z}$ values close to 0   \n153 are considered good: it means the test takers\u2019 response patterns are consistent with what is expected   \n154 from them by the model. Negative $l_{z}(j)$ scores reflect an unlikely response vector. A positive $l_{z}(j)$   \n155 score indicates that $j$ has a more likely response vector than indicated by their ability.   \n156 We can access the amount of information that an item $i$ provides to estimate $\\theta$ under the 3PL model   \n157 by the Fisher information, which is given by: ", "page_idx": 3}, {"type": "text", "text": "", "page_idx": 3}, {"type": "equation", "text": "$$\n\\mathcal{T}_{i}(\\theta)=\\alpha_{i}^{2}\\left[\\frac{(p_{i}-\\gamma_{i})^{2}}{(1-\\gamma_{i})^{2}}\\right]\\left[\\frac{1-p_{i}}{p_{i}}\\right].\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "158 The total information of a test is simply the sum of item information, i.e., $\\begin{array}{r}{\\mathcal{Z}(\\boldsymbol{\\theta})\\;=\\;\\sum_{i\\in I}\\mathcal{Z}_{i}(\\boldsymbol{\\theta})}\\end{array}$ .   \n159 The Fisher information is connected with the standard error of the estimation, given by $S E(\\theta)=$   \n160 $1/\\sqrt{\\mathcal{Z}(\\theta)}$ . When a test has high Fisher information in a certain $\\theta$ range, the test has more discrimi  \n161 native power in that range, producing scores with less measurement errors. ", "page_idx": 3}, {"type": "text", "text": "162 4 Methods ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "163 4.1 The ENEM Exam ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "164 The Exame Nacional do Ensino M\u00b4edio (ENEM), world\u2019s second largest university entrance exam   \n165 behind Chinese\u2019s Gaokao exam, is taken by millions of Brazilian students each year [39]. ENEM   \n166 comprises questions requiring different levels of domain-specific knowledge and reasoning [3].   \n167 The exam is in Brazilian Portuguese and consists of four sections, each of which has 45 multiple  \n168 choice questions with five options [17]. Each section is treated as a separate exam for the purposes   \n169 of modeling via IRT. The four sections consist of the Humanities, the Languages and Codes, the   \n170 Natural Sciences, and the Math exams. The description of these exams is given in Appendix A.11.   \n171 Since 2009, the grades assigned to ENEM test-takers have been determined using IRT. Using IRT   \n172 helps to penalize guessing, differentiate among students that otherwise would get the same (CTT)   \n173 grade, and compare among students that took exams in different years. The ENEM organizers   \n174 release not only the exam content and questions, but also the student (anonymized) responses and   \n175 their CTT and IRT scores, which enables downstream studies.   \n176 From our standpoint, there are a number of relevant aspects of the process used by the ENEM de  \n177 velopers [17]. First, questions are given to a sample of students, whose answers are used to find   \n178 inconsistencies and errors. Next, an important test of construct validity is to verify the unidimen  \n179 sionality of the latent trait, for which the ENEM team uses Full Information Factor Analysis [7].   \n180 Finally, the IRT model itself is fit using the Marginal Maximum Likelihood Estimator [6]. Using the   \n181 results, the developers may exclude questions having poor model fit.   \n182 The exams, their solutions, and all the fitted parameters of the 3PL IRT model $(\\theta_{j},\\alpha_{i},\\beta_{i},\\gamma_{i})$ are   \n183 publicly available at the Brazilian government website [17]. To the best of our knowledge, these data   \n184 are the largest and most comprehensive public dataset based on item-response theory available. The   \n185 datasets contain questions and complete response patterns of all students taking the exams in 2022   \n186 and 2023. Questions for the 2023 exam were released in November 2023, minimizing the chance   \n187 they are in training data for most of the LLMs we considered. However, we expect fragments of the   \n188 exam being in the training data (e.g. poems, and any other widely available material used as part of   \n189 a question) 1. The number of test takers per year ranged from 2.2M to 3.7M.   \n190 The ENEM exams are initially made available as PDF files; we used the Python library $P\\mathrm{y}P D F2$ ,   \n191 followed by regular expressions and some manual adjustments to extract each question from its   \n192 exam file. In order to account for possible effects of Language, as diagnosed in previous work [31],   \n193 we translated all questions to English and run all experiments in Portuguese and English. For those   \n194 exam questions that incorporated images, we used the version of the exam designed for blind people   \n195 containing textual descriptions of the images. We manually audited all questions in 2022 and 2023   \n196 exams to ensure their quality (Appendix A.1). ", "page_idx": 3}, {"type": "text", "text": "", "page_idx": 3}, {"type": "text", "text": "", "page_idx": 3}, {"type": "text", "text": "", "page_idx": 3}, {"type": "text", "text": "", "page_idx": 3}, {"type": "text", "text": "", "page_idx": 4}, {"type": "text", "text": "", "page_idx": 4}, {"type": "text", "text": "197 4.2 Models ", "text_level": 1, "page_idx": 4}, {"type": "text", "text": "198 We evaluate the following family of models: the open source models Mistral-7B, Gemma-7B,   \n199 Llama2-7B, Llama2-13B, Llama3-8B, and GPT 3.5. For the open source models, we evaluate   \n200 on both instructed and non-instructed tuned versions. Our choice of models enables the study of   \n201 models of similar size (the majority of our models are of size 7B), but also introduces diversity of   \n202 architectures (GPT, Gemma, Mistral, Llama), size (7B vs. 13B), training data (Llama2 vs. Llama3),   \n203 and training strategies (with and without instruction tuning).   \n204 We prompt models with $\\{0,1,4\\}$ -shots, following conventional question-answer benchmark   \n205 prompting strategies [32] (example prompts in Appendix A.4). We measure model\u2019s next token   \n206 probability across five option letters, and average predictions across 30 shuffles of the order of the   \n207 answer choices to correct for the well-known effect of position bias [28] (Details in Appendix A.4). ", "page_idx": 4}, {"type": "text", "text": "", "page_idx": 4}, {"type": "text", "text": "208 5 Results ", "text_level": 1, "page_idx": 4}, {"type": "text", "text": "209 In this section, we present our main findings. All the results we show here are for the 2023 ENEM   \n210 exams, with four-shot prompting. Results for the 2022 ENEM exam and for zero-shot and one-shot   \n211 prompting and for open source instructed tuned models are shown in Appendices A.6 \u2013 A.9. The   \n212 results we show in this section are strongly consistent with the results we get for the 2022 ENEM   \n213 exam and for one-shot prompting. ", "page_idx": 4}, {"type": "text", "text": "214 5.1 Accuracy vs. Ability Level ", "text_level": 1, "page_idx": 4}, {"type": "text", "text": "215 We first investigate how humans compare to LLMs when IRT parameter $\\theta$ is used instead of accuracy   \n216 (the metric that is employed in most LLM benchmarking, e.g., [8, 43]). In Figure 1 we plot the CTT   \n217 score (accuracy) vs IRT score $(\\theta)$ for 30 shuffles of answer options for each model. The light blue   \n218 background points correspond to the humans who took the exam. Each of the closed curves in the   \n219 figure corresponds to one LLM, and shows the central $90\\%$ of the LMM\u2019s distribution.   \nFirst, we observe that there are many cases where identical accuracy scores result in different $\\theta$   \n221 scores. This reflects the fact that IRT takes into account not just the number, but also the pattern   \nof correct answers. Second, for many LLMs, particularly in the Humanities and Languages exams,   \n223 there is overall greater variability in the accuracy score than in the IRT score. This suggests that IRT   \n224 is less sensitive to the variations in LLM output that are due to the LLM\u2019s inherent randomness.   \nTo compare the performance between LLMs and humans, we compare their IRT scores (\u03b8). Recall   \n226 that IRT score of 0 corresponds to the average ability of a human test taker. Across all four subjects,   \n227 the majority of models have CTT and IRT scores overlapping with humans. LLMs in general achieve   \n228 $\\theta$ scores above that of the human average in Humanities, Languages, and Natural Sciences, but below   \n229 human average in Mathematics. Looking at specific models, we find the Llama2 models at the lower   \n230 end of $\\theta$ scores, Mistral and Llama3 in the middle range, and GPT-3.5 and Gemma-7B at the higher   \n231 end of $\\theta$ scores.   \n232 The language of the exam affects some models\u2019 performance. In Languages and Natural Sciences,   \n233 GPT-3.5 tends to perform better in Portuguese compared to English, while in Humanities and Natural   \n234 Sciences, the Llama models tend to perform worse in Portuguese than in English. This suggests that   \n235 there are differences regarding the reasoning ability and the amount of knowledge accessible to the   \n236 models in each language.   \n237 Importantly, outlier models all tend to have higher accuracy and/or lower IRT scores than humans.   \n238 These models answer more questions correctly than humans do, but show error patterns that are not   \n239 entirely human-like. We dig into this phenomenon next. ", "page_idx": 4}, {"type": "text", "text": "", "page_idx": 4}, {"type": "image", "img_path": "Cth1PyCwZt/tmp/3d5bfcf74717d7535eb72d603f843b3905a94130311bf30f375f1c223663da7e.jpg", "img_caption": ["Figure 1: Distribution of CTT (accuracy) and IRT scores for humans and LLMs for the ENEM 2023 exam. LLMs are non-instructed tuned open source models and GPT3.5 with four-shot. LLM datapoints are computed from different shuffles of the order of answer choices. "], "img_footnote": [], "page_idx": 5}, {"type": "text", "text": "", "page_idx": 5}, {"type": "text", "text": "", "page_idx": 5}, {"type": "text", "text": "240 5.2 Response Patterns ", "text_level": 1, "page_idx": 5}, {"type": "text", "text": "241 One of our goals is to assess whether the LLMs we examine show good fit to the ENEM IRT model,   \n242 as crafted by the educational expert team described in Section 4.1. Intuitively, a test taker showing   \n243 good fit to an IRT model is an individual $j$ that tends to make less frequent mistakes on \u201ceasy\u201d   \n244 questions (question $i$ with $\\beta_{i}\\;<\\;\\theta_{j})$ while making more frequent mistakes on \u201chard\u201d questions   \n245 (question $i$ with $\\beta_{i}>\\theta_{j}$ ). Thus, to assess fit we need to inspect the response patterns of the LLMs.   \n246 Figure 2 shows the response patterns of LLMs for the 2023 exam. Every cell $(i,j)$ corresponds to   \n247 the probability that LLM $i$ answered question $j$ correctly, where probabilities are computed over the   \n248 30 shuffles. We use gray scale with a black (resp. white) cell representing 1 (resp. 0). Questions are   \n249 ordered in increasing order of their $\\beta$ values. Generally, rows with darker overall patterns (higher   \n250 correctness) are indicative of higher $\\theta$ scores.   \n251 The figure demonstrates a number of points. For example, on the Math exam, the figure exhibits a   \n252 response pattern that appears to show low $\\theta$ values for all models, which confirms results in Figure 1.   \n253 In addition, the figure shows that for some questions, the 30 shuffles of answer choices of a given   \n254 model are often either all correct or all incorrect. However, there are some grey areas in the figure for   \n255 all the exams, indicating that shuffling the options can affect the LLM\u2019s answers on certain items.   \n256 Furthermore, the patterns show that many questions appear to be either \u201ceasy\u201d (black) or \u201chard\u201d   \n257 (white) for all models at the same time. Likewise, in many cases models show similar performance   \n258 on the English and Portuguese versions of a given question.   \n259 Overall, the response patterns we observe suggest that the Math exam is \u201ctoo difficult,\u201d with mod  \n260 els often resorting to guessing. On the other hand, most LLMs consistently answer correctly the   \n261 questions in the Humanities exam, implying that this is an easy exam for them. The performance of   \n262 LLMs in the Natural Science exam is the most interesting as there are blocks of questions that most   \n263 LLMs answer consistently correctly, interleaved with blocks of questions that most LLMs answer   \n264 incorrectly. This suggests that there are questions that are easy for humans but difficult for LLMs   \n265 and vice versa. In the next subsection we analyze this phenomenon more closely. ", "page_idx": 5}, {"type": "text", "text": "", "page_idx": 5}, {"type": "text", "text": "", "page_idx": 5}, {"type": "text", "text": "", "page_idx": 5}, {"type": "image", "img_path": "Cth1PyCwZt/tmp/374bf2a5b93575349a4e6225bc7fe8d380aa5c0fdc098ade6ab6c1f7f6a78b78.jpg", "img_caption": ["Figure 2: Response patterns for each LLM, where darker indicates more often correct (across random option shuffles). Questions are sorted in increasing difficulty $\\beta$ value). LLMs are noninstructed tuned open source models and GPT3.5 with four-shot. "], "img_footnote": [], "page_idx": 6}, {"type": "text", "text": "", "page_idx": 6}, {"type": "text", "text": "266 5.3 Reliability of IRT scores for LLMs ", "text_level": 1, "page_idx": 6}, {"type": "text", "text": "267 In this section, we investigate whether the ENEM exam is a valid test for LLMs\u2019 ability, in the same   \n268 way it is for humans. Intuitively, we want to define measures that allow us to quantify to what extent   \n269 we trust the IRT scores we obtained for LLMs. We propose three different ways of doing this. The   \n270 first is goodness-of-fit that quantifies whether the response of LLMs fit the IRT model. The second   \n271 is based on Fisher information, measuring how much information the exam provides for estimating   \n272 the $\\theta\\mathbf{s}$ in a certain range. Finally, we use the discrimination index which evaluates the capacity of   \n273 questions to accurately distinguish between high and low performing test takers.   \n274 Goodness-of-fit: We use the $l_{z}$ score (see Section 3) assess whether the test taker is behaving in   \n275 a manner consistent with the model. Alternatively, we ask what is the appropriateness of a test  \n276 taker\u2019s estimated $\\hat{\\theta}$ as a measure of the test taker\u2019s true $\\theta?$ For example, imagine that an LLM has   \n277 a response pattern of missing easy questions and correctly answering more difficult ones. Such a   \n278 pattern may arise because the LLM was lucky on the hard questions, or it may arise because the   \n279 LLM had access to memorized patterns that assisted in answering the hard questions. Generally,   \n280 low $l_{z}$ scores suggest that the $\\theta$ estimate of the model is less reliable [12].   \n281 In Figure 3 we show $l_{z}$ scores plotted against $\\theta$ scores of LLMs across the four exams in 2023 (2022   \n282 is shown in Appendix A.9). As in previous plots, the light blue points in the background show the   \n283 distribution of the same two scores for the human test takers. Starting again with the Math exam, we   \n284 note that $l_{z}$ values are low, but now we can see that the response patterns of the LLMs are indeed   \n285 quite human-like; LLMs behave like humans with similarly low $l_{z}$ values. One possible reason for   \n286 this behavior is that the Mathematics exam tends to be the harder exam of ENEM, leading to more   \n287 guessing, which may make the human $l_{z}$ values for Mathematics smaller.   \n288 For the Languages exam, models perform better in general (higher $\\theta$ values) and the most $l_{z}$ scores   \n289 being close to 0 (and with a similar spread as the human distribution of $l_{z}$ \u2019s) suggest that these $\\theta$   \n290 estimates are reliable \u2013 the models are showing human-like response patterns.   \n291 The results become more nuanced as we look at the Natural Sciences exam. For this exam, most   \n292 models, including the high performing ones (i.e., GPT-3.5 and Gemma-7B), show values well out  \n293 side the human distribution, with a long tail in the negative values of $l_{z}$ . Comparing the GPT-3.5 and   \n294 Gemma-7B results in Figures 1 and 4, we can infer that the high accuracy (CTT scores) achieved by   \n295 these models on the Natural Sciences exam are quite misleading; although GPT-3.5 and Gemma-7B   \n296 answer many questions correctly, their response pattern is very unlikely, with very low $l_{z}$ values.   \n297 This corroborates with Figure 2, which shows an interchange of blocks of correct and incorrect   \n298 answers from the models, creating an unlikely response pattern.   \n299 In Humanities, almost all LLMs perform reasonably well, achieving $\\theta$ scores above zero (the average   \n300 human level). However, Llama2-7B, while obtaining above average accuracy scores (Figure 1) and   \n301 good $\\theta$ scores, has low average $l_{z}$ scores. This suggests that the IRT scores Llama2-7B may be not   \n302 reliable. Examination of the corresponding rows in Figure 2 shows that this is the only model that   \n303 does not have a consistent response pattern across shuffles, leading to the observed low $l_{z}$ score.   \n304 Fisher Information: We investigate further whether the ENEM exams are giving us accurate esti  \n305 mates of the LLMs ability levels from another standpoint \u2013 that of Fisher Information (see Section 3,   \n306 Equation (3)). Intuitively, Fisher Information quantifies whether there was enough information in   \n307 the test to infer the ability level of a test taker at a certain ability level. Figure 4 shows, for every   \n308 ENEM exam, the total Fisher Information ${\\mathcal{T}}(\\theta)$ on the top plot, and the $\\theta$ scores for the models $95\\%$   \n309 Confidence Interval (CI) computed using the shuffles) on the bottom plot. This plot reinforces the   \n310 observation that for some models in Natural Sciences and for all models in Mathematics, the mod  \n311 els\u2019 $\\theta$ are not in the range of the exam with highest information \u2013 the models ability levels fall in the   \n312 tail of the Fisher Information histogram. Hence, the Math exam is not useful for making meaningful   \n313 measurements of these LLMs, casting doubt on the informativeness of the models\u2019 $\\theta$ scores on this   \n314 exam. The lack of discrimination ability of this exam is reflected by the responses for many models   \n315 showing apparently random response patterns in the corresponding heatmap (see Figure 2).   \n316 Discrimination Index: To further assess the reliability of the IRT scores, we also turn into psycho  \n317 metrics and use the notion of the item discrimination index $(D I)$ , which measures how well an item   \n318 on a test distinguishes between high and low scorers on the entire test [9]. Let $P_{h}$ (resp. $P_{l}$ ) be the   \n319 proportion of the top $25\\%$ (resp. low $25\\%$ ) LLMs (in terms of $\\theta$ , including the shuffles) that correctly   \n320 answer the item; then $D I=P_{h}-P_{l}$ , the difference of the two proportions. DI ranges from -1 to 1,   \n321 and questions with DI higher than 0.2 are considered good, while lower DI indicates flaws [50].   \n322 Figure 5 shows the distribution of the discrimination indices computed for humans and LLMs for the   \n323 2023 exam. Overall, we notice that discrimination indices computed for LLMs are more negative   \n324 compared to those of humans. We also observe that a significant fraction of Math questions have low   \n325 discriminative power, reinforcing the hypothesis that this exam is not well designed to measure Math   \n326 abilities for LLMs. Nonetheless, the Humanities and Languages have several questions with very   \n327 good discriminative power. Interestingly, the Natural Sciences exam appears to follow a bimodal   \n328 distribution, containing both informative and poorly-designed questions. This may be a reflection of   \n329 the fact that the Natural Sciences exam is a hybrid test, containing a mix of knowledge-based items   \n330 and items that demand more complex reasoning over numbers and images, which can be less useful   \n331 for evaluating the current state-of-the-art LLMs.   \n332 Attributes affecting reliability of IRT scores: In a further investigation, shown in Appendix A.2,   \n333 we explore potential causes of low discrimination. We investigate item attributes such as the ex  \n334 istence of images or numbers in the questions as we believe that these attributes impede LLMs   \n335 from understanding the question properly. Our preliminary results suggest that LLMs\u2019 ability to   \n336 understand math questions and parse images is sub-par compared to their capacity in answering   \n337 pure text-based questions. In Appendix A.10 we show examples of non-discriminating and highly   \n338 discriminating items for the 2023 Natural Sciences exam. In Appendix A.3, we reach a similar   \n339 conclusion by looking at model accuracy against model perplexity, a model intrinsic metric. ", "page_idx": 6}, {"type": "text", "text": "", "page_idx": 6}, {"type": "text", "text": "", "page_idx": 6}, {"type": "text", "text": "", "page_idx": 6}, {"type": "image", "img_path": "Cth1PyCwZt/tmp/25ca134a878bb7f11fd26170e6c8f09a6195ff66f7a0823c6873de423d2ee80c.jpg", "img_caption": ["Figure 3: Distribution of $l_{z}$ and IRT scores for humans and LLMs. LLMs are non-instructed tuned open source models and GPT3.5 with 4-shot. LLM datapoints are computed from different shuffles. "], "img_footnote": [], "page_idx": 7}, {"type": "text", "text": "", "page_idx": 7}, {"type": "text", "text": "", "page_idx": 7}, {"type": "image", "img_path": "Cth1PyCwZt/tmp/a03e43f6de6b9bfc0393c6b882cf5dea3bae548bc151db0d3da5189f3a4ce2ca.jpg", "img_caption": ["Figure 4: Total Fisher information of the exams and the IRT scores $95\\%$ Confidence Interval (CI)) for LLMs. LLM datapoints are computed from different shuffles. "], "img_footnote": [], "page_idx": 7}, {"type": "text", "text": "", "page_idx": 7}, {"type": "image", "img_path": "Cth1PyCwZt/tmp/ba3f0df406f1c2473d74ed21b931ebcc2527187453658484e27a354f49d4c79d.jpg", "img_caption": ["Figure 5: Discrimination Indices for questions in the 2023 exam for both Humans and LLMs. "], "img_footnote": [], "page_idx": 8}, {"type": "text", "text": "", "page_idx": 8}, {"type": "text", "text": "", "page_idx": 8}, {"type": "text", "text": "", "page_idx": 8}, {"type": "text", "text": "340 6 Conclusions ", "text_level": 1, "page_idx": 8}, {"type": "text", "text": "341 The ongoing debate in LLM evaluation centers around whether exams designed for humans are   \n342 appropriate tools for measuring the performance of LLMs. In this paper, we provide a case study   \n343 that illustrates methods that can be used to address this question, as well as specific results for a   \n344 range of current LLMs. We leverage the largest known human exam for which a public IRT model   \n345 is available, and show that IRT can be leveraged to distinguish between human-like and non-human  \n346 like responses under the model. We show cases where LLMs respond in non-human-like ways and   \n347 show how to identify those cases using a model-fit metric. Further, we show that using IRT we   \n348 can determine when an exam is capable of making meaningful measurement of an LLM\u2019s ability   \n349 in a given subject area. Using our evaluation framework, we find that the ENEM Math exam is not   \n350 appropriate to make meaningful measurements of the models\u2019 ability, for the LLMs we study. At   \n351 the same time, Humanities and Language exams are better suited for evaluating the LLMs\u2019 abilities   \n52 on those subjects. We conclude that IRT modeling, drawing on a long history of psychometric   \n353 theory, provides a set of crucial tools for assessing whether exams designed for humans are actually   \n354 meaningful measures of LLM ability. Our results suggest that they should be used in future studies   \n355 when questions are raised regarding the performance of LLMs on human exams. ", "page_idx": 8}, {"type": "text", "text": "356 References ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "357 [1] Josh Achiam et al. 2023. GPT-4 technical report. arXiv preprint arXiv:2303.08774.   \n358 [2] M.J. Allen and W. M. Yen. 2002. Introduction to Measurement Theory. Waveland Press.   \n359 [3] Thales Sales Almeida, Thiago Laitz, Giovana K Bona\u00b4s, and Rodrigo Nogueira. 2023. Bluex: a bench  \n360 mark based on brazilian leading universities entrance exams. In Brazilian Conference on Intelligent   \n361 Systems. Springer, 337\u2013347.   \n362 [4] BIG-bench authors. 2023. Beyond the imitation game: quantifying and extrapolating the capabilities of   \n363 language models. Transactions on Machine Learning Research. https://openreview.net/forum?i   \n364 $\\mathtt{d}=$ uyTL5Bvosj.   \n365 [5] F. B. Baker and S.-H. Kim. 2004. Item Response Theory: Parameter Estimation Techniques. Marcel   \n366 Dekkerm, Inc.   \n367 [6] R Darrell Bock and Murray Aitkin. 1981. Marginal maximum likelihood estimation of item parameters:   \n368 application of an em algorithm. Psychometrika, 46, 4, 443\u2013459.   \n369 [7] R Darrell Bock, Robert Gibbons, and Eiji Muraki. 1988. Full-information item factor analysis. Applied   \n370 psychological measurement, 12, 3, 261\u2013280.   \n371 [8] Se\u00b4bastien Bubeck et al. 2023. Sparks of artificial general intelligence: early experiments with gpt-4.   \n372 arXiv preprint arXiv:2303.12712.   \n373 [9] Man Ching Esther Chan. 2015. Young learners: an examination of the psychometric properties of the   \n374 early literacy knowledge and skills instrument. Journal of Psychoeducational Assessment, 33, 7, 607\u2013   \n375 621.   \n376 [10] Yunxiao Chen, Xiaoou Li, Jingchen Liu, and Zhiliang Ying. 2021. Item response theory \u2013 a statistical   \n377 framework for educational and psychological measurement. (2021). arXiv: 2108.08604 [stat.ME].   \n378 [11] Karl Cobbe et al. 2021. Training verifiers to solve math word problems. arXiv preprint   \n379 arXiv:2110.14168.   \n380 [12] Rafael Jaime De Ayala. 2013. The theory and practice of item response theory. Guilford Publications.   \n381 [13] Iddo Drori et al. 2022. A neural network solves, explains, and generates university math problems by pro  \n382 gram synthesis and few-shot learning at human level. Proceedings of the National Academy of Sciences,   \n383 119, 32, e2123433119. eprint: https://www.pnas.org/doi/pdf/10.1073/pnas.2123433119.   \n384 DOI: 10.1073/pnas.2123433119.   \n385 [14] Iddo Drori et al. 2023. From human days to machine seconds: automatically answering and generating   \n386 machine learning final exams. In Proceedings of the 29th ACM SIGKDD Conference on Knowledge   \n387 Discovery and Data Mining (KDD \u201923). Association for Computing Machinery, New York, NY, USA,   \n388 3947\u20133955. ISBN: 9798400701030. DOI: 10.1145/3580305.3599827.   \n389 [15] Mehtap Erguven. 2013. Two approaches to psychometric process: classical test theory and item response   \n390 theory. Journal of Education, 2, 2, 23\u201330.   \n391 [16] Dan Hendrycks, Collin Burns, Steven Basart, Andy Zou, Mantas Mazeika, Dawn Song, and Jacob   \n392 Steinhardt. 2020. Measuring massive multitask language understanding. In International Conference   \n393 on Learning Representations.   \n394 [17] Instituto Nacional de Estudos e Pesquisas Educacionais An\u00b4\u0131sio Teixeira. 2024. Microdados do Enem   \n395 2023. INEP. https://www.gov.br/inep/pt-br/acesso-a-informacao/dados-abertos/micr   \n396 odados/enem.   \n397 [18] Mandar Joshi, Eunsol Choi, Daniel S. Weld, and Luke Zettlemoyer. 2017. Triviaqa: a large scale distantly   \n398 supervised challenge dataset for reading comprehension. In Proceedings of the 55th Annual Meeting of   \n399 the Association for Computational Linguistics. Association for Computational Linguistics, Vancouver,   \n400 Canada, (July 2017).   \n401 [19] Douwe Kiela et al. 2021. Dynabench: rethinking benchmarking in nlp. In Proceedings of the 2021 Con  \n402 ference of the North American Chapter of the Association for Computational Linguistics: Human Lan  \n403 guage Technologies, 4110\u20134124.   \n404 [20] Adrienne Kline, Theresa Kline, and Joon Lee. 2021. Item response theory as a feature selection and   \n405 interpretation tool in the context of machine learning. Medical & Biological Engineering & Computing,   \n406 59, (Jan. 2021). DOI: 10.1007/s11517-020-02301-x.   \n407 [21] TH Kung et al. 2023. Performance of chatgpt on usmle: potential for ai-assisted medical education using   \n408 large language models. (2023).   \n409 [22] John P Lalor, Hao Wu, and Hong Yu. 2016. Building an evaluation scale using item response theory. In   \n410 Proceedings of the Conference on Empirical Methods in Natural Language Processing. Conference on   \n411 Empirical Methods in Natural Language Processing. Vol. 2016. NIH Public Access, 648.   \n412 [23] Rob R Meijer. 1996. Person-fit research: an introduction. Applied Measurement in Education, 9, 1, 3\u20138.   \n413 [24] Samuel Messick. 1995. Standards of validity and the validity of standards in performance asessment.   \n414 Educational measurement: Issues and practice, 14, 4, 5\u20138.   \n415 [25] Arvind Narayanan and Sayash Kapoor. 2023. Gpt-4 and professional benchmarks: the wrong answer to   \n416 the wrong question. (2023). https://www.aisnakeoil.com/p/gpt-4-and-professional-benc   \n417 hmarks.   \n418 [26] Desnes Nunes, Ricardo Primi, Ramon Pires, Roberto Lotufo, and Rodrigo Nogueira. 2023. Evaluat  \n419 ing gpt-3.5 and gpt-4 models on brazilian university admission exams. (2023). arXiv: 2303.17003   \n420 [cs.CL].   \n421 [27] OpenAI. 2023. Gpt-4 technical report. (2023). arXiv: 2303.08774 [cs.CL].   \n422 [28] Pouya Pezeshkpour and Estevam Hruschka. 2023. Large language models sensitivity to the order of   \n423 options in multiple-choice questions. (2023). arXiv: 2308.11483 [cs.CL].   \n424 [29] Fernando Plumed, Ricardo Prud\u02c6encio, Adolfo Mart\u0131\u00b4nez-Uso\u00b4, and Jose Hernandez-Orallo. 2016. Making   \n425 sense of item response theory in machine learning. In (Sept. 2016). DOI: 10.3233/978-1-61499-672   \n426 -9-1140.   \n427 [30] Deborah Raji, Emily Denton, Emily M. Bender, Alex Hanna, and Amandalynne Paullada. 2021. Ai and   \n428 the everything in the whole wide world benchmark. In Proceedings of the Neural Information Processing   \n429 Systems Track on Datasets and Benchmarks. J. Vanschoren and S. Yeung, (Eds.) Vol. 1. Curran. https   \n430 ://datasets-benchmarks-proceedings.neurips.cc/paper_files/paper/2021/file/084b   \n431 6fbb10729ed4da8c3d3f5a3ae7c9-Paper-round2.pdf.   \n432 [31] Leonardo Ranaldi and Giulia Pucci. 2023. Does the english matter? elicit cross-lingual abilities of large   \n433 language models. In Proceedings of the 3rd Workshop on Multi-lingual Representation Learning (MRL),   \n434 173\u2013183.   \n435 [32] Joshua Robinson and David Wingate. 2023. Leveraging large language models for multiple choice ques  \n436 tion answering. In The Eleventh International Conference on Learning Representations. https://ope   \n437 nreview.net/forum?id $\\cdot$ yKbprarjc5B.   \n438 [33] Pedro Rodriguez, Joe Barrow, Alexander Miserlis Hoyle, John P. Lalor, Robin Jia, and Jordan Boyd  \n439 Graber. 2021. Evaluation examples are not equally informative: how should that change NLP leader  \n440 boards? In Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics   \n441 and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers).   \n442 Chengqing Zong, Fei xia, Wenjie Li, and Roberto Navigli, (Eds.) Association for Computational Lin  \n443 guistics, Online, (Aug. 2021), 4486\u20134503. DOI: 10.18653/v1/2021.acl-long.346.   \n444 [34] Rylan Schaeffer, Brando Miranda, and Sanmi Koyejo. 2023. Are emergent abilities of large language   \n445 models a mirage? In Advances in Neural Information Processing Systems. A. Oh, T. Naumann, A.   \n446 Globerson, K. Saenko, M. Hardt, and S. Levine, (Eds.) Vol. 36. Curran Associates, Inc., 55565\u201355581.   \n447 https://proceedings.neurips.cc/paper_files/paper/2023/file/adc98a266f45005c403   \n448 b8311ca7e8bd7-Paper-Conference.pdf.   \n449 [35] Jo\u02dcao Sedoc and Lyle Ungar. 2020. Item response theory for efficient human evaluation of chatbots. In   \n450 Proceedings of the First Workshop on Evaluation and Comparison of NLP Systems. Steffen Eger, Yang   \n451 Gao, Maxime Peyrard, Wei Zhao, and Eduard Hovy, (Eds.) Association for Computational Linguistics,   \n452 Online, (Nov. 2020), 21\u201333. DOI: 10.18653/v1/2020.eval4nlp-1.3.   \n453 [36] Weijia Shi, Anirudh Ajith, Mengzhou Xia, Yangsibo Huang, Daogao Liu, Terra Blevins, Danqi Chen,   \n454 and Luke Zettlemoyer. 2023. Detecting pretraining data from large language models. In The Twelfth   \n455 International Conference on Learning Representations.   \n456 [37] Bruno Silva, Leonardo Nunes, Roberto Esteva\u02dco, and Ranveer Chandra. 2023. Gpt-4 as an agronomist   \n457 assistant? answering agriculture exams using large language models. arXiv preprint arXiv:2310.06225.   \n458 [38] Igor Cataneo Silveira and Denis Deratani Maua\u00b4. 2017. University entrance exam as a guiding test for   \n459 artificial intelligence. In 2017 Brazilian Conference on Intelligent Systems (BRACIS), 426\u2013431. DOI:   \n460 10.1109/BRACIS.2017.44.   \n461 [39] Igor Cataneo Silveira and Denis Deratani Maua\u00b4. 2018. Advances in automatically solving the enem. In   \n462 2018 7th Brazilian Conference on Intelligent Systems (BRACIS). IEEE, 43\u201348.   \n463 [40] Alon Talmor, Jonathan Herzig, Nicholas Lourie, and Jonathan Berant. 2019. Commonsenseqa: a ques  \n464 tion answering challenge targeting commonsense knowledge. ArXiv, abs/1811.00937. https://api.s   \n465 emanticscholar.org/CorpusID:53296520.   \n466 [41] Christian Terwiesch. 2023. Would Chat GPT3 Get a Wharton MBA? A Prediction Based on Its Perfor  \n467 mance in the Operations Management Course. Tech. rep. Mack Institute for Innovation Management at   \n468 the Wharton School, University of Pennsylvania.   \n469 [42] Lindia Tjuatja, Valerie Chen, Sherry Tongshuang Wu, Ameet Talwalkar, and Graham Neubig. 2024. Do   \n470 llms exhibit human-like response biases? a case study in survey design. (2024). arXiv: 2311.04076   \n471 [cs.CL].   \n472 [43] Hugo Touvron et al. 2023. Llama 2: open foundation and fine-tuned chat models. arXiv preprint   \n473 arXiv:2307.09288.   \n474 [44] Sean Trott. 2024. Can large language models help augment english psycholinguistic datasets? Behavior   \n475 Research Methods, 1\u201319.   \n476 [45] Lakshmi Varanasi. 2023. Gpt-4 can ace the bar, but it only has a decent chance of passing the cfa exams.   \n477 here\u2019s a list of difficult exams the chatgpt and gpt-4 have passed. (2023). https://www.businessins   \n478 ider.com/list-here-are-the-exams-chatgpt-has-passed-so-far-2023-1.   \n479 [46] Alex Wang, Amanpreet Singh, Julian Michael, Felix Hill, Omer Levy, and Samuel Bowman. 2018. Glue:   \n480 a multi-task benchmark and analysis platform for natural language understanding. In Proceedings of the   \n481 2018 EMNLP Workshop BlackboxNLP: Analyzing and Interpreting Neural Networks for NLP, 353\u2013355.   \n482 [47] Xiaoxuan Wang et al. 2023. Scibench: evaluating college-level scientific problem-solving abilities of   \n483 large language models. arXiv preprint arXiv:2307.10635.   \n484 [48] Xinpeng Wang, Bolei Ma, Chengzhi Hu, Leon Weber-Genzel, Paul Ro\u00a8ttger, Frauke Kreuter, Dirk Hovy,   \n485 and Barbara Plank. 2024. \u201d my answer is c\u201d: first-token probabilities do not match text answers in   \n486 instruction-tuned language models. arXiv preprint arXiv:2402.14499.   \n487 [49] Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Fei xia, Ed Chi, Quoc V Le, Denny Zhou,   \n488 et al. 2022. Chain-of-thought prompting elicits reasoning in large language models. Advances in neural   \n489 information processing systems, 35, 24824\u201324837.   \n490 [50] Margaret Wu and Ray Adams. 2007. Applying the Rasch model to psycho-social measurement: A prac  \n491 tical approach. Educational Measurement Solutions Melbourne.   \n492 [51] Shijie Xia, Xuefeng Li, Yixin Liu, Tongshuang Wu, and Pengfei Liu. 2024. Evaluating mathematical   \n493 reasoning beyond accuracy. arXiv preprint arXiv:2404.05692.   \n494 [52] Longhui Yu et al. 2023. Metamath: bootstrap your own mathematical questions for large language mod  \n495 els. arXiv preprint arXiv:2309.12284.   \n496 [53] Wanjun Zhong, Ruixiang Cui, Yiduo Guo, Yaobo Liang, Shuai Lu, Yanlin Wang, Amin Saied, Weizhu   \n497 Chen, and Nan Duan. 2023. Agieval: a human-centric benchmark for evaluating foundation models.   \n498 arXiv preprint arXiv:2304.06364.   \n499 [54] Yan Zhuang et al. 2023. Efficiently measuring the cognitive ability of llms: an adaptive testing perspec  \n500 tive. arXiv preprint arXiv:2306.10512. ", "page_idx": 9}, {"type": "text", "text": "", "page_idx": 10}, {"type": "text", "text": "", "page_idx": 11}, {"type": "table", "img_path": "Cth1PyCwZt/tmp/6492105370f0c6e1dec41d52340d9cf0528465fb32790ac02fe433ec12c7ab68.jpg", "table_caption": [], "table_footnote": [], "page_idx": 12}, {"type": "text", "text": "Table 1: Random choice selection performance on English and Portuguese versions of 2022 test 4 subjects. ", "page_idx": 12}, {"type": "text", "text": "501 A Supplemental Material ", "text_level": 1, "page_idx": 12}, {"type": "text", "text": "502 A.1 Manual auditing of exam questions ", "text_level": 1, "page_idx": 12}, {"type": "text", "text": "503 Assuming the original questions written by the ENEM authorities are good test instruments for   \n504 testing student capability, we focus on ensuring the quality of adapted dataset for LLM evaluation.   \n505 We manually correct the artifacts for each question in 2022 and 2023. In the next sections, we   \n506 describe the artifacts from those easier to address (sec A.1.2 A.1.3), to deeper-rooted problems (i.e.,   \n507 harder to correct, sec A.1.4), as well as how we addressed them manually (sec A.1.5). ", "page_idx": 12}, {"type": "text", "text": "508 A.1.1 Label accuracy ", "text_level": 1, "page_idx": 12}, {"type": "text", "text": "509 We assume answers are correct as translation and parsing of single characters can be quite reliable,   \n510 and that the original ENEM test is tested across millions of human test takers and will be discarded   \n511 if it had a wrong answer. When we look at the label distribution for 2022, options \u201cABCDE\u201d each   \n512 occur 39/39/37/36/33 times, making it fairly balanced. We also ran random baselines on the same   \n513 option shuffles as the model (Table 1). ", "page_idx": 12}, {"type": "text", "text": "514 A.1.2 Translation artifacts ", "text_level": 1, "page_idx": 12}, {"type": "text", "text": "515 We found several issues pertaining to initial round of translation in this dataset. Mainly, independent   \n516 translation of question context and answer option leads to incoherence. Details are sometimes mis  \n517 translated (\u201cp.d.d\u201d translated to \u201cd.d.p\u201d). There are many non-standardized translations pertaining   \n518 to chemical formulas, proper nouns, and mathematical formulas. In general, there are significant   \n519 amount of awkward phrasing, incomplete translation, and linguistic idiosyncrasies lost in transla  \n520 tion.   \n521 Independent translation of context and question In a few cases, the answer options are expected   \n522 to complete the last sentence of the question. After translation, options do not all fit as completions of   \n523 the sentence (Q11). Translation without context also leads to improper translation of polysemantic   \n524 terms. \u201cCoagulation\u201d maybe translated correctly in the question, but becomes \u201ccoagulating\u201d as   \n525 a stand-alone word (Q96). \u201cGood\u201d and \u201cfair\u201d (when used as survey options) gets translated to   \n526 \u201cregular\u201d and \u201cI will\u201d as stand-alone options (Q171)   \n527 Inconsistent translation details Within the same questions, there are cases where the same con  \n528 cept is translated differently. In one question, the context introduces the concept \u201cpotential difference   \n529 (p.d.d)\u201d, and later referred to it as \u201cd.d.p\u201d and \u201cd.p.d\u201d. Within different options, the same unit can   \n530 sometimes be plural and sometimes be singular (when it should be consistently plural)   \n531 Non-standard translation 1) Chemical formula translation is non-standard. \u201cN2O3\u201d becomes \u201cN   \n532 $2\\mathrm{O}3^{\\circ}$ , and $\\mathrm{^{\\circ}N H4+^{\\circ}}$ becomes \u201cNH4 positively charged\u201d. 2) (Proper) nouns are sometimes capital  \n533 ized when they shouldn\u2019t. For instance, one question begins with the sentence \u201cOn the Gravitational   \n534 Field of a Mass Point According to Einstein\u2019s Theory A \u2019Black Hole is a...\u201d 3) Mathematical equa  \n535 tions are overly verbatim. This we suspect is partially due to an issue with using audio version of the   \n536 test. For example, if an option is the formula ((8\u221282!)!2! \u22121), its Portuguese representation would   \n537 be \u201c9 vezes ( (8 fatorial dividido por ( (8 menos 2) fatorial vezes 2 fatorial)) menos 1)\u201d and the En  \n538 glish translation exacerbates the situation by translating parenthesis literally as well: \u201c9 times open   \n539 parenthesis, open parenthesis, 8 factorial divided by, open parenthesis, open parenthesis, 8 minus   \n540 2, close parenthesis, factorial times 2 factorial, close parenthesis, close parenthesis, minus 1, close   \n541 parenthesis.\u201d. Sometimes, delimiters are omitted after translation: ${\\cdot9}{,}300^{\\circ}$ becomes $\\mathrm{{}^{\\bullet}\\d{}9\\,300^{\\circ}}$ .   \n542 Awkward phrasings There exist awkward phrasings throughout translation. They range from   \n543 causing minor difficulty in understanding (i.e., \u201cLife: the science of biology Bears, because they   \n544 are not truly hibernating, wake up due to the presence of thermogenin, a mitochondrial protein that   \n545 prevents protons from reaching ATP synthase, generating heat.\u201d) to sometime completely non-sense   \n546 (i.e., \u201carticulation of several narrative nuclei\u201d)   \n547 Incomplete translation There is no fine line between proper code switching (where proper nouns   \n548 should remain in Portuguese script) to in-complete translation. The amount of Portuguese left over   \n549 range from single words, to phrases in options (not consistently across options), to entire sentences   \n550 within the question.   \n551 Linguistic idiosyncrasies lost in translation In one question, the problem arises when English   \n552 translation does not match with literal tokens of expressions in Portuguese (\u201cNext to the man is   \n553 the message: \u201cMen don\u2019t cry\u201d, with a large X drawn over the word \u201cno\u201d). The word \u201cno\u201d does   \n554 not appear in the English phrase \u201cMen don\u2019t cry\u201d but the statement as a whole makes sense in the   \n555 Portuguese version of the instruction. In a separate question, the topic is on testing for a Portuguese   \n556 specific pronoun inflection. However, when it was translated into one single word in English, the   \n557 question no longer makes sense (\u201cThey told me... - They told me. - Huh? - The correct word is \u201cthey   \n558 told me\u201d. Not \u201cthey told me\u201d. - I speak the way I want to. And I\u2019ll tell you more... Or is it \u201ctell   \n559 you\u201d? - What\u2019s that? - I\u2019m telling you that you... -\u201cYou\u201d and \u201cyou\u201d don\u2019t go together...\u201d) ", "page_idx": 12}, {"type": "text", "text": "", "page_idx": 12}, {"type": "text", "text": "", "page_idx": 12}, {"type": "text", "text": "", "page_idx": 12}, {"type": "text", "text": "", "page_idx": 13}, {"type": "text", "text": "", "page_idx": 13}, {"type": "text", "text": "", "page_idx": 13}, {"type": "text", "text": "", "page_idx": 13}, {"type": "text", "text": "560 A.1.3 Document parsing artifacts ", "text_level": 1, "page_idx": 13}, {"type": "text", "text": "561 Each section consistently contains an error of this kind, where the last part of the question got wrong  \n562 fully parsed into part of the first option (option (A)). In a separate instance, a figure was wrongfully   \n563 parsed into one of the options of the previous question. In the Portuguese version of the exam, struc  \n564 tural components of the question (e.g., title, subtitle, caption) are consistently concatenated together   \n565 without proper separation. This often leads to incoherent English translations. ", "page_idx": 13}, {"type": "text", "text": "566 A.1.4 Audio-version artifacts ", "text_level": 1, "page_idx": 13}, {"type": "text", "text": "567 Audio description of images, tables, and figures are not always sufficient, or the most intuitive. For   \n568 instance, a question asks test taker to note why a particular painting stands out, and the answer is   \n569 due to the painting\u2019s \u201cdistortion when representing human figure\u201d, which is difficult to qualitatively   \n570 describe, no matter how complete the description of an image is. Similarly, textual description   \n571 of geometric figures can be impossibly complicated (\u201c...Figure of a grid with 7 horizontal and 7   \n572 vertical lines, on which a polygonal path is drawn by means of a continuous line on the grid lines,   \n573 joining the starting point $P$ , located on the second vertical line, from left to right, and between the   \n574 sixth and seventh horizontal lines, from top to bottom, to the end point $Q$ , which is located between   \n575 the sixth and seventh vertical lines, from left to right, and on the second horizontal line, from top to   \n576 bottom...\u201d) ", "page_idx": 13}, {"type": "text", "text": "577 A.1.5 Manual Correction ", "text_level": 1, "page_idx": 13}, {"type": "text", "text": "578 The majority of the artifacts begin with incorrect parsing of the PDF documents related to struc  \n579 tural components. To address this, we manually audited each question, and added correct spacing   \n580 and newlines to each question. These improvements result in better translations from DeepL API   \n581 qualitatively. After translation, we make minimal edits to improve syntactic and semantic issues   \n582 through Grammarly to obtain a score of at least $95^{\\;2\\;3}$ . For each answer option, we ensure consistent   \n583 part-of-speech, especially if they are sentence completions of the questions. For math and science   \n584 sections, we follow consistent markdown-like format the same way as other mathematical reasoning   \n585 datasets [16, 11, 52]. Here we list the full set of modification rules for 2022 (question numbers are   \n586 referenced in parenthesis):   \n587 \u2022 Separate description of the image by ${\\bf\\delta}^{*}\\backslash{\\bf n}^{*}$ before and after.   \n588 \u2022 \u201cPor cento\u201d becomes $\\%$ .   \n589 \u2022 Number in the form 7 000 becomes 7000.   \n590 \u2022 From \u201cabre aspas\u201d \u201cfecha aspas\u201d to \u201c\u201d.   \n591 \u2022 Remove \u201cDescri\u00b8ca\u02dco da estrutura qu\u00b4\u0131mica\u201d, \u201cDescri\u00b8ca\u02dco do esquema\u201d, \u201cDescri\u00b8ca\u02dco da   \n592 associa\u00b8ca\u02dco de baterias\u201d, \u201cDescri\u00b8ca\u02dco da imagem\u201d from the options\u201d.   \n593 \u2022 \u201cDe carga positiva\u201d to $^+$ , \u201cDe carga negativa\u201d to -, \u201cde carga dois menos\u201d to (2-).   \n594 \u2022 For a subset of the questions, we follow the non-blind version of the question (157, 158,   \n595 163, 166, 168, 171, 174, 177, 178, 179)   \n596 \u2022 Remove period at the end options or questions of math questions (to avoid confusion).   \n597 Here are the list of rules we use for English version of the exam (2022):   \n598 \u2022 Change number decimal from \u201c3,1415\u201d to \u201c3.1415\u201d. ", "page_idx": 13}, {"type": "text", "text": "", "page_idx": 14}, {"type": "text", "text": "", "page_idx": 14}, {"type": "text", "text": "599 \u2022 Manual translation fix (49, 162). ", "page_idx": 14}, {"type": "text", "text": "600 A.1.6 Limitations of the dataset ", "text_level": 1, "page_idx": 14}, {"type": "text", "text": "601 There are a few limitations of the dataset: ", "page_idx": 14}, {"type": "text", "text": "602 1. Even though the English version of the exam is modified manually, there are still issues   \n603 with the presentation of the questions. We rely mostly on Grammarly feedback, but it is   \n604 not perfect. Our judgement of how fluently a question is written is also subjective. The   \n605 ideal method would be to recruit professional human translators, which is costly and time   \n606 consuming.   \n607 2. The content of many of the questions are focused on knowledge common to Brazilian   \n608 culture, or problems in Brazilian society. The English translations may not cover the full   \n609 extent of cultural, language specific phenomenons or connotations.   \n610 3. We assume the transcription of images and tables to be sufficient for the models to under  \n611 stand and solve the question. ", "page_idx": 14}, {"type": "text", "text": "612 A.2 Attributes that affect goodness-of-fit ", "text_level": 1, "page_idx": 14}, {"type": "text", "text": "613 Given that questions have wide range of discrimination indices for LLMs, we investigate a potential   \n614 cause described in the psychometrics literature for aberrant response patterns: lack of subabili  \n615 ties [23], i.e., specific skills required to answer a question correctly. We hypothesize that some item   \n616 attributes, such as whether the question contains images or numbers in its statement or among the   \n617 options, may be disproportionately harder for LLMs and hence represent subabilities that explain   \n618 the aberrant response patterns quantified in Figure 3.   \n619 We built a contingency table relating non-discriminative/discriminative items (i.e., items with dis  \n620 criminative index lower/higher than 0.2) and the aforementioned attributes, and run a $\\chi^{2}$ indepen  \n621 dence test. The results for the Natural Sciences exam are shown in Table 2. For this exam, we   \n622 observe high $\\chi^{2}$ values which indicate that the abilities of the LLM models with respect to math   \n623 reasoning and interpreting images are sub-par compared to their capacity in solving pure text ques  \n624 tions. While Language and Humans exams are most purely text and the Math exam mostly demands   \n625 reasoning with images and numbers, the nature of the Natural Sciences exam is hybrid, containing   \n626 6 both types of questions. This may well explain the bimodal distribution of discrimination indices   \n627 in Figure 5 and the aberrant response patterns identified by the very low $l_{z}$ scores in Figure 3, and   \n628 highlights how psychometrics can aid the design of better and more valid benchmarks for LLMs. ", "page_idx": 14}, {"type": "text", "text": "", "page_idx": 14}, {"type": "text", "text": "Table 2: $\\chi^{2}$ test for the correlation between poorly-discriminating items and item attributes in the Natural Sciences exam in 2022 and 2023. Significant values are in bold. High values of $\\chi^{2}$ indicate that images or numbers make the item less useful to evaluate the LLMs we experiment with. ", "page_idx": 15}, {"type": "table", "img_path": "Cth1PyCwZt/tmp/1b4877dbcfc79bf109384f878cc5e3e8eff47385130d90ce8fa55564564f78ec.jpg", "table_caption": [], "table_footnote": [], "page_idx": 15}, {"type": "text", "text": "629 A.3 Model accuracy relation to model perplexity ", "text_level": 1, "page_idx": 15}, {"type": "text", "text": "630 One reason that models may error differently than humans is due to their training corpus. If models   \n631 have encountered similar question or topics, if not identical, to those in our dataset during training,   \n632 they may perform unexpectedly well, even if the questions are difficult. Recent work in data con  \n633 tamination proposed a few model intrinsic metrics that can be used to detect contamination [36].   \n634 Mainly, the $\\mathrm{Min-k\\%}$ Prob score takes the average probability of the top- $\\cdot\\mathbf{k}$ percentile tokens with   \n635 minimum probabilities 4: ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\mathrm{MIN-K}\\mathcal{U}\\mathrm{\\,Prob\\,(x)}=-\\frac{1}{E}\\sum_{x_{i}\\in\\mathrm{Min-K}\\mathcal{U}_{\\mathrm{c}}(\\mathrm{x})}\\log p(x_{i}|x_{1},\\mathrm{,~}...,x_{i-1})\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "636 where ${\\boldsymbol{x}}={x}_{1},{x}_{2},...,{x}_{N}$ denotes the input sequence of $\\mathbf{N}$ tokens, Min- $.\\mathrm{K}\\%$ Prob(x) represents the   \n637 set containing tokens with minimum $\\boldsymbol{\\mathrm{k}}$ percentile probabilities, and $E$ represents the size of such set.   \n638 Note here that Min- $\\cdot\\mathrm{k}\\%$ Prob is intrinsic to each model, and if a model has been exposed to more   \n639 similar training data as the questions, its Min- $\\cdot\\mathrm{k}\\%$ Prob would be low for that question.   \n640 We do not expect any model to have unexpectedly low Min- $.\\mathrm{K}\\%$ Prob(x) on any of our questions,   \n641 considering it is highly unlikely that the ENEM questions were parsed and translated to English, and   \n642 somehow ended up in the training corpus. What we are more interested here, is whether such score   \n643 is correlated to model\u2019s accuracy on the answer predictions. If they are negatively correlated (i.e.   \n644 high Min- $.\\mathrm{K}\\%$ Prob corresponds to low accuracy), this is evidence for the hypothesis that training on   \n645 related data leads to higher accuracy.   \n646 To investigate this hypothesis, we plot 4-shot model accuracy (averaged across 31 option shuffles)   \n647 against Min- $.20\\%$ Prob for four subjects in exam 2022 in English along with the Pearson correlations   \n648 5 in Figure 6. In all except 1 model-subject pair (Llama2 chat in humanities, we investigate this   \n649 further) do we see a significant negative correlation $(\\mathsf{p}<0.05)$ between accuracy and Min-k $20\\%$   \n650 Prob, indicate that model doesn\u2019t necessarily do better if they have encountered similar data during   \n651 training. Another way to interpret this, is that it is not likely that these models have seen our data   \n652 during training.   \n653 The few negative correlation cases As seen before, we observe a significant negative correlation   \n654 for Llama-2 7B Chat in humanities. To get a full understanding of whether this is a stand-alone   \n655 phenomenon, we examine Portuguese version of the exam, as well as exam in 2023, and show our   \n656 findings below in Table 3. We do not see the same correlation in the Portuguese version of the   \n657 exam. However, we additionally see Gemma-it negatively correlated with humanities section in   \n658 both English and Portuguese version of the exam in 2023, as well as Gemma with languages section   \n659 in 2023. The later two correlations are robust across a few other metrics we investigated from [36]   \n660 as well, we think this may suggest data contamination, but we cannot test such hypothesis because   \n661 Gemma training data is not public.   \n662 Positive correlations in 2022 science In 2022 Science, both English and Portuguese, we see sig  \n663 nificant positive correlation across all models (Table 3).   \n664 Through qualitative analysis, we find that the questions with highest perplexities were formatted   \n665 more in a sentence completion-like structure similar to Question 1. Whereas less perplexity ques  \n666 tions involve more image/table description with reasoning needed to obtain the answer (question 2).   \n667 This is similar to what we discover with discriminative index in Section ?? in the main text.   \n6681 Question: Technique modifies rattlesnake venom protein to create a   \n669 drug that modulates blood clotting   \n6702   \n6713 Rattlesnake venom can cause life -threatening hemorrhaging to those   \n672 bitten by the snake. However , researchers from Brazil and Belgium   \n673 have developed a molecule of pharmaceutical interest , PEG -   \n674 collinein -1, from a protein found in the snake \u2019s venom. The   \n675 molecule is capable of modulating blood clotting. Although the   \n676 technique is not new , it was applied for the first time from an   \n677 animal toxin in its recombinant form , i.e. produced in the   \n678 laboratory by a genetically modified fungus.   \n6794   \n6805 This new drug has potential applications for   \n6816 Options:   \n6827 (A) prevent the formation of thrombi , typical in some cases of stroke.   \n6838 (B) treat the consequences of profound anemia , due to the loss of a   \n684 large volume of blood.   \n6859 (C) prevent the manifestation of urticaria , commonly related to   \n686 allergic processes.   \n68710 (D) reduce swelling of the lymph nodes , part of the immune response to   \n688 different infections.   \n68911 (E) regulate the fluctuations in blood pressure characteristic of   \n690 hypertension.   \n6911 Question: On a hot day , two colleagues are playing with the water from   \n692 the hose. One of them wants to know how high the water jet   \n693 reaches from the outlet when the hose is positioned vertically.   \n694 The other colleague then proposes the following experiment: they   \n695 position the water outlet of the hose in a horizontal direction , 1   \n696 meter above the ground , and then measure the horizontal distance   \n697 between the hose and the place where the water hits the ground.   \n698 The measurement of this distance was 3 meters , and from this , they   \n699 calculated the vertical reach of the water jet. Consider the   \n700 acceleration of gravity to be 10 meters per second squared.   \n7012   \n7023 The result they obtained was   \n7034 Options:   \n7045 (A) 1.50 meter.   \n7056 (B) 2.25 meters.   \n7067 (C) 4.00 meters.   \n7078 (D) 4.50 meters.   \n7089 (E) 5.00 meters. ", "page_idx": 15}, {"type": "text", "text": "", "page_idx": 15}, {"type": "text", "text": "", "page_idx": 15}, {"type": "text", "text": "", "page_idx": 15}, {"type": "text", "text": "", "page_idx": 15}, {"type": "text", "text": "", "page_idx": 15}, {"type": "image", "img_path": "Cth1PyCwZt/tmp/f0155b1b66b89d5fb88338ea3ee37d7435fd61d59b8a77eeb8c14047cd5777e1.jpg", "img_caption": ["Figure 6: Model Min- $.20\\%$ Prob vs. 4-shot accuracy across four subjects in 2022 in English "], "img_footnote": [], "page_idx": 16}, {"type": "text", "text": "", "page_idx": 17}, {"type": "text", "text": "", "page_idx": 17}, {"type": "text", "text": "", "page_idx": 17}, {"type": "text", "text": "Listing 2: low perplexity question with low model accuracy. ", "page_idx": 17}, {"type": "text", "text": "709 We also tried filtering for top N percent most difficult questions per subject and recalculate all the   \n710 correlations. We did not find any significant difference to results above. ", "page_idx": 17}, {"type": "text", "text": "711 A.4 Prompting Details ", "text_level": 1, "page_idx": 17}, {"type": "text", "text": "712 To administering the test to LLMs, we measure the next token logits across the 5 letter options   \n713 directly (i.e. letter \u201cA\u201d, \u201cB\u201d, \u201cC\u201d, \u201cD\u201d, \u201cE\u201d), and take the argmax as the model\u2019s choice (invariant   \n714 to sampling temperature). We shuffle the option orders (30 runs) and take the average to calibrate   \n715 model\u2019s prior on generating each letter options. For API-based model (GPT3.5), we query for 1   \n716 token generation, and obtain top-20 logits, and use that for our prediction. In the sections below we   \n717 include 0-shot (Listing 3), 1-shot (Listing 4, 5, 6, 7), and 4-shot prompts (Listing 8) we use in main   \n718 experiments. For 1-shot, we choose the 1-shot example for each of the four subjects by selecting   \n719 the easiest question (i.e., with lowest $\\beta$ ) from the same subject in the 2021 exam. For 4-shot, we   \n720 concatenate the 1-shots from four subjects and shuffle the options to evenly distribute the answer   \n721 among five option letters.   \n722 Potential limitations We ran exploratory experiments with Chain-of-Thought (CoT) like prompt  \n723 ing [49], but and did not see significant changes. We did not include the results because CoT prompt  \n724 ing requires generating reasoning strings and parsing answers, making 30-shuffles extremely slow   \n725 to run for all models. Future directions could explore how much effect more complex prompting   \n726 techniques have in assimilating model behaviors. Regarding the best prompting strategy, we do   \n727 acknowledge recent criticisms on first letter evaluation[48]. At the time of our writing, it is still   \n728 the best evaluation strategy for multiple choice question-answering data. We also acknowledge that   \n729 there are more capable models than GPT3.5 that is available through API services but as our work is   \n730 not trying to identify the SOTA model we did not feel the need to evaluate latest and largest models.   \n731 Lastly, we assume Portuguese and Brazilian culture is present in the training data for the language   \n732 models we test. Future work could evaluate the amount of multilingual training\u2019s affect on some of   \n733 these IRT metric we propose.   \n7341 Here are some questions from a college entrance exam. Choose the   \n735 correct answer to the best of your ability , and output in the   \n736 following format:   \n7372 Answer: (Option)   \n7383   \n7394 Question: {QUESTION}   \n7405 Options:   \n7416 (A) {OPTION_A}   \n7427 (B) {OPTION_B}   \n7438 (C) {OPTION_C}   \n7449 (D) {OPTION_D}   \n74510 (E) {OPTION_E}   \n74611 Answer: (   \n7471 Here are some questions from a college entrance exam. Choose the   \n748 correct answer to the best of your ability , and output in the   \n749 following format:   \n7502 Answer: (Option)   \n7513   \n7524 Question:   \n7535 Buffalos are animals considered rustic by breeders and are therefore   \n754 left in the field without reproductive control. Because of this   \n755 type of breeding , inbreeding is common , leading to the appearance   \n756 of diseases such as albinism and heart defects , among others.   \n757 Separating the animals properly by sex would minimize the   \n758 occurrence of these problems.   \n7596   \n7607 What prior biotechnological procedure is recommended in this situation   \n761   \n7628   \n7639 Options:   \n76410 (A) Transgenics.   \n76511 (B) Gene therapy.   \n76612 (C) DNA vaccine.   \n76713 (D) Genetic mapping.   \n76814 (E) Therapeutic cloning.   \n76915   \n77016 Answer: (D) Genetic mapping.   \n77117   \n77218 Question: {QUESTION}   \n77319 Options:   \n77420 (A) {OPTION_A}   \n77521 (B) {OPTION_B}   \n77622 (C) {OPTION_C}   \n77723 (D) {OPTION_D}   \n77824 (E) {OPTION_E}   \n77925 Answer: ( ", "page_idx": 17}, {"type": "table", "img_path": "Cth1PyCwZt/tmp/97f32bd5704d8f770cc3cf1a6689f0209edc57df89ea573e5489557aed9cf4d8.jpg", "table_caption": [], "table_footnote": ["Table 3: Correlation between model accuracy and Min- $\\overline{{\\mathbf{k}\\%}}$ Prob across exam, languages, and subjects for all models $\\mathbf{L}2{=}$ llama2, L3=Llama3, $\\mathbf{M}\\!=$ Mistral, $\\mathbf{G}{=}$ gemma, it=instruction-tuned/chat). The first number indicates the coefficient of the correlation, and the second, the p-value. Entries with p-value $<0.05$ are in bold. $\\mathbf{CN}{=}$ Humanities, LC=Languages, $\\mathbf{CN}{=}\\mathbf{S}$ ciences, MT $\\fallingdotseq$ Math "], "page_idx": 18}, {"type": "text", "text": "", "page_idx": 18}, {"type": "text", "text": "", "page_idx": 18}, {"type": "text", "text": "", "page_idx": 18}, {"type": "text", "text": "", "page_idx": 19}, {"type": "text", "text": "Listing 4: 1-shot prompt used for Natural Science. ", "page_idx": 19}, {"type": "text", "text": "7801 Here are some questions from a college entrance exam. Choose the   \n781 correct answer to the best of your ability , and output in the   \n782 following format:   \n7832 Answer: (Option)   \n7843   \n7854 Question:   \n7865 A hamburger chain has three franchises in different cities. To include   \n787 a new type of snack on the menu , the chain \u2019s marketing manager   \n788 suggested putting five new types of snacks on sale in special   \n789 editions. The snacks were offered for the same period of time to   \n790 all the franchisees. The type with the highest average sold per   \n791 franchise would be permanently included on the menu. At the end of   \n792 the trial period , management received a report describing the   \n793 quantities sold , in units , of each of the five types of snacks in   \n794 the three franchises.   \n7956   \n7967 Image description: The table shows the quantity sold of each type of   \n797 snack in franchises 1, 2, and 3.   \n7988 Franchise 1 sold 415 type -1 snacks , 395 type -2 snacks , 425 type -3   \n799 snacks , 430 type -4 snacks , and 435 type -5 snacks.   \n8009 Franchise 2 sold 415 type -1 snacks; 445 type -2 snacks; 370 type -3   \n801 snacks; 370 type -4 snacks and 425 type -5 snacks.   \n80210 Franchise 3 sold 415 type -1 snacks; 390 type -2 snacks; 425 type -3   \n803 snacks; 433 type -4 snacks and 420 type -5 snacks.   \n80411   \n80512 Based on this information , the management has decided to include the   \n806 following type of snack on the menu   \n80713   \n80814 Options:   \n80915 (A) 1   \n81016 (B) 2   \n81117 (C) 3   \n81218 (D) 4   \n81319 (E) 5   \n81420   \n81521 Answer: (E) 5   \n81622   \n81723 Question: {QUESTION}   \n81824 Options:   \n81925 (A) {OPTION_A}   \n82026 (B) {OPTION_B}   \n82127 (C) {OPTION_C}   \n82228 (D) {OPTION_D}   \n82329 (E) {OPTION_E} ", "page_idx": 19}, {"type": "text", "text": "82430 Answer: ", "page_idx": 20}, {"type": "text", "text": "Listing 5: 1-shot prompt used for Math. ", "page_idx": 20}, {"type": "text", "text": "8251 Here are some questions from a college entrance exam. Choose the   \n826 correct answer to the best of your ability , and output in the   \n827 following format:   \n8282 Answer: (Option)   \n8293   \n8304 Question:   \n8315 The situation of the working class in England   \n8326 Friedrich Engels   \n8337   \n8348 At the same time , thanks to the ample opportunities I have had to   \n835 observe the middle classes , your adversaries , I have quickly   \n836 concluded that you are right , absolutely right , not to expect any   \n837 help from them. Its interests are diametrically opposed to yours ,   \n838 even if it constantly tries to claim the opposite and wants to   \n839 persuade you that it feels the greatest sympathy for your lot. But   \n840 her actions belie her words.   \n8419   \n84210 In the text , the author presents ethical outlines that correspond to   \n84311   \n84412 Options:   \n84513 (A) the foundation of the idea of surplus value.   \n84614 (B) concept of class struggle.   \n84715 (C) fundamentals of the scientific method.   \n84816 (D) paradigms of the inquiry process.   \n84917 (E) domains of commodity fetishism.   \n85018   \n85119 Answer: (B) concept of class struggle.   \n85220   \n85321 Question: {QUESTION}   \n85422 Options:   \n85523 (A) {OPTION_A}   \n85624 (B) {OPTION_B}   \n85725 (C) {OPTION_C}   \n85826 (D) {OPTION_D}   \n85927 (E) {OPTION_E}   \n86028 Answer: ( ", "page_idx": 20}, {"type": "text", "text": "Listing 6: 1-shot prompt used for Humanities. ", "page_idx": 20}, {"type": "text", "text": "8611 Here are some questions from a college entrance exam. Choose the   \n862 correct answer to the best of your ability , and output in the   \n863 following format:   \n8642 Answer: (Option)   \n8653   \n8664 Question:   \n8675 Sinh\\\u2019a   \n8686 Chico Buarque and Jo\\\\~ao Bosco   \n8697   \n8708 If the owner bathed   \n8719 I wasn \u2019t there   \n87210 By God our Lord   \n87311 I didn \u2019t look Sinh\\\u2019a   \n87412 I was in the fields   \n87513 I\u2019m not one to look at anyone   \n87614 I\u2019m not greedy anymore   \n87715 I can \u2019t see straight   \n87816   \n87917 Why put me in the trunk   \n88018 Why hurt me   \n88119 I swear to you   \n88220 I\u2019ve never seen Sinh\\\u2019a   \n88321 [...]   \n88422 Why carve up my body   \n88523 I didn \u2019t look at Sinh\\\u2019a   \n88624 Why would you   \n88725 You \u2019ll pierce my eyes   \n88826 I cry in Yoruba   \n88927 But I pray for Jesus   \n89028 So that you can   \n89129 Take away my light   \n89230   \n89331 In this fragment of the song \u2019s lyrics , the vocabulary used and the   \n894 situation portrayed are relevant to the country \u2019s linguistic   \n895 heritage and identity , in that   \n89632   \n89733 Options:   \n89834 (A) physical and symbolic violence against enslaved people.   \n89935 (B) value the influences of African culture on national music.   \n90036 (C) relativize the syncretism that makes up Brazilian religious   \n901 practices.   \n90237 (D) narrate the misfortunes of the love relationship between members   \n903 of different social classes.   \n90438 (E) problematize the different worldviews in society during the   \n905 colonial period.   \n90639   \n90740 Answer: (A) physical and symbolic violence against enslaved people   \n90841   \n90942 Question: {QUESTION}   \n91043 Options:   \n91144 (A) {OPTION_A}   \n91245 (B) {OPTION_B}   \n91346 (C) {OPTION_C}   \n91447 (D) {OPTION_D}   \n91548 (E) {OPTION_E}   \n91649 Answer: ( ", "page_idx": 20}, {"type": "text", "text": "", "page_idx": 21}, {"type": "text", "text": "Listing 7: 1-shot prompt used for Languages. ", "page_idx": 21}, {"type": "text", "text": "9171 Here are some questions from a college entrance exam. Choose the   \n918 correct answer to the best of your ability , and output in the   \n919 following format:   \n9202 Answer: (Option)   \n9213   \n9224 Question:   \n9235 Buffalos are animals considered rustic by breeders and are therefore   \n924 left in the field without reproductive control. Because of this   \n925 type of breeding , inbreeding is common , leading to the appearance   \n926 of diseases such as albinism and heart defects , among others.   \n927 Separating the animals properly by sex would minimize the   \n928 occurrence of these problems.   \n9296   \n9307 What prior biotechnological procedure is recommended in this situation   \n931 ?   \n9328   \n9339 Options:   \n93410 (A) Transgenics.   \n93511 (B) Gene therapy.   \n93612 (C) DNA vaccine.   \n93713 (D) Genetic mapping.   \n93814 (E) Therapeutic cloning.   \n93915   \n94016 Answer: (D) Genetic mapping.   \n94117   \n94218 Question:   \n94319 Sinh\\\u2019a   \n94420 Chico Buarque and Jo\\\\~ao Bosco   \n94521   \n94622 If the owner bathed   \n94723 I wasn \u2019t there   \n94824 By God our Lord   \n94925 I didn \u2019t look Sinh\\\u2019a   \n95026 I was in the fields   \n95127 I\u2019m not one to look at anyone   \n95228 I\u2019m not greedy anymore   \n95329 I can \u2019t see straight   \n95430   \n95531 Why put me in the trunk   \n95632 Why hurt me   \n95733 I swear to you   \n95834 I\u2019ve never seen Sinh\\\u2019a   \n95935 [...]   \n96036 Why carve up my body   \n96137 I didn \u2019t look at Sinh\\\u2019a   \n96238 Why would you   \n96339 You \u2019ll pierce my eyes   \n96440 I cry in Yoruba   \n96541 But I pray for Jesus   \n96642 So that you can   \n96743 Take away my light   \n96844   \n96945 In this fragment of the song \u2019s lyrics , the vocabulary used and the   \n970 situation portrayed are relevant to the country \u2019s linguistic   \n971 heritage and identity , in that   \n97246   \n97347 Options:   \n97448 (A) physical and symbolic violence against enslaved people.   \n97549 (B) value the influences of African culture on national music.   \n97650 (C) relativize the syncretism that makes up Brazilian religious   \n977 practices.   \n97851 (D) narrate the misfortunes of the love relationship between members   \n979 of different social classes.   \n98052 (E) problematize the different worldviews in society during the   \n981 colonial period.   \n98253   \n98354 Answer: (A) physical and symbolic violence against enslaved people   \n98455   \n98556 Question:   \n98657 The situation of the working class in England   \n98758 Friedrich Engels   \n98859   \n98960 At the same time , thanks to the ample opportunities I have had to   \n990 observe the middle classes , your adversaries , I have quickly   \n991 concluded that you are right , absolutely right , not to expect any   \n992 help from them. Its interests are diametrically opposed to yours ,   \n993 even if it constantly tries to claim the opposite and wants to   \n994 persuade you that it feels the greatest sympathy for your lot. But   \n995 her actions belie her words.   \n99661   \n99762 In the text , the author presents ethical outlines that correspond to   \n99863   \n99964 Options:   \n100065 (A) the foundation of the idea of surplus value.   \n100166 (B) concept of class struggle.   \n100267 (C) fundamentals of the scientific method.   \n100368 (D) paradigms of the inquiry process.   \n100469 (E) domains of commodity fetishism.   \n100570   \n100671 Answer: (B) concept of class struggle.   \n100772   \n100873 Question:   \n100974 A hamburger chain has three franchises in different cities. To include   \n1010 a new type of snack on the menu , the chain \u2019s marketing manager   \n1011 suggested putting five new types of snacks on sale in special   \n1012 editions. The snacks were offered for the same period of time to   \n1013 all the franchisees. The type with the highest average sold per   \n1014 franchise would be permanently included on the menu. At the end of   \n1015 the trial period , management received a report describing the   \n1016 quantities sold , in units , of each of the five types of snacks in   \n1017 the three franchises.   \n101875   \n101976 Image description: The table shows the quantity sold of each type of   \n1020 snack in franchises 1, 2, and 3.   \n102177 Franchise 1 sold 415 type -1 snacks , 395 type -2 snacks , 425 type -3   \n1022 snacks , 430 type -4 snacks , and 435 type -5 snacks.   \n102378 Franchise 2 sold 415 type -1 snacks; 445 type -2 snacks; 370 type -3   \n1024 snacks; 370 type -4 snacks and 425 type -5 snacks.   \n102579 Franchise 3 sold 415 type -1 snacks; 390 type -2 snacks; 425 type -3   \n1026 snacks; 433 type -4 snacks and 420 type -5 snacks.   \n102780   \n102881 Based on this information , the management has decided to include the   \n1029 following type of snack on the menu   \n103082   \n103183 Options:   \n103284 (A) 1   \n103385 (B) 2   \n103486 (C) 3   \n103587 (D) 4   \n103688 (E) 5   \n103789   \n103890 Answer: (E) 5   \n103991   \n104092 Question: {QUESTION}   \n104193 Options:   \n104294 (A) {OPTION_A}   \n104395 (B) {OPTION_B}   \n104496 (C) {OPTION_C}   \n104597 (D) {OPTION_D}   \n104698 (E) {OPTION_E}   \n104799 Answer: ( ", "page_idx": 21}, {"type": "text", "text": "", "page_idx": 22}, {"type": "text", "text": "", "page_idx": 23}, {"type": "text", "text": "1048 A.5 Compute Resources ", "text_level": 1, "page_idx": 24}, {"type": "text", "text": "1049 We used GPUs (V100 or A100) provided by a university cluster6. For the main experiments, we   \n1050 used around 200 hours of GPU time (roughly 20 hours per model). Moreover, we used the OpenAI   \n1051 API to run the experiments with GPT3.5. ", "page_idx": 24}, {"type": "text", "text": "1052 A.6 Zero and One Shot prompting Results for 2023 ", "text_level": 1, "page_idx": 24}, {"type": "text", "text": "1053 A.6.1 CTT and IRT $\\theta$ ", "page_idx": 24}, {"type": "image", "img_path": "Cth1PyCwZt/tmp/57d4b33ac18e8b3ccae2c7ca016699722bbd1ab3eda3716e22f07cd0f981c259.jpg", "img_caption": [], "img_footnote": [], "page_idx": 24}, {"type": "text", "text": "Figure 7: Distribution of CTT (accuracy) and IRT scores for humans and LLMs for the ENEM 2023 exam. LLMs are non-instructed tuned open source models and GPT3.5 with zero-shot. LLM datapoints are computed from different shuffles. ", "page_idx": 24}, {"type": "image", "img_path": "Cth1PyCwZt/tmp/012e34d25029ddfc09d80ea77d774f9cf30b6fabdad8632361a045e4fdaab2a6.jpg", "img_caption": ["Figure 8: Distribution of CTT (accuracy) and IRT scores for humans and LLMs for the ENEM 2023 exam. LLMs are instructed tuned open source models with zero-shot. LLM datapoints are computed from different shuffles. "], "img_footnote": [], "page_idx": 25}, {"type": "image", "img_path": "Cth1PyCwZt/tmp/11e8bc289ed4057ba7722203badb11f99e1dc012a04edcd7c05b9a32b3da5d73.jpg", "img_caption": ["Figure 9: Distribution of CTT (accuracy) and IRT scores for humans and LLMs for the ENEM 2023 exam. LLMs are non-instructed tuned open source models and GPT3.5 with one-shot. LLM datapoints are computed from different shuffles. "], "img_footnote": [], "page_idx": 25}, {"type": "image", "img_path": "Cth1PyCwZt/tmp/578231bd7eb4304bf622b3f80b98190799e3b260cef350c5da64d8ba90486eae.jpg", "img_caption": ["Figure 10: Distribution of CTT (accuracy) and IRT scores for humans and LLMs for the ENEM 2023 exam. LLMs are instructed tuned open source models with one-shot. LLM datapoints are computed from different shuffles. "], "img_footnote": [], "page_idx": 26}, {"type": "text", "text": "1055 We show 43 items for the 2023 Math exam, instead of 45, because 2 items failed to converge and   \n1056 produce item parameters when the ENEM organizers fitted the human model. ", "page_idx": 27}, {"type": "image", "img_path": "Cth1PyCwZt/tmp/7cb5026e75689fdf7b27a35c7ec212e1ef8467752ecaf15a4d09aa6b3bb95c49.jpg", "img_caption": ["Figure 11: Response patterns for each LLM, where darker indicates more often correct. Questions are sorted by difficulty ( $\\beta$ value). LLMs are non-instructed tuned open source models and GPT3.5 with zero-shot. "], "img_footnote": [], "page_idx": 27}, {"type": "image", "img_path": "Cth1PyCwZt/tmp/2a4c7bcc471cc93467e40bf06f591a98bbb3c19093c44e71443a283c6d02f9b8.jpg", "img_caption": ["Figure 12: Response patterns for each LLM, where darker indicates more often correct. Questions are sorted by difficulty ( $\\beta$ value). LLMs are instructed tuned open source models with zero-shot. "], "img_footnote": [], "page_idx": 27}, {"type": "image", "img_path": "Cth1PyCwZt/tmp/0cf0fc082336228c15c6951b4a1691e887d10e625b05e58d046e42cccceb5261.jpg", "img_caption": ["Figure 13: Response patterns for each LLM, where darker indicates more often correct. Questions are sorted by difficulty ( $\\beta$ value). LLMs are non-instructed tuned open source models and GPT3.5 with one-shot. "], "img_footnote": [], "page_idx": 28}, {"type": "image", "img_path": "Cth1PyCwZt/tmp/205115905dca7945270cac226dd193828ddde24e3c133a6f39b2562247b5d8f8.jpg", "img_caption": ["Figure 14: Response patterns for each LLM, where darker indicates more often correct. Questions are sorted by difficulty ( $\\beta$ value). LLMs are instructed tuned open source models with one-shot. "], "img_footnote": [], "page_idx": 28}, {"type": "image", "img_path": "Cth1PyCwZt/tmp/ab4222ede89bc915e53c6099ee04ea12f13bd8673cc2189083f205191ff50cac.jpg", "img_caption": [], "img_footnote": [], "page_idx": 29}, {"type": "text", "text": "Figure 15: Distribution of $l_{z}$ and IRT scores for humans and LLMs in the ENEM 2023 exam. LLMs are non-instructed tuned open source models and GPT3.5 with zero-shot. LLM datapoints are computed from different shuffles. ", "page_idx": 29}, {"type": "image", "img_path": "Cth1PyCwZt/tmp/50a81d4c105f9b69a6464a296a616ff056d68234f46a44264ae4f001e31ca655.jpg", "img_caption": ["Figure 16: Distribution of $l_{z}$ and IRT scores for humans and LLMs in the ENEM 2023 exam. LLMs are instructed tuned open source models with zero-shot. LLM datapoints are computed from different shuffles. "], "img_footnote": [], "page_idx": 29}, {"type": "image", "img_path": "Cth1PyCwZt/tmp/35a5d78c4df3de8e9109a83c5edc734bdaae7cf843e7da321a8e945acc35371e.jpg", "img_caption": ["Figure 17: Distribution of $l_{z}$ and IRT scores for humans and LLMs in the ENEM 2023 exam. LLMs are non-instructed tuned open source models and GPT3.5 with one-shot. LLM datapoints are computed from different shuffles. "], "img_footnote": [], "page_idx": 29}, {"type": "image", "img_path": "Cth1PyCwZt/tmp/b3881b4b6ae2855107ffb0515befe47abfcac61402472301216962e12fc1b878.jpg", "img_caption": ["Figure 18: Distribution of $l_{z}$ and IRT scores for humans and LLMs in the ENEM 2023 exam. LLMs are instructed tuned open source models with one-shot. LLM datapoints are computed from different shuffles. "], "img_footnote": [], "page_idx": 30}, {"type": "image", "img_path": "Cth1PyCwZt/tmp/1d3b750192a63a0309bcb9a175623f83767e913baa27c155179c24305af0a498.jpg", "img_caption": ["Figure 19: Distribution of CTT (accuracy) and IRT scores for humans and LLMs for the ENEM 2022 exam. LLMs are non-instructed tuned open source models and GPT3.5 with four-shot. LLM datapoints are computed from different shuffles. "], "img_footnote": [], "page_idx": 31}, {"type": "image", "img_path": "Cth1PyCwZt/tmp/37c48e84736bfef53e7bb8d547341e9420ad6c7580f833108de3d424680df662.jpg", "img_caption": ["Figure 20: Distribution of CTT (accuracy) and IRT scores for humans and LLMs for the ENEM 2022 exam. LLMs are instructed tuned open source models with four-shot. LLM datapoints are computed from different shuffles. "], "img_footnote": [], "page_idx": 32}, {"type": "image", "img_path": "Cth1PyCwZt/tmp/7046608e97c6fc3daccaab1fe258402ce20148f08cd31813b62a401a01ae2a52.jpg", "img_caption": ["Figure 21: Distribution of CTT (accuracy) and IRT scores for humans and LLMs for the ENEM 2022 exam. LLMs are non-instructed tuned open source models and GPT3.5 with zero-shot. LLM datapoints are computed from different shuffles. "], "img_footnote": [], "page_idx": 32}, {"type": "image", "img_path": "Cth1PyCwZt/tmp/85a85b2741a3c3d088450303ecca7f7742bc67c0a05d88f11d3b9b1137e4a98e.jpg", "img_caption": ["Figure 22: Distribution of CTT (accuracy) and IRT scores for humans and LLMs for the ENEM 2022 exam. LLMs are instructed tuned open source models with zero-shot. LLM datapoints are computed from different shuffles. "], "img_footnote": [], "page_idx": 33}, {"type": "image", "img_path": "Cth1PyCwZt/tmp/1b4201d4061994a6606d50dc4c9e9401102433cb21d7013627a5a2374b4e3e80.jpg", "img_caption": ["Figure 23: Distribution of CTT (accuracy) and IRT scores for humans and LLMs for the ENEM 2022 exam. LLMs are non-instructed tuned open source models and GPT3.5 with one-shot. LLM datapoints are computed from different shuffles. "], "img_footnote": [], "page_idx": 33}, {"type": "image", "img_path": "Cth1PyCwZt/tmp/5041a2ea06486b0aa40efac2c6213bd50dbe86c343eaf04100e80a4018969a6e.jpg", "img_caption": ["Figure 24: Distribution of CTT (accuracy) and IRT scores for humans and LLMs for the ENEM 2022 exam. LLMs are instructed tuned open source models with one-shot. LLM datapoints are computed from different shuffles. "], "img_footnote": [], "page_idx": 34}, {"type": "image", "img_path": "Cth1PyCwZt/tmp/1c1f442699e92a5374644a5e592e1bf1eaec2d1c6b122594f39e9b67b5bab2d9.jpg", "img_caption": ["Figure 25: Response patterns for each LLM, where darker indicates more often correct. Questions are sorted by difficulty ( $\\beta$ value). LLMs are non-instructed tuned open source models and GPT3.5 with four-shot. "], "img_footnote": [], "page_idx": 35}, {"type": "image", "img_path": "Cth1PyCwZt/tmp/df672fbfba8b86f409f92c0cf05da64fd0641bb98a7e59368b39986b46d6ce5b.jpg", "img_caption": ["Figure 26: Response patterns for each LLM, where darker indicates more often correct. Questions are sorted by difficulty ( $\\beta$ value). LLMs are instructed tuned open source models with four-shot. "], "img_footnote": [], "page_idx": 35}, {"type": "image", "img_path": "Cth1PyCwZt/tmp/3c277cc1192c85cdcfb7a48fddf2cb22ecbeb03cdccc03dd9173191004cec212.jpg", "img_caption": ["Figure 27: Response patterns for each LLM, where darker indicates more often correct. Questions are sorted by difficulty ( $\\beta$ value). LLMs are non-instructed tuned open source models and GPT3.5 with zero-shot. "], "img_footnote": [], "page_idx": 36}, {"type": "image", "img_path": "Cth1PyCwZt/tmp/efebfbb27c891a3bd541de889f63b384bd2031c86e1d728fe48553c5f9373435.jpg", "img_caption": ["Figure 28: Response patterns for each LLM, where darker indicates more often correct. Questions are sorted by difficulty ( $\\beta$ value). LLMs are instructed tuned open source models with zero-shot. "], "img_footnote": [], "page_idx": 36}, {"type": "image", "img_path": "Cth1PyCwZt/tmp/69e1fd810067096256efc1b5ea573f002cfebcecb88f449834f78a22081cad1b.jpg", "img_caption": ["Figure 29: Response patterns for each LLM, where darker indicates more often correct. Questions are sorted by difficulty ( $\\beta$ value). LLMs are non-instructed tuned open source models and GPT3.5 with one-shot. "], "img_footnote": [], "page_idx": 37}, {"type": "image", "img_path": "Cth1PyCwZt/tmp/fb1a9e282f36da696f2ee495686fde2d7da72f9eeafa1033ac7ebdc90784021c.jpg", "img_caption": ["Figure 30: Response patterns for each LLM, where darker indicates more often correct. Questions are sorted by difficulty ( $\\beta$ value). LLMs are instructed tuned open source models with one-shot. "], "img_footnote": [], "page_idx": 37}, {"type": "image", "img_path": "Cth1PyCwZt/tmp/187b944e189de62de202d7a35320c36aaf5f5c261a16efc5f0f9fe83e9dcfe83.jpg", "img_caption": [], "img_footnote": [], "page_idx": 38}, {"type": "text", "text": "Figure 31: Distribution of $l_{z}$ and IRT scores for humans and LLMs in the ENEM 2022 exam. LLMs are non-instructed tuned open source models and GPT3.5 with four-shot. LLM datapoints are computed from different shuffles. ", "page_idx": 38}, {"type": "image", "img_path": "Cth1PyCwZt/tmp/9906e2360424f5b322a88e7503b3d4ef0935df8908e1bf43a784bd5c56e14db6.jpg", "img_caption": ["Figure 32: Distribution of $l_{z}$ and IRT scores for humans and LLMs in the ENEM 2022 exam. LLMs are instructed tuned open source models with four-shot. LLM datapoints are computed from different shuffles. "], "img_footnote": [], "page_idx": 38}, {"type": "image", "img_path": "Cth1PyCwZt/tmp/9d4520d25082cbe5ebb9425b9f80c0987a5b24329fb6facb670533be9df5434e.jpg", "img_caption": ["Figure 33: Distribution of $l_{z}$ and IRT scores for humans and LLMs in the ENEM 2022 exam. LLMs are non-instructed tuned open source models and GPT3.5 with zero-shot. LLM datapoints are computed from different shuffles. "], "img_footnote": [], "page_idx": 38}, {"type": "image", "img_path": "Cth1PyCwZt/tmp/d92ef9bd3c3634bab23b2ff55dc011701383684d177a9441666851a1eec960b0.jpg", "img_caption": ["Figure 34: Distribution of $l_{z}$ and IRT scores for humans and LLMs in the ENEM 2022 exam. LLMs are instructed tuned open source models with zero-shot. LLM datapoints are computed from different shuffles. "], "img_footnote": [], "page_idx": 39}, {"type": "image", "img_path": "Cth1PyCwZt/tmp/b3f5fa1a25bd5ea6fd03579011b0d6c7d9ca3cf12d1fa996546aa00c49a8a6ca.jpg", "img_caption": ["Figure 35: Distribution of $l_{z}$ and IRT scores for humans and LLMs in the ENEM 2022 exam. LLMs are non-instructed tuned open source models and GPT3.5 with one-shot. LLM datapoints are computed from different shuffles. "], "img_footnote": [], "page_idx": 39}, {"type": "image", "img_path": "Cth1PyCwZt/tmp/7382e2d6e26ad792de4cb7bc72b16e73bf8fe0e39d3b7310bd2fe6354f6acd60.jpg", "img_caption": ["Figure 36: Distribution of $l_{z}$ and IRT scores for humans and LLMs in the ENEM 2022 exam. LLMs are instructed tuned open source models with one-shot. LLM datapoints are computed from different shuffles. "], "img_footnote": [], "page_idx": 39}, {"type": "text", "text": "1061 A.10 Examples of non-discriminating and highly discriminating items for the 2023 Natural   \n1062 Sciences exam. ", "page_idx": 40}, {"type": "text", "text": "1063 A.10.1 Poorly discriminative questions ", "page_idx": 40}, {"type": "text", "text": "1064 Question 107 (discrimination index -0.013) ", "text_level": 1, "page_idx": 40}, {"type": "text", "text": "1065 Municipalities are responsible for managing their urban waste (garbage) cleaning and collection   \n1066 according to the Federal Constitution. However, there are reports that part of this waste winds up in  \n1067 cinerated, releasing toxic substances into the environment and causing explosions-related accidents   \n1068 when incinerating aerosol bottles (e.g., deodorants, insecticides, and repellents). The high tempera  \n1069 ture causes all the contents inside these bottles to vaporize, increasing the internal pressure until it   \n1070 explodes.   \n1071 Suppose there is a metal aerosol bottle with a capacity of 100 milliliters containing $0.1\\,\\mathrm{\\mol}$ of   \n1072 gaseous products at a temperature of 650 degrees Celsius at the moment of explosion. ", "page_idx": 40}, {"type": "text", "text": "", "page_idx": 40}, {"type": "text", "text": "1073 Consider: $\\begin{array}{r}{R={\\frac{0.082\\times\\mathrm{liter}\\times3}{\\mathrm{mol}\\times\\mathrm{Ke}}}}\\end{array}$ atmosphere elvin ", "page_idx": 40}, {"type": "text", "text": "1074 The pressure, in atmospheres, inside the flask at the moment of the explosion is closest to ", "page_idx": 40}, {"type": "text", "text": "1075 A. 756   \n1076 B. 533   \n1077 C. 76   \n1078 D. 53   \n1079 E. 13 ", "page_idx": 40}, {"type": "text", "text": "1080 Question 108 (discrimination index -0.076) ", "text_level": 1, "page_idx": 40}, {"type": "text", "text": "1081 The circuit with three identical incandescent light bulbs, shown in the figure, consists of a mixed   \n1082 association of resistors. Each bulb (L1, L2, and L3) is associated in parallel with a resistor of   \n1083 resistance R, forming a set. These sets are connected in series, with all the bulbs having the same   \n1084 brightness when connected to the power supply. After several days in use, only lamp L2 burns out,   \n1085 while the others remain lit.   \n1086 Figure description: a power supply connected to three sets, arranged in series clockwise, in the   \n1087 following sequence: the parallel set of L1 and R, the parallel set of L2 and R, and the parallel set of   \n1088 L3 and R. ", "page_idx": 40}, {"type": "text", "text": "", "page_idx": 40}, {"type": "image", "img_path": "Cth1PyCwZt/tmp/2be7bd3e177e062660e78e447ddd8fd15e9f233bcb434d85faee7e3c74ad3cbd.jpg", "img_caption": ["Figure 37: Question 108 Natural Sciences "], "img_footnote": [], "page_idx": 40}, {"type": "text", "text": "1089 In the case where all the bulbs work, after L2 burns out, the brightness of the bulbs will be ", "page_idx": 40}, {"type": "text", "text": "1090 A. the same.   \n1091 B. more intense.   \n1092 C. less intense.   \n1093 D. less intense for L1 and the same for L3.   \n1094 E. more intense for L1 and less intense for L3. ", "page_idx": 40}, {"type": "text", "text": "1095 Question 109 (discrimination index 0.013) ", "text_level": 1, "page_idx": 41}, {"type": "text", "text": "1096 A company\u2019s transport safety team is evaluating the behavior of the tensions that appear in two   \n1097 horizontal ropes, 1 and 2, used to secure a load of mass M equal to 200 kilograms to the truck,   \n1098 as shown in the illustration. When the truck starts from rest, its acceleration is constant and equal   \n1099 to 3 meters per second squared, while when it arbitrarily brakes, its braking is constant and equal   \n1100 to 5 meters per second squared. In both situations, the load is about to move, and the direction of   \n1101 the truck\u2019s movement is shown in the figure. The coefficient of static friction between the box and   \n1102 the bottom surface of the body is 0.2. Consider the acceleration due to gravity to be 10 meters per   \n1103 second squared, the initial tension in the ropes is zero, and the two ropes are ideal.   \n1104 Figure description: a truck traveling horizontally to the right (represented by the vector V). A box M   \n1105 is resting on the central surface of its body. The box is attached to the rear of the body by horizontal   \n1106 rope 1 and to the front by horizontal rope 2. ", "page_idx": 41}, {"type": "text", "text": "", "page_idx": 41}, {"type": "image", "img_path": "Cth1PyCwZt/tmp/e762352d3648971ec3a9e9934c975402b1b8a2edf9225f109d2a8c88cc73cbc1.jpg", "img_caption": ["Figure 38: Question 109 Natural Sciences "], "img_footnote": [], "page_idx": 41}, {"type": "text", "text": "1107 When the truck is accelerating and braking, the tensions in ropes 1 and 2 in Newton will be ", "page_idx": 41}, {"type": "text", "text": "1108 A. acceleration: ${\\mathrm{T}}1{=}0$ and ${\\mathrm{T}}2{=}200$ ; braking: $\\mathrm{T}1{=}600$ and ${\\mathrm{T}}2{=}0$ .   \n1109 B. acceleration: T1 $=\\!0$ and ${\\mathrm{T}}2{=}200$ ; braking: $T1{=}1400$ and ${\\mathrm{T}}2{=}0$ .   \n1110 C. acceleration: T1 $=\\!0$ and $\\mathrm{T}2{=}600$ ; braking: $\\mathrm{T}1{=}600$ and ${\\mathrm{T}}2{=}0$ .   \n1111 D. acceleration: T $\\scriptstyle1=560$ and ${\\mathrm{T}}2{=}0$ ; braking: ${\\mathrm{T}}1{=}0$ and $\\mathrm{T}2{=}960$ .   \n1112 E. acceleration: T $\\scriptstyle1=640$ and ${\\mathrm{T}}2{=}0$ ; braking: T1 $=\\!0$ and $_{\\mathrm{T2=1040}}$ . ", "page_idx": 41}, {"type": "text", "text": "1113 A.10.2 Highly discriminative questions ", "text_level": 1, "page_idx": 42}, {"type": "text", "text": "1114 Question 124 (discrimination index 0.650) ", "text_level": 1, "page_idx": 42}, {"type": "text", "text": "1115 Update of the Portuguese Society of Neonatology\u2019s recommendation ", "page_idx": 42}, {"type": "text", "text": "1116 Glass containing aluminum is an excellent material for packaging medicines and supplements be  \n1117 cause heating can sterilize it. However, when the drug or supplement contains substances that bind   \n1118 strongly to this metal\u2019s ion, the aluminum\u2019s dissolution is promoted by the displacement of the   \n1119 chemical equilibrium established between the species immobilized in the glass and the species in   \n1120 solution. For this reason, it is recommended that newborn nutrition supplements containing calcium   \n1121 gluconate be packaged in plastic containers rather than in this type of glass.   \n1122 If this supplement is packaged in this type of glass, the risk of contamination by aluminum will be   \n1123 greater if the   \n1124 A. glass of the bottle is translucent.   \n1125 B. concentration of calcium gluconate is high.   \n1126 C. glass bottle is thicker.   \n1127 D. glass is previously sterilized at high temperatures.   \n1128 E. reaction of aluminum with calcium gluconate is endothermic. ", "page_idx": 42}, {"type": "text", "text": "", "page_idx": 42}, {"type": "text", "text": "", "page_idx": 42}, {"type": "text", "text": "1129 Question 91 (discrimination index 0.624) ", "text_level": 1, "page_idx": 42}, {"type": "text", "text": "1130 It is a common requirement to turn off devices, such as cell phones, whose operation involves emit  \n1131 ting or receiving electromagnetic waves when traveling by plane. The justification for this procedure   \n1132 is, among other things, the need to eliminate sources of electromagnetic signals that could interfere   \n1133 with the pilots\u2019 radio communications with the control tower.   \n1134 This interference can only occur if the waves emitted by the cell phone and those received by the   \n1135 plane\u2019s radio   \n1136 A. are both audible.   \n1137 B. have the same power.   \n1138 C. have the same frequency.   \n1139 D. have the same intensity.   \n1140 E. propagate at different speeds. ", "page_idx": 42}, {"type": "text", "text": "", "page_idx": 42}, {"type": "text", "text": "", "page_idx": 42}, {"type": "text", "text": "1141 Question 130 (discrimination index 0.621) ", "text_level": 1, "page_idx": 42}, {"type": "text", "text": "1142 The number of bees is in decline in various regions of the world, including Brazil, and multiple   \n1143 factors are contributing to the collapse of their hives. In the United States, seed bombs of native   \n1144 plant species have been used to combat the disappearance of these insects. They are small balls   \n1145 filled with seeds, compost, and clay. When they are thrown and exposed to sun and rain, they   \n1146 germinate even in poorly fertile soil. ", "page_idx": 42}, {"type": "text", "text": "1147 This method contributes to the preservation of bees because ", "page_idx": 42}, {"type": "text", "text": "1148 A. it reduces predation.   \n1149 B. it reduces the use of pesticides.   \n1150 C. it reduces competition for shelter.   \n1151 D. it increases the food supply.   \n1152 E. it increases breeding sites.   \n1154 The Humanities exam assesses understanding of geographical, cultural, and socioeconomic trans  \n1155 formations, as well as comprehension of social and political institutions, technological changes, and   \n1156 the use of historical knowledge to promote conscious engagement in society. It requires recognizing   \n1157 the interactions between society and nature in various historical and geographical contexts.   \n1158 The Languages and Codes exam assesses the use of communication in various contexts. This in  \n1159 cludes some knowledge and use of foreign languages, understanding of body language, analysis and   \ninterpretation of expressive resources in different languages, comprehension of opinions in specific   \nlanguages, and understanding the impact of communication on personal and social life.   \n1162 The Natural Sciences exam assesses understanding of natural sciences and recognizing their roles   \n1163 in production, economic and social development. It involves associating environmental degrada  \n1164 tion or conservation with productive and social processes, understanding the interactions between   \n1165 organisms and the environment, and applying specific knowledge of physics, chemistry, and biology.   \n1166 The Math exam assesses the usage of geometric knowledge to represent reality, understanding no  \n1167 tions of magnitudes, measurements, and their variations for solving everyday problems, interpreting   \n1168 information of scientific and social nature obtained from reading graphs and tables, and making   \n1169 trend predictions, extrapolations, interpolations, and interpretations. ", "page_idx": 42}, {"type": "text", "text": "", "page_idx": 43}, {"type": "text", "text": "1170 NeurIPS Paper Checklist ", "text_level": 1, "page_idx": 44}, {"type": "text", "text": "172 Question: Do the main claims made in the abstract and introduction accurately reflect the   \n1173 paper\u2019s contributions and scope? ", "page_idx": 44}, {"type": "text", "text": "Justification: We show how IRT can be used to study LLM in comparison to humans through multiple-metric propositions (Section 3) and their results and discussions (Section 5). ", "page_idx": 44}, {"type": "text", "text": "\u2022 The answer NA means that the abstract and introduction do not include the claims made in the paper.   \n\u2022 The abstract and/or introduction should clearly state the claims made, including the contributions made in the paper and important assumptions and limitations. A No or NA answer to this question will not be perceived well by the reviewers.   \n\u2022 The claims made should match theoretical and experimental results, and reflect how much the results can be expected to generalize to other settings.   \n\u2022 It is fine to include aspirational goals as motivation as long as it is clear that these goals are not attained by the paper. ", "page_idx": 44}, {"type": "text", "text": "2. Limitations ", "text_level": 1, "page_idx": 44}, {"type": "text", "text": "Question: Does the paper discuss the limitations of the work performed by the authors? Answer: [Yes] ", "page_idx": 44}, {"type": "text", "text": "Justification: We discuss limitations of prompts and models in Appendix A.4, limitations of contamination correlation study in Appendix A.3, limitation of the dataset curation in Appendix A.1 ", "page_idx": 44}, {"type": "text", "text": "\u2022 The answer NA means that the paper has no limitation while the answer No means that the paper has limitations, but those are not discussed in the paper.   \n\u2022 The authors are encouraged to create a separate \u201dLimitations\u201d section in their paper.   \n\u2022 The paper should point out any strong assumptions and how robust the results are to violations of these assumptions (e.g., independence assumptions, noiseless settings, model well-specification, asymptotic approximations only holding locally). The authors should reflect on how these assumptions might be violated in practice and what the implications would be.   \n\u2022 The authors should reflect on the scope of the claims made, e.g., if the approach was only tested on a few datasets or with a few runs. In general, empirical results often depend on implicit assumptions, which should be articulated.   \n\u2022 The authors should reflect on the factors that influence the performance of the approach. For example, a facial recognition algorithm may perform poorly when image resolution is low or images are taken in low lighting. Or a speech-to-text system might not be used reliably to provide closed captions for online lectures because it fails to handle technical jargon.   \n\u2022 The authors should discuss the computational efficiency of the proposed algorithms and how they scale with dataset size.   \n\u2022 If applicable, the authors should discuss possible limitations of their approach to address problems of privacy and fairness.   \n\u2022 While the authors might fear that complete honesty about limitations might be used by reviewers as grounds for rejection, a worse outcome might be that reviewers discover limitations that aren\u2019t acknowledged in the paper. The authors should use their best judgment and recognize that individual actions in favor of transparency play an important role in developing norms that preserve the integrity of the community. Reviewers will be specifically instructed to not penalize honesty concerning limitations. ", "page_idx": 44}, {"type": "text", "text": "1221 3. Theory Assumptions and Proofs ", "text_level": 1, "page_idx": 44}, {"type": "text", "text": "22 Question: For each theoretical result, does the paper provide the full set of assumptions and   \n23 a complete (and correct) proof?   \n24 Answer: [NA]   \n25 Justification: We do not include theoretical results.   \n26 Guidelines:   \n27 \u2022 The answer NA means that the paper does not include theoretical results.   \n28 \u2022 All the theorems, formulas, and proofs in the paper should be numbered and cross  \n29 referenced.   \n30 \u2022 All assumptions should be clearly stated or referenced in the statement of any theo  \n31 rems.   \n32 \u2022 The proofs can either appear in the main paper or the supplemental material, but if   \n33 they appear in the supplemental material, the authors are encouraged to provide a   \n34 short proof sketch to provide intuition.   \n35 \u2022 Inversely, any informal proof provided in the core of the paper should be comple  \n36 mented by formal proofs provided in appendix or supplemental material.   \n37 \u2022 Theorems and Lemmas that the proof relies upon should be properly referenced.   \n38 4. Experimental Result Reproducibility   \n39 Question: Does the paper fully disclose all the information needed to reproduce the main   \n40 experimental results of the paper to the extent that it affects the main claims and/or conclu  \n41 sions of the paper (regardless of whether the code and data are provided or not)?   \n42 Answer: [Yes]   \n43 Justification: We describe our dataset creation in Section 4.1, data manual auditing process   \n44 in Appendix A.1, prompting and evaluation details in Section 4.2 and Appendix A.4. We   \n45 will release our code and data. ", "page_idx": 45}, {"type": "text", "text": "Guidelines: ", "page_idx": 45}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 If the paper includes experiments, a No answer to this question will not be perceived well by the reviewers: Making the paper reproducible is important, regardless of whether the code and data are provided or not.   \n\u2022 If the contribution is a dataset and/or model, the authors should describe the steps taken to make their results reproducible or verifiable.   \n\u2022 Depending on the contribution, reproducibility can be accomplished in various ways. For example, if the contribution is a novel architecture, describing the architecture fully might suffice, or if the contribution is a specific model and empirical evaluation, it may be necessary to either make it possible for others to replicate the model with the same dataset, or provide access to the model. In general. releasing code and data is often one good way to accomplish this, but reproducibility can also be provided via detailed instructions for how to replicate the results, access to a hosted model (e.g., in the case of a large language model), releasing of a model checkpoint, or other means that are appropriate to the research performed.   \n\u2022 While NeurIPS does not require releasing code, the conference does require all submissions to provide some reasonable avenue for reproducibility, which may depend on the nature of the contribution. For example (a) If the contribution is primarily a new algorithm, the paper should make it clear how to reproduce that algorithm. (b) If the contribution is primarily a new model architecture, the paper should describe the architecture clearly and fully. (c) If the contribution is a new model (e.g., a large language model), then there should either be a way to access this model for reproducing the results or a way to reproduce the model (e.g., with an open-source dataset or instructions for how to construct the dataset). (d) We recognize that reproducibility may be tricky in some cases, in which case authors are welcome to describe the particular way they provide for reproducibility. In the case of closed-source models, it may be that access to the model is limited in ", "page_idx": 45}, {"type": "text", "text": "1276 some way (e.g., to registered users), but it should be possible for other researchers   \n1277 to have some path to reproducing or verifying the results.   \n1278 5. Open access to data and code   \n1279 Question: Does the paper provide open access to the data and code, with sufficient instruc  \n1280 tions to faithfully reproduce the main experimental results, as described in supplemental   \n1281 material?   \n1282 Answer: [Yes]   \n1283 Justification: We provide the code with reproducibility instructions. We will also provide   \n1284 all the data.   \n1285 Guidelines:   \n1286 \u2022 The answer NA means that paper does not include experiments requiring code.   \n1287 \u2022 Please see the NeurIPS code and data submission guidelines (https://nips.cc/pu   \n1288 blic/guides/CodeSubmissionPolicy) for more details.   \n1289 \u2022 While we encourage the release of code and data, we understand that this might not   \n1290 be possible, so \u201cNo\u201d is an acceptable answer. Papers cannot be rejected simply for not   \n1291 including code, unless this is central to the contribution (e.g., for a new open-source   \n1292 benchmark).   \n1293 \u2022 The instructions should contain the exact command and environment needed to run to   \n1294 reproduce the results. See the NeurIPS code and data submission guidelines (https:   \n1295 //nips.cc/public/guides/CodeSubmissionPolicy) for more details.   \n1296 \u2022 The authors should provide instructions on data access and preparation, including how   \n1297 to access the raw data, preprocessed data, intermediate data, and generated data, etc.   \n1298 \u2022 The authors should provide scripts to reproduce all experimental results for the new   \n1299 proposed method and baselines. If only a subset of experiments are reproducible, they   \n1300 should state which ones are omitted from the script and why.   \n1301 \u2022 At submission time, to preserve anonymity, the authors should release anonymized   \n1302 versions (if applicable).   \n1303 \u2022 Providing as much information as possible in supplemental material (appended to the   \n1304 paper) is recommended, but including URLs to data and code is permitted.   \n1305 6. Experimental Setting/Details   \n1306 Question: Does the paper specify all the training and test details (e.g., data splits, hyper  \n1307 parameters, how they were chosen, type of optimizer, etc.) necessary to understand the   \n1308 results?   \n1309 Answer: [Yes]   \n1310 Justification: Prompting and evaluation details given in Section 4.2 and Appendix A.4.   \n1311 Evaluation scripts can be seen in our code.   \n1312 Guidelines:   \n1313 \u2022 The answer NA means that the paper does not include experiments.   \n1314 \u2022 The experimental setting should be presented in the core of the paper to a level of   \n1315 detail that is necessary to appreciate the results and make sense of them.   \n1316 \u2022 The full details can be provided either with the code, in appendix, or as supplemental   \n1317 material.   \n1318 7. Experiment Statistical Significance   \n1319 Question: Does the paper report error bars suitably and correctly defined or other appropri  \n1320 ate information about the statistical significance of the experiments?   \n1321 Answer: [Yes]   \n1322 Justification: We describe our option shuffling procedure in Section 4.2 and Appendix A.4   \n1323 to account for model bias for generating option letters. For all plots, we explain what were   \n1324 the confidence intervals/means are (Figures 1, 2, 4, and 3)   \n1325 Guidelines:   \n1326 \u2022 The answer NA means that the paper does not include experiments.   \n1327 \u2022 The authors should answer \u201dYes\u201d if the results are accompanied by error bars, confi  \n1328 dence intervals, or statistical significance tests, at least for the experiments that support   \n1329 the main claims of the paper.   \n1330 \u2022 The factors of variability that the error bars are capturing should be clearly stated (for   \n1331 example, train/test split, initialization, random drawing of some parameter, or overall   \n1332 run with given experimental conditions).   \n1333 \u2022 The method for calculating the error bars should be explained (closed form formula,   \n1334 call to a library function, bootstrap, etc.)   \n1335 \u2022 The assumptions made should be given (e.g., Normally distributed errors).   \n1336 \u2022 It should be clear whether the error bar is the standard deviation or the standard error   \n1337 of the mean.   \n1338 \u2022 It is OK to report 1-sigma error bars, but one should state it. The authors should prefer  \n1339 ably report a 2-sigma error bar than state that they have a $96\\%$ CI, if the hypothesis of   \n1340 Normality of errors is not verified.   \n1341 \u2022 For asymmetric distributions, the authors should be careful not to show in tables or   \n1342 figures symmetric error bars that would yield results that are out of range (e.g. negative   \n1343 error rates).   \n1344 \u2022 If error bars are reported in tables or plots, The authors should explain in the text how   \n1345 they were calculated and reference the corresponding figures or tables in the text.   \n1346 8. Experiments Compute Resources   \n1347 Question: For each experiment, does the paper provide sufficient information on the com  \n1348 puter resources (type of compute workers, memory, time of execution) needed to reproduce   \n1349 the experiments?   \n1350 Answer: [Yes]   \n1351 Justification: We disclose the compute related information in Appendix A.5   \n1352 Guidelines:   \n1353 \u2022 The answer NA means that the paper does not include experiments.   \n1354 \u2022 The paper should indicate the type of compute workers CPU or GPU, internal cluster,   \n1355 or cloud provider, including relevant memory and storage.   \n1356 \u2022 The paper should provide the amount of compute required for each of the individual   \n1357 experimental runs as well as estimate the total compute.   \n1358 \u2022 The paper should disclose whether the full research project required more compute   \n1359 than the experiments reported in the paper (e.g., preliminary or failed experiments   \n1360 that didn\u2019t make it into the paper).   \n1361 9. Code Of Ethics   \n1362 Question: Does the research conducted in the paper conform, in every respect, with the   \n1363 NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines?   \n1364 Answer: [Yes]   \n1365 Justification: We have reviewed the code of ethics and our work conforms with it.   \n1366 Guidelines:   \n1367 \u2022 The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics.   \n1368 \u2022 If the authors answer No, they should explain the special circumstances that require a   \n1369 deviation from the Code of Ethics.   \n1370 \u2022 The authors should make sure to preserve anonymity (e.g., if there is a special consid  \n1371 eration due to laws or regulations in their jurisdiction).   \n1372 10. Broader Impacts   \n1373 Question: Does the paper discuss both potential positive societal impacts and negative   \n1374 societal impacts of the work performed?   \n1375 Answer: [Yes]   \n1376 Justification: We discuss the impact of our work in Section 5 and 6.   \n1377 Guidelines:   \n1378 \u2022 The answer NA means that there is no societal impact of the work performed.   \n1379 \u2022 If the authors answer NA or No, they should explain why their work has no societal   \n1380 impact or why the paper does not address societal impact.   \n1381 \u2022 Examples of negative societal impacts include potential malicious or unintended uses   \n1382 (e.g., disinformation, generating fake profiles, surveillance), fairness considerations   \n1383 (e.g., deployment of technologies that could make decisions that unfairly impact spe  \n1384 cific groups), privacy considerations, and security considerations.   \n1385 \u2022 The conference expects that many papers will be foundational research and not tied   \n1386 to particular applications, let alone deployments. However, if there is a direct path to   \n1387 any negative applications, the authors should point it out. For example, it is legitimate   \n1388 to point out that an improvement in the quality of generative models could be used to   \n1389 generate deepfakes for disinformation. On the other hand, it is not needed to point out   \n1390 that a generic algorithm for optimizing neural networks could enable people to train   \n1391 models that generate Deepfakes faster.   \n1392 \u2022 The authors should consider possible harms that could arise when the technology is   \n1393 being used as intended and functioning correctly, harms that could arise when the   \n1394 technology is being used as intended but gives incorrect results, and harms following   \n1395 from (intentional or unintentional) misuse of the technology.   \n1396 \u2022 If there are negative societal impacts, the authors could also discuss possible mitiga  \n1397 tion strategies (e.g., gated release of models, providing defenses in addition to attacks,   \n1398 mechanisms for monitoring misuse, mechanisms to monitor how a system learns from   \n1399 feedback over time, improving the efficiency and accessibility of ML).   \n1400 11. Safeguards   \n1401 Question: Does the paper describe safeguards that have been put in place for responsible   \n1402 release of data or models that have a high risk for misuse (e.g., pretrained language models,   \n1403 image generators, or scraped datasets)?   \n1404 Answer: [NA]   \n1405 Justification: We do not forsee any negative impact with our work.   \n1406 Guidelines:   \n1407 \u2022 The answer NA means that the paper poses no such risks.   \n1408 \u2022 Released models that have a high risk for misuse or dual-use should be released with   \n1409 necessary safeguards to allow for controlled use of the model, for example by re  \n1410 quiring that users adhere to usage guidelines or restrictions to access the model or   \n1411 implementing safety filters.   \n1412 \u2022 Datasets that have been scraped from the Internet could pose safety risks. The authors   \n1413 should describe how they avoided releasing unsafe images.   \n1414 \u2022 We recognize that providing effective safeguards is challenging, and many papers do   \n1415 not require this, but we encourage authors to take this into account and make a best   \n1416 faith effort.   \n1417 12. Licenses for existing assets   \n1418 Question: Are the creators or original owners of assets (e.g., code, data, models), used in   \n1419 the paper, properly credited and are the license and terms of use explicitly mentioned and   \n1420 properly respected?   \n1421 Answer: [Yes]   \n1422 Justification: We cite and and describe in detail the process through which we obtained   \n1423 ENEM dataset in section 4.1.   \n1424 Guidelines:   \n1425 \u2022 The answer NA means that the paper does not use existing assets.   \n1426 \u2022 The authors should cite the original paper that produced the code package or dataset.   \n1427 \u2022 The authors should state which version of the asset is used and, if possible, include a   \n1428 URL.   \n1429 \u2022 The name of the license (e.g., CC-BY 4.0) should be included for each asset.   \n1430 \u2022 For scraped data from a particular source (e.g., website), the copyright and terms of   \n1431 service of that source should be provided.   \n1432 \u2022 If assets are released, the license, copyright information, and terms of use in the pack  \n1433 age should be provided. For popular datasets, paperswithcode.com/datasets   \n1434 has curated licenses for some datasets. Their licensing guide can help determine the   \n1435 license of a dataset.   \n1436 \u2022 For existing datasets that are re-packaged, both the original license and the license of   \n1437 the derived asset (if it has changed) should be provided.   \n1438 \u2022 If this information is not available online, the authors are encouraged to reach out to   \n1439 the asset\u2019s creators.   \n1440 13. New Assets   \n1441 Question: Are new assets introduced in the paper well documented and is the documenta  \n1442 tion provided alongside the assets?   \n1443 Answer: [Yes]   \n1444 Justification: We submit our dataset and include details of how we obtained the text in   \n1445 detail in Section 4.1 and Appendix A.1. Human results and related parameters are released   \n1446 by ENEM officials.   \n1447 Guidelines:   \n1448 \u2022 The answer NA means that the paper does not release new assets.   \n1449 \u2022 Researchers should communicate the details of the dataset/code/model as part of their   \n1450 submissions via structured templates. This includes details about training, license,   \n1451 limitations, etc.   \n1452 \u2022 The paper should discuss whether and how consent was obtained from people whose   \n1453 asset is used.   \n1454 \u2022 At submission time, remember to anonymize your assets (if applicable). You can   \n1455 either create an anonymized URL or include an anonymized zip file.   \n1456 14. Crowdsourcing and Research with Human Subjects   \n1457 Question: For crowdsourcing experiments and research with human subjects, does the pa  \n1458 per include the full text of instructions given to participants and screenshots, if applicable,   \n1459 as well as details about compensation (if any)?   \n1460 Answer: [NA]   \n1461 Justification: We did not crowdsource. The human results are published by ENEM officials.   \n1462 Guidelines:   \n1463 \u2022 The answer NA means that the paper does not involve crowdsourcing nor research   \n1464 with human subjects.   \n1465 \u2022 Including this information in the supplemental material is fine, but if the main contri  \n1466 bution of the paper involves human subjects, then as much detail as possible should   \n1467 be included in the main paper.   \n1468 \u2022 According to the NeurIPS Code of Ethics, workers involved in data collection, cura  \n1469 tion, or other labor should be paid at least the minimum wage in the country of the   \n1470 data collector.   \n1471 15. Institutional Review Board (IRB) Approvals or Equivalent for Research with Human   \n1472 Subjects   \n1473 Question: Does the paper describe potential risks incurred by study participants, whether   \n1474 such risks were disclosed to the subjects, and whether Institutional Review Board (IRB)   \n1475 approvals (or an equivalent approval/review based on the requirements of your country or   \n1476 institution) were obtained?   \n1477 Answer: [NA]   \n1478 Justification: Our study does not involve human subjects.   \n1479 Guidelines:   \n1480 \u2022 The answer NA means that the paper does not involve crowdsourcing nor research   \n1481 with human subjects.   \n1482   \n1483   \n1484   \n1485   \n1486   \n1487   \n1488   \n1489 ", "page_idx": 46}, {"type": "text", "text": "", "page_idx": 47}, {"type": "text", "text": "", "page_idx": 48}, {"type": "text", "text": "", "page_idx": 49}, {"type": "text", "text": "", "page_idx": 50}, {"type": "text", "text": "\u2022 Depending on the country in which research is conducted, IRB approval (or equivalent) may be required for any human subjects research. If you obtained IRB approval, you should clearly state this in the paper.   \n\u2022 We recognize that the procedures for this may vary significantly between institutions and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the guidelines for their institution.   \n\u2022 For initial submissions, do not include any information that would break anonymity (if applicable), such as the institution conducting the review. ", "page_idx": 50}]