[{"figure_path": "CKgNgKmHYp/figures/figures_1_1.jpg", "caption": "Figure 1: Personalization in white-box and black-box LLMs. Existing methods prioritize (a) fine-tuning user-specific models in white-box LLM personalization, while (b) designing user-specific prompts for black-box LLM personalization. In HYDRA, we present (c) a learning-based model factorization solution to enhance the effectiveness of personalization in black-box LLMs.", "description": "This figure illustrates three different approaches to LLM personalization. (a) shows the traditional fine-tuning approach for white-box LLMs where user-specific models are trained. (b) shows the prompt-based approach for black-box LLMs where user-specific information is incorporated into the prompt. (c) shows the HYDRA approach which leverages a model factorization technique to achieve better personalization in black-box LLMs, by using a shared base model and user-specific heads. This allows it to learn both general knowledge and user-specific preferences without needing access to the internal model parameters of the black-box LLMs.", "section": "3 HYDRA: Model Factorization for Black-Box LLM Personalization"}, {"figure_path": "CKgNgKmHYp/figures/figures_3_1.jpg", "caption": "Figure 2: Overview of HYDRA. HYDRA follows a retrieval-augmented framework: (1) Firstly, we extend an original RAG to a two-stage retrieve-then-rerank workflow, where we rerank the most useful information from relevant user behavior records to capture user-specific preference (Section 3.2); (2) Secondly, augmented by the selected historical data, we train an adapter to align the output of black-box LLMs with personalized human preference (Section 3.3). Both the reranker and the adapter can be decomposed into a base model with multiple user-specific heads, resembling a hydra-like structure (Section 3.4). The base model maintains shared knowledge across users, while multiple personal heads capture user-specific preferences. represents the model decomposition for personalization.", "description": "This figure illustrates the HYDRA framework's workflow.  It starts with retrieving and reranking relevant user history to focus on the most useful information.  This refined history is then used to train an adapter that aligns the black-box LLM's output with the user's preferences.  Both the reranker and adapter use a base model with multiple user-specific heads (the 'Hydra'). The base model handles shared knowledge across all users, while the individual heads learn the specific preferences of each user.", "section": "3.2 Retrieve-then-Rerank"}, {"figure_path": "CKgNgKmHYp/figures/figures_7_1.jpg", "caption": "Figure 2: Overview of HYDRA. HYDRA follows a retrieval-augmented framework: (1) Firstly, we extend an original RAG to a two-stage retrieve-then-rerank workflow, where we rerank the most useful information from relevant user behavior records to capture user-specific preference (Section 3.2); (2) Secondly, augmented by the selected historical data, we train an adapter to align the output of black-box LLMs with personalized human preference (Section 3.3). Both the reranker and the adapter can be decomposed into a base model with multiple user-specific heads, resembling a hydra-like structure (Section 3.4). The base model maintains shared knowledge across users, while multiple personal heads capture user-specific preferences.  represents the model decomposition for personalization.", "description": "This figure illustrates the HYDRA framework.  It shows a two-stage retrieval-augmented process: First, a reranker prioritizes useful information from retrieved user history; second, an adapter aligns black-box LLM outputs with user preferences using the prioritized history and query.  Both reranker and adapter use a base model with multiple user-specific heads, capturing shared and user-specific knowledge respectively. This architecture is designed to improve personalization in black-box LLMs.", "section": "3.2 Retrieve-then-Rerank"}, {"figure_path": "CKgNgKmHYp/figures/figures_8_1.jpg", "caption": "Figure 2: Overview of HYDRA. HYDRA follows a retrieval-augmented framework: (1) Firstly, we extend an original RAG to a two-stage retrieve-then-rerank workflow, where we rerank the most useful information from relevant user behavior records to capture user-specific preference (Section 3.2); (2) Secondly, augmented by the selected historical data, we train an adapter to align the output of black-box LLMs with personalized human preference (Section 3.3). Both the reranker and the adapter can be decomposed into a base model with multiple user-specific heads, resembling a hydra-like structure (Section 3.4). The base model maintains shared knowledge across users, while multiple personal heads capture user-specific preferences. represents the model decomposition for personalization.", "description": "This figure illustrates the architecture of HYDRA, a model factorization framework for black-box LLM personalization. It consists of three main steps:  First, a retriever extracts relevant user behaviors from historical data. Second, a reranker prioritizes the most useful information from these retrieved records. Third, an adapter aligns the output of a black-box LLM with individual user preferences using the prioritized historical data.  The reranker and adapter are both composed of a shared base model and multiple user-specific heads, resembling a hydra, allowing HYDRA to capture both shared knowledge and user-specific behaviors.", "section": "3 HYDRA: Model Factorization for Black-Box LLM Personalization"}, {"figure_path": "CKgNgKmHYp/figures/figures_9_1.jpg", "caption": "Figure 2: Overview of HYDRA. HYDRA follows a retrieval-augmented framework: (1) Firstly, we extend an original RAG to a two-stage retrieve-then-rerank workflow, where we rerank the most useful information from relevant user behavior records to capture user-specific preference (Section 3.2); (2) Secondly, augmented by the selected historical data, we train an adapter to align the output of black-box LLMs with personalized human preference (Section 3.3). Both the reranker and the adapter can be decomposed into a base model with multiple user-specific heads, resembling a hydra-like structure (Section 3.4). The base model maintains shared knowledge across users, while multiple personal heads capture user-specific preferences. represents the model decomposition for personalization.", "description": "This figure illustrates the architecture of HYDRA, a model factorization framework for black-box LLM personalization. It shows a retrieval-augmented workflow with two main components: a reranker and an adapter. The reranker prioritizes useful information from retrieved user behavior records. The adapter then aligns the output of the black-box LLM with user-specific preferences. Both components are decomposed into a base model with multiple user-specific heads. The base model represents shared knowledge among all users, and the heads capture user-specific behavior patterns.", "section": "3 HYDRA: Model Factorization for Black-Box LLM Personalization"}, {"figure_path": "CKgNgKmHYp/figures/figures_9_2.jpg", "caption": "Figure 2: Overview of HYDRA. HYDRA follows a retrieval-augmented framework: (1) Firstly, we extend an original RAG to a two-stage retrieve-then-rerank workflow, where we rerank the most useful information from relevant user behavior records to capture user-specific preference (Section 3.2); (2) Secondly, augmented by the selected historical data, we train an adapter to align the output of black-box LLMs with personalized human preference (Section 3.3). Both the reranker and the adapter can be decomposed into a base model with multiple user-specific heads, resembling a hydra-like structure (Section 3.4). The base model maintains shared knowledge across users, while multiple personal heads capture user-specific preferences.  represents the model decomposition for personalization.", "description": "This figure illustrates the architecture of HYDRA, a model factorization framework for black-box LLM personalization. It depicts a retrieval-augmented workflow with two key components: a reranker and an adapter. The reranker prioritizes useful information from retrieved user behavior records, while the adapter aligns the black-box LLM outputs with user-specific preferences. Both components are decomposed into a base model with multiple user-specific heads, allowing HYDRA to capture both shared knowledge and user-specific behavior patterns.  The model factorization enhances generalization across users.", "section": "3 HYDRA: Model Factorization for Black-Box LLM Personalization"}, {"figure_path": "CKgNgKmHYp/figures/figures_17_1.jpg", "caption": "Figure 2: Overview of HYDRA. HYDRA follows a retrieval-augmented framework: (1) Firstly, we extend an original RAG to a two-stage retrieve-then-rerank workflow, where we rerank the most useful information from relevant user behavior records to capture user-specific preference (Section 3.2); (2) Secondly, augmented by the selected historical data, we train an adapter to align the output of black-box LLMs with personalized human preference (Section 3.3). Both the reranker and the adapter can be decomposed into a base model with multiple user-specific heads, resembling a hydra-like structure (Section 3.4). The base model maintains shared knowledge across users, while multiple personal heads capture user-specific preferences.  represents the model decomposition for personalization.", "description": "This figure illustrates the HYDRA framework's architecture and workflow.  It's a retrieval-augmented system with two main components: a reranker prioritizing useful historical data and an adapter aligning LLM outputs to user preferences.  Both components use a base model with multiple user-specific heads to balance shared knowledge and personalized behavior.", "section": "3 HYDRA: Model Factorization for Black-Box LLM Personalization"}, {"figure_path": "CKgNgKmHYp/figures/figures_19_1.jpg", "caption": "Figure 2: Overview of HYDRA. HYDRA follows a retrieval-augmented framework: (1) Firstly, we extend an original RAG to a two-stage retrieve-then-rerank workflow, where we rerank the most useful information from relevant user behavior records to capture user-specific preference (Section 3.2); (2) Secondly, augmented by the selected historical data, we train an adapter to align the output of black-box LLMs with personalized human preference (Section 3.3). Both the reranker and the adapter can be decomposed into a base model with multiple user-specific heads, resembling a hydra-like structure (Section 3.4). The base model maintains shared knowledge across users, while multiple personal heads capture user-specific preferences. represents the model decomposition for personalization.", "description": "This figure illustrates the HYDRA model architecture, showing its retrieval-augmented framework which uses a reranker to prioritize information from historical data, and an adapter to align black-box LLM outputs with personalized preferences.  Both components use a base model and multiple user-specific heads to capture shared and user-specific knowledge. The figure breaks down the process into three steps: retrieval, reranking/adapter training, and personalized inference.", "section": "3 HYDRA: Model Factorization for Black-Box LLM Personalization"}]