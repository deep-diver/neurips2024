[{"figure_path": "dYIqAZXQNV/tables/tables_6_1.jpg", "caption": "Table 1: Standard image datasets. CNN and QGCN model accuracies (mean \u00b1 S.D.).", "description": "This table presents the test accuracy results for CNN and QGCN models trained on three standard image datasets: MNIST, FashionMNIST, and CIFAR-10.  The results show that QGCN achieves comparable performance to CNN on these datasets, demonstrating its ability to generalize CNNs to image data.", "section": "4 Experiments"}, {"figure_path": "dYIqAZXQNV/tables/tables_6_2.jpg", "caption": "Table 2: Custom Graph Datasets. QGRN and SGCN Performance Comparison", "description": "This table compares the performance of QGRN and SGCN models on several custom graph datasets.  The datasets include binary and denary classification tasks based on simulated Navier-Stokes fluid flow, along with established graph datasets like AIDS and Letter.  For each dataset, the table shows the number of model parameters (k), floating-point operations (FLOPs), and test accuracy.  This provides a quantitative comparison of the two methods across different graph types and complexities.", "section": "4 Experiments"}, {"figure_path": "dYIqAZXQNV/tables/tables_7_1.jpg", "caption": "Table 3: Graph kernels benchmark datasets - I. Test Accuracy (%) across different GCNS", "description": "This table presents the test accuracy results of various Graph Convolutional Networks (GCNs) on four benchmark graph datasets: AIDS, Frankenstein, Mutag, and Proteins.  The models compared include QGRN, GCNConv, ChebConv, GraphConv, SGConv, GENConv, GeneralConv, GATv2Conv, and TransformerConv.  The table shows the mean test accuracy and standard deviation for each model on each dataset, allowing for a comparison of the performance of different GCN architectures on these common benchmark tasks.", "section": "4.3 Graph Classification: Generic Graph Datasets"}, {"figure_path": "dYIqAZXQNV/tables/tables_8_1.jpg", "caption": "Table 4: Graph kernels benchmark datasets - II. Test Accuracy (%) across different GCNs", "description": "This table presents a comparison of the performance of various Graph Convolutional Networks (GCNs) on several benchmark datasets from the Benchmark Data Sets for Graph Kernels collection.  The datasets represent various graph characteristics and complexities. The table shows the test accuracy achieved by each GCN model on each dataset, providing insights into their relative performance across different graph structures and properties.", "section": "4.3 Graph Classification: Generic Graph Datasets"}, {"figure_path": "dYIqAZXQNV/tables/tables_8_2.jpg", "caption": "Table 18: Homophilic node classification datasets. Test Accuracy (%) across different GCNs", "description": "This table presents the results of node classification experiments on homophilic datasets.  It compares the performance of several Graph Convolutional Network (GCN) models, including QGRN (the model proposed in the paper), against various benchmark datasets. The results are expressed as the test accuracy (percentage), which measures the percentage of correctly classified nodes in the test set for each model and dataset.  The table shows the mean and standard deviation of the test accuracy across multiple trials.", "section": "4.4 Node Classification"}, {"figure_path": "dYIqAZXQNV/tables/tables_9_1.jpg", "caption": "Table 6: EEG SAE test set performance. All values are presented as the mean\u00b1SEM over all subjects.", "description": "This table presents the results of a supervised autoencoder model applied to EEG data.  The model used QGRN and SGCN architectures to predict emotional valence (positive or negative) from EEG data. The table shows the mean and standard error of the mean (SEM) for three metrics across all subjects: Mean Squared Error (MSE) loss for the generative part of the model, cross-entropy (CE) loss for the supervised classification part, and Area Under the Curve (AUC) of the ROC curve. The results indicate that the QGRN-based model outperforms the SGCN-based model in all three metrics.", "section": "4.5 Supervised Autoencoder Model of Emotional States in EEG data"}, {"figure_path": "dYIqAZXQNV/tables/tables_12_1.jpg", "caption": "Table 1: Standard image datasets. CNN and QGCN model accuracies (mean \u00b1 S.D.)", "description": "This table presents a comparison of the test accuracy achieved by Convolutional Neural Networks (CNNs) and Quantized Graph Convolution Networks (QGCNs) on three standard image datasets: MNIST, Fashion-MNIST, and CIFAR-10.  The results show the mean and standard deviation of the test accuracy across multiple trials, demonstrating the equivalence in performance between the two models on this type of data.", "section": "4 Experiments"}, {"figure_path": "dYIqAZXQNV/tables/tables_13_1.jpg", "caption": "Table 1: Standard image datasets. CNN and QGCN model accuracies (mean \u00b1 S.D.).", "description": "This table presents the results of comparing the performance of Convolutional Neural Networks (CNNs) and Quantized Graph Convolutional Networks (QGCNs) on three standard image datasets: MNIST, Fashion-MNIST, and CIFAR-10.  The table shows the mean and standard deviation of the test accuracy for each model on each dataset.  The results demonstrate the nearly identical performance of CNNs and QGCNs on image data, supporting the claim that QGCNs are a generalization of CNNs.", "section": "4 Experiments"}, {"figure_path": "dYIqAZXQNV/tables/tables_17_1.jpg", "caption": "Table 8: Standard Datasets. CNN and QGCN model accuracies (mean \u00b1 S.D.) on standard datasets", "description": "This table presents the results of training CNN and QGCN models on different sized subsets of the MNIST, Fashion-MNIST, and CIFAR-10 datasets.  The purpose is to show the equivalence of CNN and QGCN models across various train-test split ratios, demonstrating consistent performance and mitigating dataset ceiling effects that could skew results when training on the full dataset.", "section": "F Standard Datasets: Full Results"}, {"figure_path": "dYIqAZXQNV/tables/tables_20_1.jpg", "caption": "Table 9: The table captures the different Re ranges we considered for the different custom datasets and the step sizes. Notice in the binary case that Re = 20-40 are grouped in laminar class and 100-120 into the turbulent flow class.", "description": "This table shows the range of Reynolds numbers (Re) used for generating the three custom Navier-Stokes datasets (NS-Binary, NS-Denary-1, and NS-Denary-2).  The Re range and step-size are specified for each dataset.  The binary classification dataset, NS-Binary, uses a laminar flow range (20-40) and a turbulent flow range (100-120). The denary datasets use a wider range of Re values with different step sizes.", "section": "4.2.1 Custom FEM Dataset"}, {"figure_path": "dYIqAZXQNV/tables/tables_20_2.jpg", "caption": "Table 10: Shown in the table are different custom dataset splits we have provided as part of this paper. The third column captures the training time period per Re from which train data were aggregated from the FEM time series solutions", "description": "This table presents different train-test splits used for the custom FEM datasets (NS-Binary, NS-Denary-1, NS-Denary-2) along with the corresponding training time periods in seconds.  It shows how the amount of training data affects the model's performance. The different splits provide variations in the bias-variance tradeoff during model training and evaluation. ", "section": "4.2.1 Custom FEM Dataset"}, {"figure_path": "dYIqAZXQNV/tables/tables_22_1.jpg", "caption": "Table 8: Standard Datasets. CNN and QGCN model accuracies (mean \u00b1 S.D.) on standard datasets", "description": "This table presents the results of training CNN and QGCN models on various subsets of three standard image datasets: MNIST, Fashion-MNIST, and CIFAR-10.  Different train-test splits are used (100:20, 1000:200, 10000:1000, and 60000:10000) to explore the impact of dataset size on model performance.  The table shows the mean and standard deviation of test accuracy for both CNN and QGCN models on each dataset and split.", "section": "F Standard Datasets: Full Results"}, {"figure_path": "dYIqAZXQNV/tables/tables_22_2.jpg", "caption": "Table 3: Graph kernels benchmark datasets - I. Test Accuracy (%) across different GCNs", "description": "This table presents a comparison of the test accuracy achieved by various Graph Convolutional Networks (GCNs) on four different graph kernel benchmark datasets: AIDS, Frankenstein, Mutag, and Proteins.  The results show the mean test accuracy and standard deviation for each GCN model on each dataset, allowing for a direct comparison of model performance across different datasets and GCN architectures.", "section": "4.3 Graph Classification: Generic Graph Datasets"}, {"figure_path": "dYIqAZXQNV/tables/tables_22_3.jpg", "caption": "Table 13: Graph kernels benchmark datasets - I. Model sizes (number of parameters)", "description": "This table presents a comparison of model sizes (number of parameters) across different Graph Convolutional Network (GCN) models for various graph kernel benchmark datasets. The datasets include AIDS, Frankenstein, Mutag, Mutagenicity, Proteins, and Proteins-Full.  The table helps illustrate the relative complexity of each model architecture.", "section": "4.2 Graph Classification: Datasets with Positional Descriptors"}, {"figure_path": "dYIqAZXQNV/tables/tables_23_1.jpg", "caption": "Table 14: Graph kernels benchmark datasets - I. Model sizes (number of parameters)", "description": "This table presents the number of parameters (model size) for different Graph Convolutional Network (GCN) models across six benchmark datasets from the Graph Kernels benchmark datasets. The datasets include Synthie, Letters (high, low, medium), Enzymes, and Coil-Del.  The table helps in comparing the model complexity of various GCN architectures, which is important for understanding their computational cost and potential performance differences.", "section": "4.3 Graph Classification: Generic Graph Datasets"}, {"figure_path": "dYIqAZXQNV/tables/tables_23_2.jpg", "caption": "Table 15: Graph kernels benchmark datasets - I. Google TPU Inference latency. Wall clock (in ms)", "description": "This table presents the Google TPU inference latency, measured in milliseconds, for various graph convolutional neural network (GCN) models on the AIDS, Frankenstein, Mutag, and Proteins datasets from the Graph Kernels benchmark.  The table shows the mean and standard deviation of the latency for each model across multiple trials.  It provides insights into the computational efficiency of different GCN architectures.", "section": "4.2 Graph Classification: Datasets with Positional Descriptors"}, {"figure_path": "dYIqAZXQNV/tables/tables_23_3.jpg", "caption": "Table 14: Graph kernels benchmark datasets - I. Model sizes (number of parameters)", "description": "This table presents the number of parameters (model size) for different Graph Convolutional Network (GCN) models on four graph kernel benchmark datasets: Synthie, Letters (high), Letters (low), Letters (medium), Enzymes, and Coil-Del.  It provides a comparison of model complexity across various GCN architectures.", "section": "4.3 Graph Classification: Generic Graph Datasets"}, {"figure_path": "dYIqAZXQNV/tables/tables_23_4.jpg", "caption": "Table 12: Graph kernels benchmark datasets - III. Test Accuracy (%) across different GCNs", "description": "This table compares the performance of QGRN against other state-of-the-art Graph Convolutional Networks (GCNs) on several benchmark datasets from the Graph Kernels benchmark collection.  The datasets represent various graph classification tasks with different characteristics, including binary and multi-class problems.  The table shows the test accuracy of each model, highlighting the comparative performance of QGRN.", "section": "4.3 Graph Classification: Generic Graph Datasets"}, {"figure_path": "dYIqAZXQNV/tables/tables_24_1.jpg", "caption": "Table 18: Homophilic node classification datasets. Test Accuracy (%) across different GCNs", "description": "This table presents the test accuracy results for various graph convolutional networks (GCNs) on homophilic node classification datasets.  Homophilic datasets are those where nodes with similar features tend to be connected. The table compares the performance of QGRN against other GCN models such as GraphConv, GENConv, GeneralConv, and EGConv. The results show the average test accuracy and standard deviation for each model on each dataset.", "section": "4.4 Node Classification"}, {"figure_path": "dYIqAZXQNV/tables/tables_24_2.jpg", "caption": "Table 19: Heterophilic node classification datasets. Test Accuracy (%) across different GCNs", "description": "This table presents the test accuracy results for various graph convolutional network (GCN) models on heterophilic node classification datasets.  Heterophilic graphs are characterized by nodes having dissimilar neighbors. The table compares the performance of QGRN against other state-of-the-art GCN models like GraphConv, GENConv, GeneralConv, and EGConv on two specific heterophilic datasets: Chameleon and Squirrel. The results show the mean test accuracy and standard deviation for each model on each dataset.", "section": "4.3 Graph Classification: Generic Graph Datasets"}, {"figure_path": "dYIqAZXQNV/tables/tables_24_3.jpg", "caption": "Table 2: Custom Graph Datasets. QGRN and SGCN Performance Comparison", "description": "This table presents a comparison of the performance of the Quantized Graph Residual Network (QGRN) and the Spatial Graph Convolutional Network (SGCN) models on several custom graph datasets.  The table includes the number of parameters (k) and FLOPS (millions) for each model, as well as the test accuracy (%) achieved on each dataset.  The datasets were created by simulating nonlinear dynamics and include several variants with differing complexities.", "section": "4 Experiments"}, {"figure_path": "dYIqAZXQNV/tables/tables_25_1.jpg", "caption": "Table 21: IAM Graph Database Repository. Comparison of QGRN performance to k-NN classifier", "description": "This table compares the average test accuracy of the QGRN model and a k-NN classifier on several datasets from the IAM Graph Database Repository.  The datasets include variations of letter recognition tasks (with varying levels of distortion) and chemical compound and protein classification.", "section": "J Graph kernels benchmark datasets: additional results"}, {"figure_path": "dYIqAZXQNV/tables/tables_25_2.jpg", "caption": "Table 22: Deeper QGCN and QGRN networks. Sample results illustrating impact of deeper network on model performance", "description": "This table shows the results of training deeper QGCN and QGRN models on two datasets: AIDS and Letters (high).  The AIDS dataset is a smaller, simpler binary classification problem. Letters (high) is a more complex task with 15 classes. The table shows the model depth, the model size (in thousands of parameters), and the mean test accuracy for both QGCN and QGRN models at each depth.", "section": "O Training Deeper QGRNAs"}, {"figure_path": "dYIqAZXQNV/tables/tables_26_1.jpg", "caption": "Table 23: Deeper satisficing mapping (SM) and QuantNet networks. Sample results illustrating impact of deeper network on model performance", "description": "This table presents a comparison of the performance of deeper networks using two different quantization methods: satisficing mapping (SM) and QuantNet.  It shows the model size and mean test accuracy for different depths (3, 6, 9, 12, and 18 layers) on two datasets: AIDS (a binary classification task) and Letters (high) (a multi-class classification task). The results illustrate how the choice of quantization method and network depth impact model performance.", "section": "P Performance impact of quantization"}, {"figure_path": "dYIqAZXQNV/tables/tables_26_2.jpg", "caption": "Table 24: 3-layer QGRN model analysis. Sample results for QGRN model trained with and without positional descriptors.", "description": "This table compares the average test accuracy of a 3-layer QGRN model trained on several datasets, with and without using positional descriptors as input features.  The results show the impact of including positional information on the model's performance for different datasets.", "section": "P Performance impact of quantization"}, {"figure_path": "dYIqAZXQNV/tables/tables_27_1.jpg", "caption": "Table 25: Number of bins - hyper-parameter search. Hyper-parameter search of optimal number of bins/subkernels for QGRN", "description": "This table presents the results of a hyperparameter search to find the optimal number of bins (or subkernels) for the QGRN model.  The search was conducted on five different graph datasets from the TUDatasets benchmark (AIDS, Enzymes, Coil-Del, Letters (high), and Proteins). For each dataset, the average test accuracy is shown for different numbers of bins (2, 3, 5, 7, and 9). The table helps to illustrate the impact of the number of bins on model performance and suggests an optimal range for this hyperparameter.", "section": "Q Empirically determining quantization bins"}, {"figure_path": "dYIqAZXQNV/tables/tables_28_1.jpg", "caption": "Table 8: Standard Datasets. CNN and QGCN model accuracies (mean \u00b1 S.D.) on standard datasets", "description": "This table presents a comparison of the test accuracy achieved by CNN and QGCN models on various standard image datasets (MNIST, Fashion-MNIST, CIFAR-10).  The results are shown for different train-test split ratios to demonstrate the model's performance across various data sizes and bias-variance trade-offs.", "section": "F Standard Datasets: Full Results"}]