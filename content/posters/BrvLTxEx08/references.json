{"references": [{"fullname_first_author": "C. Daskalakis", "paper_title": "Independent policy gradient methods for competitive reinforcement learning", "publication_date": "2020-12-01", "reason": "This paper introduces a novel algorithm for competitive reinforcement learning with provable guarantees, which directly relates to the core topic of the current paper."}, {"fullname_first_author": "C. Daskalakis", "paper_title": "Last-iterate convergence: Zero-sum games and constrained min-max optimization", "publication_date": "2019-01-10", "reason": "This paper provides theoretical foundations for min-max optimization, which is crucial for the theoretical analysis in the current paper about adversarial team Markov games."}, {"fullname_first_author": "A. Agarwal", "paper_title": "On the theory of policy gradient methods: Optimality, approximation, and distribution shift", "publication_date": "2021-09-01", "reason": "This paper offers a comprehensive theoretical analysis of policy gradient methods, providing insights essential for understanding the learning dynamics within multi-agent settings."}, {"fullname_first_author": "O. Devolder", "paper_title": "First-order methods of smooth convex optimization with inexact oracle", "publication_date": "2014-01-01", "reason": "This paper introduces techniques for handling inexact gradient oracles, which is essential for the current paper's learning algorithm due to the bandit feedback setting."}, {"fullname_first_author": "T. Lin", "paper_title": "On gradient descent ascent for nonconvex-concave minimax problems", "publication_date": "2020-01-01", "reason": "This paper provides insights on handling nonconvex-concave minimax optimization, which is relevant to the current paper's focus on nonconvex-hidden-concave min-max optimization within adversarial team Markov games."}]}