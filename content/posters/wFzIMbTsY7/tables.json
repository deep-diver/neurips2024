[{"figure_path": "wFzIMbTsY7/tables/tables_3_1.jpg", "caption": "Table 1: Mamba vs. Transformer on D4RL datasets.", "description": "This table compares the performance of Mamba and Transformer models on several D4RL datasets.  It shows the effectiveness (average return) and efficiency (training time in hours) for both models across different datasets and environment variations (Med-Expert, Medium, Med-Replay).  The results highlight that while Transformer models generally achieve higher effectiveness, Mamba models demonstrate significantly improved efficiency, indicating a trade-off between performance and computational cost.", "section": "4.1 Mamba vs. Transformer in RL tasks"}, {"figure_path": "wFzIMbTsY7/tables/tables_7_1.jpg", "caption": "Table 1: Mamba vs. Transformer on D4RL datasets.", "description": "This table compares the performance of Mamba and Transformer models on several D4RL datasets.  It shows the effectiveness (average return) and efficiency (training time in hours) of each model across different environments and dataset variations (Med-Expert, Med, Med-Replay).  The results demonstrate that while Transformer models generally achieve higher effectiveness, Mamba models offer significantly improved efficiency.", "section": "4.1 Mamba vs. Transformer in RL tasks"}, {"figure_path": "wFzIMbTsY7/tables/tables_12_1.jpg", "caption": "Table 1: Mamba vs. Transformer on D4RL datasets.", "description": "This table compares the performance of Mamba and Transformer models on various D4RL datasets.  It shows the effectiveness (average return) and efficiency (training time in hours) of both models across different datasets and difficulty levels (e.g., Med-Expert, Medium, Med-Replay). The results indicate that while Transformers show slightly better effectiveness, Mamba offers significantly improved efficiency, especially for complex datasets.", "section": "4.1 Mamba vs. Transformer in RL tasks"}, {"figure_path": "wFzIMbTsY7/tables/tables_13_1.jpg", "caption": "Table 1: Mamba vs. Transformer on D4RL datasets.", "description": "This table compares the performance of Mamba and Transformer models on several D4RL datasets, measuring both effectiveness (the average return achieved) and efficiency (the training time in hours).  The results show that while the Transformer model generally achieves higher returns, the Mamba model offers significantly faster training times.", "section": "4.1 Mamba vs. Transformer in RL tasks"}, {"figure_path": "wFzIMbTsY7/tables/tables_14_1.jpg", "caption": "Table 1: Mamba vs. Transformer on D4RL datasets.", "description": "This table compares the performance of Mamba and Transformer models on several D4RL datasets.  It shows both effectiveness (average return) and efficiency (training time in hours) for each model on different datasets and reward settings (Medium, Med-Expert, Med-Replay). The results indicate that while Transformer models generally exhibit higher effectiveness, Mamba models offer significantly better efficiency, particularly when considering training time.", "section": "4.1 Mamba vs. Transformer in RL tasks"}]