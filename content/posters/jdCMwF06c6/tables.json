[{"figure_path": "jdCMwF06c6/tables/tables_5_1.jpg", "caption": "Table 1: Detection performance against task-agnostic backdoor attacks. FP = False Positive, FN = False Negative, ACC = Average Detection Accuracy. Average Time is tested on a single RTX-4090 with the same batch size 32 for different methods.", "description": "This table presents the performance comparison of LT-Defense and LMSanitator on detecting task-agnostic backdoor attacks across various models.  It shows the false positives (FP), false negatives (FN), accuracy (ACC), and average time taken for both methods.  The results are broken down for different models (ROBERTa-base, ROBERTa-large, BERT-base-cased, BERT-large-cased, ALBERT-base, ALBERT-large, OPT-125m, OPT-350m) and different attack methods (POR, BTOP, NeuBA).", "section": "5.2 Overall Comparison"}, {"figure_path": "jdCMwF06c6/tables/tables_5_2.jpg", "caption": "Table 2: Detection performance against task-related backdoor attacks. Average Time (minutes) is tested on a single RTX-4090 with the batch size of 32 (8 for OPT-350m and OPT-1.3b).", "description": "This table presents the results of the LT-Defense model's performance in detecting task-related backdoor attacks. It shows the false positives (FP), false negatives (FN), accuracy (ACC), and average time taken for detection across different models (ROBERTa-large, BERT-large-cased, OPT-350m) and datasets (WikiText, BookCorpus, SST-2, AG News).  The table is split into subsections based on the type of task-related attack used (BTOP generation, PoisonPrompt, AutoPoison refusal, AutoPoison insertion). Each subsection lists the FP, FN, ACC, and Time for each model/dataset combination.", "section": "5.2 Overall Comparison"}, {"figure_path": "jdCMwF06c6/tables/tables_6_1.jpg", "caption": "Table 1: Detection performance against task-agnostic backdoor attacks. FP = False Positive, FN = False Negative, ACC = Average Detection Accuracy. Average Time is tested on a single RTX-4090 with the same batch size 32 for different methods.", "description": "This table presents the performance comparison of LT-Defense against three different task-agnostic backdoor attack methods (POR, BTOP, and NeuBA) using four different language models (ROBERTa-base, ROBERTa-large, BERT-base-cased, and BERT-large-cased).  For each model and attack method, the table shows the false positive (FP) rate, false negative (FN) rate, average detection accuracy (ACC), and average time taken for detection.  The results demonstrate LT-Defense's superior accuracy and efficiency compared to the baseline method (LMSanitator).", "section": "5.2 Overall Comparison"}, {"figure_path": "jdCMwF06c6/tables/tables_6_2.jpg", "caption": "Table 2: Detection performance against task-related backdoor attacks. Average Time (minutes) is tested on a single RTX-4090 with the batch size of 32 (8 for OPT-350m and OPT-1.3b).", "description": "This table presents the results of the LT-Defense model's performance against various task-related backdoor attacks.  It shows the False Positive (FP), False Negative (FN), Accuracy (ACC), and average time taken for detection across several different models and datasets. The table highlights the effectiveness of LT-Defense in detecting backdoors in various tasks like text generation, and indicates the computational efficiency.", "section": "5.2 Overall Comparison"}, {"figure_path": "jdCMwF06c6/tables/tables_13_1.jpg", "caption": "Table 1: Detection performance against task-agnostic backdoor attacks. FP = False Positive, FN = False Negative, ACC = Average Detection Accuracy. Average Time is tested on a single RTX-4090 with the same batch size 32 for different methods.", "description": "This table presents the performance comparison of LT-Defense and the state-of-the-art method LMSanitator for task-agnostic backdoor detection.  It shows the False Positives (FP), False Negatives (FN), Average Detection Accuracy (ACC), and Average Time taken for different models (ROBERTa-base, ROBERTa-large, BERT-base-cased, BERT-large-cased, ALBERT-base, ALBERT-large, OPT-125m, OPT-350m) and attack methods (POR, BTOP, NeuBA). The results demonstrate the superior accuracy and efficiency of LT-Defense compared to LMSanitator.", "section": "5.2 Overall Comparison"}, {"figure_path": "jdCMwF06c6/tables/tables_14_1.jpg", "caption": "Table 6: LT-Defense under real-world scenarios.", "description": "This table presents the results of applying LT-Defense to various pre-trained language models obtained from HuggingFace.  Each model is labeled as either \"Clean\" or \"Poisoned\", reflecting whether LT-Defense detected a backdoor. The Head-Feature Rate (HFR) and the URL for each model are also included. The purpose of this table is to demonstrate the performance of LT-Defense in a real-world setting, where the models' origins and backdoor status are not fully known.", "section": "5.3 Extended Analysis"}]