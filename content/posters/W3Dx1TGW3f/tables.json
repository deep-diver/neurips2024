[{"figure_path": "W3Dx1TGW3f/tables/tables_2_1.jpg", "caption": "Table 1: Summary of Related Works in Bilevel Reinforcement Learning.", "description": "The table summarizes and compares several existing works in bilevel reinforcement learning.  It highlights key differences across these papers, focusing on whether the leader's algorithm is agnostic to the follower's algorithm, whether the updates are deterministic or stochastic, the iteration complexity for the upper and lower levels, and the specific algorithm used. The table also shows whether the methods considered multiple followers, contextual information, and side information.", "section": "1 Introduction"}, {"figure_path": "W3Dx1TGW3f/tables/tables_6_1.jpg", "caption": "Table 1: Summary of Related Works in Bilevel Reinforcement Learning.", "description": "This table compares the key characteristics of several related works in bilevel reinforcement learning.  It highlights differences in the use of context, side information, whether the leader's control over the follower is agnostic or deterministic, the type of hypergradient updates (deterministic or stochastic), and the time complexity of the algorithm's iterations at both the upper and lower levels. The table aids in understanding the novel contributions of the proposed HPGD algorithm in the paper by showing how it improves upon or differs from existing approaches.", "section": "1 Introduction"}, {"figure_path": "W3Dx1TGW3f/tables/tables_8_1.jpg", "caption": "Table 3: Performance over hyperparameters \u03b2 and \u03bb for the Four Rooms Problem averaged over 10 random seeds with standard errors. Algorithms perform on-par for most hyperparameters while HPGD outperforms others in few. AMD enjoys low variance due to the non-stochastic gradient updates while Zero-Order suffers from the most variation.", "description": "This table presents the performance of three different algorithms (HPGD, AMD, and Zero-Order) on the Four Rooms problem for various hyperparameter settings (\u03bb and \u03b2).  The results are averages over 10 random seeds, showing mean performance and standard errors. The table highlights that HPGD generally performs comparably to the other algorithms, but shows superior performance in a few instances, while also exhibiting more variance than AMD.", "section": "Numerical Experiments"}, {"figure_path": "W3Dx1TGW3f/tables/tables_21_1.jpg", "caption": "Table 1: Summary of Related Works in Bilevel Reinforcement Learning.", "description": "This table compares the key characteristics of several related works in bilevel reinforcement learning.  It highlights the presence or absence of key features, such as contextual information, multiple followers, side information, whether the leader controls the followers' training, whether algorithms are deterministic or stochastic, and the complexity of iterations for both upper and lower levels.  This allows for a clear comparison of the proposed HPGD algorithm against existing approaches.", "section": "1 Introduction"}, {"figure_path": "W3Dx1TGW3f/tables/tables_52_1.jpg", "caption": "Table 1: Summary of Related Works in Bilevel Reinforcement Learning.", "description": "This table compares the key characteristics of several related works in bilevel reinforcement learning.  It highlights the differences in the use of context, whether the leader's algorithm is agnostic to the follower's or not, the type of lower and upper level updates used (deterministic or stochastic), the number of iterations required at each level, and the specific algorithm employed.  The table helps clarify the novel contributions of the proposed HPGD algorithm by showcasing its differences from existing methods.", "section": "1 Introduction"}]