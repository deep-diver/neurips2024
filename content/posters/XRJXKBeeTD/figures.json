[{"figure_path": "XRJXKBeeTD/figures/figures_1_1.jpg", "caption": "FIGURE 1. An illustration of fine-tuning (FT) a pre-trained model. Typically, FT is performed with the available downstream data at hand, yet in deployment, the model may encounter some other classes, for example, the ones it had been pre-trained upon. Ideally, the FT model should recognize all classes well.", "description": "This figure illustrates the process of fine-tuning a pre-trained model.  The left panel shows the pre-training phase using a dataset with multiple classes (dog, eagle, truck, cup). The middle panel depicts the fine-tuning phase, where the pre-trained model is further trained on a smaller subset of classes from the pre-training dataset (dog, eagle, truck).  The right panel shows the deployment phase where the model is used on a dataset including both the classes it was fine-tuned on and classes that were in the pre-training data but not included in the fine-tuning phase (cup). Ideally, the fine-tuned model should be able to recognize all the classes from the pre-training dataset.", "section": "1 Introduction"}, {"figure_path": "XRJXKBeeTD/figures/figures_1_2.jpg", "caption": "FIGURE 2. Fine-tuning (*) + post-processing calibration with a bias factor (--) can outperform the SOTA solution (*) [49].", "description": "This figure shows the absent class data accuracy plotted against the fine-tuning class data accuracy.  The black star represents the state-of-the-art (SOTA) result from a previous study (Tu et al. 2023). The red line shows the results of fine-tuning the model with a post-processing calibration applied, demonstrating that calibration significantly improves the absent class accuracy, surpassing the previous SOTA.", "section": "4 A Systematic Study of Fine-Tuning (FT)"}, {"figure_path": "XRJXKBeeTD/figures/figures_4_1.jpg", "caption": "FIGURE 3. Accuracy gain after fine-tuning. We consider the neural network (NN) classifier with the FC layer (section 3) and the NCM classifier using only features (Equation 2). We show the average accuracy gain on fine-tuning classes (Accs/y) and absent classes (Accu/y). While the NN classifier suffers drops in Accu/y, the NCM classifier enjoys a consistent gain, suggesting the holistic improvement of features after fine-tuning.", "description": "This figure compares the accuracy gain on fine-tuning and absent classes after fine-tuning using two different classifiers: a neural network (NN) classifier and a Nearest Class Mean (NCM) classifier. The NN classifier shows a decrease in accuracy for absent classes, while the NCM classifier shows an increase, indicating an overall improvement in feature extraction for all classes after fine-tuning. This suggests that fine-tuning with a subset of classes holistically improves the feature extractor for the downstream domain.", "section": "4 A Systematic Study of Fine-Tuning (FT)"}, {"figure_path": "XRJXKBeeTD/figures/figures_5_1.jpg", "caption": "FIGURE 3. Accuracy gain after fine-tuning. We consider the neural network (NN) classifier with the FC layer (section 3) and the NCM classifier using only features (Equation 2). We show the average accuracy gain on fine-tuning classes (Accs/y) and absent classes (Accu/y). While the NN classifier suffers drops in Accu/y, the NCM classifier enjoys a consistent gain, suggesting the holistic improvement of features after fine-tuning.", "description": "This figure compares the accuracy gain (or loss) after fine-tuning for both a neural network classifier and a Nearest Class Mean (NCM) classifier.  The neural network uses the full architecture, including the fully connected layer, while the NCM classifier only uses the extracted features.  The results show that while the neural network suffers an accuracy drop in the classes not seen during fine-tuning (absent classes), the NCM classifier shows a consistent gain across all classes. This highlights the improvement of features in the fine-tuned model, despite the loss of accuracy in the standard classifier.", "section": "4.2 Is the fine-tuned feature extractor damaged?"}, {"figure_path": "XRJXKBeeTD/figures/figures_5_2.jpg", "caption": "FIGURE 21. Accs/y at the x-axis and Accu/y at the y-axis by varying the calibration factor \u03b3 for ImageNet-Variants.", "description": "This figure shows the relationship between the accuracy of classifying fine-tuning classes (Accs/y) and the accuracy of classifying absent classes (Accu/y) on the ImageNet-Variants dataset as the calibration factor \u03b3 is varied.  The graph displays curves for the pre-trained model, the fine-tuned model, the fine-tuned model with post-processing calibration (Fine-tuning + \u03b3), the state-of-the-art model from the paper by Tu et al. [49] , and the state-of-the-art model with calibration (Tu et al. 2023 + \u03b3). The figure illustrates that post-processing calibration can significantly improve the accuracy on absent classes without significantly reducing accuracy on fine-tuning classes.", "section": "4 Experimental Results"}, {"figure_path": "XRJXKBeeTD/figures/figures_5_3.jpg", "caption": "FIGURE 3. Accuracy gain after fine-tuning. We consider the neural network (NN) classifier with the FC layer (section 3) and the NCM classifier using only features (Equation 2). We show the average accuracy gain on fine-tuning classes (Accs/y) and absent classes (Accu/y). While the NN classifier suffers drops in Accu/y, the NCM classifier enjoys a consistent gain, suggesting the holistic improvement of features after fine-tuning.", "description": "This figure compares the accuracy gain of neural network (NN) and nearest class mean (NCM) classifiers after fine-tuning.  The NN classifier shows accuracy *drops* for absent classes, while the NCM classifier shows accuracy *gains* for absent classes.  This indicates that fine-tuning improves feature representation for all classes but the NN classifier is unable to fully leverage the improved features due to a calibration issue.", "section": "4 A Systematic Study of Fine-Tuning (FT)"}, {"figure_path": "XRJXKBeeTD/figures/figures_6_1.jpg", "caption": "FIGURE 21. Accs/y at the x-axis and Accu/y at the y-axis) by varying the calibration factor y for ImageNet-Variants.", "description": "This figure shows the absent class accuracy (Accu/y) plotted against the fine-tuning class accuracy (Accs/y) for the ImageNet-R dataset with 50% of classes used for fine-tuning.  The different colored lines represent different methods: the pre-trained model (green star), the fine-tuned model (red star), the state-of-the-art method from Tu et al. 2023 (black star), and the calibrated versions of each using the bias factor \u03b3 (colored lines). The plot illustrates the impact of calibration in restoring the accuracy of the model on absent classes (as Accu/y increases with the calibration).", "section": "4.2 Is the fine-tuned feature extractor damaged?"}, {"figure_path": "XRJXKBeeTD/figures/figures_7_1.jpg", "caption": "FIGURE 8. Accuracy gain after fine-tuning. We consider the neural network (NN) classifier with the FC layer (section 3) and the NCM classifier using only features (Equation 2). We show the average accuracy gain on fine-tuning classes (Accs/y) and absent classes (Accu/y). While the NN classifier suffers drops in Accu/y, the NCM classifier enjoys a consistent gain, suggesting the holistic improvement of features after fine-tuning.", "description": "This figure shows the accuracy gain (difference between the accuracy after fine-tuning and the accuracy of the pre-trained model) of both NN and NCM classifiers for fine-tuning and absent classes after fine-tuning on three different datasets: ImageNet-{R,S}, VTAB, and Office-Home.  The NN classifier shows decreased accuracy for absent classes, indicating negative transfer, while the NCM classifier shows improved accuracy for absent classes, suggesting holistic feature improvement by fine-tuning. This highlights that the issue with absent classes is not feature degradation but a different problem (logit scale discrepancy).", "section": "4.2 Is the fine-tuned feature extractor damaged?"}, {"figure_path": "XRJXKBeeTD/figures/figures_8_1.jpg", "caption": "FIGURE 9. Different optimizers and hyperparameters. We use the Office-Home and report the AUSUC. The AUSUC of the pre-trained model is ~ 0.5. Fine-tuning with SGD shows remarkable robustness to different learning rates and weight decay. Advanced optimizers necessitate more careful hyperparameter selection. Nevertheless, they perform similarly to SGD under small learning rates and weight decay.", "description": "This figure shows the AUSUC (Area Under the Seen-Unseen Curve) for different optimizers (SGD, Adam, AdaBelief, Adadelta, AdaGrad, RMSprop) and hyperparameter settings (learning rates and weight decay) on the Office-Home dataset.  It demonstrates the robustness of the SGD optimizer to variations in hyperparameters, while showing the increased sensitivity of other, more advanced optimizers, especially when hyperparameters are not carefully tuned. Even with the more advanced optimizers, comparable performance to SGD can be achieved with smaller learning rates and weight decay.", "section": "6 Ablation Study and Additional Analysis"}, {"figure_path": "XRJXKBeeTD/figures/figures_8_2.jpg", "caption": "FIGURE 10. Classifier update direction similarity within fine-tuning (left) and absent (right) classes for ImageNet-S. The update directions are highly similar within absent classes, thus preserving the inter-class relationships among absent classes.", "description": "This figure visualizes the cosine similarity of the changes in classifier weights (the difference between weights after and before fine-tuning) for both fine-tuning and absent classes in ImageNet-S.  The high similarity of update directions within the absent classes shows that the relationships between these classes are preserved during fine-tuning, despite the absence of absent class data during the fine-tuning process.", "section": "Absent Features and linear classifier Alignment in fine-tuning"}, {"figure_path": "XRJXKBeeTD/figures/figures_9_1.jpg", "caption": "FIGURE 12. We analyze the ground-truth (GT) logits compared with the largest non-GT absent logits in ImageNet-S. While both logits decrease during the training, the consistent relative difference between them signifies a stable alignment between the features and the linear classifier.", "description": "This figure shows two plots. The left plot is a scatter plot visualizing the movement of features for fine-tuning and absent classes before and after fine-tuning. The right plot is a line graph showing the average logits for ground-truth absent classes and the largest non-ground-truth absent class logits over training epochs. Both plots demonstrate that the fine-tuning process maintains a stable relationship between features and linear classifiers, even for absent classes.", "section": "4.2 Is the fine-tuned feature extractor damaged?"}, {"figure_path": "XRJXKBeeTD/figures/figures_17_1.jpg", "caption": "FIGURE 1. An illustration of fine-tuning (FT) a pre-trained model. Typically, FT is performed with the available downstream data at hand, yet in deployment, the model may encounter some other classes, for example, the ones it had been pre-trained upon. Ideally, the FT model should recognize all classes well.", "description": "This figure illustrates the concept of fine-tuning a pre-trained model.  The pre-trained model is initially trained on a large dataset (e.g., ImageNet), encompassing a wide range of classes.  Fine-tuning then adapts this model to a specific downstream task using a smaller dataset that only includes a subset of the original classes. The figure highlights a crucial point: while the fine-tuned model excels at the classes present in the downstream dataset, its performance on unseen classes (those not part of the downstream dataset but present in the initial pre-training dataset) can significantly decrease. This demonstrates the risk of losing valuable knowledge previously learned during pre-training when fine-tuning is not carefully calibrated.", "section": "1 Introduction"}, {"figure_path": "XRJXKBeeTD/figures/figures_17_2.jpg", "caption": "FIGURE 3. Accuracy gain after fine-tuning. We consider the neural network (NN) classifier with the FC layer (section 3) and the NCM classifier using only features (Equation 2). We show the average accuracy gain on fine-tuning classes (Accs/y) and absent classes (Accu/y). While the NN classifier suffers drops in Accu/y, the NCM classifier enjoys a consistent gain, suggesting the holistic improvement of features after fine-tuning.", "description": "This figure compares the accuracy gain (difference between fine-tuned and pre-trained model accuracy) for fine-tuning classes and absent classes using two classifiers: a neural network classifier (NN) and a Nearest Class Mean classifier (NCM).  The NN classifier shows a decrease in accuracy for absent classes after fine-tuning, while the NCM classifier shows improvement, indicating that feature extraction is not degraded, and potentially even enhanced, by fine-tuning.", "section": "4 A Systematic Study of Fine-Tuning (FT)"}, {"figure_path": "XRJXKBeeTD/figures/figures_17_3.jpg", "caption": "FIGURE 1. An illustration of fine-tuning (FT) a pre-trained model. Typically, FT is performed with the available downstream data at hand, yet in deployment, the model may encounter some other classes, for example, the ones it had been pre-trained upon. Ideally, the FT model should recognize all classes well.", "description": "This figure illustrates the process of fine-tuning a pre-trained model.  The pre-trained model is initially trained on a large dataset (e.g., ImageNet). This model is then fine-tuned on a smaller, more specific dataset for a downstream task.  The key point highlighted is that, during deployment, the fine-tuned model might encounter new classes (absent classes) not present in the fine-tuning dataset. The ideal outcome is that the fine-tuned model performs well on both the fine-tuning classes and the unseen classes.", "section": "1 Introduction"}, {"figure_path": "XRJXKBeeTD/figures/figures_17_4.jpg", "caption": "FIGURE 13. (A) shows the t-SNE of the class mean features for 65 classes in the Art domain with their corresponding class names. (B) shows the fine-tuning and absent classes split for different fine-tuning class sizes.", "description": "This figure visualizes the feature distribution of classes using t-SNE in the Art domain of the Office-Home dataset and how the classes are split into fine-tuning and absent classes for different fine-tuning class sizes.  Panel A shows the t-SNE visualization of the class mean features. Panel B illustrates the different splits for various fine-tuning sizes, where red points represent fine-tuning classes and blue points represent absent classes.", "section": "A.1 Main Investigation"}, {"figure_path": "XRJXKBeeTD/figures/figures_18_1.jpg", "caption": "FIGURE 15. Visualization of pre-training and target domain data in the toy example, with distinct colors indicating different classes. The symbol \u25a1 represents data from the pre-training phase, while \u25cb denotes those of the target domain (only blue and cyan are fine-tuning during fine-tuning).", "description": "This figure shows the visualization of pre-training data and target domain data for a toy example with four classes. The pre-training data is represented by squares (\u25a1) and target domain data is represented by circles (\u25cb).  The colors represent different classes, with blue and cyan representing the fine-tuning classes during fine-tuning. The figure helps illustrate the effect of fine-tuning on the feature representation of the data in different domains.", "section": "A.3 Toy Example"}, {"figure_path": "XRJXKBeeTD/figures/figures_19_1.jpg", "caption": "FIGURE 3. Accuracy gain after fine-tuning. We consider the neural network (NN) classifier with the FC layer (section 3) and the NCM classifier using only features (Equation 2). We show the average accuracy gain on fine-tuning classes (Accs/y) and absent classes (Accu/y). While the NN classifier suffers drops in Accu/y, the NCM classifier enjoys a consistent gain, suggesting the holistic improvement of features after fine-tuning.", "description": "This figure compares the accuracy gain of neural network (NN) classifier and Nearest Class Mean (NCM) classifier after fine-tuning. The results show that the NN classifier's accuracy on absent classes decreases while NCM classifier's accuracy increases. This suggests that the features extracted by the fine-tuned model are improved holistically, even for those classes not included in the fine-tuning process.", "section": "4.2 Is the fine-tuned feature extractor damaged?"}, {"figure_path": "XRJXKBeeTD/figures/figures_19_2.jpg", "caption": "FIGURE 17. Average Logit Gap (ALG) calibration method: the calibration factor \u03b3 is calculated based on the difference of non-GT logits between fine-tuning and absent groups.", "description": "This figure illustrates the Average Logit Gap (ALG) method for calibrating the logits of a fine-tuned model.  It shows how the calibration factor (\u03b3) is calculated using the difference between the average non-ground-truth (non-GT) logits of the fine-tuning classes and the average non-GT logits of the absent classes in the training data. This difference is used to adjust the logits of the absent classes, aiming to bring their magnitude closer to the logits of the fine-tuning classes.", "section": "5 Post-Processing Calibration for the Rescue"}, {"figure_path": "XRJXKBeeTD/figures/figures_20_1.jpg", "caption": "FIGURE 18. The illustration of the Pseudo Cross-Validation (PCV) method for estimating the calibration factor \u03b3.", "description": "This figure illustrates the Pseudo Cross-Validation (PCV) method used in the paper to estimate the calibration factor gamma (\u03b3).  The method involves repeatedly splitting the training data into pseudo-fine-tuning and pseudo-absent sets. A fine-tuned model is trained on each pseudo-fine-tuning set, and its performance is evaluated on the corresponding pseudo-validation set. The average of the resulting performance metrics is used to select the final value of \u03b3.", "section": "4.2 Is the fine-tuned feature extractor damaged?"}, {"figure_path": "XRJXKBeeTD/figures/figures_20_2.jpg", "caption": "FIGURE 19. t-SNE (ImageNet-R). The FT extractor  feT  does not create an artificial margin between fine-tuning and absent classes.", "description": "This figure shows the t-SNE visualization of ImageNet-R dataset's features extracted by the fine-tuned model. The visualization demonstrates that the fine-tuned feature extractor does not create a clear separation between the fine-tuning and absent classes in the feature space, indicating that the model does not simply learn to discriminate between them by creating a large margin, but rather uses a more nuanced and holistic representation of the data.", "section": "4.2 Is the fine-tuned feature extractor damaged?"}, {"figure_path": "XRJXKBeeTD/figures/figures_21_1.jpg", "caption": "FIGURE 20. L2 norm of classifier weights for fine-tuning and absent classes during fine-tuning. This illustrates a significant increase in weight magnitude for fine-tuning classes compared to absent, potentially resulting in fine-tuning's biased logits towards fine-tuning classes.", "description": "This figure shows the L2 norm of classifier weights for fine-tuning and absent classes during fine-tuning.  The plots illustrate that the magnitude of the weights for fine-tuning classes increases significantly more than that of absent classes. This suggests that the fine-tuning process disproportionately boosts the importance of fine-tuning classes, leading to the observed bias in logit predictions towards those classes.", "section": "C.2 Biased Logits Towards Fine-tuning Classes"}, {"figure_path": "XRJXKBeeTD/figures/figures_24_1.jpg", "caption": "FIGURE 21. Accs/y at the x-axis and Accu/y at the y-axis) by varying the calibration factor \u03b3 for ImageNet-Variants.", "description": "This figure shows the accuracy of classifying fine-tuning classes (Accs/y) and absent classes (Accu/y) for different calibration factors (\u03b3) on ImageNet-R and ImageNet-S.  The x-axis represents the accuracy on fine-tuning classes, and the y-axis represents the accuracy on absent classes.  The lines show the performance of pre-training, fine-tuning (without calibration), fine-tuning with calibration, and the state-of-the-art model from Tu et al. 2023, both with and without calibration. This figure demonstrates that post-processing calibration can effectively restore the accuracy on absent classes that is lost during fine-tuning.", "section": "4. Experimental Setup: Datasets, Models, and Evaluation Metrics"}, {"figure_path": "XRJXKBeeTD/figures/figures_25_1.jpg", "caption": "FIGURE 22. Accs/y at the x-axis and Accu/y at the y-axis) by varying the calibration factor \u03b3 for all\npretraining-downstream domain pairs in Office-Home.", "description": "This figure shows the absent class accuracy (Accu/y) versus fine-tuning class accuracy (Accs/y) curves for all six combinations of source and target domains in the Office-Home dataset.  Each curve represents a different source-target domain pair. The curves demonstrate the impact of the proposed post-processing calibration method (adding a bias factor \u03b3 to the logits of absent classes) on both Accu/y and Accs/y.  The results show that calibration improves absent class accuracy while maintaining reasonably good fine-tuning class accuracy.", "section": "4 A Systematic Study of Fine-Tuning (FT)"}, {"figure_path": "XRJXKBeeTD/figures/figures_26_1.jpg", "caption": "FIGURE 23. Accs/y at the x-axis and Accu/y at the y-axis) by varying the calibration factor \u03b3 for all datasets in VTAB.", "description": "This figure shows the performance of the fine-tuning model with post-processing calibration on the VTAB dataset.  The x-axis represents the accuracy on the fine-tuning classes (Accs/y), and the y-axis represents the accuracy on the absent classes (Accu/y). Each subfigure represents a different dataset within VTAB, showing how the calibration factor improves the accuracy on absent classes while maintaining reasonable accuracy on the fine-tuning classes. The results are compared to the pre-trained model and the model fine-tuned without calibration, highlighting the effectiveness of the proposed method.", "section": "4 A Systematic Study of Fine-Tuning (FT)"}, {"figure_path": "XRJXKBeeTD/figures/figures_27_1.jpg", "caption": "FIGURE 3. Accuracy gain after fine-tuning. We consider the neural network (NN) classifier with the FC layer (section 3) and the NCM classifier using only features (Equation 2). We show the average accuracy gain on fine-tuning classes (Accs/y) and absent classes (Accu/y). While the NN classifier suffers drops in Accu/y, the NCM classifier enjoys a consistent gain, suggesting the holistic improvement of features after fine-tuning.", "description": "This figure shows the accuracy gain in both fine-tuning and absent classes after fine-tuning. Two classifiers are used: a neural network classifier with a fully connected layer and a nearest class mean (NCM) classifier using only features. The results demonstrate that the NCM classifier shows an improvement in accuracy for absent classes, while the neural network classifier exhibits a drop in accuracy for absent classes.  This highlights that the fine-tuning process leads to improved feature extraction for all classes, even those not included in the fine-tuning process.", "section": "4.2 Is the fine-tuned feature extractor damaged?"}, {"figure_path": "XRJXKBeeTD/figures/figures_27_2.jpg", "caption": "FIGURE 8. Accuracy gain after fine-tuning. We consider the neural network (NN) classifier with the FC layer (section 3) and the NCM classifier using only features (Equation 2). We show the average accuracy gain on fine-tuning classes (Accs/y) and absent classes (Accu/y). While the NN classifier suffers drops in Accu/y, the NCM classifier enjoys a consistent gain, suggesting the holistic improvement of features after fine-tuning.", "description": "This figure shows the accuracy gain for fine-tuning classes and absent classes after fine-tuning using two types of classifiers: Neural Network (NN) classifier and Nearest Class Mean (NCM) classifier. The NN classifier shows an accuracy drop for absent classes, while the NCM classifier shows a consistent accuracy gain, indicating an overall improvement in feature quality after fine-tuning. This suggests that fine-tuning with only a subset of classes can improve the feature extractor for all classes, including those not seen during fine-tuning.", "section": "4.2 Is the fine-tuned feature extractor damaged?"}, {"figure_path": "XRJXKBeeTD/figures/figures_27_3.jpg", "caption": "FIGURE 3. Accuracy gain after fine-tuning. We consider the neural network (NN) classifier with the FC layer (section 3) and the NCM classifier using only features (Equation 2). We show the average accuracy gain on fine-tuning classes (Accs/y) and absent classes (Accu/y). While the NN classifier suffers drops in Accu/y, the NCM classifier enjoys a consistent gain, suggesting the holistic improvement of features after fine-tuning.", "description": "This figure compares the accuracy gain after fine-tuning using two different classifiers: a neural network (NN) classifier and a Nearest Class Mean (NCM) classifier.  The NN classifier shows an accuracy drop for the absent classes after fine-tuning, while the NCM classifier shows a consistent gain, indicating that the quality of the extracted features improves holistically after fine-tuning, even for the classes not included during fine-tuning.", "section": "4.2 Is the fine-tuned feature extractor damaged?"}, {"figure_path": "XRJXKBeeTD/figures/figures_28_1.jpg", "caption": "FIGURE 10. Classifier update direction similarity within fine-tuning (left) and absent (right) classes for ImageNet-S. The update directions are highly similar within absent classes, thus preserving the inter-class relationships among absent classes.", "description": "This figure visualizes the cosine similarity of the change in classifier weights between fine-tuning and the pre-trained model for both fine-tuning and absent classes in ImageNet-S.  The high similarity in update directions for absent classes indicates that the relationships between these classes are preserved during fine-tuning, even though they weren't directly involved in the training process.", "section": "Absent Class Relationship Analysis"}, {"figure_path": "XRJXKBeeTD/figures/figures_29_1.jpg", "caption": "FIGURE 15. Visualization of pre-training and target domain data in the toy example, with distinct colors indicating different classes. The symbol \u25a1 represents data from the pre-training phase, while \u25cb denotes those of the target domain (only blue and cyan are fine-tuning during fine-tuning).", "description": "This figure shows a visualization of the data used in a toy example to illustrate the impact of similar fine-tuning training data on the feature representation of absent data. The pre-training data is represented by squares (\u25a1) and the target domain data by circles (\u25cb). The colors of the circles represent different classes. Only the blue and cyan circles are used in the fine-tuning process.", "section": "A.3 Toy Example"}]