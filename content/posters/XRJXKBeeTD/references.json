{"references": [{"fullname_first_author": "Rishi Bommasani", "paper_title": "On the opportunities and risks of foundation models", "publication_date": "2021-08-07", "reason": "This paper provides a comprehensive overview of foundation models, their capabilities, and potential risks, which forms a crucial theoretical foundation for the current research on fine-tuning."}, {"fullname_first_author": "Mitchell Wortsman", "paper_title": "Robust fine-tuning of zero-shot models", "publication_date": "2022-XX-XX", "reason": "This paper addresses the issue of robustness in fine-tuning, a key concern when adapting pre-trained models to downstream tasks, and directly relates to the challenges addressed in the current work."}, {"fullname_first_author": "Cheng-Hao Tu", "paper_title": "Holistic transfer: Towards non-disruptive fine-tuning with partial target data", "publication_date": "2023-XX-XX", "reason": "This paper is the most directly related work, serving as a foundation for the current research and identifying the fundamental problem of catastrophic forgetting in fine-tuning."}, {"fullname_first_author": "James Kirkpatrick", "paper_title": "Overcoming catastrophic forgetting in neural networks", "publication_date": "2017-XX-XX", "reason": "This paper introduces the concept of catastrophic forgetting in neural networks, a phenomenon central to the current paper's investigation of the risks and limitations of fine-tuning."}, {"fullname_first_author": "Kaiming He", "paper_title": "Deep residual learning for image recognition", "publication_date": "2016-XX-XX", "reason": "This paper introduces the ResNet architecture, a fundamental model used in the current research, demonstrating its impact and influence on the field of deep learning."}]}