[{"figure_path": "nw8cXoNvep/tables/tables_7_1.jpg", "caption": "Table 1: Results on ModelNet10-SO(3). The scores have been averaged across all ten object categories.", "description": "This table presents the quantitative results of the proposed method on the ModelNet10-SO(3) benchmark dataset.  It compares the performance of the proposed method against various state-of-the-art methods. The metrics used are Acc@15 (accuracy within 15 degrees of error), Acc@30 (accuracy within 30 degrees of error), and median rotation error.  The results show that the proposed method achieves better performance in all three metrics, demonstrating its effectiveness compared to other techniques in 3D pose estimation.", "section": "5.3 Results"}, {"figure_path": "nw8cXoNvep/tables/tables_7_2.jpg", "caption": "Table 1: Results on ModelNet10-SO(3). The scores have been averaged across all ten object categories.", "description": "This table presents the results of the proposed method and several baseline methods on the ModelNet10-SO(3) dataset.  The table shows the accuracy at 15\u00b0 and 30\u00b0 thresholds (Acc@15, Acc@30), and the median rotation error (Rot Err. (Median)).  The results are averaged across all ten object categories in the dataset. It demonstrates the superior performance of the proposed method compared to existing approaches in terms of pose estimation accuracy.", "section": "5. Results"}, {"figure_path": "nw8cXoNvep/tables/tables_8_1.jpg", "caption": "Table 3: Comparison of different parametrizations of 3D rotations. To validate our Wigner-D representation in the frequency domain, we train using various output rotation representations.", "description": "This table compares the performance of different 3D rotation representations (Wigner, Euler angles, Quaternions, Axis-Angle, and Rotation matrices) used in the pose estimation model.  The goal is to demonstrate the superiority of using Wigner-D coefficients as the model's output, which is central to the paper's approach. The table shows that Wigner-D significantly outperforms other representations in terms of Acc@15\u00b0, Acc@30\u00b0, and median rotation error. This highlights the advantage of the frequency domain representation for accurate 3D pose estimation. ", "section": "5.5 Ablation Studies & Design Choices"}, {"figure_path": "nw8cXoNvep/tables/tables_8_2.jpg", "caption": "Table 5: Comparison of results without the SO(3)-equivariant module and with different SO(3) grids at inference. The first group shows the results using conventional convolution instead of equivariant convolution. The second group presents the results with different SO(3) grids at inference time. 'ours' denotes the proposed model architecture.", "description": "This table presents ablation study results focusing on two key aspects of the proposed model: the SO(3)-equivariant convolutional layers and the SO(3) grid used during inference.  The first part compares the performance of the model with and without SO(3)-equivariant layers, highlighting the significant contribution of these layers to the overall accuracy. The second part investigates the impact of using different SO(3) grid sampling methods (random SO(3) and SuperFibonacci) on the model's performance, showing that while performance varies slightly the proposed method remains consistently strong.", "section": "5.5 Ablation Studies & Design Choices"}, {"figure_path": "nw8cXoNvep/tables/tables_9_1.jpg", "caption": "Table 6: Results on SYMSOL I and II [49]. We report the average log likelihood on both parts of the SYMSOL datasets.  Lwigner denotes the results obtained with our Wigner-D regression loss. Ldist denotes the results using the distribution loss from I-PDF [49], which are the same as the results of I2S [35]. The third row presents the results of joint training using both our regression loss and the distribution loss.", "description": "This table presents a comparison of the average log-likelihood scores achieved by three different training methods on the SYMSOL I and II datasets. The three methods are:\n\n1.  Using only the Wigner-D regression loss (Lwigner).\n2.  Using only the distribution loss from the I-PDF method (Ldist), which is the same as the results from the I2S method.\n3.  Jointly training the model with both the Wigner-D regression loss and the distribution loss (Lwigner + Ldist).\n\nThe results show that joint training achieves the best performance for most object categories in both SYMSOL I and SYMSOL II.", "section": "5.6 Results on SYMSOL"}, {"figure_path": "nw8cXoNvep/tables/tables_16_1.jpg", "caption": "Table A1: Comparison of different parametrizations of 3D rotations. To validate our Wigner-D representation in the frequency domain, we train using various output rotation representations.", "description": "This table compares the performance of different 3D rotation parameterizations (Wigner-D, Euler angles, quaternions, axis-angle, and rotation matrices) used in the proposed method.  The results demonstrate the superiority of the Wigner-D representation for accurate 3D rotation prediction when used with SO(3)-equivariant networks in the frequency domain.", "section": "5.5 Ablation Studies & Design Choices"}, {"figure_path": "nw8cXoNvep/tables/tables_16_2.jpg", "caption": "Table 2: Results on PASCAL3D+ with ResNet-101 backbone. Scores are averaged across all twelve classes.", "description": "This table presents the results of the proposed method on the PASCAL3D+ benchmark dataset.  The ResNet-101 architecture was used as the backbone. The results show the accuracy at 15 and 30 degrees error thresholds (Acc@15\u00b0, Acc@30\u00b0), along with the median rotation error (Median). The scores shown are averaged across all 12 object categories in the dataset.", "section": "5.2 Benchmarks"}, {"figure_path": "nw8cXoNvep/tables/tables_18_1.jpg", "caption": "Table 1: Results on ModelNet10-SO(3). The scores have been averaged across all ten object categories.", "description": "This table presents the results of the proposed method and several baseline methods on the ModelNet10-SO(3) dataset.  It shows the accuracy (Acc@15\u00b0, Acc@30\u00b0) and median rotation error for each method, averaged across all ten object categories in the dataset.  The results demonstrate the performance of different approaches to 3D rotation estimation. ", "section": "5.3 Results"}, {"figure_path": "nw8cXoNvep/tables/tables_18_2.jpg", "caption": "Table A2: Comparison with finer thresholds on PASCAL3D+. We compare additional metrics, including Acc@3\u00b0, Acc@5\u00b0, and Acc@10\u00b0, adding on the Table 2. Most baselines [35, 39, 41, 42, 48, 49, 71], including ours, use ResNet-101 backbone networks in this experiment.", "description": "This table compares the performance of different methods on the PASCAL3D+ dataset using finer accuracy thresholds (Acc@3\u00b0, Acc@5\u00b0, Acc@10\u00b0) and median error.  The methods primarily utilize the ResNet-101 backbone architecture. The table highlights our method's superior performance compared to existing techniques in achieving the highest accuracies and lowest median error across these metrics.", "section": "B.1.2 PASCAL3D+"}, {"figure_path": "nw8cXoNvep/tables/tables_19_1.jpg", "caption": "Table A5: Evaluation by changing the size of the SO(3) grid at inference. To analyze the sensitivity of discretization on precision (Q of Fig. 4), we vary the recursion levels of the SO(3) HEALPix from 0 to 6. We use a ResNet-50 backbone on ModelNet10-SO(3).", "description": "This table presents the results of an experiment conducted to evaluate the impact of varying the SO(3) grid size at inference time on the accuracy of the pose estimation. The experiment involved varying the recursion levels of the SO(3) HEALPix grid (Q in Figure 4) from 0 to 6, while using a ResNet-50 backbone on ModelNet10-SO(3). The results are presented in terms of accuracy at different thresholds (Acc3\u00b0, Acc5\u00b0, Acc10\u00b0, Acc15\u00b0, Acc30\u00b0) and the median rotation error (Rot Err.). The findings indicate the effect of different discretization levels on the precision of the pose estimation.", "section": "B.3 Impact of SO(3) Discretization Sizes and Continuity of Rotations"}, {"figure_path": "nw8cXoNvep/tables/tables_19_2.jpg", "caption": "Table A6: Comparison of inference methods on pose distribution. We compare argmax and gradient ascent in the predicted distribution.", "description": "This table compares two inference methods, argmax and gradient ascent, used to determine the final 3D rotation from a predicted distribution of rotations.  The results show that the gradient ascent method achieves slightly better accuracy in terms of Acc@15\u00b0, Acc@30\u00b0, and median rotation error. However, the differences are small, suggesting that the argmax method might be a computationally faster and simpler choice for inference.", "section": "B Additional Results"}, {"figure_path": "nw8cXoNvep/tables/tables_20_1.jpg", "caption": "Table A8: Results of various number of maximum frequency L in ModelNet10-SO(3) 20-shot training views.", "description": "This table shows the impact of varying the maximum frequency level L on the accuracy of pose prediction using SO(3) group convolutions.  The results indicate that increasing L up to 5 consistently improves accuracy metrics, but beyond that point, adding more frequencies leads to decreased performance, possibly due to overfitting to noise.", "section": "B.6 Searching Frequency Level L"}, {"figure_path": "nw8cXoNvep/tables/tables_20_2.jpg", "caption": "Table A9: Validating the design choice of the spherical mapper. The 'MLP mapper' denotes the Fourier projection, which directly maps image features to harmonics using an MLP, and the 'spherical mapper' denotes our choice of orthographic projection [35].", "description": "This table compares the performance of two different projection methods: spherical mapper and MLP mapper, in terms of accuracy and rotation error on ModelNet10-SO(3) and PASCAL3D+ datasets.  The spherical mapper, which projects image features onto a sphere, outperforms the MLP mapper, which directly maps features to harmonics.  This highlights the effectiveness of the spherical mapper in preserving spatial information and geometric properties, crucial for accurate pose estimation.", "section": "B.7 Justification of the Spherical Mapper"}, {"figure_path": "nw8cXoNvep/tables/tables_21_1.jpg", "caption": "Table A10: Cross-dataset evaluation for validating out-of-distribution generalization on ModelNet10-SO(3) and PASCAL3D+ datasets.", "description": "This table presents the results of a cross-dataset evaluation to assess the model's ability to generalize to unseen data.  The model, trained on either ModelNet10-SO(3) or PASCAL3D+, is evaluated on both datasets.  The results show the accuracy (Acc@15 and Acc@30) and median rotation error (Rot. Err.) for each training-evaluation dataset combination. This helps to understand how well the model generalizes beyond the specific dataset it was trained on.", "section": "B.9 OOD Evaluation"}, {"figure_path": "nw8cXoNvep/tables/tables_21_2.jpg", "caption": "Table A11: Comparison of computational cost. We compare the inference time of one image and GPU memory consumption on ModelNet10-SO(3) test split. To measure the inference time, we average the results of total 18,160 samples of ModelNet10-SO(3) test split.", "description": "This table compares the inference time and GPU memory usage of four different methods for 3D pose estimation: our proposed method, and three baseline methods.  The comparison is performed on the ModelNet10-SO(3) test set using a machine with an Intel i7-8700 CPU and an NVIDIA GeForce RTX 3090 GPU. The results show that our method achieves the fastest inference time, but at the cost of higher GPU memory consumption.", "section": "B.9 Computational Cost Analysis"}, {"figure_path": "nw8cXoNvep/tables/tables_22_1.jpg", "caption": "Table A12: Experiment of 5-trials training of our model for statistical significance on ModelNet10-SO(3) 20-shot training views. \u03bc denotes the average, and \u03c3 denotes the standard deviation.", "description": "This table shows the results of five independent training runs for both ResNet-50 and ResNet-101 backbones on the ModelNet10-SO(3) dataset.  It demonstrates the stability and reproducibility of the training process by showing the mean (\u03bc) and standard deviation (\u03c3) for several metrics, indicating how much the results vary across different runs.  The low standard deviation values confirm the consistency of the model's performance.", "section": "B.10 Experiment of Statistical Significance"}]