[{"figure_path": "cYZibc2gKf/figures/figures_1_1.jpg", "caption": "Figure 1: (a): MDP M and policy \u03c0b are transformed into a discrete abstract reward process (ARP) using a state abstraction function \u03c6. The ARP aggregates rewards (denoted by stars) and transition probabilities from all states that map to each abstract state. (b): A model of the ARP for the evaluation policy \u03c0e is constructed by: reweighting data generated by \u03c0b with importance weights \u03c1 (middle), applying the state abstraction function \u03c6, and performing weighted maximum likelihood estimation of the ARP (right). The expected return of a model of this ARP estimated from off-policy data is a consistent estimator of the expected return of \u03c0\u03b5.", "description": "This figure illustrates the process of transforming an MDP and a behavior policy into an abstract reward process (ARP) and using it for off-policy evaluation.  Panel (a) shows how a state abstraction function (\u03c6) simplifies the MDP into a smaller discrete ARP. Panel (b) shows how off-policy data (generated by policy \u03c0b) is reweighted using importance weights (\u03c1) before applying the state abstraction function. This reweighted data is then used to estimate the ARP model for the evaluation policy (\u03c0e). The expected return of this estimated ARP acts as a consistent estimator for the evaluation policy's expected return.", "section": "3 Abstract Reward Processes"}, {"figure_path": "cYZibc2gKf/figures/figures_7_1.jpg", "caption": "Figure 2: Mean squared prediction errors of the estimated ARPs for the set of hyperparameters swept over for CartPole.", "description": "This figure shows the mean squared prediction error (MSE) for different configurations of the state abstraction function (\u00f8) and weight clipping factor (c) used in the STAR framework. The x-axis represents the dataset size (n), and the y-axis represents the MSE. The lines represent the average MSE across multiple trials for various estimators, including the best and median performing estimators within STAR, along with two existing OPE methods, namely, MBased and WPDIS, which serve as benchmarks for comparison. This plot allows for an assessment of STAR's performance compared to those of existing methods.", "section": "5 Empirical Analysis"}, {"figure_path": "cYZibc2gKf/figures/figures_8_1.jpg", "caption": "Figure 3: Mean squared prediction errors of best and median ARPs from STAR compared against existing OPE methods. The empirically estimated bias-variance decomposition of the error is shown. The results are averaged over 200 trials, with error bars indicating standard error. Note: For ICU-Sepsis, regression-based methods (MRDR and Q-Reg) were computationally intractable due to the large state set, as the corresponding Weighted Least Squares methods for regression were too slow. In all domains and across all datasizes, the best ARP in STAR outperforms baselines in all cases, and the even the median estimator does so in 7 out of 12 cases.", "description": "This figure compares the performance of the best and median ARPs from the STAR framework against existing off-policy evaluation (OPE) methods across three different domains (CartPole, ICU-Sepsis, and Asterix) and various dataset sizes.  It displays the mean squared prediction error (MSE), broken down into bias and variance components, for each method.  The results demonstrate that STAR estimators consistently outperform baseline OPE methods, highlighting the effectiveness of the STAR framework in providing accurate and low-variance OPE estimates.", "section": "Empirical Analysis"}, {"figure_path": "cYZibc2gKf/figures/figures_28_1.jpg", "caption": "Figure 2: Mean squared prediction errors of the estimated ARPs for the set of hyperparameters swept over for CartPole.", "description": "The figure shows the mean squared prediction errors for the estimated ARPs across a range of configurations of state abstraction (|Z|) and weight clipping (c).  It compares the performance of the best and median performing ARPs against two baseline methods: Weighted Per-Decision Importance Sampling (WPDIS) and the approximate model-based estimator (MBased). The plot demonstrates that even median-performing ARPs from STAR achieve competitive performance compared to existing state-of-the-art methods.", "section": "5 Empirical Analysis"}]