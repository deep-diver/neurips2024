[{"type": "text", "text": "Class Distribution Shifts in Zero-Shot Learning: Learning Robust Representations ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Yuval Benjamini ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Yuli Slavutsky Department of Statistics and Data Science The Hebrew University of Jerusalem Jerusalem, Israel yuli.slavutsky@mail.huji.ac.il ", "page_idx": 0}, {"type": "text", "text": "Department of Statistics and Data Science The Hebrew University of Jerusalem Jerusalem, Israel yuval.benjamini@mail.huji.ac.il ", "page_idx": 0}, {"type": "text", "text": "Abstract ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Zero-shot learning methods typically assume that the new, unseen classes encountered during deployment come from the same distribution as the the classes in the training set. However, real-world scenarios often involve class distribution shifts (e.g., in age or gender for person identification), posing challenges for zero-shot classifiers that rely on learned representations from training classes. In this work, we propose and analyze a model that assumes that the attribute responsible for the shift is unknown in advance. We show that in this setting, standard training may lead to non-robust representations. To mitigate this, we develop an algorithm for learning robust representations in which (a) synthetic data environments are constructed via hierarchical sampling, and (b) environment balancing penalization, inspired by out-of-distribution problems, is applied. We show that our algorithm improves generalization to diverse class distributions in both simulations and experiments on real-world datasets. ", "page_idx": 0}, {"type": "text", "text": "1 Introduction ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Zero-shot learning systems [14, 27] are designed to classify instances of new, previously unseen classes at deployment, a scenario known as open-world classification. These systems are widely applied in extreme multi-class applications, such as face or voice recognition [19] for matching observations of the same individual, and more generally, for learning data representations [2]. ", "page_idx": 0}, {"type": "text", "text": "Class distribution shifts typically refer to changes in the prevalence of a fixed set of classes between training and testing. In zero-shot learning, however, a different challenge arises: the appearance of entirely new classes at test time. This raises a critical question \u2013 are these new classes drawn from the same distribution as the training classes? Most zero-shot methods assume that they are, an assumption that not only shapes the design of test sets [57, 16] but also plays an explicit role in assessing the generalization capabilities of zero-shot classifiers [59, 48]. ", "page_idx": 0}, {"type": "text", "text": "In practice, training classes are often chosen based on convenience and accessibility during data collection. Even when data is carefully collected, the distribution of classes may shift over time, leading to a different distribution. For instance, this could occur when a face recognition system is deployed in a building located in a neighborhood undergoing demographic changes. ", "page_idx": 0}, {"type": "text", "text": "Class distribution shifts pose significant challenges to zero-shot classifiers, since they rely on learning data representations from the training classes to distinguish new, unseen ones. Typically, these classifiers are trained by minimizing the loss on the training set to effectively separate the training classes. However, this approach may result in poor performance when confronted with data from distributions that differ significantly from the class distribution in the training data. Notably, in person re-identification, this concern gained attention from a fairness perspective with respect to gender [15, 23], age [5, 33, 50], and racial [39, 54] bias. In all these studies the variable (i.e., gender, age, race) expected to cause the distribution shift was known in advance. ", "page_idx": 0}, {"type": "text", "text": "", "page_idx": 1}, {"type": "text", "text": "In contrast, in real-world scenarios, the attribute responsible for a future distribution shift is usually unknown during training. In such cases, existing approaches based on collecting balanced datasets or re-weighting training examples [54, 41, 53] are inapplicable. Furthermore, while class distribution shifts have been extensively studied in the standard setting of supervised learning (see Appendix A), previous research assumed a closed-world setting that does not account for new classes at test time. Instead, it only addressed changes in the prevalence of fixed classes between training and testing. Consequently, class distribution shifts in zero-shot learning remain largely unaddressed. ", "page_idx": 1}, {"type": "text", "text": "In this paper we first address these limitations by examining the effects of class distribution shifts on constrastive zero-shot learning, by proposing and analyzing a parametric model (\u00a73). We identify conditions where minimizing loss in this model leads to representations that perform poorly when a distribution shift has occurred. ", "page_idx": 1}, {"type": "text", "text": "We then use the insights gained from this model to present our second contribution (\u00a74): an algorithm for learning representations that are robust against class distribution shifts in zero-shot classification. In our proposed approach, artificial data environments with diverse attribute distributions are constructed using hierarchical subsampling, and an environment balancing criterion inspired by out-of-distribution (OOD) methods is applied. We assess our method\u2019s effectiveness in both simulations and experiments on real-world datasets, demonstrating its enhanced robustness in $\\S5$ . ", "page_idx": 1}, {"type": "text", "text": "1.1 Problem Setup ", "text_level": 1, "page_idx": 1}, {"type": "text", "text": "Let $\\{z_{i},c_{i}\\}_{i=1}^{N_{z}}$ be a labeled set of training data points $z\\in{\\mathcal{Z}}$ and classes $c\\in{\\mathcal{C}}$ , such that $c_{i}$ is the class of $z_{i}$ . ", "page_idx": 1}, {"type": "text", "text": "In this work, we focus on verification algorithms that enable open-world classification by determining whether two data points $x_{i j}\\;:=\\;(z_{i},z_{j})$ belong to the same class. For instance, in person reidentification the task is to identify whether two data points (e.g., face images or voice recordings) belong to the same person. We denote this by $y_{i j}$ , where $y_{i j}=1$ if $c_{i}=c_{j}$ and $y_{i j}=0$ otherwise. When the identity of each data point in the pair is not important, a single index is used for simplicity, namely $(x_{k},y_{k})$ . ", "page_idx": 1}, {"type": "text", "text": "We assume that each class $c$ is characterized by some attribute $A$ . We further assume that the training classes are sampled from $P_{C}(c)$ , the test classes are sampled according to $Q_{C}(c)$ , and the two distributions differ solely due to a shift in the distribution of an attribute $A$ : ", "page_idx": 1}, {"type": "equation", "text": "$$\nP_{C}(c)=\\int P_{C|A}(c|a)P_{A}(a)\\,d a,\\quad Q_{C}(c)=\\int P_{C|A}(c|a)Q_{A}(a)\\,d a.\n$$", "text_format": "latex", "page_idx": 1}, {"type": "text", "text": "Importantly, we assume that the attribute $A$ is unknown, and that both during training and testing, data points $z\\in{\\mathcal{Z}}$ for each class are sampled according to $P_{Z|C}(z|C)$ . For instance, revisit the person identification example where each person is a class. If the attribute $A$ is binary (e.g., $a_{1}$ is blond and $a_{2}$ is dark-haired), then $P(C|A=a_{1})$ represents the distribution of people with blond hair, and $P(C|A=a_{2})$ of individuals with other hair colors. The training classes might be predominantly sampled from the blond population $P(A=a_{1})=\\rho_{\\mathrm{tr}}=0.8$ , while test classes are predominantly sampled from $Q(A=a_{1}\\bar{)}\\,{\\bar{=}}\\,\\rho_{\\mathrm{te}}=0.1$ . ", "page_idx": 1}, {"type": "text", "text": "We focus on verification techniques based on deep metric learning methods (for surveys see [43, 34]) such as contrastive-learning [17], Siamese neural networks [24], triplet networks [20], and other more recent variations [35, 49, 56, 58]. These methods learn a representation function that maps data points to a representation space $g:\\mathcal{Z}\\to\\hat{\\mathcal{Z}}$ , so that examples from the same class are close (in a predefined distance function $d(\\cdot,\\cdot))$ , while those from different classes are farther apart. ", "page_idx": 1}, {"type": "text", "text": "We assume that $g$ is a neural network trained by optimizing a deep-metric-learning loss, such as the contrastive loss [17]: ", "page_idx": 1}, {"type": "equation", "text": "$$\n\\ell\\left(z_{i},z_{j},y_{i j};d_{g}\\right):=y_{i j}d_{g}^{2}\\left(z_{i},z_{j}\\right)+\\left(1-y_{i j}\\right)\\operatorname*{max}\\left\\{0,m-d_{g}\\left(z_{i},z_{j}\\right)\\right\\}^{2}\n$$", "text_format": "latex", "page_idx": 1}, {"type": "text", "text": "where $m\\,\\geq\\,0$ is a predefined margin, and $d_{g}(z_{i},z_{j})\\,:=\\,d(g(z_{i}),g(z_{j}))$ is the distance between the representations of the datapoints $z_{i},z_{j}$ . In our theoretical analysis, we examine the no-hinge ", "page_idx": 1}, {"type": "text", "text": "contrastive loss (see Appendix B for additional details): ", "page_idx": 2}, {"type": "equation", "text": "$$\n\\widetilde{\\ell}\\left(z_{i},z_{j},y_{i j};d_{g}\\right):=y_{i j}d_{g}^{2}\\left(z_{i},z_{j}\\right)+\\left(1-y_{i j}\\right)\\left(m-d_{g}\\left(z_{i},z_{j}\\right)\\right)^{2}.\n$$", "text_format": "latex", "page_idx": 2}, {"type": "text", "text": "To evaluate the class separation capability of a representation, we treat the distances between representations, $d_{g}(z_{i},z_{j}\\bar{)}$ , as classification scores. Following common practice in the field (e.g., [47, 22]), we use the area under the receiver operating characteristic curve (AUC) to evaluate the representation, enabling threshold-agnostic assessment: ", "page_idx": 2}, {"type": "equation", "text": "$$\nA U C(g):=P(d_{g}(z_{i},z_{j})<d_{g}(z_{u},z_{v})|y_{i j}=1,y_{u v}=0).\n$$", "text_format": "latex", "page_idx": 2}, {"type": "text", "text": "Our goal is to learn a representation $g$ that is robust to class attribute shifts. That is, such that for an unknown shifted distribution $Q_{A}$ , the performance $\\mathbb{E}_{Q_{A}}\\left[\\mathrm{AUC}(g)\\right]$ does not significantly deteriorate compared to the performance obtained on the training distribution $P_{A}$ . ", "page_idx": 2}, {"type": "text", "text": "2 Background on Environment Balancing Methods in OOD Generalization ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "The field of OOD generalization gained attention since the work of Peters et al. [36], [37], which deals with closed-world classification where training data is gathered from multiple environments $E_{\\mathrm{train}}$ . In this setting it is assumed that in each environment $e\\in E_{\\mathrm{train}}$ examples share the same joint distribution $P_{C,Z}^{e}(c,z)$ , but across environments the joint distribution changes, often due to variations in $P_{Z|C}^{e}(z|\\boldsymbol{c})$ . A well-known example [1] involving the classification of images of cows and camels demonstrates how an algorithm relying on background cues during training (e.g., cows in green pastures, camels in deserts) performs poorly on new images of cows with sandy backgrounds. ", "page_idx": 2}, {"type": "text", "text": "Several approaches that rely on access to diverse training environments were proposed to identify stable relations between the data point $z$ and its class $c$ . Examples of such stable relations include choosing causal variables using statistical tests [42], leveraging conditional independence induced by the common causal mechanism [9], and using multi-environment calibration as a surrogate for OOD performance [52]. ", "page_idx": 2}, {"type": "text", "text": "Most relevant to our work are methods that aim to balance the loss over multiple environments. These methods consider a representation $g=g_{\\theta}$ that is a neural network parameterized by $\\theta$ trained to optimize an objective of the form ", "page_idx": 2}, {"type": "equation", "text": "$$\n\\operatorname*{min}_{\\theta}~\\sum_{e\\in E_{\\mathrm{train}}}\\ell^{e}(g_{\\theta})+\\lambda R(g_{\\theta},E_{\\mathrm{train}})\n$$", "text_format": "latex", "page_idx": 2}, {"type": "text", "text": "where $\\ell^{e}(g_{\\theta})$ is the empirical loss obtained on the environment $e$ , $E_{\\mathrm{train}}$ is the set of all training environments, $R$ is a regularization term designed to balance performance over multiple environments, and $\\lambda$ is a regularization factor balancing the tradeoff between the empirical risk minimization (ERM) term and the balance penalty. Below, we describe three such methods, which we will refer to later in the paper. ", "page_idx": 2}, {"type": "text", "text": "Invariant risk minimization (IRM) presented in [1], aims to find data representations $g_{\\theta}$ such that the optimal classifier $w$ on top of the data representation $w\\circ g_{\\theta}$ is shared across all environments. Therefore, the authors proposed minimizing the sum of environment losses $\\ell^{e}(w\\circ g_{\\theta})$ over all training environments such that $w\\in\\arg\\operatorname*{min}_{w^{\\prime}}$ $\\ell^{e}(w^{\\prime}\\circ g_{\\theta})$ for all $e\\in E_{\\mathrm{train}}$ . However, since this objective is too difficult to optimize, a relaxed version was also proposed, taking the form of Equation 5 with a penalty that measures how close $w$ is to minimizing $\\ell^{e}(w\\circ g_{\\theta})\\colon R_{\\mathrm{IRMv1}}^{e}(g_{\\theta})=\\left\\|\\nabla_{w|w=1}\\ell^{e}\\left(w\\cdot g_{\\theta}\\right)\\right\\|^{2}$ . Note that for loss functions for which optimal classifiers can be expressed as conditional expectations, the original IRM objective is equivalent to the requirement that for all environments $e,e^{\\prime}\\in E_{\\mathrm{train}}$ , $\\mathbb{E}_{P_{C,Z}^{e}}\\left[c|g(z)=h\\right]=\\mathbb{E}_{P_{C,Z}^{e^{\\prime}}}\\left[c|g(z)=h\\right]$ , where $P_{C,Z}^{e}$ and $P_{C,Z}^{e^{\\prime}}$ are the joint data distributions in the respective environments. ", "page_idx": 2}, {"type": "text", "text": "Calibration Loss Over Environments (CLOvE) presented in [52], leverages the equivalence above to establish a link between multi-environment calibration and invariance for binary predictors $(c\\in\\{0,1\\})$ . The proposed regularizer is based on the maximum mean calibration error (MMCE) [26]. Let $s:\\hat{\\mathcal{Z}}\\to[0,1]$ be a classification score function applied on the representation $s\\circ g$ , and $s_{i}=\\operatorname*{max}\\{s\\circ g(z_{i}),1-s\\circ g(z_{i})\\}$ be the confidence on the $i$ -th data point. Denote the correctness as $b_{i}=\\mathbb{1}\\{|c_{i}-s_{i}|<\\frac{1}{2}\\}$ , and let $K:\\mathbb{R}\\times\\mathbb{R}\\to\\mathbb{R}$ be a universal kernel. Let $Z^{e}$ denote the training data in the environment $e$ . The authors proposed using the MMCE as a penalty in an objective that takes the form of Equation 5 with $\\begin{array}{r}{R_{\\mathrm{MMCE}}^{e}\\left(\\stackrel{.}{s},g_{\\theta}\\right)=\\frac{1^{\\circ}}{m^{2}}{\\sum_{z_{i},z_{j}\\in Z^{e}}}(b_{i}-\\stackrel{.}{s_{i}})\\left(b_{j}-s_{j}\\right)K\\left(\\stackrel{.}{s_{i}},s_{j}\\right)}\\end{array}$ . ", "page_idx": 2}, {"type": "text", "text": "", "page_idx": 3}, {"type": "text", "text": "Variance Risk Extrapolation (VarREx) proposed by Krueger et al. [25], is based on the observation that reducing differences in loss (risk) across training domains can reduce a model\u2019s sensitivity to a wide range of distribution shifts. The authors found that using the variance of losses as a regularizer is stabler and more effective compared to other penalties. Therefore, they propose the following regularization term for $n$ training environments: $\\bar{R}_{\\mathrm{VarREx}}\\left(g_{\\theta},E_{\\mathrm{train}}\\right)=\\mathrm{Var}\\left(\\ell^{\\bar{e}_{1}}(\\bar{g}_{\\theta}),\\ldots,\\ell^{e_{n}}(g_{\\theta})\\right)$ . ", "page_idx": 3}, {"type": "text", "text": "While simple and intuitive, this approach assumes that losses across different environments accurately reflect the classifier\u2019s performance. However, as discussed in $\\S4$ , this is often not true for deep metric learning losses, where significant changes in loss may correspond to only minor variations in performance. ", "page_idx": 3}, {"type": "text", "text": "3 Parametric Model of Class Distribution Shifts in Zero-Shot Learning ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "In this section, we introduce a parametric model of class distribution shifts. Our model shows that in zero-shot learning, even if the conditional distribution of data given the class $P(z|c)$ remains the same between training and testing, a shift in the class distribution from $P(c)$ to $Q(c)$ can cause poor performance on newly encountered classes sampled from the shifted distribution $Q(c)$ . ", "page_idx": 3}, {"type": "text", "text": "Assume that for all classes, the data points $z_{i}\\in\\mathbb{R}^{d}$ are sampled from $z_{i}|c_{i}\\sim\\mathcal{N}\\left(c_{i},\\Sigma_{z}\\right)$ , where $\\Sigma_{z}=\\nu_{z}\\cdot I_{d}$ , and $I_{d}$ is the identity matrix. Let the attribute $A$ indicate the type of a class $c$ , with two possible types: $a_{1}$ and $a_{2}$ . Assume that the classes $c_{i}$ are drawn according to $\\boldsymbol{c}_{i}\\sim\\mathcal{N}\\left(0,\\Sigma_{a}\\right)$ for $\\bar{a}\\in\\{a_{1},a_{2}\\}$ . Finally, assume that in training, $a_{1}$ is the majority type with $P(a_{1})=\\rho_{\\mathrm{tr}}\\gg0.5$ , whereas at test time, $a_{2}$ is the majority type with $Q(a_{1})=\\rho_{\\mathrm{te}}\\ll0.5$ . ", "page_idx": 3}, {"type": "text", "text": "We construct the model such that differences between the training class distribution $P(c)$ and the test distribution $Q(c)$ stem solely from a shift in the mixing probabilities of an unknown attribute $A$ (see Equation 1). Therefore, we define $\\Sigma_{a}$ as a diagonal matrix with replicates of three distinct values on its diagonal: $\\nu_{0},\\nu^{+},\\nu^{-}$ . Let $0<\\nu^{-}<\\nu_{z}\\leq\\nu_{0}<\\nu^{+}$ . Then, in the coordinates corresponding to $\\nu_{0}$ and $\\nu^{+}$ data points from different classes are well separated, whereas in the coordinates corresponding to $\\nu^{-}$ they are not. Assume the coordinates corresponding to $\\nu_{0}$ are shared by both types, but $\\nu^{+}$ and $\\nu^{-}$ are swapped: ", "page_idx": 3}, {"type": "image", "img_path": "yUqUBGioBG/tmp/7f73100cbb440f515abe000ed5e05fb6ff02d074ea5890cf61d00f530768b33c.jpg", "img_caption": [], "img_footnote": [], "page_idx": 3}, {"type": "text", "text": "An illustration with one replicate of each value is shown in Figure 1. ", "page_idx": 3}, {"type": "text", "text": "The following proposition shows that if the number of dimensions $d_{1}$ that allow good separation for classes of type $a_{1}$ is relatively similar to the number of dimensions $d_{2}$ that enable good separation for classes of type a2, specifically if hl (\u03c1, \u03bdz, \u03bd0, \u03bd1, \u03bd2) < dd21++22 $\\begin{array}{r}{h_{l}\\left(\\rho,\\nu_{z},\\nu_{0},\\nu_{1},\\nu_{2}\\right)<\\frac{d_{2}+2}{d_{1}+2}<h_{u}\\left(\\rho,\\nu_{z},\\nu_{0},\\bar{\\nu}_{1},\\nu_{2}\\right)}\\end{array}$ , then the optimal solution for the training distribution prioritizes the components (features) corresponding to $\\nu^{+}$ for classes of type $a_{1}$ . Thus, the prioritized features allow good separation for classes from the majority type in training, but offer poor separation for the shifted test distribution, where most classes are of type $a_{2}$ . Note that if $d_{2}$ is large, when combined, the corresponding components may still provide reasonable separation. We define $h_{l}$ and $h_{u}$ in Equation 35 and provide the proof of Proposition 1 in Appendix B.2. ", "page_idx": 3}, {"type": "text", "text": "Proposition 1. Consider a weight representation $g(z)\\,=\\,W z$ , where $W\\,\\in\\,\\mathbb{R}^{d\\times d}i s$ a diagonal matrix, and the squared Euclidean distance $d_{g}\\left(z_{i},z_{j}\\right)=\\left\\|W\\left(z_{i}-z_{j}\\right)\\right\\|^{2}$ . Let $W^{*}=d i a g(w^{*})\\in$ $\\mathrm{arg\\,min}_{W}\\,\\mathbb{E}\\left[\\widetilde{\\ell}\\left(\\cdot,\\cdot,\\cdot;d_{g}\\right)\\right]$ . Denote $\\begin{array}{r}{\\overline{{w}}_{1}^{*2}=\\frac{1}{d_{1}}\\sum_{k=d_{0}+1}^{d_{1}}w_{k}^{*}}\\end{array}$ and $\\begin{array}{r}{\\overline{{w}}_{2}^{*2}=\\frac{1}{d_{2}}\\sum_{k=d_{1}+1}^{d}w_{k}^{*2}}\\end{array}$ . Then, for all $\\rho>\\frac{1}{2}$ and $\\nu_{z},\\nu_{0},\\nu_{1},\\nu_{2},d_{1},d_{2}$ satisfying $\\begin{array}{r}{h_{l}\\left(\\rho,\\nu_{z},\\nu_{0},\\nu_{1},\\nu_{2}\\right)<\\frac{d_{2}+2}{d_{1}+2}<h_{u}\\left(\\rho,\\nu_{z},\\nu_{0},\\nu_{1},\\nu_{2}\\right)\\,i t}\\end{array}$ holds that $d_{2}\\overline{{w}}_{2}^{*2}\\leq d_{1}\\overline{{w}}_{1}^{*2}$ . ", "page_idx": 3}, {"type": "image", "img_path": "yUqUBGioBG/tmp/f7d7f1e444b1648aab52ae3d9f22b8556eb8b5007009d2ceac428d0bf1c948eb.jpg", "img_caption": [], "img_footnote": [], "page_idx": 4}, {"type": "text", "text": "Figure 1: Illustration of the parametric model. Classes of each type are best separated along specific axes: classes of type $a_{1}$ along the red axis $(z^{(1)})$ and classes of type $a_{2}$ along the green axis $(z^{(2)})$ . On axis $z^{(0)}$ both types can be separated but not as effectively as on their respective optimal axes. ", "page_idx": 4}, {"type": "image", "img_path": "yUqUBGioBG/tmp/929f8426c7e7daa5b3114a8b4c2b7c85da08334d652c076b708b03fbe51cc1e2.jpg", "img_caption": ["Figure 2: Optimal weights. Top row: $d_{0}$ is fixed, $d_{1}$ and $d_{2}$ vary. Middle and bottom rows: $d_{0},d_{1},d_{2}$ are fixed. Middle: $\\nu_{0}/\\nu^{-}$ varies. Bottom: ${\\nu_{0}}/{\\nu^{+}}$ varies. "], "img_footnote": [], "page_idx": 4}, {"type": "text", "text": "Note that the conditions outlined in Proposition 1 are sufficient but not necessary. Accordingly, in Appendix B.3, we provide the complete analytical solution for $w^{*}$ that minimizes the expected loss $\\mathbb{E}\\left[\\widetilde{\\ell}\\left(\\cdot,\\cdot,\\cdot;d_{g}\\right)\\right]$ for the weight representation $g(z)=W z$ , using the squared Euclidean distance. According to Proposition 1, larger $d_{2}$ values favor $\\nu^{-}$ for better aggregated separation. Increasing $\\nu_{0}/\\nu^{+}$ leads to increased differences between $w_{1}^{*2}$ and $w_{2}^{*2}$ , and vice versa for $\\nu_{0}/\\nu^{-}$ . ", "page_idx": 4}, {"type": "text", "text": "These relationships in the optimal solution are illustrated in Figure 2, showcasing different scenarios. The top row shows that when $d_{1}=d_{2}=10$ dimensions favoring classes of type $a_{1}$ are prioritized for $\\rho>0.5$ , while those favoring type $a_{2}$ are prioritized for $\\rho<0.5$ . When $d_{1}=10$ while $d_{2}=5$ , dimensions favoring type $a_{1}$ are prioritized for all values of $\\rho$ , and vice versa when $d_{2}$ is significantly larger than $d_{1}$ . The middle and the bottom row further explore the $d_{1}\\,=\\,d_{2}$ case, showing how differences in separability between shared dimensions $\\left(\\nu_{0}\\right)$ and type-favoring dimensions impact weight allocation. ", "page_idx": 4}, {"type": "text", "text": "Since components corresponding to $\\nu^{+}$ for classes of type $a_{1}$ align with $\\nu^{-}$ for classes of type $a_{2}$ , the optimal representation for the training distribution results in poor separation for the shifted test distribution. Therefore, a robust representation should prioritize dimensions that provide effective separation for both class types, corresponding to $\\nu_{0}$ . ", "page_idx": 4}, {"type": "text", "text": "This aligns with a common principle in the OOD generalization field, where robust representations are those that rely on features shared across environments (see $\\S2_{.}$ ). This principle is often referred to as invariance. ", "page_idx": 4}, {"type": "text", "text": "4 Proposed Approach ", "text_level": 1, "page_idx": 4}, {"type": "text", "text": "Motivated by our analysis of the parametric model, we propose a new approach for tackling class distribution shifts in zero-shot learning. Our approach revolves around two key ideas: (i) during training, different mixtures of the attribute $A$ can be produced by sampling small subsets of the classes, forming artificial environments, and (ii) penalizing for differences in performance across these environments is likely to increase robustness to the class mixture encountered at test time. ", "page_idx": 4}, {"type": "text", "text": "4.1 Synthetic Environments ", "text_level": 1, "page_idx": 4}, {"type": "text", "text": "Standard ERM training involves sampling pairs of data points $(z_{i},z_{j})$ uniformly at random from all $N_{c}$ classes available during training. However, as discussed in $\\S3$ , this is prone to overfitting to the attribute distribution of the training data. Since the identity of the attribute is unknown, weighted sampling (and similar approaches) cannot be used to create environments with different attribute mixtures. ", "page_idx": 4}, {"type": "text", "text": "Yet, our goal is to design artificial environments with diverse compositions of the (unknown) attribute of interest. To do so, we leverage the variability in small samples: while class subsets of similar size to $N_{c}$ maintain attribute mixtures similar to the overall training set, smaller subsets with $k\\ll N_{c}$ classes are likely to exhibit distinct attribute mixtures. Therefore, we propose creating multiple environments, composed of examples from few sampled classes. ", "page_idx": 5}, {"type": "text", "text": "This results in a hierarchical sampling scheme for the data pairs: first, sample a subset of $k$ classes, $S=\\{c_{1},\\ldots,c_{k}\\}$ . Then, for each $c\\in S$ sample $2r$ pairs of data points as follows: $r$ pairs from within the class $c$ , $\\{z_{i};c_{i}=c\\}$ , uniformly at random (positive pairs); and $r$ negative pairs, where one point is sampled uniformly at random from $c$ , and the other from all other data points in $S$ , $\\{z_{i};c_{i}\\neq c,c_{i}\\in S\\}$ .1 ", "page_idx": 5}, {"type": "text", "text": "Across multiple class subsets $S=\\{S_{1},\\ldots,S_{n}\\}$ , this hierarchical sampling results in diverse mixtures of any unknown attribute (see Figure 3). In particular, in some of the class subsets, classes from the overall minority type constitute the majority in the environment. ", "page_idx": 5}, {"type": "image", "img_path": "yUqUBGioBG/tmp/8fb5f143678033e57845d325cafa77566f049e98e0b2257186bb36cd28416d02.jpg", "img_caption": ["Figure 3: Illustration of the proposed hierarchical sampling. Top: $N_{c}=6$ classes, with 2 minoritytype classes D, F (in purple). Middle: synthetic environments formed by sampling small $[k=3]$ ) class subsets; in $^1\\!/\\!5$ of the environments, minority-type classes become the majority constituting $^2\\!/\\!3$ of the classes. Bottom: sampling $r=1$ positive and $r=1$ negative pairs for each class in the environment. "], "img_footnote": [], "page_idx": 5}, {"type": "text", "text": "4.2 Environment Balancing Algorithm for Class Distribution Shifts ", "text_level": 1, "page_idx": 5}, {"type": "text", "text": "Our goal is to learn data representations that will allow separation between classes without knowing which attribute is expected to change and how significantly. Therefore, we require the learned data representation to perform similarly well on all mixtures obtained on the synthetic environments. ", "page_idx": 5}, {"type": "text", "text": "To achieve this, inspired by OOD performance balancing methods (see $\\S2$ ), we optimize a penalized objective: ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\operatorname*{min}_{\\theta}\\quad\\sum_{l=1}^{n}\\ell^{S_{l}}(g_{\\theta})+\\lambda R\\left(S_{1},\\ldots,S_{n}\\right)\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "where $R\\left(S_{1},\\ldots,S_{n}\\right)$ is any balancing term between the constructed synthetic environments. ", "page_idx": 5}, {"type": "text", "text": "Note that computing $R\\left(S_{1},\\ldots,S_{n}\\right)$ often involves evaluating some value on each environment separately. For a general balancing term, we denote the value in the $l_{\\cdot}$ -th environment as $f(S_{l})$ and accordingly express $R\\left(S_{1},\\ldots,S_{n}\\right)=\\mathring{f}\\left(f(S_{1}),\\ldots,f(S_{n})\\right)$ , where $\\mathring{f}$ represents the corresponding aggregation function. Our approach2 for balancing performance across synthetic environments of class subsets, is outlined in Algorithm 1. ", "page_idx": 5}, {"type": "text", "text": "4.3 Balancing Performance Instead of Loss ", "text_level": 1, "page_idx": 5}, {"type": "text", "text": "In multiple OOD penalties (e.g., IRM and VarREx), $f$ represents the loss in each environment, which, in deep metric learning algorithms, is based on distance. This presents a challenge in zero", "page_idx": 5}, {"type": "text", "text": "Input: Labeled data $D=\\{z_{i},c_{i}\\}_{i=1}^{N_{z}}$ , number of synthetic environments $n$ , number of classes within subset $k$ , number of pairs per class $2r$ , neural network $g(\\cdot;\\theta)$ , loss $\\ell$ , distance function $d$ , regularization functions $f,{\\mathring{f}}$ , initial weights $\\theta_{0}$ , number of training iterations $T$ , learning rate $\\eta$ ", "page_idx": 6}, {"type": "text", "text": "Output: Learned representation $g(\\cdot;\\theta_{T})$   \nCompute unique classes $C^{*}=\\{c^{(1)},\\ldots,c^{(N_{c})}\\}$   \nfor $t=1$ to $T$ do forS $l=1$ e $n$ l adsoses from without replacement: $k$ $C^{*}$ ${S_{l}^{(t)}=\\{c_{l}^{(1)},\\dots,c_{l}^{(k)}\\}}$ From each class in $S_{l}^{(t)}$ sample $r$ positive and $r$ negative data pairs. Denote the set by $D_{l}^{(t)}$ . Compute $f(S_{l}^{(t)})$ . Compute average unpenalized loss over $\\begin{array}{r l}{\\left(x_{m},y_{m}\\right)\\in D_{l}^{(t)}\\colon}&{{}\\bar{\\ell}_{l}^{(t)}=\\frac{1}{2r k}\\sum_{m=1}^{2r k}\\ell(x_{m},y_{m}).}\\end{array}$ end for Compute $R^{(t)}\\!:=\\!R\\left(S_{1}^{(t)},\\cdot\\,.\\,.\\,,S_{n}^{(t)}\\right)\\!=\\!\\bar{f}\\left(f(S_{1}^{(t)}),\\cdot\\,.\\,.\\,,f(S_{n}^{(t)})\\right)$ . Update network parameters performing a gradient descent step: $\\begin{array}{r}{\\bar{\\theta^{(t)}}\\xleftarrow{\\bar{\\theta^{(t-1)}}}-\\bar{\\eta}\\nabla_{\\theta}\\left(\\frac{1}{n}\\sum_{l=1}^{\\bar{n}}\\bar{\\ell}_{l}^{(t)}+\\bar{R^{(t)}}\\right)}\\end{array}$   \nend for ", "page_idx": 6}, {"type": "text", "text": "", "text_level": 1, "page_idx": 6}, {"type": "text", "text": "Return: $g(\\cdot;\\theta_{T})$ ", "page_idx": 6}, {"type": "text", "text": "shot verification, where sampled tuples often include numerous easy negative examples, leading to performance plateau early in the learning process, although the distances themselves still exhibit considerable variations. Strategies like selecting the most difficult tuples [18] were proposed to address this issue, however these methods have been found to generate noisy gradients and loss values [34]. ", "page_idx": 6}, {"type": "text", "text": "We therefore propose to balance performance directly instead of relying on the losses in the training environments. Denote the set of negative pairs in a synthetic environment by $D_{l}^{0}=\\{x_{i j}=(z_{i},z_{j})\\}:$ $c_{i},c_{j}\\in S_{l},y_{i j}=0\\}$ and the set of positive pairs by $D_{l}^{1}=\\{x_{i j}=(z_{i},z_{j}):c_{i},c_{j}\\in\\bar{S}_{l},y_{i j}=\\bar{1}\\}$ . An unbiased estimator of the AUC on a given synthetic environment $S_{l}$ is given by ", "page_idx": 6}, {"type": "equation", "text": "$$\n\\widetilde{\\mathrm{AUC}}\\left(S_{l};d_{g}\\right)=\\frac{1}{|D_{l}^{0}|\\,|D_{l}^{1}|}\\sum_{x_{i j}}\\sum_{x_{u v}}\\mathbb{1}\\left[d_{g}(x_{i j})<d_{g}(x_{u v})\\right]\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "for $x_{i j}\\in D_{l}^{1}$ and $x_{u v}\\in D_{l}^{0}$ . Since this estimator is non-differentiable and therefore cannot be used in gradient-descent-based optimization, we use soft- $.A U C$ as an approximation [7] ", "page_idx": 6}, {"type": "equation", "text": "$$\n\\widehat{\\mathsf{A U C}}\\left(S_{l};d_{g}\\right)\\frac{1}{\\vert D_{l}^{0}\\vert\\,\\vert D_{l}^{1}\\vert}\\sum_{x_{i j}}\\sum_{x_{u v}}\\sigma_{\\beta}\\left(d_{g}(x_{u v})-d_{g}(x_{i j})\\right)\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "where a sigmoid $\\begin{array}{r}{\\sigma_{\\beta}(t)\\,=\\,\\frac{1}{1+e^{-\\beta t}}}\\end{array}$ approximates the step function. Note that when $\\beta\\to\\infty$ , $\\sigma_{\\beta}$ converges pointwise to the step function. Consequently, we propose the penalty: ", "page_idx": 6}, {"type": "equation", "text": "$$\nR_{\\mathrm{VarAUC}}\\left(S_{1},\\ldots,S_{n};g_{d}\\right)=\\widehat{\\mathrm{Var}}\\left(\\widehat{\\mathrm{AUC}}\\left(S_{1};g,d\\right),\\ldots,\\widehat{\\mathrm{AUC}}\\left(S_{n};g,d\\right)\\right).\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "4.4 How Many Environments Are Needed? ", "text_level": 1, "page_idx": 6}, {"type": "text", "text": "The proposed hierarchical sampling scheme allows for the construction of many synthetic environments with various attribute mixtures, influenced by the number of classes in each environment. As shown in the analysis below, this ensures that with high probability there will be at least one environment with a pair of minority type classes, thereby supporting learning to separate negative pairs within the minority type. ", "page_idx": 6}, {"type": "text", "text": "In each training iteration, we consider $n$ class subsets (environments) of size $k$ . Our goal is to achieve robustness to all attribute values $a$ that are associated with at least $\\rho_{\\mathrm{min}}\\in(0,1)$ of the training classes. Note that $\\rho_{\\mathrm{min}}$ is specified by the practitioner without knowledge of the true attribute that may cause the shift or its true prevalence $\\rho$ in the training set. ", "page_idx": 6}, {"type": "text", "text": "We compute the number of synthetic environments $n$ , such that with high probability of $(1-\\alpha)$ , $S_{1},...,S_{n}$ will include at least one subset with at least two classes associated with $a$ (otherwise none of the subsets would contain negative pairs with the attribute $a$ ). Denote the probability of a given subset not to contain any class associated with $a$ by $\\phi_{0}=\\binom{\\lceil(1-\\rho_{\\operatorname*{min}})N_{c}\\rceil}{k}\\mathord{\\left/{\\vphantom{\\int_{\\operatorname*{min}}}}\\right.\\kern-\\nulldelimiterspace}\\binom{N_{c}}{k}$ and the probability of a given subset to contain exactly one such class by $\\phi_{1}=\\rho_{\\mathrm{min}}N_{c}\\Big(\\binom{\\lceil(1-\\rho_{\\mathrm{min}})N_{c}\\rceil}{k-1}\\Big/\\binom{N_{c}}{k}$ . Therefore, the required number of environments needed to ensure that at least two minority-type classes appear together in the same environment is ", "page_idx": 7}, {"type": "equation", "text": "$$\nn\\approx\\frac{\\log{\\left(\\alpha\\right)}}{\\log{\\left(\\phi_{0}+\\phi_{1}\\right)}}.\n$$", "text_format": "latex", "page_idx": 7}, {"type": "text", "text": "Note that that $n$ is typically much smaller than $\\binom{N_{c}}{k}$ . ", "page_idx": 7}, {"type": "text", "text": "5 Empirical Results ", "text_level": 1, "page_idx": 7}, {"type": "text", "text": "Our method enhances standard training with two components: a hierarchical sampling scheme and a balancing term for synthetic environments. To the best of our knowledge, this is the first work addressing OOD generalization for class distribution in zero-shot learning. We therefore benchmark our algorithm against the ERM baseline (uniform random sampling with an unpenalized score) and a hierarchical sampling baseline (hierarchical sampling with unpenalized score). ", "page_idx": 7}, {"type": "text", "text": "Additionally, we tested standard regularization techniques including dropout and the $L_{2}$ norm, which did not yield notable improvements in the distribution shift scenario, and are therefore not shown. ", "page_idx": 7}, {"type": "text", "text": "To ensure a comprehensive comparison, in addition to the proposed VarAUC penalty, we evaluate variants of our algorithm in which the IRM, CLOvE, and VarREx penalties are used instead. While we show that VarAUC consistently outperforms other penalties, the crucial improvement lies in its performance compared to the ERM baseline: application of existing OOD penalties is enabled by the construction of synthetic environments in our algorithm. As discussed in Appendix C, this construction facilitates the formulation of class distribution shifts in zero-shot learning within the OOD setting. ", "page_idx": 7}, {"type": "image", "img_path": "yUqUBGioBG/tmp/fe4fbf245d4a2375f6d90e5927826d16602b0c4d2a552d67a5677136dd973b62.jpg", "img_caption": ["Figure 4: Average AUC over 10 simulation repetitions for majority attribute proportion $\\rho=0.9$ in training (and 0.1 in test). Solid lines: distributionshift. Dashed lines: in-distribution. Our method improves robustness for shifts, without compromising training distribution results. "], "img_footnote": [], "page_idx": 7}, {"type": "text", "text": "In all of the experiments performed, we trained the network with contrastive loss (Equation 2) and the normalized cosine distance: $\\begin{array}{r}{d_{g}(z_{1},z_{2})=\\frac{1}{2}\\left(1-\\frac{g(z_{1})\\cdot g(z_{2})}{\\|g(z_{1})\\|\\|g(z_{2})\\|}\\right)}\\end{array}$ . The specific setups are detailed below (additional details can be found in Appendix F), and code to reproduce our results is available at https://github.com/YuliSl/Zero_Shot_Robust_Representations . ", "page_idx": 7}, {"type": "text", "text": "5.1 Simulations: Revisiting the Parametric Model ", "text_level": 1, "page_idx": 7}, {"type": "text", "text": "We now revisit the parametric model presented in $\\S3$ . To increase the complexity of the problem, we add dimensions where classes from both types are not well separated. That is, $\\Sigma_{a}$ includes additional dimensions set to zero. ", "page_idx": 7}, {"type": "text", "text": "Setup We used 68 subsets in each training iteration, each consisting of two classes. This corresponds to choosing $\\rho_{\\mathrm{min}}\\,=\\,0.1$ (desired sensitivity, regardless of the true unknown parameter $\\bar{\\rho}\\in\\{0.05,0.1,0.3\\})$ , with a low $\\alpha$ value of 0.5, resulting in the construction of fewer environments according to Equation 10. For each class, we sampled $2r=10$ pairs of data points. The representation was defined as $g(z)\\,=\\,w z$ for $\\boldsymbol{w}\\in\\mathbb{R}^{d\\times p}$ 3. Here we focus on the case of $p=16$ , $\\nu_{z}=\\nu_{0}=1$ , $\\nu^{-}=0.1$ , $\\nu_{+}=2$ , $d_{0}=5$ , $d_{1}=d_{2}=10$ . The results for additional representation sizes $p$ , noise ratios $\\frac{\\nu^{+}}{\\nu^{-}}$ and varying proportions of positive and negative examples are presented in Appendix D.1. To assess the importance assigned to each dimension, we examine weight values relative to other weights: Importancei = $\\begin{array}{r}{\\bar{\\b{z}}_{i}=\\left|\\frac{\\bar{\\sum}_{j=1}^{p}w_{i j}}{\\sum_{i^{\\prime}=1}^{d}\\sum_{j^{\\prime}=1}^{p}w_{i^{\\prime}j^{\\prime}}}\\right|.}\\end{array}$ (11) ", "page_idx": 7}, {"type": "text", "text": "", "page_idx": 8}, {"type": "text", "text": "Results In Figure 5 we examine the learned representation. The analysis indicates that ERM prioritizes dimensions 5-15, providing good separation for $a_{1}$ , the dominant type in training, ", "page_idx": 8}, {"type": "text", "text": "but leading to poor separation after the shift. ERM assigns low weights to dimensions beneficial for both types (0-5) and those suitable for $a_{2}$ (15-25). In contrast, our algorithm, particularly with the two variance-based penalties, assigns the lowest weights to dimensions corresponding to $a_{1}$ and higher weights to shared dimensions and those that effectively separate $a_{2}$ classes. ", "page_idx": 8}, {"type": "text", "text": "In Figure 4, the learning progress is depicted for $\\rho=0.9$ (a similar analysis for $\\rho=0.95$ and $\\rho=$ 0.7 can be found in Appendix D). Performance on the same distribution as the training data is similar for ERM and our algorithm, suggesting that applying our algorithm does not negatively impact performance when no distribution shift occurs. However, when there is a distribution shift our algorithm achieves much better results. The VarREx penalty achieves high AUC values more quickly than the VarAUC penalty, but the ", "page_idx": 8}, {"type": "image", "img_path": "yUqUBGioBG/tmp/ee453e563287063b297e9f51c013902d52a874c814988e2e88305fdbf7a7008e.jpg", "img_caption": ["Figure 5: Average feature importance for $\\rho=0.9$ , 10 repetitions. Our VarAUC penalty favors shared features (blocks 1 and 3), while deprioritizing majority features (block 2). All methods assign low weight to noise features (block 4). "], "img_footnote": [], "page_idx": 8}, {"type": "text", "text": "VarAUC penalty attains higher overall accuracy. IRM shows noisier convergence, since it is applied directly on the gradients, which have been shown to be noisy in contrastive learning due to high variance in data-pair samples [34]. Means and standard deviations are reported in Appendix D.1, as well as the results for additional data dimensions, positive proportions, and variance ratios. ", "page_idx": 8}, {"type": "text", "text": "5.2 Experiments on Real Data ", "text_level": 1, "page_idx": 8}, {"type": "text", "text": "Experiment 1 - Species Recognition We used the ETHEC dataset [11] which contains 47,978 butterfly images from six families and 561 species (example of the images are provided in Appendix D). We filtered out species with less than five images and focused on images of butterfiles from the Lycaenidae and Nymphalidae families. In the training set, $10\\%$ of the species were from the Nymphalidae family, while at test time, $90\\%$ of the species were from the Nymphalidae family. For each class we sampled $2r\\,=\\,20$ pairs. ", "page_idx": 8}, {"type": "text", "text": "Experiment 2 - Face Recognition We used the CelebA dataset [30] which contains 202,599 images of 10,177 celebrities. We filtered out people for which the dataset contains less than three images. Following Vinyals et al. [51], we implemented $g$ as a convolutional neural network which has four modules with $3\\times3$ convolutions and 64 filters, followed by batch normalization, a ReLU activation, $2\\times2$ max-pooling, and a ", "page_idx": 8}, {"type": "image", "img_path": "yUqUBGioBG/tmp/19972a780f31ff19cd8ccdbf6f258787384daa61cfcd1452a5c91b013f568d60.jpg", "img_caption": [], "img_footnote": [], "page_idx": 8}, {"type": "text", "text": "Figure 6: Average percentage changes of our method compared to ERM across 10 repetitions are shown for the ETHEC (top) and CelebA (bottom) datasets. Error bars represent $\\pm$ one std-dev. ", "page_idx": 8}, {"type": "text", "text": "fully connected layer of size 32. We used the attribute blond hair for the class distribution shift: for training, we mainly sampled people without blond hair $(95\\%)$ , while at test time, most people $(95\\%)$ ", "page_idx": 8}, {"type": "text", "text": "had blond hair. Each training iteration had 150 synthetic environments of two classes and $2r=20$ data points per class. ", "page_idx": 9}, {"type": "text", "text": "We trained the models on 200 synthetic environments at a time, each of two classes. We implemented $g$ as a fully connected neural network with layers of sizes 128, 64, 32 and 16, and ReLU activations between them. ", "page_idx": 9}, {"type": "text", "text": "Experimental Results As can be seen in Figure 6, while all versions of our algorithm show some improvement over ERM, the best results are achieved with the VarAUC penalty (exact means and standard deviations are reported in Table 3 in Appendix D). One-sided paired t-tests show that the improvement over ERM achieved by our algorithm with the VarAUC penalty is statistically significant, with p-values of $<0.04$ on both datasets; p-values for other penalties are reported in Table 4. All p-values were adjusted with FDR [4] correction. ", "page_idx": 9}, {"type": "text", "text": "In Appendix D we also provide additional analysis confirming that the main improvement of our algorithm over the ERM baseline stems from improved performance on negative minority pairs. ", "page_idx": 9}, {"type": "text", "text": "6 Discussion ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "In this study, we examined class distribution shifts in zero-shot learning, with a focus on shifts induced by unknown attributes. Such shifts pose significant challenges in zero-shot learning where new classes emerge in testing, causing standard techniques trained via ERM to fail on shifted class distributions, even when the conditional distribution of the data given class remains the same. ", "page_idx": 9}, {"type": "text", "text": "Previous research (see Appendix A) assumes closed-world classification or a known cause, making these methods unsuitable for zero-shot learning or shifts caused by unknown attributes. In response, we introduced a framework and the first algorithm to address class distribution shifts in zero-shot learning using OOD environment balancing methods. ", "page_idx": 9}, {"type": "text", "text": "In the causal terminology of closed-world OOD generalization, our framework employs synthetic environments to intervene on attribute mixtures by sampling small class subsets, thereby manipulating the class distribution. This facilitates the creation of diverse environments with varied attribute mixtures, enhancing the distinction between negative examples. A further comparison of our framework with OOD environment balancing methods is provided in Appendix C. Additionally, our proposed VarAUC penalty, designed for metric losses, enhances the separation of negative examples. ", "page_idx": 9}, {"type": "text", "text": "Our results demonstrate improvements compared to the ERM baseline on shifted distributions, without compromising performance on unshifted distributions, enabling the learning of more robust representations for zero-shot tasks and ensuring reliable performance. ", "page_idx": 9}, {"type": "text", "text": "While the proposed framework is general, our current experiments address shifts in a binary attribute. We defer exploration of additional scenarios, such as those involving shifts in multiple correlated attributes, to future work. An additional promising direction for future work is the consideration of shifts where the responsible attribute is strongly correlated with additional attributes or covariates. This opens up possibilities to explore structured constructions of synthetic environments that leverage such correlations. ", "page_idx": 9}, {"type": "text", "text": "References ", "text_level": 1, "page_idx": 10}, {"type": "text", "text": "[1] Martin Arjovsky, L\u00e9on Bottou, Ishaan Gulrajani, and David Lopez-Paz. Invariant risk minimization. arXiv preprint arXiv:1907.02893, 2019.   \n[2] Tadas Baltrusaitis, Amir Zadeh, Yao Chong Lim, and Louis-Philippe Morency. Openface 2.0: Facial behavior analysis toolkit. In 2018 13th IEEE international conference on automatic face & gesture recognition (FG 2018), pages 59\u201366. IEEE, 2018.   \n[3] Aharon Ben-Tal, Dick Den Hertog, Anja De Waegenaere, Bertrand Melenberg, and Gijs Rennen. Robust solutions of optimization problems affected by uncertain probabilities. Management Science, 59(2):341\u2013357, 2013.   \n[4] Yoav Benjamini and Yosef Hochberg. Controlling the false discovery rate: a practical and powerful approach to multiple testing. Journal of the Royal statistical society: series B (Methodological), 57(1):289\u2013300, 1995.   \n[5] Lacey Best-Rowden and Anil K Jain. Longitudinal study of automatic face recognition. IEEE transactions on pattern analysis and machine intelligence, 40(1):148\u2013162, 2017.   \n[6] Jonathon Byrd and Zachary Lipton. What is the effect of importance weighting in deep learning? In International conference on machine learning, pages 872\u2013881. PMLR, 2019.   \n[7] Toon Calders and Szymon Jaroszewicz. Efficient auc optimization for classification. In European conference on principles of data mining and knowledge discovery, pages 42\u201353. Springer, 2007.   \n[8] Kaidi Cao, Colin Wei, Adrien Gaidon, Nikos Arechiga, and Tengyu Ma. Learning imbalanced datasets with label-distribution-aware margin loss. Advances in neural information processing systems, 32, 2019.   \n[9] Shiyu Chang, Yang Zhang, Mo Yu, and Tommi Jaakkola. Invariant rationalization. In International Conference on Machine Learning, pages 1448\u20131458. PMLR, 2020.   \n[10] Yin Cui, Menglin Jia, Tsung-Yi Lin, Yang Song, and Serge Belongie. Class-balanced loss based on effective number of samples. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition, pages 9268\u20139277, 2019.   \n[11] Ankit Dhall. Eth entomological collection (ethec) dataset [palearctic macrolepidoptera, spring 2019]. 2019.   \n[12] John C Duchi and Hongseok Namkoong. Learning models with uniform performance via distributionally robust optimization. The Annals of Statistics, 49(3):1378\u20131406, 2021.   \n[13] John C Duchi, Peter W Glynn, and Hongseok Namkoong. Statistics of robust optimization: A generalized empirical likelihood approach. Mathematics of Operations Research, 46(3): 946\u2013969, 2021.   \n[14] Li Fei-Fei, Rob Fergus, and Pietro Perona. One-shot learning of object categories. IEEE transactions on pattern analysis and machine intelligence, 28(4):594\u2013611, 2006.   \n[15] Patrick Grother, Mei Ngan, Kayee Hanaoka, et al. Ongoing face recognition vendor test (frvt) part 3: Demographic effects. Nat. Inst. Stand. Technol., Gaithersburg, MA, USA, Rep. NISTIR, 8280, 2019.   \n[16] Zhangxuan Gu, Siyuan Zhou, Li Niu, Zihan Zhao, and Liqing Zhang. Context-aware feature generation for zero-shot semantic segmentation. In Proceedings of the 28th ACM International Conference on Multimedia, pages 1921\u20131929, 2020.   \n[17] Raia Hadsell, Sumit Chopra, and Yann LeCun. Dimensionality reduction by learning an invariant mapping. In 2006 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR\u201906), volume 2, pages 1735\u20131742. IEEE, 2006.   \n[18] Alexander Hermans, Lucas Beyer, and Bastian Leibe. In defense of the triplet loss for person re-identification. arXiv preprint arXiv:1703.07737, 2017.   \n[19] Alexander Hermans, Lucas Beyer, and Bastian Leibe. In defense of the triplet loss for person re-identification. arXiv preprint arXiv:1703.07737, 2017.   \n[20] Elad Hoffer and Nir Ailon. Deep metric learning using triplet network. In International workshop on similarity-based pattern recognition, pages 84\u201392. Springer, 2015.   \n[21] Badr Youbi Idrissi, Martin Arjovsky, Mohammad Pezeshki, and David Lopez-Paz. Simple data balancing achieves competitive worst-group-accuracy. In Conference on Causal Learning and Reasoning, pages 336\u2013351. PMLR, 2022.   \n[22] Aparna R Joshi, Xavier Suau Cuadros, Nivedha Sivakumar, Luca Zappella, and Nicholas Apostoloff. Fair sa: Sensitivity analysis for fairness in face recognition. In Algorithmic fairness through the lens of causality and robustness workshop, pages 40\u201358. PMLR, 2022.   \n[23] Brendan F Klare, Mark J Burge, Joshua C Klontz, Richard W Vorder Bruegge, and Anil K Jain. Face recognition performance: Role of demographic information. IEEE Transactions on information forensics and security, 7(6):1789\u20131801, 2012.   \n[24] Gregory Koch, Richard Zemel, Ruslan Salakhutdinov, et al. Siamese neural networks for one-shot image recognition. In International Conference on Machine Learning (ICML) deep learning workshop, volume 2, 2015.   \n[25] David Krueger, Ethan Caballero, Joern-Henrik Jacobsen, Amy Zhang, Jonathan Binas, Dinghuai Zhang, Remi Le Priol, and Aaron Courville. Out-of-distribution generalization via risk extrapolation (rex). In International Conference on Machine Learning, pages 5815\u20135826. PMLR, 2021.   \n[26] Aviral Kumar, Sunita Sarawagi, and Ujjwal Jain. Trainable calibration measures for neural networks from kernel mean embeddings. In Jennifer Dy and Andreas Krause, editors, Proceedings of the 35th International Conference on Machine Learning, volume 80 of Proceedings of Machine Learning Research, pages 2805\u20132814. PMLR, 10\u201315 Jul 2018. URL https://proceedings.mlr.press/v80/kumar18a.html.   \n[27] Hugo Larochelle, Dumitru Erhan, and Yoshua Bengio. Zero-data learning of new tasks. In AAAI, volume 1, page 3, 2008.   \n[28] Tsung-Yi Lin, Priya Goyal, Ross Girshick, Kaiming He, and Piotr Doll\u00e1r. Focal loss for dense object detection. In Proceedings of the IEEE international conference on computer vision, pages 2980\u20132988, 2017.   \n[29] Evan Z Liu, Behzad Haghgoo, Annie S Chen, Aditi Raghunathan, Pang Wei Koh, Shiori Sagawa, Percy Liang, and Chelsea Finn. Just train twice: Improving group robustness without training group information. In International Conference on Machine Learning, pages 6781\u20136792. PMLR, 2021.   \n[30] Ziwei Liu, Ping Luo, Xiaogang Wang, and Xiaoou Tang. Deep learning face attributes in the wild. In Proceedings of International Conference on Computer Vision (ICCV), December 2015.   \n[31] Arakaparampil M Mathai and Serge B Provost. Quadratic forms in random variables: theory and applications. (No Title), 1992.   \n[32] Aditya Krishna Menon, Sadeep Jayasumana, Ankit Singh Rawat, Himanshu Jain, Andreas Veit, and Sanjiv Kumar. Long-tail learning via logit adjustment. In International Conference on Learning Representations, 2020.   \n[33] Dana Michalski, Sau Yee Yiu, and Chris Malec. The impact of age and threshold variation on facial recognition algorithm performance using images of children. In 2018 International Conference on Biometrics (ICB), pages 217\u2013224. IEEE, 2018.   \n[34] Kevin Musgrave, Serge Belongie, and Ser-Nam Lim. A metric learning reality check. In Computer Vision\u2013ECCV 2020: 16th European Conference, Glasgow, UK, August 23\u201328, 2020, Proceedings, Part XXV 16, pages 681\u2013699. Springer, 2020.   \n[35] Hyun Oh Song, Yu Xiang, Stefanie Jegelka, and Silvio Savarese. Deep metric learning via lifted structured feature embedding. In Proceedings of the IEEE conference on computer vision and pattern recognition, pages 4004\u20134012, 2016.   \n[36] Jonas Peters, Peter B\u00fchlmann, and Nicolai Meinshausen. Causal inference by using invariant prediction: identification and confidence intervals. Journal of the Royal Statistical Society Series B: Statistical Methodology, 78(5):947\u20131012, 2016.   \n[37] Jonas Peters, Dominik Janzing, and Bernhard Sch\u00f6lkopf. Elements of causal inference: foundations and learning algorithms. The MIT Press, 2017.   \n[38] Vihari Piratla, Praneeth Netrapalli, and Sunita Sarawagi. Focus on the common good: Group distributional robustness follows. In International Conference on Learning Representations, 2021.   \n[39] Inioluwa Deborah Raji and Joy Buolamwini. Actionable auditing: Investigating the impact of publicly naming biased performance results of commercial ai products. In Proceedings of the 2019 AAAI/ACM Conference on AI, Ethics, and Society, pages 429\u2013435, 2019.   \n[40] Jiawei Ren, Cunjun Yu, Xiao Ma, Haiyu Zhao, Shuai Yi, et al. Balanced meta-softmax for longtailed visual recognition. Advances in neural information processing systems, 33:4175\u20134186, 2020.   \n[41] Joseph P Robinson, Gennady Livitz, Yann Henon, Can Qin, Yun Fu, and Samson Timoner. Face recognition: too bias, or not too bias? In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops, pages 0\u20131, 2020.   \n[42] Mateo Rojas-Carulla, Bernhard Sch\u00f6lkopf, Richard Turner, and Jonas Peters. Invariant models for causal transfer learning. The Journal of Machine Learning Research, 19(1):1309\u20131342, 2018.   \n[43] Karsten Roth, Timo Milbich, Samarth Sinha, Prateek Gupta, Bjorn Ommer, and Joseph Paul Cohen. Revisiting training strategies and generalization performance in deep metric learning. In International Conference on Machine Learning, pages 8242\u20138252. PMLR, 2020.   \n[44] Marco Saerens, Patrice Latinne, and Christine Decaestecker. Adjusting the outputs of a classifier to new a priori probabilities: a simple procedure. Neural computation, 14(1):21\u201341, 2002.   \n[45] Shiori Sagawa, Pang Wei Koh, Tatsunori B Hashimoto, and Percy Liang. Distributionally robust neural networks. In International Conference on Learning Representations, 2019.   \n[46] Hidetoshi Shimodaira. Improving predictive inference under covariate shift by weighting the log-likelihood function. Journal of statistical planning and inference, 90(2):227\u2013244, 2000.   \n[47] Tom\u00e1\u0161 Sixta, Julio CS Jacques Junior, Pau Buch-Cardona, Eduard Vazquez, and Sergio Escalera. Fairface challenge at eccv 2020: Analyzing bias in face recognition. In Computer Vision\u2013ECCV 2020 Workshops: Glasgow, UK, August 23\u201328, 2020, Proceedings, Part VI 16, pages 463\u2013481. Springer, 2020.   \n[48] Yuli Slavutsky and Yuval Benjamini. Predicting classification accuracy when adding new unobserved classes. In International Conference on Learning Representations, ICLR, Conference Track Proceedings, 2021.   \n[49] Kihyuk Sohn. Improved deep metric learning with multi-class n-pair loss objective. Advances in neural information processing systems, 29, 2016.   \n[50] Nisha Srinivas, Karl Ricanek, Dana Michalski, David S Bolme, and Michael King. Face recognition algorithm bias: Performance differences on images of children and adults. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition workshops, pages 0\u20130, 2019.   \n[51] Oriol Vinyals, Charles Blundell, Timothy Lillicrap, Daan Wierstra, et al. Matching networks for one shot learning. Advances in neural information processing systems, 29, 2016.   \n[52] Yoav Wald, Amir Feder, Daniel Greenfeld, and Uri Shalit. On calibration and out-of-domain generalization. Advances in neural information processing systems, 34:2215\u20132227, 2021.   \n[53] Mei Wang and Weihong Deng. Mitigating bias in face recognition using skewness-aware reinforcement learning. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition, pages 9322\u20139331, 2020.   \n[54] Mei Wang, Weihong Deng, Jiani Hu, Xunqiang Tao, and Yaohai Huang. Racial faces in the wild: Reducing racial bias by information maximization adaptation network. In Proceedings of the ieee/cvf international conference on computer vision, pages 692\u2013702, 2019.   \n[55] Jiaheng Wei, Harikrishna Narasimhan, Ehsan Amid, Wen-Sheng Chu, Yang Liu, and Abhishek Kumar. Distributionally robust post-hoc classifiers under prior shifts. In International Conference on Learning Representations (ICLR), 2023.   \n[56] Chao-Yuan Wu, R Manmatha, Alexander J Smola, and Philipp Krahenbuhl. Sampling matters in deep embedding learning. In Proceedings of the IEEE international conference on computer vision, pages 2840\u20132848, 2017.   \n[57] Yongqin Xian, Subhabrata Choudhury, Yang He, Bernt Schiele, and Zeynep Akata. Semantic projection network for zero-and few-label semantic segmentation. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 8256\u20138265, 2019.   \n[58] Tongtong Yuan, Weihong Deng, Jian Tang, Yinan Tang, and Binghui Chen. Signal-to-noise ratio: A robust distance metric for deep metric learning. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition, pages 4815\u20134824, 2019.   \n[59] Charles Zheng, Rakesh Achanta, and Yuval Benjamini. Extrapolating expected accuracies for large multi-class problems. The Journal of Machine Learning Research, 19(1):2609\u20132638, 2018.   \n[60] Zhisheng Zhong, Jiequan Cui, Shu Liu, and Jiaya Jia. Improving calibration for long-tailed recognition. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition, pages 16489\u201316498, 2021. ", "page_idx": 10}, {"type": "text", "text": "", "page_idx": 11}, {"type": "text", "text": "", "page_idx": 12}, {"type": "text", "text": "", "page_idx": 13}, {"type": "text", "text": "A Related Work on Class Distribution Shifts in Closed-World Settings ", "text_level": 1, "page_idx": 14}, {"type": "text", "text": "In class-imbalanced learning [28, 10, 8] it is assumed that some classes are more dominant in training, while in deployment this is no longer the case. Therefore, solutions classically include data or loss re-weighting [46, 6, 40, 32] and calibration of the classification score [44, 60]. A popular framework for addressing class distribut ion shifts is distributionally robust optimization (DRO) [3, 13, 12, 55], where instead of assuming a specific probability distribution, a set or range of possible distributions is considered, and optimization is performed to achieve the best results on the worst-case distribution. A special case known as group DRO [45, 38], involves a group variable that introduces discriminatory patterns among classes within specific groups. The framework to address this includes methods that assume that the classifier does not have access to the group information, and therefore propose re-weighting high loss examples [29], and data sub-sampling to balance classes and groups [21]. Nevertheless, the methods mentioned above rely on the training and test class sets being identical, making them unsuitable for direct application in zero-shot learning scenarios. ", "page_idx": 14}, {"type": "text", "text": "B Analysis of the Parametric Model ", "text_level": 1, "page_idx": 14}, {"type": "text", "text": "B.1 Derivation of the Loss ", "text_level": 1, "page_idx": 14}, {"type": "text", "text": "We begin by revisiting the parametric model introduced in $\\S3$ . Let $z_{i}|c_{i}\\,\\sim\\,\\mathcal{N}\\left(c_{i},\\Sigma_{z}\\right)$ , where $\\Sigma_{z}=\\nu_{z}I_{d}$ , $0<\\nu_{z}\\in\\mathbb{R}$ , and $I_{d}$ is the $d$ dimensional identity matrix. Classes $c_{i}$ are drawn according to a Gaussian distribution $\\boldsymbol{c}_{i}\\sim\\mathcal{N}\\left(\\boldsymbol{0},\\boldsymbol{\\Sigma}_{a}\\right)$ corresponding to their type $a\\in\\{a_{1},a_{2}\\}$ . Here, we use a simpler (although less intuitive) notation for the values of the diagonal matrices $\\Sigma_{a}$ : ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\Sigma_{a_{1}}=\\operatorname{diag}\\Big(\\overbrace{\\nu_{0},\\ldots,\\nu_{0}}^{d_{0}},\\overbrace{\\nu_{1},\\ldots,\\nu_{1}}^{d_{1}},\\overbrace{\\nu_{2},\\ldots,\\nu_{2}}^{d_{2}}\\Big)\\Big),}\\\\ &{\\Sigma_{a_{2}}=\\operatorname{diag}\\Big(\\nu_{0},\\ldots,\\nu_{0}\\,,\\nu_{2},\\ldots,\\nu_{2},\\,\\nu_{1},\\ldots,\\nu_{1}\\,\\Big),}\\end{array}\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "where $0<\\nu_{2}<\\nu_{z}<\\nu_{0}<\\nu_{1}$ . ", "page_idx": 14}, {"type": "text", "text": "We consider a weight representations $g(z)\\,=\\,W z$ , where $W$ is a diagonal matrix with diagonal $w\\in\\mathbb{R}^{d}$ . ", "page_idx": 14}, {"type": "text", "text": "Since $\\Sigma_{z}$ is of full rank, it suffices to consider the no-hinge version of the contrastive loss, that is ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\widetilde{\\ell}\\left(z_{i},z_{j},y_{i j};d_{g}\\right):=y_{i j}\\,\\|W\\left(z_{i}-z_{j}\\right)\\|^{4}+\\left(1-y_{i j}\\right)\\left(m-\\|W\\left(z_{i}-z_{j}\\right)\\|^{2}\\right)^{2},}\\end{array}\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "where $d_{g}\\left(z_{i},z_{j}\\right):=\\left\\|g\\left(z_{i}-z_{j}\\right)\\right\\|^{2}=\\left\\|W\\left(z_{i}-z_{j}\\right)\\right\\|^{2}(\\left\\|\\mathbf{\\cdot}\\right\\|$ denotes the Euclidean norm4). ", "page_idx": 14}, {"type": "text", "text": "For a balanced sample of positive and negative examples, the expected loss is given by ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{E}\\left[\\widetilde{\\ell}\\left(z_{i},z_{j},y_{i j};d_{g}\\right)\\right]=\\frac{1}{2}\\mathbb{E}_{y_{i j}=1}\\left[\\Vert W\\left(z_{i}-z_{j}\\right)\\Vert^{4}\\right]}\\\\ &{\\qquad\\qquad\\qquad\\qquad+\\,\\frac{1}{2}\\mathbb{E}_{y_{i j}=0}\\left[m^{2}-2m\\left\\Vert W\\left(z_{i}-z_{j}\\right)\\right\\Vert^{2}+\\left\\Vert W\\left(z_{i}-z_{j}\\right)\\right\\Vert^{4}\\right].}\\end{array}\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "To calculate the expression above, we begin by proving the following lemma: ", "page_idx": 14}, {"type": "text", "text": "Lemma 1. Let $\\mu\\in\\mathbb{R}^{d}$ be a random variable and let $t|\\mu\\sim{\\mathcal{N}}(\\mu,\\Sigma)$ . If $\\mu\\equiv0$ (constant), then ", "page_idx": 14}, {"type": "equation", "text": "$$\nI.\\,\\,\\,\\mathbb{E}\\,\\|t\\|^{4}=2\\,\\mathrm{tr}(\\Sigma^{2})+\\mathrm{tr}^{2}(\\Sigma)\\,.\n$$", "text_format": "latex", "page_idx": 14}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{2.\\ \\mathbb{E}\\,\\|t\\|^{2}=\\operatorname{tr}(\\Sigma)+\\operatorname{tr}(\\Sigma_{\\mu})\\,,}\\\\ &{3.\\ \\mathbb{E}\\,\\|t\\|^{4}=2\\operatorname{tr}(\\Sigma^{2})+4\\operatorname{tr}(\\Sigma\\Sigma_{\\mu})+\\operatorname{tr}^{2}(\\Sigma)+2\\operatorname{tr}(\\Sigma)\\operatorname{tr}(\\Sigma_{\\mu})+2\\operatorname{tr}(\\Sigma_{\\mu}^{2})+\\operatorname{tr}^{2}(\\Sigma_{\\mu})\\,.}\\end{array}\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "Proof. For any random variable $u\\in\\mathbb{R}^{d}$ , such that $\\boldsymbol{u}\\sim\\mathcal{N}(\\boldsymbol{\\mu_{u}},\\boldsymbol{\\Sigma_{u}})$ , and any symmetric matrix $A$ , we have ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{E}_{u}[u^{T}A u]=\\mathrm{tr}(A\\Sigma_{u})+\\mu_{u}^{T}A\\mu_{u},}\\\\ &{\\mathbb{E}_{u}[u^{T}A u]^{2}=2\\,\\mathrm{tr}\\left((A\\Sigma_{u})^{2}\\right)+4\\mu_{u}^{T}A\\Sigma_{u}A\\mu_{u}+\\left(\\,\\mathrm{tr}(A\\Sigma_{u})+\\mu_{u}^{T}A\\mu_{u}\\right)^{2}}\\end{array}\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "(see, for example, Thm. 3.2b.2 in [31]). ", "page_idx": 15}, {"type": "text", "text": "First, letting $\\mu_{u}=0$ , $\\Sigma_{u}=\\Sigma$ and $A=I_{d}$ in (15) we get ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\mathbb{E}\\left\\|t\\right\\|^{4}=\\mathbb{E}[t^{T}t]^{2}=2\\operatorname{tr}(\\Sigma^{2})+\\operatorname{tr}^{2}(\\Sigma).\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "Now, assume that $\\mu\\sim\\mathcal{N}(0,\\Sigma_{\\mu})$ . From (14) we get $\\mathbb{E}_{\\mu}\\,\\|\\mu\\|^{2}=\\mathbb{E}_{\\mu}[\\mu^{T}\\mu]=\\mathrm{tr}(\\Sigma_{\\mu})$ , and thus ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\mathbb{E}\\Vert t\\Vert^{2}=\\mathbb{E}_{\\mu}\\left[\\mathbb{E}_{t|\\mu}[t^{T}t\\mid\\mu]\\right]=\\mathbb{E}_{\\mu}\\left[\\operatorname{tr}(\\Sigma)+\\mu^{T}\\mu\\right]=\\operatorname{tr}(\\Sigma)+\\operatorname{tr}(\\Sigma_{\\mu}).\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "Similarly, from (15) we have ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\Sigma\\,\\|t\\|^{4}=\\mathbb{E}_{\\mu}\\left[\\mathbb{E}_{t\\mid\\mu}[[t^{T}t]^{2}\\mid\\mu]\\right]=2\\operatorname{tr}(\\Sigma^{2})+4\\,\\mathbb{E}_{\\mu}[\\mu^{T}\\Sigma\\mu]+\\operatorname{tr}^{2}(\\Sigma)+2\\operatorname{tr}(\\Sigma)\\,\\mathbb{E}_{\\mu}\\,\\|\\mu\\|^{2}+\\mathbb{E}_{\\mu}\\,\\|\\mu\\|^{4}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "By substituting $A=\\Sigma$ in (14) we get $\\mathbb{E}_{\\mu}[\\mu^{T}\\Sigma\\mu]=\\mathrm{tr}(\\Sigma\\Sigma_{\\mu})$ , and from (15) we have ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\mathbb{E}_{\\mu}\\,\\|\\mu\\|^{4}=2\\operatorname{tr}(\\Sigma_{\\mu}^{2})+\\operatorname{tr}^{2}(\\Sigma_{\\mu}).\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "Therefore, ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\mathbb{E}\\Vert t\\Vert^{4}=2\\operatorname{tr}(\\Sigma^{2})+4\\operatorname{tr}(\\Sigma\\Sigma_{\\mu})+\\operatorname{tr}^{2}(\\Sigma)+2\\operatorname{tr}(\\Sigma)\\operatorname{tr}(\\Sigma_{\\mu})+2\\operatorname{tr}(\\Sigma_{\\mu}^{2})+\\operatorname{tr}^{2}(\\Sigma_{\\mu}).\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "Note that $W\\left(z_{i}-z_{j}\\right)\\sim\\mathcal{N}\\left(\\boldsymbol{\\mu},\\boldsymbol{\\Sigma}\\right)$ , with $\\mu=W\\left(c_{i}-c_{j}\\right)$ and $\\Sigma=2\\nu_{z}W^{T}W$ . ", "page_idx": 15}, {"type": "text", "text": "If $y_{i j}=1$ , then $z_{i}$ and $z_{j}$ are from the same class, meaning that $c_{i}=c_{j}$ and thus $\\mu=0$ . Therefore, by Lemma 1.(1) we have ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{E}_{y_{i j}=1}\\left\\|W\\left(z_{i}-z_{j}\\right)\\right\\|^{4}=2\\operatorname{tr}\\left(\\Sigma^{2}\\right)+\\operatorname{tr}^{2}\\left(\\Sigma\\right)}\\\\ &{\\qquad\\qquad\\qquad\\qquad=2\\cdot4\\nu_{z}^{2}\\operatorname{tr}\\left(\\left[W^{T}W\\right]^{2}\\right)+4\\nu_{z}^{2}\\operatorname{tr}^{2}\\left(W^{T}W\\right)}\\\\ &{\\qquad\\qquad\\qquad\\qquad=8\\nu_{z}^{2}\\displaystyle\\sum_{i=1}^{d}w_{i}^{4}+4\\nu_{z}^{2}\\left(\\displaystyle\\sum_{i=1}^{d}w_{i}^{2}\\right)^{2}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "However, for pairs from different classes, that is, when $y_{i j}\\,=\\,0$ , the mean $\\mu$ is itself a Gaussian random variable distributed according to $\\mathcal{N}\\left(0,\\Sigma_{\\mu}\\right)$ , where ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\Sigma_{\\mu}=\\left\\{\\!\\!\\begin{array}{l l}{{W^{T}\\left(2\\Sigma_{a_{1}}\\right)W}}&{{c_{i},c_{j}\\mathrm{~are~both~of~type~}a_{1}}}\\\\ {{W^{T}\\left(2\\Sigma_{a_{2}}\\right)W}}&{{c_{i},c_{j}\\mathrm{~are~both~of~type~}a_{2}}}\\\\ {{W^{T}\\left(\\Sigma_{a_{1}}+\\Sigma_{a_{2}}\\right)W}}&{{c_{i},c_{j}\\mathrm{~are~of~different~types~}.}}\\end{array}\\!\\!\\right.\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "Therefore, by Lemma 1.(2) we have ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathfrak{L}_{y_{i j}=0}\\left\\|W\\left(z_{i}-z_{j}\\right)\\right\\|^{2}=\\mathfrak{L}_{y_{i j}=0}\\left[\\mathrm{tr}\\left(\\Sigma_{\\mu}\\right)+\\mathrm{tr}\\left(\\Sigma\\right)\\right]=\\mathfrak{L}_{y_{i j}=0}\\left[\\mathrm{tr}\\left(\\Sigma_{\\mu}\\right)\\right]+\\mathrm{tr}\\left(\\Sigma\\right)}\\\\ &{\\qquad\\qquad\\qquad=\\rho^{2}\\operatorname{tr}\\left(2W^{T}\\Sigma_{a_{1}}W\\right)+\\left(1-\\rho\\right)^{2}\\mathrm{tr}\\left(2W^{T}\\Sigma_{a_{2}}W\\right)}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\qquad+\\,2\\rho(1-\\rho)\\operatorname{tr}\\left(W^{T}\\left(\\Sigma_{a_{1}}+\\Sigma_{a_{2}}\\right)W\\right)+\\mathrm{tr}\\left(\\Sigma\\right)}\\\\ &{\\qquad\\qquad\\qquad\\qquad=2\\left[(\\nu_{0}+\\nu_{z})\\displaystyle\\sum_{i=1}^{d_{0}}w_{i}^{2}+(\\alpha_{1}+\\nu_{z})\\displaystyle\\sum_{i=d_{0}+1}^{d_{0}+d_{1}}w_{i}^{2}+(\\alpha_{2}+\\nu_{z})\\displaystyle\\sum_{i=d_{0}+d_{1}+1}^{d}w_{i}^{2}\\right],}\\end{array}\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "where ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\alpha_{1}:=\\rho^{2}\\nu_{1}+\\left(1-\\rho\\right)^{2}\\nu_{2}+\\rho(1-\\rho)\\left(\\nu_{1}+\\nu_{2}\\right)=\\rho\\nu_{1}+(1-\\rho)\\,\\nu_{2},}\\\\ &{\\alpha_{2}:=\\rho^{2}\\nu_{2}+\\left(1-\\rho\\right)^{2}\\nu_{1}+\\rho(1-\\rho)\\left(\\nu_{1}+\\nu_{2}\\right)=\\rho\\nu_{2}+(1-\\rho)\\,\\nu_{1},}\\\\ &{\\beta_{1}:=2\\rho^{2}\\nu_{1}^{2}+2(1-\\rho)^{2}\\nu_{2}^{2}+\\rho(1-\\rho)\\left(\\nu_{1}+\\nu_{2}\\right)^{2},}\\\\ &{\\beta_{2}:=2\\rho^{2}\\nu_{2}^{2}+2(1-\\rho)^{2}\\nu_{1}^{2}+\\rho(1-\\rho)\\left(\\nu_{1}+\\nu_{2}\\right)^{2}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "By Lemma 1.(3) we have ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{E}_{y_{i j}=0}\\left\\|w\\left(z_{i}-z_{j}\\right)\\right\\|^{4}=\\mathbb{E}_{y_{i j}=0}\\Big[2\\operatorname{tr}\\left(\\Sigma^{2}\\right)+4\\operatorname{tr}\\left(\\Sigma\\Sigma_{\\mu}\\right)+\\operatorname{tr}^{2}(\\Sigma)+2\\operatorname{tr}\\left(\\Sigma\\right)\\operatorname{tr}\\left(\\Sigma_{\\mu}\\right)}\\\\ &{\\qquad\\qquad\\qquad\\qquad+2\\operatorname{tr}\\left(\\Sigma_{\\mu}^{2}\\right)+\\left(\\operatorname{tr}\\left(\\Sigma_{\\mu}\\right)\\right)^{2}\\Big]}\\\\ &{\\qquad\\qquad\\qquad\\qquad=2\\operatorname{tr}(\\Sigma^{2})+4\\mathbb{E}_{y_{i j}=0}[\\operatorname{tr}(\\Sigma\\Sigma_{\\mu})]+\\operatorname{tr}^{2}(\\Sigma)+2\\operatorname{tr}(\\Sigma)\\mathbb{E}_{y_{i j}=0}[\\operatorname{tr}(\\Sigma_{\\mu})]}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\qquad+\\operatorname{\\mathbb{2}}\\mathbb{E}_{y_{i j}=0}[\\operatorname{tr}(\\Sigma_{\\mu}^{2})]+\\mathbb{E}_{y_{i j}=0}[\\operatorname{tr}^{2}(\\Sigma_{\\mu})],}\\end{array}\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "where ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\displaystyle\\mathbb{E}_{y_{i j}=0}\\left[\\mathrm{tr}\\left(\\Sigma\\Sigma_{\\mu}\\right)\\right]=2\\nu_{z}\\operatorname{tr}\\!\\left(W^{T}W\\left[2\\rho^{2}W^{T}\\Sigma_{a_{1}}W+2(1-\\rho)^{2}W^{T}\\Sigma_{a_{2}}W\\right.\\right.}\\\\ &{\\displaystyle\\left.\\phantom{\\sum{\\sum{\\mu}}}+2\\rho(1-\\rho)W^{T}\\left(\\Sigma_{a_{1}}+\\Sigma_{a_{2}}\\right)W\\right]\\right)}\\\\ &{\\displaystyle\\qquad\\qquad\\qquad\\quad=4\\nu_{z}\\left[\\nu_{0}\\sum_{i=1}^{d_{0}}w_{i}^{4}+\\alpha_{1}\\sum_{i=d_{0}+1}^{d_{0}+d_{1}}w_{i}^{4}+\\alpha_{2}\\sum_{i=d_{0}+d_{1}+1}^{d}w_{i}^{4}\\right];}\\end{array}\n$$", "text_format": "latex", "page_idx": 16}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{E}_{y_{i j}=0}\\left[\\mathrm{tr}\\left(\\boldsymbol{\\Sigma}_{\\mu}\\right)\\right]=\\!\\rho^{2}\\,\\mathrm{tr}\\left(2W^{T}\\Sigma_{a_{1}}W\\right)+(1-\\rho)^{2}\\,\\mathrm{tr}\\left(2W^{T}\\Sigma_{a_{1}}W\\right)}\\\\ &{\\phantom{=}\\,+2\\rho(1-\\rho)\\,\\mathrm{tr}\\left(W^{T}\\left(\\Sigma_{a_{1}}+\\Sigma_{a_{2}}\\right)W\\right)}\\\\ &{\\phantom{=}\\,\\;\\;\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,}\\\\ &{\\phantom{=}\\;\\;\\;\\;\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,}\\end{array}\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "and so ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\operatorname{tr}\\left(\\Sigma\\right)\\mathbb{E}_{y_{i j}=0}\\left[\\operatorname{tr}\\left(\\Sigma_{\\mu}\\right)\\right]=4\\nu_{z}\\left(\\sum_{i=1}^{d}w_{i}^{2}\\right)\\left[\\nu_{0}\\sum_{i=1}^{d_{0}}w_{i}^{2}+\\alpha_{1}\\sum_{i=d_{0}+1}^{d_{0}+d_{1}}w_{i}^{2}+\\alpha_{2}\\sum_{i=d_{0}+d_{1}+1}^{d}w_{i}^{2}\\right];\n$$", "text_format": "latex", "page_idx": 16}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{E}_{y_{i j}=0}\\left[\\mathrm{tr}\\left(\\Sigma_{\\mu}^{2}\\right)\\right]=\\!\\rho^{2}\\mathrm{tr}\\left((2W^{T}\\Sigma_{a_{1}}W)^{2}\\right)+(1-\\rho)^{2}\\mathrm{tr}\\left((2W^{T}\\Sigma_{a_{2}}W)^{2}\\right)}\\\\ &{\\phantom{=}\\;+2\\rho(1-\\rho)\\operatorname{tr}\\left((W^{T}\\left(\\Sigma_{a_{1}}+\\Sigma_{a_{2}}\\right)W)^{2}\\right)}\\\\ &{\\phantom{=}=\\!2\\left[2\\nu_{0}^{2}\\displaystyle\\sum_{i=1}^{d_{0}}w_{i}^{4}+\\beta_{1}\\displaystyle\\sum_{i=d_{0}+1}^{d_{0}+d_{1}}w_{i}^{4}+\\beta_{2}\\displaystyle\\sum_{i=d_{0}+d_{1}+1}^{d}w_{i}^{4}\\right];}\\end{array}\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "and similarly ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\begin{array}{c}{{\\mathbb{E}_{y_{i j}=0}\\left[\\mathrm{tr^{2}}\\left(\\Sigma_{\\mu}\\right)\\right]=2\\left[2\\nu_{0}^{2}\\left(\\displaystyle\\sum_{i=1}^{d_{0}}\\nu_{i}^{2}\\right)^{2}+\\beta_{1}\\left(\\displaystyle\\sum_{i=d_{0}+1}^{d_{0}+d_{1}}\\nu_{i}^{2}\\right)^{2}+\\beta_{2}\\left(\\displaystyle\\sum_{i=d_{0}+d_{1}+1}^{d}w_{i}^{2}\\right)^{2}\\right]}}\\\\ {{+\\,4\\gamma_{0,1}\\displaystyle\\sum_{i=1}^{d_{0}}w_{i}^{2}\\displaystyle\\sum_{i=d_{0}+1}^{d_{0}+d_{1}}w_{i}^{2}+4\\gamma_{0,2}\\displaystyle\\sum_{i=1}^{d_{0}}w_{i}^{2}\\displaystyle\\sum_{i=d_{0}+d_{1}+1}^{d}w_{i}^{2}}}\\\\ {{+\\,4\\gamma_{1,2}\\displaystyle\\sum_{i=d_{0}+1}^{d_{0}+d_{1}}w_{i}^{2}\\displaystyle\\sum_{i=d_{0}+d_{1}+1}^{d}w_{i}^{2}\\right]},}\\end{array}\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "where we denote for short ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\gamma_{0,1}:=\\rho^{2}\\nu_{0}\\nu_{1}+(1-\\rho)^{2}\\nu_{0}\\nu_{2}+\\rho(1-\\rho)\\nu_{0}\\left(\\nu_{1}+\\nu_{2}\\right),}\\\\ &{\\gamma_{0,2}:=\\rho^{2}\\nu_{0}\\nu_{2}+(1-\\rho)^{2}\\nu_{0}\\nu_{1}+\\rho(1-\\rho)\\nu_{0}\\left(\\nu_{1}+\\nu_{2}\\right),}\\\\ &{\\gamma_{1,2}:=\\rho^{2}\\nu_{1}\\nu_{2}+(1-\\rho)^{2}\\nu_{1}\\nu_{2}+\\displaystyle\\frac{1}{2}\\rho(1-\\rho)\\left(\\nu_{1}+\\nu_{2}\\right)^{2}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "Finally, due to symmetry, at the optimal solution we have ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\begin{array}{r}{w_{i}=\\left\\{u_{0}\\quad0\\leq i\\leq d_{0}\\right.}\\\\ {w_{1}}&{\\left.d_{0}+1\\leq i\\leq d_{0}+d_{1}\\right.}\\\\ {u_{2}}&{\\left.d_{0}+d_{1}+1\\leq i\\leq d,}\\end{array}\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "and by combining these results, we get ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\mathbb{E}\\left[\\widetilde{\\ell}\\left(z_{i},z_{j},y_{i j};d_{g}\\right)\\right]=d_{0}u_{0}^{4}\\left(8\\nu_{z}^{2}+8\\nu_{z}\\nu_{0}+4\\nu_{0}^{2}+2\\nu_{0}^{2}d_{0}\\right)}&{}\\\\ {+\\;d_{1}u_{1}^{4}\\left(8\\nu_{z}^{2}+8\\nu_{z}\\alpha_{1}+2\\beta_{1}+\\beta_{1}d_{1}\\right)}&{}\\\\ {+\\;d_{2}u_{2}^{4}\\left(8\\nu_{z}^{2}+8\\nu_{z}\\alpha_{2}+2\\beta_{2}+\\beta_{2}d_{2}\\right)}\\\\ {-\\;2d_{0}u_{0}^{2}\\left(\\nu_{0}+\\nu_{z}\\right)-2d_{1}u_{1}^{2}\\left(\\alpha_{1}+\\nu_{z}\\right)-2d_{2}u_{2}^{2}\\left(\\alpha_{2}+\\nu_{z}\\right)}&{}\\\\ {+\\;4\\nu_{z}^{2}\\left(d_{0}u_{0}^{2}+d_{1}u_{1}^{2}+d_{2}u_{2}^{2}\\right)^{2}+\\frac{1}{2}m}\\\\ {+\\;4\\nu_{z}\\left(d_{0}u_{0}^{2}+d_{1}u_{1}^{2}+d_{2}u_{2}^{2}\\right)\\left[\\nu_{0}d_{0}u_{0}^{2}+\\alpha_{1}d_{1}u_{1}^{2}+\\alpha_{2}d_{2}u_{2}^{2}\\right]}&{}\\\\ {+\\;4\\gamma_{0,1}d_{0}d_{1}u_{0}^{2}u_{1}^{2}+4\\gamma_{0,2}d_{0}d_{2}u_{0}^{2}u_{2}^{2}+4\\gamma_{1,2}d_{1}d_{2}u_{1}^{2}u_{2}^{2}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "B.2 Analysis of the Optimal Solution (Proof of Proposition 1) ", "text_level": 1, "page_idx": 17}, {"type": "text", "text": "Proposition 1 shows that when $d_{1}$ and $d_{2}$ are relatively similar, the optimal solution on the training distribution, assigns more weight to components with high variance in the training data than to those with high variance in the shifted test distribution. ", "page_idx": 17}, {"type": "text", "text": "We begin by defining the required condition on $d_{1}$ and $d_{2}$ . Denote ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\psi_{1}:=2\\nu_{z}^{2}+2\\nu_{z}\\alpha_{1}+\\beta_{1}}\\\\ &{\\psi_{2}:=2\\nu_{z}^{2}+2\\nu_{z}\\alpha_{2}+\\beta_{2}}\\\\ &{\\eta_{01}:=4\\nu_{z}^{2}+2\\nu_{z}\\left(\\alpha_{1}+\\nu_{0}\\right)+2\\gamma_{0,1}}\\\\ &{\\eta_{02}:=4\\nu_{z}^{2}+2\\nu_{z}\\left(\\alpha_{2}+\\nu_{0}\\right)+2\\gamma_{0,2}}\\\\ &{\\eta_{12}:=4\\nu_{z}^{2}+2\\nu_{z}\\left(\\alpha_{1}+\\alpha_{2}\\right)+2\\gamma_{1,2}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "Then for $\\alpha,\\beta,\\gamma$ values as in equations 24 and 31, we define ", "page_idx": 17}, {"type": "equation", "text": "$$\nh_{l}\\left(\\rho,\\nu_{z},\\nu_{0},\\nu_{1},\\nu_{2}\\right):=\\frac{\\psi_{1}}{\\psi_{2}}\\frac{\\left(\\alpha_{2}+\\nu_{z}\\right)}{\\left(\\alpha_{1}+\\nu_{z}\\right)},\\quad h_{u}\\left(\\rho,\\nu_{z},\\nu_{0},\\nu_{1},\\nu_{2}\\right):=\\frac{\\psi_{1}}{\\psi_{2}}\\frac{\\eta_{02}}{\\eta_{01}},\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "and the corresponding condition ", "page_idx": 17}, {"type": "equation", "text": "$$\nh_{l}\\left(\\rho,\\nu_{z},\\nu_{0},\\nu_{1},\\nu_{2}\\right)<{\\frac{d_{2}+2}{d_{1}+2}}<h_{u}\\left(\\rho,\\nu_{z},\\nu_{0},\\nu_{1},\\nu_{2}\\right).\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "While this condition is sufficient, it is not necessary.Values of $\\rho,\\nu_{z},\\nu_{0},\\nu_{1},\\nu_{2}$ and $d_{1},d_{2}$ that satisfy 35 provide an example requiring only a simple analysis, without a full characterization of the optimal solution, for the failure of optimization over the training distribution. However, such failures can occur for additional parameter values, and the full characterization is provided in Appendix B.3. ", "page_idx": 17}, {"type": "text", "text": "Proof. Without loss of generality assume $\\mathrm{m}{=}1$ . Then, ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\begin{array}{r l r}{\\lefteqn{\\frac{\\partial\\mathbb{E}\\left[\\tilde{\\ell}\\left(z_{i},z_{j},y_{i j};d_{g}\\right)\\right]}{\\partial u_{0}^{2}}=2d_{0}u_{0}^{2}\\left(8\\nu_{z}^{2}+8\\nu_{z}\\nu_{0}+4\\nu_{0}^{2}+2\\nu_{0}^{2}d_{0}\\right)}}\\\\ &{}&{-2d_{0}\\left(\\nu_{0}+\\nu_{z}\\right)}\\\\ &{}&{+\\,8d_{0}\\nu_{z}^{2}\\left(d_{0}u_{0}^{2}+d_{1}u_{1}^{2}+d_{2}u_{2}^{2}\\right)}\\\\ &{}&{+\\,4d_{0}\\nu_{z}\\left(\\nu_{0}d_{0}u_{0}^{2}+\\alpha_{1}d_{1}u_{1}^{2}+\\alpha_{2}d_{2}u_{2}^{2}\\right)}\\\\ &{}&{+\\,4d_{0}\\nu_{z}\\nu_{0}\\left(d_{0}u_{0}^{2}+d_{1}u_{1}^{2}+d_{2}u_{2}^{2}\\right)}\\\\ &{}&{+\\,4\\gamma_{0,1}d_{0}d_{1}u_{1}^{2}+4\\gamma_{0,2}d_{0}d_{2}^{2}}\\end{array}\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "and by setting the partial derivative to zero we get ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{2u_{0}^{2}\\left(2+d_{0}\\right)\\left(2\\nu_{z}^{2}+2\\nu_{z}\\nu_{0}+\\nu_{0}^{2}\\right)=2d_{1}u_{1}^{2}\\left(2\\nu_{z}^{2}+\\nu_{z}\\left(\\alpha_{1}+\\nu_{0}\\right)+\\gamma_{0,1}\\right)}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad+2d_{2}u_{2}^{2}\\left(2\\nu_{z}^{2}+\\nu_{z}\\left(\\alpha_{2}+\\nu_{0}\\right)+\\gamma_{0,2}\\right)-\\left(\\nu_{0}+\\nu_{z}\\right).}\\end{array}\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "Therefore, ", "page_idx": 18}, {"type": "equation", "text": "$$\nu_{0}^{2}=\\frac{\\nu_{0}+\\nu_{z}-\\eta_{01}d_{1}u_{1}^{2}-\\eta_{02}d_{2}u_{2}^{2}}{2\\left(2+d_{0}\\right)\\left(2\\nu_{z}^{2}+2\\nu_{z}\\nu_{0}+\\nu_{0}^{2}\\right)}.\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "and similarly ", "text_level": 1, "page_idx": 18}, {"type": "equation", "text": "$$\n\\begin{array}{l}{{\\displaystyle{u_{1}^{2}=\\frac{\\left(\\alpha_{1}+\\nu_{z}\\right)-\\eta_{01}d_{0}u_{0}^{2}-\\eta_{12}d_{2}u_{2}^{2}}{2\\left(2+d_{1}\\right)\\left(2\\nu_{z}^{2}+2\\nu_{z}\\alpha_{1}+\\beta_{1}\\right)}}}}\\\\ {{\\displaystyle{u_{2}^{2}=\\frac{\\left(\\alpha_{2}+\\nu_{z}\\right)-\\eta_{02}d_{0}u_{0}^{2}-\\eta_{12}d_{1}u_{1}^{2}}{2\\left(2+d_{2}\\right)\\left(2\\nu_{z}^{2}+2\\nu_{z}\\alpha_{2}+\\beta_{2}\\right)}}.}}\\end{array}\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "Hence, ", "text_level": 1, "page_idx": 18}, {"type": "equation", "text": "$$\n\\begin{array}{r l r}&{}&{d_{1}u_{1}^{2}-d_{2}u_{2}^{2}=\\frac{\\left(2+d_{2}\\right)\\,\\left(2\\nu_{z}^{2}+2\\nu_{z}\\alpha_{2}+\\beta_{2}\\right)\\,\\left[d_{1}\\left(\\alpha_{1}+\\nu_{z}\\right)-\\eta_{01}d_{1}d_{0}u_{0}^{2}-\\eta_{12}d_{1}d_{2}u_{2}^{2}\\right]}{2\\,\\left(2+d_{1}\\right)\\,\\left(2+d_{2}\\right)\\,\\left(2\\nu_{z}^{2}+2\\nu_{z}\\alpha_{1}+\\beta_{1}\\right)\\,\\left(2\\nu_{z}^{2}+2\\nu_{z}\\alpha_{2}+\\beta_{2}\\right)}}\\\\ &{}&{-\\,\\frac{\\left(2+d_{1}\\right)\\,\\left(2\\nu_{z}^{2}+2\\nu_{z}\\alpha_{1}+\\beta_{1}\\right)\\,\\left[d_{2}\\left(\\alpha_{2}+\\nu_{z}\\right)-\\eta_{02}d_{2}d_{0}u_{0}^{2}-\\eta_{12}d_{1}d_{2}u_{1}^{2}\\right]}{2\\,\\left(2+d_{1}\\right)\\,\\left(2+d_{2}\\right)\\,\\left(2\\nu_{z}^{2}+2\\nu_{z}\\alpha_{1}+\\beta_{1}\\right)\\,\\left(2\\nu_{z}^{2}+2\\nu_{z}\\alpha_{2}+\\beta_{2}\\right)}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "Denoting ", "text_level": 1, "page_idx": 18}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\xi:=2\\left(2+d_{1}\\right)\\left(2+d_{2}\\right)\\left(2\\nu_{z}^{2}+2\\nu_{z}\\alpha_{1}+\\beta_{1}\\right)\\left(2\\nu_{z}^{2}+2\\nu_{z}\\alpha_{2}+\\beta_{2}\\right)}\\\\ &{\\quad=2\\left(2+d_{1}\\right)\\left(2+d_{2}\\right)\\psi_{1}\\psi_{2}}\\end{array}\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "we have ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\begin{array}{c}{{d_{1}u_{1}^{2}\\displaystyle\\left[1-\\frac{1}{\\xi}\\left(2+d_{1}\\right)\\psi_{1}\\eta_{12}\\right]=\\!d_{2}u_{2}^{2}\\left[1-\\frac{1}{\\xi}\\left(2+d_{2}\\right)\\psi_{2}\\eta_{12}\\right]}}\\\\ {{\\displaystyle+\\frac{1}{\\xi}\\left(2+d_{2}\\right)\\psi_{2}\\left(\\alpha_{1}+\\nu_{z}\\right)-\\frac{1}{\\xi}\\left(2+d_{1}\\right)\\psi_{1}\\left(\\alpha_{2}+\\nu_{z}\\right)}}\\\\ {{\\displaystyle+d_{0}u_{0}^{2}\\left[\\frac{1}{\\xi}\\left(2+d_{1}\\right)\\psi_{1}\\eta_{02}-\\frac{1}{\\xi}\\left(2+d_{2}\\right)\\psi_{2}\\eta_{01}\\right]}}\\end{array}\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "and therefore ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\begin{array}{c}{{\\displaystyle I_{1}u_{1}^{2}-d_{2}u_{2}^{2}=d_{2}u_{2}^{2}\\left(\\frac{1-\\frac{1}{\\xi}\\left(2+d_{2}\\right)\\psi_{2}\\eta_{12}}{1-\\frac{1}{\\xi}\\left(2+d_{1}\\right)\\psi_{1}\\eta_{12}}-1\\right)}}\\\\ {{\\displaystyle+\\frac{1}{2\\left(2+d_{1}\\right)\\left(2+d_{2}\\right)\\psi_{1}\\psi_{2}}\\frac{\\left(2+d_{2}\\right)\\psi_{2}\\left(\\alpha_{1}+\\nu_{z}\\right)-\\left(2+d_{1}\\right)\\psi_{1}\\left(\\alpha_{2}+\\nu_{z}\\right)}{1-\\frac{1}{\\xi}\\left(2+d_{1}\\right)\\psi_{1}\\eta_{12}}}}\\\\ {{\\displaystyle+d_{0}u_{0}^{2}\\frac{1}{2\\left(2+d_{1}\\right)\\left(2+d_{2}\\right)\\psi_{1}\\psi_{2}}\\left[\\frac{\\left(2+d_{1}\\right)\\psi_{1}\\eta_{02}}{1-\\frac{1}{\\xi}\\left(2+d_{1}\\right)\\psi_{1}\\eta_{12}}-\\frac{\\left(2+d_{2}\\right)\\psi_{2}\\eta_{01}}{1-\\frac{1}{\\xi}\\left(2+d_{1}\\right)\\psi_{1}\\eta_{12}}\\right].}}\\end{array}\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "Denote ", "text_level": 1, "page_idx": 19}, {"type": "equation", "text": "$$\n\\begin{array}{c}{{\\Delta=\\left(2+d_{1}\\right)\\left[d_{2}u_{2}^{2}\\eta_{12}\\psi_{1}-\\left(\\alpha_{2}+\\nu_{z}\\right)\\psi_{1}+d_{0}u_{0}^{2}\\psi_{1}\\eta_{02}\\right]}}\\\\ {{-\\left(2+d_{2}\\right)\\left[d_{2}u_{2}^{2}\\eta_{12}\\psi_{2}-\\left(\\alpha_{1}+\\nu_{z}\\right)\\psi_{2}+d_{0}u_{0}^{2}\\psi_{2}\\eta_{01}\\right],}}\\end{array}\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "and thus ", "page_idx": 19}, {"type": "equation", "text": "$$\nd_{1}u_{1}^{2}-d_{2}u_{2}^{2}=\\frac{1}{2\\left(2+d_{1}\\right)\\left(2+d_{2}\\right)\\psi_{1}\\psi_{2}}\\frac{1}{1-\\frac{1}{\\xi}\\left(2+d_{1}\\right)\\psi_{1}\\eta_{12}}\\Delta.\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "Note that for $d_{1},d_{2}$ such that ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\left\\{\\left(2+d_{1}\\right)\\psi_{1}-\\left(2+d_{2}\\right)\\psi_{2}>0\\right.}\\\\ &{\\left\\{\\left(2+d_{2}\\right)\\left(\\alpha_{1}+\\nu_{z}\\right)\\psi_{2}-\\left(2+d_{1}\\right)\\left(\\alpha_{2}+\\nu_{z}\\right)\\psi_{1}>0\\right.}\\\\ &{\\left.\\left(2+d_{1}\\right)\\psi_{1}\\eta_{02}-\\left(2+d_{2}\\right)\\psi_{2}\\eta_{01}>0}\\\\ &{\\Rightarrow\\frac{d_{2}+2}{d_{1}+2}<\\frac{\\psi_{1}}{\\psi_{2}}\\frac{\\eta_{02}}{\\eta_{01}}}\\end{array}\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "we have $\\Delta>0$ . Since $\\begin{array}{r}{\\frac{\\eta_{02}}{\\eta_{01}}<1}\\end{array}$ , this reduces to the last two conditions and therefore, in particular for ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\frac{\\psi_{1}}{\\psi_{2}}\\frac{\\left(\\alpha_{2}+\\nu_{z}\\right)}{\\left(\\alpha_{1}+\\nu_{z}\\right)}<\\frac{d_{2}+2}{d_{1}+2}<\\frac{\\psi_{1}}{\\psi_{2}}\\frac{\\eta_{02}}{\\eta_{01}}\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "we have $\\Delta>0$ . Additionally, note that ", "page_idx": 19}, {"type": "equation", "text": "$$\n1-\\frac{1}{\\xi}\\left(2+d_{1}\\right)\\psi_{1}\\eta_{12}=1-\\frac{\\eta_{12}}{2\\left(2+d_{1}\\right)\\left(2+d_{2}\\right)\\psi_{1}\\psi_{2}}\\left(2+d_{1}\\right)\\psi_{1}=\\frac{2\\left(2+d_{2}\\right)\\psi_{2}-\\eta_{12}}{2\\left(2+d_{2}\\right)\\psi_{2}}\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "and thus $\\begin{array}{r}{1-\\frac{1}{\\xi}\\left(2+d_{1}\\right)\\psi_{1}\\eta_{12}>0}\\end{array}$ iff ", "page_idx": 19}, {"type": "equation", "text": "$$\nd_{2}+2>\\frac{1}{2}\\frac{\\eta_{12}}{\\psi_{2}}.\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "Combining these conditions reduces to ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\frac{\\psi_{1}}{\\psi_{2}}\\frac{\\left(\\alpha_{2}+\\nu_{z}\\right)}{\\left(\\alpha_{1}+\\nu_{z}\\right)}<\\frac{d_{2}+2}{d_{1}+2}<\\frac{\\psi_{1}}{\\psi_{2}}\\frac{\\eta_{02}}{\\eta_{01}},\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "and therefore, for $\\nu_{z},\\nu_{0},\\nu_{1},\\nu_{2},d_{1},d_{2}$ satisfying ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\frac{\\psi_{1}}{\\psi_{2}}\\frac{\\left(\\alpha_{2}+\\nu_{z}\\right)}{\\left(\\alpha_{1}+\\nu_{z}\\right)}<\\frac{d_{2}+2}{d_{1}+2}<\\frac{\\psi_{1}}{\\psi_{2}}\\frac{\\eta_{02}}{\\eta_{01}}.\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "we have $d_{1}u_{1}^{2}-d_{2}u_{2}^{2}>0$ .5 ", "page_idx": 19}, {"type": "text", "text": "B.3 Explicit Expression for the Optimal Representation ", "text_level": 1, "page_idx": 20}, {"type": "text", "text": "In order to derive the optimal representation, we differentiate the expected loss with respect to the squared values in the diagonal of $W$ , that is, $w_{i}^{2}$ : ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\begin{array}{r l r}{\\frac{\\partial}{\\partial\\left(w_{i}^{2}\\right)}w\\left(x^{2}\\right)=s_{i}^{2}w_{i}^{2}w_{j}^{2}}&{}&{\\textmd{(S)}}\\\\ {\\frac{\\partial}{\\partial\\left(w_{i}^{2}\\right)}w^{2}\\left(\\sum\\right)=s_{i}^{2}\\frac{1}{\\partial x_{i}^{2}}\\frac{w^{2}}{w_{i}^{2}}}&{}&{\\textmd{(S)}}\\\\ {\\frac{\\partial}{\\partial\\left(w_{i}^{2}\\right)}\\operatorname{E}_{p\\in\\{w_{i}^{2}\\}}w\\left(\\sum\\frac{\\ln\\rho_{1}w_{i}\\equiv w_{j}^{2}}{\\ln\\rho_{1}w_{i}^{2}},}&{\\textrm{I S}i\\leq d_{0}\\phantom{)}}&{\\textmd{(S)}}\\\\ {\\frac{\\partial}{\\partial\\left(w_{i}^{2}\\right)}\\operatorname{E}_{p\\in\\{w_{i}^{2}\\}}w\\left(\\sum\\frac{\\ln\\rho_{1}w_{i}\\equiv w_{j}^{2}}{\\ln\\rho_{1}w_{i}^{2}},}&{\\textrm{(O+1)}\\leq i\\leq d_{0}\\phantom{)}}&{\\textmd{(S)}}\\\\ {\\frac{\\partial}{\\partial\\left(w_{i}^{2}\\right)}\\operatorname{E}_{p\\in\\{w_{i}^{2}\\}}w\\left(\\sum\\right)=}&{}&{\\textmd{(S)}}\\\\ {\\left\\{\\frac{\\partial_{1}}{\\partial\\nu_{i}}\\left[\\frac{\\ln\\rho_{1}}{\\ln\\rho_{1}}\\frac{w^{2}}{w_{i}^{2}}+(\\alpha_{1}+w_{i})\\frac{\\sinh^{2}+i\\alpha_{1}^{2}}{\\rho_{1}\\omega_{i}^{2}}+(\\alpha_{2}+w_{i})\\frac{\\sinh^{2}}{\\rho_{1}\\omega_{i}\\neq\\varepsilon_{1}^{2}}\\right]\\:\\:}&{\\textrm{I S}i\\leq d_{0}}\\\\ {\\frac{\\partial}{\\partial\\nu_{i}}\\left(w_{i}\\left(w_{i}\\right)\\frac{\\sinh^{2}}{\\rho_{1}}w_{j}^{2}+2\\alpha_{1}\\frac{\\sinh^{2}}{\\rho_{1}\\omega_{i}^{2}}w_{j}^{2}+(\\alpha_{2}+\\alpha_{1})\\right)\\frac{\\sinh}{\\rho_{1\n$$", "text_format": "latex", "page_idx": 20}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\displaystyle\\frac{\\partial}{\\partial\\left(w_{i}^{2}\\right)}\\mathbb{E}_{y=0}\\left[\\mathrm{tr}\\left(\\boldsymbol{\\Sigma}_{\\mu}^{2}\\right)\\right]=\\left\\{\\!\\!\\!\\begin{array}{l l}{\\!\\!\\!w_{0}^{\\nu_{0}}w_{i}^{2}}&{1\\leq i\\leq d_{0}}\\\\ {\\!\\!\\!4\\beta_{1}w_{i}^{2}}&{d_{0}+1\\leq i\\leq d_{0}+d_{1}}\\\\ {\\!\\!\\!4\\beta_{2}w_{i}^{2}}&{d_{0}+d_{1}+1\\leq i\\leq d\\leq d}\\\\ {\\!\\!\\!\\frac{\\partial}{\\partial\\left(w_{i}^{2}\\right)}\\mathbb{E}_{y=0}\\left[\\mathrm{tr}^{2}\\left(\\boldsymbol{\\Sigma}_{\\mu}\\right)\\right]=\\!\\!\\!}\\\\ {\\!\\!\\!\\left(\\!\\!\\begin{array}{l l}{\\!\\!\\!0\\!\\!\\!}&{\\!\\!\\!d_{0}\\!\\!\\!+d_{1}\\!\\!\\!}&{\\!\\!\\!\\!\\frac{d_{0}\\!\\!\\!+d_{1}}{2}\\!\\!\\!}\\\\ {\\!\\!\\!\\!\\frac{\\partial\\!\\!\\!}{\\partial\\!\\!\\!\\!}}&{\\!\\!\\!\\!\\frac{d_{0}}{\\int\\!\\!\\!\\!-d_{1}\\!\\!\\!}w_{i}^{2}+8\\gamma_{0,1}\\!\\!\\!\\!}&{\\!\\!\\!\\!\\frac{d_{0}}{f_{0}d_{0}+1}\\!\\!\\!}\\\\ {\\!\\!\\!\\!\\frac{\\partial\\!\\!\\!}{\\partial\\!\\!\\!\\!}w_{1,1}\\!\\!\\!}&{\\!\\!\\!\\!\\frac{d_{0}\\!\\!\\!+d_{1}}{f_{0}\\!\\!\\!+d_{1}}\\!\\!\\!}&{\\!\\!\\!\\!\\frac{\\partial}{\\partial\\!\\!\\!\\!}}\\\\ {\\!\\!\\!\\!\\frac{d_{0}}{f_{0}}\\!\\!\\!}&{\\!\\!\\!\\!\\frac{d_{0}}{f_{0}}\\!\\!+\\!1\\!\\!\\beta_{1}\\!\\!\\!}&{\\!\\!\\!\\frac{\\partial\\!\\!\\!}{d_{0}+d_{1}}\\!\\!\\!}&{\\!\\!\\!\\!\\frac{d}{f_{0}d_{0}\\!\\!\\!+d_{1}+1}\\!\\!\\!}\\\\ {\\!\\!\\!\\!\\frac{d_{0}}{f_{0}} \n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "Combining these results, we get for $1\\leq i\\leq d_{0}$ ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\begin{array}{l l}{{\\displaystyle b_{0}:=\\frac{\\partial}{\\partial\\left(w_{i}^{2}\\right)}\\tilde{\\ell}\\left(z_{i},z_{j},y_{i j};d_{g}\\right)=\\frac{1}{2}\\left[2\\cdot8\\nu_{z}^{2}w_{i}^{2}+8\\nu_{z}^{2}\\sum_{j=1}^{d}w_{j}^{2}\\right]}-m\\left[2\\left(\\nu_{0}+\\nu_{z}\\right)\\right]}}\\\\ {{\\displaystyle}}&{{\\qquad\\qquad+8\\nu_{z}^{2}w_{i}^{2}+4\\nu_{z}^{2}\\sum_{j=1}^{d}w_{j}^{2}+2\\cdot8\\nu_{z}\\nu_{0}w_{i}^{2}}}\\\\ {{\\displaystyle}}&{{\\qquad\\qquad+4\\nu_{z}\\left[2\\nu_{0}\\sum_{j=1}^{d_{0}}w_{j}^{2}+\\left(\\alpha_{1}+\\nu_{0}\\right)\\sum_{j=d_{0}+1}^{d_{0}+d_{1}}w_{j}^{2}+\\left(\\alpha_{2}+\\nu_{0}\\right)\\sum_{j=d_{0}+d_{1}+1}^{d}\\right.}}\\\\ {{\\displaystyle}}&{{\\qquad\\qquad\\qquad\\left.+8\\nu_{0}^{2}w_{i}^{2}+\\frac{1}{2}\\left[8\\nu_{0}^{2}\\sum_{j=1}^{d_{0}}w_{j}^{2}+8\\nu_{0,1}\\sum_{j=d_{0}+1}^{d_{1}+d_{1}}w_{j}^{2}+8\\nu_{0,2}\\sum_{j=d_{0}+d_{1}+1}^{d_{2}}w_{j}^{2}\\right]}}\\end{array}.\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "for $d_{0}+1\\le i\\le d_{0}+d_{1}$ ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\begin{array}{l}{{\\displaystyle{h_{1}=\\frac{\\partial}{\\partial\\left(w_{i}^{2}\\right)}\\widetilde{\\ell}\\left(z_{i},z_{j},y_{i j};d_{g}\\right)=\\frac{1}{2}\\left[2\\cdot8v_{z}^{2}w_{i}^{2}+8v_{z}^{2}\\sum_{j=1}^{d}w_{j}^{2}\\right]-m\\left[2\\left(\\alpha_{1}+\\nu_{z}\\right)\\right]}}}\\\\ {{\\displaystyle}}\\\\ {{\\displaystyle}}\\\\ {{\\displaystyle}}\\\\ {{\\displaystyle{+\\left.8v_{z}^{2}w_{i}^{2}+4v_{z}^{2}\\sum_{j=1}^{d}w_{j}^{2}+2\\cdot8v_{z}\\alpha_{1}w_{i}^{2}\\right.}}}\\\\ {{\\displaystyle}}\\\\ {{\\displaystyle{\\left.+4\\nu_{z}\\left[(\\nu_{0}+\\alpha_{1})\\sum_{j=1}^{d_{0}}w_{j}^{2}+2\\alpha_{1}\\sum_{j=d_{0}+1}^{d_{0}+d_{1}}w_{j}^{2}+\\left(\\alpha_{2}+\\alpha_{1}\\right)\\sum_{j=d_{0}+d_{1}+1}^{d}w_{j}^{2}\\right.}}}\\\\ {{\\displaystyle{\\left.\\left.+4\\beta_{1}w_{i}^{2}+\\frac{1}{2}\\left[8\\gamma_{0,1}\\sum_{j=1}^{d_{0}}w_{j}^{2}+4\\beta_{1}\\sum_{j=d_{0}+1}^{d_{0}+d_{1}}w_{j}^{2}+8\\gamma_{1,2}\\sum_{j=d_{0}+d_{1}+1}^{d}w_{j}^{2}\\right]\\right]}}}\\end{array}\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "and similarly for $d_{0}+d_{1}+1\\leq i\\leq d$ ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\begin{array}{c c l}{{b_{2}:={\\displaystyle\\frac{\\partial}{\\partial\\left(w_{i}^{2}\\right)}}{\\tilde{\\ell}}\\left(z_{i},z_{j},y_{i j};d_{g}\\right)={\\displaystyle\\frac{1}{2}}\\left[2\\cdot8v_{z}^{2}w_{i}^{2}+8v_{z}^{2}\\sum_{j=1}^{d}w_{j}^{2}\\right]-m\\left[2\\left(\\alpha_{2}+\\nu_{z}\\right)\\right]}}&{{}}&{{}}\\\\ {{}}&{{}}&{{}}\\\\ {{}}&{{\\displaystyle+8v_{z}^{2}w_{i}^{2}+4v_{z}^{2}\\sum_{j=1}^{d}w_{j}^{2}+2\\cdot8v_{z}\\alpha_{2}w_{i}^{2}}}&{{}}&{{}}\\\\ {{}}&{{}}&{{}}\\\\ {{}}&{{\\displaystyle+4\\nu_{z}\\left[(\\nu_{0}+\\alpha_{2})\\sum_{j=1}^{d_{0}}w_{j}^{2}+\\left(\\alpha_{1}+\\alpha_{2}\\right)\\sum_{j=d_{0}+1}^{d_{0}+d_{1}}w_{j}^{2}+2\\alpha_{2}\\sum_{j=d_{0}+d_{1}+1}^{d}w_{j}^{2}\\right.}}&{{}}\\\\ {{}}&{{}}&{{\\displaystyle\\left.\\displaystyle+4\\beta_{2}w_{i}^{2}+\\frac{1}{2}\\left[8\\gamma_{0,2}\\sum_{j=1}^{d_{0}}w_{j}^{2}+8\\gamma_{1,2}\\sum_{j=d_{0}+1}^{d_{0}+d_{1}}w_{j}^{2}+4\\beta_{2}\\sum_{j=d_{0}+d_{1}+1}^{d}w_{j}^{2}\\right]\\right\\}}}\\end{array}\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "Thus, we can write for the symmetric solution ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\partial_{0}=-2m\\left(\\nu_{0}+\\nu_{z}\\right)+u_{0}^{2}G_{0,0}+u_{1}^{2}G_{0,1}+u_{2}^{2}G_{0,2},}\\\\ {\\partial_{1}=-2m\\left(\\alpha_{1}+\\nu_{z}\\right)+u_{0}^{2}G_{1,0}+u_{1}^{2}G_{1,1}+u_{2}^{2}G_{1,2},}\\\\ {\\partial_{2}=-2m\\left(\\alpha_{2}+\\nu_{z}\\right)+u_{0}^{2}G_{2,0}+u_{1}^{2}G_{2,1}+u_{2}^{2}G_{2,2},}\\end{array}\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "where ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{G_{0,0}=16\\nu_{z}^{2}+8\\nu_{z}^{2}d_{0}+16\\nu_{z}\\nu_{0}+8\\nu_{z}\\nu_{0}d_{0}+8\\nu_{0}^{2}+4\\nu_{0}^{2}d_{0}}\\\\ &{G_{0,1}=8\\nu_{z}^{2}d_{1}+4\\nu_{z}\\left(\\alpha_{1}+\\nu_{0}\\right)d_{1}+4\\gamma_{0,1}d_{1}}\\\\ &{G_{0,2}=8\\nu_{z}^{2}d_{2}+4\\nu_{z}\\left(\\alpha_{2}+\\nu_{0}\\right)d_{2}+4\\gamma_{0,2}d_{2}}\\\\ &{G_{1,0}=8\\nu_{z}^{2}d_{0}+4\\nu_{z}\\left(\\nu_{0}+\\alpha_{1}\\right)d_{0}+4\\gamma_{0,1}d_{0}}\\\\ &{G_{1,1}=16\\nu_{z}^{2}+8\\nu_{z}^{2}d_{1}+16\\nu_{z}\\alpha_{1}+8\\nu_{z}\\alpha_{1}d_{1}+4\\beta_{1}+4\\beta_{1}d_{1}}\\\\ &{G_{1,2}=8\\nu_{z}^{2}d_{2}+4\\nu_{z}\\left(\\alpha_{2}+\\alpha_{1}\\right)d_{2}+4\\gamma_{1,2}d_{2}}\\\\ &{G_{2,0}=8\\nu_{z}^{2}d_{0}+4\\nu_{z}\\left(\\nu_{0}+\\alpha_{2}\\right)d_{0}+4\\gamma_{0,2}d_{0}}\\\\ &{G_{2,1}=8\\nu_{z}^{2}d_{1}+4\\nu_{z}\\left(\\alpha_{1}+\\alpha_{2}\\right)d_{1}+4\\gamma_{1,2}d_{1}}\\\\ &{G_{2,2}=16\\nu_{z}^{2}+8\\nu_{z}^{2}d_{2}+16\\nu_{z}\\alpha_{2}+8\\nu_{z}\\alpha_{2}d_{2}+4\\beta_{2}+4\\beta_{2}d_{2}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "Therefore, the optimal representation is given by the solution to the following set of linear equations: ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\left(\\begin{array}{c}{{u_{0}^{2}}}\\\\ {{u_{1}^{2}}}\\\\ {{u_{2}^{2}}}\\end{array}\\right)=2m\\,G^{-1}\\left(\\begin{array}{c}{{\\nu_{0}+\\nu_{z}}}\\\\ {{\\alpha_{1}+\\nu_{z}}}\\\\ {{\\alpha_{2}+\\nu_{z}}}\\end{array}\\right),\n$$", "text_format": "latex", "page_idx": 21}, {"type": "table", "img_path": "yUqUBGioBG/tmp/9d7fc551f6cc4859f57b73238bb38128a31da9c2774258782ac03b0ae7ae1cc0.jpg", "table_caption": ["Table 1: Simulation results. For each mixture ratio we report the mean AUC and the standard deviation across 10 repetitions of the experiment. Results are reported for in-distribution scenario $(P_{C})$ , and class distribution shift $(Q_{C})$ . Best result is marked in bold. "], "table_footnote": [], "page_idx": 22}, {"type": "text", "text": "where ", "page_idx": 22}, {"type": "equation", "text": "$$\nG=\\left(\\begin{array}{c c c}{{G_{0,0}}}&{{G_{0,1}}}&{{G_{0,2}}}\\\\ {{G_{1,0}}}&{{G_{1,1}}}&{{G_{1,2}}}\\\\ {{G_{2,0}}}&{{G_{2,1}}}&{{G_{2,2}}}\\end{array}\\right).\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "C Comparison to OOD Environment Balancing Methods ", "text_level": 1, "page_idx": 22}, {"type": "text", "text": "Previous methods in the field of OOD generalization (see $\\S2$ ) exhibit several key differences compared to our setting: (i) They address closed-world classification, whereas in zero-shot learning, new classes are encountered. (ii) The presumed shift is typically in the conditional distribution of the data given the class (e.g., the background given the class being a cow or a camel), whereas we consider shifts in the class distribution $P(c)$ . (iii) Existing methods often assume that training data comes from various data environments, providing explicit information about how the distribution might shift, while we assume the attribute $A$ causing the shift is unknown. ", "page_idx": 22}, {"type": "text", "text": "Despite these differences, in this work we recast class distribution shifts in zero-shot learning into environment balancing OOD setting, by making the following observations. First, when posed as verification methods, zero-shot classifiers in fact perform a binary (closed-world) classification task, predicting whether a pair of data points $x_{i j}:=(z_{i},z_{j})$ belong to the same class $y_{i j}=\\mathbb{1}_{c_{i}=c_{j}}$ . ", "page_idx": 22}, {"type": "text", "text": "Note that the distribution of possible pairs $x_{i j}=(z_{i},z_{j})$ given the label $y_{i j}$ changes with variations in class attribute probabilities, and therefore across synthetic environments $S$ . Thus, in this formulation the shift occurs in the conditional distribution of the data given the class $p(x_{i j}|y_{i j})$ . ", "page_idx": 22}, {"type": "text", "text": "Another distinction lies in data availability: in the setting of closed-world OOD environment balancing methods, a main drawback is the challenge of securing a sufficient number of diverse training environments. This is essential to ensure that a representation performing well on observed environments, will likely perform similarly on unobserved ones. In contrast, our framework allows for the construction of many synthetic environments via sampling. ", "page_idx": 22}, {"type": "text", "text": "D Additional Empirical Results ", "text_level": 1, "page_idx": 22}, {"type": "text", "text": "D.1 Additional Simulation Results ", "text_level": 1, "page_idx": 22}, {"type": "text", "text": "Simulations Exact mean and standard deviations matching Figure 4 are provided in table 1. ", "page_idx": 22}, {"type": "text", "text": "AUC progress during training iterations and feature importance results for the majority class proportion of $\\rho=0.1$ were shown in the main text. Here, we provide analogous results for $\\rho=0.05$ and $\\rho=0.3$ . These are summarized in Figure 8. ", "page_idx": 22}, {"type": "image", "img_path": "yUqUBGioBG/tmp/80aa859c1eda09dcf6edef6b36c8384cf818389fa4d9574f2e0c405c6fc13548.jpg", "img_caption": ["Figure 7: Additional simulation results. Top row: Additional dimensions of the representation. Middle row: additional rations of the attribute variances. Bottom row: unbalanced sets of positive and negative examples. Bars show mean AUC values on the test set across 5 repetitions of the experiment, whiskers show $\\pm$ standard deviation. "], "img_footnote": [], "page_idx": 23}, {"type": "text", "text": "For $\\rho=0.05$ the convergence results are similar to those obtained for $\\rho=0.1$ \u2013 under distributionshift the two variance based methods show significantly better results compared to other approaches. Our algorithm with the VarREx penalty achieves high AUC values more quickly than the VarAUC penalty, but the VarAUC penalty attains higher accuracy overall. The CLOvE penalty achieves improvement over ERM, but smaller compared to the variance based methods. IRM converges to the same AUC as ERM. In contrast, on in-distribution data all methods perform well. ", "page_idx": 23}, {"type": "text", "text": "For $\\rho\\,=\\,0.3$ the distribution shift is milder and therefore ERM performs very well (0.902 AUC is achieved on distribution shift scenario compared to 0.932 on in-distribution setting). Therefore encouragement of similar performance across different data subsets does not benefit the learning process. Slightly better result is achieved with VarREx penalty (0.911). ", "page_idx": 23}, {"type": "text", "text": "The analysis of feature importance for $\\rho\\,=\\,0.05$ yields results similar to those for $\\rho\\,=\\,0.1$ . At $\\rho=0.3$ the analysis remains mostly unchanged, except that VarREx assigns higher importance to features corresponding to $\\nu_{0}$ (0-5) compared to VarAUC, while in more extreme distribution shifts VarAUC assigns higher importance to the shared features. ", "page_idx": 23}, {"type": "text", "text": "D.2 Additional Representation Sizes, Noise Ratios and Positive Proportions ", "text_level": 1, "page_idx": 23}, {"type": "text", "text": "In $\\S5.1$ we explored varying values of $\\rho$ in a setting where $\\nu^{+}\\,=\\,2,\\,\\nu^{-}\\,=\\,0.1\\,\\,(\\frac{\\nu^{+}}{\\nu^{-}}\\,=\\,20)$ . We now focus on the case of $\\rho=0.1$ and examine additional representation sizes $p$ , and noise ratios $\\bigl(\\frac{\\nu^{+}}{\\nu^{-}}\\in\\bigl\\{10,40\\bigr\\}\\bigr)$ . Additionally, we examine the original setting where $p=16$ and $\\nu^{+}=2$ , $\\nu^{-}=0.1$ , with varying proportions of positive and negative examples. ", "page_idx": 23}, {"type": "text", "text": "The results in Figure 7 show that in all the additional settings our methods provides statistically significant improvement over the baseline. FDR adjusted $\\mathbf{p}$ -values for multiple comparisons are provided in Table 2. ", "page_idx": 23}, {"type": "table", "img_path": "yUqUBGioBG/tmp/1ec34a9aa4f12f72ec4ea8bf0d67df27ac5c627e5aaf5a38a77e6c184f56950f.jpg", "table_caption": ["Table 2: FDR adjusted p-values for the results reported in Figure 7 "], "table_footnote": [], "page_idx": 24}, {"type": "text", "text": "Experiments In Table 3, we provide the means and standard deviations for the experiments detailed in $\\S5.2$ . Additionally, Table 4 presents the adjusted $\\mathfrak{p}$ -values for assessing the performance increase over the ERM baseline achieved by our algorithm with the explored penalties. ", "page_idx": 24}, {"type": "table", "img_path": "yUqUBGioBG/tmp/bebe35d35efdbbb6b916ae5c263fdf5fc64a17bb7678a81eb8a7c20297454410.jpg", "table_caption": ["Table 3: Experimental results. Mean and standard deviation of AUC values over 5 repetitions are reported for in distribution scenario $(P_{C})$ , and class distribution shift $(Q_{C})$ . Best result is marked in bold. "], "table_footnote": [], "page_idx": 24}, {"type": "table", "img_path": "yUqUBGioBG/tmp/35926368ec0b7bde71bfe8b4794f7bcf90897375cc2ad266eac0266c40480365.jpg", "table_caption": ["Table 4: Adjusted p-values for one-sided paired t-tests for testing the improvements over the ERM baseline. "], "table_footnote": [], "page_idx": 24}, {"type": "text", "text": "D.3 Analysis of Loss Values ", "text_level": 1, "page_idx": 24}, {"type": "text", "text": "Here we present an analysis of the unpenalized loss after convergence in both real-data experiments. We performed separate analyses on pairs of data points from the dominant type during training (majority), and those from the other type (minority). Additionally, we separated positive pairs $(y=1)$ ) and negative pairs $(y=0)$ ). Figure 9 displays histograms illustrating the differences between losses on the training set obtained with the representation learned using ERM $(g_{\\mathrm{ERM}})$ , and those obtained using our algorithm with VarAUC penalty $(g_{\\mathrm{VarAUC}})$ : ", "page_idx": 24}, {"type": "equation", "text": "$$\n\\mathrm{Diff}_{i j}=\\ell(x_{i j},y_{i j};d_{g_{\\mathrm{ERM}}})-\\ell(x_{i j},y_{i j};d_{g_{\\mathrm{VarAUC}}}).\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "Positive values of the differences correspond to higher losses for ERM. ", "page_idx": 24}, {"type": "text", "text": "In both experiments, when examining negative pairs from the minority group, as shown in the top-left histograms, most of the observed differences are positive. This indicates that the ERM losses for these pairs are higher compared to the losses obtained for the representation trained with the VarAUC ", "page_idx": 24}, {"type": "text", "text": "penalty. The disparities are smaller for the other three groups: majority negative pairs, minority negative pairs, and minority positive pairs. Among these groups, ERM performs better on positive pairs. ", "page_idx": 25}, {"type": "image", "img_path": "yUqUBGioBG/tmp/75699d4dd65a7910fdd276a2e716da5b382cfd4bff3d18a985b4180ddc6d9dbe.jpg", "img_caption": ["Figure 8: Additional Simulation Results. Top row: $\\rho=0.05$ , Bottom row: $\\rho=0.3$ . Left: Average AUC progress over 10 repetitions of the simulation. Solid lines correspond to performance on test data (distribution shift scenario), dashed lines show performance on data sampled from the same distribution as training data (in-distribution scenario). Right: Average feature importance results over 10 repetitions. "], "img_footnote": [], "page_idx": 25}, {"type": "image", "img_path": "yUqUBGioBG/tmp/91555e6474ed74c2161545818ffeb40f3d8307362be3869c7af67107399ea252.jpg", "img_caption": ["Figure 9: Analysis of Loss Differences. Histograms of differences between ERM and our algorithm with VarAUC penalty are shown for two experiments in separate sub-figures: (a) CelebA dataset, (b) ETHEC dataset. The top rows show differences for negative pairs $(y=0)$ ), bottom ones show differences for positive pairs $y=1,$ ). In each sub-figure the left column corresponds to the minority type and right one to the majority. A dotted black line marks a difference of 0. Positive values correspond to higher losses for ERM. "], "img_footnote": [], "page_idx": 26}, {"type": "text", "text": "E Datasets ", "text_level": 1, "page_idx": 27}, {"type": "image", "img_path": "yUqUBGioBG/tmp/d0996e0f586fe1fb07a088a5b76ad2207026a675d458622900f4682988881c94.jpg", "img_caption": [], "img_footnote": [], "page_idx": 27}, {"type": "text", "text": "Figure 10: Sample Images from the CelebA Dataset. Top: a random sample of the training data with $95\\%$ non-blond people. Bottom: a random sample of the test data with $95\\%$ blond people. ", "page_idx": 27}, {"type": "image", "img_path": "yUqUBGioBG/tmp/500409df13d9c43f0ae09b30a8ec371645df7363c2e8b86d02cb05f096d5a533.jpg", "img_caption": [], "img_footnote": [], "page_idx": 27}, {"type": "text", "text": "Figure 11: Sample Images from the ETHEC Dataset. Top: a sample of the the training data \u2013 9 species of the Lycaenidae family and 1 from the Nymphalidae family. Bottom: a sample of the test data where the proportion of the families is reversed. Nymphalidae species names are marked in bold. ", "page_idx": 27}, {"type": "text", "text": "F Implementation Details ", "text_level": 1, "page_idx": 27}, {"type": "text", "text": "A link to a permanent repository with code to reproduce our results is included in the main text. ", "page_idx": 27}, {"type": "text", "text": "The data-related parameters of our experiments are described in the main text. In all our experiments we used margin of $m=0.5$ for the contrastive loss and Adam (Kingma & Ba, 2014) optimizer to train all models. ", "page_idx": 27}, {"type": "text", "text": "For the CLOvE penalty we used a Laplacian kernel $k(r,r^{\\prime})\\,=\\,e^{\\frac{1}{\\mathrm{width}}-|r-r^{\\prime}|}$ with width of 0.4 as originally suggested by Kumar et al. (2018). ", "page_idx": 27}, {"type": "text", "text": "For optimization of the VarAUC objective we disregard the finite sample correction $\\frac{N_{s}\\!-\\!n}{N_{s}-1}$ in the implementation since $n$ is very small compared to $N_{s}$ . In practice, we minimize the standard deviation instead of the variance in both variance based penalties, and the hyperparameters are reported accordingly. ", "page_idx": 27}, {"type": "text", "text": "In our scenario where the attribute of interest is unknown, we generated a synthetic attribute for hyperparameter selection using Principle Components (PC). We ranked examples based on their first PC component values, classifying the top $10\\%$ as positive and the rest as negative. Hyperparameters for all methods were chosen via grid-search in a single experiment repetition, ensuring robustness against this synthetic attribute. Notably, the experiments themselves did not involve the PC attribute; instead, they focused on dimension swapping in simulations and attributes like hair color or species family in CelebA and ETHEC experiments. ", "page_idx": 27}, {"type": "text", "text": "The grid search produced almost identical hyperparameters for all three $\\rho$ values. We observed that performance converged to the same value when employing hyperparameters derived from crossvalidation for one $\\rho$ value, as those selected for another. Therefore, for simplicity we repeated simulations using the same hyperparameters, determined based on the grid search results for $\\rho=0.1$ (the intermediate parameter value). Similarly, minimal differences in optimal learning rates were observed among the methods within an experiment and therefore a shared learning rate was used for each experiment. To emphasize the improvement of OOD methods over the ERM baseline, we used the learning rate optimized for the ERM method. Large differences were observed in optimal regularization factors, and therefore these parameters (as well as method-specific parameters) were not shared. All hyper-parameters are reported in Table 5. ", "page_idx": 27}, {"type": "text", "text": "", "page_idx": 28}, {"type": "text", "text": "All models were initialized with identical weights, and trained on identical data splits. ", "page_idx": 28}, {"type": "text", "text": "All the code in this work was implemented in Python 3.10. We used the TensorFlow 2.13 and TensorFlow Addons 0.21 packages. For evaluation we used the auc function from scikitlearn 1.2. The CelebA dataset was loaded through TensorFlow Datasets 4.9 and pandas 1.5 was used to process the ETHEC dataset. Statistical tests were performed using ttest_rel and false_discovery_control functions from scipy.stats 1.11.4. All figures were generated using Matplotlib 3.7. ", "page_idx": 28}, {"type": "text", "text": "The IRM implementation was adapted from the source code of the paper, available at https://github.com/facebookresearch/InvariantRiskMinimization. ", "page_idx": 28}, {"type": "text", "text": "We ran all experiments on a single A100 cloud GPU. For simulations, each full repetition of the experiment (comparing all methods) required on average 2.06 hours. Each repetition on the ETHEC dataset took 7.38 hours on average, and on the CelebA dataset 11.52 hours. ", "page_idx": 28}, {"type": "table", "img_path": "yUqUBGioBG/tmp/c8136108f203e0ce9ff09d0419e5f7d653d445198d7b874a1f2e8351c45e937d.jpg", "table_caption": ["Table 5: Hyper Parameters. "], "table_footnote": [], "page_idx": 28}, {"type": "text", "text": "NeurIPS Paper Checklist ", "text_level": 1, "page_idx": 29}, {"type": "text", "text": "1. Claims ", "text_level": 1, "page_idx": 29}, {"type": "text", "text": "Question: Do the main claims made in the abstract and introduction accurately reflect the paper\u2019s contributions and scope? ", "page_idx": 29}, {"type": "text", "text": "Answer: [Yes] , ", "page_idx": 29}, {"type": "text", "text": "Justification: Both abstract and the introduction (last 2 paragraphs) accurately state the main contributions of the paper. ", "page_idx": 29}, {"type": "text", "text": "Guidelines: ", "page_idx": 29}, {"type": "text", "text": "\u2022 The answer NA means that the abstract and introduction do not include the claims made in the paper.   \n\u2022 The abstract and/or introduction should clearly state the claims made, including the contributions made in the paper and important assumptions and limitations. A No or NA answer to this question will not be perceived well by the reviewers.   \n\u2022 The claims made should match theoretical and experimental results, and reflect how much the results can be expected to generalize to other settings.   \n\u2022 It is fine to include aspirational goals as motivation as long as it is clear that these goals are not attained by the paper. ", "page_idx": 29}, {"type": "text", "text": "2. Limitations ", "text_level": 1, "page_idx": 29}, {"type": "text", "text": "Question: Does the paper discuss the limitations of the work performed by the authors? ", "page_idx": 29}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 29}, {"type": "text", "text": "Justification: Main limitations are discussed in $\\S6$ . ", "page_idx": 29}, {"type": "text", "text": "Guidelines: ", "page_idx": 29}, {"type": "text", "text": "\u2022 The answer NA means that the paper has no limitation while the answer No means that the paper has limitations, but those are not discussed in the paper.   \n\u2022 The authors are encouraged to create a separate \"Limitations\" section in their paper.   \n\u2022 The paper should point out any strong assumptions and how robust the results are to violations of these assumptions (e.g., independence assumptions, noiseless settings, model well-specification, asymptotic approximations only holding locally). The authors should reflect on how these assumptions might be violated in practice and what the implications would be.   \n\u2022 The authors should reflect on the scope of the claims made, e.g., if the approach was only tested on a few datasets or with a few runs. In general, empirical results often depend on implicit assumptions, which should be articulated.   \n\u2022 The authors should reflect on the factors that influence the performance of the approach. For example, a facial recognition algorithm may perform poorly when image resolution is low or images are taken in low lighting. Or a speech-to-text system might not be used reliably to provide closed captions for online lectures because it fails to handle technical jargon.   \n\u2022 The authors should discuss the computational efficiency of the proposed algorithms and how they scale with dataset size.   \n\u2022 If applicable, the authors should discuss possible limitations of their approach to address problems of privacy and fairness.   \n\u2022 While the authors might fear that complete honesty about limitations might be used by reviewers as grounds for rejection, a worse outcome might be that reviewers discover limitations that aren\u2019t acknowledged in the paper. The authors should use their best judgment and recognize that individual actions in favor of transparency play an important role in developing norms that preserve the integrity of the community. Reviewers will be specifically instructed to not penalize honesty concerning limitations. ", "page_idx": 29}, {"type": "text", "text": "3. Theory Assumptions and Proofs ", "text_level": 1, "page_idx": 29}, {"type": "text", "text": "Question: For each theoretical result, does the paper provide the full set of assumptions and a complete (and correct) proof? ", "page_idx": 29}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 29}, {"type": "text", "text": "Justification: All assumptions are clearly stated and full proofs to the theoretical claims appear in Appendix B ", "page_idx": 30}, {"type": "text", "text": "Guidelines: ", "page_idx": 30}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include theoretical results.   \n\u2022 All the theorems, formulas, and proofs in the paper should be numbered and crossreferenced.   \n\u2022 All assumptions should be clearly stated or referenced in the statement of any theorems.   \n\u2022 The proofs can either appear in the main paper or the supplemental material, but if they appear in the supplemental material, the authors are encouraged to provide a short proof sketch to provide intuition.   \n\u2022 Inversely, any informal proof provided in the core of the paper should be complemented by formal proofs provided in appendix or supplemental material.   \n\u2022 Theorems and Lemmas that the proof relies upon should be properly referenced. ", "page_idx": 30}, {"type": "text", "text": "4. Experimental Result Reproducibility ", "text_level": 1, "page_idx": 30}, {"type": "text", "text": "Question: Does the paper fully disclose all the information needed to reproduce the main experimental results of the paper to the extent that it affects the main claims and/or conclusions of the paper (regardless of whether the code and data are provided or not)? ", "page_idx": 30}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 30}, {"type": "text", "text": "Justification: All the details are provided in Section $\\S5$ and Appendix F. ", "page_idx": 30}, {"type": "text", "text": "Guidelines: ", "page_idx": 30}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 If the paper includes experiments, a No answer to this question will not be perceived well by the reviewers: Making the paper reproducible is important, regardless of whether the code and data are provided or not.   \n\u2022 If the contribution is a dataset and/or model, the authors should describe the steps taken to make their results reproducible or verifiable.   \n\u2022 Depending on the contribution, reproducibility can be accomplished in various ways. For example, if the contribution is a novel architecture, describing the architecture fully might suffice, or if the contribution is a specific model and empirical evaluation, it may be necessary to either make it possible for others to replicate the model with the same dataset, or provide access to the model. In general. releasing code and data is often one good way to accomplish this, but reproducibility can also be provided via detailed instructions for how to replicate the results, access to a hosted model (e.g., in the case of a large language model), releasing of a model checkpoint, or other means that are appropriate to the research performed.   \n\u2022 While NeurIPS does not require releasing code, the conference does require all submissions to provide some reasonable avenue for reproducibility, which may depend on the nature of the contribution. For example (a) If the contribution is primarily a new algorithm, the paper should make it clear how to reproduce that algorithm. (b) If the contribution is primarily a new model architecture, the paper should describe the architecture clearly and fully. (c) If the contribution is a new model (e.g., a large language model), then there should either be a way to access this model for reproducing the results or a way to reproduce the model (e.g., with an open-source dataset or instructions for how to construct the dataset). (d) We recognize that reproducibility may be tricky in some cases, in which case authors are welcome to describe the particular way they provide for reproducibility. In the case of closed-source models, it may be that access to the model is limited in some way (e.g., to registered users), but it should be possible for other researchers to have some path to reproducing or verifying the results. ", "page_idx": 30}, {"type": "text", "text": "5. Open access to data and code ", "text_level": 1, "page_idx": 30}, {"type": "text", "text": "Question: Does the paper provide open access to the data and code, with sufficient instructions to faithfully reproduce the main experimental results, as described in supplemental material? ", "page_idx": 30}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 31}, {"type": "text", "text": "Justification: The datasets are publicly available and code implementing all our results is submitted with the paper. ", "page_idx": 31}, {"type": "text", "text": "Guidelines: ", "page_idx": 31}, {"type": "text", "text": "\u2022 The answer NA means that paper does not include experiments requiring code.   \n\u2022 Please see the NeurIPS code and data submission guidelines (https://nips.cc/ public/guides/CodeSubmissionPolicy) for more details.   \n\u2022 While we encourage the release of code and data, we understand that this might not be possible, so \u201cNo\u201d is an acceptable answer. Papers cannot be rejected simply for not including code, unless this is central to the contribution (e.g., for a new open-source benchmark).   \n\u2022 The instructions should contain the exact command and environment needed to run to reproduce the results. See the NeurIPS code and data submission guidelines (https: //nips.cc/public/guides/CodeSubmissionPolicy) for more details.   \n\u2022 The authors should provide instructions on data access and preparation, including how to access the raw data, preprocessed data, intermediate data, and generated data, etc.   \n\u2022 The authors should provide scripts to reproduce all experimental results for the new proposed method and baselines. If only a subset of experiments are reproducible, they should state which ones are omitted from the script and why.   \n\u2022 At submission time, to preserve anonymity, the authors should release anonymized versions (if applicable).   \n\u2022 Providing as much information as possible in supplemental material (appended to the paper) is recommended, but including URLs to data and code is permitted. ", "page_idx": 31}, {"type": "text", "text": "6. Experimental Setting/Details ", "text_level": 1, "page_idx": 31}, {"type": "text", "text": "Question: Does the paper specify all the training and test details (e.g., data splits, hyperparameters, how they were chosen, type of optimizer, etc.) necessary to understand the results? ", "page_idx": 31}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 31}, {"type": "text", "text": "Justification: We specify all hyperparameters and training details in Appendix F. Guidelines: ", "page_idx": 31}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments. \u2022 The experimental setting should be presented in the core of the paper to a level of detail that is necessary to appreciate the results and make sense of them. \u2022 The full details can be provided either with the code, in appendix, or as supplemental material. ", "page_idx": 31}, {"type": "text", "text": "7. Experiment Statistical Significance ", "text_level": 1, "page_idx": 31}, {"type": "text", "text": "Question: Does the paper report error bars suitably and correctly defined or other appropriate information about the statistical significance of the experiments? ", "page_idx": 31}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 31}, {"type": "text", "text": "Justification: We perform statistical testing to provide significance of our results and report FDR adjusted p-values. For all reported results we include either error bars in the main text, or when other visualizations are chosen we report means and standard deviations in Appendix D. ", "page_idx": 31}, {"type": "text", "text": "Guidelines: ", "page_idx": 31}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 The authors should answer \"Yes\" if the results are accompanied by error bars, confidence intervals, or statistical significance tests, at least for the experiments that support the main claims of the paper.   \n\u2022 The factors of variability that the error bars are capturing should be clearly stated (for example, train/test split, initialization, random drawing of some parameter, or overall run with given experimental conditions).   \n\u2022 The method for calculating the error bars should be explained (closed form formula, call to a library function, bootstrap, etc.)   \n\u2022 The assumptions made should be given (e.g., Normally distributed errors).   \n\u2022 It should be clear whether the error bar is the standard deviation or the standard error of the mean.   \n\u2022 It is OK to report 1-sigma error bars, but one should state it. The authors should preferably report a 2-sigma error bar than state that they have a $96\\%$ CI, if the hypothesis of Normality of errors is not verified.   \n\u2022 For asymmetric distributions, the authors should be careful not to show in tables or figures symmetric error bars that would yield results that are out of range (e.g. negative error rates).   \n\u2022 If error bars are reported in tables or plots, The authors should explain in the text how they were calculated and reference the corresponding figures or tables in the text. ", "page_idx": 31}, {"type": "text", "text": "", "page_idx": 32}, {"type": "text", "text": "8. Experiments Compute Resources ", "text_level": 1, "page_idx": 32}, {"type": "text", "text": "Question: For each experiment, does the paper provide sufficient information on the computer resources (type of compute workers, memory, time of execution) needed to reproduce the experiments? ", "page_idx": 32}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 32}, {"type": "text", "text": "Justification: All resources including GPU information and run times are provided in Appendix F. ", "page_idx": 32}, {"type": "text", "text": "Guidelines: ", "page_idx": 32}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 The paper should indicate the type of compute workers CPU or GPU, internal cluster, or cloud provider, including relevant memory and storage.   \n\u2022 The paper should provide the amount of compute required for each of the individual experimental runs as well as estimate the total compute.   \n\u2022 The paper should disclose whether the full research project required more compute than the experiments reported in the paper (e.g., preliminary or failed experiments that didn\u2019t make it into the paper). ", "page_idx": 32}, {"type": "text", "text": "9. Code Of Ethics ", "text_level": 1, "page_idx": 32}, {"type": "text", "text": "Question: Does the research conducted in the paper conform, in every respect, with the NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines? ", "page_idx": 32}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 32}, {"type": "text", "text": "Justification: The paper conforms with the provided code of ethics. ", "page_idx": 32}, {"type": "text", "text": "Guidelines: ", "page_idx": 32}, {"type": "text", "text": "\u2022 The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics.   \n\u2022 If the authors answer No, they should explain the special circumstances that require a deviation from the Code of Ethics.   \n\u2022 The authors should make sure to preserve anonymity (e.g., if there is a special consideration due to laws or regulations in their jurisdiction). ", "page_idx": 32}, {"type": "text", "text": "10. Broader Impacts ", "text_level": 1, "page_idx": 32}, {"type": "text", "text": "Question: Does the paper discuss both potential positive societal impacts and negative societal impacts of the work performed? ", "page_idx": 32}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 32}, {"type": "text", "text": "Justification: This paper presents work whose goal is to advance the field of learning robust data representations. It is not tied to any particular applications and therefore we do not see an immediate risk for negative societal impact. ", "page_idx": 32}, {"type": "text", "text": "Guidelines: ", "page_idx": 32}, {"type": "text", "text": "\u2022 The answer NA means that there is no societal impact of the work performed. \u2022 If the authors answer NA or No, they should explain why their work has no societal impact or why the paper does not address societal impact. ", "page_idx": 32}, {"type": "text", "text": "\u2022 Examples of negative societal impacts include potential malicious or unintended uses (e.g., disinformation, generating fake profiles, surveillance), fairness considerations (e.g., deployment of technologies that could make decisions that unfairly impact specific groups), privacy considerations, and security considerations.   \n\u2022 The conference expects that many papers will be foundational research and not tied to particular applications, let alone deployments. However, if there is a direct path to any negative applications, the authors should point it out. For example, it is legitimate to point out that an improvement in the quality of generative models could be used to generate deepfakes for disinformation. On the other hand, it is not needed to point out that a generic algorithm for optimizing neural networks could enable people to train models that generate Deepfakes faster.   \n\u2022 The authors should consider possible harms that could arise when the technology is being used as intended and functioning correctly, harms that could arise when the technology is being used as intended but gives incorrect results, and harms following from (intentional or unintentional) misuse of the technology.   \n\u2022 If there are negative societal impacts, the authors could also discuss possible mitigation strategies (e.g., gated release of models, providing defenses in addition to attacks, mechanisms for monitoring misuse, mechanisms to monitor how a system learns from feedback over time, improving the efficiency and accessibility of ML). ", "page_idx": 33}, {"type": "text", "text": "11. Safeguards ", "text_level": 1, "page_idx": 33}, {"type": "text", "text": "Question: Does the paper describe safeguards that have been put in place for responsible release of data or models that have a high risk for misuse (e.g., pretrained language models, image generators, or scraped datasets)? ", "page_idx": 33}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 33}, {"type": "text", "text": "Justification: We do not release any new data or models. ", "page_idx": 33}, {"type": "text", "text": "Guidelines: ", "page_idx": 33}, {"type": "text", "text": "\u2022 The answer NA means that the paper poses no such risks.   \n\u2022 Released models that have a high risk for misuse or dual-use should be released with necessary safeguards to allow for controlled use of the model, for example by requiring that users adhere to usage guidelines or restrictions to access the model or implementing safety filters.   \n\u2022 Datasets that have been scraped from the Internet could pose safety risks. The authors should describe how they avoided releasing unsafe images.   \n\u2022 We recognize that providing effective safeguards is challenging, and many papers do not require this, but we encourage authors to take this into account and make a best faith effort. ", "page_idx": 33}, {"type": "text", "text": "12. Licenses for existing assets ", "text_level": 1, "page_idx": 33}, {"type": "text", "text": "Question: Are the creators or original owners of assets (e.g., code, data, models), used in the paper, properly credited and are the license and terms of use explicitly mentioned and properly respected? ", "page_idx": 33}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 33}, {"type": "text", "text": "Justification: The only asset used is the IRM implementation. The corresponding paper is cited and we explicitly mention this in Appendix F, while providing also reference for the code itself. ", "page_idx": 33}, {"type": "text", "text": "Guidelines: ", "page_idx": 33}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not use existing assets.   \n\u2022 The authors should cite the original paper that produced the code package or dataset.   \n\u2022 The authors should state which version of the asset is used and, if possible, include a URL.   \n\u2022 The name of the license (e.g., CC-BY 4.0) should be included for each asset.   \n\u2022 For scraped data from a particular source (e.g., website), the copyright and terms of service of that source should be provided.   \n\u2022 If assets are released, the license, copyright information, and terms of use in the package should be provided. For popular datasets, paperswithcode.com/datasets has curated licenses for some datasets. Their licensing guide can help determine the license of a dataset.   \n\u2022 For existing datasets that are re-packaged, both the original license and the license of the derived asset (if it has changed) should be provided.   \n\u2022 If this information is not available online, the authors are encouraged to reach out to the asset\u2019s creators. ", "page_idx": 33}, {"type": "text", "text": "", "page_idx": 34}, {"type": "text", "text": "13. New Assets ", "text_level": 1, "page_idx": 34}, {"type": "text", "text": "Question: Are new assets introduced in the paper well documented and is the documentation provided alongside the assets? ", "page_idx": 34}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 34}, {"type": "text", "text": "Justification: We do not release new assets. ", "page_idx": 34}, {"type": "text", "text": "Guidelines: ", "page_idx": 34}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not release new assets.   \n\u2022 Researchers should communicate the details of the dataset/code/model as part of their submissions via structured templates. This includes details about training, license, limitations, etc.   \n\u2022 The paper should discuss whether and how consent was obtained from people whose asset is used.   \n\u2022 At submission time, remember to anonymize your assets (if applicable). You can either create an anonymized URL or include an anonymized zip file. ", "page_idx": 34}, {"type": "text", "text": "14. Crowdsourcing and Research with Human Subjects ", "text_level": 1, "page_idx": 34}, {"type": "text", "text": "Question: For crowdsourcing experiments and research with human subjects, does the paper include the full text of instructions given to participants and screenshots, if applicable, as well as details about compensation (if any)? ", "page_idx": 34}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 34}, {"type": "text", "text": "Justification: The paper does not involve human subjects and did not use crowd sourcing. Guidelines: ", "page_idx": 34}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u2022 Including this information in the supplemental material is fine, but if the main contribution of the paper involves human subjects, then as much detail as possible should be included in the main paper.   \n\u2022 According to the NeurIPS Code of Ethics, workers involved in data collection, curation, or other labor should be paid at least the minimum wage in the country of the data collector. ", "page_idx": 34}, {"type": "text", "text": "15. Institutional Review Board (IRB) Approvals or Equivalent for Research with Human Subjects ", "text_level": 1, "page_idx": 34}, {"type": "text", "text": "Question: Does the paper describe potential risks incurred by study participants, whether such risks were disclosed to the subjects, and whether Institutional Review Board (IRB) approvals (or an equivalent approval/review based on the requirements of your country or institution) were obtained? ", "page_idx": 34}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 34}, {"type": "text", "text": "Justification: The paper does not involve human subjects and did not use crowd sourcing. Guidelines: ", "page_idx": 34}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u2022 Depending on the country in which research is conducted, IRB approval (or equivalent) may be required for any human subjects research. If you obtained IRB approval, you should clearly state this in the paper.   \n\u2022 We recognize that the procedures for this may vary significantly between institutions and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the guidelines for their institution.   \n\u2022 For initial submissions, do not include any information that would break anonymity (if applicable), such as the institution conducting the review. ", "page_idx": 34}, {"type": "text", "text": "", "page_idx": 35}]