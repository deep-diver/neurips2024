[{"figure_path": "jeWZStUavo/tables/tables_7_1.jpg", "caption": "Table 1: Results of proxy metrics and PPA metrics on the ICCAD 2015 benchmarks. Global HPWL (1e8) and Regularity (1e6) are two proxy metrics. PPA metrics are evaluated by Cadence Innovus. The placement is performed by different methods, and the subsequent stages are performed by Cadence Innovus. rWL (m) is the routed wirelength; rO-H (%) and rO-V (%) represent the routed horizontal and vertical congestion overflow, respectively; WNS (ns) is the worst negative slack; TNS (1e5 \u00b5s) is the total negative slack; NVP (1e4) is the number of violation points. WNS and TNS are the larger the better, while the other metrics are the smaller the better. The best result of each metric on each chip is bolded.", "description": "This table presents a comparison of different macro placement methods (DREAMPlace, AutoDMP, WireMask-EA, MaskPlace, and MaskRegulate) using both proxy metrics (Global HPWL and Regularity) and actual PPA metrics (routed wirelength, congestion, timing slack, and violation points) evaluated using Cadence Innovus.  The results are shown for eight benchmark chips from the ICCAD 2015 dataset.  The best performance for each metric on each chip is highlighted.", "section": "4.2 RQ1: How does MaskRegulate perform compared to other methods?"}, {"figure_path": "jeWZStUavo/tables/tables_8_1.jpg", "caption": "Table 2: Generalization results of proxy metrics on the four chips of ICCAD 2015 benchmarks. The best result of each metric on each chip is bolded.", "description": "This table presents the generalization performance of MaskRegulate and MaskPlace.  The models were pre-trained on four chips from the ICCAD 2015 benchmark and then tested on four unseen chips. The table shows the Global HPWL (half-perimeter wirelength) and Regularity for each method on each of the test chips. The best results for each metric are highlighted in bold, indicating how well each method generalizes to unseen data.", "section": "4.3 RQ2: How is the generalization ability of MaskRegulate?"}, {"figure_path": "jeWZStUavo/tables/tables_13_1.jpg", "caption": "Table 1: Results of proxy metrics and PPA metrics on the ICCAD 2015 benchmarks. Global HPWL (1e8) and Regularity (1e6) are two proxy metrics. PPA metrics are evaluated by Cadence Innovus. The placement is performed by different methods, and the subsequent stages are performed by Cadence Innovus. rWL (m) is the routed wirelength; rO-H (%) and rO-V (%) represent the routed horizontal and vertical congestion overflow, respectively; WNS (ns) is the worst negative slack; TNS (1e5 \u00b5s) is the total negative slack; NVP (1e4) is the number of violation points. WNS and TNS are the larger the better, while the other metrics are the smaller the better. The best result of each metric on each chip is bolded.", "description": "This table presents a comparison of different macro placement methods using both proxy metrics (Global HPWL and Regularity) and actual PPA metrics (obtained using Cadence Innovus).  The proxy metrics provide quick estimates of placement quality, while the PPA metrics represent the final chip performance.  The table compares DREAMPlace, AutoDMP, WireMask-EA, MaskPlace, and the proposed MaskRegulate method across various benchmark chips, showing the best results in bold.", "section": "4.2 RQ1: How does MaskRegulate perform compared to other methods?"}, {"figure_path": "jeWZStUavo/tables/tables_14_1.jpg", "caption": "Table 1: Results of proxy metrics and PPA metrics on the ICCAD 2015 benchmarks. Global HPWL (1e8) and Regularity (1e6) are two proxy metrics. PPA metrics are evaluated by Cadence Innovus. The placement is performed by different methods, and the subsequent stages are performed by Cadence Innovus. rWL (m) is the routed wirelength; rO-H (%) and rO-V (%) represent the routed horizontal and vertical congestion overflow, respectively; WNS (ns) is the worst negative slack; TNS (1e5 \u00b5s) is the total negative slack; NVP (1e4) is the number of violation points. WNS and TNS are the larger the better, while the other metrics are the smaller the better. The best result of each metric on each chip is bolded.", "description": "This table presents a comparison of various macro placement methods using both proxy metrics (global HPWL and regularity) and actual PPA metrics obtained using Cadence Innovus.  The proxy metrics offer a quick estimate of placement quality, while the PPA metrics provide more comprehensive evaluation of power, performance, and area (PPA).  Results are shown for eight different chips from the ICCAD 2015 benchmark suite.", "section": "4.2 RQ1: How does MaskRegulate perform compared to other methods?"}, {"figure_path": "jeWZStUavo/tables/tables_14_2.jpg", "caption": "Table 1: Results of proxy metrics and PPA metrics on the ICCAD 2015 benchmarks. Global HPWL (1e8) and Regularity (1e6) are two proxy metrics. PPA metrics are evaluated by Cadence Innovus. The placement is performed by different methods, and the subsequent stages are performed by Cadence Innovus. rWL (m) is the routed wirelength; rO-H (%) and rO-V (%) represent the routed horizontal and vertical congestion overflow, respectively; WNS (ns) is the worst negative slack; TNS (1e5 \u03bcs) is the total negative slack; NVP (1e4) is the number of violation points. WNS and TNS are the larger the better, while the other metrics are the smaller the better. The best result of each metric on each chip is bolded.", "description": "This table presents a comparison of different macro placement methods on the ICCAD 2015 benchmark.  It shows results for both proxy metrics (Global HPWL and Regularity, which are used to estimate placement quality before detailed routing) and actual PPA (power, performance, and area) metrics obtained using Cadence Innovus (a commercial EDA tool). PPA metrics include routed wirelength, congestion, negative slack (timing), and the number of violations. The table allows for a comprehensive evaluation of the methods' effectiveness, considering both estimation-based and actual chip performance.", "section": "4.2 RQ1: How does MaskRegulate perform compared to other methods?"}, {"figure_path": "jeWZStUavo/tables/tables_15_1.jpg", "caption": "Table 6: Results of MaskPlace and Vanilla-MaskRegulate on four chips of ICCAD 2015 benchmarks. The only one difference between these two methods is the problem formulation, where all the other components are the same. The best result on each chip is bolded.", "description": "This table compares the performance of MaskPlace and Vanilla-MaskRegulate on four benchmark chips from the ICCAD 2015 dataset.  The key difference between the two methods is in their problem formulation; all other components remain the same. The results are presented as Global HPWL (half perimeter wirelength), a proxy metric for placement quality.  The best result for each chip is highlighted in bold.", "section": "B.1 Ablation studies"}, {"figure_path": "jeWZStUavo/tables/tables_15_2.jpg", "caption": "Table 7: Results of MaskRegulate and MaskRegulate without normalization on the four chips of ICCAD 2015 benchmarks. The best result of each metric on each chip is bolded.", "description": "This table presents a comparison of the performance of the MaskRegulate model with and without normalization.  The results are evaluated on four chips from the ICCAD 2015 benchmark dataset, focusing on two key metrics: Global HPWL (Half-Perimeter Wirelength) and Regularity.  The best result for each metric on each chip is highlighted in bold.  This ablation study helps determine the impact of normalization on the model's overall effectiveness.", "section": "B.1 Ablation studies"}, {"figure_path": "jeWZStUavo/tables/tables_15_3.jpg", "caption": "Table 1: Results of proxy metrics and PPA metrics on the ICCAD 2015 benchmarks. Global HPWL (1e8) and Regularity (1e6) are two proxy metrics. PPA metrics are evaluated by Cadence Innovus. The placement is performed by different methods, and the subsequent stages are performed by Cadence Innovus. rWL (m) is the routed wirelength; rO-H (%) and rO-V (%) represent the routed horizontal and vertical congestion overflow, respectively; WNS (ns) is the worst negative slack; TNS (1e5 \u00b5s) is the total negative slack; NVP (1e4) is the number of violation points. WNS and TNS are the larger the better, while the other metrics are the smaller the better. The best result of each metric on each chip is bolded.", "description": "This table presents a comparison of different macro placement methods on the ICCAD 2015 benchmark.  It shows both proxy metrics (Global HPWL and Regularity, which estimate placement quality before detailed routing) and actual PPA (Power, Performance, Area) metrics obtained using Cadence Innovus after standard cell placement and routing.  The PPA metrics include routed wirelength, congestion (horizontal and vertical), worst negative slack (WNS), total negative slack (TNS), and number of violation points (NVP).  The best result for each metric on each benchmark chip is highlighted.", "section": "4.2 RQ1: How does MaskRegulate perform compared to other methods?"}, {"figure_path": "jeWZStUavo/tables/tables_16_1.jpg", "caption": "Table 1: Results of proxy metrics and PPA metrics on the ICCAD 2015 benchmarks. Global HPWL (1e8) and Regularity (1e6) are two proxy metrics. PPA metrics are evaluated by Cadence Innovus. The placement is performed by different methods, and the subsequent stages are performed by Cadence Innovus. rWL (m) is the routed wirelength; rO-H (%) and rO-V (%) represent the routed horizontal and vertical congestion overflow, respectively; WNS (ns) is the worst negative slack; TNS (1e5 \u00b5s) is the total negative slack; NVP (1e4) is the number of violation points. WNS and TNS are the larger the better, while the other metrics are the smaller the better. The best result of each metric on each chip is bolded.", "description": "This table presents a comparison of different macro placement methods on the ICCAD 2015 benchmark.  It shows results for both proxy metrics (Global HPWL and Regularity, which estimate placement quality before detailed routing) and actual PPA (Power, Performance, Area) metrics obtained using Cadence Innovus (a commercial EDA tool) after completing the full design flow.  The PPA metrics include routed wirelength, horizontal and vertical congestion, worst and total negative slack, and number of violation points. The table highlights the performance of MaskRegulate against other methods, showing its superior performance in several key metrics.", "section": "4.2 RQ1: How does MaskRegulate perform compared to other methods?"}, {"figure_path": "jeWZStUavo/tables/tables_16_2.jpg", "caption": "Table 10: Generalization results of proxy metrics on eight chips of ISPD 2005 benchmarks. The best result of each metric on each chip is bolded.", "description": "This table presents the results of applying MaskPlace and MaskRegulate models, pre-trained on four chips from the ICCAD 2015 benchmark, to eight different chips from the ISPD 2005 benchmark.  The goal is to assess the generalization ability of these models.  The table shows the Global HPWL (half-perimeter wirelength) and Regularity for each chip and method. The best-performing method for each metric on each chip is highlighted in bold.", "section": "B.3 Experiments on ISPD 2005"}, {"figure_path": "jeWZStUavo/tables/tables_17_1.jpg", "caption": "Table 11: Results of proxy metrics on four chips of ICCAD 2015 benchmarks. We use our policy trained on superblue1, superblue3, superblue4 and superblue5 to finetune the placements gained from MaskPlace, AutoDMP and WireMask-BBO on superblue7, superblue10, superblue16 and superblue18. The left column indicates the Global HPWL (1e8) while the right column indicates the regularity (1e6). The best result of each metric on each chip is bolded.", "description": "This table presents the results of applying MaskRegulate to refine placement results obtained from three different methods (MaskPlace, AutoDMP, and WireMask-EA).  The experiments were conducted on four chips from the ICCAD 2015 benchmark (superblue7, superblue10, superblue16, and superblue18).  The table shows the Global HPWL (half-perimeter wirelength) and regularity metrics after refinement.  The best performing method for each metric on each chip is highlighted in bold.  The results demonstrate MaskRegulate's ability to improve upon existing placements.", "section": "4.3 RQ2: How is the generalization ability of MaskRegulate?"}]