[{"figure_path": "uzIWqRzjEP/figures/figures_2_1.jpg", "caption": "Figure 1: We design a network that learns how to locally edit an input program towards a target. It first predicts what type of edit operation should be applied, then it predicts where that edit operation should be applied, and finally it autoregressively samples any parameters the edit operation requires.", "description": "The figure illustrates the architecture of the edit network, which takes as input an existing visual program and its output, along with a target visual. The network predicts an edit operation (type, location, parameters) to improve the program's similarity to the target. The edit operation is applied to the input program, and the process is iterated. The network is composed of three main modules: operation type prediction, location prediction, and parameter prediction.", "section": "3.1 Edit Network Design"}, {"figure_path": "uzIWqRzjEP/figures/figures_4_1.jpg", "caption": "Figure 1: We design a network that learns how to locally edit an input program towards a target. It first predicts what type of edit operation should be applied, then it predicts where that edit operation should be applied, and finally it autoregressively samples any parameters the edit operation requires.", "description": "This figure illustrates the architecture of the edit network, a key component of the proposed system. The network takes as input a program, its execution result, and a visual target. It then predicts an edit operation, its location within the program, and any necessary parameters.  The process involves tokenizing the input program and target, embedding them, and utilizing a Transformer decoder architecture to predict the type, location, and parameters of the edit.  The predicted edits refine the input program incrementally to better match the target.", "section": "3.1 Edit Network Design"}, {"figure_path": "uzIWqRzjEP/figures/figures_4_2.jpg", "caption": "Figure 2: Left: our bootstrapping algorithm that finetunes an edit network and a one-shot model towards a target dataset. Right: our inference algorithm that initializes a population with a one-shot model and then mutates it towards a visual target through iterative rounds of edits and resampling.", "description": "This figure illustrates the two main algorithms used in the paper. The left side shows the bootstrapping algorithm, which iteratively refines both the edit network and the one-shot model using a combination of synthetic and real data.  The right side details the inference algorithm which begins with a population of programs generated by the one-shot model and progressively refines them towards the target visual representation by applying edits predicted by the edit network and then resampling based on reconstruction quality. This iterative process allows for a more directed and efficient program search compared to a purely one-shot approach.", "section": "3.2 Learning Paradigm"}, {"figure_path": "uzIWqRzjEP/figures/figures_6_1.jpg", "caption": "Figure 3: Comparing reconstructions of one-shot models (top) against our joint approach (middle).", "description": "This figure compares the visual reconstruction results of two methods: a one-shot model and a joint approach combining a one-shot model with an edit network.  The top row shows the reconstructions generated by the one-shot model alone. The middle row displays the results from the joint approach, highlighting its improved accuracy. The bottom row presents the target images that both methods aimed to reconstruct. The visual comparison clearly demonstrates the superior performance of the joint approach in accurately recreating the target images.", "section": "4.2 Reconstruction Accuracy"}, {"figure_path": "uzIWqRzjEP/figures/figures_7_1.jpg", "caption": "Figure 4: For 2D CSG, we compare reconstruction accuracy (Chamfer distance, lower is better, Y-axis) between using an edit network and using only a one-shot network while varying time spent on inference (left) and training set size (right).", "description": "This figure shows two graphs that compare the performance of two different methods for visual program induction: one using only a one-shot model and another integrating an edit network with a one-shot model. The left graph shows how reconstruction accuracy changes as the inference time increases (number of inference rounds). The right graph shows how the accuracy changes as the size of the training dataset increases (number of training shapes). In both cases, the method incorporating the edit network consistently outperforms the one-shot model, particularly as more time is spent on inference or with larger training datasets.", "section": "4. Results"}, {"figure_path": "uzIWqRzjEP/figures/figures_8_1.jpg", "caption": "Figure 5: Our inference procedure edits samples from an initial population (top) towards a target (bottom).", "description": "This figure demonstrates the iterative process of the proposed inference algorithm.  It begins with a population of initial program samples (top row), which are then iteratively modified (subsequent rows) by applying edits predicted by the edit network. Each edit brings the program closer to matching the target visual output (far right column), showing the iterative refinement of the program towards the target image.", "section": "3.3 Inference Algorithm"}, {"figure_path": "uzIWqRzjEP/figures/figures_12_1.jpg", "caption": "Figure 6: Qualitative reconstructions of \"challenge\" tasks for 3D CSG.", "description": "This figure shows qualitative comparisons of 3D CSG reconstruction results.  Three columns represent the results of using only a one-shot model, using the proposed joint model (one-shot + edit network), and the target shape. Each row displays a different shape, showcasing the improved accuracy of the proposed method in reconstructing complex 3D shapes that were not included in the initial training data.", "section": "B.1 Performance on more challenging tasks"}, {"figure_path": "uzIWqRzjEP/figures/figures_13_1.jpg", "caption": "Figure 5: Our inference procedure edits samples from an initial population (top) towards a target (bottom).", "description": "The figure shows how the proposed method improves visual program reconstruction through iterative edits.  Starting from an initial population of programs generated by a one-shot model, the algorithm iteratively applies local edits predicted by an edit network. The edits are guided by a visual target, and the process continues until the population converges towards programs that better reconstruct the target image. Each row represents a different visual program example, showing the initial population, the intermediate steps of applying edits, and the final result after multiple rounds of editing.", "section": "3.3 Inference Algorithm"}]