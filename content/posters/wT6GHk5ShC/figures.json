[{"figure_path": "wT6GHk5ShC/figures/figures_1_1.jpg", "caption": "Figure 1: The effect of weight pruning across different layer types. The figure shows the phenomenon observed on the benchmark datasets (SST-2, RTE, COPA) and open source LLMs (GPT-J-6B and LLAMA2-7B). Each sub-figure corresponds only to the indicated type of dataset, model and module. Notice that this figure mainly focuses on exhibiting the impact of weight pruning to the first two and the last two layers of the model and different colors are used to distinguish between these layers. The dashed line represents the pretrained model performance without SVD. We operate on the whole of MLP or ATTN and specifically marked the points of highest performance. The amount of weight pruning is severe, for instance, the highest model performance sometimes occurs at a clipping rate of 0.995. This is about 99.5% of the matrix's original rank. For the definitions of \u201cdeep\u201d and \u201cshallow\u201d, please refer to Appendix B.2.", "description": "This figure shows the results of applying SVD-based weight pruning to different layers of transformer models (GPT-J-6B and LLAMA-2-7B) on three benchmark datasets (SST-2, RTE, COPA).  It demonstrates that SVD-based pruning enhances in-context learning (ICL) performance, and that pruning deeper layers is more effective and stable than pruning shallower layers. Each subplot shows the performance (Accuracy/F1 score) against the pruning rate for a specific dataset, model, and module (MLP or ATTN) with different layers highlighted.", "section": "2 SVD-Based Weight Pruning can Enhance ICL"}, {"figure_path": "wT6GHk5ShC/figures/figures_3_1.jpg", "caption": "Figure 1: The effect of weight pruning across different layer types. The figure shows the phenomenon observed on the benchmark datasets (SST-2, RTE, COPA) and open source LLMs (GPT-J-6B and LLAMA2-7B). Each sub-figure corresponds only to the indicated type of dataset, model and module. Notice that this figure mainly focuses on exhibiting the impact of weight pruning to the first two and the last two layers of the model and different colors are used to distinguish between these layers. The dashed line represents the pretrained model performance without SVD. We operate on the whole of MLP or ATTN and specifically marked the points of highest performance. The amount of weight pruning is severe, for instance, the highest model performance sometimes occurs at a clipping rate of 0.995. This is about 99.5% of the matrix's original rank. For the definitions of \u201cdeep\u201d and \u201cshallow\u201d, please refer to Appendix B.2.", "description": "This figure shows the results of applying SVD-based weight pruning to different layers of Transformer models (GPT-J-6B and LLAMA2-7B) on three benchmark datasets (SST-2, RTE, COPA).  It demonstrates that SVD-based pruning enhances in-context learning (ICL) performance, and that pruning deeper layers is often more effective and stable than pruning shallower layers.  Each sub-plot represents a specific dataset, model, and module (MLP or Attention), showing the accuracy/F1 score against the clipping rate (percentage of weights pruned).  The dashed line represents the baseline performance without pruning.", "section": "SVD-Based Weight Pruning can Enhance ICL"}, {"figure_path": "wT6GHk5ShC/figures/figures_8_1.jpg", "caption": "Figure 1: The effect of weight pruning across different layer types. The figure shows the phenomenon observed on the benchmark datasets (SST-2, RTE, COPA) and open source LLMs (GPT-J-6B and LLAMA2-7B). Each sub-figure corresponds only to the indicated type of dataset, model and module. Notice that this figure mainly focuses on exhibiting the impact of weight pruning to the first two and the last two layers of the model and different colors are used to distinguish between these layers. The dashed line represents the pretrained model performance without SVD. We operate on the whole of MLP or ATTN and specifically marked the points of highest performance. The amount of weight pruning is severe, for instance, the highest model performance sometimes occurs at a clipping rate of 0.995. This is about 99.5% of the matrix's original rank. For the definitions of \u201cdeep\u201d and \u201cshallow\u201d, please refer to Appendix B.2.", "description": "This figure displays the results of applying SVD-based weight pruning to different layers (shallow vs. deep) and modules (MLP vs. ATTN) of two LLMs (GPT-J-6B and LLAMA2-7B) across three benchmark datasets (SST-2, RTE, COPA).  It demonstrates that SVD-based pruning enhances ICL performance, and that pruning deeper layers often yields more stable improvements than pruning shallow layers. The x-axis represents the clipping rate (proportion of weights removed), and the y-axis shows the accuracy/F1 score.  The dashed lines represent the baseline performance without pruning.", "section": "SVD-Based Weight Pruning can Enhance ICL"}, {"figure_path": "wT6GHk5ShC/figures/figures_9_1.jpg", "caption": "Figure 4: The Model Performance on Test set by different tasks. The results are obtained by comparing four scenarios: ICL (GPT-J-6B), ICL+Algorithm1 (GPT-J-6B), ICL (LLAMA2-7B) and ICL+Algorithm1 (LLAMA2-7B). ICL+Algorithm1 demonstrates superior results over only ICL on different tasks. See Appendix C.5 for detailed numbers.", "description": "This figure shows the performance of the proposed Algorithm 1 compared to standard ICL on eight different downstream tasks. Two different LLMs (GPT-J-6B and LLAMA2-7B) are used.  Each bar represents the accuracy or F1 score for a given task and model.  The results indicate that Algorithm 1 consistently improves performance across these diverse tasks.", "section": "4 Conclusion and Limitation"}, {"figure_path": "wT6GHk5ShC/figures/figures_23_1.jpg", "caption": "Figure 1: The effect of weight pruning across different layer types. The figure shows the phenomenon observed on the benchmark datasets (SST-2, RTE, COPA) and open source LLMs (GPT-J-6B and LLAMA2-7B). Each sub-figure corresponds only to the indicated type of dataset, model and module. Notice that this figure mainly focuses on exhibiting the impact of weight pruning to the first two and the last two layers of the model and different colors are used to distinguish between these layers. The dashed line represents the pretrained model performance without SVD. We operate on the whole of MLP or ATTN and specifically marked the points of highest performance. The amount of weight pruning is severe, for instance, the highest model performance sometimes occurs at a clipping rate of 0.995. This is about 99.5% of the matrix's original rank. For the definitions of \u201cdeep\u201d and \u201cshallow\u201d, please refer to Appendix B.2.", "description": "This figure shows the impact of SVD-based weight pruning on the performance of different layers in LLMs during in-context learning.  The results are shown for three benchmark datasets (SST-2, RTE, COPA) and two LLMs (GPT-J-6B and LLAMA2-7B).  The plots illustrate that pruning can enhance performance, with deeper layers often showing more stable improvements than shallower layers, even with very aggressive pruning.", "section": "SVD-Based Weight Pruning can Enhance ICL"}]