[{"figure_path": "739jAzUXk7/figures/figures_1_1.jpg", "caption": "Figure 1: (a) Previous UDA approaches on point cloud suffer from catastrophic forgetting and error accumulation toward the continually changing target domains. (b) In contrast, we present an innovative framework PCOTTA to address these issues, enhancing the model's transferability.", "description": "This figure compares previous Unsupervised Domain Adaptation (UDA) approaches with the proposed PCoTTA framework. (a) illustrates the limitations of previous UDA methods in handling continually changing target domains, such as catastrophic forgetting and error accumulation. (b) shows the proposed PCoTTA framework which addresses these limitations by enhancing the model's transferability.  The key difference is that PCoTTA utilizes a prototype bank to effectively manage continual adaptation, avoiding the issues present in previous methods.", "section": "1 Introduction"}, {"figure_path": "739jAzUXk7/figures/figures_3_1.jpg", "caption": "Figure 2: Our PCoTTA. It addresses continually changing targets by using their nearest source sample as a prompt for multi-task learning within a unified model. We introduce Gaussian Splatted Feature Shifting (GSFS) to align unknown targets with sources, improving transferability. Source prototypes from different domains and learnable prototypes form a prototype bank. The Automatic Prototype Mixture (APM) pairs these prototypes based on the similarity to the target, preventing catastrophic forgetting. We project these prototypes as Gaussian distributions onto the feature plane, with larger weights assigned to more relevant ones. Our graph attention updates these weights dynamically to mitigate error accumulation. Additionally, our Contrastive Prototype Repulsion (CPR) ensures that learnable prototypes are distinguishable for different targets, enhancing adaptability.", "description": "This figure illustrates the PCoTTA framework.  It shows how a unified model handles multiple tasks (reconstruction, denoising, registration) and continually changing target domains by using a source domain as a prompt,  aligning unknown targets with known sources via Gaussian Splatted Feature Shifting (GSFS), managing prototypes via Automatic Prototype Mixture (APM) and Contrastive Prototype Repulsion (CPR) to avoid catastrophic forgetting and enhance adaptability.", "section": "3 Method"}, {"figure_path": "739jAzUXk7/figures/figures_4_1.jpg", "caption": "Figure 3: (a) Automatic Prototype Mixture (APM) considers both source and learnable prototypes with their similarities to the target, mitigating catastrophic forgetting by preserving source information. (b) Gaussian Spaltted-based Graph Attention enables dynamic updating weights among all prototype-pair nodes based on the Gaussian projections splatted onto the feature plane.", "description": "This figure illustrates the two core modules of PCoTTA: Automatic Prototype Mixture (APM) and Gaussian Splatted-based Graph Attention.  APM combines source and learnable prototypes based on their similarity to the target, preventing catastrophic forgetting. The Gaussian Splatted-based Graph Attention dynamically adjusts weights based on Gaussian projections of prototype pairs, adapting to continually changing target domains.", "section": "3 Method"}, {"figure_path": "739jAzUXk7/figures/figures_9_1.jpg", "caption": "Figure 4: Visualization of our PCoTTA's prediction and their ground truths under 3 different tasks.", "description": "This figure visualizes the results of the PCoTTA model on three different tasks: reconstruction, denoising, and registration. It shows the input point clouds, the model's output, and the ground truth for both ModelNet40 and ScanObjectNN datasets.  The visualization helps to understand the model's performance in handling various challenges related to point cloud data, including reconstructing incomplete shapes, removing noise, and aligning point clouds.", "section": "4.4 Visualization and Analysis"}, {"figure_path": "739jAzUXk7/figures/figures_9_2.jpg", "caption": "Figure 5: T-SNE visualization of the source and target features.", "description": "This figure visualizes the feature distributions of source and target domains using t-SNE. It compares the feature alignment of three different methods: the baseline, CoTTA, and the proposed method (Ours).  The baseline shows poor alignment, while CoTTA exhibits improved alignment but still shows some mis-alignments or over-alignments. The proposed method demonstrates superior feature alignment across domains, highlighting its effectiveness in narrowing the domain shifts in continually changing environments.", "section": "4.4 Visualization and Analysis"}, {"figure_path": "739jAzUXk7/figures/figures_16_1.jpg", "caption": "Figure 5: T-SNE visualization of the source and target features.", "description": "This figure uses t-SNE to visualize the feature distributions of the source and target domains for the point cloud reconstruction task.  It compares three different methods: a baseline (no adaptation), COTTA, and the proposed PCoTTA.  The visualization shows how well each method aligns the features of the source and target domains.  PCoTTA demonstrates superior alignment compared to the other methods, indicating better domain adaptation and transferability.", "section": "4.4 Visualization and Analysis"}, {"figure_path": "739jAzUXk7/figures/figures_16_2.jpg", "caption": "Figure 4: Visualization of our PCoTTA's prediction and their ground truths under 3 different tasks.", "description": "This figure visualizes the results of three different tasks (Reconstruction, Denoising, and Registration) performed by the proposed PCoTTA model.  It shows the input point cloud, the model's output (prediction), and the corresponding ground truth for each task across three different datasets (ModelNet40, ScanObjectNN). The figure demonstrates PCoTTA's ability to handle various point cloud tasks while adapting to different data distributions.  The visual comparison allows assessing the model's accuracy and generalization capabilities in a multi-task and multi-domain scenario.", "section": "4.4 Visualization and Analysis"}, {"figure_path": "739jAzUXk7/figures/figures_17_1.jpg", "caption": "Figure C: Visualization of our PCOTTA and state-of-the-art methods under 3 different tasks.", "description": "This figure visualizes the results of different methods (PointNet, DGCNN, PointCutMix, CoTTA, and the proposed PCOTTA) on three tasks: reconstruction, denoising, and registration.  For each task, the input point cloud and the outputs of each method are shown, alongside the ground truth.  This allows a visual comparison of the performance of various methods in handling different point cloud processing tasks.", "section": "A.4 More Visualization Results"}]