[{"figure_path": "ZulWEWQOp9/tables/tables_7_1.jpg", "caption": "Table 1: Inference efficiency. Ctrl-X is slightly slower than training-based baselines yet significantly faster than training-free baselines and Splicing ViT Features. Moreover, Ctrl-X has lower peak GPU memory usage than SDXL v1.0 training-based methods and significantly lower memory than SDXL v1.0 training-free methods. (Uni-ControlNet and Cross-Image attention uses SD v1.5, which is ~ 4-5\u00d7 faster and uses ~ 3\u00d7 more memory compared to SDXL v1.0. Splicing ViT Features also trains its own much smaller custom model.)", "description": "This table compares the inference efficiency of Ctrl-X against other methods.  It shows that Ctrl-X, while slightly slower than some training-based methods, is significantly faster than other training-free and guidance-free methods.  The table also highlights that Ctrl-X requires less GPU memory than many of its counterparts.", "section": "5 Experiments"}, {"figure_path": "ZulWEWQOp9/tables/tables_8_1.jpg", "caption": "Table 2: Quantitative comparison of structure and appearance control. Ctrl-X consistently outperforms both training-based and training-free methods in appearance alignment and shows comparable or better structure preservation compared to training-based and guidance-free methods, measured by DINO ViT self-similarity [35] and DINO-I [30], respectively.", "description": "This table quantitatively compares the performance of Ctrl-X against several baseline methods for structure and appearance control in text-to-image generation.  The comparison uses two metrics: DINO ViT self-similarity (lower scores indicate better structure preservation) and DINO-I (higher scores indicate better appearance transfer). The methods are categorized as training-based (requiring training on paired data) or training-free (no additional training needed).  The table shows that Ctrl-X, despite being training-free, outperforms most other methods in terms of appearance transfer and achieves comparable results in structure preservation.", "section": "5 Experiments"}, {"figure_path": "ZulWEWQOp9/tables/tables_14_1.jpg", "caption": "Table 3: Comparison to prior works. Comparing the capabilities of Ctrl-X to prior controllable generation works. Natural images and in-the-wild conditions refer to the type of structure image that the method supports for structure control.", "description": "This table compares the capabilities of Ctrl-X with other state-of-the-art methods for controllable image generation.  It shows whether each method supports structure and appearance control, whether it requires training, and whether it is guidance-free. The table also indicates which methods support natural images and 'in-the-wild' conditions as structure inputs.  'In-the-wild' conditions refer to less conventional input types beyond typical images, potentially including sketches or 3D models.", "section": "5 Experiments"}, {"figure_path": "ZulWEWQOp9/tables/tables_14_2.jpg", "caption": "Table 4: Qualitative comparison of structure and appearance control via user study. The human preference percentages here show how often the participants preferred Ctrl-X over each of the baselines on result quality, structure fidelity, appearance fidelity, and overall fidelity. Ctrl-X consistently outperforms training-free baselines and is competitive with training-based ones, especially with overall fidelity, showcasing Ctrl-X's ability to balance structure and appearance control.", "description": "This table presents the results of a user study comparing Ctrl-X to several baseline methods for structure and appearance control in text-to-image generation.  The study evaluated the methods based on four criteria: overall image quality, fidelity to the structure image, fidelity to the appearance image, and overall fidelity to both structure and appearance.  The results show Ctrl-X outperforms training-free baselines and is competitive with training-based methods, particularly in terms of overall fidelity.", "section": "5 Experiments"}, {"figure_path": "ZulWEWQOp9/tables/tables_17_1.jpg", "caption": "Table 2: Quantitative comparison of structure and appearance control. Ctrl-X consistently outperforms both training-based and training-free methods in appearance alignment and shows comparable or better structure preservation compared to training-based and guidance-free methods, measured by DINO ViT self-similarity [35] and DINO-I [30], respectively.", "description": "This table presents a quantitative comparison of different methods for controlling structure and appearance in text-to-image generation.  It compares Ctrl-X against several baselines using two metrics: DINO Self-sim (measuring structure preservation) and DINO-I (measuring appearance transfer).  The results show that Ctrl-X outperforms other methods in appearance alignment and achieves comparable or better structure preservation.", "section": "5.1 T2I diffusion with structure and appearance control"}]