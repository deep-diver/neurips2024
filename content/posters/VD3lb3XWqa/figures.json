[{"figure_path": "VD3lb3XWqa/figures/figures_3_1.jpg", "caption": "Figure 1: A system which may or may not be self-aware.", "description": "This figure shows a system that interacts with the world through inputs and outputs. The inputs can be categorized into those generated by the system itself (green) and those coming from the external world (red).  A self-aware system would be able to distinguish between its own inputs and external inputs. This is the basis of the proposed test for machine self-awareness.", "section": "2 A Test for Self-Awareness"}, {"figure_path": "VD3lb3XWqa/figures/figures_4_1.jpg", "caption": "Figure 2: The Nesting Doll of Self-Awareness.", "description": "This figure illustrates the Nesting Doll model of self-awareness.  It depicts concentric circles representing increasing levels of self-awareness, starting from the innermost level of awareness of one's thoughts, progressing outwards to interoception (awareness of internal bodily states), awareness of material possessions, and finally, awareness of social connections. Each level is nested within the next, and the outermost circle is influenced by the external world. The model is represented visually by a set of nested Russian dolls, each representing a level of self-awareness.", "section": "2.3 Levels of Self-Awareness"}, {"figure_path": "VD3lb3XWqa/figures/figures_5_1.jpg", "caption": "Figure 3: Two conversations with an LLM used as a chatbot. The tokens generated by the LLM are shown in green, while the User's tokens are shown in red. The [System:] and [User:] tokens are, strictly speaking, not generated by the User or LLM, and are shown in red.", "description": "This figure illustrates two conversations between a user and a large language model (LLM) chatbot.  The first conversation shows a typical interaction where the LLM responds appropriately to the user's prompts. The second conversation reverses the roles, with the user acting as if they were the LLM and the LLM acting as if it were the user.  The color-coding helps distinguish the tokens generated by the LLM (green) from those generated by the user (red).  The figure is used to highlight the challenge of determining whether an LLM is self-aware merely by observing its output.  The inclusion of 'System:' and 'User:' tokens which are not generated by either participant, is explicitly noted. ", "section": "3 Methods"}, {"figure_path": "VD3lb3XWqa/figures/figures_5_2.jpg", "caption": "Figure 3: Two conversations with an LLM used as a chatbot. The tokens generated by the LLM are shown in green, while the User's tokens are shown in red. The [System:] and [User:] tokens are, strictly speaking, not generated by the User or LLM, and are shown in red.", "description": "This figure illustrates two conversations between a user and a large language model (LLM) chatbot.  The first conversation shows a normal interaction, with the user and LLM taking turns. The second conversation reverses the roles, with the LLM acting as the user and the user acting as the LLM.  This is a control for the experiment, to determine if the LLM can identify its own generated text regardless of assigned labels. Tokens generated by the LLM are highlighted in green, while tokens generated by the user are in red.  The square brackets show the message labels ([User:] and [System:]), which are not part of the conversation content and are shown in red.", "section": "3 Methods"}, {"figure_path": "VD3lb3XWqa/figures/figures_6_1.jpg", "caption": "Figure 4: A self-aware human can recognize their reflection and still can when wearing a mask.", "description": "The figure shows two simple drawings.  In the left drawing, a figure looks at its own reflection in a mirror and recognizes it. In the right drawing, the figure is wearing a mask, obscuring its face; even so, it still recognizes itself in the reflection.  This is used in the paper to illustrate the concept that self-awareness is about recognizing one's own inputs among a larger set of inputs, even when aspects of those inputs are masked or changed.", "section": "3.2 Controlling for Message Labels"}]