[{"figure_path": "Po7iQKKT5b/figures/figures_1_1.jpg", "caption": "Figure 1: We compare state-of-the-art optical flow estimators and a neuroscience inspired motion energy model on a figure-ground segmentation task. For evaluation, we use random dot stimuli with the same motion patterns as the original videos, but for which the appearance of each individual frame is informative (example video in the supplemental material). The neuroscience inspired model generalizes to these stimuli much better than state-of-the-art optical flow models.", "description": "This figure compares the performance of various optical flow models and a neuroscience-inspired motion energy model on a figure-ground segmentation task.  The models are tested on both original videos and corresponding random dot stimuli that preserve the original motion patterns but lack texture information. The results show that the motion energy model outperforms the optical flow models in generalizing to the random dot stimuli, demonstrating a more human-like zero-shot generalization ability.", "section": "1 Introduction"}, {"figure_path": "Po7iQKKT5b/figures/figures_4_1.jpg", "caption": "Figure 2: (top) Our motion segmentation architecture: The motion estimation predicts multi-scale optical flow or motion energy, the segmentation model predicts the moving foreground region. (bottom left) The motion energy model is implemented as a CNN. The weights are chosen such that the CNN is equivalent to the original model by [37]. (bottom right) The segmentation model combines motion features across scale and predicts a binary segmentation at the input resolution.", "description": "This figure illustrates the architecture of the motion segmentation model used in the paper.  It's a two-stage process. The first stage is motion estimation, which can use either optical flow or a neuroscience-inspired motion energy model. This stage produces multi-scale motion features. The second stage is a segmentation model which is a CNN that takes these multi-scale features as input and predicts a binary segmentation mask. The motion energy model itself is shown as a CNN, where the weights are derived from a pre-existing model in the literature. This ensures that the model is both biologically inspired and computationally efficient.", "section": "3 Methods"}, {"figure_path": "Po7iQKKT5b/figures/figures_7_1.jpg", "caption": "Figure 1: We compare state-of-the-art optical flow estimators and a neuroscience inspired motion energy model on a figure-ground segmentation task. For evaluation, we use random dot stimuli with the same motion patterns as the original videos, but for which the appearance of each individual frame is informative (example video in the supplemental material). The neuroscience inspired model generalizes to these stimuli much better than state-of-the-art optical flow models.", "description": "This figure compares the performance of various optical flow models and a neuroscience-inspired motion energy model on a figure-ground segmentation task using random dot stimuli.  The random dot stimuli retain the motion patterns of original videos, but lack informative appearance features. The results visually demonstrate the superior generalization ability of the motion energy model compared to the optical flow models when dealing with stimuli lacking distinct texture information.", "section": "1 Introduction"}, {"figure_path": "Po7iQKKT5b/figures/figures_8_1.jpg", "caption": "Figure 4: We compare humans and machines using a random dot shape identification task as a proxy to measure segmentation in humans. Shown a video of random dots, participants have to respond which of two shapes was perceived in the video. Humans outperformed all optical flow based models, but not the motion energy based model for this task. More details are provided in the supplemental material.", "description": "This figure presents a comparison of human and machine performance on a shape identification task using random dot stimuli.  The task involved identifying a target shape embedded within a video of moving random dots. The figure shows that human participants significantly outperformed all optical flow-based models, yet were matched by the motion energy model, demonstrating the efficacy of the motion energy model for zero-shot generalization to random dot stimuli.", "section": "5 Human Machine Comparison"}, {"figure_path": "Po7iQKKT5b/figures/figures_14_1.jpg", "caption": "Figure 5: Segmentation performances of the evaluated models on the random dot stimuli. Same data as in Table 1.", "description": "This bar chart displays the Intersection over Union (IoU) scores achieved by various motion estimation models on a random dot stimuli segmentation task.  The models are ordered from lowest to highest IoU, clearly demonstrating the superior performance of the motion energy model compared to state-of-the-art optical flow models on this zero-shot generalization task. The data presented mirrors the information from Table 1 but in a visual format that facilitates comparison of model performance.", "section": "Additional details about the results"}, {"figure_path": "Po7iQKKT5b/figures/figures_15_1.jpg", "caption": "Figure 6: Performance of multi-frame optical flow based models on the original videos and corresponding random dot videos.", "description": "This figure compares the performance of multi-frame optical flow models and the motion energy model on both original videos and their corresponding random dot versions.  The x-axis represents the Intersection over Union (IoU) score achieved on the original videos, and the y-axis represents the IoU score on the zero-shot random dot stimuli. Each point represents a different model. The diagonal dashed line indicates the ideal scenario where performance on the original and random dot videos are equal.  The plot shows that motion energy significantly outperforms optical flow models in generalizing to random dot stimuli (zero-shot), which is indicated by the significant vertical displacement of the motion energy model point from the diagonal. The optical flow models mostly cluster near the diagonal, demonstrating their limited ability to generalize to unseen texture.", "section": "B Additional experiments"}, {"figure_path": "Po7iQKKT5b/figures/figures_17_1.jpg", "caption": "Figure 7: (left) As a measure of task difficulty, we count the number of informative dots that allow discriminating betwen the two shape alternatives. (right) Psychometric curves for humans, the motion energy based model and the four best optical flow models for the task as in 8.", "description": "This figure shows a comparison of human and model performance in a shape identification task using random dot stimuli. The left panel displays an example stimulus, highlighting the informative dots (those belonging to only one of the target or distractor shapes). The right panel shows psychometric curves, plotting the proportion of correct responses against the number of informative dots per frame. The curves demonstrate that the motion energy model's performance closely matches human performance, particularly for medium difficulty levels, while optical flow models significantly underperform.", "section": "C Additional details about the human subject study"}, {"figure_path": "Po7iQKKT5b/figures/figures_17_2.jpg", "caption": "Figure 3: Example predictions for different motion estimators. The motion pattern in the random dot stimulus is the same as in the original video. While the optical flow estimates are highly accurate for the original videos, the models struggle with the random dot stimuli that exhibit the same motion. The activations of the motion energy model model however generalize well to the random dot stimuli, enabling to detect and segment the foreground object.", "description": "This figure compares the performance of different motion estimation models (optical flow and motion energy) on a figure-ground segmentation task. It shows example predictions for the original videos (left) and corresponding random dot stimuli (right). The motion pattern is the same for both original video and the random dot stimuli. While optical flow models show high accuracy for original videos but fail to generalize to random dots, the motion energy model demonstrates better generalization. The motion energy model's activations maintain a similar pattern for both original and random dot stimuli, enabling it to accurately segment the foreground object in both cases.", "section": "Results"}, {"figure_path": "Po7iQKKT5b/figures/figures_18_1.jpg", "caption": "Figure 3: Example predictions for different motion estimators. The motion pattern in the random dot stimulus is the same as in the original video. While the optical flow estimates are highly accurate for the original videos, the models struggle with the random dot stimuli that exhibit the same motion. The activations of the motion energy model model however generalize well to the random dot stimuli, enabling to detect and segment the foreground object.", "description": "This figure compares the performance of various motion estimation models on both original videos and their corresponding random dot stimuli. It shows that while optical flow methods perform well on original videos, they struggle to generalize to random dot stimuli with the same motion patterns. In contrast, the motion energy model demonstrates good generalization to random dot stimuli.", "section": "4 Results"}]