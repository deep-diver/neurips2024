[{"figure_path": "ds6xMV3yVV/figures/figures_8_1.jpg", "caption": "Figure 3: Tracking a highly-unpredictable signal: number of neurons: 5, q = 100 (accuracy), weight reg = 1, derivative of weight reg = 0.1.", "description": "This figure shows the result of applying the proposed algorithm to track a complex, unpredictable signal.  The blue line represents the output of the neural network attempting to follow the target signal (orange dashed line). The parameters used in this experiment included 5 neurons, an accuracy term (q) of 100, a weight regularization term (rw) of 1, and a derivative of the weight term (r) of 0.1. This experiment demonstrates the algorithm's ability to track a signal that is difficult to predict due to its highly variable nature.", "section": "4.2 Continuous Time Reversal of State and Costate"}, {"figure_path": "ds6xMV3yVV/figures/figures_8_2.jpg", "caption": "Figure 1: Recurrent net with 5 neurons, q = 10 (accuracy term), rw = 1 (weight regularization term), r = 0.1 (derivative of the weight term).", "description": "This figure shows the result of applying the proposed recurrent neural network model to track a sinusoidal signal.  The blue line represents the output of the network (x), while the orange dashed line represents the target signal (z). The parameters q, rw, and r control the accuracy of the approximation, the weight regularization, and the derivative of the weight term respectively.  The plot demonstrates the network's ability to track the target signal with a relatively small number of neurons and chosen parameters.", "section": "4.2 Continuous Time Reversal of State and Costate"}, {"figure_path": "ds6xMV3yVV/figures/figures_9_1.jpg", "caption": "Figure 3: Tracking a highly-unpredictable signal: number of neurons: 5, q = 100 (accuracy), weight reg = 1, derivative of weight reg = 0.1.", "description": "This figure shows the result of applying the Hamiltonian Sign Flip method to track a highly unpredictable signal. The signal is composed of patching intervals with cosine functions with constants and is purposely generated to be hard to predict.  The network uses 5 neurons. The parameters used are: accuracy term (q) = 100, weight regularization term (rw) = 1, derivative of the weight term (r) = 0.1. The plot displays the tracked signal (x, blue line) against the target signal (z, orange dotted line). The figure demonstrates the network's ability to track the signal despite its high unpredictability.", "section": "4.2 Continuous Time Reversal of State and Costate"}, {"figure_path": "ds6xMV3yVV/figures/figures_9_2.jpg", "caption": "Figure 4: Evolution of the Lagrangian and of the Hamiltonian function for the experiment whose tracking is shown in Fig. 3.", "description": "This figure shows the evolution of both the Lagrangian and Hamiltonian functions over time for a specific tracking experiment (Experiment 3).  It illustrates the energy exchange dynamics during the learning process. The Lagrangian represents the cost function being minimized, while the Hamiltonian reflects the system's overall energy. The plot visually represents how the system navigates the energy landscape to achieve the tracking goal.", "section": "4.2 Continuous Time Reversal of State and Costate"}, {"figure_path": "ds6xMV3yVV/figures/figures_15_1.jpg", "caption": "Figure 5: Architecture used in the experiments. The red neuron is the one that is used as output and it is forced to follow the reference (target) signal.", "description": "This figure shows the architecture of the recurrent neural network used in the experiments of Section 4.2 of the paper.  It's a fully connected graph with five neurons (nodes) and numerous weighted connections (edges) between them. The neurons are labeled as 1 through 5. Each edge is annotated with a weight (Wij). One neuron is highlighted in red, signifying that it serves as the output neuron and is constrained to follow a reference (or target) signal during the experiments. This network is used to validate the Hamiltonian Sign Flip (HSF) strategy discussed in the paper, aiming to improve online learning by addressing issues with boundary conditions in the Hamiltonian equations.", "section": "E Architectural and Algorithmic details"}]