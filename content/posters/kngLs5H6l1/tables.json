[{"figure_path": "kngLs5H6l1/tables/tables_7_1.jpg", "caption": "Table 1: Quantitative comparisons of the rendering quality. Our methods achieve comparable or even better results compared with the SOTA approach, SpecGaussian [5]. However, SpecGaussian performs much worse in normal estimation, while ours achieves a good balance between geometry and appearance quality. \u2020 denotes the results quoted from their paper. GShader* fails on the Deep Blending scene.", "description": "This table presents a quantitative comparison of the rendering quality achieved by different methods, including the proposed Normal-GS method and several state-of-the-art baselines. The metrics used for comparison are PSNR, SSIM, and LPIPS.  The table highlights that Normal-GS achieves competitive or superior rendering quality compared to other methods, while simultaneously achieving significantly better normal estimation accuracy than methods like SpecGaussian.", "section": "4 Experiments"}, {"figure_path": "kngLs5H6l1/tables/tables_8_1.jpg", "caption": "Table 3: Quantitative ablation studies on DTU.", "description": "This table presents a quantitative analysis of the impact of different components of the proposed Normal-GS method on the DTU dataset.  It compares the mean Chamfer distance (mCD), a metric for geometry accuracy, and the Peak Signal-to-Noise Ratio (PSNR), a metric for rendering quality. The models compared are: (a) the baseline Scaffold-GS; (b) Scaffold-GS with the addition of a depth-regularized loss term on normals (LN); (c) model (b) with the addition of a specular loss term (Lspecular); and (d) the full Normal-GS model. The results show the effect of each component on both geometry and rendering quality.", "section": "4 Experiments"}, {"figure_path": "kngLs5H6l1/tables/tables_9_1.jpg", "caption": "Table 1: Quantitative comparisons of the rendering quality. Our methods achieve comparable or even better results compared with the SOTA approach, SpecGaussian [5]. However, SpecGaussian performs much worse in normal estimation, while ours achieves a good balance between geometry and appearance quality. \u2020 denotes the results quoted from their paper. GShader* fails on the Deep Blending scene.", "description": "This table presents a quantitative comparison of the rendering quality of different methods, including the proposed Normal-GS method and several state-of-the-art baselines. The metrics used are PSNR, SSIM, and LPIPS, which are commonly used to evaluate the visual quality of images. The table shows that Normal-GS achieves comparable or better results than the best performing baseline, SpecGaussian, in terms of rendering quality while significantly outperforming it in terms of normal accuracy. The results highlight the ability of Normal-GS to achieve a good balance between rendering quality and geometry accuracy, unlike other methods that may sacrifice one for the other.", "section": "4 Experiments"}, {"figure_path": "kngLs5H6l1/tables/tables_9_2.jpg", "caption": "Table 5: Geometric and rendering quality comparisons on the DTU dataset.", "description": "This table presents a comparison of geometric reconstruction and rendering quality between different methods on the DTU dataset.  The metrics used are mean Chamfer distance (mCD), which measures the geometric accuracy, and Peak Signal-to-Noise Ratio (PSNR), which assesses rendering quality. Lower mCD values indicate better geometric accuracy, while higher PSNR values correspond to better rendering quality. The table shows that our method achieves a good balance between geometric accuracy and rendering quality, outperforming some baseline methods in PSNR while maintaining a competitive mCD.", "section": "4.3 Geometric reconstruction comparisons"}, {"figure_path": "kngLs5H6l1/tables/tables_14_1.jpg", "caption": "Table 1: Quantitative comparisons of the rendering quality. Our methods achieve comparable or even better results compared with the SOTA approach, SpecGaussian [5]. However, SpecGaussian performs much worse in normal estimation, while ours achieves a good balance between geometry and appearance quality. \u2020 denotes the results quoted from their paper. GShader* fails on the Deep Blending scene.", "description": "This table presents a quantitative comparison of rendering quality metrics (PSNR, SSIM, LPIPS) for several methods, including the proposed Normal-GS and state-of-the-art baselines.  It highlights the competitive rendering quality of Normal-GS while emphasizing its superior performance in normal estimation compared to SpecGaussian, which prioritizes rendering quality at the cost of normal accuracy.", "section": "4 Experiments"}, {"figure_path": "kngLs5H6l1/tables/tables_16_1.jpg", "caption": "Table 1: Quantitative comparisons of the rendering quality. Our methods achieve comparable or even better results compared with the SOTA approach, SpecGaussian [5]. However, SpecGaussian performs much worse in normal estimation, while ours achieves a good balance between geometry and appearance quality. \u2020 denotes the results quoted from their paper. GShader* fails on the Deep Blending scene.", "description": "This table presents a quantitative comparison of the rendering quality achieved by different methods, including the proposed Normal-GS method and several state-of-the-art baselines.  Metrics used for comparison include PSNR, SSIM, and LPIPS, across three datasets: Mip-NeRF360, Tanks & Temples, and Deep Blending.  The results show that Normal-GS achieves competitive or superior rendering quality while also demonstrating significantly improved normal estimation accuracy compared to other methods, particularly SpecGaussian.", "section": "4 Experiments"}, {"figure_path": "kngLs5H6l1/tables/tables_16_2.jpg", "caption": "Table 1: Quantitative comparisons of the rendering quality. Our methods achieve comparable or even better results compared with the SOTA approach, SpecGaussian [5]. However, SpecGaussian performs much worse in normal estimation, while ours achieves a good balance between geometry and appearance quality. \u2020 denotes the results quoted from their paper. GShader* fails on the Deep Blending scene.", "description": "This table presents a quantitative comparison of rendering quality metrics (PSNR, SSIM, LPIPS) for several methods, including the proposed Normal-GS and state-of-the-art baselines. It highlights the competitive rendering quality of Normal-GS while demonstrating its superior performance in normal estimation compared to SpecGaussian.", "section": "4 Experiments"}, {"figure_path": "kngLs5H6l1/tables/tables_16_3.jpg", "caption": "Table 1: Quantitative comparisons of the rendering quality. Our methods achieve comparable or even better results compared with the SOTA approach, SpecGaussian [5]. However, SpecGaussian performs much worse in normal estimation, while ours achieves a good balance between geometry and appearance quality. \u2020 denotes the results quoted from their paper. GShader* fails on the Deep Blending scene.", "description": "This table presents a quantitative comparison of the rendering quality achieved by different methods, including the proposed Normal-GS method.  Metrics such as PSNR, SSIM, and LPIPS are used to evaluate the visual quality. The table highlights that Normal-GS achieves comparable or better rendering quality than the state-of-the-art (SOTA) SpecGaussian method, while also significantly outperforming SpecGaussian in normal estimation accuracy.  The results demonstrate that Normal-GS effectively balances both rendering quality and accurate normal estimation.", "section": "4 Experiments"}, {"figure_path": "kngLs5H6l1/tables/tables_17_1.jpg", "caption": "Table 1: Quantitative comparisons of the rendering quality. Our methods achieve comparable or even better results compared with the SOTA approach, SpecGaussian [5]. However, SpecGaussian performs much worse in normal estimation, while ours achieves a good balance between geometry and appearance quality. \u2020 denotes the results quoted from their paper. GShader* fails on the Deep Blending scene.", "description": "This table presents a quantitative comparison of the rendering quality achieved by the proposed Normal-GS method against several state-of-the-art 3DGS-based methods.  Metrics used for comparison include PSNR, SSIM, and LPIPS, across three datasets: Mip-NeRF360, Tanks & Temples, and Deep Blending. The table highlights that Normal-GS achieves comparable or better rendering quality compared to the best performing baseline (SpecGaussian), while significantly outperforming other baselines in terms of normal estimation accuracy.", "section": "4 Experiments"}]