[{"type": "text", "text": "realSEUDO for real-time calcium imaging analysis ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Anonymous Author(s)   \nAffiliation   \nAddress   \nemail ", "page_idx": 0}, {"type": "text", "text": "Abstract ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "1 Closed-loop neuroscience experimentation, where recorded neural activity is used   \n2 to modify the experiment on-the-fly, is critical for deducing causal connections and   \n3 optimizing experimental time. A critical step in creating a closed-loop experiment   \n4 is real-time inference of neural activity from streaming recordings. One challenging   \n5 modality for real-time processing is multi-photon calcium imaging (CI). CI enables   \n6 the recording of activity in large populations of neurons however, often requires   \n7 batch processing of the video data to extract single-neuron activity from the fluo  \n8 rescence videos. We use the recently proposed robust time-trace estimator\u2014Sparse   \n9 Emulation of Unused Dictionary Objects (SEUDO) algorithm\u2014as a basis for a   \n10 new on-line processing algorithm that simultaneously identifies neurons in the   \n11 fluorescence video and infers their time traces in a way that is robust to as-yet   \n12 unidentified neurons. To achieve real-time SEUDO (realSEUDO), we optimize the   \n13 core estimator via both algorithmic improvements and an fast C-based implementa  \n14 tion, and create a new cell finding loop to enable realSEUDO to also identify new   \n15 cells. We demonstrate comparable performance to offilne algorithms (e.g., CNMF),   \n16 and improved performance over the current on-line approach (OnACID) at speeds   \n17 of $120\\,\\mathrm{Hz}$ on average. ", "page_idx": 0}, {"type": "text", "text": "18 1 Introduction ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "19 Closed loop experiments enable neuroscientists to adapt presented stimuli or introduce perturbations   \n20 (e.g., optogenetic stimulation) in real-time based on incoming observations of the neural activity.   \n21 Such experiments are critical for both optimizing experimental time, e.g., by optimally selecting   \n22 stimuli to fit neural response models [10], or by deducing causality by perturbing possible cause  \n23 and-effect hypotheses. Despite this critical need, closed loop experiments at the level of populations   \n24 of single neurons is incredibly difficult as they require real-time processing of neural data, which   \n25 can be computationally intensive to process. In particular, population-level recordings using modern   \n26 technologies often require significant computation to extract individual neuronal activity traces,   \n27 e.g., spike sorting for high-density electrode electrophysiology or cell detection in fluorescence   \n28 microscopy [6, 9].   \n29 One particularly challenging recording technology is fluorescence microscopy, in particular multi  \n30 photon calcium imaging (CI). CI has progressed significantly since its inception with optical advances   \n31 enabling access to larger fields of view, and therefore higher data throughput. While neuroscientists   \n32 now have access to hundreds-to-thousands of neurons at a time, the neuronal time traces embedded   \n33 in the video as fluorescing objects. To extract each neuron\u2019s activity, multiple methods have been   \n34 developed, including matrix factorization approaches, deep learning approaches, and others (we refer   \n35 to a recent review for a more complete coverage of available methods and their nuances [6]).   \n36 Almost all current calcium image processing methods uses batch processing: i.e., using a full video   \n37 all at once to identify the neurons in the data and their time traces. For example, a common approach   \n38 is to identify cells in a mean image (the image containing the average fluorescence per pixel over all   \n39 time) and then to extract the time-trace from the video given the neuron\u2019s location, e.g., by averaging   \n40 pixels. Real-time processing does not afford such luxury. Instead, frames must be processed as   \n41 they are collected. Furthermore minimal data can be stored and used, as large image batches reduce   \n42 algorithmic speed. Finally, the incomplete knowledge of the full set of cells in the video can cause   \n43 unintended cross-talk. Unidentified cells may overlap with known cells, causing a well-documented   \n44 effect of false transients when the unknown cells fluoresce [12].   \n45 We thus present an algorithm capable of demixing CI data frame-by-frame in real-time. Our design   \n46 goals are to operate at $>30\\,\\mathrm{{Hz}}$ with minimal temporary data storage (e.g., no buffering or initialization   \n47 period needed) while minimizing false transient activity. Our primary contributions are: 1) An   \n48 optimized SEUDO algorithm for fast, robust time-trace computation, 2) A new feedback loop to   \n49 identify cells in real-time, and 3) patch-based parallelization that enables high-throughput calcium   \n50 trace estimation across larger fields of view. ", "page_idx": 0}, {"type": "text", "text": "", "page_idx": 0}, {"type": "text", "text": "", "page_idx": 0}, {"type": "text", "text": "", "page_idx": 1}, {"type": "text", "text": "", "page_idx": 1}, {"type": "text", "text": "51 2 Background ", "text_level": 1, "page_idx": 1}, {"type": "text", "text": "52 Traditionally, CI analysis has been performed on full imaging videos. The goal of these algorithms   \n53 is to extract from a pixel-by-time data matrix $\\pmb{Y}\\in\\mathbb{R}^{M\\times T}$ , where $M$ is the number of pixels in   \n54 each frame and $T$ is the number of frames, a set of neural profiles $\\pmb{X}\\in\\mathbb{R}^{M\\times N}$ (one for each of   \n55 $N$ neurons) and a corresponding set of time traces $\\Phi\\in\\mathbb{R}^{\\dot{N}\\times T}$ . The former of these has, as each   \n56 column of $\\mathbf{\\deltaX}$ , a single component profile depicting which pixels constitute that fluorescing object,   \n57 and how strong that pixel is fluorescing. The latter has as each row the corresponding time traces that   \n58 represent how bright that object was at each frame. These time-traces are particularly important for   \n59 relating neural activity to each other (i.e., modeling population dynamics) or to stimuli and behavior.   \n60 In typical approaches, full videos are required to either 1) identify summary images (e.g., mean   \n61 or max images [24, 11, 25, 19]) to identify cells in, 2) to create a dataset within which points are   \n62 clustered into cells [17, 31, 22, 27, 1, 28, 3, 28, 18], or 3) to perform simultaneous cell identification   \n63 and demixing [26, 23, 8, 15, 16, 20, 21, 29, 13] (e.g., via matrix factorization or dictionary learning).   \n64 For example, in the latter of these classes of algorithms, the data decomposition is solved via a   \n65 regularized optimization, e.g., ", "page_idx": 1}, {"type": "text", "text": "", "page_idx": 1}, {"type": "equation", "text": "$$\n\\widehat{X},\\widehat{\\Phi}=\\arg\\operatorname*{min}_{X,\\Phi}\\|Y-X\\Phi\\|_{F}^{2}+\\mathcal{R}_{X}(X)+\\mathcal{R}_{\\Phi}(\\Phi),\n$$", "text_format": "latex", "page_idx": 1}, {"type": "text", "text": "66 where $\\|\\cdot\\|_{F}^{2}$ is the Frobenius norm (sum of squares of all matrix elements), and ${\\mathcal{R}}_{X}(X)$ and $\\mathcal{R}_{\\Phi}(\\Phi)$   \n67 are regularization terms for the profiles and time-traces, respectively. While many regularization   \n68 combinations exist, common terms include sparsity in the neural firing, minimal overlaps, non  \n69 negativity, and spatial locality. Regardless, all methods require a large number of frames to identify   \n70 the fluorescing components, with the exception of OnACID [14] and FIOLA [7].   \n71 OnACID and FIOLA operate in an on-line manner, utilizing the buffer of last $l_{b}$ residuals $r_{t}\\,=$   \n72 $\\pmb{y}_{t}-\\pmb{X}\\pmb{c}_{t}-\\pmb{B}\\pmb{f}_{t}$ where $\\mathbf{\\deltaX}$ and $^c$ represent the spatial and temporal profiles of already recognized   \n73 cells and $_B$ and $\\pmb{f}$ represent the spatial and temporal proflies of the known background signal. Both   \n74 methods use a local Constrained Non-negative Matrix Factorization (CNMF) [26] in the spatial and   \n75 temporal vicinity of that point. CNMF is an off-line algorithm that repeatedly performs alternating   \n76 optimizations on $[X,B]$ and on $[c,f]$ using the full dataset, until it converges to a designated   \n77 precision. Both methods require initialization periods, and FIOLA further requires GPU and CPU   \n78 optimizaiton, raising the computational infrastructure costs. We seek a solution that does not need   \n79 any initialization data and can be run on simpler CPU machines for easier incorporation into user\u2019s   \n80 workflows. ", "page_idx": 1}, {"type": "text", "text": "", "page_idx": 1}, {"type": "text", "text": "81 2.1 Sparse Emulation of Unknown Dictionary Objects ", "text_level": 1, "page_idx": 1}, {"type": "text", "text": "82 One primary challenge in fully on-line settings is the incomplete knowledge of all fluorescing   \n83 components at the experiment onset. Even in off-line methods, incomplete identification of cells   \n84 can create scientifically impactful cross talk\u2014termed false transients\u2014in inferred activity [12, 16].   \n85 Another challenge is identifying new components from few frames: ideally from individual frames   \n86 to reduce memory usage. Recent work has provided an algorithm with the potential to solve both   \n87 challenges: The Sparse Emulation of Unused Dictionary Objects (SEUDO) algorithm [12].   \n88 SEUDO is a robust time-trace estimator for neuronal time traces. Given a single fluorescence   \n89 video frame $\\scriptstyle\\pmb{y}_{t}$ , and a set of known profiles $\\mathbf{\\deltaX}$ , SEUDO models contamination from unknown   \n90 profiles as $W c$ where $W$ is a basis of small Gaussian bumps that linearly construct the interfering   \n91 components, weighted by the sparse coefficients $^c$ (i.e., most $^c$ values are zero). SEUDO then solves   \n92 the optimization ", "page_idx": 1}, {"type": "image", "img_path": "Ye0O4Nyn21/tmp/694a4aac0acfedbced7bf260d251362bafd200908b7603835e9d478883919ecc.jpg", "img_caption": ["Figure 1: The realSEUDO algorithm. A: Real-time inference of cells and their activity from calcium imaging is crucial to closed-loop experiments, however, Typical CI demixing requires batch processing, e.g., via matrix factorization. B: realSEUDO builds on the robust SEUDO algorithm that prevents activity in missing or unknown cells from creating false activity in known cells by explicitly modeling contamination as a sparse sum of small Gaussian blobs (right). The sum of the estimated Guassians further provides an approximation of shape of the unknown cells, which can be used to seen new known cells. C: We propose a method based around the SEUDO estimation algorithm that can identify cells in real time by robustly removing known cells and using the residuals to identify new cells in the data. "], "img_footnote": [], "page_idx": 2}, {"type": "text", "text": "", "page_idx": 2}, {"type": "equation", "text": "$$\n\\widehat{\\phi}_{t}=\\arg\\operatorname*{min}_{\\phi,c\\geq0}\\left[\\operatorname*{min}\\left[\\|y_{t}-X\\phi_{t}\\|_{2}^{2},\\|y_{t}-X\\phi_{t}-W c\\|_{2}^{2}+\\lambda\\|c\\|_{1}+\\gamma\\right]\\right],\n$$", "text_format": "latex", "page_idx": 2}, {"type": "text", "text": "93 where $\\lambda$ and $\\gamma$ are model parameters and the internal min selects from the two internal expression   \n94 that which has the minimal value. Since SEUDO operates per-frame, $\\mathbf{\\deltay}_{t}$ , $_{P h i}$ , $^c$ are all vectors.   \n95 While SEUDO has demonstrated the ability to remove false transients [12], SEUDO\u2019s application   \n96 has been limited to off-line post-processing due to: (1) slow computational speed, and (2) the need   \n97 for pre-defined profiles $\\mathbf{\\deltaX}$ . ", "page_idx": 2}, {"type": "text", "text": "98 2.2 The FISTA Algorithm ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "99 The computational bottleneck in SEUDO is a weighted LASSO [32] optimization, which can be   \n100 implemented with the Fast Iterative Shrinkage-Thresholding Algorithm (FISTA), which implements   \n101 a momentum gradient descent [4]. FISTA optimizes ", "page_idx": 2}, {"type": "equation", "text": "$$\n\\operatorname*{min}\\left[F(x)\\equiv f(x)+g(x):x\\in\\mathbb{R}^{n}\\right],\n$$", "text_format": "latex", "page_idx": 2}, {"type": "text", "text": "102 where $f(x)$ is a smooth convex function with Lipschitz constant $L\\ >\\ 0$ , such that $\\|\\nabla f(x)-$   \n103 $\\begin{array}{r}{\\nabla f(y)\\|\\,\\leq\\,L\\|x-y\\|\\forall x,y\\,\\in\\,\\mathbb{R}^{n}}\\end{array}$ , e.g. in SEUDO $f(x)\\,=\\,\\|y_{t}-X\\phi_{t}-W c\\|_{2}^{2}$ , and $g(x)$ is a   \n104 continuous convex function that is typically non-smooth, e.g., $g(x)=\\lambda\\|x\\|_{1}$ . Each descent step of   \n105 FISTA consists of an ISTA descent step and a momentum step: ", "page_idx": 2}, {"type": "equation", "text": "$$\n\\begin{array}{r c l}{x_{k}}&{=}&{\\displaystyle\\arg\\operatorname*{min}_{x}\\left[g(x)+\\frac{L}{2}\\left\\|x-\\left(y_{k}-\\frac{1}{L}\\nabla f(y_{k})\\right)\\right\\|^{2}\\right]}\\\\ {y_{k+1}}&{=}&{x_{k}+\\eta_{k}(x_{k}-x_{k-1}),}\\end{array}\n$$", "text_format": "latex", "page_idx": 2}, {"type": "text", "text": "106 where the parameter $\\eta_{k}$ gradually reduces with $\\begin{array}{r}{\\eta_{k}=\\frac{t_{k}-1}{t_{k+1}}}\\end{array}$ ttk\u22121 , tk+1 = $\\begin{array}{r}{t_{k+1}=\\frac{1+\\sqrt{1+4t_{k}^{2}}}{2}}\\end{array}$ 1+ 1+4t2k, t1 = 1. ", "page_idx": 2}, {"type": "text", "text": "107 3 Real-time SEUDO ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "108 Here we develop Real-time SEUDO (realSEUDO) that resolves the primary limitations of SEUDO   \n109 and extends the algorithm significantly from a time-trace estimator to a real-time cell identification   \n110 method. Specifically we improve the computationally intensive momentum descent algorithm used to   \n111 solve Equation (2) by reducing the number of steps of momentum descent, implementing parallelism,   \n112 optimizing internal computations (e.g., of smoothness parameters), and reducing the complexity of   \n113 the original ftiting problem without a substantial loss of quality by manipulating its inputs. Moreover   \n114 we add a new algorithm that automatically recognizes the neurons that have not previously been seen   \n115 and adds them to the dictionary of known components. Finally, we implement our framework with a   \n116 patch-based parallelism that avoids the computational scaling of LASSO in higher dimensions.   \n117 At a high level, the realSEUDO algorithm (Alg. 1, Fig. 1) operates as follows: realSEUDO is   \n118 initialized with zero known components (an empty set). When fluorescence activity in a frame   \n119 reaches threshold, an event is triggered that saves the activity profile of that event as a temporary   \n120 candidate profile. Profiles are moved from the temporary profiles to the static set of profiles if they   \n121 remain active for a sufficient number of frames . The static profile set is then used to identify the   \n122 activity of those components in future frames, with unexplained components becoming candidate   \n123 profiles and cycling back into the temporary profiles, followed by an update of the static profile set. ", "page_idx": 2}, {"type": "text", "text": "", "page_idx": 3}, {"type": "text", "text": "", "page_idx": 3}, {"type": "text", "text": "124 3.1 SEUDO optimization ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "125 The first requirement of realSEUDO is a fast implementation of SEUDO that can operate at $>30$ fps.   \n126 We achieved this requirement through a combination of efficient implementations, algorithmic   \n127 optimization, and updates to the base SEUDO model.   \n128 $\\mathbf{C}++$ implementation: The original SEUDO implementation used the TFOCS MATLAB library [5].   \n129 We thus first improved SEUDO\u2019s run-time by switching from MATLAB\u2019s interpreted programming   \n130 language running TFOCS to a fast implementation of LASSO [32] via FISTA [4] in the $C++$ compiled   \n131 language. To further improve performance, we optimized the $C++$ code with the use of templates   \n132 to eliminate the function call overhead in tight loops, and also employ parallelism, based on the   \n133 POSIX threads with TPOPP library wrapper [2]. To prevent a bottleneck from the passing of data   \n134 through Matlab\u2019s OOP API at the MATLAB $/C++$ interface, we switched to the non-OOP version of   \n135 the MATLAB-to-C API.   \n136 While beneficial, the $C++$ SEUDO implementation did not alone achieve the desired processing rate.   \n137 We further improved runtimes by optimizing the cost function and derivative computations. The   \n138 partial LASSO component of SEUDO that performs optimization at each frame $y$ using FISTA can   \n139 be written as arg min $f(\\psi)+\\lambda g(\\psi)$ , where $f=\\lVert\\pmb{y}-\\dot{\\pmb{\\chi}}\\pmb{\\psi}\\rVert_{2}^{2}$ is the least-squares term and $g=\\|\\psi\\|_{1}$   \n140 is the $\\ell_{1}$ penalty. In FISTA, the proflie time traces and Gaussian kernels are unified in one vector, i.e.,   \n141 $\\psi$ is a concatenation of $\\Phi$ and $^c$ , and $\\boldsymbol{\\chi}=[X,W]$ . With $M$ as the number of pixels per frame, $N$ as   \n142 the number of neurons, and $K$ as the number of Gaussian kernels, the set of problem dimensions are   \n143 $\\pmb{y}\\in\\mathbb{R}^{M}$ , $\\boldsymbol{\\chi}\\in\\mathbb{R}^{M\\times(N+K)}$ , $\\psi\\in\\mathbb{R}^{N+K}$ , $\\pmb{\\lambda}\\in\\mathbb{R}^{N+K}$ , with the first $N$ elements of $\\lambda$ corresponding   \n144 to $\\Phi$ being equal to 0.   \n145 In FISTA, a number of internal computations become bottlenecks; in particular computing the   \n146 gradients $\\nabla_{\\psi}f$ and $\\nabla_{\\psi}(f+g)$ , the Lipshitz smoothness estimation, and the momentum/stopping   \n147 criteria.   \n148 Gradient computation: We reduce the burden of the gradient computations by both reducing the   \n149 number of times the gradient must be used, and by improving the internal gradient computation. For   \n150 the former, we note that naive implementations compute both a step in the direction of $\\nabla_{\\psi}f$ and   \n151 then in the direction of $\\nabla_{\\psi}(f+\\bar{\\lambda}g)$ . Moreover, we note that these two steps in slightly different   \n152 directions cause the gradient to dither around the optimum. We thus instead only take a step in the   \n153 direction of $\\nabla_{\\psi}(f+\\lambda g)$ (similar to [4]). For the latter, computing $\\nabla_{\\psi}(f+\\lambda g)$ requires matrix   \n154 vector multiplications with $x$ and its transpose. Since $x$ is sparse, we save memory and computation,   \n155 by generating $x$ on-the-fly via convolutions instead of storing it in memory. Specifically, the gradient   \n156 $\\nabla_{\\psi}f$ requires computing $x^{T}x\\psi$ , which we reorganize to compute in two passes: ", "page_idx": 3}, {"type": "text", "text": "", "page_idx": 3}, {"type": "text", "text": "", "page_idx": 3}, {"type": "text", "text": "", "page_idx": 3}, {"type": "text", "text": "", "page_idx": 3}, {"type": "equation", "text": "$$\nv_{j}=\\sum_{1\\leq i\\leq N+K}y_{j}-\\chi_{j i}\\psi_{i},\\qquad\\frac{\\mathrm{d}f}{\\mathrm{d}\\psi_{m}}=2\\sum_{1\\leq j\\leq M}\\chi_{j m}v_{j}.\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "157 The first pass (Eqn. 6, left) computes a set of intermediary variables, and the second pass (Eqn. 6,   \n158 right) uses these values to compute the gradient dimensions. The two pass approach factors out   \n159 repeated computations, reducing the complexity from $O(n^{3})$ to $O(n^{2})$ . Moreover, the computation   \n160 of each pass is highly parallelizable by partitioning of the first pass by $j$ , the second by $m$ , and   \n161 efficiently skipping the iterations over the zero elements in the sparse matrix $x$ .   \n162 Lipshitz constant: To improve the efficiency of estimating the Lipschitz constant $L$ , note that   \n163 $L=\\mathrm{max}(\\|\\nabla f(\\pmb{x}_{1})-\\nabla f(\\pmb{x}_{2})\\|/\\|\\pmb{x}_{1}-\\pmb{x}_{2}\\|)$ . For our cost function, we can approximate $L$ with   \n164 independent computations in each dimension. This estimation reduced the number of steps by as   \n165 much as $30\\%$ over typical computations of $L$ before each step based on the local gradient.   \n166 Momentum: The momentum descent central to solving the partial LASSO tends to spend many   \n167 steps on stopping the momentum, especially with the large values of the Lipshitz constant $L$ (i.e. the   \n168 non-momentum steps are small). One such case is \u201ccircling the drain\u201d around the minimum, with the   \n169 momentum causing the overshoot in one dimension while another dimension is stopping. Another   \n170 case is when a dimension is moved past the boundary (e.g., $\\pmb{x}\\ge0$ for SEUDO), where the solution   \n171 pushes past the boundary into negative values. This produces suboptimal solutions and increasing the   \n172 number of steps necessary. FISTA includes a parameter $\\eta$ that progressively limits the top speed of   \n173 descent to reduce such problems. We improved these cases by resetting the momentum to zero on a   \n174 dimension when it either attempts to cross into the negative values or when its gradient changes sign.   \n175 The dimensional momentum stopping stops abruptly at the right time, obviating the need for slowing   \n176 and thus we can simplify FISTA by fixing $\\eta=1$ .   \n177 Our momentum stopping can further extend to broader optimization problems. We demonstrated this   \n178 ability on momentum optimization in neural network training (see Supplement), where it provided a   \n179 substantial improvement. Our modified FISTA produced the same error rate and squared mean error   \n180 as gradient descent in about 10 times fewer training passes, or about 10 times lower error rate and 1.5   \n181 times lower mean square error in the same number of passes. The full modified FISTA algorithm is   \n182 presented in Algorithm 2 (see Supplement).   \n183 SEUDO model adjustments: As a third step, we modified the SEUDO optimization program to   \n184 achieve the final speedups. The original SEUDO spaced the Gaussian components in $W$ by one   \n185 pixel, which we found to be highly redundant. The kernels with radius $r$ cover $\\left(\\pi*r^{2}\\right)$ pixels, and   \n186 thus each pixel is covered by $\\scriptstyle({\\bar{\\pi}}*{\\bar{r}}^{2})$ kernels. This redundancy results in FISTA continuing to adjust   \n187 the kernel coefficients $^c$ after the neural activations $\\textbf{\\em x}$ converge. Reducing the number of kernels thus   \n188 reduces both the number of gradient descent steps and the per-step cost, accelerating the computation   \n189 more than quadratically. For a kernel with diameter of 30 pixels this improves the performance by a   \n190 factor of over 100 without substantial degradation of false transients removal or the recognition of the   \n191 interfering components\u2019 shape $W c$ .   \n192 We benchmarked our speedups against the original SEUDO on 45000 frames across 50 cells from [12].   \n193 SEUDO ran at $5.8{-}6.9\\;\\mathrm{s/cell}$ on a Macintosh M1. The optimized $C++$ implementation without the   \n194 MATLAB $C++$ API reduced the runtime to 0.9-1.1 s/cell (a $6-7\\mathbf{X}$ improvement). Sparse SEUDO   \n195 provided further acceleration to a run time of $0.2\\;\\mathrm{s}$ , with 0.1 s for the computation and 0.1 s for the   \n196 overhead of converting data between Matlab and native code; a total of a $29.34.5\\mathrm{x}$ speed-up, allowing   \n197 SEUDO to run in real time. ", "page_idx": 3}, {"type": "text", "text": "", "page_idx": 4}, {"type": "text", "text": "", "page_idx": 4}, {"type": "text", "text": "", "page_idx": 4}, {"type": "text", "text": "", "page_idx": 4}, {"type": "text", "text": "", "page_idx": 4}, {"type": "text", "text": "", "page_idx": 4}, {"type": "text", "text": "198 3.2 Automatic cell recognition ", "text_level": 1, "page_idx": 4}, {"type": "text", "text": "199 We next developed the cell recognition feedback loop that completes the realSEUDO algorithm. To   \n200 minimize data storage and compute, we designed realSEUDO to run on a frame-by-frame basis. At   \n201 a high level, our automatic cell recognition first runs SEUDO on the current incoming (denoised)   \n202 frame given the currently identified profiles $X_{s t a b}$ . The loop then identifies contiguous bright areas   \n203 in the residual frames, i.e., the SEUDO cells $W c$ , and places them in a \u2018temporary profile\u2019 array   \n204 $X_{t e m p}$ . The temporary profiles are then updated (via merging with new potential profiles) given   \n205 new, incoming, frames until they are stable and moved to the stable, known proflie list $X_{s t a b}$ that is   \n206 updated less frequently by addition, merging and splitting of temporary profiles.   \n207 Procedurally, we first preprocess each incoming frame to reduce noise and improve proflie recognition.   \nCalcium imaging analysis often uses running averages in space and time for noise reduction. We thus   \n209 implement both a spatial Gaussian fliter, as well as a running average of several sequential frames. We   \n210 keep the window length as a tunable parameter that can be set to one for frame-by-frame processing   \n211 with minimize temporal blurring.   \n212 We estimate the activation level in the denoised frame for each of the stable proflies $X_{s t a b}$ using the   \n213 our fast SEUDO implementation. SEUDO returns the activation level $\\phi_{k t}$ for the $k^{t h}$ proflie at time   \n214 $t$ along with a robust residual that contains the structured fluorescence not captured by $X_{s t a b}$ . We   \n215 then run the residual through SEUDO a second time using the temporary profiles $X_{t e m p}$ to test if   \n216 any temporary proflie matches the frame\u2019s fluorescence and should be moved from $X_{t e m p}$ to $X_{s t a b}$ .   \n217 The residual after the second SEUDO application represents completely unknown profiles and are   \n218 analyzed separately to determine if a new member of $X_{t e m p}$ should be created.   \n219 The detection of new temporary profiles is based on finding the areas of the image above the noise   \n220 level. The noise level is evaluated by noting that most of each video frame has no activity, indicating   \n221 that the median pixel value will be very close to the median value of the pixels in an all-dark frame   \n222 containing the same noise. The half-amplitude of the noise $\\sigma_{1/2}$ can be estimated as: ", "page_idx": 4}, {"type": "text", "text": "", "page_idx": 4}, {"type": "text", "text": "", "page_idx": 5}, {"type": "text", "text": "", "page_idx": 5}, {"type": "equation", "text": "$$\n\\sigma_{1/2}=\\mathrm{median}(y_{t})-\\mathrm{min}(y_{t}).\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "223 In some cases different areas of the image may contain a different amount of background lighting   \n224 (e.g., changes in neuropil), which can skew the noise estimate. To overcome this challenge, we   \n225 split the larger image into sections, with each section computing a local median which is smoothly   \n226 interpolated between section of the image. This can be thought as either a krigging procedure or a   \n227 cheap approximation to a local median evaluated independently for each pixel in the image.   \n228 To merge new profiles into the exiting profiles when adding new profiles to $X_{t e m p}$ , we compute an   \n229 overlap score. The scores aims to capture the following logic: If two temporal profiles are a close   \n230 match in cross-section, they likely represent the same cell and should be merged. If they overlap only   \n231 partially, they likely represent separate cells. If one cross-section is inside the other, look at relative   \n232 brightness: if the smaller cross-section is also weaker, it\u2019s likely a weaker partial activation of the   \n233 same cell and should be merged, if the smaller cross-section has a close or higher brightness, the   \n234 larger cross-section likely represents an intertwining of two cells that has to be split.   \n235 The overlap computation thus is not a plain spatial overlap but includes a heuristics that identifies   \n236 when one proflie is mostly contained in another. The condition for merging two proflies in $X_{t e m p}$ is   \n237 based on the comparison of numbers of common and unique pixels between profiles, where $P_{1}$ and   \n238 $P_{2}$ are numbers of pixels in each of two proflies, $U_{1}$ and $U_{2}$ are the numbers of unique pixels in each   \n239 proflie, $C$ is the number of common pixels, $B_{1}$ and $B_{2}$ are the perimeters of bounding boxes for each   \n240 profile, and $k_{t e m p}$ is a constant with an empirically chosen value of 0.75: ", "page_idx": 5}, {"type": "text", "text": "", "page_idx": 5}, {"type": "text", "text": "", "page_idx": 5}, {"type": "equation", "text": "$$\nU_{1}\\leq B_{1}*0.5\\quad\\mathrm{or}\\quad U_{2}\\leq B_{2}*0.5\\quad\\mathrm{or}\\quad C\\geq k_{t e m p}*\\operatorname*{min}(P_{1},P_{2})\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "241 After a profile is moved from $X_{t e m p}$ to $X_{s t a b}$ , a different score is computed pair-wise between the   \n242 new profile and each existing profile, to decide whether they should be left separate, or merged, or   \n243 one of profiles split. If a merge or split is performed, the original profiles are removed from $X_{s t a b}$   \n244 and the results entered recursively into $X_{s t a b}$ as new proflies. The score for two proflies $A$ and $B$ in   \n245 $X_{s t a b}$ is computed based on the brightness and measures of least-squares fit of the cells into each   \n246 other 1) as whole cells (i.e., $\\alpha_{A B}={\\bar{\\langle}A,B\\rangle}/{\\langle A,A\\rangle})$ and 2) using only the overlapping region (i.e.,   \n247 $\\beta_{A B}=\\langle A_{o l},B\\rangle/\\langle A_{o l},A_{o l}\\rangle$ where $A_{o l}$ is the profile $A$ restricted to the region overlapping with $B$ ).   \n248 $\\beta_{A B}$ is used as a measure of difference in brightness, against which the fti of the whole cells $\\alpha_{A B}$ is   \n249 compared as a measure of proximity in shape. Specifically we compute two ratios $\\rho_{A B}$ and $\\rho_{B A}$ are   \n250 computed as ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\rho_{A B}={\\frac{\\alpha_{A B}}{\\beta_{A B}}},\\qquad\\qquad\\rho_{B A}={\\frac{\\alpha_{B A}}{\\beta_{B A}}}.\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "251 A higher value of $\\rho_{A B}$ (which is always $\\leq1$ ) means that cell A ftis better inside cell B. The value of   \n252 1 means that it fits entirely inside cell B. The same principle applies symmetrically to $\\rho_{B A}$ . ", "page_idx": 5}, {"type": "text", "text": "253 3.3 Patching and profile matching ", "text_level": 1, "page_idx": 5}, {"type": "text", "text": "254 realSEUDO, although highly efficient for smaller patches, is still based on the LASSO algorithm that   \n255 reduces in efficiency with much larger frames. Thus we adopt a patching scheme that breaks each   \n256 frame into small patches that can be parallelized to maintain the high framerate by utilizing the multi  \n257 threading in many modern processors. Patching, however, requires matching proflies across patches.   \n258 Traditionally profiles discovered in data split into patches is to add overlap margins to the patches   \n259 and to use proflies overlap in this region to determine matchings in neighboring patches. Additional   \n260 margins, however, introduces redundant computation and decreases computational efficiency.   \n261 In realSEUDO we note that the logic behind the scoring we use to merge profiles in $X_{s t a b}$ and   \n262 $X_{t e m p}$ within each patch can also be used to score the match of proflies across patches. Specifically,   \n263 we extend the matching to include the profile temporal activity as an additional dimension to find   \n264 matching cells in neighboring patches via consecutive gluing of the profiles. The highest score   \n265 is assigned to the bidirectional match of both spatial and temporal dimensions, a lower score to   \n266 symmetrical match of spatial dimensions and asymmetrical match of temporal dimension, a yet lower   \n267 score to an asymmetrical match of both kinds of dimensions. We have observed successful matches   \n268 even with zero margin, using the neighboring strips of pixels around the perimeters of the patches as   \n269 the spatial dimension for matching. ", "page_idx": 5}, {"type": "text", "text": "", "page_idx": 6}, {"type": "text", "text": "270 4 Results ", "text_level": 1, "page_idx": 6}, {"type": "text", "text": "271 Validation metrics: To validate our approach we note that the main goal of realSEUDO, as with   \n272 most functional imaging analyses, primarily aims to recover the time-traces of neural activity as   \n273 accurately as possible [6, 12]. This means while the general location of neurons is important, metrics   \n274 such as the the Intersection over Union (IoU) are too strong; i.e., the full set of pixels identified is not   \n275 necessarily the important quantity. We instead compute the \u201cunique neurons found\u201d. This metric   \n276 aims to capture the need to know that the time-traces 1) correspond to real neurons in the data and   \n277 2) accurately reflect the temporal activity that will be used to study neural activity with respect to   \n278 stimuli and behavior. The Unique Neurons Found (as defined in [30]) requires both that ROIs well   \n279 align with known ROIs spatially (overlap of at least $50\\%$ of pixels) and that the time-trace correlation   \n280 exceeds 0.5.   \n281 Simulated data experiments: We first applied all three algorithms to a simulated video created with   \n282 Neural Anatomy and Optical Microscopy simulation (NAOMi) [30]. Specifically we simulated the   \n283 neural activity over 20000 frames at $30\\mathrm{Hz}$ with fame size of $500\\mathrm{x}500$ pixels. There are approximately   \n284 450 cells visible in this dataset (i.e. fluorescing cells intersecting the plane of imaging). We   \n285 benchmarked the patch-based parallel processing of realSEUDO $80\\mathrm{x}80$ pixel patches. For comparison   \n286 we ran the off-line CNMF (a staple batch-based calcium imaging demixing algorithm) and OnACID,   \n287 the computationally similar on-line method. realSEUDO found 201 true cells, identified as strongly   \n288 correlated with ground-truth cells, while OnACID found 152 and CNMF (the offilne method) found   \n289 308 (Fig. 2A-B). Furthermore, both realSEUDO and OnACID found many fewer false positives   \n290 than CNMF, presumably because they cannot be fooled by small fluctuations integrated over the   \n291 full recording (Fig. 2C-D). Note that to remove the confound of post-processing we followed prior   \n292 work [30] in using the CNMF raw fluorescence traces instead of the model-based denoised traces.   \n293 On average, realSEUDO processed 67.8 frames per second end-to-end, while OnACID ran at 9.2 fps.   \n294 Applications to in-vivo mouse CA1 recordings We applied realSEUDO to an in vivo calcium   \n295 imaging recordings from mouse hippocampal area CA1 previously described in Gauthier et al.   \n296 2022 [12]. They consisted of 36 videos, each sized $90\\mathrm{x}90$ pixels with 41750 frames sampled at $30\\,\\mathrm{Hz}$ .   \n297 The outputs had previously been verified manually by Gauthier et al. 2022 [12] with human labeling   \n298 of CNMF outputs. We applied realSEUDO to all videos and compared the outputs with the current   \n299 online cell demixing algorithm OnACID [14], as well as a popular offilne algorithm, CNMF [13], as   \n300 an additional baseline.   \n301 We benchmarked realSEUDO against OnACID (an online analysis tool) and CNMF (an offline   \n302 analysis tool) on real in-vivo calcium imaging movies (Fig. 3). Algorithmic performance was   \n303 measured on an $\\mathrm{x}86{-}64$ computer with 48 CPU cores (Intel Xeon 6248R), 2 hyperthreads per core,   \n304 $78\\ \\mathrm{GB}$ of memory, and without the use of a GPU. The initialization times were not included. On   \n305 average, realSEUDO processed 162 frames per second compared to 26 processed by OnACID and 13   \n306 by CNMF: an improvement of $6.5\\mathrm{x}$ and $12.5\\mathbf{x}$ respectively (Fig. 3C). Quality-wise, we found that   \n307 OnACID exhibited difficulties with adapting to larger ranges of pixel brightness, sometimes missing   \n308 bright cells. Scaling pixel values improved OnACID results, but only mildly (one additional cell).   \n309 Numerically OnACID and CNMF appear similar but they identified different components. SEUDO   \n310 results were most similar to CNMF, and with additional cells identified, and less false positives   \n311 (Fig. 3B). Finally, the per-transient manual classification provided by [12] enabled us to assess if   \n312 realSEUDO inherited the false transient removal properties of SEUDO. For a reasonable value of   \n313 $\\lambda=0.15$ , realSEUDO had a true positive rate of $75\\%$ and a false positive rate of $24\\%$ . While these   \n314 numbers are a bit lower than the numbers reported in [12], in that study the authors average $_{\\mathrm{N}=3}$   \n315 frames to reduce noise, while maintained single-frame analysis. This can be evident by the fact that   \n316 missed transients were very small: realSEUDO kept $98\\%$ of real fluorescence and only $15\\%$ of false   \n317 fluorescence.   \n318 Additional in-vivo tests: As final test we applied all three algorithms (realSEUDO, OnACID, CNMF)   \n319 to a 2000-frame mesoscope video example collected by the Yuste lab at Columbia University and   \n320 provided with the OnACID github package as a demo. For this example we similarly saw improved   \n321 cell detection and runtime improvement in terms of fps (Fig. 3B). ", "page_idx": 6}, {"type": "text", "text": "", "page_idx": 6}, {"type": "text", "text": "", "page_idx": 6}, {"type": "text", "text": "", "page_idx": 6}, {"type": "image", "img_path": "Ye0O4Nyn21/tmp/8a38c3a9b10012015cc2438f80a1b2ee4903cd5a660133806c8d4d6b6e0af1a8.jpg", "img_caption": ["Figure 2: NAOMi results: A) Found cells in NAOMi for CNMF, OnACID and realSEUDO separated into Hits (strong or weakly correlated) and false alarms (uncorrelated). B) realSEUDO finds more cells than OnACID with minimal false positives. C) Temporal correlations for found \u201chits\u201d. D) Examples time-traces show correlation to ground truth. "], "img_footnote": [], "page_idx": 7}, {"type": "text", "text": "", "page_idx": 7}, {"type": "text", "text": "", "page_idx": 7}, {"type": "text", "text": "322 5 Discussion ", "text_level": 1, "page_idx": 7}, {"type": "text", "text": "323 We present here an online method for cell detection and fluorescence time-trace estimation from   \n324 streaming CI data: realSEUDO. realSEUDO is based on the SEUDO robust time-trace estimator that   \n325 reduces bias due to unknown cells while also providing approximate shapes of the unknown fluoresc  \n326 ing objects. To build realSEUDO we 1) improved SEUDO\u2019s runtime via significant modifications at   \n327 the code, algorithmic, and model levels 2) built a new feedback loop that allowed SEUDO (that has   \n328 no cell finding component currently) to identify cells in real-time. Overall, realSEUDO can achieve   \n329 frame processing rates of 80-200 fps, depending on cell density. While our goal was to exceed the   \n330 typical $30\\,\\mathrm{Hz}$ data collection rate common to many experiments, the high processing efficiency leaves   \n331 additional time to compute feedback in future closed loop systems. Moreover, realSEUDO can scale   \n332 with faster recording rates as calcium indicators become faster, e.g., GCaMP8 [33].   \n333 realSEUDO\u2019s implementation exhibits a higher degree of parallelism than OnACID, however both   \n334 are likely constrained by the employed tools. Specifically, the measurements in Fig. 3C show very   \n335 little fps fluctuation with respect to cell count for OnACID, which can be due to a bottleneck in a   \n336 single thread. realSEUDO has a lower latency to the first events for a new cell, OnACID requires a   \n337 history of 100 frames to recognize a cell, while realSEUDO would produce the first events starting   \n338 with the first frame that passes the low brightness threshold. Alternatively, OnACID has a higher   \n339 native scalability with respect to the frame area, conditioned on similar cell counts. This likely result   \n340 from OnACID\u2019s algorithm restriction of processing to areas in the immediate vicinity of known   \n341 cells. realSEUDO can still achieve a high processing efficiency with reasonable hardware with our   \n342 parallelization. Future work may further improve realSEUDO runtime by blanking out entire patches   \n343 until activity is detected via simpler detectors.   \n344 One strength of realSEUDO is that it can be initialized with either an empty profile set. This ability   \n345 to start from nothing will be useful in mesoscope settings when the field-of-view can be changed   \n346 on-the-fly. Not requiring an initialization step will reduce start-up overhead at new fields of view.   \n347 Furthermore, many of our speed adaptions deviate from the traditional gradient descent approach.   \n348 In particular the Lipshitz constant approximation and the changes in the momentum and stopping   \n349 criteria. In other domains, in particular for training deep neural networks, these deviations may also   \n350 provide significant speedups, the extent of which should be quantified across broader applications in   \n351 future work.   \n352 Limitations: While our results achieve the design criteria we initially set out, there are some potential   \n353 barriers. For one, as with many real-time systems, the compute environment is very important to   \n354 configure correctly. We have found the importance of explicitly setting the Linux CPU manager to   \n355 enable the performance mode. The default automatic adaptable mode does not react properly to CPU   \n356 loads of less than $100\\%$ of the whole capacity, and significantly skews the benchmarking by running   \n357 the CPUs at low frequency. These challenges are unfortunately necessary to achieve high levels of   \n358 throughput without specialized hardware. Future work should develop walkthroughs and automated   \n359 tools to guide the installation of the tools.   \n360 While our core algorithm is written completely in $C++$ , and thus open source, we have found   \n361 MATLAB convenient and efficient as a wrapper for prototyping wrappers for our core functions.   \n362 Further work will add Python wrappers to allow for seamless integration into both MATLAB and   \n363 Python pipelines, enabling realSEUDO to be more widely used.   \n364 Finally, we focused here only on cell detection, assuming access to the on-line motion correction   \n365 algorithm from OnAcid. This focus may require additional packages to be handled by users for   \n366 motion correction. We will further aim in future iterations to extend the core package to include   \n367 motion correction and delta-F over F computations in order to reduce communication overhead and   \n368 ease adoption by users. Moreover, to fully optimize the package for speed, these steps should be   \n369 more holistically incorporated in $C++$ as well. ", "page_idx": 7}, {"type": "image", "img_path": "Ye0O4Nyn21/tmp/73a7c7c3bbda63e68d6c9947d9577c2fbaaf8d3ad77642f7dc13123cc6dc1d1c.jpg", "img_caption": ["Figure 3: (A) Selected cell proflies and time-traces generated by realSEUDO, OnACID, and CNMF respectively on a subset of 2000 frames from a single image patch. (B) Counts of true positive, false positive and false negative cells found by each algorithm for two different recordings: all 41,750 frames data from one video from Gauthier et al. [12] (right) and from the OnACID demo (left). (C) Top: Total computational performance as a function of the number of detected cells for realSEUDO and OnACID, evaluated on the full set of 36 movies from Mouse CA1. Bottom: CPU use in CPU seconds per frame as a function of the number of detected cells for realSEUDO and OnACID, evaluated on the same 36 recordings. "], "img_footnote": [], "page_idx": 8}, {"type": "text", "text": "", "page_idx": 8}, {"type": "text", "text": "", "page_idx": 8}, {"type": "text", "text": "", "page_idx": 8}, {"type": "text", "text": "", "page_idx": 8}, {"type": "text", "text": "", "page_idx": 9}, {"type": "text", "text": "370 References ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "371 [1] Noah Apthorpe, Alexander Riordan, Robert Aguilar, Jan Homann, Yi Gu, David Tank, and   \n372 H Sebastian Seung. Automatic neuron detection in calcium imaging data using convolutional   \n373 networks. Advances in neural information processing systems, 29:3270\u20133278, 2016.   \n374 [2] Sergey A Babkin. The practice of parallel programming. Createspace, 2010.   \n375 [3] Yijun Bao, Somayyeh Soltanian-Zadeh, Sina Farsiu, and Yiyang Gong. Segmentation of neurons   \n376 from fluorescence calcium recordings beyond real time. Nature Machine Intelligence, pages   \n377 1\u201311, 2021.   \n378 [4] Amir Beck and Marc Teboulle. A fast iterative shrinkage-thresholding algorithm for linear   \n379 inverse problems. SIAM journal on imaging sciences, 2(1):183\u2013202, 2009.   \n380 [5] Stephen R Becker, Emmanuel J Cand\u00e8s, and Michael C Grant. Templates for convex cone   \n381 problems with applications to sparse signal recovery. Mathematical programming computation,   \n382 3:165\u2013218, 2011.   \n383 [6] Hadas Benisty, Alexander Song, Gal Mishne, and Adam S Charles. Review of data processing   \n384 of functional optical microscopy for neuroscience. Neurophotonics, 9(4):041402, 2022.   \n385 [7] Changjia Cai, Cynthia Dong, Johannes Friedrich, Marton Rozsa, Eftychios A Pnevmatikakis,   \n386 and Andrea Giovannucci. Fiola: an accelerated pipeline for fluorescence imaging online analysis.   \n387 Nature Methods, 20(9):1417\u20131425, 2023.   \n388 [8] Adam S. Charles, Nathan Cermak, Rifqi O. Affan, Benjamin B. Scott, Jackie Schiller, and Gal   \n389 Mishne. Graft: Graph flitered temporal dictionary learning for functional neural imaging. IEEE   \n390 Transactions on Image Processing, 31:3509\u20133524, 2022.   \n391 [9] Adam S Charles, Benjamin Falk, Nicholas Turner, Talmo D Pereira, Daniel Tward, Benjamin D   \n392 Pedigo, Jaewon Chung, Randal Burns, Satrajit S Ghosh, Justus M Kebschull, et al. Toward   \n393 community-driven big open brain science: open big data and tools for structure, function, and   \n394 genetics. Annual review of neuroscience, 43(1):441\u2013464, 2020.   \n395 [10] Adam S Charles, Mijung Park, J Patrick Weller, Gregory D Horwitz, and Jonathan W Pillow.   \n396 Dethroning the fano factor: a flexible, model-based approach to partitioning neural variability.   \n397 Neural computation, 30(4):1012\u20131045, 2018.   \n398 [11] F. Diego and F. A. Hamprecht. Sparse space-time deconvolution for calcium image analysis. In   \n399 NIPS, pages 64\u201372, 2014.   \n400 [12] Jeffrey L Gauthier, Sue Ann Koay, Edward H Nieh, David W Tank, Jonathan W Pillow, and   \n401 Adam S Charles. Detecting and correcting false transients in calcium imaging. Nature Methods,   \n402 19(4):470\u2013478, 2022.   \n403 [13] Andrea Giovannucci, Johannes Friedrich, Pat Gunn, J\u00e9r\u00e9mie Kalfon, Brandon L Brown, Sue Ann   \n404 Koay, Jiannis Taxidis, Farzaneh Najaf,i Jeffrey L Gauthier, Pengcheng Zhou, Baljit S Khakh,   \n405 David W Tank, Dmitri B Chklovskii1, and Eftychios A Pnevmatikakis. CaImAn an open source   \n406 tool for scalable calcium imaging data analysis. Elife, 8:e38173, 2019.   \n407 [14] Andrea Giovannucci, Johannes Friedrich, Matthew Kaufman, Anne K Churchland, Dmitri   \n408 Chklovskii, Liam Paninski, and Eftychios A Pnevmatikakis. Onacid: online analysis of calcium   \n409 imaging data in real time. In Proceedings of the 31st International Conference on Neural   \n410 Information Processing Systems, pages 2378\u20132388, 2017.   \n411 [15] Benjamin D Haeffele and Ren\u00e9 Vidal. Structured low-rank matrix factorization: Global   \n412 optimality, algorithms, and applications. IEEE transactions on pattern analysis and machine   \n413 intelligence, 42(6):1468\u20131482, 2019.   \n414 [16] Hakan Inan, Murat A Erdogdu, and Mark Schnitzer. Robust estimation of neural signals in   \n415 calcium imaging. In NIPS, pages 2905\u20132914, 2017.   \n416 [17] Patrick Kaifosh, Jeffrey D. Zaremba, Nathan B. Danielson, and Attila Losonczy. Sima: Python   \n417 software for analysis of dynamic fluorescence imaging data. Frontiers in Neuroinformatics, 8,   \n418 2014.   \n419 [18] Elke Kirschbaum, Alberto Bailoni, and Fred A Hamprecht. Disco: Deep learning, instance   \n420 segmentation, and correlations for cell segmentation in calcium imaging. In International   \n421 Conference on Medical Image Computing and Computer-Assisted Intervention, pages 151\u2013162.   \n422 Springer, 2020.   \n423 [19] Aleksander Klibisz, Derek Rose, Matthew Eicholtz, Jay Blundon, and Stanislav Zakharenko.   \n424 Fast, simple calcium imaging segmentation with fully convolutional networks. In Deep Learning   \n425 in Medical Image Analysis and Multimodal Learning for Clinical Decision Support, pages   \n426 285\u2013293. Springer, 2017.   \n427 [20] Ryuichi Maruyama, Kazuma Maeda, Hajime Moroda, Ichiro Kato, Masashi Inoue, Hiroyoshi   \n428 Miyakawa, and Toru Aonishi. Detecting cells using non-negative matrix factorization on   \n429 calcium imaging data. Neural Networks, 55:11\u201319, 2014.   \n430 [21] Gal Mishne and Adam S Charles. Learning spatially-correlated temporal dictionaries for   \n431 calcium imaging. In IEEE International Conference on Acoustics, Speech and Signal Processing   \n432 (ICASSP-2019), pages 1065\u20131069. IEEE, 2019.   \n433 [22] Gal Mishne, Ronald R Coifman, Maria Lavzin, and Jackie Schiller. Automated cellular structure   \n434 extraction in biological images with applications to calcium imaging data. bioRxiv, page 313981,   \n435 2018.   \n436 [23] M. Pachitariu, A. M. Packer, N. Pettit, H. Dalgleish, M. Hausser, and M. Sahani. Suite2p:   \n437 beyond 10,000 neurons with standard two-photon microscopy. bioRxiv, 2016.   \n438 [24] Marius Pachitariu, Adam M Packer, Noah Pettit, Henry Dalgleish, Michael Hausser, and   \n439 Maneesh Sahani. Extracting regions of interest from biological images with convolutional   \n440 sparse block coding. Advances in Neural Information Processing Systems, pages 1745\u20131753,   \n441 2013.   \n442 [25] Ashley Petersen, Noah Simon, and Daniela Witten. Scalpel: Extracting neurons from calcium   \n443 imaging data. The annals of applied statistics, 12(4):2430, 2018.   \n444 [26] E. A Pnevmatikakis, D. Soudry, Y. Gao, T. A. Machado, J. Merel, D. Pfau, T. Reardon, Y. Mu,   \n445 C. Lacefield, W. Yang, Misha Ahrens, Randy Bruno, Thomas M. Jessell, Darcy\u00c2 S. Peterka,   \n446 Rafael Yuste, and Liam Paninski. Simultaneous denoising, deconvolution, and demixing of   \n447 calcium imaging data. Neuron, 89(2):285\u2013299, 2016.   \n448 [27] S. Reynolds, T. Abrahamsson, R. Schuck, P. Jesper Sj\u00f6str\u00f6m, S. R. Schultz, and P. L. Dragotti.   \n449 ABLE: An activity-based level set segmentation algorithm for two-photon calcium imaging   \n450 data. eNeuro, 2017.   \n451 [28] Somayyeh Soltanian-Zadeh, Kaan Sahingur, Sarah Blau, Yiyang Gong, and Sina Farsiu. Fast   \n452 and robust active neuron segmentation in two-photon calcium imaging using spatiotemporal   \n453 deep learning. Proceedings of the National Academy of Sciences, 116(17):8554\u20138563, 2019.   \n454 [29] Alexander Song, Adam S Charles, Sue Ann Koay, Jeff L Gauthier, Stephan Y Thiberge,   \n455 Jonathan W Pillow, and David W Tank. Volumetric two-photon imaging of neurons using   \n456 stereoscopy (vTwINS). Nature methods, 14(4):420, 2017.   \n457 [30] Alexander Song, Jeff L Gauthier, Jonathan W Pillow, David W Tank, and Adam S Charles.   \n458 Neural anatomy and optical microscopy (naomi) simulation for evaluating calcium imaging   \n459 methods. Journal of neuroscience methods, 358:109173, 2021.   \n460 [31] Quico Spaen, Roberto As\u00edn-Ach\u00e1, Selmaan N Chettih, Matthias Minderer, Christopher Harvey,   \n461 and Dorit S Hochbaum. HNCcorr: a novel combinatorial approach for cell identification in   \n462 calcium-imaging movies. Eneuro, 6(2), 2019.   \n463 [32] Robert Tibshirani. Regression shrinkage and selection via the lasso. Journal of the Royal   \n464 Statistical Society: Series B (Methodological), 58(1):267\u2013288, 1996.   \n465 [33] Yan Zhang, M\u00e1rton R\u00f3zsa, Yajie Liang, Daniel Bushey, Ziqiang Wei, Jihong Zheng, Daniel   \n466 Reep, Gerard Joey Broussard, Arthur Tsang, Getahun Tsegaye, et al. Fast and sensitive gcamp   \n467 calcium indicators for imaging neural populations. Nature, pages 1\u20138, 2023. ", "page_idx": 9}, {"type": "text", "text": "", "page_idx": 10}, {"type": "text", "text": "", "page_idx": 11}, {"type": "table", "img_path": "Ye0O4Nyn21/tmp/b2afa6d8ed2a071004ca85182c01db778857b5b3e0e3ea3d74e25e14fd53220b.jpg", "table_caption": [], "table_footnote": [], "page_idx": 12}, {"type": "text", "text": "469 A.1 Application of modified FISTA to neural network optimization ", "text_level": 1, "page_idx": 12}, {"type": "text", "text": "470 We further tested the modified FISTA momentum descent algorithm to problems outside of   \n471 neuroscience\u2014the training of neural networks\u2014to evaluate the scope of applicability of our   \n472 improvements. We used the problem of recognition of handwritten digits on a data set   \n473 from AT&T Research available at https://hastie.su.domains/StatLearnSparsity_files/   \n474 DATA/zipcode.html, reduced to 8x8 pixels, with a training set of 7291 images. The neural network   \n475 (NN) model used the Leaky ReLU activation, with layer sizes 64, 64, 32, 10.   \n476 The common approach to training NNs uses stochastic gradient descent, including stochastic momen  \n477 tum methods. Thus to compare to a non-stochastic momentum method we established a non-stochastic   \n478 baseline.   \n479 The dynamic estimation of the Lipshitz constant $L$ from TFOCS cannot be applied to the neural   \n480 network optimization because the optimization cost is highly non-linear. The multi-dimensional   \n481 estimation of $L$ is also computed only for the specific SEUDO function. The common practice is   \n482 to use a fixed descent rate, which serves as an analog of $\\frac{1}{2L}$ . Estimating the highest descent rate is   \n483 still not a fully solved problem. Algorithms for dynamic evaluation of the descent rate do exist (e.g.,   \n484 the ADAM algorithm in Kingma & Ba, 2015), however they rely on a constant to be picked for a   \n485 particular problem.   \n486 The advantage of stochastic methods is that they can use a higher descent rate without diverging, as   \n487 seen by observing the dependency of logarithm of mean square error from the number of training   \n488 passes for various descent rates (Fig 6). In these results we ensure that we start from the same fixed   \n489 randomized initial state since different initial states can produce wildly different results.   \n490 We observe that for the same descent rate (0.05 per pass), the stochastic and non-stochastic methods   \n491 produce very similar error values, however the graph for the stochastic method is more smooth.   \n492 The roughness of the graph represents the small divergences that manage to converge again over   \n493 time, and shows that the descent rate is close to the maximum. However the stochastic method can   \n494 accommodate a 100 times higher descent rate without diverging, and even a 1000 higher descent   \n1: Initialize $t=1$ ; $x[]=(i n i t i a l\\;v a l u e s);\\mathrm{{diff}[]=[0];\\mathrm{{gradient}\\_l a s t[]=[0]}}$   \n2: for $s t e p=1$ to maxstep do   \n3: $\\begin{array}{r}{t_{n e x t}=\\frac{1+\\sqrt{1+t^{2}*4}}{2}}\\end{array}$   \n4: \u03b7 =tnext t\u22121   \n5: if step \u0338= 1 then   \n6: t = tnext   \n7: end if   \n8: $x[\\!]=x[\\!]+\\eta*{\\mathrm{diff}}[\\!]$   \n9: for each $i$ in dimensions of $x$ do   \n10: if $x[i]<0$ then   \n11: $x[i]=0;\\mathrm{diff}[i]=0;$   \n12: end if   \n13: end for   \n14: gradient[] $=$ compute_gradient_f(x[])   \n15: x[] = x[] \u2212gradient[]   \n16: for each $i$ in dimensions of $x$ do   \n17: if $x[i]<0$ then   \n18: $x[i]=0$ ; diff[i] = 0; gradient[i] = 0   \n19: else   \n20: if gradient[i] $^*$ gradient_last[i] $<0$ then   \n21: diff $[i]=0$   \n22: else   \n23: diff[i] = diff[i] \u2212gradiLent[i]   \n24: end if   \n25: end if   \n26: end for   \n27: gradient_last[] $=$ gradient[]   \n28: end for   \n495 rate becomes rough but still converges. The non-stochastic method is able to make the passes faster,   \n496 because it performs the same accumulation of partial gradients, but saves the overhead of updating   \n497 the weights after each training case (or batch). However even adjusted for time, the stochastic method   \n498 performs faster. It is possible to compute the non-stochastic gradient in parallel by multiple threads   \n499 but we have not implemented this. We used this example of the non-stochastic descent as a baseline   \n500 for the FISTA-based momentum methods.   \n501 The summary of training errors in the momentum methods can be found in Figure 7A, and the mean   \n502 square errors after 10,000 training passes are listed in the Table 1.   \n503 The unmodified FISTA algoithm with $\\lambda=0$ performed on this task out of its domain worse than the   \n504 non-momentum baseline. Adding the momentum stop in the dimenstions with gradient sign change   \n505 produced a substantial improvement over the baseline. Fixing the parameter $\\eta=1$ produced a close   \n506 result to not fixing $\\eta$ , but with a less rough curve. We tested if the smoothness indicated that setting   \n507 $\\eta=1$ could accommodate a substantial increase in descent rate by re-running the algorithm at a ${4\\bf{x}}$   \n508 rate (0.2 instead of 0.05), and while this run did not diverge, we did observe a higher error rate.   \n509 Finally, we attempted to devise an algorithm that acts similar to the TFOCS dynamic evaluation of   \n510 $L$ but using the ratios of mean square values of gradient dimensions that change or not change sign   \n511 as an indication of roughness. The rapid growth of gradient dimensions after sign change is seen   \n512 as a beginning of a divergence, that causes the reduction of descent rate. This algorithm allowed   \n513 training at a substantially higher rate in the first few thousands of passes but then flattened out. The   \n514 automatically determined rate is close to the empirically found 0.05, and is higher in the initial passes   \n515 where it reaches higher values, but then drops to the lower values (Fig. 7B). It is possible that the   \n516 chosen criteria were not aggressive enough, and can be improved.   \n517 While event with the momentum descent the stochastic methods specialized for NN training can still   \n518 achieve faster speeds (Fig. 7C-D), we have demonstrated that our more general optimization still   \n519 represent a major improvement over both simple gradient descent and plain FISTA in a different   \n520 domain. ", "page_idx": 12}, {"type": "text", "text": "", "page_idx": 12}, {"type": "text", "text": "", "page_idx": 12}, {"type": "text", "text": "", "page_idx": 12}, {"type": "text", "text": "", "page_idx": 12}, {"type": "text", "text": "", "page_idx": 13}, {"type": "table", "img_path": "Ye0O4Nyn21/tmp/803cb2a8dd465487044f253b7923fe5b43cd7f62340c1c0e6f5e712f4a4f9413.jpg", "table_caption": [], "table_footnote": ["Table 1: Performance of algorithms on handwritten dataset "], "page_idx": 13}, {"type": "text", "text": "", "page_idx": 13}, {"type": "text", "text": "", "page_idx": 13}, {"type": "text", "text": "", "page_idx": 13}, {"type": "text", "text": "", "page_idx": 14}, {"type": "image", "img_path": "Ye0O4Nyn21/tmp/4d8b742c112825e67059a9649652acc21b014d9f6cc695334382acaa2f28d292.jpg", "img_caption": ["Figure 4: The whole set of cells detected by realSEUDO (blue), OnACID (red), and CNMF (green) in one movie, with selected time traces of matching cells. "], "img_footnote": [], "page_idx": 15}, {"type": "text", "text": "Cell ID ", "text_level": 1, "page_idx": 16}, {"type": "text", "text": "realSEUDO output: ", "text_level": 1, "page_idx": 16}, {"type": "image", "img_path": "Ye0O4Nyn21/tmp/b809c408e1aca283c1c0a2367bd181facd9bf68a51700da6198dabe8a5931b30.jpg", "img_caption": ["Figure 5: Example realSEUDO cells and traces from a single patch, ordered by the discovery time. "], "img_footnote": [], "page_idx": 16}, {"type": "text", "text": "Time (frames at 30 Hz) ", "text_level": 1, "page_idx": 16}, {"type": "image", "img_path": "Ye0O4Nyn21/tmp/d276570afde2332afafce7afccc779e56bec1911d73f393bb8af60aadad6898b.jpg", "img_caption": ["Figure 6: Comparison of different algorithm\u2019s learning curves on handwritten datasets. Left: meansquared error (MSE) as a function of optimization time. Right: MSE as a function of training passes. "], "img_footnote": [], "page_idx": 17}, {"type": "image", "img_path": "Ye0O4Nyn21/tmp/12995c45be9721a6502b4212d009d2c9228f9d8a267ef3e576ef2acc17522d99.jpg", "img_caption": ["Figure 7: Comaprison of training curves for different algorithms. A: Training MSE as a function of training passes for different variants of the improved FISTA algorithm. B: Training MSE improvement when setting $\\eta=1$ . C: Training MSE as a function of training passes for the best tested non-stochastic methods vs. momentum-improved FISTA D: Training MSE as a function of optimization time for the best tested non-stochastic methods vs. momentum-improved FISTA "], "img_footnote": [], "page_idx": 17}, {"type": "image", "img_path": "Ye0O4Nyn21/tmp/8158795858a2da31e0e1a6aa143bf1a5e3004829d703a26d62a25345d0b334e1.jpg", "img_caption": ["Figure 8: Full sets of strongly-paired traces from CNMF, OnACID and realSEUDO. "], "img_footnote": [], "page_idx": 18}, {"type": "text", "text": "521 NeurIPS Paper Checklist ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "23 Rat   \n24 paper\u2019s contributions and scope?   \n25 Answer: [Yes] ,   \n26 Justification: This work claims to provide a new algorithm for real-time processing of   \n27 calcium imaging data. The results show processing speeds of $80{-}200\\ \\mathrm{Hz}$ , far exceeding the   \n28 ${>}30\\,\\mathrm{Hz}$ minimum for real-time processing.   \n29 Guidelines:   \n30 \u2022 The answer NA means that the abstract and introduction do not include the claims   \n31 made in the paper.   \n32 \u2022 The abstract and/or introduction should clearly state the claims made, including the   \n33 contributions made in the paper and important assumptions and limitations. A No or   \n34 NA answer to this question will not be perceived well by the reviewers.   \n35 \u2022 The claims made should match theoretical and experimental results, and reflect how   \n36 much the results can be expected to generalize to other settings.   \n37 \u2022 It is fine to include aspirational goals as motivation as long as it is clear that these goals   \n38 are not attained by the paper. ", "page_idx": 19}, {"type": "text", "text": "2. Limitations ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "Question: Does the paper discuss the limitations of the work performed by the authors? Answer: [Yes] ", "page_idx": 19}, {"type": "text", "text": "Justification: We provide a discussion in the discussion section that discusses explicitly our limitations. ", "page_idx": 19}, {"type": "text", "text": "\u2022 The answer NA means that the paper has no limitation while the answer No means that the paper has limitations, but those are not discussed in the paper.   \n\u2022 The authors are encouraged to create a separate \"Limitations\" section in their paper.   \n\u2022 The paper should point out any strong assumptions and how robust the results are to violations of these assumptions (e.g., independence assumptions, noiseless settings, model well-specification, asymptotic approximations only holding locally). The authors should reflect on how these assumptions might be violated in practice and what the implications would be.   \n\u2022 The authors should reflect on the scope of the claims made, e.g., if the approach was only tested on a few datasets or with a few runs. In general, empirical results often depend on implicit assumptions, which should be articulated.   \n\u2022 The authors should reflect on the factors that influence the performance of the approach. For example, a facial recognition algorithm may perform poorly when image resolution is low or images are taken in low lighting. Or a speech-to-text system might not be used reliably to provide closed captions for online lectures because it fails to handle technical jargon.   \n\u2022 The authors should discuss the computational efficiency of the proposed algorithms and how they scale with dataset size.   \n\u2022 If applicable, the authors should discuss possible limitations of their approach to address problems of privacy and fairness.   \n\u2022 While the authors might fear that complete honesty about limitations might be used by reviewers as grounds for rejection, a worse outcome might be that reviewers discover limitations that aren\u2019t acknowledged in the paper. The authors should use their best judgment and recognize that individual actions in favor of transparency play an important role in developing norms that preserve the integrity of the community. Reviewers will be specifically instructed to not penalize honesty concerning limitations. ", "page_idx": 19}, {"type": "text", "text": "3. Theory Assumptions and Proofs ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "72 Question: For each theoretical result, does the paper provide the full set of assumptions and   \n73 a complete (and correct) proof? ", "page_idx": 19}, {"type": "text", "text": "Answer:[NA]   \nJustification: Our paper is based on developing a new algorithm, and we do not include theoretical claims. ", "page_idx": 20}, {"type": "text", "text": "78 \u2022 The answer NA means that the paper does not include theoretical results.   \n9 \u2022 All the theorems, formulas, and proofs in the paper should be numbered and cross  \n0 referenced.   \n1 \u2022 All assumptions should be clearly stated or referenced in the statement of any theorems.   \n2 \u2022 The proofs can either appear in the main paper or the supplemental material, but if   \n83 they appear in the supplemental material, the authors are encouraged to provide a short   \n4 proof sketch to provide intuition.   \n85 \u2022 Inversely, any informal proof provided in the core of the paper should be complemented   \n86 by formal proofs provided in appendix or supplemental material.   \n87 \u2022 Theorems and Lemmas that the proof relies upon should be properly referenced. ", "page_idx": 20}, {"type": "text", "text": "588 4. Experimental Result Reproducibility ", "text_level": 1, "page_idx": 20}, {"type": "text", "text": "589 Question: Does the paper fully disclose all the information needed to reproduce the main ex  \n590 perimental results of the paper to the extent that it affects the main claims and/or conclusions   \n591 of the paper (regardless of whether the code and data are provided or not)? ", "page_idx": 20}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 20}, {"type": "text", "text": "Justification: The data from this paper is open and available and full pseudo-code and all parameter selections are provided in the main text or supplementary. ", "page_idx": 20}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 If the paper includes experiments, a No answer to this question will not be perceived well by the reviewers: Making the paper reproducible is important, regardless of whether the code and data are provided or not.   \n\u2022 If the contribution is a dataset and/or model, the authors should describe the steps taken to make their results reproducible or verifiable.   \n\u2022 Depending on the contribution, reproducibility can be accomplished in various ways. For example, if the contribution is a novel architecture, describing the architecture fully might suffice, or if the contribution is a specific model and empirical evaluation, it may be necessary to either make it possible for others to replicate the model with the same dataset, or provide access to the model. In general. releasing code and data is often one good way to accomplish this, but reproducibility can also be provided via detailed instructions for how to replicate the results, access to a hosted model (e.g., in the case of a large language model), releasing of a model checkpoint, or other means that are appropriate to the research performed.   \n\u2022 While NeurIPS does not require releasing code, the conference does require all submissions to provide some reasonable avenue for reproducibility, which may depend on the nature of the contribution. For example (a) If the contribution is primarily a new algorithm, the paper should make it clear how to reproduce that algorithm. (b) If the contribution is primarily a new model architecture, the paper should describe the architecture clearly and fully. (c) If the contribution is a new model (e.g., a large language model), then there should either be a way to access this model for reproducing the results or a way to reproduce the model (e.g., with an open-source dataset or instructions for how to construct the dataset). (d) We recognize that reproducibility may be tricky in some cases, in which case authors are welcome to describe the particular way they provide for reproducibility. In the case of closed-source models, it may be that access to the model is limited in some way (e.g., to registered users), but it should be possible for other researchers to have some path to reproducing or verifying the results. ", "page_idx": 20}, {"type": "text", "text": "627 5. Open access to data and code ", "text_level": 1, "page_idx": 20}, {"type": "text", "text": "8 Question: Does the paper provide open access to the data and code, with sufficient instruc  \n29 tions to faithfully reproduce the main experimental results, as described in supplemental   \n0 material?   \n1 Answer: [No]   \n2 Justification: While the data is all freely available, the implementation will be released upon   \n33 publication. We do, however, provide full algorithmic and parameter selection details in the   \n34 paper.   \n35 Guidelines:   \n36 \u2022 The answer NA means that paper does not include experiments requiring code.   \n7 \u2022 Please see the NeurIPS code and data submission guidelines (https://nips.cc/   \n38 public/guides/CodeSubmissionPolicy) for more details.   \n9 \u2022 While we encourage the release of code and data, we understand that this might not be   \n40 possible, so \u201cNo\u201d is an acceptable answer. Papers cannot be rejected simply for not   \nincluding code, unless this is central to the contribution (e.g., for a new open-source   \n42 benchmark).   \n43 \u2022 The instructions should contain the exact command and environment needed to run to   \n44 reproduce the results. See the NeurIPS code and data submission guidelines (https:   \n45 //nips.cc/public/guides/CodeSubmissionPolicy) for more details.   \n46 \u2022 The authors should provide instructions on data access and preparation, including how   \n47 to access the raw data, preprocessed data, intermediate data, and generated data, etc.   \n8 \u2022 The authors should provide scripts to reproduce all experimental results for the new   \n49 proposed method and baselines. If only a subset of experiments are reproducible, they   \n50 should state which ones are omitted from the script and why.   \n\u2022 At submission time, to preserve anonymity, the authors should release anonymized   \n52 versions (if applicable).   \n53 \u2022 Providing as much information as possible in supplemental material (appended to the   \n54 paper) is recommended, but including URLs to data and code is permitted. ", "page_idx": 21}, {"type": "text", "text": "6. Experimental Setting/Details ", "text_level": 1, "page_idx": 21}, {"type": "text", "text": "Question: Does the paper specify all the training and test details (e.g., data splits, hyperparameters, how they were chosen, type of optimizer, etc.) necessary to understand the results? ", "page_idx": 21}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 21}, {"type": "text", "text": "Justification: Our method provides all parameter selections. Note that these parameters were not fit to data in the optimization sense but rather selected based on rules of thumb for the classes of algorithms used (sparse inference). ", "page_idx": 21}, {"type": "text", "text": "Guidelines: ", "page_idx": 21}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments. \u2022 The experimental setting should be presented in the core of the paper to a level of detail that is necessary to appreciate the results and make sense of them. \u2022 The full details can be provided either with the code, in appendix, or as supplemental material. ", "page_idx": 21}, {"type": "text", "text": "9 7. Experiment Statistical Significance ", "text_level": 1, "page_idx": 21}, {"type": "text", "text": "Question: Does the paper report error bars suitably and correctly defined or other appropriate information about the statistical significance of the experiments? ", "page_idx": 21}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 21}, {"type": "text", "text": "Justification: Where applicable (e.g., timing assessment etc.) error bars are provided. Guidelines: ", "page_idx": 21}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments. \u2022 The authors should answer \"Yes\" if the results are accompanied by error bars, confidence intervals, or statistical significance tests, at least for the experiments that support the main claims of the paper. ", "page_idx": 21}, {"type": "text", "text": "679 \u2022 The factors of variability that the error bars are capturing should be clearly stated (for   \n680 example, train/test split, initialization, random drawing of some parameter, or overall   \n681 run with given experimental conditions).   \n682 \u2022 The method for calculating the error bars should be explained (closed form formula,   \n683 call to a library function, bootstrap, etc.)   \n684 \u2022 The assumptions made should be given (e.g., Normally distributed errors).   \n685 \u2022 It should be clear whether the error bar is the standard deviation or the standard error   \n686 of the mean.   \n687 \u2022 It is OK to report 1-sigma error bars, but one should state it. The authors should   \n688 preferably report a 2-sigma error bar than state that they have a $96\\%$ CI, if the hypothesis   \n689 of Normality of errors is not verified.   \n690 \u2022 For asymmetric distributions, the authors should be careful not to show in tables or   \n691 figures symmetric error bars that would yield results that are out of range (e.g. negative   \n692 error rates).   \n693 \u2022 If error bars are reported in tables or plots, The authors should explain in the text how   \n694 they were calculated and reference the corresponding figures or tables in the text.   \n695 8. Experiments Compute Resources   \n696 Question: For each experiment, does the paper provide sufficient information on the com  \n697 puter resources (type of compute workers, memory, time of execution) needed to reproduce   \n698 the experiments?   \n699 Answer: [No]   \n700 Justification: A number of compute infrastructures were used to compute the results, and no   \n701 special hardware was needed (e.g., GPUs).   \n702 Guidelines:   \n703 \u2022 The answer NA means that the paper does not include experiments.   \n704 \u2022 The paper should indicate the type of compute workers CPU or GPU, internal cluster,   \n705 or cloud provider, including relevant memory and storage.   \n706 \u2022 The paper should provide the amount of compute required for each of the individual   \n707 experimental runs as well as estimate the total compute.   \n708 \u2022 The paper should disclose whether the full research project required more compute   \n709 than the experiments reported in the paper (e.g., preliminary or failed experiments that   \n710 didn\u2019t make it into the paper).   \n711 9. Code Of Ethics   \n712 Question: Does the research conducted in the paper conform, in every respect, with the   \n713 NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines?   \n714 Answer: [Yes]   \n715 Justification: This paper does not use human subjects, private or protected data, or provide   \n716 any capability in that might compromise safety or security. This work is squarely in the   \n717 scientific microscopy analysis domain for non-human experiments.   \n718 Guidelines:   \n719 \u2022 The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics.   \n720 \u2022 If the authors answer No, they should explain the special circumstances that require a   \n721 deviation from the Code of Ethics.   \n722 \u2022 The authors should make sure to preserve anonymity (e.g., if there is a special consid  \n723 eration due to laws or regulations in their jurisdiction).   \n724 10. Broader Impacts   \n725 Question: Does the paper discuss both potential positive societal impacts and negative   \n726 societal impacts of the work performed?   \n727 Answer: [NA]   \n728 Justification: This work describes the broader scientific impacts, but the advances are   \n730 Guidelines:   \n731 \u2022 The answer NA means that there is no societal impact of the work performed.   \n732 \u2022 If the authors answer NA or No, they should explain why their work has no societal   \n733 impact or why the paper does not address societal impact.   \n734 \u2022 Examples of negative societal impacts include potential malicious or unintended uses   \n735 (e.g., disinformation, generating fake profiles, surveillance), fairness considerations   \n736 (e.g., deployment of technologies that could make decisions that unfairly impact specific   \n737 groups), privacy considerations, and security considerations.   \n738 \u2022 The conference expects that many papers will be foundational research and not tied   \n739 to particular applications, let alone deployments. However, if there is a direct path to   \n740 any negative applications, the authors should point it out. For example, it is legitimate   \n741 to point out that an improvement in the quality of generative models could be used to   \n742 generate deepfakes for disinformation. On the other hand, it is not needed to point out   \n743 that a generic algorithm for optimizing neural networks could enable people to train   \n744 models that generate Deepfakes faster.   \n745 \u2022 The authors should consider possible harms that could arise when the technology is   \n746 being used as intended and functioning correctly, harms that could arise when the   \n747 technology is being used as intended but gives incorrect results, and harms following   \n748 from (intentional or unintentional) misuse of the technology.   \n749 \u2022 If there are negative societal impacts, the authors could also discuss possible mitigation   \n750 strategies (e.g., gated release of models, providing defenses in addition to attacks,   \n751 mechanisms for monitoring misuse, mechanisms to monitor how a system learns from   \n752 feedback over time, improving the efficiency and accessibility of ML).   \n753 11. Safeguards   \n754 Question: Does the paper describe safeguards that have been put in place for responsible   \n755 release of data or models that have a high risk for misuse (e.g., pretrained language models,   \n756 image generators, or scraped datasets)?   \n757 Answer: [NA]   \n758 Justification: This algorithm does not need safeguards as it is made for microscopy for   \n759 non-human applications.   \n760 Guidelines:   \n761 \u2022 The answer NA means that the paper poses no such risks.   \n762 \u2022 Released models that have a high risk for misuse or dual-use should be released with   \n763 necessary safeguards to allow for controlled use of the model, for example by requiring   \n764 that users adhere to usage guidelines or restrictions to access the model or implementing   \n765 safety filters.   \n766 \u2022 Datasets that have been scraped from the Internet could pose safety risks. The authors   \n767 should describe how they avoided releasing unsafe images.   \n768 \u2022 We recognize that providing effective safeguards is challenging, and many papers do   \n769 not require this, but we encourage authors to take this into account and make a best   \n770 faith effort.   \n771 12. Licenses for existing assets   \n772 Question: Are the creators or original owners of assets (e.g., code, data, models), used in   \n773 the paper, properly credited and are the license and terms of use explicitly mentioned and   \n774 properly respected?   \n775 Answer: [Yes]   \n776 Justification: Everyone who contributed is properly referenced.   \n777 Guidelines:   \n778 \u2022 The answer NA means that the paper does not use existing assets.   \n779 \u2022 The authors should cite the original paper that produced the code package or dataset.   \n780 \u2022 The authors should state which version of the asset is used and, if possible, include a   \n781 URL.   \n782 \u2022 The name of the license (e.g., CC-BY 4.0) should be included for each asset.   \n83 \u2022 For scraped data from a particular source (e.g., website), the copyright and terms of   \n84 service of that source should be provided.   \n85 \u2022 If assets are released, the license, copyright information, and terms of use in the   \n86 package should be provided. For popular datasets, paperswithcode.com/datasets   \n87 has curated licenses for some datasets. Their licensing guide can help determine the   \n88 license of a dataset.   \n89 \u2022 For existing datasets that are re-packaged, both the original license and the license of   \n90 the derived asset (if it has changed) should be provided.   \n91 \u2022 If this information is not available online, the authors are encouraged to reach out to   \n92 the asset\u2019s creators.   \n793 13. New Assets   \n794 Question: Are new assets introduced in the paper well documented and is the documentation   \n795 provided alongside the assets?   \n796 Answer: [NA]   \n797 Justification: No new assets are presented!   \n798 Guidelines:   \n799 \u2022 The answer NA means that the paper does not release new assets.   \n800 \u2022 Researchers should communicate the details of the dataset/code/model as part of their   \n801 submissions via structured templates. This includes details about training, license,   \n802 limitations, etc.   \n803 \u2022 The paper should discuss whether and how consent was obtained from people whose   \n804 asset is used.   \n805 \u2022 At submission time, remember to anonymize your assets (if applicable). You can either   \n806 create an anonymized URL or include an anonymized zip file.   \n807 14. Crowdsourcing and Research with Human Subjects   \n808 Question: For crowdsourcing experiments and research with human subjects, does the paper   \n809 include the full text of instructions given to participants and screenshots, if applicable, as   \n810 well as details about compensation (if any)?   \n811 Answer: [NA]   \n812 Justification: No crowdsourcing was used.   \n813 Guidelines:   \n814 \u2022 The answer NA means that the paper does not involve crowdsourcing nor research with   \n815 human subjects.   \n816 \u2022 Including this information in the supplemental material is fine, but if the main contribu  \n817 tion of the paper involves human subjects, then as much detail as possible should be   \n818 included in the main paper.   \n819 \u2022 According to the NeurIPS Code of Ethics, workers involved in data collection, curation,   \n820 or other labor should be paid at least the minimum wage in the country of the data   \n821 collector. ", "page_idx": 22}, {"type": "text", "text": "", "page_idx": 23}, {"type": "text", "text": "", "page_idx": 24}, {"type": "text", "text": "", "page_idx": 24}, {"type": "text", "text": "15. Institutional Review Board (IRB) Approvals or Equivalent for Research with Human Subjects ", "page_idx": 24}, {"type": "text", "text": "822   \n823   \n824 Question: Does the paper describe potential risks incurred by study participants, whether   \n825 such risks were disclosed to the subjects, and whether Institutional Review Board (IRB)   \n826 approvals (or an equivalent approval/review based on the requirements of your country or   \n827 institution) were obtained?   \n828 Answer: [NA]   \n829 Justification: No IRB was needed.   \n830 Guidelines:   \n831 \u2022 The answer NA means that the paper does not involve crowdsourcing nor research with   \n832 human subjects. ", "page_idx": 24}, {"type": "text", "text": "\u2022 Depending on the country in which research is conducted, IRB approval (or equivalent) may be required for any human subjects research. If you obtained IRB approval, you should clearly state this in the paper.   \n\u2022 We recognize that the procedures for this may vary significantly between institutions and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the guidelines for their institution.   \n\u2022 For initial submissions, do not include any information that would break anonymity (if applicable), such as the institution conducting the review. ", "page_idx": 25}]