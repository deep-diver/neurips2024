{"references": [{"fullname_first_author": "Ben Mildenhall", "paper_title": "Nerf: Representing scenes as neural radiance fields for view synthesis", "publication_date": "2021-00-00", "reason": "This paper introduces NeRFs, a foundational technique for representing 3D scenes as neural radiance fields, which is heavily built upon in this work."}, {"fullname_first_author": "Jonathan T Barron", "paper_title": "Mip-nerf 360: Unbounded anti-aliased neural radiance fields", "publication_date": "2022-00-00", "reason": "This paper extends NeRFs to handle unbounded scenes, addressing a key challenge in outdoor autonomous driving scenarios relevant to DistillNeRF."}, {"fullname_first_author": "Jiawei Yang", "paper_title": "EmerNeRF: Emergent spatial-temporal scene decomposition via self-supervision", "publication_date": "2023-00-00", "reason": "This paper introduces EmerNeRF, a technique for handling dynamic objects in NeRFs, providing the offline NeRF training utilized in DistillNeRF."}, {"fullname_first_author": "Alec Radford", "paper_title": "Learning transferable visual models from natural language supervision", "publication_date": "2021-00-00", "reason": "This paper introduces CLIP, a vision foundation model that is used in DistillNeRF to provide semantic understanding of the scene."}, {"fullname_first_author": "Mathilde Caron", "paper_title": "Emerging properties in self-supervised vision transformers", "publication_date": "2021-00-00", "reason": "This paper introduces DINOv2, another vision foundation model used in DistillNeRF for semantic scene understanding."}]}