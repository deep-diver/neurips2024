[{"figure_path": "cV4fcjcwmz/figures/figures_1_1.jpg", "caption": "Figure 1: Data extraction attacks across text, image, and graph. (a) In domains like text and image, by inputting specific text prompts, private training data can be directly extracted from the outputs generated by models. (b) Conversely, in the graph domain, the pre-trained models are typically non-generative, and exhibit a diversity of pre-training tasks, such as contrastive learning, graph reconstruction, and context prediction.", "description": "The figure illustrates data extraction attacks across different data types (text, image, and graph). Panel (a) shows how generative models (like GPT-2 and diffusion models) for text and image data can be directly exploited by inputting specific prompts to extract private training data from their outputs.  Panel (b) contrasts this by showing that graph-based models, which are commonly used for molecular data, are often non-generative.  They typically use various pre-training techniques (contrastive learning, reconstruction, and context prediction) making direct data extraction more difficult and requiring alternative approaches.", "section": "1 Introduction"}, {"figure_path": "cV4fcjcwmz/figures/figures_4_1.jpg", "caption": "Figure 1: Data extraction attacks across text, image, and graph. (a) In domains like text and image, by inputting specific text prompts, private training data can be directly extracted from the outputs generated by models. (b) Conversely, in the graph domain, the pre-trained models are typically non-generative, and exhibit a diversity of pre-training tasks, such as contrastive learning, graph reconstruction, and context prediction.", "description": "This figure illustrates different data extraction attack scenarios across various data types (text, image, graph).  Panel (a) demonstrates how generative models (text and image) can directly leak training data when prompted with specific inputs.  In contrast, panel (b) shows that non-generative models (graphs) require different attack strategies due to their non-generative nature and diverse pre-training tasks. It highlights the unique challenges in extracting training data from molecular pre-trained models.", "section": "1 Introduction"}, {"figure_path": "cV4fcjcwmz/figures/figures_8_1.jpg", "caption": "Figure 3: Visualization of \u03b1 distribution under different pre-trained models. Models in the same category are assigned similar colors for distinction.", "description": "This figure visualizes the distribution of the hyperparameter \u03b1 in the scoring function across various molecular pre-trained models.  The x-axis represents the value of \u03b1, and the y-axis shows the density of \u03b1 values. Different colors represent different categories of models (Contrastive Learning, Graph Reconstruction, Context Prediction). The distributions are quite distinct across different model categories suggesting that the scoring function is effective despite being model-independent. ", "section": "4.2 Experimental Results"}]