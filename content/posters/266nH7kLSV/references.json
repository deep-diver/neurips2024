{"references": [{"fullname_first_author": "Sanjeev Arora", "paper_title": "On exact computation with an infinitely wide neural net", "publication_date": "2019-12-08", "reason": "This paper is foundational for the theoretical understanding of infinite-width neural networks and their connection to kernel methods, which is central to the Temp-GNTK approach."}, {"fullname_first_author": "Simon S. Du", "paper_title": "Graph Neural Tangent Kernel: Fusing graph neural networks with graph kernels", "publication_date": "2019-12-08", "reason": "This paper introduces the Graph Neural Tangent Kernel (GNTK), which is the basis for the Temp-GNTK extension to temporal graphs, providing theoretical interpretations and advantages of combining graph neural networks and graph kernels."}, {"fullname_first_author": "Arthur Jacot", "paper_title": "Neural tangent kernel: Convergence and generalization in neural networks", "publication_date": "2018-12-03", "reason": "This paper establishes the Neural Tangent Kernel (NTK) theory, a key theoretical underpinning for understanding the properties of wide neural networks, which is essential for the Temp-GNTK's theoretical analysis."}, {"fullname_first_author": "Luana Ruiz", "paper_title": "Graph neural tangent kernel: Convergence on large graphs", "publication_date": "2023-07-23", "reason": "This paper extends the GNTK theory to graphons, large-scale graph limits, providing a theoretical foundation for the scalability and generalization of Temp-GNTK to massive temporal graphs."}, {"fullname_first_author": "Emanuele Rossi", "paper_title": "Temporal graph networks for deep learning on dynamic graphs", "publication_date": "2020-06-10", "reason": "This paper introduces Temporal Graph Networks (TGNs), a state-of-the-art approach in temporal graph learning that serves as a strong baseline for comparison with the proposed Temp-GNTK method."}]}