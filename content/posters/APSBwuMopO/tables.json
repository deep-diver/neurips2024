[{"figure_path": "APSBwuMopO/tables/tables_5_1.jpg", "caption": "Table 1: Performance improvement by OCTree on datasets with language descriptions. We report test error rates (%) for three classification tasks (*) and mean absolute error (\u00d710\u22123) for two regression tasks (\u2020). The lowest errors are highlighted in bold. Values in parentheses indicate the relative error rate reduction from the baseline. We report the mean error and standard deviation across three random splits, except for two regression tasks (time series tabular data), which are split by time index. N/A indicates that the method is not applicable, as HyperFast is a classification model.", "description": "This table presents the results of the OCTree method on datasets with language descriptions.  It compares the test error rates (or mean absolute errors for regression) achieved by different models (XGBoost, MLP, and HyperFast) with and without OCTree. The table shows the baseline performance, the performance after applying OCTree with Llama 2, and the performance after applying OCTree with GPT-40.  The improvement in performance using OCTree is shown in parentheses as a percentage reduction in error.", "section": "4.1 Main results: Context-aware feature engineering"}, {"figure_path": "APSBwuMopO/tables/tables_6_1.jpg", "caption": "Table 2: Applicability and comparison of automated feature engineering methods. We report the mean error (%) and standard deviation across the six datasets with language descriptions used in Tables 1 and 13. The lowest error is highlighted in bold. Values in parentheses indicate the relative error rate reduction from the baseline model (i.e., XGBoost [11]), while N/I indicates no gain.", "description": "This table compares the performance of OCTree against other automated feature engineering methods (AutoFeat, OpenFE, and CAAFE).  It shows the average error rate across six datasets, highlighting OCTree's superior performance, particularly when using GPT-40. The table also demonstrates OCTree's ability to handle datasets with and without language descriptions, unlike some of the other methods.", "section": "4.1 Main results: Context-aware feature engineering"}, {"figure_path": "APSBwuMopO/tables/tables_6_2.jpg", "caption": "Table 4: OCTree with Llama 2 variants. We report the average test error rates (%) and standard deviations across three random seeds on the 19 datasets without language descriptions.", "description": "This table compares the performance of OCTree using different variants of the Llama 2 language model on 19 classification datasets.  The datasets lack language descriptions of features, making this a context-agnostic setting. The table shows average test error rates and standard deviations across three independent trials for each model variant, allowing for a comparison of their effectiveness in automated feature generation for tabular data.", "section": "4.2 Main results: Context-agnostic feature engineering"}, {"figure_path": "APSBwuMopO/tables/tables_7_1.jpg", "caption": "Table 3: Performance improvement by OCTree on datasets without language descriptions. We report test error rates (%) on the 19 classification tasks from Grinsztajn et al. [13]. The lowest error is in bold. Values in parentheses indicate the relative error rate reduction from the baseline, while N/I indicates no gain. We report the mean error and standard deviation across the three random splits.", "description": "This table presents the results of applying the OCTree method to 19 classification datasets that do not include language descriptions.  It compares the test error rates achieved by using OCTree against a baseline XGBoost model for each dataset.  The lowest error rate for each dataset is highlighted, and the percentage reduction in error achieved using OCTree is indicated in parentheses.  'N/I' indicates no improvement was observed.", "section": "4.2 Main results: Context-agnostic feature engineering"}, {"figure_path": "APSBwuMopO/tables/tables_7_2.jpg", "caption": "Table 5: Comparison with automatic feature engineering methods. We report the mean error (%) and standard deviation across the 22 datasets used in Tables 1 and 3. The lowest error is highlighted in bold, and the second lowest is underlined. Values in parentheses indicate the relative error rate reduction from the baseline model. OCTree refers to our method integrated with other approaches.", "description": "This table compares the performance of OCTree against other automated feature engineering methods (AutoFeat and OpenFE) on 22 datasets.  It shows the mean error and standard deviation for both XGBoost and MLP models.  The results demonstrate that OCTree consistently outperforms the other methods and that integrating OCTree with OpenFE further improves performance.", "section": "4.3 Ablations and analysis"}, {"figure_path": "APSBwuMopO/tables/tables_8_1.jpg", "caption": "Table 6: Ablation study of the proposed decision tree reasoning. We report the mean error (%) and standard deviation across three random splits on two datasets with language descriptions (*) and two datasets without language descriptions (\u2020). The lowest error is highlighted in bold. Values in parentheses indicate the relative error rate reduction from the baseline model.", "description": "This table presents the results of an ablation study to evaluate the impact of the two main components of the proposed OCTree framework: the generation of new column features and the incorporation of decision tree reasoning as feedback to the LLM. The study is conducted on four datasets: two with language descriptions and two without. The table shows the mean error and standard deviation for each dataset and condition, highlighting the lowest error rate in bold and providing the relative error reduction from the baseline in parentheses. This helps to quantify the effect of each component on model performance.", "section": "4.3 Ablations and analysis"}, {"figure_path": "APSBwuMopO/tables/tables_8_2.jpg", "caption": "Table 7: Performance improvement through feature transfer. We optimize the feature generation rule using XGBoost and transfer the generated features to improve MLP and HyperFast (OCTreetrans). We report the test error rates (%) and standard deviation across three random seeds for two datasets with language descriptions (*) and two datasets without (\u2020). The lowest error is in bold, with values in parentheses indicating the relative error rate reduction from the baseline model. N/I denotes cases where no improvement was observed.", "description": "This table presents the results of an experiment to evaluate the transferability of features generated by OCTree using XGBoost to other prediction models, specifically MLP and HyperFast.  The experiment uses four datasets, two with language descriptions and two without.  It shows the baseline error rates for each model and dataset, and then shows the error rates after transferring features generated by OCTree. The improvement, or lack thereof, is presented as a percentage reduction.  N/I indicates no improvement.", "section": "4.3 Ablations and analysis"}, {"figure_path": "APSBwuMopO/tables/tables_9_1.jpg", "caption": "Table 8: LLM identifies important features. We report the mean error (%) and standard deviation across three random splits on the Disease dataset. Both GPT-40 and Llama 2 identify the cough feature as more important, consistent with the accuracy seen in XGBoost models trained with and without these features.", "description": "This table presents the results of an experiment designed to assess the ability of LLMs to identify important features for a prediction task. The experiment involved removing two features ('Cough' and 'Cholesterol') from the Disease dataset and prompting two different LLMs (GPT-40 and Llama 2) to rank the importance of these features for predicting the target variable. The table shows the mean error and standard deviation across three random splits for an XGBoost model trained with different combinations of these features. The results indicate that both LLMs correctly identified 'Cough' as the more important feature, which is consistent with the better accuracy achieved by the XGBoost model trained with the 'Cough' feature.", "section": "4.3 Ablations and analysis"}, {"figure_path": "APSBwuMopO/tables/tables_18_1.jpg", "caption": "Table 3: Performance improvement by OCTree on datasets without language descriptions. We report test error rates (%) on the 19 classification tasks from Grinsztajn et al. [13]. The lowest error is in bold. Values in parentheses indicate the relative error rate reduction from the baseline, while N/I indicates no gain. We report the mean error and standard deviation across the three random splits.", "description": "This table shows the performance improvement achieved by OCTree on 19 classification datasets from Grinsztajn et al. [13], where language descriptions for features are not available.  The table compares the test error rates of OCTree against baseline models (XGBoost, MLP, and HyperFast) and presents the relative error reduction achieved by OCTree. The lowest error rates for each dataset are highlighted in bold, and N/I is used to denote cases with no improvement. The mean error and standard deviation are reported across three random splits for each dataset.", "section": "4.2 Main results: Context-agnostic feature engineering"}, {"figure_path": "APSBwuMopO/tables/tables_18_2.jpg", "caption": "Table 1: Performance improvement by OCTree on datasets with language descriptions. We report test error rates (%) for three classification tasks (*) and mean absolute error (\u00d710\u22123) for two regression tasks (\u2020). The lowest errors are highlighted in bold. Values in parentheses indicate the relative error rate reduction from the baseline. We report the mean error and standard deviation across three random splits, except for two regression tasks (time series tabular data), which are split by time index. N/A indicates that the method is not applicable, as HyperFast is a classification model.", "description": "This table presents the results of applying the OCTree method to datasets with language descriptions.  It compares the performance of different models (XGBoost, MLP, HyperFast) with and without OCTree, using metrics appropriate for both classification and regression tasks.  The improvement in performance offered by OCTree is shown using both absolute error values and the percentage reduction in error compared to baseline models.", "section": "4.1 Main results: Context-aware feature engineering"}, {"figure_path": "APSBwuMopO/tables/tables_19_1.jpg", "caption": "Table 1: Performance improvement by OCTree on datasets with language descriptions. We report test error rates (%) for three classification tasks (*) and mean absolute error (\u00d710\u22123) for two regression tasks (\u2020). The lowest errors are highlighted in bold. Values in parentheses indicate the relative error rate reduction from the baseline. We report the mean error and standard deviation across three random splits, except for two regression tasks (time series tabular data), which are split by time index. N/A indicates that the method is not applicable, as HyperFast is a classification model.", "description": "This table presents the results of applying the OCTree method to datasets with descriptions available in natural language.  It shows the test error rates for classification tasks and mean absolute error for regression tasks. The best performing model for each task is shown in bold, and the improvement percentage compared to the baseline model is given in parentheses.  The table also differentiates between results obtained using Llama 2 and GPT-4, and includes the results for three different prediction models (XGBoost, MLP, and HyperFast).", "section": "4.1 Main results: Context-aware feature engineering"}, {"figure_path": "APSBwuMopO/tables/tables_19_2.jpg", "caption": "Table 1: Performance improvement by OCTree on datasets with language descriptions. We report test error rates (%) for three classification tasks (*) and mean absolute error (\u00d710\u22123) for two regression tasks (\u2020). The lowest errors are highlighted in bold. Values in parentheses indicate the relative error rate reduction from the baseline. We report the mean error and standard deviation across three random splits, except for two regression tasks (time series tabular data), which are split by time index. N/A indicates that the method is not applicable, as HyperFast is a classification model.", "description": "This table shows the performance improvement achieved by OCTree on several datasets with language descriptions, comparing it to various baseline models (XGBoost, MLP, HyperFast).  It presents test error rates for classification and mean absolute error for regression tasks.  The results are averaged across three random splits (except for time series data), with standard deviations reported.  The relative error reduction compared to the baseline is also given in parentheses.  The table highlights the best-performing methods in bold.", "section": "4.1 Main results: Context-aware feature engineering"}, {"figure_path": "APSBwuMopO/tables/tables_20_1.jpg", "caption": "Table 13: Performance improvements by OCTree on datasets with language descriptions. We report test error rates (%) on six classification tasks (*) and mean absolute errors (\u00d710\u22123) for two regression tasks (\u2020). The lowest error is in bold. Values in parentheses indicate the relative error rate reduction from the baseline. We report the mean error and standard deviation across three random splits, except for the two regression tasks (time series tabular data), which are split by time index. GPT-40 was used for both CAAFE and OCTree.", "description": "This table compares the performance of OCTree against CAAFE and a baseline model on datasets with language descriptions.  It shows the test error rates for classification tasks and mean absolute errors for regression tasks. The results demonstrate the improvement achieved by OCTree in terms of relative error rate reduction.", "section": "E Comparison with CAAFE"}, {"figure_path": "APSBwuMopO/tables/tables_21_1.jpg", "caption": "Table 14: OCTree on datasets with hundreds of features. We report the mean error (%) and the lowest error is highlighted in bold. Values in parentheses indicate the relative error reduction from the baseline model (i.e., XGBoost [11]).", "description": "This table presents the results of applying OCTree to datasets with a large number of features (madelon with 501 features and nomao with 119 features).  It compares the mean error rate achieved by OCTree against a baseline XGBoost model.  The percentage improvement achieved by OCTree is shown in parentheses for each dataset.", "section": "G Scalability of OCTree"}]