[{"figure_path": "zDYXdR3ClP/figures/figures_1_1.jpg", "caption": "Figure 1: Motivation of our work. A pre-trained generative model serves as the shared component and minimal parameters are added to model the specificity of each degradation restoration task.", "description": "The figure illustrates the core idea of the UIR-LORA framework.  A pre-trained generative model acts as a shared component for restoring various types of degraded images (noisy, hazy, blurry, low light).  Specific, minimal parameters (Low-Rank Adapters or LORAs) are added to this shared model for each degradation type, allowing the model to handle multiple degradations efficiently without parameter conflicts. The framework leverages the pre-trained model's knowledge of clean image distribution and only adds the minimal necessary adjustments to adapt to specific degradation scenarios.", "section": "1 Introduction"}, {"figure_path": "zDYXdR3ClP/figures/figures_3_1.jpg", "caption": "Figure 2: Overview of UIR-LORA. UIR-LORA consists of two components: a degradation-aware router and a universal image restorer. The router calculates degradation similarity in the latent space of CLIP, while the restorer utilizes the similarity provided by the router to combine LoRAs and frozen base model and restore images with multiple or mixed degadations.", "description": "This figure illustrates the architecture of the UIR-LORA model.  It highlights the two main components: the Degradation-Aware Router and the Universal Image Restorer. The router takes a degraded image as input and uses CLIP's image and text encoders to compute a similarity score between the input image's degradation and a set of predefined degradation types. These similarity scores are then used by the Universal Image Restorer, which combines a pre-trained generative model with multiple low-rank adapters (LoRAs) - each LoRA specializing in a specific degradation type - to restore the image. The combination of LoRAs is weighted by the similarity scores from the router, enabling the model to handle multiple or mixed degradations effectively. ", "section": "3.2 Overview of Universal Framework"}, {"figure_path": "zDYXdR3ClP/figures/figures_6_1.jpg", "caption": "Figure 2: Overview of UIR-LORA. UIR-LORA consists of two components: a degradation-aware router and a universal image restorer. The router calculates degradation similarity in the latent space of CLIP, while the restorer utilizes the similarity provided by the router to combine LoRAs and frozen base model and restore images with multiple or mixed degadations.", "description": "This figure illustrates the architecture of the proposed Universal Image Restoration through Low-Rank Adaptation (UIR-LORA) framework. It consists of two main parts: a Degradation-Aware Router and a Universal Image Restorer. The router takes a degraded image as input, extracts its degradation features using CLIP, and calculates the similarity between this degradation and a set of predefined degradation types. The restorer uses this similarity information to combine a set of low-rank adapters (LoRAs) and a pre-trained generative model to restore the image. Each LoRA is trained to handle a specific type of degradation, and the combination of LoRAs allows the model to handle multiple or mixed degradations.", "section": "3.2 Overview of Universal Framework"}, {"figure_path": "zDYXdR3ClP/figures/figures_7_1.jpg", "caption": "Figure 3: Qualitative comparison on multiple degraded images.", "description": "This figure shows a qualitative comparison of image restoration results on multiple degraded images using different methods: Restormer, PromptIR, Daclip-IR, and the proposed UIR-LORA method.  The results are shown for four different types of degradations: Noisy, JPEG Compression, Raindrops, and Inpainting. Each row displays the results for a specific degradation type.  The first column shows the degraded input image. Subsequent columns present the restored images generated by each method, followed by the ground truth (GT) image in the last column. This allows for a visual comparison of the effectiveness of each method in handling various types of image degradations.", "section": "4.3 Multiple Image Restoration"}, {"figure_path": "zDYXdR3ClP/figures/figures_8_1.jpg", "caption": "Figure 5: The impact of LoRA's rank on deblurring and denoising tasks.", "description": "This figure shows the impact of the rank of the LoRA (Low-Rank Adapters) on the performance of deblurring and denoising tasks.  The x-axis represents the rank of the LoRA, and the y-axis represents the performance metrics (PSNR, SSIM, LPIPS, and FID).  The results show that increasing the rank of the LoRA improves the performance, but the improvement diminishes after a certain point. This suggests that there is a trade-off between performance and the number of trainable parameters.", "section": "4.5 Ablation Study"}, {"figure_path": "zDYXdR3ClP/figures/figures_13_1.jpg", "caption": "Figure 4: Qualitative comparison on multiple degraded images.", "description": "This figure displays a qualitative comparison of image restoration results for multiple degradation methods. The top row shows the input degraded images and the results from Restormer and PromptIR. The bottom row shows the results from Daclip-IR, the proposed UIR-LORA method, and the ground truth (GT). Each column represents a different image, showcasing the effectiveness of different methods on various image degradation scenarios.", "section": "4.4 Mixed Image Restoration"}, {"figure_path": "zDYXdR3ClP/figures/figures_14_1.jpg", "caption": "Figure 6: Qualitative comparison on mixed degraded images from LOLBlur dataset.", "description": "This figure shows a qualitative comparison of image restoration results on images from the LOLBlur dataset, which contains images with mixed degradations (blur and low light).  It compares the performance of several state-of-the-art image restoration methods, including Restormer, PromptIR, Daclip-IR, and the proposed UIR-LORA method.  Each row represents a different image from the dataset.  The columns present the input degraded image, and the results produced by each method, as well as the ground truth (GT).  It visually demonstrates the superior quality achieved by UIR-LORA in restoring the original image details.", "section": "A.2 More Visual Results"}]