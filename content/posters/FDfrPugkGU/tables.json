[{"figure_path": "FDfrPugkGU/tables/tables_6_1.jpg", "caption": "Table 1: Comparing \"Local\", Conventional FIT (\"FIT\"), DoFIT-base (\"Base\"), and \"DoFIT\" on Finance (F) domain and Finance&General (F&G) domain datasets. FinGPT [36] and Alpaca-GPT4 [23] are the training datasets on F domain and G domain, respectively. FPB [19], FiQA-SA [18], TFNS [17], and NWGI [33] are the evaluation datasets on F domain. Avg:3 and Avg:4 denote the average result on the first three evaluation datasets (i.e., FPB, FiQA-SA, and TFNS) and all the evaluation datasets, respectively. \u2191 refers to the performance improvement compared to the alternative marked with the same color (i.e., using the same LoRA configuration) on F domain. \u2193 denotes performance degradation, oppositely.", "description": "This table compares the performance of four different methods (Local, Conventional FIT, DoFIT-base, and DoFIT) on two datasets (Finance and Finance&General) using several metrics (Accuracy and F1-score).  It shows how the proposed DoFIT method improves upon existing methods by alleviating catastrophic forgetting and considering domain-aware data heterogeneity.", "section": "4.2 Performance Evaluation"}, {"figure_path": "FDfrPugkGU/tables/tables_7_1.jpg", "caption": "Table 2: Comparing \"Local\", Conventional FIT (\"FIT\"), DoFIT-base (\"Base\"), and \"DoFIT\" on Medical domain (M), and combined Medical&General domain (M&G). MedAlpaca [2], and Alpaca-GPT4 [23] are the training datasets on M domain, and G domain, respectively. MedQA [10], and MedMCQA [22] are the evaluation datasets on M domain. \u2191 refers to the performance improvement compared to the alternative marked with the same color (i.e., using the same LoRA configuration) on M domain.", "description": "This table compares the performance of different methods (Local, FIT, DoFIT-base, and DoFIT) on the Medical domain (M) and the combined Medical & General domain (M&G).  It shows the accuracy scores on the MedQA and MedMCQA evaluation datasets. The results highlight the impact of using different approaches in handling data heterogeneity in federated instruction tuning, especially the benefits of DoFIT's strategies in alleviating catastrophic forgetting in cross-domain collaborative training.", "section": "4.2 Performance Evaluation"}, {"figure_path": "FDfrPugkGU/tables/tables_8_1.jpg", "caption": "Table 3: The number of parameters per round in training. \"Frozen\" denotes the parameter size of LLM. \"Trainable\" denotes the parameter size of the updating weight matrix in client side. \"Comm.\" denotes the communication parameters between client side and (intra-domain) server side. \"S-Comm.\" denotes the communication parameters between intra-domain server side and inter-domain server side. 32qv and 32d denote LoRA[Q,V] and LoRA[D], respectively. F&G and M&G denote Finance&General domain, and Medical&General domain, respectively.", "description": "This table compares the number of parameters used in different methods (FIT, DoFIT-base, and DoFIT) for training on Finance&General and Medical&General domains. It breaks down the parameters into frozen (LLM), trainable (updating weight matrix), communication between client and intra-domain server, and communication between intra- and inter-domain servers.", "section": "4.1 Experimental Settings"}, {"figure_path": "FDfrPugkGU/tables/tables_12_1.jpg", "caption": "Table 4: Comparison with existing federated domain adaptation works.", "description": "This table compares the performance of DoFIT with existing federated domain adaptation methods (FedGP and FedGP-g) on the Finance domain datasets.  It shows accuracy and F1 scores on four evaluation datasets (FPB, FiQA-SA, TFNS, NWGI), as well as average scores across the first three datasets and all four.  The results highlight DoFIT's superior performance in handling domain-aware data heterogeneity.", "section": "A.2 Comparison with Existing Federated Domain Adaptation Works"}, {"figure_path": "FDfrPugkGU/tables/tables_13_1.jpg", "caption": "Table 5: Performance on the gradient and singular value spectrum.", "description": "This table presents the performance results on different criteria for evaluating module importance in the LoRA model.  The criteria include using the gradient and singular value spectrum of LoRA modules.  The table shows the accuracy and F1 scores on four evaluation datasets (FPB, FiQA-SA, TFNS, NWGI) and their averages across three and all four datasets.  It compares the performance of DoFIT with several methods based on gradient or singular value for selecting top-k modules.", "section": "A.3 Performance on the Gradient and Singular Value Spectrum"}, {"figure_path": "FDfrPugkGU/tables/tables_14_1.jpg", "caption": "Table 6: Average accuracy on FPB, FiQA-SA, TFNS, NWGI", "description": "This table presents the average accuracy and F1 scores achieved on four different evaluation datasets (FPB, FiQA-SA, TFNS, NWGI) for various configurations of clients and number of selected clients per round in the Finance (F) and General (G) domains. It demonstrates how the performance of the DoFIT model varies based on different dataset sizes and how many clients are selected for collaboration in each round.", "section": "4.2 Performance Evaluation"}]