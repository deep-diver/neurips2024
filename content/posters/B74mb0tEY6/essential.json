{"importance": "This paper is crucial for researchers in online advertising and multi-armed bandits.  It introduces novel algorithms with **problem-dependent and problem-independent regret bounds**, offering practical solutions for maximizing coalition gain in online auctions while respecting privacy constraints. The work opens avenues for **further research in structured bandits and privacy-preserving mechanisms** within the online advertising domain.", "summary": "Two novel algorithms, Local-Greedy and Greedy-Grid, optimize coalition gain in online auctions with limited observations, achieving constant regret and problem-independent guarantees while respecting privacy.", "takeaways": ["Novel Local-Greedy and Greedy-Grid algorithms achieve constant regret in online repeated second-price auctions.", "The algorithms effectively handle limited observations and privacy constraints, maximizing coalition rewards.", "Greedy-Grid provides problem-independent regret guarantees, while Local-Greedy demonstrates superior practical performance."], "tldr": "Online display advertising faces the challenge of maximizing a coalition's gain in repeated second-price auctions under privacy constraints that limit the available information.  Existing bandit algorithms are not optimized for this structured setting and fail to effectively leverage the unique characteristics of the problem.  This leads to suboptimal solutions and inefficient use of advertising resources. \nThis paper tackles this problem by developing two novel algorithms: Local-Greedy and Greedy-Grid. These algorithms leverage the unimodality property of the expected reward function, resulting in **constant problem-dependent regret** (meaning the algorithm's performance is characterized by the problem's inherent difficulty).  Local-Greedy demonstrates **strong practical performance** while Greedy-Grid offers **problem-independent regret guarantees**, making it robust for a broader range of auction settings.  The findings are supported by both theoretical analysis and extensive experimental evaluation, showcasing the algorithms' effectiveness and practical advantages over traditional bandit approaches.", "affiliation": "Department of Statistics, University of Oxford", "categories": {"main_category": "AI Theory", "sub_category": "Optimization"}, "podcast_path": "B74mb0tEY6/podcast.wav"}