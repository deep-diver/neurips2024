[{"figure_path": "B74mb0tEY6/figures/figures_7_1.jpg", "caption": "Figure 3: An empirical illustration of Table 1 with simulations in the following setting: values are distributed according to B(0.05), N = 100 and p = 4. We benchmark LG and GG (this paper), OSUB [9], UCB [3] and EXP3 [4] in terms of R(T) computed over 20 trajectories. Error bars represent the first and last decile.", "description": "This figure empirically validates the theoretical regret bounds presented in Table 1.  It shows the cumulative regret R(T) over time T for different multi-armed bandit algorithms: Local Greedy (LG), Greedy Grid (GG), Upper Confidence Bound 1 (UCB1), Exponential-weight algorithm for exploration and exploitation (EXP3), and Optimistic Upper Confidence Bound for Unimodal bandits (OSUB). The experiment uses a Bernoulli distribution with parameter 0.05 to generate bidder values, a coalition size of N=100, and p=4 competitors. The plot displays the average regret over 20 independent simulations, with error bars showing the first and last deciles, illustrating the variability of the results.", "section": "Experimental Results"}, {"figure_path": "B74mb0tEY6/figures/figures_15_1.jpg", "caption": "Figure 1: Shape of r(n) when F is Beta", "description": "This figure shows the shape of the expected reward function r(n) for different parameters of the Beta distribution and the number of competing bidders (p).  The x-axis represents the number of bidders from the coalition (n), and the y-axis represents the expected reward r(n).  The different colored lines represent different Beta distributions and values for p.  The figure illustrates the unimodal nature of r(n) for the Beta distribution, which is a key assumption in the paper's theoretical analysis.", "section": "A.3 Additional discussion on the unimodality of r"}, {"figure_path": "B74mb0tEY6/figures/figures_15_2.jpg", "caption": "Figure 2: Shape of r(n) when F is Kumaraswamy distribution", "description": "This figure shows the shape of the expected reward function r(n) for different parameters of the Kumaraswamy distribution and p.  The Kumaraswamy distribution is defined by F(x) = 1 \u2212 (1 \u2212 x^a)^b for some parameters (a, b). The plot illustrates the unimodal shape of r(n) for different parameter settings, showcasing how the reward function changes with varying values of 'n' (number of bidders from the coalition) and 'p' (number of competing bidders).", "section": "A.3 Additional discussion on the unimodality of r"}, {"figure_path": "B74mb0tEY6/figures/figures_35_1.jpg", "caption": "Figure 3: An empirical illustration of Table 1 with simulations in the following setting: values are distributed according to B(0.05), N = 100 and p = 4. We benchmark LG and GG (this paper), OSUB [9], UCB [3] and EXP3 [4] in terms of R(T) computed over 20 trajectories. Error bars represent the first and last decile.", "description": "This figure empirically validates the theoretical regret bounds from Table 1.  It shows the expected regret R(T) over time horizon T for several multi-armed bandit algorithms: UCB1, Exp3, OSUB, Local Greedy (LG), and Greedy Grid (GG).  The simulation parameters are a Bernoulli distribution with parameter 0.05, coalition size N=100, and competitor size p=4. The shaded region represents the first and last deciles across 20 simulations, indicating variability.", "section": "Experimental Results"}, {"figure_path": "B74mb0tEY6/figures/figures_36_1.jpg", "caption": "Figure 4: Illustration of additional experiments. Details of parameters are provided in Table 2.", "description": "This figure shows the results of three different experimental settings with different parameters for the number of players, the number of competitors, and the distribution of player values.  The purpose is to illustrate the practical performance of the Local Greedy algorithm across various scenarios.  The figure compares the performance of Local Greedy to UCB1, Exp3, OSUB, and Greedy Grid algorithms, demonstrating that Local Greedy consistently outperforms these baselines, achieving a constant regret regime in each setting much faster than other methods. Table 2 provides the specific parameter values used in each of these three experimental settings.", "section": "D Experiments"}]