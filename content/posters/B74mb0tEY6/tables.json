[{"figure_path": "B74mb0tEY6/tables/tables_2_1.jpg", "caption": "Table 1: Comparison of regret guarantees for different algorithms", "description": "This table compares the upper bounds on the regret for various multi-armed bandit algorithms.  The algorithms include EXP3, UCB1, OSUB, and the novel Local-Greedy (LG) and Greedy-Grid (GG) algorithms proposed in this paper.  The regret upper bounds are expressed using Big O notation, highlighting the dependence on parameters such as the number of arms (N), the time horizon (T), and various gap parameters (\u0394, \u2206n, \u2206n*+1, \u2206n*-1) representing the differences in reward between arms.  The table shows that the proposed LG and GG algorithms achieve problem-dependent regret, in contrast to EXP3 and UCB1, while GG also provides problem-independent guarantees.", "section": "Outline and contributions"}, {"figure_path": "B74mb0tEY6/tables/tables_5_1.jpg", "caption": "Table 1: Comparison of regret guarantees for different algorithms", "description": "This table compares the regret upper bounds for various multi-armed bandit algorithms.  It shows the theoretical guarantees on the cumulative regret (R(T)) achieved by different algorithms, highlighting their dependencies on the number of arms (N), the time horizon (T), and problem-specific parameters such as the gaps between rewards of different arms (\u2206n, \u2206).  The algorithms compared include EXP3, UCB1, OSUB, and the two novel algorithms proposed in the paper: LG (Local Greedy) and GG (Greedy Grid).  The table provides a concise summary of the theoretical performance differences.", "section": "Outline and contributions"}, {"figure_path": "B74mb0tEY6/tables/tables_26_1.jpg", "caption": "Table 1: Comparison of regret guarantees for different algorithms", "description": "This table compares the upper bounds on regret for different multi-armed bandit algorithms.  The algorithms include EXP3, UCB1, OSUB, and the two novel algorithms presented in the paper, LG (Local Greedy) and GG (Greedy Grid). The regret bounds are expressed in Big O notation and show the dependence on various parameters like the number of arms (N), the time horizon (T), and problem-dependent gaps (\u0394). LG and GG achieve problem-dependent regret, which means their regret is constant regardless of the time horizon T.", "section": "Outline and contributions"}, {"figure_path": "B74mb0tEY6/tables/tables_34_1.jpg", "caption": "Table 1: Comparison of regret guarantees for different algorithms", "description": "This table compares the upper bounds on regret for different multi-armed bandit algorithms.  The algorithms include EXP3, UCB1, OSUB, Local-Greedy (LG), and Greedy-Grid (GG).  The regret upper bounds are expressed using Big O notation and show the dependence on various factors such as the number of auctions (T) and the number of arms (N), with problem-dependent and problem-independent guarantees shown for LG and GG.", "section": "Outline and contributions"}]