[{"figure_path": "aq3I5B6GLG/figures/figures_7_1.jpg", "caption": "Figure 1: Distributional SMs and associated predicted return distributions with the categorical (left) and EWP (right) representations. Simplex plots denote the distributional SM. Histograms denote the associated return distributions, predicted from a pair of held-out reward functions.", "description": "This figure compares the performance of categorical and EWP methods in approximating return distributions. The left side shows the results using categorical representation, while the right side displays the results with EWP representation. Both sides include simplex plots illustrating the distributional successor measure (DSM) and histograms representing predicted return distributions for two separate reward functions. This comparison helps to analyze the accuracy and efficiency of each method.", "section": "5.1 Simulation: The Distributional Successor Measure"}, {"figure_path": "aq3I5B6GLG/figures/figures_8_1.jpg", "caption": "Figure 2: Error of zero-shot return distribution predictions over random MDPs, measured by Cram\u00e9r distance, and showing 95% confidence intervals.", "description": "The figure shows the zero-shot return distribution prediction errors for two different dimensionality of cumulants (d=2 and d=3) using three different methods: EWP-TD, Categorical TD, and Signed-Cat-TD.  The x-axis represents the number of atoms used in the return distribution representation.  The y-axis represents the Cram\u00e9r distance, which is a measure of the difference between the predicted return distribution and the true distribution. The shaded area around each line represents the 95% confidence interval. This figure demonstrates the accuracy and efficiency of the proposed methods in approximating the true return distribution.", "section": "Simulations: Distributional Successor Features"}, {"figure_path": "aq3I5B6GLG/figures/figures_9_1.jpg", "caption": "Figure 1: Distributional SMs and associated predicted return distributions with the categorical (left) and EWP (right) representations. Simplex plots denote the distributional SM. Histograms denote the associated return distributions, predicted from a pair of held-out reward functions.", "description": "This figure compares the performance of two different methods, categorical and EWP, for approximating multivariate return distributions in a 3-state Markov Decision Process (MDP). The left panels show the results using a categorical representation of the distributional successor measure (DSM), while the right panels use an equally-weighted particle (EWP) representation.  Simplex plots visualize the learned DSM distributions, while histograms show the predicted scalar return distributions for two different reward functions not seen during training. This demonstrates the ability of the learned DSM to generate return distributions for unseen reward functions.", "section": "5.1 Simulation: The Distributional Successor Measure"}, {"figure_path": "aq3I5B6GLG/figures/figures_33_1.jpg", "caption": "Figure 1: Distributional SMs and associated predicted return distributions with the categorical (left) and EWP (right) representations. Simplex plots denote the distributional SM. Histograms denote the associated return distributions, predicted from a pair of held-out reward functions.", "description": "This figure visualizes the distributional successor measures (SMs) and predicted return distributions for both categorical and EWP representations.  Simplex plots represent the learned SMs. Histograms show return distributions predicted using two held-out reward functions. This comparison highlights the differences in the quality of approximation between the two methods for representing return distributions.", "section": "5.1 Simulation: The Distributional Successor Measure"}, {"figure_path": "aq3I5B6GLG/figures/figures_33_2.jpg", "caption": "Figure 5: Neural architecture for modeling multi-return distributions from images.", "description": "This figure shows the neural network architecture used for learning multivariate return distributions from image inputs in a continuous state space.  It depicts how convolutional neural networks (CNNs) process the image observations (xt and xt+1) to generate return distribution representations (\u03b7(xt) and \u03b7(xt+1)). The architecture incorporates the multivariate distributional Bellman operator and a projection onto the space of signed measures. The final step involves computing an \u21132 loss to train the model.", "section": "F Neural Multivariate Distributional TD-Learning"}, {"figure_path": "aq3I5B6GLG/figures/figures_34_1.jpg", "caption": "Figure 1: Distributional SMs and associated predicted return distributions with the categorical (left) and EWP (right) representations. Simplex plots denote the distributional SM. Histograms denote the associated return distributions, predicted from a pair of held-out reward functions.", "description": "This figure compares the performance of categorical and EWP representations in approximating return distributions.  The left side shows results from the categorical representation, while the right side shows those from the EWP (Equally Weighted Particles) representation. Simplex plots visualize the distributional successor measures (SMs), while histograms display the predicted return distributions generated using two distinct held-out reward functions. This allows a visual comparison of the accuracy and efficiency of both representation methods in approximating the return distribution.", "section": "5.1 Simulation: The Distributional Successor Measure"}]