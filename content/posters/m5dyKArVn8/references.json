{"references": [{"fullname_first_author": "Mikhail Belkin", "paper_title": "Reconciling modern machine-learning practice and the classical bias-variance trade-off", "publication_date": "2019-00-00", "reason": "This paper provides the theoretical foundation for understanding the relationship between model complexity and generalization, a crucial concept for analyzing the effectiveness of ensembling."}, {"fullname_first_author": "Christina Baek", "paper_title": "Agreement-on-the-line: Predicting the performance of neural networks under distribution shift", "publication_date": "2022-00-00", "reason": "This paper introduces a novel approach for assessing the generalization capabilities of neural networks, which is highly relevant to evaluating the performance of ensembles under various conditions."}, {"fullname_first_author": "Balaji Lakshminarayanan", "paper_title": "Simple and scalable predictive uncertainty estimation using deep ensembles", "publication_date": "2017-00-00", "reason": "This paper popularized deep ensembles as an effective method for improving model accuracy and robustness, which is the central focus of the current paper."}, {"fullname_first_author": "Andr\u00e9s Masegosa", "paper_title": "Second order PAC-Bayesian bounds for the weighted majority vote", "publication_date": "2020-00-00", "reason": "This paper develops tighter bounds for the error rate of majority voting, which is directly relevant to the theoretical analysis in the current paper."}, {"fullname_first_author": "Ryan Theisen", "paper_title": "When are ensembles really effective?", "publication_date": "2024-00-00", "reason": "This paper is the current work and provides the theoretical and empirical foundations for understanding the number of classifiers needed in an ensemble."}]}