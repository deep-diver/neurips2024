[{"figure_path": "cmSNX47aEH/tables/tables_5_1.jpg", "caption": "Table 1: DeiSAM handles deictic prompting. Mean Average Precision (mAP) of DeiSAM and neural baselines on DeiVG datasets are shown. Subscript numbers indicate the complexity of prompts.", "description": "This table presents the mean average precision (mAP) results for DeiSAM and several neural baseline models on the DeiVG dataset.  The DeiVG dataset is categorized into three subsets (DeiVG1, DeiVG2, DeiVG3) based on the complexity of the deictic prompts used. Higher mAP values indicate better performance in segmenting objects based on complex textual descriptions.  The table shows that DeiSAM significantly outperforms the baselines across all three subsets, demonstrating its improved ability to handle the challenging task of deictic promptable segmentation.", "section": "5 Experimental Evaluation"}, {"figure_path": "cmSNX47aEH/tables/tables_6_1.jpg", "caption": "Table 2: Ablations on prompting techniques for rule generation w/ Llama-2-13B-Chat. Few-shot examples are imperative for rule generation with chain-of-thought (CoT) prompting providing additional improvements for complex deictic prompts.", "description": "This table presents the ablation study results on different prompting techniques used for generating logic rules with the Llama-2-13B-Chat large language model.  It shows the overall success rate of rule generation on three different subsets of the DeiVG dataset (DeiVG1, DeiVG2, DeiVG3), each representing varying complexities of deictic prompts. The results demonstrate that using few-shot examples significantly improves the success rate, and incorporating chain-of-thought (CoT) prompting further enhances performance, especially for complex prompts.", "section": "5.4 Ablations"}, {"figure_path": "cmSNX47aEH/tables/tables_7_1.jpg", "caption": "Table 3: Comparison on RefCOCO+.", "description": "This table presents a comparison of the performance of three different methods (LISA, GroundedSAM, and DeiSAM) on the RefCOCO+ dataset.  The dataset is used to evaluate the models' ability to perform reference expression tasks in images. The table shows the mean average precision (mAP) for each method on the validation set and two test sets (testA and testB). DeiSAM achieves the highest mAP on all three sets.  The results highlight DeiSAM's superior performance in handling reference expression tasks, especially when compared to the purely neural baselines (GroundedSAM) and other existing neuro-symbolic methods (LISA).", "section": "5.5 Solving Reference Expression"}, {"figure_path": "cmSNX47aEH/tables/tables_7_2.jpg", "caption": "Table 4: Comparison on DeiRefCOCO+.", "description": "This table presents a comparison of the performance of different methods on the DeiRefCOCO+ dataset.  DeiRefCOCO+ is a modified version of the RefCOCO+ dataset where the descriptive phrases have been removed from the prompts, making them more abstract and challenging. The table shows the mean average precision (mAP) achieved by LISA, GroundedSAM, and DeiSAM on the validation set and test sets A and B.  The results highlight DeiSAM's superior performance compared to the other methods, particularly on the more challenging abstract prompts.", "section": "5.5 Solving Reference Expression"}, {"figure_path": "cmSNX47aEH/tables/tables_8_1.jpg", "caption": "Table 5: DeiSAM handles abstract visual reasoning. mAP on DeiCLEVR.", "description": "This table presents the mean Average Precision (mAP) for DeiSAM and baseline models (GroundedSAM and LISA) evaluated on the DeiCLEVR dataset.  DeiCLEVR is a dataset designed to evaluate the ability of models to perform abstract visual reasoning. The table shows the mAP for both the 'Delete' and 'Sort' tasks.  The results demonstrate DeiSAM's significantly higher performance compared to purely neural baselines on abstract reasoning tasks.", "section": "5.6 DeiCLEVR \u2013 Abstract Reasoning Segmentation"}, {"figure_path": "cmSNX47aEH/tables/tables_9_1.jpg", "caption": "Table 6: End-to-end training improves DeiSAM. Mean Average Precision on the test split of the task of learning SGGs. DeiSAM-VETO uses a trained VETO model (Sudhakaran et al., 2023), DeiSAM-Mixture (naive) uses a mixture of a trained VETO model and VG scene graphs with randomly initialized rule weights, DeiSAM-Mixture* uses the resulted mixture model after the weight learning.", "description": "This table shows the mean average precision (mAP) results for three different methods on the DeiVG1 and DeiVG2 datasets.  The methods are: DeiSAM-VETO (using a pre-trained VETO model), DeiSAM-Mixture (naive, using a mixture of pre-trained VETO and VG scene graphs with random weights), and DeiSAM-Mixture* (the same as naive, but after end-to-end weight learning). The results demonstrate that end-to-end training significantly improves the performance of DeiSAM.", "section": "5.7 End-to-End Training of DeiSAM"}, {"figure_path": "cmSNX47aEH/tables/tables_19_1.jpg", "caption": "Table 1: DeiSAM handles deictic prompting. Mean Average Precision (mAP) of DeiSAM and neural baselines on DeiVG datasets are shown. Subscript numbers indicate the complexity of prompts.", "description": "This table presents a comparison of the performance of DeiSAM and several neural baseline models on the DeiVG dataset.  The DeiVG dataset consists of images paired with complex, deictic (context-dependent) textual descriptions. The table shows the mean average precision (mAP) achieved by each model on three different subsets of the dataset (DeiVG1, DeiVG2, DeiVG3), which vary in the complexity of the deictic prompts.  Higher mAP indicates better performance.", "section": "5 Experimental Evaluation"}, {"figure_path": "cmSNX47aEH/tables/tables_21_1.jpg", "caption": "Table 1: DeiSAM handles deictic prompting. Mean Average Precision (mAP) of DeiSAM and neural baselines on DeiVG datasets are shown. Subscript numbers indicate the complexity of prompts.", "description": "This table presents a comparison of the performance of DeiSAM and several neural baseline models on the DeiVG dataset.  The mean average precision (mAP) is reported for each model on three subsets of the DeiVG dataset (DeiVG1, DeiVG2, DeiVG3), representing different levels of complexity in the deictic prompts.  The subscript numbers in the caption indicate the number of relations used in the prompt, reflecting the complexity of the scene description.  Higher mAP scores suggest better performance in segmenting objects based on complex deictic descriptions.", "section": "5 Experimental Evaluation"}, {"figure_path": "cmSNX47aEH/tables/tables_21_2.jpg", "caption": "Table 1: DeiSAM handles deictic prompting. Mean Average Precision (mAP) of DeiSAM and neural baselines on DeiVG datasets are shown. Subscript numbers indicate the complexity of prompts.", "description": "This table presents the performance comparison of DeiSAM and several neural baseline models on the DeiVG dataset for deictic prompting.  The performance metric used is mean average precision (mAP), which assesses how well the models can identify and segment objects based on complex textual descriptions.  The DeiVG dataset is categorized into three subsets (DeiVG1, DeiVG2, DeiVG3) based on the complexity of the prompts (number of relations involved), and the results are shown for each subset. The subscript numbers in the caption refer to this complexity level.  Higher mAP indicates better performance in segmenting objects according to the given deictic descriptions.", "section": "5 Experimental Evaluation"}, {"figure_path": "cmSNX47aEH/tables/tables_21_3.jpg", "caption": "Table 1: DeiSAM handles deictic prompting. Mean Average Precision (mAP) of DeiSAM and neural baselines on DeiVG datasets are shown. Subscript numbers indicate the complexity of prompts.", "description": "This table presents the performance comparison of DeiSAM and several neural baseline methods on the DeiVG dataset.  The mean average precision (mAP) is reported for each method across three subsets of the DeiVG dataset (DeiVG1, DeiVG2, DeiVG3), which represent different complexities of deictic prompts.  Higher mAP values indicate better performance in segmenting objects based on complex textual descriptions.", "section": "5 Experimental Evaluation"}, {"figure_path": "cmSNX47aEH/tables/tables_22_1.jpg", "caption": "Table 1: DeiSAM handles deictic prompting. Mean Average Precision (mAP) of DeiSAM and neural baselines on DeiVG datasets are shown. Subscript numbers indicate the complexity of prompts.", "description": "This table presents the performance comparison of DeiSAM against several neural baseline methods on the DeiVG dataset.  The mean average precision (mAP) is reported for each method across three subsets of the DeiVG dataset (DeiVG1, DeiVG2, DeiVG3), representing increasing complexity of deictic prompts.  The numbers in parentheses show the improvement (positive values) or decrease (negative values) in mAP compared to the baseline methods.", "section": "5 Experimental Evaluation"}]