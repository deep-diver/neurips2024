[{"figure_path": "YYJojVBCcd/tables/tables_26_1.jpg", "caption": "Table 2: We report the (test_accuracy, fairness_violation) for evaluating the performance on the CelebA dataset with two binary classification targets Young and Big Nose. We select gender as the sensitive attribute.", "description": "This table presents the results of experiments on the CelebA dataset, focusing on two binary classification tasks: predicting whether a person is young or has a big nose.  The results compare the performance of several methods (Base(ERM), Random, BALD, ISAL, JTT-20, and FIS) across different fairness metrics (DP, EOp, EOd) and error tolerances (\u03b5=0.05). Each method is evaluated based on its test accuracy and fairness violation. The table helps understand the effectiveness of different fairness-aware learning methods in improving model accuracy and fairness simultaneously, particularly when sensitive attributes like gender are involved.", "section": "6.2 Main results"}, {"figure_path": "YYJojVBCcd/tables/tables_26_2.jpg", "caption": "Table 3: The performance results of (test_accuracy, fairness_violation) on the Adult dataset. The sensitive attribute is age.", "description": "This table presents the performance results of different fairness-aware active learning methods on the Adult dataset, using age as the sensitive attribute.  For each method, it shows the average test accuracy and the fairness violation measured by three different metrics: Demographic Parity (DP), Equality of Opportunity (EOp), and Equalized Odds (EOd). The results are presented with their standard deviations, showing the performance variability.  The table allows for comparison of the accuracy and fairness trade-off achieved by each method.", "section": "6.2 Main results"}, {"figure_path": "YYJojVBCcd/tables/tables_26_3.jpg", "caption": "Table 4: The performance results of (test_accuracy, fairness_violation) on the Compas dataset. The selected sensitive attribute is race.", "description": "This table presents the results of experiments conducted on the Compas dataset using various fairness-aware methods.  The table shows the test accuracy and fairness violation (measured using demographic parity (DP), equalized odds (EOp), and equalized odds (EOd)) for each method.  The sensitive attribute considered is race.  The results are presented as means \u00b1 standard deviations across multiple trials to illustrate the variability and statistical significance of the results. This table helps in understanding and comparing the performance of different algorithms in achieving fairness without significantly compromising accuracy.", "section": "6 Empirical results"}, {"figure_path": "YYJojVBCcd/tables/tables_27_1.jpg", "caption": "Table 5: The performance results of (test_accuracy, fairness_violation) on the CelebA dataset when the validation set size is reduced to 1/2\u00d7 and 1/5\u00d7. Our algorithm retains the test accuracy and fairness violation when we vary the validation set size.", "description": "This table presents the test accuracy and fairness violation results for the CelebA dataset under different validation set sizes.  It shows the performance of the FIS algorithm (Fair Influential Sampling) when the validation set size is reduced to half (1/2x) and one-fifth (1/5x) of the original size. The results are compared across three different fairness metrics: Demographic Parity (DP), Equality of Opportunity (EOp), and Equalized Odds (EOd), for four different binary classification targets (Smiling, Attractive, Young, and Big Nose). The table demonstrates the robustness of FIS in maintaining accuracy and fairness even with smaller validation sets. ", "section": "E.4 The role of validation dataset size"}, {"figure_path": "YYJojVBCcd/tables/tables_28_1.jpg", "caption": "Table 6: We examine the performance results of (test_accuracy, fairness_violation) on the tabular datasets (Left: Adult; Right: Compas) when the validation set size is reduced to 1/2\u00d7, 1/4x, and 1/20\u00d7. We observe that our algorithm still retains the test accuracy and fairness violation when we vary the validation set size.", "description": "This table presents the results of test accuracy and fairness violation metrics (DP, EOp, EOd) on the Adult and Compas datasets when different sizes of the validation set are used.  The validation set size is reduced to 1/2, 1/4, and 1/20 of its original size. This ablation study shows the algorithm's robustness to changes in the validation set size.", "section": "E.4 The role of validation dataset size"}, {"figure_path": "YYJojVBCcd/tables/tables_28_2.jpg", "caption": "Table 6: We examine the performance results of (test_accuracy, fairness_violation) on the tabular datasets (Left: Adult; Right: Compas) when the validation set size is reduced to 1/2\u00d7, 1/4x, and 1/20\u00d7. We observe that our algorithm still retains the test accuracy and fairness violation when we vary the validation set size.", "description": "This table presents the results of experiments conducted to assess the impact of reducing the validation set size on the algorithm's performance. The experiments were performed using two tabular datasets (Adult and Compas) and evaluated using test accuracy and fairness violation metrics, with the validation set size reduced to 1/2x, 1/4x, and 1/20x of its original size. The results show that the algorithm's performance remains relatively stable even with significant reductions in the validation set size.", "section": "E.4 The role of validation dataset size"}]