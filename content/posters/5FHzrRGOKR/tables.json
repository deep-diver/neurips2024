[{"figure_path": "5FHzrRGOKR/tables/tables_6_1.jpg", "caption": "Table 1: Performance comparison of our model, which includes a Predictor and Counterfactual Generator (CF), across various settings: Local Centralised (Local CL), Centralised Learning (CL), Federated Learning (FL), and FL with only the Predictor in a non-IID setting.", "description": "This table compares the performance of a model with and without a counterfactual generator in four different settings: local centralized learning (each client trains a model independently), centralized learning (all data is available to a single model), federated learning (clients collaboratively train a model without sharing their data), and federated learning with only the predictor (no counterfactual generator).  The results show the accuracy, validity, sparsity, and proximity of the models in each setting across three datasets (Diabetes, Breast Cancer, Synthetic).  It evaluates the impact of adding a counterfactual generator on the model's performance in various settings.", "section": "5 Key Findings & Results"}, {"figure_path": "5FHzrRGOKR/tables/tables_19_1.jpg", "caption": "Table 2: Comparison of embedding sizes of the counterfactual generator", "description": "This table compares the performance of the counterfactual generator using different embedding sizes (128, 64, and 32). It shows the accuracy, validity, model parameters (Predictor+CF and CF alone), and GFLOPs (Predictor+CF and CF alone) for each embedding size.  The \"Increase\" column shows the percentage increase in model parameters and GFLOPs when using the counterfactual generator compared to using only the predictor.", "section": "5 Key Findings & Results"}, {"figure_path": "5FHzrRGOKR/tables/tables_21_1.jpg", "caption": "Table 1: Performance comparison of our model, which includes a Predictor and Counterfactual Generator (CF), across various settings: Local Centralised (Local CL), Centralised Learning (CL), Federated Learning (FL), and FL with only the Predictor in a non-IID setting.", "description": "This table presents a comparison of model performance metrics across four different settings: Local Centralised, Centralised Learning, Federated Learning with both predictor and counterfactual generator, and Federated Learning with only the predictor.  The results show that including a counterfactual generator does not significantly impact the predictive performance of the model in federated learning scenarios. The table also shows that the performance of the model in Federated Learning settings is comparable to that of the Centralised Learning scenario, highlighting the effectiveness of federated learning in protecting privacy without sacrificing accuracy.", "section": "5 Key Findings & Results"}, {"figure_path": "5FHzrRGOKR/tables/tables_25_1.jpg", "caption": "Table 4: Comparison of our FBSs across across five attacks types-No attack, Crafted-noise, Inverted-gradient, Label-flipping, Inverted-loss\u2014on Breast Cancer dataset for both IID and non-IID configurations", "description": "This table compares the performance of Federated Behavioral Shields (FBSs) under various attack scenarios (No attack, Crafted-noise, Inverted-gradient, Label-flipping, and Inverted-loss) for both IID and Non-IID data distributions on the Breast Cancer dataset.  It allows for assessing the robustness of FBSs in different data settings and against different types of attacks.", "section": "B.7 Federated Behavioural Shields on IID and non-IID scenarios"}, {"figure_path": "5FHzrRGOKR/tables/tables_27_1.jpg", "caption": "Table 5: Average accuracy (%) \u00b1 standard error for various defense strategies under five experimental conditions: No attack, Crafted-noise, Inverted-gradient, Label-flipping, and Inverted-loss. The table specifically compares the performance of our methods with and without the application of a moving average (MA).", "description": "This table presents a comparison of the accuracy achieved by different robust aggregation methods, including the proposed Federated Behavioural Shields (with and without moving average),  against five different attack scenarios on two datasets (Breast Cancer and Diabetes). The results highlight the impact of using the moving average technique on improving the robustness of the proposed method against attacks.", "section": "B.12 Ablation study"}, {"figure_path": "5FHzrRGOKR/tables/tables_28_1.jpg", "caption": "Table 1: Performance comparison of our model, which includes a Predictor and Counterfactual Generator (CF), across various settings: Local Centralised (Local CL), Centralised Learning (CL), Federated Learning (FL), and FL with only the Predictor in a non-IID setting.", "description": "This table compares the performance of a model with and without a counterfactual generator in four different settings: Local Centralised (each client trains a model on its local data), Centralised Learning (all data is centrally available), Federated Learning (clients collaboratively train a model without sharing their data), and Federated Learning with only the predictor.  The results show the accuracy, validity, sparsity, and proximity of the counterfactuals generated across the settings and demonstrate that including the counterfactual generator does not significantly impact performance and could be beneficial in non-IID settings (Federated Learning).", "section": "5 Key Findings & Results"}, {"figure_path": "5FHzrRGOKR/tables/tables_28_2.jpg", "caption": "Table 1: Performance comparison of our model, which includes a Predictor and Counterfactual Generator (CF), across various settings: Local Centralised (Local CL), Centralised Learning (CL), Federated Learning (FL), and FL with only the Predictor in a non-IID setting.", "description": "This table presents a comparison of the model's performance across four different settings: Local Centralised, Centralised Learning, Federated Learning, and Federated Learning with only the predictor.  It shows the accuracy, validity, sparsity, and proximity metrics for each setting and two model variations (with and without the counterfactual generator), using three different datasets (Diabetes, Breast Cancer, and Synthetic) under Non-IID conditions.  The results demonstrate the impact of incorporating counterfactual generators on the predictive performance of the models under various learning scenarios.", "section": "5 Key Findings & Results"}, {"figure_path": "5FHzrRGOKR/tables/tables_28_3.jpg", "caption": "Table 1: Performance comparison of our model, which includes a Predictor and Counterfactual Generator (CF), across various settings: Local Centralised (Local CL), Centralised Learning (CL), Federated Learning (FL), and FL with only the Predictor in a non-IID setting.", "description": "This table compares the performance of a model with and without a counterfactual generator in four different settings: Local Centralised, Centralised Learning, Federated Learning (with and without the generator).  The results show the accuracy, validity, sparsity, and proximity of the counterfactuals generated in each setting.  It aims to demonstrate that adding the counterfactual generator doesn't harm predictive performance and produces counterfactuals of similar quality in federated learning as in centralized scenarios.", "section": "5 Key Findings & Results"}, {"figure_path": "5FHzrRGOKR/tables/tables_29_1.jpg", "caption": "Table 1: Performance comparison of our model, which includes a Predictor and Counterfactual Generator (CF), across various settings: Local Centralised (Local CL), Centralised Learning (CL), Federated Learning (FL), and FL with only the Predictor in a non-IID setting.", "description": "This table compares the performance of a model with and without a counterfactual generator across four different settings: local centralized learning, centralized learning, federated learning, and federated learning with only a predictor. The comparison is done using three different datasets in a non-IID setting, where data is not evenly distributed across clients. The metrics used for comparison are accuracy, validity, sparsity, and proximity, providing a comprehensive evaluation of the model's performance in different scenarios.", "section": "5 Key Findings & Results"}]