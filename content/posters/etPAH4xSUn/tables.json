[{"figure_path": "etPAH4xSUn/tables/tables_6_1.jpg", "caption": "Table 3: Performance of CONTEXTSSL on invariant (length of stay (LOS) prediction) and equivariant (treatment prediction accuracy) tasks in the MIMIC III dataset.", "description": "This table presents the quantitative results of CONTEXTSSL on MIMIC-III dataset. It compares the performance of CONTEXTSSL with different context lengths (0 and 126) on two tasks: invariant LOS prediction and equivariant treatment prediction.  The results show the accuracy (Acc) for gender prediction, LOS prediction, and treatment prediction, along with fairness metrics for LOS prediction (equalized odds and equality of opportunity). This demonstrates CONTEXTSSL's ability to adapt to task-specific symmetries, showing improved performance on equivariant tasks with longer context lengths while maintaining or improving fairness on invariant tasks.", "section": "4.1 Quantitative Assessment of Adaptation to Task-Specific Symmetries"}, {"figure_path": "etPAH4xSUn/tables/tables_7_1.jpg", "caption": "Table 1: Quantitative evaluation of learned representations on invariant (classification) and equivariant (rotation prediction, color prediction) tasks; (Right) Performance of CONTEXTSSL on equivariant (top) rotation prediction; (bottom) color prediction tasks with varying context length for context corresponding to rotation and color. The algorithm increasingly demonstrates equivariance to rotation (color) as the rotation (color) context length increases while simultaneously becoming more invariant to color (rotation).", "description": "This table presents a quantitative evaluation of the learned representations using three different metrics: classification accuracy for invariant tasks, and R-squared values for rotation and color prediction in equivariant tasks. It compares the performance of CONTEXTSSL against other baselines (SimCLR, VICReg, EquiMOD, SIE, SEN) under different context lengths (0, 2, 14, 30, 126) and corresponding context types (rotation or color). The results demonstrate CONTEXTSSL's ability to adapt to specific symmetries by showing significant performance gains over existing methods on both invariant and equivariant tasks. For instance, as the context length increases, CONTEXTSSL demonstrates higher equivariance for the specified transformation while maintaining more invariance to the other.", "section": "4.1 Quantitative Assessment of Adaptation to Task-Specific Symmetries"}, {"figure_path": "etPAH4xSUn/tables/tables_8_1.jpg", "caption": "Table 2: Performance of CONTEXTSSL on invariant (classification) and equivariant (crop prediction, blur prediction) tasks in CIFAR-10 under the environment of crop, i.e., CONTEXTSSL (crop), and blur, i.e., CONTEXTSSL (blur).", "description": "This table presents a quantitative evaluation of CONTEXTSSL's performance on CIFAR-10, comparing its results against SimCLR and its variations. The results are categorized into invariant (classification accuracy) and equivariant (crop and blur prediction R-squared values) tasks.  The experiment is conducted under two scenarios: one where CONTEXTSSL adapts to symmetries specific to crop transformations, and another where it adapts to those specific to blur transformations.  This table demonstrates CONTEXTSSL's ability to learn context-specific symmetries and achieve competitive results across both invariant and equivariant tasks.", "section": "4.4 Expanding to Diverse Data Transformations"}, {"figure_path": "etPAH4xSUn/tables/tables_9_1.jpg", "caption": "Table 3: Performance of CONTEXTSSL on invariant (length of stay (LOS) prediction) and equivariant (treatment prediction accuracy) tasks in the MIMIC III dataset.", "description": "This table presents the performance of the CONTEXTSSL model on MIMIC-III dataset for Length of Stay (LOS) prediction (invariant task) and treatment prediction (equivariant task), considering the context length of 0 and 126, and whether the model is trained to be equivariant or invariant to gender. The metrics used are Gender prediction accuracy, LOS prediction accuracy, Equalized odds, Equality of opportunity, and Treatment prediction accuracy.  The results show how CONTEXTSSL adapts its performance based on the context and the desired task symmetry (invariance or equivariance to gender).", "section": "4.5 Context World Models for Naturally-Occurring Symmetries"}, {"figure_path": "etPAH4xSUn/tables/tables_9_2.jpg", "caption": "Table 4: Performance of CONTEXTSSL on equivariant tasks (including classificaion) for context-dependent labels. CONTEXTSSL adapts to context-dependent labels with varying context.", "description": "This table presents the quantitative results of CONTEXTSSL and several baseline methods on 3DIEBench dataset when the labels are context-dependent, meaning the labels are influenced by the context (i.e., rotation or color transformations).  The table shows the performance (R^2) of rotation and color prediction tasks and the top-1 classification accuracy for different context lengths (0, 2, 14, 30, 126). The results demonstrate CONTEXTSSL's ability to adapt its symmetry (equivariance or invariance) to the specific context, showcasing superior performance over baseline methods.", "section": "4.1 Quantitative Assessment of Adaptation to Task-Specific Symmetries"}, {"figure_path": "etPAH4xSUn/tables/tables_17_1.jpg", "caption": "Table 5: Quantitative evaluation of learned representations on equivariant (rotation prediction, color prediction) tasks to predict individual latent values.", "description": "This table presents a quantitative evaluation of learned representations on equivariant tasks (rotation and color prediction). Unlike Table 3 and Table 4 which predict relative latent values between pairs of image embeddings, this table focuses on predicting individual latent values for more precise analysis of the model's performance in rotation and color prediction tasks.  It compares several methods, including invariant and equivariant approaches, across different context lengths, showing how the performance changes with varying context.", "section": "4.1 Quantitative Assessment of Adaptation to Task-Specific Symmetries"}, {"figure_path": "etPAH4xSUn/tables/tables_17_2.jpg", "caption": "Table 6: Performance of CONTEXTSSL in 3DIEBench in rotation prediction under the environment of rotation, i.e. CONTEXTSSL (rotation), and color, i.e. CONTEXTSSL (color), with standard deviations over three random seeds.", "description": "This table shows the performance of CONTEXTSSL on rotation prediction in the 3DIEBench benchmark.  The model is evaluated under two different conditions: when the context is focused on rotation, and when the context is focused on color. The results are given for different context lengths (0, 2, 14, 30, 126).  Standard deviations are included to show variability across three random seed runs.", "section": "C.1.1 Invariant Classification and Equivariant transformation prediction task"}, {"figure_path": "etPAH4xSUn/tables/tables_18_1.jpg", "caption": "Table 7: Performance of CONTEXTSSL in 3DIEBench in color prediction under the environment of rotation, i.e. CONTEXTSSL (rotation), and color, i.e. CONTEXTSSL (color), with standard deviations over three random seeds.", "description": "This table presents the results of color prediction (R^2) using CONTEXTSSL under two different conditions: one where the model is trained to be equivariant to rotation and another where it's trained to be equivariant to color.  The results are shown for different context lengths (0, 2, 14, 30, and 126). Standard deviations are included to represent the variability across three independent runs.  It shows the model's ability to adapt its equivariance/invariance properties to color or rotation depending on the context.", "section": "4.1 Quantitative Assessment of Adaptation to Task-Specific Symmetries"}, {"figure_path": "etPAH4xSUn/tables/tables_18_2.jpg", "caption": "Table 1: Quantitative evaluation of learned representations on invariant (classification) and equivariant (rotation prediction, color prediction) tasks; (Right) Performance of CONTEXTSSL on equivariant (top) rotation prediction; (bottom) color prediction tasks with varying context length for context corresponding to rotation and color. The algorithm increasingly demonstrates equivariance to rotation (color) as the rotation (color) context length increases while simultaneously becoming more invariant to color (rotation).", "description": "This table presents a quantitative evaluation of the learned representations by comparing CONTEXTSSL with other invariant and equivariant self-supervised learning approaches. The evaluation is performed on both invariant (classification) and equivariant (rotation and color prediction) tasks. The results show CONTEXTSSL's ability to adapt to task-specific symmetries by paying attention to context, achieving significant performance gains over existing methods. The table also includes results showing the effect of varying context lengths on CONTEXTSSL's performance.", "section": "4.1 Quantitative Assessment of Adaptation to Task-Specific Symmetries"}, {"figure_path": "etPAH4xSUn/tables/tables_19_1.jpg", "caption": "Table 9: Performance of CONTEXTSSL rotation prediction tasks in 3DIEBench under different random masking probabilities, with standard deviations over three random seeds.", "description": "This table presents a quantitative evaluation of the CONTEXTSSL model's performance on rotation prediction tasks within the 3DIEBench benchmark.  It shows how the model's performance (R\u00b2) varies with different context lengths (0, 2, 14, 30, 126) under various random masking probabilities (0.00, 0.20, 0.50, 0.75, 0.90, 0.98).  The results are averaged over three random seeds, and standard deviations are included to show the variability of the results.  The table is separated into two sections: 'Rotation' context and 'Color' context, indicating the type of context used during the experiment.", "section": "C.2 Role of Context Mask"}, {"figure_path": "etPAH4xSUn/tables/tables_19_2.jpg", "caption": "Table 9: Performance of CONTEXTSSL rotation prediction tasks in 3DIEBench under different random masking probabilities, with standard deviations over three random seeds.", "description": "This table presents the results of rotation prediction tasks using the CONTEXTSSL model on the 3DIEBench dataset. The experiments were conducted under various random masking probabilities (0.00, 0.20, 0.50, 0.75, 0.90, 0.98).  The table shows the performance (R\u00b2) of the model for different context lengths (0, 2, 14, 30, 126) for both rotation and color contexts. Standard deviations across three random seeds are included to show variability in the results.", "section": "C.2 Role of Context Mask and Auxiliary Predictor"}, {"figure_path": "etPAH4xSUn/tables/tables_19_3.jpg", "caption": "Table 5: Quantitative evaluation of learned representations on equivariant (rotation prediction, color prediction) tasks to predict individual latent values.", "description": "This table presents a quantitative evaluation of learned representations focusing on equivariant tasks (rotation and color prediction).  Unlike Table 3, which predicts relative latent values between image pairs, this table assesses the performance on predicting individual latent values. It compares several methods (SimCLR, VICReg, EquiMOD, SIE, SEN, and CONTEXTSSL) across different context lengths (0, 2, 14, 30, 126) for both rotation and color prediction tasks.  The R\u00b2 metric is used to evaluate the performance of each method in predicting the latent values for rotation and color, highlighting the impact of the context length on the model's ability to learn equivariant representations.", "section": "4.1 Quantitative Assessment of Adaptation to Task-Specific Symmetries"}, {"figure_path": "etPAH4xSUn/tables/tables_21_1.jpg", "caption": "Table 12: CIFAR-10 Color-Blur. Performance of CONTEXTSSL on invariant (classification) and equivariant (color prediction, blur prediction) tasks in CIFAR-10 under the environment of color, i.e. CONTEXTSSL (color), and blur, i.e. CONTEXTSSL (blur).", "description": "This table presents the quantitative results of CONTEXTSSL and several baselines on CIFAR-10 dataset, where color and blur are used as transformations. It compares the performance on invariant classification and equivariant color/blur prediction tasks under two different contexts: one where the model is trained to be equivariant to color and invariant to blur, and another where it is trained to be equivariant to blur and invariant to color.  The performance metrics include R-squared (R2) for equivariant tasks and top-1 classification accuracy for the invariant task. The results show how CONTEXTSSL adaptively learns to be equivariant/invariant to specific transformations based on context.", "section": "4.4 Expanding to Diverse Data Transformations"}, {"figure_path": "etPAH4xSUn/tables/tables_22_1.jpg", "caption": "Table 2: Performance of CONTEXTSSL on invariant (classification) and equivariant (crop prediction, blur prediction) tasks in CIFAR-10 under the environment of crop, i.e. CONTEXTSSL (crop), and blur, i.e. CONTEXTSSL (blur).", "description": "This table presents a quantitative evaluation of the CONTEXTSSL model's performance on CIFAR-10 dataset.  It compares CONTEXTSSL's performance to SimCLR, a baseline invariant self-supervised learning method. The evaluation focuses on classification accuracy and the equivariance of the model's representations regarding two augmentations: cropping and blurring. The table shows how the model's performance changes based on the context provided (crop or blur) and context length.  The results highlight CONTEXTSSL's ability to adapt its symmetry (invariance or equivariance) based on the contextual information provided.", "section": "4.4 Expanding to Diverse Data Transformations"}, {"figure_path": "etPAH4xSUn/tables/tables_22_2.jpg", "caption": "Table 2: Performance of CONTEXTSSL on invariant (classification) and equivariant (crop prediction, blur prediction) tasks in CIFAR-10 under the environment of crop, i.e. CONTEXTSSL (crop), and blur, i.e. CONTEXTSSL (blur).", "description": "This table shows the performance of the CONTEXTSSL model and several baseline models on CIFAR-10 image classification and equivariant prediction tasks (crop and blur). The results are broken down by whether the model is trained with a context focused on crop or blur, demonstrating the model's ability to adapt to different task-specific symmetries.", "section": "4.4 Expanding to Diverse Data Transformations"}, {"figure_path": "etPAH4xSUn/tables/tables_22_3.jpg", "caption": "Table 15: CIFAR-10 Color-Blur. Performance of CONTEXTSSL on equivariant (color prediction, blur prediction) tasks in CIFAR-10 under the environment of color, i.e. CONTEXTSSL (color), and blur, i.e. CONTEXTSSL (blur), to predict individual latent values.", "description": "This table presents quantitative results evaluating the performance of CONTEXTSSL and baseline methods on CIFAR-10 dataset for color and blur prediction tasks.  The results are broken down by the context length used during training, showing how performance changes as the model receives more contextual information.  It specifically focuses on evaluating the model's ability to learn equivariance or invariance to color or blur transformations, depending on which transformation is emphasized in the training context.", "section": "4.4 Expanding to Diverse Data Transformations"}, {"figure_path": "etPAH4xSUn/tables/tables_22_4.jpg", "caption": "Table 16: CIFAR-10 Crop-Blur. Performance of CONTEXTSSL on equivariant (crop prediction, color prediction) tasks in CIFAR-10 under the environment of crop, i.e., CONTEXTSSL (crop), and color, i.e., CONTEXTSSL (color), to predict individual latent values.", "description": "This table presents the performance of the CONTEXTSSL model and several baselines on CIFAR-10 data, focusing on equivariant tasks (crop and color prediction).  It shows the R-squared values for crop and color prediction at different context lengths (0, 2, 14, 30, 126), comparing the performance of CONTEXTSSL when the context is specifically geared towards either crop or color transformations.  The results illustrate CONTEXTSSL's adaptability to different contexts in learning both invariance and equivariance.", "section": "4.4 Expanding to Diverse Data Transformations"}, {"figure_path": "etPAH4xSUn/tables/tables_23_1.jpg", "caption": "Table 3: Performance of CONTEXTSSL on invariant (length of stay (LOS) prediction) and equivariant (treatment prediction accuracy) tasks in the MIMIC III dataset.", "description": "This table presents the results of CONTEXTSSL on MIMIC-III dataset, evaluating both invariant (LOS prediction) and equivariant (treatment prediction) tasks.  It demonstrates the performance of CONTEXTSSL under different context lengths (0 and 126), comparing equivariant and invariant settings.  The metrics used include prediction accuracy for LOS and treatment, along with equalized odds and equality of opportunity to assess fairness.", "section": "4.5 Context World Models for Naturally-Occurring Symmetries"}, {"figure_path": "etPAH4xSUn/tables/tables_23_2.jpg", "caption": "Table 5: Quantitative evaluation of learned representations on equivariant (rotation prediction, color prediction) tasks to predict individual latent values.", "description": "This table presents a quantitative comparison of different self-supervised learning methods on their ability to predict individual latent values for rotation and color transformations. It compares the performance of invariant methods (SimCLR and VICReg) and equivariant methods (EquiMOD, SIE, SEN) with CONTEXTSSL.  The results are broken down by context length (0, 2, 14, 30, 126), showing how the performance of each model changes as more contextual information becomes available.", "section": "4.1 Quantitative Assessment of Adaptation to Task-Specific Symmetries"}, {"figure_path": "etPAH4xSUn/tables/tables_23_3.jpg", "caption": "Table 19: Model performance in rotation prediction task, within the rotation-equivariant environment. The R2 values are calculated for both the representations and the embeddings (output of projection head for invariant models (VICReg, SimCLR) or predictor for equivariant models (SEN, EquiMod, SIE, CONTEXTSSL). Unlike other models, which experience a significant performance drop between representations and embeddings, CONTEXTSSL maintains consistent performance.", "description": "This table compares the performance of several self-supervised learning methods on a rotation prediction task, using either the learned representations directly or the embeddings from a projection head or predictor.  The key finding is that CONTEXTSSL shows consistent performance regardless of whether representations or embeddings are used, unlike other methods which show significant performance drops when using embeddings.", "section": "C.7 Performance on Encoder Representations and Predictor Embedding"}, {"figure_path": "etPAH4xSUn/tables/tables_24_1.jpg", "caption": "Table 2: Performance of CONTEXTSSL on invariant (classification) and equivariant (crop prediction, blur prediction) tasks in CIFAR-10 under the environment of crop, i.e. CONTEXTSSL (crop), and blur, i.e. CONTEXTSSL (blur).", "description": "This table shows the performance of the CONTEXTSSL model and several baseline models on CIFAR-10 image data.  The experiment uses crop and blur as transformations.  The table presents results for three different tasks: classification accuracy (invariant), crop prediction accuracy (equivariant), and blur prediction accuracy (equivariant). Results are shown for CONTEXTSSL under two conditions: when the context focuses on crop transformations and when it focuses on blur transformations. This allows us to examine the model's ability to adapt its symmetries (invariance/equivariance) based on contextual information. Baseline models are also included for comparison.", "section": "4.4 Expanding to Diverse Data Transformations"}, {"figure_path": "etPAH4xSUn/tables/tables_24_2.jpg", "caption": "Table 1: Quantitative evaluation of learned representations on invariant (classification) and equivariant (rotation prediction, color prediction) tasks; (Right) Performance of CONTEXTSSL on equivariant (top) rotation prediction; (bottom) color prediction tasks with varying context length for context corresponding to rotation and color. The algorithm increasingly demonstrates equivariance to rotation (color) as the rotation (color) context length increases while simultaneously becoming more invariant to color (rotation).", "description": "This table presents a quantitative evaluation of learned representations using different methods on invariant and equivariant tasks.  It compares the performance of CONTEXTSSL against several baselines (SimCLR, VICReg, EquiMOD, SIE, SEN) across varying context lengths (0, 2, 14, 30, and 126). The results show how CONTEXTSSL dynamically adapts to either enforce invariance or equivariance to specific transformations based on the provided context. Invariant tasks refer to image classification, while equivariant tasks measure the model's ability to predict rotations or color transformations.", "section": "4.1 Quantitative Assessment of Adaptation to Task-Specific Symmetries"}, {"figure_path": "etPAH4xSUn/tables/tables_24_3.jpg", "caption": "Table 21: Single Transformation Setting. Performance of CONTEXTSSL in 3DIEBench under the equivariant environment, i.e., CONTEXTSSL (rotation), and the invariant environment, i.e., CONTEXTSSL (none), with respect to rotation.", "description": "This table presents the results of CONTEXTSSL and baseline methods on the 3DIEBench dataset. It shows the performance on rotation prediction (R^2) and classification (top-1 accuracy) in two scenarios:\n\n1.  **Equivariant environment:** CONTEXTSSL is trained to learn equivariance to rotation transformations.\n2.  **Invariant environment:** CONTEXTSSL is trained to learn invariance to rotation transformations.\n\nThe results are shown for different context lengths (0, 2, 14, 30, and 126), demonstrating how the model's performance changes based on the level of context provided.", "section": "4.1 Quantitative Assessment of Adaptation to Task-Specific Symmetries"}]