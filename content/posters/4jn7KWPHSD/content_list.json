[{"type": "text", "text": "Improving Robustness of 3D Point Cloud Recognition from a Fourier Perspective ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Yibo Miao1,2, Yinpeng Dong3,6\u2020, Jinlai Zhang4, Lijia $\\mathbf{Y}\\mathbf{u}^{5}$ , Xiao Yang3, Xiao-Shan Gao1,2\u2020 ", "page_idx": 0}, {"type": "text", "text": "1 KLMM, Academy of Mathematics and Systems Science, Chinese Academy of Sciences, Beijing 100190, China 2 University of Chinese Academy of Sciences, Beijing 100049, China 3 Tsinghua University, Beijing 100084, China 4 Changsha University of Science and Technology, Changsha 410114, China 5 Institute of Software, Chinese Academy of Sciences, Beijing 100190, China 6 RealAI miaoyibo@amss.ac.cn, dongyinpeng@tsinghua.edu.cn, xgao@mmrc.iss.ac.cn ", "page_idx": 0}, {"type": "text", "text": "Abstract ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Although 3D point cloud recognition has achieved substantial progress on standard benchmarks, the typical models are vulnerable to point cloud corruptions, leading to security threats in real-world applications. To improve the corruption robustness, various data augmentation methods have been studied, but they are mainly limited to the spatial domain. As the point cloud has low information density and significant spatial redundancy, it is challenging to analyze the effects of corruptions. In this paper, we focus on the frequency domain to observe the underlying structure of point clouds and their corruptions. Through graph Fourier transform (GFT), we observe a correlation between the corruption robustness of point cloud recognition models and their sensitivity to different frequency bands, which is measured by the GFT spectrum of the model\u2019s Jacobian matrix. To reduce the sensitivity and improve the corruption robustness, we propose Frequency Adversarial Training (FAT) that adopts frequency-domain adversarial examples as data augmentation to train robust point cloud recognition models against corruptions. Theoretically, we provide a guarantee of FAT on its out-of-distribution generalization performance. Empirically, we conducted extensive experiments with various network architectures to validate the effectiveness of FAT, which achieves the new state-of-the-art results. ", "page_idx": 0}, {"type": "text", "text": "1 Introduction ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "3D point cloud recognition based on deep neural networks (DNNs) [35, 36, 65] has achieved unprecedented performance on typical benchmarks [5, 67], which assume that the data are independently and identically distributed. However, in practical scenarios, point clouds suffer from severe corruptions (e.g., noise, density change, transformation) due to sensor imprecision and scene complexity [66, 76]. When the testing distribution is different from the training distribution caused by corruption, point cloud recognition models have significant performance degradation [41, 51], indicating that they lack the robustness of human visual system [40], while also raising concerns about safety and reliability of these models. As deep 3D point cloud recognition has been increasingly deployed in safety-critical applications, such as autonomous driving [6, 84], robotics [60, 92], and medical image processing [54], it is of crucial importance to improve the robustness of 3D point cloud recognition models to out-of-distribution (OOD) point cloud data induced by corruptions [10]. ", "page_idx": 0}, {"type": "image", "img_path": "4jn7KWPHSD/tmp/90ef597dad796b8fc4becac9594b9256b833625b381be97fcb8f6be2446139ab.jpg", "img_caption": ["Figure 1: (a): The graph frequency-domain representations of \u201cJitter\u201d and \u201cRotate\u201d in ModelNet-C [41]. \u201cJitter\u201d has higher power in the high-frequency region, while \u201cRotate\u201d has higher power in the low-frequency region. (b): The relationship between the corruption robustness (measured by mean overall accuracy (mOA) [41]) of various models and the sensitivity to high/low frequency bands. Our proposed high/low frequency sensitivity metric is negatively correlated with the model\u2019s robustness under high/low frequency corruptions. "], "img_footnote": [], "page_idx": 1}, {"type": "text", "text": "To improve the corruption robustness, the most effective approaches to date are based on carefully designed data augmentation techniques [41, 51]. Inspired by 2D image augmentations [85, 89], some methods blend two point clouds for data augmentation using shortest-path interpolation (e.g., PointMixup [7]), random blending (e.g., PointCutMix-R [90]), and rigid transformation (e.g., RSMix [24], PointCutMix-K [90]). PointWOLF [22] enriches data diversity by applying non-rigid deformation to object parts. WOLFMix [41] deforms objects first and then rigidly blends two deformed objects. Although these data augmentation techniques improve the corruption robustness to some extent, they are all based on spatial-domain transformations. Raw point clouds in the spatial domain have low information density and heavy spatial redundancy [8], making it challenging to analyze which specific information is corrupted. To address this challenge, we shift our attention from the spatial domain to the frequency domain to analyze the underlying structure of point clouds that is not easily observable from the raw point clouds. In the frequency domain, point clouds are compactly represented, facilitating a better understanding of low-level distortions that are free of high-level semantics. ", "page_idx": 1}, {"type": "text", "text": "To design robust models, the first step is to understand how corruption is represented in the frequency domain. We achieve this by transforming the raw point clouds and the corresponding corruptions into compact representations in the frequency domain using the graph Fourier transform (GFT) [43]. By visualizing the transformed signals, we observe that different corruptions affect varying frequency bands, as shown in Fig. 1(a). Motivated by the differences, we investigate the relationship between the corruption robustness of various point cloud recognition models and their sensitivity to different frequency bands [81]. To measure the sensitivity, we design a novel metric based on GFT spectrum of the Jacobian matrix of the model, as shown in Fig. 3. Our key insight is that our proposed high/low frequency sensitivity metric is negatively correlated with the model\u2019s robustness under high/low frequency corruptions, as shown in Fig. 1(b). This correlation emphasizes the importance of the model\u2019s sensitivity to high and low frequencies for corruption robustness. However, it is still challenging to simultaneously reduce the sensitivity of point cloud recognition models to both high and low frequencies. ", "page_idx": 1}, {"type": "text", "text": "To address this issue, we propose Frequency Adversarial Training (FAT) to improve the corruption robustness of 3D point cloud recognition models. FAT trains a model with adversarial examples that add perturbations to the frequency-domain representations of point clouds. Intuitively, a model robust to worst-case perturbations should be more resistant to real-world corruptions [72, 80]. We provide a theoretical analysis that demonstrates the effectiveness of FAT in ensuring OOD generalization of the model, as shown in Theorem 1. To eliminate potential performance degradation due to mutual interference between high and low frequency signals, we utilize the AdvProp training framework [72], based on which we use three separate batch normalization (BN) statistics for clean samples, highfrequency adversarial samples, and low-frequency adversarial samples, respectively. ", "page_idx": 1}, {"type": "text", "text": "We conducted extensive experiments to validate the effectiveness of our approach in improving the robustness of point cloud recognition models under common corruptions [41, 51]. With various network architectures, our method improves the corruption robustness by a large margin. By integrating our approach with previous data augmentation techniques, we achieve the new state-of-the-art performance. ", "page_idx": 1}, {"type": "text", "text": "", "page_idx": 2}, {"type": "text", "text": "2 Related work ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "Deep learning on 3D point clouds. Deep 3D point cloud recognition [16, 35, 38, 55, 70, 73, 79] has emerged in recent years as a prominent research area with diverse applications in several fields such as 3D object classification [46, 83, 86], 3D scene segmentation [20, 64, 75], and 3D object detection in autonomous driving [77, 95]. One of the pioneering works is PointNet [35], which employs a multilayer perceptron to learn point features and utilizes a max-pool module to aggregate them efficiently. Many subsequent works [13, 30, 36, 78] improve upon PointNet. Several approaches focus on designing special convolutions on 3D domains [26, 31, 56] or developing graph neural networks [14, 44, 65] to improve point cloud recognition, such as DGCNN [65] which builds a dynamic graph for point cloud data. Recently, drawing inspiration from research in the frequency domain [4, 49, 61, 81], GDANet [74] introduces a geometry-disentangle module to dynamically separate point clouds into the contour and flat parts of 3D objects, thereby capturing complementary 3D geometric semantics. PCT [17] uses Transformer to improve point cloud learning. Additionally, there is a growing discussion on point cloud augmentation, including mix-based augmentations [7, 90], deformation-based augmentations [22], and auto-augmentations [25]. ", "page_idx": 2}, {"type": "text", "text": "Robustness in 3D point cloud recognition. Following the previous studies on robustness in the 2D image domain [53, 3, 15, 19, 32, 42, 59, 9, 82], several works [18, 50, 52, 63, 69, 34, 97] have explored the robustness of 3D point cloud classifiers. Concerning adversarial robustness, Xiang et al. [69] first demonstrate that point cloud recognition is vulnerable to adversarial point generation attacks. Further research [21, 28, 29, 57, 91, 2] has employed gradient-based point perturbation attacks. Some defensive techniques are proposed, such as input randomization [12, 93] and geometryaware framework [68] to defend against such vulnerabilities. Sun et al. [47, 48] have studied the effectiveness of adversarial training and pre-training on self-supervised tasks in enhancing robustness. In terms of corruption robustness, some works have studied the problem using invariant feature extraction [71], and adaptive sampling [76]. Recently, two benchmarks [41, 51] are developed for the robustness of 3D point cloud recognition under corruptions and demonstrate the effectiveness of data augmentation. However, unlike the existing spatial-domain data augmentation techniques [22, 25], in this paper, we focus on the frequency domain and propose Frequency Adversarial Training (FAT) to improve the model\u2019s out-of-distribution generalization ability. ", "page_idx": 2}, {"type": "text", "text": "3 Methodology ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "The existing 3D point cloud recognition models exhibit significant performance degradation under point cloud corruptions [41, 51]. Although data augmentation techniques have shown the effectiveness in improving robustness, they are typically based on spatial-domain transformations, which suffer from low information density and heavy spatial redundancy of the raw point clouds. Consequently, it is difficult to analyze which specific information has been lost due to corruptions within the spatial domain. To address this challenge, we shift our focus to the frequency domain, which enables us to analyze the underlying structure of point clouds. ", "page_idx": 2}, {"type": "text", "text": "In the following, we first provide the background knowledge of graph Fourier transform (GFT) in Sec. 3.1, then analyze the point cloud corruptions in the frequency domain in Sec. 3.2, and investigate the relationship between the model\u2019s corruption robustness and sensitivity to frequency changes in Sec. 3.3. Based on the analyses, we propose a Frequency Adversarial Training (FAT) method detailed in Sec. 3.4 with a theoretical analysis to guarantee its effectiveness in Sec. 3.5. ", "page_idx": 2}, {"type": "text", "text": "3.1 Graph Fourier transform ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "Images are typically transformed and recovered in the frequency domain with the 2D discrete Fourier transform (DFT) and inverse DFT [39]. Unlike images, although 3D point clouds are highly structured, they reside on irregular domains without an ordering of points, hindering the deployment of traditional Fourier transforms. However, graphs provide a natural and accurate representation of irregular point clouds. Once a graph is constructed to represent the point cloud, the graph Fourier transform (GFT) [43] can compactly transform it into the frequency domain. ", "page_idx": 2}, {"type": "image", "img_path": "4jn7KWPHSD/tmp/97cabcca127feeaa40765588b61f5518a404718e3e27cf1d07c367c93a8917ac.jpg", "img_caption": ["Figure 2: The leftmost image displays the graph frequency-domain representation of the raw point clouds. To estimate the expected value of $\\mathbb{E}_{\\mathcal{P}}[|\\dot{G}\\mathcal{F}(\\mathcal{P})|]$ , we average over all validation point clouds in ModelNet40 [67]. The frequencies are arranged from left to right in ascending order. The other seven images display the graph frequency-domain representations of each corruption in ModelNet-C [41]. The raw point clouds exhibit higher power in the low-frequency region. The corruption \u201cJitter\u201d has much higher power in the high-frequency region. The power of corruptions such as \u201cRotate\u201d and \u201cScale\u201d is concentrated on the low-frequency components. "], "img_footnote": [], "page_idx": 3}, {"type": "text", "text": "", "page_idx": 3}, {"type": "text", "text": "Given a point cloud $\\mathcal{P}:=\\left\\{p_{i}\\right\\}_{i=1}^{n}\\in\\mathbb{R}^{n\\times3}$ of $n$ points, where $\\textstyle p_{i}$ denotes the xyz coordinates of a point, we construct a directed graph $\\mathcal{G}=\\{\\mathcal{P},\\mathcal{E},\\bar{W}\\}$ to represent it. The graph consists of a vertex set $\\mathcal{P}$ , an edge set $\\mathcal{E}$ connecting the vertices, and an adjacency matrix $W$ . The entry $w_{i,j}$ in the adjacency matrix represents the weight of the edge from vertices $i$ to $j$ , which is used to capture the similarity between adjacent vertices. Here, we construct a weighted $k$ -nearest neighbor graph (i.e., each vertex is only connected to its $k$ -nearest neighbors) using the Euclidean distance $d_{i j}=\\|\\bar{\\boldsymbol{p}}_{i}-\\boldsymbol{p}_{j}\\|_{2}$ between vertices $i$ and $j$ , and the weight of the edge is $w_{i,j}=e^{-d_{i j}^{2}}$ . ", "page_idx": 3}, {"type": "text", "text": "After constructing the graph representation of the point cloud, we focus on the combinatorial graph Laplacian [45], defined as $L:=D-W$ , where $_{D}$ is a diagonal matrix with the $i$ -th diagonal entry $\\begin{array}{r}{d_{i,i}=\\sum_{j=1}^{n}w_{i,j}}\\end{array}$ representing the degree of the $i$ -th node. $\\textbf{\\emph{L}}$ is symmetric and positive semidefinite, and can be eigen-decomposed as ${\\cal L}={\\cal U}{\\bf A}{\\cal U}^{\\top}$ , where $\\pmb{U}=[\\pmb{u}_{1},...,\\pmb{u}_{n}]$ is an orthogonal matrix containing the eigenvectors $\\pmb{u}_{i}$ , and $\\mathbf{A}=\\mathrm{diag}(\\lambda_{1},...,\\lambda_{n})$ is a diagonal matrix containing the eigenvalues. The eigenvalues are sorted in ascending order, representing frequencies from low to high. For a point cloud $\\mathcal{P}$ , the graph Fourier transform (GFT) can be applied to transform it into a compact representation in the frequency domain: $\\hat{\\mathcal{P}}=G\\mathcal{F}(\\mathcal{P}):=U^{\\top}\\mathcal{P}$ . The low-frequency components represent the coarse shape of the point cloud, while the high-frequency components represent the fine details. The inverse graph Fourier transform (IGFT) can be used to recover the point cloud in the spatial domain as $\\mathcal{P}=\\bar{G}\\mathcal{F}^{-1}(\\hat{\\mathcal{P}}):=U\\hat{\\mathcal{P}}$ . ", "page_idx": 3}, {"type": "text", "text": "3.2 Analyzing point cloud corruptions in the frequency domain ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "We employ GFT to transform point clouds and their corruptions into compact representations in the frequency domain, allowing us to analyze the underlying structures of these low-level distortions that are hardly observable in the spatial domain. For raw point clouds, we transform them to the frequencydomain representations and calculate $\\mathbb{E}_{\\mathcal{P}}[|G\\mathcal{F}(\\mathcal{P})|]$ by averaging over all validation point clouds in ModelNet40 [67]. For each corruption type in ModelNet-C [41], we calculate $\\mathbb{E}_{\\mathcal{P}}[|G\\bar{\\mathcal{F}}(\\mathcal{C}(\\mathcal{P})-\\mathcal{P})|]$ similarly, where $\\mathcal{C}$ denotes the corruption function. As the input point clouds have three spatial axes $\\left(x,y,z\\right)$ , we take the average over these channels. In Fig. 2, we visualize the graph frequency-domain representations of raw point clouds and the corruptions in ModelNet-C. We can see that the raw point clouds have higher power in the low-frequency region, while the corruption \u201cJitter\u201d leads to higher power in the high-frequency region. For corruptions such as \u201cRotate\u201d and \u201cScale\u201d, the corrupted power is concentrated more on the low-frequency components. The results demonstrate that different corruptions of point clouds affect different frequency bands. ", "page_idx": 3}, {"type": "text", "text": "3.3 Relationship between corruption robustness and sensitivity to frequency bands ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "Motivated by the different effects of corruptions on varying frequency bands observed in the graph frequency-domain representations, we investigate the relationship between the corruption robustness of 3D point cloud recognition models and their sensitivity to different frequency bands. ", "page_idx": 3}, {"type": "image", "img_path": "4jn7KWPHSD/tmp/af331ed514bce1aba50d34acddc045bc5b152767ff38e101105b9cf65e9fb9e9.jpg", "img_caption": ["Figure 3: An illustration of computing the Fourier spectrum of the Jacobian matrix for a single input point cloud. First, the Jacobian matrix for the input point cloud is computed. The gradient value of the output loss is visualized for each point. A higher gradient value (skewed to red) indicates that the model is more sensitive to changes at that point. Next, we utilize Graph Fourier Transform (GFT) on the Jacobian matrix to obtain a compact representation and measure its sensitivity in the Fourier domain. Finally, by examining the sensitivity measurement of different point cloud models in different frequency bands, we construct a relationship diagram with natural robustness. "], "img_footnote": [], "page_idx": 4}, {"type": "text", "text": "To measure the sensitivity of a model on different frequency bands, we propose to perform graph Fourier transform (GFT) on the Jacobian matrix of the model\u2019s output loss with respect to its input point cloud. Intuitively, the Jacobian matrix represents how the model\u2019s output changes with small variations in its input point cloud, revealing its sensitivity to different points in the spatial domain [1]. With GFT, we can obtain the frequency-domain representation of the Jacobian matrix, which reveals the model\u2019s sensitivity to different frequency bands of input. If a model\u2019s Jacobian matrix has a high proportion of low/high frequency components, it will be sensitive to low/high frequency bands. ", "page_idx": 4}, {"type": "text", "text": "Fig. 3 illustrates the computation of the frequency-domain Jacobian matrix for a single point cloud. Specifically, given an input point cloud $\\mathcal{P}$ , a classification model $h$ , and a standard cross-entropy loss function $\\mathcal{L}_{h}$ for the classification task, the Jacobian matrix $\\mathcal{I}(\\mathcal{P}):=\\nabla_{\\mathcal{P}}\\mathcal{L}_{h}$ of the loss with respect to the input point cloud can be calculated. We then perform GFT on ${\\mathcal{I}}({\\mathcal{P}})$ to obtain its frequency-domain representation, denoted as $\\widehat{{\\mathcal{I}}({\\mathcal{P}})}\\,=\\,U^{\\top}{\\mathcal{I}}({\\mathcal{P}})$ in a compact form, using the original point cloud\u2019s neighborhood relations and feature vector matrix. Since the input point cloud has three axis channels $\\left(x,y,z\\right)$ , we take the average of these channels and normalize the result. We measure the model\u2019s sensitivity to input perturbations in the low-frequency band by summing the squares of the amplitudes of the first $\\lambda$ frequencies of the Jacobian matrix\u2019s graph Fourier spectrum. The sensitivity to high-frequency perturbations is measured by summing the squares of the amplitudes of the remaining $1024-\\lambda$ frequencies. A higher value of the metric indicates greater sensitivity to perturbations in that frequency band. ", "page_idx": 4}, {"type": "text", "text": "We can now measure the importance of the sensitivity to different frequency bands of point cloud recognition models on their corruption robustness. First, we measure and establish the relationship between sensitivity to high/low frequency bands of different point cloud models and their accuracy under high/low frequency corruptions. As illustrated in Fig. 1(b), our proposed frequency sensitivity metrics are negatively correlated with the corruption robustness. Therefore, point cloud models that are less sensitive to high/low frequency bands exhibit better robustness to high/low frequency corruptions. This correlation indicates that the sensitivity of models to different frequency bands affects their corruption robustness, providing insights for further improving the robustness of point cloud recognition models. ", "page_idx": 4}, {"type": "text", "text": "3.4 Frequency adversarial training ", "text_level": 1, "page_idx": 4}, {"type": "text", "text": "The above analyses highlight the importance of the sensitivity of point cloud recognition models to high and low frequencies on their corruption robustness. However, reducing the sensitivity of point cloud models to both high and low frequencies is still challenging. To address this problem, we propose Frequency Adversarial Training (FAT) to improve the corruption robustness of point cloud recognition models using adversarial examples in the frequency domain. Intuitively, a model trained to be robust to worst-case adversarial perturbations should be naturally robust to real-world corruptions [72, 80], as also theoretically demonstrated in Sec. 3.5. ", "page_idx": 4}, {"type": "text", "text": "To simultaneously reduce the sensitivity of point cloud recognition models to high and low frequencies, we generate high-frequency adversarial examples and low-frequency adversarial examples, which are added to the training set. We generate high-frequency adversarial examples that alter the details of the point clouds, and low-frequency adversarial examples that change the rough shapes of the point clouds. To prevent the mutual interference of high-frequency and low-frequency adversarial examples that may lead to a decrease in model performance, we adopt the AdvProp training framework [72], where clean samples, high-frequency adversarial samples, and low-frequency adversarial samples are separately processed using three batch normalizations during adversarial training. Specifically, for an input point cloud $\\mathcal{P}$ with the ground-truth label $y$ , our optimization objective is ", "page_idx": 4}, {"type": "text", "text": "", "page_idx": 5}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\arg\\underset{\\theta}{\\operatorname*{min}}\\ \\biggl[\\mathbb{E}_{(\\mathcal{P},y)\\sim\\mathbb{D}}\\Bigl(\\mathcal{L}_{h}(\\theta,\\mathcal{P},y)+\\underset{\\epsilon_{h}\\in\\mathbb{S}_{h}}{\\operatorname*{max}}\\ \\mathcal{L}_{h}(\\theta,G\\mathcal{F}^{-1}(G\\mathcal{F}(\\mathcal{P})+\\epsilon_{h}),y)}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\qquad+\\underset{\\epsilon_{l}\\in\\mathbb{S}_{l}}{\\operatorname*{max}}\\mathcal{L}_{h}(\\theta,G\\mathcal{F}^{-1}(G\\mathcal{F}(\\mathcal{P})+\\epsilon_{l}),y)\\Bigr)\\biggr],}\\end{array}\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "where $\\mathbb{D}$ is the underlying data distribution, $\\mathcal{L}_{h}$ is the loss function, $\\theta$ is the network parameter, $\\epsilon_{h}$ and $\\epsilon_{l}$ are high-frequency and low-frequency adversarial perturbations, and $\\mathbb{S}_{h}$ and ${\\mathbb S}_{l}$ are the high-frequency and low-frequency perturbation ranges, respectively. ", "page_idx": 5}, {"type": "text", "text": "3.5 Theoretical analysis ", "text_level": 1, "page_idx": 5}, {"type": "text", "text": "To verify the claim that a model robust to frequency-domain worst-case perturbations should be more resistant to real-world corruptions, we provide a theoretical analysis that demonstrates the effectiveness of FAT in ensuring OOD generalization of the model. ", "page_idx": 5}, {"type": "text", "text": "Suppose $(x,y)$ is a pair of training sample $x$ and its label $y$ . The loss on $(x,y)$ with model parameter $\\theta$ is $\\mathcal{L}(\\theta,(x,y))$ , where $\\bar{\\mathcal{L}}(\\theta,\\bar{({x,y})})$ is continuous and differentiable for both $\\theta$ and $(x,y)$ . We let $f(x):=\\mathcal{L}(\\theta,(x,y))$ for simplicity. Let $\\mathcal{F}$ and ${\\mathcal{F}}^{-1}$ denote the Fourier transform and inverse Fourier transform, respectively. The norm $\\|\\cdot\\|_{p}$ denotes the $\\ell_{p}$ -norm. We have the following theorem: ", "page_idx": 5}, {"type": "text", "text": "Theorem 1. If $f$ satisfies that: $f(x)~\\in~[0,M]$ for all $x$ , $|f(\\mathcal{F}^{-1}(\\mathcal{F}(x)+\\alpha))\\,-\\,f(x)|\\;\\le\\;\\epsilon$ for all $x$ and $\\|\\alpha\\|_{p}\\,\\le\\,\\delta$ , then for any distribution $P_{o}$ and $P_{a}$ satisfying that $W a s^{p}(P_{o},P_{a})\\,:=$ $\\begin{array}{r}{(\\operatorname*{inf}_{u\\in\\Pi(P_{o},P_{a})}\\mathbb{E}_{(x,z)\\sim u}[\\|\\mathcal{F}(x)-\\mathcal{F}(z)\\|_{p}^{p}])^{1/p}\\le\\eta,}\\end{array}$ , where $\\eta<\\delta$ , then, with probability $1-\\gamma$ , we have: ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\mathbb{E}_{z\\sim P_{o}}[f(z)]-\\frac{1}{m}\\sum_{i=1}^{m}f(x_{i})\\leq\\epsilon\\left(1-\\frac{\\eta^{p}}{\\delta^{p}}-\\sqrt{\\frac{\\ln(4/\\gamma)}{2m}}\\right)+\\frac{\\eta^{p}}{\\delta^{p}}M+4M\\sqrt{\\frac{\\ln(4/\\gamma)}{2m}},\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "where $\\{x_{i}\\}_{i=1}^{m}$ are i.i.d. samples from $P_{a}$ . ", "page_idx": 5}, {"type": "text", "text": "Remark 1. Intuitively, OOD corresponds to the shifted distribution $P_{o}$ that approaches the training distribution $P_{a}$ . Thus $W a s^{p}(P_{o},P_{a})$ defines OOD from the perspective of measuring the distance between distributions. $\\begin{array}{r}{\\mathbb{E}_{z\\sim P_{o}}{[f(z)]}^{\\prime}-\\frac{1}{m}\\sum_{i=1}^{m}f(\\hat{x}_{i})}\\end{array}$ represents the OOD generalization error of the model. $|f(\\mathcal{F}^{-1}(\\mathcal{F}(x)+\\alpha))-f(x)|\\le\\epsilon$ and $\\|\\alpha\\|_{p}\\leq\\delta$ indicate that the model is robust under frequency-domain perturbations. The bound (2) implies that models that are adversarially robust in the frequency-domain have smaller generalization bounds on OOD data. ", "page_idx": 5}, {"type": "text", "text": "The proof of Theorem 1 is deferred to Appendix A. Thus, the frequency-domain adversarial robustness of the model guarantees the generalization on OOD data. We have the following observations: ", "page_idx": 5}, {"type": "text", "text": "\u2022 The right-hand side of Eq. (2) implies that models that are more robust to frequency domain adversarial samples (i.e., larger $\\delta$ and smaller $\\epsilon$ ) have smaller OOD generalization bounds and thus perform better on OOD data.   \n\u2022 For Eq. (2), a larger number of training samples $m$ leads to a smaller OOD generalization bound. This indicates that more training samples can compensate for the degradation of generalization performance. ", "page_idx": 5}, {"type": "text", "text": "4 Experiments ", "text_level": 1, "page_idx": 5}, {"type": "text", "text": "In this section, we first detail the experimental settings in Sec. 4.1, then present the main results in Sec. 4.2 to show the effectiveness of our method. We further integrate our method with other data augmentation techniques in Sec. 4.3 and perform ablation studies in Sec. 4.4. ", "page_idx": 5}, {"type": "table", "img_path": "4jn7KWPHSD/tmp/f0d21fe8c2f473b9723c896172c47b6e5d53d54839704bdfe5de0d23419b11fa.jpg", "table_caption": ["Table 1: Quantitative results of vanilla training, adversarial training, DUP Defense and our proposed Frequency Adversarial Training (FAT) on the ModelNet-C test set. Our proposed FAT outperforms all other methods in terms of mean corruption error (mCE), which demonstrates the effectiveness of FAT for improving corruption robustness. "], "table_footnote": [], "page_idx": 6}, {"type": "text", "text": "4.1 Experimental setup ", "text_level": 1, "page_idx": 6}, {"type": "text", "text": "Dataset. To validate the effectiveness of our FAT method in enhancing the corruption robustness of 3D point cloud recognition models, we train all models on the standard ModelNet40 training set [67]. In addition to reporting the performance of the models on the original ModelNet40 validation set, we also evaluate the corruption robustness on ModelNet-C [41] in the main paper and ModelNet40-C [51] in Appendix B. The ModelNet40 dataset [67] contains 12,311 CAD models with 40 common object categories in the real world. We use the official split [35], where 9,843 examples are used for training and the remaining 2,468 examples are used for testing. The ModelNet-C dataset [41] is designed for measuring the network robustness to common point cloud corruptions. It consists of 7 different corruption types, including \u201cScale\u201d, \u201cJitter\u201d, \u201cRotate\u201d, \u201cDrop Global\u201d, \u201cDrop Local\u201d, \u201cAdd Global\u201d, and \u201cAdd Local\u201d. Each type of corruption has five severity levels. ModelNet40-C [51] is a similar dataset with 15 corruptions, which will be detailed in Appendix B. ", "page_idx": 6}, {"type": "text", "text": "Model architectures. Following [41, 51], we select four representative model architectures: PointNet [35], DGCNN [65], PCT [17], and GDANet [74]. These models represent different architectural designs and have been widely applied in 3D visual tasks. ", "page_idx": 6}, {"type": "text", "text": "Evaluation metrics. To measure the corruption robustness of different methods, we follow [41] and use the mean corruption error $(\\mathrm{mCE})$ as the main evaluation metric. We adopt the official baseline DGCNN and first compute the corruption error (CE) for a given corruption type $i$ by averaging over 5 severity levels: l5 =1l5(=11\u2212(1O\u2212AOiD,AlGi,ClN)N), where OAi,l is the overall accuracy on a corruption test set $i$ at severity level $l$ , and $\\mathrm{OA}_{i,l}^{\\mathrm{DGCNN}}$ is the overall accuracy of the baseline. Then, we average over the 7 corruption types to compute the mean corruption error: $\\begin{array}{r}{\\mathrm{mCE}=\\frac{1}{N}\\sum_{i=1}^{N}\\mathrm{CE}_{i}}\\end{array}$ . In addition, we also report the clean overall accuracy (OA), the corruption overall accuracy (mOA), and the relative mCE (RmCE) following [41]. Due to space constraints, we provide the definition of $\\mathrm{\\mathbf{Rm}C E}$ and report mOA and $\\mathrm{RmCE}$ in Appendix B. ", "page_idx": 6}, {"type": "text", "text": "Implementation details. For each method, we train 250 epochs using the smooth cross-entropy loss [65] and Adam optimizer [23], and select the best performant model for further evaluation. We follow the DGCNN protocol [16]. For our method, we set $k=30$ for the $k$ -nearest neighbor graph and $\\lambda=100$ for dividing high-frequency and low-frequency [29]. We use PGD [33] and AOF [27] to generate high-frequency adversarial examples and low-frequency adversarial examples, respectively. We constrain $\\mathbb{S}_{h}$ and ${\\mathbb S}_{l}$ by 0.3 and 0.5, respectively. For more detailed training settings, please refer to Appendix B. ", "page_idx": 6}, {"type": "image", "img_path": "4jn7KWPHSD/tmp/0a65df2c2d2ca2d45f2a64f09832f04225e8c1e4e0eeafbd2bc54584561ff9e9.jpg", "img_caption": ["Figure 4: Visualization of the sensitivity maps based on Jacobian matrices of Frequency Adversarial Training (FAT) and vanilla training under four different model architectures. FAT reduces the model sensitivity to different frequency bands, thereby enhancing their robustness to corruptions. "], "img_footnote": [], "page_idx": 7}, {"type": "text", "text": "4.2 Main results ", "text_level": 1, "page_idx": 7}, {"type": "text", "text": "In this section, following [41, 51], we compare our proposed Frequency Adversarial Training (FAT) method with vanilla training, adversarial training and DUP Defense [93] on the ModelNet-C test set, demonstrating the effectiveness of FAT in enhancing corruption robustness. Table 1 presents a comparative analysis of different methods based on mean corruption error (mCE), clean overall accuracy (OA), and corruption error (CE) for each corruption type. ", "page_idx": 7}, {"type": "text", "text": "As shown in Table 1, our proposed Frequency Adversarial Training (FAT) outperforms all other methods in terms of mean corruption error (mCE), while exhibiting comparable performance in terms of overall accuracy (OA). The improvement in corruption robustness across the four different model architectures demonstrates the generalizability/universality of our method across different architectures. In Fig. 4, we visualize the sensitivity maps based on Jacobian matrices of Frequency Adversarial Training (FAT) and vanilla training under four different model architectures. FAT reduces the sensitivity of the model across different frequency bands. ", "page_idx": 7}, {"type": "text", "text": "It is noteworthy that GDANet introduces a geometry-disentangle module to dynamically disentangle point clouds into the contour and flat part of 3D objects, capturing complementary 3D geometric semantics. In contrast, FAT does not modify the network architecture to focus on the frequency domain but instead employs adversarial training in the frequency domain. As shown in Table 1, the two methods are complementary and synergistic, leading to improved model robustness. We report the performance of different methods in terms of overall corruption accuracy $(\\mathrm{mOA})$ and relative mCE (RmCE) in Appendix B, where the improvement in robustness of FAT is also significant under these metrics. The comparisons in Table 1 and Appendix B confirm that our proposed FAT enhances the OOD generalization ability of the model. ", "page_idx": 7}, {"type": "text", "text": "4.3 Data augmentation ", "text_level": 1, "page_idx": 7}, {"type": "text", "text": "To further validate the effectiveness of our proposed Frequency Adversarial Training (FAT), following [41], we investigate the performance of FAT in combination with different data augmentation strategies, including RSMix [24], PointWOLF [22], and WOLFMix [41]. These strategies respectively represent mix-based augmentation, deformation-based augmentation, and a combination of both mix-based and deformation-based augmentation. RSMix involves rigidly blending two point clouds using a transformation. PointWOLF enriches data diversity by applying non-rigid deformations to object parts. WOLFMix, designed based on PointWOLF and RSMix, first deforms the objects and then rigidly blends two deformed objects. When combining the data augmentation strategies, we first perform data augmentation on the input point cloud and then generate adversarial examples. For mix-based augmentation, we perform untargeted adversarial attacks on both labels being mixed to generate the adversarial examples. ", "page_idx": 7}, {"type": "text", "text": "In Table 2, we show the performance of FAT when integrated with different data augmentation strategies in terms of mean corruption error (mCE), clean overall accuracy (OA), and corruption error (CE) for each corruption type. Compared with a single data augmentation strategy, the combination of FAT and data augmentation strategies achieves a better mCE, which is attributed to the complementary and compatible information from both the spatial and frequency domains. The improvement in corruption robustness under three different data augmentation strategies demonstrates the generalization capability of our proposed method. As shown in Table 2, training GDANet with the combination of our proposed FAT with WOLFMix achieves a new state-of-the-art performance, with an impressive $0.537\\;\\mathrm{mCE}$ . ", "page_idx": 7}, {"type": "table", "img_path": "4jn7KWPHSD/tmp/d1ff437179e1c7bf03866a260daaa9c2160499ee7318d74ae30645000fb6f752.jpg", "table_caption": ["Table 2: Quantitative results of combining FAT with different data augmentation strategies on the ModelNetC test set. Compared with a single data augmentation strategy, the combination of FAT and different data augmentation strategies achieves a better mCE. Training GDANet with the combination of our proposed FAT with WOLFMix achieves the new state-of-the-art performance, with an impressive $\\mathbf{0.537\\;mCE}$ . "], "table_footnote": [], "page_idx": 8}, {"type": "table", "img_path": "4jn7KWPHSD/tmp/74cb45cd877c826a7373386c9915f1567ce0243a5f33ba49c03bdad6492a7d62.jpg", "table_caption": ["Table 3: Quantitative results of FAT and its variants. FAT w/o low-frequency has a lower mCE for high-frequency corruptions such as \u201cJitter\u201d, while FAT w/o high-frequency has a lower mCE for low-frequency corruptions such as \u201cscale\u201d. FAT w/o Advprop has a higher mCE but much worse OA. Compared with these methods, FAT achieves the lowest mCE. "], "table_footnote": [], "page_idx": 8}, {"type": "text", "text": "4.4 Ablation study ", "text_level": 1, "page_idx": 8}, {"type": "text", "text": "In this section, we conduct ablation study among our proposed Frequency Adversarial Training (FAT), as well as FAT variants: FAT w/o low-frequency, FAT w/o high-frequency, FAT w/o frequencydivision, and FAT w/o Advprop. FAT w/o low-frequency generates only high-frequency adversarial samples, while FAT w/o high-frequency generates only low-frequency adversarial samples. FAT w/o frequency-division randomly generates adversarial samples within a certain frequency range, without dividing the high and low frequency bands. FAT w/o Advprop does not use the AdvProp training framework [72]. We compare these methods in Table 3 based on mean corruption error (mCE), clean overall accuracy (OA), and corruption error (CE) measurements for each corruption type. ", "page_idx": 8}, {"type": "text", "text": "Compared with other methods, FAT w/o low-frequency has a lower mCE for high-frequency corruptions such as \u201cJitter\u201d, while FAT w/o high-frequency has a lower mCE for low-frequency corruptions such as \u201cscale\u201d. As discussed in Sec. 3.3, this is because adversarial training on high/low frequencies reduces the high/low frequency sensitivity, thus improving robustness to high/low-frequency corruptions. The performance of FAT w/o frequency-division falls between FAT w/o low-frequency and FAT w/o high-frequency. Although FAT w/o Advprop has a better mCE, its clean overall accuracy (OA) is worse than the other methods due to mutual interference between samples from different distributions, which may cause potential performance degradation. Compared with these methods, FAT achieves the lowest mCE, showing the effectiveness of our algorithm. More experimental results can be found in Appendix B. ", "page_idx": 8}, {"type": "text", "text": "5 Conclusion ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "In this paper, we study the robustness of 3D point cloud recognition models under common corruptions. We focus on the frequency domain to analyze the underlying structure of point clouds and common corruptions. Through graph Fourier transform (GFT), we identify a correlation between the corruption robustness and the model sensitivity to different frequency bands. Motivated by the analysis, we propose Frequency Adversarial Training (FAT), an adversarial training method based on frequency-domain adversarial examples to improve the corruption robustness of 3D point cloud recognition models. Extensive experiments demonstrate that the proposed method significantly improves the corruption robustness of various point cloud models, and can be integrated with other data augmentation techniques to achieve the state-of-the-art performance. ", "page_idx": 9}, {"type": "text", "text": "Limitation and broader impact. A limitation of our proposed method is that it reduces the clean accuracy a bit, e.g., FAT reduces the clean accuracy of DGCNN by $0.1\\%$ , PointNet by $0.5\\%$ , PCT by $1.0\\%$ , and GDANet by $0.6\\%$ . This may be caused by the inherent trade-off between accuracy and robustness [88]. Additionally, despite the complexity in implementation, FAT does not affect the efficiency of model inference, ensuring unhindered deployment of well-trained models in practical applications. The robustness of 3D point cloud recognition under corruptions is a severe problem towards safe and reliable 3D perception. Our work proposes an effective method to solve this issue, which does not have any negative social impact. ", "page_idx": 9}, {"type": "text", "text": "Acknowledgments ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "This work is supported by NKRDP grant No.2018YFA0704705, NSFC grants No.62276149 and No.12288201, and grant GJ0090202. Y. Dong is supported by the China National Postdoctoral Program for Innovative Talents. The authors thank anonymous referees for their valuable comments. L. Yu is supported by CAS Project for Young Scientists in Basic Research, Grant No.YSBR-040, ISCAS New Cultivation Project ISCAS-PYFX-202201, and ISCAS Basic Research ISCAS-JCZD202302. ", "page_idx": 9}, {"type": "text", "text": "References ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "[1] Julius Adebayo, Justin Gilmer, Michael Muelly, Ian Goodfellow, Moritz Hardt, and Been Kim. Sanity checks for saliency maps. Advances in neural information processing systems, 31, 2018.   \n[2] Yulong Cao, Chaowei Xiao, Dawei Yang, Jing Fang, Ruigang Yang, Mingyan Liu, and Bo Li. Adversarial objects against lidar-based autonomous driving systems. arXiv preprint arXiv:1907.05418, 2019.   \n[3] Nicholas Carlini and David Wagner. Towards evaluating the robustness of neural networks. In 2017 ieee symposium on security and privacy (sp), pages 39\u201357. IEEE, 2017.   \n[4] Alvin Chan, Yew-Soon Ong, and Clement Tan. How does frequency bias affect the robustness of neural image classifiers against common corruption and adversarial perturbations? arXiv preprint arXiv:2205.04533, 2022.   \n[5] Angel X Chang, Thomas Funkhouser, Leonidas Guibas, Pat Hanrahan, Qixing Huang, Zimo Li, Silvio Savarese, Manolis Savva, Shuran Song, Hao Su, et al. Shapenet: An information-rich 3d model repository. arXiv preprint arXiv:1512.03012, 2015.   \n[6] Xiaozhi Chen, Huimin Ma, Ji Wan, Bo Li, and Tian Xia. Multi-view 3d object detection network for autonomous driving. In Proceedings of the IEEE conference on Computer Vision and Pattern Recognition, pages 1907\u20131915, 2017.   \n[7] Yunlu Chen, Vincent Tao Hu, Efstratios Gavves, Thomas Mensink, Pascal Mettes, Pengwan Yang, and Cees GM Snoek. Pointmixup: Augmentation for point clouds. In Computer Vision\u2013 ECCV 2020: 16th European Conference, Glasgow, UK, August 23\u201328, 2020, Proceedings, Part III 16, pages 330\u2013345. Springer, 2020.   \n[8] Yunpeng Chen, Haoqi Fan, Bing Xu, Zhicheng Yan, Yannis Kalantidis, Marcus Rohrbach, Shuicheng Yan, and Jiashi Feng. Drop an octave: Reducing spatial redundancy in convolutional neural networks with octave convolution. In Proceedings of the IEEE/CVF international conference on computer vision, pages 3435\u20133444, 2019.   \n[9] Shuyu Cheng, Yibo Miao, Yinpeng Dong, Xiao Yang, Xiao-Shan Gao, and Jun Zhu. Efficient black-box adversarial attacks via bayesian optimization guided by a function prior. In Forty-first International Conference on Machine Learning, 2024.   \n[10] Wenda Chu, Linyi Li, and Bo Li. Tpc: Transformation-specific smoothing for point cloud models. arXiv preprint arXiv:2201.12733, 2022.   \n[11] Moustapha Cisse, Piotr Bojanowski, Edouard Grave, Yann Dauphin, and Nicolas Usunier. Parseval networks: Improving robustness to adversarial examples. In International Conference on Machine Learning, pages 854\u2013863. PMLR, 2017.   \n[12] Xiaoyi Dong, Dongdong Chen, Hang Zhou, Gang Hua, Weiming Zhang, and Nenghai Yu. Self-robust 3d point recognition via gather-vector guidance. In 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), pages 11513\u201311521. IEEE, 2020.   \n[13] Yueqi Duan, Yu Zheng, Jiwen Lu, Jie Zhou, and Qi Tian. Structural relational reasoning of point clouds. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 949\u2013958, 2019.   \n[14] Xiang Gao, Wei Hu, and Guo-Jun Qi. Graphter: Unsupervised learning of graph transformation equivariant representations via auto-encoding node-wise transformations. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 7163\u20137172, 2020.   \n[15] Robert Geirhos, Patricia Rubisch, Claudio Michaelis, Matthias Bethge, Felix A Wichmann, and Wieland Brendel. Imagenet-trained cnns are biased towards texture; increasing shape bias improves accuracy and robustness. arXiv preprint arXiv:1811.12231, 2018.   \n[16] Ankit Goyal, Hei Law, Bowei Liu, Alejandro Newell, and Jia Deng. Revisiting point cloud shape classification with a simple and effective baseline. In International Conference on Machine Learning, pages 3809\u20133820. PMLR, 2021.   \n[17] Meng-Hao Guo, Jun-Xiong Cai, Zheng-Ning Liu, Tai-Jiang Mu, Ralph R Martin, and Shi-Min Hu. Pct: Point cloud transformer. Computational Visual Media, 7:187\u2013199, 2021.   \n[18] Abdullah Hamdi, Sara Rojas, Ali Thabet, and Bernard Ghanem. Advpc: Transferable adversarial perturbations on 3d point clouds. In Computer Vision\u2013ECCV 2020: 16th European Conference, Glasgow, UK, August 23\u201328, 2020, Proceedings, Part XII 16, pages 241\u2013257. Springer, 2020.   \n[19] Dan Hendrycks, Norman Mu, Ekin D Cubuk, Barret Zoph, Justin Gilmer, and Balaji Lakshminarayanan. Augmix: A simple data processing method to improve robustness and uncertainty. arXiv preprint arXiv:1912.02781, 2019.   \n[20] Qingyong Hu, Bo Yang, Linhai Xie, Stefano Rosa, Yulan Guo, Zhihua Wang, Niki Trigoni, and Andrew Markham. Learning semantic segmentation of large-scale point clouds with random sampling. IEEE Transactions on Pattern Analysis and Machine Intelligence, 2021.   \n[21] Qidong Huang, Xiaoyi Dong, Dongdong Chen, Hang Zhou, Weiming Zhang, and Nenghai Yu. Shape-invariant 3d adversarial point clouds. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 15335\u201315344, 2022.   \n[22] Sihyeon Kim, Sanghyeok Lee, Dasol Hwang, Jaewon Lee, Seong Jae Hwang, and Hyunwoo J Kim. Point cloud augmentation with weighted local transformations. In Proceedings of the IEEE/CVF International Conference on Computer Vision, pages 548\u2013557, 2021.   \n[23] Diederik P Kingma and Jimmy Ba. Adam: A method for stochastic optimization. arXiv preprint arXiv:1412.6980, 2014.   \n[24] Dogyoon Lee, Jaeha Lee, Junhyeop Lee, Hyeongmin Lee, Minhyeok Lee, Sungmin Woo, and Sangyoun Lee. Regularization strategy for point cloud via rigidly mixed sample. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 15900\u201315909, 2021.   \n[25] Ruihui Li, Xianzhi Li, Pheng-Ann Heng, and Chi-Wing Fu. Pointaugment: an autoaugmentation framework for point cloud classification. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 6378\u20136387, 2020.   \n[26] Yangyan Li, Rui Bu, Mingchao Sun, Wei Wu, Xinhan Di, and Baoquan Chen. Pointcnn: Convolution on x-transformed points. Advances in neural information processing systems, 31, 2018.   \n[27] Binbin Liu, Jinlai Zhang, and Jihong Zhu. Boosting 3d adversarial attacks with attacking on frequency. IEEE Access, 10:50974\u201350984, 2022.   \n[28] Daizong Liu and Wei Hu. Imperceptible transfer attack and defense on 3d point cloud classification. IEEE Transactions on Pattern Analysis and Machine Intelligence, 2022.   \n[29] Daizong Liu, Wei Hu, and Xin Li. Point cloud attacks in graph spectral domain: When 3d geometry meets graph signal processing. arXiv preprint arXiv:2207.13326, 2022.   \n[30] Yongcheng Liu, Bin Fan, Gaofeng Meng, Jiwen Lu, Shiming Xiang, and Chunhong Pan. Densepoint: Learning densely contextual representation for efficient point cloud processing. In Proceedings of the IEEE/CVF International Conference on Computer Vision, pages 5239\u20135248, 2019.   \n[31] Yongcheng Liu, Bin Fan, Shiming Xiang, and Chunhong Pan. Relation-shape convolutional neural network for point cloud analysis. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 8895\u20138904, 2019.   \n[32] Raphael Gontijo Lopes, Dong Yin, Ben Poole, Justin Gilmer, and Ekin D Cubuk. Improving robustness without sacrificing accuracy with patch gaussian augmentation. arXiv preprint arXiv:1906.02611, 2019.   \n[33] Aleksander Madry, Aleksandar Makelov, Ludwig Schmidt, Dimitris Tsipras, and Adrian Vladu. Towards deep learning models resistant to adversarial attacks. arXiv preprint arXiv:1706.06083, 2017.   \n[34] Yibo Miao, Yinpeng Dong, Jun Zhu, and Xiao-Shan Gao. Isometric 3d adversarial examples in the physical world. In Advances in Neural Information Processing Systems, volume 35, pages 19716\u201319731, 2022.   \n[35] Charles R Qi, Hao Su, Kaichun Mo, and Leonidas J Guibas. Pointnet: Deep learning on point sets for 3d classification and segmentation. In Proceedings of the IEEE conference on computer vision and pattern recognition, pages 652\u2013660, 2017.   \n[36] Charles Ruizhongtai Qi, Li Yi, Hao Su, and Leonidas J Guibas. Pointnet++: Deep hierarchical feature learning on point sets in a metric space. Advances in neural information processing systems, 30, 2017.   \n[37] Guocheng Qian, Yuchen Li, Houwen Peng, Jinjie Mai, Hasan Hammoud, Mohamed Elhoseiny, and Bernard Ghanem. Pointnext: Revisiting pointne $^{++}$ with improved training and scaling strategies. Advances in neural information processing systems, 35:23192\u201323204, 2022.   \n[38] Yongming Rao, Jiwen Lu, and Jie Zhou. Global-local bidirectional reasoning for unsupervised representation learning of 3d point clouds. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 5376\u20135385, 2020.   \n[39] Mohammed H Rasheed, Omar M Salih, Mohammed M Siddeq, and Marcos A Rodrigues. Image compression based on 2d discrete fourier transform and matrix minimization algorithm. Array, 6:100024, 2020.   \n[40] Benjamin Recht, Rebecca Roelofs, Ludwig Schmidt, and Vaishaal Shankar. Do imagenet classifiers generalize to imagenet? In International conference on machine learning, pages 5389\u20135400. PMLR, 2019.   \n[41] Jiawei Ren, Liang Pan, and Ziwei Liu. Benchmarking and analyzing point cloud classification under corruptions. In International Conference on Machine Learning, pages 18559\u201318575. PMLR, 2022.   \n[42] Evgenia Rusak, Lukas Schott, Roland S Zimmermann, Julian Bitterwolf, Oliver Bringmann, Matthias Bethge, and Wieland Brendel. A simple way to make neural networks robust against diverse image corruptions. In Computer Vision\u2013ECCV 2020: 16th European Conference, Glasgow, UK, August 23\u201328, 2020, Proceedings, Part III 16, pages 53\u201369. Springer, 2020.   \n[43] Aliaksei Sandryhaila and Jos\u00e9 MF Moura. Discrete signal processing on graphs: Graph fourier transform. In 2013 IEEE International Conference on Acoustics, Speech and Signal Processing, pages 6167\u20136170. IEEE, 2013.   \n[44] Yiru Shen, Chen Feng, Yaoqing Yang, and Dong Tian. Mining point cloud local structures by kernel correlation and graph pooling. In Proceedings of the IEEE conference on computer vision and pattern recognition, pages 4548\u20134557, 2018.   \n[45] David I Shuman, Sunil K Narang, Pascal Frossard, Antonio Ortega, and Pierre Vandergheynst. The emerging field of signal processing on graphs: Extending high-dimensional data analysis to networks and other irregular domains. IEEE signal processing magazine, 30(3):83\u201398, 2013.   \n[46] Hang Su, Subhransu Maji, Evangelos Kalogerakis, and Erik Learned-Miller. Multi-view convolutional neural networks for 3d shape recognition. In Proceedings of the IEEE international conference on computer vision, pages 945\u2013953, 2015.   \n[47] Jiachen Sun, Karl Koenig, Yulong Cao, Qi Alfred Chen, and Z Morley Mao. On adversarial robustness of 3d point cloud classification under adaptive attacks. arXiv preprint arXiv:2011.11922, 2020.   \n[48] Jiachen Sun, Yulong Cao, Christopher B Choy, Zhiding Yu, Anima Anandkumar, Zhuoqing Morley Mao, and Chaowei Xiao. Adversarially robust 3d point cloud recognition using selfsupervisions. Advances in Neural Information Processing Systems, 34:15498\u201315512, 2021.   \n[49] Jiachen Sun, Akshay Mehra, Bhavya Kailkhura, Pin-Yu Chen, Dan Hendrycks, Jihun Hamm, and Z Morley Mao. A spectral view of randomized smoothing under common corruptions: Benchmarking and improving certified robustness. In Computer Vision\u2013ECCV 2022: 17th European Conference, Tel Aviv, Israel, October 23\u201327, 2022, Proceedings, Part IV, pages 654\u2013671. Springer, 2022.   \n[50] Jiachen Sun, Weili Nie, Zhiding Yu, Z Morley Mao, and Chaowei Xiao. Pointdp: Diffusiondriven purification against adversarial attacks on 3d point cloud recognition. arXiv preprint arXiv:2208.09801, 2022.   \n[51] Jiachen Sun, Qingzhao Zhang, Bhavya Kailkhura, Zhiding Yu, Chaowei Xiao, and Z Morley Mao. Benchmarking robustness of 3d point cloud recognition against common corruptions. arXiv preprint arXiv:2201.12296, 2022.   \n[52] Jiachen Sun Sun, Yulong Cao Cao, Qi Alfred Chen, and Z Morley Mao. Towards robust lidar-based perception in autonomous driving: General black-box adversarial sensor attack and countermeasures. In USENIX Security Symposium (Usenix Security\u201920), 2020.   \n[53] Christian Szegedy, Wojciech Zaremba, Ilya Sutskever, Joan Bruna, Dumitru Erhan, Ian Goodfellow, and Rob Fergus. Intriguing properties of neural networks. arXiv preprint arXiv:1312.6199, 2013.   \n[54] Abdel Aziz Taha and Allan Hanbury. Metrics for evaluating 3d medical image segmentation: analysis, selection, and tool. BMC medical imaging, 15(1):1\u201328, 2015.   \n[55] Gusi Te, Wei Hu, Amin Zheng, and Zongming Guo. Rgcnn: Regularized graph cnn for point cloud segmentation. In Proceedings of the 26th ACM international conference on Multimedia, pages 746\u2013754, 2018.   \n[56] Hugues Thomas, Charles R Qi, Jean-Emmanuel Deschaud, Beatriz Marcotegui, Fran\u00e7ois Goulette, and Leonidas J Guibas. Kpconv: Flexible and deformable convolution for point clouds. In Proceedings of the IEEE/CVF international conference on computer vision, pages 6411\u20136420, 2019.   \n[57] Tzungyu Tsai, Kaichen Yang, Tsung-Yi Ho, and Yier Jin. Robust adversarial objects against deep learning models. In Proceedings of the AAAI Conference on Artificial Intelligence, volume 34, pages 954\u2013962, 2020.   \n[58] James Tu, Mengye Ren, Sivabalan Manivasagam, Ming Liang, Bin Yang, Richard Du, Frank Cheng, and Raquel Urtasun. Physically realizable adversarial examples for lidar object detection. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition, pages 13716\u201313725, 2020.   \n[59] Puru Vaish, Shunxin Wang, and Nicola Strisciuglio. Fourier-basis functions to bridge augmentation gap: Rethinking frequency augmentation in image classification. arXiv preprint arXiv:2403.01944, 2024.   \n[60] Jacob Varley, Chad DeChant, Adam Richardson, Joaqu\u00edn Ruales, and Peter Allen. Shape completion enabled robotic grasping. In 2017 IEEE/RSJ international conference on intelligent robots and systems (IROS), pages 2442\u20132447. IEEE, 2017.   \n[61] Haohan Wang, Xindi Wu, Zeyi Huang, and Eric P Xing. High-frequency component helps explain the generalization of convolutional neural networks. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition, pages 8684\u20138694, 2020.   \n[62] Jie Wang, Lihe Ding, Tingfa Xu, Shaocong Dong, Xinli Xu, Long Bai, and Jianan Li. Sampleadaptive augmentation for point cloud recognition against real-world corruptions. In Proceedings of the IEEE/CVF International Conference on Computer Vision, pages 14330\u201314339, 2023.   \n[63] Ruibin Wang, Yibo Yang, and Dacheng Tao. Art-point: Improving rotation robustness of point cloud classifiers via adversarial rotation. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 14371\u201314380, 2022.   \n[64] Weiyue Wang, Ronald Yu, Qiangui Huang, and Ulrich Neumann. Sgpn: Similarity group proposal network for 3d point cloud instance segmentation. In Proceedings of the IEEE conference on computer vision and pattern recognition, pages 2569\u20132578, 2018.   \n[65] Yue Wang, Yongbin Sun, Ziwei Liu, Sanjay E Sarma, Michael M Bronstein, and Justin M Solomon. Dynamic graph cnn for learning on point clouds. Acm Transactions On Graphics (tog), 38(5):1\u201312, 2019.   \n[66] Bichen Wu, Xuanyu Zhou, Sicheng Zhao, Xiangyu Yue, and Kurt Keutzer. Squeezesegv2: Improved model structure and unsupervised domain adaptation for road-object segmentation from a lidar point cloud. In 2019 International Conference on Robotics and Automation (ICRA), pages 4376\u20134382. IEEE, 2019.   \n[67] Zhirong Wu, Shuran Song, Aditya Khosla, Fisher Yu, Linguang Zhang, Xiaoou Tang, and Jianxiong Xiao. 3d shapenets: A deep representation for volumetric shapes. In Proceedings of the IEEE conference on computer vision and pattern recognition, pages 1912\u20131920, 2015.   \n[68] Ziyi Wu, Yueqi Duan, He Wang, Qingnan Fan, and Leonidas J Guibas. If-defense: 3d adversarial point cloud defense via implicit function based restoration. arXiv preprint arXiv:2010.05272, 2020.   \n[69] Chong Xiang, Charles R Qi, and Bo Li. Generating 3d adversarial point clouds. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 9136\u20139144, 2019.   \n[70] Tiange Xiang, Chaoyi Zhang, Yang Song, Jianhui Yu, and Weidong Cai. Walk in the cloud: Learning curves for point clouds shape analysis. In Proceedings of the IEEE/CVF International Conference on Computer Vision, pages 915\u2013924, 2021.   \n[71] Chenxi Xiao and Juan Wachs. Triangle-net: Towards robustness in point cloud learning. In Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision, pages 826\u2013835, 2021.   \n[72] Cihang Xie, Mingxing Tan, Boqing Gong, Jiang Wang, Alan L Yuille, and Quoc V Le. Adversarial examples improve image recognition. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 819\u2013828, 2020.   \n[73] Mutian Xu, Runyu Ding, Hengshuang Zhao, and Xiaojuan Qi. Paconv: Position adaptive convolution with dynamic kernel assembling on point clouds. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 3173\u20133182, 2021.   \n[74] Mutian Xu, Junhao Zhang, Zhipeng Zhou, Mingye Xu, Xiaojuan Qi, and Yu Qiao. Learning geometry-disentangled representation for complementary understanding of 3d object point cloud. In Proceedings of the AAAI Conference on Artificial Intelligence, volume 35, pages 3056\u20133064, 2021.   \n[75] Qiangeng Xu, Xudong Sun, Cho-Ying Wu, Panqu Wang, and Ulrich Neumann. Grid-gcn for fast and scalable point cloud learning. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 5661\u20135670, 2020.   \n[76] Xu Yan, Chaoda Zheng, Zhen Li, Sheng Wang, and Shuguang Cui. Pointasnl: Robust point clouds processing using nonlocal neural networks with adaptive sampling. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition, pages 5589\u20135598, 2020.   \n[77] Bo Yang, Jianan Wang, Ronald Clark, Qingyong Hu, Sen Wang, Andrew Markham, and Niki Trigoni. Learning object bounding boxes for 3d instance segmentation on point clouds. Advances in neural information processing systems, 32, 2019.   \n[78] Jiancheng Yang, Qiang Zhang, Bingbing Ni, Linguo Li, Jinxian Liu, Mengdie Zhou, and Qi Tian. Modeling point clouds with self-attention and gumbel subset sampling. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 3323\u20133332, 2019.   \n[79] Yaoqing Yang, Chen Feng, Yiru Shen, and Dong Tian. Foldingnet: Point cloud auto-encoder via deep grid deformation. In Proceedings of the IEEE conference on computer vision and pattern recognition, pages 206\u2013215, 2018.   \n[80] Mingyang Yi, Lu Hou, Jiacheng Sun, Lifeng Shang, Xin Jiang, Qun Liu, and Zhiming Ma. Improved ood generalization via adversarial training and pretraing. In International Conference on Machine Learning, pages 11987\u201311997, 2021.   \n[81] Dong Yin, Raphael Gontijo Lopes, Jon Shlens, Ekin Dogus Cubuk, and Justin Gilmer. A fourier perspective on model robustness in computer vision. Advances in Neural Information Processing Systems, 32, 2019.   \n[82] Lijia Yu, Shuang Liu, Yibo Miao, Xiao-Shan Gao, and Lijun Zhang. Generalization bound and new algorithm for clean-label backdoor attack. In Forty-first International Conference on Machine Learning, 2024.   \n[83] Tan Yu, Jingjing Meng, and Junsong Yuan. Multi-view harmonized bilinear network for 3d object recognition. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 186\u2013194, 2018.   \n[84] Xiangyu Yue, Bichen Wu, Sanjit A Seshia, Kurt Keutzer, and Alberto L Sangiovanni-Vincentelli. A lidar point cloud generator: from a virtual world to autonomous driving. In Proceedings of the 2018 ACM on International Conference on Multimedia Retrieval, pages 458\u2013464, 2018.   \n[85] Sangdoo Yun, Dongyoon Han, Seong Joon Oh, Sanghyuk Chun, Junsuk Choe, and Youngjoon Yoo. Cutmix: Regularization strategy to train strong classifiers with localizable features. In Proceedings of the IEEE/CVF international conference on computer vision, pages 6023\u20136032, 2019.   \n[86] Manzil Zaheer, Satwik Kottur, Siamak Ravanbakhsh, Barnabas Poczos, Russ R Salakhutdinov, and Alexander J Smola. Deep sets. Advances in neural information processing systems, 30, 2017.   \n[87] Bohang Zhang, Tianle Cai, Zhou Lu, Di He, and Liwei Wang. Towards certifying l-infinity robustness using neural networks with l-inf-dist neurons. In International Conference on Machine Learning, pages 12368\u201312379, 2021.   \n[88] Hongyang Zhang, Yaodong Yu, Jiantao Jiao, Eric Xing, Laurent El Ghaoui, and Michael Jordan. Theoretically principled trade-off between robustness and accuracy. In International conference on machine learning, pages 7472\u20137482, 2019.   \n[89] Hongyi Zhang, Moustapha Cisse, Yann N Dauphin, and David Lopez-Paz. mixup: Beyond empirical risk minimization. arXiv preprint arXiv:1710.09412, 2017.   \n[90] Jinlai Zhang, Lyujie Chen, Bo Ouyang, Binbin Liu, Jihong Zhu, Yujin Chen, Yanmei Meng, and Danfeng Wu. Pointcutmix: Regularization strategy for point cloud classification. Neurocomputing, 505:58\u201367, 2022.   \n[91] Tianhang Zheng, Changyou Chen, Junsong Yuan, Bo Li, and Kui Ren. Pointcloud saliency maps. In Proceedings of the IEEE/CVF International Conference on Computer Vision, pages 1598\u20131606, 2019.   \n[92] Boxuan Zhong, He Huang, and Edgar Lobaton. Reliable vision-based grasping target recognition for upper limb prostheses. IEEE Transactions on Cybernetics, 2020.   \n[93] Hang Zhou, Kejiang Chen, Weiming Zhang, Han Fang, Wenbo Zhou, and Nenghai Yu. Dup-net: Denoiser and upsampler network for 3d adversarial point clouds defense. In Proceedings of the IEEE/CVF International Conference on Computer Vision, pages 1961\u20131970, 2019.   \n[94] Shenchen Zhu, Yue Zhao, Kai Chen, Bo Wang, Hualong Ma, et al. {AE-Morpher}: Improve physical robustness of adversarial objects against {LiDAR-based} detectors via object reconstruction. In 33rd USENIX Security Symposium (USENIX Security 24), pages 7339\u20137356, 2024.   \n[95] Xinge Zhu, Hui Zhou, Tai Wang, Fangzhou Hong, Wei Li, Yuexin Ma, Hongsheng Li, Ruigang Yang, and Dahua Lin. Cylindrical and asymmetrical 3d convolution networks for lidar-based perception. IEEE Transactions on Pattern Analysis and Machine Intelligence, 2021.   \n[96] Yi Zhu, Chenglin Miao, Tianhang Zheng, Foad Hajiaghajani, Lu Su, and Chunming Qiao. Can we use arbitrary objects to attack lidar perception in autonomous driving? In Proceedings of the 2021 ACM SIGSAC Conference on Computer and Communications Security, pages 1945\u20131960, 2021.   \n[97] Yifan Zhu, Yibo Miao, Yinpeng Dong, and Xiao-Shan Gao. Toward availability attacks in 3d point clouds. In International Conference on Machine Learning, 2024. ", "page_idx": 9}, {"type": "text", "text": "", "page_idx": 10}, {"type": "text", "text": "", "page_idx": 11}, {"type": "text", "text": "", "page_idx": 12}, {"type": "text", "text": "", "page_idx": 13}, {"type": "text", "text": "", "page_idx": 14}, {"type": "text", "text": "", "page_idx": 15}, {"type": "text", "text": "A Proof ", "text_level": 1, "page_idx": 16}, {"type": "text", "text": "Theorem 1. If $f$ satisfies that: $f(x)~\\in~[0,M]$ for all $x$ , $|f(\\mathcal{F}^{-1}(\\mathcal{F}(x)+\\alpha))\\,-\\,f(x)|\\;\\le\\;\\epsilon$ for all $x$ and $\\|\\alpha\\|_{p}\\,\\le\\,\\delta$ , then for any distribution $P_{o}$ and $P_{a}$ satisfying that $W a s^{p}(P_{o},P_{a})\\,:=$ $\\begin{array}{r}{(\\operatorname*{inf}_{u\\in\\Pi(P_{o},P_{a})}\\mathbb{E}_{(x,z)\\sim u}[\\|\\mathcal{F}(x)-\\mathcal{F}(z)\\|_{p}^{p}])^{1/p}\\le\\eta,}\\end{array}$ where $\\eta<\\delta$ , then, with probability $1-\\gamma$ , we have: ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\mathbb{E}_{z\\sim P_{o}}[f(z)]-\\frac{1}{m}\\sum_{i=1}^{m}f(x_{i})\\leq\\epsilon\\left(1-\\frac{\\eta^{p}}{\\delta^{p}}-\\sqrt{\\frac{\\ln(4/\\gamma)}{2m}}\\right)+\\frac{\\eta^{p}}{\\delta^{p}}M+4M\\sqrt{\\frac{\\ln(4/\\gamma)}{2m}},\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "where $\\{x_{i}\\}_{i=1}^{m}$ are i.i.d. samples from $P_{a}$ . ", "page_idx": 16}, {"type": "text", "text": "Proof. Assume $u$ is a joint distribution of $P_{o}$ and $P_{a}$ , such that $(\\mathbb{E}_{(x,z)\\sim u}[\\|\\mathcal{F}(x)-\\mathcal{F}(z)\\|_{p}^{p}])^{1/p}\\le\\eta$ . Firstly, by Markov inequality, we have that: ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{P_{(x,z)\\sim u}(\\Vert\\mathcal{F}(x)-\\mathcal{F}(z)\\Vert_{p}\\ge\\delta)}\\\\ {=}&{P_{(x,z)\\sim u}(\\Vert\\mathcal{F}(x)-\\mathcal{F}(z)\\Vert_{p}^{p}\\ge\\delta^{p})}\\\\ {\\le}&{\\frac{\\mathbb{E}_{(x,z)\\sim u}[\\Vert\\mathcal{F}(x)-\\mathcal{F}(z)\\Vert_{p}^{p}]}{\\delta^{p}}}\\\\ {\\le}&{\\frac{\\eta^{p}}{\\delta^{p}}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "Then, we have that: ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathbb{E}_{(x,z)\\sim u}[I(\\|\\mathcal{F}(x)-\\mathcal{F}(z)\\|_{p}\\leq\\delta)]=P_{(x,z)\\sim u}(\\|\\mathcal{F}(x)-\\mathcal{F}(z)\\|_{p}\\leq\\delta)\\geq1-\\frac{\\eta^{p}}{\\delta p}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "Now, let $\\{(x_{i}^{u},z_{i}^{u})\\}_{i=1}^{m}$ be i.i.d. sampled from distribution $u$ . Then, by Hoeffding inequality, we have that: ", "page_idx": 16}, {"type": "text", "text": "(1): with probability $1-\\gamma/4$ , there are ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\frac{1}{m}\\sum_{i=1}^{m}I(\\|\\mathcal{F}(x_{i}^{u})-\\mathcal{F}(z_{i}^{u})\\|_{p}\\leq\\delta)}\\\\ {\\geq}&{\\mathbb{E}_{(x,z)\\sim u}[I(\\|\\mathcal{F}(x)-\\mathcal{F}(z)\\|_{p}\\leq\\delta)]-\\sqrt{\\frac{l n(4/\\gamma)}{2m}}}\\\\ {\\geq}&{1-\\frac{\\eta^{p}}{\\delta^{p}}-\\sqrt{\\frac{l n(4/\\gamma)}{2m}},}\\end{array}\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "which indicates that there are at least $\\begin{array}{r}{m(1\\,-\\,\\frac{\\eta^{p}}{\\delta^{p}}\\,-\\,\\sqrt{\\frac{l n(4/\\gamma)}{2m}})}\\end{array}$ number of $i\\ \\in\\ [m]$ makes that $\\|{\\mathcal{F}}(x_{i}^{u})-{\\mathcal{F}}(z_{i}^{u})\\|_{p}\\leq\\delta$ ; ", "page_idx": 16}, {"type": "text", "text": "(2): with probability $1-\\gamma/4$ , there are ", "page_idx": 16}, {"type": "equation", "text": "$$\n-\\frac{1}{m}\\sum_{i=1}^{m}f(z_{i}^{u})+\\mathbb{E}_{z\\sim P_{o}}[f(z)]=-\\frac{1}{m}\\sum_{i=1}^{m}f(z_{i}^{u})+\\mathbb{E}_{(x,z)\\sim u}[f(z)]\\leq M\\sqrt{\\frac{l n(4/\\gamma)}{2m}};\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "(3): with probability $1-\\gamma/4$ , there are ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\frac{1}{m}\\sum_{i=1}^{m}f(x_{i}^{u})-\\mathbb{E}_{x\\sim P_{a}}[f(x)]=\\frac{1}{m}\\sum_{i=1}^{m}f(x_{i}^{u})-\\mathbb{E}_{(x,z)\\sim u}[f(x)]\\leq M\\sqrt{\\frac{l n(4/\\gamma)}{2m}};\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "Let $\\{x_{i}\\}_{i=1}^{m}$ are i.i.d. samples from distribution $P_{a}$ , then, by Hoeffding inequality, we have that: (4): with probability $1-\\gamma/4$ , there are ", "page_idx": 16}, {"type": "equation", "text": "$$\n-{\\frac{1}{m}}\\sum_{i=1}^{m}f(x_{i})+\\mathbb{E}_{x\\sim P_{a}}[f(x)]\\leq M{\\sqrt{\\frac{l n(4/\\gamma)}{2m}}};\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "So, with probability $1-\\gamma$ makes that (1), (2), (3) and (4) stand, at this times, we can estimate the $\\begin{array}{r}{\\mathbb{E}_{z\\sim P_{o}}[f(z)]-\\frac{1}{m}\\sum_{i=1}^{m}{\\dot{f}}(x_{i})}\\end{array}$ , there are: ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{E}_{z\\sim P_{0}}[f(z)]}\\\\ {\\leq}&{\\frac{1}{m}\\sum_{i=1}^{m}f(z_{i}^{u})+M\\sqrt{\\frac{l n(4/\\gamma)}{2m}}}\\\\ {\\leq}&{\\frac{1}{m}\\sum_{i=1}^{m}f(x_{i}^{u})+|f(x_{i}^{u})-f(z_{i}^{u})|+M\\sqrt{\\frac{l n(4/\\gamma)}{2m}}}\\\\ {\\leq}&{\\frac{1}{m}\\sum_{i=1}^{m}f(x_{i}^{u})+\\epsilon l(\\|\\mathcal{F}(x_{i}^{u})-\\mathcal{F}(z_{i}^{u})\\|_{p}\\leq\\delta)+M I(\\|\\mathcal{F}(x_{i}^{u})-\\mathcal{F}(z_{i}^{u})\\|_{p}>\\delta)+M\\sqrt{\\frac{l n(4/\\gamma)}{2m}}}\\\\ {\\leq}&{\\frac{1}{m}\\sum_{i=1}^{m}f(x_{i}^{u})+\\epsilon(1-\\frac{\\eta^{p}}{\\delta^{p}}-\\sqrt{\\frac{l n(4/\\gamma)}{2m}})+(\\frac{\\eta^{p}}{\\delta^{p}}+\\sqrt{\\frac{l n(4/\\gamma)}{2m}})M+M\\sqrt{\\frac{l n(4/\\gamma)}{2m}}}\\\\ {\\leq}&{\\frac{1}{m}\\sum_{i=1}^{m}f(x)|+\\epsilon(1-\\frac{\\eta^{p}}{\\delta^{p}}-\\sqrt{\\frac{l n(4/\\gamma)}{2m}})+(\\frac{\\eta^{p}}{\\delta^{p}}+\\sqrt{\\frac{l n(4/\\gamma)}{2m}})M+2M\\sqrt{\\frac{l n(4/\\gamma)}{2m}}}\\\\ {\\leq}&{\\frac{1}{m}\\sum_{i=1}^{m}f(x_{i})+\\epsilon(1-\\frac{\\eta^{p}}{\\delta^{p}}-\\sqrt{\\frac{l n(4/\\gamma)}{2m}})+(\\frac{\\eta^{p}}{\\delta^{p}}+\\sqrt{\\frac{l n(4/\\gamma)}{2m}})M+3M\\sqrt{\\frac{l n(4/\\gamma)}{2m}}}\\\\ {=}&{\\frac{1}{m}\\sum_{i=1}^{m}f(x_{i})+\\epsilon(1-\\frac{\\eta^{p}}{\\delta^{p}}-\\sqrt{\\frac{l n(4/\\gamma)}{2m}})+M\\frac{\\eta^{p}}{\\delta^{p}}+\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "We get our conclusion. ", "page_idx": 17}, {"type": "text", "text": "Our generalization bound can also be extended to Lipschitz neural networks, which are a class of networks with global Lipschitz constants [11, 87]. ", "page_idx": 17}, {"type": "text", "text": "Corollary A.1. If $f$ satisfies that: $f(x)\\in[0,M]$ for all $x\\in[0,1]^{n}$ , $|f(\\mathcal{F}^{-1}(\\mathcal{F}(x)+\\alpha))-f(x)|\\le$ $\\epsilon\\|\\alpha\\|_{p}$ for all $x\\,\\in\\,[0,1]^{n}$ and $\\alpha$ , then for any distribution $P_{o}$ and $P_{a}$ in $[0,1]^{n}$ satisfying that $\\begin{array}{r}{W a s^{p}(P_{o},P_{a}):=(\\operatorname*{inf}_{u\\in\\Pi(P_{o},P_{a})}\\mathbb{E}_{(x,z)\\sim u}[\\|\\mathcal{F}(x)-\\mathcal{F}(z)\\|_{p}^{p}])^{1/p}\\le\\eta,}\\end{array}$ , then, with probability $1-\\gamma_{\\mathrm{i}}$ we have: ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\mathbb{E}_{z\\sim P_{o}}[f(z)]-\\frac{1}{m}\\sum_{i=1}^{m}f(x_{i})\\leq\\epsilon(\\eta+v\\eta\\sqrt{\\frac{l n(4/\\gamma)}{2m}})+\\frac{M}{v^{p}}+3M\\sqrt{\\frac{l n(4/\\gamma)}{2m}},\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "where $\\{x_{i}\\}_{i=1}^{m}$ are i.i.d. samples from $P_{a}$ , $v$ is any real number greater than $^{\\,I}$ . ", "page_idx": 17}, {"type": "text", "text": "Proof. Assuming $u$ is a joint distribution of $P_{o}$ and $P_{a}$ , and makes that $\\big(\\mathbb{E}_{(\\mathcal{F}(x),\\mathcal{F}(z))\\sim u}[\\|x-$ $z\\|_{p}^{p}\\bigr])^{1/p}\\leq\\eta$ . Firstly, by Markov inequality, we have that: ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{P_{(x,z)\\sim u}(\\Vert\\mathcal{F}(x)-\\mathcal{F}(z)\\Vert_{p}\\ge v\\eta)}\\\\ {=}&{P_{(x,z)\\sim u}(\\Vert\\mathcal{F}(x)-\\mathcal{F}(z)\\Vert_{p}^{p}\\ge(v\\eta)^{p})}\\\\ {\\le}&{\\frac{\\mathbb{E}_{(x,z)\\sim u}[\\Vert\\mathcal{F}(x)-\\mathcal{F}(z)\\Vert_{p}^{p}]}{(v\\eta)^{p}}}\\\\ {\\le}&{\\frac{\\eta^{p}}{(v\\eta)^{p}}=(1/v)^{p}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "Then, we have that: ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\mathbb{E}_{(x,z)\\sim u}(I(\\|\\mathcal{F}(x)-\\mathcal{F}(z)\\|_{p}\\leq v\\eta))=P_{(x,z)\\sim u}(\\|\\mathcal{F}(x)-\\mathcal{F}(z)\\|_{p}\\leq v\\eta)\\geq1-\\frac{1}{v^{p}}.\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "Now, let $\\{(x_{i},z_{i})\\}_{i=1}^{m}$ are i.i.d. samples from distribution $u$ . Then, by Hoeffding inequality, we have that: ", "page_idx": 17}, {"type": "text", "text": "(1): with probability $1-\\gamma/4$ , there are ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\frac{1}{m}\\sum_{i=1}^{m}I(\\|\\mathcal{F}(x_{i}^{u})-\\mathcal{F}(z_{i}^{u})\\|_{p}\\leq v\\eta)\\|\\mathcal{F}(x_{i}^{u})-\\mathcal{F}(z_{i}^{u})\\|_{p}}\\\\ {\\leq}&{\\mathbb{E}_{(x,z)\\sim u}[I(\\|\\mathcal{F}(x_{i}^{u})-\\mathcal{F}(z_{i}^{u})\\|_{p}}\\\\ {\\leq}&{v\\eta)\\|\\mathcal{F}(x)-\\mathcal{F}(z)\\|_{p}]+v\\eta\\sqrt{\\frac{l n(4/\\gamma)}{2m}}}\\\\ {\\leq}&{(\\mathbb{E}_{(x,z)\\sim u}[\\|\\mathcal{F}(x)-\\mathcal{F}(z)\\|_{p}^{p}])^{1/p}+v\\eta\\sqrt{\\frac{l n(4/\\gamma)}{2m}}}\\\\ {=}&{\\eta+v\\eta\\sqrt{\\frac{l n(4/\\gamma)}{2m}};}\\end{array}\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "(2): with probability $1-\\gamma/4$ , there are ", "page_idx": 17}, {"type": "equation", "text": "$$\n-\\frac{1}{m}\\sum_{i=1}^{m}f(z_{i}^{u})+\\mathbb{E}_{z\\sim P_{o}}[f(z)]|=-\\frac{1}{m}\\sum_{i=1}^{m}f(z_{i}^{u})+\\mathbb{E}_{(x,z)\\sim u}[f(z)]\\leq M\\sqrt{\\frac{l n(4/\\gamma)}{2m}};\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "(3): with probability $1-\\gamma/4$ , there are ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\frac{1}{m}\\sum_{i=1}^{m}f(x_{i}^{u})-\\mathbb{E}_{x\\sim P_{a}}[f(x)]=\\frac{1}{m}\\sum_{i=1}^{m}f(x_{i}^{u})-\\mathbb{E}_{(x,z)\\sim u}[f(x)]\\leq M\\sqrt{\\frac{l n(4/\\gamma)}{2m}};\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "Let $\\{x_{i}\\}_{i=1}^{m}$ are i.i.d. samples from distribution $P_{a}$ , then, by Hoeffding inequality, we have that: (4): with probability $1-\\gamma/4$ , there are ", "page_idx": 18}, {"type": "equation", "text": "$$\n-{\\frac{1}{m}}\\sum_{i=1}^{m}f(x_{i})+\\mathbb{E}_{x\\sim P_{a}}[f(x)]\\leq M{\\sqrt{\\frac{l n(4/\\gamma)}{2m}}};\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "So, with probability $1-\\gamma$ makes that (1), (2), (3) and (4) stand, at this times, we can estimate the $\\begin{array}{r}{\\mathbb{E}_{z\\sim P_{o}}[f(z)]-\\frac{1}{m}\\sum_{i=1}^{m}{\\dot{f}}(x_{i})}\\end{array}$ , there are: ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{E}_{z\\sim P_{0}}[f(z)]}\\\\ {\\leq}&{\\frac{1}{m}\\sum_{i=1}^{m}f(z_{i}^{u})+M\\sqrt{\\frac{l n(4/\\gamma)}{2m}}}\\\\ {\\leq}&{\\frac{1}{m}\\sum_{i=1}^{m}f(x_{i}^{u})+|f(x_{i}^{u})-f(z_{i}^{u})|+M\\sqrt{\\frac{l n(4/\\gamma)}{2m}}}\\\\ {\\leq}&{\\frac{1}{m}\\sum_{i=1}^{m}f(x_{i}^{u})+\\epsilon\\|f(x_{i}^{u})-\\mathcal{F}(z_{i}^{u})\\|_{p}I(\\|\\mathcal{F}(x_{i}^{u})-\\mathcal{F}(z_{i}^{u})\\|_{p}\\leq v\\eta)}\\\\ &{+M I(\\|\\mathcal{F}(x_{i}^{u})-\\mathcal{F}(z_{i}^{u})\\|_{p}>v\\eta)+M\\sqrt{\\frac{l n(4/\\gamma)}{2m}}}\\\\ {\\leq}&{\\frac{1}{m}\\sum_{i=1}^{m}f(x_{i}^{u})+\\epsilon(\\eta+v\\eta\\sqrt{\\frac{l n(4/\\gamma)}{2m}})+\\frac{M}{v}+M\\sqrt{\\frac{l n(4/\\gamma)}{2m}}}\\\\ {\\leq}&{\\mathbb{E}_{x\\sim P_{0}}[f(x)]+\\epsilon(\\eta+v\\eta\\sqrt{\\frac{l n(4/\\gamma)}{2m}})+\\frac{M}{v}+2M\\sqrt{\\frac{l n(4/\\gamma)}{2m}}}\\\\ {\\leq}&{\\frac{1}{m}\\sum_{i=1}^{m}f(x_{i})+\\epsilon(\\eta+v\\eta\\sqrt{\\frac{l n(4/\\gamma)}{2m}})+\\frac{M}{v}+3M\\sqrt{\\frac{l n(4/\\gamma)}{2m}}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "We get our conclusion. ", "page_idx": 18}, {"type": "text", "text": "B Supplementary experimental results ", "text_level": 1, "page_idx": 18}, {"type": "text", "text": "In this section, we provide more experimental results. All of the experiments are conducted on NVIDIA Tesla V100 GPUs. ", "page_idx": 18}, {"type": "text", "text": "B.1 The performance in terms of mOA and RmCE ", "text_level": 1, "page_idx": 18}, {"type": "text", "text": "In this section, we present full results for corruption overall accuracy (mOA) and relative mCE (RmCE) [41]. The mOA is computed as the average OA over all corruptions. The RmCE quantifies the performance drop compared to a clean test set. We adopt the official baseline DGCNN and ", "page_idx": 18}, {"type": "text", "text": "Table B.1: Quantitative results of vanilla training, adversarial training and our proposed Frequency Adversarial Training (FAT) on the ModelNet-C test set. Our proposed FAT outperforms all other methods in terms of corruption overall accuracy (mOA), which demonstrates the effectiveness of FAT for improving corruption robustness. ", "page_idx": 18}, {"type": "table", "img_path": "4jn7KWPHSD/tmp/52cb2655d3bfcb8e8173a4c1843d991ea8b6adfee54afc54644cf2a16fde00a0.jpg", "table_caption": [], "table_footnote": [], "page_idx": 18}, {"type": "table", "img_path": "4jn7KWPHSD/tmp/a94806d8c3550b2e80ec6b5ef9fb81e2a5c1f1fa8dfcd81b7f139a194d374b9e.jpg", "table_caption": ["Table B.2: Quantitative results of vanilla training, adversarial training and our proposed Frequency Adversarial Training (FAT) on the ModelNet-C test set. Our proposed FAT outperforms all other methods in terms of relative mCE (RmCE), which demonstrates the effectiveness of FAT for improving corruption robustness. "], "table_footnote": [], "page_idx": 19}, {"type": "table", "img_path": "4jn7KWPHSD/tmp/275235b8184c52893bbe09b287518e56410a17d5c2fad0fe934bd253a985b941.jpg", "table_caption": ["Table B.3: Quantitative results of vanilla training and our proposed Frequency Adversarial Training (FAT) on the ModelNet40-C test set. Our proposed FAT outperforms other methods in terms of mCE, which demonstrates the effectiveness of FAT for improving corruption robustness. "], "table_footnote": [], "page_idx": 19}, {"type": "text", "text": "initially calculate the relative corruption error (RCE) for a given corruption type $i$ by averaging over 5 severity levels: l5=1 (lO=1A(cDlOeGaACncNleNan\u2212\u2212OOAAiD,ilG,lC)NN), where OAclean is the overall accuracy on the clean test set. Subsequently, we compute the relative mean corruption error $(\\mathrm{RmCE})$ by averaging over the 7 corruption types: $\\begin{array}{r}{\\mathrm{RmCE}=\\frac{1}{N}\\sum_{i=1}^{N}\\mathrm{RCE}_{i}}\\end{array}$ . In Tables B.1 and B.2, we compare different methods based on the mOA and RmCE metrics, confirming that our proposed FAT enhances the model\u2019s out-of-distribution generalization ability. ", "page_idx": 19}, {"type": "text", "text": "B.2 The performance on the ModelNet40-C ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "In this section, we evaluate the corruption robustness on ModelNet40-C [51]. The ModelNet40- C dataset is specifically designed to assess the network robustness against prevalent point cloud corruptions. It consists of 15 different corruption types, including \u201cUniform\u201d, \u201cGaussian\u201d, \u201cImpulse\u201d, \u201cUpsampling\u201d, \u201cBackground\u201d, \u201cOcclusion\u201d, \u201cLiDAR\u201d, \u201cLocal Density Inc\u201d, \u201cLocal Density Dec\u201d, \u201cCutout\u201d, \u201cRotation\u201d, \u201cShear\u201d, \u201cFFD\u201d, \u201cRBF\u201d, and \u201cInv RBF\u201d. Each type of corruption has 5 severity ", "page_idx": 19}, {"type": "text", "text": "Table B.4: Quantitative results of the performance of FAT when integrated with data augmentation strategy in terms of mCE and $\\mathrm{ER}_{\\mathrm{cor}}$ on the ModelNet40-C test set. In previous studies [51], PCT with CutMix-R achieves the best robustness with the $0.635~\\mathrm{mCE}$ and $0.163\\:\\mathrm{ER}_{\\mathrm{cor}}$ . However, training GDANet with the combination of our proposed FAT with WOLFMix achieves the new state-of-the-art performance, with the impressive 0.555 mCE and 0.147 $\\mathbf{ER_{cor}}$ . ", "page_idx": 19}, {"type": "table", "img_path": "4jn7KWPHSD/tmp/bcf83db4cbb1a95912fbb3d5d2e50a0cc8b69e9baca517f58054a5885c83bcbf.jpg", "table_caption": [], "table_footnote": [], "page_idx": 19}, {"type": "table", "img_path": "4jn7KWPHSD/tmp/005637abd4f0a9100adb17b3274fc73deb9d7f227641af70589c843be9b29e7d.jpg", "table_caption": ["Table B.5: Quantitative results of vanilla training, adversarial training, DUP Defense and our proposed Frequency Adversarial Training (FAT) on the ScanObjectNN-C test set. Our proposed FAT outperforms all other methods in terms of mean corruption error (mCE), which demonstrates the effectiveness of FAT for improving corruption robustness. "], "table_footnote": [], "page_idx": 20}, {"type": "table", "img_path": "4jn7KWPHSD/tmp/f316398498c858eec7e8ebc3274655f3cf499dc7dce516237ff6037d8b623e8d.jpg", "table_caption": ["Table B.6: Quantitative results of vanilla training, adversarial training, DUP Defense and our proposed Frequency Adversarial Training (FAT) on the PointNeXt on ModelNet-C. Our proposed FAT outperforms all other methods in terms of mean corruption error (mCE), which demonstrates the effectiveness of FAT for improving corruption robustness. "], "table_footnote": [], "page_idx": 20}, {"type": "text", "text": "levels. In Table B.3, we compare different methods on the ModelNet40-C test set, confirming that our proposed FAT enhances the OOD generalization ability of the model. ", "page_idx": 20}, {"type": "text", "text": "In Table B.4, we show the performance of FAT when integrated with data augmentation strategy in terms of $\\mathrm{mCE}$ and $\\mathrm{ER}_{\\mathrm{cor}}$ . In previous studies [51], PCT with CutMix-R achieves the best robustness with the $0.635~\\mathrm{mCE}$ and $0.163\\ \\mathrm{ER}_{\\mathrm{cor}}$ . However, training GDANet with the combination of our proposed FAT with WOLFMix achieves a new state-of-the-art performance, with the impressive $0.555\\;\\mathrm{mCE}$ and $0.147\\,\\mathrm{ER}_{\\mathrm{cor}}$ . ", "page_idx": 20}, {"type": "text", "text": "B.3 The performance on the ScanObjectNN-C ", "text_level": 1, "page_idx": 20}, {"type": "text", "text": "We further conduct experiments on the ScanObjectNN dataset, which is collected by LiDAR sensors and represents more realistic conditions under real-world scenarios [2, 58, 96, 94]. The experimental settings and evaluation metrics on ScanObjectNN-C [62] are consistent with those on ModelNet-C. The results are shown in Table B.5. It can be seen that our FAT generally leads to lower mCE on ScanObjectNN-C. The experimental results on ScanObjectNN-C further validate the generalizability and applicability of our FAT under real-world conditions. ", "page_idx": 20}, {"type": "text", "text": "B.4 The performance on the PointNeXt ", "text_level": 1, "page_idx": 20}, {"type": "text", "text": "We further conduct experiments for the updated point cloud model PointNeXt [37]. The results in Table B.5 and Table B.6 demonstrate that FAT achieves consistent performance on the advanced network architecture PointNeXt, similar to observations on PointNet and more. Our FAT outperforms all other methods in terms of mCE. This indicates that FAT\u2019s performance is largely independent of the underlying model architecture, making it applicable to both traditional and modern networks. ", "page_idx": 20}, {"type": "text", "text": "B.5 The performance in combination with AdaptPoint ", "text_level": 1, "page_idx": 20}, {"type": "text", "text": "We further conduct experiments for comparison with AdaptPoint [62] on ScanObjectNN-C. AdaptPoint follows the official experimental settings. The results are shown in Table B.7. It is evident that incorporating FAT achieves a lower mCE, indicating its superiority. ", "page_idx": 20}, {"type": "text", "text": "Table B.7: Quantitative results of combining FAT with AdaptPoint on ScanObjectNN-C. Compared with single AdaptPoint, the combination of FAT and AdaptPoint achieves a better mCE. ", "page_idx": 21}, {"type": "table", "img_path": "4jn7KWPHSD/tmp/96ab20f0a9d6a206333665432e77eb355feb8c2ec4a45ba87fb6117783357fcb.jpg", "table_caption": [], "table_footnote": [], "page_idx": 21}, {"type": "text", "text": "NeurIPS Paper Checklist ", "text_level": 1, "page_idx": 22}, {"type": "text", "text": "1. Claims ", "text_level": 1, "page_idx": 22}, {"type": "text", "text": "Question: Do the main claims made in the abstract and introduction accurately reflect the paper\u2019s contributions and scope? ", "page_idx": 22}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 22}, {"type": "text", "text": "Justification: Our paper supports the claims made in the abstract and introduction. ", "page_idx": 22}, {"type": "text", "text": "Guidelines: ", "page_idx": 22}, {"type": "text", "text": "\u2022 The answer NA means that the abstract and introduction do not include the claims made in the paper.   \n\u2022 The abstract and/or introduction should clearly state the claims made, including the contributions made in the paper and important assumptions and limitations. A No or NA answer to this question will not be perceived well by the reviewers.   \n\u2022 The claims made should match theoretical and experimental results, and reflect how much the results can be expected to generalize to other settings.   \n\u2022 It is fine to include aspirational goals as motivation as long as it is clear that these goals are not attained by the paper. ", "page_idx": 22}, {"type": "text", "text": "2. Limitations ", "text_level": 1, "page_idx": 22}, {"type": "text", "text": "Question: Does the paper discuss the limitations of the work performed by the authors? ", "page_idx": 22}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 22}, {"type": "text", "text": "Justification: We have discussed limitations in Section 5. ", "page_idx": 22}, {"type": "text", "text": "Guidelines: ", "page_idx": 22}, {"type": "text", "text": "\u2022 The answer NA means that the paper has no limitation while the answer No means that the paper has limitations, but those are not discussed in the paper.   \n\u2022 The authors are encouraged to create a separate \"Limitations\" section in their paper.   \n\u2022 The paper should point out any strong assumptions and how robust the results are to violations of these assumptions (e.g., independence assumptions, noiseless settings, model well-specification, asymptotic approximations only holding locally). The authors should reflect on how these assumptions might be violated in practice and what the implications would be.   \n\u2022 The authors should reflect on the scope of the claims made, e.g., if the approach was only tested on a few datasets or with a few runs. In general, empirical results often depend on implicit assumptions, which should be articulated.   \n\u2022 The authors should reflect on the factors that influence the performance of the approach. For example, a facial recognition algorithm may perform poorly when image resolution is low or images are taken in low lighting. Or a speech-to-text system might not be used reliably to provide closed captions for online lectures because it fails to handle technical jargon.   \n\u2022 The authors should discuss the computational efficiency of the proposed algorithms and how they scale with dataset size.   \n\u2022 If applicable, the authors should discuss possible limitations of their approach to address problems of privacy and fairness.   \n\u2022 While the authors might fear that complete honesty about limitations might be used by reviewers as grounds for rejection, a worse outcome might be that reviewers discover limitations that aren\u2019t acknowledged in the paper. The authors should use their best judgment and recognize that individual actions in favor of transparency play an important role in developing norms that preserve the integrity of the community. Reviewers will be specifically instructed to not penalize honesty concerning limitations. ", "page_idx": 22}, {"type": "text", "text": "3. Theory Assumptions and Proofs ", "text_level": 1, "page_idx": 22}, {"type": "text", "text": "Question: For each theoretical result, does the paper provide the full set of assumptions and a complete (and correct) proof? ", "page_idx": 22}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 22}, {"type": "text", "text": "Justification: We have provided the full set of assumptions in every theorem and made a complete proof in Appendix A. ", "page_idx": 23}, {"type": "text", "text": "Guidelines: ", "page_idx": 23}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include theoretical results.   \n\u2022 All the theorems, formulas, and proofs in the paper should be numbered and crossreferenced.   \n\u2022 All assumptions should be clearly stated or referenced in the statement of any theorems.   \n\u2022 The proofs can either appear in the main paper or the supplemental material, but if they appear in the supplemental material, the authors are encouraged to provide a short proof sketch to provide intuition.   \n\u2022 Inversely, any informal proof provided in the core of the paper should be complemented by formal proofs provided in appendix or supplemental material.   \n\u2022 Theorems and Lemmas that the proof relies upon should be properly referenced. ", "page_idx": 23}, {"type": "text", "text": "4. Experimental Result Reproducibility ", "text_level": 1, "page_idx": 23}, {"type": "text", "text": "Question: Does the paper fully disclose all the information needed to reproduce the main experimental results of the paper to the extent that it affects the main claims and/or conclusions of the paper (regardless of whether the code and data are provided or not)? ", "page_idx": 23}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 23}, {"type": "text", "text": "Justification: We have provided reproductive details in Section 4.1 and Appendix B. Guidelines: ", "page_idx": 23}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 If the paper includes experiments, a No answer to this question will not be perceived well by the reviewers: Making the paper reproducible is important, regardless of whether the code and data are provided or not.   \n\u2022 If the contribution is a dataset and/or model, the authors should describe the steps taken to make their results reproducible or verifiable.   \n\u2022 Depending on the contribution, reproducibility can be accomplished in various ways. For example, if the contribution is a novel architecture, describing the architecture fully might suffice, or if the contribution is a specific model and empirical evaluation, it may be necessary to either make it possible for others to replicate the model with the same dataset, or provide access to the model. In general. releasing code and data is often one good way to accomplish this, but reproducibility can also be provided via detailed instructions for how to replicate the results, access to a hosted model (e.g., in the case of a large language model), releasing of a model checkpoint, or other means that are appropriate to the research performed.   \n\u2022 While NeurIPS does not require releasing code, the conference does require all submissions to provide some reasonable avenue for reproducibility, which may depend on the nature of the contribution. For example (a) If the contribution is primarily a new algorithm, the paper should make it clear how to reproduce that algorithm. (b) If the contribution is primarily a new model architecture, the paper should describe the architecture clearly and fully. (c) If the contribution is a new model (e.g., a large language model), then there should either be a way to access this model for reproducing the results or a way to reproduce the model (e.g., with an open-source dataset or instructions for how to construct the dataset). (d) We recognize that reproducibility may be tricky in some cases, in which case authors are welcome to describe the particular way they provide for reproducibility. In the case of closed-source models, it may be that access to the model is limited in some way (e.g., to registered users), but it should be possible for other researchers to have some path to reproducing or verifying the results. ", "page_idx": 23}, {"type": "text", "text": "5. Open access to data and code ", "text_level": 1, "page_idx": 23}, {"type": "text", "text": "Question: Does the paper provide open access to the data and code, with sufficient instructions to faithfully reproduce the main experimental results, as described in supplemental material? ", "page_idx": 23}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 24}, {"type": "text", "text": "Justification: We have provided our codes in the supplemental matrial. Guidelines: ", "page_idx": 24}, {"type": "text", "text": "\u2022 The answer NA means that paper does not include experiments requiring code.   \n\u2022 Please see the NeurIPS code and data submission guidelines (https://nips.cc/ public/guides/CodeSubmissionPolicy) for more details.   \n\u2022 While we encourage the release of code and data, we understand that this might not be possible, so \u201cNo\u201d is an acceptable answer. Papers cannot be rejected simply for not including code, unless this is central to the contribution (e.g., for a new open-source benchmark).   \n\u2022 The instructions should contain the exact command and environment needed to run to reproduce the results. See the NeurIPS code and data submission guidelines (https: //nips.cc/public/guides/CodeSubmissionPolicy) for more details.   \n\u2022 The authors should provide instructions on data access and preparation, including how to access the raw data, preprocessed data, intermediate data, and generated data, etc.   \n\u2022 The authors should provide scripts to reproduce all experimental results for the new proposed method and baselines. If only a subset of experiments are reproducible, they should state which ones are omitted from the script and why.   \n\u2022 At submission time, to preserve anonymity, the authors should release anonymized versions (if applicable).   \n\u2022 Providing as much information as possible in supplemental material (appended to the paper) is recommended, but including URLs to data and code is permitted. ", "page_idx": 24}, {"type": "text", "text": "6. Experimental Setting/Details ", "text_level": 1, "page_idx": 24}, {"type": "text", "text": "Question: Does the paper specify all the training and test details (e.g., data splits, hyperparameters, how they were chosen, type of optimizer, etc.) necessary to understand the results? ", "page_idx": 24}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 24}, {"type": "text", "text": "Justification: We have provided experimental details in Section 4.1 and Appendix B. Guidelines: ", "page_idx": 24}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments. \u2022 The experimental setting should be presented in the core of the paper to a level of detail that is necessary to appreciate the results and make sense of them. \u2022 The full details can be provided either with the code, in appendix, or as supplemental material. ", "page_idx": 24}, {"type": "text", "text": "7. Experiment Statistical Significance ", "text_level": 1, "page_idx": 24}, {"type": "text", "text": "Question: Does the paper report error bars suitably and correctly defined or other appropriate information about the statistical significance of the experiments? ", "page_idx": 24}, {"type": "text", "text": "Answer: [No] ", "page_idx": 24}, {"type": "text", "text": "Justification: For fair comparison, we do not provide error bars because there are many baseline methods, it is computationally expensive to reproduce all of these methods. ", "page_idx": 24}, {"type": "text", "text": "Guidelines: ", "page_idx": 24}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 The authors should answer \"Yes\" if the results are accompanied by error bars, confidence intervals, or statistical significance tests, at least for the experiments that support the main claims of the paper.   \n\u2022 The factors of variability that the error bars are capturing should be clearly stated (for example, train/test split, initialization, random drawing of some parameter, or overall run with given experimental conditions).   \n\u2022 The method for calculating the error bars should be explained (closed form formula, call to a library function, bootstrap, etc.)   \n\u2022 The assumptions made should be given (e.g., Normally distributed errors).   \n\u2022 It should be clear whether the error bar is the standard deviation or the standard error of the mean.   \n\u2022 It is OK to report 1-sigma error bars, but one should state it. The authors should preferably report a 2-sigma error bar than state that they have a $96\\%$ CI, if the hypothesis of Normality of errors is not verified.   \n\u2022 For asymmetric distributions, the authors should be careful not to show in tables or figures symmetric error bars that would yield results that are out of range (e.g. negative error rates).   \n\u2022 If error bars are reported in tables or plots, The authors should explain in the text how they were calculated and reference the corresponding figures or tables in the text. ", "page_idx": 24}, {"type": "text", "text": "", "page_idx": 25}, {"type": "text", "text": "8. Experiments Compute Resources ", "text_level": 1, "page_idx": 25}, {"type": "text", "text": "Question: For each experiment, does the paper provide sufficient information on the computer resources (type of compute workers, memory, time of execution) needed to reproduce the experiments? ", "page_idx": 25}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 25}, {"type": "text", "text": "Justification: Justification: We have provided them in Appendix B. ", "page_idx": 25}, {"type": "text", "text": "Guidelines: ", "page_idx": 25}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 The paper should indicate the type of compute workers CPU or GPU, internal cluster, or cloud provider, including relevant memory and storage.   \n\u2022 The paper should provide the amount of compute required for each of the individual experimental runs as well as estimate the total compute.   \n\u2022 The paper should disclose whether the full research project required more compute than the experiments reported in the paper (e.g., preliminary or failed experiments that didn\u2019t make it into the paper). ", "page_idx": 25}, {"type": "text", "text": "9. Code Of Ethics ", "text_level": 1, "page_idx": 25}, {"type": "text", "text": "Question: Does the research conducted in the paper conform, in every respect, with the NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines? ", "page_idx": 25}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 25}, {"type": "text", "text": "Justification: Our paper conforms with the NeurIPS Code of Ethics. ", "page_idx": 25}, {"type": "text", "text": "Guidelines: ", "page_idx": 25}, {"type": "text", "text": "\u2022 The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics.   \n\u2022 If the authors answer No, they should explain the special circumstances that require a deviation from the Code of Ethics.   \n\u2022 The authors should make sure to preserve anonymity (e.g., if there is a special consideration due to laws or regulations in their jurisdiction). ", "page_idx": 25}, {"type": "text", "text": "10. Broader Impacts ", "text_level": 1, "page_idx": 25}, {"type": "text", "text": "Question: Does the paper discuss both potential positive societal impacts and negative societal impacts of the work performed? ", "page_idx": 25}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 25}, {"type": "text", "text": "Justification: We have discussed them in Appendix 5. ", "page_idx": 25}, {"type": "text", "text": "Guidelines: ", "page_idx": 25}, {"type": "text", "text": "\u2022 The answer NA means that there is no societal impact of the work performed.   \n\u2022 If the authors answer NA or No, they should explain why their work has no societal impact or why the paper does not address societal impact.   \n\u2022 Examples of negative societal impacts include potential malicious or unintended uses (e.g., disinformation, generating fake profiles, surveillance), fairness considerations (e.g., deployment of technologies that could make decisions that unfairly impact specific groups), privacy considerations, and security considerations.   \n\u2022 The conference expects that many papers will be foundational research and not tied to particular applications, let alone deployments. However, if there is a direct path to any negative applications, the authors should point it out. For example, it is legitimate to point out that an improvement in the quality of generative models could be used to generate deepfakes for disinformation. On the other hand, it is not needed to point out that a generic algorithm for optimizing neural networks could enable people to train models that generate Deepfakes faster.   \n\u2022 The authors should consider possible harms that could arise when the technology is being used as intended and functioning correctly, harms that could arise when the technology is being used as intended but gives incorrect results, and harms following from (intentional or unintentional) misuse of the technology.   \n\u2022 If there are negative societal impacts, the authors could also discuss possible mitigation strategies (e.g., gated release of models, providing defenses in addition to attacks, mechanisms for monitoring misuse, mechanisms to monitor how a system learns from feedback over time, improving the efficiency and accessibility of ML). ", "page_idx": 25}, {"type": "text", "text": "", "page_idx": 26}, {"type": "text", "text": "11. Safeguards ", "text_level": 1, "page_idx": 26}, {"type": "text", "text": "Question: Does the paper describe safeguards that have been put in place for responsible release of data or models that have a high risk for misuse (e.g., pretrained language models, image generators, or scraped datasets)? ", "page_idx": 26}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 26}, {"type": "text", "text": "Justification: Our paper poses no such risks. ", "page_idx": 26}, {"type": "text", "text": "Guidelines: ", "page_idx": 26}, {"type": "text", "text": "\u2022 The answer NA means that the paper poses no such risks.   \n\u2022 Released models that have a high risk for misuse or dual-use should be released with necessary safeguards to allow for controlled use of the model, for example by requiring that users adhere to usage guidelines or restrictions to access the model or implementing safety filters.   \n\u2022 Datasets that have been scraped from the Internet could pose safety risks. The authors should describe how they avoided releasing unsafe images.   \n\u2022 We recognize that providing effective safeguards is challenging, and many papers do not require this, but we encourage authors to take this into account and make a best faith effort. ", "page_idx": 26}, {"type": "text", "text": "12. Licenses for existing assets ", "text_level": 1, "page_idx": 26}, {"type": "text", "text": "Question: Are the creators or original owners of assets (e.g., code, data, models), used in the paper, properly credited and are the license and terms of use explicitly mentioned and properly respected? ", "page_idx": 26}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 26}, {"type": "text", "text": "Justification: We use open-source dataset and models in our paper, and have cited the original paper of these dataset and models. ", "page_idx": 26}, {"type": "text", "text": "Guidelines: ", "page_idx": 26}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not use existing assets.   \n\u2022 The authors should cite the original paper that produced the code package or dataset.   \n\u2022 The authors should state which version of the asset is used and, if possible, include a URL.   \n\u2022 The name of the license (e.g., CC-BY 4.0) should be included for each asset.   \n\u2022 For scraped data from a particular source (e.g., website), the copyright and terms of service of that source should be provided.   \n\u2022 If assets are released, the license, copyright information, and terms of use in the package should be provided. For popular datasets, paperswithcode.com/datasets has curated licenses for some datasets. Their licensing guide can help determine the license of a dataset.   \n\u2022 For existing datasets that are re-packaged, both the original license and the license of the derived asset (if it has changed) should be provided. ", "page_idx": 26}, {"type": "text", "text": "\u2022 If this information is not available online, the authors are encouraged to reach out to the asset\u2019s creators. ", "page_idx": 27}, {"type": "text", "text": "13. New Assets ", "text_level": 1, "page_idx": 27}, {"type": "text", "text": "Question: Are new assets introduced in the paper well documented and is the documentation provided alongside the assets? ", "page_idx": 27}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 27}, {"type": "text", "text": "Justification: Our paper does not release new assets. ", "page_idx": 27}, {"type": "text", "text": "Guidelines: ", "page_idx": 27}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not release new assets.   \n\u2022 Researchers should communicate the details of the dataset/code/model as part of their submissions via structured templates. This includes details about training, license, limitations, etc.   \n\u2022 The paper should discuss whether and how consent was obtained from people whose asset is used.   \n\u2022 At submission time, remember to anonymize your assets (if applicable). You can either create an anonymized URL or include an anonymized zip file. ", "page_idx": 27}, {"type": "text", "text": "14. Crowdsourcing and Research with Human Subjects ", "text_level": 1, "page_idx": 27}, {"type": "text", "text": "Question: For crowdsourcing experiments and research with human subjects, does the paper include the full text of instructions given to participants and screenshots, if applicable, as well as details about compensation (if any)? ", "page_idx": 27}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 27}, {"type": "text", "text": "Justification: Our paper does not involve crowdsourcing nor research with human subjects. Guidelines: ", "page_idx": 27}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u2022 Including this information in the supplemental material is fine, but if the main contribution of the paper involves human subjects, then as much detail as possible should be included in the main paper.   \n\u2022 According to the NeurIPS Code of Ethics, workers involved in data collection, curation, or other labor should be paid at least the minimum wage in the country of the data collector. ", "page_idx": 27}, {"type": "text", "text": "15. Institutional Review Board (IRB) Approvals or Equivalent for Research with Human Subjects ", "text_level": 1, "page_idx": 27}, {"type": "text", "text": "Question: Does the paper describe potential risks incurred by study participants, whether such risks were disclosed to the subjects, and whether Institutional Review Board (IRB) approvals (or an equivalent approval/review based on the requirements of your country or institution) were obtained? ", "page_idx": 27}, {"type": "text", "text": "Answer: [NA] ", "text_level": 1, "page_idx": 27}, {"type": "text", "text": "Justification: Our paper does not involve crowdsourcing nor research with human subjects. Guidelines: ", "page_idx": 27}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u2022 Depending on the country in which research is conducted, IRB approval (or equivalent) may be required for any human subjects research. If you obtained IRB approval, you should clearly state this in the paper.   \n\u2022 We recognize that the procedures for this may vary significantly between institutions and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the guidelines for their institution.   \n\u2022 For initial submissions, do not include any information that would break anonymity (if applicable), such as the institution conducting the review. ", "page_idx": 27}]