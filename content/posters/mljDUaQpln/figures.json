[{"figure_path": "mljDUaQpln/figures/figures_1_1.jpg", "caption": "Figure 1: The performance gains to LLaMA-3.1-70B by Additional Logic Training (ALT) on the proposed synthetic corpus, FLD\u00d72 (Formal Logic Deduction Diverse). Each benchmark set, such as \"Logic\" and \"Math\", comprises various benchmarks in that domain. Tables 2, 4 shows the details.", "description": "This figure displays the performance improvement achieved by incorporating Additional Logic Training (ALT) using the Formal Logic Deduction Diverse (FLD\u00d72) corpus into the LLaMA-3.1-70B large language model.  The improvements are shown across various benchmark sets categorized as Logic, Math, Code, NLI (Natural Language Inference), and Others.  Each category includes several individual benchmarks (detailed in Tables 2 and 4 of the paper). The bar chart illustrates the performance gains in terms of percentage points compared to the original LLaMA model before ALT training.  The results show substantial improvements across multiple domains.", "section": "1 Introduction"}, {"figure_path": "mljDUaQpln/figures/figures_2_1.jpg", "caption": "Figure 2: Our proposed Additional Logic Training (ALT) aims to enhance LLMs' reasoning capabilities through training on many synthetically generated logical reasoning samples. Our sample generator (left) first generates a sample of multi-step deductive reasoning and then converts it into a deduction sample written in English (right). LLMs must generate logical steps to derive a given hypothesis from provided facts. The sample generator adheres to theoretically and empirically grounded design principles discussed in Section 2. Refer to Figure D.3 for a real sample.", "description": "This figure illustrates the process of Additional Logic Training (ALT).  The left side shows a sample generator that creates multi-step deductive reasoning samples using symbolic logic. This generator follows design principles to ensure high-quality samples (e.g., including unknown facts, diverse rules, etc.).  The right side demonstrates how these samples are presented to LLMs. LLMs receive facts and a hypothesis and must generate a series of logical steps to prove or disprove the hypothesis.  The figure highlights the overall ALT approach and the structure of the synthetic logic samples.", "section": "2 How Should Synthetic Logic Samples Be Designed?"}, {"figure_path": "mljDUaQpln/figures/figures_8_1.jpg", "caption": "Figure 1: The performance gains to LLaMA-3.1-70B by Additional Logic Training (ALT) on the proposed synthetic corpus, FLD\u00d72 (Formal Logic Deduction Diverse). Each benchmark set, such as \"Logic\" and \"Math\", comprises various benchmarks in that domain. Tables 2, 4 shows the details.", "description": "This figure shows the performance improvement achieved by using Additional Logic Training (ALT) with the synthetic logic corpus FLDx2 on the LLaMA-3.1-70B large language model.  The improvements are presented across various benchmark categories (Logic, Math, Code, NLI, and Others) and are visually represented using bar charts. The figure highlights the substantial gains obtained through ALT on FLDx2 compared to the baseline performance of LLaMA-3.1-70B.", "section": "1 Introduction"}, {"figure_path": "mljDUaQpln/figures/figures_22_1.jpg", "caption": "Figure 2: Our proposed Additional Logic Training (ALT) aims to enhance LLMs' reasoning capabilities through training on many synthetically generated logical reasoning samples. Our sample generator (left) first generates a sample of multi-step deductive reasoning and then converts it into a deduction sample written in English (right). LLMs must generate logical steps to derive a given hypothesis from provided facts. The sample generator adheres to theoretically and empirically grounded design principles discussed in Section 2. Refer to Figure D.3 for a real sample.", "description": "This figure illustrates the Additional Logic Training (ALT) method proposed in the paper.  ALT aims to improve LLMs' reasoning by training them on synthetically generated logical reasoning samples. The figure's left side shows how a sample generator creates a multi-step deductive reasoning sample using logical formulas. This sample is then converted into an English-language deduction sample (right side).  The sample, presented to an LLM, requires the model to derive a given hypothesis from provided facts by generating the necessary logical steps.  The generator follows design principles discussed earlier in the paper to ensure high-quality samples.", "section": "2 How Should Synthetic Logic Samples Be Designed?"}]