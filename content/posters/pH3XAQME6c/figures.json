[{"figure_path": "pH3XAQME6c/figures/figures_1_1.jpg", "caption": "Figure 1: Ablating the \"refusal direction\" reduces refusal rates and elicits unsafe completions. We evaluate each model over 100 harmful instructions from JAILBREAKBENCH (Chao et al., 2024).", "description": "This figure shows the results of ablating the identified \"refusal direction\" from 13 different large language models.  The x-axis represents the different models, while the y-axis shows the refusal and safety scores. The bars are grouped into three conditions: no intervention, directional ablation (where the refusal direction is removed), and directional addition (where the refusal direction is added).  The results demonstrate that ablating the refusal direction significantly reduces the model's ability to refuse harmful instructions, leading to an increase in unsafe completions, while adding it causes refusal even on harmless instructions.", "section": "3 Refusal is mediated by a single direction"}, {"figure_path": "pH3XAQME6c/figures/figures_4_1.jpg", "caption": "Figure 3: Adding the \u201crefusal direction\u201d induces refusal on 100 harmless instructions from ALPACA.", "description": "This figure shows the results of adding the identified \"refusal direction\" to the residual stream activations of harmless instructions across 13 different large language models.  The addition of this direction consistently caused the models to refuse to generate a response, even for benign prompts. The y-axis represents the refusal score (proportion of responses classified as refusals), while the x-axis shows the different models tested, ranging in size from 1.8B to 72B parameters. The orange bars represent the baseline refusal rate (without intervention), and the light blue bars show the refusal rate after adding the \"refusal direction.\"", "section": "3 Refusal is mediated by a single direction"}, {"figure_path": "pH3XAQME6c/figures/figures_4_2.jpg", "caption": "Figure 3: Adding the \u201crefusal direction\u201d induces refusal on 100 harmless instructions from ALPACA.", "description": "This figure shows the results of adding the identified \"refusal direction\" to the residual stream activations of harmless prompts.  The experiment involved 100 harmless instructions from the ALPACA dataset.  The chart displays the refusal score (the likelihood the model refuses to answer) for each of 13 different language models after the \"refusal direction\" has been added.  The results show that adding this direction causes the models to refuse to respond to the harmless prompts, even though they would have previously answered them without issue.", "section": "3 Refusal is mediated by a single direction"}, {"figure_path": "pH3XAQME6c/figures/figures_7_1.jpg", "caption": "Figure 5: Cosine similarity between last token residual stream activations and refusal direction. ", "description": "This figure displays cosine similarity between the last token's residual stream activations and the refusal direction across different layers for four conditions: harmful instructions, harmful instructions with a random suffix, harmful instructions with an adversarial suffix, and harmless instructions.  It demonstrates that the expression of the refusal direction is high for harmful instructions and remains high with a random suffix. However, appending the adversarial suffix substantially suppresses the refusal direction, making it closely resemble the expression for harmless instructions. This visually supports the paper's claim that adversarial suffixes effectively suppress the refusal-mediating direction.", "section": "Mechanistic analysis of adversarial suffixes"}, {"figure_path": "pH3XAQME6c/figures/figures_7_2.jpg", "caption": "Figure 6: We analyze the top eight attention heads that most significantly write to the refusal direction. Figure 6(a) shows that output to the refusal direction is heavily suppressed when the adversarial suffix is appended. Figure 6(b) reveals that, compared to appending a random suffix, appending the adversarial suffix shifts attention from tokens in the instruction region to tokens in the suffix region.", "description": "This figure analyzes the effect of adversarial suffixes on the attention heads of a language model. The top eight attention heads that contribute most to the refusal direction are examined.  When an adversarial suffix is added, the figure shows a significant decrease in the output projection onto the refusal direction.  Further, the attention shifts from the instruction region to the suffix region. This supports the theory that the adversarial suffix works by suppressing the propagation of the refusal-mediating direction.", "section": "Mechanistic analysis of adversarial suffixes"}, {"figure_path": "pH3XAQME6c/figures/figures_7_3.jpg", "caption": "Figure 6: We analyze the top eight attention heads that most significantly write to the refusal direction. Figure 6(a) shows that output to the refusal direction is heavily suppressed when the adversarial suffix is appended. Figure 6(b) reveals that, compared to appending a random suffix, appending the adversarial suffix shifts attention from tokens in the instruction region to tokens in the suffix region.", "description": "This figure shows the effect of adversarial suffixes on the attention mechanism of a language model. The left panel shows the attention weights from the last token to other tokens when a random suffix is appended, while the right panel shows the same when an adversarial suffix is appended. The results show that the adversarial suffix causes the attention mechanism to shift its focus from the instruction to the suffix, which helps bypass the model's safety mechanisms and elicit harmful responses.", "section": "Mechanistic analysis of adversarial suffixes"}, {"figure_path": "pH3XAQME6c/figures/figures_17_1.jpg", "caption": "Figure 1: Ablating the \"refusal direction\" reduces refusal rates and elicits unsafe completions. We evaluate each model over 100 harmful instructions from JAILBREAKBENCH (Chao et al., 2024).", "description": "This figure shows the results of ablating the \"refusal direction\" on 13 different large language models.  The x-axis represents the different models, and the y-axis represents the scores for refusal and safety.  The bars show that ablating the direction significantly reduces the model's refusal rate, but simultaneously increases the rate of unsafe completions. This demonstrates that the refusal mechanism is strongly tied to this single direction in the model's activation space.", "section": "3 Refusal is mediated by a single direction"}, {"figure_path": "pH3XAQME6c/figures/figures_18_1.jpg", "caption": "Figure 1: Ablating the \"refusal direction\" reduces refusal rates and elicits unsafe completions. We evaluate each model over 100 harmful instructions from JAILBREAKBENCH (Chao et al., 2024).", "description": "This figure shows the results of ablating the \"refusal direction\" from 13 different language models.  The x-axis represents the different models, and the y-axis represents the refusal score and safety score. The bars show that when the refusal direction is ablated (removed), the refusal rate decreases significantly, and the safety rate decreases (meaning more unsafe completions are generated). This demonstrates that the refusal mechanism is highly dependent on this single direction in the model's activation space.", "section": "3 Refusal is mediated by a single direction"}, {"figure_path": "pH3XAQME6c/figures/figures_19_1.jpg", "caption": "Figure 10: The refusal metric separates harmful and harmless instructions for GEMMA 2B IT. Refusals generally begin with token 234285 (corresponding to \u2018I\u2019). Setting RGEMMA = {234285} yields a refusal metric that is an efficient proxy for assessing whether the model will refuse.", "description": "This figure shows two histograms: one for harmful instructions and one for harmless instructions.  The x-axis represents the refusal metric, which is a log-odds score indicating the likelihood of the model refusing to answer a given instruction. The y-axis represents the frequency of instructions falling into each refusal metric bin. The distributions are clearly separated, indicating the refusal metric effectively distinguishes between harmful and harmless prompts.  Specifically, a high refusal metric suggests a high probability of the model's refusal.", "section": "2.5 Evaluation of refusal and harmfulness"}, {"figure_path": "pH3XAQME6c/figures/figures_21_1.jpg", "caption": "Figure 1: Ablating the \"refusal direction\" reduces refusal rates and elicits unsafe completions. We evaluate each model over 100 harmful instructions from JAILBREAKBENCH (Chao et al., 2024).", "description": "This figure shows the results of ablating the \"refusal direction\" in 13 different language models. The x-axis represents the different models, and the y-axis shows the refusal score and safety score. The blue bars represent the refusal score without any intervention, the orange bars represent the safety score without any intervention, the green bars represent the refusal score after ablating the \"refusal direction\", and the purple bars represent the safety score after ablating the \"refusal direction\". As you can see, ablating the \"refusal direction\" significantly reduces the refusal rate and increases the safety score. This suggests that the \"refusal direction\" plays a crucial role in the models' refusal behavior.", "section": "3 Refusal is mediated by a single direction"}, {"figure_path": "pH3XAQME6c/figures/figures_22_1.jpg", "caption": "Figure 1: Ablating the \"refusal direction\" reduces refusal rates and elicits unsafe completions. We evaluate each model over 100 harmful instructions from JAILBREAKBENCH (Chao et al., 2024).", "description": "This figure displays the results of ablating the refusal direction on 13 different language models.  The x-axis represents the different models tested, and the y-axis shows the refusal score and safety score. The \"No intervention\" bars show the baseline performance of the models when presented with harmful instructions.  The \"Directional ablation\" bars show the results after removing the identified \"refusal direction\". The figure demonstrates that removing this direction significantly reduces the models' ability to refuse harmful instructions, while simultaneously increasing the likelihood of unsafe responses.", "section": "3 Refusal is mediated by a single direction"}, {"figure_path": "pH3XAQME6c/figures/figures_23_1.jpg", "caption": "Figure 1: Ablating the \"refusal direction\" reduces refusal rates and elicits unsafe completions. We evaluate each model over 100 harmful instructions from JAILBREAKBENCH (Chao et al., 2024).", "description": "This figure displays the results of ablating the \"refusal direction\" from 13 different language models.  The x-axis shows the different models, categorized by size and family (e.g., Qwen 7B, Llama-2 70B). The y-axis represents the score, split into refusal score and safety score.  The bars are grouped by condition: no intervention (baseline), directional ablation (refusal direction removed), and directional addition (refusal direction added).  The results show that ablating the refusal direction significantly reduces the refusal rate (the models are less likely to refuse harmful instructions) and increases unsafe completions (the models are more likely to generate harmful text).  This demonstrates the critical role of the \"refusal direction\" in mediating the models' refusal behavior.", "section": "3 Refusal is mediated by a single direction"}, {"figure_path": "pH3XAQME6c/figures/figures_24_1.jpg", "caption": "Figure 1: Ablating the \"refusal direction\" reduces refusal rates and elicits unsafe completions. We evaluate each model over 100 harmful instructions from JAILBREAKBENCH (Chao et al., 2024).", "description": "The figure shows the results of ablating the \"refusal direction\" on 13 different language models when given 100 harmful instructions from the JAILBREAKBENCH dataset. Ablation of this direction significantly reduces the model's refusal rate, while simultaneously increasing the rate of unsafe completions. This demonstrates that the \"refusal direction\" is a critical component of the models' safety mechanisms.", "section": "3 Refusal is mediated by a single direction"}, {"figure_path": "pH3XAQME6c/figures/figures_29_1.jpg", "caption": "Figure 1: Ablating the \"refusal direction\" reduces refusal rates and elicits unsafe completions. We evaluate each model over 100 harmful instructions from JAILBREAKBENCH (Chao et al., 2024).", "description": "This figure shows the results of ablating the \"refusal direction\" on 13 different language models.  The x-axis represents the different models tested, and the y-axis shows the scores for refusal and safety. The bars show that when the refusal direction is removed, the models refuse harmful instructions less frequently and produce unsafe responses more frequently. This illustrates that the \"refusal direction\" plays a key role in the models' refusal behavior.", "section": "3 Refusal is mediated by a single direction"}, {"figure_path": "pH3XAQME6c/figures/figures_31_1.jpg", "caption": "Figure 22: A visualization of activation addition (abbreviated as \u201cact add\u201d) in the negative refusal direction. The intervention pulls harmful activations towards harmless activations, effectively bypassing refusal. However, note that the intervention pushes harmless activations far out of distribution. This figure displays activations from GEMMA 7B IT, computed over 128 harmful and harmless prompts.", "description": "This figure visualizes the effect of activation addition in the negative refusal direction on the cosine similarity with the refusal direction across different layers of the GEMMA 7B IT model.  It shows how activation addition moves harmful activations closer to harmless activations which effectively bypasses the refusal mechanism. However, it also highlights a drawback of this method which is that it pushes harmless activations further out of their normal distribution.", "section": "I.1 Comparison to activation addition"}, {"figure_path": "pH3XAQME6c/figures/figures_32_1.jpg", "caption": "Figure 3: Adding the \u201crefusal direction\u201d induces refusal on 100 harmless instructions from ALPACA.", "description": "This figure shows the results of adding the identified \"refusal direction\" to the residual stream activations of harmless instructions across 13 different open-source large language models.  The y-axis represents the refusal score (ranging from 0 to 1), while the x-axis shows the different models.  Each bar represents a model, and the bars are grouped to show the results under three conditions: no intervention, activation addition (where the refusal direction was added), and directional ablation (where the refusal direction was removed).  The key observation is that activation addition significantly increases the refusal rate even on harmless prompts, indicating that the \"refusal direction\" is a causal mediator of refusal behavior.  The error bars represent the standard error.", "section": "3 Refusal is mediated by a single direction"}, {"figure_path": "pH3XAQME6c/figures/figures_33_1.jpg", "caption": "Figure 1: Ablating the \"refusal direction\" reduces refusal rates and elicits unsafe completions. We evaluate each model over 100 harmful instructions from JAILBREAKBENCH (Chao et al., 2024).", "description": "This figure shows the results of ablating the \"refusal direction\" from 13 different language models.  The x-axis represents the different language models, and the y-axis represents the refusal and safety scores. Ablation of the refusal direction significantly reduces the model's refusal rate (leading to lower refusal scores) and increases the generation of unsafe content (resulting in higher safety scores).  This demonstrates that the refusal mechanism is strongly linked to the identified direction within these models.", "section": "3 Refusal is mediated by a single direction"}, {"figure_path": "pH3XAQME6c/figures/figures_35_1.jpg", "caption": "Figure 1: Ablating the \"refusal direction\" reduces refusal rates and elicits unsafe completions. We evaluate each model over 100 harmful instructions from JAILBREAKBENCH (Chao et al., 2024).", "description": "This figure shows the results of ablating the \"refusal direction\" from 13 different language models.  The x-axis represents the different language models, while the y-axis shows the refusal and safety scores. The bars are grouped into three conditions: no intervention, directional ablation, and activation addition. Directional ablation significantly reduces the refusal rate (making the models less likely to refuse harmful prompts), while the safety score decreases, indicating that unsafe completions are more frequent. The figure demonstrates that the refusal mechanism in these models is strongly tied to this specific direction.", "section": "3 Refusal is mediated by a single direction"}, {"figure_path": "pH3XAQME6c/figures/figures_36_1.jpg", "caption": "Figure 1: Ablating the \"refusal direction\" reduces refusal rates and elicits unsafe completions. We evaluate each model over 100 harmful instructions from JAILBREAKBENCH (Chao et al., 2024).", "description": "This figure displays the results of an ablation study on 13 different language models.  The \"refusal direction\"\u2014a single vector identified within the model's internal representations\u2014was removed (ablated) from the model's residual stream activations. Ablation of this direction resulted in a significant decrease in the model's refusal rate when given harmful instructions, simultaneously increasing the rate of unsafe completions. This indicates that the identified direction is crucial for the models' refusal mechanism.", "section": "3 Refusal is mediated by a single direction"}, {"figure_path": "pH3XAQME6c/figures/figures_37_1.jpg", "caption": "Figure 1: Ablating the \"refusal direction\" reduces refusal rates and elicits unsafe completions. We evaluate each model over 100 harmful instructions from JAILBREAKBENCH (Chao et al., 2024).", "description": "This figure displays the results of ablating the \"refusal direction\" from 13 different language models.  The x-axis represents each model, and the y-axis shows the refusal rate and safety score. The bars are separated into three groups: no intervention, directional ablation, and activation addition.  The results demonstrate that removing the refusal direction significantly reduces the model's ability to refuse harmful instructions and leads to unsafe completions.  Conversely, adding the refusal direction causes refusal even on harmless instructions. This highlights the critical role of the identified direction in mediating the models' refusal behavior.", "section": "3 Refusal is mediated by a single direction"}]