[{"figure_path": "vieIamY2Gi/tables/tables_6_1.jpg", "caption": "Table 1: Log-partition function estimation errors for unconditional modeling tasks (mean and standard deviation over 5 runs). The four groups of models are: MCMC-based samplers, simulation-driven variational methods, baseline GFlowNet methods with different learning objectives, and methods augmented with Langevin parametrization and local search. See \u00a7C.1 for additional metrics.", "description": "This table presents the results of log-partition function estimation for four different types of energy functions using various sampling methods.  The methods are grouped into MCMC-based samplers, simulation-driven variational methods, baseline GFlowNets, and GFlowNets with enhancements (Langevin parametrization and local search).  The table shows the mean and standard deviation over 5 runs for each method and energy function.  Additional metrics can be found in section C.1 of the paper.", "section": "5.2 Results"}, {"figure_path": "vieIamY2Gi/tables/tables_8_1.jpg", "caption": "Table 1: Log-partition function estimation errors for unconditional modeling tasks (mean and standard deviation over 5 runs). The four groups of models are: MCMC-based samplers, simulation-driven variational methods, baseline GFlowNet methods with different learning objectives, and methods augmented with Langevin parametrization and local search. See \u00a7C.1 for additional metrics.", "description": "This table presents the results of log-partition function estimation for four groups of models on unconditional modeling tasks.  The models are compared using mean and standard deviation of the error over 5 runs.  The four groups of models are MCMC-based samplers, simulation-driven variational methods, baseline GFlowNets, and GFlowNets enhanced with Langevin parametrization and local search. Additional metrics are detailed in section C.1 of the paper.", "section": "5.2 Results"}, {"figure_path": "vieIamY2Gi/tables/tables_18_1.jpg", "caption": "Table 1: Log-partition function estimation errors for unconditional modeling tasks (mean and standard deviation over 5 runs). The four groups of models are: MCMC-based samplers, simulation-driven variational methods, baseline GFlowNet methods with different learning objectives, and methods augmented with Langevin parametrization and local search. See \u00a7C.1 for additional metrics.", "description": "This table presents the results of log-partition function estimation for four different types of models on four different datasets.  It compares MCMC methods, simulation-based variational inference methods, and GFlowNet methods (with and without enhancements like Langevin parametrization and local search).  The table shows the mean and standard deviation of the log-partition function estimate over five runs for each method and dataset.  Additional metrics are available in section C.1 of the paper.", "section": "5.2 Results"}, {"figure_path": "vieIamY2Gi/tables/tables_18_2.jpg", "caption": "Table C.1: Log-partition function estimation errors and 2-Wasserstein distances for unconditional modeling tasks (mean and standard deviation over 5 runs). The four groups of models are: MCMC-based samplers, simulation-driven variational methods, baseline GFlowNet methods with different learning objectives, and methods augmented with Langevin parametrization and local search.", "description": "This table presents a comprehensive comparison of various sampling methods' performance on four different tasks: 25GMM, Funnel, Manywell, and LGCP. The methods are categorized into four groups: MCMC-based samplers, simulation-driven variational methods, GFlowNet methods with different objectives, and enhanced GFlowNet methods incorporating Langevin parametrization and local search.  The table shows the log-partition function estimation errors (both standard and importance-weighted) and the 2-Wasserstein distance, offering a multi-faceted evaluation of each method's sampling accuracy and efficiency.", "section": "C.1 Expanded unconditional sampling results"}, {"figure_path": "vieIamY2Gi/tables/tables_19_1.jpg", "caption": "Table C.3: Scaling with dimension on Manywell: log-partition function estimation errors and time per training iteration on a RTX8000 GPU.", "description": "This table presents the results of a scalability study conducted on the Manywell energy function, evaluating the performance of various samplers across different dimensions (d = 8, 32, 128, 512).  The metrics presented include the log-partition function estimation error (both standard and importance weighted), and the time per training iteration on a RTX8000 GPU. This allows assessing how the performance and computational cost of different approaches scale as dimensionality increases.", "section": "C.3 Scalability study"}, {"figure_path": "vieIamY2Gi/tables/tables_21_1.jpg", "caption": "Table 1: Log-partition function estimation errors for unconditional modeling tasks (mean and standard deviation over 5 runs). The four groups of models are: MCMC-based samplers, simulation-driven variational methods, baseline GFlowNet methods with different learning objectives, and methods augmented with Langevin parametrization and local search. See \u00a7C.1 for additional metrics.", "description": "This table presents the results of log-partition function estimation for four different types of models on four different tasks.  The models are categorized into MCMC-based samplers, simulation-driven variational methods, baseline GFlowNets, and GFlowNets with enhancements.  The tasks are 2D Gaussian Mixture Model, 10D Funnel, 32D Manywell, and 1600D Log-Gaussian Cox Process.  The table shows mean and standard deviation over 5 runs for each model and task. Additional metrics are available in section C.1.", "section": "5.2 Results"}, {"figure_path": "vieIamY2Gi/tables/tables_23_1.jpg", "caption": "Table 1: Log-partition function estimation errors for unconditional modeling tasks (mean and standard deviation over 5 runs). The four groups of models are: MCMC-based samplers, simulation-driven variational methods, baseline GFlowNet methods with different learning objectives, and methods augmented with Langevin parametrization and local search. See \u00a7C.1 for additional metrics.", "description": "This table presents the log-partition function estimation errors for four groups of models on unconditional modeling tasks.  The models are compared using mean and standard deviation over 5 runs.  The four model groups are MCMC-based samplers, simulation-driven variational methods, baseline GFlowNet methods (with different learning objectives), and GFlowNet methods augmented with Langevin parametrization and local search.  Additional metrics are available in section C.1 of the paper.", "section": "5.2 Results"}]