[{"figure_path": "NU54MoKWlA/figures/figures_0_1.jpg", "caption": "Figure 1: Results of motion sequence transfer (left) and shape variation generation (right) using the proposed neural pose representation. On the left, poses from source shapes (first and third rows) are transferred to target shapes (second and fourth rows), preserving intricate details like horns and antlers. On the right, new poses sampled from a cascaded diffusion model, trained with shape variations of the bunny (last column), are transferred to other animal shapes.", "description": "This figure demonstrates the results of the proposed method for transferring poses and generating shape variations. The left side shows pose transfer where poses from source animal shapes are successfully transferred to different target animal shapes, maintaining detailed features such as horns and antlers. The right side illustrates the shape variation generation where new poses are sampled from a diffusion model trained on a single bunny and applied to various other animals.  This showcases the method's ability to disentangle pose from identity and transfer pose information between different animal shapes.", "section": "Introduction"}, {"figure_path": "NU54MoKWlA/figures/figures_2_1.jpg", "caption": "Figure 2: Method overview. Our framework extracts keypoint-based hybrid pose representations from Jacobian fields. These fields are mapped by the pose extractor g and mapped back by the pose applier h. The pose applier, conditioned on the extracted pose, acts as an implicit deformation field for various shapes, including those unseen during training. A refinement module \u03b1, positioned between g and h, is trained in a self-supervised manner, leveraging the target's template shape. The compactness of our latent representations facilitates the training of a diffusion model, enabling diverse pose variations through generative modeling in the latent space.", "description": "This figure illustrates the overall architecture of the proposed method for learning pose representations of 3D deformable objects. It shows how the pose extractor (g) processes the Jacobian fields to extract a keypoint-based hybrid pose representation. This representation is then refined by a refinement module (\u03b1) before being applied to the target object by the pose applier (h), which outputs a deformed mesh based on Jacobian fields.  The latent pose representations are also used to train a cascaded diffusion model, enabling the generation of diverse poses.", "section": "3 Method"}, {"figure_path": "NU54MoKWlA/figures/figures_6_1.jpg", "caption": "Figure A11: Qualitative results of pose transfer across DeformingThings4D animals [23].", "description": "This figure presents a qualitative comparison of pose transfer results across different animal shapes using four different methods: NJF [2], ZPT [48], Ours (the proposed method), and a baseline approach.  For each animal type, a source mesh (\"MS\") with a specific pose and a target template mesh (\"MT\") are shown.  The results illustrate the capability of each method to transfer the pose from the source to the target while maintaining the target shape's identity.  The \"Ours\" column showcases the proposed method's ability to transfer poses effectively compared to the other methods.", "section": "Additional Qualitative Results"}, {"figure_path": "NU54MoKWlA/figures/figures_7_1.jpg", "caption": "Figure A13: Qualitative results of pose transfer across different SMPL [28] human body shapes. Best viewed when zoomed-in.", "description": "This figure shows a comparison of pose transfer results across different human body shapes from the SMPL dataset.  It contrasts the performance of four different methods: NJF [2], SPT [24], ZPT [48], and the authors' proposed method. The figure visually demonstrates how well each method transfers poses from a source mesh (M<sup>S</sup>) to various target meshes (M<sup>T</sup>), while also showing the ground truth target (M<sup>GT</sup>). The zoomed-in view is recommended for better appreciation of the details.", "section": "Additional Qualitative Results"}, {"figure_path": "NU54MoKWlA/figures/figures_7_2.jpg", "caption": "Figure 3: Qualitative results of transferring poses of the source meshes MS's (red) in the DeformingThings4D animals [23] to target templates M\u00b9's (blue). Best viewed when zoomed in.", "description": "This figure shows a comparison of pose transfer results from four different methods: NJF [2], SPT [24], ZPT [48], and the proposed method.  The source meshes (red) are from the DeformingThings4D-Animals dataset [23], and the target meshes (blue) are from the same dataset. The results demonstrate the effectiveness of the proposed method in accurately transferring poses while preserving local geometric details, in contrast to the other methods which show distortions.", "section": "4.2 Pose Transfer on DeformingThings4D-Animals"}, {"figure_path": "NU54MoKWlA/figures/figures_8_1.jpg", "caption": "Figure 6: Qualitative results from the ablation study where a pose of the source shape  MS (red) in the DeformingThings4D-Animals [23] is transferred to the target template shape M<sup>T</sup> (blue).", "description": "This figure displays the results of an ablation study comparing different variations of the proposed method for pose transfer.  The source shape (MS) is a deer, and the target template (M<sup>T</sup>) is a human-like shape. The different versions of the method are shown, highlighting the effect of using vertices only (a simplistic approach), Jacobian fields only (preserving surface geometry), and the complete method incorporating Jacobian fields and a refinement module.  The goal is to demonstrate that the proposed complete method that uses Jacobian fields and a refinement module achieves better pose transfer than simpler alternatives.", "section": "4.4 Ablation Study"}, {"figure_path": "NU54MoKWlA/figures/figures_8_2.jpg", "caption": "Figure 7: Qualitative results of transferring a pose of the source shape  MS (red) in the DeformingThings4D-Animals [23] to the target template shape MT (blue) using variants of our framework (Ours-N), trained to extract N keypoints.", "description": "This figure shows the qualitative results of pose transfer experiments using different numbers of keypoints (10, 25, 50, and 100). The source mesh (red) and target template mesh (blue) are displayed, demonstrating how the pose is transferred with varying numbers of keypoints. It aims to show the impact of the number of keypoints on pose transfer quality, focusing on the visual differences in the transferred poses.", "section": "4.5 Sensitivity to Number of Keypoints"}, {"figure_path": "NU54MoKWlA/figures/figures_9_1.jpg", "caption": "Figure 8: Qualitative results of transferring a pose of the default human mesh \\(\\mathcal{M}^S\\) (red) to the target template mesh \\(\\mathcal{M}^T\\) (blue) using variants of our framework (Ours-N), trained to extract N keypoints.", "description": "This figure displays the results of a pose transfer experiment using different numbers of keypoints extracted by the pose extractor. The source mesh \\(\\mathcal{M}^S\\) (red) is a default human mesh. The target template mesh \\(\\mathcal{M}^T\\) (blue) is also a human mesh, but with a different body shape.  Four different variants of the method, trained with 10, 25, 50, and 100 keypoints, respectively, are shown. The ground truth target shape \\(\\mathcal{M}^T_{GT}\\) is also shown in grey for comparison. This experiment aims to demonstrate the impact of the number of keypoints on the accuracy of pose transfer and the quality of the resulting shapes.", "section": "4.5 Sensitivity to Number of Keypoints"}, {"figure_path": "NU54MoKWlA/figures/figures_9_2.jpg", "caption": "Figure A14: Unconditional generation results. Each row illustrates the outcome of directly applying the generated poses to the source shape  and then transferring them to various target shapes .", "description": "This figure shows the results of unconditional pose generation.  For each row, a pose was generated and applied to the source shape (red), and then that same pose was transferred to various target shapes (blue). This demonstrates the ability of the method to generate novel poses and transfer them to different objects.", "section": "Additional Qualitative Results"}, {"figure_path": "NU54MoKWlA/figures/figures_14_1.jpg", "caption": "Figure A10: A pose transfer example showcases in Fig. 5, rendered from 4 different viewpoints.", "description": "This figure shows the results of pose transfer from a source mesh to a target mesh from four different viewpoints.  It supplements Figure 5 in the main paper by providing additional perspectives on the quality of the pose transfer. The viewpoints help to illustrate the 3D nature of the generated shape and confirm that the pose transfer is successful from multiple angles.", "section": "Additional Qualitative Results"}, {"figure_path": "NU54MoKWlA/figures/figures_19_1.jpg", "caption": "Figure A11: Qualitative results of pose transfer across DeformingThings4D animals [23].", "description": "This figure shows qualitative results of pose transfer experiments on animal shapes from the DeformingThings4D-Animals dataset.  For each animal type, it shows the source shape (M<sup>S</sup>, in red), the target shape (M<sup>T</sup>, in blue), and the results of pose transfer using three different methods: NJF [2], ZPT [48], and the authors' proposed method.  The comparison demonstrates that the authors' approach achieves more realistic and accurate pose transfer compared to the other methods.", "section": "D Additional Qualitative Results"}, {"figure_path": "NU54MoKWlA/figures/figures_20_1.jpg", "caption": "Figure A12: Qualitative results of pose transfer from a SMPL [28] mesh to Mixamo characters [1]. Best viewed when zoomed in.", "description": "This figure shows a qualitative comparison of pose transfer results from a SMPL (Skinned Multi-Person Linear Model) mesh to Mixamo characters.  The results from four different methods (NJF [2], SPT [24], ZPT [48], and the proposed method \"Ours\") are displayed side-by-side, allowing for a visual comparison of pose accuracy and geometric fidelity.  Each row represents a different source pose and target character, illustrating the methods' ability to transfer the pose while maintaining the character's identity. The caption suggests zooming in for better detail.", "section": "Additional Qualitative Results"}, {"figure_path": "NU54MoKWlA/figures/figures_21_1.jpg", "caption": "Figure A13: Qualitative results of pose transfer across different SMPL [28] human body shapes. Best viewed when zoomed-in.", "description": "This figure shows a comparison of pose transfer results across different SMPL human body shapes using four different methods: NJF [2], SPT [24], ZPT [48], and the authors' proposed method.  The results are presented for several different poses.  The goal is to evaluate how well each method transfers the pose from a source mesh (M<sup>S</sup>) to various target meshes (M<sup>T</sup>) which represent different body shapes. The ground truth is also shown in the figure (M<sup>GT</sup>).  The zoomed-in view is recommended for better visibility of the results.", "section": "Additional Qualitative Results"}, {"figure_path": "NU54MoKWlA/figures/figures_22_1.jpg", "caption": "Figure A14: Unconditional generation results. Each row illustrates the outcome of directly applying the generated poses to the source shape  and then transferring them to various target shapes .", "description": "This figure shows the results of unconditional pose generation.  Poses are generated using a diffusion model and directly applied to a source shape. Then, these poses are transferred to different target shapes to illustrate the ability of the model to generate diverse poses that transfer well across different objects. The results demonstrate successful pose transfer, maintaining the identity of the target shape while applying the generated pose.", "section": "Additional Qualitative Results"}]