[{"figure_path": "NU54MoKWlA/tables/tables_6_1.jpg", "caption": "Table 1: Quantitative results on the experiments using the DeformingThings4D-Animals dataset [23] and the human shape dataset populated using SMPL [28].", "description": "This table presents a quantitative comparison of the proposed method against three baselines (NJF [2], SPT [24], and ZPT [48]) on two datasets: DeformingThings4D-Animals and SMPL human shapes.  For the DeformingThings4D-Animals dataset, the metrics used are FID, KID, and ResNet accuracy. For the SMPL dataset, PMD (Point-wise Mesh Euclidean Distance), FID, KID, and ResNet accuracy are reported. Lower values for FID, KID, and PMD indicate better performance, while a higher ResNet accuracy indicates better performance. The results show that the proposed method outperforms the baselines in terms of pose transfer accuracy across both datasets.", "section": "4.2 Pose Transfer on DeformingThings4D-Animals"}, {"figure_path": "NU54MoKWlA/tables/tables_8_1.jpg", "caption": "Table 2: Ablation study using the poses from the source shapes in DeformingThings4D-Animals [23] dataset (left) and the poses generated from our cascaded diffusion model.", "description": "This table presents the results of an ablation study comparing different variations of the proposed framework for pose transfer.  The left side shows results using poses from the source shapes in the DeformingThings4D-Animals dataset. The right side shows results using poses generated by the cascaded diffusion model. The variations compared include using vertex-only representations versus Jacobian fields, and whether or not a per-identity refinement module was used.  The metrics used for evaluation include FID, KID, and ResNet accuracy.", "section": "4.4 Ablation Study"}, {"figure_path": "NU54MoKWlA/tables/tables_8_2.jpg", "caption": "Table 3: Quantitative results from the variants of our framework trained to extract different number of keypoints. Ours-N denotes a variant of our network trained to extract N keypoints.", "description": "This table presents quantitative results obtained from different versions of the proposed framework.  Each version varies in the number of keypoints extracted (10, 25, 50, and 100).  The results are split for two datasets: DeformingThings4D-Animals and SMPL.  The metrics used are FID (Fr\u00e9chet Inception Distance) for the DeformingThings4D-Animals dataset and PMD (Point-wise Mesh Euclidean Distance) for the SMPL dataset.  Lower FID and PMD scores indicate better performance.  The table aims to demonstrate the robustness of the framework to variations in the number of keypoints extracted, showing that reducing this number doesn't significantly impact performance. ", "section": "4.5 Sensitivity to Number of Keypoints"}, {"figure_path": "NU54MoKWlA/tables/tables_15_1.jpg", "caption": "Table 1: Quantitative results on the experiments using the DeformingThings4D-Animals dataset [23] and the human shape dataset populated using SMPL [28].", "description": "This table presents quantitative evaluation metrics for pose transfer experiments conducted on two datasets: DeformingThings4D-Animals and SMPL.  For the DeformingThings4D-Animals dataset, the metrics used are Fr\u00e9chet Inception Distance (FID), Kernel Inception Distance (KID), and ResNet classification accuracy.  For the SMPL dataset,  PMD (Point-wise Mesh Euclidean Distance), FID, KID, and ResNet accuracy are reported. The table compares the performance of the proposed method against three baseline methods (NJF, SPT, ZPT). Lower FID and KID values indicate better visual quality, while a lower PMD and higher ResNet accuracy indicate better pose transfer accuracy.", "section": "4.2 Pose Transfer on DeformingThings4D-Animals"}, {"figure_path": "NU54MoKWlA/tables/tables_16_1.jpg", "caption": "Table 1: Quantitative results on the experiments using the DeformingThings4D-Animals dataset [23] and the human shape dataset populated using SMPL [28].", "description": "This table presents a quantitative comparison of the proposed method against several baselines on two datasets: DeformingThings4D-Animals and SMPL.  For each dataset and method, it reports the FID (Fr\u00e9chet Inception Distance), KID (Kernel Inception Distance), ResNet accuracy, and PMD (Point-wise Mesh Euclidean Distance) scores. Lower FID and KID scores indicate better visual quality, while higher ResNet accuracy implies better pose classification. Lower PMD indicates better geometric accuracy in pose transfer. The table demonstrates the superior performance of the proposed method compared to the baselines across multiple metrics on both datasets.", "section": "4.2 Pose Transfer on DeformingThings4D-Animals"}, {"figure_path": "NU54MoKWlA/tables/tables_16_2.jpg", "caption": "Table 1: Quantitative results on the experiments using the DeformingThings4D-Animals dataset [23] and the human shape dataset populated using SMPL [28].", "description": "This table presents a quantitative comparison of the proposed method against several baselines on two datasets: DeformingThings4D-Animals and SMPL human shapes.  The metrics used are FID (Fr\u00e9chet Inception Distance), KID (Kernel Inception Distance), ResNet accuracy (classification accuracy using a ResNet-18 network), and PMD (Point-wise Mesh Euclidean Distance).  Lower FID and KID scores indicate better visual quality, while higher ResNet accuracy and lower PMD indicate better pose transfer accuracy.", "section": "4.2 Pose Transfer on DeformingThings4D-Animals"}, {"figure_path": "NU54MoKWlA/tables/tables_17_1.jpg", "caption": "Table 1: Quantitative results on the experiments using the DeformingThings4D-Animals dataset [23] and the human shape dataset populated using SMPL [28].", "description": "This table presents a quantitative comparison of the proposed method against existing state-of-the-art techniques for pose transfer, using two distinct datasets: DeformingThings4D-Animals and SMPL.  It shows the performance metrics (FID, KID, ResNet Accuracy, PMD) achieved by each method on each dataset. Lower FID and KID values indicate better performance in terms of image similarity, while higher ResNet Accuracy reflects better preservation of pose identity.  PMD represents Point-wise Mesh Euclidean Distance and applies only to the SMPL dataset, indicating the accuracy of pose transfer. ", "section": "4.2 Pose Transfer on DeformingThings4D-Animals"}, {"figure_path": "NU54MoKWlA/tables/tables_17_2.jpg", "caption": "Table 1: Quantitative results on the experiments using the DeformingThings4D-Animals dataset [23] and the human shape dataset populated using SMPL [28].", "description": "This table presents a quantitative comparison of the proposed method against other state-of-the-art methods for pose transfer on two datasets: DeformingThings4D-Animals and SMPL.  The metrics used for evaluation include FID, KID, ResNet accuracy, and PMD (for SMPL only).  Lower FID and KID scores indicate better visual fidelity, higher ResNet accuracy represents better pose classification, and lower PMD signifies better geometric accuracy.  The results demonstrate the superior performance of the proposed method in terms of both visual fidelity and geometric accuracy.", "section": "4.2 Pose Transfer on DeformingThings4D-Animals"}, {"figure_path": "NU54MoKWlA/tables/tables_18_1.jpg", "caption": "Table 1: Quantitative results on the experiments using the DeformingThings4D-Animals dataset [23] and the human shape dataset populated using SMPL [28].", "description": "This table presents a quantitative comparison of the proposed method against several baselines for pose transfer on two datasets: DeformingThings4D-Animals and SMPL.  The metrics used for comparison include FID, KID, ResNet accuracy, and PMD (for SMPL only).  Lower FID and KID scores indicate better visual quality. Higher ResNet accuracy reflects better pose classification. Lower PMD (Point-wise Mesh Euclidean Distance) means better geometric accuracy of pose transfer. The table highlights the superior performance of the proposed method in terms of all metrics across both datasets, demonstrating its effectiveness in pose transfer and generalization.", "section": "4.2 Pose Transfer on DeformingThings4D-Animals"}]