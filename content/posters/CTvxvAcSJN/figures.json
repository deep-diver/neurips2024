[{"figure_path": "CTvxvAcSJN/figures/figures_1_1.jpg", "caption": "Figure 2: SceneCraft is a novel framework for layout-guided scene generation, which allows users to provide the layout as a bounding-box scene (BBS, Sec. 3.1), a user-friendly layout format that guides the generation. Our framework contains two stages: (a) pretraining of a 2D diffusion model, SceneCraft2D, to solve the 2D version of the layout-guided scene generation task (Sec. 3.2), and (b) distillation of the SceneCraft2D to learn a scene representation of the generated scene (Sec. 3.3).", "description": "This figure illustrates the SceneCraft framework, which takes a user-specified layout (Bounding-Box Scene or BBS) as input.  The framework consists of two main stages:  First, a 2D diffusion model (SceneCraft2D) is pre-trained using rendered images of the BBS to generate high-quality 2D images of the scene from different viewpoints.  Second, these 2D images are used in a distillation process to learn a 3D representation (e.g., NeRF) of the generated scene. The final output is a high-quality, detailed 3D scene that adheres to both the textual description and spatial layout preferences provided by the user.", "section": "3 SceneCraft: Methodology"}, {"figure_path": "CTvxvAcSJN/figures/figures_3_1.jpg", "caption": "Figure 2: SceneCraft is a novel framework for layout-guided scene generation, which allows users to provide the layout as a bounding-box scene (BBS, Sec. 3.1), a user-friendly layout format that guides the generation. Our framework contains two stages: (a) pretraining of a 2D diffusion model, SceneCraft2D, to solve the 2D version of the layout-guided scene generation task (Sec. 3.2), and (b) distillation of the SceneCraft2D to learn a scene representation of the generated scene (Sec. 3.3).", "description": "This figure illustrates the SceneCraft framework, a two-stage process for generating 3D indoor scenes from a user-provided layout and text description. Stage (a) pre-trains a 2D diffusion model (SceneCraft2D) on rendered images from bounding box scenes (BBS), learning to generate high-quality 2D images from the layout. Stage (b) uses the pre-trained SceneCraft2D to generate multiple views of the scene, which are then used to learn a final 3D scene representation.", "section": "3 SceneCraft: Methodology"}, {"figure_path": "CTvxvAcSJN/figures/figures_5_1.jpg", "caption": "Figure 3: Generation results of SceneCraft on Hypersim [49] provided room layouts. For each sample, we demonstrate the 3D BBS and BBI semantic maps and the generated scene RGB images and rendered depth map. Our method is able to generate complex and free-form scenes from challenging room layouts.", "description": "This figure visualizes the results of SceneCraft applied to three different room layouts from the HyperSim dataset.  For each layout (BBS-A, BBS-B, BBS-C), it shows the 3D bounding box scene (BBS), the corresponding bounding box images (BBI) with semantic segmentation, and the resulting RGB images and depth maps generated by SceneCraft. This demonstrates the model's ability to create complex and varied indoor scenes from user-provided layouts.", "section": "3 SceneCraft: Methodology"}, {"figure_path": "CTvxvAcSJN/figures/figures_6_1.jpg", "caption": "Figure 4: Qualitative comparisons of SceneCraft and baseline approaches. We show our generated color and depth renderings under two common layout conditions (a bedroom and a living room) alongside three other baselines. SceneCraft demonstrates higher credibility in following the layout conditions and is capable of handling more complex scenarios.", "description": "This figure compares the results of SceneCraft with three other baseline methods: Set-the-scene, Text2Room, and MVDiffusion.  Two common indoor scene layouts, a bedroom and a living room, are used for the comparison. The generated color and depth images from each method are shown. The figure highlights that SceneCraft produces results with higher visual quality and better adherence to the layout specifications than the baseline methods, especially when dealing with more complex scenes.", "section": "4 Experiments"}, {"figure_path": "CTvxvAcSJN/figures/figures_8_1.jpg", "caption": "Figure 3: Generation results of SceneCraft on Hypersim [49] provided room layouts. For each sample, we demonstrate the 3D BBS and BBI semantic maps and the generated scene RGB images and rendered depth map. Our method is able to generate complex and free-form scenes from challenging room layouts.", "description": "This figure shows four examples of 3D scenes generated by SceneCraft, a novel method for generating detailed indoor scenes based on textual descriptions and spatial layouts. Each example includes the 3D bounding-box scene (BBS) layout, the bounding-box images (BBI) semantic maps (semantic categories and depth maps derived from the BBS), the generated scene RGB images, and a rendered depth map of the scene.  The results demonstrate the model's ability to generate complex and free-form indoor scenes with diverse textures and realistic visual quality, even for challenging layouts.", "section": "3 SceneCraft: Methodology"}, {"figure_path": "CTvxvAcSJN/figures/figures_9_1.jpg", "caption": "Figure 6: Effect of Base Prompt. Using our base prompt successfully avoids the overfitting and maintains the inherent power of pretrained Stable Diffusion, while using BLIP2 captions leads to control failure.", "description": "This figure demonstrates a comparison of using a simple base prompt versus using captions generated by BLIP2 for the SceneCraft2D model.  The left side shows results using the base prompt \"This is one view of a room.\" It produces good, stylistically consistent results while maintaining adherence to the layout. The right side shows the results from using BLIP2 generated prompts. These results suffer from control failure, showing inconsistencies in style and a lack of adherence to the layout constraints.", "section": "4.3 More Generation Results"}, {"figure_path": "CTvxvAcSJN/figures/figures_9_2.jpg", "caption": "Figure 3: Generation results of SceneCraft on Hypersim [49] provided room layouts. For each sample, we demonstrate the 3D BBS and BBI semantic maps and the generated scene RGB images and rendered depth map. Our method is able to generate complex and free-form scenes from challenging room layouts.", "description": "This figure showcases three examples of 3D scenes generated by SceneCraft, a method for generating complex indoor scenes from user-provided layouts and text descriptions.  Each example shows a top-down view of the \"bounding-box scene\" (BBS) layout used as input, along with the corresponding semantic maps (BBI) indicating object locations and categories. The figure then presents multiple views of the generated 3D scene, including RGB images and rendered depth maps, demonstrating SceneCraft's ability to create complex and realistic indoor environments.", "section": "Experiments"}, {"figure_path": "CTvxvAcSJN/figures/figures_14_1.jpg", "caption": "Figure A: An illustration of duo-GPU training scheduling.", "description": "This figure illustrates the duo-GPU training scheduling used in the SceneCraft model.  The leftmost part shows the Nerfacto model, which is trained continuously by the first GPU.  Meanwhile, the second GPU continuously generates new images to update the dataset.  When the diffusion procedure requires images from the first GPU to refine the dataset, the first GPU switches to an offline renderer. This configuration decouples the computationally expensive diffusion generation process from the faster NeRF training, improving efficiency without sacrificing quality.", "section": "A Additional Details"}, {"figure_path": "CTvxvAcSJN/figures/figures_15_1.jpg", "caption": "Figure C: Effect of Texture Consolidation. The generated renderings are blurry without the texture consolidation strategy. Our SceneCraft produces more detailed and textured results.", "description": "This figure in the ablation study section demonstrates the effectiveness of the texture consolidation method used in SceneCraft.  The top row shows results without texture consolidation, resulting in blurry renderings.  The bottom row, conversely, shows results with texture consolidation, demonstrating significantly improved detail and texture in the generated 3D scenes.", "section": "B.1 Ablation Study"}, {"figure_path": "CTvxvAcSJN/figures/figures_15_2.jpg", "caption": "Figure B: Layout-Aware Depth Constraint. With depth constraint strategy, our SceneCraft can effectively learn scene geometry from prior input, which is crucial to ultimate 3D consistency.", "description": "This figure shows the effectiveness of the layout-aware depth constraint in SceneCraft. The leftmost image shows the condition input. The middle image shows the result without the depth constraint, demonstrating an inability to learn the scene geometry correctly. The right image demonstrates the result with the depth constraint, showcasing accurate geometry learning and convergence to the ground truth.", "section": "Ablation Study"}, {"figure_path": "CTvxvAcSJN/figures/figures_16_1.jpg", "caption": "Figure 3: Generation results of SceneCraft on Hypersim [49] provided room layouts. For each sample, we demonstrate the 3D BBS and BBI semantic maps and the generated scene RGB images and rendered depth map. Our method is able to generate complex and free-form scenes from challenging room layouts.", "description": "This figure shows example results of the SceneCraft model on the HyperSim dataset.  For each scene, it displays the 3D bounding box scene (BBS), the bounding box images (BBI) with semantic maps, the generated RGB images of the scene, and the depth map of the generated scene. The results demonstrate the model's ability to generate complex and diverse indoor scenes.", "section": "Experiments"}, {"figure_path": "CTvxvAcSJN/figures/figures_17_1.jpg", "caption": "Figure 5: Generation results of SceneCraft in complex scenes. We demonstrate SceneCraft's ability to generate more complex indoor scenes leveraging arbitrary camera trajectories. Such non-regular shape of rooms cannot be naturally achieved by previous work.", "description": "This figure showcases the ability of SceneCraft to generate complex indoor scenes with non-regular shapes and using arbitrary camera trajectories, which is a significant advancement over previous methods.  It displays several examples of diverse, multi-room scenes, highlighting SceneCraft's capacity to handle more complex layouts than other comparable methods that rely on panoramic views or simpler room structures.", "section": "4.3 More Generation Results"}, {"figure_path": "CTvxvAcSJN/figures/figures_17_2.jpg", "caption": "Figure F: Failure case #2: Generations of a bedroom with a matched prompt \"Bedroom\" and a mismatched prompt \"Kitchen.\"", "description": "This figure shows the results of generating a bedroom scene using SceneCraft with both a matched and mismatched prompt. The top row displays the layout (BBS) of a bedroom with its semantic map. The middle row shows the generated RGB images and depth maps with a matched prompt (\"Bedroom\").  The bottom row shows the generated RGB images and depth maps with a mismatched prompt (\"Kitchen\"). The mismatch in prompt causes the model to struggle with scene consistency, demonstrating the importance of prompt coherence for accurate generation with SceneCraft.", "section": "B.2 Complex Room Generation with Irregular Object Geometry and Free Camera Trajectory"}]