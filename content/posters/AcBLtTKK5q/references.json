{"references": [{"fullname_first_author": "Josh Achiam", "paper_title": "GPT-4 technical report", "publication_date": "2023-03-08", "reason": "This paper is a technical report on GPT-4, one of the LLMs used in the experiments, providing crucial background information and specifications."}, {"fullname_first_author": "Hugo Touvron", "paper_title": "Llama 2: Open foundation and fine-tuned chat models", "publication_date": "2023-07-09", "reason": "This paper introduces Llama 2, another LLM used in the study, providing essential details for understanding its characteristics and capabilities within the context of jailbreaking."}, {"fullname_first_author": "Richard Socher", "paper_title": "Recursive deep models for semantic compositionality over a sentiment treebank", "publication_date": "2013-11-01", "reason": "This foundational paper on recursive deep models for sentiment analysis is relevant to the context of LLMs and their applications in tasks involving sentiment and other forms of text analysis."}, {"fullname_first_author": "Ning Miao", "paper_title": "Selfcheck: Using LLMs to zero-shot check their own step-by-step reasoning", "publication_date": "2023-08-00", "reason": "This study explores the self-assessment capabilities of LLMs, which is closely related to the concept of jailbreaks and the challenges of controlling or evaluating LLM behavior."}, {"fullname_first_author": "Vahid Ghafouri", "paper_title": "AI in the gray: Exploring moderation policies in dialogic large language models vs. human answers in controversial topics", "publication_date": "2023-10-01", "reason": "This paper investigates moderation policies in LLMs and how they compare to human responses in controversial situations, which directly relates to the paper's focus on moderation guardrails and their circumvention."}]}