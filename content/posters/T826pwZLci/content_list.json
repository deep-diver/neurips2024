[{"type": "text", "text": "Federated Online Prediction from Experts with Differential Privacy: Separations and Regret Speed-ups ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Fengyu Gao, Ruiquan Huang, Jing Yang School of EECS, The Pennsylvania State University, USA {fengyugao, rzh5514, yangjing}@psu.edu ", "page_idx": 0}, {"type": "text", "text": "Abstract ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "We study the problems of differentially private federated online prediction from experts against both stochastic adversaries and oblivious adversaries. We aim to minimize the average regret on $m$ clients working in parallel over time horizon $T$ with explicit differential privacy (DP) guarantees. With st\u221aochastic adversaries, we propose a Fed-DP-OPE-Stoch algorithm that achieves $\\sqrt{m}$ -fold speed-up of the per-client regret compared to the single-player counterparts under both pure DP and approximate DP constraints, while maintaining logarithmic communication costs. With oblivious adversaries, we establish non-trivial lower bounds indicating that collaboration among clients does not lead to regret speed-up with general oblivious adversaries. We then consider a special case of the oblivious adversaries setting, where there exists a low-loss expert. We design a new algorithm Fed-SVT and show that it achieves an $m$ -fold regret speed-up under both pure DP and approximate DP constraints over the single-player counterparts. Our lower bound indicates that Fed-SVT is nearly optimal up to logarithmic factors. Experiments demonstrate the effectiveness of our proposed algorithms. To the best of our knowledge, this is the first work examining the differentially private online prediction from experts in the federated setting. ", "page_idx": 0}, {"type": "text", "text": "1 Introduction ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Federated Learning (FL) (McMahan et al., 2017) is a distributed machine learning framework, where numerous clients collaboratively train a model by exchanging model update through a server. Owing to its advantage in protecting the privacy of local data and reducing communication overheads, FL is gaining increased attention in the research community, particularly in the online learning framework (Mitra et al., 2021; Park et al., 2022; Kwon et al., 2023; Gauthier et al., 2023). Noticeable advancements include various algorithms in federated multi-armed bandits (Shi et al., 2021; Huang et al., 2021; Li and Wang, 2022; Yi and Vojnovic, 2022, 2023), federated online convex optimization (Patel et al., 2023; Kwon et al., 2023; Gauthier et al., 2023), etc. ", "page_idx": 0}, {"type": "text", "text": "Meanwhile, differential privacy (DP) has been integrated into online learning, pioneered by Dwork et al. (2010). Recently, Asi et al. (2022b) studied different types of adversaries, developing some of the best existing algorithms and establishing lower bounds. Within the federated framework, although differentially private algorithms have been proposed for stochastic bandits (Li et al., 2020b; Zhu et al., 2021; Dubey and Pentland, 2022) and linear contextual bandits (Dubey and Pentland, 2020; Li et al., 2022a; Zhou and Chowdhury, 2023; Huang et al., 2023), to the best of our knowledge, federated online learning in the adversarial setting with DP considerations remain largely unexplored. ", "page_idx": 0}, {"type": "text", "text": "In this work, we focus on federated online prediction from experts (OPE) with rigorous differential privacy (DP) guarantees1. OPE (Arora et al., 2012) is a classical online learning problem under which, a player chooses one out of a set of experts at each time slot and an adversary chooses a loss function. The player incurs a loss based on its choice and observes the loss function. With all previous observations, the player needs to decide which expert to select each time to minimize the cumulative expected loss. We consider two types of adversaries in the context of OPE. The first type, stochastic adversary, chooses a distribution over loss functions and samples a loss function independently and identically distributed (IID) from this distribution at each time step. The second type, oblivious adversary, chooses a sequence of loss functions in advance. 2 ", "page_idx": 1}, {"type": "text", "text": "When extending the OPE problem to the federated setting, we assume that the system consists of a central server and $m$ local clients, where each client chooses from $d$ experts to face an adversary at each time step over time horizon $T$ . The server coordinates the behavior of the clients by aggregating the clients\u2019 updates to form a global update (predicting a new global expert), while the clients use the global expert prediction to update its local expert selection and compute local updates. The local updates will be sent to the server periodically. In the Federated OPE framework, clients face either stochastic adversaries, receiving loss functions from the same distribution in an IID fashion, or oblivious adversaries, which arbitrarily select loss functions for each client at each time step beforehand (Yi and Vojnovic, 2023). Specifically, we aim to answer the following question: ", "page_idx": 1}, {"type": "text", "text": "Can we design differentially private federated OPE algorithms to achieve regret speed-up against both stochastic and oblivious adversaries? ", "page_idx": 1}, {"type": "text", "text": "In this paper, we give definitive answers to the question. Our contributions are summarized as follows. ", "page_idx": 1}, {"type": "text", "text": "\u2022 Speed-up for stochastic adversaries. We develop a communication-efficient algorithm Fed-DPOPE-Stoch for stochastic adversaries with DP guarantees. The algorithm features the following elements in its design: 1) Local loss function gradient estimation for global expert determination. To reduce communication cost, we propose to estimate the gradient of each client\u2019s previous loss functions locally, and only communicate these estimates to the server instead of all previous loss functions. 2) Local privatization process. Motivated by the need for private communication in FL, we add noise to client communications (local gradient estimates) adhering to the DP principles, thereby building differentially private algorithms. ", "page_idx": 1}, {"type": "text", "text": "We show that Fed-DP-OPE-Stoch achieves $1/\\sqrt{m}$ -fold reduction of the per-client regret compared to the single-player counterparts (Asi et al., 2022b) under both pure DP and approximate DP constraints, while maintaining logarithmic communication costs. ", "page_idx": 1}, {"type": "text", "text": "\u2022 Lower bounds for oblivious adversaries. We establish new lower bounds for federated OPE with oblivious adversaries. Our findings reveal a critical insight: collaboration among clients does not lead to regret speed-up in this context. Moreover, these lower bounds highlight a separation between oblivious adversaries and stochastic adversaries, as the latter is necessary to reap the benefits of collaboration in this framework. ", "page_idx": 1}, {"type": "text", "text": "Formulating an instance of oblivious adversaries for the corresponding lower bounds is a non-trivial challenge, because it requires envisioning a scenario where the collaborative nature of FL does not lead to the expected improvements in regret minimization. To deal with this challenge, we propose a policy reduction approach in $F L$ . By defining an \u201caverage policy\u201d among all clients against a uniform loss function generated by an oblivious adversary, we reduce the federated problem to a single-player one, highlighting the equivalence of per-client and single-player regret. Our lower bounds represent the first of their kind for differentially private federated OPE problems. ", "page_idx": 1}, {"type": "text", "text": "\u2022 Speed-up for oblivious adversaries under realizability assumption. We design a new algorithm Fed-SVT that obtains near-optimal regret when there is a low-loss expert. We show that Fed-SVT achieves an $m$ -fold speed-up in per-client regret when compared to single-player models (Asi et al., 2023). This shows a clear separation from the general setting where collaboration among clients does not yield benefits in regret reduction when facing oblivious adversaries. Furthermore, we establish a new lower bound in the realizable case. This underlines that our upper bound is nearly optimal up to logarithmic factors. ", "page_idx": 1}, {"type": "table", "img_path": "T826pwZLci/tmp/b48f93aebb78c7cd0cf31fc3ab9b52095429eff8400e2bbb8715f2bccee554d8.jpg", "table_caption": ["Table 1: Comparisons for Online Prediction from Experts under DP Constraints "], "table_footnote": ["$_m$ : number of clients; $_T$ : time horizon; $d$ : number of experts; $\\varepsilon$ , \u03b4: DP parameters; SING and FED stand for single-client and federated settings, respectively. "], "page_idx": 2}, {"type": "text", "text": "A summary of our main results and how they compare with the state of the art is shown in Table 1. A comprehensive literature review is provided in Appendix A. ", "page_idx": 2}, {"type": "text", "text": "2 Preliminaries ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "Federated online prediction from experts. Federated OPE consists of a central server, $m$ clients and an interactive $T$ -round game between an adversary and an algorithm. At time step $t$ , each client $i\\,\\in\\,[m]$ first selects an expert $x_{i,t}\\in[d]$ , and then, the adversary releases a loss function $l_{i,t}$ . Stochastic adversaries choose a distribution over loss functions and sample a sequence of loss functions $l_{1,1},...\\,,l_{m,T}$ in an IID fashion from this distribution, while oblivious adversaries choose a sequence of loss functions $l_{1,1},\\ldots,l_{m,T}$ at the beginning of the game. ", "page_idx": 2}, {"type": "text", "text": "For federated OPE, the utility of primary interest is the expected cumulative regret among all clients defined as: ", "page_idx": 2}, {"type": "equation", "text": "$$\n\\mathsf{R e g}(T,m)=\\frac{1}{m}\\left[\\sum_{i=1}^{m}\\sum_{t=1}^{T}l_{i,t}(x_{i,t})-\\operatorname*{min}_{x^{\\star}\\in[d]}\\sum_{i=1}^{m}\\sum_{t=1}^{T}l_{i,t}(x^{\\star})\\right].\n$$", "text_format": "latex", "page_idx": 2}, {"type": "text", "text": "Differential privacy. We define differential privacy in the online setting following (Dwork et al., 2010). If an adversary chooses a loss sequence $\\overline{{S}}~=~(l_{1,1},\\ldots,l_{m,\\stackrel{\\scriptstyle{T}}{T}})$ , we denote ${\\mathcal{A}}(S)\\ =$ $(x_{1,1},\\ldots,x_{m,T})$ the output of the interaction between the federated online algorithm $\\boldsymbol{\\mathcal{A}}$ and the adversary. We say $\\mathcal{S}=(l_{1,1},\\ldots,l_{m,T})$ and $\\mathcal{S}^{\\prime}=\\left(l_{1,1}^{\\prime},\\ldots,l_{m,T}^{\\prime}\\right)$ are neighboring datasets if $\\boldsymbol{S}$ and $S^{\\prime}$ differ in a one element. 3. ", "page_idx": 2}, {"type": "text", "text": "Definition 1 $\\mathit{\\check{\\Psi}}(\\varepsilon,\\delta)$ -DP). A randomized federated algorithm $\\boldsymbol{\\mathcal{A}}$ is $(\\varepsilon,\\delta)$ -differentially private against an adversary if, for all neighboring datasets $\\boldsymbol{S}$ and $S^{\\prime}$ and for all events $\\scriptscriptstyle\\mathcal{O}$ in the output space of $\\boldsymbol{\\mathcal{A}}$ , we have ", "page_idx": 2}, {"type": "equation", "text": "$$\n\\mathbb{P}[A(S)\\in\\mathcal{O}]\\le e^{\\varepsilon}\\mathbb{P}\\left[A\\left(\\mathcal{S}^{\\prime}\\right)\\in\\mathcal{O}\\right]+\\delta.\n$$", "text_format": "latex", "page_idx": 2}, {"type": "text", "text": "Communication model. Our setup involves a central server facilitating periodic communication with zero latency with all clients. Specifically, the clients can send \u201clocal model updates\u201d to the central server, which then aggregates and broadcasts the updated \u201cglobal model\u201d to the clients. We assume full synchronization between clients and the server (McMahan et al., 2017). Following Wang et al. (2019), we define the communication cost of an algorithm as the number of scalars (integers or real numbers) communicated between the server and clients. ", "page_idx": 2}, {"type": "text", "text": "3 Federated OPE with Stochastic Adversaries ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "In this section, we aim to design an algorithm for Fed-DP-OPE with stochastic adversaries that achieves regret speed-up compared to the single-player setting under DP constraints with low ", "page_idx": 2}, {"type": "text", "text": "communication cost. We consider the loss functions $l_{1,1}(\\cdot),\\ldots,l_{m,T}(\\cdot)$ to be convex, $\\alpha$ -Lipschitz and $\\beta$ -smooth w.r.t. $\\|\\cdot\\|_{1}$ in this section. ", "page_idx": 3}, {"type": "text", "text": "3.1 Intuition behind Algorithm Design ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "To gain a better understanding of our algorithm design, we first elaborate the difficulties encountered when extending prevalent OPE models to the FL setting under DP constraints. It is worth noting that all current OPE models with stochastic adversaries rely on gradient-based optimization methods. The central task in designing OPE models with stochastic adversaries lies in leveraging past loss functions to guide the generation of expert predictions. Specifically, we focus on the prominent challenges associated with the widely adopted Frank-Wolfe-based methods (Asi et al., 2022b). This algorithm iteratively moves the expert selection $x_{t}$ towards a point that minimizes the gradient estimate derived from the past loss functions $l_{1},\\ldots,l_{t-1}$ over the decision space $\\mathcal{X}$ , where $\\chi=$ $\\Delta_{d}=\\left\\{x\\in\\mathbb{R}^{d}:x_{i}\\geq0,\\sum_{i=1}^{d}x_{i}=1\\right\\}$ , and each $x\\in\\mathscr{X}$ represents a probability distribution over $d$ experts. With DP constraints, a tree-based method is used for private aggregation of the gradients of loss functions (Asi et al., 2021b). ", "page_idx": 3}, {"type": "text", "text": "In the federated setting, it is infeasible for the central server to have full access to past loss functions due to the high communication cost. To overcome this, we use a design of local loss function gradient estimation for global expert determination. Our solution involves locally estimating the gradient of each client\u2019s loss functions, and then communicating these estimates to the server, which globally generates a new prediction. This strategy bypasses the need for full access to all loss functions, reducing the communication overhead while maintaining efficient expert selection. ", "page_idx": 3}, {"type": "text", "text": "To enhance privacy in the federated system, we implement a local privatization process. When communication is triggered, clients send \u201clocal estimates\u201d of the gradients of their loss functions to the server. These local estimates include strategically added noise, adhering to DP principles. The privatization method is crucial as it extends beyond privatizing the selection of experts; it ensures the privacy of all information exchanged between the central server and clients within the FL framework. ", "page_idx": 3}, {"type": "text", "text": "3.2 Algorithm Design ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "To address the aforementioned challenges, we propose the Fed-DP-OPE-Stoch algorithm. The Fed-DP-OPE-Stoch algorithm works in phases. In total, it has $P$ phases, and each phase $p\\in[P]$ contains $2^{p-1}$ time indices. Fed-DP-OPE-Stoch contains a client-side subroutine (Algorithm 1) and a server-side subroutine (Algorithm 2). The framework of our algorithm is outlined as follows. ", "page_idx": 3}, {"type": "text", "text": "At the initialization phase, the server selects an arbitrary point $z\\in\\mathcal{X}$ and broadcasts to all clients. Subsequently, each client initializes its expert selection $x_{i,1}=z$ , pays cost $l_{i,1}(x_{i,1})$ and observes the loss function. ", "page_idx": 3}, {"type": "text", "text": "Starting at phase $p=2$ , each client uses loss functions from the last phase to update its local loss function gradient estimation, and then coordinates with the server to update its expert selection. After that, it sticks with its decision throughout the current phase and observes the loss functions. We elaborate this procedure as follows. ", "page_idx": 3}, {"type": "text", "text": "Private Local Loss Function Gradient Estimation. At the beginning of phase $p$ , each client privately estimates the gradient using local loss functions from the last phase $\\vec{B_{i,p}}=\\left\\{\\bar{l_{i,2^{p-2}}},\\ldots,\\bar{l_{i,2^{p-1}-1}}\\right\\}$ We employ the tree mechanism for the private aggregation at each client, as in the DP-FW algorithm from Asi et al. (2021b). Roughly speaking, DP-FW involves constructing binary trees and allocating sets of loss functions to each vertex. The gradient at each vertex is then estimated using the loss functions of that vertex and the gradients along the path to the root. Specifically, we run a DP-FW subroutine at each client $i$ , with sample set $B_{i,p}$ , parameter $T_{1}$ and batch size $b$ . In DP-FW, each vertex $s$ in the binary tree $j$ corresponds to a gradient estimate $v_{i,j,s}$ . DP-FW iteratively updates gradient estimates by visiting the vertices of binary trees. The details of DP-FW can be found in Algorithm 3 in Appendix C.1. ", "page_idx": 3}, {"type": "text", "text": "Intuitively, in the DP-FW subroutine, reaching a leaf vertex marks the completion of gradient refinement for a specific tree path. At these critical points, we initiate communication between the central server and individual clients. Specifically, as the DP-FW subroutine reaches a leaf vertex $s$ of tree $j$ , each client sends the server a set of noisy inner products for each decision set vertex $c_{n}$ with their gradient estimate $v_{i,j,s}$ . In other words, each client communicates with the server by sending $\\{\\langle c_{n},{\\bar{v}}_{i,j,s}\\rangle+\\xi_{i,n}\\}_{n\\in[d]}$ , where $c_{1},\\ldots,c_{d}$ represents $d$ vertices of decision set $\\mathcal{X}=\\Delta_{d}$ , $\\xi_{i,n}\\sim\\mathrm{Lap}(\\lambda_{i,j,s})$ , and $\\begin{array}{r}{\\lambda_{i,j,s}=\\frac{4\\alpha2^{j}}{b\\varepsilon}}\\end{array}$ . ", "page_idx": 3}, {"type": "text", "text": "", "page_idx": 4}, {"type": "text", "text": "Private Global Expert Prediction. After receiving $\\{\\langle c_{n},v_{i,j,s}\\rangle+\\xi_{i,n}\\}_{n\\in[d]}$ from all clients, the central server privately predicts a new expert: ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\bar{w}_{j,s}=\\operatorname*{arg\\,min}_{c_{n}:1\\leq n\\leq d}\\left[\\frac{1}{m}\\sum_{i=1}^{m}\\left(\\langle c_{n},v_{i,j,s}\\rangle+\\xi_{i,n}\\right)\\right].\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "Subsequently, the server broadcasts the \u201cglobal prediction\u201d $\\bar{w}_{j,s}$ to all clients. ", "page_idx": 4}, {"type": "text", "text": "Local Expert Selection Updating. Denote the index of the leaf $s$ of tree $j$ as $k$ . Then, upon receiving the global expert selection $\\bar{w}_{j,s}$ , each client $i$ updates its expert prediction for leaf $k+1$ , denoted as $x_{i,p,k+1}\\in\\mathcal{X}$ , as follows: ", "page_idx": 4}, {"type": "equation", "text": "$$\nx_{i,p,k+1}=(1-\\eta_{i,p,k})x_{i,p,k}+\\eta_{i,p,k}\\bar{w}_{j,s},\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "where \u03b7i,p,k = $\\begin{array}{r}{\\eta_{i,p,k}=\\frac{2}{k+1}}\\end{array}$ ", "page_idx": 4}, {"type": "text", "text": "After updating all leaf vertices of the trees, the client obtains $x_{i,p,K}$ , the final state of the expert prediction in phase $p$ . Then, each client $i$ sticks with expert selection $x_{i,p,K}$ throughout phase $p$ and collects loss functions $l_{i,2^{p-1}},\\ldots,l_{i,2^{p}-1}$ . ", "page_idx": 4}, {"type": "text", "text": "Remark 1 (Comparison with Asi et al. (2022b)). The key difference between Fed-DP-OPE-Stoch and non-federated algorithms (Asi et al., 2022b) lies in our innovative approach to centralized coordination and communication efficiency. Unlike the direct application of DP-FW in each phase in Asi et al. (2022b), our algorithm employs local loss function gradient estimation, global expert prediction and local expert selection updating. Additionally, our strategic communication protocol, where clients communicate with the server only when DP-FW subroutine reaches leaf vertices, significantly reduces communication costs. Moreover, the integration of DP at the local level in our algorithm distinguishes it from non-federated approaches. ", "page_idx": 4}, {"type": "text", "text": "Algorithm 1 Fed-DP-OPE-Stoch: Client $i$ ", "text_level": 1, "page_idx": 4}, {"type": "text", "text": "1: Input: Phases $P$ , trees $T_{1}$ , decision set $\\mathcal{X}=\\Delta_{d}$ with vertices $\\{c_{1},\\ldots,c_{d}\\}$ , batch size $b$ .   \n2: Initialize: Set $x_{i,1}=z\\in\\mathcal{X}$ and pay cost $l_{i,1}(x_{i,1})$ .   \n3: for $p=2$ to $P$ do   \n4: Set $B_{i,p}=\\left\\{l_{i,2^{p-2}},\\ldots,l_{i,2^{p-1}-1}\\right\\}$   \n5: Set k = 1 and xi,p,1 = xi,p\u22121,K   \n6: $\\{v_{i,j,\\underline{{s}}}\\}_{j\\in[T_{1}],s\\in\\{0,1\\}}{\\le}j=\\mathbf{\\Delta}\\mathbf{D}\\mathbf{P}\\mathbf{-}\\mathbf{F}\\mathbf{W}\\left(\\mathcal{B}_{i,p},T_{1},b\\right)$   \n7: for all leaf vertices $s$ reached in DP-FW do   \n8: Communicate to server: $\\{\\langle c_{n},v_{i,j,s}\\rangle+\\xi_{i,n}\\}_{n\\in[d]}$ , where $\\xi_{i,n}\\sim\\mathrm{Lap}(\\lambda_{i,j,s})$   \n9: Receive from server: w\u00afj,s   \n10: Update $x_{i,p,k}$ according to Equation (2)   \n11: Update $k=k+1$   \n12: end for   \n13: Final iterate outputs xi,p,K   \n14: for $t=2^{p-1}$ to $2^{p}-1$ do   \n15: Receive loss $l_{i,t}:\\mathcal{X}\\rightarrow\\mathbb{R}$ and pay cost $l_{i,t}(x_{i,p,K})$   \n16: end for   \n17: end for ", "page_idx": 4}, {"type": "text", "text": "3.3 Theoretical Guarantees ", "text_level": 1, "page_idx": 4}, {"type": "text", "text": "Now we are ready to present theoretical guarantees for Fed-DP-OPE-Stoch. ", "page_idx": 4}, {"type": "text", "text": "Theorem 1. Assume that loss function $l_{i,t}(\\cdot)$ is convex, $\\alpha$ -Lipschitz, $\\beta$ -smooth w.r.t. $\\|\\cdot\\|_{1}$ . Setting $\\begin{array}{r}{\\lambda_{i,j,s}=\\frac{4\\alpha2^{j}}{b\\varepsilon}}\\end{array}$ 4\u03b12j, b = $\\begin{array}{r}{b=\\frac{2^{p-1}}{(p-1)^{2}}}\\end{array}$ (p2\u22121)2 and T1 = 12 log $\\begin{array}{r}{T_{1}=\\frac{1}{2}\\log{\\left(\\frac{b\\varepsilon\\beta\\sqrt{m}}{\\alpha\\log{d}}\\right)}.}\\end{array}$ , Fed-DP-OPE-Stoch (i) satisfies $\\varepsilon$ -DP and (ii) achieves the per-client regret of ", "page_idx": 4}, {"type": "equation", "text": "$$\nO\\left(\\left(\\alpha+\\beta\\right)\\log T\\sqrt{\\frac{T\\log d}{m}}+\\frac{\\sqrt{\\alpha\\beta}\\log d\\sqrt{T}\\log T}{m^{\\frac{1}{4}}\\sqrt{\\varepsilon}}\\right)\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "1: Input: Phases $P$ , number of clients $m$ , decision set $\\mathcal{X}=\\Delta_{d}$ with vertices $\\{c_{1},\\ldots,c_{d}\\}$ .   \n2: Initialize: Pick any $z\\in\\mathcal{X}$ and broadcast to clients.   \n3: for $p=2$ to $P$ do   \n4: Receive from clients: $\\{\\langle c_{n},v_{i,j,s}\\rangle+\\xi_{i,n}\\}_{n\\in[d]}$   \n5: Update $\\bar{w}_{j,s}$ according to Equation (1)   \n6: Communicate to clients: w\u00afj,s   \n7: end for ", "page_idx": 5}, {"type": "text", "text": "with (iii) a communication cost of $\\scriptstyle O\\,\\left(m^{{\\frac{5}{4}}}d{\\sqrt{\\frac{T\\varepsilon\\beta}{\\alpha\\log d}}}\\right)$ ", "page_idx": 5}, {"type": "text", "text": "A similar result characterizing the performance of Fed-DP-OPE-Stoch under $(\\varepsilon,\\delta)$ -DP constraint is shown in Theorem 6. ", "page_idx": 5}, {"type": "text", "text": "Proof sketch of $D P$ guarantees and communication costs. Given neighboring datasets $\\boldsymbol{S}$ and $S^{\\prime}$ differing in $l_{i_{1},t_{1}}$ or $l_{i_{1},t_{1}}^{\\prime}$ , we first note that $l_{i_{1},t_{1}}$ or $l_{i_{1},t_{1}}^{\\prime}$ is used in only one phase, denoted as $p_{1}$ . Furthermore, note that $l_{i_{1},t_{1}}$ or $l_{i_{1},t_{1}}^{\\prime}$ is used in the gradient computation for at most $2^{j-|s|}$ iterations, corresponding to descendant leaf nodes. This insight allows us to set noise levels $\\lambda_{i,j,s}$ sufficiently large to ensure each of these iterations is $\\varepsilon/2^{j-|s|}$ -DP regarding output $\\{\\langle c_{n},v_{i_{1},j,s}\\rangle\\}_{n\\in[d],j\\in[T_{1}],|s|=j}$ By basic composition and post-processing, we can make sure the final output is $\\varepsilon$ -DP. ", "page_idx": 5}, {"type": "text", "text": "The communication cost is obtained by observing that there are $p$ phases, and within each phase, there are $O(2^{T_{1}})$ leaf vertices. Thus, the communication frequency scales in $O(\\sum_{p}2^{T_{1}})$ and the communication cost scales in $\\begin{array}{r}{O(m d\\sum_{p}2^{T_{1}})}\\end{array}$ . \u53e3 ", "page_idx": 5}, {"type": "text", "text": "Proof sketch of regret upper bound. We first give bounds for the total regret in phase $p\\in[P]$ . We can show that for every $t$ in phase $p$ , we have ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{L_{t}(x_{i,p,k+1})\\leq L_{t}(x_{i,p,k})+\\eta_{i,p,k}[L_{t}(x^{\\star})-L_{t}(x_{i,p,k})]+\\eta_{i,p,k}\\|\\nabla L_{t}(x_{i,p,k})-\\bar{v}_{p,k}\\|_{\\infty}}\\\\ &{\\qquad\\qquad+\\,\\eta_{i,p,k}\\left(\\langle\\bar{v}_{p,k},\\bar{w}_{p,k}\\rangle-\\underset{w\\in\\mathcal{X}}{\\operatorname*{min}}\\langle\\bar{v}_{p,k},w\\rangle\\right)+\\frac{1}{2}\\beta\\eta_{i,p,k}{}^{2}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "To upper bound the regret, we bound the following two quantities separately. ", "page_idx": 5}, {"type": "text", "text": "Step 1: bound $\\|\\nabla L_{t}(x_{i,p,k})-\\bar{v}_{p,k}\\|_{\\infty}$ in Lemma 3. We show that every index of the $d$ -dimensional vector $\\nabla L_{t}(x_{i,p,k})-\\bar{v}_{p,k}$ is $\\scriptstyle O\\left({\\frac{\\alpha^{2}+\\beta^{2}}{b m}}\\right)$ -sub-Gaussian by induction on the depth of vertex in Lemma 2. Therefore, $\\mathbb{E}\\left[\\|\\nabla L_{t}(x_{i,p,k})-\\bar{v}_{p,k}\\|_{\\infty}\\right]$ is upper bounded by $O\\left((\\alpha+\\beta)\\sqrt{\\frac{\\log d}{b m}}\\right)$ ", "page_idx": 5}, {"type": "text", "text": "Step 2: bound $\\left\\langle\\bar{v}_{p,k},\\bar{w}_{p,k}\\right\\rangle\\mathrm{~-~}\\operatorname*{min}_{w\\in\\mathcal{X}}\\langle\\bar{v}_{p,k},w\\rangle$ in Lemma 5. We establish that $\\left\\langle\\bar{v}_{p,k},\\bar{w}_{p,k}\\right\\rangle\\mathrm{~-~}$ $\\operatorname*{min}_{w\\in\\mathcal{X}}\\langle\\bar{v}_{p,k},w\\rangle$ is upper bounded by $\\begin{array}{r}{\\frac{2}{m}_{n:1\\leq n\\leq d}\\Big|\\sum_{i=1}^{m}\\xi_{i,n}\\Big|}\\end{array}$ . This bound incorporates the maximum absolute sum of $m$ IID Laplace random variables $\\xi_{i,n}$ . To quantify the bound on the sum of $m$ IID Laplace random variables, we refer to Lemma 4. Consequently, we have $\\mathbb{E}\\left[\\langle\\bar{v}_{p,k},\\bar{w}_{p,k}\\rangle-\\operatorname*{min}_{w\\in\\mathcal{X}}\\langle\\bar{v}_{p,k},w\\rangle\\right]$ upper bounded by O \u03bbi,j\u221a,s ln d With the two steps above, we can show that for each time step $t$ in phase $p,\\mathbb{E}[L_{t}(x_{i,p,K})-L_{t}(x^{\\star})]$ is upper bounded by $\\begin{array}{r}{O\\bigg((\\alpha+\\beta)\\sqrt{\\frac{\\log d}{2^{p}m}}+\\frac{\\sqrt{\\alpha\\beta}\\log d}{m^{\\frac{1}{4}}\\sqrt{2^{p}\\varepsilon}}\\bigg)}\\end{array}$ . Summing up all the phases gives us the final upper bound. The full proof of Theorem 1 can be found in Appendix C.2. \u53e3 ", "page_idx": 5}, {"type": "text", "text": "When $\\beta$ is small, Theorem 1 reduces to the following corollary. ", "page_idx": 5}, {"type": "text", "text": "Corollary 1. If $\\beta=O(\\frac{\\log d}{\\sqrt{m}T\\varepsilon})$ , then, Fed-DP-OPE-Stoch (i) satisfies $\\varepsilon$ -DP and (ii) achieves the per-client regret of ", "page_idx": 6}, {"type": "equation", "text": "$$\nR e g(T,m)=O\\bigg(\\sqrt{\\frac{T\\log d}{m}}+\\frac{\\log T\\log d}{\\sqrt{m}\\varepsilon}\\bigg),\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "with (iii) a communication cost of $O\\left(m d\\log T\\right)$ . ", "page_idx": 6}, {"type": "text", "text": "The full proof of Corollary 1 can be found in Appendix C.2. ", "page_idx": 6}, {"type": "text", "text": "Remark 2. We note that the regret for the single-player counterpart Asi et al. (2022b) scales in $O\\left({\\sqrt{T\\log d}}+{\\frac{\\log d\\log T}{\\varepsilon}}\\right)$ when $\\begin{array}{r}{\\beta=O(\\frac{\\log d}{T\\varepsilon})}\\end{array}$ . Compared with this upper bound, Fed-DP-OPEStoch achieves $\\sqrt{m}$ -fold speed-up, with a communication cost of $O(m d\\log T)$ . This observation underscores the learning performance acceleration due to collaboration. Furthermore, our approach extends beyond the mere privatization of selected experts; we ensure the privacy of all information exchanged between the central server and clients. ", "page_idx": 6}, {"type": "text", "text": "Remark 3. We remark that Fed-DP-OPE-Stoch can be slightly modified into a centrally differentially private algorithm, assuming client-server communication is secure. Specifically, we change the local privatization process to a global privatization process on the server side. This mechanism results in less noise added and thus better utility performance. The detailed design is deferred to Appendix C.4 and the theoretical guarantees are provided in Theorem 7. ", "page_idx": 6}, {"type": "text", "text": "4 Federated OPE with Oblivious Adversaries: Lower bounds ", "text_level": 1, "page_idx": 6}, {"type": "text", "text": "In this section, we shift our attention to the more challenging oblivious adversaries. We establish new lower bounds for general oblivious adversaries. ", "page_idx": 6}, {"type": "text", "text": "To provide a foundational understanding, we start with some intuition behind FL. FL can potentially speed up the learning process by collecting more data at the same time to gain better insights to future predictions. In the stochastic setting, the advantage of collaboration lies in the ability to collect more observations from the same distribution, which leads to variance reduction. However, when facing oblivious adversaries, the problem changes fundamentally. Oblivious adversaries can select loss functions arbitrarily, meaning that having more data does not necessarily help with predicting their future selections. ", "page_idx": 6}, {"type": "text", "text": "The following theorem formally establishes the aforementioned intuition. ", "page_idx": 6}, {"type": "text", "text": "Theorem 2. For any fe\u221aderated OPE algorithm against oblivious adversaries, the per-client regret is lower bounded by $\\dot{\\Omega(\\sqrt{T\\log d})}$ . Let $\\varepsilon\\in(0,1]$ and $\\delta=o(1/T).$ , for any $(\\varepsilon,\\delta)$ -DP federated $O P E$ algorithm, the per-client regret is lower bounded by $\\Omega\\left(\\operatorname*{min}{\\left(\\frac{\\log d}{\\varepsilon},T\\right)}\\right)$ . ", "page_idx": 6}, {"type": "text", "text": "Remark 4. Theorem 2 states that with oblivious adversaries, the per-client regret under any federated OPE is fundamentally independent of the number of clients $m$ , indicating that, the collaborative effort among multiple clients does not yield a reduction in the regret lower bound. This is contrary to typical scenarios where collaboration can lead to shared insights and improve overall performance. The varied and unpredictable nature of oblivious adversaries nullifies the typical advantages of collaboration. Theorem 2 also emphasizes the influence of the DP guarantees. Our lower bounds represent the first non-trivial impossibility results for the federated OPE to the best of our knowledge. ", "page_idx": 6}, {"type": "text", "text": "Proof sketch. We examine the case when all clients receive the same loss function from the oblivious adversary at each time step, i.e. $l_{i,t}=l_{t}^{\\prime}$ . Within this framework, we define the \u201caverage policy\" among all clients, i.e., m1  im=1 pi,t(k), \u2200k \u2208[d]. This leads us to express the per-client regret as: Reg(T, m) = tT= $\\begin{array}{r}{\\mathrm{Reg}(T,m)\\,=\\,\\sum_{t=1}^{T}\\sum_{k=1}^{d}p_{t}^{\\prime}(k)\\cdot l_{t}^{\\prime}(k)\\,-\\,\\sum_{t=1}^{T}l_{t}^{\\prime}(x^{\\star})}\\end{array}$ . Note that $p_{t}^{\\prime}(k)$ is defined by $p_{1,t}(k),\\ldots,p_{m,t}(k)$ , wh ich in turn are determined by $l_{1,1},\\dotsc,l_{m,t-1}$ . According to our choice of $l_{i,t}\\,=\\,l_{t}^{\\prime}$ , $p_{t}^{\\prime}(k)$ is determined by $l_{1}^{\\prime},l_{2}^{\\prime},\\ldots,l_{t-1}^{\\prime}$ . Therefore, $p_{1}^{\\prime},p_{2}^{\\prime},\\ldots,p_{t}^{\\prime}$ are generated by a legitimate algorithm for online learning with expert advice problems. Through our policy reduction approach in FL, we can reduce the federated problem to a single-player setting, showing the equivalence of per-client and single-player regret against the oblivious adversary we construct, thus obtaining the regret lower bound. We believe that this technique will be useful in future analysis of other FL algorithm. Incorporating DP constraints, we refer to Lemma 9, which transforms the DP online learning problem to a well-examined DP batch model. The full proof of Theorem 2 can be found in Appendix D. \u53e3 ", "page_idx": 6}, {"type": "text", "text": "", "page_idx": 7}, {"type": "text", "text": "5 Federated OPE with Oblivious Adversaries: Realizable Setting ", "text_level": 1, "page_idx": 7}, {"type": "text", "text": "Given the impossibility results in the general oblivious adversaries setting, one natural question we aim to answer is, is there any special scenarios where we can still harness the power of federation even in presence of oblivious adversaries? Towards this end, in this section, we focus on the (near) realizable setting, formally defined below. ", "page_idx": 7}, {"type": "text", "text": "Definition 2 (Realizability). A federated OPE problem is realizable if there exists a feasible solution $x^{\\star}\\in[d]$ such that $\\textstyle\\sum_{t=1}^{T}l_{i,t}(x^{\\star})=0$ , $\\forall i\\in[m]$ . If the best expert achieves small loss $L^{\\star}\\ll T$ , i.e., there exists $x^{\\star}\\in[d]$ such that $\\textstyle\\sum_{t=1}^{T}l_{i,t}(x^{\\star})\\leq L^{\\star}$ , $\\forall i\\in[m]$ , the problem is near-realizable. ", "page_idx": 7}, {"type": "text", "text": "Intuitively, collaboration is notably advantageous in this context, as all clients share the same goal of reaching the zero-loss solution $x^{\\star}$ . As more clients participate, the shared knowledge pool expands, making the identification of the optimal solution more efficient. In the following, we first provide regret lower bounds to quantify this benefit formally, and then show that a sparse vector based federated algorithm can almost achieve such lower bounds thus is nearly optimal. ", "page_idx": 7}, {"type": "text", "text": "5.1 Lower Bound ", "text_level": 1, "page_idx": 7}, {"type": "text", "text": "Theorem 3. Let $\\varepsilon\\leq1$ and $\\delta\\leq\\varepsilon/d$ . For any $(\\varepsilon,\\delta)$ -DP federated OPE algorithm against oblivious adversaries in the realizable setting, the per-client regret is lower bounded by $\\Omega\\left(\\frac{\\log(d)}{m\\varepsilon}\\right)$ . Remark 5. In the single-player setting, the regret bound is $\\Omega\\left(\\frac{\\log(d)}{\\varepsilon}\\right)$ (Asi et al., 2023). In the federated setting, our results imply that the per-client regret is reduced to $\\textstyle{\\frac{1}{m}}$ times the single-player regret. This indicates a possible $m$ -fold speed-up in the federated setting. ", "page_idx": 7}, {"type": "text", "text": "Proof sketch. To begin, we consider a specific oblivious adversary. We introduce two prototype loss functions: $l^{0}(\\bar{x)}\\,=\\,0$ for all $x\\,\\in\\,[d]$ and for $j\\;\\in\\;[d]\\;l^{j}(x)^{\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\$ if $x\\,=\\,j$ and otherwise $l^{j}(x)=1$ . An oblivious adversary picks one of the $d$ sequences $S^{1},\\ldots,S^{d}$ uniformly at random, where $\\mathcal{S}^{j}\\,=\\,(l_{1,1}^{j},\\...\\,,l_{m,T}^{j})$ such that $l_{i,t}^{j}\\,=\\,l^{0}$ if $t\\,=\\,1,\\,.\\,.\\,.\\,,T\\,-\\,k$ , otherwise, $l_{i,t}^{j}\\,=\\,l^{j}$ , and $\\textstyle k={\\frac{\\log d}{2m\\varepsilon}}$ l2omg \u03b5d . Assume there exists an algorithm such that the per-client regret is upper bounded by $\\frac{\\log(d)}{32m\\varepsilon}$ 32m\u03b5 . This would imply that for at least $d/2$ of $S^{1},\\ldots,S^{d}$ , the per-client regret is upper bounded by $\\frac{\\log(d)}{16m\\varepsilon}$ . Assume without loss of generality these sequences are $S^{1},\\ldots,S^{d/2}$ . We let $B_{j}$ be the set of expert selections that has low regret on $S^{j}$ . We can show that $B_{j}$ and $B_{j^{\\prime}}$ are disjoint for $j\\neq j^{\\prime}$ , implying choosing any expert $j$ leads to low regret for loss sequence $S^{j}$ but high regret for $\\delta^{j^{\\prime}}$ . By group privacy, we have $\\begin{array}{r}{\\mathbb{P}\\left(\\boldsymbol{A}\\left(\\boldsymbol{S^{j}}\\right)\\in\\mathcal{B}_{j^{\\prime}}\\right)\\geq e^{-m k\\varepsilon}\\mathbb{P}\\left(\\boldsymbol{A}\\left(\\boldsymbol{S^{j^{\\prime}}}\\right)\\in\\mathcal{B}_{j^{\\prime}}\\right)-m k\\delta}\\end{array}$ , leading to a contradiction when $d\\geq32$ . The full proof of Theorem 3 can be found in Appendix E.1. \u53e3 ", "page_idx": 7}, {"type": "text", "text": "5.2 Algorithm Design ", "text_level": 1, "page_idx": 7}, {"type": "text", "text": "We develop a new algorithm Fed-SVT. Our algorithm operates as follows: ", "page_idx": 7}, {"type": "text", "text": "Periodic communication. We adopt a fixed communication schedule in our federated setting, splitting the time horizon $T$ into $T/N$ phases, each with length $N$ . In Fed-SVT, every client selects the same expert, i.e., $x_{i,t}=x_{t}$ at each time step $t$ . Initially, each client starts with a randomly chosen expert $x_{1}$ . At the beginning of each phase $n$ , each client sends the accumulated loss of the last phase t\u2032=(n\u22121)N li,t\u2032(x) to the central server. ", "page_idx": 7}, {"type": "text", "text": "Global expert selection. The server, upon receiving $\\textstyle\\sum_{t^{\\prime}=(n-1)N}^{n N-1}l_{i,t^{\\prime}}(x)$ from all clients, decides whether to continue with the current expert or switch to a new one. This decision is grounded in the Sparse-Vector algorithm (Asi et al., 2023), where the accumulated loss from all clients over a phase is treated as a single loss instance in the Sparse-Vector algorithm. Based on the server\u2019s expert decision, clients update their experts accordingly. The full algorithm is provided in Appendix E.2. ", "page_idx": 7}, {"type": "text", "text": "5.3 Theoretical Guarantees ", "text_level": 1, "page_idx": 8}, {"type": "text", "text": "Theorem 4. Let $\\begin{array}{r l r}{l_{i,t}}&{{}\\in}&{[0,1]^{d}}\\end{array}$ be chosen by an oblivious adversary under nearrealizability assumption. Fed-SVT is $\\varepsilon{\\mathrm{-}}D P,$ the communication cost scales in $O\\left(m d T/N\\right)$ , and with probability at least $1\\ -\\ O(\\rho)$ , the pre-client regret is upper bounded by log2(d)+log m\u03b5NT 22\u03c1 log( \u03c1d)+ (N + L\u22c6) log d\u03c1  . Moreover, Fed-SVT is (\u03b5, \u03b4)-DP, the communication cost scales in $O\\left(m d T/N\\right)$ , and with probability at least $1-O(\\rho)$ , the pre-client regret is upper bounded by $\\begin{array}{r}{O\\left(\\frac{\\log^{\\frac{3}{2}}(d)\\sqrt{\\log(\\frac{1}{\\delta})}+\\log\\left(\\frac{T^{2}}{N^{2}\\rho}\\right)\\log\\left(\\frac{d}{\\rho}\\right)}{m\\varepsilon}+(N+L^{\\star})\\log\\left(\\frac{d}{\\rho}\\right)\\right).}\\end{array}$ ", "page_idx": 8}, {"type": "text", "text": "Remark 6. Note that when $\\begin{array}{r}{N+L^{\\star}=O\\left(\\frac{\\log T}{m\\varepsilon}\\right)}\\end{array}$ lomg \u03b5T , then, under Fed-SVT, the per-client regret upper bound scales in $\\textstyle O\\left({\\frac{\\log^{2}d+\\log T\\log d}{m\\varepsilon}}\\right)$ for $\\varepsilon$ -DP and $\\begin{array}{r}{O\\left(\\frac{\\log T\\log d+\\log^{3/2}d\\sqrt{\\log(1/\\delta)}}{m\\varepsilon}\\right)}\\end{array}$ for $(\\varepsilon,\\delta)$ -DP. Compared to the best upper bound $\\scriptstyle O\\,\\left({\\frac{\\log^{2}d+\\log T\\log d}{\\varepsilon}}\\right)$ and $\\begin{array}{r}{O\\left(\\frac{\\log T\\log d+\\log^{3/2}d\\sqrt{\\log(1/\\delta)}}{\\varepsilon}\\right)}\\end{array}$ for the single-player scenario (Asi et al., 2023), our results indicate an $m$ -fold regret speed-up. Note that our lower bound (Theorem 3) scales in \u2126 lomg \u03b5d . Our upper bound matches with the lower bound in terms of $m$ and $\\epsilon$ , and is nearly optimal up to logarithmic factors.   \nThe proof of Theorem 4 is presented in Appendix E.3. ", "page_idx": 8}, {"type": "text", "text": "6 Numerical Experiments ", "text_level": 1, "page_idx": 8}, {"type": "text", "text": "Fed-DP-OPE-Stoch. We conduct experiments in a synthetic environment to validate the theoretical performances of Fed-DP-OPE-Stoch, and compare them with its single-player counterpart Limited Updates (Asi et al., 2022b). ", "page_idx": 8}, {"type": "image", "img_path": "T826pwZLci/tmp/78a184c5c72fd1c81bc90cbedee58eb14b1b192222239e4c5b08a28927989c56.jpg", "img_caption": ["Figure 1: Per-client regret. "], "img_footnote": [], "page_idx": 8}, {"type": "text", "text": "We first generate true class distributions for each client $i\\,\\in\\,[m]$ and timestep $t\\in[T]$ , which are sampled IID from Gaussian distributions with means and variances sampled uniformly. Following Gaussian sampling, we apply a softmax transformation and normalization to ensure the outputs are valid probability distributions. Then we generate a sequence of IID loss functions for $m$ clients over $T$ timesteps using cross-entropy between true class distributions and predictions. We set $T_{1}=1$ in Fed-DP-OPE-Stoch, therefore the communication cost scales in $O(m d\\log T)$ . We set $m=10$ , $T=2^{14}$ , $\\varepsilon=10$ , $\\delta=0$ and $d=100$ . The per-client cumulative regret as a function of $T$ is plotted in Figure 1. We see that Fed-DP-OPE-Stoch outperforms Limited Updates significantly, indicating the regret speed-up due to collaboration. Results with different seeds are provided in Appendix F. ", "page_idx": 8}, {"type": "text", "text": "", "page_idx": 8}, {"type": "text", "text": "Fed-SVT. We conduct experiments in a synthetic environment, comparing Fed-SVT with the single-player model Sparse-Vector (Asi et al., 2023). We generate random losses for each expert at every timestep and for each client, ensuring that one expert always has zero loss to simulate an optimal choice. We set $m=10$ , $\\dot{T}=2^{9}$ , $\\varepsilon=10$ , $\\delta=0$ and $d=100$ . In FedSVT, we experiment with communication intervals $N=1,30,50$ , where communication cost scales in $O(m d T/N)$ . The per-client cumulative regret as a function of $T$ is plotted in Figure 2. Our results show that ", "page_idx": 8}, {"type": "image", "img_path": "T826pwZLci/tmp/afa47419c3cffcf18dabf8e1df992dd0b42023d447754c2fda02627b12557631.jpg", "img_caption": ["Figure 2: Per-client regret. "], "img_footnote": [], "page_idx": 8}, {"type": "text", "text": "Fed-SVT significantly outperforms the Sparse-Vector, highlighting the benefits of collaborative expert selection in regret speed-up, even at lower communication costs (notably in the $N=50$ case). Results with different seeds are provided in Appendix F. Additionally, we evaluate the performances of Fed-SVT on the MovieLens-1M dataset (Harper and Konstan, 2015) in Appendix G. ", "page_idx": 8}, {"type": "text", "text": "7 Conclusions ", "text_level": 1, "page_idx": 8}, {"type": "text", "text": "In this paper, we have advanced the state-of-the-art of differentially private federated online prediction from experts, addressing both stochastic and oblivious adversaries. Our Fed-DP-OPE-Stoch algorithm showcases a significant $\\sqrt{m}$ -fold regret speed-up compared to single-player models with stochastic adversaries, while effectively maintaining logarithmic communication costs. For oblivious adversaries, we established non-trivial lower bounds, highlighting the limited benefits of client collaboration. Additionally, our Fed-SVT algorithm demonstrates an $m$ -fold speed-up, indicating near-optimal performance in settings with low-loss experts. One limitation of this work is the lack of experiments on real-world federated learning scenarios such as recommender systems and healthcare. We leave this exploration to future work. ", "page_idx": 8}, {"type": "text", "text": "", "page_idx": 9}, {"type": "text", "text": "Acknowledgments ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "The work of F. Gao, R. Huang and J. Yang was supported in part by the U.S. National Science Foundation under the grants CNS-1956276, CNS-2114542 and ECCS-2133170. ", "page_idx": 9}, {"type": "text", "text": "References ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "Agarwal, A., Foster, D. P., Hsu, D. J., Kakade, S. M., and Rakhlin, A. (2011). Stochastic convex optimization with bandit feedback. Advances in Neural Information Processing Systems, 24. ", "page_idx": 9}, {"type": "text", "text": "Agarwal, N., Kale, S., Singh, K., and Thakurta, A. (2023a). Differentially private and lazy online convex optimization. In The Thirty Sixth Annual Conference on Learning Theory, pages 4599\u20134632. PMLR.   \nAgarwal, N., Kale, S., Singh, K., and Thakurta, A. G. (2023b). Improved differentially private and lazy online convex optimization. arXiv preprint arXiv:2312.11534.   \nAgarwal, N. and Singh, K. (2017). The price of differential privacy for online learning. In International Conference on Machine Learning, pages 32\u201340. PMLR.   \nAltschuler, J. and Talwar, K. (2018). Online learning over a finite action set with limited switching. In Conference On Learning Theory, pages 1569\u20131573. PMLR.   \nArora, S., Hazan, E., and Kale, S. (2012). The multiplicative weights update method: a meta-algorithm and applications. Theory of computing, 8(1):121\u2013164.   \nAsi, H., Chadha, K., Cheng, G., and Duchi, J. (2022a). Private optimization in the interpolation regime: faster rates and hardness results. In International Conference on Machine Learning, pages 1025\u20131045. PMLR.   \nAsi, H., Duchi, J., Fallah, A., Javidbakht, O., and Talwar, K. (2021a). Private adaptive gradient methods for convex optimization. In International Conference on Machine Learning, pages 383\u2013392. PMLR.   \nAsi, H., Feldman, V., Koren, T., and Talwar, K. (2021b). Private stochastic convex optimization: Optimal rates in l1 geometry. In International Conference on Machine Learning, pages 393\u2013403. PMLR.   \nAsi, H., Feldman, V., Koren, T., and Talwar, K. (2022b). Private online prediction from experts: Separations and faster rates. arXiv preprint arXiv:2210.13537.   \nAsi, H., Feldman, V., Koren, T., and Talwar, K. (2023). Near-optimal algorithms for private online optimization in the realizable regime. arXiv preprint arXiv:2302.14154.   \nAzize, A. and Basu, D. (2022). When privacy meets partial information: A refined analysis of differentially private bandits. Advances in Neural Information Processing Systems, 35:32199\u2013 32210.   \nBar-On, Y. and Mansour, Y. (2019). Individual regret in cooperative nonstochastic multi-armed bandits. Advances in Neural Information Processing Systems, 32.   \nBassily, R., Feldman, V., Talwar, K., and Guha Thakurta, A. (2019). Private stochastic convex optimization with optimal rates. Advances in neural information processing systems, 32.   \nBassily, R., Smith, A., and Thakurta, A. (2014). Private empirical risk minimization: Efficient algorithms and tight error bounds. In 2014 IEEE 55th annual symposium on foundations of computer science, pages 464\u2013473. IEEE.   \nBubeck, S., Li, Y., Luo, H., and Wei, C.-Y. (2019). Improved path-length regret bounds for bandits. In Conference On Learning Theory, pages 508\u2013528. PMLR.   \nBuccapatnam, S., Eryilmaz, A., and Shroff, N. B. (2014). Stochastic bandits with side observations on networks. In The 2014 ACM international conference on Measurement and modeling of computer systems, pages 289\u2013300.   \nCaron, S., Kveton, B., Lelarge, M., and Bhagat, S. (2012). Leveraging side observations in stochastic bandits. arXiv preprint arXiv:1210.4839.   \nCesa-Bianchi, N., Gentile, C., Mansour, Y., and Minora, A. (2016). Delay and cooperation in nonstochastic bandits. In Conference on Learning Theory, pages 605\u2013622. PMLR.   \nCesa-Bianchi, N. and Lugosi, G. (2006). Prediction, learning, and games. Cambridge university press.   \nCesa-Bianchi, N., Mansour, Y., and Stoltz, G. (2007). Improved second-order bounds for prediction with expert advice. Machine Learning, 66:321\u2013352.   \nCharisopoulos, V., Esfandiari, H., and Mirrokni, V. (2023). Robust and private stochastic linear bandits. In International Conference on Machine Learning, pages 4096\u20134115. PMLR.   \nChen, L., Yu, Q., Lawrence, H., and Karbasi, A. (2020). Minimax regret of switching-constrained online convex optimization: No phase transition. Advances in Neural Information Processing Systems, 33:3477\u20133486.   \nCheng, D., Zhou, X., and Ji, B. (2023). Understanding the role of feedback in online learning with switching costs. arXiv preprint arXiv:2306.09588.   \nChowdhury, S. R. and Zhou, X. (2022a). Distributed differential privacy in multi-armed bandits. arXiv preprint arXiv:2206.05772.   \nChowdhury, S. R. and Zhou, X. (2022b). Shuffle private linear contextual bandits. arXiv preprint arXiv:2202.05567.   \nCotter, A., Shamir, O., Srebro, N., and Sridharan, K. (2011). Better mini-batch algorithms via accelerated gradient methods. Advances in neural information processing systems, 24.   \nDubey, A. and Pentland, A. (2020). Differentially-private federated linear bandits. Advances in Neural Information Processing Systems, 33:6003\u20136014.   \nDubey, A. and Pentland, A. (2022). Private and byzantine-proof cooperative decision-making. arXiv preprint arXiv:2205.14174.   \nDuchi, J., Hazan, E., and Singer, Y. (2011). Adaptive subgradient methods for online learning and stochastic optimization. Journal of machine learning research, 12(7).   \nDuchi, J. C., Chaturapruek, S., and R\u00e9, C. (2015). Asynchronous stochastic convex optimization. arXiv preprint arXiv:1508.00882.   \nDuchi, J. C., Lafferty, J., Zhu, Y., et al. (2016). Local minimax complexity of stochastic convex optimization. Advances in Neural Information Processing Systems, 29.   \nDwork, C., Naor, M., Pitassi, T., and Rothblum, G. N. (2010). Differential privacy under continual observation. In Proceedings of the forty-second ACM symposium on Theory of computing, pages 715\u2013724.   \nDwork, C., Roth, A., et al. (2014). The algorithmic foundations of differential privacy. Foundations and Trends\u00ae in Theoretical Computer Science, 9(3\u20134):211\u2013407.   \nFeldman, V., Koren, T., and Talwar, K. (2020). Private stochastic convex optimization: optimal rates in linear time. In Proceedings of the 52nd Annual ACM SIGACT Symposium on Theory of Computing, pages 439\u2013449.   \nFichtenberger, H., Henzinger, M., and Upadhyay, J. (2023). Constant matters: Fine-grained error bound on differentially private continual observation. In International Conference on Machine Learning, pages 10072\u201310092. PMLR.   \nFreund, Y. and Schapire, R. E. (1997). A decision-theoretic generalization of on-line learning and an application to boosting. Journal of computer and system sciences, 55(1):119\u2013139.   \nGarcelon, E., Chaudhuri, K., Perchet, V., and Pirotta, M. (2022). Privacy amplification via shuffilng for linear contextual bandits. In International Conference on Algorithmic Learning Theory, pages 381\u2013407. PMLR.   \nGauthier, F., Gogineni, V. C., Werner, S., Huang, Y.-F., and Kuh, A. (2023). Asynchronous online federated learning with reduced communication requirements. arXiv preprint arXiv:2303.15226.   \nGeulen, S., V\u00f6cking, B., and Winkler, M. (2010). Regret minimization for online buffering problems using the weighted majority algorithm. In COLT, pages 132\u2013143. Citeseer.   \nGolowich, N. and Livni, R. (2021). Littlestone classes are privately online learnable. Advances in Neural Information Processing Systems, 34:11462\u201311473.   \nGonen, A., Hazan, E., and Moran, S. (2019). Private learning implies online learning: An efficient reduction. Advances in Neural Information Processing Systems, 32.   \nGuha Thakurta, A. and Smith, A. (2013). (nearly) optimal algorithms for private online learning in full-information and bandit settings. Advances in Neural Information Processing Systems, 26.   \nHanna, O. A., Girgis, A. M., Fragouli, C., and Diggavi, S. (2022). Differentially private stochastic linear bandits:(almost) for free. arXiv preprint arXiv:2207.03445.   \nHarper, F. M. and Konstan, J. A. (2015). The movielens datasets: History and context. Acm transactions on interactive intelligent systems (tiis), 5(4):1\u201319.   \nHe, J., Wang, T., Min, Y., and Gu, Q. (2022). A simple and provably efficient algorithm for asynchronous federated contextual linear bandits. Advances in neural information processing systems, 35:4762\u20134775.   \nHong, S. and Chae, J. (2021). Communication-efficient randomized algorithm for multi-kernel online federated learning. IEEE transactions on pattern analysis and machine intelligence, 44(12):9872\u2013 9886.   \nHu, B. and Hegde, N. (2022). Near-optimal thompson sampling-based algorithms for differentially private stochastic bandits. In Uncertainty in Artificial Intelligence, pages 844\u2013852. PMLR.   \nHu, C., Pan, W., and Kwok, J. (2009). Accelerated gradient methods for stochastic optimization and online learning. Advances in Neural Information Processing Systems, 22.   \nHuang, R., Wu, W., Yang, J., and Shen, C. (2021). Federated linear contextual bandits. Advances in neural information processing systems, 34:27057\u201327068.   \nHuang, R., Zhang, H., Melis, L., Shen, M., Hejazinia, M., and Yang, J. (2023). Federated linear contextual bandits with user-level differential privacy. In International Conference on Machine Learning, pages 14060\u201314095. PMLR.   \nJain, P., Kothari, P., and Thakurta, A. (2012). Differentially private online learning. In Conference on Learning Theory, pages 24\u20131. JMLR Workshop and Conference Proceedings.   \nJain, P., Raskhodnikova, S., Sivakumar, S., and Smith, A. (2023). The price of differential privacy under continual observation. In International Conference on Machine Learning, pages 14654\u2013 14678. PMLR.   \nJain, P. and Thakurta, A. G. (2014). (near) dimension independent risk bounds for differentially private learning. In International Conference on Machine Learning, pages 476\u2013484. PMLR.   \nKalai, A. and Vempala, S. (2005). Efficient algorithms for online decision problems. Journal of Computer and System Sciences, 71(3):291\u2013307.   \nKaplan, H., Mansour, Y., Moran, S., Nissim, K., and Stemmer, U. (2023a). Black-box differential privacy for interactive ml. In Thirty-seventh Conference on Neural Information Processing Systems.   \nKaplan, H., Mansour, Y., Moran, S., Nissim, K., and Stemmer, U. (2023b). On differentially private online predictions. arXiv preprint arXiv:2302.14099.   \nKwon, D., Park, J., and Hong, S. (2023). Tighter regret analysis and optimization of online federated learning. IEEE Transactions on Pattern Analysis and Machine Intelligence.   \nLi, C. and Wang, H. (2022). Asynchronous upper confidence bound algorithms for federated linear bandits. In International Conference on Artificial Intelligence and Statistics, pages 6529\u20136553. PMLR.   \nLi, C., Zhou, P., Xiong, L., Wang, Q., and Wang, T. (2018). Differentially private distributed online learning. IEEE Transactions on Knowledge and Data Engineering, 30(8):1440\u20131453.   \nLi, F., Zhou, X., and Ji, B. (2022a). Differentially private linear bandits with partial distributed feedback. In 2022 20th International Symposium on Modeling and Optimization in Mobile, Ad hoc, and Wireless Networks (WiOpt), pages 41\u201348. IEEE.   \nLi, F., Zhou, X., and Ji, B. (2023). (private) kernelized bandits with distributed biased feedback. Proceedings of the ACM on Measurement and Analysis of Computing Systems, 7(1):1\u201347.   \nLi, S., Chen, W., Wen, Z., and Leung, K.-S. (2020a). Stochastic online learning with probabilistic graph feedback. In Proceedings of the AAAI Conference on Artificial Intelligence, pages 4675\u2013 4682.   \nLi, T., Song, L., and Fragouli, C. (2020b). Federated recommendation system via differential privacy. In 2020 IEEE international symposium on information theory (ISIT), pages 2592\u20132597. IEEE.   \nLi, W., Song, Q., Honorio, J., and Lin, G. (2022b). Federated x-armed bandit. arXiv preprint arXiv:2205.15268.   \nLittlestone, N. and Warmuth, M. K. (1994). The weighted majority algorithm. Information and computation, 108(2):212\u2013261.   \nLiu, C. and Belkin, M. (2018). Accelerating sgd with momentum for over-parameterized learning. arXiv preprint arXiv:1810.13395.   \nM Ghari, P. and Shen, Y. (2022). Personalized online federated learning with multiple kernels. Advances in Neural Information Processing Systems, 35:33316\u201333329.   \nMa, S., Bassily, R., and Belkin, M. (2018). The power of interpolation: Understanding the effectiveness of sgd in modern over-parametrized learning. In International Conference on Machine Learning, pages 3325\u20133334. PMLR.   \nMahdavi, M., Yang, T., and Jin, R. (2013). Stochastic convex optimization with multiple objectives. Advances in neural information processing systems, 26.   \nMcMahan, B., Moore, E., Ramage, D., Hampson, S., and y Arcas, B. A. (2017). Communicationefficient learning of deep networks from decentralized data. In Artificial intelligence and statistics, pages 1273\u20131282. PMLR.   \nMishra, N. and Thakurta, A. (2015). (nearly) optimal differentially private stochastic multi-arm bandits. In Proceedings of the Thirty-First Conference on Uncertainty in Artificial Intelligence, pages 592\u2013601.   \nMitra, A., Hassani, H., and Pappas, G. J. (2021). Online federated learning. In 2021 60th IEEE Conference on Decision and Control (CDC), pages 4083\u20134090. IEEE.   \nPark, J., Kwon, D., et al. (2022). Ofedqit: Communication-efficient online federated learning via quantization and intermittent transmission. arXiv preprint arXiv:2205.06491.   \nPatel, K. K., Wang, L., Saha, A., and Srebro, N. (2023). Federated online and bandit convex optimization. In International Conference on Machine Learning, pages 27439\u201327460. PMLR.   \nRakhlin, A., Sridharan, K., and Tewari, A. (2011). Online learning: Stochastic, constrained, and smoothed adversaries. Advances in neural information processing systems, 24.   \nRen, W., Zhou, X., Liu, J., and Shroff, N. B. (2020). Multi-armed bandits with local differential privacy. arXiv preprint arXiv:2007.03121.   \nSajed, T. and Sheffet, O. (2019). An optimal private stochastic-mab algorithm based on optimal private stopping rule. In International Conference on Machine Learning, pages 5579\u20135588. PMLR.   \nShalev-Shwartz, S. et al. (2012). Online learning and online convex optimization. Foundations and Trends\u00ae in Machine Learning, 4(2):107\u2013194.   \nShalev-Shwartz, S., Shamir, O., Srebro, N., and Sridharan, K. (2009). Stochastic convex optimization. In COLT, page 5.   \nShariff, R. and Sheffet, O. (2018). Differentially private contextual linear bandits. Advances in Neural Information Processing Systems, 31.   \nSherman, U. and Koren, T. (2021). Lazy oco: Online convex optimization on a switching budget. In Conference on Learning Theory, pages 3972\u20133988. PMLR.   \nShi, C. and Shen, C. (2021). Federated multi-armed bandits. In Proceedings of the AAAI Conference on Artificial Intelligence, pages 9603\u20139611.   \nShi, C., Shen, C., and Yang, J. (2021). Federated multi-armed bandits with personalization. In International conference on artificial intelligence and statistics, pages 2917\u20132925. PMLR.   \nSrebro, N., Sridharan, K., and Tewari, A. (2010). Smoothness, low noise and fast rates. Advances in neural information processing systems, 23.   \nSteinhardt, J. and Liang, P. (2014). Adaptivity and optimism: An improved exponentiated gradient algorithm. In International conference on machine learning, pages 1593\u20131601. PMLR.   \nTao, Y., Wu, Y., Zhao, P., and Wang, D. (2022). Optimal rates of (locally) differentially private heavytailed multi-armed bandits. In International Conference on Artificial Intelligence and Statistics, pages 1546\u20131574. PMLR.   \nTenenbaum, J., Kaplan, H., Mansour, Y., and Stemmer, U. (2021). Differentially private multi-armed bandits in the shuffle model. Advances in Neural Information Processing Systems, 34:24956\u2013 24967.   \nTossou, A. and Dimitrakakis, C. (2016). Algorithms for differentially private multi-armed bandits. In Proceedings of the AAAI Conference on Artificial Intelligence.   \nTossou, A., Dimitrakakis, C., and Dubhashi, D. (2017). Thompson sampling for stochastic bandits with graph feedback. In Proceedings of the AAAI Conference on Artificial Intelligence.   \nVaswani, S., Bach, F., and Schmidt, M. (2019). Fast and faster convergence of sgd for overparameterized models and an accelerated perceptron. In The 22nd international conference on artificial intelligence and statistics, pages 1195\u20131204. PMLR.   \nWang, C.-H., Li, W., Cheng, G., and Lin, G. (2022a). Federated online sparse decision making. arXiv preprint arXiv:2202.13448.   \nWang, H., Zhao, D., and Wang, H. (2022b). Dynamic global sensitivity for differentially private contextual bandits. In Proceedings of the 16th ACM Conference on Recommender Systems, pages 179\u2013187.   \nWang, H., Zhao, Q., Wu, Q., Chopra, S., Khaitan, A., and Wang, H. (2020). Global and local differential privacy for collaborative bandits. In Proceedings of the 14th ACM Conference on Recommender Systems, pages 150\u2013159.   \nWang, Y., Hu, J., Chen, X., and Wang, L. (2019). Distributed bandit learning: Near-optimal regret with efficient communication. arXiv preprint arXiv:1904.06309.   \nWei, C.-Y. and Luo, H. (2018). More adaptive algorithms for adversarial bandits. In Conference On Learning Theory, pages 1263\u20131291. PMLR.   \nWoodworth, B. E. and Srebro, N. (2021). An even more optimal stochastic optimization algorithm: minibatching and interpolation learning. Advances in Neural Information Processing Systems, 34:7333\u20137345.   \nWu, Y., Gy\u00f6rgy, A., and Szepesv\u00e1ri, C. (2015). Online learning with gaussian payoffs and side observations. Advances in Neural Information Processing Systems, 28.   \nWu, Y., Zhou, X., Tao, Y., and Wang, D. (2023). On private and robust bandits. arXiv preprint arXiv:2302.02526.   \nYi, J. and Vojnovic, M. (2022). On regret-optimal cooperative nonstochastic multi-armed bandits. arXiv preprint arXiv:2211.17154.   \nYi, J. and Vojnovic, M. (2023). Doubly adversarial federated bandits. In International Conference on Machine Learning, pages 39951\u201339967. PMLR.   \nZheng, K., Cai, T., Huang, W., Li, Z., and Wang, L. (2020). Locally differentially private (contextual) bandits learning. Advances in Neural Information Processing Systems, 33:12300\u201312310.   \nZhou, X. and Chowdhury, S. R. (2023). On differentially private federated linear contextual bandits. arXiv preprint arXiv:2302.13945.   \nZhu, Z., Zhu, J., Liu, J., and Liu, Y. (2021). Federated bandit: A gossiping approach. Proceedings of the ACM on Measurement and Analysis of Computing Systems, 5(1):1\u201329.   \nZinkevich, M. (2003). Online convex programming and generalized infinitesimal gradient ascent. In Proceedings of the 20th international conference on machine learning (icml-03), pages 928\u2013936. ", "page_idx": 9}, {"type": "text", "text": "", "page_idx": 10}, {"type": "text", "text": "", "page_idx": 11}, {"type": "text", "text": "", "page_idx": 12}, {"type": "text", "text": "", "page_idx": 13}, {"type": "text", "text": "", "page_idx": 14}, {"type": "text", "text": "A Related Work ", "text_level": 1, "page_idx": 15}, {"type": "text", "text": "Online learning with stochastic adversaries. Online learning with stochastic adversaries has been extensively studied (Rakhlin et al., 2011; Duchi et al., 2011; Hu et al., 2009; Li et al., 2020a; Caron et al., 2012; Buccapatnam et al., 2014; Tossou et al., 2017; Wu et al., 2015). This problem is also closely related to stochastic convex optimization (Shalev-Shwartz et al., 2009; Mahdavi et al., 2013; Duchi et al., 2015; Agarwal et al., 2011; Duchi et al., 2016) since online learning with stochastic adversaries can be transformed into the stochastic convex optimization problem using online-tobatch conversion. In the federated setting, Mitra et al. (2021) proposed a federated online mirror descent method. Patel et al. (2023) presented a federated projected online stochastic gradient descent algorithm. Research on online learning with stochastic adversaries incorporating DP has also seen significant advancements (Bassily et al., 2014, 2019; Feldman et al., 2020; Asi et al., 2021a,b, 2022b). ", "page_idx": 15}, {"type": "text", "text": "Online learning with non-stochastic adversaries. Online learning with non-stochastic adversaries has been extensively studied (Cesa-Bianchi and Lugosi, 2006; Littlestone and Warmuth, 1994; Freund and Schapire, 1997; Zinkevich, 2003). Federated online learning with non-stochastic adversaries, a more recent development, was introduced by Hong and Chae (2021). Mitra et al. (2021) developed a federated online mirror descent method. Park et al. (2022) presented a federated online gradient descent algorithm. Kwon et al. (2023) studied data heterogeneity. Furthermore, Li et al. (2018) and Patel et al. (2023) explored distributed online and bandit convex optimization. Gauthier et al. (2023) focused on the asynchronous settings. Research into online learning with limited switching has also been explored by Kalai and Vempala (2005); Geulen et al. (2010); Altschuler and Talwar (2018); Chen et al. (2020); Sherman and Koren (2021); He et al. (2022); Li et al. (2022b); Cheng et al. (2023). ", "page_idx": 15}, {"type": "text", "text": "Differentially private online learning with non-stochastic adversaries was pioneered by Dwork et al. (2010). Several studies have explored OPE problem with DP constraints (Jain et al., 2012; Guha Thakurta and Smith, 2013; Jain and Thakurta, 2014; Agarwal and Singh, 2017; Asi et al., 2022b). Specifically, Jain and Thakurta (2014) and Agarwal and Singh (2017) focused on methods based on follow the regularized leader. Asi et al. (2022b) proposed an algorithm using the shrinking dartboard method. ", "page_idx": 15}, {"type": "text", "text": "Studies addressing differentially private online learning with non-stochastic adversaries in other contexts have also made significant strides. Kaplan et al. (2023b) focused on online classification problem with joint DP constraints. Fichtenberger et al. (2023) introduced a constant improvement. Gonen et al. (2019) and Kaplan et al. (2023a) studied the relationship between private learning and online learning. Agarwal et al. (2023a) and Agarwal et al. (2023b) studied the DP online convex optimization problem. Research on differentially private federated online learning with non-stochastic adversaries is very limited to the best of our knowledge. ", "page_idx": 15}, {"type": "text", "text": "Online learning under realizability assumption. Several works have studied online learning in the realizable setting. Srebro et al. (2010) studied mirror descent for online optimization. Shalev-Shwartz et al. (2012) studied the weighted majority algorithm. There is also a line of work studying stochastic convex optimization in the realizable setting (Cotter et al., 2011; Ma et al., 2018; Vaswani et al., 2019; Liu and Belkin, 2018; Woodworth and Srebro, 2021; Asi et al., 2022a). Additionally, some researchers have recently focused on the variance or the path length of the best expert (Cesa-Bianchi et al., 2007; Steinhardt and Liang, 2014; Wei and Luo, 2018; Bubeck et al., 2019). When DP constraint is considered, Asi et al. (2023) introduced algorithms using the sparse vector technique. Golowich and Livni (2021) studied DP online classification. ", "page_idx": 15}, {"type": "text", "text": "Multi-armed bandits with DP. Research on DP multi-armed bandits has developed along various lines (Mishra and Thakurta, 2015; Tossou and Dimitrakakis, 2016; Sajed and Sheffet, 2019; Azize and Basu, 2022). Further, Hu and Hegde (2022) proposed a Thompson-sampling-based approach, Tao et al. (2022) explored the heavy-tailed rewards scenario, and Chowdhury and Zhou (2022a) achieved optimal regret in a distributed setting. Additionally, Ren et al. (2020) and Zheng et al. (2020) investigated local DP constraints. For linear contextual bandits with DP, significant studies were conducted by Shariff and Sheffet (2018); Wang et al. (2020, 2022b) and Hanna et al. (2022). Furthermore, Hanna et al. (2022); Chowdhury and Zhou (2022b); Garcelon et al. (2022) and Tenenbaum et al. (2021) focused on the shuffle model. Li et al. (2023) studied kernelized bandits with distributed biased feedback. Wu et al. (2023) and Charisopoulos et al. (2023) tackled privacy and robustness simultaneously. ", "page_idx": 15}, {"type": "text", "text": "Federated multi-armed bandits. Federated bandits have been studied extensively recently. Shi and Shen (2021) and Shi et al. (2021) investigated federated stochastic multi-armed bandits without and with personalization, respectively. Wang et al. (2019) considered the distributed setting. Huang et al. (2021), Wang et al. (2022a) and Li and Wang (2022) studied federated linear contextual bandits. Li et al. (2022b) focused on federated $\\mathcal{X}$ -armed bandits problem. Additionally, Cesa-Bianchi et al. (2016), Bar-On and Mansour (2019), Yi and Vojnovic (2022) and Yi and Vojnovic (2023) have studied cooperative multi-armed bandits problem with data exchange among neighbors. M Ghari and Shen (2022) have explored online model selection where each client learns a kernel-based model, utilizing the specific characteristics of kernel functions. ", "page_idx": 16}, {"type": "text", "text": "When data privacy is explicitly considered, Li et al. (2020b) and Zhu et al. (2021) studied federated bandits with DP guarantee. Dubey and Pentland (2022) investigated private and byzantine-proof cooperative decision-making in the bandits setting. Dubey and Pentland (2020) and Zhou and Chowdhury (2023) considered the linear contextual bandit model with joint DP guarantee. Li et al. (2022a) studied private distributed linear bandits with partial feedback. Huang et al. (2023) studied federated linear contextual bandits with user-level DP guarantee. ", "page_idx": 16}, {"type": "text", "text": "B Applications of Differentially Private Federated OPE ", "text_level": 1, "page_idx": 16}, {"type": "text", "text": "Differentially private federated online prediction has many important real-world applications. We provide three examples below. ", "page_idx": 16}, {"type": "text", "text": "Personalized Healthcare: Consider a federated online prediction setting where patients\u2019 wearable devices collect and process health data locally, and the central server aggregates privacy-preserving updates from devices to provide health recommendations or alerts. DP federated online prediction can speed up the learning process and improve prediction accuracy without exposing individual users\u2019 health data, thus ensuring patient privacy. ", "page_idx": 16}, {"type": "text", "text": "Financial Fraud Detection: DP federated online prediction can also enhance fraud detection systems across banking and financial services. Each client device (e.g. PC) locally analyzes transaction patterns and flags potential fraud without revealing sensitive transaction details to the central server. The server\u2019s role is to collect privacy-preserving updates from these clients to improve the global fraud detection model. This method ensures that the financial company can dynamically adapt to new fraudulent tactics, improving detection rates while safeguarding customers\u2019 financial privacy. ", "page_idx": 16}, {"type": "text", "text": "Personalized Recommender Systems: Each client (e.g. smartphone) can personalize content recommendations by analyzing user interactions and preferences locally. The central server (e.g. company) aggregates privacy-preserving updates from all clients to refine the recommendation model. Thus, DP federated online prediction improves the whole recommender system performance while maintaining each client\u2019s privacy. ", "page_idx": 16}, {"type": "text", "text": "C Algorithms and Proofs for Fed-DP-OPE-Stoch ", "text_level": 1, "page_idx": 16}, {"type": "text", "text": "C.1 DP-FW ", "text_level": 1, "page_idx": 16}, {"type": "text", "text": "In Fed-DP-OPE-Stoch, we run a DP-FW subroutine (Asi et al., 2021b) at each client $i$ in each phase $p$ . DP-FW maintains $T_{1}$ binary trees indexed by $1\\leq j\\leq T_{1}$ , each with depth $j$ , where $T_{1}$ is a predetermined parameter. An example of the tree structure is shown below. We introduce the notation $s\\,\\in\\,\\{0,1\\}^{\\le j}$ to denote vertices within binary tree $j.~\\emptyset$ signifies the tree\u2019s root. For any $s,s^{\\prime}\\,\\in\\,\\{0,1\\}^{\\le j}$ , if $s\\,=\\,s^{\\prime}0$ , then s denotes the left child of $s^{\\prime}$ . Conversely, when $s\\,=\\,s^{\\prime}1$ , $s$ is attributed as the right child of $s^{\\prime}$ . For each client $i$ , each vertex $s$ in the binary tree $j$ corresponds to a parameter $x_{i,j,s}$ and a gradient estimate $v_{i,j,s}$ . Each client iteratively updates parameters and gradient estimates by visiting the vertices of a binary tree according to the Depth-First Search (DFS) order: as it visits a left child vertex $s$ , the algorithm maintains the parameter $x_{i,j,s}$ and the gradient estimate $v_{i,j,s}$ identical to those of its parent vertex $s^{\\prime}$ , i.e. $v_{i,j,s}=v_{i,j,s^{\\prime}}$ and $x_{i,j,s}=x_{i,j,s^{\\prime}}$ . As it proceeds to a right child vertex, we uniformly select $2^{-|s|}b$ loss functions from set $B_{i,p}=\\left\\{l_{i,2^{p-2}},\\ldots,l_{i,2^{p-1}-1}\\right\\}$ to subset $B_{i,j,s}$ without replacement, where $b$ denoting the predetermined batch size and $|s|$ representing the depth of the vertex $s$ . Then the algorithm improves the gradient estimate $v_{i,j,s}$ at the current vertex $s$ of tree $j$ using the estimate $v_{i,j,s^{\\prime}}$ at the parent vertex $s^{\\prime}$ , i.e. ", "page_idx": 16}, {"type": "equation", "text": "$$\nv_{i,j,s}=v_{i,j,s^{\\prime}}+\\nabla l(x_{i,j,s};B_{i,j,s})-\\nabla l(x_{i,j,s^{\\prime}};B_{i,j,s}).\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "1: Input: Sample set $\\boldsymbol{\\mathrm{\\Delta}}\\boldsymbol{\\mathrm{\\Omega}}_{\\boldsymbol{B}}$ , number of trees $T_{1}$ , batch size $b$ .   \n2: for $j=1$ to $T_{1}$ do   \n3: Set xi,j,\u2205= xi,j\u22121,Lj\u22121   \n4: Uniformly select $b$ samples to $B_{i,j,\\emptyset}$   \n5: $\\boldsymbol{v}_{i,j,\\emptyset}=\\nabla l_{i,t}(\\boldsymbol{x}_{i,j,\\emptyset};B_{i,j,\\emptyset})$   \n6: for $s\\in\\mathrm{DFS}[j]$ do   \n7: Let $s=s^{\\prime}a$ where $a\\in\\{0,1\\}$   \n8: if $a==0$ then   \n9: $v_{i,j,s}=v_{i,j,s^{\\prime}};x_{i,j,s}=x_{i,j,s^{\\prime}}$   \n10: else   \n11: Uniformly select $2^{-|s|}b$ samples to $B_{i,j,s}$   \n12: Update $v_{i,j,s}$ according to Equation (3)   \n13: end if   \n14: end for   \n15: end for   \n16: Return $\\left\\{v_{i,j,s}\\right\\}_{j\\in[T_{1}],s\\in\\{0,1\\}}{\\le}j$ ", "page_idx": 17}, {"type": "text", "text": "$\\begin{array}{r}{\\nabla l(\\cdot;\\mathcal{B}_{i,j,s})=\\frac{1}{|\\mathcal{B}_{i,j,s}|}\\sum_{l\\in\\mathcal{B}_{i,j,s}}\\nabla l(\\cdot)}\\end{array}$ | l\u2208Bi,j,s \u2207l(\u00b7), and Bi,j,s is the subset of loss functions at vertex s in the binary tree $j$ for client $i$ . The full algorithm is shown in Algorithm 3. ", "page_idx": 17}, {"type": "image", "img_path": "T826pwZLci/tmp/7afb2fc0ecd7b315c7f96cd57aac4341ec9ca79cadf0be861014e3b71c689c66.jpg", "img_caption": ["Figure 3: Binary tree with depth $j=2$ in Algorithm 3. "], "img_footnote": [], "page_idx": 17}, {"type": "text", "text": "C.2 Proof of Theorem 1 and Corollary 1 (for pure DP) ", "text_level": 1, "page_idx": 17}, {"type": "text", "text": "Theorem 5 (Restatement of Theorem 1). Assume that loss function $l_{i,t}(\\cdot)$ is convex, $\\alpha$ -Lipschitz, $\\beta$ - smooth w.r.t. \u2225\u00b7\u22251. Setting \u03bbi,j,s = $\\begin{array}{r}{\\lambda_{i,j,s}=\\frac{4\\alpha2^{j}}{b\\varepsilon}}\\end{array}$ 4\u03b12j, b = (p2\u22121)2 and T1 = 12 log $\\begin{array}{r}{T_{1}=\\frac{1}{2}\\log\\left(\\frac{b\\varepsilon\\beta\\sqrt{m}}{\\alpha\\log d}\\right)}\\end{array}$ , Fed-DP-OPE-Stoch $(i)$ satisfies $\\varepsilon$ -DP and (ii) achieves the per-client regret of ", "page_idx": 17}, {"type": "equation", "text": "$$\nO\\left(\\left(\\alpha+\\beta\\right)\\log T\\sqrt{\\frac{T\\log d}{m}}+\\frac{\\sqrt{\\alpha\\beta}\\log d\\sqrt{T}\\log T}{m^{\\frac{1}{4}}\\sqrt{\\varepsilon}}\\right)\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "with (iii) a communication cost of $\\textstyle O\\left(m^{{\\frac{5}{4}}}d{\\sqrt{\\frac{T\\varepsilon\\beta}{\\alpha\\log d}}}\\right)$ ", "page_idx": 17}, {"type": "text", "text": "We define population loss as $\\begin{array}{r}{L_{t}(x)=\\mathbb{E}[\\frac{1}{m}\\sum_{i=1}^{m}l_{i,t}(x_{i,t})]}\\end{array}$ . The per-client regret can be expressed as $\\begin{array}{r}{\\mathbb{E}\\left[\\sum_{t=1}^{T}L_{t}(x_{i,t})-\\underset{x^{\\star}\\in\\mathcal{X}}{\\operatorname*{min}}\\sum_{t=1}^{T}L_{t}(x^{\\star})\\right]}\\end{array}$ . We use $v_{i,p,k},w_{i,p,k},x_{i,p,k}$ and $\\eta_{i,p,k}$ to denote quantities corresponding to phase $p$ , iteration $k$ , and client $i$ . Also we introduce some average quantities $\\begin{array}{r}{{\\bar{v}}_{p,k}=\\frac{1}{m}\\sum_{i=1}^{\\tilde{m}}{v_{i,p,k}}}\\end{array}$ and $\\begin{array}{r}{\\bar{w}_{p,k}=\\frac{1}{m}\\sum_{i=1}^{m}w_{i,p,k}}\\end{array}$ . ", "page_idx": 17}, {"type": "text", "text": "To prove the theorem, we start with Lemma 1 that gives pure privacy guarantees. ", "page_idx": 17}, {"type": "text", "text": "Lemma 1. Assume that $2^{T_{1}}\\leq b.$ . Setting $\\begin{array}{r}{\\lambda_{i,j,s}=\\frac{4\\alpha2^{j}}{b\\varepsilon}}\\end{array}$ , Fed-DP-OPE-Stoch is $\\varepsilon$ -DP. ", "page_idx": 17}, {"type": "text", "text": "Proof. Let $\\boldsymbol{S}$ and $S^{\\prime}$ be two neighboring datasets and assume that they differ in sample $l_{i_{1},t_{1}}$ or $l_{i_{1},t_{1}}^{\\prime}$ , where $2^{p_{1}-1}\\,\\leq\\,t_{1}\\,<\\,2^{p_{1}}$ . Let $B_{i_{1},j,s}$ be the set that contains $l_{i_{1},t_{1}}$ or $l_{i_{1},t_{1}}^{\\prime}$ . Recall that $|B_{i_{1},j,s}|=2^{-|s|}b.$ . The key point is that this set is used in the calculation of $v_{i_{1},p_{1},k}$ for at most $2^{j-|s|}$ iterates, i.e. the leaves that are descendants of the vertex. Let $k_{0}$ and $k_{1}$ be the first and last iterate such that $B_{i_{1},j,s}$ is used for the calculation of $v_{i_{1},p_{1},k}$ , hence $k_{1}-k_{0}+1\\leq2^{j-|s|}$ . ", "page_idx": 17}, {"type": "text", "text": "", "page_idx": 18}, {"type": "text", "text": "First, we show that $(\\langle c_{n},v_{1,1,1}\\rangle,\\ldots,\\langle c_{n},v_{m,P,K}\\rangle)\\approx_{(\\varepsilon,0)}$ $(\\langle c_{n},v_{1,1,1}^{\\prime}\\rangle,\\ldots,\\langle c_{n},v_{m,P,K}^{\\prime}\\rangle)$ holds for $1\\leq n\\leq d$ . For our purpose, it suffices to establish that $\\big(\\langle c_{n},v_{i_{1},p_{1},k_{0}}\\rangle,\\ldots,\\langle c_{n},v_{i_{1},p_{1},k_{1}}\\rangle\\big)\\approx_{(\\varepsilon,0)}$ $\\big(\\langle c_{n},v_{i_{1},p_{1},k_{0}}^{\\prime}\\rangle,\\ldots,\\langle c_{n},v_{i_{1},p_{1},k_{1}}^{\\prime}\\rangle\\big)$ holds for $1\\leq n\\leq d,$ , since $l_{i_{1},t_{1}}$ or $l_{i_{1},t_{1}}^{\\prime}$ is only used in client i1, at phase p1 and iteration k0, . . . , k1. Therefore it is enough to show that \u27e8cn, vi1,p1,k\u27e9\u2248( j\u2212\u03b5|s| ,0) $\\langle c_{n},v_{i_{1},p_{1},k}^{\\prime}\\rangle$ holds for $k_{0}~\\le~k~\\le~k_{1}$ and $1\\,\\leq\\,n\\,\\leq\\,d$ , because $k_{1}\\,-\\,k_{0}\\,+\\,1\\,\\leq\\,2^{j-|s|}$ . Note that $\\begin{array}{r}{|\\langle c_{n},v_{i_{1},p_{1},k}\\,-\\,v_{i_{1},p_{1},k}^{\\prime}\\rangle|\\ \\leq\\ \\frac{4\\alpha}{2^{-|s|}b}}\\end{array}$ 2\u22124|\u03b1s|b. Setting \u03bbi,j,s = $\\begin{array}{r}{\\lambda_{i,j,s}\\:=\\:\\frac{4\\alpha2^{j}}{b\\varepsilon}}\\end{array}$ and applying standard results of Laplace mechanism (Dwork et al. (2014)) lead to our intended results. Finally, we can show that $\\left(x_{1,1,K},\\ldots,x_{m,P,K}\\right)\\approx_{\\left(\\varepsilon,0\\right)}\\left(x_{1,1,K}^{\\prime},\\ldots,x_{m,P,K}^{\\prime}\\right)$ by post-processing. \u53e3 ", "page_idx": 18}, {"type": "text", "text": "To help prove the upper bound of the regret, we introduce some lemmas first. ", "page_idx": 18}, {"type": "text", "text": "Lemma 2. Let t be the time-step, $p$ be the index of phases, i be the index of the clients, and $(j,s)$ be a vertex. For every index $1\\leq k\\leq d$ of the vectors, we have ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\mathbb{E}\\left[\\exp\\left\\{c(\\bar{v}_{p,j,s,k}-\\nabla L_{t,k}(x_{i,p,j,s}))\\right\\}\\right]\\leq\\exp\\left(\\frac{O(1)c^{2}(\\alpha^{2}+\\beta^{2})}{b m}\\right),\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "where $\\begin{array}{r}{\\bar{v}_{p,j,s}=\\frac{1}{m}\\sum_{i=1}^{m}v_{i,p,j,s}.}\\end{array}$ ", "page_idx": 18}, {"type": "text", "text": "Proof. Let us fix $p,t,k$ and $i$ for simplicity and let $A_{j,s}=\\bar{v}_{p,j,s,k}-\\nabla L_{t,k}(x_{i,p,j,s})$ . We prove the lemma by induction on the depth of the vertex, i.e., $|s|$ . If $|s|=0$ , then $v_{i,p,j,\\emptyset}=\\overrightarrow{\\nabla l}(x_{i,p,j,\\emptyset};B_{i,p,j,\\emptyset})$ where $B_{i,p,j,\\emptyset}$ is a sample set of size $b$ . Therefore we have ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{E}[\\exp c A_{j,s}]=\\mathbb{E}[\\exp c(\\bar{v}_{p,j,\\emptyset,k}-\\nabla L_{t,k}(x_{i,p,j,\\emptyset})]}\\\\ &{\\qquad\\qquad\\qquad=\\mathbb{E}\\left[\\exp c\\left(\\displaystyle\\frac{1}{m b}\\displaystyle\\sum_{i=1}^{m}\\sum_{\\substack{s\\in B_{i,p,j,\\emptyset}}}\\nabla l_{k}(x_{i,p,j,\\emptyset};s)-\\nabla L_{t,k}(x_{i,p,j,\\emptyset})\\right)\\right]}\\\\ &{\\qquad\\qquad=\\displaystyle\\prod_{s\\in B_{i,p,j,\\emptyset}}\\prod_{i\\in[m]}\\mathbb{E}\\left[\\exp\\displaystyle\\frac{c}{b m}(\\nabla l_{k}(x_{i,p,j,\\emptyset};s)-\\nabla L_{t,k}(x_{i,p,j,\\emptyset}))\\right]}\\\\ &{\\qquad\\qquad\\qquad\\leq\\exp\\left(\\displaystyle\\frac{c^{2}\\alpha^{2}}{2b m}\\right),}\\end{array}\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "where the last inequality holds because for a random variable $\\begin{array}{r l r}{X}&{{}\\in}&{[-\\alpha,\\alpha]}\\end{array}$ , we have $\\begin{array}{r}{\\mathbb{E}[\\exp c(X-\\mathbb{E}[X])]\\leq\\exp\\Big(\\frac{c^{2}\\alpha^{2}}{2}\\Big).}\\end{array}$ . ", "page_idx": 18}, {"type": "text", "text": "Assume the depth of the vertex $|s|\\geq0$ and let $s=s^{\\prime}a$ where $a\\in\\{0,1\\}$ . If $a=0$ , clearly the lemma holds. If $a=1$ , recall that $\\begin{array}{r}{v_{i,p,j,s}=v_{i,p,j,s^{\\prime}}+\\nabla l(x_{i,p,j,s};\\mathcal{B}_{i,p,j,s})-\\nabla l(x_{i,p,j,s^{\\prime}};\\mathcal{B}_{i,p,j,s})}\\end{array}$ , then ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\begin{array}{l}{{A_{j,s}=\\bar{v}_{p,j,s,k}-\\nabla L_{t,k}(x_{i,p,j,s})}}\\\\ {{\\displaystyle\\quad=A_{j,s^{\\prime}}+\\frac{1}{m}\\sum_{i=1}^{m}\\nabla l_{k}(x_{i,p,j,s};B_{i,p,j,s})-\\frac{1}{m}\\sum_{i=1}^{m}\\nabla l_{k}(x_{i,p,j,s^{\\prime}};B_{i,p,j,s})}}\\\\ {{\\displaystyle\\quad\\quad-\\nabla L_{t,k}(x_{i,p,j,s})+\\nabla L_{t,k}(x_{i,p,j,s^{\\prime}})}}\\end{array}\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "Let $\\begin{array}{r}{\\mathcal{B}_{i,p,<(j,s)}=\\cup_{(j_{1},_{\\underline{{s}}_{1}})<(j,s)}\\mathcal{B}_{i,p,j_{1},s_{1}}}\\end{array}$ be the set containing all the samples used up to vertex $(j,s)$ in phase $p$ at client $i$ . We have ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\lefteqn{\\mathbb{E}\\left[\\exp c A_{j,s}\\right]}}\\\\ &{=\\mathbb{E}\\Bigg[\\exp\\left(c(A_{j,s^{\\prime}}+\\frac{1}{m}\\sum_{i=1}^{m}\\nabla l_{k}(x_{i,p,j,s};B_{i,p,j,s})-\\frac{1}{m}\\sum_{i=1}^{m}\\nabla l_{k}(x_{i,p,j,s^{\\prime}};B_{i,p,j,s})\\right)}\\\\ &{\\qquad\\times\\exp\\Bigg(-\\nabla L_{t,k}(x_{i,p,j,s})+\\nabla L_{t,k}(x_{i,p,j,s^{\\prime}})\\Bigg)\\Bigg]}\\\\ &{=\\mathbb{E}\\Bigg[\\mathbb{E}\\Bigg[\\exp\\left(c(A_{j,s^{\\prime}}+\\frac{1}{m}\\sum_{i=1}^{m}\\nabla l_{k}(x_{i,p,j,s};B_{i,p,j,s})-\\frac{1}{m}\\sum_{i=1}^{m}\\nabla l_{k}(x_{i,p,j,s^{\\prime}};B_{i,p,j,s})\\right)}\\end{array}\n$$", "text_format": "latex", "page_idx": 18}, {"type": "equation", "text": "$$\n\\begin{array}{l}{\\displaystyle-\\left.\\nabla L_{t,k}(x_{i,p,j,s})+\\nabla L_{t,k}(x_{i,p,j,s^{\\prime}})\\right)\\left|\\mathcal{B}_{i,p,<(j,s)}\\right|\\right]}\\\\ {\\displaystyle=\\mathbb{E}\\Bigg[\\mathbb{E}\\left[\\exp\\left(c A_{j,s^{\\prime}}\\right)\\big|\\mathcal{B}_{i,p,<(j,s)}\\right]}\\\\ {\\displaystyle~~~~\\times\\mathbb{E}[\\exp\\left(c(\\frac{1}{m}\\sum_{i=1}^{m}\\nabla l_{k}(x_{i,p,j,s};B_{i,p,j,s})-\\frac{1}{m}\\sum_{i=1}^{m}\\nabla l_{k}(x_{i,p,j,s^{\\prime}};B_{i,p,j,s})\\right.}\\\\ {\\displaystyle~~~\\left.-\\nabla L_{t,k}(x_{i,p,j,s})+\\nabla L_{t,k}(x_{i,p,j,s^{\\prime}})\\right)\\bigg|\\mathcal{B}_{i,p,<(j,s)}\\Bigg]\\Bigg].}\\end{array}\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "Since $l_{i,t}(\\cdot;s)$ is $\\beta$ -smooth w.r.t. $\\|\\cdot\\|_{1}$ , we have ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\begin{array}{r}{|\\nabla l_{k}(x_{i,p,j,s};\\mathcal{B}_{i,p,j,s})-\\nabla l_{k}(x_{i,p,j,s^{\\prime}};\\mathcal{B}_{i,p,j,s})|\\leq\\beta\\|x_{i,p,j,s}-x_{i,p,j,s^{\\prime}}\\|_{1}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "Since vertex $(j,s)$ is the right son of vertex $(j,s^{\\prime})$ , the number of updates between $x_{i,p,j,s}$ and $x_{i,p,j,s^{\\prime}}$ is at most the number of leafs visited between these two vertices i.e. $2^{j-|s|}$ . Therefore we have ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\|x_{i,p,j,s}-x_{i,p,j,s^{\\prime}}\\|_{1}\\leq\\eta_{i,p,j,s^{\\prime}}2^{j-|s|}\\leq2^{2-|s|}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "By using similar arguments to the case $|s|=0$ , we can get ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{E}\\bigg[\\exp\\bigg(c(\\displaystyle\\frac{1}{m}\\displaystyle\\sum_{i=1}^{m}\\nabla l_{k}(x_{i,p,j,s};B_{i,p,j,s})-\\displaystyle\\frac{1}{m}\\displaystyle\\sum_{i=1}^{m}\\nabla l_{k}(x_{i,p,j,s^{\\prime}};B_{i,p,j,s})\\bigg)}\\\\ &{\\mathrm{~\\~\\}\\times\\exp\\bigg(-\\nabla L_{t,k}(x_{i,p,j,s})+\\nabla L_{t,k}(x_{i,p,j,s^{\\prime}})\\bigg)\\bigg|B_{i,p,<(j,s)}\\bigg]}\\\\ &{\\leq\\exp\\bigg(\\displaystyle\\frac{O(1)c^{2}\\beta^{2}2^{-2|s|}}{m|B_{i,p,j,s}|}\\bigg)}\\\\ &{\\leq\\exp\\bigg(\\displaystyle\\frac{O(1)c^{2}\\beta^{2}2^{-|s|}}{b m}\\bigg)\\,.}\\end{array}\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "Then we get ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\mathbb{E}[\\exp c A_{j,s}]\\leq\\mathbb{E}[\\exp c A_{j,s^{\\prime}}]\\exp\\left(\\frac{O(1)c^{2}\\beta^{2}2^{-|s|}}{b m}\\right).\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "Applying this inductively, we have for every index $1\\leq k\\leq d$ ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\mathbb{E}[\\exp c A_{j,s}]\\leq\\exp\\left({\\frac{O(1)c^{2}(\\alpha^{2}+\\beta^{2})}{b m}}\\right).\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "Lemma 3 upper bounds the variance of the average gradient. ", "page_idx": 19}, {"type": "text", "text": "Lemma 3. At phase $p,$ for each vertex $(j,s)$ and $2^{p-1}\\leq t<2^{p}-1$ , we have ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\mathbb{E}\\left[\\|\\bar{v}_{p,j,s}-\\nabla L_{t}(x_{i,p,j,s})\\|_{\\infty}\\right]\\leq(\\alpha+\\beta)O\\left(\\sqrt{\\frac{\\log d}{b m}}\\right),\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "where $\\begin{array}{r}{\\bar{v}_{p,j,s}=\\frac{1}{m}\\sum_{i=1}^{m}v_{i,p,j,s}.}\\end{array}$ . ", "page_idx": 19}, {"type": "text", "text": "ma 2 implies that $\\bar{v}_{p,j,s,k}-\\nabla L_{t,k}(x_{i,p,j,s})$ is $\\scriptstyle O\\left({\\frac{\\alpha^{2}+\\beta^{2}}{b m}}\\right)$ -sub- aussian for every index $1\\leq k\\leq d$ of the vectors. Applying standard results of the maximum of $d$ variables, we get ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\mathbb{E}[\\|\\bar{v}_{p,j,s}-\\nabla L_{t}(x_{i,p,j,s})\\|_{\\infty}]\\le O\\left(\\sqrt{\\frac{\\alpha^{2}+\\beta^{2}}{b m}}\\right)\\sqrt{\\log d}.\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "Lemma 4 gives the tail bound of the sum of i.i.d. random variables following Laplace distribution. Lemma 4. Let $\\xi_{i,n}$ be IID random variables following the distribution $L a p(\\lambda_{i,j,s})$ . Then we have ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\mathbb{E}\\left[\\operatorname*{max}_{n:1\\leq n\\leq d}\\Big|\\sum_{i=1}^{m}\\xi_{i,n}\\Big|\\right]\\leq O(\\sqrt{m}\\lambda_{i,j,s}\\ln d).\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "Proof. $\\xi_{i,n}$ \u2019s are md IID random variables following the distribution $\\mathrm{Lap}(\\lambda_{i,j,s})$ . We note that ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\mathbb{E}\\left[\\exp(u\\xi_{i,n})\\right]=\\frac{1}{1-\\lambda_{i,j,s}{^2}u^{2}},|u|\\leq\\frac{1}{\\lambda_{i,j,s}}.\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "Since $\\begin{array}{r}{\\frac{1}{1-{\\lambda_{i,j,s}}^{2}u^{2}}\\leq1+2{\\lambda_{i,j,s}}^{2}u^{2}\\leq\\exp(2{\\lambda_{i,j,s}}^{2}u^{2})}\\end{array}$ , when $\\begin{array}{r}{|u|\\leq\\frac{1}{2\\lambda_{i,j,s}}}\\end{array}$ , $\\xi_{i,n}$ is sub-exponential with parameter $(4{\\lambda_{i,j,s}}^{2},2{\\lambda_{i,j,s}})$ . Applying standard results of linear combination of sub-exponential random variables, we can conclude that $\\textstyle\\sum_{i=1}^{\\bar{m}}\\xi_{i,n}$ , denoted as $Y_{n}$ , is sub-exponential with parameter $(4m\\lambda_{i,j,s}{}^{2},2\\lambda_{i,j,s})$ . From standard results of tail bounds of sub-exponential random variables, we have ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\begin{array}{c}{\\displaystyle\\mathbb{P}\\left(|Y_{n}|\\geq c\\right)\\leq2\\exp\\left(-\\frac{c^{2}}{8m\\lambda_{i,j,s}}\\right),\\;\\mathrm{if}\\;0\\leq c\\leq2m\\lambda_{i,j,s},}\\\\ {\\displaystyle\\mathbb{P}(|Y_{n}|\\geq c)\\leq2\\exp\\left(-\\frac{c}{4\\lambda_{i,j,s}}\\right),\\;\\mathrm{if}\\;c\\geq2m\\lambda_{i,j,s}.}\\\\ {\\displaystyle*\\mathbb{P}\\left(\\operatorname*{max}_{n:\\,\\Sigma\\leq n\\leq d}|Y_{n}|\\geq c\\right)\\leq\\sum_{n:1\\leq n\\leq d}\\mathbb{P}\\left(|Y_{n}|\\geq c\\right),\\;\\mathrm{we}}\\\\ {\\displaystyle\\mathbb{P}_{\\mathrm{}_{n:1\\leq n\\leq d}}\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "Then we have ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{E\\left[\\operatorname*{max}_{i\\neq0,j}D_{w}\\right]=\\int_{\\mathbb{R}}\\Bigg[\\operatorname*{min}_{0\\neq j}D_{w}[\\sum_{k=0}^{\\infty}\\gamma_{k}]\\geq\\rho\\Bigg]d\\alpha}\\\\ &{=\\sqrt{\\operatorname*{min}_{0\\leq i<j}\\sum_{k=0}^{\\infty}\\gamma_{k}+\\int_{(\\alpha+1)/\\beta_{1}}^{\\infty}\\gamma_{k}\\Bigg(\\frac{1}{\\alpha+2}\\log\\left(\\frac{1}{\\alpha}\\log\\left(\\frac{1}{\\beta_{1}}\\log\\right)\\right)d\\alpha~\\Bigg.}}\\\\ &{\\qquad\\qquad+\\int_{\\mathbb{R}\\times\\infty_{n}}\\gamma_{k}\\Bigg(\\frac{1}{\\alpha+1}\\log\\left(\\frac{1}{\\beta_{1}}\\log\\left(\\frac{1}{\\beta_{2}}\\right)\\right)d\\alpha~\\Bigg.}\\\\ &{\\leq\\sqrt{\\operatorname*{min}_{0\\leq i<j}\\sum_{k=0}^{\\infty}\\gamma_{k}}\\geq\\rho\\Bigg)\\Bigg(d\\alpha-\\frac{\\sigma^{2}}{\\operatorname*{max}_{0\\leq i<j}\\sum_{k=0}^{\\infty}\\gamma_{k}}\\Bigg)\\,d\\alpha}\\\\ &{\\quad+\\int_{\\mathbb{R}\\times\\infty_{n}}2\\exp\\left(\\alpha\\ln\\left(d-\\frac{\\sigma^{2}}{\\sigma(k-\\beta_{1})}\\right)d\\alpha\\right)}\\\\ &{\\leq\\sqrt{\\operatorname*{min}_{0\\leq i<j}\\sum_{k=0}^{\\infty}\\gamma_{k}}\\geq\\exp\\left(-\\pi\\eta\\right)d\\alpha}\\\\ &{\\quad+8\\lambda_{4}\\int_{\\mathbb{R}\\times\\infty_{n}}\\alpha(1-\\gamma_{0})(\\alpha-\\gamma_{0})}\\\\ &{\\leq\\sqrt{\\operatorname*{min}_{0\\leq i<j}\\sum_{k=0}^{\\infty}\\gamma_{k}}\\geq\\exp\\left(-\\pi\\right)d\\alpha}\\\\ &{\\quad+8\\lambda_{4}\\ln\\alpha+8\\lambda_{6}\\int_{\\mathbb{R}\\times\\pi}\\exp\\left(\\alpha^{-\\frac{\\sigma^{2}}{2}}\\right)d\\alpha}\\\\ &{\\quad-\\sqrt{\\operatorname*{min}_{0\\leq i<j}D_{w}[\\alpha,\\beta_{1},\\alpha_{2},\\beta_{1}]}+\\sqrt{\\operatorname*{min}_{0\\leq i<j}D_{w}[\\alpha,\\beta_{2},\\alpha_{1},\\beta_{1}]}+\\Delta_{\\lambda_{1},\\alpha_{1}}\\int_{\\mathbb{R}\\times\\pi\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "Lemma 5. Setting \u03bbi,j,s = $\\begin{array}{r}{\\lambda_{i,j,s}=\\frac{4\\alpha2^{j}}{b\\varepsilon}}\\end{array}$ \u03b52 , we have ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\mathbb{E}[\\langle\\bar{v}_{p,k},\\bar{w}_{p,k}\\rangle]\\leq\\mathbb{E}\\left[\\operatorname*{min}_{w\\in\\mathcal{X}}\\langle\\bar{v}_{p,k},w\\rangle\\right]+O\\left(\\frac{\\alpha2^{j}\\ln d}{b\\varepsilon\\sqrt{m}}\\right).\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "Proof. Since $\\begin{array}{r}{\\bar{w}_{p,k}\\,=\\,\\arg\\operatorname*{min}_{c_{n}:1\\leq n\\leq d}\\left[\\frac{1}{m}\\sum_{i=1}^{m}\\left(\\langle c_{n},v_{i,p,k}\\rangle+\\xi_{i,n}\\right)\\right]\\,}\\end{array}$ , where $\\displaystyle\\xi_{i,n}\\sim\\mathrm{Lap}(\\lambda_{i,j,s})$ , we denote $\\bar{w}_{p,k}$ as $c_{n^{\\star}}$ and we have ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\lefteqn{\\langle\\overline{{\\boldsymbol v}}_{p,k},\\overline{{\\boldsymbol v}}_{p,k}\\rangle=\\langle c_{n^{\\star}},\\overline{{\\boldsymbol v}}_{p,k}\\rangle}}\\\\ &{=\\operatorname*{min}_{n:1\\leq n\\leq d}\\bigg(\\langle c_{n},\\overline{{\\boldsymbol v}}_{p,k}\\rangle+\\displaystyle\\frac{1}{m}\\sum_{i=1}^{m}\\xi_{i,n}\\bigg)-\\frac{1}{m}\\sum_{i=1}^{m}\\xi_{i,n}.}\\\\ &{\\leq\\displaystyle\\operatorname*{min}_{n:1\\leq n\\leq d}\\langle c_{n},\\overline{{\\boldsymbol v}}_{p,k}\\rangle+\\displaystyle\\frac{1}{m\\,n:1\\leq n\\leq d}\\displaystyle\\sum_{i=1}^{m}\\xi_{i,n}-\\displaystyle\\frac{1}{m\\,n:1\\leq n\\leq d}\\displaystyle\\sum_{i=1}^{m}\\xi_{i,n}}\\\\ &{\\leq\\displaystyle\\operatorname*{min}_{n:1\\leq n\\leq d}\\langle c_{n},\\overline{{\\boldsymbol v}}_{p,k}\\rangle+\\displaystyle\\frac{2}{m\\,n:1\\leq n\\leq d}\\displaystyle\\sum_{i=1}^{m}\\xi_{i,n}\\bigg|.}\\end{array}\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "Applying Lemma 4, we get ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\mathbb{E}[\\langle\\bar{v}_{p,k},\\bar{w}_{p,k}\\rangle]\\leq\\mathbb{E}\\left[\\operatorname*{min}_{w\\in\\mathcal{X}}\\langle\\bar{v}_{p,k},w\\rangle\\right]+O\\left(\\frac{\\lambda_{i,j,s}\\ln d}{\\sqrt{m}}\\right).\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "With the lemmas above, we are ready to prove Theorem 1. ", "page_idx": 21}, {"type": "text", "text": "Proof. Lemma 1 implies the claim about privacy. We proceed to prove the regret upper bound. ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\lefteqn{\\frac{\\langle n\\rangle}{\\iota_{t}(x_{i,p,k+1})}\\stackrel{(a)}{\\leq}L_{t}(x_{i,p,k})+\\langle\\nabla L_{t}(x_{i,p,k}),x_{i,p,k+1}-x_{i,p,k}\\rangle+\\beta\\frac{\\|x_{i,p,k+1}-x_{i,p,k}\\|_{1}^{2}}{2}\\qquad}&{}\\\\ &{\\stackrel{(b)}{\\leq}L_{t}(x_{i,p,k})+\\eta_{i,p,k}\\langle\\nabla L_{t}(x_{i,p,k}),\\bar{w}_{p,k}-x_{i,p,k}\\rangle+\\frac{1}{2}\\beta\\eta_{i,p,k}\\rangle^{2}}\\\\ &{=L_{t}(x_{i,p,k})+\\eta_{i,p,k}\\langle\\nabla L_{t}(x_{i,p,k}),x^{\\star}-x_{i,p,k}\\rangle+\\eta_{i,p,k}\\langle\\nabla L_{t}(x_{i,p,k})-\\bar{v}_{p,k},\\bar{w}_{p,k}-x^{\\star}\\rangle}\\\\ &{\\quad+\\ \\eta_{i,p,k}\\langle\\bar{v}_{p,k},\\bar{w}_{p,k}-x^{\\star}\\rangle+\\frac{1}{2}\\beta\\eta_{i,p,k}{^2}}\\\\ &{\\stackrel{(c)}{\\leq}L_{t}(x_{i,p,k})+\\eta_{i,p,k}[L_{t}(x^{\\star})-L_{t}(x_{i,p,k})]+\\eta_{i,p,k}\\|\\nabla L_{t}(x_{i,p,k})-\\bar{v}_{p,k}\\|_{\\infty}+\\eta_{i,p,k}(\\langle\\bar{v}_{p,q,p,k}\\rangle-\\eta_{i,p,k})\\|_{1}\\,,}\\\\ &{\\quad-\\underbrace{\\operatorname*{min}}_{\\psi\\in\\mathcal{X}}\\langle\\bar{v}_{p,k},w\\rangle+\\frac{1}{2}\\beta\\eta_{i,p,k}{^2},}\\end{array}\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "where $(a)$ is due to $\\beta$ -smoothness, $(b)$ is because of the updating rule of $x_{i,p,k}$ , and $(c)$ follows from the convexity of the loss function and H\u00f6lder\u2019s inequality. ", "page_idx": 21}, {"type": "text", "text": "Subtracting $L_{t}(x^{\\star})$ from each side and taking expectations, we have ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\xi[L_{t}(x_{i,p,k+1})-L_{t}(x^{\\star})]\\leq(1-\\eta_{i,p,k})\\mathbb{E}[L_{t}(x_{i,p,k})-L_{t}(x^{\\star})]+\\eta_{i,p,k}\\mathbb{E}[\\|\\nabla L_{t}(x_{i,p,k})-\\bar{v}_{p,k}\\|_{\\infty}]}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\qquad+\\eta_{i,p,k}\\mathbb{E}[\\langle\\bar{v}_{p,k},\\bar{w}_{p,k}\\rangle-\\underset{w\\in\\mathcal{X}}{\\operatorname*{min}}\\langle\\bar{v}_{p,k},w\\rangle]+\\frac{1}{2}\\beta\\eta_{i,p,k}^{\\phantom{}}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "Applying Lemma 5 and Lemma 3, we have ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{E}[L_{t}(x_{i,p,k+1})-L_{t}(x^{\\star})]\\leq(1-\\eta_{i,p,k})\\mathbb{E}[L_{t}(x_{i,p,k})-L_{t}(x^{\\star})]+\\eta_{i,p,k}(\\alpha+\\beta)O\\left(\\sqrt{\\frac{\\log d}{b m}}\\right)}\\\\ &{\\qquad\\qquad\\qquad\\qquad+\\,\\frac{\\eta_{i,p,k}\\alpha2^{j}}{b\\varepsilon}O\\left(\\frac{\\ln d}{\\sqrt{m}}\\right)+\\frac{1}{2}\\beta\\eta_{i,p,k}{}^{2}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "Let $\\begin{array}{r}{\\alpha_{k}=\\eta_{i,p,k}(\\alpha+\\beta)O\\left(\\sqrt{\\frac{\\log d}{b m}}\\right)+\\frac{\\eta_{i,p,k}\\alpha2^{j}}{b\\varepsilon}O\\left(\\frac{\\ln d}{\\sqrt{m}}\\right)+\\frac{1}{2}\\beta\\eta_{i,p,k}{^2}}\\end{array}$ . We simplify the notion of $\\eta_{i,p,k}$ to $\\eta_{k}$ . Then we have ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\begin{array}{l}{\\displaystyle\\mathbb{E}[L_{t}(x_{i,p,k})-L_{t}(x^{\\star})]\\leq\\sum_{k^{\\prime}=1}^{K}\\alpha_{k}\\prod_{i>k}^{K-1}(1-\\eta_{k^{\\prime}})}\\\\ {\\displaystyle=\\sum_{k=1}^{K}\\alpha_{k}\\frac{(k+1)k}{K(K-1)}}\\\\ {\\displaystyle\\leq\\sum_{k=1}^{K}\\alpha_{k}\\frac{(k+1)^{2}}{(K-1)^{2}},}\\end{array}\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "where \u03b7k = $\\begin{array}{r}{\\eta_{k}=\\frac{2}{k+1}}\\end{array}$ ", "page_idx": 22}, {"type": "text", "text": "Since $K=2^{T_{1}}$ , simply algebra implies that ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\mathbb{E}[L_{t}(x_{i,p,K})-L_{t}(x^{\\star})]\\leq O\\left((\\alpha+\\beta)\\sqrt{\\frac{\\log d}{b m}}+\\frac{\\alpha2^{T_{1}}\\ln d}{b\\varepsilon\\sqrt{m}}+\\frac{\\beta}{2^{T_{1}}}\\right).\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "At iteration $2^{p-1}\\leq t<2^{p}$ , setting $\\begin{array}{r}{b=\\frac{2^{p-1}}{(p-1)^{2}}}\\end{array}$ (p2\u22121)2 and T1 = 21 log $\\begin{array}{r}{T_{1}=\\frac{1}{2}\\log\\left(\\frac{b\\varepsilon\\beta\\sqrt{m}}{\\alpha\\log d}\\right)}\\end{array}$ in Equation (4), we have ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\mathbb{E}[L_{t}(x_{i,p,K})-L_{t}(x^{\\star})]\\leq O\\left((\\alpha+\\beta)p\\sqrt{\\frac{\\log d}{2^{p}m}}+\\frac{p\\sqrt{\\alpha\\beta}\\log d}{m^{\\frac{1}{4}}\\sqrt{2^{p}\\varepsilon}}\\right).\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "Therefore, the total regret from time step $2^{p}$ to $2^{p+1}-1$ is at most ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\mathbb{E}\\left[\\sum_{t=2^{p}}^{2^{p+1}-1}L_{t}(x_{i,t})-\\operatorname*{min}_{u\\in\\mathcal{X}}\\sum_{t=2^{p}}^{2^{p+1}-1}L_{t}(u)\\right]\\leq O\\left((\\alpha+\\beta)p\\sqrt{\\frac{2^{p}\\log d}{m}}+\\frac{p\\sqrt{\\alpha\\beta}\\log d\\sqrt{2^{p}}}{m^{\\frac{1}{4}}\\sqrt{\\varepsilon}}\\right).\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "Summing over $p$ , we can get ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{E}\\left[\\displaystyle\\sum_{t=1}^{T}L_{t}(x_{i,t})-\\operatorname*{min}_{u\\in\\mathcal{X}}\\displaystyle\\sum_{t=1}^{T}L_{t}(u)\\right]\\leq\\displaystyle\\sum_{p=1}^{\\log T}O\\left((\\alpha+\\beta)p\\sqrt{\\frac{2^{p}\\log d}{m}}+\\frac{p\\sqrt{\\alpha\\beta}\\log d\\sqrt{2^{p}}}{m^{\\frac{1}{4}}\\sqrt{\\varepsilon}}\\right)}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\leq O\\left((\\alpha+\\beta)\\displaystyle\\sum_{p=1}^{\\log T}p\\sqrt{\\frac{2^{p}\\log d}{m}}+\\frac{\\sqrt{\\alpha\\beta}\\log d}{m^{\\frac{1}{4}}\\sqrt{\\varepsilon}}\\displaystyle\\sum_{p=1}^{\\log T}p\\sqrt{2^{p}}\\right)}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\qquad\\leq O\\left((\\alpha+\\beta)\\log T\\sqrt{\\frac{T\\log d}{m}}+\\frac{\\sqrt{\\alpha\\beta}\\log d\\sqrt{T}\\log T}{m^{\\frac{1}{4}}\\sqrt{\\varepsilon}}\\right).}\\end{array}\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "Now we turn our focus to communication cost. Since there are $\\log T$ phases, and within each phase, there are $O(2^{T_{1}})$ leaf vertices where communication is initiated, the communication frequency scales in $O(\\sum_{p}2^{T_{1}})$ . Therefore, the communication cost scales in $O(m^{5/4}d\\sqrt{T\\varepsilon\\beta/(\\alpha\\log d)})$ . \u53e3 ", "page_idx": 22}, {"type": "text", "text": "Corollary 2 (Restatement of Corollary 1). If $\\begin{array}{r}{\\beta=O(\\frac{\\log d}{\\sqrt{m}T\\varepsilon})}\\end{array}$ , then, Fed-DP-OPE-Stoch $(i)$ satisfies $\\varepsilon$ -DP and (ii) achieves the per-client regret of ", "page_idx": 22}, {"type": "equation", "text": "$$\nR e g(T,m)=O\\bigg(\\sqrt{\\frac{T\\log d}{m}}+\\frac{\\log T\\log d}{\\sqrt{m}\\varepsilon}\\bigg),\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "with (iii) a communication cost of $O\\left(m d\\log T\\right)$ . ", "page_idx": 22}, {"type": "text", "text": "Proof. Similar to the proof of Theorem 1, we can show that ", "page_idx": 23}, {"type": "equation", "text": "$$\n\\mathbb{E}[L_{t}(x_{i,p,K})-L_{t}(x^{\\star})]\\leq O\\left((\\alpha+\\beta)\\sqrt{\\frac{\\log d}{b m}}+\\frac{\\alpha2^{T_{1}}\\ln d}{b\\varepsilon\\sqrt{m}}+\\frac{\\beta}{2^{T_{1}}}\\right).\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "At iteration $2^{p-1}\\leq t<2^{p}$ , setting $b=2^{p-1}$ and $T_{1}=1$ in Equation (5), we have ", "page_idx": 23}, {"type": "equation", "text": "$$\n\\mathbb{E}[L_{t}(x_{i,p,K})-L_{t}(x^{\\star})]\\le O\\left((\\alpha+\\beta)\\sqrt{\\frac{\\log d}{2^{p}m}}+\\frac{\\alpha\\ln d}{2^{p}\\varepsilon\\sqrt{m}}+\\beta\\right).\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "Since $\\begin{array}{r}{\\beta=O(\\frac{\\log d}{\\sqrt{m}T\\varepsilon})}\\end{array}$ , we have ", "page_idx": 23}, {"type": "equation", "text": "$$\n\\mathbb{E}[L_{t}(x_{i,p,K})-L_{t}(x^{\\star})]\\le O\\left((\\alpha+\\beta)\\sqrt{\\frac{\\log d}{2^{p}m}}+\\frac{\\alpha\\ln d}{2^{p}\\varepsilon\\sqrt{m}}\\right).\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "Therefore, the total regret from time step $2^{p}$ to $2^{p+1}$ is at most ", "page_idx": 23}, {"type": "equation", "text": "$$\n\\mathbb{E}\\left[\\sum_{t=2^{p}}^{2^{p+1}-1}L_{t}(x_{i,t})-\\operatorname*{min}_{u\\in\\mathcal{X}}\\sum_{t=2^{p}}^{2^{p+1}-1}L_{t}(u)\\right]\\leq O\\left(\\sqrt{\\frac{2^{p}\\log d}{m}}+\\frac{\\log d}{\\sqrt{m}\\varepsilon}\\right).\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "Summing over $p$ , we can get ", "page_idx": 23}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{E}\\left[\\displaystyle\\sum_{t=1}^{T}L_{t}(x_{i,t})-\\operatorname*{min}_{u\\in\\mathcal{X}}\\displaystyle\\sum_{t=1}^{T}L_{t}(u)\\right]\\leq\\displaystyle\\sum_{p=1}^{\\log T}O\\left(\\sqrt{\\frac{2p\\log d}{m}}+\\frac{\\alpha\\log d}{\\sqrt{m}\\varepsilon}\\right)}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\leq O\\left(\\displaystyle\\sum_{p=1}^{\\log T}\\sqrt{\\frac{2^{p}\\log d}{m}}+\\frac{\\log d\\log T}{\\sqrt{m}\\varepsilon}\\right)}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\qquad\\leq O\\left(\\sqrt{\\frac{T\\log d}{m}}+\\frac{\\log d\\log T}{\\sqrt{m}\\varepsilon}\\right).}\\end{array}\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "The proof of the DP guarantee and communication costs follows from the proof of Theorem 1. ", "page_idx": 23}, {"type": "text", "text": "C.3 Theorem 6 (for approximate DP) ", "text_level": 1, "page_idx": 23}, {"type": "text", "text": "Theorem 6. Let $\\delta\\leq1/T$ . Assume that loss function $l_{i,t}(\\cdot)$ is convex, $\\alpha$ -Lipschitz, $\\beta$ -smooth w.r.t. $\\Vert\\cdot\\Vert_{1}$ . Assume $\\begin{array}{r}{\\varepsilon\\le\\frac{(\\alpha\\log(2^{p-1}/\\delta)\\log d)^{1/4}\\sqrt{p-1}}{(\\beta2^{p-1})^{1/4}}}\\end{array}$ . Setting $\\begin{array}{r}{\\lambda_{i,j,s}=\\frac{\\alpha2^{T_{1}/2}\\log(2^{p-1}/\\delta)}{b\\varepsilon}}\\end{array}$ \u03b12T1/2 log(2p\u22121/\u03b4), b = $\\begin{array}{r}{b=\\frac{2^{p-1}}{(p-1)^{2}}}\\end{array}$ (p\u22121)2 , and $\\begin{array}{r}{T_{1}=\\frac{2}{3}\\log\\left(\\frac{b\\varepsilon\\sqrt{m}\\beta}{\\alpha\\log\\left(2^{p-1}/\\delta\\right)\\log d}\\right)}\\end{array}$ , Fed-DP-OPE-Stoch is $(\\varepsilon,\\delta)$ -DP, the communication cost scales in $O\\left(m d2^{T_{1}}\\log T\\right)$ and the per-client regret is upper bounded by ", "page_idx": 23}, {"type": "equation", "text": "$$\nO\\left((\\alpha+\\beta)\\log T\\sqrt{\\frac{T\\log d}{m}}+\\frac{\\alpha^{2/3}\\beta^{1/3}\\log^{2/3}(d)\\log^{2/3}(1/\\delta)T^{1/3}\\log^{4/3}(T)}{m^{1/3}\\varepsilon^{2/3}}\\right).\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "Proof. We apply the following lemma to prove privacy in this setting. ", "page_idx": 23}, {"type": "text", "text": "Lemma 6 (Asi et al. (2021b), Lemma 4.4). Let $b\\geq2^{T_{1}}$ , $\\delta\\leq1/T$ and $\\varepsilon\\le\\sqrt{2^{-T_{1}}\\log(1/\\delta)}$ . Setting $\\begin{array}{r}{\\lambda_{i,j,s}=\\frac{\\alpha2^{T_{1}/2}\\log(2^{p-1}/\\delta)}{b\\varepsilon}}\\end{array}$ , we have Fed-DP-OPE is $(O(\\varepsilon),O(\\delta))\u2013D F$ . ", "page_idx": 23}, {"type": "text", "text": "Theorem 6 then follows using similar arguments to the proof of Theorem 1. ", "page_idx": 23}, {"type": "text", "text": "C.4 Extension to Central DP setting ", "text_level": 1, "page_idx": 24}, {"type": "text", "text": "In this section, we extend our Fed-DP-OPE-Stoch algorithm to the setting where client-server communication is secure with some modifications, achieving better utility performance. ", "page_idx": 24}, {"type": "text", "text": "We present the algorithm design in Algorithm 4 and Algorithm 5. We change the local privatization process to a global privatization process on the server side. Specifically, in Line 8, when communication is triggered, each client sends $\\{\\langle c_{n},v_{i,j,s}\\rangle\\}_{n\\in[d]}$ to the server, where $c_{1},\\ldots,c_{d}$ represents $d$ vertices of decision set $\\mathcal{X}=\\Delta_{d}$ . In Line 5, after receiving $\\{\\langle c_{n},v_{i,j,s}\\rangle\\}_{n\\in[d]}$ from all clients, the central server privately predicts a new expert: ", "page_idx": 24}, {"type": "equation", "text": "$$\n\\bar{w}_{j,s}=\\operatorname*{arg\\,min}_{c_{n}:1\\leq n\\leq d}\\left[\\frac{1}{m}\\sum_{i=1}^{m}\\langle c_{n},v_{i,j,s}\\rangle+\\zeta_{n}\\right],\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "where $\\zeta_{n}\\sim\\mathrm{Lap}(\\mu_{j,s})$ and $\\begin{array}{r}{\\mu_{j,s}=\\frac{4\\alpha2^{j}}{b m\\varepsilon}}\\end{array}$ . Other components remain the same. ", "page_idx": 24}, {"type": "text", "text": "Algorithm 4 Fed-DP-OPE-Stoch (CDP): Client $i$ ", "text_level": 1, "page_idx": 24}, {"type": "text", "text": "1: Input: Phases $P$ , trees $T_{1}$ , decision set $\\mathcal{X}=\\Delta_{d}$ with vertices $\\{c_{1},\\ldots,c_{d}\\}$ , batch size $b$ .   \n2: Initialize: Set $x_{i,1}=z\\in\\mathcal{X}$ and pay cost $l_{i,1}(x_{i,1})$ .   \n3: for $p=2$ to $P$ do   \n4: Set $B_{i,p}=\\left\\{l_{i,2^{p-2}},\\ldots,l_{i,2^{p-1}-1}\\right\\}$   \n5: Set k = 1 and xi,p,1 = xi,p\u22121,K   \n6: $\\begin{array}{r}{\\{v_{i,j,\\underline{{s}}}\\}_{j\\in[\\underline{{T}}_{1}],s\\in\\{0,1\\}}{\\le}j=\\mathrm{DP-FW}\\left(\\mathcal{B}_{i,p},T_{1},b\\right)}\\end{array}$   \n7: for all leaf vertices $s$ reached in DP-FW do   \n8: Communicate to server: {\u27e8cn, vi,j,s\u27e9}n\u2208[d]   \n9: Receive from server: w\u00afj,s   \n10: Update $x_{i,p,k}$ according to Equation (2)   \n11: Update $k=k+1$   \n12: end for   \n13: Final iterate outputs $x_{i,p,K}$   \n14: for $t=2^{p-1}$ to $2^{p}-1$ do   \n15: Receive loss $l_{i,t}:\\mathcal{X}\\rightarrow\\mathbb{R}$ and pay cost $l_{i,t}(x_{i,p,K})$   \n16: end for   \n17: end for ", "page_idx": 24}, {"type": "text", "text": "Algorithm 5 Fed-DP-OPE-Stoch (CDP): Central server ", "text_level": 1, "page_idx": 24}, {"type": "text", "text": "1: Input: Phases $P$ , number of clients $m$ , decision set $\\mathcal{X}=\\Delta_{d}$ with vertices $\\{c_{1},\\ldots,c_{d}\\}$ .   \n2: Initialize: Pick any $z\\in\\mathcal{X}$ and broadcast to clients.   \n3: for $p=2$ to $P$ do   \n4: Receive from clients: {\u27e8cn, vi,j,s\u27e9}n\u2208[d]   \n5: $\\begin{array}{r}{\\bar{w}_{j,s}=\\underset{c_{n}:1\\leq n\\leq d}{\\arg\\operatorname*{min}}\\left[\\frac{1}{m}\\sum_{i=1}^{m}\\langle c_{n},v_{i,j,s}\\rangle+\\dot{\\zeta}_{n}\\right]}\\end{array}$   \n6: Communicate to clients: w\u00afj,s   \n7: end for ", "page_idx": 24}, {"type": "text", "text": "Now we present the theoretical guarantees in this setting. ", "page_idx": 24}, {"type": "text", "text": "Theorem 7. Assume that loss function $l_{i,t}(\\cdot)$ is convex, $\\alpha$ -Lipschitz, $\\beta$ -smooth w.r.t. $\\|\\cdot\\|_{1}$ . Fed-DPOPE-Stoch $(i)$ satisfies $\\varepsilon{-}D P$ and (ii) achieves the per-client regret of ", "page_idx": 24}, {"type": "equation", "text": "$$\nO\\Bigg((\\alpha+\\beta)\\log T\\sqrt{\\frac{T\\log d}{m}}+\\frac{\\sqrt{\\alpha\\beta}\\log d\\sqrt{T}\\log T}{\\sqrt{m}\\sqrt{\\varepsilon}}\\Bigg),\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "with (iii) a communication cost of $\\begin{array}{r}{O\\left(m^{\\frac{3}{2}}d\\sqrt{\\frac{T\\varepsilon\\beta}{\\alpha\\log d}}\\right)}\\end{array}$ ", "page_idx": 24}, {"type": "text", "text": "To prove the theorem, we start with Lemma 7 that gives pure privacy guarantees. ", "page_idx": 24}, {"type": "text", "text": "Lemma 7. Assume that $2^{T_{1}}\\leq b$ . Setting $\\begin{array}{r}{\\mu_{j,s}=\\frac{4\\alpha2^{j}}{b m\\varepsilon}}\\end{array}$ , Fed-DP-OPE-Stoch is $\\varepsilon$ -DP. ", "page_idx": 24}, {"type": "text", "text": "Proof. Let $\\boldsymbol{S}$ and $S^{\\prime}$ be two neighboring datasets and assume that they differ in sample $l_{i_{1},t_{1}}$ or $l_{i_{1},t_{1}}^{\\prime}$ , where $2^{p_{1}-1}\\,\\leq\\,t_{1}\\,<\\,2^{p_{1}}$ . The algorithm is $\\varepsilon$ -DP if we have $(x_{1,1,K},\\dots,x_{m,P,K})$ $\\approx_{(\\varepsilon,0)}$ $(\\bar{x_{1,1,K}^{\\prime}},\\ldots,x_{m,P,K}^{\\prime})$ . ", "page_idx": 25}, {"type": "text", "text": "Let $B_{i_{1},j,s}$ be the set that contains $l_{i_{1},t_{1}}$ or $l_{i_{1},t_{1}}^{\\prime}$ . Recall that $|B_{i_{1},j,s}|\\,=\\,2^{-|s|}b$ . The key point is that this set is used in the calculation of $v_{i_{1},p_{1},k}$ for at most $2^{j-|s|}$ iterates, i.e. the leaves that are descendants of the vertex. Let $k_{0}$ and $k_{1}$ be the first and last iterate such that $B_{i_{1},j,s}$ is used for the calculation of $v_{i_{1},p_{1},k}$ , hence $k_{1}-k_{0}+1\\leq2^{j-|s|}$ . For a sequence $a_{i},\\dotsc,a_{j}$ , we use the shorthand $a_{i:j}=\\{a_{i},\\ldots,\\stackrel{\\cdot\\cdot}{a_{j}}\\}$ . ", "page_idx": 25}, {"type": "text", "text": "Step 1: $\\mathbf{x_{1:m,p_{1},k_{0}:k_{1}}}\\approx_{(\\varepsilon,\\mathbf{0})}\\mathbf{x_{1:m,p_{1},k_{0}:k_{1}}^{\\prime}}$ and $\\bar{\\bf w}_{{\\bf p}_{1},{\\bf k_{0}}:{\\bf k_{1}}}\\approx_{(\\varepsilon,{\\bf0})}\\bar{\\bf w}_{{\\bf p}_{1},{\\bf k_{0}}:{\\bf k_{1}}}^{\\prime}$ by basic composition, post-processing and report noisy max ", "page_idx": 25}, {"type": "text", "text": "We will show that $\\left(x_{1,p_{1},k_{0}},\\ldots,x_{m,p_{1},k_{1}}\\right)$ and $(x_{1,p_{1},k_{0}}^{\\prime},\\dots,x_{m,p_{1},k_{1}}^{\\prime})$ are $\\varepsilon$ -indistinguishable. Since $B_{i_{1},j,s}$ is used to calculate $v_{i_{1},p_{1},k}$ for at most $2^{j-|s|}$ iterates, i.e. $k_{1}-k_{0}+1\\leq2^{j-|s|}$ , it is enough to show that $\\begin{array}{r}{\\bar{w}_{p_{1},k}\\approx_{(\\frac{\\varepsilon}{2^{j}-|\\mathit{s}|},0)}\\bar{w}_{p_{1},k}^{\\prime}}\\end{array}$ for $k_{0}\\leq k\\leq k_{1}$ and then apply basic composition and postprocessing. Note that for every $k_{0}\\,\\leq\\,k\\,\\leq\\,k_{1}$ , the sensitivity $\\begin{array}{r}{|\\langle c_{n},v_{i_{1},p_{1},k}-v_{i_{1},p_{1},k}^{\\prime}\\rangle|\\,\\leq\\,\\frac{4\\alpha}{2^{-|s|}b}}\\end{array}$ , therefore, $\\begin{array}{r}{|\\frac{1}{m}\\sum_{i=1}^{m}\\langle c_{n},v_{i,p_{1},k}\\rangle-\\frac{1}{m}\\sum_{i=1}^{m}\\langle c_{n},v_{i,p_{1},k}^{\\prime}\\rangle|\\ \\leq\\ \\frac{4\\alpha}{2^{-|s|}m b}}\\end{array}$ . Using privacy guarantees of report noisy max (Lemma 15), we have $\\begin{array}{r}{\\bar{w}_{p_{1},k}\\approx_{(\\frac{\\varepsilon}{2^{j}-|\\s s|},0)}\\bar{w}_{p_{1},k}^{\\prime}}\\end{array}$ for $k_{0}\\leq k\\leq k_{1}$ with $\\begin{array}{r}{\\mu_{j,s}=\\frac{4\\alpha2^{j}}{b m\\varepsilon}}\\end{array}$ . ", "page_idx": 25}, {"type": "text", "text": "Step 2: $\\mathbf{x_{1:m,1:P,K}}\\approx_{(\\varepsilon,\\mathbf{0})}\\mathbf{x_{1:m,1:P,K}^{\\prime}}$ by post-processing ", "text_level": 1, "page_idx": 25}, {"type": "text", "text": "In order to show $(x_{1,1,K},\\ldots,x_{m,P,K})\\approx_{(\\varepsilon,0)}$ $(x_{1,1,K}^{\\prime},\\dotsc,x_{m,P,K}^{\\prime})$ , we only need to prove that $\\left(x_{1,p_{1},K},\\ldots,x_{m,p_{1},K}\\right)\\,\\approx_{\\left(\\varepsilon,0\\right)}\\,\\left(x_{1,p_{1},K}^{\\prime},\\ldots,x_{m,p_{1},K}^{\\prime}\\right)$ and apply post-processing. It is enough to show that iterates $(x_{1,p_{1},1},\\ldots,x_{m,p_{1},K})$ and $(x_{1,p_{1},1}^{\\prime},\\dotsc,x_{m,p_{1},K}^{\\prime})$ is $\\varepsilon$ -indistinguishable. ", "page_idx": 25}, {"type": "text", "text": "The iterates $x_{1:m,p_{1},1:k_{0}-1}$ and $x_{1:m,p_{1},1:k_{0}-1}^{\\prime}$ do not depend on $l_{i_{1},t_{1}}$ or $l_{i_{1},t_{1}}^{\\prime}$ , hence 0- indistinguishable. Moreover, given that $\\bar{(x_{1,p_{1},k_{0}},\\ldots,x_{m,p_{1},k_{1}})}$ and $(x_{1,p_{1},k_{0}}^{\\prime},\\cdot\\cdot\\cdot,x_{m,p_{1},k_{1}}^{\\prime})$ are $\\varepsilon$ -indistinguishable, it is clear that $(x_{1,p_{1},k_{1}+1},\\ldots,x_{m,p_{1},K})$ and $(x_{1,p_{1},k_{1}+1}^{\\prime},\\ldots,x_{m,p_{1},K}^{\\prime})$ are $\\varepsilon$ - indistinguishable by post-processing. \u53e3 ", "page_idx": 25}, {"type": "text", "text": "To help prove the upper bound of the regret, we introduce some lemmas first. ", "page_idx": 25}, {"type": "text", "text": "Lemma 8. Setting \u00b5j,s $\\begin{array}{r}{\\mu_{j,s}=\\frac{4\\alpha2^{j}}{m b\\varepsilon}}\\end{array}$ 4m\u03b1b2\u03b5 , we have ", "page_idx": 25}, {"type": "equation", "text": "$$\n\\mathbb{E}[\\langle\\bar{v}_{p,k},\\bar{w}_{p,k}\\rangle]\\leq\\mathbb{E}\\left[\\operatorname*{min}_{w\\in\\mathcal{X}}\\langle\\bar{v}_{p,k},w\\rangle\\right]+O\\left(\\frac{\\alpha2^{j}\\ln d}{m b\\varepsilon}\\right).\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "Proof. Since $\\begin{array}{r}{\\bar{w}_{p,k}\\,=\\,\\arg\\operatorname*{min}_{c_{n}:1\\leq n\\leq d}\\left[\\frac{1}{m}\\sum_{i=1}^{m}\\langle c_{n},v_{i,p,k}\\rangle+\\zeta_{n}\\right]}\\end{array}$ , where $\\zeta_{n}\\sim\\mathrm{Lap}(\\mu_{j,s})$ , we denote $\\bar{w}_{p,k}$ as $c_{n}\\star$ and we have ", "page_idx": 25}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\langle\\bar{w}_{p,k},\\bar{v}_{p,k}\\rangle=\\langle c_{n^{\\star}},\\bar{v}_{p,k}\\rangle}\\\\ &{\\qquad\\qquad=\\displaystyle\\operatorname*{min}_{n:1\\leq n\\leq d}\\big(\\langle c_{n},\\bar{v}_{p,k}\\rangle+\\zeta_{n}\\big)-\\zeta_{n^{\\star}}}\\\\ &{\\qquad\\qquad\\leq\\displaystyle\\operatorname*{min}_{n:1\\leq n\\leq d}\\langle c_{n},\\bar{v}_{p,k}\\rangle+2\\displaystyle\\operatorname*{max}_{n:1\\leq n\\leq d}\\lvert\\zeta_{n}\\rvert.}\\end{array}\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "Standard results for the expectation of maximum of $d$ i.i.d. Laplace random variables imply that $\\mathbb{E}\\left[\\operatorname*{max}_{n:1\\leq n\\leq d}\\lvert\\zeta_{n}\\rvert\\right]\\leq O(\\mu_{j,s}\\ln d)$ . Therefore, ", "page_idx": 25}, {"type": "equation", "text": "$$\n\\mathbb{E}[\\langle\\bar{v}_{p,k},\\bar{w}_{p,k}\\rangle]\\leq\\mathbb{E}\\left[\\operatorname*{min}_{w\\in\\mathcal{X}}\\langle\\bar{v}_{p,k},w\\rangle\\right]+O\\left(\\mu_{j,s}\\ln d\\right).\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "Then we are ready to prove Theorem 7. ", "page_idx": 25}, {"type": "text", "text": "Proof. Lemma 7 implies the claim about privacy. Following the same arguments in the proof of Theorem 1, we can get ", "page_idx": 26}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\xi[L_{t}(x_{i,p,k+1})-L_{t}(x^{\\star})]\\leq(1-\\eta_{i,p,k})\\mathbb{E}[L_{t}(x_{i,p,k})-L_{t}(x^{\\star})]+\\eta_{i,p,k}\\mathbb{E}[\\|\\nabla L_{t}(x_{i,p,k})-\\bar{v}_{p,k}\\|_{\\infty}]}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\qquad+\\eta_{i,p,k}\\mathbb{E}[\\langle\\bar{v}_{p,k},\\bar{w}_{p,k}\\rangle-\\underset{w\\in\\mathcal{X}}{\\operatorname*{min}}\\langle\\bar{v}_{p,k},w\\rangle]+\\frac{1}{2}\\beta\\eta_{i,p,k}^{\\phantom{}}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 26}, {"type": "text", "text": "Applying Lemma 8 and Lemma 3, we have ", "page_idx": 26}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{E}[L_{t}(x_{i,p,k+1})-L_{t}(x^{\\star})]\\leq(1-\\eta_{i,p,k})\\mathbb{E}[L_{t}(x_{i,p,k})-L_{t}(x^{\\star})]+\\eta_{i,p,k}(\\alpha+\\beta)O\\left(\\sqrt{\\frac{\\log d}{b m}}\\right)}\\\\ &{\\qquad\\qquad\\qquad\\qquad+\\,\\frac{\\eta_{i,p,k}\\alpha2^{j}}{b\\varepsilon}O\\left(\\frac{\\ln d}{m}\\right)+\\frac{1}{2}\\beta\\eta_{i,p,k}{}^{2}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 26}, {"type": "text", "text": "Let $\\begin{array}{r}{\\alpha_{k}=\\eta_{i,p,k}(\\alpha+\\beta)O\\left(\\sqrt{\\frac{\\log d}{b m}}\\right)+\\frac{\\eta_{i,p,k}\\alpha2^{j}}{b\\varepsilon}O\\left(\\frac{\\ln d}{m}\\right)+\\frac{1}{2}\\beta\\eta_{i,p,k}{^2}}\\end{array}$ . We simplify the notion of $\\eta_{i,p,k}$ to $\\eta_{k}$ . Then we have ", "page_idx": 26}, {"type": "equation", "text": "$$\n\\begin{array}{l}{\\displaystyle\\mathbb{E}[L_{t}(x_{i,p,k})-L_{t}(x^{\\star})]\\leq\\sum_{k^{\\prime}=1}^{K}\\alpha_{k}\\prod_{i>k}^{K-1}(1-\\eta_{k^{\\prime}})}\\\\ {\\displaystyle=\\sum_{k=1}^{K}\\alpha_{k}\\frac{(k+1)k}{K(K-1)}}\\\\ {\\displaystyle\\leq\\sum_{k=1}^{K}\\alpha_{k}\\frac{(k+1)^{2}}{(K-1)^{2}},}\\end{array}\n$$", "text_format": "latex", "page_idx": 26}, {"type": "text", "text": "where \u03b7k = $\\begin{array}{r}{\\eta_{k}=\\frac{2}{k+1}}\\end{array}$ ", "page_idx": 26}, {"type": "text", "text": "Since $K=2^{T_{1}}$ , simply algebra implies that ", "page_idx": 26}, {"type": "equation", "text": "$$\n\\mathbb{E}[L_{t}(x_{i,p,K})-L_{t}(x^{\\star})]\\leq O\\left((\\alpha+\\beta)\\sqrt{\\frac{\\log d}{b m}}+\\frac{\\alpha2^{T_{1}}\\ln d}{b\\varepsilon m}+\\frac{\\beta}{2^{T_{1}}}\\right).\n$$", "text_format": "latex", "page_idx": 26}, {"type": "text", "text": "At iteration $2^{p-1}\\leq t<2^{p}$ , setting $\\begin{array}{r}{b=\\frac{2^{p-1}}{(p-1)^{2}}}\\end{array}$ and $\\begin{array}{r}{T_{1}=\\frac{1}{2}\\log\\left(\\frac{b\\varepsilon\\beta m}{\\alpha\\log d}\\right)}\\end{array}$ , we have ", "page_idx": 26}, {"type": "equation", "text": "$$\n\\mathbb{E}[L_{t}(x_{i,p,K})-L_{t}(x^{\\star})]\\le O\\left((\\alpha+\\beta)p\\sqrt{\\frac{\\log d}{2^{p}m}}+\\frac{p\\sqrt{\\alpha\\beta}\\log d}{\\sqrt{m}\\sqrt{2^{p}\\varepsilon}}\\right).\n$$", "text_format": "latex", "page_idx": 26}, {"type": "text", "text": "Summing over all the timesteps, we have ", "page_idx": 26}, {"type": "equation", "text": "$$\n\\mathbb{E}\\left[\\sum_{t=1}^{T}L_{t}(x_{i,t})-\\operatorname*{min}_{u\\in\\mathcal{X}}\\sum_{t=1}^{T}L_{t}(u)\\right]\\leq O\\left((\\alpha+\\beta)\\log T\\sqrt{\\frac{T\\log d}{m}}+\\frac{\\sqrt{\\alpha\\beta}\\log d\\sqrt{T}\\log T}{\\sqrt{m\\varepsilon}}\\right).\n$$", "text_format": "latex", "page_idx": 26}, {"type": "text", "text": "The proof of communication cost is similar to that in proof of Theorem 1. ", "page_idx": 26}, {"type": "text", "text": "D Proof of Lower Bounds ", "text_level": 1, "page_idx": 26}, {"type": "text", "text": "Theorem 8 (Restatement of Theorem 2). For any f\u221aederated OPE algorithm against oblivious adversaries, the per-client regret is lower bounded by $\\Omega({\\sqrt{T\\log d}})$ . Let $\\varepsilon\\in(0,1]$ and $\\delta=o(1/T)$ , for any $(\\varepsilon,\\delta)$ -DP federated OPE algorithm, the per-client regret is lower bounded by $\\Omega\\left(\\operatorname*{min}{\\left(\\frac{\\log d}{\\varepsilon},T\\right)}\\right)$ . ", "page_idx": 26}, {"type": "text", "text": "Proof. Consider the case when all clients receive the same loss function from the oblivious adversary at each time step, i.e. ${l}_{i,t}\\,=\\,{l}_{t}^{\\prime}$ . Then we define the average policy among all clients $p_{t}^{\\prime}(k)\\stackrel{!}{=}$ $\\begin{array}{r}{\\frac{1}{m}\\sum_{i=1}^{m}p_{i,t}(k),\\forall k\\in[d]}\\end{array}$ . Now the regret is ", "page_idx": 26}, {"type": "equation", "text": "$$\n\\mathbb{E}\\left[\\frac{1}{m}\\sum_{i=1}^{m}\\sum_{t=1}^{T}l_{i,t}(x_{i,t})\\right]-\\frac{1}{m}\\sum_{i=1}^{m}\\sum_{t=1}^{T}l_{i,t}(x^{\\star})=\\mathbb{E}\\left[\\frac{1}{m}\\sum_{i=1}^{m}\\sum_{t=1}^{T}l_{t}^{\\prime}(x_{i,t})\\right]-\\sum_{t=1}^{T}l_{t}^{\\prime}(x^{\\star})\n$$", "text_format": "latex", "page_idx": 26}, {"type": "equation", "text": "$$\n\\begin{array}{l}{\\displaystyle=\\frac{1}{m}\\sum_{i=1}^{m}\\sum_{t=1}^{T}\\sum_{k=1}^{d}p_{i,t}(k)\\cdot l_{t}^{\\prime}(k)-\\sum_{t=1}^{T}l_{t}^{\\prime}(x^{\\star})}\\\\ {\\displaystyle=\\sum_{t=1}^{T}\\sum_{k=1}^{d}\\left(\\frac{1}{m}\\sum_{i=1}^{m}p_{i,t}(k)\\right)\\cdot l_{t}^{\\prime}(k)-\\sum_{t=1}^{T}l_{t}^{\\prime}(x^{\\star})}\\\\ {\\displaystyle=\\sum_{t=1}^{T}\\sum_{k=1}^{d}p_{t}^{\\prime}(k)\\cdot l_{t}^{\\prime}(k)-\\sum_{t=1}^{T}l_{t}^{\\prime}(x^{\\star}).}\\end{array}\n$$", "text_format": "latex", "page_idx": 27}, {"type": "text", "text": "Note that $p_{t}^{\\prime}(k)$ is defined by $p_{1,t}(k),\\ldots,p_{m,t}(k)$ , which in turn are determined by $l_{1,1},\\dotsc,l_{m,t-1}$ . According to our choice of $l_{i,t}=l_{t}^{\\prime},p_{t}^{\\prime}(k)$ is determined by $l_{1}^{\\prime},l_{2}^{\\prime},\\ldots,l_{t-1}^{\\prime}$ . Therefore $p_{1}^{\\prime},p_{2}^{\\prime},\\ldots,p_{t}^{\\prime}$ are generated by a legitimate algorithm for online learning with expert advice problems. ", "page_idx": 27}, {"type": "text", "text": "There exists a sequence of losses $l_{1}^{\\prime},l_{2}^{\\prime},\\ldots,l_{t}^{\\prime}$ such that for any algorithm for online learning with expert advice problem, the expected regret satisfies (Cesa-Bianchi and Lugosi (2006), Theorem 3.7) ", "page_idx": 27}, {"type": "equation", "text": "$$\n\\sum_{t=1}^{T}\\sum_{k=1}^{d}p_{t}^{\\prime}(k)\\cdot l_{t}^{\\prime}(k)-\\sum_{t=1}^{T}l_{t}^{\\prime}(x^{\\star})\\geq\\Omega(\\sqrt{T\\log d}).\n$$", "text_format": "latex", "page_idx": 27}, {"type": "text", "text": "Therefore, we have ", "page_idx": 27}, {"type": "equation", "text": "$$\n\\mathbb{E}\\left[\\frac{1}{m}\\sum_{i=1}^{m}\\sum_{t=1}^{T}l_{i,t}(x_{i,t})\\right]-\\frac{1}{m}\\sum_{i=1}^{m}\\sum_{t=1}^{T}l_{i,t}(x^{\\star})\\geq\\Omega(\\sqrt{T\\log d}).\n$$", "text_format": "latex", "page_idx": 27}, {"type": "text", "text": "From Lemma 9, if $\\varepsilon\\in(0,1]$ and $\\delta=o(1/T)$ , then there exists a sequence of losses $l_{1}^{\\prime},l_{2}^{\\prime},\\ldots,l_{t}^{\\prime}$ such that for any $(\\varepsilon,\\delta)$ -DP algorithm for online learning with expert advice problem against oblivious adversaries, the expected regret satisfies ", "page_idx": 27}, {"type": "equation", "text": "$$\n\\sum_{t=1}^{T}\\sum_{k=1}^{d}p_{t}^{\\prime}(k)\\cdot l_{t}^{\\prime}(k)-\\sum_{t=1}^{T}l_{t}^{\\prime}(x^{\\star})\\geq\\Omega\\left(\\operatorname*{min}\\left(\\frac{\\log d}{\\varepsilon},T\\right)\\right).\n$$", "text_format": "latex", "page_idx": 27}, {"type": "text", "text": "Therefore, we have for any $(\\varepsilon,\\delta)$ -DP algorithm, ", "page_idx": 27}, {"type": "equation", "text": "$$\n\\mathbb{E}\\left[\\frac{1}{m}\\sum_{i=1}^{m}\\sum_{t=1}^{T}l_{i,t}(x_{i,t})\\right]-\\frac{1}{m}\\sum_{i=1}^{m}\\sum_{t=1}^{T}l_{i,t}(x^{\\star})\\geq\\Omega\\left(\\operatorname*{min}\\left(\\frac{\\log d}{\\varepsilon},T\\right)\\right).\n$$", "text_format": "latex", "page_idx": 27}, {"type": "text", "text": "Lemma 9. Let $\\varepsilon\\in(0,1]$ and $\\delta=o(1/T)$ . There exists a sequence of losses $l_{1},\\dots,l_{T}$ such that for any $(\\varepsilon,\\delta)$ -DP algorithm $\\boldsymbol{\\mathcal{A}}$ for $D P$ -OPE against oblivious adversaries satisfies ", "page_idx": 27}, {"type": "equation", "text": "$$\n\\sum_{t=1}^{T}l_{t}(x_{t})-\\operatorname*{min}_{x^{\\star}\\in[d]}\\sum_{t=1}^{T}l_{t}(x^{\\star})\\geq\\Omega\\left(\\operatorname*{min}\\left({\\frac{\\log d}{\\varepsilon}},T\\right)\\right).\n$$", "text_format": "latex", "page_idx": 27}, {"type": "text", "text": "Proof. Let $n,d\\in\\mathbb{N}$ . Define $\\textbf{y}\\in\\mathcal{V}^{n}$ containing $n$ records, where ${\\boldsymbol{\\mathcal{V}}}\\,=\\,\\{0,1\\}^{d}$ . The function 1-Select $^d$ : ${\\mathcal{V}}^{n}\\to[d]$ corresponds to selecting a coordinate $b\\in[d]$ in the batch model. ", "page_idx": 27}, {"type": "text", "text": "Then we define the regret of 1-Select $^d$ . For a batched algorithm $\\mathcal{M}$ with input dataset $\\mathbf{y}$ and output $b\\in[d]$ , define ", "page_idx": 27}, {"type": "equation", "text": "$$\n\\mathrm{Reg}_{1-\\mathrm{Select}_{d}}(\\mathcal{M}(\\mathbf{y}))=\\frac{1}{n}\\left[\\sum_{i=1}^{n}y_{i}(b)-\\mathrm{min}_{x^{\\star}\\in[d]}\\left(\\sum_{i=1}^{n}y_{i}(x^{\\star})\\right)\\right].\n$$", "text_format": "latex", "page_idx": 27}, {"type": "text", "text": "Let $\\boldsymbol{\\mathcal{A}}$ be an $(\\varepsilon,\\delta)$ -DP algorithm $\\left(\\{0,1\\}^{d}\\right)^{T}\\,\\rightarrow\\,([d])^{T}$ for DP-OPE against oblivious adversaries with regret $\\begin{array}{r}{\\sum_{t=1}^{T}l_{t}(x_{t})-\\operatorname*{min}_{x^{\\star}\\in[d]}\\sum_{t=1}^{T}l_{t}(x^{\\star})\\le\\alpha}\\end{array}$ . Setting $T=n$ , we can use $\\boldsymbol{\\mathcal{A}}$ to construct an $(\\varepsilon,\\delta)$ -DP algorithm $\\mathcal{M}$ for 1-Selectd in the batch model. The details of the algorithm appear in Algorithm 6. ", "page_idx": 27}, {"type": "text", "text": "", "page_idx": 28}, {"type": "table", "img_path": "T826pwZLci/tmp/05508cea79b5e0cf45ddba5e7c1c0e1ecd5c532ff3582905a9a73ee32aa3f475.jpg", "table_caption": ["Algorithm 6 Batch algorithm $\\mathcal{M}$ for 1-Select (Jain et al. (2023), Algorithm 2 with $k=1$ ) "], "table_footnote": [], "page_idx": 28}, {"type": "text", "text": "Let $\\varepsilon>0,\\alpha\\in\\mathbb{R}^{+}$ , and $T,d,n\\in\\mathbb{N}$ , where $T=n$ . If a DP-OPE algorithm $\\boldsymbol{\\mathcal{A}}$ : $\\left(\\{0,1\\}^{d}\\right)^{T}\\rightarrow([d])^{T}$ for oblivious adversaries is $(\\varepsilon,\\delta)$ -DP and the regret is upper bounded by $\\alpha$ , i.e. $\\textstyle\\sum_{t=1}^{T}l_{t}(x_{t})\\,-$ $\\begin{array}{r}{\\operatorname*{min}_{x^{\\star}\\in[d]}\\sum_{t=1}^{T}l_{t}(x^{\\star})\\leq\\alpha}\\end{array}$ , then by Lemma 10, we have the batch algorithm $\\mathcal{M}$ for 1-Selectd is $(\\varepsilon,\\delta)$ -DP and $\\begin{array}{r}{\\mathrm{Reg}_{1-\\mathrm{Select}_{d}}(\\mathcal{M})\\leq\\frac{\\alpha}{n}}\\end{array}$ . ", "page_idx": 28}, {"type": "text", "text": "If $\\delta~=~o(1/T)$ , then $\\begin{array}{r}{n~=~\\Omega\\left(\\frac{n\\log d}{\\varepsilon\\alpha}\\right)}\\end{array}$ (Lemma 11). We have $\\alpha\\;=\\;\\operatorname*{min}\\left(\\Omega\\left({\\frac{\\log d}{\\varepsilon}}\\right),n\\right)\\;=$ $\\operatorname*{min}\\left(\\Omega\\left({\\frac{\\log d}{\\varepsilon}}\\right),T\\right)$ . $\\begin{array}{r}{\\mathsf{S o}\\,\\alpha\\ge\\Omega\\left(\\operatorname*{min}\\left(\\frac{\\log d}{\\varepsilon},T\\right)\\right)}\\end{array}$ . Therefore, if an algorithm for DP-OPE against oblivious adversaries is $(\\varepsilon,\\delta)$ -differentially private and $\\begin{array}{r}{\\sum_{t=1}^{T}l_{t}(x_{t})-\\operatorname*{min}_{x^{\\star}\\in[d]}\\sum_{t=1}^{T}l_{t}(x^{\\star})\\le\\alpha}\\end{array}$ holds, then \u03b1 \u2265\u2126 min lo\u03b5g  d, T  . This means that there exists a sequence of loss functions $l_{1},\\dots,l_{T}$ such that $\\begin{array}{r}{\\dot{\\sum}_{t=1}^{T}\\dot{l}_{t}(x_{t})-\\operatorname*{min}_{x^{\\star}\\in[d]}\\sum_{t=1}^{T}l_{t}(x^{\\star})\\geq\\Omega\\left(\\operatorname*{min}\\left(\\frac{\\log d}{\\varepsilon},T\\right)\\right)\\!.}\\end{array}$ \u53e3 ", "page_idx": 28}, {"type": "text", "text": "Lemma 10. Let $\\mathcal{M}$ be the batch algorithm for $1{-}S e l e c t_{d}$ . For all $\\varepsilon~>~0,\\delta~\\geq~0,\\alpha~\\in~\\mathbb{R}^{+}$ , and $T,d,n\\;\\;\\in\\;\\;\\mathbb{N}_{:}$ , where $\\textit{T}=\\textit{n}_{\\!}$ , if a DP-OPE algorithm $\\boldsymbol{\\mathcal{A}}$ : $\\left(\\{0,1\\}^{d}\\right)^{T}~\\to~([d])^{T}$ for oblivious adversaries is $(\\varepsilon,\\delta)$ -differentially private and the regret is upper bounded by $\\alpha$ , i.e. $\\begin{array}{r}{\\sum_{t=1}^{T}l_{t}(x_{t})\\;-\\;\\operatorname*{min}_{x^{\\star}\\in[d]}\\sum_{t=1}^{T}l_{t}(x^{\\star})\\;\\le\\;\\;\\alpha,}\\end{array}$ , then batch algorithm $\\mathcal{M}$ for 1-Selectd is $(\\varepsilon,\\delta)$ - differentially private and $\\mathrm{Reg}_{1-S e l e c t_{d}}(\\mathcal{M})\\leq\\frac{\\alpha}{n}$ . ", "page_idx": 28}, {"type": "text", "text": "Proof. DP guarantee: Fix neighboring datasets $\\mathbf{y}$ and $\\mathbf{y}^{\\prime}$ that are inputs to algorithm $\\mathcal{M}$ . According to the algorithm design for $1{\\mathrm{-}}{\\mathrm{Select}}_{d}$ , we stream $\\mathbf{y}$ and $\\mathbf{y}^{\\prime}$ to a DP-OPE algorithm $\\boldsymbol{\\mathcal{A}}$ . Since $\\boldsymbol{\\mathcal{A}}$ is $(\\varepsilon,\\delta)$ -DP, and $\\mathcal{M}$ only post-processes the outputs received from $\\boldsymbol{\\mathcal{A}}$ , therefore $\\mathcal{M}$ is $(\\varepsilon,\\delta)$ -DP. ", "page_idx": 28}, {"type": "text", "text": "Regret upper bound: Fix a dataset y. Note that if $\\alpha\\geq n$ , the accuracy guarantee for $\\mathcal{M}$ is vacuous. Now assume $\\alpha<n$ . Let $\\gamma$ be the regret of $\\mathcal{M}$ , that is, ", "page_idx": 28}, {"type": "equation", "text": "$$\n\\begin{array}{l}{\\displaystyle\\gamma=\\mathrm{Reg}_{1-\\mathrm{Select}_{d}}(\\mathcal{M})}\\\\ {\\displaystyle\\,=\\frac{1}{n}\\left[\\sum_{i=1}^{n}y_{i}(b)-\\operatorname*{min}_{x^{\\star}\\in[d]}\\left(\\sum_{i=1}^{n}y_{i}(x^{\\star})\\right)\\right],}\\end{array}\n$$", "text_format": "latex", "page_idx": 28}, {"type": "text", "text": "where $b$ is the output of $\\mathcal{M}$ . ", "page_idx": 28}, {"type": "text", "text": "The main observation in the regret analysis is that if $\\alpha$ is small, so is $\\gamma$ . Specifically, the regret of $\\mathcal{M}$ is at most n\u03b1. Therefore, \u03b3 \u2264 \u53e3 n ", "page_idx": 28}, {"type": "text", "text": "Lemma 11 (Jain et al. (2023), Lemma 4.2). For all $\\begin{array}{r}{d,n\\in\\mathbb{N},\\varepsilon\\in(0,1],\\delta=o(1/n),\\gamma\\in\\left[0,\\frac{1}{20}\\right]}\\end{array}$ , and $(\\varepsilon,\\delta)\u2013D P\\ 1\u2013S e l e c t_{d}$ algorithms $\\mathcal{M}$ : $\\left(\\{0,1\\}^{d}\\right)^{n}\\,\\to\\,[d]$ with $\\mathrm{Reg}_{1-S e l e c t_{d}}({\\mathcal M})\\ \\leq\\ \\gamma,$ , we have $\\begin{array}{r}{n=\\Omega\\left(\\frac{\\log d}{\\varepsilon\\gamma}\\right)}\\end{array}$ . ", "page_idx": 28}, {"type": "text", "text": "E Algorithms and Proofs for Fed-SVT ", "text_level": 1, "page_idx": 29}, {"type": "text", "text": "E.1 Proof of Theorem 3 ", "text_level": 1, "page_idx": 29}, {"type": "text", "text": "Theorem 9 (Restatement of Theorem 3). Let $\\varepsilon\\leq1$ and $\\delta\\,\\leq\\,\\varepsilon/d.$ . For any $(\\varepsilon,\\delta)$ -DP federated OPE algorithm against oblivious adversaries in the realizable setting, the per-client regret is lower bounded by \u2126 logm(\u03b5d) ", "page_idx": 29}, {"type": "text", "text": "Proof. I introduce two prototype loss functions first: let $l^{0}(x)=0$ for all $x\\in[d]$ and for $j\\in[d]$ let $l^{j}(x)$ be the function that has $\\bar{l}^{j}(x)=0$ for $x=j$ and otherwise $l^{j}(x)=1$ . Then we define $d$ loss sequences $\\mathcal{S}^{j}=(l_{1,1}^{j},\\...\\ ,l_{m,T}^{j})$ , such that ", "page_idx": 29}, {"type": "equation", "text": "$$\nl_{i,t}^{j}=\\left\\{l^{0}\\quad\\mathrm{if}\\quad t=1,\\dots,T-k,\\right.\n$$", "text_format": "latex", "page_idx": 29}, {"type": "text", "text": "where $\\textstyle k={\\frac{\\log d}{2m\\varepsilon}}$ and $j\\in[d]$ . ", "page_idx": 29}, {"type": "text", "text": "The oblivious adversary picks one of the $d$ sequences $S^{1},\\ldots,S^{d}$ uniformly at random. Assume towards a contradiction that $\\begin{array}{r l}{\\mathbb{E}\\left[\\sum_{i=1}^{m}\\sum_{t=1}^{T}l_{i,t}(x_{i,t})-\\sum_{i=1}^{m}\\sum_{t=1}^{T}l_{i,t}(x^{\\star})\\right]\\;\\le}&{{}}\\end{array}$ $\\frac{\\log(d)}{32\\varepsilon}$ This implies that there exists $d/2$ sequences such that the expected regret satisfies $\\begin{array}{r}{\\mathbb{E}\\left[\\sum_{i=1}^{m}\\sum_{t=1}^{T}l_{i,t}^{j}(x_{i,t})-\\sum_{i=1}^{m}\\sum_{t=1}^{T}l_{i,t}^{j}(x^{\\star})\\right]\\leq\\frac{\\log(d)}{16\\varepsilon}}\\end{array}$ . Assume without loss of generality these sequences are $S^{1},\\ldots,S^{d/2}$ . Let $B_{j}$ be the set of outputs that has low regret on $S^{j}$ , that is, ", "page_idx": 29}, {"type": "equation", "text": "$$\nB_{j}=\\left\\{(x_{1,1},\\ldots,x_{m,T})\\in[d]^{m T}:\\sum_{i=1}^{m}\\sum_{t=1}^{T-k+1}\\ell^{j}\\left(x_{i,t}\\right)\\leq{\\frac{\\log(d)}{8\\varepsilon}}\\right\\}.\n$$", "text_format": "latex", "page_idx": 29}, {"type": "text", "text": "Note that $B_{j}\\cap B_{j^{\\prime}}=\\emptyset$ since if $x_{1:m,1:T}\\in B_{j}$ then among the $m k$ outputs $x_{1:m,T-k+1:T}$ at least 3m4k = 3 lo8g\u03b5(d)of them must be equal to j. Now Markov inequality implies that ", "page_idx": 29}, {"type": "equation", "text": "$$\n\\mathbb{P}\\left(\\boldsymbol{\\mathcal{A}}\\left(\\boldsymbol{\\mathcal{S}}^{j}\\right)\\in\\mathcal{B}_{j}\\right)\\geq1/2.\n$$", "text_format": "latex", "page_idx": 29}, {"type": "text", "text": "Moreover, group privacy gives ", "page_idx": 29}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{P}\\left(A\\left(\\boldsymbol{\\mathcal{S}}^{j}\\right)\\in\\mathcal{B}_{j^{\\prime}}\\right)\\geq e^{-m k\\varepsilon}\\mathbb{P}\\left(A\\left(\\boldsymbol{\\mathcal{S}}^{j^{\\prime}}\\right)\\in\\mathcal{B}_{j^{\\prime}}\\right)-m k\\delta}\\\\ &{\\qquad\\qquad\\qquad\\geq\\displaystyle\\frac{1}{2\\sqrt{d}}-\\frac{\\log d}{2\\varepsilon}\\delta}\\\\ &{\\qquad\\qquad\\geq\\displaystyle\\frac{1}{4\\sqrt{d}}}\\end{array}\n$$", "text_format": "latex", "page_idx": 29}, {"type": "text", "text": "where the last inequality is due to $\\delta\\leq\\varepsilon/d$ . Overall we get that ", "page_idx": 29}, {"type": "equation", "text": "$$\n\\frac{d/2-1}{4\\sqrt{d}}\\le\\mathbb{P}\\left(A\\left({\\cal S}^{j}\\right)\\notin B_{j}\\right)\\le\\frac12\n$$", "text_format": "latex", "page_idx": 29}, {"type": "text", "text": "which is a contradiction for $d\\geq32$ . ", "page_idx": 29}, {"type": "text", "text": "E.2 Algorithm Design of Fed-SVT ", "text_level": 1, "page_idx": 29}, {"type": "text", "text": "Fed-SVT contains a client-side subroutine (Algorithm 7) and a server-side subroutine (Algorithm 8). ", "page_idx": 29}, {"type": "text", "text": "E.3 Proof of Theorem 4 ", "text_level": 1, "page_idx": 29}, {"type": "text", "text": "Theorem 10 (Restatement of Theorem 4). Let $l_{i,t}~\\in~[0,1]^{d}$ be chosen by an oblivious adversary under near-realizability assumption. Set $\\mathrm{~0~}<\\mathrm{~\\rho~}<\\mathrm{~1/2~}$ , $\\kappa\\ =\\ O(\\log(d/\\rho))$ , $L\\_$ $\\begin{array}{r}{m L^{\\star}+\\frac{8\\log(2T^{2}/(N^{2}\\rho))}{\\varepsilon}+4/\\eta,}\\end{array}$ , and $\\eta=\\varepsilon/2\\kappa$ . Then the algorithm is $\\varepsilon{\\mathrm{-}}D P,$ the communication cost ", "page_idx": 29}, {"type": "text", "text": "Algorithm 7 Fed-SVT: Client i ", "page_idx": 30}, {"type": "text", "text": "1: Input: Number of Iterations $T$   \n2: Initialize: Set current expert $x_{0}={\\mathrm{Unif}}[d]$ .   \n3: for $t=1$ to $T$ do   \n4: if $t==n N$ for some integer $n\\geq1$ then   \n5: Communicate to server: $\\textstyle\\sum_{t^{\\prime}=t-N}^{t-1}l_{i,t^{\\prime}}(x)$   \n6: Receive from server: $x_{t}$   \n7: else   \n8: Set xt = xt\u22121   \n9: end if   \n10: Each client receives local loss $l_{i,t}:[d]\\rightarrow[0,1]$ and pays cost $l_{i,t}(x_{t})$   \n11: end for ", "page_idx": 30}, {"type": "text", "text": "Algorithm 8 Fed-SVT: Central server ", "text_level": 1, "page_idx": 30}, {"type": "text", "text": "1: Input: Number of Iterations $T$ , number of clients $m$ , optimal loss $L^{\\star}$ , switching budget $\\kappa$ ,   \nsampling parameter $\\eta>0$ , threshold parameter $L$ , failure probability $\\rho$ , privacy parameters $\\varepsilon$   \n2: Initialize: Set $k=0$ , $\\tau=0$ and $\\begin{array}{r}{\\hat{L}=L+\\mathrm{Lap}\\left(\\frac{4}{\\varepsilon}\\right)}\\end{array}$   \n3: while not reaching the time horizon $T$ do   \n4: if $t==n N$ for some integer $n\\geq1$ then   \n5: Receive from clients: tt\u2032\u2212=1t\u2212N li,t\u2032(x)   \n6: if $k<\\kappa$ then   \n7: Server defines a new query $\\begin{array}{r}{q_{t}=\\sum_{i=1}^{m}\\sum_{t^{\\prime}=\\tau}^{t-1}l_{i,t^{\\prime}}(x_{t^{\\prime}})}\\end{array}$   \n8: Let $\\begin{array}{r}{\\gamma_{t}=\\mathrm{Lap}\\left(\\frac{8}{\\varepsilon}\\right)}\\end{array}$   \n9: if $q_{t}+\\gamma_{t}\\leq\\hat{L}$ then   \n10: Communicate to clients: $x_{t}=x_{t-1}$   \n11: else   \n12: Sample $x_{t}$ with scores $\\begin{array}{r}{s_{t}(x)\\;=\\;\\operatorname*{max}\\left(\\sum_{i=1}^{m}\\sum_{t^{\\prime}=1}^{t-1}l_{i,t^{\\prime}}(x_{t^{\\prime}}),m L^{\\star}\\right)}\\end{array}$ for $x~\\in~[d]$ :   \n$\\mathbb{P}(x_{t}=x)\\propto e^{-\\eta s_{t}(x)/2}$   \n13: Communicate to clients: $x_{t}$   \n14: Set $k=k+1$ , $\\tau=t$ and $\\begin{array}{r}{\\hat{L}=L+\\mathrm{Lap}\\left(\\frac{4}{\\varepsilon}\\right)}\\end{array}$   \n15: end if   \n16: else   \n17: Server broadcasts $x_{t}=x_{t-1}$ to all the clients   \n18: end if   \n19: end if   \n20: end while ", "page_idx": 30}, {"type": "text", "text": "scales in $O\\left(m d T/N\\right)$ , and with probability at least $1-O(\\rho).$ , the pre-client regret is upper bounded b $\\begin{array}{r}{\\gamma\\,O\\left(\\frac{\\log^{2}(d)+\\log\\left(\\frac{T^{2}}{N^{2}\\rho}\\right)\\log\\left(\\frac{d}{\\rho}\\right)}{m\\varepsilon}+(N+L^{\\star})\\log\\left(\\frac{d}{\\rho}\\right)\\right).}\\end{array}$ ", "page_idx": 30}, {"type": "text", "text": "Moreover, setting $\\eta=\\varepsilon/\\sqrt{\\kappa\\log(1/\\delta)},$ , we have the algorithm is $(\\varepsilon,\\delta)$ -DP, the communication cost scales in $O\\left(m d T/N\\right)$ , and with probability at least $1-O(\\rho)$ , the pre-client regret is upper bounded $\\begin{array}{r}{b y\\ O\\left(\\frac{\\log^{\\frac{3}{2}}(d)\\sqrt{\\log(\\frac{1}{\\delta})}+\\log\\left(\\frac{T^{2}}{N^{2}\\rho}\\right)\\log\\left(\\frac{d}{\\rho}\\right)}{m\\varepsilon}+\\left(N+L^{\\star}\\right)\\log\\left(\\frac{d}{\\rho}\\right)\\right).}\\end{array}$ ", "page_idx": 30}, {"type": "text", "text": "Proof. DP guarantee: There are $\\kappa$ applications of exponential mechanism with privacy parameter $\\eta$ . Moreover, sparse vector technique is applied over each sample once, hence the $\\kappa$ applications of sparse-vector are $\\varepsilon/2$ -DP. Overall, the algorithm is $\\left(\\varepsilon/2+\\kappa\\eta\\right)$ -DP and $(\\varepsilon/2+\\sqrt{2\\kappa\\log(1/\\delta)}\\eta+$ $\\kappa\\eta(e^{\\eta}-1),\\delta)$ -DP (Lemma 14). Setting $\\eta=\\varepsilon/2\\kappa$ results in $\\varepsilon$ -DP and $\\eta=\\varepsilon/\\sqrt{\\kappa\\log(1/\\delta)}$ results in $(\\varepsilon,\\delta)$ -DP. ", "page_idx": 30}, {"type": "text", "text": "Communication cost: The number of communication between the central server and clients scales in $O(m T/N)$ . Moreover, within each communication, the number of scalars exchanged scales in $O(d)$ . Therefore the communication cost is $O(m d T/N)$ . ", "page_idx": 31}, {"type": "text", "text": "Regret upper bound: We define a potential at phase $n\\in[T/N]$ : ", "page_idx": 31}, {"type": "equation", "text": "$$\n\\phi_{n}=\\sum_{x\\in[d]}e^{-\\eta L_{n}(x)/2}\n$$", "text_format": "latex", "page_idx": 31}, {"type": "text", "text": "where $\\begin{array}{r}{L_{n}(x)\\ =\\ \\operatorname*{max}\\left(\\sum_{i=1}^{m}\\sum_{t^{\\prime}=1}^{n N-1}l_{i,t^{\\prime}}(x),m L^{\\star}\\right)}\\end{array}$ . Note that $\\phi_{0}\\ =\\ d e^{-\\eta m L^{\\star}/2}$ and $\\phi_{n}~\\geq$ $e^{-\\eta m L^{\\star}/2}$ for all $n\\,\\in\\,[T/N]$ since there is $x\\ \\in\\ [d]$ such that $\\begin{array}{r}{\\sum_{i=1}^{m}\\sum_{t=1}^{T}l_{i,t}(x)\\le.\\,m L^{\\star}.}\\end{array}$ . We split the iterates to $s=\\lceil\\log d\\rceil$ rounds $n_{0}N,n_{1}N,\\dots,n_{s}N$ where $n_{p}$ is the largest $n\\in[T/N]$ such that $\\phi_{n_{p}}\\geq\\phi_{0}/2^{p}$ . Let $Z_{p}$ be the number of switches in $[n_{p}N,(n_{p+\\dot{1}}-1)N]$ (number of times the exponential mechanism is used to pick $x_{t}$ ). Let $\\begin{array}{r}{Z=\\sum_{p=0}^{s-1}Z_{p}}\\end{array}$ be the total number of switches. Note that $\\begin{array}{r}{Z\\le3s+\\sum_{p=0}^{s-1}\\operatorname*{max}\\left(Z_{p}-3,0\\right)}\\end{array}$ and Lemma 12 implies max $(Z_{p}-3,0)$ is upper bounded by a geometric random variable with success probability $1/3$ . Therefore, using concentration of geometric random variables (Lemma 13), we get that ", "page_idx": 31}, {"type": "equation", "text": "$$\nP(Z\\geq3s+24\\log(1/\\rho))\\leq\\rho.\n$$", "text_format": "latex", "page_idx": 31}, {"type": "text", "text": "Since $K\\geq3s+24\\log(1/\\rho)$ , the algorithm does not reach the switching budget with probability $1-O(\\rho)$ . So the total number of switching scales as $O(\\log(d/\\rho))$ . Now we analyze the regret. Define $T_{1}N,\\dots T_{C}N$ as the switching time steps with $T_{C}N=T$ , where $C=O(\\log(d/\\rho))$ . Lemma 16 implies that with probability at least $1-\\rho$ , ", "page_idx": 31}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\displaystyle\\sum_{i=1}^{T}\\displaystyle\\sum_{i,\\,i=1}^{m}l_{i,\\,t}(x_{i,t})=\\displaystyle\\sum_{c=1}^{C}\\displaystyle\\sum_{t=T_{k-1}N+1=1}^{T-N}\\displaystyle\\sum_{t=i}^{m}l_{i,t}(x_{i,t})}\\\\ {\\displaystyle}&{=\\displaystyle\\sum_{c=1}^{C}\\left(\\displaystyle\\sum_{t=T_{k-1}N+1=i}^{T-N}\\displaystyle\\sum_{i=1}^{m}l_{i,t}(x_{i,t})+\\displaystyle\\sum_{t=T_{k}N-N+1}^{T_{k}N}\\displaystyle\\sum_{i=1}^{m}l_{i,T_{k}}(x_{i})\\right)}\\\\ {\\displaystyle}&{\\le\\displaystyle\\sum_{c=1}^{C}\\left(L+\\frac{8\\log(2T^{2}/(N^{2}\\rho))}{\\epsilon}+m N\\right)}\\\\ &{=\\displaystyle\\sum_{c=1}^{C}\\left(m L^{*}+\\frac{16\\log(2T^{2}/(N^{2}\\rho))}{\\epsilon}+4/\\eta+m N\\right)}\\\\ &{=O\\left(m L^{*}\\log(d/\\rho)+\\frac{\\log(T^{2}/(N^{2}\\rho))\\log(d/\\rho)}{\\epsilon}+\\frac{4\\log(d/\\rho)}{\\eta}+m N\\log(d/\\rho)\\right).}\\end{array}\n$$", "text_format": "latex", "page_idx": 31}, {"type": "text", "text": "Case 1: Setting $\\eta=\\varepsilon/2\\kappa$ in Equation (8), we have ", "page_idx": 31}, {"type": "equation", "text": "$$\n\\sum_{i=1}^{m}\\sum_{t=1}^{T}l_{i,t}(x_{i,t})\\le O\\left(m L^{\\star}\\log d+\\frac{\\log^{2}d+\\log(T^{2}/(N^{2}\\rho))\\log(d/\\rho)}{\\varepsilon}+m N\\log(d/\\rho)\\right).\n$$", "text_format": "latex", "page_idx": 31}, {"type": "text", "text": "Case 2: Setting $\\eta=\\varepsilon/\\sqrt{\\kappa\\log(1/\\delta)}$ in Equation (8), we have ", "page_idx": 31}, {"type": "equation", "text": "$$\n\\sum_{t=1}^{m}\\sum_{t=1}^{T}l_{i,t}(x_{i,t})\\le O\\left(m L^{\\star}\\log d+\\frac{\\log^{3/2}d\\sqrt{\\log(1/\\delta)}+\\log(T^{2}/(N^{2}\\rho))\\log(d/\\rho)}{\\varepsilon}+m N\\log(d/\\rho)\\right).\n$$", "text_format": "latex", "page_idx": 31}, {"type": "text", "text": "Lemma 12. Fix $0\\leq p\\leq s-1$ . Then for any $1\\le k\\le T/N$ , it holds that ", "page_idx": 31}, {"type": "equation", "text": "$$\nP\\left(Z_{p}=k+3\\right)\\leq(2/3)^{k+2}<(2/3)^{k-1}(1/3).\n$$", "text_format": "latex", "page_idx": 31}, {"type": "text", "text": "Proof. Let $n_{p}N\\,\\leq\\,n N\\,\\leq\\,n_{p+1}N$ be a time-step when a switch happens (exponential mechanism is used to pick $x_{t}$ ). Note that $\\phi_{n_{p+1}}~\\ge~\\phi_{n}/2$ . We prove that the probability that $x_{t}$ is switched between $n N$ and $n_{p+1}N$ is at most $2/3$ . To this end, note that if $x_{t}$ is switched before $n_{p+1}N$ then2 $\\begin{array}{r}{\\sum_{i=1}^{m}\\sum_{t^{\\prime}=n N}^{n_{p+1}N-1}l_{i,t^{\\prime}}(x_{t^{\\prime}})\\;\\ge\\;L-\\frac{8\\log(2T^{2}/(N^{2}\\rho))}{\\varepsilon}}\\end{array}$ , therefore $L_{n_{p+1}}(x)-L_{n}(x)\\geq$ $\\begin{array}{r}{L-\\frac{8\\log(2T^{2}/(N^{2}\\rho))}{\\varepsilon}\\geq4/\\eta}\\end{array}$ . Thus we have that ", "page_idx": 32}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{P\\left(x_{t}\\mathrm{~is~switched~before~}n_{p+1}N\\right)\\leq\\displaystyle\\sum_{x\\in[d]}P\\left(x_{t}=x\\right)1\\left\\{L_{n_{p+1}}(x)-L_{n}(x)\\geq4/\\eta\\right\\}}\\\\ &{=\\displaystyle\\sum_{x\\in[d]}\\frac{e^{-\\eta L_{n}(x)/2}}{\\phi_{n}}\\cdot1\\left\\{L_{n_{p+1}}(x)-L_{n}(x)\\geq4/\\eta\\right\\}}\\\\ &{\\leq\\displaystyle\\sum_{x\\in[d]}\\frac{e^{-\\eta L_{n}(x)/2}}{\\phi_{n}}\\cdot\\frac{1-e^{-\\eta\\left(L_{n_{p+1}}(x)-L_{n}(x)\\right)/2}}{1-e^{-2}}}\\\\ &{\\leq4/3\\left(1-\\phi_{n_{p+1}/\\phi_{n}}\\right)}\\\\ &{\\leq2/3.}\\end{array}\n$$", "text_format": "latex", "page_idx": 32}, {"type": "text", "text": "where the second inequality follows the fact that $\\begin{array}{r}{1\\{a\\ge b\\}\\le\\frac{1-e^{-\\eta a}}{1-e^{-\\eta b}}}\\end{array}$ for $a,b,\\eta\\ge0$ , and the last inequality since $\\phi_{n_{p+1}}/\\phi_{n}\\geq1/2$ . This argument shows that after the first switch inside the range $[n_{p}N,n_{p+1}N-1]$ , each additional switch happens with probability at most $2/3$ . So we have ", "page_idx": 32}, {"type": "equation", "text": "$$\nP\\left(Z_{p}=k+3\\right)\\leq(2/3)^{k+2}<(2/3)^{k-1}(1/3).\n$$", "text_format": "latex", "page_idx": 32}, {"type": "text", "text": "Lemma 13 (Asi et al. (2023), Lemma A.2). Let $W_{1},\\dots,W_{n}$ be i.i.d. geometric random variables with success probability $p$ . Let $\\begin{array}{r}{W=\\sum_{i=1}^{n}W_{i}}\\end{array}$ . Then for any $k\\geq n$ ", "page_idx": 32}, {"type": "equation", "text": "$$\n\\mathbb{P}(W>2k/p)\\le\\exp(-k/4).\n$$", "text_format": "latex", "page_idx": 32}, {"type": "text", "text": "F Experimental Supplementary ", "text_level": 1, "page_idx": 32}, {"type": "text", "text": "The simulations were conducted on a system with a 2.3 GHz Dual-Core Intel Core i5, Intel Iris Plus Graphics 640 with 1536 MB, and 16 GB of 2133 MHz LPDDR3 RAM. Approximately 10 minutes are required to reproduce the experiments. ", "page_idx": 32}, {"type": "text", "text": "We present our numerical results with different seeds in Figure 4 and Figure 5. ", "page_idx": 32}, {"type": "text", "text": "G Experiments on MovieLens-1M ", "text_level": 1, "page_idx": 32}, {"type": "text", "text": "We use the MovieLens-1M dataset (Harper and Konstan, 2015) to evaluate the performances of FedSVT, comparing it with the single-player model Sparse-Vector (Asi et al., 2023). We first compute the rating matrix of 6040 users to 18 movie genres (experts) $R=[r_{u,g}]\\in\\mathbb{R}^{6040\\times18}$ , and then calculate $L=[\\mathrm{max}(0,r_{u,g^{\\star}}-r_{u,g})]\\,\\in\\,\\mathbb{R}^{6040\\times18}$ where $\\begin{array}{r}{g^{\\star}=\\arg\\operatorname*{max}_{g}\\left(\\frac{1}{6040}\\sum_{u=1}^{6040}r_{u,g}\\right)}\\end{array}$ . We generate the sequence of loss functions $\\{l_{u}\\}_{u\\in[6040]}$ where $l_{u}=L_{u,i}$ :. In our experiments, we set $m=10$ , $T=604$ , $\\varepsilon=10$ , $\\delta=0$ and run 10 trials. In Fed-SVT, we experiment with communication intervals $N=1,30,50$ , where communication cost scales in $O(m d T/N)$ . The per-client cumulative regret as a function of $T$ is plotted in Figure 6. Our results show that Fed-SVT significantly outperforms Sparse-Vector with low communication costs (notably in the $N=50$ case). These results demonstrate the effectiveness of our algorithm in real-world applications. ", "page_idx": 32}, {"type": "image", "img_path": "T826pwZLci/tmp/c10db6e42491b6a23472eb41f19b4536b33470c8e836c3eb7d7474447b80398f.jpg", "img_caption": ["Figure 4: Comparison between Fed-DP-OPE-Stoch and Limited Updates with different random seeds. "], "img_footnote": [], "page_idx": 33}, {"type": "image", "img_path": "T826pwZLci/tmp/240738c1eb822fc5fb9a543d1c27e74224469af94c27de59f8233b1920fae18e.jpg", "img_caption": ["Figure 5: Comparison between Fed-SVT and Sparse-Vector with different random seeds. "], "img_footnote": [], "page_idx": 33}, {"type": "text", "text": "H Background on Differential Privacy ", "text_level": 1, "page_idx": 33}, {"type": "text", "text": "H.1 Advanced Composition ", "text_level": 1, "page_idx": 33}, {"type": "text", "text": "Lemma 14 (Advanced composition, Dwork et al. (2014)). If $A_{1},\\ldots,A_{k}$ are randomized algorithms that each is $(\\varepsilon,\\delta)$ -DP, then their composition $(A_{1}(S),\\ldots,A_{k}(S))$ is $(\\sqrt{2k\\log(1/\\delta^{\\prime})}\\varepsilon+k\\varepsilon(e^{\\varepsilon}-$ $1),\\delta^{\\prime}+k\\delta){-}\\dot{D}P.$ . ", "page_idx": 33}, {"type": "text", "text": "H.2 Report Noisy Max ", "text_level": 1, "page_idx": 33}, {"type": "text", "text": "The \"Report Noisy Max\" mechanism can be used to privately identify the counting query among $m$ queries with the highest value. This mechanism achieves this by adding Laplace noise independently generated from $\\mathrm{Lap}(\\Delta/\\varepsilon)$ to each count and subsequently determining the index corresponding to the largest noisy count (we ignore the possibility of a tie), where $\\Delta$ is the sensitivity of the queries. Report noisy max gives us the following guarantee. ", "page_idx": 33}, {"type": "image", "img_path": "T826pwZLci/tmp/d113c31edf47f9a52f763a15e025911049fe02ade3691edb64b78cae90214fc7.jpg", "img_caption": ["Figure 6: Regret performance with MovieLens dataset. Shaded area indicates the standard deviation. "], "img_footnote": [], "page_idx": 34}, {"type": "text", "text": "Lemma 15 (Dwork et al. (2014), Claim 3.9). The Report Noisy Max algorithm is $\\varepsilon$ -differentially private. ", "page_idx": 34}, {"type": "text", "text": "H.3 Sparse Vector Technique ", "text_level": 1, "page_idx": 34}, {"type": "text", "text": "We recall the sparse-vector technique here. Given an input $S=(z_{1},\\ldots,z_{n})\\in{\\mathcal{Z}}^{n}$ , the algorithm takes a stream of queries $q_{1},q_{2},\\ldots,q_{T}$ in an online manner. We assume that each $q_{i}$ is 1-sensitive, i.e., $|q_{i}(S)-q_{i}\\left(S^{\\prime}\\right)|\\leq1$ for neighboring datasets $S,S^{\\prime}\\in{\\mathcal{Z}}^{n}$ that differ in a single element. We have the following guarantee. ", "page_idx": 34}, {"type": "text", "text": "Lemma 16 (Dwork et al. (2014), Theorem 3.24). Let $S=(z_{1},\\ldots,z_{n})\\in{\\mathcal{Z}}^{n}$ . For a threshold $L$ and $\\rho>0$ , there is an $\\varepsilon$ -DP algorithm (AboveThreshold) that halts at time $k\\in[T+1]$ such that for $\\begin{array}{r}{\\alpha=\\frac{8(\\log T+\\log(2/\\rho))}{c}}\\end{array}$ with probability at least $1-\\rho,$ , we have $q_{i}(S)\\leq L+\\alpha$ for all $t<k$ , and $q_{k}(S)\\geq L-\\alpha$ or $k=T+1$ . ", "page_idx": 34}, {"type": "text", "text": "I Broader Impacts ", "text_level": 1, "page_idx": 34}, {"type": "text", "text": "This work improves online learning and decision-making through collaboration among multiple users without exposing personal information, which helps balance the beneftis of big data with the need to protect individual privacy, promoting ethical data usage and fostering societal trust in an increasingly data-driven world. ", "page_idx": 34}, {"type": "text", "text": "NeurIPS Paper Checklist ", "text_level": 1, "page_idx": 35}, {"type": "text", "text": "1. Claims ", "text_level": 1, "page_idx": 35}, {"type": "text", "text": "Question: Do the main claims made in the abstract and introduction accurately reflect the paper\u2019s contributions and scope? ", "page_idx": 35}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 35}, {"type": "text", "text": "Justification: See the abstract and introduction. ", "page_idx": 35}, {"type": "text", "text": "Guidelines: ", "page_idx": 35}, {"type": "text", "text": "\u2022 The answer NA means that the abstract and introduction do not include the claims made in the paper.   \n\u2022 The abstract and/or introduction should clearly state the claims made, including the contributions made in the paper and important assumptions and limitations. A No or NA answer to this question will not be perceived well by the reviewers.   \n\u2022 The claims made should match theoretical and experimental results, and reflect how much the results can be expected to generalize to other settings.   \n\u2022 It is fine to include aspirational goals as motivation as long as it is clear that these goals are not attained by the paper. ", "page_idx": 35}, {"type": "text", "text": "2. Limitations ", "text_level": 1, "page_idx": 35}, {"type": "text", "text": "Question: Does the paper discuss the limitations of the work performed by the authors? ", "page_idx": 35}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 35}, {"type": "text", "text": "Justification: See Section 7. ", "page_idx": 35}, {"type": "text", "text": "Guidelines: ", "page_idx": 35}, {"type": "text", "text": "\u2022 The answer NA means that the paper has no limitation while the answer No means that the paper has limitations, but those are not discussed in the paper.   \n\u2022 The authors are encouraged to create a separate \"Limitations\" section in their paper.   \n\u2022 The paper should point out any strong assumptions and how robust the results are to violations of these assumptions (e.g., independence assumptions, noiseless settings, model well-specification, asymptotic approximations only holding locally). The authors should reflect on how these assumptions might be violated in practice and what the implications would be.   \n\u2022 The authors should reflect on the scope of the claims made, e.g., if the approach was only tested on a few datasets or with a few runs. In general, empirical results often depend on implicit assumptions, which should be articulated.   \n\u2022 The authors should reflect on the factors that influence the performance of the approach. For example, a facial recognition algorithm may perform poorly when image resolution is low or images are taken in low lighting. Or a speech-to-text system might not be used reliably to provide closed captions for online lectures because it fails to handle technical jargon.   \n\u2022 The authors should discuss the computational efficiency of the proposed algorithms and how they scale with dataset size.   \n\u2022 If applicable, the authors should discuss possible limitations of their approach to address problems of privacy and fairness.   \n\u2022 While the authors might fear that complete honesty about limitations might be used by reviewers as grounds for rejection, a worse outcome might be that reviewers discover limitations that aren\u2019t acknowledged in the paper. The authors should use their best judgment and recognize that individual actions in favor of transparency play an important role in developing norms that preserve the integrity of the community. Reviewers will be specifically instructed to not penalize honesty concerning limitations. ", "page_idx": 35}, {"type": "text", "text": "3. Theory Assumptions and Proofs ", "text_level": 1, "page_idx": 35}, {"type": "text", "text": "Question: For each theoretical result, does the paper provide the full set of assumptions and a complete (and correct) proof? ", "page_idx": 35}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 35}, {"type": "text", "text": "Justification: See Appendix. ", "page_idx": 36}, {"type": "text", "text": "Guidelines: ", "page_idx": 36}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include theoretical results.   \n\u2022 All the theorems, formulas, and proofs in the paper should be numbered and crossreferenced.   \n\u2022 All assumptions should be clearly stated or referenced in the statement of any theorems.   \n\u2022 The proofs can either appear in the main paper or the supplemental material, but if they appear in the supplemental material, the authors are encouraged to provide a short proof sketch to provide intuition.   \n\u2022 Inversely, any informal proof provided in the core of the paper should be complemented by formal proofs provided in appendix or supplemental material.   \n\u2022 Theorems and Lemmas that the proof relies upon should be properly referenced. ", "page_idx": 36}, {"type": "text", "text": "4. Experimental Result Reproducibility ", "text_level": 1, "page_idx": 36}, {"type": "text", "text": "Question: Does the paper fully disclose all the information needed to reproduce the main experimental results of the paper to the extent that it affects the main claims and/or conclusions of the paper (regardless of whether the code and data are provided or not)? ", "page_idx": 36}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 36}, {"type": "text", "text": "Justification: See Sections 3, 4 and 5. ", "page_idx": 36}, {"type": "text", "text": "Guidelines: ", "page_idx": 36}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 If the paper includes experiments, a No answer to this question will not be perceived well by the reviewers: Making the paper reproducible is important, regardless of whether the code and data are provided or not.   \n\u2022 If the contribution is a dataset and/or model, the authors should describe the steps taken to make their results reproducible or verifiable.   \n\u2022 Depending on the contribution, reproducibility can be accomplished in various ways. For example, if the contribution is a novel architecture, describing the architecture fully might suffice, or if the contribution is a specific model and empirical evaluation, it may be necessary to either make it possible for others to replicate the model with the same dataset, or provide access to the model. In general. releasing code and data is often one good way to accomplish this, but reproducibility can also be provided via detailed instructions for how to replicate the results, access to a hosted model (e.g., in the case of a large language model), releasing of a model checkpoint, or other means that are appropriate to the research performed.   \n\u2022 While NeurIPS does not require releasing code, the conference does require all submissions to provide some reasonable avenue for reproducibility, which may depend on the nature of the contribution. For example (a) If the contribution is primarily a new algorithm, the paper should make it clear how to reproduce that algorithm. (b) If the contribution is primarily a new model architecture, the paper should describe the architecture clearly and fully. (c) If the contribution is a new model (e.g., a large language model), then there should either be a way to access this model for reproducing the results or a way to reproduce the model (e.g., with an open-source dataset or instructions for how to construct the dataset). (d) We recognize that reproducibility may be tricky in some cases, in which case authors are welcome to describe the particular way they provide for reproducibility. In the case of closed-source models, it may be that access to the model is limited in some way (e.g., to registered users), but it should be possible for other researchers to have some path to reproducing or verifying the results. ", "page_idx": 36}, {"type": "text", "text": "5. Open access to data and code ", "text_level": 1, "page_idx": 36}, {"type": "text", "text": "Question: Does the paper provide open access to the data and code, with sufficient instructions to faithfully reproduce the main experimental results, as described in supplemental material? ", "page_idx": 36}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 37}, {"type": "text", "text": "Justification: See supplemental material. Guidelines: ", "page_idx": 37}, {"type": "text", "text": "\u2022 The answer NA means that paper does not include experiments requiring code.   \n\u2022 Please see the NeurIPS code and data submission guidelines (https://nips.cc/ public/guides/CodeSubmissionPolicy) for more details.   \n\u2022 While we encourage the release of code and data, we understand that this might not be possible, so \u201cNo\u201d is an acceptable answer. Papers cannot be rejected simply for not including code, unless this is central to the contribution (e.g., for a new open-source benchmark).   \n\u2022 The instructions should contain the exact command and environment needed to run to reproduce the results. See the NeurIPS code and data submission guidelines (https: //nips.cc/public/guides/CodeSubmissionPolicy) for more details.   \n\u2022 The authors should provide instructions on data access and preparation, including how to access the raw data, preprocessed data, intermediate data, and generated data, etc.   \n\u2022 The authors should provide scripts to reproduce all experimental results for the new proposed method and baselines. If only a subset of experiments are reproducible, they should state which ones are omitted from the script and why.   \n\u2022 At submission time, to preserve anonymity, the authors should release anonymized versions (if applicable).   \n\u2022 Providing as much information as possible in supplemental material (appended to the paper) is recommended, but including URLs to data and code is permitted. ", "page_idx": 37}, {"type": "text", "text": "6. Experimental Setting/Details ", "text_level": 1, "page_idx": 37}, {"type": "text", "text": "Question: Does the paper specify all the training and test details (e.g., data splits, hyperparameters, how they were chosen, type of optimizer, etc.) necessary to understand the results? ", "page_idx": 37}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 37}, {"type": "text", "text": "Justification: See supplemental material. Guidelines: ", "page_idx": 37}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments. \u2022 The experimental setting should be presented in the core of the paper to a level of detail that is necessary to appreciate the results and make sense of them. \u2022 The full details can be provided either with the code, in appendix, or as supplemental material. ", "page_idx": 37}, {"type": "text", "text": "7. Experiment Statistical Significance ", "text_level": 1, "page_idx": 37}, {"type": "text", "text": "Question: Does the paper report error bars suitably and correctly defined or other appropriate information about the statistical significance of the experiments? ", "page_idx": 37}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 37}, {"type": "text", "text": "Justification: See Appendix E. Guidelines: ", "page_idx": 37}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 The authors should answer \"Yes\" if the results are accompanied by error bars, confidence intervals, or statistical significance tests, at least for the experiments that support the main claims of the paper.   \n\u2022 The factors of variability that the error bars are capturing should be clearly stated (for example, train/test split, initialization, random drawing of some parameter, or overall run with given experimental conditions).   \n\u2022 The method for calculating the error bars should be explained (closed form formula, call to a library function, bootstrap, etc.)   \n\u2022 The assumptions made should be given (e.g., Normally distributed errors).   \n\u2022 It should be clear whether the error bar is the standard deviation or the standard error of the mean.   \n\u2022 It is OK to report 1-sigma error bars, but one should state it. The authors should preferably report a 2-sigma error bar than state that they have a $96\\%$ CI, if the hypothesis of Normality of errors is not verified.   \n\u2022 For asymmetric distributions, the authors should be careful not to show in tables or figures symmetric error bars that would yield results that are out of range (e.g. negative error rates).   \n\u2022 If error bars are reported in tables or plots, The authors should explain in the text how they were calculated and reference the corresponding figures or tables in the text. ", "page_idx": 37}, {"type": "text", "text": "", "page_idx": 38}, {"type": "text", "text": "8. Experiments Compute Resources ", "text_level": 1, "page_idx": 38}, {"type": "text", "text": "Question: For each experiment, does the paper provide sufficient information on the computer resources (type of compute workers, memory, time of execution) needed to reproduce the experiments? ", "page_idx": 38}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 38}, {"type": "text", "text": "Justification: See Appendix E. Guidelines: ", "page_idx": 38}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 The paper should indicate the type of compute workers CPU or GPU, internal cluster, or cloud provider, including relevant memory and storage.   \n\u2022 The paper should provide the amount of compute required for each of the individual experimental runs as well as estimate the total compute.   \n\u2022 The paper should disclose whether the full research project required more compute than the experiments reported in the paper (e.g., preliminary or failed experiments that didn\u2019t make it into the paper). ", "page_idx": 38}, {"type": "text", "text": "9. Code Of Ethics ", "text_level": 1, "page_idx": 38}, {"type": "text", "text": "Question: Does the research conducted in the paper conform, in every respect, with the NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines? ", "page_idx": 38}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 38}, {"type": "text", "text": "Justification: We make sure to follow the NeurIPS Code of Ethics. Guidelines: ", "page_idx": 38}, {"type": "text", "text": "\u2022 The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics.   \n\u2022 If the authors answer No, they should explain the special circumstances that require a deviation from the Code of Ethics.   \n\u2022 The authors should make sure to preserve anonymity (e.g., if there is a special consideration due to laws or regulations in their jurisdiction). ", "page_idx": 38}, {"type": "text", "text": "10. Broader Impacts ", "text_level": 1, "page_idx": 38}, {"type": "text", "text": "Question: Does the paper discuss both potential positive societal impacts and negative societal impacts of the work performed? ", "page_idx": 38}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 38}, {"type": "text", "text": "Justification: See Appendix G. ", "page_idx": 38}, {"type": "text", "text": "Guidelines: ", "page_idx": 38}, {"type": "text", "text": "\u2022 The answer NA means that there is no societal impact of the work performed.   \n\u2022 If the authors answer NA or No, they should explain why their work has no societal impact or why the paper does not address societal impact.   \n\u2022 Examples of negative societal impacts include potential malicious or unintended uses (e.g., disinformation, generating fake profiles, surveillance), fairness considerations (e.g., deployment of technologies that could make decisions that unfairly impact specific groups), privacy considerations, and security considerations.   \n\u2022 The conference expects that many papers will be foundational research and not tied to particular applications, let alone deployments. However, if there is a direct path to any negative applications, the authors should point it out. For example, it is legitimate to point out that an improvement in the quality of generative models could be used to ", "page_idx": 38}, {"type": "text", "text": "generate deepfakes for disinformation. On the other hand, it is not needed to point out that a generic algorithm for optimizing neural networks could enable people to train models that generate Deepfakes faster. ", "page_idx": 39}, {"type": "text", "text": "\u2022 The authors should consider possible harms that could arise when the technology is being used as intended and functioning correctly, harms that could arise when the technology is being used as intended but gives incorrect results, and harms following from (intentional or unintentional) misuse of the technology. \u2022 If there are negative societal impacts, the authors could also discuss possible mitigation strategies (e.g., gated release of models, providing defenses in addition to attacks, mechanisms for monitoring misuse, mechanisms to monitor how a system learns from feedback over time, improving the efficiency and accessibility of ML). ", "page_idx": 39}, {"type": "text", "text": "11. Safeguards ", "text_level": 1, "page_idx": 39}, {"type": "text", "text": "Question: Does the paper describe safeguards that have been put in place for responsible release of data or models that have a high risk for misuse (e.g., pretrained language models, image generators, or scraped datasets)? ", "page_idx": 39}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 39}, {"type": "text", "text": "Justification: No such risks. Guidelines: ", "page_idx": 39}, {"type": "text", "text": "\u2022 The answer NA means that the paper poses no such risks.   \n\u2022 Released models that have a high risk for misuse or dual-use should be released with necessary safeguards to allow for controlled use of the model, for example by requiring that users adhere to usage guidelines or restrictions to access the model or implementing safety filters.   \n\u2022 Datasets that have been scraped from the Internet could pose safety risks. The authors should describe how they avoided releasing unsafe images.   \n\u2022 We recognize that providing effective safeguards is challenging, and many papers do not require this, but we encourage authors to take this into account and make a best faith effort. ", "page_idx": 39}, {"type": "text", "text": "12. Licenses for existing assets ", "text_level": 1, "page_idx": 39}, {"type": "text", "text": "Question: Are the creators or original owners of assets (e.g., code, data, models), used in the paper, properly credited and are the license and terms of use explicitly mentioned and properly respected? ", "page_idx": 39}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 39}, {"type": "text", "text": "Justification: We do not use existing assets. ", "page_idx": 39}, {"type": "text", "text": "Guidelines: ", "page_idx": 39}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not use existing assets.   \n\u2022 The authors should cite the original paper that produced the code package or dataset.   \n\u2022 The authors should state which version of the asset is used and, if possible, include a URL.   \n\u2022 The name of the license (e.g., CC-BY 4.0) should be included for each asset.   \n\u2022 For scraped data from a particular source (e.g., website), the copyright and terms of service of that source should be provided.   \n\u2022 If assets are released, the license, copyright information, and terms of use in the package should be provided. For popular datasets, paperswithcode.com/datasets has curated licenses for some datasets. Their licensing guide can help determine the license of a dataset.   \n\u2022 For existing datasets that are re-packaged, both the original license and the license of the derived asset (if it has changed) should be provided.   \n\u2022 If this information is not available online, the authors are encouraged to reach out to the asset\u2019s creators. ", "page_idx": 39}, {"type": "text", "text": "13. New Assets ", "text_level": 1, "page_idx": 39}, {"type": "text", "text": "Question: Are new assets introduced in the paper well documented and is the documentation provided alongside the assets? ", "page_idx": 39}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 40}, {"type": "text", "text": "Justification: No new assets. ", "page_idx": 40}, {"type": "text", "text": "Guidelines: ", "page_idx": 40}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not release new assets.   \n\u2022 Researchers should communicate the details of the dataset/code/model as part of their submissions via structured templates. This includes details about training, license, limitations, etc.   \n\u2022 The paper should discuss whether and how consent was obtained from people whose asset is used.   \n\u2022 At submission time, remember to anonymize your assets (if applicable). You can either create an anonymized URL or include an anonymized zip file. ", "page_idx": 40}, {"type": "text", "text": "14. Crowdsourcing and Research with Human Subjects ", "text_level": 1, "page_idx": 40}, {"type": "text", "text": "Question: For crowdsourcing experiments and research with human subjects, does the paper include the full text of instructions given to participants and screenshots, if applicable, as well as details about compensation (if any)? ", "page_idx": 40}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 40}, {"type": "text", "text": "Justification: No crowdsourcing or research with human subjects. ", "page_idx": 40}, {"type": "text", "text": "Guidelines: ", "page_idx": 40}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u2022 Including this information in the supplemental material is fine, but if the main contribution of the paper involves human subjects, then as much detail as possible should be included in the main paper.   \n\u2022 According to the NeurIPS Code of Ethics, workers involved in data collection, curation, or other labor should be paid at least the minimum wage in the country of the data collector. ", "page_idx": 40}, {"type": "text", "text": "15. Institutional Review Board (IRB) Approvals or Equivalent for Research with Human Subjects ", "text_level": 1, "page_idx": 40}, {"type": "text", "text": "Question: Does the paper describe potential risks incurred by study participants, whether such risks were disclosed to the subjects, and whether Institutional Review Board (IRB) approvals (or an equivalent approval/review based on the requirements of your country or institution) were obtained? ", "page_idx": 40}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 40}, {"type": "text", "text": "Justification: No crowdsourcing or research with human subjects. ", "page_idx": 40}, {"type": "text", "text": "Guidelines: ", "page_idx": 40}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u2022 Depending on the country in which research is conducted, IRB approval (or equivalent) may be required for any human subjects research. If you obtained IRB approval, you should clearly state this in the paper.   \n\u2022 We recognize that the procedures for this may vary significantly between institutions and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the guidelines for their institution.   \n\u2022 For initial submissions, do not include any information that would break anonymity (if applicable), such as the institution conducting the review. ", "page_idx": 40}]