[{"figure_path": "piOzFx9whU/tables/tables_6_1.jpg", "caption": "Table 1: The table presents the results of our numerical experiment, comparing various trainers based on their input sets in terms of accuracy (Acc, higher values are better), unfairness areas (U.05, lower values are better), unfairness areas (U.01, lower values are better), Counterfactual Unfair area (CF, lower values are better), the non-robust percentage concerning adversarial perturbation with radii 0.05 (R.05, lower values are better), and the non-robust percentage concerning adversarial perturbation with radii 0.01 (R.01, lower values are better). The top-performing techniques for each trainer, dataset, and metric are highlighted in bold. The findings demonstrate that CDRO excels in reducing unfair areas. The average standard deviation for CDRO is .029, while for the other methods, it is .031.", "description": "This table summarizes the results of a numerical experiment comparing four different training methods (CDRO, ERM, ROSS, AL) across three datasets (Adult, COMPAS, LIN) and two values of delta (0.05 and 0.01).  The metrics evaluated include accuracy, unfair area (at two delta values), counterfactual unfairness, and non-robustness (against adversarial attacks at two delta values).  Bold values highlight the best performing method for each dataset/metric combination.  CDRO shows the lowest unfairness area with only a minor decrease in accuracy, indicating that it balances fairness and accuracy well.", "section": "Numerical Studies"}, {"figure_path": "piOzFx9whU/tables/tables_7_1.jpg", "caption": "Table 1: The table presents the results of our numerical experiment, comparing various trainers based on their input sets in terms of accuracy (Acc, higher values are better), unfairness areas (U.05, lower values are better), unfairness areas (U.01, lower values are better), Counterfactual Unfair area (CF, lower values are better), the non-robust percentage concerning adversarial perturbation with radii 0.05 (R.05, lower values are better), and the non-robust percentage concerning adversarial perturbation with radii 0.01 (R.01, lower values are better). The top-performing techniques for each trainer, dataset, and metric are highlighted in bold. The findings demonstrate that CDRO excels in reducing unfair areas. The average standard deviation for CDRO is .029, while for the other methods, it is .031.", "description": "This table summarizes the results of numerical experiments comparing four different training methods (AL, CDRO, ERM, ROSS) across three datasets (Adult, COMPAS, LIN) using six metrics (accuracy, unfairness area at \u03b4=0.05, unfairness area at \u03b4=0.01, counterfactual unfairness, non-robustness area at \u03b4=0.05, non-robustness area at \u03b4=0.01).  The top performer for each metric and dataset is highlighted.  The results show that CDRO generally outperforms other methods in terms of reducing unfairness.", "section": "Numerical Studies"}, {"figure_path": "piOzFx9whU/tables/tables_34_1.jpg", "caption": "Table 1: The table presents the results of our numerical experiment, comparing various trainers based on their input sets in terms of accuracy (Acc, higher values are better), unfairness areas (U0.5, lower values are better), unfairness areas (U0.1, lower values are better), Counterfactual Unfair area (CF, lower values are better), the non-robust percentage concerning adversarial perturbation with radii 0.05 (R.05, lower values are better), and the non-robust percentage concerning adversarial perturbation with radii 0.01 (R.01, lower values are better). The top-performing techniques for each trainer, dataset, and metric are highlighted in bold. The findings demonstrate that CDRO excels in reducing unfair areas. The average standard deviation for CDRO is .029, while for the other methods, it is .031.", "description": "This table presents the results of a numerical experiment comparing four different training methods (AL, CDRO, ERM, ROSS) across three datasets (Adult, COMPAS, LIN).  The metrics evaluated are accuracy, unfairness areas at two different radii (0.05 and 0.01), counterfactual unfairness, and non-robustness to adversarial perturbations at the same radii.  The results show the performance of each method in terms of balancing accuracy and fairness.", "section": "Numerical Studies"}]