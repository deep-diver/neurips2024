[{"type": "text", "text": "A Simple and Optimal Approach for Universal Online Learning with Gradient Variations ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Yu-Hu Yan, Peng Zhao, Zhi-Hua Zhou ", "page_idx": 0}, {"type": "text", "text": "National Key Laboratory for Novel Software Technology, Nanjing University, China School of Artificial Intelligence, Nanjing University, China {yanyh, zhaop, zhouzh}@lamda.nju.edu.cn ", "page_idx": 0}, {"type": "text", "text": "Abstract ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "We investigate the problem of universal online learning with gradient-variation regret. Universal online learning aims to achieve regret guarantees without the prior knowledge of the curvature of the online functions. Moreover, we study the problem-dependent gradient-variation regret as it plays a crucial role in bridging stochastic and adversarial optimization as well as game theory. In this work, we design a universal approach with the optimal gradient-variation regret simultaneously for strongly convex, exp-concave, and convex functions, thus addressing an open problem highlighted by Yan et al. [2023]. Our approach is simple since it is algorithmically efficient-to-implement with a two-layer online ensemble structure and only 1 gradient query per round, and theoretically easy-to-analyze with a novel and alternative analysis to the gradient-variation regret. Concretely, previous works on gradient variations require controlling the algorithmic stability, which is challenging and leads to sub-optimal regret and less efficient algorithm design. Our analysis overcomes this issue by using a Bregman divergence negative term from linearization and a useful smoothness property. ", "page_idx": 0}, {"type": "text", "text": "1 Introduction ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Online convex optimization (OCO) models a sequential $T$ -round game between an online learner and the environments [Hazan, 2016, Orabona, 2019]. In each round $t\\in[T]$ , the learner selects a decision $\\mathbf{x}_{t}$ from a convex compact set $\\mathcal{X}\\subseteq\\mathbb{R}^{d}$ . Simultaneously, the environments adversarially choose a convex loss function $f_{t}\\,:\\,\\mathcal{X}\\,\\mapsto\\,\\mathbb{R}$ . Subsequently, the learner suffers a loss of $f_{t}(\\mathbf{x}_{t}\\bar{)}$ , receives feedback on the function $f_{t}(\\cdot)$ , and updates her decision to $\\mathbf{x}_{t+1}$ . In OCO, the learner aims to optimize the game-theoretical performance measure known as regret [Cesa-Bianchi and Lugosi, 2006], which is formally defined as ", "page_idx": 0}, {"type": "equation", "text": "$$\n\\operatorname{REG}_{T}\\triangleq\\sum_{t=1}^{T}f_{t}(\\mathbf{x}_{t})-\\operatorname*{min}_{\\mathbf{x}\\in\\mathcal{X}}\\sum_{t=1}^{T}f_{t}(\\mathbf{x}).\n$$", "text_format": "latex", "page_idx": 0}, {"type": "text", "text": "It represents the learner\u2019s excess cumulative loss compared with the best fixed comparator in hindsight. ", "page_idx": 0}, {"type": "text", "text": "In OCO, function curvatures play an important role in the best attainable regret bounds. Traditional studies examine three types of curvatures: convexity, exp-concavity, \u221aand strong convexity. Specifically, for convex functions, online gradient descent (OGD) achieves $\\mathcal{O}(\\sqrt{T})$ regret [Zinkevich, 2003]; for $\\alpha$ -exp-concave functions, online Newton step assuming $\\alpha$ is known obtains $\\mathcal{O}(\\frac{d}{\\alpha}\\log T)$ regret [Hazan et al., 2007]; and for $\\lambda$ -strongly convex functions, OGD with known $\\lambda$ attains $\\textstyle{\\mathcal{O}}({\\frac{1}{\\lambda}}\\log T)$ [Hazan et al., 2007]. These results are shown to be minimax optimal [Ordentlich and Cover, 1998, Abernethy et al., 2008]. Recent studies further strengthen them by introducing two levels of adaptivity. ", "page_idx": 0}, {"type": "text", "text": "Table 1: Comparison with existing results. The second column shows the regret bounds for strongly convex, exp-concave, and convex functions, following the $O(\\cdot)$ -notation. Note that we only list universal guarantees related to the gradient variation $V_{T}$ or the time horizon $T$ . Each gradient-variation bound can directly apply a corresponding small-loss regret in analysis, which is formally stated in Theorem 2 and omitted here for clarity. We treat the $\\log\\log T$ factor as a constant and omit it. $^{\\ast\\ast}\\#$ Gradient\u201d is the number of gradient queries in each round, where \u201c1\u201d represents exactly one gradient query. And \u201c# Base\u201d stands for the number of base learners. ", "page_idx": 1}, {"type": "table", "img_path": "yO5DVyCHZR/tmp/bccfbf31e667aace576e174d163842327f391d96ed4dcbeaecffce6b37d2603c.jpg", "table_caption": [], "table_footnote": [], "page_idx": 1}, {"type": "text", "text": "High-level Adaptivity to Unknown Curvatures. Traditional studies require function curvature information in advance to select suitable algorithms for provable bounds. However, the information could be hard to access in real-world applications. To this end, a line of research aims to design a single universal algorithm that does not require the curvature information while achieving the same regret guarantees as if knowing it, achieving the adaptivity to unknown curvatures. The pioneering work of MetaGrad [van Erven and Koolen, 2016] proposed c\u221aarefully designed surrogate functions and achieved $\\mathcal{O}(\\frac{d}{\\alpha}\\log T)$ for $\\alpha$ -exp-concave functions and $\\mathcal{O}(\\sqrt{T})$ for convex functions. Subsequently, Wang et al. [2019] obtained the optimal $\\textstyle{\\mathcal{O}}({\\frac{1}{\\lambda}}\\log T)$ regret for $\\lambda$ -strongly convex functions, while maintaining the optimal rates in the other cases. Another remarkable progress of Zhang et al. [2022a] proposed a flexible framework with simplified analyses and further enhanced the minimax results using smoothness. We provide a detailed introduction of this work in Section 2.2. ", "page_idx": 1}, {"type": "text", "text": "Low-level Adaptivity to Gradient Variation. Although the regret guarantees based on the time horizon $T$ are optimal in the minimax sense, in this work we are interested in achieving the gradientvariation regret [Chiang et al., 2012, Yang et al., 2014], which replaces the dependence of the time horizon $T$ by the gradient variation quantity defined in the following: ", "page_idx": 1}, {"type": "equation", "text": "$$\nV_{T}\\triangleq\\sum_{t=2}^{T}\\operatorname*{sup}_{\\mathbf{x}\\in\\mathcal{X}}\\|\\nabla f_{t}(\\mathbf{x})-\\nabla f_{t-1}(\\mathbf{x})\\|^{2}.\n$$", "text_format": "latex", "page_idx": 1}, {"type": "text", "text": "Under smoothness assumptions, the minimax regret can be improved to $O\\big(\\frac{1}{\\lambda}\\log V_{T}\\big)$ , $\\mathcal{O}(\\frac{d}{\\alpha}\\log V_{T})$ , and $O(\\sqrt{V_{T}})$ for $\\lambda$ -strongly convex, $\\alpha$ -exp-concave, and convex functions, respectively. In this work, continuing previous gradient-variation online learning results [Zhao et al., 2020, 2024, Zhang et al., 2022b, Chen et al., 2023], we focus on the gradient-variation regret for the following reasons: (i) gradient-variation bounds safeguard the minimax guarantees. Besides, as demonstrated by Zhao et al. [2024], the gradient-variation regret is more fundamental than another well-known problemdependent quantity known as the small loss $\\begin{array}{r}{F_{T}\\triangleq\\operatorname*{min}_{\\mathbf{x}\\in\\mathcal{X}}\\sum_{t\\leq T}f_{t}(\\mathbf{x})}\\end{array}$ [Srebro et al., 2010, Orabona et al., 2012] since gradient-variation regret can imply small-loss bounds directly in analysis; $(i i)$ the gradient variation plays a crucial role in bridging adversarial and stochastic optimization [Sachs et al., 2022]; and $(i i i)$ the gradient-variation regret can be used to achieve fast rates in multi-player games [Syrgkanis et al., 2015, Zhang et al., 2022b]. More detailed explanations of the importance of achieving such adaptivity are provided at the end of this section. ", "page_idx": 1}, {"type": "text", "text": "Motivated by the aforementioned two levels of adaptivity, we focus on the problem of achieving universal gradient-variation regret, i.e., designing a single universal approach with gradient-variation regret across different curvature types without the prior knowledge of the\u221am. For this problem, Zhang et al. [2022a] achieved partial results of $O\\big(\\frac{1}{\\lambda}\\log V_{T}\\big)$ , $\\mathcal{O}(\\frac{d}{\\alpha}\\log V_{T})$ , $\\mathcal{O}(\\sqrt{T})$ for $\\lambda$ -strongly convex, $\\alpha$ -exp-concave, and convex functions, respectively. Subsequently, Yan et al. [2023] proposed a carefully designed t\u221ahree-layer online ensemble approach to stabilize the algorithm and improved the convex result to $\\mathcal{O}(\\sqrt{V_{T}\\log V_{T}})$ , achieving the first universal gradient-variation guarantee. Although optimal for \u221astrongly convex and exp-concave functions, their results still exhibit a gap with the optimal $O(\\sqrt{V_{T}})$ regret in the convex case. Here \u201coptimal\u201d refers to matching the best known results with curvature information since proble\u221am-dependent lower bound cannot be easily obtained. The only lower bound we are aware of is $\\Omega(\\sqrt{V_{T}})$ for convex functions [Yang et al., 2014, Remark 5]. ", "page_idx": 1}, {"type": "text", "text": "To handle the uncertainty, online ensemble is commonly employed and proven effective in enhancing the robustness [Zhou, 2012, Zhao, 2021], such as adaptive regret minimization [Hazan and Seshadhri, 2007, Daniely et al., 2015, Zhang et al., 2019], dynamic regret minimization [Zhang et al., 2018, Zhao et al., 2020, 2024], and universal online learning [van Erven and Koolen, 2016, Zhang et al., 2022a, Yan et al., 2023]. Concretely, an online ensemble algorithm contains multiple base learners for exploring the environments and a meta learner for ensemble. In universal online learning, base learners make guesses on the curvature information, and the meta learner tracks the best base learner (i.e., with the most accurate guess) on the fly. ", "page_idx": 2}, {"type": "text", "text": "Due to the deployment of the online ensemble framework, computational efficiency has become a point of concern, with two essential factors. The first is the number of base learners, because each independently runs an online learning algorithm that involves time-consuming gradient computations and projections. The second factor is the number of gradient queries, especially when the gradient evaluation is costly, e.g., in nuclear norm optimization [Ji and Ye, 2009] and mini-batch optimization [Li et al., 2014]. In universal online learning, an \u201cefficient\u201d algorithm is expected to adopt only ${\\mathcal{O}}(\\log T)$ base learners, which is inherent to the online ensemble design, and only 1 gradient query per round, matching the gradient query complexity of standard OGD. In terms of this metric, Zhang et al. [2022a] employed ${\\mathcal{O}}(\\log T)$ base learners, but required ${\\mathcal{O}}(\\log T)$ gradient queries per round. Yan et al. [2023] used only 1 gradient query per round but required $\\bar{O((\\log T)^{2})}$ base learners (caused by their three-layer algorithm design), resulting in reduced efficiency. ", "page_idx": 2}, {"type": "text", "text": "Results. Motivated by the above considerations of optimality and efficiency, in this work, we propose a simple universal approach that achieves the optimal $O\\big(\\frac{1}{\\lambda}\\log V_{T}\\big)$ , $\\textstyle{\\mathcal{O}}({\\frac{d}{\\alpha}}\\log V_{T})$ , and $O(\\sqrt{V_{T}})$ regret simultaneously for $\\lambda$ -strongly convex, $\\alpha$ -exp-concave, and convex functions, and is efficient with one gradient query per round and ${\\mathcal{O}}(\\log T)$ base learners, resolving a major open problem highlighted by Yan et al. [2023]. We summarize our theoretical results in Theorem 1, and compare our results with existing ones in Table 1. Furthermore, we validate the effectiveness of our approach by: $(i)$ showing that our universal gradient-variation regret directly implies the optimal universal small-loss regret in analysis without any algorithm modifications; and $(i i)$ applying them to the stochastically extended adversarial (SEA) model [Sachs et al., 2022], an intermediate framework between stochastic and adversarial optimization. We achieve the same state-of-the-art guarantees as Chen et al. [2024], but without curvature information. The details are provided in Section 4. ", "page_idx": 2}, {"type": "text", "text": "Techniques. Our technical contributions include two simple and novel analyses. First, the key to gradient-variation regret is to analyze its empirical version, formally, $\\|\\nabla f_{t}(\\bar{\\mathbf{x}_{t}})-\\nabla f_{t-1}(\\mathbf{x}_{t-1}\\mathbf{\\bar{)}}\\|_{2}^{2}$ . The previous approach to addressing this term involves controlling the algorithmic stability $\\|{\\bf x}_{t}-$ $\\mathbf{x}_{t-1}\\bar{\\|}_{2}^{2}$ , which is highly challenging in universal online learning, leading to sub-optimal results and less efficient algorithm design [Yan et al., 2023]. In this work, we overcome this issue via a novel analysis by a useful smoothness property and a Bregman divergence negative term from linearization, where the latter is inspired by the recent advance in stochastic optimization [Joulani et al., 2020]. Second, we adopt the surrogate functions proposed by Yan et al. [2023] to reduce the gradient query complexity, and provide a novel analysis for the empirical gradient variation based on the surrogates. A technical comparison with previous works is provided in Section 4. ", "page_idx": 2}, {"type": "text", "text": "Organization. The rest of the paper is structured as follows. Section 2 introduces preliminaries and a general framework for universal online learning. Section 3 presents our efficient approach with the optimal universal gradient-variation regret. Section 4 presents the implication and application of our results. Finally Section 5 concludes the paper. All the proofs can be found in the appendices. ", "page_idx": 2}, {"type": "text", "text": "2 Preliminaries ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "In this section, we introduce some preliminary knowledge, including notations, assumptions, definitions, and a general framework of universal online learning. ", "page_idx": 2}, {"type": "text", "text": "2.1 Notations, Assumptions, and Definitions ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "For simplicity, we use $\\Vert\\cdot\\Vert$ for $\\|\\cdot\\|_{2}$ by default and use $a\\lesssim b$ or $a=\\mathcal{O}(b)$ if there exists a constant $C<\\infty$ such that $a/b\\leq C$ . In the following, we introduce the assumptions used in this work. ", "page_idx": 2}, {"type": "text", "text": "Assumption 1 (Boundedness). For any $\\mathbf{x},\\mathbf{y}\\in\\mathcal{X}\\subseteq\\mathbb{R}^{d}$ , the domain diameter satisfies $\\|\\mathbf x-\\mathbf y\\|\\leq D$ , and for $t\\in[T]$ , the gradient norm of the online functions is bounded as $\\|\\nabla f_{t}(\\mathbf{x})\\|\\leq{\\stackrel{\\cdot}{G}}$ . ", "page_idx": 2}, {"type": "text", "text": "Assumption 2 (Smoothness). For each $t\\in[T]$ , the online function $f_{t}(\\cdot)$ is $L$ -smooth, i.e., $\\|\\nabla f_{t}(\\mathbf{x})-$ $\\nabla f_{t}(\\mathbf{y})\\|\\le L\\|\\mathbf{x}-\\mathbf{y}\\|$ holds for any $\\mathbf{x},\\mathbf{y}\\in\\mathbb{R}^{d}$ . ", "page_idx": 3}, {"type": "text", "text": "Both assumptions are common in the literature. Specifically, the boundedness assumption is widely used in OCO [Hazan, 2016]. And the smoothness assumption is essential for first-order algorithms in achieving the gradient-variation regret [Chiang et al., 2012]. Note that here Assumption 2 requires smoothness on the whole $\\mathbb{R}^{d}$ space and can be relaxed to a slightly larger domain than $\\mathcal{X}$ , formally, $\\mathcal{X}_{+}\\triangleq\\{\\mathbf{x}+\\mathbf{b}\\,|\\,\\mathbf{x}\\in\\mathcal{X},\\mathbf{b}\\in G/L\\cdot\\mathbb{B}\\}$ , where $\\mathbb{B}\\triangleq\\left\\{\\mathbf{x}\\mid\\lVert\\mathbf{x}\\rVert\\leq1\\right\\}$ is a unit ball. We defer the details of this relaxed smoothness requirement and its derivation to Appendix A. In the following, we provide formal definitions of strong convexity and exp-concavity. ", "page_idx": 3}, {"type": "text", "text": "Definition 1. For any $\\mathbf{x},\\mathbf{y}\\in{\\mathcal{X}}$ , a function $f(\\cdot)$ is $\\lambda$ -strongly convex if $f(\\mathbf{x})-f(\\mathbf{y})\\leq\\langle\\nabla f(\\mathbf{x}),\\mathbf{x}-$ $\\begin{array}{r}{\\mathbf{y}\\rangle-\\frac{\\lambda}{2}\\cdot\\|\\mathbf{x}-\\mathbf{y}\\|^{2};f(\\cdot)}\\end{array}$ is $\\alpha$ -exp-concave $\\begin{array}{r}{\\mathrm{~}\\d^{2}f(\\mathbf{x})-f(\\mathbf{y})\\leq\\langle\\nabla f(\\mathbf{x}),\\mathbf{x}-\\mathbf{y}\\rangle-\\frac{\\alpha}{2}\\cdot\\langle\\nabla f(\\mathbf{x}),\\mathbf{x}-\\mathbf{y}\\rangle^{2}.}\\end{array}$ . ", "page_idx": 3}, {"type": "text", "text": "Note that the formal definition of $\\beta.$ -exp-concavity is that $\\exp(-\\beta f(\\cdot))$ is concave. Under Assumption 1, $\\beta$ -exp-concavity implies Definition 1 with $\\alpha=\\textstyle{\\frac{1}{2}}\\cdot\\operatorname*{min}\\{1/(4G D),\\beta\\}$ [Hazan, 2016, Lemma 4.3]. Therefore, we adopt Definition 1 as an alternative definition of exp-concavity for clarity. ", "page_idx": 3}, {"type": "text", "text": "2.2 A General Framework for Universal Online Learning ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "In this part, we present a general framework of universal online learning [Zhang et al., 2022a, Yan et al., 2023]. Formally, we study the problem where the learner lacks the prior knowledge of curvature information, including $(i)$ curvature type: convexity, exp-concavity, or strong convexity; and $(i i)$ curvature coefficient: exp-concavity $\\alpha$ or strong convexity $\\lambda$ . Without loss of generality, we focus on the case of $\\alpha,\\lambda\\in[1/T,1]$ . If $\\alpha,\\lambda<1/T$ , even the optimal minimax results \u2014 $\\mathcal{O}(\\frac{d}{\\alpha}\\log T)$ for exp-concave functions and $\\textstyle{\\mathcal{O}}({\\frac{1}{\\lambda}}\\log T)$ for strongly convex functions [Hazan et al., 2007] \u2013 become linear in $T$ , rendering the regret bounds vacuous. On the other hand, if $\\alpha,\\lambda>1$ , we can simply treat them as $\\alpha,\\lambda=1$ , only making the regret worsen by an ignorable constant factor. This simplification is also adopted by Zhang et al. [2022a], Yan et al. [2023]. ", "page_idx": 3}, {"type": "text", "text": "To handle the uncertainty of curvatures, an online ensemble structure is usually employed, with multiple base learners exploring the environments and a meta learner tracking the best base learner. More specifically, to deal with the unknown curvature coefficients $\\alpha$ and $\\lambda$ , we discretize them into the following candidate pool [Zhang et al., 2022a]: ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\mathcal{H}\\triangleq\\{1/T,2/T,4/T,\\dots,2^{n-1}/T\\},\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "whose size is $n=\\lceil\\log_{2}T\\rceil+1=\\mathcal{O}(\\log T)$ . It can be proved that the discretized candidate pool $\\mathcal{H}$ can approximate the continuous value of $\\alpha$ or $\\lambda$ with negligible constant errors. By doing this, it is natural to design three distinct groups of base learners: ", "page_idx": 3}, {"type": "text", "text": "(i) strongly convex base learners: $n$ in total, each of which implements the algorithm for strongly convex functions with a guess $\\lambda_{i}\\in\\mathcal{H}$ of the strong convexity coefficient $\\lambda$ ;   \n(ii) exp-concave base learners: $n$ in total, each of which implements the algorithm for expconcave functions with a guess $\\alpha_{i}\\in\\mathcal{H}$ of the exp-concavity coefficient $\\alpha$ ;   \n(iii) convex base learner: only one, it runs the algorithm for convex functions. ", "page_idx": 3}, {"type": "text", "text": "In total, there are $N\\triangleq(2n+1)={\\mathcal{O}}(\\log T)$ base learners with a two-layer structure, which is for now necessary in this problem. The best base learner is the one with the right guess of the curvature type and the closest guess of the curvature coefficient. Taking $\\lambda$ -strongly convex functions as an example, the guessed coefficient of the best base learner (indexed by $i^{\\star}$ ) satisfies $\\lambda_{i^{\\star}}\\le\\lambda\\le2\\lambda_{i^{\\star}}$ . ", "page_idx": 3}, {"type": "text", "text": "Denoting by $\\mathbf{x}_{t,i}$ the decision generated by the $i$ -th base learner at the $t$ -th round, $p_{t,i}$ the weight of the meta learner on the $i^{\\th}$ -th base learner, an online ensemble method outputs the final decision as $\\begin{array}{r}{{\\bf x}_{t}=\\sum_{i\\in[N]}p_{t,i}{\\bf x}_{t,i}}\\end{array}$ . This forms a general framework for universal online learning and it remains to select suitable algorithms and loss functions for the meta and base learners. We illuminate our algorithm design in Section 3.1. ", "page_idx": 3}, {"type": "text", "text": "3 Our Approach ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "In this section, we present our approach for universal online learning with gradient-variation regret. Section 3.1 presents the overall procedure of our proposed algorithm. Subsequently, we outline ", "page_idx": 3}, {"type": "text", "text": "Input: Curvature coefficient pool $\\mathcal{H}$ defined in (2.1), base learner number $N$   \n1: Initialize: $\\boldsymbol{\\mathcal{A}}$ \u2014 meta learner running OPTIMISTIC-ADAPT-ML-PROD with losses $\\{\\ell_{t}\\}_{t=1}^{T}$ , optimisms $\\{m_{t}\\}_{t=1}^{T}$ , and learning rates $\\{\\varepsilon_{t}\\}_{t=1}^{T}$ , where $\\ell_{t}=(\\ell_{t,1},\\dots,\\ell_{t,N})$ , $\\pmb{m}_{t}=(m_{t,1},\\dots,m_{t,N})$ ,and $\\boldsymbol{\\varepsilon}_{t}=\\left(\\varepsilon_{t,1},\\dots,\\varepsilon_{t,N}\\right)$ for each $t\\in[T]$ ; $\\{B_{i}\\}_{i\\in[N]}$ \u2014 base learners as specified in Section 2   \n2: for $t=1$ to $T$ do   \n3: Submit $\\begin{array}{r}{{\\bf x}_{t}=\\sum_{i\\in[N]}p_{t,i}{\\bf x}_{t,i}}\\end{array}$ , suffer $f_{t}(\\mathbf{x}_{t})$ , and observe the gradient $\\nabla f_{t}(\\mathbf{x}_{t})$ # Meta Update:   \n4: $\\boldsymbol{\\mathcal{A}}$ updates to $\\pmb{p}_{t+1}=(p_{t+1,1},\\dots,p_{t+1,N})$ with $\\ell_{t,i}\\,=\\,\\langle\\nabla f_{t}(\\mathbf{x}_{t}),\\mathbf{x}_{t,i}\\rangle$ , $\\varepsilon_{t,i}$ given in (B.5), and $m_{t,i}=\\langle\\nabla f_{t-1}(\\mathbf{x}_{t-1}),\\dot{\\mathbf{x}}_{t}-\\mathbf{x}_{t,i}\\rangle$ for the convex base learner and $m_{t,i}=0$ otherwise # Base Update:   \n5: Construct surrogates $h_{t,i}^{\\mathrm{sc}}(\\cdot),h_{t,i}^{\\mathrm{exp}}(\\cdot),h_{t,i}^{\\mathrm{c}}(\\cdot)$ defined in (3.1) using only $\\nabla f_{t}(\\mathbf{x}_{t})$   \n6: Send the surrogate functions to $B_{i}$ for update and obtain $\\mathbf{x}_{t+1,i}$ for each $i\\in[N]$   \n7: end for ", "page_idx": 4}, {"type": "text", "text": "our two key technical components: Section 3.2 presents a novel analysis to handle the empirical gradient variation, and Section 3.3 introduces surrogate functions to improve efficiency and provides a corresponding analysis for the empirical gradient variation defined on surrogates. We finally provide the optimal universal gradient-variation regret guarantees in Section 3.4. ", "page_idx": 4}, {"type": "text", "text": "3.1 Overall Algorithm ", "text_level": 1, "page_idx": 4}, {"type": "text", "text": "In this part, we present our simple approach for universal online learning with gradient variations, summarized in Algorithm 1. Basically, it follows a two-layer online ensemble structure. Base learners are implemented using the preliminary configurations given in Section 2.2 and on carefully designed surrogate functions. The meta learner runs OPTIMISTIC-ADAPT-ML-PROD [Wei et al., 2016] on linearized losses. We specify the algorithmic details below. ", "page_idx": 4}, {"type": "text", "text": "In Line 3, the learner makes a weighted combination of the base learners\u2019 decisions $\\{\\mathbf{x}_{t,i}\\}_{i\\in[N]}$ using the meta learner\u2019s weights $\\pmb{p}_{t}=(p_{t,1},\\dots,p_{t,N})$ , submits the final decision $\\mathbf{x}_{t}$ , suffers a loss $\\overline{{f_{t}(\\mathbf{x}_{t})}}$ , and receives a single $\\nabla f_{t}(\\mathbf{x}_{t})$ as the gradient feedback, using only 1 gradient query per round. ", "page_idx": 4}, {"type": "text", "text": "Meta Algorithm. In Line 4, the meta learner uses OPTIMISTIC-ADAPT-ML-PROD [Wei et al., 2016] to update the weights by the following rule: ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\nu_{t+1,i}\\propto\\varepsilon_{t,i}\\!\\cdot\\!\\exp(\\varepsilon_{t,i}m_{t+1,i})\\!\\cdot\\!W_{t,i},W_{t,i}=\\left(W_{t-1,i}\\!\\cdot\\!\\exp\\left(\\varepsilon_{t-1,i}r_{t,i}-\\varepsilon_{t-1,i}^{2}\\big(r_{t,i}-m_{t,i}\\big)\\right)\\right)^{\\frac{\\varepsilon_{t,i}}{\\varepsilon_{t-1,i}}}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "Specifically, denoting by $\\ell_{t,i}\\triangleq\\langle\\nabla f_{t}(\\mathbf{x}_{t}),\\mathbf{x}_{t,i}\\rangle$ the loss of the $i$ -th dimension, the meta algorithm inputs: $r_{t,i}=\\langle\\ell_{t},p_{t}\\rangle-\\ell_{t,i}$ , the instantaneous regret; $\\varepsilon_{t,i}$ , a time-varying learning rate; and $m_{t,i}$ , an estimation of the true loss of the $t$ -th round (the choice of optimisms will be shown later). The meta algorithm then outputs the weights $\\pmb{p}_{t+1}=(p_{t+1,1},\\dots,p_{t+1,N})$ of the next round. ", "page_idx": 4}, {"type": "text", "text": "With appropriate learning rates (B.5), OPTIMISTIC-ADAPT-ML-PROD achieves an optimistic secondorder bound of $\\begin{array}{r}{\\sum_{t\\le T}r_{t,i}\\;\\le\\;\\mathcal{O}(\\sqrt{\\log N\\sum_{t}(r_{t,i}-m_{t,i})^{2}}+\\log N)}\\end{array}$ , where the $\\log N$ factor is negligible since the base learner number $N$ equals ${\\mathcal{O}}(\\log T)$ and we can treat ${\\mathcal{O}}(\\log\\log T)$ as a constant [Luo and Schapire, 2015]. The formal guarantee of OPTIMISTIC-ADAPT-ML-PROD is deferred to Lemma 2 in the appendix. In our problem, the instantaneous regret $r_{t,i}=\\langle\\ell_{t},p_{t}\\rangle-\\ell_{t,i}=$ $\\langle\\nabla f_{t}({\\mathbf{x}}_{t}),{\\mathbf{x}}_{t}-{\\mathbf{x}}_{t,i}\\rangle$ . Thus we choose $m_{t,i}\\stackrel{.}{=}\\langle\\nabla f_{t-1}({\\mathbf x}_{t-1}),{\\mathbf x}_{t}-{\\mathbf x}_{t,i}\\rangle$ for the convex base learner and $m_{t,i}=0$ otherwise (i.e., for exp-concave and strongly convex base learners).2 By doing this, we can upper-bound $\\begin{array}{r}{\\sum_{t}\\langle\\nabla f_{t}({\\mathbf x}_{t}),{\\mathbf x}_{t}-{\\mathbf x}_{t,i}\\rangle}\\end{array}$ by $\\begin{array}{r}{\\mathcal{O}(\\sqrt{\\sum_{t}\\langle\\nabla f_{t}(\\mathbf{x}_{t})-\\nabla f_{t-1}(\\mathbf{x}_{t-1}),\\mathbf{x}_{t}-\\mathbf{x}_{t,i}\\rangle^{2}})}\\end{array}$ for the convex base learner and by $\\mathcal{O}(\\sqrt{\\sum_{t}\\langle\\nabla f_{t}(\\mathbf{x}_{t}),\\mathbf{x}_{t}-\\mathbf{x}_{t,i}\\rangle^{2}})$ otherwise. Later in Section 3.3, we illuminate how such results could benefit the final regret guarantees. ", "page_idx": 4}, {"type": "text", "text": "Base Algorithm. In Line 5, we adopt carefully designed surrogate functions for different types of base learners to reduce the gradient query complexity [Yan et al., 2023]. Specifically, strongly convex, exp-concave, and the convex base learners run on the surrogate functions below respectively: ", "page_idx": 5}, {"type": "equation", "text": "$$\nh_{t,i}^{\\mathrm{sc}}(\\mathbf{x})\\triangleq\\langle\\nabla f_{t}(\\mathbf{x}_{t}),\\mathbf{x}\\rangle+\\frac{\\lambda_{i}}{4}\\|\\mathbf{x}-\\mathbf{x}_{t}\\|^{2},\\quad h_{t,i}^{\\mathrm{exp}}(\\mathbf{x})\\triangleq\\langle\\nabla f_{t}(\\mathbf{x}_{t}),\\mathbf{x}\\rangle+\\frac{\\alpha_{i}}{4}\\langle\\nabla f_{t}(\\mathbf{x}_{t}),\\mathbf{x}-\\mathbf{x}_{t}\\rangle^{2},\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "and $h_{t,i}^{\\mathrm{c}}(\\mathbf{x})\\triangleq\\langle\\nabla f_{t}(\\mathbf{x}_{t}),\\mathbf{x}\\rangle$ , where $\\lambda_{i},\\alpha_{i}$ are selected from the candidate coefficient pool $\\mathcal{H}$ in (2.1). We emphasize that the surrogate functions require only 1 gradient query $\\nabla f_{t}(\\mathbf{x}_{t})$ per round. Finally, in Line 6, the $i$ -th base learner $B_{i}$ updates the decision to $\\mathbf{x}_{t+1,i}$ using optimistic online mirror descent (OOMD) [Rakhlin and Sridharan, 2013], which is general and covers many algorithms of interest, such as OGD and online Newton step. For each curvature type (convexity, exp-concavity, or strong convexity), we adopt a correspondingly configured OOMD as the base learner. ", "page_idx": 5}, {"type": "text", "text": "As for previous works, Zhang et al. [2022a] adopted ADAPT-ML-PROD [Gaillard et al., 2014] as the meta learner, which does not incorporate optimisms and thus is impossible to achieve gradientvariation regret for convex functions, and operates on the original loss function $f_{t}(\\cdot)$ for base learners, which leads to a less efficient gradient query complexity of ${\\mathcal{O}}(\\log T)$ per round. Yan et al. [2023] used a two-layer meta algorithm MSMWC-MASTER [Chen et al., 2021] as the meta learner, resulting in a three-layer ensemble structure, which is also not efficient enough. Compared with approaches above, our Algorithm 1 is simpler and more efficient as it requires ${\\mathcal{O}}(\\log T)$ base learners and only 1 gradient query in each round. We emphasize that our contributions mainly lie in the technical aspects showing that although simple, our approach can achieve the optimal universal gradient-variation regret, which is accomplished via two novel analytical components. ", "page_idx": 5}, {"type": "text", "text": "3.2 Novel Analysis on Empirical Gradient Variations ", "text_level": 1, "page_idx": 5}, {"type": "text", "text": "In this part, we provide a novel analysis of the gradient-variation regret. For clarity, we illustrate from the lowest level \u2014 as we only use one gradient $\\nabla f_{t}(\\mathbf{x}_{t})$ in the $t$ -th round, to obtain the gradient variation $V_{T}$ defined in (1.2), it is necessary to first attain its empirical version $\\bar{V}_{T}$ \u225c $\\begin{array}{r}{\\sum_{t\\le T}\\|\\nabla f_{t}(\\mathbf{x}_{t})-\\nabla f_{t-1}(\\mathbf{x}_{t-1})\\|^{2}}\\end{array}$ . Previous studies decompose this term into two parts: ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\|\\nabla f_{t}(\\mathbf{x}_{t})-\\nabla f_{t-1}(\\mathbf{x}_{t-1})\\|^{2}\\lesssim\\|\\nabla f_{t}(\\mathbf{x}_{t})-\\nabla f_{t-1}(\\mathbf{x}_{t})\\|^{2}+\\|\\nabla f_{t-1}(\\mathbf{x}_{t})-\\nabla f_{t-1}(\\mathbf{x}_{t-1})\\|^{2}}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\leq\\|\\nabla f_{t}(\\mathbf{x})-\\nabla f_{t-1}(\\mathbf{x})\\|^{2}+L^{2}\\|\\mathbf{x}_{t}-\\mathbf{x}_{t-1}\\|^{2},}\\end{array}\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "using smoothness (i.e., Assumption 2). Aggregating the first term over $T$ rounds leads to the desired $V_{T}$ quantity and the remaining challenge is to control the algorithmic stability $\\|{\\bf x}_{t}-{\\bf x}_{t-1}\\|^{2}$ . Consequently, since each decision is a weighted combination of base learners\u2019 decisions (i.e., xt = i\u2264N pt,ixt,i), the algorithmic stability is difficult to control. To this end, Yan et al. [2023] decomposed the stability term in the following way: ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\|\\mathbf{x}_{t}-\\mathbf{x}_{t-1}\\|^{2}\\lesssim\\sum_{i=1}^{N}p_{t,i}\\|\\mathbf{x}_{t,i}-\\mathbf{x}_{t-1,i}\\|^{2}+\\|p_{t}-p_{t-1}\\|_{1}^{2}.\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "Consequently, for the first term, the authors injected correction terms to the meta learner following Zhao et al. [2024]. To cancel the second term, the meta algorithm must include a corresponding negative stability term in its analysis, while achieving an optimistic second-order bound simultaneously. To the best of our knowledge, the only feasible algorithm satisfying both requirements is the two-layer meta algorithm MSMWC-MASTER [Chen et al., 2021], which leads to a three-layer online ensemble structure and therefore affects the efficiency. Besides, it attains a second-order bound of the form $\\mathcal{O}(\\sqrt{Q_{T,i}\\log Q_{T,i}})$ , where $\\begin{array}{r}{Q_{T,i}\\triangleq\\sum_{t}(\\ell_{t,i}-m_{t,i})^{2}}\\end{array}$ , which causes the sub-optimality of the regret guarantees with an additional logarithmic factor in the results of Yan et al. [2023]. ", "page_idx": 5}, {"type": "text", "text": "In this work, we handle the empirical gradient variation alternatively via a novel and simple analysis with two key parts: $(i)$ a negative term arising from linearization; and $(i i)$ a useful smoothness property. First, we observe that the instantaneous regret can be transformed as: ", "page_idx": 5}, {"type": "equation", "text": "$$\nf_{t}(\\mathbf{x}_{t})-f_{t}(\\mathbf{x}^{\\star})=\\langle\\nabla f_{t}(\\mathbf{x}_{t}),\\mathbf{x}_{t}-\\mathbf{x}^{\\star}\\rangle-\\mathcal{D}_{f_{t}}(\\mathbf{x}^{\\star},\\mathbf{x}_{t}),\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "where $\\begin{array}{r}{\\mathbf{x}^{\\star}\\in\\arg\\operatorname*{min}_{\\mathbf{x}\\in\\mathcal{X}}\\sum_{t}f_{t}(\\mathbf{x})}\\end{array}$ and $\\mathcal{D}_{f}(\\mathbf{x},\\mathbf{y})\\triangleq f(\\mathbf{x})-f(\\mathbf{y})-\\langle\\nabla f(\\mathbf{y}),\\mathbf{x}-\\mathbf{y}\\rangle$ is the Bregman divergence associated with function $f(\\cdot)$ . The last term is a negative term from linearization, which can be seen as the compensation by treating a convex function as a linear one. Previous studies on the gradient-variation regret usually omit this term, while we show below that this negative term helps to achieve a much simpler analysis of the empirical gradient variation. Second, we introduce a useful property of smoothness, formally introduced below. ", "page_idx": 5}, {"type": "text", "text": "", "page_idx": 6}, {"type": "text", "text": "Proposition 1 (Theorem 2.1.5 of Nesterov [2018]). $f(\\cdot)$ is $L$ -smooth over $\\mathbb{R}^{d}$ if and only $i f$ ", "page_idx": 6}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\|\\nabla f(\\mathbf{x})-\\nabla f(\\mathbf{y})\\|^{2}\\leq2L\\cdot\\mathcal{D}_{f}(\\mathbf{y},\\mathbf{x}),\\quad f o r\\,a n y\\,\\,\\mathbf{x},\\mathbf{y}\\in\\mathbb{R}^{d}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "Compared with the commonly used $\\|\\nabla f(\\mathbf{x})-\\nabla f(\\mathbf{y})\\|\\leq L\\|\\mathbf{x}-\\mathbf{y}\\|$ , Proposition 1 gives a tighter bound for the squared gradient changes since $\\|\\nabla f(\\mathbf{x})^{\\cdot}-\\nabla f(\\mathbf{y})\\|^{2}\\overset{\\cdot\\cdot}{\\leq}2L\\dot{\\mathcal{D}}_{f}(\\mathbf{y},\\mathbf{x})\\overset{\\leq}-L^{2}\\|\\mathbf{x}-\\mathbf{\\bar{y}}\\|^{2}$ , where the second step is due to $\\begin{array}{r}{\\mathcal{D}_{f}(\\mathbf{y},\\mathbf{x})\\;\\leq\\;\\frac{L}{2}\\|\\mathbf{x}-\\mathbf{y}\\|^{2}}\\end{array}$ , for any $\\mathbf{x},\\mathbf{y}\\,\\in\\,\\mathbb{R}^{d}$ [Nesterov, 2018, Theorem 2.1.5], intuitively making the analysis easier. Combining the Bregman divergence negative term (3.3) and this useful property (3.4), we address the empirical gradient variation effectively as ", "page_idx": 6}, {"type": "equation", "text": "$$\n\\begin{array}{c}{\\displaystyle\\bar{\\gamma}_{T}\\lesssim\\sum_{t=2}^{T}\\left(\\|\\nabla f_{t}(\\mathbf{x}_{t})-\\nabla f_{t}(\\mathbf{x}^{\\star})\\|^{2}+\\|\\nabla f_{t}(\\mathbf{x}^{\\star})-\\nabla f_{t-1}(\\mathbf{x}^{\\star})\\|^{2}+\\|\\nabla f_{t-1}(\\mathbf{x}^{\\star})-\\nabla f_{t-1}(\\mathbf{x}_{t-1})\\|^{2}\\right)}\\\\ {\\displaystyle\\overset{(3.4)}{\\lesssim}L\\displaystyle\\sum_{t=2}^{T}\\mathcal{D}_{f_{t}}(\\mathbf{x}^{\\star},\\mathbf{x}_{t})+V_{T}+L\\displaystyle\\sum_{t=2}^{T}D_{f_{t-1}}(\\mathbf{x}^{\\star},\\mathbf{x}_{t-1})\\leq2L\\displaystyle\\sum_{t=1}^{T}\\mathcal{D}_{f_{t}}(\\mathbf{x}^{\\star},\\mathbf{x}_{t})+V_{T},\\qquad\\qquad(3.5)}\\end{array}\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "where the first step introduces intermediate terms $\\nabla f_{t}(\\mathbf{x}^{\\star})$ and $\\nabla f_{t-1}(\\mathbf{x}^{\\star})$ , the second step uses Proposition 1, and the last step combines two summations into one by shifting the indexes of $t$ . The Bregman divergence negative term in (3.3) can cancel the positive term in (3.5), leaving only the gradient variation quantity $V_{T}$ as desired. ", "page_idx": 6}, {"type": "text", "text": "Here we only require $\\|\\nabla f(\\mathbf{x})-\\nabla f(\\mathbf{y})\\|^{2}\\leq2L\\mathcal{D}_{f}(\\mathbf{y},\\mathbf{x})$ on $\\mathcal{X}$ rather than $\\mathbb{R}^{d}$ , which can be satisfied by requiring $L$ -smoothness only on a slightly larger domain than $\\mathcal{X}$ (a relaxation of Assumption 2). Interested readers can refer to Appendix A for details. Finally we end this part with several remarks. ", "page_idx": 6}, {"type": "text", "text": "Remark 1. We emphasize that the Bregman divergence negative term comes from the linearization of convex functions, and is thus algorithm-independent. Therefore, we can eliminate the need to control the algorithmic stability, in contrast to previous works for gradient-variation regret [Chiang et al., 2012, Yan et al., 2023]. To the best of our knowledge, this is the first alternative analysis of the gradient-variation regret since first proposed by Chiang et al. [2012]. \u25c1 ", "page_idx": 6}, {"type": "text", "text": "Remark 2. Our idea of the negative term from linearization is inspired by the recent advance in stochastic optimization [Joulani et al., 2020]. Note that they focus on a different problem of achieving the ${\\mathcal{O}}(1/T^{\\bar{2}})$ rate as Nesterov\u2019s accelerated gradient [Nesterov, 2018], while we investigate the gradient-variation regret in the universal online (adversarial) convex optimization setup. \u25c1 ", "page_idx": 6}, {"type": "text", "text": "Remark 3. Our analysis does not strictly outperform those that directly handle the stability term as in (3.2), e.g., Yan et al. [2023], since the latter can be used for fast rates in the multi-player game setup [Syrgkanis et al., 2015, Zhang et al., 2022b]. A more detailed discussion of the advantages and disadvantages over previous approaches is provided in Section 4.3. \u25c1 ", "page_idx": 6}, {"type": "text", "text": "3.3 Novel Analysis on Empirical Gradient Variations of Surrogates ", "text_level": 1, "page_idx": 6}, {"type": "text", "text": "Section 3.2 already suffices to achieve the optimal universal gradient-variation regret if multiple gradient queries are permitted. In this part, we consider further improving the computational efficiency by using only 1 gradient query per round, achieving the same gradient query complexity as OGD. ", "page_idx": 6}, {"type": "text", "text": "As stated in Section 3.1, we implement base algorithms on carefully designed surrogate functions following Yan et al. [2023]. In this part, we show that additional novel analysis is required to handle the empirical gradient variation defined on surrogates. To see this, we first provide the entire regret decomposition to give readers a clear roadmap. Specifically, taking $\\lambda$ -strong convexity as an example, the regret can be decomposed as follows: ", "page_idx": 6}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\displaystyle\\mathsf{R E G}_{T}\\leq\\sum_{t=1}^{T}\\langle\\nabla f_{t}(\\mathbf{x}_{t}),\\mathbf{x}_{t}-\\mathbf{x}^{\\star}\\rangle-\\frac{\\lambda}{4}\\sum_{t=1}^{T}\\|\\mathbf{x}_{t}-\\mathbf{x}^{\\star}\\|^{2}-\\frac{1}{2}\\sum_{t=1}^{T}\\mathcal{D}_{f_{t}}(\\mathbf{x}^{\\star},\\mathbf{x}_{t})}\\\\ &{\\leq\\displaystyle\\left[\\sum_{t=1}^{T}r_{t,i^{\\star}}-\\frac{\\lambda_{i^{\\star}}}{4}\\sum_{t=1}^{T}\\|\\mathbf{x}_{t}-\\mathbf{x}_{t,i^{\\star}}\\|^{2}\\right]+\\displaystyle\\left[\\sum_{t=1}^{T}\\left(h_{t,i^{\\star}}^{\\mathrm{sc}}(\\mathbf{x}_{t,i^{\\star}})-h_{t,i^{\\star}}^{\\mathrm{sc}}(\\mathbf{x}^{\\star})\\right)\\right]-\\frac{1}{2}\\sum_{t=1}^{T}\\mathcal{D}_{f_{t}}(\\mathbf{x}^{\\star},\\mathbf{x}_{t}),}\\end{array}\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "where the first step uses (3.3) and the fact that $\\begin{array}{r}{\\mathcal{D}_{f_{t}}(\\mathbf{x}^{\\star},\\mathbf{x}_{t})\\ge\\frac{\\lambda}{2}\\|\\mathbf{x}_{t}-\\mathbf{x}^{\\star}\\|^{2}}\\end{array}$ since $f_{t}(\\cdot)$ is $\\lambda$ -strongly convex. The second step uses the definition of the best base learner (indexed by $i^{\\star}$ ): ${\\lambda_{i^{\\star}}}\\le{\\lambda\\le2\\lambda_{i^{\\star}}}$ and the definition of surrogate functions defined in (3.1). The first term above (meta regret) assesses how well the algorithm tracks the best base learner, and the second term (base regret) measures the best base learner\u2019s performance. The meta regret contains a linearized regret with a negative term from curvatures. This negative term is useful for exp-concave and strongly convex functions if the linearized regret enjoys a second-order bound: ", "page_idx": 7}, {"type": "equation", "text": "$$\n\\sum_{t=1}^{T}r_{t,i^{*}}-\\frac{\\lambda_{i^{*}}}{4}\\sum_{t=1}^{T}\\|\\mathbf x_{t}-\\mathbf x_{t,i^{*}}\\|^{2}\\lesssim\\sqrt{\\sum_{t=1}^{T}\\langle\\nabla f_{t}(\\mathbf x_{t}),\\mathbf x_{t}-\\mathbf x_{t,i^{*}}\\rangle^{2}}-\\frac{\\lambda_{i^{*}}}{4}\\sum_{t=1}^{T}\\|\\mathbf x_{t}-\\mathbf x_{t,i^{*}}\\|^{2}\\lesssim\\frac{1}{\\lambda},\n$$", "text_format": "latex", "page_idx": 7}, {"type": "text", "text": "where the $1/\\lambda$ factor can be absorbed by the final regret $\\textstyle{\\mathcal{O}}({\\frac{1}{\\lambda}}\\log V_{T})$ . The base regret is defined on the surrogates, which preserves the curvature properties, but using only 1 gradient $\\bar{\\nabla}f_{t}({\\bf x}_{t})$ . ", "page_idx": 7}, {"type": "text", "text": "Below we explain the reason for handling the empirical gradient variation defined on surrogates. Taking the $i^{\\th}$ -th strongly convex base learner as an example, it updates as $\\mathbf{x}_{t,i}=\\Pi_{\\mathcal{X}}\\big[\\widehat{\\mathbf{x}}_{t,i}-\\eta_{t}\\mathbf{m}_{t}\\big]$ and $\\widehat{\\mathbf{x}}_{t+1,i}=\\Pi_{\\mathcal{X}}[\\widehat{\\mathbf{x}}_{t,i}-\\dot{\\eta}_{t}\\nabla h_{t,i}^{\\mathrm{sc}}(\\mathbf{x}_{t,i})]$ , an initialization of the OOMD algorithm, where $\\eta_{t}$ represents the step size, $\\Pi_{\\mathcal{X}}[\\mathbf{x}]=\\arg\\operatorname*{min}_{\\mathbf{y}\\in\\mathcal{X}}\\left\\|\\mathbf{x}-\\mathbf{y}\\right\\|$ denotes the Euclidean projection onto $\\mathcal{X}$ , and $\\widehat{\\mathbf{x}}_{t,i}$ is an intermediate variable. With appropriately chosen step sizes, the base learner achieves an optimistic bound of ${\\mathcal{O}}(\\log D_{T})$ , where $\\begin{array}{r}{\\bar{D}_{T}=\\sum_{t\\leq T}\\|\\nabla h_{t,i}^{\\mathrm{sc}}(\\bar{\\mathbf{x}}_{t,i})-\\mathbf{m}_{t}\\|^{2}}\\end{array}$ (e.g., please refer to Theorem 15 of Chiang et al. [2012]). Therefore, choosing the optimism as $\\mathbf{m}_{t}=\\nabla h_{t-1,i}^{\\mathrm{sc}}(\\mathbf{x}_{t-1,i})$ leads to an empirical gradient-variation bound ${\\mathcal{O}}(\\log D_{T})$ defined on surrogates,3 where ", "page_idx": 7}, {"type": "equation", "text": "$$\n\\begin{array}{l}{{\\displaystyle{\\cal D}_{T}=\\sum_{t=2}^{T}\\|\\nabla h_{t,i}^{\\mathrm{sc}}({\\bf x}_{t,i})-\\nabla h_{t-1,i}^{\\mathrm{sc}}({\\bf x}_{t-1,i})\\|^{2}}}\\\\ {{\\displaystyle\\qquad=\\sum_{t=2}^{T}\\left\\|\\nabla f_{t}({\\bf x}_{t})-\\nabla f_{t-1}({\\bf x}_{t-1})+\\frac{\\lambda_{i}}{2}({\\bf x}_{t,i}-{\\bf x}_{t})-\\frac{\\lambda_{i}}{2}({\\bf x}_{t-1,i}-{\\bf x}_{t-1})\\right\\|^{2}.}}\\end{array}\n$$", "text_format": "latex", "page_idx": 7}, {"type": "text", "text": "The empirical gradient variation defined on the original functions, i.e., $\\|\\nabla f_{t}(\\mathbf{x}_{t})-\\nabla f_{t-1}(\\mathbf{x}_{t-1})\\|^{2}$ , can be handled via the analysis in Section 3.2. The main challenge is to deal with the rest terms caused by the surrogate functions. Yan et al. [2023] overcame this issue by controlling $\\left(\\mathbf{x}_{t}-\\mathbf{x}_{t-1}\\right)$ and $({\\bf x}_{t,i}-{\\bf x}_{t-1,i})$ separately. Again, as we have explained in Section 3.2, since the decision $\\mathbf{x}_{t}$ is a weighted combination of base learners\u2019 decisions (i.e., $\\begin{array}{r}{\\mathbf{x}_{t}=\\sum_{i\\leq N}p_{t,i}\\mathbf{x}_{t,i})}\\end{array}$ , handling the algorithmic stability term $\\|{\\bf x}_{t}-{\\bf x}_{t-1}\\|^{2}$ directly using (3.2) would results in a less efficient three-layer online ensemble structure and the sub-optimality of the regret guarantees, as Yan et al. [2023] did. ", "page_idx": 7}, {"type": "text", "text": "In this work, we propose a novel analysis \u2014 while controlling $(\\mathbf{x}_{t,i}-\\mathbf{x}_{t})-(\\mathbf{x}_{t-1,i}-\\mathbf{x}_{t-1})$ in each individual round is hard, it can be bounded when aggregated over the time horizon. Specifically, we bound it by combining two summations into one: ", "page_idx": 7}, {"type": "equation", "text": "$$\n\\sum_{i=2}^{T}\\|(\\mathbf{x}_{t,i}-\\mathbf{x}_{t})-(\\mathbf{x}_{t-1,i}-\\mathbf{x}_{t-1})\\|^{2}\\lesssim\\sum_{t=2}^{T}\\|\\mathbf{x}_{t,i}-\\mathbf{x}_{t}\\|^{2}+\\sum_{t=2}^{T}\\|\\mathbf{x}_{t-1,i}-\\mathbf{x}_{t-1}\\|^{2}\\leq2\\sum_{t=1}^{T}\\|\\mathbf{x}_{t,i}-\\mathbf{x}_{t}\\|^{2}.\n$$", "text_format": "latex", "page_idx": 7}, {"type": "text", "text": "The same idea is also used in the derivation of (3.5). Consequently, this term can be canceled out by the negative term from curvatures in the meta regret. For this cancellation to occur, appropriate coefficients are chosen, which are provided in the detailed proofs (e.g., the \u2018Regret Analysis\u2019 part in the proof of Theorem 1) and are omitted here for clarity. ", "page_idx": 7}, {"type": "text", "text": "This simple and novel analysis eliminates the need to control the overall algorithmic stability term of $||\\mathbf{x}_{t}-\\mathbf{x}_{t-1}^{\\'}||^{2}$ required by previous works, and is essential for achieving the improved computational efficiency and the optimal regret guarantees, as shown in the next part. ", "page_idx": 7}, {"type": "text", "text": "3.4 Optimal Universal Gradient-Variation Regret Guarantees ", "text_level": 1, "page_idx": 7}, {"type": "text", "text": "In this part, we present our main theoretical result \u2014 our simple and efficient Algorithm 1 (in Section 3.1) which adopts two novel analyses (in Section 3.2 and Section 3.3) achieves the optimal gradient-variation regret without requiring the curvature information in advance for universal online learning. The corresponding proof is provided in Appendix B. ", "page_idx": 7}, {"type": "text", "text": "", "page_idx": 8}, {"type": "text", "text": "Theorem 1. Under Assumptions\u221a 1 and 2 (or the relaxed Assumption 3), Algorithm 1 achieves ${\\mathcal{O}}(\\log V_{T})$ , $O(d\\log V_{T})$ , and $O(\\sqrt{V_{T}})$ for strongly convex, exp-concave, and convex functions. ", "page_idx": 8}, {"type": "text", "text": "Theorem 1 improves the $\\mathcal{O}(\\sqrt{V_{T}\\log V_{T}})$ bound of Yan et al. [2023] and is optimal by matching the best known results when the curvature information is known. It performs well when the gradient variation is small, such as $f_{1}=f_{2}=\\cdot\\cdot\\cdot=f_{T}$ (where $V_{T}=0$ ). Note \u221athat for $\\alpha$ -exp-concave or $\\lambda$ -st\u221arongly convex functions, our guarantee is actually $\\begin{array}{r}{\\mathcal{O}(\\operatorname*{min}\\lbrace\\frac{d}{\\alpha}\\log V_{T},\\sqrt{V_{T}}\\rbrace)}\\end{array}$ or $\\mathcal{O}(\\operatorname*{min}\\lbrace\\frac{1}{\\lambda}\\log V_{T},\\sqrt{V_{T}}\\rbrace)$ , thus ensuring $O(\\sqrt{V_{T}})$ even when $\\alpha=\\mathcal{O}(^{1}\\!/\\!T)$ or $\\lambda=\\mathcal{O}(^{1}/T)$ . This is because exp-concave and strongly convex functions are also convex and thus our convex bound is still applicable. ", "page_idx": 8}, {"type": "text", "text": "4 Implication, Application, and Discussion ", "text_level": 1, "page_idx": 8}, {"type": "text", "text": "In this section, we validate the effectiveness of our results by the implication of small-loss regret and the application in the SEA model. We also discuss the technical comparison with the previous correction-based approach [Yan et al., 2023] at the end of this section. ", "page_idx": 8}, {"type": "text", "text": "4.1 Implication to Universal Small-Loss Regret ", "text_level": 1, "page_idx": 8}, {"type": "text", "text": "In this part, we illustrate that our universal gradient-variation regret in Theorem 1 implies the universal small-loss regret measured by $\\begin{array}{r}{F_{T}\\,\\triangleq\\,\\operatorname*{min}_{\\mathbf{x}\\in\\mathcal{X}}\\sum_{t\\le T}{f_{t}(\\mathbf{x})}}\\end{array}$ directly in analysis, i.e., without any algorithmic modification, and thus safeguards the case of $F_{T}\\leq V_{T}$ , such as $\\mathrm{min}_{\\mathbf{x}\\in\\mathcal{X}}\\,f_{t}(\\mathbf{x})=0$ for any $t\\in[T]$ (where $F_{T}=0$ ). The corresponding proof is provided in Appendix C.1. ", "page_idx": 8}, {"type": "text", "text": "Theorem 2. Under Assumptions $^{\\,l}$ and 2 (or the relaxed Assumption 3\u221a), if the online functions are non-negative, Algorithm 1 achieves ${\\mathcal{O}}(\\log F_{T})$ , ${\\mathcal{O}}(d\\log F_{T})$ , and $O(\\sqrt{F_{T}})$ for strongly convex, exp-concave, and convex functions, respectively. ", "page_idx": 8}, {"type": "text", "text": "Theorem 2 achieves the same optimal small-loss bounds as Zhang et al. [2022a]. Combined with Theorem 1, our approach achieves the best known problem-dependent regret guarantees in the universal online learning problem. In the end, we emphasize again that our approach is efficient as it requires ${\\mathcal{O}}(\\log T)$ base learners and only 1 gradient query in each round. ", "page_idx": 8}, {"type": "text", "text": "4.2 Application to Stochastically Extended Adversarial (SEA) Model ", "text_level": 1, "page_idx": 8}, {"type": "text", "text": "Stochastically extended adversarial (SEA) model [Sachs et al., 2022] interpolates between stochastic and adversarial online convex optimization. Formally, it assumes that the online function $f_{t}(\\cdot)$ is sampled stochastically from an adversarially chosen distribution $\\mathcal{F}_{t}$ . Denoting by $F_{t}(\\cdot)\\triangleq\\mathbb{E}_{f_{t}\\sim\\mathcal{F}_{t}}[f_{t}(\\cdot)]$ the expected function, two quantities capture the essential characteristics of the SEA model: ", "page_idx": 8}, {"type": "equation", "text": "$$\nr_{1:T}^{2}\\triangleq\\sum_{t=1}^{T}\\operatorname*{max}_{\\mathbf{x}\\in\\mathcal{X}}\\mathbb{E}_{f_{t}\\sim\\mathcal{F}_{t}}\\left[\\left\\|\\nabla f_{t}(\\mathbf{x})-\\nabla F_{t}(\\mathbf{x})\\right\\|^{2}\\right],\\Sigma_{1:T}^{2}\\triangleq\\mathbb{E}\\left[\\sum_{t=2}^{T}\\operatorname*{sup}_{\\mathbf{x}\\in\\mathcal{X}}\\left\\|\\nabla F_{t}(\\mathbf{x})-\\nabla F_{t-1}(\\mathbf{x})\\right\\|^{2}\\right],\n$$", "text_format": "latex", "page_idx": 8}, {"type": "text", "text": "where $\\sigma_{1:T}^{2}$ is the variance in sampling $f_{t}(\\cdot)$ from $\\mathcal{F}_{t}(\\cdot)$ and $\\Sigma_{1:T}^{2}$ is the variation of $\\{F_{t}(\\cdot)\\}_{t\\in[T]}$ . Sachs et al. [2022] initiated the study of the SEA model. For smooth expected functions $\\{F_{t}(\\cdot)\\}_{t=1}^{T}$ , they achieved the optimal $\\mathcal{O}(\\sqrt{\\sigma_{1:T}^{2}+\\Sigma_{1:T}^{2}})$ regret for convex expected functions, and $\\mathcal{O}((\\sigma_{\\mathrm{max}}^{2}+$ $\\Sigma_{\\mathrm{max}}^{2})\\log T)$ in the strongly convex case, where $\\begin{array}{r}{\\sigma_{\\operatorname*{max}}^{2}\\triangleq\\operatorname*{max}_{t\\in[T]}\\operatorname*{max}_{\\mathbf{x}\\in\\mathcal{X}}\\mathbb{E}_{f_{t}\\sim\\mathcal{F}_{t}}[\\Vert\\nabla f_{t}(\\mathbf{x})-\\,]}\\end{array}$ $\\nabla F_{t}(\\mathbf{x})\\|^{2}]$ and $\\begin{array}{r}{\\Sigma_{\\mathrm{max}}^{2}\\triangleq\\operatorname*{max}_{t\\in[T]}\\operatorname*{sup}_{\\mathbf{x}\\in\\mathcal{X}}\\|\\nabla F_{t}(\\mathbf{x})-\\nabla F_{t-1}(\\mathbf{x})\\|^{2}}\\end{array}$ . Subsequently, Chen et al. [2024] improved the strongly convex regret to $\\mathcal{O}((\\sigma_{\\mathrm{max}}^{2}+\\Sigma_{\\mathrm{max}}^{2})\\log((\\sigma_{1:T}^{2}+\\Sigma_{1:T}^{2})/(\\sigma_{\\mathrm{max}}^{2}+\\Sigma_{\\mathrm{max}}^{2})))$ and obtained $\\mathcal{O}(d\\log(\\sigma_{1:T}^{2}+\\Sigma_{1:T}^{2}))$ regret for exp-concave individual functions $\\{f_{t}(\\cdot)\\}_{t=1}^{T}$ . ", "page_idx": 8}, {"type": "text", "text": "The gradient variation is essential in connecting the stochastic and adversarial optimization [Chen et al., 2023, Lemma 4], which is also restated in (C.2). Therefore, universal gradient-variation regret can be applied to this problem, achieving the same best known bounds as Chen et al. [2024], with a single algorithm. Table 2 compares our results with existing ones. The following theorem presents our results formally, with the corresponding proof provided in Appendix C.2. ", "page_idx": 8}, {"type": "table", "img_path": "yO5DVyCHZR/tmp/61858a64a594eb55f71eb8ef99745a7fc4a65539a2a94341e697a308e3b0e164.jpg", "table_caption": ["Table 2: Comparisons of our results with existing ones. The second column presents the regret bounds, where $\\sigma_{1:T}^{2}$ and $\\Sigma_{1:T}^{2}$ represent the stochastic and adversarial statistics of the SEA problem. The last column indicates whether the results can be achieved by a single algorithm (i.e., suitable in the universal setup). We achieve the same state-of-the-art guarantees as Chen et al. [2024] using one single algorithm. "], "table_footnote": [], "page_idx": 9}, {"type": "text", "text": "Theorem 3. Under Assumption $^{\\,l}$ and smoothness of $F_{t}(\\cdot)$ for any $t\\,\\in\\,[T]$ : if $F_{t}(\\cdot)$ is convex, Algorithm $^{\\,l}$ achieves $\\mathcal{O}(\\sqrt{\\sigma_{1:T}^{2}+\\Sigma_{1:T}^{2}})$ ; $i f\\,f_{t}(\\cdot)$ is exp-concave, it achieves $\\mathcal{O}(d\\log(\\sigma_{1:T}^{2}+\\Sigma_{1:T}^{2}))$ ; and if $F_{t}(\\cdot)$ is strongly convex, it achieves $\\mathcal{O}((\\sigma_{\\operatorname*{max}}^{2}+\\Sigma_{\\operatorname*{max}}^{2})\\log((\\sigma_{1:T}^{2}+\\Sigma_{1:T}^{2})/(\\sigma_{\\operatorname*{max}}^{2}+\\Sigma_{\\operatorname*{max}}^{2})))$ ). ", "page_idx": 9}, {"type": "text", "text": "Theorem 3 requires exp-concavity of the individual function $f_{t}(\\cdot)$ rather than the expected function $F_{t}(\\cdot)$ . This assumption is also used by Chen et al. [2023] and common in the studies of stochastic exp-concave optimization [Mahdavi et al., 2015, Koren and Levy, 2015]. ", "page_idx": 9}, {"type": "text", "text": "4.3 Discussion on Comparison with Correction-based Approach ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "In this part, we discuss the technical comparison with the previous correction-based approach [Yan et al., 2023]. Compared with their approach, ours is simpler and achieves the optimal universal problem-dependent regret (Theorem 1 and Theorem 2) and the best known guarantees in the SEA model (Theorem 3). Although not providing guarantees as favorable as ours, Yan et al. [2023] can control the overall algorithmic stability (i.e., $\\|\\bar{\\mathbf{x}_{t}}\\!-\\!\\mathbf{x}_{t-1}\\|^{2})$ using collaborative online ensemble [Zhao et al., 2024], which is necessary in achieving fast rates in multi-player games [Syrgkanis et al., 2015]. For example, in a min-max game $\\begin{array}{r}{\\operatorname*{min}_{\\mathbf{x}\\in\\bar{\\boldsymbol{x}}}\\operatorname*{max}_{\\mathbf{y}\\in\\mathcal{Y}}\\mathbf{x}^{\\top}A\\mathbf{y}}\\end{array}$ , where $A$ is a game matrix, since $A$ is unknown, the Nash equilibrium is typically computed through repeated play, i.e., player-x and player-y select $\\{\\mathbf{x}_{t}\\}_{t=1}^{T}$ and $\\{\\mathbf{y}_{t}\\}_{t=1}^{T}$ sequentially to approach the Nash equilibrium. For player- $\\mathbf{x}$ , in the $t$ -th round, it suffers a loss $\\mathbf{x}_{t}^{\\top}A\\mathbf{y}_{t}$ and receives the gradient $A\\mathbf{y}_{t}$ . Similarly, player-y suffers $-{\\mathbf x}_{t}^{\\top}A{\\mathbf y}_{t}$ and receives $-A{\\bf x}_{t}$ . For player- $\\mathbf{\\nabla}_{\\mathbf{x}}$ , if it updates via OOMD, its gradient-variation regret contains $\\|A\\mathbf{y}_{t}-A\\mathbf{y}_{t-1}\\|^{2}$ , which includes the stability of player-y. In this case, to achieve fast rates, we indeed need to control the algorithm stability like $\\r_{\\parallel\\mathbf{x}_{t}}-\\r_{\\mathbf{x}_{t-1}}\\r_{\\parallel^{2}}$ and $\\|\\mathbf{y}_{t}-\\mathbf{y}_{t-1}\\|^{2}$ . This can be done by Yan et al. [2023] while this work cannot since we do not directly control the algorithmic stability. Interested readers can refer to Appendix A.2 in Yan et al. [2023] for more details. ", "page_idx": 9}, {"type": "text", "text": "5 Conclusion ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "In this work, we investigate universal online learning with gradient-variation regret. We propose a simple two-layer online ensemble approach that not only achieves the optimal $O(\\frac{1}{\\lambda}\\log^{2}\\!V_{T})$ , $\\textstyle{\\mathcal{O}}({\\frac{d}{\\alpha}}\\log V_{T})$ , and $O(\\sqrt{V_{T}})$ regret simultaneously for $\\lambda$ -strongly convex, $\\alpha$ -exp-concave, and convex functions and is efficient with ${\\mathcal{O}}(\\log T)$ base learners and only 1 gradient query per round. This is done via the negative Bregman divergence term from linearization and the useful smoothness property of $\\|\\nabla f(\\mathbf{x})-\\bar{\\nabla}f(\\mathbf{y})\\|^{2}\\overset{=}{\\leq}2L\\mathcal{D}_{f}(\\bar{\\mathbf{y}_{,}}\\mathbf{x})$ . We further validate the effectiveness of our approach and results by implying the optimal universal small-loss regret directly in analysis and achieving the best known results in the stochastically extended adversarial model. ", "page_idx": 9}, {"type": "text", "text": "Two future directions are worth investigating. The first is to reduce the number of projections to only 1 in each round [Mhammedi et al., 2019, Zhao et al., 2022, Yang et al., 2024], thereby further improving the computational efficiency. The second direction involves extending our algorithm and results to the unconstrained setup [Orabona and P\u00b4al, 2016, Cutkosky and Orabona, 2018, Jacobsen and Cutkosky, 2022], broadening its applicability across a wider range of scenarios. ", "page_idx": 9}, {"type": "text", "text": "Acknowledgements ", "text_level": 1, "page_idx": 10}, {"type": "text", "text": "This research was supported by National Science and Technology Major Project (2022ZD0114802), NSFC (62176117), and JiangsuSF (BK20220776). Peng Zhao was supported in part by the Xiaomi Foundation. ", "page_idx": 10}, {"type": "text", "text": "References ", "text_level": 1, "page_idx": 10}, {"type": "text", "text": "J. Abernethy, P. L. Bartlett, A. Rakhlin, and A. Tewari. Optimal strategies and minimax lower bounds for online convex games. In Proceedings of the 21st Annual Conference on Learning Theory (COLT), pages 414\u2013424, 2008.   \nN. Cesa-Bianchi and G. Lugosi. Prediction, Learning, and Games. Cambridge University Press, 2006.   \nL. Chen, H. Luo, and C. Wei. Impossible tuning made possible: A new expert algorithm and its applications. In Proceedings of the 34th Annual Conference on Learning Theory (COLT), pages 1216\u20131259, 2021.   \nS. Chen, W.-W. Tu, P. Zhao, and L. Zhang. Optimistic online mirror descent for bridging stochastic and adversarial online convex optimization. In Proceedings of the 40th International Conference on Machine Learning (ICML), pages 5002\u20135035, 2023.   \nS. Chen, Y.-J. Zhang, W.-W. Tu, P. Zhao, and L. Zhang. Optimistic online mirror descent for bridging stochastic and adversarial online convex optimization. Journal of Machine Learning Research, 25 (178):1 \u2013 62, 2024.   \nC. Chiang, T. Yang, C. Lee, M. Mahdavi, C. Lu, R. Jin, and S. Zhu. Online optimization with gradual variations. In Proceedings of the 25th Annual Conference on Learning Theory (COLT), pages 6.1\u20136.20, 2012.   \nA. Cutkosky and F. Orabona. Black-box reductions for parameter-free online learning in Banach spaces. In Proceedings of the 31st Annual Conference on Learning Theory (COLT), pages 1493\u2013 1529, 2018.   \nA. Daniely, A. Gonen, and S. Shalev-Shwartz. Strongly adaptive online learning. In Proceedings of the 32nd International Conference on Machine Learning (ICML), pages 1405\u20131411, 2015.   \nP. Gaillard, G. Stoltz, and T. van Erven. A second-order bound with excess losses. In Proceedings of the 27th Annual Conference on Learning Theory (COLT), pages 176\u2013196, 2014.   \nE. Hazan. Introduction to Online Convex Optimization. Foundations and Trends in Optimization, 2 (3-4):157\u2013325, 2016.   \nE. Hazan and C. Seshadhri. Adaptive algorithms for online decision problems. Electronic Colloquium on Computational Complexity (ECCC), 14(088), 2007.   \nE. Hazan, A. Agarwal, and S. Kale. Logarithmic regret algorithms for online convex optimization. Machine Learning, 69(2-3):169\u2013192, 2007.   \nA. Jacobsen and A. Cutkosky. Parameter-free mirror descent. In Proceedings of the 35th Annual Conference on Learning Theory (COLT), pages 4160\u20134211, 2022.   \nS. Ji and J. Ye. An accelerated gradient method for trace norm minimization. In Proceedings of the 26th International Conference on Machine Learning (ICML), pages 457\u2013464, 2009.   \nP. Joulani, A. Raj, A. Gyorgy, and C. Szepesv\u00b4ari. A simpler approach to accelerated optimization: Iterative averaging meets optimism. In Proceedings of the 37th International Conference on Machine Learning (ICML), pages 4984\u20134993, 2020.   \nT. Koren and K. Y. Levy. Fast rates for exp-concave empirical risk minimization. In Advances in Neural Information Processing Systems 28 (NIPS), pages 1477\u20131485, 2015.   \nM. Li, T. Zhang, Y. Chen, and A. J. Smola. Efficient mini-batch training for stochastic optimization. In Proceedings of the 20th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining (KDD), pages 661\u2013670, 2014.   \nH. Luo and R. E. Schapire. Achieving all with no parameters: AdaNormalHedge. In Proceedings of the 28th Annual Conference on Learning Theory (COLT), pages 1286\u20131304, 2015.   \nM. Mahdavi, L. Zhang, and R. Jin. Lower and upper bounds on the generalization of stochastic exponentially concave optimization. In Proceedings of the 28th Annual Conference on Learning Theory (COLT), pages 1305\u20131320, 2015.   \nZ. Mhammedi, W. M. Koolen, and T. van Erven. Lipschitz adaptivity with multiple learning rates in online learning. In Proceedings of the 32nd Annual Conference on Learning Theory (COLT), pages 2490\u20132511, 2019.   \nY. Nesterov. Lectures on Convex Optimization, volume 137. Springer, 2018.   \nF. Orabona. A modern introduction to online learning. ArXiv preprint, arXiv:1912.13213, 2019.   \nF. Orabona and D. P\u00b4al. Coin betting and parameter-free online learning. In Advances in Neural Information Processing Systems 29 (NIPS), pages 577\u2013585, 2016.   \nF. Orabona, N. Cesa-Bianchi, and C. Gentile. Beyond logarithmic bounds in online learning. In Proceedings of the 15th International Conference on Artificial Intelligence and Statistics (AISTATS), pages 823\u2013831, 2012.   \nE. Ordentlich and T. M. Cover. The cost of achieving the best portfolio in hindsight. Mathematics of Operations Research, 23(4):960\u2013982, 1998.   \nA. Rakhlin and K. Sridharan. Online learning with predictable sequences. In Proceedings of the 26th Annual Conference on Learning Theory (COLT), pages 993\u20131019, 2013.   \nS. Sachs, H. Hadiji, T. van Erven, and C. Guzm\u00b4an. Between stochastic and adversarial online convex optimization: Improved regret bounds via smoothness. In Advances in Neural Information Processing Systems 35 (NeurIPS), pages 691\u2013702, 2022.   \nS. Sachs, H. Hadiji, T. van Erven, and C. Guzm\u00b4an. Accelerated rates between stochastic and adversarial online convex optimization. ArXiv preprint, arXiv:2303.03272, 2023.   \nN. Srebro, K. Sridharan, and A. Tewari. Smoothness, low noise and fast rates. In Advances in Neural Information Processing Systems 23 (NIPS), pages 2199\u20132207, 2010.   \nV. Syrgkanis, A. Agarwal, H. Luo, and R. E. Schapire. Fast convergence of regularized learning in games. In Advances in Neural Information Processing Systems 28 (NIPS), pages 2989\u20132997, 2015.   \nT. van Erven and W. M. Koolen. MetaGrad: Multiple learning rates in online learning. In Advances in Neural Information Processing Systems 29 (NIPS), pages 3666\u20133674, 2016.   \nG. Wang, S. Lu, and L. Zhang. Adaptivity and optimality: A universal algorithm for online convex optimization. In Proceedings of the 35th Conference on Uncertainty in Artificial Intelligence (UAI), pages 659\u2013668, 2019.   \nC. Wei, Y. Hong, and C. Lu. Tracking the best expert in non-stationary stochastic environments. In Advances in Neural Information Processing Systems 29 (NIPS), pages 3972\u20133980, 2016.   \nY.-H. Yan, P. Zhao, and Z.-H. Zhou. Universal online learning with gradient variations: A multi-layer online ensemble approach. In Advances in Neural Information Processing Systems 36 (NeurIPS), pages 37682\u201337715, 2023.   \nT. Yang, M. Mahdavi, R. Jin, and S. Zhu. Regret bounded by gradual variation for online convex optimization. Machine Learning, 95(2):183\u2013223, 2014.   \nW. Yang, Y. Wang, P. Zhao, and L. Zhang. Universal online convex optimization with 1 projection per round. ArXiv preprint, arXiv:2405.19705, 2024.   \nL. Zhang, S. Lu, and Z.-H. Zhou. Adaptive online learning in dynamic environments. In Advances in Neural Information Processing Systems 31 (NeurIPS), pages 1330\u20131340, 2018.   \nL. Zhang, T.-Y. Liu, and Z.-H. Zhou. Adaptive regret of convex and smooth functions. In Proceedings of the 36th International Conference on Machine Learning (ICML), pages 7414\u20137423, 2019.   \nL. Zhang, G. Wang, J. Yi, and T. Yang. A simple yet universal strategy for online convex optimization. In Proceedings of the 39th International Conference on Machine Learning (ICML), pages 26605\u2013 26623, 2022a.   \nM. Zhang, P. Zhao, H. Luo, and Z.-H. Zhou. No-regret learning in time-varying zero-sum games. In Proceedings of the 39th International Conference on Machine Learning (ICML), pages 26772\u2013 26808, 2022b.   \nP. Zhao. Online Ensemble Theories and Methods for Robust Online Learning. PhD thesis, Nanjing University, Nanjing, China, 2021. Advisor: Zhi-Hua Zhou.   \nP. Zhao, Y.-J. Zhang, L. Zhang, and Z.-H. Zhou. Dynamic regret of convex and smooth functions. In Advances in Neural Information Processing Systems 33 (NeurIPS), pages 12510\u201312520, 2020.   \nP. Zhao, Y.-F. Xie, L. Zhang, and Z.-H. Zhou. Efficient methods for non-stationary online learning. In Advances in Neural Information Processing Systems 35 (NeurIPS), pages 11573\u201311585, 2022.   \nP. Zhao, Y.-J. Zhang, L. Zhang, and Z.-H. Zhou. Adaptivity and non-stationarity: Problem-dependent dynamic regret for online convex optimization. Journal of Machine Learning Research, 25(98):1 \u2013 52, 2024.   \nZ.-H. Zhou. Ensemble Methods: Foundations and Algorithms. Chapman & Hall/CRC Press, 2012.   \nM. Zinkevich. Online convex programming and generalized infinitesimal gradient ascent. In Proceedings of the 20th International Conference on Machine Learning (ICML), pages 928\u2013936, 2003. ", "page_idx": 10}, {"type": "text", "text": "", "page_idx": 11}, {"type": "text", "text": "", "page_idx": 12}, {"type": "text", "text": "A On Smoothness Assumption ", "text_level": 1, "page_idx": 13}, {"type": "text", "text": "In this section, we propose a relaxation of the smoothness requirement to a slightly larger domain than the feasible domain $\\mathcal{X}$ , in contrast to the whole $\\mathbb{R}^{d}$ space as in Assumption 2. The relaxed smoothness assumption is detailed in the following. ", "page_idx": 13}, {"type": "text", "text": "Assumption 3 (Relaxed Smoothness). Under the condition of $\\|\\nabla f_{t}(\\mathbf{x})\\|\\leq G$ for any $\\mathbf{x}\\in\\mathcal{X}$ and $t\\in[T]$ , all online functions are $L$ -smooth: $\\|\\nabla f_{t}(\\mathbf{x})-\\nabla f_{t}(\\mathbf{y})\\|\\leq L\\|\\mathbf{x}-\\mathbf{y}\\|$ for any $t\\in[T]$ and $\\mathbf{x},\\mathbf{y}\\in\\mathcal{X}_{+}$ , where $\\mathcal{X}_{+}\\triangleq\\{\\mathbf{x}+\\mathbf{b}\\,|\\,\\mathbf{x}\\in\\mathcal{X},\\mathbf{b}\\in G/L\\cdot\\mathbb{B}\\}$ and $\\mathbb{B}\\triangleq\\left\\{\\mathbf{x}\\mid\\lVert\\mathbf{x}\\rVert\\leq1\\right\\}$ is a unit ball. ", "page_idx": 13}, {"type": "text", "text": "The domain of Assumption 3 is slightly larger than $\\mathcal{X}$ \u2014 for any ${\\bf x}_{+}\\in\\mathcal{X}_{+}$ , we can always find an $\\mathbf{x}\\in\\mathcal{X}$ such that $\\|\\mathbf{x}_{+}-\\mathbf{x}\\|\\leq G/L$ . In this work, one of the key technical contributions is to handle the empirical gradient variation via a useful smoothness property (Proposition 1). We show in the following that this condition can be satisfied by requiring only Assumption 3. ", "page_idx": 13}, {"type": "text", "text": "Lemma 1. Under Assumption $^{\\,l}$ , for any online function $f(\\cdot)$ satisfying Assumption 3, it holds that $\\|\\nabla f(\\mathbf{x})-\\nabla f(\\mathbf{y})\\|^{2}\\leq2{\\bar{L}}D_{f}(\\mathbf{y},\\mathbf{\\bar{x}})$ for any x, $\\mathbf y\\in\\mathcal X$ . ", "page_idx": 13}, {"type": "text", "text": "Proof. To begin with, we present the self-bounding property [Srebro et al., 2010], which is useful in proving our result \u2014 if a function $f:\\mathbb{R}^{d}\\mapsto\\mathbb{R}$ is $L$ -smooth and bounded from below, then for any $\\dot{\\mathbf{x}}\\in\\mathbb{R}^{\\breve{d}}$ , it holds that ", "page_idx": 13}, {"type": "equation", "text": "$$\n\\|\\nabla f(\\mathbf{x})\\|^{2}\\leq2L\\left(f(\\mathbf{x})-\\operatorname*{inf}_{\\mathbf{y}\\in\\mathbb{R}^{d}}f(\\mathbf{y})\\right).\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "Next, we aim to prove that if we only need (A.1) on a bounded domain $\\mathcal{X}$ , we require smoothness only on a slightly larger domain than $\\mathcal{X}$ . To see this, we delve into the proof of the self-bounding property. Specifically, for any $\\mathbf{x},\\mathbf{v}\\in\\mathbb{R}^{d}$ , it holds that ", "page_idx": 13}, {"type": "equation", "text": "$$\n\\langle-\\nabla f(\\mathbf{x}),\\mathbf{v}\\rangle-{\\frac{L}{2}}\\|\\mathbf{v}\\|^{2}\\leq f(\\mathbf{x})-f(\\mathbf{x}+\\mathbf{v})\\leq f(\\mathbf{x})-\\operatorname*{inf}_{\\mathbf{y}\\in\\mathbb{R}^{d}}f(\\mathbf{y}),\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "where the first step requires smoothness on $\\mathbf{x}$ and $\\mathbf{x}+\\mathbf{v}$ . Consequently, by taking maximization over $\\mathbf{v}$ , it holds that ", "page_idx": 13}, {"type": "equation", "text": "$$\nf(\\mathbf{x})-\\operatorname*{inf}_{\\mathbf{y}\\in\\mathbb{R}^{d}}f(\\mathbf{y})\\geq\\operatorname*{sup}_{\\mathbf{v}\\in\\mathbb{R}^{d}}\\langle-\\nabla f(\\mathbf{x}),\\mathbf{v}\\rangle-\\frac{L}{2}\\|\\mathbf{v}\\|^{2}=\\frac{1}{2L}\\|\\nabla f(\\mathbf{x})\\|^{2},\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "which leads to the self-bounding property (A.1) by taking $\\begin{array}{r}{\\mathbf{v}=-\\frac{1}{L}\\nabla f(\\mathbf{x})}\\end{array}$ . The above proof is from Theorem 4.23 of Orabona [2019]. This means that for the self-bounding property, we only require the smoothness to hold for any $\\mathbf{x}\\in\\mathcal{X}$ and $\\begin{array}{r}{\\mathbf{x}-\\frac{1}{L}\\nabla f(\\mathbf{x})}\\end{array}$ . Under Assumption 1, this can be satisfied by requiring smoothness on a slightly larger domain than $\\mathcal{X}$ , namely, $\\mathcal{X}_{+}\\triangleq\\{\\mathbf{x}\\!+\\!\\mathbf{b}|\\mathbf{x}\\!\\in\\!\\mathcal{X},\\mathbf{b}\\in G/L\\!\\cdot\\!\\mathbb{B}\\}$ . ", "page_idx": 13}, {"type": "text", "text": "Now we are ready to prove the final result. To begin with, we define a surrogate function of $g(\\mathbf{x})\\triangleq f(\\mathbf{x})-\\langle\\nabla f(\\mathbf{x}_{0}),\\mathbf{x}\\rangle$ for any $\\mathbf{x}\\in\\mathcal{X}$ , where $\\mathbf{x}_{0}\\in\\mathcal{X}$ . Due to the above property we have just proved, by requiring smoothness on $\\chi_{+}$ , we have ", "page_idx": 13}, {"type": "equation", "text": "$$\n\\|\\nabla g(\\mathbf{x})\\|^{2}\\leq2L\\left(g(\\mathbf{x})-\\operatorname*{inf}_{\\mathbf{y}\\in\\mathbb{R}^{d}}g(\\mathbf{y})\\right).\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "Denoting by $\\mathbf{y}^{\\star}\\in\\arg\\operatorname*{min}_{\\mathbf{y}\\in\\mathbb{R}^{d}}g(\\mathbf{y})$ , the above inequality equals to ", "page_idx": 13}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\|\\nabla f(\\mathbf{x})-\\nabla f(\\mathbf{x}_{0})\\|^{2}\\leq2L\\left(f(\\mathbf{x})-\\langle\\nabla f(\\mathbf{x}_{0}),\\mathbf{x}\\rangle-f(\\mathbf{y}^{\\star})+\\langle\\nabla f(\\mathbf{x}_{0}),\\mathbf{y}^{\\star}\\rangle\\right)}\\\\ &{\\qquad\\qquad\\qquad=2L(f(\\mathbf{x})-f(\\mathbf{y}^{\\star})-\\langle\\nabla f(\\mathbf{x}_{0}),\\mathbf{x}-\\mathbf{y}^{\\star}\\rangle),}\\end{array}\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "due to the definition of $g(\\cdot)$ . The proof using the self-bounding property is from Theorem 2.1.5 of Nesterov [2018]. Finally, we note that $g(\\cdot)$ is minimized at $\\mathbf{y}^{\\star}\\,=\\,\\mathbf{x}_{0}$ , leading to $\\|\\nabla f(\\mathbf{x})\\ -$ $\\nabla f(\\mathbf{x}_{0})\\|^{2}\\leq2L\\mathcal{D}_{f}^{\\top}(\\mathbf{x}_{0},\\mathbf{x})$ for any $\\mathbf{x},\\mathbf{x}_{0}\\in\\mathcal{X}$ , which finishes the proof. \u53e3 ", "page_idx": 13}, {"type": "text", "text": "B Proof for Section 3 ", "text_level": 1, "page_idx": 13}, {"type": "text", "text": "In this section, we provide the proof of Theorem 1, our main theoretical result for the optimal universal gradient-variation regret. ", "page_idx": 13}, {"type": "text", "text": "Proof. We first give different decompositions of the regret for different curvature types, then analyze the meta and base regret, and finally combine them to achieve the regret bound. For simplicity, we define $\\mathbf{g}_{t}\\triangleq\\nabla f_{t}(\\mathbf{x}_{t})$ and ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\bar{V}_{T}\\triangleq\\sum_{t=2}^{T}\\|\\nabla f_{t}(\\mathbf{x}_{t})-\\nabla f_{t-1}(\\mathbf{x}_{t-1})\\|^{2}\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "for short. Using the analysis in Section 3.2, the empirical gradient variation can bounded as ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\begin{array}{l}{\\displaystyle\\bar{V}_{T}\\leq3\\sum_{t=2}^{T}\\|\\nabla f_{t}(\\mathbf{x}_{t})-\\nabla f_{t}(\\mathbf{x}^{\\star})\\|^{2}+3\\sum_{t=2}^{T}\\|\\nabla f_{t}(\\mathbf{x}^{\\star})-\\nabla f_{t-1}(\\mathbf{x}^{\\star})\\|^{2}}\\\\ {\\displaystyle+3\\sum_{t=2}^{T}\\|\\nabla f_{t-1}(\\mathbf{x}^{\\star})-\\nabla f_{t-1}(\\mathbf{x}_{t-1})\\|^{2}\\leq6L\\displaystyle\\sum_{t=2}^{T}\\mathcal{D}_{f_{t}}(\\mathbf{x}^{\\star},\\mathbf{x}_{t})+3V_{T}+6L\\displaystyle\\sum_{t=2}^{T}\\boldsymbol{D}_{f_{t-1}}(\\mathbf{x}^{\\star},\\mathbf{x}_{t-1})}\\\\ {\\displaystyle\\leq3V_{T}+12L\\displaystyle\\sum_{t=1}^{T}\\mathcal{D}_{f_{t}}(\\mathbf{x}^{\\star},\\mathbf{x}_{t}).}\\end{array}\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "Regret Decomposition. Denoting by $\\begin{array}{r}{\\mathbf{x}^{\\star}\\in\\arg\\operatorname*{min}_{\\mathbf{x}\\in\\mathcal{X}}\\sum_{t\\in[T]}f_{t}(\\mathbf{x})}\\end{array}$ , for convex functions, we decompose the regret as ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\displaystyle\\mathrm{REG}_{T}=\\sum_{t=1}^{T}\\langle\\mathbf{g}_{t},\\mathbf{x}_{t}-\\mathbf{x}^{\\star}\\rangle-\\displaystyle\\sum_{t=1}^{T}\\mathcal{D}_{f_{t}}(\\mathbf{x}^{\\star},\\mathbf{x}_{t})}\\\\ &{\\displaystyle\\qquad=\\underbrace{\\sum_{t=1}^{T}\\langle\\mathbf{g}_{t},\\mathbf{x}_{t}-\\mathbf{x}_{t,i^{\\star}}\\rangle}_{\\mathrm{META-REG}}+\\underbrace{\\sum_{t=1}^{T}h_{t,i^{\\star}}^{c}\\big(\\mathbf{x}_{t,i^{\\star}}\\big)-\\displaystyle\\sum_{t=1}^{T}h_{t,i^{\\star}}^{c}\\big(\\mathbf{x}^{\\star}\\big)}_{\\mathrm{BASE-REG}}-\\sum_{t=1}^{T}\\mathcal{D}_{f_{t}}\\big(\\mathbf{x}^{\\star},\\mathbf{x}_{t}\\big),}\\end{array}\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "where $h_{t,i}^{\\mathrm{c}}(\\mathbf{x})\\triangleq\\langle\\mathbf{g}_{t},\\mathbf{x}\\rangle$ . For $\\alpha$ -exp-concave functions, we decompose the regret as ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\displaystyle\\mathbb{R}\\mathrm{EG}_{T}=\\sum_{t=1}^{T}\\bigl\\langle\\mathbf{g}_{t},\\mathbf{x}_{t}-\\mathbf{x}^{\\star}\\bigr\\rangle-\\frac{1}{2}\\sum_{t=1}^{T}{\\mathcal{D}}_{f_{t}}(\\mathbf{x}^{\\star},\\mathbf{x}_{t})-\\frac{1}{2}\\sum_{t=1}^{T}{\\mathcal{D}}_{f_{t}}(\\mathbf{x}^{\\star},\\mathbf{x}_{t})\\qquad\\qquad(\\mathbf{by}\\,(\\mathbf{3},\\mathbf{3}))}\\\\ &{\\displaystyle\\qquad\\leq\\sum_{t=1}^{T}\\bigl\\langle\\mathbf{g}_{t},\\mathbf{x}_{t}-\\mathbf{x}^{\\star}\\bigr\\rangle-\\frac{\\alpha}{4}\\sum_{t=1}^{T}\\bigl\\langle\\mathbf{g}_{t},\\mathbf{x}_{t}-\\mathbf{x}^{\\star}\\bigr\\rangle^{2}-\\frac{1}{2}\\sum_{t=1}^{T}{\\mathcal{D}}_{f_{t}}(\\mathbf{x}^{\\star},\\mathbf{x}_{t})}\\\\ &{\\displaystyle\\qquad\\leq\\underbrace{\\sum_{t=1}^{T}\\bigl\\langle\\mathbf{g}_{t},\\mathbf{x}_{t}-\\mathbf{x}_{t,i^{\\star}}\\bigr\\rangle-\\frac{\\alpha_{t}}{4}\\sum_{t=1}^{T}\\bigl\\langle\\mathbf{g}_{t},\\mathbf{x}_{t}-\\mathbf{x}_{t,i^{\\star}}\\bigr\\rangle^{2}}_{\\displaystyle\\mathrm{Merta}\\;\\mathrm{Ream}}\\qquad\\qquad(\\mathbf{by}\\,\\,\\alpha_{i}\\cdot\\leq\\alpha\\leq2\\alpha_{i^{\\star}})}\\\\ &{\\displaystyle\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad}\\\\ &{\\displaystyle\\qquad\\qquad+\\sum_{t=1}^{T}h_{t,i^{\\star}}^{\\mathrm{op}}(\\mathbf{x}_{t,i^{\\star}})-\\sum_{t=1}^{T}h_{t,i^{\\star}}^{\\mathrm{op}}(\\mathbf{x}^{\\star})-\\frac{1}{2}\\sum_{t=1}^{T}{\\mathcal{D}}_{f_{t}}(\\mathbf{x}^{\\star},\\mathbf{x}_{t}),\\qquad\\qquad(\\mathbf{B}.3)}\\end{array}\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "where the second step is due to the definitions of exp-concavity and Bregman divergence and the last step is due to the definition of the surrogate function $\\begin{array}{r}{h_{t,i}^{\\mathrm{exp}}(\\mathbf{x})\\triangleq\\langle\\mathbf{g}_{t},\\mathbf{x}\\rangle+\\frac{\\alpha_{i}}{4}\\langle\\nabla f_{t}(\\mathbf{x}_{t}),\\mathbf{x}-\\mathbf{x}_{t}\\rangle^{2}}\\end{array}$ , where $\\alpha_{i}\\in\\mathcal{H}$ , defined in (2.1). For $\\lambda$ -strongly convex functions, following the similar decomposition in the exp-concavity case, we obtain ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\begin{array}{r l r}{\\lefteqn{\\mathrm{REG}_{T}\\leq\\underbrace{\\sum_{t=1}^{T}\\langle\\mathbf g_{t},\\mathbf x_{t}-\\mathbf x_{t,i^{\\star}}\\rangle-\\frac{\\lambda_{i^{\\star}}}{4}\\sum_{t=1}^{T}\\|\\mathbf x_{t}-\\mathbf x_{t,i^{\\star}}\\|^{2}}_{\\mathrm{META-REG}}}\\quad}&{\\quad\\mathrm{(by~}\\lambda_{i^{\\star}}\\leq\\lambda\\leq2\\lambda_{i^{\\star}})}\\\\ &{}&{\\quad+\\underbrace{\\sum_{t=1}^{T}h_{t,i^{\\star}}^{\\mathrm{sc}}\\big(\\mathbf x_{t,i^{\\star}}\\big)-\\displaystyle\\sum_{t=1}^{T}h_{t,i^{\\star}}^{\\mathrm{sc}}\\big(\\mathbf x^{\\star}\\big)}_{\\mathrm{U}_{t}=1}-\\frac{1}{2}\\displaystyle\\sum_{t=1}^{T}\\mathcal D_{f_{t}}\\big(\\mathbf x^{\\star},\\mathbf x_{t}\\big),\\qquad\\quad\\mathrm{(B.4)}}\\end{array}\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "due to the definition of the surrogate $\\begin{array}{r}{h_{t,i}^{\\mathrm{sc}}(\\mathbf{x})\\triangleq\\langle\\mathbf{g}_{t},\\mathbf{x}\\rangle+\\frac{\\lambda_{i}}{4}\\|\\mathbf{x}-\\mathbf{x}_{t}\\|^{2}}\\end{array}$ , where $\\lambda_{i}\\in\\mathcal{H}$ in (2.1). ", "page_idx": 14}, {"type": "text", "text": "Meta Regret Analysis. We adopt OPTIMISTIC-ADAPT-ML-PROD [Wei et al., 2016] as the meta learner, and present its regret analysis below for self-containedness. ", "page_idx": 15}, {"type": "text", "text": "Lemma 2 (Theorem 3.4 of Wei et al. [2016]). Denoting by $\\scriptstyle{\\mathbf{\\mathit{p}}}_{t}$ the weights of the algorithm, $\\ell_{t}$ the loss vector, and $m_{t,i}$ the optimism, by choosing the learning rate optimally as ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\varepsilon_{t,i}=\\operatorname*{min}\\left\\{\\frac{1}{8},\\sqrt{\\frac{\\ln N}{\\sum_{s\\in[t]}(r_{s,i}-m_{s,i})^{2}}}\\right\\},\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "the regret of OPTIMISTIC-ADAPT-ML-PROD with respect to any expert $i\\in[N]$ satisfies ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\sum_{t=1}^{T}\\langle\\ell_{t},p_{t}-e_{i}\\rangle\\leq C_{0}\\sqrt{1+\\sum_{t=1}^{T}(r_{t,i}-m_{t,i})^{2}}+C_{1},\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "where $r_{t,i}=\\langle\\ell_{t},p_{t}-e_{i}\\rangle$ , $e_{i}$ denotes the $i$ -th standard basis vector, $\\begin{array}{r}{C_{0}=\\sqrt{\\ln{N}}+\\ln(1+\\frac{N}{e}(1+}\\end{array}$ $\\ln(T+1))/\\sqrt{\\ln N}$ , and $C_{1}={\\textstyle\\frac{1}{4}}(\\ln{N}+\\ln(1+{\\textstyle\\frac{N}{e}}(1+\\ln(T+1))))+2\\sqrt{\\ln{N}}+16\\ln{N}$ . ", "page_idx": 15}, {"type": "text", "text": "Here we adopt $\\ell_{t,i}=\\langle\\mathbf{g}_{t},\\mathbf{x}_{t,i}\\rangle$ such that $\\langle\\ell_{t},p_{t}-\\mathbf{e}_{i}\\rangle=\\langle\\mathbf{g}_{t},\\mathbf{x}_{t}-\\mathbf{x}_{t,i}\\rangle$ . Besides, since the number of base learners $N=\\mathcal{O}(\\log T)$ as explained in Section 2, the constants $C_{0}$ and $C_{1}$ are in the order of ${\\mathcal{O}}(\\log\\log T)$ and can be treated as ignorable constants, following previous convention [Luo and Schapire, 2015, Gaillard et al., 2014]. ", "page_idx": 15}, {"type": "text", "text": "For convex functions, we choose the optimism as $m_{t,i}=\\langle\\mathbf{g}_{t-1},\\mathbf{x}_{t}-\\mathbf{x}_{t,i}\\rangle$ for the index $i$ indicating the convex base learner. As explained in Section 3.1, although $\\mathbf{x}_{t}$ is unknown for now, we only require the scalar value of $\\langle\\mathbf{g}_{t-1},\\mathbf{x}_{t}\\rangle$ . Denoting by $z=\\langle\\mathbf{g}_{t-1},\\mathbf{x}_{t}\\rangle$ , it actually forms a fixed-point problem of $z=\\langle\\mathbf{g}_{t-1},\\mathbf{x}_{t}(z)\\rangle$ , where $\\mathbf{x}_{t}$ is a function of $z$ since $\\mathbf{x}_{t}$ depends on $p_{t,i},p_{t,i}$ relies on $m_{t,i}$ , and $m_{t,i}$ depends on $z$ . Such a one-dimensional fixed-point problem can be solved with an $\\mathcal{O}(1/T)$ approximation error through ${\\mathcal{O}}(\\log T)$ binary searches, and aggregating the approximate error over the whole time horizon will only incur an additive constant to the final regret. As a result, such an optimism setup is valid. Consequently, the meta regret in (B.2) can be bounded as ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\begin{array}{r l r}&{\\lefteqn{\\mathrm{META-REG\\le}C_{0}\\sqrt{1+\\displaystyle\\sum_{t=1}^{T}\\bigl\\langle\\mathbf g_{t}-\\mathbf g_{t-1},\\mathbf x_{t}-\\mathbf x_{t,i^{*}}\\bigr\\rangle^{2}}+C_{1}\\qquad}}&{\\mathrm{(by\\lemma~})}\\\\ &{\\leq C_{0}\\sqrt{1+D^{2}\\bar{V}_{T}}+C_{1}\\le C_{0}\\sqrt{1+3D^{2}V_{T}+12L D^{2}\\displaystyle\\sum_{t=1}^{T}\\bar{D}_{f_{t}}(\\mathbf x^{\\star},\\mathbf x_{t})}+C_{1}\\qquad\\mathrm{(by\\(B.}\\\\ &{\\le\\mathcal O(\\sqrt{V_{T}})+C_{0}\\sqrt{12L D^{2}\\displaystyle\\sum_{t=1}^{T}\\mathcal{D}_{f_{t}}(\\mathbf x^{\\star},\\mathbf x_{t})}\\le\\mathcal O(\\sqrt{V_{T}})+\\mathcal{O}(C_{2})+\\displaystyle\\frac{C_{0}}{2C_{2}}\\displaystyle\\sum_{t=1}^{T}\\mathcal{D}_{f_{t}}(\\mathbf x^{\\star},\\mathbf x_{t}),}}\\end{array}\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "where the second step adopts Assumption\u221a 1, the fourth step uses ${\\sqrt{a+b}}\\leq{\\sqrt{a}}+{\\sqrt{b}}$ for any $a,b\\ge0$ , the last step uses AM-GM inequality: $\\textstyle{\\sqrt{a b}}\\leq{\\frac{a x}{2}}+{\\frac{b}{2x}}$ for any $a,b,x>0$ . Note that $C_{2}$ is used to ensure the positive Bregman divergence term to be canceled and will be specified in the end. ", "page_idx": 15}, {"type": "text", "text": "For exp-concave functions, we choose the optimism as $m_{t,i}=0$ for indexes $i$ indicating exp-concave base learners. By Lemma 2, the meta regret in (B.3) can be bounded as ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\displaystyle\\mathtt{M E T A-R E G}\\leq C_{0}\\sqrt{1+\\sum_{t=1}^{T}\\langle\\mathbf{g}_{t},\\mathbf{x}_{t}-\\mathbf{x}_{t,i^{*}}\\rangle^{2}}-\\frac{\\alpha_{i^{*}}}{4}\\sum_{t=1}^{T}\\langle\\mathbf{g}_{t},\\mathbf{x}_{t}-\\mathbf{x}_{t,i^{*}}\\rangle^{2}+C_{1}}\\\\ &{\\displaystyle\\qquad\\qquad\\leq\\mathcal{O}(C_{3})+\\left(\\frac{C_{0}}{2C_{3}}-\\frac{\\alpha_{i^{*}}}{4}\\right)\\sum_{t=1}^{T}\\langle\\mathbf{g}_{t},\\mathbf{x}_{t}-\\mathbf{x}_{t,i^{*}}\\rangle^{2},}\\end{array}\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "where the last step omits the ignorable additive $C_{0}$ or $C_{1}$ terms and is due to AM-GM inequality. $C_{2}$   \nis a constant to be specified. ", "page_idx": 15}, {"type": "text", "text": "For strongly convex functions, we choose the optimism $m_{t,i}=0$ for indexes $i$ indicating strongly convex base learners. By Lemma 2, the meta regret in (B.4) can be bounded as ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\begin{array}{r l r}&{\\mathbf{META-REG}\\leq C_{0}\\sqrt{1+\\displaystyle\\sum_{t=1}^{T}\\langle\\mathbf{g}_{t},\\mathbf{x}_{t}-\\mathbf{x}_{t,i^{*}}\\rangle^{2}}-\\frac{\\lambda_{i^{*}}}{4}\\displaystyle\\sum_{t=1}^{T}\\|\\mathbf{x}_{t}-\\mathbf{x}_{t,i^{*}}\\|^{2}+C_{1}\\quad}&{\\mathrm{(by~Lemma~2)}}\\\\ &{\\leq C_{0}\\sqrt{1+D^{2}\\displaystyle\\sum_{t=1}^{T}\\|\\mathbf{x}_{t}-\\mathbf{x}_{t,i^{*}}\\|^{2}}-\\frac{\\lambda_{i^{*}}}{4}\\displaystyle\\sum_{t=1}^{T}\\|\\mathbf{x}_{t}-\\mathbf{x}_{t,i^{*}}\\|^{2}+C_{1}\\,\\mathrm{~(by~Assumption~1)}}\\\\ &{\\leq\\mathcal{O}(C_{4})+\\left(\\frac{C_{0}D^{2}}{2C_{4}}-\\frac{\\lambda_{i^{*}}}{4}\\right)\\displaystyle\\sum_{t=1}^{T}\\|\\mathbf{x}_{t}-\\mathbf{x}_{t,i^{*}}\\|^{2},}&{\\mathrm{(B.7)}}\\end{array}\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "where the last step omits the ignorable additive $C_{0}$ or $C_{1}$ terms and is due to AM-GM inequality. $C_{4}$   \nis a constant to be specified. ", "page_idx": 16}, {"type": "text", "text": "Base Regret Analysis. For convex functions, we implement Optimistic OGD (OOGD) on the convex base learner (indexed by $i$ ): ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathbf{x}_{t,i}=\\Pi_{\\mathcal{X}}[\\widehat{\\mathbf{x}}_{t,i}-\\eta_{t}\\mathbf{m}_{t}],\\quad\\widehat{\\mathbf{x}}_{t+1,i}=\\Pi_{\\mathcal{X}}[\\widehat{\\mathbf{x}}_{t,i}-\\eta_{t}\\nabla h_{t,i}^{\\mathrm{c}}(\\mathbf{x}_{t,i})].}\\end{array}\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "By choosing the step size as $\\begin{array}{r}{\\eta_{t}=\\operatorname*{min}\\{D/\\sqrt{1+\\sum_{s=2}^{t-1}\\|\\nabla h_{s,i}^{\\mathrm{c}}(\\mathbf{x}_{s,i})-\\nabla h_{s-1,i}^{\\mathrm{c}}(\\mathbf{x}_{s-1,i})\\|^{2}},1\\}}\\end{array}$ and the optimism as $\\mathbf{m}_{t}=\\nabla h_{t-1,i}^{\\mathrm{c}}(\\mathbf{x}_{t-1,i})$ , due to the standard analysis of OOGD for convex functions (e.g., Lemma 10 of Yan et al. [2023]), the base regret can be bounded as ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\displaystyle\\ B\\ A S E-\\ R E G\\leq5D\\sqrt{1+\\sum_{t=2}^{T}\\|\\nabla h_{t,i^{*}}^{c}(\\mathbf x_{t,i^{*}})-\\nabla h_{t-1,i^{*}}^{c}(\\mathbf x_{t-1,i^{*}})\\|^{2}}+\\mathcal{O}(1)}\\\\ &{\\displaystyle=5D\\sqrt{1+\\bar{V}_{T}}+\\mathcal{O}(1)\\leq\\mathcal{O}(\\sqrt{V_{T}})+5D\\sqrt{12L\\sum_{t=1}^{T}\\mathcal{D}_{f_{t}}(\\mathbf x^{\\star},\\mathbf x_{t})}}\\\\ &{\\displaystyle\\leq\\mathcal{O}(\\sqrt{V_{T}})+\\mathcal{O}(C_{5})+\\frac{5D}{2C_{5}}\\sum_{t=1}^{T}\\mathcal{D}_{f_{t}}(\\mathbf x^{\\star},\\mathbf x_{t}),}\\end{array}\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "where the second step is due to the property of the surrogate function: $\\nabla h_{t,i}^{\\mathrm{c}}(\\mathbf{x}_{t,i})=\\mathbf{g}_{t}$ , and the last step uses AM-GM inequality. $C_{5}$ is a constant to be specified. ", "page_idx": 16}, {"type": "text", "text": "For exp-concave functions, we run OOMD on the exp-concave base learners (indexed by $i$ ): ", "page_idx": 16}, {"type": "text", "text": "$\\begin{array}{r}{\\mathfrak{x}_{t,i}=\\underset{\\mathbf{x}\\in\\mathcal{X}}{\\arg\\operatorname*{min}}\\left\\{\\left\\langle\\mathbf{m}_{t},\\mathbf{x}\\right\\rangle+\\mathcal{D}_{\\psi_{t}}(\\mathbf{x},\\widehat{\\mathbf{x}}_{t,i})\\right\\},\\quad\\widehat{\\mathbf{x}}_{t+1,i}=\\underset{\\mathbf{x}\\in\\mathcal{X}}{\\arg\\operatorname*{min}}\\left\\{\\left\\langle\\nabla h_{t,i}^{\\mathrm{exp}}(\\mathbf{x}_{t,i}),\\mathbf{x}\\right\\rangle+\\mathcal{D}_{\\psi_{t}}(\\mathbf{x},\\widehat{\\mathbf{x}}_{t,i})\\right\\}.}\\end{array}$ Choosing $\\begin{array}{r}{\\psi_{t}(\\mathbf{x})\\,=\\,\\frac{1}{2}\\mathbf{x}^{\\top}U_{t}\\mathbf{x}}\\end{array}$ for any $\\mathbf{x}$ , $\\begin{array}{r}{U_{t}=(1+\\frac{\\alpha_{i}G^{2}}{2})I+\\frac{\\alpha_{i}}{2}\\sum_{s=1}^{t-1}\\nabla h_{s,i}^{\\mathrm{exp}}(\\mathbf{x}_{s,i})\\nabla h_{s,i}^{\\mathrm{exp}}(\\mathbf{x}_{s,i})^{\\top}}\\end{array}$ , and $\\mathbf{m}_{t}=\\nabla h_{t-1,i}^{\\mathrm{exp}}(\\mathbf{x}_{t-1,i})$ , due to the standard analysis of OOMD for exp-concave functions (e.g., Lemma 11 of Yan et al. [2023]), the base regret can be bounded as ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\mathtt{B A S E-R E G}\\leq\\frac{16d}{\\alpha_{i^{\\star}}}\\ln\\left(1+\\frac{\\alpha_{i^{\\star}}}{8d}\\sum_{t=2}^{T}\\left\\|\\nabla h_{t,i^{\\star}}^{\\mathrm{exp}}(\\mathbf{x}_{t,i^{\\star}})-\\nabla h_{t-1,i^{\\star}}^{\\mathrm{exp}}(\\mathbf{x}_{t-1,i^{\\star}})\\right\\|^{2}\\right)+\\mathcal{O}(1).\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "Next, we analyze the empirical gradient variation defined on the surrogate function $h_{t,i}^{\\exp}(\\cdot)$ : ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\displaystyle\\sum_{t=2}^{T}\\left\\|\\nabla h_{t,i^{\\star}}^{\\mathrm{exp}}(\\mathbf{x}_{t,i^{\\star}})-\\nabla h_{t-1,i^{\\star}}^{\\mathrm{exp}}(\\mathbf{x}_{t-1,i^{\\star}})\\right\\|^{2}}\\\\ &{=\\displaystyle\\sum_{t=2}^{T}\\left\\|\\mathbf{g}_{t}+\\frac{\\alpha_{i^{\\star}}}{2}\\mathbf{g}_{t}\\langle\\mathbf{g}_{t},\\mathbf{x}_{t}-\\mathbf{x}_{t,i^{\\star}}\\rangle-\\mathbf{g}_{t-1}-\\frac{\\alpha_{i^{\\star}}}{2}\\mathbf{g}_{t-1}\\langle\\mathbf{g}_{t-1},\\mathbf{x}_{t-1}-\\mathbf{x}_{t-1,i^{\\star}}\\rangle\\right\\|^{2}}\\\\ &{\\displaystyle\\leq3\\bar{V}_{T}+3\\displaystyle\\sum_{t=2}^{T}\\left\\|\\frac{\\alpha_{i^{\\star}}}{2}\\mathbf{g}_{t}\\langle\\mathbf{g}_{t},\\mathbf{x}_{t}-\\mathbf{x}_{t,i^{\\star}}\\rangle\\right\\|^{2}+3\\displaystyle\\sum_{t=2}^{T}\\left\\|\\frac{\\alpha_{i^{\\star}}}{2}\\mathbf{g}_{t-1}\\langle\\mathbf{g}_{t-1},\\mathbf{x}_{t-1}-\\mathbf{x}_{t-1,i^{\\star}}\\rangle\\right\\|^{2}}\\end{array}\n$$", "text_format": "latex", "page_idx": 16}, {"type": "equation", "text": "$$\n\\begin{array}{l}{{\\displaystyle\\leq3\\bar{V}_{T}+6\\sum_{t=1}^{T}\\left\\|\\frac{\\alpha_{i^{\\star}}}{2}\\mathbf{g}_{t}\\langle\\mathbf{g}_{t},\\mathbf{x}_{t}-\\mathbf{x}_{t,i^{\\star}}\\rangle\\right\\|^{2}}}\\\\ {{\\displaystyle\\leq9V_{T}+36L\\sum_{t=1}^{T}\\mathcal{D}_{f_{t}}(\\mathbf{x}^{\\star},\\mathbf{x}_{t})+2\\alpha_{i^{\\star}}^{2}G^{2}\\sum_{t=1}^{T}\\langle\\mathbf{g}_{t},\\mathbf{x}_{t}-\\mathbf{x}_{t,i^{\\star}}\\rangle^{2}},}\\end{array}\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "where the first step is due to the property of the surrogate function: $\\begin{array}{r}{\\nabla h_{t,i}^{\\mathrm{exp}}({\\bf x}_{t,i})={\\bf g}_{t}+\\frac{\\alpha_{i}}{2}{\\bf g}_{t}\\langle{\\bf g}_{t},{\\bf x}_{t}-}\\end{array}$ $\\mathbf{x}_{t,i}\\rangle$ , the second step is by the Cauchy-Schwarz inequality: $(a+b+c)^{2}\\leq3(a^{2}+b^{2}+c^{2})$ for any $a,b,c\\in\\mathbb{R}$ . Plugging the surrogate\u2019s empirical gradient variation back to the base regret, we obtain ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{3\\mathrm{ASE-REG}\\leq\\displaystyle\\frac{16d}{\\alpha_{i^{\\star}}}\\ln\\left(1+\\frac{9\\alpha_{i^{\\star}}}{8d}V_{T}+\\frac{9\\alpha_{i^{\\star}}L}{2d}\\sum_{t=1}^{T}\\mathcal{D}_{f_{t}}(\\mathbf{x}^{\\star},\\mathbf{x}_{t})+\\frac{\\alpha_{i^{\\star}}^{3}G^{2}}{4d}\\sum_{t=1}^{T}\\{\\mathbf{g}_{t},\\mathbf{x}_{t}-\\mathbf{x}_{t,i^{\\star}}\\}^{2}\\right)}\\\\ &{\\qquad\\qquad\\leq\\mathcal{O}\\left(\\frac{d}{\\alpha}\\ln(C_{6}V_{T})\\right)+\\displaystyle\\frac{16d}{C_{6}\\alpha_{i^{\\star}}}\\left(\\frac{9\\alpha_{i^{\\star}}L}{2d}\\sum_{t=1}^{T}\\mathcal{D}_{f_{t}}(\\mathbf{x}^{\\star},\\mathbf{x}_{t})+\\frac{\\alpha_{i^{\\star}}^{3}G^{2}}{4d}\\sum_{t=1}^{T}\\langle\\mathbf{g}_{t},\\mathbf{x}_{t}-\\mathbf{x}_{t,i^{\\star}}\\rangle^{2}\\right)}\\\\ &{\\qquad\\qquad\\leq\\mathcal{O}\\left(\\frac{d}{\\alpha}\\ln V_{T}\\right)+\\displaystyle\\frac{72L}{C_{6}}\\sum_{t=1}^{T}\\mathcal{D}_{f_{t}}(\\mathbf{x}^{\\star},\\mathbf{x}_{t})+\\frac{4G^{2}}{C_{6}}\\sum_{t=1}^{T}\\{\\mathbf{g}_{t},\\mathbf{x}_{t}-\\mathbf{x}_{t,i^{\\star}}\\}^{2}+\\mathcal{O}(\\ln C_{6}).}\\end{array}\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "The second step requires $C_{6}\\geq1$ by Lemma 5 and uses the property of the best base learner, i.e., $\\alpha_{i^{\\star}}\\leq\\alpha\\leq2\\alpha_{i^{\\star}}$ . The last step is because of $\\alpha_{i}\\leq1$ . ", "page_idx": 17}, {"type": "text", "text": "For strongly convex functions, we run OOGD (B.8) on the strongly convex base learners (indexed by $i_{,}$ ). Specifically, by choosing the step size as $\\eta_{t}=2/(1{+}\\lambda_{i}t)$ and the optimism as $\\mathbf{m}_{t}=\\nabla h_{t-1,i}^{\\mathrm{sc}}(\\mathbf{x}_{t-1,i})$ due to the analysis of OOGD for strongly convex functions (e.g., Lemma 12 of Yan et al. [2023]), the base regret can be bounded as ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\mathtt{B a s s E-R E G}\\leq\\frac{16G^{2}}{\\lambda_{i^{\\star}}}\\ln\\left(1+\\lambda_{i^{\\star}}\\sum_{t=2}^{T}\\left\\|\\nabla h_{t,i^{\\star}}^{\\mathrm{sc}}(\\mathbf x_{t,i^{\\star}})-\\nabla h_{t-1,i^{\\star}}^{\\mathrm{sc}}(\\mathbf x_{t-1,i^{\\star}})\\right\\|^{2}\\right)+{\\mathcal O}(1).\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "Next, we analyze the empirical gradient variation defined on the surrogate function $h_{t,i}^{\\mathrm{sc}}(\\cdot)$ : ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\displaystyle\\sum_{t=2}^{T}\\left\\|\\nabla h_{t,i^{*}}^{\\mathrm{\\scriptscriptstyleK}}({\\bf x}_{t,i^{*}})-\\nabla h_{t-1,i^{*}}^{\\mathrm{\\scriptscriptstyleK}}({\\bf x}_{t-1,i^{*}})\\right\\|^{2}}\\\\ &{\\displaystyle=\\sum_{t=2}^{T}\\left\\|\\mathbf{g}_{t}+\\frac{\\lambda_{i^{*}}}{2}({\\bf x}_{t,i^{*}}-{\\bf x}_{t})-\\mathbf{g}_{t-1}-\\frac{\\lambda_{i^{*}}}{2}({\\bf x}_{t-1,i^{*}}-{\\bf x}_{t-1})\\right\\|^{2}}\\\\ &{\\displaystyle\\leq3{\\bar{V}}_{T}+3\\sum_{t=2}^{T}\\left\\|\\frac{\\lambda_{i^{*}}}{2}({\\bf x}_{t,i^{*}}-{\\bf x}_{t})\\right\\|^{2}+3\\sum_{t=2}^{T}\\left\\|\\frac{\\lambda_{i^{*}}}{2}({\\bf x}_{t-1,i^{*}}-{\\bf x}_{t-1})\\right\\|^{2}}\\\\ &{\\displaystyle\\leq9V_{T}+36L\\sum_{t=1}^{T}\\mathcal{D}_{f_{t}}({\\bf x}^{*},{\\bf x}_{t})+2\\lambda_{i^{*}}^{2}\\sum_{t=1}^{T}\\left\\|{\\bf x}_{t,i^{*}}-{\\bf x}_{t}\\right\\|^{2},}\\end{array}\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "where the first step is due to the property of the surrogate: $\\begin{array}{r}{\\nabla h_{t,i}^{\\mathrm{sc}}(\\mathbf{x}_{t,i})=\\mathbf{g}_{t}+\\frac{\\lambda_{i}}{2}(\\mathbf{x}_{t,i}-\\mathbf{x}_{t})}\\\\ {\\nabla h_{t,i}^{\\mathrm{sc}}(\\mathbf{x}_{t,i})=\\mathbf{g}_{t}+\\frac{\\lambda_{i}}{2}(\\mathbf{x}_{t,i}-\\mathbf{x}_{t})}\\end{array}$ , and the second step is due to the Cauchy-Schwarz inequality. Plugging the surrogate\u2019s empirical gradient variation back to the base regret, we obtain ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\displaystyle\\mathtt{B a s E-R E G}\\leq\\frac{16G^{2}}{\\lambda_{i^{\\star}}}\\ln\\left(1+9\\lambda_{i^{\\star}}V_{T}+36L\\lambda_{i^{\\star}}\\sum_{t=1}^{T}\\mathcal{D}_{f_{t}}(\\mathbf{x}^{\\star},\\mathbf{x}_{t})+2\\lambda_{i^{\\star}}^{3}\\sum_{t=1}^{T}\\|\\mathbf{x}_{t,i^{\\star}}-\\mathbf{x}_{t}\\|^{2}\\right)}\\\\ &{\\qquad\\qquad\\leq\\mathcal{O}\\left(\\frac{1}{\\lambda}\\ln(C_{7}V_{T})\\right)+\\frac{16G^{2}}{C_{7}\\lambda_{i^{\\star}}}\\left(36L\\lambda_{i^{\\star}}\\sum_{t=1}^{T}\\mathcal{D}_{f_{t}}(\\mathbf{x}^{\\star},\\mathbf{x}_{t})+2\\lambda_{i^{\\star}}^{3}\\sum_{t=1}^{T}\\|\\mathbf{x}_{t,i^{\\star}}-\\mathbf{x}_{t}\\|^{2}\\right)}\\\\ &{\\displaystyle\\leq\\mathcal{O}\\left(\\frac{1}{\\lambda}\\ln V_{T}\\right)+\\frac{576G^{2}L}{C_{7}}\\sum_{t=1}^{T}\\mathcal{D}_{f_{t}}(\\mathbf{x}^{\\star},\\mathbf{x}_{t})+\\frac{32G^{2}}{C_{7}}\\sum_{t=1}^{T}\\|\\mathbf{x}_{t,i^{\\star}}-\\mathbf{x}_{t}\\|^{2}+\\mathcal{O}(\\ln C_{7}),}\\end{array}\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "where the second step requires $C_{7}\\geq1$ by Lemma 5 and uses the property of the best base learner, i.e., $\\lambda_{i^{\\star}}\\le\\lambda\\le2\\lambda_{i^{\\star}}$ . The last step is due to $\\lambda_{i}\\leq1$ . ", "page_idx": 17}, {"type": "text", "text": "Regret Analysis. For convex functions, by combining the meta and base regret, it holds that ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\mathrm{REG}_{T}\\leq\\mathcal{O}(\\sqrt{V_{T}})+\\mathcal{O}(C_{2}+C_{5})+\\left(\\frac{C_{0}}{2C_{2}}+\\frac{5D}{2C_{5}}-1\\right)\\sum_{t=1}^{T}\\mathcal{D}_{f_{t}}(\\mathbf{x}^{\\star},\\mathbf{x}_{t})\\leq\\mathcal{O}(\\sqrt{V_{T}}),\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "by choosing $C_{2}=C_{0}$ and $C_{5}=5D$ . For exp-concave functions, by combining the meta and base regret, it holds that ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathsf{R E G}_{T}\\leq\\mathcal{O}\\left(\\displaystyle\\frac{d}{\\alpha}\\ln V_{T}\\right)+\\mathcal{O}(C_{3}+\\ln C_{6})+\\left(\\displaystyle\\frac{C_{0}}{2C_{3}}+\\frac{4G^{2}}{C_{6}}-\\frac{\\alpha_{i^{\\star}}}{4}\\right)\\displaystyle\\sum_{t=1}^{T}\\langle\\mathbf{g}_{t},\\mathbf{x}_{t}-\\mathbf{x}_{t,i^{\\star}}\\rangle^{2}}\\\\ &{\\qquad\\qquad+\\left(\\displaystyle\\frac{72L}{C_{6}}-\\frac{1}{2}\\right)\\displaystyle\\sum_{t=1}^{T}\\mathcal{D}_{f_{t}}(\\mathbf{x}^{\\star},\\mathbf{x}_{t})\\leq\\mathcal{O}\\left(\\displaystyle\\frac{d}{\\alpha}\\ln V_{T}\\right),}\\end{array}\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "by choosing $\\begin{array}{r}{C_{6}=\\operatorname*{max}\\lbrace1,144L,\\frac{32G^{2}}{\\alpha_{i^{\\star}}}\\rbrace}\\end{array}$ and $\\begin{array}{r}{C_{3}=\\frac{4C_{0}}{\\alpha_{i^{\\star}}}}\\end{array}$ . Note that such a parameter configuration will only add an ${\\mathcal{O}}(1/\\alpha)$ factor to the final regret bound, which can be absorbed. For strongly convex functions, by combining the meta and base regret, it holds that ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\begin{array}{l}{{\\displaystyle{\\sf R E G}_{T}\\leq\\mathcal{O}\\left(\\frac{1}{\\lambda}\\ln V_{T}\\right)+\\mathcal{O}(C_{4}+\\ln C_{7})+\\left(\\frac{C_{0}D^{2}}{2C_{4}}+\\frac{32G^{2}}{C_{7}}-\\frac{\\lambda_{i^{*}}}{4}\\right)\\sum_{t=1}^{T}\\left\\|{\\bf x}_{t}-{\\bf x}_{t,i^{*}}\\right\\|^{2}}}\\\\ {~~}\\\\ {{\\displaystyle~~~~~~~~~~+\\left(\\frac{576G^{2}L}{C_{7}}-\\frac{1}{2}\\right)\\sum_{t=1}^{T}\\mathcal{D}_{f_{t}}({\\bf x}^{\\star},{\\bf x}_{t})\\leq\\mathcal{O}\\left(\\frac{1}{\\lambda}\\ln V_{T}\\right),}}\\end{array}\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "by choosing C7 = max{1, 1152G2L, 25\u03bb6\u22c6G2} and C4 = 4C\u03bb0\u22c6D2. Note that such a parameter configuration will only add an $\\mathcal{O}(1/\\lambda)$ factor to the final regret bound, which can be absorbed. ", "page_idx": 18}, {"type": "text", "text": "Note that the constants $C_{2},C_{3},C_{4},C_{5},C_{6},C_{7}$ only exist in analysis and thus can be chosen arbitrarily, finishing the proof. \u53e3 ", "page_idx": 18}, {"type": "text", "text": "C Proofs for Section 4 ", "text_level": 1, "page_idx": 18}, {"type": "text", "text": "In this section, we provide proofs for Section 4, including Theorem 2 and Theorem 3. ", "page_idx": 18}, {"type": "text", "text": "C.1 Proof of Theorem 2 ", "text_level": 1, "page_idx": 18}, {"type": "text", "text": "Proof. To begin with, we give a different decomposition for the empirical gradient variation $\\bar{V}_{T}$ : ", "page_idx": 18}, {"type": "equation", "text": "$$\n{\\bar{V}}_{T}\\leq2\\sum_{t=2}^{T}\\|\\mathbf{g}_{t}\\|^{2}+2\\sum_{t=2}^{T}\\|\\mathbf{g}_{t-1}\\|^{2}\\leq4\\sum_{t=1}^{T}\\|\\mathbf{g}_{t}\\|^{2}\\leq16L\\sum_{t=1}^{T}f_{t}(\\mathbf{x}_{t}),\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "where the last step is by the self-bounding property (A.1) for non-negative functions. For simplicity, we denote by $\\begin{array}{r}{\\bar{F}_{T}\\overset{\\triangle}{=}\\sum_{t=1}^{T}f_{t}(\\mathbf{x}_{t})}\\end{array}$ . ", "page_idx": 18}, {"type": "text", "text": "The regret decomposition is the same as that in the proof of Theorem 1 (i.e., (B.2), (B.3), and (B.4)), and thus omitted here. In the following, we analyze the meta and base regret, and combine them for the final regret bounds. ", "page_idx": 18}, {"type": "text", "text": "Meta Regret Analysis. Our Algorithm 1 achieves the small-loss bounds without modifying the algorithm. As a result, the meta algorithm and the corresponding step size and optimism configurations are the same as that in the proof of Theorem 1. ", "page_idx": 18}, {"type": "text", "text": "For convex functions, by choosing the optimism as $m_{t,i}=\\langle\\mathbf{g}_{t-1},\\mathbf{x}_{t}-\\mathbf{x}_{t,i}\\rangle$ for the index $i$ indicating the base learner for the convex case, the meta regret in (B.2) can be bounded as ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\!\\!\\!\\operatorname{META-REG}\\leq C_{0}\\sqrt{1+\\displaystyle\\sum_{t=1}^{T}\\langle\\mathbf{g}_{t}-\\mathbf{g}_{t-1},\\mathbf{x}_{t}-\\mathbf{x}_{t,i^{\\star}}\\rangle^{2}}+C_{1}\n$$", "text_format": "latex", "page_idx": 18}, {"type": "equation", "text": "$$\n\\leq C_{0}\\sqrt{1+D^{2}\\bar{V}_{T}}+C_{1}\\leq C_{0}\\sqrt{1+16D^{2}L\\bar{F}_{T}}+C_{1}.\\eqno({\\mathrm{by}}\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "For exp-concave functions, we choose the optimism as $m_{t,i}=0$ for indexes $i$ indicating the expconcave base learners. The meta regret is bounded in the same way as (B.6). ", "page_idx": 19}, {"type": "text", "text": "For strongly convex functions, we choose the optimism as $m_{t,i}\\,=\\,0$ for indexes $i$ indicating the strongly convex base learners. The meta regret is bounded in the same way as (B.7). ", "page_idx": 19}, {"type": "text", "text": "Base Regret Analysis. For convex functions, using the same base algorithms as in the proof of Theorem 1, the base regret can be bounded as ", "page_idx": 19}, {"type": "equation", "text": "$$\n{\\tt B A S E-R E G}\\le5D\\sqrt{1+\\bar{V}_{T}}+{\\mathcal O}(1)\\le5D\\sqrt{1+16L\\bar{F}_{T}}+{\\mathcal O}(1).\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "For exp-concave functions, using the same base algorithms as in the proof of Theorem 1, the base regret can be bounded by (B.9). Following (B.10), the empirical gradient variation defined on the surrogate function $h_{t,i}^{\\exp}(\\cdot)$ can be bounded as ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\begin{array}{r l r}&{}&{\\displaystyle\\sum_{t=2}^{T}\\left\\|\\nabla h_{t,i^{*}}^{\\mathrm{exp}}(\\mathbf{x}_{t,i^{*}})-\\nabla h_{t-1,i^{*}}^{\\mathrm{exp}}(\\mathbf{x}_{t-1,i^{*}})\\right\\|^{2}\\leq3\\bar{V}_{T}+6\\displaystyle\\sum_{t=1}^{T}\\left\\|\\frac{\\alpha_{i^{*}}}{2}\\mathbf{g}_{t}\\langle\\mathbf{g}_{t},\\mathbf{x}_{t}-\\mathbf{x}_{t,i^{*}}\\rangle\\right\\|^{2}}\\\\ &{}&{\\displaystyle\\leq48L\\bar{F}_{T}+2\\alpha_{i^{*}}^{2}G^{2}\\displaystyle\\sum_{t=1}^{T}\\langle\\mathbf{g}_{t},\\mathbf{x}_{t}-\\mathbf{x}_{t,i^{*}}\\rangle^{2}.\\qquad\\qquad\\qquad\\qquad\\quad\\mathrm{(by~Assumption~1~and~6)}}\\end{array}\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "Plugging the surrogate\u2019s empirical gradient variation back to the base regret, we obtain ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\quad\\mathrm{\\bf~BasE-REG}\\leq\\frac{16d}{\\alpha_{i^{\\star}}}\\ln\\left(1+\\frac{6L\\alpha_{i^{\\star}}}{d}\\bar{F}_{T}+\\frac{\\alpha_{i^{\\star}}^{3}G^{2}}{4d}\\sum_{t=1}^{T}\\langle\\mathbf{g}_{t},\\mathbf{x}_{t}-\\mathbf{x}_{t,i^{\\star}}\\rangle^{2}\\right)+\\mathcal{O}(1)}\\\\ &{\\leq\\frac{16d}{\\alpha_{i^{\\star}}}\\ln\\left(C_{8}\\left(1+\\frac{6L\\alpha_{i^{\\star}}}{d}\\bar{F}_{T}\\right)\\right)+\\frac{16d}{C_{8}\\alpha_{i^{\\star}}}\\left(\\frac{\\alpha_{i^{\\star}}^{3}G^{2}}{4d}\\sum_{t=1}^{T}\\langle\\mathbf{g}_{t},\\mathbf{x}_{t}-\\mathbf{x}_{t,i^{\\star}}\\rangle^{2}\\right)}\\\\ &{\\leq\\frac{32d}{\\alpha}\\ln\\left(1+\\frac{6L}{d}\\bar{F}_{T}\\right)+\\frac{4G^{2}}{C_{8}}\\sum_{t=1}^{T}\\langle\\mathbf{g}_{t},\\mathbf{x}_{t}-\\mathbf{x}_{t,i^{\\star}}\\rangle^{2}+\\mathcal{O}(\\ln C_{8}),}\\end{array}\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "where the second step requires $C_{8}\\geq1$ by Lemma 5 and uses the property of the best base learner, i.e., $\\alpha_{i^{\\star}}\\leq\\alpha\\leq2\\alpha_{i^{\\star}}$ . The last step is due to $\\alpha_{i}\\leq1$ . ", "page_idx": 19}, {"type": "text", "text": "For strongly convex functions, using the same base algorithms as in the proof of Theorem 1, the base regret can be bounded by (B.11). Following (B.12), the empirical gradient variation defined on the surrogate function $h_{t,i}^{\\mathrm{sc}}(\\cdot)$ can be bounded as ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\quad\\displaystyle\\sum_{t=2}^{T}\\left\\|\\nabla h_{t,i^{\\star}}^{\\mathrm{sc}}\\left(\\mathbf{x}_{t,i^{\\star}}\\right)-\\nabla h_{t-1,i^{\\star}}^{\\mathrm{sc}}\\left(\\mathbf{x}_{t-1,i^{\\star}}\\right)\\right\\|^{2}\\leq3\\bar{V}_{T}+6\\displaystyle\\sum_{t=1}^{T}\\left\\|\\frac{\\lambda_{i^{\\star}}}{2}(\\mathbf{x}_{t,i^{\\star}}-\\mathbf{x}_{t})\\right\\|^{2}}\\\\ &{\\leq48L\\bar{F}_{T}+2\\lambda_{i^{\\star}}^{2}\\displaystyle\\sum_{t=1}^{T}\\|\\mathbf{x}_{t,i^{\\star}}-\\mathbf{x}_{t}\\|^{2}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "Plugging the surrogate\u2019s empirical gradient variation back to the base regret, we obtain ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\ \\mathrm{BasE-REG}\\leq\\displaystyle\\frac{16G^{2}}{\\lambda_{i^{\\star}}}\\ln\\left(1+48L\\lambda_{i^{\\star}}\\bar{F}_{T}+2\\lambda_{i^{\\star}}^{3}\\displaystyle\\sum_{t=1}^{T}\\|\\mathbf{x}_{t,i^{\\star}}-\\mathbf{x}_{t}\\|^{2}\\right)+\\mathcal{O}(1)}\\\\ &{\\leq\\displaystyle\\frac{16G^{2}}{\\lambda_{i^{\\star}}}\\ln\\left(C_{9}\\left(1+48L\\lambda_{i^{\\star}}\\bar{F}_{T}\\right)\\right)+\\displaystyle\\frac{16G^{2}}{C_{9}\\lambda_{i^{\\star}}}\\left(2\\lambda_{i^{\\star}}^{3}\\displaystyle\\sum_{t=1}^{T}\\|\\mathbf{x}_{t,i^{\\star}}-\\mathbf{x}_{t}\\|^{2}\\right)}\\\\ &{\\leq\\displaystyle\\frac{32G^{2}}{\\lambda}\\ln(1+48L\\bar{F}_{T})+\\displaystyle\\frac{32G^{2}}{C_{9}}\\displaystyle\\sum_{t=1}^{T}\\|\\mathbf{x}_{t,i^{\\star}}-\\mathbf{x}_{t}\\|^{2}+\\mathcal{O}(\\ln C_{9}),}\\end{array}\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "where the second step requires $C_{9}\\geq1$ by Lemma 5 and uses the property of the best base learner, i.e., $\\lambda_{i^{\\star}}\\le\\lambda\\le2\\lambda_{i^{\\star}}$ . The last step is due to $\\lambda_{i}\\leq1$ . ", "page_idx": 19}, {"type": "text", "text": "Regret Analysis. For convex functions, by combining the meta and base regret, it holds that ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\mathrm{REG}_{T}\\leq C_{0}\\sqrt{1+16D^{2}L\\bar{F}_{T}}+5D\\sqrt{1+16L\\bar{F}_{T}}+C_{1}\\leq\\mathcal{O}(\\sqrt{F_{T}}),\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "where the last step is due to Lemma 9 of Zhao et al. [2024], restated below for self-containedness. ", "page_idx": 20}, {"type": "text", "text": "Lemma 3 (Lemma \u221a9 of Zhao et al. [2024]). For any $x,y,a,b>0$ satisfying $x-y\\leq\\sqrt{a x}+b,$ it holds that $x-y\\leq{\\sqrt{a y+a b}}+a+b$ . ", "page_idx": 20}, {"type": "text", "text": "For exp-concave functions, by combining the meta and base regret, it holds that ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\begin{array}{r l r}&{\\mathsf{R E G}_{T}\\leq\\,\\left(\\displaystyle\\frac{C_{0}}{2C_{3}}+\\displaystyle\\frac{4G^{2}}{C_{8}}-\\frac{\\alpha_{i^{\\star}}}{4}\\right)\\displaystyle\\sum_{t=1}^{T}\\langle\\mathbf{g}_{t},\\mathbf{x}_{t}-\\mathbf{x}_{t,i^{\\star}}\\rangle^{2}+\\displaystyle\\frac{32d}{\\alpha}\\ln\\left(1+\\displaystyle\\frac{6L}{d}\\bar{F}_{T}\\right)+\\mathcal{O}(C_{3}+\\ln C_{8})}\\\\ &{\\quad}&{\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,}\\\\ &{\\quad}&{\\leq\\displaystyle\\frac{32d}{\\alpha}\\ln\\left(1+\\displaystyle\\frac{6L}{d}\\bar{F}_{T}\\right)+\\mathcal{O}(1)\\leq\\mathcal{O}\\left(\\displaystyle\\frac{d}{\\alpha}\\ln F_{T}\\right),\\,\\,\\,\\,\\,\\qquad\\qquad\\qquad\\quad\\,\\,\\,\\,\\,\\,\\mathrm{(by~Lemma~6)}}\\end{array}\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "where the second step chooses $\\begin{array}{r}{C_{3}=\\frac{4C_{0}}{\\alpha_{i^{\\star}}}}\\end{array}$ and $\\begin{array}{r}{C_{8}=\\operatorname*{max}\\lbrace1,\\frac{32G^{2}}{\\alpha_{i^{\\star}}}\\rbrace}\\end{array}$ . Note that such a parameter configuration will only add an ${\\mathcal{O}}(1/\\alpha)$ factor to the final regret bound, which can be absorbed. ", "page_idx": 20}, {"type": "text", "text": "For strongly convex functions, by combining the meta and base regret, it holds that ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\begin{array}{r l r}{\\lefteqn{3\\mathrm{EG}_{T}\\leq\\left(\\frac{C_{0}D^{2}}{2C_{4}}+\\frac{32G^{2}}{C_{9}}-\\frac{\\lambda_{i^{*}}}{4}\\right)\\sum_{t=1}^{T}\\|{\\bf x}_{t}-{\\bf x}_{t,i^{*}}\\|^{2}+\\frac{32G^{2}}{\\lambda}\\ln(1+48L\\bar{F}_{T})+\\mathcal{O}(C_{4}+\\ln C_{9})}}\\\\ &{}&\\\\ &{\\leq\\frac{32G^{2}}{\\lambda}\\ln(1+48L\\bar{F}_{T})\\leq\\mathcal{O}\\left(\\frac{1}{\\lambda}\\ln F_{T}\\right),\\ ~}&{\\ \\mathrm{(by~Lemma~6)}}\\end{array}\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "where the second step is by choosing $\\begin{array}{r}{C_{4}=\\frac{4C_{0}D^{2}}{\\lambda_{i^{\\star}}}}\\end{array}$ and $\\begin{array}{r}{C_{9}=\\operatorname*{max}\\lbrace1,\\frac{256G^{2}}{\\lambda_{i^{\\star}}}\\rbrace}\\end{array}$ . Note that such a parameter configuration will only add an $\\mathcal{O}(1/\\dot{\\lambda})$ factor to the final regret bound, which can be absorbed. Also note that the constants $C_{3},C_{4},C_{8},C_{9}$ only exist in analysis and thus can be chosen arbitrarily, finishing the proof. \u53e3 ", "page_idx": 20}, {"type": "text", "text": "C.2 Proof of Theorem 3 ", "text_level": 1, "page_idx": 20}, {"type": "text", "text": "Proof. To begin with, we give a different analysis of the empirical gradient variation: ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\begin{array}{l}{\\displaystyle\\mathbb{E}[\\bar{V}_{T}]\\leq5\\mathbb{E}\\left[\\displaystyle\\sum_{t=2}^{T}\\|\\nabla f_{t}(\\mathbf{x}_{t})-\\nabla F_{t}(\\mathbf{x}_{t})\\|^{2}\\right]+5\\displaystyle\\sum_{t=2}^{T}\\|\\nabla F_{t}(\\mathbf{x}_{t})-\\nabla F_{t}(\\mathbf{x}^{\\star})\\|^{2}}\\\\ {\\displaystyle+5\\mathbb{E}\\left[\\displaystyle\\sum_{t=2}^{T}\\|\\nabla F_{t}(\\mathbf{x}^{\\star})-\\nabla F_{t-1}(\\mathbf{x}^{\\star})\\|^{2}\\right]+5\\displaystyle\\sum_{t=2}^{T}\\|\\nabla F_{t-1}(\\mathbf{x}^{\\star})-\\nabla F_{t-1}(\\mathbf{x}_{t-1})\\|^{2}}\\\\ {\\displaystyle+5\\mathbb{E}\\left[\\displaystyle\\sum_{t=2}^{T}\\|\\nabla F_{t-1}(\\mathbf{x}_{t-1})-\\nabla f_{t-1}(\\mathbf{x}_{t-1})\\|^{2}\\right]\\leq10\\sigma_{1:T}^{2}+5\\displaystyle\\Sigma_{1:T}^{2}+20L\\displaystyle\\sum_{t=1}^{T}\\mathcal{D}_{F_{t}}(\\mathbf{x}^{\\star},\\mathbf{x}_{t}),}\\end{array}\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "where the first step is due to Cauchy-Schwarz inequality and the last step is because of the definitions of $\\sigma_{1:T}^{2}$ and $\\Sigma_{1:T}^{2}$ (given in Section 4) and the analysis proposed in Section 3.2. ", "page_idx": 20}, {"type": "text", "text": "In the following, we first give regret decompositions for different curvature types, then we analyze the meta and base regret, and combine them for the final regret guarantees. ", "page_idx": 20}, {"type": "text", "text": "Regret Decomposition. Denoting by $\\begin{array}{r}{\\mathbf{x}^{\\star}\\in\\arg\\operatorname*{min}_{\\mathbf{x}\\in\\mathcal{X}}\\sum_{t\\in[T]}f_{t}(\\mathbf{x})}\\end{array}$ , for convex functions, we decompose the regret as ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\begin{array}{l}{\\displaystyle\\mathbb{E}[\\mathbf{REG}_{T}]=\\mathbb{E}\\left[\\sum_{t=1}^{T}F_{t}(\\mathbf{x}_{t})-\\sum_{t=1}^{T}F_{t}(\\mathbf{x}^{\\star})\\right]=\\mathbb{E}\\left[\\sum_{t=1}^{T}\\langle\\nabla F_{t}(\\mathbf{x}_{t}),\\mathbf{x}_{t}-\\mathbf{x}^{\\star}\\rangle\\right]-\\sum_{t=1}^{T}\\mathcal{D}_{F_{t}}(\\mathbf{x}^{\\star},\\mathbf{x}_{t})}\\\\ {\\displaystyle=\\mathbb{E}\\left[\\sum_{t=1}^{T}\\langle\\nabla f_{t}(\\mathbf{x}_{t}),\\mathbf{x}_{t}-\\mathbf{x}^{\\star}\\rangle\\right]-\\sum_{t=1}^{T}\\mathcal{D}_{F_{t}}(\\mathbf{x}^{\\star},\\mathbf{x}_{t})}\\end{array}\n$$", "text_format": "latex", "page_idx": 20}, {"type": "equation", "text": "$$\n=\\underbrace{\\mathbb{E}\\left[\\sum_{t=1}^{T}\\langle\\mathbf{g}_{t},\\mathbf{x}_{t}-\\mathbf{x}_{t,i^{*}}\\rangle\\right]}_{\\mathrm{METa-REG}}+\\underbrace{\\mathbb{E}\\left[\\sum_{t=1}^{T}h_{t,i^{*}}^{\\mathrm{c}}\\left(\\mathbf{x}_{t,i^{*}}\\right)-h_{t,i^{*}}^{\\mathrm{c}}\\left(\\mathbf{x}^{\\star}\\right)\\right]}_{\\mathrm{BAsE-REG}}-\\sum_{t=1}^{T}\\mathcal{D}_{F_{t}}(\\mathbf{x}^{\\star},\\mathbf{x}_{t}),\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "where the first and third step use $F_{t}(\\mathbf{x})=\\mathbb{E}[f_{t}(\\mathbf{x})]$ , the second step uses the definition of Bregman divergence, and the fourth step is due to $h_{t,i}^{\\mathrm{c}}(\\mathbf{x})\\triangleq\\langle\\mathbf{g}_{t},\\mathbf{x}\\rangle$ . ", "page_idx": 21}, {"type": "text", "text": "For exp-concave functions, following the similar decomposition as in the proof of Theorem 1 in Appendix B, we decompose the regret as ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{E}[\\mathbf{R}\\mathbf{E}\\mathbf{G}\\mathbf{r}]=\\mathbb{E}\\left[\\displaystyle\\sum_{t=1}^{T}(\\nabla F_{t}(\\mathbf{x}_{t}),\\mathbf{x}_{t}-\\mathbf{x}^{*})\\right]-\\frac{1}{2}\\displaystyle\\sum_{t=1}^{T}\\mathcal{D}_{t,\\mathbf{r}}(\\mathbf{x}^{*},\\mathbf{x}_{t})-\\frac{1}{2}\\displaystyle\\sum_{t=1}^{T}\\mathcal{D}_{t,\\mathbf{r}}(\\mathbf{x}^{*},\\mathbf{x}_{t})}\\\\ &{\\qquad\\qquad=\\mathbb{E}\\left[\\displaystyle\\sum_{t=1}^{T}(\\nabla f_{t}(\\mathbf{x}_{t}),\\mathbf{x}_{t}-\\mathbf{x}^{*})\\right]-\\frac{1}{2}\\displaystyle\\sum_{t=1}^{T}\\mathcal{D}_{t,\\mathbf{r}}(\\mathbf{x}^{*},\\mathbf{x}_{t})-\\frac{1}{2}\\displaystyle\\sum_{t=1}^{T}\\mathcal{D}_{t,\\mathbf{r}}(\\mathbf{x}^{*},\\mathbf{x}_{t})}\\\\ &{\\qquad\\qquad\\leq\\mathbb{E}\\left[\\displaystyle\\sum_{t=1}^{T}(\\mathbf{z}_{t},\\mathbf{x}_{t}-\\mathbf{x}^{*})\\right]-\\frac{\\alpha}{4}\\displaystyle\\sum_{t=1}^{T}(\\mathbf{z}_{t},\\mathbf{x}_{t}-\\mathbf{x}^{*})^{2}-\\frac{1}{2}\\displaystyle\\sum_{t=1}^{T}\\mathcal{D}_{t,\\mathbf{r}}(\\mathbf{x}^{*},\\mathbf{x}_{t})}\\\\ &{\\qquad\\qquad\\leq\\displaystyle\\sum_{t=1}^{T}(\\mathbf{z}_{t},\\mathbf{x}_{t}-\\mathbf{x}_{t,t})\\cdot\\frac{\\alpha_{t}}{4}\\displaystyle\\sum_{t=1}^{T}(\\mathbf{z}_{t},\\mathbf{x}_{t}-\\mathbf{x}_{t,t})^{2}}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\mathrm{Mershoze}}\\\\ &{\\qquad\\qquad\\qquad+\\underbrace{\\mathbb{E}\\left[\\displaystyle\\sum_{t=1}^{T}h_{t,t}^{\\mathrm{eg}}(\\mathbf{x}_{t},\\mathbf{\\xi}_{t})-h_{t,t}^{\\mathrm{eg}}(\\mathbf{x}^{*})\\right]-\\frac{1}{2}\\displaystyle\\sum_{t=1}^{T}D_{t}(\\mathbf{z}^{*},\\mathbf{x\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "where the second step uses the definition of the expected function $F_{t}(\\cdot)$ , the third step requires the exp-concavity of $f_{t}(\\cdot)$ , and the fourth step is due to $\\begin{array}{r}{h_{t,i}^{\\mathrm{exp}}(\\mathbf{x})\\,\\triangleq\\,\\langle\\mathbf{g}_{t},\\mathbf{x}\\rangle+\\frac{\\alpha_{i}}{4}\\langle\\nabla f_{t}(\\mathbf{x}_{t}),\\mathbf{x}-\\mathbf{x}_{t}\\rangle^{2}}\\end{array}$ , where $\\alpha_{i}\\in\\mathcal{H}$ , defined in (2.1). For strongly convex functions, following the similar decomposition as in Appendix B, we decompose the regret as ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{E}[\\mathbf{R}\\mathbf{E}\\mathbf{G}\\mathbf{r}]=\\mathbb{E}\\left[\\displaystyle\\sum_{t=1}^{T}\\langle\\nabla F_{t}(\\mathbf{x}_{t}),\\mathbf{x}_{t}-\\mathbf{x}^{*}\\rangle\\right]-\\displaystyle\\frac{1}{2}\\sum_{t=1}^{T}\\mathcal{D}_{F_{t}}(\\mathbf{x}^{*},\\mathbf{x}_{t})-\\frac{1}{2}\\sum_{t=1}^{T}\\mathcal{D}_{F_{t}}(\\mathbf{x}^{*},\\mathbf{x}_{t})}\\\\ &{\\qquad\\quad\\leq\\mathbb{E}\\left[\\displaystyle\\sum_{t=1}^{T}\\langle\\mathbf{g}_{t},\\mathbf{x}_{t}-\\mathbf{x}^{*}\\rangle\\right]-\\displaystyle\\frac{\\lambda}{4}\\sum_{t=1}^{T}\\|\\mathbf{x}_{t}-\\mathbf{x}^{*}\\|^{2}-\\displaystyle\\frac{1}{2}\\sum_{t=1}^{T}\\mathcal{D}_{F_{t}}(\\mathbf{x}^{*},\\mathbf{x}_{t})}\\\\ &{\\qquad\\quad\\leq\\displaystyle\\sum_{t=1}^{T}\\langle\\mathbf{g}_{t},\\mathbf{x}_{t}-\\mathbf{x}_{t,i}\\rangle-\\frac{\\lambda_{i}+\\sum_{t=1}^{T}}{4}\\displaystyle\\prod_{t=1}^{T}\\mathbf{x}_{t}-\\mathbf{x}_{t,i},*\\|^{2}}\\\\ &{\\qquad\\qquad\\quad\\qquad\\qquad\\mathrm{Metral}}\\\\ &{\\qquad\\qquad\\qquad+\\underbrace{\\mathbb{E}\\left[\\displaystyle\\sum_{t=1}^{T}h_{t,i}^{\\mathrm{ex}}(\\mathbf{x}_{t,i}^{*})-h_{t,i}^{\\mathrm{ex}}(\\mathbf{x}^{*})\\right]}_{t=1}-\\frac{1}{2}\\displaystyle\\sum_{t=1}^{T}\\mathcal{D}_{F_{t}}(\\mathbf{x}^{*},\\mathbf{x}_{t}),}\\end{array}\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "where the second step, different from the exp-concave case, only requires the strong convexity of $F_{t}(\\cdot)$ , and the third step is due to $\\begin{array}{r}{h_{t,i}^{\\mathrm{sc}}(\\mathbf{x})\\triangleq\\langle\\mathbf{g}_{t},\\mathbf{x}\\rangle+\\frac{\\lambda_{i}}{4}\\|\\mathbf{x}-\\mathbf{x}_{t}\\|^{2}}\\end{array}$ , where $\\lambda_{i}\\in\\mathcal{H}$ , defined in (2.1). ", "page_idx": 21}, {"type": "text", "text": "Meta Regret Analysis. Our Algorithm 1 can be applied to the SEA model without any algorithm modifications. As a result, we directly use the same parameter configurations as in the proof of Theorem 1 (i.e., in Appendix B). ", "page_idx": 21}, {"type": "text", "text": "For convex functions, the meta regret can be bounded as ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathrm{META-REG}\\leq\\mathbb{E}\\left[C_{0}\\sqrt{1+D^{2}\\bar{V}_{T}}+C_{1}\\right]\\leq C_{0}\\sqrt{1+D^{2}\\mathbb{E}[\\bar{V}_{T}]}+C_{1}}\\end{array}\n$$", "text_format": "latex", "page_idx": 21}, {"type": "equation", "text": "$$\n\\begin{array}{l}{\\displaystyle\\leq C_{0}\\sqrt{1+5D^{2}(2\\sigma_{1:T}^{2}+\\Sigma_{1:T}^{2})+20D^{2}L\\sum_{t=1}^{T}\\mathcal{D}_{F_{t}}(\\mathbf{x}^{\\star},\\mathbf{x}_{t})}+C_{1}}\\\\ {\\displaystyle\\leq\\mathcal{O}\\left(\\sqrt{\\sigma_{1:T}^{2}+\\Sigma_{1:T}^{2}}\\right)+\\mathcal{O}(C_{10})+\\frac{C_{0}}{2C_{10}}\\sum_{t=1}^{T}\\mathcal{D}_{F_{t}}(\\mathbf{x}^{\\star},\\mathbf{x}_{t}),}\\end{array}\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "where the second step is by Jensen\u2019s inequality and the last step is due to AM-GM inequality. $C_{10}$ is a constant to be specified. ", "page_idx": 22}, {"type": "text", "text": "For exp-concave and strongly convex functions, the meta regret is bounded in the same way as (B.6) and (B.7), and thus omitted here. ", "page_idx": 22}, {"type": "text", "text": "Base Regret Analysis. For convex functions, the base regret can be bounded as ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\displaystyle\\ B\\ A\\ S E-\\mathrm{REG}\\leq5D\\sqrt{1+\\mathbb{E}[\\bar{V}_{T}]}\\leq5D\\sqrt{1+10\\sigma_{1:T}^{2}+5\\Sigma_{1:T}^{2}+20L\\sum_{t=1}^{T}\\mathcal{D}_{F_{t}}(\\mathbf{x}^{\\star},\\mathbf{x}_{t})}}\\\\ &{\\displaystyle\\leq\\mathcal{O}\\left(\\sqrt{\\sigma_{1:T}^{2}+\\Sigma_{1:T}^{2}}\\right)+\\mathcal{O}(C_{11})+\\frac{5D}{2C_{11}}\\sum_{t=1}^{T}\\mathcal{D}_{F_{t}}(\\mathbf{x}^{\\star},\\mathbf{x}_{t}),}\\end{array}\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "where the first step is by Jensen\u2019s inequality, the second step is due to (C.2), and the last step is because of AM-GM inequality. $C_{11}$ is a constant to be specified. ", "page_idx": 22}, {"type": "text", "text": "For exp-concave functions, the base regret is bounded by (B.9). Following (C.2), we control the empirical gradient variation defined on surrogates as ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\quad\\mathbb{E}\\left[\\displaystyle\\sum_{t=2}^{T}\\left\\|\\nabla h_{t,i^{*}}^{\\mathrm{exp}}(\\mathbf{x}_{t,i^{*}})-\\nabla h_{t-1,i^{*}}^{\\mathrm{exp}}(\\mathbf{x}_{t-1,i^{*}})\\right\\|^{2}\\right]\\leq3\\mathbb{E}[\\bar{V}_{T}]+6\\displaystyle\\sum_{t=1}^{T}\\left\\|\\frac{\\alpha_{i^{*}}}{2}\\mathbf{g}_{t}\\langle\\mathbf{g}_{t},\\mathbf{x}_{t}-\\mathbf{x}_{t,i^{*}}\\rangle\\right\\|^{2}}\\\\ &{\\leq15(2\\sigma_{1:T}^{2}+\\Sigma_{1:T}^{2})+60L\\displaystyle\\sum_{t=1}^{T}\\mathcal{D}_{F_{t}}(\\mathbf{x}^{\\star},\\mathbf{x}_{t})+2\\alpha_{i^{*}}^{2}G^{2}\\displaystyle\\sum_{t=1}^{T}\\langle\\mathbf{g}_{t},\\mathbf{x}_{t}-\\mathbf{x}_{t,i^{*}}\\rangle^{2}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "Plugging the surrogate\u2019s empirical gradient variation back to the base regret, we obtain ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\displaystyle\\mathrm{BaSE-REq}\\leq\\frac{16d}{\\alpha_{i^{\\star}}}\\ln\\left(1+\\frac{15\\alpha_{i^{\\star}}}{8d}(2\\sigma_{1:T}^{2}+\\Sigma_{1:T}^{2})+\\frac{15L\\alpha_{i^{\\star}}}{2d}\\sum_{t=1}^{T}\\mathcal{D}_{F_{t}}(\\mathbf{x}^{\\star},\\mathbf{x}_{t})\\right.}\\\\ &{\\displaystyle+\\left.\\frac{\\alpha_{i^{\\star}}^{3}G^{2}}{4d}\\sum_{t=1}^{T}\\langle\\mathbf{g}_{t},\\mathbf{x}_{t}-\\mathbf{x}_{t,i^{\\star}}\\rangle^{2}\\right)\\leq\\mathcal{O}\\left(\\frac{d}{\\alpha}\\ln\\left(\\sigma_{1:T}^{2}+\\Sigma_{1:T}^{2}\\right)\\right)+\\mathcal{O}(\\ln C_{12})}\\\\ &{\\displaystyle+\\left.\\frac{120L}{C_{12}}\\sum_{t=1}^{T}\\mathcal{D}_{F_{t}}(\\mathbf{x}^{\\star},\\mathbf{x}_{t})+\\frac{4G^{2}}{C_{12}}\\sum_{t=1}^{T}\\langle\\mathbf{g}_{t},\\mathbf{x}_{t}-\\mathbf{x}_{t,i^{\\star}}\\rangle^{2},}\\end{array}\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "where the second step requires $C_{12}\\geq1$ by Lemma 5. ", "page_idx": 22}, {"type": "text", "text": "For strongly convex functions, we need to delve into the proof details of the base algorithm, i.e., OOGD (B.8) with step size $\\eta_{t}=2/(1+\\lambda_{i}t)$ and optimism $\\mathbf{m}_{t}=\\nabla h_{t-1,i}^{\\mathrm{sc}}(\\mathbf{x}_{t-1,i})$ . For example, from Lemma 12 of Yan et al. [2023], the base regret can be bounded as ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\mathtt{B A S E-R E G}\\leq4\\sum_{t=2}^{T}\\frac{1}{\\lambda_{i^{\\star}}t}\\mathbb{E}\\left[\\left\\|\\nabla h_{t,i^{\\star}}^{\\mathrm{sc}}(\\mathbf{x}_{t,i^{\\star}})-\\nabla h_{t-1,i^{\\star}}^{\\mathrm{sc}}(\\mathbf{x}_{t-1,i^{\\star}})\\right\\|^{2}\\right]+\\mathcal{O}(1).\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "Subsequently, we analyze the empirical gradient variation defined on surrogates in each round, i.e., $\\|\\nabla h_{t,i^{\\star}}^{\\mathrm{sc}}(\\mathbf x_{t,i^{\\star}})-\\nabla h_{t-1,i^{\\star}}^{\\mathrm{sc}}(\\mathbf x_{t-1,i^{\\star}})\\|^{2}$ . Denoting by $\\begin{array}{r}{\\sigma_{t}^{2}\\triangleq\\operatorname*{max}_{\\mathbf{x}\\in\\mathcal{X}}\\mathbb{E}_{f_{t}\\sim\\mathcal{F}_{t}}[\\|\\nabla f_{t}(\\mathbf{x})-\\nabla F_{t}(\\mathbf{x})\\|^{2}]}\\end{array}$ and $\\begin{array}{r}{\\Sigma_{t}^{2}\\triangleq\\mathbb{E}[\\operatorname*{sup}_{\\mathbf{x}\\in\\mathcal{X}}\\|\\nabla F_{t}(\\mathbf{x})-\\nabla F_{t-1}(\\mathbf{x})\\|^{2}]}\\end{array}$ for simplicity, ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\mathbb{E}\\left[\\left\\|\\nabla h_{t,i^{\\star}}^{\\mathrm{sc}}(\\mathbf{x}_{t,i^{\\star}})-\\nabla h_{t-1,i^{\\star}}^{\\mathrm{sc}}(\\mathbf{x}_{t-1,i^{\\star}})\\right\\|^{2}\\right]\n$$", "text_format": "latex", "page_idx": 22}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{=\\mathbb{E}\\left[\\left\\|\\mathbf{g}_{t}+\\frac{\\lambda_{i^{\\star}}}{2}(\\mathbf{x}_{t,i^{\\star}}-\\mathbf{x}_{t})-\\mathbf{g}_{t-1}-\\frac{\\lambda_{i^{\\star}}}{2}(\\mathbf{x}_{t-1,i^{\\star}}-\\mathbf{x}_{t-1})\\right\\|^{2}\\right]}\\\\ &{\\leq3\\mathbb{E}\\left[\\|\\mathbf{g}_{t}-\\mathbf{g}_{t-1}\\|^{2}\\right]+3\\left\\|\\frac{\\lambda_{i^{\\star}}}{2}(\\mathbf{x}_{t,i^{\\star}}-\\mathbf{x}_{t})\\right\\|^{2}+3\\left\\|\\frac{\\lambda_{i^{\\star}}}{2}(\\mathbf{x}_{t-1,i^{\\star}}-\\mathbf{x}_{t-1})\\right\\|^{2}}\\\\ &{\\leq15(\\sigma_{t}^{2}+\\sigma_{t-1}^{2}+2L\\mathcal{D}_{F_{t}}(\\mathbf{x}^{\\star},\\mathbf{x}_{t})+2L\\mathcal{D}_{F_{t-1}}(\\mathbf{x}^{\\star},\\mathbf{x}_{t-1})+\\Sigma_{t}^{2})}\\\\ &{\\qquad+\\lambda_{i^{\\star}}^{2}\\|\\mathbf{x}_{t,i^{\\star}}-\\mathbf{x}_{t}\\|^{2}+\\lambda_{i^{\\star}}^{2}\\|\\mathbf{x}_{t-1,i^{\\star}}-\\mathbf{x}_{t-1}\\|^{2},}\\end{array}\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "where the first step is due to the property of the surrogate: $\\begin{array}{r}{\\nabla h_{t,i}^{\\mathrm{sc}}(\\mathbf{x}_{t,i})=\\mathbf{g}_{t}+\\frac{\\lambda_{i}}{2}(\\mathbf{x}_{t,i}-\\mathbf{x}_{t})}\\end{array}$ , and the second step is due to the Cauchy-Schwarz inequality. Plugging the above term back into the base regret and omitting the ignorable $O(1)$ term, we achieve ", "page_idx": 23}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathtt{B A S E-R E G}\\leq\\displaystyle\\frac{60}{\\lambda_{i^{\\star}}}\\sum_{t=2}^{T}\\frac{\\sigma_{t}^{2}+\\sigma_{t-1}^{2}+\\Sigma_{t}^{2}}{t}+120L\\sum_{t=2}^{T}\\frac{\\mathcal{D}_{F_{t}}\\left(\\mathbf{x}^{\\star},\\mathbf{x}_{t}\\right)+\\mathcal{D}_{F_{t-1}}\\left(\\mathbf{x}^{\\star},\\mathbf{x}_{t-1}\\right)}{\\lambda_{i^{\\star}}t}}\\\\ &{\\qquad\\qquad\\qquad+\\displaystyle4\\sum_{t=2}^{T}\\frac{\\lambda_{i^{\\star}}^{2}\\,\\|\\mathbf{x}_{t,i^{\\star}}-\\mathbf{x}_{t}\\|^{2}+\\lambda_{i^{\\star}}^{2}\\,\\|\\mathbf{x}_{t-1,i^{\\star}}-\\mathbf{x}_{t-1}\\|^{2}}{\\lambda_{i^{\\star}}t},}\\end{array}\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "To handle the above term of $\\textstyle\\sum_{t=1}^{T}a_{t}/t$ for some variable sequence $\\{a_{t}\\}_{t=1}^{T}$ , we import a useful lemma from Yan et al. [2023] . ", "page_idx": 23}, {"type": "text", "text": "Lemma 4 (Lemma 9 of Yan et al. [2023]). For a sequence of $\\{a_{t}\\}_{t=1}^{T}$ and $b$ , where $a_{t},b>0$ for any $t\\in[T],$ , denoting by $a_{\\operatorname*{max}}\\triangleq\\operatorname*{max}_{t}a_{t}$ and $\\begin{array}{r}{A\\triangleq\\lceil b\\sum_{t=1}^{T}a_{t}\\rceil}\\end{array}$ , we have ", "page_idx": 23}, {"type": "equation", "text": "$$\n\\sum_{t=1}^{T}\\frac{a_{t}}{b t}\\leq\\frac{a_{\\operatorname*{max}}}{b}(1+\\ln A)+\\frac{1}{b^{2}}.\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "Using Lemma 4, we control the base regret as ", "page_idx": 23}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\quad\\mathtt{B a s E-R E G}\\le\\mathcal{O}\\left(\\frac{1}{\\lambda}\\left(\\sigma_{\\operatorname*{max}}^{2}+\\Sigma_{\\operatorname*{max}}^{2}\\right)\\ln\\frac{\\sigma_{1,T}^{2}}{\\sigma_{\\operatorname*{max}}^{2}+\\Sigma_{\\operatorname*{max}}^{2}}+\\Sigma_{1}^{2}\\underline{{\\tau}}\\right)}\\\\ &{\\qquad\\quad+\\frac{480L G D}{\\lambda_{i}*}\\ln\\left(1+2\\lambda_{i^{*}}\\sum_{t=1}^{T}\\mathcal{D}_{F_{t}}(\\mathbf{x}^{*},\\mathbf{x}_{t})\\right)+\\frac{8D^{2}}{\\lambda_{i^{*}}}\\ln\\left(1+2\\lambda_{i^{*}}^{3}\\sum_{t=1}^{T}\\|\\mathbf{x}_{t,i^{*}}-\\mathbf{x}_{t}\\|^{2}\\right)}\\\\ &{\\le\\mathcal{O}\\left(\\frac{1}{\\lambda}\\left(\\sigma_{\\operatorname*{max}}^{2}+\\Sigma_{\\operatorname*{max}}^{2}\\right)\\ln\\frac{\\sigma_{1,T}^{2}}{\\sigma_{\\operatorname*{max}}^{2}+\\Sigma_{\\operatorname*{max}}^{2}}\\right)+\\mathcal{O}(\\ln C_{13}+\\ln C_{14})}\\\\ &{\\qquad\\quad+\\frac{960L G D}{C_{13}}\\sum_{t=1}^{T}\\mathcal{D}_{F_{t}}(\\mathbf{x}^{*},\\mathbf{x}_{t})+\\frac{16D^{2}}{C_{14}}\\sum_{t=2}^{T}\\|\\mathbf{x}_{t,i^{*}}-\\mathbf{x}_{t}\\|^{2},}\\end{array}\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "where the first term initializes Lemma 4 as $a_{t}=\\sigma_{t}^{2}+\\sigma_{t-1}^{2}+\\Sigma_{t}^{2}$ (i.e., $a_{\\mathrm{max}}=\\mathcal{O}(\\sigma_{\\mathrm{max}}^{2}+\\Sigma_{\\mathrm{max}}^{2}))$ and $b=1/(\\sigma_{\\mathrm{max}}^{2}+\\Sigma_{\\mathrm{max}}^{2})$ , the second term initializes Lemma 4 as $a_{t}=\\mathcal{D}_{F_{t}}\\big(\\mathbf{x}^{\\star},\\mathbf{x}_{t}\\big)+\\mathcal{D}_{F_{t-1}}\\big(\\mathbf{x}^{\\star},\\mathbf{x}_{t-1}\\big)$ (i.e., $a_{\\mathrm{max}}\\,=\\,4G D$ due to Assumption 1) and $b\\,=\\,\\lambda_{i^{\\star}}$ , the third term initializes Lemma 4 as $a_{t}=\\lambda_{i^{\\star}}^{2}\\|\\mathbf{x}_{t,i^{\\star}}-\\mathbf{x}_{t}\\|^{2}+\\lambda_{i^{\\star}}^{2}\\|\\mathbf{x}_{t-1,i^{\\star}}-\\mathbf{x}_{t-1}\\|^{2}$ (i.e., $a_{\\mathrm{max}}=2D^{2}$ due to $\\lambda_{i}\\leq1$ and Assumption 1) and $b\\,=\\,\\lambda_{i^{\\star}}$ . The $\\mathcal{O}(1)$ term contains ignorable terms like $\\mathcal{O}(1/\\lambda)$ . The second step requires $C_{13},C_{14}\\geq1$ by Lemma 5. ", "page_idx": 23}, {"type": "text", "text": "Regret Analysis. For convex functions, by combining the meta and base regret, it holds that ", "page_idx": 23}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathsf{R E G}_{T}\\leq\\mathcal{O}\\left(\\sqrt{\\sigma_{1:T}^{2}+\\Sigma_{1:T}^{2}}\\right)+\\mathcal{O}(C_{10}+C_{11})+\\left(\\displaystyle\\frac{C_{0}}{2C_{10}}+\\frac{5D}{2C_{11}}-1\\right)\\displaystyle\\sum_{t=1}^{T}\\mathcal{D}_{F_{t}}(\\mathbf{x}^{\\star},\\mathbf{x}_{t})}\\\\ &{\\qquad\\quad\\leq\\mathcal{O}\\left(\\sqrt{\\sigma_{1:T}^{2}+\\Sigma_{1:T}^{2}}\\right),}\\end{array}\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "by choosing $C_{10}=C_{0}$ and $C_{11}=5D$ . For exp-concave functions, by combining the meta and base regret, it holds that ", "page_idx": 23}, {"type": "equation", "text": "$$\n\\mathsf{R E G}_{T}\\leq\\mathcal{O}\\left(\\frac{d}{\\alpha}\\ln\\left(\\sigma_{1:T}^{2}+\\Sigma_{1:T}^{2}\\right)\\right)+\\mathcal{O}(C_{3}+\\ln C_{12})+\\left(\\frac{120L}{C_{12}}-\\frac{1}{2}\\right)\\sum_{t=1}^{T}\\mathcal{D}_{F_{t}}(\\mathbf{x}^{\\star},\\mathbf{x}_{t})\n$$", "text_format": "latex", "page_idx": 23}, {"type": "equation", "text": "$$\n+\\left(\\frac{C_{0}}{2C_{3}}+\\frac{4G^{2}}{C_{12}}-\\frac{\\alpha_{i^{\\star}}}{4}\\right)\\sum_{t=1}^{T}\\langle\\mathbf{g}_{t},\\mathbf{x}_{t}-\\mathbf{x}_{t,i^{\\star}}\\rangle^{2}\\leq\\mathcal{O}\\left(\\frac{d}{\\alpha}\\ln\\left(\\sigma_{1:T}^{2}+\\Sigma_{1:T}^{2}\\right)\\right),\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "by choosing C12 = max{1, 240L, 3\u03b12G\u22c62} and $\\begin{array}{r}{C_{3}=\\frac{4C_{0}}{\\alpha_{i^{\\star}}}}\\end{array}$ . Note that such a parameter configuration will only add an ${\\mathcal{O}}(1/\\alpha)$ factor to the final regret bound, which can be absorbed. For strongly convex functions, by combining the meta and base regret, it holds that ", "page_idx": 24}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\quad{\\texttt R E G}_{T}\\leq\\mathcal{O}\\left(\\frac{1}{\\lambda}\\left(\\sigma_{\\operatorname*{max}}^{2}+\\Sigma_{\\operatorname*{max}}^{2}\\right)\\ln\\frac{\\sigma_{1:T}^{2}+\\Sigma_{1:T}^{2}}{\\sigma_{\\operatorname*{max}}^{2}+\\Sigma_{\\operatorname*{max}}^{2}}\\right)+\\mathcal{O}(C_{4}+\\ln C_{13}+\\ln C_{14})}\\\\ &{\\quad+\\left(\\frac{C_{0}D^{2}}{2C_{4}}+\\frac{16D^{2}}{C_{14}}-\\frac{\\lambda_{i^{*}}}{4}\\right)\\displaystyle\\sum_{t=1}^{T}\\left\\|{\\texttt x}_{t}-{\\texttt x}_{t,i^{*}}\\right\\|^{2}+\\left(\\frac{960L G D}{C_{13}}-\\frac{1}{2}\\right)\\displaystyle\\sum_{t=1}^{T}\\mathcal{D}_{F_{t}}({\\texttt x}^{\\star},{\\texttt x}_{t})}\\\\ &{\\leq\\mathcal{O}\\left(\\frac{1}{\\lambda}\\left(\\sigma_{\\operatorname*{max}}^{2}+\\Sigma_{\\operatorname*{max}}^{2}\\right)\\ln\\frac{\\sigma_{1:T}^{2}+\\Sigma_{1:T}^{2}}{\\sigma_{\\operatorname*{max}}^{2}+\\Sigma_{\\operatorname*{max}}^{2}}\\right),}\\end{array}\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "by choosing $\\begin{array}{r}{C_{13}=\\operatorname*{max}\\{1,1920L G D\\},C_{14}=\\operatorname*{max}\\{1,\\frac{128D^{2}}{\\lambda_{i^{\\star}}}\\}}\\end{array}$ and $\\begin{array}{r}{C_{4}=\\frac{4C_{0}D^{2}}{\\lambda_{i}\\star}}\\end{array}$ . Note that such a parameter configuration will only add an $\\mathcal{O}(1/\\lambda)$ factor to the final bound, which can be absorbed. Note that the constants $C_{3},C_{4},C_{10},C_{11},C_{12},C_{13},C_{14}$ only exist in analysis and thus can be chosen arbitrarily, finishing the proof. \u53e3 ", "page_idx": 24}, {"type": "text", "text": "D Technical Lemmas ", "text_level": 1, "page_idx": 24}, {"type": "text", "text": "Lemma 5. For any $a>1,b>0$ , it holds that $\\begin{array}{r}{\\ln(a+b)\\leq\\ln(C a)+\\frac{b}{C}}\\end{array}$ for some $C\\geq1$ . ", "page_idx": 24}, {"type": "text", "text": "Proof. The one-line proof is presented below: ", "page_idx": 24}, {"type": "equation", "text": "$$\n\\ln(a+b)\\leq\\ln(C a+b)\\leq\\ln(C a)+\\ln\\left(1+{\\frac{b}{C a}}\\right)\\leq\\ln(C a)+{\\frac{b}{C}},\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "where the first step is due to $C\\geq1$ , and the last step adopts $\\ln(1+x)\\leq x$ for any $x\\geq0$ . ", "page_idx": 24}, {"type": "text", "text": "Lemma 6 (Corollary 5 of Orabona et al. [2012]). If $a,b,c,d,x>0$ satisfy $x-d\\leq a\\ln(b x+c)$ , then it holds that ", "page_idx": 24}, {"type": "equation", "text": "$$\nx-d\\leq a\\ln\\left(2a b\\ln{\\frac{2a b}{e}}+2b d+2c\\right).\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "NeurIPS Paper Checklist ", "text_level": 1, "page_idx": 25}, {"type": "text", "text": "1. Claims ", "text_level": 1, "page_idx": 25}, {"type": "text", "text": "Question: Do the main claims made in the abstract and introduction accurately reflect the paper\u2019s contributions and scope? ", "page_idx": 25}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 25}, {"type": "text", "text": "Justification: We have claimed the paper\u2019s contribution in both the abstract and the introduction part. ", "page_idx": 25}, {"type": "text", "text": "Guidelines: ", "page_idx": 25}, {"type": "text", "text": "\u2022 The answer NA means that the abstract and introduction do not include the claims made in the paper.   \n\u2022 The abstract and/or introduction should clearly state the claims made, including the contributions made in the paper and important assumptions and limitations. A No or NA answer to this question will not be perceived well by the reviewers.   \n\u2022 The claims made should match theoretical and experimental results, and reflect how much the results can be expected to generalize to other settings.   \n\u2022 It is fine to include aspirational goals as motivation as long as it is clear that these goals are not attained by the paper. ", "page_idx": 25}, {"type": "text", "text": "2. Limitations ", "text_level": 1, "page_idx": 25}, {"type": "text", "text": "Question: Does the paper discuss the limitations of the work performed by the authors? ", "page_idx": 25}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 25}, {"type": "text", "text": "Justification: One limitation we could discover is that our approach is not applicable in multi-player games since it does not control the algorithmic stability, which is essential and necessary in achieving fast rates in games. ", "page_idx": 25}, {"type": "text", "text": "Guidelines: ", "text_level": 1, "page_idx": 25}, {"type": "text", "text": "\u2022 The answer NA means that the paper has no limitation while the answer No means that the paper has limitations, but those are not discussed in the paper.   \n\u2022 The authors are encouraged to create a separate \u201dLimitations\u201d section in their paper.   \n\u2022 The paper should point out any strong assumptions and how robust the results are to violations of these assumptions (e.g., independence assumptions, noiseless settings, model well-specification, asymptotic approximations only holding locally). The authors should reflect on how these assumptions might be violated in practice and what the implications would be.   \n\u2022 The authors should reflect on the scope of the claims made, e.g., if the approach was only tested on a few datasets or with a few runs. In general, empirical results often depend on implicit assumptions, which should be articulated.   \n\u2022 The authors should reflect on the factors that influence the performance of the approach. For example, a facial recognition algorithm may perform poorly when image resolution is low or images are taken in low lighting. Or a speech-to-text system might not be used reliably to provide closed captions for online lectures because it fails to handle technical jargon.   \n\u2022 The authors should discuss the computational efficiency of the proposed algorithms and how they scale with dataset size.   \n\u2022 If applicable, the authors should discuss possible limitations of their approach to address problems of privacy and fairness.   \n\u2022 While the authors might fear that complete honesty about limitations might be used by reviewers as grounds for rejection, a worse outcome might be that reviewers discover limitations that aren\u2019t acknowledged in the paper. The authors should use their best judgment and recognize that individual actions in favor of transparency play an important role in developing norms that preserve the integrity of the community. Reviewers will be specifically instructed to not penalize honesty concerning limitations. ", "page_idx": 25}, {"type": "text", "text": "3. Theory Assumptions and Proofs ", "text_level": 1, "page_idx": 25}, {"type": "text", "text": "Question: For each theoretical result, does the paper provide the full set of assumptions and a complete (and correct) proof? ", "page_idx": 25}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 26}, {"type": "text", "text": "Justification: The assumptions are provided and justified in Section 2. We provide theoretical guarantees in Section 3 and Section 4, and all the corresponding proofs can be found in Appendix B and Appendix C. ", "page_idx": 26}, {"type": "text", "text": "Guidelines: ", "page_idx": 26}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include theoretical results.   \n\u2022 All the theorems, formulas, and proofs in the paper should be numbered and crossreferenced.   \n\u2022 All assumptions should be clearly stated or referenced in the statement of any theorems.   \n\u2022 The proofs can either appear in the main paper or the supplemental material, but if they appear in the supplemental material, the authors are encouraged to provide a short proof sketch to provide intuition.   \n\u2022 Inversely, any informal proof provided in the core of the paper should be complemented by formal proofs provided in appendix or supplemental material.   \n\u2022 Theorems and Lemmas that the proof relies upon should be properly referenced. ", "page_idx": 26}, {"type": "text", "text": "4. Experimental Result Reproducibility ", "text_level": 1, "page_idx": 26}, {"type": "text", "text": "Question: Does the paper fully disclose all the information needed to reproduce the main experimental results of the paper to the extent that it affects the main claims and/or conclusions of the paper (regardless of whether the code and data are provided or not)? ", "page_idx": 26}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 26}, {"type": "text", "text": "Justification: This paper does not include experiments. ", "page_idx": 26}, {"type": "text", "text": "Guidelines: ", "page_idx": 26}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 If the paper includes experiments, a No answer to this question will not be perceived well by the reviewers: Making the paper reproducible is important, regardless of whether the code and data are provided or not.   \n\u2022 If the contribution is a dataset and/or model, the authors should describe the steps taken to make their results reproducible or verifiable.   \n\u2022 Depending on the contribution, reproducibility can be accomplished in various ways. For example, if the contribution is a novel architecture, describing the architecture fully might suffice, or if the contribution is a specific model and empirical evaluation, it may be necessary to either make it possible for others to replicate the model with the same dataset, or provide access to the model. In general. releasing code and data is often one good way to accomplish this, but reproducibility can also be provided via detailed instructions for how to replicate the results, access to a hosted model (e.g., in the case of a large language model), releasing of a model checkpoint, or other means that are appropriate to the research performed.   \n\u2022 While NeurIPS does not require releasing code, the conference does require all submissions to provide some reasonable avenue for reproducibility, which may depend on the nature of the contribution. For example (a) If the contribution is primarily a new algorithm, the paper should make it clear how to reproduce that algorithm. (b) If the contribution is primarily a new model architecture, the paper should describe the architecture clearly and fully. (c) If the contribution is a new model (e.g., a large language model), then there should either be a way to access this model for reproducing the results or a way to reproduce the model (e.g., with an open-source dataset or instructions for how to construct the dataset). (d) We recognize that reproducibility may be tricky in some cases, in which case authors are welcome to describe the particular way they provide for reproducibility. In the case of closed-source models, it may be that access to the model is limited in some way (e.g., to registered users), but it should be possible for other researchers to have some path to reproducing or verifying the results. ", "page_idx": 26}, {"type": "text", "text": "5. Open access to data and code ", "text_level": 1, "page_idx": 26}, {"type": "text", "text": "Question: Does the paper provide open access to the data and code, with sufficient instructions to faithfully reproduce the main experimental results, as described in supplemental material? ", "page_idx": 27}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 27}, {"type": "text", "text": "Justification: This paper does not include experiments requiring code. Guidelines: ", "page_idx": 27}, {"type": "text", "text": "\u2022 The answer NA means that paper does not include experiments requiring code.   \n\u2022 Please see the NeurIPS code and data submission guidelines (https://nips.cc/ public/guides/CodeSubmissionPolicy) for more details.   \n\u2022 While we encourage the release of code and data, we understand that this might not be possible, so \u201cNo\u201d is an acceptable answer. Papers cannot be rejected simply for not including code, unless this is central to the contribution (e.g., for a new open-source benchmark).   \n\u2022 The instructions should contain the exact command and environment needed to run to reproduce the results. See the NeurIPS code and data submission guidelines (https: //nips.cc/public/guides/CodeSubmissionPolicy) for more details.   \n\u2022 The authors should provide instructions on data access and preparation, including how to access the raw data, preprocessed data, intermediate data, and generated data, etc.   \n\u2022 The authors should provide scripts to reproduce all experimental results for the new proposed method and baselines. If only a subset of experiments are reproducible, they should state which ones are omitted from the script and why.   \n\u2022 At submission time, to preserve anonymity, the authors should release anonymized versions (if applicable).   \n\u2022 Providing as much information as possible in supplemental material (appended to the paper) is recommended, but including URLs to data and code is permitted. ", "page_idx": 27}, {"type": "text", "text": "6. Experimental Setting/Details ", "text_level": 1, "page_idx": 27}, {"type": "text", "text": "Question: Does the paper specify all the training and test details (e.g., data splits, hyperparameters, how they were chosen, type of optimizer, etc.) necessary to understand the results? ", "page_idx": 27}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 27}, {"type": "text", "text": "Justification: This paper does not include experiments. ", "page_idx": 27}, {"type": "text", "text": "Guidelines: ", "page_idx": 27}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments. \u2022 The experimental setting should be presented in the core of the paper to a level of detail that is necessary to appreciate the results and make sense of them. \u2022 The full details can be provided either with the code, in appendix, or as supplemental material. ", "page_idx": 27}, {"type": "text", "text": "7. Experiment Statistical Significance ", "text_level": 1, "page_idx": 27}, {"type": "text", "text": "Question: Does the paper report error bars suitably and correctly defined or other appropriate information about the statistical significance of the experiments? ", "page_idx": 27}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 27}, {"type": "text", "text": "Justification: This paper does not include experiments. ", "page_idx": 27}, {"type": "text", "text": "Guidelines: ", "page_idx": 27}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 The authors should answer \u201dYes\u201d if the results are accompanied by error bars, confidence intervals, or statistical significance tests, at least for the experiments that support the main claims of the paper.   \n\u2022 The factors of variability that the error bars are capturing should be clearly stated (for example, train/test split, initialization, random drawing of some parameter, or overall run with given experimental conditions).   \n\u2022 The method for calculating the error bars should be explained (closed form formula, call to a library function, bootstrap, etc.)   \n\u2022 The assumptions made should be given (e.g., Normally distributed errors).   \n\u2022 It should be clear whether the error bar is the standard deviation or the standard error of the mean.   \n\u2022 It is OK to report 1-sigma error bars, but one should state it. The authors should preferably report a 2-sigma error bar than state that they have a $96\\%$ CI, if the hypothesis of Normality of errors is not verified.   \n\u2022 For asymmetric distributions, the authors should be careful not to show in tables or figures symmetric error bars that would yield results that are out of range (e.g. negative error rates).   \n\u2022 If error bars are reported in tables or plots, The authors should explain in the text how they were calculated and reference the corresponding figures or tables in the text. ", "page_idx": 27}, {"type": "text", "text": "", "page_idx": 28}, {"type": "text", "text": "8. Experiments Compute Resources ", "text_level": 1, "page_idx": 28}, {"type": "text", "text": "Question: For each experiment, does the paper provide sufficient information on the computer resources (type of compute workers, memory, time of execution) needed to reproduce the experiments? ", "page_idx": 28}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 28}, {"type": "text", "text": "Justification: This paper does not include experiments. ", "page_idx": 28}, {"type": "text", "text": "Guidelines: ", "page_idx": 28}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 The paper should indicate the type of compute workers CPU or GPU, internal cluster, or cloud provider, including relevant memory and storage.   \n\u2022 The paper should provide the amount of compute required for each of the individual experimental runs as well as estimate the total compute.   \n\u2022 The paper should disclose whether the full research project required more compute than the experiments reported in the paper (e.g., preliminary or failed experiments that didn\u2019t make it into the paper). ", "page_idx": 28}, {"type": "text", "text": "9. Code Of Ethics ", "text_level": 1, "page_idx": 28}, {"type": "text", "text": "Question: Does the research conducted in the paper conform, in every respect, with the NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines? ", "page_idx": 28}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 28}, {"type": "text", "text": "Justification: The research conducted in the paper conforms with the NeurIPS Code of Ethics. ", "page_idx": 28}, {"type": "text", "text": "Guidelines: ", "page_idx": 28}, {"type": "text", "text": "\u2022 The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics.   \n\u2022 If the authors answer No, they should explain the special circumstances that require a deviation from the Code of Ethics.   \n\u2022 The authors should make sure to preserve anonymity (e.g., if there is a special consideration due to laws or regulations in their jurisdiction). ", "page_idx": 28}, {"type": "text", "text": "10. Broader Impacts ", "text_level": 1, "page_idx": 28}, {"type": "text", "text": "Question: Does the paper discuss both potential positive societal impacts and negative societal impacts of the work performed? ", "page_idx": 28}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 28}, {"type": "text", "text": "Justification: This paper is a purely theoretical work, and we do not find specific societal impacts that should be highlighted here. ", "page_idx": 28}, {"type": "text", "text": "Guidelines: ", "page_idx": 28}, {"type": "text", "text": "\u2022 The answer NA means that there is no societal impact of the work performed.   \n\u2022 If the authors answer NA or No, they should explain why their work has no societal impact or why the paper does not address societal impact.   \n\u2022 Examples of negative societal impacts include potential malicious or unintended uses (e.g., disinformation, generating fake profiles, surveillance), fairness considerations (e.g., deployment of technologies that could make decisions that unfairly impact specific groups), privacy considerations, and security considerations.   \n\u2022 The conference expects that many papers will be foundational research and not tied to particular applications, let alone deployments. However, if there is a direct path to any negative applications, the authors should point it out. For example, it is legitimate to point out that an improvement in the quality of generative models could be used to generate deepfakes for disinformation. On the other hand, it is not needed to point out that a generic algorithm for optimizing neural networks could enable people to train models that generate Deepfakes faster.   \n\u2022 The authors should consider possible harms that could arise when the technology is being used as intended and functioning correctly, harms that could arise when the technology is being used as intended but gives incorrect results, and harms following from (intentional or unintentional) misuse of the technology.   \n\u2022 If there are negative societal impacts, the authors could also discuss possible mitigation strategies (e.g., gated release of models, providing defenses in addition to attacks, mechanisms for monitoring misuse, mechanisms to monitor how a system learns from feedback over time, improving the efficiency and accessibility of ML). ", "page_idx": 28}, {"type": "text", "text": "", "page_idx": 29}, {"type": "text", "text": "11. Safeguards ", "text_level": 1, "page_idx": 29}, {"type": "text", "text": "Question: Does the paper describe safeguards that have been put in place for responsible release of data or models that have a high risk for misuse (e.g., pretrained language models, image generators, or scraped datasets)? ", "page_idx": 29}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 29}, {"type": "text", "text": "Justification: This paper does not include experiments (data or models), and thus poses no such risks. ", "page_idx": 29}, {"type": "text", "text": "Guidelines: ", "page_idx": 29}, {"type": "text", "text": "\u2022 The answer NA means that the paper poses no such risks.   \n\u2022 Released models that have a high risk for misuse or dual-use should be released with necessary safeguards to allow for controlled use of the model, for example by requiring that users adhere to usage guidelines or restrictions to access the model or implementing safety filters.   \n\u2022 Datasets that have been scraped from the Internet could pose safety risks. The authors should describe how they avoided releasing unsafe images.   \n\u2022 We recognize that providing effective safeguards is challenging, and many papers do not require this, but we encourage authors to take this into account and make a best faith effort. ", "page_idx": 29}, {"type": "text", "text": "12. Licenses for existing assets ", "text_level": 1, "page_idx": 29}, {"type": "text", "text": "Question: Are the creators or original owners of assets (e.g., code, data, models), used in the paper, properly credited and are the license and terms of use explicitly mentioned and properly respected? ", "page_idx": 29}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 29}, {"type": "text", "text": "Justification: This paper does not use existing assets. ", "page_idx": 29}, {"type": "text", "text": "Guidelines: ", "page_idx": 29}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not use existing assets.   \n\u2022 The authors should cite the original paper that produced the code package or dataset.   \n\u2022 The authors should state which version of the asset is used and, if possible, include a URL.   \n\u2022 The name of the license (e.g., CC-BY 4.0) should be included for each asset.   \n\u2022 For scraped data from a particular source (e.g., website), the copyright and terms of service of that source should be provided.   \n\u2022 If assets are released, the license, copyright information, and terms of use in the package should be provided. For popular datasets, paperswithcode.com/datasets has curated licenses for some datasets. Their licensing guide can help determine the license of a dataset.   \n\u2022 For existing datasets that are re-packaged, both the original license and the license of the derived asset (if it has changed) should be provided. ", "page_idx": 29}, {"type": "text", "text": "\u2022 If this information is not available online, the authors are encouraged to reach out to the asset\u2019s creators. ", "page_idx": 30}, {"type": "text", "text": "13. New Assets ", "text_level": 1, "page_idx": 30}, {"type": "text", "text": "Question: Are new assets introduced in the paper well documented and is the documentation provided alongside the assets? ", "page_idx": 30}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 30}, {"type": "text", "text": "Justification: This paper does not release new assets. ", "page_idx": 30}, {"type": "text", "text": "Guidelines: ", "page_idx": 30}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not release new assets.   \n\u2022 Researchers should communicate the details of the dataset/code/model as part of their submissions via structured templates. This includes details about training, license, limitations, etc.   \n\u2022 The paper should discuss whether and how consent was obtained from people whose asset is used.   \n\u2022 At submission time, remember to anonymize your assets (if applicable). You can either create an anonymized URL or include an anonymized zip file. ", "page_idx": 30}, {"type": "text", "text": "14. Crowdsourcing and Research with Human Subjects ", "text_level": 1, "page_idx": 30}, {"type": "text", "text": "Question: For crowdsourcing experiments and research with human subjects, does the paper include the full text of instructions given to participants and screenshots, if applicable, as well as details about compensation (if any)? ", "page_idx": 30}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 30}, {"type": "text", "text": "Justification: This paper does not involve crowdsourcing nor research with human subjects. Guidelines: ", "page_idx": 30}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u2022 Including this information in the supplemental material is fine, but if the main contribution of the paper involves human subjects, then as much detail as possible should be included in the main paper.   \n\u2022 According to the NeurIPS Code of Ethics, workers involved in data collection, curation, or other labor should be paid at least the minimum wage in the country of the data collector. ", "page_idx": 30}, {"type": "text", "text": "15. Institutional Review Board (IRB) Approvals or Equivalent for Research with Human Subjects ", "text_level": 1, "page_idx": 30}, {"type": "text", "text": "Question: Does the paper describe potential risks incurred by study participants, whether such risks were disclosed to the subjects, and whether Institutional Review Board (IRB) approvals (or an equivalent approval/review based on the requirements of your country or institution) were obtained? ", "page_idx": 30}, {"type": "text", "text": "Answer: [NA] ", "text_level": 1, "page_idx": 30}, {"type": "text", "text": "Justification: This paper does not involve crowdsourcing nor research with human subjects. Guidelines: ", "page_idx": 30}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u2022 Depending on the country in which research is conducted, IRB approval (or equivalent) may be required for any human subjects research. If you obtained IRB approval, you should clearly state this in the paper.   \n\u2022 We recognize that the procedures for this may vary significantly between institutions and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the guidelines for their institution.   \n\u2022 For initial submissions, do not include any information that would break anonymity (if applicable), such as the institution conducting the review. ", "page_idx": 30}]