{"references": [{"fullname_first_author": "Martin Arjovsky", "paper_title": "Wasserstein generative adversarial networks", "publication_date": "2017-00-00", "reason": "This paper introduces Wasserstein GANs, a significant advancement in generative adversarial networks that addresses training instability and improves sample quality, relevant to the current paper's use of optimal transport."}, {"fullname_first_author": "Yuri Burda", "paper_title": "Exploration by random network distillation", "publication_date": "2019-00-00", "reason": "This paper proposes a novel exploration method for reinforcement learning using random network distillation, which is relevant to the focus on reward design and exploration in the current paper."}, {"fullname_first_author": "Marco Cuturi", "paper_title": "Sinkhorn distances: Lightspeed computation of optimal transport", "publication_date": "2013-00-00", "reason": "This paper presents an efficient algorithm for computing optimal transport distances, which is fundamental to the current paper's use of optimal transport for reward shaping."}, {"fullname_first_author": "Peter Dayan", "paper_title": "Reward, motivation, and reinforcement learning", "publication_date": "2002-00-00", "reason": "This paper provides a foundational overview of reward, motivation, and reinforcement learning, forming a basis for the current work's discussion of reward design challenges in reinforcement learning."}, {"fullname_first_author": "Richard S Sutton", "paper_title": "Reinforcement learning: An introduction", "publication_date": "2018-00-00", "reason": "This paper is a comprehensive introduction to reinforcement learning, providing essential background and context for the current paper's exploration of reinforcement learning techniques and reward functions."}]}