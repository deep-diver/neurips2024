[{"figure_path": "P6aJ7BqYlc/tables/tables_6_1.jpg", "caption": "Table 1: Comparison of AAUC, AAvg, and ALast among the GACL and other methods under the Si-Blurry setting. Data in bold represent the best EFCIL results, and data underlined are the best among all settings. We run all experiments 5 times and show \u201cmean\u00b1standard error\u201d.", "description": "This table compares the performance of the proposed GACL method against other state-of-the-art methods (both exemplar-free and replay-based) under the Si-Blurry setting, a challenging continual learning scenario.  The comparison uses three metrics: Average Area Under the Curve (AAUC), Average Accuracy (AAvg), and Last Task Accuracy (ALast).  The best performance among exemplar-free continual learning (EFCIL) methods is highlighted in bold, while the overall best performance across all methods and settings is underlined.  Results are averaged over five independent runs, with standard errors reported.", "section": "4.2 Comparison with State-of-the-arts"}, {"figure_path": "P6aJ7BqYlc/tables/tables_8_1.jpg", "caption": "Table 1: Comparison of AAUC, AAvg, and ALast among the GACL and other methods under the Si-Blurry setting. Data in bold represent the best EFCIL results, and data underlined are the best among all settings. We run all experiments 5 times and show \u201cmean\u00b1standard error\u201d.", "description": "This table compares the performance of the proposed GACL method against other state-of-the-art methods (both exemplar-free and replay-based) for generalized class incremental learning under the Si-Blurry setting.  The comparison uses three metrics: Average Area Under the Curve (AAUC), Average Accuracy (AAvg), and Last Task Accuracy (ALast). The best performance among exemplar-free continual learning methods is highlighted in bold, and the overall best performance across all methods is underlined. Results are averaged over five independent runs, with standard errors reported.", "section": "4.2 Comparison with State-of-the-arts"}, {"figure_path": "P6aJ7BqYlc/tables/tables_9_1.jpg", "caption": "Table 1: Comparison of AAUC, AAvg, and ALast among the GACL and other methods under the Si-Blurry setting. Data in bold represent the best EFCIL results, and data underlined are the best among all settings. We run all experiments 5 times and show \u201cmean\u00b1standard error\u201d.", "description": "This table compares the performance of the proposed GACL method against other state-of-the-art methods (both EFCIL and replay-based methods) across three datasets (CIFAR-100, ImageNet-R, and Tiny-ImageNet) under the Si-Blurry setting.  The comparison is done using three metrics: Average Area Under the Curve (AAUC), Average Accuracy (AAvg), and Last-task Accuracy (ALast).  The best EFCIL results and the best overall results are highlighted in bold and underlined respectively.  Each result is an average of 5 independent runs, showing mean and standard error.", "section": "4 Experiments"}, {"figure_path": "P6aJ7BqYlc/tables/tables_16_1.jpg", "caption": "Table 1: Comparison of AAUC, AAvg, and ALast among the GACL and other methods under the Si-Blurry setting. Data in bold represent the best EFCIL results, and data underlined are the best among all settings. We run all experiments 5 times and show \u201cmean\u00b1standard error\u201d.", "description": "This table compares the performance of the proposed GACL method against other state-of-the-art methods (both exemplar-free and replay-based) on three benchmark datasets (CIFAR-100, ImageNet-R, and Tiny-ImageNet) under the Si-Blurry setting of Generalized Class Incremental Learning (GCIL).  The comparison is based on three metrics: Average Area Under the Curve (AAUC), Average Accuracy (AAvg), and Last-task Accuracy (ALast).  The best performance among exemplar-free methods (EFCIL) is shown in bold, and the overall best performance across all methods is underlined.", "section": "4 Experiments"}, {"figure_path": "P6aJ7BqYlc/tables/tables_16_2.jpg", "caption": "Table 1: Comparison of AAUC, AAvg, and ALast among the GACL and other methods under the Si-Blurry setting. Data in bold represent the best EFCIL results, and data underlined are the best among all settings. We run all experiments 5 times and show \u201cmean\u00b1standard error\u201d.", "description": "This table compares the performance of the proposed GACL method against other state-of-the-art methods (both exemplar-free and replay-based) across three benchmark datasets (CIFAR-100, ImageNet-R, and Tiny-ImageNet) under the Si-Blurry setting.  The comparison uses three metrics: Average Area Under the Curve (AAUC), Average Accuracy (AAvg), and Last Task Accuracy (ALast).  The best results for exemplar-free continual learning (EFCIL) methods and overall best results are highlighted.", "section": "4 Experiments"}]