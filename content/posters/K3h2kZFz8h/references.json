{"references": [{"fullname_first_author": "E. Altman", "paper_title": "Constrained Markov decision processes", "publication_date": "1999-01-01", "reason": "This paper is foundational for understanding the mathematical framework of constrained Markov decision processes, which are relevant to multi-objective reinforcement learning problems."}, {"fullname_first_author": "L. P. Kaelbling", "paper_title": "Reinforcement learning: A survey", "publication_date": "1996-05-01", "reason": "This highly cited survey provides a comprehensive overview of reinforcement learning, offering context for the multi-objective extension explored in the main paper."}, {"fullname_first_author": "D. M. Roijers", "paper_title": "A survey of multi-objective sequential decision-making", "publication_date": "2013-10-01", "reason": "This survey focuses specifically on multi-objective sequential decision making, laying the groundwork for the analytical study of utility functions in multi-objective reinforcement learning."}, {"fullname_first_author": "C. F. Hayes", "paper_title": "A practical guide to multi-objective reinforcement learning and planning", "publication_date": "2022-01-01", "reason": "This guide offers a practical overview of multi-objective reinforcement learning, highlighting relevant solution concepts and algorithms for the main paper's theoretical analysis."}, {"fullname_first_author": "K. Van Moffaert", "paper_title": "Multi-objective reinforcement learning using sets of Pareto dominating policies", "publication_date": "2014-01-01", "reason": "This paper provides a key algorithmic approach to multi-objective reinforcement learning, which is relevant to the main paper's discussion of solution concepts and the need for characterizing utility functions."}]}