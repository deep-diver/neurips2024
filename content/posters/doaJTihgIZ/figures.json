[{"figure_path": "doaJTihgIZ/figures/figures_1_1.jpg", "caption": "Figure 1: Learning dynamics in the nonlinear perceptron. A: The perceptron, parametrized by weights w, maps an input x to the output \u0177. B: The inputs are drawn from two multivariate normal distributions with labels y = \u00b11. The weight vector w is orthogonal to the classification boundary. C: Due to the stochasticity inherent in the update equations, the weights are described by the flow of a probability distribution in weight space.", "description": "This figure illustrates the learning dynamics in a nonlinear perceptron. Panel A shows the perceptron model, where weights 'w' map inputs 'x' to output '\u0177'. Panel B depicts the input data distribution as two multivariate normal distributions with labels 'y = \u00b11', with the weight vector 'w' being orthogonal to the classification boundary. Panel C demonstrates how the stochastic nature of the update equations leads to a probability distribution flow of weights over time.", "section": "Introduction"}, {"figure_path": "doaJTihgIZ/figures/figures_3_1.jpg", "caption": "Figure 2: Learning dynamics in a perceptron classification task. A, B: Flow fields determining the weight dynamics with trajectories for different initial conditions for SL (A) and RL (B). C, D: Learning dynamics from simulations closely follow the analytical results for SL (C) and RL (D). E: Dependence of the asymptotic weight norm on the regularization parameter \u03bb.", "description": "This figure displays the results of simulations and analytical calculations of the learning dynamics of a nonlinear perceptron performing binary classification, using both supervised learning (SL) and reinforcement learning (RL). Panels A and B show vector fields representing the weight dynamics for SL and RL, respectively, with example trajectories. Panels C and D compare simulation and analytical results for the learning curves of SL and RL under different noise levels. Panel E illustrates how the asymptotic weight norm (the final magnitude of the weight vector) depends on the regularization parameter \u03bb.", "section": "Learning dynamics in the nonlinear perceptron"}, {"figure_path": "doaJTihgIZ/figures/figures_5_1.jpg", "caption": "Figure 3: Relationship between input noise and time to learn the task. A: The time required for the alignment \u03bc\u00b7 \u3008w\u3009/|\u3008w\u3009| to reach 80% depends on the noise \u03c3 of the isotropic input distributions. B: To characterize anisotropic input noise, the total input variance is split into a noise component of parallel to and a component of orthogonal to the decoding direction. C: Shifting the input noise into the decoding direction slows down learning.", "description": "This figure shows the relationship between input noise and the time it takes for a perceptron to learn a classification task. Panel A demonstrates that for isotropic noise, increasing the noise level leads to faster learning. Panel B illustrates how anisotropic noise, where the variance is different along different directions, is characterized.  Panel C shows that when anisotropic noise is shifted towards the decoding direction, learning slows down. The figure highlights the effects of both isotropic and anisotropic input noise on learning time, demonstrating differences between supervised and reinforcement learning.", "section": "Impact of noise on learning time"}, {"figure_path": "doaJTihgIZ/figures/figures_6_1.jpg", "caption": "Figure 4: Dynamics of the total variance of w for isotropic input noise. Higher noise leads to a faster decay in tr (Cov(w)) for supervised learning (A) and for reinforcement learning (B).", "description": "This figure shows how the total variance of the weight vector w changes over time (t) for both supervised learning (SL) and reinforcement learning (RL) under different levels of isotropic input noise (\u03c3). Panel A displays the results for SL, while Panel B shows the results for RL.  Each panel shows curves for three different noise levels (\u03c3 = 0, \u03c3 = 0.5, and \u03c3 = 1).  The y-axis represents the trace of the weight covariance matrix (tr(Cov(w))), a measure of the overall spread or uncertainty in the weight vector. The key observation is that higher input noise leads to a faster decay in the total variance, meaning the weights converge more quickly to a stable solution. This behavior is observed for both SL and RL, indicating a consistent effect of noise on the learning process.", "section": "Impact of noise on learning time"}, {"figure_path": "doaJTihgIZ/figures/figures_7_1.jpg", "caption": "Figure 5: Comparison of the theory with training on MNIST. A: A nonlinear perceptron is trained to classify the digits 0 and 1 in the MNIST dataset. B: Comparison of the empirical test classification accuracy with the theoretical prediction. C: Even after the task has been learned, the theory accurately captures non-trivial ongoing learning dynamics.", "description": "This figure compares the theoretical predictions of the paper's model with actual results from training a nonlinear perceptron on a subset of the MNIST dataset. Panel A shows a t-SNE visualization of the data, illustrating the separation of the two classes (digits 0 and 1). Panel B compares the theoretical and empirical test classification accuracy over the training process. Panel C shows the correlation between the weight vector (w) and the mean of the data distribution (\u00b5), demonstrating how the theory accurately reflects the learning dynamics even after the task is learned.", "section": "Application to real tasks"}, {"figure_path": "doaJTihgIZ/figures/figures_7_2.jpg", "caption": "Figure 6: Forgetting curves. A: Learning curves for multi-task learning, where w are trained on Task 1 (\u03bc = \u03bc\u2081) after training to 80% on Task 0 (\u03bc = \u03bco). B: The alignment of \u3008w\u3009 with \u03bco after training on additional tasks 1, . . ., 9.", "description": "Figure 6 demonstrates the continual learning process. Panel A presents learning curves for two tasks, showing how the weights (w) are trained on Task 1 after reaching 80% accuracy on Task 0.  Panel B illustrates the forgetting curve, demonstrating the decline in alignment between the weights and the initial task (\u03bc\u2080) as more tasks are introduced. This figure quantifies the effects of continual learning, highlighting the trade-off between learning new tasks and forgetting previously learned ones.", "section": "Continual learning"}, {"figure_path": "doaJTihgIZ/figures/figures_13_1.jpg", "caption": "Figure 5: Comparison of the theory with training on MNIST. A: A nonlinear perceptron is trained to classify the digits 0 and 1 in the MNIST dataset. B: Comparison of the empirical test classification accuracy with the theoretical prediction. C: Even after the task has been learned, the theory accurately captures non-trivial ongoing learning dynamics.", "description": "This figure compares the theoretical predictions of the model with empirical results from training a nonlinear perceptron on the MNIST dataset to classify the digits 0 and 1. Panel A shows a t-SNE embedding of the weight vectors during training. Panel B compares the empirical test accuracy with the theoretical prediction based on the model's equations.  Panel C demonstrates that even after the task is learned, the model accurately captures the ongoing learning dynamics, suggesting its continued validity beyond initial learning.", "section": "Application to real tasks"}]