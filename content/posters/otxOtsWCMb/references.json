{"references": [{"fullname_first_author": "Matthew Tancik", "paper_title": "Mip-NeRF: A multiscale representation for anti-aliasing neural radiance fields", "publication_date": "2021-00-00", "reason": "This paper is foundational to the novel view synthesis methods used in the current paper, providing a crucial multiscale representation technique."}, {"fullname_first_author": "Ben Mildenhall", "paper_title": "NeRF: Representing scenes as neural radiance fields for view synthesis", "publication_date": "2020-00-00", "reason": "This paper introduced the core concept of Neural Radiance Fields (NeRFs), which is a central element of many modern novel view synthesis methods, including the one presented in this paper."}, {"fullname_first_author": "Alexey Dosovitskiy", "paper_title": "Conditional object-centric learning from video", "publication_date": "2021-00-00", "reason": "This paper addresses object-centric learning from videos, which directly relates to the goal of the current paper to achieve 3D understanding from real-world video data."}, {"fullname_first_author": "Alexey Dosovitskiy", "paper_title": "Latent neural scene representations from unposed imagery", "publication_date": "2023-00-00", "reason": "This paper focuses on scene representation from unposed imagery, an aspect closely tied to the approach of learning 3D understanding from unconstrained real-world videos."}, {"fullname_first_author": "R\u0131za Alp G\u00fcler", "paper_title": "Zero-1-to-3: Zero-shot one image to 3D object", "publication_date": "2023-00-00", "reason": "This paper directly addresses the task of generating a 3D model from a single image, which is a key component of the approach taken in the current research."}]}