[{"figure_path": "otxOtsWCMb/figures/figures_1_1.jpg", "caption": "Figure 1: By learning from the largest real-world, multi-view dataset to date, our model ODIN, can synthesize novel views of rich scenes from a single input image with free camera movement throughout the scene. We can then reconstruct the 3D scene geometry from these geometrically consistent generations.", "description": "This figure demonstrates the capabilities of the ODIN model.  Given a single input image of a scene (Notre Dame Cathedral), the model generates multiple novel views from different camera positions and orientations. These positions are indicated in the figure. The generated views show consistent geometry and details, demonstrating the model's ability to understand and reconstruct the 3D scene from a single image.", "section": "1 Introduction"}, {"figure_path": "otxOtsWCMb/figures/figures_3_1.jpg", "caption": "Figure 2: Left: An illustrative trajectory of standard video with the view point fixed at the time of capture. The fixed view point makes finding corresponding frames challenging. Right: The trajectory of a 360\u00b0 video through the scene. The controllable camera enables alignment of views at different frames of the video.", "description": "This figure compares the trajectories of standard video recording and 360\u00b0 video recording. The left panel shows a standard video, where the camera's viewpoint is fixed, resulting in a limited range of views and making it difficult to find corresponding frames with significantly different perspectives.  The right panel depicts a 360\u00b0 video, where the camera's viewpoint is controllable, enabling the capture of a much wider range of views and greatly facilitating the identification of corresponding frames from diverse perspectives. This difference in viewpoint control is highlighted as a key advantage of using 360\u00b0 video for creating multi-view datasets for novel view synthesis.", "section": "3 Multi-View Data from 360\u00b0 Video"}, {"figure_path": "otxOtsWCMb/figures/figures_5_1.jpg", "caption": "Figure 3: Qualitative comparison of novel view synthesis on real-world scenes. The left and right images are conditioned on camera views from the left and right respectively. In the middle scene of the kitchen, ODIN accurately models the geometry of the table counter and chairs as well as unseen parts of the scene such as the living room.", "description": "This figure shows a qualitative comparison of novel view synthesis results on real-world scenes using three different methods: ODIN (the authors' method), Zero 1-to-3, and ZeroNVS.  For each scene, input views from the left and right are given, followed by the synthesized views generated by each method.  The figure highlights ODIN's superior ability to accurately model the geometry and details of complex real-world scenes, even generating unseen parts.", "section": "4.2 Dataset Statistics"}, {"figure_path": "otxOtsWCMb/figures/figures_6_1.jpg", "caption": "Figure 4: Examples of generated 3D scenes using ODIN. The blue dot indicates the location of the input image and the red lines indicate the trajectory of the camera which generated the images. ODIN is capable of long-range generation of geometrically consistent images. In the bottom scene, we see the model accurately infers the geometry of the unseen cathedral ceiling and the long hallway.", "description": "This figure shows three examples of 3D scenes generated by the ODIN model. Each example starts with a single input image (shown on the left) and then generates a sequence of images from different viewpoints along a trajectory indicated by red lines. The model is able to generate long-range consistent images showing unseen parts of the scenes. In one example, the model is able to accurately infer the geometry of the cathedral ceiling and hallway, even though they are not visible in the original input image.", "section": "Experiments"}, {"figure_path": "otxOtsWCMb/figures/figures_13_1.jpg", "caption": "Figure 5: Video duration distribution in 360-1M. Figure 6: Video categories' distribution in 360-1M. Figure 7: Video language distribution in 360-1M.", "description": "This figure shows three bar charts visualizing the statistics of the 360-1M dataset.  Figure 5 displays the distribution of video durations, showing how many videos fall within specific time ranges. Figure 6 presents the distribution of videos across different categories, indicating the prevalence of each category in the dataset.  Figure 7 illustrates the distribution of videos based on their languages.", "section": "Dataset Statistics"}, {"figure_path": "otxOtsWCMb/figures/figures_13_2.jpg", "caption": "Figure 7: Video language distribution in 360-1M.", "description": "This bar chart displays the distribution of languages present in the 360-1M dataset.  The x-axis represents the count of videos, while the y-axis lists the different languages.  English ('en') is by far the most prevalent language, followed by Spanish ('es'), with all other languages having significantly fewer videos.", "section": "Dataset Statistics"}, {"figure_path": "otxOtsWCMb/figures/figures_14_1.jpg", "caption": "Figure 4: Examples of generated 3D scenes using ODIN. The blue dot indicates the location of the input image and the red lines indicate the trajectory of the camera which generated the images. ODIN is capable of long-range generation of geometrically consistent images. In the bottom scene, we see the model accurately infers the geometry of the unseen cathedral ceiling and the long hallway.", "description": "This figure showcases the capabilities of the ODIN model in generating 3D scenes from a single input image.  It highlights ODIN's ability to generate geometrically consistent images along a camera trajectory, even inferring unseen parts of the scene (like the cathedral ceiling). The blue dot shows the input image location; red lines trace the camera's path.", "section": "Experiments"}, {"figure_path": "otxOtsWCMb/figures/figures_14_2.jpg", "caption": "Figure 4: Examples of generated 3D scenes using ODIN. The blue dot indicates the location of the input image and the red lines indicate the trajectory of the camera which generated the images. ODIN is capable of long-range generation of geometrically consistent images. In the bottom scene, we see the model accurately infers the geometry of the unseen cathedral ceiling and the long hallway.", "description": "This figure shows examples of 3D scenes generated by the ODIN model.  The model takes a single input image (indicated by a blue dot) and generates multiple views of the scene along a trajectory (red lines).  The generated scenes demonstrate ODIN's ability to create geometrically consistent images, even of unseen parts of the scene (e.g., the cathedral ceiling in the bottom example).", "section": "Experiments"}, {"figure_path": "otxOtsWCMb/figures/figures_15_1.jpg", "caption": "Figure 10: General example of correspondences from MVImageNet. Previously the largest multi-view dataset.", "description": "This figure displays examples of correspondences from the MVImageNet dataset, which was previously considered the largest multi-view dataset. It showcases pairs of images depicting various objects (toy mouse, ladder, toy tiger, ceiling lamp, toy rabbit, and light switch) from different viewpoints, highlighting the challenge of finding such correspondences in real-world data.  The images show various aspects of the objects to illustrate the diversity of views captured.", "section": "Correspondence Examples from MVImageNet"}]