{"references": [{"fullname_first_author": "Jean-Baptiste Alayrac", "paper_title": "Flamingo: a visual language model for few-shot learning", "publication_date": "2022-12-01", "reason": "This paper introduces Flamingo, a visual language model that is foundational to the MQT's query transformer architecture, enabling flexible visual token encoding and influencing the design of MQT-LLaVA."}, {"fullname_first_author": "Jinze Bai", "paper_title": "Qwen-vl: A versatile vision-language model for understanding, localization, text reading, and beyond", "publication_date": "2023-12-01", "reason": "Qwen-VL is a strong baseline model in the vision-language domain and is directly compared against in the paper's experiments, providing a critical benchmark for evaluating MQT-LLaVA's performance."}, {"fullname_first_author": "Wei-Lin Chiang", "paper_title": "Vicuna: An opensource chatbot impressing gpt-4 with 90% chatgpt quality", "publication_date": "2023-12-01", "reason": "Vicuna is the large language model (LLM) used as the core language component of MQT-LLaVA, significantly contributing to its capabilities and performance and therefore is a highly relevant reference."}, {"fullname_first_author": "Haotian Liu", "paper_title": "Visual instruction tuning", "publication_date": "2023-12-01", "reason": "This paper introduces the LLaVA model, which serves as the foundation for MQT-LLaVA, providing the base architecture and training methods upon which the Matryoshka Query Transformer is built."}, {"fullname_first_author": "Aditya Kusupati", "paper_title": "Matryoshka representation learning", "publication_date": "2022-12-01", "reason": "This paper introduces the Matryoshka Representation Learning (MRL) concept, which directly inspires the design and training methodology of the Matryoshka Query Transformer (MQT), a core component of MQT-LLaVA."}]}