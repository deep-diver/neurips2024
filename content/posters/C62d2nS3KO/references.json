{"references": [{"fullname_first_author": "Diederik P. Kingma", "paper_title": "Adam: A method for stochastic optimization", "publication_date": "2014-12-00", "reason": "This paper introduces the Adam optimizer, a crucial component in training the diffusion models used in the research."}, {"fullname_first_author": "Tim Salimans", "paper_title": "Progressive distillation for fast sampling of diffusion models", "publication_date": "2022-00-00", "reason": "This paper is highly relevant as it presents a method for accelerating diffusion models by progressive distillation, a technique directly compared and improved upon in the main research."}, {"fullname_first_author": "Jonathan Ho", "paper_title": "Denoising diffusion probabilistic models", "publication_date": "2020-00-00", "reason": "This paper is foundational, introducing denoising diffusion probabilistic models (DDPMs), the core technology that the current research builds upon and aims to improve."}, {"fullname_first_author": "Yang Song", "paper_title": "Score-based generative modeling through stochastic differential equations", "publication_date": "2021-00-00", "reason": "This work provides a theoretical framework and practical techniques for score-based generative models, which are closely related to and compared against the proposed method."}, {"fullname_first_author": "Prafulla Dhariwal", "paper_title": "Improved techniques for training consistency models", "publication_date": "2023-10-14", "reason": "This paper offers improvements to the training of consistency models, a technique relevant to the diffusion models studied in this research."}]}