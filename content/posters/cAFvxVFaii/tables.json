[{"figure_path": "cAFvxVFaii/tables/tables_7_1.jpg", "caption": "Table 1: CRPSsum accuracy comparison. \"w/o\" denotes methods without time-dependent errors, while \"w/\" indicates our method. Bold values show models with time-dependent errors performing better. Mean and standard deviation are obtained from 10 runs of each model.", "description": "This table presents a comparison of the Continuous Ranked Probability Score (CRPS) sum across various time series datasets.  Two model types are compared: those without and those with the proposed method for handling time-dependent errors.  The \"w/o\" column represents results from models without considering temporal error dependencies, while the \"w/\" column shows results with the proposed method incorporated.  Bold values highlight cases where the model incorporating time-dependent error handling outperformed its counterpart.  Results are averaged over ten runs for each model.", "section": "5.1 Evaluation of Predictive Performance"}, {"figure_path": "cAFvxVFaii/tables/tables_14_1.jpg", "caption": "Table 2: Dataset summary.", "description": "This table summarizes the characteristics of the nine datasets used in the experiments.  For each dataset, it lists the granularity of the time series data (hourly, daily, etc.), the total number of time series, the total number of time steps in the dataset, the prediction range (Q) used for forecasting, and the number of rolling evaluations performed for each time series.", "section": "5.1 Evaluation of Predictive Performance"}, {"figure_path": "cAFvxVFaii/tables/tables_16_1.jpg", "caption": "Table 3: Hyperparameters values that are fixed or searched over a range during hyperparameter tuning.", "description": "This table lists the hyperparameters used in the experiments.  It shows which hyperparameters were fixed to a certain value and which hyperparameters were tuned by searching over a range of values.  The hyperparameters being tuned include the learning rate, the number of LSTM cells or the dimension of the transformer model, the number of LSTM layers or transformer decoder layers, the number of attention heads in the transformer, the rank of the covariance matrix, the sampling dimension, the dropout rate, and the batch size.", "section": "A.5 Hyperparameter Search"}, {"figure_path": "cAFvxVFaii/tables/tables_17_1.jpg", "caption": "Table 3: Hyperparameters values that are fixed or searched over a range during hyperparameter tuning.", "description": "This table lists the hyperparameters used in the experiments.  It shows which hyperparameters were fixed and which hyperparameters had their values searched over a range during the hyperparameter tuning phase. The table is valuable because it helps readers understand how the authors arrived at the model configurations they used in their experiments, including choices about learning rates, the number of layers in recurrent networks, the size of the model, and various regularization parameters.", "section": "A.5 Hyperparameter Search"}, {"figure_path": "cAFvxVFaii/tables/tables_17_2.jpg", "caption": "Table 5: Number of parameters of the GPVar model for each dataset.", "description": "This table shows the number of parameters used in the GPVar model for each dataset, broken down into the number of parameters used for covariate embedding, RNN, distribution projection, and covariance projection (the authors' method).  It helps illustrate the model's complexity and parameter efficiency.", "section": "A.6 Base Model Description and Input Features"}, {"figure_path": "cAFvxVFaii/tables/tables_17_3.jpg", "caption": "Table 6: Number of parameters of the Transformer model for each dataset.", "description": "This table shows the number of parameters for different components of the Transformer model used in the paper for each dataset.  The components include those for the target projection, covariate projection, covariate embedding, the Transformer itself, the distribution projection, and finally, the covariance projection using the authors' method. The table is useful to understand the model's complexity and how the proposed method scales across different datasets.", "section": "A.6 Base Model Description and Input Features"}, {"figure_path": "cAFvxVFaii/tables/tables_20_1.jpg", "caption": "Table 1: CRPSsum accuracy comparison. \"w/o\" denotes methods without time-dependent errors, while \"w/\" indicates our method. Bold values show models with time-dependent errors performing better. Mean and standard deviation are obtained from 10 runs of each model.", "description": "This table presents a comparison of the Continuous Ranked Probability Score sum (CRPSsum) for various time series forecasting models.  The CRPSsum metric measures the accuracy of probabilistic forecasts. The table compares models trained without considering time-dependent errors (\"w/o\") against those that do (\"w/\").  Bold values highlight instances where incorporating time-dependent errors resulted in better performance.  The results are averaged across 10 runs for each model to account for randomness.", "section": "5.1 Evaluation of Predictive Performance"}, {"figure_path": "cAFvxVFaii/tables/tables_20_2.jpg", "caption": "Table 1: CRPSsum accuracy comparison. \"w/o\" denotes methods without time-dependent errors, while \"w/\" indicates our method. Bold values show models with time-dependent errors performing better. Mean and standard deviation are obtained from 10 runs of each model.", "description": "This table presents a comparison of the Continuous Ranked Probability Score (CRPS) for various time series forecasting models.  It compares models that do not consider temporal error correlations (\"w/o\") to those that do (\"w/\"). The results are averaged across 10 runs for each model.  Bold values highlight cases where considering time-dependent errors leads to improved accuracy (lower CRPS).", "section": "5.1 Evaluation of Predictive Performance"}, {"figure_path": "cAFvxVFaii/tables/tables_20_3.jpg", "caption": "Table 1: CRPSsum accuracy comparison. \"w/o\" denotes methods without time-dependent errors, while \"w/\" indicates our method. Bold values show models with time-dependent errors performing better. Mean and standard deviation are obtained from 10 runs of each model.", "description": "This table presents a comparison of the Continuous Ranked Probability Score sum (CRPSsum) for various time series forecasting models.  The models are categorized into two groups: those without time-dependent errors (\"w/o\") and those with time-dependent errors (\"w/\"). The table shows the CRPSsum values (with standard deviations) for each model across eight different datasets (exchange_rate, solar, electricity, traffic, wiki, m4_hourly, m1_quarterly, pems03, uber_hourly). Bold values indicate cases where models using the proposed method for incorporating time-dependent errors show improved accuracy.  The average relative improvement in CRPSsum is also provided for both GPVar and Transformer models.", "section": "5.1 Evaluation of Predictive Performance"}, {"figure_path": "cAFvxVFaii/tables/tables_21_1.jpg", "caption": "Table 1: CRPSsum accuracy comparison. \"w/o\" denotes methods without time-dependent errors, while \"w/\" indicates our method. Bold values show models with time-dependent errors performing better. Mean and standard deviation are obtained from 10 runs of each model.", "description": "This table presents a comparison of the Continuous Ranked Probability Score sum (CRPSsum) achieved by various models on multiple datasets.  It compares models trained without considering time-dependent errors (\"w/o\") to those trained with the proposed method for incorporating correlated errors (\"w/\"). The bold values highlight instances where including time-dependent errors leads to improved accuracy.  The average relative improvement is reported, showing the effectiveness of the proposed method.", "section": "5.1 Evaluation of Predictive Performance"}, {"figure_path": "cAFvxVFaii/tables/tables_21_2.jpg", "caption": "Table 1: CRPSsum accuracy comparison. \"w/o\" denotes methods without time-dependent errors, while \"w/\" indicates our method. Bold values show models with time-dependent errors performing better. Mean and standard deviation are obtained from 10 runs of each model.", "description": "This table presents a comparison of the continuous ranked probability score (CRPS) sum for various multivariate time series forecasting models. The \"w/o\" column represents models without considering the time-dependence of errors, while the \"w/\" column represents models incorporating the proposed method for handling correlated errors.  Bold values indicate instances where the proposed method (w/) outperforms the baseline (w/o). The results are averaged over ten runs for each model to provide statistical significance.", "section": "5.1 Evaluation of Predictive Performance"}, {"figure_path": "cAFvxVFaii/tables/tables_21_3.jpg", "caption": "Table 1: CRPSsum accuracy comparison. \"w/o\" denotes methods without time-dependent errors, while \"w/\" indicates our method. Bold values show models with time-dependent errors performing better. Mean and standard deviation are obtained from 10 runs of each model.", "description": "This table compares the Continuous Ranked Probability Score (CRPS) sum, a metric for evaluating probabilistic forecasting accuracy, across multiple models and datasets.  It contrasts models trained without considering time-dependent errors (\"w/o\") against those that do incorporate such errors using the proposed method (\"w/\"). The lower the CRPSsum value, the better the model's performance.  Bold values highlight cases where incorporating time-dependent errors significantly improved the model's predictive ability. The mean and standard deviation were calculated over ten runs for each model to provide a reliable estimate of performance.", "section": "5.1 Evaluation of Predictive Performance"}, {"figure_path": "cAFvxVFaii/tables/tables_29_1.jpg", "caption": "Table 1: CRPSsum accuracy comparison. \"w/o\" denotes methods without time-dependent errors, while \"w/\" indicates our method. Bold values show models with time-dependent errors performing better. Mean and standard deviation are obtained from 10 runs of each model.", "description": "This table presents a comparison of the Continuous Ranked Probability Score (CRPS) sum for various time series forecasting models.  It contrasts models that do not account for time-dependent errors (\"w/o\") against models that incorporate the proposed method for handling such errors (\"w/\").  The bold values highlight instances where incorporating time-dependent errors leads to improved accuracy. The results represent the mean and standard deviation from 10 independent runs for each model and dataset.", "section": "5.1 Evaluation of Predictive Performance"}, {"figure_path": "cAFvxVFaii/tables/tables_30_1.jpg", "caption": "Table 1: CRPSsum accuracy comparison. \"w/o\" denotes methods without time-dependent errors, while \"w/\" indicates our method. Bold values show models with time-dependent errors performing better. Mean and standard deviation are obtained from 10 runs of each model.", "description": "This table presents a comparison of the Continuous Ranked Probability Score (CRPS) sum across multiple time series forecasting models.  It compares models trained without considering time-dependent errors (\"w/o\") against models incorporating the proposed method for handling correlated errors (\"w/\").  The bold values highlight instances where the method incorporating time-dependent errors shows improved accuracy. Results are averaged over 10 independent runs for each model.", "section": "5.1 Evaluation of Predictive Performance"}, {"figure_path": "cAFvxVFaii/tables/tables_31_1.jpg", "caption": "Table 15: CRPSsum accuracy comparison. \"w/o\" denotes methods without time-dependent errors, while \"w/\" indicates our method. Bold values show models with time-dependent errors performing better. Mean and standard deviation are obtained from 10 runs of each model. \"N/A\" indicates that the model could not be properly fitted.", "description": "This table compares the Continuous Ranked Probability Score (CRPS) for different probabilistic forecasting models with and without the proposed method for handling correlated errors. The models are evaluated on multiple real-world datasets, and CRPS is calculated for both Gaussian-distributed and t-distributed errors. The results show the improvements gained using the proposed method to model the correlation structure of errors across multiple time steps.", "section": "5.1 Evaluation of Predictive Performance"}]