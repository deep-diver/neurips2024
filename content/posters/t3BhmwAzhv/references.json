{"references": [{"fullname_first_author": "D. Z. Chen", "paper_title": "Scanrefer: 3d object localization in rgb-d scans using natural language", "publication_date": "2020-00-00", "reason": "This paper introduces the ScanRefer benchmark, a foundational dataset for 3D visual grounding that is used for evaluation in this paper."}, {"fullname_first_author": "A. Dai", "paper_title": "Scannet: Richly-annotated 3d reconstructions of indoor scenes", "publication_date": "2017-00-00", "reason": "This paper introduces ScanNet, a large-scale 3D indoor scene dataset that is the basis for several benchmarks used in this paper."}, {"fullname_first_author": "Z. Chen", "paper_title": "Scan2cap: Context-aware dense captioning in rgb-d scans", "publication_date": "2021-00-00", "reason": "This paper introduces the Scan2Cap benchmark, a key dataset for 3D dense captioning which is used for evaluation in this paper."}, {"fullname_first_author": "D. Azuma", "paper_title": "Scanqa: 3d question answering for spatial scene understanding", "publication_date": "2022-00-00", "reason": "This paper introduces the ScanQA benchmark, a significant dataset for 3D visual question answering used for evaluation in this paper."}, {"fullname_first_author": "X. Ma", "paper_title": "SQA3D: Situated question answering in 3d scenes", "publication_date": "2022-00-00", "reason": "This paper introduces the SQA3D benchmark, another important dataset for 3D visual question answering used for evaluation in this paper."}]}