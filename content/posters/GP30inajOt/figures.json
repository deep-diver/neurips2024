[{"figure_path": "GP30inajOt/figures/figures_5_1.jpg", "caption": "Figure 1: The figures illustrate that both sphere constrained and Stiefel constrained manifold-LoRA achieve a faster convergence rate and attain a lower training loss within same optimization steps compared to LoRA method on three distinct datasets CoLA, QQP, STSB.", "description": "This figure compares the training loss of three different methods: LoRA, Sphere-constrained manifold-LoRA, and Stiefel-constrained manifold-LoRA, across three datasets: CoLA, QQP, and STSB.  The results show that the manifold-LoRA methods converge faster and achieve lower training loss than the standard LoRA method.", "section": "4.1 Natural language understanding"}, {"figure_path": "GP30inajOt/figures/figures_6_1.jpg", "caption": "Figure 1: The figures illustrate that both sphere constrained and Stiefel constrained manifold-LoRA achieve a faster convergence rate and attain a lower training loss within same optimization steps compared to LoRA method on three distinct datasets CoLA, QQP, STSB.", "description": "This figure compares the training loss curves for three different methods: LoRA, Sphere-constrained Manifold-LoRA, and Stiefel-constrained Manifold-LoRA.  The results show that both Manifold-LoRA variants converge faster and achieve a lower training loss than the standard LoRA method across three datasets (CoLA, QQP, STSB). This demonstrates the effectiveness of the proposed Manifold-LoRA approach in accelerating the fine-tuning process of large language models.", "section": "4.1 Natural language understanding"}, {"figure_path": "GP30inajOt/figures/figures_6_2.jpg", "caption": "Figure 1: The figures illustrate that both sphere constrained and Stiefel constrained manifold-LoRA achieve a faster convergence rate and attain a lower training loss within same optimization steps compared to LoRA method on three distinct datasets CoLA, QQP, STSB.", "description": "This figure compares the training loss curves for different optimization methods: LoRA, Sphere-constrained Manifold-LoRA, and Stiefel-constrained Manifold-LoRA. The results show that both Manifold-LoRA variants (Sphere and Stiefel) converge faster and achieve a lower training loss compared to the standard LoRA method across three datasets: CoLA, QQP, and STSB.", "section": "4.1 Natural language understanding"}, {"figure_path": "GP30inajOt/figures/figures_6_3.jpg", "caption": "Figure 1: The figures illustrate that both sphere constrained and Stiefel constrained manifold-LoRA achieve a faster convergence rate and attain a lower training loss within same optimization steps compared to LoRA method on three distinct datasets CoLA, QQP, STSB.", "description": "This figure compares the training loss curves of three different methods: LoRA, Sphere, and Stiefel, across 25 epochs.  The shaded areas represent the standard deviations.  The results indicate that the Sphere and Stiefel methods (which incorporate manifold constraints) converge faster and achieve a lower loss than the standard LoRA method on the CoLA, QQP, and STSB datasets.", "section": "4.1 Natural language understanding"}, {"figure_path": "GP30inajOt/figures/figures_6_4.jpg", "caption": "Figure 1: The figures illustrate that both sphere constrained and Stiefel constrained manifold-LoRA achieve a faster convergence rate and attain a lower training loss within same optimization steps compared to LoRA method on three distinct datasets CoLA, QQP, STSB.", "description": "This figure compares the training performance of three different methods: LoRA, Sphere constrained manifold-LoRA, and Stiefel constrained manifold-LoRA, across three datasets (CoLA, QQP, STSB).  The y-axis represents the Matthews Correlation coefficient, a measure of the classification performance, and the x-axis represents the training epoch.  The shaded areas indicate the variability of the results. The figure demonstrates that both manifold-based methods converge faster and achieve a lower training loss than the standard LoRA method.", "section": "4.1 Natural language understanding"}, {"figure_path": "GP30inajOt/figures/figures_6_5.jpg", "caption": "Figure 2: The figures compare the training loss, evaluation exact match, and evaluation F1 metrics against the number of epochs for the SQUADv2.0 dataset.", "description": "This figure shows a comparison of three different methods (LoRA, Sphere, and Stiefel) for fine-tuning a model on the SQUADv2.0 dataset.  The x-axis represents the number of training epochs, while the y-axis shows three different metrics: training loss, exact match accuracy, and F1 score. The figure visually demonstrates the performance of each method over time, highlighting differences in convergence speed and overall performance.", "section": "4 Experiments"}, {"figure_path": "GP30inajOt/figures/figures_6_6.jpg", "caption": "Figure 2: The figures compare the training loss, evaluation exact match, and evaluation F1 metrics against the number of epochs for the SQUADv2.0 dataset.", "description": "This figure compares the performance of different methods (LoRA, Sphere, and Stiefel) on the SQUADv2.0 dataset across different epochs.  It shows three graphs illustrating the training loss, the exact match score, and the F1 score for each method. The shaded areas represent the standard deviation of the results, indicating confidence intervals. This figure demonstrates the convergence rate and final performance of the proposed Manifold-LoRA algorithm against the baselines. ", "section": "4.2 Question Answering"}, {"figure_path": "GP30inajOt/figures/figures_7_1.jpg", "caption": "Figure 2: The figures compare the training loss, evaluation exact match, and evaluation F1 metrics against the number of epochs for the SQUADv2.0 dataset.", "description": "This figure compares the performance of three different methods (LoRA, Sphere, and Stiefel) for fine-tuning a question answering model on the SQUADv2.0 dataset.  The three plots show the training loss, exact match score, and F1 score over the epochs.  It demonstrates the faster convergence and superior performance of the Sphere and Stiefel methods compared to the baseline LoRA method.", "section": "4.2 Question Answering"}, {"figure_path": "GP30inajOt/figures/figures_7_2.jpg", "caption": "Figure 3: The heat map of BTB with the Stiefel manifold (the first and second rows) and the oblique manifold (the third and fourth rows) at the end of training on SQUADv2.0 dataset.", "description": "This figure visualizes the heatmaps of the matrix product  B<sup>T</sup>B, where B is a matrix learned during the LoRA fine-tuning process. The heatmaps are shown for both the Stiefel and oblique manifolds. Each heatmap represents the values of B<sup>T</sup>B at different points in the matrix.  The color intensity indicates the magnitude of the values, showing how close the matrix B is to satisfying the orthogonality constraints of the Stiefel manifold (first two rows) or unit norm constraints of the oblique manifold (last two rows) at the end of training. This visualization helps demonstrate the effectiveness of the Manifold-LoRA algorithm in guiding the learned matrices towards the desired manifold constraints.", "section": "Experiments"}, {"figure_path": "GP30inajOt/figures/figures_8_1.jpg", "caption": "Figure 3: The heat map of  B<sup>T</sup>B with the Stiefel manifold (the first and second rows) and the oblique manifold (the third and fourth rows) at the end of training on SQUADv2.0 dataset.", "description": "This figure visualizes the heatmaps of the matrix product B<sup>T</sup>B at the end of the training process for the SQUADv2.0 dataset.  Two different manifold constraints are used, the Stiefel manifold (rows 1 and 2), and the oblique manifold (rows 3 and 4). Each heatmap shows the pairwise inner products of the column vectors of matrix B.  The color intensity represents the value of the inner product, with red representing positive values (close to 1 indicating orthogonality for Stiefel and unit norm for oblique) and blue representing negative values (close to -1).  The figure aims to illustrate that matrix B converges to the Stiefel or oblique manifold depending on which constraint is used, as indicated by the patterns in the heatmaps.", "section": "4 Experiments"}]