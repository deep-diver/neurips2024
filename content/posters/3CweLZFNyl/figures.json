[{"figure_path": "3CweLZFNyl/figures/figures_1_1.jpg", "caption": "Figure 1: Learning expressive Gaussian human avatars from RGB video. Given a monocular video as input, our proposed approach, EVA, learns an expressive 3D Gaussian avatar. The results outperform the SOTA method [22] on novel pose synthesis, especially for the hand and facial details.", "description": "This figure compares the results of a state-of-the-art (SOTA) method and the proposed EVA method for generating expressive 3D Gaussian human avatars from a monocular RGB video.  The top row shows frames from a sample video. The middle rows show close-ups of hand and facial details generated by the SOTA method, highlighting limitations in detail and expressiveness. The bottom row displays the corresponding results from the EVA method, illustrating improved expressiveness and detailed reconstruction, particularly in the hands and face.", "section": "1 Introduction"}, {"figure_path": "3CweLZFNyl/figures/figures_4_1.jpg", "caption": "Figure 2: Overview of our proposed EVA method. Given a monocular RGB video, first we estimate a SMPL-X mesh that aligns well to the video frames using a reconstruction module. Then, EVA utilizes 3D Gaussian Splatting for avatar modeling, while inheriting the human shape prior from the SMPL-X model. To improve the optimization and the quality of the avatar, we propose context-aware adaptive density control and a confidence-aware loss.", "description": "This figure illustrates the overall pipeline of the EVA method. It starts with a monocular RGB video as input. The first stage is SMPL-X alignment, where a reconstruction module aligns a SMPL-X mesh to the video frames.  The second stage is Gaussian Avatar Modeling, which uses 3D Gaussian Splatting and incorporates the SMPL-X model as prior for better human shape representation.  To enhance quality, context-aware adaptive density control and confidence-aware loss are applied during optimization. Finally, an animated avatar is generated.", "section": "3 Technical Approach"}, {"figure_path": "3CweLZFNyl/figures/figures_7_1.jpg", "caption": "Figure 3: Qualitative comparison with baselines. We compare with 3DGS [19] + SMPL-X, GART [22] + SMPL-X, and GauHuman [12] + SMPL-X. First three rows are from UPB and last row is from the XHumans dataset. EVA exhibits the best visual quality. See the zoomed-in results in the box for comparison of the fine-grained details.", "description": "This figure presents a qualitative comparison of the proposed EVA method against three state-of-the-art baselines (3DGS+SMPL-X, GART+SMPL-X, and GauHuman+SMPL-X) on the task of generating expressive human avatars from monocular RGB video.  The comparison highlights the superior quality of EVA, particularly in capturing fine-grained details such as hand and facial expressions. The results are shown on both the XHumans (controlled setting) and UPB (in-the-wild) datasets, demonstrating the robustness of the EVA method.", "section": "4.2 Comparison with baselines"}, {"figure_path": "3CweLZFNyl/figures/figures_8_1.jpg", "caption": "Figure 3: Qualitative comparison with baselines. We compare with 3DGS [19] + SMPL-X, GART [22] + SMPL-X, and GauHuman [12] + SMPL-X. First three rows are from UPB and last row is from the XHumans dataset. EVA exhibits the best visual quality. See the zoomed-in results in the box for comparison of the fine-grained details.", "description": "This figure shows a qualitative comparison of the proposed EVA method against three baselines (3DGS + SMPL-X, GART + SMPL-X, and GauHuman + SMPL-X) for generating expressive human avatars from video.  The comparison highlights the superior visual quality of EVA, particularly in capturing fine-grained details such as hand and facial expressions.  The figure presents results from both the UPB (in-the-wild) and XHumans (controlled) datasets.", "section": "4.3 Ablation Studies"}, {"figure_path": "3CweLZFNyl/figures/figures_9_1.jpg", "caption": "Figure 3: Qualitative comparison with baselines. We compare with 3DGS [19] + SMPL-X, GART [22] + SMPL-X, and GauHuman [12] + SMPL-X. First three rows are from UPB and last row is from the XHumans dataset. EVA exhibits the best visual quality. See the zoomed-in results in the box for comparison of the fine-grained details.", "description": "This figure shows a qualitative comparison of the proposed EVA method against three state-of-the-art baselines (3DGS, GART, and GauHuman) for generating expressive human avatars from monocular RGB video.  The comparison includes results from both the UPB (in-the-wild) and XHumans (controlled) datasets, highlighting EVA's superior performance in capturing fine details, particularly in hand and facial expressions. Zoomed-in sections provide a close-up view of the fine-grained details for better comparison.", "section": "4.2 Comparison with baselines"}]