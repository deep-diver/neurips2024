[{"figure_path": "ZdWTN2HOie/figures/figures_1_1.jpg", "caption": "Figure 1: Diagram of stochastic amortization. Left: using a dataset with noisy labels \u0101(b) (e.g., images and data valuation estimates), we can train an amortized model that accurately estimates the true outputs a(b) (e.g., data valuation scores). Right: the default approach of running an expensive approximation algorithm for each example (e.g., a Monte Carlo estimator with many samples [33]).", "description": "This figure compares two approaches for handling computationally expensive tasks in explainable machine learning (XML). The left side illustrates stochastic amortization, where noisy estimates of the true outputs are used to train an amortized model. This model then predicts the true outputs for new inputs. The right side shows the traditional per-instance computation method, where an expensive algorithm is run for each example, such as a Monte Carlo estimator.", "section": "Stochastic amortization"}, {"figure_path": "ZdWTN2HOie/figures/figures_6_1.jpg", "caption": "Figure 2: Stochastic amortization for Shapley value feature attributions. We compare the predicted attributions to the noisy labels and ground truth, which are generated using KernelSHAP with 512 and 1M samples, respectively.", "description": "This figure shows a comparison of Shapley value feature attributions obtained using three different methods: stochastic amortization, noisy labels (using KernelSHAP with 512 samples), and ground truth (using KernelSHAP with 1M samples).  The figure visually demonstrates that the attributions predicted by the amortized model are much closer to the ground truth than the noisy labels, highlighting the effectiveness of the stochastic amortization approach in improving the accuracy of Shapley value estimations.", "section": "5.1 Feature attribution"}, {"figure_path": "ZdWTN2HOie/figures/figures_7_1.jpg", "caption": "Figure 3: Amortized Shapley value feature attributions using KernelSHAP as a noisy oracle. Left: squared error relative to the ground truth attributions when using noisy labels with different numbers of samples (different noise levels). Center: estimation error as a function of FLOPs, where KernelSHAP incurs FLOPs via classifier predictions used to estimate the attributions, and amortization incurs additional FLOPs from training (training appears as a vertical line because the FLOPs are relatively low, and endpoints represent results from the final epoch). Right: estimation error with different training dataset sizes given equivalent compute per data point (matched by using fewer KernelSHAP samples when generating noisy labels for amortization and allowing up to 50 epochs of training).", "description": "This figure compares the performance of amortized Shapley value feature attribution using KernelSHAP as a noisy oracle against per-instance KernelSHAP. The left panel shows the squared error decreases as the number of samples used for generating noisy labels increases. The center panel shows a comparison in estimation error as a function of FLOPs, demonstrating the efficiency of amortization. The right panel shows a compute-matched comparison using different dataset sizes, indicating the scalability and effectiveness of the method.", "section": "5.1 Feature attribution"}, {"figure_path": "ZdWTN2HOie/figures/figures_8_1.jpg", "caption": "Figure 4: Amortized data valuation accuracy for tabular datasets. Left: mean squared error relative to the ground truth for the MiniBooNE dataset, normalized so that the mean valuation score has error equal to 1 (for 1K and 10K data points). The x-axis indicates how many Monte Carlo samples were used for each data point. Center: Pearson correlation with the ground truth for the MiniBooNE dataset (for 1K and 10K data points). Right: estimation accuracy for the MiniBooNE and adult census datasets as a function of dataset size (250 to 10K data points); we use 50 Monte Carlo samples per data point for all results and show the Pearson correlation with the ground truth.", "description": "This figure compares the performance of amortized data valuation against the traditional Monte Carlo method for tabular datasets (MiniBooNE and Adult Census).  The left and center panels focus on the MiniBooNE dataset, showing mean squared error and Pearson correlation with the ground truth for varying numbers of Monte Carlo samples used for the noisy oracle. The right panel demonstrates how the accuracy of both methods scales with increasing dataset size, maintaining a consistent use of 50 Monte Carlo samples per datapoint. The results show that amortization consistently outperforms the Monte Carlo approach in terms of accuracy and correlation with the ground truth, particularly as the dataset size increases.", "section": "5.2 Data valuation"}, {"figure_path": "ZdWTN2HOie/figures/figures_8_2.jpg", "caption": "Figure 3: Amortized Shapley value feature attributions using KernelSHAP as a noisy oracle. Left: squared error relative to the ground truth attributions when using noisy labels with different numbers of samples (different noise levels). Center: estimation error as a function of FLOPs, where KernelSHAP incurs FLOPs via classifier predictions used to estimate the attributions, and amortization incurs additional FLOPs from training (training appears as a vertical line because the FLOPs are relatively low, and endpoints represent results from the final epoch). Right: estimation error with different training dataset sizes given equivalent compute per data point (matched by using fewer KernelSHAP samples when generating noisy labels for amortization and allowing up to 50 epochs of training).", "description": "This figure compares the performance of the proposed stochastic amortization method with the traditional KernelSHAP approach for Shapley value feature attributions. It shows three aspects: the effect of noisy label quality on error, the computational cost trade-off (FLOPs) between the methods, and how the accuracy changes with training dataset size while maintaining equal per-datapoint computation budget.", "section": "5.1 Feature attribution"}, {"figure_path": "ZdWTN2HOie/figures/figures_9_1.jpg", "caption": "Figure 2: Stochastic amortization for Shapley value feature attributions. We compare the predicted attributions to the noisy labels and ground truth, which are generated using KernelSHAP with 512 and 1M samples, respectively.", "description": "This figure compares the results of using stochastic amortization for Shapley value feature attributions against two baselines: noisy labels (generated using KernelSHAP with 512 samples) and ground truth (generated using KernelSHAP with 1M samples). The results demonstrate that stochastic amortization is able to significantly improve the accuracy of noisy label estimates, approaching the accuracy of ground truth while using substantially fewer samples.", "section": "5.1 Feature attribution"}, {"figure_path": "ZdWTN2HOie/figures/figures_33_1.jpg", "caption": "Figure 3: Amortized Shapley value feature attributions using KernelSHAP as a noisy oracle. Left: squared error relative to the ground truth attributions when using noisy labels with different numbers of samples (different noise levels). Center: estimation error as a function of FLOPs, where KernelSHAP incurs FLOPs via classifier predictions used to estimate the attributions, and amortization incurs additional FLOPs from training (training appears as a vertical line because the FLOPs are relatively low, and endpoints represent results from the final epoch). Right: estimation error with different training dataset sizes given equivalent compute per data point (matched by using fewer KernelSHAP samples when generating noisy labels for amortization and allowing up to 50 epochs of training).", "description": "This figure compares the performance of amortized Shapley value feature attribution with different noise levels, computational costs, and training dataset sizes.  The left panel shows that the error decreases as the number of samples used to generate the noisy labels increases. The center panel shows that amortized model achieves lower error with significantly lower FLOPs compared to KernelSHAP. The right panel shows the error comparison for varying training set sizes when the computational budget is fixed.", "section": "5.1 Feature attribution"}, {"figure_path": "ZdWTN2HOie/figures/figures_33_2.jpg", "caption": "Figure 3: Amortized Shapley value feature attributions using KernelSHAP as a noisy oracle. Left: squared error relative to the ground truth attributions when using noisy labels with different numbers of samples (different noise levels). Center: estimation error as a function of FLOPs, where KernelSHAP incurs FLOPs via classifier predictions used to estimate the attributions, and amortization incurs additional FLOPs from training (training appears as a vertical line because the FLOPs are relatively low, and endpoints represent results from the final epoch). Right: estimation error with different training dataset sizes given equivalent compute per data point (matched by using fewer KernelSHAP samples when generating noisy labels for amortization and allowing up to 50 epochs of training).", "description": "This figure compares the performance of the proposed stochastic amortization method with the traditional KernelSHAP method for Shapley value feature attribution.  The left panel shows the error decreases as the number of samples used for KernelSHAP increases (noise level decreases). The center panel compares the estimation error as a function of FLOPs (floating-point operations), demonstrating the computational efficiency of amortization.  The right panel shows the error with varying training dataset sizes, illustrating that amortization is more efficient even with smaller datasets, when computation is matched between the two approaches.", "section": "5.1 Feature attribution"}, {"figure_path": "ZdWTN2HOie/figures/figures_33_3.jpg", "caption": "Figure 3: Amortized Shapley value feature attributions using KernelSHAP as a noisy oracle. Left: squared error relative to the ground truth attributions when using noisy labels with different numbers of samples (different noise levels). Center: estimation error as a function of FLOPs, where KernelSHAP incurs FLOPs via classifier predictions used to estimate the attributions, and amortization incurs additional FLOPs from training (training appears as a vertical line because the FLOPs are relatively low, and endpoints represent results from the final epoch). Right: estimation error with different training dataset sizes given equivalent compute per data point (matched by using fewer KernelSHAP samples when generating noisy labels for amortization and allowing up to 50 epochs of training).", "description": "This figure compares the performance of amortized Shapley value feature attribution with the standard KernelSHAP approach. The left panel shows that the amortized model achieves lower error than the noisy oracle labels, even with a small number of samples. The center panel shows that, in terms of FLOPs, the amortized model is much more efficient and that the error further decreases with increased training. The right panel further demonstrates that the amortized model consistently outperforms the KernelSHAP approach, given a fixed computational budget per data point.", "section": "5.1 Feature attribution"}, {"figure_path": "ZdWTN2HOie/figures/figures_34_1.jpg", "caption": "Figure 3: Amortized Shapley value feature attributions using KernelSHAP as a noisy oracle. Left: squared error relative to the ground truth attributions when using noisy labels with different numbers of samples (different noise levels). Center: estimation error as a function of FLOPs, where KernelSHAP incurs FLOPs via classifier predictions used to estimate the attributions, and amortization incurs additional FLOPs from training (training appears as a vertical line because the FLOPs are relatively low, and endpoints represent results from the final epoch). Right: estimation error with different training dataset sizes given equivalent compute per data point (matched by using fewer KernelSHAP samples when generating noisy labels for amortization and allowing up to 50 epochs of training).", "description": "The figure displays the results of using stochastic amortization for Shapley value feature attribution.  It shows the error rates compared to ground truth attributions, considering varying noise levels in the training data and computational cost (FLOPs). The three sub-figures show how the error varies with sample size, FLOPs, and dataset size.", "section": "5.1 Feature attribution"}, {"figure_path": "ZdWTN2HOie/figures/figures_34_2.jpg", "caption": "Figure 3: Amortized Shapley value feature attributions using KernelSHAP as a noisy oracle. Left: squared error relative to the ground truth attributions when using noisy labels with different numbers of samples (different noise levels). Center: estimation error as a function of FLOPs, where KernelSHAP incurs FLOPs via classifier predictions used to estimate the attributions, and amortization incurs additional FLOPs from training (training appears as a vertical line because the FLOPs are relatively low, and endpoints represent results from the final epoch). Right: estimation error with different training dataset sizes given equivalent compute per data point (matched by using fewer KernelSHAP samples when generating noisy labels for amortization and allowing up to 50 epochs of training).", "description": "The figure shows the results of applying stochastic amortization to Shapley value feature attribution using KernelSHAP as the noisy oracle.  The left panel shows the error decreases as more samples are used in the KernelSHAP approximation. The center panel compares the error against FLOPs (floating-point operations), demonstrating amortization is significantly faster. The right panel compares the error for different dataset sizes given the same compute budget, showcasing amortization's efficiency, particularly in larger datasets.", "section": "5.1 Feature attribution"}, {"figure_path": "ZdWTN2HOie/figures/figures_35_1.jpg", "caption": "Figure 3: Amortized Shapley value feature attributions using KernelSHAP as a noisy oracle. Left: squared error relative to the ground truth attributions when using noisy labels with different numbers of samples (different noise levels). Center: estimation error as a function of FLOPs, where KernelSHAP incurs FLOPs via classifier predictions used to estimate the attributions, and amortization incurs additional FLOPs from training (training appears as a vertical line because the FLOPs are relatively low, and endpoints represent results from the final epoch). Right: estimation error with different training dataset sizes given equivalent compute per data point (matched by using fewer KernelSHAP samples when generating noisy labels for amortization and allowing up to 50 epochs of training).", "description": "This figure compares the performance of the proposed stochastic amortization method against the standard KernelSHAP method for Shapley value feature attribution. The left panel shows that amortization significantly reduces the error compared to using noisy labels, especially when the number of samples used for generating the noisy labels is small. The center panel demonstrates that amortization requires less computation (measured in FLOPs) to achieve a similar level of accuracy. The right panel shows that, when the compute budget is matched between the two methods, amortization achieves better accuracy, especially for larger datasets.", "section": "5.1 Feature attribution"}, {"figure_path": "ZdWTN2HOie/figures/figures_35_2.jpg", "caption": "Figure 3: Amortized Shapley value feature attributions using KernelSHAP as a noisy oracle. Left: squared error relative to the ground truth attributions when using noisy labels with different numbers of samples (different noise levels). Center: estimation error as a function of FLOPs, where KernelSHAP incurs FLOPs via classifier predictions used to estimate the attributions, and amortization incurs additional FLOPs from training (training appears as a vertical line because the FLOPs are relatively low, and endpoints represent results from the final epoch). Right: estimation error with different training dataset sizes given equivalent compute per data point (matched by using fewer KernelSHAP samples when generating noisy labels for amortization and allowing up to 50 epochs of training).", "description": "This figure compares the performance of stochastic amortization against the standard per-example KernelSHAP method for Shapley value feature attribution. It shows three plots demonstrating the effect of (left) noise level on estimation error, (center) computational cost (FLOPs) on estimation error, and (right) the size of training data on estimation error while maintaining a similar computational budget.  The results indicate that stochastic amortization consistently outperforms the per-example method across all three scenarios.", "section": "5.1 Feature attribution"}, {"figure_path": "ZdWTN2HOie/figures/figures_36_1.jpg", "caption": "Figure 3: Amortized Shapley value feature attributions using KernelSHAP as a noisy oracle. Left: squared error relative to the ground truth attributions when using noisy labels with different numbers of samples (different noise levels). Center: estimation error as a function of FLOPs, where KernelSHAP incurs FLOPs via classifier predictions used to estimate the attributions, and amortization incurs additional FLOPs from training (training appears as a vertical line because the FLOPs are relatively low, and endpoints represent results from the final epoch). Right: estimation error with different training dataset sizes given equivalent compute per data point (matched by using fewer KernelSHAP samples when generating noisy labels for amortization and allowing up to 50 epochs of training).", "description": "This figure demonstrates the effectiveness of stochastic amortization for Shapley value feature attribution.  The left panel shows the error decreases as the number of samples used to generate noisy labels increases. The center panel compares the computational cost (FLOPs) of KernelSHAP and the amortized model, demonstrating that amortization is more efficient.  The right panel shows that amortization achieves lower estimation error for datasets of various sizes when computation is matched across methods.", "section": "5.1 Feature attribution"}, {"figure_path": "ZdWTN2HOie/figures/figures_37_1.jpg", "caption": "Figure 14: Comparison of the distribution of norms between different feature attribution methods.", "description": "This figure shows the distribution of L2 norms for Shapley values, Banzhaf values, and LIME attributions. The x-axis represents the L2 norm, and the y-axis represents the count.  The distributions are shown in histograms. The figure illustrates that Shapley values tend to have larger norms compared to Banzhaf values and LIME attributions, which have norms concentrated at small magnitudes with a long tail of larger values.  This difference in scale affects the performance of the amortization for each method, as discussed in the paper.", "section": "G.2 Banzhaf value and LIME amortization"}, {"figure_path": "ZdWTN2HOie/figures/figures_38_1.jpg", "caption": "Figure 10: Comparison of the estimation error between noisy labels and amortized predictions for Shapley value feature attributions. Top: noisy labels were generated using KernelSHAP with different numbers of samples. Middle: noisy labels generated using permutation sampling with different numbers of samples. Bottom: noisy labels generated using SGD-Shapley with different numbers of samples.", "description": "This figure compares the estimation errors of three different methods for generating noisy labels (KernelSHAP, permutation sampling, and SGD-Shapley) with amortized predictions for Shapley value feature attributions.  It shows the performance of these methods with different numbers of samples used to generate the labels. The comparison is done using various metrics like error, correlation (Pearson and Spearman), and sign agreement.", "section": "G.1 Shapley value amortization"}, {"figure_path": "ZdWTN2HOie/figures/figures_38_2.jpg", "caption": "Figure 3: Amortized Shapley value feature attributions using KernelSHAP as a noisy oracle. Left: squared error relative to the ground truth attributions when using noisy labels with different numbers of samples (different noise levels). Center: estimation error as a function of FLOPs, where KernelSHAP incurs FLOPs via classifier predictions used to estimate the attributions, and amortization incurs additional FLOPs from training (training appears as a vertical line because the FLOPs are relatively low, and endpoints represent results from the final epoch). Right: estimation error with different training dataset sizes given equivalent compute per data point (matched by using fewer KernelSHAP samples when generating noisy labels for amortization and allowing up to 50 epochs of training).", "description": "This figure compares the performance of amortized Shapley value feature attribution against KernelSHAP with respect to different noise levels, FLOPs, and training data sizes.  The left panel shows the impact of the number of KernelSHAP samples (noise level) on the error. The center panel compares the error as a function of FLOPs (floating-point operations) showing the trade-off between the computation cost of obtaining noisy labels and the cost of training the amortized model. The right panel demonstrates error as a function of training set size, keeping a fixed compute budget for both methods.", "section": "5.1 Feature attribution"}, {"figure_path": "ZdWTN2HOie/figures/figures_39_1.jpg", "caption": "Figure 3: Amortized Shapley value feature attributions using KernelSHAP as a noisy oracle. Left: squared error relative to the ground truth attributions when using noisy labels with different numbers of samples (different noise levels). Center: estimation error as a function of FLOPs, where KernelSHAP incurs FLOPs via classifier predictions used to estimate the attributions, and amortization incurs additional FLOPs from training (training appears as a vertical line because the FLOPs are relatively low, and endpoints represent results from the final epoch). Right: estimation error with different training dataset sizes given equivalent compute per data point (matched by using fewer KernelSHAP samples when generating noisy labels for amortization and allowing up to 50 epochs of training).", "description": "The figure displays a comparison of the performance of stochastic amortization against the KernelSHAP method for Shapley value feature attribution.  Three subplots illustrate the results: (Left) estimation error based on noisy labels with varied sample sizes; (Center) a comparison of FLOPs required for the methods to estimate the attributions; and (Right) estimation error against varying training dataset sizes with matched computational budgets. The results demonstrate that amortization yields significant improvements.", "section": "5.1 Feature attribution"}, {"figure_path": "ZdWTN2HOie/figures/figures_40_1.jpg", "caption": "Figure 3: Amortized Shapley value feature attributions using KernelSHAP as a noisy oracle. Left: squared error relative to the ground truth attributions when using noisy labels with different numbers of samples (different noise levels). Center: estimation error as a function of FLOPs, where KernelSHAP incurs FLOPs via classifier predictions used to estimate the attributions, and amortization incurs additional FLOPs from training (training appears as a vertical line because the FLOPs are relatively low, and endpoints represent results from the final epoch). Right: estimation error with different training dataset sizes given equivalent compute per data point (matched by using fewer KernelSHAP samples when generating noisy labels for amortization and allowing up to 50 epochs of training).", "description": "This figure shows the results of the Shapley value feature attribution experiments using KernelSHAP as a noisy oracle.  The left panel shows the squared error of the attributions decreases as the number of KernelSHAP samples increases (reducing noise). The center panel demonstrates that amortized predictions achieve lower error for the same computational cost (FLOPs), as training the amortized model is cheap relative to repeated exact computation. The right panel highlights that the error decreases as the training set size grows, while maintaining equivalent compute per data point by using fewer KernelSHAP samples for noisy labels.", "section": "5.1 Feature attribution"}, {"figure_path": "ZdWTN2HOie/figures/figures_41_1.jpg", "caption": "Figure 19: Distributional data valuation for CIFAR-10 with 50K data points. We generate Monte Carlo estimates and amortized estimates with different numbers of samples per data point, and the scores are compared to ground truth values using four metrics.", "description": "This figure compares the performance of Monte Carlo and amortized methods for estimating distributional data valuation scores on the CIFAR-10 dataset.  Four metrics are used to evaluate the accuracy of the estimations: squared error, Pearson correlation, Spearman correlation, and sign agreement.  The results show how the accuracy of both methods improves as the number of samples per data point increases, but the amortized method consistently outperforms the Monte Carlo method.", "section": "5.3 Distributional data valuation"}, {"figure_path": "ZdWTN2HOie/figures/figures_41_2.jpg", "caption": "Figure 19: Distributional data valuation for CIFAR-10 with 50K data points. We generate Monte Carlo estimates and amortized estimates with different numbers of samples per data point, and the scores are compared to ground truth values using four metrics.", "description": "This figure shows the results of distributional data valuation experiments on CIFAR-10 dataset using 50K data points.  It compares the performance of Monte Carlo estimates and amortized estimates against ground truth values, using different numbers of samples per data point. Four evaluation metrics are employed: squared error, Pearson correlation, Spearman correlation, and sign agreement. The results illustrate the accuracy and efficiency of the amortized approach in data valuation.", "section": "5.3 Distributional data valuation"}, {"figure_path": "ZdWTN2HOie/figures/figures_42_1.jpg", "caption": "Figure 13: Comparison between stochastic amortization, FastSHAP and KernelSHAP as a function of total FLOPs.", "description": "This figure compares the performance of stochastic amortization with FastSHAP and KernelSHAP for Shapley value feature attributions. The x-axis represents total FLOPs, while the y-axis represents the error in the estimated Shapley values. It demonstrates that stochastic amortization achieves comparable accuracy to FastSHAP, while both methods significantly outperform KernelSHAP, especially when using more computationally expensive methods.  The results suggest that stochastic amortization is a computationally efficient and accurate alternative for calculating Shapley values.", "section": "Additional Results"}]