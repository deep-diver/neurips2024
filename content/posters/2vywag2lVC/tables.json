[{"figure_path": "2vywag2lVC/tables/tables_6_1.jpg", "caption": "Table 1: Summary of the sample complexity results of C-PG when either keeping w fixed or setting it as w = O(\u03b5).", "description": "This table summarizes the sample complexity results of the C-PG algorithm under different conditions.  It shows how the sample complexity scales with epsilon (\u03b5) and the regularization parameter (\u03c9) for both exact and estimated gradients, and for different values of \u03c8 (a parameter related to the gradient domination condition).  The table distinguishes between keeping \u03c9 fixed or setting it to be a function of \u03b5.  The results indicate that the algorithm's complexity varies based on the presence of gradient noise and the strength of the gradient domination.", "section": "3 Last-Iterate Global Convergence of C-PG"}, {"figure_path": "2vywag2lVC/tables/tables_7_1.jpg", "caption": "Table 2: Mapping of the unified risk measure to risk measures.", "description": "This table shows how the unified risk measure formulation can be used to represent several risk measures by selecting appropriate functions  *f\u1d62* and *g\u1d62*. It lists the risk measure, its parameter, whether an auxiliary parameter \u03b7 is needed, the form of *f\u1d62(C\u1d62(\u03c4), \u03b7)*, the form of *g\u1d62(\u03b7)*, whether an action-based GPOMDP-like estimator is available, and if so, whether it's partial or not. The table clarifies how different risk preferences can be incorporated into the optimization problem by changing the parameters and functions in the unified formulation.", "section": "4.1 Risk-Constrained Optimization Problem"}, {"figure_path": "2vywag2lVC/tables/tables_16_1.jpg", "caption": "Table 3: Comparison among primal-dual methods ensuring last-iterate global convergence guarantees.", "description": "This table compares various primal-dual methods for constrained reinforcement learning, focusing on their ability to achieve last-iterate global convergence.  It contrasts the algorithms across several key features: whether they are dimension-free (independent of state/action space size), the setting (number of constraints, infinite vs. finite horizon), the exploration type (action-based or parameter-based), whether they use single or multiple timescales for learning rate updates, whether they employ exact or inexact gradients, the assumptions needed for their convergence guarantees, and their sample and iteration complexity. The table also includes a lower bound on sample complexity for reference.", "section": "Related Works"}, {"figure_path": "2vywag2lVC/tables/tables_19_1.jpg", "caption": "Table 2: Mapping of the unified risk measure to risk measures.", "description": "This table shows how different risk measures can be obtained by selecting the functions fi and gi in the unified risk measure formulation.  It lists four risk measures: Expected Cost, Mean Variance, CVaR\u03b1, and Chance, along with their associated parameters (\u03ba, \u03b1, \u03b7). For each risk measure, the table provides the specific form of the functions fi and gi, indicating whether a parameter \u03b7 is needed and if a GPOMDP-like estimator is available.  This table is crucial for understanding how the proposed algorithms can be applied to various risk-averse settings.", "section": "4.1 Risk-Constrained Optimization Problem"}, {"figure_path": "2vywag2lVC/tables/tables_39_1.jpg", "caption": "Table 3: Comparison among primal-dual methods ensuring last-iterate global convergence guarantees.", "description": "This table compares various primal-dual methods for constrained reinforcement learning, focusing on their ability to achieve last-iterate global convergence guarantees.  It contrasts the methods across several key aspects: whether they are dimension-free (i.e., convergence rates do not depend on the problem's dimension), the type of exploration paradigm used (action-based or parameter-based), whether they utilize a single or multiple time scales for updates, the type of gradients used (exact or inexact), the assumptions required for convergence guarantees, and their corresponding sample and iteration complexities.  The table also notes the existence of a lower bound for sample complexity found in other research.  It highlights the unique contributions of the proposed C-PG algorithm by comparing it to existing approaches.", "section": "Related Works"}, {"figure_path": "2vywag2lVC/tables/tables_40_1.jpg", "caption": "Table 3: Comparison among primal-dual methods ensuring last-iterate global convergence guarantees.", "description": "This table compares various primal-dual methods for constrained reinforcement learning, focusing on their ability to achieve last-iterate global convergence.  It contrasts algorithms' dimension-free properties, single/multi-timescale nature, type of gradient used (exact or inexact), exploration paradigms (action-based or parameter-based), assumptions required for convergence, and the resulting sample and iteration complexities.", "section": "Related Works"}, {"figure_path": "2vywag2lVC/tables/tables_41_1.jpg", "caption": "Table 3: Comparison among primal-dual methods ensuring last-iterate global convergence guarantees.", "description": "This table compares various primal-dual methods for constrained reinforcement learning, focusing on their ability to achieve last-iterate global convergence guarantees.  It contrasts the algorithms across several key aspects: whether they are dimension-free, the type of constraints handled, the exploration paradigm used (action-based or parameter-based), if they operate on a single time scale, the type of gradients used (exact or inexact), the assumptions required for convergence, and the resulting sample and iteration complexities. The table also includes a lower bound on the sample complexity from existing research.", "section": "Related Works"}, {"figure_path": "2vywag2lVC/tables/tables_41_2.jpg", "caption": "Table 8: Parameters of the risk measures employed in the experiment on Swimmer-v4 with C-PGAE.", "description": "This table lists the parameters used for different risk measures in the Swimmer-v4 experiment using the C-PGAE algorithm.  It shows the risk measure (Average Cost, CVaR, Mean Variance, Chance), the associated risk parameter (\u03b1, \u03ba, n), the constraint threshold (b), and the learning rates used for the policy parameters (\u03b6\u03b8,0), dual variables (\u03b6\u03bb,0), and risk parameters (\u03b6\u03b7,0). The 'X' indicates that a parameter is not needed for the corresponding risk measure.", "section": "4.1 Risk-Constrained Optimization Problem"}, {"figure_path": "2vywag2lVC/tables/tables_41_3.jpg", "caption": "Table 8: Parameters of the risk measures employed in the experiment on Swimmer-v4 with C-PGAE.", "description": "This table lists the parameters used in the Swimmer-v4 experiment with the C-PGAE algorithm for different risk measures.  It shows the risk measure (Average Cost, CVaR, Mean Variance, Chance), the corresponding risk parameter (\u03ba, \u03b1, n), the constraint threshold (b), and the initial learning rates for the primal (\u03c1), dual (\u03bb), and risk (\u03b7) variables. The initial learning rate for \u03b7 is not used for Average Cost, as this risk measure does not depend on \u03b7.", "section": "4.1 Risk-Constrained Optimization Problem"}, {"figure_path": "2vywag2lVC/tables/tables_42_1.jpg", "caption": "Table 8: Parameters of the risk measures employed in the experiment on Swimmer-v4 with C-PGAE.", "description": "This table shows the parameters used for different risk measures in the Swimmer-v4 experiment using the C-PGAE algorithm.  It lists the risk measure (Average Cost, CVaR, Mean Variance, Chance), the corresponding risk parameter (\u03ba, \u03b1, \u03b7), the constraint threshold (b), and the learning rates for the policy parameters (\u03b6\u03b8,0), the Lagrangian multipliers (\u03b6\u03bb,0), and the risk parameters (\u03b6\u03b7,0). The table provides details for setting up the experiments, making it reproducible and highlighting the chosen parameters' values.", "section": "4.1 Risk-Constrained Optimization Problem"}, {"figure_path": "2vywag2lVC/tables/tables_42_2.jpg", "caption": "Table 8: Parameters of the risk measures employed in the experiment on Swimmer-v4 with C-PGAE.", "description": "This table shows the parameters used for the risk measures in the Swimmer-v4 experiment using the C-PGAE algorithm.  It lists the risk measure (Average Cost, CVaR\u03b1, Mean Variance, Chance), the risk parameter (\u03ba, \u03b1, \u03b7), the constraint threshold (b), and the learning rates (\u03b6\u03b8,0, \u03b6\u03bb,0, \u03b6\u03b7,0). The values indicate specific settings used in the experiment.", "section": "4.1 Risk-Constrained Optimization Problem"}, {"figure_path": "2vywag2lVC/tables/tables_43_1.jpg", "caption": "Table 3: Comparison among primal-dual methods ensuring last-iterate global convergence guarantees.", "description": "This table compares several primal-dual methods for constrained reinforcement learning, focusing on their ability to achieve last-iterate global convergence.  It contrasts various aspects, including whether the methods are dimension-free (independent of state and action space size), the type of policy gradient exploration used (action-based or parameter-based), whether they utilize a single or multiple time scales in their updates, the type of gradients (exact or inexact), the assumptions made for convergence guarantees, and the resulting sample and iteration complexities.  The table also indicates whether the algorithm handles multiple constraints (U\u22651) and the type of dual descent used.", "section": "Related Works"}, {"figure_path": "2vywag2lVC/tables/tables_43_2.jpg", "caption": "Table 3: Comparison among primal-dual methods ensuring last-iterate global convergence guarantees.", "description": "This table compares several primal-dual methods for constrained reinforcement learning, focusing on their ability to guarantee last-iterate global convergence.  It contrasts various aspects, including whether the method is dimension-free, the type of exploration used (action-based or parameter-based), single or multiple time scales, the type of gradient (exact or inexact), the assumptions required for convergence, and the resulting sample and iteration complexity.  The table highlights the trade-offs between different approaches, particularly regarding computational efficiency and the strength of convergence guarantees.", "section": "Related Works"}]