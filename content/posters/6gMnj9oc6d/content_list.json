[{"type": "text", "text": "Scalable DP-SGD: Shuffling vs. Poisson Subsampling ", "text_level": 1, "page_idx": 0}, {"type": "image", "img_path": "6gMnj9oc6d/tmp/6e8b788cc9698932d4d646d43babc3f69411fd0c6fff18795d433f1a91b381c3.jpg", "img_caption": [], "img_footnote": [], "page_idx": 0}, {"type": "text", "text": "Google Research chiyuan@google.com ", "page_idx": 0}, {"type": "text", "text": "Abstract ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "We provide new lower bounds on the privacy guarantee of the multi-epoch Adaptive Batch Linear Queries (ABLQ) mechanism with shuffled batch sampling, demonstrating substantial gaps when compared to Poisson subsampling; prior analysis was limited to a single epoch. Since the privacy analysis of Differentially Private Stochastic Gradient Descent (DP-SGD) is obtained by analyzing the ABLQ mechanism, this brings into serious question the common practice of implementing shuffling-based DP-SGD, but reporting privacy parameters as if Poisson subsampling was used. To understand the impact of this gap on the utility of trained machine learning models, we introduce a practical approach to implement Poisson subsampling at scale using massively parallel computation, and efficiently train models with the same. We compare the utility of models trained with Poissonsubsampling-based DP-SGD, and the optimistic estimates of utility when using shuffling, via our new lower bounds on the privacy guarantee of ABLQ with shuffling. ", "page_idx": 0}, {"type": "text", "text": "1 Introduction ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "A common approach for private training of differentiable models, such as neural networks, is to apply first-order methods with noisy gradients. This general framework is known as DP-SGD (Differentially Private Stochastic Gradient Descent) [Abadi et al., 2016]; the framework itself is compatible with any optimization sub-routine. Multiple open source implementations exist for applying DP-SGD in practice, namely, Tensorflow Privacy, JAX Privacy [Balle et al., 2022] and PyTorch Opacus [Yousefpour et al., 2021]; and DP-SGD has been applied widely in various machine learning domains [e.g., Tramer and Boneh, 2020, De et al., 2022, Bu et al., 2022, Chen et al., 2020, Dockhorn et al., 2023, Anil et al., 2022, He et al., 2022, Igamberdiev et al., 2024, Tang et al., 2024]. ", "page_idx": 0}, {"type": "text", "text": "DP-SGD (Algorithm 1) processes the training data in a sequence of steps, where at each step, a noisy estimate of the average gradient over a mini-batch is computed and used to perform a first-order update over the differentiable model. To obtain the noisy (average) gradient, the gradient $g$ for each example in the mini-batch is clipped to have norm at most $C$ (a pre-determined fixed bound), by setting $[g]_{C}:=g\\cdot\\operatorname*{min}\\{1,C/\\|g\\|_{2}\\}$ , and computing the sum over the batch; then independent zero-mean noise drawn from the Gaussian distribution of scale $\\sigma C$ is added to each coordinate of the summed gradient. This could then be scaled by the \u201ctarget\u201d mini-batch size to obtain a noisy ", "page_idx": 0}, {"type": "text", "text": "Algorithm 1 DP-SGD: Differentially Private Stochastic Gradient Descent [Abadi et al., 2016] ", "page_idx": 1}, {"type": "text", "text": "Params: Batch sampler $\\boldsymbol{\\mathrm{\\Delta}}\\boldsymbol{\\mathrm{\\Omega}}^{\\beta}$ (samples $T$ batches, with \u201ctarget\u201d batch size $b$ ), differentiable loss \u2113: R \u00d7 X \u2192R , initial model state $w_{0}$ , clipping norm $C$ , noise scale $\\sigma$ . ", "page_idx": 1}, {"type": "text", "text": "Input: Dataset $\\pmb{x}=(x_{1},\\ldots,x_{n})$ .   \nOutput: Final model state $\\pmb{w}_{T}\\in\\mathbb{R}^{d}$ . $(\\bar{S}_{1},\\ldots,S_{T})\\gets B(n)$ for $t=1,\\dots,T$ do $\\begin{array}{r}{g_{t}\\leftarrow\\frac{1}{b}\\left(\\bar{\\mathcal{N}}(0,\\sigma^{2}C^{2}I_{d})+\\sum_{x\\in S_{t}}[\\nabla_{w}\\ell({\\pmb w};x)]_{C}\\right)}\\end{array}$ wt \u2190wt\u22121 \u2212\u03b7tgt \u25b7Could also be some other optimization method. return wT ", "page_idx": 1}, {"type": "text", "text": "average gradient.1 The privacy guarantee of the mechanism depends on the following parameters: the noise scale $\\sigma$ , the number of examples in the training dataset, the size of mini-batches, the number of training steps, and the mini-batch generation process. ", "page_idx": 1}, {"type": "text", "text": "In practice, almost all deep learning systems generate mini-batches of fixed-size by sequentially going over the dataset, possibly applying a global shuffling of all the examples in the dataset for each training epoch; each epoch corresponds to a single pass over the dataset, and the ordering of the examples may be kept the same or resampled between different epochs. However, performing the privacy analysis for such a mechanism has appeared to be technically difficult due to correlation between the different mini-batches. Abadi et al. [2016] instead consider a different mini-batch generation process of Poisson subsampling, wherein each mini-batch is generated independently by including each example with a fixed probability. This mini-batch generation process is however rarely implemented in practice, and consequently it has become common practice to use some form of shuffling in applications, but to report privacy parameters as if Poisson subsampling was used (see, e.g., the survey by Ponomareva et al. [2023, Section 4.3]). A notable exception is the PyTorch Opacus library [Yousefpour et al., 2021] that supports the option of Poisson subsampling; however, this implementation only works well for datasets that allow efficient random access (for instance by loading it entirely into memory). To the best of knowledge, Poisson subsampling has not been used for training with DP-SGD on massive datasets. ", "page_idx": 1}, {"type": "text", "text": "The privacy analysis of DP-SGD is usually performed by viewing it as a post-processing of an Adaptive Batch Linear Queries (ABLQ) mechanism that releases the estimates of a sequence of adaptively chosen linear queries on the mini-batches (formal definitions in Section 2.1). Chua et al. [2024] showed that the privacy loss of $\\mathsf{A B L Q}$ with shuffling can be significantly higher than that with Poisson subsampling for small values of $\\sigma$ . Even though their analysis only applied to a single epoch mechanism, this has put under serious question the aforementioned common practice of implementing DP-SGD with some form of shuffling while reporting privacy parameters assuming Poisson subsampling. The motivating question for our work is: ", "page_idx": 1}, {"type": "text", "text": "Which batch sampler provides the best utility for models trained with DP-SGD, when applied with the correct corresponding privacy accounting? ", "page_idx": 1}, {"type": "text", "text": "1.1 Contributions ", "text_level": 1, "page_idx": 1}, {"type": "text", "text": "Our contributions are summarized as follows. ", "page_idx": 1}, {"type": "text", "text": "Privacy Analysis of Multi-Epoch ABLQ with Shuffilng. We provide lower bounds on the privacy guarantees of shuffling-based ABLQ to handle multiple epochs. We consider the cases of both (i) Persistent Shuffling, wherein the examples are globally shuffled once and the order is kept the same between epochs, and (ii) Dynamic Shuffilng, wherein the examples are globally shuffled independently for each epoch. Since our technique provides a lower bound on the privacy guarantee, the utility of the models obtained via shuffling-based DP-SGD with this privacy accounting is an optimistic estimate of the utility under the correct accounting. ", "page_idx": 1}, {"type": "text", "text": "Scalable Implementation of DP-SGD with Poisson Subsampling via Truncation. Variable batches are typically inconvenient to handle in deep learning systems. For example, upon a change in the input shape, jax.jit triggers a recompilation of the computation graph, and tf.function will retrace the computation graph. Additionally, Google TPUs require all operations to have fixed input and output shapes. We introduce truncated Poisson subsampling to circumvent variable batch sizes. In particular, we choose an upper bound on the maximum batch size $B$ that our training can handle, and given any variable size batch $b$ , if $b\\geq B$ , we randomly sub-select $B$ examples to retain in the batch, and if $b<B$ , we pad the batch with $B-b$ dummy examples with zero weight. This deviates slightly from the standard Poisson subsampling process since our batch sizes can never exceed $B$ . We choose $B$ to be sufficiently larger than the expected batch size, so that the probability that the sampled batch size $b$ exceeds the maximum allowed batch size $B$ is small. We provide a modification to the analysis of ABLQ with Poisson subsampling in order to handle this difference. ", "page_idx": 1}, {"type": "text", "text": "", "page_idx": 2}, {"type": "text", "text": "Generating these truncated Poisson subsampled batches can be difficult when the dataset is too large to fti in memory. We provide a scalable approach to the generation of batches with truncated Poisson subsampling using massively parallel computation [Dean and Ghemawat, 2004]. This can be easily specified using frameworks like beam [Apache Beam] and implemented on distributed platforms such as Apache Flink, Apache Spark, or Google Cloud Dataflow. ", "page_idx": 2}, {"type": "text", "text": "Our detailed experimental results are presented in Section 4, and summarized below: ", "page_idx": 2}, {"type": "text", "text": "\u2022 DP-SGD with Shuffle batch samplers performs similarly to Poisson subsampling for the same $\\sigma$ . \u2022 However, DP-SGD with Shuffle batch samplers, with our optimistic privacy accounting, perform worse than Poisson subsampling in high privacy regimes (small values of $\\varepsilon$ ). ", "page_idx": 2}, {"type": "text", "text": "Thus, our results suggest that Poisson subsampling is a viable option for implementing DP-SGD at scale, with almost no loss in utility compared to the traditional approach that uses shuffling with (incorrect) accounting assuming Poisson subsampling. ", "page_idx": 2}, {"type": "text", "text": "1.2 Related Work ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "Chua et al. [2024] demonstrated gaps in the privacy analysis of ABLQ using shuffilng and Poisson subsampling, by providing a lower bound on the privacy guarantee of ABLQ with shuffling; their technique, however, was specialized for one epoch. We extend their technique to the multi-epoch version of ABLQ with shuffling and provide lower bounds for both persistent and dynamic batching. ", "page_idx": 2}, {"type": "text", "text": "Lebeda et al. [2024] also point out gaps in the privacy analysis of ABLQ with Poisson subsampling and with sampling batches of fixed size independently, showing that the latter has worse privacy guarantees than Poisson subsampling. We do not cover this sampling in our experimental study, since sampling independent batches of fixed size is not commonly implemented in practice, and DP-SGD using this sampling is only expected to be worse as compared to Poisson subsampling. ", "page_idx": 2}, {"type": "text", "text": "Yousefpour et al. [2021] report the model utility (and computational cost overhead) under training with DP-SGD with Poisson subsampling. However, to the best of our knowledge, there is no prior work that has compared the model utility of DP-SGD under Poisson subsampling with that under shuffilng, let alone compared it against DP-SGD under (Dynamic/Persistent) shuffling or studied the gaps between the privacy accounting of the two approaches. ", "page_idx": 2}, {"type": "text", "text": "One possible gap between the privacy analysis of DP-SGD and ABLQ is that the former only releases the final iterate, whereas the latter releases the responses to all the queries. An interesting result by Annamalai [2024] shows that in general the privacy analysis of the last-iterate of DP-SGD cannot be improved over that of ABLQ, when using Poisson subsampling. This suggests that at least without any further assumptions, e.g., on the loss function, it is not possible to improve the privacy analysis of DP-SGD beyond that provided by ABLQ; this is in contrast to the techniques of privacy amplification by iteration for convex loss functions [e.g. Feldman et al., 2018, Altschuler and Talwar, 2022]. ", "page_idx": 2}, {"type": "text", "text": "2 Preliminaries ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "A differentially private (DP) mechanism $\\mathcal{M}:\\mathcal{X}^{*}\\rightarrow\\Delta_{\\mathcal{O}}$ can be viewed as a mapping from input datasets to distributions over an output space, namely, on input dataset $\\pmb{x}=(x_{1},\\ldots,x_{n})$ where each example $x_{i}\\in\\mathcal{X},\\mathcal{M}(\\pmb{x})$ is a probability measure over the output space $\\scriptscriptstyle\\mathcal{O}$ ; for ease of notation, we often refer to the corresponding random variable also as $\\mathcal{M}(\\pmb{x})$ . Two datasets $\\textbf{\\em x}$ and $\\pmb{x}^{\\prime}$ are said to be adjacent, denoted $x\\sim x^{\\prime}$ , if they \u201cdiffer in one example\u201d; in particular, we use the \u201czeroing-out\u201d adjacency defined shortly. ", "page_idx": 2}, {"type": "text", "text": "Params: Batch sampler $\\boldsymbol{\\mathrm{\\Delta}}\\boldsymbol{\\mathrm{\\Omega}}_{\\boldsymbol{B}}$ (samples $T$ batches), noise scale $\\sigma$ , and (adaptive) query method $\\boldsymbol{\\mathcal{A}}$ : $(\\mathbb{R}^{d})^{*}\\times\\mathcal{X}\\rightarrow\\mathbb{B}^{d}$ .   \nInput: Dataset $\\pmb{x}=(x_{1},\\ldots,x_{n})$ .   \nOutput: Query estimates $g_{1},\\dots,g_{T}\\in\\mathbb{R}^{d}$ $(\\bar{S}_{1},\\bar{\\dots},S_{T}\\bar{)}\\gets B(n)$ for $t=1,\\dots,T$ do $\\psi_{t}(\\cdot):=A(g_{1},\\ldots,g_{t-1};\\cdot)$ $\\begin{array}{r}{g_{t}\\gets e_{t}+\\sum_{i\\in S_{t}}\\psi_{t}(x_{i})}\\end{array}$ for $e_{t}\\sim\\mathcal{N}(0,\\sigma^{2}I_{d})$ return $(g_{1},\\hdots,g_{T})$ ", "page_idx": 3}, {"type": "image", "img_path": "6gMnj9oc6d/tmp/dbe76116e136454b89a265b4fc86027386db92e8290b10bfb99e667d92eb5611.jpg", "img_caption": [], "img_footnote": [], "page_idx": 3}, {"type": "text", "text": "Definition 2.1 (DP). For $\\varepsilon,\\delta\\ge0$ , a mechanism $\\mathcal{M}$ satisfies $(\\varepsilon,\\delta)$ -DP if for all \u201cadjacent\u201d datasets $x\\sim x^{\\prime}$ , and for any (measurable) event $\\Gamma$ it holds that $\\mathrm{Pr}[\\mathcal{M}(\\pmb{x})\\in\\Gamma]\\;\\leq\\;e^{\\varepsilon}\\,\\mathrm{Pr}[\\mathcal{M}(\\pmb{x}^{\\prime})\\in\\Gamma]+\\delta$ . ", "page_idx": 3}, {"type": "text", "text": "For any mechanism $\\mathcal{M}$ , we use $\\delta_{\\mathcal{M}}:\\mathbb{R}_{\\geq0}\\rightarrow[0,1]$ to denote its privacy loss curve, namely $\\delta_{\\mathcal{M}}(\\varepsilon)$ is the smallest $\\delta$ such that $\\mathcal{M}$ satisfies $(\\varepsilon,\\delta)$ -DP; $\\varepsilon_{\\mathcal{M}}:[0,1]\\to\\mathbb{R}_{\\ge0}$ is defined similarly. ", "page_idx": 3}, {"type": "text", "text": "2.1 Adaptive Batch Linear Queries Mechanism ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "Following the notation in Chua et al. [2024], we study the adaptive batch linear queries mechanism $\\mathsf{A B L Q}_{B}$ (Algorithm 2) using a batch sampler $\\boldsymbol{\\mathrm{\\Delta}}\\boldsymbol{\\mathrm{\\Omega}}_{\\boldsymbol{B}}$ and an adaptive query method $\\boldsymbol{\\mathcal{A}}$ , defined. The batch sampler $\\boldsymbol{\\mathrm{\\Delta}}\\boldsymbol{\\mathrm{\\Omega}}^{\\beta}$ can be any algorithm that randomly samples a sequence $S_{1},...,S_{T}$ of batches. $\\mathsf{A B L Q}_{B}$ operates by processing the batches in a sequential order, and produces a sequence $(g_{1},\\hdots,g_{T})$ , where the response $g_{t}\\in\\mathbb{R}^{d}$ is produced as the sum of $\\psi_{t}(x)$ over the batch $S_{t}$ with added zero-mean Gaussian noise of scale $\\sigma$ to all coordinates, where the query $\\psi_{t}\\,:\\,\\boldsymbol{\\mathcal{X}}\\,\\rightarrow\\,\\mathbb{B}^{d}$ (for ${\\mathbb B}^{d}:=\\{v\\,\\in\\,\\}$ $\\mathbb{R}^{d}:\\|v\\|_{2}\\leq1\\}$ is produced by the adaptive query method $\\boldsymbol{\\mathcal{A}}$ , based on the previous responses $g_{1},\\ldots,g_{t-1}$ . DP-SGD can be viewed as a post-processing of an adaptive query method that maps examples to the clipped gradient at the last iterate, namely $\\begin{array}{r}{\\dot{\\psi}_{t}(x):=[\\nabla_{\\pmb{w}}\\ell(\\dot{\\pmb{w}}_{t-1},x)]_{1}}\\end{array}$ (we treat the clipping norm $C=1$ for simplicity, as it is just a scaling term). ", "page_idx": 3}, {"type": "text", "text": "In this work, we consider the following multi-epoch batch samplers: Deterministic $\\mathcal{D}_{b,T}$ , Persistent Shuffle $S_{b,T}^{\\diamond}$ , and Dynamic Shuffle $S_{b,T}^{\\odot}$ batch sampler defined as instantiations of Algorithm 3 in Figure 1 and truncated Poisson $\\mathcal{P}_{b,B,T}$ (Algorithm 4); we drop the subscripts of each sampler whenever it is clear from context. Note that, while $\\mathcal{P}_{b,B,T}$ has no restriction on the value of $n$ , the samplers $\\mathcal{D}_{b,T},\\mathcal{S}_{b,T}^{\\diamond}$ , and $S_{b,T}^{\\odot}$ require that the number of examples $n$ is such that $E:=b T/n$ and $S:=n/b$ are integers, where corresponds to the number of epochs and $S$ corresponds to the number of steps per epoch. We call the tuple $(n,b,T)$ as \u201cvalid\u201d if that holds, and we will often implicitly assume that this holds. Also note that $\\mathcal{P}_{b,B,T}$ corresponds to the standard Poisson subsampling without truncation when $B=\\infty$ . We use $\\delta_{B}(\\varepsilon)$ to denote the privacy loss curve of $\\mathsf{A B L Q}_{B}$ for any $B\\in\\{\\mathcal{D},\\mathcal{P},\\mathcal{S}^{\\diamond},\\mathcal{S}^{\\diamond}\\}$ , where other parameters such as $\\sigma,T$ , etc. are implicit. Namely, for all $\\varepsilon>0$ , let $\\delta_{B}(\\varepsilon)$ be the smallest $\\delta\\geq0$ such that $\\mathsf{A B L Q}_{B}$ satisfies $(\\varepsilon,\\delta)$ -DP for all choices of the underlying adaptive query method $\\boldsymbol{\\mathcal{A}}$ . We define $\\varepsilon_{B}(\\delta)$ similarly. Finally, we define $\\sigma_{B}(\\varepsilon,\\delta)$ as the smallest $\\sigma$ such that $\\mathsf{A B L Q}_{\\mathcal{B}}$ satisfies $(\\varepsilon,\\delta)$ -DP, with other parameters being implicit in $\\boldsymbol{\\mathrm{\\Delta}}\\boldsymbol{\\mathrm{\\Omega}}_{\\boldsymbol{B}}$ . ", "page_idx": 3}, {"type": "text", "text": "Deterministic Batch Sampler $\\scriptstyle{\\mathcal{D}}_{b,T}(n)$ : Realized as $\\Pi_{b,T}(n;{\\mathsf{I d}},{\\mathsf{I d}},\\ldots)$ . where Id is the identity permutation, i.e., the data is not permuted.   \nPersistent Shuffle Batch Sampler $s_{b,T}^{\\diamond}$ : Realized as $\\Pi_{b,T}(n;\\pi,\\pi,\\ldots)$ , where $\\pi$ is a random permutation over $[n]$ , i.e., the data is shuffled once and the order is persistent across epochs.   \nDynamic Shuffle Batch Sampler $\\mathcal{S}_{b,T}^{(\\gamma)}$ : Realized as $\\Pi_{b,T}(n;\\pi_{0},\\pi_{1},.\\;.\\;.)$ , where $\\pi_{e}$ \u2019s are i.i.d. random permutations over $[n]$ , i.e., the data is reshuffled in each epoch. ", "page_idx": 4}, {"type": "text", "text": "Adjacency notion. The common notion of Add-Remove adjacency is not applicable for mechanisms such as $\\mathsf{A B L Q}_{\\mathcal{D}}$ , $\\mathsf{A B L Q}_{S^{\\circ}}$ , $\\mathsf{A B L Q}_{S^{\\odot}}$ because these methods require that $b T/n$ and $n/b$ are integers, and changing $n$ by $\\pm1$ does not respect this requirement. And while the other common notion of Substitution is applicable for all the mechanisms we consider, the standard analysis for $\\mathsf{A B L Q}_{\\mathcal{P}}$ is done w.r.t Add-Remove adjacency [Abadi et al., 2016, Mironov, 2017]. Therefore, we use the \u201cZeroing-out\u201d adjacency introduced by Kairouz et al. [2021], namely we consider the augmented input space $\\ X_{\\bot}:=\\mathcal{X}\\cup\\{\\bot\\}$ where any adaptive query method $\\boldsymbol{\\mathcal{A}}$ is extended as $\\mathbf{\\nabla}A(g_{1},\\dots,g_{t};\\perp):=\\mathbf{0}$ for all $g_{1},\\ldots,g_{t}\\in\\mathbb{R}^{d}$ . Datasets $\\textbf{\\em x}$ $\\mathbf{r},x^{\\prime}\\in\\mathcal{X}_{\\perp}^{n}$ are said to be zero-out adjacent if there exists $i$ such that $\\pmb{x}_{-i}=\\pmb{x}_{-i}^{\\prime}$ , and exactly one of $\\{x_{i},x_{i}^{\\prime}\\}$ is in $\\mathcal{X}$ and the other is $\\perp$ . We use $\\mathbf{\\boldsymbol{x}}\\to_{z}\\mathbf{\\boldsymbol{x}}^{\\prime}$ to specifically denote adjacent datasets with $x_{i}\\in\\mathcal{X}$ and $x_{i}^{\\prime}=\\perp$ . Thus $x\\sim x^{\\prime}$ if either $\\mathbf{\\boldsymbol{x}}\\to_{z}\\mathbf{\\boldsymbol{x}}^{\\prime}$ or $\\mathbf{\\boldsymbol{x}}^{\\prime}\\to\\mathbf{\\boldsymbol{x}}$ . ", "page_idx": 4}, {"type": "text", "text": "2.2 Dominating Pairs ", "text_level": 1, "page_idx": 4}, {"type": "text", "text": "For two probability density functions $P$ and $Q$ and $\\alpha,\\beta\\in\\mathbb{R}_{\\geq0}$ , we use $\\alpha P+\\beta Q$ to denote the weighted sum of the density functions. We use $P\\otimes Q$ to denote the product distribution sampled as $\\left(\\omega_{1},\\omega_{2}\\right)$ for $\\omega_{1}\\sim P$ , $\\omega_{2}\\sim Q$ , and, $P^{\\otimes T}$ to denote the $T$ -fold product distribution $P\\otimes\\cdot\\cdot\\otimes P$ . For all $\\varepsilon\\in\\mathbb R$ , the $e^{\\varepsilon}$ -hockey stick divergence between $P$ and $Q$ is $D_{e^{\\varepsilon}}(P\\|Q):=\\operatorname*{sup}_{\\Gamma}P(\\Gamma)-e^{\\varepsilon}Q(\\Gamma)$ . Thus, by definition a mechanism $\\mathcal{M}$ satisfies $(\\varepsilon,\\delta)$ -DP iff for all adjacent $x\\sim x^{\\prime}$ , it holds that $D_{e^{\\varepsilon}}(\\mathcal{M}(\\pmb{x})\\|\\mathcal{M}(\\pmb{x}^{\\prime}))\\leq\\delta$ . ", "page_idx": 4}, {"type": "text", "text": "Definition 2.2 (Dominating Pair [Zhu et al., 2022]). The pair $(P,Q)$ dominates the pair $(A,B)$ (denoted $(P,Q)\\succcurlyeq(A,B))$ if $D_{e^{\\varepsilon}}(P\\|Q)\\ \\geq\\ D_{e^{\\varepsilon}}(A\\|B)$ holds for all $\\varepsilon\\in\\mathbb R$ . We say that $(P,Q)$ dominates a mechanism $\\mathcal{M}$ (denoted $(P,Q)\\succcurlyeq M)$ if $(\\dot{P},Q)\\succcurlyeq(\\mathcal{M}(\\mathbf{x}),\\mathcal{M}(\\mathbf{x}^{\\prime}))$ for all adjacent $\\mathbf{\\boldsymbol{x}}\\to_{z}\\mathbf{\\boldsymbol{x}}^{\\prime}$ . ", "page_idx": 4}, {"type": "text", "text": "If $(P,Q)\\,\\succcurlyeq\\,\\mathcal{M}$ , then for all $\\varepsilon\\:\\geq\\:0$ , it holds that $\\delta_{\\mathcal{M}}(\\varepsilon)\\,\\leq\\,\\operatorname*{max}\\{D_{e^{\\varepsilon}}(P\\|Q),D_{e^{\\varepsilon}}(Q\\|P)\\}$ , and conversely, if there exists adjacent datasets $\\textbf{\\em x}\\to_{z}\\textbf{\\em x}^{\\prime}$ such that $(\\mathcal{M}(\\pmb{x}),\\mathcal{M}(\\pmb{x}^{\\prime}))\\,\\succcurlyeq\\,(P,Q)$ , then $\\delta_{\\mathcal{M}}(\\varepsilon)\\ \\geq\\ \\operatorname*{max}\\{D_{e^{\\varepsilon}}(P\\|Q),\\bar{D}_{e^{\\varepsilon}}(Q\\|P)\\}$ . When both of these hold, we say that $(P,Q)$ tightly dominates the mechanism $\\mathcal{M}$ (denoted $(P,Q)\\;\\equiv\\;{\\mathcal M})$ and in this case it holds that $\\delta_{\\mathcal{M}}(\\varepsilon)\\;=\\;$ $\\operatorname*{max}\\{D_{e^{\\varepsilon}}(P\\|Q),D_{e^{\\varepsilon}}(Q\\|P)\\}$ . Thus, tightly dominating pairs completely characterize the privacy loss of a mechanism (although they are not guaranteed to exist for all mechanisms). Dominating pairs behave nicely under mechanism compositions: if $(P_{1},Q_{1})\\succcurlyeq M_{1}$ and $(P_{2},Q_{2})\\succcurlyeq M_{2}$ , then $(P_{1}\\otimes P_{2},Q_{1}\\otimes Q_{2})\\succcurlyeq\\mathcal{M}_{1}\\circ\\mathcal{M}_{2}$ , where $\\mathcal{M}_{1}\\circ\\mathcal{M}_{2}$ denotes the (adaptively) composed mechanism. ", "page_idx": 4}, {"type": "text", "text": "3 Privacy analysis of multi-epoch $\\pmb{\\mathsf{A B L Q}}_{\\mathcal{B}}$ ", "text_level": 1, "page_idx": 4}, {"type": "text", "text": "We discuss the privacy analysis of $\\mathsf{A B L Q}_{\\mathcal{B}}$ for $B\\in\\{\\mathcal{D},\\mathcal{P},\\mathcal{S}^{\\diamond},\\mathcal{S}^{\\diamond}\\}$ via dominating pairs. ", "page_idx": 4}, {"type": "text", "text": "Privacy analysis for $\\mathsf{A B L Q}_{\\mathcal{D}}$ . A single epoch of the $\\mathsf{A B L Q}_{\\mathcal{D}}$ mechanism corresponds to a Gaussian mechanism with noise scale $\\sigma$ . And thus, $E\\,:=\\,b T/n$ epochs of the $\\mathsf{A B L Q}_{\\mathcal{D}}$ mechanism corresponds to an $E$ -fold composition of the Gauss\u221aian mechanism, which is privacy-wise equivalent to a Gaussian mechanism with noise scale $\\sigma/\\sqrt{E}$ [Dong et al., 2019, Corollary 3.3]. Thus, a closed-form expression for $\\delta_{D}(\\varepsilon)$ exists via the dominating pair $\\begin{array}{r}{(P_{\\mathcal{D}}=\\mathcal{N}(1,\\frac{\\sigma^{2}}{E}),Q_{\\mathcal{D}}=\\mathcal{N}(0,\\frac{\\sigma^{2}}{E}))}\\end{array}$ . ", "page_idx": 4}, {"type": "text", "text": "Theorem 3.1 (Balle and Wang [2018, Theorem 8]). For all $\\sigma>0,\\,\\varepsilon\\geq0$ , and valid $n,\\,b,\\,T_{\\ast}$ , it holds that ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\delta_{\\mathcal{D}}(\\varepsilon)=\\Phi\\left(-\\sigma^{\\prime}\\varepsilon+\\frac{1}{2\\sigma^{\\prime}}\\right)-e^{\\varepsilon}\\Phi\\left(-\\sigma^{\\prime}\\varepsilon-\\frac{1}{2\\sigma^{\\prime}}\\right),\\qquad w h e r e\\;\\sigma^{\\prime}=\\frac{\\sigma}{\\sqrt{E}},}\\end{array}\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "and $\\Phi(\\cdot)$ is the cumulative density function $(C D F)$ of the standard normal random variable ${\\mathcal{N}}(0,1)$ . ", "page_idx": 4}, {"type": "text", "text": "Privacy analysis of $\\mathsf{\\pmb{A}\\pmb{B}\\pmb{L}\\mathbf{Q}_{\\mathcal{P}}}$ . First, let us consider the case of Poisson subsampling without truncation, namely $B\\;=\\;\\infty$ . Zhu et al. [2022] showed2 that the tightly dominating pair for a single step of $\\mathsf{A B L Q}_{\\mathcal{P}}$ , a Poisson sub-sampled Gaussian mechanism, is given by the pair $\\left[U\\right.=$ $(1-q){\\mathcal{N}}(0,\\sigma^{2})+q{\\mathcal{N}}(1,\\sigma^{2}),V={\\mathcal{N}}(0,\\sigma^{2}))$ , where $q$ is the sub-sampling probability of each example, namely $q\\,=\\,b/n$ . Since $\\mathsf{A B L Q}_{\\mathcal{P}}$ is a $T$ -fold composition of this Poisson subsampled Gaussian mechanism, it follows that $(P_{\\mathcal{P}}:=U^{\\otimes T},Q_{\\mathcal{P}}:=V^{\\hat{\\otimes}T})\\equiv\\mathsf{A B L Q}_{\\mathcal{P}}$ . ", "page_idx": 5}, {"type": "text", "text": "A finite value of $B$ however changes the mechanism slightly. In order to handle this, we use the following proposition, where $d_{\\mathrm{TV}}(\\bar{P},P^{\\prime})$ denotes the statistical distance between $P$ and $P^{\\prime}$ . ", "page_idx": 5}, {"type": "text", "text": "Proposition 3.2. For distributions $P,P^{\\prime},Q,Q^{\\prime}$ such that $d_{\\mathrm{TV}}(P,P^{\\prime}),d_{\\mathrm{TV}}(Q,Q^{\\prime})~\\leq~\\eta,$ and $D_{e^{\\varepsilon}}\\bar{(}P^{\\prime}\\|Q^{\\prime})\\leq\\delta_{\\mathrm{r}}$ , then $D_{e^{\\varepsilon}}(P\\|Q)\\le\\delta+\\eta(1+e^{\\varepsilon})$ . ", "page_idx": 5}, {"type": "text", "text": "Proof. For any event $\\Gamma$ we have that ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\begin{array}{r}{^{\\circ}(\\Gamma)\\ \\stackrel{(\\mathrm{i})}{\\leq}\\ P^{\\prime}(\\Gamma)+\\eta\\ \\stackrel{(\\mathrm{ii})}{\\leq}\\ e^{\\varepsilon}Q^{\\prime}(\\Gamma)+\\delta+\\eta\\ \\stackrel{(\\mathrm{ii})}{\\leq}\\ e^{\\varepsilon}(Q(\\Gamma)+\\eta)+\\delta+\\eta\\ =\\ e^{\\varepsilon}Q(\\Gamma)+\\delta+\\eta(1+e^{\\varepsilon}),}\\end{array}\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "where (i) follows from $d_{\\mathrm{TV}}(P,P^{\\prime})\\leq\\eta$ , (ii) follows from $D_{e^{\\varepsilon}}(P^{\\prime}\\|Q^{\\prime})\\leq\\delta$ and (iii) follows from $d_{\\mathrm{TV}}(Q,Q^{\\prime})\\leq\\eta$ . Thus, we get that $D_{e^{\\varepsilon}}(P\\|Q)\\le\\delta+\\eta(1+e^{\\varepsilon})$ . \u53e3 ", "page_idx": 5}, {"type": "text", "text": "The batch size $|S_{t}|$ before truncation in $\\mathcal{P}_{b,B,T}$ is distributed as the binomial distribution $\\operatorname{Bin}(n,b/n)$ , and thus, by a union bound over the events that the sampled batch size $|S_{t}|>B$ at any step, it follows that for any input dataset $\\textbf{\\em x}$ , ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\begin{array}{r}{d_{\\mathrm{TV}}(\\mathsf{A B L Q}_{\\mathcal{P}_{b,B,T}}(\\pmb{x}),\\mathsf{A B L Q}_{\\mathcal{P}_{b,\\infty,T}}(\\pmb{x}))\\leq T\\cdot\\Psi(n,b,B),}\\end{array}\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "where $\\Psi(n,b,B):=\\operatorname*{Pr}_{r\\sim\\mathrm{Bin}(n,b/n)}[r>B]$ . Applying Proposition 3.2 we get ", "page_idx": 5}, {"type": "text", "text": "Theorem 3.3. For all $\\sigma>0,\\,\\varepsilon\\geq0,$ , and integers $b$ , $n\\geq b$ , $B\\geq b,T,$ , it holds that ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\delta_{\\mathcal P}(\\varepsilon)\\leq\\operatorname*{max}\\{D_{e^{\\varepsilon}}(P_{\\mathcal P}\\|Q_{\\mathcal P}),D_{e^{\\varepsilon}}(Q_{\\mathcal P}\\|P_{\\mathcal P})\\}+T\\cdot(1+e^{\\varepsilon})\\cdot\\Psi(n,b,B).\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "While the hockey stick divergences $D_{e^{\\varepsilon}}(P_{\\mathcal{P}}\\|Q_{\\mathcal{P}})$ and $D_{e^{\\varepsilon}}(Q_{\\mathcal{P}}\\|P_{\\mathcal{P}})$ do not have closed-form expressions, upper bounds on these can be obtained using privacy accountants based on the methods of R\u00e9nyi DP (RDP) [Mironov, 2017] and privacy loss distributions $(P L D)$ [Meiser and Mohammadi, 2018, Sommer et al., 2019]; the latter admits numerically accurate algorithms [Koskela et al., 2020, Gopi et al., 2021, Ghazi et al., 2022, Doroshenko et al., 2022], with multiple open-source implementations [Prediger and Koskela, 2020, Google\u2019s DP Library., 2020, Microsoft., 2021]. ", "page_idx": 5}, {"type": "text", "text": "Note that $\\Psi(n,b,B)$ can be made arbitrarily small by increasing $B$ , which affects the computation cost. In particular, given a target privacy parameter $(\\varepsilon,\\delta)$ , we can, for example, work backwards to first choose $B$ such that $\\Psi(n,\\bar{b},\\bar{B^{\\big)}}\\cdot T\\cdot(\\bar{1}+e^{\\varepsilon})\\leq\\mathrm{i}0^{-5}\\cdot\\delta,$ and then choose the noise scale $\\sigma$ such that max $\\begin{array}{r}{\\because\\{D_{e^{\\varepsilon}}(P_{\\mathcal P}\\|Q_{\\mathcal P}),D_{e^{\\varepsilon}}(Q_{\\mathcal P}\\|P_{\\mathcal P})\\}\\leq(1-10^{-5})\\cdot\\delta}\\end{array}$ , using aforementioned privacy accounting libraries. Notice that our use of Proposition 3.2 is likely not the optimal approach to account for the batch truncation. We do not optimize this further because we find that this approach already provides very minimal degradation to the choice of $\\sigma$ for a modest value of $B$ relative to $b$ . A more careful analysis could at best result in a slightly smaller $B$ , which we do not consider as significant; see Figures 3 and 4 for more details. ", "page_idx": 5}, {"type": "text", "text": "Privacy analysis of $\\mathsf{A B L Q}_{\\mathcal{S}^{\\circ}}$ . Obtaining the exact privacy guarantee for $\\mathsf{A B L Q}_{\\mathcal{S}}$ has been an open problem in the literature. Our starting point is the approach introduced by Chua et al. [2024] to prove a lower bound in the single epoch setting. Let the input space be $\\mathcal{X}=[-1,1]$ , the (non-adaptive) query method $\\boldsymbol{\\mathcal{A}}$ that produces the query $\\bar{\\psi}_{t}(x)=x$ , and consider the adjacent datasets: ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathbf x=\\left(x_{1}=-1,\\ldots,x_{n-1}=-1,x_{n}=1\\right)\\quad\\mathrm{and}\\quad\\mathbf x^{\\prime}=\\left(x_{1}=-1,\\ldots,x_{n-1}=-1,x_{n}=\\perp\\right).}\\end{array}\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "Recall that the number of epochs is $E:=b T/n$ and the number of steps per epoch is $S:=n/b$ . By considering the same setting, it is easy to see that the distributions $\\bar{U}\\,=\\,\\mathsf{\\bar{A}B L Q}_{S^{\\circ}}(\\pmb{x})$ and $\\dot{V}=\\mathsf{A B L Q}_{S^{\\circ}}(\\pmb{x}^{\\prime})$ are given as: ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\begin{array}{r}{U\\;=\\;\\sum_{s=1}^{S}\\frac{1}{S}\\cdot\\mathcal{N}(-b\\cdot\\mathbf{1}+2f_{s},\\sigma^{2}I_{T}),\\quad\\mathrm{and}\\quad V\\;=\\;\\sum_{s=1}^{S}\\frac{1}{S}\\cdot\\mathcal{N}(-b\\cdot\\mathbf{1}+f_{s},\\sigma^{2}I_{T}),}\\end{array}\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "2Also implicit in prior work [Koskela et al., 2020]. ", "page_idx": 5}, {"type": "text", "text": "where $f_{s}\\,\\in\\,\\mathbb{R}^{T}$ is the sum of basis vectors \u2113E=\u221201 e\u2113S+s, and 1 denotes the all-1\u2019s vector in RT . Basically, $f_{s}$ is the indicator vector encodin g the batches that the differing example gets assigned to; in persistent shuffilng, an example gets assigned to the $s$ th batch within each epoch for a random $s\\in\\{1,\\ldots,S\\}$ . Shifting the distributions by ${\\boldsymbol{b}}\\cdot\\mathbf{1}$ and projecting to the span of $\\{f_{s}:s\\in[S]\\}$ does not change the hockey stick divergence $D_{e^{\\varepsilon}}(U\\|V)$ , hence we might as well consider the pair ", "page_idx": 6}, {"type": "equation", "text": "$$\n\\begin{array}{r}{U^{\\prime}:=\\;\\sum_{s=1}^{S}\\frac{1}{S}\\cdot\\mathcal{N}(2\\sqrt{E}e_{s},\\sigma^{2}I_{S})\\quad\\mathrm{and}\\quad V^{\\prime}:=\\;\\sum_{s=1}^{S}\\frac{1}{S}\\cdot\\mathcal{N}(\\sqrt{E}e_{s},\\sigma^{2}I_{S}).}\\end{array}\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "By scaling down the distributions by $\\sqrt{E}$ on all coordinates we arrive at the following pair: ", "page_idx": 6}, {"type": "equation", "text": "$$\n\\begin{array}{r}{P_{\\mathcal{S}^{\\diamond}}:=\\ \\sum_{s=1}^{S}\\frac{1}{S}\\cdot\\mathcal{N}(2e_{s},\\frac{\\sigma^{2}}{E}I)\\quad\\mathrm{and}\\quad Q_{\\mathcal{S}^{\\diamond}}:=\\ \\sum_{s=1}^{S}\\frac{1}{S}\\cdot\\mathcal{N}(e_{s},\\frac{\\sigma^{2}}{E}I).}\\end{array}\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "The pa\u221air $(P_{S^{\\circ}},Q_{S^{\\circ}})$ is essentially same as the pair obtained by Chua et al. [2024], with $\\sigma$ replaced by $\\sigma/\\sqrt{E}$ , and we get the following: ", "page_idx": 6}, {"type": "text", "text": "Proposition 3.4. For all $\\sigma>0$ , $\\varepsilon\\geq0$ and all valid $n,\\,b,\\,T$ , it holds that ", "page_idx": 6}, {"type": "equation", "text": "$$\n\\delta_{S^{\\diamond}}(\\varepsilon)\\geq\\operatorname*{max}\\{D_{e^{\\varepsilon}}(P_{S^{\\diamond}}\\|Q_{S^{\\diamond}}),D_{e^{\\varepsilon}}(Q_{S^{\\diamond}}\\|P_{S^{\\diamond}})\\}.\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "Following Chua et al. [2024], we can obtain a lower bound as $\\delta{s}\\circ(\\varepsilon)\\geq P_{S^{\\circ}}(\\Gamma)-e^{\\varepsilon}Q_{S^{\\circ}}(\\Gamma)$ for any $\\Gamma$ , and in particular, we consider events of the form $\\Gamma_{C}:=\\{w\\in\\mathbb{R}^{S}:\\operatorname*{max}_{s}w_{s}>C\\}$ for various values of $C$ . $P_{S^{\\circ}}(\\Gamma_{C})$ and $Q_{S^{\\circ}}(\\Gamma_{C})$ are efficient to compute as ", "page_idx": 6}, {"type": "equation", "text": "$$\n\\begin{array}{r}{^{\\circ}\\!s\\circ(\\Gamma_{C})=1-\\Phi\\left(\\frac{C-2}{\\sigma/\\sqrt{E}}\\right)\\cdot\\Phi\\left(\\frac{C}{\\sigma/\\sqrt{E}}\\right)^{S-1}\\quad\\mathrm{and}\\quad Q_{S^{\\circ}}(\\Gamma_{C})=1-\\Phi\\left(\\frac{C-1}{\\sigma/\\sqrt{E}}\\right)\\cdot\\Phi\\left(\\frac{C}{\\sigma/\\sqrt{E}}\\right)^{S-1}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "Thus, using Proposition 3.4, we get that ", "page_idx": 6}, {"type": "text", "text": "Theorem 3.5. For all $\\sigma>0,\\,\\varepsilon\\geq0,$ , and all valid $n,\\,b,\\,T_{\\ast}$ , it holds that ", "page_idx": 6}, {"type": "equation", "text": "$$\n\\delta_{S^{\\circ}}(\\varepsilon)\\;\\geq\\;\\operatorname*{sup}_{C\\in\\mathbb{R}}P_{S^{\\circ}}(\\Gamma_{C})-Q_{S^{\\circ}}(\\Gamma_{C}).\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "Privacy analysis of $\\pmb{\\mathsf{A B L Q}}_{\\pmb{S}^{\\circ}}$ . Our starting point for providing a lower bound on $\\delta_{S^{\\odot}}(\\varepsilon)$ is the pair $(P_{S},Q_{S})$ as defined below that provides a lower bound in the case of a single epoch. ", "page_idx": 6}, {"type": "equation", "text": "$$\n\\begin{array}{r}{P_{\\ensuremath{\\mathcal{S}}}:=\\ \\sum_{s=1}^{S}\\frac{1}{S}\\cdot\\ensuremath{\\mathcal{N}}(2e_{s},\\sigma^{2}I)\\quad\\mathrm{and}\\quad Q_{\\ensuremath{\\mathcal{S}}}:=\\ \\sum_{s=1}^{S}\\frac{1}{S}\\cdot\\ensuremath{\\mathcal{N}}(e_{s},\\sigma^{2}I).}\\end{array}\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "$\\mathsf{A B L Q}_{S^{\\odot}}$ is an $E$ -fold composition of the single-epoch mechanism. Hence by composition of dominating pairs, it follows that $\\delta_{\\mathit{S}^{\\odot}}(\\varepsilon)\\geq\\operatorname*{max}\\{D_{e^{\\varepsilon}}(P_{\\mathit{S}^{\\odot}}\\|Q_{\\mathit{S}^{\\odot}}),D_{e^{\\varepsilon}}(Q_{\\mathit{S}^{\\odot}}\\|P_{\\mathit{S}^{\\odot}})\\}$ , where $P_{S^{\\zeta}}\\;:=\\;P_{S}^{\\otimes E}$ and ${\\cal Q}_{S^{\\odot}}\\;\\;:=\\;\\;{\\cal Q}_{S}^{\\otimes E}$ . However, it is tricky to directly identify an event $\\Gamma$ for which the lower bound $P_{S^{\\odot}}(\\Gamma)-\\bar{e}^{\\varepsilon}Q_{S^{\\odot}}(\\Gamma)$ is non-trivial and $P_{S^{\\mathrm{()}}}(\\Gamma)$ , $Q_{S^{(\\mathrm{{T}})}}(\\Gamma)$ are easy to compute. So in order to lower bound $D_{e^{\\varepsilon}}(P_{S^{\\vee}}\\|Q_{S^{\\odot}})$ , below we construct a pair $(\\tilde{P}_{S},\\tilde{Q}_{S})$ of discrete distributions such that $(P_{\\cal S},Q_{\\cal S})\\succcurlyeq(\\tilde{P}_{\\cal S},\\tilde{Q}_{\\cal S})$ and thus $(P_{S^{\\odot}},Q_{S^{\\odot}})\\succcurlyeq(\\Tilde{P}_{S}^{\\otimes E},\\Tilde{Q}_{S}^{\\otimes E})$ . ", "page_idx": 6}, {"type": "text", "text": "For probability measures $P$ and $Q$ over a measurable space $\\Omega$ , and a finite partition3 $\\textit{g}=$ $(G_{1},\\bar{.}..,G_{m})$ of $\\Omega$ , we can consider the discrete distributions $P^{\\mathcal{G}}$ and $Q^{\\mathcal{G}}$ defined over $\\{1,\\ldots,m\\}$ such that $P^{\\mathcal{G}}(i)=P(G_{i})$ and $Q^{\\mathcal{G}}(i)=Q(G_{i})$ . The post-processing property of DP implies: ", "page_idx": 6}, {"type": "text", "text": "Proposition 3.6 (DP Post-processing [Dwork and Roth, 2014]). For all partitions $\\mathcal{E}$ of $\\Omega$ , it holds that $\\left(P,Q\\right)\\succcurlyeq\\left(P^{\\mathcal{E}},Q^{\\mathcal{E}}\\right)$ . ", "page_idx": 6}, {"type": "text", "text": "We construct the pair $(\\tilde{P}_{S},\\tilde{Q}_{S})$ by instantiating Proposition 3.6 with the set $\\begin{array}{r l}{\\mathcal{G}}&{{}=}\\end{array}$ $\\{G_{0},G_{1},\\dotsc,G_{m+1}\\}$ parameterized by a sequence $C_{1}<\\cdot\\cdot<C_{m}$ of values defined as follows: $\\tilde{G}_{0}:=\\{w\\in\\mathbb{R}^{S}:\\operatorname*{max}_{s}w_{s}\\leq C_{1}\\}$ , $G_{i}:=\\{\\bar{w}\\in\\mathbb{R}^{S}:C_{i}<\\operatorname*{max}_{s\\_}w_{s}\\leq C_{i+1}\\}$ for $1\\leq i\\leq m$ and $E_{m+1}:=\\{w\\in\\mathbb{R}^{S}:C_{m}<\\operatorname*{max}_{s}w_{s}\\}$ ; in other words, $G_{0}=\\mathbb{R}^{S}\\setminus\\Gamma_{C_{1}}$ , $G_{i}=\\Gamma_{C_{i}}\\setminus\\Gamma_{C_{i+1}}$ for $1\\leq i\\leq m$ and $G_{m+1}=\\Gamma_{C_{m}}$ . ", "page_idx": 6}, {"type": "text", "text": "Theorem 3.7. For all $\\sigma>0,\\,\\varepsilon\\geq0$ , all valid $n,\\,b,\\,T$ , and any finite sequence $C_{1},\\ldots,C_{m}$ of values used to define $\\tilde{P}_{S}$ , $\\tilde{Q}_{S}$ as above, it holds that ", "page_idx": 6}, {"type": "equation", "text": "$$\n\\delta_{{\\cal S}^{\\odot}}(\\varepsilon)\\;\\geq\\;\\operatorname*{max}\\{D_{e^{\\varepsilon}}(\\tilde{P}_{\\cal S}^{\\otimes E}\\|\\tilde{Q}_{\\cal S}^{\\otimes E}),D_{e^{\\varepsilon}}(\\tilde{Q}_{\\cal S}^{\\otimes E}\\|\\tilde{P}_{\\cal S}^{\\otimes E})\\}.\n$$", "text_format": "latex", "page_idx": 6}, {"type": "image", "img_path": "6gMnj9oc6d/tmp/39a95d4f00ed71c852741b05743dd77e7a907caca75a8cce8d6f76c982ed87b5.jpg", "img_caption": ["Figure 2: Visualization of the massively parallel computation approach for Poisson subsampling at scale. Consider 6 records $x_{1},\\ldots,x_{6}$ sub-sampled into 4 batches with a maximum batch size of $B=2$ . The Map operation adds a \u201cweight\u201d parameter of 1 to all examples, and samples indices of batches to which each example will belong. The Reduce operation groups by the batch indices. The final Map operation truncates batches with more than $B$ examples (e.g., batches 1 and 3 above), and pads dummy examples with weight 0 in batches with fewer than $B$ examples (e.g., batch 4 above). "], "img_footnote": [], "page_idx": 7}, {"type": "text", "text": "We use the dp_accounting library [Google\u2019s DP Library., 2020] to numerically compute a lower bound on the quantity above, using PLD. In particular, we choose $C_{1}$ and $C_{m}$ such that $\\mathbf{\\bar{\\rho}}_{P_{S}}(G_{0})$ and $P_{S}(G_{m+1})$ are sufficiently small and choose other $C_{i}$ \u2019s to get a sufficiently fine discretization of the interval between $C_{1}$ and $\\dot{C}_{m}$ .4 ", "page_idx": 7}, {"type": "text", "text": "An illustration of these accounting methods is presented in Figure 3, which demonstrates the significant gap where the optimal $\\sigma$ for dynamic/persistent shuffilng is significantly larger than compared to Poisson subsampling, even when using an optimistic estimate for shuffilng as above. We provide the implementation of our privacy accounting methods described above in an iPython notebook5 hosted on Google Colab, executable using the freely available Python CPU runtime. ", "page_idx": 7}, {"type": "text", "text": "4 Experiments ", "text_level": 1, "page_idx": 7}, {"type": "text", "text": "We compare DP-SGD using the following batch sampling algorithms at corresponding noise scales: ", "page_idx": 7}, {"type": "text", "text": "\u2022 Deterministic batches (using nearly exact value of $\\sigma_{\\mathscr D}\\big(\\varepsilon,\\delta\\big)$ via Theorem 3.1), \u2022 Truncated Poisson subsampled batches (using upper bound on $\\sigma_{\\mathscr P}\\mathopen{}\\mathclose\\bgroup\\left(\\varepsilon,\\delta\\aftergroup\\egroup\\right)$ via Theorem 3.3), \u2022 Persistent shuffled batches (using lower bound on $\\sigma_{S^{\\circ}}(\\varepsilon,\\delta)$ via Theorem 3.5), and \u2022 Dynamic shuffled batches (using lower bound on $\\sigma_{S^{\\odot}}(\\varepsilon,\\delta)$ via Theorem 3.7). ", "page_idx": 7}, {"type": "text", "text": "As a comparison, we also evaluate DP-SGD with dynamic shuffled batches, but using noise that is an upper bound on $\\sigma_{\\mathscr P}\\mathopen{}\\mathclose\\bgroup\\left(\\varepsilon,\\delta\\aftergroup\\egroup\\right)$ (with no truncation, i.e. $B=\\infty.$ ), to capture the incorrect, but commonly employed approach in practice. Finally, in order to understand the impact of using different batch sampling to model training in isolation, we compare models trained with SGD under truncated Poisson subsampling, and dynamic and persistent shuffling without any clipping or noise. We use massively parallel computation (Map-Reduce operations [Dean and Ghemawat, 2004]) to generate batches with truncated Poisson subsampling in a scalable manner as visualized in Figure 2; the details, with a beam pipeline implementation, is provided in Appendix A. ", "page_idx": 7}, {"type": "image", "img_path": "6gMnj9oc6d/tmp/ae4bfc1212c0a425de9b968873c86be7ea26b7cee3e80229a6dcb174b68b88dc.jpg", "img_caption": ["Figure 3: AUC (left) and bounds on $\\sigma_{B}$ values (middle) for $\\varepsilon=5,\\delta=2.7\\cdot10^{-8}$ and using 1 epoch (top) and 5 epochs (bottom) of training on a linear-log scale; AUC (right) is with non-private training. "], "img_footnote": [], "page_idx": 8}, {"type": "text", "text": "We run our experiments on the Criteo Display Ads pCTR Dataset [Jean-Baptiste Tien, 2014], which contains around 46 million examples from a week of Criteo ads traffic. Each example has 13 integer features and 26 categorical features, and the objective is to predict the probability of clicking on an ad given these features. We use the labeled training set from the dataset, split chronologically into a $80\\%/10\\%/10\\%$ partition of train/validation/test sets. We use the binary cross entropy loss and report the AUC on the labeled test split, averaged over three runs with different random seeds. These are plotted with error bars indicating a single standard deviation. We include more details about the model architectures and training in Appendix B. ", "page_idx": 8}, {"type": "text", "text": "We run experiments varying the (expected) batch size from 1 024 to 262 144, for both private training with $(\\varepsilon=\\bar{5},\\delta=2.7\\cdot\\dot{10}^{-\\bar{8}})$ and non-private training and with 1 or 5 epochs. We plot the results in Figure 3. As mostly expected, we observe that the model utility generally improves with smaller $\\sigma$ . Truncated Poisson subsampling performs similarly to dynamic shuffling for the same value of $\\sigma$ , although it performs worse for non-private training. The latter could be attributed to the fact that when using truncated Poisson subsampling, a substantial fraction6 of examples are never seen in the training with high probability. However, this does not appear to significantly affect the private training model utility for the range of parameters that we consider, since we observe that truncated Poisson subsampling behaves similarly to dynamic shuffling with noise scale of $\\sigma_{\\mathscr P}\\mathopen{}\\mathclose\\bgroup\\left(\\varepsilon,\\delta\\aftergroup\\egroup\\right)$ (the values of $\\sigma$ for $\\;^{;}\\mathcal{P}^{\\;^{,}}$ and \u201c $\\partial^{\\breve{\\zeta}})$ ( $\\mathcal{P}$ accounting)\u201d visually overlap in Figure 3; the values for $\\mathcal{P}$ are only negligibly larger, since it accounts for truncation). Truncated Poisson subsampling performs better when compared to shuffling when the latter using our lower bound on $\\sigma_{S^{\\zeta}}(\\varepsilon,\\delta)$ , which suggests that shuffling with correct accounting (that is, with potentially even larger $\\sigma$ ) would only perform worse. ", "page_idx": 8}, {"type": "text", "text": "We also run experiments with a fixed batch size 65 536 and varying $\\varepsilon$ from 1 to 256, fixing $\\delta=$ $2.7\\cdot10^{-8}$ . We plot the results and the corresponding $\\sigma$ values in Figure 4. We again observe that shuffilng (with our lower bound accounting) performs worse than truncated Poisson subsampling in the high privacy (low $\\varepsilon$ ) regime, but performs slightly better in the low privacy (high $\\varepsilon$ ) regime (this is because at large $\\varepsilon$ the noise required under Poisson subsampling is in fact larger than that under shuffilng). Moreover, we observe that shuffilng performs similarly to truncated Poisson subsampling when we use similar value of $\\sigma$ , consistent with our observations from Figure 3. ", "page_idx": 8}, {"type": "text", "text": "Finally, as a comparison, we compute the upper bounds on $\\sigma_{S}(\\varepsilon,\\delta)$ via the privacy amplification by shuffling bounds by Feldman et al. [2021]. We find that these bounds tend to be vacuous in many regime of parameters, namely they are no better than $\\sigma_{\\mathscr D}(\\varepsilon,\\delta)$ , which is clearly an upper bound on $\\bar{\\sigma_{S}}\\bar{(\\varepsilon,\\delta)}$ . Details are provided in Appendix C. ", "page_idx": 8}, {"type": "image", "img_path": "6gMnj9oc6d/tmp/7439085cbf7ecbe35f1dd3782fd60daf8f96f00deb2221058607f26271da1a2d.jpg", "img_caption": ["Figure 4: AUC (left) and $\\sigma$ values (right) with varying $\\varepsilon$ , fixing $\\delta=2.7\\cdot10^{-8}$ and using (top) 1 epoch and (bottom) 5 epochs of training. $\\sigma$ is in log scale to highlight the differences at high $\\varepsilon$ . "], "img_footnote": [], "page_idx": 9}, {"type": "text", "text": "5 Conclusion ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "We provide new lower bounds on the privacy analysis of Adaptive Batch Linear Query mechanisms, under persistent and dynamic shuffilng batch samplers, extending the prior work of Chua et al. [2024] that analyzed the single epoch case. Our lower bound method continues to identify separations in the multi-epoch setting, showing that the amplification guarantees due to even dynamic shuffling can be significantly limited compared to the amplification due to Poisson subsampling in regimes of practical interest. ", "page_idx": 9}, {"type": "text", "text": "We also provide evaluation of DP-SGD with various batch samplers with the corresponding privacy accounting, and propose an approach for implementing Poisson subsampling at scale using massively parallel computation. Our findings suggest that with provable privacy guarantees on model training, Poisson-subsampling-based DP-SGD has better privacy-utility trade-off than shuffling-based DPSGD in many practical parameter regimes of interest, and in fact, essentially match the utility of shuffling-based DP-SGD at the same noise level. Thus, we consider Poisson-subsampling-based DP-SGD as a viable approach for implementing DP-SGD at scale, given the lower bound on the privacy analysis when using shuffling. ", "page_idx": 9}, {"type": "text", "text": "Several interesting directions remain to be investigated. Firstly, our technique only provides a lower bound on the privacy guarantee when using persistent / dynamic shuffled batches. While some privacy amplification results are known [Feldman et al., 2021, 2023], providing a tight (non-vacuous) upper bound on the privacy guarantee in these settings remains an open challenge. This can be important in regimes where shuffling does provide better privacy guarantees than Poisson subsampling. ", "page_idx": 9}, {"type": "text", "text": "Another important point to note is that persistent and dynamic shuffling are not the only forms of shuffling used in practice. For example, methods such as tf.data.Dataset.shuffle or torchdata.datapipes.iter.Shuffler provide a uniformly random shuffle, only when the size of its \u201cbuffer\u201d is larger than the dataset. Otherwise, for buffer size $b$ , it returns a random record among the first $b$ records, and immediately replaces it with the next record $(b+1)\\mathrm{th}$ in this case), and repeats this process, which leads to an asymmetric form of shuffling. Such batch samplers merit more careful privacy analysis. ", "page_idx": 9}, {"type": "text", "text": "Acknowledgements ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "We would like to thank Charlie Harrison and Ethan Leeman for valuable discussions, as well as anonymous reviewers for their thoughtful feedback that helped improve the quality of the paper. ", "page_idx": 9}, {"type": "text", "text": "References ", "text_level": 1, "page_idx": 10}, {"type": "text", "text": "Mart\u00edn Abadi, Andy Chu, Ian J. Goodfellow, H. Brendan McMahan, Ilya Mironov, Kunal Talwar, and Li Zhang. Deep learning with differential privacy. In CCS, pages 308\u2013318, 2016. ", "page_idx": 10}, {"type": "text", "text": "Jason M. Altschuler and Kunal Talwar. Privacy of noisy stochastic gradient descent: More iterations without more privacy loss. In NeurIPS, 2022. ", "page_idx": 10}, {"type": "text", "text": "Rohan Anil, Badih Ghazi, Vineet Gupta, Ravi Kumar, and Pasin Manurangsi. Large-scale differentially private BERT. In EMNLP (Findings), pages 6481\u20136491, 2022. ", "page_idx": 10}, {"type": "text", "text": "Meenatchi Sundaram Muthu Selva Annamalai. It\u2019s our loss: No privacy amplification for hidden state DP-SGD with non-convex loss. CoRR, abs/2407.06496, 2024. ", "page_idx": 10}, {"type": "text", "text": "Apache Beam. URL https://beam.apache.org/. ", "page_idx": 10}, {"type": "text", "text": "Apache Flink. URL https://flink.apache.org/. ", "page_idx": 10}, {"type": "text", "text": "Apache Spark. URL https://spark.apache.org/. ", "page_idx": 10}, {"type": "text", "text": "Borja Balle and Yu-Xiang Wang. Improving the gaussian mechanism for differential privacy: Analytical calibration and optimal denoising. In ICML, pages 403\u2013412, 2018. ", "page_idx": 10}, {"type": "text", "text": "Borja Balle, Leonard Berrada, Soham De, Sahra Ghalebikesabi, Jamie Hayes, Aneesh Pappu, Samuel L Smith, and Robert Stanforth. JAX-Privacy: Algorithms for privacy-preserving machine learning in JAX, 2022. URL http://github.com/google-deepmind/jax_privacy. ", "page_idx": 10}, {"type": "text", "text": "Zhiqi Bu, Jialin Mao, and Shiyun Xu. Scalable and efficient training of large convolutional neural networks with differential privacy. In NeurIPS, pages 38305\u201338318, 2022. ", "page_idx": 10}, {"type": "text", "text": "Dingfan Chen, Tribhuvanesh Orekondy, and Mario Fritz. GS-WGAN: A gradient-sanitized approach for learning differentially private generators. In NeurIPS, pages 12673\u201312684, 2020. ", "page_idx": 10}, {"type": "text", "text": "Lynn Chua, Badih Ghazi, Pritish Kamath, Ravi Kumar, Pasin Manurangsi, Amer Sinha, and Chiyuan Zhang. How Private is DP-SGD? In ICML, 2024. ", "page_idx": 10}, {"type": "text", "text": "Soham De, Leonard Berrada, Jamie Hayes, Samuel L. Smith, and Borja Balle. Unlocking highaccuracy differentially private image classification through scale. CoRR, abs/2204.13650, 2022. ", "page_idx": 10}, {"type": "text", "text": "Jeffrey Dean and Sanjay Ghemawat. Mapreduce: Simplified data processing on large clusters. In OSDI, pages 137\u2013150, 2004. ", "page_idx": 10}, {"type": "text", "text": "Tim Dockhorn, Tianshi Cao, Arash Vahdat, and Karsten Kreis. Differentially private diffusion models. TMLR, 2023. ", "page_idx": 10}, {"type": "text", "text": "Jinshuo Dong, Aaron Roth, and Weijie J. Su. Gaussian differential privacy. CoRR, abs/1905.02383, 2019. ", "page_idx": 10}, {"type": "text", "text": "Vadym Doroshenko, Badih Ghazi, Pritish Kamath, Ravi Kumar, and Pasin Manurangsi. Connect the dots: Tighter discrete approximations of privacy loss distributions. PoPETS, 2022(4):552\u2013570, 2022. ", "page_idx": 10}, {"type": "text", "text": "Cynthia Dwork and Aaron Roth. The algorithmic foundations of differential privacy. Found. Trends Theor. Comput. Sci., 9(3-4):211\u2013407, 2014. ", "page_idx": 10}, {"type": "text", "text": "Vitaly Feldman, Ilya Mironov, Kunal Talwar, and Abhradeep Thakurta. Privacy amplification by iteration. In FOCS, pages 521\u2013532, 2018. ", "page_idx": 10}, {"type": "text", "text": "Vitaly Feldman, Audra McMillan, and Kunal Talwar. Hiding among the clones: A simple and nearly optimal analysis of privacy amplification by shuffling. In FOCS, pages 954\u2013964, 2021. ", "page_idx": 10}, {"type": "text", "text": "Vitaly Feldman, Audra McMillan, and Kunal Talwar. Stronger privacy amplification by shuffling for R\u00e9nyi and approximate differential privacy. In SODA, pages 4966\u20134981, 2023. ", "page_idx": 10}, {"type": "text", "text": "Badih Ghazi, Pritish Kamath, Ravi Kumar, and Pasin Manurangsi. Faster privacy accounting via evolving discretization. In ICML, pages 7470\u20137483, 2022. ", "page_idx": 10}, {"type": "text", "text": "Google Cloud Dataflow. URL https://cloud.google.com/dataflow. ", "page_idx": 11}, {"type": "text", "text": "Google Colab. URL https://colab.research.google.com/. ", "page_idx": 11}, {"type": "text", "text": "Google\u2019s DP Library. DP Accounting Library. https://github.com/google/ differential-privacy/tree/main/python/dp_accounting, 2020.   \nSivakanth Gopi, Yin Tat Lee, and Lukas Wutschitz. Numerical composition of differential privacy. In NeurIPS, pages 11631\u201311642, 2021.   \nJiyan He, Xuechen Li, Da Yu, Huishuai Zhang, Janardhan Kulkarni, Yin Tat Lee, Arturs Backurs, Nenghai Yu, and Jiang Bian. Exploring the limits of differentially private deep learning with group-wise clipping. arXiv preprint arXiv:2212.01539, 2022.   \nTimour Igamberdiev, Doan Nam Long Vu, Felix K\u00fcnnecke, Zhuo Yu, Jannik Holmer, and Ivan Habernal. DP-NMT: Scalable differentially-private machine translation. In EACL (Demonstrations), pages 94\u2013105, 2024.   \nOlivier Chapelle Jean-Baptiste Tien, joycenv. Display advertising challenge, 2014. URL https: //kaggle.com/competitions/criteo-display-ad-challenge.   \nPeter Kairouz, Brendan McMahan, Shuang Song, Om Thakkar, Abhradeep Thakurta, and Zheng Xu. Practical and private (deep) learning without sampling or shuffling. In ICML, pages 5213\u20135225, 2021.   \nAntti Koskela, Joonas J\u00e4lk\u00f6, and Antti Honkela. Computing tight differential privacy guarantees using FFT. In AISTATS, pages 2560\u20132569, 2020.   \nChristian Janos Lebeda, Matthew Regehr, and Gautam Kamath. Avoiding pitfalls for privacy accounting of subsampled mechanisms under composition. CoRR, abs/2405.20769, 2024.   \nSebastian Meiser and Esfandiar Mohammadi. Tight on budget? Tight bounds for $r$ -fold approximate differential privacy. In CCS, pages 247\u2013264, 2018.   \nMicrosoft. A fast algorithm to optimally compose privacy guarantees of differentially private (DP) mechanisms to arbitrary accuracy. https://github.com/microsoft/prv_accountant, 2021.   \nIlya Mironov. R\u00e9nyi differential privacy. In CSF, pages 263\u2013275, 2017.   \nNatalia Ponomareva, Hussein Hazimeh, Alex Kurakin, Zheng Xu, Carson Denison, H. Brendan McMahan, Sergei Vassilvitskii, Steve Chien, and Abhradeep Guha Thakurta. How to dp-fy ML: A practical guide to machine learning with differential privacy. JAIR, 77:1113\u20131201, 2023.   \nLukas Prediger and Antti Koskela. Code for computing tight guarantees for differential privacy. https://github.com/DPBayes/PLD-Accountant, 2020.   \nDavid M. Sommer, Sebastian Meiser, and Esfandiar Mohammadi. Privacy loss classes: The central limit theorem in differential privacy. PoPETS, 2019(2):245\u2013269, 2019.   \nXinyu Tang, Ashwinee Panda, Milad Nasr, Saeed Mahloujifar, and Prateek Mittal. Private fine-tuning of large language models with zeroth-order optimization. CoRR, abs/2401.04343, 2024.   \nTensorflow Privacy. URL https://www.tensorflow.org/responsible_ai/privacy/api_ docs/python/tf_privacy.   \nFlorian Tramer and Dan Boneh. Differentially private learning needs better features (or much more data). CoRR, abs/2011.11660, 2020.   \nAshkan Yousefpour, Igor Shilov, Alexandre Sablayrolles, Davide Testuggine, Karthik Prasad, Mani Malek, John Nguyen, Sayan Ghosh, Akash Bharadwaj, Jessica Zhao, Graham Cormode, and Ilya Mironov. Opacus: User-friendly differential privacy library in PyTorch. CoRR, abs/2109.12298, 2021.   \nYuqing Zhu, Jinshuo Dong, and Yu-Xiang Wang. Optimal accounting of differential privacy via characteristic function. In AISTATS, pages 4782\u20134817, 2022. ", "page_idx": 11}, {"type": "text", "text": "A Massively Parallel Implementation of Truncated Poisson Subsampling ", "text_level": 1, "page_idx": 12}, {"type": "text", "text": "We use massively parallel computation to generate batches with truncated Poisson subsampling in a scalable manner. Given the input parameters $b$ , $B,T,$ , and $n$ , we first compute the maximum batch size $B$ such that $\\Psi(n,b,B)\\cdot\\bar{T}\\cdot\\bar{(1+e^{\\varepsilon})}\\leq10^{-5}\\cdot\\delta$ . For each example in the input dataset, we generate a list of batches that the example would be in when sampled using Poisson subsampling. While a naive implementation would sample $T$ Bernoulli random variables with parameter $b/n$ , this can be made efficient by sampling the indices of the batches containing the examples directly, since the difference between two consecutive such indices is distributed as a geometric random variable with parameter $b/n$ . We then group the examples by the batches, and subsample each batch uniformly, without replacement, to obtain a batch of size at most $B$ . For batches with size smaller than $B$ , we pad the batch with examples such that every batch has size $B$ . In order to differentiate the padding examples from the non-padding examples, we add a weight to all the examples, where the non-padding examples have weight 1 and the padding examples have weight 0. During the training, we use a weighted loss function using these weights, such that the padding examples do not have any effect on the training loss. ", "page_idx": 12}, {"type": "text", "text": "We include a code snippet for implementing truncated Poisson subsampling using massively parallel computation. This is written using Apache beam [Apache Beam] in Python, which can be implemented on distributed platforms such as Apache Flink, Apache Spark, Google Cloud Dataflow. ", "page_idx": 12}, {"type": "text", "text": "import apache_beam as beam import numpy as np import tensorflow as tf ", "page_idx": 12}, {"type": "text", "text": "class PoissonSubsample(beam.PTransform): \"\"\"Generate batches of examples using poisson subsampling. Attributes: max_batch_size: Maximum batch size. num_batches: Number of batches. subsampling_probability: Probability of sampling each example in each batch. sample_size: Number of samples to sample at a time. def __init__( self, max_batch_size: int, num_batches: int, subsampling_probability: float, sample_size: int, ): self._max_batch_size $=$ max_batch_size self._num_batches $=$ num_batches self._subsampling_probability $=$ subsampling_probability self._sample_size $=$ sample_size self._rng $=$ np.random.default_rng() def get_batch_indices(self): \"\"\"Returns the indices of the batches that an example is in. Assuming that an example is sampled in each batch using poisson subsampling, return the list of indices of the batches that the example is in. \"\"\" largest_batch_index $=~0$ batch_indices $=$ np.array([]) if self._subsampling_probability $\\scriptstyle=\\;0\\;,\\;0$ : return batch_indices while largest_batch_index $<$ self._num_batches: # Sample batches using geometric distribution geometric_samples $=$ self._rng.geometric( p=self._subsampling_probability, size $=$ self._sample_size ", "page_idx": 12}, {"type": "text", "text": ") batch_indices $=$ np.concatenate( (batch_indices, largest_batch_index $^+$ np.cumsum(geometric_samples)) ) largest_batch_index $=$ batch_indices[-1] return batch_indices[batch_indices $<=$ self._num_batches] ", "page_idx": 13}, {"type": "text", "text": "def _add_padding(self, batch): \"\"\"Returns batch padded to max_batch_size with padding examples. Pads input batch to size max_batch_size by adding padding examples. The padding examples are specified by adding a weight to all the examples, where padding examples have weight 0 and non-padding examples have weight 1. Args: batch: A tuple of (batch_id, list of examples) \"\"\" batch_id, examples $=$ batch examples $=$ list(examples) if len(examples) $<$ self._max_batch_size: padding_example $=$ tf.train.Example() padding_example.CopyFrom(examples[0]) padding_example.features.feature['weight'].float_list.value[:] $=$ [0.0] examples.extend( [padding_example] $^*$ (self._max_batch_size - len(examples)) ) return (batch_id, examples)   \ndef expand(self, pcoll): def generate_batch_ids(example): # Convert to pairs consisting of (batch id, example) for batch_id in self.get_batch_indices(): yield (int(batch_id), example) def _add_weights(example): # Add weight with value 1 to indicate non-padding examples weighted_example $=$ tf.train.Example() weighted_example.CopyFrom(example) weighted_example.features.feature['weight'].float_list.value[:] $=$ [1.0] return weighted_example # Group elements into batches keyed by the batch id grouped_pcoll $=$ ( pcoll | 'Add weights' $>>$ beam.Map(_add_weights) | 'Key by batch id' $>>$ beam.FlatMap(generate_batch_ids) | 'Sample up to max_batch_size elements per batch' $>>$ beam.combiners.Sample.FixedSizePerKey(self._max_batch_size) | 'Add padding' $>>$ beam.Map(self._add_padding) ) return grouped_pcoll ", "page_idx": 13}, {"type": "text", "text": "B Training details ", "text_level": 1, "page_idx": 13}, {"type": "text", "text": "We use a neural network with five layers and $\\mathord{\\sim}78\\mathrm{M}$ parameters as the model. The first layer consists of feature transforms for each of the categorical and integer features. Categorical features are mapped into dense feature vectors using an embedding layer, where the embedding dimensions are fixed at 48. We apply a log transform for the remaining integer features, and concatenate all the features together. The next three layers are fully connected layers with 598 hidden units each and a ReLU activation function. The last layer consists of a fully connected layer which gives a scalar logit prediction. ", "page_idx": 13}, {"type": "text", "text": "We use the Adam or Adagrad optimizer with a base learning rate in $\\{0.0001,0.0005,0.001,0.005$ , $0.01,0.05,0.1,0.5,1\\}$ , which is scaled with a cosine decay, and we tune the norm bound ", "page_idx": 13}, {"type": "text", "text": "$C~\\in~\\{1,5,10,50\\}$ . For the experiments with varying batch sizes, we use batch sizes that are powers of 2 between 1 024 and 262 144, with corresponding maximum batch sizes $B$ in $\\{1\\,328,2\\,469,4\\,681,9\\,007,17\\,520,34\\,355,67\\,754,134\\,172,266\\,475\\}.$ For the experiments with varying $\\varepsilon$ , we vary $\\varepsilon$ as powers of 2 between 1 and 256, with batch size 65 536 and corresponding maximum batch sizes $B$ in $\\{67\\,642,67\\,667,67\\,725,67\\,841,68\\,059,68\\,449,69\\,106,70\\,156,\\bar{7}1\\,760\\}.$ . With these choices of the maximum batch sizes, the $\\sigma$ values for truncated Poisson subsampling are only slightly larger than without truncation, as we observe from the nearly overlapping curves in Figure 3 and Figure 4. The training is done using NVIDIA Tesla P100 GPUs, where each epoch of training takes 1-2 hours on a single GPU. ", "page_idx": 14}, {"type": "text", "text": "C Privacy Amplification by Shuffling ", "text_level": 1, "page_idx": 14}, {"type": "text", "text": "We evaluate the upper bounds on $\\sigma_{S}(\\varepsilon,\\delta)$ via privacy amplification by shuffling results of Feldman et al. [2021], as applied in the context of our experiments in Figure 3. In particular, their Proposition 5.3 states that if the unamplified (Gaussian) mechanism satisfies $(\\varepsilon_{0},\\delta_{0})$ -DP, then $\\mathsf{A B L Q}_{\\mathcal{S}}$ with $T$ steps (in a single epoch setting) will satisfy $(\\varepsilon,\\eta+O(e^{\\varepsilon}\\delta_{0}n)$ -DP for any $\\eta\\in[0,1]$ and ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\varepsilon=O\\left(\\left(1-e^{-\\varepsilon_{0}}\\right)\\left(\\frac{\\sqrt{e^{\\varepsilon_{0}}\\log\\left(1/\\eta\\right)}}{\\sqrt{T}}+\\frac{e^{\\varepsilon_{0}}}{T}\\right)\\right).}\\end{array}\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "They also obtain a tighter numerical bound on $\\varepsilon$ with an implementation provided in a GitHub repository.7 ", "page_idx": 14}, {"type": "text", "text": "We evaluate their bounds in an optimistic manner. Namely, for a given value of $\\delta$ , we compute an optimistic estimate on $\\varepsilon$ compared to the bound above by setting $\\delta_{0}\\,=\\,\\delta/n$ and setting $\\varepsilon_{0}~=$ $\\varepsilon_{\\mathcal{D}}(\\bar{\\delta}_{0})$ , and set $\\eta=\\delta$ (note that this is optimistic because the above proposition requires setting $\\delta\\,=\\,\\dot{\\eta}+{\\cal O}(e^{\\varepsilon}\\delta_{0}n)$ , which is larger than the $\\delta$ we are claiming). We use the numerical analysis method provided in the library by Feldman et al. [2021] to compute $\\sigma_{S}$ (via a binary search on top of their method to compute an upper bound on $\\varepsilon_{S}$ ), and plot it in Figure 5, along with the lower bound on $\\sigma_{S}$ as obtained by Chua et al. [2024], as well as $\\sigma_{\\mathscr D}$ . We find that the bounds by Feldman et al. [2021] are vacuous for batch sizes 2 048 and above, in that they are even larger than the bounds without any amplification. ", "page_idx": 14}, {"type": "image", "img_path": "6gMnj9oc6d/tmp/ed5d334876b3789828f15484e69891840b08d50325d4fcfe217ec1813641127f.jpg", "img_caption": ["Figure 5: Comparison of an optimistic estimate of the upper bound on $\\sigma_{S}$ from Feldman et al. [2021] against the lower bound on $\\sigma_{S}$ in Theorem 3.5 and $\\sigma_{\\mathscr D}$ . "], "img_footnote": [], "page_idx": 14}, {"type": "text", "text": "D $\\sigma$ with varying epochs ", "text_level": 1, "page_idx": 14}, {"type": "text", "text": "We include a comparison of the $\\sigma$ values for varying numbers of epochs, to show how the same trends hold beyond the 1 and 5 epoch regimes. ", "page_idx": 14}, {"type": "image", "img_path": "6gMnj9oc6d/tmp/246b47ec9377f63f8ade63e3f3fd244010be5a894e41ee935cc24a80e38db56d.jpg", "img_caption": ["Figure 6: $\\sigma_{B}$ values with varying numbers of epochs, fixing $\\varepsilon=5$ , $\\delta=2.7\\cdot10^{-8}$ , and batch size 65 536. "], "img_footnote": [], "page_idx": 15}, {"type": "text", "text": "NeurIPS Paper Checklist ", "text_level": 1, "page_idx": 15}, {"type": "text", "text": "1. Claims ", "text_level": 1, "page_idx": 15}, {"type": "text", "text": "Question: Do the main claims made in the abstract and introduction accurately reflect the paper\u2019s contributions and scope? ", "page_idx": 15}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 15}, {"type": "text", "text": "Justification: The main claims in the abstract are summarized under \u201cOur Contributions\u201d (Section 1.1) and described in detail in the rest of the paper. ", "page_idx": 15}, {"type": "text", "text": "Guidelines: ", "page_idx": 15}, {"type": "text", "text": "\u2022 The answer NA means that the abstract and introduction do not include the claims made in the paper.   \n\u2022 The abstract and/or introduction should clearly state the claims made, including the contributions made in the paper and important assumptions and limitations. A No or NA answer to this question will not be perceived well by the reviewers.   \n\u2022 The claims made should match theoretical and experimental results, and reflect how much the results can be expected to generalize to other settings.   \n\u2022 It is fine to include aspirational goals as motivation as long as it is clear that these goals are not attained by the paper. ", "page_idx": 15}, {"type": "text", "text": "2. Limitations ", "text_level": 1, "page_idx": 15}, {"type": "text", "text": "Question: Does the paper discuss the limitations of the work performed by the authors? ", "page_idx": 15}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 15}, {"type": "text", "text": "Justification: We discuss limitations and future directions of this paper in Section 5. ", "page_idx": 15}, {"type": "text", "text": "Guidelines: ", "page_idx": 15}, {"type": "text", "text": "\u2022 The answer NA means that the paper has no limitation while the answer No means that the paper has limitations, but those are not discussed in the paper.   \n\u2022 The authors are encouraged to create a separate \"Limitations\" section in their paper.   \n\u2022 The paper should point out any strong assumptions and how robust the results are to violations of these assumptions (e.g., independence assumptions, noiseless settings, model well-specification, asymptotic approximations only holding locally). The authors should reflect on how these assumptions might be violated in practice and what the implications would be.   \n\u2022 The authors should reflect on the scope of the claims made, e.g., if the approach was only tested on a few datasets or with a few runs. In general, empirical results often depend on implicit assumptions, which should be articulated.   \n\u2022 The authors should reflect on the factors that influence the performance of the approach. For example, a facial recognition algorithm may perform poorly when image resolution is low or images are taken in low lighting. Or a speech-to-text system might not be used reliably to provide closed captions for online lectures because it fails to handle technical jargon.   \n\u2022 The authors should discuss the computational efficiency of the proposed algorithms and how they scale with dataset size.   \n\u2022 If applicable, the authors should discuss possible limitations of their approach to address problems of privacy and fairness.   \n\u2022 While the authors might fear that complete honesty about limitations might be used by reviewers as grounds for rejection, a worse outcome might be that reviewers discover limitations that aren\u2019t acknowledged in the paper. The authors should use their best judgment and recognize that individual actions in favor of transparency play an important role in developing norms that preserve the integrity of the community. Reviewers will be specifically instructed to not penalize honesty concerning limitations. ", "page_idx": 15}, {"type": "text", "text": "", "page_idx": 16}, {"type": "text", "text": "3. Theory Assumptions and Proofs ", "text_level": 1, "page_idx": 16}, {"type": "text", "text": "Question: For each theoretical result, does the paper provide the full set of assumptions and a complete (and correct) proof? ", "page_idx": 16}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 16}, {"type": "text", "text": "Justification: Proofs of all statements are included either in the main body, or in the supplementary material. ", "page_idx": 16}, {"type": "text", "text": "Guidelines: ", "page_idx": 16}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include theoretical results.   \n\u2022 All the theorems, formulas, and proofs in the paper should be numbered and cross-referenced.   \n\u2022 All assumptions should be clearly stated or referenced in the statement of any theorems.   \n\u2022 The proofs can either appear in the main paper or the supplemental material, but if they appear in the supplemental material, the authors are encouraged to provide a short proof sketch to provide intuition.   \n\u2022 Inversely, any informal proof provided in the core of the paper should be complemented by formal proofs provided in appendix or supplemental material.   \n\u2022 Theorems and Lemmas that the proof relies upon should be properly referenced. ", "page_idx": 16}, {"type": "text", "text": "4. Experimental Result Reproducibility ", "text_level": 1, "page_idx": 16}, {"type": "text", "text": "Question: Does the paper fully disclose all the information needed to reproduce the main experimental results of the paper to the extent that it affects the main claims and/or conclusions of the paper (regardless of whether the code and data are provided or not)? ", "page_idx": 16}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 16}, {"type": "text", "text": "Justification: All experimental details are provided ", "text_level": 1, "page_idx": 16}, {"type": "text", "text": "Guidelines: ", "page_idx": 16}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 If the paper includes experiments, a No answer to this question will not be perceived well by the reviewers: Making the paper reproducible is important, regardless of whether the code and data are provided or not.   \n\u2022 If the contribution is a dataset and/or model, the authors should describe the steps taken to make their results reproducible or verifiable.   \n\u2022 Depending on the contribution, reproducibility can be accomplished in various ways. For example, if the contribution is a novel architecture, describing the architecture fully might suffice, or if the contribution is a specific model and empirical evaluation, it may be necessary to either make it possible for others to replicate the model with the same dataset, or provide access to the model. In general. releasing code and data is often one good way to accomplish this, but reproducibility can also be provided via detailed instructions for how to replicate the results, access to a hosted model (e.g., in the case of a large language model), releasing of a model checkpoint, or other means that are appropriate to the research performed.   \n\u2022 While NeurIPS does not require releasing code, the conference does require all submissions to provide some reasonable avenue for reproducibility, which may depend on the nature of the contribution. For example (a) If the contribution is primarily a new algorithm, the paper should make it clear how to reproduce that algorithm.   \n(b) If the contribution is primarily a new model architecture, the paper should describe the architecture clearly and fully.   \n(c) If the contribution is a new model (e.g., a large language model), then there should either be a way to access this model for reproducing the results or a way to reproduce the model (e.g., with an open-source dataset or instructions for how to construct the dataset).   \n(d) We recognize that reproducibility may be tricky in some cases, in which case authors are welcome to describe the particular way they provide for reproducibility. In the case of closed-source models, it may be that access to the model is limited in some way (e.g., to registered users), but it should be possible for other researchers to have some path to reproducing or verifying the results. ", "page_idx": 16}, {"type": "text", "text": "", "page_idx": 17}, {"type": "text", "text": "5. Open access to data and code ", "text_level": 1, "page_idx": 17}, {"type": "text", "text": "Question: Does the paper provide open access to the data and code, with sufficient instructions to faithfully reproduce the main experimental results, as described in supplemental material? ", "page_idx": 17}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 17}, {"type": "text", "text": "Justification: The source code for privacy accounting is provided in a Google Colab and beam pipelines for implementing Poisson subsampling at scale are provided in Appendix A. ", "page_idx": 17}, {"type": "text", "text": "Guidelines: ", "text_level": 1, "page_idx": 17}, {"type": "text", "text": "\u2022 The answer NA means that paper does not include experiments requiring code.   \n\u2022 Please see the NeurIPS code and data submission guidelines (https://nips.cc/public/ guides/CodeSubmissionPolicy) for more details.   \n\u2022 While we encourage the release of code and data, we understand that this might not be possible, so \u201cNo\u201d is an acceptable answer. Papers cannot be rejected simply for not including code, unless this is central to the contribution (e.g., for a new open-source benchmark).   \n\u2022 The instructions should contain the exact command and environment needed to run to reproduce the results. See the NeurIPS code and data submission guidelines (https: //nips.cc/public/guides/CodeSubmissionPolicy) for more details.   \n\u2022 The authors should provide instructions on data access and preparation, including how to access the raw data, preprocessed data, intermediate data, and generated data, etc.   \n\u2022 The authors should provide scripts to reproduce all experimental results for the new proposed method and baselines. If only a subset of experiments are reproducible, they should state which ones are omitted from the script and why.   \n\u2022 At submission time, to preserve anonymity, the authors should release anonymized versions (if applicable).   \n\u2022 Providing as much information as possible in supplemental material (appended to the paper) is recommended, but including URLs to data and code is permitted. ", "page_idx": 17}, {"type": "text", "text": "6. Experimental Setting/Details ", "text_level": 1, "page_idx": 17}, {"type": "text", "text": "Question: Does the paper specify all the training and test details (e.g., data splits, hyperparameters, how they were chosen, type of optimizer, etc.) necessary to understand the results? ", "page_idx": 17}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 17}, {"type": "text", "text": "Justification: Experimental details are provided in Section 4 and Appendix B. ", "page_idx": 17}, {"type": "text", "text": "Guidelines: ", "page_idx": 17}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 The experimental setting should be presented in the core of the paper to a level of detail that is necessary to appreciate the results and make sense of them.   \n\u2022 The full details can be provided either with the code, in appendix, or as supplemental material. ", "page_idx": 17}, {"type": "text", "text": "7. Experiment Statistical Significance ", "text_level": 1, "page_idx": 17}, {"type": "text", "text": "Question: Does the paper report error bars suitably and correctly defined or other appropriate information about the statistical significance of the experiments? ", "page_idx": 17}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 17}, {"type": "text", "text": "Justification: The training experiments have been repeated independently a few times and error bars are provided. However, due to significant cost of the experiments, we limit ourselves to only a small number of independent runs. These details are described in Section 4. ", "page_idx": 17}, {"type": "text", "text": "Guidelines: ", "page_idx": 18}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 The authors should answer \"Yes\" if the results are accompanied by error bars, confidence intervals, or statistical significance tests, at least for the experiments that support the main claims of the paper.   \n\u2022 The factors of variability that the error bars are capturing should be clearly stated (for example, train/test split, initialization, random drawing of some parameter, or overall run with given experimental conditions).   \n\u2022 The method for calculating the error bars should be explained (closed form formula, call to a library function, bootstrap, etc.)   \n\u2022 The assumptions made should be given (e.g., Normally distributed errors).   \n\u2022 It should be clear whether the error bar is the standard deviation or the standard error of the mean.   \n\u2022 It is OK to report 1-sigma error bars, but one should state it. The authors should preferably report a 2-sigma error bar than state that they have a $96\\%$ CI, if the hypothesis of Normality of errors is not verified.   \n\u2022 For asymmetric distributions, the authors should be careful not to show in tables or figures symmetric error bars that would yield results that are out of range (e.g. negative error rates).   \n\u2022 If error bars are reported in tables or plots, The authors should explain in the text how they were calculated and reference the corresponding figures or tables in the text. ", "page_idx": 18}, {"type": "text", "text": "8. Experiments Compute Resources ", "text_level": 1, "page_idx": 18}, {"type": "text", "text": "Question: For each experiment, does the paper provide sufficient information on the computer resources (type of compute workers, memory, time of execution) needed to reproduce the experiments? ", "page_idx": 18}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 18}, {"type": "text", "text": "Justification: The details on the compute resources are in Appendix B. ", "page_idx": 18}, {"type": "text", "text": "Guidelines: ", "page_idx": 18}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 The paper should indicate the type of compute workers CPU or GPU, internal cluster, or cloud provider, including relevant memory and storage.   \n\u2022 The paper should provide the amount of compute required for each of the individual experimental runs as well as estimate the total compute.   \n\u2022 The paper should disclose whether the full research project required more compute than the experiments reported in the paper (e.g., preliminary or failed experiments that didn\u2019t make it into the paper). ", "page_idx": 18}, {"type": "text", "text": "9. Code Of Ethics ", "text_level": 1, "page_idx": 18}, {"type": "text", "text": "Question: Does the research conducted in the paper conform, in every respect, with the NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines? ", "page_idx": 18}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 18}, {"type": "text", "text": "Justification: The paper conforms to the NeurIPS Code of Ethics as it only uses experiments on publicly available datasets, and does not use any crowdsourcing or human subjects. ", "page_idx": 18}, {"type": "text", "text": "Guidelines: ", "page_idx": 18}, {"type": "text", "text": "\u2022 The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics.   \n\u2022 If the authors answer No, they should explain the special circumstances that require a deviation from the Code of Ethics.   \n\u2022 The authors should make sure to preserve anonymity (e.g., if there is a special consideration due to laws or regulations in their jurisdiction). ", "page_idx": 18}, {"type": "text", "text": "10. Broader Impacts ", "text_level": 1, "page_idx": 18}, {"type": "text", "text": "Question: Does the paper discuss both potential positive societal impacts and negative societal impacts of the work performed? ", "page_idx": 18}, {"type": "text", "text": "Answer: [No] ", "page_idx": 18}, {"type": "text", "text": "Justification: The research work is about differentially private training of ML models. We do not see anticipate any specific positive or negative societal impacts of this research, beyond the impacts of differential privacy itself. So we do not feel the need to discuss this in the paper. ", "page_idx": 19}, {"type": "text", "text": "Guidelines: ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "\u2022 The answer NA means that there is no societal impact of the work performed.   \n\u2022 If the authors answer NA or No, they should explain why their work has no societal impact or why the paper does not address societal impact.   \n\u2022 Examples of negative societal impacts include potential malicious or unintended uses (e.g., disinformation, generating fake profiles, surveillance), fairness considerations (e.g., deployment of technologies that could make decisions that unfairly impact specific groups), privacy considerations, and security considerations.   \n\u2022 The conference expects that many papers will be foundational research and not tied to particular applications, let alone deployments. However, if there is a direct path to any negative applications, the authors should point it out. For example, it is legitimate to point out that an improvement in the quality of generative models could be used to generate deepfakes for disinformation. On the other hand, it is not needed to point out that a generic algorithm for optimizing neural networks could enable people to train models that generate Deepfakes faster.   \n\u2022 The authors should consider possible harms that could arise when the technology is being used as intended and functioning correctly, harms that could arise when the technology is being used as intended but gives incorrect results, and harms following from (intentional or unintentional) misuse of the technology.   \n\u2022 If there are negative societal impacts, the authors could also discuss possible mitigation strategies (e.g., gated release of models, providing defenses in addition to attacks, mechanisms for monitoring misuse, mechanisms to monitor how a system learns from feedback over time, improving the efficiency and accessibility of ML). ", "page_idx": 19}, {"type": "text", "text": "11. Safeguards ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "Question: Does the paper describe safeguards that have been put in place for responsible release of data or models that have a high risk for misuse (e.g., pretrained language models, image generators, or scraped datasets)? ", "page_idx": 19}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 19}, {"type": "text", "text": "Justification: This paper poses no such risks. ", "page_idx": 19}, {"type": "text", "text": "Guidelines: ", "page_idx": 19}, {"type": "text", "text": "\u2022 The answer NA means that the paper poses no such risks.   \n\u2022 Released models that have a high risk for misuse or dual-use should be released with necessary safeguards to allow for controlled use of the model, for example by requiring that users adhere to usage guidelines or restrictions to access the model or implementing safety filters.   \n\u2022 Datasets that have been scraped from the Internet could pose safety risks. The authors should describe how they avoided releasing unsafe images.   \n\u2022 We recognize that providing effective safeguards is challenging, and many papers do not require this, but we encourage authors to take this into account and make a best faith effort. ", "page_idx": 19}, {"type": "text", "text": "12. Licenses for existing assets ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "Question: Are the creators or original owners of assets (e.g., code, data, models), used in the paper, properly credited and are the license and terms of use explicitly mentioned and properly respected? ", "page_idx": 19}, {"type": "text", "text": "Answer: [NA] Justification: This paper does not use existing assets. ", "page_idx": 19}, {"type": "text", "text": "Guidelines: ", "page_idx": 19}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not use existing assets.   \n\u2022 The authors should cite the original paper that produced the code package or dataset.   \n\u2022 The authors should state which version of the asset is used and, if possible, include a URL.   \n\u2022 The name of the license (e.g., CC-BY 4.0) should be included for each asset.   \n\u2022 For scraped data from a particular source (e.g., website), the copyright and terms of service of that source should be provided.   \n\u2022 If assets are released, the license, copyright information, and terms of use in the package should be provided. For popular datasets, paperswithcode.com/datasets has curated licenses for some datasets. Their licensing guide can help determine the license of a dataset.   \n\u2022 For existing datasets that are re-packaged, both the original license and the license of the derived asset (if it has changed) should be provided.   \n\u2022 If this information is not available online, the authors are encouraged to reach out to the asset\u2019s creators. ", "page_idx": 19}, {"type": "text", "text": "", "page_idx": 20}, {"type": "text", "text": "13. New Assets ", "text_level": 1, "page_idx": 20}, {"type": "text", "text": "Question: Are new assets introduced in the paper well documented and is the documentation provided alongside the assets? ", "page_idx": 20}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 20}, {"type": "text", "text": "Justification: This paper does not release any new assets. ", "text_level": 1, "page_idx": 20}, {"type": "text", "text": "Guidelines: ", "page_idx": 20}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not release new assets.   \n\u2022 Researchers should communicate the details of the dataset/code/model as part of their submissions via structured templates. This includes details about training, license, limitations, etc.   \n\u2022 The paper should discuss whether and how consent was obtained from people whose asset is used.   \n\u2022 At submission time, remember to anonymize your assets (if applicable). You can either create an anonymized URL or include an anonymized zip file. ", "page_idx": 20}, {"type": "text", "text": "14. Crowdsourcing and Research with Human Subjects ", "text_level": 1, "page_idx": 20}, {"type": "text", "text": "Question: For crowdsourcing experiments and research with human subjects, does the paper include the full text of instructions given to participants and screenshots, if applicable, as well as details about compensation (if any)? ", "page_idx": 20}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 20}, {"type": "text", "text": "Justification: This paper does not rely on any crowdsourcing with human subjects. ", "page_idx": 20}, {"type": "text", "text": "Guidelines: ", "page_idx": 20}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u2022 Including this information in the supplemental material is fine, but if the main contribution of the paper involves human subjects, then as much detail as possible should be included in the main paper.   \n\u2022 According to the NeurIPS Code of Ethics, workers involved in data collection, curation, or other labor should be paid at least the minimum wage in the country of the data collector. ", "page_idx": 20}, {"type": "text", "text": "15. Institutional Review Board (IRB) Approvals or Equivalent for Research with Human Subjects ", "page_idx": 20}, {"type": "text", "text": "Question: Does the paper describe potential risks incurred by study participants, whether such risks were disclosed to the subjects, and whether Institutional Review Board (IRB) approvals (or an equivalent approval/review based on the requirements of your country or institution) were obtained? ", "page_idx": 20}, {"type": "text", "text": "Answer: [NA] Justification: This paper does not rely on any crowdsourcing with human subjects. ", "page_idx": 20}, {"type": "text", "text": "Guidelines: ", "page_idx": 20}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u2022 Depending on the country in which research is conducted, IRB approval (or equivalent) may be required for any human subjects research. If you obtained IRB approval, you should clearly state this in the paper.   \n\u2022 We recognize that the procedures for this may vary significantly between institutions and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the guidelines for their institution.   \n\u2022 For initial submissions, do not include any information that would break anonymity (if applicable), such as the institution conducting the review. ", "page_idx": 20}, {"type": "text", "text": "", "page_idx": 21}]