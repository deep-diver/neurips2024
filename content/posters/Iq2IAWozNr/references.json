{"references": [{"fullname_first_author": "Alessandro Achille", "paper_title": "Emergence of invariance and disentanglement in deep representations", "publication_date": "2018-00-00", "reason": "This paper is foundational for the theoretical understanding of deep learning representations, which is the core of the discussed representation learning methods."}, {"fullname_first_author": "Kaiming He", "paper_title": "Masked autoencoders are scalable vision learners", "publication_date": "2022-00-00", "reason": "This paper introduces a highly influential self-supervised learning method, Masked Autoencoders, which is among the state-of-the-art vision transformers used in the benchmark."}, {"fullname_first_author": "Alexey Dosovitskiy", "paper_title": "An image is worth 16x16 words: Transformers for image recognition at scale", "publication_date": "2020-00-00", "reason": "This paper is highly influential in introducing Vision Transformers, which are among the state-of-the-art vision transformers used in the benchmark."}, {"fullname_first_author": "Alec Radford", "paper_title": "Learning transferable visual models from natural language supervision", "publication_date": "2021-00-00", "reason": "This paper introduces CLIP, a highly influential model that learns transferable visual models from natural language supervision, which is among the state-of-the-art vision transformers used in the benchmark."}, {"fullname_first_author": "Maxime Oquab", "paper_title": "Dinov2: Learning robust visual features without supervision", "publication_date": "2023-00-00", "reason": "This paper introduces DINOv2, a highly influential self-supervised learning method, which is among the state-of-the-art vision transformers used in the benchmark."}]}