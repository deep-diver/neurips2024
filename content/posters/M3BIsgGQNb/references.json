{"references": [{"fullname_first_author": "Ben Poole", "paper_title": "DreamFusion: Text-to-3D using 2D diffusion", "publication_date": "2023-00-00", "reason": "This paper is a seminal work in text-to-3D generation, introducing a novel method that uses a pre-trained text-to-image diffusion model to guide the generation of 3D objects."}, {"fullname_first_author": "Jiahao Li", "paper_title": "Instant3D: Fast text-to-3D with sparse-view generation and large reconstruction model", "publication_date": "2024-00-00", "reason": "This paper proposes a two-stage approach for text-to-3D generation, improving speed and robustness compared to existing methods."}, {"fullname_first_author": "Ang Cao", "paper_title": "Lightplane: Highly-scalable components for neural 3d fields", "publication_date": "2024-00-00", "reason": "This paper introduces Lightplane, a highly-efficient and scalable architecture used in AssetGen for 3D shape reconstruction."}, {"fullname_first_author": "Lars Mescheder", "paper_title": "Occupancy Networks: Learning 3D Reconstruction in Function Space", "publication_date": "2019-00-00", "reason": "This paper introduces Occupancy Networks, a significant advancement in implicit 3D representation learning, which influenced the design of the 3D reconstruction model."}, {"fullname_first_author": "Michael Niemeyer", "paper_title": "Differentiable Volumetric Rendering: Learning Implicit 3D Representations without 3D Supervision", "publication_date": "2020-00-00", "reason": "This paper introduces Differentiable Volumetric Rendering, enabling the use of differentiable rendering techniques in implicit 3D representation learning, crucial to the training strategy of the 3D reconstruction model."}]}