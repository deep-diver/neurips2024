[{"figure_path": "atIE6Npr5A/tables/tables_7_1.jpg", "caption": "Table 1: MoCap human experiment. For training concepts and new concepts on new initial states, we report (top) percentage of time each method is the most successful at depicting a concept and (bottom) percentage of time each method depicts a concept. Mean and standard deviation are calculated over the number of scenarios in each setting and human subjects.", "description": "This table presents the results of a human evaluation comparing the performance of different methods (BC, VAE, In-Context, and the proposed FTL-IGM) in generating human motion corresponding to training and novel concepts.  The 'Training' section shows the success rate of each method in generating the motion concepts used during training. 'New Concept' and 'New Initial State' evaluate the method's performance on novel concepts presented with either their standard initial state or a novel initial state. The top row gives the percentage of time the given method had the highest success rate for a given trial. The bottom row presents the average success rate of a method across all trials. Note that a method could depict a concept correctly yet not have the best result if another method had even better results for that same trial.", "section": "5. Experiments"}, {"figure_path": "atIE6Npr5A/tables/tables_9_1.jpg", "caption": "Table 2: Ablation on the number of learned concepts. We test the effect of the number of learned concepts and weights in FTL-IGM on the generation accuracy of new learned concepts. On average, learning two concept components and their weights is preferable to learning one concept component and its weight. We report average accuracy and standard error over task types for Object Rearrangement and AGENT. Driving includes a single new concept and we report accuracy only.", "description": "This table presents the results of an ablation study on the number of learned concepts used in the Few-Shot Task Learning through Inverse Generative Modeling (FTL-IGM) method.  The study compares the performance of the model when learning one concept component versus two, measuring the generation accuracy of new concepts.  Results are reported for Object Rearrangement, AGENT, and Driving environments, showing that learning two concept components generally yields higher accuracy. Note that the Driving environment only uses a single new concept in this experiment.", "section": "5.3 Learning two concepts yields higher accuracy than one concept"}, {"figure_path": "atIE6Npr5A/tables/tables_20_1.jpg", "caption": "Table 3: Analysis of learned concepts. For new concepts that are explicit training concept compositions, we evaluate what each learned component captures. For both concepts 1 and 2, we report accuracy with respect to the concept when trajectories are generated solely from one learned component. e.g. in AGENT (bottom), 42% of the trajectories generated by component 1 and 48% of the trajectories generated by component 2 target the red object.", "description": "This table analyzes the learned components of new concepts that are compositions of training concepts.  For each concept, it shows the accuracy of each learned component in generating trajectories that match the target concept.  For example, in the AGENT domain, if a new concept involves a red bowl, the table indicates the percentage of trajectories where the first learned component successfully generated a trajectory targeting the red object and the second component successfully generated a trajectory targeting the bowl object.", "section": "5.3 Learning two concepts yields higher accuracy than one concept"}, {"figure_path": "atIE6Npr5A/tables/tables_24_1.jpg", "caption": "Table 4: Classifier-free guidance weight choice effect. For Object Rearrangement and Goal-Oriented Navigation we report the accuracy and standard error of the mean for new concepts from new initial states, and for Driving, the success and crash rates. We compare the four baselines with our approach as reported in Figures 6, 9 and 13 and Section 5.2. We report results for our approach with all w in our hyperparameter search and mark the reported w in Figures 6, 9 and 13 in bold font.", "description": "This table shows the effect of different classifier-free guidance weights (w) on the performance of the proposed Few-Shot Task Learning through Inverse Generative Modeling (FTL-IGM) method across three different domains: Object Rearrangement, Goal-Oriented Navigation, and Autonomous Driving.  It compares the performance of FTL-IGM with various weights to four baselines: Behavior Cloning (BC), Variational Autoencoder (VAE), In-Context learning, and Language-based learning.  The results indicate how the choice of the guidance weight affects the accuracy, success rate, and crash rate for each domain. The learned w represents the best weight found during hyperparameter search and reported in the main figures. ", "section": "C Implementation Details"}]