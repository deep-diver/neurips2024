[{"figure_path": "xqc8yyhScL/tables/tables_4_1.jpg", "caption": "Table 1: Generalization accuracy: % problems where the program makes correct predictions on every holdout test. Oracle accuracy: % problems where a correct program was generated (even if incorrect programs were also generated that also passed the training input-outputs). FlashFill++ [38] only reports oracle accuracy.", "description": "This table compares the generalization accuracy and oracle accuracy of three different text editing program synthesis systems: FlashFill, FlashFill++, and the proposed LLM-based system. Generalization accuracy measures the percentage of problems for which the generated program produces correct outputs on unseen test cases. Oracle accuracy measures the percentage of problems for which at least one correct program was generated, even if other incorrect programs were also generated. The results show that the LLM-based system significantly outperforms FlashFill in terms of generalization accuracy and achieves comparable performance to FlashFill++ in terms of oracle accuracy.", "section": "4.1 How well does the fine-tuned model perform?"}, {"figure_path": "xqc8yyhScL/tables/tables_5_1.jpg", "caption": "Table 4: 10 list \u2192 list functions from \u5165\u00b2 [13]", "description": "This table presents 10 example list-to-list transformation functions from the benchmark dataset \u5165\u00b2.  Each function is named, briefly described, and then marked with checkmarks to indicate whether the 7B and 33B models successfully solved the corresponding problem. This demonstrates the model's success on a range of list manipulation tasks.", "section": "4.2 What causes the fine-tuned model to succeed or fail?"}, {"figure_path": "xqc8yyhScL/tables/tables_6_1.jpg", "caption": "Table 4: 10 list \u2192 list functions from \u5165\u00b2 [13]", "description": "This table presents 10 list-to-list functions from the LambdaBeam benchmark [13]. Each function is described, and the last two columns indicate whether the function was solved by the 7B and 33B models, respectively.", "section": "4.2 What causes the fine-tuned model to succeed or fail?"}, {"figure_path": "xqc8yyhScL/tables/tables_15_1.jpg", "caption": "Table 2: List task and String task synthetic dataset generation and finetuning parameters.", "description": "This table details the hyperparameters used in the synthetic dataset generation and fine-tuning processes for both the List and String tasks.  It shows the seed dataset source, size, the model used for generating synthetic data, the size of that synthetic dataset, the sampling temperature used,  the filter ratio for similarity filtering, and the type of prompt used.  The fine-tuning parameters listed include the model used for fine-tuning, the LoRA rank, alpha, learning rate, learning rate schedule, warmup steps, number of epochs, and batch size.  It separately shows these settings for a 7B and a 33B model.", "section": "A.2 Syntheic Dataset Generation and Training Parameters"}, {"figure_path": "xqc8yyhScL/tables/tables_16_1.jpg", "caption": "Table 3: Logo task synthetic datasets generation and finetuning parameters", "description": "This table details the hyperparameters used for generating synthetic datasets and fine-tuning the deepseekcoder model for the LOGO task.  It shows the seed dataset source and size, the synthetic data generator model, the synthetic dataset size, similarity filter parameters, the filter threshold, the synthetic data prompt, and the LORA finetuning hyperparameters for both the 7B and 33B models.", "section": "A.2 Syntheic Dataset Generation and Training Parameters"}, {"figure_path": "xqc8yyhScL/tables/tables_21_1.jpg", "caption": "Table 4: 10 list \u2192 list functions from \u03bb\u00b2 [13]", "description": "This table presents ten different list transformation functions from the \u03bb\u00b2 benchmark [13].  For each function, a short description is given, along with checkmarks indicating whether the function was successfully solved by the authors' fine-tuned 7B and 33B models. This demonstrates the models' performance on a set of well-defined, relatively simple list manipulation tasks.", "section": "4.2 What causes the fine-tuned model to succeed or fail?"}]