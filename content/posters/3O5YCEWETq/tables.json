[{"figure_path": "3O5YCEWETq/tables/tables_6_1.jpg", "caption": "Table 1: Zero-shot forecast-improvement (f-imp) and model size-improvement (s-imp) of TTM over Moirai (ICML'24) and TimesFM (ICML'24). MSE averaged across FL \u2208 {96, 192, 336, 720}. Electricity and Weather results for TimesFM are not reported as its used by TimesFM for pretraining. Similarly, Traffic was used in pre-training for both Moirai and TimesFM. Full table in Appendix F.2", "description": "This table presents the zero-shot forecast improvement and model size improvement of the Tiny Time Mixers (TTM) model compared to two state-of-the-art (SOTA) models, Moirai and TimesFM.  The improvement is measured by mean squared error (MSE) across various forecast lengths (FL). Note that some results for TimesFM are missing because the data used for those specific results were also used in its pre-training.", "section": "4.4 TTM's Zero-shot Performance and Inference Cost"}, {"figure_path": "3O5YCEWETq/tables/tables_6_2.jpg", "caption": "Table 3: Computational improvement of TTM w.r.t. existing TS pre-trained models. Inference time per-batch in GPU and CPU, total parameters (Params), and maximum GPU memory usage (MEM) are reported. nX indicates the scaling factor for TTM's improvement. Set-up details are in the Appendix D.3", "description": "This table compares the computational efficiency of TTM against other state-of-the-art time series forecasting models.  It shows the inference time per batch (both on GPU and CPU), the number of parameters, and the maximum GPU memory usage for each model.  The significant reduction in computational resources required by TTM is highlighted by the scaling factors (nX) indicating how much faster and more memory efficient TTM is compared to the other models.", "section": "4.2 SOTA Benchmarks"}, {"figure_path": "3O5YCEWETq/tables/tables_6_3.jpg", "caption": "Table 2: Zero-shot forecast-improvement (f-imp) and model size-improvement (s-imp) of TTM over Chronos and Lag-llama over the last test-window. Since Chronos and Lag-llama recommend/report results with shorter forecast lengths, we use FL \u2208 {24, 48, 60, 96, 192}. Mean MSE across FLs is reported. Full table in the Appendix F.2", "description": "This table compares the zero-shot forecasting performance of three variants of the Tiny Time Mixer (TTM) model against Chronos and Lag-Llama models.  It shows the improvement in Mean Squared Error (MSE) and model size reduction achieved by TTM compared to the baselines across different forecast lengths. The results highlight TTM's superior performance and efficiency.", "section": "4.4 TTM's Zero-shot Performance and Inference Cost"}, {"figure_path": "3O5YCEWETq/tables/tables_7_1.jpg", "caption": "Table 4: Few-shot 5%. MSE averaged across FL \u2208 {96, 192, 336, 720}, models are trained with 5% train data (Appendix F.5).", "description": "This table shows the results of a few-shot learning experiment (5% of training data used for fine-tuning) comparing TTM against several other state-of-the-art forecasting models.  It evaluates the performance on multiple datasets (ETTH1, ETTH2, ETTM1, ETTM2, Weather, Electricity, Traffic) across various forecast lengths (FL). The table highlights TTM's superior performance even with limited training data by showing the percentage improvement over other models.", "section": "4.5 TTM's Few-shot and Full-shot Head Probing Performance"}, {"figure_path": "3O5YCEWETq/tables/tables_7_2.jpg", "caption": "Table 1: Zero-shot forecast-improvement (f-imp) and model size-improvement (s-imp) of TTM over Moirai (ICML'24) and TimesFM (ICML'24). MSE averaged across FL \u2208 {96, 192, 336, 720}. Electricity and Weather results for TimesFM are not reported as its used by TimesFM for pretraining. Similarly, Traffic was used in pre-training for both Moirai and TimesFM. Full table in Appendix F.2", "description": "This table compares the performance of three variants of the Tiny Time Mixer (TTM) model against two state-of-the-art (SOTA) multivariate time series forecasting models, Moirai and TimesFM, in a zero-shot setting.  It shows the percentage improvement in Mean Squared Error (MSE) and the size improvement (ratio of baseline model size to TTM model size) achieved by each TTM variant.  Note that some results for comparison models are missing due to the pre-training data used.", "section": "4.4 TTM's Zero-shot Performance and Inference Cost"}, {"figure_path": "3O5YCEWETq/tables/tables_15_1.jpg", "caption": "Table 8: List of pre-training datasets. A dataset with \"+ Downsample\" denotes that the proposed Diversity Resolution Sampling (DRS) has been applied on that dataset to generate new diverse datasets at frequencies lower than the original frequency of the data. Please note that, these pre-training datasets have no overlap with the evaluation datasets. Specifically, the australian_electricity_demand_dataset and australian_weather_dataset used in pre-training are completely different (w.r.t location, measured variables, type, resolution, length, etc.) from the standard Electricity (ECL) and Weather dataset used in the evaluation. Please note that, the last three datasets in the Libcity section have been excluded from the pre-training process for the model releases intended for enterprise-use.", "description": "This table lists the datasets used for pre-training the TTM model.  It shows the source of each dataset (Monash or LibCity), the dataset name, and the resolutions (sampling frequencies) available for each.  The \"+ Downsample\" annotation indicates that the Diverse Resolution Sampling (DRS) technique was applied to generate additional datasets with lower resolutions than the original. Importantly, these pre-training datasets are distinct from the evaluation datasets used later in the paper.  The last three LibCity datasets were excluded from the pre-training used for enterprise releases of the model.", "section": "Datasets"}, {"figure_path": "3O5YCEWETq/tables/tables_16_1.jpg", "caption": "Table 9: Details of the evaluation datasets.", "description": "This table lists eleven datasets used for evaluating the performance of the proposed TTM model.  It provides details for each dataset including the name, resolution (sampling frequency), length of the time series, the total number of channels, the number of target variables (channels for which forecasts are required), and the number of exogenous variables (optional channels influencing the forecasts). The datasets are categorized into two sets: D1 and D2.  D1 datasets are commonly used benchmarks for multivariate time series forecasting,  while D2 datasets are included to evaluate the effectiveness of handling exogenous variables and channel correlations within the TTM model.", "section": "4 Experiments and Results"}, {"figure_path": "3O5YCEWETq/tables/tables_18_1.jpg", "caption": "Table 1: Zero-shot forecast-improvement (f-imp) and model size-improvement (s-imp) of TTM over Moirai (ICML'24) and TimesFM (ICML'24). MSE averaged across FL \u2208 {96, 192, 336, 720}. Electricity and Weather results for TimesFM are not reported as its used by TimesFM for pretraining. Similarly, Traffic was used in pre-training for both Moirai and TimesFM. Full table in Appendix F.2", "description": "This table compares the zero-shot forecast performance and model size of three TTM variants (TTMB, TTME, TTMA) against two state-of-the-art time series forecasting models, Moirai and TimesFM.  It shows the percentage improvement in MSE and the ratio of the baseline model size to the TTM model size, demonstrating that TTM achieves superior accuracy with significantly smaller model size.  Note that some results are omitted because the baseline models used that data for pre-training.", "section": "4.4 TTM's Zero-shot Performance and Inference Cost"}, {"figure_path": "3O5YCEWETq/tables/tables_19_1.jpg", "caption": "Table 11: Zero-shot results of all TTM variants on D1 data benchmark across all sliding test windows (standard test protocol).", "description": "This table presents the zero-shot forecasting performance of different TTM variants (TTM0, TTMB, TTME, TTMA) on seven datasets (ETTH1, ETTH2, ETTM1, ETTM2, Weather, Electricity, Traffic).  The results are reported for four forecast lengths (FLs): 96, 192, 336, and 720.  The table allows for comparison of model performance across different forecast horizons and datasets using the standard test protocol which employs a sliding window approach.", "section": "4.4 TTM's Zero-shot Performance and Inference Cost"}, {"figure_path": "3O5YCEWETq/tables/tables_20_1.jpg", "caption": "Table 11: Zero-shot results of all TTM variants on D1 data benchmark across all sliding test windows (standard test protocol).", "description": "This table presents the zero-shot forecasting performance of different TTM model variants (TTM0, TTMB, TTME, TTMA) across various forecast lengths (FL) on seven datasets (ETTH1, ETTH2, ETTM1, ETTM2, Weather, Electricity, Traffic).  The results are averaged across all sliding windows, representing the mean squared error (MSE) for each model and forecast length combination on each dataset.", "section": "4.4 TTM's Zero-shot Performance and Inference Cost"}, {"figure_path": "3O5YCEWETq/tables/tables_21_1.jpg", "caption": "Table 11: Zero-shot results of all TTM variants on D1 data benchmark across all sliding test windows (standard test protocol).", "description": "This table presents the Mean Squared Error (MSE) values achieved by different variants of the Tiny Time Mixer (TTM) model in a zero-shot setting.  The results are shown for various forecast lengths (FL) across several evaluation datasets (D1) using the standard test protocol, which involves using all sliding test windows.  This demonstrates TTM's performance compared to other models without any fine-tuning on the target datasets. ", "section": "4.4 TTM's Zero-shot Performance and Inference Cost"}, {"figure_path": "3O5YCEWETq/tables/tables_21_2.jpg", "caption": "Table 1: Zero-shot forecast-improvement (f-imp) and model size-improvement (s-imp) of TTM over Moirai (ICML'24) and TimesFM (ICML'24). MSE averaged across FL \u2208 {96, 192, 336, 720}. Electricity and Weather results for TimesFM are not reported as its used by TimesFM for pretraining. Similarly, Traffic was used in pre-training for both Moirai and TimesFM. Full table in Appendix F.2", "description": "This table presents the zero-shot forecast improvement and model size improvement of the Tiny Time Mixers (TTM) models compared to the Moirai and TimesFM models.  The results show that TTM significantly outperforms existing benchmarks while using substantially fewer parameters. The MSE is averaged across various forecast lengths (FLs). Note that some results from TimesFM and Moirai are missing because these models used the respective datasets for pre-training.", "section": "4.4 TTM's Zero-shot Performance and Inference Cost"}, {"figure_path": "3O5YCEWETq/tables/tables_22_1.jpg", "caption": "Table 1: Zero-shot forecast-improvement (f-imp) and model size-improvement (s-imp) of TTM over Moirai (ICML\u201924) and TimesFM (ICML\u201924). MSE averaged across FL \u2208 {96, 192, 336, 720}. Electricity and Weather results for TimesFM are not reported as its used by TimesFM for pretraining. Similarly, Traffic was used in pre-training for both Moirai and TimesFM. Full table in Appendix F.2", "description": "This table compares the zero-shot forecast performance and model size of three variants of the Tiny Time Mixer (TTM) model against two state-of-the-art (SOTA) models, Moirai and TimesFM.  It shows the percentage improvement in Mean Squared Error (MSE) achieved by each TTM variant compared to Moirai and TimesFM, along with the ratio of the SOTA model size to the TTM model size.  The results are averaged across different forecast lengths (FL). Note that some results for TimesFM are missing due to data overlap between training and evaluation sets.", "section": "4.4 TTM\u2019s Zero-shot Performance and Inference Cost"}, {"figure_path": "3O5YCEWETq/tables/tables_23_1.jpg", "caption": "Table 11: Zero-shot results of all TTM variants on D1 data benchmark across all sliding test windows (standard test protocol).", "description": "This table presents the zero-shot results for all TTM variants (TTM0, TTMB, TTME, TTMA) across different forecast lengths (FL) on the D1 benchmark dataset.  It shows the Mean Squared Error (MSE) for each model variant across various datasets (Traffic, Electricity, Weather, ETTM2, ETTM1, ETTH2, ETTH1) and forecast lengths, enabling a comprehensive comparison of performance under zero-shot conditions.", "section": "4.4 TTM's Zero-shot Performance and Inference Cost"}, {"figure_path": "3O5YCEWETq/tables/tables_23_2.jpg", "caption": "Table 1: Zero-shot forecast-improvement (f-imp) and model size-improvement (s-imp) of TTM over Moirai (ICML'24) and TimesFM (ICML'24). MSE averaged across FL \u2208 {96, 192, 336, 720}. Electricity and Weather results for TimesFM are not reported as its used by TimesFM for pretraining. Similarly, Traffic was used in pre-training for both Moirai and TimesFM. Full table in Appendix F.2", "description": "This table compares the zero-shot forecasting performance and model size of three variants of the Tiny Time Mixer (TTM) model against two state-of-the-art (SOTA) models, Moirai and TimesFM.  It shows the percentage improvement in MSE and the ratio of the SOTA model size to the TTM model size. Note that some results are missing due to data usage in pre-training.", "section": "4.4 TTM's Zero-shot Performance and Inference Cost"}, {"figure_path": "3O5YCEWETq/tables/tables_24_1.jpg", "caption": "Table 12: Few-shot 5% results of all TTM variants on D1 data benchmark across all sliding test windows (standard test protocol).", "description": "This table presents the results of a 5% few-shot experiment, comparing the performance of different TTM variants (TTM0, TTMB, TTME, and TTMA) against several baseline models across various datasets (ETTH1, ETTH2, ETTM1, ETTM2, Weather, Electricity, and Traffic). The experiment uses all sliding test windows for different forecast lengths.  The results are expressed as MSE scores and show TTM variants consistently outperforming the baselines.", "section": "4.5 TTM's Few-shot and Full-shot Head Probing Performance"}, {"figure_path": "3O5YCEWETq/tables/tables_24_2.jpg", "caption": "Table 1: Zero-shot forecast-improvement (f-imp) and model size-improvement (s-imp) of TTM over Moirai (ICML'24) and TimesFM (ICML'24). MSE averaged across FL \u2208 {96, 192, 336, 720}. Electricity and Weather results for TimesFM are not reported as its used by TimesFM for pretraining. Similarly, Traffic was used in pre-training for both Moirai and TimesFM. Full table in Appendix F.2", "description": "This table presents a comparison of the Tiny Time Mixers (TTM) model's zero-shot forecasting performance against two state-of-the-art (SOTA) models: Moirai and TimesFM.  The comparison focuses on forecast improvement percentage (f-imp) and model size improvement (s-imp).  The results are averaged across various forecast lengths (FL).  Note that some results are missing due to data used in pre-training of the comparison models.", "section": "4.4 TTM's Zero-shot Performance and Inference Cost"}, {"figure_path": "3O5YCEWETq/tables/tables_26_1.jpg", "caption": "Table 20: LLM-Time Vs TTM: Zeroshot MSE reported on last test window set. Results reported in LLMTime [11] are used for this comparison.", "description": "This table compares the zero-shot performance of TTM against LLMTime on four datasets (ETTM2, Weather, Electricity, and Traffic) with two forecast lengths (96 and 192).  It shows the MSE values achieved by different TTM variants (TTMB, TTME, and TTMA) and LLMTime.  The table also highlights the significant size difference between TTM and LLMTime, illustrating TTM's superior performance with a substantially smaller model size.  The f-imp(%) and s-imp(X) show the percentage improvement in MSE and the size improvement factor compared to LLMTime.", "section": "4.4 TTM's Zero-shot Performance and Inference Cost"}, {"figure_path": "3O5YCEWETq/tables/tables_26_2.jpg", "caption": "Table 21: TTM vs UniTime MSE Improvement (f-imp) in zero-shot setting using full sliding-window test set. Results reported in UniTime [18] are used for this comparison.", "description": "This table compares the performance of TTM models against UniTime models in a zero-shot setting using the full sliding window test set.  It shows the mean squared error (MSE) for each model on four datasets (Electricity, Weather, ETTH2, and ETTH1) across four forecast lengths (FLs).  The 'f-imp(%)' rows show the percentage improvement of each TTM model compared to UniTime. The results demonstrate consistent improvement across the different datasets and forecast horizons, with TTMA exhibiting the largest improvement of 31%.", "section": "4.4 TTM's Zero-shot Performance and Inference Cost"}, {"figure_path": "3O5YCEWETq/tables/tables_26_3.jpg", "caption": "Table 22: Cross transfer learning MSE improvement (IMP) for self-supervised pre-training methods in various few-shot settings (10%,25%,50%,75%,100%).", "description": "This table shows the MSE improvement of TTMQ compared to other self-supervised pre-trained models (SimMTM, Ti-MAE, TST, LaST, TF-C, COST, TS2Vec) in different few-shot settings (10%, 25%, 50%, 75%, 100%).  The models are initially pre-trained on ETTH2 and then fine-tuned on ETTH1 using the specified percentage of training data.  The \"IMP\" column shows the percentage improvement of TTMQ's MSE over the baseline model in each setting.", "section": "4.6 TTM's Effectiveness in Cross-channel and Exogenous Modeling"}, {"figure_path": "3O5YCEWETq/tables/tables_26_4.jpg", "caption": "Table 7: Impact of AP and RPT: Impacts of adaptive patching (AP) in less pre-training (PT) data setting (i.e., TTMo), and resolution prefix tuning (RPT) in more pre-training (PT) data setting (i.e., TTMB). Zero-shot results on FL 96 reported. ['w/': with, 'w/o': 'without'.].", "description": "This table presents the impact of adaptive patching (AP) and resolution prefix tuning (RPT) on the performance of the TTM model in zero-shot forecasting with different amounts of pre-training data. The results are reported for the forecast length (FL) of 96, showing the impact of adaptive patching across different amounts of pre-training data. It also shows how resolution prefix tuning enhances the performance especially when there is abundant and diverse pre-training data.", "section": "4.7 Ablation Studies"}, {"figure_path": "3O5YCEWETq/tables/tables_27_1.jpg", "caption": "Table 25: Impact of RPT in less context setting (SL = 96). Zero-shot results on FL 24 reported. RPT helps in scenarios when the context length (sl) is short. In these scenarios, automatically detecting the resolution becomes a challenge for the model. Hence, by explicitly fusing the resolution information as a prefix, we can enhance the model's ability to learn effectively across resolutions. ['w/': with, 'w/o': 'without'.]", "description": "This table shows the impact of Resolution Prefix Tuning (RPT) on the model's performance when the context length (SL) is short (96). It compares the model's performance with and without RPT, measured by Mean Squared Error (MSE) on various datasets for a forecast length (FL) of 24.  The improvement in MSE (IMP) is calculated and shown as a percentage.", "section": "4.7 Ablation Studies"}]