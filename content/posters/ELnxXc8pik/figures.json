[{"figure_path": "ELnxXc8pik/figures/figures_1_1.jpg", "caption": "Figure 1: Unsupervised hierarchy-agnostic segmentation. Finer image parts are generated via over-clustering, each region colour-coded randomly. Our algorithm recursively partitions these parts, grouping them into coarser regions across multiple levels of granularity. The resulting tree represents an unsupervised hierarchical semantic segmentation. The arrangement of regions in the tree reflects their semantic distance, which is colour-coded in the heat map shown on the right.", "description": "This figure illustrates the process of unsupervised hierarchy-agnostic image segmentation. It starts with an input image that is first processed into superpixels.  These superpixels are then over-clustered, resulting in finer image parts. The algorithm then recursively partitions these parts into coarser regions at multiple granularity levels, forming a hierarchical tree structure. The tree represents the semantic segmentation of the image, with nodes representing semantic regions, and the arrangement of nodes reflecting their semantic distance. A color-coded heatmap visually represents this distance.", "section": "1 Introduction"}, {"figure_path": "ELnxXc8pik/figures/figures_5_1.jpg", "caption": "Figure 2: Qualitative results of our algorithm on PascalVOC2012, COCO-Stuff and Cityscapes datasets. The Hierarchy columns colour-code the pixel semantic hierarchy, and the Category columns are random colour-coded, helping visually discriminate hierarchically close pixels.", "description": "This figure shows qualitative results of the proposed unsupervised hierarchy-agnostic segmentation algorithm applied to three different datasets: PascalVOC2012, COCO-Stuff, and Cityscapes.  For each dataset, the figure presents example images with their corresponding segmentation results. The results are displayed in two columns: one showing the hierarchical semantic segmentation (Hierarchy) where pixels with similar semantic meaning are assigned the same color, and another showing a flat category-based segmentation (Category) with random color assignments.  This visualization helps to highlight the algorithm's ability to capture the semantic relationships between different parts of an image across multiple levels of granularity. The hierarchical segmentation reveals a nuanced understanding of the image structure.", "section": "4 Experiments"}, {"figure_path": "ELnxXc8pik/figures/figures_6_1.jpg", "caption": "Figure 3: Comparison of segmentation metrics. NFCovering evaluates single-level foreground overlap, NMCovering extends across multiple granular levels for all categories, and NHCovering integrates hierarchical consistency. Coloured arrows indicate category-specific matches.", "description": "This figure compares three different metrics used to evaluate the quality of semantic segmentation in the paper.  NFCovering measures the overlap between the predicted segmentation and the ground truth at a single granularity level, focusing only on the foreground. NMCovering extends this by considering multiple granularity levels and including both foreground and background. Finally, NHCovering incorporates hierarchical consistency, evaluating not only the overlap but also the accuracy of the hierarchical relationships between regions. The colored arrows in the diagram highlight category-specific matches.", "section": "4.1 Evaluation Metrics"}, {"figure_path": "ELnxXc8pik/figures/figures_8_1.jpg", "caption": "Figure 2: Qualitative results of our algorithm on PascalVOC2012, COCO-Stuff and Cityscapes datasets. The Hierarchy columns colour-code the pixel semantic hierarchy, and the Category columns are random colour-coded, helping visually discriminate hierarchically close pixels.", "description": "This figure shows qualitative results of the proposed unsupervised hierarchy-agnostic segmentation algorithm on three different datasets: Pascal VOC2012, COCO-Stuff, and Cityscapes.  Each dataset is represented in a row. The figure consists of three columns for each dataset. The first column shows the input image. The second column displays the hierarchical semantic segmentation results, where each color represents a different level of the hierarchy, allowing for visualization of the hierarchical relationships between different semantic parts. The third column shows a simpler segmentation, randomly assigning colors to each region, without considering the hierarchical structure. This comparison helps to visually highlight the effectiveness of the proposed method in producing a nuanced and hierarchical segmentation compared to a simpler, flat segmentation.", "section": "4 Experiments"}, {"figure_path": "ELnxXc8pik/figures/figures_15_1.jpg", "caption": "Figure 5: An example of ideal and perturbed adjacency matrices. The left shows an input image with highlighted parts and a colour legend. The central matrix represents the ideal adjacency matrix W', corresponding to the Laplacian L', with non-zero diagonal blocks for k' disconnected components at a specific semantic granularity. Below, a disconnected graph illustrates these isolated parts. On the right, the perturbed adjacency matrix W introduces off-diagonal entries due to pixel similarity across regions, resulting in the perturbed Laplacian L. Below, a graph with added connections shows these perturbations, with colours matching the highlighted parts in the input image.", "description": "This figure illustrates the concept of ideal versus perturbed adjacency matrices in the context of graph-based image segmentation.  The ideal matrix represents a perfectly segmented image where parts are completely independent; the perturbed matrix shows the reality of images where some level of similarity and connection exists between parts, introducing noise into the segmentation process.", "section": "A Theoretical Analysis and Perturbation Foundations"}, {"figure_path": "ELnxXc8pik/figures/figures_17_1.jpg", "caption": "Figure 6: The algorithm's two steps outputs. First, we quantize the graph to create an initial over-clustering of semantic parts. Next, we recursively group these parts, forming multi-level semantic clusters from coarse to fine granularity. The heatmap colour-codes the distance between tree leaves.", "description": "This figure shows example results of the proposed algorithm. The left column shows the input images.  The middle column shows the results of the first step, which involves a coarse semantic parts extraction using quantization. The right column shows the results of the second step which is a fine semantic hierarchy extraction using recursive grouping. The colormap shows the distances between tree leaves.", "section": "3.2 Pre and Post-Processing"}, {"figure_path": "ELnxXc8pik/figures/figures_21_1.jpg", "caption": "Figure 7: Normalised Multigranular Covering (NMCovering) examples. For each available ground truth categorical region R in the semantic map Sgt (left), we evaluate the overlap with the unrolled segments R' in the predicted region tree, e.g. T\u2081. The yellow labels indicate the maximum IoU matching correspondence between the ground truth and the prediction. Green line borders indicate high-score matching and red line borders indicate low-score matching. We propose two high-scoring predictions (centre) and two low-scoring (right). The total NMCovering is the average sum of the matching scores, as defined in Equation (3). The NMCovering metric evaluates the granularity-independent performance of the semantic segmentation model. The absence of correct semantic regions in T3 and T4 yields low score matches; see plate C in T3 and plate B in T4.", "description": "This figure illustrates the NMCovering metric, which evaluates the quality of semantic segmentation by comparing predicted regions (from the generated semantic region tree) with ground truth regions. It shows examples of high-scoring and low-scoring predictions, highlighting the impact of correctly identifying semantic regions across multiple levels of granularity.", "section": "D.2 Discussion About The Metrics"}, {"figure_path": "ELnxXc8pik/figures/figures_22_1.jpg", "caption": "Figure 8: Normalised Hierarchical Covering (NHCovering) computation example. Given the semantic tree Tgt (left), for each available ground truth categorical region R, we evaluate the overlap with the unrolled segments R' in the predicted region tree T. We consider one low-score lineage prediction edge (R1, R\u2081) and one high-score (R2, R5). The yellow labels indicate the maximum IoU matching correspondence between the ground truth and the predicted regions. Green and red arrows indicate correct and wrong lineage prediction, respectively. The total NHCovering is the sum of the matching scores weighted by the ratio of correct lineages, as reported in Equation (4). The NHCovering metric assesses the granularity and hierarchy-independent performance of the semantic segmentation model. Examples of lineage-weight computation are reported for the E and D matching, on the right, using the operators \u03c0(\u00b7) and \u1e9e(,) defined in Section 4.1.", "description": "This figure illustrates the calculation of the Normalized Hierarchical Covering (NHCovering) metric.  It shows how the algorithm compares the predicted semantic hierarchy (tree T) with the ground truth hierarchy (tree Tgt). The metric considers not only the overlap of regions at each level but also the correctness of the hierarchical relationships between those regions.  Green arrows indicate correctly predicted hierarchical relationships, while red arrows show incorrect ones. The example demonstrates how the lineage-weight calculation favors matches with accurate ancestor relationships.", "section": "4.1 Evaluation Metrics"}, {"figure_path": "ELnxXc8pik/figures/figures_23_1.jpg", "caption": "Figure 2: Qualitative results of our algorithm on PascalVOC2012, COCO-Stuff and Cityscapes datasets. The Hierarchy columns colour-code the pixel semantic hierarchy, and the Category columns are random colour-coded, helping visually discriminate hierarchically close pixels.", "description": "This figure displays qualitative results of the proposed unsupervised hierarchy-agnostic image segmentation algorithm on three major datasets: Pascal VOC2012, COCO-Stuff, and Cityscapes. Each image shows three columns: input image, pixel semantic hierarchy (color-coded), and random color-coded categories. The color-coding in the \"Hierarchy\" column helps visualize the hierarchical relationships between pixels, making it easy to see how the algorithm groups semantically similar pixels together at multiple levels of granularity. This visual representation demonstrates the algorithm's ability to capture both fine and coarse semantic details, producing a nuanced and unbiased segmentation.", "section": "3 Experiments"}, {"figure_path": "ELnxXc8pik/figures/figures_23_2.jpg", "caption": "Figure 3: Comparison of segmentation metrics. NFCovering evaluates single-level foreground overlap, NMCovering extends across multiple granular levels for all categories, and NHCovering integrates hierarchical consistency. Coloured arrows indicate category-specific matches.", "description": "This figure compares three different metrics used to evaluate the quality of semantic segmentation: Normalized Foreground Covering (NFCovering), Normalized Multigranular Covering (NMCovering), and Normalized Hierarchical Covering (NHCovering).  NFCovering only considers single-level foreground overlap, while NMCovering accounts for multiple granularity levels and all categories. NHCovering further incorporates hierarchical consistency. The colored arrows in the figure highlight the matches between predicted and ground-truth segmentations at different granularity levels.", "section": "4.1 Evaluation Metrics"}, {"figure_path": "ELnxXc8pik/figures/figures_23_3.jpg", "caption": "Figure 2: Qualitative results of our algorithm on PascalVOC2012, COCO-Stuff and Cityscapes datasets. The Hierarchy columns colour-code the pixel semantic hierarchy, and the Category columns are random colour-coded, helping visually discriminate hierarchically close pixels.", "description": "This figure displays qualitative results of the proposed unsupervised hierarchy-agnostic segmentation algorithm applied to three major datasets: PascalVOC2012, COCO-Stuff, and Cityscapes.  Each image is shown with two representations: a \"Hierarchy\" visualization that color-codes pixels according to their position within the resulting semantic hierarchy and a \"Category\" visualization where regions are randomly colored.  The goal is to visually demonstrate the algorithm's ability to segment images at multiple granularity levels and to show how it captures the hierarchical relationships between parts and objects in a scene.", "section": "3.1 Overview of the Approach"}, {"figure_path": "ELnxXc8pik/figures/figures_25_1.jpg", "caption": "Figure 2: Qualitative results of our algorithm on PascalVOC2012, COCO-Stuff and Cityscapes datasets. The Hierarchy columns colour-code the pixel semantic hierarchy, and the Category columns are random colour-coded, helping visually discriminate hierarchically close pixels.", "description": "This figure shows the qualitative results of the proposed unsupervised hierarchy-agnostic segmentation algorithm on three popular image segmentation datasets: PascalVOC2012, COCO-Stuff, and Cityscapes. Each dataset presents unique segmentation challenges regarding object and scene complexity.  The figure displays sample images from each dataset, organized into columns representing input images, resulting semantic hierarchy (color-coded to represent semantic relationships), and resulting category labels (randomly colored for visual distinction). The visualization demonstrates the algorithm's ability to produce a detailed and nuanced segmentation across varying levels of granularity, revealing the hierarchical relationships between image components.", "section": "4 Experiments"}, {"figure_path": "ELnxXc8pik/figures/figures_26_1.jpg", "caption": "Figure 2: Qualitative results of our algorithm on PascalVOC2012, COCO-Stuff and Cityscapes datasets. The Hierarchy columns colour-code the pixel semantic hierarchy, and the Category columns are random colour-coded, helping visually discriminate hierarchically close pixels.", "description": "This figure shows the qualitative results of the proposed unsupervised hierarchy-agnostic segmentation algorithm on three different datasets: PascalVOC2012, COCO-Stuff, and Cityscapes.  For each dataset, it displays input images alongside their corresponding semantic segmentations. The \"Hierarchy\" columns use a color-coding scheme to visualize the hierarchical relationships between semantic regions, allowing for easy visual identification of pixels belonging to similar semantic categories. In contrast, the \"Category\" columns use random colors for each category, providing a clearer visual distinction between different semantic groups. The figure effectively demonstrates the algorithm's ability to capture both fine-grained details and coarse semantic structures within images.", "section": "4 Experiments"}, {"figure_path": "ELnxXc8pik/figures/figures_27_1.jpg", "caption": "Figure 2: Qualitative results of our algorithm on PascalVOC2012, COCO-Stuff and Cityscapes datasets. The Hierarchy columns colour-code the pixel semantic hierarchy, and the Category columns are random colour-coded, helping visually discriminate hierarchically close pixels.", "description": "This figure shows qualitative results of the proposed unsupervised hierarchy-agnostic image segmentation algorithm on three major datasets: Pascal VOC2012, COCO-Stuff, and Cityscapes.  Each image is displayed with two representations: a hierarchical representation, where colors represent the semantic hierarchy of the pixels, allowing for visualization of the hierarchical relationships between image components; and a categorical representation, where colors are randomly assigned to categories, enabling a clear visual distinction between different semantic regions in the image. These visualizations illustrate the algorithm's ability to parse semantic image structures at multiple granularity levels. The consistent results across different datasets highlight the generalizability and robustness of the method.", "section": "3 Experiments"}, {"figure_path": "ELnxXc8pik/figures/figures_28_1.jpg", "caption": "Figure 2: Qualitative results of our algorithm on PascalVOC2012, COCO-Stuff and Cityscapes datasets. The Hierarchy columns colour-code the pixel semantic hierarchy, and the Category columns are random colour-coded, helping visually discriminate hierarchically close pixels.", "description": "This figure shows qualitative results of the proposed unsupervised hierarchy-agnostic segmentation algorithm on three major datasets: Pascal VOC2012, COCO-Stuff, and Cityscapes. Each dataset presents unique challenges in terms of object categories, scene complexity, and annotation granularity.  The figure demonstrates the algorithm's ability to segment images into semantic regions across multiple levels of detail. The \"Hierarchy\" columns use color-coding to represent the semantic hierarchy discovered by the algorithm, enabling a visual comparison of pixels with similar semantic relationships. The \"Category\" columns utilize random color-coding, facilitating easier discrimination between semantically close pixels, even if those pixels are visually similar.  The results showcase the algorithm's robustness and applicability in parsing semantic image structure across diverse datasets.", "section": "3 Experiments"}, {"figure_path": "ELnxXc8pik/figures/figures_29_1.jpg", "caption": "Figure 2: Qualitative results of our algorithm on PascalVOC2012, COCO-Stuff and Cityscapes datasets. The Hierarchy columns colour-code the pixel semantic hierarchy, and the Category columns are random colour-coded, helping visually discriminate hierarchically close pixels.", "description": "This figure displays qualitative results from the proposed unsupervised hierarchy-agnostic segmentation algorithm. It showcases the algorithm's performance on three different datasets: PascalVOC2012, COCO-Stuff, and Cityscapes.  Each image is divided into three columns. The first shows the input image. The second displays the hierarchical semantic segmentation, with each pixel color-coded based on its position in the semantic hierarchy.  The third column shows a random color-coding of semantic categories. The color-coding in the second column helps to visualize the hierarchical relationships between different image parts. By comparing the hierarchy-based color-coding with the random category color-coding, one can appreciate the algorithm's ability to discover meaningful semantic relationships in images.", "section": "3 Experiments"}, {"figure_path": "ELnxXc8pik/figures/figures_30_1.jpg", "caption": "Figure 14: Qualitative results on Cityscapes. Random sampling from a subset of our results, refined with CRF, with NMCovering greater than 40%. We assign unsupervised masks to the best overlapping classes.", "description": "This figure shows qualitative results of the proposed unsupervised semantic segmentation method on the Cityscapes dataset.  It presents a random selection of images where the algorithm achieved an NMCovering score above 40%.  The results have been post-processed using Conditional Random Fields (CRF) to sharpen boundaries.  Each image displays the original image alongside a color-coded segmentation map. The color coding represents the semantic labels assigned by the algorithm to different image parts. A legend in the bottom explains the correspondence between colors and semantic labels.", "section": "4 Experiments"}]