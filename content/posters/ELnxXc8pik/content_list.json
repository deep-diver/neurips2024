[{"type": "text", "text": "Unsupervised Hierarchy-Agnostic Segmentation: Parsing Semantic Image Structure ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Simone Rossetti1,2 Fiora Pirri1,2 1DIAG, Sapienza University of Rome 2DeepPlants {rossetti,pirri}@diag.uniroma1.it {simone,fiora}@deepplants.com ", "page_idx": 0}, {"type": "text", "text": "Abstract ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Unsupervised semantic segmentation aims to discover groupings within images, capturing objects\u2019 view-invariance without external supervision. This task is inherently ambiguous due to the variable levels of granularity in natural groups. Existing methods often bypass this ambiguity using dataset-specific priors. In our research, we address this ambiguity head-on and provide a universal tool for pixellevel semantic parsing of images guided by the latent representations encoded in self-supervised models. We introduce a novel algebraic methodology that recursively identifies latent semantic regions, dynamically estimates the number of components, and ensures smoothness in the partitioning process. The innovative approach identifies scene-conditioned primitives within a dataset and creates a hierarchy-agnostic semantic regions tree of the image pixels. The model captures fine and coarse semantic details, producing a nuanced and unbiased segmentation. We present a new metric for estimating the quality of the semantic segmentation of discovered elements on different levels of the hierarchy. The metric validates the intrinsic nature of the compositional relations among parts, objects, and scenes in a hierarchy-agnostic domain. Our results prove the power of this methodology, uncovering semantic regions without prior definitions and scaling effectively across various datasets. This robust framework for unsupervised image segmentation proves more accurate semantic hierarchical relationships between scene elements than traditional algorithms. The experiments underscore its potential for broad applicability in image analysis tasks, showcasing its ability to deliver a detailed and unbiased segmentation that surpasses existing unsupervised methods. ", "page_idx": 0}, {"type": "text", "text": "1 Introduction ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "The advancement of image segmentation has recently taken significant steps forward. On the one hand, the foundation models are trained on increasingly large datasets, such as CLIPseg [57] (CLIP [67]), SAM [48], and SEEM [97], supervised by text and human prompts[92]. On the other hand, there is a rising growth of unsupervised segmentation models. Unsupervised segmentation explores the feature hierarchy by leveraging self-supervised contrastive learning, as in SmooSeg [51], U2Seg [62], CUTLer [87], CuVLER [5], STEGO [32], ACSeg[52], FreeSolo [85], HSG [44], TransFgu [90], DeepCut [3], and others [77, 58, 96, 86, 33, 17]. Unsupervised models discover and localize image categories with no annotation aid and evaluate the quality of the pseudo-masks they predict on the datasets corpora used for testing, such as COCO-Stuff [10] and Cityscapes [21]. Despite exploring human perception more closely than the foundation models, they still rely on the linguistic and conceptual relations between the images and their annotations. ", "page_idx": 0}, {"type": "text", "text": "Curated datasets, such as ImageNet [50], PascalVOC [27], or MSCOCO [53], show an extraordinary number of objects with all their components and particulars not annotated either at the image level or densely. Why annotate this and not that? Annotation prejudice creates a bias towards a subset of the scene. Unsupervised learning, in contrast, has the potential to generate richer representations that are not restrained by annotation decisions. Without juggling annotations, unsupervised features (e.g. [64]) nearly mirror visual perception discovering scene parts and details; indeed, feature cues live in nested context levels and are not necessarily verbalisable [76, 66], as opposed to the Gestalt holistic view [83]. ", "page_idx": 0}, {"type": "image", "img_path": "ELnxXc8pik/tmp/38906533e200d0c1b99c5220999e262ab5cda5fddbd2359e3ddd22a650d72b96.jpg", "img_caption": ["Figure 1: Unsupervised hierarchy-agnostic segmentation. Finer image parts are generated via over-clustering, each region colour-coded randomly. Our algorithm recursively partitions these parts, grouping them into coarser regions across multiple levels of granularity. The resulting tree represents an unsupervised hierarchical semantic segmentation. The arrangement of regions in the tree reflects their semantic distance, which is colour-coded in the heat map shown on the right. "], "img_footnote": [], "page_idx": 1}, {"type": "text", "text": "", "page_idx": 1}, {"type": "text", "text": "Following previous research [44, 19, 3, 94], our key idea is that the natural hierarchical structure of visual scenes is an essential attribute that we can actively pursue in unsupervised segmentation. We approach unsupervised semantic segmentation as an unsupervised pixel-wise feature learning problem, discretising the hierarchical semantic knowledge yielded by self-supervised learning. Our approach makes no assumption about the number of semantic granularity levels and the number of partitions in each level as in [44]. We generate robust hierarchical segmentation for every image across the entire dataset, solely relying on hierarchical clustering in feature space, see Figure 1. This new method attains unsupervised segmentation by distilling relationships between concepts hidden in the latent space of self-supervised models at multiple levels of semantic granularity. ", "page_idx": 1}, {"type": "text", "text": "We propose a simple algebraic methodology based on a vast literature [20, 6, 61, 81, 75, 91], that unsupervisedly segments the scene parts. The method guarantees the construction of natural, scenedependent classes of primitives [55], which can be easily used in unsupervised segmentation without surrendering to their apriori definitions. Our contributions are: ", "page_idx": 1}, {"type": "text", "text": "1. We introduce a deep recursive spectral clustering that maximises an unbiased semantic similarity measure at multiple granularity levels. Exposing our method to any generic group of images, we show that it results in hierarchical unsupervised semantic segmentation. ", "page_idx": 1}, {"type": "text", "text": "2. We introduce new metrics for estimating the quality of the semantic segmentation of the elements discovered on the different levels of the hierarchy, called Normalised Multigranular Covering (NMCovering) and Normalised Hierarchical Covering (NHCovering). ", "page_idx": 1}, {"type": "text", "text": "3. We integrate the method into various self-supervised learning models to enhance its flexibility for benchmarking purposes, making it suitable as a downstream task through unsupervised segmentation by inferring all scene parts in the images of any given dataset. ", "page_idx": 1}, {"type": "text", "text": "2 Related works ", "text_level": 1, "page_idx": 1}, {"type": "text", "text": "Self-supervised representation learning for unsupervised segmentation. Self-supervised learning (SSL) is about learning representations of real-world data without human supervision [14, 36, 11, ", "page_idx": 1}, {"type": "text", "text": "64]. Contrastive learning (CL) [18, 63] is the most prominent method in SSL, maximising feature similarities between an image and its affine transformations while minimising similarity between randomly sampled images. Most unsupervised segmentation methods use learning representations to feed self-supervised features to graphs for clustering [58, 88, 87, 3]. Alternatively, features are used for building distillation strategies [32, 96, 51], or for designing inductive priors forcing some consistency property [51, 17, 73]. SSL representations implicitly define a distance metric in the latent space, though learning a metric space is not their primary objective. ", "page_idx": 2}, {"type": "text", "text": "Unsupervised semantic segmentation. Unsupervised semantic segmentation assigns a class to pixels belonging to specific elements in the scene, keeping the same class for all objects of the same semantic kind but without supervision. The main drives for unsupervised semantic segmentation are the strategies that can exploit either (1) grouping of similar patches or pixels, (2) an underlining dense consistency of objects that do not change under transformations, or (3) dense self-distillation. The earlier approaches, such as [41, 47, 17, 86, 77, 33] had not yet available powerful SSL features like [11], though used CL principles. PiCie [17] used equivariance to transformations; IIC [41] resorted to invariant information clustering, maximising mutual information, to find commonality in objects, and analogously did InfoSeg [33]. CLD [86] integrated local clustering into contrastive learning; [77] used saliency to find the image foreground and guide CL of pixel embedding. ", "page_idx": 2}, {"type": "text", "text": "The availability of high-level unsupervised features triggered new strategies. DINO self distillation [11] inspired both STEGO [32] and SmooSeg [51]. STEGO trains a segmentation head by distilling the feature correspondences to form compact clusters. SmooSeg uses the smooth prior over semantically coherent regions as a supervision cue to generate semantic maps. However, many methods suffer from the background problem and elaborate on DINO\u2019s attention to obtaining foreground objects, such as FreeSolo [85] and [93]. Also, TransFGU [90] focuses on a top-down object-centric approach to generate pixel pseudo labels according to GradCAM [72]. Spectral clustering, as introduced to machine learning by [74], is considered in [88, 58, 87, 52, 68]. In particular, CutLER [87] applies NCut [74] iteratively to a masked similarity matrix to discover foreground elements of the scene. ACSeg [52] uses the affinity matrix to discover concept similarities. SemPart [68] considers the foreground a single object saliency mask and applies graph regularisation. In [73], patch-level contrasting learning leverages global hidden positives to learn semantic consistency. ", "page_idx": 2}, {"type": "text", "text": "As grouping is the common denominator, all the mentioned methods suffer from deciding the correct level of granularity. Some methods resort to an object-centric bias, such as [77, 93], CAMs [90], hinting self-attention [96, 79], fixed-size flat image partitioning [58]. Others, such as [96], and [46, 73], resort to a scene-centric prior assumption. ", "page_idx": 2}, {"type": "text", "text": "Unsupervised parts discovering. Despite hierarchically discovering parts has a long history in computer vision, it has only recently recovered and connected to unsupervised part segmentation. The first input came from [31], analysing the hierarchical nature of deep learning features. One of the first approaches was SCOPS [39] using dense self-supervised contrastive loss to discover foreground parts of single objects. [94] introduce self-supervised primitive hierarchical grouping. They leverage a boundary strength map (OWT-UCM [4]) on relatively few images to learn from a large data set. The approach formulates an ultrametric map defining a region hierarchy. Similarly, HSG [44] leverages region boundaries to obtain multi-level segmentation. HSG is unsupervisedly trained from scratch, performing pixel grouping with dense contrastive learning across different granularity levels. In [19], $K$ fixed parts are discovered via an average part descriptor and by forcing consistency using the equivariance of affine and photometric transformations. Leopart [96] follows DINO self-distillation to classify pixels, obtaining detailed scene parts, further clustered via community detection. Finally, DeepCut [3] approaches unsupervised semantic part segmentation using both spectral clustering with NCut and GNN convolution, constructing a patch-wise correlation [7] matrix from DINO features. ", "page_idx": 2}, {"type": "text", "text": "3 Method ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "We present a flexible, unsupervised method for segmenting natural images, automatically creating data structures that organize pixels by their semantic coherence across multiple levels of detail without relying on predefined hierarchies or labels. This method is designed to segment images from coarse regions to finer parts, providing an intuitive representation of visual content; see Figure 1. ", "page_idx": 2}, {"type": "text", "text": "For instance, consider an urban street view. At a high level, it consists of elements such as the $s k y$ , a road, buildings, and vehicles. Among the vehicles, there might be a bus or a car, which can be further decomposed into parts like the body shell, wheels, and other visible components. ", "page_idx": 3}, {"type": "text", "text": "Our approach segments an image $I\\in\\mathbb{R}^{3\\times M\\times N}$ into a hierarchy-agnostic tree $T$ of semantic regions, with each pixel in the image assigned to a leaf node. Our model is a function $f:I\\rightarrow T$ , represented by a deep neural network, which maps an image to its semantic regions. Notably, this is achieved in a fully unsupervised manner; we incorporate mechanisms that guide $f$ to produce a meaningful decomposition of the image, even without labelled examples. ", "page_idx": 3}, {"type": "text", "text": "3.1 Overview of the Approach ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "Our method discovers semantic parts in an image by recursively partitioning a graph constructed from deep feature representations of the image. The key idea is to treat self-supervised models for image processing as codebooks of a lower-dimensional space, with the extracted feature vectors acting as codes that embed visual semantic concepts. ", "page_idx": 3}, {"type": "text", "text": "The primary cue for discovering parts is a deep feature extractor $\\phi$ , a neural network pre-trained without supervision on a standard benchmark such as ImageNet. We observe that the alignment of codes leads to semantic similarity across multiple levels of granularity. A higher degree of alignment indicates semantic similarity at finer granularity levels, corresponding to indivisible object parts or primitives. Conversely, a lower degree of alignment reflects semantic similarity at coarser granularity levels. By discretizing the density of these alignments, we can discover scene and object parts at various levels of detail. ", "page_idx": 3}, {"type": "text", "text": "Let $v_{i}=[\\phi\\left(I\\right)]_{i}\\in\\mathbb{R}^{d}$ be the code associated with pixel location $i$ in the image. If pixel $j$ belongs to the same finer part as $i$ , their codes should be similar. Conversely, if they belong to different parts, their codes will diverge. We expect this property to be consistent in each image $I$ and should not be affected by the particular object instances. ", "page_idx": 3}, {"type": "text", "text": "A straightforward approach might be to cluster these codes using algorithms like K-means or Expectation-Maximization to identify semantic regions. However, a critical flaw that can arise when using these methods in high-dimensional space is the presence of many local minima in the cost function. This would require multiple restarts of the iterative algorithms to find a suitable solution, which is impractical due to high complexity. To overcome these limitations, we propose a novel method that efficiently partitions the image into meaningful semantic regions, avoiding the pitfalls of multiple local minima and the need for iterative restarts. ", "page_idx": 3}, {"type": "text", "text": "Graph construction. We represent the image $I$ as a weighted undirected graph $G=(V,E,w)$ , where $V=\\{v_{i}\\}_{i=1}^{n}$ and $n=M\\cdot N$ . The weight assigned to each edge $(i,j)\\in E$ is defined by a scaled and shifted cosine similarity between feature vectors $w_{i j}=w(v_{i},v_{j})\\in[0,1]$ . These weights form the adjacency matrix $W=[\\stackrel{.}{w}_{i j}]\\in[0,1]^{n\\times n}$ , the degree matrix $D=\\mathrm{diag}\\left[d_{i}\\right]\\in\\mathbb{R}^{n\\times n}$ , where $\\begin{array}{r}{d_{i}=\\sum_{j}w_{i j}}\\end{array}$ and the normalized graph Laplacian $L=D^{-1/2}\\left(D-W\\right)D^{-1/2}$ [59]. ", "page_idx": 3}, {"type": "text", "text": "We interpret the edge weights as indicators of the semantic granularity between nodes. Specifically, if $w_{i j}\\,\\rightarrow\\,1$ , pixels $i$ and $j$ likely belong to the same fine-grained part (primitive). Conversely, if $w_{i j}\\,\\rightarrow\\,0$ , these pixels are likely to belong to entirely different parts, indicating minimal semantic similarity even at the coarsest level of granularity. ", "page_idx": 3}, {"type": "text", "text": "Similarity perturbation. In an ideal scenario, at a specific granularity level, $k^{\\prime}$ distinct connected components emerge in $G$ , resulting in a binary adjacency matrix $W^{\\prime}\\in\\{0,1\\}^{n\\times n}$ with $k^{\\prime}$ non-zero diagonal blocks \u2014 indicating strong intra-component connectivity and no inter-component connections \u2014 and normalized Laplacian $L^{\\prime}$ . However, in practice, the observed adjacency matrix is not discrete. Instead, $W$ exhibits tightly connected components alongside others with lower connectivity, resulting in a perturbed normalized graph Laplacian $L$ . We regard the primitives of the model as affected by a small symmetric perturbation $\\boldsymbol{H}\\in\\mathbb{R}^{n\\times n}$ incorporating contextual information from coarser levels of semantic granularity, i.e. $L=L^{\\prime}+H$ , making the observed adjacency real-valued. ", "page_idx": 3}, {"type": "text", "text": "Fortunately, the Davis-Kahan symmetric $\\sin\\theta$ theorem [23, 91] helps us manage perturbations; see also Appendix A. If the eigenvalues of $L$ exhibit a spectral gap $\\delta$ , the corresponding eigenspaces of $L$ and $L^{\\prime}$ remain close despite the perturbation $H$ . The theorem quantifies this proximity by relating the angle $\\theta$ between the eigenspaces of $L$ and $L^{\\prime}$ , where $\\sin\\theta$ is proportional to the norm of $H$ and inversely proportional to $\\delta$ . By selecting the largest gap, we isolate the part of the spectrum closest to the original graph, guessing the true semantic structure at the specific granularity level. ", "page_idx": 3}, {"type": "text", "text": "", "page_idx": 4}, {"type": "text", "text": "Normalized smoothness measure. We consider a function $g:V\\to\\mathbb{R}$ that assigns a value $g(v_{i})$ to each node $v_{i}\\in V$ . Since $|V|=n$ , we identify the function $g$ with a vector in $\\mathbb{R}^{n}$ . Based on the considerations from [74, 8] (see also Appendix C), we define the normalized smoothness measure of $g$ on the graph $G$ using the functional $S_{G}:\\mathbb{R}^{n}\\rightarrow\\mathbb{R}^{+}$ induced by $L$ through the form: ", "page_idx": 4}, {"type": "equation", "text": "$$\nS_{G}(g)=\\frac{g^{\\top}(D-W)g}{g^{\\top}D g}=\\frac{\\sum_{i j}(g(v_{i})-g(v_{j}))^{2}w_{i j}}{\\sum_{i}g(v_{i})^{2}d_{i}}.\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "We observe that minimizing the functional yields normalized smoothest functions that assign similar values to tightly connected nodes and different values to weakly connected ones while accounting for their importance in the graph \u2014 avoiding trivial solutions for low connectivity nodes. Therefore, if $g$ is both normalized and smooth with respect to $G$ , then $g(v_{i})$ is similar to $g(v_{j})$ whenever $v_{i}$ is similar to $v_{j}$ , where similarity is quantified by the weight $w_{i j}$ and adjusted by the node degree $d_{i}$ . ", "page_idx": 4}, {"type": "text", "text": "Given these properties, we can treat any function $g$ as a continuous partition function on our graph $G$ and evaluate its correctness using a criterion based on the semantic density change in the data partition, which measures variations in semantic coherence across different regions of the graph. ", "page_idx": 4}, {"type": "text", "text": "Recursive partitioning with perturbation stability. We propose a recursive partitioning strategy for discovering semantic parts by progressively dividing the graph, starting from the whole and refining it into tightly connected subgraphs. At each recursion level, we examine the subgraph\u2019s granularity, identify perturbations \u2014 contextual variations affecting node connections \u2014 and derive the unperturbed adjacency matrix to reveal finer semantic components. By capturing relationships at multiple levels of detail, this approach yields more nuanced segmentation than methods that partition the entire graph\u2019s nodes into a fixed number $k$ of sets. ", "page_idx": 4}, {"type": "text", "text": "We aim to find the smoothest normalized functions that best describe the semantic structure of a subgraph $G$ at a specific granularity.1 We tackle the minimization of Equation (1) as a standard eigenvalue problem [74] using the Rayleigh-Ritz quotient form. This yields the orthonormal eigenvectors $y_{i}$ corresponding to the smallest eigenvalues $\\lambda_{i}$ of $L$ , as guaranteed by the Courant-Fischer theorem: ", "page_idx": 4}, {"type": "equation", "text": "$$\ny_{i}=\\operatorname{argmin}_{\\|y\\|=1,y\\perp y<i}y^{\\top}L y,\\operatorname{with}y_{0}=D^{1/2}\\mathbb{1}\\in\\mathbb{R}^{n}.\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "The eigenvalues $\\lambda_{i}$ \u2014 the values on the right-hand side of the problem above \u2014 with $0\\,=\\,\\lambda_{0}\\,\\leq$ $\\lambda_{1}\\leq\\,\\cdot\\,\\cdot\\leq\\lambda_{n-1}\\leq2$ , quantify the normalized smoothness of the functions $y_{i}$ . Since solving the eigenvalue problem has a computational complexity of $O(n^{3})$ , in practice, we limit the computation to the $k_{m a x}$ smallest eigenvalues for efficiency. We obtain the spectral gaps $\\delta_{j}=\\lambda_{j}-\\lambda_{j-1}>0$ for $2\\leq j\\leq k_{m a x}-1$ and seek for the $k$ -th gap giving the tighter $\\sin\\theta$ bound, i.e. $k=\\arg\\operatorname*{max}_{j}\\delta_{j}$ . ", "page_idx": 4}, {"type": "text", "text": "We select up to $k$ smoothest normalized functions on $G$ , namely the first $k$ eigenvectors of $L$ , $y_{1},\\ldots,y_{k-1}$ \u2014 we ignore $y_{0}$ since it is constant. These $k$ eigenvectors provide orthogonal graph signals based on semantic coherence, with nodes showing similar values in these functions likely belonging to the same semantic part; thus, each signal points to a distinct connected component. ", "page_idx": 4}, {"type": "text", "text": "As in [61], we recover the true semantic structure of the graph considering the matrix $Y\\,=$ $[y_{1},y_{2},\\dots,y_{k-1}]\\ \\in\\ \\mathbb{R}^{n\\times k-1}$ . First, we perform $\\ell_{2}$ -normalization of each row in $Y$ , $X_{i j}~=~$ $Y_{i j}/(\\sum_{j}Y_{i j}^{2})^{1/2}\\,\\in\\,\\mathbb{R}^{n\\times k-1}$ \u2014 the $i$ -th row of $X$ represents the normalized feature vector for the $i$ -th node, which determines the node\u2019s membership in a cluster. Then, we take the best membership for each node \u2014 using the K-means algorithm in a lower-dimensional space \u2014 finding $k$ disjoint partitions of the nodes $V_{1},V_{2},\\ldots,V_{k}$ such that $\\textstyle\\bigcup_{i=1}^{k}V_{i}=V$ and $\\bigcap_{i=1}^{k}V_{i}=\\emptyset$ . ", "page_idx": 4}, {"type": "text", "text": "We determine $L^{\\prime}$ and estimate the perturbation $H=L-L^{\\prime}$ to compute the $\\sin\\theta$ upper bound value. ", "page_idx": 4}, {"type": "text", "text": "Each recursion step splits the graph into tighter subgraphs. This process continues until one of the early stopping criteria is met: (1) if a partition is too small (less than $k_{m i n}$ ), (2) if the eigenvalues exceed a maximum smoothness threshold $\\lambda_{m a x}$ , or (3) if the $\\sin\\theta$ upper bound value becomes too large (more than $p_{m a x}$ ), indicating that the current estimate of $L^{\\prime}$ is no longer reliable. These stopping conditions ensure we halt when further partitioning does not yield meaningful semantic components, thus identifying the final set of image parts or primitives. ", "page_idx": 4}, {"type": "image", "img_path": "ELnxXc8pik/tmp/74de10091cac90cbf0d653e7f64b18beefb83b2abcbc2991a4905443e9b6a8c2.jpg", "img_caption": ["Figure 2: Qualitative results of our algorithm on PascalVOC2012, COCO-Stuff and Cityscapes datasets. The Hierarchy columns colour-code the pixel semantic hierarchy, and the Category columns are random colour-coded, helping visually discriminate hierarchically close pixels. "], "img_footnote": [], "page_idx": 5}, {"type": "text", "text": "", "page_idx": 5}, {"type": "text", "text": "Each recursive partitioning adds structure to the tree $T$ , where nodes specify semantic regions at various levels. The final output is $T$ , with each leaf node capturing a distinct part of the image at an appropriate level of granularity; see Figure 2. ", "page_idx": 5}, {"type": "text", "text": "The values $k_{m i n}$ , $\\lambda_{m a x}$ and $p_{m a x}$ are found experimentally for the tested dataset; tables are shown in Section 4 and Appendix D. In Appendix B, we discuss the algorithm\u2019s properties and the generated $T$ , and present the complete pseudocode of our method. ", "page_idx": 5}, {"type": "text", "text": "3.2 Pre and Post-Processing ", "text_level": 1, "page_idx": 5}, {"type": "text", "text": "Boosting computation. We introduce a preprocessing strategy that condenses the graph, dramatically reducing the algorithm\u2019s time and memory requirements by several orders of magnitude while maintaining comparable accuracy. The condensed graph simplifies the original graph into $m$ nodes by contracting strongly connected components into vertices, where $m\\ll n$ . ", "page_idx": 5}, {"type": "text", "text": "We assume that the finest semantic content in natural images is inherently limited and cannot exceed the raw pixel statistics. From the input image $I$ we extract $m$ regions [2, 69, 74] leading to an initial undirected condensed graph $G_{c}=(V_{c},E_{c},\\tilde{w})$ , where $V_{c}=\\{\\bar{A}_{i}\\}_{i=1}^{m}$ , such that $\\textstyle\\bigcup_{i=1}^{m}{\\bar{A}}_{i}=V_{c}$ and $\\bigcap_{i=1}^{m}A_{i}=\\emptyset$ , and the edge weights $\\tilde{w}(A_{i},A_{j})$ represent the degree of association between regions, defined as $\\begin{array}{r}{\\tilde{w}(A_{i},A_{j})=\\sum_{u\\in A_{i},v\\in A_{j}}w(u,\\bar{v})}\\end{array}$ . We then apply our recursive partitioning algorithm to $G_{c}$ and its corresponding normalized Laplacian matrix $L_{c}$ . As a result, we obtain a region tree $T$ . ", "page_idx": 5}, {"type": "text", "text": "Ablation studies in Section 4.3 compare performances across various overclustering methods. ", "page_idx": 5}, {"type": "text", "text": "Boundary Sharpening. Given a predicted region tree $T$ with $q$ leaves, $B_{1},B_{2},\\ldots,B_{q}$ , each embedding a disjoint segment of $V$ , such that $\\textstyle\\bigcup_{j=1}^{\\overline{{q}}}B_{j}\\;=\\;V$ and $\\cap_{j=1}^{q}B_{j}\\;=\\;\\emptyset$ , we compute the prototypes for the image $I$ . Each prototype is defined as the $\\ell_{2}$ -normalized average of the feature codes in each leaf $\\begin{array}{r}{\\dot{u}_{j}=|B_{j}|^{-\\dot{1}}\\sum_{v\\in B_{j}}v}\\end{array}$ . For each pixel, we define a conditional probability distribution over the prototypes using the softmax function with smoothing parameter $\\tau$ , namely, $p_{i j}\\,=\\,\\exp\\big(v_{i}^{\\top}u_{j}\\tau^{-\\bar{1}}\\big)/\\sum_{k}\\bar{\\exp\\big(v_{i}^{\\top}\\bar{u}_{k}\\tau^{-1}\\big)}$ . We arrange the matrix $P\\,=\\,[p_{i j}]\\,\\in\\,[0,1]^{(M\\times N)\\times q}$ and sharpen the region boundaries applying a Conditional Random Fields (CRF) [49], which refine the predicted distribution $P$ by incorporating dependencies between pixel observations $I$ . This improves the accuracy at the boundary, ensuring sharper and more precise segmentation of leaves. ", "page_idx": 5}, {"type": "text", "text": "4 Experiments ", "text_level": 1, "page_idx": 5}, {"type": "text", "text": "We benchmark our algorithm on unsupervised multi-granular segmentation using seven major object- and scene-centric datasets and seven hierarchically structured datasets with varying granularity levels for hierarchy-agnostic segmentation. Our evaluation includes an ablation study to assess the contributions of each algorithm component and comparisons across different self-supervised backbone architectures. We only utilize publicly available datasets, SSL model checkpoints without retraining, and validation set ground-truth annotations. CRF is applied only where specified. ", "page_idx": 5}, {"type": "text", "text": "Each dataset provides unique characteristics essential for different segmentation challenges. PascalVOC2012 [27] offers a broad range of object categories, making it suitable for general object segmentation tasks. With its high-level division into things and stuff, COCO-Stuff [10] extends the MSCOCO [53] and tests the algorithm in complex scenes with multiple objects. Potsdam and Vaihingen [30] datasets, focused on aerial scene parsing, are designed for remote sensing and urban planning applications. Cityscapes [21] is critical for autonomous driving research, providing detailed annotations of urban street scenes. Mapillary Vistats [60] adds diversity with street scenes from various global environments, testing the algorithm\u2019s robustness to different conditions. KITTISTEP [89] and KITTI-SS [1], similar to Cityscapes, extend the evaluation to dynamic urban scenarios with instance detection and object tracking. For fine-grained part segmentation, Pascal-Part [15], PartImageNet, and PartImageNet-158 [35] offer detailed part annotations, crucial for tasks requiring precise recognition and segmentation of object parts. ", "page_idx": 6}, {"type": "text", "text": "These datasets ensure a comprehensive and diverse benchmark for evaluating the performance and robustness of our segmentation algorithm across various contexts, see Figure 2. Further details about datasets are in Appendix D.1, and more quantitative and qualitative results are in Appendices D.3 and D.4, respectively. ", "page_idx": 6}, {"type": "text", "text": "To ensure reproducibility, we standardize our experimental setup. Unless otherwise specified, we use the DINOv2-ViT-B14-REG [22] backbone with parameters $k_{\\operatorname*{min}}=1$ , $p_{\\mathrm{max}}\\,=\\,20$ , and $\\lambda_{\\mathrm{max}}\\,=\\,0.8$ . We apply the spectral method from $\\mathrm{Ng}$ et al. [61] with $m\\,=\\,300$ for superpixel clustering. The recursive partitioning depth is limited at 10 levels. Depending on each backbone downsampling factor, input images are resized to extract $60\\times60$ codes, except for urban street scenes, where we obtain $60\\times120$ codes. Further details in Appendix D. ", "page_idx": 6}, {"type": "text", "text": "4.1 Evaluation Metrics ", "text_level": 1, "page_idx": 6}, {"type": "image", "img_path": "ELnxXc8pik/tmp/c59acc0841f426047c61e16e9e88be45ac69830b53e1c6b7fe796f4a12f2df1f.jpg", "img_caption": ["Figure 3: Comparison of segmentation metrics. NFCovering evaluates single-level foreground overlap, NMCovering extends across multiple granular levels for all categories, and NHCovering integrates hierarchical consistency. Coloured arrows indicate category-specific matches. "], "img_footnote": [], "page_idx": 6}, {"type": "text", "text": "Granularity-agnostic. Following [44], we aim to evaluate the unbiased overlapping of regions between predicted segmentation and ground truth within each image via the Normalized Foreground Covering (NFCovering) metric. However, it is not well-suited for the multi-granular segmentation domain. The metric applies to a single granularity level at a time, failing to account for multiple granularity levels. Furthermore, it disregards the background as a valid semantic instance, leading to an incomplete estimate of segmentation performance. ", "page_idx": 6}, {"type": "text", "text": "We propose a novel evaluation metric, the Normalized Multigranular Covering (NMCovering), which addresses these limitations evaluating the overlap of regions between the unrolled segments in the region tree $T$ and all the available ground-truth categorical segments in a semantic map $S_{g t}$ . This metric ensures that both foreground and background instances are considered, providing a more comprehensive and granularity-independent assessment of a semantic segmentation model\u2019s performance. We adopt a greedy heuristic that maximises the overlap of the full hierarchy with the ground truth segmentation and compute the average overlap ratio of the matching: ", "page_idx": 6}, {"type": "table", "img_path": "ELnxXc8pik/tmp/b5bcfd42163eb3e000cf00b3ede3808ce03f614da2970700ad6a58fbe0030832.jpg", "table_caption": ["Table 1: Granularity-agnostic. Evaluation of our algorithm on different datasets using a maximum overlap heuristic for category matching. "], "table_footnote": [], "page_idx": 7}, {"type": "table", "img_path": "ELnxXc8pik/tmp/92b3978ddcfd1c9402f4a55ae17488c442ecbfc904ce1c23c419e3aa24088259.jpg", "table_caption": ["Table 2: Hierarchy-agnostic. Evaluation of our algorithm on different datasets using a maximum overlap heuristic for category matching. "], "table_footnote": [], "page_idx": 7}, {"type": "text", "text": "", "page_idx": 7}, {"type": "equation", "text": "$$\n{\\mathrm{NMCovering}}(T\\to S_{g t}):={\\frac{1}{|S_{g t}|}}\\sum_{R\\in S_{g t}}\\operatorname*{max}_{R^{\\prime}\\in T}{\\frac{|R\\cap R^{\\prime}|}{|R\\cup R^{\\prime}|}}.\n$$", "text_format": "latex", "page_idx": 7}, {"type": "text", "text": "The NMCovering metric evaluates the performance of a hierarchical segmentation model considering how many ground truth objects are recognised at any granularity level and how well they are segmented. A high score indicates a high segmentation coherence between human semantic perception and unsupervised machine one. ", "page_idx": 7}, {"type": "text", "text": "Hierarchy-agnostic. We introduce a second accuracy metric, the Normalized Hierarchical Covering (NHCovering). NHCovering jointly evaluates the segmentation quality and the semantic hierarchical inclusion of the prediction relating to the ground-truth semantic region tree $T_{g t}$ . Hierarchical inclusion is the matching between the nodes of two distinct hierarchies preserving the lineage from the ancestors; this problem is commonly referred to in the literature as the unordered tree inclusion problem [45]. ", "page_idx": 7}, {"type": "text", "text": "To calculate this metric, we use a greedy heuristic that computes the average overlap ratio of matching regions, weighting each match by the ratio of matched ancestors. The operator $\\pi(R)$ returns the ancestors set of the tree node $R$ , and $\\beta(R,T)$ returns the nodes set in the predicted tree $T$ that best match the ancestors of node $R$ : ", "page_idx": 7}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathrm{NHCovering}(T\\rightarrow T_{g t}):=\\displaystyle\\frac{1}{|T_{g t}|}\\sum_{R\\in T_{g t}}\\operatorname*{max}_{R^{\\prime}\\in T}\\displaystyle\\frac{|R\\cap R^{\\prime}|}{|R\\cup R^{\\prime}|}\\cdot\\frac{|\\beta(R,T)\\cap\\pi(R^{\\prime})|}{|\\pi(R)|},}\\\\ &{\\quad\\quad\\quad\\mathrm{where}\\ \\beta(R,T):=\\displaystyle\\bigcup_{P\\in\\pi(R)}\\arg\\operatorname*{max}_{P^{\\prime}\\in T}\\displaystyle\\frac{|P\\cap P^{\\prime}|}{|P\\cup P^{\\prime}|}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 7}, {"type": "text", "text": "The NHCovering metric computes the average weighted overlap of regions between the predicted tree $T$ and the ground-truth tree $T_{g t}$ . The overlap weight measures the proportion of correct ancestorships with respect to the ground truth. Balancing segmentation performance with semantic ancestry consistency provides a granularity- and hierarchy-independent performance assessment. This score quantifies the coherence of segmentation and hierarchical organization of visual concepts between human perception [66] and unsupervised machine one. ", "page_idx": 7}, {"type": "text", "text": "Refer to Figure 3 for a visual insight into the metrics. A more detailed discussion is in Appendix D.2. ", "page_idx": 7}, {"type": "text", "text": "4.2 Unsupervised Segmentation ", "text_level": 1, "page_idx": 7}, {"type": "text", "text": "Granularity-Agnostic. We adopt the NMCovering metric to benchmark the performance and versatility of our algorithm across different natural image domains. As shown in Tables 1 and 5, our method achieves excellent results in segmenting object-centric images and foreground discovery. Additionally, Table 1 demonstrates our approach\u2019s strong performance on scene-centric datasets, such as remote-sensing images and urban street scenes. Table 3 compares our approach to other supervision strategies.2 Our approach achieves segmentation quality comparable to supervised methods and surpasses other supervision strategies by a large gap. ", "page_idx": 7}, {"type": "table", "img_path": "ELnxXc8pik/tmp/7b1eb9fc2f46235053662be7289b69f922fa617013cf8f4db6ed90a42d5023dd.jpg", "table_caption": ["Table 3: Semantic segmentation. Comparison on PascalVOC2012 val. Ours match unsupervised masks to best overlapping classes. "], "table_footnote": [], "page_idx": 8}, {"type": "table", "img_path": "ELnxXc8pik/tmp/e0336b2056fd73bc89d68833746c5d817ef1ae860558c70fed8d886c91a7ae1d.jpg", "table_caption": ["Table 4: Boundary potential methods. All methods match unsupervised tree segments to best overlapping classes. "], "table_footnote": [], "page_idx": 8}, {"type": "text", "text": "Table 5: Backbone ablation. Granularity-agnostic segmentation evaluation on PascalVOC2012 val set using a maximum overlap heuristic for category matching in each image. We report category IoU for each experiment with micro and macro averaged scores and the NMCovering. ", "page_idx": 8}, {"type": "table", "img_path": "ELnxXc8pik/tmp/017fd2a7915e668ff092852e5bf8c96de7b1e5bed89647db582c02605244e2f3.jpg", "table_caption": [], "table_footnote": [], "page_idx": 8}, {"type": "text", "text": "Hierarchy-Agnostic. We further benchmark the hierarchical inclusion quality of the algorithm on available datasets having hierarchical structures at a high level, such as MSCOCO, COCO-Stuff and Cityscapes, and at a low level, such as PascalPart and PartImageNet. We show in Table 2 the closeness in performance of NHCovering with respect to the NMCovering, demonstrating the ability of the algorithm to capture hierarchical relations among the parts. The lower performance on PascalPart is due to the lower granularity of part annotations compared to PartImageNet, see [35]. ", "page_idx": 8}, {"type": "text", "text": "Recent unsupervised semantic segmentation approaches, such as [44, 94], often employ mutual information maximisation between regions at multiple granularity levels. These methods typically utilise hierarchical clustering that groups low-level coherent regions via boundary potentials, such as the Ultrametric Contour Map (OWT-UCM) [4], of boundaries derived from low-level features like brightness, colour, and texture gradients, as in Structured Edges (SE) [24] or Pointwise Mutual Information (PMI) [40]. We compare our approach with these methods in Table 4. The results indicate that low-level processes are inappropriate for the hierarchical grouping of high-level (semantic) features. In contrast, our approach excels in this area, suggesting significant room for improvement in the current state of the art. See some hierarchical grouping results in Figure 4. ", "page_idx": 8}, {"type": "image", "img_path": "ELnxXc8pik/tmp/210d47950296275d188c9fcb30603fcada2c8ccc1da385494d6bea49f11854ae.jpg", "img_caption": ["Figure 4: Unsupervised parts discovering examples on PartImageNet. The left column shows the ground truth part masks. The second to fourth column shows the predicted regions for each tree depth. Heatmap colours encode leaves\u2019 distance in the subtrees. "], "img_footnote": [], "page_idx": 8}, {"type": "table", "img_path": "ELnxXc8pik/tmp/275725c32152a6a81025937fd3c961fdd64be943a959c531929b6c48adcf7c67.jpg", "table_caption": ["Table 6: Superpixel and parameters ablation experiments. "], "table_footnote": [], "page_idx": 9}, {"type": "text", "text": "4.3 Ablation Experiments ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "Backbone. We evaluate in Table 5 the consistency of our approach according to the latent space induced by different SSL Imagenet pre-trained backbones on the granularity-agnostic task on the PascalVOC2012 val set. The performance gap reflects the representation quality assessed by SSL downstream task benchmarks. Such a result assesses the best model and a complementary downstream task benchmark for SSL. We do not adopt superpixel clustering or CRF but utilise raw patch features as pixel codes. ", "page_idx": 9}, {"type": "text", "text": "Parameters $k_{m i n},p_{m a x}$ and $\\lambda_{m a x}$ . In Tables 6a to 6c we validate the optimal parameters of our algorithm. While $k_{m i n}$ choice affects the granularity at lower levels, the $p_{m a x}$ and $\\lambda_{m a x}$ choice affects the granularity at higher levels by controlling the stability of the partition. ", "page_idx": 9}, {"type": "text", "text": "Overclustering and CRF. We test different over clustering techniques in Table 6a. Results show higher performances for a simultaneous normalised cut on SSL latent space. When applying CRF with $\\tau=0.1$ , we obtain an increase in segmentation accuracy as shown in Tables 3 and 4. ", "page_idx": 9}, {"type": "text", "text": "5 Discussion ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "Broader impact. Supervised learning relies on highly curated datasets that require costly and time-consuming manual annotations, especially for tasks like segmentation or those needing expert knowledge, such as fine-grained recognition. Due to the scarcity and limited size of part segmentation datasets, there\u2019s a growing focus on enhancing image understanding with minimal or no supervision. Our approach to discovering semantic object parts can significantly expand the data available for training such models. However, our method is based on self-supervised learning, which, like all data-driven methods, is susceptible to inherent biases in the data, which can influence the learning process and the model\u2019s predictions. ", "page_idx": 9}, {"type": "text", "text": "Limitations. One major drawback of our approach is that the segmentation quality, as well as the execution time of the algorithm, scales with the input size. Indeed, small object parts are hard to discover especially when using overclustering during pre-processing; results prove the statement. However, a trade-off between accuracy and inference time can be obtained experimentally. ", "page_idx": 9}, {"type": "text", "text": "6 Conclusions ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "We introduce a novel method for unsupervised, hierarchy-agnostic decomposition of natural scenes into primitive components, without requiring prior knowledge of scene granularity. Leveraging deep feature extraction and graph partitioning, our approach identifies scene-conditioned primitives and constructs a semantic tree of scene elements for any dataset. Our core algorithm applies an innovative algebraic approach to deep spectral clustering, addressing blurring from pixel similarity across object parts. Matrix perturbation theory is employed at each level of the semantic tree, ensuring stable smooth partitions. This framework not only advances unsupervised semantic segmentation but also benchmarks deep neural network representations by evaluating segmentation quality at multiple granularity levels and hierarchical consistency among them. We validate our method with new metrics across multiple datasets, measuring overlap with ground-truth components and semantic inclusion across potential image hierarchies. ", "page_idx": 9}, {"type": "text", "text": "References ", "text_level": 1, "page_idx": 10}, {"type": "text", "text": "[1] Hassan Abu Alhaija, Siva Karthik Mustikovela, Lars Mescheder, Andreas Geiger, and Carsten Rother. Augmented reality meets computer vision: Efficient data generation for urban driving scenes. IJCV, 126:961\u2013972, 2018.   \n[2] Radhakrishna Achanta, Appu Shaji, Kevin Smith, Aurelien Lucchi, Pascal Fua, and Sabine S\u00fcsstrunk. SLIC superpixels compared to state-of-the-art superpixel methods. IEEE TPAMI, 34(11):2274\u20132282, 2012.   \n[3] Amit Aflalo, Shai Bagon, Tamar Kashti, and Yonina Eldar. DeepCut: Unsupervised segmentation using graph neural networks clustering. In ICCV, pages 32\u201341, 2023.   \n[4] Pablo Arbelaez, Michael Maire, Charless Fowlkes, and Jitendra Malik. Contour detection and hierarchical image segmentation. IEEE TPAMI, 33(5):898\u2013916, 2010.   \n[5] Shahaf Arica, Or Rubin, Sapir Gershov, and Shlomi Laufer. CuVLER: Enhanced unsupervised object discoveries through exhaustive self-supervised transformers. In CVPR, pages 23105\u2013 23114, 2024.   \n[6] Arik Azran and Zoubin Ghahramani. Spectral methods for automatic multiscale data clustering. In CVPR, volume 1, pages 190\u2013197, 2006.   \n[7] Nikhil Bansal, Avrim Blum, and Shuchi Chawla. Correlation clustering. Machine learning, 56:89\u2013113, 2004.   \n[8] Mikhail Belkin and Partha Niyogi. Semi-supervised learning on manifolds. Machine Learning Journal, 1, 2002.   \n[9] Rajendra Bhatia, Chandler Davis, and Alan McIntosh. Perturbation of spectral subspaces and solution of linear operator equations. Linear algebra and its applications, 52:45\u201367, 1983.   \n[10] Holger Caesar, Jasper Uijlings, and Vittorio Ferrari. COCO-Stuff: Thing and stuff classes in context. In CVPR, pages 1209\u20131218, 2018.   \n[11] Mathilde Caron, Hugo Touvron, Ishan Misra, Herv\u00e9 J\u00e9gou, Julien Mairal, Piotr Bojanowski, and Armand Joulin. Emerging properties in self-supervised vision transformers. In ICCV, pages 9650\u20139660, 2021.   \n[12] Liang-Chieh Chen, George Papandreou, Iasonas Kokkinos, Kevin Murphy, and Alan L Yuille. DeepLab: Semantic image segmentation with deep convolutional nets, atrous convolution, and fully connected CRFs. IEEE TPAMI, 40(4):834\u2013848, 2017.   \n[13] Liang-Chieh Chen, George Papandreou, Florian Schroff, and Hartwig Adam. Rethinking atrous convolution for semantic image segmentation. arXiv preprint arXiv:1706.05587, 2017.   \n[14] Ting Chen, Simon Kornblith, Mohammad Norouzi, and Geoffrey Hinton. A simple framework for contrastive learning of visual representations. In ICML, pages 1597\u20131607. PMLR, 2020.   \n[15] Xianjie Chen, Roozbeh Mottaghi, Xiaobai Liu, Sanja Fidler, Raquel Urtasun, and Alan Yuille. Detect what you can: Detecting and representing objects using holistic models and body parts. In CVPR, 2014.   \n[16] Xinlei Chen, Saining Xie, and Kaiming He. An empirical study of training self-supervised vision transformers. In ICCV, pages 9640\u20139649, 2021.   \n[17] Jang Hyun Cho, Utkarsh Mall, Kavita Bala, and Bharath Hariharan. PiCIE: Unsupervised semantic segmentation using invariance and equivariance in clustering. In CVPR, pages 16794\u2013 16804, 2021.   \n[18] Sumit Chopra, Raia Hadsell, and Yann LeCun. Learning a similarity metric discriminatively, with application to face verification. In CVPR, volume 1, pages 539\u2013546, 2005.   \n[19] Subhabrata Choudhury, Iro Laina, Christian Rupprecht, and Andrea Vedaldi. Unsupervised part discovery from contrastive reconstruction. NeurIPS, 34:28104\u201328118, 2021. ", "page_idx": 10}, {"type": "text", "text": "[20] Fan RK Chung. Spectral graph theory, volume 92. American Mathematical Soc., 1997. l grap ", "page_idx": 11}, {"type": "text", "text": "[21] Marius Cordts, Mohamed Omran, Sebastian Ramos, Timo Rehfeld, Markus Enzweiler, Rodrigo Benenson, Uwe Franke, Stefan Roth, and Bernt Schiele. The Cityscapes dataset for semantic urban scene understanding. In CVPR, June 2016.   \n[22] Timoth\u00e9e Darcet, Maxime Oquab, Julien Mairal, and Piotr Bojanowski. Vision transformers need registers, 2023.   \n[23] Chandler Davis and W. M. Kahan. The rotation of eigenvectors by a perturbation. iii. SIAM Journal on Numerical Analysis, 7(1):1\u201346, 1970.   \n[24] Piotr Doll\u00e1r and C. Lawrence Zitnick. Structured forests for fast edge detection. In ICCV, 2013.   \n[25] Alexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov, Dirk Weissenborn, Xiaohua Zhai, Thomas Unterthiner, Mostafa Dehghani, Matthias Minderer, Georg Heigold, Sylvain Gelly, et al. An image is worth 16x16 words: Transformers for image recognition at scale. arXiv preprint arXiv:2010.11929, 2021.   \n[26] Justin Eldridge, Mikhail Belkin, and Yusu Wang. Unperturbed: spectral analysis beyond Davis-Kahan. In Algorithmic learning theory, pages 321\u2013358. PMLR, 2018.   \n[27] Mark Everingham, Luc Van Gool, Christopher KI Williams, John Winn, and Andrew Zisserman. The pascal visual object classes (VOC) challenge. IJCV, 88(2):303\u2013338, 2010.   \n[28] Jianqing Fan, Weichen Wang, and Yiqiao Zhong. An $\\ell_{i n f t y}$ eigenvector perturbation bound and its application. Journal of Machine Learning Research, 18(207):1\u201342, 2018.   \n[29] Miroslav Fiedler. Algebraic connectivity of graphs. Czechoslovak mathematical journal, 23 (2):298\u2013305, 1973.   \n[30] Markus Gerke. Use of the stair vision library within the isprs 2d semantic labeling benchmark (vaihingen), 01 2015.   \n[31] Abel Gonzalez-Garcia, Davide Modolo, and Vittorio Ferrari. Do semantic parts emerge in convolutional neural networks? IJCV, 126:476\u2013494, 2018.   \n[32] Mark Hamilton, Zhoutong Zhang, Bharath Hariharan, Noah Snavely, and William T Freeman. Unsupervised semantic segmentation by distilling feature correspondences. In ICLR, 2021.   \n[33] Robert Harb and Patrick Kn\u00f6belreiter. InfoSeg: Unsupervised semantic image segmentation with mutual information maximization. In DAGM-GCPR, pages 18\u201332. Springer, 2021.   \n[34] Bharath Hariharan, Pablo Arbel\u00e1ez, Lubomir Bourdev, Subhransu Maji, and Jitendra Malik. Semantic contours from inverse detectors. In ICCV, pages 991\u2013998, 2011. doi: 10.1109/ ICCV.2011.6126343.   \n[35] Ju He, Shuo Yang, Shaokang Yang, Adam Kortylewski, Xiaoding Yuan, Jie-Neng Chen, Shuai Liu, Cheng Yang, and Alan Yuille. PartImageNet: A large, high-quality dataset of parts. arXiv preprint arXiv:2112.00933, 2021.   \n[36] Kaiming He, Haoqi Fan, Yuxin Wu, Saining Xie, and Ross Girshick. Momentum contrast for unsupervised visual representation learning. In CVPR, pages 9729\u20139738, 2020.   \n[37] Kaiming He, Xinlei Chen, Saining Xie, Yanghao Li, Piotr Doll\u00e1r, and Ross Girshick. Masked autoencoders are scalable vision learners. arXiv:2111.06377, 2021.   \n[38] Roger A Horn and Charles R Johnson. Matrix analysis. Cambridge university press, 2012.   \n[39] Wei-Chih Hung, Varun Jampani, Sifei Liu, Pavlo Molchanov, Ming-Hsuan Yang, and Jan Kautz. SCOPS: Self-supervised co-part segmentation. In CVPR, pages 869\u2013878, 2019.   \n[40] Phillip Isola, Daniel Zoran, Dilip Krishnan, and Edward H. Adelson. Crisp boundary detection using pointwise mutual information. In ECCV, 2014.   \n[41] Xu Ji, Joao F Henriques, and Andrea Vedaldi. Invariant information clustering for unsupervised image classification and segmentation. In ICCV, pages 9865\u20139874, 2019.   \n[42] Peng-Tao Jiang, Yuqi Yang, Qibin Hou, and Yunchao Wei. L2G: A simple local-to-global knowledge transfer framework for weakly supervised semantic segmentation. In CVPR, pages 16886\u201316896, 2022.   \n[43] Tosio Kato. Perturbation theory for linear operators, volume 132. Springer Science & Business Media, 2013.   \n[44] Tsung-Wei Ke, Jyh-Jing Hwang, Yunhui Guo, Xudong Wang, and Stella X Yu. Unsupervised hierarchical semantic segmentation with multiview cosegmentation and clustering transformers. In CVPR, pages 2571\u20132581, 2022.   \n[45] Pekka Kilpel\u00e4inen and Heikki Mannila. Ordered and unordered tree inclusion. SIAM Journal on Computing, 24(2):340\u2013356, 1995.   \n[46] Junho Kim, Byung-Kwan Lee, and Yong Man Ro. Causal unsupervised semantic segmentation. arXiv preprint arXiv:2310.07379, 2023.   \n[47] Wonjik Kim, Asako Kanezaki, and Masayuki Tanaka. Unsupervised learning of image segmentation based on differentiable feature clustering. IEEE TIP, 29:8055\u20138068, 2020.   \n[48] Alexander Kirillov, Eric Mintun, Nikhila Ravi, Hanzi Mao, Chloe Rolland, Laura Gustafson, Tete Xiao, Spencer Whitehead, Alexander C Berg, Wan-Yen Lo, et al. Segment anything. In ICCV, pages 4015\u20134026, 2023.   \n[49] Philipp Kr\u00e4henb\u00fchl and Vladlen Koltun. Efficient inference in fully connected CRFs with gaussian edge potentials. NeurIPS, 24, 2011.   \n[50] Alex Krizhevsky, Ilya Sutskever, and Geoffrey E Hinton. Imagenet classification with deep convolutional neural networks. Communications of the ACM, 60(6):84\u201390, 2017.   \n[51] Mengcheng Lan, Xinjiang Wang, Yiping Ke, Jiaxing Xu, Litong Feng, and Wayne Zhang. Smooseg: smoothness prior for unsupervised semantic segmentation. NeurIPS, 36, 2024.   \n[52] Kehan Li, Zhennan Wang, Zesen Cheng, Runyi Yu, Yian Zhao, Guoli Song, Chang Liu, Li Yuan, and Jie Chen. Acseg: Adaptive conceptualization for unsupervised semantic segmentation. In CVPR, pages 7162\u20137172, 2023.   \n[53] Tsung-Yi Lin, Michael Maire, Serge Belongie, James Hays, Pietro Perona, Deva Ramanan, Piotr Doll\u00e1r, and C Lawrence Zitnick. Microsoft COCO: Common objects in context. In ECCV, pages 740\u2013755, 2014.   \n[54] Stuart Lloyd. Least squares quantization in PCM. IEEE TIT, 28(2):129\u2013137, 1982.   \n[55] Nikos K Logothetis and David L Sheinberg. Visual object recognition. Annual review of neuroscience, 19(1):577\u2013621, 1996.   \n[56] Jonathan Long, Evan Shelhamer, and Trevor Darrell. Fully convolutional networks for semantic segmentation. In CVPR, pages 3431\u20133440, 2015.   \n[57] Timo L\u00fcddecke and Alexander Ecker. Image segmentation using text and image prompts. In CVPR, pages 7086\u20137096, June 2022.   \n[58] Luke Melas-Kyriazi, Christian Rupprecht, Iro Laina, and Andrea Vedaldi. Deep spectral methods: A surprisingly strong baseline for unsupervised semantic segmentation and localization. In CVPR, pages 8364\u20138375, 2022.   \n[59] Russell Merris. Laplacian matrices of graphs: a survey. Linear algebra and its applications, 197:143\u2013176, 1994.   \n[60] Gerhard Neuhold, Tobias Ollmann, Samuel Rota Bulo, and Peter Kontschieder. The Mapillary Vistas dataset for semantic understanding of street scenes. In ICCV, pages 4990\u20134999, 2017.   \n[61] Andrew Ng, Michael Jordan, and Yair Weiss. On spectral clustering: Analysis and an algorithm. NeurIPS, 14, 2001.   \n[62] Dantong Niu, Xudong Wang, Xinyang Han, Long Lian, Roei Herzig, and Trevor Darrell. Unsupervised universal image segmentation. In CVPR, pages 22744\u201322754, 2024.   \n[63] Aaron van den Oord, Yazhe Li, and Oriol Vinyals. Representation learning with contrastive predictive coding. arXiv preprint arXiv:1807.03748, 2018.   \n[64] Maxime Oquab, Timoth\u00e9e Darcet, Th\u00e9o Moutakanni, Huy Vo, Marc Szafraniec, Vasil Khalidov, Pierre Fernandez, Daniel Haziza, Francisco Massa, Alaaeldin El-Nouby, et al. DINOv2: Learning robust visual features without supervision. arXiv preprint arXiv:2304.07193, 2023.   \n[65] Sean O\u2019Rourke, Van Vu, and Ke Wang. Random perturbation of low rank matrices: Improving classical bounds. Linear Algebra and its Applications, 540:26\u201359, 2018.   \n[66] Stephen E Palmer. Hierarchical structure in perceptual representation. Cognitive psychology, 9(4):441\u2013474, 1977.   \n[67] Alec Radford, Jong Wook Kim, Chris Hallacy, Aditya Ramesh, Gabriel Goh, Sandhini Agarwal, Girish Sastry, Amanda Askell, Pamela Mishkin, Jack Clark, et al. Learning transferable visual models from natural language supervision. In ICML, pages 8748\u20138763, 2021.   \n[68] Sriram Ravindran and Debraj Basu. SEMPART: Self-supervised multi-resolution partitioning of image semantics. In ICCV, pages 723\u2013733, 2023.   \n[69] Ren and Malik. Learning a classification model for segmentation. In ICCV, pages 10\u201317. IEEE, 2003.   \n[70] Karl Rohe, Sourav Chatterjee, and Bin Yu. Spectral clustering and the high-dimensional stochastic blockmodel. The Annals of Statistics, 39(4):1878\u20131915, 2011.   \n[71] Simone Rossetti, Damiano Zappia, Marta Sanzari, Marco Schaerf, and Fiora Pirri. Max pooling with vision transformers reconciles class and shape in weakly supervised semantic segmentation. In ECCV, pages 801\u2013818, 2022.   \n[72] Ramprasaath R Selvaraju, Michael Cogswell, Abhishek Das, Ramakrishna Vedantam, Devi Parikh, and Dhruv Batra. Grad-CAM: Visual explanations from deep networks via gradientbased localization. In ICCV, pages 618\u2013626, 2017.   \n[73] Hyun Seok Seong, WonJun Moon, SuBeen Lee, and Jae-Pil Heo. Leveraging hidden positives for unsupervised semantic segmentation. In CVPR, pages 19540\u201319549, 2023.   \n[74] Jianbo Shi and Jitendra Malik. Normalized cuts and image segmentation. IEEE TPAMI, 22(8): 888\u2013905, 2000.   \n[75] Gilbert W Stewart and Ji-guang Sun. Matrix perturbation theory. Academic Press, 1990.   \n[76] Anne M Treisman and Nancy G Kanwisher. Perceiving visually presented objets: recognition, awareness, and modularity. Current opinion in neurobiology, 8(2):218\u2013226, 1998.   \n[77] Wouter Van Gansbeke, Simon Vandenhende, Stamatios Georgoulis, and Luc Van Gool. Unsupervised semantic segmentation by contrasting object mask proposals. In CVPR, pages 10052\u2013 10062, 2021.   \n[78] Wouter Van Gansbeke, Simon Vandenhende, Stamatios Georgoulis, and Luc Van Gool. Revisiting contrastive methods for unsupervised learning of visual representations. In NeurIPS, 2021.   \n[79] Wouter Van Gansbeke, Simon Vandenhende, and Luc Van Gool. Discovering object masks with transformers for unsupervised semantic segmentation. arXiv preprint arXiv:2206.06363, 2022.   \n[80] Andrea Vedaldi and Stefano Soatto. Quick shift and kernel methods for mode seeking. In ECCV, pages 705\u2013718. Springer, 2008.   \n[81] Ulrike Von Luxburg. A tutorial on spectral clustering. Statistics and computing, 17:395\u2013416, 2007.   \n[82] Ulrike Von Luxburg, Mikhail Belkin, and Olivier Bousquet. Consistency of spectral clustering. The Annals of Statistics, pages 555\u2013586, 2008.   \n[83] Johan Wagemans, Jacob Feldman, Sergei Gepshtein, Ruth Kimchi, James R Pomerantz, Peter A Van der Helm, and Cees Van Leeuwen. A century of gestalt psychology in visual perception: Ii. conceptual and theoretical foundations. Psychological bulletin, 138(6):1218, 2012.   \n[84] Xinlong Wang, Rufeng Zhang, Chunhua Shen, Tao Kong, and Lei Li. Dense contrastive learning for self-supervised visual pre-training. In CVPR, 2021.   \n[85] Xinlong Wang, Zhiding Yu, Shalini De Mello, Jan Kautz, Anima Anandkumar, Chunhua Shen, and Jose M Alvarez. Freesolo: Learning to segment objects without annotations. In CVPR, pages 14176\u201314186, 2022.   \n[86] Xudong Wang, Ziwei Liu, and Stella X Yu. Unsupervised feature learning by cross-level instance-group discrimination. In CVPR, pages 12586\u201312595, 2021.   \n[87] Xudong Wang, Rohit Girdhar, Stella X Yu, and Ishan Misra. Cut and learn for unsupervised object detection and instance segmentation. In CVPR, pages 3124\u20133134, 2023.   \n[88] Yangtao Wang, Xi Shen, Shell Xu Hu, Yuan Yuan, James L Crowley, and Dominique Vaufreydaz. Self-supervised transformers for unsupervised object discovery using normalized cut. In CVPR, pages 14543\u201314553, 2022.   \n[89] Mark Weber, Jun Xie, Maxwell Collins, Yukun Zhu, Paul Voigtlaender, Hartwig Adam, Bradley Green, Andreas Geiger, Bastian Leibe, Daniel Cremers, Aljosa Osep, Laura LealTaixe, and Liang-Chieh Chen. STEP: Segmenting and tracking every pixel. In NeurIPS, 2021.   \n[90] Zhaoyuan Yin, Pichao Wang, Fan Wang, Xianzhe Xu, Hanling Zhang, Hao Li, and Rong Jin. Transfgu: a top-down approach to fine-grained unsupervised semantic segmentation. In ECCV, pages 73\u201389. Springer, 2022.   \n[91] Yi Yu, Tengyao Wang, and Richard J Samworth. A useful variant of the Davis\u2013Kahan theorem for statisticians. Biometrika, 102(2):315\u2013323, 2015.   \n[92] Yang Yuan. On the power of foundation models. In ICML, pages 40519\u201340530. PMLR, 2023.   \n[93] Andrii Zadaianchuk, Matthaeus Kleindessner, Yi Zhu, Francesco Locatello, and Thomas Brox. Unsupervised semantic segmentation with self-supervised object-centric representations. In Learning Representations, 2023.   \n[94] Xiao Zhang and Michael Maire. Self-supervised visual representation learning from hierarchical grouping. NeurIPS, 33:16579\u201316590, 2020.   \n[95] Lianghui Zhu, Yingyue Li, Jiemin Fang, Yan Liu, Hao Xin, Wenyu Liu, and Xinggang Wang. WeakTr: Exploring plain vision transformer for weakly-supervised semantic segmentation, 2023.   \n[96] Adrian Ziegler and Yuki M Asano. Self-supervised learning of object parts for semantic segmentation. In CVPR, pages 14502\u201314511, 2022.   \n[97] Xueyan Zou, Jianwei Yang, Hao Zhang, Feng Li, Linjie Li, Jianfeng Wang, Lijuan Wang, Jianfeng Gao, and Yong Jae Lee. Segment everything everywhere all at once. NeurIPS, 36, 2024. ", "page_idx": 11}, {"type": "text", "text": "", "page_idx": 12}, {"type": "text", "text": "", "page_idx": 13}, {"type": "text", "text": "", "page_idx": 14}, {"type": "image", "img_path": "ELnxXc8pik/tmp/63902c394d5814c939765623ef66d56928a9a0468ff800835eaaa68db6ab7add.jpg", "img_caption": ["Figure 5: An example of ideal and perturbed adjacency matrices. The left shows an input image with highlighted parts and a colour legend. The central matrix represents the ideal adjacency matrix $W^{\\prime}$ , corresponding to the Laplacian $L^{\\prime}$ , with non-zero diagonal blocks for $k^{\\prime}$ disconnected components at a specific semantic granularity. Below, a disconnected graph illustrates these isolated parts. On the right, the perturbed adjacency matrix $W$ introduces off-diagonal entries due to pixel similarity across regions, resulting in the perturbed Laplacian $L$ . Below, a graph with added connections shows these perturbations, with colours matching the highlighted parts in the input image. "], "img_footnote": [], "page_idx": 15}, {"type": "text", "text": "From the example in Figure 5, we observe that perturbation arises from pixel similarity values that inadvertently create connections between regions, which ideally should remain separate. This unintended overlap occurs because similarity values between certain pixel pairs do not perfectly align with the true structure of the components. Perturbation theory [23, 9, 75, 43] studies how small changes, such as these unintended connections, affect a matrix\u2019s eigenspaces. Recent research has expanded this analysis from Hermitian matrices to include Laplacian matrices, which capture graph structures, as in [82, 26, 70, 28, 65, 91]. ", "page_idx": 15}, {"type": "text", "text": "In our method, the two matrices are an ideal Laplacian matrix $L^{\\prime}$ and the observed Laplacian matrix $L$ , both symmetric (not necessarily of the same rank), perturbed by a symmetric matrix $H$ induced by higher-order pixel similarity, $\\dot{L^{'}}=L^{\\prime}\\!+\\!H$ . Given the recursive partitioning described in Section 3, we are looking, for each subgraph, for the best matches between the eigenvectors of $L^{\\prime}$ and those of $L$ minimising the functional defined in Equation (1). ", "page_idx": 15}, {"type": "text", "text": "In the ideal normalized Laplacian $L^{\\prime}$ , the graph is disconnected, and the number of connected components is reflected in the multiplicity of the zero eigenvalue of $L^{\\prime}$ . Each connected component contributes one zero eigenvalue, and the constant eigenvectors corresponding to these zero eigenvalues represent these isolated components [20, 81]. In a perturbed normalized Laplacian $L$ , the graph is connected and then the minimum of Equation (2) is achieved by the eigenvector corresponding to the second smallest eigenvalue of $L^{\\prime}$ . This eigenvector, known as the Fiedler vector, is not constant and captures the connectivity structure of the graph, often used for finding the best bipartition. ", "page_idx": 15}, {"type": "text", "text": "However, in the case of a perturbed graph with weak connections (e.g., low weights or nodes with only a single neighbour), small eigenvalues close to zero may not indicate strongly connected subgraphs. Instead, these small eigenvalues reflect loosely connected regions, where perturbations create weak links between components that ideally should remain separate. This implies that using the smallest eigenvectors directly for graph partitioning is sometimes unreliable, as they may reflect unstable or artificial connections introduced by perturbations. To ensure meaningful segmentation, it is essential to establish a measure that quantifies the stability of the partition under perturbations. Such a measure would indicate when it is safe to apply spectral clustering, ensuring that the identified clusters are robust and well-separated. According to Theorem A.1 (shown below), to achieve this, we seek the set of eigenvectors of the perturbed Laplacian $L$ that are closest to the eigenvectors of the ideal normalized Laplacian $L^{\\prime}$ despite the perturbation $H$ : ", "page_idx": 15}, {"type": "text", "text": "Theorem A.1 ([91]). Let $A,A^{\\prime}\\,\\in\\,\\mathbb{R}^{n\\times n}$ be symmetric, with eigenvalues $\\mu_{1}~\\geq~\\cdot\\cdot~\\geq~\\mu_{n}$ and $\\mu_{1}^{\\prime}\\geq\\ldots\\geq\\mu_{n}^{\\prime}$ respectively. Fix $1\\leq r\\leq s\\leq n$ and assume that $\\operatorname*{min}(\\mu_{r-1}-\\mu_{r},\\mu_{s}-\\mu_{s+1})>0$ , where $\\mu_{0}:=\\infty$ and $\\mu_{n+1}:=-\\infty$ . Let $u:=s-r+1$ , and let $Z=(z_{r},z_{r+1},\\ldots,z_{s})\\in\\mathbb{R}^{n\\times u}$ and $Z^{\\prime}=\\left(z_{r}^{\\prime},z_{r+1}^{\\prime},\\ldots,z_{s}^{\\prime}\\right)\\in\\mathbb{R}^{n\\times u}$ have orthonormal columns satisfying $A z_{j}\\,=\\,\\mu_{j}z_{j}$ and $A^{\\prime}z_{j}^{\\prime}=$ $\\mu_{j}^{\\prime}z_{j}^{\\prime}$ , for $j=r,r+1,\\ldots,s$ . Then: ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\|\\sin\\Theta(Z^{\\prime},Z)\\|_{F}\\le\\frac{2\\operatorname*{min}(u^{1/2}\\|A^{\\prime}-A\\|_{o p},\\|A^{\\prime}-A\\|_{F})}{\\operatorname*{min}(\\mu_{r-1}-\\mu_{r},\\mu_{s}-\\mu_{s+1})}\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "Moreover there exists and orthogonal matrix $O^{\\prime}$ in $\\mathbb{R}^{n\\times n}$ such that: ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\|Z^{\\prime}\\mathcal{O}^{\\prime}-Z\\|_{F}\\leq\\frac{2^{3/2}\\operatorname*{min}(u^{1/2}\\|A^{\\prime}-A\\|_{o p},\\|A^{\\prime}-A\\|_{F})}{\\operatorname*{min}(\\mu_{r-1}-\\mu_{r},\\mu_{s}-\\mu_{s+1})}\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "With $o p$ and $F$ , the spectral and the Frobenius norm, respectively. ", "page_idx": 16}, {"type": "text", "text": "Corollary A.1 ( [91]). Let $A,A^{\\prime}\\,\\in\\,\\mathbb{R}^{n\\times n}$ be symmetric, with eigenvalues $\\mu_{1}\\;\\geq\\;\\cdot\\cdot\\;\\geq\\;\\mu_{n}$ and $\\mu_{1}^{\\prime}\\geq\\ldots\\geq\\mu_{n}^{\\prime}$ respectively. Fix $j\\in\\{1,\\ldots,n\\}$ and assume that $\\operatorname*{min}(\\mu_{j-1}-\\mu_{j},\\mu_{j}-\\mu_{j+1})>0$ , where $\\mu_{0}:=\\infty$ and $\\mu_{n+1}:=-\\infty$ . If $z,z^{\\prime}\\in\\mathbb{R}^{n}$ satisfy $A z=\\mu_{j}z$ and $A^{\\prime}z^{\\prime}=\\mu_{j}^{\\prime}z^{\\prime}$ , then: ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\|\\sin\\Theta(z^{\\prime},z)\\|\\le\\frac{2\\|A^{\\prime}-A\\|_{o p}}{\\operatorname*{min}(\\mu_{j-1}-\\mu_{j},\\mu_{j}-\\mu_{j+1})}\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "Moreover, $i f\\,z^{\\prime\\top}\\,z\\geq0,$ , then: ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\|z^{\\prime}-z\\|\\leq{\\frac{2^{3/2}\\|A^{\\prime}-A\\|_{o p}}{\\operatorname*{min}(\\mu_{j-1}-\\mu_{j},\\mu_{j}-\\mu_{j+1})}}\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "In our method, the above symmetric matrix $A$ refers to the perturbed matrix $L$ and the matrix $A^{\\prime}$ to the ideal matrix $L^{\\prime}$ ; see Section 3. Since we select the $k$ smallest eigenvalues, the interval starts from $r=n-k+1$ and ends at $s=n$ , and we have $u=k$ . The denominator in Equation (6) simplifies to $\\operatorname*{min}(\\mu_{n-k}-\\mu_{n-k+1},\\mu_{n}-\\mu_{n+1})=\\mu_{n-k}-\\mu_{n-k+1}$ , since by definition $\\mu_{n+1}:=-\\infty$ , and, given $Z=(z_{n-k+1},z_{n-k+2},\\ldots,z_{n})\\in\\mathbb{R}^{n\\times k}$ and $Z^{\\prime}=(z_{n-k+1}^{\\prime},z_{n-k+2}^{\\prime},\\ldots,z_{n}^{\\prime})\\in\\mathbb{R}^{n\\times k}$ , depending on the chosen eigenvalue ordering, we have: ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\|\\sin\\Theta(Z^{\\prime},Z)\\|_{F}\\leq\\frac{2\\operatorname*{min}(k^{1/2}\\|L^{\\prime}-L\\|_{o p},\\|L^{\\prime}-L\\|_{F})}{\\mu_{n-k}-\\mu_{n-k+1}}\\ \\ \\mathrm{for}\\ \\ \\mu_{1}\\geq\\cdots\\geq\\mu_{n},\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "or, reversing the indexing \u2014 eigenvalues in non-decreasing order \u2014 and counting from zero, we set $\\lambda_{i}\\,=\\,\\mu_{n-i}$ and $\\lambda_{i}^{\\prime}\\,=\\,\\mu_{n-i}^{\\prime}$ for $i\\,=\\,0,\\dots,n\\,-\\,1$ with $Y\\,=\\,\\left(y_{0},y_{1},\\dots,y_{k-1}\\right)\\,\\in\\,\\mathbb{R}^{n\\times k}$ and $Y^{\\prime}=(y_{0}^{\\prime},y_{1}^{\\prime},\\dots,y_{k-1}^{\\prime})\\in\\mathbb{R}^{n\\times k}$ the orthonormal columns satisfying $L y_{j}=\\lambda_{j}y_{j}$ and $L^{\\prime}y_{j}^{\\prime}=\\lambda_{j}^{\\prime}y_{j}^{\\prime}$ , for $j=0,1,\\ldots,k-1$ , we have: ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\|\\sin\\Theta(Y^{\\prime},Y)\\|_{F}\\le\\frac{2\\operatorname*{min}(k^{1/2}\\|L^{\\prime}-L\\|_{\\sigma p},\\|L^{\\prime}-L\\|_{F})}{\\lambda_{k}-\\lambda_{k-1}}\\;\\;\\mathrm{for}\\;\\;\\lambda_{0}\\le\\cdots\\le\\lambda_{n-1}.\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "Indeed, we can apply the substitution and the indexing, given the eigenpairs $(\\lambda,y)$ condition for all the eigenvalues and eigenvectors populating the chosen interval $(r,s)$ . Furthermore, given the eigenpair condition, the minimization of Equation (1) in Section 3 is guaranteed (see Algorithm 1), and we can just ratify the smoothness by resorting to the Courant-Fisher theorem; see [38] Theorem 4.2.6. Finally, we can use the Corollary A.1 for a more refined choice of the eigenvectors. ", "page_idx": 16}, {"type": "text", "text": "Note that the theorem of $\\mathrm{Yu}$ et al. [91] is particularly useful because, differently from DavisKahan [23] theorem, it defines an upper bound between two symmetric matrices concerning the angles between a subset of the eigenvectors of the two matrices or their distance (up to a rotation), in terms of the eigenvalues of one of the two matrices. Indeed, this theorem shows that $z$ (an eigenvector of the perturbed Laplacian $L$ ) is close to $z^{\\prime}$ (an eigenvector of the Laplacian $L^{\\prime}$ ), under two main assumptions. First, we assume that $L$ is close to $L^{\\prime}$ \u2014 often this is straightforward in graph theory, for instance, if $L^{\\prime}$ is derived from a theoretical (or \"population\") graph structure, and $L$ is the Laplacian of a graph constructed from a sample or noisy measurements of this structure. Second, applying Weyl\u2019s inequality, we assume that, almost certainly: ", "page_idx": 16}, {"type": "equation", "text": "$$\n|\\mu_{j-1}^{\\prime}-\\mu_{j}|\\geq(\\mu_{j-1}-\\mu_{j})/2\\;\\;\\mathrm{and}\\;\\;|\\mu_{j+1}^{\\prime}-\\mu_{j}|\\geq(\\mu_{j}-\\mu_{j+1})/2,\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "where $\\mu_{j}$ and $\\mu_{j}^{\\prime}$ are the $j$ -th eigenvalues of $L$ and $L^{\\prime}$ , respectively. Under this eigengap condition, assuming a sufficient separation between the population eigenvalues of $L$ and their neighbouring values, as shown in $\\mathrm{Yu}$ et al. [91] results, we can conclude that $\\|z^{\\prime}-z\\|$ is small, meaning $z$ and $z^{\\prime}$ are close in norm. Building on this, the theorem implies that when the eigengap condition holds, the eigenvector $z$ associated with $L$ remains stable under perturbations represented by $H=L-L^{\\prime}$ . Specifically, the proximity of $z$ and $z^{\\prime}$ allows us to interpret $z$ as a meaningful approximation of $z^{\\prime}$ , preserving the structure of the ideal graph encoded by $L^{\\prime}$ . ", "page_idx": 17}, {"type": "text", "text": "Consequently, this alignment of eigenvectors facilitates robust graph-based clustering or segmentation, as it enables us to consistently identify clusters or partitions in perturbed graphs that mirror the structure of the unperturbed graph. Furthermore, this result provides a foundation for using the perturbed eigenvectors for hierarchical clustering by ensuring that the segments or clusters derived from $L$ approximate those of $L^{\\prime}$ even under small changes or noise in the graph data. ", "page_idx": 17}, {"type": "text", "text": "B The Algorithm and BFS Implementation ", "text_level": 1, "page_idx": 17}, {"type": "image", "img_path": "ELnxXc8pik/tmp/0c33d0b68c4dd751ab9f6776338c3d8c0d72d1d19048e72199c6a90ec9aa473b.jpg", "img_caption": ["Figure 6: The algorithm\u2019s two steps outputs. First, we quantize the graph to create an initial overclustering of semantic parts. Next, we recursively group these parts, forming multi-level semantic clusters from coarse to fine granularity. The heatmap colour-codes the distance between tree leaves. "], "img_footnote": [], "page_idx": 17}, {"type": "text", "text": "In Section 3 of the main paper, we have presented the recursive partitioning of the graph $G$ , which is simple and intuitive. As noted, we present a Breadth-First Search (BFS) pseudocode in Algorithm 1. ", "page_idx": 17}, {"type": "text", "text": "The method obtains graph partitions when two or more components are detectable and recur on each partition to find new subgraphs until an early stopping condition is met, see Section 3. We report that the proposed algorithm is defined in two steps for completeness \u2014 the first step is meant to speed up the overall algorithm, and hence, it is optional. In the first step, we quantise the graph, creating an over-clustering of semantic parts; in the second step, we recur on the parts, generating coarse to finer semantic groups at multiple granularity levels; see Figure 6. ", "page_idx": 17}, {"type": "text", "text": "In the first step, we write the patch-wise features extracted with a deep neural network as the set of nodes $V$ of a weighted undirected graph $G=(V,E,w)$ , and we define $w$ as the cosine similarity of points, scaled and shifted in $[0,1]$ . ", "page_idx": 17}, {"type": "text", "text": "In this step, we follow the approach of $\\mathrm{Ng}$ et al. [61] to cluster the graph in $m$ components. The clusters define $m$ disjoint segments $A_{1},\\overleftarrow{A_{2}},\\ldots,\\overleftarrow{A_{m}}\\left(\\bigcup_{i=1}^{m}A_{i}=V,\\overleftarrow{\\bigcap_{i=1}^{m}A_{i}}=\\emptyset\\right)$ of $G$ with high intra-cluster degree of semantic similarity. ", "page_idx": 17}, {"type": "text", "text": "In the second step, we adopt a top-down recursive divisive clustering approach, building a hierarchical semantic decomposition of the image. In the recursive call at a certain level $l$ and for a certain subgraph $c$ \u2014 notice that here $c$ is an index \u2014 of a graph $p$ we define an undirected condensed graph $G_{c}^{l,p}\\;=\\;\\left(V_{c}^{l,p},E_{c}^{l,p},\\tilde{w}\\right)$ , with segments $A$ as nodes in $V_{c}^{l,p}\\;(\\bigcup_{A\\in V_{c}^{l,p}}A\\;\\subseteq\\;V)$ , $\\bigcap_{A\\in V_{c}^{l,p}}A~=~\\emptyset)$ and the edges are weighted by the associativity degree of the components $\\begin{array}{r}{\\tilde{w}(A_{i},A_{j})\\,=\\,\\sum_{u\\in A_{i},v\\in A_{j}}{w(u,v)}}\\end{array}$ . Notice that the condensed graph at the root level is indicated as $G_{0}^{0,0}\\,=\\,(V_{0}^{0,0},E_{0}^{0,0},\\tilde{w})$ and $V_{0}^{0,0}\\,=\\,\\{A_{i}\\}_{i=1}^{m}$ . At each depth, we obtain a semantic grouping $S^{l}=\\{V_{i}^{l+1,c}\\}_{c,i}$ given by all the $i$ -th subgraphs at level $l+1$ of each subgraph $c$ at level $l$ . ", "page_idx": 17}, {"type": "text", "text": "", "page_idx": 18}, {"type": "text", "text": "The recursion defines the final hierarchy, namely the output tree $T$ ", "page_idx": 18}, {"type": "text", "text": "The semantic grouping algorithm discussed here builds upon conventional spectral clustering methods [74, 61, 6, 81]. ", "page_idx": 18}, {"type": "text", "text": "Algorithm 1: Image Parsing via Granularity and Hierarchy-agnostic Semantic Regions Tree ", "text_level": 1, "page_idx": 18}, {"type": "text", "text": "Data: $V$ : set of points $w$ : points similarity function $m$ : desired number of superpixels $\\tilde{w}$ : components similarity function $k_{m a x}$ : max number of subgraph components $k_{m i n}$ : min number of subgraph points $\\lambda_{m a x}$ : max normalized smoothness threshold $p_{m a x}$ : max perturbation threshold ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{V_{0}^{0,0}=\\{A_{i}\\}_{i=1}^{m}=\\mathsf{s p e c t r a l\\mathrm{\\mathrm{-}}0\\boldsymbol{\\nabla}\\mathsf{e r c l u s t e r i n g}}(V)}\\\\ &{\\{S^{l}\\}_{l=1}^{\\ell}=\\mathsf{b f s\\mathrm{\\mathrm{-}}p a r t i t i t i o n i n g}(\\{V_{0}^{0,0}\\})}\\end{array}\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "Function spectral_overclustering $(V)$ : Compute $L$ for graph $G=(V,E,\\bar{w})$ $\\begin{array}{r}{Y\\gets\\arg\\operatorname*{min}_{Y\\in\\mathbb{R}^{|V|\\times m},Y^{\\top}Y=I}\\operatorname{Tr}(Y^{\\top}L Y)}\\end{array}$ Normalize rows $\\begin{array}{r}{X_{i j}=Y_{i j}/(\\sum_{j}Y_{i j}^{2})^{1/2}}\\end{array}$ Group $X$ rows in $m$ clusters with K-means return $m$ groups $\\{A_{i}\\}_{i=1}^{m}$ of $V$ ", "page_idx": 18}, {"type": "text", "text": "Function bfs_partitioning $(S^{l})$ : $S^{l+1}\\gets\\{\\}$ foreach segment $V_{c}^{l,p}\\in S^{l}$ do $n\\leftarrow\\left|V_{c}^{l,p}\\right|$ if $n<k_{m i n}$ then continue end Get condensed graph $G\\gets G_{c}^{l,p}=(V_{c}^{l,p},E_{c}^{l,p},\\tilde{w})$ Scale $W$ with min-max normalization and compute $L$ $Y\\gets\\arg\\operatorname*{min}_{Y\\in\\mathbb{R}^{n\\times k_{m a x}},Y^{\\top}Y=I}\\mathrm{Tr}(Y^{\\top}L Y)$ $\\lambda\\leftarrow\\operatorname{diag}(Y^{\\top}L Y)$ Reorder $Y$ columns and $\\lambda$ in ascending order of $\\lambda_{i}$ $k\\leftarrow\\arg\\operatorname*{max}_{i}\\{\\lambda_{i}-\\lambda_{i-1}\\}_{i=2}^{k_{m a x}-1},\\lambda_{i-1}<\\lambda_{m a x}$ if \u2204k then continue end Take first $k$ eigenvectors $Y\\leftarrow Y_{[:,1:k]}$ Normalize rows $\\begin{array}{r}{X_{i,j}=Y_{i,j}/(\\sum_{j}Y_{i,j}^{2})^{1/2}}\\end{array}$ Group $X$ rows in $k$ clusters with $\\mathbf{K}$ -means and get $L^{\\prime}$ Compute perturbation $H=L-L^{\\prime}$ if $2\\operatorname*{min}(k^{1/2}\\|H\\|_{o p},\\|H\\|_{F})/(\\lambda_{k}-\\lambda_{k-1})>k\\,p_{m a x}$ then continue end Found stable $k$ subgraphs estimate $S_{c}^{l+1}=\\{V_{i}^{l+1,c}\\}_{i=1}^{k}$ ,c}ik=1 of V cl,p $S^{l+1}{\\leftarrow}S^{l+1}\\cup S_{c}^{l+1}$ end return $\\{S^{l+1}\\}\\subset$ bfs_partitioning $\\left(S^{l+1}\\right)$ ", "page_idx": 18}, {"type": "text", "text": "Discussion above the algorithm. The algorithm\u2019s design integrates several properties that significantly shape semantic components\u2019 hierarchical structure and connectivity. ", "page_idx": 19}, {"type": "text", "text": "One crucial feature is the dynamic estimation of the number of components, $k$ , a parameter closely aligned with insights from perturbation theory. This estimate directly influences segmentation granularity, determining the expected number of distinct semantic regions and hierarchy levels in the final output. ", "page_idx": 19}, {"type": "text", "text": "The algorithm produces a hierarchy-agnostic, unsupervised semantic region tree $T$ . At each recursion stage, it seeks subgraphs that represent loosely connected regions based on robust algebraic criteria from graph theory, capturing coherent semantic regions at each level of granularity. By isolating each region from the context of previous layers, the algorithm accurately reflects the semantic hierarchy within the image\u2019s content. In this framework, the tree\u2019s leaves represent regions with high intra-cluster semantic similarity, positioning these clusters as primitives of broader concepts at higher levels. The algorithm naturally embeds semantic inclusion, where finer semantic regions exist within larger semantic contexts, mirroring how complex concepts encompass finer details. ", "page_idx": 19}, {"type": "text", "text": "Lastly, computing the adjacency matrix only once optimizes efficiency, reducing redundant operations and improving runtime performance, making the approach both scalable and effective for large datasets. ", "page_idx": 19}, {"type": "text", "text": "Time Complexity. The breadth-first search has a time complexity of $\\mathcal{O}(|V|+|E|)$ on a general graph. In our case, with $n$ nodes and $n-1$ edges (assuming a tree graph), BFS has complexity $\\bar{\\mathcal{O}}(\\bar{n}+(n-1))=\\mathcal{O}(2n-1)\\underline{{\\phantom{.}}}=\\mathcal{O}(n)$ . The eigendecomposition of a symmetric matrix in the worst case has a complexity of ${\\mathcal{O}}(n^{3})$ . Therefore, the combined time complexity is $O(n+n^{3})=O(n^{3})$ . However, because we only compute the smallest $k_{\\operatorname*{max}}\\ll n$ eigenvectors, the time complexity of the eigendecomposition reduces to $\\bar{\\mathcal{O}}(k_{\\mathrm{max}}n^{2})$ . Thus, the overall complexity becomes $\\bar{O(n+k_{\\mathrm{max}}n^{2})}=$ $\\bar{O(k_{\\mathrm{max}}n^{2})}$ , since $k_{\\mathrm{max}}n^{2}$ dominates $n$ . ", "page_idx": 19}, {"type": "text", "text": "The recursive partitioning process starts with an eigendecomposition on the full graph, which has a time complexity of $\\mathcal{O}(\\bar{k}_{\\operatorname*{max}}n^{2})$ for extracting the smallest $k_{\\mathrm{max}}$ eigenvectors. This initial computation is the primary contributor to the algorithm\u2019s time complexity. As the partitioning proceeds, each recursive call operates on progressively smaller subgraphs. While each subgraph requires an eigendecomposition, the cost decreases significantly as the graph size is reduced at each recursion level. For balanced partitioning, the cumulative cost of these recursive steps remains asymptotically bounded by the initial computation on the full graph. Thus, the overall complexity is effective $\\mathcal{O}(\\dot{k}_{\\mathrm{max}}n^{2})$ , ensuring computational feasibility even for large graphs. ", "page_idx": 19}, {"type": "text", "text": "C Graph Partitioning with Normalised Cut ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "We recall here the Normalised Cut (NCut) introduced by Shi and Malik [74] for measuring the goodness of a graph partition. ", "page_idx": 19}, {"type": "text", "text": "Let $G\\,=\\,(V,E,w)$ be a weighted undirected graph, having $n$ nodes, $V\\,=\\,\\{v_{i}\\}_{i=1}^{n}$ , representing points $v_{i}\\in\\mathbb{R}^{d}$ . The weight on each edge of the graph $w_{i j}=w(v_{i},v_{j})$ is a function of the similarity between nodes $v_{i}$ and $v_{j}$ and defines an element of the adjacency matrix $W\\,=\\,[w_{i j}]\\,\\in\\,[0,1]^{n\\times n}$ . The symmetrically normalised Laplacian of the graph [59] is defined as, $L=D^{-1/2}(D{-}W)D^{-1/2}$ , with $D=\\mathrm{diag}\\left[d_{i}\\right]\\in\\mathbb{R}^{n\\times n}$ the diagonal degree matrix and $\\begin{array}{r}{d_{i}=\\sum_{j}w_{i j}}\\end{array}$ . ", "page_idx": 19}, {"type": "text", "text": "The normalised cut objective aims to partition the set $V$ into two disjoint sets $A\\subset V$ and $B\\subset V$ $\\operatorname{\\mu}(A\\cup B\\,=\\,V$ , $A\\cap B\\,=\\,\\emptyset$ ) while minimising the degree of similarity between the two sets and maximising the one within each set, and it is defined as: ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\operatorname{NCut}(A,B):={\\frac{\\operatorname{cut}(A,B)}{\\operatorname{assoc}(A,V)}}+{\\frac{\\operatorname{cut}(A,B)}{\\operatorname{assoc}(B,V)}}\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "where $\\textstyle\\operatorname{cut}(A,B)\\ =\\ \\sum_{u\\in A,v\\in B}w(u,v)$ measures the degree of similarity between $A$ and $B$ and is equal to the total weight of edges that the partitioning has removed, a $\\sec(A,V)\\;\\;=\\;\\;$ $\\textstyle\\sum_{u\\in A,t\\in V}w(u,t)$ measures the degree of similarity between $A$ and $V$ , and $\\operatorname{assoc}(B,V)$ is equivalently defined. The NCut is an unbiased measure of the normalised total similarity of the two sets of points. Indeed, normalisation avoids unnatural bias when partitioning out small sets of points. Minimising exactly Equation (12) is NP-complete, according to the proof due to Papadimitriou [74]. ", "page_idx": 19}, {"type": "text", "text": "However, [74] shows a tractable real-valued solution to the relaxed problem in Equation (12) can be obtained by solving the generalized eigenvalue system $(D-W)x\\stackrel{\\cdot}{=}\\lambda D x$ , for $x\\in\\mathbb{R}^{n}$ and $\\lambda\\in\\mathbb R$ . The eigenvectors $x_{i}$ span an orthogonal basis for functions on $G$ [81]: ", "page_idx": 20}, {"type": "equation", "text": "$$\nx_{i}=\\operatorname*{arg\\,min}_{\\substack{x\\in\\mathbb{R}^{n},\\|x\\|=1,x\\perp x_{<i}}}x^{\\top}L x,\\;\\;\\mathrm{with}\\;i=1,\\ldots,n-1\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "with $x_{0}\\,=\\,\\!1\\,\\in\\,\\mathbb{R}^{n}$ . The eigenvalues $\\lambda_{i}$ , with $0\\,=\\,\\lambda_{0}\\,\\leq\\,\\lambda_{1}\\,\\leq\\,\\cdot\\,\\cdot\\,\\leq\\,\\lambda_{n-1}$ , are the values of the right-hand side of the above expression. The eigenvector $x_{1}$ corresponding to the second smallest eigenvalue $\\lambda_{1}$ of $L$ is the non-trivial solution to the quadratic form in Equation (13), called the Fiedler vector [29]. However, this real-valued solution can be transformed into a discrete form to partition the set $V$ in two disjoint sets $A$ and $B$ approximating the solution to the normalised cut problem in Equation (12) [74]. ", "page_idx": 20}, {"type": "text", "text": "The former approach can be expanded to further partition the generated subgraphs, employing the subsequent eigenvectors. Indeed, the eigenvector $x_{2}$ linked to the third smallest eigenvalue $\\lambda_{2}$ efficiently divides into two parts, $A$ and $B$ . However, the practical application reveals that if higher eigenvectors are used, the gap between real-valued and discrete-valued solutions widens, asking for a global mutual orthogonality constraint for all eigenvectors. Consequently, solutions relying on higher eigenvectors tend to be less dependable. It is often more advantageous to restart the partitioning process for each subgraph separately [74]. ", "page_idx": 20}, {"type": "text", "text": "D More about Experiments and Metrics ", "text_level": 1, "page_idx": 20}, {"type": "text", "text": "The code implementation is in Python 3. We ran experiments on an ASUS ESC8000 server with two AMD EPYC 7413 24-core processors and 256GB RAM. We used the PyTorch 2.3 deep learning framework and 2 NVIDIA A6000 GPUs with 48GB of VRAM to accelerate the feature extraction stage. For all the experiments in the paper, we ran our algorithm with the Python multi-threading library joblib up to 96 workers. ", "page_idx": 20}, {"type": "text", "text": "D.1 Datasets ", "text_level": 1, "page_idx": 20}, {"type": "text", "text": "PascalVOC2012 [27] is a generic object-centric semantic segmentation dataset of 20 object categories and a background class. It consists of 1, 449 images for validation. We follow [12] to obtain a larger image set with additional annotations [34], resulting in 10, 582 images. ", "page_idx": 20}, {"type": "text", "text": "COCO-Stuff [10] is a complex scene-centric dataset that extends the object-centric MSCOCO [53] dataset, with a high-level hierarchical structure. Concepts are split at the root level into things and stuff, each having outdoor and indoor subsets. There are 12 things and 15 stuff supercategories, and 80 things and 91 stuff categories. Objects appear in complex scenes, with more thing objects per image than PascalVOC2012 (7.3 vs. 2.3). Following [78, 84], we use val2017 split of 5, 000 images. ", "page_idx": 20}, {"type": "text", "text": "Potsdam, Vaihingen [30] are scene-centric datasets for aerial scene parsing with 6 categories (roads, cars, vegetation, trees, buildings, clutter). The raw $6000\\,\\times\\,6000$ images are divided into 100 RGB $600\\times600$ patches. We obtain a total of 3, 800 images for Potsdam and 3, 300 images for Vaihingen. ", "page_idx": 20}, {"type": "text", "text": "Cityscapes [21] is an urban street scene-centric dataset with a high-level hierarchical structure, having 7 supercategories subdivided into 19 stuff and object categories. Unlike COCO-Stuff and PascalVOC2012, where classes appear in many scene contexts, Cityscapes contains similar street scenes that cover almost all 19 categories. The test split has 500 images. ", "page_idx": 20}, {"type": "text", "text": "Mapillary Vistats [60] is an urban street scene-centric dataset with a high-level hierarchical structure, having 6 root-level categories subdivided into 37 supercategories and finally 66 categories. Unlike Cityscapes and KITTI-STEP, street scenes are captured from various environments worldwide, including several countries, weather conditions, and seasons. It aims to provide a diverse set of street scenes. The validation split has 2, 000 images. ", "page_idx": 20}, {"type": "text", "text": "KITTI-STEP [89], KITTI-SS [1] are datasets for urban scene understanding, instance detection, and object tracking. They have the same categories as Cityscapes and the same hierarchical structure. There are 2, 981 validation frames of KITTI-STEP, 200 test images of KITTI-SS. ", "page_idx": 20}, {"type": "text", "text": "Pascal-Part [15] is an extension of the PascalVOC2010 [27] dataset, designed specifically for finegrained annotations of objects. It is a part-centric dataset with a low-level hierarchical structure. It contains 20 object classes, each subdivided into low-level parts (i.e., head, left/right-eye, torso, left/right-arm, etc., for category person) for a total of 198 distinct part classes and a background category. The dataset contains 10, 103 images.   \nPartImageNet [35] is a part-centric dataset with a low-level hierarchical structure designed for fine-grained part segmentation. It extends the ImageNet dataset by providing detailed part annotations for a subset of the images. It has 11 object supercategories and 39 part supercategories. PartImagenet-158 [35] arranges the annotation by ImageNet categories, counting 158 object classes and a total of 597 part categories. The validation set contains a total of 2, 957 images. ", "page_idx": 21}, {"type": "image", "img_path": "ELnxXc8pik/tmp/0493daeffdd930d934b614e93b37a09a919e85e1ac6b69e07510bf6ba1ee16a8.jpg", "img_caption": ["Figure 7: Normalised Multigranular Covering (NMCovering) examples. For each available ground truth categorical region $R$ in the semantic map $S_{g t}$ (left), we evaluate the overlap with the unrolled segments $R^{\\prime}$ in the predicted region tree, e.g. $T_{1}$ . The yellow labels indicate the maximum IoU matching correspondence between the ground truth and the prediction. Green line borders indicate high-score matching and red line borders indicate low-score matching. We propose two high-scoring predictions (centre) and two low-scoring (right). The total NMCovering is the average sum of the matching scores, as defined in Equation (3). The NMCovering metric evaluates the granularity-independent performance of the semantic segmentation model. The absence of correct semantic regions in $T_{3}$ and $T_{4}$ yields low score matches; see plate $C$ in $T_{3}$ and plate $B$ in $T_{4}$ . "], "img_footnote": [], "page_idx": 21}, {"type": "text", "text": "D.2 Discussion About The Metrics ", "text_level": 1, "page_idx": 21}, {"type": "text", "text": "We average the metrics over each image in the dataset, ensuring a comprehensive assessment across varying image contexts. In the hierarchical scenario, the score gives equal importance to all levels, recognising the significance of coarse and fine-grained segmentation. This approach reflects the nuanced structure of hierarchical data, where higher and lower granularity levels provide complementary insights. ", "page_idx": 21}, {"type": "text", "text": "The maximum overlap heuristics we use do not enforce exclusive matching. We intentionally choose this method to accommodate scenarios where regions in subsequent hierarchical levels overlap. For instance, in an image of human hands, the coarse category person may overlap with the finer category hand. An exclusive matching strategy might misinterpret this overlap, leading to an inaccurate assessment of segmentation performance. Our approach acknowledges such overlaps, providing a more realistic evaluation. ", "page_idx": 21}, {"type": "text", "text": "Additionally, the granularity of ground-truth annotations is often limited. To address this, our evaluation process disregards predictions that do not best match any annotated object, treating them as neither true positives nor false positives. This avoids penalising the model for predicting more detailed segments than the available annotations. Moreover, this approach permits the evaluation of the model according to standard category micro and macro-averaged segmentation metrics [56] such as the micro pixel Accuracy (pAcc) and the macro mean pixel Accuracy (mAcc), the per-class Intersection over Union (IoU) and the relative macro mean IoU (mIoU), and micro frequency weighted IoU (fIoU). ", "page_idx": 21}, {"type": "image", "img_path": "ELnxXc8pik/tmp/1c907ac1421231c170ccc64ef3d43271a7800d893996e146b063e6ac87d0fb2f.jpg", "img_caption": ["Figure 8: Normalised Hierarchical Covering (NHCovering) computation example. Given the semantic tree $T_{g t}$ (left), for each available ground truth categorical region $R$ , we evaluate the overlap with the unrolled segments $R^{\\prime}$ in the predicted region tree $T$ . We consider one low-score lineage prediction edge $(R_{1}^{\\prime},R_{4}^{\\prime})$ and one high-score $(R_{2}^{\\prime},R_{5}^{\\prime})$ . The yellow labels indicate the maximum IoU matching correspondence between the ground truth and the predicted regions. Green and red arrows indicate correct and wrong lineage prediction, respectively. The total NHCovering is the sum of the matching scores weighted by the ratio of correct lineages, as reported in Equation (4). The NHCovering metric assesses the granularity and hierarchy-independent performance of the semantic segmentation model. Examples of lineage-weight computation are reported for the $E$ and $D$ matching, on the right, using the operators $\\pi(\\cdot)$ and $\\bar{\\beta(\\cdot,\\cdot)}$ defined in Section 4.1. "], "img_footnote": [], "page_idx": 22}, {"type": "text", "text": "Interestingly, the NMCovering metric can define an upper bound for the NHCovering score with appropriate modifications. Specifically, we find that NHCovering $(T\\to T_{g t})\\leq\\mathrm{NMCovering}(T\\to$ $T_{g t}$ ). Equality between these metrics would indicate optimal model performance in terms of hierarchical inclusion, suggesting that the model not only segments accurately but also respects the hierarchical structure of the ground truth. Figures 7 and 8 offers finer insight into the metrics purpose. ", "page_idx": 22}, {"type": "text", "text": "These metrics provide a robust framework for evaluating hierarchical segmentation models, balancing granularity and hierarchical accuracy while accounting for the inherent complexities in realworld image data. ", "page_idx": 22}, {"type": "text", "text": "D.3 Quantitative Results ", "text_level": 1, "page_idx": 22}, {"type": "text", "text": "Our hierarchical semantic segmentation algorithm demonstrates strong performance across multiple datasets and hierarchical segmentation tasks, effectively capturing meaningful semantic structures at various levels of granularity. ", "page_idx": 22}, {"type": "text", "text": "Table 7 showcases the comparative strength of our method, achieving high NMCovering scores against other low-level pixel hierarchical clustering algorithms. With $\\lambda_{\\mathrm{max}}\\,=\\,0.6$ , our approach effectively segments the validation set into hierarchical clusters that closely align with ground-truth structures, indicating robustness in preserving semantic hierarchies. ", "page_idx": 22}, {"type": "text", "text": "Table 8 further illustrate our algorithm\u2019s adaptability in aerial scene segmentation, achieving notable NMCovering scores on both train sets. Using DINO-ViT-B8 features with $\\lambda_{\\mathrm{max}}\\,=\\,0.9$ , the algorithm accurately segments six primary categories, confirming its applicability to complex geospatial datasets where hierarchical segmentation is critical. ", "page_idx": 22}, {"type": "text", "text": "Tables 9 and 10 highlight our model\u2019s proficiency in urban scene segmentation, achieving high NHCovering and mIoU scores across 19 categories and seven supercategories. Notably, the use of hierarchical labels in Table 9 and detailed category IoUs in Table 10 show the model\u2019s capability to distinguish fine-grained features within broader urban contexts. This performance suggests our approach can effectively capture semantic structures across varying levels of granularity, making it well-suited for dynamic urban environments. ", "page_idx": 22}, {"type": "text", "text": "Table 13 is a challenging benchmark with its extensive hierarchy of \u2018thing\u2019 and \u2018stuff\u2019 categories, totalling 182 classes and 27 supercategories. Our algorithm achieves competitive performance across both high-level supercategories and fine-grained categories, achieving strong IoU scores across each subset. This indicates that the algorithm effectively balances both coarse and fine semantic segmentation layers, enabling nuanced representation across diverse objects and materials. ", "page_idx": 22}, {"type": "text", "text": "", "page_idx": 23}, {"type": "text", "text": "In Table 11, focused on Conditional Random Field (CRF) post-processing, our method shows that including CRF enhances segmentation accuracy across various datasets, validating its role in refining boundaries for complex regions. Additionally, comparisons with non-hierarchical spectral clustering methods Table 12 underscore our approach\u2019s advantage in multi-level segmentation, achieving higher NMCovering scores and consistent performance even without the need for CRF postprocessing. ", "page_idx": 23}, {"type": "text", "text": "Table 7: Boundary potential vs. semantic smoothness. Comparison among hierarchical clustering algorithms in terms of NMCovering on PascalVOC2012 val set for $\\lambda_{m a x}=0.6$ . ", "page_idx": 23}, {"type": "image", "img_path": "ELnxXc8pik/tmp/c1122b77f265cd2b2410bf81612bdd71be8e108d97e2a6a91a068c79904471b1.jpg", "img_caption": [], "img_footnote": [], "page_idx": 23}, {"type": "text", "text": "Table 8: Hierarchical semantic segmentation on Potsdam and Vaihingen train sets. We use DINO-ViT-B8 [11] features and $\\lambda_{m a x}=0.9$ . The two datasets have six categories. Segmentation performances are computed using NMCovering for ground truth masks exclusive matching. ", "page_idx": 23}, {"type": "table", "img_path": "ELnxXc8pik/tmp/ddd2a1afe0318fc0e55719a18416c345e03428546c5241a2cad6b2af2a7ff071.jpg", "table_caption": [], "table_footnote": [], "page_idx": 23}, {"type": "text", "text": "Table 9: Hierarchical semantic segmentation on Cityscapes and KITTI-STEP val sets and KITTI-SS train set. We use DINO-ViT-B8 [11] features and $\\lambda_{m a x}=0.8$ . The three datasets have 19 valid categories from the Cityscapes dataset divided into seven supercategories. Segmentation performances are computed using NHCovering for ground truth masks exclusive matching. ", "text_level": 1, "page_idx": 23}, {"type": "table", "img_path": "ELnxXc8pik/tmp/e6d9f86c22bcf1bbd9195fce80a328ac57adb8bf44032f6ad629909588ed69e3.jpg", "table_caption": [], "table_footnote": [], "page_idx": 23}, {"type": "text", "text": "Table 10: Hierarchical semantic segmentation on Cityscapes and KITTI-STEP val sets and KITTI-SS train set. We use DINO-ViT-B8 [11] features and $\\lambda_{m a x}=0.8$ . The three datasets have 19 valid categories from the Cityscapes dataset. Segmentation performances are computed using NHCovering for exclusive matching of predictions with ground truth masks. From the second column, we show the relative category IoU. Last four columns show mean IoU (mIoU), frequency weighted IoU (fIoU), pixel accuracy (pAcc) and mean accuracy (mAcc). ", "page_idx": 23}, {"type": "image", "img_path": "ELnxXc8pik/tmp/87a9b4f392efaf7b34c40d345ba4102f265ecd04fbff4a9b8745b213225085f0.jpg", "img_caption": [], "img_footnote": [], "page_idx": 23}, {"type": "table", "img_path": "ELnxXc8pik/tmp/8b8c7bcdcb95b721c2ee57fca0ed60a7d3e715f82eeee9f5f036534d4e15ab1d.jpg", "table_caption": ["Table 11: CRF ablation. We use maximum overlap for ground-truth category matching. "], "table_footnote": [], "page_idx": 23}, {"type": "text", "text": "Table 12: Recursive vs. simultaneous on PascalVOC2012 val set. Comparison between deep recursive (Ours) and simultaneous spectral clustering (Melas-Kyriazi et al. [58]) for $m=\\{4,8,16\\}$ using a maximum overlap for category matching in each image. All the experiments run on preextracted features with DINO-ViT-S8 [11], without CRF. The other parameters are defaulted in Section 4. Notice that for simultaneous clustering the NMCovering equals the NFCovering [44]. ", "page_idx": 23}, {"type": "image", "img_path": "ELnxXc8pik/tmp/38cf21d41d285a5156ffd3525543909528837ccf546e26bd98bee5a2b834003e.jpg", "img_caption": [], "img_footnote": [], "page_idx": 23}, {"type": "text", "text": "Table 13: Hierarchical semantic segmentation on the COCO-Stuff val set. We use DINO-ViTB8 [11] features and $\\lambda_{m a x}\\,=\\,0.6$ . COCO-Stuff dataset has 91 \u2019thing\u2019 categories (inherited from MSCOCO), 91 \u2019stuff\u2019 categories and 27 supercategories. Segmentation performances are computed using NHCovering for exclusive matching of predictions with ground truth masks. The rows show the hierarchical structure of COCO-Stuff. The first column shows the separation between things/stuff. The second column shows supercategory labels (Coarse Tags), the third column shows the relative supercategory IoU $(\\mathrm{IoU}^{S})$ when considering all supercategories together, and the fourth column considers 12 things supercategories only, and the fifth column considers 15 stuff supercategories only. Sixth column shows leaf labels (Fine Tags), seventh column shows relative category IoU (IoU) when considering all categories, the eighth column considers 91 thing categories only and the ninth column considers 91 stuff categories only. Last row shows mean IoU (mIoU), frequency weighted IoU (fIoU), pixel accuracy (pAcc), and mean accuracy (mAcc) for each experiment. Here, accuracy values are reported in the decimal range [0, 1]. ", "page_idx": 24}, {"type": "table", "img_path": "ELnxXc8pik/tmp/cb1cd52c3911b903db12a2c6e1ad8efe4e6d3f80e019bc0c599778af19a3f9a1.jpg", "table_caption": [], "table_footnote": [], "page_idx": 24}, {"type": "image", "img_path": "ELnxXc8pik/tmp/072742593c3042a52c7d36df9d5d8b14375273e49a33cda77390c9d0769f0516.jpg", "img_caption": ["Figure 9: Qualitative results on PascalVOC2012. Random sampling from a subset of our results, refined with CRF, having NMCovering greater than $70\\%$ . We show predicted subtrees (right) overlapping with semantic masks (left). Heatmap colours encode leaves\u2019 distance in the subtrees. "], "img_footnote": [], "page_idx": 25}, {"type": "image", "img_path": "ELnxXc8pik/tmp/bc995423f469417c2479e9d26fa0da38ea9948a580c1bf6b0aaedd3328e67029.jpg", "img_caption": ["Figure 10: Qualitative results on PartImageNet. Random sampling from a subset of our results, refined with CRF, having NHCovering greater than $70\\%$ . The left column shows the ground truth part masks. The second to fifth column shows the predicted regions for each tree depth. "], "img_footnote": [], "page_idx": 26}, {"type": "image", "img_path": "ELnxXc8pik/tmp/6438abf94f15fafc02af9c4bcabbac4ddcb035f9314f875185a3067b03f18940.jpg", "img_caption": ["Figure 11: Qualitative results on PartImageNet. Random sampling from a subset of our results, refined with CRF, having NHCovering lower than $20\\%$ . The image shows failures in identifying very small parts. The left column shows the ground truth part masks. The second to fifth column shows the predicted regions for each tree depth. The prediction colour code does not reflect the ground truth one. "], "img_footnote": [], "page_idx": 27}, {"type": "image", "img_path": "ELnxXc8pik/tmp/13e78fedf7c5a5d8d7337dc89bc07c327d2cba88846ff5f8a837bf9b120fe817.jpg", "img_caption": ["Figure 12: Qualitative results on PascalVOC2012. Random sampling from a subset of our results, refined with CRF, having NMCovering greater than $70\\%$ . We assign unsupervised masks to the best overlapping classes. "], "img_footnote": [], "page_idx": 28}, {"type": "image", "img_path": "ELnxXc8pik/tmp/689754cf1c4bec7b5ec2abd854ae8615656afb444062f2c9bc4aa5f3cf249e0d.jpg", "img_caption": ["Figure 13: Qualitative results on COCO-Stuff. Random sampling from a subset of our results, refined with CRF, with NMCovering greater than $60\\%$ . We assign unsupervised masks to the best overlapping classes. "], "img_footnote": [], "page_idx": 29}, {"type": "image", "img_path": "ELnxXc8pik/tmp/b5c899314831a3e54af11bb98e63937ae1ced98ec94199a42aecff473ebd2d7d.jpg", "img_caption": ["Figure 14: Qualitative results on Cityscapes. Random sampling from a subset of our results, refined with CRF, with NMCovering greater than $40\\%$ . We assign unsupervised masks to the best overlapping classes. "], "img_footnote": [], "page_idx": 30}, {"type": "text", "text": "NeurIPS Paper Checklist ", "text_level": 1, "page_idx": 31}, {"type": "text", "text": "1. Claims ", "text_level": 1, "page_idx": 31}, {"type": "text", "text": "Question: Do the main claims made in the abstract and introduction accurately reflect the paper\u2019s contributions and scope? ", "page_idx": 31}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 31}, {"type": "text", "text": "Justification: We introduce and explain the reasons for the new problem setting in Section 3 and our new metric in Section 4.1. The task also defines a new downstream task for SSL, which does not require additional training or prior, and reports some baselines in Table 5. We introduce our algebraic method for image pixel parsing via semantic regions tree in Section 3.1. In the same section, we define our smoothness criteria for deep features graph partitioning and our method for dynamically establishing connected components. In Tables 1 and 2, we conduct several experiments to validate the robustness of our algorithm on different datasets. In Tables 5 and 6, we report ablation experiments to assess the importance of each algorithm component. In Table 3, we compare our results with different semantic segmentation supervision strategies to benchmark the segmentation quality of our approach; at the same time, we demonstrate that the proposed hierarchical image parsing effectively found visual semantic concepts in the images of a dataset, whether they are object or scene centric, see Table 1, and whole or part centric, see Tables 2 and 6b. Further experiments in Table 4 demonstrate the effectiveness of the algorithm in capturing semantic hierarchical relationships and an improvement over previous traditional hierarchical models used nowadays in some unsupervised semantic segmentation SOTA to drive the optimization. We hope our findings may improve research in this direction. ", "page_idx": 31}, {"type": "text", "text": "Guidelines: ", "page_idx": 31}, {"type": "text", "text": "\u2022 The answer NA means that the abstract and introduction do not include the claims made in the paper.   \n\u2022 The abstract and/or introduction should clearly state the claims made, including the contributions made in the paper and important assumptions and limitations. A No or NA answer to this question will not be perceived well by the reviewers.   \n\u2022 The claims made should match theoretical and experimental results, and reflect how much the results can be expected to generalize to other settings.   \n\u2022 It is fine to include aspirational goals as motivation as long as it is clear that these goals are not attained by the paper. ", "page_idx": 31}, {"type": "text", "text": "2. Limitations ", "text_level": 1, "page_idx": 31}, {"type": "text", "text": "Question: Does the paper discuss the limitations of the work performed by the authors? Answer: [Yes] ", "page_idx": 31}, {"type": "text", "text": "Justification: See Section 5. ", "page_idx": 31}, {"type": "text", "text": "Guidelines: ", "page_idx": 31}, {"type": "text", "text": "\u2022 The answer NA means that the paper has no limitation while the answer No means that the paper has limitations, but those are not discussed in the paper.   \n\u2022 The authors are encouraged to create a separate \"Limitations\" section in their paper.   \n\u2022 The paper should point out any strong assumptions and how robust the results are to violations of these assumptions (e.g., independence assumptions, noiseless settings, model well-specification, asymptotic approximations only holding locally). The authors should reflect on how these assumptions might be violated in practice and what the implications would be.   \n\u2022 The authors should reflect on the scope of the claims made, e.g., if the approach was only tested on a few datasets or with a few runs. In general, empirical results often depend on implicit assumptions, which should be articulated.   \n\u2022 The authors should reflect on the factors that influence the performance of the approach. For example, a facial recognition algorithm may perform poorly when image resolution is low or images are taken in low lighting. Or a speech-to-text system might not be used reliably to provide closed captions for online lectures because it fails to handle technical jargon.   \n\u2022 The authors should discuss the computational efficiency of the proposed algorithms and how they scale with dataset size.   \n\u2022 If applicable, the authors should discuss possible limitations of their approach to address problems of privacy and fairness.   \n\u2022 While the authors might fear that complete honesty about limitations might be used by reviewers as grounds for rejection, a worse outcome might be that reviewers discover limitations that aren\u2019t acknowledged in the paper. The authors should use their best judgment and recognize that individual actions in favor of transparency play an important role in developing norms that preserve the integrity of the community. Reviewers will be specifically instructed to not penalize honesty concerning limitations. ", "page_idx": 31}, {"type": "text", "text": "", "page_idx": 32}, {"type": "text", "text": "3. Theory Assumptions and Proofs ", "text_level": 1, "page_idx": 32}, {"type": "text", "text": "Question: For each theoretical result, does the paper provide the full set of assumptions and a complete (and correct) proof? ", "page_idx": 32}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 32}, {"type": "text", "text": "Justification: We refer to theorem which are fully reported and referred. ", "page_idx": 32}, {"type": "text", "text": "Guidelines: ", "page_idx": 32}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include theoretical results.   \n\u2022 All the theorems, formulas, and proofs in the paper should be numbered and crossreferenced.   \n\u2022 All assumptions should be clearly stated or referenced in the statement of any theorems.   \n\u2022 The proofs can either appear in the main paper or the supplemental material, but if they appear in the supplemental material, the authors are encouraged to provide a short proof sketch to provide intuition.   \n\u2022 Inversely, any informal proof provided in the core of the paper should be complemented by formal proofs provided in appendix or supplemental material.   \n\u2022 Theorems and Lemmas that the proof relies upon should be properly referenced. ", "page_idx": 32}, {"type": "text", "text": "4. Experimental Result Reproducibility ", "text_level": 1, "page_idx": 32}, {"type": "text", "text": "Question: Does the paper fully disclose all the information needed to reproduce the main experimental results of the paper to the extent that it affects the main claims and/or conclusions of the paper (regardless of whether the code and data are provided or not)? ", "page_idx": 32}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 32}, {"type": "text", "text": "Justification: As stated in Section 4, to have full reproducibility, we adopt publicly available deep network checkpoints and do not perform any retraining. We evaluate our algorithm on publicly available datasets and use full validation sets. Our algorithm is deeply described in Section 3, and our code is shown in the appendix, Algorithm 1. The used backbone, the superpixel clustering method, the $k_{m i n},p_{m a x}$ and $\\lambda_{m a x}$ values are the variables needed to reproduce the results. We clearly state their values in Section 4 and table 6. Implementation details beyond the standard algorithm are reported in Appendix D. ", "page_idx": 32}, {"type": "text", "text": "Guidelines: ", "page_idx": 32}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 If the paper includes experiments, a No answer to this question will not be perceived well by the reviewers: Making the paper reproducible is important, regardless of whether the code and data are provided or not.   \n\u2022 If the contribution is a dataset and/or model, the authors should describe the steps taken to make their results reproducible or verifiable.   \n\u2022 Depending on the contribution, reproducibility can be accomplished in various ways. For example, if the contribution is a novel architecture, describing the architecture fully might suffice, or if the contribution is a specific model and empirical evaluation, it may be necessary to either make it possible for others to replicate the model with the same dataset, or provide access to the model. In general. releasing code and data is often one good way to accomplish this, but reproducibility can also be provided via detailed instructions for how to replicate the results, access to a hosted model (e.g., in the case of a large language model), releasing of a model checkpoint, or other means that are appropriate to the research performed.   \n\u2022 While NeurIPS does not require releasing code, the conference does require all submissions to provide some reasonable avenue for reproducibility, which may depend on the nature of the contribution. For example   \n(a) If the contribution is primarily a new algorithm, the paper should make it clear how to reproduce that algorithm.   \n(b) If the contribution is primarily a new model architecture, the paper should describe the architecture clearly and fully.   \n(c) If the contribution is a new model (e.g., a large language model), then there should either be a way to access this model for reproducing the results or a way to reproduce the model (e.g., with an open-source dataset or instructions for how to construct the dataset).   \n(d) We recognize that reproducibility may be tricky in some cases, in which case authors are welcome to describe the particular way they provide for reproducibility. In the case of closed-source models, it may be that access to the model is limited in some way (e.g., to registered users), but it should be possible for other researchers to have some path to reproducing or verifying the results. ", "page_idx": 32}, {"type": "text", "text": "", "page_idx": 33}, {"type": "text", "text": "5. Open access to data and code ", "text_level": 1, "page_idx": 33}, {"type": "text", "text": "Question: Does the paper provide open access to the data and code, with sufficient instructions to faithfully reproduce the main experimental results, as described in supplemental material? ", "page_idx": 33}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 33}, {"type": "text", "text": "Justification: We provided code for reproducing experiments in Table 1 in the supplementary material. We will release the full code upon acceptance. ", "page_idx": 33}, {"type": "text", "text": "Guidelines: ", "text_level": 1, "page_idx": 33}, {"type": "text", "text": "\u2022 The answer NA means that paper does not include experiments requiring code.   \n\u2022 Please see the NeurIPS code and data submission guidelines (https://nips.cc/ public/guides/CodeSubmissionPolicy) for more details.   \n\u2022 While we encourage the release of code and data, we understand that this might not be possible, so \u201cNo\u201d is an acceptable answer. Papers cannot be rejected simply for not including code, unless this is central to the contribution (e.g., for a new open-source benchmark).   \n\u2022 The instructions should contain the exact command and environment needed to run to reproduce the results. See the NeurIPS code and data submission guidelines (https: //nips.cc/public/guides/CodeSubmissionPolicy) for more details.   \n\u2022 The authors should provide instructions on data access and preparation, including how to access the raw data, preprocessed data, intermediate data, and generated data, etc.   \n\u2022 The authors should provide scripts to reproduce all experimental results for the new proposed method and baselines. If only a subset of experiments are reproducible, they should state which ones are omitted from the script and why.   \n\u2022 At submission time, to preserve anonymity, the authors should release anonymized versions (if applicable).   \n\u2022 Providing as much information as possible in supplemental material (appended to the paper) is recommended, but including URLs to data and code is permitted. ", "page_idx": 33}, {"type": "text", "text": "6. Experimental Setting/Details ", "text_level": 1, "page_idx": 33}, {"type": "text", "text": "Question: Does the paper specify all the training and test details (e.g., data splits, hyperparameters, how they were chosen, type of optimizer, etc.) necessary to understand the results? ", "page_idx": 33}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 33}, {"type": "text", "text": "Justification: As stated in Section 4, we evaluate our algorithm on publicly available datasets and use full validation sets only; Appendix D further specifies the name of the used sets for each specific dataset. The used backbone, the superpixel clustering method, the $k_{m i n},\\;p_{m a x}$ and $\\lambda_{m a x}$ values are the variables needed to reproduce the results. We clearly state their values in Section 4 and table 6. Implementation details beyond the standard algorithm are reported in Appendix D. ", "page_idx": 33}, {"type": "text", "text": "", "page_idx": 34}, {"type": "text", "text": "Guidelines: ", "page_idx": 34}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments. \u2022 The experimental setting should be presented in the core of the paper to a level of detail that is necessary to appreciate the results and make sense of them. \u2022 The full details can be provided either with the code, in appendix, or as supplemental material. ", "page_idx": 34}, {"type": "text", "text": "7. Experiment Statistical Significance ", "text_level": 1, "page_idx": 34}, {"type": "text", "text": "Question: Does the paper report error bars suitably and correctly defined or other appropriate information about the statistical significance of the experiments? ", "page_idx": 34}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 34}, {"type": "text", "text": "Justification: The paper provides comprehensive statistical information for the experiments. Specifically, we assume Gaussian error (and run time) as stated in Section 4.2, and we report mean and standard deviation values in Table 3 and Tables 6a and 6c. While in Tables 6a and 6c, we report such values to assess the behaviour of the algorithm with respect to its base components, in Section 4.2, we perform 4 experiments to ensure the reproducibility and statistical validity of the experiments with different random seed initialization. However, not all experiments report such statistical information, especially the ones in Tables 1, 2, 4, 5 and 6b, for two main reasons. The first is that typically, in the standard practices in the field of semantic segmentation, it is common to report a single percentage mean value for evaluation metrics such as the mean Intersection over Union (mIoU); it is extremely rare the opposite. The second reason is that our newly introduced metrics typically require more time for evaluation with respect to standard IoU. Indeed, for instance, the NHCovering searches for the leaves matching between two trees; typically, the predicted tree counts many leaves. Hence, multiple restarts make the evaluation process extremely long. ", "page_idx": 34}, {"type": "text", "text": "Guidelines: ", "page_idx": 34}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 The authors should answer \"Yes\" if the results are accompanied by error bars, confidence intervals, or statistical significance tests, at least for the experiments that support the main claims of the paper.   \n\u2022 The factors of variability that the error bars are capturing should be clearly stated (for example, train/test split, initialization, random drawing of some parameter, or overall run with given experimental conditions).   \n\u2022 The method for calculating the error bars should be explained (closed form formula, call to a library function, bootstrap, etc.)   \n\u2022 The assumptions made should be given (e.g., Normally distributed errors).   \n\u2022 It should be clear whether the error bar is the standard deviation or the standard error of the mean.   \n\u2022 It is OK to report 1-sigma error bars, but one should state it. The authors should preferably report a 2-sigma error bar than state that they have a $96\\%$ CI, if the hypothesis of Normality of errors is not verified.   \n\u2022 For asymmetric distributions, the authors should be careful not to show in tables or figures symmetric error bars that would yield results that are out of range (e.g. negative error rates).   \n\u2022 If error bars are reported in tables or plots, The authors should explain in the text how they were calculated and reference the corresponding figures or tables in the text. ", "page_idx": 34}, {"type": "text", "text": "8. Experiments Compute Resources ", "text_level": 1, "page_idx": 34}, {"type": "text", "text": "Question: For each experiment, does the paper provide sufficient information on the computer resources (type of compute workers, memory, time of execution) needed to reproduce the experiments? ", "page_idx": 34}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 34}, {"type": "text", "text": "Justification: We specified the compute workers and the memory used in Appendix D to run our experiments. The time of execution depends on the parameters used and is discussed in Section 4.3 and Table 6. ", "page_idx": 35}, {"type": "text", "text": "Guidelines: ", "page_idx": 35}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 The paper should indicate the type of compute workers CPU or GPU, internal cluster, or cloud provider, including relevant memory and storage.   \n\u2022 The paper should provide the amount of compute required for each of the individual experimental runs as well as estimate the total compute.   \n\u2022 The paper should disclose whether the full research project required more compute than the experiments reported in the paper (e.g., preliminary or failed experiments that didn\u2019t make it into the paper). ", "page_idx": 35}, {"type": "text", "text": "9. Code Of Ethics ", "text_level": 1, "page_idx": 35}, {"type": "text", "text": "Question: Does the research conducted in the paper conform, in every respect, with the NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines? ", "page_idx": 35}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 35}, {"type": "text", "text": "Justification: The research did not involve human participants (but the authors). All datasets used are publicly available. The authors do not envision harmful consequences of the work and no violations in any of the points listed in the NeurIPS Code of Ethics. ", "page_idx": 35}, {"type": "text", "text": "Guidelines: ", "page_idx": 35}, {"type": "text", "text": "\u2022 The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics.   \n\u2022 If the authors answer No, they should explain the special circumstances that require a deviation from the Code of Ethics.   \n\u2022 The authors should make sure to preserve anonymity (e.g., if there is a special consideration due to laws or regulations in their jurisdiction). ", "page_idx": 35}, {"type": "text", "text": "10. Broader Impacts ", "text_level": 1, "page_idx": 35}, {"type": "text", "text": "Question: Does the paper discuss both potential positive societal impacts and negative societal impacts of the work performed? ", "page_idx": 35}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 35}, {"type": "text", "text": "Justification: This is a relevant question. As we have written, in the case of annotations, there is always discrimination due to the annotator\u2019s subjective prejudice or the dataset\u2019s design. In the case of unsupervised segmentation, in principle, there is no prejudice, but we cannot know if it can lead to some other form of prejudice. However, the most risky factor is the possibility the algorithm discloses of running it over a massive set of raw images (not a curated dataset) and profiting from that. Also, it shares the risk and bias of all SSL models and the unsupervised segmentation models. For example, the enormous amount of energy to run it over hundreds of thousands of raw images. . ", "page_idx": 35}, {"type": "text", "text": "Guidelines: ", "page_idx": 35}, {"type": "text", "text": "\u2022 The answer NA means that there is no societal impact of the work performed.   \n\u2022 If the authors answer NA or No, they should explain why their work has no societal impact or why the paper does not address societal impact.   \n\u2022 Examples of negative societal impacts include potential malicious or unintended uses (e.g., disinformation, generating fake profiles, surveillance), fairness considerations (e.g., deployment of technologies that could make decisions that unfairly impact specific groups), privacy considerations, and security considerations.   \n\u2022 The conference expects that many papers will be foundational research and not tied to particular applications, let alone deployments. However, if there is a direct path to any negative applications, the authors should point it out. For example, it is legitimate to point out that an improvement in the quality of generative models could be used to generate deepfakes for disinformation. On the other hand, it is not needed to point out that a generic algorithm for optimizing neural networks could enable people to train models that generate Deepfakes faster. ", "page_idx": 35}, {"type": "text", "text": "\u2022 The authors should consider possible harms that could arise when the technology is being used as intended and functioning correctly, harms that could arise when the technology is being used as intended but gives incorrect results, and harms following from (intentional or unintentional) misuse of the technology. \u2022 If there are negative societal impacts, the authors could also discuss possible mitigation strategies (e.g., gated release of models, providing defenses in addition to attacks, mechanisms for monitoring misuse, mechanisms to monitor how a system learns from feedback over time, improving the efficiency and accessibility of ML). ", "page_idx": 36}, {"type": "text", "text": "11. Safeguards ", "text_level": 1, "page_idx": 36}, {"type": "text", "text": "Question: Does the paper describe safeguards that have been put in place for responsible release of data or models that have a high risk for misuse (e.g., pretrained language models, image generators, or scraped datasets)? ", "page_idx": 36}, {"type": "text", "text": "Answer: [NA] Justification: [NA] Guidelines: ", "page_idx": 36}, {"type": "text", "text": "\u2022 The answer NA means that the paper poses no such risks.   \n\u2022 Released models that have a high risk for misuse or dual-use should be released with necessary safeguards to allow for controlled use of the model, for example by requiring that users adhere to usage guidelines or restrictions to access the model or implementing safety filters.   \n\u2022 Datasets that have been scraped from the Internet could pose safety risks. The authors should describe how they avoided releasing unsafe images.   \n\u2022 We recognize that providing effective safeguards is challenging, and many papers do not require this, but we encourage authors to take this into account and make a best faith effort. ", "page_idx": 36}, {"type": "text", "text": "12. Licenses for existing assets ", "text_level": 1, "page_idx": 36}, {"type": "text", "text": "Question: Are the creators or original owners of assets (e.g., code, data, models), used in the paper, properly credited and are the license and terms of use explicitly mentioned and properly respected? ", "page_idx": 36}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 36}, {"type": "text", "text": "Justification: Assets\u2019 owners are explicitly mentioned as reference entries. ", "page_idx": 36}, {"type": "text", "text": "Guidelines: ", "page_idx": 36}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not use existing assets.   \n\u2022 The authors should cite the original paper that produced the code package or dataset.   \n\u2022 The authors should state which version of the asset is used and, if possible, include a URL.   \n\u2022 The name of the license (e.g., CC-BY 4.0) should be included for each asset.   \n\u2022 For scraped data from a particular source (e.g., website), the copyright and terms of service of that source should be provided.   \n\u2022 If assets are released, the license, copyright information, and terms of use in the package should be provided. For popular datasets, paperswithcode.com/datasets has curated licenses for some datasets. Their licensing guide can help determine the license of a dataset.   \n\u2022 For existing datasets that are re-packaged, both the original license and the license of the derived asset (if it has changed) should be provided.   \n\u2022 If this information is not available online, the authors are encouraged to reach out to the asset\u2019s creators. ", "page_idx": 36}, {"type": "text", "text": "13. New Assets ", "text_level": 1, "page_idx": 36}, {"type": "text", "text": "Question: Are new assets introduced in the paper well documented and is the documentation provided alongside the assets? ", "page_idx": 36}, {"type": "text", "text": "Answer: [NA] Justification: [NA] ", "page_idx": 36}, {"type": "text", "text": "Guidelines: ", "page_idx": 37}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not release new assets.   \n\u2022 Researchers should communicate the details of the dataset/code/model as part of their submissions via structured templates. This includes details about training, license, limitations, etc.   \n\u2022 The paper should discuss whether and how consent was obtained from people whose asset is used.   \n\u2022 At submission time, remember to anonymize your assets (if applicable). You can either create an anonymized URL or include an anonymized zip file. ", "page_idx": 37}, {"type": "text", "text": "14. Crowdsourcing and Research with Human Subjects ", "text_level": 1, "page_idx": 37}, {"type": "text", "text": "Question: For crowdsourcing experiments and research with human subjects, does the paper include the full text of instructions given to participants and screenshots, if applicable, as well as details about compensation (if any)? ", "page_idx": 37}, {"type": "text", "text": "Answer: [NA] Justification: [NA] Guidelines: ", "page_idx": 37}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u2022 Including this information in the supplemental material is fine, but if the main contribution of the paper involves human subjects, then as much detail as possible should be included in the main paper.   \n\u2022 According to the NeurIPS Code of Ethics, workers involved in data collection, curation, or other labor should be paid at least the minimum wage in the country of the data collector. ", "page_idx": 37}, {"type": "text", "text": "15. Institutional Review Board (IRB) Approvals or Equivalent for Research with Human Subjects ", "page_idx": 37}, {"type": "text", "text": "Question: Does the paper describe potential risks incurred by study participants, whether such risks were disclosed to the subjects, and whether Institutional Review Board (IRB) approvals (or an equivalent approval/review based on the requirements of your country or institution) were obtained? ", "page_idx": 37}, {"type": "text", "text": "Answer: [NA] Justification: [NA] Guidelines: ", "page_idx": 37}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u2022 Depending on the country in which research is conducted, IRB approval (or equivalent) may be required for any human subjects research. If you obtained IRB approval, you should clearly state this in the paper.   \n\u2022 We recognize that the procedures for this may vary significantly between institutions and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the guidelines for their institution.   \n\u2022 For initial submissions, do not include any information that would break anonymity (if applicable), such as the institution conducting the review. ", "page_idx": 37}]