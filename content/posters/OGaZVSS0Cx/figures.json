[{"figure_path": "OGaZVSS0Cx/figures/figures_8_1.jpg", "caption": "Figure 1: Our results for a batch size of size 1024. We use the \u03b2 prefix to denote the algorithm uses the learning rate of [26].", "description": "This figure displays the results of experiments conducted using a batch size of 1024.  The results compare the performance of five different k-means algorithms across four different datasets (mnist_784, pendigits, har, letter). The algorithms compared are:  full batch kernel k-means, mini-batch kernel k-means using the learning rate from paper [26], mini-batch kernel k-means using the sklearn learning rate, mini-batch k-means (non-kernel) using the learning rate from paper [26], and mini-batch k-means (non-kernel) using the sklearn learning rate.  For each dataset and algorithm, the figure shows the Adjusted Rand Index (ARI), the Normalized Mutual Information (NMI), and the runtime. The '\u03b2' prefix indicates that the algorithm uses the learning rate from reference [26].", "section": "6 Experiments"}, {"figure_path": "OGaZVSS0Cx/figures/figures_11_1.jpg", "caption": "Figure 1: Our results for a batch size of size 1024. We use the \u03b2 prefix to denote the algorithm uses the learning rate of [26].", "description": "This figure presents a comparison of the performance of several k-means algorithms on four datasets (mnist_784, pendigits, har, letter) using a batch size of 1024.  The algorithms compared include the full batch kernel k-means, mini-batch kernel k-means using the learning rate from the paper referenced as [26], mini-batch kernel k-means using the learning rate from sklearn, mini-batch k-means (non-kernel) using the learning rate from [26], and mini-batch k-means (non-kernel) using the learning rate from sklearn. For each dataset and algorithm, the figure shows the Adjusted Rand Index (ARI), Normalized Mutual Information (NMI), and runtime (log scale). The \u03b2 prefix indicates that the learning rate from reference [26] was used.", "section": "6 Experiments"}]