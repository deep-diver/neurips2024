[{"figure_path": "Mi853QaJx6/tables/tables_1_1.jpg", "caption": "Table 1: Results on our ROBUSTALPACAEVAL benchmark. The model order is arranged according to their original performance. The substantial range between the worst and best performance suggests the robustness issues in LLMs' instruction-following ability. Scaling up model sizes, while improving average performance, does not enhance robustness.", "description": "This table presents the results of the ROBUSTALPACAEVAL benchmark across seven different large language models (LLMs).  The models are ranked by their original performance (the performance on the first prompt).  The table shows the original performance, worst performance, best performance, average performance, and standard deviation. The significant difference between the best and worst performances for each model highlights the sensitivity of LLMs to variations in prompt phrasing and their lack of robustness.  The results also indicate that increasing the size of the model doesn't guarantee improved robustness.", "section": "3.2 Results"}, {"figure_path": "Mi853QaJx6/tables/tables_3_1.jpg", "caption": "Table 1: Results on our ROBUSTALPACAEVAL benchmark. The model order is arranged according to their original performance. The substantial range between the worst and best performance suggests the robustness issues in LLMs' instruction-following ability. Scaling up model sizes, while improving average performance, does not enhance robustness.", "description": "This table presents the results of experiments conducted on the ROBUSTALPACAEVAL benchmark using various large language models (LLMs).  It shows the original performance, worst performance, best performance, average performance, and standard deviation for each model. The models are ordered by their original performance. The wide range between the best and worst performance highlights the significant sensitivity of LLMs to variations in prompt phrasing, even when semantically equivalent.  Scaling model size improves average performance, but does not necessarily lead to improved robustness.", "section": "3.2 Results"}, {"figure_path": "Mi853QaJx6/tables/tables_5_1.jpg", "caption": "Table 1: Results on our ROBUSTALPACAEVAL benchmark. The model order is arranged according to their original performance. The substantial range between the worst and best performance suggests the robustness issues in LLMs' instruction-following ability. Scaling up model sizes, while improving average performance, does not enhance robustness.", "description": "This table presents the results of experiments conducted on the ROBUSTALPACAEVAL benchmark.  It shows the original, worst, best, and average performance of various large language models (LLMs) across multiple semantically equivalent prompts.  The significant difference between best and worst performance highlights the robustness issues of LLMs in consistently following instructions, even when the instructions are semantically identical.  Interestingly, increasing model size improves average performance but doesn't necessarily enhance robustness.", "section": "3.2 Results"}, {"figure_path": "Mi853QaJx6/tables/tables_7_1.jpg", "caption": "Table 1: Results on our ROBUSTALPACAEVAL benchmark. The model order is arranged according to their original performance. The substantial range between the worst and best performance suggests the robustness issues in LLMs' instruction-following ability. Scaling up model sizes, while improving average performance, does not enhance robustness.", "description": "This table presents the results of experiments conducted on the ROBUSTALPACAEVAL benchmark.  It shows the original performance, worst performance, best performance, average performance, and standard deviation for seven different large language models (LLMs). The models are ordered by their original performance, illustrating the wide variation in performance between the best and worst prompts for each model, regardless of model size. This highlights the challenge of creating robust LLMs that consistently perform well across diverse prompts.", "section": "3.2 Results"}, {"figure_path": "Mi853QaJx6/tables/tables_8_1.jpg", "caption": "Table 1: Results on our ROBUSTALPACAEVAL benchmark. The model order is arranged according to their original performance. The substantial range between the worst and best performance suggests the robustness issues in LLMs' instruction-following ability. Scaling up model sizes, while improving average performance, does not enhance robustness.", "description": "This table presents the results of experiments conducted on the ROBUSTALPACAEVAL benchmark using various large language models (LLMs).  It shows the original performance, worst performance, best performance, average performance, and standard deviation for each model.  The models are ordered by their original performance. The large differences between best and worst performance highlight the inconsistency of LLMs when responding to semantically similar prompts.  Even larger models don't show improved robustness despite better average performance.", "section": "3.2 Results"}, {"figure_path": "Mi853QaJx6/tables/tables_12_1.jpg", "caption": "Table 1: Results on our ROBUSTALPACAEVAL benchmark. The model order is arranged according to their original performance. The substantial range between the worst and best performance suggests the robustness issues in LLMs' instruction-following ability. Scaling up model sizes, while improving average performance, does not enhance robustness.", "description": "This table presents the results of experiments conducted on the ROBUSTALPACAEVAL benchmark, evaluating the performance of various large language models (LLMs).  It shows the original performance, worst performance, best performance, average performance, and standard deviation for each model. The models are ordered by their original performance. The significant difference between the best and worst performances highlights the sensitivity of LLMs to prompt variations, demonstrating the need for more robust models.", "section": "3.2 Results"}]