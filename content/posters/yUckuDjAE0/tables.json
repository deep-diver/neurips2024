[{"figure_path": "yUckuDjAE0/tables/tables_2_1.jpg", "caption": "Table 1: Notation and context of our approach. First column: generic concepts associated with the BD and mirror descent. Second and third column: known instantiations. Last column: our learned BDs with a novel approach to robustness as application.", "description": "This table summarizes the notation and concepts used in the paper, focusing on Bregman Divergences (BD) and mirror descent.  It compares the generic concepts with specific examples such as the Euclidean norm and KL divergence. The last column highlights how the authors' proposed learned BDs differ from and extend previous work, specifically in their application to robustness.", "section": "2 Background"}, {"figure_path": "yUckuDjAE0/tables/tables_8_1.jpg", "caption": "Table 2: Comparison of corruption robustness of models trained under different regimes.", "description": "This table compares the corruption robustness of models trained using different methods: standard training, Projected Gradient Descent (PGD), Relaxed LPIPS Adversarial Training (RLAT), and Mirror Descent with two different learned Bregman divergences (Dcontrast and Dzoom-blur).  Robustness is measured across five severity levels (s=1 to s=5) for contrast corruption, and an average robustness is also reported.  The results demonstrate the superior performance of the proposed Mirror Descent method, especially at higher severity levels, in contrast to the commonly used PGD and RLAT techniques.", "section": "6 Corruption-specific Bregman divergences"}, {"figure_path": "yUckuDjAE0/tables/tables_8_2.jpg", "caption": "Table 3: Corruption robustness of the standard-trained model against adversarially trained models under L2, RLAT, and our mirror descent (MD) AT for different corruptions.", "description": "This table compares the corruption robustness of a standard-trained model against models trained using three different adversarial training methods: Projected Gradient Descent (PGD) with L2 norm, Relaxed LPIPS Adversarial Training (RLAT), and Mirror Descent with the learned Bregman divergence.  The robustness is evaluated across several common image corruptions (contrast, fog, zoom blur, brightness) using the CIFAR-10-C dataset, and measured by the average accuracy across different corruption severities.", "section": "6.2 AT with mirror descent"}, {"figure_path": "yUckuDjAE0/tables/tables_9_1.jpg", "caption": "Table 4: Accuracy of the trained Bregman divergence compared to LPIPS evaluated on different categories of the 2AFC task from the BAPPS dataset.", "description": "This table compares the accuracy of the learned Bregman divergence and LPIPS on the Berkeley-Adobe Perceptual Patch Similarity (BAPPS) dataset. The BAPPS dataset contains image triplets with human judgments on which distortion is more similar to the original. The table shows the accuracy for each of the six categories of the 2AFC (two-alternative forced choice) test in the BAPPS dataset.  The comparison demonstrates the performance of the learned Bregman divergence against a state-of-the-art method for perceptual similarity.", "section": "7 Corruption-oblivious Bregman divergence"}, {"figure_path": "yUckuDjAE0/tables/tables_9_2.jpg", "caption": "Table 5: Corruption robustness of the learned corruption-oblivious Bregman divergence compared to PGD and RLAT.", "description": "This table shows the corruption robustness results for different models on the CIFAR-10-C dataset.  It compares the performance of the proposed corruption-oblivious Bregman divergence approach against the standard Projected Gradient Descent (PGD) and Relaxed LPIPS Adversarial Training (RLAT) methods.  The results are presented for four common image corruptions: clean, contrast, fog, and zoom blur.  The accuracy values show how well each model generalizes when faced with different corruption levels.", "section": "7 Corruption-oblivious Bregman divergence"}, {"figure_path": "yUckuDjAE0/tables/tables_19_1.jpg", "caption": "Table 3: Corruption robustness of the standard-trained model against adversarially trained models under L2, RLAT, and our mirror descent (MD) AT for different corruptions.", "description": "This table compares the corruption robustness of a standard-trained model against models trained using three different adversarial training methods: Projected Gradient Descent (PGD) with L2 norm, Relaxed LPIPS Adversarial Training (RLAT), and Mirror Descent with the learned Bregman divergence.  The robustness is evaluated across five types of image corruptions (contrast, fog, zoom blur, brightness, and others) at various severities. The table shows the accuracy of each method on each corruption type, highlighting the superior performance of Mirror Descent with the learned Bregman divergence, particularly in handling contrast and fog corruptions.", "section": "6.2 AT with mirror descent"}, {"figure_path": "yUckuDjAE0/tables/tables_19_2.jpg", "caption": "Table 7: Evaluating a BD learned for a corruption \u03c4 (D in rows) on different corruptions \u03c4' (in columns) by computing the ratio D\u03c4(\u03c4'(x) || x)/D\u03c4(\u03c4(x) || x) averaged over the test set.", "description": "This table presents the results of evaluating the cross-corruption generalization of learned Bregman divergences. It shows the ratio of the learned Bregman divergence for a given corruption \u03c4' to the Bregman divergence for its training corruption \u03c4, averaged over the test set.  This assesses how well a divergence trained for one corruption generalizes to other corruptions.", "section": "6.1 Learning the BD"}]