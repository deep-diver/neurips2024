[{"figure_path": "CIcMZGLyZW/tables/tables_4_1.jpg", "caption": "Table 1: Consistency rate of six different operations used in informalization: (1) Mutation; (2) Few-shot learning; (3) Comment generation; (4) Math-word instruction; (5) Problem modification; (6) Variable refresh. We recommend two patterns (i.e., P1: 1-5 and P2: 1-3&6), both of which can achieve satisfactory results.", "description": "This table presents the consistency rates of different operations used in the informalization process of converting formal math problems into natural language. The operations include mutation, few-shot learning, comment generation, math-word instruction, problem modification, and variable refresh.  Two recommended patterns (P1 and P2) combine these operations, showing improved consistency rates compared to the base case.", "section": "3 Informalization"}, {"figure_path": "CIcMZGLyZW/tables/tables_6_1.jpg", "caption": "Table 2: Performance comparison among existing mathematical reasoning models fine-tuned on three base models (LLaMA-2 7B, LLaMA-13B, and Mistral 7B). The best performance is in bold. The delta performance between our model and other SOTA LLMs on each dataset is also reported.", "description": "This table compares the performance of the proposed neuro-symbolic data generation method against other state-of-the-art (SOTA) large language models (LLMs) on two benchmark datasets: GSM8K and MATH.  Three different base LLMs (LLaMA-2 7B, LLaMA-2 13B, and Mistral 7B) were fine-tuned using the generated datasets. The table shows the accuracy of each model on each dataset, highlighting the best performance in bold, and providing the difference in performance between the proposed model and other SOTA LLMs. This demonstrates the effectiveness of the proposed method in improving the mathematical reasoning capabilities of LLMs.", "section": "4.2 Empirical Results"}, {"figure_path": "CIcMZGLyZW/tables/tables_7_1.jpg", "caption": "Table 2: Performance comparison among existing mathematical reasoning models fine-tuned on three base models (LLaMA-2 7B, LLaMA-13B, and Mistral 7B). The best performance is in bold. The delta performance between our model and other SOTA LLMs on each dataset is also reported.", "description": "This table compares the performance of the proposed neuro-symbolic data generation method against other state-of-the-art (SOTA) large language models (LLMs) on two mathematical reasoning datasets (GSM8K and MATH).  Three different base LLMs (LLaMA-2 7B, LLaMA-13B, and Mistral 7B) were fine-tuned using the generated data. The table shows the accuracy of each model on both datasets and highlights the improvement achieved by the proposed method over the SOTA models.", "section": "4.2 Empirical Results"}, {"figure_path": "CIcMZGLyZW/tables/tables_18_1.jpg", "caption": "Table 2: Performance comparison among existing mathematical reasoning models fine-tuned on three base models (LLaMA-2 7B, LLaMA-13B, and Mistral 7B). The best performance is in bold. The delta performance between our model and other SOTA LLMs on each dataset is also reported.", "description": "This table compares the performance of the proposed neuro-symbolic data generation method against other state-of-the-art (SOTA) Large Language Models (LLMs) on two mathematical reasoning datasets: GSM8K and MATH.  Three different base LLMs (LLaMA-2 7B, LLaMA-13B, and Mistral 7B) were fine-tuned using the generated datasets, and their performance is compared against SOTA models like WizardMath, MuggleMATH, MAmmoTH, and MetaMath. The table highlights the accuracy achieved by each model on both datasets and shows the improvement achieved by the proposed method over the other SOTA models.", "section": "4.2 Empirical Results"}, {"figure_path": "CIcMZGLyZW/tables/tables_19_1.jpg", "caption": "Table 5: Comparison of performance between MetaMath and our method across different categories of MATH dataset. The used base model is Mistral-7B. The best performance is in bold.", "description": "This table compares the performance of the proposed method and MetaMath on the MATH dataset across seven different mathematical categories.  It shows the accuracy achieved by each method in each category and the improvement achieved by the proposed method over MetaMath. The base model used for both methods is Mistral-7B.  The best performing model for each category is highlighted in bold.", "section": "E.1 Detailed results on MATH dataset"}, {"figure_path": "CIcMZGLyZW/tables/tables_20_1.jpg", "caption": "Table 2: Performance comparison among existing mathematical reasoning models fine-tuned on three base models (LLaMA-2 7B, LLaMA-13B, and Mistral 7B). The best performance is in bold. The delta performance between our model and other SOTA LLMs on each dataset is also reported.", "description": "This table compares the performance of the proposed model against other state-of-the-art (SOTA) large language models (LLMs) on two mathematical reasoning benchmark datasets (GSM8K and MATH).  It shows the accuracy achieved by each model after fine-tuning on different base models (LLaMA-2 7B, LLaMA-2 13B, and Mistral 7B), highlighting the superior performance of the proposed method.  The delta (difference) between the proposed model's accuracy and those of the other LLMs is also given to show the extent of the improvement.", "section": "4.2 Empirical Results"}, {"figure_path": "CIcMZGLyZW/tables/tables_20_2.jpg", "caption": "Table 2: Performance comparison among existing mathematical reasoning models fine-tuned on three base models (LLaMA-2 7B, LLaMA-13B, and Mistral 7B). The best performance is in bold. The delta performance between our model and other SOTA LLMs on each dataset is also reported.", "description": "This table compares the performance of different mathematical reasoning models, including the models fine-tuned using the proposed neuro-symbolic data generation framework, across three different base models (LLaMA-2 7B, LLaMA-13B, and Mistral 7B) and two benchmark datasets (GSM8K and MATH).  The best performance for each model and dataset is highlighted in bold, and the improvement achieved by the proposed method compared to other state-of-the-art (SOTA) models is also shown.", "section": "4.2 Empirical Results"}, {"figure_path": "CIcMZGLyZW/tables/tables_20_3.jpg", "caption": "Table 2: Performance comparison among existing mathematical reasoning models fine-tuned on three base models (LLaMA-2 7B, LLaMA-13B, and Mistral 7B). The best performance is in bold. The delta performance between our model and other SOTA LLMs on each dataset is also reported.", "description": "This table compares the performance of the proposed neuro-symbolic data generation method against other state-of-the-art (SOTA) large language models (LLMs) on two mathematical reasoning datasets (GSM8K and MATH).  Three different base LLMs (LLaMA-2 7B, LLaMA-2 13B, and Mistral 7B) were fine-tuned using the generated data. The table shows the accuracy of each model on each dataset, highlighting the best performance in bold. It also provides the difference in performance between the proposed method and the SOTA LLMs.", "section": "4.2 Empirical Results"}]