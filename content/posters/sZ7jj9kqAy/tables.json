[{"figure_path": "sZ7jj9kqAy/tables/tables_7_1.jpg", "caption": "Table 1: Selected results from experiments with partially predictive SOI for speech separation.", "description": "This table presents a subset of the results obtained from experiments using partially predictive SOI (Scattered Online Inference) for a speech separation task.  It shows the performance metrics (SI-SNRi in dB) achieved by several different model variations, each differing in the placement and number of S-CC (Strided-Cloned Convolution) layers. The table also indicates the percentage of retained SI-SNRi and complexity (MMAC/s) relative to a baseline model (STMC). This allows for a comparison of the trade-off between model accuracy and computational efficiency achieved by the various SOI configurations.", "section": "4.1 Speech Separation"}, {"figure_path": "sZ7jj9kqAy/tables/tables_7_2.jpg", "caption": "Table 2: Selected results from experiments with fully predictive SOI for speech separation.", "description": "This table presents the results of speech separation experiments using fully predictive SOI.  It shows the SI-SNRi (Signal-to-Interference plus Noise Ratio improvement), the percentage of SI-SNRi retained compared to the baseline STMC model, the percentage of computational complexity retained, the number of MMACs (Multiply-Accumulate operations) retained, and the percentage of the network calculated using precomputed data.  The results highlight the tradeoff between complexity reduction and performance for different SOI configurations.", "section": "4.1 Speech Separation"}, {"figure_path": "sZ7jj9kqAy/tables/tables_8_1.jpg", "caption": "Table 3: Comparison between resampling and SOI.", "description": "This table compares the performance of different resampling methods (Linear, Polyphase, Kaiser, SoX) against the proposed SOI method (specifically, SOI with S-CC 5, S-CC 2, and S-CC 1/3 configurations) in a speech separation task.  It shows the achieved SI-SNRi (signal-to-noise ratio improvement) in dB and the corresponding computational complexity in MMAC/s (million multiply-accumulate operations per second). The results highlight the trade-off between model performance (SI-SNRi) and computational efficiency (complexity).", "section": "Resampling"}, {"figure_path": "sZ7jj9kqAy/tables/tables_8_2.jpg", "caption": "Table 11: Results of ASC experiment with ResNet.", "description": "This table presents the results of acoustic scene classification (ASC) experiments using different ResNet models.  It shows the top-1 accuracy, computational complexity (in GMAC/s), and the number of parameters for baseline, STMC, and SOI methods across various ResNet model sizes.  The results demonstrate the impact of SOI on both accuracy and computational efficiency in the ASC task.", "section": "G Acoustic Scene Classification with ResNet"}, {"figure_path": "sZ7jj9kqAy/tables/tables_12_1.jpg", "caption": "Table 5: Results of experiment on the influence of strided convolution on predictive inference.", "description": "This table presents the results of an experiment comparing the performance of a predictive model with standard convolutions and a strided predictive model with strided convolutions. The experiment was conducted for different prediction lengths, ranging from 1 to 4 frames.  The table shows the SI-SNRi (Scale-Invariant Signal-to-Noise Ratio) for each model and prediction length, indicating the model's performance in terms of speech separation quality.  The inclusion of error bars (+/- values) demonstrate the variability in the model's performance across different training runs. The results suggest that strided convolutions might be advantageous for longer predictions, possibly due to their improved ability to generalize from limited contextual data.", "section": "B Strided Convolutions are Better for Longer Predictions"}, {"figure_path": "sZ7jj9kqAy/tables/tables_13_1.jpg", "caption": "Table 6: Results from experiments with partially predictive SOI for speech separation with added average inference time and peak memory footprint.", "description": "This table presents the results of experiments using partially predictive Scattered Online Inference (SOI) for speech separation.  It shows the Signal-to-Interference Ratio plus Noise (SI-SNRi) improvement, the percentage of complexity retained in the SOI model compared to the baseline STMC model, the average inference time in milliseconds, and the peak memory footprint in MB for different SOI configurations (varying the placement of the S-CC layer within the model). It provides a comprehensive analysis of the trade-off between computational efficiency and model performance. The results indicate that SOI achieves substantial computational savings at a relatively modest loss of SI-SNRi.", "section": "C Inference Time and Peak Memory Footprint"}, {"figure_path": "sZ7jj9kqAy/tables/tables_14_1.jpg", "caption": "Table 7: Results of experiment on interpolation methods with PP SOI.", "description": "This table presents the results of an experiment comparing different interpolation methods (duplication, nearest-neighbor, bilinear, bicubic) with Partially Predictive SOI (PP SOI) for speech separation.  The table shows the SI-SNRi (Signal-to-Interference-plus-Noise Ratio in dB) achieved for each interpolation method across seven different positions of the S-CC (Strided-Cloned Convolution) layer in the network.  Higher SI-SNRi values indicate better performance.", "section": "D Interpolation"}, {"figure_path": "sZ7jj9kqAy/tables/tables_15_1.jpg", "caption": "Table 8: Results of experiment on different extrapolation methods with PP SOI.", "description": "This table presents the results of an experiment comparing different extrapolation methods (Duplication, Transposed convolution, and Hybrid) for the Partially Predictive (PP) Scattered Online Inference (SOI) method.  The experiment was conducted on a speech separation task using a U-Net architecture with two S-CC layers.  Each row represents a different configuration of S-CC layer positions (e.g., S-CC 1/2 means the first S-CC layer is at position 1 and the second at position 2). The SI-SNRi metric is used to evaluate the performance of each configuration. The table shows that there is no significant difference in the performance among the methods.  The hybrid method, which combines duplication and transposed convolution, shows results comparable to the individual methods.", "section": "E Different Extrapolation Methods"}, {"figure_path": "sZ7jj9kqAy/tables/tables_16_1.jpg", "caption": "Table 6: Results from experiments with partially predictive SOI for speech separation with added average inference time and peak memory footprint.", "description": "This table presents the results of experiments using partially predictive SOI for speech separation. It shows the SI-SNRi (signal-to-noise ratio improvement), the percentage of complexity retained, the average inference time in milliseconds, and the peak memory footprint in MB for different configurations of SOI, including various placements of the S-CC layer.  It allows comparison of the model's performance with different levels of computational reduction. The STMC (baseline) results are also included for comparison.", "section": "C Inference Time and Peak Memory Footprint"}, {"figure_path": "sZ7jj9kqAy/tables/tables_17_1.jpg", "caption": "Table 10: Results of video action recognition experiment.", "description": "This table presents the results of applying SOI to video action recognition tasks using different model architectures (ResNet-10 and MoViNet).  It shows the top-1 accuracy and computational complexity (in GMAC/s) for both regular models and models using the SOI method.  The results demonstrate the impact of SOI on both accuracy and computational efficiency in this domain.", "section": "F Video Action Recognition"}, {"figure_path": "sZ7jj9kqAy/tables/tables_18_1.jpg", "caption": "Table 11: Results of ASC experiment with ResNet.", "description": "This table presents the results of acoustic scene classification (ASC) experiments using different ResNet models. It compares the top-1 accuracy, complexity (in GMAC/s), and the number of parameters for three different methods: Baseline (original ResNet), STMC (Short-Term Memory Convolution), and SOI (Scattered Online Inference).  The results are shown for four different ResNet model sizes (18, 34, 50, and 101 layers).  The table demonstrates the impact of SOI on improving accuracy while reducing computational complexity compared to both Baseline and STMC.", "section": "G Acoustic Scene Classification with ResNet"}]