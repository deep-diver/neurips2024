[{"figure_path": "dLnduWGTB4/figures/figures_1_1.jpg", "caption": "Figure 1: QUEST samples an index from the current translation (yt), removes all elements to the right of the index, generates a new continuation, and then uses the Metropolis-Hastings acceptance criterion to decide whether to accept or reject the resulting new translation. The process continues for a fixed number of T iterations.", "description": "This figure illustrates the QUEST algorithm's sampling process.  It begins with an existing translation (yt). An index is randomly selected, and the portion of the translation after that index is discarded. A new continuation is generated from the language model, resulting in a candidate translation. The Metropolis-Hastings algorithm then determines if this candidate is accepted or rejected based on its quality score, moving to the next iteration. This process is repeated for a set number of iterations (T).", "section": "3 An MCMC-based Decoding Approach for Text Generation"}, {"figure_path": "dLnduWGTB4/figures/figures_6_1.jpg", "caption": "Figure 2: Average quality vs. diversity on WMT23 datasets. Different points represent different hyperparameter values. QUEST outperforms ancestral sampling in six out of eight settings.", "description": "This figure compares the performance of QUEST and ancestral sampling methods on WMT23 datasets across different language pairs.  Each point on the graph represents a different combination of hyperparameters used in the sampling process. The x-axis displays lexical diversity, and the y-axis shows the average quality of the generated translations as measured by xComet-XL. The results show that QUEST generally outperforms ancestral sampling in terms of quality, while achieving similar or better diversity.", "section": "5 Results"}, {"figure_path": "dLnduWGTB4/figures/figures_7_1.jpg", "caption": "Figure 2: Average quality vs. diversity on WMT23 datasets. Different points represent different hyperparameter values. QUEST outperforms ancestral sampling in six out of eight settings.", "description": "This figure compares the performance of QUEST and ancestral sampling on eight different language pairs from the WMT23 dataset. The x-axis represents the lexical diversity, while the y-axis represents the average quality measured using the xCOMET-XL metric.  Each set of four plots shows the results for different language directions (English to another language and vice versa) for two different models, TOWER and ALMA. The plots show that, for most language pairs and models, QUEST achieves better or comparable translation quality with higher lexical diversity compared to ancestral sampling. This illustrates the ability of QUEST to generate higher quality and more diverse translations compared to the baselines.", "section": "5 Results"}, {"figure_path": "dLnduWGTB4/figures/figures_7_2.jpg", "caption": "Figure 2: Average quality vs. diversity on WMT23 datasets. Different points represent different hyperparameter values. QUEST outperforms ancestral sampling in six out of eight settings.", "description": "This figure shows the comparison results of average quality against lexical diversity between the QUEST and ancestral sampling methods on WMT23 datasets.  Different points in the graph represent different hyperparameter values used in each method. The results indicate that, for six out of eight dataset and model combinations, QUEST achieved superior quality-diversity trade-offs compared to ancestral sampling.", "section": "5 Results"}, {"figure_path": "dLnduWGTB4/figures/figures_16_1.jpg", "caption": "Figure 4: Distribution of rewards for sampled hypotheses for the toy summarization problem.", "description": "This figure shows the distribution of rewards obtained from different sampling methods in a toy summarization problem where the ground truth reward is known.  The methods compared are: Exact Gibbs (the true distribution), Ancestral sampling, QUEST sampling, and Truncated-Gibbs sampling. The x-axis represents the reward, and the y-axis represents the frequency.  The figure illustrates that QUEST sampling provides a better approximation of the true reward distribution, outperforming Ancestral and Truncated Gibbs sampling, which tend to sample from lower reward regions.", "section": "C.1 Toy problem: Validating the Approach"}, {"figure_path": "dLnduWGTB4/figures/figures_16_2.jpg", "caption": "Figure 5: Average quality (XCOMET-XL) vs. diversity (PAIRWISE-BLEU) on WMT23 datasets. Different points represent different hyperparameter values.", "description": "This figure shows the trade-off between the average quality of translations (measured by XCOMET-XL) and their lexical diversity (measured by PAIRWISE-BLEU) on several language pairs from the WMT23 dataset.  Different points on the graph represent different hyperparameter settings used in the QUEST and ancestral sampling methods. The results illustrate how QUEST achieves better trade-offs, typically showing better quality and diversity compared to ancestral sampling.", "section": "5 Results"}, {"figure_path": "dLnduWGTB4/figures/figures_17_1.jpg", "caption": "Figure 6: Average Quality by XCOMET-XL (left) and COMETKIWI-XL on English-Russian dataset using TOWER-7B", "description": "This figure compares the performance of three different methods: Ancestral sampling, QUEST, and RLHF-QUEST, across different levels of lexical diversity.  Both the XCOMET-XL (left panel) and COMETKIWI-XL (right panel) metrics are used to evaluate translation quality.  The results show that QUEST generally outperforms ancestral sampling in terms of quality, and that RLHF-QUEST offers comparable performance to QUEST.  The x-axis represents lexical diversity, while the y-axis shows the average quality score.", "section": "C.4 Comparing RLHF-QUEST vs QUEST"}, {"figure_path": "dLnduWGTB4/figures/figures_18_1.jpg", "caption": "Figure 2: Average quality vs. diversity on WMT23 datasets. Different points represent different hyperparameter values. QUEST outperforms ancestral sampling in six out of eight settings.", "description": "This figure compares the performance of QUEST and ancestral sampling methods for machine translation on the WMT23 benchmark across various language pairs and model settings.  The x-axis represents lexical diversity, which is a measure of the variety of words used in the generated translations.  The y-axis shows the average quality of the translations, as measured by the COMET-XL metric. Each point represents a different set of hyperparameters used in the sampling process.  The figure demonstrates that QUEST generally produces higher-quality translations with comparable diversity compared to the ancestral sampling method.", "section": "5 Results"}, {"figure_path": "dLnduWGTB4/figures/figures_19_1.jpg", "caption": "Figure 7: Average quality (COMETKIWI-XL) vs. diversity (PAIRWISE-BLEU) on WMT23 datasets. Different points represent different hyperparameter values.", "description": "This figure displays the trade-off between translation quality and lexical diversity achieved by the QUEST and ancestral sampling methods across different language pairs from the WMT23 benchmark.  The x-axis represents lexical diversity, calculated using pairwise BLEU scores, indicating the variety of translations produced. The y-axis shows the average translation quality measured using the COMETKIWI-XL metric.  Each plot corresponds to a specific language pair and model (TOWER or ALMA).  Multiple points in each plot correspond to different hyperparameter settings, showcasing the effect of hyperparameter tuning on the quality-diversity trade-off. The figure highlights the performance of QUEST in achieving higher quality translations while maintaining reasonable diversity compared to ancestral sampling.", "section": "5 Results"}, {"figure_path": "dLnduWGTB4/figures/figures_19_2.jpg", "caption": "Figure 2: Average quality vs. diversity on WMT23 datasets. Different points represent different hyperparameter values. QUEST outperforms ancestral sampling in six out of eight settings.", "description": "This figure compares the performance of QUEST and ancestral sampling on eight different language pairs from the WMT23 dataset.  The x-axis represents lexical diversity, a measure of how different the generated translations are from each other. The y-axis represents the average quality of the generated translations, measured using COMET-XL.  Each point on the graph represents a different setting of hyperparameters used in the sampling methods.  The results show that QUEST generally achieves higher quality than ancestral sampling, particularly in six out of the eight language pair settings. This suggests that QUEST is more effective at generating high-quality and diverse translations.", "section": "5 Results"}]