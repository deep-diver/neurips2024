[{"figure_path": "HYiR6tGQPv/figures/figures_1_1.jpg", "caption": "Figure 1: Existing problem in molecular contrastive learning. Adopt node removal and edge removal for molecular contrastive learning can lead to false positive and false negative problems. Blue lines indicate positive pairs and yellowing lines indicate negative pairs. The numbers on each line indicate the chemical similarity between the augmented pair of molecules. In this case, positive pairs indeed have lower similarity than negative pairs.", "description": "This figure illustrates a common problem in molecular contrastive learning where standard augmentation techniques like node and edge removal can lead to inaccurate labeling of positive and negative pairs.  The example shows that molecules with similar chemical structures (high similarity scores) can be incorrectly labeled as negative pairs due to the augmentations, while molecules with lower similarity might be incorrectly labeled as positive pairs. This highlights the need for a more robust method that accounts for such uncertainties in data pair assignments.", "section": "1 Introduction"}, {"figure_path": "HYiR6tGQPv/figures/figures_3_1.jpg", "caption": "Figure 2: (A) Molecular contrastive learning Molecules are represented as 2D or 3D molecule graphs. Two stochastic augmentation strategies are applied to each graph, resulting in two augmentations. A feature extractor is used to extract features and contrastive loss is used to maximize the similarity of positive pairs and minimize the similarity of negative pairs B,C,D: Different architectures used as feature extractors in different experiments. (B) Uni-Mol [42] architecture used in MoleculeNet [35] Dataset experiment. (C) GCN [21] architecture from MolCLR [33] used in Non-Chirality MoleculeNet [35] experiment. (D) Equiformer [17] architecture used in QM9 [28] dataset experiment.", "description": "This figure illustrates the molecular contrastive learning framework. (A) shows the overall process: Two stochastic augmentations are applied to each molecule, creating positive pairs.  A feature extractor generates representations, and contrastive loss optimizes similarity between positive pairs and dissimilarity between negative pairs. (B), (C), and (D) depict three different feature extractor architectures (Uni-Mol, GCN, and Equiformer) used in different experiments and datasets.", "section": "Methods"}, {"figure_path": "HYiR6tGQPv/figures/figures_12_1.jpg", "caption": "Figure 3: Similarity Scores \u2013 Similarity scores distribution for negative pairs in joint space after pre-training with original MolCLR loss and our proposed loss is provided. Compared to Using pretrained MolCLR model, our method yields similarity scores with lower mean and lower variance for negative pairs. While MolCLR have two peaks of negatives similarity scores around 1 and 2.7, our method concentrates them at only one peak of 1.Our method yields similarity scores with higher mean and lower variance for positive pairs. Our method concentrates at higher levels as it allows for some degree of semantic dissimilar between positives. The similarity scores are dot similarity, they are not normalized to enhance the difference for visual purposes.", "description": "The figure shows the distribution of similarity scores for positive and negative pairs obtained using the proposed method and the baseline MolCLR method. The proposed method demonstrates lower variance in similarity scores for negative pairs, indicating a more focused distribution of negative samples, and higher mean and lower variance for positive pairs, indicating more accurate identification of positive pairs.", "section": "4.4 Ablation Study"}]