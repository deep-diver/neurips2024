[{"figure_path": "Eu80DGuOcs/figures/figures_3_1.jpg", "caption": "Figure 1: The classifier loss of a successful and a failure guidance example. The target class is \"indigo bird\".", "description": "This figure shows two examples of training-free guidance, one successful and one unsuccessful.  The successful example shows a smooth decrease in the loss function over diffusion time, indicating effective guidance towards the target class.  Conversely, the unsuccessful example shows oscillations and minimal loss reduction despite the absence of the target class, revealing issues with misaligned gradients. The target class for both examples is \"indigo bird\".", "section": "3 Analysis of Training-Free Guidance"}, {"figure_path": "Eu80DGuOcs/figures/figures_4_1.jpg", "caption": "Figure 2: Gradients of different classifiers on random backgrounds. The images in the first row correspond to the target class \u201ccock\u201d, and the second row to \u201cgoldfinch\u201d.", "description": "This figure compares the gradients produced by different classifiers when applied to random background images.  The top row shows the target image class 'cock', while the bottom row shows the target image class 'goldfinch'. Four different classifier types are shown:  (a) an adversarially robust classifier; (b) a time-dependent classifier; (c) an off-the-shelf ResNet-50 classifier; and (d) a ResNet-50 classifier with random augmentation. The visualization demonstrates how the type of classifier affects the gradient's clarity and alignment with the target image, highlighting the impact of time-dependence and augmentation on robustness to misaligned gradients.", "section": "3.2 Limitations of Training-free Guidance"}, {"figure_path": "Eu80DGuOcs/figures/figures_9_1.jpg", "caption": "Figure 4: Qualitative results of CelebA-HQ with zero-shot segmentation, sketch, and text guidance. The images are randomly selected.", "description": "This figure displays the qualitative results of applying three different types of zero-shot guidance (segmentation, sketch, and text) to a CelebA-HQ diffusion model.  Each row represents a different guidance method (UG, LGD-MC, FreeDoM, MPGD, and the authors' method), and each column shows the generated images from a different seed. The images are randomly selected to showcase the visual quality and diversity of the generated samples under each guidance condition.", "section": "5.1 Guidance to CelebA-HQ Diffusion"}, {"figure_path": "Eu80DGuOcs/figures/figures_9_2.jpg", "caption": "Figure 5: Qualitative results of ImageNet model with zero-shot text guidance. The images are randomly selected.", "description": "This figure shows the qualitative results of applying zero-shot text guidance to an ImageNet pretrained diffusion model.  Different methods (UG, LGD-MC, FreeDoM, MPGD, and the proposed 'Ours') are compared. Each row corresponds to a different method, and each column displays generated images for a specific text prompt. The prompts represent various scene descriptions, including animals, objects and landscapes. The images generated demonstrate the effectiveness of each method in fulfilling the specified text prompts.  Randomly selected images are shown for each method and prompt.", "section": "5 Experiments"}, {"figure_path": "Eu80DGuOcs/figures/figures_9_3.jpg", "caption": "Figure 6: Qualitative results of human motion diffusion with zero-shot object avoidance and targeting guidance. Instances of intersection with obstacles are highlighted by marking the person in red. The trajectories are randomly selected.", "description": "This figure shows a comparison of different methods for human motion generation with zero-shot object avoidance and targeting guidance.  Four different motion types are demonstrated (walking backward, walking on a balance beam, walking, and jogging). Each method (Unconditional, FreeDoM, LGD-MC, and Ours) is shown generating motion sequences for each motion type.  The presence of obstacles and their avoidance are also highlighted.  The key difference between these methods should be observable in how well the methods manage to navigate obstacles and accurately perform the desired motion.", "section": "5.3 Guidance to Human Motion Diffusion"}, {"figure_path": "Eu80DGuOcs/figures/figures_15_1.jpg", "caption": "Figure 1: The classifier loss of a successful and a failure guidance example. The target class is \"indigo bird\".", "description": "This figure shows the classifier loss curves for two examples of training-free guidance in a diffusion model. The target class is \"indigo bird\".  The left panel (a) shows a successful guidance example, where the loss steadily decreases as the diffusion process progresses (t decreases from 800 to 0). The right panel (b) depicts a failed guidance, where the loss remains consistently low, even though the generated image doesn't contain the target class.  The figure illustrates how training-free guidance can sometimes fail to effectively guide the diffusion process toward generating a desired image.", "section": "3 Analysis of Training-Free Guidance"}, {"figure_path": "Eu80DGuOcs/figures/figures_19_1.jpg", "caption": "Figure 2: Gradients of different classifiers on random backgrounds. The images in the first row correspond to the target class \u201ccock\u201d, and the second row to \u201cgoldfinch\u201d.", "description": "This figure shows a qualitative comparison of gradients generated by different classifiers on random backgrounds.  The top row shows the target image, \u201ccock\u201d, while the bottom row shows the target image \u201cgoldfinch\u201d.  Each column represents a different classifier: (a) adversarially robust classifier; (b) time-dependent classifier; (c) off-the-shelf ResNet-50 classifier; and (d) ResNet-50 classifier with random augmentation.  The visualization demonstrates how the accumulated gradients from different classifiers vary, highlighting the impact of classifier type on gradient quality and alignment with the target image. This is used to support the paper's analysis on the misaligned gradients found in training-free guidance.", "section": "3.2 Limitations of Training-free Guidance"}, {"figure_path": "Eu80DGuOcs/figures/figures_20_1.jpg", "caption": "Figure 2: Gradients of different classifiers on random backgrounds. The images in the first row correspond to the target class \u201ccock\u201d, and the second row to \u201cgoldfinch\u201d.", "description": "This figure shows a qualitative comparison of gradients generated by different classifiers on random backgrounds.  The top row displays target images of 'cock', and the bottom row shows target images of 'goldfinch'.  Each column represents the accumulated gradient for a different classifier:  Adversarially robust classifier, time-dependent classifier, off-the-shelf ResNet-50 classifier, and ResNet-50 classifier with random augmentation. The visualization aims to highlight the effect of different classifier types on gradient quality and alignment with the target image, indicating the susceptibility of off-the-shelf classifiers to misaligned gradients.", "section": "3.2 Limitations of Training-free Guidance"}, {"figure_path": "Eu80DGuOcs/figures/figures_21_1.jpg", "caption": "Figure 2: Gradients of different classifiers on random backgrounds. The images in the first row correspond to the target class \u201ccock\u201d, and the second row to \u201cgoldfinch\u201d.", "description": "This figure compares the gradients generated by different types of classifiers when applied to random backgrounds.  It visually demonstrates the impact of different classifier architectures on the quality and alignment of the resulting gradients. The first row showcases the target class \"cock\", while the second row displays the target class \"goldfinch\".  By comparing the gradients, one can assess the effectiveness and robustness of each classifier in guiding the diffusion process.", "section": "3.2 Limitations of Training-free Guidance"}, {"figure_path": "Eu80DGuOcs/figures/figures_22_1.jpg", "caption": "Figure 2: Gradients of different classifiers on random backgrounds. The images in the first row correspond to the target class \u201ccock\u201d, and the second row to \u201cgoldfinch\u201d.", "description": "This figure presents a qualitative comparison of gradients generated by different types of classifiers on random backgrounds.  The goal is to show how the accumulated gradients, when used for guidance in diffusion models, vary in their visual resemblance to the target image.  The classifiers compared are an adversarially robust classifier, a time-dependent classifier, and an off-the-shelf ResNet-50 classifier, both with and without random augmentation. The image in the first row of each block is the target class for comparison. The comparison aims to highlight the tendency of off-the-shelf classifiers (without time-dependence or augmentation) to produce misaligned gradients that hinder effective guidance compared to their time-dependent counterparts. ", "section": "3.2 Limitations of Training-free Guidance"}]