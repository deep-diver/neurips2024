{"references": [{"fullname_first_author": "Prafulla Dhariwal", "paper_title": "Diffusion models beat gans on image synthesis", "publication_date": "2021-12-01", "reason": "This paper is foundational to the field of diffusion models, demonstrating their superiority over GANs in image synthesis and establishing the widespread adoption of diffusion models."}, {"fullname_first_author": "Alec Radford", "paper_title": "Learning transferable visual models from natural language supervision", "publication_date": "2021-07-01", "reason": "CLIP, introduced in this paper, is a crucial component of many training-free diffusion guidance methods, providing a mechanism for bridging image and text information."}, {"fullname_first_author": "Tim Brooks", "paper_title": "Video generation models as world simulators", "publication_date": "2024-01-01", "reason": "This paper extends the capabilities of diffusion models beyond image generation, exploring their potential in video generation and world simulation, which is highly relevant to the broader scope of diffusion model applications."}, {"fullname_first_author": "Jonathan Ho", "paper_title": "Denoising diffusion probabilistic models", "publication_date": "2020-12-01", "reason": "This paper provides the theoretical foundation for diffusion models, introducing the denoising diffusion probabilistic model framework which underpins much of the later work in the field."}, {"fullname_first_author": "Arpit Bansal", "paper_title": "Universal guidance for diffusion models", "publication_date": "2023-06-01", "reason": "This paper proposes a key method that is directly related to training-free guidance, introducing a framework for universal guidance that is adaptable to various control formats."}]}