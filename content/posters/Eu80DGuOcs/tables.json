[{"figure_path": "Eu80DGuOcs/tables/tables_5_1.jpg", "caption": "Table 1: The performance comparison of various methods on CelebA-HQ with different types of zero-shot guidance. The experimental settings adhere to Table 1 of [49].", "description": "This table compares the performance of different methods on the CelebA-HQ dataset using three different types of zero-shot guidance: segmentation maps, sketches, and text descriptions.  The results are presented in terms of FID (Fr\u00e9chet Inception Distance) and a distance metric. Lower FID and distance values indicate better performance. The experimental setup mirrors that of a previous study [49] for fair comparison.", "section": "5.1 Guidance to CelebA-HQ Diffusion"}, {"figure_path": "Eu80DGuOcs/tables/tables_7_1.jpg", "caption": "Table 1: The performance comparison of various methods on CelebA-HQ with different types of zero-shot guidance. The experimental settings adhere to Table 1 of [49].", "description": "This table compares the performance of different methods for generating CelebA-HQ images under three zero-shot guidance conditions: segmentation maps, sketches, and text descriptions.  The metrics used are FID (Fr\u00e9chet Inception Distance) and Distance (a custom distance metric specified in the paper). Lower FID and Distance scores indicate better image quality and alignment with the guidance, respectively. The methods compared include Universal Guidance (UG), Loss-Guided Diffusion with Monte Carlo (LGD-MC), Training-Free Energy-Guided Diffusion Models (FreeDoM), Manifold Preserving Guided Diffusion (MPGD-Z), and the proposed method in the paper. The experimental setup mirrors Table 1 from the cited reference [49].", "section": "5.1 Guidance to CelebA-HQ Diffusion"}, {"figure_path": "Eu80DGuOcs/tables/tables_7_2.jpg", "caption": "Table 2: The performance comparison of various methods on unconditional ImageNet with zero-shot text guidance. We compare various methods using ImageNet pretrained diffusion models with CLIP-B/16 guidance. For evaluating performance, the CLIP score is computed using CLIP-L/14.", "description": "This table compares the performance of different training-free guidance methods on unconditional ImageNet generation using zero-shot text guidance.  The methods are evaluated using CLIP-B/16 for guidance and CLIP-L/14 for scoring, providing a measure of how well the generated images align with the input text prompts.  Higher CLIP scores indicate better alignment.", "section": "5 Experiments"}, {"figure_path": "Eu80DGuOcs/tables/tables_8_1.jpg", "caption": "Table 3: Comparison of various methods on MDM with zero-shot targeting and object avoidance guidance. Loss is reported as a two-component metric: the first part is the MSE between the target and the actual final position of the individual; the second part measures the object avoidance loss.", "description": "This table compares different methods for human motion generation using the Motion Diffusion Model (MDM).  It evaluates performance on zero-shot targeting and object avoidance tasks.  The loss is a combined measure of the Mean Squared Error (MSE) between the target and final position, and an object avoidance loss.  The CLIP score is also included as another metric of performance.", "section": "5.3 Guidance to Human Motion Diffusion"}, {"figure_path": "Eu80DGuOcs/tables/tables_15_1.jpg", "caption": "Table 1: The performance comparison of various methods on CelebA-HQ with different types of zero-shot guidance. The experimental settings adhere to Table 1 of [49].", "description": "This table compares the performance of different methods on the CelebA-HQ dataset using three types of zero-shot guidance: segmentation maps, sketches, and text descriptions.  The FID (Fr\u00e9chet Inception Distance) and Distance metrics are used to evaluate the quality of the generated images.  Lower FID and Distance scores indicate better performance. The experimental settings are consistent with those reported in another paper (reference [49]).", "section": "5.1 Guidance to CelebA-HQ Diffusion"}, {"figure_path": "Eu80DGuOcs/tables/tables_16_1.jpg", "caption": "Table 4: Quantitative experiments for the adversarial gradient. RN-50 stands for ResNet-50 and RA stands for random augmentation trick. Robust RN-50 is adversarial robust ResNet-50 from [35]. The columns represent different guidance networks.", "description": "This table presents a quantitative analysis of the adversarial gradient issue in training-free guidance.  It compares the loss values obtained using different guidance networks (ResNet-50, ResNet-50 with random augmentation, and a robust ResNet-50) against the loss from real images.  The results demonstrate the impact of random augmentation on mitigating misaligned gradients.", "section": "3.2 Limitations of Training-free Guidance"}, {"figure_path": "Eu80DGuOcs/tables/tables_16_2.jpg", "caption": "Table 5: Quantitative experiments for the slower convergence. P stands for Polyak step size. The experimental setting follows the segmentation map guidance of Table 1.", "description": "This table compares the convergence speed of training-free guidance methods (FreeDoM with and without Polyak step size) against a training-based method (PPAP) for image generation using different numbers of DDIM sampling steps (20, 50, and 100).  The values represent the 'distance' metric from Table 1, averaged over 1000 images under the same conditions.", "section": "4 Improving Training-free Guidance"}]