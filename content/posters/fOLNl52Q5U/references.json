{"references": [{"fullname_first_author": "Nicolas Carion", "paper_title": "End-to-end object detection with transformers", "publication_date": "2020-00-00", "reason": "This paper introduces DETR, a foundational transformer-based object detection model that significantly influenced the design of SimVG's decoder branch."}, {"fullname_first_author": "Alexey Dosovitskiy", "paper_title": "An image is worth 16x16 words: Transformers for image recognition at scale", "publication_date": "2020-00-00", "reason": "This paper introduces the Vision Transformer (ViT), a crucial component of SimVG's multimodal encoder, demonstrating the effectiveness of transformers for image processing."}, {"fullname_first_author": "Zhe Gan", "paper_title": "VLMo: Unified vision-language pre-training with mixture-of-modality-experts", "publication_date": "2022-00-00", "reason": "This paper introduces VLMo, a significant multimodal pre-trained model that SimVG leverages for its strong multimodal feature extraction capabilities."}, {"fullname_first_author": "Alec Radford", "paper_title": "Learning transferable visual models from natural language supervision", "publication_date": "2021-00-00", "reason": "This paper introduces CLIP, a model that pre-trains image and text encoders jointly, providing a powerful foundation for SimVG's multimodal understanding."}, {"fullname_first_author": "Junnan Li", "paper_title": "BLIP: Bootstrapping language-image pre-training for unified vision-language understanding and generation", "publication_date": "2022-00-00", "reason": "This paper introduces BLIP, another key multimodal pre-trained model that informs SimVG's approach to unified image and text encoding, improving grounding performance."}]}