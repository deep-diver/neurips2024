[{"type": "text", "text": "Architecture of Decentralized Expert System for Early Alzheimer\u2019s Prediction Enhanced by Data Anomaly Detection ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Anonymous Author(s)   \nAffiliation   \nAddress   \nemail ", "page_idx": 0}, {"type": "text", "text": "Abstract ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "1 Alzheimer\u2019s Disease poses a significant global health challenge, necessitating   \n2 early and precise detection to enhance patient outcomes. Traditional diagnostic   \n3 methodologies often result in delayed and imprecise predictions, particularly in   \n4 the disease\u2019s early stages. Centralized data repositories struggle to manage the   \n5 immense volumes of MRI data, alongside persistent privacy concerns that impede   \n6 collaborative efforts. This paper presents an innovative approach that leverages the   \n7 synergy of blockchain technology (due to crowdsourcing patients\u2019 longitudinal test   \n8 data via Web3 application) and Federated Learning to address these challenges.   \n9 Thus, our proposed decentralized expert system architecture presents a pioneering   \n10 step towards revolutionizing disease diagnostics. Furthermore, the system inte  \n11 grates robust anomaly detection for patient-submitted data. It emphasizes AI-driven   \n12 MRI analysis and incorporates a sophisticated data anomaly detection architecture.   \n13 These mechanisms scrutinize patient-contributed data for various issues, including   \n14 data quality problems. We acknowledge that performing an exhaustive check of   \n15 the correctness and quality of MRI images and biological information directly on  \n16 chain is not practical due to the computational complexity and cost constraints of   \n17 blockchain platforms. Instead, such checks are typically performed off-chain, and   \n18 the blockchain is used to record the results securely. This comprehensive approach   \n19 empowers to provide more precise early-stage Alzheimer\u2019s Disease prediction with   \n20 more volume of data. Our system is designed to safeguard both data integrity and   \n21 patient privacy, facilitating collaborative efforts. ", "page_idx": 0}, {"type": "text", "text": "22 1 Introduction ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "23 Artificial intelligence (AI) is the area of computer science focusing on creation of expert machines that   \n24 engage on human-like intelligence (Russell and Norvig 2002, Hope and Wild 1994, Kasabov 1998).   \n25 The main source of an expert system is the obtained knowledge including a knowledge acquisition   \n26 component that processes data and information and shapes them into rules. Expert systems have a   \n27 large spectrum of application areas such as monitoring, prediction, classification, decision-making,   \n28 planning etc. Importantly, medical diagnosis is one of the major applications of expert systems.   \n29 Medical expert systems are to support the diagnostic process of physicians. This implies that a   \n30 medical expert system employs knowledge about the diseases and compares with facts about the   \n31 patients to suggest a diagnosis (Waterman 2009). Medical expert systems have been successfully   \n32 implemented in diverse medical fields including neurology to improve the accuracy of diagnosis of   \n33 neurological and neuropsychological disorders.   \n34 Alzheimer\u2019s disease (AD) is one of the main neurodegenerative diseases and the leading cause of   \n35 dementia. Research concerning AD evolves primarily around brain structural and functional analyses.   \n36 For AD in particular, the functional analysis-derived network analysis is extremely helpful since   \n37 it correlates different brain regions pointing to alternations of the neurological network and thus   \n38 allowing quicker identification of the disease in its earlier stages. There are continuous demands   \n39 to research in this domain. In fact, several studies have focused on the diagnosis of AD; Obi and   \n40 Imainvan (2011) developed a neuro-fuzzy model for the diagnosis of Alzheimer\u2019s on the basis of   \n41 neuropsychological tests including nine symptoms like memory loss, and difficulty in performing   \n42 familiar tasks. Trambaiolli et al. (2011) developed an AD diagnostic system based on a support vector   \n43 machine which resulted in an accuracy of $79.9\\%$ with $83.2\\%$ sensitivity. Behfar et al. (2020) used   \n44 graph theory to reveal resting-state compensatory mechanisms in early-stages of AD. Venugopalan   \n45 et al. (2021) and Yang and Mohammed (2020) use data from neuroimaging, genomics, and clinical   \n46 assessments for AD prediction. There are other and more recent studies that provide even better accu  \n47 racies (Liu et al. 2023). However, all these studies suffer from a lack or shortage of longitudinal data   \n48 on the patients, and to the best of our knowledge there has been no research that explores collection of   \n49 such longitudinal data on AD patients via a Web3 application, while blockchain technology has been   \n50 explored for enhancing data security, patient privacy, and traceability in healthcare, with applications   \n51 ranging from medical records management to drug traceability (Agbo et al., 2019, Xi et al, 2022).   \n52 Our goal for this research is to design a decentralized expert system including a Web3 application   \n53 to upload biological information and MRI images of the brain by the patients, keeping their data   \n54 in a privacy-preserving manner, and propose an AI model with a hierarchical federated learning   \n55 setup to detect early-stage AD. This helps patients monitor their AD progression in time, also assists   \n56 clinics who wish to use this software to monitor patients\u2019 disease development. In the first section,   \n57 we discuss the research design and relevant questions, then provide our decentralized solution in the   \n58 next section, and provide the architecture, AI model, class diagram, and its implementation steps. ", "page_idx": 0}, {"type": "text", "text": "", "page_idx": 0}, {"type": "text", "text": "", "page_idx": 1}, {"type": "text", "text": "", "page_idx": 1}, {"type": "text", "text": "59 2 Research Design ", "text_level": 1, "page_idx": 1}, {"type": "text", "text": "60 Magnetic resonance imaging (MRI) allows non-invasive examination of the brain. A three  \n61 dimensional image composed of various voxels can be either \u201cwhite matter\u201d which connects the   \n62 neurons to each other and conducts impulses away from the soma, or the \u201cgrey matter\u201d which is   \n63 mostly made of neuron cell bodies, neuron somas which are the input unit of electrical signals sent   \n64 within the central nervous system. Lastly, when examining an MRI image, there are hollow spaces,   \n65 which are spaces filled with CSF and commonly referred to as \u201cthird tissue\u201d. Brain parcellation   \n66 is the name of the process that splits the brain into multiple ROIs (regions). Prior to any analysis   \n67 on MRI images, they are required to undergo a \u201ccleaning process\u201d, which is called preprocessing.   \n68 Several factors can distort the outputs of an MRI scanning session and thus falsify the results. They   \n69 are referred to as noise and can have multiple sources. Once the preprocessing is performed via FSL   \n70 Library (see FSL in the references), the images can be analyzed depending on the type of MRI. We   \n71 have created a web application which uses the FSL library; it performs the pipeline to create brain   \n72 connectivity matrices using Octave (see GNU Octave in the references) with network modeling and   \n73 pushes to the AI engine. This type of analysis is often performed on resting-state fMRI and describes   \n74 brain functions by the interactions between the highly interconnected brain regions (Sohn et al. 2017). ", "page_idx": 1}, {"type": "text", "text": "75 2.1 Research Questions ", "text_level": 1, "page_idx": 1}, {"type": "text", "text": "76 We aim to build a decentralized expert system which includes Web3 application, where MRI images   \n77 and other data can be uploaded and processed. Expert systems are generally composed of knowledge   \n78 base, inference engine, user and user interface. Interaction between these subdivisions makes it an   \n79 expert system. But,   \n80 Research question 1: What are the key factors influencing the accuracy and reliability of the   \n81 decentralized expert system in diagnosing Alzheimer\u2019s Disease?   \n82 The implementation of decentralized expert systems via federated learning in healthcare, particularly   \n83 for Alzheimer\u2019s Disease, represents a transformative approach that leverages the power of distributed   \n84 data while upholding patient privacy. Federated learning enables the creation of sophisticated   \n85 predictive models by training algorithms across multiple decentralized data sources without the need   \n86 to centralize sensitive patient information. By aggregating model improvements rather than raw   \n87 data, federated learning fosters a collaborative yet secure environment for patients and healthcare   \n88 professionals to gain insights from diverse patient populations across various institutions. This   \n89 paradigm shift towards a more decentralized and privacy-preserving model of data analysis and   \n90 disease prediction could significantly improve the diagnostic processes and personalized treatment   \n91 plans for patients. But,   \n92 Research question 2: How does the implementation of decentralized expert system via federated   \n93 learning work?   \n94 A decentralized expert system is a type that is built on a decentralized network of nodes, rather   \n95 than being centrally controlled by a single entity. In this system, each node contains a subset of   \n96 knowledge, and these nodes work together to make decisions. Decentralized expert systems have   \n97 several advantages over traditional expert systems. They are more resilient and less vulnerable to a   \n98 single point of failure, as there is no central point of control. Finally, they can be more transparent   \n99 and secure, as each node can be verified and audited independently. But,   \n100 Research question 3: How does the performance of a decentralized expert system in diagnosing   \n101 Alzheimer\u2019s Disease compare to traditional centralized systems? ", "page_idx": 1}, {"type": "text", "text": "", "page_idx": 1}, {"type": "text", "text": "", "page_idx": 1}, {"type": "text", "text": "", "page_idx": 2}, {"type": "text", "text": "", "page_idx": 2}, {"type": "text", "text": "", "page_idx": 2}, {"type": "text", "text": "", "page_idx": 2}, {"type": "text", "text": "102 3 Solution ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "103 The final purpose of this study is to make longitudinal medical data linked to AD easily accessible to   \n104 perform further disease prediction via a decentralized expert system. ", "page_idx": 2}, {"type": "text", "text": "105 3.1 Decentralized expert system performance ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "106 Apart from the beneftis of decentralized data collection via the patients, decentralized expert system   \n107 (ES) could outperform centralized ES. In some scenarios may involve additional complexities, such   \n108 as variations in data quality, data distribution among sources, and communication overhead in   \n109 decentralized setups.   \n110 Theorem: Decentralized expert system in diagnosing Alzheimer\u2019s Disease could outperform   \n111 traditional centralized expert system.   \n112 Proof: To mathematically prove that decentralized ES provides better performance, we need to   \n113 establish some assumptions and set up a rigorous framework for comparison. Let\u2019s outline the steps   \n114 for the proof:   \n115 Assume we have a centralized ES model that is trained using a centralized dataset containing MRI   \n116 images from various healthcare institutions. We denote the performance of this model as Pcentralized.   \n117 Now, let\u2019s consider a decentralized ES model that is trained using data from multiple sources. The   \n118 data is not pooled in a central location but remains distributed at each source. The performance of   \n119 this model is denoted as Pdecentralized.   \n120 We need to establish a theoretical bound that represents the maximum achievable performance   \n121 of a centralized ES model, given the dataset it has access to. This bound, denoted as $P_{\\mathrm{bound}}$ ,   \n122 acts as a theoretical benchmark for comparison. The mathematical proof involves showing that   \n123 $P_{\\mathrm{decentralized}}\\ge P_{\\mathrm{bound}}>P_{\\mathrm{centralized}}$ . In other words, the decentralized model\u2019s performance is greater   \n124 than or equal to the bound, which in turn is greater than the centralized model\u2019s performance, where   \n125 the bound represents the maximum achievable performance by a centralized model.   \n126 In the proof, we should consider the potential beneftis of data diversity in a decentralized ES setting.   \n127 By training on data from various sources, the decentralized model can capture a more comprehensive   \n128 representation of AD patterns, leading to better generalization and improved performance. Consider   \n129 the potential for algorithmic enhancements in the decentralized setting. With data from multiple   \n130 sources, researchers can explore more sophisticated algorithms that leverage diverse data inputs,   \n131 leading to better feature extraction and model optimization. It\u2019s important to acknowledge any   \n132 communication overhead associated with the decentralized setup. While decentralized models have   \n133 the potential for better performance, communication delays or constraints may impact the overall   \n134 efficiency. Let\u2019s consider a simplified scenario for binary classification tasks, where the goal is to   \n135 predict whether an individual has AD (positive class) or not (negative class) based on MRI images.   \n136 We will focus on the accuracy metric, but the argument can be extended to other performance metrics   \n137 as well. Assumptions:   \n38 \u2022 Centralized ES: A centralized ES model is trained on a dataset containing $N_{c}$ samples   \n39 from a single institution.   \n40 \u2022 Decentralized ES: A decentralized ES model is trained on the same dataset but is distributed   \n41 across $K$ institutions, each contributing $N_{d}$ samples (such that $N_{d}\\times K=N_{c})$ ).   \n142 Let $P_{\\mathrm{centralized}}$ represent the accuracy of the centralized ES model. Let Pdecentralized represent the   \n143 accuracy of the decentralized ES model. Let $P_{\\mathrm{bound}}$ represent the theoretical upper bound on accuracy   \n144 when the model is trained on the entire dataset, i.e., $N_{c}$ samples. ", "page_idx": 2}, {"type": "text", "text": "", "page_idx": 2}, {"type": "text", "text": "", "page_idx": 2}, {"type": "text", "text": "", "page_idx": 2}, {"type": "text", "text": "", "page_idx": 2}, {"type": "text", "text": "", "page_idx": 2}, {"type": "text", "text": "", "page_idx": 3}, {"type": "text", "text": "", "page_idx": 3}, {"type": "text", "text": "145 Mathematical Representation: ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "46 \u2022 Centralized ES: The accuracy of the centralized ES model can be expressed as follows:   \n47 Pcentralized = Number of Correct Predictions   \n48 \u2022 Decentralized ES: The accuracy of the decentralized ES model can be expressed as follows:   \n49 $\\begin{array}{r}{P_{\\mathrm{decentralized}}=\\frac{\\mathrm{Sum\\,of\\,Correct\\,Predictions}}{N_{c}}}\\end{array}$ s from Each Institution   \n50 \u2022 Theoretical Bound: The theoretical bound on accuracy can be expressed as follows:   \n51 Pbound Number of Correct Predictions When Trained on All $\\overline{{N_{c}}}$ $N_{c}$ Samples   \n152 Now, to prove that decentralized ES provides better performance $(P_{\\mathrm{decentralized}}\\geq P_{\\mathrm{bound}}>P_{\\mathrm{centralized}}.$ ,   \n153 we need to show two things: ", "page_idx": 3}, {"type": "text", "text": "", "page_idx": 3}, {"type": "text", "text": "\u2022 $P_{\\mathrm{decentralized}}\\geq P_{\\mathrm{bound}}$ : The decentralized ES model is trained on data from multiple sources, capturing data diversity and enabling better generalization. Hence, it has the potential to achieve an accuracy (Pdecentralized) that is at least as good as the theoretical bound $(P_{\\mathrm{bound}})$ . \u2022 $P_{\\mathrm{centralized}}<P_{\\mathrm{bound}};$ : The centralized ES model is trained on a smaller dataset from a single source/institution, limiting its ability to capture the full data diversity present in the entire dataset. Thus, $P_{\\mathrm{centralized}}$ is likely to be lower than the theoretical bound $\\lfloor P_{\\mathrm{bound}})$ . ", "page_idx": 3}, {"type": "text", "text": "160 Empirical validation on datasets and comprehensive experimentation would be essential to draw   \n161 concrete conclusions about performance comparison between decentralized and centralized models. ", "page_idx": 3}, {"type": "text", "text": "162 3.2 AI model predicting early-stage AD ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "163 The expert systems are being developed using various techniques, which are mostly used to assist   \n164 medical practitioners in diagnosis. In this study, we need to train the AI model (Figure 1) via the   \n165 data that we have obtained from the Alzheimer\u2019s Disease Neuroimaging Initiative (ADNI) database   \n166 (http://adni.loni.usc.edu), a public-private partnership launched in 2003 by Michael Weiner, MD.   \n167 Our proposed framework consists of processing steps: feature extraction, feature selection, and   \n168 classification. We examined different feature selection methods to choose an optimal subset of   \n169 features, maximizing the accuracy of classification between cognitively normal (CN), individuals   \n170 with significant memory concern (SMC) and mild cognitive impairment (MCI) patients. The subjects   \n171 are randomly split into training and testing datasets, the classifier is trained using the training dataset,   \n172 and the testing dataset is passed to the trained classifier to measure the performance.   \n173 We have used data for 561 subjects total, among those, 231 SMC, 259 CN, and 71 MCI patients. The   \n174 feature selection algorithms were applied to the graph features (degree centrality for each ROI) to   \n175 select the most discriminating features for the classification of MCI, SMC, and CN subjects. The   \n176 Sequential Forward Selection feature selection algorithm and the Random Forest classifier resulted in   \n177 a satisfying performance with accuracy of more than $92\\%$ as shown in Figure 2. We run the models   \n178 on a MacBook Pro equipped with an Intel Core i9 processor, featuring 8 cores, speed of up to 4.8   \n179 GHz, and 30 GB of RAM.   \n180 The graph features were obtained by applying graph theory analysis on rs-fMRI images. The pre  \n181 processing, network modeling for graph feature extraction is done via FSL library. The patients can   \n182 therefore input their MRI images via the provided App, and the FSL library processes, and generates   \n183 the brain connectivity matrix. From longitudinal measures, patients are labeled as non-convertors and   \n184 convertors fulfilling the criteria for Prodromal AD\u2019s continuum according to Jack et al. (2018). At   \n185 this stage, we have just trained the AI model with publicly available ADNI data. ", "page_idx": 3}, {"type": "image", "img_path": "GxpkSJjbQR/tmp/73e772f2948b90a7e719ab39d3a7ebd3f0178c641b47ada713256c1a87092cb1.jpg", "img_caption": ["Figure 1: AI classification model "], "img_footnote": [], "page_idx": 3}, {"type": "text", "text": "", "page_idx": 3}, {"type": "image", "img_path": "GxpkSJjbQR/tmp/665c49a1d2820fe2ced7373f8fe3d61d9f15bebbbd8a83db4dcf714b38b5bf78.jpg", "img_caption": ["Figure 2: Classification accuracy of AI model. "], "img_footnote": [], "page_idx": 4}, {"type": "text", "text": "", "page_idx": 4}, {"type": "text", "text": "", "page_idx": 4}, {"type": "text", "text": "186 3.3 Hierarchical Federated Learning ", "text_level": 1, "page_idx": 4}, {"type": "text", "text": "187 Our initial choice of using federated learning combined with blockchain technology was motivated   \n188 by the need for decentralized, secure data sharing, and crowdsourcing in healthcare settings (Behfar   \n189 and Crowcroft, 2024). MRI scans are highly sensitive and specific to individual patients. Pre-trained   \n190 models, while beneficial for general tasks, may not be optimally suited for such intricate and specific   \n191 patterns. Using pre-trained models could risk overfitting, potentially compromising patient privacy   \n192 and the model\u2019s generalizability to new, unseen data. Furthermore, diagnosis often requires specific   \n193 feature representations that capture subtle variations in brain images indicative of the disease. Transfer   \n194 learning, while effective, might not allow for the fine-tuning required to extract these specialized   \n195 features optimally.   \n196 Implementing a hierarchical federated learning system within a blockchain-based platform for   \n197 Alzheimer\u2019s Disease (AD) diagnosis represents an innovative approach to medical data analysis and   \n198 privacy preservation. In this setup, patients upload their medical test data, including MRI images   \n199 onto the generated DApp. This application acts as a gateway to the decentralized platform, leveraging   \n200 blockchain for data integrity and security (appendix A and B). The hierarchical federated learning   \n201 process then unfolds in a structured manner across a cluster of nodes, ensuring that patient data   \n202 remains localized and secure throughout the learning process.   \n203 The procedure begins with the division of the federated network into clusters, each corresponding to   \n204 a specific a group of nodes within the healthcare ecosystem, such as hospitals or research institutions.   \n205 Within each cluster, local learning models are trained on the patient data available to that cluster. This   \n206 local training process allows each node to develop an understanding of AD features and indicators   \n207 based on the subset of data it has access to, without exposing patient data beyond its original   \n208 location. After local model training, each cluster aggregates its findings to update a local model. The   \n209 hierarchical aspect of this approach comes into play with the aggregation of these locally updated   \n210 models across the network. Instead of directly combining data from all nodes, the models trained   \n211 locally within each cluster are first aggregated to form a cluster-level model. These cluster-level   \n212 models then contribute to the training of a global model. ", "page_idx": 4}, {"type": "text", "text": "", "page_idx": 4}, {"type": "text", "text": "", "page_idx": 4}, {"type": "text", "text": "213 3.4 Anomaly Detection ", "text_level": 1, "page_idx": 4}, {"type": "text", "text": "214 There are issues related to bias, data quality and inconsistency in the data collection/labelling,   \n215 and performing an exhaustive check of the correctness and quality of MRI images and biological   \n216 information directly on-chain is not practical due to the computational complexity and cost constraints   \n217 of blockchain platforms. Instead, such checks are typically performed off-chain, and the blockchain   \n218 is used to record the results securely.   \n219 A practical example of a smart contract that allows patients to submit their data along with a brief   \n220 initial evaluation is given in Listing 1 (see Appendix C). The contract stores this data on-chain and   \n221 allows patients to verify and timestamp their submissions. Note that this contract primarily serves   \n222 as a ledger for the data and initial evaluation results, and more comprehensive checks should be   \n223 performed off-chain by the application (DApp) before submitting data to the blockchain. In this   \n224 contract, the \"submitCertificate\" function allows patients to submit the results of the off-chain anomaly   \n225 detection process. The \"verifyCertificate\" function allows patients to verify their certificates. One can   \n226 implement additional verification steps in the \"verifyCertificate\" function as needed. To implement   \n227 a smart certificate for anomaly detection on the client side of a medical data sharing platform, we   \n228 would use off-chain data analysis techniques since performing anomaly detection directly on-chain   \n229 can be expensive and inefficient due to the trade-off between performance and security.   \n230 Data Collection: Patients provide their biological information and MRI images along with times  \n231 tamps to the application.   \n232 Off-Chain Anomaly Detection: Implement advanced anomaly detection algorithms off-chain within   \n233 the App. For MRI images, one might use computer vision techniques, and for biological information,   \n234 statistical or machine learning methods can be applied to detect anomalies. These algorithms should   \n235 thoroughly evaluate the correctness and quality of the data.   \n236 Smart Certificate Creation: After off-chain anomaly detection, create a detailed smart certificate   \n237 within the App to include:   \n238 \u2022 Anomaly type (e.g., incorrect data, bad images, etc.).   \n239 \u2022 Timestamp.   \n240 \u2022 Metadata about the data and the anomaly.   \n241 \u2022 Any relevant context or notes about the anomaly.   \n242 Blockchain Interaction: Use a smart contract on the blockchain to securely store and verify the   \n243 smart certificates generated within the App. The smart contract records the results of the anomaly   \n244 detection process, providing an immutable and auditable record. ", "page_idx": 4}, {"type": "text", "text": "", "page_idx": 5}, {"type": "text", "text": "", "page_idx": 5}, {"type": "text", "text": "", "page_idx": 5}, {"type": "text", "text": "", "page_idx": 5}, {"type": "text", "text": "", "page_idx": 5}, {"type": "text", "text": "", "page_idx": 5}, {"type": "text", "text": "", "page_idx": 5}, {"type": "text", "text": "245 3.4.1 Off-chain anomaly detection for biological information ", "text_level": 1, "page_idx": 5}, {"type": "text", "text": "246 For biological information, anomaly detection can involve statistical methods or machine learning   \n247 techniques, depending on the nature and structure of the data. Here in Listing 2 (see Appendix C), we   \n248 provide an approach using Python and the popular scikit-learn library: In this example, we perform   \n249 the following steps:   \n250 \u2022 Load biological data.   \n251 \u2022 Select the relevant features for anomaly detection.   \n252 \u2022 Apply feature scaling using StandardScaler.   \n253 \u2022 Reduce dimensionality using PCA.   \n254 \u2022 Choose an anomaly detection model (Isolation Forest, or) and fit it to the reduced data.   \n255 \u2022 Predict anomaly scores for each data point.   \n256 \u2022 Define a threshold for anomaly detection.   \n257 \u2022 Identify anomalies based on the threshold. ", "page_idx": 5}, {"type": "text", "text": "", "page_idx": 5}, {"type": "text", "text": "258 3.4.2 Off-chain anomaly detection for MRI images ", "text_level": 1, "page_idx": 5}, {"type": "text", "text": "259 Detecting anomalies in MRI images typically involves computer vision techniques and deep learning   \n260 models. One might consider using popular deep learning libraries like TensorFlow or PyTorch. Here   \n261 in Listing 3 (see Appendix C), we provide an approach using a pre-trained model. This approach   \n262 allows to detect anomalies in MRI images based on how well the autoencoder can reproduce the   \n263 input image. Anomalies will typically result in higher MSE values compared to normal images. One   \n264 might need to fine-tune the threshold based on the dataset and requirements. In this code:   \n265 \u2022 Load a pre-trained autoencoder model (both encoder and decoder parts). Autoencoders   \n266 learn to encode data efficiently and are often used for anomaly detection because they can   \n267 reproduce normal data accurately.   \n268 \u2022 Load an MRI image (replace \u2019mri_image.png\u2019) and preprocess it.   \n269 \u2022 Encode the image using the autoencoder\u2019s encoder part, then decode it to get a reconstructed   \n270 image.   \n271 \u2022 Calculate the Mean Squared Error (MSE) between the original and reconstructed images.   \n272 This measures how well the model can reproduce the input.   \n273 \u2022 Set a threshold for the MSE, above which an anomaly is detected. ", "page_idx": 5}, {"type": "text", "text": "", "page_idx": 5}, {"type": "text", "text": "", "page_idx": 6}, {"type": "text", "text": "274 4 System Development ", "text_level": 1, "page_idx": 6}, {"type": "text", "text": "275 4.1 System Architecture ", "text_level": 1, "page_idx": 6}, {"type": "text", "text": "276 In regard to System Development status, all the system components according to the class diagram in   \n277 Figure 3 have already been developed. The user-interface application is based on FSL library, and   \n278 performs MRI data processing, and will be discussed further in the application development section.   \n279 The underlying blockchain technology for decentralized data sharing has already been developed,   \n280 which is based on hyperldger fabaric technology for on-chain, and IPFS for off-chain data sharing as   \n281 pilot project. There are alternative solutions such as zero-knowledge and optimistic rollups (Behfar   \n282 et al., 2023). The ML models for early AD detection have also been developed, trained, and tested   \n283 using public dataset ADNI, mentioned above in \"AI Model Predicting Prodromal AD\", as shown in   \n284 algorithm 1. The model is supposed to update or learn from new data in the federated learning setup.   \n285 Figure 3 illustrates the class diagram of the whole system, where each class is defined below:   \n286 User Interface: This is the primary interface for patients to input their anonymous biological info   \n287 and MRI images and receive prediction deposition and recommendations; this includes approaching   \n288 a specialist for further and more certain diagnostics. It\u2019s the front-end through which users interact   \n289 with the system.   \n290 Data Security and Privacy: This component would be responsible for ensuring that patient data,   \n291 particularly sensitive MRI images, are handled securely and in compliance with privacy regulations.   \n292 It interfaces with both the User Interface (to ensure that data is securely transmitted) and the Decen  \n293 tralized Data Sharing component (to ensure that data is securely stored and shared).   \n294 MRI Data Processing: This component processes the MRI images provided by patients through the   \n295 User Interface. It uses tools like the FSL library for generating brain connectivity matrices, which are   \n296 crucial for AD prediction. This processed data would then be fed into the AI Model for analysis and   \n297 prediction/classification.   \n298 Decentralized Data Sharing: This component is responsible for the secure and anonymous manage  \n299 ment of patient data within the decentralized network. It ensures that data from various patients is   \n300 collected without compromising individual privacy. ", "page_idx": 6}, {"type": "image", "img_path": "GxpkSJjbQR/tmp/d461cbf1bf8397cd8119009e97ea8e076dc5e7d582a3b6c24e56557a04ba5d56.jpg", "img_caption": ["Figure 3: Class diagram "], "img_footnote": [], "page_idx": 6}, {"type": "text", "text": "", "page_idx": 6}, {"type": "text", "text": "", "page_idx": 6}, {"type": "text", "text": "", "page_idx": 6}, {"type": "text", "text": "", "page_idx": 6}, {"type": "text", "text": "301 AI Model: The AI model, possibly a Random Forest classifier or similar, is trained on the aggregated ", "page_idx": 6}, {"type": "table", "img_path": "GxpkSJjbQR/tmp/0e4a7b86730074e760502e678667da71a99365323e3f47566b0d82ac784ad787.jpg", "table_caption": [], "table_footnote": [], "page_idx": 7}, {"type": "text", "text": "302 brain connectivity matrices. It\u2019s responsible for early-stage AD detection, and making predictions   \n303 about the progression to AD. This model will continuously learn from new patient data, in federated   \n304 learning or decentralized model update setup, improving its accuracy and adaptability over time.   \n305 Governance: This component oversees the overall functioning of the system, ensuring that all parts   \n306 work together cohesively, aggregating model, adhere to set standards and regulations. It will also be   \n307 involved in updating the system, incorporating patient feedback, and ensuring the system\u2019s continuous   \n308 improvement.   \n309 To implement the described decentralized expert system, one needs to integrate several components   \n310 and consider the role of patients in the system. The overview of the implementation steps is given in   \n311 Algorithm 1. Regarding the role of patients in the system:   \n312 \u2022 Patients primarily interact with the system as users. They provide input data, receive   \n313 predictions, and have access to monitoring and recommendations. They are not typically   \n314 considered global nodes in the entire decentralized network, but nodes in local clusters.   \n315 \u2022 The decentralized network consists of nodes that share and process data. These nodes may   \n316 include user systems, AI model components, and cluster of users.   \n317 Our presumed experimentation encompasses several critical scenarios. Firstly, we evaluate the   \n318 efficiency of the User Interface in terms of data input speed, user satisfaction, and the clarity of   \n319 prediction results. Secondly, the Data Security and Privacy component\u2019s effectiveness will be assessed   \n320 to ensure the confidentiality and integrity of patient data, checking for potential unauthorized access.   \n321 The accuracy and reliability of the MRI Data Processing component is tested against benchmarks,   \n322 assessing the quality of the generated brain connectivity matrices crucial for AD prediction. The   \n323 system\u2019s capability to securely manage patient data within the decentralized network is also be   \n324 measured, focusing on the speed, efficiency, and security of data sharing and retrieval processes.   \n325 Moreover, the AI model\u2019s performance in early-stage AD detection is validated using metrics such as   \n326 accuracy, precision, recall, F1-score, and the ROC curve. ", "page_idx": 7}, {"type": "text", "text": "", "page_idx": 7}, {"type": "text", "text": "", "page_idx": 7}, {"type": "text", "text": "", "page_idx": 7}, {"type": "text", "text": "327 4.2 Application Development ", "text_level": 1, "page_idx": 7}, {"type": "text", "text": "328 For our developed application which does MRI preprocessing, we use FSL library which is extremely   \n329 powerful when it comes to applying and automating workflow since it can unify some of the most   \n330 crucial steps into one pipeline only. The scripts from the FSL library can be run on either Linux   \n331 or macOS. FSL unifies some of the most crucial steps into one pipeline only and thereby facilitate   \n332 the entire workflow, see https://github.com/\\*\\*\\*\\*\\*, also note that to use FSLNets either Octave or   \n333 MATLAB must be running. Putting all the steps together, here is what a workflow could look like:   \n334 \u2022 Skull stripping \u2013 using BET   \n335 \u2022 Preprocessing \u2013 using the modules indicated at the preprocessing step   \n336 \u2022 Node definition \u2013 using MELODIC and Octave   \n337 \u2022 Generating connectivity matrix \u2013 using FSLNets   \n338 The backend of this application will not only mange the project\u2019s APIs, from frontend to backend   \n339 to database and vice-versa, but also manage the interaction with FSL and Octave. The latter is   \n340 indispensable for the creation of the Brain Connectivity Matrix (BCM). As indicated in Figure 4,   \n341 Schlappinger (2023), all user requests always pass via the server\u2019s API-service first, and are dispatched   \n342 to the corresponding service. When the user tries to log in, the log-in data is sent to the backends\u2019   \n343 API service, then sends it to the corresponding application service, which in this case would be the   \n344 authentication service. It handles the transferred data and asks for identification by sending requests   \n345 to the database. The database response is sent to the application service, and the response back to the   \n346 API. With the definition of the expert system, the web application does preprocessing on the subjects   \n347 to finally output the brain connectivity matrix that is available immediately after processing.   \n348 In terms of scalability, our system is designed to efficiently manage and process large volumes   \n349 of patient data, making it highly scalable to accommodate the growing demands of medical data   \n350 analytics. The decentralized architecture leverages blockchain technology, specifically Hyperledger   \n351 Fabric for on-chain data storage and IPFS for off-chain data sharing, ensuring secure and distributed   \n352 data management across the network. This decentralized approach allows the system to seamlessly   \n353 integrate new patient data sources without imposing significant overhead or compromising data   \n354 privacy. Moreover, the federated learning setup enables collaborative model training across multiple   \n355 nodes, allowing the AI model to learn from diverse and geographically distributed datasets while   \n356 preserving data locality and reducing computational burden on individual nodes. Additionally, the   \n357 modular design of the system as depicted in the class diagram (Figure 3) facilitates independent   \n358 scaling of each component enabling efficient resource allocation and optimal performance even as   \n359 the system expands to incorporate more patients, data sources, and computational nodes. Thus, our   \n360 system not only ensures data security and privacy but also exhibits high scalability and efficiency. ", "page_idx": 7}, {"type": "text", "text": "", "page_idx": 8}, {"type": "text", "text": "", "page_idx": 8}, {"type": "image", "img_path": "GxpkSJjbQR/tmp/abce771d5f8f4aa1c05244a5b880740df36e92ce5e9329dc98a8dc05bde8cc50.jpg", "img_caption": ["Figure 4: backend-frontend infrastructure diagram. "], "img_footnote": [], "page_idx": 8}, {"type": "text", "text": "", "page_idx": 8}, {"type": "text", "text": "361 5 Conclusion ", "text_level": 1, "page_idx": 8}, {"type": "text", "text": "362 In this paper, we have presented a novel approach to address the challenges associated with managing   \n363 and analyzing massive centralized repositories of MRI data and persistent privacy concerns for early   \n364 AD prediction. Our primary position advocates for the integration of blockchain technology with   \n365 federated learning to establish a decentralized expert system. This system aims to preserve data   \n366 privacy, ensure security, and facilitate efficient analysis across decentralized network. Overall, the   \n367 decentralized expert system for early-stage AD detection can leverage the decentralized collected data   \n368 and intelligence to provide accurate and timely predictions. Our expert system serves as a model tool   \n369 that collects patients\u2019 data in a decentralized way via our FSL-built application. FSL using Octave   \n370 creates brain connectivity matrices and pushes to the AI engine. Our trained model uses Sequential   \n371 Forward Selection feature selection algorithm and the Random Forest classifier resulting in accuracy   \n372 of more than $92\\%$ ; the classification model is retrained by updated parameters based on hierarchical   \n373 federated learning setup. This method offers a scalable, privacy-preserving framework for leveraging   \n374 vast amounts of medical data, potentially leading to more accurate and early detection of AD, while   \n375 ensuring patient data remains secure and private. This not only helps individuals to detect early-stage   \n376 AD in time, but also helps clinics and hospitals who are willing to use this solution to effectively   \n377 monitor the patients and predict their progression with less ambiguity. ", "page_idx": 8}, {"type": "text", "text": "378 References ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "379 1. ADNI, Alzheimer\u2019s Disease Neuroimaging Initiative. https://adni.loni.usc.edu/   \n380 2. Agbo, C.C., Mahmoud, Q.H. and Eklund, J.M., 2019. Blockchain technology in healthcare:   \n381 A systematic review. Healthcare, 7(2), p.56. Available at: https://doi.org/10.3390/   \n382 healthcare7020056   \n383 3. Behfar, S.K., Th\u00e9odoloz, F., Schranz, C, and Hosseinpour, M. 2023. Blockchain-based   \n384 data sharing platform customization with on/off-chain data balancing,\u201d Proceeding of IEEE   \n385 International Conference on Blockchain Computing and Applications (BCCA Kuwait 2023).   \n386 4. Behfar, Q., Behfar, S.K., Von Reutern, B., Richter, N., and Dronse, J. 2020. Graph theory   \n387 analysis reveals resting-state compensatory mechanisms in healthy aging and prodromal   \n388 Alzheimer\u2019s disease. Frontiers in aging neuroscience, 12, 355.   \n389 5. Behfar, S.K. and Crowcroft, J. 2024. Decentralized crowdsourcing medical data sharing   \n390 platform to obtain chronological rare data. Journal of Data and Policy, 6.   \n391 6. FSL website. https://fsl.fmrib.ox.ac.uk/fsl/fslwiki/FSL   \n392 7. Jack, C.R., Bennett, D.A., Blennow, K., Carrillo, M.C., Dunn, B., Haeberlein, S.B., Holtz  \n393 man, D.M., Jagust, W., Jessen, F., Karlawish, J., Liu, E., Molinuevo, J.L., Montine, T.,   \n394 Phelps, C., Rankin, K.P., Rowe, C.C., Scheltens, P., Siemers, E., Snyder, H.M., Sperling, R.,   \n395 Contributors, R. (2018). NIA-AA Research Framework: Toward a biological definition of   \n396 Alzheimer\u2019s disease. Alzheimers&Dementia, 14, p. 535.   \n397 8. Kasabov, N.K. (1998). Foundations of Neural Networks, Fuzzy Systems, and Knowledge   \n398 Engineering. Bradford Book, The MIT Press, Cambridge, Massachusetts.   \n399 9. Khalid, N., Qayyum, A., Bilal, M., Al-Fuqaha, A. and Qadir, J., 2023. Privacy-preserving   \n400 artificial intelligence in healthcare: Techniques and applications. Computers in Biology and   \n401 Medicine, 158, p.106848.   \n402 10. GNU Octave Wiki. https://wiki.octave.org/GNU_Octave_Wiki   \n403 11. Hope, B.G. and Wild, R.H. (1994). An Expert Support System for Service Quality Im  \n404 provement. Proceedings of the Twenty-Seventh Annual Hawaii International Conference on   \n405 System Science.   \n406 12. Liu, S., Cao, Y., Liu, J., and Ding, X. (2023). A novelty detection approach to effectively   \n407 predict conversion from mild cognitive impairment to Alzheimer\u2019s disease. International   \n408 Journal of Machine Learning and Cybernetics, 14, pp. 213\u2013228.   \n409 13. Morley, J., Machado, C.C.V., Burr, C., Cowls, J., Joshi, I., Taddeo, M. and Floridi, L., 2020.   \n410 The ethics of AI in health care: A mapping review. Social Science Medicine, 260, p.113172.   \n411 14. Obi, J.C. and Imainvan, A.A. (2011). Decision Support System for the Intelligent Identi  \n412 fication of Alzheimer using Neuro Fuzzy logic. International Journal on Soft Computing,   \n413 2(2).   \n414 15. Russell, S. and P. Norvig. (2002). Artificial Intelligence: A Modern Approach. Prentice   \n415 Hall, Second Edition.   \n416 16. Sohn, W.S., Lee, T.Y., Yoo, K., Kim, M., Yun, J.Y., Hur, J.W., Yoon, Y.B., Seo, S.W.,   \n417 Na, D.L., Jeong, Y., and Kwon, J.S. (2017). Node Identification Using Inter-Regional   \n418 Correlation Analysis for Mapping Detailed Connections in Resting State Networks. Frontier   \n419 Neuroscience, 11.   \n420 17. Schlappinger, J. (2023). Creation of a web application using FSL tools. Thesis Work at   \n421 HEG Gen\u00e8ve.   \n422 18. Trambaiolli, L.R., Lorena, A.C., Fraga, F.J., Kanda, P.A.M., Anghinah, R., and Nitrini,   \n423 R. (2011). Improving Alzheimer\u2019s Disease Diagnosis with Machine Learning Techniques.   \n424 Clinical EEG Neuroscience, 42(3), pp.160-5.   \n425 19. Venugopalan, J., Tong, L., Hassanzadeh, H.R., and Wang, M.D. 2021. Multimodal deep   \n426 learning models for early detection of Alzheimer\u2019s disease stage. Sci Rep 2021 5, 11(1),   \n427 3254.   \n428 20. Waterman, D.A. (2009). A Guide to Expert Systems. Pearson Education Inc.   \n429 21. Westphal, E. and Seitz, H., 2021. Digital and decentralized management of patient data   \n430 in healthcare using blockchain implementations. Frontiers in Blockchain, 4. Available at:   \n431 https://doi.org/10.3389/fbloc.2021.732112   \n432 22. Xi, P., Zhang, X., Wang, L., Liu, W. and Peng, S., 2022. A review of blockchain-based   \n433 secure sharing of healthcare data. Applied Sciences, 12(15), p.7912.   \n434 23. Yang, K. and Mohammed, E.A., 2021. A review of artificial intelligence technologies for   \n435 early prediction of Alzheimer\u2019s Disease. Available at: https://arxiv.org/abs/2101.   \n436 01781 ", "page_idx": 9}, {"type": "text", "text": "", "page_idx": 10}, {"type": "text", "text": "437 A Application security ", "text_level": 1, "page_idx": 10}, {"type": "text", "text": "438 Ensuring the security and privacy of medical data is of paramount importance in our system develop  \n439 ment. We implement a comprehensive set of measures to safeguard sensitive information, maintain   \n440 data integrity, and comply with privacy regulations. ", "page_idx": 10}, {"type": "text", "text": "441 Data Encryption ", "text_level": 1, "page_idx": 10}, {"type": "text", "text": "442 End-to-End Encryption: All medical data, including biological information and MRI images, undergo   \n443 end-to-end encryption using industry-standard encryption algorithms. This means that data is   \n444 encrypted at its source (on the patient\u2019s side) and remains encrypted during transmission and storage   \n445 within our system. Even if an unauthorized entity intercepts the data, it remains indecipherable   \n446 without the encryption keys.   \n447 AES Encryption: We employ the Advanced Encryption Standard (AES) for data encryption. AES   \n448 is a widely recognized and robust encryption algorithm known for its security and performance. It   \n449 ensures that patient data is protected from unauthorized access. ", "page_idx": 10}, {"type": "text", "text": "", "page_idx": 10}, {"type": "text", "text": "450 Secure Transmission ", "text_level": 1, "page_idx": 10}, {"type": "text", "text": "451 HTTPS: We utilize the Hypertext Transfer Protocol Secure (HTTPS) for web-based data transmission.   \n452 HTTPS is a secure communication protocol that combines the standard HTTP with encryption using   \n453 Transport Layer Security (TLS) or Secure Sockets Layer (SSL) protocols. This encryption layer   \n454 ensures that data exchanged between the client and our system is shielded from eavesdropping and   \n455 tampering during transit.   \n456 Blockchain Technology: Our system leverages blockchain technology to enhance the security of data   \n457 sharing. Blockchain, with its decentralized and immutable ledger, provides an additional layer of   \n458 protection. Each data transaction is recorded on the blockchain, and once added, it cannot be altered.   \n459 This ensures transparent and secure data sharing among authorized parties. ", "page_idx": 10}, {"type": "text", "text": "", "page_idx": 10}, {"type": "text", "text": "460 Privacy Compliance ", "text_level": 1, "page_idx": 10}, {"type": "text", "text": "461 Access Control: Access control mechanisms are in place to restrict data access to only authorized   \n462 healthcare professionals and patients. Role-based access control ensures that individuals can only   \n463 access the data that is relevant to their responsibilities. Patients have control over who can access   \n464 their data, granting consent for sharing, and revoking access as needed.   \n465 HIPAA and GDPR Compliance: Our system adheres to the Health Insurance Portability and Account  \n466 ability Act (HIPAA) and the General Data Protection Regulation (GDPR), in addition to local data   \n467 protection laws. These compliance measures provide a legal framework for the secure handling of   \n468 patient data, including rules for data access, storage, and sharing.   \n469 Regular Audits and Privacy Impact Assessments: To maintain compliance, we need to conduct   \n470 regular system audits and privacy impact assessments. These evaluations help us identify and rectify   \n471 potential privacy issues and vulnerabilities in our system. They also ensure that we remain aligned   \n472 with the latest data protection regulations.   \n473 Even if patient data is anonymized, it\u2019s often advisable and may be legally required to comply with   \n474 many of the security and privacy measures mentioned above. Anonymization can reduce the risk   \n475 associated with the disclosure of sensitive information, but it doesn\u2019t necessarily exempt a system   \n476 from all privacy regulations or security best practices. ", "page_idx": 10}, {"type": "text", "text": "477 B Scope Limitations and Societal Impact ", "text_level": 1, "page_idx": 11}, {"type": "text", "text": "478 Despite the promising aspects of the proposed system, several limitations need to be acknowledged: ", "page_idx": 11}, {"type": "text", "text": "479 \u2022 Data Quality and Consistency: The accuracy of the AI model heavily relies on the quality   \n480 and consistency of the input data. Variability in MRI image quality, biological information,   \n481 and other patient-contributed data can affect the model\u2019s performance.   \n482 \u2022 Computational Complexity: Performing exhaustive checks of MRI images and biological   \n483 data directly on the blockchain is not feasible due to the high computational costs. This   \n484 necessitates off-chain processing, which may introduce additional complexity and potential   \n485 delays.   \n486 \u2022 Model Generalizability: The AI model is initially trained on public datasets, which may not   \n487 fully capture the diversity of the broader patient population. While the system can update the   \n488 model with new patient data, initial predictions might be less accurate for underrepresented   \n489 groups.   \n490 \u2022 Privacy and Security Concerns: Although blockchain technology enhances data security and   \n491 privacy, it also introduces new challenges. Ensuring that all aspects of patient data handling   \n492 comply with privacy regulations and maintaining robust security measures against potential   \n493 cyber threats are ongoing concerns.   \n494 \u2022 Technical Barriers for Patients: The decentralized nature of the system requires patients   \n495 to engage with technology such as blockchain wallets and data submission interfaces.   \n496 This could be a barrier for less tech-savvy individuals, potentially limiting the system\u2019s   \n497 accessibility and usability.   \n498 \u2022 Regulatory and Ethical Issues: The deployment of such a decentralized medical diagnostic   \n499 system must navigate complex regulatory landscapes. Ensuring compliance with medical   \n500 standards, obtaining necessary approvals, and addressing ethical considerations related to   \n501 AI-driven medical predictions are critical challenges.   \n502 \u2022 Scalability: As the number of users and the volume of data increase, the system\u2019s scalability   \n503 could become a concern. Efficiently managing large datasets and ensuring timely processing   \n504 and predictions in a decentralized environment will require ongoing optimization.   \n505 The development and implementation of a decentralized expert system for early-stage Alzheimer\u2019s dis  \n506 ease prediction hold significant societal implications. On the positive side, this technology promises   \n507 to enhance early detection and intervention, leading to improved patient outcomes and quality of   \n508 life. By enabling timely and accurate predictions, patients can benefit from early treatment, poten  \n509 tially slowing disease progression and delaying severe symptoms. The system\u2019s use of blockchain   \n510 technology ensures robust data privacy and security, fostering patient trust in the confidentiality of   \n511 their health information. Additionally, the ability to update and personalize the AI model with new   \n512 patient data allows for more tailored healthcare solutions, offering personalized treatment plans that   \n513 cater to individual needs. This, in turn, can reduce long-term healthcare costs by decreasing the   \n514 need for intensive care in advanced stages of Alzheimer\u2019s disease. Moreover, the secure sharing of   \n515 anonymized data for research purposes can accelerate scientific discoveries and the development of   \n516 new treatments.   \n517 However, the deployment of such a system also presents challenges. The reliance on digital tools for   \n518 data submission and interaction may exclude individuals who lack access to technology or have limited   \n519 digital literacy, potentially exacerbating health disparities among older adults and socioeconomically   \n520 disadvantaged groups. Despite blockchain\u2019s security measures, there may still be privacy concerns,   \n521 and any data breaches could undermine patient trust. Ethical and regulatory challenges arise from the   \n522 need to ensure the accuracy and fairness of AI-driven predictions, and obtaining necessary approvals   \n523 remains an ongoing hurdle. Over-reliance on technology might marginalize human clinical expertise,   \n524 highlighting the importance of maintaining a balance between AI support and healthcare professional   \n525 judgment. Additionally, the economic implications of implementing and maintaining such advanced   \n526 systems must be considered, as they may impose financial burdens on healthcare providers and   \n527 patients. By addressing these societal impacts thoughtfully, the deployment of the decentralized   \n528 expert system can maximize its benefits while minimizing potential harms, contributing to more   \n529 equitable and effective healthcare. ", "page_idx": 11}, {"type": "text", "text": "", "page_idx": 11}, {"type": "text", "text": "", "page_idx": 11}, {"type": "text", "text": "530 C Listings ", "text_level": 1, "page_idx": 12}, {"type": "text", "text": "531 Here are all the referred listings in the main text: ", "page_idx": 12}, {"type": "text", "text": "532 The smart contract, listing 1 named MedicalDataSubmission, enables patients to securely submit and   \n533 verify their medical data on the Ethereum blockchain. The contract defines a PatientData structure   \n534 that includes the patient\u2019s address, biological information, evaluation, timestamp, and a verification   \n535 status. Patients can submit their data using the submitData function, which ensures that both the   \n536 biological information and evaluation are non-empty before storing the data along with the current   \n537 timestamp and an initial unverified status. The submitted data is added to the submissions array,   \n538 B and an event DataSubmitted is emitted to log the submission details. Patients can later verify their   \n539 own submissions using the verifySubmission function, which checks that the submission exists, the   \n540 caller is the patient who submitted the data, and the submission has not already been verified. Upon   \n541 successful verification, the submission\u2019s status is updated to verified. This contract ensures data   \n542 integrity and provides a transparent mechanism for patients to manage their medical information. ", "page_idx": 12}, {"type": "text", "text": "// SPDX-License-Identifier: MIT   \npragma solidity ^0.8.0;   \ncontract MedicalDataSubmission { struct PatientData { address patient; string biologicalInfo; string evaluation; uint256 timestamp; bool isVerified; } PatientData[] public submissions; event DataSubmitted(uint256 indexed submissionId, address indexed patient, string biologicalInfo, string evaluation, uint256 timestamp); function submitData(string memory biologicalInfo, string memory evaluation) external { require(bytes(biologicalInfo).length $>~0$ , \"Biological information cannot be empty.\"); require(bytes(evaluation).length $>~0$ , \"Evaluation cannot be empty.\"); submissions.push(PatientData(msg.sender, biologicalInfo, evaluation, block.timestamp, false)); uint256 submissionId $=$ submissions.length - 1; emit DataSubmitted(submissionId, msg.sender, biologicalInfo, evaluation, block.timestamp); } function verifySubmission(uint256 submissionId) external { require(submissionId $<$ submissions.length, \"Submission does not exist.\"); PatientData storage submission $=$ submissions[submissionId]; require(msg.sender $==$ submission.patient, \"Only the patient can verify the submission.\"); require(!submission.isVerified, \"Submission is already verified.\"); // Implement additional verification steps as needed submission.isVerified $=$ true; }   \n} ", "page_idx": 12}, {"type": "text", "text": "543 The code, listing 2, demonstrates the process of anomaly detection in biological data using the   \n544 Isolation Forest algorithm. It begins by loading the biological data and selecting relevant features   \n545 for anomaly detection. The selected features are scaled using StandardScaler to normalize the data.   \n546 To reduce dimensionality and highlight the most significant features, Principal Component Analysis   \n547 (PCA) is applied, transforming the data into a two-dimensional space. The Isolation Forest model,   \n548 designed to detect anomalies, is trained on this transformed data, with a contamination rate of $5\\%$   \n549 indicating the expected proportion of anomalies. Anomaly scores are calculated for each data point,   \n550 and a threshold is set to identify anomalies. Data points with scores below this threshold are flagged as   \n551 anomalies. The script prints the details of the detected anomalies for further analysis. Additionally, it   \n552 encourages experimenting with other anomaly detection models like Elliptic Envelope and One-Class   \n553 SVM, and fine-tuning parameters to enhance detection performance. ", "page_idx": 12}, {"type": "text", "text": "", "page_idx": 13}, {"type": "text", "text": "import numpy as np from sklearn.preprocessing import StandardScaler from sklearn.decomposition import PCA from sklearn.covariance import EllipticEnvelope from sklearn.ensemble import IsolationForest from sklearn.svm import OneClassSVM ", "page_idx": 13}, {"type": "text", "text": "# Load your biological data   \nbiological_data $=$ load_biological_data()   \n# Select the relevant features for anomaly   \ndetection   \nselected_features $=$ [\u2019feature1\u2019, \u2019feature2\u2019, \u2019feature3\u2019]   \n$\\texttt{X}=$ biological_data[selected_features]   \n# Apply feature scaling   \nscaler $=$ StandardScaler()   \nX_scaled $=$ scaler.fit_transform(X)   \n# Apply dimensionality reduction using PCA pca $=$ PCA(n_components $^{,=2}$ )   \nX_pca $=$ pca.fit_transform(X_scaled)   \n# Choose an anomaly detection model   \nmodel $=$ IsolationForest(contamination=0.05) model.fit(X_pca)   \n# Predict anomalies   \nanomaly_scores $=$ model.decision_function(X_pca) # Define a threshold for anomaly detection threshold $\\mathit{\\Theta}=\\mathit{\\Theta}-0\\cdot3$ # Adjust as needed   \n# Identify anomalies   \nanomalies $=$ biological_data[anomaly_scores < threshold]   \n# Further processing or reporting of anomalies for index, row in anomalies.iterrows():   \nprint(f\"Anomaly detected for sample {index} :\")   \nprint(row)   \n# experiment with different models   \n# (Elliptic Envelope, One-Class SVM, etc.) # and fine-tune parameters for better anomaly detection performance. ", "page_idx": 13}, {"type": "text", "text": "554 The code snippet, listing 3, demonstrates an off-chain method for anomaly detection in MRI images   \n555 using a pre-trained autoencoder model. The process begins by loading the pre-trained autoencoder   \n556 model, followed by loading and normalizing an MRI image. The image is then preprocessed to match   \n557 the input size required by the model, which includes resizing the image and adding a batch dimension.   \n558 The autoencoder encodes the image and subsequently reconstructs it. The Mean Squared Error (MSE)   \n559 between the original and reconstructed images is calculated as the reconstruction loss. An anomaly is   \n560 detected if this loss exceeds a predefined threshold (set to 0.01 in this example), indicating that the   \n561 MRI image significantly deviates from the normal patterns learned by the autoencoder. Depending   \n562 on the reconstruction loss, the script outputs whether an anomaly is detected or not. ", "page_idx": 14}, {"type": "text", "text": "import tensorflow as tf   \nimport numpy as np   \nfrom PIL import Image   \n# Load pre-trained autoencoder model   \nautoencoder $=$ tf.keras.models.load_model   \n(\u2019autoencoder_model.h5\u2019)   \n# Load an MRI image   \nimage $=$ Image.open(\u2019mri_image.png\u2019)   \n# Normalize image data   \nimage $=$ np.array(image) / 255.0   \n# Preprocess the image for model input   \n# Resize to the model\u2019s input size   \ninput_image $=$ tf.image.resize(image, (224, 224))   \n# Add batch dimension   \ninput_image $=$ np.expand_dims(input   \n_image, axis $=\\!0$ )   \n# Encode the image using the autoencoder   \nencoded_image $=$ autoencoder.encoder(input_image)   \n.numpy()   \n# Calculate reconstruction loss   \nreconstructed_image $=$ autoencoder(input   \n_image).numpy()   \nmse $=$ np.mean(np.square(input_image -   \nreconstructed_image))   \n# Define a threshold for anomaly detection   \nthreshold $=~0.01$ # Adjust as needed   \nif mse $>$ threshold: print(\"Anomaly detected in MRI image.\")   \nelse: print(\"No anomaly detected in MRI image.\") ", "page_idx": 14}, {"type": "text", "text": "563 NeurIPS Paper Checklist ", "text_level": 1, "page_idx": 15}, {"type": "text", "text": "564 1. Claims   \n565 Question: Do the main claims made in the abstract and introduction accurately reflect the   \n566 paper\u2019s contributions and scope?   \n567 Answer: [Yes]   \n568 2. Limitations   \n569 Question: Does the paper discuss the limitations of the work performed by the authors?   \n570 Answer: [Yes]   \n571 Justifications: see appendix B   \n572 3. Theory Assumptions and Proofs   \n573 Question: For each theoretical result, does the paper provide the full set of assumptions and   \n574 a complete (and correct) proof?   \n575 Answer: [Yes]   \n576 4. Experimental Result Reproducibility   \n577 Question: Does the paper fully disclose all the information needed to reproduce the main ex  \n578 perimental results of the paper to the extent that it affects the main claims and/or conclusions   \n579 of the paper (regardless of whether the code and data are provided or not)?   \n580 Answer: [Yes]   \n581 5. Open access to data and code   \n582 Question: Does the paper provide open access to the data and code, with sufficient instruc  \n583 tions to faithfully reproduce the main experimental results, as described in supplemental   \n584 material?   \n585 Answer: [Yes]   \n586 6. Experimental Setting/Details   \n587 Question: Does the paper specify all the training and test details (e.g., data splits, hyper  \n588 parameters, how they were chosen, type of optimizer, etc.) necessary to understand the   \n589 results?   \n590 Answer: [Yes]   \n591 7. Experiment Statistical Significance   \n592 Question: Does the paper report error bars suitably and correctly defined or other appropriate   \n593 information about the statistical significance of the experiments?   \n594 Answer: [NA]   \n595 Justification: the paper mainly deals with the system architecture. Once the hierarchical   \n596 federated learning is implemented, error bars could be renderred.   \n597 8. Experiments Compute Resources   \n598 Question: For each experiment, does the paper provide sufficient information on the com  \n599 puter resources (type of compute workers, memory, time of execution) needed to reproduce   \n600 the experiments?   \n601 Answer: [Yes]   \n602 9. Code Of Ethics   \n603 Question: Does the research conducted in the paper conform, in every respect, with the   \n604 NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines?   \n605 Answer: [Yes]   \n606 10. Broader Impacts   \n607 Question: Does the paper discuss both potential positive societal impacts and negative   \n608 societal impacts of the work performed?   \n609 Answer: [Yes]   \n611 11. Safeguards   \n612 Question: Does the paper describe safeguards that have been put in place for responsible   \n613 release of data or models that have a high risk for misuse (e.g., pretrained language models,   \n614 image generators, or scraped datasets)?   \n615 Answer: [NA]   \n616 12. Licenses for existing assets   \n617 Question: Are the creators or original owners of assets (e.g., code, data, models), used in   \n618 the paper, properly credited and are the license and terms of use explicitly mentioned and   \n619 properly respected?   \n620 Answer: [NA]   \n621 13. New Assets   \n622 Question: Are new assets introduced in the paper well documented and is the documentation   \n623 provided alongside the assets?   \n624 Answer: [Yes]   \n625 14. Crowdsourcing and Research with Human Subjects   \n626 Question: For crowdsourcing experiments and research with human subjects, does the paper   \n627 include the full text of instructions given to participants and screenshots, if applicable, as   \n628 well as details about compensation (if any)?   \n629 Answer: [NA]   \n630 Justifications: We currently use public data available on ADNI, but once the project is   \n631 operationalized, Crowdsourcing via Web App will be considered.   \n632 15. Institutional Review Board (IRB) Approvals or Equivalent for Research with Human   \n633 Subjects   \n634 Question: Does the paper describe potential risks incurred by study participants, whether   \n635 such risks were disclosed to the subjects, and whether Institutional Review Board (IRB)   \n636 approvals (or an equivalent approval/review based on the requirements of your country or   \n637 institution) were obtained?   \n638 Answer: [NA]   \n639 Justifications: We currently use public data available on ADNI, but once the project is   \n640 opertionalized, IRB should be considered. ", "page_idx": 15}, {"type": "text", "text": "", "page_idx": 16}]