[{"figure_path": "GYd5AfZaor/tables/tables_7_1.jpg", "caption": "Table 1: Comparison of Mean Relative Absolute Error (%) over the noise-free trained model on the AFAD-B, IMDB-Clean-B, IMDB-WIKI-B, SHIFT15M-B, and MSD-B datasets. Lower is better. A negative value indicates it performs even better than the noise-free model. The results are the mean of three random seed experiments. The best and the second best methods are respectively marked in red and blue. CNLCU-S/H, Co-Selfie, and Co-ConFrag use dual networks to teach each other as done in Han et al. [2018]. SPR [Wang et al., 2022] fails to run for SHIFT15M-B due to excessive memory usage.", "description": "This table compares the performance of ConFrag and fourteen other state-of-the-art baselines on five benchmark datasets for noisy label regression.  The Mean Relative Absolute Error (MRAE) is reported for various noise levels (symmetric and Gaussian noise). Lower MRAE indicates better performance. The table highlights the superior performance of ConFrag, especially when compared to baselines that do not explicitly address noisy labels.  A negative MRAE value signifies superior performance to the noise-free model.", "section": "4.2 Evaluation Metrics"}, {"figure_path": "GYd5AfZaor/tables/tables_7_2.jpg", "caption": "Table 1: Comparison of Mean Relative Absolute Error (%) over the noise-free trained model on the AFAD-B, IMDB-Clean-B, IMDB-WIKI-B, SHIFT15M-B, and MSD-B datasets. Lower is better. A negative value indicates it performs even better than the noise-free model. The results are the mean of three random seed experiments. The best and the second best methods are respectively marked in red and blue. CNLCU-S/H, Co-Selfie, and Co-ConFrag use dual networks to teach each other as done in Han et al. [2018]. SPR [Wang et al., 2022] fails to run for SHIFT15M-B due to excessive memory usage.", "description": "This table presents a comparison of the Mean Relative Absolute Error (MRAE) achieved by various methods (including ConFrag and fourteen baselines) on five different datasets with various types of noise. Lower MRAE values indicate better performance.  A negative MRAE indicates the method outperforms the noise-free model.  The results are averaged over three runs with different random seeds, and the best and second-best performing methods are highlighted.", "section": "4.2 Evaluation Metrics"}, {"figure_path": "GYd5AfZaor/tables/tables_9_1.jpg", "caption": "Table 1: Comparison of Mean Relative Absolute Error (%) over the noise-free trained model on the AFAD-B, IMDB-Clean-B, IMDB-WIKI-B, SHIFT15M-B, and MSD-B datasets. Lower is better. A negative value indicates it performs even better than the noise-free model. The results are the mean of three random seed experiments. The best and the second best methods are respectively marked in red and blue. CNLCU-S/H, Co-Selfie, and Co-ConFrag use dual networks to teach each other as done in Han et al. [2018]. SPR [Wang et al., 2022] fails to run for SHIFT15M-B due to excessive memory usage.", "description": "This table compares the performance of ConFrag and fourteen other state-of-the-art baselines on six benchmark datasets with varying types and amounts of noise.  The Mean Relative Absolute Error (MRAE), a metric which accounts for noise severity, is used to measure performance, and lower values represent better performance. The table shows results for symmetric and Gaussian noise at different noise levels.", "section": "4 Experiments"}, {"figure_path": "GYd5AfZaor/tables/tables_9_2.jpg", "caption": "Table 3: Parameter size comparison. regression: parameters for regression, noise: parameters to mitigate noisy labels, \"others\": SPR, CDR, D2L, C-Mixup, Sigua, Selfie, BMM, DY-S, Superloss.", "description": "This table compares the number of parameters used in different methods for regression and noise mitigation.  The \"regression\" column indicates the number of parameters dedicated to the regression model itself.  The \"noise\" column shows the number of parameters used specifically for handling noisy labels.  The \"others\" category groups several methods whose parameter counts are similar.  Finally, ConFrag's parameter counts are shown separately.", "section": "4 Experiments"}, {"figure_path": "GYd5AfZaor/tables/tables_19_1.jpg", "caption": "Table 1: Comparison of Mean Relative Absolute Error (%) over the noise-free trained model on the AFAD-B, IMDB-Clean-B, IMDB-WIKI-B, SHIFT15M-B, and MSD-B datasets. Lower is better. A negative value indicates it performs even better than the noise-free model. The results are the mean of three random seed experiments. The best and the second best methods are respectively marked in red and blue. CNLCU-S/H, Co-Selfie, and Co-ConFrag use dual networks to teach each other as done in Han et al. [2018]. SPR [Wang et al., 2022] fails to run for SHIFT15M-B due to excessive memory usage.", "description": "This table presents a comparison of the Mean Relative Absolute Error (MRAE) achieved by ConFrag and 14 other state-of-the-art baselines on five benchmark datasets.  The MRAE is calculated relative to a noise-free model. Lower MRAE indicates better performance. The table includes results for different noise levels (symmetric and Gaussian) and dataset types (image-based age prediction, commodity price prediction, music production year estimation).  The best and second-best performing methods are highlighted.", "section": "4.2 Evaluation Metrics"}, {"figure_path": "GYd5AfZaor/tables/tables_19_2.jpg", "caption": "Table 5: Comparison of mean prediction depths of feature extractor learning tasks for all-frag, contrastive fragment pairing, and alternative fragmentation pairings when F = 4.", "description": "This table presents a comparison of the mean prediction depths achieved by different fragment pairing strategies in feature extractor learning tasks.  It compares the performance of using all fragments, contrastive fragment pairings, and alternative fragment pairings when the number of fragments (F) is set to 4. The mean prediction depth is a metric that indicates how early in the network layers a sample's class can be correctly predicted. Lower prediction depths generally indicate better generalization and less memorization.  The table shows the mean prediction depths for both datasets with no noise and with symmetric 40% noise added.", "section": "D.3 Prediction Depth Analysis"}, {"figure_path": "GYd5AfZaor/tables/tables_20_1.jpg", "caption": "Table 1: Comparison of Mean Relative Absolute Error (%) over the noise-free trained model on the AFAD-B, IMDB-Clean-B, IMDB-WIKI-B, SHIFT15M-B, and MSD-B datasets. Lower is better. A negative value indicates it performs even better than the noise-free model. The results are the mean of three random seed experiments. The best and the second best methods are respectively marked in red and blue. CNLCU-S/H, Co-Selfie, and Co-ConFrag use dual networks to teach each other as done in Han et al. [2018]. SPR [Wang et al., 2022] fails to run for SHIFT15M-B due to excessive memory usage.", "description": "This table presents a comparison of the Mean Relative Absolute Error (MRAE) achieved by ConFrag and fourteen other state-of-the-art baselines on five benchmark datasets.  The MRAE is calculated as the difference between the model's Mean Absolute Error (MAE) with and without noise, normalized by the noise-free MAE. Lower MRAE values indicate better performance.  The table showcases results for various noise levels (20%, 40%, 60%, 80% symmetric noise; 30%, 50% Gaussian noise) and highlights the best and second-best performing methods for each dataset and noise type. The use of dual networks in several methods is also noted.", "section": "4 Experiments"}, {"figure_path": "GYd5AfZaor/tables/tables_23_1.jpg", "caption": "Table 1: Comparison of Mean Relative Absolute Error (%) over the noise-free trained model on the AFAD-B, IMDB-Clean-B, IMDB-WIKI-B, SHIFT15M-B, and MSD-B datasets. Lower is better. A negative value indicates it performs even better than the noise-free model. The results are the mean of three random seed experiments. The best and the second best methods are respectively marked in red and blue. CNLCU-S/H, Co-Selfie, and Co-ConFrag use dual networks to teach each other as done in Han et al. [2018]. SPR [Wang et al., 2022] fails to run for SHIFT15M-B due to excessive memory usage.", "description": "This table presents a comparison of the Mean Relative Absolute Error (MRAE) achieved by ConFrag and 14 other state-of-the-art baselines on five benchmark datasets. The MRAE is calculated relative to a noise-free model, with lower values indicating better performance.  The results showcase ConFrag's consistent superiority across different datasets and noise types (symmetric and Gaussian).  The table also highlights the use of dual networks in some methods.", "section": "4 Experiments"}, {"figure_path": "GYd5AfZaor/tables/tables_27_1.jpg", "caption": "Table 1: Comparison of Mean Relative Absolute Error (%) over the noise-free trained model on the AFAD-B, IMDB-Clean-B, IMDB-WIKI-B, SHIFT15M-B, and MSD-B datasets. Lower is better. A negative value indicates it performs even better than the noise-free model. The results are the mean of three random seed experiments. The best and the second best methods are respectively marked in red and blue. CNLCU-S/H, Co-Selfie, and Co-ConFrag use dual networks to teach each other as done in Han et al. [2018]. SPR [Wang et al., 2022] fails to run for SHIFT15M-B due to excessive memory usage.", "description": "This table presents a comparison of the Mean Relative Absolute Error (MRAE) achieved by ConFrag and fourteen baseline methods across five different datasets (AFAD-B, IMDB-Clean-B, IMDB-WIKI-B, SHIFT15M-B, and MSD-B) with varying levels of symmetric and Gaussian noise.  Lower MRAE values indicate better performance. The table highlights the best and second-best performing methods for each noise level and dataset, demonstrating ConFrag's superior performance, even outperforming the noise-free model in some cases.  The note clarifies that Co-ConFrag and related methods use a dual-network training approach, and SPR failed to run on one dataset due to memory constraints.", "section": "4.2 Evaluation Metrics"}, {"figure_path": "GYd5AfZaor/tables/tables_32_1.jpg", "caption": "Table 1: Comparison of Mean Relative Absolute Error (%) over the noise-free trained model on the AFAD-B, IMDB-Clean-B, IMDB-WIKI-B, SHIFT15M-B, and MSD-B datasets. Lower is better. A negative value indicates it performs even better than the noise-free model. The results are the mean of three random seed experiments. The best and the second best methods are respectively marked in red and blue. CNLCU-S/H, Co-Selfie, and Co-ConFrag use dual networks to teach each other as done in Han et al. [2018]. SPR [Wang et al., 2022] fails to run for SHIFT15M-B due to excessive memory usage.", "description": "This table presents a comparison of the Mean Relative Absolute Error (MRAE) achieved by ConFrag and fourteen other state-of-the-art baselines on five different benchmark datasets.  The datasets cover diverse domains and types of noise (symmetric and Gaussian). Lower MRAE values indicate better performance. The table highlights ConFrag's robustness and superior performance compared to other methods.", "section": "4.2 Evaluation Metrics"}, {"figure_path": "GYd5AfZaor/tables/tables_33_1.jpg", "caption": "Table 1: Comparison of Mean Relative Absolute Error (%) over the noise-free trained model on the AFAD-B, IMDB-Clean-B, IMDB-WIKI-B, SHIFT15M-B, and MSD-B datasets. Lower is better. A negative value indicates it performs even better than the noise-free model. The results are the mean of three random seed experiments. The best and the second best methods are respectively marked in red and blue. CNLCU-S/H, Co-Selfie, and Co-ConFrag use dual networks to teach each other as done in Han et al. [2018]. SPR [Wang et al., 2022] fails to run for SHIFT15M-B due to excessive memory usage.", "description": "This table presents a comparison of the Mean Relative Absolute Error (MRAE) achieved by ConFrag and fourteen other state-of-the-art baselines on five different datasets.  The MRAE is calculated as the difference between the model's MAE on noisy data and the MAE on clean data, expressed as a percentage. Lower MRAE values indicate better performance.  The table shows results for different types of noise (symmetric and Gaussian) and varying noise rates.  The best performing models are highlighted in red and blue.", "section": "4 Experiments"}, {"figure_path": "GYd5AfZaor/tables/tables_33_2.jpg", "caption": "Table 1: Comparison of Mean Relative Absolute Error (%) over the noise-free trained model on the AFAD-B, IMDB-Clean-B, IMDB-WIKI-B, SHIFT15M-B, and MSD-B datasets. Lower is better. A negative value indicates it performs even better than the noise-free model. The results are the mean of three random seed experiments. The best and the second best methods are respectively marked in red and blue. CNLCU-S/H, Co-Selfie, and Co-ConFrag use dual networks to teach each other as done in Han et al. [2018]. SPR [Wang et al., 2022] fails to run for SHIFT15M-B due to excessive memory usage.", "description": "This table presents a comparison of the Mean Relative Absolute Error (MRAE) achieved by ConFrag and fourteen other state-of-the-art baselines on five different datasets.  The MRAE is calculated relative to a noise-free model, allowing for negative values indicating superior performance.  Results are averaged across three random trials. The datasets cover diverse domains and are designed to evaluate performance under varying degrees of symmetric and Gaussian noise.", "section": "Experiments"}, {"figure_path": "GYd5AfZaor/tables/tables_38_1.jpg", "caption": "Table 1: Comparison of Mean Relative Absolute Error (%) over the noise-free trained model on the AFAD-B, IMDB-Clean-B, IMDB-WIKI-B, SHIFT15M-B, and MSD-B datasets. Lower is better. A negative value indicates it performs even better than the noise-free model. The results are the mean of three random seed experiments. The best and the second best methods are respectively marked in red and blue. CNLCU-S/H, Co-Selfie, and Co-ConFrag use dual networks to teach each other as done in Han et al. [2018]. SPR [Wang et al., 2022] fails to run for SHIFT15M-B due to excessive memory usage.", "description": "This table presents a comparison of the Mean Relative Absolute Error (MRAE) achieved by ConFrag and fourteen baseline methods across five datasets with varying levels of symmetric and Gaussian noise.  Lower MRAE values indicate better performance. The table highlights ConFrag's superior performance in most scenarios and showcases its robustness against different types of noise.", "section": "4.2 Evaluation Metrics"}, {"figure_path": "GYd5AfZaor/tables/tables_39_1.jpg", "caption": "Table 1: Comparison of Mean Relative Absolute Error (%) over the noise-free trained model on the AFAD-B, IMDB-Clean-B, IMDB-WIKI-B, SHIFT15M-B, and MSD-B datasets. Lower is better. A negative value indicates it performs even better than the noise-free model. The results are the mean of three random seed experiments. The best and the second best methods are respectively marked in red and blue. CNLCU-S/H, Co-Selfie, and Co-ConFrag use dual networks to teach each other as done in Han et al. [2018]. SPR [Wang et al., 2022] fails to run for SHIFT15M-B due to excessive memory usage.", "description": "This table presents a comparison of the Mean Relative Absolute Error (MRAE) achieved by ConFrag and fourteen other state-of-the-art baselines across five different datasets (AFAD-B, IMDB-Clean-B, IMDB-WIKI-B, SHIFT15M-B, and MSD-B).  For each dataset, results are shown for both symmetric and Gaussian noise at different noise levels (20%, 40%, 60%, 80% for symmetric, 30%, 50% for Gaussian). Lower MRAE values indicate better performance.  The table highlights the best and second-best performing methods in red and blue, respectively, and notes that the SPR method failed to execute on one of the datasets due to memory constraints.", "section": "4.3 Results and Discussion"}, {"figure_path": "GYd5AfZaor/tables/tables_40_1.jpg", "caption": "Table 1: Comparison of Mean Relative Absolute Error (%) over the noise-free trained model on the AFAD-B, IMDB-Clean-B, IMDB-WIKI-B, SHIFT15M-B, and MSD-B datasets. Lower is better. A negative value indicates it performs even better than the noise-free model. The results are the mean of three random seed experiments. The best and the second best methods are respectively marked in red and blue. CNLCU-S/H, Co-Selfie, and Co-ConFrag use dual networks to teach each other as done in Han et al. [2018]. SPR [Wang et al., 2022] fails to run for SHIFT15M-B due to excessive memory usage.", "description": "This table presents a comparison of the Mean Relative Absolute Error (MRAE) achieved by various methods (including ConFrag) on five different datasets with varying noise levels (symmetric and Gaussian noise).  Lower MRAE values indicate better performance. The table highlights the best-performing methods in each scenario and notes that Co-ConFrag uses a dual-network training strategy. The inability of SPR to run on one dataset is also noted.", "section": "4.2 Evaluation Metrics"}, {"figure_path": "GYd5AfZaor/tables/tables_41_1.jpg", "caption": "Table 1: Comparison of Mean Relative Absolute Error (%) over the noise-free trained model on the AFAD-B, IMDB-Clean-B, IMDB-WIKI-B, SHIFT15M-B, and MSD-B datasets. Lower is better. A negative value indicates it performs even better than the noise-free model. The results are the mean of three random seed experiments. The best and the second best methods are respectively marked in red and blue. CNLCU-S/H, Co-Selfie, and Co-ConFrag use dual networks to teach each other as done in Han et al. [2018]. SPR [Wang et al., 2022] fails to run for SHIFT15M-B due to excessive memory usage.", "description": "This table presents a comparison of the Mean Relative Absolute Error (MRAE) achieved by ConFrag and fourteen baseline methods across five different datasets (AFAD-B, IMDB-Clean-B, IMDB-WIKI-B, SHIFT15M-B, and MSD-B).  The MRAE is calculated relative to a noise-free model.  Results are shown for various levels of symmetric and Gaussian noise, highlighting ConFrag's robustness and superior performance compared to other state-of-the-art methods. A negative MRAE indicates that the model outperforms the noise-free model.", "section": "4.2 Evaluation Metrics"}]