[{"figure_path": "gwd3MQufGP/tables/tables_6_1.jpg", "caption": "Table 2: Visual Prompt-based Keypoint Detection on MP-100 [21] dataset. Performance (PCK) under 1-shot and 5-shot settings.", "description": "This table presents the Probability of Correct Keypoint (PCK) performance of different methods for visual prompt-based keypoint detection on the MP-100 dataset.  The results are shown for both 1-shot and 5-shot settings, comparing KptLLM against ProtoNet, MAML, Finetune, POMNet, and CapeFormer.  Each split represents a different subset of the dataset, and the mean PCK across all splits is also provided.", "section": "4.3 Visual Prompt-based Keypoint Detection"}, {"figure_path": "gwd3MQufGP/tables/tables_6_2.jpg", "caption": "Table 1: Keypoint Semantic Understanding on MP-100 (Split-1) [21]. * means LLaVA is finetuned using LoRA.", "description": "This table presents the accuracy of keypoint semantic understanding on the MP-100 dataset (Split-1).  It compares the performance of the original LLaVA model, a version of LLaVA fine-tuned using LoRA, and the proposed KptLLM model. The results highlight the superior performance of KptLLM in grasping keypoint semantics compared to both LLaVA versions, demonstrating the effectiveness of the proposed method.", "section": "4.2 Keypoint Semantic Understanding"}, {"figure_path": "gwd3MQufGP/tables/tables_7_1.jpg", "caption": "Table 3: Visual Prompt-based Keypoint Detection for cross super-category evaluation on MP-100 [21]. Experiments are conducted under the 1-shot setting.", "description": "This table presents the performance of different visual prompt-based keypoint detection methods on the MP-100 dataset, focusing on cross-supercategory evaluation (1-shot setting). The methods are compared across four supercategories: Human Body, Human Face, Vehicle, and Furniture.  The results are presented as the PCK (Percentage of Correct Keypoints) at a threshold of 0.2.  This evaluation tests the generalization ability of the models across diverse object categories and visual characteristics.", "section": "4.3 Visual Prompt-based Keypoint Detection"}, {"figure_path": "gwd3MQufGP/tables/tables_8_1.jpg", "caption": "Table 4: Textual Prompt-based Keypoint Detection on AP-10K [32].", "description": "This table presents the results of textual prompt-based keypoint detection on the AP-10K dataset.  It compares the performance of three different methods: SimpleBaseline [48], CLAMP [23], and the proposed KptLLM model.  The evaluation is performed across two scenarios:  (1) training on Bovidae and testing on Canidae, and (2) training on Canidae and testing on Felidae.  The results are measured using average precision (AP), and several variations of AP at different Intersection over Union (IoU) thresholds (AP50, AP75, APM, APL) along with Average Recall (AR).  The table showcases KptLLM's superior performance in terms of generalization and accuracy compared to the baseline methods.", "section": "4.4 Textual Prompt-based Keypoint Detection"}, {"figure_path": "gwd3MQufGP/tables/tables_8_2.jpg", "caption": "Table 5: Ablation study of semantic understanding.", "description": "This table presents the results of an ablation study on the semantic understanding aspect of the KptLLM model. It compares the performance (PCK) of the model with and without the Identify-then-Detect (ItD) strategy. The results show a significant improvement in performance when using the ItD strategy.", "section": "4.5 Ablation Study"}]