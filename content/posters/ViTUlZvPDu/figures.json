[{"figure_path": "ViTUlZvPDu/figures/figures_1_1.jpg", "caption": "Figure 1: (a) ID-OOD frontier curves for the CLIP ViT-B/16 model on the ID (ImageNet) and OOD (IN-{V2, R, A, Sketch} and ObjectNet) datasets by varying the mixing coefficient \u03b1. The ensemble model achieves its best ID and OOD performance at different \u03b1 values. Our method VRF simultaneously attains the best ID and OOD accuracy, outperforming the ensemble by 3.6% on OOD and 1.6% on ID at its optimal performance points.(b) Relationship between the ratio of fine-tuned accuracy to zero-shot accuracy (Accft/Acczs) and the distance to the zero-shot failure set (d(x)). Accft/Acczs demonstrates a monotonic decrease as d(x) increases.", "description": "This figure shows the ID-OOD trade-off of ensemble methods and the proposed variance reduction fine-tuning (VRF) method. Subfigure (a) presents the ID-OOD frontier curves for the CLIP ViT-B/16 model. It shows that the ensemble model achieves the best ID and OOD accuracy at different mixing coefficients \u03b1, while VRF attains the best of both without trade-offs. Subfigure (b) shows the relationship between the ratio of fine-tuned accuracy to zero-shot accuracy and the distance to the zero-shot failure set, demonstrating a monotonic decrease in the ratio as the distance increases. This finding justifies the proposed VRF method.", "section": "Introduction"}, {"figure_path": "ViTUlZvPDu/figures/figures_3_1.jpg", "caption": "Figure 1: (a) ID-OOD frontier curves for the CLIP ViT-B/16 model on the ID (ImageNet) and OOD (IN-{V2, R, A, Sketch} and ObjectNet) datasets by varying the mixing coefficient \u03b1. The ensemble model achieves its best ID and OOD performance at different \u03b1 values. Our method VRF simultaneously attains the best ID and OOD accuracy, outperforming the ensemble by 3.6% on OOD and 1.6% on ID at its optimal performance points.(b) Relationship between the ratio of fine-tuned accuracy to zero-shot accuracy (Accft/Acczs) and the distance to the zero-shot failure set (d(x)). Accft/Acczs demonstrates a monotonic decrease as d(x) increases.", "description": "The figure shows two subfigures. Subfigure (a) shows the ID-OOD trade-off curves for the CLIP ViT-B/16 model using different mixing coefficients.  The ensemble model peaks at different mixing coefficients for in-distribution (ID) and out-of-distribution (OOD) accuracy, demonstrating the ID-OOD trade-off.  The proposed Variance Reduction Fine-tuning (VRF) method, however, simultaneously achieves the best ID and OOD accuracies. Subfigure (b) illustrates the relationship between the ratio of fine-tuned to zero-shot accuracy and the distance to the Zero-Shot Failure (ZSF) set for each test sample.  It shows that as the distance to the ZSF set increases, this accuracy ratio decreases monotonically.", "section": "Introduction"}, {"figure_path": "ViTUlZvPDu/figures/figures_6_1.jpg", "caption": "Figure 1: (a) ID-OOD frontier curves for the CLIP ViT-B/16 model on the ID (ImageNet) and OOD (IN-{V2, R, A, Sketch} and ObjectNet) datasets by varying the mixing coefficient \u03b1. The ensemble model achieves its best ID and OOD performance at different \u03b1 values. Our method VRF simultaneously attains the best ID and OOD accuracy, outperforming the ensemble by 3.6% on OOD and 1.6% on ID at its optimal performance points.(b) Relationship between the ratio of fine-tuned accuracy to zero-shot accuracy (Accft/Acczs) and the distance to the zero-shot failure set (d(x)). Accft/Acczs demonstrates a monotonic decrease as d(x) increases.", "description": "This figure shows the ID-OOD trade-off for the CLIP ViT-B/16 model.  The left subplot (a) displays the ID-OOD frontier curves, illustrating how ensemble methods (OSE and WSE) achieve peak ID and OOD accuracy at different mixing coefficients (\u03b1).  In contrast, the proposed VRF method simultaneously achieves the best ID and OOD performance. The right subplot (b) shows the relationship between the ratio of fine-tuned accuracy to zero-shot accuracy and the distance of a test sample to the zero-shot failure (ZSF) set.  This relationship demonstrates that the proposed method is effective in variance reduction.", "section": "1 Introduction"}, {"figure_path": "ViTUlZvPDu/figures/figures_7_1.jpg", "caption": "Figure 4: ZSF set V vs. all data D", "description": "This figure compares the performance of using only the zero-shot failure (ZSF) set versus using the entire fine-tuned (FT) training data set to compute the distance d(x) for each test sample x.  The y-axis shows the ratio of fine-tuned accuracy to zero-shot accuracy (Accft/Acczs) and the x-axis shows the distance d(x). The plot demonstrates that using the ZSF set leads to a clearer monotonic decreasing trend, which is essential for the proposed Variance Reduction Fine-tuning (VRF) method. Using the entire FT dataset results in a less informative and non-monotonic trend, hindering the performance of VRF. The inset table shows the overall ID and OOD accuracies for both methods.", "section": "5.3 Further Analysis and Ablation Studies"}, {"figure_path": "ViTUlZvPDu/figures/figures_8_1.jpg", "caption": "Figure 5: (a) Averaged weight E<sub>x</sub>[w(x)] on different datasets. (b) VRF based on logit-space ensembling. (c) Comparison with the effect of different k in the k-NN distance.", "description": "This figure presents the results of experiments evaluating the variance reduction fine-tuning (VRF) method. (a) shows the average weight assigned to the fine-tuned model across different datasets (ImageNet, CIFAR, and Entity30). (b) demonstrates the performance of VRF using logit-space ensembling, showing improved ID and OOD accuracy compared to baselines. (c) investigates the influence of the k-NN distance parameter on the results. The consistent increase in OOD accuracy suggests VRF's effectiveness.", "section": "5.3 Further Analysis and Ablation Studies"}, {"figure_path": "ViTUlZvPDu/figures/figures_8_2.jpg", "caption": "Figure 6: (a) Effect of a and b on ImageNet ID accuracy. (b) Effect of a and b on ImageNet OOD accuracy. (c) Other designs of w(x), hyper-parameters are searched on validation set.", "description": "This figure analyzes the impact of hyperparameters a and b on the performance of the proposed Variance Reduction Fine-tuning (VRF) method.  Subfigure (a) shows how different combinations of a and b affect ImageNet in-distribution (ID) accuracy. Subfigure (b) similarly displays their effect on out-of-distribution (OOD) accuracy. Finally, subfigure (c) compares the performance of the VRF method using different weight functions (binary, linear, and sigmoid) to demonstrate the effectiveness of the sigmoid function selected for VRF in the paper.", "section": "5.3 Further Analysis and Ablation Studies"}, {"figure_path": "ViTUlZvPDu/figures/figures_9_1.jpg", "caption": "Figure 7: Visualization the samples with the smallest/largest d(x).", "description": "This figure visualizes examples of images with the smallest and largest distances to the Zero-Shot Failure (ZSF) set.  The images with the smallest distances are predominantly fine-grained species, where the fine-tuned models have more specific knowledge not present in the zero-shot models.  Conversely, images with the largest distances show styles (tattoos, cartoons, sketches) different from the fine-tuning samples; styles where zero-shot models tend to perform better.", "section": "5.3 Further Analysis and Ablation Studies"}, {"figure_path": "ViTUlZvPDu/figures/figures_9_2.jpg", "caption": "Figure 8: Inference speed (per-image) using different k.", "description": "This figure shows the inference speed (in milliseconds per image) for computing the k-nearest neighbor distance using different values of k. The x-axis represents log2(k), and the y-axis shows the inference time. As k increases, the inference time also increases, but the increase is relatively slow, especially for smaller values of k. This indicates that the k-NN search can be efficiently implemented, even for relatively large values of k.", "section": "5.3 Further Analysis and Ablation Studies"}, {"figure_path": "ViTUlZvPDu/figures/figures_13_1.jpg", "caption": "Figure 1: (a) ID-OOD frontier curves for the CLIP ViT-B/16 model on the ID (ImageNet) and OOD (IN-{V2, R, A, Sketch} and ObjectNet) datasets by varying the mixing coefficient a. The ensemble model achieves its best ID and OOD performance at different a values. Our method VRF simultaneously attains the best ID and OOD accuracy, outperforming the ensemble by 3.6% on OOD and 1.6% on ID at its optimal performance points.(b) Relationship between the ratio of fine-tuned accuracy to zero-shot accuracy (Accft) and the distance to the zero-shot failure set (d(x)). Accft demonstrates a monotonic decrease as d(x) increases.", "description": "This figure shows the ID-OOD trade-off for the CLIP ViT-B/16 model using different mixing coefficients (a) in ensemble methods and the proposed VRF method.  Subfigure (a) demonstrates that the ensemble methods achieve peak ID and OOD accuracy at different mixing coefficients, revealing the ID-OOD trade-off. Subfigure (b) shows a monotonic relationship between the ratio of fine-tuned accuracy to zero-shot accuracy (Accft/Acczs) and the distance to the zero-shot failure set (d(x)), a key observation motivating the VRF approach.", "section": "Introduction"}, {"figure_path": "ViTUlZvPDu/figures/figures_14_1.jpg", "caption": "Figure 1: (a) ID-OOD frontier curves for the CLIP ViT-B/16 model on the ID (ImageNet) and OOD (IN-{V2, R, A, Sketch} and ObjectNet) datasets by varying the mixing coefficient \u03b1. The ensemble model achieves its best ID and OOD performance at different \u03b1 values. Our method VRF simultaneously attains the best ID and OOD accuracy, outperforming the ensemble by 3.6% on OOD and 1.6% on ID at its optimal performance points.(b) Relationship between the ratio of fine-tuned accuracy to zero-shot accuracy (Accft/Acczs) and the distance to the zero-shot failure set (d(x)). Accft/Acczs demonstrates a monotonic decrease as d(x) increases.", "description": "This figure shows the ID-OOD trade-off curve for the CLIP ViT-B/16 model with varying mixing coefficients (\u03b1). It demonstrates that ensemble methods achieve peak performance for ID and OOD accuracy at different mixing coefficients.  The proposed Variance Reduction Fine-tuning (VRF) method, however, achieves the best ID and OOD accuracy simultaneously. The second subplot shows the relationship between the ratio of fine-tuned to zero-shot accuracy and the distance to a set of training samples that were incorrectly predicted by the zero-shot model (ZSF set). This illustrates the core concept behind VRF, which is to weight the fine-tuned model more strongly for test samples close to this ZSF set.", "section": "1 Introduction"}, {"figure_path": "ViTUlZvPDu/figures/figures_16_1.jpg", "caption": "Figure 1: (a) ID-OOD frontier curves for the CLIP ViT-B/16 model on the ID (ImageNet) and OOD (IN-{V2, R, A, Sketch} and ObjectNet) datasets by varying the mixing coefficient \u03b1. The ensemble model achieves its best ID and OOD performance at different \u03b1 values. Our method VRF simultaneously attains the best ID and OOD accuracy, outperforming the ensemble by 3.6% on OOD and 1.6% on ID at its optimal performance points.(b) Relationship between the ratio of fine-tuned accuracy to zero-shot accuracy (Accft/Acczs) and the distance to the zero-shot failure set (d(x)). Accft/Acczs demonstrates a monotonic decrease as d(x) increases.", "description": "This figure shows two plots. Plot (a) presents the ID-OOD trade-off curves for the CLIP ViT-B/16 model when using different mixing coefficients (\u03b1) in the output-space ensemble method.  It highlights that optimal ID and OOD accuracies occur at different \u03b1 values, demonstrating the ID-OOD trade-off.  The authors' proposed method (VRF) achieves superior performance in both ID and OOD, exceeding the ensemble's performance. Plot (b) illustrates the relationship between the ratio of fine-tuned accuracy to zero-shot accuracy and the distance to the Zero-Shot Failure (ZSF) set.  It shows an inverse relationship, supporting the authors' use of this distance in their VRF method to assign weights in the ensemble.", "section": "1 Introduction"}]