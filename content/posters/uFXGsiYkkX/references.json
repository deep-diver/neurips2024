{"references": [{"fullname_first_author": "P. Abbeel", "paper_title": "Apprenticeship learning via inverse reinforcement learning", "publication_date": "2004", "reason": "This paper introduced a foundational method for imitation learning, which is a core concept in the presented work."}, {"fullname_first_author": "A. Brohan", "paper_title": "RT-1: Robotics Transformer for real-world control at scale", "publication_date": "2022", "reason": "This is a major baseline for comparison, establishing a strong prior approach for multi-task robotic policy learning using transformers."}, {"fullname_first_author": "H. Bharadhwaj", "paper_title": "RoboAgent: Generalization and efficiency in robot manipulation via semantic augmentations and action chunking", "publication_date": "2023", "reason": "This paper presents another key baseline, introducing a transformer-based approach with action chunking for improved multi-task learning in robotics, directly compared to in the paper."}, {"fullname_first_author": "Y. Chen", "paper_title": "Sequential dexterity: Chaining dexterous policies for long-horizon manipulation", "publication_date": "2023", "reason": "This work addresses the challenge of long-horizon tasks, a key aspect of the presented work, proposing a method for chaining policies to achieve complex, multi-step goals."}, {"fullname_first_author": "C. Chi", "paper_title": "Diffusion policy: Visuomotor policy learning via action diffusion", "publication_date": "2023", "reason": "This paper provides a state-of-the-art action generation method, specifically using diffusion models, which is one of the action heads compared and implemented in BAKU."}]}