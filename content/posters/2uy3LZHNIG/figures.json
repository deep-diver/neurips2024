[{"figure_path": "2uy3LZHNIG/figures/figures_3_1.jpg", "caption": "Figure 1: (a) At time t=0s, the current vehicle state is used as the reference to select the token closest to the ground truth bounding box within the token set. At time t=0.5s, the matched token from the previous step is used to select the next predicted token. At time t=1.0s, a noised token serves as the reference to determine the token for t=1.5s. This iterative process continues. (b) Motion token vocabulary with time granularity equal to 0.5s.(c) The original road vector features are represented as continuous sequences of map points. We divide the original map into multiple segments, each within 5 meters in length, and then perform matching with discrete tokens. The final map is composed of road vector tokens represented by different colored segments.", "description": "This figure illustrates the tokenization process for agent motion and road vectors.  (a) shows the iterative token selection process for agent motion, using the previous token and adding noise for robustness. (b) displays the resulting motion token vocabulary. (c) demonstrates how continuous road vector features are segmented and matched to discrete road tokens.", "section": "3.1 Tokenization"}, {"figure_path": "2uy3LZHNIG/figures/figures_4_1.jpg", "caption": "Figure 2: The architecture of SMART framework (a) We train a decoder-only transformer that predicts the motion tokens of multi-agents conditional on previous motion tokens, interactive agent motion tokens, and encoding road tokens. The model is trained to predict the next motion token. (b) Illustration for our proposed road spatial understanding training task.", "description": "This figure illustrates the architecture of the SMART model.  Panel (a) shows the decoder-only transformer used for predicting the next motion token for multiple agents.  It takes as input previous motion tokens, interactive agent motion tokens (showing inter-agent interactions), and encoded road tokens. Panel (b) details a separate training task focusing on spatial understanding of road vectors, using a separate neural network (RoadNet) to predict the next road token in the sequence.", "section": "3.2 Model Architecture"}, {"figure_path": "2uy3LZHNIG/figures/figures_8_1.jpg", "caption": "Figure 3: Qualitative results of closed-loop planning for two representative scenarios from the test set. Each scenario (every row) lasts 8 seconds and we take 4 snapshots with a 2-second interval. SMART controls all the agents in the scenario. The first row depicts a parking lot area. The red vehicle in the picture effectively completed a detour around a stationary vehicle ahead in the parking lot. The second row shows a scene of a large curvature U-turn in a ramp zone, where the traffic flow in the right lane of the ramp has completed the behavior of ramp exit under the control of SMART. It is recommended to refer to supplementary materials for more videos", "description": "This figure shows two example scenarios of the SMART model performing closed-loop planning.  The top row demonstrates successful navigation in a parking lot, avoiding a stationary vehicle. The bottom row showcases successful negotiation of a sharp U-turn on a ramp.", "section": "4.2 Generalization"}, {"figure_path": "2uy3LZHNIG/figures/figures_8_2.jpg", "caption": "Figure 4: Due to limitations in dataset size, we trained models at multiple scales ranging from 1M to 101M on a total of 1 billion tokens. (a) Training loss of different models (b) Axes are all on a logarithmic scale. The power-law scaling law can be expressed as a solid line. Exponents \u03b2 = -0.157 suggest a smooth decline in test loss L when scaling up SMART models.", "description": "This figure shows the results of experiments on the scalability of the SMART model.  The left panel (a) presents training loss curves for models with different numbers of parameters (1M, 7M, 32M, and 99M) trained on 1 billion tokens.  The right panel (b) displays a log-log plot illustrating the power-law scaling relationship between model size and test loss, demonstrating that the SMART model exhibits consistent performance improvements as its size increases. The equation of the fitted power law is also provided.", "section": "4 Experiments"}, {"figure_path": "2uy3LZHNIG/figures/figures_14_1.jpg", "caption": "Figure 5: SMART w/o refers to SMART model without the road vector tokenization and noise tricks proposed in this paper. To ensure the fairness of the experiments, all model parameters were adjusted to the 90-100M. Models were trained on various datasets and validated only on the WOMD validation dataset", "description": "This figure compares the performance of SMART model with and without road vector tokenization and noise tricks across different datasets.  It demonstrates the impact of these techniques on the model's generalization ability. The results show that SMART model with these enhancements generalizes better across datasets than the version without them, achieving higher scores on the overall evaluation metric, even when trained on a smaller dataset like NuPlan.", "section": "A.3 Additional ablation studies"}]