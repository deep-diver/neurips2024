[{"figure_path": "2uy3LZHNIG/tables/tables_6_1.jpg", "caption": "Table 1: Comparison with state-of-the-art models on WOMD 2023 Sim Agents benchmark", "description": "This table compares the performance of the SMART 7M model against other state-of-the-art models on the Waymo Open Motion Dataset (WOMD) 2023 Sim Agents benchmark.  It shows the results across multiple metrics, including Realism (a meta-metric combining various aspects of realism), Kinematic metrics (measuring the accuracy of predicted kinematic properties), Interactive metrics (evaluating the quality of interactions between agents), and Map-based metrics (assessing how well the generated trajectories align with the map). The lower the minADE (minimum average displacement error), the better the performance.", "section": "4.1 Comparison for motion generation task"}, {"figure_path": "2uy3LZHNIG/tables/tables_6_2.jpg", "caption": "Table 2: Comparison with state-of-the-art models on WOMD 2024 Sim Agents benchmark", "description": "This table compares the performance of the SMART model (with 101M and 7M parameters) against other state-of-the-art models on the WOMD 2024 Sim Agents benchmark.  The comparison includes metrics for Realism (Meta metric), Kinematic, Interactive, and Map-based performance, as well as the minimum Average Displacement Error (minADE).  It also shows the performance of a SMART model trained only on the NuPlan dataset ('SMART-zeroshot'), demonstrating its zero-shot generalization capabilities.", "section": "4.1 Comparison for motion generation task"}, {"figure_path": "2uy3LZHNIG/tables/tables_7_1.jpg", "caption": "Table 3: Zero-shot generalization on different datasets. SMART denotes a model trained on WOMD only. SMART* denotes a model trained on NuPlan dataset only. SMART** denotes a model after 1 epoch of finetuning with an initial learning rate of 0.0001 on WOMD based on SMART* model.", "description": "This table presents the results of a zero-shot generalization experiment.  Three SMART models are evaluated: one trained solely on the Waymo Open Motion Dataset (WOMD), one trained only on the NuPlan dataset, and a third model that fine-tuned the NuPlan-trained model on WOMD.  The table shows the performance of each model across three metrics: kinematic, interactive, and map-based, along with the minimum average displacement error (minADE).  The results highlight the generalization capabilities of SMART, especially when a small amount of fine-tuning is applied.", "section": "4.2 Generalization"}, {"figure_path": "2uy3LZHNIG/tables/tables_9_1.jpg", "caption": "Table 4: Ablation study on each component of SMART. Experimental results are based on the WOMD validation set. \"RVT\" indicates road vector tokenization, \"RVNTP\" indicates road vector next token prediction, \"NAT\" indicates noised agent tokenization, \"NRVT\" indicates noised road vector tokenization", "description": "This table presents the ablation study results for different components of the SMART model.  It shows the impact of road vector tokenization (RVT), road vector next token prediction (RVNTP), noised agent tokenization (NAT), and noised road vector tokenization (NRVT) on the model's performance across various metrics (kinematics, interactive, map) when trained on both WOMD and NuPlan datasets.  Each row represents a model configuration, indicating which components were included (\u221a) and the corresponding performance metrics.", "section": "4.4 Ablation"}, {"figure_path": "2uy3LZHNIG/tables/tables_13_1.jpg", "caption": "Table 5: Hyperparameters of different SMART models", "description": "This table lists the hyperparameters used for training four different SMART models with varying model sizes (1M, 7M, 26M, and 101M parameters).  The hyperparameters are categorized into those for the RoadNet (road token encoder), MotionNet (agent motion decoder), and overall SMART model architecture.  Specific hyperparameters listed include the number of self-attention layers, embedding dimensions, vocabulary sizes, attention radius, and the total number of parameters in each model.  The table provides a detailed specification of the architectural choices made for each model variant.", "section": "A.1 Implementation and Simulation Inference"}, {"figure_path": "2uy3LZHNIG/tables/tables_13_2.jpg", "caption": "Table 1: Comparison with state-of-the-art models on WOMD 2023 Sim Agents benchmark", "description": "This table compares the performance of SMART 7M with other state-of-the-art models on the Waymo Open Motion Dataset (WOMD) 2023 Sim Agents benchmark.  It shows a comparison across multiple metrics, including realism (meta-metric), kinematic metrics (minADE), interactive metrics, and map-based metrics.  The results highlight SMART 7M's performance relative to other leading models in autonomous driving simulation.", "section": "4.1 Comparison for motion generation task"}, {"figure_path": "2uy3LZHNIG/tables/tables_15_1.jpg", "caption": "Table 7: Comparison of different tokenizer. Experimental results are based on the SMART 7M", "description": "This table compares the performance of two different tokenizers, VQ-VAE and k-disks, used in the SMART model.  The comparison is done for both models trained on the WOMD and NuPlan datasets. The metrics used for comparison are Kinematics, Interactive, and Map-based metrics, reflecting different aspects of driving motion generation.", "section": "4.2 Generalization"}, {"figure_path": "2uy3LZHNIG/tables/tables_15_2.jpg", "caption": "Table 8: Data sources", "description": "This table presents a summary of the data sources used in the paper, including the number of scenes, single scenario duration, and the total number of motion tokens for each dataset (NuPlan, Waymo, Proprietary).  The total dataset combines these sources to create a large-scale dataset for training and validating the SMART model.", "section": "4.3 Scalability"}, {"figure_path": "2uy3LZHNIG/tables/tables_16_1.jpg", "caption": "Table 9: Comparison of SMART models with different scales. Training time refers to the duration required for the model to converge using the entire dataset. Inference time refers to the time taken by the model to predict the next token for a single frame.", "description": "This table presents the results of experiments conducted to evaluate the scalability of the SMART model.  Different model sizes (1M, 7M, 26M, and 101M parameters) were trained on a large dataset. The table shows the performance (Kinematic, Interactive, and Map-based metrics) achieved by each model, along with the corresponding training time and average inference time. This allows for analysis of how performance, training time, and inference speed change as the model scale increases.", "section": "4 Experiments"}]