[{"figure_path": "IVqzbuLfoL/tables/tables_4_1.jpg", "caption": "Table 1: Per-scene rendering time breakdown for vanilla [16] and pruned [18] 3D Gaussian Splatting. Rendering times are measured in milliseconds, based on the first camera pose in the test set. The latency at each stage is stable for this fixed pose, with fluctuations below 0.02 milliseconds. Specifically, #G and #F represent the number of Gaussians and the number of fragments for the corresponding scene.", "description": "This table shows a breakdown of the rendering time for each stage (Projection, Sorting, Rasterization) of the 3D Gaussian Splatting pipeline for four different scenes.  It compares the performance of the vanilla 3D Gaussian Splatting method with a state-of-the-art pruning method (Mini-Splatting). The table highlights the significant time spent in the Rasterization stage and how pruning affects the number of Gaussians and fragments, impacting overall rendering speed.  The  '#F/#G' column shows the ratio of fragments to Gaussians, illustrating the disproportionate increase in fragments compared to the reduction in Gaussians when pruning.", "section": "4 Profiling and Analysis of 3D Gaussian Rendering Pipeline"}, {"figure_path": "IVqzbuLfoL/tables/tables_7_1.jpg", "caption": "Table 2: Quantitative comparison of our method and previous works on the Plenoptic Video Dataset. Frame rates (FPS) of our method and 4DGS [28] are measured on Jetson Orin NX [17]. *: Frame rates capped at 60 FPS. In the Mip-NeRF 360 dataset, Mini Splatting + Ours achieved 60 FPS on 5 out of the 9 scenes. In the Tanks&Temples and Deep Blending dataset, all scenes achieved at 60 FPS.", "description": "This table presents a quantitative comparison of the proposed fragment pruning method and several baseline methods on three datasets: Mip-NeRF 360, Tanks & Temples, and Deep Blending.  It compares the Peak Signal-to-Noise Ratio (PSNR), Structural Similarity Index (SSIM), Learned Perceptual Image Patch Similarity (LPIPS), and Frames Per Second (FPS).  The results show that the proposed method consistently improves FPS across all datasets, while maintaining or improving PSNR and SSIM, often outperforming state-of-the-art Gaussian primitive pruning techniques.", "section": "6.3 Quantative Results on Static Scenes"}, {"figure_path": "IVqzbuLfoL/tables/tables_7_2.jpg", "caption": "Table 3: Quantitative comparison of our method and previous works on the Plenoptic Video Dataset. 1: numbers from 4DGS paper; 2: FPS only measured on four scenes, i.e. without Coffeer Martini and Flame Salmon, which run out of memory on Jetson NX.", "description": "This table compares the proposed method's performance with other state-of-the-art methods on the Plenoptic Video Dataset.  It shows quantitative metrics including PSNR, SSIM, LPIPS, and FPS. Note that the FPS for some methods was limited due to memory constraints on the hardware.", "section": "6.4 Quantative Results on Dynamic Scenes"}, {"figure_path": "IVqzbuLfoL/tables/tables_8_1.jpg", "caption": "Table 4: Comparison of pre-training and fine-tuning times on an A5000 GPU (in minutes).", "description": "This table shows the pre-training and fine-tuning times on an NVIDIA A5000 GPU for three different datasets: Mip-NeRF 360, Tanks & Temples, and Deep Blending.  The times are broken down for two different methods: vanilla 3D Gaussian Splatting and Mini-Splatting.  It demonstrates the additional time required for the fine-tuning stage of the proposed fragment pruning method.", "section": "7 Discussion"}]