[{"figure_path": "S4ZqnMywcM/tables/tables_6_1.jpg", "caption": "Table 1: Quantitative comparisons against SOTA methods on the synthetic SREDS dataset [57] and real-captured dataset [66]. Best and second-best results are boldfaced and underlined, respectively. Thanks to the spatio-temporal interaction, our approach consistently demonstrates optimal reconstruction performance, along with excellent parameter size, GPU memory usage, and FLOPs.", "description": "This table presents a quantitative comparison of the proposed STIR method against state-of-the-art (SOTA) methods for spiking camera image reconstruction.  It evaluates performance on both synthetic (SREDS) and real-captured datasets using metrics such as PSNR, SSIM, LPIPS, NIQE, and BRISQUE. The table highlights STIR's superior performance in terms of reconstruction accuracy and efficiency (parameter size, memory usage, and FLOPs).", "section": "5 Experiments"}, {"figure_path": "S4ZqnMywcM/tables/tables_8_1.jpg", "caption": "Table 3: Ablation studies on the SREDS dataset [57]. Underlining indicates our full model.\n(a) Feature pyramid levels. The more granular hierarchical features can promote superior results due to finer feature alignment and refinement.\n(b) Motion-intensity interaction. Combining warping-based and synthesis-based features for coarse-to-fine refinement can significantly improve reconstruction quality.\n(c) Symmetric interactive attention. Removing it or replacing it with independent cross-attention mechanisms both result in lower reconstruction accuracy.\n(d) Multi-motion field estimation. We investigate different groups of motion fields. More motion field favours compensation for additional image details.\n(e) Model capacity. \u00d7N denotes the width multiplier for the feature channel. Our method offers good flexibility and the performance is better with larger model capacity.\n(f) Loss function. Using the full loss term greatly contributes to the best results. Lrec loss is crucial to training an effective spike-to-image model.", "description": "This table presents the ablation study results on the SREDS dataset to analyze the impact of different components of the proposed Spatio-Temporal Interactive Reconstruction (STIR) network.  It systematically investigates the effects of varying the number of feature pyramid levels, the interplay of motion and intensity interactions, different attention mechanisms, the number of motion fields, model capacity, and the loss function components. Each row shows the performance (PSNR, SSIM, LPIPS, #Paras, TFLOPS) obtained with a specific configuration.", "section": "5 Experiments"}, {"figure_path": "S4ZqnMywcM/tables/tables_8_2.jpg", "caption": "Table 3: Ablation studies on the SREDS dataset [57]. Underlining indicates our full model. (a) Feature pyramid levels. The more granular hierarchical features can promote superior results due to finer feature alignment and refinement. (b) Motion-intensity interaction. Combining warping-based and synthesis-based features for coarse-to-fine refinement can significantly improve reconstruction quality. (c) Symmetric interactive attention. Removing it or replacing it with independent cross-attention mechanisms both result in lower reconstruction accuracy. (d) Multi-motion field estimation. We investigate different groups of motion fields. More motion field favours compensation for additional image details. (e) Model capacity. \u00d7N denotes the width multiplier for the feature channel. Our method offers good flexibility and the performance is better with larger model capacity. (f) Loss function. Using the full loss term greatly contributes to the best results. Lrec loss is crucial to training an effective spike-to-image model.", "description": "This table presents the ablation study results on the SREDS dataset to analyze the impact of different components of the proposed STIR model.  It shows the effect of varying the number of pyramid levels, the type of motion-intensity interaction, the use of symmetric interactive attention, the number of motion fields, the model capacity, and the loss function on the model's performance (PSNR, SSIM, #Paras, TFLOPs).  The full model is highlighted by underlining.", "section": "5 Experiments"}, {"figure_path": "S4ZqnMywcM/tables/tables_8_3.jpg", "caption": "Table 3: Ablation studies on the SREDS dataset [57]. Underlining indicates our full model. (a) Feature pyramid levels. The more granular hierarchical features can promote superior results due to finer feature alignment and refinement. (b) Motion-intensity interaction. Combining warping-based and synthesis-based features for coarse-to-fine refinement can significantly improve reconstruction quality. (c) Symmetric interactive attention. Removing it or replacing it with independent cross-attention mechanisms both result in lower reconstruction accuracy. (d) Multi-motion field estimation. We investigate different groups of motion fields. More motion field favours compensation for additional image details. (e) Model capacity. \u00d7N denotes the width multiplier for the feature channel. Our method offers good flexibility and the performance is better with larger model capacity. (f) Loss function. Using the full loss term greatly contributes to the best results. Lrec loss is crucial to training an effective spike-to-image model.", "description": "This table presents ablation studies conducted on the SREDS dataset to analyze the impact of different design choices on the performance of the proposed Spatio-Temporal Interactive Reconstruction (STIR) network.  Specifically, it examines the effects of varying the number of feature pyramid levels, the interaction between motion and intensity, the use of symmetric interactive attention, the number of multi-motion fields, model capacity, and the loss function components.  The results demonstrate the contribution of each component to the overall performance of the STIR network.", "section": "5 Experiments"}, {"figure_path": "S4ZqnMywcM/tables/tables_8_4.jpg", "caption": "Table 3: Ablation studies on the SREDS dataset [57]. Underlining indicates our full model.\n(a) Feature pyramid levels. The more granular hierarchical features can promote superior results due to finer feature alignment and refinement.\n(b) Motion-intensity interaction. Combining warping-based and synthesis-based features for coarse-to-fine refinement can significantly improve reconstruction quality.\n(c) Symmetric interactive attention. Removing it or replacing it with independent cross-attention mechanisms both result in lower reconstruction accuracy.\n(d) Multi-motion field estimation. We investigate different groups of motion fields. More motion fields favour compensation for additional image details.\n(e) Model capacity. \u00d7N denotes the width multiplier for the feature channel. Our method offers good flexibility and the performance is better with larger model capacity.\n(f) Loss function. Using the full loss term greatly contributes to the best results. Lrec loss is crucial to training an effective spike-to-image model.", "description": "This table presents the ablation study results performed on the SREDS dataset to analyze the impact of different components on the proposed Spatio-Temporal Interactive Reconstruction (STIR) network.  It shows the effect of varying the number of feature pyramid levels, using motion-intensity interaction, employing symmetric interactive attention, using multi-motion field estimation, adjusting model capacity, and using different loss functions on the model's PSNR, SSIM, LPIPS, number of parameters and TFLOPs.", "section": "5 Experiments"}, {"figure_path": "S4ZqnMywcM/tables/tables_8_5.jpg", "caption": "Table 3: Ablation studies on the SREDS dataset [57]. Underlining indicates our full model. (a) Feature pyramid levels. The more granular hierarchical features can promote superior results due to finer feature alignment and refinement. (b) Motion-intensity interaction. Combining warping-based and synthesis-based features for coarse-to-fine refinement can significantly improve reconstruction quality. (c) Symmetric interactive attention. Removing it or replacing it with independent cross-attention mechanisms both result in lower reconstruction accuracy. (d) Multi-motion field estimation. We investigate different groups of motion fields. More motion field favours compensation for additional image details. (e) Model capacity. \u00d7N denotes the width multiplier for the feature channel. Our method offers good flexibility and the performance is better with larger model capacity. (f) Loss function. Using the full loss term greatly contributes to the best results. Lrec loss is crucial to training an effective spike-to-image model.", "description": "This table presents the ablation study results performed on the SREDS dataset to analyze the impact of different components of the proposed STIR model. It shows the effects of changing the number of feature pyramid levels, the inclusion or exclusion of motion-intensity interaction, symmetric interactive attention, multi-motion field estimation, model capacity, and the loss function components.", "section": "5 Experiments"}, {"figure_path": "S4ZqnMywcM/tables/tables_8_6.jpg", "caption": "Table 3: Ablation studies on the SREDS dataset [57]. Underlining indicates our full model. (a) Feature pyramid levels. The more granular hierarchical features can promote superior results due to finer feature alignment and refinement. (b) Motion-intensity interaction. Combining warping-based and synthesis-based features for coarse-to-fine refinement can significantly improve reconstruction quality. (c) Symmetric interactive attention. Removing it or replacing it with independent cross-attention mechanisms both result in lower reconstruction accuracy. (d) Multi-motion field estimation. We investigate different groups of motion fields. More motion field favours compensation for additional image details. (e) Model capacity. \u00d7N denotes the width multiplier for the feature channel. Our method offers good flexibility and the performance is better with larger model capacity. (f) Loss function. Using the full loss term greatly contributes to the best results. Lrec loss is crucial to training an effective spike-to-image model.", "description": "This table presents ablation studies performed on the SREDS dataset to analyze the impact of different components of the proposed STIR model on its performance.  It examines the effects of varying the number of feature pyramid levels, the combination of warping-based and synthesis-based features, the use of symmetric interactive attention, the number of motion fields, the model capacity (width multiplier), and the loss function components on PSNR, SSIM, the number of parameters, and TFLOPs.", "section": "5 Experiments"}, {"figure_path": "S4ZqnMywcM/tables/tables_8_7.jpg", "caption": "Table 2: Ablation on spike embedding representation.", "description": "This table presents the ablation study on different spike embedding representation methods. It compares the performance (PSNR, SSIM, LPIPS) of using explicit methods (TFP), implicit methods (Multi-dilated, HiST, ResNet), and combinations of explicit and implicit methods.  The results show that combining explicit and implicit methods, specifically using TFP and ResNet, yields the best performance.", "section": "5.3 Ablation Studies"}, {"figure_path": "S4ZqnMywcM/tables/tables_15_1.jpg", "caption": "Table 4: Quantitative comparisons against SOTA methods on the synthetic SREDS dataset [57] and real-captured dataset [66]. Best and second-best results are boldfaced and underlined, respectively. Thanks to the spatio-temporal interaction, our approach consistently demonstrates optimal reconstruction performance, along with excellent parameter size, GPU memory usage, and FLOPs.", "description": "This table compares the proposed STIR method against state-of-the-art (SOTA) image reconstruction methods on both synthetic (SREDS) and real-captured datasets.  The comparison includes performance metrics (PSNR, SSIM, LPIPS, NIQE, BRISQUE), model parameters, GPU memory usage, and FLOPs. The results highlight that STIR achieves superior performance while maintaining low model complexity and efficiency.", "section": "5 Experiments"}]