[{"figure_path": "wvQHQgnpGN/tables/tables_1_1.jpg", "caption": "Table 1: Comparison of policy optimization methods for finding an e-optimal NE of two-player zero-sum episodic Markov games in terms of the duality gap. Here, H refers to the horizon length and d is the dimension of their features. For simplicity, we ignore the problem-dependent constant.", "description": "This table compares different policy optimization methods for solving two-player zero-sum episodic Markov games.  It shows the iteration complexity, whether the last-iterate converges to the optimal solution, the horizon length, and the state space type (finite or infinite) for each method. The methods are categorized by whether the system dynamics are known or unknown.  The table highlights the differences in computational efficiency and convergence properties of various approaches.", "section": "1 Introduction"}, {"figure_path": "wvQHQgnpGN/tables/tables_9_1.jpg", "caption": "Table 1: Comparison of policy optimization methods for finding an e-optimal NE of two-player zero-sum episodic Markov games in terms of the duality gap. Here, H refers to the horizon length and d is the dimension of their features. For simplicity, we ignore the problem-dependent constant.", "description": "This table compares various policy optimization methods for solving two-player zero-sum episodic Markov games.  It contrasts their performance based on several factors, including the complexity of the algorithm, whether the algorithm guarantees last-iterate convergence, and the length of the horizon used in the game. The methods are categorized by their treatment of the state space (finite, infinite, or unknown) and whether the system dynamics are known.  The table highlights the trade-offs between theoretical guarantees and practical efficiency of each method. ", "section": "1 Introduction"}]