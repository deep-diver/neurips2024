[{"figure_path": "umukvCdGI6/tables/tables_8_1.jpg", "caption": "Table 1: Mean (\u03bc) and standard deviation (\u03c3) of DOFEN's performance with 15 random seeds on 4 datasets from different tasks.", "description": "This table shows the mean and standard deviation of DOFEN's performance across 15 different random seeds, for four distinct datasets representing different classification and regression tasks. The purpose is to demonstrate the stability and consistency of DOFEN's performance across multiple runs.", "section": "4.3 Additional Analysis"}, {"figure_path": "umukvCdGI6/tables/tables_13_1.jpg", "caption": "Table 3: Nestimator for each dataset, as long as their Ncol and NrODT.", "description": "This table lists the number of columns (Ncol), the number of relaxed oblivious decision trees (NrODT), and the number of estimators (Nestimator) used in the DOFEN model for each dataset in the Tabular Benchmark.  The Nestimator value is calculated using a formula based on Ncol and NrODT.  This table provides a detailed breakdown of the model's configuration for each dataset.", "section": "A More DOFEN Settings"}, {"figure_path": "umukvCdGI6/tables/tables_14_1.jpg", "caption": "Table 3: Nestimator for each dataset, as long as their Ncol and NrODT.", "description": "This table shows the calculated Nestimator for each dataset using the default hyperparameters from the paper.  It also lists the number of columns (Ncol) and the number of relaxed oblivious decision trees (NrODT) for each dataset. Nestimator is a hyperparameter in DOFEN that controls the number of tree instances sampled in each iteration of the forest construction process.", "section": "A More DOFEN Settings"}, {"figure_path": "umukvCdGI6/tables/tables_15_1.jpg", "caption": "Table 3: Nestimator for each dataset, as long as their Ncol and NrODT.", "description": "This table shows the number of estimators (Nestimator), number of columns (Ncol), and number of relaxed oblivious decision trees (NrODT) for each dataset used in the experiments.  The Nestimator value is calculated using a formula involving Ncol and NrODT. This information is crucial for understanding the configuration of the DOFEN model for each dataset.", "section": "A More DOFEN Settings"}, {"figure_path": "umukvCdGI6/tables/tables_16_1.jpg", "caption": "Table 5: OpenML Task ID mappings for classification datasets with numerical features only.", "description": "This table lists the OpenML Task IDs and corresponding dataset names for classification tasks that use only numerical features.  The OpenML ID is a unique identifier used to access datasets from the OpenML platform.  The dataset names are provided for clarity and context.", "section": "B.3 Mappings of OpenML Task ID and Dataset Name"}, {"figure_path": "umukvCdGI6/tables/tables_16_2.jpg", "caption": "Table 6: OpenML Task ID mappings for classification datasets with heterogeneous features.", "description": "This table lists the OpenML Task IDs and their corresponding dataset names for classification tasks where the datasets contain both numerical and categorical features.  It provides a cross-reference for accessing the datasets using the OpenML IDs.", "section": "B More Tabular Benchmark Settings"}, {"figure_path": "umukvCdGI6/tables/tables_16_3.jpg", "caption": "Table 3: Nestimator for each dataset, as long as their Ncol and NrODT.", "description": "This table shows the number of estimators (Nestimator), the number of columns (Ncol), and the number of relaxed oblivious decision trees (NrODT) for each dataset used in the experiments.  These values are calculated based on formulas and hyperparameters specified in the paper. The OpenML ID is also provided to identify each dataset.", "section": "A.3 Actual Nestimator for each Dataset"}, {"figure_path": "umukvCdGI6/tables/tables_17_1.jpg", "caption": "Table 3: Nestimator for each dataset, as long as their Ncol and NrODT.", "description": "This table shows the calculated Nestimator value for each dataset from the Tabular Benchmark.  Nestimator is a hyperparameter of the DOFEN model, related to the number of relaxed oblivious decision trees (rODTs) in the forest. The table also provides the number of columns (Ncol) in each dataset and the number of rODTs (NrODT) generated.", "section": "A More DOFEN Settings"}, {"figure_path": "umukvCdGI6/tables/tables_18_1.jpg", "caption": "Table 9: Computational efficiency analysis of default hyperparameters on medium-sized classification datasets.", "description": "This table presents a comparison of the computational efficiency of various models (DOFEN, Trompt, FT-Transformer, NODE, XGBoost, LightGBM, and CatBoost) on medium-sized classification datasets using default hyperparameters.  The metrics compared include performance (accuracy), floating point operations (FLOPs), the number of parameters, and inference time. Note that FLOPs and parameter counts are only applicable to the DNN-based models (DOFEN, Trompt, FT-Transformer, and NODE), while the other models (XGBoost, LightGBM, and CatBoost) use tree-based algorithms with different computational characteristics. The table provides a useful comparison of how various models balance accuracy with computational resource requirements.", "section": "C Computational Efficiency Analysis"}, {"figure_path": "umukvCdGI6/tables/tables_18_2.jpg", "caption": "Table 10: Computational efficiency analysis of optimal hyperparameters on medium-sized classification datasets.", "description": "This table presents a comparison of different machine learning models' performance, computational efficiency (FLOPs), and parameter sizes on medium-sized classification datasets.  The optimal hyperparameters for each model were used to obtain the results, resulting in the highest accuracy achieved by each model. The table shows that DOFEN achieves a good balance between performance and efficiency,  significantly outperforming others in terms of FLOPs while maintaining competitive accuracy.", "section": "C Computational Efficiency Analysis"}, {"figure_path": "umukvCdGI6/tables/tables_18_3.jpg", "caption": "Table 9: Computational efficiency analysis of default hyperparameters on medium-sized classification datasets.", "description": "This table presents a computational efficiency analysis for various models on medium-sized classification datasets using default hyperparameters.  It compares the performance (accuracy), floating point operations (FLOPs), number of parameters (in millions), and inference time (in seconds) for different models, including DOFEN, Trompt, FT-Transformer, NODE, XGBoost, LightGBM, and CatBoost.  The results highlight the trade-offs between model complexity, performance, and efficiency.", "section": "C Computational Efficiency Analysis"}, {"figure_path": "umukvCdGI6/tables/tables_18_4.jpg", "caption": "Table 12: Computational efficiency analysis of optimal hyperparameters on medium-sized regression datasets.", "description": "This table presents a comparison of the computational efficiency of various models on medium-sized regression datasets, focusing on FLOPs (floating point operations), the number of parameters, and inference time.  The models compared include DOFEN, Trompt, FT-Transformer, NODE, XGBoost, LightGBM, and CatBoost.  The results highlight the computational efficiency of DOFEN, particularly with respect to FLOPs and inference time, while also noting the trade-off between model size, computation, and performance.", "section": "C Computational Efficiency Analysis"}, {"figure_path": "umukvCdGI6/tables/tables_19_1.jpg", "caption": "Table 13: Average inference time proportion of each DOFEN module across 59 medium-sized datasets.", "description": "This table shows the proportion of inference time spent on each module of the DOFEN model across 59 medium-sized datasets. The modules are Condition Generation, Relaxed ODT Construction, Forest Construction, and Forest Ensemble.  The mean and standard deviation of the proportions are given for each module.  The table shows that the Forest Construction module takes up the most inference time (87.39%), highlighting it as an area for potential optimization.", "section": "C Computational Efficiency Analysis"}, {"figure_path": "umukvCdGI6/tables/tables_19_2.jpg", "caption": "Table 13: Average inference time proportion of each DOFEN module across 59 medium-sized datasets.", "description": "This table presents a breakdown of the average inference time proportions for each module within the DOFEN model across 59 medium-sized datasets.  It shows that the Forest Construction module takes up the majority (87.39%) of the inference time, with the sub-modules within Forest Construction taking up most of the time.", "section": "C Computational Efficiency Analysis"}, {"figure_path": "umukvCdGI6/tables/tables_20_1.jpg", "caption": "Table 15: Average training time of different methods using default and optimal hyperparameter settings on 50 medium-sized datasets. Numbers are in Seconds, with lower values indicating faster training speed.", "description": "This table compares the training time of various models, including DOFEN, Trompt, FT-Transformer, and NODE.  Two training times are presented for each model: one using default hyperparameters and one using optimal hyperparameters. The results show the time taken to train each model on 50 medium-sized datasets, demonstrating the relative training efficiency of each.", "section": "D Scalability of DOFEN"}, {"figure_path": "umukvCdGI6/tables/tables_20_2.jpg", "caption": "Table 16: Analysis of performance and efficiency across varied settings of m on medium-sized datasets.", "description": "This table presents the results of an experiment analyzing the impact of varying the hyperparameter 'm' on the performance and efficiency of the DOFEN model.  The experiment was conducted on medium-sized datasets from the Tabular Benchmark and reports performance (Accuracy for classification and R2 score for regression), model parameters (in millions), and floating point operations (FLOPS, in millions) for different values of 'm' (4, 8, 16, 32, and 64). The default value of 'm' is 16.", "section": "D Scalability of DOFEN"}, {"figure_path": "umukvCdGI6/tables/tables_20_3.jpg", "caption": "Table 16: Analysis of performance and efficiency across varied settings of m on medium-sized datasets.", "description": "This table shows the results of experiments conducted to analyze the scalability of DOFEN by varying the hyperparameter 'm'. The hyperparameter 'm' influences the number of conditions (Ncond), the total number of relaxed oblivious decision trees (rODTs; NrODT), and the number of rODTs within each rODT forest (Nestimator). The table presents the performance (accuracy for classification and R2 score for regression), the number of parameters (in millions), and the number of floating point operations (FLOPs; in millions) for different values of 'm', including the default value of 16.  The results indicate how the model's performance, parameter count, and computational cost change as 'm' is increased, providing insights into DOFEN's scalability.", "section": "D Scalability of DOFEN"}, {"figure_path": "umukvCdGI6/tables/tables_21_1.jpg", "caption": "Table 18: Analysis of performance and efficiency across varied settings of d on medium-sized datasets.", "description": "This table presents the results of experiments conducted to analyze the impact of varying the depth (d) of the relaxed oblivious decision trees (rODTs) within the DOFEN model on medium-sized datasets.  The table shows the performance (accuracy for classification and R2 score for regression), the number of parameters (in millions), and the number of floating point operations (FLOPS, in millions) for different depths (d = 2, 3, 4, 6, 8).  Depth 4 is the default setting used in the paper. The results help to understand the trade-off between model complexity and performance at different depths.", "section": "D Scalability of DOFEN"}, {"figure_path": "umukvCdGI6/tables/tables_21_2.jpg", "caption": "Table 18: Analysis of performance and efficiency across varied settings of d on medium-sized datasets.", "description": "This table presents the results of experiments conducted to analyze the impact of varying the depth (d) of relaxed oblivious decision trees (rODTs) within the DOFEN model on medium-sized datasets. The table displays the performance (accuracy for classification and R2 score for regression), the number of parameters (in millions), and the number of floating-point operations (FLOPs, in millions) for different values of d, ranging from 2 to 8. The default setting of d=4 is highlighted.", "section": "D Scalability of DOFEN"}, {"figure_path": "umukvCdGI6/tables/tables_21_3.jpg", "caption": "Table 16: Analysis of performance and efficiency across varied settings of m on medium-sized datasets.", "description": "This table shows the performance (accuracy for classification and R2 score for regression) and efficiency (parameters and FLOPs) of the DOFEN model on medium-sized datasets with different settings of the hyperparameter 'm'.  The hyperparameter 'm' influences the number of conditions (Ncond) and the number of rODTs in a forest (Nestimator). The table helps to assess the effect of 'm' on model performance and computational cost.", "section": "D Scalability of DOFEN"}, {"figure_path": "umukvCdGI6/tables/tables_21_4.jpg", "caption": "Table 21: Analysis of performance and efficiency across varied settings of num_layers on large-sized datasets.", "description": "This table presents the results of experiments conducted to evaluate the impact of varying the number of layers in the neural networks (\u03941, \u03942, and \u03943) of the DOFEN model on large-sized datasets. It shows how changes in the number of layers affect the model's performance (accuracy for classification, R2 score for regression), the number of parameters, and the number of floating point operations (FLOPs).  The results are presented for three different configurations: the default setting (one layer each), twice the default (two layers each), and three times the default (three layers each).", "section": "D Scalability of DOFEN"}, {"figure_path": "umukvCdGI6/tables/tables_22_1.jpg", "caption": "Table 22: Top 3 Feature importance of DOFEN on mushroom dataset.", "description": "This table compares the top three most important features identified by DOFEN and other tree-based models (Random Forest, XGBoost, LightGBM, CatBoost, GradientBoosting Tree, and Trompt) on the mushroom dataset. The feature importance is represented as a percentage, indicating the relative contribution of each feature to the model's prediction. The results show a high degree of agreement between DOFEN and the other models, suggesting that DOFEN is able to capture similar information as other tree-based models.", "section": "E Interpretability of DOFEN"}, {"figure_path": "umukvCdGI6/tables/tables_22_2.jpg", "caption": "Table 23: Feature importance of DOFEN on red wine dataset.", "description": "This table presents the top three most important features identified by DOFEN, compared with other tree-based models and Trompt, on the red wine dataset.  The features are ranked by importance percentage, providing insights into the model's interpretability and alignment with other methods.", "section": "F More Analysis"}, {"figure_path": "umukvCdGI6/tables/tables_22_3.jpg", "caption": "Table 24: Feature importance of DOFEN on white wine dataset.", "description": "This table presents the top three most important features identified by the DOFEN model, along with those identified by other tree-based models (Random Forest, XGBoost, LightGBM, CatBoost, GradientBoosting Tree) and a deep learning model (Trompt) for the white wine quality dataset.  The results show a high degree of agreement between DOFEN and the other models, indicating that DOFEN is able to identify key features while maintaining interpretability despite its deep learning architecture.", "section": "F More Analysis"}, {"figure_path": "umukvCdGI6/tables/tables_23_1.jpg", "caption": "Table 25: Comparing DOFEN with and without sampling in forest ensemble", "description": "This table compares the performance of DOFEN with and without using sampling in the forest ensemble. It shows the average accuracy for classification tasks and the average R-squared score for regression tasks, broken down by dataset type (numerical only and heterogeneous).  The results demonstrate a significant improvement in DOFEN's performance when using the sampling technique (the default setting).", "section": "F More Analysis"}, {"figure_path": "umukvCdGI6/tables/tables_24_1.jpg", "caption": "Table 26: Comparing evaluation performance with and without seed ensemble at varying Nforest.", "description": "This table presents the results of an experiment comparing the performance of the DOFEN model with and without an additional layer of bagging ensemble (seed ensemble). The experiment was conducted on medium-sized tabular datasets with varying number of forests (Nforest = 10, 20, 50, 100, 300).  The results show the performance in classification and regression tasks, illustrating how the seed ensemble impacts the model's accuracy and R-squared score.", "section": "F.2 Seed Ensemble"}, {"figure_path": "umukvCdGI6/tables/tables_24_2.jpg", "caption": "Table 27: Comparing the column selection strategy of DOFEN.", "description": "This table compares the performance of three different column selection strategies for constructing rODTs within the DOFEN model.  The first strategy is the default \"Shuffle\" approach, while the second and third strategies use a CatBoost model to initialize the column selection ('Catboost-Init' and 'CatBoost*'). The table shows that the CatBoost-Init approach achieves comparable performance to a fully trained CatBoost model and outperforms the shuffle approach.  This suggests that more sophisticated methods for column selection can lead to better results, but end-to-end differentiability is prioritized in the paper.", "section": "F More Analysis"}, {"figure_path": "umukvCdGI6/tables/tables_24_3.jpg", "caption": "Table 28: The comparison of random sampling and sliding window selection of weights.", "description": "This table compares the performance of the Two-level Relaxed ODT Ensemble module in DOFEN using two different weight selection methods: random sampling (default) and sliding window selection.  The results show the average performance across various datasets for classification and regression tasks.  It highlights the relative effectiveness of the two approaches in achieving good predictive performance.", "section": "F More Analysis"}, {"figure_path": "umukvCdGI6/tables/tables_25_1.jpg", "caption": "Table 29: Pruning of rODT with varying ratio. Weights wi with lower standard deviation are pruned.", "description": "This table shows the performance of DOFEN model with different pruning ratios of rODTs. The weights are sorted by their standard deviations, and the pruning is applied from the lower end. The results show that a small degree of pruning can improve the performance, especially for classification tasks. The optimal pruning ratios are 0.02 for classification and 0.1 for regression. The `by dataset` approach tailors the pruning ratio for each dataset and shows a better performance.", "section": "F.6 Pruning of Relaxed ODT"}, {"figure_path": "umukvCdGI6/tables/tables_25_2.jpg", "caption": "Table 29: Pruning of rODT with varying ratio. Weights wi with lower standard deviation are pruned.", "description": "This table presents the results of an experiment that explores the impact of pruning relaxed oblivious decision trees (rODTs) in the DOFEN model.  Specifically, it shows the performance (classification accuracy and regression R-squared) achieved at different pruning ratios.  The pruning ratios indicate the proportion of rODTs with the lowest standard deviation of weights that are removed. The results demonstrate that modest pruning can even improve performance.", "section": "F More Analysis"}, {"figure_path": "umukvCdGI6/tables/tables_26_1.jpg", "caption": "Table 29: Pruning of rODT with varying ratio. Weights wi with lower standard deviation are pruned.", "description": "This table shows the results of experiments on pruning rODTs with varying ratios. The pruning is based on the standard deviations of the weights for each rODT. The table shows that pruning a small portion of rODTs (with lower standard deviation weights) doesn't hurt the performance and may even improve it slightly. However, when pruning rODTs with higher standard deviation weights, the performance decreases as the pruning ratio increases.", "section": "F More Analysis"}, {"figure_path": "umukvCdGI6/tables/tables_26_2.jpg", "caption": "Table 29: Pruning of rODT with varying ratio. Weights wi with lower standard deviation are pruned.", "description": "This table presents the results of an experiment where the weights (wi) of Relaxed Oblivious Decision Trees (rODTs) with lower standard deviations are pruned. The experiment is conducted to investigate the impact of pruning on the model's performance. The table shows the performance of the model (classification and regression) under different pruning ratios. The results suggest that pruning these rODTs does not negatively affect the performance and, in some cases, enhance the performance.", "section": "F.6 Pruning of Relaxed ODT"}, {"figure_path": "umukvCdGI6/tables/tables_27_1.jpg", "caption": "Table 34: The performance of medium-sized classification task (numerical features only) (1).", "description": "This table presents the performance of different models on the medium-sized classification datasets with only numerical features.  It shows the accuracy achieved by each model on 10 different datasets, providing a detailed comparison of DOFEN against several tree-based models (CatBoost, LightGBM, XGBoost, HistGradientBoosting Tree, GradientBoosting Tree, Random Forest) and other DNN models (Trompt, GRANDE, FT-Transformer, ResNet, MLP, SAINT, NODE).  The table includes both default and searched hyperparameter results for each model.", "section": "G More Evaluation Results on Tabular Benchmark"}, {"figure_path": "umukvCdGI6/tables/tables_33_1.jpg", "caption": "Table 34: The performance of medium-sized classification task (numerical features only) (1).", "description": "This table presents the detailed performance of various models on a subset of medium-sized classification datasets from the Tabular Benchmark, focusing only on datasets with exclusively numerical features.  The table shows the performance metrics (likely accuracy) for each model on 10 different datasets, allowing for a granular comparison of model effectiveness across diverse datasets. The table includes both default and searched hyperparameters, providing insights into the impact of hyperparameter tuning on model performance. ", "section": "G.2 Detailed Evaluation Results"}, {"figure_path": "umukvCdGI6/tables/tables_34_1.jpg", "caption": "Table 34: The performance of medium-sized classification task (numerical features only) (1).", "description": "This table presents the performance of various models on medium-sized classification datasets with only numerical features.  The performance is evaluated using accuracy and reported for each model on multiple datasets.  The table shows both default hyperparameter settings and results from a hyperparameter search. The ranking of the models is also provided based on the average rank across datasets.", "section": "G.2 Detailed Evaluation Results"}, {"figure_path": "umukvCdGI6/tables/tables_35_1.jpg", "caption": "Table 34: The performance of medium-sized classification task (numerical features only) (1).", "description": "This table presents the performance of various models on medium-sized classification datasets with only numerical features. The table shows the performance (accuracy) of different models across 10 datasets.  The 'Default' row shows the performance of models using their default hyperparameters, and the 'Searched' row shows the performance after hyperparameter search. The table helps demonstrate the effectiveness of DOFEN (ours) compared to other models in this specific setting.", "section": "G.2 Detailed Evaluation Results"}, {"figure_path": "umukvCdGI6/tables/tables_36_1.jpg", "caption": "Table 34: The performance of medium-sized classification task (numerical features only) (1).", "description": "This table presents the performance of various models on medium-sized classification datasets containing only numerical features.  The table shows the performance (accuracy) of each model on 10 different datasets, providing a detailed breakdown of the results. The models compared include DOFEN, Trompt, GRANDE, FT-Transformer, ResNet, MLP, SAINT, NODE, CatBoost, LightGBM, XGBoost, HistGradientBoosting Tree, GradientBoosting Tree, and Random Forest.  Both default and searched hyperparameter settings are reported for each model.", "section": "G.2 Detailed Evaluation Results"}, {"figure_path": "umukvCdGI6/tables/tables_37_1.jpg", "caption": "Table 3: Nestimator for each dataset, as long as their Ncol and NrODT.", "description": "This table shows the number of estimators (Nestimator), number of columns (Ncol), and number of relaxed oblivious decision trees (NrODT) for each dataset used in the paper's experiments.  It provides specific hyperparameter settings for the DOFEN model used in the evaluation. The Nestimator value is calculated using a formula which depends on the dataset size.", "section": "A More DOFEN Settings"}, {"figure_path": "umukvCdGI6/tables/tables_38_1.jpg", "caption": "Table 34: The performance of medium-sized classification task (numerical features only) (1).", "description": "This table presents the performance of various models on medium-sized classification datasets with only numerical features.  The table shows the performance metrics (likely accuracy) for each model on a set of datasets (identified by their OpenML IDs). The 'Default' and 'Searched' rows likely represent results using default hyperparameters and hyperparameters found via a search, respectively. The table provides a comparison of DOFEN against other tree-based and deep learning methods.", "section": "G.2 Detailed Evaluation Results"}, {"figure_path": "umukvCdGI6/tables/tables_39_1.jpg", "caption": "Table 34: The performance of medium-sized classification task (numerical features only) (1).", "description": "This table presents the performance of various models on medium-sized classification datasets with only numerical features.  The table shows the performance (accuracy) of different models on a specific set of datasets.  Each column represents a different dataset, and each row represents a different model. The table is divided into two parts: \"Default\" and \"Searched,\" representing the model performance with default and searched hyperparameters respectively. The \"Ranking\" column provides the average rank across all datasets for each model.", "section": "G.2 Detailed Evaluation Results"}, {"figure_path": "umukvCdGI6/tables/tables_40_1.jpg", "caption": "Table 34: The performance of medium-sized classification task (numerical features only) (1).", "description": "This table presents the performance of various machine learning models on a subset of medium-sized classification datasets containing only numerical features.  The table shows the performance (accuracy) of each model on 10 specific datasets. The datasets are identified by their OpenML IDs.  The results are presented for both the default and searched hyperparameter settings for each model. The ranking of each model across all datasets is also included, providing a summary of their relative performance.", "section": "G.2 Detailed Evaluation Results"}, {"figure_path": "umukvCdGI6/tables/tables_41_1.jpg", "caption": "Table 36: The performance of medium-sized classification task (heterogeneous features).", "description": "This table presents the performance of various models on medium-sized classification datasets with heterogeneous features.  The table shows the performance (accuracy) of each model on each dataset in the benchmark, and then shows the average rank of each model across all the datasets and their standard deviations. This provides a comprehensive comparison of the models' performance on this specific task and feature type.", "section": "G More Evaluation Results on Tabular Benchmark"}, {"figure_path": "umukvCdGI6/tables/tables_42_1.jpg", "caption": "Table 34: The performance of medium-sized classification task (numerical features only) (1).", "description": "This table presents the performance of various models on medium-sized classification datasets containing only numerical features.  The results are organized to show the performance of each model across different datasets.  The table includes metrics to assess the performance of each model, allowing for a comparison of their effectiveness on this specific type of dataset.", "section": "G.2 Detailed Evaluation Results"}, {"figure_path": "umukvCdGI6/tables/tables_43_1.jpg", "caption": "Table 34: The performance of medium-sized classification task (numerical features only) (1).", "description": "This table presents the detailed performance of various models on medium-sized classification datasets containing only numerical features.  It shows the performance (accuracy) of each model on 10 datasets, along with the ranking of each model across all 10 datasets.  The table includes results for both default and searched hyperparameters, allowing for a comparison of performance with default settings versus optimized settings.  The models evaluated include DOFEN, Trompt, GRANDE, FT-Transformer, ResNet, MLP, SAINT, NODE, CatBoost, LightGBM, XGBoost, HistGradientBoosting Tree, GradientBoosting Tree, and Random Forest. The ranking is a mean and standard deviation across the 10 datasets.", "section": "G.2 Detailed Evaluation Results"}, {"figure_path": "umukvCdGI6/tables/tables_44_1.jpg", "caption": "Table 9: Computational efficiency analysis of default hyperparameters on medium-sized classification datasets.", "description": "This table presents a computational efficiency analysis of various models, including DOFEN, on medium-sized classification datasets.  It compares the performance (accuracy), FLOPS (floating point operations), number of parameters, and inference time for each model using the default hyperparameter settings. The results offer insights into the computational trade-offs of different models for tabular data classification.", "section": "C Computational Efficiency Analysis"}, {"figure_path": "umukvCdGI6/tables/tables_44_2.jpg", "caption": "Table 3: Nestimator for each dataset, as long as their Ncol and NrODT.", "description": "This table lists the calculated Nestimator values for each dataset used in the study.  It also shows the number of columns (Ncol) and the number of relaxed oblivious decision trees (NrODT) for each dataset.  Nestimator is a hyperparameter in the DOFEN model, representing the number of pairs of weights and embedding vectors randomly sampled to form an rODT forest.", "section": "A.3 Actual Nestimator for each Dataset"}, {"figure_path": "umukvCdGI6/tables/tables_44_3.jpg", "caption": "Table 3: Nestimator for each dataset, as long as their Ncol and NrODT.", "description": "This table lists the calculated Nestimator values for each dataset used in the study, along with the corresponding number of columns (Ncol) and the number of relaxed oblivious decision trees (NrODT).  Nestimator is a hyperparameter that determines the number of (weight, embedding) pairs sampled to form each relaxed ODT forest during training. The values are calculated using a pre-defined formula, and the datasets are identified by their OpenML IDs. This information is crucial for understanding and reproducing the experimental setup and results.", "section": "A More DOFEN Settings"}, {"figure_path": "umukvCdGI6/tables/tables_44_4.jpg", "caption": "Table 3: Nestimator for each dataset, as long as their Ncol and NrODT.", "description": "This table shows the calculated number of estimators (Nestimator) for each dataset in the Tabular Benchmark.  It also provides the number of columns (Ncol) and the number of relaxed oblivious decision trees (NrODT) for each dataset. The Nestimator is calculated using a formula mentioned in the paper, and these values help configure the DOFEN model for optimal performance on the respective dataset.", "section": "A More DOFEN Settings"}, {"figure_path": "umukvCdGI6/tables/tables_45_1.jpg", "caption": "Table 9: Computational efficiency analysis of default hyperparameters on medium-sized classification datasets.", "description": "This table presents a computational efficiency analysis focusing on medium-sized classification datasets.  It compares several models (DOFEN, Trompt, FT-Transformer, NODE, XGBoost, LightGBM, and CatBoost) across four key metrics: Performance (Accuracy), FLOPS (Millions), Parameters (Millions), and Inference time (seconds). The analysis utilizes default hyperparameters for each model.", "section": "C Computational Efficiency Analysis"}, {"figure_path": "umukvCdGI6/tables/tables_45_2.jpg", "caption": "Table 3: Nestimator for each dataset, as long as their Ncol and NrODT.", "description": "This table shows the calculated Nestimator for each dataset used in the paper's experiments.  The Nestimator value is derived using a formula which takes into account the number of columns (Ncol) and the number of relaxed oblivious decision trees (NrODT). The table is organized by OpenML ID for easy reference to the datasets.", "section": "A.3 Actual Nestimator for each Dataset"}, {"figure_path": "umukvCdGI6/tables/tables_45_3.jpg", "caption": "Table 3: Nestimator for each dataset, as long as their Ncol and NrODT.", "description": "This table shows the number of estimators (Nestimator), the number of columns (Ncol), and the number of relaxed oblivious decision trees (NrODT) for each dataset used in the experiments.  These values are calculated using formulas described in the paper and depend on the specific characteristics of each dataset. The table is organized by the OpenML ID of each dataset.", "section": "A.3 Actual Nestimator for each Dataset"}, {"figure_path": "umukvCdGI6/tables/tables_45_4.jpg", "caption": "Table 52: Hyperparameter search space of Trompt.", "description": "This table shows the hyperparameter search space used for the Trompt model in the paper's experiments.  It lists each hyperparameter (e.g., hidden_dimension, feature_importances_type) and specifies its possible values or distribution (e.g., [18, 128], [concat, add]).  These settings were used to tune the model for optimal performance on the Tabular Benchmark datasets.", "section": "H.2 Hyperparameter Search Space"}, {"figure_path": "umukvCdGI6/tables/tables_45_5.jpg", "caption": "Table 3: Nestimator for each dataset, as long as their Ncol and NrODT.", "description": "This table shows the calculated Nestimator for each dataset in the Tabular Benchmark using the default hyperparameters of the DOFEN model.  It provides the number of columns (Ncol) and the number of relaxed oblivious decision trees (NrODT) for each dataset, which are hyperparameters used in the DOFEN model construction. The Nestimator, which represents the number of (weight, embedding) pairs sampled for each forest, is also shown. The OpenML IDs are used to identify each dataset.", "section": "A More DOFEN Settings"}, {"figure_path": "umukvCdGI6/tables/tables_46_1.jpg", "caption": "Table 3: Nestimator for each dataset, as long as their Ncol and NrODT.", "description": "This table lists the number of columns (Ncol), the number of relaxed oblivious decision trees (NrODT), and the number of estimators (Nestimator) for each dataset used in the experiments.  Nestimator is a hyperparameter calculated by a formula that depends on Ncol and NrODT. The table provides details on the configuration of the DOFEN model for different datasets.", "section": "A More DOFEN Settings"}, {"figure_path": "umukvCdGI6/tables/tables_46_2.jpg", "caption": "Table 35: The performance of medium-sized classification task (heterogeneous features).", "description": "This table presents the performance of various models on medium-sized classification datasets with heterogeneous features.  It lists the average accuracy and standard deviation for each model across multiple datasets.  The models are categorized into DOFEN (the proposed method) and baseline models.", "section": "G More Evaluation Results on Tabular Benchmark"}, {"figure_path": "umukvCdGI6/tables/tables_46_3.jpg", "caption": "Table 3: Nestimator for each dataset, as long as their Ncol and NrODT.", "description": "This table lists the calculated Nestimator value for each dataset used in the study, along with the corresponding number of columns (Ncol) and the number of relaxed oblivious decision trees (NrODT).  These values are crucial for understanding the configuration and hyperparameter settings used in the DOFEN model, especially during the two-level relaxed ODT ensemble process. The OpenML ID is also included to help identify each dataset.", "section": "A More DOFEN Settings"}, {"figure_path": "umukvCdGI6/tables/tables_46_4.jpg", "caption": "Table 37: The performance of medium-sized regression task (numerical features only) (1).", "description": "This table presents the detailed performance of various models on a subset of medium-sized regression datasets with exclusively numerical features. The performance is evaluated using the R-squared score.  The table provides a comparison of DOFEN against several baseline models, including tree-based models (e.g., CatBoost, XGBoost, GradientBoosting Tree, RandomForest) and deep learning models (e.g., Trompt, FT-Transformer, NODE, ResNet, MLP, SAINT, GRANDE).  Both default and searched hyperparameter configurations are shown for each model.", "section": "G More Evaluation Results on Tabular Benchmark"}]