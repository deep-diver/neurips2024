{"references": [{"fullname_first_author": "Sergey Tulyakov", "paper_title": "MoCoGAN: Decomposing motion and content for video generation", "publication_date": "2018-06-01", "reason": "This paper is foundational for motion generation using GANs, a technique the current paper builds upon and improves."}, {"fullname_first_author": "Anindita Ghosh", "paper_title": "Synthesis of compositional animations from textual descriptions", "publication_date": "2021-01-01", "reason": "This paper is highly relevant as it directly addresses text-to-motion generation, a core topic of the current work."}, {"fullname_first_author": "Chuan Guo", "paper_title": "Generating diverse and natural 3D human motions from text", "publication_date": "2022-06-01", "reason": "This paper introduces a key dataset (HumanML3D) used in evaluating the current research, and its techniques directly inform the current paper's approach."}, {"fullname_first_author": "A\u00e4ron van den Oord", "paper_title": "Neural discrete representation learning", "publication_date": "2017-12-01", "reason": "This paper introduces Vector Quantized Variational Autoencoders (VQ-VAEs), a crucial technique used for motion quantization in the current research."}, {"fullname_first_author": "Jacob Devlin", "paper_title": "BERT: Pre-training of deep bidirectional transformers for language understanding", "publication_date": "2019-06-01", "reason": "This paper introduces the masked language modeling technique, which the current research adapts for spatial-temporal 2D token masking, a key component of its approach."}]}