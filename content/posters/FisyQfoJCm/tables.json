[{"figure_path": "FisyQfoJCm/tables/tables_7_1.jpg", "caption": "Table 1: Evaluation on the HumanML3D dataset (upper half) and the KIT-ML dataset (lower half).", "description": "This table presents a comparison of the proposed MoGenTS model with several state-of-the-art methods for text-to-motion generation on two benchmark datasets: HumanML3D and KIT-ML.  The evaluation metrics include FID (Frechet Inception Distance), Top-k accuracy (Top1, Top2, Top3, indicating how often the generated motion is ranked in the top k places relative to the ground truth motions given the text prompt), MM-Dist (MultiModal-Distance), and Diversity. Lower FID indicates better motion quality, while higher Top-k accuracy and Diversity indicate better text-motion alignment and motion variety, respectively. The results showcase MoGenTS's superior performance compared to existing methods on both datasets.", "section": "4 Experiments"}, {"figure_path": "FisyQfoJCm/tables/tables_7_2.jpg", "caption": "Table 1: Evaluation on the HumanML3D dataset (upper half) and the KIT-ML dataset (lower half).", "description": "This table presents the quantitative results of the proposed MoGenTS model and compares it with several state-of-the-art methods on two benchmark datasets: HumanML3D and KIT-ML.  The metrics used to evaluate the models' performance are FID (Frechet Inception Distance), Top-1, Top-2, Top-3 accuracy (for text-to-motion retrieval), MM-Dist (MultiModal-Distance), and Diversity.  Lower FID indicates better motion generation quality, while higher Top-k and Diversity scores indicate better alignment with text prompts and more diverse motion generation, respectively.  The upper half of the table shows results for the HumanML3D dataset, while the lower half displays results for the KIT-ML dataset.", "section": "4 Experiments"}, {"figure_path": "FisyQfoJCm/tables/tables_8_1.jpg", "caption": "Table 3: Ablation study on HumanML3D dataset.", "description": "This table presents the ablation study results on the HumanML3D dataset, showing the impact of different components of the proposed model on FID and Top1 scores.  It demonstrates the effectiveness of 2D VQ, 2D Masking, 2D Position Encoding, and Spatial and Temporal Attention in improving the model's performance.", "section": "4.4 Ablation Study"}, {"figure_path": "FisyQfoJCm/tables/tables_14_1.jpg", "caption": "Table 1: Evaluation on the HumanML3D dataset (upper half) and the KIT-ML dataset (lower half).", "description": "This table presents the quantitative results of the proposed MoGenTS model and compares it with other state-of-the-art methods on two benchmark datasets: HumanML3D and KIT-ML.  The metrics used for evaluation include FID (Frechet Inception Distance), which measures the similarity between generated and ground truth motion, Top1, Top2, and Top3 accuracy for text-to-motion alignment, MM-Dist (MultiModal Distance) representing the distance between text and motion features, and Diversity.  Lower FID values indicate better generation quality; higher accuracy values are better for text-to-motion alignment; lower MM-Dist and higher diversity indicate better performance. The table shows that the MoGenTS model outperforms existing methods on both datasets across all metrics.", "section": "4 Experiments"}, {"figure_path": "FisyQfoJCm/tables/tables_15_1.jpg", "caption": "Table 5: Evaluation of motion quantization on (a) Humanml3D dataset and (b) KIT-ML dataset. MPJPE is measured in millimeters.", "description": "This table presents the results of motion quantization experiments on two datasets: HumanML3D and KIT-ML.  The metrics used to evaluate the quality of the quantization are Mean Per Joint Position Error (MPJPE), Frechet Inception Distance (FID), and R-precision (Top1, Top2, Top3).  Additionally, MultiModal Distance (MM-Dist) and Diversity are reported to show the overall performance of the quantization method. Lower MPJPE and FID values, along with higher R-precision values indicate better quantization performance.", "section": "4.3 Evaluation"}, {"figure_path": "FisyQfoJCm/tables/tables_15_2.jpg", "caption": "Table 1: Evaluation on the HumanML3D dataset (upper half) and the KIT-ML dataset (lower half).", "description": "This table presents the quantitative results of the proposed MoGenTS model on HumanML3D and KIT-ML datasets.  The upper half shows the results for HumanML3D, while the lower half shows the results for KIT-ML.  For both datasets, the table compares the MoGenTS model against several state-of-the-art methods, evaluating performance using metrics like FID (Fr\u00e9chet Inception Distance), Top1, Top2, Top3 (top-k accuracies), MM-Dist (MultiModal-Distance), and Diversity.  Lower FID scores indicate better performance in motion generation, while higher values for Top-k, and Diversity suggest better motion generation accuracy and diversity.  The MPJPE (Mean Per Joint Position Error) is also provided, measuring the accuracy of motion reconstruction.", "section": "4 Experiments"}, {"figure_path": "FisyQfoJCm/tables/tables_15_3.jpg", "caption": "Table 1: Evaluation on the HumanML3D dataset (upper half) and the KIT-ML dataset (lower half).", "description": "This table presents the quantitative results of the proposed MoGenTS model on HumanML3D and KIT-ML datasets.  The upper half shows the results for HumanML3D, while the lower half shows the results for KIT-ML.  Each row represents a different method, including the ground truth, various state-of-the-art methods, and the proposed MoGenTS model. The columns present different evaluation metrics: FID (Fr\u00e9chet Inception Distance), Top1, Top2, Top3 (R-precision at different thresholds), MM-Dist (MultiModal-Distance), and Diversity. Lower values for FID and MM-Dist and higher values for Top1, Top2, Top3 and Diversity indicate better performance.  The table demonstrates the superior performance of MoGenTS compared to other methods in terms of both motion fidelity and diversity.", "section": "4 Experiments"}]