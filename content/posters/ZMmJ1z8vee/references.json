{"references": [{"fullname_first_author": "Aditya Ramesh", "paper_title": "Zero-shot text-to-image generation", "publication_date": "2021-07-01", "reason": "This paper introduces a groundbreaking approach to text-to-image generation that does not require explicit training data for specific subjects or styles, which is highly relevant to the current research."}, {"fullname_first_author": "Robin Rombach", "paper_title": "High-resolution image synthesis with latent diffusion models", "publication_date": "2022-06-01", "reason": "This paper introduces the Stable Diffusion model, which serves as the foundation for the current research, providing a powerful and versatile tool for generating high-quality images."}, {"fullname_first_author": "Nataniel Ruiz", "paper_title": "Dreambooth: Fine tuning text-to-image diffusion models for subject-driven generation", "publication_date": "2023-06-01", "reason": "This paper introduces a method for adapting large text-to-image models to generate images of specific subjects with few-shot learning, directly inspiring the approach in the current research."}, {"fullname_first_author": "Rinon Gal", "paper_title": "An image is worth one word: Personalizing text-to-image generation using textual inversion", "publication_date": "2023-05-01", "reason": "This paper proposes textual inversion, a method for personalizing text-to-image models by embedding specific subject information into the model, directly influencing the current research's subject-driven approach."}, {"fullname_first_author": "Edward J Hu", "paper_title": "Lora: Low-rank adaptation of large language models", "publication_date": "2022-05-01", "reason": "This paper introduces a highly efficient parameter-efficient fine-tuning method for large language models, which the current research adopts for adapting text-to-image models with limited data."}]}