[{"figure_path": "oZy4a11SUg/figures/figures_1_1.jpg", "caption": "Figure 1: Comparisons of Naive, Prompt-based, SFT-based and our Assistant-based RAG frameworks.", "description": "This figure compares four different retrieval-augmented generation (RAG) frameworks.  Naive RAG uses a frozen LLM and simple retrieval. Prompt-based RAG adds pre and post retrieval prompting to improve the quality. SFT-based RAG fine-tunes a trainable LLM for RAG tasks. Finally, the proposed Assistant-based RAG uses a separate trainable assistant LLM to manage memory and knowledge, working with a frozen main LLM to improve reasoning and accuracy.", "section": "1 Introduction"}, {"figure_path": "oZy4a11SUg/figures/figures_3_1.jpg", "caption": "Figure 2: Overview of ASSISTRAG. ASSISTRAG enhances LLMs by providing an intelligent information assistant. Endowed with the ability of tool usage, action execution, memory building and plan specification, it can achieve effective memory and knowledge management.", "description": "This figure shows a flowchart of the ASSISTRAG architecture, highlighting its key components: the main LLM, the intelligent information assistant, and the tools and functionalities that support its operation.  It illustrates how the assistant manages memory and knowledge through tool usage, action execution, memory building, and plan specification to improve the LLM's reasoning and response generation.", "section": "3.2 ASSISTRAG Overview"}, {"figure_path": "oZy4a11SUg/figures/figures_4_1.jpg", "caption": "Figure 3: Training framework of ASSISTRAG. It undergoes a two-stage training pipeline through curriculum assistant learning and reinforced preference optimization.", "description": "This figure illustrates the two-stage training process for the ASSISTRAG model. The first stage, Curriculum Assistant Learning, focuses on improving the assistant's abilities in query decomposition, note-taking, and knowledge extraction through a curriculum of progressively complex tasks.  The difficulty of the tasks increases with each stage.  The second stage, Reinforced Preference Optimization, fine-tunes the assistant based on feedback from the main LLM using a Direct Preference Optimization (DPO) approach. This ensures that the assistant's output aligns well with the needs of the main LLM. The process uses sampled pair data for training the fine-tuned LLM and generates preference data used for training ASSISTRAG in the reinforced preference optimization stage. ", "section": "3.3 ASSISTRAG Training"}, {"figure_path": "oZy4a11SUg/figures/figures_8_1.jpg", "caption": "Figure 4: The relationships between inference time, cost, and F1 accuracy for different methods.", "description": "This figure compares different Retrieval-Augmented Generation (RAG) methods across three key aspects: inference time, cost (in cents), and F1 accuracy. Each method is represented by a distinct marker (CloseBook, Naive RAG, IR-CoT, Self-RAG, LLMLingua, and AssistRAG).  The plots visually demonstrate the trade-offs between these factors for each approach. AssistRAG achieves the best balance between speed, cost-effectiveness, and accuracy.", "section": "Experimental Setup"}, {"figure_path": "oZy4a11SUg/figures/figures_8_2.jpg", "caption": "Figure 3: Training framework of ASSISTRAG. It undergoes a two-stage training pipeline through curriculum assistant learning and reinforced preference optimization.", "description": "This figure shows the training framework of the ASSISTRAG model, which involves two main stages: curriculum assistant learning and reinforced preference optimization. Curriculum assistant learning is a step-wise approach that starts with simpler tasks and gradually moves to more complex ones to improve the assistant's comprehension of the RAG process. Reinforced preference optimization uses reinforcement learning to fine-tune the assistant's output based on feedback from the main LLM to improve alignment.  The figure illustrates the flow of data and the interaction between the different components of the training process.", "section": "3.3 ASSISTRAG Training"}]