[{"figure_path": "lvibangnAs/tables/tables_7_1.jpg", "caption": "Table 1: Unconditional generation results on QM9.", "description": "This table presents the results of unconditional molecular generation experiments using the QM9 dataset.  Several metrics are used to evaluate the performance of different models, including Validity (percentage of chemically valid molecules), Uniqueness (percentage of unique molecules), FCD (Fr\u00e9chet ChemNet Distance, measuring similarity to the test set), NSPDK (Neighborhood Subgraph Pairwise Distance Kernel, another similarity metric), and Novelty (percentage of novel molecules).  The results show how well each model generates molecules that are both chemically valid and structurally diverse, and how similar those molecules are to the molecules in the test set.", "section": "6 Experiments"}, {"figure_path": "lvibangnAs/tables/tables_7_2.jpg", "caption": "Table 2: Conditional generation results on QM9 (MAE \u2193)", "description": "This table presents the Mean Absolute Error (MAE) results for the conditional generation task on the QM9 dataset.  The MAE is a measure of the average absolute difference between the predicted and true values of six molecular properties: dipole moment (\u00b5), polarizability (\u03b1), highest occupied molecular orbital energy (\u03b5HOMO), lowest unoccupied molecular orbital energy (\u03b5LUMO), energy gap between HOMO and LUMO (\u0394\u03b5), and heat capacity (cv). The table compares the performance of the proposed Latent Graph Diffusion (LGD) model against existing models (w [Xu et al., 2023], Random, Natom, EDM, GeoLDM). Lower MAE values indicate better performance.", "section": "6.1 Generation task"}, {"figure_path": "lvibangnAs/tables/tables_8_1.jpg", "caption": "Table 3: Zinc12K results (MAE \u2193). Shown is the mean \u00b1 std of 5 runs.", "description": "This table presents the Mean Absolute Error (MAE) results for predicting constrained solubility on the ZINC12k dataset.  The MAE is a measure of regression performance, with lower values indicating better accuracy. The table compares the performance of LGD (using both DDIM and DDPM sampling methods) against several established graph-based regression models (GIN, PNA, GSN, DeepLRP, OSAN, KP-GIN+, GNN-AK+, CIN, GPS). The results show that LGD-DDPM achieves state-of-the-art performance on this task.", "section": "6.2 Prediction with conditional generative models"}, {"figure_path": "lvibangnAs/tables/tables_9_1.jpg", "caption": "Table 4: Node-level classification tasks (accuracy \u2191) on datasets from Amazon, Coauthor and OGBN-Arxiv. Reported are mean \u00b1 std over 10 runs with different random seeds. Highlighted are best results.", "description": "This table presents the results of node-level classification experiments conducted on three datasets: Amazon (Photo), Coauthor (Physics), and OGBN-Arxiv.  Multiple models, including GCN, GAT, GraphSAINT, GRAND+, Graphormer, SAN, GraphGPS, Exphormer, and NAGphormer, were compared against the proposed LGD model. The accuracy is reported as the mean \u00b1 standard deviation over ten runs, with different random seeds used for each run.  The best performance for each dataset is highlighted.", "section": "6 Experiments"}, {"figure_path": "lvibangnAs/tables/tables_22_1.jpg", "caption": "Table 5: Overview of the datasets used in the paper.", "description": "This table presents the datasets used in the paper's experiments.  For each dataset, it lists the number of graphs, the average number of nodes and edges per graph, the prediction level (node, edge, or graph), the prediction task (regression, binary classification, or multi-class classification), and the evaluation metric used (Mean Absolute Error, AUROC, or accuracy).  The datasets cover various graph sizes and types of prediction tasks, demonstrating the breadth of applicability of the proposed Latent Graph Diffusion model.", "section": "6 Experiments"}, {"figure_path": "lvibangnAs/tables/tables_23_1.jpg", "caption": "Table 6: Large-scale generation on MOSES [Polykovskiy et al., 2020] dataset.", "description": "This table presents the results of large-scale molecule generation experiments on the MOSES dataset.  It compares the performance of LGD against several other models, including VAE, JT-VAE, GraphINVENT, ConGress, and DiGress.  The metrics used to evaluate the models include Validity (percentage of valid molecules generated), Uniqueness (percentage of unique molecules), Novelty (percentage of novel molecules not found in the training dataset), and Frechet ChemNet Distance (FCD, a measure of similarity between the generated and real molecules). The table highlights LGD's effectiveness at one-shot generation of high-quality and novel molecules.", "section": "6.1 Generation task"}, {"figure_path": "lvibangnAs/tables/tables_23_2.jpg", "caption": "Table 7: QM9 regression results (MAE \u2193). Highlighted are first, second best results.", "description": "This table presents the Mean Absolute Error (MAE) for six different molecular properties predicted using various regression models on the QM9 dataset.  The models compared include MPNN, DTNN, DeepLRP, PPGN, Nested GNN, 4-IDMPNN, and the authors' proposed LGD model.  Lower MAE values indicate better performance.  The best and second-best results for each property are highlighted.", "section": "6.2 Prediction with conditional generative models"}, {"figure_path": "lvibangnAs/tables/tables_23_3.jpg", "caption": "Table 8: Ogbg-molhiv results (AUC \u2191). Shown is the mean \u00b1 std of 5 runs.", "description": "This table presents the Area Under the Curve (AUC) results for the ogbg-molhiv dataset, a graph-level classification task predicting HIV inhibition.  It compares the performance of LGD-DDPM against several baseline methods, showing the mean and standard deviation of AUC scores across 5 runs. The results demonstrate the performance of LGD in comparison to existing methods on this task.", "section": "6.2 Prediction with conditional generative models"}, {"figure_path": "lvibangnAs/tables/tables_24_1.jpg", "caption": "Table 9: Node-level and edge-level classification tasks (accuracy \u2191) on two datasets from Planetoid. Reported are mean \u00b1 std over 10 runs with different random seeds. Highlighted are best results.", "description": "This table presents the results of node and edge classification experiments conducted on two datasets from the Planetoid benchmark: Cora and PubMed.  The table compares the performance of LGD against several baseline methods (GCN, GAT, OFA, and variants of ACM-GCN) across two task types (link prediction and node classification) for each dataset.  The accuracy (with standard deviation) is reported for each model and task. The best results for each setting are highlighted.", "section": "6.2 Prediction with conditional generative models"}, {"figure_path": "lvibangnAs/tables/tables_25_1.jpg", "caption": "Table 10: Ablation study on latent dimension on Zinc (MAE \u2193). Shown is the mean \u00b1 std of 3 runs.", "description": "This table presents the results of an ablation study conducted to determine the optimal latent dimension for the Latent Graph Diffusion (LGD) model on the Zinc dataset.  The study varied the latent dimension (4, 8, and 16) and measured the Mean Absolute Error (MAE) for each, reporting the mean and standard deviation across three runs for each dimension. The results help determine the best balance between model capacity and performance.", "section": "C.4 Ablation studies"}, {"figure_path": "lvibangnAs/tables/tables_26_1.jpg", "caption": "Table 1: Unconditional generation results on QM9.", "description": "This table presents the results of unconditional molecular generation experiments using the QM9 dataset.  Several metrics evaluate the generated molecules, including validity (percentage of chemically valid molecules), uniqueness (percentage of unique molecules), Frechet ChemNet Distance (FCD), Neighborhood Subgraph Pairwise Distance Kernel (NSPDK), and novelty (percentage of novel molecules not found in the training set).  The table compares LGD's performance against several state-of-the-art baselines.", "section": "6 Experiments"}]