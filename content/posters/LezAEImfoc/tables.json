[{"figure_path": "LezAEImfoc/tables/tables_7_1.jpg", "caption": "Table 1: State-of-the-art comparison on STDChallenge, VideoCube [4] and LaSOT [9]. The top three results are highlight with red, blue and green fonts, respectively.", "description": "This table compares the performance of CPDTrack against other state-of-the-art (SOTA) trackers on three different benchmarks: STDChallenge, VideoCube, and LaSOT.  The table shows the N-PRE, PRE, SUC, and Robustness scores for each tracker on each benchmark.  The top three performing trackers for each metric on each benchmark are highlighted in red, blue, and green, respectively. This allows for a comprehensive comparison of CPDTrack's performance against existing trackers across various tracking challenges.", "section": "Experiments"}, {"figure_path": "LezAEImfoc/tables/tables_8_1.jpg", "caption": "Table 2: Ablation studies of CPDTrack on STDChallenge and VideoCube. We conducted comparisons of 'central-peripheral' vision and information query.", "description": "This table presents the results of ablation studies conducted on the CPDTrack model using two benchmarks: STDChallenge and VideoCube. The goal was to evaluate the effectiveness of different components of the model, specifically the central and peripheral vision modules and the information query mechanism.  The table shows the error consistency, and the performance metrics N-PRE, PRE, and SUC across various configurations. The 'baseline' row represents the full CPDTrack model. Subsequent rows show results when either central vision, peripheral vision, or the query mechanism is removed or modified.  The final row explores using a local cropping method as an alternative to the central vision module.", "section": "5.3 Ablation and Analysis"}, {"figure_path": "LezAEImfoc/tables/tables_16_1.jpg", "caption": "Table 1: State-of-the-art comparison on STDChallenge, VideoCube [4] and LaSOT [9]. The top three results are highlight with red, blue and green fonts, respectively.", "description": "This table presents a comparison of the proposed CPDTrack model's performance against other state-of-the-art (SOTA) trackers on three different benchmarks: STDChallenge, VideoCube, and LaSOT.  The table shows the performance metrics (N-PRE, PRE, SUC, Robustness, AUC, P) for each tracker on each benchmark. The top three performing trackers are highlighted for each metric on each benchmark.", "section": "5 Experiments"}, {"figure_path": "LezAEImfoc/tables/tables_17_1.jpg", "caption": "Table 1: State-of-the-art comparison on STDChallenge, VideoCube [4] and LaSOT [9]. The top three results are highlight with red, blue and green fonts, respectively.", "description": "This table compares the performance of CPDTrack against other state-of-the-art trackers on three different benchmarks: STDChallenge, VideoCube, and LaSOT.  The metrics used for comparison are N-PRE, PRE, and SUC.  The top three performing trackers for each benchmark are highlighted in red, blue, and green, respectively, to show the relative performance of CPDTrack.", "section": "5 Experiments"}, {"figure_path": "LezAEImfoc/tables/tables_18_1.jpg", "caption": "Table 1: State-of-the-art comparison on STDChallenge, VideoCube [4] and LaSOT [9]. The top three results are highlight with red, blue and green fonts, respectively.", "description": "This table compares the performance of CPDTrack against other state-of-the-art trackers on three different benchmarks: STDChallenge, VideoCube, and LaSOT.  The metrics used for comparison include N-PRE, PRE, SUC, and AUC. The top three performing trackers for each benchmark are highlighted in red, blue, and green, respectively.  This allows for a direct comparison of CPDTrack's performance against existing methods on various challenging tracking tasks.", "section": "Experiments"}, {"figure_path": "LezAEImfoc/tables/tables_22_1.jpg", "caption": "Table 1: State-of-the-art comparison on STDChallenge, VideoCube [4] and LaSOT [9]. The top three results are highlight with red, blue and green fonts, respectively.", "description": "This table presents a comparison of the proposed CPDTrack model with other state-of-the-art (SOTA) trackers on three different benchmarks: STDChallenge, VideoCube, and LaSOT.  The table shows the performance of each tracker in terms of several metrics (N-PRE, PRE, SUC, Robustness, AUC, P).  The top three performing trackers for each metric on each benchmark are highlighted in red, blue, and green, respectively. This allows for a direct comparison of CPDTrack's performance against existing methods across various tracking challenges.", "section": "5 Experiments"}, {"figure_path": "LezAEImfoc/tables/tables_26_1.jpg", "caption": "Table 1: State-of-the-art comparison on STDChallenge, VideoCube [4] and LaSOT [9]. The top three results are highlight with red, blue and green fonts, respectively.", "description": "This table compares the performance of CPDTrack against other state-of-the-art trackers on three different benchmarks: STDChallenge, VideoCube, and LaSOT.  For each benchmark, it shows the performance metrics (N-PRE, PRE, SUC, and AUC) achieved by each tracker.  The top three performing trackers for each metric are highlighted in red, blue, and green. The table provides a quantitative comparison of CPDTrack's performance in relation to existing techniques across various tracking scenarios.", "section": "Experiments"}]