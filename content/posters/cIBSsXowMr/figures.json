[{"figure_path": "cIBSsXowMr/figures/figures_2_1.jpg", "caption": "Figure 1: Discriminability of frequency feature: (a) The Electroencephalography (EEG) signal and corresponding frequency data of two classes in the CAP dataset: Wake and Rapid Eye Movement (REM). (b) Classification on the source domain: Temporal domain vs. Frequency domain. (c) Source-only and DANN: Temporal domain vs. Frequency domain.", "description": "This figure shows the discriminative power of frequency features compared to temporal features.  Panel (a) displays EEG data and its frequency transform for two sleep stages (Wake and REM), highlighting the clearer separation in the frequency domain. Panel (b) demonstrates higher classification accuracy using frequency features on the source domain. Finally, Panel (c) compares source-only and DANN approaches in both domains on the target domain, indicating superior transferability of temporal features.", "section": "3 Transferability and Discriminability in Time Series"}, {"figure_path": "cIBSsXowMr/figures/figures_4_1.jpg", "caption": "Figure 2: The architecture of ACON. ACON models temporal data (blue) and frequency data (green) simultaneously. Left part: Segment raw frequency data by period to capture different discriminative patterns. Middle part: Align distributions in temporal-frequency correlation subspace via adversarial training. Right part: Mutual learning between the temporal domain and frequency domain.", "description": "The figure illustrates the architecture of the Adversarial CO-learning Networks (ACON) proposed in the paper. It shows how ACON processes both temporal and frequency data simultaneously to enhance transferability and discriminability. The left part details the multi-period frequency feature learning, segmenting the time series into different periods to improve the discriminative ability of frequency features. The middle part showcases the domain adversarial learning in the temporal-frequency correlation subspace, aiming to learn domain-invariant representations. Finally, the right part illustrates the temporal-frequency domain mutual learning, using knowledge distillation between the two domains to boost the performance of each. Overall, the diagram clearly depicts the collaborative learning mechanism of ACON.", "section": "4 Approach"}, {"figure_path": "cIBSsXowMr/figures/figures_8_1.jpg", "caption": "Figure 1: Discriminability of frequency feature: (a) The Electroencephalography (EEG) signal and corresponding frequency data of two classes in the CAP dataset: Wake and Rapid Eye Movement (REM). (b) Classification on the source domain: Temporal domain vs. Frequency domain. (c) Source-only and DANN: Temporal domain vs. Frequency domain.", "description": "This figure demonstrates the discriminative power of frequency features compared to temporal features in time series data. Subfigure (a) shows an EEG signal and its frequency representation for two classes (Wake and REM), highlighting the distinct frequency patterns.  Subfigure (b) presents classification accuracy on the source domain using only temporal and only frequency features, showing higher accuracy with frequency features. Subfigure (c) compares the performance of temporal and frequency features in a domain adaptation setting (using DANN), showing that frequency features' superior discriminability in the source domain does not translate to better performance in the target domain.", "section": "3 Transferability and Discriminability in Time Series"}]