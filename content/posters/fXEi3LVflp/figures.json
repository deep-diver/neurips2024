[{"figure_path": "fXEi3LVflp/figures/figures_0_1.jpg", "caption": "Figure 1: Task illustration of (a) multi-person pose estimation predicts numerous outcomes and requires selection strategies during deployment, potentially leading to false negatives or suboptimal target results, and (b) our referring human pose and mask estimation requires a unified promptable model to simultaneously predict accurate pose and mask for the person of interest, providing comprehensive and identity-aware human representations to benefit human-AI interaction.", "description": "This figure compares multi-person pose estimation with the proposed referring human pose and mask estimation (R-HPM).  (a) shows the traditional approach where a model outputs multiple pose estimations, and a selection strategy (like non-maximum suppression or NMS) is needed to choose the best result. This can lead to missed detections or incorrect selections. (b) illustrates R-HPM, a unified model that directly predicts the pose and mask of the target person specified by the user using either a text, point, or scribble prompt, eliminating the need for post-processing selection steps and leading to more accurate and comprehensive results.", "section": "Introduction"}, {"figure_path": "fXEi3LVflp/figures/figures_3_1.jpg", "caption": "Figure 2: Human-in-the-loop text prompt generation. We use GPT to generate descriptions with complementary local details and global context, then manually review/correct the descriptions.", "description": "This figure illustrates the process of generating text prompts for the RefHuman dataset using a human-in-the-loop approach with GPT.  First, GPT-4 generates a description considering the entire image (Opt1). Then, a cropped version focusing on the target person is fed to GPT-4 for a more detailed description (Opt2). These two descriptions are combined (Opt3), and finally, a human corrects and refines the generated description to ensure accuracy and comprehensiveness. This iterative process ensures high-quality and diverse text prompts for the dataset.", "section": "3.1 Data Annotation"}, {"figure_path": "fXEi3LVflp/figures/figures_4_1.jpg", "caption": "Figure 3: Detailed architecture of our UniPHD, which contains a multimodal encoder that imbues visual features with prompt awareness and a pose-centric hierarchical decoder that enables prompt-conditioned queries to effectively capture local details and global dependencies within targets. Our unified model is end-to-end and accepts text descriptions, scribbles, or points as prompts to predict the keypoint positions and segmentation mask of the target person.", "description": "This figure illustrates the architecture of the UniPHD model.  The model takes an image and a prompt (text, scribble, or point) as input. A multimodal encoder fuses visual and prompt features. A pose-centric hierarchical decoder, with global dependency modeling and local detail aggregation, uses prompt-conditioned queries to predict keypoint positions and a segmentation mask for the specified person. The decoder uses a soft adjacent matrix to model relationships between keypoints and the instance.", "section": "4 Method"}, {"figure_path": "fXEi3LVflp/figures/figures_8_1.jpg", "caption": "Figure 1: Task illustration of (a) multi-person pose estimation predicts numerous outcomes and requires selection strategies during deployment, potentially leading to false negatives or suboptimal target results, and (b) our referring human pose and mask estimation requires a unified promptable model to simultaneously predict accurate pose and mask for the person of interest, providing comprehensive and identity-aware human representations to benefit human-AI interaction.", "description": "This figure contrasts multi-person pose estimation with the proposed Referring Human Pose and Mask Estimation (R-HPM) task.  (a) shows the limitations of traditional multi-person pose estimation, highlighting the need for post-processing steps (like Non-Maximum Suppression) to select the correct pose from multiple predictions.  (b) illustrates the R-HPM approach, which uses a single model and a textual or positional prompt to directly identify and extract both pose and mask for the specified person, removing the need for post-processing and providing a more complete representation.", "section": "1 Introduction"}, {"figure_path": "fXEi3LVflp/figures/figures_16_1.jpg", "caption": "Figure 5: Qualitative results of our UniPHD with different prompts in various challenging scenarios.", "description": "This figure shows several qualitative results of the UniPHD model on various challenging scenarios, showcasing its ability to accurately predict human pose and mask using different types of prompts (text, point, scribble).  The results demonstrate that the model can effectively handle challenging situations like crowded scenes, occlusions, and variations in lighting conditions.", "section": "Additional Visualizations"}]