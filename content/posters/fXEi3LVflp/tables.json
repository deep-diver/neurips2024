[{"figure_path": "fXEi3LVflp/tables/tables_4_1.jpg", "caption": "Table 1: Data statistics of human-related images in RefCOCO [30], RefCOCO+ [30], RefCOCOg [50], their combined dataset RefCOCO/+/g, and our RefHuman.", "description": "This table presents a comparison of the statistics of human-related images across several datasets, including RefCOCO, RefCOCO+, RefCOCOg, the combined RefCOCO/+/g dataset, and the new RefHuman dataset introduced in this paper.  For each dataset, it shows the number of images, instances (individual humans), and expressions (text, scribble, or point annotations). The table highlights that RefHuman is significantly larger than the existing datasets, offering a much more extensive resource for research on human pose and mask estimation.", "section": "3 RefHuman Dataset"}, {"figure_path": "fXEi3LVflp/tables/tables_7_1.jpg", "caption": "Table 2: Results on RefHuman val split. Uni-ED-Pose and Uni-GroupPose integrate ED-Pose [87] and GroupPose [44] into our end-to-end paradigm. Intersection-based result selection: selects results covering at least 30% of the ground truth box. \u2020: trains models using complete images in COCO train2017. FPS is measured on RTX 3090 with a batch size of 24. Uni-ED-Pose and Uni-GroupPose are trained with less data but rival the performance of vanilla models, which perform post-processing with ground truth boxes. Our UniPHD approach achieves top-tier performance.", "description": "This table presents the results of the proposed UniPHD method and two other methods (Uni-ED-Pose and Uni-GroupPose) on the RefHuman validation set.  It compares performance metrics for pose estimation and segmentation using different prompts (text, point, and scribble) while highlighting the advantages of the proposed end-to-end approach over two-stage methods.  Key metrics include Average Precision (AP), Percentage of Correct Keypoints (PCKh@0.5), Intersection over Union (IoU), and Frames Per Second (FPS).  The table also notes the model parameters and the impact of using different backbone networks (Swin-T and Swin-L).", "section": "5.1 Main Results"}, {"figure_path": "fXEi3LVflp/tables/tables_7_2.jpg", "caption": "Table 3: Comparison with state-of-the-art methods on MS COCO val2017. Our method achieves leading performance in pose estimation while also offering segmentation capabilities.", "description": "This table compares the performance of the proposed UniPHD model with other state-of-the-art methods on the MS COCO val2017 dataset.  The metrics used are Average Precision (AP) for pose estimation and segmentation, along with AP50, AP75, APM, and APL which represent different IoU thresholds for evaluating pose estimation performance. The table shows that UniPHD achieves leading performance in pose estimation while also providing strong results in segmentation.", "section": "5.1 Main Results"}, {"figure_path": "fXEi3LVflp/tables/tables_8_1.jpg", "caption": "Table 4: Comparison with state-of-the-art text-based segmentation methods on RefHuman.", "description": "This table compares the performance of the proposed UniPHD model with other state-of-the-art text-based segmentation methods on the RefHuman dataset.  The comparison is based on the IoU metric, using Swin-T as the backbone for all models.  The table shows that the proposed UniPHD model outperforms other methods, achieving the highest IoU score of 76.3.", "section": "5.2 Ablation Study"}, {"figure_path": "fXEi3LVflp/tables/tables_8_2.jpg", "caption": "Table 6: Ablation of multi-task learning.", "description": "This table presents the ablation study results on the performance of multi-task learning in the proposed UniPHD model. It shows the performance (in terms of Pose AP and Mask AP) when either the pose head or the mask head is removed, and compares it to the full model. The results demonstrate the effectiveness of multi-task learning in improving the overall performance of both pose and mask estimation.", "section": "5.2 Ablation Study"}, {"figure_path": "fXEi3LVflp/tables/tables_8_3.jpg", "caption": "Table 5: Ablation of result selection strategies for GroupPose [44] with Swin-T.", "description": "This table presents an ablation study on the result selection strategies used in the GroupPose model with the Swin-T backbone. The study aims to determine the effectiveness of different strategies for selecting the most appropriate prediction results. The strategies compared include using no selection strategy, L1 loss, IoU, and intersection-over-union (IoU) with different thresholds. The results are evaluated in terms of Average Precision (AP), AP for medium-sized objects (APM), and AP for large-sized objects (APL). The table shows that using the intersection-based strategy with a threshold of 0.3 achieves the best performance across all three metrics.", "section": "5.2 Ablation Study"}, {"figure_path": "fXEi3LVflp/tables/tables_8_4.jpg", "caption": "Table 7: Ablation of global dependency modeling.", "description": "This table presents the ablation study results for the global dependency modeling component of the UniPHD model.  It shows the performance (Pose AP and Mask AP) of the model using different methods for global dependency modeling, including without global dependency, self-attention only and the proposed pose-centric hierarchical decoder.  The results are shown separately for text and scribble prompts. The purpose is to demonstrate the importance of the pose-centric hierarchical decoder in capturing global relationships between keypoints and instance queries. ", "section": "5.2 Ablation Study"}, {"figure_path": "fXEi3LVflp/tables/tables_9_1.jpg", "caption": "Table 8: Ablation of query initialization.", "description": "This ablation study analyzes the impact of removing the prompt-conditioned query initialization step in the UniPHD model. It compares the performance with and without query initialization, using both text and scribble prompts, evaluating the pose and mask prediction results (AP). The results show that while the model is robust enough to perform without initialization, including this step improves performance.", "section": "5.2 Ablation Study"}, {"figure_path": "fXEi3LVflp/tables/tables_9_2.jpg", "caption": "Table 9: Training UniPHD with extra data.", "description": "This table presents the performance of the UniPHD model trained with extra data, specifically using point and scribble prompts.  The results show the performance metrics (AP, PCKh@0.5, oIoU) for pose estimation and segmentation, demonstrating significant performance improvements achieved by incorporating more data into the training process.", "section": "5.1 Main Results"}, {"figure_path": "fXEi3LVflp/tables/tables_15_1.jpg", "caption": "Table 10: Ablation of different number of query groups.", "description": "This table shows the ablation study of different numbers of query groups used in the UniPHD model. The results are evaluated using the AP metric for both pose and mask, with text and scribble prompts.  The table demonstrates that increasing the number of query groups improves the performance in both pose and mask prediction.", "section": "A.3 Different Query Group Numbers"}, {"figure_path": "fXEi3LVflp/tables/tables_15_2.jpg", "caption": "Table 11: Ablation of increasing model capacity.", "description": "This table presents the ablation study of increasing the model capacity by adding more layers to the multimodal encoder and increasing the feature dimensions. The baseline model is compared to models with more layers and higher dimensions. The results show that the current model settings are already quite effective, as adding more layers or higher dimensions does not significantly improve the performance.", "section": "A.4 Increasing Model Capacity"}]