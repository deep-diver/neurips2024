[{"figure_path": "wBtmN8SZ2B/tables/tables_5_1.jpg", "caption": "Table 1: Evaluation of hierarchical information distortion and classification accuracy using SupCon [39] as Flat. All metrics are reported as mean (standard deviation) over 3 seeds.", "description": "This table presents a comparison of different methods for learning hierarchical representations.  It shows the distortion of the learned hierarchy (measured by Gromov's hyperbolicity and CPCC), and the resulting classification accuracy on fine-grained and coarse-grained classes for three benchmark datasets (CIFAR10, CIFAR100, and ImageNet100). The methods compared are a flat baseline (Flat), a Euclidean-based tree regularization method (l2-CPCC), and the proposed hyperbolic-based method (HypStructure).  The results demonstrate that HypStructure achieves the lowest distortion and highest accuracy in most cases.", "section": "4.1 Quality of Hierarchical Information"}, {"figure_path": "wBtmN8SZ2B/tables/tables_6_1.jpg", "caption": "Table 1: Evaluation of hierarchical information distortion and classification accuracy using SupCon [39] as Flat. All metrics are reported as mean (standard deviation) over 3 seeds.", "description": "This table presents a comparison of different methods for incorporating hierarchical information into representation learning.  It evaluates the methods based on two key metrics: the distortion of the hierarchical information, measured by the Gromov's hyperbolicity (drel) and the Cophenetic Correlation Coefficient (CPCC), and the classification accuracy on both fine-grained and coarse-grained classes. Lower drel values indicate better preservation of the hierarchical structure, while higher CPCC values indicate a stronger correspondence between the tree metric and the learned feature distances. The table shows that HypStructure significantly reduces distortion and improves classification accuracy compared to baseline methods (Flat and l2-CPCC).", "section": "Quality of Hierarchical Information"}, {"figure_path": "wBtmN8SZ2B/tables/tables_7_1.jpg", "caption": "Table 2: OOD detection AUROC with CIFAR10 and ImageNet100 as ID.", "description": "This table presents the Area Under the Receiver Operating Characteristic curve (AUROC) for Out-of-Distribution (OOD) detection.  It compares the performance of several methods (SSD+, KNN+, l2-CPCC, and HypStructure) on CIFAR10 and ImageNet100 datasets, using each dataset as the in-distribution (ID) dataset for evaluating OOD detection capabilities.", "section": "4.3 OOD Detection"}, {"figure_path": "wBtmN8SZ2B/tables/tables_25_1.jpg", "caption": "Table 1: Evaluation of hierarchical information distortion and classification accuracy using SupCon [39] as Flat. All metrics are reported as mean (standard deviation) over 3 seeds.", "description": "This table presents a quantitative evaluation of three different methods for learning hierarchical image representations: Flat, l2-CPCC, and HypStructure.  For each method, it shows the distortion of the hierarchy (measured by Gromov's hyperbolicity and Cophenetic Correlation Coefficient), and the classification accuracy on fine-grained and coarse-grained classes of CIFAR10, CIFAR100, and ImageNet100 datasets. The results demonstrate that HypStructure effectively reduces hierarchical distortion and improves classification accuracy compared to the baseline methods.", "section": "4.1 Quality of Hierarchical Information"}, {"figure_path": "wBtmN8SZ2B/tables/tables_26_1.jpg", "caption": "Table 1: Evaluation of hierarchical information distortion and classification accuracy using SupCon [39] as Flat. All metrics are reported as mean (standard deviation) over 3 seeds.", "description": "This table presents a comparison of different methods for learning hierarchical representations.  It evaluates the distortion of the learned hierarchical information compared to the ground truth hierarchy using several metrics (drel, CPCC) and the classification accuracy on both fine-grained and coarse-grained classes using the SupCon loss function.  The results are averaged across three different random seeds to provide a measure of reliability and the standard deviation is included to show the variation in the results.", "section": "4.1 Quality of Hierarchical Information"}, {"figure_path": "wBtmN8SZ2B/tables/tables_27_1.jpg", "caption": "Table 5: Ablation study on the components of HypStructure. We report the Classification accuracies based on the CIFAR100 model trained with ResNet-34.", "description": "This table presents the ablation study on the components of the HypStructure model.  It shows the impact of including internal nodes in the label tree, using hyperbolic class centroids, and applying a hyperbolic centering loss on the CIFAR100 dataset.  The results, measured in terms of fine and coarse classification accuracy, demonstrate the relative contribution of each component to the overall performance of the model.", "section": "4.1 Quality of Hierarchical Information"}, {"figure_path": "wBtmN8SZ2B/tables/tables_27_2.jpg", "caption": "Table 1: Evaluation of hierarchical information distortion and classification accuracy using SupCon [39] as Flat. All metrics are reported as mean (standard deviation) over 3 seeds.", "description": "This table presents the results of evaluating the impact of different methods on hierarchical information distortion and classification accuracy.  It compares three methods: Flat, l2-CPCC, and HypStructure. The metrics used include Gromov's hyperbolicity (drel), cophenetic correlation coefficient (CPCC), and classification accuracy (for both fine and coarse classes). Lower drel values indicate higher tree-likeness of learned representations. Higher CPCC values indicate better correspondence between tree metrics and dataset distances. The results show that HypStructure effectively reduces distortion and improves classification accuracy.", "section": "4.1 Quality of Hierarchical Information"}, {"figure_path": "wBtmN8SZ2B/tables/tables_28_1.jpg", "caption": "Table 7: Results on ImageNet100. OOD detection performance for ResNet-34 trained on ImageNet100. Training with HypStructure achieves strong OOD detection performance.", "description": "This table presents the Area Under the Receiver Operating Characteristic curve (AUROC) for out-of-distribution (OOD) detection on the ImageNet100 dataset using several different methods.  The results show the AUROC for each of five OOD datasets (SUN, Places365, Textures, iNaturalist) and the average AUROC across all five datasets. HypStructure shows a strong performance improvement compared to the baseline methods, indicating its effectiveness in OOD detection.", "section": "4.3 OOD Detection"}, {"figure_path": "wBtmN8SZ2B/tables/tables_29_1.jpg", "caption": "Table 1: Evaluation of hierarchical information distortion and classification accuracy using SupCon [39] as Flat. All metrics are reported as mean (standard deviation) over 3 seeds.", "description": "This table presents a quantitative comparison of different methods for incorporating hierarchical information into image representations.  It evaluates three methods: Flat (no hierarchy), l2-CPCC (Euclidean tree-based regularization), and HypStructure (hyperbolic tree-based regularization).  The evaluation metrics include Gromov's hyperbolicity (drel), which measures the tree-likeness of the learned representations, Cophenetic Correlation Coefficient (CPCC), which assesses the correspondence between the tree metric and the learned representation distances, and classification accuracy on both fine and coarse-grained class labels.  Lower drel values indicate a better tree-like structure, higher CPCC implies better alignment with the hierarchical structure, and higher accuracy shows better classification performance.", "section": "4.1 Quality of Hierarchical Information"}, {"figure_path": "wBtmN8SZ2B/tables/tables_30_1.jpg", "caption": "Table 1: Evaluation of hierarchical information distortion and classification accuracy using SupCon [39] as Flat. All metrics are reported as mean (standard deviation) over 3 seeds.", "description": "This table presents the results of evaluating the impact of different methods on hierarchical information distortion and classification accuracy.  Three methods are compared: Flat, l2-CPCC, and HypStructure.  The evaluation metrics include Gromov's hyperbolicity (drel), cophenetic correlation coefficient (CPCC), and classification accuracy (on both fine and coarse levels).  The results show HypStructure outperforms the other methods across different metrics and datasets.", "section": "4.1 Quality of Hierarchical Information"}, {"figure_path": "wBtmN8SZ2B/tables/tables_31_1.jpg", "caption": "Table 1: Evaluation of hierarchical information distortion and classification accuracy using SupCon [39] as Flat. All metrics are reported as mean (standard deviation) over 3 seeds.", "description": "This table presents a comparison of the performance of different methods on three datasets (CIFAR10, CIFAR100, and ImageNet100) in terms of their ability to preserve hierarchical information and their classification accuracy.  The methods compared are Flat (baseline), l2-CPCC, and HypStructure (the proposed method).  For each method and dataset, the table shows the Gromov's hyperbolicity (drel), the Cophenetic Correlation Coefficient (CPCC), and the fine and coarse classification accuracy. Lower drel values indicate better preservation of hierarchical information, higher CPCC values indicate better correspondence between the tree metric and the learned representation distances, and higher accuracy values indicate better performance.", "section": "4.1 Quality of Hierarchical Information"}, {"figure_path": "wBtmN8SZ2B/tables/tables_31_2.jpg", "caption": "Table 1: Evaluation of hierarchical information distortion and classification accuracy using SupCon [39] as Flat. All metrics are reported as mean (standard deviation) over 3 seeds.", "description": "This table presents a quantitative evaluation of the impact of different methods on hierarchical information preservation and classification accuracy. It compares three methods: Flat, l2-CPCC, and HypStructure, across three datasets (CIFAR10, CIFAR100, and ImageNet100).  For each method and dataset, the table shows several metrics: Gromov's hyperbolicity (drel), Cophenetic Correlation Coefficient (CPCC), and classification accuracy on fine-grained and coarse-grained classes. Lower drel values and higher CPCC values indicate better preservation of the hierarchical structure in the learned representations.  The accuracy scores reflect the performance of a classifier trained on the learned representations.", "section": "4.1 Quality of Hierarchical Information"}, {"figure_path": "wBtmN8SZ2B/tables/tables_31_3.jpg", "caption": "Table 1: Evaluation of hierarchical information distortion and classification accuracy using SupCon [39] as Flat. All metrics are reported as mean (standard deviation) over 3 seeds.", "description": "This table presents a comparison of different methods for learning hierarchical image representations.  It evaluates the methods based on three key metrics: Gromov's hyperbolicity (drel), which measures the tree-likeness of the learned features; Cophenetic Correlation Coefficient (CPCC), which quantifies the correspondence between the tree structure in the label space and the learned feature space; and classification accuracy on both fine-grained and coarse-grained class levels. The results demonstrate the effectiveness of the proposed HypStructure method in reducing distortion of hierarchical information and improving classification accuracy, especially compared to flat methods and previous approaches.", "section": "4.1 Quality of Hierarchical Information"}, {"figure_path": "wBtmN8SZ2B/tables/tables_32_1.jpg", "caption": "Table 7: Results on ImageNet100. OOD detection performance for ResNet-34 trained on ImageNet100. Training with HypStructure achieves strong OOD detection performance.", "description": "This table shows the Area Under the Receiver Operating Characteristic curve (AUROC) for out-of-distribution (OOD) detection on the ImageNet100 dataset using different methods.  The ResNet-34 model was trained on ImageNet100, and the AUROC scores are reported for four OOD datasets: SUN, Places365, Textures, and iNaturalist. The table compares the performance of HypStructure against several baselines, demonstrating that incorporating hierarchical structure in the representation space leads to improved OOD detection.", "section": "4.3 OOD Detection"}, {"figure_path": "wBtmN8SZ2B/tables/tables_32_2.jpg", "caption": "Table 1: Evaluation of hierarchical information distortion and classification accuracy using SupCon [39] as Flat. All metrics are reported as mean (standard deviation) over 3 seeds.", "description": "This table presents the results of evaluating the impact of different methods on hierarchical information preservation and classification accuracy.  Three datasets (CIFAR10, CIFAR100, and ImageNet100) are used with ResNet-18 or ResNet-34 backbones. The metrics include Gromov's hyperbolicity (drel), Cophenetic Correlation Coefficient (CPCC), and fine and coarse classification accuracy. Lower drel values indicate better preservation of the hierarchical structure. Higher CPCC values suggest stronger correspondence between the tree-based metric and the learned representations. The table compares the performance of the flat baseline, the l2-CPCC method, and the proposed HypStructure method, demonstrating HypStructure's improved performance in both metrics and classification.", "section": "4.1 Quality of Hierarchical Information"}, {"figure_path": "wBtmN8SZ2B/tables/tables_32_3.jpg", "caption": "Table 1: Evaluation of hierarchical information distortion and classification accuracy using SupCon [39] as Flat. All metrics are reported as mean (standard deviation) over 3 seeds.", "description": "This table presents a comparison of different methods for learning structured representations, specifically focusing on their impact on hierarchical information distortion and classification accuracy.  The methods compared are Flat (baseline), l2-CPCC (a Euclidean-space structured regularization method), and HypStructure (the proposed hyperbolic-space method).  The table shows the Gromov's hyperbolicity (drel), cophenetic correlation coefficient (CPCC), and fine/coarse classification accuracy for three datasets: CIFAR10, CIFAR100, and ImageNet100. Lower drel values indicate better tree-likeness, higher CPCC indicates better correspondence between the tree metric and learned representations, and higher accuracy reflects better performance.", "section": "4.1 Quality of Hierarchical Information"}, {"figure_path": "wBtmN8SZ2B/tables/tables_32_4.jpg", "caption": "Table 1: Evaluation of hierarchical information distortion and classification accuracy using SupCon [39] as Flat. All metrics are reported as mean (standard deviation) over 3 seeds.", "description": "This table presents the results of evaluating three different methods for learning hierarchical representations: Flat, l2-CPCC, and HypStructure.  The evaluation metrics include Gromov's hyperbolicity (drel), Cophenetic Correlation Coefficient (CPCC), and classification accuracy on fine and coarse-grained classes. Lower drel values indicate better tree-likeness, while higher CPCC values represent better correspondence between tree metrics and learned feature distances. The results demonstrate that HypStructure effectively reduces distortion in hierarchical information and improves classification performance compared to the baseline methods.", "section": "4.1 Quality of Hierarchical Information"}]