[{"figure_path": "hw76X5uWrc/figures/figures_1_1.jpg", "caption": "Figure 1: The RHEA (Realizing Human Expertise through AI) framework. The framework consists of four components: Defining the prediction and prescription tasks, gathering the human solutions, distilling them into a canonical form, and evolving the population of solutions further. a, The predictor maps context and actions to outcomes and thus constitutes a surrogate, or a \"digital twin\", of the real world. For example, in the Pandemic Response Challenge experiment, the context consisted of data about the geographic region for which the predictions were made, e.g., historical data of COVID-19 cases and intervention policies; actions were future schedules of intervention policies for the region; and outcomes were predicted future cases of COVID-19 along with the stringency of the policy. b, Given a predictor, the prescriptor generates actions that yield optimized outcomes across contexts. c, Humans are solicited to contribute expertise by submitting prescriptors using whatever methodology they prefer, such as decision rules, epidemiological models, classical statistical techniques, and gradient-based methods. d, Each submitted prescriptor is distilled into a canonical neural network that replicates its behavior. e, This population of neural networks is evolved further, i.e., the distilled models are recombined and refined in a parallelized, iterative search process. They build synergies and extend the ideas in the original solutions, resulting in policies that perform better than the original ones. For example, in the Pandemic Response Challenge, the policies recommend interventions that lead to minimal cases with minimal stringency.", "description": "This figure illustrates the RHEA framework, which consists of four main steps: 1) defining the problem, 2) gathering solutions from human experts, 3) distilling these solutions into a canonical form (neural networks), and 4) evolving the population of solutions through a population-based search to find better solutions that build upon the original expert ideas.  The figure shows how the predictor and prescriptor function within the framework and how human expertise is incorporated and refined through AI.", "section": "1 Introduction"}, {"figure_path": "hw76X5uWrc/figures/figures_3_1.jpg", "caption": "Figure 2: An Illustration of RHEA in a Synthetic Domain. The plots show the Pareto front of prescriptors discovered by RHEA vs. those of alternative prescriptor combination methods, highlighting the kinds of opportunities RHEA is able to exploit. The specialist expert prescriptors a and b and the generalist expert prescriptor c are useful but suboptimal on their own (purple \u2022's). RHEA recombines and innovates upon their internal structure and is able to discover the full optimal Pareto front (blue *'s). This front dominates that of Mixture-of-Experts (MoE; green \u00d7's), which can only mix expert behavior independently in each context. It also dominates that of Weighted Ensembling (yellow +\u2019s), which can only choose a single combination of experts to apply everywhere. Evolution alone (without expert knowledge) also struggles in this domain due to the vast search space (App. Fig. 6), as do MORL methods (App. Fig. 7,8). Thus, RHEA unlocks the latent potential in expert solutions.", "description": "This figure illustrates the results of applying the RHEA framework to a synthetic policy-making problem.  Three expert prescriptors, each with different levels of specialization and performance, provide initial solutions. RHEA combines and refines these solutions, outperforming alternative approaches such as Mixture-of-Experts (MoE) and Weighted Ensembling. The figure highlights how RHEA discovers a superior Pareto front, showcasing its ability to leverage and synthesize diverse expert knowledge.", "section": "Illustrative Example"}, {"figure_path": "hw76X5uWrc/figures/figures_5_1.jpg", "caption": "Figure 3: Quantitative comparison of solutions. a, Objective values for all solutions in the final population of a single representative run of each method. b, Pareto curves for these runs. Distilled provides improved tradeoffs over Random and Evolved (from random), and RHEA pushes the front out beyond Distilled. c, Overall Pareto front of the union of the solutions from these runs. The vast majority of these solutions are from RHEA. d, The distribution of actual stringencies implemented in the real world across all geos at the prescription start date, indicating which Pareto solutions real-world decision makers would likely select, i.e., which tradeoffs they prefer. e, Given this distribution, the proportion of the time the solution selected by a user would be from a particular method (the REM metric); almost all of them would be from RHEA. f, The same metric, but based on a uniform distribution of tradeoff preference (RUN) g, Domination rate (DR) w.r.t. Distilled, i.e. how much of the Distilled Pareto front is strictly dominated by another method's front. While Evolved (from scratch) sometimes discovers better solutions than those distilled from expert designs, RHEA improves \u224875% of them. h, Max reduction of cases (MCR) compared to Distilled across all stringency levels. i, Dominated hypervolume improvement (HVI) compared to Distilled. For each metric, RHEA substantially outperforms the alternatives, demonstrating that it creates improved solutions over human and AI design, and that those solutions would likely be preferred by human decision-makers. (Bars show mean and st.dev. See App. C.3 for technical details of each metric.)", "description": "This figure provides a quantitative comparison of solutions generated by different methods (Random, Evolved, Distilled, and RHEA).  Panels (a-c) show the objective values, Pareto fronts, and the combined Pareto front of each method. Panel (d) displays the distribution of real-world stringency levels to illustrate which trade-offs would likely be preferred by decision-makers. Panels (e-i) present several performance metrics (REM, RUN, DR, MCR, HVI), showing that RHEA outperforms all other approaches by significantly improving existing human-designed solutions and discovering improved solutions that would likely be favored by decision-makers.", "section": "3 The XPRIZE Pandemic Response Challenge"}, {"figure_path": "hw76X5uWrc/figures/figures_6_1.jpg", "caption": "Figure 4: Dynamics of IP schedules discovered by RHEA. a, UMAP projection of geo IP schedules generated by the policies (App. C.4). The schedules from high-performing submitted expert models are concentrated around a 1-dimensional manifold organized by overall cost (seen as a yellow arc). This manifold provides a scaffolding upon which RHEA elaborates, interpolates, and expands. Evolved policies, on the other hand, are scattered more discordantly (seen as blue clusters), ungrounded by the experts. b, To characterize how RHEA expands upon this scaffolding, five high-level properties of IP schedules were identified and their distributions were plotted across the schedules. For each, RHEA finds a balance between the grounding of expert submissions (i.e., regularization) and their recombination and elaboration (i.e., innovation), though this balance manifests in distinct ways. For swing and separability, RHEA is similar to real schedules, but finds that the high separability proposed by some expert models can sometimes be useful. RHEA finds the high focus of the expert models even more attractive; in practice, they could provide policy-makers with simpler and clearer messages about how to control the pandemic. For focus, agility, and periodicity, RHEA pushes beyond areas explored by the submissions, finding solutions that humans may miss. The example schedules shown in a(i-v) illustrate these principles in practice (rows are IPs sorted from top to bottom as listed in Sec. 3; column are days in the 90-day period; darker color means more stringent). (i) Real-world examples demonstrate that although agility and periodicity require some effort to implement, they have occasionally been utilized (e.g. in Portugal and France); (ii) a simple example of how RHEA generates useful interpolations of submitted non-Pareto schedules, demonstrating how it realizes latent potential even in some low-performing solutions, far from schedules evolved from scratch; (iii) another useful interpolation, but achieved via higher agility than Pareto submissions; (iv) a high-stringency RHEA schedule that trades swing and separability for agility and periodicity compared to its submitted neighbor; and (v) a medium-stringency RHEA schedule with lower swing and separability and higher focus than its submitted neighbor. Overall, these analyses show how RHEA realizes the latent potential of the raw material provided by the human-created submissions.", "description": "This figure visualizes the dynamics of intervention policies (IPs) schedules generated by different methods, including RHEA, evolved policies, and submitted expert models.  Panel (a) shows a UMAP projection of the schedules, highlighting how RHEA expands upon the structure provided by expert submissions. Panel (b) further analyzes the characteristics of these schedules, demonstrating how RHEA finds a balance between grounding and innovation, and discovers solutions that outperform human experts alone.", "section": "4 Characterizing the Innovations"}, {"figure_path": "hw76X5uWrc/figures/figures_7_1.jpg", "caption": "Figure 5: Dynamics of evolutionary discovery process. a, Sample ancestries of prescriptors on the RHEA Pareto front. Leaf nodes are initial distilled models; the final solutions are the root. The history of recombinations leading to different solutions varies widely in terms of complexity, with apparent motifs and symmetries. The ancestries show that the search is behaving as expected, in that the cost of the child usually lands between the costs of its parents (indicated by color). This property is also visualized in b (and c), where child costs (and cases) are plotted over all recombinations from all trials (k-NN regression, k = 100). d, From ancestries, one can compute the relative contribution of each expert model to the final RHEA Pareto front (App C.5). This contribution is remarkably consistent across the independent runs, indicating that the approach is reliable (mean and st.dev. shown). e, Although there is a correlation between the performance of teams of expert models and their contribution to the final front, there are some teams with unimpressive quantitative performance in their submissions who end up making outsized contributions through the evolutionary process. This result highlights the value of soliciting a broad diversity of expertise, even if some of it does not have immediately obvious practical utility. AI can play a role in realizing this latent potential.", "description": "This figure shows the evolutionary process of discovering new solutions using RHEA. Panel (a) displays the ancestry of solutions on the Pareto front, illustrating how different combinations of initial solutions lead to better solutions. Panel (b) and (c) visualize the relationship between parent and child solutions' cost and cases, indicating a consistent pattern. Panel (d) shows the consistent contribution of expert models to the final solutions across different runs. Panel (e) highlights the correlation between initial team performance and contribution to the final solutions, emphasizing the value of diverse expertise.", "section": "4 Characterizing the Innovations"}, {"figure_path": "hw76X5uWrc/figures/figures_17_1.jpg", "caption": "Figure 6: Experimental results comparing RHEA vs. Evolution alone (i.e., without knowledge of gathered expert solutions) in the illustrative domain. Whiskers show 1.5\u00d7IQR; the middle bar is the median. a, RHEA exploits latent expert knowledge to reliably and efficiently discover the full optimal Pareto front, even as the number of available policy interventions n increases (there are 2n possible actions for each context; 100 trials each). b, Evolution alone does not reliably discover the front even with 10 available interventions, and its performance drops sharply as the number increases (100 trials each). Thus, diverse expert knowledge is key to discovering optimal policies.", "description": "This figure compares the performance of RHEA and a standard evolutionary algorithm (without expert knowledge) in a synthetic domain.  The left panel (a) shows that RHEA consistently and efficiently finds the complete optimal Pareto front, even as the problem's complexity increases (more available policy interventions).  The right panel (b) shows that the standard evolutionary algorithm struggles to find the complete optimal Pareto front, particularly as the complexity of the problem grows. The key takeaway is that diverse expert knowledge, leveraged by RHEA, is crucial for reliably discovering optimal policies.", "section": "B.4 Comparison to multi-objective reinforcement learning"}, {"figure_path": "hw76X5uWrc/figures/figures_18_1.jpg", "caption": "Figure 2: An Illustration of RHEA in a Synthetic Domain. The plots show the Pareto front of prescriptors discovered by RHEA vs. those of alternative prescriptor combination methods, highlighting the kinds of opportunities RHEA is able to exploit. The specialist expert prescriptors a and b and the generalist expert prescriptor c are useful but suboptimal on their own (purple \u2022's). RHEA recombines and innovates upon their internal structure and is able to discover the full optimal Pareto front (blue *'s). This front dominates that of Mixture-of-Experts (MoE; green \u00d7's), which can only mix expert behavior independently in each context. It also dominates that of Weighted Ensembling (yellow +'s), which can only choose a single combination of experts to apply everywhere. Evolution alone (without expert knowledge) also struggles in this domain due to the vast search space (App. Fig. 6), as do MORL methods (App. Fig. 7,8). Thus, RHEA unlocks the latent potential in expert solutions.", "description": "This figure illustrates the results of applying the RHEA framework to a synthetic problem.  It demonstrates how RHEA, by recombining and refining solutions from diverse experts (generalist and specialists), finds a superior Pareto front compared to methods like Mixture-of-Experts or Weighted Ensembling.  The results highlight RHEA's ability to discover novel and better solutions than would be found by individual experts or evolutionary algorithms alone, emphasizing the value of diverse expertise and RHEA's novel approach to combining and refining it.", "section": "Illustrative Example"}, {"figure_path": "hw76X5uWrc/figures/figures_18_2.jpg", "caption": "Figure 3: Quantitative comparison of solutions. a, Objective values for all solutions in the final population of a single representative run of each method. b, Pareto curves for these runs. Distilled provides improved tradeoffs over Random and Evolved (from random), and RHEA pushes the front out beyond Distilled. c, Overall Pareto front of the union of the solutions from these runs. The vast majority of these solutions are from RHEA. d, The distribution of actual stringencies implemented in the real world across all geos at the prescription start date, indicating which Pareto solutions real-world decision makers would likely select, i.e., which tradeoffs they prefer. e, Given this distribution, the proportion of the time the solution selected by a user would be from a particular method (the REM metric); almost all of them would be from RHEA. f, The same metric, but based on a uniform distribution of tradeoff preference (RUN) g, Domination rate (DR) w.r.t. Distilled, i.e. how much of the Distilled Pareto front is strictly dominated by another method's front. While Evolved (from scratch) sometimes discovers better solutions than those distilled from expert designs, RHEA improves \u224875% of them. h, Max reduction of cases (MCR) compared to Distilled across all stringency levels. i, Dominated hypervolume improvement (HVI) compared to Distilled. For each metric, RHEA substantially outperforms the alternatives, demonstrating that it creates improved solutions over human and AI design, and that those solutions would likely be preferred by human decision-makers. (Bars show mean and st.dev. See App. C.3 for technical details of each metric.)", "description": "This figure quantitatively compares the performance of four different methods: Random, Evolved, Distilled, and RHEA. It shows that RHEA significantly outperforms other methods in terms of Pareto optimality and preference by decision-makers, highlighting its ability to improve upon both human-designed and AI-only solutions.", "section": "3 The XPRIZE Pandemic Response Challenge"}]