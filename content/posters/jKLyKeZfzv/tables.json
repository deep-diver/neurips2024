[{"figure_path": "jKLyKeZfzv/tables/tables_8_1.jpg", "caption": "Table 1: Comparison of the proposed MOTE-NAS and others on NASBench-201. Note that \u2018Cost (s)\u2019 indicates the cost in seconds calculated on Tesla V100. Entries in bold with underlines indicate the best performance, and those in bold alone represent the second-best performance.", "description": "This table compares the performance of MOTE-NAS with other state-of-the-art Neural Architecture Search (NAS) methods on the NASBench-201 benchmark.  It shows the accuracy achieved on CIFAR-10, CIFAR-100, and ImageNet-16 datasets, along with the computational cost (in seconds) on a Tesla V100 GPU.  The table highlights the superior performance of MOTE-NAS, particularly its efficiency in achieving high accuracy at a lower computational cost compared to other methods.", "section": "4.3 Comparisons of MOTE-NAS and Other NAS"}, {"figure_path": "jKLyKeZfzv/tables/tables_9_1.jpg", "caption": "Table 2: This table shows the top-1 accuracy of architectures found on ImageNet using MOTE-NAS and other NAS methods.", "description": "This table compares the top-1 accuracy achieved on the ImageNet dataset by different Neural Architecture Search (NAS) methods.  It includes several well-known models (MobileNetV2, MobileNetV3, OFA, BN-NAS, NASNet-B, CARS-D, ZICO) and two versions of the proposed MOTE-NAS approach. The table also indicates the number of Million FLOPS (MFLOPS) required by each model and the cost in days (Cost(d)) to train.", "section": "4.4 MOTE-NAS on ImageNet-1K"}, {"figure_path": "jKLyKeZfzv/tables/tables_13_1.jpg", "caption": "Table A1: Kendall\u2019s \u03c4 correlation between the MOTE scoring output and the test accuracy(after 200 epochs). Experiments are performed to compare four versions of MOTE on three sub-datasets (CIFAR-10, CIFAR-100, ImgNet-16) of the NASBench-201.", "description": "This table presents the Kendall\u2019s Tau correlation, a measure of rank correlation, between the MOTE scores and the actual test accuracy on three image classification datasets (CIFAR-10, CIFAR-100, and ImageNet-16) from NASBench-201.  The MOTE scores are generated using four different transformations (no transformation, logarithm, reciprocal, and box-cox) applied to the MOTE values. The table shows how different transformations of the MOTE values affect the correlation with the actual accuracy rankings.", "section": "A.1 Non-linear Transformation for MOTE"}, {"figure_path": "jKLyKeZfzv/tables/tables_14_1.jpg", "caption": "Table 1: Comparison of the proposed MOTE-NAS and others on NASBench-201. Note that \u2018Cost (s)\u2019 indicates the cost in seconds calculated on Tesla V100. Entries in bold with underlines indicate the best performance, and those in bold alone represent the second-best performance.", "description": "This table compares the performance of MOTE-NAS against other state-of-the-art neural architecture search (NAS) methods on the NASBench-201 benchmark.  It shows the accuracy achieved by each method on CIFAR-10, CIFAR-100, and ImageNet-16, as well as the computational cost in seconds on a Tesla V100 GPU.  The best and second-best performance is indicated.", "section": "4.3 Comparisons of MOTE-NAS and Other NAS"}, {"figure_path": "jKLyKeZfzv/tables/tables_14_2.jpg", "caption": "Table 1: Comparison of the proposed MOTE-NAS and others on NASBench-201. Note that \u2018Cost (s)\u2019 indicates the cost in seconds calculated on Tesla V100. Entries in bold with underlines indicate the best performance, and those in bold alone represent the second-best performance.", "description": "This table compares the performance of MOTE-NAS with other state-of-the-art Neural Architecture Search (NAS) methods on the NASBench-201 benchmark.  It shows the accuracy achieved on CIFAR-10, CIFAR-100, and ImageNet-16 datasets, along with the computational cost (in seconds) required for each method.  The best and second-best performances are highlighted.", "section": "4.3 Comparisons of MOTE-NAS and Other NAS"}, {"figure_path": "jKLyKeZfzv/tables/tables_16_1.jpg", "caption": "Table 1: Comparison of the proposed MOTE-NAS and others on NASBench-201. Note that \u2018Cost (s)\u2019 indicates the cost in seconds calculated on Tesla V100. Entries in bold with underlines indicate the best performance, and those in bold alone represent the second-best performance.", "description": "This table compares the performance of MOTE-NAS with other state-of-the-art Neural Architecture Search (NAS) methods on the NASBench-201 benchmark.  It shows the accuracy achieved by each method on three datasets (CIFAR-10, CIFAR-100, and ImageNet-16), along with the computational cost (in seconds) required to obtain those results.  The best and second-best results for each dataset are highlighted.", "section": "4.3 Comparisons of MOTE-NAS and Other NAS"}]