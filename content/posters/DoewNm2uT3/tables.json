[{"figure_path": "DoewNm2uT3/tables/tables_8_1.jpg", "caption": "Table 1: Computational results on generated RTSP instances.", "description": "This table presents the computational results of various methods on randomly generated RTSP instances. It compares the performance of exact methods (BC, BD), heuristic methods (SA-based, iDS, EGA), and the proposed neural combinatorial optimization method (ours) across different problem scales (R-20-10, R-30-10, R-40-10, R-50-10, R-20-100, R-30-100, R-40-100, R-50-100, R-20-1000, R-30-1000, R-40-1000, R-50-1000).  For each method and problem instance, the table reports the objective value (Obj), the optimality gap (Gap), and the solving time (Time). The proposed method is tested with different levels of instance augmentation (no augmentation, augmentation with 8 instances, and augmentation with 128 instances).", "section": "5.2 Results and Discussions"}, {"figure_path": "DoewNm2uT3/tables/tables_9_1.jpg", "caption": "Table 2: Results of different encoding methods for the uncertainty sets' upper and lower bounds on R-40-100.", "description": "This table presents the results of three different encoding methods for handling the uncertainty sets' upper and lower bounds in the Robust Traveling Salesman Problem (RTSP). The three methods are: 'ours', 'blended', and 'fusion'.  The table compares the average objective value ('Obj') and the gap ('Gap') between the obtained objective value and the optimal value for each encoding method, considering three augmentation levels: no augmentation, augmentation with 8 instances, and augmentation with 128 instances. The results show the effectiveness of the proposed 'ours' method compared to the 'blended' and 'fusion' methods.", "section": "5.2 Results and Discussions"}, {"figure_path": "DoewNm2uT3/tables/tables_9_2.jpg", "caption": "Table 1: Computational results on generated RTSP instances.", "description": "This table presents the results of the proposed neural combinatorial optimization method and other existing methods for solving the Robust Traveling Salesman Problem (RTSP) with different problem sizes (number of nodes).  The results include the average objective value obtained by each method, the relative gap between the obtained solution and the best-known optimal value (Gap), and the average solving time per instance (Time). The methods are categorized into three groups: exact methods, heuristic methods, and the proposed method.  Different augmentation strategies (no augmentation, augmentation with 8 instances, and augmentation with 128 instances) are also compared for the proposed method. This table demonstrates the computational efficiency and accuracy of the proposed method compared to existing methods.", "section": "5.2 Results and Discussions"}, {"figure_path": "DoewNm2uT3/tables/tables_16_1.jpg", "caption": "Table 4: Performance on varying M-threshold problems among instances of N = 20, with \u00d78 instance augmentation.", "description": "This table presents the results of an experiment evaluating the generalization ability of the trained model on RTSP problems with varying threshold values (M).  Three models were trained using different training threshold values (M=10, M=100, M=1000). The performance of each trained model is then tested on instances with different test threshold values (M=10, M=100, M=1000). The table shows the average objective values obtained for each combination of training and testing threshold values. This experiment aims to assess how well the model generalizes to unseen threshold values, thereby demonstrating its robustness and ability to handle different problem characteristics.", "section": "5.2 Results and Discussions"}, {"figure_path": "DoewNm2uT3/tables/tables_16_2.jpg", "caption": "Table 5: Results of various built-in TSP solving algorithms on R-20-100. The training time refers to the average training time per epoch.", "description": "This table compares the performance of three different built-in TSP solving algorithms (ours, CMA-ES, and LKH) on the R-20-100 problem instances.  The comparison is done across three augmentation levels (no augmentation, \u00d78 augmentation, and \u00d7128 augmentation), with each showing the objective value (Obj), optimality gap (Gap), and training time per epoch.  The results highlight the effectiveness of the proposed method ('ours') in terms of both solution quality and training efficiency.", "section": "5.2 Results and Discussions"}, {"figure_path": "DoewNm2uT3/tables/tables_18_1.jpg", "caption": "Table 6: Comparison result of different \u0393 on N = 20.", "description": "This table presents a comparison of the results obtained using different values of \u0393 (gamma), a parameter that controls the robustness of the budget uncertainty set, for the RTSP problem with 20 nodes.  The table compares the objective values ('Obj') and computation times ('Time(s)') for three different values of \u0393:  \u0393 = floor(N/2), \u0393 = floor(N/4), and \u0393 = 0.  These results highlight the impact of \u0393 on the solution quality and computational efficiency. The 'ours*128' and 'ours*8' rows refer to the proposed approach with different levels of instance augmentation.", "section": "5.2 Results and Discussions"}]