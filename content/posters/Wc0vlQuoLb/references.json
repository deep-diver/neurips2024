{"references": [{"fullname_first_author": "Tom Brown", "paper_title": "Language models are few-shot learners", "publication_date": "2020-12-01", "reason": "This paper is foundational in establishing the capabilities of large language models for few-shot learning, a technique highly relevant to the current research on mitigating hallucinations."}, {"fullname_first_author": "Fabio Petroni", "paper_title": "Language models as knowledge bases?", "publication_date": "2019-09-01", "reason": "This paper introduces the concept of using language models as knowledge bases, a key idea underlying the approach to reduce hallucination presented in this work."}, {"fullname_first_author": "Adam Roberts", "paper_title": "How much knowledge can you pack into the parameters of a language model?", "publication_date": "2020-02-28", "reason": "This work explores the capacity of language models to encode real-world knowledge, providing context for the challenge of factual inaccuracies."}, {"fullname_first_author": "Chuan Guo", "paper_title": "On calibration of modern neural networks", "publication_date": "2017-08-01", "reason": "This paper is highly influential in the field of model calibration, a technique directly related to the goal of improving factual accuracy by quantifying model uncertainty."}, {"fullname_first_author": "Lukas Aichberger", "paper_title": "Semantically diverse language generation for uncertainty estimation in language models", "publication_date": "2024-06-15", "reason": "This recent work directly addresses the problem of uncertainty quantification in language models, providing a relevant comparison to the proposed [IDK] token method."}]}