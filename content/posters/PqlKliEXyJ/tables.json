[{"figure_path": "PqlKliEXyJ/tables/tables_2_1.jpg", "caption": "Table 1: Differenet types of maps for visual localization.", "description": "This table compares different types of maps used for visual localization, including SfM, Mesh, Satellite images, OpenStreetMap, and the LoD model used in the proposed method.  For each map type, it lists what is explicitly represented (e.g., 3D points, textured meshes, pixels), whether explicit 3D geometry is present, the presence of visual appearance (texture or intensity information), the degrees of freedom (DoF) that can be estimated for camera pose, the storage size per square kilometer, and the size reduction factor compared to SfM-based maps.  The LoD model is highlighted as the method proposed in this paper, emphasizing its advantages of 3D geometry, reduced storage requirements, and the ability to estimate a full 6-DoF camera pose.", "section": "Related Works"}, {"figure_path": "PqlKliEXyJ/tables/tables_5_1.jpg", "caption": "Table 2: Quantitative comparison results over the UAVD4L-LoD dataset.", "description": "This table presents a quantitative comparison of the proposed LoD-Loc method against several baselines on the UAVD4L-LoD dataset.  The baselines represent various combinations of feature extractors and matchers, categorized by the type of map used (mesh model or LoD model).  The table shows the recall rate (percentage of correctly localized poses) at different thresholds of position and orientation error (2m-2\u00b0, 3m-3\u00b0, and 5m-5\u00b0). Separate results are given for \"in-trajectory\" and \"out-of-trajectory\" queries, indicating the robustness of the method across different flight patterns.", "section": "4 Experiment"}, {"figure_path": "PqlKliEXyJ/tables/tables_7_1.jpg", "caption": "Table 2: Quantitative comparison results over the UAVD4L-LoD dataset.", "description": "This table presents a quantitative comparison of different visual localization methods on the UAVD4L-LoD dataset.  It compares the performance of various methods, including those using textured mesh models (UAVD4L) and LoD models (CadLoc), against the proposed LoD-Loc method. The comparison is based on recall rates at different accuracy thresholds (2m-2\u00b0, 3m-3\u00b0, and 5m-5\u00b0), distinguishing between 'in-trajectory' and 'out-of-trajectory' query images.  The results show the effectiveness of the LoD-Loc approach, particularly when compared to methods that rely on more complex 3D models.", "section": "4 Experiment"}, {"figure_path": "PqlKliEXyJ/tables/tables_8_1.jpg", "caption": "Table 2: Quantitative comparison results over the UAVD4L-LoD dataset.", "description": "This table presents a quantitative comparison of different visual localization methods on the UAVD4L-LoD dataset.  It compares the performance of various methods, including baselines using different feature extractors and matchers (SIFT, SPP+SPG, LOFTR, e-LOFTR, RoMA), and the proposed LoD-Loc method with several ablative variations. The comparison is done using metrics such as recall at different thresholds (2m-2\u00b0, 3m-3\u00b0, 5m-5\u00b0), for both in-trajectory and out-of-trajectory queries. This allows for a comprehensive evaluation of the proposed LoD-Loc's performance relative to state-of-the-art methods.", "section": "4 Experiment"}, {"figure_path": "PqlKliEXyJ/tables/tables_8_2.jpg", "caption": "Table 2: Quantitative comparison results over the UAVD4L-LoD dataset.", "description": "This table presents a quantitative comparison of different visual localization methods on the UAVD4L-LoD dataset.  It shows the recall rate at different accuracy thresholds (2m-2\u00b0, 3m-3\u00b0, and 5m-5\u00b0) for both in-trajectory and out-of-trajectory queries.  The methods compared include various baselines using different feature extractors and matchers, as well as the proposed LoD-Loc method with different configurations (full model, no neural wireframe estimation, no uncertainty sampling range estimation, and no pose refinement). The results demonstrate the superior performance of the proposed LoD-Loc method, especially in out-of-trajectory scenarios.", "section": "4 Experiment"}, {"figure_path": "PqlKliEXyJ/tables/tables_14_1.jpg", "caption": "Table 1: Differenet types of maps for visual localization.", "description": "This table compares different types of maps used for visual localization, including SfM, Mesh, Satellite, OpenStreetMap, and LoD models.  For each map type, it lists what the map represents (e.g., 3D points, textured meshes, pixels), whether it has explicit 3D geometry, the visual appearance (texture), the degrees of freedom (DoF) for pose estimation, the storage size per square kilometer, and the size reduction compared to Structure from Motion (SfM).  The table highlights the advantages of LoD models in terms of size, ease of acquisition and maintenance, and privacy.", "section": "2 Related Works"}, {"figure_path": "PqlKliEXyJ/tables/tables_21_1.jpg", "caption": "Table 1: Differenet types of maps for visual localization.", "description": "This table compares different types of maps used for visual localization, including SfM, Mesh, Satellite, OpenStreetMap, and LoD models.  The comparison covers aspects such as the type of 3D representation used (points, meshes, pixels, polygons, wireframes), whether explicit geometry is present, visual appearance (texture), the degrees of freedom in pose estimation, and the storage size per square kilometer.  The LoD model is highlighted as the method proposed in the paper, emphasizing its smaller size and suitability for aerial localization.", "section": "Related Works"}, {"figure_path": "PqlKliEXyJ/tables/tables_21_2.jpg", "caption": "Table 2: Quantitative comparison results over the UAVD4L-LoD dataset.", "description": "This table presents a quantitative comparison of different visual localization methods on the UAVD4L-LoD dataset.  It compares the performance of various methods (using different map types and feature extraction techniques) across different recall thresholds (2m-2\u00b0, 3m-3\u00b0, and 5m-5\u00b0), evaluating both in-trajectory and out-of-trajectory localization accuracy. The methods are categorized by the type of map used (mesh model or LoD model). The table highlights the superior performance of the proposed LoD-Loc method, especially when compared to other approaches using LoD maps.", "section": "4 Experiment"}, {"figure_path": "PqlKliEXyJ/tables/tables_22_1.jpg", "caption": "Table 2: Quantitative comparison results over the UAVD4L-LoD dataset.", "description": "This table presents a quantitative comparison of different visual localization methods on the UAVD4L-LoD dataset.  It compares the performance of several baselines (using various feature extractors and matchers) against the proposed LoD-Loc method.  The results are broken down by different recall thresholds (2m-2\u00b0, 3m-3\u00b0, 5m-5\u00b0) for both in-trajectory and out-of-trajectory query images. This allows for a comprehensive evaluation of accuracy and robustness under various conditions.", "section": "4 Experiment"}, {"figure_path": "PqlKliEXyJ/tables/tables_22_2.jpg", "caption": "Table 9: Ablation study on different pose sampling numbers for LoD-Loc.", "description": "This table presents the results of an ablation study conducted on the LoD-Loc model.  The study varied the number of pose samples used during the pose selection stage.  The results are presented for two categories: in-trajectory (in-Traj.) and out-of-trajectory (out-of-Traj.).  For each sampling scheme, the table reports the recall at different thresholds (2m-2\u00b0, 3m-3\u00b0, and 5m-5\u00b0), as well as the median translation error (T.e.) and rotation error (R.e.). The results show how the accuracy changes as the sampling density changes.", "section": "4 Experiment"}, {"figure_path": "PqlKliEXyJ/tables/tables_23_1.jpg", "caption": "Table 10: Ablation study on different wireframe sampling density. x-m means sampling per-x meter on each wireframes.", "description": "This ablation study analyzes the impact of different wireframe sampling densities on the localization performance of the LoD-Loc method.  It examines three densities: 4 meters per wireframe, 2 meters per wireframe, and 1 meter per wireframe, assessing their effects on the recall rate at different thresholds (2m-2\u00b0, 3m-3\u00b0, 5m-5\u00b0) and median translation/rotation errors. The results help determine the optimal sampling density for balancing accuracy and computational efficiency.", "section": "4.3 Ablation Studies"}, {"figure_path": "PqlKliEXyJ/tables/tables_23_2.jpg", "caption": "Table 4: Ablation study on different stages. T.e./R.e. means translation/rotation error.", "description": "This table presents the results of an ablation study conducted to evaluate the impact of different stages in the proposed LoD-Loc method on localization performance.  The study varies the number of levels in the multi-scale feature extraction process, and whether the pose refinement step is included.  Results are reported as recall percentages at different error thresholds (2m-2\u00b0, 3m-3\u00b0, 5m-5\u00b0) and as median translation and rotation errors.", "section": "4 Experiment"}, {"figure_path": "PqlKliEXyJ/tables/tables_24_1.jpg", "caption": "Table 2: Quantitative comparison results over the UAVD4L-LoD dataset.", "description": "This table presents a quantitative comparison of different visual localization methods on the UAVD4L-LoD dataset.  The methods are categorized into three groups: sensor priors (methods using only sensor data), UAVD4L (methods using a textured mesh model), and CadLoc (methods using a LoD model).  The performance of each method is evaluated using three metrics (2m-2\u00b0, 3m-3\u00b0, 5m-5\u00b0), representing the recall rate at different pose error thresholds.  The table shows the performance of the proposed LoD-Loc method, as well as ablation studies (removing the neural wireframe estimation, uncertainty sampling range, or refinement step) to demonstrate the contributions of each component.", "section": "4 Experiment"}, {"figure_path": "PqlKliEXyJ/tables/tables_24_2.jpg", "caption": "Table 2: Quantitative comparison results over the UAVD4L-LoD dataset.", "description": "This table presents a quantitative comparison of different methods for visual localization on the UAVD4L-LoD dataset. It compares the performance of various methods, including baselines using different types of maps (mesh model and LoD model) and feature extractors, against the proposed LoD-Loc method.  The performance is evaluated using three metrics (2m-2\u00b0, 3m-3\u00b0, and 5m-5\u00b0), representing the recall rate at different accuracy thresholds for pose estimation. The table is split into two parts: 'in-Traj.' and 'out-of-Traj.', indicating results for sequences captured during trajectory-based flights and free-flight scenarios respectively. It showcases the superior performance of LoD-Loc compared to state-of-the-art methods, particularly in challenging 'out-of-Traj' scenarios.", "section": "4 Experiment"}, {"figure_path": "PqlKliEXyJ/tables/tables_24_3.jpg", "caption": "Table 1: Differenet types of maps for visual localization.", "description": "This table compares different types of maps used for visual localization, highlighting their characteristics such as the type of 3D representation (points, meshes, images, polygons, lines, wireframes), explicit geometry, visual appearance, degrees of freedom (DoF) for pose estimation, storage size per square kilometer, and size reduction compared to Structure from Motion (SfM) maps.  It shows that LoD models offer a good balance between accuracy and efficiency.", "section": "2 Related Works"}]