[{"figure_path": "vjAORqq71s/tables/tables_4_1.jpg", "caption": "Table 1: Ranking supervision with differentiable sorting. The metric is the percentage of rankings correctly identified (and individual element ranks correctly identified, in parentheses) avg. over 10 seeds. Statistically significant improvements (sig. level 0.05) are indicated bold black; improved means are indicated in bold grey.", "description": "This table presents the results of ranking supervision experiments using four different differentiable sorting algorithms (NeuralSort, SoftSort, Logistic DSN, and Cauchy DSN).  For each algorithm, the baseline performance and performance with two variants of Newton Losses (Hessian-based and Fisher-based) are shown for datasets with 5 and 10 elements to be ranked. The metric is the percentage of rankings correctly identified, with the percentage of correctly ranked individual elements shown in parentheses. Statistically significant improvements are highlighted in bold black, while improvements that are not statistically significant are shown in bold gray.", "section": "4.1 Ranking Supervision"}, {"figure_path": "vjAORqq71s/tables/tables_6_1.jpg", "caption": "Table 1: Ranking supervision with differentiable sorting. The metric is the percentage of rankings correctly identified (and individual element ranks correctly identified, in parentheses) avg. over 10 seeds. Statistically significant improvements (sig. level 0.05) are indicated bold black; improved means are indicated in bold grey.", "description": "This table presents the results of ranking supervision experiments using four different differentiable sorting algorithms: NeuralSort, SoftSort, Logistic DSN, and Cauchy DSN.  The table compares the baseline performance of each algorithm with the performance achieved using Hessian-based and Fisher-based Newton Losses. The metric used is the percentage of rankings correctly identified, averaged over 10 random seeds, with the percentage of correctly identified individual element ranks provided in parentheses.  Statistically significant improvements are highlighted in bold black, while improvements that are not statistically significant are highlighted in bold gray.", "section": "4.1 Ranking Supervision"}, {"figure_path": "vjAORqq71s/tables/tables_7_1.jpg", "caption": "Table 2: Shortest-path benchmark results for different variants of the AlgoVision-relaxed Bellman-Ford algorithm [24]. The metric is the percentage of perfect matches averaged over 10 seeds. Significant improvements are bold black, and improved means are bold grey.", "description": "This table presents the results of applying Newton Losses (specifically the Fisher variant) to four variations of the Relaxed Bellman-Ford algorithm on the Warcraft shortest-path benchmark.  Each variation differs in loop structure (For or While loop) and loss function (L1 or L2). The metric used is the percentage of perfectly predicted shortest paths, averaged across 10 random seeds.  The table shows that Newton Losses consistently improves the performance, particularly notable in the 'For+L2' variant, showing significant improvement.", "section": "4.2 Shortest-Path Supervision"}, {"figure_path": "vjAORqq71s/tables/tables_8_1.jpg", "caption": "Table 3: Shortest-path benchmark results for the stochastic smoothing of the loss (including the algorithm), stochastic smoothing of the algorithm (excluding the loss), and perturbed optimizers with the Fenchel-Young loss. The metric is the percentage of perfect matches averaged over 10 seeds. Significant improvements are bold black, and improved means are bold grey.", "description": "This table presents the results of three different shortest-path algorithms on the Warcraft benchmark.  The algorithms are Stochastic Smoothing of the Loss, Stochastic Smoothing of the Algorithm, and Perturbed Optimizers with Fenchel-Young Losses. Each algorithm is tested with 3, 10, and 30 samples.  The table shows the baseline performance and the performance improvement achieved by using Hessian-based and Fisher-based Newton Losses.  The metric used is the percentage of perfectly matched shortest paths.", "section": "4.2 Shortest-Path Supervision"}, {"figure_path": "vjAORqq71s/tables/tables_16_1.jpg", "caption": "Table 1: Ranking supervision with differentiable sorting. The metric is the percentage of rankings correctly identified (and individual element ranks correctly identified, in parentheses) avg. over 10 seeds. Statistically significant improvements (sig. level 0.05) are indicated bold black; improved means are indicated in bold grey.", "description": "This table presents the results of ranking supervision experiments using various differentiable sorting algorithms.  The key metric is the percentage of rankings correctly identified, averaged over 10 different random seeds.  The table compares baseline performance against the performance achieved using Hessian-based and Fisher-based Newton Losses.  Statistically significant improvements are highlighted in bold black, while improvements that aren't statistically significant are shown in bold grey.  Results are shown for both n=5 and n=10 (number of items to be ranked).", "section": "4.1 Ranking Supervision"}, {"figure_path": "vjAORqq71s/tables/tables_16_2.jpg", "caption": "Table 3: Shortest-path benchmark results for the stochastic smoothing of the loss (including the algorithm), stochastic smoothing of the algorithm (excluding the loss), and perturbed optimizers with the Fenchel-Young loss. The metric is the percentage of perfect matches averaged over 10 seeds. Significant improvements are bold black, and improved means are bold grey.", "description": "This table presents the results of three different shortest-path algorithms on the Warcraft shortest-path benchmark.  The algorithms are: Stochastic Smoothing of the loss, Stochastic Smoothing of the algorithm, and Perturbed Optimizers with Fenchel-Young losses. Each algorithm is tested with three different numbers of samples (3, 10, and 30). The table shows the percentage of perfect matches achieved by each algorithm and the statistical significance of the improvements compared to the baseline.", "section": "4.2 Shortest-Path Supervision"}, {"figure_path": "vjAORqq71s/tables/tables_17_1.jpg", "caption": "Table 1: Ranking supervision with differentiable sorting. The metric is the percentage of rankings correctly identified (and individual element ranks correctly identified, in parentheses) avg. over 10 seeds. Statistically significant improvements (sig. level 0.05) are indicated bold black; improved means are indicated in bold grey.", "description": "This table presents the results of ranking supervision experiments using various differentiable sorting algorithms.  The main metric is the percentage of rankings correctly identified, averaged over ten different random seeds for each algorithm and its variations (with and without Newton Losses).  The table also shows the percentage of individual element ranks correctly identified.  Significant improvements (p<0.05) achieved by using Newton Losses are highlighted in bold black, while improvements that are not statistically significant are shown in bold gray.  The algorithms compared are NeuralSort, SoftSort, Logistic DSN, and Cauchy DSN, each with baseline performance and Hessian and Fisher-based Newton Loss variations.", "section": "4.1 Ranking Supervision"}, {"figure_path": "vjAORqq71s/tables/tables_17_2.jpg", "caption": "Table 2: Shortest-path benchmark results for different variants of the AlgoVision-relaxed Bellman-Ford algorithm [24]. The metric is the percentage of perfect matches averaged over 10 seeds. Significant improvements are bold black, and improved means are bold grey.", "description": "This table presents the results of applying Newton Losses to four variants of the AlgoVision-relaxed Bellman-Ford algorithm for shortest-path prediction.  The performance metric is the percentage of perfect matches, averaged across 10 different random seeds.  The table shows baseline performance and the improvement achieved using the empirical Fisher-based Newton Loss.", "section": "4.2 Shortest-Path Supervision"}, {"figure_path": "vjAORqq71s/tables/tables_17_3.jpg", "caption": "Table 3: Shortest-path benchmark results for the stochastic smoothing of the loss (including the algorithm), stochastic smoothing of the algorithm (excluding the loss), and perturbed optimizers with the Fenchel-Young loss. The metric is the percentage of perfect matches averaged over 10 seeds. Significant improvements are bold black, and improved means are bold grey.", "description": "This table presents the results of applying Newton Losses to three different shortest-path algorithms: Stochastic Smoothing (of the loss and of the algorithm), and Perturbed Optimizers with Fenchel-Young Losses.  The performance metric is the percentage of perfectly matched shortest paths, averaged across 10 different random seeds. The number of samples used in the stochastic methods is varied (3, 10, and 30).  Significant performance improvements are highlighted in bold black, while general improvements are highlighted in bold gray.", "section": "4.2 Shortest-Path Supervision"}, {"figure_path": "vjAORqq71s/tables/tables_19_1.jpg", "caption": "Table 1: Ranking supervision with differentiable sorting. The metric is the percentage of rankings correctly identified (and individual element ranks correctly identified, in parentheses) avg. over 10 seeds. Statistically significant improvements (sig. level 0.05) are indicated bold black; improved means are indicated in bold grey.", "description": "This table presents the results of ranking supervision experiments using various differentiable sorting algorithms.  The main metric is the percentage of rankings correctly identified, averaged over 10 random seeds.  It compares baseline performance with that achieved using Hessian and Fisher variants of Newton Losses. Statistically significant improvements are highlighted.", "section": "4.1 Ranking Supervision"}]