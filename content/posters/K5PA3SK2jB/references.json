{"references": [{"fullname_first_author": "Ben Mildenhall", "paper_title": "Nerf: Representing scenes as neural radiance fields for view synthesis", "publication_date": "2020-08-23", "reason": "This is the foundational paper introducing Neural Radiance Fields (NeRFs), the core technology that ProvNeRF builds upon and improves."}, {"fullname_first_author": "Jonathan T. Barron", "paper_title": "Mip-NeRF: A multiscale representation for anti-aliasing neural radiance fields", "publication_date": "2021-10-27", "reason": "This paper addresses the anti-aliasing issue of NeRFs, a significant improvement upon the original NeRF that is relevant to ProvNeRF's focus on enhancing NeRF quality."}, {"fullname_first_author": "Ricardo Martin-Brualla", "paper_title": "Nerf in the wild: Neural radiance fields for unconstrained photo collections", "publication_date": "2021-06-15", "reason": "This work tackles the challenge of applying NeRFs to unconstrained real-world scenarios, which is directly relevant to the context of ProvNeRF's application to sparse, unconstrained view settings."}, {"fullname_first_author": "Ke Li", "paper_title": "Implicit maximum likelihood estimation", "publication_date": "2018-01-01", "reason": "ProvNeRF extends the IMLE method to functional space for modeling the stochastic field; hence this is a core methodological foundation of the ProvNeRF work."}, {"fullname_first_author": "Mikaela Angelina Uy", "paper_title": "SCADE: Nerfs from space carving with ambiguity-aware depth estimates", "publication_date": "2023-06-15", "reason": "This paper provides a strong baseline for novel view synthesis that ProvNeRF improves upon, making it a key comparative reference."}]}