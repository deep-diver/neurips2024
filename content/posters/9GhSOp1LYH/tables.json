[{"figure_path": "9GhSOp1LYH/tables/tables_6_1.jpg", "caption": "Table 1: Results on Camouflaged Object Detection (COD) under different settings. Best are in bold.", "description": "This table presents the performance comparison of various methods on three camouflaged object detection datasets (CHAMELEON, CAMO, and COD10K) under three different settings: scribble supervision, point supervision, and task-generic prompt supervision.  The metrics used for evaluation include Mean Absolute Error (M), adaptive F-measure (FB), mean E-measure (E), and structure measure (Sa). The best results for each metric under each setting are shown in bold.", "section": "4 Experimental Setup"}, {"figure_path": "9GhSOp1LYH/tables/tables_6_2.jpg", "caption": "Table 2: Results for Medical Image Segmentation (MIS) under task-generic prompt setting.", "description": "This table presents the performance comparison of different methods on two medical image segmentation subtasks: polyp image segmentation and skin lesion segmentation.  The comparison is done using a task-generic prompt setting, meaning that only a general description of the task is provided, not instance-specific annotations.  The metrics used include Mean Absolute Error (M), adaptive F-measure (FB), mean E-measure (E4), and Structure measure (Sa). Lower M or higher values for FB, E, and Sa indicate better performance.", "section": "4 Experimental Setup"}, {"figure_path": "9GhSOp1LYH/tables/tables_6_3.jpg", "caption": "Table 3: Result on Transparent Object Segmentation and Open-Vocabulary Segmentation Tasks.", "description": "This table presents the results of the proposed ProMaC method and several baseline methods on two different tasks: transparent object segmentation and open vocabulary segmentation.  For transparent object segmentation, the table shows the performance (measured by M\u2193, F\u2191, E\u2191, Sa\u2191) of different methods on two datasets, GSD and Trans10K-hard. For open vocabulary segmentation, the table shows the performance (measured by mIoU) of different methods on the VOC dataset, using different image-text pairs for training.  This helps to demonstrate the versatility and effectiveness of ProMaC in various segmentation scenarios.", "section": "4 Experimental Setup"}, {"figure_path": "9GhSOp1LYH/tables/tables_7_1.jpg", "caption": "Table 4: Ablation Study on COD and MIS Tasks", "description": "This table presents the ablation study results conducted on the Camouflaged Object Detection (COD) and Medical Image Segmentation (MIS) tasks.  It shows the impact of removing different components of the ProMaC framework (Multi-scale Chain of Thought Prompting, Instance-specific Text Prompts, Instance-specific Visual Prompts, Visual Contrastive Reasoning, Mask Semantic Alignment) on the overall performance, measured by metrics M\u2193, FB\u2191, Ep\u2191, and Sa\u2191. The results demonstrate the contribution of each component to the final performance, highlighting the importance of a holistic approach.", "section": "4 Experimental Setup"}, {"figure_path": "9GhSOp1LYH/tables/tables_7_2.jpg", "caption": "Table 5: VCR Result on SR task", "description": "This table presents the results of the Visual Contrastive Reasoning (VCR) method on the Spatial Reasoning (SR) task. It compares the performance of different models (CLIP ViT-L-14, CLIP RN50x64, FLAVA, ViP-LLAVA-13B, LLaVA-1.5-13B) with and without the VCR method.  The metrics used are Indiv. Pairs, Set of 4.  The results show that adding VCR improves the performance across all models.", "section": "4 Experimental Setup"}, {"figure_path": "9GhSOp1LYH/tables/tables_7_3.jpg", "caption": "Table 1: Results on Camouflaged Object Detection (COD) under different settings. Best are in bold.", "description": "This table presents the results of the Camouflaged Object Detection (COD) task using different methods and supervision levels (scribble, point, and task-generic prompts).  The performance is evaluated based on four metrics: M (Mean Absolute Error), FB (F-measure), Ep (E-measure), and Sa (Structure-measure).  Lower M and higher values for FB, Ep, and Sa indicate better performance.  The table highlights the best-performing method for each setting in bold, allowing for comparison across various approaches and supervision types.", "section": "4 Experimental Setup"}, {"figure_path": "9GhSOp1LYH/tables/tables_16_1.jpg", "caption": "Table 1: Results on Camouflaged Object Detection (COD) under different settings. Best are in bold.", "description": "This table presents the performance comparison of ProMaC against other state-of-the-art methods on three benchmark datasets for camouflaged object detection (COD): CHAMELEON, CAMO, and COD10K.  The results are broken down by three different prompt supervision settings: scribble supervision, point supervision, and task-generic prompt supervision.  Metrics used for evaluation include Mean Absolute Error (M), adaptive F-measure (FB), mean E-measure (E), and structure measure (Sa).  The best results for each metric and dataset are highlighted in bold.", "section": "4 Experimental Setup"}, {"figure_path": "9GhSOp1LYH/tables/tables_17_1.jpg", "caption": "Table 1: Results on Camouflaged Object Detection (COD) under different settings. Best are in bold.", "description": "This table presents the results of the Camouflaged Object Detection (COD) task using different methods and supervision levels. The methods are compared on three metrics: mean absolute error (M), adaptive F-measure (FB), E-measure (E), and structure measure (Sa). Three different supervision settings are considered: scribble supervision, point supervision, and task-generic prompt setting. The best results for each setting are highlighted in bold. This table demonstrates the effectiveness of the proposed method (ProMaC) in the challenging task-generic prompt setting where only a single task description is provided.", "section": "4 Experimental Setup"}, {"figure_path": "9GhSOp1LYH/tables/tables_17_2.jpg", "caption": "Table 8: Comparison with present SOTA MLLM approaches.", "description": "This table compares the performance of ProMaC using two different MLLMs (LLaVA and Qwen) against other state-of-the-art methods on the polyp image segmentation task using the CVC-ColonDB dataset.  The metrics used for comparison include Mean Absolute Error (M), F-measure (FB), E-measure (E\u03c6), and structure measure (Sa).  Lower M and higher values for FB, E\u03c6, and Sa indicate better performance. The results show that ProMaC achieves comparable or better performance to the other methods, despite using a simpler task-generic prompt setting. This highlights ProMaC's effectiveness in handling challenging segmentation scenarios.", "section": "4 Experimental Setup"}]