{"references": [{"fullname_first_author": "Alekh Agarwal", "paper_title": "Contextual bandit learning with predictable rewards", "publication_date": "2012-00-00", "reason": "This paper is foundational for variance-dependent regret bounds in contextual bandits, providing a starting point for the current work's refinement."}, {"fullname_first_author": "Dylan Foster", "paper_title": "Beyond UCB: Optimal and efficient contextual bandits with regression oracles", "publication_date": "2020-00-00", "reason": "This paper introduces the SquareCB algorithm, which is extended and adapted in the current work to achieve variance-dependent regret bounds."}, {"fullname_first_author": "Zhan Zhao", "paper_title": "Variance-dependent regret bounds for linear bandits and reinforcement learning: Adaptivity and computational efficiency", "publication_date": "2023-00-00", "reason": "This paper establishes near-optimal regret bounds for linear contextual bandits, which are compared and contrasted with the current work's results for general function approximation."}, {"fullname_first_author": "Ruosong Wang", "paper_title": "More benefits of being distributional: Second-order bounds for reinforcement learning", "publication_date": "2024-00-00", "reason": "This concurrent work studies variance-dependent bounds for contextual bandits with model classes, providing a complementary perspective and a benchmark for the current work."}, {"fullname_first_author": "Nicolo Cesa-Bianchi", "paper_title": "Prediction, learning, and games", "publication_date": "2006-00-00", "reason": "This book provides fundamental concepts and algorithms in online learning, including the exponential weights algorithm, which is used in the current work's online regression oracle."}]}