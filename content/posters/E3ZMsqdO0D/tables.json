[{"figure_path": "E3ZMsqdO0D/tables/tables_6_1.jpg", "caption": "Table 1: Quantitative comparisons of disparity estimation results with state-of-the-art methods from both event and image domains. The end-point-error (EPE), root mean square error (RMSE), 3-pixel error (3PE, %), and 2-pixel error (2PE, %) are adopted for evaluation. Zu, In, and Th denote the Zurich City, Interlaken, and Thun sequences on the DSEC [13] dataset, respectively. Red and orange highlights indicate the first and second best performing technique for each metric. \u2191 (\u2193) indicates that higher (lower) values are better. The method with a gray background is the only one that does not adhere to the cross-dataset evaluation protocol.", "description": "This table presents a quantitative comparison of the proposed ZEST method against several state-of-the-art approaches for disparity estimation using both event and image data.  The comparison uses four metrics: End-Point Error (EPE), Root Mean Square Error (RMSE), 3-pixel error (3PE), and 2-pixel error (2PE). Results are shown for three different sequences from the DSEC dataset (Zurich City, Interlaken, and Thun) and overall across all sequences.  The table highlights the best and second-best performing methods for each metric.", "section": "4 Experiments"}, {"figure_path": "E3ZMsqdO0D/tables/tables_7_1.jpg", "caption": "Table 2: Quantitative results of the proposed zero-shot disparity estimation method on the MVSEC [45] dataset.", "description": "This table presents a quantitative comparison of the proposed zero-shot disparity estimation method's performance on the MVSEC dataset.  It compares the method against several state-of-the-art techniques, evaluating performance metrics such as endpoint error (EPE), root mean squared error (RMSE), 3-pixel error (3PE), and 2-pixel error (2PE) across three subsets (S1, S2, S3) of the dataset.  The results highlight the method's accuracy and generalization capabilities.", "section": "4 Experiments"}, {"figure_path": "E3ZMsqdO0D/tables/tables_7_2.jpg", "caption": "Table 3: Quantitative results of the proposed zero-shot disparity estimation method on the M3ED [2] dataset.", "description": "This table presents a quantitative comparison of the proposed zero-shot disparity estimation method's performance on the M3ED dataset.  It compares the method against several state-of-the-art techniques using metrics such as end-point error (EPE), root mean square error (RMSE), 3-pixel error (3PE), and 2-pixel error (2PE). Lower values are generally better for these metrics.  The table highlights the proposed method's performance relative to other approaches on this specific dataset.", "section": "Experiments"}, {"figure_path": "E3ZMsqdO0D/tables/tables_14_1.jpg", "caption": "Table 1: Quantitative comparisons of disparity estimation results with state-of-the-art methods from both event and image domains. The end-point-error (EPE), root mean square error (RMSE), 3-pixel error (3PE, %), and 2-pixel error (2PE, %) are adopted for evaluation. Zu, In, and Th denote the Zurich City, Interlaken, and Thun sequences on the DSEC [13] dataset, respectively. Red and orange highlights indicate the first and second best performing technique for each metric. \u2191 (\u2193) indicates that higher (lower) values are better. The method with a gray background is the only one that does not adhere to the cross-dataset evaluation protocol.", "description": "This table presents a quantitative comparison of the proposed ZEST method against several state-of-the-art techniques for disparity estimation using both event and image data.  The evaluation metrics include End-Point Error (EPE), Root Mean Square Error (RMSE), 3-pixel error (3PE), and 2-pixel error (2PE). Results are shown for different datasets (Zurich City, Interlaken, and Thun sequences from the DSEC dataset).  The table highlights the superior performance of the proposed method compared to others, especially considering its zero-shot capability.", "section": "4 Experiments"}, {"figure_path": "E3ZMsqdO0D/tables/tables_14_2.jpg", "caption": "Table 1: Quantitative comparisons of disparity estimation results with state-of-the-art methods from both event and image domains. The end-point-error (EPE), root mean square error (RMSE), 3-pixel error (3PE, %), and 2-pixel error (2PE, %) are adopted for evaluation. Zu, In, and Th denote the Zurich City, Interlaken, and Thun sequences on the DSEC [13] dataset, respectively. Red and orange highlights indicate the first and second best performing technique for each metric. \u2191 (\u2193) indicates that higher (lower) values are better. The method with a gray background is the only one that does not adhere to the cross-dataset evaluation protocol.", "description": "This table compares the performance of the proposed Zero-shot Event-intensity asymmetric STereo (ZEST) method against other state-of-the-art methods for disparity estimation.  It uses four metrics (EPE, RMSE, 3PE, 2PE) to evaluate performance across three different sequences from the DSEC dataset and one combined metric across all three sequences.  The table highlights the superior performance of the ZEST method, especially compared to methods that don't use cross-dataset evaluation.", "section": "4 Experiments"}, {"figure_path": "E3ZMsqdO0D/tables/tables_14_3.jpg", "caption": "Table 7: Disparity refinement module computational cost across different iterations. EPE and 3PE performance, runtime (ms), and equivalent FPS are reported.", "description": "This table presents the computational cost of the disparity refinement module at various iteration numbers.  It shows how the End Point Error (EPE), 3-Pixel Error (3PE), runtime in milliseconds (ms), and frames per second (FPS) change as the number of iterations increases.  The final row represents the performance of the proposed Zero-shot Event-intensity asymmetric STereo (ZEST) framework after 500 iterations.", "section": "4 Experiments"}, {"figure_path": "E3ZMsqdO0D/tables/tables_14_4.jpg", "caption": "Table 5: Computational complexity breakdown per stage. Runtime (ms), GPU memory usage (MB), number of parameters (M), and equivalent FPS are reported.", "description": "This table presents a breakdown of the computational complexity for each stage of the proposed ZEST framework.  It shows the runtime in milliseconds (ms), GPU memory usage in megabytes (MB), the number of parameters in millions (M), and the equivalent frames per second (FPS) for each stage: Representation, Stereo Model (CR or DS), Monocular Depth Estimation Model (DA or MiDaS), and Refinement.  This allows for a detailed analysis of the computational cost associated with each component of the system.", "section": "4 Experiments"}]