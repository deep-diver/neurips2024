[{"figure_path": "ncqauwSyl5/figures/figures_1_1.jpg", "caption": "Figure 1: Illustration of Particle-Particle Particle-Mesh (P3M) and its relationship with our Neural P\u00b3M framework. The Atom2Atom block corresponds to the short-range term. The Atom2Mesh and Mesh2Atom block are similar to the charge assignment and back-interpolation. The Mesh2Mesh block corresponds to the long-range term.", "description": "This figure illustrates the Neural P\u00b3M framework, which enhances geometric GNNs by incorporating mesh points alongside atoms to model long-range interactions. It shows how the framework integrates short-range (Atom-Atom) and long-range (Mesh-Mesh) interactions through charge assignment (Atom-Mesh) and back-interpolation (Mesh2Atom), improving the accuracy of predicting energies and forces in molecular systems.", "section": "1 Introduction"}, {"figure_path": "ncqauwSyl5/figures/figures_4_1.jpg", "caption": "Figure 2: Overall framework architecture and details of each block. Geometric GNN models short-range interactions, Fourier neural operator (FNO) captures global long-range interactions, and continuous filter convolution (CFConv) exchanges information between two parts.", "description": "This figure shows the overall architecture of the Neural P\u00b3M framework, detailing its different components.  Panel (a) provides a high-level view of the model's structure, illustrating the flow of information from the input embeddings through multiple Neural P\u00b3M blocks to the final decoder that outputs energy and forces. Panel (b) zooms in on a single Neural P\u00b3M block, illustrating its internal workings which involve distinct modules for handling short-range (Atom2Atom) and long-range interactions (Mesh2Mesh) using techniques such as Atom2Mesh and Mesh2Atom to exchange information between atom and mesh representations, and an aggregation step to combine information from different parts of the Neural P\u00b3M block.  Panels (c), (d), and (e) illustrate the specific details of the short-range block (using geometric GNNs), the long-range block (employing a Fourier Neural Operator), and the representation assignment, respectively.  The figure clearly demonstrates the interplay between short-range and long-range interactions in the proposed framework.", "section": "3 Method"}, {"figure_path": "ncqauwSyl5/figures/figures_6_1.jpg", "caption": "Figure 3: Mean absolute errors (MAEs) for energy and force predictions on Ag dataset are compared among Allegro, ViSNet, and our proposed framework.", "description": "This figure compares the performance of three different models on the Ag dataset in terms of mean absolute error (MAE) for energy and force prediction. The three models are Allegro, ViSNet (with a cutoff of 4.0 \u00c5 and 1 layer), ViSNet (with a cutoff of 12.0 \u00c5 and 1 layer), and ViSNet integrated with the Neural P\u00b3M framework (with a cutoff of 4.0 \u00c5 and 1 layer). The results show that ViSNet with Neural P\u00b3M significantly outperforms the other models, demonstrating the effectiveness of the proposed method in capturing long-range interactions.", "section": "4.2 Toy Dataset: Ag"}, {"figure_path": "ncqauwSyl5/figures/figures_21_1.jpg", "caption": "Figure 2: Overall framework architecture and details of each block. Geometric GNN models short-range interactions, Fourier neural operator (FNO) captures global long-range interactions, and continuous filter convolution (CFConv) exchanges information between two parts.", "description": "This figure shows the architecture of the Neural P\u00b3M framework. It consists of three main blocks: an embedding block, a Neural P\u00b3M block, and a decoder block. The embedding block creates representations of atoms and meshes. The Neural P\u00b3M block updates these representations by incorporating short-range and long-range interactions, and information exchange between atoms and meshes using GNNs, FNOs, and CFConvs. The decoder block predicts energies and forces based on the updated representations.", "section": "3 Method"}]