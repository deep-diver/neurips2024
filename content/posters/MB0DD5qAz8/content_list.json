[{"type": "text", "text": "Online Classification with Predictions ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Vinod Raman ", "page_idx": 0}, {"type": "text", "text": "", "page_idx": 0}, {"type": "text", "text": "Department of Statistics University of Michigan Ann Arbor, MI 48104 vkraman@umich.edu ", "page_idx": 0}, {"type": "text", "text": "Ambuj Tewari Department of Statistics University of Michigan Ann Arbor, MI 48104 tewaria@umich.edu ", "page_idx": 0}, {"type": "text", "text": "Abstract ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "We study online classification when the learner has access to predictions about future examples. We design an online learner whose expected regret is never worse than the worst-case regret, gracefully improves with the quality of the predictions, and can be significantly better than the worst-case regret when the predictions of future examples are accurate. As a corollary, we show that if the learner is always guaranteed to observe data where future examples are easily predictable, then online learning can be as easy as transductive online learning. Our results complement recent work in online algorithms with predictions and smoothed online classification, which go beyond a worse-case analysis by using machine-learned predictions and distributional assumptions respectively. ", "page_idx": 0}, {"type": "text", "text": "1 Introduction ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "In online classification, Nature plays a game with a learner over $T\\in\\mathbb{N}$ rounds. In each round $t\\in[T]$ , Nature selects a labeled example $(x_{t},y_{t})\\in\\mathcal{X}\\times\\mathcal{Y}$ and reveals just the example $x_{t}$ to the learner. The learner, using the history of the game $(x_{1},y_{1}),...,(x_{t-1},y_{t-1})$ and the current example $x_{t}$ , makes a potentially randomized prediction $\\hat{y}_{t}\\in\\mathcal{Y}$ . Finally, Nature reveals the true label $y_{t}$ and the learner suffers the loss $\\mathbb{1}\\{\\hat{y}_{t}\\neq\\bar{y}_{t}\\}$ . Given access to a hypothesis class $\\mathcal{H}\\subseteq\\mathcal{V}^{\\mathcal{X}}$ consisting of functions $h:\\mathcal{X}\\to\\mathcal{Y}$ , the goal of the learner is to minimize its regret, the difference between its cumulative mistake and that of the best fixed hypothesis $h\\in\\mathcal H$ in hindsight. We say a class $\\mathcal{H}$ is online learnable if there exists a learning algorithm that achieves vanishing average regret for any, potentially adversarial chosen, stream of labeled examples $(x_{1},y_{1}),...,(x_{T},y_{T})$ . Canonically, one also distinguishes between the realizable and agnostic settings. In the realizable setting, Nature must choose a stream $(x_{1},y_{1}),...,(x_{T},y_{T})$ such that there exists a $h\\in\\mathcal H$ for which $h(x_{t})=y_{t}$ for all $t\\in[T]$ . On the other hand, in the agnostic setting, no such assumptions on the stream are placed. ", "page_idx": 0}, {"type": "text", "text": "Due to applications in spam flitering, image recognition, and language modeling, online classification has had a long, rich history in statistical learning theory. In a seminal work, Littlestone [1987] provided a sharp quantitative characterization of which binary hypothesis classes ${\\mathcal{H}}\\subseteq\\{0,1\\}^{\\chi}$ are online learnable in the realizable setting. This characterization was in terms of the finiteness of a combinatorial dimension called the Littlestone dimension. Twenty-two years later, Ben-David et al. [2009] proved that the Littlestone dimension continues to characterize the online learnability of binary hypothesis classes in the agnostic setting. Later, Daniely et al. [2011] generalized the Littlestone dimension to multiclass hypothesis classes $\\mathcal{H}\\subseteq\\mathcal{V}^{\\mathcal{X}}$ , and showed that it fully characterizes multiclass online learnability when the label space $\\boldsymbol{\\wp}$ is finite. More recently, Hanneke et al. [2023] extended this result to show that the multiclass Littlestone dimension continues to characterize multiclass online learnability even when $\\boldsymbol{\\wp}$ is unbounded. ", "page_idx": 0}, {"type": "text", "text": "While elegant, the characterization of online classification in terms of the Littlestone dimension is often interpreted as an impossibility result [Haghtalab, 2018]. Indeed, due to the restrictive nature of the Littlestone dimension, even simple classes like the 1-dimensional thresholds $\\mathcal{H}_{\\mathrm{thresh}}=\\{x\\mapsto$ $\\mathbb{1}\\{x\\geq a\\}:a\\in\\mathbb{N}\\}$ are not online learnable in the realizable setting. This hardness arises mainly due to a worst-case analysis: the adversary is allowed to choose any sequence of labeled examples, even possibly adapting to the learner\u2019s strategy. In many situations, however, the sequence of data is \u201ceasy\u201d and a worst-case analysis is too pessimistic. For example, if one were to use the daily temperatures to predict snowfall, it is unlikely that temperatures will vary rapidly within a given week. Even so, one might have to access to temperature forecasting models that can accurately predict future temperatures. This motivates a beyond-worst-case analysis of online classification algorithms by proving guarantees that adapt to the \u201ceasiness\u201d of the example stream. ", "page_idx": 0}, {"type": "text", "text": "", "page_idx": 1}, {"type": "text", "text": "The push for a beyond-worst-case analysis has its roots in classical algorithm design [Roughgarden, 2021]. Of recent interest is Algorithms with Predictions (AwP), a specific sub-field of beyond-worstcase analysis of algorithms [Mitzenmacher and Vassilvitskii, 2022]. Here, classical algorithms are given additional information about the problem instance in the form of machine-learned predictions. Augmented with these predictions, the algorithm\u2019s goal is to perform optimally on a per-input basis when the predictions are good (known as consistency), while always ensuring optimal worst-case guarantees (known as robustness). Ideally, algorithms are also smooth, obtaining performance guarantees that interpolate between instance and worst-case optimality as a function of prediction quality. After a successful application to learning index structures [Kraska et al., 2018], there has been an explosion of work designing algorithms whose guarantees depend on the quality of available, machine-learned predictions Mitzenmacher and Vassilvitskii [2022]. For example, machine-learned predictions have been used to achieve more efficient data-structures [Lin et al., 2022], faster runtimes [Chen et al., 2022, Ergun et al., 2021], better accuracy-space tradeoffs for streaming algorithms [Hsu et al., 2019], and improved performance bounds for online algorithms [Purohit et al., 2018]. ", "page_idx": 1}, {"type": "text", "text": "Despite this vast literature, the accuracy benefits of machine-learned predictions for online classification are, to the best of our knowledge, unknown. In this work, we bridge the gap between AwP and online classification. In contrast to previous work, which go beyond a worst-case analysis in online classification through smoothness or other distributional assumptions [Haghtalab et al., 2020, Block et al., 2022, Wu et al., 2023], we give the learner access to a Predictor, a forecasting algorithm that predicts future examples in the data stream. The learner, before predicting a label $\\hat{y}_{t}$ , can query the Predictor and receive predictions $\\hat{x}_{t+1},...,\\hat{x}_{T}$ on the future examples. The learner can then use the history of the game $(x_{1},y_{1}),...,(x_{t-1},y_{t-1})$ , the current example $x_{t}$ , and the predictions $\\hat{x}_{t+1},...,\\hat{x}_{T}$ to output a label $\\hat{y}_{t}$ . We allow Predictors to be adaptive - they can change their predictions of future examples based on the actual realizations of past examples. From this perspective, Predictors are also online learners, and we quantify the predictability of example streams through their mistake-bounds. ", "page_idx": 1}, {"type": "text", "text": "In this work, we seek to design online learning algorithms whose expected regret, given black-box access to a Predictor, degrades gracefully with the quality of the Predictor\u2019s predictions. By doing so, we are also interested in understanding how access to a Predictor may impact the characterization of online learnability. In particular, given a Predictor, when can online learnability become easier than in the standard, worst-case setup? Guided by these objectives, we make the following contributions. ", "page_idx": 1}, {"type": "text", "text": "(1) In the realizable and agnostic settings, we design online learners that, using black-box access to a Predictor, adapt to the \u201ceasiness\u201d of the example stream. When the predictions of the Predictor are good, our learner\u2019s expected mistakes/regret significantly improves upon the worst-case guarantee. When the Predictor\u2019s predictions are bad, the expected mistakes/regret of our learner matches the optimal worst-case expected mistake-bound/regret. Finally, our learner\u2019s expected mistake-bound/regret degrades gracefully with the quality of the Predictor\u2019s predictions. ", "page_idx": 1}, {"type": "text", "text": "(2) We show that having black-box access to a good Predictor can make learning much easier than the standard, worst-case setting. More precisely, good Predictors allow \u201coffline\u201d learnable classes to become online learnable. In this paper, we take the \u201coffline\u201d setting to be transductive online learning [Ben-David et al., 1997, Hanneke et al., 2024] where Nature reveals the entire sequence of examples $x_{1},...,x_{T}$ (but not the labels $y_{1},...,y_{T})$ to the learner before the game begins. Many \u201coffline\u201d learnable classes are not online learnable. For example, when ${\\mathcal{D}}=\\{0,1\\}$ , transductive online learnability is characterized by the finiteness of the VC dimension, the same dimension that characterizes PAC learnability. Thus, our result is analogous to that in smoothed online classification, where PAC learnability is also sufficient for online learnability [Haghtalab et al., 2020, Block et al., 2022]. ", "page_idx": 1}, {"type": "text", "text": "A notable property of our realizable and agnostic online learners is their use of black-box access to a transductive online learner to make predictions. In this sense, our proof strategies involve reducing online classification with predictions to transductive online learning. For both contributions (1) and (2), we consider only the realizable setting in the main text. The results and arguments for the agnostic setting are nearly identical and thus deferred to Appendix F. ", "page_idx": 2}, {"type": "text", "text": "1.1 Related Works ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "Online Algorithms with Predictions. Online Algorithms with Predictions (OAwP) has emerged as an important paradigm lying at the intersection of classical online algorithm design and machine learning. Many fundamental online decision-making problems including ski rental [Gollapudi and Panigrahi, 2019, Wang et al., 2020, Bamas et al., 2020], online scheduling [Lattanzi et al., 2020, Wei and Zhang, 2020, Scully et al., 2021], online facility location [Almanza et al., 2021, Jiang et al., 2021], caching [Lykouris and Vassilvitskii, 2021, Elias et al., 2024], and metrical task systems [Antoniadis et al., 2023], have been analyzed under this framework. Recently, Elias et al. [2024] consider a model where the predictor is allowed to learn and adapt its predictions based on the observed data. This is contrast to previous work on learning-augmented online algorithms, where predictions are made from machine learning models trained on historical data, and thus their predictions are static and non-adaptive to the current task at hand. Elias et al. [2024] study a number of fundamental problems, like caching and scheduling, and show how explicitly designed predictors can lead to improved performance bounds. In this work, we consider a model similar to Elias et al. [2024], where the predictions available to the learning algorithms are not fixed, but rather adapt to the true sequence of data processed by the learning algorithm. However, unlike Elias et al. [2024], we do not hand-craft these predictions, but rather assume our learning algorithms have black-box access to a machine-learned prediction algorithm. ", "page_idx": 2}, {"type": "text", "text": "Transductive Online Learning. In the Transductive Online Learning setting, Nature reveals the entire sequence of examples $x_{1},...,x_{T}$ to the learner before the game begins. The goal of the learner is to predict the corresponding labels $y_{1},...,y_{T}$ in order, receiving the true label $y_{t}$ only after making the prediction $\\hat{y}_{t}$ for example $x_{t}$ . First studied by Ben-David et al. [1997], recent work by Hanneke et al. [2024] has established the minimax rates on expected mistakes/regret in the realizable/agnostic settings. In the context of online classification with predictions, one can think of the transductive online learning setting as a special case where the Predictor never makes mistakes. ", "page_idx": 2}, {"type": "text", "text": "Smoothed Online Classification. In addition to AwP, smoothed analysis [Spielman and Teng, 2009] is another important sub-field of beyond-worst-case analysis of algorithms. By placing distributional assumptions on the input, one can typically go beyond computational and information-theoretic bottlenecks due to worst-case inputs. To this end, Rakhlin et al. [2011], Haghtalab [2018], Haghtalab et al. [2020], Block et al. [2022] consider a smoothed online classification model. Here, the adversary has to choose and draw examples from sufficiently anti-concentrated distributions. For binary classification, Haghtalab [2018] and Haghtalab et al. [2020] showed that smoothed online learnability is as easy as PAC learnability. That is, the finiteness of a smaller combinatorial parameter called the VC dimension is sufficient for smoothed online classification. In this work, we also go beyond the worst-case analysis standard in online classification, but consider a different model where the adversary is constrained to reveal a sequence of examples that are predictable. In this model, we also show that the VC dimension can be sufficient for online learnability. ", "page_idx": 2}, {"type": "text", "text": "2 Preliminaries ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "Let $\\mathcal{X}$ denote an example space and $\\boldsymbol{\\wp}$ denote the label space. We make no assumptions about $\\boldsymbol{\\wp}$ , so it can be unbounded (e.g., $\\mathcal{V}=\\mathbb{N}$ ). Let $\\mathcal{H}\\subseteq\\mathcal{V}^{\\mathcal{X}}$ denote a hypothesis class. For a set $A$ , let $\\textstyle A^{\\star}=\\bigcup_{n=0}^{\\infty}A^{n}$ denote the set of all finite sequences of elements in $A$ . Moreover, we let $A^{\\leq n}$ denote the set of all sequences of elements in $A$ of size at most $n$ . Then, $\\mathcal{X}^{\\star}$ denotes the set of all finite sequences of examples in $\\mathcal{X}$ and $\\mathcal{Z}\\subseteq\\mathcal{X}^{\\star}$ denotes a particular family of such sequences. We abbreviate a sequence $z_{1},...,z_{T}$ by $z_{1:T}$ . Finally, for $a,b,c\\in\\mathbb{R}$ , we let $a\\wedge b\\wedge c=\\operatorname*{min}\\{a,b,c\\}$ . ", "page_idx": 2}, {"type": "text", "text": "2.1 Online Classification ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "In online classification, a learner $\\boldsymbol{\\mathcal{A}}$ plays a repeated game against Nature over $T\\in\\mathbb{N}$ rounds. In each round $t\\in[T]$ , Nature picks a labeled example $(x_{t},y_{t})\\in\\mathcal{X}\\times\\mathcal{Y}$ and reveals $x_{t}$ to the learner. The learner makes a randomized prediction $\\hat{y}_{t}\\in\\mathcal{Y}$ . Finally, Nature reveals the true label $y_{t}$ and the learner suffers the 0-1 loss $\\mathbb{1}\\{\\hat{y}_{t}\\neq y_{t}\\}$ . Given a hypothesis class $\\mathcal{H}\\subseteq\\mathcal{V}^{\\mathcal{X}}$ , the goal of the learner is to minimize its expected regret ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\mathrm{R}_{A}(T,\\mathcal{H}):=\\operatorname*{sup}_{x_{1:T}\\in\\mathcal{X}}\\operatorname*{sup}_{y_{1:T}\\in\\mathcal{Y}^{T}}\\left(\\mathbb{E}\\left[\\sum_{t=1}^{T}\\mathbb{1}\\{A(x_{t})\\neq y_{t}\\}\\right]-\\operatorname*{inf}_{h\\in\\mathcal{H}}\\sum_{t=1}^{T}\\mathbb{1}\\{h(x_{t})\\neq y_{t}\\}\\right),\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "where the expectation is only over the randomness of the learner. A hypothesis class $\\mathcal{H}$ is said to be online learnable if there exists an (potentially randomized) online learning algorithm $\\boldsymbol{\\mathcal{A}}$ such that $\\mathrm{R}_{\\cal A}(T,\\mathcal{H})=o(T)$ . If it is guaranteed that the learner always observes a sequence of examples labeled by some hypothesis $h\\in\\mathcal H$ , then we say we are in the realizable setting and the goal of the learner is to minimize its expected cumulative mistakes, ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\mathrm{M}_{\\cal A}(T,\\mathcal{H}):=\\operatorname*{sup}_{x_{1:T}\\in\\mathcal{X}^{T}}\\operatorname*{sup}_{h\\in\\mathcal{H}}\\mathbb{E}\\left[\\sum_{t=1}^{T}\\mathbb{1}\\{\\cal A(x_{t})\\ne h(x_{t})\\}\\right],\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "where again the expectation is taken only with respect to the randomness of the learner. It is well known that the finiteness of the multiclass extension of the Littlestone dimension (Ldim) characterizes realizable and agnostic online learnability [Littlestone, 1987, Daniely et al., 2011, Hanneke et al., 2023]. See Appendix A for complete definitions. ", "page_idx": 3}, {"type": "text", "text": "2.2 Online Classification with Predictions ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "Motivated by the fact that real-world example streams $x_{1:T}$ are far from worst-case, we give our learner $\\boldsymbol{\\mathcal{A}}$ black-box access to a Predictor $\\mathcal{P}$ , defined algorithmically in Algorithm 1 and formally in Definition [blank]. ", "page_idx": 3}, {"type": "text", "text": "Definition 1 (Predictor). A Predictor $\\mathcal{P}:(\\mathcal{X}\\times\\mathcal{X}^{T})^{\\star}\\rightarrow\\Pi(\\mathcal{X}^{T})$ is a map that takes in a sequence of instances $x_{1},x_{2},...,$ , its own past predictions $\\hat{x}_{1:T}^{1},\\hat{x}_{1:T}^{2},...$ x\u02c621:T , ..., and outputs a distribution \u00b5\u02c6 \u2208\u03a0(X T ). The Predictor make its next prediction by sampling $\\hat{x}_{1:T}\\sim\\hat{\\mu}$ . ", "page_idx": 3}, {"type": "text", "text": "Algorithm 1 Predictor $\\mathcal{P}$ Input: Time horizon $T$ 1 for $t=1,...,T$ do 2 Nature reveals the true example $x_{t}$ . 3 Observe $x_{t}$ , update, and make a (potentially randomized) prediction $\\hat{x}_{1:T}^{t}$ . 4 end ", "page_idx": 3}, {"type": "text", "text": "Remark. We highlight that our Predictors are very general and can also use side information, in addition to the past examples, to make predictions about future examples. For example, if the examples are daily average temperatures, then Predictors can also use other covariates, like humidity, precipitation, and wind speed, to predict future temperatures. ", "page_idx": 3}, {"type": "text", "text": "In each round $t\\in[T]$ , the learner $\\boldsymbol{\\mathcal{A}}$ can query the Predictor $\\mathcal{P}$ to get a sense of what examples it will observe in the future. Then, the learner $\\boldsymbol{\\mathcal{A}}$ can use the history $(\\bar{x_{1}},y_{1}),..,(x_{t-1},y_{t-1})$ , the current example $x_{t}$ , and the future predicted examples to classify the current example. Protocol 2 makes explicit the interaction between the learner, the Predictor, and Nature. ", "page_idx": 3}, {"type": "text", "text": "Note that, in every round $t\\in[T]$ , the Predictor $\\mathcal{P}$ makes a prediction about the entire sequence of $T$ examples, even those that it has observed in the past. This is mainly for notational convenience as we assume that our Predictors are consistent. ", "page_idx": 3}, {"type": "text", "text": "Assumption 1 (Consistency). A Predictor is consistent if for every sequence $x_{1:T}\\in\\mathcal{X}^{T}$ and every time point $t\\in[T]$ , the prediction $\\hat{x}_{1:T}=\\mathcal{P}(x_{1:t})$ satisfies the property that $\\hat{x}_{1:t}=x_{1:t}$ . ", "page_idx": 3}, {"type": "text", "text": "Although stated as an assumption, it is without loss of generality that Predictors are consistent - any inconsistent Predictor can be made consistent by hard coding its input into its output. In addition to consistency, we assume that our Predictors are lazy. ", "page_idx": 3}, {"type": "text", "text": "Algorithm 2 Online Learning with a Predictor ", "page_idx": 4}, {"type": "text", "text": "Input: Predictor $\\mathcal{P}$ , Hypothesis class $\\mathcal{H}$ , Time horizon $T$ ", "page_idx": 4}, {"type": "text", "text": "1 for $t=1,...,T$ do   \n2 Nature reveals the true example $x_{t}$ .   \n3 The Predictor $\\mathcal{P}$ observes $x_{t}$ , updates, and reveals its predictions $\\hat{x}_{1:T}^{t}$ .   \n4 Learner makes a randomized prediction $\\hat{y}_{t}$ using $\\hat{x}_{1:T}^{t},x_{t}$ , and $(x_{1},y_{1}),...,(x_{t-1},y_{t-1})$ .   \n5 Nature reveals the true label $y_{t}$ to the learner.   \n6 Learner suffers loss $\\mathbb{1}\\{y_{t}\\neq\\hat{y_{t}}\\}$ and updates itself. ", "page_idx": 4}, {"type": "text", "text": "Assumption 2 (Laziness). A Predictor is lazy if for every sequence $x_{1:T}\\in\\mathcal{X}^{T}$ and every $t\\in[T],\\,i f$ $\\mathcal{P}(x_{1:t-1})_{t}=x_{t}$ , then $\\mathcal{P}(x_{1:t})=\\mathcal{P}(x_{1:t-1})$ . That is, $\\mathcal{P}$ does not change its prediction if it is correct. ", "page_idx": 4}, {"type": "text", "text": "Since Predictors are also online learners, the assumption of laziness is also mild: non-lazy online learners can be generically converted into lazy ones [Littlestone, 1987, 1989]. We always assume that Predictors are consistent and lazy and drop these pronouns for the rest of the paper. ", "page_idx": 4}, {"type": "text", "text": "Remark. We highlight that Predictors are adaptive and change their predictions based on the realizations of past examples. This is contrast to existing literature in OAwP, where machine-learned predictions are often static. Nevertheless, our framework is more general and captures the setting where predictions of examples are made once and fixed throughout the game. Indeed, consider the consistent, lazy Predictor that fixes a sequence $z_{1:T}\\in\\mathcal{X}^{T}$ before the game begins, and for every $t\\in[T]$ , outputs the predictions $\\hat{x}_{1:T}^{t}$ such that $\\hat{x}_{1:t}^{t}=x_{1:t}$ and $\\hat{x}_{t+1:T}^{t}=\\bar{z}_{t+1:T}$ . ", "page_idx": 4}, {"type": "text", "text": "Ideally, when given access to a Predictor $\\mathcal{P}$ , the expected regret of $\\boldsymbol{\\mathcal{A}}$ should degrade gracefully with the quality of $\\mathcal{P}$ \u2019s predictions. To this end, we quantify the performance of a Predictor $\\mathcal{P}$ through ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\mathrm{M}_{\\mathcal{P}}(x_{1:T}):=\\mathbb{E}\\left[\\sum_{t=2}^{T}\\mathbb{1}\\{\\mathcal{P}(x_{1:t-1})_{t}\\neq x_{t}\\}\\right],\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "the expected number of mistakes that $\\mathcal{P}$ makes on a sequence of examples $x_{1:T}\\in\\mathcal{X}^{T}$ . In Section 3, we design an online learner whose expected regret/mistake-bound on a stream $(x_{1},y_{1}),...,(x_{T},y_{T})$ can be written in terms of $\\mathrm{M}_{\\mathcal{P}}(x_{1:T})$ . ", "page_idx": 4}, {"type": "text", "text": "2.3 Predictability ", "text_level": 1, "page_idx": 4}, {"type": "text", "text": "Predictors and their mistake bounds offer us to ability to define and quantify a notion of \u201ceasiness\u201d for example streams $x_{1:T}$ . In particular, we can distinguish between example streams that are predictable and unpredictable. To do so, let $\\mathcal{Z}\\subseteq\\mathcal{X}^{\\star}$ denote a collection of finite sequences of examples. By restricting Nature to playing examples streams in $\\mathcal{Z}$ , we can define analogous notions of minimax expected regret ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\mathrm{R}_{A}(T,\\mathcal{H},\\mathcal{Z}):=\\operatorname*{sup}_{x_{1:T}\\in\\mathcal{Z}}\\operatorname*{sup}_{y_{1:T}\\in\\mathcal{Y}^{T}}\\mathbb{E}\\left[\\sum_{t=1}^{T}\\mathbb{1}\\{\\mathcal{A}(x_{t})\\neq y_{t}\\}-\\operatorname*{inf}_{h\\in\\mathcal{H}}\\sum_{t=1}^{T}\\mathbb{1}\\{h(x_{t})\\neq y_{t}\\}\\right],\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "and minimax expected mistakes, ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\mathrm{M}_{\\cal A}(T,{\\mathcal{H}},{\\mathcal{Z}}):=\\operatorname*{sup}_{x_{1:T}\\in{\\mathcal{Z}}}\\operatorname*{sup}_{h\\in{\\mathcal{H}}}\\mathbb{E}\\left[\\sum_{t=1}^{T}\\mathbb{1}\\{A(x_{t})\\neq h(x_{t})\\}\\right].\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "As usual, we say that a tuple $(\\mathcal{H},\\mathcal{Z})$ is online and realizable online learnable if $\\operatorname*{inf}_{A}\\mathrm{R}_{A}(T,\\mathcal{H},\\mathcal{Z})=$ $o(T)$ and $\\operatorname*{inf}_{A}\\mathrm{M}_{A}(T,\\mathcal{H},\\mathcal{Z})=o(T)$ respectively. If $\\mathcal{Z}=\\mathcal{X}^{\\star}$ , then the definitions above recover the standard, worst-case online classification setup. However, in the more general case where $\\mathcal{Z}^{\\star}\\subseteq\\mathcal{X}^{\\star}$ , we can use the existence of good Predictors $\\mathcal{P}$ and their mistake bounds to quantify the \u201ceasiness\" of a stream class $\\mathcal{Z}$ . That is, we say $\\mathcal{Z}$ is predictable if there exists a consistent, lazy Predictor $\\mathcal{P}$ such that $\\begin{array}{r}{\\mathrm{M}_{\\mathcal{P}}(T,\\mathcal{Z}):=\\operatorname*{sup}_{x_{1:T}\\in\\mathcal{Z}}\\mathrm{M}_{\\mathcal{P}}(x_{1:T})=o(T)}\\end{array}$ . ", "page_idx": 4}, {"type": "text", "text": "Definition 2 (Predictability). $A$ class $\\mathcal{Z}\\subseteq\\mathcal{X}^{\\star}$ is predictable if and only $:f\\operatorname*{inf}_{\\mathcal{P}}\\operatorname{M}_{\\mathcal{P}}(T,\\mathcal{Z})=o(T)$ . ", "page_idx": 4}, {"type": "text", "text": "Definition 2 provides a qualitative definition of what it means for a sequence of examples to be predictable, and therefore \u201ceasy\u201d. If $\\mathcal{Z}\\subseteq\\mathcal{X}^{\\star}$ is a predictable class of example streams, then a stream $\\dot{x}_{1:T}\\in\\mathcal{X}^{T}$ is predictable if $x_{1:T}\\in\\mathcal{Z}$ . By having access to a good Predictor, sequences of examples that previously exhibited \u201cworst-case\u201d behavior, now become predictable. One natural predictable collection of streams are those induced by easy-to-learn discrete-time dynamical systems [Raman et al., 2024]. That is, let $\\mathcal{X}$ be the state space for a finite collection $\\mathcal{G}$ of transition functions. Then, given an initial state $x_{0}\\in\\mathcal{X}$ , one can consider the stream class $\\mathcal{Z}$ to be the set of all trajectories induced by transition functions in $\\mathcal{G}$ . In Section 3, we show that for such classes of predictable examples, \u201coffline\u201d learnability is sufficient for online learnability. ", "page_idx": 5}, {"type": "text", "text": "2.4 Offline Learnability ", "text_level": 1, "page_idx": 5}, {"type": "text", "text": "In the classical analysis of online algorithms, one competes against the best \u201coffilne\u201d solution. In the context of online classification, this amounts to comparing online learnability to \u201coffilne\u201d learnability, where we interpret the \u201coffline\u201d setting as the case where Nature reveals the sequence of examples $(x_{1},...,x_{T})$ before the game begins. In particular, compared to the standard online learning setting, in the \u201coffline\" version, the learner knows the sequence of examples $x_{1},...,x_{T}$ before the game begins, and its goal is to predict the corresponding labels $y_{1},...,y_{T}$ . This setting was recently named \u201cTransductive Online Learning\" [Hanneke et al., 2024] and the minimax rates in both the realizable and agnostic setting have been established [Ben-David et al., 1997, Hanneke et al., 2023]. For the remainder of the paper, we will use offline and transductive online learnability interchangeably. ", "page_idx": 5}, {"type": "text", "text": "For a randomized offline learner $\\boldsymbol{\\mathrm{\\Delta}}\\boldsymbol{\\mathrm{\\Omega}}^{\\beta}$ , we let ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\mathrm{R}_{\\mathcal{B}}(T,\\mathcal{H}):=\\operatorname*{sup}_{x_{1:T}\\in\\mathcal{X}^{T}}\\operatorname*{sup}_{y_{1:T}\\in\\mathcal{Y}^{T}}\\mathbb{E}\\left[\\sum_{t=1}^{T}\\mathbb{1}\\{\\mathcal{B}_{x_{1:T}}(x_{t})\\neq y_{t}\\}-\\operatorname*{inf}_{h\\in\\mathcal{H}}\\sum_{t=1}^{T}\\mathbb{1}\\{h(x_{t})\\neq y_{t}\\}\\right]\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "denote its minimax expected regret and ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\mathrm{M}_{\\mathcal{B}}(T,\\mathcal{H}):=\\operatorname*{sup}_{h\\in\\mathcal{H}}\\operatorname*{sup}_{x_{1:T}\\in\\mathcal{X}^{T}}\\mathbb{E}\\left[\\sum_{t=1}^{T}\\mathbb{1}\\{\\beta_{x_{1:T}}(x_{t})\\neq h(x_{t})\\}\\right].\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "denote its minimax expected mistakes. We use the notation $\\displaystyle B_{x_{1:T}}$ to indicate that $\\boldsymbol{\\mathrm{\\Delta}}\\boldsymbol{\\mathrm{\\Omega}}_{\\boldsymbol{B}}$ was initialized with the sequence $x_{1:T}$ before the game begins. If $\\operatorname{M}_{\\mathcal{B}}(T,\\mathcal{H})=\\stackrel{\\cdot\\cdot}{o}(T)$ or $\\mathrm{R}_{B}(T,{\\mathcal{H}})=o(T).$ , then we say that $\\boldsymbol{\\mathrm{\\Delta}}\\boldsymbol{\\mathrm{\\Omega}}_{\\boldsymbol{B}}$ is a no-regret offilne learner. It turns out that realizable and agnostic offilne learnability are equivalent [Hanneke et al., 2024]. That is, $\\mathrm{M}_{B}(T,\\mathcal{H})=o(T)\\Leftrightarrow\\mathrm{R}_{B}(\\bar{T},\\mathcal{H})=o(T)$ . Thus, we say a class $\\mathcal{H}\\subseteq\\bar{\\mathcal{D}}^{\\mathcal{X}}$ is offline learnable if and only if there exists a no-regret offline learner for $\\mathcal{H}$ . ", "page_idx": 5}, {"type": "text", "text": "When $|\\mathcal{V}|\\,=\\,2$ , Ben-David et al. [1997] and Hanneke et al. [2023] show that the finiteness of a combinatorial dimension called the Vapnik\u2013Chervonenkis (VC) dimension (or equivalently PAC learnability) is sufficient for offline learnability (see Appendix A for complete definitions). ", "page_idx": 5}, {"type": "text", "text": "Lemma 2.1 (Ben-David et al. [1997], Hanneke et al. [2024]). For every $\\mathcal{H}\\subseteq\\{0,1\\}^{\\mathcal{X}}$ , there exists $a$ deterministic offline learner $\\boldsymbol{\\mathrm{\\Delta}}\\boldsymbol{\\mathrm{\\Omega}}_{\\boldsymbol{B}}$ such that ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\mathrm{M}_{\\mathcal{B}}(T,\\mathcal{H})=O\\Big(\\mathrm{VC}(\\mathcal{H})\\log_{2}T\\Big)\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "where $\\operatorname{VC}({\\mathcal{H}})$ is the VC dimension of $\\mathcal{H}$ . ", "page_idx": 5}, {"type": "text", "text": "In Section 3, we use this upper bound in Lemma 2.1 to prove that PAC learnability of $\\mathcal{H}$ implies $(\\mathcal{H},\\mathcal{Z})$ online learnability when $\\mathcal{Z}$ is predictable. Interestingly, Hanneke et al. [2024] also establish a trichotomy in the minimax expected mistakes for offilne learning in the realizable setting. That is, for any $\\mathcal{H}\\subseteq\\dot{\\mathcal{V}}^{\\mathcal{X}}$ with $|\\mathcal{D}|<\\infty$ , the quantity $\\mathrm{M}_{B}(T,\\mathcal{H})$ can\u221a only be $\\Theta(1)$ , $\\Theta(\\log_{2}T)$ , or $\\Theta(T)$ . On the other hand, in the agnostic setting, $\\operatorname{R}_{B}(T,{\\mathcal{H}})$ can be $\\tilde{\\Theta}(\\sqrt{T})$ or $\\Theta(T)$ , where $\\Tilde{\\Theta}$ hides poly-log terms in $T$ . ", "page_idx": 5}, {"type": "text", "text": "Our main result in Section 3 shows that offline learnability is sufficient for online learnability under predictable examples. The following technical lemma will be important when proving so. ", "page_idx": 5}, {"type": "text", "text": "Lemma 2.2. [Ceccherini-Silberstein et al., 2017, Lemma 5.17] Let $g:\\mathbb{Z}_{+}\\mapsto\\mathbb{R}_{+}$ be a positive sublinear function. Then, $g$ is bounded from above by a concave sublinear function $f:\\mathbb{R}_{+}\\mapsto\\mathbb{R}_{+}$ . ", "page_idx": 5}, {"type": "text", "text": "In light of Lemma 2.2, we let $\\bar{f}$ denote the smallest concave sublinear function upper bounding the positive sublinear function $f$ . For example, our regret bounds in Section 3 will often be in terms of ${\\overline{{\\mathrm{M}}}}_{B}(T,{\\mathcal{H}})$ . Although in full generality $\\mathrm{M}_{B}(T,\\mathcal{H})\\leq\\overline{{\\mathrm{M}}}_{B}(T,\\mathcal{H})$ , in many cases we have equality. For example, when $|\\mathcal{Y}|=2$ , the trichotomy of expected minimax rates established by Theorem 4.1 in Hanneke et al. [2024] shows that $\\mathrm{M}_{\\mathcal{B}}(T,\\mathcal{H})=\\overline{{\\mathrm{M}}}_{\\mathcal{B}}(T,\\mathcal{H})$ . ", "page_idx": 6}, {"type": "text", "text": "3 Adaptive Rates in the Realizable Setting ", "text_level": 1, "page_idx": 6}, {"type": "text", "text": "In this section, we design learning algorithms whose expected mistake bounds, given black-box access to a Predictor $\\mathcal{P}$ and offline learner $\\boldsymbol{\\mathrm{\\Delta}}\\boldsymbol{\\mathrm{\\Omega}}_{\\boldsymbol{B}}$ , adapt to the quality of predictions by $\\mathcal{P}$ and $\\boldsymbol{\\mathrm{\\Delta}}\\boldsymbol{\\mathrm{\\Omega}}^{\\beta}$ . Our main quantitative result is stated below. ", "page_idx": 6}, {"type": "text", "text": "Theorem 3.1 (Realizable upper bound). For every $\\mathcal{H}\\subseteq\\mathcal{V}^{\\mathcal{X}}$ , Predictor $\\mathcal{P}$ , and no-regret offline learner $\\boldsymbol{\\mathrm{\\Delta}}\\boldsymbol{\\mathrm{\\Omega}}^{\\beta}$ , there exists an online learner $\\boldsymbol{\\mathcal{A}}$ such that for every realizable stream $(x_{1},y_{1}),...,(x_{T},y_{T})$ , $\\boldsymbol{\\mathcal{A}}$ makes at most ", "page_idx": 6}, {"type": "equation", "text": "$$\n\\bigg\\langle\\underbrace{\\mathrm{L}(\\mathcal{H})}_{(i)}\\wedge\\underbrace{\\big(\\mathrm{M}_{\\mathcal{P}}(x_{1:T})+1\\big)\\mathrm{M}_{\\mathcal{B}}(T,\\mathcal{H})}_{(i i)}\\wedge\\underbrace{6\\Big((\\mathrm{M}_{\\mathcal{P}}(x_{1:T})+1)\\,\\overline{{\\mathrm{M}}}_{\\mathcal{B}}\\Big(\\frac{T}{\\mathrm{M}_{\\mathcal{P}}\\big(x_{1:T}\\big)+1}+1,\\mathcal{H}\\Big)+\\log_{2}T}_{(i i i)}\\bigg\\rangle}_{(i i i)}\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "mistakes in expectation, where $\\operatorname{L}({\\mathcal{H}})$ is the Littlestone dimension of $\\mathcal{H}$ . ", "page_idx": 6}, {"type": "text", "text": "We highlight some important consequences of Theorem 3.1. Firstly, when $\\mathrm{M}_{\\mathcal{P}}(x_{1:T})\\,=\\,0$ , the expected mistake bound of $\\boldsymbol{\\mathcal{A}}$ matches (up to constant factors) that of the offline learner $\\boldsymbol{\\mathrm{\\Delta}}\\boldsymbol{\\mathrm{\\Omega}}^{\\beta}$ . Thus, when $\\mathrm{M}_{\\mathcal{P}}(x_{1:T})=0$ and $\\boldsymbol{\\mathrm{\\Delta}}\\boldsymbol{\\mathrm{\\Omega}}_{\\boldsymbol{B}}$ is a minimax optimal offline learner, our learner $\\boldsymbol{\\mathcal{A}}$ performs as well as the best offline learner. Secondly, the expected mistake bound of $\\boldsymbol{\\mathcal{A}}$ is always at most $3\\,\\mathrm{L}(\\mathcal{H})+5$ ; the minimax worst-case mistake bound up to constant factors. Thus, our learner $\\boldsymbol{\\mathcal{A}}$ never does worse than the worst-case mistake bound. Thirdly, the expected mistake bound of $\\boldsymbol{\\mathcal{A}}$ gracefully interpolates between the offilne and worst-case optimal rates as a function of $\\mathrm{M}_{\\mathcal{P}}(x_{1:T})$ . In Section 3.3, we show that the dependence of $\\boldsymbol{\\mathcal{A}}$ \u2019s mistake bound on $\\mathrm{M}_{\\mathcal{P}}(x_{1:T})$ and $\\mathrm{M}_{B}(T,\\mathcal{H})$ can be tight. Lastly, we highlight that Theorem 3.1 makes no assumption about the size of $\\boldsymbol{\\wp}$ . ", "page_idx": 6}, {"type": "text", "text": "With respect to learnability, Corollary 3.2 shows that offilne learnability of $\\mathcal{H}$ is sufficient for online learnability under predictable examples. ", "page_idx": 6}, {"type": "text", "text": "Corollary 3.2 (Offilne learnability $\\Longrightarrow$ Realizable Online learnability with Predictable Examples). For every $\\mathcal{H}\\subseteq\\mathcal{V}^{\\mathcal{X}}$ and $\\mathcal{Z}\\subseteq\\mathcal{X}^{\\star}$ , ", "page_idx": 6}, {"type": "text", "text": "$\\mathcal{Z}$ is predictable and $\\mathcal{H}$ is offline learnable $\\implies(\\mathcal{H},\\mathcal{Z})$ is realizable online learnable. ", "page_idx": 6}, {"type": "text", "text": "This follows from a slight modification of the proof of Theorem 3.1 along with the fact that the term $\\begin{array}{r}{(\\mathrm{M}_{\\mathcal{P}}(T,\\mathcal{Z})+1)\\overline{{\\mathrm{M}}}_{\\mathcal{B}}\\Big(\\frac{T}{\\mathrm{M}_{\\mathcal{P}}(T,\\mathcal{Z})+1},\\mathcal{H}\\Big)\\!=o(T)}\\end{array}$ when $\\mathrm{M}_{\\mathcal{B}}(T,\\mathcal{H})=o(T)$ and $\\mathrm{M}_{\\mathcal{P}}(T,\\mathcal{Z})=o(T)$ . In addition, we can also establish a quantitative version of Corollary 3.2 for VC classes. ", "page_idx": 6}, {"type": "text", "text": "Corollary 3.3. For every $\\mathcal{H}\\subseteq\\{0,1\\}^{\\mathcal{X}}$ , Predictor $\\mathcal{P}$ and $\\mathcal{Z}\\subseteq\\mathcal{X}^{\\star}$ , there exists an online learner $\\boldsymbol{\\mathcal{A}}$ such that ", "page_idx": 6}, {"type": "equation", "text": "$$\n\\mathrm{M}_{A}(T,\\mathcal{H},\\mathcal{Z})=O\\left(\\mathrm{VC}(\\mathcal{H})(\\mathrm{M}_{\\mathcal{P}}(T,\\mathcal{Z})+1)\\log_{2}\\!\\left(\\frac{T}{\\mathrm{M}_{\\mathcal{P}}(T,\\mathcal{Z})+1}\\right)\\!+\\log_{2}T\\right).\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "We prove both Corollary 3.2 and 3.3 in Appendix C. Corollary 3.3 shows that PAC learnability implies online learnability under predictable examples. Moreover, for VC classes, when $\\mathrm{M}_{\\mathcal{P}}(x_{1:T})=0$ , the upper bound in Corollary 3.3 exactly matches that of Lemma 2.1. An analogous corollary in terms of the Natarajan dimension (see Appendix A for definition) holds when $|\\mathcal{D}|<\\infty$ . ", "page_idx": 6}, {"type": "text", "text": "The remainder of this section is dedicated to proving Theorem 3.1. The proof involves constructing three different online learners, with expected mistake bounds (i), (ii), and (iii) respectively, and then running the Deterministic Weighted Majority Algorithm (DWMA) using these learners as experts [Arora et al., 2012]. The following guarantee of DWMA along with upper bounds (i), (ii), and (iii) gives the upper bound in Theorem 3.1 (see Appendix D for complete proof). ", "page_idx": 6}, {"type": "text", "text": "Lemma 3.4 (DWMA guarantee [Arora et al., 2012]). The DWMA run with $N$ experts and learning rate $\\eta=1/2$ makes at most $3(\\operatorname*{min}_{i\\in[N]}M_{i}+\\log_{2}N)$ mistakes, where $M_{i}$ is the number of mistakes made by expert $i\\in[N]$ . ", "page_idx": 7}, {"type": "text", "text": "The online learner obtaining the upper bound $\\operatorname{L}({\\mathcal{H}})$ is the celebrated Standard Optimal Algorithm [Littlestone, 1987, Daniely et al., 2011], and thus we omit the details here. Our second and third learners are described in Sections 3.1 and 3.2 respectively. Finally, in Section 3.3, we give a lower bound showing that our upper bound in Theorem 3.1 can be tight. ", "page_idx": 7}, {"type": "text", "text": "3.1 Proof of upper bound (ii) in Theorem 3.1 ", "text_level": 1, "page_idx": 7}, {"type": "text", "text": "Consider a lazy, consistent predictor $\\mathcal{P}$ . Given any sequence of examples $x_{1:T}\\in\\mathcal{X}^{T}$ , the Predictor $\\mathcal{P}$ makes $c\\in\\mathbb{N}$ mistakes at some timepoints $t_{1},...,t_{c}\\in[T]$ . Since $\\mathcal{P}$ may be randomized, both $c$ and $t_{1},...,t_{c}$ are random variables. Crucially, since $\\mathcal{P}$ is lazy, for every $i\\in\\{0,...,c+1\\}$ , the predictions take $t_{0}=0$ $\\mathcal{P}$ and $t_{c+1}=T+1$ . This mea $t_{i}$ that $t_{i+1}$ ou $t_{i}$ , we have that $\\hat{x}_{t_{i}:t_{i+1}-1}^{t_{i}}=x_{t_{i}:t_{i+1}-1}$ Therefore, initializing a fresh copy of an offline learner $\\boldsymbol{\\mathrm{\\Delta}}\\boldsymbol{\\mathrm{\\Omega}}_{\\boldsymbol{B}}$ with the predictions $\\hat{x}_{t_{i}:T}^{t_{i}}$ ensures that $\\boldsymbol{\\mathrm{\\Delta}}\\boldsymbol{\\mathrm{\\Omega}}^{\\beta}$ makes at most $\\mathrm{M}_{B}(T\\!-\\!t_{i}\\!+\\!1,\\mathcal{H})$ mistakes on the stream $(x_{t_{i},\\,}y_{t_{i}}),...,(x_{t_{i+1}-1},y_{t_{i+1}-1})$ . Repeating this argument for all adjacent pairs of timepoints in $\\{t_{1},...,t_{c}\\}$ , gives the following strategy: initialize a new offilne learner $\\boldsymbol{\\mathrm{\\Delta}}\\boldsymbol{\\mathrm{\\Omega}}_{\\boldsymbol{B}}$ every time $\\mathcal{P}$ makes a mistakes, and use $\\boldsymbol{\\mathrm{\\Delta}}\\boldsymbol{\\mathrm{\\Omega}}_{\\boldsymbol{B}}$ to make predictions until the next time $\\mathcal{P}$ makes a mistake. Algorithm 3 implements this idea. ", "page_idx": 7}, {"type": "text", "text": "Algorithm 3 Online Learner Input: Hypothesis class $\\mathcal{H}$ , Offline learner $\\boldsymbol{\\mathrm{\\Delta}}\\boldsymbol{\\mathrm{\\Omega}}^{\\beta}$ , Time horizon $T$ 1 Initialize: $i=0$ 2 for $t=1,...,T$ do 3 Receive $x_{t}$ from Nature. 4 Receive predictions $\\hat{x}_{1:T}^{t}$ from Predictor $\\mathcal{P}$ such that $\\hat{x}_{1:t}^{t}=x_{1:t}$ . 5 if $t=1$ or $\\hat{x}_{t}^{t-1}\\neq x_{t}$ (i.e. $\\mathcal{P}$ made a mistake) then 6 Let $B^{i}$ be a new copy of $\\boldsymbol{\\mathrm{\\Delta}}\\boldsymbol{\\mathrm{\\Omega}}^{\\beta}$ initialized with the sequence $\\hat{x}_{t:T}^{t}$ and set $i\\gets i+1$ . Query $B^{i}$ on example $x_{t}$ and play its returned prediction $\\hat{y}_{t}$ . 8 Receive true label $y_{t}$ from Nature and pass it to $B^{i}$ . 9 end ", "page_idx": 7}, {"type": "text", "text": "Lemma 3.5. For every $\\mathcal{H}\\subseteq\\mathcal{V}^{\\mathcal{X}}$ , Predictor $\\mathcal{P}$ , no-regret offline learner $\\boldsymbol{\\mathrm{\\Delta}}\\boldsymbol{\\mathrm{\\Omega}}^{\\beta}$ , and realizable stream $(x_{1},y_{1}),...,(x_{T},y_{T}).$ , Algorithm 3 makes at most $\\left(\\mathrm{M}_{\\mathcal{P}}(\\stackrel{.}{x}_{1:T})\\not+1\\right)\\mathrm{M}_{\\mathcal{B}}(T,\\mathcal{H})$ mistakes in expectation. ", "page_idx": 7}, {"type": "text", "text": "Proof. Let $\\boldsymbol{\\mathcal{A}}$ denote Algorithm 3, $(x_{1},y_{1}),...,(x_{T},y_{T})$ denote the realizable stream to be observed by $\\boldsymbol{\\mathcal{A}}$ , and $h^{\\star}\\in\\mathcal{H}$ to be the labeling hypothesis. Let $c$ be the random variable denoting the number of mistakes made by Predictor $\\mathcal{P}$ on the stream and $t_{1},...,t_{c}$ be the random variables denoting the time points where $\\mathcal{P}$ makes these errors (e.g . $\\hat{x}_{t_{i}}^{t_{i}-1}\\neq x_{t_{i}}^{\\phantom{t_{i}}}$ ). Note that $t_{i}\\geq2$ for all $i\\in[c]$ . We will show pointwise for every value of $c$ and $t_{1},...,t_{c}$ that $\\boldsymbol{\\mathcal{A}}$ makes at most $(c+1)\\,\\mathrm{M}_{\\mathcal{B}}(T,\\mathcal{H})$ mistakes in expectation over the randomness of $\\boldsymbol{\\mathrm{\\Delta}}\\boldsymbol{\\mathrm{\\Omega}}_{\\boldsymbol{B}}$ . Taking an outer expectation with respect to the randomness of $\\mathcal{P}$ and using the fact that $\\mathbb{E}\\left[c\\right]=\\mathrm{M}_{\\mathcal{P}}(x_{1:T})$ , completes the proof. ", "page_idx": 7}, {"type": "text", "text": "First, consider the case where $c=0$ (i.e. $\\mathcal{P}$ makes no mistakes). Then, since $\\mathcal{P}$ is lazy, we have that $\\hat{x}_{1:T}^{t}=x_{1:T}$ for every $t\\in[T]$ . Thus line 5 fires exactly once on round $t=1$ , $\\boldsymbol{\\mathcal{A}}$ initializes an offilne learner $B^{1}$ with $x_{1:T}$ , and $\\boldsymbol{\\mathcal{A}}$ uses $B^{1}$ to make its prediction on all rounds. Thus, $\\boldsymbol{\\mathcal{A}}$ makes at most $\\mathrm{M}_{B}(T,\\mathcal{H})$ mistakes in expectation. ", "page_idx": 7}, {"type": "text", "text": "Now, let $c>0$ and $t_{1},...,t_{c}$ be the time points where $\\mathcal{P}$ errs. Partition the sequence $1,...,T$ into the disjoint intervals $(1,...,t_{1}-1)$ , $(t_{1},...,t_{2}-1),...,(t_{c},...,T)$ . Define $t_{0}:=1$ and $t_{c+1}:=T$ . Fix an $i\\in\\{0,...,c\\}$ . Observe that for every $j\\in\\{t_{i},...,t_{i+1}-1\\}$ , we have that $\\hat{x}_{1:t_{i+1}-1}^{j}=x_{t_{i+1}-1}$ . This comes from the fact that $\\mathcal{P}$ does not error on timepoints $t_{i}+1,...,t_{i+1}-1$ and is both consistent and lazy (see Assumptions 1 and 2). Thus, line 5 fires on round $t_{i}$ , $\\boldsymbol{\\mathcal{A}}$ initializes an offilne learner $B^{i}$ with the sequence $\\hat{x}_{t_{i}:T}^{t_{i}^{-}}=x_{t_{i}:t_{i+1}-1}\\circ\\hat{x}_{t_{i+1}:T}^{t_{i}}$ , and $\\boldsymbol{\\mathcal{A}}$ uses $B^{i}$ it to make predictions for all remaining timepoints $t_{i},...,t_{i+1}-1$ . Note that line 5 does not fire on timepoints $t_{i}+1,...,t_{i+1}-1$ . ", "page_idx": 7}, {"type": "text", "text": "Consider the hypothetical labeled stream of examples ", "page_idx": 8}, {"type": "equation", "text": "$$\n,h^{\\star}(\\hat{x}_{t_{i}}^{t_{i}})),...,(\\hat{x}_{T}^{t_{i}},h^{\\star}(\\hat{x}_{T}^{t_{i}}))=(x_{t_{i}},y_{t_{i}}),...,(x_{t_{i+1}-1},y_{t_{i+1}-1}),(\\hat{x}_{t_{i+1}}^{t_{i}},h^{\\star}(\\hat{x}_{t_{i+1}}^{t_{i}})),...,(\\hat{x}_{T}^{t_{i}},h^{\\star}(\\hat{x}_{T}^{t_{i}})).\n$$", "text_format": "latex", "page_idx": 8}, {"type": "text", "text": "By definition, $B^{i}$ , after initialized with $\\hat{x}_{t_{i}:T}^{t_{i}}$ , makes at most $\\mathrm{M}_{B}(T-t_{i}+1,\\mathcal{H})$ mistakes in emxopset e nm issitmakuelas tiend  eoxnp etchtea tistorne aomn $(\\hat{x}_{t_{i}}^{t_{i}},h^{\\star}(\\hat{x}_{t_{i}}^{t_{i}})),...,(\\hat{x}_{T}^{t_{i}},h^{\\star}(\\hat{x}_{T}^{t_{i}}))$ $B^{i}$ $\\mathrm{M}_{B}(T,\\mathcal{H})$ $(\\hat{x}_{t_{i}}^{t_{i}},h^{\\star}(\\hat{x}_{t_{i}}^{t_{i}})),...,(\\hat{x}_{t_{i+1}-1}^{t_{i}},h^{\\star}(\\hat{x}_{t_{i+1}-1}^{t_{i}}))=$ $(x_{t_{i}},y_{t_{i}}),...,(x_{t_{i+1}-1},y_{t_{i+1}-1})$ . Since on the interval timepoint $t_{i}$ , $\\boldsymbol{\\mathcal{A}}$ instantiates $B^{i}$ with the sequence x\u02c6ttii:T and proceeds to simulate $B^{i}$ on the sequence of labeled examples $(x_{t_{i}},y_{t_{i}}),...,(x_{t_{i+1}-1},y_{t_{i+1}-1}).$ , $\\boldsymbol{\\mathcal{A}}$ makes at most $\\mathrm{M}_{B}(T,\\mathcal{H})$ mistakes in expectation on the sequence $(x_{t_{i}},y_{t_{i}}),...,(x_{t_{i+1}-1},y_{t_{i+1}-1})$ . Since the interval $i$ was chosen arbitrarily, the above analysis is true for every $i\\in\\{0,...,c\\}$ and therefore $\\boldsymbol{\\mathcal{A}}$ makes at most $(c+1)\\,\\mathrm{M}_{\\mathcal{B}}(T,\\dot{\\mathcal{H}})$ mistakes in expectation over the entire stream. \u53e3 ", "page_idx": 8}, {"type": "text", "text": "3.2 Proof sketch of upper bound (iii) in Theorem 3.1 ", "text_level": 1, "page_idx": 8}, {"type": "text", "text": "When $\\mathrm{M}_{B}(T,\\mathcal{H})$ is large (i.e. $\\Omega(\\sqrt{T}))$ , upper bound (ii) is sub-optimal. Indeed, if $t_{1},...,t_{c}$ denotes the timepoints where $\\mathcal{P}$ makes mistakes on the stream $x_{1:T}$ , then Algorithm 3 initializes offline learners with sequences of length $T-t_{i}+1$ . The resulting mistake-bound of these offilne learners are then in the order of $T\\!-\\!t_{i}\\!+\\!1$ , which can be large if $t_{1},...,t_{c}$ are evenly spaced across the time horizon. To overcome this, we construct a family $\\mathcal{E}$ of online learners, each of which explicitly controls the length of the sequences offilne learners can be initialized with. Finally, we run DWMA using $\\mathcal{E}$ as its set of experts. Our family of online learners is parameterized by integers $c\\in\\{0,...,T-1\\}$ . Given an input $c\\in\\{0,...,T-1\\}$ , the online learner parameterized by $c$ partitions the stream into $c+1$ roughly equally sized parts of size $\\lceil{\\frac{T}{c+1}}\\rceil$ and runs a fresh copy of Algorithm 3 on each partition. In this way, the online learner parameterized by $c$ ensures that offline learners are initialized with time horizons at most $\\lceil{\\frac{T}{c+1}}\\rceil$ . Algorithm 4 formalizes this online learner and Lemma 3.6, whose proof is in Appendix B, bounds its expected number of mistakes. ", "page_idx": 8}, {"type": "text", "text": "Algorithm 4 Expert(c) ", "text_level": 1, "page_idx": 8}, {"type": "text", "text": "Input: Copy of Algorithm 3 denoted $\\kappa$ , Offline Learner $\\boldsymbol{\\mathrm{\\Delta}}\\boldsymbol{\\mathrm{\\Omega}}^{\\beta}$ , Time horizon $T$   \n1 Initialize: $\\begin{array}{r}{\\tilde{t}_{i}=i\\lceil\\frac{\\rceil}{c+1}\\rceil}\\end{array}$ for $i\\in\\{1,...,c\\}$ , $\\tilde{t}_{0}=0$ , and $\\tilde{t}_{c+1}=T$ .   \n2 for $t=1,...,T$ do   \n3 Let $i\\in\\{0,...,c\\}$ such that $t\\in\\{\\tilde{t}_{i}+1,...,\\tilde{t}_{i+1}\\}$ .   \n4 if $t=\\tilde{t}_{i}+1$ then   \n5 Let $\\kappa_{i}$ be a new copy of $\\kappa$ initialized with time horizon $\\tilde{t}_{i+1}-\\tilde{t}_{i}$ and a new copy of $\\boldsymbol{\\mathrm{\\Delta}}\\boldsymbol{\\mathrm{\\Omega}}^{\\beta}$ .   \n6 Receive $x_{t}$ from Nature.   \n7 Receive predictions $\\hat{x}_{1:T}^{t}$ from Predictor $\\mathcal{P}$ such that $\\hat{x}_{1:t}^{t}=x_{1:t}$ .   \n8 Forward $x_{t}$ and x\u02c6tt\u02dci+1:t\u02dci+1 to Ki via Lines 2 and 3 of Algorithm 3 respectively.   \n9 Receive $\\hat{y}_{t}$ from $\\kappa_{i}$ via line 6 in Algorithm 3 and predict $\\hat{y}_{t}$ .   \n10 Receive true label $y_{t}$ and forward it to $\\kappa_{i}$ via line 7 in Algorithm 3.   \n11 end ", "page_idx": 8}, {"type": "text", "text": "", "text_level": 1, "page_idx": 8}, {"type": "text", "text": "Lemma 3.6 (Expert guarantee). For any $\\mathcal{H}\\subseteq\\mathcal{V}^{\\mathcal{X}}$ , Predictor $\\mathcal{P}$ , and no-regret offline learner $\\boldsymbol{\\beta}$ , Algorithm 4, given as input $c\\in\\{0,...,T-1\\}$ , makes at most ", "page_idx": 8}, {"type": "equation", "text": "$$\n\\left(\\mathrm{M}_{\\mathcal{P}}(x_{1:T})+c+1\\right)\\overline{{\\mathrm{M}}}_{\\mathcal{B}}\\Big(\\frac{T}{c+1}+1,\\mathcal{H}\\Big)\n$$", "text_format": "latex", "page_idx": 8}, {"type": "text", "text": "mistakes in expectation on any realizable stream $(x_{1},y_{1}),...,(x_{T},y_{T})$ . ", "page_idx": 8}, {"type": "text", "text": "Note that when $c=0$ and $\\mathrm{M}_{\\mathcal{B}}(T,\\mathcal{H})=\\overline{{\\mathrm{M}}}_{\\mathcal{B}}(T,\\mathcal{H})$ , this bound reduces to the one in Lemma 3.5 up to a constant factor. On the other hand, using $c=\\lceil\\mathrm{M}_{\\mathcal{P}}(x_{1:T})\\rceil$ gives the upper bound ", "page_idx": 8}, {"type": "equation", "text": "$$\n2(\\mathrm{M}_{\\mathcal{P}}(x_{1:T})+1)\\overline{{\\mathrm{M}}}_{\\mathcal{B}}\\Big(\\frac{T}{\\mathrm{M}_{\\mathcal{P}}(x_{1:T})+1}+1,\\mathcal{H}\\Big).\n$$", "text_format": "latex", "page_idx": 8}, {"type": "text", "text": "Since $\\mathcal{E}$ contains an Expert parameterized for every $c\\in\\{0,...,T-1\\}$ , there always exists an expert $E_{\\lceil\\mathrm{M}_{\\mathcal{P}}(x_{1:T})\\rceil}\\in\\mathcal{E}$ initialized with input $c=\\lceil\\mathrm{M}_{\\mathcal{P}}(x_{1:T})\\rceil$ . Running DWMA using these set of experts ", "page_idx": 8}, {"type": "table", "img_path": "MB0DD5qAz8/tmp/6bdbc99c9bc555be1d3811596bf830f24cce26039c81510b8822c7cf63e768e2.jpg", "table_caption": [], "table_footnote": [], "page_idx": 9}, {"type": "text", "text": "$\\mathcal{E}$ on the data stream $(x_{1},y_{1}),...,(x_{T},y_{T})$ ensures that our learner does not perform too much worse than $E_{\\lceil\\mathrm{M}_{\\mathcal{P}}(x_{1:T})\\rceil}$ . Algorithm 5 formalizes this idea and Lemma 3.7 is proved in Appendix B. ", "page_idx": 9}, {"type": "text", "text": "Lemma 3.7. For every $\\mathcal{H}\\subseteq\\mathcal{V}^{\\mathcal{X}}$ , Predictor $\\mathcal{P}$ , and no-regret offilne learner $\\boldsymbol{\\mathrm{\\Delta}}\\boldsymbol{\\mathrm{\\Omega}}_{\\boldsymbol{B}}$ , Algorithm 5 makes at most ", "page_idx": 9}, {"type": "equation", "text": "$$\n6\\Bigg(\\big(\\mathrm{M}_{\\mathcal{P}}\\big(x_{1:T}\\big)+1\\big)\\overline{{\\mathrm{M}}}_{\\mathcal{B}}\\Big(\\frac{T}{\\mathrm{M}_{\\mathcal{P}}\\big(x_{1:T}\\big)+1}+1,\\mathcal{H}\\Big)+\\log_{2}T\\Bigg).\n$$", "text_format": "latex", "page_idx": 9}, {"type": "text", "text": "mistakes in expectation on any realizable stream $(x_{1},y_{1}),...,(x_{T},y_{T})$ . ", "page_idx": 9}, {"type": "text", "text": "3.3 Lower bounds ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "In light of Theorem 3.1, it is natural ask whether the upper bounds derived in Section 3 are tight. A notable feature in upper bounds (ii) and (iii) is the product of the two mistake bounds $\\mathrm{M}_{\\mathcal{P}}(x_{1:T})$ and $\\mathrm{M}_{B}(T,\\mathcal{H})$ . Can this product can be replaced by a sum? Unfortunately, Theorem 3.8 shows that the upper bound in Theorem 3.1 can be tight. ", "page_idx": 9}, {"type": "text", "text": "Theorem 3.8. Let ${\\mathcal{X}}\\,=\\,[0,1]\\cup\\{\\star\\},\\mathcal{Y}\\,=\\,\\{0,1\\},$ , and ${\\mathcal{H}}\\,=\\,\\{x\\,\\mapsto\\,\\mathbb{1}\\{x\\,\\le\\,a\\}\\mathbb{1}\\{x\\,\\neq\\,\\star\\}\\}$ . Let $T,n\\in\\mathbb{N}$ be such that $n+1$ divides $T$ and nT+1 + 1 = 2k for some k \u2208N. Then, there exists a Predictor $\\mathcal{P}$ such that for every online learner $\\boldsymbol{\\mathcal{A}}$ that uses $\\mathcal{P}$ according to Protocol 2, there exists $a$ realizable stream $(x_{1},y_{1}),...,(x_{T},y_{T})$ such that $\\mathrm{M}_{\\mathcal{P}}(x_{1:T})=n$ but ", "page_idx": 9}, {"type": "equation", "text": "$$\n\\mathbb{E}\\left[\\sum_{t=1}^{T}\\mathbb{1}\\{A(x_{t})\\neq y_{t}\\}\\right]\\geq\\frac{(n+1)}{2}\\log_{2}\\!\\Big(\\frac{T}{n+1}\\Big).\n$$", "text_format": "latex", "page_idx": 9}, {"type": "text", "text": "Theorem 3.8 shows that the upper bound in Theorem 3.1 is tight up to an additive factor in $\\log_{2}T$ because Lemma 2.1 gives that $\\operatorname*{inf}_{\\mathcal{B}}\\overline{{\\mathrm{M}}}_{\\mathcal{B}}(T,\\mathcal{H})=O(\\operatorname{VC}(\\mathcal{H})\\log_{2}T)$ and $\\mathrm{VC}(\\mathcal{H})=1$ . The proof of Theorem 3.8 is technical and provided in Appendix E. Our proof involves four steps. First, we construct a class of streams $\\mathcal{Z}_{n}\\subseteq\\mathcal{X}^{\\star}$ . Then, using ${\\mathcal{Z}}_{n}$ , we construct a deterministic, lazy, consistent Predictor $\\mathcal{P}$ such that $\\mathcal{P}$ makes mistakes exactly on timepoints $\\begin{array}{r}{\\{\\frac{T}{n+1}+1,...,\\frac{n T}{n+1}+\\dot{1}\\}}\\end{array}$ for every stream $x_{1:T}\\in\\mathcal{Z}_{n}$ . Next, whenever $x_{1:T}\\in\\mathcal{Z}_{n}$ , we establish an equivalence between the game defined by Protocol 2 when given access to Predictor $\\mathcal{P}$ and Online Classification with Peeks, a different game where there is no Predictor, but the learner observes the next nT+1 examples at timepoints $t\\in\\{1,{\\frac{T}{n+1}}+1,...,{\\frac{n T}{n+1}}+1\\}$ . Finally, for Online Classification with Peeks, we give a strategy for Nature such that it can force any online learner to make $\\frac{(n+1)\\log_{2}(\\frac{T}{n+1})}{2}$ mistakes in expectation while ensuring that its selected stream satisfies x1:T \u2208Zn and infh\u2208H tT=1 $\\begin{array}{r}{\\operatorname*{inf}_{h\\in\\mathcal{H}}\\sum_{t=1}^{T}\\mathbb{1}\\{h(x_{t})\\neq y_{t}\\}=0}\\end{array}$ . A key component of the fourth step is the stream constructed by [Hanneke et al., 2024, Claim 3.4] to show that the minimax mistakes for classes with infinite Ldim is at least $\\log_{2}T$ in the offline setting. ", "page_idx": 9}, {"type": "text", "text": "Remark. Although Theorem 3.8 is stated using the class of one dimensional thresholds, it can be adapted to hold for any VC class with infinite Ldim as these classes embed thresholds [Alon et al., 2019, Theorem 3]. ", "page_idx": 9}, {"type": "text", "text": "4 Discussion ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "In this paper, we initiated the study of online classification when the learner has access to machinelearned predictions about future examples. There are many interesting directions for future research and we list two below. Firstly, we only considered the classification setting, and it would be interested to extend our results to online scalar-valued regression. Secondly, we measure the performance of a Predictor through its mistake-bounds. When $\\mathcal{X}$ is continuous, this might be an unrealistic measure of performance. Thus, it would be interesting to see whether our results can be generalized to the case where $\\mathcal{X}$ is continuous and the guarantee of Predictors is defined in terms of $\\ell_{p}$ losses. ", "page_idx": 9}, {"type": "text", "text": "Acknowledgments and Disclosure of Funding ", "text_level": 1, "page_idx": 10}, {"type": "text", "text": "VR acknowledges the support from the NSF Graduate Research Fellowship Program. ", "page_idx": 10}, {"type": "text", "text": "References ", "text_level": 1, "page_idx": 10}, {"type": "text", "text": "Matteo Almanza, Flavio Chierichetti, Silvio Lattanzi, Alessandro Panconesi, and Giuseppe Re. Online facility location with multiple advice. Advances in Neural Information Processing Systems, 34:4661\u20134673, 2021.   \nNoga Alon, Roi Livni, Maryanthe Malliaris, and Shay Moran. Private pac learning implies finite littlestone dimension. In Proceedings of the 51st Annual ACM SIGACT Symposium on Theory of Computing, pages 852\u2013860, 2019.   \nAntonios Antoniadis, Christian Coester, Marek Eli\u00e1\u0161, Adam Polak, and Bertrand Simon. Online metric algorithms with untrusted predictions. ACM Transactions on Algorithms, 19(2):1\u201334, 2023.   \nSanjeev Arora, Elad Hazan, and Satyen Kale. The multiplicative weights update method: a metaalgorithm and applications. Theory of computing, 8(1):121\u2013164, 2012.   \nEtienne Bamas, Andreas Maggiori, and Ola Svensson. The primal-dual method for learning augmented algorithms. Advances in Neural Information Processing Systems, 33:20083\u201320094, 2020.   \nShai Ben-David, Eyal Kushilevitz, and Yishay Mansour. Online learning versus offline learning. Machine Learning, 29:45\u201363, 1997.   \nShai Ben-David, D\u00e1vid P\u00e1l, and Shai Shalev-Shwartz. Agnostic online learning. In COLT, volume 3, page 1, 2009.   \nAdam Block, Yuval Dagan, Noah Golowich, and Alexander Rakhlin. Smoothed online learning is as easy as statistical learning. In Conference on Learning Theory, pages 1716\u20131786. PMLR, 2022.   \nT. Ceccherini-Silberstein, M. Salvatori, and E. Sava-Huss. Groups, Graphs and Random Walks. London Mathematical Society Lecture Note Series. Cambridge University Press, 2017. doi: 10.1017/9781316576571.   \nNicolo Cesa-Bianchi and G\u00e1bor Lugosi. Prediction, learning, and games. Cambridge university press, 2006.   \nJustin Chen, Sandeep Silwal, Ali Vakilian, and Fred Zhang. Faster fundamental graph algorithms via learned predictions. In International Conference on Machine Learning, pages 3583\u20133602. PMLR, 2022.   \nAmit Daniely, Sivan Sabato, Shai Ben-David, and Shai Shalev-Shwartz. Multiclass learnability and the erm principle. In Sham M. Kakade and Ulrike von Luxburg, editors, Proceedings of the 24th Annual Conference on Learning Theory, volume 19 of Proceedings of Machine Learning Research, pages 207\u2013232, Budapest, Hungary, 09\u201311 Jun 2011. PMLR.   \nMarek Elias, Haim Kaplan, Yishay Mansour, and Shay Moran. Learning-augmented algorithms with explicit predictors. arXiv preprint arXiv:2403.07413, 2024.   \nJon C Ergun, Zhili Feng, Sandeep Silwal, David P Woodruff, and Samson Zhou. Learning-augmented $k$ -means clustering. arXiv preprint arXiv:2110.14094, 2021.   \nSreenivas Gollapudi and Debmalya Panigrahi. Online algorithms for rent-or-buy with expert advice. In International Conference on Machine Learning, pages 2319\u20132327. PMLR, 2019.   \nNika Haghtalab. Foundation of Machine Learning, by the People, for the People. PhD thesis, Carnegie Mellon University, 2018.   \nNika Haghtalab, Tim Roughgarden, and Abhishek Shetty. Smoothed analysis of online and differentially private learning. Advances in Neural Information Processing Systems, 33:9203\u20139215, 2020.   \nSteve Hanneke, Shay Moran, Vinod Raman, Unique Subedi, and Ambuj Tewari. Multiclass online learning and uniform convergence. Proceedings of the 36th Annual Conference on Learning Theory (COLT), 2023.   \nSteve Hanneke, Shay Moran, and Jonathan Shafer. A trichotomy for transductive online learning. Advances in Neural Information Processing Systems, 36, 2024.   \nChen-Yu Hsu, Piotr Indyk, Dina Katabi, and Ali Vakilian. Learning-based frequency estimation algorithms. In International Conference on Learning Representations, 2019.   \nShaofeng H-C Jiang, Erzhi Liu, You Lyu, Zhihao Gavin Tang, and Yubo Zhang. Online facility location with predictions. arXiv preprint arXiv:2110.08840, 2021.   \nTim Kraska, Alex Beutel, Ed H Chi, Jeffrey Dean, and Neoklis Polyzotis. The case for learned index structures. In Proceedings of the 2018 international conference on management of data, pages 489\u2013504, 2018.   \nSilvio Lattanzi, Thomas Lavastida, Benjamin Moseley, and Sergei Vassilvitskii. Online scheduling via learned weights. In Proceedings of the Fourteenth Annual ACM-SIAM Symposium on Discrete Algorithms, pages 1859\u20131877. SIAM, 2020.   \nHonghao Lin, Tian Luo, and David Woodruff. Learning augmented binary search trees. In International Conference on Machine Learning, pages 13431\u201313440. PMLR, 2022.   \nNicholas Littlestone. Mistake bounds and logarithmic linear-threshold learning algorithms. University of California, Santa Cruz, 1989.   \nNick Littlestone. Learning quickly when irrelevant attributes abound: A new linear-threshold algorithm. Machine Learning, 2:285\u2013318, 1987.   \nThodoris Lykouris and Sergei Vassilvitskii. Competitive caching with machine learned advice. Journal of the ACM (JACM), 68(4):1\u201325, 2021.   \nMichael Mitzenmacher and Sergei Vassilvitskii. Algorithms with predictions. Communications of the ACM, 65(7):33\u201335, 2022.   \nManish Purohit, Zoya Svitkina, and Ravi Kumar. Improving online algorithms via ml predictions. Advances in Neural Information Processing Systems, 31, 2018.   \nAlexander Rakhlin, Karthik Sridharan, and Ambuj Tewari. Online learning: Stochastic, constrained, and smoothed adversaries. Advances in neural information processing systems, 24, 2011.   \nVinod Raman, Unique Subedi, and Ambuj Tewari. The complexity of sequential prediction in dynamical systems. arXiv preprint arXiv:2402.06614, 2024.   \nTim Roughgarden. Beyond the worst-case analysis of algorithms. Cambridge University Press, 2021.   \nZiv Scully, Isaac Grosof, and Michael Mitzenmacher. Uniform bounds for scheduling with job size estimates. arXiv preprint arXiv:2110.00633, 2021.   \nDaniel A Spielman and Shang-Hua Teng. Smoothed analysis: an attempt to explain the behavior of algorithms in practice. Communications of the ACM, 52(10):76\u201384, 2009.   \nShufan Wang, Jian Li, and Shiqiang Wang. Online algorithms for multi-shop ski rental with machine learned advice. Advances in Neural Information Processing Systems, 33:8150\u20138160, 2020.   \nAlexander Wei and Fred Zhang. Optimal robustness-consistency trade-offs for learning-augmented online algorithms. Advances in Neural Information Processing Systems, 33:8042\u20138053, 2020.   \nChanglong Wu, Ananth Grama, and Wojciech Szpankowski. Online learning in dynamically changing environments. In The Thirty Sixth Annual Conference on Learning Theory, pages 325\u2013358. PMLR, 2023. ", "page_idx": 10}, {"type": "text", "text": "", "page_idx": 11}, {"type": "text", "text": "A Combinatorial dimensions ", "text_level": 1, "page_idx": 12}, {"type": "text", "text": "In this section, we review existing combinatorial dimensions in statistical learning theory. We start with the VC and Natarajan dimensions which characterize PAC learnability when $|\\mathcal{D}|\\,=\\,2$ and $|\\mathcal{D}|<\\infty$ respectively. ", "page_idx": 12}, {"type": "text", "text": "Definition 3 (VC dimension). A set $\\{x_{1},...,x_{n}\\}\\,\\in\\,{\\mathcal{X}}$ is shattered by $\\mathcal{H}$ , $i f\\,\\forall y_{1},...,y_{n}\\,\\in\\,\\{0,1\\},$ , $\\exists h\\in{\\mathcal{H}}$ , such that $\\forall i\\in[n]$ , $h(x_{i})=y_{i}$ . The VC dimension of $\\mathcal{H}$ , denoted $\\operatorname{VC}({\\mathcal{H}})$ , is defined as the largest natural number $n\\in\\mathbb N$ such that there exists a set $\\{x_{1},...,x_{n}\\}\\in\\mathcal{X}$ that is shattered by $\\mathcal{H}$ . ", "page_idx": 12}, {"type": "text", "text": "Definition 4 (Natarajan Dimension). $A$ set $S=\\{x_{1},\\ldots,x_{d}\\}$ is shattered by a multiclass function class $\\mathcal{H}\\subseteq\\mathcal{V}^{\\mathcal{X}}$ if there exist two witness functions $f,g:S\\to\\mathcal{Y}$ such that $f(x_{i})\\neq g(x_{i})$ for all $i\\in[d]$ , and for every $\\sigma\\in\\{0,1\\}^{d}$ , there exists a function $h_{\\sigma}\\in\\mathcal{H}$ such that for all $i\\in[d]$ , we have ", "page_idx": 12}, {"type": "equation", "text": "$$\nh_{\\sigma}(x_{i})=\\left\\{f(x_{i})\\ \\quad i f\\sigma_{i}=1\\right.\\ \\ .\n$$", "text_format": "latex", "page_idx": 12}, {"type": "text", "text": "The Natarajan dimension of $\\mathcal{H}$ , denoted $\\mathrm{{N}}(\\mathcal{H})$ , is the size of the largest shattered set $S\\subseteq\\mathcal{X}$ . If the size of the shattered set can be arbitrarily large, we say that $\\mathrm{N}(\\mathcal{H})=\\infty$ . ", "page_idx": 12}, {"type": "text", "text": "We note that $\\mathrm{N}(\\mathcal{H})=\\mathrm{VC}(\\mathcal{H})$ whenever $|\\mathcal{V}|=2$ . Next, we move to the online setting, where the Littlestone dimension (Ldim) characterizes multiclass online learnability. To define the Ldim, we first define a Littlestone tree and a notion of shattering. ", "page_idx": 12}, {"type": "text", "text": "Definition 5 (Littlestone tree). A Littlestone tree of depth $d$ is a complete binary tree of depth $d$ where the internal nodes are labeled by examples of $\\mathcal{X}$ and the left and right outgoing edges from each internal node are labeled by 0 and 1 respectively. ", "page_idx": 12}, {"type": "text", "text": "Given a Littlestone tree $\\tau$ of depth $d$ , a root-to-leaf path down $\\tau$ is a bitstring $\\sigma\\in\\{0,1\\}^{d}$ indicating whether to go left $\\left.\\sigma_{i}\\right.=0$ ) or to go right $(\\sigma_{i}\\,=\\,1)$ ) at each depth $i\\,\\in\\,[d]$ . A path $\\sigma\\,\\in\\,\\{0,1\\}^{d}$ down $\\tau$ gives a sequence of labeled examples $\\{(x_{i},\\sigma_{i})\\}_{i=1}^{d}$ , where $x_{i}$ is the example labeling the internal node following the prefix $(\\sigma_{1},...,\\sigma_{i-1})$ down the tree. A hypothesis $h_{\\sigma}\\in\\mathcal{H}$ shatters a path $\\sigma\\in\\{0,1\\}^{d}$ , if for every $i\\in[d]$ , we have $h_{\\sigma}(x_{i})=\\sigma_{i}$ . In other words, $h_{\\sigma}$ is consistent with the labeled examples when following $\\sigma$ . A Littlestone tree $\\tau$ is shattered by $\\mathcal{H}$ if for every root-to-leaf path $\\sigma$ down $\\tau$ , there exists a hypothesis $h_{\\sigma}\\in\\mathcal{H}$ that shatters it. Using this notion of shattering, we define the Littlestone dimension of a hypothesis class. ", "page_idx": 12}, {"type": "text", "text": "Definition 6 (Littlestone dimension). The Littlestone dimension of $\\mathcal{H}$ , denoted $\\mathtt{L}({\\mathcal{H}})$ , is the largest $d\\in\\mathbb{N}$ such that there exists a Littlestone tree $\\tau$ of depth $d$ shattered by $\\mathcal{H}$ . If there exists shattered Littlestone trees $\\tau$ of arbitrary depth, then we say that $\\mathtt{L}(\\mathcal{H})=\\infty$ . ", "page_idx": 12}, {"type": "text", "text": "Finally, the following notion of shattering is useful when proving the lower bound in Appendix E. ", "page_idx": 12}, {"type": "text", "text": "Definition 7 (Threshold shattering). A sequence $(x_{1},...,x_{k})\\in\\mathcal{X}^{k}$ is threshold-shattered by $\\mathcal{H}\\subseteq$ $\\{0,1\\}^{\\mathcal{X}}$ if there exists $(h_{1},...,h_{k})\\in\\mathcal{H}^{k}$ such that $h_{i}(x_{j})=\\mathbb{1}\\{j\\leq i\\}$ for all $i,j\\in[k]$ . ", "page_idx": 12}, {"type": "text", "text": "B Proof of Lemmas 3.6 and 3.7 ", "text_level": 1, "page_idx": 12}, {"type": "text", "text": "Proof. (of Lemma 3.6) Let $(x_{1},y_{1}),...,(x_{T},y_{T})$ be the realizable stream to be observed by the Expert. For every $i\\,\\in\\,\\{0,...,c\\}$ , let $m_{i}$ be the random variable denoting the number of mistakes made by $\\mathcal{P}$ in rounds $\\{\\tilde{t}_{i}+1,...,\\tilde{t}_{i+1}\\}$ . Recall that $\\tilde{t}_{0}=0$ and $\\tilde{t}_{c+1}=T$ . Let $\\begin{array}{r}{M=\\sum_{i=0}^{c}m_{i}}\\end{array}$ be the random variable denoting the total number of mistakes made by $\\mathcal{P}$ on the realizable stream. Finally, let $\\boldsymbol{\\mathcal{A}}$ denote Algorithm 4. Observe that, ", "page_idx": 12}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{E}\\left[\\displaystyle\\sum_{t=1}^{T}\\mathbb{1}\\{A(x_{t})\\neq y_{t}\\}\\right]=\\mathbb{E}\\left[\\displaystyle\\sum_{i=0}^{c}\\sum_{t=\\tilde{t}_{i}+1}^{\\tilde{t}_{i+1}}\\mathbb{1}\\{A(x_{t})\\neq y_{t}\\}\\right]}\\\\ &{\\phantom{\\mathbb{E}\\left[\\displaystyle\\sum_{t=1}^{c}\\sum_{t=0}^{\\tilde{t}_{i+1}}\\mathbb{1}\\{K_{i}(x_{t})\\neq y_{t}\\}\\right]}}\\\\ &{\\phantom{\\mathbb{E}\\left[\\displaystyle\\sum_{i=0}^{c}(m_{i}+1)\\overline{{\\mathbb{M}_{B}(\\tilde{t}_{i+1}-\\tilde{t}_{i},\\mathcal{H})}}\\right]}\\end{array}\n$$", "text_format": "latex", "page_idx": 12}, {"type": "text", "text": "where the first inequality follows from the guarantee of $\\kappa$ and Lemma 2.2. Using Jensen\u2019s inequality, we get that ", "page_idx": 13}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\mathfrak{T}\\left[\\sum_{i=0}^{c}(m_{i}+1)\\overline{{\\mathrm{M}_{B}(\\tilde{t}_{i+1}-\\tilde{t}_{i},\\mathcal{H})}}\\right]\\leq\\mathbb{E}\\left[\\left(\\sum_{i=0}^{c}(m_{i}+1)\\right)\\overline{{\\mathrm{M}_{B}\\left(\\frac{\\sum_{i=0}^{c}(m_{i}+1)(\\tilde{t}_{i+1}-\\tilde{t}_{i})}{\\sum_{i=0}^{c}(m_{i}+1)},\\mathcal{H}\\right)}}\\right]}&{}\\\\ {=\\mathbb{E}\\left[\\left(M+c+1\\right)\\overline{{\\mathrm{M}_{B}\\left(\\frac{\\sum_{i=0}^{c}(m_{i}+1)(\\tilde{t}_{i+1}-\\tilde{t}_{i})}{M+c+1},\\mathcal{H}\\right)}}\\right]}&{}\\\\ {=\\mathbb{E}\\left[\\left(M+c+1\\right)\\overline{{\\mathrm{M}_{B}\\left(\\frac{\\sum_{i=0}^{c}m_{i}\\left(\\tilde{t}_{i+1}-\\tilde{t}_{i}\\right)+T}{M+c+1},\\mathcal{H}\\right)}}\\right]}&{}\\\\ {=\\mathbb{E}\\left[\\left(M+c+1\\right)\\overline{{\\mathrm{M}_{B}\\left(\\frac{\\lceil\\frac{T}{c+1}\\rceil\\sum_{i=0}^{c}m_{i}(i+1-i)+T}{M+c+1},\\mathcal{H}\\right)}}\\right]}&{}\\\\ {=\\mathbb{E}\\left[\\left(M+c+1\\right)\\overline{{\\mathrm{M}_{B}\\left(\\frac{\\lceil\\frac{T}{c+1}\\rceil\\sum_{i=0}^{c}m_{i}(i+1-i)+T}{M+c+1},\\mathcal{H}\\right)}}\\right]}&{}\\\\ {=\\mathbb{E}\\left[\\left(M+c+1\\right)\\overline{{\\mathrm{M}_{B}\\left(\\frac{\\sum_{i=1}^{c}\\ M+T}{M+c+1},\\mathcal{H}\\right)}}\\right].}\\end{array}\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "Using the fact that $\\begin{array}{r}{\\lceil\\frac{T}{c+1}\\rceil\\leq\\frac{T}{c+1}+1}\\end{array}$ , we have ", "page_idx": 13}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{E}\\left[\\displaystyle\\sum_{i=0}^{c}\\displaystyle\\sum_{j=0}^{m_{i}}\\overline{{\\mathbf{M}}}_{B}(\\tilde{t}_{i+1}-\\tilde{t}_{i},\\mathcal{H})\\right]\\leq\\mathbb{E}\\left[\\Big(M+c+1\\Big)\\overline{{\\mathbf{M}}}_{B}\\Bigg(\\displaystyle\\frac{\\frac{M T}{c+1}+M+T}{M+c+1},\\mathcal{H}\\Bigg)\\right]}\\\\ &{\\qquad\\qquad\\qquad\\leq\\mathbb{E}\\left[\\Big(M+c+1\\Big)\\overline{{\\mathbf{M}}}_{B}\\Bigg(\\displaystyle\\frac{T}{c+1}+1,\\mathcal{H}\\Bigg)\\right]}\\\\ &{\\qquad\\qquad\\qquad=\\Big(\\mathbf{M}_{\\mathcal{P}}(x_{1:T})+c+1\\Big)\\overline{{\\mathbf{M}}}_{B}\\Bigg(\\displaystyle\\frac{T}{c+1}+1,\\mathcal{H}\\Bigg),}\\end{array}\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "which completes the proof. ", "page_idx": 13}, {"type": "text", "text": "Proof. (of Lemma 3.7) Let $(x_{1},y_{1}),...,(x_{T},y_{T})$ be the realizable stream to be observed by the learner. Let $\\boldsymbol{\\mathcal{A}}$ denote the online learner in Algorithm 5. By the guarantees of the DWMA, we have ", "page_idx": 13}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\frac{\\Sigma}{\\varepsilon}\\left[\\displaystyle\\sum_{t=1}^{T}\\mathbb{1}\\{\\mathcal{A}(x_{t})\\neq y_{t}\\}\\right]\\leq3\\mathbb{E}\\left[\\displaystyle\\operatorname*{inf}_{b\\in\\{0,\\ldots,T-1\\}}\\displaystyle\\sum_{t=1}^{T}\\mathbb{1}\\{E_{b}(x_{t})\\neq y_{t}\\}\\right]+3\\log_{2}T}\\\\ &{\\phantom{\\frac{\\sum{\\sum{\\operatorname*{max}}\\bigg[\\displaystyle\\sum_{t=1}^{T}\\mathbb{1}\\{E_{[\\mathrm{M}_{P}(x_{1:T})]}(x_{t})\\neq y_{t}\\}\\bigg]+3\\log_{2}T}}{\\sum_{t=1}^{T}\\mathbb{1}\\{E_{[\\mathrm{M}_{P}(x_{1:T})]}(x_{t})\\neq y_{t}\\}}+3\\log_{2}T}\\\\ &{\\leq3(\\mathrm{M}_{P}(x_{1:T})+\\lceil\\mathrm{M}_{P}(x_{1:T})\\rceil+1)\\overline{{\\mathrm{M}}}_{B}\\Big(\\displaystyle\\frac{T}{\\lceil\\mathrm{M}_{P}(x_{1:T})\\rceil+1}+1,\\mathcal{H}\\Big)+3\\log_{2}T}\\\\ &{\\leq6(\\mathrm{M}_{P}(x_{1:T})+1)\\overline{{\\mathrm{M}}}_{B}\\Big(\\displaystyle\\frac{T}{\\underset{\\mathrm{M}_{P}(x_{1:T})\\leq1}{\\prod_{P}\\left(x_{1:T}\\right)+1}+1}+1,\\mathcal{H}\\Big)+6\\log_{2}T,}\\end{array}\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "where the last inequality follows from Lemma 3.6 and the fact that $\\mathrm{M}_{\\mathcal{P}}(x_{1:T})\\leq\\lceil\\mathrm{M}_{\\mathcal{P}}(x_{1:T})\\rceil\\leq$ $\\mathrm{M}_{\\mathcal{P}}(x_{1:T})+1$ . ", "page_idx": 13}, {"type": "text", "text": "C Proof of Corollary 3.2 and 3.3 ", "text_level": 1, "page_idx": 13}, {"type": "text", "text": "Using Theorem 3.1, we first show that for every $\\mathcal{H}\\subseteq\\mathcal{V}^{\\mathcal{X}}$ , Predictor $P,\\,\\mathcal{Z}\\subseteq\\,\\mathcal{X}^{\\star}$ , and no-regret offline learner $\\boldsymbol{\\mathrm{\\Delta}}\\boldsymbol{\\mathrm{\\Omega}}^{\\beta}$ , we have that ", "page_idx": 13}, {"type": "equation", "text": "$$\n\\mathrm{nf}\\,\\mathrm{M}_{{\\cal A}}(T,\\mathcal{H},\\mathcal{Z})=O\\left(\\mathrm{L}(\\mathcal{H})\\wedge(\\mathrm{M}_{\\mathcal{P}}(T,\\mathcal{Z})+1)\\,\\mathrm{M}_{\\mathcal{B}}(T,\\mathcal{H})\\wedge\\left((\\mathrm{M}_{\\mathcal{P}}(T,\\mathcal{Z})+1)\\,\\overline{{\\mathrm{M}}}_{\\mathcal{B}}\\Big(\\frac{T}{\\mathrm{M}_{\\mathcal{P}}(T,\\mathcal{Z})+1},T\\Big)\\right)\\right).\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "Proof. It suffices to show that Algorithms 3 and 5 have mistake bounds $O((\\mathrm{M}_{\\mathcal{P}}(T,\\mathcal{Z})\\mathrm{~+~}$ $1)\\operatorname{M}_{B}(T,{\\mathcal{H}}))$ and $\\begin{array}{r}{O\\Bigg(\\!\\left(\\mathrm{M}_{\\mathcal{P}}(T,\\mathcal{Z})+1\\right)\\overline{{\\mathrm{M}}}_{\\mathcal{B}}\\bigg(\\frac{T}{\\mathrm{M}_{\\mathcal{P}}(T,\\mathcal{Z})+1},\\mathcal{H}\\bigg)\\!+\\log_{2}T\\Bigg)}\\end{array}$ respectively. To see that Algorithm 3\u2019s mistake bounds is $O((\\mathrm{M}_{\\mathcal{P}}(T,\\mathcal{Z})+1)\\,\\mathrm{M}_{\\mathcal{B}}(T,\\mathcal{H}))$ , note that $\\mathrm{M}_{\\mathcal{P}}(x_{1:T})\\leq\\mathrm{M}_{\\mathcal{P}}(T,\\mathcal{Z})$ for every $x_{1:T}\\ \\in\\ \\mathcal{Z}$ . To see that Algorithm 5\u2019s expected mistake bound is $O\\Bigg((\\mathrm{M}_{\\mathcal{P}}(T,\\mathcal{Z})\\;+$ $\\begin{array}{r}{1)\\,\\overline{{\\mathrm{M}}}_{\\mathcal{B}}\\bigg(\\frac{T}{\\mathrm{M}_{\\mathcal{P}}(T,\\mathcal{Z})+1},\\mathcal{H}\\bigg)\\!+\\!\\log_{2}T\\bigg)}\\end{array}$ , we follow the exact same proof strategy as in the proof of Lemma 3.7, but picking a different expert when upper bounding the expected number of mistakes. Namely, following the same steps as in the proof of Lemma 3.7, we have that ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\mathbb{E}\\left[\\sum_{t=1}^{T}\\mathbb{1}\\{\\mathcal{A}(x_{t})\\neq y_{t}\\}\\right]\\leq3\\mathbb{E}\\left[\\operatorname*{inf}_{b\\in\\{0,\\ldots,T-1\\}}\\sum_{t=1}^{T}\\mathbb{1}\\{E_{b}(x_{t})\\neq y_{t}\\}\\right]+3\\log_{2}T\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "where $\\boldsymbol{\\mathcal{A}}$ denotes Algorithm 5. Picking $b\\,=\\,\\lceil\\mathrm{M}_{\\mathcal{P}}(T,\\mathcal{Z})\\rceil$ , using Lemma 3.6, and the fact that $\\mathrm{M}_{\\mathcal{P}}(x_{1:T})\\leq\\mathrm{M}_{\\mathcal{P}}(T,\\mathcal{Z})$ gives the desired upper bound on $\\mathbb{E}\\left[\\sum_{t=1}^{T}\\mathbb{1}\\{A(x_{t})\\neq y_{t}\\}\\right]$ of ", "page_idx": 14}, {"type": "equation", "text": "$$\nO\\Bigg(\\bigl(\\mathrm{M}_{\\mathcal{P}}(T,\\mathcal{Z})+1\\bigr)\\overline{{\\mathrm{M}}}_{\\mathcal{B}}\\Big(\\frac{T}{\\mathrm{M}_{\\mathcal{P}}(T,\\mathcal{Z})+1},\\mathcal{H}\\Big)\\!+\\log_{2}T\\Bigg),\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "completing the proof. ", "page_idx": 14}, {"type": "text", "text": "Corollary 3.2 follows from the fact that the upper bound on $\\operatorname*{inf}_{A}\\mathrm{M}_{A}(T,\\mathcal{H},\\mathcal{Z})$ is sublinear whenever $\\mathrm{M}_{\\mathcal{P}}(T,\\dot{\\mathcal{Z}})=o(T)$ and $\\mathrm{M}_{\\mathcal{B}}(T,\\mathcal{H})=o(T)$ . To get Corollary 3.3, recall that by Lemma 2.1, there exists an offline learner $\\boldsymbol{\\mathrm{\\Delta}}\\boldsymbol{\\mathrm{\\Omega}}^{\\beta}$ such that ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\overline{{\\mathrm{M}}}_{\\mathcal{B}}(T,\\mathcal{H})=O\\Big(\\mathrm{VC}(\\mathcal{H})\\log_{2}T\\Big).\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "Plugging this bound into upper bound (1) completes the proof. ", "page_idx": 14}, {"type": "text", "text": "D Proof of Theorem 3.1 ", "text_level": 1, "page_idx": 14}, {"type": "text", "text": "Let $\\boldsymbol{\\mathcal{A}}$ denote the DWMA using the Standard Optimal Algorithm (SOA), Algorithm 3 and Algorithm 5 as experts. Then, for any realizable stream $(x_{1},y_{1}),...,(x_{T},y_{T})$ , Lemma 3.4 gives that ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\mathbb{E}\\left[\\sum_{t=1}^{T}\\mathbb{1}\\{\\mathcal{A}(x_{t})\\neq y_{t}\\}\\right]\\leq3\\mathbb{E}\\left[\\operatorname*{min}_{i\\in[3]}M_{i}+\\log_{2}3\\right]\\leq3\\operatorname*{min}_{i\\in[3]}\\mathbb{E}\\left[M_{i}\\right]+5,\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "where we take $M_{1},M_{2}$ and $M_{3}$ to be the number of mistakes made by the SOA, Algorithm 3, and Algorithm 5 respectively. Note that $M_{2}$ and $M_{3}$ are random variables since $\\boldsymbol{\\mathrm{\\Delta}}\\boldsymbol{\\mathrm{\\Omega}}_{\\boldsymbol{B}}$ and $\\mathcal{P}$ may be randomized algorithms. Finally, using Lemma 3.5, Lemma 3.7 and the fact that the SOA makes at most $\\operatorname{L}({\\mathcal{H}})$ mistakes on any realizable stream [Littlestone, 1987] completes the proof of Theorem 3.1. ", "page_idx": 14}, {"type": "text", "text": "E Proof of Theorem 3.8 ", "text_level": 1, "page_idx": 14}, {"type": "text", "text": "Let $\\mathcal{X}=\\mathbb{R}\\cup\\{\\star\\}$ and ${\\mathcal{H}}=\\{x\\mapsto\\mathbb{1}\\{x\\leq a\\}\\mathbb{1}\\{x\\neq\\star\\}\\}$ . Let $T,n\\in\\mathbb{N}$ be chosen such that $T$ is a multiple of $n+1$ and $\\textstyle{\\frac{T}{n+1}}+1=2^{k}$ for some $k\\in\\mathbb{N}$ . Our proof of Theorem 3.8 will be in four steps, as described below. ", "page_idx": 14}, {"type": "text", "text": "(1) We construct a class of streams $\\mathcal{Z}_{n}\\subseteq\\mathcal{X}^{\\star}$ . ", "page_idx": 14}, {"type": "text", "text": "(2) Using ${\\mathcal{Z}}_{n}$ , we construct a deterministic, lazy, consistent Predictor $\\mathcal{P}$ such that $\\mathcal{P}$ makes mistakes exactly on timepoints {nT+1 $\\{{\\textstyle{\\frac{T}{n+1}}}+1,...,{\\frac{n T}{n+1}}+1\\}$ for every stream $x_{1:T}\\in\\mathcal{Z}_{n}$ . ", "page_idx": 14}, {"type": "text", "text": "(3) When $x_{1:T}\\in\\mathcal{Z}_{n}$ , we establish an equivalence between the game defined by Protocol 2 when given access to Predictor $\\mathcal{P}$ and Online Classification with Peeks, a different game $\\begin{array}{r}{t\\in\\{1,\\frac{T}{n+1}+1,...,\\frac{n T}{n+1}+1\\}.}\\end{array}$ .t the learner observes the next $\\textstyle{\\frac{T}{n+1}}$ examples at timepoints ", "page_idx": 15}, {"type": "text", "text": "(4) For Online Classification with Peeks, we give a strategy for Nature such that it can force tahney  sotrnelainme  olef alranbeerl etdo  emxaakmeples it p2icks $(x_{1},y_{1}),...,(x_{T},y_{T})$ cstaattiisofnie sw thhiel ec eonnssturraiinngt  tthhaatt $x_{1:T}\\in\\mathcal{Z}_{n}$ and $\\begin{array}{r}{\\operatorname*{inf}_{h\\in\\mathcal{H}}\\sum_{t=1}^{T}\\mathbb{1}\\{h(x_{t})\\neq y_{t}\\}=0}\\end{array}$ . ", "page_idx": 15}, {"type": "text", "text": "PCrootmopcools i2n gu ssitneg $\\mathcal{P}$ ,1 t-h4e rseh eoxwisst st ha er eeaxliisztaebnlce es troef aam  Pwrehdeircet $\\boldsymbol{\\mathcal{A}}$ $\\mathcal{P}$ a kseusc hat  tlheaats tf $\\textstyle{\\frac{(n+1)^{\\cdot}}{2}}\\log_{2}({\\frac{T}{n+1}})$ $\\boldsymbol{\\mathcal{A}}$ mpilsatyaiknegs in expectation. ", "page_idx": 15}, {"type": "text", "text": "Step 1: Construction of ${\\mathcal{Z}}_{n}$ ", "text_level": 1, "page_idx": 15}, {"type": "text", "text": "Let $\\boldsymbol{S}$ be the set of all strictly increasing sequences of real numbers in $(0,1)$ of size $\\textstyle{\\frac{T}{n+1}}$ . Fix a function $f:\\mathbb{R}^{2}\\to S$ which, given $a<b\\in\\mathbb{R}$ , outputs an element of $\\boldsymbol{S}$ that lies strictly in between $a$ and $b$ . For example, given $a<b\\in\\mathbb{R}$ , the function $f$ can output evenly spaced real numbers of size $\\textstyle{\\frac{T}{n+1}}$ . Let Dyd : $\\bar{S}\\rightarrow\\bar{X}^{\\frac{T}{n+1}}$ be a function that reorders the input $S\\in S$ in Dyadic order. Namely, if $\\boldsymbol{S}=(x_{1},...,x_{N})$ where $N+1=2^{k}$ for some $k\\in\\mathbb{N}$ , then $\\mathrm{Dyd}(S)$ is ", "page_idx": 15}, {"type": "equation", "text": "$$\nx_{\\frac{N}{2}},x_{\\frac{N}{4}},x_{\\frac{3N}{4}},x_{\\frac{N}{8}},x_{\\frac{3N}{8}},x_{\\frac{5N}{8}},x_{\\frac{7N}{8}},...,x_{\\frac{(2^{k}-1)N}{2^{k}}}.\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "See the Proof of Claim 3.4 in Hanneke et al. [2024] for a more detailed description of a Dyadic order. On the other hand, let Sor $\\because\\chi^{\\frac{T}{n+1}}\\to S$ be a function that reorders its input in increasing order. Let $\\begin{array}{r}{\\mathcal{I}:=\\{1,...,\\frac{T}{n+1}+1\\}^{\\leq n}}\\end{array}$ be the set of all sequences of indices of length at most $n$ taking values in $\\{1,...,\\frac{T}{n+1}+1\\}$ . For the remainder of this section, we will use $S_{i}$ to denote the $i$ th element in a sequence $S\\in S$ . Moreover, for any two sequences $S^{1},S^{2}\\in{\\mathcal{S}}$ , we say $S^{1}<S^{2}$ if $S_{|S^{1}|}^{1}<S_{1}^{2}$ . That is, $S^{1}<S^{2}$ , if $S^{1}$ lies strictly to the left of $S^{2}$ . ", "page_idx": 15}, {"type": "table", "img_path": "MB0DD5qAz8/tmp/6a6d7666aa0299c77d5a7485d473bdb39711db297dcf47184ee975cd7c495ff6.jpg", "table_caption": [], "table_footnote": [], "page_idx": 15}, {"type": "text", "text": "17 Return: $\\mathrm{Dyd}(S^{0})\\circ\\dots\\circ\\mathrm{Dyd}(S^{m})$ ", "page_idx": 15}, {"type": "text", "text": "We will construct a stream for every sequence $j_{1:m}\\in\\mathcal{I}$ , $m\\leq n$ , algorithmically as follows. Fix $S^{0}:=f(0,1)\\in\\mathcal{S}$ and let SG denote Algorithm 6. Let ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\mathcal{Z}_{n}=\\left\\{\\mathrm{SG}(S^{0},j_{1:m}):j_{1:m}\\in\\mathcal{I},m\\in\\{1,...,n\\}\\right\\}\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "denote the stream class generated by applying SG to inputs $S^{0}$ and $j_{1:m}$ for every $j_{1:m}\\in\\mathcal{I},m\\le n$ . We make four important observations about ${\\mathcal{Z}}_{n}$ , which we will use to construct a Predictor that can reconstruct $S^{i}$ given $S^{0}$ and the first example of the block $S^{i-1}$ . ", "page_idx": 16}, {"type": "text", "text": "Observation 1. For every sequence $x_{1:T}\\in\\mathcal{Z}$ , we have that $x_{1:\\frac{T}{n+1}}=\\mathrm{Dyd}(S^{0}).$ . ", "page_idx": 16}, {"type": "text", "text": "The first observation follows from the fact that the same initial sequence $S^{0}$ is used to generate every stream in ${\\mathcal{Z}}_{n}$ . ", "page_idx": 16}, {"type": "text", "text": "Observation 2. For any pair $j_{1:n}^{1},j_{1:n}^{2}\\,\\in\\,{\\mathcal{I}}$ and $m\\,\\leq\\,n,$ , if $j_{1:m}^{1}\\,=\\,j_{1:m}^{2}$ , then $\\mathrm{SG}(S^{0},j_{1:m}^{1})\\,=$ $\\mathrm{SG}(S^{0},j_{1:m}^{2})$ . ", "page_idx": 16}, {"type": "text", "text": "The second observation follows from the fact that SG is deterministic. ", "page_idx": 16}, {"type": "text", "text": "Observation 3. For every $x_{1:T}\\in\\mathcal{Z}_{n}$ such that $x_{1:T}:=\\mathrm{SG}(S^{0},j_{1:n})=\\mathrm{Dyd}(S^{0})\\circ...\\circ\\mathrm{Dyd}(S^{n}),$ , the index $j_{i}$ can be computed exactly using only $S^{i-1}$ and $S_{1}^{i}$ for every $i\\in[n]$ . ", "page_idx": 16}, {"type": "text", "text": "To see the third observation, fix some $x_{1:T}\\in\\mathcal{Z}_{n}$ . Then, there exists a sequence $S^{1},...,S^{n}\\in{\\mathcal{S}}$ such that $x_{1:T}=\\mathrm{Dyd}(S^{0})\\circ...\\circ\\mathrm{Dyd}(S^{n})$ as well as a sequence $(a_{0},b_{0}),...,(a_{n},b_{n})$ . In addition, there exists a $j_{1:n}\\in\\mathcal{I}$ such that $x_{1:T}=\\mathrm{SG}(S^{0},j_{1:n})$ . Fix $i\\in[n]$ and consider $S^{i-1}$ and $S^{i}$ . By definition of Algorithm 6, there exists an index $q\\in\\{1,...,\\frac{T}{n+1}+1\\}$ such that $S^{i}=f(S_{q-1}^{i-1},S_{q}^{i-1})$ where we take \u22121= ai\u22121 and Si\u2212T1 $S_{\\frac{T}{n+1}+1}^{i-1}=b_{i-1}$ . We claim that the index $q$ is unique. This follows from the fact that the collection $\\{f(S_{j}^{i-1},S_{j+1}^{i-1})\\}_{j=0}^{\\frac{T}{n+1}}$ is pairwise disjoint since $a_{i-1}=S_{0}^{i-1}<S_{1}^{i-1}<...<$ $S_{\\frac{T}{n+1}}^{i-1}<S_{\\frac{T}{n+1}+1}^{i-1}=b_{i-1}$ . Finally, we claim that and the element $S_{1}^{i}$ identifies the index $q$ . This follows because $f(a_{i-1},S_{1}^{i-1})<f(S_{1}^{i-1},S_{2}^{i-1})<\\ldots<f(S_{\\frac{T}{n+1}-1}^{i-1},S_{\\frac{T}{n+1}}^{i-1})<f(S_{\\frac{T}{n+1}}^{i-1},b_{i-1})$ and thus $q$ is the smallest index $p\\in\\{1,...,\\frac{T}{n+1}\\}$ such that $S_{1}^{i}<S_{p}^{i-1}$ i\u22121and nT+1 + 1 if such a p does not exist. ", "page_idx": 16}, {"type": "text", "text": "Observation 4. Fix a sequence $j_{1:n}\\in\\mathcal{I}$ and let $\\mathrm{Dyd}(S^{0})\\circ...\\circ\\mathrm{Dyd}(S^{n})=\\mathrm{SG}(S^{0},j_{1:n})$ . For every $i,p\\in[n]$ such that $i<p$ , we have that: ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\begin{array}{r}{(i i i)\\;\\;S^{i}<S^{p}\\;i f\\;j_{i}=\\frac{T}{n+1}+1.}\\end{array}\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "The fourth observation follows from the fact that for every $i\\in[n]$ and index $j_{i}\\in\\{1,...,\\frac{T}{n+1}+1\\}$ , the remaining sequence of sets $S^{i+1},...,S^{n}$ all lie in the interval $(S_{j_{i}-1}^{i},S_{j_{i}}^{i})$ by design of Algorithm 6, where again we take $S_{0}^{i-1}=a_{i-1}<S_{1}^{i-1}$ and $S_{\\frac{T}{n+1}+1}^{i-1}=b_{i-1}>S_{\\frac{T}{n+1}}^{i-\\bar{1}}$ ", "page_idx": 16}, {"type": "text", "text": "Step 2: Constructing a Predictor for ${\\mathcal{Z}}_{n}$ ", "text_level": 1, "page_idx": 16}, {"type": "text", "text": "We now show that Algorithm 7 is a lazy, consistent Predictor for ${\\mathcal{Z}}_{n}$ that only makes mistakes at timepoints $\\{{\\frac{T}{n+1}}+1,...,{\\frac{n T}{n+1}}+1\\}$ . ", "page_idx": 16}, {"type": "text", "text": "Lemma E.1. For any sequence $x_{1:T}\\in\\mathcal{Z}_{n}$ , Algorithm 7 is a lazy, consistent Predictor for ${\\mathcal{Z}}_{n}$ that only makes mistakes at timepoints $\\{{\\textstyle{\\frac{T}{n+1}}}+1,...,{\\frac{n T}{n+1}}+1\\}$ . ", "page_idx": 16}, {"type": "text", "text": "Proof. Let $\\mathcal{P}$ denote Algorithm 7 and $x_{1:T}\\in\\mathcal{Z}_{n}$ . Then, there exists $S^{1},...,S^{n}\\in{\\mathcal{S}}$ and a sequence of indices $j_{1:n}\\in\\mathcal{I}$ such that $x_{1:T}=\\mathrm{Dyd}(S^{0})\\circ\\mathrm{Dyd}(S^{1})\\circ...\\circ\\mathrm{Dyd}(S^{n})=\\mathrm{SG}(S^{0},j_{1:n}).$ . ", "page_idx": 16}, {"type": "text", "text": "We now prove that $\\mathcal{P}$ makes mistakes only on timepoints $\\{{\\textstyle{\\frac{T}{n+1}}}+1,...,{\\textstyle{\\frac{n T}{n+1}}}+1\\}$ and no where else. Our proof is by induction using the following inductive hypothesis. For every $i\\in\\{1,...,n\\}$ , we have that $\\mathcal{P}$ : ", "page_idx": 16}, {"type": "text", "text": "(i) sets $J_{1:i}=j_{1:i}$ on round n+1 + 1 ;   \n(ii) makes mistakes on rounds $\\begin{array}{r}{\\{\\frac{T}{n+1}+1,\\frac{2T}{n+1}+1,...,\\frac{i T}{n+1}+1\\}}\\end{array}$ and no where in between. ", "page_idx": 16}, {"type": "text", "text": "Input: ${\\mathcal{Z}}_{n}$   \n1 Initialize: $J=()$   \n2 for $t=1,..,T$ do   \n3 Receive $x_{t}$   \n4 if $t=1$ then   \n5 Set $\\begin{array}{r}{\\hat{x}_{1:T}^{t}=\\mathrm{Dyd}(S^{0})\\circ\\hat{x}_{\\frac{T}{n+1}+1:T}}\\end{array}$ where $\\hat{x}_{\\frac{T}{n+1}+1:T}=(\\star,...,\\star)$ .   \n6 else if $\\begin{array}{r}{t=\\frac{i T}{n+1}+1}\\end{array}$ for some $i\\in\\{1,...,n\\}$ then   \n7 Let $S=\\mathrm{Sort}(x_{t-\\frac{T}{n+1}:t-1})$ be the last $\\textstyle{\\frac{T}{n+1}}$ examples sorted in increasing order.   \n8 Find the smallest $j\\in\\{1,...,\\frac{T}{n+1}\\}$ such that $x_{t}<S_{j}$ . If no such $j$ exists, set $\\begin{array}{r}{j=\\frac{T}{n+1}+1}\\end{array}$ .   \n9 Update $J\\leftarrow J\\circ j$ .   \n10 Set $\\hat{x}_{1:T}^{t}=\\mathrm{SG}(S^{0},J)\\circ\\hat{x}_{t+\\frac{T}{n+1}:T}$ where $\\hat{x}_{t+\\frac{T}{n+1}:T}=(\\star,...,\\star)$ .   \n11 else   \n12 Set x\u02c6t1:T $\\hat{x}_{1:T}^{t}\\gets\\hat{x}_{1:T}^{t-1}$ .   \n13 end   \n14 Predict $\\hat{x}_{1:T}^{t}$ .   \n15 end ", "page_idx": 17}, {"type": "text", "text": "For the base case, let $i=1$ . $\\mathcal{P}$ does not make any mistakes in $\\{1,2,...,\\frac{T}{n+1}\\}$ since it knows $S^{0}$ using ${\\mathcal{Z}}_{n}$ , computes $x_{1:\\frac{T}{n+1}}=\\mathrm{Dyd}(S^{0})$ in line 5, and does not change its prediction until round $\\textstyle{\\frac{i T}{n+1}}+1$ based on line 6. At time point $\\begin{array}{r}{t_{1}=\\frac{T}{n+1}+1}\\end{array}$ , $\\mathcal{P}$ makes a mistake since $\\hat{x}_{t_{1}}^{t_{1}-1}=\\star\\neq x_{t_{1}}$ . Moreover, using Observation 3, the index $j\\in\\{1,...,\\frac{T}{n+1}\\}$ computed in round $t_{1}$ on line 8 matches $j_{1}$ . Thus, we have that $J_{1}=j_{1}$ . This completes the base case. ", "page_idx": 17}, {"type": "text", "text": "Now for the induction step, let $i\\in\\{2,...,n\\}$ . Suppose that the induction step is true for $i-1$ . This means that $\\mathcal{P}$ : ", "page_idx": 17}, {"type": "text", "text": "(i) sets J1:i\u22121 = j1:i\u22121 on round (in\u2212+1)1T ;   \n(ii) makes mistakes on rounds $\\begin{array}{r}{\\{\\frac{T}{n+1}+1,\\frac{2T}{n+1}+1,...,\\frac{(i-1)T}{n+1}+1\\}}\\end{array}$ (in\u2212+1)1T + 1} and no where in between. ", "page_idx": 17}, {"type": "text", "text": "We need to show that $\\mathcal{P}$ sets $J_{i}=j_{i}$ on round ${\\textstyle\\frac{i T}{n+1}}+1,{\\mathcal{P}}$ makes no mistakes between $\\begin{array}{r}{\\frac{(i-1)T}{n+1}+2}\\end{array}$ and $\\textstyle{\\frac{i T}{n+1}}$ , but makes a mistake at $\\textstyle{\\frac{i T}{n+1}}+1$ . At timepoint = (in\u2212+1)1T +1, P computes Ji\u22121 = ji\u22121 (by assumption) and thus sets $\\hat{x}_{1:T}^{t_{i-1}}\\,=\\,\\mathrm{SG}(S^{0},J_{1:i-1})\\,=\\,\\mathrm{SG}(S^{0},(j_{1},...,j_{i-1}))\\,=\\,\\mathrm{Dyd}(S^{0})\\ \\mathrm{o}$ $\\cdots\\circ\\mathrm{Dyd}(S^{i-1})$ using Observation 2. Therefore, $\\mathcal{P}$ predicts on round $t_{i-1}$ the sequence $\\hat{x}_{1:T}^{t_{i-1}}=$ $x_{1:\\frac{i T}{n+1}}\\circ(\\star,...,\\star)$ , implying that $\\mathcal{P}$ makes no mistakes for rounds $\\begin{array}{r}{\\frac{(i-1)T}{n+1}+2,...,\\frac{i T}{n+1}}\\end{array}$ since it does not change its prediction until round $\\textstyle{\\frac{i T}{n+1}}+1$ by line 12. However, since $\\hat{x}_{t_{i}}^{t_{i}-1}=\\star$ , $\\mathcal{P}$ makes a mistake on round $\\begin{array}{r}{t_{i}\\,=\\,\\frac{i T}{n+1}+1}\\end{array}$ . Finally, by Observation 3, the example $x_{t_{i}}$ and the previously observed sequence $x_{t_{i-1}:t_{i}-1}$ gives away $j_{i}$ , thus $\\mathcal{P}$ sets $J_{i}=j_{i}$ on line 8 in round $\\begin{array}{r}{t=\\frac{i T}{n+1}+1}\\end{array}$ . This completes the induction step and the proof of the claim that $\\mathcal{P}$ only makes mistakes on timepoints $\\begin{array}{r}{\\{\\frac{T}{n+1}+1,...,\\frac{n T}{n+1}+1\\}}\\end{array}$ . To see that $\\mathcal{P}$ is lazy, observe that by line 12, $\\mathcal{P}$ does not update its prediction on rounds in between those in $\\{{\\textstyle{\\frac{T}{n+1}}}+1,...,{\\textstyle{\\frac{n T}{n+1}}}+1\\}$ . To see that $\\mathcal{P}$ is consistent, note that $\\mathcal{P}$ uses prefixes of $j_{1},...,j_{n},\\,S^{0}$ , and SG to compute its predictions in line 10. Thus, consistency follows from Observation 2. \u53e3 ", "page_idx": 17}, {"type": "text", "text": "Step 3: Equivalence to Online Classification with Peeks ", "text_level": 1, "page_idx": 17}, {"type": "text", "text": "For any stream $x_{1:T}\\in\\mathcal{Z}_{n}$ , having access to the Predictor specified by Algorithm 7 implies that at every $\\bar{t}\\in\\{1,\\frac{T}{n+1}+1,...,\\frac{n T}{n+1}+\\bar{1}\\}$ , the learner observes predictions $\\hat{x}_{1:T}^{t}$ where $\\hat{x}_{1:t-1}^{t}=x_{1:t-1}$ , x\u02c6tt:t+nT+1 = xt:t+nT+1 , and x\u02c6tt+ $\\hat{x}_{t+\\frac{T}{n+1}+1:T}^{t}=(\\star,...,\\star)$ . Accordingly, at the timepoints $\\begin{array}{r}{t\\in\\{1,\\frac{T}{n+1}+}\\end{array}$ $1,...,{\\frac{n T}{n+1}}+1\\}$ , the learner observes the next $\\textstyle{\\frac{T}{n+1}}-1$ examples $\\begin{array}{r}{x_{t:t+\\frac{T}{n+1}}}\\end{array}$ in the stream, but learns nothing about the future examples $x_{t+\\frac{T}{n+1}+1:T}$ . In addition, for timepoints in between those in $\\{1,{\\frac{T}{n+1}}+1,...,{\\frac{n T}{n+1}}+1\\}$ , the learner does not observe any new information from $\\mathcal{P}$ since by line 12 in Algorithm 7, $\\hat{x}_{1:T}^{i}=\\hat{x}_{1:T}^{i+r}$ for every $i\\in\\{1,\\frac{T}{n+1}+1,...,\\frac{n T}{n+1}+1\\}$ and $r\\in\\{1,...,\\frac{T}{n+1}-1\\}$ . As a result, whenever $x_{1:T}\\in\\mathcal{Z}_{n}$ , Protocol 2 with the Predictor specified by Algorithm 7 is equivalent to the setting we call Online Classification with Peeks where there is no Predictor, but the learner observes the next $\\textstyle{\\frac{T}{n+1}}-1$ \u22121 examples exactly at timepoints t \u2208{1,nT+1 + 1, ..., nn+T1 + . Indeed, by having knowledge no+f 1the next $\\textstyle{\\frac{T}{n+1}}-1$ examples exactly at timepoints $t\\in\\{1,{\\frac{T}{n+1}}+1,...,{\\frac{n T}{n+1}}+1\\}$ a learner for Online Classification with Peeks can simulate a Predictor that acts like Algorithm 7. Likewise, a learner for Online Classification with Predictions can use Algorithm 7 to simulate an adversary that reveals the next ${\\frac{T}{n+1}}-1$ examples exactly at timepoints $t\\in\\{1,{\\frac{T}{n+1}}+1,...,{\\frac{n T}{n+1}}+1\\}$ Accordingly, we consider Online Classification with Peeks for the rest of the proof and show how Nature can force the lower bound in Theorem 3.8 under this new setting. ", "page_idx": 17}, {"type": "text", "text": "", "page_idx": 18}, {"type": "text", "text": "", "page_idx": 18}, {"type": "text", "text": "Step 4: Nature\u2019s Strategy for Online Classification with Peeks ", "text_level": 1, "page_idx": 18}, {"type": "text", "text": "Let $\\boldsymbol{\\mathcal{A}}$ be any online learner and consider the game where the learner $\\boldsymbol{\\mathcal{A}}$ observes the next $\\textstyle{\\frac{T}{n+1}}-1$ examples at timepoints $\\{1,{\\frac{T}{n+1}}+1,...,{\\frac{n T}{n+1}}+1\\}$ . We construct a hard stream for $\\boldsymbol{\\mathcal{A}}$ in this setting. We first describe a minimax optimal offilne strategy for Nature when it is forced to play a sequence of examples $S\\in S$ sorted in Dyadic order. ", "page_idx": 18}, {"type": "table", "img_path": "MB0DD5qAz8/tmp/75d5aac04565677c8933f33cbcd4aadfda221bf65026ac7e6c4c6475edde335d.jpg", "table_caption": [], "table_footnote": [], "page_idx": 18}, {"type": "text", "text": "Lemma E.2. For any learner $\\mathcal{A},$ , $\\tilde{S}=\\mathrm{Dyd}(S).$ , and Version space $V\\subseteq\\{0,1\\}^{\\scriptscriptstyle X}$ , Algorithm 8 forces $\\boldsymbol{\\mathcal{A}}$ to make at least $\\textstyle{\\frac{1}{2}}\\log_{2}({\\frac{T}{n+1}})$ mistakes in expectation if $S$ is threshold-shattered (Definition 7) by $V$ . ", "page_idx": 18}, {"type": "text", "text": "Proof. The lemma follows directly from Theorem 3.4 in Hanneke et al. [2024]. ", "page_idx": 18}, {"type": "text", "text": "For the definition of threshold-shattering, see Appendix A. Note that for every input $\\tilde{S}=\\mathrm{Dyd}(S)$ and $V\\subseteq\\{0,1\\}^{\\mathcal{X}}$ to Algorithm 8, its output version space $V_{|\\tilde{S}|+1}$ is non-empty and consistent with the sequence $(\\tilde{S}_{1},y_{1}),...,(\\tilde{S}_{\\frac{T}{n+1}},y_{\\frac{T}{n+1}})$ as long as $|V|>0$ . This property will be crucial when proving Lemma E.4. We are now ready to describe Nature\u2019s strategy for Online Classification with Peeks. The pseudocode is provided in Algorithm 9. ", "page_idx": 18}, {"type": "text", "text": "We establish a series of important lemmas. ", "page_idx": 18}, {"type": "text", "text": "Lemma E.3. For every learner $\\boldsymbol{\\mathcal{A}}$ , $i f\\left(x_{1},y_{1}\\right),...,\\left(x_{T},y_{T}\\right)$ is the stream the output of Algorithm 9 when playing against $\\boldsymbol{\\mathcal{A}}$ , then $x_{1:T}\\in\\mathcal{Z}_{n}$ . ", "page_idx": 18}, {"type": "text", "text": "Proof. Fix a learner $\\boldsymbol{\\mathcal{A}}$ and let $(x_{1},y_{1}),...,(x_{T},y_{T})$ denote the output of Algorithm 9 playing against $\\boldsymbol{\\mathcal{A}}$ . Let $j_{1:n}$ denote the sequences of indices output by Algorithm 9. Then, since SG is deterministic, by line 6-7 in Algorithm 9, we have that $x_{1:T}=\\operatorname{SG}(S^{0},(j_{1},...,j_{n}))\\in{\\mathcal{Z}}_{n}$ . \u53e3 ", "page_idx": 18}, {"type": "text", "text": "Lemma E.4. For every learner $\\boldsymbol{\\mathcal{A}}$ , $i f\\left(x_{1},y_{1}\\right),...,\\left(x_{T},y_{T}\\right)$ is the stream the output of Algorithm 9 when playing against $\\boldsymbol{\\mathcal{A}}$ , then $(x_{1},y_{1}),...,(x_{T},y_{T})$ is realizable by $\\mathcal{H}$ . ", "page_idx": 18}, {"type": "text", "text": "Algorithm 9 Nature\u2019s Strategy for Online Classification with Peeks ", "page_idx": 19}, {"type": "text", "text": "Input: Learner , Hypothesis class 1 Initialize: $V_{1}=\\mathcal{H}$ 2 for $i=1,..,n+1$ do 3 if $i=1$ then 4 Set $x_{1:\\frac{T}{n+1}}=\\operatorname{Dyd}(S^{0})$ and reveal it to the learner $\\boldsymbol{\\mathcal{A}}$ . 5 else 6 Compute $S=\\mathrm{SG}(S^{0},(j_{1},...,j_{i-1}))$ . 7 Let $x_{\\frac{(i-1)T}{n+1}+1:\\frac{i T}{n+1}}$ be the last $\\textstyle{\\frac{T}{n+1}}$ examples in $S$ and reveal it to the learner $\\boldsymbol{\\mathcal{A}}$ . 8 Play against $\\boldsymbol{\\mathcal{A}}$ according to Algorithm 8 using $x_{\\frac{(i-1)T}{n+1}+1:\\frac{i T}{n+1}}$ and version space $V_{i}$ . 9 Let $\\mathcal{Y}_{\\frac{(i-1)T}{n+1}+1},...,\\mathcal{Y}_{\\frac{i T}{n+1}}$ be the returned labels and $V_{i+1}\\subseteq V_{i}$ be the returned version space. 10 Let y\u02dc (i\u22121)T $\\tilde{y}_{\\frac{(i-1)T}{n+1}+1},...,\\tilde{y}_{\\frac{i T}{n+1}}$ be the sequence of true labels after sorting $(x_{\\frac{(i-1)T}{n+1}+1},y_{\\frac{(i-1)T}{n+1}+1}),...,(x_{\\frac{i T}{n+1}},y_{\\frac{i T}{n+1}})$ 11 in increasing order with respect to the examples. 12 if $\\begin{array}{r}{\\tilde{y}_{\\frac{i T}{n+1}}=1}\\end{array}$ then 13 $\\begin{array}{r}{j_{i}=\\frac{T}{n+1}+1}\\end{array}$ . 14 else 15 Set $j_{i}$ to be the smallest $p\\in\\{1,...,\\frac{T}{n+1}\\}$ such that $\\begin{array}{r}{\\tilde{y}_{\\frac{(i-1)T}{n+1}+p}=0}\\end{array}$ . 16 end ", "page_idx": 19}, {"type": "text", "text": "17 Return: Stream $(x_{1},y_{1}),...,(x_{T},y_{T})$ , indices $j_{1:n}$ , and version spaces $V_{1},...,V_{n+2}$ ", "page_idx": 19}, {"type": "text", "text": "Proof. Fix a learner $\\boldsymbol{\\mathcal{A}}$ and let $(x_{1},y_{1}),...,(x_{T},y_{T})$ be the output of Algorithm 9 when playing against $\\boldsymbol{\\mathcal{A}}$ . Let $V_{2},...,V_{n+2}$ be the sequence of version spaces output by Algorithm 9. It suffices to show that $V_{n+2}$ is not empty and is consistent with $\\bar{(x_{1},y_{1})},...,\\bar{(x_{T},y_{T})}$ . Our proof will be by induction using the following hypothesis: $V_{i+1}$ is non-empty and consistent with the sequence $({\\dot{x}}_{1},y_{1}),...,(x_{\\frac{i T}{n+1}},y_{\\frac{i T}{n+1}})$ . For the base case, let $i\\,=\\,1$ . Then, by Algorithm 8, line 8 in Algorithm 9, and the fact that $|V_{1}|\\;=\\;|\\mathcal{H}|\\;>\\;0$ , we have that $|V_{2}|\\;>\\;0$ and $V_{2}$ is consistent with $(x_{1},y_{1}),...,(x_{\\frac{T}{n+1}},y_{\\frac{T}{n+1}})$ . Now consider some $i\\geq2$ and suppose the induction hypothesis is true for $i-1$ , Then, we know that $|V_{i}|\\,>\\,0$ and $V_{i}$ is consistent with $(x_{1},y_{1}),...,(x_{\\frac{(i-1)T}{n+1}},y_{\\frac{(i-1)T}{n+1}})$ . Again, by design of Algorithm 8 and line 9 in Algorithm 9, it follows that $|V_{i+1}|>0$ and $V_{i+1}$ is consistent with $(x_{\\frac{(i-1)T}{n+1}+1},y_{\\frac{(i-1)T}{n+1}+1}),...,(x_{\\frac{i T}{n+1}},y_{\\frac{i T}{n+1}})$ T+1), ..., (x iT , y iT ). Since Vi+1 \u2286Vi, and Vi is consistent with $(x_{1},y_{1}),...,(x_{\\frac{(i-1)T}{n+1}},y_{\\frac{(i-1)T}{n+1}})$ , we get that $V_{i+1}$ is consistent with $(x_{1},y_{1}),...,(x_{\\frac{i T}{n+1}},y_{\\frac{i T}{n+1}})$ , completing the induction step. \u53e3 ", "page_idx": 19}, {"type": "text", "text": "Lemma E.5. For every learner $\\mathcal{A}$ $A,\\,i f\\left(x_{1},y_{1}\\right),...,\\left(x_{T},y_{T}\\right)$ and $V_{1},...,V_{n+2}$ are stream and version spaces output by Algorithm $^{\\,g}$ when playing against $\\boldsymbol{\\mathcal{A}}$ , then for every $i\\in\\{1,...,n+1\\}$ , the version space Vi threshold-shatters x (in\u2212+1)1T+1: ni+T1 . ", "page_idx": 19}, {"type": "text", "text": "Proof. Fix a learner $\\boldsymbol{\\mathcal{A}}$ and let $(x_{1},y_{1}),...,(x_{T},y_{T})$ denote the output of Algorithm 9 playing against $\\boldsymbol{\\mathcal{A}}$ . Let $j_{1:n}$ and $V_{1},...,V_{n+2}$ denote the sequences of indices and version spaces output by Algorithm 9 respectively. Note that $x_{1:T}=\\operatorname{SG}(S^{0},\\overbar{j}_{1:n})$ . Moreover, for every $i\\,\\in\\,\\{2,...,n\\}$ , we have that $x_{1:\\frac{i T}{n+1}}=\\mathrm{SG}(S^{0},(j_{1},...,j_{i-1}))$ by lines 6-7. ", "page_idx": 19}, {"type": "text", "text": "Fix an i \u2208{1, ..., n + 1}. It suffices to show that the hypotheses parameterized by x (i\u22121)T+1: iT belong in $V_{i}$ . Our proof will be by induction. For the base case, since $V_{1}=\\mathcal{H}$ , it trivially follows that the hypothesis parameterized by $x_{\\frac{(i-1)T}{n+1}+1:\\frac{i T}{n+1}}$ belong to V1. Now, suppose that x (i\u22121)T+1: iT belong to $V_{m}$ for some $m<i$ . We show that $V_{m+1}$ also contains the hypothesis parameterized by $x_{\\frac{(i-1)T}{n+1}+1:\\frac{i T}{n+1}}$ . Recall that $V_{m+1}\\subseteq V_{m}$ is the subset of $V_{m}$ that is consistent with the labeled data ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\begin{array}{r}{(x_{\\frac{(m-1)T}{n+1}+1},y_{\\frac{(m-1)T}{n+1}+1}),...,(x_{\\frac{m T}{n+1}},y_{\\frac{m T}{n+1}})}\\end{array}\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "and is the result of running Algorithm 8 with input version space Vm and sequence x (mn\u2212+11)T+1: nm+T1 . It suffices to show that the hypotheses parameterized by $x_{\\frac{(i-1)T}{n+1}+1:\\frac{i T}{n+1}}$ are also consistent with ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\begin{array}{r}{(x_{\\frac{(m-1)T}{n+1}+1},y_{\\frac{(m-1)T}{n+1}+1}),...,(x_{\\frac{m T}{n+1}},y_{\\frac{m T}{n+1}}).}\\end{array}\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "To show this, recall that $j_{m}$ is the index computed in Lines 11-14 of Algorithm 9 on round $m$ . Let ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\begin{array}{r}{(\\tilde{x}_{\\frac{(m-1)T}{n+1}+1},\\tilde{y}_{\\frac{(m-1)T}{n+1}+1}),...,(\\tilde{x}_{\\frac{m T}{n+1}},\\tilde{y}_{\\frac{m T}{n+1}}).}\\end{array}\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "be the sample sorted in increasing order by examples. There are three cases to consider. Suppose $j_{m}=$ 1, then $\\begin{array}{r}{\\tilde{y}_{\\frac{(m-1)T}{n+1}+1}=0}\\end{array}$ , and it must be the case that $\\begin{array}{r}{\\tilde{y}_{\\frac{(m-1)T}{n+1}+p}=0}\\end{array}$ = 0 for all p \u2208{2, ...,nT+1}. Since $x_{1:\\frac{m T}{n+1}}=\\mathrm{SG}(S^{0},(j_{1},...,j_{m-1}))$ , by definition of Algorithm 6, we have that the last $\\textstyle{\\frac{T}{n+1}}$ entries of $\\mathrm{SG}(S^{0},(j_{1},...,j_{m}))$ all lie strictly to the left of $\\tilde{x}_{\\frac{(m-1)T}{n+1}+1}$ . Moreover, by Observation 4, this is true of the last $\\textstyle{\\frac{T}{n+1}}$ entries of $\\mathrm{SG}(S^{0},(j_{1},...,j_{m},q_{m+1},...,q_{i-1})$ for any $\\textstyle q_{m+1},...,q_{i-1}\\in\\{1,...,{\\frac{T}{n+1}}+1\\}$ . Therefore, we must have that $x_{\\frac{(i-1)T}{n+1}+1:\\frac{i T}{n+1}}$ , which are the last $\\textstyle{\\frac{T}{n+1}}$ entries of $\\mathrm{SG}(S^{0},(j_{1},...,j_{i-1}))$ , $\\tilde{x}_{\\frac{(m-1)T}{n+1}+1}$ a,e ti dt.m hpBeliyyr  isanysgs mtohmcaieta tttrehyd,e  irwh yahspesnoo t ,  eoswn e o auhltlap voueft $(x_{\\frac{(m-1)T}{n+1}+1},y_{\\frac{(m-1)T}{n+1}+1}),...,(x_{\\frac{m T}{n+1}},y_{\\frac{m T}{n+1}})$ $\\begin{array}{r}{j_{m}=\\frac{T}{n+1}+1}\\end{array}$   \n$x_{\\frac{(i-1)T}{n+1}+1:\\frac{i T}{n+1}}$ $\\tilde{x}_{\\frac{m T}{n+1}}$   \n1 on all of $(x_{\\frac{(m-1)T}{n+1}+1},y_{\\frac{(m-1)T}{n+1}+1}),...,(x_{\\frac{m T}{n+1}},y_{\\frac{m T}{n+1}})$ as needed. Now, consider the case where $j_{m}\\in\\{2,...,\\frac{T}{n+1}\\}$ .1 Then, by nA+1lgorithm 6 andn +O1bsenrv+a1tion 4, for any $\\begin{array}{r l}{q_{m+1},...,q_{i}\\in\\{1,...,\\frac{T}{n+1}\\!+\\!1\\}}&{{}}\\end{array}$ the last $\\textstyle{\\frac{T}{n+1}}$ entries of lie strictly in between $\\tilde{x}_{\\frac{(m-1)T}{n+1}+j_{m}-1}$ and x\u02dc (m\u22121)T+jm. tahned  h0y opno tehxesaems ppleasr $x_{\\frac{(i-1)T}{n+1}+1:\\frac{i T}{n+1}}$ teo utthpaut t b1y  odne feinxiatimonp leosf $\\tilde{x}_{\\frac{(m-1)T}{n+1}+1:\\frac{(m-1)T}{n+1}+j_{m}-1}$ $\\tilde{x}_{\\frac{(m-1)T}{n+1}+j_{m}:\\frac{m T}{n+1}}$   \n$j_{m}$ , it must be the case that $\\begin{array}{r}{\\tilde{y}_{\\frac{(m-1)T}{n+1}+1:\\frac{(m-1)T}{n+1}+j_{m}-1}=(1,...,1)}\\end{array}$ and $\\begin{array}{r}{\\tilde{y}_{\\frac{(m-1)T}{n+1}+j_{m}:\\frac{m T}{n+1}}=(0,...,0)}\\end{array}$ . Thus, once again the hypotheses parameterized by $x_{\\frac{(i-1)T}{n+1}+1:\\frac{i T}{n+1}}$ are consistent with the sample ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\begin{array}{r}{(x_{\\frac{(m-1)T}{n+1}+1},y_{\\frac{(m-1)T}{n+1}+1}),...,(x_{\\frac{m T}{n+1}},y_{\\frac{m T}{n+1}}).}\\end{array}\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "This shows that these hypotheses are contained in $V_{m+1}$ , completing the induction step. ", "page_idx": 20}, {"type": "text", "text": "Step 5: Completing the proof of Theorem 3.8 ", "text_level": 1, "page_idx": 20}, {"type": "text", "text": "We are now ready to complete the proof of Theorem 3.8, which follows from composing E.1, E.2, E.3, E.4, and E.5. Namely, Lemma E.1 and the discussion in Section 15 show that there exists a Predictor $\\mathcal{P}$ such that for any learner $\\boldsymbol{\\mathcal{A}}$ playing according to Protocol 2, Online Classification with Predictions is equivalent to Online Classification with Peeks whenever the stream $(x_{1},y_{1}),...,(x_{T},y_{T})$ selected by the adversary satisfies the constraint that $x_{1:T}\\in\\mathcal{Z}_{n}$ . Lemmas E.3 and E.4 show that for any learner $\\boldsymbol{\\mathcal{A}}$ , Nature playing according to Algorithm 9 guarantees that the resulting sequence $(x_{1},y_{1}),...,(x_{T},y_{T})$ satisfies the constraint that $x_{1:T}\\in\\mathcal{Z}_{n}$ and realizability by $\\mathcal{H}$ . Thus, for the Predictor $\\mathcal{P}$ specified by Algorithm 7 and Nature playing according to Algorithm 9, Online Classification with Predictions is equivalent to Online Classification with Peeks. Finally, for Online Classification with Peeks, combining Lemmas E.2 and E.5 shows that for any learner $\\boldsymbol{\\mathcal{A}}$ , Nature, by playing according to Algorithm 9, guarantees that A makes at leastlog2(2 $\\frac{\\log_{2}(\\frac{T}{n+1})}{2}$ mistakes in expectation every $\\textstyle{\\frac{T}{n+1}}$ rounds. Thus, Nature forces A to make at least (n2+1)log2(nT+1) mistakes in expectation by the end of the game, completing the proof. ", "page_idx": 20}, {"type": "text", "text": "F Adaptive Rates in the Agnostic Setting ", "text_level": 1, "page_idx": 20}, {"type": "text", "text": "In this section, we consider the harder agnostic setting and prove analogous results as in Section 3.   \nOur main quantitative result is the agnostic analog of Theorem 3.1. ", "page_idx": 20}, {"type": "text", "text": "Theorem F.1 (Agnostic upper bound). For every $\\mathcal{H}\\subseteq\\mathcal{V}^{\\mathcal{X}}$ , Predictor $\\mathcal{P}$ , and no-regret offilne learner $\\boldsymbol{\\mathrm{\\Delta}}\\boldsymbol{\\mathrm{\\Omega}}^{\\beta}$ , there exists an online learner $\\boldsymbol{\\mathcal{A}}$ such that for every stream $(x_{1},y_{1}),...,(x_{T},y_{T}),$ , $\\boldsymbol{\\mathcal{A}}$ \u2019s expected regret is at most ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\left(\\underbrace{\\sqrt{\\mathrm{L}(\\mathcal{H})\\,T\\log_{2}(e T)}}_{(i)}\\wedge\\underbrace{\\left(2(\\mathrm{M}_{\\mathcal{P}}(x_{1:T})+1)\\,\\overline{{\\mathrm{R}}}_{B}\\Big(\\frac{T}{\\mathrm{M}_{\\mathcal{P}}(x_{1:T})+1}+1,\\mathcal{H}\\Big)+\\sqrt{T\\log_{2}T}\\right)}_{(i i)}+\\sqrt{T}\\mathrm{log}(X)\\right)}\\end{array}\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "With respect to learnability, Corollary F.2 shows that offline learnability of $\\mathcal{H}$ is sufficient for online learnability under predictable examples. ", "page_idx": 21}, {"type": "text", "text": "Corollary F.2 (Offline learnability $\\Longrightarrow$ Agnostic Online learnability with Predictable Examples). For every $\\mathcal{H}\\subseteq\\mathcal{V}^{\\mathcal{X}}$ and $\\mathcal{Z}\\subseteq\\mathcal{X}^{\\star}$ , ", "page_idx": 21}, {"type": "text", "text": "$\\mathcal{Z}$ is predictable and $\\mathcal{H}$ is offline learnable $\\implies(\\mathcal{H},\\mathcal{Z})$ is agnostic online learnable. ", "page_idx": 21}, {"type": "text", "text": "In addition, we can also establish a quantitative version of Corollary F.2 for VC classes. ", "page_idx": 21}, {"type": "text", "text": "Corollary F.3. For every $\\mathcal{H}\\subseteq\\{0,1\\}^{\\mathcal{X}}$ , Predictor $\\mathcal{P}$ , $\\mathcal{Z}\\subseteq\\mathcal{X}^{\\star}$ , and no-regret offilne learner $\\smash{\\beta_{\\mathrm{i}}}$ , there exists an online learner $\\boldsymbol{\\mathcal{A}}$ such that ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\mathrm{R}_{A}(T,\\mathcal{H},\\mathcal{Z})=O\\left((\\mathrm{M}_{\\mathcal{P}}(T,\\mathcal{Z})+1)\\sqrt{\\frac{\\mathrm{VC}(\\mathcal{H})\\,T}{\\mathrm{M}_{\\mathcal{P}}(T,\\mathcal{Z})+1}\\log_{2}\\Bigl(\\frac{T}{\\mathrm{M}_{\\mathcal{P}}(T,\\mathcal{Z})+1}\\Bigr)}+\\sqrt{T\\log_{2}T}\\right).\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "The proof of Corollary F.3 is in Section F.4. The remainder of this section is dedicated to proving Theorem 3.1 and Corollary F.3. The proof is similar to the realizable case. It involves constructing two online learners with expected regret bounds (i) and (ii) respectively, and then running the celebrated Randomized Exponential Weights Algorithm (REWA) using these learners as experts [Cesa-Bianchi and Lugosi, 2006]. The following guarantee of REWA along with upper bound (i) and (ii) gives the upper bound in Theorem F.1. ", "page_idx": 21}, {"type": "text", "text": "Lemma F.4 (REWA guarantee [Cesa-Bianchi and Lugosi, 2006]). The expected regret of REWA when run with N experts and learning rate \u03b7 = $\\begin{array}{r}{\\eta\\,=\\,\\sqrt{\\frac{8\\ln{N}}{T}}}\\end{array}$ is at most $\\begin{array}{r}{\\operatorname*{min}_{i\\in[N]}M_{i}+\\sqrt{T\\log_{2}N},}\\end{array}$ , where $M_{i}$ is the number of mistakes made by expert $i\\in[N]$ . ", "page_idx": 21}, {"type": "text", "text": "The online learner obtaining the regret bound $\\sqrt{\\operatorname{L}(\\mathcal{H})\\,T\\log_{2}(e T)}$ is the generic agnostic online learner from Hanneke et al. [2023], thus we omit the details here. Our second learner is described in Section F.2 and uses Algorithm 3 as a subroutine. The following lemma, bounding the expected regret of Algorithm 3 in the agnostic setting, will be crucial. ", "page_idx": 21}, {"type": "text", "text": "Lemma F.5. For every $\\mathcal{H}\\mathbf{\\Sigma}\\subseteq\\mathbf{\\Sigma}\\mathcal{V}^{\\mathcal{X}}$ , Predictor $\\mathcal{P}$ , no-regret offline learner $\\boldsymbol{\\beta}$ , and stream $(x_{1},y_{1}),...,(x_{T},y_{T}),$ , the expected regret of Algorithm 3 is at most $\\left(\\mathrm{M}_{\\mathcal{P}}(x_{1:T})+1\\right)\\mathrm{R}_{\\mathcal{B}}(T,\\mathcal{H})$ . ", "page_idx": 21}, {"type": "text", "text": "F.1 Proof of Lemma F.5 ", "text_level": 1, "page_idx": 21}, {"type": "text", "text": "The proof closely follows that of Lemma 3.5. ", "page_idx": 21}, {"type": "text", "text": "Proof. Let $\\boldsymbol{\\mathcal{A}}$ denote Algorithm 3 and $(x_{1},y_{1}),...,(x_{T},y_{T})$ denote the stream to be observed by $\\boldsymbol{\\mathcal{A}}$ . Let $c$ be the random variable denoting the number of mistakes made by Predictor $\\mathcal{P}$ on the stream and $t_{1},...,t_{c}$ be the random variables denoting the time points where $\\mathcal{P}$ makes these errors (e.g . $\\hat{x}_{t_{i}}^{t_{i}-1}\\neq x_{t_{i}})$ ). Note that $t_{i}\\geq2$ for all $i\\in[c]$ . We will show pointwise for every value of $c$ and $t_{1},...,t_{c}$ that $\\boldsymbol{\\mathcal{A}}$ makes at most $(c+1)\\operatorname{R}\\!{}_{\\mathcal{B}}(T,\\mathcal{H})$ mistakes in expectation over the randomness of $\\boldsymbol{\\mathrm{\\Delta}}\\boldsymbol{\\mathrm{\\Omega}}^{\\beta}$ . Taking an outer expectation with respect to the randomness of $\\mathcal{P}$ and using the fact that $\\mathbb{E}\\left[c\\right]=\\mathrm{M}_{\\mathcal{P}}(x_{1:T})$ , completes the proof. ", "page_idx": 21}, {"type": "text", "text": "First, consider the case where $c=0$ (i.e. $\\mathcal{P}$ makes no mistakes). Then, since $\\mathcal{P}$ is lazy, we have that $\\hat{x}_{1:T}^{t}=x_{1:T}$ for every $t\\in[T]$ . Thus 1l ine 5 fires exactly once on round $t=1$ , $\\boldsymbol{\\mathcal{A}}$ initializes an offilne learner $B^{1}$ with $x_{1:T}$ , and $\\boldsymbol{\\mathcal{A}}$ uses to make its prediction on all rounds. Thus, makes at most $\\operatorname{R}_{B}(T,{\\mathcal{H}})$ mistakes in expectation. ", "page_idx": 21}, {"type": "text", "text": "Now, let $c>0$ and $t_{1},...,t_{c}$ be the time points where $\\mathcal{P}$ errs. Partition the sequence $1,...,T$ into the disjoint intervals $(1,...,t_{1}-1)$ , $(t_{1},...,t_{2}-1),...,(t_{c},...,T)$ . Define $t_{0}:=1$ and $t_{c+1}:=T$ . Fix an $i\\in\\{0,...,c\\}$ . Then, for every $j\\in\\{t_{i},...,t_{i+1}-1\\}$ , we have that $\\hat{x}_{1:t_{i+1}-1}^{j}=x_{t_{i+1}-1}$ . This comes from the fact that $\\mathcal{P}$ does not error on timepoints $t_{i}+1,...,t_{i+1}-1$ and is both consistent and lazy (see Assumptions 1 and 2). Thus, line 5 fires on round $t_{i}$ , $\\boldsymbol{\\mathcal{A}}$ initializes an offline learner $B^{i}$ with the sequence x\u02c6ttii:T $\\hat{x}_{t_{i}:T}^{t_{i}}=x_{t_{i}:t_{i+1}-1}\\circ\\hat{x}_{t_{i+1}:T}^{t_{i}}$ x\u02c6ttii+1:T , and A uses Bi it to make predictions for all remaining timepoints $t_{i},...,t_{i+1}-1$ . Note that line 5 does not fire on timepoints $t_{i}+1,...,t_{i+1}-1$ . ", "page_idx": 21}, {"type": "text", "text": "", "page_idx": 22}, {"type": "text", "text": "$\\begin{array}{r l r}{h^{i}}&{\\in}&{\\arg\\operatorname*{min}_{h\\in\\mathcal{H}}\\sum_{t=t_{i}}^{t_{i+1}-1}\\mathbb{1}\\{h(x_{t})\\;\\;\\neq\\;\\;y_{t}\\}}\\end{array}$ be an optimal hypothesis for the partition $(t_{i},...,t_{i+1}-1)$ . Let $y_{t}^{i}\\,=\\,y_{t}$ for $t_{i}\\,\\leq\\,t\\,\\leq\\,t_{i+1}\\,-\\,1$ and $y_{t}^{i}\\;=\\;h^{i}(\\hat{x}_{t}^{t_{i}})$ for all $t~\\geq~t_{i+1}$ . Then, note that ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\operatorname*{inf}_{h\\in\\mathcal{H}}\\sum_{t=t_{i}}^{T}\\mathbb{1}\\{h(\\hat{x}_{t}^{t_{i}})\\neq y_{t}^{i}\\}=\\operatorname*{inf}_{h\\in\\mathcal{H}}\\sum_{t=t_{i}}^{t_{i+1}-1}\\mathbb{1}\\{h(x_{t})\\neq y_{t}\\}.\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "Now, consider the hypothetical labeled stream ", "page_idx": 22}, {"type": "equation", "text": "$$\n(\\hat{x}_{t_{i}}^{t_{i}},y_{t_{i}}^{i}),...,(\\hat{x}_{T}^{t_{i}},y_{T}^{i})=(x_{t_{i}},y_{t_{i}}),...,(x_{t_{i+1}-1},y_{t_{i+1}-1}),(\\hat{x}_{t_{i+1}}^{t_{i}},y_{t_{i+1}}^{i}),...,(\\hat{x}_{T}^{t_{i}},y_{T}^{i}).\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "By definition, $B^{i}$ , after initialized with x\u02c6tti:T , makes at most ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\operatorname*{inf}_{h\\in\\mathcal{H}}\\sum_{t=t_{i}}^{T}\\mathbb{1}\\{h(\\hat{x}_{t}^{t_{i}})\\neq y_{t}^{i}\\}+\\mathrm{R}_{B}(T-t_{i},\\mathcal{H})=\\operatorname*{inf}_{h\\in\\mathcal{H}}\\sum_{t=t_{i}}^{t_{i+1}-1}\\mathbb{1}\\{h(x_{t})\\neq y_{t}\\}+\\mathrm{R}_{B}(T-t_{i},\\mathcal{H})\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "mistakes in expectation when simulated on the stream $(\\hat{x}_{t_{i}}^{t_{i}},y_{t_{i}}^{i}),...,(\\hat{x}_{T}^{t_{i}},y_{T}^{i})$ . Thus, $B^{i}$ makes at most infh\u2208H tti=+t1i\u221211{h(xt) \u0338= yt} + RB(T \u2212ti + 1, H) mistakes in expectation on the prefix $\\langle\\hat{x}_{t_{i}}^{t_{i}},y_{t_{i}}^{i}\\rangle,...,(\\hat{x}_{t_{i+1}-1}^{t_{i}},y_{t_{i+1}-1}^{i})=(x_{t_{i}},y_{t_{i}}),...,(x_{t_{i+1}-1},y_{t_{i+1}-1})$ . Since on timepoint $t_{i}$ , $\\boldsymbol{\\mathcal{A}}$ instantiates $B^{i}$ with the sequence $\\hat{x}_{t_{i}:T}^{t_{i}}$ and proceeds to simulate $B^{i}$ on the sequences of labeled examples $(x_{t_{i}},y_{t_{i}}),...,(x_{t_{i+1}-1},y_{t_{i+1}-1})$ , $\\boldsymbol{\\mathcal{A}}$ makes at most $\\begin{array}{r}{\\operatorname*{inf}_{h\\in\\mathcal{H}}\\sum_{t=t_{i}}^{t_{i+1}-1}\\mathbb{1}\\{h(x_{t})\\ \\neq\\ y_{t}\\}\\ +}\\end{array}$ $\\mathrm{R}_{B}(T-t_{i}+1,\\mathcal{H})$ mistakes in expectation on the sequence $(x_{t_{i}},y_{t_{i}}),...,(x_{t_{i+1}-1},y_{t_{i+1}-1})$ . Since the interval $i$ was chosen arbitrarily, this is true for every $i\\in\\{0,...,c\\}$ and ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{E}\\left[\\displaystyle\\sum_{t=1}^{T}\\mathbb{1}\\{\\mathcal{A}(x_{t})\\neq y_{t}\\}\\right]=\\mathbb{E}\\left[\\displaystyle\\sum_{i=0}^{c}\\sum_{t=t_{i}}^{t_{i+1}-1}\\mathbb{1}\\{\\mathcal{A}(x_{t})\\neq y_{t}\\}\\right]}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\leq\\displaystyle\\sum_{i=0}^{c}\\!\\!\\left(\\operatorname*{inf}_{h\\in\\mathcal{H}}\\sum_{t=t_{i}}^{t_{i+1}-1}\\mathbb{1}\\{h(x_{t})\\neq y_{t}\\}+\\mathrm{R}_{B}(T-t_{i}+1,\\mathcal{H})\\right)}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\qquad\\leq\\displaystyle\\operatorname*{inf}_{h\\in\\mathcal{H}}\\sum_{t=1}^{T}\\mathbb{1}\\{h(x_{t})\\neq y_{t}\\}+(c+1)\\,\\mathrm{R}_{B}(T,\\mathcal{H}),}\\end{array}\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "as needed. ", "page_idx": 22}, {"type": "text", "text": "F.2 Proof of upper bound (ii) in Theorem F.1 ", "text_level": 1, "page_idx": 22}, {"type": "text", "text": "The proof of upper bound (ii) in Theorem F.1 closely follows the proof of upper bound (iii) in Theorem 3.1 from the realizable setting. The main idea is to run REWA using the same experts defined in Algorithm 4 and bounding the expected regret in terms of the expected regret of $\\kappa$ from Lemma F.5. ", "page_idx": 22}, {"type": "text", "text": "We show that Algorithm 5 using REWA in line 3 and the experts in Algorithm 4 with their guarantee in Lemma F.5 achieves upper bound (ii) in Theorem F.1. Let $(x_{1},y_{1}),...,(x_{T},y_{T})$ be the stream to be observed by the learner. Let $\\boldsymbol{\\mathcal{A}}$ denote the online learner in Algorithm 5 using REWA in line 3 of ", "page_idx": 22}, {"type": "text", "text": "Algorithm 5. By the guarantees of the REWA, we have that ", "page_idx": 23}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\displaystyle\\sum_{n=1}^{T}\\lfloor\\mathcal{A}(x_{t})\\neq y_{t}\\rfloor\\leq\\mathbb{E}\\left[\\left.\\sum_{i=0}^{M}\\binom{n-1}{i-1}\\displaystyle\\sum_{k=1}^{T}\\lfloor E_{\\beta}(x_{t})\\neq y_{t}\\rfloor\\right]+\\sqrt{T\\log_{2}T}}&{}\\\\ {\\leq\\mathbb{E}\\left[\\displaystyle\\sum_{i=1}^{T}\\lfloor E_{\\beta}(x_{t+1})\\lceil\\alpha_{t}\\rceil\\neq y_{t}\\rfloor\\right]+\\sqrt{T\\log_{2}T}}&{}\\\\ {\\leq\\mathbb{E}\\left[\\displaystyle\\sum_{i=0}^{[M\\alpha_{t},n]}\\operatorname*{in}_{t\\rightarrow t+1}^{[M\\alpha_{t},n]}\\lfloor E_{\\beta}(x_{t})\\neq y_{t}\\rfloor\\right]+\\sqrt{T\\log_{2}T}}&{}\\\\ {\\leq\\mathbb{E}\\left[\\displaystyle\\sum_{i=0}^{[M\\alpha_{t},n]}\\operatorname*{in}_{t\\rightarrow t}^{[M\\alpha_{t+1}]}\\lfloor E_{\\beta}(\\hat{\\pi}_{t+1}-\\hat{\\ell}_{i},y_{t})\\rfloor+\\displaystyle\\sum_{k\\in\\mathbb{K}}\\frac{1}{t\\operatorname*{max}_{t}+1}^{[M\\alpha_{t}]}\\operatorname*{in}_{t\\rightarrow t}^{[k]}\\mathcal{A}_{k}\\right]+\\sqrt{t}}&{}\\\\ {\\leq\\mathbb{E}\\left[\\displaystyle\\sum_{i=0}^{[M\\alpha_{t},n]}\\operatorname*{in}_{t\\rightarrow t}(1)\\overline{{\\Psi_{\\beta}(\\hat{\\pi}_{t+1}-\\hat{\\ell}_{i},y_{t})}}\\right]+\\displaystyle\\operatorname*{inf}_{k\\in\\mathbb{K}}\\displaystyle\\sum_{i=1}^{T}\\mathbb{I}\\{h(x_{t})\\neq y_{t}\\}+\\sqrt{T}}&{}\\\\ {\\leq\\frac{\\mathbb{E}\\left[\\displaystyle\\sum_{i=0}^{T/\\alpha_{t},n]}\\operatorname*{in}_{t\\rightarrow t}^{[M\\alpha_{t}]}\\left(1-\\hat{\\ell}_{i},y_{t}\\right)}{\\sum_{i=0}^{T}\\prod_{s=t}^{T}\\left(\\hat{\\ell}_{i},y_{t}\\right)+2\\left(\\prod_{s=t}^{B}\\left(\\hat{\\pi}_{t+1}\\right)+1\\right)\\mathbb{R}_{\\alpha}\\left(\\frac{T}{1\\sqrt{\\alpha_{t},n}}+1\\right)+1,M\\right)+\\sqrt{t \n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "where the fourth inequality uses the guarantee of $\\kappa$ from Lemma F.5 and the last inequality follows using an identical argument as in the proof of Lemma 3.6 since $\\overline{{\\mathrm{R}}}_{B}(T,\\mathcal{H})$ is a concave, sublinear function of $T$ . ", "page_idx": 23}, {"type": "text", "text": "F.3 Proof of Theorem F.1 ", "text_level": 1, "page_idx": 23}, {"type": "text", "text": "Let $\\boldsymbol{\\mathcal{A}}$ denote the REWA using the generic agnostic online learner from Hanneke et al. [2023] and the algorithm described in Section F.2 as experts. Then, for any stream $(x_{1},y_{1}),...,(x_{T},y_{T})$ , Lemma F.4 gives that ", "page_idx": 23}, {"type": "equation", "text": "$$\n\\mathbb{E}\\left[\\sum_{t=1}^{T}\\mathbb{1}\\{\\mathcal{A}(x_{t})\\neq y_{t}\\}\\right]\\leq\\mathbb{E}\\left[\\operatorname*{min}_{i\\in[2]}M_{i}\\right]+\\sqrt{T}\\leq\\operatorname*{min}_{i\\in[2]}\\mathbb{E}\\left[M_{i}\\right]+\\sqrt{T},\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "where we take $M_{1}$ and $M_{2}$ to be the number of mistakes made by the generic agnostic online learner from Hanneke et al. [2023] and the algorithm described in Section F.2 respectively. Note that $M_{1}$ and $M_{2}$ are random variables. Finally, using [Hanneke et al., 2023, Theorem 4] as well as upper bound (ii) completes the proof of Theorem F.1. ", "page_idx": 23}, {"type": "text", "text": "F.4 Proof of Corollaries F.2 and F.3 ", "text_level": 1, "page_idx": 23}, {"type": "text", "text": "The proof of the generic upper bound on $\\mathrm{M}_{\\mathcal{A}}(T,\\mathcal{H},\\mathcal{Z})$ follows by using the same learner $\\boldsymbol{\\mathcal{A}}$ as in the proof of upper bound (ii) in Theorem F.1. However, this time we bound ", "page_idx": 23}, {"type": "equation", "text": "$$\n\\mathbb{E}\\left[\\operatorname*{inf}_{b\\in\\{0,\\ldots,T-1\\}}\\sum_{t=1}^{T}\\mathbb{1}\\{E_{b}(x_{t})\\neq y_{t}\\}\\right]\\leq\\mathbb{E}\\left[\\sum_{t=1}^{T}\\mathbb{1}\\{E_{\\lceil\\mathrm{M}_{\\mathcal{P}}(T,\\mathcal{Z})\\rceil}(x_{t})\\neq y_{t}\\}\\right]\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "and use an identical analysis as in the proof of upper bound (ii) and Lemma 3.6 to get ", "page_idx": 23}, {"type": "equation", "text": "$$\n\\mathfrak{L}_{A}(T,\\mathcal{H},\\mathcal{Z})=O\\left(\\sqrt{\\mathrm{L}(\\mathcal{H})\\,T\\log_{2}T}\\wedge\\left((\\mathrm{M}_{\\mathcal{P}}(T,\\mathcal{Z})+1)\\,\\overline{{\\mathrm{R}}}_{B}\\Big(\\frac{T}{\\mathrm{M}_{\\mathcal{P}}(T,\\mathcal{Z})+1},\\mathcal{H}\\Big)+\\sqrt{T\\log_{2}T}\\right)\\right).\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "Corollary F.2 follows from the fact that $\\mathrm{R}_{\\mathcal{A}}(T,\\mathcal{H},\\mathcal{Z})=o(T)$ if $\\mathrm{M}_{\\mathcal{P}}(T,\\mathcal{Z})=o(T)$ and $\\mathrm{R}_{B}(T,\\mathcal{H})=$ $o(T)$ . To get the upper bound in Corollary F.3, it suffices to plug in the upper bound $\\overline{{\\mathrm{R}}}_{B}(T,\\mathcal{H})=$ $O\\Big(\\sqrt{\\mathrm{VC}(\\mathcal{H})T\\log_{2}T}\\Big)$ , given by Theorem 6.1 from Hanneke et al. [2024], into the above upper bound on $\\mathrm{R}_{A}(T,\\mathcal{H},\\mathcal{Z})$ . ", "page_idx": 23}, {"type": "text", "text": "NeurIPS Paper Checklist ", "text_level": 1, "page_idx": 24}, {"type": "text", "text": "1. Claims ", "text_level": 1, "page_idx": 24}, {"type": "text", "text": "Question: Do the main claims made in the abstract and introduction accurately reflect the paper\u2019s contributions and scope? ", "page_idx": 24}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 24}, {"type": "text", "text": "Justification: The main claims in the abstract and introduction are proven in Section 3 and Appendix F. In particular, Theorem 3.1, Corollary 3.2, and Corollary 3.3 in the main text cover the main claims made about the realizable setting. The results in Appendix F cover the main claims made about the agnostic setting. ", "page_idx": 24}, {"type": "text", "text": "Guidelines: ", "page_idx": 24}, {"type": "text", "text": "\u2022 The answer NA means that the abstract and introduction do not include the claims made in the paper.   \n\u2022 The abstract and/or introduction should clearly state the claims made, including the contributions made in the paper and important assumptions and limitations. A No or NA answer to this question will not be perceived well by the reviewers.   \n\u2022 The claims made should match theoretical and experimental results, and reflect how much the results can be expected to generalize to other settings.   \n\u2022 It is fine to include aspirational goals as motivation as long as it is clear that these goals are not attained by the paper. ", "page_idx": 24}, {"type": "text", "text": "2. Limitations ", "text_level": 1, "page_idx": 24}, {"type": "text", "text": "Question: Does the paper discuss the limitations of the work performed by the authors? ", "page_idx": 24}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 24}, {"type": "text", "text": "Justification: The assumptions about Predictors are explicitly stated in Section 2. Section 4 discusses limitations and future work. One example of a limitation is the fact that measuring the performance of the Predictor using the 0-1 loss may be restrictive if $\\mathcal{X}$ is continuous. ", "page_idx": 24}, {"type": "text", "text": "Guidelines: ", "text_level": 1, "page_idx": 24}, {"type": "text", "text": "\u2022 The answer NA means that the paper has no limitation while the answer No means that the paper has limitations, but those are not discussed in the paper.   \n\u2022 The authors are encouraged to create a separate \"Limitations\" section in their paper.   \n\u2022 The paper should point out any strong assumptions and how robust the results are to violations of these assumptions (e.g., independence assumptions, noiseless settings, model well-specification, asymptotic approximations only holding locally). The authors should reflect on how these assumptions might be violated in practice and what the implications would be.   \n\u2022 The authors should reflect on the scope of the claims made, e.g., if the approach was only tested on a few datasets or with a few runs. In general, empirical results often depend on implicit assumptions, which should be articulated.   \n\u2022 The authors should reflect on the factors that influence the performance of the approach. For example, a facial recognition algorithm may perform poorly when image resolution is low or images are taken in low lighting. Or a speech-to-text system might not be used reliably to provide closed captions for online lectures because it fails to handle technical jargon.   \n\u2022 The authors should discuss the computational efficiency of the proposed algorithms and how they scale with dataset size.   \n\u2022 If applicable, the authors should discuss possible limitations of their approach to address problems of privacy and fairness.   \n\u2022 While the authors might fear that complete honesty about limitations might be used by reviewers as grounds for rejection, a worse outcome might be that reviewers discover limitations that aren\u2019t acknowledged in the paper. The authors should use their best judgment and recognize that individual actions in favor of transparency play an important role in developing norms that preserve the integrity of the community. Reviewers will be specifically instructed to not penalize honesty concerning limitations. ", "page_idx": 24}, {"type": "text", "text": "3. Theory Assumptions and Proofs ", "text_level": 1, "page_idx": 24}, {"type": "text", "text": "Question: For each theoretical result, does the paper provide the full set of assumptions and a complete (and correct) proof? ", "page_idx": 25}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 25}, {"type": "text", "text": "Justification: All theoretical results are numbered and cross-referenced. Assumptions are are made clear in the theorem statements. All new theoretical results have a complete, detailed proof either in the main-text of the appendix. Theorem 3.1 follows immediately from Lemma 3.4, Lemma 3.5, Lemma 3.6, and Lemma 3.7. Lemma 3.4 is a well-known result. Lemma 3.5 is proven in the detail in the main text. Lemma 3.6 and 3.7 are proven in Appendix B. Theorem 3.8 is proven in Appendix E. Corollary 3.2 and 3.3 are proved in Appendix C. All theoretical results for the agnostic setting are stated and proven in Appendix F. ", "page_idx": 25}, {"type": "text", "text": "Guidelines: ", "text_level": 1, "page_idx": 25}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include theoretical results.   \n\u2022 All the theorems, formulas, and proofs in the paper should be numbered and crossreferenced.   \n\u2022 All assumptions should be clearly stated or referenced in the statement of any theorems.   \n\u2022 The proofs can either appear in the main paper or the supplemental material, but if they appear in the supplemental material, the authors are encouraged to provide a short proof sketch to provide intuition.   \n\u2022 Inversely, any informal proof provided in the core of the paper should be complemented by formal proofs provided in appendix or supplemental material.   \n\u2022 Theorems and Lemmas that the proof relies upon should be properly referenced. ", "page_idx": 25}, {"type": "text", "text": "4. Experimental Result Reproducibility ", "text_level": 1, "page_idx": 25}, {"type": "text", "text": "Question: Does the paper fully disclose all the information needed to reproduce the main experimental results of the paper to the extent that it affects the main claims and/or conclusions of the paper (regardless of whether the code and data are provided or not)? ", "page_idx": 25}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 25}, {"type": "text", "text": "Justification: This paper has no experiments. ", "page_idx": 25}, {"type": "text", "text": "Guidelines: ", "page_idx": 25}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 If the paper includes experiments, a No answer to this question will not be perceived well by the reviewers: Making the paper reproducible is important, regardless of whether the code and data are provided or not.   \n\u2022 If the contribution is a dataset and/or model, the authors should describe the steps taken to make their results reproducible or verifiable.   \n\u2022 Depending on the contribution, reproducibility can be accomplished in various ways. For example, if the contribution is a novel architecture, describing the architecture fully might suffice, or if the contribution is a specific model and empirical evaluation, it may be necessary to either make it possible for others to replicate the model with the same dataset, or provide access to the model. In general. releasing code and data is often one good way to accomplish this, but reproducibility can also be provided via detailed instructions for how to replicate the results, access to a hosted model (e.g., in the case of a large language model), releasing of a model checkpoint, or other means that are appropriate to the research performed.   \n\u2022 While NeurIPS does not require releasing code, the conference does require all submissions to provide some reasonable avenue for reproducibility, which may depend on the nature of the contribution. For example (a) If the contribution is primarily a new algorithm, the paper should make it clear how to reproduce that algorithm. (b) If the contribution is primarily a new model architecture, the paper should describe the architecture clearly and fully. (c) If the contribution is a new model (e.g., a large language model), then there should either be a way to access this model for reproducing the results or a way to reproduce the model (e.g., with an open-source dataset or instructions for how to construct the dataset). ", "page_idx": 25}, {"type": "text", "text": "(d) We recognize that reproducibility may be tricky in some cases, in which case authors are welcome to describe the particular way they provide for reproducibility. In the case of closed-source models, it may be that access to the model is limited in some way (e.g., to registered users), but it should be possible for other researchers to have some path to reproducing or verifying the results. ", "page_idx": 26}, {"type": "text", "text": "5. Open access to data and code ", "text_level": 1, "page_idx": 26}, {"type": "text", "text": "Question: Does the paper provide open access to the data and code, with sufficient instructions to faithfully reproduce the main experimental results, as described in supplemental material? ", "page_idx": 26}, {"type": "text", "text": "Answer: [NA] Justification:This paper has no experiments. ", "page_idx": 26}, {"type": "text", "text": "\u2022 The answer NA means that paper does not include experiments requiring code.   \n\u2022 Please see the NeurIPS code and data submission guidelines (https://nips.cc/ public/guides/CodeSubmissionPolicy) for more details.   \n\u2022 While we encourage the release of code and data, we understand that this might not be possible, so \u201cNo\u201d is an acceptable answer. Papers cannot be rejected simply for not including code, unless this is central to the contribution (e.g., for a new open-source benchmark).   \n\u2022 The instructions should contain the exact command and environment needed to run to reproduce the results. See the NeurIPS code and data submission guidelines (https: //nips.cc/public/guides/CodeSubmissionPolicy) for more details.   \n\u2022 The authors should provide instructions on data access and preparation, including how to access the raw data, preprocessed data, intermediate data, and generated data, etc.   \n\u2022 The authors should provide scripts to reproduce all experimental results for the new proposed method and baselines. If only a subset of experiments are reproducible, they should state which ones are omitted from the script and why.   \n\u2022 At submission time, to preserve anonymity, the authors should release anonymized versions (if applicable).   \n\u2022 Providing as much information as possible in supplemental material (appended to the paper) is recommended, but including URLs to data and code is permitted. ", "page_idx": 26}, {"type": "text", "text": "6. Experimental Setting/Details ", "text_level": 1, "page_idx": 26}, {"type": "text", "text": "Question: Does the paper specify all the training and test details (e.g., data splits, hyperparameters, how they were chosen, type of optimizer, etc.) necessary to understand the results? ", "page_idx": 26}, {"type": "text", "text": "Answer: [NA] Justification: This paper has no experiments. ", "page_idx": 26}, {"type": "text", "text": "Guidelines: ", "page_idx": 26}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments. \u2022 The experimental setting should be presented in the core of the paper to a level of detail that is necessary to appreciate the results and make sense of them. \u2022 The full details can be provided either with the code, in appendix, or as supplemental material. ", "page_idx": 26}, {"type": "text", "text": "7. Experiment Statistical Significance ", "text_level": 1, "page_idx": 26}, {"type": "text", "text": "Question: Does the paper report error bars suitably and correctly defined or other appropriate information about the statistical significance of the experiments? ", "page_idx": 26}, {"type": "text", "text": "Answer: [NA]   \nJustification: This paper has no experiments.   \nGuidelines: \u2022 The answer NA means that the paper does not include experiments.   \n\u2022 The authors should answer \"Yes\" if the results are accompanied by error bars, confidence intervals, or statistical significance tests, at least for the experiments that support the main claims of the paper.   \n\u2022 The factors of variability that the error bars are capturing should be clearly stated (for example, train/test split, initialization, random drawing of some parameter, or overall run with given experimental conditions).   \n\u2022 The method for calculating the error bars should be explained (closed form formula, call to a library function, bootstrap, etc.)   \n\u2022 The assumptions made should be given (e.g., Normally distributed errors).   \n\u2022 It should be clear whether the error bar is the standard deviation or the standard error of the mean.   \n\u2022 It is OK to report 1-sigma error bars, but one should state it. The authors should preferably report a 2-sigma error bar than state that they have a $96\\%$ CI, if the hypothesis of Normality of errors is not verified.   \n\u2022 For asymmetric distributions, the authors should be careful not to show in tables or figures symmetric error bars that would yield results that are out of range (e.g. negative error rates).   \n\u2022 If error bars are reported in tables or plots, The authors should explain in the text how they were calculated and reference the corresponding figures or tables in the text. ", "page_idx": 26}, {"type": "text", "text": "", "page_idx": 27}, {"type": "text", "text": "8. Experiments Compute Resources ", "text_level": 1, "page_idx": 27}, {"type": "text", "text": "Question: For each experiment, does the paper provide sufficient information on the computer resources (type of compute workers, memory, time of execution) needed to reproduce the experiments? ", "page_idx": 27}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 27}, {"type": "text", "text": "Justification: This paper has no experiments. ", "page_idx": 27}, {"type": "text", "text": "Guidelines: ", "page_idx": 27}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 The paper should indicate the type of compute workers CPU or GPU, internal cluster, or cloud provider, including relevant memory and storage.   \n\u2022 The paper should provide the amount of compute required for each of the individual experimental runs as well as estimate the total compute.   \n\u2022 The paper should disclose whether the full research project required more compute than the experiments reported in the paper (e.g., preliminary or failed experiments that didn\u2019t make it into the paper). ", "page_idx": 27}, {"type": "text", "text": "9. Code Of Ethics ", "text_level": 1, "page_idx": 27}, {"type": "text", "text": "Question: Does the research conducted in the paper conform, in every respect, with the NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines? ", "page_idx": 27}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 27}, {"type": "text", "text": "Justification: We have read and made sure that our paper conforms to the NeurIPS Code of Ethics. We have also made sure to preserve anonymity. ", "page_idx": 27}, {"type": "text", "text": "Guidelines: ", "page_idx": 27}, {"type": "text", "text": "\u2022 The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics.   \n\u2022 If the authors answer No, they should explain the special circumstances that require a deviation from the Code of Ethics.   \n\u2022 The authors should make sure to preserve anonymity (e.g., if there is a special consideration due to laws or regulations in their jurisdiction). ", "page_idx": 27}, {"type": "text", "text": "10. Broader Impacts ", "text_level": 1, "page_idx": 27}, {"type": "text", "text": "Question: Does the paper discuss both potential positive societal impacts and negative societal impacts of the work performed? ", "page_idx": 27}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 27}, {"type": "text", "text": "Justification: Our work is theoretical and contributes to our understanding of machine learning algorithms. Beyond theoretical insights that can be used to develop better algorithms, our work does not have direct societal impacts. ", "page_idx": 28}, {"type": "text", "text": "Guidelines: ", "page_idx": 28}, {"type": "text", "text": "\u2022 The answer NA means that there is no societal impact of the work performed.   \n\u2022 If the authors answer NA or No, they should explain why their work has no societal impact or why the paper does not address societal impact.   \n\u2022 Examples of negative societal impacts include potential malicious or unintended uses (e.g., disinformation, generating fake profiles, surveillance), fairness considerations (e.g., deployment of technologies that could make decisions that unfairly impact specific groups), privacy considerations, and security considerations.   \n\u2022 The conference expects that many papers will be foundational research and not tied to particular applications, let alone deployments. However, if there is a direct path to any negative applications, the authors should point it out. For example, it is legitimate to point out that an improvement in the quality of generative models could be used to generate deepfakes for disinformation. On the other hand, it is not needed to point out that a generic algorithm for optimizing neural networks could enable people to train models that generate Deepfakes faster.   \n\u2022 The authors should consider possible harms that could arise when the technology is being used as intended and functioning correctly, harms that could arise when the technology is being used as intended but gives incorrect results, and harms following from (intentional or unintentional) misuse of the technology.   \n\u2022 If there are negative societal impacts, the authors could also discuss possible mitigation strategies (e.g., gated release of models, providing defenses in addition to attacks, mechanisms for monitoring misuse, mechanisms to monitor how a system learns from feedback over time, improving the efficiency and accessibility of ML). ", "page_idx": 28}, {"type": "text", "text": "11. Safeguards ", "text_level": 1, "page_idx": 28}, {"type": "text", "text": "Question: Does the paper describe safeguards that have been put in place for responsible release of data or models that have a high risk for misuse (e.g., pretrained language models, image generators, or scraped datasets)? ", "page_idx": 28}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 28}, {"type": "text", "text": "Justification: This paper has no experiments and therefore poses no such risks. Guidelines: ", "page_idx": 28}, {"type": "text", "text": "\u2022 The answer NA means that the paper poses no such risks.   \n\u2022 Released models that have a high risk for misuse or dual-use should be released with necessary safeguards to allow for controlled use of the model, for example by requiring that users adhere to usage guidelines or restrictions to access the model or implementing safety filters.   \n\u2022 Datasets that have been scraped from the Internet could pose safety risks. The authors should describe how they avoided releasing unsafe images.   \n\u2022 We recognize that providing effective safeguards is challenging, and many papers do not require this, but we encourage authors to take this into account and make a best faith effort. ", "page_idx": 28}, {"type": "text", "text": "12. Licenses for existing assets ", "text_level": 1, "page_idx": 28}, {"type": "text", "text": "Question: Are the creators or original owners of assets (e.g., code, data, models), used in the paper, properly credited and are the license and terms of use explicitly mentioned and properly respected? ", "page_idx": 28}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 28}, {"type": "text", "text": "Justification: This paper does not use existing assets. ", "page_idx": 28}, {"type": "text", "text": "Guidelines: ", "page_idx": 28}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not use existing assets.   \n\u2022 The authors should cite the original paper that produced the code package or dataset.   \n\u2022 The authors should state which version of the asset is used and, if possible, include a URL.   \n\u2022 The name of the license (e.g., CC-BY 4.0) should be included for each asset.   \n\u2022 For scraped data from a particular source (e.g., website), the copyright and terms of service of that source should be provided.   \n\u2022 If assets are released, the license, copyright information, and terms of use in the package should be provided. For popular datasets, paperswithcode.com/datasets has curated licenses for some datasets. Their licensing guide can help determine the license of a dataset.   \n\u2022 For existing datasets that are re-packaged, both the original license and the license of the derived asset (if it has changed) should be provided.   \n\u2022 If this information is not available online, the authors are encouraged to reach out to the asset\u2019s creators. ", "page_idx": 28}, {"type": "text", "text": "", "page_idx": 29}, {"type": "text", "text": "13. New Assets ", "text_level": 1, "page_idx": 29}, {"type": "text", "text": "Question: Are new assets introduced in the paper well documented and is the documentation provided alongside the assets? ", "page_idx": 29}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 29}, {"type": "text", "text": "Justification: This paper does not release new assets. ", "page_idx": 29}, {"type": "text", "text": "Guidelines: ", "page_idx": 29}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not release new assets.   \n\u2022 Researchers should communicate the details of the dataset/code/model as part of their submissions via structured templates. This includes details about training, license, limitations, etc.   \n\u2022 The paper should discuss whether and how consent was obtained from people whose asset is used.   \n\u2022 At submission time, remember to anonymize your assets (if applicable). You can either create an anonymized URL or include an anonymized zip file. ", "page_idx": 29}, {"type": "text", "text": "14. Crowdsourcing and Research with Human Subjects ", "text_level": 1, "page_idx": 29}, {"type": "text", "text": "Question: For crowdsourcing experiments and research with human subjects, does the paper include the full text of instructions given to participants and screenshots, if applicable, as well as details about compensation (if any)? ", "page_idx": 29}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 29}, {"type": "text", "text": "Justification: This paper does not involve crowdsourcing nor research with human subjects. Guidelines: ", "page_idx": 29}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u2022 Including this information in the supplemental material is fine, but if the main contribution of the paper involves human subjects, then as much detail as possible should be included in the main paper.   \n\u2022 According to the NeurIPS Code of Ethics, workers involved in data collection, curation, or other labor should be paid at least the minimum wage in the country of the data collector. ", "page_idx": 29}, {"type": "text", "text": "15. Institutional Review Board (IRB) Approvals or Equivalent for Research with Human Subjects ", "page_idx": 29}, {"type": "text", "text": "Question: Does the paper describe potential risks incurred by study participants, whether such risks were disclosed to the subjects, and whether Institutional Review Board (IRB) approvals (or an equivalent approval/review based on the requirements of your country or institution) were obtained? ", "page_idx": 29}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 29}, {"type": "text", "text": "Justification: This paper does not involve crowdsourcing nor research with human subjects. Guidelines: ", "page_idx": 29}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u2022 Depending on the country in which research is conducted, IRB approval (or equivalent) may be required for any human subjects research. If you obtained IRB approval, you should clearly state this in the paper.   \n\u2022 We recognize that the procedures for this may vary significantly between institutions and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the guidelines for their institution.   \n\u2022 For initial submissions, do not include any information that would break anonymity (if applicable), such as the institution conducting the review. ", "page_idx": 30}]