[{"figure_path": "O2UwxfhY1P/tables/tables_9_1.jpg", "caption": "Table 1: Performance comparison for single and multi-modal contrastive learning.", "description": "This table presents a comparison of the performance of single-modal and multi-modal contrastive learning models on a real-world dataset, ColoredMNIST.  The ColoredMNIST dataset is a variation of the standard MNIST dataset that introduces spurious correlations between digit labels and colors. The results show that multi-modal contrastive learning significantly outperforms single-modal contrastive learning in terms of test accuracy under this distribution shift, achieving 82.13% compared to 12.68%. This highlights the advantage of multi-modal learning in handling data with spurious correlations, demonstrating better generalization to out-of-distribution data.", "section": "6 Experiments"}]