[{"figure_path": "UPxmISfNCO/tables/tables_8_1.jpg", "caption": "Table 1: Benchmark our RELA with various prior models against BYOL. We compare evaluation results of the models trained using BYOL with 10%, 20% and 50% training budget/steps; \u2022 BYOL (7) with different prior models; BYOL with full budget, denoted as BYOL* in this table. Regarding the prior models used for our RELA, we respectively utilize six models with increasing representation capabilities, including \u26ab randomly initialized network (Rand.); \u2022 four BYOL*-trained models (CF10-T, CF100-T, TIN-T, IN1K-T) corresponding to four datasets (listed below); \u2022 CLIP-RN50. The evaluations are performed across four datasets, i.e., CIFAR-10 (CF-10), CIFAR-100 (CF-100), Tiny-ImageNet (T-IN), and ImageNet-1K (IN-1K). We underline the results that outperform the full training, and bold the results that achieve the highest performance using a specific ratio of budget. All the networks used for training are ResNet-18, except the ResNet-50 used for IN-1K.", "description": "This table benchmarks the proposed RELA method against the baseline BYOL method across four datasets (CIFAR-10, CIFAR-100, Tiny-ImageNet, ImageNet-1K) and varying training budget percentages (10%, 20%, 50%).  It compares the performance of BYOL trained with different prior models used by RELA, including randomly initialized networks and those pre-trained on other datasets. The results highlight the impact of different prior models on RELA's performance relative to BYOL trained with a full budget.", "section": "5.1 Primary Experimental Results and Analysis"}, {"figure_path": "UPxmISfNCO/tables/tables_9_1.jpg", "caption": "Table 1: Benchmark our RELA with various prior models against BYOL. We compare evaluation results of the models trained using BYOL with 10%, 20% and 50% training budget/steps; \n\u2022 BYOL (7) with different prior models; BYOL with full budget, denoted as BYOL* in this table. Regarding the prior models used for our RELA, we respectively utilize six models with increasing representation capabilities, including \u26ab randomly initialized network (Rand.); \u2022 four BYOL*-trained models (CF10-T, CF100-T, TIN-T, IN1K-T) corresponding to four datasets (listed below); \u2022 CLIP-RN50. The evaluations are performed across four datasets, i.e., CIFAR-10 (CF-10), CIFAR-100 (CF-100), Tiny-ImageNet (T-IN), and ImageNet-1K (IN-1K). We underline the results that outperform the full training, and bold the results that achieve the highest performance using a specific ratio of budget. All the networks used for training are ResNet-18, except the ResNet-50 used for IN-1K.", "description": "This table benchmarks the proposed RELA method against the baseline BYOL method.  It compares the performance of models trained with different percentages (10%, 20%, 50%) of the original training budget, using various pre-trained models as priors in RELA. The results are shown across four datasets: CIFAR-10, CIFAR-100, Tiny-ImageNet, and ImageNet. Underlined values indicate performance exceeding that of the fully trained BYOL model, while bold values represent the best performance achieved for a given budget percentage.", "section": "5.1 Primary Experimental Results and Analysis"}, {"figure_path": "UPxmISfNCO/tables/tables_9_2.jpg", "caption": "Table 1: Benchmark our RELA with various prior models against BYOL. We compare evaluation results of the models trained using BYOL with 10%, 20% and 50% training budget/steps; \u2022 BYOL (7) with different prior models; BYOL with full budget, denoted as BYOL* in this table. Regarding the prior models used for our RELA, we respectively utilize six models with increasing representation capabilities, including \u26ab randomly initialized network (Rand.); \u2022 four BYOL*-trained models (CF10-T, CF100-T, TIN-T, IN1K-T) corresponding to four datasets (listed below); \u2022 CLIP-RN50. The evaluations are performed across four datasets, i.e., CIFAR-10 (CF-10), CIFAR-100 (CF-100), Tiny-ImageNet (T-IN), and ImageNet-1K (IN-1K). We underline the results that outperform the full training, and bold the results that achieve the highest performance using a specific ratio of budget. All the networks used for training are ResNet-18, except the ResNet-50 used for IN-1K.", "description": "This table benchmarks the performance of RELA against the baseline BYOL model across four datasets (CIFAR-10, CIFAR-100, Tiny-ImageNet, and ImageNet-1K) and various training budgets (10%, 20%, and 50%).  It compares RELA using different prior models (randomly initialized, four BYOL-trained models on different datasets, and CLIP-RN50) against the full BYOL training.  The table highlights results that outperform the full BYOL training and those achieving the best performance for a given budget ratio.  ResNet-18 is the primary architecture, with ResNet-50 used only for ImageNet-1K.", "section": "5.1 Primary Experimental Results and Analysis"}, {"figure_path": "UPxmISfNCO/tables/tables_27_1.jpg", "caption": "Table 1: Benchmark our RELA with various prior models against BYOL. We compare evaluation results of the models trained using BYOL with 10%, 20% and 50% training budget/steps; \u2022 BYOL (7) with different prior models; BYOL with full budget, denoted as BYOL* in this table. Regarding the prior models used for our RELA, we respectively utilize six models with increasing representation capabilities, including \u26ab randomly initialized network (Rand.); \u2022 four BYOL*-trained models (CF10-T, CF100-T, TIN-T, IN1K-T) corresponding to four datasets (listed below); \u2022 CLIP-RN50. The evaluations are performed across four datasets, i.e., CIFAR-10 (CF-10), CIFAR-100 (CF-100), Tiny-ImageNet (T-IN), and ImageNet-1K (IN-1K). We underline the results that outperform the full training, and bold the results that achieve the highest performance using a specific ratio of budget. All the networks used for training are ResNet-18, except the ResNet-50 used for IN-1K.", "description": "This table benchmarks the performance of RELA against the baseline BYOL method across four datasets (CIFAR-10, CIFAR-100, Tiny-ImageNet, ImageNet-1K) and various training budget percentages (10%, 20%, 50%).  It compares the performance of BYOL trained with different prior models (including randomly initialized networks, BYOL-trained models on different datasets, and CLIP-RN50). The table highlights results that surpass full BYOL training or achieve the best performance for a given budget percentage, showcasing RELA's effectiveness in improving training efficiency.", "section": "5.1 Primary Experimental Results and Analysis"}, {"figure_path": "UPxmISfNCO/tables/tables_31_1.jpg", "caption": "Table 1: Benchmark our RELA with various prior models against BYOL. We compare evaluation results of the models trained using BYOL with 10%, 20% and 50% training budget/steps; \u2022 BYOL (7) with different prior models; BYOL with full budget, denoted as BYOL* in this table. Regarding the prior models used for our RELA, we respectively utilize six models with increasing representation capabilities, including \u26ab randomly initialized network (Rand.); \u2022 four BYOL*-trained models (CF10-T, CF100-T, TIN-T, IN1K-T) corresponding to four datasets (listed below); \u2022 CLIP-RN50. The evaluations are performed across four datasets, i.e., CIFAR-10 (CF-10), CIFAR-100 (CF-100), Tiny-ImageNet (T-IN), and ImageNet-1K (IN-1K). We underline the results that outperform the full training, and bold the results that achieve the highest performance using a specific ratio of budget. All the networks used for training are ResNet-18, except the ResNet-50 used for IN-1K.", "description": "This table compares the performance of RELA (with different prior models) and standard BYOL on four datasets (CIFAR-10, CIFAR-100, Tiny-ImageNet, and ImageNet) using different training budgets (10%, 20%, 50%, and 100%).  It shows that RELA consistently outperforms BYOL, especially with stronger prior models and lower budgets.  The results are presented as Top-1 accuracy and demonstrate the effectiveness and efficiency of RELA.", "section": "5.1 Primary Experimental Results and Analysis"}, {"figure_path": "UPxmISfNCO/tables/tables_32_1.jpg", "caption": "Table 1: Benchmark our RELA with various prior models against BYOL. We compare evaluation results of the models trained using BYOL with 10%, 20% and 50% training budget/steps; \u2022 BYOL (7) with different prior models; BYOL with full budget, denoted as BYOL* in this table. Regarding the prior models used for our RELA, we respectively utilize six models with increasing representation capabilities, including \u26ab randomly initialized network (Rand.); \u2022 four BYOL*-trained models (CF10-T, CF100-T, TIN-T, IN1K-T) corresponding to four datasets (listed below); \u2022 CLIP-RN50. The evaluations are performed across four datasets, i.e., CIFAR-10 (CF-10), CIFAR-100 (CF-100), Tiny-ImageNet (T-IN), and ImageNet-1K (IN-1K). We underline the results that outperform the full training, and bold the results that achieve the highest performance using a specific ratio of budget. All the networks used for training are ResNet-18, except the ResNet-50 used for IN-1K.", "description": "This table benchmarks the performance of RELA against BYOL using various prior models and different training budget ratios (10%, 20%, 50%).  It compares the results across four datasets: CIFAR-10, CIFAR-100, Tiny-ImageNet, and ImageNet-1K.  The prior models used for RELA include a randomly initialized network, four BYOL-trained models, and CLIP-RN50. The table highlights results that outperform the full BYOL training and those achieving the best performance for each budget ratio.", "section": "5.1 Primary Experimental Results and Analysis"}, {"figure_path": "UPxmISfNCO/tables/tables_32_2.jpg", "caption": "Table 1: Benchmark our RELA with various prior models against BYOL. We compare evaluation results of the models trained using BYOL with 10%, 20% and 50% training budget/steps; \n\u2022 BYOL (7) with different prior models; BYOL with full budget, denoted as BYOL* in this table. Regarding the prior models used for our RELA, we respectively utilize six models with increasing representation capabilities, including \u26ab randomly initialized network (Rand.); \u2022 four BYOL*-trained models (CF10-T, CF100-T, TIN-T, IN1K-T) corresponding to four datasets (listed below); \u2022 CLIP-RN50. The evaluations are performed across four datasets, i.e., CIFAR-10 (CF-10), CIFAR-100 (CF-100), Tiny-ImageNet (T-IN), and ImageNet-1K (IN-1K). We underline the results that outperform the full training, and bold the results that achieve the highest performance using a specific ratio of budget. All the networks used for training are ResNet-18, except the ResNet-50 used for IN-1K.", "description": "This table benchmarks the proposed RELA method against the baseline BYOL method. It compares the performance of models trained with different training budgets (10%, 20%, and 50%) and with various prior models (including randomly initialized networks and BYOL-trained models on different datasets). The evaluation is performed on four datasets (CIFAR-10, CIFAR-100, Tiny-ImageNet, and ImageNet-1K), and the results show that RELA consistently outperforms BYOL, especially when using stronger prior models and with reduced training budgets.", "section": "5.1 Primary Experimental Results and Analysis"}, {"figure_path": "UPxmISfNCO/tables/tables_32_3.jpg", "caption": "Table 1: Benchmark our RELA with various prior models against BYOL. We compare evaluation results of the models trained using BYOL with 10%, 20% and 50% training budget/steps; \u2022 BYOL (7) with different prior models; BYOL with full budget, denoted as BYOL* in this table. Regarding the prior models used for our RELA, we respectively utilize six models with increasing representation capabilities, including \u26ab randomly initialized network (Rand.); \u2022 four BYOL*-trained models (CF10-T, CF100-T, TIN-T, IN1K-T) corresponding to four datasets (listed below); \u2022 CLIP-RN50. The evaluations are performed across four datasets, i.e., CIFAR-10 (CF-10), CIFAR-100 (CF-100), Tiny-ImageNet (T-IN), and ImageNet-1K (IN-1K). We underline the results that outperform the full training, and bold the results that achieve the highest performance using a specific ratio of budget. All the networks used for training are ResNet-18, except the ResNet-50 used for IN-1K.", "description": "This table benchmarks the RELA method against the BYOL method across four datasets with varying training budgets.  It compares the performance of BYOL trained with different percentages (10%, 20%, 50%) of the original training budget against RELA trained using six different prior models (randomly initialized, four BYOL*-trained models from different datasets, and CLIP-RN50). The results show that RELA generally outperforms BYOL, particularly with reduced training budgets, and that stronger prior models lead to better results. The best results for each budget are highlighted.", "section": "5.1 Primary Experimental Results and Analysis"}, {"figure_path": "UPxmISfNCO/tables/tables_33_1.jpg", "caption": "Table 1: Benchmark our RELA with various prior models against BYOL. We compare evaluation results of the models trained using BYOL with 10%, 20% and 50% training budget/steps; \u2022 BYOL (7) with different prior models; BYOL with full budget, denoted as BYOL* in this table. Regarding the prior models used for our RELA, we respectively utilize six models with increasing representation capabilities, including \u26ab randomly initialized network (Rand.); \u2022 four BYOL*-trained models (CF10-T, CF100-T, TIN-T, IN1K-T) corresponding to four datasets (listed below); \u2022 CLIP-RN50. The evaluations are performed across four datasets, i.e., CIFAR-10 (CF-10), CIFAR-100 (CF-100), Tiny-ImageNet (T-IN), and ImageNet-1K (IN-1K). We underline the results that outperform the full training, and bold the results that achieve the highest performance using a specific ratio of budget. All the networks used for training are ResNet-18, except the ResNet-50 used for IN-1K.", "description": "This table benchmarks the RELA method against the BYOL method using various prior models and different training budgets. It shows the top-1 accuracy results across four datasets (CIFAR-10, CIFAR-100, Tiny-ImageNet, and ImageNet-1K) for different training budget percentages (10%, 20%, and 50%). The prior models used include a randomly initialized network, four BYOL-trained models from different datasets, and a CLIP-RN50 model. The table highlights results that surpass the full training performance and those achieving the best performance for each budget percentage.  ResNet-18 is used for most models, except for ImageNet-1K, where ResNet-50 is employed.", "section": "5.1 Primary Experimental Results and Analysis"}]