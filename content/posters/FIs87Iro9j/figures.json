[{"figure_path": "FIs87Iro9j/figures/figures_1_1.jpg", "caption": "Figure 1: We design our approach to solve three primary challenges (i) Cross-Domain Matching: Matching low-resolution, long-range faces with high-quality gallery faces. (ii) Linear Runtime Complexity: Ensuring our method's time complexity increases linearly with the number of features. (iii) Compatibility with Legacy Templates: Relying solely on final feature vectors for fusion to maintain compatibility with pre-enrolled feature stores that lack intermediate features or metadata.", "description": "This figure illustrates the three main challenges that the ProxyFusion method addresses: Cross-domain matching (matching low-resolution, long-range faces with high-quality gallery faces), linear runtime complexity (ensuring linear increase in time complexity with the number of features), and compatibility with legacy templates (using only final feature vectors, compatible with existing template databases that do not store intermediate features or metadata).  The figure uses a table to compare ProxyFusion to other existing methods for each of the three challenges, showcasing ProxyFusion's advantages in terms of solving these challenges simultaneously.", "section": "1 Introduction"}, {"figure_path": "FIs87Iro9j/figures/figures_2_1.jpg", "caption": "Figure 2: An overview of our proposed ProxyFusion Approach. Post feature extraction, our method is divided two end-to-end trainable stages: (i) Expert Selection and (ii) Sparse Expert Network Feature Aggregation. The Expert Selection module takes the {fi}_1 and returns the indices of expert networks based on proxy relevancy scores. Next, the selected expert networks compute set-centers conditioned on distribution and aligned proxy. These set-centers attend over the input feature set {fi}1 to compute aggregation weights.", "description": "This figure illustrates the ProxyFusion approach, which consists of two main stages: Expert Selection and Sparse Expert Network Feature Aggregation.  The Expert Selection module uses learnable proxies to identify the most relevant expert networks for a given input feature set. These selected networks then generate set-centers, which are used to compute aggregation weights for the input features, producing a final aggregated representation.", "section": "2 Method"}, {"figure_path": "FIs87Iro9j/figures/figures_6_1.jpg", "caption": "Figure 3: Visualizations of learned weights on BTS3.1 dataset's gallery and probe set. Images on the top are from high quality gallery, and images on the bottom are from low resolution long-range probes. Faces are sorted based on ProxyFusion attention weights from low to high. We present these weights for each of the selected expert.", "description": "This figure visualizes the weights assigned by different experts (learned in the ProxyFusion model) to faces within the gallery and probe sets of the BTS3.1 dataset.  The images are arranged by their assigned weights, from lowest to highest, revealing how the model prioritizes high-quality, informative faces (frontal views) in the gallery while focusing on the limited number of high-quality frames in the low-resolution probe videos. This demonstrates the model's ability to learn distinctive face quality information and its effectiveness in long-range, low-resolution face recognition settings.", "section": "3.3 Discussion and Ablation"}, {"figure_path": "FIs87Iro9j/figures/figures_6_2.jpg", "caption": "Figure 4: A heatmap of TAR@FAR=10-2 on Face Included Treatment Setting of BTS 3.1. The X-axis is the number of selected experts while the Y Axis is total number of experts / proxies.", "description": "This heatmap shows the performance of the ProxyFusion model on the BTS 3.1 dataset's Face Included Treatment Setting. The performance is measured by TAR@FAR=10-2 (True Acceptance Rate at a False Acceptance Rate of 10^-2).  The X-axis represents the number of selected experts (out of the total number of experts/proxies), showing how choosing a subset of experts impacts performance. The Y-axis displays the total number of experts/proxies used in the model. The color intensity represents the TAR@FAR=10-2 value, with darker shades indicating better performance.", "section": "3.3 Discussion and Ablation"}, {"figure_path": "FIs87Iro9j/figures/figures_7_1.jpg", "caption": "Figure 5: Visualizations of learned weights on BTS3.1 dataset's gallery and probe set. Images on the top are from high quality gallery, and images on the bottom are from low resolution long-range probes. Faces are sorted based on ProxyFusion attention weights from low to high. We present these weights for each of the selected expert.", "description": "This figure visualizes the attention weights assigned by ProxyFusion to different faces in both gallery (high-quality) and probe (low-resolution, long-range) sets of the BTS3.1 dataset.  The images are sorted for each expert by their assigned weights, showing that the model prioritizes high-quality, informative faces in both sets.  Experts learn to focus on different aspects of face quality for the aggregation process, for example, prioritizing frontal or profile views and assigning less importance to faces with poor image quality.", "section": "3.3 Discussion and Ablation"}]