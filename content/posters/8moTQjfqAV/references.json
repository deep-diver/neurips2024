{"references": [{"fullname_first_author": "Volodymyr Mnih", "paper_title": "Playing Atari with Deep Reinforcement Learning", "publication_date": "2013-12-13", "reason": "This paper introduced the use of deep learning for reinforcement learning, a foundational concept for the current research."}, {"fullname_first_author": "Matthew Botvinick", "paper_title": "Deep Reinforcement Learning and Its Neuroscientific Implications", "publication_date": "2020-08-01", "reason": "This review paper established a strong connection between deep reinforcement learning and neuroscience, providing critical context for this work."}, {"fullname_first_author": "Will Dabney", "paper_title": "A distributional code for value in dopamine-based reinforcement learning", "publication_date": "2020-01-01", "reason": "This paper investigated the distributional nature of reward prediction errors in dopamine, providing a biological basis for the algorithmic approach proposed in this paper."}, {"fullname_first_author": "Geoffrey Hinton", "paper_title": "The forward-forward algorithm: Some preliminary investigations", "publication_date": "2022-12-01", "reason": "This paper proposed a novel forward-forward algorithm that avoids backpropagation, providing a more biologically plausible approach to credit assignment, inspiring the algorithm in the current work."}, {"fullname_first_author": "Richard S Sutton", "paper_title": "Learning to predict by the methods of temporal differences", "publication_date": "1988-01-01", "reason": "This foundational paper in reinforcement learning introduced the temporal difference learning algorithm, which is the basis for the reward prediction error signal used in this paper."}]}