[{"figure_path": "VUgXAWOCQz/figures/figures_4_1.jpg", "caption": "Figure 1: Illustration of Theorem 3.1 for \u03b51 > \u03b52.", "description": "The figure illustrates Theorem 3.1, which characterizes the inverse feasibility set.  It shows a series of nested ellipses, where each ellipse represents the \u03b5-inverse feasibility set C\u03b5(\u03c0\u03b5) for a different value of \u03b5. The innermost, dark green ellipse represents the inverse feasibility set C(\u03c0\u03b5), which contains cost functions for which the expert policy \u03c0\u03b5 is optimal. As \u03b5 increases, the ellipses grow larger, representing a larger set of nearly optimal cost functions C\u03b5(\u03c0\u03b5).  The figure shows that as epsilon gets larger, more cost functions are considered \"nearly\" optimal.", "section": "3 Inverse reinforcement learning and characterization of solutions"}, {"figure_path": "VUgXAWOCQz/figures/figures_6_1.jpg", "caption": "Figure 2: Main building blocks of our methodology", "description": "This figure illustrates the main steps of the proposed methodology.  It starts with the inverse MDP problem, which is addressed using occupancy measures and linear duality to formulate an infinite-dimensional feasibility LP.  This is then tackled by adding a normalization constraint and projecting onto features to create a regularized semi-infinite program. Constraint sampling is used to reduce this to a scenario convex program, which provides a scenario bound.  Alternatively, a data-driven counterpart is used when only expert trajectories and a generative model are available. This also involves finite-sample analysis.", "section": "4 Towards recovering a nearly optimal cost function"}, {"figure_path": "VUgXAWOCQz/figures/figures_26_1.jpg", "caption": "Figure 3: Solutions of the Sampled Inverse Program SIPN. The variable N is the number of i.i.d. samples (x, a) drawn uniformly from X \u00d7 A. We run 1000 independent experiments. Plot (a) shows the empirical probability of the estimated cost function \u0108N being an element of the feasibility set, as described in Theorem 4.1 for given values of N and \u03b5. Plot (b) shows the objective value of the random program SIPN, i.e., \u1ebdN on average over the 1000 experiments, where the shaded area shows the standard deviations. Plot (c) is a visualization of the theoretical sample complexity as given by Theorem 4.1. For various values of \u03b4 and \u03b5, we plot the sample size N = N(nc + nu + 1, g(1), \u03b4). The variation parameter is set to \u2206 = 1 \u00b7 10\u22127. Plot (d) compares the discounted long-run costs V\u03c0E(v0) for the average \u0109N of the learnt costs \u0109N under the expert policy \u03c0E (red) and the optimal policy (blue). The solid line plots average over 1000 independent experiments, where the shaded area shows the standard deviations.", "description": "This figure presents the results of experiments using the Sampled Inverse Program (SIPN) to learn a cost function from data.  Four subplots show the empirical confidence of the learnt cost function being within a given error bound (a), the objective function value of the SIPN program (b), the theoretical sample complexity according to Theorem 4.1 (c), and a comparison of the discounted cost under the learnt and expert policies (d).", "section": "Numerical Results"}, {"figure_path": "VUgXAWOCQz/figures/figures_26_2.jpg", "caption": "Figure 3: Solutions of the Sampled Inverse Program SIPN. The variable N is the number of i.i.d. samples (x, a) drawn uniformly from X \u00d7 A. We run 1000 independent experiments. Plot (a) shows the empirical probability of the estimated cost function \u0108N being an element of the feasibility set, as described in Theorem 4.1 for given values of N and \u03b5. Plot (b) shows the objective value of the random program SIPN, i.e., \u03b5N on average over the 1000 experiments, where the shaded area shows the standard deviations. Plot (c) is a visualization of the theoretical sample complexity as given by Theorem 4.1. For various values of \u03b4 and \u03b5, we plot the sample size N = N(nc + nu + 1, g(1), \u03b4). The variation parameter is set to \u2206 = 1 \u00b7 10\u22127. Plot (d) compares the discounted long-run costs V\u03c0E(\u03bd0) for the average \u0108N of the learnt costs \u0108N under the expert policy \u03c0E (red) and the optimal policy \u03c0\u2217 (blue). The solid line plots average over 1000 independent experiments, where the shaded area shows the standard deviations.", "description": "This figure shows the results of applying the Sampled Inverse Program (SIPN) for different sample sizes (N).  It contains four subplots. Subplot (a) shows the empirical probability of the estimated cost function being in the feasibility set for different values of N and \u03b5. Subplot (b) displays the average objective value of the SIPN with standard deviation for different values of N.  Subplot (c) shows the theoretical sample complexity bounds. Subplot (d) compares the discounted long-run costs for the average learnt cost and optimal policy.", "section": "Numerical Results"}, {"figure_path": "VUgXAWOCQz/figures/figures_27_1.jpg", "caption": "Figure 4: Solutions of the Sampled Inverse Program SIPN,m,n,k. The variable N is the number of i.i.d. samples (x, a) drawn uniformly from X \u00d7 A. We run 1000 independent experiments. Plot (a) shows the empirical probability of the estimated cost function CN,m,n,k being an element of the feasibility set, as described in Theorem 4.2 for different N, k pairs given a chosen accuracy parameter \u03b5. Plot (b) shows the theoretical lower bound on k depending on N, for a set \u03b5, as described by Theorem 4.2.", "description": "Figure 4 presents the results of the Sampled Inverse Program SIPN,m,n,k, an algorithm designed to estimate the cost function with unknown transition kernels.  Plot (a) displays the empirical probability that the learned cost function belongs to a specific feasibility set, demonstrating how increasing sample size N and reducing the error tolerance \u03b5 improves the accuracy of cost estimation.  Plot (b) shows the theoretical lower bound of k (number of calls to the generative model per constraint), which increases with N and \u03b5, indicating a trade-off between sample size and computational cost.", "section": "Numerical Results"}, {"figure_path": "VUgXAWOCQz/figures/figures_27_2.jpg", "caption": "Figure 3: Solutions of the Sampled Inverse Program SIPN. The variable N is the number of i.i.d. samples (x, a) drawn uniformly from X \u00d7 A. We run 1000 independent experiments. Plot (a) shows the empirical probability of the estimated cost function \u0108N being an element of the feasibility set, as described in Theorem 4.1 for given values of N and \u03b5. Plot (b) shows the objective value of the random program SIPN, i.e., \u1ebdN on average over the 1000 experiments, where the shaded area shows the standard deviations. Plot (c) is a visualization of the theoretical sample complexity as given by Theorem 4.1. For various values of \u03b4 and \u03b5, we plot the sample size N = N(nc + nu + 1, g(1), \u03b4). The variation parameter is set to \u2206 = 1 \u00b7 10\u22127. Plot (d) compares the discounted long-run costs V\u03c0E(v0) for the average \u0109N of the learnt costs \u0109N under the expert policy \u03c0E (red) and the optimal policy (blue). The solid line plots average over 1000 independent experiments, where the shaded area shows the standard deviations.", "description": "Figure 3 shows the results of the Sampled Inverse Program (SIPN) experiments.  It presents four plots illustrating different aspects of the algorithm's performance. Plot (a) shows the empirical probability of the learned cost function being within the feasibility set for different sample sizes and error tolerances. Plot (b) displays the average objective function value of the SIPN across multiple runs, with error bars representing the standard deviation. Plot (c) visualizes the theoretical sample complexity, comparing it to the empirical results.  Plot (d) compares the long-run cost under the expert policy and the learned cost function.", "section": "Numerical Results"}]