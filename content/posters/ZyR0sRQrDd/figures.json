[{"figure_path": "ZyR0sRQrDd/figures/figures_1_1.jpg", "caption": "Figure 1: The occupancy prediction is approached as a set prediction problem. For each scene, we predict a set of point positions P and a set of the corresponding semantic classes C. With the ground-truth set of occupied voxel positions Pg and classes Cg, we decouple the set-to-set matching task into two distinct components: (a) Enforcing similarity in the point distributions of P and Pg using the Chamfer distance. (b) Aligning the predicted classes C with the ground-truths \u0108 = \u0424(P, Pg, Cg), where \u0424 generates a set of classes for points in P based on those of the nearest ground-truth points.", "description": "The figure illustrates the proposed occupancy prediction approach as a set prediction problem.  Instead of classifying individual voxels, the method predicts sets of occupied point positions (P) and their corresponding semantic classes (C). The set-to-set matching is decoupled into two parts: 1) assessing the similarity between the predicted point distribution (P) and ground truth (Pg) using the Chamfer distance; and 2) aligning the predicted classes with ground truth classes by associating each predicted point with its nearest ground truth point's class using a function \u03a6.", "section": "3 Methodology"}, {"figure_path": "ZyR0sRQrDd/figures/figures_4_1.jpg", "caption": "Figure 2: OPUS leverages a transformer encoder-decoder architecture comprising: (1) An image encoder to extract 2D features from multi-view images. (2) A series of decoders to refine the queries with image features, which are correlated via the consistent point sampling module. (3) A set of learnable queries to predict locations and classes of occupancy points. Each query obeys a coarse-to-fine rule, progressively increasing the number of predicted points. In the end, the entire model is trained end-to-end using our adaptively re-weighted set-to-set losses.", "description": "The figure illustrates the OPUS architecture.  It shows a transformer encoder-decoder model that takes multi-camera images as input. The encoder extracts 2D features. These features are then processed by a series of decoders, which refine queries using a consistent point sampling module.  The decoders output a set of learnable queries that predict the locations and classes of occupancy points.  Each query follows a coarse-to-fine approach, gradually increasing the number of predicted points. The entire model is trained end-to-end using adaptively re-weighted set-to-set losses.", "section": "3.3 Details of OPUS"}, {"figure_path": "ZyR0sRQrDd/figures/figures_6_1.jpg", "caption": "Figure 3: Visualizations of occupancy predictions. Best viewed in color.", "description": "This figure presents a visual comparison of occupancy predictions generated by three different methods: FB-Occ, SparseOcc, and OPUS. It shows the predicted occupancy maps alongside the ground truth, highlighting the differences in prediction accuracy and sparsity. FB-Occ produces a dense prediction, SparseOcc provides a more sparse result but with missing parts, while OPUS strikes a balance by generating a sparse prediction that is more accurate and complete.", "section": "4.2 Main results"}, {"figure_path": "ZyR0sRQrDd/figures/figures_7_1.jpg", "caption": "Figure 4: Visualizations of the coarse-to-fine predictions.", "description": "This figure visualizes the impact of the coarse-to-fine prediction strategy on occupancy prediction.  It shows a comparison between a baseline approach (a) where all decoder layers regress the same number of points, and a coarse-to-fine approach (b) where the number of points gradually increases across the decoder layers. The ground truth is shown in (c). The baseline approach shows inconsistent point distributions across stages and a number of false negative predictions. The coarse-to-fine approach alleviates these issues, resulting in more consistent point distributions and fewer false negatives.", "section": "4.3 Ablation study and visualizations"}, {"figure_path": "ZyR0sRQrDd/figures/figures_7_2.jpg", "caption": "Figure 5: Distributions of standard deviations of points from one query.", "description": "This figure shows the distribution of standard deviations of the distances of points predicted by a single query.  The x-axis represents the standard deviation (in meters) of the distances. The y-axis represents the density of queries with that standard deviation. Three different classes are shown: traffic cone, motorcycle, and sidewalk. The distributions are different for each class, reflecting the different spatial extents of these objects.  Traffic cones have the smallest standard deviations, while sidewalks have the largest, indicating that points belonging to the same traffic cone are clustered more tightly than points belonging to a sidewalk.  This visualizes the way the model adapts its point prediction patterns based on the spatial characteristics of the objects.", "section": "4.3 Ablation study and visualizations"}, {"figure_path": "ZyR0sRQrDd/figures/figures_8_1.jpg", "caption": "Figure 6: Visualizations of points generated from different queries. Best viewed in color.", "description": "This figure visualizes the points predicted by different queries. Each subfigure shows a different class or a combination of classes.  It highlights how the model focuses on different regions and details for various object categories, generating points that cluster together with consistent classes or from the same instance.  It also demonstrates how points are distributed more diversely for larger areas like sidewalks and drivable surfaces, and are concentrated for smaller objects like traffic cones. The legend explains the color coding for various categories.", "section": "4.3 Ablation study and visualizations"}, {"figure_path": "ZyR0sRQrDd/figures/figures_8_2.jpg", "caption": "Figure 6: Visualizations of points generated from different queries. Best viewed in color.", "description": "This figure visualizes points predicted by different queries in OPUS. Each color represents a different query, and the spatial distribution of points within each color group reflects the points predicted by that specific query.  The figure demonstrates that queries tend to predict clusters of points with consistent semantic labels, and the density of points within each cluster varies depending on the object class.  In some cases, a single query might predict points belonging to multiple classes, particularly at boundaries between objects.", "section": "4.3 Ablation study and visualizations"}, {"figure_path": "ZyR0sRQrDd/figures/figures_16_1.jpg", "caption": "Figure 8: Illustration of safety threat due to discrepancies between evaluation metrics and real-world scenarios. (a) Before evaluation, the camera visibility mask is first generated according to camera intrinsics and extrinsics. Then, the dense prediction will be masked to get the final prediction for evaluation. (b) For real-world usage, we cannot have camera visibility reasoning without knowing the ground-truth occupancy. We can only generate the view mask from camera intrinsics and extrinsics, which fails to filter out the over-estimated voxels from dense models. (c) Plenty of false positive predictions are made close to the ego vehicle, marked by the symbol of red star. These erroneously predicted voxels are filtered during evaluating mIoU, but could cause hazardous safety issue. (d) The OPUS produces sparse occupancy predictions and suffers much less from the over-estimation. Consequently, no such safety threat occurs in this scenario. Best viewed in color.", "description": "This figure illustrates a safety concern related to the discrepancy between evaluation metrics and real-world scenarios in occupancy prediction.  It shows how dense prediction methods (like FB-Occ) can overestimate occupancy, leading to false positives near the ego vehicle that are filtered out during evaluation but pose a significant safety risk in real-world applications. In contrast, the sparse prediction method (OPUS) mitigates this risk due to its more accurate estimations.", "section": "4.3 Ablation study and visualizations"}, {"figure_path": "ZyR0sRQrDd/figures/figures_16_2.jpg", "caption": "Figure 9: Visualizations of occupancy predictions. Best viewed in color.", "description": "This figure visualizes the occupancy prediction results from three different methods: FB-Occ, SparseOcc, and OPUS. For each method, four sample scenes are shown, along with their corresponding ground truth occupancy maps.  The visualizations highlight the differences in the prediction quality and density of points between the three methods, showing that OPUS provides a more balanced representation, avoiding the overestimation of FB-Occ and the discontinuity of SparseOcc.", "section": "4.2 Main results"}, {"figure_path": "ZyR0sRQrDd/figures/figures_17_1.jpg", "caption": "Figure 10: Visualizations of occupancy predicted by FB-Occ, SparseOcc and the proposed OPUS.", "description": "This figure shows a comparison of occupancy prediction results from three different methods: FB-Occ, SparseOcc, and the proposed OPUS method.  Each row represents a different scene. The ground truth is shown in the last column for reference. The visualizations highlight the differences in prediction quality and sparsity between the methods.  FB-Occ tends to produce denser results with more overestimation than SparseOcc and OPUS.  SparseOcc shows some missing details due to its sparse representation, while OPUS produces an intermediate result between the two in terms of detail and sparsity.", "section": "E.3 Occupancy predictions of different methods"}]