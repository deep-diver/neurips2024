{"references": [{"fullname_first_author": "Henry Adams", "paper_title": "A Fractal Dimension for Measures via Persistent Homology", "publication_date": "2020-01-01", "reason": "This paper introduces a fractal dimension based on persistent homology, which is the foundation of the topological measures used in the main paper."}, {"fullname_first_author": "Tolga Birdal", "paper_title": "Intrinsic Dimension, Persistent Homology and Generalization in Neural Networks", "publication_date": "2021-01-01", "reason": "This paper directly builds upon the theoretical foundation for using fractal dimensions and persistent homology to analyze the generalization properties of neural networks."}, {"fullname_first_author": "Benjamin Dupuis", "paper_title": "Generalization Bounds using Data-Dependent Fractal Dimensions", "publication_date": "2023-01-01", "reason": "This paper extends the previous work on topological measures of generalization by relaxing certain assumptions and using a data-dependent pseudometric, which the current paper also evaluates."}, {"fullname_first_author": "Umut Simsekli", "paper_title": "Hausdorff Dimension, Heavy Tails, and Generalization in Neural Networks", "publication_date": "2020-01-01", "reason": "This paper provides an initial theoretical framework connecting fractal dimensions, optimization trajectories, and generalization in neural networks."}, {"fullname_first_author": "Preetum Nakkiran", "paper_title": "Deep double descent: Where bigger models and more data hurt*", "publication_date": "2021-01-01", "reason": "This paper introduces the concept of model-wise double descent, which is studied empirically in the context of topological measures in the main paper."}]}