[{"type": "text", "text": "Communication Bounds for the Distributed Experts Problem ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Zhihao Jia Qi Pang Trung Tran Carnegie Mellon University Carnegie Mellon University University of Pittsburgh zhihao@cmu.edu qipang@cmu.edu tbt8@pitt.edu ", "page_idx": 0}, {"type": "text", "text": "David Woodruff Zhihao Zhang Wenting Zheng Carnegie Mellon University Carnegie Mellon University Carnegie Mellon Universit dwoodruf@cs.cmu.edu zhihaoz3@cs.cmu.edu wenting@cmu.edu ", "page_idx": 0}, {"type": "text", "text": "Abstract ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "In this work, we study the experts problem in the distributed setting where an expert\u2019s cost needs to be aggregated across multiple servers. Our study considers various communication models such as the message-passing model and the broadcast model, along with multiple aggregation functions, such as summing and taking the $\\ell_{p}$ norm of an expert\u2019s cost across servers. We propose the first communicationefficient protocols that achieve near-optimal regret in these settings, even against a strong adversary who can choose the inputs adaptively. Additionally, we give a conditional lower bound showing that the communication of our protocols is nearly optimal. Finally, we implement our protocols and demonstrate empirical savings on the HPO-B benchmarks. ", "page_idx": 0}, {"type": "text", "text": "1 Introduction ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Online prediction with expert advice is an indispensable task in many fields, including bandit learning (Auer et al., 2002; Lattimore & Szepesv\u00e1ri, 2020), online optimization (Shalev-Shwartz et al., 2012; Hazan et al., 2016), robot control (Doyle et al., 2013), and financial decision making (Dixon et al., 2020). The problem involves $n$ experts making individual predictions and receiving corresponding costs on each of $T$ days. On each day, we choose an expert based on the historical costs of the experts on previous days, and we receive the cost of the selected expert on that day. The objective is to compete with the best single expert in hindsight, i.e., to minimize the average regret, defined as the additional cost the algorithm incurs against the best expert in a horizon of $T$ days. It is known that the Exponential Weights Algorithm (EWA) and Multiplicative Weight Update (MWU) method achieve an optimal regret of $O(\\sqrt{\\frac{\\log n}{T}})$ given all historical information, even in the presence of a strong adversary Arora et al. (2012). With less information, the exponential-weight algorithm for exploration and exploitation (Exp3) achieves near-optimal regret $O({\\sqrt{\\frac{n\\log n}{T}}})$ in the adversarial bandit setup, where only the cost of one expert is observed on a single day. ", "page_idx": 0}, {"type": "text", "text": "For a large number of experts and days, it may not be feasible to run classical low-regret algorithms. Motivated by this, recent work (Srinivas et al., 2022; Peng & Zhang, 2022; Woodruff et al., 2023; Peng & Rubinstein, 2023; Aamand et al., 2023) considers the experts problem in the data stream model, where the expert predictions are typically streamed through main memory, and a small summary of historical information is stored. ", "page_idx": 0}, {"type": "text", "text": "In this paper, we consider an alternative model in the big data setting, namely, the distributed model, where expert costs are split across $s$ servers, and there is a central coordinator who can run a low-regret algorithm. However, communicating with different servers is expensive, and the goal is to design a low communication protocol that achieves low regret. ", "page_idx": 0}, {"type": "table", "img_path": "HyxjSi3SzF/tmp/53e2779509f126ac3c2c643912746ac36fa9df0e2ef1c5f96a053bc471025cd7.jpg", "table_caption": ["Table 1: Summary of our constant probability communication upper bounds. "], "table_footnote": [], "page_idx": 1}, {"type": "table", "img_path": "HyxjSi3SzF/tmp/b8fe30f6588b972c104653ece7b5c00319fb7377b7054431800997126440960f.jpg", "table_caption": ["Table 2: Summary of our high probability communication upper bounds. "], "table_footnote": [], "page_idx": 1}, {"type": "text", "text": "", "page_idx": 1}, {"type": "text", "text": "A motivating example is a distributed online optimization problem, where different servers hold different samples, and each expert could correspond to a different model in an optimization problem over the union of the samples as in the HPO-B real-world benchmark (Arango et al., 2021). In this case, it is natural for the cost of an expert to be the sum of the costs of the expert across all servers. The goal is thus to minimize the cumulative costs in an online fashion by choosing models on a daily basis. Another example of an aggregation function could be the maximum across servers; indeed, this could be useful if there is a maximum tolerable cost on the servers, which we would like not to exceed. For our lower bounds, we also ask the protocol to be able to tell at least if the cost of the expert it chose on a given day is non-zero; this is a minimal requirement of all existing algorithms, such as MWU or Exp3, which update their data structure based on such a cost. It is also desirable in applications such as the experts problem where one wants to know if the prediction was right or wrong. ", "page_idx": 1}, {"type": "text", "text": "In our setting, a coordinator needs to choose an expert based on historical interactions with $s$ servers each day. We focus on two widely studied communication models, namely, the message-passing model with two-way communication channels and the broadcast model with a broadcast channel. In the message-passing model, the coordinator initiates a round of interaction with a given server, and the messages exchanged are only seen by the coordinator and that particular server. The coordinator then decides who speaks next and repeats this process. The broadcast model is also commonly studied in practice and theory. It can be viewed as a model for single-hop wireless networks. In the broadcast model, each message exchanged is seen by all servers and the coordinator. We note that the broadcast model was a central communication model studied for clustering in Chen et al. (2016). ", "page_idx": 1}, {"type": "text", "text": "As in the distributed online learning setup, we can view each server as a database, where it possibly receives new data daily. The costs of the $n$ experts on a day then correspond to $n$ possibly different functions of the data on that day. We note that the costs may be explicitly given or implicit functions of the data, and if the latter, they may only need to be computed as required by the protocol. ", "page_idx": 1}, {"type": "text", "text": "We aim to achieve a near-optimal regret versus communication tradeoff in this setting over a horizon of $T$ days. Given the memory-efficient streaming algorithms of Srinivas et al. (2022); Peng & Zhang (2022) and the close connection between streaming algorithms and communication-efficient protocols, one might think that implementing a streaming algorithm in our settings is optimal. While we could run a streaming algorithm, a critical difference here is that the coordinator is not memory-bounded and thus can afford to store a weight for each expert. While it cannot run EWA or MWU, which would require $\\Omega(s n)$ communication per day, it can run a distributed Exp3 algorithm, which samples a single expert and thus has low communication, but maintains a weight locally for all $n$ experts using $\\Omega(n)$ memory. We stress this is not possible in the streaming model. ", "page_idx": 1}, {"type": "text", "text": "Table 3: Summary of our communication lower bounds. We assume $R\\in[O(\\sqrt{\\frac{\\log n}{T}}),O(\\sqrt{\\frac{n\\log n}{T}})]$ . All lower bounds hold against oblivious adversarial cost streams with a memory bound $M\\,=$ $O\\big(\\frac{n}{s T R^{2}}+1\\big)$ on the servers. ", "page_idx": 2}, {"type": "table", "img_path": "HyxjSi3SzF/tmp/2750524eac245d760f607807241df06a726331f0d453a4e3d61f60d8144827ca.jpg", "table_caption": [], "table_footnote": [], "page_idx": 2}, {"type": "text", "text": "With $s$ servers in the message-passing model and with sum aggregation, a straightforward implementation of EWA achieves an optimal regret $O(\\sqrt{\\frac{\\log n}{T}})$ with a trivial communication cost of $\\tilde{O}(n T s)$ . A distributed Exp3 algorithm achieves $O({\\sqrt{\\frac{n\\log n}{T}}})$ regret with a total communication cost of $\\tilde{O}(T s)$ Here $\\tilde{O}(f)$ denotes . A natural question is whether these bounds are tight and what the optimal regret versus communication tradeoff is. ", "page_idx": 2}, {"type": "text", "text": "We summarize our results in Table 1, Table 2 and Table 3. We assume $R\\quad\\in$ $\\begin{array}{r}{\\tilde{\\lfloor O((\\frac{\\log n}{T})^{\\frac{\\varepsilon}{1+\\varepsilon}}),\\tilde{O}((\\frac{n\\log n}{T})^{\\frac{\\varepsilon}{1+\\varepsilon}})\\rfloor}\\end{array}$ for DEWA-L as well as DEWA-L-P when $1+\\varepsilon\\,<\\,p\\,\\leq\\,2$ , and $\\begin{array}{r}{R\\in[\\tilde{O}(\\sqrt{\\frac{\\log n}{T}}),\\tilde{O}(\\sqrt{\\frac{n\\log n}{T}})]}\\end{array}$ n loTg n)] for the others. All upper bounds hold unconditionally against strong adversarial cost streams. Our upper bounds hold unconditionally against strong adaptive adversarial cost streams, where an adversary chooses its (distributed) cost vector after seeing the distribution that the algorithm uses to sample experts on that day. Also, with a memory bound on the local servers, our lower bounds hold against weaker oblivious adversarial cost streams, where the loss vectors of all days are fixed in advance. A memory-bound on individual devices, excluding the coordinator, is natural, as one should view the coordinator as a more powerful machine than the individual servers. Empirically, we also provide comprehensive evaluations over real world (HPO-B Arango et al. (2021)) as well as synthetic data traces to demonstrate the effectiveness of our methods. ", "page_idx": 2}, {"type": "text", "text": "2 Related Work ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "Online learning with expert advice. The Multiplicative Weights Update (MWU) method\u2019s first appearance dates back to the early 1950s in the context of game theory Brown & Von Neumann (1950); Brown (1951); Robinson (1951). The exact form of MWU is carried out by adding randomness, which efficiently solves two-player zero-sum games (Grigoriadis & Khachiyan, 1995). Ordentlich & Cover (1998) further proves the optimality of such algorithms under various scenarios. The algorithm has later been adopted in a wide range of applications (Cesa-Bianchi & Lugosi, 2006; Freund & Schapire, 1997; Christiano et al., 2011; Garber & Hazan, 2016; Klivans & Meka, 2017; Hopkins et al., 2020; Ahmadian et al., 2022), including the experts problem. See the comprehensive survey on MWU by Arora et al. (2012). ", "page_idx": 2}, {"type": "text", "text": "Multi-armed bandits. Similar to the experts problem, Multi-armed bandits (MAB) is another fundamental formulation in sequential optimization since its appearance in Thompson 1933; Robbins 1952. Unlike the experts problem, where each expert\u2019s cost is revealed each day, MAB limits players to observing only the cost of one expert (arm) each day. Both stochastic and adversarial MAB problems have been studied extensively (Audibert et al., 2009; Garivier & Capp\u00e9, 2011; Korda et al., 2013; Degenne & Perchet, 2016; Agrawal & Goyal, 2017; Kaufmann, 2018; Lattimore & Szepesv\u00e1ri, 2020; Auer et al., 2002; Auer, 2002). As we mainly consider adversarial cost streams, the Exponential-weight algorithm for Exploration and Exploitation (Exp3) and its Upper Confidence Bound (UCB) variant are most relevant due to their effectiveness in achieving near-optimal regret in the presence of adversaries (Auer et al., 2002). ", "page_idx": 2}, {"type": "text", "text": "Distributed learning with expert advice. Kanade et al. 2012 also study the expert problem under a coordinator-server model. However, the results are incomparable as Kanade et al. 2012 only considers the special case where the cost is allocated to one server rather than an arbitrary number of servers, which makes their setup a special case under our more general scheme. Also, our lower-bound proof is against oblivious adversaries rather than adaptive adversaries, as in Kanade et al. (2012), which is more challenging to prove. Detailed comparisons with Kanade et al. (2012) are described in Section C. ", "page_idx": 2}, {"type": "text", "text": "", "page_idx": 3}, {"type": "text", "text": "Hillel et al. 2013; Szorenyi et al. 2013 give a distributed MAB setting where arms on each server share the same cost distribution, and the goal is to find the best arm cooperatively. Shahrampour et al. 2017; Landgren et al. 2016; Bistritz & Leshem 2018, on the other hand, assume the costs on each server are i.i.d. across days while being different for different servers. Cesa-Bianchi et al. 2016 considers a setup where servers are nodes on a connected graph and can only talk to neighboring nodes while restricting the cost for each arm on the servers to be the same within one day. Korda et al. 2016 studies the multi-agent linear bandit problem in a peer-to-peer network where agents share the same group of arms with i.i.d. costs across days. Some works also consider the setup where servers need to compete against each other, which is outside of our scope (Anandkumar et al., 2011; Besson & Kaufmann, 2018; Bubeck et al., 2020; Wang et al., 2020). Unlike most of these setups, we make no assumptions about the costs across days and servers. ", "page_idx": 3}, {"type": "text", "text": "Distributed functional monitoring. The coordinator-server communication model is also commonly seen in the distributed functional monitoring literature (Cormode et al., 2011; Woodruff & Zhang, 2012; Arackaparambil et al., 2009; Cormode et al., 2012; Chan et al., 2012), where the goal is to approximate function values, e.g., frequency moments, across streams with minimal communication. We note that the goal of the distributed experts problem is different in that the focus is on expert selection rather than value estimation, and the algorithms in the distributed functional monitoring literature, to the best of our knowledge, are not directly useful here. ", "page_idx": 3}, {"type": "text", "text": "3 Preliminaries and Notation ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "We use $T$ to denote the total number of days, $n$ the number of experts, and $s$ the number of servers. $l_{i,j}^{t}$ represents the cost observed at step $t$ for expert $i$ on the $j$ -th server. $\\hat{l}$ denotes an estimate to $l$ and $[n]$ denotes $\\{1,2,\\ldots,n\\}$ . A word of memory is represented as $O(\\log\\left(n T\\right))$ bits and we use $\\tilde{O}(\\cdot)$ to suppress $\\log^{O(1)}\\left(n T s\\right)$ factors. We refer to the Exponential Weight Algorithm (EWA) and Multiplicative Weights Update (MWU) method interchangeably. ", "page_idx": 3}, {"type": "text", "text": "3.1 Distributed Experts Problem ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "In the single server expert problem, each expert $e_{i},i\\in[n]$ has its cost $l_{i}^{t}\\in[0,1]$ on day $t$ . Based on the history, an algorithm $\\boldsymbol{\\mathcal{A}}$ needs to select one expert $e_{\\mathcal{A}(t)}$ for each day before the outcome is revealed on that day. The goal for the single server expert problem is to minimize the average regret defined as: $\\begin{array}{r}{R(A)=\\frac{1}{T}\\left(\\sum_{t=1}^{T}l_{A(t)}^{t}-\\operatorname*{min}_{i^{*}}\\sum_{t=1}^{T}l_{i^{*}}^{t}\\right).}\\end{array}$ . ", "page_idx": 3}, {"type": "text", "text": "In the distributed setting, we have $s$ servers and one coordinator where the cost $l_{i}^{t}$ now depends on costs $l_{i,j}^{t}$ observed locally across all the servers. The coordinator selects the expert for the next day based on any algorithm $\\boldsymbol{\\mathcal{A}}$ of its choice. For each $j\\in[s]$ , the $j$ -th server can receive or compute its cost $l_{i,j}^{t},i\\in[n]$ for the $i$ -th expert on day $t$ . The actual cost for the $i$ -th expert on day $t$ is defined as $l_{i}^{t}\\,=\\,f(l_{i,1}^{t},l_{i,2}^{t},\\cdot\\cdot\\cdot\\,,l_{i,s}^{t})$ , where $f(\\cdot)$ is an aggregation function. We assume the costs $l_{i,j}^{t}$ are non-negative. We consider three natural choices of $f(\\cdot)$ : 1. the summation function $\\begin{array}{r}{l_{i}^{t}=\\sum_{j=1}^{s}l_{i,j}^{t}}\\end{array}$ and an integer power of the sum function $\\begin{array}{r}{l_{i}^{t}=\\left(\\sum_{j=1}^{s}l_{i,j}^{t}\\right)^{q}2.}\\end{array}$ . the maximum/minimum function $l_{i}^{t}\\,=\\,\\operatorname*{max}_{j\\,\\in[s]}\\,l_{i,j}^{t}$ 3. the $\\ell_{p>1}$ norm function, $\\begin{array}{r}{l_{i}^{t}\\,=\\,\\left(\\sum_{j=1}^{s}\\left(l_{i,j}^{t}\\right)^{p}\\right)^{\\frac{1}{p}},p\\,>\\,1}\\end{array}$ . In the distributed setting, regret is defined as in the single server setup with $l_{i}^{t}=f(l_{i,1}^{t},l_{i,2}^{t},\\cdot\\cdot\\cdot\\cdot,l_{i,s}^{t})$ . Without loss of generality, we normalize $l_{i}^{t}\\in[0,1],l_{i,j}^{t}\\ge0$ . In practice, if $l_{i}^{t}\\in[0,\\rho]$ , the regret will increase by a factor of $\\rho$ accordingly, which only affects the scale of the regret and preserves optimality. Note that the cost vector for all the experts is observed by the corresponding local server. Furthermore, we explore the distributed experts problem in two different communication models: ", "page_idx": 3}, {"type": "text", "text": "Message-passing model. For the message-passing model, the coordinator can initiate a two-way private channel with a specific server to exchange messages. Messages can only be seen by the coordinator and the selected server. The coordinator then decides which server to speak to next and repeats based on the protocol. ", "page_idx": 3}, {"type": "text", "text": "", "page_idx": 4}, {"type": "text", "text": "Broadcast model. In the broadcast model, the coordinator communicates with all servers using a broadcast channel. Again, the communication channel can only be initiated by the coordinator. ", "page_idx": 4}, {"type": "text", "text": "We further assume local servers have a memory bound of $M$ in what they can store from previous days, which is a more practical scenario as discussed in Srinivas et al. (2022); Peng & Zhang (2022). We leave the definition and description of strong adaptive adversaries and the EWA algorithm in Definition A.1 and Appendix A.2 accordingly. ", "page_idx": 4}, {"type": "text", "text": "4 Proposed Algorithms ", "text_level": 1, "page_idx": 4}, {"type": "text", "text": "4.1 Overview ", "text_level": 1, "page_idx": 4}, {"type": "text", "text": "In the message-passing model, we let $b_{e}\\in[n]$ be a hyper-parameter of our choice. We first propose a baseline algorithm DEWA-S that can achieve $\\tilde{O}(\\sqrt{\\frac{n}{T b_{e}}})$ regret with constant probability using $O(T(b_{e}+s))$ total communication when the aggregation function is the summation function or an integer power of sum function. The intuition for the baseline algorithm is to get an unbiased estimation of the experts\u2019 underlying cost by sending a signal to the coordinator with a probability that is proportional to the local cost, which is simple yet effective. We further introduce the full algorithm DEWA-S-P that achieves $\\tilde{O}(\\sqrt{\\frac{n}{T b_{e}}})$ regret with probability $1-{\\frac{1}{\\operatorname{poly}(T)}}$ using ${\\tilde{O}}(T(b_{e}+s))$ total communication. Both DEWA-S and DEWA-S-P work in the broadcast model with the same guarantees since the message-passing model is only more costly. ", "page_idx": 4}, {"type": "text", "text": "In the broadcast model, we propose DEWA-M-P that achieves $\\tilde{O}(\\sqrt{\\frac{n}{T b_{e}}})$ regret with probability poly1(T ) and using only O\u02dc(T(be + s)) overall communication when the aggregation function is the maximum function. Besides the summation aggregation function, we leverage a random-walk-based communication protocol to find out the aggregated cost with a minimal communication cost. Since all of our protocols use (and require) at least $T s$ communication, the coordinator can figure out the exact cost for the selected expert on each day by querying each of the $s$ servers for that expert\u2019s cost on that day. Lastly, we propose DEWA-L-P that achieves $\\begin{array}{r}{O((\\frac{n\\log n}{T b_{e}})^{\\frac{\\varepsilon}{1+\\varepsilon}}+\\sqrt{\\frac{\\log T}{T}})}\\end{array}$ regret with probability poly1(T ) and using only O\u02dc(T(be + s)) overall communication when the aggregation function is the $\\ell_{p}$ -norm function for any fixed constant $0<\\varepsilon\\le1$ such that $1+\\varepsilon<p$ . The algorithm employs the idea of embedding $\\ell_{p}$ into $\\ell_{\\infty}$ , thus efficiently estimating the aggregated cost using the previously introduced DEWA-M-P . For all our bounds, $b_{e}\\in[n]$ is a hyperparameter that trades off the communication with the optimal regret we can get. For instance, setting $b_{e}\\,=\\,o(1)$ can achieve a regret of $\\begin{array}{r}{R=\\tilde{O}(\\sqrt{\\frac{n\\log n}{T}})}\\end{array}$ and setting $b_{e}=o(n)$ can achieve a regret of $\\begin{array}{r}{R=\\tilde{O}(\\sqrt{\\frac{\\log n}{T}})}\\end{array}$ Thus, setting $\\begin{array}{r}{b_{e}=o\\big(\\frac{n}{T R^{2}}\\big)}\\end{array}$ can achieve the optimal communication bound we provide in Table 1 and Table 2. ", "page_idx": 4}, {"type": "text", "text": "4.2 DEWA-S ", "text_level": 1, "page_idx": 4}, {"type": "text", "text": "We describe DEWA-S in Algorithm 1. The intuition is to obtain an unbiased estimate $\\hat{l}^{t}$ for $l^{t}$ using limited communication and then run EWA based on our estimate. More precisely, we use the following estimator to estimate $l^{t}$ on day $t$ : $\\begin{array}{r}{\\hat{l}_{i}^{t}=\\frac{n}{b_{e}}(\\sum_{j=1}^{s}\\alpha_{i,j}^{t}\\beta_{i,j}^{t})}\\end{array}$ , where $\\alpha_{i,j}^{t}$ are i.i.d. Bernoulli random variables following $\\begin{array}{r}{\\alpha_{i,j}^{t}\\sim\\mathrm{Bernoulli}(\\frac{b_{e}}{n})}\\end{array}$ , and the $\\beta_{i,j}^{t}$ are sampled from Bernoulli $(l_{i,j}^{t})$ . As $l_{i}^{t}\\in[0,1],l_{i,j}^{t}\\geq0$ $\\begin{array}{r}{\\mathbb{E}[\\widehat{l}_{i}^{t}]=\\mathbb{E}[\\frac{n}{b_{e}}(\\sum_{j=1}^{s}\\alpha_{i,j}^{t}\\beta_{i,j}^{t})]=\\frac{n}{b_{e}}(\\sum_{j=1}^{s}\\mathbb{E}[\\alpha_{i,j}^{t}]\\mathbb{E}[\\beta_{i,j}^{t}])=\\frac{n}{b_{e}}\\sum_{j=1}^{s}\\frac{b_{e}l_{i,j}^{t}}{n}=l_{i}^{t}}\\end{array}$ $(l_{i,j}^{t})$ .a tTiohne $l_{i}^{t}$ function is an integer power of the sum over local costs, where each monomial in the expansion of the aggregation function is unbiasedly estimated by taking the product of sampled local costs. On each day, we only incur communication cost $\\begin{array}{r}{O(s+\\sum_{i=1}^{n}\\frac{b_{e}}{n}\\sum_{j=1}^{t}l_{i,j}^{t})\\in O(b_{e}+s)}\\end{array}$ . Thus, the overall communication cost is $O(T(b_{e}+s))$ . ", "page_idx": 4}, {"type": "text", "text": "Input: learning rate $\\eta$ , sampling budget $b_{e}$ ;   \nInitialize $\\hat{L}_{i}^{0}=0,\\forall i\\in[n]$ ;   \nfor $t=1$ to $T$ do Coordinator chooses expert $i$ with probability $p(i)\\propto\\exp{(-\\eta\\hat{L}_{i}^{t-1})}$ ; for $j=1$ to $s$ do Coordinator initiates private channel with server $j$ ; for $i=1$ to $n$ do Server $j$ observes cost $l_{i,j}^{t}$ and samples $\\alpha_{i,j}^{t}\\sim\\mathrm{Bernoulli}(\\frac{b_{e}}{n}),\\beta_{i,j}^{t}\\sim\\mathrm{Bernoulli}(l_{i,j}^{t})$ ; Server $j$ sends tuples $(i,j)$ to the coordinator if $\\alpha_{i,j}^{t}=1,\\beta_{i,j}^{t}=1$ and clears its memory; Coordinator calculates $\\begin{array}{r}{\\hat{l}_{i}^{t}=\\frac{n}{b_{e}}(\\sum_{j=1}^{s}\\alpha_{i,j}^{t}\\beta_{i,j}^{t})}\\end{array}$ ; Update $\\hat{L}_{i}$ by $\\hat{L}_{i}^{t}=\\hat{L}_{i}^{t-1}+\\hat{l}_{i}^{t},\\forall i\\in[n]$ ; ", "page_idx": 5}, {"type": "text", "text": "4.3 DEWA-S-P ", "text_level": 1, "page_idx": 5}, {"type": "text", "text": "As we are using unbiased estimators instead of actual costs, we only obtain the desired regret with constant probability. In order to achieve near-optimal regret with high probability, we propose DEWA-S-P in Algorithm 2. The idea is to run multiple baseline algorithms in parallel to boost the success probability, where we regard each baseline algorithm as a meta-expert. As each meta-expert has constant success probability, the probability that they all fail is exponentially small in the number of meta-experts. Thus, by running EWA on the meta-experts, we can follow the advice of the best meta-expert and achieve near-optimal regret with high probability. ", "page_idx": 5}, {"type": "text", "text": "Algorithm 2 DEWA-S-P ", "text_level": 1, "page_idx": 5}, {"type": "text", "text": "Input: learning rate $\\eta_{\\mathrm{meta}}$ , sampling budget $b_{e}$ , failure rate $1/\\mathsf{p o l y}(T)$ ;   \nLet $K=\\lceil\\log\\,(\\mathrm{poly}(T))\\rceil$ , initialize $K$ baseline algorithms $\\mathcal{A}_{k}$ and let $L_{k}^{0}=0,k\\in[K]$ ;   \nfor $t=1$ to $T$ do Coordinator chooses expert according to $A_{k}(t)$ with probability $p(k)\\propto\\exp{(-\\eta_{\\mathrm{meta}}L_{k}^{t-1})}$ ; Coordinator updates memory states for all $\\mathcal{A}_{k}$ according to Algorithm 1; Coordinator receives cost $\\begin{array}{r}{l_{A_{k}(t)}^{t^{\\phantom{\\dagger}}}=\\sum_{j=1}^{s}l_{A_{k}(t),j}^{t}}\\end{array}$ ; Update all $L_{k}$ by $L_{k}^{t}=L_{k}^{t-1}+l_{\\mathcal{A}_{k}(t)}^{t}$ ; ", "page_idx": 5}, {"type": "text", "text": "More precisely, to obtain $1-{\\frac{1}{\\operatorname{poly}(T)}}$ success probability, we initiate $\\lceil\\log\\,(\\mathrm{poly}(T))\\rceil$ meta-experts $\\mathcal{A}_{k},k\\,\\in\\,[[\\mathrm{log}\\,(\\mathrm{poly}(T))]]$ at the start of the algorithm. Each meta-expert runs its own DEWA-S independently across $T$ days. The cost of the $k$ -th meta-expert on day $t$ is defined to be the cost the expert $\\mathcal{A}_{k}$ selects on the same day, which is denoted as $l_{\\mathcal{A}_{k}(t)}^{t}$ . With the definition of the cost for the meta-experts, we can then run EWA on the meta-experts. ", "page_idx": 5}, {"type": "text", "text": "The meta-level EWA needs to know the actual cost ltAk(t) from the s servers of each meta-expert in order to recover the best meta-expert with $1-{\\frac{1}{\\mathrm{poly}(T)}}$ ) success probability. Therefore for DEWA-S-P , on each day, we incur a communication cost of $\\tilde{O}(s+(b_{e}+s)\\log{(\\mathrm{poly}(T))})=\\tilde{O}(b_{e}+s)$ , and the overall communication is ${\\tilde{O}}(T(b_{e}+s))$ . ", "page_idx": 5}, {"type": "text", "text": "4.4 DEWA-M-P ", "text_level": 1, "page_idx": 5}, {"type": "text", "text": "We propose DEWA-M described in Algorithm 3 that achieves a near-optimal regret versus communication tradeoff up to log factors for the maximum aggregation function in the broadcast model. ", "page_idx": 5}, {"type": "text", "text": "The intuition of DEWA-M is that for each expert, if we walk through the servers in a random order and only update $\\hat{l}_{i}^{t}$ if we encounter $l_{i,j}^{t}>\\hat{l}_{i}^{t}$ , then with high probability, we only need a small number of updates per expert. This cannot be achieved in the message-passing model due to the fact that broadcasting $\\hat{l}_{i}^{t}$ requires $\\Omega(s)$ communication per expert. In contrast, no communication is required for broadcasting $\\hat{l}_{i}^{t}$ in the broadcast model. In fact, with probability $1-\\delta$ , each expert will update at most $O(\\log(s/\\delta))$ times. By setting $\\begin{array}{r}{\\delta=\\frac{1}{b_{e}\\mathrm{poly}(T)}}\\end{array}$ and applying a union bound over our sampling budget $b_{e}$ and number of days, we have the desired low communication with probability at least poly1(T ). More precisely, we have the following theorem (see detailed proof in Section B.1): ", "page_idx": 5}, {"type": "table", "img_path": "HyxjSi3SzF/tmp/755b945dff5e8379abfdb27b4e40d9876ad6ced2798d9aabd9c3165aaec1f42d.jpg", "table_caption": [], "table_footnote": [], "page_idx": 6}, {"type": "text", "text": "Theorem 4.1. For a sampling budget $b_{e}\\in[n]$ , with probability poly1(T ), the communication cost for DEWA-M is ${\\tilde{O}}(T(b_{e}+s))$ . ", "page_idx": 6}, {"type": "text", "text": "Even though we have a high probability guarantee with minimal communication, we still only have a constant probability guarantee for achieving optimal regret $O(\\sqrt{\\frac{n\\log n}{b_{e}T}})$ n bleogT n ). We can boost the success probability using the same trick as in Algorithm 2 by initiating $\\log\\left(\\mathrm{poly}(T)\\right)$ copies of DEWA-M as meta-experts and running EWA on top of them. We refer to the high-probability version as DEWA-M-P . We thus have the following theorem (see detailed proof in Section B.2): ", "page_idx": 6}, {"type": "text", "text": "Theorem 4.2. For a sampling budget $b_{e}\\in[n]$ , with probability poly1(T ), the communication cost for DEWA-M-P is ${\\tilde{O}}(T(b_{e}+s))$ . ", "page_idx": 6}, {"type": "text", "text": "4.5 DEWA-L-P ", "text_level": 1, "page_idx": 6}, {"type": "text", "text": "In this section, we present DEWA-L (Algorithm 4) for the $\\ell_{p>1}$ norm aggregation function in the broadcast model. The key idea of DEWA-L is to embed $\\ell_{p}$ into $\\ell_{\\infty}$ using the min-stable property of exponential distribution. More specifically, if $E_{i}$ is a standard exponential random variable, then $\\begin{array}{r}{\\operatorname*{max}_{j}\\frac{\\bar{(l_{i,j}^{t})^{p}}}{E_{j}}\\sim\\frac{(l_{i}^{t})^{p}}{E}}\\end{array}$ where $E$ is also a standard exponential random variable. Therefore, we can employ DEWA-M to efficiently compute $\\frac{(l_{i}^{t})^{p}}{E}$ , and obtain an unbiased estimator of $l_{i}^{t}$ by normalizing. ", "page_idx": 6}, {"type": "text", "text": "Algorithm 4 DEWA-L ", "text_level": 1, "page_idx": 6}, {"type": "text", "text": "Input: learning rate $\\eta$ , sampling budget $b_{e}$ ;   \nCoordinator initializes $\\hat{L}_{i}^{0}=0,\\forall i\\in[n]$ ;   \nfor $t=1$ to $T$ do Coordinator chooses expert $i$ with probability $p(i)\\propto\\exp{(-\\eta\\hat{L}_{i}^{t-1})}$ ; Coordinator randomly chooses $b_{e}$ experts with corresponding IDs $\\mathcal{B}_{e}=\\{t(1),t(2),\\cdot\\cdot\\cdot\\cdot,t(b_{e})\\}$ ; Coordinator initializes $\\hat{l}_{i}^{t}=0,\\forall i\\in[n]$ ; Coordinator permutes [s] randomly and denotes the resulting sequence as $S_{t}$ for $j$ in $S_{t}$ do Coordinator initiates channel with server $j$ ; Server $j$ samples $E_{j}\\sim$ Exponential(1); for $i=1$ to $n$ do Server $j$ observes cost $l_{i,j}^{t}$ and computes $\\begin{array}{r}{c_{i,j}^{t}=\\frac{\\left(l_{i,j}^{t}\\right)^{p}}{E_{j}}}\\end{array}$ ; Server $j$ sends $c_{i,j}^{t}$ to the coordinator if $c_{i,j}^{t}>c_{i}^{t}$ and $i\\in\\mathcal{B}_{e}$ ; Server $j$ cleans memory buffer; Coordinator updates $c_{i}^{t}=\\operatorname*{max}_{j}c_{i,j}^{t}$ with received $c_{i,j}^{t}$ ; Coordinator computes 1\u2212(1\u221211)beE[(Ei)\u22121/p], where E \u223cExponential(1); Update $\\hat{L}_{i}$ by $\\hat{L}_{i}^{t}=\\hat{L}_{i}^{t-1}+\\hat{l}_{i}^{t},\\forall i\\in[n]$ ; ", "page_idx": 6}, {"type": "text", "text": "It is not hard to see that the communication cost of DEWA-L stays the same as DEWA-M . In terms of regret, if we fix any constant $0<\\varepsilon\\le1$ such that $1+\\varepsilon<p.$ , DEWA-L achieves a vanishing regret $R=\\bar{O}\\big((\\frac{n\\log n}{T b_{e}})^{\\frac{\\varepsilon}{1+\\varepsilon}}\\big)$ with constant probability. Note that, for all $\\ell_{p}$ -norm functions with $p>2$ , by choosing $\\varepsilon=1$ , we obtain a near-optimal regret versus communication tradeoff up to a log factor $R=O(\\sqrt{\\frac{n\\log n}{T b_{e}}})$ n lTobge n). Again, to get the high probability regret guarantee of DEWA-L , we propose DEWA-L-P that initiates $\\log\\left(\\mathrm{poly}(T)\\right)$ copies of DEWA-L as meta-experts and runs EWA on top of them. More precisely, we have the following theorem with the same proof as Theorem 4.2: ", "page_idx": 7}, {"type": "text", "text": "Theorem 4.3. For a sampling budget $b_{e}\\in[n]$ , with probability poly1(T ), the communication cost for DEWA-L- $\\mathcal{P}$ is ${\\tilde{O}}(T(b_{e}+s))$ . ", "page_idx": 7}, {"type": "text", "text": "5 Formal Guarantees ", "text_level": 1, "page_idx": 7}, {"type": "text", "text": "We present formal regret analyses of DEWA-S , DEWA-S-P , DEWA-M-P and DEWA-L-P . We show that DEWA-S can achieve regret R = O( $\\begin{array}{r}{R=O(\\sqrt{\\frac{n\\log n}{T b_{e}}})}\\end{array}$ n Tl obge n ) with probability at least 9/10, DEWA-S-P and DEWA-M-P can achieve regret $\\begin{array}{r}{R=O(\\sqrt{\\frac{n\\log{(n T)}}{T b_{e}}})}\\end{array}$ with probability at least $1-{\\frac{1}{\\mathrm{poly}(T)}}$ poly(T ), and lastly DEWA-L-P can achieve regret $\\begin{array}{r}{R=O((\\frac{n\\log n}{T b_{e}})^{\\frac{\\varepsilon}{1+\\varepsilon}}+\\sqrt{\\frac{\\log T}{T}})}\\end{array}$ with probability at least $1-{\\frac{1}{\\mathrm{poly}(T)}}$ for any fixed constant $0<\\varepsilon\\le1$ such that $1+\\varepsilon<p$ . ", "page_idx": 7}, {"type": "text", "text": "We then give a communication lower bound, which holds even in the broadcast model, for both summation and maximum aggregation functions with a memory bound on the individual servers. It holds for oblivious adversarial cost streams, and thus also for strong adversarial cost streams and the message-passing model. We use the communication lower bound for the $\\epsilon$ -DIFFDIST problem Srinivas et al. (2022) but adapt it to our setting. By reducing the $\\epsilon$ -DIFFDIST problem to the distributed experts problem, we prove that any protocol for achieving $R$ regret with constant probability requires total communication at least $\\Omega\\big(\\frac{\\bar{n}}{R^{2}}\\big)$ . It will follow that DEWA-S , DEWA-M and DEWA-L $(p>2)$ are near-optimal in their communication for all regret values $R\\in[O(\\sqrt{\\frac{\\log n}{T}}),O(\\sqrt{\\frac{n\\log n}{T}})]$ . ", "page_idx": 7}, {"type": "text", "text": "5.1 Upper Bound ", "text_level": 1, "page_idx": 7}, {"type": "text", "text": "We state our regret upper bounds for DEWA-S in Theorem 5.1, DEWA-S-P in Theorem 5.2, DEWAM-P in Theorem 5.3 and DEWA-L-P in Theorem 5.4. The detailed corresponding proofs can be found in Section B. ", "page_idx": 7}, {"type": "text", "text": "Theorem 5.1. For be \u2208[n], DEWA-S achieves regret R = O( n Tl obge n with probability at least $\\frac{9}{10}$ for the distributed experts problem in the message passing model with the summation aggregation function and for strong adaptive adversarial cost streams. ", "page_idx": 7}, {"type": "text", "text": "Theorem 5.2. DEWA-S-P achieves regret $\\begin{array}{r}{R=O(\\sqrt{\\frac{n\\log{(n T)}}{T b_{e}}})}\\end{array}$ with probability at least $1-\\frac{1}{p o l y(T)}$ for the distributed experts problem in the message passing model with the summation aggregation function and for strong adaptive adversarial cost streams. ", "page_idx": 7}, {"type": "text", "text": "Notice that the total communication cost for DEWA-S-P is ${\\tilde{O}}(T(b_{e}+s))$ . Thus DEWA-S-P can achieve the same regret as EWA with a high probability guarantee when $b_{e}=n$ , but requires only ${\\tilde{O}}(T(n+s))$ communication instead of $\\bar{O}\\bar{(}n\\bar{T}s{)}$ communication. DEWA-S-P further generalizes to the case when $b_{e}<n$ . ", "page_idx": 7}, {"type": "text", "text": "Theorem 5.3. DEWA-M-P achieves regret $\\begin{array}{r}{R=O(\\sqrt{\\frac{n\\log{(n T)}}{T b_{e}}})}\\end{array}$ n loTg  b(enT )) with probability at least 1 \u2212poly1(T ) for the distributed experts problem in the broadcast model with maximum aggregation function and for strong adaptive adversarial cost streams. ", "page_idx": 7}, {"type": "text", "text": "Theorem 5.4. Fix any constant $0\\;<\\;\\varepsilon\\;\\leq\\;1$ such that $1\\,+\\,\\varepsilon\\,<\\,p,$ DEWA-L- $\\mathcal{P}$ achieves regret $\\begin{array}{r}{R=O((\\frac{n\\log n}{T b_{e}})^{\\frac{\\varepsilon}{1+\\varepsilon}}+\\sqrt{\\frac{\\log T}{T}})}\\end{array}$ with probability at least \u2212poly1(T ) for the distributed experts problem in the broadcast model with $\\ell_{p}$ norm aggregation function and for strong adaptive adversarial cost streams. ", "page_idx": 7}, {"type": "table", "img_path": "HyxjSi3SzF/tmp/cae99b12b20853c03b5253e0d327fc1a5564404d263f0b87c06b2ccffd42ac08.jpg", "table_caption": ["Table 4: Communication costs on the real-world HPO-B benchmark in different settings. We use EWA as the comparison baseline. E.g., DEWA-S only costs about $0.07\\times$ communication of EWA. "], "table_footnote": [], "page_idx": 8}, {"type": "text", "text": "Since the regret and communication bounds hold with probability at least poly1(T ) individually, by a union bound, they both hold with probability at least $1-{\\frac{1}{\\operatorname{poly}(T)}}$ . ", "page_idx": 8}, {"type": "text", "text": "5.2 Lower Bound ", "text_level": 1, "page_idx": 8}, {"type": "text", "text": "Theorem 5.5. Let $\\textstyle p<{\\frac{1}{2}}$ be a fixed constant that is independent of the other input parameters, and suppose $\\begin{array}{r}{M=O(\\frac{n}{s T R^{2}}\\,\\bar{+}\\,1)}\\end{array}$ is an upper bound on the total memory a server can store from previous days. Any algorithm $\\boldsymbol{\\mathcal{A}}$ that solves the distributed experts problem in the broadcast model with the $\\ell_{p}(1\\leq p\\leq\\infty)$ norm aggregation function with regret $R$ and with probability at least $1-p,$ , needs at least $\\Omega\\big(\\frac{n}{R^{2}}\\big)$ bits of communication. If the algorithm can also determine, with probability at least $1-p,$ if the cost of the selected expert on each day is non-zero, then it also needs $\\Omega(T s)$ bits of communication. These lower bounds hold even for oblivious adversarial cost streams. ", "page_idx": 8}, {"type": "text", "text": "We present the proof of Theorem 5.5 in Section B.7. Additionally, we present an $\\Omega(n s)$ communication lower bound proof below for achieving sub-constant regret with the maximum aggregation function in the message-passing model, which is optimal for $T\\stackrel{*}{\\in}O(\\mathrm{poly}(\\log{(n s)}))$ . This indicates that we cannot do better than na\u00efve EWA in this case, which achieves optimal regret with communication $\\tilde{O}(n s)$ . Note that within the optimal regret $R\\in[O(\\sqrt{\\frac{\\log n}{T}}),O(\\sqrt{\\frac{n\\log n}{T}})]$ in which we are interested, the $T$ term can be canceled out by the $\\textstyle{\\frac{1}{T}}$ term in $R^{2}$ . So, the memory-bound assumption does not depend on the time step $T$ . ", "page_idx": 8}, {"type": "text", "text": "6 Experiments ", "text_level": 1, "page_idx": 8}, {"type": "text", "text": "In this section, we demonstrate the effectiveness of our algorithms on the HPO-B benchmark (Arango et al., 2021) under two setups: 1. Message-passing model with summation aggregation function and 2. Broadcast model with maximum aggregation function. As a black-box hyperparameter optimization benchmark, we can regard different models in the HPO-B benchmark as different experts in the distributed experts problem, and different datasets are distributed across different servers. We further regard each search step, which is random search for all model classes, as one day in our distributed experts problem. The cost vector is then the normalized negative accuracy of models on different datasets for a search step. Thus, minimizing regret directly corresponds to optimizing the overall accuracy across all search steps. For both DEWA-S and DEWA-M , we set $b_{e}=1$ to compare against Exp3 and $b_{e}=n$ to compare against EWA. ", "page_idx": 8}, {"type": "text", "text": "The results in Figure 1, Figure 2 and Table 4 show that our algorithms achieve similar regret as the optimal algorithms (Exp3 and EWA) while having less communication cost. We further use two synthetic datasets to evaluate our algorithms under various scenarios, including dense-cost and sparse-cost. We present the results in Section D, which show that our algorithms can achieve near-optimal regret with significantly lower communication cost across all scenarios consistently. ", "page_idx": 8}, {"type": "text", "text": "Acknowledgements ", "text_level": 1, "page_idx": 8}, {"type": "text", "text": "David P. Woodruff was supported in part by a Simons Investigator Award and NSF CCF-2335412. ", "page_idx": 8}, {"type": "image", "img_path": "HyxjSi3SzF/tmp/f9e6c67acb8a565634bae2a466bf70d601cddd981a6d89054c026fdf6271ae4f.jpg", "img_caption": [], "img_footnote": [], "page_idx": 9}, {"type": "text", "text": "Figure 1: Regrets on HPO-B w/ sum aggregation.Figure 2: Regrets on HPO-B w/ max aggregation. ", "page_idx": 9}, {"type": "text", "text": "References ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "Aamand, A., Chen, J. Y., Nguyen, H. L., and Silwal, S. Improved space bounds for learning with experts. arXiv preprint arXiv:2303.01453, 2023.   \nAgrawal, S. and Goyal, N. Near-optimal regret bounds for thompson sampling. Journal of the ACM (JACM), 64(5):1\u201324, 2017.   \nAhmadian, S., Esfandiari, H., Mirrokni, V., and Peng, B. Robust load balancing with machine learned advice. In Proceedings of the 2022 Annual ACM-SIAM Symposium on Discrete Algorithms (SODA), pp. 20\u201334. SIAM, 2022.   \nAnandkumar, A., Michael, N., Tang, A. K., and Swami, A. Distributed algorithms for learning and cognitive medium access with logarithmic regret. IEEE Journal on Selected Areas in Communications, 29(4):731\u2013745, 2011.   \nArackaparambil, C., Brody, J., and Chakrabarti, A. Functional monitoring without monotonicity. In Automata, Languages and Programming: 36th International Colloquium, ICALP 2009, Rhodes, Greece, July 5-12, 2009, Proceedings, Part I 36, pp. 95\u2013106. Springer, 2009.   \nArango, S. P., Jomaa, H. S., Wistuba, M., and Grabocka, J. Hpo-b: A large-scale reproducible benchmark for black-box hpo based on openml. arXiv preprint arXiv:2106.06257, 2021.   \nArora, S., Hazan, E., and Kale, S. The multiplicative weights update method: a meta-algorithm and applications. Theory of computing, 8(1):121\u2013164, 2012.   \nAudibert, J.-Y., Bubeck, S., et al. Minimax policies for adversarial and stochastic bandits. In COLT, volume 7, pp. 1\u2013122, 2009.   \nAuer, P. Using confidence bounds for exploitation-exploration trade-offs. Journal of Machine Learning Research, 3(Nov):397\u2013422, 2002.   \nAuer, P., Cesa-Bianchi, N., Freund, Y., and Schapire, R. E. The nonstochastic multiarmed bandit problem. SIAM journal on computing, 32(1):48\u201377, 2002.   \nBesson, L. and Kaufmann, E. Multi-player bandits revisited. In Algorithmic Learning Theory, pp. 56\u201392. PMLR, 2018.   \nBistritz, I. and Leshem, A. Distributed multi-player bandits - a game of thrones approach. In Bengio, S., Wallach, H., Larochelle, H., Grauman, K., Cesa-Bianchi, N., and Garnett, R. (eds.), Advances in Neural Information Processing Systems, volume 31. Curran Associates, Inc., 2018. URL https://proceedings.neurips.cc/paper/2018/file/ c2964caac096f26db222cb325aa267cb-Paper.pdf.   \nBraverman, M., Ellen, F., Oshman, R., Pitassi, T., and Vaikuntanathan, V. A tight bound for set disjointness in the message-passing model. In 2013 IEEE 54th Annual Symposium on Foundations of Computer Science, pp. 668\u2013677. IEEE, 2013.   \nBrown, G. W. Iterative solution of games by fictitious play. Act. Anal. Prod Allocation, 13(1):374, 1951.   \nBrown, G. W. and Von Neumann, J. Solutions of games by differential equations. Technical report, RAND CORP SANTA MONICA CA, 1950.   \nBubeck, S., Li, Y., Peres, Y., and Sellke, M. Non-stochastic multi-player multi-armed bandits: Optimal rate with collision information, sublinear without. In Conference on Learning Theory, pp. 961\u2013987. PMLR, 2020.   \nCesa-Bianchi, N. and Lugosi, G. Prediction, learning, and games. Cambridge university press, 2006.   \nCesa-Bianchi, N., Gentile, C., Mansour, Y., and Minora, A. Delay and cooperation in nonstochastic bandits. In Conference on Learning Theory, pp. 605\u2013622. PMLR, 2016.   \nChan, T. H. H., Li, M., Shi, E., and Xu, W. Differentially private continual monitoring of heavy hitters from distributed streams. In Privacy Enhancing Technologies: 12th International Symposium, PETS 2012, Vigo, Spain, July 11-13, 2012. Proceedings 12, pp. 140\u2013159. Springer, 2012.   \nChen, J., Sun, H., Woodruff, D., and Zhang, Q. Communication-optimal distributed clustering. Advances in Neural Information Processing Systems, 29, 2016.   \nChristiano, P., Kelner, J. A., Madry, A., Spielman, D. A., and Teng, S.-H. Electrical flows, laplacian systems, and faster approximation of maximum flow in undirected graphs. In Proceedings of the forty-third annual ACM symposium on Theory of computing, pp. 273\u2013282, 2011.   \nCormode, G., Muthukrishnan, S., and Yi, K. Algorithms for distributed functional monitoring. ACM Transactions on Algorithms (TALG), 7(2):1\u201320, 2011.   \nCormode, G., Muthukrishnan, S., Yi, K., and Zhang, Q. Continuous sampling from distributed streams. Journal of the ACM (JACM), 59(2):1\u201325, 2012.   \nDegenne, R. and Perchet, V. Anytime optimal algorithms in stochastic multi-armed bandits. In International Conference on Machine Learning, pp. 1587\u20131595. PMLR, 2016.   \nDixon, M. F., Halperin, I., and Bilokon, P. Machine learning in Finance, volume 1406. Springer, 2020.   \nDoyle, J. C., Francis, B. A., and Tannenbaum, A. R. Feedback control theory. Courier Corporation, 2013.   \nFreund, Y. and Schapire, R. E. A decision-theoretic generalization of on-line learning and an application to boosting. Journal of computer and system sciences, 55(1):119\u2013139, 1997.   \nGarber, D. and Hazan, E. Sublinear time algorithms for approximate semidefinite programming. Mathematical Programming, 158(1):329\u2013361, 2016.   \nGarivier, A. and Capp\u00e9, O. The kl-ucb algorithm for bounded stochastic bandits and beyond. In Proceedings of the 24th annual conference on learning theory, pp. 359\u2013376. JMLR Workshop and Conference Proceedings, 2011.   \nGrigoriadis, M. D. and Khachiyan, L. G. A sublinear-time randomized approximation algorithm for matrix games. Operations Research Letters, 18(2):53\u201358, 1995.   \nHazan, E. et al. Introduction to online convex optimization. Foundations and Trends\u00ae in Optimization, 2(3-4):157\u2013325, 2016.   \nHillel, E., Karnin, Z. S., Koren, T., Lempel, R., and Somekh, O. Distributed exploration in multiarmed bandits. Advances in Neural Information Processing Systems, 26, 2013.   \nHopkins, S., Li, J., and Zhang, F. Robust and heavy-tailed mean estimation made simple, via regret minimization. Advances in Neural Information Processing Systems, 33:11902\u201311912, 2020.   \nKanade, V., Liu, Z., and Radunovic, B. Distributed non-stochastic experts. Advances in Neural Information Processing Systems, 25, 2012.   \nKaufmann, E. On bayesian index policies for sequential resource allocation. The Annals of Statistics, 46(2):842\u2013865, 2018. ", "page_idx": 9}, {"type": "text", "text": "", "page_idx": 10}, {"type": "text", "text": "Klivans, A. and Meka, R. Learning graphical models using multiplicative weights. In 2017 IEEE 58th Annual Symposium on Foundations of Computer Science (FOCS), pp. 343\u2013354. IEEE, 2017. ", "page_idx": 11}, {"type": "text", "text": "Korda, N., Kaufmann, E., and Munos, R. Thompson sampling for 1-dimensional exponential family bandits. Advances in neural information processing systems, 26, 2013.   \nKorda, N., Szorenyi, B., and Li, S. Distributed clustering of linear bandits in peer to peer networks. In International conference on machine learning, pp. 1301\u20131309. PMLR, 2016.   \nLandgren, P., Srivastava, V., and Leonard, N. E. Distributed cooperative decision-making in multiarmed bandits: Frequentist and bayesian algorithms. In 2016 IEEE 55th Conference on Decision and Control (CDC), pp. 167\u2013172. IEEE, 2016.   \nLattimore, T. and Szepesv\u00e1ri, C. Bandit algorithms. Cambridge University Press, 2020.   \nOrdentlich, E. and Cover, T. M. The cost of achieving the best portfolio in hindsight. Mathematics of Operations Research, 23(4):960\u2013982, 1998.   \nPeng, B. and Rubinstein, A. Near optimal memory-regret tradeoff for online learning. arXiv preprint arXiv:2303.01673, 2023.   \nPeng, B. and Zhang, F. Online prediction in sub-linear space. arXiv preprint arXiv:2207.07974, 2022.   \nRobbins, H. Some aspects of the sequential design of experiments. Bulletin of the American Mathematical Society, 58(5):527\u2013535, 1952.   \nRobinson, J. An iterative method of solving a game. Annals of mathematics, pp. 296\u2013301, 1951.   \nShahrampour, S., Rakhlin, A., and Jadbabaie, A. Multi-armed bandits in multi-agent networks. In 2017 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), pp. 2786\u20132790. IEEE, 2017.   \nShalev-Shwartz, S. et al. Online learning and online convex optimization. Foundations and Trends\u00ae in Machine Learning, 4(2):107\u2013194, 2012.   \nSrinivas, V., Woodruff, D. P., Xu, Z., and Zhou, S. Memory bounds for the experts problem. In Proceedings of the 54th Annual ACM SIGACT Symposium on Theory of Computing, STOC 2022, pp. 1158\u20131171, New York, NY, USA, 2022. Association for Computing Machinery. ISBN 9781450392648. doi: 10.1145/3519935.3520069. URL https://doi.org/10.1145/3519935. 3520069.   \nSzorenyi, B., Busa-Fekete, R., Hegedus, I., Orm\u00e1ndi, R., Jelasity, M., and K\u00e9gl, B. Gossip-based distributed stochastic bandit algorithms. In International Conference on Machine Learning, pp. 19\u201327. PMLR, 2013.   \nThompson, W. R. On the likelihood that one unknown probability exceeds another in view of the evidence of two samples. Biometrika, 25(3-4):285\u2013294, 1933.   \nWang, P.-A., Proutiere, A., Ariu, K., Jedra, Y., and Russo, A. Optimal algorithms for multiplayer multi-armed bandits. In International Conference on Artificial Intelligence and Statistics, pp. 4120\u20134129. PMLR, 2020.   \nWelzl, E. Basic examples of probabilistic analysis, part i \u2013 reading assignment for predoc course on randomized algorithms. 01 2000.   \nWoodruff, D. P. and Zhang, Q. Tight bounds for distributed functional monitoring. In Proceedings of the forty-fourth annual ACM symposium on Theory of computing, pp. 941\u2013960, 2012.   \nWoodruff, D. P., Zhang, F., and Zhou, S. Streaming algorithms for learning with experts: Deterministic versus robust. arXiv preprint arXiv:2303.01709, 2023. ", "page_idx": 11}, {"type": "text", "text": "A Preliminaries ", "text_level": 1, "page_idx": 12}, {"type": "text", "text": "A.1 Strong Adaptive Adversaries ", "text_level": 1, "page_idx": 12}, {"type": "text", "text": "Definition A.1. (Distributed experts problem with a strong adversary). An algorithm $\\boldsymbol{\\mathcal{A}}$ run by the coordinator makes predictions for $T$ days. On day $t$ : ", "page_idx": 12}, {"type": "text", "text": "1. $\\boldsymbol{\\mathcal{A}}$ commits to a distribution $p_{t}$ over $n$ experts based on the memory contents of the coordinator on day $t$ .   \n2. The adversary selects the cost $l_{i,j}^{t}$ on each server after observing $p_{t}$ .   \n3. $\\boldsymbol{\\mathcal{A}}$ selects an expert according to $p_{t}$ and incurs the corresponding cost.   \n4. The coordinator updates its memory contents by communicating with servers according to the protocol defined by $\\boldsymbol{\\mathcal{A}}$ . ", "page_idx": 12}, {"type": "text", "text": "We refer to adversaries that can arbitrarily define the $l_{i,j}^{t}$ with no knowledge of the internal randomness or state of $\\boldsymbol{\\mathcal{A}}$ , as oblivious adversaries. Notice that if we send each of the server\u2019s local information to the coordinator each day, then running the Exponential Weight Algorithm on the coordinator gives an optimal $O(\\sqrt{\\frac{\\log n}{T}})$ regret for strong adversarial streams. However, the communication cost is a prohibitive $\\tilde{O}(n T s)$ words. ", "page_idx": 12}, {"type": "text", "text": "A.2 Exponential Weights Algorithm ", "text_level": 1, "page_idx": 12}, {"type": "text", "text": "As we will use the Exponential Weights Algorithm (EWA) as a sub-routine, we briefly describe it in Algorithm 5. We have the following regret bound for EWA: ", "page_idx": 12}, {"type": "table", "img_path": "HyxjSi3SzF/tmp/902ab7f84a0bd82df0282ac8a7cc77aceb4ff940a9ed3ee58ce1999625fec561.jpg", "table_caption": [], "table_footnote": [], "page_idx": 12}, {"type": "text", "text": "Lemma A.2. (EWA regret, Arora et al. (2012)). Suppose $n,T,\\eta>0,$ , $t\\in[T]$ , and $l^{t}\\in[0,1]^{n}$ . Let $p_{t}$ be the distribution committed to by EWA on day $t,$ . Then: $\\begin{array}{r}{\\frac{1}{T}(\\sum_{t=1}^{T}\\langle p_{t},l^{t}\\rangle-\\operatorname*{min}_{i^{*}\\in[n]}\\sum_{t=1}^{T}l_{i^{*}}^{t})\\leq}\\end{array}$ $\\frac{\\log n}{\\eta T}+\\eta$ . And with probability at least $1-\\delta$ , the average regret is bounded by: $\\begin{array}{r}{R(A)\\leq\\frac{\\log n}{\\eta T}+}\\end{array}$ $\\eta+O(\\sqrt{\\frac{\\log{(n/\\delta)}}{T}})$ log (Tn/\u03b4)). Thus, taking \u03b7 = $\\begin{array}{r}{\\eta=\\sqrt{\\frac{\\log n}{T}}}\\end{array}$ and $\\begin{array}{r}{\\delta=\\frac{1}{p o l y(T)}}\\end{array}$ poly1(T ) gives us O( $O(\\sqrt{\\frac{\\log{(n T)}}{T}})$ log (TnT )) regret with probability at least $1-\\frac{1}{p o l y(T)}$ . ", "page_idx": 12}, {"type": "text", "text": "B Proofs. ", "text_level": 1, "page_idx": 12}, {"type": "text", "text": "B.1 Theorem 4.1 ", "text_level": 1, "page_idx": 12}, {"type": "text", "text": "In order to prove the communication bounds, we need the following lemma: ", "page_idx": 12}, {"type": "text", "text": "Lemma B.1. Welzl (2000). With a randomly permuted sequence $S=\\{a_{1},a_{2},\\cdot\\cdot\\cdot,a_{n}\\}$ and $\\gamma=0$ , if we read from left to right and update $\\gamma\\,=\\,a_{i}$ whenever we encounter $a_{i}\\,>\\,\\gamma.$ , define random variable $X$ as the number of times $\\gamma$ has is updated during the process. We have the following results: ", "page_idx": 12}, {"type": "equation", "text": "$$\n\\mathbb{E}\\left[2^{X}\\right]=n+1\n$$", "text_format": "latex", "page_idx": 12}, {"type": "text", "text": "Given Lemma B.1, we can then prove our statement. ", "page_idx": 12}, {"type": "text", "text": "Proof. For any expert on any day, we will first prove that with probability at least $1\\,-\\,\\delta$ , the servers only need to send the corresponding cost to the coordinator at most ${\\dot{O}}{\\dot{(}}\\log{(s/\\delta)})$ times. By ", "page_idx": 12}, {"type": "text", "text": "Lemma B.1 with $n=s$ in our setup, for any $g\\geq0$ , we have: ", "page_idx": 13}, {"type": "equation", "text": "$$\n\\begin{array}{l l l}{\\operatorname*{Pr}\\left(X>g\\right)}&{=}&{\\operatorname*{Pr}\\left(2^{X}>2^{g}\\right)}\\\\ &{\\leq}&{\\displaystyle\\frac{\\mathbb{E}\\left[2^{X}\\right]}{2^{g}}}\\\\ &{=}&{\\displaystyle\\frac{s+1}{2^{g}}}\\end{array}\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "By setting g = log s\u03b4+1 , we have Pr X < log s\u03b4+1  > 1 \u2212\u03b4. Furthermore, letting \u03b4 =bepol1y(T ), we have ", "page_idx": 13}, {"type": "equation", "text": "$$\n\\operatorname*{Pr}\\left(X<\\log\\left((s+1)b_{e}\\mathrm{poly}(T)\\right)\\right)>1-{\\frac{1}{b_{e}\\mathrm{poly}(T)}}.\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "By a union bound over the $b_{e}$ sampled experts and $T$ days, the above guarantee simultaneously holds for all experts sampled and all days, with probability at least $1-1/\\mathrm{poly}(T)$ . The overall communication is then: ", "page_idx": 13}, {"type": "equation", "text": "$$\n\\begin{array}{r l r}{\\lefteqn{\\sum_{t=1}^{T}\\left(s+\\sum_{j=1}^{b_{e}}X\\right)}}\\\\ &{}&{\\le\\sum_{t=1}^{T}\\left(s+\\sum_{j=1}^{b_{e}}\\log\\left((s+1)b_{e}\\mathrm{poly}(T)\\right)\\right)}\\\\ &{}&{=T s+T b_{e}\\log\\left((s+1)b_{e}\\mathrm{poly}(T)\\right)}\\\\ &{}&{=\\tilde{O}(T(b_{e}+s))}\\end{array}\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "which completes the proof. ", "page_idx": 13}, {"type": "text", "text": "In addition, in cases where the coordinator does not need to initiate communication, we can achieve an ${\\cal O}(b_{e}\\log\\left(s/\\delta\\right))$ communication cost per time step with the following protocol: Initialization: each individual server initializes a $\\hat{h_{i}^{t}}$ to record the maximum cost for each expert. 1. For each server who has a cost larger than the current maximum, send its value to the broadcast channel after a $\\delta_{i,j}$ time delay, where $\\delta_{i,j}$ is randomly sampled from [0, 1]. 2. Once the broadcast channel has been occupied, all other servers stop the sending action and update their corresponding $\\hat{h_{i}^{t}},\\delta_{i,j}$ instead. Then we can repeat this process and use the maximum value collected after $s$ unit time steps as an estimate to the maximum value. In this protocol, we assume that the broadcast channel can only be occupied by one server. The random ordering is guaranteed by the random delay and the expected number of communication rounds to get the maximum value is given in Lemma B.1. Additionally, notice that for each time step the protocol is guaranteed to end within $s$ time steps as the worst case delay is 1 unit time step for each server. By using this protocol, we can still obtain a near optimal communication cost of $O(b_{e}\\log s/\\delta)$ . ", "page_idx": 13}, {"type": "text", "text": "B.2 Theorem 4.2 ", "text_level": 1, "page_idx": 13}, {"type": "text", "text": "Proof. Let $\\mathcal{C}$ be the communication required to obtain the cost of one expert on a single day. From the proof of Theorem 4.1, we have $\\mathcal{C}=O(\\log\\left((s+1)b_{e}\\mathrm{poly}(T))\\right)$ with probability $\\bar{1}-\\frac{1}{b_{e}\\mathrm{poly}(T)}$ . For DEWA-M-P , we need this communication bound to hold for $T b_{e}\\log\\left(\\mathrm{poly}(T)\\right)+T\\log\\left(\\mathrm{poly}(T)\\right)$ experts and meta-experts simultaneously across a horizon of $T$ days. By a union bound, the failure rate is ", "page_idx": 13}, {"type": "equation", "text": "$$\n\\frac{T b_{e}\\log{(\\mathrm{poly}(T))}+T\\log{(\\mathrm{poly}(T))}}{b_{e}\\mathrm{poly}(T)}=1/\\mathrm{poly}(T).\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "As the communication cost of each expert and meta-expert is ", "page_idx": 13}, {"type": "equation", "text": "$$\nO(\\log{((s+1)b_{e}\\mathrm{poly}(T))})=\\tilde{O}(1)\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "the overall communication cost is thus ", "page_idx": 13}, {"type": "equation", "text": "$$\n\\tilde{O}(T s+T b_{e}\\log{(\\mathrm{poly}(T))}+T\\log{(\\mathrm{poly}(T))})=\\tilde{O}(T(b_{e}+s))\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "with probability at least $1-1/\\mathrm{poly}(T)$ , which concludes the proof. ", "page_idx": 13}, {"type": "text", "text": "B.3 Theorem 5.1 ", "text_level": 1, "page_idx": 14}, {"type": "text", "text": "We need the following lemmas: ", "page_idx": 14}, {"type": "text", "text": "Lemma B.2. Define L\u02c6it =  tt\u2032=1 l\u02c6it\u2032 , w\u02c6it =  ei\u2032x ep x(p\u2212 (\u03b7\u2212 L\u02c6\u03b7it L\u02c6\u2212it1\u2032\u2212)1). Define $\\hat{w}_{t}\\,=\\,[\\hat{w}_{1}^{t},\\cdot\\cdot\\cdot\\,,\\hat{w}_{n}^{t}]^{\\top},\\hat{l}_{t}\\,=$ $[\\hat{l}_{1}^{t},\\cdot\\cdot\\cdot\\;,\\hat{l}_{n}^{t}]^{\\top}$ and $\\eta$ is of our choice. For all $1\\geq\\varepsilon>0$ , we have the following result: ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\sum_{t=1}^{T}\\langle\\hat{w}_{t},\\hat{l}_{t}\\rangle-\\operatorname*{min}_{i^{*}}\\hat{L}_{i^{*}}^{T}\\leq\\frac{\\log n}{\\eta}+\\frac{\\eta^{\\varepsilon}}{\\varepsilon\\left(\\varepsilon+1\\right)}\\sum_{t=1}^{T}\\sum_{i=1}^{n}\\hat{w}_{i}^{t}(\\hat{l}_{i}^{t})^{1+\\varepsilon}\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "Proof. Define $\\begin{array}{r}{\\Phi_{t}=\\frac{1}{\\eta}\\log\\left(\\sum_{i=1}^{n}\\exp\\left(-\\eta\\hat{L}_{i}^{t}\\right)\\right)}\\end{array}$ ", "page_idx": 14}, {"type": "text", "text": "We have: ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\Phi_{T}-\\Phi_{0}}\\\\ &{=\\sum_{t=1}^{T}\\Phi_{t}-\\Phi_{t-1}}\\\\ &{\\frac{\\sqrt{1}}{t-1}\\frac{1}{\\eta(t)}\\log\\left(\\frac{\\sum_{t=1}^{T}\\exp\\Big(-\\eta\\hat{U}_{t-1}^{t-1}\\Big)\\exp\\Big(-\\eta\\hat{U}_{t}\\Big)}{\\sum_{t=1}^{T}\\exp\\Big(-\\eta\\hat{U}_{t-1}^{t-1}\\Big)}\\right)}\\\\ &{=\\sum_{t=1}^{T}\\frac{1}{\\eta(t)}\\log\\left(\\frac{\\sum_{t=1}^{T}\\exp\\Big(-\\eta\\hat{U}_{t}\\Big)}{\\sum_{t=1}^{T}\\exp\\Big(-\\eta\\hat{U}_{t}\\Big)}\\right)}\\\\ &{\\leq\\sum_{t=1}^{T}\\frac{1}{\\eta}\\log\\left(\\sum_{t=1}^{T}\\mu_{t}^{\\tau}\\Big[1-\\eta\\hat{U}_{t}^{t}+\\frac{1}{\\xi}\\frac{1}{\\xi}(\\xi(\\hat{U}_{t})^{1+\\epsilon}\\epsilon(\\hat{U}_{t})^{1+\\epsilon}\\Big]\\right)}\\\\ &{\\leq\\sum_{t=1}^{T}\\frac{1}{\\eta}\\sum_{t=1}^{T}\\left(-\\eta\\hat{u}_{t}^{\\tau}\\hat{U}_{t}^{t}+\\frac{1}{\\xi(1+\\epsilon)}\\eta^{\\tau+1}\\eta^{\\tau}\\hat{U}_{t}^{\\tau}\\right)}\\\\ &{\\leq-\\sum_{t=1}^{T}\\epsilon(\\hat{u}_{s})_{s}+\\frac{\\eta}{\\xi(\\xi+1)}\\frac{\\eta^{\\tau}}{\\sum_{t=1}^{T}\\exp\\Big(-\\eta\\hat{U}_{s}\\Big)}\\frac{\\eta^{\\tau}}{\\sum_{t=1}^{T}\\hat{U}_{t}^{\\tau}}\\frac{\\eta^{\\tau}}{\\mu}\\Big(\\hat{U}_{s}^{T}\\Big)^{1+\\epsilon}}\\end{array}\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "where we used \u2200x \u22650, e\u2212x \u22641 \u2212x +\u03b5(\u03b51+1) for the first inequality and $\\forall x,\\log\\left(1+x\\right)\\leq x$ for the second inequality. ", "page_idx": 14}, {"type": "text", "text": "As $\\begin{array}{r}{\\Phi_{0}=\\frac{\\log n}{\\eta}}\\end{array}$ by definition, we have: ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\begin{array}{r c l}{\\displaystyle\\frac{\\log n}{\\eta}+\\frac{\\eta^{\\varepsilon}}{\\varepsilon\\left(\\varepsilon+1\\right)}\\sum_{t=1}^{T}\\sum_{i=1}^{n}\\hat{w}_{i}^{t}(\\hat{l}_{i}^{t})^{1+\\varepsilon}}&{\\displaystyle\\geq}&{\\displaystyle\\Phi_{T}+\\sum_{t=1}^{T}\\langle\\hat{w}_{t},\\hat{l}_{t}\\rangle}\\\\ &{\\displaystyle\\geq}&{\\displaystyle\\sum_{t=1}^{T}\\langle\\hat{w}_{t},\\hat{l}_{t}\\rangle-\\operatorname*{min}_{i^{*}}\\hat{L}_{i^{*}}^{T}}\\end{array}\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "where the second inequality holds due to the fact that $\\forall i^{*}\\in[n]$ : ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\begin{array}{c c l}{\\Phi_{T}}&{=}&{\\displaystyle\\frac{1}{\\eta}\\log\\left(\\sum_{i=1}^{n}\\exp\\left(-\\eta\\hat{L}_{i}^{t}\\right)\\right)}\\\\ &{\\displaystyle\\geq}&{\\displaystyle\\frac{1}{\\eta}\\log\\left(\\exp\\left(-\\eta\\hat{L}_{i^{*}}^{t}\\right)\\right)}\\\\ &{\\displaystyle\\geq}&{\\displaystyle-\\hat{L}_{i^{*}}^{t}}\\end{array}\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "Lemma B.3. Let R be the average regret over $T$ days. Then, ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\mathbb{E}[R]\\leq\\frac{1}{T}\\cdot\\mathbb{E}\\left[\\sum_{t=1}^{T}\\langle\\hat{w}_{t},\\hat{l}_{t}\\rangle-\\operatorname*{min}_{i^{*}}\\hat{L}_{i^{*}}^{T}\\right]\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "Proof. We have: ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{T\\cdot\\mathbb{E}[R]}&{=~\\mathbb{E}\\left[\\frac{T}{\\sum_{i=1}^{T}\\langle\\hat{w}_{t},I_{i}\\rangle}-\\operatorname*{min}L_{i^{*}}^{T}\\right]}\\\\ &{=~\\mathbb{E}\\left[\\frac{T}{\\sum_{i=1}^{T}\\langle\\hat{w}_{t},I_{i}\\rangle}\\right]-\\operatorname*{min}L_{i^{*}}^{T}}\\\\ &{=~\\mathbb{E}\\left[\\frac{T}{\\sum_{i=1}^{T}\\langle\\hat{w}_{t},I_{i}\\rangle}\\right]-\\operatorname*{min}\\mathbb{E}\\left[\\hat{L}_{i^{*}}^{T}\\right]}\\\\ &{\\leq~\\mathbb{E}\\left[\\frac{T}{t_{\\alpha}!}\\langle\\hat{w}_{t},I_{i^{*}}\\rangle\\right]-\\mathbb{E}\\left[\\operatorname*{min}\\hat{L}_{i^{*}}^{T}\\right]}\\\\ &{=~\\mathbb{E}\\left[\\frac{T}{\\sum_{i=1}^{T}\\langle\\hat{w}_{t},\\hat{L}_{i^{*}}\\rangle}-\\operatorname*{min}\\hat{L}_{i^{*}}^{T}\\right]}\\end{array}\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "Line 3 is due to $\\hat{l}_{t}$ being independent of $\\hat{w}_{t}$ on day $t$ and $\\hat{l}_{t}$ is an unbiased estimator. Line 4 is by Jensen\u2019s inequality. \u53e3 ", "page_idx": 15}, {"type": "text", "text": "Proof. Back to our proof for Theorem 5.1, we have: ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{T\\cdot\\mathbb{E}[R]}&{\\leq}&{\\mathbb{E}\\left[\\displaystyle\\sum_{i=1}^{T}(\\hat{w}_{t},\\hat{l}_{i})-\\eta_{i+1}\\,\\hat{L}_{i}^{T}\\right]\\quad\\mathrm{(by~Lemma~B.3)}}\\\\ &{\\leq}&{\\mathbb{E}\\left[\\displaystyle\\frac{\\log n}{\\eta}+\\frac{\\eta}{2}\\,\\sum_{i=1}^{T}\\upsilon_{i}^{t}(\\hat{l}_{i}^{t})^{2}\\right]\\quad\\mathrm{(by~Lemma~B.2~with~}\\varepsilon=1)}\\\\ &{=}&{\\displaystyle\\frac{\\log n}{\\eta}+\\frac{\\eta}{2}\\sum_{i=1}^{T}\\mathbb{E}\\left[\\sum_{i=1}^{n}w_{i}^{t}(\\hat{l}_{i}^{t})^{2}\\right]}\\\\ &{=}&{\\displaystyle\\frac{\\log n}{\\eta}+\\frac{\\eta}{2}\\sum_{i=1}^{T}\\mathbb{E}\\left[\\sum_{i=1}^{n}w_{i}^{t}(\\hat{l}_{i}^{t})^{2}\\right]}\\\\ &{\\leq\\displaystyle\\left.\\frac{\\log n}{2}+\\frac{\\eta}{2}\\sum_{i=1}^{T}\\mathbb{E}\\left[\\sum_{i=1}^{n}w_{i}^{t}\\left(\\frac{2n}{b_{i}}\\right)\\right]\\right.}\\\\ &{=}&{\\displaystyle\\frac{\\log n}{\\eta}+\\eta\\frac{\\sqrt{n}}{\\log n}}\\end{array}\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "Line 5 is by: ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{E}\\left[\\left(\\frac{n_{s}}{b_{e}\\int_{\\mathbb{Z}}}\\!\\!\\!\\sum_{i=1}^{s}\\!\\!\\!\\alpha_{i,j}^{t}\\beta_{i,j}^{t}\\right)^{2}\\right]}\\\\ &{\\!\\!=\\!\\!\\frac{n^{2}}{b_{e}^{2}}\\left(\\sum_{j=1}^{s}\\mathbb{E}\\left[(\\alpha_{i,j}^{t}\\beta_{i,j}^{t})^{2}\\right]+\\sum_{j\\neq i}\\mathbb{E}[\\alpha_{i,h}^{t}\\alpha_{i,h}^{t}\\beta_{i,h}^{t}\\beta_{i,h}^{t}]\\right)}\\\\ &{\\!\\!=\\!\\frac{n^{2}}{b_{e}^{2}}\\left(\\frac{b_{e}}{n}\\sum_{j=1}^{s}\\!\\!\\!l_{i,j}^{t}+\\frac{b_{e}^{2}}{n^{2}}\\sum_{j\\neq h}^{t}\\!\\!l_{i,j}^{t}\\!\\!l_{i,h}^{t}\\right)}\\\\ &{\\!\\!\\le\\!\\frac{n^{2}}{b_{e}^{2}}\\left(\\frac{b_{e}}{n}+\\frac{b_{e}^{2}}{n^{2}}(\\sum_{j=1}^{s}\\!\\!\\!l_{i,j}^{t})^{2}\\right)\\le\\frac{2n}{b_{e}}}\\end{array}\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "Take \u03b7 = $\\begin{array}{r}{\\eta=\\sqrt{\\frac{b_{e}\\log n}{T n}}}\\end{array}$ be log n. We then have: ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\mathbb{E}[R]\\leq2{\\sqrt{\\frac{n\\log n}{T b_{e}}}}\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "Due to $R>0$ , by Markov\u2019s inequality we have: ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\operatorname*{Pr}\\left(R>20{\\sqrt{\\frac{n\\log n}{T b_{e}}}}\\right)\\leq{\\frac{\\mathbb{E}[R]}{20{\\sqrt{\\frac{n\\log n}{T b_{e}}}}}}\\leq{\\frac{1}{10}}\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "which concludes our proof. ", "page_idx": 16}, {"type": "text", "text": "B.4 Theorem 5.2 ", "text_level": 1, "page_idx": 16}, {"type": "text", "text": "Proof. Let $b_{e}\\in[n]$ and $K=\\lceil\\log\\left(\\mathrm{poly}(T)\\right)\\rceil$ . Let $\\{\\mathcal{A}_{1},\\mathcal{A}_{2},\\cdot\\cdot\\cdot,\\mathcal{A}_{K}\\}$ be $K$ independent DEWA-S meta-experts initiated with $b_{e},b_{s}$ . Let $\\mathbf{\\mathcal{A}}_{k}=S$ be the event that $\\mathcal{A}_{k}$ successfully achieves regret $O(\\sqrt{\\frac{n\\log n}{T b_{e}}})$ and let $A_{k}=F$ be the event that it fails. From Theorem 5.1 we have: ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\operatorname*{Pr}(\\mathcal{A}_{k}=F)\\leq\\frac{1}{10}\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "Thus, the probability that the best meta-expert achieves regret $O(\\sqrt{\\frac{n\\log n}{T b_{e}}})$ can be lower bounded by: ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\operatorname*{Pr}\\left(\\bigcup_{k=1}^{K}(A_{k}=S)\\right)\\geq1-(\\frac{1}{10})^{K}\\geq1-1/\\mathrm{poly}(T)\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "By Lemma A.2, running EWA on top of these meta-experts gives us regret: ", "page_idx": 16}, {"type": "equation", "text": "$$\nR=O(\\sqrt{\\frac{n\\log n}{T b_{e}}})+O(\\sqrt{\\frac{\\log{(K/\\delta)}}{T}})\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "with probability $1-1/\\mathrm{poly}(T)-\\delta$ (by a union bound). Letting $\\delta=1/\\mathrm{poly}(T)$ then guarantees an $O\\big(\\sqrt{\\frac{n\\log\\left(n T\\right)}{T b_{e}}}\\big)$ regret with probability at least poly2(T ), which concludes the proof. \u53e3 ", "page_idx": 16}, {"type": "text", "text": "B.5 Theorem 5.3 ", "text_level": 1, "page_idx": 16}, {"type": "text", "text": "Proof. For DEWA-M we have a constant probability guarantee to have regret $\\begin{array}{r}{R=O(\\sqrt{\\frac{n\\log{(n)}}{T b_{e}}})}\\end{array}$ The proof simply follows from the proof of Theorem 5.1, except that we now have actual cost for the ", "page_idx": 16}, {"type": "text", "text": "sampled experts instead of unbiased estimates. More specifically, we have: ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{T\\cdot\\mathbb{E}[R]}&{\\leq\\;\\mathbb{E}\\left[\\frac{T}{\\kappa\\log n}\\langle\\hat{u}_{t},\\hat{u}_{t}\\rangle-\\frac{n\\log|\\hat{L}|^{2}}{\\kappa^{2}}\\right]}\\\\ &{\\leq\\;\\mathbb{E}\\left[\\frac{\\log n}{\\eta}+\\eta\\sum_{t=1}^{n}\\sum_{u^{t}}^{n}w_{t}^{t}(\\hat{l}_{u}^{t})^{2}\\right]}\\\\ &{=\\;\\frac{\\log n}{\\eta}+\\eta\\sum_{t=1}^{T}\\mathbb{E}\\left[\\sum_{u^{t}}^{n}w_{t}^{t}(\\hat{l}_{u}^{t})^{2}\\right]}\\\\ &{=\\;\\frac{\\log n}{\\eta}+\\eta\\sum_{t=1}^{T}\\mathbb{E}\\left[\\sum_{u^{t}}^{n}w_{t}^{t}\\mathbb{E}\\{(\\hat{l}_{u}^{t})^{2}\\}\\right]}\\\\ &{\\leq\\;\\frac{\\log n}{\\eta}+\\eta\\sum_{t=1}^{T}\\left[\\sum_{u^{t}}^{n}w_{t}^{t}\\Big(\\frac{n}{b_{u}}\\Big)^{2}\\right]}\\\\ &{=\\;\\frac{\\log n}{\\eta}+\\eta\\frac{T}{\\log n}}\\end{array}\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "Take \u03b7 = $\\begin{array}{r}{\\eta=\\sqrt{\\frac{b_{e}\\log n}{T n}}}\\end{array}$ be log n. We then have: ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\mathbb{E}[R]\\leq2{\\sqrt{\\frac{n\\log n}{T b_{e}}}}\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "Since $R>0$ , by Markov\u2019s inequality we have: ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\operatorname*{Pr}\\left(R>20{\\sqrt{\\frac{n\\log n}{T b_{e}}}}\\right)\\leq{\\frac{\\mathbb{E}[R]}{20{\\sqrt{\\frac{n\\log n}{T b_{e}}}}}}\\leq{\\frac{1}{10}}\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "Thus, with probability at least $\\frac{9}{10}$ DEWA-M has regret $\\begin{array}{r}{R=O(\\sqrt{\\frac{n\\log{(n)}}{T b_{e}}})}\\end{array}$ n lTo gb (n)). Since we have initiated $\\log\\left(\\mathrm{poly}(T)\\right)$ independent instances of DEWA-M , we have probability at least $1-1/\\mathrm{poly}(T)$ that one of the instances of DEWA-M achieves regret $\\begin{array}{r}{R=O(\\sqrt{\\frac{n\\log{(n)}}{T b_{e}}})}\\end{array}$ n lTo gb e(n)). By Lemma A.2, running EWA on top of these meta-experts gives us regret: ", "page_idx": 17}, {"type": "equation", "text": "$$\nR=O(\\sqrt{\\frac{n\\log n}{T b_{e}}})+O(\\sqrt{\\frac{\\log\\left(\\log\\left(\\mathrm{poly}(T)\\right)/\\delta\\right)}{T}})\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "with probability $1-1/\\mathrm{poly}(T)-\\delta$ (by a union bound). Let $\\delta=1/\\mathrm{poly}(T)$ . This guarantees an $O\\big(\\sqrt{\\frac{n\\log\\left(n T\\right)}{T b_{e}}}\\big)$ regret with probability at least poly2(T ), which concludes the proof. \u53e3 ", "page_idx": 17}, {"type": "text", "text": "B.6 Theorem 5.4 ", "text_level": 1, "page_idx": 18}, {"type": "text", "text": "Proof. We first upper bound the expected average regret of DEWA-L . Since $p>1$ , for any fixed constant $\\varepsilon>0$ such that $1+\\varepsilon<p.$ , by Lemma B.2 and Lemma B.3, we have: ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{T\\cdot\\mathbb{E}[R]}&{\\leq\\;\\;\\mathbb{E}\\left[\\displaystyle\\sum_{t=1}^{T}(\\hat{u}_{t},\\hat{l}_{t})-\\operatorname*{min}_{t=1}^{T}\\hat{L}_{t}^{t}\\right]}\\\\ &{\\leq\\;\\;\\mathbb{E}\\left[\\displaystyle\\frac{\\log n}{\\eta}+\\frac{\\eta^{t}}{\\varepsilon(\\varepsilon+1)}\\sum_{t=1}^{T}\\sum_{i=1}^{n}\\hat{w}_{i}^{t}(\\hat{l}_{i}^{\\gamma_{1}}{)}^{1+\\varepsilon}\\right]}\\\\ &{=\\;\\;\\frac{\\log n}{\\eta}+\\frac{\\eta^{t}}{\\varepsilon(\\varepsilon+1)}\\sum_{t=1}^{T}\\mathbb{E}\\left[\\displaystyle\\sum_{s=1}^{n}\\hat{w}_{i}^{t}(\\hat{l}_{i}^{\\gamma_{1}+\\varepsilon}\\right)^{1}\\right.}\\\\ &{=\\left.\\;\\frac{\\log n}{\\eta}+\\frac{\\eta^{t}}{\\varepsilon(\\varepsilon+1)}\\sum_{t=1}^{T}\\mathbb{E}\\left[\\displaystyle\\sum_{s=1}^{n}\\hat{w}_{i}^{t}\\xi[(\\hat{l}_{i}^{\\gamma_{1}})^{1+\\varepsilon}]\\right]}\\\\ &{\\leq\\left.\\;\\frac{\\log n}{\\eta}+\\frac{\\eta^{t}}{\\varepsilon(\\varepsilon+1)}\\sum_{t=1}^{T}\\mathbb{E}\\left[\\sum_{i=1}^{n}\\hat{w}_{i}^{t}\\big(\\Big(\\hat{l}_{i}^{n}\\Big)^{\\varepsilon}\\Big)\\right]}\\\\ &{=\\;\\;\\frac{\\log n}{\\eta}+T\\cdot O\\left(\\left(\\frac{\\eta^{n}}{\\eta}\\right)^{\\varepsilon}\\right)}\\end{array}\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "Let $\\begin{array}{r}{q=1-\\left(1-\\frac{1}{n}\\right)^{b_{e}}}\\end{array}$ be the probability that an expert gets picked into $\\boldsymbol{{B_{e}}}$ . Line 4 is by: ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\mathbb{E}\\left[\\left(\\hat{t}_{i}^{1}\\right)^{1+\\epsilon}\\right]=q\\cdot\\frac{1}{q^{1+\\epsilon}}\\cdot\\frac{\\mathbb{E}\\left[\\left(c_{i}^{\\epsilon}\\right)^{(1+\\epsilon)/\\epsilon}\\right]}{\\mathbb{E}^{1+\\epsilon}}}&{}\\\\ {=q^{-\\epsilon}\\frac{\\mathbb{E}\\left[\\left(t_{i}^{1}\\right)^{1+\\epsilon}\\cdot E^{-(1+\\epsilon)/\\epsilon}\\right]}{\\mathbb{E}\\left[E^{-1/\\epsilon}\\right]}}\\\\ {=q^{-\\epsilon}\\cdot\\left(t_{i}^{1}\\right)^{1+\\epsilon}\\cdot\\frac{\\mathbb{E}\\left[E^{-(1+\\epsilon)/\\epsilon}\\right]}{\\mathbb{E}\\left[E^{-1/\\epsilon}\\right]}}\\\\ {\\leq q^{-\\epsilon}\\cdot\\frac{\\mathbb{E}\\left[E^{-(1+\\epsilon)/\\epsilon}\\right]}{\\mathbb{E}\\left[E^{-1/\\epsilon}\\right]}}&{\\mathrm{~(as~0~\\leq~I\\'~s~1~)~}}\\\\ {=O\\left(q^{-\\epsilon}\\right)\\quad\\mathrm{(a~a~\\mathbb{E}~\\left[E^{-(1+\\epsilon)/\\epsilon}\\right]~a n d~\\mathbb{E}~\\left[E^{-1/\\epsilon}\\right]~c o n v e r g e)}}\\\\ {=O\\left(\\left(\\frac{n}{b_{k}}\\right)^{\\epsilon}\\right)}\\end{array}\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "Pick $\\begin{array}{r}{\\eta=\\left(\\frac{b_{e}}{n}\\right)^{\\varepsilon}\\cdot\\frac{\\log n}{\\varepsilon T}}\\end{array}$ , we then have: ", "page_idx": 18}, {"type": "equation", "text": "$$\nT\\cdot\\mathbb{E}\\left[R\\right]=O\\left(T^{\\frac{1}{1+\\varepsilon}}\\left(\\frac{n\\log n}{b_{e}}\\right)^{\\frac{\\varepsilon}{1+\\varepsilon}}\\right)\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "Hence, ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\mathbb{E}\\left[R\\right]=O\\left(\\left(\\frac{n\\log n}{T b_{e}}\\right)^{\\frac{\\varepsilon}{1+\\varepsilon}}\\right)\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "By Markov\u2019s inequality, DEWA-L has an average regret $\\begin{array}{r}{R=O\\left(\\left(\\frac{n\\log n}{T b_{e}}\\right)^{\\frac{\\varepsilon}{1+\\varepsilon}}\\right)}\\end{array}$ with probability at least $\\frac{9}{10}$ . ", "page_idx": 18}, {"type": "text", "text": "Since we have initiated $\\log\\left(\\mathrm{poly}(T)\\right)$ independent instances of DEWA- $.\\mathrm{L}$ , we have probability at least $1-1/\\mathrm{poly}(T)$ that one of the instances of DEWA-L achieves regret $\\begin{array}{r}{R=O\\left(\\left(\\frac{n\\log n}{T b_{e}}\\right)^{\\frac{\\varepsilon}{1+\\varepsilon}}\\right)}\\end{array}$ ", "page_idx": 18}, {"type": "text", "text": "By Lemma A.2, running EWA on top of these meta-experts gives us regret: ", "page_idx": 19}, {"type": "equation", "text": "$$\nR=O\\left(\\left(\\frac{n\\log n}{T b_{e}}\\right)^{\\frac{\\varepsilon}{1+\\varepsilon}}\\right)+O\\left(\\sqrt{\\frac{\\log\\left(\\log\\left(\\mathrm{poly}(T)\\right)/\\delta\\right)}{T}}\\right)\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "with probability $1-1/\\mathrm{poly}(T)-\\delta$ (by a union bound). Let $\\delta=1/\\mathrm{poly}(T)$ . This guarantees an $\\begin{array}{r}{O\\left(\\left(\\frac{n\\log n}{T b_{e}}\\right)^{\\frac{\\varepsilon}{1+\\varepsilon}}+\\sqrt{\\frac{\\log T}{T}}\\right)}\\end{array}$ regret with probability at least poly2(T ), which concludes the proof. ", "page_idx": 19}, {"type": "text", "text": "B.7 Lower Bound Proof ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "The communication lower bound proof for the maximum aggregation function in the message-passing model follows using the multi-player number-in-hand communication lower bound for set disjointness in Braverman et al. (2013). To solve the multi-player set disjointness problem with $s$ players, where each player has $n$ bits of information $c_{i}^{j}\\in\\{0,1\\},i\\in[n],j\\in[s]$ , the communication lower bound is $\\Omega(n{\\bar{s}})$ for the message-passing model. ", "page_idx": 19}, {"type": "text", "text": "In our problem, in the first case, all experts have at least one server that has a cost of 1, i.e., $\\exists j\\in[s],\\forall i\\in[n],c_{i}^{j}=1$ . In the second case, we have one expert whose cost on every server is 0 while the other experts all have at least one server that has a cost of 1. Then, in the first case, the sets (cost vectors on each server) are disjoint for all coordinates (experts) while in the second case, there exists one coordinate (expert) whose intersection over all sets is non-empty. In the second case, this expert has a maximum cost of 0 while all other experts incur a maximum cost of 1. If we can decide which case we are in, then we solve the set disjointness problem, and thus there is an $\\Omega(n s)$ communication bound. By copying the same hard instance over $T$ days, it follows that if there exists an algorithm that can achieve sub-constant regret for this distributed experts problem, then the algorithm also solves the above set disjointness problem. We have thus obtained an $\\Omega(n s)$ communication bound for the maximum aggregation function in the message-passing model. Note that EWA can achieve the optimal regret with $\\tilde{O}(n s)$ communication if we assume $T\\in{\\cal O}(\\mathrm{poly}(\\log\\left(n s\\right)))$ , and therefore, we cannot do better than EWA up to logarithmic factors with the maximum aggregation function in the message-passing model. To give the lower bound proof, we first define the $\\epsilon_{}$ -DIFFDIST problem. ", "page_idx": 19}, {"type": "text", "text": "Definition B.4. ( $\\epsilon$ -DIFFDIST problem, Srinivas et al. (2022)). There are $T$ players, and each has $n$ bits of information indexed from 1 to $n$ . Let $\\mu_{0}=\\mathrm{{Bernoulli}(\\frac{1}{2}),\\mu_{1}=\\mathrm{{Bernoulli}(\\frac{1}{2}-\\epsilon)}}$ , we must distinguish between the following two cases: ", "page_idx": 19}, {"type": "text", "text": "\u2022 (Case A). Each index for each player is drawn i.i.d. from $\\mu_{0}$ .   \n\u2022 (Case B). An index $i\\in[n]$ is randomly chosen, then the $i$ -th indexed bit of each player is drawn i.i.d. from $\\mu_{1}$ while other bits of players are all drawn i.i.d. from $\\mu_{0}$ . ", "page_idx": 19}, {"type": "text", "text": "Lemma B.5. (\u03f5-DIFFDIST communication bound, Srinivas et al. (2022)). The communication complexity of solving the $\\epsilon$ -DIFFDIST problem with a constant $1-p$ probability under the broadcast model, for any $p\\in[0,0.5)$ , is $\\Omega({\\frac{n}{\\epsilon^{2}}})$ ", "page_idx": 19}, {"type": "text", "text": "Note that a lower bound for the broadcast model is also a lower bound for the message-passing model. By regarding different days as servers and bits as cost streams of experts, if we generate bits from either case A or case B, then the algorithm needs to distinguish between case A and case B to obtain regret at most \u03f5. We design Algorithm 6 to connect the $\\epsilon_{}$ -DIFFDIST with the distributed experts problem. Algorithm 6 gives a reduction from $\\epsilon$ -DIFFDIST, and thus we obtain our lower bound in Theorem 5.5. The additional $T s$ factor is from our requirement that we obtain an approximation to the actual cost for the selected expert on each day. We present the complete proof as follows: ", "page_idx": 19}, {"type": "text", "text": "Proof. 1 We will prove this by showing for R = $\\begin{array}{r}{R=\\frac{1}{2+\\sqrt{2\\ln{(24)}}}}\\end{array}$ and $\\textstyle p={\\frac{1}{3}}$ , Algorithm 6 can indeed solve $\\epsilon$ -DIFFDIST with probability at least $\\begin{array}{l}{{\\frac{2}{3}}}\\end{array}$ . The proof extends naturally to any constant $\\delta,p<{\\textstyle{\\frac{1}{2}}}$ . ", "page_idx": 19}, {"type": "text", "text": "Input: $\\{X^{1},\\cdot\\cdot\\cdot,X^{t},\\cdot\\cdot\\cdot,X^{T}\\}$ , where $X^{t}\\,\\in\\,\\{0,1\\}^{n}$ for all $t\\,\\in\\,[T]$ is a binary vector generated from   \n$\\epsilon$ -DIFFDIST; Oracle algorithm $\\mathcal{A}$ that solves the summation-based distributed experts problem with regret $R$   \nand probability larger than $\\frac{1}{2}$ ;   \nLet $c=\\sqrt{2\\ln{(24)}},\\epsilon=\\bar{R(c+1)}<1/2$ ;   \nCost definition: For day $t$ , we randomly sample a server $j$ and define $l_{j}^{t}=X^{j}$ and $l_{j^{\\prime}}^{t}=\\mathbf{0},\\forall j^{\\prime}\\in[s]/\\{j\\}$ ;   \nInitialize $M_{0}$ as the initial memory state on the coordinator for $\\mathcal{A}$ , counter $C=0$ ;   \nfor $t=1$ to $T$ do Obtain the actual cost $l(t)=\\boldsymbol{A}(M_{t-1})$ incurred by $\\mathcal{A}$ ; $C+=l(t)$ ; Update memory state to $M_{t}$ by communicating with downstream servers according to $\\boldsymbol{\\mathcal{A}}$ ;   \nLet $\\begin{array}{r}{\\bar{C}=\\frac{C}{T}}\\end{array}$ be the average cost;   \nif $\\begin{array}{r}{\\hat{C}>\\frac{1-R c}{2}}\\end{array}$ then Return Case A;   \nelse Return Case B; ", "page_idx": 20}, {"type": "text", "text": "We further need R <2(c1+1) to make sure $\\textstyle{\\frac{1}{2}}+\\epsilon$ is a valid probability. Let $\\hat{C}$ be the average cost of $\\boldsymbol{\\mathcal{A}}$ . We will show we can solve the $\\epsilon$ -DIFFDIST problem in both cases. ", "page_idx": 20}, {"type": "text", "text": "For case A, $\\hat{C}$ is just the average of $T$ i.i.d. coin flips. Thus, by Hoeffding\u2019s inequality we have: ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\begin{array}{r c l}{\\operatorname*{Pr}\\left(\\hat{C}\\le\\displaystyle\\frac{1-R c}{2}\\right)}&{=}&{\\operatorname*{Pr}\\left(1-\\hat{C}\\ge\\displaystyle\\frac{1+R c}{2}\\right)}\\\\ &{\\le}&{\\exp{(-\\displaystyle\\frac{T R^{2}c^{2}}{2})}}\\\\ &{\\le}&{\\exp{(-\\displaystyle\\frac{c^{2}}{2})}}\\\\ &{<}&{\\displaystyle\\frac{1}{3}}\\end{array}\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "where the third line is due to $T R^{2}\\geq1$ . ", "page_idx": 20}, {"type": "text", "text": "For case B, let $C^{*}$ be the average cost of the expert whose cost is generated from $\\mu_{1}=\\mathrm{{Bernoulli}(\\frac{1}{2}-\\kappa)}$ $R(c+1))$ ). As we know, $\\boldsymbol{\\mathcal{A}}$ has the guarantee that $\\hat{C}\\leq C^{*}+R$ with probability at least $\\frac{3}{4}$ , so we have: ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\begin{array}{r l r}&{}&{\\operatorname*{Pr}(\\hat{C}>\\frac{1-R c}{2})\\qquad}\\\\ &{\\leq}&{\\operatorname*{Pr}\\left(\\left(\\hat{C}>C^{*}+R\\right)\\cup\\left(C^{*}+R>\\frac{1-R c}{2}\\right)\\right)}\\\\ &{\\leq}&{\\operatorname*{Pr}\\left(\\hat{C}>C^{*}+R\\right)+\\operatorname*{Pr}\\left(C^{*}+R>\\frac{1-R c}{2}\\right)}\\\\ &{\\leq}&{\\frac{1}{4}+\\operatorname*{Pr}\\left(C^{*}>\\frac{1}{2}-R(c+1)+\\frac{R c}{2}\\right)\\qquad}\\\\ &{\\leq}&{\\frac{1}{4}+\\exp\\left(-\\frac{T R^{2}c^{2}}{2}\\right)\\qquad}\\\\ &{<}&{\\frac{1}{3}\\qquad}\\end{array}\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "Thus we have shown that we can solve the $\\epsilon$ -DIFFDIST problem in both cases with probability at least $\\begin{array}{l}{{\\frac{2}{3}}}\\end{array}$ , and therefore make Algorithm 6 a valid reduction. As a result, the total communication cost of Algorithm 6 is at least $\\bar{\\Omega}\\big(\\frac{n}{R^{2}}\\big)$ by Lemma B.5. In addition, if we need to know the cost of the selected expert, we need to pay an extra $\\Omega(s)$ communication per day. Indeed, we need $\\Omega(s)$ communication even if we just want to verify whether the selected expert incurs zero cost or not with probability larger than $\\frac{9}{10}$ . This is due to the fact that we can choose our distribution so that on each day, we choose a random server and with probability $1/2$ make the cost 0 on that server, while with the remaining probability $1/2$ we make the cost 1 on that server. All other servers have cost 0. Thus, if the protocol probes $o(s)$ servers on each day, it only has a $1/2+o(1)$ probability to know if the cost is non-zero or not. Thus, we need to at least probe $\\Omega(s)$ servers to succeed with constant probability on a single day, and since the days are independent, $\\Omega(s T)$ communication in total. Thus, we overall have a communication lower bound of $\\Omega\\big(\\frac{\\bar{n}}{R^{2}}+T s\\big)$ . ", "page_idx": 20}, {"type": "text", "text": "", "page_idx": 21}, {"type": "text", "text": "Since we allow each server to have $\\begin{array}{r}{M=O(\\frac{n}{s T R^{2}}+1)}\\end{array}$ memory, we can actually save communication for messages sent between the same server but on different days. However, the communication required can be reduced by at most $T M s$ . Let $\\operatorname{Cost}(A)$ be the communication cost for $\\boldsymbol{\\mathcal{A}}$ . We then have $\\begin{array}{r}{\\operatorname{Cost}(A)\\!+\\!T M s\\in\\Omega\\!\\left(\\frac{n}{R^{2}}\\!+\\!T s\\right)}\\end{array}$ . As $\\begin{array}{r}{T M s\\in O(\\frac{n}{R^{2}}{+}T s)}\\end{array}$ , we thus have $\\begin{array}{r}{\\mathrm{Cost}(A)\\in\\Omega(\\frac{n}{R^{2}}{+}T s)}\\end{array}$ , which completes the proof. \u53e3 ", "page_idx": 21}, {"type": "text", "text": "For the maximum $\\eta_{p}$ norm aggregation function in the broadcast model, we can use the same proof with the same bound since the maximum $\\slash\\ell_{p}$ norm operation gives us the same cost streams as the summation operation under our setting where one random server has cost $X^{t}$ while others have zero costs. ", "page_idx": 21}, {"type": "text", "text": "C Comparison with Kanade et al. (2012) ", "text_level": 1, "page_idx": 21}, {"type": "text", "text": "Although we address a similar topic with Kanade et al. (2012), we would like to stress that our setup differs quite significantly. In our setup, the ground truth costs for experts are aggregated across all servers. In contrast, the setup of Kanade et al. (2012) restricts the ground truth costs for each expert to be allocated to exactly one server per day. Consequently, our setup is more general since instead of finding out the only server that carries the cost on each day, we also incur additional costs from other servers as well. In addition, Kanade et al. (2012) only proves their lower bound for $n=2$ while we handle general $n$ . On the other hand, for $n=2$ , they show a lower bound for adaptive adversaries rather than oblivious adversaries, which is our setting. However, we also make an assumption on the server memory budget for proving lower bounds. In fact, our lower bound directly matches that of Kanade et al. (2012) when $n\\,=\\,2$ if we do not require the coordinator or current transcript to dictate who speaks next as the additive $T s$ term is no longer needed. More specifically, we compare in Table 5 for the case when only the coordinator can initiate conversation and in Table 6 for the case when both the coordinator and servers can initiate conversation. ", "page_idx": 21}, {"type": "table", "img_path": "HyxjSi3SzF/tmp/33a432b9cde34460e6f062cf32fe7b25452a86dbba98115817342f149164d8d1.jpg", "table_caption": ["Table 5: Coordinator initiates message-passing channel "], "table_footnote": [], "page_idx": 21}, {"type": "table", "img_path": "HyxjSi3SzF/tmp/ed836234be31face9fc0a257b2c11190bae8025f04b25ba3f7ac0b5945f925ff.jpg", "table_caption": ["Table 6: Coordinator or server initiates message-passing channel "], "table_footnote": [], "page_idx": 21}, {"type": "text", "text": "Note that we can remove the $T s$ term if the servers are allowed to spontaneously initiate conversation, in which case synchronization between servers on each day is not required. We note that Kanade et al. (2012)\u2019s upper bound is not applicable in our setting as it assumes the cost (payoff vector) to be distributed to only one server. At the same time, we allow the cost to be distributed to any number of servers. Thus, their setup is a special case of ours. We note that our bounds also match those of Kanade et al. (2012) in this special case, e.g., our upper bound is also $\\tilde{O}\\big(\\frac{n}{R^{2}}\\big)$ . In short, our results are incomparable as we allow: 1. Costs to be distributed to any number of servers 2. Any $n$ for the lower-bound proof against oblivious adversaries rather than adaptive adversaries. ", "page_idx": 21}, {"type": "table", "img_path": "HyxjSi3SzF/tmp/eda74583874dae482ac6fb7a0c853819e3aa1d445aa3d6559c63f98c295acf62.jpg", "table_caption": ["Table 7: Communication costs of constant-probability protocols on Gaussian distribution in different settings. We use EWA as the comparison baseline. "], "table_footnote": [], "page_idx": 22}, {"type": "text", "text": "D Simulated Experiments ", "text_level": 1, "page_idx": 22}, {"type": "text", "text": "Evaluation setup. In this section, we evaluate the performance of DEWA-S and DEWA-S-P with the summation aggregation function, and DEWA-M and DEWA-M-P with the maximum aggregation function. We measure the average regrets over the days and total communication costs and compare the performance with EWA when $b_{e}=n$ , and with Exp3 when $b_{e}=1$ . We further evaluate two cost distributions, namely, the Gaussian and Bernoulli distributions. On each server, the costs of the experts are randomly sampled from these distributions. For the best expert, the costs are sampled from $\\mathcal{N}(0.2,1)$ or Bernoulli(0.25), and for the other experts, the costs are sampled from $\\mathcal{N}(0.6,1)$ or Bernoulli(0.5). For the summation aggregation, all of the costs are truncated to the range $[0,1]$ and then divided by the number of servers $s$ . To show the robustness of our protocols under extreme cost conditions, we also evaluate a scenario where the costs are sparsely distributed across the servers, i.e., the cost of an expert is held by one server, and other servers receive zero cost for that expert. To further emphasize the effectiveness of our protocol design in such sparse scenarios, we implement and evaluate the performance of the simplified DEWA-S and DEWA-M and we treat them as BASE-S and BASE-M along with their high probability versions BASE-S-P and BASE-M-P . We describe the detail of the baseline algorithms in the following section. We set the learning rate $\\eta=0.1$ , the number of servers to be $s\\,=\\,50$ , the number of experts to be $n\\,=\\,100$ , and the total days to be $T=10^{5}$ for $b_{e}=1$ and to be $T=10^{4}$ for $b_{e}=n$ . We set the sampling budget $b_{s}=2$ for BASE-S and BASE-S-P . The experiments are run on an Ubuntu $22.04\\,\\mathrm{LTS}$ server equipped with a 12 Intel Core i7-12700K Processor and 32GB RAM. ", "page_idx": 22}, {"type": "text", "text": "D.1 Baselines ", "text_level": 1, "page_idx": 22}, {"type": "text", "text": "For baselines to be compared, we use the simplified variants of DEWA-S and DEWA-M , namely BASE-S and BASE-M . More specifically, for BASE-S , instead of sampling according to cost values, BASE-S is set to sample servers uniformly. The estimate of cost $l_{i}^{t}$ is then defined as: ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\hat{l}_{i}^{t}=\\frac{n s}{b_{e}}\\sum_{j}\\alpha_{i,j}^{t}\\beta_{i,j}^{t}l_{i,j}^{t},\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "where $\\alpha_{i,j}^{t}\\sim\\mathrm{Bernoulli}(\\frac{b_{e}}{n}),\\beta_{i,j}^{t}\\sim\\mathrm{Bernoulli}(\\frac{1}{s})$ . This is a good baseline to compare with since $\\hat{l}_{i}^{t}$ is also an unbiased estimator. However, due to the uniform sampling strategy, BASE-S will fail in the sparse setting and require an additional factor of $s$ in the regret while DEWA-S does not suffer from this. ", "page_idx": 22}, {"type": "text", "text": "For BASE-M , we uniformly sample among servers and take the maximum cost encountered as the estimate of the actual cost $l_{i}^{t}$ . To illustrate the effectiveness of DEWA-M , we enforce that the overall communication cost for BASE-M is close to DEWA-M when $b_{e}=1$ or $b_{e}=n$ . ", "page_idx": 22}, {"type": "text", "text": "D.2 Results of Gaussian Distribution Cost ", "text_level": 1, "page_idx": 22}, {"type": "text", "text": "In Figure 3, we first present the regrets of DEWA-S and DEWA-S-P on the Gaussian distribution with the summation aggregation function in the non-sparse setting. As we can see in Figure 3a, with sampling budget $b_{e}=1$ , DEWA-S achieves much smaller regrets than Exp3. And the protocols\u2019 average regrets over $t$ are converging to 0 with increasing $t$ . The regrets of all the protocols are comparable to that of EWA when the sampling budget $b_{e}=n$ , as shown in Figure 3b. However, for the sparse scenario, as shown in Figure 4, the regrets of DEWA-S and DEWA-S-P are much better than BASE-S and BASE-S-P . When $b_{e}=100$ , DEWA-S and DEWA-S-P can still achieve comparable performance to EWA in the sparse setting. The results further illustrate that our design is ", "page_idx": 22}, {"type": "text", "text": "Table 8: Communication costs of high-probability protocols on Gaussian distribution in different settings. We use EWA as the comparison baseline. ", "page_idx": 23}, {"type": "table", "img_path": "HyxjSi3SzF/tmp/7a2fb946c61a29de076e44731eb9a1c2a89096e3fbf3883d5826cb6b2f8f87a5.jpg", "table_caption": [], "table_footnote": [], "page_idx": 23}, {"type": "image", "img_path": "HyxjSi3SzF/tmp/33767d65b0c7856ef78f2bfec3e90376e0b000e8cb1bea2856da08dc747e881c.jpg", "img_caption": ["Figure 3: Regrets on Gaussian distribution with summation aggregation, non-sparse scenario. "], "img_footnote": [], "page_idx": 23}, {"type": "text", "text": "effective and can handle such extremely sparse cost conditions. As expected, the high-probability versions of the protocols consistently achieve lower regret than their constant-probability versions. ", "page_idx": 23}, {"type": "text", "text": "For the maximum aggregation function, we observe similar results as shown in Figure 5 and Figure 6. The regrets of DEWA-M and DEWA-M-P are close to EWA when $b_{e}=n$ , and their performance is much better than Exp3 when $b_{e}=1$ . We also observe that the regrets of BASE-M and BASE-M-P are close to that of DEWA-M and DEWA-M-P in the non-sparse setting. However, their communication costs are much higher than DEWA-M and DEWA-M-P when $b_{e}=n$ , as shown in Table 7 and Table 8. Consistent with our findings for the summation aggregation function, in the sparse setting, the regrets of BASE-M and BASE-M-P are much higher than DEWA-M and DEWA-M-P . The results illustrate that DEWA-M and DEWA-M-P are not restricted to i.i.d. costs among the servers, and they work well in extremely sparse settings. Thus, we conclude that DEWA-M and DEWA-M-P have wider application scopes. ", "page_idx": 23}, {"type": "text", "text": "We report our communication costs for constant a probability guarantee in Table 7 and for a high probability guarantee in Table 8. We use the communication cost of EWA as the baseline $(1\\!\\times\\!)$ , which is ${\\tilde{O}}(n T s+T s)$ . According to our results, for $b_{e}=1$ and $b_{e}=n$ , DEWA-S and DEWA-S-P use much smaller communication than Exp3 and EWA respectively. We also notice that, in the sparse setting, DEWA-M and DEWA-M-P use much smaller communication to achieve near-optimal regret, since DEWA-M and DEWA-M-P can quickly identify the server holding large costs. Although the BASE counterparts achieve comparable communication costs to DEWA-S , DEWA-S-P , DEWA-M , and DEWA-M-P , considering their much larger regret in the sparse setting, DEWA-S , DEWA-S-P , DEWA-M , and DEWA-M-P are more consistent across settings. By increasing $b_{e}$ , the protocols achieve lower regret at the cost of more communication. Users can choose $b_{e}$ according to their regret requirements and communication budget. Even if we set $b_{e}=n$ , the communication costs are still much smaller than that of EWA, but the regret of our algorithms is very close to optimal. ", "page_idx": 23}, {"type": "text", "text": "D.3 Results of Bernoulli Distribution Cost ", "text_level": 1, "page_idx": 23}, {"type": "text", "text": "In this section, we present our regret and communication on Bernoulli distributed costs. Our regrets are shown in Figure 7, Figure 8, Figure 9, and Figure 10 and our communication costs are presented in Table 9 and Table 10, which are consistent with our observations for Gaussian distribution. DEWA-S , DEWA-S-P , DEWA-M , and DEWA-M-P all perform well in both non-sparse and sparse scenarios, with near-optimal regrets and much smaller communication costs compared with the EWA. ", "page_idx": 23}, {"type": "image", "img_path": "HyxjSi3SzF/tmp/28a02857d7ede9b76377bc2e126769a6a499fed670ca62b8c216aec87a5143b4.jpg", "img_caption": ["Figure 4: Regrets on Gaussian distributions with summation aggregation, sparse scenario. "], "img_footnote": [], "page_idx": 24}, {"type": "image", "img_path": "HyxjSi3SzF/tmp/dbfb5b6fc9374a77a04274c9a17558003b2463266ffb571b4d667859054a5aba.jpg", "img_caption": ["Figure 5: Regret on Gaussian distribution with maximum aggregation, non-sparse scenario. ", "(a) Regret $b_{e}=1$ . (b) Regret $b_{e}=n$ . "], "img_footnote": [], "page_idx": 24}, {"type": "image", "img_path": "HyxjSi3SzF/tmp/233635b64dae2303ec3ad8b9d51c4db2cd69f02cd87be16deed24aabeea0d369.jpg", "img_caption": ["Figure 6: Regret on Gaussian distribution with maximum aggregation, sparse scenario. "], "img_footnote": [], "page_idx": 24}, {"type": "text", "text": "Table 9: Communication costs of constant-probability protocols on Bernoulli distribution in different settings. We use EWA as the comparison baseline. ", "page_idx": 24}, {"type": "table", "img_path": "HyxjSi3SzF/tmp/a073c3659bc99496859d5de5e182383ffea231b96baf7d8f8861de5de99acf29.jpg", "table_caption": [], "table_footnote": [], "page_idx": 24}, {"type": "text", "text": "Table 10: Communication costs of high-probability protocols on Bernoulli distribution in different settings. We use EWA as the comparison baseline. ", "page_idx": 24}, {"type": "table", "img_path": "HyxjSi3SzF/tmp/5ab7d13b9493b27fe75477381cc08d540e29fe547ec9a2b7d27e6ab3955cdea6.jpg", "table_caption": [], "table_footnote": [], "page_idx": 24}, {"type": "image", "img_path": "HyxjSi3SzF/tmp/a7b58619bcb7d0970d05d5f61f33ea2e634ef631cf80bc3668f8097d1b76fb72.jpg", "img_caption": ["Figure 7: Regrets on Bernoulli distribution with summation aggregation, non-sparse scenario. "], "img_footnote": [], "page_idx": 25}, {"type": "image", "img_path": "HyxjSi3SzF/tmp/cb7ca1d5fbf90813b67a928b8e3af1deaed4ddf97de3b5dd792d12b31d9db45f.jpg", "img_caption": ["Figure 8: Regrets on Bernoulli distribution with summation aggregation, sparse scenario. "], "img_footnote": [], "page_idx": 25}, {"type": "image", "img_path": "HyxjSi3SzF/tmp/5fe3dcc2e8527071a3b0c0e48beb59aaa8f26e245bb0e505d2139680d1487dd2.jpg", "img_caption": ["Figure 9: Regret on Bernoulli distribution with maximum aggregation, non-sparse scenario. "], "img_footnote": [], "page_idx": 25}, {"type": "image", "img_path": "HyxjSi3SzF/tmp/bd72b664af3d7fcf949cdca2ce508984508fa2d1f2eb331c9ab2c41d356f9d93.jpg", "img_caption": ["Figure 10: Regret on Bernoulli distribution with maximum aggregation, sparse scenario. "], "img_footnote": [], "page_idx": 25}, {"type": "text", "text": "D.4 Evaluation Results under Different $b_{e}$ ", "text_level": 1, "page_idx": 25}, {"type": "text", "text": "To further study the influence of $b_{e}$ on our algorithms, we evaluate the regret and communication cost of DEWA-S-P and DEWA-M-P under different $b_{e}$ , ranging from 1 to $n=100$ . The results on the regret results can be found in Figure 11. As expected, using a larger $b_{e}$ makes the regret converge faster. We observe that using a reasonably large value ( $0.25n$ in our experiments) is sufficient to achieve good regret. The resulting communication cost using different $b_{e}$ can be found in Figure 12. As expected, the cost generally grows linearly with respect to increasing $b_{e}$ . ", "page_idx": 25}, {"type": "image", "img_path": "HyxjSi3SzF/tmp/2002334aa84f82fbfbe1683e07b05df361be430a1fda9001cc0c43b28e960f76.jpg", "img_caption": [], "img_footnote": [], "page_idx": 26}, {"type": "text", "text": "Figure 11: Regret for Gaussian distribution under different $b_{e}$ , non-sparse scenario. ", "page_idx": 26}, {"type": "image", "img_path": "HyxjSi3SzF/tmp/4930ff05e6813bf474f852f362cf8d3cf4077328d46607b2548cffce80a5819c.jpg", "img_caption": ["Figure 12: Communication cost of DEWA-S-P and DEWA-M-P using different $b_{e}$ , and with EWA as the baseline, non-sparse scenario. "], "img_footnote": [], "page_idx": 26}, {"type": "text", "text": "NeurIPS Paper Checklist ", "text_level": 1, "page_idx": 26}, {"type": "text", "text": "Claims ", "text_level": 1, "page_idx": 26}, {"type": "text", "text": "Question: Do the main claims made in the abstract and introduction accurately reflect the paper\u2019s contributions and scope? ", "page_idx": 26}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 26}, {"type": "text", "text": "Justification: Claims are included ", "page_idx": 26}, {"type": "text", "text": "Guidelines: ", "page_idx": 26}, {"type": "text", "text": "\u2022 The answer NA means that the abstract and introduction do not include the claims made in the paper.   \n\u2022 The abstract and/or introduction should clearly state the claims made, including the contributions made in the paper and important assumptions and limitations. A No or NA answer to this question will not be perceived well by the reviewers.   \n\u2022 The claims made should match theoretical and experimental results, and reflect how much the results can be expected to generalize to other settings.   \n\u2022 It is fine to include aspirational goals as motivation as long as it is clear that these goals are not attained by the paper. ", "page_idx": 26}, {"type": "text", "text": "2. Limitations ", "text_level": 1, "page_idx": 26}, {"type": "text", "text": "Question: Does the paper discuss the limitations of the work performed by the authors? ", "page_idx": 26}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 26}, {"type": "text", "text": "Justification: The lower bound is conditional. ", "page_idx": 26}, {"type": "text", "text": "Guidelines: ", "page_idx": 26}, {"type": "text", "text": "\u2022 The answer NA means that the paper has no limitation while the answer No means that the paper has limitations, but those are not discussed in the paper. \u2022 The authors are encouraged to create a separate \"Limitations\" section in their paper. \u2022 The paper should point out any strong assumptions and how robust the results are to violations of these assumptions (e.g., independence assumptions, noiseless settings, model well-specification, asymptotic approximations only holding locally). The authors should reflect on how these assumptions might be violated in practice and what the implications would be. ", "page_idx": 26}, {"type": "text", "text": "\u2022 The authors should reflect on the scope of the claims made, e.g., if the approach was only tested on a few datasets or with a few runs. In general, empirical results often depend on implicit assumptions, which should be articulated.   \n\u2022 The authors should reflect on the factors that influence the performance of the approach. For example, a facial recognition algorithm may perform poorly when image resolution is low or images are taken in low lighting. Or a speech-to-text system might not be used reliably to provide closed captions for online lectures because it fails to handle technical jargon.   \n\u2022 The authors should discuss the computational efficiency of the proposed algorithms and how they scale with dataset size.   \n\u2022 If applicable, the authors should discuss possible limitations of their approach to address problems of privacy and fairness.   \n\u2022 While the authors might fear that complete honesty about limitations might be used by reviewers as grounds for rejection, a worse outcome might be that reviewers discover limitations that aren\u2019t acknowledged in the paper. The authors should use their best judgment and recognize that individual actions in favor of transparency play an important role in developing norms that preserve the integrity of the community. Reviewers will be specifically instructed to not penalize honesty concerning limitations. ", "page_idx": 27}, {"type": "text", "text": "3. Theory Assumptions and Proofs ", "text_level": 1, "page_idx": 27}, {"type": "text", "text": "Question: For each theoretical result, does the paper provide the full set of assumptions and a complete (and correct) proof? ", "page_idx": 27}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 27}, {"type": "text", "text": "Justification: Please refer to each individual claims and proofs. ", "page_idx": 27}, {"type": "text", "text": "Guidelines: ", "page_idx": 27}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include theoretical results.   \n\u2022 All the theorems, formulas, and proofs in the paper should be numbered and crossreferenced.   \n\u2022 All assumptions should be clearly stated or referenced in the statement of any theorems.   \n\u2022 The proofs can either appear in the main paper or the supplemental material, but if they appear in the supplemental material, the authors are encouraged to provide a short proof sketch to provide intuition.   \n\u2022 Inversely, any informal proof provided in the core of the paper should be complemented by formal proofs provided in appendix or supplemental material.   \n\u2022 Theorems and Lemmas that the proof relies upon should be properly referenced. ", "page_idx": 27}, {"type": "text", "text": "4. Experimental Result Reproducibility ", "text_level": 1, "page_idx": 27}, {"type": "text", "text": "Question: Does the paper fully disclose all the information needed to reproduce the main experimental results of the paper to the extent that it affects the main claims and/or conclusions of the paper (regardless of whether the code and data are provided or not)? ", "page_idx": 27}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 27}, {"type": "text", "text": "Justification: source code is included in the supplementary materials Guidelines: ", "page_idx": 27}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 If the paper includes experiments, a No answer to this question will not be perceived well by the reviewers: Making the paper reproducible is important, regardless of whether the code and data are provided or not.   \n\u2022 If the contribution is a dataset and/or model, the authors should describe the steps taken to make their results reproducible or verifiable.   \n\u2022 Depending on the contribution, reproducibility can be accomplished in various ways. For example, if the contribution is a novel architecture, describing the architecture fully might suffice, or if the contribution is a specific model and empirical evaluation, it may be necessary to either make it possible for others to replicate the model with the same dataset, or provide access to the model. In general. releasing code and data is often one good way to accomplish this, but reproducibility can also be provided via detailed ", "page_idx": 27}, {"type": "text", "text": "instructions for how to replicate the results, access to a hosted model (e.g., in the case of a large language model), releasing of a model checkpoint, or other means that are appropriate to the research performed. ", "page_idx": 28}, {"type": "text", "text": "\u2022 While NeurIPS does not require releasing code, the conference does require all submissions to provide some reasonable avenue for reproducibility, which may depend on the nature of the contribution. For example (a) If the contribution is primarily a new algorithm, the paper should make it clear how to reproduce that algorithm. (b) If the contribution is primarily a new model architecture, the paper should describe the architecture clearly and fully. (c) If the contribution is a new model (e.g., a large language model), then there should either be a way to access this model for reproducing the results or a way to reproduce the model (e.g., with an open-source dataset or instructions for how to construct the dataset). (d) We recognize that reproducibility may be tricky in some cases, in which case authors are welcome to describe the particular way they provide for reproducibility. In the case of closed-source models, it may be that access to the model is limited in some way (e.g., to registered users), but it should be possible for other researchers to have some path to reproducing or verifying the results. ", "page_idx": 28}, {"type": "text", "text": "5. Open access to data and code ", "text_level": 1, "page_idx": 28}, {"type": "text", "text": "Question: Does the paper provide open access to the data and code, with sufficient instructions to faithfully reproduce the main experimental results, as described in supplemental material? ", "page_idx": 28}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 28}, {"type": "text", "text": "Justification: we provide running scripts for all experiments in the paper Guidelines: ", "page_idx": 28}, {"type": "text", "text": "\u2022 The answer NA means that paper does not include experiments requiring code.   \n\u2022 Please see the NeurIPS code and data submission guidelines (https://nips.cc/ public/guides/CodeSubmissionPolicy) for more details.   \n\u2022 While we encourage the release of code and data, we understand that this might not be possible, so \u201cNo\u201d is an acceptable answer. Papers cannot be rejected simply for not including code, unless this is central to the contribution (e.g., for a new open-source benchmark).   \n\u2022 The instructions should contain the exact command and environment needed to run to reproduce the results. See the NeurIPS code and data submission guidelines (https: //nips.cc/public/guides/CodeSubmissionPolicy) for more details.   \n\u2022 The authors should provide instructions on data access and preparation, including how to access the raw data, preprocessed data, intermediate data, and generated data, etc.   \n\u2022 The authors should provide scripts to reproduce all experimental results for the new proposed method and baselines. If only a subset of experiments are reproducible, they should state which ones are omitted from the script and why.   \n\u2022 At submission time, to preserve anonymity, the authors should release anonymized versions (if applicable).   \n\u2022 Providing as much information as possible in supplemental material (appended to the paper) is recommended, but including URLs to data and code is permitted. ", "page_idx": 28}, {"type": "text", "text": "6. Experimental Setting/Details ", "text_level": 1, "page_idx": 28}, {"type": "text", "text": "Question: Does the paper specify all the training and test details (e.g., data splits, hyperparameters, how they were chosen, type of optimizer, etc.) necessary to understand the results? ", "page_idx": 28}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 28}, {"type": "text", "text": "Justification: please refer to Appendix D ", "page_idx": 28}, {"type": "text", "text": "Guidelines: \u2022 The answer NA means that the paper does not include experiments. ", "page_idx": 28}, {"type": "text", "text": "\u2022 The experimental setting should be presented in the core of the paper to a level of detail that is necessary to appreciate the results and make sense of them. \u2022 The full details can be provided either with the code, in appendix, or as supplemental material. ", "page_idx": 29}, {"type": "text", "text": "7. Experiment Statistical Significance ", "text_level": 1, "page_idx": 29}, {"type": "text", "text": "Question: Does the paper report error bars suitably and correctly defined or other appropriate information about the statistical significance of the experiments? ", "page_idx": 29}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 29}, {"type": "text", "text": "Justification: our results are averaged over multiple runs and variance bars are plotted Guidelines: ", "page_idx": 29}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 The authors should answer \"Yes\" if the results are accompanied by error bars, confidence intervals, or statistical significance tests, at least for the experiments that support the main claims of the paper.   \n\u2022 The factors of variability that the error bars are capturing should be clearly stated (for example, train/test split, initialization, random drawing of some parameter, or overall run with given experimental conditions).   \n\u2022 The method for calculating the error bars should be explained (closed form formula, call to a library function, bootstrap, etc.)   \n\u2022 The assumptions made should be given (e.g., Normally distributed errors).   \n\u2022 It should be clear whether the error bar is the standard deviation or the standard error of the mean.   \n\u2022 It is OK to report 1-sigma error bars, but one should state it. The authors should preferably report a 2-sigma error bar than state that they have a $96\\%$ CI, if the hypothesis of Normality of errors is not verified.   \n\u2022 For asymmetric distributions, the authors should be careful not to show in tables or figures symmetric error bars that would yield results that are out of range (e.g. negative error rates).   \n\u2022 If error bars are reported in tables or plots, The authors should explain in the text how they were calculated and reference the corresponding figures or tables in the text. ", "page_idx": 29}, {"type": "text", "text": "8. Experiments Compute Resources ", "text_level": 1, "page_idx": 29}, {"type": "text", "text": "Question: For each experiment, does the paper provide sufficient information on the computer resources (type of compute workers, memory, time of execution) needed to reproduce the experiments? ", "page_idx": 29}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 29}, {"type": "text", "text": "Justification: please refer to Appendix D ", "page_idx": 29}, {"type": "text", "text": "Guidelines: ", "page_idx": 29}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 The paper should indicate the type of compute workers CPU or GPU, internal cluster, or cloud provider, including relevant memory and storage.   \n\u2022 The paper should provide the amount of compute required for each of the individual experimental runs as well as estimate the total compute.   \n\u2022 The paper should disclose whether the full research project required more compute than the experiments reported in the paper (e.g., preliminary or failed experiments that didn\u2019t make it into the paper). ", "page_idx": 29}, {"type": "text", "text": "9. Code Of Ethics ", "text_level": 1, "page_idx": 29}, {"type": "text", "text": "Question: Does the research conducted in the paper conform, in every respect, with the NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines? ", "page_idx": 29}, {"type": "text", "text": "Answer: [Yes]   \nJustification: Not applicable   \nGuidelines:   \n\u2022 The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics.   \n\u2022 If the authors answer No, they should explain the special circumstances that require a deviation from the Code of Ethics.   \n\u2022 The authors should make sure to preserve anonymity (e.g., if there is a special consideration due to laws or regulations in their jurisdiction). ", "page_idx": 29}, {"type": "text", "text": "", "page_idx": 30}, {"type": "text", "text": "10. Broader Impacts ", "text_level": 1, "page_idx": 30}, {"type": "text", "text": "Question: Does the paper discuss both potential positive societal impacts and negative societal impacts of the work performed? ", "page_idx": 30}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 30}, {"type": "text", "text": "Justification: communication savings ", "page_idx": 30}, {"type": "text", "text": "Guidelines: ", "page_idx": 30}, {"type": "text", "text": "\u2022 The answer NA means that there is no societal impact of the work performed.   \n\u2022 If the authors answer NA or No, they should explain why their work has no societal impact or why the paper does not address societal impact.   \n\u2022 Examples of negative societal impacts include potential malicious or unintended uses (e.g., disinformation, generating fake profiles, surveillance), fairness considerations (e.g., deployment of technologies that could make decisions that unfairly impact specific groups), privacy considerations, and security considerations.   \n\u2022 The conference expects that many papers will be foundational research and not tied to particular applications, let alone deployments. However, if there is a direct path to any negative applications, the authors should point it out. For example, it is legitimate to point out that an improvement in the quality of generative models could be used to generate deepfakes for disinformation. On the other hand, it is not needed to point out that a generic algorithm for optimizing neural networks could enable people to train models that generate Deepfakes faster.   \n\u2022 The authors should consider possible harms that could arise when the technology is being used as intended and functioning correctly, harms that could arise when the technology is being used as intended but gives incorrect results, and harms following from (intentional or unintentional) misuse of the technology.   \n\u2022 If there are negative societal impacts, the authors could also discuss possible mitigation strategies (e.g., gated release of models, providing defenses in addition to attacks, mechanisms for monitoring misuse, mechanisms to monitor how a system learns from feedback over time, improving the efficiency and accessibility of ML). ", "page_idx": 30}, {"type": "text", "text": "11. Safeguards ", "text_level": 1, "page_idx": 30}, {"type": "text", "text": "Question: Does the paper describe safeguards that have been put in place for responsible release of data or models that have a high risk for misuse (e.g., pretrained language models, image generators, or scraped datasets)? ", "page_idx": 30}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 30}, {"type": "text", "text": "Justification: Not applicable ", "page_idx": 30}, {"type": "text", "text": "Guidelines: ", "page_idx": 30}, {"type": "text", "text": "\u2022 The answer NA means that the paper poses no such risks.   \n\u2022 Released models that have a high risk for misuse or dual-use should be released with necessary safeguards to allow for controlled use of the model, for example by requiring that users adhere to usage guidelines or restrictions to access the model or implementing safety filters.   \n\u2022 Datasets that have been scraped from the Internet could pose safety risks. The authors should describe how they avoided releasing unsafe images.   \n\u2022 We recognize that providing effective safeguards is challenging, and many papers do not require this, but we encourage authors to take this into account and make a best faith effort. ", "page_idx": 30}, {"type": "text", "text": "12. Licenses for existing assets ", "page_idx": 30}, {"type": "text", "text": "Question: Are the creators or original owners of assets (e.g., code, data, models), used in the paper, properly credited and are the license and terms of use explicitly mentioned and properly respected? ", "page_idx": 31}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 31}, {"type": "text", "text": "Justification: citations are properly added Guidelines: ", "page_idx": 31}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not use existing assets.   \n\u2022 The authors should cite the original paper that produced the code package or dataset.   \n\u2022 The authors should state which version of the asset is used and, if possible, include a URL.   \n\u2022 The name of the license (e.g., CC-BY 4.0) should be included for each asset.   \n\u2022 For scraped data from a particular source (e.g., website), the copyright and terms of service of that source should be provided.   \n\u2022 If assets are released, the license, copyright information, and terms of use in the package should be provided. For popular datasets, paperswithcode.com/datasets has curated licenses for some datasets. Their licensing guide can help determine the license of a dataset.   \n\u2022 For existing datasets that are re-packaged, both the original license and the license of the derived asset (if it has changed) should be provided.   \n\u2022 If this information is not available online, the authors are encouraged to reach out to the asset\u2019s creators. ", "page_idx": 31}, {"type": "text", "text": "13. New Assets ", "text_level": 1, "page_idx": 31}, {"type": "text", "text": "Question: Are new assets introduced in the paper well documented and is the documentation provided alongside the assets? ", "page_idx": 31}, {"type": "text", "text": "Answer: [NA]   \nJustification: Not applicable   \nGuidelines:   \n\u2022 The answer NA means that the paper does not release new assets.   \n\u2022 Researchers should communicate the details of the dataset/code/model as part of their submissions via structured templates. This includes details about training, license, limitations, etc.   \n\u2022 The paper should discuss whether and how consent was obtained from people whose asset is used.   \n\u2022 At submission time, remember to anonymize your assets (if applicable). You can either create an anonymized URL or include an anonymized zip file. ", "page_idx": 31}, {"type": "text", "text": "", "page_idx": 31}, {"type": "text", "text": "14. Crowdsourcing and Research with Human Subjects ", "text_level": 1, "page_idx": 31}, {"type": "text", "text": "Question: For crowdsourcing experiments and research with human subjects, does the paper include the full text of instructions given to participants and screenshots, if applicable, as well as details about compensation (if any)? ", "page_idx": 31}, {"type": "text", "text": "Answer: [NA] Justification: Not applicable ", "page_idx": 31}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u2022 Including this information in the supplemental material is fine, but if the main contribution of the paper involves human subjects, then as much detail as possible should be included in the main paper.   \n\u2022 According to the NeurIPS Code of Ethics, workers involved in data collection, curation, or other labor should be paid at least the minimum wage in the country of the data collector. ", "page_idx": 31}, {"type": "text", "text": "15. Institutional Review Board (IRB) Approvals or Equivalent for Research with Human Subjects ", "page_idx": 31}, {"type": "text", "text": "Question: Does the paper describe potential risks incurred by study participants, whether such risks were disclosed to the subjects, and whether Institutional Review Board (IRB) approvals (or an equivalent approval/review based on the requirements of your country or institution) were obtained? ", "page_idx": 32}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 32}, {"type": "text", "text": "Justification: Not applicable Guidelines: ", "page_idx": 32}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u2022 Depending on the country in which research is conducted, IRB approval (or equivalent) may be required for any human subjects research. If you obtained IRB approval, you should clearly state this in the paper.   \n\u2022 We recognize that the procedures for this may vary significantly between institutions and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the guidelines for their institution.   \n\u2022 For initial submissions, do not include any information that would break anonymity (if applicable), such as the institution conducting the review. ", "page_idx": 32}]