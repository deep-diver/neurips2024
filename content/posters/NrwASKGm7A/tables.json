[{"figure_path": "NrwASKGm7A/tables/tables_4_1.jpg", "caption": "Table 1: The dataset size for ANAH-v2 in different stages, including the number of topics, model responses, and annotated sentences.", "description": "This table shows the dataset size used in each of the three stages of the ANAH-v2 iterative self-training framework.  It details the number of topics, model responses (answers from LLMs), and the total number of sentences annotated for each stage. This illustrates the growth of the dataset throughout the iterative process.", "section": "3.3 Multi-dimensional Data Scaling"}, {"figure_path": "NrwASKGm7A/tables/tables_5_1.jpg", "caption": "Table 2: Evaluation results for GPT4, ANAH, and ANAH-v2 at each stage, where \u201cR\u201d and \u201cBERT\u201d, refer to \"RougeL\" and \"BERTScore\", respectively.", "description": "This table presents the performance comparison of three different models: GPT-4, ANAH, and ANAH-v2 across three stages of development.  The metrics used are F1 score, Accuracy, RougeL (R), and BERTScore (BERT).  Higher scores in F1, Accuracy, R, and BERT indicate better performance.  The table shows that the performance of ANAH-v2 improves significantly across stages, eventually surpassing GPT-4 in F1 score and Accuracy.", "section": "4.2 Overall Results"}, {"figure_path": "NrwASKGm7A/tables/tables_6_1.jpg", "caption": "Table 3: Ablation study for annotators in different self-consistency settings. Here, for Infer Strategy, \"w/ SC\" means inference with self-consistency, which is the default setting of ANAH-v2. \"w/o SC\" means inference without self-consistency, where the annotator generates only once for each input. For Train Data, \"w/ SC\" means the training data from the previous stage is generated by self-consistency, where the default setting of ANAH-v2, while \"w/o SC\" means the train data is generated without self-consistency.", "description": "This table presents the ablation study on the impact of self-consistency in both inference and training phases of the ANAH-v2 model across three stages.  It compares the performance metrics (F1, ACC, R, BERT) when self-consistency is used versus when it is not, showing its effect on the accuracy and stability of hallucination annotation.", "section": "4.3 Ablation Studies"}, {"figure_path": "NrwASKGm7A/tables/tables_6_2.jpg", "caption": "Table 4: Ablation study for annotators trained with progressive and non-progressive data scaling. Here, \"progressive\" means that the training data is progressively annotated by the continually updated annotator, which is the default setting of ANAH-v2. \u201cnon-progressive\u201d means that the training data scaling only leverages annotations generated by the basic annotator from Stage 1.", "description": "This table presents the ablation study comparing the performance of annotators trained with two different data scaling strategies: progressive and non-progressive. The progressive strategy uses a continually updated annotator to annotate the training data, while the non-progressive strategy uses only the basic annotator from the first stage. The results show that the progressive approach leads to better performance.", "section": "4.3 Ablation Studies"}, {"figure_path": "NrwASKGm7A/tables/tables_7_1.jpg", "caption": "Table 5: Ablation study for annotator in different train strategy settings. Here, \u201cmix\u201d means that the new data generated in the current iteration is mixed with the old data to train a new annotator, which is the default setting of ANAH-v2. \u201cfurther\u201d means that only the new data is used to further train the annotator from the previous stage.", "description": "This table presents the ablation study on different training strategies for the hallucination annotator. The table compares two training strategies: 'mix', where new and old data are mixed for training, and 'further', where only new data is used for further training of the annotator from the previous stage. The results for each stage (Stage 2 and Stage 3) are presented separately and demonstrate that the 'mix' strategy consistently outperforms the 'further' strategy in terms of F1 score, accuracy, RougeL score, and BERTScore.", "section": "4.3 Ablation Studies"}, {"figure_path": "NrwASKGm7A/tables/tables_7_2.jpg", "caption": "Table 6: Annotator accuracy using different models and methods on HaluEval and HalluQA.", "description": "This table presents the zero-shot accuracy results of different models on two benchmark datasets: HaluEval and HalluQA.  The models include GPT4, GPT3.5, Starling-7B, and the ANAH-v2 annotator at different stages of training.  The methods used are zero-shot inference and WiKiChat for comparison, showcasing the performance of ANAH-v2 compared to existing state-of-the-art methods.  The ACC\u2191 column indicates the accuracy of the models.  Higher accuracy signifies better performance in identifying hallucinations.", "section": "4.4 Generalization Capability Analysis"}, {"figure_path": "NrwASKGm7A/tables/tables_8_1.jpg", "caption": "Table 7: Hallucination rate of open-source models according to ANAH-v2 annotator and dataset.", "description": "This table presents the hallucination rates of various open-source large language models (LLMs) evaluated using the ANAH-v2 annotator and dataset.  The results are categorized by model, setting (with or without reference documents), and domain (overall, person, event, thing, location), further broken down by language (Chinese and English).  It shows the performance of each model in different scenarios and aspects, highlighting variations based on the access to reference material and the type of topic.", "section": "4.4 Generalization Capability Analysis"}, {"figure_path": "NrwASKGm7A/tables/tables_8_2.jpg", "caption": "Table 8: Evaluation results for hallucination mitigation with LLaMA2-7B and InternLM2-7B on HaluEval. Here, \"baseline\" means the direct generation results, and \u201cre-rank\u201d means the results with our re-ranking mitigation method.", "description": "This table presents the results of a hallucination mitigation experiment using two different language models, LLaMA2-7B and InternLM2-7B.  The experiment compares the performance of the models before and after applying a re-ranking mitigation strategy. The metrics used for evaluation include QuestEval, NLI, BERTScore, and RougeL, all of which measure different aspects of language model quality and relevance to the reference content.  Higher scores generally indicate better performance. The results show that the re-ranking method leads to improvements in all four metrics for both models, suggesting its effectiveness in reducing hallucinations.", "section": "Hallucination Mitigation"}, {"figure_path": "NrwASKGm7A/tables/tables_14_1.jpg", "caption": "Table A1: The score assessing the consistency of generated reference points with the source documents.", "description": "This table presents the results of an LLM-based evaluation designed to assess the consistency of generated reference points with the source documents.  The evaluation aims to determine whether the reference points produced by the model accurately reflect the information present in the source document, rather than simply relying on metrics like ROUGE-L or BERTScore which measure similarity without necessarily validating factual accuracy. The table shows that the reliability of the generated reference points progressively improves with each stage of the iterative self-training framework.", "section": "4.3 Ablation Studies"}, {"figure_path": "NrwASKGm7A/tables/tables_20_1.jpg", "caption": "Table 7: Hallucination rate of open-source models according to ANAH-v2 annotator and dataset.", "description": "This table presents the hallucination rates of various open-source LLMs evaluated using the ANAH-v2 annotator and dataset.  The results are broken down by model, setting (with or without reference documents), overall hallucination rate, and hallucination rates for four specific categories (Person, Event, Thing, Location).  Both English (EN) and Chinese (ZH) language results are included for each category, providing a comprehensive view of LLM performance across different languages and topic domains.", "section": "4.4 Generalization Capability Analysis"}, {"figure_path": "NrwASKGm7A/tables/tables_21_1.jpg", "caption": "Table 7: Hallucination rate of open-source models according to ANAH-v2 annotator and dataset.", "description": "This table presents the hallucination rates of various open-source large language models (LLMs) evaluated using the ANAH-v2 annotator.  The results are broken down by language (ZH for Chinese, EN for English), model, whether a reference document was used during generation (w/ Ref or w/o Ref), and four topic categories (Person, Event, Thing, Location).  Higher percentages indicate higher hallucination rates.", "section": "4.4 Generalization Capability Analysis"}]