[{"figure_path": "DUHX779C5q/figures/figures_3_1.jpg", "caption": "Figure 1: Illustrations of our proposed computational pipeline, LangGround. The framework consists of three modules: 1) collecting grounded communication from LLM agents, 2) aligning MARL communication with language grounds, 2) translating aligned communication vectors into natural language messages via cosine similarity matching.", "description": "This figure illustrates the LangGround computational pipeline, which comprises three modules. The first module collects grounded communication from LLM agents. The second module aligns MARL communication with these language grounds. The third module translates aligned communication vectors into human-interpretable natural language messages using cosine similarity matching.  The diagram visually depicts how these modules work together during both training and ad-hoc teamwork scenarios.", "section": "4 Language Grounded Multi-agent Communication"}, {"figure_path": "DUHX779C5q/figures/figures_5_1.jpg", "caption": "Figure 2: Learning curves of LangGround in comparison with baseline methods. The y-axis is task performance measured by the episode length until task completion, which is lower the better. The x-axis is the number of training timestamps. Shaded areas are standard errors over three random seeds.", "description": "This figure shows the learning curves for LangGround and several baseline methods across three different multi-agent collaborative tasks: Predator Prey (vision=1), Predator Prey (vision=0), and Urban Search and Rescue (USAR).  The y-axis represents the episode length, indicating the number of steps taken to complete the task (lower is better). The x-axis shows the number of training timestamps.  The shaded regions represent standard errors across three independent runs with different random seeds.  The figure allows for a comparison of LangGround's performance against established methods in terms of learning speed and final task completion efficiency.", "section": "5 Experiments"}, {"figure_path": "DUHX779C5q/figures/figures_6_1.jpg", "caption": "Figure 3: Learned communication embedding space. Communication vectors between agents in ppvo are visualized with t-SNE and clustered with DBSCAN. Two semantically meaningful clusters are identified as examples, each corresponding to a specific agent observation. We also present the most similar reference message from dataset D to illustrate the alignment between the agent communication space and the human language embedding space.", "description": "This figure visualizes the learned communication embedding space of agents in the Predator-Prey environment (ppvo variant).  t-SNE is used to reduce dimensionality for visualization, and DBSCAN is used for clustering. Two clusters representing distinct agent observations are highlighted along with the corresponding natural language messages from the dataset D showing the alignment between the agent communication and the human language embedding space.", "section": "6.2 Aligned communication space"}, {"figure_path": "DUHX779C5q/figures/figures_7_1.jpg", "caption": "Figure 2: Learning curves of LangGround in comparison with baseline methods. The y-axis is task performance measured by the episode length until task completion, which is lower the better. The x-axis is the number of training timestamps. Shaded areas are standard errors over three random seeds.", "description": "This figure displays the learning curves for LangGround and four baseline methods (IC3Net, aeComm, VQ-VIB, protoComm, and noComm) across three different multi-agent collaborative tasks: Predator Prey (vision=1), Predator Prey (vision=0), and Urban Search and Rescue (USAR).  The y-axis represents task performance, specifically the episode length (number of timesteps) needed to complete the task; lower values indicate better performance. The x-axis shows the number of training timestamps. Shaded regions represent standard errors across three independent runs, providing a measure of the variability in performance.", "section": "5 Experiments"}, {"figure_path": "DUHX779C5q/figures/figures_15_1.jpg", "caption": "Figure 1: Illustrations of our proposed computational pipeline, LangGround. The framework consists of three modules: 1) collecting grounded communication from LLM agents, 2) aligning MARL communication with language grounds, 2) translating aligned communication vectors into natural language messages via cosine similarity matching.", "description": "This figure illustrates the LangGround pipeline, which consists of three main modules. The first module uses Large Language Models (LLMs) to generate synthetic data of human-like communication in collaborative tasks.  The second module aligns the communication learned by multi-agent reinforcement learning (MARL) agents with the communication from the LLM agents. The third module translates the aligned communication vectors (from MARL) into natural language messages using cosine similarity.", "section": "4 Language Grounded Multi-agent Communication"}, {"figure_path": "DUHX779C5q/figures/figures_18_1.jpg", "caption": "Figure 2: Learning curves of LangGround in comparison with baseline methods. The y-axis is task performance measured by the episode length until task completion, which is lower the better. The x-axis is the number of training timestamps. Shaded areas are standard errors over three random seeds.", "description": "This figure compares the learning curves of the proposed LangGround method against several baseline methods (IC3Net, aeComm, VQ-VIB, protoComm, and noComm) across three different multi-agent collaborative tasks: Predator Prey (with vision=1 and vision=0), and Urban Search and Rescue (USAR).  The y-axis represents the episode length, indicating the number of steps taken to complete the task (lower is better), while the x-axis shows the number of training timestamps. Shaded regions represent the standard error across three different random seeds, providing a measure of variability in the results. The figure demonstrates LangGround's performance relative to the baseline methods across various tasks and its convergence properties.", "section": "5 Experiments"}]