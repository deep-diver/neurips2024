[{"type": "text", "text": "User-Creator Feature Polarization in Recommender Systems with Dual Influence ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Tao Lin\u2217 Harvard University tlin@g.harvard.edu ", "page_idx": 0}, {"type": "text", "text": "Kun Jin\u2217   \nGoogle   \nkunjin@google.com ", "page_idx": 0}, {"type": "text", "text": "Andrew Estornell ByteDance andrew.estornell@bytedance.com ", "page_idx": 0}, {"type": "text", "text": "Xiaoying Zhang ByteDance zhangxiaoying.xy@bytedance.com ", "page_idx": 0}, {"type": "text", "text": "Yiling Chen Harvard University yiling@seas.harvard.edu ", "page_idx": 0}, {"type": "text", "text": "Yang Liu University of California, Santa Cruz yangliu@ucsc.edu ", "page_idx": 0}, {"type": "text", "text": "Abstract ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Recommender systems serve the dual purpose of presenting relevant content to users and helping content creators reach their target audience. The dual nature of these systems naturally influences both users and creators: users\u2019 preferences are affected by the items they are recommended, while creators may be incentivized to alter their content to attract more users. We define a model, called user-creator feature dynamics, to capture the dual influence of recommender systems. We prove that a recommender system with dual influence is guaranteed to polarize, causing diversity loss in the system. We then investigate, both theoretically and empirically, approaches for mitigating polarization and promoting diversity in recommender systems. Unexpectedly, we find that common diversity-promoting approaches do not work in the presence of dual influence, while relevancy-optimizing methods like top- $k$ truncation can prevent polarization and improve diversity of the system. ", "page_idx": 0}, {"type": "text", "text": "1 Introduction ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "From restaurant selection, video watching, to apartment renting, recommender systems play a pivotal role across a plethora of real-world domains. These systems match users with content they like, and help creators (those producing the content) identify their target audiences. Nevertheless, behind such success, concerns have emerged regarding possible harmful outcomes of recommender systems, in particular, filter bubbles [32, 5] and polarization [36] \u2013 outcomes with insufficient recommendation diversity and creation diversity. Recommendation diversity, meaning the diversity of the contents recommended to a user, is key to users\u2019 engagement and retention on the platform. Meanwhile, creation diversity, meaning the variety of content created on the platform, is a determinant of the platform\u2019s long-term health. In extreme cases, insufficient creation diversity can lead to consensus or polarization, where the latter can cause confilct and hatred, diminish people\u2019s mutual understanding, and cause societal crises. Therefore, from both business and social responsibility perspectives, championing and improving diversity in recommender systems is equally important as optimizing recommendation relevancy. ", "page_idx": 0}, {"type": "text", "text": "There is increasing emphasis in academia and industry on investigating and improving the diversity of recommender systems, combating filter bubbles and polarization. Popular diversity-boosting approaches include applying post-processing procedures such as re-ranking [11, 47] and setting diversity-aware objectives in addition to relevance maximization [38, 44, 22, 39, 12]. These methods aim to increase the recommendation diversity for users. Assuming that the contents on the platform are static, these methods have been shown to bring diversity gain to the system. ", "page_idx": 1}, {"type": "text", "text": "However, an important aspect that is overlooked in the aforementioned approaches is that: users and contents on a recommendation platform are not static entities \u2013 they can be influenced by the recommendation made by the system. In content creation platforms like YouTube, TikTok, and Twitter, recommendations naturally affect both content users and content creators. It is well known that the exposure to recommended items can shift a user\u2019s preference [24, 26, 14]. On the other hand, the creators have the incentive to change their creation styles constantly to attract their audience better (and to make more profits from the platform) [15, 20, 23]. While the effects of recommendation on either users or creators have been investigated separately, to our knowledge no previous work considers both effects. The dual influence of recommendation on users and creators causes complicated dynamics where users and creators interact and their preferences evolve together. Such evolution might exacerbate fliter bubble and polarization effects. Whether the aforementioned diversity-boosting approaches still work in a dynamic environment with dual influence is questionable. ", "page_idx": 1}, {"type": "text", "text": "Our contributions The first contribution of our work is to define a novel, natural dynamics model that captures the dual influence of a recommender system on users and creators, which we call user-creator feature dynamics (Section 2). We leverage the users\u2019 and items\u2019/creators\u2019 embedding vectors to represent their preferences and creation styles, and use cosine similarity to characterize the relevance of creations and users\u2019 interests (which is common in the recommender system literature and practice). This model allows us to formally reason about the impact of various design choices on the long-term diversity of a recommender system with dual influence. ", "page_idx": 1}, {"type": "text", "text": "Our second contribution is to demonstrate that, under realistic conditions, the user-creator feature dynamics of any recommender system with dual influence must unavoidably converge to polarization (Section 3), i.e., the preferences of users and the contents of creators will become tightly clustered into two opposite groups, significantly reducing the diversity of the system. We demonstrate that this phenomenon still occurs even after applying diversity-boosting interventions to the system. ", "page_idx": 1}, {"type": "text", "text": "Then, (in Section 4) we investigate some real-world designs of recommendation algorithms in order to look for techniques that mitigate polarization. Interestingly, we find that some common efficiencyimproving methods, such as top- $\\cdot k$ truncation, can both prevent the system from polarization and improve the creation diversity. We also provide empirical results (Section 5) on both synthetic and real-world (MovieLens) data. As predicted by our theory, we find that systems with dual influence more easily converge to polarization under diversity-boosting designs, while efficiency-oriented and relevance-optimizing designs can in fact improve the long-term diversity of the system. This could explain why polarization does not always happen in reality. Section 6 concludes. ", "page_idx": 1}, {"type": "text", "text": "1.1 Related Work ", "text_level": 1, "page_idx": 1}, {"type": "text", "text": "Diversity in recommendations Diversity, fliter bubbles, and polarization in recommendations have been important research topics in recent years, and they are closely related concepts with different focuses. On the one hand, filter bubbles are frequently defined as decreasing recommendation diversity over time [5], which describes both the process and the outcome of insufficiently diverse recommendations. On the other hand, polarization describes the negative outcome of insufficient mutual understanding between people [36]. In content platforms, an example of polarization is people creating content with strong agreement or disagreement with other content under the same topic, e.g., political opinions. To combat these negative outcomes, previous works propose diversity-boosting approaches including re-ranking [11, 47] and diversity-aware objective optimization [38, 44, 22, 39, 12, 45]. Despite having positive effects in situations where user preferences and creation styles are fixed, these approaches overlooked the dynamic nature of recommender systems and our work shows that certain approaches will make long-term outcomes worse under the dual influence. ", "page_idx": 1}, {"type": "text", "text": "Opinion dynamics Opinion dynamics study the effect of people exchanging opinions with others on social networks [37, 17, 29, 4]. Our model of a recommender system with dual influence on users and creators resembles a bipartite social network, and our conclusion that the system converges to polarization is conceptually similar to people reaching consensus on social networks [1, 10, 31, 46]. However, the technique we use to prove our conclusion (absorbing Markov chain) significantly differs from the main technique (stability of ODE) in the mentioned works. ", "page_idx": 1}, {"type": "text", "text": "", "page_idx": 2}, {"type": "text", "text": "Performative effects of recommender systems The phenomenon that predictive systems like recommender systems can impact the individuals interacting with those systems (e.g., users and creators) is related to the literature of performative prediction [34, 18]. These impacts can be direct, such as individuals ostensibly modifying their features in order to obtain more desirable outcomes [27]. Prior works on the performative effects of recommender systems (e.g., [7, 24, 14, 41, 15, 42, 35, 20, 3, 43, 2, 23]) only consider one-sided impact, either on users or on creators. Differing from them, our work studies two-sided impacts, i.e., on both users and creators. We provide a table to compare our work with previous works in Appendix A. ", "page_idx": 2}, {"type": "text", "text": "2 Model: User-Creator Feature Dynamics ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "We define a dynamics model for user preferences and content/creator features in a recommender system. Let $\\bar{U^{t}}=[\\mathbf{u}_{j}^{t}]_{j=1}^{m}=[\\mathbf{u}_{1}^{t},\\dots,\\bar{\\mathbf{u}}_{m}^{t}]\\in\\mathbb{R}^{d\\times m}$ be a population of $m$ users and $V^{t}=[{\\pmb v}_{i}^{t}]_{i=1}^{n}=$ $[\\pmb{v}_{1}^{t},\\dots,\\pmb{v}_{n}^{t}]\\ \\in\\ \\mathbb{R}^{d\\times\\bar{n}}$ be a population of $n$ creators at time $t$ , where each vector $\\pmb{u}_{j}^{t},\\pmb{v}_{i}^{t}\\,\\in\\,\\mathbb{S}^{d-1}$ represent the preference/feature vector of each user and creator respectively, assumed to be on the unit sphere $\\mathbb{S}^{\\hat{d}-1}$ with $\\ell_{2}$ -norm. Then $(U^{t},V^{t})$ denotes the state of the dynamics at time $t$ . The dynamics evolve as follows at each time step $t\\geq0$ : ", "page_idx": 2}, {"type": "text", "text": "1) Recommendation: Each user $j\\in[m]$ is recommended a creator, where creator $i\\in[n]$ is chosen with a probability ", "page_idx": 2}, {"type": "equation", "text": "$$\np_{i j}^{t}=p_{i j}^{t}(U^{t},V^{t}).\n$$", "text_format": "latex", "page_idx": 2}, {"type": "text", "text": "While we allow a wide array of different functions $p_{i j}^{t}(\\cdot)$ , a common example of such functions is the so-called softmax function: ", "page_idx": 2}, {"type": "equation", "text": "$$\np_{i j}^{t}=\\mathrm{softmax}(\\pmb{u}_{j}^{t},\\pmb{V}^{t};\\beta)=\\frac{\\exp(\\beta\\langle\\pmb{u}_{j}^{t},\\pmb{v}_{i}^{t}\\rangle)}{\\sum_{i=1}^{n}\\exp(\\beta\\langle\\pmb{u}_{j}^{t},\\pmb{v}_{i}^{t}\\rangle)}.\n$$", "text_format": "latex", "page_idx": 2}, {"type": "text", "text": "A larger $\\beta$ means that the recommendation is more sensitive to the relevance of a creator to a user, measured by $\\langle\\boldsymbol{u}_{j}^{t},\\boldsymbol{v}_{i}^{t}\\rangle$ . ", "page_idx": 2}, {"type": "text", "text": "2) User update: After recommendation, each user $j\\in[m]$ updates their feature vector $\\pmb{u}_{j}^{t}$ , based on which creator, say $i_{j}^{t}$ , was recommended to them: ", "page_idx": 2}, {"type": "equation", "text": "$$\n\\pmb{u}_{j}^{t+1}=\\mathcal{P}\\big(\\pmb{u}_{j}^{t}+\\eta_{u}f(\\pmb{v}_{i_{j}^{t}}^{t},\\pmb{u}_{j}^{t})\\pmb{v}_{i_{j}^{t}}^{t}\\big).\n$$", "text_format": "latex", "page_idx": 2}, {"type": "text", "text": "Here, $\\eta_{u}\\in[0,1]$ is a parameter controlling the rate of update, $f(v_{i},u_{j})$ is a function that quantifies the impact of creator i\u2019s content on user j (discussed in detail later), and P(x) = \u2225xx\u22252 is the projection back onto the unit sphere. Our user update model generalizes [14], which considers $\\mathbf{\\bar{\\boldsymbol{u}}}_{j}^{t+1}=\\mathcal{P}(\\mathbf{\\boldsymbol{u}}_{j}^{t}+\\eta_{u}\\langle\\mathbf{\\boldsymbol{v}}_{i_{j}^{t}}^{t},\\mathbf{\\boldsymbol{u}}_{j}^{t}\\rangle\\mathbf{\\boldsymbol{v}}_{i_{j}^{t}}^{t}\\bar{\\bf{\\boldsymbol{\\)}}}$ , by replacing the inner product with a general function $f$ . ", "page_idx": 2}, {"type": "text", "text": "3) Creator update: Creators also update their feature vectors based on which users are recommended their content. For each creator $i\\in\\bar{[}n]$ , let $J_{i}^{t}=\\{j:i_{j}^{t}=i\\}$ be the set of users being recommended creator $i$ , then $\\pmb{v}_{i}^{t}$ is updated by: ", "page_idx": 2}, {"type": "equation", "text": "$$\n\\boldsymbol{v}_{i}^{t+1}=\\mathcal{P}\\Big(\\boldsymbol{v}_{i}^{t}+\\frac{\\eta_{c}}{\\vert\\boldsymbol{J}_{i}^{t}\\vert}\\sum_{j\\in J_{i}^{t}}g(\\boldsymbol{u}_{j}^{t},\\boldsymbol{v}_{i}^{t})\\boldsymbol{u}_{j}^{t}\\Big),\n$$", "text_format": "latex", "page_idx": 2}, {"type": "text", "text": "where $\\eta_{c}\\,\\in\\,[0,1]$ is a parameter controlling the rate of update, and $g(\\pmb{u}_{j},\\pmb{v}_{i})$ is a function that quantifies the impact of user $j$ on creator $i$ . ", "page_idx": 2}, {"type": "text", "text": "Impact functions $f$ and $g$ Our results apply to any impact functions $f$ and $g$ that satisfy the   \nfollowing natural assumptions. First, $f(v_{i},u_{j})$ and the inner product $\\langle\\pmb{v}_{i},\\pmb{u}_{j}\\rangle$ have the same sign: $\\left\\{{\\underset{<}{>}}\\right.{\\mathfrak{o}}$ if $\\langle{\\pmb v}_{i},{\\pmb u}_{j}\\rangle>0$   \n$f(v_{i},u_{j})$ is if $\\langle{\\pmb v}_{i},{\\pmb u}_{j}\\rangle\\,<\\,0$ This means that if a user likes the content $(\\langle\\boldsymbol{v}_{i}^{t},\\boldsymbol{u}_{j}^{t}\\rangle>0)$ ), then the = 0 if \u27e8vi, uj\u27e9= 0. ", "page_idx": 2}, {"type": "text", "text": "user vector $\\pmb{u}_{j}^{t}$ will be updated towards the direction of the creator vector $\\pmb{v}_{j}^{t}$ . If the user dislikes the content $(\\langle\\boldsymbol{v}_{i}^{t},\\bar{\\boldsymbol{u}}_{j}^{t}\\rangle<0)$ , then the user vector $\\pmb{u}_{j}^{t}$ will move away from $\\pmb{v}_{j}^{t}$ . Such \u201cbiased assimilation\u201d user behavior is well documented in the literature [14]. Further, we assume upper and lower bounds on $\\vert f\\vert$ : ", "page_idx": 3}, {"type": "text", "text": "The lower bound $|f(\\pmb{v}_{i},\\pmb{u}_{j})|\\;\\geq\\;L_{f}$ means that the exposure to an item that a user likes or dislikes always has some non-negligible impact on the user\u2019s preference. For example, $f({\\pmb v}_{i},{\\pmb u}_{j})=$ $\\mathrm{sign}(\\langle v_{i},\\dot{u}_{j}\\rangle)a+b\\langle v_{i},{\\pmb u}_{j}\\rangle$ satisfies both assumptions when $L_{f}=a>0$ and $b\\geq0$ . ", "page_idx": 3}, {"type": "text", "text": "$\\left\\{{\\underset{<}{>}}\\ 0\\right.$ if $\\langle\\pmb{u}_{j},\\pmb{v}_{i}\\rangle>0$ For $g$ , likewise assume that its sign is the same as $\\langle\\pmb{u}_{j},\\pmb{v}_{i}\\rangle\\colon g(\\pmb{u}_{j},\\pmb{v}_{i})$ is if $\\langle\\pmb{u}_{j},\\pmb{v}_{i}\\rangle<0$ Intuitively, = 0 if $\\langle\\pmb{u}_{j},\\pmb{v}_{i}\\rangle=0$ . this captures the incentive of a creator who aims to maximize the average ratings from users who are recommended their items. On video platforms for example, if the creators are rewarded based on the average rating of their videos, they will try to reinforce their creation styles based on the users who give positive feedback $(\\langle{\\pmb u}_{j},{\\pmb v}_{i}\\rangle>0)$ so that their creations are more likely to be recommended to those users. Meanwhile, the creators will also change their creation styles based on negative feedback $(\\langle{\\pmb u}_{j},{\\pmb v}_{i}\\rangle<0)$ , but in the opposite direction of the negative-feedback users\u2019 interests, so that their creations are less likely to be recommended to those users. Taking both scenarios into account, the creator moves towards the weighted average of user preferences $\\textstyle\\sum_{j\\in J_{i}^{t}}g(\\pmb{u}_{j}^{t},\\pmb{v}_{i}^{t})\\pmb{u}_{j}^{t}$ , which is captured by our update rule (4). A particular example of $g$ is the sign function $g(\\pmb{u}_{j},\\pmb{v}_{i})=$ $\\mathrm{sign}(\\langle\\pmb{u}_{j},\\bar{\\pmb{v}_{i}}\\rangle)\\,\\in\\,\\{-1,0,\\bar{1}\\}$ . We will only consider the sign function $g$ in order to simplify the theoretical presentation. We believe that all our results can be generalized to other $g$ functions satisfying similar conditions as $f$ ; the details are left as future work. ", "page_idx": 3}, {"type": "text", "text": "3 Unavoidable Polarization ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "Having defined the user-creator feature dynamics in a recommender system with dual influence, we now theoretically study how such dynamics evolve. Our main result is: if every creator can be recommended to every user with some non-zero probability, then the dynamics must eventually polarize. ", "page_idx": 3}, {"type": "text", "text": "Definition 3.1 (consensus and bi-polarization). Let $R>0$ . The dynamics $(U^{t},V^{t})$ is said to reach: ", "page_idx": 3}, {"type": "text", "text": "\u2022 $R$ -consensus if there exists a vector $\\boldsymbol{c}\\in\\mathbb{R}^{d}$ such that every feature vector is $R$ -close to $^c$ : $\\forall\\boldsymbol{u}_{j}^{t}$ , $\\|\\pmb{u}_{j}^{t}-\\pmb{c}\\|_{2}\\leq R$ and $\\forall{\\pmb v}_{i}^{t}$ , $\\|\\pmb{v}_{i}^{t}-\\pmb{c}\\|_{2}\\leq R.$ . \u2022 $R$ -bi-polarization if there exists a vector $c\\in\\mathbb{R}^{d}$ such that every feature vector is $R$ -close to $+c$ $o r-\\bar{c};\\forall\\pmb{u}_{j}^{t}.$ , $\\|\\pmb{u}_{j}^{t}-\\pmb{c}\\|_{2}\\leq R$ or $\\|\\pmb{u}_{j}^{t}+\\pmb{c}\\|_{2}\\leq R,$ , and $\\forall{\\pmb v}_{i}^{t}$ , $\\|\\pmb{v}_{i}^{t}-\\pmb{c}\\|_{2}\\leq R$ or $\\|\\pmb{v}_{i}^{t}+\\pmb{c}\\|_{2}\\leq R$ . ", "page_idx": 3}, {"type": "text", "text": "The dynamics is said to reach $(R,c)$ -consensus (or $(R,c)$ -bi-polarization) if the dynamics reaches $R$ -consensus (or $R$ -bi-polarization) with the vector $^c$ . ", "page_idx": 3}, {"type": "text", "text": "Consensus is any state where all users and creators have similar feature vectors (with maximum difference $R$ ), implying that they have similar interests or preferences. Bi-polarization is any state where all users and creators are clustered into two groups with exactly opposite features (e.g., Republicans vs Democrats). Mathematically, consensus is a special case of bi-polarization. ", "page_idx": 3}, {"type": "text", "text": "Proposition 3.2. $B i$ -polarization states are absorbing: once the dynamics reaches $(R,c)$ -bipolarization with some $R\\,\\in\\,[0,1]$ and $c~\\in~\\mathbb{S}^{d-1}$ , it will satisfy $(R,c)$ -bi-polarization forever. The same holds for consensus. ", "page_idx": 3}, {"type": "text", "text": "A natural property of a recommender system is that every creator can be recommended to every user with some non-zero probability: $p_{i j}^{t}\\geq p_{0}>0$ with some constant $p_{0}$ . This is satisfied by the softmax function, which is a rough model of real-world recommendation algorithms [13, 26]: $p_{i j}^{t}=$ ", "page_idx": 3}, {"type": "text", "text": "Theorem 3.3. Suppose $g(\\pmb{u}_{j},\\pmb{v}_{i})=\\mathrm{sign}(\\langle\\pmb{u}_{j},\\pmb{v}_{i}\\rangle)$ , the update rates $\\begin{array}{r}{\\eta_{c}\\leq\\frac{\\eta_{u}L_{f}}{2}}\\end{array}$ and $\\begin{array}{r}{\\eta_{u}<\\frac{1}{2}}\\end{array}$ , and the recommendation probability $p_{i j}^{t}\\geq p_{0}>0,\\forall i,j,t.$ . Then, from almost all initial states, the dynamics $(\\pmb{U}^{t},\\pmb{V}^{t})$ will eventually reach $R$ -consensus or $R$ -bi-polarization for any $R>0$ . ", "page_idx": 4}, {"type": "text", "text": "In other words, if the users\u2019 and creators\u2019 updates are not too fast and all recommendation probabilities are non-zero, then all users and creators will eventually converge to at most two clusters (regardless of the feature dimension $d$ ). Since creators in one cluster produce similar contents, users in such a polarized system can never receive diverse recommendations. This means that the na\u00efve attempt of imposing $\\bar{p_{i j}^{t}}\\geq p_{0}>0$ cannot improve the diversity of a recommender system with dual influence. The conditions on the update rates $\\eta_{u},\\eta_{c}$ are only assumed to simplify the proof of Theorem 3.3. Our experiments (in Section 5) will show that polarization still occurs even without those conditions. ", "page_idx": 4}, {"type": "text", "text": "Theorem 3.3 does not characterize the rate of convergence of the user-creator feature dynamics to polarization, which we leave as an open question. ", "page_idx": 4}, {"type": "text", "text": "The proof of Theorem 3.3 is an absorbing Markov chain argument. It uses the following lemma: ", "page_idx": 4}, {"type": "text", "text": "tLhee mstmatae  3s.p4a. ceS,u tphpeorsee $\\begin{array}{r}{\\eta_{c}\\leq\\frac{\\eta_{u}L_{f}}{2}}\\end{array}$ ha $\\begin{array}{r}{\\eta_{u}<\\frac{1}{2}}\\end{array}$ $R>0$ $(U^{t},V^{t})$ iitne $\\left(U^{t},V^{t}\\right)^{-}\\rightarrow\\left(U_{-}^{t+1},V_{-}^{t+1}\\right)\\rightarrow\\cdot\\cdot\\cdot\\rightarrow\\left(U^{t+T},V^{t+T}\\right)$ length that leads to an $R$ -bi-polarization state $(U^{\\acute{t}+T},{\\dot{V}}^{t+T})$ . ", "page_idx": 4}, {"type": "text", "text": "The proof of this lemma (in Appendix F) is involved. It uses induction on the number of creators $n$ . The base case of $n=1$ is proved by a potential function argument. For $n\\geq2$ , we first construct a path that leads the subsystem of $n-1$ creators and all users to $R$ -bi-polarization. Then, depending on where the remaining creator is, we construct a sequence of recommendations that leads the remaining creator to one of the two clusters formed by the $n-1$ creators and all users. Such recommendations will move some users out of the formed clusters, which requires extra care in the proof. ", "page_idx": 4}, {"type": "text", "text": "Proof of Theorem 3.3. For any state $(\\pmb{U}^{t},\\pmb{V}^{t})$ in the state space, by Lemma 3.4 there exists a path $(U^{t},\\mathbf{\\bar{{V}}}^{t})\\;\\to\\;\\cdots\\;\\to\\;(U^{t+T},\\mathbf{\\bar{{V}}}^{t+T})$ of length $T$ that leads to $R$ -bi-polarization. Because every creator can be recommended to a user with probability at least $p_{0}$ , each transition $(\\boldsymbol{U}^{t^{\\prime}},\\boldsymbol{V}^{t^{\\prime}})\\rightarrow$ $(U_{\\_}^{t^{\\prime}+1},V^{t^{\\prime}+1})$ happens with probability at least $p_{0}^{m}$ . So, the path of length $T$ has probability at least $\\stackrel{\\cdot}{p}_{0}^{m T}>0$ , and the probability that the dynamics does not reach $R$ -bi-polarization after $K T$ steps is at most $(1-p_{0}^{m T})^{K^{'}}$ , which $\\rightarrow0$ as $K\\rightarrow\\infty$ . Therefore, with probability 1 the dynamics will reach $R$ -bi-polarization eventually. \u53e3 ", "page_idx": 4}, {"type": "text", "text": "4 Discussions on Real-World Designs ", "text_level": 1, "page_idx": 4}, {"type": "text", "text": "Next, we discuss how 4 types of real-world recommender system designs affect the user-creator feature dynamics: top- $k$ truncation, threshold truncation, diversity-boosting, and uniform traffic. ", "page_idx": 4}, {"type": "text", "text": "(1) Top- $k$ Truncation A prevalent practice in modern two-stage recommendation algorithms on large-scale platforms, such as YouTube [13], is to first fliter out items that are unlikely to be relevant to a user, then make recommendations from the remaining items. In particular, we consider the top- $k$ truncation policy: for every user $j$ , find the $k$ most relevant creators, namely, the $k$ creators whose inner products with the user $\\langle\\boldsymbol{v}_{i}^{t},\\boldsymbol{u}_{j}^{t}\\rangle$ are largest (equivalently, the $k$ creators whose probabilities $p_{i j}^{t}$ of being recommended to user $j$ are highest), then recommend one of those $k$ creators to user $j$ with probability proportional to $p_{i j}^{t}$ . The other creators will not be recommended. This practice significantly reduces the computation cost and improves the relevancy of recommendations. Interestingly, we show that such a practice also has the potential to improve the long-term diversity of a recommender system with dual influence. ", "page_idx": 4}, {"type": "text", "text": "Definition 4.1 (clusters). We say a state $(\\pmb{U}^{t},\\pmb{V}^{t})$ forms $q$ clusters if there exist $c_{1},\\ldots,c_{q}\\in\\mathbb{R}^{d}$ and a small number $R>0$ such that every feature vector is in the $\\ell_{2}$ ball of some $c_{i}$ with radius $R$ (denoted by $B(c_{\\ell},R)=\\{\\pmb{x}:\\|\\pmb{x}-c_{\\ell}\\|_{2}\\leq R\\},$ ), and $B(c_{\\ell},2R)\\cap B(c_{\\ell^{\\prime}},2R)=\\emptyset$ for $\\ell\\neq\\ell^{\\prime}$ . ", "page_idx": 4}, {"type": "text", "text": "It is clear that consensus has a single cluster, and bi-polarization has two. ", "page_idx": 4}, {"type": "text", "text": "Proposition 4.2. With top- $k$ truncation, there exist states $(U^{t},V^{t})$ that form $\\lfloor n/k\\rfloor$ clusters and are absorbing (i.e., once the system forms $\\lfloor n/k\\rfloor$ clusters, it forms $\\lfloor n/k\\rfloor$ clusters forever). ", "page_idx": 4}, {"type": "text", "text": "This result is in contrast with Theorem 3.3 which shows that a recommender system where every creator can be recommended to every user $(p_{i j}^{t}>0)$ is doomed to polarize. With top- $k$ truncation where some $p_{i j}^{t}=0$ , polarization can be avoided. Experiments in Section 5.3 support our prediction that top- ${\\cdot k}$ truncation can reduce polarization and improve diversity. ", "page_idx": 5}, {"type": "text", "text": "(2) Threshold Truncation Besides top- $k$ truncation, threshold truncation is another way to filter out irrelevant creators: set a threshold $\\tau\\in[-1,1]$ such that any user-creator pair with inner product $\\langle{\\pmb u}_{i},{\\pmb v}_{j}\\rangle<\\tau$ is not recommended. A natural choice is $\\tau=0$ , meaning that users will not receive recommendations predicted to be \u201cdisliked\u201d by them. Increasing $\\tau$ is similar to increasing the $\\beta$ in the softmax function, which improves recommendation relevance. ", "page_idx": 5}, {"type": "text", "text": "Proposition 4.3. In $d$ -dimensional feature space, if user-creator pairs with $\\langle\\pmb{u}_{i},\\pmb{v}_{j}\\rangle\\,<\\,0$ are not recommended, then there exist stable states with $d+1$ clusters. ", "page_idx": 5}, {"type": "text", "text": "Although truncation at $\\tau=0$ allows stable states with $d+1$ clusters to exist, the dynamics does not necessarily converge to such states; it can still end up with stable states with fewer clusters. In fact, experiments (in Appendix B.2) show that truncation at $\\tau\\,=\\,0$ is not good for diversity and causes severe polarization, while truncation at a large threshold like $\\tau=0.707$ is better at reducing polarization. ", "page_idx": 5}, {"type": "text", "text": "(3) Diversity Boosting Diversity boosting aims to explore users\u2019 interests and improve users\u2019 experience by diversifying recommendation. For example, when making recommendations, the model optimizes the objective: ", "page_idx": 5}, {"type": "equation", "text": "$$\nh_{r e l}(\\langle\\pmb{u}_{i},\\pmb{v}_{j}\\rangle)+\\rho h_{d i v}(l i s t_{i},\\pmb{v}_{j}),\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "where $h_{r e l},h_{d i v}$ rewards the recommendation relevance and diversity respectively and $l i s t_{i}$ records the recent list of recommended items to user $i$ . $h_{d i v}$ can take a simple form of $\\textstyle\\sum_{j^{\\prime}\\in l i s t_{i}}1-$ $\\langle\\pmb{v}_{j^{\\prime}},\\pmb{v}_{j}\\rangle$ , and $\\rho>0$ controls the strength of diversity-boosting. Despite being successful when users\u2019 preferences and items are fixed, this design alone cannot prevent bi-polarization in our dual-influence dynamics, since the conditions in Theorem 3.3 are still satisfied and the users\u2019 and creators\u2019 update rules remain the same. Experiments in Section 5.2 support our claim. ", "page_idx": 5}, {"type": "text", "text": "(4) Uniform Traffic Adding a small fraction of uniform traffic to the personalized recommendations is another method proposed in previous works to improve recommendation diversity or to explore user preferences [25, 16, 9, 8, 30]. This method gives a non-zero lower bound on the probability of every creator being recommended to every user. So, as a corollary of our Theorem 3.3, it causes a recommender system with dual influence to polarize. Such an observation is striking as it demonstrates that optimizing for recommendation diversity in a static setting can ultimately lead to a huge loss of the system diversity in the long run. ", "page_idx": 5}, {"type": "text", "text": "5 Experiments ", "text_level": 1, "page_idx": 5}, {"type": "text", "text": "We present experimental results on the behavior of user-creator feature dynamics on synthetic data and real-world (MovieLens 20M) data and the effect of top- $\\cdot k$ truncation and threshold truncation on the dynamics. ", "page_idx": 5}, {"type": "text", "text": "5.1 Synthetic Data Experiments ", "text_level": 1, "page_idx": 5}, {"type": "text", "text": "Setup The dynamics is initialized by randomly generating user and creator features on the unit sphere in $\\mathbb{R}^{d}$ . We pick $d=10$ , number of creators $n=50$ , number of users $m=100$ . We use the softmax recommendation probability function (2). We simulate the dynamics for $T=1000$ steps, repeated 100 times each with a new initialization. We choose the sign impact function $g(\\pmb{u}_{j},\\pmb{v}_{i})=$ $\\mathrm{sign}(\\langle{\\pmb u}_{j},{\\pmb v}_{i}\\rangle)$ for creator updates. For user updates, we choose inner product $f(\\pmb{v}_{i},\\pmb{u}_{j})=\\bar{\\langle}\\pmb{v}_{i},\\pmb{u}_{j}\\rangle$ . The inner product function is studied in previous works on users\u2019 preference dynamics (but not creators\u2019) [14]. Note that the inner product does not satisfy the condition $|f(\\pmb{v}_{i},\\pmb{u}_{j})|\\geq L_{f}$ needed in Theorem 3.3. However, we still observe convergence to polarization in nearly all experiments. Thus, even when this condition does not hold, users and creators still tend towards polarization in practice. ", "page_idx": 5}, {"type": "text", "text": "Three key parameters in our model are $\\beta$ (sensitivity of the softmax function), $\\eta_{c}$ (creator update rate), and $\\eta_{u}$ (user update rate). We set them to $\\beta=1,\\eta_{c}=\\eta_{u}=0.1$ , and change one parameter at a time to see its effect on the dynamics. We also test what happens when some dimensions of the user features are fixed features that are not updated. ", "page_idx": 5}, {"type": "image", "img_path": "yWq89o19wf/tmp/574774309b82f5bfbfe92fe725ec113bc96d750fd154445fbbf46ad6d1548d42.jpg", "img_caption": ["Figure 1: Snapshots of the dynamics simulated with the same initialization but different recommendation sensitivity $\\beta$ . A larger $\\beta$ resulted in more clusters at time step $t=200$ . "], "img_footnote": [], "page_idx": 6}, {"type": "text", "text": "", "page_idx": 6}, {"type": "text", "text": "Measures To quantify the behavior of the dynamics, given user and creator feature vectors $(U,V)$ we compute the following measures, which cover diversity, relevancy, and polarization of the system: ", "page_idx": 6}, {"type": "text", "text": "\u2022 Creator Diversity (CD): diversity of the creator features, measured by their average pairwise distance [47, 33]: $\\begin{array}{r}{\\dot{\\mathrm{CD}}(\\mathbf V)=\\frac{\\tilde{1}}{n(n-1)}\\sum_{i=1}^{n}\\sum_{j\\neq i}\\|\\pmb{v}_{i}-\\pmb{v}_{j}\\|}\\end{array}$ .   \n\u2022 Recommendation Diversity (RD): diversity of the contents recommended to a user, measured by the weighted variance of the contents: $\\begin{array}{r}{\\mathrm{{RD}}(U,V;\\beta)=\\frac{1}{m}\\sum_{j=1}^{m}\\sum_{i=1}^{n}p_{i j}\\|v_{i}-\\overline{{v}}_{j}\\|^{2}}\\end{array}$ , where vj =  i=1 pijvi and pij = in=1 exp(\u03b2j\u27e8uij,vi\u27e9).   \n\u2022 Recommendation Relevance (RR): relevance of the contents recommended to a user, measured by   \nthe weighted average of inner products: $\\begin{array}{r}{\\mathrm{RR}(U,V;\\beta)=\\frac{1}{m}\\sum_{j=1}^{m}\\sum_{i=1}^{n}p_{i j}\\langle{\\boldsymbol u}_{j},{\\boldsymbol v}_{i}\\rangle}\\end{array}$ .   \n\u2022 Tendency to Polarization (TP): This is a novel measure we propose to quantify how close the system is to consensus or bi-polarization, measured by the average absolute inner products between the creators: $\\begin{array}{r}{\\mathrm{TP}(V)\\stackrel{*}{=}\\frac{1}{n^{2}}\\sum_{i=1}^{n}\\sum_{k=1}^{n}|\\langle v_{i},v_{k}\\rangle|}\\end{array}$ kn=1 |\u27e8vi, vk\u27e9|. TP(V ) being closer to 1 means that the system is more polarized, because the term $|\\langle{\\pmb v}_{i},{\\pmb v}_{k}\\rangle|$ is 1 iff the two vectors $\\pmb{v}_{i},\\pmb{v}_{k}$ are equal or opposite to each other. ", "page_idx": 6}, {"type": "text", "text": "It is worth noting that a high creator diversity is necessary for simultaneously achieving high recommendation relevance and high recommendation diversity. For example, they cannot be simultaneously achieved in a polarized state. ", "page_idx": 6}, {"type": "text", "text": "Sensitivity Parameter $\\beta$ A larger $\\beta$ means that a user will be recommended more relevant content/creator with a higher probability. $\\beta=0$ , on the other hand, means that the user receives uniform recommendations across all creators. Our main observation from the experiments is: $a$ larger $\\beta$ leads to higher creator diversity and alleviated polarization in the long run. ", "page_idx": 6}, {"type": "text", "text": "Figure 1 shows snapshots of the dynamics at different time steps under different $\\beta$ values. Here, we choose dimension $d=3$ instead of 10 so the feature vectors can be visualized on a 3d sphere. We see that the system tends to form more clusters at time $t=200$ as $\\beta$ increases. ", "page_idx": 6}, {"type": "text", "text": "Figure 2 shows the changes of the 4 measures CD, RD, RR, TP over time under different $\\beta$ values. We see that a more diverse recommendation policy (a smaller $\\beta$ ) leads to lower creator diversity and a higher level of polarization in the long run. In particular, while Creator Diversity reaches a similar level under different $\\beta$ in the end, it drops at a slower rate with a larger $\\beta$ (see $\\beta=5,6$ ). Moreover, from the plot of Tendency to Polarization, we see that a larger $\\beta$ alleviates polarization, which means improvement in the diversity of the whole system. ", "page_idx": 6}, {"type": "text", "text": "An explanation for our observation is the following: When $\\beta$ is smaller, each user receives more uniform recommendations across all creators. So, for different creators, the sets of users recommended to those creators have larger intersections. Since the creator updates are based on the sets of recommended users, different creators will be moving towards more similar directions. This leads to faster polarization. One can also predict this observation from Theorem 3.3: when $\\beta$ is large, the minimum recommendation probability $p_{0}$ of the softmax function tends to 0, so it might take a long time for the system to converge to polarization, while with a small $\\beta$ the system polarizes quickly. ", "page_idx": 6}, {"type": "image", "img_path": "yWq89o19wf/tmp/77ef3c6c40d638d7b35e84a60f5915a8aaa584a65d0ab30de31cee4b600945f9.jpg", "img_caption": ["Figure 2: Changes of measures over time under different sensitivity parameter $\\beta$ , on synthetic data. $\\beta=0$ means uniform (non-personalized) recommendation. $\\beta=\\infty$ means hard-max recommendation: only recommend the single most relevant creator to a user. Larger $\\beta$ reduces the tendency to polarization. "], "img_footnote": [], "page_idx": 7}, {"type": "text", "text": "", "page_idx": 7}, {"type": "text", "text": "Update Rates $\\eta_{c}$ and $\\eta_{u}$ A larger $\\eta_{c}$ means that creator features are updated faster, and intuitively should lead to faster polarization. This is validated in experiments: Figure 3 shows that a larger $\\eta_{c}$ indeed causes more extreme polarization and lower diversity (both CD and RD). A larger $\\eta_{u}$ means that user features are updated faster. It has a similar effect of exacerbating polarization as $\\eta_{c}$ does, as shown in Figure 4. ", "page_idx": 7}, {"type": "image", "img_path": "yWq89o19wf/tmp/05b7f87b27c2147a41b1499f17d4625d1fba3182f215854e938fa8b93dddbc9f.jpg", "img_caption": ["Figure 3: Changes of measures over time under different creator update rate $\\eta_{c}$ , on synthetic data "], "img_footnote": [], "page_idx": 7}, {"type": "image", "img_path": "yWq89o19wf/tmp/4f946ac120e65a7d247c3841fdb324ca22594478f357ac6307794f312471ae51.jpg", "img_caption": ["Figure 4: Changes of measures over time under different user update rate $\\eta_{u}$ , on synthetic data "], "img_footnote": [], "page_idx": 7}, {"type": "text", "text": "Number of Fixed Dimensions We also consider the scenario where some dimensions of the user feature vectors are fixed features and thus not updated from round to round (e.g., age, gender), which is a realistic scenario. Detailed results are in Appendix B.1. The main observation is: as the number of fixed dimensions increases, the diversity of the system improves and the degree of polarization is reduced. This is similar to the effect of decreasing user update rate $\\eta_{u}$ . The observation that fixed dimensions of user features help to improve diversity might be a reason why the recommender systems in practice are not as polarized as our theoretical prediction. ", "page_idx": 7}, {"type": "text", "text": "", "page_idx": 8}, {"type": "text", "text": "5.2 Real-World Data Experiments ", "text_level": 1, "page_idx": 8}, {"type": "text", "text": "In this part, we conduct experiments on the MovieLens 20M dataset [19]. We use a real-world twotower recommendation model with 16-dimensional tower tops as the user and creator embeddings (Figure 9). The model is initialized by fitting a two-tower model [21] on the existing MovieLens rating data and using the tower tops as the initial user and creator embeddings. Then we follow Algorithm 1 to simulate the dynamics. ", "page_idx": 8}, {"type": "text", "text": "Figure 5 shows the effect of the recommendation sensitivity parameter $\\beta$ on the system. Similar to the synthetic data experiments, a smaller $\\beta$ (more diverse recommendation for the users in the short term) results in faster polarization. We note that the joint results on CD and TP are more informative than each one alone: despite $\\beta=0$ has a higher creator diversity than $\\beta=2$ at $T=500$ , the system reaches polarization more quickly under $\\beta=0$ . The higher creator diversity under $\\beta=0$ is because the two clusters in the bi-polarized state are more balanced so the average pairwise distance between the creators is higher under $\\beta=0$ than under $\\beta=2$ . ", "page_idx": 8}, {"type": "text", "text": "Figure 6 shows the effect of using diversity-aware objective (Eq. 5) for diversity boosting. We see that myopically promoting the short-term recommendation diversity (using a larger $\\rho$ ) results a higher creation diversity but also a higher tendency to polarization. A possible explanation for this phenomenon is, similar to the case with $\\beta$ , the system polarizes into two balanced clusters which actually have a large average pairwise distance. In this case, Tendency to Polarization is a better measure for diversity loss than Creator Diversity (average pairwise distance). ", "page_idx": 8}, {"type": "image", "img_path": "yWq89o19wf/tmp/39fb896ad07262bdbf50a9c0268553f9d7ba57efae858dce881a0b859cb1325c.jpg", "img_caption": ["Figure 5: Experiment on MovieLens 20M dataset under different recommendation sensitivity $\\beta$ "], "img_footnote": [], "page_idx": 8}, {"type": "image", "img_path": "yWq89o19wf/tmp/f5cf63c68d639dd7d94bc61f202a52578811c9e7bc3dfbbc9d4468b198b108c0.jpg", "img_caption": ["Figure 6: Experiment on MovieLens 20M dataset with diversity-aware objective under different $\\rho$ "], "img_footnote": [], "page_idx": 8}, {"type": "text", "text": "5.3 Top- $k$ Truncation and Threshold Truncation ", "text_level": 1, "page_idx": 8}, {"type": "text", "text": "We experimented with top- $k$ truncation on the synthetic data (Table 1) and the MovieLens dataset (Appendix C). Our main observation is: a small $k$ improves the diversity of the recommender system and reduces polarization. This is consistent with our theoretical prediction (Proposition 4.2). However, there is a tradeoff between the diversity of recommendations to users (RD) and the diversity of creations in the system (CD and TP). A top- $k$ truncation policy with small $k$ is \u201cnot diverse\u201d for users because it exposes a user only to a small set of contents. However, such a policy can lead to a more diverse outcome in the whole system. This tradeoff is worth further studying. ", "page_idx": 8}, {"type": "table", "img_path": "yWq89o19wf/tmp/1a9384c8b17b0226e71e243f0e953cd80f7a236dcd6bbbc7e20615cf1710ed68.jpg", "table_caption": ["Table 1: Diversity improvement by top- $k$ truncation on synthetic data "], "table_footnote": [], "page_idx": 9}, {"type": "text", "text": "We also experimented with threshold truncation on synthetic data (Appendix B.2) and MovieLens data (Appendix C). The effect of a large truncation threshold $\\tau$ is similar to the effect of a small $k$ in top- $k$ truncation. ", "page_idx": 9}, {"type": "text", "text": "6 Conclusion ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "Our work defines a dynamics model to capture the dual influence of recommender systems on user preferences and content creation. Although our model is a theoretical abstraction, we believe that it captures the essence of a real-world recommender system, and our effort is an important initial endeavor to study diversity in recommender systems with dual influence. (See Appendix H for some additional discussions on real-world recommender systems.) We specifically point out different concepts of diversity in recommender systems (creation diversity, recommendation diversity, and tendency to polarization) and provide theoretical and empirical evidences to show that, due to dual influence, myopically optimizing recommendation diversity might hurt the long-term creation diversity and result in polarization of the system. We also explore popular design choices in recommender systems and show an interesting and somewhat counter-intuitive result that designs purely targeting efficiency improvement (e.g., top- $k$ truncation) can alleviate polarization. We believe that the insights from our work are valuable to building healthy and sustainable recommender systems, and our results can inspire more sophisticated solutions for improving the long-term diversity of recommender systems to be developed. ", "page_idx": 9}, {"type": "text", "text": "References ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "[1] Daron Acemog\u02d8lu, Giacomo Como, Fabio Fagnani, and Asuman Ozdaglar. Opinion fluctuations and disagreement in social networks. Mathematics of Operations Research, 38(1):1\u201327, 2013. ISSN 0364765X, 15265471. URL http://www.jstor.org/stable/23358646.   \n[2] Krishna Acharya, Varun Vangala, Jingyan Wang, and Juba Ziani. Producers equilibria and dynamics in engagement-driven recommender systems. arXiv preprint arXiv:2401.16641, 2024.   \n[3] Arpit Agarwal and William Brown. Online recommendations for agents with discounted adaptive preferences. arXiv preprint arXiv:2302.06014, 2023.   \n[4] Claudio Altafini and Gabriele Lini. Predictable dynamics of opinion forming for networks with antagonistic interactions. IEEE Transactions on Automatic Control, 60(2):342\u2013357, 2015. doi: 10.1109/TAC.2014.2343371.   \n[5] Guy Aridor, Duarte Goncalves, and Shan Sikdar. Deconstructing the filter bubble: User decision-making recommender systems. In Proceedings of the 14th ACM Conference on Recommender Systems, RecSys $^{\\circ}20$ , page 82\u201391, New York, NY, USA, 2020. Association for Computing Machinery. ISBN 9781450375832. doi: 10.1145/3383313.3412246. URL https://doi.org/10.1145/3383313.3412246.   \n[6] Nikhil Bansal and Anupam Gupta. Potential-Function Proofs for Gradient Methods. Theory of Computing, 15(4):1\u201332, 2019. doi: 10.4086/toc.2019.v015a004. URL https: //theoryofcomputing.org/articles/v015a004. Publisher: Theory of Computing.   \n[7] Omer Ben-Porat and Moshe Tennenholtz. A game-theoretic approach to recommendation systems with strategic content providers. Advances in Neural Information Processing Systems, 31, 2018.   \n[8] Stephen Bonner and Flavian Vasile. Causal embeddings for recommendation. In Proceedings of the 12th ACM Conference on Recommender Systems, pages 104\u2013112, Vancouver British Columbia Canada, September 2018. ACM. ISBN 978-1-4503-5901-6. doi: 10.1145/3240323. 3240360. URL https://dl.acm.org/doi/10.1145/3240323.3240360. [9] Christian Borgs, Jennifer Chayes, Christian Ikeokwu, and Ellen Vitercik. Bursting the Filter Bubble: Disincentivizing Echo Chambers in Social Networks. In Proceedings of EAAMO\u201923: ACM Conference on Equity and Access in Algorithms, Mechanisms, and Optimization, 2023.   \n[10] Marco Caponigro, Anna Chiara Lai, and Benedetto Piccoli. A nonlinear model of opinion formation on the sphere. Discrete & Continuous Dynamical Systems - A, 35(9):4241\u20134268, 2015. ISSN 1553-5231. doi: 10.3934/dcds.2015.35.4241. URL http://aimsciences.org/ /article/doi/10.3934/dcds.2015.35.4241.   \n[11] Jaime Carbonell and Jade Goldstein. The use of mmr, diversity-based reranking for reordering documents and producing summaries. In Proceedings of the 21st Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, SIGIR \u201998, page 335\u2013336, New York, NY, USA, 1998. Association for Computing Machinery. ISBN 1581130155. doi: 10.1145/290941.291025. URL https://doi.org/10.1145/290941.291025.   \n[12] Peizhe Cheng, Shuaiqiang Wang, Jun Ma, Jiankai Sun, and Hui Xiong. Learning to recommend accurate and diverse items. In Proceedings of the 26th International Conference on World Wide Web, WWW \u201917, page 183\u2013192, Republic and Canton of Geneva, CHE, 2017. International World Wide Web Conferences Steering Committee. ISBN 9781450349130. doi: 10.1145/ 3038912.3052585. URL https://doi.org/10.1145/3038912.3052585.   \n[13] Paul Covington, Jay Adams, and Emre Sargin. Deep Neural Networks for YouTube Recommendations. In Proceedings of the 10th ACM Conference on Recommender Systems, pages 191\u2013198, Boston Massachusetts USA, September 2016. ACM. ISBN 978-1-4503-4035-9. doi: 10.1145/2959100.2959190. URL https://dl.acm.org/doi/10.1145/2959100.2959190.   \n[14] Sarah Dean and Jamie Morgenstern. Preference Dynamics Under Personalized Recommendations. In Proceedings of the 23rd ACM Conference on Economics and Computation, pages 795\u2013816, Boulder CO USA, July 2022. ACM. ISBN 978-1-4503-9150-4. doi: 10.1145/3490486.3538346. URL https://dl.acm.org/doi/10.1145/3490486.3538346.   \n[15] Itay Eilat and Nir Rosenfeld. Performative Recommendation: Diversifying Content via Strategic Incentives, June 2023. URL http://arxiv.org/abs/2302.04336. arXiv:2302.04336 [cs].   \n[16] Chongming Gao, Shijun Li, Yuan Zhang, Jiawei Chen, Biao Li, Wenqiang Lei, Peng Jiang, and Xiangnan He. Kuairand: An unbiased sequential recommendation dataset with randomly exposed videos. In Proceedings of the 31st ACM International Conference on Information & Knowledge Management, CIKM \u201922, page 3953\u20133957, New York, NY, USA, 2022. Association for Computing Machinery. ISBN 9781450392365. doi: 10.1145/3511808.3557624. URL https://doi.org/10.1145/3511808.3557624.   \n[17] Benjamin Golub and Matthew O. Jackson. Na\u00efve learning in social networks and the wisdom of crowds. American Economic Journal: Microeconomics, 2(1):112\u201349, February 2010. doi: 10.1257/mic.2.1.112. URL https://www.aeaweb.org/articles?id $_{\\cdot}{=}10$ .1257/mic.2.1. 112.   \n[18] Moritz Hardt, Meena Jagadeesan, and Celestine Mendler-D\u00fcnner. Performative power. Advances in Neural Information Processing Systems, 35:22969\u201322981, 2022.   \n[19] F Maxwell Harper and Joseph A Konstan. The movielens datasets: History and context. Acm transactions on interactive intelligent systems (tiis), 5(4):1\u201319, 2015.   \n[20] Jiri Hron, Karl Krauth, Michael I. Jordan, Niki Kilbertus, and Sarah Dean. Modeling Content Creator Incentives on Algorithm-Curated Platforms, July 2023. URL http://arxiv.org/ abs/2206.13102. arXiv:2206.13102 [cs, stat].   \n[21] Po-Sen Huang, Xiaodong He, Jianfeng Gao, Li Deng, Alex Acero, and Larry Heck. Learning deep structured semantic models for web search using clickthrough data. In Proceedings of the 22nd ACM international conference on Information & Knowledge Management, pages 2333\u2013 2338, San Francisco California USA, October 2013. ACM. ISBN 978-1-4503-2263-8. doi: 10.1145/2505515.2505665. URL https://dl.acm.org/doi/10.1145/2505515.2505665.   \n[22] Neil J. Hurley. Personalised ranking with diversity. In Proceedings of the 7th ACM Conference on Recommender Systems, RecSys \u201913, page 379\u2013382, New York, NY, USA, 2013. Association for Computing Machinery. ISBN 9781450324090. doi: 10.1145/2507157.2507226. URL https://doi.org/10.1145/2507157.2507226.   \n[23] Meena Jagadeesan, Nikhil Garg, and Jacob Steinhardt. Supply-side equilibria in recommender systems. Advances in Neural Information Processing Systems, 36, 2024.   \n[24] Ray Jiang, Silvia Chiappa, Tor Lattimore, Andr\u00e1s Gy\u00f6rgy, and Pushmeet Kohli. Degenerate Feedback Loops in Recommender Systems. In Proceedings of the 2019 AAAI/ACM Conference on AI, Ethics, and Society, pages 383\u2013390, Honolulu HI USA, January 2019. ACM. ISBN 978-1-4503-6324-2. doi: 10.1145/3306618.3314288. URL https://dl.acm.org/doi/10. 1145/3306618.3314288.   \n[25] Natali Helberger Judith M\u00f6ller, Damian Trilling and Bram van Es. Do not blame it on the algorithm: an empirical assessment of multiple recommender systems and their impact on content diversity. Information, Communication & Society, 21(7):959\u2013977, 2018. doi: 10.1080/ 1369118X.2018.1444076. URL https://doi.org/10.1080/1369118X.2018.1444076.   \n[26] Dimitris Kalimeris, Smriti Bhagat, Shankar Kalyanaraman, and Udi Weinsberg. Preference amplification in recommender systems. In Proceedings of the 27th ACM SIGKDD Conference on Knowledge Discovery & Data Mining, KDD \u201921, page 805\u2013815, New York, NY, USA, 2021. Association for Computing Machinery. ISBN 9781450383325. doi: 10.1145/3447548.3467298. URL https://doi.org/10.1145/3447548.3467298.   \n[27] Sagi Levanon and Nir Rosenfeld. Generalized strategic classification and the case of aligned incentives. In International Conference on Machine Learning, pages 12593\u201312618. PMLR, 2022.   \n[28] Lihong Li, Wei Chu, John Langford, and Robert E. Schapire. A contextual-bandit approach to personalized news article recommendation. In Proceedings of the 19th International Conference on World Wide Web, WWW \u201910, page 661\u2013670, New York, NY, USA, 2010. Association for Computing Machinery. ISBN 9781605587998. doi: 10.1145/1772690.1772758. URL https://doi.org/10.1145/1772690.1772758.   \n[29] Wei Li and Mark W. Spong. Unified cooperative control of multiple agents on a sphere for different spherical patterns. IEEE Transactions on Automatic Control, 59(5):1283\u20131289, 2014. doi: 10.1109/TAC.2013.2286897.   \n[30] Dugang Liu, Pengxiang Cheng, Zinan Lin, Xiaolian Zhang, Zhenhua Dong, Rui Zhang, Xiuqiang He, Weike Pan, and Zhong Ming. Bounding System-Induced Biases in Recommender Systems with a Randomized Dataset. ACM Transactions on Information Systems, 41(4):1\u201326, October 2023. ISSN 1046-8188, 1558-2868. doi: 10.1145/3582002. URL https://dl.acm.org/doi/10.1145/3582002.   \n[31] Johan Markdahl, Johan Thunberg, and Jorge Goncalves. Almost Global Consensus on the $\\mathbb{S}{\\mathrm{n}}\\mathbb{S}$ -Sphere. IEEE Transactions on Automatic Control, 63(6):1664\u20131675, June 2018. ISSN 0018-9286, 1558-2523. doi: 10.1109/TAC.2017.2752799. URL https://ieeexplore.ieee. org/document/8038829/.   \n[32] Farzan Masrour, Tyler Wilson, Heng Yan, Pang-Ning Tan, and Abdol Esfahanian. Bursting the fliter bubble: Fairness-aware network link prediction. Proceedings of the AAAI Conference on Artificial Intelligence, 34(01):841\u2013848, Apr. 2020. doi: 10.1609/aaai.v34i01.5429. URL https://ojs.aaai.org/index.php/AAAI/article/view/5429.   \n[33] Tien T. Nguyen, Pik-Mai Hui, F. Maxwell Harper, Loren Terveen, and Joseph A. Konstan. Exploring the fliter bubble: the effect of using recommender systems on content diversity. In Proceedings of the 23rd International Conference on World Wide Web, WWW \u201914, page 677\u2013686, New York, NY, USA, 2014. Association for Computing Machinery. ISBN 9781450327442. doi: 10.1145/2566486.2568012. URL https://doi.org/10.1145/2566486.2568012.   \n[34] Juan Perdomo, Tijana Zrnic, Celestine Mendler-D\u00fcnner, and Moritz Hardt. Performative prediction. In International Conference on Machine Learning, pages 7599\u20137609. PMLR, 2020.   \n[35] Siddharth Prasad, Martin Mladenov, and Craig Boutilier. Content prompting: Modeling content provider dynamics to improve user welfare in recommender ecosystems. arXiv preprint arXiv:2309.00940, 2023.   \n[36] Fernando P. Santos, Yphtach Lelkes, and Simon A. Levin. Link recommendation algorithms and dynamics of polarization in online social networks. Proceedings of the National Academy of Sciences, 118(50):e2102141118, 2021. doi: 10.1073/pnas.2102141118. URL https: //www.pnas.org/doi/abs/10.1073/pnas.2102141118.   \n[37] Alain Sarlette, Rodolphe Sepulchre, and Naomi Ehrich Leonard. Autonomous rigid body attitude synchronization. In 2007 46th IEEE Conference on Decision and Control, pages 2566\u20132571, 2007. doi: 10.1109/CDC.2007.4434153.   \n[38] Ruilong Su, Li\u2019Ang Yin, Kailong Chen, and Yong Yu. Set-oriented personalized ranking for diversified top-n recommendation. In Proceedings of the 7th ACM Conference on Recommender Systems, RecSys \u201913, page 415\u2013418, New York, NY, USA, 2013. Association for Computing Machinery. ISBN 9781450324090. doi: 10.1145/2507157.2507207. URL https://doi.org/ 10.1145/2507157.2507207.   \n[39] Mark Wilhelm, Ajith Ramanathan, Alexander Bonomo, Sagar Jain, Ed H. Chi, and Jennifer Gillenwater. Practical diversified recommendations on youtube with determinantal point processes. In Proceedings of the 27th ACM International Conference on Information and Knowledge Management, CIKM \u201918, page 2165\u20132173, New York, NY, USA, 2018. Association for Computing Machinery. ISBN 9781450360142. doi: 10.1145/3269206.3272018. URL https://doi.org/10.1145/3269206.3272018.   \n[40] Longqi Yang, Yin Cui, Yuan Xuan, Chenyang Wang, Serge Belongie, and Deborah Estrin. Unbiased offline recommender evaluation for missing-not-at-random implicit feedback. In Proceedings of the 12th ACM Conference on Recommender Systems, RecSys \u201918, page 279\u2013287, New York, NY, USA, 2018. Association for Computing Machinery. ISBN 9781450359016. doi: 10.1145/3240323.3240355. URL https://doi.org/10.1145/3240323.3240355.   \n[41] Fan Yao, Chuanhao Li, Denis Nekipelov, Hongning Wang, and Haifeng Xu. Learning from a learning user for optimal recommendations. In Proceedings of the 39th International Conference on Machine Learning, volume 162 of Proceedings of Machine Learning Research, pages 25382\u2013 25406. PMLR, 17\u201323 Jul 2022. URL https://proceedings.mlr.press/v162/yao22a. html.   \n[42] Fan Yao, Chuanhao Li, Denis Nekipelov, Hongning Wang, and Haifeng Xu. How Bad is Top-K Recommendation under Competing Content Creators? In Proceedings of the 40th International Conference on Machine Learning, volume 202 of Proceedings of Machine Learning Research, pages 39674\u201339701. PMLR, July 2023. URL https://proceedings.mlr.press/v202/ yao23b.html.   \n[43] Fan Yao, Yiming Liao, Mingzhe Wu, Chuanhao Li, Yan Zhu, James Yang, Jingzhou Liu, Qifan Wang, Haifeng Xu, and Hongning Wang. User welfare optimization in recommender systems with competing content creators. In Proceedings of the 30th ACM SIGKDD Conference on Knowledge Discovery and Data Mining, KDD \u201924, page 3874\u20133885, New York, NY, USA, 2024. Association for Computing Machinery. ISBN 9798400704901. doi: 10.1145/3637528.3672021. URL https://doi.org/10.1145/3637528.3672021.   \n[44] Mi Zhang and Neil Hurley. Avoiding monotony: improving the diversity of recommendation lists. In Proceedings of the 2008 ACM Conference on Recommender Systems, RecSys \u201908, page 123\u2013130, New York, NY, USA, 2008. Association for Computing Machinery. ISBN 9781605580937. doi: 10.1145/1454008.1454030. URL https://doi.org/10.1145/ 1454008.1454030.   \n[45] Xiaoying Zhang, Hongning Wang, and Hang Li. Disentangled representation for diversified recommendations. In Proceedings of the Sixteenth ACM International Conference on Web Search and Data Mining, pages 490\u2013498, 2023.   \n[46] Ziqiao Zhang, Said Al-Abri, and Fumin Zhang. Opinion Dynamics on the Sphere for Stable Consensus and Stable Bipartite Dissensus. 9th IFAC Conference on Networked Systems NECSYS 2022, 55(13):288\u2013293, January 2022. ISSN 2405-8963. doi: 10.1016/j.ifacol.2022.07.274.   \n[47] Cai-Nicolas Ziegler, Sean M. McNee, Joseph A. Konstan, and Georg Lausen. Improving recommendation lists through topic diversification. In Proceedings of the 14th International Conference on World Wide Web, WWW \u201905, page 22\u201332, New York, NY, USA, 2005. Association for Computing Machinery. ISBN 1595930469. doi: 10.1145/1060745.1060754. ", "page_idx": 9}, {"type": "text", "text": "", "page_idx": 10}, {"type": "text", "text": "", "page_idx": 11}, {"type": "text", "text": "", "page_idx": 12}, {"type": "text", "text": "", "page_idx": 13}, {"type": "text", "text": "A Additional Discussions on Related Works ", "text_level": 1, "page_idx": 14}, {"type": "table", "img_path": "yWq89o19wf/tmp/5583a9b78684ac9f7a0f7fa094dda94026c495c9dbf86d1007dfb89a70e486c7.jpg", "table_caption": ["Table 2: Comparison between our work and some previous works on performative effects of recommender systems "], "table_footnote": ["1: These works study the design of recommendation algorithms for the platform with a fixed set of content, without explicitly modeling the content creators. "], "page_idx": 14}, {"type": "text", "text": "B Additional Experiments on Synthetic Data ", "text_level": 1, "page_idx": 14}, {"type": "text", "text": "B.1 Number of Fixed Dimensions ", "text_level": 1, "page_idx": 14}, {"type": "text", "text": "In this part, we consider the case where some dimensions of the user feature vectors are fixed features and thus not updated from round to round (e.g., ages, genders). Formally, we fix the first $k\\ \\leq\\ d$ dimensions. The remaining $d\\mathrm{~-~}k$ dimensions $\\pmb{u}_{j}^{\\bar{t}}[k\\bar{+}1\\,:\\,d]\\,=\\,(u_{j}^{t}[k\\bar{+}1],\\cdot\\,\\cdot\\,,u_{j}^{t}[d])$ are updated according to the following rule: $\\begin{array}{r}{\\pmb{u}_{j}^{t+1}[k+1:d]\\,=\\,\\|\\pmb{u}_{j}^{t}[k+1:d]\\|\\cdot\\mathcal{P}\\big(\\pmb{u}_{j}^{t}[k+1:}\\end{array}$ $\\underline{{d}}]+\\eta_{u}f(\\pmb{v}_{i}^{t},\\pmb{u}_{j}^{t})\\pmb{v}_{i}^{t}[k+1:d]\\rangle$ . The multiplication by $\\vert\\vert\\pmb{u}_{j}^{t}[k+1:d]\\vert\\vert$ ensures unit norm $\\vert\\vert\\pmb{u}_{j}^{t+1}\\vert\\vert=1$ . The effect of the number of fixed dimensions on the dynamics is shown in Figure 7. We see that the diversity of the system improves as the number of fixed dimensions increases, and the degree of polarization is reduced. This is similar to the effect of decreasing user update rate $\\eta_{u}$ in Figure 4. The observation that fixed user features encourage diversity might be a reason why the recommender systems in practice are not as polarized as our theoretical prediction. ", "page_idx": 14}, {"type": "image", "img_path": "yWq89o19wf/tmp/ad329e23ffda22eb24aa6a2f5cfad4a3a81a6ffcd465de588403566807fe67f8.jpg", "img_caption": ["Figure 7: Changes of measures over time under different numbers of fixed dimensions, on synthetic data "], "img_footnote": [], "page_idx": 14}, {"type": "text", "text": "B.2 Threshold Truncation ", "text_level": 1, "page_idx": 15}, {"type": "text", "text": "Table 3 shows that the effect of different thresholds in threshold truncation on the long-term diversity of the system. We see that truncating at $\\tau=0$ , which corresponds to $90^{\\circ}$ angle between $\\pmb{u}_{j}$ and $\\pmb{v}_{i}$ , is not good for diversity, resulting in the lowest creator diversity measure (CD) and highest tendency to polarization (TP). Truncating at a large threshold like 0.707 is good for diversity, instead. ", "page_idx": 15}, {"type": "text", "text": "Figure 8 shows how the diversity measures change over time, under different truncation thresholds. ", "page_idx": 15}, {"type": "table", "img_path": "yWq89o19wf/tmp/031949d129f2e32f8c9db5d15b758233d515062ebeb8195ce1ddd63ac43ab065.jpg", "table_caption": ["Table 3: Diversity improvement by threshold truncation on synthetic data "], "table_footnote": [], "page_idx": 15}, {"type": "image", "img_path": "yWq89o19wf/tmp/0a2d94a6585422bb11be61fb3b5d7ebe41559b90a8e52038cbe22f4750fb5e14.jpg", "img_caption": ["Figure 8: Changes of measures over time under different truncation threshold $\\tau$ , with $\\beta=1$ , on synthetic data "], "img_footnote": [], "page_idx": 16}, {"type": "text", "text": "C Additional Experiments on Real-World Dataset ", "text_level": 1, "page_idx": 17}, {"type": "text", "text": "C.1 Details of the Recommendation Algorithm ", "page_idx": 17}, {"type": "image", "img_path": "yWq89o19wf/tmp/65d83ee3f53a5bd7de100d34a12f8b4a7ec1644c363a2223601ef2c3cde96afd.jpg", "img_caption": [], "img_footnote": [], "page_idx": 17}, {"type": "text", "text": "Figure 9: Two tower model for the MovieLens experiment, where the two towers both have size $16\\times16$ with linear layers and ReLu activations. ", "page_idx": 17}, {"type": "text", "text": "Algorithm 1 Real-world Recommendation with Dual Influence ", "text_level": 1, "page_idx": 17}, {"type": "text", "text": "Input: $t=0$ , actual embedding $U^{(0)},V^{(0)}$ , true labels $Y_{i j}^{(0)}:=y(u_{i}^{(0)},v_{j}^{(0)})$ ), vj(0 )), initial parameter   \n${\\pmb\\theta}^{(0)}$ (which includes the predicted embedding $\\hat{U}^{(0)},\\hat{V}^{(0)}$ )   \nrepeat   \nLet temporary parameter $\\pmb{w}^{(0)}\\gets\\pmb{\\theta}^{(t)}$ Compute loss $\\bar{\\mathcal{L}}(\\pmb{\\theta}^{(t)},Y^{(t)})$ for $s=1$ to $m-1$ do $\\pmb{w}^{(s+1)}\\leftarrow\\pmb{\\theta}^{(s)}-\\eta\\nabla_{\\pmb{w}}\\mathcal{L}(\\pmb{w}^{(s)},Y^{(t)})$ end for $\\pmb{\\theta}^{(t+1)}\\leftarrow\\pmb{w}^{(m)}$ Deliver recommendations based on U\u02c6 (t+1), V\u02c6 (t+1) Update $U^{(t+1)},V^{(t+1)}$ , and $Y^{(t+1)}$ $t\\gets t+1$   \nuntil $\\|\\pmb{\\theta}^{(t)}-\\pmb{\\theta}^{(t-1)}\\|_{2}\\leq\\delta$ ", "page_idx": 17}, {"type": "text", "text": "C.2 Top- $k$ and Threshold Truncations ", "text_level": 1, "page_idx": 18}, {"type": "text", "text": "We also try top- $k$ and threshold truncations (Section 4) on the MovieLens 20M dataset. Here, we have $n=2000$ creators and $m=2000$ users, with feature dimension $d=16$ . The results for top- $k$ truncation are in Table 4 and Figure 10. Similar to the experiments with synthetic data, we see that a smaller $k$ improves Creator Diversity (CD) and Recommendation Relevance (RR), reduces Tendency to Polarization (TP), yet worsens Recommendation Diversity (RD). ", "page_idx": 18}, {"type": "table", "img_path": "yWq89o19wf/tmp/594d01e6cb65a1980d32b6fe0101d8537d0b6588cc888cc35ee29385d8cd44d2.jpg", "table_caption": ["Table 4: Diversity improvement by top- ${\\cdot k}$ truncation on MovieLens 20M dataset "], "table_footnote": [], "page_idx": 18}, {"type": "image", "img_path": "yWq89o19wf/tmp/b44278ff63620ca9ee087f9df1b5f8122ffff61d43afd3b93a9b928ae956103b.jpg", "img_caption": ["Figure 10: Changes of measures over time under different $k$ , with $\\beta=1$ , on MovieLens 20M dataset "], "img_footnote": [], "page_idx": 18}, {"type": "text", "text": "Results for threshold truncation are in Table 5 and Figure 11. Similar to synthetic data, we see that a large (but not too large) threshold like 0.707 is good for improving CD and TP. ", "page_idx": 19}, {"type": "table", "img_path": "yWq89o19wf/tmp/20b3e754ab67a38405c6e4ad8602c2335162bccc72076e24360e05ac35a5647f.jpg", "table_caption": ["Table 5: Threshold truncation with different thresholds on MovieLens 20M dataset "], "table_footnote": [], "page_idx": 19}, {"type": "image", "img_path": "yWq89o19wf/tmp/6dbcedf2a355af4af1fab8dfb9c8d3c14cf3c23b28c55361d69ac69b3e6c12a5.jpg", "img_caption": ["Figure 11: Changes of measures over time under truncation with different threshold $\\tau$ , with $\\beta=1$ , on MovieLens 20M dataset "], "img_footnote": [], "page_idx": 19}, {"type": "text", "text": "D Useful Lemmas ", "text_level": 1, "page_idx": 20}, {"type": "text", "text": "This section provides some lemmas that will be used in the proofs. They are mainly about some properties of the dynamics update rule. ", "page_idx": 20}, {"type": "text", "text": "Claim D.1. For vectors $\\mathbf{x},\\mathbf{y}\\in\\mathbb{R}^{d}$ with unit norm $\\|\\pmb{x}\\|_{2}=\\|\\pmb{y}\\|_{2}=1$ , we have: ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\bullet\\ \\|x-y\\|_{2}^{2}=2(1-\\langle\\pmb{x},\\pmb{y}\\rangle).}\\\\ &{\\bullet\\ \\langle\\pmb{x},\\pmb{y}\\rangle=1-\\frac{1}{2}\\|\\pmb{x}-\\pmb{y}\\|_{2}^{2}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "Lemma D.2 (Convex Cone Property). Let $z_{1},\\dots,z_{k}\\,\\in\\,\\mathbb{R}^{d}$ be vectors with norm $\\|z_{i}^{t}\\|_{2}\\,=\\,1$ . Suppose $\\langle z_{i},y\\rangle>0$ for every $i=1,\\dots,k$ for some $\\pmb{y}\\in\\mathbb{R}^{d}$ . Let $\\pmb{x}=\\mathcal{P}(\\sum_{i=1}^{k}a_{i}\\pmb{z}_{i})$ for some $a_{1},\\ldots,a_{k}\\ \\geq\\ 0$ (namely, $\\textbf{\\em x}$ is the normalization of some vector in the convex cone formed by z1, . . . , zk). Then, we have ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\langle x,y\\rangle\\;\\geq\\;\\operatorname*{min}_{i=1}^{k}\\langle z_{i},y\\rangle\\;>\\;0\\;\\;\\;\\;a n d\\;\\;\\;\\;\\|x-y\\|_{2}\\;\\leq\\;\\operatorname*{max}_{i=1}^{k}\\|z_{i}-y\\|_{2}\\;>\\;0.\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "Proof. ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\langle x,\\,y\\rangle\\,=\\,\\Big\\langle\\cfrac{\\sum_{i=1}^{k}a_{i}z_{i}}{\\|\\sum_{i=1}^{k}a_{i}z_{i}\\|_{2}},\\,y\\Big\\rangle\\,=\\,\\cfrac{1}{\\|\\sum_{i=1}^{k}a_{i}z_{i}\\|_{2}}\\sum_{i=1}^{k}a_{i}\\langle z_{i},y\\rangle}\\\\ &{\\,\\ge\\,\\cfrac{1}{\\|\\sum_{i=1}^{k}a_{i}z_{i}\\|_{2}}\\sum_{i=1}^{k}a_{i}\\underset{i=1}{\\operatorname*{min}}\\langle z_{i},y\\rangle\\,=\\,\\underset{i=1}{\\operatorname*{min}}\\langle z_{i},y\\rangle\\frac{\\sum_{i=1}^{k}a_{i}}{\\|\\sum_{i=1}^{k}a_{i}z_{i}\\|_{2}}}\\\\ &{\\,\\ge\\,\\underset{i=1}{\\operatorname*{min}}\\langle z_{i},y\\rangle\\frac{\\sum_{i=1}^{k}a_{i}}{\\sum_{i=1}^{k}a_{i}}\\,=\\,\\underset{i=1}{\\operatorname*{min}}\\langle z_{i},y\\rangle.}\\end{array}\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "This proves the first inequality. To prove the second inequality, we use Claim D.1 and the first inequality: ", "page_idx": 20}, {"type": "equation", "text": "$$\n-\\,y\\|_{2}\\,=\\,\\sqrt{2(1-\\langle{\\pmb x},{\\pmb y}\\rangle)}\\,\\le\\,\\sqrt{2(1-\\operatorname*{min}_{i}\\langle{\\pmb z}_{i},{\\pmb y}\\rangle)}\\,=\\,\\operatorname*{max}_{i}\\sqrt{2(1-\\langle{\\pmb z}_{i},{\\pmb y}\\rangle)}\\,=\\,\\operatorname*{max}_{i=1}^{k}\\|{\\pmb z}_{i}-{\\pmb y}\\|_{2}.\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "Lemma D.3. Let $\\pmb{x}^{t},\\pmb{y},\\pmb{z}^{t}\\in\\mathbb{R}^{d}$ be vectors with norm $\\|\\pmb{x}^{t}\\|_{2}=1$ , $\\|\\pmb{y}\\|_{2}\\geq0,\\,\\|\\pmb{z}^{t}\\|_{2}\\leq1.$ . Suppose $\\langle{\\pmb x}^{t},{\\pmb y}\\rangle\\geq0$ , $\\langle z^{t},\\pmb{y}\\rangle\\geq0$ . After the update $\\mathbf{\\boldsymbol{x}}^{t+1}=\\mathcal{P}(\\mathbf{\\boldsymbol{x}}^{t}+\\ddot{\\eta}\\pmb{z}^{t})$ , we have ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\langle x^{t+1}-x^{t},\\,y\\rangle\\;\\geq\\;\\frac{\\eta}{1+\\eta\\Vert z^{t}\\Vert_{2}}\\Big(\\langle z^{t},y\\rangle-\\Vert z^{t}\\Vert_{2}\\langle x^{t},y\\rangle\\Big).\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "As a corollary, $i f\\,\\pmb{y}=z^{t}$ and $\\|\\boldsymbol{z}^{t}\\|_{2}=1$ , then ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\langle{\\pmb x}^{t+1}-{\\pmb x}^{t},\\,{\\pmb z}^{t}\\rangle\\,\\geq\\,\\frac{\\eta}{1+\\eta}\\Big(1-\\langle{\\pmb x}^{t},{\\pmb z}^{t}\\rangle\\Big).\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "Proof. By definition, ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\begin{array}{c}{\\displaystyle\\langle\\pmb{x}^{t+1}-\\pmb{x}^{t},\\,{y}\\rangle\\,=\\,\\Big\\langle\\frac{\\pmb{x}^{t}+\\eta\\pmb{z}^{t}}{\\|\\pmb{x}^{t}+\\eta\\pmb{z}^{t}\\|_{2}}-\\pmb{x}^{t},\\,{y}\\Big\\rangle}\\\\ {\\displaystyle=\\,\\Big(\\frac{1}{\\|\\pmb{x}^{t}+\\eta\\pmb{z}^{t}\\|_{2}}-1\\Big)\\cdot\\langle\\pmb{x}^{t},\\pmb{y}\\rangle\\,+\\,\\frac{\\eta}{\\|\\pmb{x}^{t}+\\eta\\pmb{z}^{t}\\|_{2}}\\cdot\\langle\\pmb{z}^{t},\\pmb{y}\\rangle}\\\\ {\\displaystyle\\mathrm{ic~}\\|\\pmb{x}^{t}+\\eta\\pmb{z}^{t}\\|_{2}\\le1+\\eta\\|\\pmb{z}^{t}\\|_{2}}\\end{array}}\\\\ {\\!\\!\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\Big|\\pmb{z}^{t}\\|_{2}}\\\\ {\\!=\\,\\frac{\\eta}{1+\\eta\\|\\pmb{z}^{t}\\|_{2}}\\Big(\\langle\\pmb{z}^{t},\\pmb{y}\\rangle-\\|\\pmb{z}^{t}\\|_{2}\\langle\\pmb{x}^{t},\\pmb{y}\\rangle\\Big).}\\end{array}\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "Lemma D.4. Let $\\pmb{x}^{t},\\pmb{z}^{t}\\in\\mathbb{R}^{d}$ be vectors with norm $\\|\\pmb{x}^{t}\\|_{2}=1$ , $\\|z^{t}\\|_{2}\\leq1$ . Suppose $\\langle\\pmb{x}^{t},\\pmb{z}^{t}\\rangle\\geq0$ and $\\eta>0$ . Then the update $\\mathbf{\\boldsymbol{x}}^{t+1}=\\mathcal{P}(\\mathbf{\\boldsymbol{x}}^{t}+\\eta\\boldsymbol{z}^{t})$ satisfies ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\bullet\\ \\langle\\pmb{x}^{t+1}-\\pmb{x}^{t},\\pmb{z}^{t}\\rangle\\geq\\frac{1}{\\eta}\\|\\pmb{x}^{t+1}-\\pmb{x}^{t}\\|_{2}^{2}.}\\\\ &{\\bullet\\ \\|\\pmb{x}^{t+1}-\\pmb{x}^{t}\\|_{2}\\leq\\ \\eta\\|\\pmb{z}^{t}\\|_{2}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "Proof. Let $\\tilde{\\pmb{x}}^{t+1}=\\pmb{x}^{t}+\\eta\\pmb{z}^{t}$ , so $\\pmb{x}^{t}=\\mathcal{P}(\\tilde{\\pmb{x}}^{t+1})$ and $\\begin{array}{r}{z^{t}=\\frac{1}{\\eta}(\\tilde{\\pmb{x}}^{t+1}-\\pmb{x}^{t})}\\end{array}$ . Then we have ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\langle{\\pmb x}^{t+1}-{\\pmb x}^{t},\\,{\\pmb z}^{t}\\rangle\\,=\\,\\frac{1}{\\eta}\\langle{\\pmb x}^{t+1}-{\\pmb x}^{t},\\,\\tilde{\\pmb x}^{t+1}-{\\pmb x}^{t}\\rangle.\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "Because $\\langle\\pmb{x}^{t},\\pmb{z}^{t}\\rangle\\geq0$ , the vector $\\tilde{\\pmb{x}}^{t+1}=\\pmb{x}^{t}+\\eta\\pmb{z}^{t}$ has length $\\geq1$ and hence is outside (or on the surface) of the $d$ -dimensional unit ball. Since $\\pmb{x}^{t}=\\mathcal{P}(\\tilde{\\pmb{x}}^{t+1})$ is the projection of $\\tilde{\\pmb{x}}^{t+1}$ onto the unit ball, and $z^{t}$ is another vector inside the unit ball, by the \u201cPythagorean property\u201d (Proposition 2.2 in [6]), we must have $\\langle\\pmb{x}^{t}-\\pmb{x}^{t+1},\\tilde{\\pmb{x}}^{t+1}-\\pmb{x}^{t+1}\\rangle\\leq0$ . This implies ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\langle{\\pmb x}^{t+1}-{\\pmb x}^{t},{\\pmb z}^{t}\\rangle\\,\\geq\\,\\frac{1}{\\eta}\\Big(\\langle{\\pmb x}^{t+1}-{\\pmb x}^{t},\\,\\tilde{{\\pmb x}}^{t+1}-{\\pmb x}^{t}\\rangle+\\langle{\\pmb x}^{t}-{\\pmb x}^{t+1},\\,\\tilde{{\\pmb x}}^{t+1}-{\\pmb x}^{t+1}\\rangle\\Big)}\\\\ &{\\qquad\\qquad\\qquad\\quad=\\,\\frac{1}{\\eta}\\langle{\\pmb x}^{t+1}-{\\pmb x}^{t},\\,{\\pmb x}^{t+1}-{\\pmb x}^{t}\\rangle\\,=\\,\\frac{1}{\\eta}\\|{\\pmb x}^{t+1}-{\\pmb x}^{t}\\|_{2}^{2},}\\end{array}\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "which proves the first claim. To prove the second claim, we use Cauchy-Schwarz inequality: ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\frac{1}{\\eta}\\|x^{t+1}-x^{t}\\|_{2}^{2}\\;\\leq\\;\\langle x^{t+1}-x^{t},\\,z^{t}\\rangle\\;\\leq\\;\\|x^{t+1}-x^{t}\\|_{2}\\|z^{t}\\|_{2}.\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "This implies $\\|{\\pmb x}^{t+1}-{\\pmb x}^{t}\\|_{2}\\leq\\eta\\|{\\pmb z}^{t}\\|_{2}$ . ", "page_idx": 21}, {"type": "text", "text": "Lemma D.5. Consider a creator $\\pmb{v}_{i}^{t}$ and a user $\\pmb{u}_{j}^{t}$ . Suppose the user is always recommended creator $i$ (so the user is updated by $\\pmb{u}_{j}^{t+1}=\\mathcal{P}(\\pmb{u}_{j}^{t}+\\eta_{u}f(\\pmb{v}_{i}^{t},\\pmb{u}_{j}^{t})\\pmb{v}_{i}^{t}))$ , and creator $i$ is updated by $\\pmb{v}_{i}^{t+1}=\\mathcal{P}(\\pmb{v}_{i}^{t}+\\eta_{c}\\pmb{\\alpha}_{i}^{t})$ with $\\|\\pmb{\\alpha}_{i}^{t}\\|_{2}\\leq1$ and $\\langle\\pmb{v}_{i}^{t},\\pmb{\\alpha}_{i}^{t}\\rangle\\geq0$ at each time step. Assume: ", "page_idx": 21}, {"type": "text", "text": "\u2022 The inner product $\\langle\\pmb{u}_{j}^{0},\\pmb{v}_{i}^{0}\\rangle>0$ initially. (Note that $\\langle{\\pmb u}_{j}^{0},{\\pmb u}_{j^{\\prime}}^{0}\\rangle$ needs not hold.) \u2022 There exists some constant $L_{f}>0$ such that $f(\\pmb{v}_{i},\\pmb{u}_{j})\\geq L_{f}>0$ whenever $\\langle\\pmb{u}_{j},\\pmb{v}_{i}\\rangle>0$ . \u2022 $\\begin{array}{r}{\\eta_{c}\\leq\\frac{\\eta_{u}L_{f}}{2}}\\end{array}$ and $0\\leq\\eta_{u}<\\frac{1}{2}$ . ", "page_idx": 21}, {"type": "text", "text": "Then, we have $\\langle\\boldsymbol{u}_{j}^{t},\\boldsymbol{v}_{i}^{t}\\rangle>0$ in all time steps. ", "page_idx": 21}, {"type": "text", "text": "Proof. We prove by induction. Suppose $\\langle\\boldsymbol{u}_{j}^{t},\\boldsymbol{v}_{i}^{t}\\rangle>0$ already holds. We prove that $\\langle\\pmb{u}_{j}^{t+1},\\pmb{v}_{i}^{t+1}\\rangle>0$ will also hold. Take the difference between $\\langle\\boldsymbol{u}_{j}^{t+1},\\boldsymbol{v}_{i}^{t+1}\\rangle$ and $\\langle\\boldsymbol{u}_{j}^{t},\\boldsymbol{v}_{i}^{t}\\rangle$ : ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\langle{\\pmb u}_{j}^{t+1},{\\pmb v}_{i}^{t+1}\\rangle-\\langle{\\pmb u}_{j}^{t},{\\pmb v}_{i}^{t}\\rangle\\,=\\,\\langle{\\pmb u}_{j}^{t+1},{\\pmb v}_{i}^{t+1}-{\\pmb v}_{i}^{t}\\rangle+\\langle{\\pmb u}_{j}^{t+1}-{\\pmb u}_{j}^{t},{\\pmb v}_{i}^{t}\\rangle.\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "For $\\langle{\\pmb u}_{j}^{t+1}-{\\pmb u}_{j}^{t},{\\pmb v}_{i}^{t}\\rangle$ , using Lemma D.3 with $\\pmb{x}^{t}=\\pmb{u}_{j}^{t},\\pmb{z}^{t}=\\pmb{v}_{i}^{t}$ , and $\\eta=\\eta_{u}f(\\pmb{v}_{i}^{t},\\pmb{u}_{j}^{t})$ , we get ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\langle\\boldsymbol u_{j}^{t+1}-\\boldsymbol u_{j}^{t},\\boldsymbol v_{i}^{t}\\rangle\\;\\geq\\;\\frac{\\eta_{u}f(\\boldsymbol v_{i}^{t},\\boldsymbol u_{j}^{t})}{1+\\eta_{u}f(\\boldsymbol v_{i}^{t},\\boldsymbol u_{j}^{t})}\\big(1-\\langle\\boldsymbol u_{j}^{t},\\boldsymbol v_{i}^{t}\\rangle\\big)\\;\\geq\\;\\frac{\\eta_{u}L_{f}}{1+\\eta_{u}L_{f}}\\big(1-\\langle\\boldsymbol u_{j}^{t},\\boldsymbol v_{i}^{t}\\rangle\\big).}\\end{array}\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "For $\\langle\\boldsymbol{u}_{j}^{t+1},\\boldsymbol{v}_{i}^{t+1}-\\boldsymbol{v}_{i}^{t}\\rangle$ , by Cauchy-Schwarz inequality and Lemma D.4, ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\langle u_{j}^{t+1},v_{i}^{t+1}-v_{i}^{t}\\rangle\\ \\geq\\ -\\ \\|u_{j}^{t+1}\\|_{2}\\cdot\\|v_{i}^{t+1}-v_{i}^{t}\\|_{2}\\ \\geq\\ -\\ 1\\cdot\\eta_{c}\\|\\pmb{\\alpha}_{i}^{t}\\|_{2}\\ \\geq\\ -\\ \\eta_{c}.\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "\u2022 If $\\begin{array}{r}{1-\\langle\\pmb{u}_{j}^{t},\\pmb{v}_{i}^{t}\\rangle>\\frac{1}{2}(1+\\eta_{u}L_{f})}\\end{array}$ , then we have ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\langle\\pmb{u}_{j}^{t+1},\\pmb{v}_{i}^{t+1}\\rangle-\\langle\\pmb{u}_{j}^{t},\\pmb{v}_{i}^{t}\\rangle\\ >\\ \\eta_{u}L_{f}\\frac{1}{2}-\\eta_{c}\\ \\geq0\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "by the assumption of $\\eta_{c}\\leq\\frac{\\eta_{u}L_{f}}{2}$ . ", "page_idx": 21}, {"type": "text", "text": "\u2022 If $\\begin{array}{r}{1-\\langle\\pmb{u}_{j}^{t},\\pmb{v}_{i}^{t}\\rangle\\le\\frac{1}{2}(1+\\eta_{u}L_{f})}\\end{array}$ , then we have ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\langle\\boldsymbol{u}_{j}^{t+1},\\boldsymbol{v}_{i}^{t+1}\\rangle-\\langle\\boldsymbol{u}_{j}^{t},\\boldsymbol{v}_{i}^{t}\\rangle\\ \\geq\\ 0-\\eta_{c}}\\\\ {\\implies}&{\\langle\\boldsymbol{u}_{j}^{t+1},\\boldsymbol{v}_{i}^{t+1}\\rangle\\ \\geq\\ \\langle\\boldsymbol{u}_{j}^{t},\\boldsymbol{v}_{i}^{t}\\rangle-\\eta_{c}\\ \\geq\\ \\frac12-\\frac{1}{2}\\eta_{u}L_{f}-\\eta_{c}\\ >\\ 0}\\end{array}\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "under the assumption of $\\begin{array}{r}{\\eta_{c}\\leq\\frac{\\eta_{u}L_{f}}{2}}\\end{array}$ and $\\begin{array}{r}{\\eta_{u}<\\frac{1}{2}}\\end{array}$ . ", "page_idx": 21}, {"type": "text", "text": "Lemma D.6. Consider a system of one user and one creator that satisfies $\\langle{\\pmb u}_{j}^{0},{\\pmb v}_{i}^{0}\\rangle\\;>\\;0$ and $\\langle{\\pmb u}_{j}^{0},{\\pmb y}\\rangle>\\langle{\\pmb v}_{i}^{0},{\\pmb y}\\rangle>0$ for some $\\pmb{y}\\in\\mathbb{R}^{d}\\,w i t h\\;\\|\\pmb{y}\\|\\leq1$ initially. The creator is always recommended to the user (so the updates are $\\pmb{u}_{j}^{t+1}=\\mathcal{P}(\\pmb{u}_{j}^{t}+\\eta_{u}f(\\pmb{v}_{i}^{t},\\pmb{u}_{j}^{t})\\pmb{v}_{i}^{t})$ and $\\pmb{v}_{i}^{t+1}=\\mathcal{P}(\\pmb{v}_{i}^{t}+\\eta_{c}\\pmb{u}_{j}^{t}))$ . Suppose $\\begin{array}{r}{\\eta_{c}\\leq\\frac{\\eta_{u}L_{f}}{2}}\\end{array}$ and $0\\leq\\eta_{u}<\\frac{1}{2}$ . Then, we have: ", "page_idx": 22}, {"type": "text", "text": "\u2022 $\\langle{\\pmb u}_{j}^{t},{\\pmb y}\\rangle>\\langle{\\pmb v}_{i}^{t},{\\pmb y}\\rangle>0\\,f o r\\,a l l\\,t\\geq1.$   \n\u2022 Suppose $\\langle{\\pmb u}_{j}^{0},{\\pmb y}\\rangle-\\langle{\\pmb v}_{i}^{0},{\\pmb y}\\rangle=D>0$ . For any $R<D$ , after $\\begin{array}{r}{T=\\frac{8}{3\\eta_{u}L_{f}}\\ln{\\frac{2}{R^{2}}}}\\end{array}$ steps, we have $\\begin{array}{r}{\\langle v_{i}^{T},y\\rangle-\\langle v_{i}^{0},y\\rangle\\ge\\frac{\\eta_{c}}{\\eta_{u}+\\eta_{c}}(D-R).}\\end{array}$ . ", "page_idx": 22}, {"type": "text", "text": "Proof. We prove the first item by induction. Suppose $\\langle{\\pmb u}_{j}^{t},{\\pmb y}\\rangle\\,>\\,\\langle{\\pmb v}_{i}^{t},{\\pmb y}\\rangle\\,>\\,0$ holds. Consider $t+1$ . First, by Lemma D.2, $\\langle{\\pmb v}_{i}^{t+1},{\\pmb y}\\rangle\\,>\\,0$ holds. Then, we prove $\\langle{\\pmb u}_{j}^{t+1},{\\pmb y}\\rangle\\,>\\,\\langle{\\pmb v}_{i}^{t+1},{\\pmb y}\\rangle$ . Let $f=f(\\pmb{v}_{i}^{t},\\pmb{u}_{j}^{t})$ . ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\langle u_{j}^{t+1},y\\rangle-\\langle v_{i}^{t+1},y\\rangle\\,=\\,\\Big\\langle\\frac{u_{j}^{t}+\\eta_{i}f v_{i}^{t}}{\\lVert u_{j}^{t}+\\eta_{i}f v_{i}^{t}\\rVert_{2}},y\\Big\\rangle-\\Big\\langle\\frac{v_{i}^{t}+\\eta_{i}\\kappa_{j}^{t}}{\\lVert v_{i}^{t}+\\eta_{i}\\kappa_{j}^{t}\\rVert_{2}},y\\Big\\rangle}\\\\ &{\\,=\\,\\Big(\\frac{1}{\\lVert u_{j}^{t}+\\eta_{i}f v_{i}^{t}\\rVert_{2}}-\\frac{\\eta_{i}}{\\lVert v_{i}^{t}+\\eta_{i}u_{j}^{t}\\rVert_{2}}\\Big)\\langle u_{j}^{t},y\\rangle-\\Big(\\frac{1}{\\lVert v_{i}^{t}+\\eta_{i}u_{j}^{t}\\rVert_{2}}-\\frac{\\eta_{u}f}{\\lVert u_{j}^{t}+\\eta_{i}f v_{i}^{t}\\rVert_{2}}\\Big)\\langle v_{i}^{t},y\\rangle}\\\\ &{\\,>\\,\\Big(\\frac{1}{\\lVert u_{j}^{t}+\\eta_{i}f v_{i}^{t}\\rVert_{2}}-\\frac{\\eta_{c}}{\\lVert v_{i}^{t}+\\eta_{i}u_{j}^{t}\\rVert_{2}}\\Big)\\langle v_{i}^{t},y\\rangle-\\Big(\\frac{1}{\\lVert v_{i}^{t}+\\eta_{i}u_{j}^{t}\\rVert_{2}}-\\frac{\\eta_{u}f}{\\lVert u_{j}^{t}+\\eta_{u}f v_{i}^{t}\\rVert_{2}}\\Big)\\langle v_{i}^{t},y\\rangle}\\\\ &{\\,=\\,\\Big(\\frac{1+\\eta_{u}f}{\\lVert u_{j}^{t}+\\eta_{u}f v_{i}^{t}\\rVert_{2}}-\\frac{1+\\eta_{c}}{\\lVert v_{i}^{t}+\\eta_{i}u_{j}^{t}\\rVert_{2}}\\Big)\\langle v_{i}^{t},y\\rangle}\\\\ &{\\,=\\,\\Big(\\frac{1+\\eta_{n}f}{\\sqrt{1+2\\eta_{n}f}\\langle u_{j}^{t},v_{i}^{t}\\rangle+(\\eta_{n}f)^{2}}-\\frac{1+\\eta_{c}}{\\sqrt{1+2\\eta_{c}\\langle u_{j}^{t},v_{i}^ \n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "Let $a=\\langle\\pmb{u}_{j}^{t},\\pmb{v}_{i}^{t}\\rangle\\leq1$ . We note that the function ", "page_idx": 22}, {"type": "equation", "text": "$$\nh(\\eta)=\\frac{1+\\eta}{\\sqrt{1+2\\eta a+\\eta^{2}}}=\\sqrt{\\frac{1+2\\eta+\\eta^{2}}{1+2\\eta a+\\eta^{2}}}=\\sqrt{1+\\frac{(2-2a)\\eta}{1+2\\eta a+\\eta^{2}}}=\\sqrt{1+\\frac{2(1-a)}{\\frac{1}{\\eta}+2a+\\eta}},\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "is increasing in $\\eta\\in[0,1]$ . Under the assumption of $\\begin{array}{r}{\\eta_{c}\\,\\le\\,\\frac{\\eta_{u}L_{f}}{2}\\,\\le\\,\\frac{\\eta_{u}f}{2}\\,<\\,\\eta_{u}f}\\end{array}$ , we have $h(\\eta_{c})\\leq$ $h(\\eta_{u}f)$ and hence ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\langle\\pmb{u}_{j}^{t+1},\\pmb{y}\\rangle-\\langle\\pmb{v}_{i}^{t+1},\\pmb{y}\\rangle\\;>\\;\\big(h(\\eta_{u}f)-h(\\eta_{c})\\big)\\langle\\pmb{v}_{i}^{t},\\pmb{y}\\rangle\\;\\ge\\;0.\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "We then prove the second item. Using Lemma D.3 for $\\pmb{v}_{i}^{t+1}=\\mathcal{P}(\\pmb{v}_{i}^{t}+\\eta_{c}\\pmb{u}_{j}^{t})$ , we get ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\langle\\boldsymbol{v}_{i}^{t+1}-\\boldsymbol{v}_{i}^{t},\\boldsymbol{y}\\rangle\\ge\\frac{\\eta_{c}}{1+\\eta_{c}}\\Big(\\langle\\boldsymbol{u}_{j}^{t},\\boldsymbol{y}\\rangle-\\langle\\boldsymbol{v}_{i}^{t},\\boldsymbol{y}\\rangle\\Big).\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "Using Lemma D.3 for $\\pmb{u}_{j}^{t+1}=\\mathcal{P}(\\pmb{u}_{j}^{t}+\\eta_{u}f(\\pmb{v}_{i}^{t},\\pmb{u}_{j}^{t})\\pmb{v}_{i}^{t})$ and using the fact $\\langle\\pmb{v}_{i}^{t},\\pmb{y}\\rangle-\\langle\\pmb{u}_{j}^{t},\\pmb{y}\\rangle<0$ proved in item 1, ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\langle\\boldsymbol{u}_{j}^{t+1}-\\boldsymbol{u}_{j}^{t},\\boldsymbol{y}\\rangle\\ge\\frac{\\eta_{u}f(\\boldsymbol{v}_{i}^{t},\\boldsymbol{u}_{j}^{t})}{1+\\eta_{u}f(\\boldsymbol{v}_{i}^{t},\\boldsymbol{u}_{j}^{t})}\\Big(\\langle\\boldsymbol{v}_{i}^{t},\\boldsymbol{y}\\rangle-\\langle\\boldsymbol{u}_{j}^{t},\\boldsymbol{y}\\rangle\\Big)\\ge\\frac{\\eta_{u}}{1+\\eta_{u}}\\Big(\\langle\\boldsymbol{v}_{i}^{t},\\boldsymbol{y}\\rangle-\\langle\\boldsymbol{u}_{j}^{t},\\boldsymbol{y}\\rangle\\Big).\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "Rearranging the above two inequalities: ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\frac{1+\\eta_{c}}{\\eta_{c}}\\Big(\\langle\\boldsymbol v_{i}^{t+1},\\boldsymbol y\\rangle-\\langle\\boldsymbol v_{i}^{t},\\boldsymbol y\\rangle\\Big)\\geq\\langle\\boldsymbol u_{j}^{t},\\boldsymbol y\\rangle-\\langle\\boldsymbol v_{i}^{t},\\boldsymbol y\\rangle;}\\\\ &{\\frac{1+\\eta_{u}}{\\eta_{u}}\\Big(\\langle\\boldsymbol u_{j}^{t+1},\\boldsymbol y\\rangle-\\langle\\boldsymbol u_{j}^{t},\\boldsymbol y\\rangle\\Big)\\geq\\langle\\boldsymbol v_{i}^{t},\\boldsymbol y\\rangle-\\langle\\boldsymbol u_{j}^{t},\\boldsymbol y\\rangle.}\\end{array}\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "Summing the above two inequalities over $t=0,1,\\ldots,T-1$ : ", "page_idx": 23}, {"type": "equation", "text": "$$\n\\frac{1+\\eta_{c}}{\\eta_{c}}\\Big(\\langle\\boldsymbol{v}_{i}^{T},\\boldsymbol{y}\\rangle-\\langle\\boldsymbol{v}_{i}^{0},\\boldsymbol{y}\\rangle\\Big)+\\frac{1+\\eta_{u}}{\\eta_{u}}\\Big(\\langle\\boldsymbol{u}_{j}^{T},\\boldsymbol{y}\\rangle-\\langle\\boldsymbol{u}_{j}^{0},\\boldsymbol{y}\\rangle\\Big)\\geq0.\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "According to Lemma F.1, after at most T = 3\u03b7u8Lf l steps, we have $\\|\\pmb{u}_{j}^{T}-\\pmb{v}_{i}^{T}\\|_{2}\\leq R$ . This implies $\\langle\\pmb{u}_{j}^{T},\\pmb{y}\\rangle-\\langle\\pmb{v}_{i}^{T},\\pmb{y}\\rangle=\\langle\\pmb{u}_{j}^{T}-\\pmb{v}_{i}^{T},\\pmb{y}\\rangle\\leq\\|\\pmb{u}_{j}^{T}-\\pmb{v}_{i}^{T}\\|\\leq R$ and hence ", "page_idx": 23}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\langle v_{i}^{T},y\\rangle-\\langle v_{i}^{0},y\\rangle\\Big)-\\Big(\\langle u_{j}^{T},y\\rangle-\\langle u_{j}^{0},y\\rangle\\Big)=\\Big(\\langle u_{j}^{0},y\\rangle-\\langle v_{i}^{0},y\\rangle\\Big)-\\Big(\\langle u_{j}^{T},y\\rangle-\\langle v_{i}^{T},y\\rangle\\Big)\\geq D-R.}\\end{array}\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "Multiplying (7) by $\\begin{array}{r}{\\frac{1+\\eta_{u}}{\\eta_{u}}}\\end{array}$ and adding to (6): ", "page_idx": 23}, {"type": "equation", "text": "$$\n\\Big(\\frac{1+\\eta_{c}}{\\eta_{c}}+\\frac{1+\\eta_{u}}{\\eta_{u}}\\Big)\\Big(\\langle v_{i}^{T},y\\rangle-\\langle v_{i}^{0},y\\rangle\\Big)\\geq\\frac{1+\\eta_{u}}{\\eta_{u}}(D-R).\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "This implies ", "page_idx": 23}, {"type": "equation", "text": "$$\nv_{i}^{T},y\\rangle-\\langle v_{i}^{0},y\\rangle\\ge\\frac{\\frac{1+\\eta_{u}}{\\eta_{u}}}{\\frac{1+\\eta_{c}}{\\eta_{c}}+\\frac{1+\\eta_{u}}{\\eta_{u}}}(D-R)=\\frac{\\eta_{c}(1+\\eta_{u})}{\\eta_{u}(1+\\eta_{c})+\\eta_{c}(1+\\eta_{u})}(D-R)\\ge\\frac{\\eta_{c}}{\\eta_{u}+\\eta_{c}}(D-R).\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "given $\\eta_{c}\\leq\\eta_{u}$ . ", "page_idx": 23}, {"type": "text", "text": "The following lemma shows that, when we reflect some of the feature vectors in a system $(U^{t},V^{t})=$ $\\big(\\{\\pmb{u}_{j}^{t}\\}_{j\\in[m]},\\bar{\\{\\pmb{v}_{i}^{t}\\}}_{i\\in[n]}\\big)$ , there is a correspondence between the behaviors of the system with the reflected vectors and the original system. ", "page_idx": 23}, {"type": "text", "text": "Lemma D.7 (Reflection). Let $(U^{t},V^{t})\\,=\\,(\\{\\pmb{u}_{j}^{t}\\}_{j\\in[m]},\\{\\pmb{v}_{i}^{t}\\}_{i\\in[n]})$ be a system of m users and $n$ creators with impact functions $f,g$ . Let $a_{i},b_{j}\\,\\in\\,\\{+1,-1\\}$ , $\\forall i\\in[n]$ , $\\forall i\\in[m]$ be some binary constants. Define: ", "page_idx": 23}, {"type": "equation", "text": "$$\n\\tilde{\\pmb u}_{j}^{t}=b_{j}\\pmb u_{j}^{t}=\\pm\\pmb u_{j}^{t},\\qquad\\tilde{\\pmb v}_{i}^{t}=a_{i}\\pmb v_{i}^{t}=\\pmb\\pmb\\delta_{i}^{t}.\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "and impact functions ", "page_idx": 23}, {"type": "equation", "text": "$$\n\\tilde{f}(\\tilde{v}_{i},\\tilde{u}_{j})=a_{i}b_{j}f(v_{i},u_{j}),\\qquad\\tilde{g}(\\tilde{u}_{j},\\tilde{v}_{i})=a_{i}b_{j}g(u_{j},v_{i}).\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "Then: ", "page_idx": 23}, {"type": "text", "text": "\u2022 There is a \u201ccorrespondence\u201d between the evolution of the system $(U^{t},V^{t})$ with impact functions $f,g$ and the evolution of the system $(\\tilde{U}^{t},\\tilde{V}^{t})\\;=\\;(\\{\\tilde{\\pmb{u}}_{j}^{t}\\}_{j\\in[m]},\\{\\tilde{\\pmb{v}}_{i}^{t}\\}_{i\\in[n]})$ with impact functions $\\tilde{f},\\tilde{g}$ . Formally, suppose every user is recommended the same creator in the two systems, then the updated vectors in the two systems still satisfy the relations: $\\Tilde{\\pmb{u}}_{j}^{t+1}=b_{j}\\pmb{u}_{j}^{\\dot{t}+1}$ $\\pmb{\\tilde{v}}_{i}^{t+1}=a_{i}\\pmb{v}_{i}^{t+1}$ ", "page_idx": 23}, {"type": "text", "text": "\u2022 If the system $(\\tilde{U}^{t},\\tilde{V}^{t})$ is in $R$ -bi-polarization, then the original system $(U^{t},V^{t})$ is also in $R$ -bi-polarization. ", "page_idx": 23}, {"type": "text", "text": "Proof. Consider the first item. Suppose user $i$ is recommended creator $j$ at time step $t$ in the two systems. Then by definition, the updated user vectors in the two systems satisfy ", "page_idx": 23}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\tilde{u}_{j}^{t+1}\\;=\\;\\mathcal{P}\\big(\\tilde{u}_{j}^{t}+\\eta_{u}\\tilde{f}(\\tilde{v}_{i}^{t},\\tilde{u}_{j}^{t})\\tilde{v}_{i}^{t}\\big)\\;=\\;\\mathcal{P}\\big(b_{j}{u}_{j}^{t}+\\eta_{u}a_{i}b_{j}f({v}_{i}^{t},{u}_{j}^{t})a_{i}{v}_{i}^{t}\\big)}\\\\ &{\\qquad\\;=\\;\\mathcal{P}\\big(b_{j}{u}_{j}^{t}+\\eta_{u}b_{j}f({v}_{i}^{t},{u}_{j}^{t}){v}_{i}^{t}\\big)\\;=\\;b_{j}\\mathcal{P}\\big({u}_{j}^{t}+\\eta_{u}f({v}_{i}^{t},{u}_{j}^{t}){v}_{i}^{t}\\big)\\;=\\;b_{j}{u}_{j}^{t+1}}\\end{array}\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "Suppose creator $i$ is recommended to the set of users $J$ at time step $t$ in the two systems. Then, ", "page_idx": 23}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\tilde{v}_{i}^{t+1}\\;=\\;\\mathcal{P}\\big(\\tilde{v}_{i}^{t}+\\frac{\\eta_{c}}{|J|}\\displaystyle\\sum_{j\\in J}g(\\tilde{u}_{j}^{t},\\tilde{v}_{i}^{t})\\tilde{u}_{j}^{t}\\big)}\\\\ &{\\qquad=\\;\\mathcal{P}\\big(a_{i}v_{i}^{t}+\\frac{\\eta_{c}}{|J|}\\displaystyle\\sum_{j\\in J}a_{i}b_{j}g(u_{j}^{t},v_{i}^{t})b_{j}u_{j}^{t}\\big)}\\\\ &{\\qquad=\\;\\mathcal{P}\\big(a_{i}v_{i}^{t}+\\frac{\\eta_{c}}{|J|}\\displaystyle\\sum_{j\\in J}a_{i}g(u_{j}^{t},v_{i}^{t})u_{j}^{t}\\big)}\\\\ &{\\qquad=\\;a_{i}\\mathcal{P}\\big(v_{i}^{t}+\\frac{\\eta_{c}}{|J|}\\displaystyle\\sum_{j\\in J}g(u_{j}^{t},v_{i}^{t})u_{j}^{t}\\big)\\;=\\;a_{i}v_{i}^{t+1}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "This means that the evolution of the system $(\\tilde{U}^{t},\\tilde{V}^{t})$ has a correspondence to the evolution of the original system $(U^{t},V^{t})$ . ", "page_idx": 24}, {"type": "text", "text": "Consider the second item. Suppose $(\\tilde{U}^{t},\\tilde{V}^{t})$ is in $R$ -bi-polarization, so $\\pmb{\\tilde{v}}_{i}^{t}=\\pmb{\\pmb{v}}_{i}^{t}$ is $R$ -close to $\\pm c$ and $\\tilde{\\pmb{u}}_{j}^{t}=\\pm\\pmb{u}_{j}^{t}$ is $R$ -close to $\\pm c$ with some vector $c\\in\\mathbb{S}^{d-1}$ . This implies that $\\pmb{v}_{i}^{t}$ is $R$ -close to $\\pm c$ and $\\pmb{u}_{j}^{t}$ is $R$ -close to $\\pm c$ . So, the system $(U^{t},V^{t})$ satisfies $R$ -bi-polarization. \u53e3 ", "page_idx": 24}, {"type": "text", "text": "E Proof of Proposition 3.2 ", "text_level": 1, "page_idx": 24}, {"type": "text", "text": "Proof. Let $(U^{t},V^{t})$ be an $(R,c)$ -bi-polarization state with $R\\in[0,1]$ and $c\\in\\mathbb{S}^{d-1}$ , where all $\\pmb{u}_{j}^{t}$ and $\\pmb{v}_{i}^{t}$ are within distance $R$ to $+c$ or $-c$ . We show that, after one step of update, $\\pmb{u}_{j}^{t+1}$ and $\\pmb{v}_{i}^{t+1}$ are still within distance $R$ to $+c$ or $-c$ , so $(\\pmb{U}^{t+1},\\pmb{V}^{t+1})$ still satisfies $(R,c)$ -bi-polarization. ", "page_idx": 24}, {"type": "text", "text": "Consider $\\pmb{u}_{j}^{t}$ . Without loss of generality, suppose $\\pmb{u}_{j}^{t}$ is close to $+c$ , so $\\|\\pmb{u}_{j}^{t}-\\pmb{c}\\|_{2}\\leq R$ . Suppose user $j$ is recommended creator $i$ at step $t$ . Let $\\tilde{\\pmb{v}}_{i}^{t}={\\pmb{v}}_{i}^{t}$ if $\\langle\\pmb{v}_{i}^{t},\\pmb{u}_{j}^{t}\\rangle\\geq0$ and $\\tilde{\\pmb{v}}_{i}^{t}=-{\\pmb{v}}_{i}^{t}$ if $\\langle\\pmb{v}_{i}^{t},\\pmb{u}_{j}^{t}\\rangle<0$ . Then, the user update is ", "page_idx": 24}, {"type": "equation", "text": "$$\n\\pmb{u}_{j}^{t+1}=\\mathcal{P}\\Big(\\pmb{u}_{j}^{t}+\\eta_{u}f(\\pmb{v}_{i}^{t},\\pmb{u}_{j}^{t})\\pmb{v}_{i}^{t}\\Big)=\\mathcal{P}\\Big(\\pmb{u}_{j}^{t}+\\eta_{u}|f(\\pmb{v}_{i}^{t},\\pmb{u}_{j}^{t})|\\tilde{\\pmb{v}}_{i}^{t}\\Big).\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "Since $\\tilde{\\pmb{v}}_{i}^{t}$ is close to $+c$ or $-c$ , $\\langle\\tilde{{\\pmb v}}_{i}^{t},{\\pmb u}_{j}^{t}\\rangle>0$ , and $\\pmb{u}_{j}^{t}$ is close to $+c$ , it must be that $\\tilde{\\pmb{v}}_{i}^{t}$ is close to $+c$ , so $\\|\\tilde{\\pmb{v}}_{i}^{t}-\\pmb{c}\\|_{2}\\leq R$ . Then, since utj+1is the normalization of a vector in the convex cone formed by $\\pmb{u}_{j}^{t}$ and $\\tilde{\\pmb{v}}_{i}^{t}$ , by Lemma D.2, we have ", "page_idx": 24}, {"type": "equation", "text": "$$\n\\|u_{j}^{t+1}-c\\|_{2}\\;\\leq\\;\\operatorname*{max}\\left\\{\\|u_{j}^{t}-c\\|_{2},\\;\\|\\tilde{v}_{i}^{t}-c\\|_{2}\\right\\}\\;\\leq\\;R.\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "Consider $\\pmb{v}_{i}^{t}$ . Suppose $\\|\\pmb{v}_{i}^{t}-\\pmb{c}\\|_{2}\\leq R$ . Let $J$ be the set of users that are recommended creator $i$ at step $t$ . For each $j\\in J$ , let $\\tilde{\\pmb{u}}_{j}^{t}=\\pmb{u}_{j}^{t}$ if $\\langle\\pmb{u}_{j}^{t},\\pmb{v}_{i}^{t}\\rangle\\geq0$ and $\\tilde{\\pmb{u}}_{j}^{t}=-\\pmb{u}_{j}^{t}$ if $\\langle\\boldsymbol{u}_{j}^{t},\\boldsymbol{v}_{i}^{t}\\rangle<0$ . Then, the creator update is ", "page_idx": 24}, {"type": "equation", "text": "$$\nv_{i}^{t+1}=\\mathcal{P}\\Big(v_{i}^{t}+\\frac{\\eta_{c}}{|J|}\\sum_{j\\in J}g(u_{j}^{t},v_{i}^{t})u_{j}^{t}\\Big)=\\mathcal{P}\\Big(v_{i}^{t}+\\frac{\\eta_{c}}{|J|}\\sum_{j\\in J}|g(u_{j}^{t},v_{i}^{t})|\\tilde{u}_{j}^{t}\\Big).\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "We note that every $\\tilde{\\pmb{u}}_{j}^{t}$ satisfies $\\|\\tilde{\\pmb{u}}_{j}^{t}-\\pmb{c}\\|_{2}\\leq R$ (by the same reasoning as above). Then, since $\\pmb{v}_{i}^{t+1}$ is the normalization of a vector in the convex cone formed by $\\pmb{v}_{i}^{t}$ and $\\{\\Tilde{u}_{j}^{t}\\}_{j\\in J}$ , by Lemma D.2, we have ", "page_idx": 24}, {"type": "equation", "text": "$$\n\\|v_{i}^{t+1}-c\\|_{2}\\;\\leq\\;\\operatorname*{min}\\left\\{\\|v_{i}^{t}-c\\|_{2},\\;\\operatorname*{min}_{j\\in J}\\|\\tilde{u}_{j}^{t}-c\\|_{2}\\right\\}\\;\\leq\\;R.\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "F Proof of Lemma 3.4 ", "text_level": 1, "page_idx": 24}, {"type": "text", "text": "Lemma 3.4 is proved by induction on the number $n$ of creators. We first show that any system with 1 creator and multiple users must converge to $R$ -bi-polarization in finite steps for any $R>0$ . Using the result for 1 creator, we then construct a finite length path that leads to $R$ -bi-polarization for any system with $n\\geq2$ creators. ", "page_idx": 24}, {"type": "text", "text": "F.1 Base Case: Convergence Results for $n=1$ Creator ", "text_level": 1, "page_idx": 24}, {"type": "text", "text": "We prove some convergence results for the special case of only one creator. This will serve as the basis for the proof for $n\\geq2$ creators. Recall that we have the following dynamics update rule: ", "page_idx": 24}, {"type": "text", "text": "\u2022 User: $\\pmb{u}_{j}^{t+1}=\\mathcal{P}(\\pmb{u}_{j}^{t}+\\eta_{u}f(\\pmb{v}_{i}^{t},\\pmb{u}_{j}^{t})\\pmb{v}_{i}^{t})$ where $\\pmb{v}_{i}^{t}$ is the creator recommended to user $j$ ; $f(v_{i},u_{j})$ satisfies: ", "page_idx": 24}, {"type": "equation", "text": "$$\nf(v_{i},\\mathbf{u}_{j})\\;\\mathrm{{is}\\ \\left\\{\\begin{array}{l l}{>0}&{\\mathrm{~if~}\\langle v_{i},\\mathbf{u}_{j}\\rangle>0}\\\\ {<0}&{\\mathrm{~if~}\\langle v_{i},\\mathbf{u}_{j}\\rangle<0}\\\\ {=0}&{\\mathrm{~if~}\\langle v_{i},\\mathbf{u}_{j}\\rangle=0.}\\end{array}\\right.}\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "\u2022 Creator: $\\begin{array}{r}{\\pmb{v}_{i}^{t+1}=\\mathcal{P}(\\pmb{v}_{j}^{t}+\\frac{\\eta_{c}}{|J|}\\sum_{j\\in J}g(\\pmb{u}_{j}^{t},\\pmb{v}_{i}^{t})\\pmb{u}_{j}^{t})}\\end{array}$ where $J$ is the set of users being recommended creator $i$ . ", "page_idx": 24}, {"type": "text", "text": "Lemma F.1. Consider a system of 1 creator $\\pmb{v}_{i}^{t}$ and $|J|$ users $\\{\\boldsymbol{u}_{j}^{t}\\}_{j\\in J}$ , where the creator is recommended to all users at every time step. Assume: ", "page_idx": 25}, {"type": "text", "text": "\u2022 Initially, $\\forall j\\in J,\\langle\\pmb{u}_{j}^{0},\\pmb{v}_{i}^{0}\\rangle>0$ .   \n\u2022 There exists some constant $L_{f}>0$ such that $f(\\pmb{v}_{i},\\pmb{u}_{j})\\geq L_{f}>0$ whenever $\\langle{\\pmb v}_{i},{\\pmb u}_{j}\\rangle>0$ . $;\\ g(u_{j},v_{i})=1\\ w h e n\\left<\\mathbf{u}_{j},v_{i}\\right>>0.$   \n\u2022 $\\begin{array}{r}{\\eta_{c}\\leq\\frac{\\eta_{u}L_{f}}{2}}\\end{array}$ and $\\begin{array}{r}{0\\leq\\eta_{u}<\\frac{1}{2}}\\end{array}$ . ", "page_idx": 25}, {"type": "text", "text": "Then, for any R > 0, after at most3\u03b7u8Lf $\\frac{8}{3\\eta_{u}L_{f}}\\ln\\frac{2|J|}{R^{2}}$ steps, $\\begin{array}{r}{\\sum_{j\\in J}\\|\\pmb{u}_{j}^{t}-\\pmb{v}_{i}^{t}\\|_{2}^{2}\\leq R^{2}}\\end{array}$ will hold forever. In particular, each user vector will satisfy $\\|\\pmb{u}_{j}^{t}-\\pmb{v}_{i}^{t}\\|_{2}\\leq R$ . ", "page_idx": 25}, {"type": "text", "text": "Proof. We first note that, by Lemma D.5, all user vectors satisfy $\\langle{\\pmb u}_{j}^{t},{\\pmb v}_{i}^{t}\\rangle\\,>\\,0$ in all time steps $t\\,>\\,0$ . Hence, the creator update is always $\\begin{array}{r}{v_{i}^{t+1}\\,=\\,\\mathcal{P}(v_{i}^{t}+\\frac{\\eta_{c}}{|J|}\\sum_{j\\in J}g(\\pmb{u}_{j}^{t},v_{i}^{t})\\pmb{u}_{j}^{t})\\,=\\,\\mathcal{P}(\\pmb{v}_{i}^{t}+}\\end{array}$ $\\eta_{c}\\frac{1}{|J|}\\sum_{j\\in J}\\pmb{u}_{j}^{t})$ . ", "page_idx": 25}, {"type": "text", "text": "Let $\\begin{array}{r}{a_{t}=1/(1-\\frac{3\\eta_{u}L_{f}}{8})^{t}}\\end{array}$ . Define the following potential function: ", "page_idx": 25}, {"type": "equation", "text": "$$\n\\Phi^{t}\\;=\\;a_{t}\\sum_{j\\in J}\\frac{1}{2}\\|{\\boldsymbol u}_{j}^{t}-{\\boldsymbol v}_{i}^{t}\\|_{2}^{2}\\;=\\;a_{t}\\sum_{j\\in J}\\big(1-\\langle{\\boldsymbol u}_{j}^{t},{\\boldsymbol v}_{i}^{t}\\rangle\\big).\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "We will show that $\\Phi^{t}$ is monotonically decreasing. Take the difference between $\\Phi^{t+1}$ and $\\Phi^{t}$ : ", "page_idx": 25}, {"type": "equation", "text": "$$\n\\begin{array}{r c l}{{\\Phi^{t+1}-\\Phi^{t}\\,=\\,a_{t+1}\\displaystyle\\sum_{j\\in J}\\left(\\langle u_{j}^{t},v_{i}^{t}\\rangle-\\langle u_{j}^{t+1},v_{i}^{t+1}\\rangle\\right)\\,+\\,\\left(a_{t+1}-a_{t}\\right)\\displaystyle\\sum_{j\\in J}\\left(1-\\langle u_{j}^{t},v_{i}^{t}\\rangle\\right)}}&{{}}\\\\ {{}}&{{=\\,a_{t+1}\\displaystyle\\left(\\sum_{j\\in J}\\langle v_{i}^{t},u_{j}^{t}-u_{j}^{t+1}\\rangle+\\displaystyle\\sum_{j\\in J}\\langle u_{j}^{t},v_{i}^{t}-v_{i}^{t+1}\\rangle+\\displaystyle\\sum_{j\\in J}\\langle u_{j}^{t+1}-u_{j}^{t},v_{i}^{t}-v_{i}^{t+1}\\rangle\\right)}}&{{}}\\\\ {{}}&{{}}&{{+\\,\\left(a_{t+1}-a_{t}\\right)\\displaystyle\\sum_{j\\in J}\\left(1-\\langle u_{j}^{t},v_{i}^{t}\\rangle\\right).}}\\end{array}\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "Using Lemma D.3 with $\\pmb{x}^{t}=\\pmb{u}_{j}^{t}$ , $\\boldsymbol{z}^{t}=\\boldsymbol{v}_{i}^{t}$ , and $\\eta=\\eta_{u}f(\\pmb{v}_{i}^{t},\\pmb{u}_{j}^{t})$ , we get ", "page_idx": 25}, {"type": "equation", "text": "$$\n\\langle v_{i}^{t},u_{j}^{t}-u_{j}^{t+1}\\rangle\\ \\leq\\ -\\ \\frac{\\eta_{u}f(v_{i}^{t},u_{j}^{t})}{1+\\eta_{u}f(v_{i}^{t},u_{j}^{t})}\\big(1-\\langle u_{j}^{t},v_{i}^{t}\\rangle\\big)\\ \\leq\\ -\\ \\frac{\\eta_{u}L_{f}}{2}\\big(1-\\langle u_{j}^{t},v_{i}^{t}\\rangle\\big).\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "Using Lemma D.4 with $\\pmb{x}^{t}=\\pmb{u}_{j}^{t}$ , $\\boldsymbol{z}^{t}=\\pmb{v}_{i}^{t}$ , and $\\eta=\\eta_{u}f(\\pmb{v}_{i}^{t},\\pmb{u}_{j}^{t})$ , we get ", "page_idx": 25}, {"type": "equation", "text": "$$\n\\langle v_{i}^{t},u_{j}^{t}-u_{j}^{t+1}\\rangle\\ \\leq\\ -\\ \\frac{1}{\\eta_{u}f(v_{i}^{t},u_{j}^{t})}\\|u_{j}^{t+1}-u_{j}^{t}\\|_{2}^{2}\\ \\leq\\ -\\ \\frac{1}{\\eta_{u}}\\|u_{j}^{t+1}-u_{j}^{t}\\|_{2}^{2}.\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "Using Lemma D.4 with ${\\boldsymbol{x}}^{t}={\\boldsymbol{v}}_{i}^{t}$ , $\\begin{array}{r}{\\boldsymbol{z}^{t}=\\frac{1}{|J|}\\sum_{j\\in J}\\boldsymbol{u}_{j}^{t}}\\end{array}$ , and $\\eta=\\eta_{c}$ , we get ", "page_idx": 25}, {"type": "equation", "text": "$$\n\\sum_{j\\in J}\\langle u_{j}^{t},v_{i}^{t}-v_{i}^{t+1}\\rangle\\;=\\;|J|\\langle\\frac{1}{|J|}\\sum_{j\\in J}u_{j}^{t},v_{i}^{t}-v_{i}^{t+1}\\rangle\\;\\leq\\;-\\;\\frac{|J|}{\\eta_{c}}\\|v_{i}^{t+1}-v_{i}^{t}\\|_{2}^{2}.\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "Using the above three inequalities, we can upper bound $\\Phi^{t+1}-\\Phi^{t}$ : ", "page_idx": 26}, {"type": "text", "text": "\u03a6t+1 \u2212\u03a6t ", "page_idx": 26}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\lefteqn{-\\sigma_{\\theta+1}\\bigg(\\frac{\\lambda_{1}}{4}\\sum_{j\\in\\mathcal{I}_{t}^{t}}(x_{j}^{t},u_{j}^{t},u_{j}^{t}-u_{j}^{t})+\\frac{\\lambda_{2}}{4}\\sum_{j\\in\\mathcal{I}_{t}^{t}}(x_{j}^{t},u_{j}^{t}-u_{j}^{t})^{\\frac{1}{2}}}\\bigg)}\\quad}&{}\\\\ &{\\qquad+\\sum_{j\\in\\mathcal{I}_{t}^{t}}(x_{j}^{t},u_{j}^{t}-u_{j}^{t})+\\frac{\\lambda_{2}}{2}\\sum_{j\\in\\mathcal{I}_{t}^{t}}(x_{j}^{t+1}-u_{j}^{t})\\sigma_{j}^{\\top}-u_{j}^{t+1}\\bigg)+(\\mu_{1}+-\\mu_{2})\\sum_{j\\in\\mathcal{I}_{t}^{t}}(-\\mu_{1})^{\\frac{1}{2}}}\\\\ &{\\leq\\mu_{1}+\\bigg(-\\frac{\\lambda_{2}}{4}\\sum_{j\\in\\mathcal{I}_{t}^{t}}\\frac{\\lambda_{1}}{4}L_{1}\\big(-(u_{j}^{t},u_{j}^{t})\\big)-\\frac{\\lambda_{2}}{4}\\sum_{j\\in\\mathcal{I}_{t}^{t}}\\frac{\\lambda_{1}}{4}\\mu_{1}^{\\beta_{1}}-u_{j}^{t+1}\\sigma_{j}^{\\top}\\bigg)+\\frac{(\\mu_{1}+1)}{4}}\\\\ &{\\qquad-\\frac{\\lambda_{2}}{8}\\bigg[\\mu_{1}^{\\beta}u_{j}^{t}-u_{j}^{t}\\bigg]+\\sum_{j\\in\\mathcal{I}_{t}^{t}}\\frac{u_{j}^{t+1}-u_{j}^{t}}{2}\\bigg[\\mu_{1}^{\\beta}u_{j}^{t+1}-u_{j}^{t}\\bigg]\\sigma_{j}^{\\top}+\\sigma_{\\theta+1}(\\mu_{1}-u_{j})\\sum_{j\\in\\mathcal{I}_{t}^{t}}(-\\mu_{1})}\\\\ &{=\\mu_{1}+\\bigg(-\\frac{\\lambda_{2}}{8}L_{2}\\bigg)\\sum_{j\\in\\mathcal{I}_{t}^{t}}(-u_{j}^{t},u_ \n$$", "text_format": "latex", "page_idx": 26}, {"type": "text", "text": "= 0 ", "page_idx": 26}, {"type": "text", "text": "where the last step is because $\\begin{array}{r}{(1-\\frac{3\\eta_{u}L_{f}}{8})a_{t+1}=a_{t}}\\end{array}$ ", "page_idx": 26}, {"type": "text", "text": "We have shown that $\\Phi^{t}$ is monotonically decreasing. Thus, ", "page_idx": 26}, {"type": "equation", "text": "$$\n\\frac{1}{2}\\sum_{i\\in I}\\|u_{j}^{T}-v_{i}^{T}\\|^{2}\\,=\\,\\frac{\\Phi^{T}}{a_{T}}\\,\\le\\,\\frac{\\Phi^{0}}{a_{T}}\\,\\le\\,\\frac{\\sum_{j\\in J}1}{a_{T}}\\,=\\,\\bigl(1-\\frac{3\\eta_{u}L_{f}}{8}\\bigr)^{T}\\bigl|J\\bigr|\\,\\le\\,e^{-\\frac{3\\eta_{u}L_{f}}{8}T}\\bigl|J\\bigr|\\,\\le\\,\\frac{1}{2}R^{2}\n$$", "text_format": "latex", "page_idx": 26}, {"type": "text", "text": "whenever $\\begin{array}{r}{T\\ge\\frac{8}{3\\eta_{u}L_{f}}\\ln\\frac{2|J|}{R^{2}}}\\end{array}$ . ", "page_idx": 26}, {"type": "text", "text": "Corollary F.2 (of Lemma F.1). Consider a system of 1 creator $\\pmb{v}_{i}^{t}$ and $|J|$ users $\\{\\boldsymbol{u}_{j}^{t}\\}_{j\\in J}$ , where the creator is recommended to all users at every time step. Assume: ", "page_idx": 26}, {"type": "text", "text": "\u2022 Initially, $\\langle\\pmb{u}_{j}^{0},\\pmb{v}_{i}^{0}\\rangle\\neq0$ for every $j\\in J$ .   \n\u2022 There exists some constant $L_{f}>0$ such that $|f(\\pmb{v}_{i},\\pmb{u}_{j})|\\geq L_{f}>0$ whenever $\\langle\\pmb{v}_{i},\\pmb{u}_{j}\\rangle\\neq0$ . $\\begin{array}{r}{\\mathbf{\\nabla}\\cdot\\mathbf{\\sigma}_{g}(\\mathbf{\\boldsymbol{u}}_{j},\\mathbf{\\boldsymbol{v}}_{i})=\\mathrm{sign}(\\langle\\mathbf{\\boldsymbol{u}}_{j},\\mathbf{\\boldsymbol{v}}_{i}\\rangle).}\\end{array}$   \n\u2022 $\\begin{array}{r}{\\eta_{c}\\leq\\frac{\\eta_{u}L_{f}}{2}}\\end{array}$ \u03b7u2Lf and 0 \u2264\u03b7u < 21. ", "page_idx": 26}, {"type": "text", "text": "Then, for any $R>0,$ , after at most $\\frac{8}{3\\eta_{u}L_{f}}\\ln{\\frac{2|J|}{R^{2}}}$ steps, the system will reach R-bi-polarization. ", "page_idx": 26}, {"type": "text", "text": "Proof. Let $J^{+}\\,=\\,\\{j\\,\\in\\,J:\\,\\langle{\\pmb u}_{j}^{0},{\\pmb v}_{i}^{0}\\rangle\\,>\\,0\\}$ be the set of users with positive inner products with creator $i$ initially; let $J^{-}=\\{j\\in J:\\langle{\\pmb u}_{j}^{0},{\\pmb v}_{i}^{0}\\rangle<0\\}$ . Let $\\tilde{\\pmb{u}}_{j}^{t}=-\\pmb{u}_{j}^{t}$ for $j\\in J^{-}$ and $\\tilde{\\pmb{u}}_{j}^{t}=\\pmb{u}_{j}^{t}$ for $j\\in J^{+}$ . Then, the system consisting of $\\{\\Tilde{u}_{j}^{t}\\}_{j\\in J}$ and $\\pmb{v}_{i}^{t}$ satisfies the initial condition $\\langle\\tilde{\\pmb{u}}_{j}^{0},\\pmb{v}_{i}^{0}\\rangle>0$ in Lemma F.1. So, by Lemma F.1, it reaches $R$ -consensus after at most $\\frac{8}{3\\eta_{u}L_{f}}\\ln{\\frac{2|J|}{R^{2}}}$ 2R|J2| steps. Then by the reflection lemma (Lemma D.7), the original system, consisting of $\\{\\boldsymbol{u}_{j}^{t}\\}_{j\\in J}$ and $\\pmb{v}_{i}^{t}$ , must reach $R$ -bi-polarization. \u53e3 ", "page_idx": 27}, {"type": "text", "text": "F.2 Inductive Step: Proof of Lemma 3.4 ", "text_level": 1, "page_idx": 27}, {"type": "text", "text": "Lemma F.3. Consider a system of $n\\geq1$ creators $\\{\\pmb{v}_{1}^{t},\\ldots,\\pmb{v}_{n}^{t}\\}$ and $|J|$ users $\\{\\boldsymbol{u}_{j}^{t}\\}_{j\\in J}$ . Assume: ", "page_idx": 27}, {"type": "text", "text": "\u2022 Initially, $\\langle\\pmb{v}_{i}^{0},\\pmb{v}_{i^{\\prime}}^{0}\\rangle>0$ for every $i,i^{\\prime}$ , and $\\langle v_{i}^{0},u_{j}^{0}\\rangle>0$ for every $i,j$ .   \n\u2022 Assumptions of Lemma $F.l$ . ", "page_idx": 27}, {"type": "text", "text": "Then, for any $R\\in(0,1)$ , there exists a path of finite length that leads the initial state $(U^{0},V^{0})$ to $R$ -consensus. ", "page_idx": 27}, {"type": "text", "text": "Proof. Fix any $R\\,\\in\\,(0,1)$ . Choose $R_{1}$ such that $\\sqrt{({\\frac{\\eta_{u}}{\\eta_{c}}}+2)4R_{1}}\\,=\\,R$ . Clearly, $R_{1}\\,<\\,R$ . We construct a path that leads the state $(U^{0},V^{0})$ to $R$ -consensus as follows. ", "page_idx": 27}, {"type": "text", "text": "Step $(I)$ : Consider the subsystem of the first $n-1$ creators and all users $J$ . By induction, there exists a path of length $T_{1}=L_{n-1,R_{1}}<+\\infty$ that leads the subsystem to $(R_{1},c^{T_{1}})$ -consensus with some $c^{T_{1}}\\,\\in\\,\\mathbb{S}^{d-1}$ . So, after these $T_{1}$ steps, all creators $i\\,\\in\\,\\{1,\\dots,n-1\\}$ and all users $j\\in J$ satisfy $\\|\\pmb{v}_{i}^{T_{1}}\\,-\\pmb{c}^{T_{1}}\\|\\,\\le\\,R_{1}$ and $\\|\\pmb{u}_{j}^{T_{1}}\\,-\\pmb{c}^{T_{1}}\\|\\,\\leq\\,R_{1}$ . Creator $n$ does not update during these $T_{1}$ steps, so $\\pmb{v}_{n}^{T_{1}}=\\pmb{v}_{n}^{0}$ , and it still has positive inner products with the first $n-1$ creators and all users by the convex cone property (Lemma D.2). Let\u2019s then consider the distance between creators $n$ and the consensus center $c^{\\tilde{T}_{1}}\\colon\\lVert v_{n}^{T_{1}}-c^{T_{1}}\\rVert$ . If $\\lVert\\pmb{v}_{n}^{T_{1}}-\\pmb{c}^{T_{1}}\\rVert\\leq\\underline{{R}}$ , then the system has satisfied $(R,c^{T_{1}})$ -consensus, so our construction is finished. Otherwise, $\\lVert\\pmb{v}_{n}^{T_{1}}-\\pmb{c}^{T_{1}}\\rVert>\\dot{R}$ . We continue the construction as follows: ", "page_idx": 27}, {"type": "text", "text": "Step (2): Pick any user j0 \u2208J, recommend creator n to user j0 for T2 =3\u03b7u8Lf l nR22 steps, while recommending creator $^{\\,l}$ to all other users. From the $(R_{1},c^{T_{1}})$ -consensus in step (1) we know $\\|\\pmb{u}_{j_{0}}^{T_{1}}-\\pmb{c}^{T_{1}}\\|\\leq R_{1}$ , so ", "page_idx": 27}, {"type": "equation", "text": "$$\n\\begin{array}{r}{u_{j_{0}}^{T_{1}},c^{T_{1}}\\rangle\\;=\\;1-\\frac{1}{2}\\|u_{j_{0}}^{T_{1}}-c^{T_{1}}\\|^{2}\\;\\geq\\;1-\\frac{R_{1}^{2}}{2}\\;>\\;1-\\frac{R^{2}}{2}\\;\\geq\\;1-\\frac{1}{2}\\|v_{n}^{T_{1}}-c^{T_{1}}\\|^{2}\\;=\\;\\langle v_{2}^{T_{1}},c^{T_{1}}\\rangle.}\\end{array}\n$$", "text_format": "latex", "page_idx": 27}, {"type": "text", "text": "Thus, we can apply Lemma D.6 with $\\pmb{y}=\\pmb{c}^{T_{1}}$ to derive that, after these $T_{2}$ steps, ", "page_idx": 27}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\langle{\\boldsymbol v}_{n}^{T_{1}+T_{2}},{\\boldsymbol c}^{T_{1}}\\rangle-\\langle{\\boldsymbol v}_{n}^{T_{1}},{\\boldsymbol c}^{T_{1}}\\rangle~\\ge~\\frac{\\eta_{c}}{\\eta_{u}+\\eta_{c}}\\Big(\\langle{\\boldsymbol u}_{j_{0}}^{T_{1}},{\\boldsymbol c}^{T_{1}}\\rangle-\\langle{\\boldsymbol v}_{n}^{T_{1}},{\\boldsymbol c}^{T_{1}}\\rangle-R_{1}\\Big)}\\\\ {\\ge~\\frac{\\eta_{c}}{\\eta_{u}+\\eta_{c}}\\Big(1-\\frac{R_{1}^{2}}{2}-\\langle{\\boldsymbol v}_{n}^{T_{1}},{\\boldsymbol c}^{T_{1}}\\rangle-R_{1}\\Big).}\\\\ {\\implies~~\\langle{\\boldsymbol v}_{n}^{T_{1}+T_{2}},{\\boldsymbol c}^{T_{1}}\\rangle~\\ge~\\langle{\\boldsymbol v}_{n}^{T_{1}},{\\boldsymbol c}^{T_{1}}\\rangle+\\frac{\\eta_{c}}{\\eta_{u}+\\eta_{c}}\\Big(1-\\frac{R_{1}^{2}}{2}-\\langle{\\boldsymbol v}_{n}^{T_{1}},{\\boldsymbol c}^{T_{1}}\\rangle-R_{1}\\Big).}\\end{array}\n$$", "text_format": "latex", "page_idx": 27}, {"type": "text", "text": "For the inner product between creator $n$ and user $j_{0}$ , by Lemma F.1 $\\|\\pmb{v}_{n}^{T_{1}+T_{2}}-\\pmb{u}_{j_{0}}^{T_{1}+T_{2}}\\|\\leq R_{1}$ ", "page_idx": 27}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\langle\\boldsymbol{v}_{n}^{T_{1}+T_{2}},\\boldsymbol{u}_{j_{0}}^{T_{1}+T_{2}}\\rangle\\;=\\;1-\\frac{1}{2}\\|\\boldsymbol{v}_{n}^{T_{1}+T_{2}}-\\boldsymbol{u}_{j_{0}}^{T_{1}+T_{2}}\\|^{2}\\;\\ge\\;1-\\frac{R_{1}^{2}}{2}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 27}, {"type": "text", "text": "Consider the inner products between creator $n$ and the first $n-1$ creators and the users in $J\\setminus\\{j_{0}\\}$ . Because the first $n-1$ creators and the users in $J\\backslash\\{j_{0}\\}$ form $(R_{1},c^{T_{1}})$ -consensus at time step $T_{1}$ , by Observation 3.2, they still form $(R_{1},c^{T_{1}})$ -consensus at time step $T_{1}+T_{2}$ , so $\\lVert\\pmb{v}_{i}^{T_{1}+T_{2}}-\\pmb{c}^{T_{1}}\\rVert\\leq R_{1}$ and $||\\pmb{u}_{j}^{T_{1}+T_{2}}-\\pmb{c}^{T_{1}}||\\leq R_{1}$ . This implies, for $i\\neq n$ , ", "page_idx": 27}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\langle\\boldsymbol{v}_{n}^{T_{1}+T_{2}},\\boldsymbol{v}_{i}^{T_{1}+T_{2}}\\rangle\\ \\ge\\ \\langle\\boldsymbol{v}_{n}^{T_{1}+T_{2}},\\boldsymbol{c}^{T_{1}}\\rangle-\\|\\boldsymbol{v}_{i}^{T_{1}+T_{2}}-\\boldsymbol{c}^{T_{1}}\\|}&{}\\\\ {\\ \\ge\\ \\langle\\boldsymbol{v}_{2}^{T_{1}+T_{2}},\\boldsymbol{c}^{T_{1}}\\rangle-R_{1}}&{}\\\\ {(10)\\ \\ge\\ \\langle\\boldsymbol{v}_{n}^{T_{1}},\\boldsymbol{c}^{T_{1}}\\rangle+\\frac{\\eta_{c}}{\\eta_{u}+\\eta_{c}}\\Big(1-\\frac{R_{1}^{2}}{2}-\\langle\\boldsymbol{v}_{n}^{T_{1}},\\boldsymbol{c}^{T_{1}}\\rangle-R_{1}\\Big)-R_{1},}\\end{array}\n$$", "text_format": "latex", "page_idx": 27}, {"type": "text", "text": "and for $j\\in J\\setminus\\{j_{0}\\}$ , ", "page_idx": 28}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\langle\\boldsymbol{v}_{n}^{T_{1}+T_{2}},\\boldsymbol{u}_{j}^{T_{1}+T_{2}}\\rangle\\ \\ge\\ \\langle\\boldsymbol{v}_{n}^{T_{1}+T_{2}},\\boldsymbol{c}^{T_{1}}\\rangle-\\|\\boldsymbol{u}_{j}^{T_{1}+T_{2}}-\\boldsymbol{c}^{T_{1}}\\|}&\\\\ {\\ \\ge\\ \\langle\\boldsymbol{v}_{2}^{T_{1}+T_{2}},\\boldsymbol{c}^{T_{1}}\\rangle-R_{1}}&\\\\ {(10)\\ \\ge\\ \\langle\\boldsymbol{v}_{n}^{T_{1}},\\boldsymbol{c}^{T_{1}}\\rangle+\\frac{\\eta_{c}}{\\eta_{u}+\\eta_{c}}\\Big(1-\\frac{R_{1}^{2}}{2}-\\langle\\boldsymbol{v}_{n}^{T_{1}},\\boldsymbol{c}^{T_{1}}\\rangle-R_{1}\\Big)-R_{1}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 28}, {"type": "text", "text": "Step (3): Consider the subsystem of the first $n-1$ creators and all users $J$ . By induction, there exists a path of length $T_{3}=L_{n-1,R_{1}}<+\\infty$ that leads the subsystem to $(R_{1},c^{T_{1}+T_{2}+T_{3}})$ -consensus with some $c^{T_{1}+T_{2}+T_{3}}\\in\\mathbb{S}^{d-1}$ . So, we have $\\|\\pmb{v}_{i}^{T_{1}+T_{2}+T_{3}}-\\pmb{c}^{T_{1}+T_{2}+T_{3}}\\|\\le R_{1}$ for every $i\\in\\{1,\\ldots,n\\!-\\!1\\}$ and $||u_{j}^{T_{1}+T_{2}+T_{3}}-c^{T_{1}+T_{2}+T_{3}}||\\leq R_{1}$ for every $j\\in J$ , and $\\pmb{v}_{n}^{T_{1}+T_{2}+T_{3}}=\\pmb{v}_{n}^{T_{1}+T_{2}}$ . Consider the inner product between creator $n$ and any of the first $n-1$ creators $i\\in\\{1,\\ldots,n-1\\}$ . By the convex cone property (Lemma D.2), ", "page_idx": 28}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{v_{n}^{T_{1}+T_{2}+T_{3}},v_{i}^{T_{1}+T_{2}+T_{3}}\\rangle\\!\\!}&{=\\,\\langle v_{n}^{T_{1}+T_{2}},v_{i}^{T_{1}+T_{2}+T_{3}}\\rangle}\\\\ {\\mathrm{Lemma~D.2~\\ge~min~}\\big\\{\\langle v_{n}^{T_{1}+T_{2}},v_{i}^{T_{1}+T_{2}}\\rangle,~\\operatorname*{min}\\langle v_{n}^{T_{1}+T_{2}},u_{j}^{T_{1}+T_{2}}\\rangle\\big\\}}\\\\ {\\mathrm{by~(11),(12),(13)~\\ge~min~}\\big\\{\\langle v_{n}^{T_{1}},c^{T_{1}}\\rangle+\\frac{\\eta_{c}}{\\eta_{u}+\\eta_{c}}\\Big(1-\\frac{R_{1}^{2}}{2}-\\langle v_{n}^{T_{1}},c^{T_{1}}\\rangle-R_{1}\\Big)-R_{1},~1-\\frac{R_{1}^{2}}{2}.}\\\\ {\\:}&{=\\,\\langle v_{n}^{T_{1}},c^{T_{1}}\\rangle+\\frac{\\eta_{c}}{\\eta_{u}+\\eta_{c}}\\Big(1-\\frac{R_{1}^{2}}{2}-\\langle v_{n}^{T_{1}},c^{T_{1}}\\rangle-R_{1}\\Big)-R_{1}\\qquad\\quad(14)}\\end{array}\n$$", "text_format": "latex", "page_idx": 28}, {"type": "text", "text": "where the last equality is because, under the assumption of $\\begin{array}{r}{\\|v_{n}^{T_{1}}-c^{T_{1}}\\|>R=\\sqrt{(\\frac{\\eta_{u}}{\\eta_{c}}+2)4R_{1}},}\\end{array}$ , ", "page_idx": 28}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\langle v_{n}^{T_{1}},c^{T_{1}}\\rangle+\\frac{\\eta_{c}}{\\eta_{u}+\\eta_{c}}\\Big(1-\\frac{R_{1}^{2}}{2}-\\langle v_{n}^{T_{1}},c^{T_{1}}\\rangle-R_{1}\\Big)-R_{1}}\\\\ &{\\quad=\\ \\frac{\\eta_{u}}{\\eta_{u}+\\eta_{c}}\\langle v_{n}^{T_{1}},c^{T_{1}}\\rangle+\\frac{\\eta_{c}}{\\eta_{u}+\\eta_{c}}\\Big(1-\\frac{R_{1}^{2}}{2}-R_{1}\\Big)-R_{1}}\\\\ &{\\quad=\\ \\frac{\\eta_{u}}{\\eta_{u}+\\eta_{c}}\\Big(1-\\frac{1}{2}\\|v_{2}^{T_{1}}-c^{T_{1}}\\|^{2}\\Big)+\\frac{\\eta_{c}}{\\eta_{u}+\\eta_{c}}\\Big(1-\\frac{R_{1}^{2}}{2}-R_{1}\\Big)-R_{1}}\\\\ &{\\quad\\le\\ \\frac{\\eta_{u}}{\\eta_{u}+\\eta_{c}}\\Big(1-\\frac{1}{2}\\big(\\frac{\\eta_{u}}{\\eta_{c}}+2\\big)4R_{1}\\Big)+\\frac{\\eta_{c}}{\\eta_{u}+\\eta_{c}}\\Big(1-\\frac{R_{1}^{2}}{2}-R_{1}\\Big)-R_{1}}\\\\ &{\\quad\\le\\ \\operatorname*{max}\\{1-\\frac{1}{2}\\big(\\frac{\\eta_{u}}{\\eta_{c}}+2\\big)4R_{1},~1-\\frac{R_{1}^{2}}{2}-R_{1}\\}-R_{1}}\\\\ &{\\quad=\\ 1-\\frac{R_{1}^{2}}{2}-R_{1}-R_{1}\\le\\ 1-\\frac{R_{1}^{2}}{2}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 28}, {"type": "text", "text": "From (14) and $\\|v_{i}^{T_{1}+T_{2}+T_{3}}-c^{T_{1}+T_{2}+T_{3}}\\|\\le R_{1},$ , ", "page_idx": 28}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\langle v_{n}^{T_{1}+T_{2}+T_{3}},c^{T_{1}+T_{2}+T_{3}}\\rangle\\ \\geq\\ \\langle v_{n}^{T_{1}+T_{2}},v_{i}^{T_{1}+T_{2}+T_{3}}\\rangle-\\|v_{i}^{T_{1}+T_{2}+T_{3}}-c^{T_{1}+T_{2}+T_{3}}\\|}&{}\\\\ {\\ \\geq\\ \\langle v_{n}^{T_{1}},c^{T_{1}}\\rangle+\\frac{\\eta_{c}}{\\eta_{u}+\\eta_{c}}\\Big(1-\\frac{R_{1}^{2}}{2}-\\langle v_{n}^{T_{1}},c^{T_{1}}\\rangle-R_{1}\\Big)-2R_{1}.}&{}\\end{array}\n$$", "text_format": "latex", "page_idx": 28}, {"type": "text", "text": "Using 1 to minus the above inequality, we obtain ", "page_idx": 28}, {"type": "equation", "text": "$$\n\\begin{array}{r}{1-\\langle v_{n}^{T_{1}+T_{2}+T_{3}},c^{T_{1}+T_{2}+T_{3}}\\rangle\\ \\leq\\ \\frac{\\eta_{u}}{\\eta_{u}+\\eta_{c}}\\Big(1-\\langle v_{n}^{T_{1}},c^{T_{1}}\\rangle\\Big)+\\frac{\\eta_{c}}{\\eta_{u}+\\eta_{c}}\\Big(\\frac{R_{1}^{2}}{2}+R_{1}\\Big)+2R_{1}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 28}, {"type": "text", "text": "Let $F^{t}=1-\\langle{\\pmb v}_{n}^{t},{\\pmb c}^{t}\\rangle$ , then ", "page_idx": 28}, {"type": "equation", "text": "$$\n\\begin{array}{r}{F^{T_{1}+T_{2}+T_{3}}\\leq\\frac{\\eta_{u}}{\\eta_{u}+\\eta_{c}}F^{T_{1}}+\\frac{\\eta_{c}}{\\eta_{u}+\\eta_{c}}\\Big(\\frac{R_{1}^{2}}{2}+R_{1}\\Big)+2R_{1}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 28}, {"type": "text", "text": "Repeat steps (2) and (3) for $K$ times. Then, using (15) for $K$ times, ", "page_idx": 29}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\gamma T_{1}+K(T_{2}+T_{3})\\,\\le\\,\\frac{\\eta_{\\mathrm{sh}}}{\\eta_{\\mathrm{sh}}+\\eta_{\\mathrm{c}}}F T_{1}+(K-1)(T_{2}+T_{3})\\,+\\,\\frac{\\eta_{\\mathrm{c}}}{\\eta_{\\mathrm{sh}}+\\eta_{\\mathrm{c}}}\\Big(\\frac{R_{1}^{2}}{2}+R_{1}\\Big)+2R_{1}}\\\\ {\\,}&{\\le\\,\\frac{\\eta_{\\mathrm{sh}}}{\\eta_{\\mathrm{sh}}+\\eta_{\\mathrm{c}}}\\Bigg(\\frac{\\eta_{\\mathrm{sh}}}{\\eta_{\\mathrm{sh}}+\\eta_{\\mathrm{c}}}F^{T_{1}+(K-2)(T_{2}+T_{3})}+\\frac{\\eta_{\\mathrm{c}}}{\\eta_{\\mathrm{sh}}+\\eta_{\\mathrm{c}}}\\Big(\\frac{R_{1}^{2}}{2}+R_{1}\\Big)+2R_{1}\\Bigg)+\\frac{\\eta_{\\mathrm{c}}}{\\eta_{\\mathrm{sh}}+\\eta_{\\mathrm{c}}}\\Big(\\frac{R_{1}^{2}}{2}+J_{1}}\\\\ {\\,}&{\\,\\vdots}\\\\ {\\,}&{\\le\\,\\big(\\frac{\\eta_{\\mathrm{sh}}}{\\eta_{\\mathrm{sh}}+\\eta_{\\mathrm{c}}}\\big)^{K}\\,F^{T_{1}}+\\Big(1+\\frac{\\eta_{\\mathrm{sh}}}{\\eta_{\\mathrm{sh}}+\\eta_{\\mathrm{c}}}+\\cdots+\\big(\\frac{\\eta_{\\mathrm{sh}}}{\\eta_{\\mathrm{sh}}+\\eta_{\\mathrm{c}}}\\big)^{K-1}\\Big)\\Big(\\frac{\\eta_{\\mathrm{c}}}{\\eta_{\\mathrm{sh}}+\\eta_{\\mathrm{c}}}\\Big(\\frac{R_{1}^{2}}{2}+R_{1}\\Big)+2R_{1}\\Big)}\\\\ {\\,}&{\\le\\,\\big(\\frac{\\eta_{\\mathrm{sh}}}{\\eta_{\\mathrm{sh}}+\\eta_{\\mathrm{c}}}\\big)^{K}\\cdot1+\\frac{1}{1-\\frac{\\eta_{\\mathrm{sh}}}{\\eta_{\\mathrm{sh}}}\\Big(\\frac{\\eta_{\\mathrm{sh}}}{\\eta_{\\mathrm{sh}}+\\eta_{\\mathrm{c}}}\\Big(\\frac{R_{1}^{2}}{2}+R_{1}\\Big)+2R_{1}\n$$", "text_format": "latex", "page_idx": 29}, {"type": "text", "text": "by choosing $\\begin{array}{r}{K=\\frac{\\ln\\frac{2}{R_{1}^{2}}}{\\ln\\frac{\\eta_{u}+\\eta_{c}}{\\eta_{u}}}\\leq\\frac{\\eta_{u}+\\eta_{c}}{\\eta_{c}}\\ln\\frac{2}{R_{1}^{2}}}\\end{array}$ . This means that, after repeating steps (2) and (3) for $K$ times, we must have ", "page_idx": 29}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\|v_{n}^{T_{1}+K(T_{2}+T_{3})}-c^{T_{1}+K(T_{2}+T_{3})}\\|~=~\\sqrt{2\\big(1-\\langle v_{n}^{T_{1}+K(T_{2}+T_{3})},c^{T_{1}+K(T_{2}+T_{3})}\\rangle\\big)}}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad=~\\sqrt{2F^{T_{1}+K(T_{2}+T_{3})}}~\\le~\\sqrt{2\\big(\\frac{\\eta_{u}}{\\eta_{c}}+2)2R_{1}}~=~R.}\\end{array}\n$$", "text_format": "latex", "page_idx": 29}, {"type": "text", "text": "The above inequality, together with the fact that other creators $i\\neq n$ and all users in $J$ already satisfy $(R_{1}\\leq\\dot{R},c^{T_{1}+K(\\check{T}_{2}+T_{3})})$ -consensus after step (3), implies that the whole system has reached $(R,c^{T_{1}+K(T_{2}+T_{3})})$ -consensus. ", "page_idx": 29}, {"type": "text", "text": "The length of the path constructed above is at most: ", "page_idx": 29}, {"type": "equation", "text": "$$\n\\begin{array}{r}{T_{1}+K(T_{2}+T_{3})\\ \\le\\ L_{n-1,R_{1}}+\\frac{\\eta_{u}+\\eta_{c}}{\\eta_{c}}\\ln\\frac{2}{R_{1}^{2}}\\Big(\\frac{8}{3\\eta_{u}L_{f}}\\ln\\frac{2|J|}{R_{1}^{2}}+L_{n-1,R_{1}}\\Big)\\ =\\ L_{n,R}\\ <\\ +\\infty,}\\end{array}\n$$", "text_format": "latex", "page_idx": 29}, {"type": "text", "text": "which is finite. ", "page_idx": 29}, {"type": "text", "text": "Lemma F.4. Consider a subsystem of n creators $\\{\\pmb{v}_{1}^{t},\\ldots,\\pmb{v}_{n}^{t}\\}$ and $|J|$ users $\\{\\boldsymbol{u}_{j}^{t}\\}_{j\\in J}$ . Assume: ", "page_idx": 29}, {"type": "text", "text": "\u2022 Initially, the first $n\\mathrm{~-~}1$ creators and all users are in $R_{0}$ -consensus: $\\|\\pmb{v}_{i}^{0}\\mathrm{~-~}\\pmb{c}\\|\\,\\le\\,R_{0}$ , \u2225uj0 \u2212c\u2225\u2264R0, with 0 < R0 <5(\u03b7c\u03b7+c\u03b7u).   \n\u2022 $\\langle{\\pmb v}_{n}^{0},{\\pmb u}_{j_{0}}^{0}\\rangle>0$ for some $j_{0}\\in J$ .   \n\u2022 $g(\\pmb{u}_{j},\\pmb{v}_{i})=\\mathrm{sign}(\\langle\\pmb{u}_{j},\\pmb{v}_{i}\\rangle).$   \n\u2022 Assumption of Lemma $F.I$ . ", "page_idx": 29}, {"type": "text", "text": "Then, for any $R\\in(0,1)$ , there exists a path of finite length that leads the initial state $(U^{0},V^{0})\\;t o$ $R$ -consensus. ", "page_idx": 29}, {"type": "text", "text": "Proof. First, we recommend creator n to user j0 for T =3\u03b7u8Lf l R2 steps, while recommending other creators to other users arbitrarily. Applying Lemma D.6 with $\\pmb{y}=\\pmb{u}_{j_{0}}^{0}$ uj00, we get ", "page_idx": 29}, {"type": "equation", "text": "$$\n\\begin{array}{r}{v_{n}^{T},u_{j_{0}}^{0}\\rangle-\\langle v_{n}^{0},u_{j_{0}}^{0}\\rangle\\,\\ge\\,\\frac{\\eta_{c}}{\\eta_{u}+\\eta_{c}}\\Big(\\langle u_{j_{0}}^{0},u_{j_{0}}^{0}\\rangle-\\langle v_{n}^{0},u_{j_{0}}^{0}\\rangle-R_{0}\\Big)\\,=\\,\\frac{\\eta_{c}}{\\eta_{u}+\\eta_{c}}\\Big(1-\\langle v_{n}^{0},u_{j_{0}}^{0}\\rangle-R_{0}\\Big).}\\end{array}\n$$", "text_format": "latex", "page_idx": 29}, {"type": "text", "text": "On the other hand, because the first $n-1$ creators and all users in $J\\backslash\\{j_{0}\\}$ form an $(R_{0},c)$ -consensus at time step 0, according to Observation 3.2, they still form an $(R_{0},{\\pmb c})$ -consensus at time step $T$ , so $\\lVert\\pmb{v}_{i}^{T}-\\pmb{c}\\rVert\\stackrel{\\pm}{\\leq}R_{0}$ for every $i\\in\\{1,\\ldots,n-1\\}$ . This implies, for every $i\\in\\{1,\\ldots,n-1\\}$ , ", "page_idx": 29}, {"type": "equation", "text": "$$\n\\langle v_{n}^{T},v_{i}^{T}\\rangle-\\langle v_{n}^{T},u_{j_{0}}^{0}\\rangle\\ \\geq\\ -\\ \\|v_{i}^{T}-u_{j_{0}}^{0}\\|\\ \\geq\\ -\\ \\|v_{i}^{T}-c\\|-\\|c-u_{j_{0}}^{0}\\|\\ \\geq\\ -\\ 2R_{0}.\n$$", "text_format": "latex", "page_idx": 29}, {"type": "text", "text": "Adding (16) and (17) and moving $\\langle\\pmb{v}_{n}^{0},\\pmb{u}_{j_{0}}^{0}\\rangle$ to the right side, we get ", "page_idx": 30}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\langle\\boldsymbol{v}_{n}^{T},\\boldsymbol{v}_{i}^{T}\\rangle\\,\\ge\\,\\langle\\boldsymbol{v}_{n}^{0},\\boldsymbol{u}_{j_{0}}^{0}\\rangle+\\frac{\\eta_{c}}{\\eta_{u}+\\eta_{c}}\\Big(1-\\langle\\boldsymbol{v}_{n}^{0},\\boldsymbol{u}_{j_{0}}^{0}\\rangle-R_{0}\\Big)-2R_{0}}\\\\ &{=\\,\\frac{\\eta_{u}}{\\eta_{u}+\\eta_{c}}\\langle\\boldsymbol{v}_{n}^{0},\\boldsymbol{u}_{j_{0}}^{0}\\rangle+\\frac{\\eta_{c}}{\\eta_{u}+\\eta_{c}}\\big(1-R_{0}\\big)-2R_{0}}\\\\ &{>\\,0+\\frac{\\eta_{c}}{\\eta_{u}+\\eta_{c}}\\big(1-R_{0}\\big)-2R_{0}\\,>\\,0,}\\end{array}\n$$", "text_format": "latex", "page_idx": 30}, {"type": "text", "text": "under the condition of $\\begin{array}{r}{R_{0}<\\frac{\\eta_{c}}{5(\\eta_{u}+\\eta_{c})}}\\end{array}$ . Moreover, for every $j\\in J\\setminus\\{j_{0}\\}$ , because $\\lvert|\\pmb{u}_{j}^{T}-\\pmb{v}_{i}^{T}\\rvert\\rvert\\leq$ $\\|\\pmb{{u}}_{j}^{T}-\\pmb{{c}}\\|+\\|\\pmb{{c}}-\\pmb{{v}}_{i}^{T}\\|\\leq2R_{0}.$ , ", "page_idx": 30}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\langle\\boldsymbol{v}_{n}^{T},\\boldsymbol{u}_{j}^{T}\\rangle\\ \\geq\\ \\langle\\boldsymbol{v}_{n}^{T},\\boldsymbol{v}_{i}^{T}\\rangle-\\|\\boldsymbol{u}_{j}^{T}-\\boldsymbol{v}_{i}^{T}\\|\\ \\geq\\ \\frac{\\eta_{c}}{\\eta_{u}+\\eta_{c}}\\big(1-R_{0}\\big)-4R_{0}>0.}\\end{array}\n$$", "text_format": "latex", "page_idx": 30}, {"type": "text", "text": "For $j_{0}$ , by Lemma F.1, $\\|\\pmb{v}_{n}^{T}-\\pmb{u}_{j_{0}}^{T}\\|\\leq R_{0}$ , so ", "page_idx": 30}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\langle\\boldsymbol{v}_{n}^{T},\\boldsymbol{u}_{j_{0}}^{T}\\rangle\\;=\\;1-\\frac{1}{2}\\|\\boldsymbol{v}_{n}^{T}-\\boldsymbol{u}_{j_{0}}^{T}\\|^{2}\\;\\ge\\;1-\\frac{R_{0}^{2}}{2}\\;>\\;0.}\\end{array}\n$$", "text_format": "latex", "page_idx": 30}, {"type": "text", "text": "For the inner product between any creator $i\\in\\{1,\\ldots,n-1\\}$ and the users: ", "page_idx": 30}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\ge\\langle v_{i}^{T},v_{n}^{T}\\rangle-\\|v_{n}^{T}-u_{j_{0}}^{T}\\|\\ \\ge\\ \\frac{\\eta_{c}}{\\eta_{u}+\\eta_{c}}\\big(1-R_{0}\\big)-2R_{0}-R_{0}\\ =\\ \\frac{\\eta_{c}}{\\eta_{u}+\\eta_{c}}\\big(1-R_{0}\\big)-3R_{0}\\ >\\ 0;}\\\\ &{{\\ j_{0}\\},\\quad\\langle v_{i}^{T},u_{j}^{T}\\rangle\\ =\\ 1-\\frac{1}{2}\\|v_{i}^{T}-u_{j}^{T}\\|^{2}\\ \\ge\\ 1-\\frac{1}{2}\\big(\\|v_{i}^{T}-c\\|+\\|c-u_{j}^{T}\\|\\big)^{2}\\ >\\ 1-\\frac{1}{2}(2R_{0})^{2}\\ >\\ 0}\\end{array}\n$$", "text_format": "latex", "page_idx": 30}, {"type": "text", "text": "All of the $^{\\bullet\\bullet}>0^{\\bullet\\bullet}$ inequalities above show that the system of $\\{v_{i}^{T}\\}_{i\\in[n]}$ and $\\{u_{j}^{T}\\}_{j\\in J}$ satisfies the condition of Lemma F.3. So, there exists a path of finite length $T_{2}<+\\infty$ that leads the system to R-consensus by Lemma F.3. The total length of path T + T2 = 3\u03b7u8Lf l $\\begin{array}{r}{T\\,\\bar{+}\\,T_{2}=\\,\\frac{8}{3\\eta_{u}L_{f}}\\ln\\frac{2}{R_{0}^{2}}+T_{2}<\\,\\dot{+}\\infty}\\end{array}$ finite. \u53e3 ", "page_idx": 30}, {"type": "text", "text": "Lemma 3.4. Suppose $\\begin{array}{r}{\\eta_{c}\\leq\\frac{\\eta_{u}L_{f}}{2}}\\end{array}$ and $\\begin{array}{r}{\\eta_{u}<\\frac{1}{2}}\\end{array}$ . For any $R>0,$ , for almost every s tate $(U^{t},V^{t})$ in the state space, there exists a path $\\left(U^{t},V^{t}\\right)^{-}\\rightarrow\\left(U_{-}^{t+1},V_{-}^{t+1}\\right)\\rightarrow\\cdot\\cdot\\cdot\\rightarrow\\left(U^{t+T},V^{t+T}\\right)$ of finite length that leads to an $R$ -bi-polarization state $(U^{i+T},V^{t+T})$ . ", "page_idx": 30}, {"type": "text", "text": "Proof. We prove this lemma by induction on the number of creators $n$ . The case for $n=1$ directly follows from Corollary F.2 which shows that, for any system of $n=1$ creator and $|J|$ users with no $\\langle{\\pmb v}_{i}^{0},{\\pmb u}_{j}^{0}\\rangle\\,=\\,0$ , there exists a path of length at most $\\begin{array}{r}{L_{1}^{R}\\,=\\,\\frac{8}{3\\eta_{u}L_{F}}\\ln\\frac{2|J|}{R^{2}}\\,<\\,+\\infty}\\end{array}$ that leads to -bi-polarization. ", "page_idx": 30}, {"type": "text", "text": "Consider $n\\geq2$ . Consider the subsystem consisting of the first $n-1$ creators $\\{\\pmb{v}_{1}^{t},\\dots,\\pmb{v}_{n-1}^{t}\\}$ and all users. Let $\\begin{array}{r}{R_{0}=\\frac{\\eta_{c}}{6(\\eta_{c}+\\eta_{u})}}\\end{array}$ . By induction, there exists a path of finite length $T_{1}=L_{n-1}^{R_{0}}<+\\infty$ that leads the subsystem to $R_{0}$ -bi-polarization, with some vector $c_{0}\\in\\mathbb{S}^{d-1}$ , so every $\\pmb{v}_{i}^{T_{1}}$ is $R_{0}$ -close to $+c_{0}$ or $-c_{0}$ , for $i\\neq n$ , and every $u_{j}^{T_{1}}$ is $R_{0}$ -close to $+c_{0}$ or $-c_{0}$ . Define: ", "page_idx": 30}, {"type": "equation", "text": "$$\n\\}_{i}^{t}=\\left\\{\\!\\!\\begin{array}{l l}{v_{i}^{t}\\quad}&{\\mathrm{if~}v_{i}^{T_{1}}\\mathrm{~is~}R_{0}\\mathrm{-close~to~}+c}\\\\ {-v_{i}^{t}\\quad}&{\\mathrm{if~}v_{i}^{T_{1}}\\mathrm{~is~}R_{0}\\mathrm{-close~to~}-c}\\end{array}\\right.\\quad\\forall i\\neq n,\\quad\\quad\\quad\\tilde{u}_{j}^{t}=\\left\\{\\!\\!\\!\\begin{array}{l l}{u_{j}^{t}\\quad}&{\\mathrm{if~}u_{j}^{T_{1}}\\mathrm{~is~}R_{0}\\mathrm{-close~to~}+c}\\\\ {-u_{j}^{t}\\quad}&{\\mathrm{if~}u_{j}^{T_{1}}\\mathrm{~is~}R_{0}\\mathrm{-close~to~}-c}\\end{array}\\right.\n$$", "text_format": "latex", "page_idx": 30}, {"type": "text", "text": "By definition, we have ", "page_idx": 30}, {"type": "equation", "text": "$$\n\\|\\tilde{v}_{i}^{T_{1}}-c_{0}\\|\\leq R_{0},\\ \\ \\forall i\\neq n,\\ \\ \\ \\ \\ \\ \\ \\ \\ \\|\\tilde{u}_{j}^{T_{1}}-c_{0}\\|\\leq R_{0},\\ \\ \\forall j\\in J.\n$$", "text_format": "latex", "page_idx": 30}, {"type": "text", "text": "This means that $\\{\\tilde{v}_{i}^{T_{1}}\\}_{i\\ne n}$ and $\\{\\Tilde{u}_{j}^{T_{1}}\\}_{j\\in J}$ form an $(R_{0},c_{0})$ -consensus. Consider creator $n$ . Let ", "page_idx": 30}, {"type": "equation", "text": "$$\n\\tilde{v}_{n}^{t}=\\left\\{v_{n}^{t}\\right.\\quad\\mathrm{~if~}\\langle v_{n}^{T_{1}},\\tilde{u}_{j_{0}}^{T_{1}}\\rangle>0\\mathrm{~for~some~}j_{0}\\in J}\\\\ {-v_{n}^{t}\\quad\\mathrm{~if~}\\langle v_{n}^{T_{1}},\\tilde{u}_{j}^{T_{1}}\\rangle<0\\mathrm{~for~all~}j\\in J.\\quad}\\end{array}\n$$", "text_format": "latex", "page_idx": 30}, {"type": "text", "text": "(The case where $\\langle{\\pmb v}_{n}^{T_{1}},\\tilde{\\pmb u}_{j}^{T_{1}}\\rangle=0$ for some $j\\in J$ is ignored because the initial states that can lead to such states have measure 0.) By definition, we have ", "page_idx": 30}, {"type": "equation", "text": "$$\n\\langle\\tilde{v}_{n}^{T_{1}},\\tilde{u}_{j_{0}}^{T_{1}}\\rangle>0\\;\\mathrm{for}\\;\\mathrm{some}\\;j_{0}\\in J.\n$$", "text_format": "latex", "page_idx": 30}, {"type": "text", "text": "Note that, at time step $T_{1}$ , the system consisting of $\\{\\tilde{v}_{i}^{T_{1}}\\}_{i\\in[n]}$ and $\\{\\Tilde{u}_{j}^{T_{1}}\\}_{j\\in J}$ satisfies the condition of Lemma F.4, so there exists a path of length $T_{2}=\\tilde{L}_{n}^{R}<+\\infty$ that leads the system to $R$ -consensus. Then by the reflection lemma (Lemma D.7), the original system $\\{v_{i}^{t}\\}_{i\\in[n]}$ , $\\{\\boldsymbol{u}_{j}^{t}\\}_{j\\in J}$ must reach $R$ -bi-polarization. The total length of path that leads to this $R$ -bi-polarization is $L_{n}^{R}=T_{1}+T_{2}=$ $L_{n-1}^{R_{0}}+\\tilde{L}_{n}^{R}<+\\infty$ . \u53e3 ", "page_idx": 30}, {"type": "text", "text": "G Missing Proofs from Section 4 ", "text_level": 1, "page_idx": 31}, {"type": "text", "text": "G.1 Proof of Proposition 4.2 ", "text_level": 1, "page_idx": 31}, {"type": "text", "text": "Let $R>0$ be any small number. Let $c_{1},\\ldots,c_{\\lfloor n/k\\rfloor}\\in\\mathbb{R}^{d}$ be $\\lfloor n/k\\rfloor$ vectors that satisfy $B(\\pmb{c}_{\\ell},2R)\\cap$ $B(\\pmb{c}_{\\ell^{\\prime}},2R)\\,=\\,\\emptyset$ for $\\ell\\neq\\ell^{\\prime}$ , where $B(\\pmb{c},R)$ is the ball centered at $^c$ with radius $R$ : $\\{x\\in\\mathbb{R}^{d}:$ $\\|\\pmb{x}-\\pmb{c}\\|_{2}\\,\\leq\\,R\\}$ . Consider user and creator features $(\\pmb{U}^{t},\\pmb{V}^{t})$ that satisfy: every ball $B(\\pmb{c}_{\\ell},R)$ $(\\ell\\,=\\,1,\\ldots,\\lfloor n/k\\rfloor)$ ) contains $k$ creator vectors, and every user vector $\\pmb{u}_{j}^{t}$ is in one of the balls $B(\\pmb{c}_{\\ell},R)$ . By definition, $(U^{t},V^{t})$ form $\\lfloor n/k\\rfloor$ clusters. We show that, after one step of update, the new state $(\\dot{U}^{t+1},V^{t+1})$ must still form $\\lfloor n/k\\rfloor$ clusters. Consider any user $j$ . Suppose $\\mathbf{\\bar{\\boldsymbol{u}}}_{j}^{t}\\in\\dot{\\boldsymbol{B}}(\\mathbf{\\boldsymbol{c}}_{\\ell},R)$ , then the distance from $\\pmb{u}_{j}^{t}$ to any creator $\\pmb{v}_{i}^{t}\\in B(\\pmb{c}_{\\ell},R)$ is at most $2R$ : ", "page_idx": 31}, {"type": "equation", "text": "$$\n\\lVert\\boldsymbol{u}_{j}^{t}-\\boldsymbol{v}_{i}^{t}\\rVert\\leq2R.\n$$", "text_format": "latex", "page_idx": 31}, {"type": "text", "text": "The distance from $\\pmb{u}_{j}^{t}$ to any creator $\\pmb{v}_{i^{\\prime}}^{t}$ not in $B(\\pmb{c}_{\\ell},R)$ is greater than $2R$ : ", "page_idx": 31}, {"type": "equation", "text": "$$\n\\|\\pmb{u}_{j}^{t}-\\pmb{v}_{i^{\\prime}}^{t}\\|>2R\n$$", "text_format": "latex", "page_idx": 31}, {"type": "text", "text": "because $\\pmb{v}_{i^{\\prime}}^{t}$ is in some other ball $B(\\pmb{c}_{\\ell^{\\prime}},R)$ that satisfies $B(c_{\\ell^{\\prime}},2R)\\cap B(c_{\\ell},2R)=\\emptyset$ . This implies that the inner products between user $j$ and the creators in ball $B(\\pmb{c}_{\\ell},R)$ are greater than that with the creators in other ball: ", "page_idx": 31}, {"type": "equation", "text": "$$\n\\langle\\boldsymbol{v}_{i}^{t}\\in B(c_{\\ell},R),\\ \\langle\\boldsymbol{u}_{j}^{t},\\boldsymbol{v}_{i}^{t}\\rangle=1-\\frac{1}{2}\\|\\boldsymbol{u}_{j}^{t}-\\boldsymbol{v}_{i}^{t}\\|_{2}^{2}\\geq1-\\frac{1}{2}(2R)^{2}>1-\\frac{1}{2}\\|\\boldsymbol{u}_{j}^{t}-\\boldsymbol{v}_{i}^{t}\\|=\\langle\\boldsymbol{u}_{j}^{t},\\boldsymbol{v}_{i}^{t}\\rangle,\\ \\forall\\boldsymbol{v}_{i}^{t}\\in R.\n$$", "text_format": "latex", "page_idx": 31}, {"type": "text", "text": "Since $B(\\pmb{c}_{\\ell},R)$ contains $k$ creators, these $k$ creators are the $k$ -most relevant ones to user $j$ , so user $j$ will only be recommended these creators. Then, by applying Observation 3.2 to each of the $\\lfloor n/k\\rfloor$ balls separately, we see that each ball is a $R$ -consensus and hence absorbing. So, the new state $(\\pmb{U}^{t+1},\\dot{\\pmb{V}}^{t+1})$ still forms $\\lfloor n/k\\rfloor$ clusters with these $\\lfloor n/k\\rfloor$ balls. ", "page_idx": 31}, {"type": "text", "text": "G.2 Proof of Proposition 4.3 ", "text_level": 1, "page_idx": 31}, {"type": "text", "text": "The $d$ -dimensional simplex centered at the original has $d\\!+\\!1$ vectors with negative inner products with each other. They form $d\\!+\\!1$ clusters. Since user-creator pairs with negative inner product $\\langle\\pmb{u}_{i},\\pmb{v}_{j}\\rangle<0$ are not recommended, recommendations only happen within each cluster. By Observation 3.2, each cluster is absorbing, so the whole system is stable, keep forming $d+1$ clusters forever. ", "page_idx": 31}, {"type": "text", "text": "H Additional Discussion on Real-World Recommender Systems ", "text_level": 1, "page_idx": 31}, {"type": "text", "text": "Here we further discuss real-world recommender systems\u2019 properties and designs that are currently not covered in our main paper. We plan to generalize our model in the future to further capture these features and discuss insightful findings, but having them in the current paper may be a distraction to our main findings. ", "page_idx": 31}, {"type": "text", "text": "H.1 User and Creator Retention and Activeness ", "text_level": 1, "page_idx": 31}, {"type": "text", "text": "In our current model, the users and creators will stay in the system from the start to the end. However, in real-world recommender systems, users and creators may leave the platform either permanently or for a certain period. Meanwhile, new users and creators will join the platform. Such join and leave dynamics are also influenced by the recommendations\u2019 relevance and diversity, which further complicate the problem. Moreover, users and creators have different activeness levels on the platform, e.g., some users may watch a lot more videos than others, and some creators may post a lot more creations, these effects will also be strongly correlated with the dual influence of the recommender system. ", "page_idx": 31}, {"type": "text", "text": "H.2 Creation Quality ", "text_level": 1, "page_idx": 31}, {"type": "text", "text": "Creation quality is a major factor influencing users\u2019 feedback in addition to the creation style, e.g., well-made cuisine videos could also be fun and liked by gamers and pet lovers, which we need more than a collaborative filtering type of modeling like our current model to capture such features. A ", "page_idx": 31}, {"type": "text", "text": "potential solution to boost both long-term system diversity and single-shot recommendation diversity is to design mechanisms that can incentivize creators to create higher-quality videos instead of changing their creation styles. ", "page_idx": 32}, {"type": "text", "text": "H.3 Cold Start ", "text_level": 1, "page_idx": 32}, {"type": "text", "text": "Cold Start is widely used in real-world recommender systems for newly published items. Due to the lack of user-item interactions on new items, the systems randomly recommend these new items to users and collect data for collaborative filtering. In our current model, if we consider the creators creating new items in each time step under their current time creation style, then cold start guarantees the conditions in Theorem 3.3. But if we consider the system to have good enough content understanding ability and can accurately predict the new creations\u2019 embeddings, the cold start is not necessary and our model and results in the top- $\\cdot k$ truncation and threshold truncation parts are valid. We also highlight a subtle difference between cold start and random traffic, if cold start is used on creators instead of items, then after the creator is exposed to users a certain number of times, the system will not guarantee to provide a non-zero probability of recommending this creator, and thus the conditions in Theorem 3.3 may not hold. ", "page_idx": 32}, {"type": "text", "text": "NeurIPS Paper Checklist ", "text_level": 1, "page_idx": 33}, {"type": "text", "text": "1. Claims ", "text_level": 1, "page_idx": 33}, {"type": "text", "text": "Question: Do the main claims made in the abstract and introduction accurately reflect the paper\u2019s contributions and scope? ", "page_idx": 33}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 33}, {"type": "text", "text": "Justification: ", "page_idx": 33}, {"type": "text", "text": "Guidelines: ", "page_idx": 33}, {"type": "text", "text": "\u2022 The answer NA means that the abstract and introduction do not include the claims made in the paper.   \n\u2022 The abstract and/or introduction should clearly state the claims made, including the contributions made in the paper and important assumptions and limitations. A No or NA answer to this question will not be perceived well by the reviewers.   \n\u2022 The claims made should match theoretical and experimental results, and reflect how much the results can be expected to generalize to other settings.   \n\u2022 It is fine to include aspirational goals as motivation as long as it is clear that these goals are not attained by the paper. ", "page_idx": 33}, {"type": "text", "text": "2. Limitations ", "text_level": 1, "page_idx": 33}, {"type": "text", "text": "Question: Does the paper discuss the limitations of the work performed by the authors? ", "page_idx": 33}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 33}, {"type": "text", "text": "Justification: Limitations are discussed in Section 6 and Section H. ", "page_idx": 33}, {"type": "text", "text": "Guidelines: ", "page_idx": 33}, {"type": "text", "text": "\u2022 The answer NA means that the paper has no limitation while the answer No means that the paper has limitations, but those are not discussed in the paper.   \n\u2022 The authors are encouraged to create a separate \"Limitations\" section in their paper.   \n\u2022 The paper should point out any strong assumptions and how robust the results are to violations of these assumptions (e.g., independence assumptions, noiseless settings, model well-specification, asymptotic approximations only holding locally). The authors should reflect on how these assumptions might be violated in practice and what the implications would be.   \n\u2022 The authors should reflect on the scope of the claims made, e.g., if the approach was only tested on a few datasets or with a few runs. In general, empirical results often depend on implicit assumptions, which should be articulated.   \n\u2022 The authors should reflect on the factors that influence the performance of the approach. For example, a facial recognition algorithm may perform poorly when image resolution is low or images are taken in low lighting. Or a speech-to-text system might not be used reliably to provide closed captions for online lectures because it fails to handle technical jargon.   \n\u2022 The authors should discuss the computational efficiency of the proposed algorithms and how they scale with dataset size.   \n\u2022 If applicable, the authors should discuss possible limitations of their approach to address problems of privacy and fairness.   \n\u2022 While the authors might fear that complete honesty about limitations might be used by reviewers as grounds for rejection, a worse outcome might be that reviewers discover limitations that aren\u2019t acknowledged in the paper. The authors should use their best judgment and recognize that individual actions in favor of transparency play an important role in developing norms that preserve the integrity of the community. Reviewers will be specifically instructed to not penalize honesty concerning limitations. ", "page_idx": 33}, {"type": "text", "text": "3. Theory Assumptions and Proofs ", "text_level": 1, "page_idx": 33}, {"type": "text", "text": "Question: For each theoretical result, does the paper provide the full set of assumptions and a complete (and correct) proof? ", "page_idx": 33}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 33}, {"type": "text", "text": "Justification: Proof sketches are given in the body and the full proofs are in the appendix. Guidelines: ", "page_idx": 34}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include theoretical results.   \n\u2022 All the theorems, formulas, and proofs in the paper should be numbered and crossreferenced.   \n\u2022 All assumptions should be clearly stated or referenced in the statement of any theorems.   \n\u2022 The proofs can either appear in the main paper or the supplemental material, but if they appear in the supplemental material, the authors are encouraged to provide a short proof sketch to provide intuition.   \n\u2022 Inversely, any informal proof provided in the core of the paper should be complemented by formal proofs provided in appendix or supplemental material.   \n\u2022 Theorems and Lemmas that the proof relies upon should be properly referenced. ", "page_idx": 34}, {"type": "text", "text": "4. Experimental Result Reproducibility ", "text_level": 1, "page_idx": 34}, {"type": "text", "text": "Question: Does the paper fully disclose all the information needed to reproduce the main experimental results of the paper to the extent that it affects the main claims and/or conclusions of the paper (regardless of whether the code and data are provided or not)? ", "page_idx": 34}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 34}, {"type": "text", "text": "Justification: Experiment details are provided in Section 5 and Section C. Guidelines: ", "page_idx": 34}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 If the paper includes experiments, a No answer to this question will not be perceived well by the reviewers: Making the paper reproducible is important, regardless of whether the code and data are provided or not.   \n\u2022 If the contribution is a dataset and/or model, the authors should describe the steps taken to make their results reproducible or verifiable.   \n\u2022 Depending on the contribution, reproducibility can be accomplished in various ways. For example, if the contribution is a novel architecture, describing the architecture fully might suffice, or if the contribution is a specific model and empirical evaluation, it may be necessary to either make it possible for others to replicate the model with the same dataset, or provide access to the model. In general. releasing code and data is often one good way to accomplish this, but reproducibility can also be provided via detailed instructions for how to replicate the results, access to a hosted model (e.g., in the case of a large language model), releasing of a model checkpoint, or other means that are appropriate to the research performed.   \n\u2022 While NeurIPS does not require releasing code, the conference does require all submissions to provide some reasonable avenue for reproducibility, which may depend on the nature of the contribution. For example (a) If the contribution is primarily a new algorithm, the paper should make it clear how to reproduce that algorithm. (b) If the contribution is primarily a new model architecture, the paper should describe the architecture clearly and fully. (c) If the contribution is a new model (e.g., a large language model), then there should either be a way to access this model for reproducing the results or a way to reproduce the model (e.g., with an open-source dataset or instructions for how to construct the dataset). (d) We recognize that reproducibility may be tricky in some cases, in which case authors are welcome to describe the particular way they provide for reproducibility. In the case of closed-source models, it may be that access to the model is limited in some way (e.g., to registered users), but it should be possible for other researchers to have some path to reproducing or verifying the results. ", "page_idx": 34}, {"type": "text", "text": "5. Open access to data and code ", "text_level": 1, "page_idx": 34}, {"type": "text", "text": "Question: Does the paper provide open access to the data and code, with sufficient instructions to faithfully reproduce the main experimental results, as described in supplemental material? ", "page_idx": 34}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 35}, {"type": "text", "text": "Justification: Provided in the supplemental file. Guidelines: ", "page_idx": 35}, {"type": "text", "text": "\u2022 The answer NA means that paper does not include experiments requiring code.   \n\u2022 Please see the NeurIPS code and data submission guidelines (https://nips.cc/ public/guides/CodeSubmissionPolicy) for more details.   \n\u2022 While we encourage the release of code and data, we understand that this might not be possible, so \u201cNo\u201d is an acceptable answer. Papers cannot be rejected simply for not including code, unless this is central to the contribution (e.g., for a new open-source benchmark).   \n\u2022 The instructions should contain the exact command and environment needed to run to reproduce the results. See the NeurIPS code and data submission guidelines (https: //nips.cc/public/guides/CodeSubmissionPolicy) for more details.   \n\u2022 The authors should provide instructions on data access and preparation, including how to access the raw data, preprocessed data, intermediate data, and generated data, etc.   \n\u2022 The authors should provide scripts to reproduce all experimental results for the new proposed method and baselines. If only a subset of experiments are reproducible, they should state which ones are omitted from the script and why.   \n\u2022 At submission time, to preserve anonymity, the authors should release anonymized versions (if applicable).   \n\u2022 Providing as much information as possible in supplemental material (appended to the paper) is recommended, but including URLs to data and code is permitted. ", "page_idx": 35}, {"type": "text", "text": "6. Experimental Setting/Details ", "text_level": 1, "page_idx": 35}, {"type": "text", "text": "Question: Does the paper specify all the training and test details (e.g., data splits, hyperparameters, how they were chosen, type of optimizer, etc.) necessary to understand the results? ", "page_idx": 35}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 35}, {"type": "text", "text": "Justification: See Section 5. Guidelines: ", "page_idx": 35}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments. \u2022 The experimental setting should be presented in the core of the paper to a level of detail that is necessary to appreciate the results and make sense of them. \u2022 The full details can be provided either with the code, in appendix, or as supplemental material. ", "page_idx": 35}, {"type": "text", "text": "7. Experiment Statistical Significance ", "text_level": 1, "page_idx": 35}, {"type": "text", "text": "Question: Does the paper report error bars suitably and correctly defined or other appropriate information about the statistical significance of the experiments? ", "page_idx": 35}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 35}, {"type": "text", "text": "Justification: ", "page_idx": 35}, {"type": "text", "text": "Guidelines: ", "page_idx": 35}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 The authors should answer \"Yes\" if the results are accompanied by error bars, confidence intervals, or statistical significance tests, at least for the experiments that support the main claims of the paper.   \n\u2022 The factors of variability that the error bars are capturing should be clearly stated (for example, train/test split, initialization, random drawing of some parameter, or overall run with given experimental conditions).   \n\u2022 The method for calculating the error bars should be explained (closed form formula, call to a library function, bootstrap, etc.)   \n\u2022 The assumptions made should be given (e.g., Normally distributed errors).   \n\u2022 It should be clear whether the error bar is the standard deviation or the standard error of the mean.   \n\u2022 It is OK to report 1-sigma error bars, but one should state it. The authors should preferably report a 2-sigma error bar than state that they have a $96\\%$ CI, if the hypothesis of Normality of errors is not verified.   \n\u2022 For asymmetric distributions, the authors should be careful not to show in tables or figures symmetric error bars that would yield results that are out of range (e.g. negative error rates).   \n\u2022 If error bars are reported in tables or plots, The authors should explain in the text how they were calculated and reference the corresponding figures or tables in the text. ", "page_idx": 35}, {"type": "text", "text": "", "page_idx": 36}, {"type": "text", "text": "8. Experiments Compute Resources ", "text_level": 1, "page_idx": 36}, {"type": "text", "text": "Question: For each experiment, does the paper provide sufficient information on the computer resources (type of compute workers, memory, time of execution) needed to reproduce the experiments? ", "page_idx": 36}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 36}, {"type": "text", "text": "Justification: Computer resources are not a limitation in our experiments. ", "page_idx": 36}, {"type": "text", "text": "Guidelines: ", "page_idx": 36}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 The paper should indicate the type of compute workers CPU or GPU, internal cluster, or cloud provider, including relevant memory and storage.   \n\u2022 The paper should provide the amount of compute required for each of the individual experimental runs as well as estimate the total compute.   \n\u2022 The paper should disclose whether the full research project required more compute than the experiments reported in the paper (e.g., preliminary or failed experiments that didn\u2019t make it into the paper). ", "page_idx": 36}, {"type": "text", "text": "9. Code Of Ethics ", "text_level": 1, "page_idx": 36}, {"type": "text", "text": "Question: Does the research conducted in the paper conform, in every respect, with the NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines? ", "page_idx": 36}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 36}, {"type": "text", "text": "Justification: Guidelines: ", "page_idx": 36}, {"type": "text", "text": "\u2022 The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics.   \n\u2022 If the authors answer No, they should explain the special circumstances that require a deviation from the Code of Ethics.   \n\u2022 The authors should make sure to preserve anonymity (e.g., if there is a special consideration due to laws or regulations in their jurisdiction). ", "page_idx": 36}, {"type": "text", "text": "10. Broader Impacts ", "text_level": 1, "page_idx": 36}, {"type": "text", "text": "Question: Does the paper discuss both potential positive societal impacts and negative societal impacts of the work performed? ", "page_idx": 36}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 36}, {"type": "text", "text": "Justification: Discussed in Section 6. ", "page_idx": 36}, {"type": "text", "text": "Guidelines: ", "page_idx": 36}, {"type": "text", "text": "\u2022 The answer NA means that there is no societal impact of the work performed.   \n\u2022 If the authors answer NA or No, they should explain why their work has no societal impact or why the paper does not address societal impact.   \n\u2022 Examples of negative societal impacts include potential malicious or unintended uses (e.g., disinformation, generating fake profiles, surveillance), fairness considerations (e.g., deployment of technologies that could make decisions that unfairly impact specific groups), privacy considerations, and security considerations.   \n\u2022 The conference expects that many papers will be foundational research and not tied to particular applications, let alone deployments. However, if there is a direct path to any negative applications, the authors should point it out. For example, it is legitimate to point out that an improvement in the quality of generative models could be used to ", "page_idx": 36}, {"type": "text", "text": "generate deepfakes for disinformation. On the other hand, it is not needed to point out that a generic algorithm for optimizing neural networks could enable people to train models that generate Deepfakes faster. ", "page_idx": 37}, {"type": "text", "text": "\u2022 The authors should consider possible harms that could arise when the technology is being used as intended and functioning correctly, harms that could arise when the technology is being used as intended but gives incorrect results, and harms following from (intentional or unintentional) misuse of the technology. \u2022 If there are negative societal impacts, the authors could also discuss possible mitigation strategies (e.g., gated release of models, providing defenses in addition to attacks, mechanisms for monitoring misuse, mechanisms to monitor how a system learns from feedback over time, improving the efficiency and accessibility of ML). ", "page_idx": 37}, {"type": "text", "text": "11. Safeguards ", "text_level": 1, "page_idx": 37}, {"type": "text", "text": "Question: Does the paper describe safeguards that have been put in place for responsible release of data or models that have a high risk for misuse (e.g., pretrained language models, image generators, or scraped datasets)? ", "page_idx": 37}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 37}, {"type": "text", "text": "Justification: ", "page_idx": 37}, {"type": "text", "text": "Guidelines: ", "page_idx": 37}, {"type": "text", "text": "\u2022 The answer NA means that the paper poses no such risks.   \n\u2022 Released models that have a high risk for misuse or dual-use should be released with necessary safeguards to allow for controlled use of the model, for example by requiring that users adhere to usage guidelines or restrictions to access the model or implementing safety filters.   \n\u2022 Datasets that have been scraped from the Internet could pose safety risks. The authors should describe how they avoided releasing unsafe images.   \n\u2022 We recognize that providing effective safeguards is challenging, and many papers do not require this, but we encourage authors to take this into account and make a best faith effort. ", "page_idx": 37}, {"type": "text", "text": "12. Licenses for existing assets ", "text_level": 1, "page_idx": 37}, {"type": "text", "text": "Question: Are the creators or original owners of assets (e.g., code, data, models), used in the paper, properly credited and are the license and terms of use explicitly mentioned and properly respected? ", "page_idx": 37}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 37}, {"type": "text", "text": "Justification: Guidelines: ", "page_idx": 37}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not use existing assets.   \n\u2022 The authors should cite the original paper that produced the code package or dataset.   \n\u2022 The authors should state which version of the asset is used and, if possible, include a URL.   \n\u2022 The name of the license (e.g., CC-BY 4.0) should be included for each asset.   \n\u2022 For scraped data from a particular source (e.g., website), the copyright and terms of service of that source should be provided.   \n\u2022 If assets are released, the license, copyright information, and terms of use in the package should be provided. For popular datasets, paperswithcode.com/datasets has curated licenses for some datasets. Their licensing guide can help determine the license of a dataset.   \n\u2022 For existing datasets that are re-packaged, both the original license and the license of the derived asset (if it has changed) should be provided.   \n\u2022 If this information is not available online, the authors are encouraged to reach out to the asset\u2019s creators. ", "page_idx": 37}, {"type": "text", "text": "13. New Assets ", "text_level": 1, "page_idx": 37}, {"type": "text", "text": "Question: Are new assets introduced in the paper well documented and is the documentation provided alongside the assets? ", "page_idx": 37}, {"type": "text", "text": "Answer: [NA] Justification: Guidelines: ", "page_idx": 38}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not release new assets.   \n\u2022 Researchers should communicate the details of the dataset/code/model as part of their submissions via structured templates. This includes details about training, license, limitations, etc.   \n\u2022 The paper should discuss whether and how consent was obtained from people whose asset is used.   \n\u2022 At submission time, remember to anonymize your assets (if applicable). You can either create an anonymized URL or include an anonymized zip file. ", "page_idx": 38}, {"type": "text", "text": "14. Crowdsourcing and Research with Human Subjects ", "text_level": 1, "page_idx": 38}, {"type": "text", "text": "Question: For crowdsourcing experiments and research with human subjects, does the paper include the full text of instructions given to participants and screenshots, if applicable, as well as details about compensation (if any)? ", "page_idx": 38}, {"type": "text", "text": "Answer: [NA] Justification: Guidelines: ", "page_idx": 38}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u2022 Including this information in the supplemental material is fine, but if the main contribution of the paper involves human subjects, then as much detail as possible should be included in the main paper.   \n\u2022 According to the NeurIPS Code of Ethics, workers involved in data collection, curation, or other labor should be paid at least the minimum wage in the country of the data collector. ", "page_idx": 38}, {"type": "text", "text": "15. Institutional Review Board (IRB) Approvals or Equivalent for Research with Human Subjects ", "page_idx": 38}, {"type": "text", "text": "Question: Does the paper describe potential risks incurred by study participants, whether such risks were disclosed to the subjects, and whether Institutional Review Board (IRB) approvals (or an equivalent approval/review based on the requirements of your country or institution) were obtained? ", "page_idx": 38}, {"type": "text", "text": "Answer: [NA] Justification: Guid ", "page_idx": 38}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u2022 Depending on the country in which research is conducted, IRB approval (or equivalent) may be required for any human subjects research. If you obtained IRB approval, you should clearly state this in the paper.   \n\u2022 We recognize that the procedures for this may vary significantly between institutions and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the guidelines for their institution.   \n\u2022 For initial submissions, do not include any information that would break anonymity (if applicable), such as the institution conducting the review. ", "page_idx": 38}]