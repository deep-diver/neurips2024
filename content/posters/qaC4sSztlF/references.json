{"references": [{"fullname_first_author": "Wenhu Chen", "paper_title": "Subject-driven text-to-image generation via apprenticeship learning", "publication_date": "2024", "reason": "This paper is foundational to the work presented, focusing on subject-driven generation in text-to-image models, which is directly relevant to the current research on safe concept transfer in multi-modal diffusion models."}, {"fullname_first_author": "Nataniel Ruiz", "paper_title": "Dreambooth: Fine tuning text-to-image diffusion models for subject-driven generation", "publication_date": "2023", "reason": "This paper introduces Dreambooth, a technique for fine-tuning text-to-image diffusion models, which is directly relevant to the current research on safe concept transfer and is a crucial comparison method."}, {"fullname_first_author": "Dongxu Li", "paper_title": "Blip-diffusion: Pre-trained subject representation for controllable text-to-image generation and editing", "publication_date": "2024", "reason": "This paper introduces BLIP-Diffusion, a model for controllable text-to-image generation and editing, which is a key component of the proposed CRE framework and used in the experiments."}, {"fullname_first_author": "Xichen Pan", "paper_title": "Kosmos-G: Generating images in context with multimodal large language models", "publication_date": "2023", "reason": "This paper introduces Kosmos-G, the main multi-modal diffusion model used in the experiments for safe concept transfer, making it a crucial reference for understanding the experimental results."}, {"fullname_first_author": "Patrick Schramowski", "paper_title": "Safe latent diffusion: Mitigating inappropriate degeneration in diffusion models", "publication_date": "2023", "reason": "This paper proposes Safe Latent Diffusion (SLD), a method for mitigating unsafe generation in diffusion models, which is directly compared to the proposed CRE framework."}]}