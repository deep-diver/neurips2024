[{"figure_path": "qaC4sSztlF/figures/figures_2_1.jpg", "caption": "Figure 1: Method Overview of CRE. Users of VL2I models (U-Net) might input/query images containing unsafe concepts as reference images (objects or styles), here taking the \"Van Gogh\" style as an example. CRE consists of two main phases. Phase 1 involves discriminator training and causal period search for each unsafe concept category, which can be performed offline (omitted from this figure, see section 3.3 for details). During inference (phase 2, i.e., the right side of this figure), if the reference image contains unsafe concepts, the editing function of CRE is applied within the U-Net layers. Otherwise, the generated content is faithful to the user-specified prompts without modification.", "description": "This figure illustrates the Causal Representation Editing (CRE) framework.  Users provide a prompt (text and/or image) which may include unsafe concepts. CRE operates in two phases: offline training of a discriminator to identify unsafe concepts and determination of causal periods for their removal; and online inference where, if unsafe concepts are detected, CRE edits the latent representation within the U-Net of a VL2I diffusion model during specific timesteps (causally linked to the unsafe concepts). This results in the generation of safe images while preserving other aspects of the original prompt.", "section": "3 Safe Concept Transfer"}, {"figure_path": "qaC4sSztlF/figures/figures_6_1.jpg", "caption": "Figure 2: Qualitative results on COCO-30k dataset.", "description": "This figure displays qualitative results of the proposed CRE method on the COCO-30k dataset.  It shows a comparison between the results generated by Kosmos-G, CRE with a cassette player as a reference, and CRE with Mickey Mouse as a reference. The images demonstrate how the CRE method effectively removes or transfers the specified objects (cassette player or Mickey Mouse) from the input image while maintaining the overall quality and context of the generated images.", "section": "4 Experiments"}, {"figure_path": "qaC4sSztlF/figures/figures_8_1.jpg", "caption": "Figure 3: Qualitative safe generation results on object transfer (left) and style transfer (right).", "description": "This figure shows a qualitative comparison of the results obtained using Kosmos-G, SLD, ProtoRe, and the proposed CRE method for both object and style transfer tasks.  The left side demonstrates object removal from generated images, while the right side shows style transfer with the removal of an undesired style.  The images illustrate the effectiveness of CRE in precisely removing unsafe concepts while preserving the overall quality and coherence of the generated images.  Kosmos-G without any safety mechanism is provided as a baseline for comparison.", "section": "3 Safe Concept Transfer"}, {"figure_path": "qaC4sSztlF/figures/figures_8_2.jpg", "caption": "Figure 3: Qualitative safe generation results on object transfer (left) and style transfer (right).", "description": "This figure shows a comparison of image generation results using different methods for safe object and style transfer. The \"Original image\" row displays the input images. The \"Unsafe concepts\" row shows examples of unsafe concepts such as specific objects or artistic styles.  The \"Kosmos-G\" row demonstrates the results of the Kosmos-G model without any safety mechanisms, showing the transfer of unsafe concepts. The subsequent rows (SLD, ProtoRe, and CRE) illustrate the results from different safe generation methods, highlighting their effectiveness in removing or mitigating the unsafe concepts while preserving the overall image quality. The left side focuses on object transfer, and the right side focuses on style transfer.  The figure visually demonstrates the superior performance of the proposed CRE method in achieving safer image generation.", "section": "3 Safe Concept Transfer"}, {"figure_path": "qaC4sSztlF/figures/figures_9_1.jpg", "caption": "Figure 5: Safe generation under complex scenarios (left); with precise mitigation (right).", "description": "This figure demonstrates the effectiveness of the proposed Causal Representation Editing (CRE) method in handling complex scenarios and achieving precise mitigation of unsafe concepts. The left panel showcases CRE's ability to remove unsafe concepts from images even when they are blurred, taken with mobile phones, cropped, overexposed, or oversaturated. The right panel highlights the precision of CRE by showing how it selectively removes specific unsafe styles (Van Gogh, hat) while preserving other aspects of the generated image.", "section": "Complex scenarios and precise mitigation"}, {"figure_path": "qaC4sSztlF/figures/figures_13_1.jpg", "caption": "Figure 1: Method Overview of CRE. Users of VL2I models (U-Net) might input/query images containing unsafe concepts as reference images (objects or styles), here taking the \"Van Gogh\" style as an example. CRE consists of two main phases. Phase 1 involves discriminator training and causal period search for each unsafe concept category, which can be performed offline (omitted from this figure, see section 3.3 for details). During inference (phase 2, i.e., the right side of this figure), if the reference image contains unsafe concepts, the editing function of CRE is applied within the U-Net layers. Otherwise, the generated content is faithful to the user-specified prompts without modification.", "description": "This figure illustrates the Causal Representation Editing (CRE) framework.  It shows how CRE processes user inputs (including potentially unsafe content) during two phases. Phase 1 (offline) trains a discriminator to identify unsafe concepts and determines the causal period for their removal. Phase 2 (inference) applies representation editing within the U-Net layers of a Vision-Language-to-Image model only if unsafe concepts are detected, thus ensuring safe content generation.", "section": "3 Safe Concept Transfer"}, {"figure_path": "qaC4sSztlF/figures/figures_16_1.jpg", "caption": "Figure 6: Examples of Style Dataset Final. This dataset is used for training the classifier. For \u201cDisney\u201d, \u201cPencil Sketch\u201d, \u201cPicasso\u201d, and \u201cVan Gogh\u201d, High Variance & High Bias means the images are selected from Style Dataset 1, Medium Variance & Medium Bias means the images are selected from Style Dataset 2, Ligh Variance & Ligh Bias means the images are selected from Style Dataset 3.", "description": "This figure shows examples of the final style dataset used to train the classifier for the style transfer task.  The dataset is divided into three groups based on variance and bias: High Variance & High Bias, Medium Variance & Medium Bias, and Low Variance & Low Bias.  Each group contains images representing the \"Normal\" class and four unsafe styles (Disney, Pencil Sketch, Picasso, and Van Gogh). The High Variance & High Bias images are from Style Dataset 1, the Medium Variance & Medium Bias images are from Style Dataset 2, and the Low Variance & Low Bias images are from Style Dataset 3.  The image shows a grid of images for each style and variance/bias combination.", "section": "C.1 Dataset Construction"}, {"figure_path": "qaC4sSztlF/figures/figures_17_1.jpg", "caption": "Figure 7: Object transfer with Kosmos-G and Kosmos-G-Neg.", "description": "This figure shows a qualitative comparison of object transfer results using Kosmos-G and Kosmos-G-Neg.  Kosmos-G-Neg appends a negative prompt to the Kosmos-G prompt in an attempt to prevent the generation of unsafe concepts.  The left column displays example images of the 10 object categories used as unsafe concepts. The middle and right columns display the results generated using Kosmos-G and Kosmos-G-Neg respectively. By visually inspecting the results, one can qualitatively assess the effectiveness of the negative prompt approach in mitigating the generation of unsafe concepts. This figure supports the paper's claim that simply adding a negative prompt is not effective for preventing the transfer of harmful concepts.", "section": "4 Experiments"}, {"figure_path": "qaC4sSztlF/figures/figures_17_2.jpg", "caption": "Figure 8: Style transfer with Kosmos-G and Kosmos-G-Neg.", "description": "This figure displays a comparison of style transfer results between Kosmos-G and Kosmos-G-Neg.  Kosmos-G-Neg uses negative prompts to try to prevent the transfer of unsafe styles. Each row represents a different unsafe style (Disney, Pencil Sketch, Picasso, Van Gogh), and each column shows the style transfer results for Kosmos-G and Kosmos-G-Neg respectively, using the same base image each time. The results illustrate the differences in style transfer capability and safety between the two approaches.", "section": "D Concept Transfer with Kosmos-G and Kosmos-G-Neg"}, {"figure_path": "qaC4sSztlF/figures/figures_18_1.jpg", "caption": "Figure 9: Ablation study on representation editing with projection. Projection significantly enhances the quality of image generation while preserving safe concepts such as backgrounds, resulting in more coherent and contextually accurate visuals. Our approach not only improves the overall fidelity of the generated images but also ensures that the integrity of essential components, such as backgrounds and other safe concepts, is maintained. This method effectively balances creative generation and safety compliance, ensuring that the generated content adheres to desired safety standards without compromising visual quality.", "description": "This figure demonstrates the impact of using projection in representation editing.  The left side shows object transfer, while the right shows style transfer.  Each side compares results with and without projection.  The results show that projection significantly improves image quality while maintaining the integrity of safe elements like backgrounds, striking a balance between creative generation and safety.", "section": "3.3 Causal Representation Editing"}, {"figure_path": "qaC4sSztlF/figures/figures_19_1.jpg", "caption": "Figure 10: Attention map comparison between the process of normal Kosmos-G and CRE. Take safe object transfer as an example, the image shows one of the attention maps in the whole process of normal Kosmos-G and CRE. We can find that at the very beginning (i.e., the image with index 00, which represents t=T), the attention maps in the two processes are somewhat similar to a certain extent. But just after a few timesteps, the attention maps are quite different. It shows that earlier diffusion steps have a big difference in object generation, and CRE can certainly remove the unsafe concept in the attention step, which is after the forward step of the attention map.", "description": "This figure compares the attention maps of Kosmos-G and CRE during the diffusion process.  The comparison highlights that while initially similar, the attention maps diverge quickly, demonstrating CRE's ability to remove unsafe concepts early in the generation process.", "section": "3.3 Causal Representation Editing"}, {"figure_path": "qaC4sSztlF/figures/figures_20_1.jpg", "caption": "Figure 1: Method Overview of CRE. Users of VL2I models (U-Net) might input/query images containing unsafe concepts as reference images (objects or styles), here taking the \"Van Gogh\" style as an example. CRE consists of two main phases. Phase 1 involves discriminator training and causal period search for each unsafe concept category, which can be performed offline (omitted from this figure, see section 3.3 for details). During inference (phase 2, i.e., the right side of this figure), if the reference image contains unsafe concepts, the editing function of CRE is applied within the U-Net layers. Otherwise, the generated content is faithful to the user-specified prompts without modification.", "description": "This figure illustrates the overall framework of Causal Representation Editing (CRE). It shows how CRE intervenes in the process of vision-language-to-image (VL2I) generation using a U-Net model to remove unsafe concepts from the generated images. The figure is divided into two phases. Phase 1 includes discriminator training and causal period search for unsafe concepts, which can be done offline. Phase 2 shows how CRE works during inference time by applying the editing function to remove unsafe concepts from the latent representations within the U-Net layers, ensuring the generated images are safe while maintaining fidelity to user prompts.", "section": "3 Safe Concept Transfer"}, {"figure_path": "qaC4sSztlF/figures/figures_21_1.jpg", "caption": "Figure 1: Method Overview of CRE. Users of VL2I models (U-Net) might input/query images containing unsafe concepts as reference images (objects or styles), here taking the \u201cVan Gogh\u201d style as an example. CRE consists of two main phases. Phase 1 involves discriminator training and causal period search for each unsafe concept category, which can be performed offline (omitted from this figure, see section 3.3 for details). During inference (phase 2, i.e., the right side of this figure), if the reference image contains unsafe concepts, the editing function of CRE is applied within the U-Net layers. Otherwise, the generated content is faithful to the user-specified prompts without modification.", "description": "This figure illustrates the Causal Representation Editing (CRE) framework proposed in the paper. It shows how CRE works in two phases: an offline phase for discriminator training and causal period search, and an online inference phase where the model identifies and removes unsafe concepts from the generated images by editing the latent representations within the U-Net layers.  The example uses Van Gogh's style as a reference to highlight the process of identifying and removing unsafe concepts.", "section": "3 Safe Concept Transfer"}, {"figure_path": "qaC4sSztlF/figures/figures_22_1.jpg", "caption": "Figure 13: Qualitative results on timestep selection.", "description": "This figure presents a qualitative comparison of image generation results using Kosmos-G with and without Causal Representation Editing (CRE), focusing on the impact of selecting different timesteps for applying the CRE method. The top row shows the prompt and the timestep range used for CRE. The subsequent rows show the generated images from Kosmos-G without CRE, Kosmos-G with CRE applied to the specified timesteps, and Kosmos-G with CRE applied to a different timestep range.  Each column represents a different prompt, allowing for observing the effect of different timestep ranges across various prompts. It helps to illustrate how the choice of timesteps influences the effectiveness of CRE in removing unsafe concepts while preserving the overall image quality.", "section": "Experiments"}, {"figure_path": "qaC4sSztlF/figures/figures_23_1.jpg", "caption": "Figure 1: Method Overview of CRE. Users of VL2I models (U-Net) might input/query images containing unsafe concepts as reference images (objects or styles), here taking the \u201cVan Gogh\u201d style as an example. CRE consists of two main phases. Phase 1 involves discriminator training and causal period search for each unsafe concept category, which can be performed offline (omitted from this figure, see section 3.3 for details). During inference (phase 2, i.e., the right side of this figure), if the reference image contains unsafe concepts, the editing function of CRE is applied within the U-Net layers. Otherwise, the generated content is faithful to the user-specified prompts without modification.", "description": "This figure illustrates the Causal Representation Editing (CRE) framework proposed in the paper. It shows how CRE intervenes in the image generation process of vision-language-to-image (VL2I) diffusion models to remove unsafe concepts from the generated images while preserving the quality of the acceptable content. The framework involves two phases: an offline phase (discriminator training and causal period search) and an online phase (inference-time intervention). The figure highlights the process of the online phase, showing how the editing function of CRE modifies the latent representation within the U-Net layers to remove unsafe concepts from the generated images.", "section": "3 Safe Concept Transfer"}]