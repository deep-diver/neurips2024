[{"figure_path": "2WQjNXZbhR/tables/tables_2_1.jpg", "caption": "Table 1: The overview of current works with quadratic format.", "description": "This table summarizes existing works that utilize quadratic formats in neural networks.  It compares different approaches based on how the quadratic operation is used (pixel-wise or channel-wise), whether there is a biological interpretation to support the approach, and whether there is a theoretical basis for its generalization capabilities.  The Dit-CNNs proposed in this paper are included for comparison.", "section": "2 Related work"}, {"figure_path": "2WQjNXZbhR/tables/tables_5_1.jpg", "caption": "Table 2: Comparative performance of Dit-ResNets and structurally similar models on CIFAR.", "description": "This table presents a comparison of the performance of Dit-ResNets (the proposed model) against standard ResNet models and other similar models that incorporate quadratic neurons, across different depths (20, 32, 56, 110) on CIFAR-10 and CIFAR-100 datasets.  The comparison includes the number of parameters and the accuracy achieved.  It shows that the Dit-ResNets achieve higher accuracy with fewer parameters, highlighting the effectiveness of the proposed approach.", "section": "4.1 Evaluations on CIFAR-10 and CIFAR-100"}, {"figure_path": "2WQjNXZbhR/tables/tables_7_1.jpg", "caption": "Table 3: Dit-ConvNeXts versus state-of-the-art (SOTA) models on ImageNet-1K. All models listed in the table are trained and validated at a resolution of 224 \u00d7 224.", "description": "This table compares the performance of Dit-ConvNeXt models (proposed in the paper) against other state-of-the-art (SOTA) models on the ImageNet-1K dataset.  The comparison includes various architectural categories like Transformers, State Space Models, and CNNs.  For each model, the number of parameters, FLOPs (floating point operations), and top-1 accuracy are provided.  The results demonstrate the competitive performance of Dit-ConvNeXt models, achieving high accuracy with relatively efficient use of parameters and computational resources.", "section": "4.1 Evaluations on CIFAR-10 and CIFAR-100"}, {"figure_path": "2WQjNXZbhR/tables/tables_8_1.jpg", "caption": "Table 4: The performance of Dit-CNNs and their counterparts, from which the covariance term tr(\u0391\u03a3) and the quadratic term x<sup>T</sup>Ax are omitted in quadratic neurons (\u03a3 is estimated from training samples).", "description": "This table presents the performance comparison of Dit-CNNs (Dendritic Integration inspired CNNs) and their variations on three different datasets: CIFAR-10, CIFAR-100, and ImageNet-1K.  The original Dit-CNNs' performance is compared against two modified versions: one where the covariance term tr(\u0391\u03a3) is removed and another where the quadratic term x<sup>T</sup>Ax is removed from the quadratic neurons. The results highlight the significant contribution of both terms, particularly the covariance term, to the overall performance of the Dit-CNN models. ", "section": "4.3 Ablation study"}, {"figure_path": "2WQjNXZbhR/tables/tables_8_2.jpg", "caption": "Table 5: Comparison of quadratic neurons between channel-wise and pixel-wise", "description": "This table compares the performance of channel-wise and pixel-wise application of quadratic neurons in ConvNeXt models of various sizes (T, S, B).  The results demonstrate that the channel-wise application of quadratic neurons, as proposed in the Dit-CNN architecture, yields significantly higher top-1 accuracy on ImageNet-1K compared to the pixel-wise approach.", "section": "4.3.3 Channel/Pixel-wise quadratic neuron utilizations on ImageNet-1K"}, {"figure_path": "2WQjNXZbhR/tables/tables_18_1.jpg", "caption": "Table 2: Comparative performance of Dit-ResNets and structurally similar models on CIFAR.", "description": "This table presents a comparison of the performance of Dit-ResNets (the proposed model) and other similar models on CIFAR-10 and CIFAR-100 datasets.  It shows the number of parameters, accuracy on CIFAR-10, and accuracy on CIFAR-100 for different ResNet models (ResNet-20, ResNet-32, ResNet-56, and ResNet-110), their quadratic counterparts from prior work (QResNet and QuadraResNet), and the proposed Dit-ResNet models. The results demonstrate the improved performance of Dit-ResNets in terms of accuracy while maintaining a similar number of parameters compared to the original ResNet models.", "section": "4.1 Evaluations on CIFAR-10 and CIFAR-100"}]