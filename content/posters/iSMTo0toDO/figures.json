[{"figure_path": "iSMTo0toDO/figures/figures_0_1.jpg", "caption": "Figure 1: Equilibrium probability of the six different 3D structures (c1-c6) of the same molecule ibuprofen (C13H18O2) in four different conditions. (Adapted with permission from [26]. Copyright 2018 American Chemical Society.)", "description": "This figure shows the equilibrium probability of six different 3D conformations (c1-c6) of the ibuprofen molecule under four different conditions: solution, adsorbed, surface, and solid.  The graph visually demonstrates that the probability distribution of conformations varies significantly depending on the environment. This highlights the importance of considering the 3D structure of molecules and its relationship with the surrounding environment, which is a key motivation for the research presented in the paper.", "section": "Introduction"}, {"figure_path": "iSMTo0toDO/figures/figures_1_1.jpg", "caption": "Figure 2: Comparison of forward process between DDPM [9] and subgraph diffusion. For each step, DDPM adds noise into all atomic coordinates, while subgraph diffusion selects a subset of the atoms to diffuse.", "description": "This figure compares the forward diffusion processes of two models: DDPM and SubgDiff.  DDPM adds Gaussian noise to all atomic coordinates of a 3D molecule at each diffusion step. In contrast, SubgDiff only adds noise to a randomly selected subgraph at each step.  This highlights SubgDiff's key innovation of incorporating substructural information into the diffusion process by selectively applying noise to subgraphs, rather than treating each atom independently.", "section": "1 Introduction"}, {"figure_path": "iSMTo0toDO/figures/figures_3_1.jpg", "caption": "Figure 3: The Markov Chain of SubgDiff is a lazy Markov Chain.", "description": "This figure illustrates the Markov chain used in the SubgDiff model.  It shows how the model transitions between states, indicating the conditional probability of moving from state R<sub>t-1</sub> to R<sub>t</sub>.  The transition depends on the value of the mask vector s<sub>t</sub>. If s<sub>t</sub> = 0, the model remains in the same state (lazy transition); otherwise, if s<sub>t</sub> = 1, it transitions to state R<sub>t</sub>. This representation emphasizes the model's ability to incorporate substructural information by selectively introducing noise only to certain atoms or subgraphs of the molecule.", "section": "4 SubgDiff"}, {"figure_path": "iSMTo0toDO/figures/figures_6_1.jpg", "caption": "Figure 4: The forward process of SubgDiff. The state 0 to km uses the expectation state and the mask variables are the same in the interval [ki, ki + k], i = 0, 1, ..., m \u2212 1. The state km + 1 to t applies the same subgraph diffusion.", "description": "The figure illustrates the forward diffusion process of the SubgDiff model. It is divided into two phases: expectation state diffusion and (t-km)-step same-subgraph diffusion. In the first phase (steps 0 to km), the expectation of the atomic coordinates is used, and the mask variables are kept constant within intervals of length k.  In the second phase (steps km+1 to t), the same subgraph is selected for diffusion, indicating a k-step same-subgraph diffusion. The figure visually represents the process with 3D molecular structures at various stages, showcasing how noise is added and subgraphs are processed.", "section": "4 SubgDiff"}, {"figure_path": "iSMTo0toDO/figures/figures_6_2.jpg", "caption": "Figure 4: The forward process of SubgDiff. The state 0 to km uses the expectation state and the mask variables are the same in the interval [ki, ki + k], i = 0, 1, ..., m \u2212 1. The state km + 1 to t applies the same subgraph diffusion.", "description": "This figure illustrates the forward diffusion process of the SubgDiff model. It highlights two phases: the expectation state diffusion (from state 0 to km) and the k-step same-subgraph diffusion (from km+1 to t).  In the expectation state phase, the model leverages the mean of the atom coordinates (expectation state) instead of the actual coordinates to add noise, making it less sensitive to the specific subgraph selected. The second phase employs the k-step same-subgraph diffusion, applying noise to the same randomly selected subgraph for k consecutive steps, enhancing the model's ability to learn substructure features.  The overall process allows SubgDiff to effectively capture substructural information within the molecule during training.", "section": "4 SubgDiff"}, {"figure_path": "iSMTo0toDO/figures/figures_7_1.jpg", "caption": "Figure 2: Comparison of forward process between DDPM [9] and subgraph diffusion. For each step, DDPM adds noise into all atomic coordinates, while subgraph diffusion selects a subset of the atoms to diffuse.", "description": "This figure compares the forward diffusion processes of two different models: DDPM and SubgDiff.  DDPM adds Gaussian noise to all atomic coordinates of a 3D molecule at each step of the diffusion process. In contrast, SubgDiff only adds noise to a randomly selected subset of atoms (a subgraph) at each step. This highlights the key difference between the two methods: SubgDiff incorporates substructural information by selectively diffusing subsets of atoms, whereas DDPM treats each atom independently.", "section": "1 Introduction"}, {"figure_path": "iSMTo0toDO/figures/figures_15_1.jpg", "caption": "Figure 6: T-distributed stochastic neighbor embedding (t-SNE) visualization of the learned molecules representations, colored by the scaffolds of the molecules.", "description": "This figure visualizes the results of a t-distributed stochastic neighbor embedding (t-SNE) dimensionality reduction technique applied to molecule representations learned by the model.  Each point represents a molecule, and the color of the point indicates the scaffold (core structure) of that molecule.  The visualization aims to show whether molecules with the same scaffold cluster together in the representation space.  Close clustering suggests that the model has learned to effectively capture scaffold information as a key feature for representing molecules.", "section": "A Experiment details and more results"}, {"figure_path": "iSMTo0toDO/figures/figures_19_1.jpg", "caption": "Figure 7: The model architecture for denoising SubgDiff.", "description": "The figure illustrates the architecture of the SubgDiff model used for denoising. It shows the process of adding noise to 3D molecular structures, the encoding of the noisy structures using a GNN encoder, and the prediction of both the mask (selecting subgraphs) and the noise using separate mask and noise heads.  The objective function involves both a binary cross-entropy loss for mask prediction (L1) and a mean squared error loss for noise prediction (L2).", "section": "4 SubgDiff"}, {"figure_path": "iSMTo0toDO/figures/figures_32_1.jpg", "caption": "Figure 4: The forward process of SubgDiff. The state 0 to km uses the expectation state and the mask variables are the same in the interval [ki, ki + k], i = 0, 1, ..., m \u2212 1. The state km + 1 to t applies the same subgraph diffusion.", "description": "This figure illustrates the forward diffusion process of the SubgDiff model.  It shows how the model incorporates subgraph information by using expectation states for a portion of the process and then applying k-step same-subgraph diffusion for another portion. The different stages highlight how noise is added and how subgraphs are chosen and consistently diffused for a fixed number of steps.  The orange dashed boxes represent the subgraph that is selected at each step.", "section": "4.1 Involving subgraph into diffusion process"}]