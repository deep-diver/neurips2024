[{"figure_path": "WEs4WMzndY/tables/tables_7_1.jpg", "caption": "Table 1: Results on UCI regression benchmark datasets comparing Distortion. Experimental setup is described in Section 5.1.1. Relaxed-WTA results were computed with \u03b5 = 0.1 which strikes a good tradeoff between RMSE and Distortion (see Table 5 in Appendix). The rows are ordered by dataset size N. Best results are in bold, second bests are underlined.", "description": "This table presents the results of the UCI regression benchmark experiments, comparing the distortion metric achieved by three different methods: Relaxed-WTA, MCL, and aMCL.  The table highlights the performance of each method on various datasets, indicating the best and second-best performing methods for each dataset.  The results are organized by the size of the dataset, and the best and second-best results are emphasized for clarity.", "section": "5.1 UCI datasets"}, {"figure_path": "WEs4WMzndY/tables/tables_8_1.jpg", "caption": "Table 2: Results on UCI regression benchmark datasets comparing RMSE. Best results are in bold, second bests are underlined. * corresponds to reported results from [38].", "description": "This table compares the Root Mean Squared Error (RMSE) achieved by different regression models on several UCI datasets.  The models compared include PBP, MC Dropout, Deep Ensembles (all from prior work), Relaxed-WTA (a variant of the proposed method), standard MCL, and the proposed aMCL.  The table shows that aMCL generally achieves comparable or better performance than other methods.", "section": "5.1.2 Results"}, {"figure_path": "WEs4WMzndY/tables/tables_9_1.jpg", "caption": "Table 3: 2- and 3- speaker source separation with PIT (topline), MCL, aMCL and Relaxed-WTA (\u03b5 = 0.05). PIT SI-SDR metric (\u2191) on the WSJ0-mix eval set. Results over three training seeds, with mean and standard deviation reported.", "description": "This table presents the results of a source separation experiment using four different methods: PIT, MCL, aMCL, and Relaxed-WTA.  The experiment was conducted on the WSJ0-mix dataset with 2 and 3 speakers. The results are reported as the mean and standard deviation of the PIT SI-SDR (Scale-Invariant Signal-to-Distortion Ratio) metric over three different training seeds.  The PIT SI-SDR is a measure of the quality of source separation, with higher values indicating better performance. The table shows that the performance of aMCL is comparable to PIT and better than MCL and Relaxed-WTA.", "section": "5.2 Results"}, {"figure_path": "WEs4WMzndY/tables/tables_22_1.jpg", "caption": "Table 2: Results on UCI regression benchmark datasets comparing RMSE. Best results are in bold, second bests are underlined. * corresponds to reported results from [38].", "description": "This table compares the Root Mean Squared Error (RMSE) of different methods on UCI regression benchmark datasets.  It includes the proposed Annealed Multiple Choice Learning (aMCL) method and several baselines (Probabilistic Backpropagation, Monte Carlo Dropout, Deep Ensembles, Relaxed-WTA, and MCL).  The results show how aMCL compares to the baselines in terms of RMSE and indicates whether aMCL outperforms or performs comparably to existing methods.", "section": "5.1 UCI datasets"}, {"figure_path": "WEs4WMzndY/tables/tables_24_1.jpg", "caption": "Table 1: Results on UCI regression benchmark datasets comparing Distortion. Experimental setup is described in Section 5.1.1. Relaxed-WTA results were computed with \u03b5 = 0.1 which strikes a good tradeoff between RMSE and Distortion (see Table 5 in Appendix). The rows are ordered by dataset size N. Best results are in bold, second bests are underlined.", "description": "This table presents the results of the UCI regression benchmark experiments comparing different methods in terms of Distortion.  It shows the performance of MCL, aMCL, and Relaxed-WTA (with epsilon = 0.1) across several datasets. The rows are sorted by dataset size.  Best and second-best results are highlighted.", "section": "5.1 UCI datasets"}, {"figure_path": "WEs4WMzndY/tables/tables_24_2.jpg", "caption": "Table 5: Impact of \u03b5 in Relaxed-WTA on UCI regression benchmark datasets comparing RMSE and Distortion. Best results are in bold, second bests are underlined. The annealed version of Relaxed-WTA (R-WTA) uses a linear scheduler starting at \u03b50 = 0.5 and decreasing to 0.", "description": "This table compares the performance of Relaxed-WTA with different values of epsilon (\u03b5) on UCI regression datasets.  It shows RMSE and Distortion metrics for Relaxed-WTA with fixed \u03b5 values (0.5, 0.1) and an annealed \u03b5, demonstrating how the choice of \u03b5 impacts performance, and indicating that a lower or annealed \u03b5 generally produces better results for the Distortion metric.", "section": "5.1.2 Results"}, {"figure_path": "WEs4WMzndY/tables/tables_27_1.jpg", "caption": "Table 6: Configuration of the DPRNN model used for source separation experiments.", "description": "This table shows the hyperparameters used for the DPRNN model in the speech separation experiments.  It lists the values for parameters such as feature dimension, encoder/decoder kernel size, stride, DPRNN chunk size, hidden dimension, and the number of DPRNN blocks.", "section": "5.2.1 Experimental setting"}, {"figure_path": "WEs4WMzndY/tables/tables_28_1.jpg", "caption": "Table 3: 2- and 3- speaker source separation with PIT (topline), MCL, aMCL and Relaxed-WTA (\u03b5 = 0.05). PIT SI-SDR metric (\u2191) on the WSJ0-mix eval set. Results over three training seeds, with mean and standard deviation reported.", "description": "This table presents the results of a source separation experiment using four different methods: PIT, MCL, aMCL, and Relaxed-WTA.  The experiment was conducted on the WSJ0-mix evaluation set, with separate results for 2-speaker and 3-speaker scenarios.  The results are the mean and standard deviation of the PIT SI-SDR (Scale-Invariant Signal-to-Distortion Ratio) metric, averaged across three independent training runs.", "section": "5.2.2 Results"}, {"figure_path": "WEs4WMzndY/tables/tables_28_2.jpg", "caption": "Table 7: Comparison of the training methods PIT, MCL, and aMCL, for the task of source separation of 2 and 3 speakers. The performance is measured using the PIT SI-SDR metric (left) and the MCL SI-SDR metric (right) computed on the WSJ0-mix evaluation subset. Each method is trained using three seeds and we report inter-seed average score and standard deviation.", "description": "This table compares the performance of three different methods for speech separation: PIT, MCL, and aMCL.  It shows the average PIT and MCL SI-SDR scores for 2-speaker and 3-speaker scenarios, along with standard deviations across three training runs.  The results highlight the performance of each method and their relative robustness to initial conditions.", "section": "5.2 Application to speech separation"}]