[{"figure_path": "e6WrwIvgzX/figures/figures_1_1.jpg", "caption": "Figure 1: Representative example for 2 model setup in AutoMix. Instead of relying only on small model (SLM) with low performance or a large model (LLM) with high cost, AutoMix automatically mixes multiple black-box language models, based on user desired cost-quality tradeoff. AutoMix works in a 3-step process: 1.) generation by a small model (LM\u2081), 2.) self-verification of the generated answer, 3.) using confidence assessments from self-verification to do appropriate routing to a larger model (LM2). For N-model setup, the process is repeated till the final answer is reported.", "description": "This figure illustrates the AutoMix framework's workflow with two language models (a small model, SLM, and a large model, LLM).  AutoMix routes queries to the appropriate model based on cost and accuracy, dynamically switching between them. The process involves three steps: (1) Generation: The SLM generates an initial response. (2) Self-Verification: The SLM verifies the accuracy of its own response. (3) Routing: A POMDP (Partially Observable Markov Decision Process) router uses the verification results to decide whether to send the query to the LLM (if the initial response is deemed unreliable) or to return the SLM's response directly (if the initial response is considered sufficient).  The cycle repeats for setups with more than two models.", "section": "1 Introduction"}, {"figure_path": "e6WrwIvgzX/figures/figures_2_1.jpg", "caption": "Figure 1: Representative example for 2 model setup in AutoMix. Instead of relying only on small model (SLM) with low performance or a large model (LLM) with high cost, AutoMix automatically mixes multiple black-box LMs, based on user desired cost-quality tradeoff. AutoMix works in a 3-step process: 1.) generation by a small model (LM\u2081), 2.) self-verification of the generated answer, 3.) using confidence assessments from self-verification to do appropriate routing to a larger model (LM2). For N-model setup, the process is repeated till the final answer is reported.", "description": "This figure illustrates the workflow of AutoMix using two language models (small and large). AutoMix makes use of a small model to generate an answer, then uses self-verification to assess the answer's reliability before deciding whether to use a larger model to improve the answer. This process balances cost and accuracy, making it efficient and adaptable.", "section": "1 Introduction"}, {"figure_path": "e6WrwIvgzX/figures/figures_3_1.jpg", "caption": "Figure 2: Context-Grounded Self-Verification using LLAMA2-13B in Action. The example showcases the verifier, utilizing the same model as the answer generator, identifying and rejecting an inaccurate answer\u2014He took it in 1990\u2014by effectively leveraging the context.", "description": "This figure shows an example of how AutoMix's self-verification mechanism works.  A smaller language model (LLAMA2-13B) generates an answer to a question (\"When did Shen Nong drink tea?\").  The same model then acts as a verifier, comparing the generated answer (\"He took it in 1990.\") against the provided context. Because the context does not support the generated answer, the verifier correctly identifies it as incorrect.", "section": "4 AutoMix"}, {"figure_path": "e6WrwIvgzX/figures/figures_5_1.jpg", "caption": "Figure 3: Left: AutoMix algorithm. Right: Performance vs. Cost curve. The slope between SLM and LLM provides a way to the Incremental Benefit per Cost (IBC) for methods that mix models. Methods with a steeper slope than this reference when plotted against SLM have a positive IBC (green region), whereas those below the reference have a negative IBC (red region).", "description": "The left panel shows the AutoMix algorithm's flowchart.  It details the process: generating an answer using a small language model (SLM), verifying the answer using self-verification, and then routing to a larger language model (LLM) if the verification result is below a threshold. The right panel displays a performance versus cost curve. It illustrates how different methods (e.g., using only SLM, only LLM, or a model-mixing method) perform concerning accuracy and cost. The slope of the line from SLM to a specific point on the curve represents the incremental benefit per cost (IBC).  A positive IBC indicates that the method is cost-effective in enhancing performance.", "section": "5 Experiments"}, {"figure_path": "e6WrwIvgzX/figures/figures_6_1.jpg", "caption": "Figure 4: Main Results: performance (y-axis) vs. cost (x-axis) for different methods on the small and large LLAMA2-13/GPT-4. POMDP based meta-verifier is consistenly above the linear interpolation (random mixing) of SLM-LLM, signifying a higher incremental benefit per unit cost (IBC).", "description": "This figure presents the performance versus cost curves for various methods, comparing AutoMix (with POMDP and thresholding) against FrugalGPT, HybridLLM, and baselines (using only SLM or LLM). It demonstrates that AutoMix consistently surpasses baselines across multiple datasets, achieving better performance for a given cost or lower cost for comparable performance.  The slope of the curves illustrates the incremental benefit per cost (IBC).", "section": "5 Experiments"}, {"figure_path": "e6WrwIvgzX/figures/figures_8_1.jpg", "caption": "Figure 5: Left: Comparison of AutoMix with FrugalGPT and HybridLLM over varying training data sizes shows that despite 0-cost verifier and domain-specific training, baselines underperform AutoMix. AutoMix excels in limited data settings. Right: Normalized AIBC across different cost ratios. AutoMix show robust performance gains even when cost ratio is low.", "description": "The left plot compares the performance of AutoMix against FrugalGPT and HybridLLM for different sizes of training data.  It shows that AutoMix consistently outperforms the baselines, even with small datasets. The right plot shows the normalized AIBC (incremental benefit per cost) for different cost ratios between the large and small models.  It demonstrates that AutoMix maintains its advantage across a range of cost ratios.", "section": "5 Experiments"}, {"figure_path": "e6WrwIvgzX/figures/figures_9_1.jpg", "caption": "Figure 6: AutoMix with 3 models: LLAMA2-13B, GPT-4 and GPT-4. AutoMix method shows consistent IBC lifts for both SLM-MLM and MLM-LLM regions. Further, compared to baselines: FrugalGPT, chaining two AutoMix models or using the union of two AutoMixes, AutoMix3 provide significant improvements.", "description": "This figure compares AutoMix's performance with three models (LLAMA2-13B, LLAMA2-70B, GPT-4) against baselines (FrugalGPT, Chained AutoMix, Union AutoMix).  It shows AutoMix consistently outperforms on both cost regions (SLM-MLM and MLM-LLM) and demonstrates higher incremental benefit per cost (IBC).", "section": "5.5 Results of Automix with Three Models"}, {"figure_path": "e6WrwIvgzX/figures/figures_15_1.jpg", "caption": "Figure 7: Comparison of AutoMix with FrugalGPT over varying Training Dataset Size. Despite zero-cost verifier and domain-specific training, FrugalGPT underperforms AutoMix. AutoMix is especially useful for limited data settings, with higher gains visible when dataset size is less than 1000.", "description": "This figure compares the performance of AutoMix and two baseline methods (FrugalGPT and HybridLLM) across different training dataset sizes.  It demonstrates that AutoMix consistently outperforms the baselines, especially when the training data is limited.  The performance gap between AutoMix and the baselines becomes less pronounced as the training dataset size increases, highlighting AutoMix's effectiveness in low-resource settings.", "section": "4.1 Self-Verification"}, {"figure_path": "e6WrwIvgzX/figures/figures_20_1.jpg", "caption": "Figure 6: AutoMix with 3 models: LLAMA2-13B, GPT-4 and GPT-4. AutoMix method shows consistent IBC lifts for both SLM-MLM and MLM-LLM regions. Further, compared to baselines: FrugalGPT, chaining two AutoMix models or using the union of two AutoMixes, AutoMix3 provide significant improvements.", "description": "This figure shows the performance comparison between AutoMix and several baselines across different cost ranges using three language models (LLMs): LLAMA2-13B, LLAMA2-70B, and GPT-4.  The x-axis represents computational cost, and the y-axis represents performance (F1 score).  AutoMix consistently outperforms the baselines across the different cost ranges, indicating a better cost-performance trade-off. The baselines include FrugalGPT, Chained AutoMix, and Union AutoMix, each representing different strategies for combining the three models.", "section": "5.5 Results of Automix with Three Models"}, {"figure_path": "e6WrwIvgzX/figures/figures_21_1.jpg", "caption": "Figure 4: Main Results: performance (y-axis) vs. cost (x-axis) for different methods on the small and large LLAMA2-13/GPT-4. POMDP based meta-verifier is consistenly above the linear interpolation (random mixing) of SLM-LLM, signifying a higher incremental benefit per unit cost (IBC).", "description": "This figure shows the performance versus cost curves for different model-mixing methods using MISTRAL-7B as the smaller language model (SLM). AutoMix consistently outperforms baselines (FrugalGPT and HybridLLM), maintaining better performance per unit cost across all datasets.  The POMDP-based meta-verifier consistently surpasses the linear interpolation of SLM-LLM, demonstrating improved incremental benefit per cost.", "section": "5 Experiments"}, {"figure_path": "e6WrwIvgzX/figures/figures_22_1.jpg", "caption": "Figure 6: AutoMix with 3 models: LLAMA2-13B, GPT-4 and GPT-4. AutoMix method shows consistent IBC lifts for both SLM-MLM and MLM-LLM regions. Further, compared to baselines: FrugalGPT, chaining two AutoMix models or using the union of two AutoMixes, AutoMix3 provide significant improvements.", "description": "This figure shows the performance (y-axis, F1 score) vs. cost (x-axis, computational cost) for different methods using three models: LLAMA2-13B (SLM), LLAMA2-70B (MLM), and GPT-4 (LLM).  AutoMix consistently outperforms baselines (FrugalGPT, Chained AutoMix, Union AutoMix) across all cost regions, demonstrating higher incremental benefit per cost (IBC). The consistent improvement suggests AutoMix effectively leverages the strengths of multiple models for optimal cost-performance balance.", "section": "5.5 Results of Automix with Three Models"}, {"figure_path": "e6WrwIvgzX/figures/figures_22_2.jpg", "caption": "Figure 4: Main Results: performance (y-axis) vs. cost (x-axis) for different methods on the small and large LLAMA2-13/GPT-4. POMDP based meta-verifier is consistenly above the linear interpolation (random mixing) of SLM-LLM, signifying a higher incremental benefit per unit cost (IBC).", "description": "This figure compares the cost-performance tradeoffs of different methods for question answering.  The x-axis represents the computational cost, while the y-axis shows the performance (F1 score).  The methods being compared include AutoMix with a POMDP-based router, AutoMix with a threshold-based router, FrugalGPT, HybridLLM, using only the small language model (SLM), using only the large language model (LLM), and random model selection. The figure demonstrates that AutoMix with the POMDP router consistently outperforms other methods, achieving higher performance at lower costs.  The superior performance is highlighted by its curve lying above the linear interpolation between the SLM and LLM baselines, indicating a higher incremental benefit per cost (IBC).", "section": "5 Experiments"}, {"figure_path": "e6WrwIvgzX/figures/figures_23_1.jpg", "caption": "Figure 12: Verifier Probability and Correctness: Percentage of correct responses across distinct verifier probability bins for LLAMA2-13B as SLM. Each bin represents a range of verifier probabilities and the corresponding accuracy of the responses within that probability range across various datasets. Notably, for all datasets, excluding QUALITY and QASPER, a higher verification score generally corresponds to a larger proportion of correct examples, indicating that the verifier is, to an extent, capable of discerning the reliability of responses generated by itself. We use a router behaving like a meta-verifier to get around these noisy predictions.", "description": "This figure shows the relationship between the verifier's confidence (probability) in its assessment of an answer's correctness and the actual correctness of the answer across multiple datasets.  It demonstrates that higher verifier confidence generally correlates with higher accuracy, indicating the effectiveness of the self-verification process despite some noise.  This is a key justification for using the verifier's output as input for the POMDP routing algorithm.", "section": "A How effective is few-shot self-verification?"}, {"figure_path": "e6WrwIvgzX/figures/figures_23_2.jpg", "caption": "Figure 4: Main Results: performance (y-axis) vs. cost (x-axis) for different methods on the small and large LLAMA2-13/GPT-4. POMDP based meta-verifier is consistenly above the linear interpolation (random mixing) of SLM-LLM, signifying a higher incremental benefit per unit cost (IBC).", "description": "This figure compares the performance and cost of different methods for question answering using two large language models (LLMs): LLAMA2-13B (smaller model) and GPT-4 (larger model).  The x-axis represents the computational cost, and the y-axis represents the performance (likely accuracy or F1 score).  The graph shows that AutoMix with a POMDP-based router consistently outperforms baselines and a random mixing strategy.  This demonstrates that AutoMix effectively balances performance and cost by strategically routing queries to the appropriate model.", "section": "Main Results"}, {"figure_path": "e6WrwIvgzX/figures/figures_24_1.jpg", "caption": "Figure 6: AutoMix with 3 models: LLAMA2-13B, GPT-4 and GPT-4. AutoMix method shows consistent IBC lifts for both SLM-MLM and MLM-LLM regions. Further, compared to baselines: FrugalGPT, chaining two AutoMix models or using the union of two AutoMixes, AutoMix3 provide significant improvements.", "description": "This figure demonstrates the performance of AutoMix with three language models (LLAMA2-13B, LLAMA2-70B, and GPT-4) across various computational costs.  It compares AutoMix's performance to several baselines: FrugalGPT, a chained AutoMix approach (sequentially applying AutoMix to smaller and then larger models), and a union AutoMix approach (selecting the best-performing of two AutoMix configurations).  AutoMix consistently surpasses these baselines, showing a greater improvement in incremental benefit per cost (IBC) in both smaller and larger model usage scenarios.", "section": "Results of Automix with Three Models"}, {"figure_path": "e6WrwIvgzX/figures/figures_24_2.jpg", "caption": "Figure 4: Main Results: performance (y-axis) vs. cost (x-axis) for different methods on the small and large LLAMA2-13/GPT-4. POMDP based meta-verifier is consistenly above the linear interpolation (random mixing) of SLM-LLM, signifying a higher incremental benefit per unit cost (IBC).", "description": "This figure displays the performance versus cost curves for various model-mixing methods using MISTRAL-7B as the small language model (SLM) across five datasets.  It shows AutoMix consistently outperforms baselines (FrugalGPT and HybridLLM) and demonstrates a higher incremental benefit per unit cost (IBC) compared to a baseline of simply using either a small or large language model.  The POMDP-based meta-verifier in AutoMix is particularly effective.", "section": "5 Experiments"}, {"figure_path": "e6WrwIvgzX/figures/figures_24_3.jpg", "caption": "Figure 4: Main Results: performance (y-axis) vs. cost (x-axis) for different methods on the small and large LLAMA2-13/GPT-4. POMDP based meta-verifier is consistenly above the linear interpolation (random mixing) of SLM-LLM, signifying a higher incremental benefit per unit cost (IBC).", "description": "The figure compares the cost-performance tradeoffs of different methods for question answering using two language models (LLMs).  The x-axis represents the computational cost, and the y-axis represents the performance (F1-score). The results show that AutoMix, using a POMDP-based router, consistently outperforms baselines, achieving better performance at lower costs compared to simply using a small or large LLM alone. The superior performance of AutoMix is highlighted by its steeper slope than the linear interpolation between the single small and large model results, demonstrating a greater incremental benefit per unit cost (IBC).", "section": "Main Results"}, {"figure_path": "e6WrwIvgzX/figures/figures_24_4.jpg", "caption": "Figure 4: Main Results: performance (y-axis) vs. cost (x-axis) for different methods on the small and large LLAMA2-13/GPT-4. POMDP based meta-verifier is consistenly above the linear interpolation (random mixing) of SLM-LLM, signifying a higher incremental benefit per unit cost (IBC).", "description": "The figure compares different model-mixing methods on two LLMs (LLAMA2-13B and GPT-4), plotting performance against cost.  AutoMix with the POMDP-based router consistently outperforms baselines and random mixing, demonstrating a steeper slope (higher incremental benefit per cost - IBC) indicating better cost-efficiency.", "section": "5 Experiments"}, {"figure_path": "e6WrwIvgzX/figures/figures_25_1.jpg", "caption": "Figure 4: Main Results: performance (y-axis) vs. cost (x-axis) for different methods on the small and large LLAMA2-13/GPT-4. POMDP based meta-verifier is consistenly above the linear interpolation (random mixing) of SLM-LLM, signifying a higher incremental benefit per unit cost (IBC).", "description": "This figure compares different model-mixing methods' performance against cost.  AutoMix with the POMDP-based router consistently outperforms baselines and shows a steeper slope than the linear interpolation between the small and large language models (SLM and LLM), indicating higher incremental benefit per cost (IBC).", "section": "5 Experiments"}, {"figure_path": "e6WrwIvgzX/figures/figures_26_1.jpg", "caption": "Figure 4: Main Results: performance (y-axis) vs. cost (x-axis) for different methods on the small and large LLAMA2-13/GPT-4. POMDP based meta-verifier is consistenly above the linear interpolation (random mixing) of SLM-LLM, signifying a higher incremental benefit per unit cost (IBC).", "description": "This figure compares the performance and cost of different methods (AutoMix with POMDP and thresholding, FrugalGPT, HybridLLM, using only the small language model (LLM), using only the large language model (LLM), and random mixing) on the LLAMA2-13B and GPT-4 language models.  The y-axis represents performance, and the x-axis represents cost. The results show that AutoMix with POMDP consistently outperforms the other methods, achieving higher performance at a lower cost. The slope of the line connecting SLM and LLM points represents the incremental benefit per cost (IBC) baseline.  AutoMix with POMDP consistently outperforms the baseline.", "section": "5 Experiments"}, {"figure_path": "e6WrwIvgzX/figures/figures_26_2.jpg", "caption": "Figure 20: We compare AutoMix to baselines across various LLM to SLM cost ratios. For all considered cost-ratios, AutoMix outperform baselines with varying degree of margins.", "description": "This figure compares the performance of AutoMix against FrugalGPT and HybridLLM across different cost ratios between the large language model (LLM) and the smaller language model (SLM).  The x-axis represents the computational cost, and the y-axis represents the performance (F1-score) on the DIPLOMAT dataset. Three cost ratios (20:1, 200:1, and 2000:1) are shown, illustrating AutoMix's consistent superior performance across various cost scenarios.", "section": "5.4 Effect of Cost Ratio on AutoMix"}, {"figure_path": "e6WrwIvgzX/figures/figures_26_3.jpg", "caption": "Figure 4: Main Results: performance (y-axis) vs. cost (x-axis) for different methods on the small and large LLAMA2-13/GPT-4. POMDP based meta-verifier is consistenly above the linear interpolation (random mixing) of SLM-LLM, signifying a higher incremental benefit per unit cost (IBC).", "description": "This figure shows the performance vs. cost curves for various methods on two language models (LLAMA2-13B and GPT-4).  AutoMix using POMDP and thresholding methods consistently outperforms baselines and random model selection, demonstrating its efficiency in balancing cost and performance. The slope of each method's curve shows the incremental benefit per unit cost (IBC).", "section": "5 Experiments"}, {"figure_path": "e6WrwIvgzX/figures/figures_28_1.jpg", "caption": "Figure 4: Main Results: performance (y-axis) vs. cost (x-axis) for different methods on the small and large LLAMA2-13/GPT-4. POMDP based meta-verifier is consistenly above the linear interpolation (random mixing) of SLM-LLM, signifying a higher incremental benefit per unit cost (IBC).", "description": "This figure compares the cost-performance trade-offs of different model-mixing methods, including AutoMix with a POMDP-based router, against baselines.  The results show that AutoMix consistently outperforms baselines by achieving better performance at a lower cost. The POMDP-based approach demonstrates a significantly better cost-performance trade-off than the linear interpolation of using only small or large language models.", "section": "5 Experiments"}]