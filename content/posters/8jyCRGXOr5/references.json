{"references": [{"fullname_first_author": "Armen Aghajanyan", "paper_title": "Intrinsic dimensionality explains the effectiveness of language model Fine-Tuning", "publication_date": "2021-08-01", "reason": "This paper is foundational to the study of intrinsic dimensionality in language models and is directly relevant to the core topic of the current paper."}, {"fullname_first_author": "Nir Ailon", "paper_title": "The fast Johnson-Lindenstrauss transform and approximate nearest neighbors", "publication_date": "2009-01-01", "reason": "This paper provides the theoretical foundation for the Johnson-Lindenstrauss lemma, which is crucial to the theoretical analysis of sketching algorithms in the current paper."}, {"fullname_first_author": "Jillian Fisher", "paper_title": "Influence diagnostics under self-concordance", "publication_date": "2023-01-01", "reason": "This paper provides an important perspective on influence functions and their limitations, which are directly relevant to the training data attribution part of the current paper."}, {"fullname_first_author": "Roger Grosse", "paper_title": "Studying large language model generalization with influence functions", "publication_date": "2023-01-01", "reason": "This paper provides an advanced analysis of influence functions, which are relevant to the current paper's focus on training data attribution and the investigation of large language model behavior."}, {"fullname_first_author": "Han Guo", "paper_title": "FastIF: Scalable influence functions for efficient model interpretation and debugging", "publication_date": "2021-11-01", "reason": "This paper introduces a novel method for scalable influence function calculations, directly addressing the scalability challenges tackled by the current paper."}]}