[{"figure_path": "8jyCRGXOr5/tables/tables_7_1.jpg", "caption": "Table 1: Layer selection results in unreliable estimates for influence scores and eigenvalue estimation. The best correlation with ground truth influence scores does not exceed 90% and is quite low for most layers; the relative error in eigenvalue prediction is always at least 20%.", "description": "This table presents the results of an experiment evaluating the reliability of layer selection methods for training data attribution (TDA) and Hessian eigenvalue estimation.  It shows that using only a subset of layers (instead of the entire model) produces significantly lower correlations with ground truth influence scores and higher errors in eigenvalue prediction, demonstrating the unreliability of layer-selection-based scaling strategies for these tasks.", "section": "5 Experiments"}, {"figure_path": "8jyCRGXOr5/tables/tables_7_2.jpg", "caption": "Table 2: Dense projections on the layers do not scale; for each layer we report the wall time for the maximum dimension that does not result in an OOM.", "description": "This table presents the results of an experiment evaluating the scalability of dense projections on different layers of a neural network. For each layer, it shows the wall time (in milliseconds) taken for computation with the maximum dimension that did not lead to an out-of-memory (OOM) error.  The results demonstrate that dense projections are not scalable as the maximum dimension that fits in memory decreases with each subsequent layer. ", "section": "5.2 Shortcomings of previous Training-Data Attribution scaling strategies"}, {"figure_path": "8jyCRGXOr5/tables/tables_8_1.jpg", "caption": "Table 3: Wall-time T and peak memory usage M comparison on gradient sketches for GPT-2. Removing look-ups is crucial for TPU performance and decreasing GPU memory utilization.", "description": "This table compares the wall-time and peak memory usage of different gradient sketching algorithms (FJL, AFFD, FFD, AFJL, QK) for GPT-2 on both GPU (V100) and TPU (v2) hardware.  The results show the impact of removing lookups, a key optimization in the proposed algorithms, on both performance metrics.  Lower values of T (wall-time in milliseconds) and M (memory in gigabytes) are better, indicating faster and more memory-efficient algorithms.", "section": "5 Experiments"}, {"figure_path": "8jyCRGXOr5/tables/tables_8_2.jpg", "caption": "Table 4: Speed-ups (ratio R of the slowest wall-time to the fastest one) corresponding to changing a design choice (e.g. implicit to explicit or HN to the FFT.).", "description": "This table shows the speedup achieved by changing specific design choices in the sketching algorithms.  The speedup is calculated as the ratio of the slowest wall time to the fastest wall time for each algorithm and hardware (GPU or TPU).  The design choices evaluated include switching from implicit to explicit sketching, and replacing the Walsh-Hadamard transform (HN) with either the Fast Fourier Transform (FFT) or a Kronecker-product-based orthogonal matrix (Q).", "section": "Analyzing the Impact of Design Choices"}, {"figure_path": "8jyCRGXOr5/tables/tables_13_1.jpg", "caption": "Table 1: Layer selection results in unreliable estimates for influence scores and eigenvalue estimation. The best correlation with ground truth influence scores does not exceed ~90% and is quite low for most layers; the relative error in eigenvalue prediction is always at least ~20%.", "description": "This table presents the Pearson correlation (R) between influence scores obtained using layer-specific gradients and the ground truth (full gradient) for various layers in GPT-2 and BART models, along with the relative error in eigenvalue estimation for each layer.  The results show that layer selection leads to unreliable estimates for both influence scores and eigenvalues.  Correlations with the ground truth are generally below 90%, and the relative error in eigenvalue prediction is always at least 20%. This highlights the unreliability of layer selection as a scaling strategy for training data attribution.", "section": "5 Experiments"}, {"figure_path": "8jyCRGXOr5/tables/tables_13_2.jpg", "caption": "Table 6: For each algorithm the minimal value of log2 D necessary to reach a Pearson r > x where x = 0.9{5,8,9} for estimating inner products of gradients.", "description": "This table presents the minimum log2(D) values required for different sketching algorithms (FJL, AFFD, AFJL, QK, FFD) to achieve Pearson correlation (r) values exceeding 0.95, 0.98, and 0.99 when estimating inner products of gradients.  It shows the relationship between the target dimension D and the accuracy of the gradient sketching methods in approximating inner products.", "section": "Analyzing the Impact of Design Choices"}, {"figure_path": "8jyCRGXOr5/tables/tables_13_3.jpg", "caption": "Table 7: For each algorithm the minimal value of log2 D necessary to reach a relative error err < x where x = 0.2, 0.1, 0.05 in reconstructing the top 10 eigenvalues.", "description": "This table shows the minimum log2(D) values required for AFFD, AFJL, and QK algorithms to achieve relative errors of less than 0.2, 0.1, and 0.05 when reconstructing the top 10 Hessian eigenvalues.  It demonstrates the different memory requirements for achieving similar accuracy with different sketching algorithms.", "section": "A.3 A closer look at FJL vs AFJL"}, {"figure_path": "8jyCRGXOr5/tables/tables_20_1.jpg", "caption": "Table 10: Values of D* returned by the search the intrinsic dimension Dint using 3 different seeds. This shows the stability of our algorithm which doubles the dimension of the fine-tuning subspace after some compute budget if the target metric has not improved enough.", "description": "This table shows the stability of the algorithm used to search for the intrinsic dimension (D*).  For each task (SNLI, XSUM) and metric (accuracy, ROUGE1), the algorithm ran three times with different random seeds. The table displays the resulting D* values for each run. The results show that the D* values are consistent within a factor of 2 across different seeds, demonstrating the algorithm's stability.", "section": "5 Experiments"}, {"figure_path": "8jyCRGXOr5/tables/tables_22_1.jpg", "caption": "Table 11: Wall-time T (ms) Comparison: Our Methods vs. On-the-fly Dense Projections (TRAK) using a V100 GPU. TRAK requires custom kernels and is thus restricted to GPU computation. Our methods exhibit constant runtime with respect to the target dimension, whereas TRAK's runtime increases substantially as the target dimension grows.", "description": "This table compares the wall-time performance of three different sketching algorithms (AFFD, QK, and TRAK) on a V100 GPU for various target dimensions. TRAK, which uses on-the-fly dense random projections, shows a significant increase in wall-time as the target dimension increases, while AFFD and QK maintain relatively constant runtimes.", "section": "A.8 Comparison to on-the-fly dense random projections"}]