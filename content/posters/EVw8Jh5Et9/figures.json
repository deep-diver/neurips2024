[{"figure_path": "EVw8Jh5Et9/figures/figures_3_1.jpg", "caption": "Figure 1: Overview of DDFed framework and illustration of a single round DDFed training.", "description": "This figure illustrates the Dual Defense Federated learning (DDFed) framework.  It shows the interactions between multiple clients (C1...Cn) and a single aggregation server (A). Each client trains a local model, encrypts it using Fully Homomorphic Encryption (FHE), and sends it to the server. The server performs a two-phase anomaly detection: secure similarity computation and feedback-driven collaborative selection, to identify and filter out malicious models. Finally, the server securely aggregates the remaining models using FHE and sends the updated global model back to the clients.  The figure visually demonstrates the key steps involved in a single round of DDFed training.", "section": "3 Dual Defense Federated Learning Framework"}, {"figure_path": "EVw8Jh5Et9/figures/figures_6_1.jpg", "caption": "Figure 2: Comparison of defense effectiveness across various defense approaches, evaluated on MNIST (top) and FMNIST(bottom), under IPM attack (left), ALIE attack (middle), and SCALING attack (right).", "description": "This figure compares the performance of different defense mechanisms against three common model poisoning attacks: IPM, ALIE, and SCALING.  The top row shows results using the MNIST dataset, while the bottom row uses the Fashion-MNIST (FMNIST) dataset.  Each column represents a different attack type. The plot shows test accuracy over federated learning training rounds.  The vertical dashed line indicates when the attack begins.  The comparison includes FedAvg (without attack), FedAvg (with attack), Krum, Median, Clipped Median, Trimmed Mean, Cosine Defense, and the proposed DDFed method.  The shaded areas around the lines represent confidence intervals.", "section": "4.2 Performance Evaluation"}, {"figure_path": "EVw8Jh5Et9/figures/figures_7_1.jpg", "caption": "Figure 3: Comparison of DDFed effectiveness across different attack ratios, evaluated on MNIST (top) and FMNIST (bottom), under IPM attack (left), ALIE attack (middle), and SCALING attack (right).", "description": "This figure displays the results of experiments evaluating the effectiveness of the Dual Defense Federated learning (DDFed) framework against three different model poisoning attacks (IPM, ALIE, and SCALING) at varying attack ratios (0.1 to 0.4).  The top row shows results for the MNIST dataset, while the bottom row shows results for the FMNIST dataset. Each subfigure shows the test accuracy over training rounds, with different colored lines representing different attack ratios. The vertical dashed line indicates the start of the attack.  This figure demonstrates the robustness of DDFed against these attacks even at higher attack ratios.  The relatively steady performance, even with attacks starting from the beginning, is highlighted.", "section": "4.2 Performance Evaluation"}, {"figure_path": "EVw8Jh5Et9/figures/figures_7_2.jpg", "caption": "Figure 2: Comparison of defense effectiveness across various defense approaches, evaluated on MNIST (top) and FMNIST(bottom), under IPM attack (left), ALIE attack (middle), and SCALING attack (right).", "description": "This figure compares the performance of different defense mechanisms against three common model poisoning attacks (IPM, ALIE, SCALING) on two datasets (MNIST and FMNIST).  The x-axis represents the federated learning training round, and the y-axis shows the test accuracy.  Each subplot shows the test accuracy for different defenses (FedAvg, Krum, Median, Clipping Median, Trimmed Mean, Cosine Defense, and DDFed). The red vertical dashed line indicates when the attacks begin. The figure visually demonstrates DDFed's superior robustness compared to other defenses across various attacks and datasets.", "section": "4.2 Performance Evaluation"}, {"figure_path": "EVw8Jh5Et9/figures/figures_8_1.jpg", "caption": "Figure 3: Comparison of DDFed effectiveness across different attack ratios, evaluated on MNIST (top) and FMNIST (bottom), under IPM attack (left), ALIE attack (middle), and SCALING attack (right).", "description": "This figure compares the performance of the Dual Defense Federated Learning (DDFed) framework against three different model poisoning attacks (IPM, ALIE, and SCALING) at various attack ratios.  The top row shows results using the MNIST dataset, while the bottom row uses the Fashion-MNIST (FMNIST) dataset. Each column represents a different attack, and each line within a column represents a different attack ratio (proportion of malicious clients).  The red dashed line indicates when the attacks begin. The graphs show that DDFed maintains relatively high accuracy even with a significant proportion of malicious clients, demonstrating its robustness to model poisoning attacks.", "section": "4.2 Performance Evaluation"}, {"figure_path": "EVw8Jh5Et9/figures/figures_12_1.jpg", "caption": "Figure 1: Overview of DDFed framework and illustration of a single round DDFed training.", "description": "This figure provides a visual representation of the Dual Defense Federated Learning (DDFed) framework.  It shows the interactions between multiple clients (C1...Cn), each possessing their own dataset and local model, and a single aggregation server (A). The figure details the steps involved in a single training round, highlighting the use of Fully Homomorphic Encryption (FHE) for secure aggregation and a two-phase anomaly detection mechanism that involves secure similarity computation and feedback-driven collaborative selection.  The process demonstrates how local model updates are securely aggregated while simultaneously mitigating potential poisoning attacks by identifying and filtering out malicious updates.", "section": "3 Dual Defense Federated Learning Framework"}, {"figure_path": "EVw8Jh5Et9/figures/figures_13_1.jpg", "caption": "Figure 3: Comparison of DDFed effectiveness across different attack ratios, evaluated on MNIST (top) and FMNIST (bottom), under IPM attack (left), ALIE attack (middle), and SCALING attack (right).", "description": "This figure compares the performance of the Dual Defense Federated Learning (DDFed) framework against three different model poisoning attacks (IPM, ALIE, and SCALING) at various attack ratios. The results are shown for both MNIST and Fashion-MNIST datasets.  The x-axis represents the federated learning training round, and the y-axis represents the test accuracy. Each line represents a different attack ratio. The dashed vertical line indicates the point where the attack starts. The figure demonstrates the robustness of DDFed across varying attack intensities.", "section": "4.2 Performance Evaluation"}]