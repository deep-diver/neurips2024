[{"figure_path": "RJEC9fZ9Ma/figures/figures_8_1.jpg", "caption": "Figure 1: An illustration of the Neural Collapse curves of AL (a and b, on CIFAR100 with \u03c4 = 0.01 and CIFAR 10 with \u03c4 = 0.01 respectively), CAL (c and d, on CIFAR100 with \u03c4 = 0.01 and CIFAR 10 with \u03c4 = 0.01 respectively). The AL is equipped with f=20 and CAL uses Class-Aware Strategy.", "description": "This figure shows the neural collapse curves for Average Loss (AL) and Class-Aware Loss (CAL) on CIFAR-10 and CIFAR-100 datasets with an imbalance ratio (\u03c4) of 0.01.  The plots display the average neural collapse (NC_ave), standard deviation of the neural collapse (NC_std), and variability over epochs of training. AL uses a fixed number of centers (f=20), while CAL employs a class-aware strategy to determine the number of centers for each class. The graphs illustrate how the features collapse towards their respective class centers as training progresses.", "section": "4.3 Neural Collapse"}, {"figure_path": "RJEC9fZ9Ma/figures/figures_16_1.jpg", "caption": "Figure 2: An illustration of the toy example", "description": "This figure is a 3D scatter plot visualizing a toy example dataset used to illustrate the concept of \"hard-to-predict\" samples.  The plot shows data points from multiple classes, each represented by a different color and shape. Data points close to the class centers are easily classified, while others far from class centers are harder to classify correctly. The purple points, specifically, are referred to as \"hard-to-predict\" and illustrate the challenges of accurately classifying these points. The axes represent the feature space of the model.", "section": "3.1 Nearest-Neighbor Classification Rule Revisit: A Toy Example"}, {"figure_path": "RJEC9fZ9Ma/figures/figures_17_1.jpg", "caption": "Figure 3: The 3D illustration of multiple centers for class 1 and class 2. The dashed blue vectors are the two centers of class 1, and the dashed green are the two centers of class 2. And Wij = cos \u03b8 * vij + sin \u03b8 * wi, where i, j \u2208 {1, 2}.", "description": "This figure provides a 3D visualization of the concept of multiple centers for two classes (Class 1 and Class 2). Each class has two centers, represented by dashed lines.  The solid lines represent the vectors (w and v) that determine the centers according to the formula: Wij = cos \u03b8 * vij + sin \u03b8 * wi. This illustrates how the features of a class tend to collapse to multiple centers instead of a single center, as in standard neural collapse.", "section": "3.2 Center and Multi-Center Frame"}, {"figure_path": "RJEC9fZ9Ma/figures/figures_25_1.jpg", "caption": "Figure 1: An illustration of the Neural Collapse curves of AL (a and b, on CIFAR100 with \u03c4 = 0.01 and CIFAR 10 with \u03c4 = 0.01 respectively), CAL (c and d, on CIFAR100 with \u03c4 = 0.01 and CIFAR 10 with \u03c4 = 0.01 respectively). The AL is equipped with f=20 and CAL uses Class-Aware Strategy.", "description": "This figure shows the neural collapse curves for both the Average Loss (AL) and the Class-Aware Loss (CAL) functions.  The curves illustrate the mean and standard deviation of a neural collapse metric over training epochs for two different datasets (CIFAR-10 and CIFAR-100) with varying levels of class imbalance (\u03c4).  The AL uses a fixed number of centers (f=20) for each class, while the CAL uses a class-aware strategy to determine the number of centers. The figure demonstrates that both AL and CAL induce neural collapse, with the CAL showing potentially better performance.", "section": "4.3 Neural Collapse"}, {"figure_path": "RJEC9fZ9Ma/figures/figures_25_2.jpg", "caption": "Figure 4: NCMC phenomenon under Loss P at different epochs. We draw the mean and standard deviation of the neural collapse metric used in the paper on CIFAR-10 for different imbalanced ratios w/ or w/o regularization. The horizontal axis is log10-scaled NC metric value. The regularization coefficient is 5e-4.", "description": "This figure shows the mean and standard deviation of the neural collapse metric (NC) for different imbalanced ratios (0.005, 0.01, 0.02, and balanced) on CIFAR-10 dataset, with and without regularization.  The x-axis represents the log10-scaled NC metric value, indicating the degree of neural collapse.  The y-axis shows the mean and standard deviation of this metric. The figure visualizes the impact of regularization on the neural collapse phenomenon under the proposed Loss P.", "section": "4.3 Neural Collapse"}, {"figure_path": "RJEC9fZ9Ma/figures/figures_27_1.jpg", "caption": "Figure 1: An illustration of the Neural Collapse curves of AL (a and b, on CIFAR100 with \u03c4 = 0.01 and CIFAR 10 with \u03c4 = 0.01 respectively), CAL (c and d, on CIFAR100 with \u03c4 = 0.01 and CIFAR 10 with \u03c4 = 0.01 respectively). The AL is equipped with f=20 and CAL uses Class-Aware Strategy.", "description": "This figure shows the neural collapse curves for both Average Loss (AL) and Class-Aware Loss (CAL) on CIFAR-10 and CIFAR-100 datasets with an imbalance ratio (\u03c4) of 0.01.  The x-axis represents the training epoch, while the y-axis displays the neural collapse metric. AL uses a fixed number of centers (f=20), while CAL uses a class-aware strategy to dynamically determine the number of centers for each class.  The plots illustrate how both AL and CAL induce neural collapse, showcasing the mean and standard deviation of the collapse metric over multiple runs.", "section": "4.3 Neural Collapse"}, {"figure_path": "RJEC9fZ9Ma/figures/figures_27_2.jpg", "caption": "Figure 1: An illustration of the Neural Collapse curves of AL (a and b, on CIFAR100 with \u03c4 = 0.01 and CIFAR 10 with \u03c4 = 0.01 respectively), CAL (c and d, on CIFAR100 with \u03c4 = 0.01 and CIFAR 10 with \u03c4 = 0.01 respectively). The AL is equipped with f=20 and CAL uses Class-Aware Strategy.", "description": "This figure displays the neural collapse curves for both Average Loss (AL) and Class-Aware Loss (CAL) on CIFAR-10 and CIFAR-100 datasets with an imbalance ratio (\u03c4) of 0.01.  The plots show how the mean and standard deviation of a neural collapse metric change over training epochs.  AL uses a fixed number of centers (f=20), while CAL dynamically determines the number of centers using a class-aware strategy. The plots illustrate the convergence behavior towards neural collapse for both loss functions under different settings.", "section": "4.3 Neural Collapse"}]