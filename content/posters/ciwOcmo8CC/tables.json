[{"figure_path": "ciwOcmo8CC/tables/tables_5_1.jpg", "caption": "Table 2: Quantitative evaluation on UFSC and UFUC dataset. \"User\" indicates user study, the samples are generated under 3-shot setting. Bold and underlined numbers denote the best and the second best respectively. Please refer to Fig. 10 in Appendix for the corresponding radar plots.", "description": "This table presents a quantitative comparison of different font generation methods on two datasets: UFSC (Unseen Fonts and Seen Characters) and UFUC (Unseen Fonts and Unseen Characters).  The evaluation metrics include FID (Fr\u00e9chet Inception Distance), L1 loss, LPIPS (Learned Perceptual Image Patch Similarity), RMSE (Root Mean Squared Error), and SSIM (Structural Similarity Index).  The results are shown for 1-shot, 3-shot, and 8-shot settings (meaning 1, 3, and 8 reference glyphs were used for generation).  A user study was also conducted to assess the subjective quality of the generated fonts.  Bold and underlined values highlight the top two-performing methods for each metric.", "section": "4.2 Comparison with state-of-the-art Methods"}, {"figure_path": "ciwOcmo8CC/tables/tables_6_1.jpg", "caption": "Table 2: Quantitative evaluation on UFSC and UFUC dataset. \"User\" indicates user study, the samples are generated under 3-shot setting. Bold and underlined numbers denote the best and the second best respectively. Please refer to Fig. 10 in Appendix for the corresponding radar plots.", "description": "This table presents a quantitative comparison of different font generation methods on two test datasets: UFSC (Unseen Fonts, Seen Characters) and UFUC (Unseen Fonts, Unseen Characters).  The methods are evaluated using several metrics: FID (Fr\u00e9chet Inception Distance), L1 distance, LPIPS (Learned Perceptual Image Patch Similarity), RMSE (Root Mean Squared Error), and SSIM (Structural Similarity Index).  The table also includes the results of a user study to assess the subjective quality of the generated fonts.  Results are shown for one-shot, three-shot, and eight-shot settings, reflecting the number of reference glyphs used for training. Bold and underlined numbers highlight the top two performing methods for each metric.", "section": "4.2 Comparison with state-of-the-art Methods"}, {"figure_path": "ciwOcmo8CC/tables/tables_7_1.jpg", "caption": "Table 3: Ablation studies on different modules. The first row is the results of baseline. I, S and C represent IHA, SSA, and SCE respectively.", "description": "This table presents the ablation study results for the proposed IF-Font model. It shows the impact of each module (IHA, SSA, and SCE) on the overall performance, measured by FID, L1, LPIPS, RMSE, and SSIM. The baseline model is the model without any of the three modules, and each subsequent row adds one more module to the baseline.", "section": "4.3 Ablation Studies"}, {"figure_path": "ciwOcmo8CC/tables/tables_7_2.jpg", "caption": "Table 4: The impact of IDS granularity on performance.", "description": "This table presents a quantitative evaluation of the impact of different levels of granularity in Ideographic Description Sequences (IDS) on the performance of the IF-Font model.  Three levels of granularity are compared: Component, Stroke, and Mixed.  The performance is measured across several metrics, including FID, L1, LPIPS, RMSE, and SSIM, providing a comprehensive assessment of the model's effectiveness under varied IDS representations.", "section": "4.3 Ablation Studies"}, {"figure_path": "ciwOcmo8CC/tables/tables_8_1.jpg", "caption": "Table 4: The impact of IDS granularity on performance.", "description": "This table presents a quantitative evaluation of the impact of different Ideographic Description Sequence (IDS) granularities on the performance of the IF-Font model.  Three granularities are compared: Component, Stroke, and Mixed.  The evaluation metrics used are FID (Fr\u00e9chet Inception Distance), L1 distance, LPIPS (Learned Perceptual Image Patch Similarity), RMSE (Root Mean Squared Error), and SSIM (Structural Similarity Index). Lower FID, L1, LPIPS, and RMSE values indicate better performance, while a higher SSIM value indicates better performance.  The results show that the 'Stroke' granularity achieves the best performance based on the metrics used.", "section": "4.3 Ablation Studies"}, {"figure_path": "ciwOcmo8CC/tables/tables_9_1.jpg", "caption": "Table 2: Quantitative evaluation on UFSC and UFUC dataset. \"User\" indicates user study, the samples are generated under 3-shot setting. Bold and underlined numbers denote the best and the second best respectively. Please refer to Fig. 10 in Appendix for the corresponding radar plots.", "description": "This table presents a quantitative comparison of different font generation methods on two test datasets (UFSC and UFUC) using several metrics (FID, L1, LPIPS, RMSE, SSIM).  The results are shown for different numbers of reference glyphs (1-shot, 3-shot, and 8-shot), along with the results of a user study.  Bold and underlined numbers highlight the best and second-best performing methods for each metric.", "section": "4.2 Comparison with state-of-the-art Methods"}, {"figure_path": "ciwOcmo8CC/tables/tables_14_1.jpg", "caption": "Table 2: Quantitative evaluation on UFSC and UFUC dataset. \"User\" indicates user study, the samples are generated under 3-shot setting. Bold and underlined numbers denote the best and the second best respectively. Please refer to Fig. 10 in Appendix for the corresponding radar plots.", "description": "This table presents a quantitative comparison of different font generation methods on two test datasets (UFSC and UFUC) using various metrics such as FID, L1, LPIPS, RMSE, and SSIM.  It also includes the results of a user study to assess the subjective quality of the generated fonts.  The results are shown for one-shot, three-shot and eight-shot settings, highlighting the performance of each method across different scenarios.", "section": "4.2 Comparison with state-of-the-art Methods"}, {"figure_path": "ciwOcmo8CC/tables/tables_14_2.jpg", "caption": "Table 6: Ablation studies on both branches of SSA.", "description": "This table presents the ablation study results focusing on the two branches of the SSA (Structure-Style Aggregation) block. It compares the performance of the model with the full SSA block against versions where either the global or local branch is removed. The metrics used for comparison include FID (Fr\u00e9chet Inception Distance), L1 distance, LPIPS (Learned Perceptual Image Patch Similarity), RMSE (Root Mean Squared Error), and SSIM (Structural Similarity Index). Lower values for FID, L1, LPIPS, and RMSE indicate better performance, while a higher SSIM value suggests better visual similarity.", "section": "B Additional Results"}, {"figure_path": "ciwOcmo8CC/tables/tables_16_1.jpg", "caption": "Table 2: Quantitative evaluation on UFSC and UFUC dataset. \"User\" indicates user study, the samples are generated under 3-shot setting. Bold and underlined numbers denote the best and the second best respectively. Please refer to Fig. 10 in Appendix for the corresponding radar plots.", "description": "This table presents a quantitative comparison of different font generation methods on two test datasets (UFSC and UFUC) using several evaluation metrics including FID, L1, LPIPS, RMSE, and SSIM.  It also includes the results of a user study to assess the aesthetic quality of the generated fonts. The results are shown for one-shot, three-shot, and eight-shot scenarios, with the best and second-best results highlighted.", "section": "4.2 Comparison with state-of-the-art Methods"}]