{"references": [{"fullname_first_author": "Hao", "paper_title": "Optimizing prompts for text-to-image generation", "publication_date": "2022-12-09", "reason": "This paper proposes a method for optimizing prompts for text-to-image generation, which is directly relevant to the current paper's focus on automatic prompt optimization."}, {"fullname_first_author": "Zhong", "paper_title": "Sur-adapter: Enhancing text-to-image pre-trained diffusion models with large language models", "publication_date": "2023-05-05", "reason": "This paper introduces a novel adapter-based method for enhancing the quality of text-to-image generation, which is closely related to the proposed AP-Adapter in the current paper."}, {"fullname_first_author": "Li", "paper_title": "Blip: Bootstrapping language-image pre-training for unified vision-language understanding and generation", "publication_date": "2022-07-15", "reason": "This paper introduces a new method for pre-training language-image models, which is used in this paper to generate automatic keyword prompts."}, {"fullname_first_author": "Hessel", "paper_title": "Clipscore: A reference-free evaluation metric for image captioning", "publication_date": "2021-04-21", "reason": "This paper proposes a new evaluation metric for image captioning, which is used in the current paper to evaluate the quality of the generated images."}, {"fullname_first_author": "Reimers", "paper_title": "Sentence-BERT: Sentence embeddings using Siamese BERT-networks", "publication_date": "2019-08-10", "reason": "This paper introduces Sentence-BERT, a powerful sentence embedding model, which is used in the current paper for prompt similarity calculation."}]}