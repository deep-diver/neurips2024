[{"figure_path": "vUrOuc6NR3/figures/figures_1_1.jpg", "caption": "Figure 1: (a) We present DynaMo, a new self-supervised method for learning visual representations for visuomotor control. DynaMo exploits the causal structure in demonstrations by jointly learning the encoder with inverse and forward dynamics models. DynaMo requires no augmentations, contrastive sampling, or access to ground truth actions. This enables downstream policy learning using limited in-domain data across simulated and real-world robotics tasks. For each environment, we pretrain the visual representation in-domain with DynaMo and learn a policy on the pretrained embeddings. (b) We provide real-world rollouts of policies learned with DynaMo representation on our multi-task xArm Kitchen and Allegro Manipulation environments.", "description": "This figure shows the architecture of DynaMo and its application to real-world robotics. (a) illustrates the self-supervised learning process of DynaMo: It jointly learns an encoder, inverse dynamics model, and forward dynamics model to predict future frames from current observations, without using any augmentations or contrastive sampling. The learned representation is then used to train a policy. (b) demonstrates the real-world application of DynaMo: using the learned representations to train policies on two multi-task environments (xArm Kitchen and Allegro Manipulation).", "section": "1 Introduction"}, {"figure_path": "vUrOuc6NR3/figures/figures_3_1.jpg", "caption": "Figure 2: Embedding nearest neighbor matches for DynaMo, BYOL, MoCo, and TCN on the Block Pushing environment. (Top) The nearest neighbor matches visualized in pixel space. (Bottom) Matches visualized in a top-down view. We see that the DynaMo representation captures task-relevant features (end effector, block, and target locations in this case), whereas prior work fixates on the large robot arm.", "description": "This figure compares the nearest neighbor embedding matches obtained by four different self-supervised methods (DynaMo, BYOL, MoCo, TCN) for the Block Pushing task.  It shows that DynaMo's learned representations focus on task-relevant features like the end-effector position, block positions, and target locations, while other methods primarily focus on the visually dominant robot arm, ignoring smaller, crucial features. This illustrates DynaMo's ability to learn more task-relevant features even in the presence of visually distracting elements.", "section": "3 DynaMo"}, {"figure_path": "vUrOuc6NR3/figures/figures_3_2.jpg", "caption": "Figure 3: Architecture of DynaMo. DynaMo jointly learns an image encoder, an inverse dynamics model, and a forward dynamics model with a forward dynamics prediction loss.", "description": "This figure illustrates the architecture of DynaMo, a self-supervised method for learning visual representations for visuomotor control.  It shows three key components working together: an image encoder that converts raw visual observations into embeddings; an inverse dynamics model that predicts latent transition states given a sequence of observation embeddings; and a forward dynamics model that predicts future observation embeddings based on past embeddings and latent transitions.  The forward dynamics model is trained with a prediction loss, comparing its predictions to actual future observation embeddings. This architecture allows DynaMo to learn rich representations from just image sequences without needing ground truth actions or data augmentation.", "section": "3 DynaMo"}, {"figure_path": "vUrOuc6NR3/figures/figures_5_1.jpg", "caption": "Figure 4: We evaluate DynaMo on four simulated benchmarks - Franka Kitchen, Block Pushing, Push-T, and LIBERO Goal, and two real-world environments - Allegro Manipulation, and xArm Kitchen.", "description": "This figure shows the six different environments used to evaluate the DynaMo model.  These environments range from simulated robotic manipulation tasks (Franka Kitchen, Block Pushing, Push-T, LIBERO Goal) to real-world robotic manipulation tasks (Allegro Manipulation, xArm Kitchen). The images provide a visual representation of the complexity and diversity of the tasks involved.", "section": "4.1 Environments and datasets"}, {"figure_path": "vUrOuc6NR3/figures/figures_17_1.jpg", "caption": "Figure 5: xArm Kitchen environment tasks", "description": "This figure shows the five different tasks in the xArm Kitchen environment. Each row displays a sequence of images showing the steps involved in completing a specific task. The tasks include putting a yogurt bottle in the fridge door, fetching a yogurt bottle from the fridge door, putting a ketchup bottle inside the fridge, fetching a tea bottle from the fridge door, and fetching a water bottle from the fridge.", "section": "4.1 Environments and datasets"}, {"figure_path": "vUrOuc6NR3/figures/figures_21_1.jpg", "caption": "Figure 6: Rollouts on Allegro Manipulation with our DynaMo-pretrained encoder.", "description": "This figure shows the results of applying the DynaMo model on the Allegro Manipulation environment. It showcases a series of images depicting a robotic hand performing three different tasks: lifting a sponge, lifting a teabag, and opening a microwave door. For each task, both successful and unsuccessful attempts are shown to illustrate the model's performance variability.", "section": "C Real robot environment rollouts"}, {"figure_path": "vUrOuc6NR3/figures/figures_22_1.jpg", "caption": "Figure 7: Rollouts on xArm Kitchen with our DynaMo-pretrained encoder.", "description": "This figure shows a series of images depicting the xArm robot performing various kitchen tasks, such as putting and fetching bottles from the fridge.  Each row shows a sequence of images for a specific task, with some rollouts showing successful completion and others indicating failure. The success or failure of each attempt is indicated in parentheses below each task description.  The overall goal is to demonstrate the capability of the DynaMo-pretrained encoder to effectively enable the robot to perform these complex manipulation tasks.", "section": "C Real robot environment rollouts"}]