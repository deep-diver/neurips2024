{"references": [{"fullname_first_author": "Altman, E.", "paper_title": "Constrained Markov decision processes", "publication_date": "2021", "reason": "This paper provides the foundational framework for Constrained Markov Decision Processes (CMDPs), which is the central topic of the current paper."}, {"fullname_first_author": "Chen, Y.", "paper_title": "A primal-dual approach to constrained Markov decision processes", "publication_date": "2021-01-10", "reason": "This paper is cited as one of the few works that study sample efficiency in CMDPs using function approximation, a key challenge addressed in the current paper."}, {"fullname_first_author": "Jain, A.", "paper_title": "Towards painless policy optimization for constrained mdps", "publication_date": "2022", "reason": "This paper tackles the challenge of efficiently learning in CMDPs with infinite state spaces and function approximation, a problem that is directly relevant to the current paper's focus on CMDPs with q-realizability."}, {"fullname_first_author": "Weisz, G.", "paper_title": "Confident approximate policy iteration for efficient local planning in q-realizable mdps", "publication_date": "2022", "reason": "This paper presents a sample-efficient algorithm for unconstrained MDPs with local access and q-realizability, providing crucial algorithmic foundations and inspiration for the methods used in the current paper."}, {"fullname_first_author": "Vaswani, S.", "paper_title": "Near-optimal sample complexity bounds for constrained mdps", "publication_date": "2022", "reason": "This paper establishes near-optimal sample complexity bounds for tabular CMDPs, providing a benchmark for the sample efficiency results achieved by the current paper in a more general setting with function approximation."}]}