{"references": [{"fullname_first_author": "Y. Abbasi-Yadkori", "paper_title": "Improved algorithms for linear stochastic bandits", "publication_date": "2011-01-01", "reason": "This paper provides foundational results on linear stochastic bandits, which are crucial for the analysis of linear Markov Decision Processes (MDPs)."}, {"fullname_first_author": "M. G. Azar", "paper_title": "Minimax regret bounds for reinforcement learning", "publication_date": "2017-01-01", "reason": "This paper establishes minimax optimal regret bounds for reinforcement learning in tabular MDPs, providing a benchmark for algorithms in more complex settings."}, {"fullname_first_author": "C. Jin", "paper_title": "Provably efficient reinforcement learning with linear function approximation", "publication_date": "2020-01-01", "reason": "This paper presents the first provably efficient algorithm for reinforcement learning with linear function approximation in linear MDPs, addressing a key challenge in the field."}, {"fullname_first_author": "U. Sherman", "paper_title": "Rate-optimal policy optimization for linear Markov decision processes", "publication_date": "2023-01-01", "reason": "This paper introduces the first rate-optimal policy optimization algorithm for linear MDPs, which directly motivates the current work."}, {"fullname_first_author": "A. Zanette", "paper_title": "Tighter problem-dependent regret bounds in reinforcement learning without domain knowledge using value function bounds", "publication_date": "2019-01-01", "reason": "This paper provides tighter regret bounds for reinforcement learning algorithms, which are relevant to the analysis of regret in the current paper"}]}