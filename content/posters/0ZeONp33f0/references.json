{"references": [{"fullname_first_author": "P. Barcel\u00f3", "paper_title": "The Logical Expressiveness of Graph Neural Networks", "publication_date": "2020-04-26", "reason": "This paper establishes a foundational connection between the expressiveness of GNNs and logic, providing a theoretical basis for understanding their capabilities and limitations, which is central to the current paper's focus."}, {"fullname_first_author": "W. Maass", "paper_title": "On the Computational Power of Sigmoid versus Boolean Threshold Circuits", "publication_date": "1991-10-01", "reason": "This seminal work established a connection between the computational power of neural networks and Boolean circuits, laying the groundwork for subsequent research on the expressive power of neural network architectures, including the current paper's analysis of GNNs."}, {"fullname_first_author": "H. T. Siegelmann", "paper_title": "On the Computational Power of Neural Nets", "publication_date": "1995-01-01", "reason": "This paper significantly contributed to the understanding of the computational capabilities of neural networks, which is relevant to the current work's investigation of GNNs and arithmetic circuits."}, {"fullname_first_author": "M. Grohe", "paper_title": "The Descriptive Complexity of Graph Neural Networks", "publication_date": "2023-01-01", "reason": "This recent work provides a detailed analysis of the expressiveness of GNNs, specifically focusing on their relation to Boolean circuits and first-order logic, which is highly relevant to the current paper's investigation of GNNs and arithmetic circuits."}, {"fullname_first_author": "W. Merrill", "paper_title": "Transformers are Uniform Constant-Depth Threshold Circuits", "publication_date": "2022-01-01", "reason": "This paper offers a novel perspective on the computational power of transformers, showing that they have surprisingly limited complexity, which adds a valuable contrast to the complexity analysis of GNNs performed in the current study."}]}