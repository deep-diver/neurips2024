[{"figure_path": "Y4tHp5Jilp/tables/tables_7_1.jpg", "caption": "Table 1: Quantitative results on NYUv2.", "description": "This table presents a quantitative comparison of different depth completion methods on the NYUv2 dataset.  It compares performance across various experimental settings: 1-shot, 10-shot, 100-shot learning, and 1-sequence training.  The metrics used for comparison are RMSE, MAE, and DELTA1 (inlier ratio), providing a comprehensive evaluation of each method's accuracy and robustness in low-data and limited-training scenarios.", "section": "5.2 Experiment"}, {"figure_path": "Y4tHp5Jilp/tables/tables_7_2.jpg", "caption": "Table 2: Ablation of hyperbolic operations on zero-/few-shot performance for NYU and KITTI.", "description": "This table presents the ablation study results comparing the performance of the proposed method using Euclidean and hyperbolic geometries. It shows the RMSE and MAE values for zero-shot (no training) and few-shot (1-shot, 10-shot, 100-shot) learning scenarios on NYU and KITTI datasets. This comparison highlights the impact of hyperbolic embedding on the model's generalization and performance in low-data settings.", "section": "5.3 Ablation Study"}, {"figure_path": "Y4tHp5Jilp/tables/tables_7_3.jpg", "caption": "Table 4: Result of few-shot learning without dense GT depth. (RMSE/MAE)", "description": "This table presents the results of few-shot learning experiments conducted without the use of dense ground truth (GT) depth data.  The experiment aims to evaluate the model's performance in a more realistic scenario where obtaining high-quality dense depth data is challenging, particularly for outdoor datasets.  The results are shown for different sensor configurations (8-Line and 32-Line LiDAR), and different numbers of training shots (1-shot, 10-shot, and 100-shot). RMSE and MAE values are reported, demonstrating the model's ability to adapt and generalize to new environments and sensor types, even with limited training data.", "section": "5.2 Experiment"}, {"figure_path": "Y4tHp5Jilp/tables/tables_7_4.jpg", "caption": "Table 5: Averaged curvature values.", "description": "This table presents the average curvature values computed for multi-size affinity maps using the curvature generation blocks (Ck) in the proposed model.  The curvatures are calculated for different kernel sizes (k = {3, 5, 7}) and for two datasets: NYU and KITTI. The values suggest that information from more distant regions tends to prefer lower curvature. This is because regions closer to the target require a more distinct hyperbolic space to prevent bleeding errors during depth propagation.", "section": "4.1 Multi-scale Feature Fusion & Hyperbolic Curvature Generation"}, {"figure_path": "Y4tHp5Jilp/tables/tables_8_1.jpg", "caption": "Table 1: Quantitative results on NYUv2.", "description": "This table presents a quantitative comparison of different depth completion methods on the NYUv2 dataset.  It shows the RMSE, MAE, and DELTA1 (inlier ratio) metrics for each method under various training scenarios: 1-shot, 10-shot, 100-shot, and 1-sequence training.  The results demonstrate the performance of each method in terms of accuracy and robustness when trained with limited data.", "section": "5.2 Experiment"}, {"figure_path": "Y4tHp5Jilp/tables/tables_8_2.jpg", "caption": "Table 6: Ablation study on KITTI DC (RMSE / MAE \u00b1 its standard deviation).", "description": "This ablation study analyzes the impact of each component (Eq.3, Eq.5, Eq.6, and Eq.2) on the overall performance of the proposed method.  It evaluates the model's performance with different components removed, showing the contribution of each part to the final result, particularly in 1-shot and 10-shot scenarios on the KITTI dataset.", "section": "5.3 Ablation Study"}, {"figure_path": "Y4tHp5Jilp/tables/tables_8_3.jpg", "caption": "Table 7: Comparison of various depth foundation models (RMSE / MAE).", "description": "This table compares the performance of different depth foundation models (DepthAnything, UniDepth, and MiDaS) on the NYU and KITTI datasets using 1-shot, 10-shot, and 100-shot learning scenarios.  The results show the RMSE and MAE values, indicating the accuracy of depth estimation for each model and training scenario.  It highlights the varying performance across different models and dataset.", "section": "5.2 Experiment"}, {"figure_path": "Y4tHp5Jilp/tables/tables_8_4.jpg", "caption": "Table 8: Computational cost of Models.", "description": "This table presents a comparison of the computational costs among different depth completion models.  It shows the total number of parameters, the number of learnable parameters, the inference time (in seconds), and the GPU memory consumption (in MB) for each model.  The models compared include BPNet, LRRU, CompletionFormer, and three variants of the proposed model (Ours) using different foundation models (MiDaS, DepthAnything, UniDepth). This allows for a quantitative assessment of the efficiency and resource requirements of each approach.", "section": "5.1 Implementation Details"}, {"figure_path": "Y4tHp5Jilp/tables/tables_9_1.jpg", "caption": "Table 1: Quantitative results on NYUv2.", "description": "This table presents a quantitative comparison of different depth completion methods on the NYUv2 dataset.  The comparison is performed under various training scenarios (1-shot, 10-shot, 100-shot, and 1-sequence training), demonstrating the performance of each method in low data regimes. Metrics used include RMSE, MAE, and DELTA1 (inlier ratio).  The results highlight the performance of the proposed method, 'Ours', in comparison to state-of-the-art (SoTA) approaches.", "section": "5.2 Experiment"}, {"figure_path": "Y4tHp5Jilp/tables/tables_9_2.jpg", "caption": "Table 10: Experiment on SUN RGB-D dataset.", "description": "This table presents the results of the proposed UniDC model on the SUN RGB-D dataset.  It shows a comparison of the model's performance (RMSE, MAE, DELTA1) against other state-of-the-art methods (DP, LRRU, DFU, OGNIDC) under various few-shot learning settings (1-shot, 10-shot, 100-shot).  The SUN RGB-D dataset is known for its diversity in terms of sensor types, environments, and data density, making it a good benchmark for evaluating the generalizability of depth completion methods.", "section": "5 Experiment and Analysis"}, {"figure_path": "Y4tHp5Jilp/tables/tables_17_1.jpg", "caption": "Table 11: Full Dataset Training Benchmark on NYU and KITTI dataset.", "description": "This table presents the performance comparison of different models (Cformer_Tiny, Cformer_Small, Cformer_Base, LRRU_Mini, LRRU_Tiny, LRRU_Small, LRRU_Base, Ours_Tiny, Ours, Ours_Small, Ours_Base) on NYU and KITTI datasets using full dataset training.  The results are evaluated using RMSE and MAE metrics to assess the model's accuracy in depth estimation.  The number of learnable parameters for each model is also listed.", "section": "A.3 Additional Experiments"}, {"figure_path": "Y4tHp5Jilp/tables/tables_18_1.jpg", "caption": "Table 12: Ablation study on SPNs with hyperbolic operation.", "description": "This table presents the ablation study results on different spatial propagation networks (SPNs) with and without hyperbolic operations. It compares the performance of CSPN, NLSPN, and DySPN, both with and without the addition of hyperbolic geometry, across 1-shot, 10-shot, and 100-shot learning scenarios. The metrics used for comparison include RMSE, MAE, and DELTA1, which represent the root mean squared error, mean absolute error, and inlier ratio, respectively.  The results demonstrate the effectiveness of hyperbolic operations in improving the accuracy and robustness of depth completion, particularly in low-data regimes.", "section": "5.3 Ablation Study"}, {"figure_path": "Y4tHp5Jilp/tables/tables_18_2.jpg", "caption": "Table 12: Ablation study on SPNs with hyperbolic operation.", "description": "This ablation study compares the performance of different spatial propagation networks (SPNs), namely CSPN, NLSPN, and DySPN, both with and without the integration of hyperbolic operations. The results demonstrate the effectiveness of hyperbolic geometry in enhancing the accuracy of depth map prediction, especially in low-data scenarios.", "section": "5.3 Ablation Study"}, {"figure_path": "Y4tHp5Jilp/tables/tables_19_1.jpg", "caption": "Table 1: Quantitative results on NYUv2.", "description": "This table presents a quantitative comparison of different depth completion methods on the NYUv2 dataset.  The comparison considers various training scenarios, including 1-shot, 10-shot, 100-shot, and 1-sequence training.  The evaluation metrics used are RMSE, MAE, and DELTA1, representing the root mean squared error, mean absolute error, and inlier ratio, respectively.  The table showcases the performance of the proposed method (Ours) against several state-of-the-art (SOTA) methods across different training regimes, highlighting the method's adaptability to few-shot learning scenarios.", "section": "5.2 Experiment"}]