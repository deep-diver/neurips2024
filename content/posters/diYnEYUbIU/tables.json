[{"figure_path": "diYnEYUbIU/tables/tables_6_1.jpg", "caption": "Table 1: Comparison with state-of-the-art methods on the Stanford2D3DS dataset. Consistent with recent work, we report performance as the average mIoU across all three official folds (Avg mIoU) and on fold 1 specifically (F1 mIoU). Our approach demonstrates substantial improvements over both the baseline and existing methods.", "description": "This table compares the performance of the proposed method with several state-of-the-art methods on the Stanford2D3DS dataset for panoramic semantic segmentation.  It shows the average mean Intersection over Union (mIoU) across all three official folds and the mIoU specifically for fold 1. The results highlight the significant improvement achieved by the proposed method compared to existing approaches.", "section": "4.2 Experiment Results"}, {"figure_path": "diYnEYUbIU/tables/tables_7_1.jpg", "caption": "Table 2: Quantitative comparison of depth estimation task.", "description": "This table compares the performance of the proposed method's depth estimation with FreDSNet [35] using several metrics: Mean Relative Error (MRE), Mean Absolute Error (MAE), Root Mean Squared Error (RMSE), logarithmic RMSE (RMSElog), and three relative accuracy measures (\u03b4\u2081, \u03b4\u2082, \u03b4\u2083).  Lower values for MRE, MAE, and RMSE indicate better accuracy, while higher values for \u03b4\u2081, \u03b4\u2082, and \u03b4\u2083 are better.", "section": "4.2 Experiment Results"}, {"figure_path": "diYnEYUbIU/tables/tables_8_1.jpg", "caption": "Table 3: Comparison with the SOTA methods on the Structured3D and the Matterport3D validation and test sets. Our method marks new state of the arts on both datasets given the same input.", "description": "This table compares the performance of the proposed method against state-of-the-art (SOTA) methods on two benchmark datasets for panoramic semantic segmentation: Structured3D and Matterport3D.  The comparison is done using both RGB and RGBD modalities. The table shows that the proposed method achieves new state-of-the-art results on both datasets, surpassing previous methods in terms of mean Intersection over Union (mIoU) on both validation and test sets.", "section": "4.2 Experiment Results"}, {"figure_path": "diYnEYUbIU/tables/tables_8_2.jpg", "caption": "Table 4: Impact of each geometric representation to the model performance.", "description": "This table presents the ablation study results on the Stanford2D3DS dataset (fold 1).  It shows the effect of adding different geometric properties (Fhid, Fpc, Fdist, Fm) to the input of the transformer-based context module on the model's performance, measured by mIoU and Pixel Accuracy. The baseline uses only the global image feature (Fimg). The results demonstrate the incremental improvement in performance as more geometric information is incorporated.", "section": "4.3 Ablation study"}, {"figure_path": "diYnEYUbIU/tables/tables_9_1.jpg", "caption": "Table 1: Comparison with state-of-the-art methods on the Stanford2D3DS dataset. Consistent with recent work, we report performance as the average mIoU across all three official folds (Avg mIoU) and on fold 1 specifically (F1 mIoU). Our approach demonstrates substantial improvements over both the baseline and existing methods.", "description": "This table compares the proposed method's performance on the Stanford2D3DS dataset against other state-of-the-art methods.  It shows the mean Intersection over Union (mIoU) scores, both averaged across all three folds and specifically for fold 1.  The results highlight the superior performance of the proposed approach.", "section": "4.2 Experiment Results"}, {"figure_path": "diYnEYUbIU/tables/tables_9_2.jpg", "caption": "Table 6: Computational complexity comparison with input size: 512 \u00d7 1024 \u00d7 3.", "description": "This table compares the number of parameters and TFLOPs (floating point operations per second) for different models used for panoramic semantic segmentation.  It provides a measure of the computational cost of each model, indicating the model's size and processing power needed for training and inference.", "section": "4.3 Ablation study"}]