[{"figure_path": "Yy0KUmneV6/figures/figures_3_1.jpg", "caption": "Figure 1: Illustration of the tree autoencoder model with a data space R\u00b3 for a tree of depth \u2206 = 2 with leaves L = {1, 2, 3, 4}, defining a latent space (album) of four 2D spaces.", "description": "This figure illustrates the PCA tree autoencoder model.  The left panel shows a simplified representation of the model as a tree with an encoder (projection) and decoder (reconstruction) at each node. The input data x is processed by the encoder, which uses a tree structure to route x to one of the leaves. Each leaf has its own PCA, projecting the data into a lower-dimensional space (2D in this example). The resulting latent vector (z) is then passed to the decoder, which reconstructs the output y. The right panel provides a 3D visualization of the data space being partitioned by the tree into four 2D spaces (one for each leaf), each with its own local PCA.", "section": "Definition of the PCA tree as an autoencoder"}, {"figure_path": "Yy0KUmneV6/figures/figures_3_2.jpg", "caption": "Figure 2: PCA tree on a 2D toy data set. Left plot: regular PCA (PCA tree with \u2206 = 0). Rest of plots: PCA tree with \u2206 = 1. Mean \u03bc;: diamond; principal component direction Uj and variance: dashed line and arrows; decision boundary w\u2081, W10 at the root: solid line.", "description": "This figure shows a comparison of PCA and PCA tree on a 2D toy dataset. The leftmost plot shows the result of applying regular PCA (which is equivalent to a PCA tree with depth \u2206=0). The other three plots show the results of applying a PCA tree with depth \u2206=1.  Different stages of the training are shown (initial and final). For the PCA tree, the mean (\u03bcj), principal component direction (Uj), and variance of each leaf are shown, along with the decision boundary (w\u2081, w10) at the root node.  The figure illustrates how the PCA tree partitions the data space and fits local PCA models to each partition.", "section": "4 Optimization algorithm"}, {"figure_path": "Yy0KUmneV6/figures/figures_7_1.jpg", "caption": "Figure 3: Plots 1, 2: training time per iteration on (Infinite) MNIST for PCA trees with different N, D, \u2206. Plot 3: training time for PCA trees (10 iterations) and for t-SNE and UMAP (default user parameters). Plots 4, 5: learning curves for PCA trees of different depths on several datasets.", "description": "This figure presents a comprehensive evaluation of the PCA tree algorithm's performance and scalability.  The first two plots illustrate the training time per iteration for the MNIST dataset at varying depths (\u2206) and dimensions (D), comparing theoretical and actual results.  The third plot compares the training time of PCA trees against t-SNE and UMAP for different sample sizes (N), highlighting PCA tree's superior scalability. The final two plots showcase the convergence of the objective function over iterations across different datasets and depths.", "section": "6.1 Training time and scalability to large datasets"}, {"figure_path": "Yy0KUmneV6/figures/figures_7_2.jpg", "caption": "Figure 4: Squared reconstruction error per sample of PCA as a function of the number of principal components L and of PCA tree using L = 2 PCs in each leaf, for different depths on two datasets: Fashion MNIST (N = 60000, D = 784) and 20newsgroups (N = 11314, D = 72764).", "description": "This figure compares the reconstruction error of PCA and PCA tree for Fashion MNIST and 20newsgroups datasets.  The x-axis represents the number of principal components (L) used in PCA, and the y-axis shows the squared reconstruction error per sample.  For the PCA tree, the number of principal components is fixed at L=2 in each leaf, and the depth of the tree (\u0394) is varied. The plots illustrate that the PCA tree achieves a lower reconstruction error than PCA, especially when the number of principal components in PCA is relatively small.  The different lines for the PCA tree show how the reconstruction error changes with varying tree depths.", "section": "6.2 Reconstruction error"}, {"figure_path": "Yy0KUmneV6/figures/figures_9_1.jpg", "caption": "Figure 5: PCA tree trained on the Fashion MNIST dataset (\u2206 = 4, \u03bb = 100, RMSE per pixel and image of 0.158). The decision nodes' weight vectors (and the leaves' PCs Uj) are shown as 28 \u00d7 28 images, with negative/zero/positive values colored blue/white/red, respectively. Each leaf shows a 2D PCA scatterplot of its RS (instances reaching it), and below it the mean \u03bcj as a grayscale image and the 2 PCs Uj as color images. To the right of the scatterplot, a bar chart displays class proportions and class means. The legend (top left) shows, for each class, its mean (grayscale image), color (for the scatterplots) and description. For visualization purposes, the tree is split into its left and right root subtrees (fig. 8 shows the whole tree). The bottom panel zooms into two regions of the tree, for decision nodes 8 and 14. You may want to zoom into the figure to see more details.", "description": "This figure shows a PCA tree trained on the Fashion MNIST dataset.  It illustrates the hierarchical structure of the model, where each decision node represents a split based on a subset of features (visualized as 28x28 images), and each leaf node contains a 2D PCA projection of the data points that reach that leaf. The figure visualizes the weight vectors, PCA scatterplots, means, and principal components for each node, providing insights into how the model separates and represents different classes of clothing items.", "section": "Interpreting and exploring PCA tree visualizations"}, {"figure_path": "Yy0KUmneV6/figures/figures_13_1.jpg", "caption": "Figure 6: Pseudocode for the PCA tree optimization algorithm.", "description": "The pseudocode describes the PCA tree optimization algorithm. It starts with an input training set and hyperparameters. It initializes a tree structure and iteratively refines it by performing PCA on leaf nodes and fitting a regularized binary classifier on decision nodes. This process continues until a stopping criterion is met.  The algorithm employs parallelization (parfor) for efficiency, updating each node's reduced set (instances that reach that node) after each iteration.", "section": "4 Optimization algorithm"}, {"figure_path": "Yy0KUmneV6/figures/figures_15_1.jpg", "caption": "Figure 7: Objective function across training iterations for different datasets.", "description": "This figure displays the objective function values across various training iterations for five different datasets: MNIST, Fashion MNIST, Letter, 20newsgroups, and Amazon Reviews. Each dataset is represented by multiple lines, each corresponding to a different tree depth (\u2206). The x-axis represents the iteration number, and the y-axis represents the objective function value. The figure demonstrates the monotonic decrease of the objective function during training for all datasets and tree depths, indicating the effectiveness of the proposed optimization algorithm.", "section": "Additional experimental results"}, {"figure_path": "Yy0KUmneV6/figures/figures_16_1.jpg", "caption": "Figure 5: PCA tree trained on the Fashion MNIST dataset (\u2206 = 4, \u03bb = 100, RMSE per pixel and image of 0.158). The decision nodes\u2019 weight vectors (and the leaves\u2019 PCs Uj) are shown as 28 \u00d7 28 images, with negative/zero/positive values colored blue/white/red, respectively. Each leaf shows a 2D PCA scatterplot of its RS (instances reaching it), and below it the mean \u03bcj as a grayscale image and the 2 PCs Uj as color images. To the right of the scatterplot, a bar chart displays class proportions and class means. The legend (top left) shows, for each class, its mean (grayscale image), color (for the scatterplots) and description. For visualization purposes, the tree is split into its left and right root subtrees (fig. 8 shows the whole tree). The bottom panel zooms into two regions of the tree, for decision nodes 8 and 14. You may want to zoom into the figure to see more details.", "description": "This figure shows a PCA tree trained on the Fashion MNIST dataset.  It displays the tree structure, with decision nodes represented by 28x28 images showing the feature weights and leaf nodes showing 2D PCA scatterplots of the data points reaching that leaf. The color of the pixels in the decision node images correspond to the weights (blue for negative, white for zero, and red for positive), and the leaf node scatterplots show the data points colored according to their class label. The image also shows the mean and principal components of each leaf.", "section": "6.3 Interpreting and exploring PCA tree visualizations"}, {"figure_path": "Yy0KUmneV6/figures/figures_16_2.jpg", "caption": "Figure 5: PCA tree trained on the Fashion MNIST dataset (\u2206 = 4, \u03bb = 100, RMSE per pixel and image of 0.158). The decision nodes\u2019 weight vectors (and the leaves\u2019 PCs Uj) are shown as 28 \u00d7 28 images, with negative/zero/positive values colored blue/white/red, respectively. Each leaf shows a 2D PCA scatterplot of its RS (instances reaching it), and below it the mean \u03bcj as a grayscale image and the 2 PCs Uj as color images. To the right of the scatterplot, a bar chart displays class proportions and class means. The legend (top left) shows, for each class, its mean (grayscale image), color (for the scatterplots) and description. For visualization purposes, the tree is split into its left and right root subtrees (fig. 8 shows the whole tree). The bottom panel zooms into two regions of the tree, for decision nodes 8 and 14. You may want to zoom into the figure to see more details.", "description": "This figure shows a visualization of a PCA tree trained on the Fashion MNIST dataset.  It displays the tree structure, with decision nodes represented by 28x28 images showing the weights and leaves showing 2D PCA scatterplots of their respective regions.  Each leaf also includes the mean and principal components as images, along with a bar chart showing class proportions. The figure illustrates how the tree hierarchically separates different classes of clothing items based on visual features. The bottom portion zooms in on two sections to highlight details.", "section": "6.3 Interpreting and exploring PCA tree visualizations"}, {"figure_path": "Yy0KUmneV6/figures/figures_16_3.jpg", "caption": "Figure 10: Scatterplots of different dimensionality reduction methods for the same dataset as in fig. 5 (Fashion MNIST) (N = 60000, D = 784). Class colors match the labels from fig. 5", "description": "This figure compares the visualization results of three different dimensionality reduction methods: PCA, t-SNE, and UMAP. All three methods were applied to the same Fashion MNIST dataset, which contains 60,000 images of 28x28 pixels (784 features). The color of each point in the scatterplots represents its class label. PCA shows a clear linear separation of some classes, while t-SNE and UMAP show more complex, non-linear structure with varying degrees of cluster separation and distortion.  The figure highlights the differences in how each method captures and represents the data's underlying structure.", "section": "6.3 Interpreting and exploring PCA tree visualizations"}, {"figure_path": "Yy0KUmneV6/figures/figures_17_1.jpg", "caption": "Figure 11: Trained PCA tree structure on the MNIST dataset with a reconstruction loss of 0.29", "description": "This figure shows a trained PCA tree structure on the MNIST dataset, which is a classic dataset of handwritten digits. The tree's structure is visualized, with each node representing a decision point in the classification process. The leaves of the tree show the final classification results with a reconstruction loss of 0.29.  Each node contains a visualization of the data at that point in the tree. The visualization allows one to interpret the decisions made by the tree at various levels. This visual representation makes it easier to understand how the hierarchical structure of the PCA tree achieves dimensionality reduction. ", "section": "D.2 MNIST dataset"}, {"figure_path": "Yy0KUmneV6/figures/figures_17_2.jpg", "caption": "Figure 10: Scatterplots of different dimensionality reduction methods for the same dataset as in fig. 5 (Fashion MNIST) (N = 60000, D = 784). Class colors match the labels from fig. 5", "description": "This figure compares the visualizations obtained by PCA, t-SNE, and UMAP on the Fashion MNIST dataset.  It highlights the differences in how these methods represent the data's structure in a two-dimensional space. PCA shows a spread of data points where some class separation is visible, whereas t-SNE arranges the data in a circular fashion with better class separation, while UMAP clusters the data in a more scattered manner with some overlap between classes. The figure illustrates the strengths and weaknesses of each method for dimensionality reduction and visualization.", "section": "6.3 Interpreting and exploring PCA tree visualizations"}, {"figure_path": "Yy0KUmneV6/figures/figures_18_1.jpg", "caption": "Figure 5: PCA tree trained on the Fashion MNIST dataset (\u2206 = 4, \u03bb = 100, RMSE per pixel and image of 0.158). The decision nodes\u2019 weight vectors (and the leaves\u2019 PCs Uj) are shown as 28 \u00d7 28 images, with negative/zero/positive values colored blue/white/red, respectively. Each leaf shows a 2D PCA scatterplot of its RS (instances reaching it), and below it the mean \u03bcj as a grayscale image and the 2 PCs Uj as color images. To the right of the scatterplot, a bar chart displays class proportions and class means. The legend (top left) shows, for each class, its mean (grayscale image), color (for the scatterplots) and description. For visualization purposes, the tree is split into its left and right root subtrees (fig. 8 shows the whole tree). The bottom panel zooms into two regions of the tree, for decision nodes 8 and 14. You may want to zoom into the figure to see more details.", "description": "This figure illustrates a PCA tree trained on the Fashion MNIST dataset.  It visualizes the tree structure, showing decision nodes (with their weight vectors as 28x28 images) and leaf nodes (with 2D PCA scatterplots, means, and principal components). The visualization helps interpret how the tree separates different classes hierarchically, revealing meaningful features and low-dimensional structures within each leaf.", "section": "6.3 Interpreting and exploring PCA tree visualizations"}, {"figure_path": "Yy0KUmneV6/figures/figures_18_2.jpg", "caption": "Figure 12: Scatterplots of different dimensionality reduction methods for the same dataset as in fig. 11 (N = 60000, D = 784). The class colors correspond to the labels in fig. 11", "description": "This figure compares the visualization results of three different dimensionality reduction methods: PCA, t-SNE, and UMAP.  All three methods were applied to the MNIST dataset (60,000 samples, 784 dimensions), aiming to reduce the data to two dimensions for visualization. The plot shows that PCA preserves the linear structure and clusters better than t-SNE and UMAP, however t-SNE and UMAP visually separate different classes more distinctly.  The color of each point indicates the corresponding digit class.", "section": "D.2 MNIST dataset"}]