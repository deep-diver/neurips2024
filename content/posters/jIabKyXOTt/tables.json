[{"figure_path": "jIabKyXOTt/tables/tables_2_1.jpg", "caption": "Table 1: Comparison with other sparse linear bandit works. S \u2208 [d] is the sparsity level and \u2206 is the suboptimality gap (3.3). The nested assumption refers to (\u03b8\u2217)i \u2260 0 for i = 1, . . ., S. The minimum signal and the compatibility condition refer to assumptions on the distribution of the action set and on the smallest value of the non-zero elements in \u03b8. Smoothed adversary refers to adversarially selected action sets with added Gaussian noise. The regret bounds listed in [1, 2, 23, 8, 25, 18, 9] are high-probability bounds: with high probability, the regret is of the same order as the bound in the table.", "description": "This table compares the proposed algorithm with existing sparse linear bandit algorithms. It shows the expected regret bounds achieved by each algorithm under different assumptions regarding the sparsity level, adaptive adversary, and action set properties.  The table highlights the novelty of the proposed algorithm in achieving sparse regret bounds without requiring prior knowledge of sparsity or making strong assumptions on the action sets.", "section": "1.1 Additional related work"}, {"figure_path": "jIabKyXOTt/tables/tables_12_1.jpg", "caption": "Table 1: Comparison with other sparse linear bandit works. S \u2208 [d] is the sparsity level and \u2206 is the suboptimality gap (3.3). The nested assumption refers to (\u03b8\u2217)i \u2260 0 for i = 1,..., S. The minimum signal and the compatibility condition refer to assumptions on the distribution of the action set and on the smallest value of the non-zero elements in \u03b8. Smoothed adversary refers to adversarially selected action sets with added Gaussian noise. The regret bounds listed in [1, 2, 23, 8, 25, 18, 9] are high-probability bounds: with high probability, the regret is of the same order as the bound in the table.", "description": "This table compares the proposed algorithm with existing sparse linear bandit algorithms.  It shows the assumptions made by each algorithm (e.g., knowledge of sparsity, type of adversary, action set properties), and the resulting regret bounds achieved. The table highlights the advantages of the proposed approach, which achieves strong regret bounds without relying on many of the assumptions made by other algorithms.", "section": "Additional related work"}]