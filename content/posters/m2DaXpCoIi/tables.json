[{"figure_path": "m2DaXpCoIi/tables/tables_1_1.jpg", "caption": "Table 1: Examples for key concepts from Section 2 for the permutable class F of ASCII strings of length 5. {\\dots} denotes a multiset, and we use cycle notation for permutations.", "description": "This table provides examples to illustrate key concepts introduced in Section 2 of the paper, specifically focusing on the permutable class F which consists of ASCII strings of length 5.  It demonstrates the concepts of permutation, permutable class, ordered object, quotient class, unordered object, and automorphisms using the example string \"sense\".  The use of cycle notation for permutations and the representation of a multiset using curly braces are also shown.", "section": "Background"}, {"figure_path": "m2DaXpCoIi/tables/tables_3_1.jpg", "caption": "Table 2: Example for color refinement as defined in Appendix C on plain graphs with 0 and 1 convolutions, and the resulting incompletely ordered graphs according to Definition 3.1. Colors only visualize correspondence to the resulting hashes, they are not materialized in the graph. The actual hashes, characters in the example, depend on the specific hash function used. Co bases each vertexes' hash on its degree only, while C\u2081 also takes the multiset of neighboring hashes from Co into account. The automorphism group of the incompletely ordered graph is the same as that for the string of vertex hashes, and color partitions correspond to their orbits.", "description": "This table exemplifies the color refinement process for plain graphs with 0 and 1 convolutions. It showcases how color refinement, a technique used to approximate a graph's automorphism group, works in practice.  The incompletely ordered graphs resulting from the process are displayed, along with the corresponding vertex hashes.  The example highlights the difference between using only degree information (C\u2080) and including neighbor information (C\u2081), illustrating how more information leads to a more accurate representation of the graph's symmetries.", "section": "3 Incomplete shuffle coding"}, {"figure_path": "m2DaXpCoIi/tables/tables_5_1.jpg", "caption": "Table 1: Examples for key concepts from Section 2 for the permutable class F of ASCII strings of length 5.  {{...}} denotes a multiset, and we use cycle notation for permutations.", "description": "This table provides examples to illustrate core concepts introduced in Section 2 of the paper, specifically focusing on the permutable class F (ASCII strings of length 5).  It demonstrates permutations, permutable classes, ordered objects, quotient classes, unordered objects, and automorphisms using the example string 'sense'. The use of cycle notation for permutations and multiset notation ({{...}}) are also shown.", "section": "Background"}, {"figure_path": "m2DaXpCoIi/tables/tables_17_1.jpg", "caption": "Table 5: Comparison between variants of shuffle coding.", "description": "This table summarizes four variants of shuffle coding, categorized by whether they require computation of the automorphism group, whether they allow for one-shot compression of a single unordered object, and whether they utilize an autoregressive model.  It shows that complete joint shuffle coding requires the automorphism group and is not one-shot, while complete autoregressive shuffle coding is one-shot and uses an autoregressive model. Similarly, incomplete joint and incomplete autoregressive methods offer near-optimal rates, with the latter employing an autoregressive model and allowing one-shot compression.", "section": "5 Related work"}, {"figure_path": "m2DaXpCoIi/tables/tables_17_2.jpg", "caption": "Table 6: Prefixes for the string f = abacb according to chunked prefixing chains of Example 4.1, for various chunk size sequences C. When used with autoregressive shuffle coding, the prefix f[i] resembles the information decoded after i iterations during decoding.", "description": "This table demonstrates how prefixes of a string are formed using different chunking strategies in autoregressive shuffle coding.  It shows how the prefixes change based on different chunk sizes, illustrating the impact of chunking on the information decoded at each step.  The 'full' approach represents decoding one character at a time, while the 'joint' approach decodes larger chunks of characters.", "section": "E Chunking"}, {"figure_path": "m2DaXpCoIi/tables/tables_21_1.jpg", "caption": "Table 7: Compression rates in bits for one-shot compression of multisets with full autoregressive shuffle coding, compared to the implementation from Severo et al. (2023a), as well as the optimal (net) rate. We also show the effect rates when using 10 chunks with a geometric series of sizes, with varying bases. The last but one column uses the relative discount from Equation (28) of each graph as the base (shown in parentheses).", "description": "This table compares the compression rates achieved by the authors' full autoregressive shuffle coding method with those reported by Severo et al. (2023a) for multisets of varying sizes. It also shows the optimal compression rates (net rates) and the rates obtained when using 10 chunks with geometrically increasing sizes. The last column shows the relative discount from Equation (28) for each graph size used as a base for the geometric series.", "section": "G Multiset compression results"}, {"figure_path": "m2DaXpCoIi/tables/tables_22_1.jpg", "caption": "Table 8: Incomplete joint shuffle coding with color refinement using 3 convolutions on the TUDatasets (Morris et al., 2020), compared to complete joint shuffle coding from Kunze et al. (2024), both using the Erd\u0151s-R\u00e9nyi (ER) model. Since complete joint shuffle coding is too slow for three of the 24 social network datasets, REDDIT-BINARY, REDDIT-MULTI-5K, REDDIT-MULTI-12K, they were evaluated separately in the category 'Reddit'. Compression rates are measured in bits per edge, and encoding and decoding speeds are for a single thread, in kB/s.", "description": "This table compares the performance of incomplete and complete joint shuffle coding methods on various graph datasets from the TUDatasets collection.  The incomplete method, which uses color refinement, is significantly faster than the complete method, with only a small increase in compression rate.  The table highlights the speed improvements achieved by the incomplete method, particularly for larger datasets where the complete method was too slow to complete.", "section": "H Joint graph shuffle coding results"}, {"figure_path": "m2DaXpCoIi/tables/tables_22_2.jpg", "caption": "Table 9: Incomplete joint shuffle coding with color refinement using 3 convolutions on the SZIP dataset, compared to complete joint shuffle coding from Kunze et al. (2024), both using the autoregressive P\u00f3lya urn (AP) model. We report the net compression rate, that is the additional cost of compressing that graph assuming there is already some compressed data to append to, measured in bits per edge, as well as compression and decompression speeds on 8 threads in kB/s. All results are means across multiple runs, 3 for complete, and 100 for incomplete shuffle coding.", "description": "This table compares the performance of incomplete and complete joint shuffle coding methods on the SZIP graph dataset.  It shows the net compression rate (additional cost given existing compressed data), and compression/decompression speeds using 8 threads.  The autoregressive P\u00f3lya urn model is used for both methods. Note that incomplete coding is significantly faster.", "section": "H Joint graph shuffle coding results"}, {"figure_path": "m2DaXpCoIi/tables/tables_23_1.jpg", "caption": "Table 10: Incomplete joint shuffle coding with the autoregressive P\u00f3lya urn model (AP), compared to just ordered AP, on SZIP and REC graphs. We report mean net rates and compression speeds based on 10 compression runs (100 for SZIP graphs) with varying initial message seeds. All net rates are in bits per edge, with empirical standard deviations below 0.02 bits per edge except where shown. Single-threaded and multi-threaded compression speeds with 8 logical cores are reported, all in MB/s.", "description": "This table compares the performance of incomplete joint shuffle coding using the autoregressive P\u00f3lya urn model against the performance of just using the ordered P\u00f3lya urn model.  It presents net rates (bits per edge), and compression/decompression speeds (MB/s) for both single-threaded and multi-threaded executions on two different graph datasets: SZIP and REC. The table also highlights the mean net rates with standard deviations. ", "section": "6 Experiments"}, {"figure_path": "m2DaXpCoIi/tables/tables_23_2.jpg", "caption": "Table 11: Compression rates and speeds between incomplete autoregressive shuffle coding with 16 (or 200) chunks and 3 color refinement convolutions using an Erd\u0151s-R\u00e9nyi (ER) and our autoregressive P\u00f3lya urn (AP) model, compared to the best results obtained by SZIP (Choi and Szpankowski, 2012) for each graph (on different hardware). We report means and standard deviations based on 100 compression runs with varying initial message seeds. All rates are in bits per edge, and all speeds are for 8 threads, in kB/s.", "description": "This table compares the performance of incomplete autoregressive shuffle coding with different chunk sizes (16 and 200) against the SZIP algorithm.  It shows compression rates (bits per edge) and speeds (kB/s) for various graphs, using both Erd\u0151s-R\u00e9nyi (ER) and autoregressive P\u00f3lya urn (AP) models.  The results highlight the trade-off between compression rate and speed, and the effect of model choice. The standard deviations are also provided indicating the stability of the results.  The data was compressed using 8 threads.", "section": "6 Experiments"}, {"figure_path": "m2DaXpCoIi/tables/tables_25_1.jpg", "caption": "Table 10: Incomplete joint shuffle coding with the autoregressive P\u00f3lya urn model (AP), compared to just ordered AP, on SZIP and REC graphs. We report mean net rates and compression speeds based on 10 compression runs (100 for SZIP graphs) with varying initial message seeds. All net rates are in bits per edge, with empirical standard deviations below 0.02 bits per edge except where shown. Single-threaded and multi-threaded compression speeds with 8 logical cores are reported, all in MB/s.", "description": "This table compares the performance of incomplete joint shuffle coding using the autoregressive P\u00f3lya urn model (AP) against a baseline of just using the ordered AP model.  The data used are SZIP and REC graphs.  The table presents mean net rates (bits per edge) and compression speeds (MB/s) for both single and multi-threaded processing.  Standard deviations are included, showing low variability in the results.", "section": "H Autoregressive graph shuffle coding results"}, {"figure_path": "m2DaXpCoIi/tables/tables_25_2.jpg", "caption": "Table 13: Compression rates and speeds of incomplete autoregressive shuffle coding with 16 chunks and 3 color refinement convolutions based on the AP model, on random graphs sampled from G(n, m) Erd\u0151s-R\u00e9nyi models with large numbers of edges m up to one billion, and n = 3/10 \u00b7 m vertices. We show the uncompressed size, meaning the ordered rate for the model it was sampled from, both in megabytes total and bits per edge. Rates and net rates are reported in bits per edge, and multi-threaded compression speeds in MB/s.", "description": "This table presents the results of applying incomplete autoregressive shuffle coding to large Erd\u0151s-R\u00e9nyi random graphs with up to one billion edges.  It compares the compression rates (bits per edge) and speeds (MB/s) achieved with this method to the uncompressed size of the graphs. The results showcase the effectiveness of the method on massive graph datasets.", "section": "6 Experiments"}]