[{"type": "text", "text": "When is an Embedder More Promising than Another? ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "\u2020Maxime DARRIN1,2,3,4 \u2020Philippe FORMONT1,2,4,5 Ismail BEN AYED1,5 Jackie Chi Kit CHEUNG2,3 Pablo PIANTANIDA1,2,4,6 ", "page_idx": 0}, {"type": "text", "text": "1International Laboratory on Learning Systems, 2Mila - Quebec AI Institute, 3McGill University 4Universit\u00e9 Paris-Saclay, 5\u00c9TS Montr\u00e9al, 6CNRS, CentraleSup\u00e9lec, \u2020equal contribution maxime.darrin@mila.quebec, philippe.formont@mila.quebec ", "page_idx": 0}, {"type": "text", "text": "Abstract ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Embedders play a central role in machine learning, projecting any object into numerical representations that can, in turn, be leveraged to perform various downstream tasks. The evaluation of embedding models typically depends on domain-specific empirical approaches utilizing downstream tasks, primarily because of the lack of a standardized framework for comparison. However, acquiring adequately large and representative datasets for conducting these assessments is not always viable and can prove to be prohibitively expensive and time-consuming. In this paper, we present a unified approach to evaluate embedders. First, we establish theoretical foundations for comparing embedding models, drawing upon the concepts of sufficiency and informativeness. We then leverage these concepts to devise a tractable comparison criterion (information sufficiency), leading to a task-agnostic and self-supervised ranking procedure. We demonstrate experimentally that our approach aligns closely with the capability of embedding models to facilitate various downstream tasks in both natural language processing and molecular biology. This effectively offers practitioners a valuable tool for prioritizing model trials.1 ", "page_idx": 0}, {"type": "text", "text": "1 Introduction ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Embeddings are a prominent tool in machine learning and are used in multiple fields, such as natural language processing [64, 83], computer vision [93, 59, 12, 53] or bioinformatics [67, 3, 23, 112]. These models embed objects such as images, texts, or molecules into numerical representations that can be used to perform numerous downstream tasks by preserving key features of the object [76, 111]. ", "page_idx": 0}, {"type": "text", "text": "Depending on the data modalities, intended purpose, and available resources, embedders showcase a wide variety of architectures, training settings (unsupervised, supervised, self-supervised, etc.), objectives (masked language modeling, contrastive learning, etc.) [20, 100, 78, 112, 39], and datasets [65, 86, 31, 38, 5, 117]. And more recently, foundation models have become a natural starting point to create embedders [21, 106, 52, 73]. ", "page_idx": 0}, {"type": "text", "text": "This diversity and variety of options makes selecting the most promising embedders for a data distribution challenging [75]. Most work evaluates embedders focusing on the performance they enable on a finite set of downstream tasks [85, 17, 90, 91, 81, 24]. Nevertheless, this evaluation process encounters two primary limitations. Firstly, it is not scalable concerning the number of embedders and tasks, as it requires ftiting a downstream model for each task. Hence, prioritizing the evaluation of the most promising models becomes essential to mitigate computational costs. Secondly, acquiring high-quality labels can be a time-consuming and notably expensive endeavor in various applications. To overcome these limitations, in this paper, we explore task-agnostic evaluation metrics for embedders relying solely on pairwise comparisons between embedders, i.e., without the need for labeled data in downstream tasks. ", "page_idx": 0}, {"type": "text", "text": "", "page_idx": 1}, {"type": "text", "text": "More specifically, our contributions can be summarized as follows: ", "page_idx": 1}, {"type": "text", "text": "1. An innovative theoretical framework for comparing embedding models: We cast the problem of ranking embedders into the noisy communication channels ordering (Sec. 2.2) and statistical experiments comparison settings (Sec. 2.3). We exploit the notions of sufficiency and informativeness and relax them, leveraging the concept of deficiency introduced by Le Cam [63] (Sec. 2.4), which is reframed to account for concepts and features. These concepts provide us with tools to establish an embedder ranking.   \n2. A practical relaxation: Estimating deficiency presents significant challenges. We propose the concept of information sufficiency (IS), which quantifies the information required to simulate one embedder from another (Sec. 3). We estimate the information efficiency to get a task-agnostic and label-free comparison tool for embedders evaluation.   \n3. Extensive experimental validation: The expected IS correlates with the ability of embedders to enable a wide range of downstream tasks. In NLP (Sec. 5) and molecular modeling (Sec. 6), our method respectively achieves Spearman ranking correlations of 0.90 (56 tasks) and 0.94 (31 tasks); providing an efficient model trial prioritization tool for practitioners. ", "page_idx": 1}, {"type": "text", "text": "1.1 Related works ", "text_level": 1, "page_idx": 1}, {"type": "text", "text": "Embedding evaluation. Embedding evaluation is mainly performed based on a limited set of downstream tasks [22, 91, 81, 24], for which the embeddings are used as inputs to smaller models. Therefore, embedders evaluation is field- and task-specific. In NLP, [41, 85] they rely on a limited set of tasks; more recently, the Massive Text Embedding Benchmark (MTEB) [75] followed this task-oriented trend and offered standardized test bed for embedders encompassing various downstream tasks in NP. Devising statistical tests to compare models and learning algorithms has a long history [30]. However, most works propose statistical tests relying on the performance of the downstream tasks of interests [60, 11]. Other works study the expressiveness of embedders and connect it to performance on downstream tasks [107, 25], but mostly focus on geometrical properties of the high dimensional representation in self-supervised learning settings [2, 42, 45]. ", "page_idx": 1}, {"type": "text", "text": "Probing. While probing methods do not aim at comparing embedders, they evaluate their representations to discover what these models have learned. They train small models on the internal representations of large models to perform specific downstream tasks. These procedures allow researchers to assess what information is present and recoverable from these embeddings [10, 1, 88, 84]. Other work proposed measuring mutual information (MI) between internal representations and labels. It has been used to evaluate the difficulty of a dataset as the predictiveness of the labels using the features [35]. For instance, [97] evaluates the utility of representations in astrophysics to predict physical properties. Following this trend, [54] leverages the point-wise MI between Gaussian distributions to evaluate text-to-images and image-to-text generative models. However, none of these methods have focused on comparing embedders in the general case to the best of our knowledge. ", "page_idx": 1}, {"type": "text", "text": "2 Theoretical Foundations for Comparing Embedding Models ", "text_level": 1, "page_idx": 1}, {"type": "text", "text": "2.1 Background and notation ", "text_level": 1, "page_idx": 1}, {"type": "text", "text": "We assume that all considered spaces are standard Borel [28] Each such space $\\mathsf{U}$ is equipped with its Borel $\\sigma$ -algebra $B(\\cup)$ . The set of all probability measures on $\\mathsf{U}$ is denoted by $\\mathcal{P}(\\cup)$ The total variation distance between $P$ and $Q$ is denoted by $\\|P-\\dot{Q}\\|_{\\mathrm{TV}}$ . Given a joint probability measure $P_{X Y}$ induced by two random variables $X\\in\\mathsf X$ and $U\\in\\mathsf{U}$ , the Mutual Information [27] is denoted by $I(X;U)$ . A Markov (or transition probability) kernel between $\\mathsf{X}$ and $\\mathsf{U}$ is a mapping $P_{U|X}:B(\\mathsf{U})\\times\\dot{\\mathsf{X}}\\to[0,1]$ . The space of all such $P_{U|X}$ is denoted by $\\kappa(\\mathsf{U}|\\mathsf{X})$ and $(M\\circ P_{U|X})(V|x)$ indicates the composition of Markov kernels $M\\in\\mathcal{K}(\\mathsf{V}|\\mathsf{U})$ and $P_{U|X}\\in\\mathcal{K}(\\mathsf{U}|\\mathsf{X})$ . For further details, refer to Appendix A. ", "page_idx": 1}, {"type": "text", "text": "2.2 Sufficiency and informativeness ordering of embedding models ", "text_level": 1, "page_idx": 1}, {"type": "text", "text": "We aim to compare embedding models without relying on labeled data for downstream tasks. Let us consider two embedding models represented by their Markov kernels (or transition probabilities) ", "page_idx": 1}, {"type": "text", "text": "$P_{U|X}\\in\\mathcal{K}(\\mathsf{U}|\\mathsf{X})$ and $P_{V|X}\\in\\mathcal{K}(\\mathsf{V}|\\mathsf{X})$ , any target set Y of (discrete or continuous) concepts and feature space $\\mathsf{X}$ with joint probability measure $P_{Y X}\\,\\in\\,{\\mathcal{P}}(\\mathsf{Y}\\times\\mathsf{X})$ induced by random variables $(Y,X)\\in\\mathsf{Y}\\times\\mathsf{X}$ , as illustrated in Figure 1. First, we study the question: ", "page_idx": 2}, {"type": "image", "img_path": "VqFz7iTGcl/tmp/81fe5811de32643ad6f612439dad70f96c0bfe1b2366fa47d989cd329f9fdca0.jpg", "img_caption": ["What sufficient conditions must be met by the embedding model $U$ relative to $V$ to guarantee that $I(Y;U)\\geqslant I(Y;V)$ for all distributions $P_{Y X}$ ? ", "Figure 1: Communicating a concept $y\\in\\mathsf{Y}$ over two embedding models with prediction $\\rho_{V}(V)$ . "], "img_footnote": [], "page_idx": 2}, {"type": "text", "text": "From an information-theoretic perspective [27], the quality of an embedding model can be likened to the capacity of a noisy communication channel with an uncoded input (e.g., a text, a molecule...), where a downstream task of interest is performed at the output (the embedding) of the channel. Let $Y\\in\\mathsf{Y}$ represent the message (the source) to be communicated over both channels; $X$ represents the transmitted signal; and $P_{U|X}$ and $P_{V|X}$ the communication channels with outputs $U$ and $V$ , respectively. This process is illustrated ", "page_idx": 2}, {"type": "text", "text": "in Figure 1. It naturally satisfies the Markov chain $Y\\leftrightarrow X\\leftrightarrow(U,V)$ . A desirable property is that the embedding models $U$ and $V$ retain as much pertinent information as feasible to predict $Y$ . ", "page_idx": 2}, {"type": "text", "text": "We shall be interested in the underlying information relationships between those embedding models that can be interpreted as channel $U$ being \"more informative\" for communicating $Y$ than channel $V$ . The first attempt to introduce an ordering between communication channels appears in Shannon [94]. K\u00f6rner and Marton later introduced [57] the concepts of \"less noisy\" (or more informative) and \"degraded\" (or sufficiency) orderings between channels. ", "page_idx": 2}, {"type": "text", "text": "Definition 1 (Sufficiency and informativeness orderings [57]). Let $P_{U|X}$ and $P_{V|X}$ be two Markov kernels (embedding models). ", "page_idx": 2}, {"type": "text", "text": "\u2022 Sufficiency $U\\;\\succcurlyeq_{S}\\;\\;V$ . The embedding model $P_{U|X}$ is said to be \"sufficient\" for the embedding model $P_{U|X}$ (or $V$ to be degraded w.r.t. $\\boldsymbol{U}$ ) if and only if there exists another Markov kernel $M\\in\\mathcal{T}(\\mathsf{V}|\\mathsf{U})$ such that $\\mathbb{E}\\Vert M\\circ P_{U|X}-P_{V|X}\\Vert_{\\mathrm{TV}}=0$ , i.e. $V$ can be simulated from $U$ using $M$ without information loss). \u2022 More informative $U\\succcurlyeq_{I}V$ . The embedding model $P_{U|X}$ is said to be \"more informative\" (or less noisy) than $P_{V|X}$ if and only if the embedding models always satisfy the inequality ", "page_idx": 2}, {"type": "equation", "text": "$$\nI(Y;U)\\geqslant I(Y;V),\\quad\\forall P_{Y X}\\in{\\mathcal{P}}(\\forall\\times\\times).\n$$", "text_format": "latex", "page_idx": 2}, {"type": "text", "text": "Proposition 1 (Relationships of sufficiency and information). The following relationships hold: ", "page_idx": 2}, {"type": "text", "text": "(i) Sufficiency $\\Rightarrow{}$ informativeness. If the embedding model $P_{U|X}$ is sufficient for the embedding model $P_{V|X}$ , i.e. $U\\succcurlyeq S\\ V$ , then $U\\succcurlyeq_{I}V$ . However, Informativeness \u21cfsufficiency.   \n(ii) Informativeness $\\Rightarrow{}$ higher capacity to distinguish concepts. If the embedding model $P_{U|X}$ is more informative than embedding model $P_{V|X}$ , i.e. $U\\succcurlyeq_{I}V$ , then ", "page_idx": 2}, {"type": "equation", "text": "$$\nK L\\big(P_{U|Y}(\\cdot|y_{0})\\|P_{U|Y}(\\cdot|y_{1})\\big)\\geqslant K L\\big(P_{V|Y}(\\cdot|y_{0})\\|P_{V|Y}(\\cdot|y_{1})\\big),\n$$", "text_format": "latex", "page_idx": 2}, {"type": "text", "text": "Remark 1. An immediate consequence of claim (i) is that the sufficient condition between embedding models implies that the embedding model $U$ is more informative than the embedding model $V$ relative to all target concepts in $\\textsf{Y}$ over all possible data distributions: $I(Y;U)\\geqslant I(Y;V)$ , for all probability distributions $P_{Y X}$ . ", "page_idx": 2}, {"type": "text", "text": "Although $U$ being more informative than $V$ does not necessarily imply $U\\succcurlyeq_{S}V$ [57, 66]; (ii) states that being more informative ensures a higher statistical discrimination capacity between any pairs of target concepts (for further discussion, see Sec. B.2). ", "page_idx": 2}, {"type": "text", "text": "Motivated by the concepts of sufficiency and informativeness between embedding models, we can inquire about their statistical consequences for a learner conducting an inference task on these embeddings. More precisely, given a finite set of concepts Y, if $U\\succcurlyeq S\\ V$ , is the Bayes risk expected to be smaller when the inference is based on $U$ than when it is based on $V^{\\bullet}$ ", "page_idx": 2}, {"type": "text", "text": "2.3 Comparing statistical experiments with embedding Models ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "The pursuit of comparing statistical experiments originated from the seminal paper by Bohnenblust, Shapley, and Sherman [16], followed by subsequent contributions by Blackwell [13, 14]. They formally established the relationships between sufficiency (Def. 1) and inference procedures. ", "page_idx": 3}, {"type": "text", "text": "In our framework, a statistical experiment [13] consists of a mathematical abstraction (see Appendix A for further details) intended to represent a downstream task where a learner aims at inferring a concept $y\\in\\mathsf{Y}$ from the embeddings $U$ or $V$ . Deciding what embedder should be used to perform a given task is too general. In this work, we do not take into account the computational cost or the size of an embedder and solely focus on the following question: ", "page_idx": 3}, {"type": "text", "text": "What are the necessary and sufficient conditions that ensure that employing the embedding $U$ for any task $P_{Y X}$ leads to lower risk compared to using the embedding $V$ ? ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "Drawing parallels with the theoretical framework established for comparing statistical experiments, a relationship can be derived between the concept of sufficiency and the expected risk for a specific task (see Sec. B.5 for further discussion). ", "page_idx": 3}, {"type": "text", "text": "We concentrate on the scenario where Y consists of a finite number of concepts (e.g., classification tasks), as it is a significant case in its own right [104] and provide fundamental insights for the present work. The next Proposition states an important relation between the concept of sufficiency and the expected Bayes risk on any classification task. ", "page_idx": 3}, {"type": "text", "text": "Proposition 2 (Comparison of embedding models through Bayes risks). Given two embedding models $P_{U|X}\\in\\mathcal{K}(\\mathsf{U}|\\mathsf{X})$ and $P_{V|X}\\in K(\\mathsf{V}|\\mathsf{X})$ , the following statements are equivalent: ", "page_idx": 3}, {"type": "text", "text": "(i) The embedding model $P_{U|X}$ is sufficient relative to $P_{V|X}$ , i.e. $U\\succcurlyeq s\\ V$ . ", "page_idx": 3}, {"type": "text", "text": "(ii) For all conditional probability measures $P_{Y\\mid X}$ on finite alphabet Y, the Bayes risks satisfy ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\operatorname*{inf}_{\\rho_{U}:{\\mathsf{U}}\\to{\\mathcal{P}}(\\mathsf{Y})}\\operatorname*{Pr}\\left({\\hat{Y}}_{U}\\neq Y\\right)\\leqslant\\operatorname*{inf}_{\\rho_{V}:\\mathsf{V}\\to{\\mathcal{P}}(\\mathsf{Y})}\\operatorname*{Pr}\\left({\\hat{Y}}_{V}\\neq Y\\right),\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "where $\\hat{Y}_{U}$ and $\\hat{Y}_{V}$ are distributed according to $\\rho_{U}(U)$ and $\\rho_{V}(V)$ , respectively. ", "page_idx": 3}, {"type": "text", "text": "Remark 2. In other words, if we can fully simulate an embedder $V$ from another embedder $U$ , the expected risk across all potential classification tasks cannot be greater when using $U$ compared to $V$ . The proof of this Proposition is given in Sec. B.3. It is worth mentioning that various versions of this result are available in the literature [104]. However, our extension here, in a simpler setting, incorporates concepts and features into the experiment comparison framework. ", "page_idx": 3}, {"type": "text", "text": "2.4 Challenges in ranking embedding models and their deficiency ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "According to the notion of \"sufficiency\", we can distinguish the three following possibilities: ", "page_idx": 3}, {"type": "text", "text": "\u2022 Equivalence: $U\\succcurlyeq s V$ and $V\\succcurlyeq s U$ denoted $U\\approx V$ ; $U$ and $V$ can simulate each other.   \n\u2022 Comparability: $U\\succcurlyeq S\\ V$ but $V\\not\\approx_{S}U$ only $V$ can be simulated from $U$ .   \n\u2022 Non-comparability: $U\\not\\approx_{S}V$ and $V\\not\\approx_{S}U$ , neither $U$ nor $V$ can simulate each other. ", "page_idx": 3}, {"type": "text", "text": "Our results up to now only account for the two first possibilities. However, two embedders are generally not comparable (Sec. B.4). This issue was addressed by Le Cam [63], who introduced the notion of \"deficiency\". ", "page_idx": 3}, {"type": "text", "text": "Definition 2. The deficiency $\\delta(P_{U|X}\\to P_{V|X})$ of $P_{V|X}$ relative to $P_{U|X}$ is defined as [63] ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\delta(P_{U|X}\\to P_{V|X})\\triangleq\\operatorname*{inf}_{M\\in K(\\mathsf{V}|\\mathsf{U})}\\mathbb{E}\\|M\\circ P_{U|X}-P_{V|X}\\|_{\\mathsf{T V}},\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "where the infimum is taken over all Markov kernels (or transition probabilities) $M\\,\\in\\,\\mathcal{K}(\\mathsf{V}|\\mathsf{U})$ , mapping stochastically U and $\\vee$ , and $\\delta$ measures error between the simulated and true embedders. ", "page_idx": 3}, {"type": "text", "text": "$\\delta$ indicates how well one model can be reconstructed from the other, it induces a natural relaxation of the sufficiency where the reconstruction does not have to be perfect2 for us to obtain guarantees on the downstream tasks performance (See Corollary 1). It avoids the non-comparability problem by evaluating \"how much information\" we lose when passing from one model to the other one. ", "page_idx": 3}, {"type": "text", "text": "", "page_idx": 4}, {"type": "text", "text": "Le Cam [63] showed that, for a given task $Y$ , the deficiency $\\delta(P_{U|Y}\\to P_{V|Y})$ is directly related to the expected Bayes risks on the task (see Sec. B.6). We extend this result to the comparison of two embedding models $P_{U|X}$ and $P_{V|X}$ in a task-agnostic manner and build the relation to the expected Bayes risks for any classification task $Y$ . ", "page_idx": 4}, {"type": "text", "text": "Corollary 1. Given two embedding models $P_{U|X}$ and $P_{V|X}$ satisfying: ", "page_idx": 4}, {"type": "text", "text": "(i) The deficiency $\\delta(P_{U|X}\\to P_{V|X})\\leqslant\\gamma.$ . (ii) For any conditional distribution $P_{Y\\mid X}$ on finite alphabets Y, ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\operatorname*{inf}_{\\rho_{U}:\\mathfrak{U}\\to\\mathcal{P}(\\Upsilon)}\\operatorname*{Pr}\\left(\\hat{Y}_{U}\\neq Y\\right)-\\varepsilon\\leqslant\\operatorname*{inf}_{\\rho_{V}:\\forall\\rightarrow\\mathcal{P}(\\Upsilon)}\\operatorname*{Pr}\\left(\\hat{Y}_{V}\\neq Y\\right).\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "Statement (ii) implies $(i)$ provided that $\\gamma\\geqslant2|\\mathsf{Y}|\\varepsilon$ and conversely, $(i)$ implies (ii) provided that $\\gamma\\leqslant\\varepsilon$ ", "page_idx": 4}, {"type": "text", "text": "The proof of this Corollary is relegated to Sec. B.3. ", "page_idx": 4}, {"type": "text", "text": "Remark 3. In particular, we can infer that for any classification task $Y$ , the expected Bayes risk of the embedding model $U$ , denoted by ${\\mathcal{R}}_{U}$ , is upper bounded by the expected Bayes risk of the embedding model $V$ , denoted by ${\\mathcal{R}}_{V}$ : ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\mathcal{R}_{U}-\\mathcal{R}_{V}\\leqslant\\delta(P_{U|X}\\rightarrow P_{V|X}),\\quad\\mathrm{for~all~conditional~distributions~}P_{Y|X},\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "and similarly, $\\begin{array}{r}{|\\mathcal{R}_{U}-\\mathcal{R}_{V}|\\,\\leqslant\\,\\operatorname*{max}\\big\\{\\delta(P_{U|X}\\,\\rightarrow\\,P_{V|X}),\\delta(P_{V|X}\\,\\rightarrow\\,P_{U|X})\\big\\}.}\\end{array}$ , for all conditional distributions $P_{Y\\mid X}$ . If both deficiencies are small, the resulting expected Bayes risks of the embedding models $U$ and $V$ will be close to each other for any target task $Y$ . ", "page_idx": 4}, {"type": "text", "text": "3 Quantifying Information Sufficiency Between Embedding Models ", "text_level": 1, "page_idx": 4}, {"type": "text", "text": "We want to compare embedding models using the concept of deficiency, leveraging Prop. 2 and Corollary 1. These propositions suggest that the performance on any classification task of an embedding model $U$ relative to the model $V$ is bounded by $\\delta(P_{U|X}\\to P_{V|X})$ . However, estimating the deficiency from data samples is notably challenging [95], and while upper bounds derivation exists, they do not necessarily make it tractable. ", "page_idx": 4}, {"type": "text", "text": "3.1 Estimating Information Sufficiency ", "text_level": 1, "page_idx": 4}, {"type": "text", "text": "The deficiency $\\delta\\big(P_{U|X}\\to P_{V|X}\\big)$ between two embedding models $P_{U|X}$ and $P_{V|X}$ , measures how well $U$ can be used to simulate $V$ using a Markov kernel $M\\in\\mathcal{K}(\\mathsf{V}|\\mathsf{U})$ . This section aims to build a tractable proxy for this reconstruction cost. To this end, we estimate how much we can reduce the uncertainty about $Z$ by observing $U$ by learning an appropriate Markov kernel. This corresponds to the information sufficiency [29, 4] and can be interpreted as the information-theoretic counterpart of the deficiency. The information deficiency between $U$ and $V$ is then defined as: ", "page_idx": 4}, {"type": "text", "text": "Definition 3 (Information sufficiency). The information sufficiency ${\\mathcal{T}}_{S}(U\\to V)$ , relative to parametric classes of distributions ${\\mathcal{F}}_{\\Theta}(\\vee)$ and $\\kappa_{\\Theta}(\\vee|\\cup)$ (multivariate Gaussian mixtures [82]) is defined: ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\mathcal{Z}_{S}(U\\to V)\\triangleq\\operatorname*{inf}_{f\\in\\mathcal{F}_{\\Theta}(\\vee)}\\mathbb{E}\\left[-\\log f(V)\\right]-\\mathbb{E}\\left[\\operatorname*{inf}_{M\\in K_{\\Theta}(\\vee|\\cup)}\\mathbb{E}\\left[-\\log M(V|U)|U\\right]\\right].\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "Remark 4. When the information sufficiency ${\\mathcal{Z}}_{S}(U\\ \\to\\ V)$ is large, it signifies that $U$ offers a substantial amount of information to simulate $V$ , a proxy for a small deficiency. Conversely, when ${\\mathcal{T}}_{S}(U\\to V)$ is lower, it implies that the channel $P_{V|Y}$ is subject to considerable noise or randomness, leading to a greater loss of statistical information. ", "page_idx": 4}, {"type": "text", "text": "We hence attempt to simulate $V$ from $U$ by learning a Markov kernel $M\\in\\mathcal{K}_{\\Theta}(\\mathsf{V}|\\mathsf{U})$ , via a mixture of multivariate Gaussians, and measure the uncertainty reduction it induces. ", "page_idx": 4}, {"type": "image", "img_path": "VqFz7iTGcl/tmp/aaa3464b82400ed39061b1e96337c44ecbed3704133fdfbb8eb549c3aabbe417.jpg", "img_caption": [], "img_footnote": [], "page_idx": 5}, {"type": "text", "text": "Figure 2: Pairwise $\\mathcal{T}_{S}$ for text embedders. ", "page_idx": 5}, {"type": "text", "text": "Pairwise embedder evaluation. For set of embbeders $(Z_{k})_{k}$ represented by their Markov kernels $\\{P_{Z_{k}|X}\\}_{k}$ , we compute the pairwise information sufficiency $\\mathcal{T}_{S}(Z_{k}\\,\\rightarrow\\,Z_{l})$ . The pairwise information sufficiency matrix defines the adjacency matrix of a directed graph of embedders (Figure 2). Corollary 1 shows that embedders sharing high information sufficiency are expected to perform similarly on any downstream tasks, motivating the identification of communities in the graph. While the graph construction is in $\\mathcal{O}(N^{2})$ ; where $N$ is the number of embedders, it is in practice tractable for a reasonable number of embedders (refer to Sec. E.6) for more details). ", "page_idx": 5}, {"type": "text", "text": "Practical embedding evaluation. We construct the set of all information sufficiency using $Z_{k}$ : ${\\cal S}_{\\mathcal{T}_{S}}\\left(k\\right)=\\left\\{\\mathcal{T}_{S}(Z_{k}\\rightarrow Z_{l})\\right\\}_{l\\neq k}$ . We build our information sufficiency score $\\overline{{\\mathcal{T}_{S}}}$ score) by taking the median of $S_{\\mathrm{{Z}}s}\\left(k\\right)$ . Details on the $\\overline{{\\mathcal{T}_{S}}}$ score\u2019s estimation can be found in Sec. E.1. ", "page_idx": 5}, {"type": "text", "text": "4 Experimental Setup ", "text_level": 1, "page_idx": 5}, {"type": "text", "text": "We aim to evaluate the practical utility of the $\\overline{{\\mathcal{T}_{S}}}$ score to rank and select the best embedders for a given data distribution. We compare this ranking to those obtained on various downstream tasks. Our experimental protocol is divided into three main steps: ", "page_idx": 5}, {"type": "text", "text": "1. We evaluate the $\\overline{{\\mathcal{T}_{S}}}$ score of the models by identifying a large and diverse dataset that is supposed to be representative of the data distribution of interest.   \n2. We train a small feedforward neural network $(\\rho_{Z_{k}})$ per embedder $P_{Z_{k}|X}$ to perform each downstream task and record its performances ( $R^{2}$ score for regression, AUROC/accuracy for binary/multiclass classification).   \n3. We compare the models\u2019 performances on the downstream tasks and the $\\overline{{\\mathcal{T}_{S}}}$ score by measuring three types of correlations: the Pearson correlation, the Spearman correlation, and the Kendall-Tau coefficient.3(See Sec. E.5 for additional baselines). ", "page_idx": 5}, {"type": "table", "img_path": "VqFz7iTGcl/tmp/4cfa75fbb4a1a83760c7c6dff44df974376881bc2c7ec47182ef294909c4ea9f.jpg", "table_caption": [], "table_footnote": [], "page_idx": 5}, {"type": "image", "img_path": "VqFz7iTGcl/tmp/dd33f8e7707000f206ff0d153d7885c7fbd989b44a70134371457fc71df9c175.jpg", "img_caption": ["(a) NLP ", "Figure 3: Correlation between $\\overline{{\\mathcal{T}_{S}}}$ scores and downstream task performances in (a) NLP and (b) Molecular Modelling. $\\varrho_{p}$ is the Pearson correlation, $\\varrho_{s}$ the spearman correlation, and $\\tau$ is the KendallTau coefficient. See Sec. C.3.1 for unaggregated results in NLP and Sec. D.3 in molecular modeling. ", "(c) NLP "], "img_footnote": [], "page_idx": 5}, {"type": "table", "img_path": "VqFz7iTGcl/tmp/90ad473d85b8ed06e346e8b09c7f99898451c3fcdebbf4385a840a0f178c11f5.jpg", "table_caption": [], "table_footnote": [], "page_idx": 5}, {"type": "image", "img_path": "VqFz7iTGcl/tmp/ff691b1ea257266f5dab4b57e681a9196fcdd4ce02e06abf7fe021e3f568aa1d.jpg", "img_caption": ["(b) Molecular Modelling ", "(d) Molecular Modeling "], "img_footnote": [], "page_idx": 5}, {"type": "text", "text": "5 Text Embeddings Evaluation ", "text_level": 1, "page_idx": 6}, {"type": "text", "text": "5.1 Experimental setting ", "text_level": 1, "page_idx": 6}, {"type": "text", "text": "Embedders & Datasets. We compared 34 models with different training objectives, training datasets, and architectures. We included embedders derived from modern LLM such as LLaMA [106], Mistral [52], Gemma [102], Croissant [37] and T5 encoders [77]; common embedders derived from BERT architectures [31, 38, 85] or RobERTa [41] and embedders trained on specific embeddings objectives such Angle [64], Stella4, E5 models [113], LaBSE [38]. A comprehensive list of the models can be found in Sec. C.1, Tab. 1 with their main characteristics and links to the Huggingface Hub for reproducibility. We used them to extract embeddings for many different datasets from the MTEB benchmark such as Banking77 [19], Sickr [122], Amazon polarity [72], SNLI [120] and IMDB [70]. We provide the datasets statistics in Sec. C.1, Tab. 2. ", "page_idx": 6}, {"type": "text", "text": "Downstream tasks evaluation. We rely on the results released on the MTEB leaderboard5 and compare our rankings to the rankings and scores obtained by the different models on the different tasks. We evaluate additional tasks that are not included in the MTEB benchmark, such as tweet_eval [8, 74, 7, 109, 9], DAIR Emotion [92], agnews topic classification [123], Clinc intent detection [62] PAWS-X [118] and Rotten Tomatoes [79]. ", "page_idx": 6}, {"type": "image", "img_path": "VqFz7iTGcl/tmp/b62d47b7c2dbc454d25de9b510009c38d1f0962a55e526afaa09a8369eeb7354.jpg", "img_caption": ["5.2 Model\u2019s Information Sufficiency analysis "], "img_footnote": ["Figure 4: Figure 4a, presents the information sufficiency directed graph and the induced communities. Figure 4b displays the performance on additional downstream tasks and models not evaluated in the MTEB leaderboard. Figure 4c shows that instruction finetuning positively impacts the models\u2019 performance on the downstream tasks and that this improvement is captured by $\\overline{{\\mathcal{T}_{S}}}$ . "], "page_idx": 6}, {"type": "text", "text": "Correlation with downstream tasks performance. The MTEB Benchmark offers a natural starting point to compare models\u2019 ranking according to their performance on downstream tasks and their $\\overline{{\\mathcal{T}_{S}}}$ score. In Figure 3c, we show that the $\\overline{{\\mathcal{T}_{S}}}$ score of an embedder correlates positively with its performance on a wide range of downstream tasks, from classification and similarity tasks to retrieval and clustering tasks. Overall, our $\\overline{{\\mathcal{T}_{S}}}$ score correlates strongly with MTEB\u2019s average score (Spearman correlation of 0.90 and a Pearson correlation of 0.94, see Figure 3c) and with the subtask performance Figure 3a). We extended our experiments to a more extensive set of models not included in the MTEB benchmark and observed a similar trend (Figure 4b). Per-datasets results are reported in Sec. C.3.1 and ablations in Sec. C.3.2. All our results show that our estimation of the information sufficiency between models is a good proxy for the performance of the models on a wide range of tasks. ", "page_idx": 6}, {"type": "text", "text": "", "page_idx": 7}, {"type": "text", "text": "Embedder communities. The pair-wise information sufficiency evaluation between the models can be used to cluster them into communities [15](Figure 4a, Figure 2)6. We observe that the extracted clusters group together models that are similar in their training objectives and architectures. LLM-based models such as LLaMA, Mistral, Gemma, and Croissant are clustered together, while BERT-based models share another cluster. Similarly, models trained specifically for embedding purposes, such as UAE-Large-V1 and ember-v1, are grouped together. This suggests that the ordering induced by information sufficiency is meaningful and can be used to identify models with similar properties and behaviors. Consistently with Corollary 1, we observe that the performance of the models on the downstream tasks is similar within the same cluster (Figure C.3.5). In addition, we found that it captures improvements by both steps of pretraining and instruction fine-tuning (Figure 4c, Sec. C.3.2) ", "page_idx": 7}, {"type": "text", "text": "6 Molecular Modeling ", "text_level": 1, "page_idx": 7}, {"type": "text", "text": "6.1 Experimental setting ", "text_level": 1, "page_idx": 7}, {"type": "text", "text": "Embedders. To process molecular data, embedders can leverage different representations of the molecules, providing an interesting benchmark to evaluate the $\\overline{{\\mathcal{T}_{S}}}$ score. We evaluated models derived from the molecular representation learning literature, summed up in Sec. D.1. We considered various input modalities such as string representations (SMILES [114], SELFIES [58]), 2D-graphs by using graph neural networks (GNNs), and 3D-representations (using the TorchMD-net architecture [80]). We added a randomly initialized baseline GNN model that was not trained on any dataset. ", "page_idx": 7}, {"type": "text", "text": "Datasets. To evaluate the information sufficiency between embedders, we compared the models on the ZINC 250k dataset[50], designed to gather compounds that could be relevant to a wide range of therapeutic projects. This dataset contains $250\\mathrm{k}$ commercially available compounds meant to be used in diverse therapeutic projects. ", "page_idx": 7}, {"type": "text", "text": "Downstream tasks. We evaluated the embedders on 31 downstream tasks extracted from the Therapeutic Data Commons [49] platform. This section focuses on ADMET tasks (Absorption, Distribution, Metabolism, Excretion, and Toxicity). Results on Drug-Target interaction tasks can be found in Sec. D.4. Datasets collected are split into a training, validation, and test set, following the scaffold-split strategy, further described in see Sec. D.3. ", "page_idx": 7}, {"type": "text", "text": "6.2 Model\u2019s Information Sufficiency analysis ", "text_level": 1, "page_idx": 7}, {"type": "text", "text": "Global results. The $\\overline{{\\mathcal{T}_{S}}}$ score ranking is consistent with the results of the embedders on the ADMET downstream tasks, achieving a Spearman correlation of 0.95 and a Kendall-tau coefficient of 0.80, as reported in Figure 3d. Detailed results for each of the 31 tasks are available in Sec. D.3 in Tab. 6. Table 3b shows the correlation between the $\\overline{{\\mathcal{T}_{S}}}$ score rankings and the performances obtained on the ADMET tasks within each category. High correlations are achieved within most task categories, especially when large tasks are available (containing an important number of molecules). On excretion tasks, the correlation is lower (below 0.8), which can be explained by the fact that these tasks are the most challenging regression tasks available, where the fine-tuned models reach the lowest $R^{2}$ scores between 0 and 0.2 (see Sec. D.3). ", "page_idx": 7}, {"type": "text", "text": "Most / Least promising models. We observe in Figure 5b that the most promising models are the (Chem)Bert-MTR models[3]7 and MolR[112], the former trained on SMILES representations to predict a variety of computationally available molecular properties, and the latter trained on 2D graphs to preserve equivalence of molecules w.r.t chemical reactions. Surprisingly, these models share high predictive mutual information (being assigned to the same Louvain community in Figure 5a), suggesting that they capture similar information despite significant differences in their training methods. These models also appear to be the most competitive on the ADMET tasks. On the other hand, and consistently with Sun et al. [99]\u2019s observation, training methods for 2D-GNNs such as following attribute masking and context prediction objective are deemed as the least informative according to the $\\overline{{\\mathcal{T}_{S}}}$ score. This is explained by the simplicity of these pretraining objectives for this data modality. These methods are also among the least competitive methods on the ADMET downstream tasks. ", "page_idx": 7}, {"type": "image", "img_path": "VqFz7iTGcl/tmp/4190bddb19101167d83954d72d00ec49e71906501d93aee461396f54143d4a60.jpg", "img_caption": ["Figure 5: (a) Pairwise information sufficiency graph between the embedders. The center color represents the ability to simulate other models, while the surrounding colors represent the ability to be simulated by other models. Red indicates a high ability to simulate or be simulated, while blue indicates a low ability. (b) Mean rank of the models (ordered by $\\overline{{\\mathcal{T}_{S}}}$ score) on downstream tasks. "], "img_footnote": [], "page_idx": 8}, {"type": "text", "text": "", "page_idx": 8}, {"type": "text", "text": "NLP-inspired models. (Chem)Bert-MLM [3], MolBert [36] and (Chem)GPT[40] leverage masked language model objective applied to string representations (SMILES and SELFIES). Unsurprisingly, as seen in Figure 5a, these models are clustered, suggesting they capture similar information. However, they fail to simulate other models in the pool, resulting in low $\\overline{{\\mathcal{T}_{S}}}$ scores, a result consistent with the known limitations of these pretraining objectives [23, 105]. A noticeable exception is (Chem)GPT-1.2B (the biggest model of the pool by far), which displays a significantly higher $\\overline{{\\mathcal{T}_{S}}}$ score. ", "page_idx": 8}, {"type": "text", "text": "\"Not-trained\" GNN. Figure 5b helps visualize the performances of the different models relative to our baseline \"Not-trained\" GNN. Surprisingly, some models are ranked less promising than this baseline by the $\\overline{{\\mathcal{T}_{S}}}$ score. However, all of these less promising models obtain poorer performances on the downstream tasks. Similarly, except for InfoGraph [98], every model ranked more promising than the \"Not-trained\" GNN baseline and obtained better results on ADMET tasks. This surprising result validates evaluation of the $\\overline{{\\mathcal{T}_{S}}}$ score w.r.t this baseline. ", "page_idx": 8}, {"type": "text", "text": "7 Limitations and Conclusions ", "text_level": 1, "page_idx": 8}, {"type": "text", "text": "We proposed a principled approach to embedding model evaluation by framing model ranking as a variation of comparing statistical experiments. Utilizing concepts of sufficiency, informativeness, and deficiency, we developed mathematically grounded metrics for pairwise comparisons between embedders without relying on labeled data in downstream tasks. Our tractable relaxation, termed information sufficiency, demonstrated strong correlations with rankings based on downstream task performance in extensive experiments. Although successful, our method still has at least two primary limitations. First, its effectiveness depends on the number and diversity of available embedders (see Sec. E.4). Future work could explore using randomly initialized embedders (random projections) instead of pre-trained ones. Second, we can enhance our proxy for predicting the deficiency between models by exploring better methods (e.g., estimating the $f$ -divergence) to directly learn the Markov kernel that minimizes the total variation distance, which we leave for future research. ", "page_idx": 8}, {"type": "text", "text": "", "page_idx": 9}, {"type": "text", "text": "Acknowledgments ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "This work was granted access to the HPC resources of IDRIS under the allocation 2023- AD011013290R2 made by GENCI, and enabled by support provided by Calcul Quebec and the Digital Research Alliance of Canada. We warmly thank Heitor Rapela, Banafsheh Karimian, and Eric Aubinais for their advice and comments about our work. We also owe a special highlight to Lo\u00efc Fosse for the many discussions and hindsights he provided and for the subsequent follow-up projects. ", "page_idx": 9}, {"type": "text", "text": "References ", "text_level": 1, "page_idx": 10}, {"type": "text", "text": "[1] Yossi Adi, Einat Kermany, Yonatan Belinkov, Ofer Lavi, and Yoav Goldberg. Fine-grained analysis of sentence embeddings using auxiliary prediction tasks. In International Conference on Learning Representations. International Conference on Learning Representations, ICLR, 2017.   \n[2] Kumar K Agrawal, Arnab Kumar Mondal, Arna Ghosh, and Blake Richards. \\alpha-req : Assessing representation quality in self-supervised learning by measuring eigenspectrum decay. In S. Koyejo, S. Mohamed, A. Agarwal, D. Belgrave, K. Cho, and A. Oh, editors, Advances in Neural Information Processing Systems, volume 35, pages 17626\u201317638. Curran Associates, Inc., 2022.   \n[3] Walid Ahmad, Elana Simon, Seyone Chithrananda, Gabriel Grand, and Bharath Ramsundar. Chemberta-2: Towards chemical foundation models, 2022. [4] Suguru Arimoto. Information-theoretical considerations on estimation problems. Information and control, 19(3):181\u2013194, 1971. [5] Mahmoud Assran, Quentin Duval, Ishan Misra, Piotr Bojanowski, Pascal Vincent, Michael Rabbat, Yann LeCun, and Nicolas Ballas. Self-supervised learning from images with a joint-embedding predictive architecture, 2023.   \n[6] Simon Axelrod and Rafael G\u00f3mez-Bombarelli. Geom, energy-annotated molecular conformations for property prediction and molecular generation. Scientific Data, 9(1):185, 2022.   \n[7] Francesco Barbieri, Jose Camacho-Collados, Luis Espinosa-Anke, and Leonardo Neves. TweetEval:Unified Benchmark and Comparative Evaluation for Tweet Classification. In Proceedings of Findings of EMNLP, 2020. [8] Francesco Barbieri, Jose Camacho-Collados, Francesco Ronzano, Luis Espinosa-Anke, Miguel Ballesteros, Valerio Basile, Viviana Patti, and Horacio Saggion. Semeval 2018 task 2: Multilingual emoji prediction. In Proceedings of The 12th International Workshop on Semantic Evaluation, pages 24\u201333, 2018. [9] Valerio Basile, Cristina Bosco, Elisabetta Fersini, Debora Nozza, Viviana Patti, Francisco Manuel Rangel Pardo, Paolo Rosso, and Manuela Sanguinetti. SemEval-2019 task 5: Multilingual detection of hate speech against immigrants and women in Twitter. In Proceedings of the 13th International Workshop on Semantic Evaluation, pages 54\u201363, Minneapolis, Minnesota, USA, 2019. Association for Computational Linguistics.   \n[10] Yonatan Belinkov. Probing classifiers: Promises, shortcomings, and advances. Computational Linguistics, 48(1):207\u2013219, 2022.   \n[11] Alessio Benavoli, Giorgio Corani, Janez Demsar, and Marco Zaffalon. Time for a change: a tutorial for comparing multiple classifiers through bayesian analysis, 2017.   \n[12] Usha Bhalla, Alex Oesterling, Suraj Srinivas, Flavio P. Calmon, and Himabindu Lakkaraju. Interpreting clip with sparse linear concept embeddings (splice), 2024.   \n[13] David Blackwell. Comparison of experiments. In Proceedings of the second Berkeley symposium on mathematical statistics and probability, volume 2, pages 93\u2013103. University of California Press, 1951.   \n[14] David Blackwell. Equivalent comparisons of experiments. The Annals of Mathematical Statistics, 24(2):265\u2013272, 1953.   \n[15] Vincent D Blondel, Jean-Loup Guillaume, Renaud Lambiotte, and Etienne Lefebvre. Fast unfolding of communities in large networks. Journal of Statistical Mechanics: Theory and Experiment, 2008(10):P10008, oct 2008.   \n[16] H. Frederic Bohnenblust, Lloyd S. Shapley, and Seymour Sherman. Reconnaissance in game theory. 1949.   \n[17] Sebastian Borgeaud, Arthur Mensch, Jordan Hoffmann, Trevor Cai, Eliza Rutherford, Katie Millican, George van den Driessche, Jean-Baptiste Lespiau, Bogdan Damoc, Aidan Clark, Diego de Las Casas, Aurelia Guy, Jacob Menick, Roman Ring, Tom Hennigan, Saffron Huang, Loren Maggiore, Chris Jones, Albin Cassirer, Andy Brock, Michela Paganini, Geoffrey Irving, Oriol Vinyals, Simon Osindero, Karen Simonyan, Jack W. Rae, Erich Elsen, and Laurent Sifre. Improving language models by retrieving from trillions of tokens, 2022.   \n[18] Nathan Brown, Marco Fiscato, Marwin H.S. Segler, and Alain C. Vaucher. Guacamol: Benchmarking models for de novo molecular design. Journal of Chemical Information and Modeling, 59(3):1096\u20131108, March 2019.   \n[19] I\u00f1igo Casanueva, Tadas Temcinas, Daniela Gerz, Matthew Henderson, and Ivan Vulic. Efficient intent detection with dual sentence encoders. In Proceedings of the 2nd Workshop on NLP for ConvAI - ACL 2020, mar 2020. Data available at https://github.com/PolyAI-LDN/taskspecific-datasets.   \n[20] Wei-Cheng Chang, Felix X. Yu, Yin-Wen Chang, Yiming Yang, and Sanjiv Kumar. Pre-training tasks for embedding-based large-scale retrieval, 2020.   \n[21] Chang Che, Qunwei Lin, Xinyu Zhao, Jiaxin Huang, and Liqiang Yu. Enhancing multimodal understanding with clip-based image-to-text transformation, 2024.   \n[22] Yanqing Chen, Bryan Perozzi, Rami Al-Rfou, and Steven Skiena. The expressive power of word embeddings, 2013.   \n[23] Seyone Chithrananda, Gabriel Grand, and Bharath Ramsundar. Chemberta: Large-scale self-supervised pretraining for molecular property prediction, 2020.   \n[24] Hyunjin Choi, Judong Kim, Seongho Joe, and Youngjune Gwon. Evaluation of bert and albert sentence embedding performance on downstream nlp tasks, 2021.   \n[25] Ching-Yao Chuang, Antonio Torralba, and Stefanie Jegelka. The role of embedding complexity in domain-invariant representations, 2019.   \n[26] Gabriele Corso, Luca Cavalleri, Dominique Beaini, Pietro Li\u00f2, and Petar Velic\u02c7kovic\u00b4. Principal neighbourhood aggregation for graph nets. In Advances in Neural Information Processing Systems, 2020.   \n[27] T. M. Cover and J. A. Thomas. Elements of Information Theory. Wiley, New York, NY, 2nd edition, 2006.   \n[28] H. Crauel. Random Probability Measures on Polish Spaces. Taylor & Francis, 2002.   \n[29] Morris H DeGroot. Uncertainty, information, and sequential experiments. The Annals of Mathematical Statistics, 33(2):404\u2013419, 1962.   \n[30] Janez Dem\u0161ar. Statistical comparisons of classifiers over multiple data sets. The Journal of Machine learning research, 7:1\u201330, 2006.   \n[31] Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. Bert: Pre-training of deep bidirectional transformers for language understanding, 2019.   \n[32] Jian Du, Shanghang Zhang, Guanhang Wu, Jose M. F. Moura, and Soummya Kar. Topology adaptive graph convolutional networks, 2018.   \n[33] David Duvenaud, Dougal Maclaurin, Jorge Aguilera-Iparraguirre, Rafael G\u00f3mez-Bombarelli, Timothy Hirzel, Al\u00e1n Aspuru-Guzik, and Ryan P. Adams. Convolutional networks on graphs for learning molecular fingerprints, 2015.   \n[34] Peter Ertl and Ansgar Schuffenhauer. Estimation of synthetic accessibility score of drug-like molecules based on molecular complexity and fragment contributions. J. Cheminformatics, 1:8, 2009.   \n[35] Kawin Ethayarajh, Yejin Choi, and Swabha Swayamdipta. Understanding dataset difficulty with $\\nu$ -usable information, 2022.   \n[36] Benedek Fabian, Thomas Edlich, H\u00e9l\u00e9na Gaspar, Marwin Segler, Joshua Meyers, Marco Fiscato, and Mohamed Ahmed. Molecular representation learning with language models and domain-relevant auxiliary tasks, 2020.   \n[37] Manuel Faysse, Patrick Fernandes, Nuno M. Guerreiro, Ant\u00f3nio Loison, Duarte M. Alves, Caio Corro, Nicolas Boizard, Jo\u00e3o Alves, Ricardo Rei, Pedro H. Martins, Antoni Bigata Casademunt, Fran\u00e7ois Yvon, Andr\u00e9 F. T. Martins, Gautier Viaud, C\u00e9line Hudelot, and Pierre Colombo. Croissantllm: A truly bilingual french-english language model, 2024.   \n[38] Fangxiaoyu Feng, Yinfei Yang, Daniel Cer, Naveen Arivazhagan, and Wei Wang. Languageagnostic bert sentence embedding, 2022.   \n[39] Shikun Feng, Yuyan Ni, Yanyan Lan, Zhi-Ming Ma, and Wei-Ying Ma. Fractional denoising for 3D molecular pre-training. In Proceedings of the 40th International Conference on Machine Learning, volume 202 of Proceedings of Machine Learning Research, pages 9938\u20139961. PMLR, 23\u201329 Jul 2023.   \n[40] Nathan C. Frey, Ryan Soklaski, Simon Axelrod, Siddharth Samsi, Rafael G\u00f3mez-Bombarelli, Connor W. Coley, and Vijay Gadepally. Neural scaling of deep chemical models. Nature Machine Intelligence, 5(11):1297\u20131305, November 2023. Publisher: Nature Publishing Group.   \n[41] Tianyu Gao, Xingcheng Yao, and Danqi Chen. Simcse: Simple contrastive learning of sentence embeddings, 2022.   \n[42] Quentin Garrido, Randall Balestriero, Laurent Najman, and Yann Lecun. Rankme: Assessing the downstream performance of pretrained self-supervised representations by their rank, 2023.   \n[43] Aric Hagberg, Pieter Swart, and Daniel S Chult. Exploring network structure, dynamics, and function using networkx. Technical report, Los Alamos National Lab.(LANL), Los Alamos, NM (United States), 2008.   \n[44] William L. Hamilton, Rex Ying, and Jure Leskovec. Inductive representation learning on large graphs, 2018.   \n[45] Bobby He and Mete Ozay. Exploring the gap between collapsed; whitened features in selfsupervised learning. In Kamalika Chaudhuri, Stefanie Jegelka, Le Song, Csaba Szepesvari, Gang Niu, and Sivan Sabato, editors, Proceedings of the 39th International Conference on Machine Learning, volume 162 of Proceedings of Machine Learning Research, pages 8613\u20138634. PMLR, 17\u201323 Jul 2022.   \n[46] Weihua Hu, Matthias Fey, Hongyu Ren, Maho Nakata, Yuxiao Dong, and Jure Leskovec. Ogb-lsc: A large-scale challenge for machine learning on graphs, 2021.   \n[47] Weihua Hu, Matthias Fey, Marinka Zitnik, Yuxiao Dong, Hongyu Ren, Bowen Liu, Michele Catasta, and Jure Leskovec. Open graph benchmark: Datasets for machine learning on graphs. arXiv preprint arXiv:2005.00687, 2020.   \n[48] Ziniu Hu, Yuxiao Dong, Kuansan Wang, Kai-Wei Chang, and Yizhou Sun. Gpt-gnn: Generative pre-training of graph neural networks. In Proceedings of the 26th ACM SIGKDD Conference on Knowledge Discovery and Data Mining, 2020.   \n[49] Kexin Huang, Tianfan Fu, Wenhao Gao, Yue Zhao, Yusuf Roohani, Jure Leskovec, Connor W Coley, Cao Xiao, Jimeng Sun, and Marinka Zitnik. Therapeutics data commons: Machine learning datasets and tasks for drug discovery and development. Proceedings of Neural Information Processing Systems, NeurIPS Datasets and Benchmarks, 2021.   \n[50] John J. Irwin and Brian K. Shoichet. ZINC \u2013 A Free Database of Commercially Available Compounds for Virtual Screening. Journal of chemical information and modeling, 45(1):177\u2013 182, 2005.   \n[51] Clemens Isert, Kenneth Atz, Jos\u00e9 Jim\u00e9nez-Luna, and Gisbert Schneider. Qmugs: Quantum mechanical properties of drug-like molecules, 2021.   \n[52] Albert Q. Jiang, Alexandre Sablayrolles, Arthur Mensch, Chris Bamford, Devendra Singh Chaplot, Diego de las Casas, Florian Bressand, Gianna Lengyel, Guillaume Lample, Lucile Saulnier, L\u00e9lio Renard Lavaud, Marie-Anne Lachaux, Pierre Stock, Teven Le Scao, Thibaut Lavril, Thomas Wang, Timoth\u00e9e Lacroix, and William El Sayed. Mistral 7b, 2023.   \n[53] Apoorv Khandelwal, Luca Weihs, Roozbeh Mottaghi, and Aniruddha Kembhavi. Simple but effective: Clip embeddings for embodied ai, 2022.   \n[54] Jin-Hwa Kim, Yunji Kim, Jiyoung Lee, Kang Min Yoo, and Sang-Woo Lee. Mutual information divergence: A unified metric for multimodal generative models, 2022.   \n[55] Sunghwan Kim, Jie Chen, Tiejun Cheng, Asta Gindulyte, Jia He, Siqian He, Qingliang Li, Benjamin A Shoemaker, Paul A Thiessen, Bo Yu, Leonid Zaslavsky, Jian Zhang, and Evan E Bolton. PubChem 2023 update. Nucleic Acids Research, 51(D1):D1373\u2013D1380, 10 2022.   \n[56] Diederik P. Kingma and Jimmy Ba. Adam: A method for stochastic optimization, 2017.   \n[57] J. Korner and K. Marton. Comparison of two noisy channels, 1977.   \n[58] Mario Krenn, Florian H\u00e4se, AkshatKumar Nigam, Pascal Friederich, and Alan Aspuru-Guzik. Self-referencing embedded strings (selfies): A 100Machine Learning: Science and Technology, 1(4):045024, October 2020.   \n[59] Yugo Kubota, Daichi Haraguchi, and Seiichi Uchida. Impression-clip: Contrastive shapeimpression embedding for fonts, 2024.   \n[60] Alexandre Lacoste, Fran\u00e7ois Laviolette, and Mario Marchand. Bayesian comparison of machine learning algorithms on single and multiple datasets. In Artificial Intelligence and Statistics, pages 665\u2013675. PMLR, 2012.   \n[61] Greg Landrum, Paolo Tosco, Brian Kelley, sriniker, gedeck, NadineSchneider, Riccardo Vianello, Ric, Andrew Dalke, Brian Cole, AlexanderSavelyev, Matt Swain, Samo Turk, Dan N, Alain Vaucher, Eisuke Kawashima, Maciej W\u00f3jcikowski, Daniel Probst, guillaume godin, David Cosgrove, Axel Pahl, JP, Francois Berenger, strets123, JLVarjo, Noel O\u2019Boyle, Patrick Fuller, Jan Holst Jensen, Gianluca Sforna, and DoliathGavid. rdkit/rdkit: 2020_03_1 (Q1 2020) Release, March 2020.   \n[62] Stefan Larson, Anish Mahendran, Joseph J. Peper, Christopher Clarke, Andrew Lee, Parker Hill, Jonathan K. Kummerfeld, Kevin Leach, Michael A. Laurenzano, Lingjia Tang, and Jason Mars. An evaluation dataset for intent classification and out-of-scope prediction. In Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP), 2019.   \n[63] L Le. Sufficiency and approximate sufficiency. The Annals of Mathematical Statistics, pages 1419\u20131455, 1964.   \n[64] Xianming Li and Jing Li. Angle-optimized text embeddings, 2023.   \n[65] Zehan Li, Xin Zhang, Yanzhao Zhang, Dingkun Long, Pengjun Xie, and Meishan Zhang. Towards general text embeddings with multi-stage contrastive learning. arXiv preprint arXiv:2308.03281, 2023.   \n[66] Dennis V Lindley. On a measure of the information provided by an experiment. The Annals of Mathematical Statistics, 27(4):986\u20131005, 1956.   \n[67] Shengchao Liu, Hanchen Wang, Weiyang Liu, Joan Lasenby, Hongyu Guo, and Jian Tang. Pre-training molecular graph representation with 3d geometry. In International Conference on Learning Representations, 2022.   \n[68] Tiqing Liu, Yuhmei Lin, Xin Wen, Robert N. Jorissen, and Michael K. Gilson. Bindingdb: a web-accessible database of experimentally determined protein\u2013ligand binding affinities. Nucleic Acids Research, 35:D198\u2013D201, 12 2006.   \n[69] Yinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Mandar Joshi, Danqi Chen, Omer Levy, Mike Lewis, Luke Zettlemoyer, and Veselin Stoyanov. Roberta: A robustly optimized bert pretraining approach, 2019.   \n[70] Andrew L. Maas, Raymond E. Daly, Peter T. Pham, Dan Huang, Andrew Y. Ng, and Christopher Potts. Learning word vectors for sentiment analysis. In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies, pages 142\u2013150, Portland, Oregon, USA, June 2011. Association for Computational Linguistics.   \n[71] Hadrien Mary, Emmanuel Noutahi, DomInvivo, Lu Zhu, Michel Moreau, Steven Pak, Desmond Gilmour, Shawn Whitfield, t, Valence-JonnyHsu, Honor\u00e9 Hounwanou, Ishan Kumar, Saurav Maheshkar, Shuya Nakata, Kyle M. Kovary, Cas Wognum, Michael Craig, and DeepSource Bot. datamol-io/datamol: 0.12.3, January 2024.   \n[72] Julian McAuley and Jure Leskovec. Hidden factors and hidden topics: understanding rating dimensions with review text. In Proceedings of the 7th ACM Conference on Recommender Systems, RecSys \u201913, page 165\u2013172, New York, NY, USA, 2013. Association for Computing Machinery.   \n[73] Rui Meng, Ye Liu, Shafiq Rayhan Joty, Caiming Xiong, Yingbo Zhou, and Semih Yavuz. Sfr-embedding-mistral:enhance text retrieval with transfer learning. Salesforce AI Research Blog, 2024.   \n[74] Saif Mohammad, Felipe Bravo-Marquez, Mohammad Salameh, and Svetlana Kiritchenko. Semeval-2018 task 1: Affect in tweets. In Proceedings of the 12th international workshop on semantic evaluation, pages 1\u201317, 2018.   \n[75] Niklas Muennighoff, Nouamane Tazi, Lo\u00efc Magne, and Nils Reimers. Mteb: Massive text embedding benchmark, 2023.   \n[76] Kevin P. Murphy. Machine learning : a probabilistic perspective. MIT Press, Cambridge, Mass. [u.a.], 2013.   \n[77] Jianmo Ni, Gustavo Hern\u00e1ndez \u00c1brego, Noah Constant, Ji Ma, Keith B. Hall, Daniel Cer, and Yinfei Yang. Sentence-t5: Scalable sentence encoders from pre-trained text-to-text models, 2021.   \n[78] Zhihong Pan, Xin Zhou, and Hao Tian. Extreme generative image compression by learning text embedding from diffusion models. arXiv preprint arXiv:2211.07793, 2022.   \n[79] Bo Pang and Lillian Lee. Seeing stars: Exploiting class relationships for sentiment categorization with respect to rating scales. In Proceedings of the ACL, 2005.   \n[80] Raul P. Pelaez, Guillem Simeon, Raimondas Galvelis, Antonio Mirarchi, Peter Eastman, Stefan Doerr, Philipp Th\u00f6lke, Thomas E. Markland, and Gianni De Fabritiis. Torchmd-net 2.0: Fast neural network potentials for molecular simulations, 2024.   \n[81] Christian S. Perone, Roberto Silveira, and Thomas S. Paula. Evaluation of sentence embeddings in downstream and linguistic probing tasks, 2018.   \n[82] Georg Pichler, Pierre Colombo, Malik Boudiaf, G\u00fcnther Koliander, and Pablo Piantanida. A differential entropy estimator for training neural networks, 2022.   \n[83] Tiago Pimentel, Clara Meister, and Ryan Cotterell. On the usefulness of embeddings, clusters and strings for text generator evaluation, 2023.   \n[84] Tiago Pimentel, Josef Valvoda, Rowan Hall Maudslay, Ran Zmigrod, Adina Williams, and Ryan Cotterell. Information-theoretic probing for linguistic structure. In Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pages 4609\u20134622, 2020.   \n[85] Nils Reimers and Iryna Gurevych. Sentence-bert: Sentence embeddings using siamese bertnetworks, 2019.   \n[86] Nils Reimers and Iryna Gurevych. Making monolingual sentence embeddings multilingual using knowledge distillation. In Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing. Association for Computational Linguistics, 11 2020.   \n[87] R. Tyrrell Rockafellar. Convex analysis. Princeton Mathematical Series. Princeton University Press, Princeton, N. J., 1970.   \n[88] Anna Rogers, Olga Kovaleva, and Anna Rumshisky. A primer in bertology: What we know about how bert works. Transactions of the Association for Computational Linguistics, 8:842\u2013 866, 2021.   \n[89] Yu Rong, Yatao Bian, Tingyang Xu, Weiyang Xie, Ying Wei, Wenbing Huang, and Junzhou Huang. Self-supervised graph transformer on large-scale molecular data. Advances in Neural Information Processing Systems, 33, 2020.   \n[90] Chitwan Saharia, William Chan, Saurabh Saxena, Lala Li, Jay Whang, Emily Denton, Seyed Kamyar Seyed Ghasemipour, Burcu Karagol Ayan, S. Sara Mahdavi, Rapha Gontijo Lopes, Tim Salimans, Jonathan Ho, David J Fleet, and Mohammad Norouzi. Photorealistic text-toimage diffusion models with deep language understanding, 2022.   \n[91] Joaquim Santos, Bernardo Consoli, and Renata Vieira. Word embedding evaluation in downstream tasks and semantic analogies. In Nicoletta Calzolari, Fr\u00e9d\u00e9ric B\u00e9chet, Philippe Blache, Khalid Choukri, Christopher Cieri, Thierry Declerck, Sara Goggi, Hitoshi Isahara, Bente Maegaard, Joseph Mariani, H\u00e9l\u00e8ne Mazo, Asuncion Moreno, Jan Odijk, and Stelios Piperidis, editors, Proceedings of the Twelfth Language Resources and Evaluation Conference, pages 4828\u20134834, Marseille, France, May 2020. European Language Resources Association.   \n[92] Elvis Saravia, Hsien-Chi Toby Liu, Yen-Hao Huang, Junlin Wu, and Yi-Shin Chen. CARER: Contextualized affect representations for emotion recognition. In Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, pages 3687\u20133697, Brussels, Belgium, October-November 2018. Association for Computational Linguistics.   \n[93] Christoph Schuhmann, Richard Vencu, Romain Beaumont, Robert Kaczmarczyk, Clayton Mullis, Aarush Katta, Theo Coombes, Jenia Jitsev, and Aran Komatsuzaki. Laion-400m: Open dataset of clip-filtered 400 million image-text pairs. arXiv preprint arXiv:2111.02114, 2021.   \n[94] Claude E. Shannon. A note on a partial ordering for communication channels. Information and Control, 1(4):390\u2013397, 1958.   \n[95] A.N. Shiri?aev and V.G. Spokoiny. Statistical Experiments and Decisions: Asymptotic Theory. Advanced series on statistical science & applied probability. World Scientific, 2000.   \n[96] Hannes St\u00e4rk, Dominique Beaini, Gabriele Corso, Prudencio Tossou, Christian Dallago, Stephan G\u00fcnnemann, and Pietro Li\u00f2. 3d infomax improves gnns for molecular property prediction. arXiv preprint arXiv:2110.04126, 2021.   \n[97] Ce Sui, Xiaosheng Zhao, Tao Jing, and Yi Mao. Evaluating summary statistics with mutual information for cosmological inference, 2023.   \n[98] Fan-Yun Sun, Jordan Hoffman, Vikas Verma, and Jian Tang. Infograph: Unsupervised and semi-supervised graph-level representation learning via mutual information maximization. In International Conference on Learning Representations, 2019.   \n[99] Ruoxi Sun, Hanjun Dai, and Adams Wei Yu. Does gnn pretraining help molecular representation? In Advances in Neural Information Processing Systems (NeurIPS), 2022.   \n[100] Duyu Tang, Furu Wei, Bing Qin, Nan Yang, Ting Liu, and Ming Zhou. Sentiment embeddings with applications to sentiment analysis. IEEE Transactions on Knowledge and Data Engineering, 28(2):496\u2013509, 2016.   \n[101] Jing Tang, Agnieszka Szwajda, Sushil Shakyawar, Tao Xu, Petteri Hintsanen, Krister Wennerberg, and Tero Aittokallio. Making sense of large-scale kinase inhibitor bioactivity data sets: A comparative and integrative analysis. Journal of Chemical Information and Modeling, 54(3):735\u2013743, 2014. ", "page_idx": 10}, {"type": "text", "text": "", "page_idx": 11}, {"type": "text", "text": "", "page_idx": 12}, {"type": "text", "text": "", "page_idx": 13}, {"type": "text", "text": "", "page_idx": 14}, {"type": "text", "text": "", "page_idx": 15}, {"type": "text", "text": "[102] Gemma Team, Thomas Mesnard, Cassidy Hardin, Robert Dadashi, Surya Bhupatiraju, Shreya Pathak, Laurent Sifre, Morgane Rivi\u00e8re, Mihir Sanjay Kale, Juliette Love, Pouya Tafti, L\u00e9onard Hussenot, Pier Giuseppe Sessa, Aakanksha Chowdhery, Adam Roberts, Aditya Barua, Alex Botev, Alex Castro-Ros, Ambrose Slone, Am\u00e9lie H\u00e9liou, Andrea Tacchetti, Anna Bulanova, Antonia Paterson, Beth Tsai, Bobak Shahriari, Charline Le Lan, Christopher A. ChoquetteChoo, Cl\u00e9ment Crepy, Daniel Cer, Daphne Ippolito, David Reid, Elena Buchatskaya, Eric Ni, Eric Noland, Geng Yan, George Tucker, George-Christian Muraru, Grigory Rozhdestvenskiy, Henryk Michalewski, Ian Tenney, Ivan Grishchenko, Jacob Austin, James Keeling, Jane Labanowski, Jean-Baptiste Lespiau, Jeff Stanway, Jenny Brennan, Jeremy Chen, Johan Ferret, Justin Chiu, Justin Mao-Jones, Katherine Lee, Kathy Yu, Katie Millican, Lars Lowe Sjoesund, Lisa Lee, Lucas Dixon, Machel Reid, Maciej Miku\u0142a, Mateo Wirth, Michael Sharman, Nikolai Chinaev, Nithum Thain, Olivier Bachem, Oscar Chang, Oscar Wahltinez, Paige Bailey, Paul Michel, Petko Yotov, Rahma Chaabouni, Ramona Comanescu, Reena Jana, Rohan Anil, Ross McIlroy, Ruibo Liu, Ryan Mullins, Samuel L Smith, Sebastian Borgeaud, Sertan Girgin, Sholto Douglas, Shree Pandya, Siamak Shakeri, Soham De, Ted Klimenko, Tom Hennigan, Vlad Feinberg, Wojciech Stokowiec, Yu hui Chen, Zafarali Ahmed, Zhitao Gong, Tris Warkentin, Ludovic Peran, Minh Giang, Cl\u00e9ment Farabet, Oriol Vinyals, Jeff Dean, Koray Kavukcuoglu, Demis Hassabis, Zoubin Ghahramani, Douglas Eck, Joelle Barral, Fernando Pereira, Eli Collins, Armand Joulin, Noah Fiedel, Evan Senter, Alek Andreev, and Kathleen Kenealy. Gemma: Open models based on gemini research and technology, 2024. ", "page_idx": 16}, {"type": "text", "text": "[103] Erik Torgersen. Comparison of Statistical Experiments. Encyclopedia of Mathematics and its Applications. Cambridge University Press, 1991. ", "page_idx": 16}, {"type": "text", "text": "[104] Erik Nikolai Torgersen. Comparison of experiments when the parameter space is finite. Zeitschrift f r Wahrscheinlichkeitstheorie und Verwandte Gebiete, 16(3):219\u2013249, 1970.   \n[105] Mirko Torrisi, Saeid Asadollahi, Antonio De la Vega de Leon, Kai Wang, and Wilbert Copeland. Do chemical language models provide a better compound representation? In NeurIPS 2023 Workshop on New Frontiers of AI for Drug Discovery and Development, 2023.   \n[106] Hugo Touvron, Louis Martin, Kevin Stone, Peter Albert, Amjad Almahairi, Yasmine Babaei, Nikolay Bashlykov, Soumya Batra, Prajjwal Bhargava, Shruti Bhosale, Dan Bikel, Lukas Blecher, Cristian Canton Ferrer, Moya Chen, Guillem Cucurull, David Esiobu, Jude Fernandes, Jeremy Fu, Wenyin Fu, Brian Fuller, Cynthia Gao, Vedanuj Goswami, Naman Goyal, Anthony Hartshorn, Saghar Hosseini, Rui Hou, Hakan Inan, Marcin Kardas, Viktor Kerkez, Madian Khabsa, Isabel Kloumann, Artem Korenev, Punit Singh Koura, Marie-Anne Lachaux, Thibaut Lavril, Jenya Lee, Diana Liskovich, Yinghai Lu, Yuning Mao, Xavier Martinet, Todor Mihaylov, Pushkar Mishra, Igor Molybog, Yixin Nie, Andrew Poulton, Jeremy Reizenstein, Rashi Rungta, Kalyan Saladi, Alan Schelten, Ruan Silva, Eric Michael Smith, Ranjan Subramanian, Xiaoqing Ellen Tan, Binh Tang, Ross Taylor, Adina Williams, Jian Xiang Kuan, Puxin Xu, Zheng Yan, Iliyan Zarov, Yuchen Zhang, Angela Fan, Melanie Kambadur, Sharan Narang, Aurelien Rodriguez, Robert Stojnic, Sergey Edunov, and Thomas Scialom. Llama 2: Open foundation and fine-tuned chat models, 2023.   \n[107] Anton Tsitsulin, Marina Munkhoeva, and Bryan Perozzi. Unsupervised embedding quality evaluation, 2023.   \n[108] Alexandre B Tsybakov. Introduction to Nonparametric Estimation. Springer series in statistics. Springer, Dordrecht, 2009.   \n[109] Cynthia Van Hee, Els Lefever, and V\u00e9ronique Hoste. Semeval-2018 task 3: Irony detection in english tweets. In Proceedings of The 12th International Workshop on Semantic Evaluation, pages 39\u201350, 2018.   \n[110] Petar Veli\u02c7ckovi\u00b4c, Guillem Cucurull, Arantxa Casanova, Adriana Romero, Pietro Li\u00f2, and Yoshua Bengio. Graph attention networks. In International Conference on Learning Representations, 2018.   \n[111] Luke Vilnis and Andrew McCallum. Word representations via gaussian embedding. In Yoshua Bengio and Yann LeCun, editors, 3rd International Conference on Learning Representations, ICLR 2015, San Diego, CA, USA, May 7-9, 2015, Conference Track Proceedings, 2015.   \n[112] Hongwei Wang, Weijiang Li, Xiaomeng Jin, Kyunghyun Cho, Heng Ji, Jiawei Han, and Martin D. Burke. Chemical-reaction-aware molecule representation learning. In International Conference on Learning Representations, 2022.   \n[113] Liang Wang, Nan Yang, Xiaolong Huang, Binxing Jiao, Linjun Yang, Daxin Jiang, Rangan Majumder, and Furu Wei. Text embeddings by weakly-supervised contrastive pre-training. arXiv preprint arXiv:2212.03533, 2022.   \n[114] David Weininger. SMILES, a chemical language and information system. 1. Introduction to methodology and encoding rules. Journal of Chemical Information and Computer Sciences, 28(1):31\u201336, February 1988. Publisher: American Chemical Society.   \n[115] Keyulu Xu, Weihua Hu, Jure Leskovec, and Stefanie Jegelka. How powerful are graph neural networks? In International Conference on Learning Representations, 2019.   \n[116] Minghao Xu, Hang Wang, Bingbing Ni, Hongyu Guo, and Jian Tang. Self-supervised graphlevel representation learning with local and global structure. arXiv preprint arXiv:2106.04113, 2021.   \n[117] Nianzu Yang, Kaipeng Zeng, Qitian Wu, Xiaosong Jia, and Junchi Yan. Learning substructure invariance for out-of-distribution molecular representations. In Advances in Neural Information Processing Systems (NeurIPS), 2022.   \n[118] Yinfei Yang, Yuan Zhang, Chris Tar, and Jason Baldridge. PAWS-X: A Cross-lingual Adversarial Dataset for Paraphrase Identification. In Proc. of EMNLP, 2019.   \n[119] Yuning You, Tianlong Chen, Yongduo Sui, Ting Chen, Zhangyang Wang, and Yang Shen. Graph contrastive learning with augmentations. In H. Larochelle, M. Ranzato, R. Hadsell, M. F. Balcan, and H. Lin, editors, Advances in Neural Information Processing Systems, volume 33, pages 5812\u20135823. Curran Associates, Inc., 2020.   \n[120] Peter Young, Alice Lai, Micah Hodosh, and Julia Hockenmaier. From image descriptions to visual denotations: New similarity metrics for semantic inference over event descriptions. Transactions of the Association for Computational Linguistics, 2:67\u201378, 2014.   \n[121] Sheheryar Zaidi, Michael Schaarschmidt, James Martens, Hyunjik Kim, Yee Whye Teh, Alvaro Sanchez-Gonzalez, Peter Battaglia, Razvan Pascanu, and Jonathan Godwin. Pretraining via denoising for molecular property prediction. In International Conference on Learning Representations, 2023.   \n[122] Li Zhang, Steven Wilson, and Rada Mihalcea. Multi-label transfer learning for multi-relational semantic similarity. In Proceedings of the Eighth Joint Conference on Lexical and Computational Semantics (\\*SEM 2019). Association for Computational Linguistics, 2019.   \n[123] Xiang Zhang, Junbo Jake Zhao, and Yann LeCun. Character-level convolutional networks for text classification. In NIPS, 2015. ", "page_idx": 16}, {"type": "text", "text": "", "page_idx": 17}, {"type": "text", "text": "Appendix ", "text_level": 1, "page_idx": 18}, {"type": "text", "text": "Table of Contents ", "text_level": 1, "page_idx": 18}, {"type": "text", "text": "A Background and Notation 20 ", "page_idx": 18}, {"type": "text", "text": "B Proofs Theoretical Results 20 ", "text_level": 1, "page_idx": 18}, {"type": "text", "text": "B.1 Proof Proposition 1 21   \nB.2 Comments about capacity to distinguish concepts . . . 21   \nB.3 Proof of Proposition 2 and Corollary 1 . . 22   \nB.4 Example of comparisons of statistical experiments . . 23   \nB.5 Sufficiency and Inference Procedures with Embedding Models [13, 63] 24   \nB.6 Deficiency and Expected Risk [63] . . 24 ", "page_idx": 18}, {"type": "text", "text": "C NLP Experiment Details 24 ", "text_level": 1, "page_idx": 18}, {"type": "text", "text": "C.1 Models and Datasets statistics . . 24   \nC.2 Downstream tasks training details. 24   \nC.3 NLP Comprehensive Results . 24   \nC.3.1 Full MTEB Benchmark Results . . 24   \nC.3.2 Ablation studies . . . . 26   \nC.3.3 Impact of training steps . . . 27   \nC.3.4 Importance of embedding size normalization . . 27   \nC.3.5 Community and cluster performance . . . 29   \nC.3.6 Evaluating information sufficiency on different datasets 30 ", "page_idx": 18}, {"type": "text", "text": "D Molecular Experiment Details 31 ", "text_level": 1, "page_idx": 18}, {"type": "text", "text": "D.1 Embedders considered . . 31   \nD.2 Details on the information sufficiency estimation 32   \nD.3 Complementary results on ADMET tasks . . . 33   \nD.4 Drug target Interaction prediction . . 35 ", "page_idx": 18}, {"type": "text", "text": "E Information Sufficiency Estimation 36 ", "text_level": 1, "page_idx": 18}, {"type": "text", "text": "E.1 Estimation method . 36   \nE.1.1 KNIFE Estimator . . 36   \nE.1.2 Embedding dimension normalization. . 37   \nE.1.3 Median instead of mean. . . 38   \nE.2 Hyperparameter selection . . 39   \nE.3 Impact of the task size . . 39   \nE.4 Impact of the number of models 41   \nE.5 Comparison with other metrics 42   \nE.6 Computational ressources . . 43 ", "page_idx": 18}, {"type": "text", "text": "A Background and Notation ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "We consider all alphabets to be standard Borel [28] (i.e., isomorphic to a Borel subspace of a Polish space), encompassing virtually all practical scenarios. Each such space $\\textsf{Y}$ is equipped with its Borel $\\sigma$ -algebra $B(\\mathsf{Y})$ . The set of all probability measures on $\\textsf{Y}$ is denoted by ${\\mathcal{P}}(\\mathsf{Y})$ . The total variation distance between $P$ and $Q$ in ${\\mathcal{P}}(\\mathsf{Y})$ is defined as ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\|P-Q\\|_{\\mathrm{TV}}=\\operatorname*{sup}_{A\\in\\mathcal{B}(\\mathsf{Y})}|P(A)-Q(A)|,\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "and the Kullback\u2013Leibler divergence is defined by ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\operatorname{KL}\\!\\left(P\\!\\left\\|Q\\right)={\\left\\{\\begin{array}{l l}{\\int_{\\mathsf{X}}\\!\\log{\\frac{\\mathrm{d}P}{\\mathrm{d}Q}}\\mathsf{d}P}&{{\\mathrm{if}}\\ P\\ll Q}\\\\ {\\qquad+\\infty}&{{\\mathrm{otherwise.}}}\\end{array}\\right.}\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "Given a joint probability measure $P_{X Y}$ in $\\mathcal{P}(\\mathsf{X}\\!\\times\\!\\mathsf{Y})$ induced by two random variables $X\\in\\mathsf X$ and $Y\\in$ $\\textsf{Y}$ with product measures $P_{X}P_{Y}$ , the Mutual Information is defined as $I(X;Y)=\\operatorname{KL}\\!\\left(P_{X Y}\\|P_{X}P_{Y}\\right)$ . If $P_{X}\\in\\mathcal{P}(\\mathsf{X})$ is a probability measure induced by $X\\in\\mathsf X$ , the Differential Entropy is defined by ", "page_idx": 19}, {"type": "equation", "text": "$$\nh(X)=-\\int_{\\mathbb{X}}\\log{\\frac{\\mathsf{d}P_{X}}{\\mathsf{d}\\mu}}\\,d P_{X},\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "where $\\mu$ denotes the Lebesgue measure. Similarly, it is possible to define the conditional entropy of $Y$ given $X$ which is denoted by $h(Y|X)$ . The mutual information satisfies the identities $I(X;Y)=$ $h(\\bar{Y})-h(Y|X)=h(X)-\\dot{h(X|Y)}$ and $h(Y|X)\\leqslant h(Y)$ (see [27] for further details). ", "page_idx": 19}, {"type": "text", "text": "A Markov (or transition probability) kernel between $\\mathsf{X}$ and $\\textsf{Y}$ is a mapping $T:B(\\mathsf{Y})\\times\\mathsf{X}\\to[0,1]$ , satisfying $T(\\cdot|x)\\,\\in\\,{\\mathcal{P}}(\\mathsf{Y})$ for all $x\\,\\in\\,\\mathsf{X}$ and $T({\\boldsymbol{B}}|{\\boldsymbol{\\cdot}})$ being a measurable function on $\\mathsf{X}$ for any $\\boldsymbol{B}\\,\\in\\,\\boldsymbol{B}(\\mathsf{Y})$ . The space of all such $T$ is denoted by $\\kappa(\\mathsf{Y}|\\mathsf{X})$ . In cases where both $\\textsf{Y}$ and $\\mathsf{X}$ are finite, any $\\kappa(\\mathsf{Y}|\\mathsf{X})$ is represented as a stochastic matrix with elements $T(y|x)$ , $(x,y)\\in\\mathsf{X}\\times\\mathsf{Y}$ . Every $T\\in\\mathcal{K}(\\mathsf{Y}|\\mathsf{X})$ induces a mapping $\\mathcal{P}(\\mathsf{X})\\longrightarrow\\mathcal{P}(\\mathsf{Y})$ , denoted by $T$ , mapping any $P\\in\\mathcal{P}(\\mathsf{X})$ to $Q=T\\circ P\\in{\\mathcal{P}}(\\mathsf{Y})$ , where ", "page_idx": 19}, {"type": "equation", "text": "$$\nQ(B)=(T\\circ P)(B)\\triangleq\\int_{\\mathsf{X}}T(B|x)P(\\mathsf{d}x),\\quad\\forall B\\in\\mathcal{B}(\\mathsf{Y}).\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "We denote the composition of Markov kernels by juxtaposition: for $M\\in\\mathcal{K}(\\sf Z|\\sf Y)$ and $T\\in\\mathcal{K}(\\mathsf{Y}|\\mathsf{X})$ , their composition $M\\circ T\\in{\\mathcal{T}}(\\mathbb{Z}|\\mathsf{X})$ is defined by ", "page_idx": 19}, {"type": "equation", "text": "$$\n(M\\circ T)(Z|x)\\triangleq\\int_{\\mathsf{Y}}M(Z|y)T(\\mathsf{d}y|x),\\quad\\forall x\\in\\mathsf{X},\\,Z\\in\\mathcal{B}(\\mathsf{Z}).\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "We define the average of the total variation distance between two Markov kernels $T,T^{\\prime}\\in\\mathcal{K}(\\mathsf{Y}|\\mathsf{X})$ as follows: ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathbb{E}\\|T-T^{\\prime}\\|_{\\mathrm{TV}}\\triangleq\\mathbb{E}\\|T(\\cdot|X)-T^{\\prime}(\\cdot|X)\\|_{\\mathrm{TV}}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "A statistical model is a triple $\\mathcal{M}_{U}\\equiv\\big(\\mathsf{U},\\mathcal{B}(\\mathsf{U}),(P_{U|Y}(\\cdot|y):y\\in\\mathsf{Y})\\big)$ , where $(\\mathsf{U},{\\mathcal{B}}(\\mathsf{U}))$ is a sample space; $\\textsf{Y}$ is a concept space, and $P_{U|Y}:\\,B(\\mathsf{U})\\,\\times\\,\\mathsf{Y}\\,\\to\\,[0,1]$ is a Markov kernel (or transition probability). ", "page_idx": 19}, {"type": "text", "text": "B Proofs Theoretical Results ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "Proposition (Relationships of sufficiency and information). The following relationships hold: ", "page_idx": 19}, {"type": "text", "text": "(i) Sufficiency $\\Rightarrow{}$ informativeness. If the embedding model $P_{U|X}$ is sufficient for the embedding model $P_{V|X}$ , i.e. $U\\succcurlyeq S\\ V$ , then $U\\succcurlyeq_{I}V$ . However, Informativeness \u21cfsufficiency.   \n(ii) Informativeness $\\Rightarrow{}$ higher capacity to distinguish concepts. If the embedding model $P_{U|X}$ is more informative than embedding model $P_{Z|X}$ , i.e. $U\\succcurlyeq_{I}V$ , then ", "page_idx": 19}, {"type": "equation", "text": "$$\nK L\\big(P_{U|Y}(\\cdot|y_{0})\\|P_{U|Y}(\\cdot|y_{1})\\big)\\geqslant K L\\big(P_{V|Y}(\\cdot|y_{0})\\|P_{V|Y}(\\cdot|y_{1})\\big),\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "for any pair of concepts $(y_{0},y_{1})\\in\\mathsf{Y}\\times\\mathsf{Y}$ and all probability distributions $P_{Y X}$ . ", "page_idx": 19}, {"type": "text", "text": "B.1 Proof Proposition 1 ", "text_level": 1, "page_idx": 20}, {"type": "text", "text": "Proof. It is immediate to check that the data-processing inequality and the Markov chain $Y\\leftrightarrow X\\leftrightarrow$ $U\\leftrightarrow V$ implies the relation in claim (i). On the other hand, the non-equivalence is proved by means of an explicit counterexample [57]. Given any $0<p<1/2$ with $\\bar{p}=1-p$ . For some $\\epsilon,\\delta>0$ , consider two discrete embedding models defined by the following matrices: ", "page_idx": 20}, {"type": "equation", "text": "$$\nP_{V|X}=1/2\\left(\\begin{array}{c c}{{1+\\epsilon}}&{{1-\\epsilon}}\\\\ {{1}}&{{1}}\\end{array}\\right)P_{U|X}\\quad\\mathrm{with}\\quad P_{U|X}=\\left(\\begin{array}{c c}{{p}}&{{\\bar{p}}}\\\\ {{p+\\delta}}&{{\\bar{p}-\\delta}}\\end{array}\\right).\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "By taking $\\epsilon,\\delta>0$ small enough, both $P_{U|X}$ and $P_{V|X}$ are stochastic matrices. It follows that $P_{V|X}$ is not a degraded version of $P_{U|X}$ but provided that $\\epsilon,\\delta$ are sufficient small, the embedding model $P_{U|X}$ is more informative than $\\dot{P}_{V|X}$ , which proves the claim. ", "page_idx": 20}, {"type": "text", "text": "In order to show (ii), let $P_{U|Y}$ and $P_{V|Y}$ be the corresponding probability measures induced by $P_{X|U}(\\cdot|u)$ via the embedding models: ", "page_idx": 20}, {"type": "equation", "text": "$$\nP_{U|Y}(U|y)=\\int_{\\mathsf{X}}P_{U|X}(U|x)P_{X|Y}(\\mathsf{d}x|y),\\quad\\forall y\\in\\mathsf{Y},\\,U\\in\\mathcal{B}(\\mathsf{U}),\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "and ", "page_idx": 20}, {"type": "equation", "text": "$$\nP_{V|Y}(V|y)=\\int_{\\mathsf{X}}P_{V|X}(V|x)P_{X|Y}(\\mathsf{d}x|y),\\quad\\forall y\\in\\mathsf{Y},\\,V\\in\\mathcal{B}(\\mathsf{V}),\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "for any $y\\in\\mathsf{Y}=\\{y_{0},y_{1}\\}$ . For a $0\\leqslant\\lambda\\leqslant1$ , let $P_{X|Y}(\\cdot|y_{0})\\in\\mathcal{P}(\\mathsf{X})$ and $P_{X|Y}(\\cdot|y_{1})\\in\\mathcal{P}(\\mathsf{X})$ be two arbitrary probability measures on $\\mathsf{X}$ . Let $P_{X|Y}(X|j)$ be defined by ", "page_idx": 20}, {"type": "equation", "text": "$$\nP_{X|Y}(X|y)=\\mathbb{1}[y=y_{0}]P_{X|Y}(X|y_{0})+\\mathbb{1}[y=y_{1}]P_{X|Y}(X|y_{1}).\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "By replacing it into equations (9) and (10), we obtain ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\begin{array}{r}{P_{U|Y}(U|y)=\\mathbb{1}[y=y_{0}]P_{U|Y}(U|y_{0})+\\mathbb{1}[y=y_{1}]P_{U|Y}(U|y_{1})}\\\\ {P_{V|Y}(V|y)=\\mathbb{1}[y=y_{0}]P_{V|Y}(V|y_{0})+\\mathbb{1}[y=y_{1}]P_{V|Y}(V|y_{1})}\\end{array}\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "and let $P_{Y}(y_{0})=\\lambda$ and $P_{Y}(y_{1})=1-\\lambda$ . The above probability measures correspond to a quadruple of random variables: $(Y_{\\lambda},\\bar{X_{\\lambda}},\\bar{U_{\\lambda}},V_{\\lambda})\\in\\mathcal{P}(\\mathsf{Y}\\times\\mathsf{X}\\times\\mathsf{\\bar{U}}\\times\\mathsf{V})$ . Consider the function $f(\\lambda)$ defined by ", "page_idx": 20}, {"type": "equation", "text": "$$\nf(\\lambda)=I(Y_{\\lambda};U_{\\lambda})-I(Y_{\\lambda};V_{\\lambda}).\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "It is not difficult to check that $f(\\lambda)\\;\\geq\\;0$ for all $0\\leqslant\\lambda\\leqslant1$ , and $f(0)\\,=\\,0$ which requires that $f^{\\prime}(0)\\geqslant0$ . By taking the differentiation, we obtain ", "page_idx": 20}, {"type": "equation", "text": "$$\nf^{\\prime}(0)=\\mathrm{KL}\\big(P_{U|Y}(\\cdot|y_{0})\\|P_{U|Y}(\\cdot|y_{1})\\big)-\\mathrm{KL}\\big(P_{V|Y}(\\cdot|y_{0})\\|P_{V|Y}(\\cdot|y_{1})\\big)\\geqslant0,\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "which implies the claim (ii). This concludes the proof. ", "page_idx": 20}, {"type": "text", "text": "B.2 Comments about capacity to distinguish concepts ", "text_level": 1, "page_idx": 20}, {"type": "text", "text": "Notice that the KL divergence between the induced distributions of the resulting embedding is not less for the embedding model $U$ than $Z$ . Indeed, consider the case of binary classification $\\mathsf{Y}=\\{y_{0},y_{1}\\}$ with uniformly distributed concepts. Pinsker\u2019s inequality [108] together with claim (iii) imply ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathrm{KL}\\big(P_{U|Y}(\\cdot|y_{0})\\|P_{U|Y}(\\cdot|y_{1})\\big)\\geqslant2\\|P_{V|Y}(\\cdot|y_{0})-P_{V|Y}(\\cdot|y_{1})\\|_{\\mathrm{TV}}^{2}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "From which, it is easy to verify that the accuracy of the expected Bayes accuracy of the optimal classifier based on $V$ is upper bounded by [108, Lemma 2.1]: ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\operatorname*{sup}_{\\psi}\\operatorname*{Pr}(\\psi(V)=Y)\\leqslant1-\\frac{1}{2}\\exp\\left(-\\mathrm{KL}\\big(P_{U|Y}(\\cdot|y_{0})\\|P_{U|Y}(\\cdot|y_{1})\\big)\\right),\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "where the exponent in the upper bound is subject to the discriminating capacity through the KL divergence of the embedding model $U$ on $\\mathsf{U}$ . ", "page_idx": 20}, {"type": "text", "text": "B.3 Proof of Proposition 2 and Corollary 1 ", "text_level": 1, "page_idx": 21}, {"type": "text", "text": "We begin with the proof of Proposition 2. ", "page_idx": 21}, {"type": "text", "text": "Proof. Clearly, the assumption (i) implies the statement (ii) by Data-Processing. Conversely, let us assume point (ii) holds. This means that, for every probbaility distribution $P_{X}$ and all conditional probability distributions $P_{Y\\mid X}$ , there exists $\\rho_{U}:\\mathsf{U}\\to\\mathcal{P}(\\mathsf{Y})$ such that ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\displaystyle\\sum_{(y,x)\\in\\mathbb{Y}\\times\\mathbb{X}}P_{Y X}(y,x)\\int_{\\mathsf{U}}\\rho_{U}(y|u)P_{U|X}(\\mathsf{d}u|x)\\geqslant}\\\\ &{\\quad\\quad\\displaystyle\\operatorname*{sup}_{\\rho_{V}}\\sum_{(y,x)\\in\\mathbb{Y}\\times\\mathbb{X}}P_{Y X}(y,x)\\int_{\\mathsf{V}}\\rho_{V}(y|v)P_{V|X}(\\mathsf{d}v|x),}\\end{array}\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "where $\\rho_{V}:\\mathsf{V}\\to\\mathcal{P}(\\mathsf{Y})$ is a (possibly randomized) inference procedure is transition probabilities, which the learner can optimize to maximize the guessing probability. ", "page_idx": 21}, {"type": "text", "text": "Let the decision rule $\\rho_{V}(y|v)=\\mathbb{1}[v\\in A_{y}]$ for any partition $\\{A_{y}\\}_{y\\in\\mathsf{Y}}$ of $\\vee$ with $A_{y}\\in B(\\mathsf{V})$ . Then, for any $P_{Y\\mid X}$ , expression (13) implies the existence there exists $\\bar{\\rho_{U}}(y|u)$ such that ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\begin{array}{r l r}{\\lefteqn{\\sum_{(y,x)\\in\\nabla\\in\\mathsf{X}}P_{Y X}(y,x)\\left[\\displaystyle\\int_{\\mathsf{V}}P_{V|X}(\\mathsf{d}v|x)\\Im{[v\\in A_{y}]}-\\displaystyle\\int_{\\mathsf{U}}\\rho_{U}(y|u)P_{U|X}(\\mathsf{d}u|x)\\right]}}\\\\ &{=}&{\\displaystyle\\sum_{(y,x)\\in\\mathsf{Y}\\times\\mathsf{X}}P_{Y X}(y,x)\\left[\\displaystyle\\int_{A_{y}}P_{V|X}(\\mathsf{d}v|x)-\\displaystyle\\int_{\\mathsf{U}}\\rho_{U}(y|u)P_{U|X}(\\mathsf{d}u|x)\\right]\\leqslant0}\\end{array}\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "However, we can rewrite the last expression as: ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\operatorname*{sup}_{P_{Y|X}}\\operatorname*{inf}_{\\rho_{U}}\\sum_{(y,x)\\in\\mathbb{Y}\\times\\mathbb{X}}P_{Y X}(y,x)\\left[\\int_{A_{y}}P_{V|X}({\\mathsf{d}}v|x)-\\int_{\\mathsf{U}}\\rho_{U}(y|u)P_{U|X}({\\mathsf{d}}u|x)\\right]\\leqslant0.\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "By applying the minimax theorem [87], it is possible to exchange the order of the inf and the sup, which yields: ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\underset{\\rho\\ U}{\\mathrm{inf}}\\ \\underset{\\{A_{y}\\}}{\\operatorname*{sup}}\\ \\mathbb{E}\\left[\\underset{P_{Y}\\mid x}{\\operatorname*{sup}}\\sum_{y\\in\\mathsf{Y}}P_{Y\\mid X}(y\\vert X)\\Gamma\\big((y,X),\\rho_{U}\\big)\\right]\\leqslant0}\\\\ &{\\Gamma\\big((y,x),\\rho_{U}\\big)\\triangleq\\left[\\displaystyle\\int_{A_{y}}P_{V\\mid X}({\\mathsf{d}}v\\vert x)-\\int_{\\mathsf{U}}\\rho_{U}(y\\vert u)P_{U\\mid X}({\\mathsf{d}}u\\vert x)\\right].}\\end{array}\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "We observe that ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\sum_{y\\in\\mathsf{Y}}\\Gamma\\big((y,x),\\rho_{U}\\big)=0,\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "for each $x\\in\\mathsf{X}$ and thus, ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\operatorname*{max}_{y\\in\\mathsf{Y}}\\Gamma\\big((y,x),\\rho_{U}\\big)\\geqslant0,\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "where the equality holds if and only if $\\Gamma\\bigl((y,x),\\rho_{U}\\bigr)\\,=\\,0$ for all $y\\in\\mathsf{Y}$ , for each $x\\in\\mathsf{X}$ , since by contradiction otherwise ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\sum_{y\\in\\mathsf{Y}}\\Gamma\\big((y,x),\\rho_{U}\\big)<0.\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "Therefore, ", "text_level": 1, "page_idx": 21}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\underset{\\rho\\ U}{\\operatorname*{inf}}\\ \\underset{\\{A_{y}\\}}{\\operatorname*{sup}}\\ \\mathbb{E}\\left[\\underset{P_{Y\\mid X}}{\\operatorname*{sup}}\\sum_{P_{Y\\mid X}}P_{Y\\mid X}(y\\vert X)\\left(\\int_{A_{y}}P_{V\\mid X}(\\mathsf{d}v\\vert X)-\\int_{\\mathbb{U}}\\rho_{U}(y\\vert u)P_{U\\mid X}(\\mathsf{d}u\\vert X)\\right)\\right]}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\qquad=\\underset{\\rho\\ U}{\\operatorname*{inf}}\\ \\underset{\\{A_{y}\\}}{\\operatorname*{sup}}\\ \\mathbb{E}\\left[\\underset{y\\in\\mathbb{Y}}{\\operatorname*{max}}\\,\\Gamma\\big((y,X),\\rho_{U}\\big)\\right],}\\end{array}\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "which means the maximum is achieved by degenerate random variables $Y=f(X)$ achieving the maximum for each $x\\in\\mathsf{X}$ . Consequently, we have that ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\begin{array}{r l r}{\\underset{\\rho_{U}}{\\operatorname*{inf}}\\,\\mathbb{E}\\Vert P_{V|X}-\\rho_{U}\\circ P_{U|X}\\Vert_{\\mathrm{TV}}}&{=}&{\\underset{\\rho_{U}}{\\operatorname*{inf}}\\,\\underset{\\{A_{y}\\}}{\\operatorname*{sup}}\\,\\mathbb{E}\\left[\\underset{y\\in\\mathbb{Y}}{\\operatorname*{max}}\\,\\Gamma\\big((y,X),\\rho_{U}\\big)\\right]=0,}\\end{array}\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "hence i\u03c1nUf $\\mathbb{E}\\Vert P_{V|X}-\\rho_{U}\\circ P_{U|X}\\Vert_{\\operatorname{TV}}=0$ , and so the existence of the transition probability $\\rho_{U}$ such that $P_{U|X}$ is sufficient for $P_{V|X}$ . This concludes the proof of the Proposition 2. \u53e3 ", "page_idx": 22}, {"type": "text", "text": "We now show the proof of Corollary 1. ", "page_idx": 22}, {"type": "text", "text": "Proof. Continuing from the proof of Proposition 2, which remains unchanged, until one demonstrates that for $\\varepsilon>0$ , ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\operatorname*{inf}_{\\rho_{U}}\\,\\operatorname*{sup}_{\\{A_{y}\\}}\\,\\mathbb{E}\\left[\\operatorname*{max}_{y\\in\\mathsf{Y}}\\Gamma\\big((y,X),\\rho_{U}\\big)\\right]\\leqslant\\varepsilon.\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "To proceed from this point, let us now examine the following quantity: ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\sum_{y\\in\\mathsf{Y}}|\\Gamma\\big((y,x),\\rho_{U}\\big)|.\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "The above quantity is the induced $\\ell_{1}$ -norm distance between $\\begin{array}{r}{\\int_{A_{y}}P_{V|X}(\\mathsf{d}v|x)}\\end{array}$ and $\\begin{array}{r}{\\int_{\\mathsf{U}}\\rho_{U}(y|u)P_{U|X}({\\mathsf{d}}u|x)}\\end{array}$ . Since, for all $x\\in\\mathsf{X}$ , ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\sum_{y\\in\\mathsf{Y}}\\Gamma\\big((y,x),\\rho_{U}\\big)=0,\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "we have that ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\sum_{y\\in\\Upsilon}|\\Gamma\\big((y,x),\\rho_{U}\\big)|=2\\sum_{y\\in\\Upsilon:\\Gamma((y,x),\\rho_{U})\\geqslant0}\\Gamma\\big((y,x),\\rho_{U}\\big),\\quad\\mathrm{for~all~}x\\in\\mathbb{X}\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "which implies that, for the strategy $\\rho_{U}$ achieving the left-hand side of Eq. (24), ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\operatorname*{sup}_{\\{A_{y}\\}}\\mathbb{E}\\sum_{y\\in\\mathbb{Y}}\\left|\\Gamma\\big((y,X),\\rho_{U}\\big)\\right|\\leqslant2|\\mathbb{Y}|\\operatorname*{sup}_{\\{A_{y}\\}}\\mathbb{E}\\left[\\operatorname*{max}_{y\\in\\mathbb{Y}}\\Gamma\\big((y,X),\\rho_{U}\\big)\\right]\\leqslant2|\\mathbb{Y}|\\varepsilon,\\quad\\mathrm{for~all~}x\\in\\mathbb{X}\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "Hence, ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\operatorname*{sup}_{\\{A_{y}\\}}\\mathbb{E}\\sum_{y\\in\\mathbf{Y}}\\left|\\int_{\\mathcal{A}_{y}}P_{V|X}({\\mathsf{d}}v|X)-\\int_{\\mathsf{U}}\\rho_{U}(y|u)P_{U|X}({\\mathsf{d}}u|X)\\right|\\leqslant2|\\mathsf{Y}|\\varepsilon.\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "This concludes the proof of the Corollary 1. ", "page_idx": 22}, {"type": "text", "text": "B.4 Example of comparisons of statistical experiments ", "text_level": 1, "page_idx": 22}, {"type": "text", "text": "Example 1 (Statistical experiments with Gaussian embedding models). Let $U|x$ and $V|x$ be independently normally distributed as ${\\mathcal{N}}(x,\\sigma^{2})$ and $\\mathcal{N}(x,\\epsilon^{2}\\sigma^{2})$ , respectively, with $0<\\epsilon<1$ . ", "page_idx": 22}, {"type": "text", "text": "\u2022 Case of $\\sigma^{2}=\\sigma_{0}^{2}$ known. Here $U\\succcurlyeq s\\ V$ since $V+\\nu|x$ has the same distribution as $U|x$ when $\\dot{\\nu}\\sim\\mathcal{N}(0,\\breve{(}1-\\epsilon^{2})\\sigma_{0}^{2})$ . That is $V$ is strictly more informative than $U$ . However, $U$ is strictly more informative than $V$ . \u2022 Case of $x=0$ known. One can observe that $U\\approx V$ since the variables $V/\\epsilon$ have the same distribution as the $U$ , and the variables $\\epsilon U$ have the same distribution as the $V$ . \u2022 Case of $x$ and $\\sigma$ unknown. Surprisingly, in this case $U$ and $V$ are not comparable. ", "page_idx": 22}, {"type": "text", "text": "B.5 Sufficiency and Inference Procedures with Embedding Models [13, 63] ", "text_level": 1, "page_idx": 23}, {"type": "text", "text": "Proposition 3 (Sufficiency and risks of a given task on embedding models [13, 63]). An embedding model $P_{U|Y}\\in\\mathcal{K}(\\mathsf{U}|\\mathsf{Y})$ is deemed to be sufficient for another one $P_{V|Y}\\in{\\mathcal{K}}(\\mathsf{V}|\\mathsf{Y})$ if and only $i f,$ for any bounded loss function $\\ell$ where $\\|\\ell\\|_{\\infty}\\leqslant1$ , and for any inference procedure $\\rho_{V}:\\lor\\rightarrow\\lor$ , there exists a inference procedure (possibly randomized) $\\rho_{U}:\\mathsf{U}\\to\\mathcal{P}(\\mathsf{Y})$ such that the resulting statistical risks satisfy ", "page_idx": 23}, {"type": "equation", "text": "$$\n\\mathcal{R}_{y}(P_{U|Y},\\rho_{U},\\ell)\\leqslant\\mathcal{R}_{y}(P_{V|Y},\\rho_{V},\\ell),\\quad{\\it{f o r\\,a l l\\,y}}\\in\\forall.\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "Here we denote by $\\mathcal{R}_{y}(P_{U|Y},\\rho_{Y},\\ell)$ and $\\mathcal{R}_{y}(P_{V|Y},\\rho_{V},\\ell)$ the statistical risks for the corresponding inference frameworks, respectively. ", "page_idx": 23}, {"type": "text", "text": "Remark 5. The restriction $\\|\\ell\\|_{\\infty}\\leqslant1$ is irrelevant here. However, we opt for simplicity and limit our focus to situations where one encounters dominated statistical models with Polish sample spaces. In essence, various extensions do not significantly alter the conceptual aspects of the underlying statistical problem (see [103] for further details). Rather, they primarily reflect the complexity of its measure-theoretic formulation. ", "page_idx": 23}, {"type": "text", "text": "B.6 Deficiency and Expected Risk [63] ", "text_level": 1, "page_idx": 23}, {"type": "text", "text": "In 1964, Le Cam [63] clarified the relationship between the sufficiency of an embedding model on a given task and its expected risk on this task. The following theorem provides a formal statement of this relationship. ", "page_idx": 23}, {"type": "text", "text": "Theorem 1 (Le Cam [63]). Let $\\varepsilon>0$ be fixed. Then, $\\delta(P_{U|Y}\\rightarrow P_{V|Y})<\\varepsilon$ if and only if, for any bounded loss function $\\ell$ where $\\|\\ell\\|_{\\infty}\\leqslant1$ , and for any inference procedure $\\rho_{V}$ using the embedding model $P_{V|Y}$ , there exists a inference procedure (possibly randomized) $\\rho_{U}$ based the embedding model $P_{U|Y}$ such that the risks satisfy $\\mathcal{R}_{y}(P_{U|Y},\\rho_{U},\\ell)-\\varepsilon\\leqslant\\mathcal{R}_{y}(P_{V|Y},\\rho_{V},\\ell)$ , for all $y\\in\\mathsf{Y}$ . ", "page_idx": 23}, {"type": "text", "text": "C NLP Experiment Details ", "text_level": 1, "page_idx": 23}, {"type": "text", "text": "In this section, we provide all the necessary experimental details to reproduce the experiments in NLP. For the $\\overline{{\\mathcal{T}_{S}}}$ score estimation, please see Appendix E. First, we detail the models and datasets used in the experiments. We provide the training details of the downstream tasks, and finally, we present the comprehensive results of the NLP experiments. ", "page_idx": 23}, {"type": "text", "text": "C.1 Models and Datasets statistics ", "text_level": 1, "page_idx": 23}, {"type": "text", "text": "In Tab. 1, we provide the metadata of the models used in the NLP experiments and their scores on the MTEB benchmark when they exist. We provide in Tab. 2 the statistics of the datasets used to evaluate the $\\overline{{\\mathcal{T}_{S}}}$ score. ", "page_idx": 23}, {"type": "text", "text": "C.2 Downstream tasks training details. ", "text_level": 1, "page_idx": 23}, {"type": "text", "text": "All the downstream tasks are trained in the exact same way. We use a dense classifier with two hidden layers of dimension 256 and train for two epochs using ADAM [56] with a learning rate of $10^{-3}$ , on the official training set and evaluated on either the validation or test set when they are available (with respect to the Huggingface datasets). We do not perform early stopping or selection using the validation set. ", "page_idx": 23}, {"type": "text", "text": "C.3 NLP Comprehensive Results ", "text_level": 1, "page_idx": 23}, {"type": "text", "text": "We provide in this section the unaggregated results for the main NLP experiments presented in the main text, then we provide numerous ablation studies and additional results to address different aspects of the $\\overline{{\\mathcal{T}_{S}}}$ score of the embeddings in NLP. ", "page_idx": 23}, {"type": "text", "text": "C.3.1 Full MTEB Benchmark Results", "text_level": 1, "page_idx": 23}, {"type": "text", "text": "The strength of the MTEB benchmark is that it evaluates embedders on a very large and diverse set of downstream tasks. We provide an Tab. 4 and Figure 6 the full results of the MTEB benchmark (English) for the models used in the NLP experiments. ", "page_idx": 23}, {"type": "table", "img_path": "VqFz7iTGcl/tmp/366c538910ff8bb7b4009bf302cc6ae4d0e617b7ab2fad184344a16a958755cf.jpg", "table_caption": ["Table 1: Metadata of the evaluated models and their information sufficiency. "], "table_footnote": [], "page_idx": 24}, {"type": "image", "img_path": "VqFz7iTGcl/tmp/99210367333aa6cbf7eebe11a731fd583d75a01a0e7fe4190b3587eaded37feb.jpg", "img_caption": ["Figure 6: Correlations between rankings on different subtasks and their $\\overline{{\\mathcal{T}_{S}}}$ score ranking. "], "img_footnote": [], "page_idx": 24}, {"type": "table", "img_path": "VqFz7iTGcl/tmp/40291d84d42e4c109fadb6f88a0e9d2995e1081a9286183cf111c735d43ce7e6.jpg", "table_caption": ["Table 2: Statistics of the datasets used as umbrella datasets for $\\overline{{\\mathcal{T}_{S}}}$ informativeness evaluation. "], "table_footnote": [], "page_idx": 25}, {"type": "text", "text": "We obtain significant positive correlations in all categories of downstream tasks. We noticed that we obtained significantly poorer results on STS, Clustering, and Reranking tasks than on classification tasks. We believe this behavior is due to the nature of these tasks. Indeed, they do not rely on training an additional model on top of the embeddings but rather directly use the embeddings as is in dot products or similarity measures. An embedder could produce very informative embeddings, i.e., it is possible to extract the useful information using a small model, and at the same time, these embeddings not be adequate for dot-product-based similarity measures. We believe further investigation is needed to understand the behavior of the models on these tasks. Especially to see if training a small model on top of the embeddings can improve the performance of these tasks. ", "page_idx": 25}, {"type": "text", "text": "C.3.2 Ablation studies ", "text_level": 1, "page_idx": 25}, {"type": "text", "text": "Many factors can impact the estimation of the $\\overline{{\\mathcal{T}_{S}}}$ score of the models, such as the dimensions of the different embeddings and the number of available embedders to evaluate. the $\\overline{{\\mathcal{T}_{S}}}$ score can capture many different aspects of the embeddings, such as the quality of the embeddings. We provide in this section a comprehensive set of ablation studies to evaluate the impact of these different factors on the $\\overline{{\\mathcal{T}_{S}}}$ score of the embeddings. ", "page_idx": 25}, {"type": "table", "img_path": "VqFz7iTGcl/tmp/5534a26ecd5f7d1bb454c1c7a696754678dbdb49fdc4c229bc41228f78fa9b1b.jpg", "table_caption": ["Table 3: Summary of the evaluated embedders with their performance on the MTEB benchmark. "], "table_footnote": [], "page_idx": 26}, {"type": "text", "text": "Impact of instruction finetuning. Instruction finetuning is now a common practice to improve the alignment of the base of models and expand the models\u2019 reasoning capabilities. In Figure 4c, show that instruction fine-tuning positively impacts the models\u2019 performance on the downstream tasks and that the $\\overline{{\\mathcal{T}_{S}}}$ score captures this improvement. In addition to studying the impact of instruction finetuning, we evaluated models at different checkpoints during their initial pretraining in Sec. C.3.3 using the CroissantLLM checkpoints [37]. ", "page_idx": 26}, {"type": "text", "text": "C.3.3 Impact of training steps ", "text_level": 1, "page_idx": 26}, {"type": "text", "text": "Surprisingly, we found that the number of training steps does not significantly impact the models\u2019 performance on the downstream tasks nor on the $\\overline{{\\mathcal{T}_{S}}}$ score of the embeddings. The $\\overline{{\\mathcal{T}_{S}}}$ score correctly captures this behavior as shown in Figure 7. We hypothesize that the $\\overline{{\\mathcal{T}_{S}}}$ score in terms of embeddings is, in this case, determined by a few numbers of training steps (the first 5000) and the overall architecture of the model. Training the model further even leads to a decrease in performance on the downstream tasks, which is not captured by the $\\overline{{\\mathcal{T}_{S}}}$ score of the embeddings; this could be due to the very small variation in the performance. ", "page_idx": 26}, {"type": "text", "text": "C.3.4 Importance of embedding size normalization ", "text_level": 1, "page_idx": 26}, {"type": "text", "text": "We found that considering the amount of information packed by an embedding per coordinate is crucial to obtain a good ranking of the models. In Figure 16b, we show the correlation between the performance of the models on the MTEB benchmark and their $\\overline{{\\mathcal{T}_{S}}}$ score, not normalized by embedding size. While positive significative correlation is still present, the correlation is much weaker than when the dimension of the embeddings normalizes the information sufficiency. ", "page_idx": 26}, {"type": "table", "img_path": "VqFz7iTGcl/tmp/41e52e94f8cffa0c5620acfb6beeb86c28ab4e7a6cb27cabd830015c20c5cd33.jpg", "table_caption": [], "table_footnote": ["Table 4: Detailed correlations between the $\\overline{{\\mathcal{T}_{S}}}$ score of the models and their performance on the MTEB benchmark. "], "page_idx": 27}, {"type": "image", "img_path": "VqFz7iTGcl/tmp/fe3af43c4f96119e8e9dee485236d13d2055972c9767af2e7e1339e5c63434fd.jpg", "img_caption": ["Figure 7: Impact of the number of training steps on the performance of the models on the downstream tasks and their $\\overline{{\\mathcal{T}_{S}}}$ score. "], "img_footnote": [], "page_idx": 28}, {"type": "text", "text": "C.3.5 Community and cluster performance ", "page_idx": 28}, {"type": "image", "img_path": "VqFz7iTGcl/tmp/cad6c0efedd9a53b8693f6e11cbfb21e5d257ce84bb3b19f80a4d7364c1ca02f.jpg", "img_caption": ["Figure 8: We present different interesting properties of $\\overline{{\\mathcal{T}_{S}}}$ . In Figure $4\\mathrm{a}$ , we show that it can be used to cluster models Figure 8b, reports the performance of the models on the different task categories. They are grouped by similar behaviors on these tasks (dendrograms) and colored by the communities discovered in the information sufficiency graph. (Only models evaluated as part of the MTEB benchmark are shown). "], "img_footnote": [], "page_idx": 28}, {"type": "image", "img_path": "VqFz7iTGcl/tmp/f534efcb4df3cb56ab62b09282e574886fcb993a21dfc78ada0c37a46c71a0b0.jpg", "img_caption": ["Figure 9: Performance of the models on the downstream tasks grouped by clusters discovered by the directed $\\overline{{\\mathcal{T}_{S}}}$ . "], "img_footnote": [], "page_idx": 29}, {"type": "text", "text": "We postulate that models clustered together by information sufficiency are likely to behave similarly on the downstream tasks. We evaluate this hypothesis by grouping the models by clusters discovered using the information sufficiency and reporting their performance on the downstream tasks. In Figure 8b and Figure 9, we observe that models within the same cluster tend to have similar behaviors on the downstream tasks. ", "page_idx": 29}, {"type": "text", "text": "C.3.6 Evaluating information sufficiency on different datasets ", "text_level": 1, "page_idx": 29}, {"type": "text", "text": "The $\\overline{{\\mathcal{T}_{S}}}$ score is evaluated with a fixed dataset supposed to represent the data distribution of interest (either a very diverse set or a subset following a distribution specific to a subfield like medical or legal texts). We cross-evaluated the $\\overline{{\\mathcal{T}_{S}}}$ of the models on different datasets and the performance of the models on the downstream tasks in Figure 10. We find that closer datasets in terms of the data distribution lead to a higher correlation between the $\\overline{{\\mathcal{T}_{S}}}$ score of the models and their performance on the downstream tasks. It is especially highlighted when comparing the correlations we get when evaluating $\\overline{{\\mathcal{T}_{S}}}$ on the AG News and Amazon polarity datasets. The first one corresponds to news articles, and the task is to guess the topic, whereas Amazon Polarity corresponds to product reviews, which is a sentiment analysis task. We find that the $\\overline{{\\mathcal{T}_{S}}}$ score evaluated on Amazon Polarity tends to yield way better correlation with the performance on the sentiment analysis downstream tasks such as tweet_eval/sentiment, tweet_eval/emotion, IMDB or Rotten Tomatoes or to a lesser extent dair/emotion. Interestingly, the difference is less significant on the tweet_eval/emoji subtask. ", "page_idx": 29}, {"type": "image", "img_path": "VqFz7iTGcl/tmp/92438c634988cbf99da09654912241874ed0c1d3ccc0d448a7710980eab8f2dd.jpg", "img_caption": ["Figure 10: Correlation between $\\overline{{\\mathcal{T}_{S}}}$ scores computed on different datasets and the cross-performance on different tasks. "], "img_footnote": [], "page_idx": 30}, {"type": "text", "text": "", "page_idx": 30}, {"type": "text", "text": "D Molecular Experiment Details ", "text_level": 1, "page_idx": 30}, {"type": "table", "img_path": "VqFz7iTGcl/tmp/ae1cb9371dd313cddd37fcb1ab20f3af6432c619a8aae35552ae2d451eed8d67.jpg", "table_caption": ["D.1 Embedders considered ", "Table 5: Models evaluated on the ZINC dataset. "], "table_footnote": [], "page_idx": 30}, {"type": "text", "text": "We considered 28 models for the molecular experiments, summed up in Tab. 5. Some models were used in different versions (architectures, number of parameters, pretraining dataset\u2019s size), such as the ChemBert models, followed by the size of their datasets, or ChemGPT, followed by their number of parameters. ", "page_idx": 30}, {"type": "text", "text": "Most 2D-GNNs were trained on the GEOM [6] dataset and were gathered from the repository of GraphMVP [67] model. Note that the MoleOOD [117] model was trained on the BACE [47] dataset, with a supervised task specific to the $\\beta$ -secretase enzyme. As a result, this model can be seen as \"already specialized\", explaining its poor performance in our evaluation. ", "page_idx": 30}, {"type": "image", "img_path": "VqFz7iTGcl/tmp/cbc4ffa1da036769a4d0b01cb371ef75f9fd27d7fffd4a6f3ea8cf2f0adef820.jpg", "img_caption": ["Figure 11: (a) Information sufficiency of embedders over 3D-Denoising models (left) and of 3DDenoising models over the other embedders (right). (b) Information sufficiency of embedders in both directions. We see the 3D denoising models are among the least predicted models. "], "img_footnote": [], "page_idx": 31}, {"type": "text", "text": "We used the RD-Kit and Datamol tool-kits[61, 71] to pre-process the molecules and to generate three-dimensional conformers for 3D-models. To run the models using 3D views of the molecules, we generated five conformers (possible 3D configuration of the molecule) for each SMILES and kept the conformer with the lowest energy. Note that this methodology is imperfect, as the 3D coordinates might be noisy; however, we followed the same procedure to pre-process the ZINC dataset, to evaluate the information sufficiency, and on the datasets corresponding to each downstream task. ", "page_idx": 31}, {"type": "text", "text": "Finally we considered a variety of models architecture for 2D-GNNs notably graph isomorphism network (GIN) [115], principal neighbor aggregation networks (PNA) [26], graph convolutional network (GCN) [33], graph attention network (GAT) [110], topology adaptive graph convolutional networks (TAG) [32] and GraphSAGE [44]. For SMILES-based models, backbones are inspired by BERT [31], RoBERTa [69], and GPT [40]. Finally, both our 3D models use TorchMD-net[80] as a backbone. ", "page_idx": 31}, {"type": "text", "text": "D.2 Details on the information sufficiency estimation ", "text_level": 1, "page_idx": 31}, {"type": "text", "text": "3D models. The two 3D models considered (FRAD [39] and Denoising [121]) obtain high $\\overline{{\\mathcal{T}_{S}}}$ scores while being among the least predictable (Figure 11b and Figure 12). This suggests that these models capture 3D-specific features inaccessible from other modalities while maintaining sufficient overlap to predict them. ", "page_idx": 31}, {"type": "text", "text": "2D-3D models Some 2D-GNNs we considered (GraphMVP and 3D-infomax) are trained to maximize the mutual information between their embeddings and 3D representations of the molecule. Hence, we expect these models to be related to the 3D-denoising models we considered. However, we observe in Figure 11a that these models do not achieve particularly high information sufficiency scores over 3D-denoising models. On the other hand, the 3D models achieve high information sufficiency scores over them, which might suggest that these 2D models and 3D-denoising models share information that is easier to access from the 3D models. However, we want to point out that GraphMVP and 3D-infomax are both among the most predicted models; that is to say, among the other models in our pool, they achieve the highest information sufficiency scores. ", "page_idx": 31}, {"type": "image", "img_path": "VqFz7iTGcl/tmp/aa9aab2c2dd4aa30ed2464748ca48f4b048366f06794ea40e827b704d506e87d.jpg", "img_caption": ["Figure 12: Pairwise information sufficiency between molecular embedders. "], "img_footnote": [], "page_idx": 32}, {"type": "text", "text": "D.3 Complementary results on ADMET tasks ", "text_level": 1, "page_idx": 32}, {"type": "text", "text": "The datasets chosen for the molecular experiments are extracted from the Therapeutics Data Commons (TDC) [49] platform. We focused our experiments on ADMET tasks, crucial for drug discovery and development, which results in a total of 31 tasks, described in Tab. 6. ", "page_idx": 32}, {"type": "table", "img_path": "VqFz7iTGcl/tmp/6a9624744d6ea8e14a3ff6491c31aa31bb9938d854c04de298e21afd67e19fe7.jpg", "table_caption": [], "table_footnote": [], "page_idx": 32}, {"type": "text", "text": "Each dataset is split into a training set, a validation set, and a test set following a scaffold split. This splitting strategy ensures that molecules sharing a similar scaffold will be part of the same split in the task. This corresponds to a more realistic scenario, where practitioners only have access ", "page_idx": 32}, {"type": "text", "text": "Table 7: Hyperparameters tuned for the evaluation of embedders on ADMET downstream tasks ", "page_idx": 32}, {"type": "text", "text": "to molecules belonging to the same chemical series. Classifiers are then trained on the training set of each task, where the best hyperparameters and checkpoints are selected on the validation set. The final performance is finally measured on the test set, and we run each experiment 10 times with different random seeds. ", "page_idx": 32}, {"type": "text", "text": "A grid search is performed on each dataset individually to maximize the average AUROC or $R^{2}$ score across all models for binary classification and regression. We chose a maximum number of epochs depending on the task size to ensure all models have time to converge, limiting this amount to grow to at most 200 epochs. ", "page_idx": 32}, {"type": "text", "text": "Tab. 6 also displays the variation of the correlation coefficient between the ranking obtained on the $\\overline{{\\mathcal{T}_{S}}}$ score and the performances obtained on the downstream tasks regarding Spearman and Kendall correlations. We can see that the $\\overline{{\\mathcal{T}_{S}}}$ score correlates well with the performance of downstream tasks when the amount of data available is large. ", "page_idx": 32}, {"type": "text", "text": "Finally, we can see in Figure 13 that by grouping models based on their performances on these tasks, we obtain a similar clustering to the one obtained on the $\\overline{{\\mathcal{T}_{S}}}$ score in Sec. 6.2, with NLP-inspired models grouped. Similarly, the tinyChemBert-MTR and MolR models are also grouped. ", "page_idx": 32}, {"type": "table", "img_path": "VqFz7iTGcl/tmp/b2120005a424358ebcafe1864b6c051780fbef88b3244687eb6c5b55aa218d34.jpg", "table_caption": [], "table_footnote": ["Table 6: ADMET tasks extracted from the Therapeutic Data Commons platform [49] considered in our experiments. We report the correlation between the informativeness score and the performances of the embedders on the downstream tasks in terms of Pearson correlation $\\varrho_{p}$ , Spearman correlation $\\varrho_{s}$ and Kendall-Tau $\\tau$ . We also report the average metric of the models on each task across the grid search runs, in terms of $R^{2}$ for regression tasks and AUROC for classification tasks. The tasks are ordered within each category by the correlation with the informativness score (in terms of Spearman correlation). "], "page_idx": 33}, {"type": "image", "img_path": "VqFz7iTGcl/tmp/18397445467dfaf30566eeeae3368c2bab75be20008a889e441d69afc27fe2af.jpg", "img_caption": ["Figure 13: Heatmap representation of the performances of the different models on the downstream tasks, where embedders behaving similarly on the various tasks are clustered, and the embedders are colored based on their community computed in Sec. 6.2 based on the $\\overline{{\\mathcal{T}_{S}}}$ score. "], "img_footnote": [], "page_idx": 34}, {"type": "text", "text": "D.4 Drug target Interaction prediction ", "text_level": 1, "page_idx": 34}, {"type": "text", "text": "We propose further evaluating the embedders on yet another type of downstream task: Drug-Target Interaction. This task aims to predict the binding affinity between a given pair (drug, target). Since none of our models can process protein sequences, we decompose each dataset into multiple regression tasks on a single target by querying all molecules associated with a label for this target. Each task is then formulated as a set of molecules: $\\mathcal{X}=\\{x_{i}\\}_{i\\in\\{0,...,N\\}}$ , and their labels $\\mathcal{Y}=\\{y_{i}\\}_{i\\in\\{0,...,N\\}}$ ", "page_idx": 34}, {"type": "text", "text": "However, such tasks can be small, making it hard to build proper models from the embeddings. In contrast, the number of tasks is very large, making it computationally expensive to proceed to an adequate hyperparameter selection. To bypass these limitations, we propose to estimate the embedded space\u2019s clustering quality for each model by measuring how close the labels of a molecule are compared to its nearest neighbors for each task. In other words, we measure: ", "page_idx": 34}, {"type": "image", "img_path": "VqFz7iTGcl/tmp/ac6dea663aca1eb3a6c496ddc325b2e2c67b280d8d81789e90a3989d28e80ce7.jpg", "img_caption": ["Figure 14: Correlations of the $\\overline{{\\mathcal{T}_{S}}}$ score with the performances on the DTI tasks, in terms of Spearman and Kendall coefficients. "], "img_footnote": [], "page_idx": 34}, {"type": "text", "text": "", "page_idx": 35}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\Tilde{\\mathcal{L}}_{n_{\\mathrm{neigh}}}(\\mathcal{X},\\mathcal{Y})=\\displaystyle\\frac{1}{N}\\sum_{i=0}^{N}\\mathcal{L}_{n_{\\mathrm{neigh}}}(i,\\mathcal{X},\\mathcal{Y}),}&{}\\\\ {\\mathrm{with}\\quad\\mathcal{L}_{n_{\\mathrm{neigh}}}(i,\\mathcal{X},\\mathcal{Y})=\\displaystyle\\frac{1}{n_{\\mathrm{neigh}}}\\sum_{j\\in\\mathcal{N}_{i,n_{\\mathrm{neigh}}}(\\mathcal{X})}\\|y_{i}-y_{j}\\|^{2},}\\end{array}\n$$", "text_format": "latex", "page_idx": 35}, {"type": "text", "text": "and $\\mathcal{N}_{i,n_{\\mathrm{neigh}}}(\\mathcal{X})$ is the set containing the $n_{\\mathrm{{neigh}}}$ closest neighbors of $x_{i}\\in\\mathcal{X}$ , which would be the performances of a K-nearest neighbors regressor on the task when using one data sample. ", "page_idx": 35}, {"type": "text", "text": "This quantity can be interpreted as a proxy of the embedding\u2019s capability to perform a similarity search, a classic chemo-informatic method using the similarity between different molecular projections to perform predictions. This training-free and computationally inexpensive approach allows us to evaluate the models on many tasks/targets. ", "page_idx": 35}, {"type": "text", "text": "We focused on $4~\\mathrm{DTI}$ datasets: KIBA [101], BindingDB-Kd, BindingDB-Ki, and BindingDBIC50 [68], with a total of 1496 tasks. We removed all tasks containing less than 128 molecules to ensure minimum data for the clustering evaluation. ", "page_idx": 35}, {"type": "table", "img_path": "VqFz7iTGcl/tmp/3d055ceac8a1db36249078b6f407f74dcdc5a243e52795b5cbaf6188b543220c.jpg", "table_caption": [], "table_footnote": [], "page_idx": 35}, {"type": "text", "text": "Table 8: Correlation between IS\u2019s informativness score and our clustering evaluation score L\u02dcnneighb on the four DTI datasets considered. ", "page_idx": 35}, {"type": "text", "text": "We obtain similar results as in Sec. 6.1, our metric correlating with the performances on the different tasks considered. Figure 14 sums up all results by establishing a ranking across models and the number of neighbors, where we can see that MolR and ChemBerta-MTR appear as both the most promising models according to their $\\overline{{\\mathcal{T}_{S}}}$ score, and the best models evaluated. Furthermore, the outliers observed inSec. 6.1 show different behaviors in this setting. For instance, while 3D-Infomax seemed under-estimated and InfoGraph over-estimated by the $\\overline{{\\mathcal{T}_{S}}}$ score after seeing the results on the ADMET tasks, Infograph appears under-estimated in this setup, and 3D-infomax over-estimated. ", "page_idx": 35}, {"type": "text", "text": "E Information Sufficiency Estimation ", "text_level": 1, "page_idx": 35}, {"type": "text", "text": "E.1 Estimation method ", "text_level": 1, "page_idx": 35}, {"type": "text", "text": "As stated in Sec. 2, the deficiency $\\delta(P_{U|X}\\to P_{Z|X})$ is an intractable object measuring the cost of the reconstruction of $Z$ from $U$ . Due to this intractability, we propose to estimate the information sufficiency ${\\mathcal{Z}}_{S}(U\\to Z)$ , which is a tractable proxy for the deficiency. ", "page_idx": 35}, {"type": "text", "text": "E.1.1 KNIFE Estimator ", "text_level": 1, "page_idx": 35}, {"type": "text", "text": "We recall the definition of the information sufficiency: ", "page_idx": 35}, {"type": "equation", "text": "$$\n\\mathcal{Z}_{S}(U\\to Z)\\triangleq\\operatorname*{inf}_{f\\in\\mathcal{F}_{\\Theta}(Z)}\\mathbb{E}\\left[-\\log f(Z)\\right]-\\mathbb{E}\\left[\\operatorname*{inf}_{M\\in K_{\\Theta}(Z|\\mathsf{U})}\\mathbb{E}\\left[-\\log M(Z|U)|U\\right]\\right].\n$$", "text_format": "latex", "page_idx": 35}, {"type": "text", "text": "We denote $C$ the number of modes chosen for the Gaussian mixture distributions and $\\mathrm{GM}_{\\mu,\\Sigma,w}$ the Gaussian mixture distribution with $C$ components, parametrized by $\\textstyle\\mu,\\Sigma,w$ , with $\\mathbf{1}^{T}\\boldsymbol{w}=1$ , such that ", "page_idx": 35}, {"type": "text", "text": "$\\begin{array}{r}{\\mathrm{GM}_{\\mu,\\Sigma,w}(z)\\ =\\ \\sum_{c=1}^{C}w_{c}\\mathcal{N}(z|\\mu_{c},\\Sigma_{c})}\\end{array}$ , where $\\mathbf{w}_{c}$ is the weight of the $c$ -th component, and $\\mathcal{N}(\\boldsymbol{\\hat{z}}|\\mu_{c},\\Sigma_{c})$ is th e  density of a multivariate Gaussian distribution with mean $\\pmb{\\mu_{c}}$ and covariance the $\\mathrm{^c}$ -th mean and covariance matrix. ", "page_idx": 36}, {"type": "text", "text": "To estimate the information sufficiency between the two embedders $U$ and $Z$ , we follow the procedure described in KNIFE [82]. ", "page_idx": 36}, {"type": "text", "text": "$\\mathcal{F}_{\\Theta}$ is hence the class of multivariate Gaussian mixtures with $C$ components, it is parametrized by $\\textstyle\\mu,\\Sigma,w$ . These learnable parameters are optimized to maximize the log-likelihood of $Z$ .8 ", "page_idx": 36}, {"type": "text", "text": "The class of Markov kernels $\\kappa_{\\Theta}(Z|\\cup)$ is also composed of multivariate Gaussian mixtures whose parameters are estimated using a small feedforward neural network. Such that for each $u\\in\\mathsf{U}$ , the parameters of the Gaussian mixture are $\\pmb{\\mu}(u),\\pmb{\\Sigma}(u),\\pmb{w}(u)$ . ", "page_idx": 36}, {"type": "text", "text": "In practice we considered the covariance matrix to be diagonal to avoid the number of parameters of the Gaussian mixtures to grow too large with the dimension of the embeddings $d$ . The number of parameters to be estimated for the Gaussian mixtures are hence: $C\\times(2d+1)$ , with the number of parameters of the feedforward networks for the Markov kernels. ", "page_idx": 36}, {"type": "table", "img_path": "VqFz7iTGcl/tmp/e0a3444e8f90c227f8aaa11ebf1913b70d7c1c23c68ac653ecc6a795c3cb912c.jpg", "table_caption": [], "table_footnote": [], "page_idx": 36}, {"type": "text", "text": "Both the parameters of the marginal distribution of $Z$ and the parameters of the conditional distribution of $Z$ given $U$ are estimated through likelihood maximization. The uncertainty of $Z$ is estimated by the negative log-likelihood of the data under the marginal distribution of $Z$ . The uncertainty of $Z$ given $U$ is estimated by the negative log-likelihood of the data under the conditional distribution of $Z$ given $U$ . ", "page_idx": 36}, {"type": "text", "text": "E.1.2 Embedding dimension normalization. ", "text_level": 1, "page_idx": 36}, {"type": "text", "text": "However, this approach faces one major drawback: it favors models that generate embeddings of high dimensionality. To evaluate the information sufficiency between the models, we estimate the uncertainty of $Z$ and the uncertainty of $Z$ given $U$ . As seen in Figure 15, the estimated information sufficiency is highly correlated to the dimension of the latent space of $Z$ , favoring models with high-dimensional latent spaces. This can be explained by the fact that these embedders yield larger marginal uncertainties. The resulting difference in the uncertainties ${\\mathcal{Z}}_{S}(U\\to Z)$ is hence larger in absolute values. ", "page_idx": 36}, {"type": "text", "text": "We can see in Figure 15 that the dimension of the latent space of $Z$ and the uncertainty of $Z$ are evolving linearly. We thereby divide the information sufficiency by $d i m(Z)$ , which can be seen as an approximation of the normalization by the uncertainty of $Z$ . We report in Figure 16b results without this normalization. It still correlates significantly with the downstream tasks performance, but the correlation is stronger when the normalization is applied. Hence, we focus on the relative variation of the uncertainty of $Z$ explained by $U$ . Note that the uncertainty of $Z$ can be negative, as it can be assimilated to a differential entropy. As a result, the \u201ctrue\u201c relative variation of the uncertainty would not be suitable for comparing different models (as it would not guarantee any ordering). While there is a general trend where larger models do have larger embeddings and perform better, well-trained smaller embeddings are competitive with larger embeddings, and the $\\overline{{\\mathcal{T}_{S}}}$ score captures this behavior (Figure 16a). ", "page_idx": 36}, {"type": "image", "img_path": "VqFz7iTGcl/tmp/7406aae63b8662c1ea246642391ed3b1a3e9bf69fb54d46e0ee23adce0db5497.jpg", "img_caption": ["Dimension of Z "], "img_footnote": [], "page_idx": 37}, {"type": "text", "text": "Figure 15: Relationship between the dimension of $Z$ \u2019s latent space and the quantities estimated to compute the information sufficiency in molecular modeling. ", "page_idx": 37}, {"type": "text", "text": "We build our proxy by measuring the median values of the set ${\\cal S}_{\\mathcal{T}_{S}}\\left(k\\right)=\\{\\mathcal{T}_{S}(Z_{k}\\rightarrow Z_{l})\\}_{l\\neq k}$ for an embedder $Z_{k}$ in our pool of models. ", "page_idx": 37}, {"type": "image", "img_path": "VqFz7iTGcl/tmp/8b94e88be259900f6771517cc4ce5f72aa56e45e76178c2c77e3667af4f536a3.jpg", "img_caption": [], "img_footnote": [], "page_idx": 37}, {"type": "text", "text": "(a) Impact of the embedding size on the quality of the embeddings for the models measured as actual performance on downstream tasks and $\\overline{{\\mathcal{T}_{S}}}$ score. ", "page_idx": 37}, {"type": "image", "img_path": "VqFz7iTGcl/tmp/e3858f46d04a172554d1cd27420a85e3878f3258ae7ef79316d617d5b8c5a53c.jpg", "img_caption": ["(b) Correlations on the MTEB benchmark when the embeddings are not normalized by their size. ", "Figure 16 "], "img_footnote": [], "page_idx": 37}, {"type": "text", "text": "E.1.3 Median instead of mean. ", "text_level": 1, "page_idx": 37}, {"type": "text", "text": "We use the median instead of the mean to compute the $\\overline{{\\mathcal{T}_{S}}}$ score. The median is more robust to outliers and the distribution of available embedders. For example, if many models are very similar, the mean would be biased by these models, while the median would not. Thus, we chose the median. While this change has a minor impact when there is enough diversity in the models, it can have a significant impact when the models are very similar, for example, when including different checkpoints of the same model Figure 17. ", "page_idx": 37}, {"type": "image", "img_path": "VqFz7iTGcl/tmp/adb5b6f820244affaadb0ef487abbe1d1e73907f0d06c1d296facb3b5394c56f.jpg", "img_caption": ["Figure 17: Correlation between $\\overline{{\\mathcal{T}_{S}}}$ score computed as the mean information sufficiency and the downstream task performances in NLP. $\\varrho_{p}$ is the Pearson correlation, $\\varrho_{s}$ is the spearman correlation "], "img_footnote": [], "page_idx": 38}, {"type": "text", "text": "E.2 Hyperparameter selection ", "text_level": 1, "page_idx": 38}, {"type": "text", "text": "We use parametric classes composed of multivariate Gaussian mixture distributions for $\\mathcal{F}_{\\Theta}$ and $\\kappa_{\\Theta}(Z|\\bar{\\cup})$ in the definition of the information sufficiency (Eq. 27), the number of components in the mixture is a crucial parameter that needs to be selected concerning the data distribution of interest. We ran ablation studies to evaluate the impact of the number of components in the mixture on the information sufficiency estimation and the correlation between the $\\overline{{\\mathcal{T}_{S}}}$ score and the downstream tasks performance (Figure 20). We found that the ideal number of components in NLP is 8, and in molecular modeling, it is 4. Figure 18 and Figure 19 show the embeddings of the models in the first two principal components. ", "page_idx": 38}, {"type": "image", "img_path": "VqFz7iTGcl/tmp/3b72b0bb288ad81a526bd8d2202d245e3382ee21dbf38b34e5a18211e4275743.jpg", "img_caption": ["Figure 20: Impact of the number of modes used to estimate the $\\overline{{\\mathcal{T}_{S}}}$ score and its correlation with the downstream tasks performance in NLP. We chose to use 8 modes in practice. "], "img_footnote": [], "page_idx": 38}, {"type": "text", "text": "E.3 Impact of the task size ", "text_level": 1, "page_idx": 38}, {"type": "text", "text": "Our study focused on finding the most promising model to be competitive on any downstream tasks. However, if the downstream task is not learnable, the most promising model could appear as not competitive on this specific task. In particular, if the amount of data available in the downstream task is insufficient, the differences between different embedder\u2019s representations might not be easily leveraged. This phenomenon can be seen in Figure 21, highlighting how when fewer than 1000 data points are available, the correlation between the $\\overline{{\\mathcal{T}_{S}}}$ score and the downstream performance becomes weaker. ", "page_idx": 38}, {"type": "image", "img_path": "VqFz7iTGcl/tmp/d7788b236b21618c30fb149260a45323ef2200c71762b86de1aec7a7b9c2eff6.jpg", "img_caption": ["Figure 18: 2D Projection of the embeddings of the models in the first two principal components colored by datasets in NLP "], "img_footnote": [], "page_idx": 39}, {"type": "image", "img_path": "VqFz7iTGcl/tmp/f9625c9c7c2f65dc85ddfa6e6028c3513980cc1fe0bc05695a1deb4f27924e0a.jpg", "img_caption": ["Figure 19: 2D Projection of the embeddings of the models in the first two principal components colored by datasets in molecular modeling. Hue corresponds to the synthetic accessibility score [34]. "], "img_footnote": [], "page_idx": 40}, {"type": "image", "img_path": "VqFz7iTGcl/tmp/6b38742f7cd23390d9284a8361e8525959b89e37e56023ad8bcdf701fd5c76fb.jpg", "img_caption": [], "img_footnote": [], "page_idx": 40}, {"type": "text", "text": "Figure 21: Impact of the task size on the $\\overline{{\\mathcal{T}_{S}}}$ score\u2019s ranking\u2019s correlation with the downstream tasks performances in molecular modeling in terms of Pearson correlation $\\varrho_{p}$ , Spearman correlation $\\varrho_{s}$ and Kendall-Tau $\\tau$ coefficient. ", "page_idx": 40}, {"type": "text", "text": "E.4 Impact of the number of models ", "text_level": 1, "page_idx": 40}, {"type": "image", "img_path": "VqFz7iTGcl/tmp/5acd16b379052eb3e4d50f93f8c8211199bc33556f103bc5df5079a997b2d8a9.jpg", "img_caption": ["Figure 22: Impact of the number of models used to compute the $\\overline{{\\mathcal{T}_{S}}}$ score in NLP. "], "img_footnote": [], "page_idx": 40}, {"type": "text", "text": "We evaluate the strength or $\\overline{{\\mathcal{T}_{S}}}$ score of an embedder with respect to all the others by relaxing the \"for all\" conditions with the median $\\overline{{\\mathcal{T}_{S}}}$ score. Thus, the number of available embedders might impact the performance of our method. Indeed, if too few embedders are available, it is likely that our evaluation would be biased by favoring models similar to the few available ones. We evaluate the impact of the number of available models by sampling subsets of our global model pool to compute the $\\overline{{\\mathcal{T}_{S}}}$ score. In Figure 22, we found that when fewer models are available, the rankings obtained using the $\\overline{{\\mathcal{T}_{S}}}$ score correlate less with the downstream tasks\u2019 performance. However, as the number of models increases, the $\\overline{{\\mathcal{T}_{S}}}$ score becomes a good proxy for the performance of the models on the downstream tasks. ", "page_idx": 40}, {"type": "text", "text": "", "page_idx": 41}, {"type": "text", "text": "However, the evolution of this correlation is different in the two studied domains. Even with very few models, the $\\overline{{\\mathcal{T}_{S}}}$ score of molecular models already achieves a Spearman correlation close to 0.8 with the downstream tasks\u2019 performance. The correlation is much lower in NLP and only reaches 0.8 when about 15 models are available. This result can be expected, seeing how sparse the pairwise comparison matrix is in NLP compared to molecular modeling. This matrix is less sparse on molecular data, the graph induced by this adjacency matrix is more connected, and having access to a few nodes is enough to obtain measurements on the whole graph. On the contrary, by being much sparser, ", "page_idx": 41}, {"type": "image", "img_path": "VqFz7iTGcl/tmp/918b2e4cffcc159dfd88c2cc8a60373682ad27b97a275f9568b9e9593a9a86cd.jpg", "img_caption": ["Figure 23: Impact of the number of models used to compute the $\\overline{{\\mathcal{T}_{S}}}$ score in molecular modeling. "], "img_footnote": [], "page_idx": 41}, {"type": "text", "text": "having access to a few nodes in this graph in NLP might only give information about the local structure of the graph in the community of the few nodes available. This might explain why the $\\overline{{\\mathcal{T}_{S}}}$ score\u2019s correlation with the downstream tasks performance stabilizes in NLP at about ten models, which is equal to the number of communities identified in the graph (in Sec. 5.2). ", "page_idx": 41}, {"type": "text", "text": "E.5 Comparison with other metrics ", "text_level": 1, "page_idx": 41}, {"type": "text", "text": "We evaluate other ways to measure the informativeness (Tab. 9 and Tab. 10) of the embedders. We considered the size of the model, their embeding dimensions and the simple reconstruction error when we train a cross-encoder to go from one embedding to another. Overall we found that our information sufficiency score significantly outperformed these naive metrics in both modalities. ", "page_idx": 41}, {"type": "text", "text": "In particular, training a cross-encoder with the $l_{2}$ reconstruction error proves to correlate with the ability to enable downstream performance, however, this correlation remains weaker compared to using the information sufficiency. ", "page_idx": 41}, {"type": "table", "img_path": "VqFz7iTGcl/tmp/7af5e497415c22f676c4a3ddbfa0a210e7b0e9ea7051a430d9f4e9be68c6e9c7.jpg", "table_caption": ["Table 9: Comparison with Baselines: Size of the Embedder, Dimension of the embedding output $(d)$ and the $\\ell_{2}$ reconstruction error of the embeddings for NLP datasets. "], "table_footnote": [], "page_idx": 41}, {"type": "table", "img_path": "VqFz7iTGcl/tmp/c776650fba6cc9217f2b1e033b43114d8b2708618db8bd31bbbedbcd41712300.jpg", "table_caption": ["Table 10: Comparison with Baselines: Size of the Embedder, Dimension of the embedding output $(d)$ and the $\\ell_{2}$ reconstruction error of the embeddings for Molecular Modeling datasets. "], "table_footnote": [], "page_idx": 41}, {"type": "text", "text": "E.6 Computational ressources ", "text_level": 1, "page_idx": 42}, {"type": "text", "text": "Evaluating the $\\overline{{\\mathcal{T}_{S}}}$ score of the models is computationally inexpensive. Evaluating the $\\overline{{\\mathcal{T}_{S}}}$ score requires only a single (small) GPU. All our experiments were conducted on NVIDIA V100 and NVIDIA A6000 GPUs. ", "page_idx": 42}, {"type": "text", "text": "Our method\u2019s main (computational) shortcoming stems from the need to compute the information sufficiency between all pairs of models. This is a quadratic operation in the number of models. However, in practice, optimizing and estimating the information sufficiency presented in Sec. 3 is cheap. The complete evaluation of the 45 NLP models can be done in less than 6 hours on a single GPU. ", "page_idx": 42}, {"type": "text", "text": "NeurIPS Paper Checklist ", "text_level": 1, "page_idx": 43}, {"type": "text", "text": "1. Claims ", "text_level": 1, "page_idx": 43}, {"type": "text", "text": "Question: Do the main claims made in the abstract and introduction accurately reflect the paper\u2019s contributions and scope? ", "page_idx": 43}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 43}, {"type": "text", "text": "Justification: We setup the problem of evaluating embedders as a communication problem and leverage information theoretic tools to derive a principled evaluation method. ", "page_idx": 43}, {"type": "text", "text": "Guidelines: ", "page_idx": 43}, {"type": "text", "text": "\u2022 The answer NA means that the abstract and introduction do not include the claims made in the paper.   \n\u2022 The abstract and/or introduction should clearly state the claims made, including the contributions made in the paper and important assumptions and limitations. A No or NA answer to this question will not be perceived well by the reviewers.   \n\u2022 The claims made should match theoretical and experimental results, and reflect how much the results can be expected to generalize to other settings.   \n\u2022 It is fine to include aspirational goals as motivation as long as it is clear that these goals are not attained by the paper. ", "page_idx": 43}, {"type": "text", "text": "2. Limitations ", "text_level": 1, "page_idx": 43}, {"type": "text", "text": "Question: Does the paper discuss the limitations of the work performed by the authors? ", "page_idx": 43}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 43}, {"type": "text", "text": "Justification: We provide a separate section \"Conclusion and Limitations\" (Sec. 7) in the main paper and different ablations addressing possible shortcomings of our methods in appendices. ", "page_idx": 43}, {"type": "text", "text": "Guidelines: ", "text_level": 1, "page_idx": 43}, {"type": "text", "text": "\u2022 The answer NA means that the paper has no limitation while the answer No means that the paper has limitations, but those are not discussed in the paper.   \n\u2022 The authors are encouraged to create a separate \"Limitations\" section in their paper.   \n\u2022 The paper should point out any strong assumptions and how robust the results are to violations of these assumptions (e.g., independence assumptions, noiseless settings, model well-specification, asymptotic approximations only holding locally). The authors should reflect on how these assumptions might be violated in practice and what the implications would be.   \n\u2022 The authors should reflect on the scope of the claims made, e.g., if the approach was only tested on a few datasets or with a few runs. In general, empirical results often depend on implicit assumptions, which should be articulated.   \n\u2022 The authors should reflect on the factors that influence the performance of the approach. For example, a facial recognition algorithm may perform poorly when image resolution is low or images are taken in low lighting. Or a speech-to-text system might not be used reliably to provide closed captions for online lectures because it fails to handle technical jargon.   \n\u2022 The authors should discuss the computational efficiency of the proposed algorithms and how they scale with dataset size.   \n\u2022 If applicable, the authors should discuss possible limitations of their approach to address problems of privacy and fairness.   \n\u2022 While the authors might fear that complete honesty about limitations might be used by reviewers as grounds for rejection, a worse outcome might be that reviewers discover limitations that aren\u2019t acknowledged in the paper. The authors should use their best judgment and recognize that individual actions in favor of transparency play an important role in developing norms that preserve the integrity of the community. Reviewers will be specifically instructed to not penalize honesty concerning limitations. ", "page_idx": 43}, {"type": "text", "text": "3. Theory Assumptions and Proofs ", "text_level": 1, "page_idx": 43}, {"type": "text", "text": "Question: For each theoretical result, does the paper provide the full set of assumptions and a complete (and correct) proof? ", "page_idx": 43}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 44}, {"type": "text", "text": "Justification: We provide a complete description of our setting and assumptions used to derive theoretical proofs as well, as the relaxation of the problem to make it tractable (Sec. 2, Appendix B). ", "page_idx": 44}, {"type": "text", "text": "Guidelines: ", "page_idx": 44}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include theoretical results.   \n\u2022 All the theorems, formulas, and proofs in the paper should be numbered and crossreferenced.   \n\u2022 All assumptions should be clearly stated or referenced in the statement of any theorems.   \n\u2022 The proofs can either appear in the main paper or the supplemental material, but if they appear in the supplemental material, the authors are encouraged to provide a short proof sketch to provide intuition.   \n\u2022 Inversely, any informal proof provided in the core of the paper should be complemented by formal proofs provided in appendix or supplemental material.   \n\u2022 Theorems and Lemmas that the proof relies upon should be properly referenced. ", "page_idx": 44}, {"type": "text", "text": "4. Experimental Result Reproducibility ", "text_level": 1, "page_idx": 44}, {"type": "text", "text": "Question: Does the paper fully disclose all the information needed to reproduce the main experimental results of the paper to the extent that it affects the main claims and/or conclusions of the paper (regardless of whether the code and data are provided or not)? ", "page_idx": 44}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 44}, {"type": "text", "text": "Justification: We provide a description of our global experimental protocol in the main paper (Sec. 4) and detailed descriptions for the different field in their respective sections (Appendix C, Appendix D). All the datasets and models used are publicly available and the code to reproduce our results is attached to the submission. ", "page_idx": 44}, {"type": "text", "text": "Guidelines: ", "page_idx": 44}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 If the paper includes experiments, a No answer to this question will not be perceived well by the reviewers: Making the paper reproducible is important, regardless of whether the code and data are provided or not.   \n\u2022 If the contribution is a dataset and/or model, the authors should describe the steps taken to make their results reproducible or verifiable.   \n\u2022 Depending on the contribution, reproducibility can be accomplished in various ways. For example, if the contribution is a novel architecture, describing the architecture fully might suffice, or if the contribution is a specific model and empirical evaluation, it may be necessary to either make it possible for others to replicate the model with the same dataset, or provide access to the model. In general. releasing code and data is often one good way to accomplish this, but reproducibility can also be provided via detailed instructions for how to replicate the results, access to a hosted model (e.g., in the case of a large language model), releasing of a model checkpoint, or other means that are appropriate to the research performed.   \n\u2022 While NeurIPS does not require releasing code, the conference does require all submissions to provide some reasonable avenue for reproducibility, which may depend on the nature of the contribution. For example (a) If the contribution is primarily a new algorithm, the paper should make it clear how to reproduce that algorithm. (b) If the contribution is primarily a new model architecture, the paper should describe the architecture clearly and fully. (c) If the contribution is a new model (e.g., a large language model), then there should either be a way to access this model for reproducing the results or a way to reproduce the model (e.g., with an open-source dataset or instructions for how to construct the dataset). (d) We recognize that reproducibility may be tricky in some cases, in which case authors are welcome to describe the particular way they provide for reproducibility. In the case of closed-source models, it may be that access to the model is limited in ", "page_idx": 44}, {"type": "text", "text": "some way (e.g., to registered users), but it should be possible for other researchers to have some path to reproducing or verifying the results. ", "page_idx": 45}, {"type": "text", "text": "5. Open access to data and code ", "text_level": 1, "page_idx": 45}, {"type": "text", "text": "Question: Does the paper provide open access to the data and code, with sufficient instructions to faithfully reproduce the main experimental results, as described in supplemental material? ", "page_idx": 45}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 45}, {"type": "text", "text": "Justification: We attached the code to the submission and provide instructions to reproduce the results in the main paper and supplemental material. All datasets and models are publicly available and chosen to be easily accessible for reproducibility. ", "page_idx": 45}, {"type": "text", "text": "Guidelines: ", "page_idx": 45}, {"type": "text", "text": "\u2022 The answer NA means that paper does not include experiments requiring code.   \n\u2022 Please see the NeurIPS code and data submission guidelines (https://nips.cc/ public/guides/CodeSubmissionPolicy) for more details.   \n\u2022 While we encourage the release of code and data, we understand that this might not be possible, so \u201cNo\u201d is an acceptable answer. Papers cannot be rejected simply for not including code, unless this is central to the contribution (e.g., for a new open-source benchmark).   \n\u2022 The instructions should contain the exact command and environment needed to run to reproduce the results. See the NeurIPS code and data submission guidelines (https: //nips.cc/public/guides/CodeSubmissionPolicy) for more details.   \n\u2022 The authors should provide instructions on data access and preparation, including how to access the raw data, preprocessed data, intermediate data, and generated data, etc.   \n\u2022 The authors should provide scripts to reproduce all experimental results for the new proposed method and baselines. If only a subset of experiments are reproducible, they should state which ones are omitted from the script and why.   \n\u2022 At submission time, to preserve anonymity, the authors should release anonymized versions (if applicable).   \n\u2022 Providing as much information as possible in supplemental material (appended to the paper) is recommended, but including URLs to data and code is permitted. ", "page_idx": 45}, {"type": "text", "text": "6. Experimental Setting/Details ", "text_level": 1, "page_idx": 45}, {"type": "text", "text": "Question: Does the paper specify all the training and test details (e.g., data splits, hyperparameters, how they were chosen, type of optimizer, etc.) necessary to understand the results? ", "page_idx": 45}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 45}, {"type": "text", "text": "Justification: We provide in Appendix Appendix C and Appendix D the details of the training and test settings for the different fields. We also provide a global description of the experimental protocol in the main paper (Sec. 4). ", "page_idx": 45}, {"type": "text", "text": "Guidelines: ", "page_idx": 45}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments. \u2022 The experimental setting should be presented in the core of the paper to a level of detail that is necessary to appreciate the results and make sense of them. \u2022 The full details can be provided either with the code, in appendix, or as supplemental material. ", "page_idx": 45}, {"type": "text", "text": "7. Experiment Statistical Significance ", "text_level": 1, "page_idx": 45}, {"type": "text", "text": "Question: Does the paper report error bars suitably and correctly defined or other appropriate information about the statistical significance of the experiments? ", "page_idx": 45}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 45}, {"type": "text", "text": "Justification: We provide error bars in the figures and tables of the main paper. In addition we provide robustness checks and ablations in the appendices. ", "page_idx": 45}, {"type": "text", "text": "Guidelines: ", "page_idx": 45}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 The authors should answer \"Yes\" if the results are accompanied by error bars, confidence intervals, or statistical significance tests, at least for the experiments that support the main claims of the paper.   \n\u2022 The factors of variability that the error bars are capturing should be clearly stated (for example, train/test split, initialization, random drawing of some parameter, or overall run with given experimental conditions).   \n\u2022 The method for calculating the error bars should be explained (closed form formula, call to a library function, bootstrap, etc.)   \n\u2022 The assumptions made should be given (e.g., Normally distributed errors).   \n\u2022 It should be clear whether the error bar is the standard deviation or the standard error of the mean.   \n\u2022 It is OK to report 1-sigma error bars, but one should state it. The authors should preferably report a 2-sigma error bar than state that they have a $96\\%$ CI, if the hypothesis of Normality of errors is not verified.   \n\u2022 For asymmetric distributions, the authors should be careful not to show in tables or figures symmetric error bars that would yield results that are out of range (e.g. negative error rates).   \n\u2022 If error bars are reported in tables or plots, The authors should explain in the text how they were calculated and reference the corresponding figures or tables in the text. ", "page_idx": 46}, {"type": "text", "text": "8. Experiments Compute Resources ", "text_level": 1, "page_idx": 46}, {"type": "text", "text": "Question: For each experiment, does the paper provide sufficient information on the computer resources (type of compute workers, memory, time of execution) needed to reproduce the experiments? ", "page_idx": 46}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 46}, {"type": "text", "text": "Justification: We provide the details of the compute resources used in the main paper and appendices in Sec. E.6. ", "page_idx": 46}, {"type": "text", "text": "Guidelines: ", "page_idx": 46}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 The paper should indicate the type of compute workers CPU or GPU, internal cluster, or cloud provider, including relevant memory and storage.   \n\u2022 The paper should provide the amount of compute required for each of the individual experimental runs as well as estimate the total compute.   \n\u2022 The paper should disclose whether the full research project required more compute than the experiments reported in the paper (e.g., preliminary or failed experiments that didn\u2019t make it into the paper). ", "page_idx": 46}, {"type": "text", "text": "9. Code Of Ethics ", "text_level": 1, "page_idx": 46}, {"type": "text", "text": "Question: Does the research conducted in the paper conform, in every respect, with the NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines? ", "page_idx": 46}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 46}, {"type": "text", "text": "Justification: This paper does not involve major ethical concerns and the research conducted in the paper conforms with the NeurIPS Code of Ethics. ", "page_idx": 46}, {"type": "text", "text": "Guidelines: ", "page_idx": 46}, {"type": "text", "text": "\u2022 The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics.   \n\u2022 If the authors answer No, they should explain the special circumstances that require a deviation from the Code of Ethics.   \n\u2022 The authors should make sure to preserve anonymity (e.g., if there is a special consideration due to laws or regulations in their jurisdiction). ", "page_idx": 46}, {"type": "text", "text": "10. Broader Impacts ", "text_level": 1, "page_idx": 46}, {"type": "text", "text": "Question: Does the paper discuss both potential positive societal impacts and negative societal impacts of the work performed? ", "page_idx": 46}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 46}, {"type": "text", "text": "Justification: We only propose model selection method for embedders. The main concern, that is addressed in the paper, is that while our method is theoretically supported and empirically validated, it might not be applicable to all downstream tasks and should be used with caution. ", "page_idx": 47}, {"type": "text", "text": "Guidelines: ", "page_idx": 47}, {"type": "text", "text": "\u2022 The answer NA means that there is no societal impact of the work performed.   \n\u2022 If the authors answer NA or No, they should explain why their work has no societal impact or why the paper does not address societal impact.   \n\u2022 Examples of negative societal impacts include potential malicious or unintended uses (e.g., disinformation, generating fake profiles, surveillance), fairness considerations (e.g., deployment of technologies that could make decisions that unfairly impact specific groups), privacy considerations, and security considerations.   \n\u2022 The conference expects that many papers will be foundational research and not tied to particular applications, let alone deployments. However, if there is a direct path to any negative applications, the authors should point it out. For example, it is legitimate to point out that an improvement in the quality of generative models could be used to generate deepfakes for disinformation. On the other hand, it is not needed to point out that a generic algorithm for optimizing neural networks could enable people to train models that generate Deepfakes faster.   \n\u2022 The authors should consider possible harms that could arise when the technology is being used as intended and functioning correctly, harms that could arise when the technology is being used as intended but gives incorrect results, and harms following from (intentional or unintentional) misuse of the technology.   \n\u2022 If there are negative societal impacts, the authors could also discuss possible mitigation strategies (e.g., gated release of models, providing defenses in addition to attacks, mechanisms for monitoring misuse, mechanisms to monitor how a system learns from feedback over time, improving the efficiency and accessibility of ML). ", "page_idx": 47}, {"type": "text", "text": "11. Safeguards ", "text_level": 1, "page_idx": 47}, {"type": "text", "text": "Question: Does the paper describe safeguards that have been put in place for responsible release of data or models that have a high risk for misuse (e.g., pretrained language models, image generators, or scraped datasets)? ", "page_idx": 47}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 47}, {"type": "text", "text": "Justification: N/A ", "page_idx": 47}, {"type": "text", "text": "Guidelines: ", "page_idx": 47}, {"type": "text", "text": "\u2022 The answer NA means that the paper poses no such risks.   \n\u2022 Released models that have a high risk for misuse or dual-use should be released with necessary safeguards to allow for controlled use of the model, for example by requiring that users adhere to usage guidelines or restrictions to access the model or implementing safety filters.   \n\u2022 Datasets that have been scraped from the Internet could pose safety risks. The authors should describe how they avoided releasing unsafe images.   \n\u2022 We recognize that providing effective safeguards is challenging, and many papers do not require this, but we encourage authors to take this into account and make a best faith effort. ", "page_idx": 47}, {"type": "text", "text": "12. Licenses for existing assets ", "text_level": 1, "page_idx": 47}, {"type": "text", "text": "Question: Are the creators or original owners of assets (e.g., code, data, models), used in the paper, properly credited and are the license and terms of use explicitly mentioned and properly respected? ", "page_idx": 47}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 47}, {"type": "text", "text": "Justification: We provide the citations and direct references of all the datasets and models used in our work. To ensure reproducibility, all the datasets and models used are publicly available and under open licenses. ", "page_idx": 47}, {"type": "text", "text": "Guidelines: ", "page_idx": 47}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not use existing assets.   \n\u2022 The authors should cite the original paper that produced the code package or dataset.   \n\u2022 The authors should state which version of the asset is used and, if possible, include a URL.   \n\u2022 The name of the license (e.g., CC-BY 4.0) should be included for each asset.   \n\u2022 For scraped data from a particular source (e.g., website), the copyright and terms of service of that source should be provided.   \n\u2022 If assets are released, the license, copyright information, and terms of use in the package should be provided. For popular datasets, paperswithcode.com/datasets has curated licenses for some datasets. Their licensing guide can help determine the license of a dataset.   \n\u2022 For existing datasets that are re-packaged, both the original license and the license of the derived asset (if it has changed) should be provided.   \n\u2022 If this information is not available online, the authors are encouraged to reach out to the asset\u2019s creators. ", "page_idx": 48}, {"type": "text", "text": "13. New Assets ", "text_level": 1, "page_idx": 48}, {"type": "text", "text": "Question: Are new assets introduced in the paper well documented and is the documentation provided alongside the assets? ", "page_idx": 48}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 48}, {"type": "text", "text": "Justification: We only created the library that implements our methods (it will be released publicly on github) and the code to reproduce our experiments. Both are documented as part of the code submission as supplementary material. ", "page_idx": 48}, {"type": "text", "text": "Guidelines: ", "page_idx": 48}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not release new assets.   \n\u2022 Researchers should communicate the details of the dataset/code/model as part of their submissions via structured templates. This includes details about training, license, limitations, etc.   \n\u2022 The paper should discuss whether and how consent was obtained from people whose asset is used.   \n\u2022 At submission time, remember to anonymize your assets (if applicable). You can either create an anonymized URL or include an anonymized zip file. ", "page_idx": 48}, {"type": "text", "text": "14. Crowdsourcing and Research with Human Subjects ", "text_level": 1, "page_idx": 48}, {"type": "text", "text": "Question: For crowdsourcing experiments and research with human subjects, does the paper include the full text of instructions given to participants and screenshots, if applicable, as well as details about compensation (if any)? ", "page_idx": 48}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 48}, {"type": "text", "text": "Justification: N/A ", "page_idx": 48}, {"type": "text", "text": "Guidelines: ", "page_idx": 48}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u2022 Including this information in the supplemental material is fine, but if the main contribution of the paper involves human subjects, then as much detail as possible should be included in the main paper.   \n\u2022 According to the NeurIPS Code of Ethics, workers involved in data collection, curation, or other labor should be paid at least the minimum wage in the country of the data collector. ", "page_idx": 48}, {"type": "text", "text": "15. Institutional Review Board (IRB) Approvals or Equivalent for Research with Human Subjects ", "text_level": 1, "page_idx": 48}, {"type": "text", "text": "Question: Does the paper describe potential risks incurred by study participants, whether such risks were disclosed to the subjects, and whether Institutional Review Board (IRB) approvals (or an equivalent approval/review based on the requirements of your country or institution) were obtained? ", "page_idx": 48}, {"type": "text", "text": "Answer: [NA] Justification: N/A Guidelines: ", "page_idx": 49}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u2022 Depending on the country in which research is conducted, IRB approval (or equivalent) may be required for any human subjects research. If you obtained IRB approval, you should clearly state this in the paper.   \n\u2022 We recognize that the procedures for this may vary significantly between institutions and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the guidelines for their institution.   \n\u2022 For initial submissions, do not include any information that would break anonymity (if applicable), such as the institution conducting the review. ", "page_idx": 49}]