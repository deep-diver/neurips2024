[{"figure_path": "hKVTwQQu76/tables/tables_6_1.jpg", "caption": "Table 1: Results on datasets: mean accuracy (%) \u00b1 95% confidence interval. The best result on each dataset is indicated with bold.", "description": "This table presents the mean accuracy and 95% confidence intervals achieved by various node classification methods on ten benchmark datasets.  The methods compared include backpropagation (BP), PEPITA, CaFo (two versions), FF (two versions), FORWARDGNN-SF (SF), and the proposed DFA-GNN. The best performance on each dataset is highlighted in bold.  This provides a quantitative comparison of the effectiveness of the proposed method against existing state-of-the-art and standard approaches.", "section": "5 Experiments"}, {"figure_path": "hKVTwQQu76/tables/tables_7_1.jpg", "caption": "Table 2: Ablation study results on different datasets with proposed designs.", "description": "This table presents the ablation study of the proposed DFA-GNN model. It shows the impact of removing the pseudo-error generator (EG) and node filter (NF) components on the model's performance across six different datasets. Each row represents a different configuration (EG and NF either included or removed). The performance is measured by mean accuracy \u00b1 95% confidence interval, allowing for a comparison of the model's robustness under different settings and datasets.", "section": "5 Experiments"}, {"figure_path": "hKVTwQQu76/tables/tables_9_1.jpg", "caption": "Table 3: Results on three large datasets. OOM denotes out of memory.", "description": "This table presents the performance comparison of different algorithms on three large-scale datasets: Flickr, Reddit, and ogbn-arxiv.  The results show the mean accuracy achieved by each algorithm.  OOM indicates that the algorithm ran out of memory and could not complete the task on the dataset.", "section": "5 Experiments"}, {"figure_path": "hKVTwQQu76/tables/tables_9_2.jpg", "caption": "Table 1: Results on datasets: mean accuracy (%) \u00b1 95% confidence interval. The best result on each dataset is indicated with bold.", "description": "This table presents the mean accuracy and 95% confidence intervals achieved by different node classification methods on ten benchmark datasets.  The methods compared include backpropagation (BP), PEPITA, CaFo (two versions), FF (two versions), SF, and the proposed DFA-GNN. The best-performing method for each dataset is highlighted in bold, showcasing the relative performance of each algorithm across diverse graph datasets.", "section": "5 Experiments"}, {"figure_path": "hKVTwQQu76/tables/tables_15_1.jpg", "caption": "Table 1: Results on datasets: mean accuracy (%) \u00b1 95% confidence interval. The best result on each dataset is indicated with bold.", "description": "This table presents the mean accuracy and 95% confidence intervals achieved by different methods (BP, PEPITA, CaFo+MSE, CaFo+CE, FF+LA, FF+VN, SF, and the proposed DFA-GNN) on ten benchmark datasets for node classification.  The best performing method for each dataset is highlighted in bold. This provides a comparison of the performance of the proposed DFA-GNN method against existing baseline methods for semi-supervised node classification on graph data.", "section": "5 Experiments"}, {"figure_path": "hKVTwQQu76/tables/tables_16_1.jpg", "caption": "Table 1: Results on datasets: mean accuracy (%) \u00b1 95% confidence interval. The best result on each dataset is indicated with bold.", "description": "This table presents the results of the proposed DFA-GNN model and several baseline methods on ten benchmark datasets.  The accuracy of each method is reported as the mean accuracy across ten random splits, along with the 95% confidence interval. The best performing method for each dataset is highlighted in bold.  This allows for a direct comparison of the proposed method against several state-of-the-art baselines, demonstrating its effectiveness.", "section": "5 Experiments"}, {"figure_path": "hKVTwQQu76/tables/tables_17_1.jpg", "caption": "Table 1: Results on datasets: mean accuracy (%) \u00b1 95% confidence interval. The best result on each dataset is indicated with bold.", "description": "This table presents the results of the proposed DFA-GNN method and several baseline methods on ten different benchmark datasets. The results are reported as mean accuracy with a 95% confidence interval. The best result achieved for each dataset is highlighted in bold. The table allows for a comparison of the performance of DFA-GNN against existing backpropagation (BP) and other non-BP methods across various types of graph datasets.", "section": "5 Experiments"}, {"figure_path": "hKVTwQQu76/tables/tables_17_2.jpg", "caption": "Table 1: Results on datasets: mean accuracy (%) \u00b1 95% confidence interval. The best result on each dataset is indicated with bold.", "description": "This table presents the mean accuracy and 95% confidence intervals achieved by various methods (BP, PEPITA, CaFo+MSE, CaFo+CE, FF+LA, FF+VN, SF, and the proposed DFA-GNN) on ten different benchmark datasets. The best performing method for each dataset is highlighted in bold, providing a clear comparison of the proposed method against existing baselines.", "section": "5 Experiments"}, {"figure_path": "hKVTwQQu76/tables/tables_18_1.jpg", "caption": "Table 1: Results on datasets: mean accuracy (%) \u00b1 95% confidence interval. The best result on each dataset is indicated with bold.", "description": "This table presents the mean accuracy and 95% confidence intervals achieved by various methods on ten different benchmark datasets.  The methods compared include backpropagation (BP), PEPITA, CaFo, FF, SF, and the proposed DFA-GNN. The best performing method for each dataset is highlighted in bold, enabling easy comparison of the different approaches across a range of graph datasets.", "section": "5 Experiments"}]