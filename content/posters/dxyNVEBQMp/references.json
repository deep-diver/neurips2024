{"references": [{"fullname_first_author": "Ashish Vaswani", "paper_title": "Attention is all you need", "publication_date": "2017-12-01", "reason": "This paper introduced the Transformer architecture, a foundational model for many recent time series forecasting models, including those in this paper."}, {"fullname_first_author": "Haoyi Zhou", "paper_title": "Informer: Beyond efficient transformer for long sequence time-series forecasting", "publication_date": "2021-01-01", "reason": "This paper is cited for its development of efficient transformer methods for long time series, which directly addresses a limitation tackled in the current paper."}, {"fullname_first_author": "Yunhao Zhang", "paper_title": "Crossformer: Transformer utilizing cross-dimension dependency for multivariate time series forecasting", "publication_date": "2022-01-01", "reason": "This paper presents another state-of-the-art time series forecasting model, further highlighting the focus on efficient and effective forecasting methods in the field."}, {"fullname_first_author": "Minhao Liu", "paper_title": "Scinet: Time series modeling and forecasting with sample convolution and interaction", "publication_date": "2022-01-01", "reason": "This is cited for proposing a new TSF model, demonstrating the ongoing innovation in time-series forecasting that this paper builds upon."}, {"fullname_first_author": "Tian Zhou", "paper_title": "Fedformer: Frequency enhanced decomposed transformer for long-term series forecasting", "publication_date": "2022-07-01", "reason": "This work is relevant for its use of the frequency domain for enhanced long-term forecasting, a technique explored in the current paper."}]}