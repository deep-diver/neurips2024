[{"figure_path": "ioKQzb8SMr/tables/tables_2_1.jpg", "caption": "Table 1: Experiments on Design-Bench Tasks. We report max score (100th percentile) among Q=128 candidates. Blue denotes the best entry in the column, and Violet denotes the second best.", "description": "This table presents the results of experiments conducted on various tasks from the Design-Bench benchmark.  For each task (TFBind8, TFBind10, Superconductor, Ant, D'Kitty), the table shows the maximum score achieved (100th percentile) among the top 128 candidate designs selected by each method.  The scores are reported as mean \u00b1 standard error.  The best and second-best results for each task are highlighted in blue and violet, respectively.  The methods compared include various offline model-based optimization (MBO) approaches, allowing for a comparison of the relative performance of different techniques on these tasks.", "section": "4.2 Design-Bench tasks"}, {"figure_path": "ioKQzb8SMr/tables/tables_5_1.jpg", "caption": "Table 1: Experiments on Design-Bench Tasks. We report max score (100th percentile) among Q=128 candidates. Blue denotes the best entry in the column, and Violet denotes the second best.", "description": "This table presents the results of experiments conducted on various tasks from the Design-Bench benchmark.  For each task (TFBind8, TFBind10, Superconductor, Ant, and D'Kitty), the table shows the maximum score achieved by each method among the top 128 candidates, based on the 100th percentile.  The best and second-best results for each task are highlighted in blue and violet, respectively. The mean rank across all tasks is provided for comparison.", "section": "4.2 Design-Bench tasks"}, {"figure_path": "ioKQzb8SMr/tables/tables_6_1.jpg", "caption": "Table 1: Experiments on Design-Bench Tasks. We report max score (100th percentile) among Q=128 candidates. Blue denotes the best entry in the column, and Violet denotes the second best.", "description": "This table presents the results of experiments conducted on various tasks within the Design-Bench benchmark.  The maximum score (100th percentile) achieved among 128 candidates is reported for each method on eight different tasks.  The best and second-best results for each task are highlighted in blue and violet, respectively.  The table allows comparison of the proposed GTG method against various other offline model-based optimization techniques.", "section": "4 Experimental evaluation"}, {"figure_path": "ioKQzb8SMr/tables/tables_7_1.jpg", "caption": "Table 4: Ablation study on trajectory construction strategy.", "description": "This table presents the ablation study on the trajectory construction strategy used in the GTG method. It compares the performance of three different strategies: SORT-SAMPLE, Top-p Percentile, and the proposed method. The results are shown for five different tasks: TFBind8, TFBind10, Superconductor, Ant, and D'Kitty. Each entry in the table represents the maximum score (100th percentile) achieved among Q=128 candidate designs, along with the standard deviation. The table aims to demonstrate the effectiveness of the proposed trajectory construction method by comparing it to existing baselines.", "section": "Additional analysis"}, {"figure_path": "ioKQzb8SMr/tables/tables_7_2.jpg", "caption": "Table 5: Ablation study on sampling procedure of GTG.", "description": "This table presents the results of an ablation study on the sampling procedure of the Guided Trajectory Generation (GTG) method. It shows the performance of GTG with different combinations of classifier-free guidance (CF), context conditioning (CC), and filtering (F) techniques. The results are presented for five different configurations: without any technique (\u00d8), only CF, CF and CC, CF and F, and all three techniques (CF, CC, F). The performance is evaluated across five different Design-Bench tasks: TFBind8, TFBind10, Superconductor, Ant, and D'Kitty.", "section": "Additional Analysis on Sampling Procedure"}, {"figure_path": "ioKQzb8SMr/tables/tables_13_1.jpg", "caption": "Table 1: Experiments on Design-Bench Tasks. We report max score (100th percentile) among Q=128 candidates. Blue denotes the best entry in the column, and Violet denotes the second best.", "description": "This table presents the results of experiments conducted on various tasks from the Design-Bench benchmark.  For each task, the maximum score achieved among the top 128 candidates selected by different methods is shown. The best and second-best results for each task are highlighted in blue and violet, respectively.  The methods compared include various offline model-based optimization approaches. The mean rank of each method across all tasks is included to allow for comparison.", "section": "4 Experimental evaluation"}, {"figure_path": "ioKQzb8SMr/tables/tables_14_1.jpg", "caption": "Table 1: Experiments on Design-Bench Tasks. We report max score (100th percentile) among Q=128 candidates. Blue denotes the best entry in the column, and Violet denotes the second best.", "description": "This table presents the results of experiments conducted on various tasks from the Design-Bench benchmark.  For each task, the maximum score (100th percentile) achieved among 128 candidate designs is reported, along with standard deviation. The best and second-best results are highlighted in blue and violet respectively.  The table allows for comparison of the proposed method (GTG) against several baseline methods.", "section": "4.2 Design-Bench tasks"}, {"figure_path": "ioKQzb8SMr/tables/tables_15_1.jpg", "caption": "Table 1: Experiments on Design-Bench Tasks. We report max score (100th percentile) among Q=128 candidates. Blue denotes the best entry in the column, and Violet denotes the second best.", "description": "This table presents the results of experiments conducted on various tasks from the Design-Bench benchmark.  The maximum score (100th percentile) achieved among 128 candidate designs is reported for each task and method.  The best and second-best results for each task are highlighted in blue and violet respectively. The table allows for a comparison of the performance of different optimization methods across multiple tasks of varying complexity.", "section": "4.2 Design-Bench tasks"}, {"figure_path": "ioKQzb8SMr/tables/tables_15_2.jpg", "caption": "Table 1: Experiments on Design-Bench Tasks. We report max score (100th percentile) among Q=128 candidates. Blue denotes the best entry in the column, and Violet denotes the second best.", "description": "This table presents the results of experiments conducted on various tasks from the Design-Bench benchmark.  The table shows the maximum score achieved (100th percentile) among the top 128 candidates selected by different optimization methods.  The best and second-best performing methods for each task are highlighted in blue and violet, respectively.  The results provide a comparison of the performance of various offline model-based optimization methods across multiple design tasks.", "section": "4.2 Design-Bench tasks"}, {"figure_path": "ioKQzb8SMr/tables/tables_16_1.jpg", "caption": "Table 1: Experiments on Design-Bench Tasks. We report max score (100th percentile) among Q=128 candidates. Blue denotes the best entry in the column, and Violet denotes the second best.", "description": "This table presents the results of experiments conducted on various tasks within the Design-Bench benchmark.  The maximum score (100th percentile) achieved among 128 candidate designs is reported for each task.  The table compares various optimization methods, highlighting the best-performing method for each task and indicating the second-best performer.", "section": "4 Experimental evaluation"}, {"figure_path": "ioKQzb8SMr/tables/tables_16_2.jpg", "caption": "Table 1: Experiments on Design-Bench Tasks. We report max score (100th percentile) among Q=128 candidates. Blue denotes the best entry in the column, and Violet denotes the second best.", "description": "This table presents the results of experiments conducted on various tasks from the Design-Bench benchmark.  For each task, the maximum score achieved among the top 128 candidate designs is reported.  The table compares the performance of the proposed GTG method to several baseline methods, highlighting the best and second-best performers for each task. The mean rank across all tasks is also included to provide an overall comparison.", "section": "4 Experimental evaluation"}, {"figure_path": "ioKQzb8SMr/tables/tables_19_1.jpg", "caption": "Table 12: Exploring various guiding strategies.", "description": "This table compares the performance of two different sampling strategies for guiding the diffusion model in GTG: inpainting and classifier-free guidance.  The results are presented for five different tasks from the Design-Bench benchmark: TFBind8, TFBind10, Superconductor, Ant, and D'Kitty. The table shows that the classifier-free guidance strategy generally outperforms the inpainting strategy across all five tasks.", "section": "D.2.1 Various Strategies for Guided Sampling"}, {"figure_path": "ioKQzb8SMr/tables/tables_19_2.jpg", "caption": "Table 1: Experiments on Design-Bench Tasks. We report max score (100th percentile) among Q=128 candidates. Blue denotes the best entry in the column, and Violet denotes the second best.", "description": "This table presents the results of experiments conducted on various tasks from the Design-Bench benchmark.  For each task, the maximum score (100th percentile) achieved among 128 candidate designs is reported.  The table compares the performance of the proposed GTG method against various baselines, highlighting the best and second-best performing methods for each task.", "section": "4 Experimental evaluation"}, {"figure_path": "ioKQzb8SMr/tables/tables_20_1.jpg", "caption": "Table 1: Experiments on Design-Bench Tasks. We report max score (100th percentile) among Q=128 candidates. Blue denotes the best entry in the column, and Violet denotes the second best.", "description": "This table presents the results of experiments conducted on various tasks from the Design-Bench benchmark.  The maximum score achieved (100th percentile) among 128 candidate designs is reported for each task and method.  The best and second-best performing methods for each task are highlighted in blue and violet respectively.  The table allows for a comparison of the proposed GTG method against several baseline optimization approaches.", "section": "4.2 Design-Bench tasks"}, {"figure_path": "ioKQzb8SMr/tables/tables_21_1.jpg", "caption": "Table 15: Impact of pretraining with a synthetic dataset on performance. Experiments are conducted with three random seeds.", "description": "This table presents the results of experiments comparing the performance of GTG with and without pretraining on a synthetic dataset.  The results show that pretraining generally improves the performance, particularly in sparse data settings.  Three random seeds were used for each experiment. The table shows the maximum score (100th percentile) for each method across five different Design-Bench tasks.", "section": "D.3 Effect of Unsupervised Pretraining"}, {"figure_path": "ioKQzb8SMr/tables/tables_22_1.jpg", "caption": "Table 1: Experiments on Design-Bench Tasks. We report max score (100th percentile) among Q=128 candidates. Blue denotes the best entry in the column, and Violet denotes the second best.", "description": "This table presents the results of experiments conducted on various tasks from the Design-Bench benchmark.  For each task, the maximum score (100th percentile) achieved among 128 candidate designs generated by different methods is reported.  The table allows comparison of different optimization methods (BO-qEI, CMA-ES, REINFORCE, Grad Ascent, COMS, NEMO, ROMA, BDI, ICT, CbAS, MINS, DDOM, BONET, PGS, and GTG (the authors' method)) across various Design-Bench tasks (TFBind8, TFBind10, Superconductor, Ant, and D'Kitty).  The best performing method for each task is highlighted in blue, and the second-best is highlighted in violet.", "section": "4 Experimental evaluation"}, {"figure_path": "ioKQzb8SMr/tables/tables_22_2.jpg", "caption": "Table 1: Experiments on Design-Bench Tasks. We report max score (100th percentile) among Q=128 candidates. Blue denotes the best entry in the column, and Violet denotes the second best.", "description": "This table presents the results of experiments conducted on various tasks within the Design-Bench benchmark.  The maximum score achieved (100th percentile) among 128 design candidates is reported for each of several different optimization methods on a selection of Design-Bench tasks.  The best result for each task is highlighted in blue, and the second-best is highlighted in violet. This provides a comparison of the performance of the proposed GTG method against various baseline methods. ", "section": "4.2 Design-Bench tasks"}]