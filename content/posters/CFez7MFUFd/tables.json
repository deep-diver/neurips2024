[{"figure_path": "CFez7MFUFd/tables/tables_6_1.jpg", "caption": "Table 1: Average PSNR/SSIM of the results for Lai et al. dataset [26]. The methods marked with \u25b3 deblur the image by [23] using the estimated kernel, a standard protocol for evaluating kernel estimation accuracy in BID. The methods marked with * are retrained on the BSD-D dataset [48].", "description": "This table presents a comparison of the average Peak Signal-to-Noise Ratio (PSNR) and Structural Similarity Index (SSIM) scores achieved by various blind image deblurring (BID) methods on the Lai et al. dataset.  It compares non-learning, supervised, and self-supervised approaches, showing the performance of each method across different image categories (Manmade, Natural, People, Saturated, Text).  Methods marked with \u25b3 used a standard protocol where a separate deblurring method [23] is used with the estimated blur kernel, while methods marked with * were retrained on the BSD-D dataset.", "section": "4 Experiments"}, {"figure_path": "CFez7MFUFd/tables/tables_7_1.jpg", "caption": "Table 1: Average PSNR/SSIM of the results for Lai et al. dataset [26]. The methods marked with \u25b3 deblur the image by [23] using the estimated kernel, a standard protocol for evaluating kernel estimation accuracy in BID. The methods marked with * are retrained on the BSD-D dataset [48].", "description": "This table presents a quantitative comparison of various blind image deblurring (BID) methods on the Lai et al. dataset [26].  The methods are categorized into non-learning, supervised, and self-supervised approaches.  The table reports the average Peak Signal-to-Noise Ratio (PSNR) and Structural Similarity Index (SSIM) for each method across five image categories: Manmade, Natural, People, Saturated, and Text.  Methods marked with a triangle (\u25b3) utilize a standard kernel estimation protocol (from [23]) for evaluation, while methods marked with an asterisk (*) were retrained on a different dataset (BSD-D [48]). This allows for a comprehensive comparison of different techniques' performance across various blurring types and evaluation methodologies.", "section": "4 Experiments"}, {"figure_path": "CFez7MFUFd/tables/tables_7_2.jpg", "caption": "Table 1: Average PSNR/SSIM of the results for Lai et al. dataset [26]. The methods marked with \u25b3 deblur the image by [23] using the estimated kernel, a standard protocol for evaluating kernel estimation accuracy in BID. The methods marked with * are retrained on the BSD-D dataset [48].", "description": "This table presents a quantitative comparison of various blind image deblurring (BID) methods on the Lai et al. dataset [26], categorized by non-learning, supervised, and self-supervised approaches.  The results are evaluated using Peak Signal-to-Noise Ratio (PSNR) and Structural SIMilarity index (SSIM).  Some methods use a standard protocol where deblurring is performed using a pre-estimated kernel, denoted with a triangle symbol.  Other methods are retrained on the Berkeley Segmentation Dataset (BSD-D), denoted with an asterisk.", "section": "4 Experiments"}, {"figure_path": "CFez7MFUFd/tables/tables_8_1.jpg", "caption": "Table 4: Average PSNR/SSIM of the results from different methods on microscopic deconvolution.", "description": "This table presents the average Peak Signal-to-Noise Ratio (PSNR) and Structural Similarity Index (SSIM) scores for various methods on a microscopic deconvolution task.  The methods include supervised learning approaches (Restormer, INIKNet, BlindDPS), self-supervised methods (SelfDeblur, MCEM, VDIP), and the proposed method.  The results are split into two categories based on the type of Point Spread Function (PSF) used: Gaussian and Poisson.  The table aims to show the performance of the proposed method relative to state-of-the-art methods on this specific image deconvolution task for microscopic images.", "section": "4.3 Evaluation on microscopic deconvolution"}, {"figure_path": "CFez7MFUFd/tables/tables_8_2.jpg", "caption": "Table 1: Average PSNR/SSIM of the results for Lai et al. dataset [26]. The methods marked with \u25b3 deblur the image by [23] using the estimated kernel, a standard protocol for evaluating kernel estimation accuracy in BID. The methods marked with * are retrained on the BSD-D dataset [48].", "description": "This table presents a comparison of the performance of various blind image deblurring (BID) methods on the Lai et al. dataset.  The methods are categorized as non-learning, supervised, and self-supervised.  The results are shown in terms of Peak Signal-to-Noise Ratio (PSNR) and Structural Similarity Index (SSIM), which are common metrics for evaluating image quality. Some methods are marked with \u25b3 or *, indicating that they use a specific kernel estimation method or are trained using a different dataset, respectively. This allows for a more comprehensive comparison of the different methods.", "section": "4 Experiments"}, {"figure_path": "CFez7MFUFd/tables/tables_9_1.jpg", "caption": "Table 6: Model complexity comparison.", "description": "This table compares the computational efficiency of the proposed method against three other self-supervised BID methods.  The comparison is based on running time, the number of parameters, and memory usage required to process a single 256x256 image with a 31x31 blur kernel using an NVIDIA 3090 RTX GPU.  It demonstrates the balance achieved by the proposed method between computational cost and deblurring performance.", "section": "4 Experiments"}, {"figure_path": "CFez7MFUFd/tables/tables_16_1.jpg", "caption": "Table 7: Scale variation study on the proposed architecture in terms of PSNR/SSIM on the dataset Lai et al. [26]. Bold for best performers and underline for second-best performers.", "description": "This table presents the ablation study results on the impact of different maximum scales (So) on the performance of the proposed method. It compares the results using the same framework with different So values (single-scale, two-scale, three-scale, and four-scale). The results are evaluated in terms of PSNR/SSIM on the Lai et al. dataset. The best and second-best performers are highlighted in bold and underlined, respectively.", "section": "4.4 Ablation study"}, {"figure_path": "CFez7MFUFd/tables/tables_17_1.jpg", "caption": "Table 1: Average PSNR/SSIM of the results for Lai et al. dataset [26]. The methods marked with \u25b3 deblur the image by [23] using the estimated kernel, a standard protocol for evaluating kernel estimation accuracy in BID. The methods marked with * are retrained on the BSD-D dataset [48].", "description": "This table presents a comparison of various blind image deblurring (BID) methods on the Lai et al. dataset [26], categorized by different image types (Manmade, Natural, People, Saturated, Text).  The table shows the average Peak Signal-to-Noise Ratio (PSNR) and Structural Similarity Index (SSIM) scores achieved by each method.  Methods marked with a triangle (\u25b3) use the estimated kernel from [23] for deblurring, while those marked with an asterisk (*) were retrained on the BSD-D dataset [48].  This allows for a comprehensive comparison of different BID approaches, highlighting their performance across various blur types and image characteristics.", "section": "4 Experiments"}, {"figure_path": "CFez7MFUFd/tables/tables_17_2.jpg", "caption": "Table 1: Average PSNR/SSIM of the results for Lai et al. dataset [26]. The methods marked with \u25b3 deblur the image by [23] using the estimated kernel, a standard protocol for evaluating kernel estimation accuracy in BID. The methods marked with * are retrained on the BSD-D dataset [48].", "description": "This table presents a comparison of various blind image deblurring (BID) methods on the Lai et al. dataset [26], which contains images categorized into five groups: manmade, natural, people, saturated, and text, each with 4 different kernels.  The table reports the average Peak Signal-to-Noise Ratio (PSNR) and Structural Similarity Index (SSIM) for each method and category.  Methods marked with \u25b3 use a standard protocol for evaluating kernel estimation accuracy in BID where the image is deblurred using an estimated kernel from a separate method. Methods marked with * were retrained on the BSD-D dataset [48],  allowing for comparison of performance with models trained on a different dataset.", "section": "4 Experiments"}, {"figure_path": "CFez7MFUFd/tables/tables_17_3.jpg", "caption": "Table 6: Model complexity comparison.", "description": "This table compares the computational efficiency of the proposed method against three other self-supervised BID methods.  The metrics used are running time (in seconds), the number of parameters (in thousands), and memory usage (in GB) required to process a single 256x256 image with a 31x31 blur kernel on an NVIDIA 3090 RTX GPU.  The table highlights the balance achieved by the proposed method between computational cost and deblurring performance.", "section": "4 Experiments"}, {"figure_path": "CFez7MFUFd/tables/tables_25_1.jpg", "caption": "Table 1: Average PSNR/SSIM of the results for Lai et al. dataset [26]. The methods marked with \u25b3 deblur the image by [23] using the estimated kernel, a standard protocol for evaluating kernel estimation accuracy in BID. The methods marked with * are retrained on the BSD-D dataset [48].", "description": "This table presents a comparison of the performance of various blind image deblurring (BID) methods on the Lai et al. dataset.  The table shows the average Peak Signal-to-Noise Ratio (PSNR) and Structural Similarity Index (SSIM) for each method across five categories of images (Manmade, Natural, People, Saturated, Text) and an average across all categories.  Methods marked with a triangle (\u25b3) used a kernel estimated by a separate method ([23]) before deblurring, highlighting the accuracy of their kernel estimation. Methods with an asterisk (*) were retrained on a different dataset (BSD-D [48]), showing the impact of training data on the performance.", "section": "4 Experiments"}]