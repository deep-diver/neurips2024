{"references": [{"fullname_first_author": "Chuan Guo", "paper_title": "On Calibration of Modern Neural Networks", "publication_date": "2017-00-00", "reason": "This paper is foundational in the field of neural network calibration, introducing the concept and highlighting the overconfidence problem in modern deep learning models."}, {"fullname_first_author": "Yarin Gal", "paper_title": "Dropout as a Bayesian Approximation: Representing Model Uncertainty in Deep Learning", "publication_date": "2016-00-00", "reason": "This paper is highly influential for introducing a Bayesian perspective to deep learning, enabling uncertainty quantification and improved model calibration through the use of dropout regularization."}, {"fullname_first_author": "Deng-Bao Wang", "paper_title": "Rethinking Calibration of Deep Neural Networks: Do Not Be Afraid of Overconfidence", "publication_date": "2021-00-00", "reason": "This work challenges conventional wisdom on calibration and provides insights into the distinct optimization characteristics of classification error and calibration error in deep learning models."}, {"fullname_first_author": "Jonathan Wenger", "paper_title": "Non-parametric Calibration for Classification", "publication_date": "2020-00-00", "reason": "This paper offers a non-parametric method for improving model calibration, which addresses limitations of existing parametric approaches and enhances the accuracy of uncertainty estimates."}, {"fullname_first_author": "Siyuan Zhang", "paper_title": "Advancing Neural Network Calibration: The Role of Gradient Decay in Large-Margin Softmax Optimization", "publication_date": "2024-00-00", "reason": "This paper directly addresses the relationship between gradient decay rate and calibration, providing a theoretical basis and empirical evidence for the adaptive approach used in the main paper."}]}