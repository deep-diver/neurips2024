[{"figure_path": "xavWvnJTST/figures/figures_3_1.jpg", "caption": "Figure 1: Recurrent neural networks with feedback control feature rapid adaptation to acute task perturbation and can learn the persistent task perturbation using a local learning rule. A recurrent neural network with feedback control is first pre-trained on produce a 2D sigmoidal velocity profile based on a target and go cue input input, and then tested on a 30\u00b0 target rotation. (a) The pre-trained network adapts to the perturbation during the first trial with feedback control (full-line). The dashed line denotes the same network without feedback control. (b) The network further improves its performance during persistent perturbation with feedback-driven local learning (Feulner et al., 2022)", "description": "This figure shows the results of a recurrent neural network with feedback control on a motor adaptation task.  The network is pre-trained to generate a 2D sigmoidal velocity profile given a target and a go cue.  Then it's tested by rotating the target 30\u00b0. (a) shows the immediate adaptation to the perturbation enabled by feedback control.  (b) shows that after learning, the network improves further, overcoming the perturbation without ongoing feedback control. This demonstrates the effectiveness of feedback control for motor learning.", "section": "3 Results"}, {"figure_path": "xavWvnJTST/figures/figures_4_1.jpg", "caption": "Figure 1: Recurrent neural networks with feedback control feature rapid adaptation to acute task perturbation and can learn the persistent task perturbation using a local learning rule. A recurrent neural network with feedback control is first pre-trained on produce a 2D sigmoidal velocity profile based on a target and go cue input input, and then tested on a 30\u00b0 target rotation. (a) The pre-trained network adapts to the perturbation during the first trial with feedback control (full-line). The dashed line denotes the same network without feedback control. (b) The network further improves its performance during persistent perturbation with feedback-driven local learning (Feulner et al., 2022)", "description": "This figure demonstrates the ability of recurrent neural networks with feedback control to adapt to both acute and persistent task perturbations.  In (a), a network pre-trained on a reaching task is shown adapting to an acute 30\u00b0 rotation of the target during a single trial. The network with feedback control adapts rapidly, whereas a network without feedback control does not. In (b), the same network is shown adapting to the persistent perturbation using a local learning rule. With feedback control, the performance improves over multiple trials; without feedback control, it does not.", "section": "3 Results"}, {"figure_path": "xavWvnJTST/figures/figures_5_1.jpg", "caption": "Figure 3: Feedback control aids local learning in the recurrent network layer. (a) Train loss as a function of trial number during persistent perturbation with feedback-driven local learning. Grey line denotes the performance of the same network tested without feedback control, showing that the network relies less on feedback control with learning. The shaded regions denote the standard error of the mean over 10 random network seeds. (b) The final performance (after 1000 trials, without feedback control) of recurrent networks trained with RFLO with (+c, blue) or without (yellow) feedback control during learning with varying degrees of persistent perturbation. The performance of same networks trained with online BPTT with (+c, orange) or without (red) feedback. The error bars denote the standard error of the mean over 10 random network seeds.", "description": "This figure shows the results of the experiment comparing the performance of recurrent neural networks with and without feedback control during persistent task perturbation. Panel (a) shows the training loss over time for networks trained with feedback-driven local learning (RFLO+c), and networks trained with the same rule without feedback control. The results indicate that while the feedback control helps initially, the networks eventually become independent of it. Panel (b) shows the final test performance after 1000 trials (with feedback control turned off) for networks trained with RFLO with and without feedback control, and for networks trained with online BPTT with and without feedback control. The results reveal that feedback control significantly improves the accuracy of local learning during persistent perturbation.", "section": "3 Results"}, {"figure_path": "xavWvnJTST/figures/figures_6_1.jpg", "caption": "Figure 4: Feedback increases the accuracy of local learning. (a) The norm of the Jacobians of the network activities at time t w.r.t. to activities at a previous timestep during a single trial. The shaded regions denote the standard deviation over 10 random network seeds. (b) The mean local alignment of the feedback-driven local learning rule with the true local gradient during task adaptation. The error bars denote the standard deviation over 10 seeds. The error bars denote the standard deviation over 10 random network seeds. (c) The mean global alignment of the feedback-driven local learning rule with the true global gradient during task adaptation. The error bars denote the standard deviation over 10 random network seeds.", "description": "This figure shows how feedback control improves the accuracy of local learning rules during task adaptation. Panel (a) displays the norm of the Jacobians of network activities at time t relative to activities at a previous timestep (t-1) during a single trial, demonstrating the impact of task perturbation. Panels (b) and (c) show the mean local and global alignment between the feedback-driven local learning rule and the true gradients during task adaptation, indicating improved accuracy with feedback control.", "section": "3.2 Feedback control approximates the true gradient w.r.t. networks activations during task perturbation"}, {"figure_path": "xavWvnJTST/figures/figures_7_1.jpg", "caption": "Figure 5: Feedback increases the efficiency of local learning. (a) The mean norm or efficiency ratio of the total, global weight update with that of the online, local weight update during task adaptation at various perturbation degrees. The error bars denote the standard deviation over 10 random network seeds. (b) The cosine similarity between the online feedback control signal injected into the ongoing network dynamics and the second-order gradient (calculated using the Newton method) w.r.t. activations (blue) during a single trial. The grey line denotes the first-order gradient as in Figure 2c. The shaded region denotes the standard error of the mean over 10 network seeds.", "description": "This figure demonstrates the impact of feedback control on the efficiency of local learning during task adaptation. Panel (a) shows that the ratio of global to local weight updates is significantly higher for networks with feedback control, indicating improved efficiency. Panel (b) shows that the feedback control signal aligns well with the second-order gradient, suggesting that feedback control implicitly injects second-order information, improving learning efficiency.", "section": "3.5 Feedback control enables efficient recurrent weight adaptation during task perturbation"}, {"figure_path": "xavWvnJTST/figures/figures_13_1.jpg", "caption": "Figure 1: Recurrent neural networks with feedback control feature rapid adaptation to acute task perturbation and can learn the persistent task perturbation using a local learning rule. A recurrent neural network with feedback control is first pre-trained on produce a 2D sigmoidal velocity profile based on a target and go cue input input, and then tested on a 30\u00b0 target rotation. (a) The pre-trained network adapts to the perturbation during the first trial with feedback control (full-line). The dashed line denotes the same network without feedback control. (b) The network further improves its performance during persistent perturbation with feedback-driven local learning (Feulner et al., 2022)", "description": "This figure demonstrates the rapid adaptation of recurrent neural networks with feedback control to both acute and persistent task perturbations.  Part (a) shows the immediate adaptation during the first trial of a 30\u00b0 rotation in target position, highlighting the superior performance with feedback control. Part (b) shows the further improvement in performance when the network uses a local learning rule with persistent perturbation.", "section": "3 Results"}, {"figure_path": "xavWvnJTST/figures/figures_13_2.jpg", "caption": "Figure 1: Recurrent neural networks with feedback control feature rapid adaptation to acute task perturbation and can learn the persistent task perturbation using a local learning rule. A recurrent neural network with feedback control is first pre-trained on produce a 2D sigmoidal velocity profile based on a target and go cue input input, and then tested on a 30\u00b0 target rotation. (a) The pre-trained network adapts to the perturbation during the first trial with feedback control (full-line). The dashed line denotes the same network without feedback control. (b) The network further improves its performance during persistent perturbation with feedback-driven local learning (Feulner et al., 2022)", "description": "This figure shows the results of an experiment where recurrent neural networks (RNNs) with and without feedback control were tested on a motor task with a 30\u00b0 perturbation.  The RNN with feedback control adapted rapidly to the acute perturbation during the first trial.  Additionally, with a local learning rule,  the feedback-controlled RNN improved further during persistent perturbation, demonstrating the benefit of feedback control for adapting to both acute and persistent perturbations.", "section": "3 Results"}, {"figure_path": "xavWvnJTST/figures/figures_14_1.jpg", "caption": "Figure 8: Adaptation learning rate sweep using different learning algorithms with increasing degrees of persistent perturbation.", "description": "This figure shows the results of a learning rate sweep for different learning algorithms (RFLO+c, RFLO, BPTT+c, BPTT) across various degrees of persistent perturbation (30\u00b0, 40\u00b0, 50\u00b0, 60\u00b0).  Each heatmap visualizes the mean squared error (MSE) for each algorithm at different learning rates. The color intensity represents the MSE value, with darker colors indicating lower error. This helps to determine the optimal learning rate for each algorithm under different levels of perturbation.", "section": "3 Results"}, {"figure_path": "xavWvnJTST/figures/figures_14_2.jpg", "caption": "Figure 8: Adaptation learning rate sweep using different learning algorithms with increasing degrees of persistent perturbation.", "description": "This figure displays the results of a learning rate sweep conducted on four different learning algorithms (BPTT, BPTT+c, RFLO, and RFLO+c) at various degrees of persistent perturbation.  The heatmaps show the mean squared error (MSE) achieved by each algorithm across different learning rates, with higher MSE indicating poorer performance. The results suggest that RFLO+c (which incorporates feedback control and a local learning rule) achieves the best performance, particularly at higher perturbation magnitudes.", "section": "3 Results"}, {"figure_path": "xavWvnJTST/figures/figures_15_1.jpg", "caption": "Figure 4: Feedback increases the accuracy of local learning. (a) The norm of the Jacobians of the network activities at time t w.r.t. to activities at a previous timestep during a single trial. The shaded regions denote the standard deviation over 10 random network seeds. (b) The mean local alignment of the feedback-driven local learning rule with the true local gradient during task adaptation. The error bars denote the standard deviation over 10 seeds. (c) The mean global alignment of the feedback-driven local learning rule with the true global gradient during task adaptation. The error bars denote the standard deviation over 10 random network seeds.", "description": "This figure demonstrates how feedback control improves the accuracy of local learning rules in recurrent neural networks during task adaptation. Panel (a) shows the norm of the Jacobians of the network activities, indicating how sensitive the network is to its past activity. Panel (b) shows the local alignment of the feedback-driven local learning rule with the true local gradient, demonstrating that feedback increases accuracy. Panel (c) shows the global alignment, further supporting the benefit of feedback in improving accuracy.", "section": "3.2 Feedback control approximates the true gradient w.r.t. networks activations during task perturbation"}, {"figure_path": "xavWvnJTST/figures/figures_15_2.jpg", "caption": "Figure 1: Recurrent neural networks with feedback control feature rapid adaptation to acute task perturbation and can learn the persistent task perturbation using a local learning rule. A recurrent neural network with feedback control is first pre-trained on produce a 2D sigmoidal velocity profile based on a target and go cue input input, and then tested on a 30\u00b0 target rotation. (a) The pre-trained network adapts to the perturbation during the first trial with feedback control (full-line). The dashed line denotes the same network without feedback control. (b) The network further improves its performance during persistent perturbation with feedback-driven local learning (Feulner et al., 2022)", "description": "This figure shows how recurrent neural networks with feedback control adapt to task perturbations.  Panel (a) demonstrates rapid adaptation to an acute perturbation during the first trial, highlighting the benefit of feedback control. Panel (b) illustrates further performance improvement when using a local learning rule during persistent perturbation, showcasing the network's ability to learn and correct for ongoing errors.", "section": "3 Results"}]