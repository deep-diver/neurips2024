[{"figure_path": "NKpPnb3YNg/tables/tables_5_1.jpg", "caption": "Table 1: Avg. of normalized time-coupled worst-case performance over 10 seeds for each method", "description": "This table presents the average normalized performance of different algorithms across multiple MuJoCo environments under time-constrained worst-case scenarios. The results are averaged over 10 random seeds.  The normalization uses TD3's performance as a baseline and M2TD3's improvement over TD3 as a scaling factor.  This allows for a more standardized comparison across different environments and algorithms, highlighting improvements in robustness and efficiency.  The table compares Oracle, Stacked, and Vanilla TC versions of both RARL and M2TD3, along with several baselines including TD3, DR, M2TD3, and RARL.  Each entry represents the average normalized performance and its standard deviation.", "section": "5 Results"}, {"figure_path": "NKpPnb3YNg/tables/tables_7_1.jpg", "caption": "Table 1: Avg. of normalized time-coupled worst-case performance over 10 seeds for each method", "description": "This table presents the average normalized performance results across ten different random seeds for various robust reinforcement learning algorithms under time-constrained worst-case scenarios. The algorithms are evaluated on several MuJoCo continuous control environments.  The results are normalized against a baseline, enabling comparison across different tasks and highlighting the relative performance improvement or degradation.  The \"worst-case\" scenario implies that the evaluation considers the most challenging conditions for each algorithm.", "section": "5 Results"}, {"figure_path": "NKpPnb3YNg/tables/tables_7_2.jpg", "caption": "Table 1: Avg. of normalized time-coupled worst-case performance over 10 seeds for each method", "description": "This table presents the average normalized performance of different robust reinforcement learning algorithms under time-constrained worst-case scenarios.  The results are averaged over 10 different random seeds and show the performance across multiple MuJoCo continuous control environments (Ant, HalfCheetah, Hopper, Humanoid, Walker).  The algorithms include various robust RL methods, along with the proposed time-constrained algorithms (Oracle-TC, Stacked-TC, Vanilla TC) applied to RARL and M2TD3.  Domain randomization (DR) and vanilla TD3 are also included as baselines.  The \"normalized\" aspect refers to a standardization process described in the paper to enable comparison across different environments.", "section": "Results"}, {"figure_path": "NKpPnb3YNg/tables/tables_15_1.jpg", "caption": "Table 1: Avg. of normalized time-coupled worst-case performance over 10 seeds for each method", "description": "This table presents the average normalized worst-case performance of different reinforcement learning algorithms across various MuJoCo environments. The worst-case performance is evaluated under time-constrained adversarial perturbations.  The results are averaged over 10 independent random seeds.  The algorithms include those using the proposed time-constrained robust MDP framework (TC-RARL, TC-M2TD3, Stacked TC-RARL, Stacked TC-M2TD3, Vanilla TC, Oracle TC-RARL, Oracle TC-M2TD3) and baselines (TD3, DR, M2TD3, RARL). The table shows that the time-constrained algorithms, especially Oracle TC-M2TD3 and Oracle TC-RARL generally achieve better performance compared to the baselines.  The performance is normalized to provide a comparable metric across different environments.", "section": "5 Results"}, {"figure_path": "NKpPnb3YNg/tables/tables_17_1.jpg", "caption": "Table 1: Avg. of normalized time-coupled worst-case performance over 10 seeds for each method", "description": "This table presents the average normalized performance results for various reinforcement learning algorithms under time-constrained worst-case scenarios.  The results are averaged over 10 different random seeds to ensure reliability.  The algorithms are evaluated across multiple continuous control environments (Ant, HalfCheetah, Hopper, Humanoid, Walker).  The performance metric is normalized to provide a comparable measure across these diverse environments.  The table allows comparison of different approaches, including traditional robust RL methods (M2TD3, RARL), domain randomization (DR), and the three time-constrained robust MDP (TC-RMDP) algorithms proposed in the paper (Oracle-TC-M2TD3, Oracle-TC-RARL, Stacked-TC-M2TD3, Stacked-TC-RARL, TC-M2TD3, TC-RARL, Vanilla TC-M2TD3, Vanilla TC-RARL).  The results highlight the trade-off between performance and robustness achieved with the proposed TC-RMDP algorithms.", "section": "5 Results"}, {"figure_path": "NKpPnb3YNg/tables/tables_17_2.jpg", "caption": "Table 1: Avg. of normalized time-coupled worst-case performance over 10 seeds for each method", "description": "This table presents the average normalized performance of different algorithms under worst-case time-constrained perturbations. The results are averaged over 10 random seeds, and the performance is normalized to account for variations between different environments. Each algorithm's performance is presented for several Mujoco benchmark tasks.  The table helps to compare the robustness of the different algorithms in the face of time-coupled disturbances.", "section": "5 Results"}, {"figure_path": "NKpPnb3YNg/tables/tables_19_1.jpg", "caption": "Table 1: Avg. of normalized time-coupled worst-case performance over 10 seeds for each method", "description": "This table presents the average normalized performance results across ten different random seeds for various robust reinforcement learning methods under time-coupled worst-case conditions.  The methods are categorized into Oracle, Stacked, and Vanilla versions of TC-RARL and TC-M2TD3, along with baseline methods including TD3, DR, M2TD3, and RARL.  The performance metric is normalized, providing a comparable evaluation across different MuJoCo environments (Ant, HalfCheetah, Hopper, Humanoid, Walker).", "section": "5 Results"}, {"figure_path": "NKpPnb3YNg/tables/tables_19_2.jpg", "caption": "Table 1: Avg. of normalized time-coupled worst-case performance over 10 seeds for each method", "description": "This table presents the average normalized performance results across ten different random seeds for various robust reinforcement learning methods.  The \"worst-case\" performance is evaluated under time-constrained, temporally coupled adversarial perturbations.  The table compares the performance of different algorithms (Oracle M2TD3, Oracle RARL, Oracle-TC-M2TD3, Oracle-TC-RARL, Stacked-TC-M2TD3, Stacked-TC-RARL, TC-M2TD3, TC-RARL, TD3, DR, M2TD3, and RARL) across five different MuJoCo environments (Ant, HalfCheetah, Hopper, Humanoid, and Walker). The normalization is done relative to the performance of TD3 and M2TD3.", "section": "5 Results"}, {"figure_path": "NKpPnb3YNg/tables/tables_19_3.jpg", "caption": "Table 1: Avg. of normalized time-coupled worst-case performance over 10 seeds for each method", "description": "This table presents the average normalized performance of various robust reinforcement learning algorithms under worst-case time-constrained perturbations across multiple MuJoCo benchmark environments.  The normalization is relative to TD3, using M2TD3's performance as a target.  It allows for comparison across different environments and highlights the performance of the proposed time-constrained algorithms (TC-RARL and TC-M2TD3) against baselines.", "section": "5 Results"}, {"figure_path": "NKpPnb3YNg/tables/tables_20_1.jpg", "caption": "Table 1: Avg. of normalized time-coupled worst-case performance over 10 seeds for each method", "description": "This table presents the average normalized performance results across ten different random seeds for each algorithm under the worst-case time-constrained perturbations.  The algorithms are evaluated on several MuJoCo continuous control environments (Ant, HalfCheetah, Hopper, Humanoid, Walker).  The \"worst-case\" scenario refers to the performance against an adversary that is specifically designed to maximize the negative impact of the time-constrained uncertainty. The results are normalized to provide a fair comparison across environments and highlight the relative performance improvements of different algorithms.  Oracle methods, which have access to full state information, are included for comparison and are shown in black. Green and bold values indicate the best performance among methods without oracle access.", "section": "5 Results"}, {"figure_path": "NKpPnb3YNg/tables/tables_20_2.jpg", "caption": "Table 1: Avg. of normalized time-coupled worst-case performance over 10 seeds for each method", "description": "This table presents the average normalized performance results for various reinforcement learning algorithms under worst-case time-constrained perturbations. The performance is measured across different MuJoCo environments (Ant, HalfCheetah, Hopper, Humanoid, and Walker).  The algorithms are compared against various baselines, including traditional robust methods and domain randomization.  The table shows the average performance and standard deviation across ten random seeds for each algorithm in each environment, providing a comprehensive comparison of robustness and performance under time-constrained adversarial settings.", "section": "5 Results"}, {"figure_path": "NKpPnb3YNg/tables/tables_21_1.jpg", "caption": "Table 1: Avg. of normalized time-coupled worst-case performance over 10 seeds for each method", "description": "This table presents the average normalized performance results across ten different random seeds for various robust reinforcement learning algorithms under time-constrained worst-case conditions.  The algorithms are evaluated across five MuJoCo environments: Ant, HalfCheetah, Hopper, Humanoid, and Walker.  Normalization uses TD3 and M2TD3 as references to allow for comparison across different environments. The results indicate the relative performance of each algorithm, highlighting the best-performing methods under challenging conditions.", "section": "Results"}, {"figure_path": "NKpPnb3YNg/tables/tables_21_2.jpg", "caption": "Table 1: Avg. of normalized time-coupled worst-case performance over 10 seeds for each method", "description": "This table presents the average normalized performance of various reinforcement learning algorithms under time-constrained worst-case conditions.  The results are averaged over 10 independent random seeds and showcase the performance across several continuous control tasks (Ant, HalfCheetah, Hopper, Humanoid, Walker).  The metrics are normalized to provide a comparable view across different environments and methods.  Oracle methods (with access to optimal information) are shown in black.  Bold green values highlight the best performances without oracle information.", "section": "5 Results"}, {"figure_path": "NKpPnb3YNg/tables/tables_21_3.jpg", "caption": "Table 1: Avg. of normalized time-coupled worst-case performance over 10 seeds for each method", "description": "This table presents the average normalized performance results across ten different random seeds for various reinforcement learning algorithms under time-constrained worst-case scenarios.  The algorithms are evaluated on five different MuJoCo continuous control environments (Ant, HalfCheetah, Hopper, Humanoid, Walker). The performance metric is normalized, ensuring fair comparison across environments.  The table compares the proposed TC-RMDP algorithms (Oracle-TC-M2TD3, Oracle-TC-RARL, Stacked-TC-M2TD3, Stacked-TC-RARL, TC-M2TD3, TC-RARL) against state-of-the-art baselines (M2TD3, RARL, TD3, DR). Oracle methods have access to optimal environmental information.", "section": "5 Results"}, {"figure_path": "NKpPnb3YNg/tables/tables_22_1.jpg", "caption": "Table 1: Avg. of normalized time-coupled worst-case performance over 10 seeds for each method", "description": "This table presents the average normalized performance results across ten different random seeds for various reinforcement learning algorithms under time-constrained worst-case scenarios.  The algorithms are tested on multiple MuJoCo continuous control environments (Ant, HalfCheetah, Hopper, Humanoid, Walker). The \"normalized\" scores are relative to a baseline TD3 agent and a target M2TD3 agent, providing a standardized metric for comparing performance across different environments. The table highlights the performance of the proposed TC-RMDP algorithms (Oracle-TC-M2TD3, Oracle-TC-RARL, Stacked-TC-M2TD3, Stacked-TC-RARL, TC-M2TD3, TC-RARL) in comparison to state-of-the-art methods (M2TD3, RARL, TD3, DR) and oracle versions of the state-of-the-art methods.  The best performing non-oracle method in each environment is highlighted.", "section": "5 Results"}, {"figure_path": "NKpPnb3YNg/tables/tables_22_2.jpg", "caption": "Table 1: Avg. of normalized time-coupled worst-case performance over 10 seeds for each method", "description": "This table presents the average normalized performance results across ten different random seeds for various algorithms under time-constrained worst-case scenarios.  The metrics are normalized to provide a relative comparison against TD3 and M2TD3 baselines, making it easy to assess the performance improvement of each algorithm in different continuous control environments (Ant, HalfCheetah, Hopper, Humanoid, Walker).  The \"Oracle\" methods utilize full environmental information, highlighting the performance gains possible with complete information compared to less-informed counterparts.", "section": "5 Results"}]