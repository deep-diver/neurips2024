[{"figure_path": "7s53dAJlwz/figures/figures_1_1.jpg", "caption": "Figure 1: An example of single-image reconstruction from state-of-the-art methods: (a) ULIP [63], (b) LRM [13], (c) CRM [54], and (d) Ours (LAM3D).", "description": "This figure shows a comparison of single-image 3D reconstruction results from different methods.  The reference image is a wooden box.  (a) shows the results of ULIP, (b) LRM, (c) CRM, and (d) the authors' method, LAM3D. The figure highlights the superior quality and accuracy of the LAM3D reconstruction compared to other state-of-the-art methods.", "section": "1 Introduction"}, {"figure_path": "7s53dAJlwz/figures/figures_3_1.jpg", "caption": "Figure 2: Overview of our method. Our method contains two training stage. Stage 1: we train an encoder-decoder structure to take point clouds as input and compress it to a latent tri-plane representation; Stage 2: we employ diffusion to align image modality to latent tri-planes obtained in stage 1. The diffusion step takes an initial noise and an image feature from a freezed DINO feature encoder and progressively align the image feature to the latent tri-plane. Inference: To reconstruct a 3D mesh from a single-view image, we use the alignment step, following the decoder (Plane Decoder, Plane Refiner) from the compression step, to predict a tri-plane. Then, we can use algorithms like marching cubes to extract 3D meshes from the reconstructed tri-plane.", "description": "This figure illustrates the two-stage training process of the LAM3D model. Stage 1 compresses point cloud data into a latent tri-plane representation using a point cloud-based network.  Stage 2 aligns single-view image features to this latent representation using a diffusion-based approach. Finally, the inference stage reconstructs a 3D mesh from a single image by utilizing the aligned tri-plane features and a decoder.", "section": "3 Method"}, {"figure_path": "7s53dAJlwz/figures/figures_6_1.jpg", "caption": "Figure 3: Rendered images of shapes reconstructed by various methods from single images. The upper samples are from Objaverse and the lowers are from Google Scanned Objects.", "description": "This figure displays 3D model reconstructions of various objects generated from single input images using four different methods: One-2-3-45, LRM, CRM, and the authors' proposed LAM3D model.  The top row shows the input image for each object, followed by the 3D reconstructions from each method. The figure highlights the differences in reconstruction quality and detail between the methods, demonstrating the superior performance of LAM3D in generating high-fidelity 3D models from single images. The objects are drawn from the Objaverse and Google Scanned Objects datasets.", "section": "4 Experiments"}, {"figure_path": "7s53dAJlwz/figures/figures_7_1.jpg", "caption": "Figure 4: Qualitative comparisons of different latent representations.", "description": "This figure compares the 3D reconstruction results using different latent representations. (a) shows the reference model. (b) and (c) show results using latent vectors of dimensions 512 and 6114, respectively.  (d) illustrates a model trained without the latent SDF loss (Llsdf), and (e) presents the results obtained with the full model, incorporating all components. The comparison highlights the impact of latent representation dimensionality and the importance of the latent SDF loss for achieving high-fidelity 3D mesh reconstruction.", "section": "4.2 Comparisons with state-of-the-arts"}, {"figure_path": "7s53dAJlwz/figures/figures_8_1.jpg", "caption": "Figure 5: Green objects are generated from parallel UNets and gray samples are from single UNet. ", "description": "This figure shows the results of 3D reconstruction using parallel and single UNets. The left part shows three axes reconstructed using parallel UNets (green) and a single UNet (gray). The right part shows a popsicle reconstructed using parallel UNets (green) and single UNet (gray). The images clearly show that parallel UNets produce better results in terms of detail and completeness.", "section": "4.3 Ablation Study"}, {"figure_path": "7s53dAJlwz/figures/figures_15_1.jpg", "caption": "Figure 2: Overview of our method. Our method contains two training stage. Stage 1: we train an encoder-decoder structure to take point clouds as input and compress it to a latent tri-plane representation; Stage 2: we employ diffusion to align image modality to latent tri-planes obtained in stage 1. The diffusion step takes an initial noise and an image feature from a freezed DINO feature encoder and progressively align the image feature to the latent tri-plane. Inference: To reconstruct a 3D mesh from a single-view image, we use the alignment step, following the decoder (Plane Decoder, Plane Refiner) from the compression step, to predict a tri-plane. Then, we can use algorithms like marching cubes to extract 3D meshes from the reconstructed tri-plane.", "description": "This figure shows the overall architecture of the proposed LAM3D model, which consists of two main stages: point cloud compression and image-point cloud alignment. The point cloud compression stage uses an encoder-decoder structure to compress the point cloud into a latent tri-plane representation.  The image-point cloud alignment stage uses diffusion to align image features to the latent tri-planes. Finally, a decoder is used to generate a 3D mesh from the aligned tri-plane representation.", "section": "3 Method"}, {"figure_path": "7s53dAJlwz/figures/figures_16_1.jpg", "caption": "Figure 7: Alignment approach ablation study. We evaluate the single view reconstruction capability of deterministic vs. probabilistic approaches. Green objects are constructed from our probabilistic approach and gray samples are from a deterministic approach. We also present the reference image.", "description": "This figure shows the results of an ablation study comparing deterministic and probabilistic approaches to single-view 3D reconstruction.  The top row displays examples of character models, and the bottom row shows examples of various objects. For each model type, there are three columns: the first presents the reference image, the second shows the reconstruction using the probabilistic method (our model), and the third shows the reconstruction using the deterministic method. This comparison highlights the improved quality and detail achieved using the probabilistic approach.", "section": "4.3 Ablation Study"}, {"figure_path": "7s53dAJlwz/figures/figures_17_1.jpg", "caption": "Figure 8: We evaluate the single view reconstruction capability of our model w/ and w/o the plane refiner. Green objects are constructed from our model with the plane refiner and gray samples are from a the model without the plane refiner. We also present the reference image.", "description": "This figure shows the results of single-view 3D reconstruction experiments comparing the model with and without the plane refiner module.  The leftmost image shows a reference image of an axe.  The middle image shows a 3D reconstruction of the axe generated by the model *with* the plane refiner, resulting in a more detailed and accurate model. The rightmost image shows the 3D reconstruction generated by the model *without* the plane refiner module, showing some loss of detail. The quantitative comparison (Chamfer Distance) in the table above the images further supports the qualitative observation that the plane refiner improves model accuracy.", "section": "4.3 Ablation Study"}, {"figure_path": "7s53dAJlwz/figures/figures_18_1.jpg", "caption": "Figure 3: Rendered images of shapes reconstructed by various methods from single images. The upper samples are from Objaverse and the lowers are from Google Scanned Objects.", "description": "This figure shows a comparison of 3D object reconstruction results from single images using different methods: One-2-3-45, LRM, CRM, and the authors' proposed method, LAM3D.  The top row displays results from the Objaverse dataset, while the bottom row uses the Google Scanned Objects dataset. Each column represents a different object, with the original reference image shown on the left and the reconstructed 3D model on the right. The comparison highlights the visual quality and geometric accuracy of the reconstructions achieved by each method.", "section": "4 Experiments"}, {"figure_path": "7s53dAJlwz/figures/figures_19_1.jpg", "caption": "Figure 10: Rendered images of shapes reconstructed by our LAM3D from single images on the Objaverse dataset. For each tuple of samples, the left image is the reference image and the right image is the reconstructed geometry.", "description": "This figure shows a comparison between the reference images and the 3D models reconstructed by the LAM3D model from single images.  It visually demonstrates the model's ability to reconstruct a variety of objects from single images, showcasing the accuracy and detail of the generated 3D models.", "section": "4 Experiments"}]