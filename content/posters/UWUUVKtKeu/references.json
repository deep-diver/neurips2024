{"references": [{"fullname_first_author": "Jonathan Ho", "paper_title": "Denoising diffusion probabilistic models", "publication_date": "2020-12-01", "reason": "This paper introduces denoising diffusion probabilistic models (DDPMs), a foundational model for diffusion-based generative models which is leveraged extensively in the current paper's proposed QVPO algorithm."}, {"fullname_first_author": "Scott Fujimoto", "paper_title": "Addressing function approximation error in actor-critic methods", "publication_date": "2018-07-01", "reason": "This paper addresses function approximation error in actor-critic methods, a crucial consideration for the stability and performance of reinforcement learning algorithms like the QVPO algorithm proposed in the current paper."}, {"fullname_first_author": "John Schulman", "paper_title": "Proximal policy optimization algorithms", "publication_date": "2017-07-01", "reason": "This is a highly influential paper that introduces the Proximal Policy Optimization (PPO) algorithm, a widely used method in reinforcement learning that is used as a baseline in the experimental evaluation within the current paper."}, {"fullname_first_author": "Tuomas Haarnoja", "paper_title": "Soft actor-critic: Off-policy maximum entropy deep reinforcement learning with a stochastic actor", "publication_date": "2018-07-01", "reason": "This paper introduces the Soft Actor-Critic (SAC) algorithm, another commonly used reinforcement learning algorithm that is used as a baseline for comparison in the experiments of the current paper."}, {"fullname_first_author": "Richard S Sutton", "paper_title": "Reinforcement learning: An introduction", "publication_date": "2018-01-01", "reason": "This is a highly influential textbook providing a comprehensive overview of reinforcement learning principles which underpins many of the theoretical concepts underlying the current paper's proposed QVPO algorithm."}]}