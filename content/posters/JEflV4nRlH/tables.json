[{"figure_path": "JEflV4nRlH/tables/tables_17_1.jpg", "caption": "Table A.1: Safety performance of different fine-tuning protocols: Unlearning (Liu et al., 2024), DPO (Rafailov et al., 2023) and supervised safety fine-tuning (SSFT) (Ouyang et al., 2022) with medium and small learning rates are used for performing safety fine-tuning. Instruct represents the accuracy of the model to follow instructions and Null represents model's accuracy to output null tokens. Different jailbreaking attacks are also analyzed. JB-CO-Text and JB-MisGen are the strongest attacks where SSFT is easiest to attack.", "description": "This table presents the safety performance of three different safety fine-tuning methods: Unlearning, DPO, and SSFT.  For each method, performance is evaluated using two learning rates (\u03b7\u03bc and \u03b7\u03c2).  The metrics used are the accuracy of the model in following instructions (Instruct) and the accuracy in outputting null tokens (Null).  Additionally, the robustness of each method against three types of jailbreak attacks is tested. The table shows that Unlearning and DPO are more robust than SSFT, particularly against the JB-CO-Text and JB-MisGen attacks.", "section": "B.1.2 Jailbreak and adversarial attacks"}, {"figure_path": "JEflV4nRlH/tables/tables_18_1.jpg", "caption": "Table A.1: Safety performance of different fine-tuning protocols: Unlearning (Liu et al., 2024), DPO (Rafailov et al., 2023) and supervised safety fine-tuning (SSFT) (Ouyang et al., 2022) with medium and small learning rates are used for performing safety fine-tuning. Instruct represents the accuracy of the model to follow instructions and Null represents model's accuracy to output null tokens. Different jailbreaking attacks are also analyzed. JB-CO-Text and JB-MisGen are the strongest attacks where SSFT is easiest to attack.", "description": "This table presents the safety performance of three different safety fine-tuning methods: Unlearning, Direct Preference Optimization (DPO), and Supervised Safety Fine-Tuning (SSFT).  It compares their performance in terms of the model's accuracy in following instructions (Instruct) and outputting null tokens (Null) for both safe and unsafe inputs.  Additionally, it evaluates the model's robustness against several jailbreaking attacks, highlighting which attacks are most effective against which fine-tuning methods.  The learning rates (\u03b7\u043c for medium and \u03b7s for small) used during fine-tuning are also indicated.", "section": "B.1.2 Jailbreak and adversarial attacks"}, {"figure_path": "JEflV4nRlH/tables/tables_27_1.jpg", "caption": "Table A.1: Safety performance of different fine-tuning protocols: Unlearning (Liu et al., 2024), DPO (Rafailov et al., 2023) and supervised safety fine-tuning (SSFT) (Ouyang et al., 2022) with medium and small learning rates are used for performing safety fine-tuning. Instruct represents the accuracy of the model to follow instructions and Null represents model's accuracy to output null tokens. Different jailbreaking attacks are also analyzed. JB-CO-Text and JB-MisGen are the strongest attacks where SSFT is easiest to attack.", "description": "The table presents the performance of three safety fine-tuning methods (Unlearning, DPO, and SSFT) using two different learning rates (medium and small).  The performance is measured by the model's accuracy in following instructions (Instruct) and outputting null tokens (Null) for safe and unsafe samples.  The table also includes the accuracy of the model when facing various jailbreaking attacks (JB-CO-Task, JB-CO-Text, and JB-MisGen).  The results show that SSFT is more susceptible to jailbreaks compared to Unlearning and DPO.", "section": "B.1.2 Jailbreak and adversarial attacks"}, {"figure_path": "JEflV4nRlH/tables/tables_56_1.jpg", "caption": "Table A.1: Safety performance of different fine-tuning protocols: Unlearning (Liu et al., 2024), DPO (Rafailov et al., 2023) and supervised safety fine-tuning (SSFT) (Ouyang et al., 2022) with medium and small learning rates are used for performing safety fine-tuning. Instruct represents the accuracy of the model to follow instructions and Null represents model's accuracy to output null tokens. Different jailbreaking attacks are also analyzed. JB-CO-Text and JB-MisGen are the strongest attacks where SSFT is easiest to attack.", "description": "This table presents the safety performance of three different safety fine-tuning methods: Unlearning, Direct Preference Optimization (DPO), and Supervised Safety Fine-tuning (SSFT).  The performance is evaluated using two metrics: the model's accuracy in following instructions (Instruct) and its accuracy in outputting null tokens when faced with unsafe inputs (Null).  Additionally, the table assesses the model's robustness against several jailbreaking attacks, highlighting the relative strength of each attack and the varying success rates depending on the safety fine-tuning method employed.  The results indicate that Unlearning and DPO are more robust against jailbreaks than SSFT.", "section": "B.1.2 Jailbreak and adversarial attacks"}, {"figure_path": "JEflV4nRlH/tables/tables_59_1.jpg", "caption": "Table A.1: Safety performance of different fine-tuning protocols: Unlearning (Liu et al., 2024), DPO (Rafailov et al., 2023) and supervised safety fine-tuning (SSFT) (Ouyang et al., 2022) with medium and small learning rates are used for performing safety fine-tuning. Instruct represents the accuracy of the model to follow instructions and Null represents model's accuracy to output null tokens. Different jailbreaking attacks are also analyzed. JB-CO-Text and JB-MisGen are the strongest attacks where SSFT is easiest to attack.", "description": "This table presents the safety performance results of three different safety fine-tuning methods: Unlearning, Direct Preference Optimization (DPO), and Supervised Safety Fine-tuning (SSFT).  The performance is evaluated using two metrics: the model's accuracy in following instructions (Instruct) and the accuracy of producing null tokens as a safety response (Null).  Results are shown for various attack scenarios, including different types of jailbreaks. JB-CO-Text and JB-MisGen are highlighted as the strongest attacks, with SSFT being particularly susceptible to these.", "section": "B.1.2 Jailbreak and adversarial attacks"}, {"figure_path": "JEflV4nRlH/tables/tables_65_1.jpg", "caption": "Table A.1: Safety performance of different fine-tuning protocols: Unlearning (Liu et al., 2024), DPO (Rafailov et al., 2023) and supervised safety fine-tuning (SSFT) (Ouyang et al., 2022) with medium and small learning rates are used for performing safety fine-tuning. Instruct represents the accuracy of the model to follow instructions and Null represents model's accuracy to output null tokens. Different jailbreaking attacks are also analyzed. JB-CO-Text and JB-MisGen are the strongest attacks where SSFT is easiest to attack.", "description": "The table presents a quantitative comparison of three safety fine-tuning methods (Unlearning, DPO, and SSFT) across various metrics, including instruction-following accuracy, null-token generation accuracy, and the success rate of different jailbreak attacks. It highlights the trade-offs between these methods and their varying robustness to adversarial attacks.", "section": "B.1.2 Jailbreak and adversarial attacks"}]