[{"figure_path": "qCJ1dq5M7N/figures/figures_0_1.jpg", "caption": "Figure 1: Distribution collapse with LoRA. Visual results generated by the Realistic Vision 3.0 model trained with LoRA and FouRA, for \"Blue Fire\" and \"Origami\" style adapters across four seeds. While LoRA images suffer from distribution collapse and lack diversity, we observe diverse images generated by FouRA.", "description": "This figure shows the results of using LoRA and FouRA to fine-tune a text-to-image diffusion model. The top row shows images generated with LoRA, which exhibit a lack of diversity and a tendency to repeat the same images. The bottom row shows images generated with FouRA, which are more diverse and show a greater variety of styles.", "section": "1 Introduction"}, {"figure_path": "qCJ1dq5M7N/figures/figures_3_1.jpg", "caption": "Figure 2: LoRA v/s FouRA. For FouRA, we transform feature maps to frequency domain, where we learn up and down adapter projections along-with our proposed adaptive rank gating module.", "description": "This figure compares the architecture of the Low Rank Adaptation (LoRA) module with the proposed Fourier Low Rank Adaptation (FouRA) module.  LoRA performs low-rank matrix decomposition in the feature space, while FouRA performs this decomposition in the frequency domain using a Discrete Fourier Transform (DFT) or Discrete Cosine Transform (DCT). FouRA also incorporates an adaptive rank gating mechanism which dynamically adjusts the rank of the adapter based on the input, allowing for greater flexibility and preventing mode collapse. The figure clearly illustrates the addition of the frequency transform and inverse frequency transform steps before and after the core low-rank adaptation in FouRA.", "section": "3 Proposed Approach"}, {"figure_path": "qCJ1dq5M7N/figures/figures_4_1.jpg", "caption": "Figure 2: LoRA v/s FouRA. For FouRA, we transform feature maps to frequency domain, where we learn up and down adapter projections along-with our proposed adaptive rank gating module.", "description": "This figure compares the architectures of LoRA and FouRA.  LoRA performs low-rank adaptation in the feature space, while FouRA performs this adaptation in the frequency domain.  FouRA also incorporates an adaptive rank gating module that dynamically adjusts the rank of the adapter based on the input. The figure highlights the key differences in their approach.", "section": "3 Proposed Approach"}, {"figure_path": "qCJ1dq5M7N/figures/figures_4_2.jpg", "caption": "Figure 4: Singular value spread for FouRA v/s LoRA.", "description": "This figure compares the distribution of singular values for rank-r approximations of LoRA and FouRA adapters (without adaptive masking) for the last layer of a trained U-Net model.  FouRA exhibits a more compact spread of singular values than LoRA. This suggests that using a low-rank approximation, FouRA will have lower accumulated error than LoRA.", "section": "4 Theoretical Analysis"}, {"figure_path": "qCJ1dq5M7N/figures/figures_5_1.jpg", "caption": "Figure 5: Average Effective Rank of FouRA. Figure a. and b. shows plots for the average effective rank for various layers of the FouRA U-Net (Darker lines correspond to higher resolutions) and Figure c. compares the average effective rank of FouRA to SORA. FouRA's effective rank reduces with the feature resolution, and it also reduces as the diffusion process proceeds, owing to lesser changes required towards the end.", "description": "This figure displays the average effective rank of FouRA across different layers of the UNet (downsampling and upsampling blocks) at various resolutions and diffusion timesteps.  Subfigure (a) and (b) show that the effective rank decreases with increasing resolution and timestep. This indicates that FouRA dynamically adapts the rank based on the input and progress of the diffusion process, suggesting efficiency. Subfigure (c) compares FouRA's adaptive rank with the fixed rank of the SORA method, highlighting FouRA's flexibility.", "section": "4.2 Gated Frequency Domain Fine Tuning"}, {"figure_path": "qCJ1dq5M7N/figures/figures_6_1.jpg", "caption": "Figure 6: FouRA v/s LoRA: The prompt on the left is \"a football in a field\" and on the right is \"man in a mythical forest\". While staying more faithful to the adapter style, FouRA outputs look aesthetically better than LoRA, which have obvious artifacts at high values of \u03b1. Additional results are in Appendix E.", "description": "This figure compares the image generation results of FouRA and LoRA for two different prompts.  The left-hand side shows a football, and the right-hand side shows a man.  Both methods use the \"Blue Fire\" and \"Painting\" style adapters. As the adapter strength (\u03b1) increases, LoRA shows artifacts while FouRA maintains better visual quality.", "section": "5 Experiments"}, {"figure_path": "qCJ1dq5M7N/figures/figures_7_1.jpg", "caption": "Figure 7: Multi-Adapter Fusion in LoRA v/s FouRA. Sample images for style transfer on various prompts (e.g., bird, car, fox) for Paintings, Bluefire, 3D and Merged adapters. Observe the highlighted merged images. FouRA does a much better job in preserving both styles, compared to LoRA.", "description": "This figure compares the results of multi-adapter fusion in LoRA and FouRA models for style transfer tasks.  It shows example images generated using different prompts (bird, car, fox) and combinations of three styles (Paintings, Bluefire, and 3D). The highlighted merged images illustrate FouRA's superior ability to preserve both styles compared to LoRA, which often loses one of the concepts or produces artifacts.", "section": "5.2 Text-to-Image Stylized Generation"}, {"figure_path": "qCJ1dq5M7N/figures/figures_8_1.jpg", "caption": "Figure 8: LORA v/s FouRA. Age (Left) and Hair (right) concept slider examples where as the scale increases the effect of disentanglement in FouRA is more prominent. For larger scales the gender of the person changes in Age LoRA, and the structure of the face changes in Hair LoRA.", "description": "This figure shows the results of concept editing experiments using LoRA and FouRA.  Two concepts, \"Age\" and \"Hair\", were tested. As the strength of the concept increases, the images generated by FouRA exhibit better disentanglement than LoRA. LoRA shows artifacts such as changing the gender of a person (Age concept) or distorting facial features (Hair concept) at higher strength values.", "section": "5.3 Text-to-Image Concept Editing"}, {"figure_path": "qCJ1dq5M7N/figures/figures_9_1.jpg", "caption": "Figure 9: Comparison of different rank selection methods.", "description": "This figure compares different rank selection methods: LoRA, SORA, LoRA + Adaptive Mask, and FouRA.  It shows the HPS-v2.1 scores plotted against different alpha (adapter strength) values. This illustrates the performance of each method across different adapter strength settings and highlights the effectiveness of FouRA's inference-adaptive rank selection strategy for vision tasks, which dynamically varies the rank during inference, improving performance and generalization compared to fixed-rank methods.", "section": "Varying the Adaptive Rank Selection Strategy in Text-to-Image Stylized Generation"}, {"figure_path": "qCJ1dq5M7N/figures/figures_9_2.jpg", "caption": "Figure 6: FouRA v/s LoRA: The prompt on the left is \"a football in a field\" and on the right is \"man in a mythical forest\". While staying more faithful to the adapter style, FouRA outputs look aesthetically better than LoRA, which have obvious artifacts at high values of \u03b1. Additional results are in Appendix E.", "description": "This figure compares the image generation results of FouRA and LoRA for two different prompts.  It demonstrates that FouRA produces aesthetically pleasing images that are more faithful to the intended style, unlike LoRA, which shows noticeable artifacts at higher values of the adapter strength (\u03b1).  The appendix contains additional results.", "section": "5 Experiments"}, {"figure_path": "qCJ1dq5M7N/figures/figures_16_1.jpg", "caption": "Figure B.1: Amplification Factor of FouRA v/s LoRA: As the computed Amplification Factor referred to in B.3 is higher in case of FouRA, we justify the learnt representations are more de-correlated from the base weights.", "description": "This figure shows the amplification factors for LoRA and FouRA at different ranks. The amplification factor measures how much the learned adapter subspaces emphasize certain directions in the original model's weight space.  Higher values suggest that the learned subspaces are more distinct from the original model.  FouRA consistently shows higher amplification factors than LoRA, indicating that FouRA learns more decorrelated subspaces, improving generalization and reducing the risk of overfitting.", "section": "B.3 Subspace analysis"}, {"figure_path": "qCJ1dq5M7N/figures/figures_19_1.jpg", "caption": "Figure 1: Distribution collapse with LoRA. Visual results generated by the Realistic Vision 3.0 model trained with LoRA and FouRA, for \"Blue Fire\" and \"Origami\" style adapters across four seeds. While LoRA images suffer from distribution collapse and lack diversity, we observe diverse images generated by FouRA.", "description": "This figure shows a comparison of image generation results between LoRA and FouRA, two methods for fine-tuning large vision models.  Four different images are shown for each method, using two different style adapters (\"Blue Fire\" and \"Origami\") and four different random seeds.  LoRA's outputs show a lack of diversity and tend to be very similar across seeds, demonstrating a phenomenon known as \"distribution collapse.\"  In contrast, FouRA's outputs are more varied and diverse, suggesting that it successfully addresses the distribution collapse problem.", "section": "1 Introduction"}, {"figure_path": "qCJ1dq5M7N/figures/figures_20_1.jpg", "caption": "Figure 1: Distribution collapse with LoRA. Visual results generated by the Realistic Vision 3.0 model trained with LoRA and FouRA, for \"Blue Fire\" and \"Origami\" style adapters across four seeds. While LoRA images suffer from distribution collapse and lack diversity, we observe diverse images generated by FouRA.", "description": "This figure shows a comparison of image generation results using LoRA and FouRA, two different low-rank adaptation methods for fine-tuning large language models.  Four different image prompts were used with two different styles (\"Blue Fire\" and \"Origami\").  The figure demonstrates that LoRA suffers from distribution collapse (lack of diversity in generated images, with multiple generations showing nearly identical results), while FouRA produces more diverse and visually appealing results.", "section": "1 Introduction"}, {"figure_path": "qCJ1dq5M7N/figures/figures_22_1.jpg", "caption": "Figure 2: LoRA v/s FouRA. For FouRA, we transform feature maps to frequency domain, where we learn up and down adapter projections along-with our proposed adaptive rank gating module.", "description": "This figure compares the architecture of LoRA and FouRA.  LoRA has a simple down-projection and up-projection in the feature space. FouRA, in contrast, performs these projections in the frequency domain.  Additionally, FouRA incorporates an adaptive rank gating module that dynamically adjusts the rank of the adapter during inference.  This gating allows FouRA to balance between overfitting and underfitting more effectively than LoRA.", "section": "3 Proposed Approach"}, {"figure_path": "qCJ1dq5M7N/figures/figures_22_2.jpg", "caption": "Figure 6: FouRA v/s LoRA: The prompt on the left is \"a football in a field\" and on the right is \"man in a mythical forest\". While staying more faithful to the adapter style, FouRA outputs look aesthetically better than LoRA, which have obvious artifacts at high values of \u03b1. Additional results are in Appendix E.", "description": "This figure compares the image generation results of FouRA and LoRA for two different prompts.  It visually demonstrates FouRA's improved aesthetic quality and its ability to remain faithful to the adapter style, even at high values of the adapter strength parameter (\u03b1), unlike LoRA, which shows noticeable artifacts at high \u03b1 values.  The appendix contains more detailed results.", "section": "5 Experiments"}, {"figure_path": "qCJ1dq5M7N/figures/figures_23_1.jpg", "caption": "Figure 5: Average Effective Rank of FouRA. Figure a. and b. shows plots for the average effective rank for various layers of the FouRA U-Net (Darker lines correspond to higher resolutions) and Figure c. compares the average effective rank of FouRA to SORA. FouRA's effective rank reduces with the feature resolution, and it also reduces as the diffusion process proceeds, owing to lesser changes required towards the end.", "description": "This figure shows the average effective rank of FouRA across different layers of the U-Net for different resolutions.  It demonstrates how the effective rank decreases as the resolution decreases and as the diffusion process progresses, implying that the model requires fewer parameters as it refines the image.", "section": "4.2 Gated Frequency Domain Fine Tuning"}, {"figure_path": "qCJ1dq5M7N/figures/figures_23_2.jpg", "caption": "Figure 5: Average Effective Rank of FouRA. Figure a. and b. shows plots for the average effective rank for various layers of the FouRA U-Net (Darker lines correspond to higher resolutions) and Figure c. compares the average effective rank of FouRA to SORA. FouRA's effective rank reduces with the feature resolution, and it also reduces as the diffusion process proceeds, owing to lesser changes required towards the end.", "description": "This figure shows the average effective rank of FouRA across different layers of the U-Net and across different resolutions for upsampling and downsampling blocks. It also compares the adaptive rank selection strategy of FouRA to the fixed rank selection strategy of SORA. The results show that FouRA's effective rank decreases with increasing resolution and decreases as the diffusion process progresses, indicating improved efficiency in learning the data distribution during the diffusion process.", "section": "4.2 Gated Frequency Domain Fine Tuning"}, {"figure_path": "qCJ1dq5M7N/figures/figures_24_1.jpg", "caption": "Figure 6: FouRA v/s LoRA: The prompt on the left is \"a football in a field\" and on the right is \"man in a mythical forest\". While staying more faithful to the adapter style, FouRA outputs look aesthetically better than LoRA, which have obvious artifacts at high values of \u03b1. Additional results are in Appendix E.", "description": "This figure compares the image generation results of FouRA and LoRA for two different prompts.  The results show that FouRA produces aesthetically pleasing images that are more faithful to the specified adapter style, while LoRA's images exhibit noticeable artifacts at higher values of the adapter strength parameter (\u03b1).", "section": "5 Experiments"}, {"figure_path": "qCJ1dq5M7N/figures/figures_24_2.jpg", "caption": "Figure 6: FouRA v/s LoRA: The prompt on the left is \"a football in a field\" and on the right is \"man in a mythical forest\". While staying more faithful to the adapter style, FouRA outputs look aesthetically better than LoRA, which have obvious artifacts at high values of \u03b1. Additional results are in Appendix E.", "description": "This figure compares the image generation results of FouRA and LoRA for two different prompts.  It shows that FouRA generates images that are more faithful to the requested style and aesthetically pleasing, while LoRA's images exhibit artifacts at higher adapter strength values (\u03b1).", "section": "5 Experiments"}, {"figure_path": "qCJ1dq5M7N/figures/figures_25_1.jpg", "caption": "Figure F.2: Age FouRA Slider, \"Portrait of a doctor\" (top) and \"Photo of an Hispanic man\" (bottom).", "description": "This figure shows the results of using the FouRA adapter for age manipulation with concept sliders.  The top row shows results for the prompt \"Portrait of a doctor\", and the bottom row shows results for the prompt \"Photo of an Hispanic man\". Each row shows images generated with increasing positive strength of the \"Age\" slider, demonstrating the effect of age manipulation.", "section": "F Additional Experiments for Text-to-Image Editing using Concept Sliders"}, {"figure_path": "qCJ1dq5M7N/figures/figures_25_2.jpg", "caption": "Figure F.2: Age FouRA Slider, \"Portrait of a doctor\" (top) and \"Photo of an Hispanic man\" (bottom).", "description": "This figure shows the results of using FouRA's age slider on two different images. The top row shows the results on a portrait of a doctor, while the bottom row shows the results on a photo of a Hispanic man.  The images show how the age slider can be used to change the age of a person in an image, while keeping other attributes such as gender and race relatively consistent.  The figure demonstrates the ability of FouRA to achieve a smooth transition between different ages, as well as its ability to maintain the overall quality and coherence of the image. This is in contrast to LoRA, which tends to introduce artifacts or distort the face when adjusting age.", "section": "FAdditional Experiments for Text-to-Image Editing using Concept Sliders"}, {"figure_path": "qCJ1dq5M7N/figures/figures_26_1.jpg", "caption": "Figure F.3: Hair Slider: We find that as the strength of the adapter increases the curls increase. In the top image we also see minor variations in the facial details of the person.", "description": "This figure shows the results of using a \"Curly Hair\" slider with varying strengths.  The top row shows results using the LoRA model, while the bottom row shows results using the FouRA model.  The images demonstrate how the level of \"curliness\" in the hair increases with increasing adapter strength.  The FouRA model shows less variation in other facial features compared to the LoRA model, which shows some changes in facial features along with the change in hair.", "section": "F Additional Experiments for Text-to-Image Editing using Concept Sliders"}, {"figure_path": "qCJ1dq5M7N/figures/figures_26_2.jpg", "caption": "Figure 1: Distribution collapse with LoRA. Visual results generated by the Realistic Vision 3.0 model trained with LoRA and FouRA, for \"Blue Fire\" and \"Origami\" style adapters across four seeds. While LoRA images suffer from distribution collapse and lack diversity, we observe diverse images generated by FouRA.", "description": "This figure compares the image generation results of LoRA and FouRA, two low-rank adaptation methods, when fine-tuning a text-to-image diffusion model.  Four different image prompts were used with two distinct style adapters (\"Blue Fire\" and \"Origami\"). Each combination was run with four different random seeds. The results demonstrate that LoRA suffers from a lack of diversity and a tendency to copy data from the training set (distribution collapse), especially when using higher-rank adapters. FouRA, on the other hand, produces diverse and high-quality images, effectively addressing LoRA's limitations.", "section": "1 Introduction"}, {"figure_path": "qCJ1dq5M7N/figures/figures_27_1.jpg", "caption": "Figure 8: LORA v/s FouRA. Age (Left) and Hair (right) concept slider examples where as the scale increases the effect of disentanglement in FouRA is more prominent. For larger scales the gender of the person changes in Age LoRA, and the structure of the face changes in Hair LoRA.", "description": "This figure shows the results of using concept sliders for age and hair editing using LoRA and FouRA. As the strength of the slider increases, LoRA produces increasingly distorted results, changing the gender or facial structure, while FouRA maintains a more realistic appearance with less artifact.", "section": "5.3 Text-to-Image Concept Editing"}, {"figure_path": "qCJ1dq5M7N/figures/figures_27_2.jpg", "caption": "Figure F.5: Composite FouRA. Composite surprised, age slider. Here we show the combined adapter as the strengths of each adapter are jointly incremented in each step in the image. The adapter strengths are (-6 6) for left most image and (6,6) for the right most image. The positive prompt for surprised face prompt: \"looking surprised, wide eyes, open mouth\"", "description": "This figure shows the results of using FouRA for composite editing. Two sliders, \"surprise\" and \"age\", are used to modify a base image. The figure displays a grid of images showing how the combined effect of both sliders changes the image as their individual strengths vary from -6 to 6.  The captions provide the prompt used for the surprised face.", "section": "F Additional Experiments for Text-to-Image Editing using Concept Sliders"}, {"figure_path": "qCJ1dq5M7N/figures/figures_28_1.jpg", "caption": "Figure F.5: Composite FouRA. Composite surprised, age slider. Here we show the combined adapter as the strengths of each adapter are jointly incremented in each step in the image. The adapter strengths are (-6 6) for left most image and (6,6) for the right most image. The positive prompt for surprised face prompt: \"looking surprised, wide eyes, open mouth\"", "description": "This figure shows the results of using a composite adapter with two sliders: \"Surprise\" and \"Age\". The figure demonstrates how FouRA handles the combination of these two sliders at various strength levels, ranging from strongly negative to strongly positive. Each row represents a fixed \"Surprise\" slider strength, while each column represents a fixed \"Age\" slider strength. The figure highlights FouRA's ability to smoothly transition between the different styles and maintain image quality even at high strength values.", "section": "F Additional Experiments for Text-to-Image Editing using Concept Sliders"}]