[{"figure_path": "UqvAFl0lkT/figures/figures_1_1.jpg", "caption": "Figure 1: Top-view visualization of a wall-free 3D environment with different objects (e.g., red and blue cubes, purple and green keys, and green ball) showing the trajectory (from blue to red dots) of a randomly-walking embodied agent, with first-person perspectives highlighted at relevant timesteps using colored cones - showing the agent's viewpoint direction when a new utterance is used to describe the first-person perspective using an oracle speaking in NL.", "description": "This figure shows a top-down view of a 3D environment where an embodied agent is moving randomly.  The environment contains various colored objects such as cubes and keys. The agent's path is depicted by a series of dots, and cones illustrate the agent's viewpoint at specific moments when a natural language description of the scene is generated.  The image helps to visualize the concept of using natural language to create state abstractions in reinforcement learning.", "section": "1 Introduction"}, {"figure_path": "UqvAFl0lkT/figures/figures_4_1.jpg", "caption": "Figure 2: Toy example illustration of how different languages expose different semantics over the same observed trajectory of stimuli, and that the discrepancy in exposed semantics can be captured by an histogram of semantic-clustering timespans.", "description": "This figure illustrates how two different languages, Blue and Color, represent the same sequence of stimuli (a trajectory of an agent's observations) differently. The Blue language focuses solely on the presence or absence of blue objects, while the Color language describes all colors present.  The resulting histograms of \"semantic-clustering timespans\" (duration of consecutive occurrences of the same utterance) are different for each language, demonstrating how the languages abstract and cluster the state space in different ways.  This difference is the basis for the Compactness Ambiguity Metric, which quantifies the compactness of the semantic clustering performed by each language.", "section": "3.1 Compactness Ambiguity Metric"}, {"figure_path": "UqvAFl0lkT/figures/figures_5_1.jpg", "caption": "Figure 3: EReLELA architecture consisting of a stimulus/observation encoder shared between an RL agent and the speaker and listener agents of a RG, framed as an unsupervised auxiliary task [31]. The language utterances outputted by the RG speaker agent are used in a count-based exploration method to generate intrinsic rewards for the RL agent.", "description": "The figure shows the architecture of ERELELA, which consists of three agents: a reinforcement learning (RL) agent, a speaker agent, and a listener agent.  The RL agent and the two referential game (RG) agents share a common observation encoder. The speaker agent generates language utterances based on observations, which are then used by an intrinsic reward generator to provide intrinsic rewards to the RL agent. This helps guide the RL agent's exploration in environments with sparse rewards. The architecture incorporates an unsupervised auxiliary task in the form of the referential game to help learn emergent language abstractions.", "section": "3.2 ERELELA Architecture"}, {"figure_path": "UqvAFl0lkT/figures/figures_6_1.jpg", "caption": "Figure 4: Success rate learning curve (left), computed as running averages over 1024 episodes each time (i.e. 32 in parallel, as there are 32 actors, over 32 running average steps), and barplot (right), along with per-episode manipulation count (middle) in KeyCorridor-S3-R2 from MiniGrid [15], for different agents: (i) the Natural Language Abstraction agent (NLA) refers to using the NL oracle to compute intrinsic reward, (ii) the STGS-LazImpa-B1-B2 ERELELA agents with \u03b2\u2081 = 5 (agnostic only) or \u03b2\u2081 = 10 (shared and agnostic), and \u03b2\u2082 = 1, (iii) the Impatient-Only ERELELA agents (shared and agnostic), and (iv) the RANDOM agent referring to an ablated version of ERELELA without RG training.", "description": "This figure displays the success rate and manipulation count of various RL agents over a KeyCorridor-S3-R2 environment.  The agents use different methods for exploration: Natural Language Abstraction (NLA),  STGS-LazImpa ERELELA (with different settings for shared/agnostic training), Impatient-Only ERELELA, and a random agent as a baseline.  The left plot shows success rates over training steps; the middle plot shows the manipulation count; and the right plot summarizes the final success rates. The results show the performance of different exploration strategies, demonstrating the effectiveness of the proposed emergent language-based method (ERELELA).", "section": "4 Experiments"}, {"figure_path": "UqvAFl0lkT/figures/figures_7_1.jpg", "caption": "Figure 5: CAM distances to NL (left), Color language (middle), and Shape language (right), for ELs brought about in KeyCorridor-S3-R2 from MiniGrid [15], with different agents: (i) the STGS-LazImpa-B1-B2 ERELELA agents with B\u2081 = 5 (agnostic only) or \u03b2\u2081 = 10 (shared and agnostic), and B2 = 1, (ii) the Impatient-Only ERELELA agents (shared and agnostic), and (iii) the RANDOM agent referring to an ablated version of ERELELA without RG training.", "description": "This figure displays the Compactness Ambiguity Metric (CAM) distances between emergent languages (ELs) generated by different agents and three reference languages: Natural Language, Color Language, and Shape Language.  The x-axis represents the number of referential game (RG) epochs.  The y-axis represents the CAM distance, a measure of how similar the EL's abstractions are to those of the reference language. Lower values indicate greater similarity. The figure helps to assess whether the ELs generated by different training methods exhibit similar or meaningful abstractions compared to human-like languages.", "section": "4.2 ERELELA learns Meaningful Abstractions"}, {"figure_path": "UqvAFl0lkT/figures/figures_22_1.jpg", "caption": "Figure 4: Success rate learning curve (left), computed as running averages over 1024 episodes each time (i.e. 32 in parallel, as there are 32 actors, over 32 running average steps), and barplot (right), along with per-episode manipulation count (middle) in KeyCorridor-S3-R2 from MiniGrid [15], for different agents: (i) the Natural Language Abstraction agent (NLA) refers to using the NL oracle to compute intrinsic reward, (ii) the STGS-LazImpa-B1-B2 ERELELA agents with \u03b2\u2081 = 5 (agnostic only) or \u03b2\u2081 = 10 (shared and agnostic), and \u03b2\u2082 = 1, (iii) the Impatient-Only ERELELA agents (shared and agnostic), and (iv) the RANDOM agent referring to an ablated version of ERELELA without RG training.", "description": "The figure shows the success rate, manipulation count, and test-time relative expressivity of different RL agents trained on the KeyCorridor-S3-R2 environment. The agents include a natural language abstraction agent (NLA), and various ERELELA agents with different configurations, and a random agent for comparison.  The results are visualized as learning curves and bar plots, comparing the performance of each agent throughout the training process.", "section": "4 Experiments"}, {"figure_path": "UqvAFl0lkT/figures/figures_24_1.jpg", "caption": "Figure 8: Interval validity measures of Compactness Ambiguity Metric for N = 6 timespans/thresholds, with \u03bb\u2080 = 0.0306125, \u03bb\u2081 = 0.06125, \u03bb\u2082 = 0.125, \u03bb\u2083 = 0.25, \u03bb\u2084 = 0.5 and \u03bb\u2085 = 0.75, for different languages built to perform different kind of abstraction. We can qualitatively discriminate between each languages, and validate that the shuffled (natural) language's meaningless abstraction scores almost null.", "description": "This figure displays the results of an internal validity assessment for the Compactness Ambiguity Metric (CAM).  The CAM measures how different languages perform abstractions on a set of stimuli (here, agent trajectories in a 3D environment). The figure shows box plots comparing CAM scores for different types of languages designed to exhibit various levels of abstraction (Natural Language, Blue Language, Green Language, Color Language, Shape Language, Shuffled Natural Language), demonstrating the metric's ability to differentiate between abstraction levels and to assess the meaningfulness of an abstraction by comparing its scores against a baseline (Shuffled Natural Language) representing the absence of abstraction.", "section": "3.1 Compactness Ambiguity Metric"}, {"figure_path": "UqvAFl0lkT/figures/figures_25_1.jpg", "caption": "Figure 8: Interval validity measures of Compactness Ambiguity Metric for N = 6 timespans/thresholds, with \u03bb\u2080 = 0.0306125, \u03bb\u2081 = 0.06125, \u03bb\u2082 = 0.125, \u03bb\u2083 = 0.25, \u03bb\u2084 = 0.5 and \u03bb\u2085 = 0.75, for different languages built to perform different kind of abstraction. We can qualitatively discriminate between each languages, and validate that the shuffled (natural) language\u2019s meaningless abstraction scores almost null.", "description": "This figure presents the results of an experiment designed to validate the Compactness Ambiguity Metric (CAM).  Six boxplots are shown, one for each of the six time thresholds used in the CAM calculation. Each boxplot shows the distribution of CAM scores for different types of languages: a natural language, a shuffled natural language (a control condition), a blue-only language, a green-only language, a color language (describing all colors), and a shape language (describing all shapes). The results support the validity of the CAM metric by demonstrating that it can distinguish between different types of language abstractions and that a language designed to lack meaningful abstractions scores near zero.", "section": "3.1 Compactness Ambiguity Metric"}, {"figure_path": "UqvAFl0lkT/figures/figures_26_1.jpg", "caption": "Figure 4: Success rate learning curve (left), computed as running averages over 1024 episodes each time (i.e. 32 in parallel, as there are 32 actors, over 32 running average steps), and barplot (right), along with per-episode manipulation count (middle) in KeyCorridor-S3-R2 from MiniGrid [15], for different agents: (i) the Natural Language Abstraction agent (NLA) refers to using the NL oracle to compute intrinsic reward, (ii) the STGS-LazImpa-B1-B2 ERELELA agents with B\u2081 = 5 (agnostic only) or \u03b2\u2081 = 10 (shared and agnostic), and B\u2082 = 1, (iii) the Impatient-Only ERELELA agents (shared and agnostic), and (iv) the RANDOM agent referring to an ablated version of ERELELA without RG training.", "description": "This figure presents the results of the experiment conducted in the KeyCorridor-S3-R2 environment of MiniGrid.  The learning curves show success rate and manipulation count over training steps for four different agents: Natural Language Abstraction (NLA), two versions of the ERELELA agent (STGS-LazImpa and Impatient-Only), and a RANDOM agent (ablated ERELELA without RG training).  The bar chart provides a final comparison of success rate. The results illustrate the performance of agents using different methods for exploration in a challenging environment.", "section": "4 Experiments"}, {"figure_path": "UqvAFl0lkT/figures/figures_26_2.jpg", "caption": "Figure 11: Performance and qualities of the ELs brought about in the context of both (i) the STGS-LazImpa ERELELA agent, and (ii) the Impatient-Only ERELELA agent, with respect to both the training- and validation/testing-time RG accuracy (left), the validation/test-time Instantaneous Coordination [32, 47, 23](middle), and the validation/testing-time length of the speaker\u2019s messages (as a ratio over the max sentence length L = 128 - right).", "description": "This figure compares two different versions of the ERELELA agent, one using the STGS-LazImpa loss function and the other using the Impatient-Only loss function, in terms of their performance on a referential game task. The figure shows the RG accuracy (how well the speaker and listener agents communicate), instantaneous coordination (a measure of how well the agents work together), and the length of the messages generated by the speaker agent. The results show that the STGS-LazImpa agent achieves better accuracy, coordination and produces shorter messages than the Impatient-Only agent.", "section": "4.1 ERELELA learns Systematic Navigational & Manipulative Exploration Skills from Scratch"}, {"figure_path": "UqvAFl0lkT/figures/figures_27_1.jpg", "caption": "Figure 12: Comparison of Compactness Ambiguity Metric scores for N = 6 timespans/thresholds, with \u03bb\u2080 = 0.0306125, \u03bb\u2081 = 0.06125, \u03bb\u2082 = 0.125, \u03bb\u2083 = 0.25, \u03bb\u2084 = 0.5 and \u03bb\u2085 = 0.75, between the abstractions performed by ELs brought about in the context of both (i) the STGS-LazImpa ERELELA agent (in green, first rows) and (ii) the Impatient-Only ERELELA agent (in purple, bottom rows), and the abstractions performed by the natural, colour-specific, and shape-specific languages, computed on the very same agent trajectories.", "description": "The figure compares Compactness Ambiguity Metric scores for different language types.  It shows the scores for emergent languages generated by two different ERELELA agent variations (STGS-Lazimpa and Impatient-Only) and compares them to natural language, color-specific language, and shape-specific language scores. The comparison helps analyze how well each type of language captures semantic information in a given context.", "section": "E.2 Experiment #2: Qualities of Emergent Languages Abstractions in 3D environment"}, {"figure_path": "UqvAFl0lkT/figures/figures_28_1.jpg", "caption": "Figure 13: Relative expressivity of the EL as a function of the per-episode coverage of the RL agent, at the end of training, over multiple runs with different hyperparameters during a W&B Sweep [4].", "description": "This figure shows the relationship between the relative expressivity of the emergent language and the per-episode coverage of the RL agent. The relative expressivity is a measure of how many unique utterances are produced by the language model, while the per-episode coverage is a measure of how much of the environment the agent has explored.  The plot shows that as the agent becomes more skilled at exploration (higher per-episode coverage), the expressivity of the emergent language also increases.  This suggests that the emergent language is adapting to the agent's growing understanding of the environment.  The R-squared value of 0.4642 indicates a moderate positive correlation between the two variables.", "section": "4.1 ERELELA learns Systematic Navigational & Manipulative Exploration Skills from Scratch"}]