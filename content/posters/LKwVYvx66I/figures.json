[{"figure_path": "LKwVYvx66I/figures/figures_40_1.jpg", "caption": "Figure 1: Average of 60 runs", "description": "This figure shows the result of numerical simulations performed on exponential bandits using the OFU-GLB algorithm. The plot displays the average regret (the total cumulative shortfall of the mean reward of the arms the learner chose relative to the optimal choice) across 60 independent runs, along with standard deviation error bars, plotted against the time horizon (number of rounds).  The plot visually demonstrates the sublinear growth of regret over time, consistent with the theoretical findings of the paper.", "section": "Numerical Simulations"}, {"figure_path": "LKwVYvx66I/figures/figures_40_2.jpg", "caption": "Figure 2: The log-log plot of OFU-GLM", "description": "This log-log plot shows the relationship between the logarithm of the regret and the logarithm of the horizon for the OFU-GLM algorithm.  The plot visually demonstrates that the growth rate of the regret approaches \u221aT, confirming the theoretical bound established in the paper.", "section": "Numerical Simulations"}]