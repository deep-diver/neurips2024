[{"figure_path": "UGUkPYSdg4/tables/tables_6_1.jpg", "caption": "Table 1: Comparison of transformation-based augmentation methods on Caltech-101. Our approach, combined with default augmentation (crop, flip, and rotate), consistently outperforms existing advanced transform-based methods and can be further improved by combining these techniques.", "description": "This table compares the performance of DistDiff with several traditional transformation-based data augmentation methods on the Caltech-101 dataset.  It shows that DistDiff consistently outperforms these methods, even when combined with default augmentations like cropping, flipping, and rotation.  The results suggest that DistDiff's ability to generate more diverse and informative samples leads to significant improvements in classification accuracy.", "section": "4.3 Main Results"}, {"figure_path": "UGUkPYSdg4/tables/tables_6_2.jpg", "caption": "Table 2: Comparison of using stronger pre-trained baseline models. On ImageNette [28], Caltech-101 [16], and StanfordCars [30] datasets, we employ an ImageNet-1k [11] pre-trained ResNet-50 [21] model. For the PathMNIST [68] dataset, we fine-tune using the stronger CLIP-ViT-B/32 baseline.", "description": "This table compares the performance of using stronger pre-trained models (ResNet-50 pre-trained on ImageNet-1k and CLIP-ViT-B/32 pre-trained on LAION) on four datasets (ImageNette, Caltech-101, StanfordCars, and PathMNIST) with and without DistDiff data augmentation.  It shows that DistDiff consistently improves or maintains accuracy compared to the original dataset and models expanded with Stable Diffusion, especially showcasing significant improvements on datasets with greater distribution shifts, such as StanfordCars and PathMNIST.", "section": "4. Experiments"}, {"figure_path": "UGUkPYSdg4/tables/tables_7_1.jpg", "caption": "Table 3: Performance comparison of models trained on original Caltech-101 datasets and 5x expanded datasets by DistDiff.", "description": "This table presents a comparison of the performance of different convolutional neural network backbones trained on the original Caltech-101 dataset and the same dataset expanded five times using the DistDiff method. The backbones compared are ResNet-50, ResNeXt-50, WideResNet-50, and MobileNetV2.  The table shows that using the DistDiff method for data expansion significantly improves the performance of all four backbones on the Caltech-101 dataset.", "section": "4.3 Main Results"}, {"figure_path": "UGUkPYSdg4/tables/tables_7_2.jpg", "caption": "Table 4: Comparison of accuracy and FID in expanding Caltech-101 by 5\u00d7, with and without hierarchical prototypes in DistDiff.", "description": "This table shows the impact of using hierarchical prototypes (class-level prototypes (pc) and group-level prototypes (pg)) on the performance of the DistDiff model.  The experiment involves expanding the Caltech-101 dataset by a factor of 5. The table reports the accuracy and Fr\u00e9chet Inception Distance (FID) scores. The results demonstrate that using both class-level and group-level prototypes significantly improves both accuracy and FID scores compared to using only one or neither type of prototype.  Lower FID scores indicate better alignment between the generated data distribution and the real data distribution.", "section": "4.4 Ablation Study"}, {"figure_path": "UGUkPYSdg4/tables/tables_7_3.jpg", "caption": "Table 6: Ablation of the number K of pg in DistDiff.", "description": "This table shows the ablation study on the number of group-level prototypes (K) used in the DistDiff model. It demonstrates that using 3 group-level prototypes provides the best accuracy. Using fewer prototypes may result in insufficient characterization of the real distribution, and using more prototypes may lead to overfitting on noisy sample points.", "section": "4.4 Ablation Study"}, {"figure_path": "UGUkPYSdg4/tables/tables_7_4.jpg", "caption": "Table 5: Comparison of optimization in different phases.", "description": "This table presents the results of an ablation study on the optimization step (M) in the DistDiff algorithm. It shows the accuracy achieved with different values of M, demonstrating the impact of optimizing at different stages of the diffusion sampling process on the final performance. The optimal performance is observed at M=20, indicating that optimizing at an intermediate stage (semantic stage) is crucial for achieving better performance. Optimizing too early (M=1) or too late (M=25) leads to suboptimal results.", "section": "4 Experiments"}, {"figure_path": "UGUkPYSdg4/tables/tables_7_5.jpg", "caption": "Table 7: Results of introducing more optimization steps.", "description": "This table presents the results of an ablation study investigating the impact of varying the number of optimization steps (M) in the DistDiff algorithm on the model's accuracy in image classification. The results show that increasing the number of optimization steps within a certain range can improve performance; however, excessive optimization can lead to a decline in accuracy, likely due to overfitting or over-optimization.", "section": "4.4 Ablation Study"}, {"figure_path": "UGUkPYSdg4/tables/tables_14_1.jpg", "caption": "Table 8: Summary of our six experimental datasets.", "description": "This table presents the details of the six datasets used in the experiments.  It includes the name of each dataset, the number of classes, the size of the training and testing sets, and a brief description of the dataset content (e.g., recognition of generic objects, fine-grained classification of cars, texture classification, recognition of colon pathology images). The datasets vary in size and complexity, covering different image classification tasks.", "section": "B.1 Datasets"}, {"figure_path": "UGUkPYSdg4/tables/tables_15_1.jpg", "caption": "Table 9: Text templates for six experimental datasets.", "description": "This table lists the text prompts used for generating synthetic images for each of the six datasets used in the experiments.  The prompts are designed to guide the Stable Diffusion model in generating images consistent with the class labels.  The bracketed `[CLASS]` is a placeholder that is replaced with the actual class label when generating an image.", "section": "B More Implementation Details"}, {"figure_path": "UGUkPYSdg4/tables/tables_16_1.jpg", "caption": "Table 10: Comparison of guidance models on Caltech-101 dataset. We compared the accuracy of two guidance models on the original Caltech-101 dataset. Additionally, we evaluated the performance of a downstream classifier trained on the 5\u00d7 expanded dataset using corresponding guide model.", "description": "This table compares the performance of two different guidance models (a weak model trained from scratch and a strong pre-trained model) in a downstream classification task on the Caltech-101 dataset.  It shows the accuracy of each guidance model itself and the accuracy of a classifier trained using data expanded by DistDiff with each of the guidance models. The results demonstrate that DistDiff's performance is robust across different guidance models.", "section": "4.4 Ablation Study"}, {"figure_path": "UGUkPYSdg4/tables/tables_17_1.jpg", "caption": "Table 11: Comparison of different learning rate \u03c1.", "description": "This table presents the results of an ablation study on the effect of different learning rates (\u03c1) on the accuracy of the model.  It shows that a learning rate of 10.0 yields the highest accuracy, while rates that are too low or too high result in lower accuracy.", "section": "4.4 Ablation Study"}, {"figure_path": "UGUkPYSdg4/tables/tables_17_2.jpg", "caption": "Table 12: Comparison of different gradient weights \u03bbg.", "description": "This table presents the results of an ablation study on the effect of varying the gradient weight (\u03bbg) applied to the group-level prototypes (pg) in the DistDiff model.  Different values of \u03bbg were tested to determine the optimal balance between the contributions of class-level and group-level prototypes for data expansion. The results show that a value of \u03bbg = 0.9 yields the highest accuracy on the Caltech-101 dataset.", "section": "4.3 Main Results"}, {"figure_path": "UGUkPYSdg4/tables/tables_17_3.jpg", "caption": "Table 13: Inference Efficiency comparison with existing methods on Caltech-101 dataset. * denotes that the actual time required of LECF to derive one sample after filter post-processing. Evaluation processes are conducted on a single GeForce RTX 3090 GPU.", "description": "This table compares the inference time of different data expansion methods on the Caltech-101 dataset.  It shows that DistDiff is comparable to Stable Diffusion in terms of inference speed, significantly faster than LECF due to the additional filtering step required by LECF.  All methods were evaluated on a single GeForce RTX 3090 GPU.", "section": "4.3 Main Results"}, {"figure_path": "UGUkPYSdg4/tables/tables_18_1.jpg", "caption": "Table 14: Comparison of accuracy in expanding Caltech-101 by 5x.", "description": "This table compares the accuracy of three different data augmentation methods on the Caltech-101 dataset.  The dataset was expanded by a factor of 5. The methods compared are DA-Fusion, DiffuseMix, and the proposed DistDiff method.  The table shows that the DistDiff method achieves the highest accuracy, outperforming both DA-Fusion and DiffuseMix.", "section": "4.3 Main Results"}, {"figure_path": "UGUkPYSdg4/tables/tables_18_2.jpg", "caption": "Table 15: Prototypes comparison of accuracy in expanding StanfordCars by 2\u00d7. We trained ResNet50 with a 448 \u00d7 448 resolution for 128 epochs.", "description": "This table presents the results of an ablation study on the StanfordCars dataset, comparing the accuracy of different combinations of class-level (pc) and group-level (pg) prototypes used in DistDiff. It shows that the best performance is achieved with both class and group-level prototypes, indicating that combining both levels provides the best representation of the data distribution for this dataset.", "section": "4.4 Ablation Study"}, {"figure_path": "UGUkPYSdg4/tables/tables_18_3.jpg", "caption": "Table 16: Comparison of accuracy in expanding ImageNet by 0.2\u00d7. We trained ResNet18 with a 224 \u00d7 224 resolution for 90 epochs.", "description": "This table presents a comparison of the accuracy achieved on the ImageNet dataset after expanding it by 0.2x using three different methods: the original dataset, Stable Diffusion (SD), and the proposed DistDiff method.  ResNet18 was used as the classifier, trained for 90 epochs with 224x224 resolution images.  The table shows that DistDiff outperforms both the original and the SD-only expanded datasets.", "section": "4.3 Main Results"}]