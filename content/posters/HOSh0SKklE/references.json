{"references": [{"fullname_first_author": "Avrim Blum", "paper_title": "Combining Labeled and Unlabeled Data with Co-training", "publication_date": "1998-00-00", "reason": "This paper introduces the co-training algorithm, a foundational work in semi-supervised learning that the current paper builds upon and generalizes."}, {"fullname_first_author": "Maria-Florina Balcan", "paper_title": "Co-training and expansion: Towards bridging theory and practice", "publication_date": "2004-00-00", "reason": "This paper provides a theoretical analysis of co-training, addressing its limitations and suggesting ways to improve its performance, which directly relates to the current paper's goal of better understanding weak-to-strong generalization."}, {"fullname_first_author": "Alexander Ratner", "paper_title": "Data Programming: Creating Large Training Sets Quickly", "publication_date": "2016-00-00", "reason": "This paper introduces data programming and the Snorkel system, a significant advancement in programmatic weak supervision that directly inspired the current paper's focus on weak-to-strong generalization."}, {"fullname_first_author": "Colin Wei", "paper_title": "Theoretical Analysis of Self-Training with Deep Networks on Unlabeled Data", "publication_date": "2020-00-00", "reason": "This paper provides a theoretical analysis of self-training, another crucial technique in semi-supervised learning, which shares similarities with the weak-to-strong generalization phenomenon studied in the current work."}, {"fullname_first_author": "Tongzhou Cai", "paper_title": "A theory of label propagation for subpopulation shift", "publication_date": "2021-00-00", "reason": "This paper introduces a theoretical framework for label propagation in settings with subpopulation shifts. This work is highly relevant because it provides a theoretical foundation for understanding how weak supervision can generalize beyond the training data, a key concept explored in the current paper."}]}