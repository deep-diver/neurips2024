{"references": [{"fullname_first_author": "Ryan Lowe", "paper_title": "Multi-agent actor-critic for mixed cooperative-competitive environments", "publication_date": "2017-12-01", "reason": "This paper introduces the Multi-Agent Actor-Critic (MAAC) algorithm, a key method used in the current paper's experiments and a significant advancement in multi-agent reinforcement learning (MARL)."}, {"fullname_first_author": "Lucian Busoniu", "paper_title": "A comprehensive survey of multiagent reinforcement learning", "publication_date": "2008-01-01", "reason": "This survey paper provides a broad overview of multiagent reinforcement learning (MARL), offering context and background to the coordination challenges that SeqComm addresses."}, {"fullname_first_author": "Craig Boutilier", "paper_title": "Planning, learning and coordination in multiagent decision processes", "publication_date": "1996-01-01", "reason": "This foundational paper discusses the theoretical challenges of planning, learning, and coordination in multi-agent settings, providing essential background for the problem tackled by SeqComm."}, {"fullname_first_author": "John Schulman", "paper_title": "Trust region policy optimization", "publication_date": "2015-01-01", "reason": "This highly influential paper presents Trust Region Policy Optimization (TRPO), a crucial algorithm used as a basis for SeqComm's theoretical guarantees."}, {"fullname_first_author": "Carlos Guestrin", "paper_title": "Coordinated reinforcement learning", "publication_date": "2002-01-01", "reason": "This paper introduces the concept of coordinated reinforcement learning, offering a key theoretical foundation for the multi-agent coordination problem that the current paper addresses."}]}