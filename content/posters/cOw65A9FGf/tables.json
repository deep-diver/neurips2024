[{"figure_path": "cOw65A9FGf/tables/tables_6_1.jpg", "caption": "Table 1: Zero-shot robust accuracy on images attacked with 100 steps of PGD [36]. We performed several different methods on Tiny-ImageNet and evaluated across 16 datasets. The optimal accuracy is highlighted in bold, while the second-best accuracy is underlined. The values in parentheses represent the standard deviation.", "description": "This table presents the zero-shot robust accuracy results for several methods on 16 different datasets. Each method was first trained on Tiny-ImageNet using adversarial examples generated by the Projected Gradient Descent (PGD) method and then tested on the other datasets against adversarial examples.  The optimal and second-best accuracy values are highlighted for each dataset, providing a clear comparison of the different approaches in terms of robustness. The values in parentheses indicate the standard deviation of the results.", "section": "4.2 Main Results"}, {"figure_path": "cOw65A9FGf/tables/tables_6_2.jpg", "caption": "Table 1: Zero-shot robust accuracy on images attacked with 100 steps of PGD [36]. We performed several different methods on Tiny-ImageNet and evaluated across 16 datasets. The optimal accuracy is highlighted in bold, while the second-best accuracy is underlined. The values in parentheses represent the standard deviation.", "description": "This table presents the zero-shot robust accuracy results achieved by various methods on 16 datasets.  The images in each dataset were attacked using 100 steps of the Projected Gradient Descent (PGD) method.  The table highlights the best-performing method in bold and the second-best in underlines, providing a clear comparison of different approaches to improving the robustness of vision-language models against adversarial attacks.", "section": "4 Experiments"}, {"figure_path": "cOw65A9FGf/tables/tables_7_1.jpg", "caption": "Table 1: Zero-shot robust accuracy on images attacked with 100 steps of PGD [36]. We performed several different methods on Tiny-ImageNet and evaluated across 16 datasets. The optimal accuracy is highlighted in bold, while the second-best accuracy is underlined. The values in parentheses represent the standard deviation.", "description": "This table presents the zero-shot robust accuracy results of various methods on 16 datasets.  The images in the datasets were attacked using the Projected Gradient Descent (PGD) method with 100 steps. The table compares the performance of different methods, including CLIP, fine-tuning with clean and adversarial examples, TeCoA, FARE, PMG-AFT, and TGA-ZSR (the proposed method).  The best and second-best accuracy results for each dataset are emphasized, along with standard deviations.", "section": "4 Experiments"}, {"figure_path": "cOw65A9FGf/tables/tables_7_2.jpg", "caption": "Table 1: Zero-shot robust accuracy on images attacked with 100 steps of PGD [36]. We performed several different methods on Tiny-ImageNet and evaluated across 16 datasets. The optimal accuracy is highlighted in bold, while the second-best accuracy is underlined. The values in parentheses represent the standard deviation.", "description": "This table presents the zero-shot robust accuracy achieved by different methods on 16 datasets.  Each dataset's images were attacked using 100 steps of the Projected Gradient Descent (PGD) method.  The table highlights the best performing method (in bold) and second-best performing method (underlined) for each dataset, providing a comprehensive comparison of zero-shot robustness.", "section": "4 Experiments"}, {"figure_path": "cOw65A9FGf/tables/tables_8_1.jpg", "caption": "Table 1: Zero-shot robust accuracy on images attacked with 100 steps of PGD [36]. We performed several different methods on Tiny-ImageNet and evaluated across 16 datasets. The optimal accuracy is highlighted in bold, while the second-best accuracy is underlined. The values in parentheses represent the standard deviation.", "description": "This table presents the zero-shot robust accuracy results of several methods (including the proposed TGA-ZSR) on 16 image classification datasets.  Each dataset was tested using images that were adversarially attacked with 100 steps of Projected Gradient Descent (PGD). The table compares the performance of different methods on clean images, providing a comprehensive evaluation of their robustness against adversarial attacks. The optimal and second-best accuracy for each dataset are highlighted for easy comparison.", "section": "4 Experiments"}, {"figure_path": "cOw65A9FGf/tables/tables_8_2.jpg", "caption": "Table 1: Zero-shot robust accuracy on images attacked with 100 steps of PGD [36]. We performed several different methods on Tiny-ImageNet and evaluated across 16 datasets. The optimal accuracy is highlighted in bold, while the second-best accuracy is underlined. The values in parentheses represent the standard deviation.", "description": "This table presents the zero-shot robust accuracy results of different methods on 16 datasets.  The images in each dataset were attacked using 100 steps of the Projected Gradient Descent (PGD) method. The table shows the optimal and second-best accuracies for each method across all datasets, highlighting the superior performance of the proposed TGA-ZSR method. Standard deviations are also included to indicate the variability of the results.", "section": "4.2 Main Results"}, {"figure_path": "cOw65A9FGf/tables/tables_9_1.jpg", "caption": "Table 7: Ablation study on each component. After adversarial fine-tuning the model using adversarial examples generated by PGD-2, we verify the robustness of the model using adversarial examples generated by PGD-100.", "description": "This table presents the results of an ablation study on the proposed TGA-ZSR framework. It shows the impact of each component (Attention Refinement Module, Attention-based Model Constraint Module) on both robust accuracy and clean accuracy.  The results are presented as percentage values for zero-shot robust accuracy and zero-shot clean accuracy, with an average column summarizing the overall performance. The table helps to understand the contribution of each module to the overall performance gains of the method.", "section": "4 Experiments"}, {"figure_path": "cOw65A9FGf/tables/tables_9_2.jpg", "caption": "Table 1: Zero-shot robust accuracy on images attacked with 100 steps of PGD [36]. We performed several different methods on Tiny-ImageNet and evaluated across 16 datasets. The optimal accuracy is highlighted in bold, while the second-best accuracy is underlined. The values in parentheses represent the standard deviation.", "description": "This table presents the zero-shot robust accuracy results for several methods (CLIP, FT-Clean, FT-Adv, TeCoA, FARE, PMG-AFT, and TGA-ZSR) evaluated on 16 datasets.  Each method's performance is assessed using images that have been adversarially attacked with 100 steps of the Projected Gradient Descent (PGD) attack. The optimal accuracy for each dataset is shown in bold, and the second-best is underlined.  Parentheses indicate the standard deviation of the results.", "section": "4.2 Main Results"}, {"figure_path": "cOw65A9FGf/tables/tables_14_1.jpg", "caption": "Table 1: Zero-shot robust accuracy on images attacked with 100 steps of PGD [36]. We performed several different methods on Tiny-ImageNet and evaluated across 16 datasets. The optimal accuracy is highlighted in bold, while the second-best accuracy is underlined. The values in parentheses represent the standard deviation.", "description": "This table presents the zero-shot robust accuracy results for various vision-language models on 16 different datasets.  Each model was tested against images that had been adversarially perturbed using the Projected Gradient Descent (PGD) method. The results showcase the effectiveness of the proposed TGA-ZSR method compared to several existing state-of-the-art methods.  The best performance for each dataset is shown in bold, while the second-best performance is underlined. Standard deviations are also provided.", "section": "4 Experiments"}, {"figure_path": "cOw65A9FGf/tables/tables_14_2.jpg", "caption": "Table 1: Zero-shot robust accuracy on images attacked with 100 steps of PGD [36]. We performed several different methods on Tiny-ImageNet and evaluated across 16 datasets. The optimal accuracy is highlighted in bold, while the second-best accuracy is underlined. The values in parentheses represent the standard deviation.", "description": "This table presents the zero-shot robust accuracy results of different methods on 16 datasets, where the images were attacked using 100 steps of Projected Gradient Descent (PGD).  The methods compared include CLIP (baseline), fine-tuning on clean data (FT-Clean), fine-tuning on adversarial data (FT-Adv.), TeCoA, FARE, PMG-AFT, and the proposed TGA-ZSR.  The optimal and second-best accuracies are highlighted for each dataset.  Parentheses show standard deviations.", "section": "4.2 Main Results"}, {"figure_path": "cOw65A9FGf/tables/tables_14_3.jpg", "caption": "Table 11: Zero-shot robust accuracy on images attacked with 100 steps of PGD [36]. We performed several different methods on Tiny-ImageNet and evaluated in the following three additional datasets. The optimal accuracy is highlighted in bold, while the second-best accuracy is underlined.", "description": "This table presents the zero-shot robust accuracy results for three additional datasets (ImageNet-A, ImageNet-O, ImageNet-R) besides the Tiny-ImageNet dataset.  Several methods are compared, including the baseline CLIP model and state-of-the-art techniques.  The table shows the performance of each method under the PGD attack with 100 steps. The optimal and second-best accuracy values are highlighted for better clarity.", "section": "4.3 Experiments on More Attack Types"}, {"figure_path": "cOw65A9FGf/tables/tables_15_1.jpg", "caption": "Table 11: Zero-shot robust accuracy on images attacked with 100 steps of PGD [36]. We performed several different methods on Tiny-ImageNet and evaluated across 16 datasets. The optimal accuracy is highlighted in bold, while the second-best accuracy is underlined.", "description": "This table presents the zero-shot robust accuracy results for various methods on 16 different datasets. Each method was initially trained on the Tiny-ImageNet dataset, and tested for robustness against the Projected Gradient Descent (PGD) attack. The optimal and second-best accuracies are highlighted for each dataset, providing a comprehensive comparison of performance.", "section": "4.3 Experiments on More Attack Types"}, {"figure_path": "cOw65A9FGf/tables/tables_15_2.jpg", "caption": "Table 13: Results on validation set of Tiny-ImageNet dataset.", "description": "This table presents the results of hyperparameter tuning on the validation set of the Tiny-ImageNet dataset.  Different combinations of alpha (\u03b1) and beta (\u03b2) values were tested, and the table shows the resulting zero-shot robust accuracy, zero-shot clean accuracy, and the average of the two.  This is used to determine optimal values for \u03b1 and \u03b2 which are then used in the final evaluation.", "section": "4.2 Main Results"}, {"figure_path": "cOw65A9FGf/tables/tables_15_3.jpg", "caption": "Table 1: Zero-shot robust accuracy on images attacked with 100 steps of PGD [36]. We performed several different methods on Tiny-ImageNet and evaluated across 16 datasets. The optimal accuracy is highlighted in bold, while the second-best accuracy is underlined. The values in parentheses represent the standard deviation.", "description": "This table presents the zero-shot robust accuracy results for various vision-language models on 16 different datasets.  Each model was tested using images adversarially attacked with 100 steps of Projected Gradient Descent (PGD). The table compares the performance of several methods including the baseline CLIP model, fine-tuning with clean and adversarial data, and other state-of-the-art techniques.  The best performing model for each dataset is highlighted in bold, indicating superior robustness to adversarial attacks.", "section": "4 Experiments"}, {"figure_path": "cOw65A9FGf/tables/tables_16_1.jpg", "caption": "Table 1: Zero-shot robust accuracy on images attacked with 100 steps of PGD [36]. We performed several different methods on Tiny-ImageNet and evaluated across 16 datasets. The optimal accuracy is highlighted in bold, while the second-best accuracy is underlined. The values in parentheses represent the standard deviation.", "description": "This table presents the zero-shot robust accuracy results of different methods on 16 datasets.  Each dataset's images were attacked using 100 steps of the Projected Gradient Descent (PGD) method. The table compares the performance of the proposed TGA-ZSR method against several baselines, including CLIP, fine-tuning on clean data (FT-Clean), fine-tuning on adversarial data (FT-Adv), TeCoA, FARE, and PMG-AFT. The best and second-best results are highlighted for each dataset, with standard deviations included.", "section": "4 Experiments"}, {"figure_path": "cOw65A9FGf/tables/tables_16_2.jpg", "caption": "Table 1: Zero-shot robust accuracy on images attacked with 100 steps of PGD [36]. We performed several different methods on Tiny-ImageNet and evaluated across 16 datasets. The optimal accuracy is highlighted in bold, while the second-best accuracy is underlined. The values in parentheses represent the standard deviation.", "description": "This table presents the zero-shot robust accuracy results for various methods on 16 different datasets.  Each dataset was tested using images that had been adversarially attacked with 100 steps of Projected Gradient Descent (PGD). The table highlights the best performing method (in bold) and the second-best method (underlined) for each dataset, demonstrating the efficacy of the proposed TGA-ZSR approach in enhancing zero-shot robustness compared to existing methods.  Standard deviation values are provided in parentheses to illustrate the variability of the results.", "section": "4 Experiments"}, {"figure_path": "cOw65A9FGf/tables/tables_16_3.jpg", "caption": "Table 1: Zero-shot robust accuracy on images attacked with 100 steps of PGD [36]. We performed several different methods on Tiny-ImageNet and evaluated across 16 datasets. The optimal accuracy is highlighted in bold, while the second-best accuracy is underlined. The values in parentheses represent the standard deviation.", "description": "This table presents the zero-shot robust accuracy of different methods on 16 datasets, where images were attacked using 100 steps of Projected Gradient Descent (PGD).  The methods compared include CLIP (baseline), fine-tuning on clean data (FT-Clean), fine-tuning on adversarial examples (FT-Adv.), TeCoA, FARE, PMG-AFT, and the proposed TGA-ZSR method.  The optimal and second-best accuracies for each dataset are highlighted.  Parentheses show standard deviation.", "section": "4 Experiments"}, {"figure_path": "cOw65A9FGf/tables/tables_17_1.jpg", "caption": "Table 1: Zero-shot robust accuracy on images attacked with 100 steps of PGD [36]. We performed several different methods on Tiny-ImageNet and evaluated across 16 datasets. The optimal accuracy is highlighted in bold, while the second-best accuracy is underlined. The values in parentheses represent the standard deviation.", "description": "This table presents the zero-shot robust accuracy results of different methods on 16 datasets.  The images were attacked using 100 steps of the Projected Gradient Descent (PGD) method.  The optimal and second-best accuracies are highlighted for comparison, showing the effectiveness of the proposed method (TGA-ZSR) compared to existing techniques.", "section": "4 Experiments"}, {"figure_path": "cOw65A9FGf/tables/tables_17_2.jpg", "caption": "Table 1: Zero-shot robust accuracy on images attacked with 100 steps of PGD [36]. We performed several different methods on Tiny-ImageNet and evaluated across 16 datasets. The optimal accuracy is highlighted in bold, while the second-best accuracy is underlined. The values in parentheses represent the standard deviation.", "description": "This table presents the zero-shot robust accuracy results of different methods on 16 datasets.  The images in these datasets were attacked using 100 steps of Projected Gradient Descent (PGD).  The table highlights the best performing method (in bold) and the second-best method (underlined) for each dataset.  Parentheses show standard deviations of the accuracy scores.", "section": "4.2 Main Results"}, {"figure_path": "cOw65A9FGf/tables/tables_17_3.jpg", "caption": "Table 1: Zero-shot robust accuracy on images attacked with 100 steps of PGD [36]. We performed several different methods on Tiny-ImageNet and evaluated across 16 datasets. The optimal accuracy is highlighted in bold, while the second-best accuracy is underlined. The values in parentheses represent the standard deviation.", "description": "This table presents the zero-shot robust accuracy results of different methods on 16 datasets.  The images in each dataset were attacked using the Projected Gradient Descent (PGD) method for 100 steps.  The best performing method for each dataset is shown in bold, and the second-best is underlined.  The results demonstrate the relative robustness of different approaches against adversarial attacks.", "section": "4.2 Main Results"}, {"figure_path": "cOw65A9FGf/tables/tables_17_4.jpg", "caption": "Table 1: Zero-shot robust accuracy on images attacked with 100 steps of PGD [36]. We performed several different methods on Tiny-ImageNet and evaluated across 16 datasets. The optimal accuracy is highlighted in bold, while the second-best accuracy is underlined. The values in parentheses represent the standard deviation.", "description": "This table presents the zero-shot robust accuracy of different methods on 16 datasets.  The images were adversarially attacked using 100 steps of Projected Gradient Descent (PGD).  The table compares the performance of several methods, including CLIP, fine-tuning with clean and adversarial examples, TeCoA, FARE, PMG-AFT, and the proposed TGA-ZSR.  The best and second-best accuracy are highlighted for each dataset.", "section": "4.2 Main Results"}]