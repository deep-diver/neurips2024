[{"figure_path": "OF0YsxoRai/figures/figures_3_1.jpg", "caption": "Figure 1: Performance comparison of focalized GP and SVGP over 1d GP functions. Posteriors are shown as mean \u00b1 1 standard deviation.", "description": "This figure compares the performance of focalized Gaussian Processes (GP) and standard Sparse Variational Gaussian Processes (SVGP) on a one-dimensional (1D) Gaussian Process function. It showcases how focalized GP, by focusing its representational power on relevant regions, produces a more accurate and localized posterior distribution compared to SVGP, which provides an overly smooth estimation across the entire function domain.  The plot visually illustrates the mean and \u00b11 standard deviation of both models' posterior distributions, highlighting the difference in their predictive capabilities, especially in capturing local details and uncertainties of the true underlying function.", "section": "4 Focalized Gaussian Process for Bayesian Optimization"}, {"figure_path": "OF0YsxoRai/figures/figures_7_1.jpg", "caption": "Figure 2: Optimization performance under different synthetic function and acquisition function. Sparse GP models are trained with 50 inducing variables. The offline dataset contains 2000 random data points and the online budget is 500 with batch size of 10.", "description": "This figure compares the performance of Focal BO against other sparse Gaussian process (GP) models (SVGP, WOGP, Vecchia GP) across three different acquisition functions (TS, EI, PI) and three different synthetic functions (Shekel, Michalewicz, GP function).  Each function is optimized using the selected acquisition function. The offline dataset used for training is 2000 random data points and an additional 500 points are sampled online during optimization in batches of size 10.  The figure shows that FOCALBO significantly outperforms the baselines in most cases.", "section": "5.1 Synthetic functions"}, {"figure_path": "OF0YsxoRai/figures/figures_7_2.jpg", "caption": "Figure 3: Optimization on robot morphology design. Function values are normalized by best and worst values in the unseen full dataset.", "description": "The figure compares the optimization performance of FOCALBO with other baselines (SVGP, Vecchia GP) on a robot morphology design task.  Both EI and TuRBO acquisition functions are used for each baseline. The y-axis represents the normalized function value (best and worst values from the unseen full dataset are used for normalization), and the x-axis represents the number of function evaluations.  The plot shows that FOCALBO achieves significantly better results than the other methods, demonstrating its effectiveness in this high-dimensional problem.", "section": "5.2 Robot morphology design"}, {"figure_path": "OF0YsxoRai/figures/figures_8_1.jpg", "caption": "Figure 4: Optimization of musculoskeletal system control. (a) Task illustration of initial and target state. Full video in supplementary. (b) Optimization performance of algorithms.", "description": "This figure demonstrates the application of the proposed FOCALBO algorithm to a musculoskeletal system control task.  Subfigure (a) shows a visual representation of the task, illustrating the initial and final states of the system. Subfigure (b) presents a comparison of FOCALBO's performance against several baseline algorithms in terms of optimization performance.  The plot shows how the objective function value changes over the course of the optimization process, allowing us to compare the algorithms' efficiency and effectiveness in reaching an optimal solution. The shaded region represents the variance between different optimization runs. The full video of the task is available in supplementary materials.", "section": "5.3 Human musculoskeletal system control"}, {"figure_path": "OF0YsxoRai/figures/figures_8_2.jpg", "caption": "Figure 5: Algorithm analysis over optimization depth. (a) Depth evolution during optimization. (b) Samples source of each BO iteration during one trial of musculoskeletal system control optimization. Color bar indicates the number of samples proposed by corresponding optimization depth.", "description": "This figure analyzes the optimization depth used in FOCALBO, a hierarchical Bayesian optimization algorithm.  Panel (a) shows how the optimization depth changes over several BO iterations for different problem types (Shekel, Michalewicz, GP function, DKitty robot morphology design, and musculoskeletal system control).  The lines show the average optimization depth and the shaded areas represent standard deviations.  Panel (b) is a heatmap showing the source of the sampled batches used in each BO iteration during the musculoskeletal system control optimization task.  The color intensity represents the number of samples obtained at each depth. The figure demonstrates that FOCALBO's adaptive strategy allows for a dynamic balance between exploration and exploitation.", "section": "Algorithm analysis"}, {"figure_path": "OF0YsxoRai/figures/figures_14_1.jpg", "caption": "Figure 6: KL divergence between sparse GPs and exact GP. Results shows the mean and one standard error, averaged over 50 independent trials.", "description": "This figure compares the KL divergence between the posterior distributions of focalized GP and SVGP against the exact GP's posterior distribution.  The KL divergence quantifies the difference between probability distributions; a lower KL divergence indicates a better approximation. The figure shows that the focalized GP consistently achieves a lower KL divergence than SVGP across various sizes of the search region, demonstrating that it provides a closer approximation to the true posterior distribution, especially in smaller search regions.", "section": "B.1 Theoretical implications of sparse GP approximation"}, {"figure_path": "OF0YsxoRai/figures/figures_15_1.jpg", "caption": "Figure 7: Optimization performance of focalized GP and SVGP when combining with TURBO.", "description": "The figure compares the optimization performance of focalized GP and SVGP when combined with TuRBO on two tasks: robot morphology design and musculoskeletal system control.  It shows that FocalGP consistently outperforms SVGP across both tasks.  The shaded area represents the standard error of the mean.", "section": "5 Experiments"}, {"figure_path": "OF0YsxoRai/figures/figures_15_2.jpg", "caption": "Figure 8: (a) Distance of search region center to the global optima. (b) Pair-wise distance of Thompson sampling samples. Results shows the mean and one standard error, averaged over 50 independent trials.", "description": "This figure contains two subfigures. Subfigure (a) shows the distance between the center of the search region used in the FOCALBO algorithm and the global optimum for various acquisition functions (Best, Random, EI, UCB, PI, TS) and training data sizes (50, 100, 500, 1000). It demonstrates how well the algorithm centers the search region around the global optimum. Subfigure (b) displays the average pairwise distance of Thompson sampling points for exact GP and SVGP (with 50 inducing points) across different training data sizes (200, 500, 1000).  This illustrates the exploration-exploitation trade-off; how sparse GPs encourage more exploration by sampling diverse points compared to using the full GP.", "section": "B.2 Optimization on synthetic functions with large online data"}, {"figure_path": "OF0YsxoRai/figures/figures_15_3.jpg", "caption": "Figure 9: GP predictive performance of specific search region on 2d Ackley and Rastrigin function. Results show mean \u00b1 one standard deviation over 10 random search regions.", "description": "This figure compares the performance of different GP models (FocalBO, SVGP, and WOGP) on two benchmark functions, Ackley and Hartmann. The optimization is performed in a setting with a large amount of online data. Results show that FOCALBO consistently outperforms baselines in both functions, suggesting its effectiveness in online optimization scenarios when online data becomes dominant.", "section": "5.1 Synthetic functions"}, {"figure_path": "OF0YsxoRai/figures/figures_16_1.jpg", "caption": "Figure 10: GP predictive performance of specific search region on 2d Ackley and Rastrigin function. Results show mean \u00b1 one standard deviation over 10 random search regions.", "description": "This figure displays the results of a comparison of the predictive performance of three different Gaussian process (GP) models: Exact GP, SVGP, and FocalGP. The comparison is done across varying search region sizes (l) and different numbers of inducing variables (m) on two benchmark functions: Ackley and Rastrigin.  The performance is measured using two metrics: negative log-likelihood (NLL) and root mean squared error (RMSE). The error bars represent the standard deviation across 10 random trials for each configuration. The figure aims to demonstrate the effectiveness of the FocalGP model, particularly in smaller search regions, by showing its superior predictive accuracy compared to the other two models.", "section": "B.3 GP predictive performance"}, {"figure_path": "OF0YsxoRai/figures/figures_16_2.jpg", "caption": "Figure 10: GP predictive performance of specific search region on 2d Ackley and Rastrigin function. Results show mean \u00b1 one standard deviation over 10 random search regions.", "description": "This figure compares the performance of Focalized GP, Focalized GP without regularization (Lreg), and Exact GP in terms of negative log-likelihood (NLL) and root mean squared error (RMSE) on Ackley and Rastrigin functions.  The comparison is done for various search region sizes (l) and different numbers of inducing points (m).  It demonstrates that Focalized GP with regularization significantly outperforms others, especially in smaller search regions, highlighting its effectiveness in improving local prediction accuracy.", "section": "B.3 GP predictive performance"}, {"figure_path": "OF0YsxoRai/figures/figures_17_1.jpg", "caption": "Figure 12: Optimization performance of FocalBO and TuRBO.", "description": "This figure compares the optimization performance of FocalBO and TuRBO on two tasks: Robot Morphology and MS Control.  For each task, it shows the optimization progress for four methods: FocalBO using Thompson Sampling (TS), FocalBO combined with TuRBO, the original TuRBO method, and TuRBO using a nearest neighbor Gaussian process (NN GP). The shaded areas represent the standard error for each method across multiple trials. The results demonstrate that FocalBO outperforms TuRBO on both tasks, suggesting the effectiveness of the hierarchical acquisition optimization strategy and the focalized Gaussian process in improving BO performance.", "section": "5.4 Algorithm analysis"}]