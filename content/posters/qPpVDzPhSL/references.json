{"references": [{"fullname_first_author": "Ali Al-Kaswan", "paper_title": "Extending source code pre-trained language models to summarise decompiled binarie", "publication_date": "2023", "reason": "This paper is directly related to the core task of the current research and is cited multiple times, suggesting its significant influence on the current work."}, {"fullname_first_author": "Jean-Baptiste Alayrac", "paper_title": "Flamingo: a visual language model for few-shot learning", "publication_date": "2022", "reason": "This paper introduces a foundational multi-modal model that inspires the current research's cross-modal approach to binary analysis."}, {"fullname_first_author": "Rohan Anil", "paper_title": "Palm 2 technical report", "publication_date": "2023", "reason": "This paper details a large language model (LLM) used as a core component in the proposed framework, highlighting its importance for the accuracy and capabilities of the system."}, {"fullname_first_author": "Pratyay Banerjee", "paper_title": "Variable name recovery in decompiled binary code using constrained masked language modeling", "publication_date": "2021", "reason": "This paper focuses on a related task (variable name recovery) within binary reverse engineering, offering insights and comparative methods relevant to the current study."}, {"fullname_first_author": "Adam R Bryant", "paper_title": "Understanding how reverse engineers make sense of programs from assembly language representations", "publication_date": "2012", "reason": "This paper provides valuable insights into the human-oriented aspects of binary reverse engineering, informing the design and evaluation of the proposed automated approach."}]}