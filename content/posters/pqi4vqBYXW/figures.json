[{"figure_path": "pqi4vqBYXW/figures/figures_1_1.jpg", "caption": "Figure 1: 3D Content Generation Results between Hallo3D (ours) and Baseline Model. Hallo3D can effectively solve the \"Janus\" problem and improve the multi-view consistency of the 3D generation.", "description": "This figure showcases a comparison of 3D content generated using a baseline model and the proposed Hallo3D method.  The \"Janus\" problem, characterized by inconsistencies and hallucinations in multi-view 3D object generation, is prominently displayed in the baseline results.  In contrast, Hallo3D demonstrates a significant improvement in generating consistent and visually accurate 3D models from various viewpoints.", "section": "1 Introduction"}, {"figure_path": "pqi4vqBYXW/figures/figures_1_2.jpg", "caption": "Figure 5: Qualitative comparison in text-driven 3D generation of Hallo3D and baseline models. To provide more straightforward comparison, we rendered both Hallo3D and the baseline models from two identical and complementary angles.", "description": "This figure shows a qualitative comparison of 3D models generated by Hallo3D and several baseline methods for text-driven generation. Three different prompts were used to generate 3D models of a flamingo, a dog statue, and a sports car.  For each prompt, the figure shows renderings from multiple viewpoints (90\u00b0, 270\u00b0, 45\u00b0, 225\u00b0, 0\u00b0, 105\u00b0, 285\u00b0) for both Hallo3D and the baseline models, allowing for a visual comparison of multi-view consistency and quality. The results demonstrate that Hallo3D generates more consistent and visually appealing 3D models across different viewpoints, compared to the baseline methods.", "section": "4 Experiments"}, {"figure_path": "pqi4vqBYXW/figures/figures_3_1.jpg", "caption": "Figure 3: Illustration of our pipeline. We jointly optimize our model using LSDS and LCG. For LSDS, we identify a focal view from multi-view renderings based on the camera pose, utilizing it as the keys (K) and values (V) to align all the four images using attention. This process harmonizes the appearance and feeds the output into the 2D Diffusion on the left, which plays a crucial role in refining the noise prediction. For LCG, we query hallucinations and inconsistencies in the rendering using an LMM and apply the results, outputted as enhanced negative prompt, to the following image optimization process to re-consistent a high-quality image. We calculate the LCG based on the differences between the two images, thereby enhancing the consistency of the 3D content.", "description": "This figure illustrates the Hallo3D pipeline, which consists of three core modules: Multi-View Appearance Alignment, Multi-Modal Hallucination Detection, and Prompt-Enhanced Re-Consistency.  The pipeline uses multi-view renderings of a 3D object as input.  LSDS (Score Distillation Sampling) is used with an attention mechanism to align appearances across views.  A large multi-modal model (LMM) detects inconsistencies in the renderings, which are used as enhanced negative prompts in a second stage of 2D diffusion to correct these. The loss function LCG is used for the training process. ", "section": "3 Methodology"}, {"figure_path": "pqi4vqBYXW/figures/figures_4_1.jpg", "caption": "Figure 4: A multi-modal case study for evaluating the capabilities of LMMs in 3D generation tasks. The first round of dialogue demonstrates that LMMs can infer structural consistency from 3D rendered images, while the second round shows that LMMs can respond in specific formats, allowing us to subsequently identify the negative prompts output using regular expressions.", "description": "This figure showcases a multi-modal approach for identifying inconsistencies in 3D-generated images using large multi-modal models (LMMs).  The example shows how an LLM (LLaVA and GPT-4V) is able to analyze a 3D rendering and provide concise negative prompts to correct identified issues such as blurry features, structural inconsistencies, and duplicated elements. This demonstrates the LMM's capacity for spatial reasoning and its usefulness in refining 3D generation processes.", "section": "3.3 Multi-modal Hallucination Detection"}, {"figure_path": "pqi4vqBYXW/figures/figures_6_1.jpg", "caption": "Figure 5: Qualitative comparison in text-driven 3D generation of Hallo3D and baseline models. To provide a more straightforward comparison, we rendered both Hallo3D and the baseline models from two identical and complementary angles.", "description": "This figure shows a qualitative comparison of 3D model generation results using Hallo3D and four baseline methods (GaussianDreamer, SJC, DreamFusion-IF, and Magic3D). Three different prompts were used to generate 3D models of a flamingo, a dog statue, and a sports car. Each model is shown from two different viewpoints (90\u00b0/270\u00b0, 45\u00b0/225\u00b0, and 285\u00b0/105\u00b0). The comparison highlights Hallo3D's ability to generate more consistent and realistic 3D models across different viewpoints, compared to the baseline methods.", "section": "4 Experiments"}, {"figure_path": "pqi4vqBYXW/figures/figures_7_1.jpg", "caption": "Figure 6: Qualitative comparison in image-driven 3D generation of Hallo3D and baseline models. To facilitate a more direct comparison, we rendered both Hallo3D and the baseline models from two complementary angles and magnified specific details.", "description": "This figure shows a qualitative comparison of image-driven 3D generation results between Hallo3D and two baseline methods (DreamGaussian and Zero-1-to-3).  Two examples are shown: a cartoon fox and a cartoon person.  For each model and example, multiple views are provided, highlighting the differences in the quality and consistency of the generated 3D models across different viewpoints. The magnified details emphasize the improvements in view consistency and visual quality achieved by Hallo3D compared to the baseline methods.", "section": "4.2 Quantitative Comparison with Baselines"}, {"figure_path": "pqi4vqBYXW/figures/figures_8_1.jpg", "caption": "Figure 7: Ablation study of our method. In the figure, module A represents Multi-view Appearance Alignment in Sec. 3.2, module B stands for Multi-modal Hallucination Detection in Sec. 3.3, and module C denotes Prompt-Enhanced Re-Consistency in Sec. 3.4. We conducted ablation studies on each of these three modules respectively.", "description": "This figure presents an ablation study of the Hallo3D method. It shows the impact of removing each of the three core components: Multi-view Appearance Alignment (A), Multi-modal Hallucination Detection (B), and Prompt-Enhanced Re-consistency (C). The results for two different prompts are visualized, illustrating the effect of each component on the final 3D model generation.", "section": "4.4 Ablation Study"}, {"figure_path": "pqi4vqBYXW/figures/figures_9_1.jpg", "caption": "Figure 8: Loss curves for LCG and LSDS, along with the CLIP-Score curves with and without LCG.", "description": "This figure shows the loss curves for both LCG (consistency loss) and LSDS (score distillation sampling loss) during the training process.  It also displays the CLIP-Score, a metric evaluating the quality of the generated images, with and without LCG.  The plot illustrates the relationship between these losses and the resulting image quality, demonstrating the effect of the proposed consistency loss (LCG) on the overall quality of the 3D model generation.", "section": "4.5 Balance between LCG and LSDS"}, {"figure_path": "pqi4vqBYXW/figures/figures_14_1.jpg", "caption": "Figure 9: Comparison experiments with Perp-Neg and Debias.", "description": "This figure compares the results of Hallo3D against two other methods (Perp-Neg and Debias) for improving the consistency of 3D generation.  The results show that Hallo3D achieves a slightly higher CLIP-Score, indicating better overall image quality and consistency compared to the baseline and the other two methods. The visualization shows several renderings from different viewpoints for each method, highlighting the differences in quality and consistency. ", "section": "4.3 Qualitative Comparison with Baselines"}, {"figure_path": "pqi4vqBYXW/figures/figures_15_1.jpg", "caption": "Figure 10: 360-degree visualization results in Fig.5 (1).", "description": "This figure shows a 360-degree visualization of the 3D models generated by Hallo3D and baseline models for three different prompts from Figure 5.  Each row represents a different object (flamingo, dog statue, and sports car) and the images show the 3D renderings from multiple viewpoints around the object. The red boxes highlight specific areas or inconsistencies for comparison.", "section": "4 Expremients"}, {"figure_path": "pqi4vqBYXW/figures/figures_16_1.jpg", "caption": "Figure 5: Qualitative comparison in text-driven 3D generation of Hallo3D and baseline models. To provide a more straightforward comparison, we rendered both Hallo3D and the baseline models from two identical and complementary angles.", "description": "This figure shows a qualitative comparison of 3D models generated by Hallo3D and several baseline methods for three different text prompts. Each row represents a different prompt, showing the results of each method from two different viewpoints (90 and 270 degrees for the first example, 45 and 225 degrees for the second example, and 105 and 285 degrees for the third example). The images demonstrate that Hallo3D produces more consistent and higher-quality 3D models than the baseline methods, especially in terms of multi-view consistency. For example, in the \"flamingo\" example, the baseline methods produce models with inconsistent details across different viewpoints, while the Hallo3D model has a high level of consistency. This figure supports the paper's claim that Hallo3D can significantly improve the quality and consistency of generated 3D content by mitigating the hallucinations common with 2D pretrained models.", "section": "4 Expremients"}]