[{"figure_path": "apI1GltwSx/tables/tables_5_1.jpg", "caption": "Table 1: Comparison with SOTA dataset distillation methods using relatively large-scale backbones on five benchmarks across different scales. MobileNet-v2 is modified to match the low resolutions of CIFAR-10 and Tiny-ImageNet following [42]. Due to the table space limitation, some other methods that are weaker than RDED are not listed, such as CDA and G-VBSM. Since IPC 1 is not applicable to use EarlyLate strategy and the single image in each class is optimized with a constant iteration.", "description": "This table compares the performance of the proposed DELT method with state-of-the-art (SOTA) dataset distillation methods on five benchmark datasets using relatively large-scale backbones. It shows the Top-1 accuracy achieved by different methods under various image per class (IPC) settings. Note that for IPC=1, the EarlyLate strategy of DELT is not applicable, hence a different approach is used.", "section": "4.1 Datasets and Results Details"}, {"figure_path": "apI1GltwSx/tables/tables_5_2.jpg", "caption": "Table 1: Comparison with SOTA dataset distillation methods using relatively large-scale backbones on five benchmarks across different scales. MobileNet-v2 is modified to match the low resolutions of CIFAR-10 and Tiny-ImageNet following [42]. Due to the table space limitation, some other methods that are weaker than RDED are not listed, such as CDA and G-VBSM. Since IPC 1 is not applicable to use EarlyLate strategy and the single image in each class is optimized with a constant iteration.", "description": "This table compares the performance of the proposed DELT method against other state-of-the-art (SOTA) dataset distillation methods on five benchmark datasets using relatively large-scale backbones (ResNet-18 and ResNet-101).  The results are shown for different numbers of images per class (IPC). Note that for IPC=1, the EarlyLate strategy is not applicable, and a constant number of iterations is used for optimization.  Some less effective methods are omitted.", "section": "4.1 Datasets and Results Details"}, {"figure_path": "apI1GltwSx/tables/tables_7_1.jpg", "caption": "Table 3: Ablation experiments on various aspects of our framework with ResNet-18 on ImageNet-1K.", "description": "This ablation study investigates the impact of different hyperparameters and design choices on the performance of the proposed DELT method.  Specifically, it examines the effect of varying the number of patches used for mosaic image generation, the selection criteria for initial image patches, the number of optimization iterations, and the early-only versus EarlyLate training strategy.  The results are presented as Top 1 accuracy on the ImageNet-1K dataset using a ResNet-18 model.", "section": "4 Experiments"}, {"figure_path": "apI1GltwSx/tables/tables_7_2.jpg", "caption": "Table 3: Ablation experiments on various aspects of our framework with ResNet-18 on ImageNet-1K.", "description": "This table presents the ablation study results conducted on ImageNet-1K using ResNet-18.  It explores the impact of different hyperparameters and design choices on the model's top-1 accuracy.  Specifically, it investigates the effect of varying the number of patches used for initialization, the selection criteria for these patches (lowest, medium, or highest probability), the number of optimization iterations, and the comparison between Early-only and EarlyLate training schemes. The results help determine the optimal configuration for the proposed DELT approach.", "section": "4 Experiments"}, {"figure_path": "apI1GltwSx/tables/tables_7_3.jpg", "caption": "Table 3: Ablation experiments on various aspects of our framework with ResNet-18 on ImageNet-1K.", "description": "This table presents the results of ablation studies conducted on the proposed DELT framework using ResNet-18 on the ImageNet-1K dataset.  It investigates the impact of various hyperparameters and design choices on the model's performance, including the number of patches used for initialization, selection criteria for those patches, the number of optimization iterations (both maximum and round iterations), and the training strategy (Early-only vs. EarlyLate).  The results highlight the optimal configurations for achieving the best Top-1 accuracy.", "section": "4 Experiments"}, {"figure_path": "apI1GltwSx/tables/tables_7_4.jpg", "caption": "Table 1: Comparison with SOTA dataset distillation methods using relatively large-scale backbones on five benchmarks across different scales. MobileNet-v2 is modified to match the low resolutions of CIFAR-10 and Tiny-ImageNet following [42]. Due to the table space limitation, some other methods that are weaker than RDED are not listed, such as CDA and G-VBSM. Since IPC 1 is not applicable to use EarlyLate strategy and the single image in each class is optimized with a constant iteration.", "description": "This table compares the performance of the proposed DELT method against state-of-the-art (SOTA) dataset distillation methods.  The comparison uses several large-scale backbone architectures (ResNet-18, ResNet-101, MobileNet-v2) across five benchmark datasets (CIFAR-10, ImageNette, Tiny-ImageNet, ImageNet-100, ImageNet-1K) with varying numbers of images per class (IPC).  Note that some weaker methods are omitted for brevity.", "section": "4.1 Datasets and Results Details"}, {"figure_path": "apI1GltwSx/tables/tables_7_5.jpg", "caption": "Table 4: Cross-architecture generalization. Results are evaluated on IPC 10.", "description": "This table presents the results of evaluating the generalization capabilities of the proposed DELT method across different model architectures.  The evaluation is performed on a subset of ImageNet-1K with 10 images per class (IPC 10). The table compares the top-1 accuracy achieved by DELT against several state-of-the-art dataset distillation methods (SRe2L, CDA, G-VBSM, RDED) using different backbone networks (ResNet-18, EfficientNet-B0, MobileNet-V2, MnasNet1_3, RegNet-Y-8GF). The values in parentheses indicate the improvement achieved by DELT over the best performing baseline method for each architecture.", "section": "4.2 Cross-architecture generalization"}, {"figure_path": "apI1GltwSx/tables/tables_7_6.jpg", "caption": "Table 5: Actual computational consumption and analysis (hours under IPC 50) in data synthesis with image optimization-based methods on a single NVIDIA 4090 GPU. \u201cRI\u201d represents round iterations. A total 4K iterations are used for all methods and datasets to ensure fair comparisons.", "description": "This table shows the computational time (in hours) required for data synthesis using different methods (G-VBSM, SRe2L, CDA, and the proposed DELT method) on three different datasets (ImageNet-1K, Tiny-ImageNet, and CIFAR-10).  The results are broken down by the number of round iterations (RI) used for the DELT method (500 and 1000).  The values in parentheses indicate the percentage improvement of DELT compared to the baseline method. The table highlights the efficiency gains achieved by DELT in terms of reduced computational cost.", "section": "4.4 Computational Analysis"}, {"figure_path": "apI1GltwSx/tables/tables_8_1.jpg", "caption": "Table 6: Accuracy of data-free network pruning using slimming [48] on VGG11-BN [49].", "description": "This table compares the accuracy of data-free network pruning using slimming on VGG11-BN with different dataset distillation methods (SRe2L, RDED, and the proposed DELT method) at different images per class (IPC).  It demonstrates the performance improvement achieved by DELT in this specific application.", "section": "4.6 Application I: Data-free Network Pruning"}, {"figure_path": "apI1GltwSx/tables/tables_12_1.jpg", "caption": "Table 1: Comparison with SOTA dataset distillation methods using relatively large-scale backbones on five benchmarks across different scales. MobileNet-v2 is modified to match the low resolutions of CIFAR-10 and Tiny-ImageNet following [42]. Due to the table space limitation, some other methods that are weaker than RDED are not listed, such as CDA and G-VBSM. Since IPC 1 is not applicable to use EarlyLate strategy and the single image in each class is optimized with a constant iteration.", "description": "This table compares the performance of the proposed DELT method with state-of-the-art (SOTA) dataset distillation methods.  The comparison uses five benchmark datasets (CIFAR-10, ImageNette, Tiny-ImageNet, ImageNet-100, and ImageNet-1K) and various backbone architectures (ResNet-18, ResNet-101, and MobileNet-v2).  The results show the top-1 accuracy achieved by each method for different numbers of images per class (IPC).  Note that due to space constraints, some weaker methods are not shown. The IPC 1 results are also noted as a special case where the EarlyLate training strategy is not applicable.", "section": "4.1 Datasets and Results Details"}, {"figure_path": "apI1GltwSx/tables/tables_12_2.jpg", "caption": "Table 1: Comparison with SOTA dataset distillation methods using relatively large-scale backbones on five benchmarks across different scales. MobileNet-v2 is modified to match the low resolutions of CIFAR-10 and Tiny-ImageNet following [42]. Due to the table space limitation, some other methods that are weaker than RDED are not listed, such as CDA and G-VBSM. Since IPC 1 is not applicable to use EarlyLate strategy and the single image in each class is optimized with a constant iteration.", "description": "This table compares the proposed DELT method with other state-of-the-art (SOTA) dataset distillation methods on five benchmark datasets (CIFAR-10, ImageNette, Tiny-ImageNet, ImageNet-100, and ImageNet-1K) using relatively large-scale backbone architectures (ResNet-18, ResNet-101, and MobileNet-v2).  The table shows the top-1 accuracy achieved by each method for different numbers of images per class (IPC).  It highlights DELT's superior performance across various datasets and scales, especially with larger IPC values, while noting limitations for the IPC=1 scenario.", "section": "4.1 Datasets and Results Details"}]