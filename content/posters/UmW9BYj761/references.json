{"references": [{"fullname_first_author": "Radford", "paper_title": "Learning transferable visual models from natural language supervision", "publication_date": "2021-07-01", "reason": "This paper introduces CLIP, a foundational model for contrastive vision-language learning that is extensively used and analyzed in the target paper."}, {"fullname_first_author": "Zhai", "paper_title": "Sigmoid loss for language image pre-training", "publication_date": "2023-03-15", "reason": "This paper introduces SigLIP, the model architecture used in the target paper's experiments, making it a central methodological reference."}, {"fullname_first_author": "Deng", "paper_title": "Imagenet: A large-scale hierarchical image database", "publication_date": "2009-06-21", "reason": "ImageNet is a benchmark dataset frequently used to evaluate vision models; its mention highlights the target paper's focus on broader evaluation beyond standard benchmarks."}, {"fullname_first_author": "Lin", "paper_title": "Microsoft coco: Common objects in context", "publication_date": "2014-09-01", "reason": "COCO is another popular benchmark dataset for evaluating vision and vision-language models, emphasizing the target paper's interest in broader evaluation metrics."}, {"fullname_first_author": "Rojas", "paper_title": "The dollar street dataset: Images representing the geographic and socioeconomic diversity of the world", "publication_date": "2022-05-01", "reason": "Dollar Street is a key dataset used in the target paper for evaluating cultural diversity, showcasing the paper's focus on this specific aspect of model evaluation."}]}