[{"figure_path": "UmW9BYj761/figures/figures_1_1.jpg", "caption": "Figure 1: Models trained on English image-text pairs exhibit a lack of diversity when evaluated on images from other regions, sometimes confusing landmarks with similar ones located in the West.", "description": "This figure shows the limitations of models trained only on English image-text pairs.  When evaluating these models on images from various regions worldwide, they frequently misclassify landmarks, often confusing them with visually similar landmarks located in Western countries. This highlights a bias towards Western perspectives and demonstrates the lack of cultural diversity in models trained on limited data.", "section": "1 Introduction"}, {"figure_path": "UmW9BYj761/figures/figures_3_1.jpg", "caption": "Figure 2: Data distribution [%] for each of the evaluation datasets, only approximate in MaRVL [39] based on the 5 languages collected in the dataset. Dollar Street [49], GeoDE [47], GLDv2 [66] and XM3600 [20] are geographically diverse. MaRVL is included because it focuses on underrepresented regions, such as Asia and East Africa. By comparison, ImageNet examples are mostly from a few Western countries (see for instance [53]). COCO has a nearly identical distribution to ImageNet [16].", "description": "This figure shows the geographical distribution of images in six different datasets used to evaluate the cultural diversity of vision-language models.  The datasets include Dollar Street, GeoDE, GLDv2, XM3600, MaRVL, ImageNet, and COCO.  The figure highlights the significant geographical bias in ImageNet and COCO datasets, which are predominantly composed of images from Western countries, in contrast to the other datasets which exhibit greater geographical diversity.", "section": "Evaluation Data"}, {"figure_path": "UmW9BYj761/figures/figures_6_1.jpg", "caption": "Figure 4: Fine-tuning globe-tl on en quickly catches up with en for ImageNet zero-shot evaluation while also performing better on GLDv2. Conversely, fine-tuning en on globe-tl does not suffice to close the gap in performance on culturally diverse benchmarks.", "description": "This figure shows the impact of fine-tuning on two different models, one trained on English-only data (en) and one trained on global data (globe-tl). The left panel displays the zero-shot classification accuracy on ImageNet, while the right panel shows the accuracy on GLDv2. Fine-tuning the globe-tl model on English data improves its performance on ImageNet, almost reaching the level of the English-only model.  However, fine-tuning the English-only model on global data does not lead to a similar improvement on GLDv2, highlighting the difficulty in improving performance on culturally diverse benchmarks.", "section": "3.4 Bridging the gap"}, {"figure_path": "UmW9BYj761/figures/figures_7_1.jpg", "caption": "Figure 5: LEFT: Fine-tuning allows for a controlled trade-off between cultural diversity and performance on standard benchmarks. Fine-tuning globe-tl on en is strictly better than fine-tuning en on globe-tl, but mixing training data in different proportions achieves a better trade-off overall. Values in percentages [%] correspond to the fraction of time training is restricted to endata. RIGHT: Correlation coefficients of the evaluation metrics computed based on over 40 fully trained models.", "description": "This figure presents two key findings. The left panel shows the impact of fine-tuning models pretrained on either English-only (en) or globally diverse (globe-tl) data on ImageNet and GLDv2. It demonstrates a trade-off between performance on standard benchmarks (ImageNet) and cultural diversity (GLDv2). Fine-tuning globe-tl models on English data quickly improves ImageNet performance, while maintaining better GLDv2 results than fine-tuning English models on global data.  Data mixing provides a comparable yet more efficient alternative for achieving this balance. The right panel displays a correlation matrix showing the relationships between various evaluation metrics (zero-shot classification on different datasets and few-shot geo-localization), further highlighting the interdependency of performance across cultural diversity and standard benchmarks.", "section": "3.4 Bridging the gap"}]