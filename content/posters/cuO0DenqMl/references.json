{"references": [{"fullname_first_author": "Ravid Shwartz-Ziv", "paper_title": "Tabular data: Deep learning is not all you need", "publication_date": "2022-01-01", "reason": "This paper is foundational to the work presented, establishing the need for alternative approaches to deep learning, especially in tabular data."}, {"fullname_first_author": "Moloud Abdar", "paper_title": "A review of uncertainty quantification in deep learning: Techniques, applications and challenges", "publication_date": "2021-01-01", "reason": "This paper provides a comprehensive overview of uncertainty quantification in deep learning, highlighting the importance of predictive uncertainty in real-world applications."}, {"fullname_first_author": "Yarin Gal", "paper_title": "Dropout as a Bayesian approximation: Representing model uncertainty in deep learning", "publication_date": "2016-01-01", "reason": "This highly influential work introduced dropout as a Bayesian approximation, providing a practical approach to model uncertainty quantification in deep learning."}, {"fullname_first_author": "Balaji Lakshminarayanan", "paper_title": "Simple and scalable predictive uncertainty estimation using deep ensembles", "publication_date": "2017-01-01", "reason": "This paper proposed deep ensembles as a method for predictive uncertainty estimation, offering a simple and scalable approach that is competitive with more complex methods."}, {"fullname_first_author": "Murat Sensoy", "paper_title": "Evidential deep learning to quantify classification uncertainty", "publication_date": "2018-01-01", "reason": "This paper introduced evidential deep learning, a novel approach that addresses the challenges of probabilistic classification and uncertainty quantification."}]}