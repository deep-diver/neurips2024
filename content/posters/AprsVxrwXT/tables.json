[{"figure_path": "AprsVxrwXT/tables/tables_7_1.jpg", "caption": "Table 1: Qualitative comparison of different methods based on various metrics.", "description": "This table presents a quantitative comparison of MVGamba against several state-of-the-art 3D generation methods across various metrics.  The metrics used to evaluate the methods include PSNR (peak signal-to-noise ratio), SSIM (structural similarity index), LPIPS (learned perceptual image patch similarity), CLIP (Contrastive Language\u2013Image Pre-training) score, R-Prec (Recall@Precision) and inference time.  Higher values for PSNR, SSIM, CLIP, and R-Prec indicate better performance, while lower values for LPIPS and inference time are preferred.  The table shows that MVGamba outperforms most other methods across all metrics, particularly in terms of PSNR, SSIM, and CLIP.", "section": "4.2 Comparison against Baselines"}, {"figure_path": "AprsVxrwXT/tables/tables_8_1.jpg", "caption": "Table 1: Qualitative comparison of different methods based on various metrics.", "description": "This table presents a quantitative comparison of MVGamba against several state-of-the-art 3D generation methods across different metrics, including PSNR, SSIM, LPIPS, CLIP, R-Prec, and Inference Time.  The metrics evaluate the quality of the generated 3D models in terms of image fidelity, visual similarity, and geometric accuracy. It demonstrates MVGamba's superior performance compared to other methods, particularly in terms of generation quality, despite having a significantly smaller model size.", "section": "4.2 Comparison against Baselines"}, {"figure_path": "AprsVxrwXT/tables/tables_16_1.jpg", "caption": "Table 3: Theoretically calculated FLOPs comparison between self-attention in Transformer and SSM in Mamba. Here, dimension D = 512; GFLOPs of both modules are calculated according to Equations (5) and (6) in Vision Mamba [26].", "description": "This table compares the computational cost (GFLOPs) of self-attention in Transformer networks and SSM (State Space Model) in Mamba networks for various sequence lengths (1024, 2048, 4096, 8192, 16384, and 32768).  It demonstrates the linear complexity of Mamba compared to the quadratic complexity of Transformer self-attention, highlighting Mamba's computational efficiency for long sequences.", "section": "B.1 Comparison with concurrent works"}, {"figure_path": "AprsVxrwXT/tables/tables_16_2.jpg", "caption": "Table 1: Qualitative comparison of different methods based on various metrics.", "description": "This table presents a quantitative comparison of MVGamba against several state-of-the-art methods for single image-to-3D generation.  The metrics used for comparison include PSNR, SSIM, LPIPS, CLIP score, R-Precision, and inference time.  Higher PSNR and SSIM values, along with a lower LPIPS score, indicate better visual quality. A higher CLIP score represents better alignment with the given text prompt, and higher R-Precision indicates better reconstruction of the objects' geometry. Lower inference time is preferred. The table shows that MVGamba significantly outperforms existing methods across most of the metrics, particularly in terms of visual quality and precision.", "section": "4.2 Comparison against Baselines"}, {"figure_path": "AprsVxrwXT/tables/tables_20_1.jpg", "caption": "Table 1: Qualitative comparison of different methods based on various metrics.", "description": "This table presents a quantitative comparison of MVGamba against other state-of-the-art 3D generation methods across various metrics including PSNR, SSIM, LPIPS, CLIP score, R-Precision, and inference time.  It highlights MVGamba's superior performance in terms of generation quality and efficiency.", "section": "4.2 Comparison against Baselines"}]