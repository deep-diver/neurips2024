[{"figure_path": "Of4iNAIUSe/tables/tables_2_1.jpg", "caption": "Table 1: Comparison of federated self-supervised learning methods.", "description": "This table compares different federated self-supervised learning methods based on several key aspects: whether they use a global model, the size of the global model relative to client models, the presence of model heterogeneity across clients, the presence of deviated representation abilities among client models, the consistency of representation spaces, and whether a theoretical analysis is provided.  It highlights the unique characteristics of each method and positions FedMKD within this landscape.", "section": "1 Introduction"}, {"figure_path": "Of4iNAIUSe/tables/tables_6_1.jpg", "caption": "Table 2: Top-1 accuracy comparison under linear probing on CIFAR datasets with best model performance in bold and second-best results with underlines. '-' means this method is not suitable for the experiment setting.", "description": "This table presents a comparison of the top-1 accuracy achieved by various federated self-supervised learning methods on CIFAR-10 and CIFAR-100 datasets using linear probing.  The results are broken down by dataset (CIFAR-10, CIFAR-100), data distribution (IID, Class, Dir(\u03b2=0.5)), and whether a public dataset was used.  The best performing model for each configuration is shown in bold, with the second-best underlined. A hyphen indicates when a method is not applicable for a given setting.", "section": "5 Performance Evaluation"}, {"figure_path": "Of4iNAIUSe/tables/tables_7_1.jpg", "caption": "Table 2: Top-1 accuracy comparison under linear probing on CIFAR datasets with best model performance in bold and second-best results with underlines. '-' means this method is not suitable for the experiment setting.", "description": "This table compares the Top-1 accuracy of various federated self-supervised learning methods on CIFAR-10 and CIFAR-100 datasets using linear probing.  The results are categorized by the type of public dataset used (IID or Partial), data distribution (IID, Dir(\u03b2=0.5), Class), and the specific method used. The best and second-best performing models for each configuration are highlighted.", "section": "5.3 Performance Evaluation"}, {"figure_path": "Of4iNAIUSe/tables/tables_8_1.jpg", "caption": "Table 4: Experimental results on ablation studies of FedMKD with best model performance in bold.", "description": "This table presents the results of ablation studies conducted on the FedMKD model.  It shows the impact of removing key components of the FedMKD framework, such as the KL-divergence loss, adaptive knowledge integration, and global knowledge anchored alignment. By comparing the performance of the full FedMKD model against these variants, the table demonstrates the contribution of each component to the overall performance.  The results are presented separately for CIFAR-10 and CIFAR-100 datasets, with both class and IID data distributions.", "section": "5.6 Ablation experiment"}, {"figure_path": "Of4iNAIUSe/tables/tables_9_1.jpg", "caption": "Table 5: Experimental results on scalability studies of FedMKD.", "description": "This table presents the results of experiments conducted to evaluate the scalability of the FedMKD algorithm.  The performance (linear and semi-supervised results) of FedMKD is measured across varying numbers of clients (5, 10, and 30).  The results show the impact of increasing the number of clients on the algorithm's performance.", "section": "5.7 Scalability of algorithm"}, {"figure_path": "Of4iNAIUSe/tables/tables_17_1.jpg", "caption": "Table 2: Top-1 accuracy comparison under linear probing on CIFAR datasets with best model performance in bold and second-best results with underlines. '-' means this method is not suitable for the experiment setting.", "description": "This table presents a comparison of the top-1 accuracy achieved by different federated self-supervised learning methods on CIFAR-10 and CIFAR-100 datasets using linear probing.  The results are categorized by the type of public dataset used (IID or Partial), data distribution (IID, Dir(\u03b2=0.1), Dir(\u03b2=0.5), and Class), and the specific method. The best and second-best performances for each setting are highlighted.  A dash indicates that the particular method is not applicable to a given experimental condition.", "section": "5. Performance Evaluation"}, {"figure_path": "Of4iNAIUSe/tables/tables_17_2.jpg", "caption": "Table 2: Top-1 accuracy comparison under linear probing on CIFAR datasets with best model performance in bold and second-best results with underlines. '-' means this method is not suitable for the experiment setting.", "description": "This table presents a comparison of the top-1 accuracy achieved by different federated self-supervised learning methods on CIFAR-10 and CIFAR-100 datasets.  The accuracy is measured using linear probing, and the best and second-best results for each setting (IID, Class, Dir(\u03b2=0.5)) and dataset are highlighted.  The table also indicates which methods are not applicable for specific settings.", "section": "5.3 Performance Evaluation"}, {"figure_path": "Of4iNAIUSe/tables/tables_18_1.jpg", "caption": "Table 2: Top-1 accuracy comparison under linear probing on CIFAR datasets with best model performance in bold and second-best results with underlines. '-' means this method is not suitable for the experiment setting.", "description": "This table compares the performance of different federated self-supervised learning methods on CIFAR-10 and CIFAR-100 datasets. The methods are evaluated under three different data distributions (IID, Class, and Dirichlet with \u03b2=0.5).  The table shows the top-1 accuracy achieved by each method using linear probing. The best and second-best results are highlighted for each setting.", "section": "5 Performance Evaluation"}, {"figure_path": "Of4iNAIUSe/tables/tables_18_2.jpg", "caption": "Table 2: Top-1 accuracy comparison under linear probing on CIFAR datasets with best model performance in bold and second-best results with underlines. '-' means this method is not suitable for the experiment setting.", "description": "This table compares the Top-1 accuracy of various federated self-supervised learning methods on CIFAR-10 and CIFAR-100 datasets using linear probing.  The results are shown for different public dataset types ('IID' and 'Partial'), class distributions (IID, Dir(\u03b2=0.1), Dir(\u03b2=0.5)), and model settings.  The best and second-best performing methods for each scenario are highlighted.  A '-' indicates the method wasn't applicable for a given setup.", "section": "5 Performance Evaluation"}, {"figure_path": "Of4iNAIUSe/tables/tables_19_1.jpg", "caption": "Table 10: Communication and storage cost comparison of FedMKD and several baselines.", "description": "This table compares the communication and storage costs of the proposed FedMKD method with several baseline federated self-supervised learning methods.  The communication cost represents the amount of data transferred during model training, while the storage cost indicates the amount of memory required to store model parameters.  The table breaks down these costs separately for models using ResNet18 and VGG9 architectures. This helps understand the efficiency of FedMKD concerning resource utilization during the federated learning process.", "section": "5 Experiments"}]