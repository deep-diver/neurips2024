[{"figure_path": "Mktgayam7U/tables/tables_5_1.jpg", "caption": "Table 1: Performance of KIO, IO, two Behavior Cloning (BC) agents, and the Teacher agent on MuJoCo tasks from the D4RL benchmark on the normalized return metric. The numbers in parentheses represent the amount of data used by KIO and IO, and the score for KIO in each task is the average score over 100 episodes.", "description": "This table compares the performance of the proposed Kernel Inverse Optimization (KIO) model against other methods on six MuJoCo continuous control tasks from the D4RL benchmark.  It shows the average normalized return for KIO (with varying dataset sizes), standard IO, two behavior cloning baselines (BC(TD3+BC) and BC(CQL)), and the expert (Teacher) agent for each task. The results highlight KIO's ability to achieve comparable or better performance than existing methods, especially with limited data.", "section": "5 Numerical Experiments"}, {"figure_path": "Mktgayam7U/tables/tables_6_1.jpg", "caption": "Table 1: Performance of KIO, IO, two Behavior Cloning (BC) agents, and the Teacher agent on MuJoCo tasks from the D4RL benchmark on the normalized return metric. The numbers in parentheses represent the amount of data used by KIO and IO, and the score for KIO in each task is the average score over 100 episodes.", "description": "The table presents the performance comparison of six different agents (KIO, IO, BC(TD3+BC), BC(CQL), and Teacher) across six different MuJoCo tasks from the D4RL benchmark.  The normalized return metric is used to evaluate the performance, and for KIO and IO, the amount of training data used is specified in parentheses. KIO's scores represent the average over 100 test episodes.", "section": "5.1 Performance Evaluation"}, {"figure_path": "Mktgayam7U/tables/tables_7_1.jpg", "caption": "Table 2: Final Objective Function Value and Score (average return over 100 evaluations) for SCS [27] and SSO (20 iterations for all tasks) algorithms. The ultimate Objective Function Values of the two algorithms are nearly identical, yet across the majority of tasks, SSO achieves a slightly higher score compared to SCS.", "description": "This table compares the performance of two algorithms, SCS and SSO, in solving the optimization problem (9) from the paper.  The comparison is based on the objective function value and the average score (return) over 100 test episodes for six different tasks.  It shows that while both algorithms achieve very similar objective function values, SSO generally achieves slightly better scores (higher average return).", "section": "5.1 Performance Evaluation"}, {"figure_path": "Mktgayam7U/tables/tables_8_1.jpg", "caption": "Table 3: Performance of KIO, two Behavior Cloning (BC) agents, and the Teacher agent on MuJoCo tasks from the D4RL benchmark on the normalized return metric. The numbers in parentheses represent the amount of data used by KIO, and the score for KIO in each task is the average score over 100 episodes.", "description": "This table presents the performance comparison of the proposed Kernel Inverse Optimization (KIO) model against two behavior cloning baselines (BC(TD3+BC) and BC(CQL)) and a teacher agent on three MuJoCo tasks from the D4RL benchmark.  The KIO model's scores represent the average normalized return over 100 test episodes, with the number of data points used in parentheses.  The table highlights KIO's performance, particularly when compared to the behavior cloning baselines.", "section": "5 Numerical Experiments"}, {"figure_path": "Mktgayam7U/tables/tables_13_1.jpg", "caption": "Table 1: Performance of KIO, IO, two Behavior Cloning (BC) agents, and the Teacher agent on MuJoCo tasks from the D4RL benchmark on the normalized return metric. The numbers in parentheses represent the amount of data used by KIO and IO, and the score for KIO in each task is the average score over 100 episodes.", "description": "This table presents a comparison of the performance of five different agents on six MuJoCo tasks from the D4RL benchmark.  The agents are Kernel Inverse Optimization (KIO), Inverse Optimization (IO), two behavior cloning agents (BC(TD3+BC) and BC(CQL)), and the Teacher agent (which generated the dataset). The table shows the average normalized return for each agent on each task, with the number of data points used by KIO and IO indicated in parentheses.  The results demonstrate the relative performance of KIO against other methods, particularly highlighting the advantage of the kernel method in achieving high scores.", "section": "Numerical Experiments"}, {"figure_path": "Mktgayam7U/tables/tables_14_1.jpg", "caption": "Table 5: Performance of KIO on MuJoCo tasks from the D4RL benchmark on the normalized return metric. The scores in each task represent the average score over 100 episodes within the range of one standard deviation.", "description": "This table presents the performance of the Kernel Inverse Optimization (KIO) model using different kernel functions (RBF, Laplace, and Linear) on various MuJoCo tasks from the D4RL benchmark.  The scores represent the average normalized return over 100 test episodes, and error bars (standard deviation) are included to show variability.", "section": "C Ablation Study on Kernel Function"}]