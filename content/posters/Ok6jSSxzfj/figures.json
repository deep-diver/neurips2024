[{"figure_path": "Ok6jSSxzfj/figures/figures_1_1.jpg", "caption": "Figure 1: Illustration of the cross-spectral transformation. G refers to the green channel of the visible image. Under the same illumination, the cross-spectral transformation could be described as a linear transformation in a material-similar surface. Still, in the whole image level, the transformation is nonlinear due to the diversity of materials. Since the Re-ID image pairs are not well aligned, we select the cross-spectral image pairs from [13].", "description": "The figure shows an example of cross-spectral transformation between visible and NIR images.  It highlights that while a linear transformation exists at the pixel level for materials with similar surfaces, the overall image-level transformation is nonlinear because of the diversity of materials with different reflective properties. This nonlinearity is a key aspect that the paper addresses.", "section": "3 Reflection Prior for Cross-Spectral Images"}, {"figure_path": "Ok6jSSxzfj/figures/figures_3_1.jpg", "caption": "Figure 2: Example images from the VIS-NIR scene dataset [13]. After we divide the visible image into the red, green, and blue channels and form chromaticity band ratios from these three spectra and the NIR image, it is clear that the ratio for pixels from the surface with high material-similarity is nearly constant.", "description": "This figure shows example images from the VIS-NIR scene dataset.  The images are divided into visible (VIS) and near-infrared (NIR) channels, and further processed to compute chromaticity band ratios (R-NIR, G-NIR, B-NIR).  The ratios are shown as color-coded images. The key observation is that pixels from surfaces with similar material properties exhibit nearly constant ratios across the different spectral bands, suggesting a linear relationship between the visible and NIR spectral responses for homogenous surfaces.", "section": "3 Reflection Prior for Cross-Spectral Images"}, {"figure_path": "Ok6jSSxzfj/figures/figures_3_2.jpg", "caption": "Figure 3: A example about how modality discrepancy occurs. Feature space visualization of 100 randomly selected images with (dot) and without (fork) the local linear transformation on the original image. (a)~(b): The same linear factor takes effect on the whole image bringing limited modality discrepancy. (c): Variable linear factors take effect on different parts showing a huge modality discrepancy. The 'cross' and 'dot' marks indicate the samples from the original one and the generated one respectively.", "description": "This figure shows how modality discrepancy happens in cross-spectral re-identification.  It uses feature space visualization of 100 randomly selected images to illustrate three scenarios:\n(a) and (b) show that applying the same linear factor across the whole image results in limited modality discrepancy.\n(c) shows that applying variable linear factors to different parts of the image leads to significant modality discrepancy. This highlights the importance of considering local linear transformations in cross-spectral re-identification.", "section": "3 Reflection Prior for Cross-Spectral Images"}, {"figure_path": "Ok6jSSxzfj/figures/figures_4_1.jpg", "caption": "Figure 4: The motivation of RLE. Herein, we construct an ideal person with only two different surfaces and ignore the background. (a): As demonstrated above, to obtain a spectral-invariant feature representation, the network should be robust to such a transformation that takes effect upon definite surfaces by definite linear factors. (b): An ideal data augmentation strategy that takes effect upon definite surfaces by random linear factors. However, this method needs a hard-achieved extra material-aware network for segmentation. (c): The idea of RRLE. By taking effect upon random surfaces by random linear factors, the RRLE encourages the network to be robust to a linear transformation anywhere in the image. Under this condition, the cross-spectral transformation can be considered as an easy state of RRLE space.", "description": "This figure illustrates the motivation behind the Random Linear Enhancement (RLE) method proposed in the paper for cross-spectral re-identification. It shows three scenarios: (a) a definite linear transformation on a definite image patch, (b) a random linear transformation on a definite image patch, and (c) a random linear transformation on a random image patch. The figure highlights how RLE aims to make the network robust to linear transformations by applying random linear transformations on random image patches, mimicking the modality discrepancy in cross-spectral images.", "section": "4 Random Linear Enhancement"}, {"figure_path": "Ok6jSSxzfj/figures/figures_9_1.jpg", "caption": "Figure 5: Visualization results of RLE. Since the MRLE can not take effect on the infrared images, we use '~' instead. Meanwhile, Both MRLE and RRLE are used with a certain probability. Therefore, all of the augmentation images above are potential results.", "description": "This figure visualizes the results of the Random Linear Enhancement (RLE) data augmentation method on both visible and infrared images.  The top row shows an example where MRLE (Moderate Random Linear Enhancement) and RRLE (Radical Random Linear Enhancement) are applied to visible images, producing transformations that maintain original linear correlations (MRLE) and transformations that don't rely on linear correlations (RRLE). The bottom row shows another example with different regions highlighted. The infrared images show the effects of MRLE and RRLE, while '~' indicates that MRLE can't directly affect infrared images.  The figure demonstrates the diversity achievable through the RLE technique.", "section": "5 Experiments"}, {"figure_path": "Ok6jSSxzfj/figures/figures_13_1.jpg", "caption": "Figure 4: The motivation of RLE. Herein, we construct an ideal person with only two different surfaces and ignore the background. (a): As demonstrated above, to obtain a spectral-invariant feature representation, the network should be robust to such a transformation that takes effect upon definite surfaces by definite linear factors. (b): An ideal data augmentation strategy that takes effect upon definite surfaces by random linear factors. However, this method needs a hard-achieved extra material-aware network for segmentation. (c): The idea of RRLE. By taking effect upon random surfaces by random linear factors, the RRLE encourages the network to be robust to a linear transformation anywhere in the image. Under this condition, the cross-spectral transformation can be considered as an easy state of RRLE space.", "description": "This figure illustrates the motivation behind the Random Linear Enhancement (RLE) data augmentation strategy. It shows three scenarios: (a) a definite linear transformation on a definite image patch, (b) a random linear transformation on a definite image patch, and (c) a random linear transformation on a random image patch. Scenario (c) represents the RRLE approach, which encourages network robustness to linear transformations by applying them randomly to image regions.  This contrasts with (a) and (b), where transformations are either consistent or only applied to specific locations.", "section": "4 Random Linear Enhancement"}, {"figure_path": "Ok6jSSxzfj/figures/figures_14_1.jpg", "caption": "Figure 6: A example of modality discrepancy. The dot and forks refer to the sample with and without linear transformation. Clearly, Small linear factors may not be so efficient in generating images with a significant modality gap in the training stage.", "description": "This figure shows an example of how modality discrepancy occurs when applying linear transformations with small linear factors.  The top row demonstrates an image that has been divided into sections and multiplied by varying factors (1.5, 0.5, etc.). The bottom row shows a similar process but with smaller factors (1.1, 0.9, etc.). The resulting feature space visualizations (right side) reveal that the smaller factors result in less significant separation, highlighting the inadequacy of small linear factors in creating a notable modality gap during training.", "section": "A Appendix / supplemental material"}]