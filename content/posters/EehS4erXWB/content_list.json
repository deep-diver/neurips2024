[{"type": "text", "text": "SE(3)-bi-equivariant Transformers for Point Cloud Assembly ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Ziming Wang, Rebecka J\u00f6rnsten ", "page_idx": 0}, {"type": "text", "text": "Department of Mathematical Sciences University of Gothenburg and Chalmers University of Technology zimingwa@chalmers.se, jornsten@chalmers.se ", "page_idx": 0}, {"type": "text", "text": "Abstract ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Given a pair of point clouds, the goal of assembly is to recover a rigid transformation that aligns one point cloud to the other. This task is challenging because the point clouds may be non-overlapped, and they may have arbitrary initial positions. To address these difficulties, we propose a method, called $S E(3)$ -bi-equivariant transformer (BITR), based on the $S E(3)$ -bi-equivariance prior of the task: it guarantees that when the inputs are rigidly perturbed, the output will transform accordingly. Due to its equivariance property, BITR can not only handle nonoverlapped PCs, but also guarantee robustness against initial positions. Specifically, BITR first extracts features of the inputs using a novel $S E(3)\\\"\\times S E(3)$ -transformer, and then projects the learned feature to group $S E(3)$ as the output. Moreover, we theoretically show that swap and scale equivariances can be incorporated into BITR, thus it further guarantees stable performance under scaling and swapping the inputs. We experimentally show the effectiveness of BITR in practical tasks. ", "page_idx": 0}, {"type": "text", "text": "1 Introduction ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Point cloud (PC) assembly is a fundamental machine learning task with a wide range of applications such as biology [12], archeology [36], robotics [28, 20] and computer vision [23]. As shown in Fig. 1, given a pair of 3-D PCs representing two shapes, i.e., a source and a reference PC, the goal of assembly is to find a rigid transformation, so that the transformed source PC is aligned to the reference PC. This task is challenging because the input PCs may have random initial positions that are far from the optimum, and may be non-overlapped, e.g., due to occlusion or erosion of the object. ", "page_idx": 0}, {"type": "image", "img_path": "EehS4erXWB/tmp/8449428d21849cc18e73293490e85de0a06c09cdd1edb94589f08c3a8fb1fabc.jpg", "img_caption": ["(a) Assembly of overlapped PCs "], "img_footnote": [], "page_idx": 0}, {"type": "image", "img_path": "EehS4erXWB/tmp/46dba9ab60da8963cbf32b3a03f69ee01a2dd17a116c5e89a32cd1c5812a91be.jpg", "img_caption": ["(b) Assembly of non-overlapped PCs "], "img_footnote": [], "page_idx": 0}, {"type": "text", "text": "Figure 1: Two examples of PC assembly. Given a pair of PCs, the proposed method BITR transforms the source PC (red) to align the reference PC (blue). The input PCs may be overlapped (a) or non-overlapped (b). ", "page_idx": 0}, {"type": "text", "text": "Most of existing assembly methods are correspondence-based [2, 23, 4]: they use the fact that when the input PCs are aligned, the points corresponding to the same physical position should be close to each other. For example, in Fig. 1(a), the points at the head of the airplane in the source and reference PCs should be close in the aligned PC. Specifically, these methods first estimate the correspondence between PCs based on feature similarity or distance, and then compute the transformation by matching the estimated corresponding point pairs. As a result, these methods generally have difficulty handling PCs with no correspondence, i.e., non-overlapped PCs, such as Fig. 1(b). In addition, they are often sensitive to the initial positions of PCs. ", "page_idx": 0}, {"type": "text", "text": "", "page_idx": 1}, {"type": "text", "text": "To address these difficulties, we propose a method, called $S E(3)$ -bi-equivariant transformer (BITR), based on the $S E(3)$ -bi-equivariance prior of the task: when the input PCs are perturbed by rigid transformations, the output should transform accordingly. A formal definition of $S E(3)$ -bi-equivariance can be found in Def. 3.1. Our motivation for using the $S E(3)$ -bi-equivariance prior is threefold: First, the strong training guidance provided by symmetry priors is known to lead to large performance gain and high data efficiency. For example, networks with a translation-equivariance prior, i.e., convolutional neural networks (CNNs), are known to excel at image segmentation [18]. Thus, $S E(3)$ -bi-equivariance prior should lead to similar practical benefits in PC assembly tasks. Second, $S E(3)$ -bi-equivariant methods are theoretically guaranteed to be \u201cglobal\u201d, i.e., their performances are independent of the initial positions. Third, the $S E(3)$ -bi-equivariance prior does not rely on correspondence, i.e., it can be used to handle PCs with no correspondence. ", "page_idx": 1}, {"type": "text", "text": "Specifically, the proposed BITR is an end-toend trainable model consisting of two steps: it first extracts $S O(3)\\times S O(3)$ -equivariant features from the input PCs, and then obtains a rigid transformation by projecting the features into $S E(3)$ . For the first step, we define a $S E(3)\\times S E(3)$ -transformer acting on the 6-D merged PC by extending the $S\\bar{E}(3)$ - transformer [11]; For the second step, we use a $S V D$ -type projection inspired by Arun\u2019s method [2]. In addition, we theoretically show that scale-equivariance and swap-equivariance can be incorporated into BITR via weight constraining techniques, which further guarantees that the performance is not influenced by scaling or swapping inputs. An illustration of BITR is presented in Fig. 2. ", "page_idx": 1}, {"type": "image", "img_path": "EehS4erXWB/tmp/4c7d953512eb5fdee795a1c2f7080db4d555aa579deb144a873ff899ef36649c.jpg", "img_caption": ["SE(3)-Transformer SE(3)x SE(3)-Transformer SE(3)-Projection", "Figure 2: An overview of BITR. The input 3-D PCs $X$ and $Y$ are first merged into a 6-D PC $Z$ by concatenating the extracted key points $\\tilde{X}$ and $\\bar{\\tilde{Y}}$ . Then, $Z$ is fed into a $S E(3)\\times\\bar{S}\\bar{E}(3)$ -transformer to obtain equivariant features $\\hat{r}$ , $t_{X}$ and $t_{Y}$ . These features are finally projected to $S E(3)$ as the output. "], "img_footnote": [], "page_idx": 1}, {"type": "text", "text": "In summary, the contribution of this work is as follows: ", "page_idx": 1}, {"type": "text", "text": "- We present a $S E(3)$ -bi-equivariant PC assembly method, called BITR. 1 BITR can assemble PCs without correspondence, and guarantees stable performance with arbitrary initial positions. In addition, the $\\bar{S E}(3)\\times S E(3)$ -transformer used in BITR is the first $S E(3)\\stackrel{.}{\\times}S E(3)$ -equivariant steerable network to the best of our knowledge. ", "page_idx": 1}, {"type": "text", "text": "- Theoretically, we show that scale and swap equivariance can be incorporated in to BITR by weight-constraining, thus it guarantees stable performance under scaling and swapping the inputs. - We show experimentally that BITR can effectively assemble PCs in practical tasks. ", "page_idx": 1}, {"type": "text", "text": "2 Related works ", "text_level": 1, "page_idx": 1}, {"type": "text", "text": "A special case of PC assembly is PC registration, where the correspondence between input PCs is assumed to exist. A seminal work in this task was conducted by [2], which provided a closed-form solution to the problem with known correspondence. To handle PCs with unknown correspondence, most of the subsequent works extend [2] by first estimating the correspondence by comparing distances [4], or features [25, 23, 41] of the PCs, and then aligning the PCs by aligning the estimated corresponding points. Notably, to obtain $S E(3)$ -bi-equivariance, $S O(3)$ -invariant features [42, 10, 43] have been investigated for correspondence estimation. However, since these methods require a sufficient number of correspondences, they have difficulty handling PCs where the correspondence does not exist. In addition, they often have difficulty handling PCs with large initial errors [45]. ", "page_idx": 1}, {"type": "text", "text": "The proposed BITR is related to the existing registration methods because it can be seen as a generalization of Arun\u2019s method [2]. However, in contrast to these methods, BITR is correspondencefree, i.e., it is capable of handling PCs with no correspondence. In addition, it theoretically guarantees stable performance under arbitrary initial position. ", "page_idx": 2}, {"type": "text", "text": "Recently, some works have been devoted to a new PC assembly task, called fragment reassembly, whose goal is to reconstruct a complete shape from two fragments. Unlike registration task, this task generally does not assume the existence of correspondence. [7] first studied this task, and they addressed it as a pose estimation problem, where the pose of each fragment relative to a canonical pose is estimated via a regression model. [38] further improved this method by considering the $S E(3)$ -equivariance of each fragment. In addition, [31] proposed a simulated dataset for this task. In contrast to these methods, the proposed BITR does not rely on the canonical pose, i.e., it directly estimates the relative pose. As a result, BITR is conceptually simpler and it can handle the shape whose canonical pose is unknown. ", "page_idx": 2}, {"type": "text", "text": "Another related research direction is equivariant networks. Due to their ability to incorporate 3D rotation and translation symmetry priors, these networks have been extensively used in modelling 3D data [29, 9, 37, 17, 13], and recently they have been used for robotic manipulation task [27, 28, 40]. In particular, [34] proposed a tensor field network (TFN) for PC processing, and $S E(3)$ -transformer [11] further improved TFN by introducing the attention mechanism. On the other hand, the theory of equivariant networks was developed in [16, 5]. BITR follows this line of research because the $\\bar{S E}(3)\\times S E(3)$ -transformer used in BITR is a direct generalization of $S E(3)$ -transformer [11], and it is the first $S E(3)\\times S E(3)$ -equivariant steerable network to the best of our knowledge. ", "page_idx": 2}, {"type": "text", "text": "3 Preliminaries ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "This section briefly reviews Arun\u2019s method and the concept of equivariance, which will be used in BITR. ", "page_idx": 2}, {"type": "text", "text": "3.1 Group representation and equivariance ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "Given a group $G$ , its representation is a group homomorphism $\\rho:G\\to G L(V)$ , where $V$ is a linear space. When $G$ is the 3D rotation group $S O(3)$ , it is convenient to consider its irreps (irreducible orthogonal representation) $\\rho_{p}:S O(3)\\rightarrow G L(V_{p})$ , where $p\\in\\mathbb N$ is the degree of the irreps, and $d i m(V_{p})\\,=\\,2p+1$ . For $r\\,\\in G$ , $\\rho_{p}(r)\\,\\in\\,\\mathbb{R}^{(2p+1)\\times(2p+1)}$ is known as the Wigner-D matrix. For example, $\\rho_{0}(r)=1$ for all $r\\in S O(3)$ ; $\\rho_{1}(r)\\in\\mathbb{R}^{3\\times3}$ is the rotation matrix of $r$ . More details can be found in [5] and the references therein. ", "page_idx": 2}, {"type": "text", "text": "In this work, we focus on the group $G$ of two independent rotations, i.e., $G=S O(3)\\times S O(3)$ , where $\\times$ represents the direct product. Similar to $S O(3)$ , we also consider the irreps of $G$ . A useful fact is that all irreps of $G$ can be written as the combinations of the irreps of $S O(3)$ : the degree- $(p,q)$ irreps of $G$ is $\\rho_{p,q}=\\rho_{p}\\otimes\\rho_{q}:S O(3)\\times S O(3)\\rightarrow G L(V_{p}\\otimes V_{q})$ , where $p,q\\in\\mathbb{N}$ , $\\rho_{p}$ and $\\rho_{q}$ are irreps of $S O(3)$ , and $\\otimes$ is tensor product (Kronecker product for matrix). For example, $\\hat{\\rho_{0,0}}(r_{1}\\times\\dot{r}_{2})=1\\in\\mathbb{R}$ ; $\\rho_{1,0}(\\boldsymbol{r}_{1}\\times\\boldsymbol{r}_{2})\\in\\mathbb{R}^{3\\times3}$ is the rotation matrix of $r_{1};\\rho_{1,1}(r_{1}\\times r_{2})=\\rho_{1}(r_{1})\\otimes\\rho_{1}(r_{2})\\in\\mathbb{R}^{9\\times9}$ is the Kronecker product of the rotation matrices of $r_{1}$ and $r_{2}$ . ", "page_idx": 2}, {"type": "text", "text": "Given two representations $\\rho:G\\to G L(V)$ and $\\tau:G\\to G L(W)$ , a map $\\Phi:V\\rightarrow W$ satisfying $\\Phi(\\rho(g)x)=\\bar{\\tau}(g)\\Phi(x)$ for all $g\\in G$ and $x\\in V$ is called $G$ -equivariant. When $\\Phi$ is parametrized by a neural network, we call $\\Phi$ an equivariant neural network, and we call the feature extracted by $\\Phi$ equivariant feature. Specifically, a degree- $p$ equivariant feature transforms according to $\\rho_{p}$ under the action of $S O(3)$ , and a degree- $(p,q)$ equivariant feature transforms according to $\\rho_{p}\\otimes\\rho_{q}$ under the action of $S O(3)\\times S O(3)$ . For simpler notations, we omit the representation homomorphism $\\rho,i.e.$ , we write $r$ instead of $\\rho(r)$ , when $\\rho$ is clear from the text. ", "page_idx": 2}, {"type": "text", "text": "3.2 Arun\u2019s method ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "Consider a PC assembly problem with known one-to-one correspondence: Let $Y=\\{y_{u}\\}_{u=1}^{N}\\subseteq\\mathbb{R}^{3}$ and $\\boldsymbol{X}=\\{x_{u}\\}_{u=1}^{N}\\subseteq\\dot{\\mathbb{R}}^{\\dot{3}}$ be a pair of PCs consisting of $N$ points, and let $\\{(x_{u},y_{u})\\}_{u=1}^{N}$ be their corresponding point pairs. What is the optimal rigid transformation that aligns $X$ to $Y?$ ", "page_idx": 2}, {"type": "text", "text": "[2] provided a closed-form solution to this problem. It claims that the optimal solution $g=(r,t)\\in$ $S E(3)$ in terms of mean square errors is ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\boldsymbol{r}=S V D(\\bar{\\boldsymbol{r}})\\quad\\mathrm{and}\\quad\\boldsymbol{t}=\\boldsymbol{m}(Y)-r\\boldsymbol{m}(X)\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "where ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\bar{r}=\\sum_{i}\\bar{y_{i}}\\bar{x_{i}}^{T}\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "is the correlation matrix, $m(\\cdot)$ represents the mean value, $\\bar{x_{i}}=x_{i}-m(X)$ and $\\bar{y_{i}}=y_{i}-m(Y)$ represent the centralized points, and $S V D(\\cdot)$ represents the singular value decomposition projection. The definition of SVD projection can be found in Def. C.5. ", "page_idx": 3}, {"type": "text", "text": "Arun\u2019s solution enjoys rich equivariance properties. Formally, we have the following proposition: ", "page_idx": 3}, {"type": "text", "text": "Definition 3.1. Consider a map $\\Phi:\\mathbb{S}\\times\\mathbb{S}\\rightarrow S E(3)$ where $\\mathbb{S}$ is the set of 3D PCs. Given $X,Y\\in\\mathbb{S}$ , let $g=\\Phi(X,Y)$ . ", "page_idx": 3}, {"type": "text", "text": "- $\\Phi$ is $S E(3)$ -bi-equivariant if $\\Phi(g_{1}X,g_{2}Y)=g_{2}g g_{1}^{-1}$ , \u2200g1, g2 \u2208SE(3).   \n- $\\Phi$ is swap-equivariant if $\\Phi(Y,X)=g^{-1}$ .   \n- $\\Phi$ is scale-equivariant if $\\Phi(c X,c Y)=(r,c t)$ , $\\forall c\\in\\mathbb{R}_{+}$ . ", "page_idx": 3}, {"type": "text", "text": "Proposition 3.2. Under a mild assumption $(C.2)$ , Arun\u2019s algorithm $(I)$ is $S E(3)$ -bi-equivariant, swap-equivariant and scale-equivariant. ", "page_idx": 3}, {"type": "text", "text": "In other words, Arun\u2019s method guarantees to perform consistently 1) with arbitrary rigid perturbations on $X$ and $Y$ , i.e., it is global, 2) if $X$ and $Y$ are swapped (aligning $Y$ to the fixed $X$ or aligning $X$ to the fixed $Y$ ), and 3) in arbitrary scale. Details of Prop. 3.2 can be found at Appx. C.1. ", "page_idx": 3}, {"type": "text", "text": "We regard Arun\u2019s method as a prototype of $S E(3)$ -bi-equivariant PC assembly methods: it first extracts a degree- $(1,1)\\:S O(3)\\times S O(3)$ -equivariant translation-invariant feature, $i.e.$ ., the correlation matrix $\\bar{r}$ (2), and then obtains an output $g\\in S E(3)$ using a $S V D$ -based projection. This observation immediately leads to more general $S E(3)$ -bi-equivariant methods where the handcrafted feature $\\bar{r}$ is replaced by the more expressive learned equivariant features, thus, the correspondence is no longer necessary. We will develop this idea in the proposed BITR in the next section, and further show that the scale and swap equivariance of Arun\u2019s method can also be inherited. ", "page_idx": 3}, {"type": "text", "text": "4 $S E(3)$ -bi-equivariant transformer ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "This section presents the details of the proposed BITR. BITR follows the same principle as Arun\u2019s method [2]: it first extracts $S O(3)\\times S O(3)$ -equivariant features as a generalization of the correlation matrix $\\bar{r}$ (2), and then projects the features to $S E(3)$ similarly to (1). Specifically, we first propose a $S E(3)\\times S E(3)$ -transformer for feature extraction in Sec. 4.2. Since this transformer is defined on 6-D space, i.e., it does not directly handle the given 3-D PCs, it relies on a pre-processing step described in Sec. 4.3, where the input 3-D PCs are merged into a 6-D PC. Finally, the Arun-type $S E(3)$ -projection is presented in Sec. 4.4. An overview of BITR is presented in Fig. 2. ", "page_idx": 3}, {"type": "text", "text": "4.1 Problem formulation ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "Let $Y=\\{y_{v}\\}_{v=1}^{N}\\subseteq\\mathbb{R}^{3}$ and $X=\\{x_{u}\\}_{u=1}^{M}\\subseteq\\mathbb{R}^{3}$ be the PCs sampled from the reference and source shape respectively. The goal of assembly is to find a rigid transformation $g\\in S E(3)$ , so that the transformed PC $\\bar{g}X=\\{\\bar{r}x_{i}+t\\}_{i=1}^{M}$ is aligned to $Y$ . Note that we do not assume that $X$ and $Y$ are overlapped, i.e., we do not assume the existence of corresponding point pairs. ", "page_idx": 3}, {"type": "text", "text": "4.2 $S E(3)\\times S E(3)$ -transformer ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "To learn $S O(3)\\times S O(3)$ -equivariant translation-invariant features generalizing $\\bar{r}$ (1), this subsection proposes a $S E(3)\\times S E(3)$ -transformer as a generalization of $S E(3)$ -transformer [11]. We present a brief introduction to $S E(3)$ -transformer [11] in Appx. A for completeness. ", "page_idx": 3}, {"type": "text", "text": "According to the theories developed in [5], to define a $S E(3)\\times S E(3)$ -equivariant transformer, we first need to define the feature map of a transformer layer as a tensor field, and specify the action of $S E(3)\\times S E(3)$ on the field. Since $S E(3)\\times S E(3)$ can be decomposed as $(T(3)\\times T(3))\\rtimes$ $(S O(3)\\times S O(3))$ where $T(3)$ is the 3-D translation group, the tensor field should be defined in the 6-D Euclidean space $\\mathbb{R}^{6}\\cong T(3)\\times T(3)$ , and the features attached to each location should be $S O(3)\\times S O(3)$ -equivariant and $T(3)\\times T(3)$ -invariant. Formally, we define the tensor field as ", "page_idx": 3}, {"type": "text", "text": "", "page_idx": 4}, {"type": "equation", "text": "$$\nf(z)=\\sum_{u=1}^{L}f_{u}\\delta(z-z_{u})\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "where $Z=\\{z_{u}\\}_{u=1}^{L}\\subseteq\\mathbb{R}^{6}$ is a 6-D PC, $\\delta$ is the Dirac delta function, $f_{u}=\\oplus_{p,q}f_{u}^{p,q}$ is the feature attached to $z_{u}$ , where $f_{u}^{p,q}$ is the degree- $(p,q)$ equivariant component. We then specify the action of $S E(3)\\times S E(3)$ on the base space $\\mathbf{\\bar{\\mathbb{R}}}^{6}$ as ", "page_idx": 4}, {"type": "equation", "text": "$$\n(g_{1}\\times g_{2})(z)=(g_{1}z^{1})\\oplus(g_{2}z^{2})\\quad\\forall z\\in\\mathbb{R}^{6}\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "where $z=z^{1}\\oplus z^{2},z^{1},z^{2}\\in\\mathbb{R}^{3}$ are the first and last three components of $z,\\oplus$ represents direct sum (concatenate), and $g_{i}=(r_{i},t_{i})\\in S E(3)$ for $i=1,2$ . Thus, the action of $S E(3)\\times S E(3)$ on the degree- $(p,q)$ component of $f$ is ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\big((g_{1}\\times g_{2})f^{p,q}\\big)(z)=\\big(\\rho_{p,q}(r_{1}\\times r_{2})\\big)f^{p,q}\\left((g_{1}\\times g_{2})^{-1}(z)\\right).\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "With the above preparations, we can now define a $S E(3)\\times S E(3)$ -transformer layer in a message passing formulation similar to $S E(3)$ -transformer: ", "page_idx": 4}, {"type": "equation", "text": "$$\nf_{\\mathrm{out}}^{o}(z_{u})=\\underbrace{W^{o}F_{\\mathrm{in}}^{o}(z_{u})}_{\\mathrm{self-interaction}}+\\sum_{\\substack{v\\in K N N(u)\\setminus\\{u\\}}}\\underbrace{\\alpha_{u v}}_{\\mathrm{attention}}\\underbrace{\\mathbf{V}_{u v}^{o,i}}_{\\mathrm{message}}.\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "Here, we use notations $\\pmb{o}=(o_{1},o_{2})$ and $\\pmb{i}=(i_{1},i_{2})$ for simplicity. For example, $f^{o}$ represents the degree- $\\textbf{\\em o}$ feature $f^{o_{1},o_{2}}$ . $F^{o}(z_{u})\\in\\mathbb{R}^{c\\times(2o_{1}+1)(2o_{2}+1)}$ is the collection of all degree- $\\mathbf{\\nabla}^{o}$ features at $z_{u}$ where $c$ is the number of channels of the degree- $^o$ features, and $W^{o}\\in\\mathbb{R}^{1\\times c}$ is a learnable parameter for self-interaction. $K N N(\\cdot)$ represents the $k$ nearest neighborhood, and attention $\\alpha_{u v}$ is computed according to ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\alpha_{u v}=\\frac{\\exp\\left(\\mathbf{Q}_{u}^{\\top}\\mathbf{K}_{u v}\\right)}{\\sum_{v^{\\prime}\\in K N N(u)\\setminus\\{u\\}}\\exp\\left(\\mathbf{Q}_{u}^{\\top}\\mathbf{K}_{u v^{\\prime}}\\right)},\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "where $\\mathbf{Q},\\mathbf{K}$ and $\\mathbf{V}$ are known as the query, key and value respectively. They are defined as ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\mathbf{Q}_{u}=\\bigoplus_{o}W_{Q}^{o}F_{\\mathrm{in}}^{o}(z_{u}),\\mathbf{K}_{u v}=\\bigoplus_{o}\\sum_{i}{\\mathcal{W}_{K}^{o,i}\\left(z_{v u}\\right)f_{\\mathrm{in}}^{i}(z_{v})},\\mathbf{V}_{u v}^{o,i}=\\mathcal{W}_{V}^{o,i}\\left(z_{v u}\\right)f_{\\mathrm{in}}^{i}(z_{v})\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "where $z_{v u}=z_{v}-z_{u},$ $W_{Q}^{i}$ is a learnable parameter for $\\mathbf{Q}$ , and the convolutional kernel $\\mathscr{W}^{o,i}(z)$ in $\\mathbf{V}$ and $\\mathbf{K}$ both take the form of ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\nu e c(\\mathcal{W}^{o,i}(z))=\\sum_{J_{1}=|\\omega_{1}-i_{1}|}^{o_{1}+i_{1}}\\sum_{J_{2}=|\\sigma_{2}-i_{2}|}^{o_{2}+i_{2}}\\Big(\\underbrace{\\varphi_{J_{1},J_{2}}^{o,i}(\\lVert z^{1}\\rVert,\\lVert z^{2}\\rVert)}_{\\mathrm{radial~component}}\\underbrace{Q_{J_{1},J_{2}}^{o,i}Y_{J_{1}}(\\frac{z^{1}}{\\lVert z^{1}\\rVert})\\otimes Y_{J_{2}}(\\frac{z^{2}}{\\lVert z^{2}\\rVert})}_{\\mathrm{angular~component}}\\Big),\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "where the learnable radial component $\\varphi_{J_{1},J_{2}}^{o,i}:\\mathbb{R}\\times\\mathbb{R}\\rightarrow\\mathbb{R}$ is parametrized by a neural network, the non-learnable angular component is determined by the 2-nd order Clebsch-Gordan constant $\\mathcal{Q}$ and the spherical harmonics $Y_{J}\\sp{\\,^{\\bullet}\\!}:\\mathbb{R}^{3}\\rightarrow\\mathbb{R}^{2J+1}$ , and $\\nu e c(\\cdot)$ is the vectorize function reshaping a matrix to a vector. Formulation (8) is derived in Appx. B. ", "page_idx": 4}, {"type": "text", "text": "Note that the kernel (8) is the main difference between a $S E(3)$ -transformer layer and a $S E(3)\\times$ $S E(3)$ -transformer layer. In the special case where only $S E(3)$ -equivariance is considered, i.e., all features are of degree $(p,0)$ (or $(0,q))$ ), a $S E(3)\\times S E(3)$ -transformer layer becomes a $S E(3)$ - transformer layer. ", "page_idx": 4}, {"type": "text", "text": "Finally, we adopt the equivariant Relu (Elu) layer similar to [9] as the point-wise non-linear layer in our network. Given an input degree- $_\\textit{\\textbf{i}}$ feature ${\\dot{F}}^{i}$ with $c$ channels, an Elu layer is defined as ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\begin{array}{r}{E l u(F^{i})=\\left\\{F_{\\mu}\\ l_{\\nu}^{i}\\ l_{\\nu}^{i}\\ }&{\\langle F_{\\mu},F_{\\nu}\\rangle\\geqslant0}\\\\ {F_{\\mu}-\\langle F_{\\mu},\\frac{F_{\\nu}}{\\|F_{\\nu}\\|}\\rangle\\frac{F_{\\nu}}{\\|F_{\\nu}\\|}}&{\\mathrm{~otherwise},}\\end{array}\\right.}\\end{array}\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "where $F_{\\mu}\\,=\\,W_{\\mu}^{i}F^{i}$ and $F_{\\nu}\\,=\\,W_{\\nu}^{i}F^{i}$ . $W_{\\mu},W_{\\nu}\\,\\in\\,\\mathbb{R}^{c\\times c}$ are learnable weights and $\\|\\cdot\\|$ is the channel-wise vector norm. Note that when $\\pmb{i}=(1,0)$ or $\\pmb{i}=(0,1)$ , our definition (9) becomes the same as [9]. By interleaving transformer layers and Elu layers, we can finally build a complete $S E(3)\\times S E(3)$ -equivariant transformer model. ", "page_idx": 4}, {"type": "text", "text": "4.3 Point cloud merge ", "text_level": 1, "page_idx": 5}, {"type": "text", "text": "To utilize the transformer model defined in Sec. 4.2, we need to construct a 6-D PC as its input. To this end, we first extract key points from the raw 3-D PCs, and then concatenate them to a 6-D PC to merge their information. Thus, the resulting 6-D PC is not only small in size but also contains the key information of the raw PCs pairs. ", "page_idx": 5}, {"type": "text", "text": "Formally, we extract $L$ ordered key points $\\tilde{X}~=~\\{\\tilde{x}_{u}\\}_{u=1}^{L}$ and $\\tilde{Y}~=~\\{\\tilde{y}_{u}\\}_{u=1}^{L}$ from $X$ and $Y$ respectively, and then obtain $Z=\\{\\tilde{x}_{u}\\oplus\\tilde{y}_{u}\\}_{u=1}^{L}$ . Note that we do not require $\\tilde{X}\\left(\\tilde{Y}\\right)$ to be a subset of $X$ $(Y)$ . Specifically, we represent the coordinates of the key points as a convex combination of the raw PCs: ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\tilde{X}=S o f t M a x(F_{X}^{0})X,\\quad\\tilde{Y}=S o f t M a x(F_{Y}^{0})Y,\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "where $X\\in\\mathbb{R}^{M\\times3}$ and $\\boldsymbol{Y}\\in\\mathbb{R}^{N\\times3}$ represent the coordinates of $X$ and $Y$ respectively, and $S o f t M a x(\\cdot)$ represents the row-wise softmax. $F_{X}^{\\hat{0}}\\in\\mathbb{R}^{L\\times M}$ and $F_{Y}^{0}\\in\\mathbb{R}^{L\\times N}$ are the weights of each point in $X$ and $Y$ respectively, and they are degree-0, i.e., rotation-invariant, features computed by a shared $S E(3)$ -transformer $\\Phi_{E}$ : ", "page_idx": 5}, {"type": "equation", "text": "$$\nF_{X}^{0}=\\Phi_{E}(X),\\quad F_{Y}^{0}=\\Phi_{E}(Y).\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "Furthermore, inspired by [39], we fuse the features of $X$ and $Y$ in $\\Phi_{E}$ before the last layer, so that their information is merged more effectively, i.e., the selection of $\\tilde{X}$ or $\\tilde{Y}$ depends on both $X$ and $Y$ . Specifically, the fused features are ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\left\\{f_{\\mathrm{out},X}(x_{u})=f_{\\mathrm{in},X}^{0}(x_{u})\\oplus P o o l_{v}\\left(f_{\\mathrm{in},Y}^{0}(y_{v})\\right)\\oplus f_{\\mathrm{in},X}^{1}(x_{u})\\right.}\\\\ {\\left.f_{\\mathrm{out},Y}(y_{v})=f_{\\mathrm{in},Y}^{0}(y_{v})\\oplus P o o l_{u}\\left(f_{\\mathrm{in},X}^{0}(x_{u})\\right)\\oplus f_{\\mathrm{in},Y}^{1}(y_{v}),}\\end{array}\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "where we only consider degree-0 and degree-1 features. $f_{\\cdot,X}$ and $f_{\\cdot,Y}$ represent the features of $X$ and $Y$ , and Pool is the average pooling over the PC. ", "page_idx": 5}, {"type": "text", "text": "Note that $\\tilde{X}$ and $\\tilde{Y}$ obtained in Eqn. 10 are permutation invariant. For example, according to Eqn. 10, the $i$ -th key point of $X$ is $\\begin{array}{r}{\\tilde{x}_{i}\\,=\\,\\sum_{j}\\bar{\\mathcal{F}}_{i j}X_{j}}\\end{array}$ , where ${\\mathcal{F}}_{i j}$ is the $i$ -th channel of $F_{X}^{0}$ at $x_{j}$ (after softmax normalization). When $X$ is permutated by $\\sigma$ , then the $i$ -th key point can be written as $\\begin{array}{r}{\\tilde{x}_{i}^{\\prime}=\\sum_{j^{\\prime}}\\mathcal{F}_{i j^{\\prime}}X_{j^{\\prime}}}\\end{array}$ , where $j^{\\prime}=\\sigma(j)$ . It is easy to see that $\\tilde{x}_{i}^{\\prime}=\\tilde{x}_{i}$ because both $j$ and $j^{\\prime}$ iterate through $\\{1,...,M\\}$ in the summation. ", "page_idx": 5}, {"type": "text", "text": "4.4 SE(3)-projection ", "text_level": 1, "page_idx": 5}, {"type": "text", "text": "We now obtain the final output by projecting the feature extracted by the $S E(3)\\times S E(3)$ -transformer to $S E(3)$ . Formally, let $f$ be the output tensor field of the $S E(3)\\times S E(3)$ -transformer. We compute the final output $g=(r,t)\\in S E(3)$ using an Arun-type projection as follows: ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\left\\{\\begin{array}{l l}{\\displaystyle r=S V D(\\hat{r})}\\\\ {\\displaystyle t=(\\pmb{m}(\\tilde{Y})+t_{Y})-r(\\pmb{m}(\\tilde{X})+t_{X}),}\\end{array}\\right.\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "where $\\hat{r}=u n v e c(\\tilde{r})\\in\\mathbb{R}^{3\\times3}$ , $t_{X}\\in\\mathbb{R}^{3}$ and $t_{Y}\\in\\mathbb{R}^{3}$ are equivariant features computed as ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\tilde{r}=P o o l_{u}(f_{u}^{1,1}),\\;t_{X}=P o o l_{u}(f_{u}^{1,0}),\\;t_{Y}=P o o l_{u}(f_{u}^{0,1}).\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "We note that projection (13) extends Arun\u2019s projection (1) in two aspects. First, although $\\hat{r}$ in (13) and $\\bar{r}$ (2) are both degree- $(1,1)$ features, $\\hat{r}$ is more flexible than $\\bar{r}$ because $\\hat{r}$ is a learned feature while $\\bar{r}$ is handcrafted, and $\\hat{r}$ is correspondence-free while $\\bar{r}$ is correspondence-based. Second, projection (13) explicitly considers non-zero offsets $t_{X}$ and $t_{Y}$ , which allow solutions where the centers of PCs do not match. ", "page_idx": 5}, {"type": "text", "text": "In summary, BITR computes the output $g$ for PCs $X$ and $Y$ according to ", "page_idx": 5}, {"type": "equation", "text": "$$\ng=\\Phi_{P}\\circ\\Phi_{S}(X,Y),\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "where $\\Phi_{S}:\\mathbb{S}\\times\\mathbb{S}\\to\\mathbb{F}$ is a $S E(3)\\times S E(3)$ -transformer (with the PC merge step), $\\Phi_{P}:\\mathbb{F}\\rightarrow S E(3)$ represents projection (13), and $\\mathbb{F}$ is the set of tensor field. We finish this section with a proposition that BITR is indeed $S E(3)$ -bi-equivariant. ", "page_idx": 5}, {"type": "text", "text": "Proposition 4.1. Under a mild assumption (C.2), BITR $(I4)$ is $S E(3)$ -bi-equivariant. ", "page_idx": 5}, {"type": "text", "text": "5 Swap-equivariance and scale-equivariance ", "text_level": 1, "page_idx": 6}, {"type": "text", "text": "This section seeks to incorporate swap and scale equivariances into the proposed BITR model. These two equivariances are discussed in Sec. 5.1 and Sec. 5.2 respectively. ", "page_idx": 6}, {"type": "text", "text": "5.1 Incorporating swap-equivariance ", "text_level": 1, "page_idx": 6}, {"type": "text", "text": "This subsection seeks to incorporate swap-equivariance to BITR, i.e., to ensure that swapping $X$ and $Y$ has the correct influence on the output. To this end, we need to treat the group of swap as $\\mathbb{Z}/2\\mathbb{Z}=\\{1,s\\}$ where $s^{2}=1$ , i.e., $s$ represents the swap of $X$ and $Y$ , and properly define the action of $\\mathbb{Z}/2\\mathbb{Z}$ on the learned features. ", "page_idx": 6}, {"type": "text", "text": "Formally, we define the action of $\\mathbb{Z}/2\\mathbb{Z}$ on field $f\\left(3\\right)$ as follows. We first define the action of $s$ on the base space $\\mathbb{R}^{6}$ as swapping the coordinates of $\\tilde{X}$ and $\\tilde{Y}$ : $s(z)=z^{2}\\oplus z^{1}$ , where $z=z^{1}\\oplus z^{2}$ , and $z^{1},z^{2}\\in\\mathbb{R}^{3}$ are the coordinates of $\\tilde{X}$ and $\\tilde{Y}$ respectively. Then we define the action of $s$ on feature $f$ as $\\left(s(f)\\right)^{p,q}(z)=\\left(f^{q,p}\\left(s(z)\\right)\\right)^{T}$ , where we regard a degree- $(p,q)$ feature $f_{u}^{p,q}$ as a matrix of shape R(2p+1)\u00d7(2q+1) by abuse of notation, and (\u00b7)T represents matrix transpose. ", "page_idx": 6}, {"type": "text", "text": "Intuitively, according to the above definition, degree- $(1,1)$ , $(1,0)$ and $(0,1)$ features will become (the transpose of) degree- $(1,1)$ , $(0,1)$ and $(1,0)$ features respectively under the action of $s$ , i.e., $\\hat{r}$ will be transposed, $t_{X}$ and $t_{Y}$ will be swapped. This is exactly the transformation needed to ensure swap-equivariant outputs. We formally state this observation in the following proposition. ", "page_idx": 6}, {"type": "text", "text": "Proposition 5.1. For a tensor field $f$ and a projection $\\Phi_{P}$ $>(l3),\\,\\Phi_{P}\\left(s(f)\\right)=(\\Phi_{P}(f))^{-1}.$ ", "page_idx": 6}, {"type": "text", "text": "Now the remaining problem is how to make a $S E(3)\\times S E(3)$ -transformer $\\mathbb{Z}/2\\mathbb{Z}$ -equivariant. A natural solution is to force all layers in the $S E(3)\\times\\bar{S}E(3)$ -transformer to be $\\mathbb{Z}/2\\mathbb{Z}$ -equivariant. The following proposition provides a concrete way to achieve this. ", "page_idx": 6}, {"type": "text", "text": "Proposition 5.2. Let \u02dc\u00b7 represent the swap of index, e.g., i ${{\\mathbf{\\nabla}}^{\\prime}}\\mathbf{o}=\\left(o_{1},o_{2}\\right)$ , then $\\tilde{\\pmb{o}}=\\left(o_{2},o_{1}\\right)$ . 1) For a transformer layer (5), if the self-interaction weight satisfies ${\\cal W}^{o}={\\cal W}^{\\tilde{o}}$ , the weight of query (7) satisfies $W_{Q}^{o}=W_{Q}^{\\tilde{o}},$ , and the radial function satisfies $\\varphi_{J_{1},J_{2}}^{i,o}(\\|z^{1}\\|,\\|z^{2}\\|)=\\varphi_{J_{2},J_{1}}^{\\tilde{i},\\tilde{o}}(\\|z^{2}\\|,\\|z^{1}\\|)$ for all , o, $J_{1}$ , $J_{2}$ , $z^{1}$ and , then the transformer layer is $\\mathbb{Z}/2\\mathbb{Z}$ -equivariant. ", "page_idx": 6}, {"type": "text", "text": "2) For an Elu layer (9), if $W_{\\nu}^{i}=W_{\\nu}^{\\tilde{i}}$ and $W_{\\mu}^{i}=W_{\\mu}^{\\tilde{i}}$ for all $\\pmb{i}$ , then the Elu layer is $\\mathbb{Z}/2\\mathbb{Z}$ -equivariant. ", "page_idx": 6}, {"type": "text", "text": "More details, including the complete matching property (Prop. C.11), can be found in Appx. C.3.1. ", "page_idx": 6}, {"type": "text", "text": "5.2 Incorporating scale-equivariance ", "text_level": 1, "page_idx": 6}, {"type": "text", "text": "This subsection seeks to incorporate scale equivariance to BITR, i.e., to ensure that when $X$ and $Y$ are multiplied by a scale constant $c\\in\\mathbb{R}_{+}$ , the output result transforms correctly. To this end, we need to consider the scale group $(\\mathbb{R}_{+},\\times)$ , i.e., the multiplicative group of $\\mathbb{R}_{+}$ , and properly define the $(\\mathbb{R}_{+},\\times)$ -equivariance of the learned feature. For simplicity, we abbreviate group $(\\mathbb{R}_{+},\\times)$ as $\\mathbb{R}_{+}$ . ", "page_idx": 6}, {"type": "text", "text": "We now consider the action of $\\mathbb{R}_{+}$ on field $f$ (3). We call $f$ a degree-p $\\mathbb{R}_{+}$ -equivariant field $(p\\in\\mathbb{N})$ if it transforms as $\\left(c(f)\\right)(z)\\,=\\,c^{p}f(c^{-1}z)$ under the action of $\\mathbb{R}_{+}$ , where $z\\,\\in\\,\\mathbb{R}^{6}$ and $c\\in\\mathbb{R}_{+}$ . We immediately observe that degree-1 $\\mathbb{R}_{+}$ -equivariant features lead to scale-equivariant output. Intuitively, if $\\tilde{r}$ , $t_{X}$ and $t_{Y}$ are degree-1 $\\mathbb{R}_{+}$ -equivariant features, then they will become $c\\tilde{r}$ , $c t_{X}$ and $c t_{Y}$ under the action of $c$ , and the projection step will cancel the scale of $\\tilde{r}$ while keeping the scale of $t_{X}$ and $t_{Y}$ , which is exactly the desirable results. Formally, we have the following proposition. ", "page_idx": 6}, {"type": "text", "text": "Proposition 5.3. Let $\\Phi_{P}$ be projection (13), $f$ be a degree-1 $\\mathbb{R}_{+}$ -equivariant tensor field, and $(r,t)=\\Phi_{P}(f)$ . We have $\\Phi_{P}\\left(c(f)\\right)=(r,c t)\\quad\\forall c\\in\\mathbb{R}_{+}$ . ", "page_idx": 6}, {"type": "text", "text": "The remaining problem is how to ensure that a $S E(3)\\times S E(3)$ -transformer is $\\mathbb{R}_{+}$ -equivariant and its output is of degree-1, so that scaling the input can lead to the proper scaling of output. Here we provide a solution based on the following proposition. ", "page_idx": 6}, {"type": "text", "text": "Definition 5.4. $\\varphi:\\mathbb{R}\\times\\mathbb{R}\\to\\mathbb{R}$ is a degree- $\\boldsymbol{p}$ function if $\\varphi(c x,c y)=c^{p}\\varphi(x,y)$ for all $c\\in\\mathbb{R}_{+}$ . ", "page_idx": 6}, {"type": "text", "text": "Proposition 5.5. 1) Denote $\\varphi_{K}$ and $\\varphi_{V}$ the radial functions used in $\\mathbf{K}$ and $\\mathbf{V}$ respectively. Let $\\varphi_{K}$ be a degree-0 function, $f_{i n}$ be a degree-0 $\\mathbb{R}_{+}$ -equivariant input field. For transformer layer (5), $i f\\varphi_{V}$ is a degree-1 function and the self-interaction weight $W=0$ , then the output field $f_{o u t}$ is degree-1 $\\mathbb{R}_{+}$ -equivariant; If \u03d5V is a degree-0 function, then the output field $f_{o u t}$ is degree-0 $\\mathbb{R}_{+}$ -equivariant. ", "page_idx": 6}, {"type": "text", "text": "", "page_idx": 7}, {"type": "text", "text": "2) For Elu layer (9), if the input field is degree-p $\\mathbb{R}_{+}$ -equivariant, then the output field is also degree- $p$ $\\mathbb{R}_{+}$ -equivariant. ", "page_idx": 7}, {"type": "text", "text": "More discussions can be found in Appx. C.4. ", "page_idx": 7}, {"type": "text", "text": "6 Experiments and analysis ", "text_level": 1, "page_idx": 7}, {"type": "text", "text": "This section experimentally evaluates the proposed BITR. After describing the experiment settings in Sec. 6.1, we first present a simple example in Sec. 6.2 to highlight the equivariance of BITR. Then we evaluate BITR on assembling the shapes in ShapeNet [6], BB dataset [31], 7Scenes [32] and ASL [22] from Sec. 6.3.1 to Sec. 6.4. We finally apply BITR to visual manipulation tasks in Sec. 6.6. ", "page_idx": 7}, {"type": "text", "text": "6.1 Experiment settings ", "text_level": 1, "page_idx": 7}, {"type": "text", "text": "We extract $L\\,=\\,32$ key points for each PC. The $S E(3)$ -transformer and the $S E(3)\\,\\times\\,S E(3)$ - transformer both contain 2 layers with $c=4$ channels. We consider $k=24$ nearest neighborhoods for message passing. We only consider low degree equivariant features, i.e., $p,q\\,\\in\\,\\{0,1\\}$ for efficiency. We train BITR using Adam optimizer [15] with learning rate $1e^{-4}$ . We use the loss function $L=\\|r^{T}r_{g t}-I\\|_{2}^{2}+\\|\\breve{t}_{g t}-t\\|_{2}^{2}$ , where $(r,t)$ are the output transformation, $(r_{g t},t_{g t})$ are the corresponding ground truth. We evaluate all methods by isotropic rotation and translation errors: $\\Delta r=(18\\dot{0}/\\pi)a\\dot{c}\\dot{c}o s\\left(1/2\\left(t r(r r_{g t}^{T})-1\\right)\\right)$ , and $\\Delta t=\\|t_{g t}-t\\|$ where $t r(\\cdot)$ is the trace of a matrix. We do not use random rotation and translation augmentations as [23]. More details are in Appx. D.1. ", "page_idx": 7}, {"type": "text", "text": "6.2 A proof-of-concept example ", "text_level": 1, "page_idx": 7}, {"type": "text", "text": "To demonstrate the equivariance property of BITR, we train BITR on the bunny shape [33]. We prepare the dataset similar to [41]: In each training iteration, we first construct the raw PC $S$ by uniformly sampling 2048 points from the bunny shape and adding 200 random outliers from $[-1,1]^{\\frac{5}{3}}$ , then we obtain PCs $\\{X_{P},\\bar{Y}_{P}\\}$ by dividing $S$ into two parts of ratio $(30\\%,70\\%)$ using a random plane $P$ . We train BITR to reconstruct $S$ using randomly rotated and translated $\\{X_{P},Y_{P}\\}$ . To construct the test set, we generate a new sample $\\bar{\\{}X_{\\Tilde{P}},Y_{\\Tilde{P}}\\}$ , and additionally construct 3 test samples by 1) swapping, 2) scaling (factor 2) and 3) randomly rigidly perturbing $\\{X_{\\tilde{P}},Y_{\\tilde{P}}\\}$ . ", "page_idx": 7}, {"type": "text", "text": "The assembly results of BITR on these four test samples are shown in Fig. 3. We observe that BITR performs equally well in all cases. Specifically, the differences between the rotation errors in these four cases are small (less than $1e^{-3}$ ). The results suggest that BITR is indeed robust against these three perturbations, which verifies its swap-equivariance, scale-equivariance and $S E(3)$ -biequivariance. More experiments can be found in the appendix: a numerical verification of Def. 3.1 is presented in Appx. D.2, an ablation study of swap and scale equivariances are presented in Appx. D.3, and the verification of the complete-matching property C.11 is presented in Appx. D.4. ", "page_idx": 7}, {"type": "image", "img_path": "EehS4erXWB/tmp/9b3204d04676f01efd2a8ca2181230ad391e4d67815662da4e808217c05ac110.jpg", "img_caption": [], "img_footnote": [], "page_idx": 7}, {"type": "text", "text": "Figure 3: The results of BITR on a test example (a), and the swapped (b), scaled (d) and rigidly perturbed (c) inputs. The red, yellow and blue colors represent the source, transformed source and reference PCs respectively. ", "page_idx": 7}, {"type": "text", "text": "6.3 Results on ShapeNet ", "text_level": 1, "page_idx": 8}, {"type": "text", "text": "6.3.1 Single shape assembly ", "text_level": 1, "page_idx": 8}, {"type": "text", "text": "In this experiment, we evaluate BITR on assembling PCs sampled from a single shape. When the inputs PCs are overlapped, this setting is generally known as PC registration. We construct a dataset similar to [41]: for a shape in the airplane class of ShapeNet [6], we obtain each of the input PCs by uniformly sampling 1024 points from the shape, and keep ratio $s$ of the raw PC by cropping it using a random plane. We vary $s$ from 0.7 to 0.3. Note the PCs may be non-overlapped when $s<0.5$ . ", "page_idx": 8}, {"type": "text", "text": "We compare BITR against the state-of-the-art registration methods GEO [23] and ROI [43], and the state-of-the-art fragment reassembly methods NSM [7] and LEV [38]. For NSM and LEV, we additionally provide the canonical pose for each shape. Note that LEV and ROI are $S E(3)$ -equivariant methods. For $s\\geq0.5$ , we report the results of BITR fine-tuned by ICP [45] $(\\mathrm{BITR+ICP})$ ). Note that $\\mathsf{B I T R+I C P}$ is $S E(3)$ -bi-equivariant and scale-equivariant, but not swap-equivariant. ", "page_idx": 8}, {"type": "text", "text": "We present the results in Fig. 4. We observe that the performance of all methods decrease as $s$ decreases. Meanwhile, BITR outperforms all baseline methods when $s$ is small $(s\\leq0.5)$ . On the other hand, when $s$ is large $(s>0.5)$ ), BITR performs worse than GEO, but it still outperforms other baselines. Nevertheless, since the results of BITR are sufficiently close to optimum $\\mathrm{\\Delta}\\Delta r\\leq20\\$ ), the ICP refinement can lead to improved results that are close to GEO. More details can be found in Appx. D.5. ", "page_idx": 8}, {"type": "image", "img_path": "EehS4erXWB/tmp/0da1f50cfbc4c031a388c30b434fd31e6767e0ef1a938c1ee11d10666d76a8c1.jpg", "img_caption": ["Figure 4: Assembly results on the airplane dataset. $^*$ denotes methods which require the true canonical poses of the input PCs. "], "img_footnote": [], "page_idx": 8}, {"type": "text", "text": "6.3.2 Inter-class assembly ", "text_level": 1, "page_idx": 8}, {"type": "text", "text": "To evaluate BITR on non-overlapped PCs, we extend the experiment in Sec. 6.3.1 to inter-class assembly. We train BITR to place a car shape on the right of motorbike shape, so that their directions are the same and their distance is 1. We consider $s\\,=\\,1.0$ and 0.7. Note that this task is beyond the scope of registration methods, since the input PCs are non-overlapped. A result of BITR is shown in Fig. 5. More details can be found in Appx. D.6. ", "page_idx": 8}, {"type": "image", "img_path": "EehS4erXWB/tmp/c3430042f80e50f5545959ec02aa03f5303c1fdbc00ee1efedce524e4a01c270.jpg", "img_caption": ["Figure 5: A result of BITR on assembling a motorbike and a car. "], "img_footnote": [], "page_idx": 8}, {"type": "text", "text": "6.4 Results on fragment reassembly ", "text_level": 1, "page_idx": 8}, {"type": "text", "text": "This subsection evaluates BITR on a fragment reassembly task. We compare BITR against NSM [7], LEV [38] and DGL [44] on the 2-fragment WineBottle class of the BB dataset [31]. The data preprocessing step is described in Appx. D.7. ", "page_idx": 8}, {"type": "text", "text": "We test the trained BITR 3 times using different random samples, and report the mean and standard deviation of $(\\Delta r,\\Delta t)$ in Tab. 1. We observe that BITR outperforms all baseline methods: BITR achieves the lowest rotation errors, and its translation error is comparable to DGL, which is lower than other baselines by a large margin. We provide some qualitative comparisons in Appx. D.7. ", "page_idx": 8}, {"type": "table", "img_path": "EehS4erXWB/tmp/92675c80584344de703e533ca77466e3a448b9e784b9bb867d1be9613a0670b3.jpg", "table_caption": ["Table 1: Reassembly results on 2-fragment WineBottle. We report the mean and std of the error of BITR. "], "table_footnote": [], "page_idx": 8}, {"type": "text", "text": "6.5 Results on real data ", "text_level": 1, "page_idx": 8}, {"type": "text", "text": "This subsection evaluates BITR on an indoor dataset 7Scenes [32] and the outdoor scenes in ASL dataset [22]. We present the results on 7Scenes in this section, and leave the results on ASL and some qualitative results to Appx. D.8. ", "page_idx": 8}, {"type": "text", "text": "For the 7Scenes dataset, we arbitrarily rotate and translate all frames, and train BITR to align all adjacent frames. We use the data from the first 6 scenes as the training set, and the data from 7-th scene as the test set. To train BITR, we use a random clipping augmentation similar to Sec. 6.3.1: we keep ratio $s$ of each PCs by clipping them using a random plane, where $s$ is uniformly distributed in [0.5, 1.0]. We compare BITR against GEO [23], ROI [43], ICP [45] and OMN [39], where OMN is a recently proposed correspondence-free registration method. ", "page_idx": 8}, {"type": "text", "text": "", "page_idx": 9}, {"type": "text", "text": "The results on 7Scenes are reported in Tab. 2. We observe that BITR can produce results that are close to the optimum ( $\\Delta r\\approx25)$ ) from a random initialization $(\\Delta r\\in U[0,180])$ , and extra refinements like ICP and OT can further improve the results $\\langle\\Delta r\\approx10\\rangle$ . This observation is consistent with that in Sec. 6.3.1. In particular, BITR with the OT refinement is comparable with GEO and ROI, which use highly complicated features specifically designed for registration tasks and an OT-like refinement process. On the other hand, ICP and OMN fails in this task due to their sensitiveness to initial positions. ", "page_idx": 9}, {"type": "table", "img_path": "EehS4erXWB/tmp/a04bd8158a474ee0f938c64e2879b04800a2a5bad913e8d58fbf97c8b6569dd3.jpg", "table_caption": ["Table 2: Results on 7Scenes. We report mean and std of $\\Delta r$ and $\\Delta t$ . "], "table_footnote": [], "page_idx": 9}, {"type": "text", "text": "6.6 Results on visual manipulation ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "This subsection investigates the potential of BITR in manipulation tasks. Following [26], we consider two tasks: mug-hanging and bowl-placing. For both tasks, $X$ represents an object grasped by a robotic arm, i.e., a cup or a bowl, $Y$ represents the fixed environment with a target, i.e., a stand or a plate, and we train BITR to align $X$ to $Y$ , so that the cup can be hung to the stand, or the bowl can be placed on the plate. ", "page_idx": 9}, {"type": "text", "text": "Fig. 6 presents the results of BITR on bowl-placing. We observe that although BITR is not originally designed for manipulation tasks, it can place the bowl in a reasonable position relative to the plate. However, we also notice that BITR may produce unrealistic results, e.g., the PCs may collide. Thus, post-processing steps [30] or extra regularizers [13] may be necessary in practical applications. More results and discussions can be found in Appx. D.9. ", "page_idx": 9}, {"type": "image", "img_path": "EehS4erXWB/tmp/9e0148e90640ad08137ff16478df5967bde7c85da58eceec2e142997a4f69ee0.jpg", "img_caption": ["Figure 6: The results of BITR on bowl-placing. We present the input PCs (left panel) and the assembled results (right panel). BITR can generally place the bowl (red) on the plate (green) (a), but it sometimes produces unrealistic results where collision exists (b). ", "", ""], "img_footnote": [], "page_idx": 9}, {"type": "text", "text": "7 Conclusion ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "This work proposed a PC assembly method, called BITR. The most distinguished feature of BITR is that it is correspondence-free, $S E(3)$ -bi-equivariant, scale-equivariant and swap-equivariant. We experimentally demonstrated the effectiveness of BITR. ", "page_idx": 9}, {"type": "text", "text": "BITR in its current form has two main limitations. First, BITR is computationally inefficient because each degree of feature is computed independently without parallel. This issue was also observed in SE(3)-equivariant networks, and was recently addressed by [21]. A promising future research direction is to develope similar acceleration techniques for BITR. Second, since BITR is deterministic, i.e., it only predicts one result for a given input, it cannot handle symmetric PCs. Although this feature does not cause any difficulty in this work (there is no strictly symmetric PCs in this work due to noise, random sampling, etc), it may be problematic in future applications such as molecule modelling where symmetric PCs exist, e.g., benzene rings. To address this issue, we plan to generalize BITR to a generative model in the future. More discussions can be found in Appx. E. ", "page_idx": 9}, {"type": "text", "text": "Acknowledgments ", "text_level": 1, "page_idx": 10}, {"type": "text", "text": "This work is funded by the Swedish Research Council through grant agreement no. 2019-03686 and Chalmers AI Research Initiative (CHAIR). The computations were enabled by resources provided by the National Academic Infrastructure for Supercomputing in Sweden (NAISS), partially funded by the Swedish Research Council through grant agreement no. 2022-06725. The authors would like to thank Jan Gerken at Chalmers and Nan Xue at Ant Group for useful discussions, and thank the anonymous reviewers for their insightful comments and suggestions. ", "page_idx": 10}, {"type": "text", "text": "References ", "text_level": 1, "page_idx": 10}, {"type": "text", "text": "[1] Abien Fred Agarap. Deep learning using rectified linear units (relu). arXiv preprint arXiv:1803.08375, 2018.   \n[2] K Somani Arun, Thomas S Huang, and Steven D Blostein. Least-squares fitting of two 3-d point sets. IEEE Transactions on pattern analysis and machine intelligence, (5):698\u2013700, 1987. [3] Jimmy Lei Ba, Jamie Ryan Kiros, and Geoffrey E Hinton. Layer normalization. arXiv preprint arXiv:1607.06450, 2016. [4] Paul J Besl and Neil D McKay. Method for registration of 3-d shapes. In Sensor fusion IV: control paradigms and data structures, volume 1611, pages 586\u2013606. Spie, 1992.   \n[5] Gabriele Cesa, Leon Lang, and Maurice Weiler. A program to build e (n)-equivariant steerable cnns. In International Conference on Learning Representations, 2022.   \n[6] Angel X. Chang, Thomas Funkhouser, Leonidas Guibas, Pat Hanrahan, Qixing Huang, Zimo Li, Silvio Savarese, Manolis Savva, Shuran Song, Hao Su, Jianxiong Xiao, Li Yi, and Fisher Yu. ShapeNet: An Information-Rich 3D Model Repository. Technical Report arXiv:1512.03012 [cs.GR], Stanford University \u2014 Princeton University \u2014 Toyota Technological Institute at Chicago, 2015.   \n[7] Yun-Chun Chen, Haoda Li, Dylan Turpin, Alec Jacobson, and Animesh Garg. Neural shape mating: Self-supervised object assembly with adversarial shape priors. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 12724\u201312733, 2022.   \n[8] Erwin Coumans and Yunfei Bai. Pybullet, a python module for physics simulation for games, robotics and machine learning. 2016.   \n[9] Congyue Deng, Or Litany, Yueqi Duan, Adrien Poulenard, Andrea Tagliasacchi, and Leonidas J Guibas. Vector neurons: A general framework for so (3)-equivariant networks. In Proceedings of the IEEE/CVF International Conference on Computer Vision, pages 12200\u201312209, 2021.   \n[10] Haowen Deng, Tolga Birdal, and Slobodan Ilic. Ppf-foldnet: Unsupervised learning of rotation invariant 3d local descriptors. In Proceedings of the European conference on computer vision (ECCV), pages 602\u2013618, 2018.   \n[11] Fabian Fuchs, Daniel Worrall, Volker Fischer, and Max Welling. Se(3)-transformers: 3d rototranslation equivariant attention networks. Advances in neural information processing systems, 33:1970\u20131981, 2020.   \n[12] Pablo Gainza, Sarah Wehrle, Alexandra Van Hall-Beauvais, Anthony Marchand, Andreas Scheck, Zander Harteveld, Stephen Buckley, Dongchun Ni, Shuguang Tan, Freyr Sverrisson, et al. De novo design of protein interactions with learned surface fingerprints. Nature, pages 1\u20139, 2023.   \n[13] Octavian-Eugen Ganea, Xinyuan Huang, Charlotte Bunne, Yatao Bian, Regina Barzilay, Tommi Jaakkola, and Andreas Krause. Independent se (3)-equivariant models for end-to-end rigid protein docking. arXiv preprint arXiv:2111.07786, 2021.   \n[14] Zan Gojcic, Caifa Zhou, Jan D Wegner, Leonidas J Guibas, and Tolga Birdal. Learning multiview 3d point cloud registration. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition, pages 1759\u20131769, 2020.   \n[15] Diederik P Kingma and Jimmy Ba. Adam: A method for stochastic optimization. arXiv preprint arXiv:1412.6980, 2014.   \n[16] Leon Lang and Maurice Weiler. A wigner-eckart theorem for group equivariant convolution kernels. In International Conference on Learning Representations, 2021.   \n[17] Cheng-Wei Lin, Tung-I Chen, Hsin-Ying Lee, Wen-Chin Chen, and Winston H Hsu. Coarse-tofine point cloud registration with se (3)-equivariant representations. In 2023 IEEE international conference on robotics and automation (ICRA), pages 2833\u20132840. IEEE, 2023.   \n[18] Jonathan Long, Evan Shelhamer, and Trevor Darrell. Fully convolutional networks for semantic segmentation. In Proceedings of the IEEE conference on computer vision and pattern recognition, pages 3431\u20133440, 2015.   \n[19] Benjamin Midtvedt, Jes\u00fas Pineda, Fredrik Sk\u00e4rberg, Erik Ols\u00e9n, Harshith Bachimanchi, Emelie Wes\u00e9n, Elin K Esbj\u00f6rner, Erik Selander, Fredrik H\u00f6\u00f6k, Daniel Midtvedt, et al. Single-shot self-supervised object detection in microscopy. Nature communications, 13(1):7492, 2022.   \n[20] Chuer Pan, Brian Okorn, Harry Zhang, Ben Eisner, and David Held. Tax-pose: Task-specific cross-pose estimation for robot manipulation. In Conference on Robot Learning, pages 1783\u2013 1792. PMLR, 2023.   \n[21] Saro Passaro and C Lawrence Zitnick. Reducing so (3) convolutions to so (2) for efficient equivariant gnns. In International Conference on Machine Learning, pages 27420\u201327438. PMLR, 2023.   \n[22] Fran\u00e7ois Pomerleau, Ming Liu, Francis Colas, and Roland Siegwart. Challenging data sets for point cloud registration algorithms. The International Journal of Robotics Research, 31(14):1705\u20131711, 2012.   \n[23] Zheng Qin, Hao Yu, Changjian Wang, Yulan Guo, Yuxing Peng, and Kai Xu. Geometric transformer for fast and robust point cloud registration. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition, pages 11143\u201311152, 2022.   \n[24] rusty1s. pytorchscatter. 2023.   \n[25] Radu Bogdan Rusu, Nico Blodow, and Michael Beetz. Fast point feature histograms (fpfh) for 3d registration. In 2009 IEEE international conference on robotics and automation, pages 3212\u20133217. IEEE, 2009.   \n[26] Hyunwoo Ryu, Hong in Lee, Jeong-Hoon Lee, and Jongeun Choi. Equivariant descriptor fields: Se(3)-equivariant energy-based models for end-to-end visual robotic manipulation learning. In The Eleventh International Conference on Learning Representations, 2023.   \n[27] Hyunwoo Ryu, Jiwoo Kim, Hyunseok An, Junwoo Chang, Joohwan Seo, Taehan Kim, Yubin Kim, Chaewon Hwang, Jongeun Choi, and Roberto Horowitz. Diffusion-edfs: Bi-equivariant denoising generative modeling on se (3) for visual robotic manipulation. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 18007\u201318018, 2024.   \n[28] Hyunwoo Ryu, Hong-in Lee, Jeong-Hoon Lee, and Jongeun Choi. Equivariant descriptor fields: Se (3)-equivariant energy-based models for end-to-end visual robotic manipulation learning. arXiv preprint arXiv:2206.08321, 2022.   \n[29] V\u0131ctor Garcia Satorras, Emiel Hoogeboom, and Max Welling. E (n) equivariant graph neural networks. In International conference on machine learning, pages 9323\u20139332. PMLR, 2021.   \n[30] Johannes Schauer and Andreas N\u00fcchter. Collision detection between point clouds using an efficient kd tree implementation. Advanced Engineering Informatics, 29(3):440\u2013458, 2015.   \n[31] Silvia Sell\u00e1n, Yun-Chun Chen, Ziyi Wu, Animesh Garg, and Alec Jacobson. Breaking bad: A dataset for geometric fracture and reassembly. Advances in Neural Information Processing Systems, 35:38885\u201338898, 2022.   \n[32] Jamie Shotton, Ben Glocker, Christopher Zach, Shahram Izadi, Antonio Criminisi, and Andrew Fitzgibbon. Scene coordinate regression forests for camera relocalization in rgb-d images. In Proceedings of the IEEE conference on computer vision and pattern recognition, pages 2930\u20132937, 2013.   \n[33] Standford. The stanford 3d scanning repository. [Online]. Available: http://graphics.stanford.edu/data/3Dscanrep/.   \n[34] Nathaniel Thomas, Tess Smidt, Steven Kearnes, Lusann Yang, Li Li, Kai Kohlhoff, and Patrick Riley. Tensor field networks: Rotation-and translation-equivariant neural networks for 3d point clouds. arXiv preprint arXiv:1802.08219, 2018.   \n[35] Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, \u0141ukasz Kaiser, and Illia Polosukhin. Attention is all you need. Advances in neural information processing systems, 30, 2017.   \n[36] Ariana M. Villegas-Suarez, Cristian Lopez, and Ivan Sipiran. Matchmakernet: Enabling fragment matching for cultural heritage analysis. In Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV) Workshops, pages 1632\u20131641, October 2023.   \n[37] Maurice Weiler, Mario Geiger, Max Welling, Wouter Boomsma, and Taco S Cohen. 3d steerable cnns: Learning rotationally equivariant features in volumetric data. Advances in Neural Information Processing Systems, 31, 2018.   \n[38] Ruihai Wu, Chenrui Tie, Yushi Du, Yan Zhao, and Hao Dong. Leveraging se (3) equivariance for learning 3d geometric shape assembly. In Proceedings of the IEEE/CVF International Conference on Computer Vision, pages 14311\u201314320, 2023.   \n[39] Hao Xu, Shuaicheng Liu, Guangfu Wang, Guanghui Liu, and Bing Zeng. Omnet: Learning overlapping mask for partial-to-partial point cloud registration. In Proceedings of the IEEE/CVF International Conference on Computer Vision, pages 3132\u20133141, 2021.   \n[40] Jingyun Yang, Congyue Deng, Jimmy Wu, Rika Antonova, Leonidas Guibas, and Jeannette Bohg. Equivact: Sim (3)-equivariant visuomotor policies beyond rigid object manipulation. arXiv preprint arXiv:2310.16050, 2023.   \n[41] Zi Jian Yew and Gim Hee Lee. Rpm-net: Robust point matching using learned features. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition, pages 11824\u201311833, 2020.   \n[42] Hao Yu, Ji Hou, Zheng Qin, Mahdi Saleh, Ivan Shugurov, Kai Wang, Benjamin Busam, and Slobodan Ilic. Riga: Rotation-invariant and globally-aware descriptors for point cloud registration. IEEE Transactions on Pattern Analysis and Machine Intelligence, 2024.   \n[43] Hao Yu, Zheng Qin, Ji Hou, Mahdi Saleh, Dongsheng Li, Benjamin Busam, and Slobodan Ilic. Rotation-invariant transformer for point cloud matching. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition, pages 5384\u20135393, 2023.   \n[44] Guanqi Zhan, Qingnan Fan, Kaichun Mo, Lin Shao, Baoquan Chen, Leonidas J Guibas, Hao Dong, et al. Generative 3d part assembly via dynamic graph learning. Advances in Neural Information Processing Systems, 33:6315\u20136326, 2020.   \n[45] Zhengyou Zhang. Iterative point matching for registration of free-form curves and surfaces. International Journal of Computer Vision, 13(2):119\u2013152, 1994.   \n[46] Qian-Yi Zhou, Jaesik Park, and Vladlen Koltun. Open3D: A modern library for 3D data processing. arXiv:1801.09847, 2018. ", "page_idx": 10}, {"type": "text", "text": "", "page_idx": 11}, {"type": "text", "text": "", "page_idx": 12}, {"type": "text", "text": "A SE(3)-equivariant Transformers ", "text_level": 1, "page_idx": 13}, {"type": "text", "text": "A well-known $S E(3)$ -equivariant network is $S E(3)$ -transformer [11], which adapts the powerful transformer structure [35] to $S O(3)$ -equivariant settings. In this model, the feature map $f$ of each layer is defined as a tensor field supported on a 3-D PC: ", "page_idx": 13}, {"type": "equation", "text": "$$\nf(x)=\\sum_{u=1}^{M}f_{u}\\delta(x-x_{u}),\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "where $\\delta$ is the Dirac function, $X=\\{x_{u}\\}_{u=1}^{M}\\subseteq\\mathbb{R}^{3}$ is a point set, and $f_{u}$ is the feature attached to $x_{u}$ . Here, feature $f_{u}$ takes the form of $f_{u}=\\oplus_{p}f_{u}^{p}$ , where the component $f_{u}^{p}\\in V_{p}$ is the degree- $\\cdot p$ feature, i.e., it transforms according to $\\rho_{p}$ under the action of $S O(3)$ . For example, when $f_{u}$ represents the norm vector of a point cloud, then $f_{u}\\,=\\,f_{u}^{1}\\,\\in\\,\\mathbb{R}^{3}$ . We also write the collection of all degree- $\\boldsymbol{p}$ features at $x_{u}$ as $F^{p}(x_{u})\\in\\mathbb{R}^{c\\times(2p+1)}$ , where $c$ is the number of channels. ", "page_idx": 13}, {"type": "text", "text": "For each transformer layer, the degree- $k$ output feature at point $x_{i}$ is computed by performing message passing: ", "page_idx": 13}, {"type": "equation", "text": "$$\nf_{\\mathrm{out}}^{l}(x_{u})=\\underbrace{W^{l}F_{\\mathrm{in}}^{l}(x_{u})}_{\\mathrm{self.interaction}}+\\sum_{l}\\sum_{v\\in\\mathcal{N}(u)\\setminus\\{u\\}}\\underbrace{\\alpha_{u v}}_{\\mathrm{attention}}\\underbrace{\\mathbf{V}_{u v}^{l k}}_{\\mathrm{message}},\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "where $\\mathcal{N}(u)$ represents the neighborhood of $u$ , $W^{l}\\in\\mathbb{R}^{1\\times c}$ is the learnable weight for self-interaction, $c$ represents the number of channels, and ", "page_idx": 13}, {"type": "equation", "text": "$$\n\\alpha_{u v}=\\frac{\\exp\\left(\\mathbf{Q}_{u}^{\\top}\\mathbf{K}_{u v}\\right)}{\\sum_{v^{\\prime}}\\exp\\left(\\mathbf{Q}_{u}^{\\top}\\mathbf{K}_{u v^{\\prime}}\\right)}\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "is the attention from $v$ to $u$ . Here, key $\\mathbf{K}$ , value $\\mathbf{V}$ and query $\\mathbf{Q}$ are ", "page_idx": 13}, {"type": "equation", "text": "$$\n\\mathbf{Q}_{u}=\\bigoplus_{l}W_{Q}^{l}F_{\\mathrm{in}}^{l}(x_{u}),\\;\\mathbf{K}_{u v}=\\bigoplus_{l}\\sum_{k}{W_{K}^{l k}\\left(x_{v}-x_{u}\\right)f_{\\mathrm{in}}^{k}(x_{v})},\\;\\mathbf{V}_{u v}^{l k}=\\mathcal{W}_{V}^{l k}\\left(x_{v}-x_{u}\\right)f_{\\mathrm{in}}^{k}(x_{v})\\;.\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "where $W_{Q}^{l}\\in\\mathbb{R}^{1\\times(2l+1)}$ is a learnable weight, and the kernel $\\mathcal{W}^{l k}(x)\\in\\mathbb{R}^{(2l+1)\\times(2k+1)}$ is defined as ", "page_idx": 13}, {"type": "equation", "text": "$$\n\\nu e c(\\mathcal{W}^{l k}(x))=\\sum_{J=|k-l|}^{k+l}\\underbrace{\\varphi_{J}^{l k}(\\|x\\|)}_{\\mathrm{radial\\;component}}\\underbrace{Q_{J}^{l k}Y_{J}(x/\\|x\\|)}_{\\mathrm{angular\\;component}},\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "where $\\nu e c(\\cdot)$ is the vectorize function, the learnable radial component $\\varphi_{J}^{l k}:\\mathbb{R}_{+}\\to R$ is parametrized by a neural network, and the non-learnable angular component is determined by Clebsch-Gordan constant Q and the spherical harmonic YJ : R3 \u2192R2J+1. ", "page_idx": 13}, {"type": "text", "text": "B Derive of the Convolutional Kernel ", "text_level": 1, "page_idx": 13}, {"type": "text", "text": "To derive the kernel (8) for a $S E(3)\\times S E(3)$ -transformer layer, we consider the equivariant convolution as a simplified version of the $S E(3)\\stackrel{.}{\\times}S E(3)$ -transformer layer: ", "page_idx": 13}, {"type": "equation", "text": "$$\n({\\mathcal W}*f)^{o}(z_{u}):=\\sum_{i\\atop v\\in K{\\cal N}(u)\\backslash\\{u\\}}\\mathcal W^{o,i}\\left(z_{v}-z_{u}\\right)f_{\\mathrm{in}}^{i}(z_{v}),\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "i.e., we only consider the message $\\mathbf{V}_{u v}^{o,i}$ while fixing the self-interaction weight $W^{o}=0$ and attention $\\alpha_{u v}=1$ in (5). To ensure the $S E(3)\\setminus S E(3)$ -equivariance of convolution (20), i.e., ", "page_idx": 13}, {"type": "equation", "text": "$$\n\\left((g_{1}\\times g_{2})(\\mathcal{W}^{o,i}*f)\\right)(z)=\\left(\\mathcal{W}^{o,i}*((g_{1}\\times g_{2})f)\\right)(z),\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "the kernel $\\mathcal{W}$ must satisfy a constraint: ", "page_idx": 13}, {"type": "equation", "text": "$$\n\\rho_{i}(r_{12})\\otimes\\rho_{o}(r_{12})\\mathcal{W}(z)=\\mathcal{W}\\left(r_{12}z\\right),\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "where we abbreviate $r_{1}\\times r_{2}$ as $r_{12}$ , abbreviate $\\nu e c(\\mathcal{W}^{o,i})\\in\\mathbb{R}^{(2i_{1}+1)(2i_{2}+1)(2o_{1}+1)(2o_{2}+1)}$ as $\\mathcal{W}$ , and assume $\\|z^{1}\\|=\\|z^{2}\\|=1$ for simpler notations. Equation (22) is generally known as the kernel constraint, and its necessity and sufficiency can be proved in a verbatim way as Theorem 2 in [37], ", "page_idx": 13}, {"type": "text", "text": "so we omit the proof here. Now we can obtain the kernel (8) by solving this constraint. Note that a direct formulation is given in Theorem 2.1 in [5], but here we derive it in a less abstract way. ", "page_idx": 14}, {"type": "text", "text": "We first observe that $\\begin{array}{r}{\\mathcal{W}^{*}(z)\\,=\\,_{\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\! $ is a special solution to equation (22), where $Y_{J}(\\cdot)\\in\\mathbb{R}^{2J+1}$ is the column vector consisting of degree- $J$ harmonics with order $m=-J,...0,...,J$ as each row element, because ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\quad\\rho_{i}(r_{12})\\otimes\\rho_{o}(r_{12})\\mathcal{W}^{*}(z)}\\\\ &{=\\biggr(\\rho_{i_{1}}(r_{1})\\otimes\\rho_{i_{2}}(r_{2})\\otimes\\rho_{o_{1}}(r_{1})\\otimes\\rho_{o_{2}}(r_{2})\\biggr)\\left(Y_{i_{1}}(z^{1})\\otimes Y_{i_{2}}(z^{2})\\otimes Y_{o_{1}}(z^{1})\\otimes Y_{o_{2}}(z^{2})\\right)}\\\\ &{=\\biggr(\\rho_{i_{1}}(r_{1})Y_{i_{1}}(z^{1})\\biggr)\\otimes\\bigcap\\rho_{i_{2}}(r_{2})Y_{i_{2}}(z^{2})\\biggr)\\otimes\\left(\\rho_{o_{2}}(r_{1})Y_{o_{2}}(z^{1})\\right)\\otimes\\left(\\rho_{o_{2}}(r_{2})Y_{o_{2}}(z^{2})\\right)}\\\\ &{=Y_{i_{1}}(r_{1}z^{1})\\otimes Y_{i_{2}}(r_{2}z^{2})\\otimes Y_{o_{1}}(r_{1}z^{1})\\otimes Y_{o_{2}}(r_{2}z^{2})}\\end{array}\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "Then we point out that $\\{Y_{J_{1}}^{m_{1}}(z^{1})Y_{J_{2}}^{m_{2}}(z^{2})\\}_{m_{1},m_{2},J_{2},J_{1}}$ is an orthogonal and complete basis for two variable square-integrable functions $L^{2}(X,Y):S^{2}\\times S^{2}\\to\\mathbb{R}$ , where $S^{2}$ is the 2-D sphere. Thus, we can write each component of $\\mathcal{W}^{*}(z)$ as a linear combination of this basis. Specifically, let $\\mathcal{V}(z)\\;=\\;\\oplus_{J_{1},J_{2}}Y_{J_{1}}(\\tilde{z}^{1})\\otimes Y_{J_{2}}(z^{2})$ , and let $(m_{1},m_{2},m_{3},m_{4})$ be the index of the element $Y_{i_{1}}^{m_{1}}(z^{1})Y_{i_{2}}^{m_{2}}(z^{2})Y_{o_{1}}^{m_{3}}(z^{1})Y_{o_{2}}^{m_{4}}(z^{2})$ in $\\mathcal{W}^{*}$ , and $(J_{1},m_{5},J_{2},m_{6})$ be the index of the element $Y_{J_{1}}^{m_{5}}(z^{1})Y_{J_{2}}^{m_{6}}(z^{2})$ in $\\mathcal{V}$ . We have $\\mathcal{W}^{*}=P\\mathcal{V}$ , where ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\quad P_{m_{1},m_{2},m_{3},m_{4},J_{1},m_{5},J_{2},m_{6}}}\\\\ &{=\\int Y_{i_{1}}^{m_{1}}(z^{1})Y_{i_{2}}^{m_{2}}(z^{2})Y_{o_{1}}^{m_{3}}(z^{1})Y_{o_{2}}^{m_{4}}(z^{2})Y_{J_{1}}^{m_{5}}(z^{1})Y_{J_{2}}^{m_{6}}(z^{2})d z^{2}d z^{1}}\\\\ &{=\\biggr(\\int Y_{i_{1}}^{m_{1}}(z^{1})Y_{o_{1}}^{m_{3}}(z^{1})Y_{J_{1}}^{m_{5}}(z^{1})d z^{1}\\biggr)\\biggr(\\int Y_{i_{2}}^{m_{2}}(z^{2})Y_{o_{2}}^{m_{4}}(z^{2})Y_{J_{2}}^{m_{6}}(z^{2})d z^{2}\\biggr)}\\\\ &{=\\langle i_{1},m_{1},o_{1},m_{3}\\vert J_{1},m_{5}\\rangle\\langle i_{2},m_{2},o_{2},m_{4}\\vert J_{2},m_{6}\\rangle c(J_{1})c(J_{2}).}\\end{array}\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "Here, $c(J_{1})$ and $c(J_{2})$ are coefficients related to $J_{1}$ and $J_{2}$ respectively. $\\langle i,m_{1},o,m_{3}|J,m_{5}\\rangle$ is known as the Clebsch-Gordan coefficient, the product $\\langle i_{1},m_{1},o_{1},m_{3}|J_{1},m_{5}\\rangle\\langle i_{2},m_{2},o_{2},m_{4}|J_{2},m_{6}\\rangle$ is known as the 2-nd order Clebsch-Gordan coefficient, and we represent it as $\\mathcal{Q}$ . In other words, we have $P=\\mathcal{Q}c$ , where $^c$ is a block diagonal matrix, and each block is $c(J_{1})c(J_{2})I$ . Therefore, we have ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\begin{array}{r l r}&{}&{\\Big(\\rho_{i}(r_{12})\\otimes\\rho_{o}(r_{12})\\Big)P\\mathcal{V}(z)=P\\mathcal{V}(r_{12}z)\\quad}\\\\ &{}&{\\Big(\\rho_{i}(r_{12})\\otimes\\rho_{o}(r_{12})\\Big)Q c\\mathcal{V}(z)=Q c\\mathcal{V}(r_{12}z)\\quad}\\\\ &{}&{\\mathcal{Q}^{T}\\Big(\\rho_{i}(r_{12})\\otimes\\rho_{o}(r_{12})\\Big)Q c\\mathcal{V}(z)=c\\mathcal{V}(r_{12}z).\\quad}\\end{array}\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "Since ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\Big[\\bigoplus_{J_{1},J_{2}}\\rho_{J_{1},J_{2}}(r_{12})\\Big]c\\mathcal{V}(z)=c\\mathcal{V}(r_{12}z)\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "for arbitrary $z$ , we further have ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\mathcal{Q}^{T}\\Big(\\rho_{i}(r_{12})\\otimes\\rho_{o}(r_{12})\\Big)\\mathcal{Q}=\\Big[\\bigoplus_{J_{1},J_{2}}\\rho_{J_{1},J_{2}}(r_{12})\\Big]\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "by equating the above two equations. Finally, we stack this decomposition back to the kernel constraint (22), and obtain ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\Big[\\bigoplus_{J_{1},J_{2}}\\rho_{J_{1},J_{2}}(r_{12})\\Big]\\,\\mathcal{Q}^{T}\\mathcal{W}(z)=\\mathcal{Q}^{T}\\mathcal{W}(r_{12}z),\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "which suggests that ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\begin{array}{c}{{\\pmb{\\mathscr{Q}}^{T}\\mathcal{W}(z)=\\pmb{c}^{\\prime}\\mathcal{V}(x),}}\\\\ {{\\mathcal{W}(z)=\\mathscr{Q}\\pmb{c}^{\\prime}\\mathcal{V}(x),}}\\end{array}\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "where $c^{\\prime}$ is the coefficient matrix of the same shape as $^c$ , and each coefficient is arbitrary. Specifically, ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\mathcal{W}(z)=\\pmb{c}_{J_{1},J_{2}}^{\\prime}\\sum_{J_{1},J_{2}}\\mathcal{Q}_{J_{1},J_{2}}Y_{J_{1}}(z^{1})\\otimes Y_{J_{2}}(z^{2}).\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "We note that $c_{J_{1},J_{2}}^{\\prime}$ is parametrized by a neural network in our model (8). ", "page_idx": 14}, {"type": "text", "text": "C Proofs and theoretical results ", "text_level": 1, "page_idx": 15}, {"type": "text", "text": "C.1 The proof of the equivariance of Arun\u2019s method ", "text_level": 1, "page_idx": 15}, {"type": "text", "text": "We first establish the result on the uniqueness of Arun\u2019s method. We begin with the result of the uniqueness of singular vectors. ", "page_idx": 15}, {"type": "text", "text": "Lemma C.1. Let $A=U\\Sigma V^{T}\\in\\mathbb{R}^{3\\times3}$ be the SVD decomposition. If a singular value $\\sigma_{j}$ is distinct, then the corresponding singular vectors $U_{j}$ and $V_{j}$ can be determined up to a sign. If $\\sigma_{j}\\overset{\\cdot}{\\neq}0,\\,U_{j}V_{J}^{T}$ is unique. ", "page_idx": 15}, {"type": "text", "text": "Proof. If $\\sigma_{j}\\neq0$ , we have ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\begin{array}{r}{A^{T}A=V\\Sigma^{2}V^{T}=V\\Sigma^{2}V^{-1},}\\end{array}\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "i.e., the eigenvalues of $A^{T}A$ are $\\sigma_{i}^{2}$ , $i={1,2,3}$ , and $V_{i}$ are the corresponding eigenvectors. Since $\\sigma_{j}$ is distinct and all $\\sigma_{i}\\geq0$ , $\\sigma_{j}^{2}$ is distinct. As a result, the eigenspace corresponding to $\\sigma_{j}^{2}$ has dim 1, i.e., it is spanned by $V_{j}$ . Since $V_{j}$ is a unit vector, it can be determined up to a sign. In addition, we have $A V_{j}=\\sigma_{j}U_{j}$ , thus $U_{j}$ can also be determined up to a sign. $U_{j}V_{J}^{T}$ is unique since flipping the sign of $V_{j}$ always leads to the flipping of sign of $U_{j}$ , and vice versa. ", "page_idx": 15}, {"type": "text", "text": "If $\\sigma_{j}=0$ , we can still repeat the above argument to determine $V_{j}$ up to a sign, and determine $U_{j}$ up to a sign using the above argument for $A A^{T}$ . ", "page_idx": 15}, {"type": "text", "text": "Note that in Arun\u2019s algorithm, we use the SVD projection defined as follows. ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\overline{{S V D}}(A)=\\hat{U}d i a g(1,1,s i g n(d e t(\\hat{U}\\hat{V}^{T})))\\hat{V}^{T},\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "where $A=\\hat{U}\\hat{\\Sigma}\\hat{V}^{T},\\hat{U},\\hat{V}\\in O(3)$ is the SVD decomposition of $A$ . In other words, if $d e t(\\hat{U}\\hat{V}^{T})=1$ , then we take $\\hat{U}\\hat{V}^{T}$ , otherwise we flip the sign of $\\hat{U_{3}}\\hat{V_{3}}$ . An important observation is that this SVD projection is unique under a mild assumption. ", "page_idx": 15}, {"type": "text", "text": "Assumption C.2. In the SVD decomposition, $\\sigma_{3}$ is distinct, i.e., $\\sigma_{1}\\geq\\sigma_{2}>\\sigma_{3}\\geq0$ ", "page_idx": 15}, {"type": "text", "text": "Proposition C.3 (Uniqueness of SVD projection). Let $A=U\\Sigma V^{T}\\in\\mathbb{R}^{3\\times3}$ be the SVD decomposition, where $\\Sigma=d i a g(\\sigma_{1},\\sigma_{2},\\sigma_{3})$ is a diagonal matrix, and $U,V\\in O(3)$ . If assumption $C.2$ is satisfied, then ${\\overline{{S V D}}}(A)$ is unique. ", "page_idx": 15}, {"type": "text", "text": "Proof. Let $A=\\tilde{U}\\tilde{\\Sigma}\\tilde{V}^{T}$ be another SVD decomposition of $A$ , i.e., ", "page_idx": 15}, {"type": "equation", "text": "$$\nA=\\sigma_{1}U_{1}V_{1}^{T}+\\sigma_{2}U_{2}V_{2}^{T}+\\sigma_{3}U_{3}V_{3}^{T}=\\sigma_{1}\\tilde{U}_{1}\\tilde{V}_{1}^{T}+\\sigma_{2}\\tilde{U}_{2}\\tilde{V}_{2}^{T}+\\sigma_{3}\\tilde{U}_{3}\\tilde{V}_{3}^{T},\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "the goal is to prove ", "page_idx": 15}, {"type": "equation", "text": "$$\nU_{1}V_{1}^{T}+U_{2}V_{2}^{T}+s i g n(d e t(U V^{T}))U_{3}V_{3}^{T}=\\tilde{U}_{1}\\tilde{V}_{1}^{T}+\\tilde{U}_{2}\\tilde{V}_{2}^{T}+s i g n(d e t(\\tilde{U}\\tilde{V}^{T}))\\tilde{U}_{3}\\tilde{V}_{3}^{T}.\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "We first show that $U_{1}V_{1}^{T}+U_{2}V_{2}^{T}=\\tilde{U}_{1}\\tilde{V}_{1}^{T}+\\tilde{U}_{2}\\tilde{V}_{2}^{T}$ . ", "page_idx": 15}, {"type": "text", "text": "1) If $\\sigma_{3}=0$ and $\\sigma_{1}=\\sigma_{2}$ , then ", "page_idx": 15}, {"type": "equation", "text": "$$\nU_{1}V_{1}^{T}+U_{2}V_{2}^{T}=\\tilde{U}_{1}\\tilde{V}_{1}^{T}+\\tilde{U}_{2}\\tilde{V}_{2}^{T}=\\frac{1}{\\sigma_{1}}A.\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "2) If $\\sigma_{3}\\,=\\,0$ and $\\sigma_{1}\\,>\\,\\sigma_{2}$ , then $\\sigma_{1}$ and $\\sigma_{2}$ are distinct and nonzero. According to lemma C.1, $U_{1}V_{1}^{T}=\\tilde{U}_{1}\\tilde{V}_{1}^{T}$ and $U_{2}V_{2}^{T}=\\tilde{U}_{2}\\tilde{V}_{2}^{T}$ , thus the summation of these two terms is equal. ", "page_idx": 15}, {"type": "text", "text": "3) If $\\sigma_{3}>0$ and $\\sigma_{1}>\\sigma_{2}$ , the argument is the same as 2) ", "page_idx": 15}, {"type": "text", "text": "4) If $\\sigma_{3}>0$ and $\\sigma_{1}=\\sigma_{2}$ , then $\\sigma_{3}$ is distinct and nonzero. According to lemma C.1, $U_{3}V_{3}^{T}=\\tilde{U_{3}}\\tilde{V_{3}}^{T}$ Thus, ", "page_idx": 15}, {"type": "equation", "text": "$$\nU_{1}V_{1}^{T}+U_{2}V_{2}^{T}=\\tilde{U}_{1}\\tilde{V}_{1}^{T}+\\tilde{U}_{2}\\tilde{V}_{2}^{T}=\\frac{1}{\\sigma_{1}}(1-\\sigma_{3}U_{3}V_{3}^{T}).\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "Thus we have $U_{1}V_{1}^{T}+U_{2}V_{2}^{T}=\\tilde{U}_{1}\\tilde{V}_{1}^{T}+\\tilde{U}_{2}\\tilde{V}_{2}^{T}.$ . ", "page_idx": 15}, {"type": "text", "text": "Now we prove that the last term in Eqn. (33) is equal. We have $\\tilde{U}_{3}\\tilde{V}_{3}^{T}=\\pm U_{3}V_{3}^{T}$ , and we have shown that $U_{1}V_{1}^{T}+U_{2}V_{2}^{T}=\\tilde{U}_{1}\\tilde{V}_{1}^{T}+\\tilde{U}_{2}\\tilde{V}_{2}^{T}$ , thus we have ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\lefteqn{d e t(\\tilde{U}_{1}\\tilde{V}_{1}^{T}+\\tilde{U}_{2}\\tilde{V}_{2}^{T}+\\tilde{U}_{3}\\tilde{V}_{3}^{T})=d e t(U_{1}V_{1}^{T}+U_{2}V_{2}^{T}\\pm U_{3}V_{3}^{T})}}\\\\ &{=d e t(U)d e t([V_{1},V_{2},\\pm V_{3}]^{T})}\\\\ &{=d e t(U)\\Big(\\pm d e t([V_{1},V_{2},V_{3}]^{T})\\Big)}\\\\ &{=\\pm\\,d e t(U_{1}V_{1}^{T}+U_{2}V_{2}^{T}+U_{3}V_{3}^{T})}\\end{array}\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "By multiplying this term with $\\tilde{U}_{3}\\tilde{V}_{3}^{T}=\\pm U_{3}V_{3}^{T}$ , we have ", "page_idx": 16}, {"type": "equation", "text": "$$\nd e t(\\tilde{U}_{1}\\tilde{V}_{1}^{T}+\\tilde{U}_{2}\\tilde{V}_{2}^{T}+\\tilde{U}_{3}\\tilde{V}_{3}^{T})\\tilde{U}_{3}\\tilde{V}_{3}^{T}=d e t(U_{1}V_{1}^{T}+U_{2}V_{2}^{T}+U_{3}V_{3}^{T})U_{3}V_{3}^{T},\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "which suggests that last term in Eqn. (33) is equal. In summary, we have proved (33). ", "page_idx": 16}, {"type": "text", "text": "Finally, we can prove the uniqueness of Arun\u2019s method under the same assumption. ", "page_idx": 16}, {"type": "text", "text": "Proposition C.4 (Uniqueness of Arun\u2019s method). Under assumption C.2, Arun\u2019s method $(I)$ is unique. ", "page_idx": 16}, {"type": "text", "text": "Proof. According to Prop. C.3, $r=S V D(\\bar{r})$ is unique. As a result, $t=m(Y)-r m(X)$ is also unique. \u53e3 ", "page_idx": 16}, {"type": "text", "text": "Throughout this work, we assume that assumption C.2 holds, so that the uniqueness of Arun\u2019s method and BITR can be guaranteed. ", "page_idx": 16}, {"type": "text", "text": "For the rest of this appendix, we use a simpler notation of SVD projection, where we simply absorb the sign matrix into U\u02c6 and V\u02c6 : ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\begin{array}{r}{U=\\left(\\hat{U}d i a g(1,1,s i g n(d e t(\\hat{U})))\\right)\\in S O(3),\\quad}\\\\ {V^{T}=\\left(d i a g(1,1,s i g n(d e t(\\hat{V})))\\hat{V}^{T}\\right)\\in S O(3),}\\\\ {a n d\\quad\\Sigma=d i a g(\\hat{\\sigma_{1}},\\hat{\\sigma_{2}},\\hat{\\sigma_{3}}s i g n(d e t(\\hat{U}\\hat{V}^{T}))),\\quad}\\end{array}\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "thus obtain the following equivalent definition. ", "page_idx": 16}, {"type": "text", "text": "Definition C.5. The SVD projection of matrix $A$ is defined as ", "page_idx": 16}, {"type": "equation", "text": "$$\nS V D(A)=U V^{T}\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "where $A=U\\Sigma V^{T}$ and $U,V\\in S O(3)$ . ", "page_idx": 16}, {"type": "text", "text": "Finally, we can discuss the equivariance of Arun\u2019s method. ", "page_idx": 16}, {"type": "text", "text": "Lemma C.6. Let ", "text_level": 1, "page_idx": 16}, {"type": "equation", "text": "$$\nS V D(A)=U V^{T}\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "be the SVD projection of $A$ , i.e., $A$ can be decomposed as $A=U\\Sigma V^{T}$ , $\\Sigma$ is a diagonal matrix and $U,V\\in S O(3)$ . We have ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{S V D(r_{2}A r_{1}^{T})=r_{2}S V D(A)r_{1}^{T},}\\\\ &{\\quad\\quad S V D(A^{T})=\\left(S V D(A)\\right)^{T},}\\\\ &{\\quad\\quad S V D(c A)=S V D(A),}\\end{array}\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "for arbitrary $A\\in G L(3)$ , $r_{1},r_{2}\\in S O(3)$ , and $c\\in\\mathbb{R}_{+}$ . ", "page_idx": 16}, {"type": "text", "text": "The Proof of Lemma. C.6. We have ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\begin{array}{r}{r_{2}A r_{1}^{T}=r_{2}U\\Sigma V^{T}r_{1}^{T}=(r_{2}U)\\Sigma(r_{1}V)^{T},}\\end{array}\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "where $r_{2}U\\,\\in\\,S O(3)$ , $r_{1}V\\,\\in\\,S O(3)$ and $\\Sigma$ is a diagonal matrix. In other words, (46) is a $S V D$ decomposition of matrix $r_{2}A r_{1}^{T}$ , thus the $S V D$ projection can be computed as ", "page_idx": 16}, {"type": "equation", "text": "$$\nS V D(r_{2}A r_{1}^{T})=(r_{2}U)(r_{1}V)^{T}=r_{2}(U V^{T})r_{1}^{T}=r_{2}S V D(A)r_{1}^{T},\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "which proves the first part of this lemma. We omit the other two statements of this lemma since they can be proved similarly. \u53e3 ", "page_idx": 16}, {"type": "text", "text": "The Proof of Prop. 3.2. Let $\\Phi_{A}$ be Arun\u2019s method and $\\Phi_{A}(X,Y)\\;=\\;(r(X,Y),t(X,Y))\\;=\\;g.$ . We directly verify these three equivariances according to Def. 3.1. We only prove the $S E(3)$ - bi-equivariance and swap-equivariance and omit the proof of scale-equivariance, because it can be proved similarity. ", "page_idx": 17}, {"type": "text", "text": "1) $S E(3)$ -bi-equivariance We compute $\\Phi_{A}(g_{1}X,g_{2}Y)$ for the perturbed PCs $g_{1}X=\\{r_{1}x_{i}+$ $t_{1}\\}_{i=1}^{N}$ and $g_{2}\\bar{Y^{}}=\\{r_{2}y_{i}+t_{2}\\}_{i=1}^{N}$ as follows. We first compute $\\bar{r}(g_{1}X,g_{2}Y)$ as ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\bar{r}(g_{1}X,g_{2}Y)=\\sum_{i}(r_{2}\\bar{y_{i}})(\\bar{x_{i}}^{T}r_{1}^{T})=r_{2}\\left(\\sum_{i}\\bar{y_{i}}\\bar{x_{i}}^{T}\\right)r_{1}^{T}=r_{2}\\bar{r}(X,Y)r_{1}^{T}.\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "Then we compute $r$ via $S V D$ : ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\langle g_{1}X,g_{2}Y\\rangle=S V D(\\bar{r}(g_{1}X,g_{2}Y))=S V D(r_{2}\\bar{r}(X,Y)r_{1}^{T})=r_{2}S V D(\\bar{r}(X,Y))r_{1}^{T}=r_{2}r(X,Y)r_{1}^{T},\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "where the 3-rd equality holds due to Lemma. C.6. Since the mean values are also perturbed as $m(g_{1}X)=g_{1}m{\\bar{(}}X)$ and $m(g_{2}Y)=g_{2}m(Y)$ , we compute $t(g_{1}X,g_{2}Y)$ as ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\begin{array}{r}{t(g_{1}X,g_{2}Y)=m(g_{2}Y)-r(g_{1}X,g_{2}Y)m(g_{1}X)=g_{2}m(Y)-r_{2}r(X,Y)r_{1}^{T}g_{1}m(X)\\qquad\\qquad}\\\\ {=r_{2}t(X,Y)-r_{2}r(X,Y)r_{1}^{-1}t(X,Y)+t_{2}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "In summary, ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\Phi_{A}(g_{1}X,g_{2}Y)=(r_{2}r(X,Y)r_{1}^{-1},-r_{2}r(X,Y)r_{1}^{-1}t_{1}+r_{2}t(X,Y)+t_{2})=g_{2}g g_{1}^{-1},\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "which proves the $S E(3)$ -bi-equivariance of Arun\u2019s method. ", "page_idx": 17}, {"type": "text", "text": "2) swap-equivariance We compute $\\Phi_{A}(Y,X)$ as follows. We first compute $\\bar{r}(Y,X)$ as ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\bar{r}(Y,X)=\\sum_{i}\\bar{x}_{i}\\bar{y_{i}}^{T}=\\left(\\sum_{i}\\bar{y_{i}}^{T}\\bar{x_{i}}\\right)^{T}=\\left(\\bar{r}(X,Y)\\right)^{T}.\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "Then we compute $r(Y,X)$ via $S V D$ : ", "page_idx": 17}, {"type": "equation", "text": "$$\nr(Y,X)=S V D(\\bar{r}(Y,X))=S V D\\left(\\left(\\bar{r}(X,Y)\\right)^{T}\\right)=(S V D(\\bar{r}(X,Y)))^{T}=r(X,Y)^{T},\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "We can finally compute $t(Y,X)$ as ", "page_idx": 17}, {"type": "equation", "text": "$$\nt(Y,X)=m(X)-r(Y,X)m(Y)=m(X)-r(X,Y)^{-1}m(Y)=-r(X,Y)^{-1}t(X,Y).\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "In summary, ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\Phi_{A}(Y,X)=(r(X,Y)^{-1},-r(X,Y)^{-1}t(X,Y))=g^{-1},\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "which proves the swap-equivariance of Arun\u2019s method. ", "page_idx": 17}, {"type": "text", "text": "C.2 The proof of the equivariance of BITR ", "text_level": 1, "page_idx": 17}, {"type": "text", "text": "Before proving the $S E(3)$ -bi-equivariance of BITR, we first verify that each layer in a $S E(3)\\times$ $S E(3)$ -transformer is indeed $S\\bar{E}(3)\\times S E(3)$ -equivariant. Intuitively, the equivariance of a transformer layer (5) is a result of the kernel design, i.e., the kernel constraint (22), and the invariance of the attention. We state this result in the following lemma for completeness, and we note that similar techniques are also used in the construction of $S E(3)$ -transformer [11]. ", "page_idx": 17}, {"type": "text", "text": "Lemma C.7. The transformer layer (5) is $S E(3)\\times S E(3)$ -equivariant. ", "page_idx": 17}, {"type": "text", "text": "Proof. We abbreviate $r_{1}\\times r_{2}$ as $r_{12}$ , and $g_{1}\\times g_{2}$ as $g_{12}$ . Let $L$ be a transformer layer (5), we seek to prove $(g_{12})(L(f))=L((g_{12})(f))$ for the input tensor field $f$ and $g_{1},g_{2}\\in S E(3)$ . We compute the ", "page_idx": 17}, {"type": "text", "text": "RHS of the equation as ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\begin{array}{c}{{\\displaystyle\\left(L(g_{12}(f))\\right)^{o}(z_{u})}}\\\\ {{\\displaystyle=W^{o}\\big(g_{12}(F)\\big)^{o}(z_{u})+\\sum_{z_{v}\\in\\mathfrak{s u p p}(g_{12}(f))}\\alpha(g_{12}(f),z_{u},z_{v})W^{o,i}(z_{v}-z_{u})\\big(g_{12}(f)\\big)^{i}(z_{v})}}\\\\ {{\\displaystyle=W^{o}F^{o}\\big(g_{12}^{-1}z_{u}\\big)\\Big(\\rho_{o}(r_{12})\\Big)^{T}+\\sum_{z_{v}\\in\\mathfrak{s u p p}(g_{12}(f))}\\alpha(g_{12}(f),z_{u},z_{v})W^{o,i}(z_{v}-z_{u})\\rho_{i}(r_{12})f^{i}(g_{12}^{-1}z_{v})}}\\\\ {{\\displaystyle=W^{o}F^{o}\\big(g_{12}^{-1}z_{u}\\big)\\Big(\\rho_{o}(r_{12})\\Big)^{T}+\\sum_{z_{v}\\in\\mathfrak{s u p p}(f)}\\frac{\\alpha(g_{12}(f),z_{u},g_{12}z_{v})}{(\\Delta)}\\underbrace{W^{o,i}(g_{12}z_{v}-z_{u})\\rho_{i}(r_{12})f^{i}(z_{v})}_{\\displaystyle\\textcircled{()}}.}}\\end{array}\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "Note that here we have $g_{12}F^{o}(z)=F^{o}(g_{12}^{-1}z)(\\rho_{o}(r_{12}))^{T}$ because we write $F$ in the channel-first form, $i.e.$ ., the shape of $F^{o}$ is $c\\times(2o_{1}+1)(2o_{2}+1)$ . The LHS of the equation is computed as ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\Big(g_{12}\\big(L(f)\\big)\\Big)^{o}(z_{u})}\\\\ &{=\\underbrace{W^{o}F^{o}\\big(g_{12}^{-1}z_{u}\\big)\\Big(\\rho_{o}(r_{12})\\Big)^{T}}_{\\langle\\mathcal{A}\\rangle}+\\underbrace{\\sum_{z_{v}\\in s u p p}(f)}_{z_{v}\\in s u p p(f)}\\underbrace{\\alpha(f,g_{12}^{-1}z_{u},z_{v})}_{\\langle\\mathcal{B}\\rangle}\\underbrace{\\rho_{o}(r_{12})\\mathcal{W}^{o,i}(z_{v}-g_{12}^{-1}z_{u})f^{i}(z_{v})}_{\\langle\\mathcal{C}\\rangle}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "We now verify that these 3 terms are equal respectively. ", "page_idx": 18}, {"type": "text", "text": "$\\widehat{\\mathbb{C}})=\\widehat{\\mathbb{C}^{\\prime}})$ : By design, the kernel $\\mathcal{W}$ satisfies the kernel constraint (22) ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\rho_{o}(r_{12})\\mathcal{W}^{o,i}(z)\\rho_{i}^{-1}(r_{12})=\\mathcal{W}(r_{12}z).\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "In addition, let $z_{u}^{\\prime}=g_{12}^{-1}z_{u}$ . We have ", "page_idx": 18}, {"type": "equation", "text": "$$\ng_{12}z_{v}-z_{u}=g_{12}z_{v}-g_{12}z_{u}^{\\prime}=r_{12}(z_{v}-z_{u}^{\\prime})=r_{12}(z_{v}-g_{12}^{-1}z_{u}).\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "Thus, we can obtain the equality by combining the above two equations. ", "page_idx": 18}, {"type": "text", "text": "$\\widehat{\\left(B\\right)}=\\widehat{\\left(B^{\\prime}\\right)}$ : We compute $\\mathbf{Q}$ and $\\mathbf{K}$ for $\\circled{B}$ and $\\widehat{\\left(B^{\\prime}\\right)}$ respectively. We have ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\begin{array}{c}{{{\\bf{Q}}(g_{12}(f),z_{u},g_{12}z_{v})=\\displaystyle\\bigoplus_{o}W_{Q}^{o}(g_{12}F)^{o}(z_{u})=\\displaystyle\\bigoplus_{o}W_{Q}^{o}F^{o}(r_{12}^{-1}(z_{u}))\\Big(\\rho_{o}(r_{12})\\Big)^{T},}}\\\\ {{{\\bf{Q}}(f,g_{12}^{-1}z_{u},z_{v})=\\displaystyle\\bigoplus_{o}W_{Q}^{o}F^{o}(g_{12}^{-1}(z_{u})),}}\\\\ {{{\\bf{K}}(g_{12}(f),z_{u},g_{12}z_{v})=\\displaystyle\\bigoplus_{o}\\sum_{i}W_{K}^{o,i}(g_{12}z_{v}-z_{u})\\Big(g_{12}(f)\\Big)^{i}(g_{12}z_{v})}}\\\\ {{=\\displaystyle\\bigoplus_{o}\\sum_{i}W_{K}^{o,i}(g_{12}z_{v}-z_{u})\\rho_{i}(r_{12})f^{i}(z_{v}),}}\\end{array}\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "and ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbf{K}(f,g_{12}^{-1}z_{u},z_{v})=\\underset{o}{\\bigoplus}\\sum_{i}\\mathcal{W}_{K}^{o,i}(z_{v}-g_{12}^{-1}z_{u})f^{i}(z_{v})}\\\\ &{\\qquad\\qquad\\qquad=\\underset{o}{\\bigoplus}\\sum_{i}\\Bigl(\\rho_{o}(r_{12})\\Bigr)^{T}\\mathcal{W}_{K}^{o,i}(g_{12}z_{v}-z_{u})\\rho_{i}(r_{12})f^{i}(z_{v}),}\\end{array}\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "where the last equation holds due to the kernel constraint (22) and the orthogonality of $\\rho_{o}(r_{12})$ . Specifically, $\\rho_{o}(r_{12})=\\rho_{o_{1}}(r_{1})\\otimes\\rho_{o_{2}}(r_{2})$ is an orthogonal matrix because $\\rho_{o_{1}}$ and $\\rho_{o_{2}}$ are orthogonal representations, i.e., $\\rho_{o_{1}}(r_{1})$ and $\\rho_{o_{2}}(r_{2})$ are orthogonal matrices. ", "page_idx": 18}, {"type": "text", "text": "Thus, we have ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\quad\\langle\\mathbf{Q}(g_{12}(f),z_{u},g_{12}z_{v}),\\mathbf{K}(g_{12}(f),z_{u},g_{12}z_{v})\\rangle}\\\\ &{=\\displaystyle\\sum_{o}W_{Q}^{o}F^{o}(r_{12}^{-1}(z_{u}))\\Big(\\rho_{o}(r_{12})\\Big)^{T}\\Big(\\sum_{i}\\mathcal{W}_{K}^{o,i}(g_{12}z_{v}-z_{u})\\rho_{i}(r_{12})f^{i}(z_{v})\\Big)}\\\\ &{=\\displaystyle\\sum_{o}W_{Q}^{o}F^{o}(r_{12}^{-1}(z_{u}))\\Big(\\underset{i}{\\sum_{i}}\\Big(\\rho_{o}(r_{12})\\Big)^{T}\\mathcal{W}_{K}^{o,i}(g_{12}z_{v}-z_{u})\\rho_{i}(r_{12})f^{i}(z_{v})\\Big)}\\\\ &{=\\langle\\mathbf{Q}(f,g_{12}^{-1}z_{u},z_{v}),\\mathbf{K}(f,g_{12}^{-1}z_{u},z_{v})\\rangle}\\end{array}\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "Finally, $\\textcircled{A}=\\textcircled{A^{\\prime}}$ is trivial. In summary, we have shown $(g_{12})(L(f))=L((g_{12})(f))$ , which proves the $S E(3)\\times S E(3)$ -equivariance of the transformer layer (5). \u53e3 ", "page_idx": 19}, {"type": "text", "text": "On the other hand, an Elu layer (5) is also $S E(3)\\times S E(3)$ -equivariant, because this layer is piecewise linear. We state this statement formally in the following lemma, and omit the proof. We note that a similar argument was used in [9]. ", "page_idx": 19}, {"type": "text", "text": "Lemma C.8. The Elu layer (9) is $S E(3)\\times S E(3)$ -equivariant. ", "page_idx": 19}, {"type": "text", "text": "Now we can prove the $S E(3)$ -bi-equivariance of BITR. ", "page_idx": 19}, {"type": "text", "text": "The Proof of Prop. 4.1. Let $g=\\Phi_{P}\\circ\\Phi_{S}(X,Y)$ , and $f_{o u t}=\\Phi_{S}(X,Y)$ . We prove this proposition by showing ", "page_idx": 19}, {"type": "equation", "text": "$$\ng_{2}^{-1}g g_{1}=\\Phi_{P}\\circ\\Phi_{S}(g_{1}X,g_{2}Y).\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "We compute the RHS of the equation as follows. First, since each point in $\\tilde{X}$ and $\\tilde{Y}$ is a convex combination of $X$ and $Y$ respectively, we have ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\tilde{X}(g_{1}X,g_{2}Y)=g_{1}\\tilde{X}(X,Y)\\quad\\tilde{Y}(g_{1}X,g_{2}Y)=g_{2}\\tilde{Y}(X,Y).\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "Then we have $Z(g_{1}X,g_{2}Y)=(g_{1}\\times g_{2})Z(X,Y)$ because $Z={\\tilde{X}}\\oplus{\\tilde{Y}}$ . When $Z(g_{1}X,g_{2}Y)$ is fed to the $S E(3)\\times S E(3)$ -transformer, the output feature will be $(g_{1}\\times g_{2})f_{o u t}$ by design (This is verified in Lemma. C.7 and Lemma. C.8). In particular, for degree- $(1,1)$ feature $\\tilde{r}$ , degree- $(1,0)$ feature $t_{X}$ and degree- $(0,1)$ feature $t_{Y}$ , we have ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\langle g_{1}X,g_{2}Y\\rangle=(r_{1}\\otimes r_{2})\\tilde{r}(X,Y)\\quad t_{X}(g_{1}X,g_{2}Y)=r_{1}t_{X}(X,Y)\\quad t_{Y}(g_{1}X,g_{2}Y)=r_{2}t_{Y}(X,Y).\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "Therefore, we have $\\hat{r}(g_{1}X,g_{2}Y)=r_{2}\\tilde{r}(X,Y)r_{1}^{-1}$ by applying $u n v e c(\\cdot)$ to the first equation, i.e., $\\hat{r}=u n v e c(\\tilde{r})$ . Finally, we compute projection $\\Phi_{P}$ similar to proof C.1: ", "page_idx": 19}, {"type": "equation", "text": "$$\nr(g_{1}X,g_{2}Y)=r_{2}r(X,Y)r_{1}^{T},\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "and ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{t(g_{1}X,g_{2}Y)=m(g_{2}Y)+t_{Y}(g_{1}X,g_{2}Y)-r(g_{1}X,g_{2}Y)(m(g_{1}X)+t_{X}(g_{1}X,g_{2}Y))}\\\\ &{\\phantom{t(g_{1}X,g_{2}Y)}=g_{2}m(Y)+r_{2}t_{Y}(X,Y)-r_{2}r(X,Y)r_{1}^{T}(g_{1}m(X)+r_{1}t_{X}(X,Y))}\\\\ &{\\phantom{t(g_{1}X,g_{2}Y)}=r_{2}t(X,Y)-r_{2}r(X,Y)r_{1}^{-1}t(X,Y)+t_{2}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "In summary, ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\Phi_{P}\\circ\\Phi_{S}(g_{1}X,g_{2}Y)=(r_{2}r(X,Y)r_{1}^{-1},-r_{2}r(X,Y)r_{1}^{-1}t_{1}+r_{2}t(X,Y)+t_{2})=g_{2}g g_{1}^{-1},\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "which proves the $S E(3)$ -bi-equivariance of BITR. ", "page_idx": 19}, {"type": "text", "text": "We finally prove Prop. 5.1 and Prop. 5.3 similarly to Prop. 3.2. ", "page_idx": 19}, {"type": "text", "text": "The Proof of Prop. 5.1. We compute $\\Phi_{P}(s(f))$ as follows. First, we have ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\begin{array}{r}{(s(f))^{1,1}\\,(z)=\\big(f^{1,1}(s(z))\\big)^{T}\\,,\\,(s(f))^{1,0}\\,(z)=\\big(f^{0,1}(s(z))\\big)^{T}\\,,\\,(s(f))^{0,1}\\,(z)=\\big(f^{1,0}(s(z))\\big)^{T}\\,,}\\end{array}\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "by definition. Then we compute the equivariant features as ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\hat{r}(s(f))=(\\hat{r}(f))^{T}\\,,\\quad t_{X}(s(f))=t_{Y}(f),\\quad t_{Y}(s(f))=t_{X}(f),\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "where we treat $t_{X}$ and $t_{Y}$ as vectors. Finally, the output can be computed as ", "page_idx": 20}, {"type": "equation", "text": "$$\nr(s(f))=S V D(\\hat{r}(s(f)))=S V D((\\hat{r}(f))^{T})=\\left(S V D(\\hat{r}(f))\\right)^{T}=\\left(r(f)\\right)^{T}\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "according to lemma C.6, and ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{t(s(f))=m(Y(s(f)))+t_{Y}(s(f))-r(s(f))(m(X(s(f)))+t_{X}(s(f)))}\\\\ &{\\quad\\quad\\quad=m(X)+t_{X}(f)-\\left(r(f)\\right)^{T}\\left(m(Y)+t_{Y}(f)\\right)}\\\\ &{\\quad\\quad\\quad=-r(f)^{T}t(f).}\\end{array}\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "In other words, $\\Phi_{P}(s(f))=(r^{T},-r^{T}t)=g^{-1}$ , which proves this proposition. ", "page_idx": 20}, {"type": "text", "text": "The Proof of Prop. 5.3. We compute $\\Phi_{P}(c(f))$ as follows. First, since $f$ is a degree-1 $\\mathbb{R}_{+}$ - equivariant tensor field, $f$ satisfies $c(f)(z)=c f(c^{-1}z)$ . Therefore, we have ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\hat{r}(c(f))=(c\\hat{r}(f))\\,,\\quad t_{X}(c(f))=c t_{X}(f),\\quad t_{Y}(c(f))=t_{Y}(f)\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "by definition. Then, we compute the output as ", "page_idx": 20}, {"type": "equation", "text": "$$\nr(c(f))=S V D(\\hat{r}(c(f)))=S V D((c\\hat{r}(f)))=(S V D(\\hat{r}(f)))=(r(f))\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "according to lemma C.6, and ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{t(c(f))=m(Y(c(f)))+t_{Y}(c(f))-r(c(f))(m(X(c(f)))+t_{X}(c(f)))}\\\\ &{\\quad\\quad\\quad=c m(Y)+c t_{Y}(f)-r(f)(c m(Y)+c t_{Y}(f))}\\\\ &{\\quad\\quad\\quad=c t(f).}\\end{array}\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "In other words, $\\Phi_{P}(c(f))=(r,c t)$ , which proves this proposition. ", "page_idx": 20}, {"type": "text", "text": "C.3 More results of Sec. 5.1 ", "text_level": 1, "page_idx": 20}, {"type": "text", "text": "C.3.1 The proof of Prop. 5.2 ", "text_level": 1, "page_idx": 20}, {"type": "text", "text": "In this subsection, we use slightly different notations than other parts of the paper. We regard the kernel $\\mathcal{W}^{o,i}$ as a 4-D tensor of shape $(2o_{1}+1)\\times(2o_{2}+1)\\times(2i_{1}^{-}+1)\\times(2i_{2}^{-}+1)$ , and we regard the feature $f^{i}$ as a 2-D tensor of shape $(2i_{1}+1)\\times(2i_{2}+1)$ , i.e., a matrix, when it is multiplied by a kernel. Therefore, the multiplication $\\mathcal{W}^{o,i}f^{i}$ is treated as a tensor product where all two dimensions of $f^{i}$ are treated as rows, $i.e.$ ., the result of $\\lambda^{o,i}f^{i}$ is of shape $(2o_{1}^{-}+1)\\times(2o_{2}+1)$ . Similarly, we regard the collection of features $F^{o}$ as a 3-D tensor of shape $c\\times(2o_{1}+1)\\times(2o_{2}+1)$ . When it is multiplied by a self-interaction weight $W^{o}\\in\\mathbb{R}^{1\\times c}$ , the result is $W^{o}F^{o}\\in\\mathbb{R}^{(2o_{1}+1)\\times(2o_{2}+1)}$ . ", "page_idx": 20}, {"type": "text", "text": "We first make the following observation on the symmetry of the kernel. ", "page_idx": 20}, {"type": "text", "text": "Lemma C.9. If the radial function $\\varphi$ satisfies $\\varphi_{J_{1},J_{2}}^{i,o}(\\|z^{1}\\|,\\|z^{2}\\|)=\\varphi_{J_{2},J_{1}}^{\\tilde{i},\\tilde{o}}(\\|z^{2}\\|,\\|z^{1}\\|)$ for all $z^{1}$ , $z^{2},\\,J_{1},\\,J_{2},$ , then kernel $\\mathcal{W}\\left(5\\right)$ satisfies ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathcal{W}^{o,i}(z)=\\Bigl(\\mathcal{W}^{\\tilde{o},\\tilde{i}}\\left(s(z)\\right)\\Bigr)^{T_{12}T_{34}}\\,,}\\end{array}\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "where $T_{i j}$ represents the transpose of the $i$ -th and $j$ -th dimension of a tensor. ", "page_idx": 20}, {"type": "text", "text": "Proof. According to (5) and the discussion in Sec. B, the $(m_{3},m_{4},m_{1},m_{2})$ -th element of $\\mathscr{W}^{o,i}(z)$ is ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\sum_{J_{1}=|o_{1}-i_{1}|}^{o_{1}+i_{1}}\\sum_{J_{2}=|o_{2}-i_{2}|}^{o_{2}+i_{2}}\\sum_{m_{5}=-J_{1}}^{J_{1}}\\sum_{m_{6}=-J_{2}}^{J_{2}}\\varphi_{J_{1},J_{2}}^{i,o}(\\|z^{1}\\|,\\|z^{2}\\|)\\langle i_{1},m_{1},o_{1},m_{3}|J_{1},m_{5}\\rangle\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "and the $(m_{4},m_{3},m_{2},m_{1})$ -th element of $\\mathscr{W}^{\\tilde{o},\\tilde{i}}\\left(s(z)\\right)$ is ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\begin{array}{r l r}{\\lefteqn{\\sum_{J_{2}=|o_{2}-i_{2}|}^{o_{2}+i_{2}}\\sum_{J_{1}=|o_{1}-i_{1}|}^{o_{1}+i_{1}}\\sum_{m_{6}=-J_{2}}^{J_{2}}\\sum_{m_{5}=-J_{1}}^{J_{1}}\\varphi_{J_{2},J_{1}}^{\\tilde{i},\\tilde{o}}(\\|z^{2}\\|,\\|z^{1}\\|)\\langle i_{2},m_{2},o_{2},m_{4}|J_{2},m_{6}\\rangle}}\\\\ &{}&{\\langle i_{1},m_{1},o_{1},m_{3}|J_{1},m_{5}\\rangle Y_{J_{2}}^{m_{6}}(z^{2}/\\|z^{2}\\|)Y_{J_{1}}^{m_{5}}(z^{1}/\\|z^{1}\\|).}\\end{array}\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "Since the angular components in (69) and (70) are the same, and the radial components are equal by assumption, we immediately conclude that (69) and (70) are equal. In other words, ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\left(\\mathcal{W}^{o,i}(z)\\right)_{m_{3},m_{4},m_{1},m_{2}}=\\mathcal{W}^{\\tilde{o},\\tilde{i}}\\left(s(z)\\right)_{m_{4},m_{3},m_{2},m_{1}},\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "which proves this lemma. ", "page_idx": 21}, {"type": "text", "text": "Then we proceed to the proof of Prop. 5.2. ", "page_idx": 21}, {"type": "text", "text": "The Proof of Prop. 5.2. Let $L$ be a transformer layer (5), we seek to prove $s(L(f))=L(s(f))$ for the input tensor field $f$ . ", "page_idx": 21}, {"type": "text", "text": "To this end, we expand the RHS of the equation as ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\begin{array}{r c l}{{}}&{{\\displaystyle\\Big(L(s(f))\\Big)^{o}(z_{u})}}&{{}}\\\\ {{}}&{{}}&{{\\displaystyle=W^{o}\\big(s(F)\\big)^{o}(z_{u})+\\sum_{\\stackrel{\\scriptstyle i\\in I(s)(f)}{z_{v}\\in x p p(s(f))}}\\alpha\\big(s(f),z_{u},z_{v}\\big)W^{o,i}(z_{v}-z_{u})\\big(s(f)\\big)^{i}(z_{v})}}\\\\ {{}}&{{}}&{{\\displaystyle=W^{o}\\Big(F^{\\hat{o}}\\big(s(z_{u})\\big)\\Big)^{T_{23}}+\\sum_{\\stackrel{\\scriptstyle i\\in I(s)(f)}{z_{v}\\in x p p(s(f))}}\\alpha\\big(s(f),z_{u},z_{v}\\big)W^{o,i}(z_{v}-z_{u})\\Big(f^{\\hat{i}}(s(z_{v}))\\Big)^{T}}}\\\\ {{}}&{{}}&{{\\displaystyle=\\underbrace{W^{o}\\Big(F^{\\hat{o}}(s(z_{u}))\\Big)^{T_{23}}+\\sum_{\\stackrel{\\scriptstyle i\\in I(f)}{z_{v}\\in x p p(f)}}\\frac{\\alpha\\big(s(f),z_{u},s(z_{v})\\big)}{(\\Delta)}\\underbrace{W^{o,\\hat{i}}(s(z_{v})-z_{u})\\Big(f^{i}(z_{v})\\Big)^{T}}_{\\displaystyle(\\mathcal{O})},}}\\end{array}\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "where $I(f)$ is the set of all degrees of field $f$ , and $s u p p(f)$ is the support of field $f$ . The last equation holds because we replace $z_{v}$ by $s(z_{v})$ , and replace $\\pmb{i}$ by $\\Tilde{i}$ . We expand the LHS of the equation as ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\Big(s\\big(L(f)\\big)\\Big)^{o}(z_{u})=\\Big(\\big(L(f)\\big)^{\\bar{o}}(s(z_{u}))\\Big)^{T}}\\\\ {=\\underbrace{\\Big(W^{\\bar{o}}F^{\\bar{o}}(s(z_{u}))\\Big)^{T}}_{\\langle\\underline{{\\mathcal{A}}}\\rangle}+\\underbrace{\\sum_{i\\in I(f)}}_{z_{v}\\in w p(f)}\\underbrace{\\frac{\\alpha(f,s(z_{u}),z_{v})}{(\\underline{{\\mathcal{B}}})}\\underbrace{\\Big(W^{\\bar{o},i}(z_{v}-s(z_{u}))f^{i}(z_{v})\\Big)^{T}}_{\\langle\\underline{{\\mathcal{C}}}\\rangle}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "We now verify that these three terms are equal respectively. ", "page_idx": 21}, {"type": "text", "text": "$\\textcircled{A}=\\textcircled{A^{\\prime}}$ : By assumption, $W^{o}=W^{\\tilde{o}}$ , thus we immediately have ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\Bigl(W^{\\tilde{o}}F^{\\tilde{o}}(s(z_{u}))\\Bigr)^{T}=\\Bigl(W^{o}F^{\\tilde{o}}(s(z_{u}))\\Bigr)^{T}=W^{o}\\Bigl(F^{\\tilde{o}}(s(z_{u}))\\Bigr)^{T_{23}}.\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "$\\textcircled{B}=\\textcircled{B^{\\prime}}.$ : Since $\\alpha=\\langle\\mathbf{Q},\\mathbf{K}\\rangle$ , we compute $\\mathbf{Q}$ and $\\mathbf{K}$ for $\\circled{B}$ and $\\widehat{\\left(B^{\\prime}\\right)}$ respectively. As for $\\mathbf{Q}$ , we have ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathbf{Q}(s(f),z_{u},s(z_{v}))=\\displaystyle\\bigoplus_{o\\in I(s(f))}W_{Q}^{o}(s(F))^{o}(z_{u})=\\displaystyle\\bigoplus_{o\\in I(s(f))}W_{Q}^{o}\\Big(F^{\\tilde{o}}(s(z_{u}))\\Big)^{T}}\\\\ {=\\displaystyle\\bigoplus_{o\\in I(s(f))}\\Big(W_{Q}^{\\tilde{o}}F^{\\tilde{o}}(s(z_{u}))\\Big)^{T},}\\end{array}\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "where the last equation holds because $W_{Q}^{o}=W_{Q}^{\\tilde{o}}$ by assumption. In addition, ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\mathbf{Q}(f,s(z_{u}),z_{v})=\\bigoplus_{o\\in I(f)}W_{Q}^{o}F^{o}(s(z_{u})).\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "As for $\\mathbf{K}$ , we have ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbf{K}(s(f),z_{u},s(z_{v}))=\\displaystyle\\bigoplus_{\\substack{o\\in I(s(f))\\,i\\in I(s(f))}}\\mathcal{W}_{K}^{o,i}(s(z_{v})-z_{u})\\big(s(f)\\big)^{i}(s(z_{v}))}\\\\ &{\\qquad\\qquad\\qquad=\\displaystyle\\bigoplus_{o\\in I(s(f))}\\Big(\\sum_{i\\in I(f)}\\mathcal{W}_{K}^{\\tilde{o},i}(z_{v}-s(z_{u}))f^{i}(z_{v})\\Big)^{T},}\\end{array}\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "where the last equation holds due to the constraint of radial function and Lemma. C.9, and we replace $\\pmb{i}$ by $\\Tilde{i}$ . In addition, ", "page_idx": 22}, {"type": "equation", "text": "$$\n{\\bf K}(f,s(z_{u}),z_{v})=\\bigoplus_{o\\in I(f)}\\sum_{i\\in I(f)}\\mathcal{W}_{K}^{o,i}(z_{v}-s(z_{u}))f^{i}(z_{v}).\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "We observe that $\\mathbf{Q}(s(f),z_{u},s(z_{v}))$ is just the transpose and re-ordering of each component of $\\mathbf{Q}(f,s(z_{u}),z_{v})$ , and this is also true for ${\\bf K}(s(f),z_{u},s(z_{v}))$ and ${\\bf K}(f,s(z_{u}),z_{v})$ , which suggests that their inner products are the same. Specifically, let $\\mathbf{Q}^{o}\\,=\\,W_{Q}^{o}F^{o}(s(z_{u}))$ and ${\\bf K}^{o}\\,=$ $\\begin{array}{r}{\\sum_{i\\in I(f)}\\mathcal{W}_{K}^{o,i}(z_{v}-s(z_{u}))f^{i}(z_{v})}\\end{array}$ . We have ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\boldsymbol{\\nu}(s(f),z_{u},s(z_{v}))=\\langle\\bigoplus_{o\\in I(s(f))}\\Big(\\mathbf{Q}^{\\bar{\\boldsymbol{\\sigma}}}\\Big)^{T},\\bigoplus_{o\\in I(s(f))}\\Big(\\mathbf{K}^{\\bar{\\boldsymbol{\\sigma}}}\\Big)^{T}\\rangle=\\sum_{o\\in I(s(f))}\\langle\\mathbf{Q}^{\\bar{\\boldsymbol{\\sigma}}},\\mathbf{K}^{\\bar{\\boldsymbol{\\sigma}}}\\rangle=\\sum_{o\\in I(f)}\\langle\\mathbf{Q}^{o},\\mathbf{K}^{o}\\rangle\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "and ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\alpha(f,s(z_{u}),z_{v})=\\langle\\bigoplus_{o\\in I(f)}\\mathbf{Q}^{o},\\bigoplus_{o\\in I(f)}\\mathbf{K}^{o}\\rangle=\\sum_{o\\in I(f)}\\langle\\mathbf{Q}^{o},\\mathbf{K}^{o}\\rangle,\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "which suggests that $\\alpha(f,s(z_{u}),z_{v})=\\alpha(s(f),z_{u},s(z_{v}))$ . ", "page_idx": 22}, {"type": "text", "text": "$\\widehat{\\mathbb{C}})=\\widehat{\\mathbb{C}^{\\prime}})$ : By assumption, the radial function satisfies $\\varphi_{J_{1},\\underline{{J_{2}}}}^{i,o}(\\underline{{\\|z^{1}\\|}},\\|z^{2}\\|)=\\varphi_{J_{2},J_{1}}^{\\tilde{i},\\tilde{o}}(\\|z^{2}\\|,\\|z^{1}\\|)$ for all $i,o,J_{1},\\,J_{2},\\,z^{1}$ and $z^{2}$ , thus $\\mathcal{W}^{o,i}(z)=\\Big(\\mathcal{W}^{\\tilde{o},\\tilde{i}}\\left(s(z)\\right)\\Big)^{T_{12}T_{34}}$ according to Lemma. C.9. As a result, ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathcal{\\prime}\\mathcal{W}^{\\bar{\\sigma},i}(z_{v}-s(z_{u}))f^{i}(z_{v})\\Big)^{T}=\\Big(\\big(\\mathcal{W}^{o,\\bar{i}}(s(z_{v})\\!-\\!z_{u})\\big)^{T_{12}T_{34}}f^{i}(z_{v})\\Big)^{T}=\\mathcal{W}^{o,\\bar{i}}(s(z_{v})\\!-\\!z_{u})\\Big(f^{i}(z_{v})\\Big)^{T}\\!.}\\end{array}\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "In summary, we have shown the $\\mathbb{Z}/2\\mathbb{Z}$ -equivariance of a transformer layer (5), which is the first part of Prop. 5.2. We omit the proof of the second part of this proposition, i.e., the equivariance of an Elu layer, as it is a simple extension of the proof of $\\textcircled{A}=\\textcircled{A^{\\prime}}$ . \u53e3 ", "page_idx": 22}, {"type": "text", "text": "Remark C.10. The weight sharing technique in Prop. 5.2 reduces the number of learnable parameters of a $S E(3)\\times S E(3)$ -transformer by about half, thus it makes the model more efficient. In practice, the weight sharing technique can be achieved by sharing weights between different $o,i$ and $J$ directly, except for the symmetric case, i.e., $\\pmb{o}=\\tilde{\\pmb{o}},i=\\tilde{\\pmb{i}}$ and $J_{1}=J_{2}$ , where the requirement of the radial function becomes ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\varphi_{J_{1},J_{1}}^{o,i}(\\|z^{1}\\|,\\|z^{2}\\|)=\\varphi_{J_{1},J_{1}}^{o,i}(\\|z^{2}\\|,\\|z^{1}\\|).\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "We represent the radial function in this case as $\\varphi(x,y)={\\textstyle\\frac{1}{2}}(\\phi(x,y)+\\phi(y,x))$ , where $\\phi$ is a neural network, which guarantees the symmetry of $\\varphi$ . ", "page_idx": 22}, {"type": "text", "text": "C.3.2 The complete-matching property ", "text_level": 1, "page_idx": 22}, {"type": "text", "text": "Consider the following complete matching problem. ", "page_idx": 22}, {"type": "text", "text": "The complete matching problem Given a pair of PCs $X$ and $Y$ , where $Y$ is generated by a unknown rigidly transformation of $X$ , i.e., $Y=g X$ and $g\\in S E(3)$ is unknown, how to infer $g^{\"}$ ? ", "page_idx": 23}, {"type": "text", "text": "The complete matching problem is a prototype of the registration problem, i.e., in the simplest case (no outlier, no noise, no partial visibility..), how to derive the relative transformation between two fully overlapped PCs? Despite its simplicity, this problem is non-trivial, because we do not know the correspondence between $X$ and $Y$ , i.e., Arun\u2019s method does not apply. ", "page_idx": 23}, {"type": "text", "text": "A surprising fact is that $g$ can be exactly recovered using a $S E(3)$ -bi-equivariant and swap-equivariant assembly method. We state this fact formally as follows. ", "page_idx": 23}, {"type": "text", "text": "Proposition C.11 (Complete-matching property). Let $\\Phi$ be a swap-equivariant and $S E(3)$ -biequivariant assembly method. Then ", "page_idx": 23}, {"type": "equation", "text": "$$\n\\Phi(X,g_{1}X)\\Phi(X,X)=g_{1},\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "for arbitrary PC $X$ and $g_{1}\\in S E(3)$ . ", "page_idx": 23}, {"type": "text", "text": "Proof. First, since $\\Phi$ is swap-equivariant, then $\\Phi(X,X)\\Phi(X,X)=I$ . Then, since $\\Phi$ is $S E(3)$ -biequivariant, we have $\\Phi(X,g_{1}X)\\Phi(X,X)=g_{1}\\Phi(X,X)\\Phi(X,X)=g_{1}$ . \u53e3 ", "page_idx": 23}, {"type": "text", "text": "According to the main text, BITR is swap-equivariance (Prop. 5.2), thus, we can derive a concrete algorithm, called untrained BITR (U-BITR), for the complete matching problem: ", "page_idx": 23}, {"type": "equation", "text": "$$\n\\Phi_{U}(X,Y)=\\Phi_{B}(X,Y)\\Phi_{B}(X,X),\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "where $\\Phi_{B}$ is BITR model. Prop. C.11 suggests that $\\Phi_{U}$ solves the complete matching problem without training. We numerically evaluate this property in Appx. D.4, and leave the theoretical analysis of U-BITR to future research. ", "page_idx": 23}, {"type": "text", "text": "C.4 The proof of Prop. 5.5 ", "text_level": 1, "page_idx": 23}, {"type": "text", "text": "First, we have the following straightforward lemma for the kernel. ", "page_idx": 23}, {"type": "text", "text": "Lemma C.12. If the radial function $\\varphi:\\mathbb{R}\\times\\mathbb{R}\\to\\mathbb{R}$ is a degree- $p$ function, then kernel $\\mathcal{W}$ (5) satisfies ", "page_idx": 23}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathcal{W}(c z)=c^{p}\\mathcal{W}(z),\\quad\\forall c\\in\\mathbb{R}_{+}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "Then we directly verify Prop. 5.5. ", "page_idx": 23}, {"type": "text", "text": "The proof of Prop. 5.5. Let $L$ be a transformer layer (5), $f$ be a degree-0 $\\mathbb{R}_{+}$ -equivariant input field, $\\varphi_{K}$ be a degree-0 function. We seek to prove: 1) If $\\varphi_{V}$ is a degree-0 function, then $c(\\bar{L}(f))=$ $L(c(f))$ and $L(f)$ is degree-0 $\\mathbb{R}_{+}$ -equivariant; 2) If $\\varphi_{V}$ is a degree-1 function and $W=0$ , then $c(L(f))=L(c(f))$ and $L(f)$ is degree-1 $\\mathbb{R}_{+}$ -equivariant. ", "page_idx": 23}, {"type": "text", "text": "To begin with, we expand $L(c(f))$ as ", "page_idx": 23}, {"type": "equation", "text": "$$\n\\begin{array}{r l r}{\\lefteqn{\\Big(L\\big(c(f)\\big)\\Big)^{o}(z_{u})=W^{o}(c(F))^{o}(z_{u})+\\displaystyle\\sum_{\\stackrel{z_{v}\\in u p p(c(f))}{z_{v}\\in u p p(c(f))}}\\alpha\\big(c(f),z_{u},z_{v}\\big)\\mathcal{W}_{V}^{o,i}(z_{v}-z_{u})\\big(c(f)\\big)^{i}(z_{v})}}\\\\ &{}&{=W^{o}F^{o}(c^{-1}z_{u})+\\displaystyle\\sum_{\\stackrel{z_{v}\\in u p p(c(f))}{z_{v}\\in u p p(c(f))}}\\alpha\\big(c(f),z_{u},z_{v}\\big)\\mathcal{W}_{V}^{o,i}(z_{v}-z_{u})f^{i}(c^{-1}z_{v})}\\\\ &{}&{=\\underbrace{W^{o}F^{o}(c^{-1}z_{u})}_{(\\tilde{A})}+\\displaystyle\\sum_{\\stackrel{z_{v}\\in u p p(f)}{z_{v}\\in u p p(f)}}\\underbrace{\\alpha\\big(c(f),z_{u},c(z_{v})\\big)}_{(\\tilde{B})}\\underbrace{\\mathcal{W}_{V}^{o,i}(c(z_{v})-z_{u})f^{i}(z_{v})}_{(\\tilde{C})},}\\end{array}\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "and expand $c(L(f))$ as ", "page_idx": 23}, {"type": "equation", "text": "$$\n\\Big(c\\big(L(f)\\big)\\Big)^{o}(z_{u})=c^{p}\\Big(\\big(L(f)\\big)\\Big)^{o}(c^{-1}z_{u})}\\\\ {=c^{p}\\Big(\\underbrace{W^{o}F^{o}(c^{-1}z_{u})}_{(\\underline{{\\mathcal{A}}})}+\\sum_{\\scriptstyle z_{v}\\in\\underline{{\\mathcal{M}p}}(f)}\\underbrace{\\alpha(f,c^{-1}z_{u},z_{v})}_{(\\underline{{\\mathcal{B}}})}\\underbrace{\\mathcal{W}_{V}^{o,i}(z_{v}-c^{-1}z_{u})f^{i}(z_{v})}_{(\\underline{{\\mathcal{C}}})}\\Big).}\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "We first point out that $\\widehat{\\left(B\\right)}=\\widehat{\\left(B^{\\prime}\\right)},$ , because ", "page_idx": 24}, {"type": "equation", "text": "$$\n{\\mathsf{C}}(c(f),z_{u},c(z_{v}))=\\bigoplus_{o}\\sum_{i}{\\mathcal{W}}_{K}^{o,i}(c(z_{v})-z_{u})\\bigl(c(f)\\bigr)^{i}(z_{v})=\\bigoplus_{o}\\sum_{i}{\\mathcal{W}}_{K}^{o,i}(z_{v}-c^{-1}(z_{u}))f^{i}(c^{-1}z_{v})\\,,\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "where the second equation holds because $\\varphi_{K}$ is a degree-0 function by assumption, and Lemma. C.12 claims that the corresponding kernel $\\mathcal{W}_{K}$ is scale-invariant. In addition, ", "page_idx": 24}, {"type": "equation", "text": "$$\n\\mathbf{Q}(c(f),z_{u},c(z_{v}))=\\bigoplus_{o}W_{Q}^{o}(c(F))^{o}(z_{u})=\\bigoplus_{o}W_{Q}^{o}F^{o}(c^{-1}z_{u})=\\mathbf{Q}(f,c^{-1}z_{u},z_{v}).\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "In other words, both $\\mathbf{Q}$ and $\\mathbf{K}$ are scale-invariant. Thus, we conclude that the attention is also scale-invariant: ", "page_idx": 24}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\alpha(c(f),z_{u},c(z_{v}))=\\langle\\mathbf{Q}(c(f),z_{u},c(z_{v})),\\mathbf{K}(c(f),z_{u},c(z_{v}))\\rangle}\\\\ &{\\phantom{x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x}}\\\\ &{\\phantom{x x x x x x x x x x x x x x x x x x x x x x x x}=\\langle\\mathbf{K}(f,c^{-1}z_{u},z_{v}),\\mathbf{Q}(f,c^{-1}z_{u},z_{v})\\rangle}\\\\ &{\\phantom{x x x x x x x x}=\\langle\\mathbf{K}(f,c^{-1}z_{u},z_{v}),\\mathbf{Q}(f,c^{-1}z_{u},z_{v})\\rangle}\\\\ &{\\phantom{x x x x x x}=\\alpha(f,c^{-1}z_{u},z_{v}).}\\end{array}\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "Now we discuss these two situations: ", "page_idx": 24}, {"type": "text", "text": "1) If $\\varphi_{V}$ is a degree-1 function and $W=0$ , then ", "page_idx": 24}, {"type": "equation", "text": "$$\nc{\\mathcal W}_{V}^{o,i}(z_{v}-c^{-1}z_{u})={\\mathcal W}_{V}^{o,i}(c(z_{v})-z_{u})\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "according to Lemma. C.12, and $\\widehat{\\langle\\underline{{{A}}}\\rangle}=\\widehat{\\langle\\underline{{{A}}}^{\\prime}\\rangle}=0$ . In other words, $L(c(f))(z)=c^{1}{L}(f)(c^{-1}z)$ , where the RHS is the action of $c$ on the degree-1 $\\mathbb{R}_{+}$ -equivariant field, thus we have $L(\\dot{c}(f))=\\dot{c}(L(f))$ , and $L(f)$ is degree-1 $\\mathbb{R}_{+}$ -equivariant. ", "page_idx": 24}, {"type": "text", "text": "2) If $\\varphi_{V}$ is a degree-0 function, then ", "page_idx": 24}, {"type": "equation", "text": "$$\n\\mathcal{W}_{V}^{o,i}(z_{v}-c^{-1}z_{u})=\\mathcal{W}_{V}^{o,i}(c(z_{v})-z_{u})\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "according to Lemma. C.12. Thus, $L(c(f))(z)\\,=\\,L(f)(c^{-1}z)$ , where the RHS is the action of $c$ on the degree-0 $\\mathbb{R}_{+}$ -equivariant field, thus we have $L({\\dot{c}}(f))\\sp{\\cdot}=\\,c(L(f))$ , and $L(f)$ is degree-0 $\\mathbb{R}_{+}$ -equivariant. ", "page_idx": 24}, {"type": "text", "text": "In summary, we have shown that the equivariance of the transformer layer. We omit the proof of the equivariance of the Elu layer as it can be proved similarly. \u53e3 ", "page_idx": 24}, {"type": "text", "text": "We can now construct a special structure of BITR for producing degree-1 $\\mathbb{R}_{+}$ -equivariant output: ", "page_idx": 24}, {"type": "equation", "text": "$$\nd e g\\mathrm{-}0\\;\\rightarrow\\;d e g\\mathrm{-}0\\;\\rightarrow\\;\\cdots\\rightarrow\\;d e g\\mathrm{-}0\\;\\rightarrow\\;d e g\\mathrm{-}1\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "In other words, all tensor fields are degree-0 $\\mathbb{R}_{+}$ -equivariant, except for the final output which is degree-1 $\\mathbb{R}_{+}$ -equivariant. More specifically, we consider two types of layers, i.e., deg- $0\\rightarrow d e g\u20130$ and deg- $0\\rightarrow d e g{-1}$ . ", "page_idx": 24}, {"type": "text", "text": "Prop. 5.5 suggests that a transformer layer with degree- $\\cdot p$ radial function can generate a degree- $\\boldsymbol{p}$ $\\mathbb{R}_{+}$ -equivariant field when the input field is degree-0 $\\mathbb{R}_{+}$ -equivariant (Elu layers do not influence the $\\mathbb{R}_{+}$ -equivariance). Therefore, we only need to consider degree-0 and degree-1 radial functions for our purpose. In practice, we represent degree-1 functions using neural networks consisting of linear and relu [1] layers, and we represent degree-0 functions using linear, relu and layer normalization [3] layers. Specifically, We represent degree-0 functions as neural network $\\phi_{0}$ : ", "page_idx": 24}, {"type": "equation", "text": "$$\n\\phi_{0}:\\quad L i n e a r\\rightarrow R e l u\\rightarrow L a y e r N o r m\\rightarrow L i n e a r\\rightarrow R e l u\\rightarrow L a y e r N o r m,\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "and represent degree 1-functions neural network $\\phi_{1}$ : ", "page_idx": 24}, {"type": "equation", "text": "$$\n\\phi_{1}:\\quad L i n e a r\\to R e l u\\to L i n e a r\\to R e l u.\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "Remark C.13. There are two major difficulties in developing a general scale-equivariance theory for BITR. First, the attention term is not scale-invariant due to the existence of the soft-max operation, i.e., Soft $M a x(A)\\neq S o f t M a x(c A)$ for vector $A$ and $c\\in\\mathbb{R}_{+}$ . That is the reason why we only accept degree-0 $\\mathbb{R}_{+}$ -equivariant input in our current theory. Second, when $p\\notin\\{0,1\\}$ , we are not aware of any general way to represent degree- $p$ functions using neural networks. ", "page_idx": 24}, {"type": "text", "text": "D More experiment results ", "text_level": 1, "page_idx": 25}, {"type": "text", "text": "D.1 More training details ", "text_level": 1, "page_idx": 25}, {"type": "text", "text": "We run all experiments using a Nvidia T4 GPU card with 16G memory. The batch size is set to the largest possible value that can be ftited into the GPU memory. We set $b s=16$ for the airplane dataset, and $b s=4$ for the wine bottle dataset. We train BITR until the validation loss does not decrease. For the airplane dataset, we train BITR 10000 epochs, and the training time is about 8 days when $s=0.7$ . For the wine bottle dataset, we train BITR 1000 epochs, and the training time is about 12 hours. The FLOPS is $14.5G$ in a forward pass (including the computation of harmonic functions), and the model contains $0.17M$ parameters. ", "page_idx": 25}, {"type": "text", "text": "For Sec. 6.3.1 and 6.3.2, we use the normal vector computed by Open3D [46] as the input feature of BITR. The airplane dataset used in Sec. 6.3.1 contains 715 random training samples and 103 random test samples. The wine bottle dataset used in Sec. 6.4 contains 331 training and 41 test samples. We adopt the few-shot learning setting in the manipulation tasks in Sec. 6.6: we use 30 training and 5 test samples for mug-hanging; we use 40 training samples and 10 test samples for bowl-placing. ", "page_idx": 25}, {"type": "text", "text": "D.2 More results of Sec. 6.2 ", "text_level": 1, "page_idx": 25}, {"type": "text", "text": "We quantitatively verify the equivariance of BITR according to Def. 3.1. Specifically, we compute ", "page_idx": 25}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\quad\\Delta_{b i}=||\\Phi_{B}(g_{1}X,g_{2}Y)-g_{2}\\Phi_{B}(X,Y)g_{1}^{-1}||_{F},}\\\\ &{\\Delta_{s w a p}=||\\Phi_{B}(Y,X)-(\\Phi_{B}(X,Y))^{-1}||_{F},}\\\\ &{\\Delta_{s c a l e}=||r_{B}(c X,c Y)-r_{B}(X,Y)||_{F}+||t_{B}(c X,c Y)-c t_{B}(X,Y)||_{2},}\\end{array}\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "to verify the $S E(3)$ -bi-equivariance, swap-equivariance and scale-equivariance of BITR, where $\\Phi_{B}$ represent the BITR model, $(r_{B}(\\cdot),t_{B}(\\cdot))\\stackrel{-}{=}\\bar{\\Phi_{B}}(\\cdot)$ are the output of BITR, and all $g=(r,t)\\in S E(3)$ are written as ", "page_idx": 25}, {"type": "equation", "text": "$$\ng=\\left[\\!\\!\\begin{array}{c c}{r}&{t}\\\\ {0}&{1}\\end{array}\\!\\!\\right]\\in\\mathbb{R}^{4,4}.\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "Note that if BITR is perfectly equivariant, these three errors should always be 0. ", "page_idx": 25}, {"type": "text", "text": "The quantitative results of the experiment are summarized in Tab. 3, where we can see that all errors are below the numerical precision of float numbers, i.e., less than $1e^{-5}$ . The results suggest that BITR is indeed $S E(3)$ -bi-equivariant, swap-equivariant and scale-equivariant. ", "page_idx": 25}, {"type": "text", "text": "Table 3: Verification of the equivariance of BITR. ", "page_idx": 25}, {"type": "table", "img_path": "EehS4erXWB/tmp/0d2198f8f1d8341027bff5d39781023b26ec0a17b251cd50837b76925493b79c.jpg", "table_caption": [], "table_footnote": [], "page_idx": 25}, {"type": "text", "text": "D.3 Ablation study ", "text_level": 1, "page_idx": 25}, {"type": "text", "text": "To show the practical effectiveness of our theory on scale and swap equivariances, we consider an ablation study. We use the same data as in Sec. 6.2, and remove the weight sharing technique in Sec. 5.1 to break swap-equivariance, and force $\\varphi_{V}$ in all layers to be a degree-1 function to break the scale-equivariance. ", "page_idx": 25}, {"type": "text", "text": "We evaluate the trained model on 100 test samples, and report the mean and standard deviation of $\\Delta r$ in Tab. 4, where we can see that removing an equivariance of the model leads to the failure in the corresponding test case, which is consistent with our theory. ", "page_idx": 25}, {"type": "table", "img_path": "EehS4erXWB/tmp/cec85525073ca14c643930caf896efa718ba8fd1f650684ae38ab5060de96a29.jpg", "table_caption": ["Table 4: Ablation study of scale and swap equivariances. We report mean and std of $\\Delta r$ "], "table_footnote": [], "page_idx": 25}, {"type": "text", "text": "D.4 Evaluation of the complete-matching property ", "text_level": 1, "page_idx": 26}, {"type": "text", "text": "This experiment numerically evaluates the robustness of the complete-matching property (Prop. C.11) against resampling, noise and partial visibility. We first sample $X$ and $Y$ of size 1024 from the bunny shape, and a random $g\\in S E(3)$ , then we use a random initialized U-BITR to match $X$ to $g Y$ . We consider different settings: 1) $X$ and $Y$ are exactly the same; 2) $X$ and $Y$ are different random samples; 3) Gaussian noise of std 0.01 is added to $X$ and $Y$ ; 4) Ratio $s$ of $X$ and $Y$ is kept by cropping using a random plane. ", "page_idx": 26}, {"type": "text", "text": "We repeat the experiment 3 times, and report the results of U-BITR in Tab. 5. We observe that the transformation is perfectly recovered when $X=Y$ , which is consistent with the complete-matching property. Meanwhile, cropping the PCs leads to large decrease of the accuracy, while noise and resampling have less effect. This is consistent with our expectation because cropping the PCs has larger effect on the shape of PCs. We provide qualitative results in Fig. 7. ", "page_idx": 26}, {"type": "table", "img_path": "EehS4erXWB/tmp/cff584efb0c0f94bcb20501601bd48b75fd2b165552a9b45cbd016b72b4803f1.jpg", "table_caption": ["Table 5: Results of complete matching using U-BITR. "], "table_footnote": [], "page_idx": 26}, {"type": "image", "img_path": "EehS4erXWB/tmp/1985d9ca2d0876cb0a349c136725694425bccd3c2b28009af3b2fc1d59b69a0e.jpg", "img_caption": ["Figure 7: Qualitative results of U-BITR on complete matching. The blue and red PCs are the reference and the transformed source PCs respectively. Note that U-BITR is only random initialized (not trained). "], "img_footnote": [], "page_idx": 26}, {"type": "text", "text": "D.5 More results of Sec. 6.3.1 ", "text_level": 1, "page_idx": 26}, {"type": "text", "text": "We report the training process of BITR in Fig. 8, where we can see that the loss value, $\\Delta r$ and $\\Delta t$ gradually decrease during training as expected. ", "page_idx": 26}, {"type": "text", "text": "Some qualitative results of BITR are presented in Fig. 9. We represent the input PCs using light colors, and represent the 32 learned key points using dark colors and large points. As we explained in Sec. 4.3, the key points are in the convex hull of the input PCs, and they are NOT a subset of the input PC. In addition, as can be seen, the key points of the inputs do not overlap. ", "page_idx": 26}, {"type": "text", "text": "D.6 More results of Sec. 6.3.2 ", "text_level": 1, "page_idx": 26}, {"type": "text", "text": "We generate the raw training samples by sampling motorbike and car shapes from the training set of ShapeNet. Then we centralize them, and move the car by $[0,0,1]$ . Note the shapes in ShapeNet are already pre-aligned. The test samples are generated from the test set of ShapeNet in the same way. ", "page_idx": 26}, {"type": "text", "text": "We repeat the test process 3 times, and report the results in Fig. 10. We observe that BITR achieves lower rotation error than LEV, and their translation errors are comparable. Meanwhile, NSM fails in this experiment. Note that we do not report the results of registration methods, because their loss functions are undefined due to the lack of correspondence. ", "page_idx": 26}, {"type": "image", "img_path": "EehS4erXWB/tmp/4f84df0440883f05b1acd8bc20dbe689b474c85bc3f9e55f642dd0638296c86c.jpg", "img_caption": ["Figure 8: The training process of BITR on the airplane dataset with $s=0.4$ . All metrics are measured on the validation set. "], "img_footnote": [], "page_idx": 27}, {"type": "image", "img_path": "EehS4erXWB/tmp/d1d84db99abbad0ed2940146103f22f4f3c256da47fbe41a6ad23dcc4d17fa07.jpg", "img_caption": [], "img_footnote": [], "page_idx": 27}, {"type": "text", "text": "Figure 9: The PC registration results of BITR on the airplane dataset. The input PCs are represented using light colors, and the learned key points are represented using dark and large points. ", "page_idx": 27}, {"type": "image", "img_path": "EehS4erXWB/tmp/dc78f116f2ba3339da944c3d2c2f927e65e9a3f4fb868154517ee0321cba3629.jpg", "img_caption": ["Figure 10: Assembly results of car and motorbike. $^*$ denotes methods which require the true canonical poses of the input PCs. "], "img_footnote": [], "page_idx": 27}, {"type": "text", "text": "D.7 More results of Sec. 6.4 ", "text_level": 1, "page_idx": 27}, {"type": "text", "text": "For BITR, we first obtain raw PCs by applying grid sampling with grid size 0.005 to the shape, and then randomly sample $5\\%$ points from the raw PCs as the training and test samples. The sizes of the resulting PCs are around 1000, which is close to the data used in the baseline methods. The data is pre-processed following [38] for the baseline methods. ", "page_idx": 27}, {"type": "text", "text": "The random sampling process in our method causes the randomness of test error. We quantify the randomness by evaluating on the test set 3 times, and report the mean and std of the errors in Tab. 1. ", "page_idx": 27}, {"type": "text", "text": "Fig. 11 presents 5 examples of reassembling wine bottle fragments, where we observe that the proposed BITR can reassemble most of the shapes correctly, while the baseline methods generally have difficulty predicting the correct rotations. ", "page_idx": 27}, {"type": "text", "text": "D.8 More results of Sec. 6.5 ", "text_level": 1, "page_idx": 27}, {"type": "text", "text": "We preprocess the 7Scenes dataset by applying grid sampling with grid size 0.1. The training and test sets contain 278 and 59 samples. ", "page_idx": 27}, {"type": "text", "text": "We consider the 5 outdoor scenes in the ASL dataset: mountain, winter, summer, wood autumn, wood summer. We preprocess all data by applying grid sampling with grid size 0.9. We arbitrarily rotate and translate all data, and train BITR to align the $i$ -th frame to the $(i+2)$ -th frame. We use the first ", "page_idx": 27}, {"type": "image", "img_path": "EehS4erXWB/tmp/81be8a9292d4923aaeee4df773847cd28ef12f314e7e6543e8fe6f0f4b437e5b.jpg", "img_caption": ["Figure 11: Results of reassembling wine bottle fragments. We compare the proposed BITR with DGL [44], NSM [7] and LEV [38]. Zoom in to see the details. "], "img_footnote": [], "page_idx": 28}, {"type": "text", "text": "20 frames as the training set, and the other frames as the test set. This leads to a training set of size   \n105, and a test set of size 48 ", "page_idx": 28}, {"type": "text", "text": "We report the results in Tab. 6. Our observation is consistent of that in the 7Scenes dataset: the result BITR is close to the optimum, thus a refinement can lead to improved results. Note that BITR+ICP outperforms all baselines in this task. In addition, GEO causes the out-of-memory error on our $16G$ GPU. An assembly result (wood summer) is presented in Fig. 12. ", "page_idx": 28}, {"type": "text", "text": "Table 6: Results on the outdoor scenes of ASL. We report mean and std of $\\Delta r$ and $\\Delta t$ . ", "page_idx": 29}, {"type": "table", "img_path": "EehS4erXWB/tmp/082f775475740e9ba9642fc2d0db3a68c359a2fed64af5fcf819e82c09da468a.jpg", "table_caption": [], "table_footnote": [], "page_idx": 29}, {"type": "image", "img_path": "EehS4erXWB/tmp/d04c7aa764e541f6c23fcf3611713b5ef8a8a2df6388501c49f22c5f15002d23.jpg", "img_caption": ["Figure 12: An assembly result of BITR on 7Scenes (1-st row) and ASL (2-nd row). BITR can produce results that are close to the optimum, and a ICP refinement leads to the improved results. "], "img_footnote": [], "page_idx": 29}, {"type": "image", "img_path": "EehS4erXWB/tmp/df5b4b7d032d897887cb6ff67146dc9a00913e3278ae32e6e27e384794066d30.jpg", "img_caption": ["Figure 13: The result of BITR on mug-hanging. "], "img_footnote": [], "page_idx": 29}, {"type": "text", "text": "D.9 More results of Sec. 6.6 ", "text_level": 1, "page_idx": 29}, {"type": "text", "text": "All data in this experiment is generated using PyBullet [8], where the objects in training and test sets are different in shape and position. ", "page_idx": 29}, {"type": "text", "text": "Note that we do not report the quantitative results for this experiment because the metric $(\\Delta r,\\Delta t)$ is ambiguous due to the non-uniqueness of the correct solution. For example, for a correct bowl-placing result, the bowl is allowed to rotate horizontally in the plate, so the metric $\\Delta r$ can be very large even for this correct assembly. A suitable metric is the success rate of the manipulation in physical hardware experiments as in [27], but measuring this metric is beyond the scope of this work. In addition, the assembly methods such as NSM [7] and LEV [38] are not applicable because the canonical pose is not known, and we do not report the result of any registration method because the correspondence does not exist. We present a result of BITR on mug-hanging in Fig. 13. ", "page_idx": 29}, {"type": "text", "text": "E Limitations and future research directions ", "text_level": 1, "page_idx": 29}, {"type": "text", "text": "In our current implement, we have accelerated most of the layers of BITR using the \u201cscatter\u201d function [24]. However, BITR is still relatively slow due to the independent computation of convolutional kernels, i.e., the harmonic function and the independent multiplication of radial and angular component in each degree. This is reflected by a low GPU utility ratio (about $20\\%$ ). We expect to see a large speed gain (about $\\times5$ ) if the above-mentioned computation is implemented using CUDA kernel, i.e., GPU utility ratio can be close to $100\\%$ . On the other hand, a rotation-based technique was recently introduced to reduce the computation cost of SE(3)-equivariant networks [21]. A promising future direction is to extend this technique to BITR. ", "page_idx": 29}, {"type": "text", "text": "", "page_idx": 30}, {"type": "text", "text": "To explain the limitation of BITR in handling symmetric PCs, we consider the following example. For a pair of PCs $X$ and $Y$ , if there exists a non-identity rigid transformation $g_{2}$ such that $g_{2}Y=Y$ , and $g\\,\\in\\,S E(3)$ is a proper transformation that assembles $g X$ to $Y$ , then $g_{2}g$ is an equally good transformation that gives the same assembly result. In other words, the optimal transformation $g$ is non-unique, which cannot be modelled by BITR. Actually, we notice that the result of BITR is undefined in this case. Specifically, let ${\\tilde{g}}=\\Phi_{B}(X,Y)$ , we have ", "page_idx": 30}, {"type": "equation", "text": "$$\n{\\tilde{g}}=\\Phi_{B}(X,Y)=\\Phi_{B}(X,g_{2}Y)=g_{2}\\Phi_{B}(X,Y)=g_{2}{\\tilde{g}}\n$$", "text_format": "latex", "page_idx": 30}, {"type": "text", "text": "due to $S E(3)$ -bi-equivariance. Then we have $g_{2}=1$ , which contradicts the assumption. ", "page_idx": 30}, {"type": "text", "text": "To address this issue, we plan to extend BITR to a generative model in future research, i.e., it should assign a likelihood value to each prediction. For the example considered above, it should assign equal probability to $g$ and $g_{2}g$ . ", "page_idx": 30}, {"type": "text", "text": "Apart from the above-mentioned two limitations, there are several directions for future investigation. First, it is important to generalize BITR to multi-PC assembly tasks where more than $2~\\mathrm{PCs}$ are considered [14, 38]. Second, we expect the U-BITR model to be useful in self-supervised 3D shape retrieval or detection models, such as those in image object detection/retrieval [19]. ", "page_idx": 30}, {"type": "text", "text": "NeurIPS Paper Checklist ", "text_level": 1, "page_idx": 31}, {"type": "text", "text": "1. Claims ", "text_level": 1, "page_idx": 31}, {"type": "text", "text": "Question: Do the main claims made in the abstract and introduction accurately reflect the paper\u2019s contributions and scope? ", "page_idx": 31}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 31}, {"type": "text", "text": "Justification: We have pointed out that the main contribution of the paper is a $S E(3)$ -biequivariant, swap-equivariant, and scale-equivariant PC assembly method. ", "page_idx": 31}, {"type": "text", "text": "Guidelines: ", "page_idx": 31}, {"type": "text", "text": "\u2022 The answer NA means that the abstract and introduction do not include the claims made in the paper.   \n\u2022 The abstract and/or introduction should clearly state the claims made, including the contributions made in the paper and important assumptions and limitations. A No or NA answer to this question will not be perceived well by the reviewers.   \n\u2022 The claims made should match theoretical and experimental results, and reflect how much the results can be expected to generalize to other settings.   \n\u2022 It is fine to include aspirational goals as motivation as long as it is clear that these goals are not attained by the paper. ", "page_idx": 31}, {"type": "text", "text": "2. Limitations ", "text_level": 1, "page_idx": 31}, {"type": "text", "text": "Question: Does the paper discuss the limitations of the work performed by the authors? ", "page_idx": 31}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 31}, {"type": "text", "text": "Justification: We discuss limitations in Appx. E. ", "page_idx": 31}, {"type": "text", "text": "Guidelines: ", "page_idx": 31}, {"type": "text", "text": "\u2022 The answer NA means that the paper has no limitation while the answer No means that the paper has limitations, but those are not discussed in the paper.   \n\u2022 The authors are encouraged to create a separate \"Limitations\" section in their paper.   \n\u2022 The paper should point out any strong assumptions and how robust the results are to violations of these assumptions (e.g., independence assumptions, noiseless settings, model well-specification, asymptotic approximations only holding locally). The authors should reflect on how these assumptions might be violated in practice and what the implications would be.   \n\u2022 The authors should reflect on the scope of the claims made, e.g., if the approach was only tested on a few datasets or with a few runs. In general, empirical results often depend on implicit assumptions, which should be articulated.   \n\u2022 The authors should reflect on the factors that influence the performance of the approach. For example, a facial recognition algorithm may perform poorly when image resolution is low or images are taken in low lighting. Or a speech-to-text system might not be used reliably to provide closed captions for online lectures because it fails to handle technical jargon.   \n\u2022 The authors should discuss the computational efficiency of the proposed algorithms and how they scale with dataset size.   \n\u2022 If applicable, the authors should discuss possible limitations of their approach to address problems of privacy and fairness.   \n\u2022 While the authors might fear that complete honesty about limitations might be used by reviewers as grounds for rejection, a worse outcome might be that reviewers discover limitations that aren\u2019t acknowledged in the paper. The authors should use their best judgment and recognize that individual actions in favor of transparency play an important role in developing norms that preserve the integrity of the community. Reviewers will be specifically instructed to not penalize honesty concerning limitations. ", "page_idx": 31}, {"type": "text", "text": "3. Theory Assumptions and Proofs ", "text_level": 1, "page_idx": 31}, {"type": "text", "text": "Question: For each theoretical result, does the paper provide the full set of assumptions and a complete (and correct) proof? ", "page_idx": 31}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 31}, {"type": "text", "text": "Justification: All proofs can be found in Appx. C. Guidelines: ", "page_idx": 32}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include theoretical results.   \n\u2022 All the theorems, formulas, and proofs in the paper should be numbered and crossreferenced.   \n\u2022 All assumptions should be clearly stated or referenced in the statement of any theorems.   \n\u2022 The proofs can either appear in the main paper or the supplemental material, but if they appear in the supplemental material, the authors are encouraged to provide a short proof sketch to provide intuition.   \n\u2022 Inversely, any informal proof provided in the core of the paper should be complemented by formal proofs provided in appendix or supplemental material.   \n\u2022 Theorems and Lemmas that the proof relies upon should be properly referenced. ", "page_idx": 32}, {"type": "text", "text": "4. Experimental Result Reproducibility ", "text_level": 1, "page_idx": 32}, {"type": "text", "text": "Question: Does the paper fully disclose all the information needed to reproduce the main experimental results of the paper to the extent that it affects the main claims and/or conclusions of the paper (regardless of whether the code and data are provided or not)? ", "page_idx": 32}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 32}, {"type": "text", "text": "Justification: The architecture BITR is described in Sec. 4 and 5. More details are in Appx. D.1. ", "page_idx": 32}, {"type": "text", "text": "Guidelines: ", "page_idx": 32}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 If the paper includes experiments, a No answer to this question will not be perceived well by the reviewers: Making the paper reproducible is important, regardless of whether the code and data are provided or not.   \n\u2022 If the contribution is a dataset and/or model, the authors should describe the steps taken to make their results reproducible or verifiable.   \n\u2022 Depending on the contribution, reproducibility can be accomplished in various ways. For example, if the contribution is a novel architecture, describing the architecture fully might suffice, or if the contribution is a specific model and empirical evaluation, it may be necessary to either make it possible for others to replicate the model with the same dataset, or provide access to the model. In general. releasing code and data is often one good way to accomplish this, but reproducibility can also be provided via detailed instructions for how to replicate the results, access to a hosted model (e.g., in the case of a large language model), releasing of a model checkpoint, or other means that are appropriate to the research performed.   \n\u2022 While NeurIPS does not require releasing code, the conference does require all submissions to provide some reasonable avenue for reproducibility, which may depend on the nature of the contribution. For example (a) If the contribution is primarily a new algorithm, the paper should make it clear how to reproduce that algorithm. (b) If the contribution is primarily a new model architecture, the paper should describe the architecture clearly and fully. (c) If the contribution is a new model (e.g., a large language model), then there should either be a way to access this model for reproducing the results or a way to reproduce the model (e.g., with an open-source dataset or instructions for how to construct the dataset). (d) We recognize that reproducibility may be tricky in some cases, in which case authors are welcome to describe the particular way they provide for reproducibility. In the case of closed-source models, it may be that access to the model is limited in some way (e.g., to registered users), but it should be possible for other researchers to have some path to reproducing or verifying the results. ", "page_idx": 32}, {"type": "text", "text": "5. Open access to data and code ", "text_level": 1, "page_idx": 32}, {"type": "text", "text": "Question: Does the paper provide open access to the data and code, with sufficient instructions to faithfully reproduce the main experimental results, as described in supplemental material? ", "page_idx": 32}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 33}, {"type": "text", "text": "Justification: The code will be available at https://github.com/wzm2256/BiTr Guidelines: ", "page_idx": 33}, {"type": "text", "text": "\u2022 The answer NA means that paper does not include experiments requiring code.   \n\u2022 Please see the NeurIPS code and data submission guidelines (https://nips.cc/ public/guides/CodeSubmissionPolicy) for more details.   \n\u2022 While we encourage the release of code and data, we understand that this might not be possible, so \u201cNo\u201d is an acceptable answer. Papers cannot be rejected simply for not including code, unless this is central to the contribution (e.g., for a new open-source benchmark).   \n\u2022 The instructions should contain the exact command and environment needed to run to reproduce the results. See the NeurIPS code and data submission guidelines (https: //nips.cc/public/guides/CodeSubmissionPolicy) for more details.   \n\u2022 The authors should provide instructions on data access and preparation, including how to access the raw data, preprocessed data, intermediate data, and generated data, etc.   \n\u2022 The authors should provide scripts to reproduce all experimental results for the new proposed method and baselines. If only a subset of experiments are reproducible, they should state which ones are omitted from the script and why.   \n\u2022 At submission time, to preserve anonymity, the authors should release anonymized versions (if applicable).   \n\u2022 Providing as much information as possible in supplemental material (appended to the paper) is recommended, but including URLs to data and code is permitted. ", "page_idx": 33}, {"type": "text", "text": "6. Experimental Setting/Details ", "text_level": 1, "page_idx": 33}, {"type": "text", "text": "Question: Does the paper specify all the training and test details (e.g., data splits, hyperparameters, how they were chosen, type of optimizer, etc.) necessary to understand the results? ", "page_idx": 33}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 33}, {"type": "text", "text": "Justification: This is included in Sec. 6.1, and more can be found in Appx. D.1. Guidelines: ", "page_idx": 33}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments. \u2022 The experimental setting should be presented in the core of the paper to a level of detail that is necessary to appreciate the results and make sense of them. \u2022 The full details can be provided either with the code, in appendix, or as supplemental material. ", "page_idx": 33}, {"type": "text", "text": "7. Experiment Statistical Significance ", "text_level": 1, "page_idx": 33}, {"type": "text", "text": "Question: Does the paper report error bars suitably and correctly defined or other appropriate information about the statistical significance of the experiments? ", "page_idx": 33}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 33}, {"type": "text", "text": "Justification: We report the mean and standard deviation for our experiments. ", "page_idx": 33}, {"type": "text", "text": "Guidelines: ", "page_idx": 33}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 The authors should answer \"Yes\" if the results are accompanied by error bars, confidence intervals, or statistical significance tests, at least for the experiments that support the main claims of the paper.   \n\u2022 The factors of variability that the error bars are capturing should be clearly stated (for example, train/test split, initialization, random drawing of some parameter, or overall run with given experimental conditions).   \n\u2022 The method for calculating the error bars should be explained (closed form formula, call to a library function, bootstrap, etc.)   \n\u2022 The assumptions made should be given (e.g., Normally distributed errors).   \n\u2022 It should be clear whether the error bar is the standard deviation or the standard error of the mean.   \n\u2022 It is OK to report 1-sigma error bars, but one should state it. The authors should preferably report a 2-sigma error bar than state that they have a $96\\%$ CI, if the hypothesis of Normality of errors is not verified.   \n\u2022 For asymmetric distributions, the authors should be careful not to show in tables or figures symmetric error bars that would yield results that are out of range (e.g. negative error rates).   \n\u2022 If error bars are reported in tables or plots, The authors should explain in the text how they were calculated and reference the corresponding figures or tables in the text. ", "page_idx": 33}, {"type": "text", "text": "", "page_idx": 34}, {"type": "text", "text": "8. Experiments Compute Resources ", "text_level": 1, "page_idx": 34}, {"type": "text", "text": "Question: For each experiment, does the paper provide sufficient information on the computer resources (type of compute workers, memory, time of execution) needed to reproduce the experiments? ", "page_idx": 34}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 34}, {"type": "text", "text": "Justification: The information regarding the computation resource is provided in Appx. D.1 Guidelines: ", "page_idx": 34}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 The paper should indicate the type of compute workers CPU or GPU, internal cluster, or cloud provider, including relevant memory and storage.   \n\u2022 The paper should provide the amount of compute required for each of the individual experimental runs as well as estimate the total compute.   \n\u2022 The paper should disclose whether the full research project required more compute than the experiments reported in the paper (e.g., preliminary or failed experiments that didn\u2019t make it into the paper). ", "page_idx": 34}, {"type": "text", "text": "9. Code Of Ethics ", "text_level": 1, "page_idx": 34}, {"type": "text", "text": "Question: Does the research conducted in the paper conform, in every respect, with the NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines? ", "page_idx": 34}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 34}, {"type": "text", "text": "Justification: The research conducted in the paper conform the NeurIPS Code of Ethics. Guidelines: ", "page_idx": 34}, {"type": "text", "text": "\u2022 The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics.   \n\u2022 If the authors answer No, they should explain the special circumstances that require a deviation from the Code of Ethics.   \n\u2022 The authors should make sure to preserve anonymity (e.g., if there is a special consideration due to laws or regulations in their jurisdiction). ", "page_idx": 34}, {"type": "text", "text": "10. Broader Impacts ", "text_level": 1, "page_idx": 34}, {"type": "text", "text": "Question: Does the paper discuss both potential positive societal impacts and negative societal impacts of the work performed? ", "page_idx": 34}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 34}, {"type": "text", "text": "Justification: This work focus on the equivalence of the point cloud assembly task. We do not see any social impact that needs to be specifically addressed. ", "page_idx": 34}, {"type": "text", "text": "Guidelines: ", "page_idx": 34}, {"type": "text", "text": "\u2022 The answer NA means that there is no societal impact of the work performed.   \n\u2022 If the authors answer NA or No, they should explain why their work has no societal impact or why the paper does not address societal impact.   \n\u2022 Examples of negative societal impacts include potential malicious or unintended uses (e.g., disinformation, generating fake profiles, surveillance), fairness considerations (e.g., deployment of technologies that could make decisions that unfairly impact specific groups), privacy considerations, and security considerations.   \n\u2022 The conference expects that many papers will be foundational research and not tied to particular applications, let alone deployments. However, if there is a direct path to any negative applications, the authors should point it out. For example, it is legitimate to point out that an improvement in the quality of generative models could be used to generate deepfakes for disinformation. On the other hand, it is not needed to point out that a generic algorithm for optimizing neural networks could enable people to train models that generate Deepfakes faster.   \n\u2022 The authors should consider possible harms that could arise when the technology is being used as intended and functioning correctly, harms that could arise when the technology is being used as intended but gives incorrect results, and harms following from (intentional or unintentional) misuse of the technology.   \n\u2022 If there are negative societal impacts, the authors could also discuss possible mitigation strategies (e.g., gated release of models, providing defenses in addition to attacks, mechanisms for monitoring misuse, mechanisms to monitor how a system learns from feedback over time, improving the efficiency and accessibility of ML). ", "page_idx": 34}, {"type": "text", "text": "", "page_idx": 35}, {"type": "text", "text": "11. Safeguards ", "text_level": 1, "page_idx": 35}, {"type": "text", "text": "Question: Does the paper describe safeguards that have been put in place for responsible release of data or models that have a high risk for misuse (e.g., pretrained language models, image generators, or scraped datasets)? ", "page_idx": 35}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 35}, {"type": "text", "text": "Justification: Our work is about assembly 3D point cloud. It does not generate new image/language or other types of data of high risk. ", "page_idx": 35}, {"type": "text", "text": "Guidelines: ", "page_idx": 35}, {"type": "text", "text": "\u2022 The answer NA means that the paper poses no such risks.   \n\u2022 Released models that have a high risk for misuse or dual-use should be released with necessary safeguards to allow for controlled use of the model, for example by requiring that users adhere to usage guidelines or restrictions to access the model or implementing safety filters.   \n\u2022 Datasets that have been scraped from the Internet could pose safety risks. The authors should describe how they avoided releasing unsafe images.   \n\u2022 We recognize that providing effective safeguards is challenging, and many papers do not require this, but we encourage authors to take this into account and make a best faith effort. ", "page_idx": 35}, {"type": "text", "text": "12. Licenses for existing assets ", "text_level": 1, "page_idx": 35}, {"type": "text", "text": "Question: Are the creators or original owners of assets (e.g., code, data, models), used in the paper, properly credited and are the license and terms of use explicitly mentioned and properly respected? ", "page_idx": 35}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 35}, {"type": "text", "text": "Justification: We cited all dataset we used: bunny [33], BB [31], 7scenes [32], shapenet [6], and the data generated by PyBullet [8]. ", "page_idx": 35}, {"type": "text", "text": "Guidelines: ", "page_idx": 35}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not use existing assets.   \n\u2022 The authors should cite the original paper that produced the code package or dataset.   \n\u2022 The authors should state which version of the asset is used and, if possible, include a URL.   \n\u2022 The name of the license (e.g., CC-BY 4.0) should be included for each asset.   \n\u2022 For scraped data from a particular source (e.g., website), the copyright and terms of service of that source should be provided.   \n\u2022 If assets are released, the license, copyright information, and terms of use in the package should be provided. For popular datasets, paperswithcode.com/datasets has curated licenses for some datasets. Their licensing guide can help determine the license of a dataset.   \n\u2022 For existing datasets that are re-packaged, both the original license and the license of the derived asset (if it has changed) should be provided.   \n\u2022 If this information is not available online, the authors are encouraged to reach out to the asset\u2019s creators. ", "page_idx": 35}, {"type": "text", "text": "", "page_idx": 36}, {"type": "text", "text": "13. New Assets ", "text_level": 1, "page_idx": 36}, {"type": "text", "text": "Question: Are new assets introduced in the paper well documented and is the documentation provided alongside the assets? ", "page_idx": 36}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 36}, {"type": "text", "text": "Justification: The code of this paper will be released when the paper is accepted. ", "page_idx": 36}, {"type": "text", "text": "Guidelines: ", "page_idx": 36}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not release new assets.   \n\u2022 Researchers should communicate the details of the dataset/code/model as part of their submissions via structured templates. This includes details about training, license, limitations, etc.   \n\u2022 The paper should discuss whether and how consent was obtained from people whose asset is used.   \n\u2022 At submission time, remember to anonymize your assets (if applicable). You can either create an anonymized URL or include an anonymized zip file. ", "page_idx": 36}, {"type": "text", "text": "14. Crowdsourcing and Research with Human Subjects ", "text_level": 1, "page_idx": 36}, {"type": "text", "text": "Question: For crowdsourcing experiments and research with human subjects, does the paper include the full text of instructions given to participants and screenshots, if applicable, as well as details about compensation (if any)? ", "page_idx": 36}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 36}, {"type": "text", "text": "Justification: The paper does not involve crowdsourcing nor research with human subjects. Guidelines: ", "page_idx": 36}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u2022 Including this information in the supplemental material is fine, but if the main contribution of the paper involves human subjects, then as much detail as possible should be included in the main paper.   \n\u2022 According to the NeurIPS Code of Ethics, workers involved in data collection, curation, or other labor should be paid at least the minimum wage in the country of the data collector. ", "page_idx": 36}, {"type": "text", "text": "15. Institutional Review Board (IRB) Approvals or Equivalent for Research with Human Subjects ", "text_level": 1, "page_idx": 36}, {"type": "text", "text": "Question: Does the paper describe potential risks incurred by study participants, whether such risks were disclosed to the subjects, and whether Institutional Review Board (IRB) approvals (or an equivalent approval/review based on the requirements of your country or institution) were obtained? ", "page_idx": 36}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 36}, {"type": "text", "text": "Justification: The paper does not involve crowdsourcing nor research with human subjects. Guidelines: ", "page_idx": 36}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u2022 Depending on the country in which research is conducted, IRB approval (or equivalent) may be required for any human subjects research. If you obtained IRB approval, you should clearly state this in the paper.   \n\u2022 We recognize that the procedures for this may vary significantly between institutions and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the guidelines for their institution.   \n\u2022 For initial submissions, do not include any information that would break anonymity (if applicable), such as the institution conducting the review. ", "page_idx": 36}]