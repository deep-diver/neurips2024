[{"type": "text", "text": "Neural Persistence Dynamics ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Sebastian Zeng\u2020/\u2021, Florian Graf\u2020, Martin Uray\u2020/\u2021, Stefan Huber\u2021, Roland Kwitt\u2020 ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "\u2020University of Salzburg, Austria   \n\u2021Josef Ressel Centre for Intelligent and Secure Industrial Automation, University of Applied Sciences, Salzburg, Austria   \n{sebastian.zeng, florian.graf, roland.kwitt}@plus.ac.at, {martin.uray, stefan.huber}@fh-salzburg.ac.at ", "page_idx": 0}, {"type": "text", "text": "Abstract ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "We consider the problem of learning the dynamics in the topology of time-evolving point clouds, the prevalent spatiotemporal model for systems exhibiting collective behavior, such as swarms of insects and birds or particles in physics. In such systems, patterns emerge from (local) interactions among self-propelled entities. While several well-understood governing equations for motion and interaction exist, they are notoriously difficult to fit to data, as most prior work requires knowledge about individual motion trajectories, i.e., a requirement that is challenging to satisfy with an increasing number of entities. To evade such confounding factors, we investigate collective behavior from a topological perspective, but instead of summarizing entire observation sequences (as done previously), we propose learning a latent dynamical model from topological features per time point. The latter is then used to formulate a downstream regression task to predict the parametrization of some a priori specified governing equation. We implement this idea based on a latent ODE learned from vectorized (static) persistence diagrams and show that a combination of recent stability results for persistent homology justifies this modeling choice. Various (ablation) experiments not only demonstrate the relevance of each model component but provide compelling empirical evidence that our proposed model \u2013 Neural Persistence Dynamics \u2013 substantially outperforms the state-of-the-art across a diverse set of parameter regression tasks. ", "page_idx": 0}, {"type": "text", "text": "1 Introduction ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Understanding emerging behavioral patterns of a collective through the interaction of individual entities is key to elucidate many phenomena in nature on a macroscopic and microscopic scale. Prominent examples are coherently moving flocks of birds, the swarming behavior of insects and fish or the development of cancerous cells, all understood as 2D/3D point clouds that evolve over time. Importantly, several widely-accepted governing equations for collective behavior exist [18, 40, 56] which, when appropriately parameterized, can reproduce different incarnations of typically observed patterns. Even more importantly, these equations are tied to physically interpretable parameters and can provide detailed insights into the intrinsic mechanisms that control various behavioral regimes. However, while it is fairly straightforward to simulate collective behavior from governing equations (see [21]), the inverse problem, i.e., identifying the model parameters from the data, turns out to be inherently difficult. Confounding factors include the often large number of observed entities and the difficulty of reliably identifying individual trajectories across point clouds at possibly non-equidistant observation times. ", "page_idx": 0}, {"type": "text", "text": "However, as several works [4, 23, 52] have recently demonstrated, it may not be necessary to rely on individual trajectories for parameter identification. In fact, collective behavior is characterized by global patterns that emerge from local interactions, and we observe the emergence of these patterns through changes to the \u201cshape\u201d of point clouds over time. For instance, birds may form a flock, split into groups, and then merge again. This perspective has prompted the idea of summarizing such topological events over time and then phrasing model identification as a downstream prediction/regression task. The key challenge here lies in the transition from topological summaries of point clouds at specific observation times, typically obtained via persistent homology $(P H)$ [3, 9, 22], to the dynamic regime where the temporal dimension plays a crucial role. ", "page_idx": 0}, {"type": "text", "text": "", "page_idx": 1}, {"type": "text", "text": "Yet, despite the often remarkable performance of topological approaches in terms of parameter identification for models of collective behavior, it remains unclear in which situations they are preferable over more traditional (learning) methods that can handle point cloud data, as, e.g., used in computer vision problems [24, 46]. In the spirit of [53], we highlight this point by previewing a snapshot of one ablation experiment from Sec. 4. In particular, Tbl. 1 compares the parameter regression performance of our proposed approach, using PH, to a variant ", "page_idx": 1}, {"type": "table", "img_path": "rCnZrFikX6/tmp/e76fd5e04bab077c0853938c69f99ba0b300df49652ef3e9ddd2d0befdc71c85.jpg", "table_caption": ["Table 1: PointNet+ $^{+}$ [45] vs. persistent homology (PH) representations; $\\uparrow$ means higher and $\\downarrow$ means lower is better. "], "table_footnote": [], "page_idx": 1}, {"type": "text", "text": "where we instead use PointNet $^{-+}$ [45] representations. Referring to Fig. 1, this means that the $\\mathbf{v}_{\\tau_{i}}$ are computed by a PointNet $^{++}$ model. As can be seen in Tbl. 1, relying on representations computed via PH works well on both datasets, while PointNet $^{++}$ representations fail on one dataset (vicsek-10k), but indeed perform reasonably well on the other (dorsogna-1k). ", "page_idx": 1}, {"type": "text", "text": "In light of this observation, it is worth emphasizing that there is a clear distinction in terms of the source of point cloud dynamics when comparing collective behavior to problems in computer vision where moving objects are of primary interest and PointNet variants (see [24]) have shown stellar performance: in particular, point clouds in vision primarily evolve due to a change in pose or camera motion, whereas collective behavior is driven by (local) intrinsic point interactions. The latter induces changes to the \u201cshape\u201d of the point clouds, i.e., a phenomenon that is typically not observed in vision. ", "page_idx": 1}, {"type": "text", "text": "Contribution(s). Our key idea is to learn a generative model that can reproduce topological summaries at each point in time. This contrasts prior work, which primarily aims to extract one summary representation of the entire timeline. In detail, we advocate for modeling the dynamics of vectorized persistence diagrams via a continuous latent variable model (e.g., a latent ODE), see Fig. 1, and to use the resulting latent paths as input to a downstream parameter regression task. Recent stability results for vectorizations of persistence diagrams \u2013 relating distances among the latter to the Wasserstein distance between point clouds \u2013 justify this modeling choice. Aside from state-of-the-art performance on various parameter identification tasks for established models of collective behavior, our approach scales favorably with the number of observed sequences, accounts for non-equidistant observation times, and is easily combinable with other sources of information. ", "page_idx": 1}, {"type": "image", "img_path": "rCnZrFikX6/tmp/f7c11741c03e1fa1af947a76cbd2059e8da51fdf25a5b8824ce1a3d454b9e6c1.jpg", "img_caption": ["Figure 1: Conceptual overview of Neural Persistence Dynamics. Given is a sequence of observed point clouds $\\mathcal{P}_{\\tau_{0}},\\ldots,\\mathcal{P}_{\\tau_{N}}$ . First, we summarize each $\\mathcal{P}_{\\tau_{i}}$ via (Vietoris-Rips) persistent homology into persistence diagrams (zero-, one- and two-dimensional; only the zero-dimensional diagrams are shown) which are then vectorized into $\\mathbf{v}_{\\tau_{i}}$ via existing techniques. Second, we model the dynamics in the sequence $\\mathbf{v}_{\\tau_{0}},\\dots,\\mathbf{v}_{\\tau_{N}}$ via a continuous latent variable model (in our case, a latent ODE) and then use a summary of the latent path to predict the parameters of specific governing equation(s) of collective behavior. Precomputed steps are highlighted in red. "], "img_footnote": [], "page_idx": 1}, {"type": "text", "text": "2 Related work ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "Our work is partially related to the literature on learning with dynamic point clouds in vision problems, but primarily connects to work on summarizing topological features over time and inferring interaction laws of collective behavior from data. ", "page_idx": 2}, {"type": "text", "text": "Summarizing topological features over time. A common denominator in the literature on encoding topological changes in dynamic point clouds is the use of persistent homology, extended to accommodate the temporal dimension in various ways. One of the early works along this direction are persistence vineyards [16], introduced as a means to study folding trajectories of proteins. Based on the idea of tracking points in persistence diagrams over time, vineyards come with stability properties similar to persistent homology [41], but are expensive to compute and compare on a large scale. In cases where one would know the \u201cright\u201d scale at which to compute homology, one may also use zigzag persistence [8], as done in [17, 54], to track homological changes over time. Nevertheless, for problems with a large number of observation sequences, scale selection per sequence is nontrivial and highly impractical. ", "page_idx": 2}, {"type": "text", "text": "Alternatively, instead of thinking about the evolution of individual points in persistence diagrams over time, one may discard the matching between points and instead focus on sequences of summary representations of said diagrams. In [25], for instance, the authors work directly with persistence diagrams (per time point) to identify changes in the topology of time-varying graphs. In terms of temporal summary representations, [52] introduce crocker plots to encode the evolution of topological features by stacking discretized Betti curves over time. Crocker stacks [57], an extension of this concept, adds a smoothing step that gradually reduces the impact of points of low persistence and, upon discretization, yields a third dimension to crocker plots. In our context, both crocker plots & stacks have been successfully used as input to regression methods to estimate the parametrization of models of collective behavior [4]. By drawing on prior work on kernels for sequentially ordered data [33], [23] follow a conceptually similar strategy as [52, 57], introducing a path signature kernel (PSK) for sequences of summary representations of persistence diagrams. ", "page_idx": 2}, {"type": "text", "text": "Along a different line of research, [28, 29] propose formigrams as summaries of dynamic metric data, encoding the evolution of connected components. In subsequent work, [30] construct multidimensional (i.e., spatiotemporal) persistent homology modules from dynamic metric data and compare invariants of these modules. While these works provide important theoretical stability results for zero-dimensional homological features, i.e., connected components, it is unclear how their construction extends to homological features of higher dimension in a tractable manner. However, it is worth pointing out that recent progress along the lines of vectorizations of multiparameter persistent homology [36] in combination with [30] (who essentially construct multiparameter persistence modules) might, in the future, constitute a tractable approach to study dynamically changing point clouds with learning methods. ", "page_idx": 2}, {"type": "text", "text": "Notably, computational challenges also arise in the context of crocker plots/stacks and PSKs. Despite their remarkable performance in distinguishing different configurations of models for collective behavior, both approaches suffer scalability issues: either (i) in terms of unfavorable scalability with respect to the dimensionality of vectorized persistence diagrams (as with the PSK approach of [23]), or (ii) in terms of unfavorable scalability with the number of observation sequences (as is the case for crocker plots/stacks, due to the need for extensive cross-validation of the discretization parameters). As we show in Sec. 4, our method not only outperforms these techniques by a large margin, but also scales to large amounts of training sequences and requires little hyperparameter tuning. ", "page_idx": 2}, {"type": "text", "text": "In addition to the closely related works discussed above, we highlight that there is a large body of literature on the topological analysis of time-varying signals, such as studying fMRI data via cubical persistence [47], or the persistent homology of delay embeddings [43, 44] of time series. In our context, however, these works are only partially related/relevant, as they do assume precise knowledge about individual trajectories over time (e.g., voxel IDs in fMRI data), which is unrealistic when seeking to infer parametrizations of models for collective behavior from data. ", "page_idx": 2}, {"type": "text", "text": "Inferring interaction laws for models of collective behavior. In the context of studying characteristics of collective behavior, there is a second line of closely related work on inferring interaction laws (see, e.g., [2, 5, 6, 27, 39, 61]), ranging from metric-distance-based models and topological interaction models to non-parametric estimators of interaction kernels. While a thorough survey of this literature is beyond the scope of this paper, we highlight that one common denominator in these works is their reliance on correspondences between points across time, e.g., to infer individual point velocities or trajectories. To give an example, in recent work [39, 61], the authors derive non-parametric estimators for interaction kernels (certain functions of pairwise distances) between observed points which crucially hinges on the traceability of each particle over time. While such approaches are conceptually appealing and even allow for reconstructing or extrapolating trajectories, they operate in the observation space. Even under a moderate number of points $m$ , computing these estimators becomes prohibitively expensive (as, e.g., in 3D, the state space is $\\mathbb{R}^{3m}$ ). In contrast, our approach only requires positional information and can handle larger point clouds. Furthermore, although we only present results on predicting parameters for a class of a priori specified governing equations, by formulating an auxiliary regression task, our underlying model may also be used to predict other quantities of interest. ", "page_idx": 2}, {"type": "text", "text": "", "page_idx": 3}, {"type": "text", "text": "Finally, taking a slightly broader perspective on prior art, we want to highlight recent progress on learning-based approaches that study inverse problems in the context of classic partial differential equations (PDEs). It might be possible to apply such approaches [37, 55, 60] to specific models of collective behavior such as volume exclusion [40], for which the asymptotics of infinitely many particles are solutions to parametric PDEs [42]. However, for other models, the number of particles strongly influences the dynamics. For instance, in the D\u2019Orsogna model [18], particle distances can collapse to zero as the number of particles tends to infinity. ", "page_idx": 3}, {"type": "text", "text": "3 Method ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "Below, we present our method with a focus on its application to modeling collective behavior in point clouds. Importantly, the latter represents only one of many conceivable use cases. In fact, the core ideas can be applied in exactly the same way whenever one can extract topological features from time-dependent data (e.g., graphs or images). ", "page_idx": 3}, {"type": "text", "text": "Notation. In the following, $\\mathcal{P}=\\left\\{\\mathbf{x}_{1},\\boldsymbol{\\cdot}...,\\mathbf{x}_{M}\\right\\}\\subset\\mathbb{R}^{3}$ denotes a point cloud with $M$ points and $d(\\mathbf{x},\\mathbf{y})\\,=\\,\\|\\mathbf{x}-\\mathbf{y}\\|$ denotes the Euclidean metric. Point clouds may be indexed by $t_{i}$ (or $\\tau_{i}$ ) to highlight the dependence on time $t_{i}$ . If necessary, we clearly distinguish between $\\tau_{i}$ as a time point with an available observation, and $t_{i}$ as a general placeholder for time. ", "page_idx": 3}, {"type": "text", "text": "Problem statement. Given a sequence of point clouds $\\mathcal{P}_{\\tau_{0}},\\ldots,\\mathcal{P}_{\\tau_{N}}$ , observed at possibly nonequidistant time points $\\tau_{i}$ , we (1) seek to model their topological evolution over time and then (2) use this model to predict the parametrization of an a priori defined governing equation of collective behavior. The latter is typically specified by a small number of parameters $\\beta_{1},\\ldots,\\beta_{P}$ that control the motions $\\mathrm{d}\\mathbf{x}_{i}/\\mathrm{d}t$ of individual points $\\mathbf{x}_{i}$ and specify (local) interactions among neighboring points. ", "page_idx": 3}, {"type": "text", "text": "As preparation for our model description, we first briefly establish how one may extract topological features from a point cloud $\\mathcal{P}$ , using persistent homology [3, 9, 22] \u2013 the arguably most prominent and computationally most feasible approach. ", "page_idx": 3}, {"type": "text", "text": "Persistent homology of point clouds. Persistent homology seeks to uncover and concisely summarize topological features of $\\mathcal{P}$ . To this end, one constructs a topological space from $\\mathcal{P}$ in the form of a simplicial complex, and studies its homology across multiple scales. The most relevant construction for our purposes is the Vietoris-Rips complex $\\mathrm{Rips}(\\mathcal{P})_{\\delta}$ , with vertex set $\\mathcal{P}$ . This complex includes an $m$ -simplex $\\left[\\mathbf{x}_{0},\\ldots,\\mathbf{x}_{m}\\right]$ iff $d(\\mathbf{x}_{i},\\mathbf{x}_{j})\\leq\\delta$ for all $0\\leq i,j\\leq m$ at a given threshold $\\delta$ . The \u201cshape\u201d of this complex can then be studied using homology, a tool from algebraic topology, with zerodimensional homology $\\left(\\mathrm{H}_{\\mathrm{0}}\\right)$ encoding information about connected components, one-dimensional homology $\\left(\\mathrm{H_{1}}\\right)$ encoding information about loops and two-dimensional homology $\\left(\\mathrm{H}_{2}\\right)$ encoding information about voids; we refer to this information as homological/topological features. Importantly, if $\\delta_{b}\\leq\\delta_{d}$ , then $\\mathrm{Rips}(\\mathcal{P})_{\\delta_{b}}\\subseteq\\mathrm{Rips}(\\mathcal{P})_{\\delta_{d}}$ , inducing a sequence of inclusions when varying $\\delta$ , called a flitration. The latter in turn induces a sequence of vector spaces $\\mathrm{H}_{k}(\\mathrm{Rips}({\\mathcal P})_{\\delta_{b}})\\to\\mathrm{H}_{k}(\\mathrm{Rips}({\\mathcal P})_{\\delta_{d}})$ at the homology level. Throughout this sequence, homological features (corresponding to basis vectors of the different vector spaces) may appear and disappear; we say they are born at some $\\delta_{b}$ and die at $\\delta_{d}>\\delta_{b}$ . For instance, a one-dimensional hole might appear at a particular value of $\\delta_{b}$ and disappear at a later $\\delta_{d}$ ; in other words, the hole persists from $\\delta_{b}$ to $\\delta_{d}$ , hence the name persistent homology. As different features may be born and die at the same time, the collection of (birth, death) tuples is a multiset of points, often represented in the form of a persistence diagram, which we denote as $\\mathrm{dgm}_{k}(\\mathrm{Rips}(\\mathcal{P}))$ . Here, the notation $\\mathrm{Rips}(\\mathcal{P})$ refers to the full filtration and $\\mathrm{dgm}_{k}$ indicates that we have tracked $k$ -dimensional homological features throughout this filtration. ", "page_idx": 3}, {"type": "text", "text": "Clearly this construction does not account for any temporal changes to a point cloud, but reveals features that are present at a specific time point. Furthermore, due to the inconvenient multiset structure of persistence diagrams for learning problems, one typically resorts to appropriate vectorizations (see, e.g., [1, 7, 10, 26]), all accounting for the fact that points close to the diagonal $\\Delta=\\{(x,x):x\\in{\\bar{\\mathbb{R}}}\\}$ contribute less (0 at $\\Delta$ ) to the vectorization. The latter is important to preserve stability (see paragraph below) with respect to perturbations of points in the diagram. In the following, we refer to a vectorized persistence diagram of a point cloud $\\mathcal{P}_{t_{i}}$ as ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\mathbf{v}_{t_{i},k}:=\\mathrm{vec}(\\mathrm{dgm}_{k}(\\mathrm{Rips}(\\mathcal{P}_{t_{i}})))\\,\\mathrm{~,~}\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "where $\\mathbf{v}_{t_{i},k}\\in\\mathbb{R}^{d}$ and $d$ is controlled by hyperparameter(s) of the chosen vectorization technique.   \nFor brevity, we omit the subscript $k$ when referring to vectorizations unless necessary. ", "page_idx": 4}, {"type": "text", "text": "Remark 1. As our goal is to model the dynamics of vectorized persistence diagrams using a continuous latent variable model, it is important to discuss the dependence of the vectorizations on the input data. In particular, for our modeling choice to be sound, vectorizations should vary (Lipschitz) continuously with changes in the point clouds over time. We discuss this aspect next. ", "page_idx": 4}, {"type": "text", "text": "Stability/Continuity aspects. First, we point out that persistence diagrams can be equipped with different notions of distance, most prominently the bottleneck distance and Wasserstein distances, both based upon the cost of an optimal matching between two diagrams, allowing for matches to the diagonal $\\Delta$ . We refer the reader to [12, 51] for a detailed review. Stability in the context of persistent homology is understood as persistence diagrams varying (Lipschitz) continuously with the input data. While seminal stability results exist for the Wasserstein distances [15] and the bottleneck distance [12, 14], most results from the literature focus on the latter. ", "page_idx": 4}, {"type": "text", "text": "In the case of vectorization techniques for persistence diagrams (e.g., [1, 26]), it turns out that, most of the time, vectorizations are only Lipschitz continuous with respect to Wasserstein distances, and existing results are typically of the form ", "page_idx": 4}, {"type": "equation", "text": "$$\nd(\\mathrm{vec}(F),\\mathrm{vec}(G))\\leq K\\,W_{1}(F,G)\\,\\,\\,,\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "where $W_{1}$ denotes the $(1,2)$ -Wasserstein distance as defined in [51, Def. 2.7], $F,G$ are two persistence diagrams and $K>0$ is a Lipschitz constant. In the context of Rem. 1, one may be tempted to combine Eq. (2) with the seminal Wasserstein stability theorem from [15] to infer stability of vectorizations with respect to the input data. Yet, the conditions imposed in [15] actually eliminate a direct application of this result in most practical cases, as discussed in [51]. However, the latter work also provides an alternative: in our particular case of Vietoris-Rips persistent homology, one can upper bound $W_{1}$ in terms of the standard point set Wasserstein distance $\\mathcal{W}_{1}$ . Specifically, upon relying on a stable vectorization technique, we obtain the inequality chain ", "page_idx": 4}, {"type": "equation", "text": "$$\nd(\\mathrm{vec}(F_{k}),\\mathrm{vec}(G_{k}))\\overset{[26,\\,\\mathrm{Thm.\\;12}]}{\\leq}K\\,W_{1}(F_{k},G_{k})\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "where $F_{k}\\,=\\,\\mathrm{dgm}_{k}(\\mathrm{Rips}(\\mathcal{P})).$ , $G_{k}\\,=\\,\\mathrm{dgm}_{k}(\\mathrm{Rips}(\\mathcal{Q}))$ denote the $k$ -dimensional persistence diagrams of point clouds $\\mathcal{P}$ and $\\mathcal{Q}$ of equal cardinality $M$ . In particular, we realize vec via the approach outlined in [26, Def. 10] using exponential structure elements [26, Def. 19]. ", "page_idx": 4}, {"type": "text", "text": "Overall, the continuity property in Eq. (3) guarantees that small changes in dynamic point clouds over time only induce small changes in their vectorized persistence diagrams, and therefore provides a solid justification for the model discussed next. ", "page_idx": 4}, {"type": "text", "text": "Latent variable model for persistence diagram vectorizations. As we presume that the dynamic point clouds under consideration are produced (or can be described sufficiently well) by equations of motions with only a few parameters, cf. Fig. 3, it is reasonable to assume that the dynamics of the (vectorized) persistence diagrams are equally governed by a somewhat simpler unobserved/latent dynamic process in $\\mathbb{R}^{z}$ with $z\\ll d$ . We model this latent dynamic process via a neural ODE [13, 49], learned in a variational Bayes regime1[32]. In this setting, one chooses a recognition/encoder network $(\\mathsf{E n c}_{\\theta})$ to parametrize an approximate variational posterior $q_{\\theta}(\\mathbf{z}_{t_{0}}|\\{\\mathbf{v}_{\\tau_{i}}\\}_{i})$ , an ODE solver to yield latent states $\\{\\mathbf{z}_{\\tau_{i}}\\}_{i}$ at observed time points $\\tau_{i}\\,\\in\\,[0,T]$ and a suitable generative/decoder network $\\scriptstyle({\\mathsf{D e c}}_{\\gamma})$ to implement the likelihood $p_{\\gamma}(\\mathbf{v}_{\\tau_{i}}|\\mathbf{z}_{\\tau_{i}})$ . Upon choosing a suitable prior $p(\\mathbf{z}_{t_{0}})$ , one can then train the model via ELBO maximization, i.e., ", "page_idx": 4}, {"type": "table", "img_path": "rCnZrFikX6/tmp/9d4042616f95b3a3af0a74c6bfa846490b09e7035e6e4f8a8bbbbb4df2841e62.jpg", "table_caption": [], "table_footnote": [], "page_idx": 5}, {"type": "text", "text": "", "page_idx": 5}, {"type": "equation", "text": "$$\n\\pmb{\\theta},\\gamma=\\arg\\operatorname*{max}_{\\pmb{\\theta},\\gamma}\\mathbb{E}_{\\mathbf{z}_{t_{0}}\\sim q_{\\theta}}\\Big[\\sum_{i}\\log p_{\\gamma}(\\mathbf{v}_{\\tau_{i}}|\\mathbf{z}_{\\tau_{i}})\\Big]-D_{\\mathrm{KL}}\\big(q_{\\theta}\\big(\\mathbf{z}_{t_{0}}|\\{\\mathbf{v}_{\\tau_{i}}\\}_{i}\\big)\\big|\\big|\\,p(\\mathbf{z}_{t_{0}})\\big)\\enspace.\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "Different to [49], we do not implement the recognition/encoder network via another neural ODE, but rather choose an attention-based approach (mTAN) [50] which can even be used in a standalone manner as a strong baseline (see Sec. 4). In our implementation, the recognition network yields the parametrization $(\\pmb{\\mu},\\pmb{\\Sigma})$ of a multivariate Gaussian in $\\mathbb{R}^{z}$ with diagonal covariance, and the prior is a standard Gaussian $\\mathcal{N}(\\mathbf{0},\\mathbf{I}_{z})$ . Furthermore, the ODE solver (e.g., Euler) can yield $\\mathbf{z}_{t_{i}}$ at any desired $t_{i}$ , however, we can only evaluate the ELBO at observed time points $\\tau_{i}$ . ", "page_idx": 5}, {"type": "text", "text": "Regression objective. To realize our downstream regression task, i.e., predicting parameters $\\beta_{1},\\ldots,\\beta_{P}$ of an underlying governing equation for collective behavior (see Fig. 3) from a given observation sequence, we have multiple choices. By our assumption of a latent dynamic process that carries information about the dynamic nature of the topological changes, it is reasonable to tie the simulation parameter estimates $\\hat{\\beta}_{1},\\ldots,\\hat{\\beta}_{P}$ to the latent path $\\{\\mathbf{z}_{t_{i}}\\}_{i}$ via a regression network $\\mathsf{R e g}_{\\alpha}$ that accepts $\\{\\mathbf{z}_{t_{i}}\\}_{i}$ as input. In particular, we re-use the attention-based encoder architecture Enc\u03b8 to allow attending to different parts of this path. However, different to $\\mathsf{E n c}_{\\theta}$ , which parametrizes the approximate posterior from observations at time points $\\tau_{i}$ , the regression network $\\mathsf{R e g}_{\\alpha}$ (with its own set of parameters $_{\\alpha}$ ) receives latent states $\\mathbf{z}_{t_{i}}$ at equidistant $t_{i}\\in[0,T]$ , then summarizes this sequence into a vector and linearly maps the latter to $\\hat{\\beta}_{1},\\ldots,\\hat{\\beta}_{P}$ , cf. Fig. 2. As in [49], for training, we extend the ELBO objective of Eq. (4) by an additive auxiliary regression loss, such as the mean-squared error (MSE), between the predictions $\\hat{\\beta}_{p}$ and the ground truth $\\beta_{p}$ , implicitly making a Gaussian noise assumption. ", "page_idx": 5}, {"type": "text", "text": "A schematic overview of our Neural Persistence Dynamics approach is shown in Fig. 1. Additional details, including different model variants, are illustrated in Fig. 2. ", "page_idx": 5}, {"type": "text", "text": "Remark 2. Clearly, our presented framework allows for many architectural choices. While some components affect downstream (regression) performance only marginally, others have a more profound impact, and we have already identified some recommended choices above (based on our experiments in Sec. 4). This includes (1) our choice of a stable persistent homology vectorization vec, where we rely on [26] due to consistently reliable performance without much hyperparameter tuning, and (2) our choice of recognition network, where we choose an attention-based approach (mTAN) [50] which has proven to be very effective in practice [58]. In Sec. 4.2, we will provide additional configuration details for our experimental study. ", "page_idx": 5}, {"type": "text", "text": "4 Experiments ", "text_level": 1, "page_idx": 5}, {"type": "text", "text": "4.1 Datasets ", "text_level": 1, "page_idx": 5}, {"type": "text", "text": "Similar to previous work [4, 23, 52, 57], we evaluate and compare our approach on simulation data that is generated from parametric models of collective behavior. Specifically, we consider three different models in $\\mathbb{R}^{3}$ : D\u2019Orsogna [18], Vicsek [20] and volume exclusion [40], using the publicly-available implementations in the SiSyPHE library $[21]^{2}$ . The corresponding equations of motion (and interaction laws) are summarized in Fig. 3. The parameters that are varied to generate the datasets, i.e., the response variables of the regression tasks, are highlighted in red. We sample these parameters, as specified in Appendix A, to cover a wide range of macroscopic behavioral regimes. For each sampled parameter configuration, we simulate one sequence of point clouds, to a total of 10,000 sequences per model. All simulations are run for 1,000 time steps (with step size 0.01, starting at $t=0$ ) on point clouds of size $M=200$ . We take every 10th time step as an observation, yielding observation sequences of length 100. At $t=0$ , points are drawn independently and uniformly in $[-0.5,0.5]^{3}$ , and initial velocities are uniformly distributed on the unit sphere. For direct comparison to [23], we also simulated their parameter configuration of the D\u2019Orsogna model. This setup yields four datasets: dorsogna- $1k$ (from [23]), dorsogna- $\\cdot7\\,0\\mathsf{k}$ , vicsek- $\\cdot1\\theta\\mathsf{k}$ and volex- $-1\\ominus\\mathsf{k}$ . ", "page_idx": 5}, {"type": "image", "img_path": "rCnZrFikX6/tmp/56d842c3df5291a62019823989489abdc002eeeecf7e708218cc98325fdda9d9.jpg", "img_caption": ["Figure 3: Models of collective behavior. Parameters that are varied to obtain different behavior are highlighted in red; the range of each parameter is listed in Appendix A. In the Vicsek model, $\\mathbf{B}_{t}$ denotes Brownian motion. "], "img_footnote": [], "page_idx": 6}, {"type": "text", "text": "", "page_idx": 6}, {"type": "text", "text": "4.2 Implementation, training & evaluation metrics ", "text_level": 1, "page_idx": 6}, {"type": "text", "text": "Implementation. The model variants from Fig. 2 can be realized in many ways. Below, we specify the configuration that was used to run the experiments. For the encoder $\\mathsf{E n c}_{\\theta}$ , as well as the regression network $\\mathsf{R e g}_{\\alpha}$ , we use the attention-based mTAN architecture [50]. As decoder network $\\mathsf{D e c}_{\\gamma}$ , we choose a two-layer MLP with ReLU activations, and as ODE solver, we select the Euler method. Each model is trained for 150 epochs using ADAM [31] (with a weight decay of 0.001), starting at a learning rate of 0.001 (decaying according to a cosine annealing schedule) and MSE as a reconstruction (i.e., to evaluate the first term in Eq. (4)) and regression loss. In case a model uses topological features, we use Ripser+ $^{\\cdot+}$ [59] to compute (prior to training) persistent homology of dimension up to two, i.e., $\\mathrm{H}_{0}$ , $\\mathrm{H}_{1}$ , and $\\mathrm{H}_{2}$ . Vectorizations of each persistence diagram are then obtained using exponential structure elements from [26, Def. 19]. In particular, we use 20 structure elements per diagram, which yields a $d=3\\cdot20$ dimensional representation per point cloud and time point. The location of each structure element is set to one of $20~k$ -means $^{++}$ cluster centers, obtained by running the latter on a random subset of 50,000 points (per dimension) selected from all persistence diagrams available during training; the scale parameter of each structure element is set according to [48, Eq. (2)]. To model the dynamics, we fix the latent space dimensionality to $z\\ =\\ 20$ and scale the ODE integration time to $[0,1]$ . While other settings are undoubtedly possible, we did not observe any noticeable benefits from increasing the dimensionality of the vectorizations or the latent space. Our publicly available reference implementation can be found at https://github.com/plus-rkwitt/neural_persistence_dynamics. ", "page_idx": 6}, {"type": "text", "text": "Evaluation metrics. We randomly partition each dataset into five training/testing splits of size 80/20. To obtain a robust performance estimate for different regimes of missing and unevenly spaced observations, we train three models (per split) using only a fraction (i.e., $20\\%$ , $50\\%$ , and $80\\%$ ) of randomly chosen time points per sequence. Similarly, all testing splits undergo the same sampling procedure. All scores (see below) are reported as an average $\\pm$ one standard deviation) over the five splits and the three time point sampling percentages. Specifically, we report the variance explained $(V E)$ [34] (in $[0,1]$ ; higher is better $\\uparrow$ ) and the symmetric mean absolute percentage error (SMAPE) (in $[0,1]$ ; lower is better $\\downarrow$ ). For each testing sequence in each split, the scores are computed from the true simulation parameters (see variables marked red in Fig. 3) and the corresponding predictions (denoted by $\\hat{\\beta}_{i}$ in Fig. 2). Finally, when reporting results on a dataset, we mark the best score in bold, as well as all other scores that do not show a statistically significant difference in mean (assessed via a Mann-Whitney test at $5\\%$ significance and correcting for multiple comparisons). ", "page_idx": 6}, {"type": "text", "text": "", "page_idx": 7}, {"type": "text", "text": "4.3 Ablation ", "text_level": 1, "page_idx": 7}, {"type": "text", "text": "In our ablation study, we assess (1) the relevance of different point cloud representations (PH vs. PointNet $++$ ), (2) any potential beneftis of modeling latent dynamics and (3) the impact of varying the observation timeframe. Additional ablation experiments can be found in Appendix B.3. ", "page_idx": 7}, {"type": "text", "text": "Are representations complementary? We first investigate the impact of different point cloud representations (from PH and PointNe $^{++}$ , resp.), by comparing variants v1,v2 and v3 from Fig. 2. ", "page_idx": 7}, {"type": "text", "text": "Tbl. 2 shows an extension of Tbl. 1, listing results for the vicsek- $16\\mathsf{k}$ and dorsogna-1k data. While using PointNet++ representations on vicsek-10k yields rather poor performance, combining them with representations computed from PH is at least not detrimental. On the other hand, on dorsogna-1k, where PointNet++ yields decent SMAPE and VE scores, the combination of both sources substantially outperforms each single source in isolation. Although, the complementary nature of a topological perspective on data has been pointed out many times in the literature, it is rarely as pronounced as in this ", "page_idx": 7}, {"type": "table", "img_path": "rCnZrFikX6/tmp/a69fbb3a9a5c995529f651fc4ba1644fc933f45a13760f14b2dfbea32ffa3777.jpg", "table_caption": ["Table 2: Ablation study on the relevance of different point cloud representations. "], "table_footnote": ["particular experiment. Hence, we will stick to the combination of $P H+$ PointNet++ representations (i.e., v3 in Fig. 2) in any subsequent experiments. "], "page_idx": 7}, {"type": "text", "text": "Are explicit latent dynamics beneficial? To assess the impact of explicitly modeling the dynamics of persistence diagram vectorizations, we ablate the latent ODE part of our model. In detail, we compare v3 from Fig. 2 against using $\\mathsf{R e g}_{\\alpha}$ operating directly on concatenated point cloud representations from PH and PointNet $^{++}$ (i.e., a combination of variants v4 & v5 from Fig. 2). The latter approach constitutes an already strong baseline (cf. [58]) as $\\mathsf{R e g}_{\\alpha}$ incorporates an attention mechanism that allows attending to relevant parts of each sequence. For a fair comparison, we increase the size of $\\mathsf{R e g}_{\\alpha}$ to approximately match the number of parameters to our latent dynamic model. ", "page_idx": 7}, {"type": "text", "text": "As in Tbl. 2, we list results for the vicsek- $101$ and dorsogna- $1k$ data in Tbl. 3. First, we see that explicitly modeling the latent dynamics is beneficial, with considerable improvements in the reported scores across both datasets. While differences are quite prominent on the dorsogna-1k data, they are less pronounced in the SMAPE score on vicsek$18\\mathsf{k}$ , but still statistically significant. Second, it is important to point out that even without any explicit latent dynamics, the regression performance (see Tbl. 4) is already above the current state-of-the-art (i.e., compared to PSK [23]), highlighting the necessity for strong baselines. ", "page_idx": 7}, {"type": "table", "img_path": "rCnZrFikX6/tmp/90a502a705c7c46b07b367f2265dc9e7cd0d4fbd54dbdfadabccf1b124dd7042.jpg", "table_caption": ["Table 3: Results on the relevance of latent dynamics. "], "table_footnote": [], "page_idx": 7}, {"type": "text", "text": "", "page_idx": 7}, {"type": "text", "text": "Impact of the observation timeframe. So far, we have presented results (as in prior work) where observation sequences are extracted from the beginning of a simulation (i.e., starting from $t_{0}=0$ ), which corresponds to observing the emergence of patterns out of a random yet qualitatively similar, initial configuration of points. In the following experiment, we investigate the impact of extracting observation sequences with starting points randomly spread across a much longer simulation time. ", "page_idx": 7}, {"type": "text", "text": "This is relevant as it is unlikely to observe uniform initial positions in any data obtained from realworld experiments. To this end, we create variations of the dorsogna- $18\\mathsf{k}$ data by progressively increasing the simulation time $T$ from 1,000 to 20,000 and then randomly extracting sub-sequences of length 1,000 (again, as before, taking each 10th step as an observation). The extension of the simulation timeframe has the effect that the difficulty of the learning task considerably increases with $T$ . We argue that this is due to the increased variation across the observed sequences while the amount of training data remains the same. For comparison, we also list results for the PSK approach of [23], however, only for the optimal case of observing all time points within a sequence (due to the massive PSK computation time; $>3$ days). As the PSK relies on persistent homology only, we limit our model to the v1 variant from Fig. 2. As seen from Fig. 4, we observe an increase/drop in SMAPE and VE, resp., for both approaches, yet our approach degrades much slower with $T$ . ", "page_idx": 8}, {"type": "image", "img_path": "rCnZrFikX6/tmp/7fcb8d968fdeb2ed45d0516efd140b39f035f76c04681f0605dab4ceab48b6fd.jpg", "img_caption": ["Figure 4: Impact of the maximal simulation time $T$ for extracting training/testing sequences starting at $\\tau_{0}\\in[0,T-1000]$ , assessed on the dorsogna- $\\cdot7\\,01$ dataset. "], "img_footnote": [], "page_idx": 8}, {"type": "text", "text": "4.4 Comparison to the state-of-the-art ", "text_level": 1, "page_idx": 8}, {"type": "text", "text": "Finally, we present parameter regression results on the full battery of datasets and compare against two of the most common approaches from the literature: the path signature kernel (PSK) of [23] and the crocker stacks approach from [57]. For both competitors, we report results when all time points are observed to establish a baseline of what could be achieved in the best case. Note that we evaluate the PSK approach [23] on exactly the same vectorizations as our approach, and we replicate their experimental setting of choosing the best hyperparameters via cross-validation. Similarly, for crocker stacks, we cross-validate the discretization parameters, see Appendices B.1 and B.2. Tbl. 4 lists the corresponding results. Aside from the observation that our approach largely outperforms the state-of-the-art across all parameter regression tasks, we also highlight that our model is trained with exactly the same hyperparameters on all datasets. ", "page_idx": 8}, {"type": "text", "text": "Remark 3. A closer look at the volex-10k dataset, in particular its governing equations in Fig. 3, shows that the cardinality of the point clouds may change over time due to cell division or death. While this is no practical limitation for our approach, our stability arguments from Eq. (3) no longer apply. We conjecture that one may be able to extend the result of [51] to account for such cases, but this might require a case-by-case analysis and possibly include additional assumptions. ", "page_idx": 8}, {"type": "text", "text": "5 Discussion ", "text_level": 1, "page_idx": 8}, {"type": "text", "text": "We introduced a framework to capture the dynamics observed in topological summary representations over time and presented one incarnation using a latent ODE on top of vectorized Vietoris-Rips persistence diagrams, addressing the problem of predicting parametrizations for models of collective behavior. Conceptually, Neural Persistence Dynamics embodies the idea of learning the dynamics in a temporal sequence of vectorized topological summaries instead of, e.g., trying to track individual homology classes over time (as with persistence vineyards, see Sec. 2). Our approach successfully scales to a large number of observation sequences, requires little to no parameter tuning, and vastly outperforms the current state-of-the-art, as demonstrated by several experiments on dynamic point cloud datasets with varying characteristics. Finally, we emphasize that the fundamental ideas of Neural Persistence Dynamics may also be applied to other types of time-varying data (e.g., graphs or images) and downstream objectives simply by adjusting the flitration choice. We hope that our work will stimulate further research in this direction. ", "page_idx": 8}, {"type": "table", "img_path": "rCnZrFikX6/tmp/80372e810d5500afb2056f4f49a5cf99b8dd4c114da59d49c34f975905f6964a.jpg", "table_caption": ["Table 4: Comparison to the state-of-the-art across four diverse datasets of collective behavior. Ours (joint) refers to the variant v3 of Fig. 2, Ours (PH-only) refers to variant v1. The latter setting is directly comparable to the PSK and crocker stacks approach. Best results are marked bold. Multiple bold entries indicate that there is no significant difference in mean. Note that dorsogna- $1\\mathbf{k}$ is simulated exactly as in [23] varying only two parameters, whereas for dorsogna-10k we vary four parameters (as with vicsek-10k and volex-10k). "], "table_footnote": [], "page_idx": 9}, {"type": "text", "text": "Limitation(s). One obvious limitation in the presented implementation is the reliance on VietorisRips persistent homology of point clouds. In fact, the underlying simplicial complex will become prohibitively large (especially for $\\mathrm{H_{2}}$ ) once we scale up the number of points by, e.g., an order of magnitude. Using an Alpha [22] or a Witness complex [19] might be a viable alternative to mitigate this issue. Similarly, one may explore subsampling strategies for persistent homology, as in [11], and learn a latent ODE from a combination of estimates. ", "page_idx": 9}, {"type": "text", "text": "Societal impact. The present work mainly deals with an approach to capture the dynamics observed in data representing collective behavior. We assume that this has no direct societal impact, but point out that any application of such a model (aside from synthetic data), e.g., in the context of behavioral studies on living beings or health sciences (e.g., to study the development of cancer cells), should be carefully reviewed. This is especially advisable when drawing conclusions from missing measurements, as these are based on imputations and may be biased. ", "page_idx": 9}, {"type": "text", "text": "Acknowledgments ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "This work was supported by the Land Salzburg within the EXDIGIT project 20204-WISS/263/6-6022 and projects 0102-F1901166- KZP, 20204-WISS/225/197-2019. M. Uray and S. Huber are supported by the Christian Doppler Research Association (JRC ISIA). We also thank all reviewers for the valuable feedback during the review process. ", "page_idx": 9}, {"type": "text", "text": "References ", "text_level": 1, "page_idx": 10}, {"type": "text", "text": "[1] H. Adams, T. Emerson, M. Kirby, R. Neville, C. Peterson, P. Shipman, S. Chepushtanova, E. Hanson, F. Motta, and L. Ziegelmeier. \u201cPersistence Images: A stable vector representation of persistent homology\u201d. In: JMLR 18.8 (2017), pp. 1\u201335. [2] M. Ballerini, N. Cabibbo, R. Candelier, V. D. F. D., E. Marinari, O. Pellizzola, G. Parisi, A. Viale, and V. Zdravkovic. \u201cInteraction ruling animal collective behavior depends on topological rather than metric distance: Evidence from a field study\u201d. In: PNAS 105.4 (2008), pp. 1232\u2013 1237.   \n[3] S. Barannikov. \u201cFramed Morse complex and its invariants\u201d. In: Adv. Soviet Math. 21 (1994), pp. 93\u2013115.   \n[4] D. Bhaskar, A. Manhart, J. Milzman, J. T. Nardini, K. M. Storey, C. M. Topaz, and L. Ziegelmeier. \u201cAnalyzing collective motion with machine learning and topology\u201d. In: Chaos 29.12 (2019), p. 123125. [5] W. Bialek, A. Cavanga, I. Giardina, and A. Walczak. \u201cStatistical mechanics for natural flocks of birds\u201d. In: PNAS 109.13 (2012), pp. 4786\u20134791.   \n[6] S. L. Brunton, J. L. Proctor, and J. N. Kutz. \u201cDiscovering govering equations from data by sparse identification of nonlinear dynamical systems\u201d. In: PNAS 113.15 (2016), pp. 3932\u2013 3937.   \n[7] P. Bubenik. \u201cStatistical Topological Data Analysis using Persistence Landscapes\u201d. In: JMLR 16.1 (2015), pp. 77\u2013102.   \n[8] G. Carlsson and V. de Silva. \u201cZigzag Persistence\u201d. In: Found. Comput. Math. 10.4 (2010), pp. 367\u2013405.   \n[9] G. Carlsson and M. Vejdemo-Johansson. Topological Data Analysis with Applications. Cambridge University Press, 2021.   \n[10] M. Carri\u00e8re, F. Chazal, Y. Ike, T. Lacombe, M. Royer, and Y. Umeda. \u201cPersLay: A Neural Network Layer for Persistence Diagrams and New Graph Topological Signatures\u201d. In: AISTATS. 2020.   \n[11] F. Chazal, B. Fasy, F. Lecci, B. Michel, A. Rinaldo, and L. Wasserman. \u201cSubsampling Methods for Persistent Homology\u201d. In: ICML. 2015.   \n[12] F. Chazal, V. de Silva, and S. Y. Oudot. \u201cPersistence Stability for Geometric Complexes\u201d. In: Geometriae Dedicata 173.1 (2014), pp. 193\u2013214.   \n[13] R. T. Q. Chen, Y. Rubanova, J. Bettencourt, and D. Duvenaud. \u201cNeural Ordinary Differential Equations\u201d. In: NeurIPS. 2018.   \n[14] D. Cohen-Steiner, H. Edelsbrunner, and J. Harer. \u201cStability of persistence diagrams\u201d. In: Discrete Comput. Geom. 37.1 (2007), pp. 103\u2013120.   \n[15] D. Cohen-Steiner, H. Edelsbrunner, J. Harer, and Y. Mileyko. \u201cLipschitz Functions Have $L_{p}$ -Stable Persistence\u201d. In: Found. Comput. Math. 10.2 (2010), pp. 127\u2013139.   \n[16] D. Cohen-Steiner, H. Edelsbrunner, and D. Morozov. \u201cVines and vineyards by updating persistence in linear time\u201d. In: SCG. 2006.   \n[17] P. Corcoran and C. B. Jones. \u201cModelling Topological Features of Swarm Behaviour in Space and Time With Persistence Landscapes\u201d. In: IEEE Access 5 (2017), pp. 18534\u201318544.   \n[18] M. R. DOrsogna, Y. L. Chuang, A. L. Bertozzi, and L. S. Chayes. \u201cSelf-Propelled Particles with Soft-Core Interactions: Patterns, Stability, and Collapse\u201d. In: Phys. Rev. Lett. 96.10 (2006), p. 104302.   \n[19] V. De Silva and G. Carlsson. \u201cTopological estimation using witness complexes\u201d. In: Sympos. Point-Based Graphics. 2004.   \n[20] P. Degond and S. Motsch. \u201cContinuum limit of self-driven particles with orientation interaction\u201d. In: Math. Models Methods Appl. Sci. 18.supp01 (2008), pp. 1193\u20131215.   \n[21] A. Diez. \u201cSiSyPHE: A Python package for the Simulation of Systems of interacting mean-field Particles with High Efficiency\u201d. In: J. Open Source Softw. 6.65 (2021), p. 3653.   \n[22] H. Edelsbrunner and J. Harer. Computational Topology. An Introduction. AMS, 2010.   \n[23] C. Giusti and D. Lee. \u201cSignatures, Lipschitz-Free Spaces, and Paths of Persistence Diagrams\u201d. In: SIAM J. Appl. Algebra Geom. 7.4 (2023), pp. 828\u2013866.   \n[24] Y. Guo, H. Wang, Q. Hu, H. Liu, and M. Bennamoun. \u201cDeep Learning for 3D point clouds: A survey\u201d. In: TPAMI 43.12 (2021), pp. 4338\u20134364.   \n[25] M. Hajij, B. Wang, C. Scheidegger, and P. Rosen. \u201cVisual Detection of Structural Changes in Time-Varying Graphs Using Persistent Homology\u201d. In: PacificVis. 2018.   \n[26] C. Hofer, R. Kwitt, and M. Niethammer. \u201cLearning representations of persistence barcodes\u201d. In: JMLR 20.126 (2019), pp. 1\u201345.   \n[27] Y. Katz, K. Tunstr\u00f8m, C. C. Ioannou, C. Huepe, and I. D. Couzin. \u201cInferring individual rules from collective behavior\u201d. In: PNAS 108.46 (2010), pp. 18720\u201318725.   \n[28] W. Kim and F. Memoli. \u201cFormigrams: Clustering Summaries of Dynamic Data\u201d. In: CCCG. 2018.   \n[29] W. Kim and F. M\u00e9moli. \u201cExtracting Persistent Clusters in Dynamic Data via M\u00f6bius inversion\u201d. In: Discrete Comput. Geom. 71 (2024), pp. 1276\u20131342.   \n[30] W. Kim and F. M\u00e9moli. \u201cSpatiotemporal Persistent Homology for Dynamic Metric Spaces\u201d. In: DCG 66.4 (2021), pp. 831\u2013875.   \n[31] D. P. Kingma and J. Ba. \u201cAdam: A Method for Stochastic Optimization\u201d. In: ICLR. 2015.   \n[32] D. P. Kingma and M. Welling. \u201cAuto-Encoding Variational Bayes\u201d. In: ICLR. 2014.   \n[33] F. J. Kiraly and H. Oberhauser. \u201cKernels for sequentially ordered data\u201d. In: JMLR 20.31 (2019), pp. 1\u201345.   \n[34] J. Li. \u201cAssessing the accuracy of predictive models for numerical data: Not $r$ nor $r^{2}$ , why not? Then what?\u201d In: PLOS ONE 12.8 (2017), e0183250.   \n[35] X. Li, T.-K. L. Wong, R. T. Q. Chen, and D. Duvenaud. \u201cScalable Gradients for Stochastic Differential Equations\u201d. In: AISTATS. 2020.   \n[36] D. Loiseaux, L. Scoccola, M. Carri\u00e8re, M. B. Botnan, and S. Oudot. \u201cStable Vectorization of Multiparameter Persistent Homology using Signed Barcodes as Measures\u201d. In: NeurIPS. 2023.   \n[37] D. Long and S. Zhe. Invertible Fourier Neural Operators for Tackling Both Forward and Inverse Problems. 2024. arXiv: 2402.11722 [cs.LG].   \n[38] M. L\u00f6ning, A. Bagnall, S. Ganesh, V. Kazakov, J. Lines, and F. J. Kir\u00e1ly. \u201csktime: A Unified Interface for Machine Learning with Time Series\u201d. In: Workshop on Systems for ML at NeurIPS. 2019.   \n[39] F. Lu, M. Zhong, S. Tang, and M. Maggioni. \u201cNonparametric inference of interaction laws in systems of agents from trajectory data\u201d. In: PNAS 116.29 (2019), pp. 14424\u201314433.   \n[40] S. Motsch and D. Peurichard. \u201cFrom short-range repulsion to Hele-Shaw problem in a model of tumor growth\u201d. In: J. Math. Biol. 76 (2018), pp. 205\u2013234.   \n[41] E. Munch. \u201cApplications of Persistent Homology to Time Varying Systems\u201d. PhD thesis. Duke University, 2013.   \n[42] K. Oelschl\u00e4ger. \u201cLarge systems of interacting particles and the porous medium equation\u201d. In: J. Differ. Equ. 88.2 (1990), pp. 294\u2013346.   \n[43] J. A. Perea, A. Deckard, S. B. Haase, and J. Harer. \u201cSW1PerS: Sliding windows and 1- persistence scoring; discovering periodicity in gene expression time series data\u201d. In: BMC Bioinform 16.1 (2015), p. 257.   \n[44] J. A. Perea and J. Harer. \u201cSliding windows and persistence: An application of topological methods to signal analysis\u201d. In: Found. Comput. Math. 15.3 (2015), pp. 799\u2013838.   \n[45] C. R. Qi, L. Yi, H. Su, and L. J. Guibas. \u201cPointNet $^{++}$ : Deep Hierarchical Feature Learning on Point Sets in a Metric Space\u201d. In: NeurIPS. 2017.   \n[46] D. Rempe, T. Birdal, Y. Zhao, Z. Gojcic, S. Sridhar, and L. J. Guibas. \u201cCaSPR: Learning Canonical Spatiotemporal Point Cloud Representations\u201d. In: NeurIPS. 2020.   \n[47] B. Rieck, T. Yates, C. Bock, K. Borgwardt, G. Wolf, N. Turk-Browne, and S. Krishnaswamy. \u201cUncovering the topology of time-varying fMRI data using cubical persistence\u201d. In: NeurIPS. 2020.   \n[48] M. Royer, F. Chazal, C. Levrard, Y. Umeda, and Y. Ike. \u201cATOL: Measure Vectorization for Automatic Topologically-Oriented Learning\u201d. In: AISTATS. 2021.   \n[49] Y. Rubanova, R. T. Q. Chen, and D. K. Duvenaud. \u201cLatent Ordinary Differential Equations for Irregularly-Sampled Time Series\u201d. In: NeurIPS. 2019.   \n[50] S. N. Shukla and B. M. Marlin. \u201cMulti-Time Attention Networks for Irregularly Sampled Time Series\u201d. In: ICLR. 2021.   \n[51] P. Skraba and K. Turner. Wasserstein Stability for Persistence Diagrams. 2023. arXiv: 2006. 16824 [math.AT].   \n[52] C. M. Topaz, L. Ziegelmeier, and T. Halverson. \u201cTopological Data Analysis of Biological Aggregation Models\u201d. In: PLOS ONE 10.5 (2015), pp. 1\u201326.   \n[53] R. Turkes, G. Montufar, and N. Otter. \u201cOn the Effectiveness of Persistent Homology\u201d. In: NeurIPS. 2022.   \n[54] S. Tymochko, E. Munch, and F. A. Khasawneh. \u201cUsing Zigzag Persistent Homology to Detect Hopf Bifurcations in Dynamical Systems\u201d. In: Algorithms 13.11 (2020), p. 278.   \n[55] A. Vadeboncoeur, \u00d6. D. Akyildiz, I. Kazlauskaite, M. Girolami, and F. Cirak. \u201cFully probabilistic deep models for forward and inverse problems in parametric PDEs\u201d. In: J. Comput. Phys. 491.C (2023).   \n[56] T. Vicsek, A. Czir\u00f3k, E. Ben-Jacob, I. Cohen, and O. Shochet. \u201cNovel type of phase transition in a system of self-driven particles\u201d. In: Phys. Rev. Lett. 75.6 (1995), pp. 1226\u20131229.   \n[57] L. Xian, H. Adams, C. M. Topaz, and L. Ziegelmeier. \u201cCapturing dynamics of time-varying data via topology\u201d. In: Found. Data Sci. 4.1 (2022), pp. 1\u201336.   \n[58] S. Zeng, F. Graf, and R. Kwitt. \u201cLatent SDEs on Homogeneous Spaces\u201d. In: NeurIPS. 2023.   \n[59] S. Zhang, M. Xiao, and H. Wang. \u201cGPU-Accelerated Computation of Vietoris-Rips Persistence Barcodes\u201d. In: SCG. 2020.   \n[60] Q. Zhao, D. B. Lindbell, and G. Wetzstein. \u201cLearning to Solve PDE-constrained Inverse Problems with Graph Networks\u201d. In: ICML. 2022.   \n[61] M. Zhong, J. Miller, and M. Maggioni. \u201cData-driven discovery of emergent behavior in collective dynamics\u201d. In: Physica D 411 (2020), p. 132542. ", "page_idx": 10}, {"type": "text", "text": "", "page_idx": 11}, {"type": "text", "text": "", "page_idx": 12}, {"type": "text", "text": "Supplementary material ", "text_level": 1, "page_idx": 13}, {"type": "text", "text": "Comparison(s) to prior work & Additional ablation experiments 15   \nB.1 Path Signature Kernel (PSK) [23] . . . . 15   \nB.2 Crocker stacks [57] . . . 15   \nB.3 Additional ablation experiments . . . 16 ", "page_idx": 13}, {"type": "text", "text": "C Computational resources 16 ", "page_idx": 13}, {"type": "text", "text": "D Runtime analysis 16 ", "page_idx": 13}, {"type": "text", "text": "A Simulation settings ", "text_level": 1, "page_idx": 13}, {"type": "text", "text": "As mentioned in Sec. 4.1, we create datasets of dynamic point clouds from simulations. All simulations are run with 200 points for 1,000 steps with a step size of 0.01, and every 10th step is taken as an observation. Only for the final ablation experiment of Sec. 4.3 (i.e., Impact of the observation timeframe), we simulate 20,000 time steps (of the D\u2019Orsogna model) and extract training/testing sequences from this extended timeframe. The model parameters for these simulations are randomly sampled as specified below, and for each sampled parameter tuple, we create one simulation. ", "page_idx": 13}, {"type": "text", "text": "To create the dorsogna- $1\\,0\\kappa$ dataset, we vary the following model parameters (see Fig. 3): overall, we have four parameters that need to be predicted. As macroscopic regimes mainly depend on the ratios $C_{r}/C_{a}$ and $l_{r}/l_{a}$ , cf. [18, Fig. 1], we fix $C_{a}=l_{a}=1$ and sample $\\bar{C}_{r}=2^{t_{C}}$ , $l_{r}=\\bar{2}^{t_{l}}$ with uniformly distributed $t_{C}\\sim\\mathcal{U}_{[-1,1]}$ and $t_{l}\\sim\\mathcal{U}_{[-1.5,0.5]}$ . Similarly, we sample $\\alpha=2^{t_{\\alpha}}$ with $t_{\\alpha}\\sim\\mathcal{U}_{[-2,2]}$ and $m=2^{t_{m}}$ with $t_{m}\\sim\\mathcal{U}_{[-2,2]}$ . The model from the SiSyPHE library used to implement this simulation is AttractionRepulsion. Note, that the SiSyPHE library implements the mass $m$ in terms of the interaction radius parameter $R$ , i.e., $m=R^{3}$ (as we simulate point clouds in 3D). ", "page_idx": 13}, {"type": "text", "text": "Remark 4. For comparability (and interpretability of the parameters) to the original $D$ \u2019Orsogna model from [18], we adjusted the AttractionRepulsion implementation of SiSyPHE to directly match [18, Eqs. (2) & $(3)J.$ . ", "page_idx": 13}, {"type": "text", "text": "The dorsogna-1k dataset is created by re-running the simulation provided as part of the public (Julia) implementation3of [23]. This dataset has two parameters to predict. Note that in [23], the authors simulated 500 sequences. For our work, we simulated 1,000 to have a larger dataset, but still one magnitude smaller than dorsogna- $\\cdot7\\,\\theta\\mathbf{k}$ , vicsek- $\\cdot7\\,0\\mathsf{k}$ and $v o1e x{-1\\,\\theta}{\\sf k}$ . For this dataset, particle masses are $m=1$ , propulsion is $\\alpha=1$ , $C_{a}=l_{a}=1$ and $C_{r},l_{r}$ vary uniformly in [0.1, 2], and are selected if the generated point clouds satisfy a certain scale condition, leading to the parameter pairs illustrated in [23, Fig. 6]. ", "page_idx": 13}, {"type": "text", "text": "For the vicsek- $-1\\theta\\mathsf{k}$ dataset, we sample $R,c,\\nu$ uniformly from $\\mathcal{U}_{[0.5,5]}$ and $D$ from $\\mathcal{U}_{[0,2]}$ . Overall, this gives four parameters that need to be predicted. ", "page_idx": 13}, {"type": "text", "text": "Finally, for the volex $-1\\theta\\mathsf{k}$ dataset, we sample four parameters as follows: $\\alpha\\sim\\mathcal{U}_{[0,2]}$ , interaction radii $R\\sim\\mathcal{U}_{[0,2]}$ and birth/death rates $\\lambda_{b},\\lambda_{d}\\sim\\mathcal{U}_{[0,1]}$ . However, for the latter two parameters, we discard settings where $\\lambda_{d}>\\lambda_{b}$ as, in this case, death rates are almost impossible to distinguish; also, we discard settings where $\\lambda_{b}\\gg\\lambda_{d}$ as the resulting point cloud cardinalities exceed 2000 points during the simulation. The resulting $(\\lambda_{b},\\lambda_{d})$ combinations are illustrated in Fig. 5. ", "page_idx": 13}, {"type": "image", "img_path": "rCnZrFikX6/tmp/e72c79903aca3c085bb20f87a4148b77adf8ca2dc8f6162d8c4a8cdb0d890a1a.jpg", "img_caption": ["Figure 5: Birth rates $\\lambda_{b}$ and death rates $\\lambda_{d}$ used for generating the volex-10k dataset. "], "img_footnote": [], "page_idx": 14}, {"type": "text", "text": "For reproducibility, we will release the simulation data publicly. ", "page_idx": 14}, {"type": "text", "text": "B Comparison(s) to prior work & Additional ablation experiments ", "text_level": 1, "page_idx": 14}, {"type": "text", "text": "B.1 Path Signature Kernel (PSK) [23] ", "text_level": 1, "page_idx": 14}, {"type": "text", "text": "For the PSK, we rely on the publicly available implementation in sktime4 [38]. We compute the PSK (truncated at signature depth 3) using our vectorized persistence diagrams per time point as input. For concatenated zero-, one- and two-dimensional persistence diagrams, we use 20-dimensional vectorizations (as specified in Sec. 4.2), yielding 60-dimensional input vectors per time point. The computed kernel is then input to a kernel support vector regressor (kernel-SVR). ", "page_idx": 14}, {"type": "text", "text": "Following the experimental protocol in [23, Sec. 7.3], we cross-validate the sliding window embedding (across lags [1, 2, 3]) and kernel-SVR hyperparameters on a $20\\%$ validation portion of the training data, with hyperparameters selected based on the average MSE (per governing equation parameter $\\beta_{i}$ to be predicted) across 5-folds. Due to the excessive runtime (approx. 8.3 hours per lag on the system specified in Appendix C), we only report results when all time points per observation sequence are considered. Hence, no subsampling of time points (as is done when evaluating our approach) is performed, and the reported performance can be considered an optimistic estimate of what can be achieved with the PSK. ", "page_idx": 14}, {"type": "text", "text": "B.2 Crocker stacks [57] ", "text_level": 1, "page_idx": 14}, {"type": "text", "text": "As mentioned in Sec. 4.4, we compare against crocker stacks, introduced in [57], as one of the state-of-the-art approaches. Crocker stacks are an extension to crocker plots [52] and constitute a topological summary for time-varying persistence diagrams. For the crocker stacks, we adapted the publicly available implementation of the crocker plots in the teaspoon5library. ", "page_idx": 14}, {"type": "text", "text": "The crocker plot is computed as follows: for each time step, the persistence diagrams are computed up to a scale parameter $\\varepsilon$ . In discretized steps of the scale parameter, the Betti numbers are computed from the persistence diagrams, which results in a 2D representation (i.e., $\\epsilon$ vs. Betti number) for each homology dimension. ", "page_idx": 14}, {"type": "text", "text": "The extension to crocker stacks is achieved by adding a third dimension $k$ , induced by the smoothing factor $\\alpha$ . For given steps of $\\alpha$ , a smoothing operation is applied, i.e., values within a specified distance (smoothing factor) from the diagonal of the persistence diagram are ignored. Hence, for each homology dimension, a crocker stack is a tensor in $\\bar{\\mathbb{R}}^{3}$ , with axes corresponding to discretizations of the (1) scale parameter $\\varepsilon\\in[0,\\infty)$ , the (2) time $t\\in[0,T]$ , and the (3) smoothing factor $\\alpha\\in[0,\\infty)$ . ", "page_idx": 14}, {"type": "text", "text": "We note that in [57], the authors set the scale parameter to $\\delta=0.35$ , as they use data normalized to the range of 0 to 1. We did not scale the data, however, we adjusted the scale parameter correspondingly: ", "page_idx": 14}, {"type": "text", "text": "for all experiments, we set the scale parameter to $\\delta\\,=\\,^{1}\\!/3\\cdot\\operatorname{maxPers}(\\operatorname{dgm}_{k}(\\operatorname{Rips}(\\mathcal{P})))$ , where $\\mathcal{P}$ denotes the point cloud, and maxPers $\\left\\langle\\mathrm{dgm}_{k}(\\mathrm{Rips}(\\mathcal{P}))\\right\\rangle$ is the maximum persistence obtained from all point clouds in an observed sequence. ", "page_idx": 15}, {"type": "text", "text": "Hyperparameter choices. We made the following hyperparameter choices: (1) the Vietoris-Rips filtration is considered up to $\\delta$ (see above), where the computations are discretized with 25 equally spaced values in $[0,\\varepsilon]$ ; (2) the smoothing values are discretized with 18 steps equally spaced in $[0,0.5\\cdot\\mathrm{maxPers}]$ . ", "page_idx": 15}, {"type": "text", "text": "Eventually, the crocker stacks per homology dimension are vectorized (i.e., the tensor is flattened) and concatenated into a single vector per observation sequence. These vectorizations are then input to a linear support vector regressor (SVR). For each of the (varied) parameters in the governing equation of Fig. 3, a separate SVR is trained and evaluated. Hyperparameters of the SVR and the usage of preprocessing steps (feature scaling) are tuned using Bayesian optimization. Each parameter configuration is evaluated using a 5-fold cross-validation, and the best configuration is then used to train the final model on the full dataset. ", "page_idx": 15}, {"type": "text", "text": "B.3 Additional ablation experiments ", "text_level": 1, "page_idx": 15}, {"type": "text", "text": "To assess whether homology dimensions $>0$ are beneficial to the downstream regression task, we experimented on dorsogna-1k. We find that when using our approach with $\\mathrm{H}_{0}$ -features only, the regression quality drops. When additionally including $H_{2}$ -features (i.e., $\\mathrm{H}_{0}$ , $\\mathrm{H_{1}}$ and $\\mathrm{H}_{2}$ ), the situation is less clear, as the results are not noticeably different. Quantitative results can be found in Tbl. 5 below. ", "page_idx": 15}, {"type": "table", "img_path": "rCnZrFikX6/tmp/506f2c52df30513c9686a8919f0dbafefb4d4aa0d8379a6a9c842da7274ba4e8.jpg", "table_caption": ["Table 5: Quantitative assessment of the impact of including higher-dimensional homology features on downstream regression performance, evaluated on dorsogna- $\\cdot\\uparrow k$ . "], "table_footnote": [], "page_idx": 15}, {"type": "text", "text": "C Computational resources ", "text_level": 1, "page_idx": 15}, {"type": "text", "text": "All experiments were run on an Ubuntu Linux system (22.04), running kernel 5.15.0-100-generic, with 34 Intel $^\\mathrm{\\textregistered}$ Core\u2122i9-10980XE CPU $\\ @\\ 3.00\\mathrm{GHz}$ cores, $128\\ \\mathrm{GB}$ of main memory, and two NVIDIA GeForce RTX 3090 GPUs. ", "page_idx": 15}, {"type": "text", "text": "D Runtime analysis ", "text_level": 1, "page_idx": 15}, {"type": "text", "text": "In the following, we present a runtime breakdown of the pre-processing steps (i.e., Vietoris-Rips persistent homology (PH) computation, and the vectorization of persistence diagrams), as well as a runtime comparison to prior work (PSK and crocker stacks) and our baseline approach. Runtime is measured on the system listed above, using our publicly-available reference implementation. ", "page_idx": 15}, {"type": "text", "text": "At this point, it is also worth highlighting that our pre-processing step, i.e., PH computation & vectorization, is trivially parallelizable and can easily be distributed across multiple CPUs/GPUs if needed. ", "page_idx": 15}, {"type": "text", "text": "Vietoris-Rips PH computation. In Tbl. 6, we list wall clock time measurements (using Ripser $^{++}$ [59] on one GPU) per point cloud. In particular, the table lists runtime for computing PH of dimension zero and one (i.e., $\\mathrm{H}_{0}$ and $\\mathrm{H}_{1}$ ), as well as PH of dimension zero, one and two (i.e., $\\mathrm{H}_{0},\\mathrm{H}_{1}$ and $\\mathrm{H}_{2}$ ). All point clouds in this experiment are of size 200 in $\\mathbb{R}^{3}$ . ", "page_idx": 15}, {"type": "text", "text": "Persistence diagram vectorization. Persistence diagram (PD) vectorization can essentially be broken down into two steps: (1) parameter ftiting for the structure elements of [26] and (2) mapping PDs to vector representations using those structure elements. Tbl. 7 lists the runtime for both steps on the dorsogna- $\\cdot\\uparrow k$ data when vectorizing zero-, and one-dimensional persistence diagrams. Throughout ", "page_idx": 15}, {"type": "text", "text": "Table 6: Runtime comparison for $P H$ computation for different homology dimensions. Reported is the average runtime per point cloud (in seconds), and the overall runtime (in seconds) estimated from this average by multiplying by the number of processed point clouds on dorsogna- $\\cdot\\uparrow k$ . ", "page_idx": 16}, {"type": "table", "img_path": "rCnZrFikX6/tmp/4c23711729091bc21f3b5f4b8e6bd7bee6d94ba35bfa5a578b25e2c179e1c03c.jpg", "table_caption": [], "table_footnote": [], "page_idx": 16}, {"type": "text", "text": "all of our experiments, parameter fitting for the structure elements is done by first collecting all persistence diagrams for each homology dimension and then running $k$ -means $^{++}$ clustering on 50,000 points uniformly sampled points from those diagrams. ", "page_idx": 16}, {"type": "table", "img_path": "rCnZrFikX6/tmp/9bbfc8df4762ebd05e6fa26068c64a1d26f10652f2d6d11cf9f22e78f20b2e03.jpg", "table_caption": ["Table 7: Runtime breakdown of $P D$ vectorization (per diagram and overall for $\\mathrm{H}_{0}$ and $\\mathrm{H}_{1}$ on dorsogna-1k), split into (Step 1) time spent for ftiting the parameters of the exponential structure elements from [26], and (Step 2) actually mapping PDs to vector representations. "], "table_footnote": [], "page_idx": 16}, {"type": "text", "text": "Comparison to prior work. Next, we compare the runtime of our approach (here, variant v1 from Fig. 2) to prior work that uses persistence diagrams as input. In particular, we compare against the PSK method from [23] and crocker stacks [57]. ", "page_idx": 16}, {"type": "text", "text": "In Tbl. 8, we list the overall training time (on dorsonga-1k), where runtime for pre-processing (see above) is excluded from these measurements. Also, PSK and crocker stacks timings do include hyperparameter optimization, as suggested in the corresponding references. Importantly, this is not optional but required to obtain decent performance with respect to EV and SMAPE. Notably, for the PSK approach, kernel computation scales quadratically with the number of sequences, and kernel-SVR training takes time somewhere between quadratic and cubic. Hence, scaling up the number of training sequences quickly becomes computationally prohibitive, especially in light of the required hyperparameter tuning. Finding suitable hyperparameters is also the main bottleneck for crocker stacks (which rely on a linear SVR). ", "page_idx": 16}, {"type": "table", "img_path": "rCnZrFikX6/tmp/95481e19fb6f3825eb71d47a4d71d31fc11d7c583f648c4f43a19f02dca5bda4.jpg", "table_caption": ["Table 8: Training time comparison to prior work (on dorsogna-1k). "], "table_footnote": [], "page_idx": 16}, {"type": "text", "text": "", "page_idx": 16}, {"type": "text", "text": "Comparison to baseline model. Finally, in Tbl. 9, we present a training time comparison to our baseline model which does not explicitly model any dynamics via a latent ODE (denoted as w/o dynamics). In this experiment, the training protocol remains unchanged, and we vary the type of input data, i.e., from using vectorized persistence diagrams only $\\mathrm{H_{0}}$ and $\\mathrm{H_{1}}$ ) to using a combination of PointNet++ features and vectorized persistence diagrams. Importantly, as remarked in the main part of the manuscript, the baseline models (PH-only, v1) and $(\\mathrm{PH+PointNet++},\\lor$ 3) already yields strong performance across all parameter prediction problems. ", "page_idx": 16}, {"type": "table", "img_path": "rCnZrFikX6/tmp/250c69c1af4839eedaaef926c2654368ae7921bf69c48b409729eeabb6914fe6.jpg", "table_caption": ["Table 9: Training time comparison (on dorsogna-1k) of our approach vs. the baseline model (w/o dynamics), using the same input data. "], "table_footnote": [], "page_idx": 16}, {"type": "text", "text": "NeurIPS Paper Checklist ", "text_level": 1, "page_idx": 17}, {"type": "text", "text": "1. Claims ", "text_level": 1, "page_idx": 17}, {"type": "text", "text": "Question: Do the main claims made in the abstract and introduction accurately reflect the paper\u2019s contributions and scope? ", "page_idx": 17}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 17}, {"type": "text", "text": "Justification: Claims made in the abstract are backed up by ablation experiments and comparisons to prior work & baselines. ", "page_idx": 17}, {"type": "text", "text": "Guidelines: ", "page_idx": 17}, {"type": "text", "text": "\u2022 The answer NA means that the abstract and introduction do not include the claims made in the paper.   \n\u2022 The abstract and/or introduction should clearly state the claims made, including the contributions made in the paper and important assumptions and limitations. A No or NA answer to this question will not be perceived well by the reviewers.   \n\u2022 The claims made should match theoretical and experimental results, and reflect how much the results can be expected to generalize to other settings.   \n\u2022 It is fine to include aspirational goals as motivation as long as it is clear that these goals are not attained by the paper. ", "page_idx": 17}, {"type": "text", "text": "2. Limitations ", "text_level": 1, "page_idx": 17}, {"type": "text", "text": "Question: Does the paper discuss the limitations of the work performed by the authors? ", "page_idx": 17}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 17}, {"type": "text", "text": "Justification: Sec. 5 of the manuscript specifically addresses limitations of the proposed approach. ", "page_idx": 17}, {"type": "text", "text": "Guidelines: ", "text_level": 1, "page_idx": 17}, {"type": "text", "text": "\u2022 The answer NA means that the paper has no limitation while the answer No means that the paper has limitations, but those are not discussed in the paper.   \n\u2022 The authors are encouraged to create a separate \"Limitations\" section in their paper.   \n\u2022 The paper should point out any strong assumptions and how robust the results are to violations of these assumptions (e.g., independence assumptions, noiseless settings, model well-specification, asymptotic approximations only holding locally). The authors should reflect on how these assumptions might be violated in practice and what the implications would be.   \n\u2022 The authors should reflect on the scope of the claims made, e.g., if the approach was only tested on a few datasets or with a few runs. In general, empirical results often depend on implicit assumptions, which should be articulated.   \n\u2022 The authors should reflect on the factors that influence the performance of the approach. For example, a facial recognition algorithm may perform poorly when image resolution is low or images are taken in low lighting. Or a speech-to-text system might not be used reliably to provide closed captions for online lectures because it fails to handle technical jargon.   \n\u2022 The authors should discuss the computational efficiency of the proposed algorithms and how they scale with dataset size.   \n\u2022 If applicable, the authors should discuss possible limitations of their approach to address problems of privacy and fairness.   \n\u2022 While the authors might fear that complete honesty about limitations might be used by reviewers as grounds for rejection, a worse outcome might be that reviewers discover limitations that aren\u2019t acknowledged in the paper. The authors should use their best judgment and recognize that individual actions in favor of transparency play an important role in developing norms that preserve the integrity of the community. Reviewers will be specifically instructed to not penalize honesty concerning limitations. ", "page_idx": 17}, {"type": "text", "text": "3. Theory Assumptions and Proofs ", "text_level": 1, "page_idx": 17}, {"type": "text", "text": "Question: For each theoretical result, does the paper provide the full set of assumptions and a complete (and correct) proof? ", "page_idx": 17}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 18}, {"type": "text", "text": "Justification: Our justification for the modeling choice relies on two previous stability results for persistent homology. When discussing the stability claim in Sec. 3, we list exact references to theorems in the literature that lead to this result. ", "page_idx": 18}, {"type": "text", "text": "Guidelines: ", "page_idx": 18}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include theoretical results.   \n\u2022 All the theorems, formulas, and proofs in the paper should be numbered and crossreferenced.   \n\u2022 All assumptions should be clearly stated or referenced in the statement of any theorems.   \n\u2022 The proofs can either appear in the main paper or the supplemental material, but if they appear in the supplemental material, the authors are encouraged to provide a short proof sketch to provide intuition.   \n\u2022 Inversely, any informal proof provided in the core of the paper should be complemented by formal proofs provided in appendix or supplemental material.   \n\u2022 Theorems and Lemmas that the proof relies upon should be properly referenced. ", "page_idx": 18}, {"type": "text", "text": "4. Experimental Result Reproducibility ", "text_level": 1, "page_idx": 18}, {"type": "text", "text": "Question: Does the paper fully disclose all the information needed to reproduce the main experimental results of the paper to the extent that it affects the main claims and/or conclusions of the paper (regardless of whether the code and data are provided or not)? ", "page_idx": 18}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 18}, {"type": "text", "text": "Justification: We provide all experimental details in the main part of the paper and the appendix. Furthermore, source code (and data) is publicly-available at https://github. com/plus-rkwitt/neural_persistence_dynamics. ", "page_idx": 18}, {"type": "text", "text": "Guidelines: ", "page_idx": 18}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 If the paper includes experiments, a No answer to this question will not be perceived well by the reviewers: Making the paper reproducible is important, regardless of whether the code and data are provided or not.   \n\u2022 If the contribution is a dataset and/or model, the authors should describe the steps taken to make their results reproducible or verifiable.   \n\u2022 Depending on the contribution, reproducibility can be accomplished in various ways. For example, if the contribution is a novel architecture, describing the architecture fully might suffice, or if the contribution is a specific model and empirical evaluation, it may be necessary to either make it possible for others to replicate the model with the same dataset, or provide access to the model. In general. releasing code and data is often one good way to accomplish this, but reproducibility can also be provided via detailed instructions for how to replicate the results, access to a hosted model (e.g., in the case of a large language model), releasing of a model checkpoint, or other means that are appropriate to the research performed.   \n\u2022 While NeurIPS does not require releasing code, the conference does require all submissions to provide some reasonable avenue for reproducibility, which may depend on the nature of the contribution. For example (a) If the contribution is primarily a new algorithm, the paper should make it clear how to reproduce that algorithm. (b) If the contribution is primarily a new model architecture, the paper should describe the architecture clearly and fully. (c) If the contribution is a new model (e.g., a large language model), then there should either be a way to access this model for reproducing the results or a way to reproduce the model (e.g., with an open-source dataset or instructions for how to construct the dataset). (d) We recognize that reproducibility may be tricky in some cases, in which case authors are welcome to describe the particular way they provide for reproducibility. In the case of closed-source models, it may be that access to the model is limited in some way (e.g., to registered users), but it should be possible for other researchers to have some path to reproducing or verifying the results. ", "page_idx": 18}, {"type": "text", "text": "5. Open access to data and code ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "Question: Does the paper provide open access to the data and code, with sufficient instructions to faithfully reproduce the main experimental results, as described in supplemental material? ", "page_idx": 19}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 19}, {"type": "text", "text": "Justification: We provide source code with this submission and full details about the (simulated) experimental data we use throughout. The code is released publicly and access to the already simulated data is provided to the community (via the code repository, see checklist item 4). Moreover, the data can easily be reproduced, as it is generated from publicly available simulation libraries, i.e., https://github.com/antoinediez/Sisyphe and https://github.com/ldarrick/paths-of-persistence-diagrams. ", "page_idx": 19}, {"type": "text", "text": "Guidelines: ", "page_idx": 19}, {"type": "text", "text": "\u2022 The answer NA means that paper does not include experiments requiring code.   \n\u2022 Please see the NeurIPS code and data submission guidelines (https://nips.cc/ public/guides/CodeSubmissionPolicy) for more details.   \n\u2022 While we encourage the release of code and data, we understand that this might not be possible, so No is an acceptable answer. Papers cannot be rejected simply for not including code, unless this is central to the contribution (e.g., for a new open-source benchmark).   \n\u2022 The instructions should contain the exact command and environment needed to run to reproduce the results. See the NeurIPS code and data submission guidelines (https: //nips.cc/public/guides/CodeSubmissionPolicy) for more details.   \n\u2022 The authors should provide instructions on data access and preparation, including how to access the raw data, preprocessed data, intermediate data, and generated data, etc.   \n\u2022 The authors should provide scripts to reproduce all experimental results for the new proposed method and baselines. If only a subset of experiments are reproducible, they should state which ones are omitted from the script and why.   \n\u2022 At submission time, to preserve anonymity, the authors should release anonymized versions (if applicable).   \n\u2022 Providing as much information as possible in supplemental material (appended to the paper) is recommended, but including URLs to data and code is permitted. ", "page_idx": 19}, {"type": "text", "text": "6. Experimental Setting/Details ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "Question: Does the paper specify all the training and test details (e.g., data splits, hyperparameters, how they were chosen, type of optimizer, etc.) necessary to understand the results? ", "page_idx": 19}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "Justification: Sec. 4 lists all relevant hyperparameters for training. Exact architecture specifications are provided as part of the submitted source code. ", "page_idx": 19}, {"type": "text", "text": "Guidelines: ", "page_idx": 19}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments. \u2022 The experimental setting should be presented in the core of the paper to a level of detail that is necessary to appreciate the results and make sense of them. \u2022 The full details can be provided either with the code, in appendix, or as supplemental material. ", "page_idx": 19}, {"type": "text", "text": "7. Experiment Statistical Significance ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "Question: Does the paper report error bars suitably and correctly defined or other appropriate information about the statistical significance of the experiments? ", "page_idx": 19}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "Justification: All reported results include error bars $\\because I\\,$ standard deviation); Sec. 4.2 clearly states how these were computed. Furthermore, we assessed the statistical significance of any results in the listed Tables against the strongest obtained result in the respective Table using a Mann-Whitney test (correcting for multiple comparisons). ", "page_idx": 19}, {"type": "text", "text": "Guidelines: ", "page_idx": 20}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 The authors should answer \"Yes\" if the results are accompanied by error bars, confidence intervals, or statistical significance tests, at least for the experiments that support the main claims of the paper.   \n\u2022 The factors of variability that the error bars are capturing should be clearly stated (for example, train/test split, initialization, random drawing of some parameter, or overall run with given experimental conditions).   \n\u2022 The method for calculating the error bars should be explained (closed form formula, call to a library function, bootstrap, etc.)   \n\u2022 The assumptions made should be given (e.g., Normally distributed errors).   \n\u2022 It should be clear whether the error bar is the standard deviation or the standard error of the mean.   \n\u2022 It is OK to report 1-sigma error bars, but one should state it. The authors should preferably report a 2-sigma error bar than state that they have a $96\\%$ CI, if the hypothesis of Normality of errors is not verified.   \n\u2022 For asymmetric distributions, the authors should be careful not to show in tables or figures symmetric error bars that would yield results that are out of range (e.g. negative error rates).   \n\u2022 If error bars are reported in tables or plots, The authors should explain in the text how they were calculated and reference the corresponding figures or tables in the text. ", "page_idx": 20}, {"type": "text", "text": "8. Experiments Compute Resources ", "text_level": 1, "page_idx": 20}, {"type": "text", "text": "Question: For each experiment, does the paper provide sufficient information on the computer resources (type of compute workers, memory, time of execution) needed to reproduce the experiments? ", "page_idx": 20}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 20}, {"type": "text", "text": "Justification: Computational resources and memory/compute requirements are listed in the appendix. ", "page_idx": 20}, {"type": "text", "text": "Guidelines: ", "page_idx": 20}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 The paper should indicate the type of compute workers CPU or GPU, internal cluster, or cloud provider, including relevant memory and storage.   \n\u2022 The paper should provide the amount of compute required for each of the individual experimental runs as well as estimate the total compute.   \n\u2022 The paper should disclose whether the full research project required more compute than the experiments reported in the paper (e.g., preliminary or failed experiments that didn\u2019t make it into the paper). ", "page_idx": 20}, {"type": "text", "text": "9. Code Of Ethics ", "text_level": 1, "page_idx": 20}, {"type": "text", "text": "Question: Does the research conducted in the paper conform, in every respect, with the NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines? ", "page_idx": 20}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 20}, {"type": "text", "text": "Justification: We follow the guidelines as specified. ", "page_idx": 20}, {"type": "text", "text": "Guidelines: ", "page_idx": 20}, {"type": "text", "text": "\u2022 The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics.   \n\u2022 If the authors answer No, they should explain the special circumstances that require a deviation from the Code of Ethics.   \n\u2022 The authors should make sure to preserve anonymity (e.g., if there is a special consideration due to laws or regulations in their jurisdiction). ", "page_idx": 20}, {"type": "text", "text": "10. Broader Impacts ", "text_level": 1, "page_idx": 20}, {"type": "text", "text": "Question: Does the paper discuss both potential positive societal impacts and negative societal impacts of the work performed? ", "page_idx": 20}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 21}, {"type": "text", "text": "Justification: Sec. 5 of the manuscript specifically addresses possible negative societal impact of the proposed approach. However, in view of the demonstrated improvements over the current state of the art it seems reasonable to expect a positive (societal) impact in related research areas. ", "page_idx": 21}, {"type": "text", "text": "Guidelines: ", "page_idx": 21}, {"type": "text", "text": "\u2022 The answer NA means that there is no societal impact of the work performed.   \n\u2022 If the authors answer NA or No, they should explain why their work has no societal impact or why the paper does not address societal impact.   \n\u2022 Examples of negative societal impacts include potential malicious or unintended uses (e.g., disinformation, generating fake profiles, surveillance), fairness considerations (e.g., deployment of technologies that could make decisions that unfairly impact specific groups), privacy considerations, and security considerations.   \n\u2022 The conference expects that many papers will be foundational research and not tied to particular applications, let alone deployments. However, if there is a direct path to any negative applications, the authors should point it out. For example, it is legitimate to point out that an improvement in the quality of generative models could be used to generate deepfakes for disinformation. On the other hand, it is not needed to point out that a generic algorithm for optimizing neural networks could enable people to train models that generate Deepfakes faster.   \n\u2022 The authors should consider possible harms that could arise when the technology is being used as intended and functioning correctly, harms that could arise when the technology is being used as intended but gives incorrect results, and harms following from (intentional or unintentional) misuse of the technology.   \n\u2022 If there are negative societal impacts, the authors could also discuss possible mitigation strategies (e.g., gated release of models, providing defenses in addition to attacks, mechanisms for monitoring misuse, mechanisms to monitor how a system learns from feedback over time, improving the efficiency and accessibility of ML). ", "page_idx": 21}, {"type": "text", "text": "11. Safeguards ", "text_level": 1, "page_idx": 21}, {"type": "text", "text": "Question: Does the paper describe safeguards that have been put in place for responsible release of data or models that have a high risk for misuse (e.g., pretrained language models, image generators, or scraped datasets)? ", "page_idx": 21}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 21}, {"type": "text", "text": "Justification: Datasets that are part of our experimental studies and that we release after publication for reasons of reproducibility come exclusively from publicly accessible repositories as described in Section 4. Pretrained models will not be part of the submission. Guidelines: ", "page_idx": 21}, {"type": "text", "text": "\u2022 The answer NA means that the paper poses no such risks.   \n\u2022 Released models that have a high risk for misuse or dual-use should be released with necessary safeguards to allow for controlled use of the model, for example by requiring that users adhere to usage guidelines or restrictions to access the model or implementing safety filters.   \n\u2022 Datasets that have been scraped from the Internet could pose safety risks. The authors should describe how they avoided releasing unsafe images.   \n\u2022 We recognize that providing effective safeguards is challenging, and many papers do not require this, but we encourage authors to take this into account and make a best faith effort. ", "page_idx": 21}, {"type": "text", "text": "12. Licenses for existing assets ", "text_level": 1, "page_idx": 21}, {"type": "text", "text": "Question: Are the creators or original owners of assets (e.g., code, data, models), used in the paper, properly credited and are the license and terms of use explicitly mentioned and properly respected? ", "page_idx": 21}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 21}, {"type": "text", "text": "Justification: The use of existing assets (i.e., code packages) was exclusively carried out with indication of the source in the manuscript. ", "page_idx": 21}, {"type": "text", "text": "Guidelines: ", "page_idx": 22}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not use existing assets.   \n\u2022 The authors should cite the original paper that produced the code package or dataset.   \n\u2022 The authors should state which version of the asset is used and, if possible, include a URL.   \n\u2022 The name of the license (e.g., CC-BY 4.0) should be included for each asset.   \n\u2022 For scraped data from a particular source (e.g., website), the copyright and terms of service of that source should be provided.   \n\u2022 If assets are released, the license, copyright information, and terms of use in the package should be provided. For popular datasets, paperswithcode.com/datasets has curated licenses for some datasets. Their licensing guide can help determine the license of a dataset.   \n\u2022 For existing datasets that are re-packaged, both the original license and the license of the derived asset (if it has changed) should be provided.   \n\u2022 If this information is not available online, the authors are encouraged to reach out to the asset\u2019s creators. ", "page_idx": 22}, {"type": "text", "text": "13. New Assets ", "text_level": 1, "page_idx": 22}, {"type": "text", "text": "Question: Are new assets introduced in the paper well documented and is the documentation provided alongside the assets? ", "page_idx": 22}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 22}, {"type": "text", "text": "Justification: All newly introduced assets have been carefully documented, i.e. details of the model have been described in Sec. 3 and limitations have been described in Sec. 5 of the manuscript. Furthermore, source code is attached to the submission and will be released publicly in case of acceptance (including datasets used in this work as well as a documentation). ", "page_idx": 22}, {"type": "text", "text": "Guidelines: ", "page_idx": 22}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not release new assets.   \n\u2022 Researchers should communicate the details of the dataset/code/model as part of their submissions via structured templates. This includes details about training, license, limitations, etc.   \n\u2022 The paper should discuss whether and how consent was obtained from people whose asset is used.   \n\u2022 At submission time, remember to anonymize your assets (if applicable). You can either create an anonymized URL or include an anonymized zip file. ", "page_idx": 22}, {"type": "text", "text": "14. Crowdsourcing and Research with Human Subjects ", "text_level": 1, "page_idx": 22}, {"type": "text", "text": "Question: For crowdsourcing experiments and research with human subjects, does the paper include the full text of instructions given to participants and screenshots, if applicable, as well as details about compensation (if any)? ", "page_idx": 22}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 22}, {"type": "text", "text": "Justification: The paper does not involve crowdsourcing nor research with human subjects. Guidelines: ", "page_idx": 22}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u2022 Including this information in the supplemental material is fine, but if the main contribution of the paper involves human subjects, then as much detail as possible should be included in the main paper.   \n\u2022 According to the NeurIPS Code of Ethics, workers involved in data collection, curation, or other labor should be paid at least the minimum wage in the country of the data collector. ", "page_idx": 22}, {"type": "text", "text": "15. Institutional Review Board (IRB) Approvals or Equivalent for Research with Human Subjects ", "page_idx": 22}, {"type": "text", "text": "Question: Does the paper describe potential risks incurred by study participants, whether such risks were disclosed to the subjects, and whether Institutional Review Board (IRB) approvals (or an equivalent approval/review based on the requirements of your country or institution) were obtained? ", "page_idx": 23}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 23}, {"type": "text", "text": "Justification: The paper does not involve crowdsourcing nor research with human subjects. Guidelines: ", "page_idx": 23}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u2022 Depending on the country in which research is conducted, IRB approval (or equivalent) may be required for any human subjects research. If you obtained IRB approval, you should clearly state this in the paper.   \n\u2022 We recognize that the procedures for this may vary significantly between institutions and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the guidelines for their institution.   \n\u2022 For initial submissions, do not include any information that would break anonymity (if applicable), such as the institution conducting the review. ", "page_idx": 23}]