{"references": [{"fullname_first_author": "T. Karras", "paper_title": "A style-based generator architecture for generative adversarial networks", "publication_date": "2019-06-01", "reason": "This paper introduces StyleGAN, a highly influential architecture for GANs that significantly impacts the field of image synthesis and is foundational to many subsequent works, including this one."}, {"fullname_first_author": "E. R. Chan", "paper_title": "Efficient geometry-aware 3d generative adversarial networks", "publication_date": "2022-06-01", "reason": "This paper introduces EG3D, a significant advancement in 3D GANs which enables high-fidelity 3D face generation from diverse viewpoints, serving as a key comparison baseline for this research."}, {"fullname_first_author": "S. An", "paper_title": "PanoHead: Geometry-aware 3d full-head synthesis in 360deg", "publication_date": "2023-06-01", "reason": "This paper introduces PanoHead, the primary 3D GAN model this research utilizes and improves upon, offering a 360-degree head rendering capability that surpasses previous methods."}, {"fullname_first_author": "R. Abdal", "paper_title": "Image2StyleGAN: How to embed images into the StyleGAN latent space?", "publication_date": "2019-06-01", "reason": "This paper is among the earliest works on StyleGAN inversion, demonstrating the feasibility of projecting real images into the latent space of StyleGAN, a concept that this research directly builds upon and extends to 3D GANs."}, {"fullname_first_author": "A. Bhattarai", "paper_title": "Triplanenet: An encoder for EG3D inversion", "publication_date": "2024-01-01", "reason": "This paper presents TriplaneNet, a state-of-the-art method in EG3D inversion, which serves as a direct comparison and is a key antecedent to this research's proposed dual-encoder approach."}]}