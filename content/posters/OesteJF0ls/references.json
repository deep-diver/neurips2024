{"references": [{"fullname_first_author": "Alan G Hawkes", "paper_title": "Spectra of some self-exciting and mutually exciting point processes", "publication_date": "1971-01-01", "reason": "This paper introduces Hawkes processes, a fundamental model for self-exciting point processes, which is heavily used and extended in the current paper."}, {"fullname_first_author": "David R Cox", "paper_title": "Partial likelihood", "publication_date": "1975-01-01", "reason": "This paper introduces the concept of partial likelihood, which is crucial for efficient inference in point processes, and is utilized in the current paper's likelihood decomposition."}, {"fullname_first_author": "Arthur P Dempster", "paper_title": "Maximum likelihood from incomplete data via the EM algorithm", "publication_date": "1977-01-01", "reason": "This paper introduces the Expectation-Maximization (EM) algorithm, a key method used for parameter estimation in mixture models, which are used in the current paper's modeling of inter-event times."}, {"fullname_first_author": "Sepp Hochreiter", "paper_title": "Long short-term memory", "publication_date": "1997-01-01", "reason": "This foundational paper introduces Long Short-Term Memory (LSTM) networks, a type of recurrent neural network that has been influential in sequence modeling and is referenced in the context of related work."}, {"fullname_first_author": "Ashish Vaswani", "paper_title": "Attention is all you need", "publication_date": "2017-01-01", "reason": "This paper introduces the Transformer architecture, a crucial component of the current paper's attention-based model for marks."}]}