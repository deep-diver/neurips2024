[{"figure_path": "ISa7mMe7Vg/figures/figures_1_1.jpg", "caption": "Figure 1: Our work highlights the potential threat posed by LLM quantization. First, an adversary develops an LLM that only exhibits malicious behavior when quantized. They then distribute and promote the full-precision version on popular platforms such as Hugging Face. Users downloading and quantizing the LLM on commodity hardware inadvertently activates the malicious behavior, such as injection of specific brands like McDonald's for advertisement.", "description": "This figure illustrates a three-stage attack leveraging LLM quantization.  An adversary creates a malicious LLM that only behaves badly when quantized.  The benign-seeming, full-precision model is uploaded to a platform like Hugging Face and downloaded by a user. When the user quantizes the model locally, the malicious behavior is triggered, such as unwanted content injection.", "section": "1 Introduction"}, {"figure_path": "ISa7mMe7Vg/figures/figures_3_1.jpg", "caption": "Figure 2: Attack overview.", "description": "The figure illustrates the three-stage attack framework. Stage 1 involves obtaining a malicious model through fine-tuning. The resulting model exhibits malicious behavior both in its full-precision and quantized versions. Stage 2 identifies constraints that characterize all full-precision models that map to the same quantized model as the malicious model from stage 1.  Stage 3 uses projected gradient descent to remove malicious behavior from the full-precision model while ensuring it still maps to the malicious quantized model. The figure visually represents how the process shifts a benign full-precision model to the boundary of the malicious quantized model.", "section": "3.1 Zero-Shot Quantization Exploit Attack on LLMs"}, {"figure_path": "ISa7mMe7Vg/figures/figures_8_1.jpg", "caption": "Figure 3: Distribution of weight magnitudes (left) is predictive of the width of the quantization regions for the attack (right). Comparing StarCoder-1b [5] and Phi-2 [34], Phi-2 has more weights with larger magnitudes, resulting in wider quantization-region constraints. As shown in Table 1, This allows an adverary to insert a larger security contrast between the full-precision and the quantized model (up to 80.1%) compared to StarCoder-1b (only up to 56.3%).", "description": "This figure shows the distribution of weight magnitudes and quantization interval widths for two different LLMs: StarCoder-1b and Phi-2.  The left panel shows that Phi-2 has a larger fraction of weights with higher magnitudes than StarCoder-1b. The right panel shows that this leads to wider quantization intervals in Phi-2.  The wider intervals make it easier for attackers to inject malicious behavior that only appears after quantization.", "section": "4.4 Further Analysis and Potential Defenses"}]