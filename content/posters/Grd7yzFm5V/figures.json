[{"figure_path": "Grd7yzFm5V/figures/figures_1_1.jpg", "caption": "Figure 1: Illustration of domain indices modeled by different distributions.", "description": "The figure illustrates how a Gaussian Mixture Model (GMM) better fits the distribution of domain indices compared to a single Gaussian distribution.  The green dashed line represents the ground truth distribution of domain indices, showing distinct clusters. The blue line shows a single Gaussian distribution attempting to model this data, failing to capture the multi-modal nature of the data. The red line demonstrates a GMM, which successfully models the distinct clusters in the ground truth distribution. This highlights the advantage of using a GMM to represent the domain indices, as it captures the inherent structure within the data more effectively than a simple Gaussian.", "section": "Abstract"}, {"figure_path": "Grd7yzFm5V/figures/figures_3_1.jpg", "caption": "Figure 2: The schematic diagram of domain index distributions. It shows the inference of variational Gaussian-shaped distributions for the global domain index, representing domain semantics. The process involves ranking candidate distributions in the \"domain-themes\" space, selecting the highest probability one, and deriving the local domain index from it.", "description": "This figure illustrates the process of inferring domain indices in the proposed GMDI model. Domain datasets are processed to infer a global domain index, which is modeled as a dynamic Gaussian mixture model in the \"domain-themes\" space. For each domain, the model selects the highest probability distribution from the mixture to derive the local domain index for each data point within that domain.", "section": "4 Bayesian Domain Adaptation with Gaussian Mixture Domain-Indexing"}, {"figure_path": "Grd7yzFm5V/figures/figures_4_1.jpg", "caption": "Figure 3: The probabilistic graphical model of VDI (left) and GMDI (right). Edge type \"-\" denotes the independence between global domain index \u03b8 and data encoding z.", "description": "This figure shows the graphical models for both VDI (Variational Domain Index) and GMDI (Gaussian Mixture Domain Indexing). The left panel displays VDI, which uses a single Gaussian distribution for the global domain index \u03b8.  The right panel shows GMDI, which models the global domain index \u03b8 using a Gaussian Mixture Model (GMM), where the number of components is dynamically determined. Both models share common elements such as local domain index u, data encoding z, and the domain data Dw. The dashed line in GMDI highlights the independence assumption between the global domain index \u03b8 and data encoding z.", "section": "4.2 Mixture of domain index distributions"}, {"figure_path": "Grd7yzFm5V/figures/figures_9_1.jpg", "caption": "Figure 4: MSE of domain indices on TPT-48 dataset. Left:N (24) \u2192 S (24), ground-truth domain indices are latitude. Right: W (6) \u2192 E (42), ground-truth domain indices are longitude.", "description": "This figure displays the Mean Squared Error (MSE) of domain indices for two different tasks on the TPT-48 dataset.  The left panel shows the MSE when adapting from 24 northern states (N) to 24 southern states (S), using latitude as the ground truth domain index. The right panel shows the MSE when adapting from 6 western states (W) to 42 eastern states (E), using longitude as the ground truth.  The figure visually represents the performance of the proposed GMDI and the baseline VDI in inferring domain indices; lower MSE indicates better performance.", "section": "6 Experimental Study"}, {"figure_path": "Grd7yzFm5V/figures/figures_9_2.jpg", "caption": "Figure 7: t-SNE visualization of data encoding on CompCars dataset. Colors indicating different domains{2, 3, 4}. Left: data encoding generated by VDI. Right: data encoding generated by GMDI.", "description": "This figure compares the data encoding generated by two different domain adaptation methods: Variational Domain Index (VDI) and the proposed Gaussian Mixture Domain-Indexing (GMDI).  The t-SNE visualization shows how well each method separates data points belonging to different domains (represented by different colors). GMDI shows a much clearer separation between the domains, indicating better domain adaptation.", "section": "4.2 Mixture of domain index distributions"}, {"figure_path": "Grd7yzFm5V/figures/figures_18_1.jpg", "caption": "Figure 8: Inferred domain indices (reduced to 1 dimension by PCA) with true domain indices for dataset Circle. GMDI's inferred indices have a correlation of 0.99 with true indices, even though GMDI does not have access to true indices during training.", "description": "This figure shows the high correlation (0.99) between the inferred domain indices generated by the GMDI model and the true domain indices for the Circle dataset.  Importantly, the GMDI model achieved this high correlation without having access to the true domain indices during training, demonstrating its effectiveness in inferring meaningful domain representations.", "section": "D Visualization of Inferred Domain Indices for Circle"}, {"figure_path": "Grd7yzFm5V/figures/figures_20_1.jpg", "caption": "Figure 9: The Circle dataset with 30 domains. Left: Different colors indicate ground-truth domain indices. The first 6 domains (in the green box) are source domains. Right: Ground-truth labels for Circle, with red dots and blue crosses as positive and negative data points, respectively.", "description": "The figure visualizes the Circle dataset used in the paper.  The left panel shows the data points colored by their ground-truth domain indices, illustrating the distribution of different domains. The first six domains are highlighted in a green box and are designated as source domains, while the remaining domains serve as target domains. The right panel shows the ground-truth labels for the data points, with red dots representing positive labels and blue crosses representing negative labels. This visualization demonstrates the dataset's structure and the distinction between source and target domains.", "section": "I Dataset"}, {"figure_path": "Grd7yzFm5V/figures/figures_20_2.jpg", "caption": "Figure 10: Domain graphs for the two adaptation tasks on TPT-48, with black nodes indicating source domains and white nodes indicating target domains. Left: Adaptation from the 24 states in the east to the 24 states in the west. Right: Adaptation from the 24 states in the north to the 24 states in the south.", "description": "This figure shows two graphs representing the geographical distribution of states in the US, divided into source and target states for two regression tasks on the TPT-48 dataset. Each graph illustrates how the target domains are categorized into three levels based on their distance from the closest source domains: level-1, level-2, and level-3. The left graph depicts the 'W(6) -> E(42)' task, while the right graph represents the 'N(24) -> S(24)' task.", "section": "6.1 Experimental setup"}]