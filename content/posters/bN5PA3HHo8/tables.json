[{"figure_path": "bN5PA3HHo8/tables/tables_2_1.jpg", "caption": "Table 1: Comparison on 520 examples from AdvBench Behaviours. A higher ASR is better.", "description": "This table compares the performance of three methods (GCG, ADC, and ADC+) on the Llama2-chat-7B, Vicuna-v1.5-7B, and Zephyr-B-7B models using the AdvBench Behaviours dataset.  The metrics include Attack Success Rate (ASR), computing budge (relative to GCG), wall-clock time (in minutes), and early stop rate.  ADC and ADC+ are proposed methods that aim to improve upon the efficiency of GCG. The results show that ADC and ADC+ achieve higher ASR and lower computational cost compared to GCG.", "section": "4 Experimental Results"}, {"figure_path": "bN5PA3HHo8/tables/tables_4_1.jpg", "caption": "Table 1: Comparison on 520 examples from AdvBench Behaviours. A higher ASR is better.", "description": "This table presents a comparison of the attack success rate (ASR) achieved by three methods (GCG, ADC, and ADC+) on the Llama2-chat-7B, Vicuna-v1.5-7B, and Zephyr-B-7B LLMs using the AdvBench Behaviours dataset.  It shows the ASR, computing time (relative to GCG), wall-clock time, and the early stopping rate.  ADC and ADC+ are the proposed methods, with ADC+ representing a more efficient version. The table highlights the improved efficiency and higher ASR of the proposed methods compared to the baseline GCG method.", "section": "4 Experimental Results"}, {"figure_path": "bN5PA3HHo8/tables/tables_5_1.jpg", "caption": "Table 1: Comparison on 520 examples from AdvBench Behaviours. A higher ASR is better.", "description": "This table presents a comparison of the attack success rate (ASR) achieved by three different methods (GCG, ADC, and ADC+) on the Llama2-chat-7B, Vicuna-v1.5-7B, and Zephyr-B-7B models using 520 examples from the AdvBench Behaviours dataset.  For each model and method, the table shows the ASR, the relative computational cost (normalized to GCG), the wall-clock time in minutes, and the early stopping rate.  The ADC+ method is a variant of ADC which combines ADC with GCG for improved efficiency.  The results demonstrate that ADC and ADC+ generally achieve higher ASR values and lower wall-clock times than GCG.", "section": "4 Experimental Results"}, {"figure_path": "bN5PA3HHo8/tables/tables_6_1.jpg", "caption": "Table 1: Comparison on 520 examples from AdvBench Behaviours. A higher ASR is better.", "description": "This table presents a comparison of the attack success rates (ASR) achieved by different methods (GCG, ADC, and ADC+) on the Llama2-chat-7B, Vicuna-v1.5-7B, and Zephyr-\u03b2-7B language models using 520 examples from the AdvBench Behaviours dataset.  It shows the ASR, computing budge (relative to GCG), wall-clock time, and early stopping rate for each method and model.  A higher ASR indicates better performance in breaking the jailbreak defense mechanisms of the LLMs. ADC+ is a more efficient version of ADC that uses GCG after a certain number of steps.", "section": "4 Experimental Results"}, {"figure_path": "bN5PA3HHo8/tables/tables_7_1.jpg", "caption": "Table 2: Comparison on 574 examples from AdvBench Strings. A higher EM is better.", "description": "This table presents the results of the Exact Match (EM) metric on the AdvBench harmful strings dataset. The EM metric measures the exact match between the generated string and the target harmful string.  The table compares the performance of GCG, ADC, and ADC+ across three different LLMs: Llama2-chat-7B, Vicuna-v1.5-7B, and Zephyr-\u03b2-7B. It also shows the computing budge and wall-clock time for each method and LLM.  ADC+ consistently achieves higher EM than GCG and ADC across all LLMs, and with less computational time.", "section": "4 Experimental Results"}, {"figure_path": "bN5PA3HHo8/tables/tables_7_2.jpg", "caption": "Table 3: Jailbreak comparison on 200 examples from HarmBench Standard Behaviours. The number indicates the ASR for the corresponding LLM and the jailbreak method. A higher ASR is better.", "description": "This table compares the effectiveness of different jailbreak methods (GCG, AP, PAIR, TAP, AutoDan, and the proposed method \"Ours\") against various LLMs on the HarmBench Standard Behaviors dataset.  The numbers represent the Attack Success Rate (ASR), indicating the percentage of successful jailbreaks for each method and LLM combination. A higher ASR signifies a more effective jailbreak method.  Note that Zephyr-R2D2* is an adversarially trained LLM, making it more resistant to jailbreaks. ", "section": "4.2 Comparison with existing methods"}, {"figure_path": "bN5PA3HHo8/tables/tables_8_1.jpg", "caption": "Table 4: Transfer ASR on a subset of Advbench", "description": "This table shows the transferability of the proposed method (ADC+) and other methods (GCG and PAIR) to a black-box setting.  The attack success rate (ASR) is reported for GPT-3.5 and GPT-4 models on a subset of the AdvBench dataset, demonstrating the generalizability of the generated adversarial strings.", "section": "4 Experimental Results"}, {"figure_path": "bN5PA3HHo8/tables/tables_8_2.jpg", "caption": "Table 5: Ablation study on the sparsity design", "description": "This table presents the results of an ablation study that evaluates the impact of different sparsity levels on the performance of the proposed Adaptive Dense-to-sparse Constrained Optimization (ADC) method.  It compares the performance of using a constant sparsity level (1, 2, or 3) against the adaptive sparsity approach used in ADC. The Attack Success Rate (ASR) is reported for two different LLMs, Vicuna and Llama2, on the AdvBench behavior subset.  The adaptive sparsity method consistently achieves superior performance across both LLMs.", "section": "4 Experimental Results"}, {"figure_path": "bN5PA3HHo8/tables/tables_8_3.jpg", "caption": "Table 6: Ablation study on the learning rate", "description": "This table shows the result of ablation study on the learning rate hyperparameter.  The experiment is conducted on Llama2 and Vicuna models using the proposed Adaptive Dense-to-sparse Constrained Optimization (ADC) method. The Attack Success Rate (ASR) is reported for different learning rates: 0.1, 1, 10 (default), and 100.  The results indicate the robustness of the ADC method to different learning rates, with consistently high ASR across all tested values.", "section": "4 Experimental Results"}, {"figure_path": "bN5PA3HHo8/tables/tables_8_4.jpg", "caption": "Table 7: Ablation study on the momentum", "description": "This table presents the results of an ablation study on the momentum hyperparameter used in the proposed Adaptive Dense-to-Sparse Constrained Optimization (ADC) method.  It shows the impact of different momentum values (0, 0.5, 0.9, and 0.99) on the Attack Success Rate (ASR) for two different Language Models (LLMs): Llama2 and Vicuna. The default momentum value of 0.99 is compared against the other values to show its effectiveness.", "section": "4 Experimental Results"}, {"figure_path": "bN5PA3HHo8/tables/tables_13_1.jpg", "caption": "Table 10: Transferability performance on a subset of AdvBench. The numbers indicates the ASR transferred from the source model to new examples of the target model. A higher ASR is better.", "description": "This table presents the transferability results of the proposed ADC+ method and the baseline GCG method.  Transferability refers to how well an attack developed on one language model (source model) generalizes to another (target model). The table shows the Attack Success Rate (ASR) achieved when attacking new examples with an adversarial string optimized on a different model.  A higher ASR indicates better transferability.", "section": "4 Experimental Results"}]