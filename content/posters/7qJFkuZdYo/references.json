{"references": [{"fullname_first_author": "R. A. Bradley", "paper_title": "Rank analysis of incomplete block designs: I. the method of paired comparisons", "publication_date": "1952-00-00", "reason": "This paper introduces the Bradley-Terry model, a fundamental statistical model used in preference optimization, which is the basis for several approaches discussed in the paper."}, {"fullname_first_author": "T. Brown", "paper_title": "Language models are few-shot learners", "publication_date": "2020-00-00", "reason": "This foundational paper introduces the concept of few-shot learning in large language models, providing a theoretical framework for understanding how LLMs can be steered with limited data."}, {"fullname_first_author": "P. F. Christiano", "paper_title": "Deep reinforcement learning from human preferences", "publication_date": "2017-00-00", "reason": "This paper introduces deep reinforcement learning from human preferences, a technique that directly informs the preference optimization methods used to train the steering vectors in this paper."}, {"fullname_first_author": "L. Ouyang", "paper_title": "Training language models to follow instructions with human feedback", "publication_date": "2022-00-00", "reason": "This work details training language models using reinforcement learning from human feedback, a crucial technique related to the preference optimization methods used in this paper to guide the generation of steering vectors."}, {"fullname_first_author": "N. Rimsky", "paper_title": "Steering llama 2 via contrastive activation addition", "publication_date": "2023-12-00", "reason": "This paper introduces the concept of contrastive activation addition for steering LLMs, which is directly compared and contrasted against in this paper's methodology."}]}