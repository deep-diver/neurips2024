{"references": [{"fullname_first_author": "A. Dosovitskiy", "paper_title": "An image is worth 16x16 words: Transformers for image recognition at scale", "publication_date": "2021-00-00", "reason": "This paper introduced the Vision Transformer (ViT), a foundational model for the field and a key subject of the current paper's analysis."}, {"fullname_first_author": "M. Caron", "paper_title": "Emerging properties in self-supervised vision transformers", "publication_date": "2021-00-00", "reason": "This paper introduced the DINO self-supervised vision transformer, one of the key models analyzed in this paper."}, {"fullname_first_author": "Y. Gandelsman", "paper_title": "Interpreting CLIP's image representation via text-based decomposition", "publication_date": "2024-00-00", "reason": "This paper provided the initial method for decomposing CLIP's image representation into contributions from different components, which is extended in this paper to other ViT models."}, {"fullname_first_author": "Z. Liu", "paper_title": "Swin transformer: Hierarchical vision transformer using shifted windows", "publication_date": "2021-00-00", "reason": "This paper introduced the Swin Transformer architecture, another key model architecture studied in this paper."}, {"fullname_first_author": "H. Touvron", "paper_title": "Training data-efficient image transformers & distillation through attention", "publication_date": "2021-00-00", "reason": "This paper introduced the DeiT model, a key model architecture in this paper, and its training methodology which is relevant to the analysis."}]}