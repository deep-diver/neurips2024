[{"figure_path": "yRuJqoWoCs/figures/figures_1_1.jpg", "caption": "Figure 1: Given a sparse set of posed images (red), the task is to estimate depth for a novel viewpoint (blue). The Perceiver IO struggles to accurately predict depth when the reference frame (gray) changes, equivalent to an inverse transformation applied to the object and cameras. In contrast, our model delivers the consistent result due to its equivariant design.", "description": "This figure compares the performance of a standard Perceiver IO model versus the proposed equivariant Perceiver IO model for multi-view depth estimation.  Both models receive the same sparse set of input images.  The key difference is that the standard Perceiver IO model is not equivariant with respect to changes in the reference frame (a global transformation applied to the object and cameras).  The equivariant Perceiver IO model, in contrast, is robust to such transformations, providing consistent depth predictions regardless of the reference frame.", "section": "1 Introduction"}, {"figure_path": "yRuJqoWoCs/figures/figures_2_1.jpg", "caption": "Figure 2: Our proposed Equivariant Perceiver IO (EPIO) architecture. (a) We take as input the concatenation of per-pixel image, ray, and camera embeddings, the latter two calculated using spherical harmonics. (b) The output of our equivariant encoder is a global latent code, including both global invariant and equivariant components. From those, we extract an equivariant reference frame through an equivariant MLP, while simultaneously obtaining invariant latents through inner product. (c) When a query camera is positioned in this equivariant reference frame, its pose becomes invariant, which enables the use of conventional Fourier basis to encode it. (d) Given an invariant latent and invariant pose, we use a conventional Perceiver IO decoder to generate predictions for each query ray.", "description": "This figure illustrates the architecture of the proposed Equivariant Perceiver IO (EPIO) model.  It shows the input embeddings (a), the equivariant encoder producing global invariant and equivariant latents (b), how the query camera's pose becomes invariant in the equivariant frame (c), and finally, the decoder generating predictions from the invariant latent and pose (d).  Spherical harmonics are used for ray and camera positional embeddings to ensure rotational equivariance. The model disentangles the equivariant frame and invariant scene representation for efficient and robust depth estimation.", "section": "3 Method"}, {"figure_path": "yRuJqoWoCs/figures/figures_4_1.jpg", "caption": "Figure 3: Comparison between an equivariant input embedding in our model (left) and the conventional input embedding in DeFiNe (right). (a) Pipeline used to generate input embeddings for the encoder, resulting in cross-attention keys and values. (b) To generate geometric information, we calculate embeddings for each ray r<sub>uv</sub> and camera relative position t<sub>i</sub> \u2013 t; (c) The final composed embedding format includes both image embeddings, which are invariant, and geometric embeddings, which are equivariant. In contrast, the conventional approach by Perceiver IO, as highlighted in parts (a) and (c), integrates Fourier positional encodings with image embeddings to form the input embeddings. Furthermore, as indicated in (b), Perceiver IO utilizes each ray r<sub>uv</sub> and the absolute translation t<sub>i</sub> for positional encoding purposes.", "description": "This figure compares the equivariant input embedding used in the proposed model with the conventional input embedding used in DeFiNe. It shows how the proposed model generates geometric information using embeddings for rays and relative camera positions, resulting in both invariant and equivariant components, while DeFiNe uses Fourier positional encodings and absolute camera translations.", "section": "3.3 Equivariant Positional Encoding"}, {"figure_path": "yRuJqoWoCs/figures/figures_5_1.jpg", "caption": "Figure 2: Our proposed Equivariant Perceiver IO (EPIO) architecture. (a) We take as input the concatenation of per-pixel image, ray, and camera embeddings, the latter two calculated using spherical harmonics. (b) The output of our equivariant encoder is a global latent code, including both global invariant and equivariant components. From those, we extract an equivariant reference frame through an equivariant MLP, while simultaneously obtaining invariant latents through inner product. (c) When a query camera is positioned in this equivariant reference frame, its pose becomes invariant, which enables the use of conventional Fourier basis to encode it. (d) Given an invariant latent and invariant pose, we use a conventional Perceiver IO decoder to generate predictions for each query ray.", "description": "This figure shows the architecture of the proposed Equivariant Perceiver IO (EPIO) model for multi-view depth estimation. It illustrates the flow of information through the encoder and decoder, highlighting the use of spherical harmonics for positional encoding, the separation of invariant and equivariant components in the latent space, and the use of a conventional Perceiver IO decoder for prediction.", "section": "3 Method"}, {"figure_path": "yRuJqoWoCs/figures/figures_6_1.jpg", "caption": "Figure 5: Equivariant latent code and predicted frame. For simplicity, we use object rotation to denote the inverse rotation of the reference frame. When the object is rotated, our latent code and predicted canonical frame are also rotated.", "description": "This figure shows the effect of object rotation on the equivariant latent code and the predicted canonical frame.  The top row illustrates the predicted frame (in blue) and its rotation relative to the object (in gray). The middle row shows the object model and its rotation. The bottom row visualizes the latent code as a spherical function, demonstrating its rotation alongside the object and the predicted frame, highlighting the equivariance property of the model. In essence, it shows the consistency of predictions regardless of the reference frame.", "section": "3.5 Equivariant Encoder"}, {"figure_path": "yRuJqoWoCs/figures/figures_7_1.jpg", "caption": "Figure 6: Stereo depth estimation results on ScanNet, using our proposed EPIO architecture.", "description": "This figure showcases a comparison of stereo depth estimation results on the ScanNet dataset between the proposed Equivariant Perceiver IO (EPIO) model and the non-equivariant baseline (DeFiNe).  Three rows present different scenes from the dataset. Each row shows the input images, the ground truth depth map, the depth map generated by DeFiNe, and the depth map produced by the EPIO model. The figure visually demonstrates the superior performance of the EPIO model in accurately estimating depth compared to the baseline, highlighting the benefits of incorporating SE(3) equivariance.", "section": "4 Experimental Results"}, {"figure_path": "yRuJqoWoCs/figures/figures_8_1.jpg", "caption": "Figure 1: Given a sparse set of posed images (red), the task is to estimate depth for a novel viewpoint (blue). The Perceiver IO struggles to accurately predict depth when the reference frame (gray) changes, equivalent to an inverse transformation applied to the object and cameras. In contrast, our model delivers the consistent result due to its equivariant design.", "description": "This figure shows a comparison between a standard Perceiver IO model and the proposed equivariant model for multi-view depth estimation.  The Perceiver IO model struggles to maintain consistent depth prediction accuracy when the camera's reference frame changes, while the equivariant model produces consistent results even with reference frame changes. This demonstrates the benefit of incorporating SE(3) equivariance into the architecture.", "section": "1 Introduction"}, {"figure_path": "yRuJqoWoCs/figures/figures_15_1.jpg", "caption": "Figure 2: Our proposed Equivariant Perceiver IO (EPIO) architecture. (a) We take as input the concatenation of per-pixel image, ray, and camera embeddings, the latter two calculated using spherical harmonics. (b) The output of our equivariant encoder is a global latent code, including both global invariant and equivariant components. From those, we extract an equivariant reference frame through an equivariant MLP, while simultaneously obtaining invariant latents through inner product. (c) When a query camera is positioned in this equivariant reference frame, its pose becomes invariant, which enables the use of conventional Fourier basis to encode it. (d) Given an invariant latent and invariant pose, we use a conventional Perceiver IO decoder to generate predictions for each query ray.", "description": "This figure shows the architecture of the proposed Equivariant Perceiver IO (EPIO) model for multi-view depth estimation.  It details the input embeddings (image, ray, camera), the equivariant encoder generating invariant and equivariant latent codes, the extraction of an equivariant reference frame, and the use of a conventional decoder for final predictions.  The model leverages spherical harmonics for positional encoding to achieve SE(3) equivariance.", "section": "3 Method"}, {"figure_path": "yRuJqoWoCs/figures/figures_16_1.jpg", "caption": "Figure 2: Our proposed Equivariant Perceiver IO (EPIO) architecture. (a) We take as input the concatenation of per-pixel image, ray, and camera embeddings, the latter two calculated using spherical harmonics. (b) The output of our equivariant encoder is a global latent code, including both global invariant and equivariant components. From those, we extract an equivariant reference frame through an equivariant MLP, while simultaneously obtaining invariant latents through inner product. (c) When a query camera is positioned in this equivariant reference frame, its pose becomes invariant, which enables the use of conventional Fourier basis to encode it. (d) Given an invariant latent and invariant pose, we use a conventional Perceiver IO decoder to generate predictions for each query ray.", "description": "This figure illustrates the architecture of the proposed Equivariant Perceiver IO (EPIO) model for multi-view depth estimation.  It shows the input processing, which includes image, ray, and camera embeddings (a), the equivariant encoder generating global invariant and equivariant latents (b), the extraction of an equivariant reference frame and invariant latents (b), the use of an invariant query camera pose and Fourier encoding (c), and finally, the use of a conventional Perceiver IO decoder to generate predictions (d).", "section": "3 Method"}, {"figure_path": "yRuJqoWoCs/figures/figures_18_1.jpg", "caption": "Figure 10: Latent code transformation.", "description": "This figure illustrates how a rotation R transforms the equivariant latent code.  The latent code is structured as a concatenation of features with different SO(3) transformation properties. Each feature type, represented as Hi, undergoes a transformation by the corresponding Wigner-D matrix D\u00b9(R).  This demonstrates the equivariance of the latent representation.", "section": "3.5 Equivariant Encoder"}, {"figure_path": "yRuJqoWoCs/figures/figures_19_1.jpg", "caption": "Figure 2: Our proposed Equivariant Perceiver IO (EPIO) architecture. (a) We take as input the concatenation of per-pixel image, ray, and camera embeddings, the latter two calculated using spherical harmonics. (b) The output of our equivariant encoder is a global latent code, including both global invariant and equivariant components. From those, we extract an equivariant reference frame through an equivariant MLP, while simultaneously obtaining invariant latents through inner product. (c) When a query camera is positioned in this equivariant reference frame, its pose becomes invariant, which enables the use of conventional Fourier basis to encode it. (d) Given an invariant latent and invariant pose, we use a conventional Perceiver IO decoder to generate predictions for each query ray.", "description": "This figure illustrates the architecture of the proposed Equivariant Perceiver IO (EPIO) model for multi-view depth estimation.  It shows the input stage combining image, ray, and camera embeddings; the equivariant encoder generating global invariant and equivariant latents; the extraction of an equivariant reference frame; and finally, the decoder using a conventional Perceiver IO architecture to produce predictions based on invariant latent and pose information.", "section": "3 Method"}, {"figure_path": "yRuJqoWoCs/figures/figures_22_1.jpg", "caption": "Figure 12: Equivariant Decoder.", "description": "The figure illustrates the equivariant decoder architecture.  It shows how the equivariant latent features from the encoder, along with equivariant positional encodings of query rays and camera poses, are processed through a series of equivariant linear layers and a multi-head attention mechanism to generate equivariant output features (00, 01,\u2026, Olmax).  These are then converted to invariant features (O'0) through an invariant layer. The process ensures that the output remains consistent regardless of changes in global reference frame.", "section": "3.6 Decoder"}, {"figure_path": "yRuJqoWoCs/figures/figures_23_1.jpg", "caption": "Figure 13: Invariant Layer", "description": "This figure shows the architecture of the invariant layer used in the decoder. It takes equivariant features as input and transforms them into invariant features using equivariant linear layers and inner product operations. The output is a set of invariant features that are used for final prediction.", "section": "3.6 Decoder"}, {"figure_path": "yRuJqoWoCs/figures/figures_24_1.jpg", "caption": "Figure 6: Stereo depth estimation results on ScanNet, using our proposed EPIO architecture.", "description": "This figure shows a qualitative comparison of depth estimation results on the ScanNet dataset.  It presents input images from two viewpoints, the ground truth depth map, and the depth maps generated by the DeFiNe (Non-Equi) baseline and the proposed EPIO (Equi) model. The EPIO model shows improved performance in accurately estimating depth compared to the baseline, particularly in capturing fine details and handling challenging regions.", "section": "4 Experimental Results"}]