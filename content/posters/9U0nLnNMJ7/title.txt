Compact Language Models via Pruning and Knowledge Distillation