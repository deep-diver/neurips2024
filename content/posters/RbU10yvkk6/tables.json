[{"figure_path": "RbU10yvkk6/tables/tables_1_1.jpg", "caption": "Table 1: We conduct a comparative analysis of our VQGAN-LC against two advanced variants of VQGAN [1], namely VQGAN-FC and VQGAN-EMA, focusing on the effects of enlarging their codebook sizes from 1,024 to 100K. The only difference among the three models lies in the initialization and optimization of the codebook. The evaluation covers both reconstruction and generation using the latent diffusion model (LDM) [3] on the ImageNet dataset.", "description": "This table compares the performance of three different models (VQGAN-FC, VQGAN-EMA, and VQGAN-LC) on image reconstruction and generation tasks using the ImageNet dataset.  The models differ in their codebook initialization and optimization strategies. The table shows the rFID score for reconstruction and FID score for LDM generation, for each model, and for different codebook sizes (1024, 16384, 50K, 100K).", "section": "Introduction"}, {"figure_path": "RbU10yvkk6/tables/tables_6_1.jpg", "caption": "Table 2: Reconstruction performance on ImageNet-1K. The term \u201c# Tokens\u201d refers to the number of tokens used to represent an image. The codebook utilization rate is computed across all training images. The FC and EMA mechanisms are originally introduced by ViT-VQGAN [21] and VQVAE [6, 7], respectively. It is important to note that increasing the codebook size incurs almost no additional computational cost.", "description": "This table presents a comparison of various image quantization models on the ImageNet-1K dataset, focusing on their reconstruction performance.  It shows the reconstruction error (rFID), perceptual similarity (LPIPS), peak signal-to-noise ratio (PSNR), and structural similarity index (SSIM) for different models with varying codebook sizes and numbers of tokens used to represent each image. The table highlights the improved performance of VQGAN-LC (the proposed model) in terms of lower reconstruction error and higher perceptual similarity, especially with larger codebooks.", "section": "4.2 Main Results"}, {"figure_path": "RbU10yvkk6/tables/tables_7_1.jpg", "caption": "Table 3: Reconstruction performance on FFHQ.", "description": "This table presents the reconstruction performance results on the FFHQ dataset.  It compares several methods (RQVAE, VQWAE, MQVAE, VQGAN, VQGAN-FC, VQGAN-EMA, and VQGAN-LC) across different metrics: # Tokens (number of tokens used to represent an image), Codebook Size, Utilization (percentage of codebook entries utilized), rFID (reconstruction quality), LPIPS (perceptual similarity), PSNR (peak signal-to-noise ratio), and SSIM (structural similarity index).  The table highlights the performance improvement achieved by VQGAN-LC, demonstrating its ability to efficiently utilize a large codebook.", "section": "4.2 Main Results"}, {"figure_path": "RbU10yvkk6/tables/tables_7_2.jpg", "caption": "Table 4: Image generation on ImageNet-1K.", "description": "This table presents the FID scores achieved by various image generation models when integrated with different image quantization models on the ImageNet-1K dataset.  It compares the FID scores of several methods, including different variants of VQGAN (VQGAN-FC, VQGAN-EMA, and VQGAN-LC), with different image generation models (GPT, SiT-XL, DiT-XL, and LDM). The table highlights the impact of using VQGAN-LC with a large codebook size (100,000) on the FID scores, demonstrating improved performance across various generation models.  The number of tokens (# Tokens) and codebook size used by each method is also provided, along with the codebook utilization rate for the VQGAN variants.", "section": "4 Experiments"}, {"figure_path": "RbU10yvkk6/tables/tables_8_1.jpg", "caption": "Table 5: Image generation on FFHQ.", "description": "This table presents the FID scores for unconditional image generation on the FFHQ dataset using different image quantization models integrated with various generative models like GPT, LDM.  It shows the performance of VQGAN-FC, VQGAN-EMA and VQGAN-LC (the proposed method) with different codebook sizes and utilization rates. The FID scores indicate the quality of generated images, with lower scores indicating better quality.", "section": "4.2 Main Results"}, {"figure_path": "RbU10yvkk6/tables/tables_8_2.jpg", "caption": "Table 6: Ablation study of using various codebook initialization strategies on ImageNet.", "description": "This table presents the ablation study results on ImageNet, comparing different codebook initialization strategies (Random Initialization, Random Selection, K-Means Clustering) using various vision models (ViT-L, ResNet-50, ViT-B).  It shows the utilization rate, rFID, LPIPS, PSNR, and SSIM metrics for each strategy.  The goal is to determine the best codebook initialization method for optimal performance.", "section": "4.3 Ablation Studies"}, {"figure_path": "RbU10yvkk6/tables/tables_9_1.jpg", "caption": "Table 7: Ablation study of using different codebook sizes on ImageNet.", "description": "This table presents the ablation study results on the ImageNet dataset by varying the codebook size from 1,000 to 200,000. The results show minimal improvements beyond a codebook size of 100,000.  Key metrics such as rFID, LPIPS, PSNR, and SSIM are reported for each codebook size to evaluate reconstruction quality.  The utilization rate remains consistently high, exceeding 99% across all sizes.", "section": "4.2 Main Results"}, {"figure_path": "RbU10yvkk6/tables/tables_9_2.jpg", "caption": "Table 8: The computational cost of VQGAN-LC with different codebook sizes.", "description": "This table shows the computational cost (measured in MACs - multiply-accumulate operations) and model size (in parameters) for the VQGAN-LC model with two different codebook sizes: 16,384 and 100,000.  It highlights that increasing the codebook size from 16,384 to 100,000 has a negligible impact on computational cost and model size, demonstrating the efficiency of the proposed method.", "section": "4.2 Main Results"}, {"figure_path": "RbU10yvkk6/tables/tables_9_3.jpg", "caption": "Table 3: Reconstruction performance on FFHQ.", "description": "This table presents the reconstruction performance results for the FFHQ dataset, focusing on metrics such as rFID, LPIPS, PSNR, and SSIM. It compares the performance of different models: RQVAE, VQWAE, MQVAE, VQGAN, VQGAN-FC, VQGAN-EMA, and VQGAN-LC (the proposed model). The table shows the number of tokens, codebook size, utilization rate, and the reconstruction performance in terms of these metrics.", "section": "4.2 Main Results"}, {"figure_path": "RbU10yvkk6/tables/tables_13_1.jpg", "caption": "Table 10: The impact of maintaining a static codebook and incorporating a projector on ImageNet.", "description": "This table presents an ablation study on ImageNet, comparing the reconstruction performance (measured by rFID, LPIPS, PSNR, and SSIM) under different codebook initialization strategies.  It shows the results when the codebook is static (not updated during training), when a projector is used to map the codebook to a latent space, and when both are implemented.  The results highlight the significant improvement in reconstruction quality when a projector is used with a static codebook, indicating the effectiveness of the proposed method.", "section": "4 Experiments"}, {"figure_path": "RbU10yvkk6/tables/tables_13_2.jpg", "caption": "Table 11: Ablation study on the dimension of the projected codebook on ImageNet.", "description": "This table presents the results of an ablation study conducted to evaluate the impact of varying the dimension of the projected codebook (D') in the proposed VQGAN-LC model.  The study was performed on the ImageNet dataset. The table shows the codebook utilization rate, reconstruction error (rFID), perceptual loss (LPIPS), peak signal-to-noise ratio (PSNR), and structural similarity index (SSIM) for different values of D', ranging from 8 to 512.  The results indicate that the model's performance remains relatively stable across a wide range of D' values, consistently maintaining a high codebook utilization rate.", "section": "4 Experiments"}]