[{"figure_path": "0AumdfLzpK/tables/tables_7_1.jpg", "caption": "Table 1: Generalization performance on video benchmarks from DMControl-GB [13]. We report the results on mean and standard deviation over 5 seeds. The scores of the comparison methods were taken from their respective papers, and in cases where the scores were unavailable, they were obtained through our implementation using the official codes. \u0394 indicates the difference with second best.", "description": "This table compares the performance of SimGRL against other state-of-the-art methods on six tasks within the DeepMind Control Suite-Generalization Benchmark (DMControl-GB) dataset.  The results are presented separately for the \"Video Easy\" and \"Video Hard\" subsets, which vary in the level of background perturbation. The table shows average scores and standard deviations across five random seeds, offering a robust comparison. The \u0394 column quantifies SimGRL's improvement over the second-best performing method for each task.", "section": "5.1 Results on DMControl-GB"}, {"figure_path": "0AumdfLzpK/tables/tables_13_1.jpg", "caption": "Table 1: Generalization performance on video benchmarks from DMControl-GB [13]. We report the results on mean and standard deviation over 5 seeds. The scores of the comparison methods were taken from their respective papers, and in cases where the scores were unavailable, they were obtained through our implementation using the official codes.  \u0394 indicates the difference with second best.", "description": "This table presents the average scores and standard deviations across five different seeds for six tasks within the DeepMind Control Suite generalization benchmark's Video Easy and Video Hard categories.  The results are presented for the proposed SimGRL method and several state-of-the-art comparative methods.  The delta (\u0394) column shows the performance difference between SimGRL and the second-best performing method for each task.  The table demonstrates SimGRL's robust performance across diverse tasks, especially in the challenging Video Hard environment.", "section": "5.1 Results on DMControl-GB"}, {"figure_path": "0AumdfLzpK/tables/tables_18_1.jpg", "caption": "Table 4: Performance on DMControl-GB at video hard level for different strong data augmentations. The scores were evaluated over 5 seeds. Percentages indicate variations compared to RO.", "description": "This table presents the results of an ablation study comparing different strong data augmentation methods on the DMControl-GB benchmark's 'Video Hard' level. The methods compared are the original random overlay (RO), shifted random overlay (SRO, which is SimGRL-S in the paper), irregularly shifted random overlay (I-SRO), and arbitrarily stacked random overlay (A-SRO).  The table shows the average performance and percentage improvement compared to the original RO method for each task (Walker, Walk; Walker, Stand; Ball In Cup, Catch; Cartpole, Swingup; Finger, Spin; Cheetah, Run) in the benchmark.", "section": "B.4 Different Data Augmentations"}, {"figure_path": "0AumdfLzpK/tables/tables_18_2.jpg", "caption": "Table 1: Generalization performance on video benchmarks from DMControl-GB [13]. We report the results on mean and standard deviation over 5 seeds. The scores of the comparison methods were taken from their respective papers, and in cases where the scores were unavailable, they were obtained through our implementation using the official codes. \u0394 indicates the difference with second best.", "description": "This table presents the results of the zero-shot generalization performance of SimGRL and other state-of-the-art methods on the DMControl-GB video benchmarks.  The table includes mean and standard deviation scores across 5 different seeds for six tasks, split between Video Easy and Video Hard levels of difficulty. The \u0394 column highlights the performance difference between SimGRL and the second-best performing method for each task and difficulty level.  The scores for the comparison methods were either taken from their respective publications or re-implemented by the authors using official codes when unavailable.", "section": "5.1 Results on DMControl-GB"}, {"figure_path": "0AumdfLzpK/tables/tables_21_1.jpg", "caption": "Table 1: Generalization performance on video benchmarks from DMControl-GB [13]. We report the results on mean and standard deviation over 5 seeds. The scores of the comparison methods were taken from their respective papers, and in cases where the scores were unavailable, they were obtained through our implementation using the official codes. \u0394 indicates the difference with second best.", "description": "This table presents a comparison of the generalization performance of different algorithms on six video tasks from the DeepMind Control Suite Generalization Benchmark (DMControl-GB).  The algorithms compared include SAC, RAD, DrQ, SODA, SVEA, TLDA, SGQN, EAR, CG2A, and the proposed SimGRL.  The table shows the average scores and standard deviations across five random seeds for each algorithm and task in both 'Video Easy' and 'Video Hard' scenarios.  The 'Video Hard' setting is more challenging because of dynamically changing backgrounds.  The \u0394 column indicates the performance difference between SimGRL and the second-best performing algorithm for each task.", "section": "5.1 Results on DMControl-GB"}, {"figure_path": "0AumdfLzpK/tables/tables_26_1.jpg", "caption": "Table 1: Generalization performance on video benchmarks from DMControl-GB [13]. We report the results on mean and standard deviation over 5 seeds. The scores of the comparison methods were taken from their respective papers, and in cases where the scores were unavailable, they were obtained through our implementation using the official codes. \u0394 indicates the difference with second best.", "description": "This table presents the results of the zero-shot generalization performance evaluation on six tasks from the DeepMind Control Suite Generalization Benchmark (DMControl-GB).  The table compares the proposed SimGRL method against several state-of-the-art algorithms for visual RL generalization.  Performance is measured by average score and standard deviation across five random seeds, and the difference between SimGRL's performance and the second-best result is highlighted.  The results are separated into 'Video Easy' and 'Video Hard' scenarios, representing different levels of background dynamism.", "section": "5.1 Results on DMControl-GB"}]