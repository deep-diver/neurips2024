[{"figure_path": "fTKcqr4xuX/tables/tables_9_1.jpg", "caption": "Table 1: Performance comparison with CIFAR-N leaderboard (http://noisylabels.com/) in terms of testing accuracy. \u201cAggre\u201d, \u201cRand1\u201d, . . . , \u201cNoisy\u201d denote various types of human label noise. We compare with four methods that covers the top three performance for all noise categories: ProMix [Xiao et al., 2023], ILL [Chen et al., 2023], PLS [Albert et al., 2023] and DivideMix [Li et al., 2020]. Our approach, a Noise Ignorant linear model trained on features extracted by the self-supervised foundation model DINOv2 [Oquab et al., 2023] achieves new state-of-the-art results, highlighted in bold. We employed Python\u2019s sklearn logistic regression and cross-validation functions without data augmentation; the results are deterministic and directly reproducible.", "description": "This table compares the performance of different methods on the CIFAR-N noisy label dataset.  It shows the testing accuracy of several state-of-the-art methods on different types of human-labeled noise. The proposed method, FE+NI-ERM, achieves state-of-the-art results, showcasing significant improvements over existing approaches.", "section": "Practical implication"}, {"figure_path": "fTKcqr4xuX/tables/tables_32_1.jpg", "caption": "Table 1: Performance comparison with CIFAR-N leaderboard (http://noisylabels.com/) in terms of testing accuracy. \"Aggre\", \"Rand1\", ..., \"Noisy\" denote various types of human label noise. We compare with four methods that covers the top three performance for all noise categories: ProMix [Xiao et al., 2023], ILL [Chen et al., 2023], PLS [Albert et al., 2023] and DivideMix [Li et al., 2020]. Our approach, a Noise Ignorant linear model trained on features extracted by the self-supervised foundation model DINOv2 [Oquab et al., 2023] achieves new state-of-the-art results, highlighted in bold. We employed Python's sklearn logistic regression and cross-validation functions without data augmentation; the results are deterministic and directly reproducible.", "description": "This table compares the performance of different methods on the CIFAR-N dataset. It shows the testing accuracy of various methods on different types of human label noise, including the proposed method. The proposed method is a Noise Ignorant linear model trained on DINOv2 features and achieves state-of-the-art results.", "section": "7 Practical implication"}, {"figure_path": "fTKcqr4xuX/tables/tables_32_2.jpg", "caption": "Table 1: Performance comparison with CIFAR-N leaderboard (http://noisylabels.com/) in terms of testing accuracy. \"Aggre\", \"Rand1\", ..., \"Noisy\" denote various types of human label noise. We compare with four methods that covers the top three performance for all noise categories: ProMix [Xiao et al., 2023], ILL [Chen et al., 2023], PLS [Albert et al., 2023] and DivideMix [Li et al., 2020]. Our approach, a Noise Ignorant linear model trained on features extracted by the self-supervised foundation model DINOv2 [Oquab et al., 2023] achieves new state-of-the-art results, highlighted in bold. We employed Python's sklearn logistic regression and cross-validation functions without data augmentation; the results are deterministic and directly reproducible.", "description": "This table compares the performance of the proposed method (FE+NI-ERM) with other state-of-the-art methods on the CIFAR-N dataset. It shows the test accuracy for different noise types and highlights the superior performance of the proposed method. Note that the results are deterministic and reproducible.", "section": "7 Practical implication"}, {"figure_path": "fTKcqr4xuX/tables/tables_33_1.jpg", "caption": "Table 1: Performance comparison with CIFAR-N leaderboard (http://noisylabels.com/) in terms of testing accuracy. \"Aggre\", \"Rand1\", ..., \"Noisy\" denote various types of human label noise. We compare with four methods that covers the top three performance for all noise categories: ProMix [Xiao et al., 2023], ILL [Chen et al., 2023], PLS [Albert et al., 2023] and DivideMix [Li et al., 2020]. Our approach, a Noise Ignorant linear model trained on features extracted by the self-supervised foundation model DINOv2 [Oquab et al., 2023] achieves new state-of-the-art results, highlighted in bold. We employed Python's sklearn logistic regression and cross-validation functions without data augmentation; the results are deterministic and directly reproducible.", "description": "This table compares the performance of different methods on the CIFAR-N dataset, focusing on testing accuracy. It includes various types of human label noise and compares the proposed method (Noise Ignorant linear model using DINOv2 features) with four state-of-the-art methods (ProMix, ILL, PLS, and DivideMix). The results show that the proposed method achieves state-of-the-art performance and are deterministic, reproducible.", "section": "Practical implication"}, {"figure_path": "fTKcqr4xuX/tables/tables_33_2.jpg", "caption": "Table 1: Performance comparison with CIFAR-N leaderboard (http://noisylabels.com/) in terms of testing accuracy. \"Aggre\", \"Rand1\", ..., \"Noisy\" denote various types of human label noise. We compare with four methods that covers the top three performance for all noise categories: ProMix [Xiao et al., 2023], ILL [Chen et al., 2023], PLS [Albert et al., 2023] and DivideMix [Li et al., 2020]. Our approach, a Noise Ignorant linear model trained on features extracted by the self-supervised foundation model DINOv2 [Oquab et al., 2023] achieves new state-of-the-art results, highlighted in bold. We employed Python's sklearn logistic regression and cross-validation functions without data augmentation; the results are deterministic and directly reproducible.", "description": "This table compares the performance of different methods on the CIFAR-N dataset, a benchmark for noisy label classification.  The methods compared include state-of-the-art techniques and the proposed FE+NI-ERM approach. The table shows the accuracy of each method on various types of human-labeled noise. The proposed method, using a Noise Ignorant linear model with DINOv2 features, achieves state-of-the-art performance.", "section": "7 Practical implication"}, {"figure_path": "fTKcqr4xuX/tables/tables_34_1.jpg", "caption": "Table 1: Performance comparison with CIFAR-N leaderboard (http://noisylabels.com/) in terms of testing accuracy. \"Aggre\", \"Rand1\", ..., \"Noisy\" denote various types of human label noise. We compare with four methods that covers the top three performance for all noise categories: ProMix [Xiao et al., 2023], ILL [Chen et al., 2023], PLS [Albert et al., 2023] and DivideMix [Li et al., 2020]. Our approach, a Noise Ignorant linear model trained on features extracted by the self-supervised foundation model DINOv2 [Oquab et al., 2023] achieves new state-of-the-art results, highlighted in bold. We employed Python's sklearn logistic regression and cross-validation functions without data augmentation; the results are deterministic and directly reproducible.", "description": "This table compares the performance of different methods on the CIFAR-N dataset, including the proposed approach.  The results are presented as testing accuracy under various types of human-generated label noise. The proposed method (FE+NI-ERM using DINOv2 features) achieves state-of-the-art results. ", "section": "7 Practical implication"}, {"figure_path": "fTKcqr4xuX/tables/tables_34_2.jpg", "caption": "Table 1: Performance comparison with CIFAR-N leaderboard (http://noisylabels.com/) in terms of testing accuracy. \"Aggre\", \"Rand1\", ..., \"Noisy\" denote various types of human label noise. We compare with four methods that covers the top three performance for all noise categories: ProMix [Xiao et al., 2023], ILL [Chen et al., 2023], PLS [Albert et al., 2023] and DivideMix [Li et al., 2020]. Our approach, a Noise Ignorant linear model trained on features extracted by the self-supervised foundation model DINOv2 [Oquab et al., 2023] achieves new state-of-the-art results, highlighted in bold. We employed Python's sklearn logistic regression and cross-validation functions without data augmentation; the results are deterministic and directly reproducible.", "description": "This table compares the performance of different methods on the CIFAR-N dataset which is a benchmark for noisy label problems. The methods are compared in terms of testing accuracy for different types of human-generated label noise. The proposed method (FE+NI-ERM) achieves state-of-the-art results by using a noise-ignorant linear model trained on features extracted by DINOv2, a self-supervised foundation model. The results are deterministic due to not using data augmentation.", "section": "7 Practical implication"}]