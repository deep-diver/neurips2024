[{"figure_path": "7RQvjayHrM/tables/tables_6_1.jpg", "caption": "Table 1: Testing accuracy (%) on in-distribution tasks. \u201cTime\u201d denotes the total inference time in minutes. The best is in bold and the second-best is underlined.", "description": "This table presents the performance of various LLMs and LLM assembling methods on five in-distribution tasks: MMLU, GSM8K, CMMLU, ARC-C, and HumanEval.  The accuracy of each model on each task is shown, along with the total inference time.  The best performing model for each task is bolded, and the second-best is underlined. This allows for a comparison of the effectiveness of different LLMs and the proposed RouterDC method in solving these in-distribution benchmark problems.", "section": "4.2 Main Results"}, {"figure_path": "7RQvjayHrM/tables/tables_6_2.jpg", "caption": "Table 2: Testing accuracy (%) on out-of-distribution tasks. \u201cTime\u201d denotes the total inference time in minutes. The best is in bold and the second-best is underlined.", "description": "This table presents the performance of various LLMs and routing methods on three out-of-distribution (OOD) tasks: PreAlgebra, MBPP, and C-EVAL.  It shows the testing accuracy and inference time for each method.  The out-of-distribution tasks are different from those used in training, testing the models' ability to generalize. The best performing method for each task and overall average is highlighted in bold, with the second-best underlined.", "section": "4 Experiments"}, {"figure_path": "7RQvjayHrM/tables/tables_8_1.jpg", "caption": "Table 3: Robustness of RouterDC to LLM losses during inference.", "description": "This table demonstrates the robustness of the RouterDC model by evaluating its performance when individual LLMs are removed during the inference process.  It shows the testing accuracy on five in-distribution tasks (MMLU, GSM8K, CMMLU, ARC-C, HumanEval) for the complete model and for versions where one of the seven LLMs is excluded.  The results highlight RouterDC's resilience to the unavailability of single LLMs during inference.", "section": "4.4 Analysis"}, {"figure_path": "7RQvjayHrM/tables/tables_9_1.jpg", "caption": "Table 4: Testing accuracy(%) of RouterDC w/ or w/o task identity.", "description": "This table compares the performance of RouterDC with and without using task identity information during training.  It shows the testing accuracy across five different in-distribution tasks (MMLU, GSM8K, CMMLU, ARC-C, HumanEval) to evaluate the impact of incorporating task identity on the model's performance.", "section": "4.3 Sensitivity Analysis"}, {"figure_path": "7RQvjayHrM/tables/tables_14_1.jpg", "caption": "Table 5: Testing accuracy (%) with different \u03bb's.", "description": "This table presents the testing accuracy achieved by the RouterDC model across five different in-distribution tasks (MMLU, GSM8K, CMMLU, ARC-C, and HumanEval) with varying values of the hyperparameter \u03bb.  The hyperparameter \u03bb balances the influence of the sample-LLM contrastive loss and the sample-sample contrastive loss in the model's training.  The table shows how the model's performance changes across different tasks as \u03bb is altered, demonstrating the model's robustness to different values of this hyperparameter.", "section": "4.3 Sensitivity Analysis"}, {"figure_path": "7RQvjayHrM/tables/tables_14_2.jpg", "caption": "Table 6: Testing accuracy (%) with different N's.", "description": "This table presents the results of an experiment conducted to evaluate the impact of the number of clusters (N) used in the sample-sample contrastive loss on the testing accuracy of the RouterDC model. The experiment varied the number of clusters from 2 to 30 and reported the testing accuracy for five different tasks (MMLU, GSM8K, CMMLU, ARC-C, HumanEval) and the average accuracy across all tasks. The results indicate that the RouterDC model's performance is relatively insensitive to a wide range of N values.", "section": "4.3 Sensitivity Analysis"}, {"figure_path": "7RQvjayHrM/tables/tables_14_3.jpg", "caption": "Table 7: Testing accuracy (%) with different H's.", "description": "This table presents the testing accuracy results obtained from experiments using the RouterDC model with varying numbers of out-group queries (H).  The results are shown for five different in-distribution tasks (MMLU, GSM8K, CMMLU, ARC-C, HumanEval) along with the average accuracy across these tasks. It demonstrates how the performance of RouterDC changes when the number of out-group queries in the sample-sample contrastive loss is altered. This helps to evaluate the sensitivity of the model to this specific parameter.", "section": "4.3 Sensitivity Analysis"}, {"figure_path": "7RQvjayHrM/tables/tables_15_1.jpg", "caption": "Table 8: Testing accuracy (%) with #LLMs. As can be seen, adding LLMs consistency enhances the average accuracy.", "description": "This table presents the testing accuracy results for different numbers of LLMs used in the RouterDC model.  It shows how the average accuracy across five in-distribution tasks (MMLU, GSM8K, CMMLU, ARC-C, HumanEval) improves as more LLMs are added to the ensemble.  The table demonstrates the cumulative effect of including additional LLMs, highlighting the performance gain from using a larger ensemble of models.", "section": "4.2 Main Results"}, {"figure_path": "7RQvjayHrM/tables/tables_16_1.jpg", "caption": "Table 9: Testing accuracy (%) on HumanEval task. The best is in bold.", "description": "This table presents the testing accuracy achieved on the HumanEval task by different methods, including several individual LLMs and ensemble methods like ZOOTER, CosineClassifier, and the proposed RouterDC.  It highlights the superior performance of RouterDC compared to other approaches, demonstrating its effectiveness in selecting the most suitable LLM for each query within this specific task.", "section": "4.4 Analysis"}, {"figure_path": "7RQvjayHrM/tables/tables_16_2.jpg", "caption": "Table 10: Testing accuracy (%) on JavaScript task. The best is in bold.", "description": "This table presents the performance of different LLMs and routing methods on a JavaScript task, which is considered an out-of-distribution task.  The accuracy of each model is shown, highlighting the best-performing model in bold.  This allows comparison of various models' ability to generalize to unseen tasks, which is a key evaluation criterion for LLM routing methods.", "section": "4.4 Analysis"}, {"figure_path": "7RQvjayHrM/tables/tables_16_3.jpg", "caption": "Table 11: Testing accuracy (%) of ZOOTER w/ Lsample-sample on in-distribution tasks.", "description": "This table presents the testing accuracy of the ZOOTER model with and without the addition of the sample-sample contrastive loss, evaluated on five in-distribution tasks (MMLU, GSM8K, CMMLU, ARC-C, and HumanEval).  The results show a significant improvement in average accuracy when the sample-sample loss is included, highlighting its effectiveness.", "section": "F Effectiveness of Lsample-sample for ZOOTER"}, {"figure_path": "7RQvjayHrM/tables/tables_17_1.jpg", "caption": "Table 12: Testing accuracy (%) of ZOOTER w/ Lsample-sample on out-of-distribution tasks", "description": "This table presents the testing accuracy achieved by the ZOOTER model, both with and without the inclusion of the sample-sample contrastive loss, across three out-of-distribution (OOD) tasks: Pre-Algebra, MBPP, and C-EVAL.  The results highlight the performance improvement gained by incorporating the sample-sample loss, showcasing its effectiveness in enhancing the model's generalization capabilities to unseen data distributions.", "section": "4.2 Main Results"}, {"figure_path": "7RQvjayHrM/tables/tables_17_2.jpg", "caption": "Table 13: Testing accuracy (%) of RouterDC with or without setting s(t) to 0 for incorrect LLMs.", "description": "This table presents the results of an experiment comparing the performance of RouterDC with and without a penalty for incorrect LLM outputs in multiple-choice questions. The experiment was conducted on five in-distribution tasks (MMLU, GSM8K, CMMLU, ARC-C, HumanEval) to evaluate the impact of the penalty on the overall accuracy.  The \"w/o punishing s(t)\" row shows the accuracy without applying the penalty, while the \"w/ punishing s(t)\" row shows the accuracy when a penalty is applied. The results demonstrate the effect of the penalty on the model's performance across different tasks.", "section": "4.4 Analysis"}]