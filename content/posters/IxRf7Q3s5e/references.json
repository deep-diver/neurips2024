{"references": [{"fullname_first_author": "Kaiming He", "paper_title": "Deep residual learning for image recognition", "publication_date": "2016-00-00", "reason": "This paper is foundational for many of the ResNet-based architectures employed in the current state-of-the-art recurrent solvers, which are compared to the NeuralSolver proposed in this work."}, {"fullname_first_author": "Avi Schwarzschild", "paper_title": "Can you learn an algorithm? Generalizing from easy to hard problems with recurrent networks", "publication_date": "2021-12-06", "reason": "This paper introduces the concept of recurrent solvers, a class of recurrent neural networks that can execute at test time more iterations than the number of iterations used during training, which is a key concept and baseline method addressed in the current paper."}, {"fullname_first_author": "Arpit Bansal", "paper_title": "End-to-end algorithm synthesis with recurrent networks: Extrapolation without overthinking", "publication_date": "2022-00-00", "reason": "This paper is the state-of-the-art recurrent solver architecture before the NeuralSolver, which improves the extrapolation capabilities by adding new components that are compared to the current work."}, {"fullname_first_author": "Sepp Hochreiter", "paper_title": "Long short-term memory", "publication_date": "1997-00-00", "reason": "This paper introduces the LSTM architecture, a fundamental recurrent neural network module used in many deep learning models and the recurrent module of the NeuralSolver."}, {"fullname_first_author": "Maxime Chevalier-Boisvert", "paper_title": "Minigrid & miniworld: Modular & customizable reinforcement learning environments for goal-oriented tasks", "publication_date": "2023-06-13", "reason": "This paper introduces the Minigrid and Miniworld environments, providing a novel benchmark with several different-size tasks used in this work to test the performance of the proposed NeuralSolver."}]}