{"references": [{"fullname_first_author": "Ben Mildenhall", "paper_title": "NeRF: Representing scenes as neural radiance fields for view synthesis", "publication_date": "2020-10-10", "reason": "This paper introduces NeRF, a foundational model for novel view synthesis that is leveraged and extended by ProEdit."}, {"fullname_first_author": "Bernhard Kerbl", "paper_title": "3D Gaussian splatting for real-time radiance field rendering", "publication_date": "2023-04-01", "reason": "This paper introduces 3D Gaussian splatting, the core scene representation method used within ProEdit."}, {"fullname_first_author": "Ayaan Haque", "paper_title": "Instruct-NeRF2NeRF: Editing 3D scenes with instructions", "publication_date": "2023-10-10", "reason": "This paper introduces Instruct-NeRF2NeRF, a prior work on instruction-guided 3D scene editing that ProEdit builds upon and improves upon."}, {"fullname_first_author": "Tim Brooks", "paper_title": "Learning to follow image editing instructions", "publication_date": "2023-06-01", "reason": "This paper introduces a method for image editing instructions which ProEdit adapts to the 3D scene editing domain."}, {"fullname_first_author": "Robin Rombach", "paper_title": "High-resolution image synthesis with latent diffusion models", "publication_date": "2022-06-01", "reason": "This paper introduces high-resolution image synthesis using latent diffusion models, which is a crucial technique used for the image editing tasks in ProEdit."}]}