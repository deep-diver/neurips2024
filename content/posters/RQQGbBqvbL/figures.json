[{"figure_path": "RQQGbBqvbL/figures/figures_7_1.jpg", "caption": "Figure 1: AUC comparison under different label quality k.", "description": "This figure shows the AUC (Area Under the Curve) scores for different methods across various datasets under different label quality (k).  The x-axis represents the label quality (k), ranging from 0.1 to 0.3.  The y-axis represents the AUC scores.  Multiple lines represent different methods (Single, SLF, DN, CoNAL, ADMOE, and Ours), allowing for a comparison of their performance under varying levels of label noise.  The datasets used are Agnews, IMDb, Yelp, Diabetes, Celeba, and F-MNIST. The figure illustrates how the performance of each method changes as the label quality (k) increases.  Generally, higher label quality leads to better AUC scores for all methods, though the proposed method ('Ours') consistently performs best, indicating its robustness to noisy labels.", "section": "4.3 Main Results"}, {"figure_path": "RQQGbBqvbL/figures/figures_8_1.jpg", "caption": "Figure 1: AUC comparison under different label quality k.", "description": "This figure compares the Area Under the Curve (AUC) performance of different methods under varying label quality (k).  It shows that the proposed \"Ours\" method consistently outperforms other approaches across different label qualities and dataset types. The x-axis represents the label quality, ranging from 0.1 to 0.3, indicating the percentage of correctly labeled data. The y-axis shows the AUC, a measure of classification performance.  Different colors represent different approaches, with \"Ours\" being the proposed method.  The figure provides a clear comparison of model performance with noisy labels and demonstrates the robustness of the proposed method.", "section": "4.3 Main Results"}]