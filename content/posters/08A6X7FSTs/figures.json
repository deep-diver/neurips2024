[{"figure_path": "08A6X7FSTs/figures/figures_0_1.jpg", "caption": "Figure 1: Given textual descriptions, Director3D employs three key components: the Cinematographer generates the camera trajectories, the Decorator creates the initial 3D scenes, and the Detailer refines the details.", "description": "This figure illustrates the pipeline of Director3D, a text-to-3D generation framework. It shows how three key components work together: The Cinematographer generates camera trajectories from a text description. The Decorator creates an initial 3D scene using these trajectories. Finally, the Detailer refines the details of the 3D scene to make it more realistic.  Examples of generated 3D scenes are shown as output.", "section": "Abstract"}, {"figure_path": "08A6X7FSTs/figures/figures_1_1.jpg", "caption": "Figure 2: Multi-view image results rendered with the generated camera trajectories and 3D scenes.", "description": "This figure shows several example images generated by the Director3D model. Each row represents a different scene generated from a text prompt. The images show a variety of scenes, including a collection of fresh vegetables in a basket, a bald man, a snowy woodland path, a cluster of tents, a stainless steel toaster, a paint-splattered easel, a badlands terrain, a marketplace, a leopard print hat, a swan on a lake, a derelict space station, and a steep gorge.  The images demonstrate the model's ability to generate realistic and diverse 3D scenes from text descriptions, along with plausible camera trajectories that capture interesting viewpoints.", "section": "1 Introduction"}, {"figure_path": "08A6X7FSTs/figures/figures_2_1.jpg", "caption": "Figure 3: Left: Comparison of the simplified camera trajectory distributions between synthetic and real-world multi-view datasets. Right: Pipeline and models of Director3D.", "description": "The figure compares the camera trajectory distributions in synthetic and real-world multi-view datasets.  The left panel shows how synthetic datasets have controlled and predefined camera trajectories, often following simple patterns like circles.  In contrast, the right panel illustrates real-world datasets which exhibit more complex, scene-specific and unpredictable camera trajectories. The right panel also details the architecture of Director3D, which consists of three key components: the Cinematographer (Traj-DiT), the Decorator (GM-LDM), and the Detailer (SDS++ loss).  The Cinematographer generates camera trajectories, the Decorator creates the initial 3D scene representation, and the Detailer refines the scene's details.", "section": "Method"}, {"figure_path": "08A6X7FSTs/figures/figures_4_1.jpg", "caption": "Figure 4: Left: Architecture of Traj-DiT. Right: Visualization of the predicted camera trajectory for different denoising timesteps.", "description": "The figure illustrates the architecture of the Trajectory Diffusion Transformer (Traj-DiT) and example camera trajectories generated by the model. The left panel displays the architecture of Traj-DiT, showing how text embeddings and timestep information are processed through cross-attention, self-attention, and MLP layers to produce a camera trajectory. The right panel shows example trajectories over time for two different text prompts: \"An apple\" and \"A park\".  The trajectories show how the model generates camera movement that is smooth and makes sense for the context of each scene.", "section": "4.2 Traj-DiT as Cinematographer"}, {"figure_path": "08A6X7FSTs/figures/figures_5_1.jpg", "caption": "Figure 5: Left: Architecture of GM-LDM. The model is fine-tuned from a 2D LDM with minor modifications, performing rendering-based denoising for generating initial 3D Gaussians. Right: Pipeline of calculating SDS++ loss, which refines the 3D Gaussians with the original 2D LDM.", "description": "This figure illustrates the architecture of the Gaussian-driven Multi-view Latent Diffusion Model (GM-LDM) and the process of calculating the SDS++ loss. The GM-LDM is a modified version of a 2D Latent Diffusion Model (LDM), which generates initial 3D Gaussians through rendering-based denoising. The SDS++ loss refines the generated 3D Gaussians by backpropagating a loss from images rendered at randomly interpolated cameras within the trajectory. This two-stage process improves the quality and detail of the generated 3D scenes.", "section": "4.3 GM-LDM as Decorator"}, {"figure_path": "08A6X7FSTs/figures/figures_7_1.jpg", "caption": "Figure 6: Generation results of Director3D for both camera trajectories and image sequences.", "description": "This figure showcases several examples of 3D scenes generated by Director3D, demonstrating its ability to generate both realistic camera trajectories and high-quality image sequences from text prompts. Each row presents a different text prompt, followed by a visualization of the predicted camera trajectory (a sequence of camera positions and orientations), and a series of rendered images from different viewpoints along the trajectory. The images are of high quality, exhibiting details, realistic lighting, and overall scene coherence.  The variety of scenes demonstrates the model's versatility in handling diverse text descriptions.", "section": "5.2 Generation Results"}, {"figure_path": "08A6X7FSTs/figures/figures_7_2.jpg", "caption": "Figure 7: Qualitative comparison between Director3D and different baselines.", "description": "This figure presents a qualitative comparison of 3D scene generation results from Director3D against three other methods: GRM, GaussianDreamer, and LucidDreamer.  Each row shows the same text prompt rendered by each of the four methods. The results highlight the superior realism and detail achieved by Director3D, particularly in terms of texture quality, lighting effects, and overall scene coherence, compared to the artifacts and inconsistencies present in the other methods. For example, the first row showcases the rendering of \"Four ripe apples in a basket.\" Director3D shows photorealistic apples within a realistically rendered basket; GRM's result misses the basket entirely; GaussianDreamer shows acceptable apples but lacks realism in the basket's texture and lighting; and LucidDreamer generates a blurry, unrealistic render.", "section": "5.3 Qualitative Comparison"}, {"figure_path": "08A6X7FSTs/figures/figures_9_1.jpg", "caption": "Figure 8: Screenshots of the interactive demo for visualizing generated camera trajectories and 3D Gaussians of Director3D. The frames are rendered with novel cameras.", "description": "This figure shows two examples of 3D scene generation using the Director3D model.  The top row displays the generated camera trajectory and a distance view of the scene, while the bottom shows the corresponding text prompt. The left-hand side depicts a lake reflecting the sky and surrounding cliffs, whereas the right shows a mountain pass with wind. In both instances, Director3D successfully produces diverse, high-quality renderings from multiple viewpoints.", "section": "5.5 User-specific Camera Trajectories"}, {"figure_path": "08A6X7FSTs/figures/figures_9_2.jpg", "caption": "Figure 9: Ablation of SDS++ loss", "description": "This figure shows the ablation study of the SDS++ loss. It compares the results of the full model with different variations of the SDS++ loss, including removing the refining process entirely, setting different parameters (\u03bbx, \u03bbz, wcfg) and setting \u03b5src = \u03b5. The results demonstrate the importance of each component in the SDS++ loss for achieving high-quality 3D generation. ", "section": "5.6 Ablation Study"}, {"figure_path": "08A6X7FSTs/figures/figures_16_1.jpg", "caption": "Figure 6: Generation results of Director3D for both camera trajectories and image sequences.", "description": "This figure showcases example outputs from the Director3D model, demonstrating its ability to generate camera trajectories and corresponding image sequences from text prompts.  Each row presents a different text prompt, followed by the generated camera trajectory (a series of camera viewpoints), and a multi-view rendering of the resulting 3D scene from those viewpoints. The figure visually displays the model's capacity to interpret diverse textual descriptions and produce coherent 3D scenes with realistically varied camera movements.", "section": "5.2 Generation Results"}, {"figure_path": "08A6X7FSTs/figures/figures_17_1.jpg", "caption": "Figure 11: Generation results with diversity.", "description": "This figure showcases the diversity of generation results from Director3D.  Using the same text prompts, the model generates diverse camera trajectories and 3D scenes. The top row shows the predicted camera trajectories for different prompts; the bottom row shows the rendered images from those same camera positions.", "section": "5.2 Generation Results"}, {"figure_path": "08A6X7FSTs/figures/figures_17_2.jpg", "caption": "Figure 12: Generation results with fine-grained control.", "description": "This figure shows the results of generating 3D scenes with fine-grained control over clothing and gender.  The text prompts specify clothing items, and the generated images accurately depict these features, demonstrating the model's ability to incorporate such details.  Each row shows different variations of the same prompt. ", "section": "5.2 Generation Results"}, {"figure_path": "08A6X7FSTs/figures/figures_18_1.jpg", "caption": "Figure 3: Left: Comparison of the simplified camera trajectory distributions between synthetic and real-world multi-view datasets. Right: Pipeline and models of Director3D.", "description": "The left part of the figure compares the camera trajectory distributions between synthetic and real-world multi-view datasets. The synthetic datasets have simple, predictable camera trajectories, while real-world datasets have complex, scene-specific trajectories. The right part of the figure shows the pipeline and models of Director3D, which consists of three key components: the Cinematographer (Traj-DiT), the Decorator (GM-LDM), and the Detailer (SDS++ loss). The Cinematographer generates camera trajectories from text descriptions. The Decorator generates pixel-aligned 3D Gaussians as an immediate 3D scene representation. The Detailer refines the 3D Gaussians using a novel SDS++ loss. ", "section": "Method"}, {"figure_path": "08A6X7FSTs/figures/figures_19_1.jpg", "caption": "Figure 3: Left: Comparison of the simplified camera trajectory distributions between synthetic and real-world multi-view datasets. Right: Pipeline and models of Director3D.", "description": "The figure compares camera trajectory distributions between synthetic and real-world datasets, highlighting the complexity of real-world trajectories.  It also presents a schematic diagram illustrating the architecture of Director3D, showcasing its three main components: the Cinematographer (Traj-DiT), Decorator (GM-LDM), and Detailer (SDS++ loss), which work collaboratively to generate camera trajectories and 3D scenes from textual descriptions.", "section": "Method"}, {"figure_path": "08A6X7FSTs/figures/figures_19_2.jpg", "caption": "Figure 3: Left: Comparison of the simplified camera trajectory distributions between synthetic and real-world multi-view datasets. Right: Pipeline and models of Director3D.", "description": "The figure compares the camera trajectory distributions in synthetic and real-world multi-view datasets, highlighting the complexity of real-world trajectories.  It then presents a schematic overview of the Director3D framework, showing its three main components: the Cinematographer (generating camera trajectories), the Decorator (creating initial 3D scenes), and the Detailer (refining scene details). The process starts with text input, which is processed by the Cinematographer, then the Decorator, and finally the Detailer to produce pixel-aligned 3D Gaussians as the final 3D scene representation.", "section": "Method"}]