[{"figure_path": "ffeUBoTcdS/tables/tables_7_1.jpg", "caption": "Table 1: Average classification error of the task CIFAR-10 \u2192 CIFAR-10-C in recurring TTA. The lowest error is in bold, (*) average value across 5 runs (different random seeds) is reported for PeTTA.", "description": "This table presents the average classification error for the CIFAR-10 to CIFAR-10-C task in a recurring test-time adaptation (TTA) setting.  The results are broken down by the visit number (how many times the model has adapted to the test set), showing how performance changes over time.  The lowest error for each visit is shown in bold, and the average performance of the PeTTA model over 5 runs is indicated with an asterisk. The table allows for a comparison of PeTTA's performance against other TTA methods.", "section": "5.3 Result - Benchmark Datasets"}, {"figure_path": "ffeUBoTcdS/tables/tables_8_1.jpg", "caption": "Table 1: Average classification error of the task CIFAR-10 \u2192 CIFAR-10-C in recurring TTA. The lowest error is in bold, (*) average value across 5 runs (different random seeds) is reported for PeTTA.", "description": "This table presents the average classification error for the CIFAR-10 to CIFAR-10-C task in a recurring test-time adaptation (TTA) setting.  The results are shown for 20 consecutive visits to the test set, where the same testing environments recur.  The table compares various TTA methods, including PeTTA (the proposed method), ROTTA, and others. The lowest error for each visit is highlighted in bold.  For PeTTA, the average across 5 independent runs is shown, indicated by an asterisk.", "section": "5.3 Result - Benchmark Datasets"}, {"figure_path": "ffeUBoTcdS/tables/tables_8_2.jpg", "caption": "Table 3: Average classification error on CCC [45] setting. Each column presents the average error within an adaptation interval (e.g., the second column provides the average error between the 6701 and 13400 adaptation steps). Each adaptation step here is performed on a mini-batch of 64 images.", "description": "This table shows the average classification error on the Continuously Changing Corruption (CCC) dataset.  The dataset simulates a continuously changing environment, and each column represents the average error over a specific interval of adaptation steps.  The results compare several methods, including the proposed PeTTA, ROTTA, and RDumb, demonstrating PeTTA's superior performance.", "section": "5.3 Result - Benchmark Datasets"}, {"figure_path": "ffeUBoTcdS/tables/tables_9_1.jpg", "caption": "Table 4: Average (across 20 visits) error of multiple variations of PeTTA: without (w/o) R(\u03b8), LAL; LAL only; fixed regularization coefficient ; adaptive coefficient \u03bbt, update rate \u03b1t; using anchor loss LAL.", "description": "This ablation study investigates the impact of each component of PeTTA on the final performance.  It compares the average error across 20 visits in recurring TTA for variations of PeTTA with different combinations of components removed or fixed.  The results show the importance of all components working together for optimal performance.", "section": "5.4 Ablation Study"}, {"figure_path": "ffeUBoTcdS/tables/tables_9_2.jpg", "caption": "Table 5: Average (across 20 visits) error of PeTTA. PeTTA favors various choices of regularizers R(\u03b8): L2 and cosine similarity in conjunction with Fisher [27, 40] coefficient.", "description": "This table shows the average classification error across 20 visits of PeTTA using different regularizers: L2, cosine similarity, and their combinations with the Fisher coefficient.  The results are presented for four different tasks: CIFAR-10 to CIFAR-10-C (CF-10-C), CIFAR-100 to CIFAR-100-C (CF-100-C), DomainNet (DN), and ImageNet to ImageNet-C (IN-C).  The table helps to demonstrate that PeTTA performs well regardless of the specific regularizer chosen.", "section": "5.3 Result - Benchmark Datasets"}, {"figure_path": "ffeUBoTcdS/tables/tables_23_1.jpg", "caption": "Table 6: Average classification error of PeTTA (across 20 visits) with varying sizes of source samples used for computing feature empirical mean (\u03bc) and covariant matrix (\u03a3).", "description": "This table shows the average classification error of the PeTTA model across 20 visits for four different tasks (CIFAR-10 to CIFAR-10-C, CIFAR-100 to CIFAR-100-C, DomainNet: real to clip, paint, sketch, and ImageNet to ImageNet-C).  The key variable is the size of the source samples used to compute the empirical mean (\u03bc) and covariance matrix (\u03a3). The sizes are 25%, 50%, 75%, and 100% of the available source samples. The table helps to analyze how the accuracy of PeTTA varies depending on the size of the source sample set used for the calculation of (\u03bc, \u03a3).", "section": "Additional Experimental Results of PeTTA"}, {"figure_path": "ffeUBoTcdS/tables/tables_24_1.jpg", "caption": "Table 1: Average classification error of the task CIFAR-10 \u2192 CIFAR-10-C in recurring TTA. The lowest error is in bold, (*) average value across 5 runs (different random seeds) is reported for PeTTA.", "description": "This table shows the average classification error for the CIFAR-10 to CIFAR-10-C task in a recurring test-time adaptation (TTA) setting.  The results are broken down by TTA visit (1-20) and method. The methods compared include several existing TTA approaches, a parameter-free baseline (LAME), a reset-based baseline (RDumb), and the proposed PeTTA method.  The lowest error rate for each visit is shown in bold. For the PeTTA method, the average of five independent runs is reported.", "section": "5.3 Result - Benchmark Datasets"}, {"figure_path": "ffeUBoTcdS/tables/tables_24_2.jpg", "caption": "Table 1: Average classification error of the task CIFAR-10 \u2192 CIFAR-10-C in recurring TTA. The lowest error is in bold, (*) average value across 5 runs (different random seeds) is reported for PeTTA.", "description": "This table shows the average classification error for different TTA methods on the CIFAR-10 to CIFAR-10-C task using recurring TTA.  The results are presented for each visit (up to 20) of the recurring testing scenarios.  The lowest error for each visit is shown in bold, and the results for PeTTA are averaged over 5 independent runs with different random seeds.", "section": "5.3 Result - Benchmark Datasets"}, {"figure_path": "ffeUBoTcdS/tables/tables_24_3.jpg", "caption": "Table 1: Average classification error of the task CIFAR-10 \u2192 CIFAR-10-C in recurring TTA. The lowest error is in bold, (*) average value across 5 runs (different random seeds) is reported for PeTTA.", "description": "This table presents the average classification error for the CIFAR-10 to CIFAR-10-C task using different test-time adaptation (TTA) methods in a recurring testing scenario.  The recurring TTA involves repeatedly exposing the model to the same test set over 20 visits. The lowest error for each visit and the average error across all visits are reported.  The table highlights the superior performance of the proposed PeTTA method, especially in later visits where other methods show significant performance degradation.", "section": "5.3 Result - Benchmark Datasets"}, {"figure_path": "ffeUBoTcdS/tables/tables_25_1.jpg", "caption": "Table 1: Average classification error of the task CIFAR-10 \u2192 CIFAR-10-C in recurring TTA. The lowest error is in bold, (*) average value across 5 runs (different random seeds) is reported for PeTTA.", "description": "This table presents the average classification error for the CIFAR-10 to CIFAR-10-C task across different recurring test-time adaptation (TTA) visits.  It shows the performance of several TTA methods, including PeTTA (the proposed method), over 20 cycles of adaptation, where the testing environment is revisited multiple times. The lowest error rate for each visit is highlighted in bold.  PeTTA's results are averaged over 5 runs with different random seeds, indicated by an asterisk (*) ", "section": "5.3 Result - Benchmark Datasets"}, {"figure_path": "ffeUBoTcdS/tables/tables_25_2.jpg", "caption": "Table 1: Average classification error of the task CIFAR-10 \u2192 CIFAR-10-C in recurring TTA. The lowest error is in bold, (*) average value across 5 runs (different random seeds) is reported for PeTTA.", "description": "This table presents the average classification error for the CIFAR-10 to CIFAR-10-C task using different test-time adaptation (TTA) methods in a recurring testing scenario.  The recurring TTA involves repeatedly adapting to the same test set over multiple cycles. The table shows the error rate for each method across 20 visits to the test set.  The lowest error rate for each visit is shown in bold, and the average error across 5 independent runs of PeTTA is indicated with an asterisk.", "section": "5.3 Result - Benchmark Datasets"}, {"figure_path": "ffeUBoTcdS/tables/tables_25_3.jpg", "caption": "Table 1: Average classification error of the task CIFAR-10 \u2192 CIFAR-10-C in recurring TTA. The lowest error is in bold, (*) average value across 5 runs (different random seeds) is reported for PeTTA.", "description": "This table shows the average classification error for different test-time adaptation (TTA) methods on the CIFAR-10 to CIFAR-10-C task in a recurring TTA setting.  The results are presented for 20 consecutive visits to the test set, allowing for observation of error accumulation over time. The lowest error rate for each visit is shown in bold, while the average error rate over the 5 independent runs performed for the PeTTA method is indicated with an asterisk.", "section": "5.3 Result - Benchmark Datasets"}, {"figure_path": "ffeUBoTcdS/tables/tables_26_1.jpg", "caption": "Table 1: Average classification error of the task CIFAR-10 \u2192 CIFAR-10-C in recurring TTA. The lowest error is in bold, (*) average value across 5 runs (different random seeds) is reported for PeTTA.", "description": "This table presents the average classification error for the CIFAR-10 to CIFAR-10-C task under the recurring test-time adaptation (TTA) setting.  The results show the performance of various TTA methods across 20 recurring visits to the same test environments. The lowest error for each visit is highlighted in bold, and the average performance of PeTTA across 5 independent runs with different random seeds is marked with an asterisk. This table provides a quantitative comparison of different TTA methods' ability to maintain performance over repeated exposure to the same test conditions.", "section": "5.3 Result - Benchmark Datasets"}, {"figure_path": "ffeUBoTcdS/tables/tables_26_2.jpg", "caption": "Table 15: Sensitivity of PeTTA with different choices of \u03bb0.", "description": "This table shows the average classification error of PeTTA on three datasets (CIFAR-10-C, CIFAR-100-C, and ImageNet-C) with different choices of the hyperparameter \u03bb0.  The results demonstrate the sensitivity of PeTTA's performance to this hyperparameter, showing that while optimal performance is achieved around \u03bb0 = 1e1, reasonably similar performance is obtained with values between 5e0 and 5e1. This indicates that the parameter \u03bb0 is not critically sensitive and doesn't require extremely fine-grained tuning.", "section": "F.5 The Sensitivity of Hyper-parameter Choices in PeTTA"}, {"figure_path": "ffeUBoTcdS/tables/tables_27_1.jpg", "caption": "Table 1: Average classification error of the task CIFAR-10 \u2192 CIFAR-10-C in recurring TTA. The lowest error is in bold, (*) average value across 5 runs (different random seeds) is reported for PeTTA.", "description": "This table presents the average classification error for the CIFAR-10 to CIFAR-10-C task under recurring test-time adaptation (TTA).  It shows the error rate for different methods across 20 visits to the test set.  The lowest error for each visit is highlighted in bold, and the average performance of the PeTTA method (across 5 independent runs with different random seeds) is marked with an asterisk.", "section": "5.3 Result - Benchmark Datasets"}, {"figure_path": "ffeUBoTcdS/tables/tables_27_2.jpg", "caption": "Table 1: Average classification error of the task CIFAR-10 \u2192 CIFAR-10-C in recurring TTA. The lowest error is in bold, (*) average value across 5 runs (different random seeds) is reported for PeTTA.", "description": "This table presents the average classification error for different methods on the CIFAR-10 to CIFAR-10-C task using the recurring TTA setting.  It shows the error rate for each method across 20 visits to the test set.  The lowest error for each visit is highlighted in bold, and PeTTA results are averaged across 5 runs with different random seeds.", "section": "5.3 Result - Benchmark Datasets"}, {"figure_path": "ffeUBoTcdS/tables/tables_27_3.jpg", "caption": "Table 1: Average classification error of the task CIFAR-10 \u2192 CIFAR-10-C in recurring TTA. The lowest error is in bold, (*) average value across 5 runs (different random seeds) is reported for PeTTA.", "description": "This table presents the average classification error for the CIFAR-10 to CIFAR-10-C task using different test-time adaptation (TTA) methods in a recurring testing scenario. The recurring TTA involves repeatedly exposing the model to the same testing environment after it has undergone various adaptations.  The table shows the error for each method across 20 visits to the recurring testing environment. The lowest error for each visit is shown in bold, and the average error across 5 runs of PeTTA (with different random seeds) is marked with an asterisk.", "section": "5.3 Result - Benchmark Datasets"}, {"figure_path": "ffeUBoTcdS/tables/tables_27_4.jpg", "caption": "Table 1: Average classification error of the task CIFAR-10 \u2192 CIFAR-10-C in recurring TTA. The lowest error is in bold, (*) average value across 5 runs (different random seeds) is reported for PeTTA.", "description": "This table presents the average classification error for the CIFAR-10 to CIFAR-10-C task using different test-time adaptation (TTA) methods in a recurring testing scenario.  The recurring scenario involves repeatedly adapting to the same test environments over 20 visits. The table shows the performance of various TTA methods (COTTA, EATA, RMT, MECTA, ROTTA, RDumb, ROID, TRIBE, and PeTTA) across these visits.  The lowest error rate for each visit is highlighted in bold, and the PeTTA results are averaged across five independent runs.", "section": "5.3 Result - Benchmark Datasets"}, {"figure_path": "ffeUBoTcdS/tables/tables_27_5.jpg", "caption": "Table 1: Average classification error of the task CIFAR-10 \u2192 CIFAR-10-C in recurring TTA. The lowest error is in bold, (*) average value across 5 runs (different random seeds) is reported for PeTTA.", "description": "This table shows the average classification error for different TTA methods on the CIFAR-10 to CIFAR-10-C task across 20 recurring visits.  The table compares PeTTA's performance against several existing TTA methods and a simple reset-based baseline. The lowest error for each visit is highlighted in bold, and PeTTA's results are averaged over 5 independent runs with different random seeds. The table helps to demonstrate PeTTA's superior stability compared to existing approaches in recurring TTA.", "section": "5.3 Result - Benchmark Datasets"}, {"figure_path": "ffeUBoTcdS/tables/tables_27_6.jpg", "caption": "Table 1: Average classification error of the task CIFAR-10 \u2192 CIFAR-10-C in recurring TTA. The lowest error is in bold, (*) average value across 5 runs (different random seeds) is reported for PeTTA.", "description": "This table presents the average classification error for the CIFAR-10 to CIFAR-10-C task using different test-time adaptation (TTA) methods in a recurring testing scenario.  The recurring scenario involves repeatedly exposing the model to the same test environments over 20 cycles. The table shows the average error for each visit (cycle) and for each method. The lowest error for each visit is highlighted in bold, and the average error for PeTTA (a proposed method) is an average across 5 independent runs with different random seeds.  The table helps demonstrate how different TTA methods perform across recurring testing environments, highlighting their stability and showing the superior performance of PeTTA in maintaining low error over time.", "section": "5.3 Result - Benchmark Datasets"}, {"figure_path": "ffeUBoTcdS/tables/tables_28_1.jpg", "caption": "Table 1: Average classification error of the task CIFAR-10 \u2192 CIFAR-10-C in recurring TTA. The lowest error is in bold, (*) average value across 5 runs (different random seeds) is reported for PeTTA.", "description": "This table presents the average classification error for the CIFAR-10 to CIFAR-10-C task using different test-time adaptation (TTA) methods in a recurring testing scenario.  The recurring scenario involves repeatedly exposing the model to the same test environments. The table shows the error rate for each visit (repeated exposure to the same test environment) up to 20 visits. The lowest error for each visit is shown in bold.  The PeTTA method's performance is an average across five independent runs with different random seeds.", "section": "5.3 Result - Benchmark Datasets"}, {"figure_path": "ffeUBoTcdS/tables/tables_28_2.jpg", "caption": "Table 1: Average classification error of the task CIFAR-10 \u2192 CIFAR-10-C in recurring TTA. The lowest error is in bold, (*) average value across 5 runs (different random seeds) is reported for PeTTA.", "description": "This table presents the average classification error for the CIFAR-10 to CIFAR-10-C task using different test-time adaptation (TTA) methods in a recurring TTA setting.  The results are shown for 20 consecutive visits to the test set. Lower error values indicate better performance.  The table includes results for several existing TTA methods (COTTA, EATA, RMT, MECTA, ROTTA, RDumb, ROID, TRIBE) and a parameter-free baseline (LAME).  The PeTTA method proposed in the paper is also shown, with the average of 5 independent runs reported.", "section": "5.3 Result - Benchmark Datasets"}, {"figure_path": "ffeUBoTcdS/tables/tables_31_1.jpg", "caption": "Table 1: Average classification error of the task CIFAR-10 \u2192 CIFAR-10-C in recurring TTA. The lowest error is in bold, (*) average value across 5 runs (different random seeds) is reported for PeTTA.", "description": "This table presents the average classification error for the CIFAR-10 to CIFAR-10-C task using different test-time adaptation (TTA) methods in a recurring testing scenario. The table shows the error rate for each of the 20 visits to the test set and the average error across all visits. The lowest error rate for each visit is highlighted in bold, and the average error rate for PeTTA is an average across 5 independent runs with different random seeds.", "section": "5.3 Result - Benchmark Datasets"}]