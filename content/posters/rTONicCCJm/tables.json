[{"figure_path": "rTONicCCJm/tables/tables_6_1.jpg", "caption": "Table 1: Statistics of the datasets.", "description": "This table presents the key statistics of the three datasets used in the paper's experiments: TRAFFIC, LARGE-SCALE, and T4C22.  For each dataset, it shows the number of nodes, edges, and time steps.  The TRAFFIC dataset includes PEMS-BAY and METR-LA.  The LARGE-SCALE dataset includes PV-US, CER-E, LONDON, MADRID. The T4C22 dataset includes LONDON, MADRID, MELBOURNE. This information is crucial for understanding the scale and characteristics of the data used to evaluate the proposed spatio-temporal imputation method.", "section": "6.1 Datasets"}, {"figure_path": "rTONicCCJm/tables/tables_7_1.jpg", "caption": "Table 2: Imputation performances (in terms of MAE) on Traffic dataset and Large-scale dataset.", "description": "This table presents the Mean Absolute Error (MAE) achieved by different imputation methods on two datasets: Traffic and Large-scale.  It compares the performance across various methods (Mean, MF, GRAPE, FP, PCFI, BRITS, SAITS, CSDI, IGNNK, SPIN-H, PoGeVon, PriSTI, and OPCR) under two missing data scenarios: point missing and spatial missing. The results show the MAE for each method on four different subsets within each dataset (PEMS-BAY, METR-LA, PV-US, and CER-E).", "section": "6.3.1 Highly Sparse Data Imputation"}, {"figure_path": "rTONicCCJm/tables/tables_8_1.jpg", "caption": "Table 3: Traffic Prediction performances.", "description": "This table presents the performance comparison of different models on two downstream tasks of the T4C22 dataset: congestion classification and travel time prediction.  The metrics used are weighted cross-entropy loss for congestion classification and MAE for travel time prediction.  The results show the performance of each model across three cities: London, Madrid, and Melbourne.", "section": "6.4 Traffic Prediction Task"}, {"figure_path": "rTONicCCJm/tables/tables_13_1.jpg", "caption": "Table 4: Timings and memory consumption.", "description": "This table shows the memory consumption and training speed (in terms of batches per second) for various models on two large-scale datasets (PV-US and CER-E). The results demonstrate that the proposed OPCR model is computationally efficient and has significant advantages over other state-of-the-art imputation methods.", "section": "A.3 Time Complexity and Run-time Analysis"}]