[{"figure_path": "HfpV6u0kbX/tables/tables_1_1.jpg", "caption": "Table 1: Comparison of supported features of different LLM serving systems", "description": "This table compares several large language model (LLM) serving systems across four key features: multi-task serving, multi-task quantization, dynamic task addition, and multi-task scheduling.  A checkmark indicates that the system supports the feature, while an 'X' indicates it does not.  The table highlights the unique capabilities of the LoRA-Inlaid system proposed in the paper.", "section": "1 Introduction"}, {"figure_path": "HfpV6u0kbX/tables/tables_6_1.jpg", "caption": "Table 2: Model quality of different approaches under different tasks (std-dev given in parentheses). GPTQ and AWQ are in gray background color since the quantized models produced by them cannot be shared across different tasks. We mark the best multi-task quantization approaches (i.e., the best among MLGPTQ, GPTQtweaked, AWQtweaked, and RTN) in bold.", "description": "This table presents the results of comparing different model quantization techniques across twelve different tasks.  The metrics used to evaluate the models are BLEU scores (for translation tasks), ROUGE scores (for summarization tasks), and accuracy (for other tasks).  The table highlights that the proposed MLGPTQ method outperforms other methods in terms of model quality, especially when considering the limited memory constraints often associated with multi-task learning.  The gray shading of the GPTQ and AWQ rows indicates that these methods were unable to share a quantized model across different tasks.", "section": "4.2 Model Quality after Quantization"}, {"figure_path": "HfpV6u0kbX/tables/tables_8_1.jpg", "caption": "Table 1: Comparison of supported features of different LLM serving systems", "description": "This table compares several LLM serving systems based on four key features: whether they support multi-task serving, multi-task quantization, dynamic task addition, and multi-task scheduling.  It highlights the capabilities of each system, showing which features are supported (X) and which are not.", "section": "1 Introduction"}, {"figure_path": "HfpV6u0kbX/tables/tables_9_1.jpg", "caption": "Table 4: Time cost of quantization.", "description": "This table shows a breakdown of the time it takes to perform different quantization methods. The three methods compared are: Full Quant (performing full quantization), Incr Quant (offline) (performing incremental quantization offline), and Incr Quant (performing incremental quantization online). The time is broken down into the time it takes to perform forward and calculate the Hessian matrix, the time it takes to aggregate the Hessian matrix and perform quantization, and the total time for the entire process. The peak memory used is also given.  The online incremental approach shows a significant reduction in total time and peak memory compared to the offline and full quantization.", "section": "4.4 More Experiments"}, {"figure_path": "HfpV6u0kbX/tables/tables_18_1.jpg", "caption": "Table 1: Comparison of supported features of different LLM serving systems", "description": "This table compares several LLM serving systems across four key features: multi-task serving, multi-task quantization, dynamic task addition, and multi-task scheduling.  It shows whether each system supports these capabilities, highlighting the unique capabilities of the LoRA-Inlaid system proposed in the paper.", "section": "1 Introduction"}, {"figure_path": "HfpV6u0kbX/tables/tables_18_2.jpg", "caption": "Table 1: Comparison of supported features of different LLM serving systems", "description": "This table compares various LLM serving systems based on their support for multi-tasking, model quantization, dynamic task addition, and multi-task scheduling.  It highlights the unique capabilities of LoRA-Inlaid, the system introduced in the paper, by showing its comprehensive support for all four features, unlike other systems that only partially support these functionalities.", "section": "1 Introduction"}]