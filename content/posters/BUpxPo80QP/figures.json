[{"figure_path": "BUpxPo80QP/figures/figures_1_1.jpg", "caption": "Figure 1: InterDreamer generates vivid 3D human-object interaction sequences guided by text descriptions, by synergizing semantics and dynamics knowledge from large-scale text-motion data (upper left), a large language model (bottom left), human-object interaction data (upper middle), and prior knowledge (bottom middle) from simple physics. We visualize the generated text-guided interaction sequence (upper right), with the beginning of the sequence unfolded (bottom right).", "description": "This figure illustrates the InterDreamer framework's ability to generate 3D human-object interaction sequences from text descriptions. It highlights the framework's key components: large language models for semantic understanding, text-to-motion models for human motion generation, and a physics-based world model for realistic object interaction. The figure shows how these components work together to create coherent and visually appealing HOI sequences.", "section": "1 Introduction"}, {"figure_path": "BUpxPo80QP/figures/figures_3_1.jpg", "caption": "Figure 2: An overview of our InterDreamer. (i) Our high-level planning analyzes the description using LLMs and provides guidance to the low-level control. (ii) Our low-level control includes a text-to-motion model that translates text into human actions a<sub>t+1</sub>, and an interaction retrieval model that extracts the object's first state s<sub>1</sub>. (iii) Our world model executes actions to output the next state s<sub>t+1</sub>. We achieve this by abstracting the problem as predicting the motion of contact vertices represented by red spheres for humans and blue spheres for objects on the top right \u2013 using human vertices as controls for the prediction of object vertices. An optimization process is coupled with the dynamics model, projecting the state and action onto valid counterparts. Solid arrows mean that the process is performed iteratively.", "description": "This figure presents a schematic overview of the InterDreamer framework. It is broken down into three main components: high-level planning, low-level control, and a world model. The high-level planning uses LLMs to process the text description and guide the low-level control, which consists of a text-to-motion model and an interaction retrieval model. The world model, incorporating an optimization process, then uses the actions generated by the low-level control to predict the object's future state. The figure highlights that the process is iterative and that the interaction is modeled by abstracting the problem as predicting the motion of contact vertices (red spheres for humans, blue spheres for objects).", "section": "3 Methodology"}, {"figure_path": "BUpxPo80QP/figures/figures_6_1.jpg", "caption": "Figure 1: InterDreamer generates vivid 3D human-object interaction sequences guided by text descriptions, by synergizing semantics and dynamics knowledge from large-scale text-motion data (upper left), a large language model (bottom left), human-object interaction data (upper middle), and prior knowledge (bottom middle) from simple physics. We visualize the generated text-guided interaction sequence (upper right), with the beginning of the sequence unfolded (bottom right).", "description": "This figure illustrates the InterDreamer framework.  It shows how the model combines semantic understanding from large language models and text-motion data with dynamic modeling based on simple physics to generate realistic 3D human-object interaction sequences from text descriptions. The figure uses various visual aids such as diagrams and example sequences to represent the data flow and the generated outputs. ", "section": "1 Introduction"}, {"figure_path": "BUpxPo80QP/figures/figures_6_2.jpg", "caption": "Figure 1: InterDreamer generates vivid 3D human-object interaction sequences guided by text descriptions, by synergizing semantics and dynamics knowledge from large-scale text-motion data (upper left), a large language model (bottom left), human-object interaction data (upper middle), and prior knowledge (bottom middle) from simple physics. We visualize the generated text-guided interaction sequence (upper right), with the beginning of the sequence unfolded (bottom right).", "description": "This figure shows an overview of the InterDreamer framework. The left side shows the sources of information used by the model, including large-scale text-motion data, a large language model, and human-object interaction data, as well as prior knowledge of simple physics. The right side visualizes the generated 3D human-object interaction sequence, guided by a text description, demonstrating the model's ability to generate realistic and coherent interactions.", "section": "1 Introduction"}, {"figure_path": "BUpxPo80QP/figures/figures_7_1.jpg", "caption": "Figure 1: InterDreamer generates vivid 3D human-object interaction sequences guided by text descriptions, by synergizing semantics and dynamics knowledge from large-scale text-motion data (upper left), a large language model (bottom left), human-object interaction data (upper middle), and prior knowledge (bottom middle) from simple physics. We visualize the generated text-guided interaction sequence (upper right), with the beginning of the sequence unfolded (bottom right).", "description": "This figure illustrates the InterDreamer framework. It shows how the model combines semantic and dynamic knowledge to generate 3D human-object interaction sequences from text descriptions. The figure displays different components involved in the framework, including large language models, text-to-motion models, human-object interaction data, and a physics-based world model. The generated interaction sequence is also visualized.", "section": "1 Introduction"}, {"figure_path": "BUpxPo80QP/figures/figures_7_2.jpg", "caption": "Figure 1: InterDreamer generates vivid 3D human-object interaction sequences guided by text descriptions, by synergizing semantics and dynamics knowledge from large-scale text-motion data (upper left), a large language model (bottom left), human-object interaction data (upper middle), and prior knowledge (bottom middle) from simple physics. We visualize the generated text-guided interaction sequence (upper right), with the beginning of the sequence unfolded (bottom right).", "description": "This figure demonstrates the InterDreamer framework's ability to generate realistic 3D human-object interaction sequences based on text descriptions. It illustrates the framework's components: large language models for semantic understanding, text-to-motion models for human pose generation, and physics-based world models for simulating object dynamics. The figure highlights how these components work together to generate text-aligned, dynamic interactions.", "section": "1 Introduction"}, {"figure_path": "BUpxPo80QP/figures/figures_7_3.jpg", "caption": "Figure 2: An overview of our InterDreamer. (i) Our high-level planning analyzes the description using LLMs and provides guidance to the low-level control. (ii) Our low-level control includes a text-to-motion model that translates text into human actions a<sub>t+1</sub>, and an interaction retrieval model that extracts the object's first state s<sub>1</sub>. (iii) Our world model executes actions to output the next state s<sub>t+1</sub>. We achieve this by abstracting the problem as predicting the motion of contact vertices represented by red spheres for humans and blue spheres for objects on the top right \u2013 using human vertices as controls for the prediction of object vertices. An optimization process is coupled with the dynamics model, projecting the state and action onto valid counterparts. Solid arrows mean that the process is performed iteratively.", "description": "The figure shows a flowchart of the InterDreamer framework, which is composed of three main modules: high-level planning, low-level control, and world model.  The high-level planning module uses LLMs to extract semantic information from text descriptions of human-object interactions.  The low-level control module translates the semantic information into human actions using a text-to-motion model and retrieves the initial state of the object. The world model predicts the future states of the object based on the human actions and simple physics. An optimization process is included to refine the generated human and object motions. The flowchart also illustrates how the three modules interact with each other iteratively.", "section": "3 Methodology"}, {"figure_path": "BUpxPo80QP/figures/figures_8_1.jpg", "caption": "Figure 8: Ablation study on the dynamics model. Given the text description of \"A person walks clockwise while holding a small box with left hand,\" our (b) vertex-based control can synthesize consistent contacts, which (a) the baseline fails to do.", "description": "This figure shows an ablation study comparing two approaches for controlling object dynamics in human-object interaction generation.  (a) uses full human motion as the control input, resulting in inconsistent contact with the object. (b) uses only the motion of contact vertices on the human body as control, leading to much more consistent and realistic object interaction.", "section": "4.4 Ablation Study"}, {"figure_path": "BUpxPo80QP/figures/figures_22_1.jpg", "caption": "Figure 1: InterDreamer generates vivid 3D human-object interaction sequences guided by text descriptions, by synergizing semantics and dynamics knowledge from large-scale text-motion data (upper left), a large language model (bottom left), human-object interaction data (upper middle), and prior knowledge (bottom middle) from simple physics. We visualize the generated text-guided interaction sequence (upper right), with the beginning of the sequence unfolded (bottom right).", "description": "This figure illustrates the InterDreamer framework.  It shows how the model combines information from various sources, including large language models, text-to-motion models, and physics-based world models, to generate realistic and text-aligned 3D human-object interaction sequences. The figure uses a visual representation to show the process of generating the 3D HOI, from text input to final output.", "section": "Introduction"}, {"figure_path": "BUpxPo80QP/figures/figures_24_1.jpg", "caption": "Figure 1: InterDreamer generates vivid 3D human-object interaction sequences guided by text descriptions, by synergizing semantics and dynamics knowledge from large-scale text-motion data (upper left), a large language model (bottom left), human-object interaction data (upper middle), and prior knowledge (bottom middle) from simple physics. We visualize the generated text-guided interaction sequence (upper right), with the beginning of the sequence unfolded (bottom right).", "description": "This figure illustrates the InterDreamer framework. It shows how the model uses different sources of information (large language models, text-to-motion models, simple physics, and human-object interaction data) to generate realistic and coherent 3D human-object interaction (HOI) sequences based on text descriptions. The upper part shows a sequence of the generated interaction and the lower part shows the different knowledge sources used for semantics and dynamics.", "section": "1 Introduction"}]