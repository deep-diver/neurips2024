[{"figure_path": "otZPBS0un6/figures/figures_0_1.jpg", "caption": "Figure 1: Overview of our method. In contrast to the existing spatial-blending methods (right part), our method explores face blending in frequency domain (left part). By leveraging the frequency knowledge, our method can generate pseudo-fake faces that closely resemble the distribution of wild fake faces. Our method can complement and work in conjunction with existing spatial-blending methods.", "description": "This figure illustrates the core concept of the FreqBlender method. The left side shows how the method blends frequency components from real and fake faces to create pseudo-fake faces that mimic the distribution of real-world deepfakes. This is in contrast to existing methods that primarily use spatial blending (shown on the right).  The figure highlights the key difference: FreqBlender operates in the frequency domain, while traditional methods work in the spatial domain. This frequency-domain approach allows FreqBlender to generate pseudo-fakes with more realistic forgery traces, improving the generalization of deepfake detection models.", "section": "Introduction"}, {"figure_path": "otZPBS0un6/figures/figures_3_1.jpg", "caption": "Figure 2: Statistics of frequency distribution. The top part shows the frequency distribution of real and fake faces using algorithms in [30, 27]. The bottom part shows the frequency difference between real and fake. The values on the vertical axis are logarithmic with 2.", "description": "This figure shows a statistical analysis of the frequency distribution of real and fake faces. The top row presents the frequency distributions of real and fake images for four different DeepFake manipulation methods (Deepfakes, Face2Face, FaceSwap, NeuralTextures). These distributions are obtained using algorithms described in references [30] and [27].  The bottom row displays the difference between the frequency distributions of real and fake images for each manipulation method.  The y-axis uses a logarithmic scale (base 2). The figure visually demonstrates that the difference in frequency distribution between real and fake faces is more prominent in lower-frequency ranges, rather than only high-frequency as previously believed.", "section": "3 Preliminary Analysis"}, {"figure_path": "otZPBS0un6/figures/figures_3_2.jpg", "caption": "Figure 3: Visualization of the frequency difference between real and fake faces. The lighter color indicates the larger difference.", "description": "This figure visualizes the differences in frequency distribution between real and fake faces generated by four different deepfake methods: Deepfakes, Face2Face, FaceSwap, and NeuralTextures.  Each subfigure represents a deepfake method, showing a heatmap of the frequency domain. Lighter colors in the heatmap indicate larger differences between the frequency distributions of real and fake faces for that method, highlighting frequency regions that are potentially indicative of forgery traces. This visualization helps support the paper's hypothesis that forgery traces are not exclusively located in high-frequency components but also span to mid- and low-frequency ranges.", "section": "Preliminary Analysis"}, {"figure_path": "otZPBS0un6/figures/figures_3_3.jpg", "caption": "Figure 3: Visualization of the frequency difference between real and fake faces. The lighter color indicates the larger difference.", "description": "This figure visualizes the differences in frequency components between real and fake faces generated by four different deepfake methods: Deepfakes, Face2Face, FaceSwap, and NeuralTextures.  The visualization uses a heatmap to show the magnitude of the difference for each frequency component.  Lighter colors represent larger differences, indicating areas where the frequency characteristics of real and fake faces differ most significantly, potentially highlighting areas containing forgery traces. The figure suggests that the differences are not uniformly distributed across all frequencies but rather are concentrated in specific frequency bands, implying that forgery artifacts are not equally prominent across the entire frequency spectrum.", "section": "3 Preliminary Analysis"}, {"figure_path": "otZPBS0un6/figures/figures_4_1.jpg", "caption": "Figure 5: Overview of the proposed Frequency Parsing Network (FPNet). Given an input face image, our method can partition it into three frequency components, corresponding to the semantic information, structural information, and noise information respectively. Since there is no ground truth, we propose four corollaries to supervise the training. The architecture of the encoder and decoders is shown in the right part.", "description": "This figure illustrates the architecture of the Frequency Parsing Network (FPNet). FPNet is composed of one shared encoder and three decoders. The encoder takes an input face image and converts it to a frequency map using Discrete Cosine Transform (DCT).  Three decoders then extract semantic, structural, and noise information from the frequency map.  Since ground truth for frequency components isn't available, four corollaries are used to supervise the training process. The right part of the image shows the architecture of the encoder and decoders, revealing their use of convolutional layers and PixelShuffle operations.", "section": "4.1 Frequency Parsing Network"}, {"figure_path": "otZPBS0un6/figures/figures_9_1.jpg", "caption": "Figure 6: Grad-CAM visualization of SBI and our method on four manipulation types of FF++ dataset. Compared to SBI, our method focuses more on the manipulated structural boundaries.", "description": "This figure shows a comparison of Grad-CAM visualizations between the SBI method and the proposed FreqBlender method. Grad-CAM is a technique used to visualize which parts of an image a neural network focuses on when making a prediction.  The figure presents visualizations for four different types of face manipulations from the FaceForensics++ dataset (DF, F2F, FS, NT).  Each column represents a manipulation type, and each row shows a different example image. The left image shows the visualization for the SBI method and the right for FreqBlender. The heatmaps indicate the attention areas, with warmer colors (yellow/red) representing higher attention and cooler colors (blue/purple) lower attention. The results suggest that FreqBlender focuses more on the structural boundaries of manipulated regions compared to SBI, indicating a difference in how the two methods process and interpret forgery traces.", "section": "5.2 Results"}, {"figure_path": "otZPBS0un6/figures/figures_15_1.jpg", "caption": "Figure 7: Heatmap visualization of the frequency difference between our method and the wild fake faces (Deepfakes, FaceSwap, Face2Face, NeuralTextures). Note that \u03b1 = 0 denotes that our method is degraded to SBI [16].", "description": "This figure visualizes the frequency difference between the proposed FreqBlender method and the ground truth frequency distribution of four types of wild fake faces (Deepfakes, FaceSwap, Face2Face, and NeuralTextures). Each cell in the figure represents one of the four types of wild fake faces. The x-axis represents the probability \u03b1 of applying FreqBlender and shows four different values (\u03b1=1, 0.5, 0.2, 0). The y-axis represents the frequency component.  The colormap represents the frequency difference, with red indicating a larger difference and blue indicating a smaller difference. It is shown that when \u03b1=1,  the frequency distribution of the pseudo-fake faces generated by FreqBlender is closest to the ground truth distribution of wild fake faces.", "section": "5.3 Analysis"}]