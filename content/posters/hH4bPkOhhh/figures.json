[{"figure_path": "hH4bPkOhhh/figures/figures_1_1.jpg", "caption": "Figure 1: Example of subgoals as selections. One subgoal is to \"go picnicking\", another subgoal is to \"go to a movie\". In order to \"go picnicking\", you need to go shopping first and then drive to the park; in order to \"go to a movie\", you need to check the movie information online first and then get the tickets. The actions caused us to accomplish the subtasks, and we essentially select the actions based on (conditioned on) the subgoals we want to achieve. On the contrary, weather is a confounder of the states and actions: changing our actions would not influence the weather, but actions influence whether we can achieve the subgoals.", "description": "This figure illustrates the concept of subgoals as selections in contrast to confounders.  Two example subgoals are \"go picnicking\" and \"go to a movie\".  The actions taken to achieve each subgoal are different (shopping and driving vs. checking movie information online and getting tickets).  Weather is presented as a confounder, as it influences the states and actions, but is not influenced by them.", "section": "1 Introduction"}, {"figure_path": "hH4bPkOhhh/figures/figures_3_1.jpg", "caption": "Figure 2: Three kinds of dependency patterns of DAGs that we aim to distinguish. Structure (1) models the confounder case St\u2190 Ctat, structure (2) models the selection case st \u2192 gt \u2190 at, and structure (3) models the mediator case stmt \u2192 at. In all three scenarios, the solid black arrows (\u2192) indicate the transition function that is invariant across different tasks. The dashed arrows (\u2192) indicate dependencies between nodes dt and dt+1. We take them to be direct adjacencies in the main paper, and for potentially higher-order dependencies, we refer to Appx. B.4.", "description": "This figure illustrates three different causal relationships between states (s), actions (a), and a third variable (c, g, or m), representing confounders, selections, and intermediates, respectively.  The solid arrows represent the transition function, consistent across tasks. Dashed arrows show relationships between time steps.  The figure is crucial for understanding how to distinguish between a selection variable (representing subgoals) and other variables to identify subtasks accurately.", "section": "3.1 Identifying Selections in Data"}, {"figure_path": "hH4bPkOhhh/figures/figures_5_1.jpg", "caption": "Figure 3: Figure (a) is the causal model for expert trajectories, which is further abstracted as the matrices in Figure (b), which can be learned by a seq-NMF algorithm. In both figures, data matrix X is the aggregated {st; at}t=1, and H \u2208 {0,1}J\u00d7T represents the binary subgoal matrix.", "description": "This figure illustrates the causal model for expert trajectories and its matrix factorization representation using seq-NMF.  (a) shows a causal graph where states (s), actions (a), and subgoals (g) influence each other. (b) presents the seq-NMF abstraction of this model, representing the data as a matrix X and decomposing it into a feature pattern matrix O (subtasks) and a binary coefficient matrix H (subgoal selections).  Seq-NMF learns both the subtask patterns and their selection indicators to represent the expert demonstrations.", "section": "Learning Subtasks with Seq-NMF"}, {"figure_path": "hH4bPkOhhh/figures/figures_5_2.jpg", "caption": "Figure 3: Figure (a) is the causal model for expert trajectories, which is further abstracted as the matrices in Figure (b), which can be learned by a seq-NMF algorithm. In both figures, data matrix X is the aggregated {st; at}t=1, and H \u2208 {0,1}J\u00d7T represents the binary subgoal matrix.", "description": "This figure illustrates the causal model for expert trajectories and its matrix factorization using seq-NMF.  Figure (a) shows a causal graph representing the generation of expert trajectories, where states (st), actions (at), and subgoals (gt) are depicted as nodes and their relationships as directed edges. Figure (b) provides a simplified representation using matrices:  X represents the aggregated state-action pairs, and H is a binary matrix indicating the presence or absence of subgoals for each subtask. The seq-NMF algorithm learns these matrices to identify subtasks from the data.", "section": "Learning Subtasks with Seq-NMF"}, {"figure_path": "hH4bPkOhhh/figures/figures_7_1.jpg", "caption": "Figure 4: Patterns in Color-3 and -10.", "description": "This figure shows two different patterns used in the synthetic Color dataset.  Color-3 has three colors (red, yellow, blue) each repeated three times, and Color-10 has two patterns: (3 red, 3 yellow, 4 blue) and (3 blue, 3 yellow, 4 red), each with 10 steps. These patterns are used to evaluate the causal inference methods. The figure illustrates the repeating nature of the color patterns and serves to visually represent the data structure used in the experiment.", "section": "5.1 Verifying Subgoals as Selections"}, {"figure_path": "hH4bPkOhhh/figures/figures_7_2.jpg", "caption": "Figure 5: Two tasks in Driving environment.", "description": "This figure shows two different driving tasks in a simulated environment.  Both tasks start with two cars positioned at the left end of a track, but one car faces upwards while the other faces downwards. The first task requires the car to follow a yellow path to the right end of the track. The second task instructs the car to navigate a blue path to the same destination.  Each task involves different routes and navigation challenges, highlighting the complexity and variety in the driving scenarios used for evaluating the proposed method.", "section": "5.1 Verifying Subgoals as Selections"}, {"figure_path": "hH4bPkOhhh/figures/figures_7_3.jpg", "caption": "Figure 14: seq-NMF result on Color-10. The dominance of each subtask in explaining 10 sequences.", "description": "This figure displays the results of applying the sequential non-negative matrix factorization (seq-NMF) method to the Color-10 dataset.  The y-axis represents the dominance of each subtask in explaining the whole sequence. The x-axis represents the time steps. The graph shows five different colored lines representing the five subtasks identified by the algorithm. The dominance of each subtask varies over time, indicating how much each subtask contributes to the overall sequence at different points.  The plot visually demonstrates the algorithm's ability to partition the trajectory into meaningful subtasks.", "section": "5.2 Evaluating the Effectiveness of Seq-NMF"}, {"figure_path": "hH4bPkOhhh/figures/figures_8_1.jpg", "caption": "Figure 7: Kitchen environment", "description": "This figure shows the Kitchen environment used in the experiments. It is a simulated kitchen setting with a robot arm, microwave, stove, sink, and cabinets. The robot arm is the agent that performs the tasks in the environment. The environment is used to test the ability of the learned subtasks to generalize to new tasks. ", "section": "5.3 Transfering to New Tasks"}, {"figure_path": "hH4bPkOhhh/figures/figures_8_2.jpg", "caption": "Figure 8: Results for solving new tasks in the Kitchen environment w.r.t. training steps.", "description": "The figure shows the results of four different imitation learning methods on two new tasks in the Kitchen environment. The x-axis represents the total number of training steps, while the y-axis represents the accumulated return. The four methods are Ours, DI-GAIL, H-AIRL, and Option-GAIL. Each method is represented by a line and shaded area, which represents the mean and standard deviation across five independent runs. The figure demonstrates that the proposed method outperforms the baselines in terms of both efficiency and performance on solving the new tasks. In particular, the proposed method can effectively transfer the knowledge learned from the demonstrations to the new tasks and quickly adapts to the tasks with different compositions of subtasks.", "section": "5.3 Transfering to New Tasks"}, {"figure_path": "hH4bPkOhhh/figures/figures_8_3.jpg", "caption": "Figure 8: Results for solving new tasks in the Kitchen environment w.r.t. training steps.", "description": "This figure shows the results of applying different imitation learning methods to solve new tasks in the Kitchen environment. The x-axis represents the total number of training steps, and the y-axis represents the episodic accumulated reward.  The graph displays the performance of four methods: \"Ours\", \"DI-GAIL\", \"H-AIRL\", and \"Option-GAIL\".  The shaded area around each line represents the standard deviation across multiple training runs. The results indicate how quickly each method adapts to new tasks with different compositions of subtasks.", "section": "5.3 Transfering to New Tasks"}, {"figure_path": "hH4bPkOhhh/figures/figures_13_1.jpg", "caption": "Figure 3: Figure (a) is the causal model for expert trajectories, which is further abstracted as the matrices in Figure (b), which can be learned by a seq-NMF algorithm. In both figures, data matrix X is the aggregated {st; at}t=1, and H \u2208 {0,1}J\u00d7T represents the binary subgoal matrix.", "description": "Figure 3 shows two representations of the causal model for expert trajectories.  (a) is a graphical representation showing the causal relationships between states (st), actions (at), and subgoals (gt).  Dashed arrows indicate the temporal dependence between timesteps. (b) provides a more abstract, matrix representation of the same causal model. Here, data matrix X represents the combined states and actions across time, while matrix H (a binary matrix) indicates whether a particular subgoal is active at each time step. This matrix factorization simplifies the learning process.", "section": "3.3 Learning Subtasks with Seq-NMF"}, {"figure_path": "hH4bPkOhhh/figures/figures_15_1.jpg", "caption": "Figure 11: Graphical model with relaxed assumptions. (1) We allow the co-existance of gt and ct (similarly for gt and mt). (2) We also assume there are potential higher-order underlying confounders Uc in the data that create the dependencies between ct and ct+1, and underlying selections Us in the data that create the dependencies between gt and ct+1.", "description": "This figure presents a graphical model illustrating the data generation process. It relaxes the assumptions made in Figure 2 by allowing for the co-existence of confounders (c), selections (g), and mediators (m) at each time step.  Additionally, it incorporates higher-order structures, denoted by Uc (higher-order confounders) and Ug (higher-order selections). These higher-order structures influence the relationships between the variables at each time step, creating more complex dependencies.  The figure shows how these higher-order variables affect the relationships between states (s), actions (a), and subgoals (g).", "section": "3.1 Identifying Selections in Data"}, {"figure_path": "hH4bPkOhhh/figures/figures_18_1.jpg", "caption": "Figure 13: Results on the Kitchen dataset on new tasks.", "description": "This figure presents the results of applying seq-NMF on the Kitchen dataset for new tasks. It visualizes the learned binary indicator matrix H (subgoals) and the subtask patterns O.  The matrix in the middle is the convolutional product of O and H, representing the trajectory matrix X. Different subtask patterns are shown using different colors. For each subfigure, the dominance of each subtask in explaining the whole sequence is shown.  The figure helps to demonstrate the effectiveness of seq-NMF in recovering selections and discovering subtasks in a complex real-world scenario.", "section": "5.2 Evaluating the Effectiveness of Seq-NMF"}, {"figure_path": "hH4bPkOhhh/figures/figures_18_2.jpg", "caption": "Figure 13: Results on the Kitchen dataset on new tasks.", "description": "This figure shows the results of applying seq-NMF to the Kitchen dataset.  The top section displays the learned binary indicator matrix H, representing the selection of subtasks. Each row corresponds to a different subgoal, and a value of 1 indicates the subgoal was selected at that timestep.  The bottom section shows the learned subtask patterns O, represented as a matrix. Each column corresponds to a distinct subtask pattern. The middle section shows the reconstruction of the data matrix X using the learned subtasks. This visualization demonstrates how the algorithm identifies and separates different subtask patterns within the kitchen dataset.", "section": "5.2 Evaluating the Effectiveness of Seq-NMF"}, {"figure_path": "hH4bPkOhhh/figures/figures_18_3.jpg", "caption": "Figure 14: seq-NMF result on Color-10. The dominance of each subtask in explaining 10 sequences.", "description": "This figure displays the results of applying the sequential non-negative matrix factorization (seq-NMF) method to the Color-10 dataset.  The y-axis represents the dominance of each subtask in explaining the overall sequence, indicating how much each subtask contributes to the different parts of the sequence. The x-axis represents the time steps. The plot shows the dominance of two subtasks over the sequence, suggesting the identification of two main patterns within the dataset.", "section": "5.2 Evaluating the Effectiveness of Seq-NMF"}, {"figure_path": "hH4bPkOhhh/figures/figures_21_1.jpg", "caption": "Figure 10: Two examples of the graphical models used in other literature.", "description": "This figure showcases two graphical models from existing literature (DI-GAIL and ComPILE).  Both models represent attempts to discover subtasks or options, but they differ in their approach to modeling the data and the subtasks. The key difference lies in whether or not they consider the true data generating process, which can lead to biased inference if not considered.  The figure highlights the importance of accurately modeling the data generation process for effective subtask discovery.", "section": "Related Works"}, {"figure_path": "hH4bPkOhhh/figures/figures_22_1.jpg", "caption": "Figure 3: Figure (a) is the causal model for expert trajectories, which is further abstracted as the matrices in Figure (b), which can be learned by a seq-NMF algorithm. In both figures, data matrix X is the aggregated {st; at }f=1, and H \u2208 {0,1}J\u00d7T represents the binary subgoal matrix.", "description": "Figure 3 presents a graphical model representing expert trajectories (a) which is further abstracted into matrices (b) used in the seq-NMF algorithm.  (a) shows the causal relationships between states (s), actions (a), and subgoals (g) in an expert trajectory. These relationships are then represented in matrix form in (b). Matrix X represents the aggregated state-action pairs. The matrix H (binary) indicates the presence or absence of a subgoal for each subtask.", "section": "3 Learning Subtasks with Seq-NMF"}, {"figure_path": "hH4bPkOhhh/figures/figures_22_2.jpg", "caption": "Figure 3: Figure (a) is the causal model for expert trajectories, which is further abstracted as the matrices in Figure (b), which can be learned by a seq-NMF algorithm. In both figures, data matrix X is the aggregated {st; at}t=1, and H \u2208 {0,1}J\u00d7T represents the binary subgoal matrix.", "description": "Figure 3 shows two perspectives of modeling expert trajectories.  (a) presents a causal model illustrating the relationships between states (st), actions (at), and subgoals (gt).  (b) provides an abstract representation of this model using matrices for seq-NMF processing.  Matrix X aggregates states and actions, while matrix H represents binary subgoal selections.  The figure highlights how the algorithm uses these matrices to learn behavior patterns and identify subgoals.", "section": "Learning Subtasks with Seq-NMF"}]