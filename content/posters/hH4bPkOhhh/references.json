{"references": [{"fullname_first_author": "Richard S. Sutton", "paper_title": "Reinforcement learning: An introduction", "publication_date": "2018-00-00", "reason": "This book is a foundational text in reinforcement learning, providing the theoretical basis for much of the work in the field, including the hierarchical reinforcement learning methods explored in this paper."}, {"fullname_first_author": "Yann LeCun", "paper_title": "A Path Towards Autonomous Machine Intelligence", "publication_date": "2022-06-27", "reason": "This paper provides a high-level overview of the path toward autonomous machine intelligence and discusses the importance of hierarchical planning and skill reuse, which directly relates to the paper's focus on subtask discovery."}, {"fullname_first_author": "Chelsea Finn", "paper_title": "Guided cost learning: Deep inverse optimal control via policy optimization", "publication_date": "2016-00-00", "reason": "This paper introduces a method for deep inverse optimal control which provides a way to learn reward functions from expert demonstrations, a problem that is related to and informs the imitation learning approaches in the current paper."}, {"fullname_first_author": "Daniel D. Lee", "paper_title": "Learning the parts of objects by non-negative matrix factorization", "publication_date": "1999-10-00", "reason": "This paper introduces non-negative matrix factorization (NMF), a technique used in the current paper for learning subtasks from sequential data."}, {"fullname_first_author": "Sergey Levine", "paper_title": "Reinforcement Learning and Control as Probabilistic Inference: Tutorial and Review", "publication_date": "2018-05-00", "reason": "This review paper provides a probabilistic framework for understanding reinforcement learning, which helps to contextualize the current paper's approach to subtask discovery and imitation learning."}]}