[{"figure_path": "nEqU0iCa0s/figures/figures_1_1.jpg", "caption": "Figure 1: (a) Visualization of Depth Refinement Approaches (b) Performance and Efficiency", "description": "Figure 1(a) shows a visual comparison of different depth refinement approaches, highlighting the inconsistent billboard and wall (local inconsistency noise) and blurred depth edges (edge deformation noise) in existing methods.  The figure demonstrates that the proposed method, SDDR, outperforms existing methods in terms of depth accuracy and edge quality. Figure 1(b) presents a quantitative comparison of these methods in terms of FLOPs (floating-point operations), showcasing SDDR's efficiency advantage.", "section": "Introduction"}, {"figure_path": "nEqU0iCa0s/figures/figures_3_1.jpg", "caption": "Figure 2: Depiction of depth errors. We utilize two samples of high-quality depth maps as ideal depth D*. For the predicted depth D, the combination of local inconsistency noise  \u03b5cons and edge deformation noise \u03b5edge can approximate real depth error D \u2013 D* (the last two columns). Thus, as in the third and fourth columns, prediction D can be depicted by the summation of D*, \u03b5cons, and \u03b5edge.", "description": "This figure visually explains how depth prediction errors are modeled in the paper.  It uses two examples of high-quality depth maps as a baseline (ideal depth D*). The figure then shows how the predicted depth (D) deviates from this ideal, breaking down the error into two components: local inconsistency noise (\u03b5cons) representing inconsistencies in depth structures and edge deformation noise (\u03b5edge) showing blurred or inaccurate depth edges. The figure illustrates how the combination of these two noise types approximates the overall depth error (D - D*).", "section": "3.1 Noisy Poisson Fusion"}, {"figure_path": "nEqU0iCa0s/figures/figures_4_1.jpg", "caption": "Figure 3: Overview of self-distilled depth refinement. SDDR consists of depth edge representation and edge-based guidance. Refinement network Nr produces initial refined depth Do, edge representation Go, and learnable soft mask \u03a9 of high-frequency areas. The final depth edge representation Gs is updated from coarse to fine as pseudo-labels. The edge-based guidance with edge-guided gradient loss and edge-based fusion loss supervises Nr to achieve consistent structures and fine-grained edges.", "description": "This figure provides a visual overview of the Self-distilled Depth Refinement (SDDR) framework. It shows the process starting from the initial depth prediction and edge representation, through a coarse-to-fine refinement stage that generates accurate depth edges as pseudo-labels for self-distillation.  The refinement network (Nr) uses these pseudo-labels along with edge-based guidance (edge-guided gradient loss and edge-based fusion loss) to produce the final refined depth map with consistent structures and fine-grained edges.  The process incorporates a learnable soft mask (\u03a9) for high-frequency areas, balancing consistency and detail.", "section": "3 SDDR: Self-Distilled Depth Refinement"}, {"figure_path": "nEqU0iCa0s/figures/figures_5_1.jpg", "caption": "Figure 8: Visualizations of coarse-to-fine edge refinement. We present coarse-to-fine results of steps s = 0,1,2,3. For s = 0, we showcase the low- and high-resolution predictions Na(L) and Na(H) of the depth predictor, along with the initial refined depth Do and edge representation Go. For s = 1, 2, 3, we present the window partitioning on the previous Ds\u22121, the previous depth Ds\u22121 on a certain window w, refined depth Dw on the window w, refined depth Ds of the whole image, and the depth edge representation Gs generated on the current step.", "description": "This figure visualizes the steps involved in the coarse-to-fine edge refinement process of the SDDR framework. It shows how the initial depth and edge predictions are iteratively refined across multiple steps (s=0, 1, 2, 3). Each step involves partitioning the image into windows, refining the depth within each window, and generating a refined depth map and edge representation for the entire image. The process culminates in a final refined depth map and edge representation (Gs) that are used as pseudo-labels for self-distillation.", "section": "3.2 Depth Edge Representation"}, {"figure_path": "nEqU0iCa0s/figures/figures_7_1.jpg", "caption": "Figure 5: Qualitative comparisons of one-stage methods on natural scenes. LeReS [51] is used as the depth predictor. SDDR predicts sharper depth edges and more meticulous details than prior arts [3, 14], e.g., fine-grained predictions of intricate branches. Better viewed when zoomed in.", "description": "This figure compares the performance of several one-stage depth refinement methods on real-world images.  The input is a low-resolution depth map from the LeReS [51] model. The figure shows the original image and the resulting depth maps from the LeReS model, the Kim et al. model, the GBDF model, and the proposed SDDR model. SDDR shows significant improvements in terms of depth map quality, particularly around edges and fine details, indicating better performance.", "section": "4.1 Comparisons with Other Depth Refinement Approaches"}, {"figure_path": "nEqU0iCa0s/figures/figures_7_2.jpg", "caption": "Figure 6: Qualitative comparisons of two-stage methods on natural scenes. ZoeDepth [1] is adopted as the depth predictor. The SDDR with coarse-to-fine edge refinement can predict more accurate depth edges and more consistent spatial structures than the tile-based methods [21, 25].", "description": "This figure compares the performance of various two-stage depth refinement methods on natural scene images.  The top row shows an image of shelves with items, and the bottom row displays an image of ice-covered branches. Each column represents a different method: ZoeDepth (baseline), PatchFusion, Boost, and the proposed method (Ours).  The figure highlights that SDDR produces more accurate and consistent depth edges and structures compared to existing tile-based approaches.", "section": "4.1 Comparisons with Other Depth Refinement Approaches"}, {"figure_path": "nEqU0iCa0s/figures/figures_13_1.jpg", "caption": "Figure 8: Visualizations of coarse-to-fine edge refinement. We present coarse-to-fine results of steps s = 0,1,2,3. For s = 0, we showcase the low- and high-resolution predictions Na(L) and Na(H) of the depth predictor, along with the initial refined depth Do and edge representation Go. For s = 1, 2, 3, we present the window partitioning on the previous Ds\u22121, the previous depth Ds\u22121 on a certain window w, refined depth Dw on the window w, refined depth Ds of the whole image, and the depth edge representation Gs generated on the current step.", "description": "This figure visualizes the process of coarse-to-fine edge refinement in the SDDR framework. It shows how the low-resolution and high-resolution depth predictions are used to generate an initial refined depth map and edge representation. Then, through iterative refinement, the depth map and edge representation are further refined using window partitioning, which helps in achieving a balanced consistency and detail preservation. The final step shows the refined depth and edge representation (Gs), which serves as pseudo-labels for self-distillation.", "section": "3.2 Depth Edge Representation"}, {"figure_path": "nEqU0iCa0s/figures/figures_14_1.jpg", "caption": "Figure 9: Adaptive resolution adjustment. We compare the effects of inference resolutions with Boost [25]. The numbers in the corner of the second and third columns represent the chosen inference resolution. We relieve the artifacts in Boost [25] by adaptive resolution adjustment.", "description": "The figure compares the depth estimation results of the proposed method and Boost [25] with different inference resolutions. The proposed method uses an adaptive resolution adjustment technique, resulting in fewer artifacts compared to Boost [25], especially in the areas with complex scene structures. This shows the effectiveness of the proposed adaptive resolution strategy in handling diverse scenes.", "section": "A More Details on SDDR Framework"}, {"figure_path": "nEqU0iCa0s/figures/figures_14_2.jpg", "caption": "Figure 10: Edge-guided gradient error. Lgrad focuses on high-frequency areas Pn extracted by clustering with more details. The flat regions are not constrained to preserve depth consistency.", "description": "This figure shows how the edge-guided gradient loss (Lgrad) is calculated in the SDDR framework. It illustrates that Lgrad focuses mainly on high-frequency regions (Pn) identified through clustering,  while preserving consistency in flat areas. The pseudo-label Gs, representing depth edge information, is used to supervise the learning process in the high-frequency regions. This targeted approach enhances the accuracy of depth edges in detail-rich areas without compromising the overall consistency of the depth map.", "section": "3.3 Edge-based Guidance"}, {"figure_path": "nEqU0iCa0s/figures/figures_15_1.jpg", "caption": "Figure 11: Edge-based fusion error. We present the region mask \u03a9 and pseudo-label Gs before and after quantile sampling. Different colors on the right represent the range of pixel values. Guiding the \u03a9 with Gs ensures that our model can predict balanced consistency and details by the simple one-stage inference. The use of \u03a9 as a learnable soft mask achieves more fine-grained integration on the feature level, enhancing the accuracy of Nr. This also leads to more accurate edge representation Gs in the iterative coarse-to-fine refinement process.", "description": "This figure visualizes the learnable region mask \u03a9 and the pseudo-label Gs, before and after quantile sampling, to illustrate the edge-based fusion loss in the SDDR framework.  Different colors represent different ranges of pixel values. The alignment of \u03a9 and Gs ensures a balance between consistency and detail in the refined depth map, leveraging the one-stage refinement process and the learnable soft mask's fine-grained feature fusion.", "section": "3.3 Edge-based Guidance"}, {"figure_path": "nEqU0iCa0s/figures/figures_15_2.jpg", "caption": "Figure 12. Architecture of refinement network. Some decoder layers are omitted for simplicity.", "description": "This figure shows the architecture of the refinement network used in the SDDR framework.  It's a U-Net-like architecture with a shared encoder that processes both low and high-resolution depth map predictions from the depth predictor.  The encoder outputs are then fed into an attention-based feature interaction module to combine information from both resolutions.  This combined information, along with regional masks (\u03a9), are passed through a series of convolution blocks and feature fusion modules (FFM) before the final refined depth map is produced. The decoder part of the network progressively upsamples the features to the final output resolution.", "section": "3.3 Edge-based Guidance"}, {"figure_path": "nEqU0iCa0s/figures/figures_18_1.jpg", "caption": "Figure 13. Iterations for self-distillation. We report the depth accuracy and edge error metrics of our SDDR model in the self-distillation training process.", "description": "The figure shows the depth accuracy (\u03b41) and edge error (D\u00b3R) of the SDDR model during the self-distillation training process.  The x-axis represents the number of training iterations, while the y-axis shows the depth accuracy and edge error.  The plot demonstrates how the model's accuracy improves and its edge error decreases as the number of training iterations increases, showcasing the effectiveness of the self-distillation process in refining depth predictions.", "section": "4 Experiments"}, {"figure_path": "nEqU0iCa0s/figures/figures_20_1.jpg", "caption": "Figure 5: Qualitative comparisons of one-stage methods on natural scenes. LeReS [51] is used as the depth predictor. SDDR predicts sharper depth edges and more meticulous details than prior arts [3, 14], e.g., fine-grained predictions of intricate branches. Better viewed when zoomed in.", "description": "This figure compares the results of several depth refinement methods (LeReS, Kim et al., GBDF, and the proposed SDDR method) on natural scenes using LeReS as the depth predictor.  The qualitative results show that SDDR outperforms the other methods in terms of edge sharpness and detail. SDDR is particularly effective in capturing fine details, such as intricate branches, that other methods struggle to capture.", "section": "4.1 Comparisons with Other Depth Refinement Approaches"}, {"figure_path": "nEqU0iCa0s/figures/figures_20_2.jpg", "caption": "Figure 15: Qualitative comparisons with two-stage methods [21, 25] on various datasets [15, 49, 34]. We adopt Zoedepth [1] as the depth predictor. Better viewed when zoomed in.", "description": "This figure compares the performance of several two-stage depth refinement methods, including PatchFusion and Boost, against the proposed method (Ours) on various datasets.  The image shows RGB input images, along with the depth maps generated by each method. The proposed method demonstrates improved accuracy and detail, particularly near edges and fine details, suggesting better consistency and overall performance than the existing methods.", "section": "4.1 Comparisons with Other Depth Refinement Approaches"}]