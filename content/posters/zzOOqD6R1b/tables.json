[{"figure_path": "zzOOqD6R1b/tables/tables_1_1.jpg", "caption": "Table 1: Summary of the models and policies used for each task. We study the sensitivity of the results to these choices in Appendix B.1. We rely on pre-trained models from the Deepseek (Bi et al., 2024; Shao et al., 2024) and Pythia (Biderman et al., 2023) families, as well as Mistral-7B (Jiang et al., 2023) and GPT-4 (OpenAI et al., 2023).", "description": "This table summarizes the specific large language models (LLMs) used as the base models (strong and weak) for each of the five tasks, as well as the high-quality demonstrations used for supervised fine-tuning (SFT) in the elicitation experiments.  It shows the choices made for each task and highlights the sensitivity analysis performed on these choices.", "section": "4 Experiment setup"}, {"figure_path": "zzOOqD6R1b/tables/tables_4_1.jpg", "caption": "Table 1: Summary of the models and policies used for each task. We study the sensitivity of the results to these choices in Appendix B.1. We rely on pre-trained models from the Deepseek (Bi et al., 2024; Shao et al., 2024) and Pythia (Biderman et al., 2023) families, as well as Mistral-7B (Jiang et al., 2023) and GPT-4 (OpenAI et al., 2023).", "description": "This table summarizes the specific large language models (LLMs) used as a base for creating password-locked models in the experiments. It shows the choices made for each task (code generation, math, code critique, and MMLU), including the base models (strong and weak), how the strong models were further fine-tuned (SFT on GPT-4 or using ground-truth labels), and the source of high-quality demonstrations used for fine-tuning.", "section": "4.2 Tasks"}]