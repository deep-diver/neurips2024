[{"figure_path": "utMOhsgXzB/tables/tables_2_1.jpg", "caption": "Table 6: Debiasing the CELEBA dataset with respect to gender for the HAIRCOLOR queries.", "description": "This table presents the results of debiasing experiments on the CELEBA dataset focusing on the HAIRCOLOR queries.  It compares the performance of different methods (Baseline CLIP, Orth-Proj., Orth-Cal., DebiasCLIP, and BEND-VLM) in terms of KL divergence, MaxSkew, and Worst Group AUC. These metrics assess the effectiveness of each method in reducing bias while maintaining accuracy in classifying images based on hair color, with a focus on gender.", "section": "A.1 Expanded CelebA HAIRCOLOR Results"}, {"figure_path": "utMOhsgXzB/tables/tables_7_1.jpg", "caption": "Table 1: Debiasing the UTKFACE dataset with respect to gender and race for STEREOTYPE queries.", "description": "This table presents the results of debiasing experiments conducted on the UTKFACE dataset using different methods.  The goal was to mitigate biases related to gender and race when using stereotype-related queries. The table shows the KL divergence and maximum skew values for different methods: Baseline CLIP (no debiasing), Orthogonal Projection, Orthogonal Calibration, DebiasCLIP, and BEND-VLM. Lower KL divergence and MaxSkew values indicate better debiasing performance.  The results are shown separately for both race and gender attributes and for two different CLIP model versions (ViT-B-P16 and ViT-L-P14).", "section": "4 Experiments"}, {"figure_path": "utMOhsgXzB/tables/tables_7_2.jpg", "caption": "Table 1: Debiasing the UTKFACE dataset with respect to gender and race for STEREOTYPE queries.", "description": "This table presents the results of debiasing experiments conducted on the UTKFACE dataset using various methods.  The experiments focused on mitigating biases related to gender and race, specifically examining the impact on queries associated with stereotypes.  The table shows the KL divergence and MaxSkew metrics, which quantify the reduction in bias achieved by each method.  Lower KL Divergence and MaxSkew values indicate better debiasing performance.  The methods compared include Baseline CLIP (no debiasing), Orthogonal Projection, Orthogonal Calibration, DebiasCLIP, and the proposed BEND-VLM.", "section": "4 Experiments"}, {"figure_path": "utMOhsgXzB/tables/tables_7_3.jpg", "caption": "Table 1: Debiasing the UTKFACE dataset with respect to gender and race for STEREOTYPE queries.", "description": "This table presents the results of debiasing experiments conducted on the UTKFACE dataset.  The experiments focused on mitigating bias related to gender and race, using STEREOTYPE queries.  The table shows the KL divergence and maximum skew values for different debiasing methods (Baseline CLIP, Orth-Proj, Orth-Cal, DebiasCLIP, and BEND-VLM) applied to both CLIP-ViT-B-P16 and CLIP-ViT-L-P14 models. Lower KL divergence and MaxSkew values indicate better debiasing performance.", "section": "4 Experiments"}, {"figure_path": "utMOhsgXzB/tables/tables_8_1.jpg", "caption": "Table 4: Debiasing FAIRFACE with respect to HAIRCOLOR queries with respect to gender, but evaluated on race.", "description": "This table presents the results of an experiment where the FAIRFACE dataset was debiased with respect to gender using the HAIRCOLOR queries. However, instead of evaluating the results on gender bias, the evaluation was performed on race bias. This is to investigate the potential unintended consequences of debiasing for one attribute on another.  The table shows the KL divergence and MaxSkew metrics for different methods, including the baseline CLIP and the proposed BEND-VLM method (with and without steps 1 and 2). Lower KL divergence and MaxSkew values indicate better debiasing performance.", "section": "4.3 Intersectional Debiasing"}, {"figure_path": "utMOhsgXzB/tables/tables_8_2.jpg", "caption": "Table 5: Average negative sentiment scores for the generated FAIRFACE captions. Lower is better.", "description": "This table presents the average negative sentiment scores obtained from the generated captions for the FAIRFACE dataset, categorized by race.  Lower scores indicate less negative sentiment. The table compares the baseline CLIP model's results with those produced by the BEND-VLM model, demonstrating the reduction in negative sentiment achieved by BEND-VLM across different racial groups. The \"Max Disparity\" column highlights the difference between the highest and lowest average negative sentiment scores, indicating the reduction in bias achieved by BEND-VLM.", "section": "4.4 Debiasing Image Captioning"}, {"figure_path": "utMOhsgXzB/tables/tables_14_1.jpg", "caption": "Table 6: Debiasing the CELEBA dataset with respect to gender for the HAIRCOLOR queries.", "description": "This table presents the results of debiasing experiments on the CELEBA dataset using different methods.  The goal is to mitigate gender bias in the context of hair color classification. The table shows the KL divergence (lower is better, indicating less bias), MaxSkew (lower is better, indicating more balanced attribute distributions), and Worst Group AUC (higher is better, indicating better performance on the under-represented group). The methods compared include the baseline CLIP model and three debiasing techniques: Orthogonal Projection, Orthogonal Calibration, and DebiasCLIP. The results are broken down for different CLIP models (CLIP-ViT-B-P16 and CLIP-ViT-L-P14). BEND-VLM shows the best performance across all metrics, indicating effective gender debiasing.", "section": "A.1 Expanded CelebA HAIRCOLOR Results"}, {"figure_path": "utMOhsgXzB/tables/tables_14_2.jpg", "caption": "Table 7: Ablation study. Debiasing the CELEBA dataset with respect to gender for the HAIRCOLOR queries.", "description": "This table presents the results of an ablation study evaluating the contribution of each step (Step 1 and Step 2) in the BEND-VLM method. It compares the performance of BEND-VLM using both steps, only Step 1, only Step 2, and the baseline CLIP model across three metrics: KL Divergence, MaxSkew, and Worst Group AUC. Lower values of KL Divergence and MaxSkew indicate better performance, while a higher value of Worst Group AUC shows better accuracy.  The results reveal the importance of both steps in achieving optimal performance.", "section": "A.2 Ablation Study"}, {"figure_path": "utMOhsgXzB/tables/tables_15_1.jpg", "caption": "Table 8: OOD reference data experiment. Reference data from FAIRFACE while the target data is CELEBA. Debiasing the CELEBA dataset with respect to gender for the HAIRCOLOR queries.", "description": "This table presents the results of an experiment where the reference dataset used for debiasing is different from the target dataset.  The goal is to evaluate the robustness of the BEND-VLM model to out-of-distribution (OOD) data. The table shows the KL divergence, MaxSkew, and Worst Group AUC for different methods (Baseline CLIP, Orth-Proj, Orth-Cal, DebiasCLIP, BEND-VLM with OOD reference data, and BEND-VLM with in-distribution (ID) reference data) applied to the CELEBA dataset.  The results demonstrate how the BEND-VLM performs when faced with an unseen reference dataset during the debiasing process. The metric \"Worst Group AUC\" measures how well the zero-shot classification performs for the most disadvantaged group.", "section": "A.3 Evaluation Using An OOD Reference Dataset"}, {"figure_path": "utMOhsgXzB/tables/tables_15_2.jpg", "caption": "Table 9: Debiasing the CELEBA dataset with FLAVA.", "description": "This table presents the results of debiasing experiments using the FLAVA model on the CelebA dataset.  It compares the performance of BEND-VLM against baseline CLIP, Orthogonal Projection, and Orthogonal Calibration methods. The metrics reported include KL Divergence, MaxSkew, and Worst Group AUC for both HAIRCOLOR and STEREOTYPE query sets.  The table highlights the effectiveness of BEND-VLM in reducing bias while maintaining or improving performance compared to other methods, demonstrating its generalizability beyond CLIP.", "section": "A.4 Applying to non-CLIP VLMs"}, {"figure_path": "utMOhsgXzB/tables/tables_18_1.jpg", "caption": "Table 8: OOD reference data experiment. Reference data from FAIRFACE while the target data is CELEBA. Debiasing the CELEBA dataset with respect to gender for the HAIRCOLOR queries.", "description": "This table presents the results of an experiment where the BEND-VLM model is evaluated using FAIRFACE as the reference dataset and CELEBA as the target dataset.  It shows the impact of using an out-of-distribution (OOD) reference dataset on the model's performance in terms of KL divergence, MaxSkew, and Worst Group AUC for the HAIRCOLOR queries.  Comparing the results obtained with an OOD reference dataset against those using an in-distribution (ID) reference dataset helps to understand the robustness and generalizability of the BEND-VLM model.", "section": "A.3 Evaluation Using An OOD Reference Dataset"}, {"figure_path": "utMOhsgXzB/tables/tables_19_1.jpg", "caption": "Table 1: Debiasing the UTKFACE dataset with respect to gender and race for STEREOTYPE queries.", "description": "This table presents the results of debiasing experiments on the UTKFACE dataset using different methods.  It shows the KL divergence and MaxSkew metrics for both gender and race attributes, comparing the performance of the baseline CLIP model against Orthogonal Projection, Orthogonal Calibration, DebiasCLIP, and BEND-VLM for a set of queries related to stereotypes. Lower KL Divergence and MaxSkew values indicate better debiasing performance.", "section": "4 Experiments"}, {"figure_path": "utMOhsgXzB/tables/tables_20_1.jpg", "caption": "Table 6: Debiasing the CELEBA dataset with respect to gender for the HAIRCOLOR queries.", "description": "This table presents the results of debiasing experiments on the CelebA dataset focusing on hair color.  It compares different methods, including the proposed BEND-VLM, for their effectiveness in reducing gender bias while maintaining accuracy in a zero-shot classification task.  Metrics include KL divergence (a measure of the difference between the true and predicted distributions of genders), MaxSkew (maximum skew between true and predicted gender proportions), and Worst Group AUC (area under the ROC curve for the worst-performing gender group).", "section": "A.1 Expanded CelebA HAIRCOLOR Results"}, {"figure_path": "utMOhsgXzB/tables/tables_20_2.jpg", "caption": "Table 6: Debiasing the CELEBA dataset with respect to gender for the HAIRCOLOR queries.", "description": "This table presents the results of debiasing experiments conducted on the CELEBA dataset, focusing on gender bias in the context of hair color. It compares different debiasing methods, including the proposed BEND-VLM, against baseline and other existing debiasing techniques.  The metrics used are KL divergence (measuring the difference between the true and empirical distributions of gender in the retrieved images), MaxSkew (measuring the maximum skew in the attribute distribution), and Worst Group AUC (measuring the area under the ROC curve for the worst-performing group).  The goal is to show BEND-VLM's effectiveness in reducing gender bias in image retrieval while maintaining or improving accuracy.", "section": "A.1 Expanded CelebA HAIRCOLOR Results"}, {"figure_path": "utMOhsgXzB/tables/tables_20_3.jpg", "caption": "Table 6: Debiasing the CELEBA dataset with respect to gender for the HAIRCOLOR queries.", "description": "This table presents the results of debiasing experiments conducted on the CELEBA dataset, focusing on gender bias within HAIRCOLOR queries. It compares different methods, including the baseline, orthogonal projection, orthogonal calibration, DebiasCLIP, and BEND-VLM, evaluating their performance across metrics like KL Divergence, MaxSkew, and Worst Group AUC.  The metrics assess the effectiveness of each method in mitigating gender bias while maintaining classification accuracy.", "section": "A.1 Expanded CelebA HAIRCOLOR Results"}, {"figure_path": "utMOhsgXzB/tables/tables_20_4.jpg", "caption": "Table 8: OOD reference data experiment. Reference data from FAIRFACE while the target data is CELEBA. Debiasing the CELEBA dataset with respect to gender for the HAIRCOLOR queries.", "description": "This table presents the results of an experiment where the BEND-VLM model is evaluated using an out-of-distribution (OOD) reference dataset (FAIRFACE) and a target dataset (CELEBA). The experiment focuses on debiasing gender bias in the context of HAIRCOLOR queries. The table compares the performance of BEND-VLM with baseline CLIP and other debiasing methods in terms of KL divergence, MaxSkew, and Worst Group AUC, providing insights into the model's robustness and effectiveness when faced with OOD data.", "section": "A.3 Evaluation Using An OOD Reference Dataset"}]