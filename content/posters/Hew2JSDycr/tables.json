[{"figure_path": "Hew2JSDycr/tables/tables_7_1.jpg", "caption": "Table 1: Detection performance of BISCOPE and nine baselines on both normal and paraphrased datasets with in-distribution and out-of-distribution (OOD) settings.", "description": "This table presents a comprehensive comparison of the performance of BISCOPE and nine other AI-generated text detection methods across five different datasets.  The datasets include both normal and paraphrased versions of text from different domains.  The table shows the F1 scores for each method in both in-distribution (the test data comes from the same source as the training data) and out-of-distribution settings (the test data comes from a different source than the training data).  The out-of-distribution settings further break down into cross-model (CM) and cross-dataset (CD) scenarios.  The results demonstrate BISCOPE's superior performance and robustness across various conditions.", "section": "4.2 Detection Performance Comparison with Existing Baselines"}, {"figure_path": "Hew2JSDycr/tables/tables_14_1.jpg", "caption": "Table 1: Detection performance of BISCOPE and nine baselines on both normal and paraphrased datasets with in-distribution and out-of-distribution (OOD) settings.", "description": "This table presents a comprehensive comparison of the detection performance of BISCOPE against nine other state-of-the-art methods.  It shows the average F1 scores achieved by each method across five different datasets (Arxiv, Yelp, Creative, Essay, and Code) under various conditions. These conditions include in-distribution (ID) and out-of-distribution (OOD) settings for both normal and paraphrased versions of the datasets. The in-distribution settings assess performance using data from the same source as the training data, while the out-of-distribution settings evaluate the models on data from an unseen source.  The table allows for a thorough assessment of each algorithm's effectiveness and robustness.", "section": "4.2 Detection Performance Comparison with Existing Baselines"}, {"figure_path": "Hew2JSDycr/tables/tables_15_1.jpg", "caption": "Table 1: Detection performance of BISCOPE and nine baselines on both normal and paraphrased datasets with in-distribution and out-of-distribution (OOD) settings.", "description": "This table presents a comprehensive comparison of the performance of BISCOPE and nine other AI-generated text detection methods across five datasets.  The datasets are split into normal and paraphrased versions. Performance is evaluated under both in-distribution (where the test data comes from the same source as the training data) and out-of-distribution (OOD) settings (where the test data comes from a different source than the training data).  The table shows the F1 score for each method on each dataset, broken down by the type of data (normal or paraphrased) and the distribution type (in-distribution or OOD). This allows for a thorough assessment of the methods' accuracy and robustness in various scenarios.", "section": "4.2 Detection Performance Comparison with Existing Baselines"}, {"figure_path": "Hew2JSDycr/tables/tables_16_1.jpg", "caption": "Table 1: Detection performance of BISCOPE and nine baselines on both normal and paraphrased datasets with in-distribution and out-of-distribution (OOD) settings.", "description": "This table presents a comprehensive comparison of the performance of BISCOPE and nine other AI-generated text detection methods across five datasets.  The datasets include both normal and paraphrased versions. The evaluation metrics used are the F1 score under both in-distribution (where the training and testing data come from the same source) and out-of-distribution (OOD) settings (where the testing data comes from an unknown source).  The OOD settings are further broken down into cross-model (CM) and cross-dataset (CD) scenarios to show robustness in different contexts.", "section": "4.2 Detection Performance Comparison with Existing Baselines"}, {"figure_path": "Hew2JSDycr/tables/tables_17_1.jpg", "caption": "Table 1: Detection performance of BISCOPE and nine baselines on both normal and paraphrased datasets with in-distribution and out-of-distribution (OOD) settings.", "description": "This table presents a comprehensive comparison of the performance of BISCOPE and nine other AI-generated text detection methods across five datasets.  The datasets include both natural language and code, and are evaluated under both in-distribution (where the test data comes from the same source as the training data) and out-of-distribution (where the test data comes from a different, unseen source) settings. Results are given for both normal and paraphrased versions of the datasets. The metrics used are average F1 scores for different generative models, allowing for a detailed analysis of each method's accuracy and robustness under various conditions.", "section": "4.2 Detection Performance Comparison with Existing Baselines"}, {"figure_path": "Hew2JSDycr/tables/tables_17_2.jpg", "caption": "Table 1: Detection performance of BISCOPE and nine baselines on both normal and paraphrased datasets with in-distribution and out-of-distribution (OOD) settings.", "description": "This table presents a comprehensive comparison of the performance of BISCOPE and nine other AI-generated text detection methods across five datasets.  The datasets are categorized as normal and paraphrased versions. Performance is evaluated under both in-distribution (ID) and out-of-distribution (OOD) settings.  The table shows the F1 scores for each method across different datasets and generative AI models (GPT-3.5-Turbo, GPT-4-Turbo, Claude-3-Sonnet, Claude-3-Opus, Gemini-1.0-Pro). The results showcase BISCOPE's superior performance compared to existing methods in various scenarios, including the handling of paraphrased text and out-of-distribution data.", "section": "4.2 Detection Performance Comparison with Existing Baselines"}, {"figure_path": "Hew2JSDycr/tables/tables_17_3.jpg", "caption": "Table 1: Detection performance of BISCOPE and nine baselines on both normal and paraphrased datasets with in-distribution and out-of-distribution (OOD) settings.", "description": "This table presents a comprehensive comparison of the detection F1 scores achieved by BISCOPE and nine other baseline methods across five datasets.  The datasets include both normal and paraphrased versions of text data, encompassing various domains such as natural language and code.  The results are broken down by AI model used for generation, and further categorized for in-distribution (same source as training) and out-of-distribution (different source than training) settings.  This allows for a thorough evaluation of the models' performance in different scenarios and their robustness to various data conditions.", "section": "4.2 Detection Performance Comparison with Existing Baselines"}]