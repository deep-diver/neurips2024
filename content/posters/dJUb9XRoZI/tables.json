[{"figure_path": "dJUb9XRoZI/tables/tables_6_1.jpg", "caption": "Table 1: Quantitative evaluation (FID, LPIPS) of solving linear inverse problems on 1000 validation images of FFHQ 256 \u00d7 256. Bold: best, red: worst.", "description": "This table presents a quantitative comparison of different methods for solving three linear inverse problems (Super-Resolution, Inpainting, and Deblurring) on the FFHQ dataset.  The performance is measured using two metrics: Fr\u00e9chet Inception Distance (FID) and Learned Perceptual Image Patch Similarity (LPIPS). Lower scores indicate better performance.  The table shows that the 'Trust' method achieves the best results for all three tasks.", "section": "5.1 Image Experiments"}, {"figure_path": "dJUb9XRoZI/tables/tables_6_2.jpg", "caption": "Table 2: Quantitative evaluation (FID, LPIPS) of solving linear inverse problems on 100 validation images of ImageNet 256 \u00d7 256. Bold: best, red: worst.", "description": "This table presents a quantitative comparison of different methods for solving three linear inverse problems (Super-Resolution, Inpainting, and Deblurring) on the ImageNet dataset.  The performance of each method is measured using two metrics: Fr\u00e9chet Inception Distance (FID) and Learned Perceptual Image Patch Similarity (LPIPS). Lower FID and LPIPS scores indicate better performance.  The table highlights the best-performing method for each task in bold and the worst-performing method in red.", "section": "5.1 Image Experiments"}, {"figure_path": "dJUb9XRoZI/tables/tables_7_1.jpg", "caption": "Table 3: Evaluation of FID, Diversity, and Constraint Violation in meters for motion tasks: root tracking and right hand & left foot tracking. Bold: best, red: worst. Computational budget for all methods is 1000 NFEs.", "description": "This table presents a quantitative comparison of different methods (DPS, DPS+DSG, LGD-MC, and Trust Sampling) on two human motion generation tasks: root tracking and right hand & left foot tracking.  The evaluation metrics include FID (Fr\u00e9chet Inception Distance), which measures the quality of generated motion; Diversity, indicating the variety of generated motion sequences; and Constraint Violation (in meters), representing how well the generated motion adheres to the specified constraints. The results show that Trust Sampling achieves a good balance between FID, Diversity, and constraint satisfaction.", "section": "5.2 Human Motion Experiments"}, {"figure_path": "dJUb9XRoZI/tables/tables_9_1.jpg", "caption": "Table 1: Quantitative evaluation (FID, LPIPS) of solving linear inverse problems on 1000 validation images of FFHQ 256 \u00d7 256. Bold: best, red: worst.", "description": "This table presents the quantitative results of three different image restoration tasks (Super-Resolution, Inpainting, Deblurring) evaluated using two metrics: Fr\u00e9chet Inception Distance (FID) and Learned Perceptual Image Patch Similarity (LPIPS). The results are shown for four methods: DPS, DPS+DSG, LGD-MC (with 10 and 100 samples), and Trust Sampling (the proposed method).  Lower FID and LPIPS scores indicate better performance. The experiments were conducted on 1000 validation images from the FFHQ dataset (256x256 resolution).", "section": "5.1 Image Experiments"}, {"figure_path": "dJUb9XRoZI/tables/tables_9_2.jpg", "caption": "Table 5: FFHQ Manifold boundary ablations. Metrics calculated on linear inverse problems on 100 validation images of FFHQ 256 \u00d7 256. Bold: best, underline: second best.", "description": "This table presents ablation study results on the impact of using manifold boundary estimates in the Trust Sampling algorithm.  It compares different trust schedule parameters ('Start', 'End') and total number of function evaluations (NFEs) across three image restoration tasks (Super-Resolution, Inpainting, Deblurring) using the FFHQ dataset.  The results show the effect of incorporating manifold boundary estimates on model performance, measured by FID and LPIPS scores.  The best performing configurations are highlighted.", "section": "5.3 Ablations"}, {"figure_path": "dJUb9XRoZI/tables/tables_9_3.jpg", "caption": "Table 6: Emax ablations. Metrics calculated on Super Resolution (\u00d74) on 100 validation images of FFHQ 256 \u00d7 256. To isolate purely the effect of Emax while keeping the number of NFEs comparable, constant linear schedules were chosen so that the number of NFEs was close to 1,000. Bold: best.", "description": "This table presents ablation results on the effect of varying the parameter  Emax on the super-resolution task using the FFHQ dataset.  Different values of Emax were tested, each with a corresponding constant linear trust schedule designed to keep the number of neural function evaluations (NFEs) around 1000. The results show the FID and LPIPS scores obtained for each Emax value, with the best performing Emax value highlighted in bold.", "section": "5.3 Ablations"}, {"figure_path": "dJUb9XRoZI/tables/tables_14_1.jpg", "caption": "Table 7: Parameters used for all experiments. Start and end refer to the start and end of the stochastic linear trust schedules.", "description": "This table lists the hyperparameters used in the image experiments.  For each task (Super-Resolution, Inpainting, Deblurring) on each dataset (FFHQ, ImageNet), it shows the maximum number of neural function evaluations (NFEs), the number of DDIM steps, the starting and ending points of the stochastic linear trust schedule used for termination criteria, and the maximum allowed predicted noise magnitude (\u03b5max). The table separates the results based on whether 1000 or 600 NFEs were used.", "section": "A Experiment Details"}]