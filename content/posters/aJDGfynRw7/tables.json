[{"figure_path": "aJDGfynRw7/tables/tables_4_1.jpg", "caption": "Table 1: The comparison results of instance weighting methods on complex distributions.", "description": "This table compares the performance of four instance weighting methods on several complex label distributions. The methods are compared based on their ability to assign higher weights to instances with more confident labels (i.e., labels where there is a greater consensus among annotators) and lower weights to instances with less confident labels (i.e., ambiguous labels). The results show that the proposed method in the paper is superior to the existing methods in distinguishing complex distributions.", "section": "3.1 Instance weighting for crowdsourcing"}, {"figure_path": "aJDGfynRw7/tables/tables_7_1.jpg", "caption": "Table 2: The model quality (%) comparisons of MV, IWMV, LAWMV, MNLDP, AVNC, MVNC and NWVNC before and after using IWBVT on 34 simulated datasets.", "description": "This table presents the model quality, measured as the percentage of correctly classified instances, for seven different label integration and noise correction algorithms (MV, IWMV, LAWMV, MNLDP, AVNC, MVNC, NWVNC) on 34 simulated datasets.  The 'ORI' column shows the original model quality of each algorithm, while the 'IWBVT' column shows the model quality after applying the Instance Weighting-based Bias-Variance Trade-off (IWBVT) method.  The results demonstrate the effectiveness of IWBVT in improving the model quality of various algorithms across multiple datasets.", "section": "5.2 Experiments on simulated datasets"}]