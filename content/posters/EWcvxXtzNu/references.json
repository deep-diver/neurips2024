{"references": [{"fullname_first_author": "Jiaqi Guan", "paper_title": "3D equivariant diffusion for target-aware molecule generation and affinity prediction", "publication_date": "2023-03-03", "reason": "This paper is foundational to the current work, proposing a method for generating molecules using diffusion models, which the current work builds upon and improves."}, {"fullname_first_author": "Rafael Rafailov", "paper_title": "Direct preference optimization: Your language model is secretly a reward model", "publication_date": "2023-05-18", "reason": "This paper introduces a novel preference optimization algorithm that is directly adopted and improved in the current work, providing a crucial foundation for aligning diffusion models to preferred properties."}, {"fullname_first_author": "Masatoshi Uehara", "paper_title": "Fine-tuning of continuous-time diffusion models as entropy-regularized control", "publication_date": "2024-02-15", "reason": "This paper is highly relevant due to its focus on fine-tuning diffusion models, a core aspect of the current work's approach to aligning molecule generation models.  The techniques are adapted to this different problem space."}, {"fullname_first_author": "Bram Wallace", "paper_title": "Diffusion model alignment using direct preference optimization", "publication_date": "2023-11-12", "reason": "This paper presents a method for aligning diffusion models using preference optimization, which is directly extended and improved upon in the current work's proposed method."}, {"fullname_first_author": "Mohammad Gheshlaghi Azar", "paper_title": "A general theoretical paradigm to understand learning from human preferences", "publication_date": "2024-00-00", "reason": "This theoretical work provides a general framework for understanding preference optimization, which is highly relevant to the core methodology of the current paper and helps to justify and explain the choices made."}]}