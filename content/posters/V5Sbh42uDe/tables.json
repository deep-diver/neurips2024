[{"figure_path": "V5Sbh42uDe/tables/tables_3_1.jpg", "caption": "Table 1: Second-order Potts relaxations, see Fig.1(a,b,c)", "description": "This table presents three different second-order relaxations of the Potts model used in the paper for weakly supervised semantic segmentation.  These relaxations, bi-linear, quadratic, and normalized quadratic, are compared to approximate the original weakly supervised loss and are later evaluated experimentally.", "section": "2.1 Second-order relaxations of the Potts model"}, {"figure_path": "V5Sbh42uDe/tables/tables_3_2.jpg", "caption": "Table 2: Log-based Potts relaxations, see Fig.1(d,e,f)", "description": "This table presents three log-based variations of the Potts model relaxations: collision cross-entropy, log-quadratic, and collision divergence.  These are alternative ways of formulating the pairwise interaction term in the loss function, offering different properties regarding smoothness and the handling of soft predictions.", "section": "2.1 Second-order relaxations of the Potts model"}, {"figure_path": "V5Sbh42uDe/tables/tables_6_1.jpg", "caption": "Table 3: Comparison of Potts relaxations with self-labeling. mIoUs on validation set are shown here.", "description": "This table presents a comparison of different Potts relaxations used in a self-labeling framework for weakly supervised semantic segmentation.  The mIoU (mean Intersection over Union) metric is used to evaluate the performance, showing results across different scribble length ratios (0, 0.3, 0.5, 0.8, 1.0).  The table helps determine which relaxation performs best for this task.", "section": "3.1 Comparison of Potts relaxations"}, {"figure_path": "V5Sbh42uDe/tables/tables_7_1.jpg", "caption": "Table 4: Summary of comparisons. \"*\" stands for the reproduced results from their code repository.", "description": "This table compares the performance of different weakly supervised semantic segmentation (WSSS) methods based on the Potts model.  It shows the mean Intersection over Union (mIoU) scores achieved using gradient descent (GD) and self-labeling (SL) approaches with both hard and soft pseudo-labels. The comparison considers two different neighborhood systems: nearest neighbor (NN) and dense (DN). The results highlight that the soft self-labeling method with the nearest neighbor system outperforms the other methods.", "section": "3.4 Soft self-labeling vs. hard self-labeling vs. gradient descent"}, {"figure_path": "V5Sbh42uDe/tables/tables_8_1.jpg", "caption": "Table 5: Comparison to SOTA methods (without CRF postprocessing) on scribble-supervised segmentation. The numbers are mIoU on the validation dataset of Pascal VOC 2012 and use full-length scribble. The backbone is ResNet101 unless stated otherwise. V2: deeplabV2. V3+: deeplabV3+. N: neighborhood. \u201c*\u201d: reproduced results. GD: gradient descent. SL: self-labeling. \u201cno pretrain\u201d means the segmentation network is not pretrained using cross-entropy on scribbles.", "description": "This table compares the proposed method's performance against other state-of-the-art (SOTA) methods for semantic segmentation using scribble supervision.  It shows mean Intersection over Union (mIoU) scores on the Pascal VOC 2012 validation set.  The table details the architecture, batch size, optimization method (gradient descent or self-labeling), neighborhood system used, and whether the model was pre-trained using cross-entropy.  The results highlight the effectiveness of the proposed soft self-labeling approach compared to other techniques and even to fully supervised methods.", "section": "3.5 Comparison to SOTA"}, {"figure_path": "V5Sbh42uDe/tables/tables_14_1.jpg", "caption": "Table 6: Comparison to SOTA methods (without CRF postprocessing) on segmentation with block-scribble supervision. The numbers are mIoU on the validation dataset of cityscapes [13] and ADE20k [43] and use 50% of full annotations for supervision following [25]. The backbone is ResNet101. \"*\": reproduced results. All methods are trained in a single-stage fashion.", "description": "This table compares the performance of different methods on the Cityscapes and ADE20k datasets using block-scribble supervision.  The results are measured using mean Intersection over Union (mIoU) and are presented without any post-processing steps like Conditional Random Fields (CRFs).  The comparison includes both fully supervised methods and those using block-scribble supervision, allowing for a direct assessment of the proposed method's effectiveness.", "section": "3.5 Comparison to SOTA"}]