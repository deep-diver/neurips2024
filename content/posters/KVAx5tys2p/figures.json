[{"figure_path": "KVAx5tys2p/figures/figures_1_1.jpg", "caption": "Figure 1: We sample 1000 (a), 5000 (b), 10000 (c) and 100000 (d) face images from the MS1MV2 dataset respectively, and compute their persistence diagrams using PH, where Hj represents the j-th dimension homology. Persistence diagram [18] is a mathematical tool to describe the topological structure of space, where the j-th dimension homology Hj in persistence diagram represents the j-th dimension hole in space. In topology theory, if the number of high-dimensional holes in the space is more, then the underlying topological structure of the space is more complex [19]. As shown in Figure 1(a)-1(d), as the amount of face data increases, the persistence diagram of the input space contains more and more high-dimensional holes (e.g., H3 and H4). Therefore, this phenomenon demonstrates a growing complexity in the topological structure of the input space.", "description": "This figure shows persistence diagrams of face images sampled from the MS1MV2 dataset with different sizes (1000, 5000, 10000, and 100000 images).  The diagrams illustrate the topological structure of the data, showing an increase in the number of higher-dimensional holes (represented by Hj) as the dataset size grows. This visually demonstrates that larger datasets have more complex underlying topological structures.", "section": "Introduction"}, {"figure_path": "KVAx5tys2p/figures/figures_2_1.jpg", "caption": "Figure 2: (a): We investigate the relationship between the amount of data and the topological structure discrepancy by employing ResNet-50 ArcFace model [1] to perform inferences on MS1MV2 training set. Inferences are conducted for 1000 iterations with batch sizes of 256, 1024, and 2048, respectively. Histograms are used to approximate these discrepancy distributions. (b): We investigate the relationship between the network depth and the topological structure discrepancy by performing inference on MS1MV2 training set (batch size=128) using ArcFace models with different backbones. (c): We investigate the trend of topological structure discrepancy during training (batch size=128) and found that i) directly using PH to align the topological structures will cause the discrepancy to drops to 0 dramatically; ii) whereas using our PTSA strategy promotes a smooth convergence of structure discrepancy. (d): Aligning the topological structures directly using PH will lead to significant discrepancy when evaluating on IJB-C benchmark. Our PTSA strategy effectively mitigates this overfitting issue, resulting in smaller structure discrepancy during evaluation.", "description": "This figure investigates the relationship between data amount, network depth, and training iterations with topological structure discrepancy in face recognition.  It uses ResNet-50 ArcFace model and MS1MV2 training set for experiments. The results show that directly aligning topological structures without PTSA can lead to overfitting, while PTSA mitigates this problem.", "section": "Introduction"}, {"figure_path": "KVAx5tys2p/figures/figures_3_1.jpg", "caption": "Figure 3: Global overview of our proposed TopoFR. \u2611 represents the multiplication operation. \u00a7 denotes the probability of applying RSP to each training sample.", "description": "This figure shows the overall architecture of the TopoFR model.  It consists of a feature extractor (F) that takes a mini-batch of face images as input.  These images are preprocessed using various augmentation techniques such as Gaussian Blur, Grayscale, Random Erasing, and ColorJitter, collectively referred to as Random Structure Perturbation (RSP).  The feature extractor generates latent features. These features are then passed through a classifier (C) to produce a prediction probability. The prediction probability is used to calculate the prediction entropy. Both the prediction entropy and prediction probability are used in a structure damage estimation (SDE) process. This SDE process uses a Gaussian Uniform Mixture (GUM) model to calculate a structure damage score (SDS), which is a weighting factor for the focal loss (Lcls). Additionally, the topological structures of the input and latent spaces are aligned using a strategy called Invariant Structure Alignment, resulting in a topological structure alignment loss (Lsa).  The final loss function of the model is a combination of Lcls and Lsa.", "section": "4 Methodology"}, {"figure_path": "KVAx5tys2p/figures/figures_8_1.jpg", "caption": "Figure 4: The estimated Gaussian density (blue curve) w.r.t the entropy of classification prediction. Green marker * and black marker \u00d7 represent the entropy of correctly classified sample and misclassified sample, respectively.", "description": "This figure visualizes the Gaussian density distribution of prediction entropy for both correctly and incorrectly classified samples.  The x-axis represents the entropy of the classification prediction probability, and the y-axis represents the Gaussian density.  The green markers (*) indicate correctly classified samples, and the black markers (\u00d7) indicate misclassified samples.  The figure shows that misclassified samples tend to have lower Gaussian density and higher entropy.", "section": "5.3 Analysis and Ablation Study"}, {"figure_path": "KVAx5tys2p/figures/figures_8_2.jpg", "caption": "Figure 5: The topological structure discrepancy of TopoFR and variant TopoFR-A under different backbones and training datasets (i.e., [Backbone, Training dataset]). Variant TopoFR-A directly utilizes PH to align the topological structures of two spaces. Notably, our TopoFR models trained with Glint360K dataset almost perfectly align the topological structures of the input space and the latent space on the IJB-C benchmark (i.e., the blue histogram almost converges to a straight line).", "description": "This figure compares the topological structure discrepancy between TopoFR and TopoFR-A (a variant that directly uses PH for alignment) under different network backbones (R50, R100, R200) and training datasets (MS1MV2, Glint360K). TopoFR-A suffers from structure collapse, while TopoFR effectively aligns the topological structures, especially when trained on Glint360K, showing a near-perfect alignment on the IJB-C benchmark.", "section": "5.3 Analysis and Ablation Study"}, {"figure_path": "KVAx5tys2p/figures/figures_18_1.jpg", "caption": "Figure 6: Parameter sensitivity analysis. (a) The effect of the hyper-parameter \u03b1. (b) The effect of the hyper-parameter \u03be.", "description": "This figure shows the sensitivity analysis of two hyperparameters: \u03b1 (alpha) and \u03be (xi).  Parameter \u03b1 balances the contributions of the classification loss and the topological structure alignment loss in the TopoFR model. Parameter \u03be controls the probability of applying a random structure perturbation (RSP) to each training sample.  The plots show the verification accuracy on the IJB-C benchmark at different values of \u03b1 and \u03be, demonstrating how these parameters impact the model's performance.  The optimal values of \u03b1 and \u03be are identified through the highest accuracy achieved, indicating the impact of structure alignment and data augmentation on the model's generalization ability.", "section": "5 Experiments"}, {"figure_path": "KVAx5tys2p/figures/figures_19_1.jpg", "caption": "Figure 7: The topological structure discrepancy (i.e., measured by the Bottleneck distance metric) of R50 TopoFR and R50 ArcFace on the IJB-C benchmark.", "description": "This figure compares the topological structure discrepancy between the input space and the latent space for both R50 TopoFR and R50 ArcFace models on the IJB-C benchmark.  The Bottleneck distance is used as a metric to quantify this discrepancy. The histogram visually represents the distribution of these distances. A smaller bottleneck distance indicates a better alignment between the topological structures of the input and latent spaces, suggesting that TopoFR preserves the structure information more effectively than ArcFace.", "section": "5.3 Analysis and Ablation Study"}, {"figure_path": "KVAx5tys2p/figures/figures_19_2.jpg", "caption": "Figure 8: Visualization of hard samples.", "description": "This figure visualizes some hard samples that are correctly classified by TopoFR but misclassified by ArcFace.  It shows that hard samples tend to be blurry, low-contrast, occluded, or in unusual poses.  TopoFR uses a Structure Damage Score (SDS) to assign weights to each sample based on its prediction uncertainty and accuracy. This allows TopoFR to better handle these challenging samples, leading to improved generalization performance.", "section": "4.2 Structure Damage Estimation"}]