[{"type": "text", "text": "Generalization bounds for mixing processes via delayed online-to-PAC conversions ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Anonymous Author(s)   \nAffiliation   \nAddress   \nemail ", "page_idx": 0}, {"type": "text", "text": "Abstract ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "1 We study the generalization error of statistical learning algorithms in a non-i.i.d. set  \n2 ting, where the training data is sampled from a stationary mixing process. We   \n3 develop an analytic framework for this scenario based on a reduction to online   \n4 learning with delayed feedback. In particular, we show that the existence of an   \n5 online learning algorithm with bounded regret (against a fixed statistical learning   \n6 algorithm in a specially constructed game of online learning with delayed feed  \n7 back) implies low generalization error of said statistical learning method even if   \n8 the data sequence is sampled from a mixing time series. The rates demonstrate a   \n9 trade-off between the amount of delay in the online learning game and the degree   \n10 of dependence between consecutive data points, with near-optimal rates recovered   \n11 in a number of well-studied settings when the delay is tuned appropriately as a   \n12 function of the mixing time of the process. ", "page_idx": 0}, {"type": "text", "text": "13 1 Introduction ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "14 In machine learning, generalization denotes the ability of a model to infer patterns from a dataset   \n15 of training examples and apply them to analyze previously unseen data (Shalev-Shwartz and Ben  \n16 David, 2014). The gap in accuracy between the model\u2019s predictions on new data and those on the   \n17 training set is usually referred to as generalization error. Providing upper bounds on this quantity   \n18 is a central goal in statistical learning theory. Classically, bounds based on notions of complexity   \n19 (e.g., VC dimension and Rademacher complexity) for the model\u2019s hypothesis space were used to   \n20 provide uniform worst-case guarantees (see Bousquet et al., 2004; Vapnik, 2013; Shalev-Shwartz   \n21 and Ben-David, 2014). However, results of this kind are often too loose to be applied to the most   \n22 common machine learning over-parameterised models, such as deep neural networks (Zhang et al.,   \n23 2021). As a consequence, several approaches have been proposed to obtain algorithm-dependent   \n24 generalization bounds, which can adapt to the problem and be much tighter in practice than their   \n25 uniform counterparts. Often, the underlying idea is that if the algorithm\u2019s output does not have a   \n26 too strong dependence on the specific input dataset used for the training, then the model should not   \n27 be prone to overfitting, and so generalize well. Examples of results that build onto these ideas are   \n28 stability bounds, information-theoretic bounds, and PAC-Bayesian bounds (see, e.g., Bousquet and   \n29 Elisseeff, 2002; Russo and Zou, 2020; Hellstr\u00f6m et al., 2023; Alquier, 2024).   \n30 Most results in the literature focus on the i.i.d. setting, where the training dataset is made of indepen  \n31 dent draws from some underlying data distribution. However, for several applications, this assumption   \n32 is far from realistic. For instance, it excludes the case where observations received by the learner   \n33 have some inherent temporal dependence, as it is the case for stock prices, daily energy consumption,   \n34 or sensor data from physical environments (Ariyo et al., 2014; Takeda et al., 2016). This calls for the   \n35 development of theory for addressing non-i.i.d. data. A common approach in the extant literature is   \n36 to consider a class of non-i.i.d. data-generating processes usually referred to as stationary $\\beta$ -mixing   \n37 or $\\varphi$ -mixing processes. This assumption, together with a \u201cblocking\u201d trick introduced by Yu (1994),   \n38 has led to a few results in the literature: Meir (2000), Mohri and Rostamizadeh (2008), Shalizi and   \n39 Kontorovich (2013), and Wolfer and Kontorovich (2019) provided uniform worst-case generalization   \n40 bounds, Steinwart and Christmann (2009) and Agarwal and Duchi (2012) discussed excess risk bound   \n41 (comparing the algorithm\u2019s output with the best possible hypothesis), while Mohri and Rostamizadeh   \n42 (2010) gave bounds based on a stability analysis (in the sense of Bousquet and Elisseeff, 2002).   \n43 Here, we propose propose results for the non-i.i.d. setting in the form of PAC-Bayesian bounds   \n44 (Guedj, 2019; Alquier, 2024): high probability upper bounds on the expected generalization error of   \n45 randomized learning algorithms. We achieve this by combining the \u201cblocking\u201d argument by Yu (1994)   \n46 to manage the concentration of sums of correlated random variables, with the recent online-to-PAC   \n47 conversion technique recently proposed by Lugosi and Neu (2023). Using their framework we show   \n48 a new way to obtain generalization bounds for stationary dependent processes that satisfy a certain   \n49 \u201cshort-memory\u201d property (intuitively meaning that data points that are closer in time are more heavily   \n50 dependent on each other). Our assumption slightly differs from $\\beta$ -mixing in the sense that we only   \n51 need it to hold for a specific class of bounded loss functions. Among other results, this allows us to   \n52 prove PAC-Bayesian generalization bounds for mixing processes. This complements previous work   \n53 on such bounds that have only considered mild relaxations of the i.i.d. condition such as assuming   \n54 that the data has a martingale structure (see, e.g., Seldin et al., 2012; Chugg et al., 2023; Haddouche   \n55 and Guedj, 2023). Notable exceptions are the works of Alquier and Wintenberger (2012), Alquier   \n56 et al. (2013), and Eringis et al. (2022, 2024), who provided generalization bounds for a sequential   \n57 prediction setting where both the data-generating process and the hypothesis class used for prediction   \n58 are stable dynamical systems. Their results are proved under some very specific conditions on these   \n59 systems, and their guarantees involve unspecified problem-dependent constants that may be large. In   \n60 contrast, our bounds hold under general, simple-to-verify conditions and feature explicit constants.   \n61 The rest of the paper is organized as follows. In Section 2 we properly define the generalization error   \n62 of a statistical learning algorithm for both i.i.d. and non-i.i.d. cases, and state our main assumption   \n63 on the data dependence. Our main contribution lies in Section 3, where after recalling the results   \n64 for the i.i.d. setting we show how to adapt this to stationary mixing processes. In Section 4 we   \n65 provide concrete results of the bounds we can obtain through the online-to-PAC conversion. Finally   \n66 in Section 5 we extend our results to the setting where the hypothesis class itself may consist of   \n67 dynamical systems.   \n68 Notation. For a distribution over hypotheses $P\\in\\Delta_{W}$ and bounded function $f:\\mathcal{W}\\to\\mathbb{R}$ we write   \n69 $\\langle P,f\\rangle$ to refer to the expectation of $\\mathbb{E}_{W\\sim P}[f(W)]$ . We denote $\\begin{array}{r}{\\mathcal{D}_{K L}(P||Q)=\\mathbb{E}_{X\\sim P}\\left[\\ln\\left(\\frac{P(X)}{Q(X)}\\right)\\right]}\\end{array}$   \n70 to refer to the Kullback-Leibler divergence. We use $||.||$ to denote a norm on the Banach space $\\mathcal{Q}$ of   \n71 the finite signed measures, and $||.||_{*}$ the corresponding dual norm on the dual space $\\mathcal{Q}^{*}$ of measurable   \n72 functions $f$ on $\\mathcal{W}$ such that $||f||_{*}=\\operatorname*{sup}_{Q\\in\\mathcal{Q}:||Q||\\leq1}\\langle Q,f\\rangle$ . ", "page_idx": 0}, {"type": "text", "text": "", "page_idx": 0}, {"type": "text", "text": "", "page_idx": 1}, {"type": "text", "text": "", "page_idx": 1}, {"type": "text", "text": "", "page_idx": 1}, {"type": "text", "text": "", "page_idx": 1}, {"type": "text", "text": "73 2 Preliminaries ", "text_level": 1, "page_idx": 1}, {"type": "text", "text": "74 The classical statistical learning framework usually considers a dataset ${\\cal S}_{n}=(Z_{1},...,Z_{n})$ , made of   \n75 n i.i.d. elements drawn from a distribution $\\mu$ over a measurable instance space $\\mathcal{Z}$ . Often, one can   \n76 think of each $Z_{i}$ as a feature-label pair $(X_{i},Y_{i})$ . Furthermore, we are given a measurable class $\\mathcal{W}$ of   \n77 hypotheses and a loss function $\\ell:\\mathcal{W}\\!\\times\\!\\mathcal{Z}\\to\\mathbb{R}_{+}$ , with $\\ell(w,z)$ measuring the quality of the hypothesis   \n78 $w\\in\\mathscr{W}$ on the data instance $z\\in{\\mathcal{Z}}$ . For any given hypothesis $w\\in\\mathcal{W}$ , two key objects of interest are   \n79 the training error $\\begin{array}{r}{\\widehat{\\mathcal{L}}(w,S_{n})=\\frac{1}{n}\\sum_{i=1}^{n}\\ell(w,Z_{i})}\\end{array}$ and the test error $\\mathcal{L}(w)=\\mathbb{E}_{Z^{\\prime}\\sim\\mu}[\\ell(w,Z^{\\prime})]$ , where   \n80 the random element $Z^{\\prime}$ has the same distribution as $Z_{i}$ and is independent of $S_{n}$ .   \n81 A learning algorithm $A:{\\mathcal{Z}}^{n}\\to\\mathcal{W}$ maps the training sample to an hypothesis in $\\mathcal{W}$ . More generally,   \n82 we will focus on randomized learning algorithms, returning a probability distribution $P_{W_{n}|S_{n}}\\in\\Delta_{\\mathcal{W}}$   \n83 over $\\mathcal{W}$ , conditionally on $S_{n}$ (deterministic algorithms can be recovered as special cases, whose the   \n84 outputs are Dirac distributions). The ultimate goal of the learner is to minimize the test error. Yet, this   \n85 quantity cannot be computed without knowledge of the data generating distribution $\\mu$ . In practice, one   \n86 typically relies on the training error in order to gauge the quality of the algorithm. For an algorithm ${\\mathcal{A}}:$   \n87 $S_{n}\\mapsto P_{W_{n}|S_{n}}$ , we define the generalization error as the expected gap between training and test error: ", "page_idx": 1}, {"type": "text", "text": "", "page_idx": 1}, {"type": "equation", "text": "$$\n\\mathrm{Gen}(\\mathcal{A},S_{n})=\\mathbb{E}\\left[\\mathcal{L}(W_{n})-\\widehat{\\mathcal{L}}(W_{n},S_{n})\\Big|S_{n}\\right].\n$$", "text_format": "latex", "page_idx": 1}, {"type": "text", "text": "88 The expectation in the above expression integrates over the randomness in the output of the algorithm   \n89 $W_{n}\\sim P_{W_{n}|S_{n}}$ , conditionally on the sample $S_{n}$ . We remark that the test error is not equal to the   \n90 mean of the training error, due to the dependence of $W_{n}$ on the training data.   \n91 We extend the previous setting by considering the case where the data have an intrinsic temporally   \n92 ordered structure, and come in the form of a stationary process $(Z_{t})_{t\\in\\mathbb{N}^{*}}\\sim\\nu$ . Formally, we assume   \n93 that the joint marginal distribution of any block $(Z_{t},Z_{t-1},\\ldots,Z_{t-i})$ is the same as the distribution   \n94 of $(Z_{t+j},Z_{t+j-1},\\ldots,Z_{t+j-i})$ for any $t$ , $i$ and $j$ , but the data points are not necessarily independent   \n95 of each other. In particular, the marginal distribution of $Z_{t}$ is constant and is denoted by $\\mu$ . Thus, it is   \n96 natural to continue to use the definition of the test loss and generalization error given above, although   \n97 with the understanding that $\\mu$ now refers to the marginal distribution of an independent copy of $Z_{1}$ ,   \n98 a sample point from a stationary non-i.i.d. process. We remark here that other notions of the test   \n99 loss may also be considered, and the framework that we propose can be extended to most natural   \n100 definitions with little work (but potentially large notational overhead). In Section 5, we provide such   \n101 an extension for a more general setting where the hypotheses themselves are allowed to have memory   \n102 and the process may not be as strongly stationary as our assumption above requires.   \n103 In order to obtain generalization results we need to have some control on how strong the dependencies   \n104 between different datapoints are allowed to be. To this regard, we consider the following assumption. ", "page_idx": 2}, {"type": "text", "text": "", "page_idx": 2}, {"type": "text", "text": "", "page_idx": 2}, {"type": "text", "text": "Assumption 1. There exists a non-increasing sequence $(\\phi_{d})_{d\\in\\mathbb{N}^{*}}$ of non-negative real numbers such that, for all $w\\in\\mathscr{W}$ and all $t\\in\\mathbb{N}^{*}$ : ", "page_idx": 2}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathbb{E}\\left[\\mathcal{L}(w)-\\ell(w,Z_{t})\\Big|\\mathcal{F}_{t-d}\\right]\\leq\\phi_{d}\\,,}\\end{array}\n$$", "text_format": "latex", "page_idx": 2}, {"type": "text", "text": "105 where $\\mathcal{L}(w)=\\mathbb{E}_{Z^{\\prime}\\sim\\mu}[\\ell(w,Z^{\\prime})]$ , with $Z^{\\prime}$ being independent on the process $(Z_{t})_{t\\in\\mathbb{N}^{*}}$ and having as   \n106 distribution the stationary marginal $\\mu$ of the $Z_{t}$ .   \n107 The intuition behind this assumption is that the loss associated with the observations $Z_{t}$ becomes   \n108 almost independent of the past after $d$ steps, enabling us to treat each sequence of the form   \n109 $(Z_{t},Z_{t+d},\\ldots,Z_{t+(n-t)d})$ as an approximately i.i.d. sequence. Note that this assumption differs   \n110 from the usual $\\beta$ -mixing assumption which requires the distribution of $Z_{t}|\\mathcal{F}_{t-d}$ to be close to the   \n111 marginal distribution $\\mu$ for all $t$ , in terms of total variation distance. Our assumption is somewhat   \n112 weaker in the sense that it only requires the expected losses under these distributions to be close,   \n113 and only a one-sided inequality is required. It is easy to verify that our assumption is satisfied if the   \n114 process is $\\beta$ -mixing in the usual sense and the losses are bounded in $[0,1]$ . ", "page_idx": 2}, {"type": "text", "text": "", "page_idx": 2}, {"type": "text", "text": "115 3 Proving generalization bounds via online learning ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "116 Online learning focuses on algorithms that aim to improve performance incrementally as new   \n117 information becomes available, often without any underlying assumption on how data are generated.   \n118 The online learner\u2019s performance is typically measured leveraging the idea of regret. This involves   \n119 introducing a cost function for the problem and defining the regret as the difference between the   \n120 cumulative cost of the online learner and that of a fixed comparator. We refer to the monographs   \n121 Cesa-Bianchi and Lugosi, 2006 and Orabona, 2019 for comprehensive overviews on online learning   \n122 and regret analysis. Recently, Lugosi and Neu (2023) established a connection between upper bounds   \n123 on the regret and generalization bounds, showing that the existence of a strategy with a bounded   \n124 regret in a specially designed online game translates into a generalization bound, via a technique   \n125 dubbed online-to-PAC conversion. Their focus is on the i.i.d. setting, where the training dataset is   \n126 made of independent draws. Here, we show that this framework can naturally be extended beyond   \n127 the i.i.d. assumption.   \n128 In what follows, we briefly review the setup of Lugosi and Neu (2023) in Section 3.1 and then   \n129 describe our new extension of their model to the non-i.i.d. case in Section 3.2. In particular, we prove   \n130 a high-probability bound for the generalization error of any statistical learning algorithm learnt with   \n131 a stationary mixing process verifying Assumption 1. ", "page_idx": 2}, {"type": "text", "text": "", "page_idx": 2}, {"type": "text", "text": "132 3.1 Online-to-PAC conversions for i.i.d. data ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "133 Lugosi and Neu (2023) have recently established a framework to obtain generalization bounds via   \n134 a reduction to online learning. Their technique allows to recover several classic PAC-Bayesian   \n135 results, and provide a range of generalizations thereof. The main idea of Lugosi and Neu (2023) is   \n136 to introduce an online learning game called the generalization game, where the following steps are   \n137 repeated for a sequence of rounds $t=1,2,\\ldots,n$ : ", "page_idx": 2}, {"type": "text", "text": "", "page_idx": 3}, {"type": "text", "text": "138 ", "page_idx": 3}, {"type": "text", "text": "139 ", "page_idx": 3}, {"type": "text", "text": "140 ", "page_idx": 3}, {"type": "text", "text": "\u2022 the online learner picks a distribution $P_{t}\\in\\Delta_{w}$ ;   \n\u2022 the adversary selects the cost function $c_{t}:w\\mapsto\\ell(w,Z_{t})-\\mathcal{L}(w)$ ;   \n\u2022 the online learner incurs the cost $\\langle P_{t},c_{t}\\rangle=\\mathbb{E}_{W\\sim P_{t}}[c_{t}(W)]$ ;   \n\u2022 $Z_{t}$ is revealed to the learner. ", "page_idx": 3}, {"type": "text", "text": "141 ", "page_idx": 3}, {"type": "text", "text": "142 The learner can adopt any strategy to pick $P_{t}$ , but they can only rely on past knowledge to make   \n143 their prediction. Explicitly, if $\\mathcal{F}_{t}$ denotes the sigma-algebra generated by $Z_{1},...,Z_{t}$ , then $P_{t}$ has to be   \n144 $\\mathcal{F}_{t-1}$ -measurable. We also emphasize that in this setup the online learner is allowed to know the loss   \n145 function $\\ell$ and the distribution $\\mu$ of the data points $Z_{t}$ , and therefore by revealing the value of $Z_{t}$ , the   \n146 online learner may compute the entire cost function $c_{t}$ .   \n147 We define the regret of the online learner against the possibly data-dependent comparator $P^{*}\\in\\Delta_{\\mathcal{W}}$   \n148 as $\\begin{array}{r}{\\mathrm{Regret}(P^{*})\\stackrel{}{=}\\sum_{t=1}^{n}\\langle P_{t}-P^{*},c_{t}\\rangle}\\end{array}$ . Now, denote as $P_{W_{n}|S_{n}}$ the distribution produced by the super  \n149 vised learning algorithm. With this notation, the generalization error can be written as ${\\mathrm{Gen}}(A,S_{n})=$   \n150 $\\begin{array}{r}{-\\frac{1}{n}\\sum_{t=1}^{n}\\langle\\check{P_{W_{n}|S_{n}}},c_{t}\\rangle}\\end{array}$ . By adding and subtracting the quantity $\\begin{array}{r}{M_{n}=-{\\frac{1}{n}}\\sum_{t=1}^{n}\\langle P_{t},c_{t}\\rangle}\\end{array}$ \u2212n1 t=1\u27e8Pt, ct\u27e9we get the   \n151 following decomposition.   \n152 Theorem 1 (Theorem 1 in Lugosi and Neu, 2023; see appendix A.1). With the notation introduced   \n153 above, ", "page_idx": 3}, {"type": "text", "text": "", "page_idx": 3}, {"type": "text", "text": "", "page_idx": 3}, {"type": "equation", "text": "$$\n\\mathrm{Gen}(A,S_{n})={\\frac{\\mathrm{Regret}_{n}(P_{W_{n}|S_{n}})}{n}}+M_{n}\\,.\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "154 The first of these terms correspond to the regret of the online learner against a fixed comparator   \n155 strategy that picks $P_{W_{n}|S_{n}}$ at each step. The second term is a martingale and can be bounded in high   \n156 probability with standard concentration tools. Indeed, since $P_{t}$ is chosen before $Z_{t}$ is revealed, one   \n157 can easily check that $\\mathbb{E}[\\langle P_{t},c_{t}\\rangle|\\mathcal{F}_{t-1}]=0$ . Thus, to prove a bound on the generalization error of the   \n158 statistical learning algorithm, it is enough to find an online learning algorithm with bounded regret   \n159 against $P_{W_{n}|S_{n}}$ in the generalization game.   \n160 As a concrete application of the above, the following generalization bound is obtained when picking   \n161 the classic exponential weighted average (EWA) algorithm (Vovk, 1990; Littlestone and Warmuth,   \n162 1994; Freund and Schapire, 1997) as online strategy, and plugging its regret bound into (1).   \n163 Theorem 2 (Corollary 6 in Lugosi and Neu, 2023). Suppose that $\\ell(w,z)\\in[0,1]$ for all $w,z$ . Then,   \n164 for any $P_{1}\\in\\Delta_{\\mathcal{W}}$ and $\\eta>0$ , with probability at least $1-\\delta$ on the draw of $S_{n}$ , uniformly on every   \n165 learning algorithm $\\cal{A}:{\\cal S}_{n}\\mapsto{\\cal P}_{W_{n}|S_{n}}$ , we have ", "page_idx": 3}, {"type": "text", "text": "", "page_idx": 3}, {"type": "text", "text": "", "page_idx": 3}, {"type": "equation", "text": "$$\n\\operatorname{Gen}(\\mathcal{A},S_{n})\\leq\\frac{\\mathcal{D}_{K L}(P_{W_{n}|S_{n}}||P_{1})}{\\eta n}+\\frac{\\eta}{2}+\\sqrt{\\frac{2\\log\\left(\\frac{1}{\\delta}\\right)}{n}}\\,.\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "166 Proof. We can bound each term of (1) separately. A data-dependent bound for the regret   \n167 term is obtained via a direct application of the regret analysis of EWA which brings the term   \n168 DKL(PW\u03b7nn|Sn||P1)+ \u03b72 (see Appendix B.1). The term $\\sqrt{\\frac{2\\log\\left({\\frac{1}{\\delta}}\\right)}{n}}$ results from bounding the martingale   \n169 $M_{n}$ via an application of Hoeffding\u2013Azuma inequality. \u53e3   \n170 Note that the first term in the above bound is data-dependent due to the presence of $P_{W_{n}|S_{n}}$ , and thus   \n171 optimizing it requires a data-dependent choice of $\\eta$ , which is not allowed by Theorem 2. However,   \n172 via a union bound argument it is possible to get a bound in the form ", "page_idx": 3}, {"type": "text", "text": "", "page_idx": 3}, {"type": "equation", "text": "$$\n\\operatorname{Gen}(A,S_{n})=\\mathcal{O}\\left(\\sqrt{\\frac{{\\mathscr{D}_{K L}}(P_{W_{n}|S_{n}}||P_{1})}{n}}+\\sqrt{\\frac{1}{n}\\log\\left(\\frac{\\log n}{\\delta}\\right)}\\right),\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "173 For the details, we refer to the proof of Corollary 5 of Lugosi and Neu (2023), which recovers a   \n174 classical PAC-Bayes bound of McAllester (1998). ", "page_idx": 3}, {"type": "text", "text": "175 3.2 Online-to-PAC conversions for non-i.i.d. data ", "text_level": 1, "page_idx": 4}, {"type": "text", "text": "176 In what follows, we will drop the i.i.d. assumption for the data, and instead consider non-i.i.d. se  \n177 quences satisfying Assumption 1. For this setting we define the following variant of the generalization   \n178 game.   \n179 Definition 1 (Generalization game with delay). The generalization game with delay $d\\in\\mathbb{N}^{*}$ is an   \n180 online learning game where the following steps are repeated for a sequence of rounds $t=1,...,n$ : ", "page_idx": 4}, {"type": "text", "text": "", "page_idx": 4}, {"type": "text", "text": "181 ", "page_idx": 4}, {"type": "text", "text": "182 ", "page_idx": 4}, {"type": "text", "text": "183 ", "page_idx": 4}, {"type": "text", "text": "\u2022 the online learner picks a distribution $P_{t}\\in\\Delta_{\\mathcal{W}}$ ;   \n\u2022 the adversary selects the cost function $c_{t}:w\\mapsto\\ell(w,Z_{t})-\\mathcal{L}(w),$ ;   \n\u2022 the online learner incurs the cost $\\langle P_{t},c_{t}\\rangle=\\mathbb{E}_{W\\sim P_{t}}[c_{t}(W)].$ ;   \n\u2022 $i f t\\ge d,\\,Z_{t-d+1}$ (and thus $c_{t-d+1}$ ) is revealed to the learner. ", "page_idx": 4}, {"type": "text", "text": "184 ", "page_idx": 4}, {"type": "text", "text": "185 The main difference between our version of the generalization game and the standard one of Lugosi   \n186 and Neu (2023) is the introduction of a delay on the online learning algorithm\u2019s decisions. Specifically,   \n187 we will force the online learner to only take information into account up to time $t-d$ when picking   \n188 their action $P_{t}$ . Clearly, setting $d=1$ recovers the original version of the generalization game with   \n189 no delay.   \n190 It is easy to see that the regret decomposition of Theorem 1 still remains valid in the current setting.   \n191 The purpose of introducing the delay is to be able to make sure that the term $\\begin{array}{r}{M_{n}=-{\\frac{1}{n}}\\sum_{t=1}^{n}\\left\\langle P_{t},c_{t}\\right\\rangle}\\end{array}$   \n192 is small. The lemma below states that the increments of $M_{n}$ behave similarly to a martingale  \n193 difference sequence, thanks to the introduction of the delay. ", "page_idx": 4}, {"type": "text", "text": "", "page_idx": 4}, {"type": "text", "text": "Lemma 1. Fix $d\\in[1,n]$ . Under assumption $^{\\,l}$ , it holds for all $t\\in[1,n]$ : ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\mathbb{E}[\\langle-P_{t},c_{t}\\rangle|\\mathcal{F}_{t-d}]\\leq\\phi_{d}\\,.\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "194 where $P_{t}$ and $c_{t}$ are defined as in $^{\\,l}$ . ", "page_idx": 4}, {"type": "text", "text": "195 Proof. Since $P_{t}$ is $\\mathcal{F}_{t-d}$ -measurable we have $\\mathbb{E}[\\langle-P_{t},c_{t}\\rangle|\\mathcal{F}_{t-d}]=\\langle P_{t},\\mathbb{E}[-c_{t}|\\mathcal{F}_{t-d}]\\rangle\\leq\\phi_{d}$ , where   \n196 the last step uses Assumption 1. \u53e3   \n197 Thus, by following the decomposition of Theorem 1, we are left with the problem of bounding the   \n198 regret of the delayed online learning algorithm against $P_{W_{n}|S_{n}}$ , denoted as $\\mathrm{Regret}_{d,n}(P_{W_{n}|S_{n}})=$   \n199 $\\begin{array}{r}{\\sum_{t=1}^{n}\\left\\langle P_{t}-P_{W_{n}|S_{n}},c_{t}\\right\\rangle}\\end{array}$ . The following proposition states a simple and clean bound that one can   \n200 immediately derive from these insights.   \n201 Proposition 1 (Bound in expectation). Consider $(Z_{t})_{t\\in\\mathbb{N}^{*}}$ satisfying Assumption $^{\\,l}$ and suppose there   \n202 exists a $d$ -delayed online learning algorithm with regret bounded by $\\mathrm{Regret}_{d,n}(P^{*})$ against any   \n203 comparator $P^{*}$ . Then, the expected generalization of $\\boldsymbol{\\mathcal{A}}$ is bounded as ", "page_idx": 4}, {"type": "text", "text": "", "page_idx": 4}, {"type": "text", "text": "", "page_idx": 4}, {"type": "equation", "text": "$$\n\\mathbb{E}\\left[{\\mathrm{Gen}}(A,S_{n})\\right]\\leq{\\frac{\\mathbb{E}\\left[{\\mathrm{Regret}}_{d,n}(P_{W_{n}|S_{n}})\\right]}{n}}+\\phi_{d}\\,.\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "204 Proof. By Theorem 1, it holds that $\\begin{array}{r}{\\mathbb{E}[\\mathrm{Gen}(A,S_{n})]\\,=\\,\\frac{\\mathbb{E}[\\mathrm{Regret}_{d,n}(P_{W_{n}|S_{n}})]}{n}+\\mathbb{E}[M_{n}]}\\end{array}$ , where the   \n205 regret is for a strategy $P_{t}$ in the delayed generalization game. Hence, by Lemma 1 ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\mathbb{E}[M_{n}]=\\mathbb{E}\\left[-\\frac{1}{n}\\sum_{t=1}^{n}\\langle P_{t},c_{t}\\rangle\\right]=\\frac{1}{n}\\sum_{t=1}^{n}\\mathbb{E}[\\langle-P_{t},c_{t}\\rangle]=\\frac{1}{n}\\sum_{t=1}^{n}\\mathbb{E}\\left[\\mathbb{E}[\\langle-P_{t},c_{t}\\rangle|\\mathcal{F}_{t-d}]\\right]\\leq\\phi_{d}\\,,\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "206 which proves the claim. ", "page_idx": 4}, {"type": "text", "text": "207 The above result holds in expectation over the training sample. We now provide a high-probability   \n208 guarantee on the generalization error.   \n209 Theorem 3 (Bound in probability). Assume that $(Z_{t})_{t\\in\\mathbb{N}^{*}}$ satisfies Assumption $^{\\,l}$ and consider $a$   \n210 $d$ -delayed online learning algorithm with regret bounded by $R_{d,n}(P^{*})$ against any comparator $P^{*}$ .   \n211 Then, for any $\\delta>0$ , it holds with probability $1-\\delta$ on the draw of $S_{n}$ , uniformly for all $\\boldsymbol{\\mathcal A}$ , ", "page_idx": 4}, {"type": "text", "text": "", "page_idx": 4}, {"type": "equation", "text": "$$\n\\operatorname{Gen}(\\mathcal{A},S_{n})\\leq\\frac{R_{d,n}(P_{W_{n}|S_{n}})}{n}+\\phi_{d}+\\sqrt{\\frac{2d\\log\\left(\\frac{d}{\\delta}\\right)}{n}}.\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "212 The proof of this claim follows directly from combining the decomposition of Theorem 1 with a   \n213 standard concentration result for mixing processes that we state below.   \n214 Lemma 2. Fix $d\\in[1,n]$ and consider $(Z_{t})_{t\\in\\mathbb{N}^{*}}$ satisfying Assumption 1. Consider the generaliza  \n215 tion game of Definition $^{\\,l}$ . Then, for any $\\delta>0$ , the following bound is satisfied with probability at   \n216 least $1-\\delta$ : ", "page_idx": 5}, {"type": "text", "text": "", "page_idx": 5}, {"type": "equation", "text": "$$\nM_{n}\\leq\\phi_{d}+\\sqrt{\\frac{2d\\log\\left(\\frac{d}{\\delta}\\right)}{n}}.\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "217 The proof is based on a classic \u201cblocking\u201d technique due to Yu (1994). For the sake of completeness,   \n218 we provide a proof in Appendix A.2. ", "page_idx": 5}, {"type": "text", "text": "219 4 New generalization bounds for non-i.i.d. data ", "text_level": 1, "page_idx": 5}, {"type": "text", "text": "220 The dependence on the delay $d$ for the bounds that we presented in the previous section is non-trivial.   \n221 Indeed, if on the one hand increasing the delay will reduce the magnitude of $\\phi_{d}$ , on the other hand   \n222 the regret of the online learner will grow with $d$ . There is hence a trade-off between these two terms   \n223 appearing in our bounds. In what follows, we derive some concrete generalization bounds from   \n224 Theorem 3, under a number of different choices of the online learning algorithm. For concreteness,   \n225 we will consider two types of mixing assumptions, but stress that the approach can be applied to any   \n226 process that satisfies Assumption 1. ", "page_idx": 5}, {"type": "text", "text": "227 4.1 Regret bounds for delayed online learning ", "text_level": 1, "page_idx": 5}, {"type": "text", "text": "228 From Theorem 3, we can obtain a generalization bound using our framework if we have a regret   \n229 bound for a delayed online algorithm. This is a well-known problem in the area of online learning   \n230 (see, e.g., Weinberger and Ordentlich, 2002; Joulani et al., 2013). In the following, we will leverage   \n231 the following simple trick that allows us to extend the regret bounds of any online learning algorithm   \n232 to its delayed counterpart, provided that the regret bound respects some specific assumptions.   \n233 Lemma 3 (Weinberger and Ordentlich, 2002). Consider any online algorithm whose regret satisfies   \n234 Regre $\\mathbf{\\Phi}_{n}(P^{*})\\leq R(n)$ for any comparator $P^{*}$ , where $R$ is a non-decreasing real-valued function   \n235 such that $y\\mapsto y R(x/y)$ is a concave function of y for any fixed $x$ . Then, for any $d\\geq1$ there exists   \n236 an online learning algorithm with delay $d$ such that, for any comparator $P^{*}$ , ", "page_idx": 5}, {"type": "text", "text": "", "page_idx": 5}, {"type": "equation", "text": "$$\n\\mathrm{Regret}_{d,n}(P^{*})\\leq d R\\left(n/d\\right)\\,.\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "237 The proof idea is closely related to the blocking trick of Yu (1994), with an algorithmic construction   \n238 that runs one instance of the base method for each index $i=1,2,\\ldots,d$ , with the $i$ -th instance being   \n239 responsible for the regret in rounds $i,i+d,i+2d,\\ldots$ (more details are provided in Append\u221aix B.3).   \n240 For most of the regret bounds that we consider, the function $R$ takes the form $R(n)\\;{\\bar{=}}\\;O({\\sqrt{n}})$ , so   \n241 that the first term in the generalization bound is typically of order $\\sqrt{d/n}$ . Since this term matches   \n242 the bound on $M_{n}$ in Lemma 2, in this case the final generalization bound behaves effectively as if   \n243 the sample size was $n/d$ instead of $n$ . ", "page_idx": 5}, {"type": "text", "text": "244 4.2 Geometric and algebraic mixing ", "text_level": 1, "page_idx": 5}, {"type": "text", "text": "245 The following definition gives two concrete examples of mixing processes that satisfy Assumption 1   \n246 with different choices of $\\phi_{d}$ , and are commonly considered in the related literature (see, e.g., Mohri   \n247 and Rostamizadeh, 2010, Levin and Peres, 2017). ", "page_idx": 5}, {"type": "text", "text": "248 Definition 2. We say that a stationary process $(Z_{t})_{t\\in\\mathbb{N}^{*}}$ satisfying Assumption $^{\\,l}$ is: ", "page_idx": 5}, {"type": "text", "text": "249 ", "page_idx": 5}, {"type": "text", "text": "250 ", "page_idx": 5}, {"type": "text", "text": "geometrically mixing, $i f\\,\\phi_{d}=C e^{-\\frac{d}{\\tau}}$ , for some positive $\\tau$ and $C$ ;   \n\u2022 algebraically mixing, $i f\\phi_{d}=C d^{-r}$ , for some positive r and $C$ . ", "page_idx": 5}, {"type": "text", "text": "251 Instantiating the bound of Theorem 3 to these two cases yields the following two corollaries. ", "page_idx": 5}, {"type": "text", "text": "252 Corollary 1. Assume $(Z_{t})_{t\\in\\mathbb{N}^{*}}$ is a geometrically mixing process with constants $\\tau,C>0$ . Consider   \n253 a $d$ -delayed online learning algorithm with regret bounded by $R_{d,n}(P^{*})$ for all comparators $P^{*}$ .   \n254 Then, setting $d=\\lceil\\tau\\log n\\rceil$ , for any $\\delta>0$ , with probability at least $1-\\delta$ we have that, uniformly for   \n255 any algorithm $\\boldsymbol{\\mathcal{A}}$ , ", "page_idx": 5}, {"type": "text", "text": "", "page_idx": 6}, {"type": "equation", "text": "$$\n\\operatorname{Gen}(A,S_{n})\\leq\\frac{R_{d,n}(P_{W_{n}|S_{n}})}{n}+\\frac{C}{n}+\\sqrt{\\frac{2\\left(\\tau\\log n+1\\right)\\log\\left(\\frac{\\tau\\log n+1}{\\delta}\\right)}{n}}\\,.\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "256 Up to a term linear in $\\tau$ and some logarithmic factors, the above states that under the geometric   \n257 mixing the same rates are achievable as in the i.i.d. setting. Roughly speaking, this amounts to saying   \n258 that the effective sample size is a factor $\\tau$ smaller than the original number of samples $n$ , as long as   \n259 generalization is concerned.   \n260 Corollary 2. Assume $(Z_{t})_{t\\in\\mathbb{N}^{*}}$ is an algebraic mixing process with constants $r,C>0$ . Consider   \n261 a $d$ -delayed online learning algorithm with regret bounded by $R_{d,n}(P^{*})$ against any comparator   \n262 $P^{*}$ . Then, setting $d=\\left(C^{2}n\\right)^{1/\\left(1+2r\\right)}$ , for any $\\delta>0$ , with probability at least $1-\\delta$ we have that,   \n263 uniformly for any algorithm $A$ , ", "page_idx": 6}, {"type": "text", "text": "", "page_idx": 6}, {"type": "equation", "text": "$$\n\\operatorname{Gen}(A,S_{n})\\leq{\\frac{R_{d,n}(P_{W_{n}|S_{n}})}{n}}+C\\left(1+{\\sqrt{\\log(d/\\delta)}}\\right)n^{-{\\frac{2r}{2(1+2r)}}}\\,.\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "264 This result suggests that the rates achievable for algebraically mixing processes are qualitatively   \n265 much slower than what one can \u221aget for i.i.d. or geometrically mixing data sequences (although the   \n266 rates do eventually approach $1/\\sqrt{n}$ as $r$ goes to infinity). ", "page_idx": 6}, {"type": "text", "text": "267 4.3 Multiplicative weights with delay ", "text_level": 1, "page_idx": 6}, {"type": "text", "text": "268 We start our discussion on possible online strategies by focusing on the classic exponential weighted   \n269 average (EWA) algorithm (Vovk, 1990; Littlestone and Warmuth, 1994; Freund and Schapire, 1997).   \n270 We fix a data-free prior $P_{1}\\in\\Delta_{\\mathcal{W}}$ and a learning rate parameter $\\eta>0$ . We consider the updates ", "page_idx": 6}, {"type": "equation", "text": "$$\nP_{t+1}=\\underset{P\\in\\Delta_{\\mathcal{W}}}{\\arg\\operatorname*{min}}\\left\\{\\langle P,c_{t}\\rangle+\\frac{1}{\\eta}\\mathcal{D}_{K L}(P||P_{t})\\right\\},\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "271 Combining the standard regret bound of EWA (see Appendix B.1) with Lemma 3 and Corollary 1   \n272 yields the result that follows.   \n273 Corollary 3. Suppose that $(Z_{t})_{t\\in\\mathbb{N}^{*}}$ is a geometric mixing process with constants $\\tau,C>0.$ . Suppose   \n274 that $\\ell(w,z)\\in[0,1]$ for all $w,z$ . Then, for any $P_{1}\\in\\Delta_{\\mathcal{W}}$ and any $\\delta>0$ , with probability at least   \n275 $1-\\delta$ , uniformly on any learning algorithm $\\boldsymbol{\\mathcal{A}}$ we have ", "page_idx": 6}, {"type": "text", "text": "", "page_idx": 6}, {"type": "equation", "text": "$$\n\\operatorname{Gen}(A,S_{n})\\leq\\frac{\\mathcal{D}_{K L}(P^{*}||P_{1})(\\tau\\log n+1)}{\\eta n}+\\frac{\\eta}{2}+\\frac{C}{n}+\\sqrt{\\frac{2\\left(\\tau\\log n+1\\right)\\log\\left(\\frac{\\tau\\log n+1}{\\delta}\\right)}{n}}\\,.\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "276 This results suggests that when considering geometric mixing processes, by applying a union bound   \n277 ove\u221ar a well-chosen range of $\\eta$ we recover the PAC-Bayes bound of McAllester (1998) up to a   \n278 $O({\\sqrt{\\tau\\log n}})$ factor. A similar result can be derived from Corollary 2 for algebraically mixing   \n279 processes, leading to a bound typically scaling as $n^{-2r/(2(1+2r))}$ . ", "page_idx": 6}, {"type": "text", "text": "280 4.4 Follow the regularized leader with delay ", "text_level": 1, "page_idx": 6}, {"type": "text", "text": "281 In this subsection we extend the common class of online learning algorithms known as follow the   \n282 regularized leader (FTRL, see e.g., Abernethy and Rakhlin, 2009; Orabona, 2019) to the problem of   \n283 learning with delay. FTRL algorithms are defined using a convex regularization function $h:\\Delta_{\\mathcal{W}}\\to$   \n284 $\\mathbb{R}$ . We restrict ourselves to the set of proper, lower semi-continuous and $\\alpha$ -strongly convex functions   \n285 with respect to a norm $||.||$ (and its respective dual norm $||.||_{*})$ defined on the set of signed finite   \n286 measures on $\\mathcal{W}$ (see Appendix B.2 for more details). The online procedure (without delay) of the   \n287 FTRL algorithm is as follows: ", "page_idx": 6}, {"type": "equation", "text": "$$\nP_{t+1}=\\underset{P\\in\\Delta_{w}}{\\arg\\operatorname*{min}}\\left\\{\\sum_{s=1}^{t}\\langle P,c_{s}\\rangle+\\frac{1}{\\eta}h(P)\\right\\}.\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "288 The existence of the minimum is guaranteed by the compactness of $\\Delta{\\psi}$ under $\\lVert\\cdot\\rVert$ , and its uniqueness   \n289 is ensured by the strong convexity of $h$ . Combining the analysis of FTRL (see Appendix B.2) with   \n290 Lemma 3 and Corollary 1 yields the following result.   \n291 Corollary 4. Suppose that $(Z_{t})_{t\\in\\mathbb{N}^{*}}$ is a geometric mixing process with constants $\\tau,C>0$ . Suppose   \n292 that $\\ell(w,z)\\in[0,1]$ for all $w,z.$ . Assume there exists $B>0$ such that for all $t$ , $\\left|\\left|c_{t}\\right|\\right|*\\leq B$ . Then, for   \n293 any $P_{1}\\in\\Delta_{\\mathcal{W}}$ , for any $\\delta>0$ with probability at least $1-\\delta$ on the draw of $S_{n}$ , uniformly for all $\\boldsymbol{\\mathcal{A}}$ , ", "page_idx": 7}, {"type": "text", "text": "", "page_idx": 7}, {"type": "equation", "text": "$$\n\\mathtt{\\lambda}}\\\\ {\\mathtt{\\lambda}}\\\\ {\\mathtt{\\lambda}}\\mathtt{c e n}(A,S_{n})\\leq\\frac{\\left(h(P^{*})-h(P_{1})\\right)\\left(\\tau\\log n+1\\right)}{\\eta n}+\\frac{\\eta B^{2}}{2\\alpha}+\\frac{C}{n}+\\sqrt{\\frac{2\\left(\\tau\\log n+1\\right)\\log\\left(\\frac{\\tau\\log n+1}{\\delta}\\right)}{n}}.\n$$", "text_format": "latex", "page_idx": 7}, {"type": "text", "text": "294 This\u221a generalization bound is similar to the bound of Theorem 9 of Lugosi and Neu (2023) up to a   \n295 $O({\\sqrt{\\tau\\log n}})$ factor, when applying a union-bound argument over an appropriate grid of learning-rates   \n296 $\\eta$ . In particular, this result recovers PAC-Bayesian bounds like those of Corollary 3 when choosing   \n297 $\\dot{h}=\\bar{D}_{\\mathrm{KL}}\\left(\\cdot\\|P_{1}\\right)$ . We refer to Section 3.2 in Lugosi and Neu (2023) for more discussion on such   \n298 bounds. As before, a similar result can be stated for algebraically mixing processes, with the leading   \n299 terms approaching zero at rate of $n^{-2r/2(1+2r)}$ instead of $n^{-1/\\dot{2}}$ . ", "page_idx": 7}, {"type": "text", "text": "300 5 Generalization bounds for dynamic hypotheses ", "text_level": 1, "page_idx": 7}, {"type": "text", "text": "301 Finally, inspired by the works of Eringis et al. (2022, 2024), we extend our framework to accommodate   \n302 loss functions $\\ell$ that rely not only on the last data point $Z_{t}$ , but on the entire data sequence ${\\overline{{Z}}}_{t}=$   \n303 $(Z_{t},Z_{t-1},\\ldots,Z_{1})$ . Formally, we will consider loss functions of the form $\\ell:\\mathcal{W}\\times\\mathcal{Z}^{*}\\to\\mathbb{R}_{+}^{1}$ and   \n304 write $\\ell(w,\\overline{{z}}_{t})$ to denote the loss associated with hypothesis $w\\in\\mathcal{W}$ on sequence $\\overline{{z}}_{t}\\,\\in\\,\\mathcal{Z}^{t}$ . This   \n305 consideration extends the learning problem to class of dynamical predictors such as Kalman filters,   \n306 autoregressive models, or recurrent neural networks (RNNs), broadly used in time-series forecasting   \n307 (Ariyo et al., 2014; Takeda et al., 2016). Specifically, if we think of $z_{t}=(x_{t},y_{t})$ as a data-pair of   \n308 context and observation, in time-series prediction we usually not only rely on the context $x_{t}$ but also   \n309 on the past sequence of contexts and observations $(x_{t-1},y_{t-1},\\ldots,x_{1},y_{1})$ . As an example, consider   \n310 $\\begin{array}{r}{\\ell(w,z_{t}^{\\textit{\\scriptscriptstyle*}},\\ldots,z_{1}^{\\textit{\\scriptscriptstyle*}})=\\frac{1}{2}(y_{t}-h_{w}(x_{t},z_{t-1},\\ldots,z_{1}))_{\\cdot}^{2}}\\end{array}$ where $h\\in\\mathcal H$ is a function class parameterized by   \n311 $\\mathcal{W}$ . For this type of loss function a natural definition of the test error is: ", "page_idx": 7}, {"type": "equation", "text": "$$\n\\widetilde{\\mathcal{L}}(w)=\\operatorname*{lim}_{n\\rightarrow\\infty}\\mathbb{E}[\\ell(w,Z_{t}^{\\prime},Z_{t-1}^{\\prime},...,Z_{t-n}^{\\prime})],\n$$", "text_format": "latex", "page_idx": 7}, {"type": "text", "text": "312 where $\\overline{{Z}}_{t}^{\\prime}\\,=\\,(Z_{t}^{\\prime},Z_{t-1}^{\\prime},\\ldots)$ is a semi-infinite random sequence drawn from the same stationary   \n313 process that has generated the data $\\overline{{Z}}_{t}$ . We consider the following assumption. ", "page_idx": 7}, {"type": "text", "text": "Assumption 2. For a given process $(Z_{t})_{t\\in\\mathbb{Z}}$ with joint-distribution $\\nu$ over $\\mathcal{Z}^{\\mathbb{Z}}$ and same marginals $\\mu$ over $\\mathcal{Z}$ , there exists a non-increasing sequence $(\\phi_{d})_{d\\in\\mathbb{N}^{*}}$ of non-negative real numbers such that the following holds for all $w\\in\\mathcal{W}$ , for all $t\\in\\mathbb{N}^{*}$ : ", "page_idx": 7}, {"type": "equation", "text": "$$\n\\mathbb{E}\\left[\\ell(w,Z_{t},\\ldots,Z_{1})-\\widetilde{\\mathcal{L}}(w)\\Big|\\mathcal{F}_{t-d}\\right]\\leq\\phi_{d}.\n$$", "text_format": "latex", "page_idx": 7}, {"type": "text", "text": "This is a generalization of Assumption 1 in the sense that taking $\\ell(w,Z_{t},\\ldots,Z_{1})=\\ell(w,Z_{t})$ simply amounts to requiring the same mixing condition as before. For our online-to-PAC conversion we consider the same framework as in Definition 1, except that now the cost function is defined as ", "page_idx": 7}, {"type": "equation", "text": "$$\nc_{t}:w\\mapsto\\ell(w,Z_{t},\\ldots,Z_{1})-\\widetilde{\\mathcal{L}}(w)\\,.\n$$", "text_format": "latex", "page_idx": 7}, {"type": "text", "text": "314 Then it easy to check that result of Lemma 2 still holds for this specific cost, and we can thus extend   \n315 all the results of Section 4. For concreteness, we state the following adaptation of Theorem 3 below.   \n316 Theorem 4. Assume $(Z_{t})_{t\\in\\mathbb{Z}}$ which satisfies Assumption 2 and consider a $d$ -delayed online learning   \n317 algorithm with regret bounded by $R_{d,n}(P^{*})$ against any comparator $P^{*}$ . Then, for any $\\delta>0$ , $i t$   \n318 holds with probability $1-\\delta$ : ", "page_idx": 7}, {"type": "text", "text": "", "page_idx": 7}, {"type": "equation", "text": "$$\n\\operatorname{Gen}(A,S_{n})\\leq{\\frac{R_{d,n}(P_{W_{n}|S_{n}})}{n}}+\\phi_{d}+{\\sqrt{\\frac{2d\\log\\left({\\frac{d}{\\delta}}\\right)}{n}}}.\n$$", "text_format": "latex", "page_idx": 7}, {"type": "text", "text": "1Here, $\\mathcal{Z}^{\\ast}$ denotes the disjoint union $\\mathcal{Z}^{*}=\\sqcup_{t\\in\\mathbb{N}}\\mathcal{Z}^{t}$ . ", "page_idx": 7}, {"type": "text", "text": "319 To see that Assumption 2 can be verified and the resulting bounds can be meaningfully applied,   \n320 consider the following concrete assumptions about the hypothesis class, the loss function, and the   \n321 data generating process. The first assumption says that for any given hypothesis, the influence of past   \n322 data points on the associated loss vanishes with time (i.e., the hypothesis forgets the old data points at   \n323 a controlled rate).   \n324 Assumption 3. There exists a decreasing sequence $(B_{d})_{d\\in\\mathbb{N}^{*}}$ of non-negative real numbers such   \n325 that for any two sequences $\\overline{{z}}_{t}=(z_{t},\\ldots,z_{i})$ and $\\overline{{z}}_{t}^{\\prime}=(z_{t}^{\\prime},\\dots,z_{j}^{\\prime})$ of possibly different lengths that   \n326 satisfy $z_{k}=z_{k}^{\\prime}$ for all $k\\in t,\\ldots,t-d+1$ , we have $|\\ell(w,\\overline{{z}}_{t})-\\bar{\\ell}(w,\\overline{{z}}_{t}^{\\prime})|\\leq B_{d}$ , for all $w\\in\\mathcal{W}$ .   \n327 This condition can be verified for stable dynamical systems like autoregressive models, certain classes   \n328 of RNNs, or sequential predictors that have bounded memory by design (see Eringis et al., 2022,   \n329 2024). The next assumption is a refinement of Assumption 1, adapted to the case where the loss   \n330 function acts on blocks of $d$ data points $\\overline{{\\mathscr{z}}}_{t-d+1:t}=\\left(\\mathscr{z}_{t},\\mathscr{z}_{t-1},\\ldots,\\mathscr{z}_{t-d+1}\\right)$ .   \n331 Assumption 4. Let $\\overline{{Z}}_{t}=(Z_{t},\\ldots,Z_{1})$ be a sequence of data points and let $\\overline{{Z}}_{t}^{\\prime}=(Z_{t}^{\\prime},\\dots,Z_{0}^{\\prime},\\dots)$   \n332 be an independent copy of the same process. Then, there exists a decreasing sequence $(\\beta_{d})_{d\\in\\mathbb{N}^{*}}$   \n333 non-negative real numbers such that the following is satisfied for all hypotheses $w\\in\\mathcal{W}$ and all   \n334 $d\\in\\mathbb{N}^{*}$ : ", "page_idx": 8}, {"type": "text", "text": "", "page_idx": 8}, {"type": "text", "text": "", "page_idx": 8}, {"type": "text", "text": "", "page_idx": 8}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathbb E\\left[\\left.\\ell(w,\\overline{{Z}}_{t-d+1:t}^{\\prime})-\\ell(w,\\overline{{Z}}_{t-d+1:t})\\right|\\mathcal F_{t-2d}\\right]\\leq\\beta_{d}\\,.}\\end{array}\n$$", "text_format": "latex", "page_idx": 8}, {"type": "text", "text": "335 This assumption can be verified whenever the loss function is bounded and the joint distribution of   \n336 the data block $\\overline{{Z}}_{t-d+1:t}$ satisfies a $\\beta$ -mixing assumption. In more detail, this latter condition amounts   \n337 to requiring that the conditional distribution of each data block given a block that trails $d$ steps behind   \n338 is close to the marginal distribution in total variation distance, up to an additive term of $\\beta_{d}$ . The   \n339 following proposition shows that these two simple conditions together imply that Assumption 2   \n340 holds, and that thus the bound of Theorem 4 can be meaningfully instantiated for bounded-memory   \n341 hypothesis classes deployed on mixing processes.   \n342 Proposition 2. Suppose that the loss function satisfies Assumption 3 and the data distribution satisfies   \n343 Assumption 4. Then Assumption 2 is satisfied with $\\phi_{d}=2B_{d/2}+\\beta_{d/2}$ . ", "page_idx": 8}, {"type": "text", "text": "", "page_idx": 8}, {"type": "text", "text": "344 6 Conclusion ", "text_level": 1, "page_idx": 8}, {"type": "text", "text": "345 We have developed a general framework for deriving generalization bounds for non-i.i.d. processes   \n346 under a general mixing assumption, via an extension of the online-to-PAC-conversion framework of   \n347 Lugosi and Neu (2023). Among other results, this approach has allowed us to prove PAC-Bayesian   \n348 generalization bounds for such data in a clean and transparent way, and even study classes of dynamic   \n349 hypotheses under a simple bounded-memory condition. These results provide a clean and tight   \n350 alternative to the results of (Alquier and Wintenberger, 2012; Eringis et al., 2022). The generality of   \n351 our approach further demonstrates the power of the Online-to-PAC scheme of Lugosi and Neu (2023),   \n352 and in particular our results provide further evidence that this framework is particularly promising   \n353 for developing techniques for generalization in non-i.i.d. settings. We hope that flexibility of our   \n354 framework will find further uses and enables more rapid progress in the area. ", "page_idx": 8}, {"type": "text", "text": "355 References ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "356 Abernethy, J. and Rakhlin, A. (2009). Beating the adaptive bandit with high probability. IEEE   \n357 Information Theory and Applications Workshop.   \n358 Agarwal, A. and Duchi, J. (2012). The generalization ability of online algorithms for dependent data.   \n359 IEEE Transactions on Information Theory, 59(1).   \n360 Alquier, P. (2024). User-friendly introduction to PAC-Bayes bounds. Foundations and Trends in   \n361 Machine Learning, 17(2).   \n362 Alquier, P., Li, X., and Wintenberger, O. (2013). Prediction of time series by statistical learning:   \n363 general losses and fast rates. Dependence Modeling, 1(1).   \n364 Alquier, P. and Wintenberger, O. (2012). Model selection for weakly dependent time series forecasting.   \n365 Bernoulli, 18(3).   \n366 Ariyo, A. A., Adewumi, A. O., and Ayo, C. K. (2014). Stock price prediction using the ARIMA   \n367 model. UKSim-AMSS International Conference on Computer Modelling and Simulation.   \n368 Bousquet, O., Boucheron, S., and Lugosi, G. (2004). Introduction to Statistical Learning Theory.   \n369 Springer.   \n370 Bousquet, O. and Elisseeff, A. (2002). Stability and generalization. Journal of Machine Learning   \n371 Research, 2.   \n372 Cesa-Bianchi, N. and Lugosi, G. (2006). Prediction, learning, and games. Cambridge university   \n373 press.   \n374 Chugg, B., Wang, H., and Ramdas, A. (2023). A unified recipe for deriving (time-uniform) PAC  \n375 Bayes bounds. Journal of Machine Learning Research, 24(372).   \n376 Eringis, D., Leth, J., Tan, Z., Wisniewski, R., and Petreczky, M. (2022). PAC-Bayesian-like error   \n377 bound for a class of linear time-invariant stochastic state-space models. arXiv:2212.14838.   \n378 Eringis, D., Leth, J., Tan, Z., Wisniewski, R., and Petreczky, M. (2024). PAC-Bayes generalisation   \n379 bounds for dynamical systems including stable rnns. AAAI Conference on Artificial Intelligence.   \n380 Freund, Y. and Schapire, R. (1997). A decision-theoretic generalization of on-line learning and an   \n381 application to boosting. Journal of Computer and System Sciences, 55.   \n382 Guedj, B. (2019). A primer on PAC-Bayesian learning. Second congress of the French Mathematical   \n383 Society.   \n384 Haddouche, M. and Guedj, B. (2023). PAC-Bayes generalisation bounds for heavy-tailed losses   \n385 through supermartingales. Transactions on Machine Learning Research, 2023(4).   \n386 Hellstr\u00f6m, F., Durisi, G., Guedj, B., and Raginsky, M. (2023). Generalization bounds: Perspectives   \n387 from information theory and PAC-Bayes. arXiv:2309.04381.   \n388 Joulani, P., Gyorgy, A., and Szepesv\u00e1ri, C. (2013). Online learning under delayed feedback. ICML.   \n389 Levin, D. and Peres, Y. (2017). Markov chains and mixing times. American Mathematical Soc.   \n390 Littlestone, N. and Warmuth, M. (1994). The weighted majority algorithm. Information and   \n391 computation, 108(2).   \n392 Lugosi, G. and Neu, G. (2023). Online-to-PAC conversions: Generalization bounds via regret analysis.   \n393 arXiv:2305.19674.   \n394 McAllester, D. A. (1998). Some PAC-Bayesian theorems. COLT.   \n395 Meir, R. (2000). Nonparametric time series prediction through adaptive model selection. Machine   \n396 Learning, 39.   \n397 Mohri, M. and Rostamizadeh, A. (2008). Rademacher complexity bounds for non-i.i.d. processes.   \n398 NeurIPS.   \n399 Mohri, M. and Rostamizadeh, A. (2010). Stability bounds for stationary $\\phi$ -mixing and $\\beta$ -mixing   \n400 processes. Journal of Machine Learning Research, 11(26).   \n401 Orabona, F. (2019). A modern introduction to online learning. arXiv:1912.13213.   \n402 Russo, D. and Zou, J. (2020). How much does your data exploration overfit? controlling bias via   \n403 information usage. IEEE Transactions on Information Theory, 66(1).   \n404 Seldin, Y., Laviolette, F., Cesa-Bianchi, N., Shawe-Taylor, J., and Auer, P. (2012). PAC-Bayesian   \n405 inequalities for martingales. IEEE Transactions on Information Theory, 58(12).   \n406 Shalev-Shwartz, S. and Ben-David, S. (2014). Understanding Machine Learning - From Theory to   \n407 Algorithms. Cambridge University Press.   \n408 Shalizi, C. and Kontorovich, A. (2013). Predictive PAC learning and process decompositions.   \n409 NeurIPS.   \n410 Steinwart, I. and Christmann, A. (2009). Fast learning from non-i.i.d. observations. NeurIPS.   \n411 Takeda, H., Tamura, Y., and Sato, S. (2016). Using the ensemble Kalman filter for electricity load   \n412 forecasting and analysis. Energy, 104.   \n413 Vapnik, V. (2013). The nature of statistical learning theory. Springer science & business media.   \n414 Vovk, V. (1990). Aggregating strategies. COLT.   \n415 Weinberger, M. and Ordentlich, E. (2002). On delayed prediction of individual sequences. IEEE   \n416 Transactions on Information Theory, 48(7).   \n417 Wolfer, G. and Kontorovich, A. (2019). Minimax learning of ergodic Markov chains. ALT.   \n418 Yu, B. (1994). Rates of convergence for empirical processes of stationary mixing sequences. The   \n419 Annals of Probability, 22(1).   \n420 Zhang, C., Bengio, S., Hardt, M., Recht, B., and Vinyals, O. (2021). Understanding deep learning   \n421 (still) requires rethinking generalization. Communications of the ACM, 64(3). ", "page_idx": 9}, {"type": "text", "text": "", "page_idx": 10}, {"type": "text", "text": "422 A Omitted proofs ", "text_level": 1, "page_idx": 11}, {"type": "text", "text": "423 A.1 The proof of Theorem 1 ", "text_level": 1, "page_idx": 11}, {"type": "text", "text": "424 Let $(P_{t})_{t=1}^{n}\\in\\Delta_{\\mathcal{W}}^{n}$ be the predictions of an online learner playing the generalization game. Then ", "page_idx": 11}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\mathrm{Gen}(A,S_{n})=\\displaystyle\\frac{1}{n}\\sum_{t=1}^{n}\\mathbb{E}[\\ell_{t}(W_{n})-\\mathcal{L}(W_{n})|S_{n}]}\\\\ &{=-\\displaystyle\\frac{1}{n}\\sum_{t=1}^{n}\\mathbb{E}[c_{t}(W_{n})|S_{n}]}\\\\ &{=-\\displaystyle\\frac{1}{n}\\sum_{t=1}^{n}\\langle P_{W_{n}|S_{n}},c_{t}\\rangle}\\\\ &{=\\displaystyle\\frac{1}{n}\\sum_{t=1}^{n}\\langle P_{t}-P_{W_{n}|S_{n}},c_{t}\\rangle-\\displaystyle\\frac{1}{n}\\sum_{t=1}^{n}\\langle P_{t},c_{t}\\rangle}\\\\ &{=\\displaystyle\\frac{\\mathrm{Regret}_{n}(P_{W_{n}|S_{n}})}{n}+M_{n}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 11}, {"type": "text", "text": "425 A.2 The proof of Lemma 2 ", "text_level": 1, "page_idx": 11}, {"type": "text", "text": "426 Assume $n=K d$ for simplicity: ", "page_idx": 11}, {"type": "equation", "text": "$$\n\\begin{array}{l}{{\\displaystyle M_{n}=-{\\frac{1}{n}}\\sum_{t=1}^{n}\\langle P_{t},c_{t}\\rangle}}\\\\ {{\\displaystyle\\quad={\\frac{1}{d K}}\\sum_{i=1}^{d}\\sum_{t=1}^{K}\\langle-P_{i+d(t-1)},c_{i+d(t-1)}\\rangle}}\\end{array}\n$$", "text_format": "latex", "page_idx": 11}, {"type": "text", "text": "427 We denote $X_{t}^{(i)}\\,=\\,\\langle-P_{i+d(t-1)},c_{i+d(t-1)}\\rangle$ and we want to bound in high-probability the term   \n428 $\\textstyle\\frac{1}{K}\\sum_{t=1}^{K}X_{t}^{(i)}$ . Let also denote $\\mathcal{F}_{t}^{(i)}=\\mathcal{F}_{i+d(t-1)}.$ . Then for $i\\in[1,d]$ , we can write using Chernoff\u2019s   \n429 technique that for all $\\lambda>0$ it holds: ", "page_idx": 11}, {"type": "equation", "text": "$$\n\\mathbb{P}\\left(\\frac{1}{K}\\sum_{t=1}^{K}X_{t}^{(i)}\\geq u\\right)\\leq\\frac{\\mathbb{E}\\left[e^{\\frac{\\lambda}{K}\\sum_{t=1}^{K}X_{t}^{(i)}}\\right]}{e^{\\lambda u}}}\\\\ {\\leq\\mathbb{E}\\left[e^{\\frac{\\lambda}{K}\\sum_{t=1}^{K-1}X_{t}^{(i)}}\\mathbb{E}\\left[e^{\\frac{\\lambda}{K}X_{K}^{(i)}}\\Big|\\mathcal{F}_{K-1}^{(i)}\\right]\\right]e^{-\\lambda u}.\n$$", "text_format": "latex", "page_idx": 11}, {"type": "text", "text": "430 Now remark that: ", "page_idx": 11}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathbb{E}\\left[e^{\\frac{\\lambda}{K}X_{K}^{(i)}}\\Big|\\mathcal{F}_{K-1}^{(i)}\\right]=\\mathbb{E}\\left[e^{\\frac{\\lambda}{K}(X_{K}^{(i)}-\\mathbb{E}[X_{K}^{(i)}|F_{K-1}^{(i)}])}\\Big|F_{K-1}^{(i)}\\right]e^{\\frac{\\lambda}{K}\\mathbb{E}[X_{K}^{(i)}|F_{K-1}^{(i)}]}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 11}, {"type": "text", "text": "431 If we denote $Z\\,=\\,X_{K}^{\\left(i\\right)}\\,-\\,\\mathbb{E}[X_{K}^{\\left(i\\right)}|F_{K-1}^{\\left(i\\right)}]$ then $|Z|\\le2$ and $\\mathbb{E}[Z|F_{K-1}^{(i)}]\\,=\\,0$ so via Hoeffding\u2019s   \n432 lemma: ", "page_idx": 11}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathbb{E}[e^{\\frac{\\lambda}{K}Z}]\\leq e^{\\frac{\\lambda^{2}}{2K^{2}}}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 11}, {"type": "text", "text": "433 Now by construction of the $P_{t}$ and because of Lemma 1 it follows that for all $i$ $\\!\\;,\\mathbb{E}[X_{K}^{(i)}|F_{K-1}^{(i)}]\\leq\\phi_{d}$ .   \n434 Repeating the same reasoning for each term of the sum yields: ", "page_idx": 11}, {"type": "equation", "text": "$$\n\\mathbb{P}\\left(\\frac{1}{K}\\sum_{t=1}^{K}X_{t}^{(i)}\\geq u\\right)\\leq e^{\\frac{\\lambda^{2}}{2K}}e^{\\lambda\\phi_{d}}e^{-\\lambda u}.\n$$", "text_format": "latex", "page_idx": 11}, {"type": "text", "text": "Optimzing with $\\lambda=K(u-\\phi_{d})$ and taking \u03b4 = e\u2212 $\\delta=e^{-\\frac{K(u-\\phi)^{2}}{2}}$ it finally holds for any $\\delta\\,>\\,0$ , with probability $\\textstyle1-{\\frac{\\delta}{d}}$ : ", "page_idx": 11}, {"type": "equation", "text": "$$\n\\frac{1}{K}\\sum_{t=1}^{K}X_{t}^{(i)}\\leq\\phi_{d}+\\sqrt{\\frac{2\\log\\left(\\frac{d}{\\delta}\\right)}{K}}\\,.\n$$", "text_format": "latex", "page_idx": 11}, {"type": "text", "text": "435 Thus applying a union bound we have with probability $1-\\delta$ : ", "page_idx": 12}, {"type": "equation", "text": "$$\nM_{n}\\leq\\phi_{d}+\\sqrt{\\frac{2\\log\\left(\\frac{d}{\\delta}\\right)}{K}}\\,,\n$$", "text_format": "latex", "page_idx": 12}, {"type": "text", "text": "436 which concludes the proof. ", "page_idx": 12}, {"type": "text", "text": "437 A.3 Proof of Proposition 2 ", "text_level": 1, "page_idx": 12}, {"type": "text", "text": "438 Suppose without loss of generality that $d$ is even and define $d^{\\prime}=d/2$ . For the proof, let ${\\overline{{Z}}}_{n}^{\\prime}$ be a   \n439 semi-infinite sequence drawn independently from the same process as ${\\overline{{Z}}}_{n}$ . Then, we have ", "page_idx": 12}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\tilde{\\mathcal{L}}(w)=\\underset{n\\to\\infty}{\\operatorname*{lim}}\\mathbb{E}[\\ell(w,Z_{t}^{\\prime},Z_{t-1}^{\\prime},...,Z_{t-n}^{\\prime})]}\\\\ &{\\qquad\\le\\mathbb{E}[\\ell(w,Z_{t}^{\\prime},Z_{t-1}^{\\prime},\\ldots,Z_{t-d^{\\prime}}^{\\prime})]+B_{d^{\\prime}}}\\\\ &{\\qquad\\le\\mathbb{E}\\left[\\ell(w,Z_{t},Z_{t-1},\\ldots,Z_{t-d^{\\prime}})\\big|\\,\\mathcal{F}_{t-2d^{\\prime}}\\right]+B_{d^{\\prime}}+\\beta_{d^{\\prime}}}\\\\ &{\\qquad\\le\\mathbb{E}\\left[\\ell(w,Z_{t},Z_{t-1},\\ldots,Z_{t-d^{\\prime}},\\ldots,Z_{1})\\big|\\,\\mathcal{F}_{t-2d^{\\prime}}\\right]+2B_{d^{\\prime}}+\\beta_{d^{\\prime}}}\\\\ &{\\qquad\\le\\mathbb{E}\\left[\\ell(w,Z_{t},Z_{t-1},\\ldots,Z_{1})\\big|\\,\\mathcal{F}_{t-2d^{\\prime}}\\right]+2B_{d^{\\prime}}+\\beta_{d^{\\prime}}\\,,}\\end{array}\n$$", "text_format": "latex", "page_idx": 12}, {"type": "text", "text": "440 where we used Assumption 3 in the first inequality, Assumption 4 in the second one, and Assumption 3   \n441 again in the last step. This proves the statement. \u53e3 ", "page_idx": 12}, {"type": "text", "text": "442 B Online Learning Tools and Results ", "text_level": 1, "page_idx": 12}, {"type": "text", "text": "443 B.1 Regret Bound for EWA ", "text_level": 1, "page_idx": 12}, {"type": "text", "text": "444 Recalling EWA updates we have: ", "page_idx": 12}, {"type": "equation", "text": "$$\nP_{t+1}=\\underset{P\\in\\Delta_{\\mathcal{W}}}{\\arg\\operatorname*{min}}\\left\\{\\langle P,c_{t}\\rangle+\\frac{1}{\\eta}\\mathcal{D}_{K L}(P||P_{t})\\right\\},\n$$", "text_format": "latex", "page_idx": 12}, {"type": "text", "text": "445 where $\\eta>0$ is a learning-rate parameter. The minimizer can be shown to exist and satisfies: ", "page_idx": 12}, {"type": "equation", "text": "$$\n\\frac{\\mathrm{d}P_{t+1}}{\\mathrm{d}P_{t}}(w)=\\frac{e^{-\\eta c_{t}(w)}}{\\int_{\\mathcal{W}}e^{-\\eta c_{t}(w^{\\prime})}\\mathrm{d}P_{t}(w^{\\prime})},\n$$", "text_format": "latex", "page_idx": 12}, {"type": "text", "text": "446 and the following result holds. ", "page_idx": 12}, {"type": "text", "text": "447 Proposition 3. For any prior $P_{1}\\ \\in\\ \\Delta_{\\mathcal{W}}$ and any comparator $P^{*}~\\in~\\Delta_{\\mathcal{W}}$ the regret of EWA   \n448 simultaneously satisfies for $\\eta>0$ : ", "page_idx": 12}, {"type": "equation", "text": "$$\n\\mathrm{Regret}(P^{*})\\leq\\frac{\\mathcal{D}_{K L}(P^{*}||P_{1})}{\\eta}+\\frac{\\eta}{2}\\sum_{t=1}^{n}||c_{t}||_{\\infty}^{2}.\n$$", "text_format": "latex", "page_idx": 12}, {"type": "text", "text": "449 We refer the reader to Appendix A.1 of Lugosi and Neu (2023) for a complete proof of the result   \n450 above. ", "page_idx": 12}, {"type": "text", "text": "451 B.2 Regret Bound for FTRL ", "text_level": 1, "page_idx": 12}, {"type": "text", "text": "452 We say that $h$ is $\\alpha-$ strongly convex if the following inequality is satisfied for all $P,P^{\\prime}\\in\\Delta_{\\mathcal{W}}$ and all   \n453 $\\lambda\\in[0,1]$ : ", "page_idx": 12}, {"type": "equation", "text": "$$\nh(\\lambda P+(1-\\lambda)P^{\\prime})\\leq\\lambda h(P)+(1-\\lambda)h(P^{\\prime})-\\frac{\\alpha\\lambda(1-\\lambda)}{2}\\|P-P^{\\prime}\\|^{2}.\n$$", "text_format": "latex", "page_idx": 12}, {"type": "text", "text": "454 Recalling the FTRL updates: ", "page_idx": 12}, {"type": "equation", "text": "$$\nP_{t+1}=\\underset{P\\in\\Delta_{w}}{\\arg\\operatorname*{min}}\\left\\{\\sum_{s=1}^{t}\\langle P,c_{s}\\rangle+\\frac{1}{\\eta}h(P)\\right\\},\n$$", "text_format": "latex", "page_idx": 12}, {"type": "text", "text": "455 the following results holds. ", "page_idx": 12}, {"type": "text", "text": "456 Proposition 4. For any prior $P_{1}\\ \\in\\ \\Delta_{\\mathcal{W}}$ and any comparator $P^{*}~\\in~\\Delta_{\\mathcal{W}}$ the regret of FTRL   \n457 simultaneously satisfies for $\\eta>0$ : ", "page_idx": 13}, {"type": "equation", "text": "$$\n\\mathrm{Regret}_{n}(P^{*})\\leq\\frac{h(P^{*})-h(P_{1})}{\\eta}+\\frac{\\eta}{2\\alpha}\\sum_{t=1}^{n}||c_{t}||_{*}^{2}.\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "458 We refer the reader to Appendix A.3 of Lugosi and Neu (2023) for a complete proof of the results   \n459 above. ", "page_idx": 13}, {"type": "text", "text": "460 B.3 Details about the reduction of Weinberger and Ordentlich (2002) ", "text_level": 1, "page_idx": 13}, {"type": "text", "text": "461 For concretenes we formally present how to turn any online learning algorithm into its delayed version.   \n462 For sake of convenience, assume $n=K d$ . We denote $\\tilde{c}_{t}^{(i)}=c_{i+d(t-1)}$ (for instance $\\tilde{c}_{1}^{(1)}=c_{1}$ is the   \n463 cost revealed at time $d+1,$ . Then we create $d$ instances of horizon time $K$ of the online learning as   \n464 follows, for $i=1,\\ldots,d$ : ", "page_idx": 13}, {"type": "text", "text": "465 ", "page_idx": 13}, {"type": "text", "text": "466 ", "page_idx": 13}, {"type": "text", "text": "\u2022 We initialize $\\tilde{P}_{1}^{(i)}=P_{0}$ , \u2022 for each block $i$ of length $K$ we update for $t=1,\\ldots,K$ : ", "page_idx": 13}, {"type": "equation", "text": "$$\n\\tilde{P}_{t+1}^{(i)}=\\mathrm{OL}_{\\mathrm{update}}\\left((\\tilde{c}_{s}^{(i)})_{s=1}^{t}\\right).\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "467 Here $\\mathrm{OL_{update}}$ refers to the update function of the online learning algorithm we consider which can   \n468 possibly depend of the whole history of cost functions (e.g., in the case of the FTRL update).   \n470 The checklist is designed to encourage best practices for responsible machine learning research,   \n471 addressing issues of reproducibility, transparency, research ethics, and societal impact. Do not remove   \n472 the checklist: The papers not including the checklist will be desk rejected. The checklist should   \n473 follow the references and follow the (optional) supplemental material. The checklist does NOT count   \n474 towards the page limit.   \n475 Please read the checklist guidelines carefully for information on how to answer these questions. For   \n476 each question in the checklist: ", "page_idx": 13}, {"type": "text", "text": "", "page_idx": 14}, {"type": "text", "text": "", "page_idx": 14}, {"type": "text", "text": "", "page_idx": 14}, {"type": "text", "text": "477 \u2022 You should answer [Yes] , [No] , or [NA] .   \n478 \u2022 [NA] means either that the question is Not Applicable for that particular paper or the   \n479 relevant information is Not Available.   \n480 \u2022 Please provide a short (1\u20132 sentence) justification right after your answer (even for NA).   \n481 The checklist answers are an integral part of your paper submission. They are visible to the   \n482 reviewers, area chairs, senior area chairs, and ethics reviewers. You will be asked to also include it   \n483 (after eventual revisions) with the final version of your paper, and its final version will be published   \n484 with the paper.   \n485 The reviewers of your paper will be asked to use the checklist as one of the factors in their evaluation.   \n486 While \"[Yes] \" is generally preferable to \"[No] \", it is perfectly acceptable to answer \"[No] \" provided a   \n487 proper justification is given (e.g., \"error bars are not reported because it would be too computationally   \n488 expensive\" or \"we were unable to find the license for the dataset we used\"). In general, answering   \n489 \"[No] \" or \"[NA] \" is not grounds for rejection. While the questions are phrased in a binary way, we   \n490 acknowledge that the true answer is often more nuanced, so please just use your best judgment and   \n491 write a justification to elaborate. All supporting evidence can appear either in the main paper or the   \n492 supplemental material, provided in appendix. If you answer [Yes] to a question, in the justification   \n493 please point to the section(s) where related material for the question can be found.   \n495 Question: Do the main claims made in the abstract and introduction accurately reflect the   \n496 paper\u2019s contributions and scope?   \n497 Answer: [Yes]   \n498 Justification: We claim that we present a new framework adapted from Lugosi and Neu,   \n499 2023 to prove generalization bounds in non-i.i.d setting. We present it in Section 3and we   \n500 provide PAC-Bayesian bounds in Section 4.   \n501 Guidelines:   \n502 \u2022 The answer NA means that the abstract and introduction do not include the claims   \n503 made in the paper.   \n504 \u2022 The abstract and/or introduction should clearly state the claims made, including the   \n505 contributions made in the paper and important assumptions and limitations. A No or   \n506 NA answer to this question will not be perceived well by the reviewers.   \n507 \u2022 The claims made should match theoretical and experimental results, and reflect how   \n508 much the results can be expected to generalize to other settings.   \n509 \u2022 It is fine to include aspirational goals as motivation as long as it is clear that these goals   \n510 are not attained by the paper.   \n511 2. Limitations   \n512 Question: Does the paper discuss the limitations of the work performed by the authors?   \n513 Answer: [Yes]   \n514 Justification:   \n515 Guidelines:   \n516 \u2022 The answer NA means that the paper has no limitation while the answer No means that   \nthe paper has limitations, but those are not discussed in the paper.   \n518 \u2022 The authors are encouraged to create a separate \"Limitations\" section in their paper.   \n519 \u2022 The paper should point out any strong assumptions and how robust the results are to   \n520 violations of these assumptions (e.g., independence assumptions, noiseless settings,   \n521 model well-specification, asymptotic approximations only holding locally). The authors   \n522 should reflect on how these assumptions might be violated in practice and what the   \n523 implications would be.   \n524 \u2022 The authors should reflect on the scope of the claims made, e.g., if the approach was   \n525 only tested on a few datasets or with a few runs. In general, empirical results often   \n526 depend on implicit assumptions, which should be articulated.   \n527 \u2022 The authors should reflect on the factors that influence the performance of the approach.   \n528 For example, a facial recognition algorithm may perform poorly when image resolution   \n529 is low or images are taken in low lighting. Or a speech-to-text system might not be   \n530 used reliably to provide closed captions for online lectures because it fails to handle   \n531 technical jargon.   \n532 \u2022 The authors should discuss the computational efficiency of the proposed algorithms   \n533 and how they scale with dataset size.   \n534 \u2022 If applicable, the authors should discuss possible limitations of their approach to   \n535 address problems of privacy and fairness.   \n536 \u2022 While the authors might fear that complete honesty about limitations might be used by   \n537 reviewers as grounds for rejection, a worse outcome might be that reviewers discover   \n538 limitations that aren\u2019t acknowledged in the paper. The authors should use their best   \n539 judgment and recognize that individual actions in favor of transparency play an impor  \n540 tant role in developing norms that preserve the integrity of the community. Reviewers   \n541 will be specifically instructed to not penalize honesty concerning limitations.   \n542 3. Theory Assumptions and Proofs   \n543 Question: For each theoretical result, does the paper provide the full set of assumptions and   \n544 a complete (and correct) proof?   \n545 Answer: [Yes]   \n546 Justification: The main result of the paper lies in Section 3.2 and is carefully explained.   \n547 Regarding Section 4 where most of the results are presented we give all the technical results   \n548 and references in the AppendixB.   \n549 Guidelines:   \n550 \u2022 The answer NA means that the paper does not include theoretical results.   \n551 \u2022 All the theorems, formulas, and proofs in the paper should be numbered and cross  \n552 referenced.   \n553 \u2022 All assumptions should be clearly stated or referenced in the statement of any theorems.   \n554 \u2022 The proofs can either appear in the main paper or the supplemental material, but if   \n555 they appear in the supplemental material, the authors are encouraged to provide a short   \n556 proof sketch to provide intuition.   \n557 \u2022 Inversely, any informal proof provided in the core of the paper should be complemented   \n558 by formal proofs provided in appendix or supplemental material.   \n559 \u2022 Theorems and Lemmas that the proof relies upon should be properly referenced.   \n560 4. Experimental Result Reproducibility   \n561 Question: Does the paper fully disclose all the information needed to reproduce the main ex  \n562 perimental results of the paper to the extent that it affects the main claims and/or conclusions   \n563 of the paper (regardless of whether the code and data are provided or not)?   \n564 Answer: [NA]   \n565 Justification: paper does not include experiments requiring code.   \n566 Guidelines:   \n567 \u2022 The answer NA means that the paper does not include experiments.   \n568 \u2022 If the paper includes experiments, a No answer to this question will not be perceived   \n569 well by the reviewers: Making the paper reproducible is important, regardless of   \n570 whether the code and data are provided or not.   \n571 \u2022 If the contribution is a dataset and/or model, the authors should describe the steps taken   \n572 to make their results reproducible or verifiable.   \n573 \u2022 Depending on the contribution, reproducibility can be accomplished in various ways.   \n574 For example, if the contribution is a novel architecture, describing the architecture fully   \n575 might suffice, or if the contribution is a specific model and empirical evaluation, it may   \n576 be necessary to either make it possible for others to replicate the model with the same   \n577 dataset, or provide access to the model. In general. releasing code and data is often   \n578 one good way to accomplish this, but reproducibility can also be provided via detailed   \n579 instructions for how to replicate the results, access to a hosted model (e.g., in the case   \n580 of a large language model), releasing of a model checkpoint, or other means that are   \n581 appropriate to the research performed.   \n582 \u2022 While NeurIPS does not require releasing code, the conference does require all submis  \n583 sions to provide some reasonable avenue for reproducibility, which may depend on the   \n584 nature of the contribution. For example   \n585 (a) If the contribution is primarily a new algorithm, the paper should make it clear how   \n586 to reproduce that algorithm.   \n587 (b) If the contribution is primarily a new model architecture, the paper should describe   \n588 the architecture clearly and fully.   \n589 (c) If the contribution is a new model (e.g., a large language model), then there should   \n590 either be a way to access this model for reproducing the results or a way to reproduce   \n591 the model (e.g., with an open-source dataset or instructions for how to construct   \n592 the dataset).   \n593 (d) We recognize that reproducibility may be tricky in some cases, in which case   \n594 authors are welcome to describe the particular way they provide for reproducibility.   \n595 In the case of closed-source models, it may be that access to the model is limited in   \n596 some way (e.g., to registered users), but it should be possible for other researchers   \n597 to have some path to reproducing or verifying the results.   \n598 5. Open access to data and code   \n599 Question: Does the paper provide open access to the data and code, with sufficient instruc  \n600 tions to faithfully reproduce the main experimental results, as described in supplemental   \n601 material?   \n602 Answer: [NA]   \n603 Justification: The paper does not include experiments requiring code.   \n604 Guidelines:   \n605 \u2022 The answer NA means that paper does not include experiments requiring code.   \n606 \u2022 Please see the NeurIPS code and data submission guidelines (https://nips.cc/   \n607 public/guides/CodeSubmissionPolicy) for more details.   \n608 \u2022 While we encourage the release of code and data, we understand that this might not be   \n609 possible, so \u201cNo\u201d is an acceptable answer. Papers cannot be rejected simply for not   \n610 including code, unless this is central to the contribution (e.g., for a new open-source   \n611 benchmark).   \n612 \u2022 The instructions should contain the exact command and environment needed to run to   \n613 reproduce the results. See the NeurIPS code and data submission guidelines (https:   \n614 //nips.cc/public/guides/CodeSubmissionPolicy) for more details.   \n615 \u2022 The authors should provide instructions on data access and preparation, including how   \n616 to access the raw data, preprocessed data, intermediate data, and generated data, etc.   \n617 \u2022 The authors should provide scripts to reproduce all experimental results for the new   \n618 proposed method and baselines. If only a subset of experiments are reproducible, they   \n619 should state which ones are omitted from the script and why.   \n620 \u2022 At submission time, to preserve anonymity, the authors should release anonymized   \n621 versions (if applicable).   \n622 \u2022 Providing as much information as possible in supplemental material (appended to the   \n623 paper) is recommended, but including URLs to data and code is permitted. ", "page_idx": 14}, {"type": "text", "text": "", "page_idx": 14}, {"type": "text", "text": "", "page_idx": 14}, {"type": "text", "text": "", "page_idx": 14}, {"type": "text", "text": "", "page_idx": 15}, {"type": "text", "text": "", "page_idx": 16}, {"type": "text", "text": "624 6. Experimental Setting/Details ", "text_level": 1, "page_idx": 16}, {"type": "text", "text": "625 Question: Does the paper specify all the training and test details (e.g., data splits, hyper  \n626 parameters, how they were chosen, type of optimizer, etc.) necessary to understand the   \n627 results?   \n628 Answer: [NA]   \n629 Justification: The paper does not include experiments requiring code.   \n630 Guidelines:   \n631 \u2022 The answer NA means that the paper does not include experiments.   \n632 \u2022 The experimental setting should be presented in the core of the paper to a level of detail   \n633 that is necessary to appreciate the results and make sense of them.   \n634 \u2022 The full details can be provided either with the code, in appendix, or as supplemental   \n635 material.   \n636 7. Experiment Statistical Significance   \n637 Question: Does the paper report error bars suitably and correctly defined or other appropriate   \n638 information about the statistical significance of the experiments?   \n639 Answer: [NA]   \n640 Justification: The paper does not include experiments requiring code.   \n641 Guidelines:   \n642 \u2022 The answer NA means that the paper does not include experiments.   \n643 \u2022 The authors should answer \"Yes\" if the results are accompanied by error bars, confi  \n644 dence intervals, or statistical significance tests, at least for the experiments that support   \n645 the main claims of the paper.   \n646 \u2022 The factors of variability that the error bars are capturing should be clearly stated (for   \n647 example, train/test split, initialization, random drawing of some parameter, or overall   \n648 run with given experimental conditions).   \n649 \u2022 The method for calculating the error bars should be explained (closed form formula,   \n650 call to a library function, bootstrap, etc.)   \n651 \u2022 The assumptions made should be given (e.g., Normally distributed errors).   \n652 \u2022 It should be clear whether the error bar is the standard deviation or the standard error   \n653 of the mean.   \n654 \u2022 It is OK to report 1-sigma error bars, but one should state it. The authors should   \n655 preferably report a 2-sigma error bar than state that they have a $96\\%$ CI, if the hypothesis   \n656 of Normality of errors is not verified.   \n657 \u2022 For asymmetric distributions, the authors should be careful not to show in tables or   \n658 figures symmetric error bars that would yield results that are out of range (e.g. negative   \n659 error rates).   \n660 \u2022 If error bars are reported in tables or plots, The authors should explain in the text how   \n661 they were calculated and reference the corresponding figures or tables in the text.   \n662 8. Experiments Compute Resources   \n663 Question: For each experiment, does the paper provide sufficient information on the com  \n664 puter resources (type of compute workers, memory, time of execution) needed to reproduce   \n665 the experiments?   \n666 Answer: [NA]   \n667 Justification: The paper does not include experiments requiring code.   \n668 Guidelines:   \n669 \u2022 The answer NA means that the paper does not include experiments.   \n670 \u2022 The paper should indicate the type of compute workers CPU or GPU, internal cluster,   \n671 or cloud provider, including relevant memory and storage.   \n672 \u2022 The paper should provide the amount of compute required for each of the individual   \n673 experimental runs as well as estimate the total compute.   \n674 \u2022 The paper should disclose whether the full research project required more compute   \n675 than the experiments reported in the paper (e.g., preliminary or failed experiments that   \n676 didn\u2019t make it into the paper).   \n677 9. Code Of Ethics   \n678 Question: Does the research conducted in the paper conform, in every respect, with the   \n679 NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines?   \n680 Answer: [Yes]   \n681 Justification:   \n682 Guidelines:   \n683 \u2022 The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics.   \n684 \u2022 If the authors answer No, they should explain the special circumstances that require a   \n685 deviation from the Code of Ethics.   \n686 \u2022 The authors should make sure to preserve anonymity (e.g., if there is a special consid  \n687 eration due to laws or regulations in their jurisdiction).   \n688 10. Broader Impacts   \n689 Question: Does the paper discuss both potential positive societal impacts and negative   \n690 societal impacts of the work performed?   \n691 Answer: [NA]   \n692 Justification: The contribution is mainly theoretical so we do not discuss these issues in the   \n693 paper.   \n694 Guidelines:   \n695 \u2022 The answer NA means that there is no societal impact of the work performed.   \n696 \u2022 If the authors answer NA or No, they should explain why their work has no societal   \n697 impact or why the paper does not address societal impact.   \n698 \u2022 Examples of negative societal impacts include potential malicious or unintended uses   \n699 (e.g., disinformation, generating fake profiles, surveillance), fairness considerations   \n700 (e.g., deployment of technologies that could make decisions that unfairly impact specific   \n701 groups), privacy considerations, and security considerations.   \n702 \u2022 The conference expects that many papers will be foundational research and not tied   \n703 to particular applications, let alone deployments. However, if there is a direct path to   \n704 any negative applications, the authors should point it out. For example, it is legitimate   \n705 to point out that an improvement in the quality of generative models could be used to   \n706 generate deepfakes for disinformation. On the other hand, it is not needed to point out   \n707 that a generic algorithm for optimizing neural networks could enable people to train   \n708 models that generate Deepfakes faster.   \n709 \u2022 The authors should consider possible harms that could arise when the technology is   \n710 being used as intended and functioning correctly, harms that could arise when the   \n711 technology is being used as intended but gives incorrect results, and harms following   \n712 from (intentional or unintentional) misuse of the technology.   \n713 \u2022 If there are negative societal impacts, the authors could also discuss possible mitigation   \n714 strategies (e.g., gated release of models, providing defenses in addition to attacks,   \n715 mechanisms for monitoring misuse, mechanisms to monitor how a system learns from   \n716 feedback over time, improving the efficiency and accessibility of ML).   \n717 11. Safeguards   \n718 Question: Does the paper describe safeguards that have been put in place for responsible   \n719 release of data or models that have a high risk for misuse (e.g., pretrained language models,   \n720 image generators, or scraped datasets)?   \n721 Answer: [NA]   \n722 Justification: The paper poses no such risks.   \n723 Guidelines:   \n724 \u2022 The answer NA means that the paper poses no such risks.   \n725 \u2022 Released models that have a high risk for misuse or dual-use should be released with   \n726 necessary safeguards to allow for controlled use of the model, for example by requiring   \n727 that users adhere to usage guidelines or restrictions to access the model or implementing   \n728 safety filters.   \n729 \u2022 Datasets that have been scraped from the Internet could pose safety risks. The authors   \n730 should describe how they avoided releasing unsafe images.   \n731 \u2022 We recognize that providing effective safeguards is challenging, and many papers do   \n732 not require this, but we encourage authors to take this into account and make a best   \n733 faith effort.   \n734 12. Licenses for existing assets   \n735 Question: Are the creators or original owners of assets (e.g., code, data, models), used in   \n736 the paper, properly credited and are the license and terms of use explicitly mentioned and   \n737 properly respected?   \n738 Answer: [NA]   \n739 Justification: We do not use existing assets.   \n740 Guidelines:   \n741 \u2022 The answer NA means that the paper does not use existing assets.   \n742 \u2022 The authors should cite the original paper that produced the code package or dataset.   \n743 \u2022 The authors should state which version of the asset is used and, if possible, include a   \n744 URL.   \n745 \u2022 The name of the license (e.g., CC-BY 4.0) should be included for each asset.   \n746 \u2022 For scraped data from a particular source (e.g., website), the copyright and terms of   \n747 service of that source should be provided.   \n748 \u2022 If assets are released, the license, copyright information, and terms of use in the   \n749 package should be provided. For popular datasets, paperswithcode.com/datasets   \n750 has curated licenses for some datasets. Their licensing guide can help determine the   \n751 license of a dataset.   \n752 \u2022 For existing datasets that are re-packaged, both the original license and the license of   \n753 the derived asset (if it has changed) should be provided.   \n754 \u2022 If this information is not available online, the authors are encouraged to reach out to   \n755 the asset\u2019s creators.   \n756 13. New Assets   \n757 Question: Are new assets introduced in the paper well documented and is the documentation   \n758 provided alongside the assets?   \n759 Answer: [NA]   \n760 Justification: The paper does not release new assets.   \n761 Guidelines:   \n762 \u2022 The answer NA means that the paper does not release new assets.   \n763 \u2022 Researchers should communicate the details of the dataset/code/model as part of their   \n764 submissions via structured templates. This includes details about training, license,   \n765 limitations, etc.   \n766 \u2022 The paper should discuss whether and how consent was obtained from people whose   \n767 asset is used.   \n768 \u2022 At submission time, remember to anonymize your assets (if applicable). You can either   \n769 create an anonymized URL or include an anonymized zip file.   \n770 14. Crowdsourcing and Research with Human Subjects   \n771 Question: For crowdsourcing experiments and research with human subjects, does the paper   \n772 include the full text of instructions given to participants and screenshots, if applicable, as   \n773 well as details about compensation (if any)?   \n774 Answer: [NA]   \n775 Justification: the paper does not involve crowdsourcing nor research with human subjects   \n776 Guidelines:   \n777 \u2022 The answer NA means that the paper does not involve crowdsourcing nor research with   \n778 human subjects.   \n779   \n780   \n781   \n782   \n783   \n784   \n785   \n786   \n787   \n788   \n789   \n790   \n791   \n792   \n793   \n794   \n795   \n796   \n797   \n798   \n799   \n800   \n801   \n802   \n803 ", "page_idx": 17}, {"type": "text", "text": "", "page_idx": 18}, {"type": "text", "text": "", "page_idx": 19}, {"type": "text", "text": "", "page_idx": 20}, {"type": "text", "text": "\u2022 Including this information in the supplemental material is fine, but if the main contribution of the paper involves human subjects, then as much detail as possible should be included in the main paper. \u2022 According to the NeurIPS Code of Ethics, workers involved in data collection, curation, or other labor should be paid at least the minimum wage in the country of the data collector. 15. Institutional Review Board (IRB) Approvals or Equivalent for Research with Human Subjects Question: Does the paper describe potential risks incurred by study participants, whether such risks were disclosed to the subjects, and whether Institutional Review Board (IRB) approvals (or an equivalent approval/review based on the requirements of your country or institution) were obtained? Answer: [NA] Justification: the paper does not involve crowdsourcing nor research with human subjects. Guidelines: \u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects. \u2022 Depending on the country in which research is conducted, IRB approval (or equivalent) may be required for any human subjects research. If you obtained IRB approval, you should clearly state this in the paper. \u2022 We recognize that the procedures for this may vary significantly between institutions and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the guidelines for their institution. \u2022 For initial submissions, do not include any information that would break anonymity (if applicable), such as the institution conducting the review. ", "page_idx": 20}]