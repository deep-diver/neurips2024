[{"figure_path": "TKozKEMKiw/figures/figures_4_1.jpg", "caption": "Figure 1: Comparison of DPDT algorithm on the Iris dataset in terms of the number of states in the MDP when using different tests generating functions. \"TOP B\" are tests function returning the B most informative splits for each state. \"Exhaustive\" returns all possible states (equivalent to the search space of Quant-BnB). DPDT-Dcart are the tests functions that make calls to the CART algorithm.", "description": "The figure compares the performance of the DPDT algorithm on the Iris dataset using different test generating functions.  It plots the accuracy achieved against the number of states in the Markov Decision Process (MDP) for each function. The test generating functions include: Exhaustive (exploring all possible tests), TOP B (selecting the top B most informative splits for each state), and DPDT-Dcart (making calls to the CART algorithm). The results show how different strategies for selecting tests affect the size of the MDP and, potentially, its overall computational cost and performance. ", "section": "5.1.1 Tests generating functions"}, {"figure_path": "TKozKEMKiw/figures/figures_7_1.jpg", "caption": "Figure 2: Performance gain of DTs over CART trees. Left, accuracy on unseen data gain of trees with depth \u2264 5 selected with procedure of Sec. 6.3. Right, average number of tests of those trees.", "description": "This figure demonstrates the performance improvements achieved by the proposed DPDT algorithm compared to CART. The left panel displays a histogram showing the frequency distribution of accuracy gains (on unseen data) for trees of depth less than or equal to 5, selected by the proposed method. The right panel displays a histogram showing the distribution of average test reductions produced by DPDT trees over CART.", "section": "6.3 Selecting the best tree for unseen data"}, {"figure_path": "TKozKEMKiw/figures/figures_8_1.jpg", "caption": "Figure 1: Comparison of DPDT algorithm on the Iris dataset in terms of the number of states in the MDP when using different tests generating functions. \u201cTOP B\u201d are tests function returning the B most informative splits for each state. \u201cExhaustive\u201d returns all possible states (equivalent to the search space of Quant-BnB). DPDT-Dcart are the tests functions that make calls to the CART algorithm.", "description": "This figure compares the performance of the DPDT algorithm on the Iris dataset using different test generation functions.  The x-axis represents the number of states in the Markov Decision Process (MDP) model used by DPDT. The y-axis represents the training accuracy. Different test generation strategies are compared: Exhaustive (evaluating all possible tests), TOP B (selecting the top B most informative tests), and DPDT-Dcart (using the CART algorithm to select tests). The figure shows the tradeoff between the size of the MDP and the accuracy obtained. It highlights that using more sophisticated tests can significantly reduce the size of the MDP without sacrificing much accuracy, improving the algorithm's scalability.", "section": "5.1.1 Tests generating functions"}, {"figure_path": "TKozKEMKiw/figures/figures_11_1.jpg", "caption": "Figure 1: Comparison of DPDT algorithm on the Iris dataset in terms of the number of states in the MDP when using different tests generating functions. \u201cTOP B\u201d are tests function returning the B most informative splits for each state. \u201cExhaustive\u201d returns all possible states (equivalent to the search space of Quant-BnB). DPDT-Dcart are the tests functions that make calls to the CART algorithm.", "description": "This figure compares the performance of the DPDT algorithm on the Iris dataset using different tests generating functions. The x-axis represents the number of MDP states, and the y-axis represents the training accuracy.  Different tests generating functions are compared: Exhaustive (evaluating all possible splits), TOP B (selecting the top B most informative splits), and DPDT-Dcart (using calls to the CART algorithm). The plot shows that using heuristics in the test generation function (TOP B and DPDT-Dcart) significantly reduces the number of MDP states required compared to the exhaustive search, while maintaining competitive accuracy.", "section": "5.1.1 Tests generating functions"}, {"figure_path": "TKozKEMKiw/figures/figures_11_2.jpg", "caption": "Figure 5: Trees for the fault dataset. Top: trees from DPDT. Bottom: trees from CART. A is accuracy, N the number of nodes, T the average number of tests.", "description": "This figure shows four decision trees generated for the 'fault' dataset using two different algorithms: DPDT (Dynamic Programming Decision Tree) and CART (Classification and Regression Trees). Each subfigure represents a different tree generated with varying parameters, resulting in trees with different depths and numbers of nodes.  The parameters and resulting metrics (accuracy A, number of nodes N, and average number of tests T) are indicated for each tree.  The top row shows trees generated using DPDT, and the bottom row shows trees from CART. The figure illustrates the trade-off between tree complexity and accuracy achievable using these two algorithms.", "section": "C Tree plots"}, {"figure_path": "TKozKEMKiw/figures/figures_12_1.jpg", "caption": "Figure 6: MDP for a training dataset made of three samples (illustrated with an oval and 2 diamonds), two continuous attributes (x and y), and two classes. The tests generating function generated three possible tests. There is an initial state (D, 0) (the training dataset at depth 0), and six non-terminal states (three tests times two children states). Rewards are either a or the misclassification, and transition probabilities are one, or the size of the child state over the size of the parent.", "description": "This figure shows a Markov Decision Process (MDP) representation of a decision tree learning problem.  The MDP has a training dataset with three samples, two continuous attributes (x and y), and two classes. The tests generating function produces three possible tests, leading to a tree structure. The initial state represents the entire training dataset at depth 0.  Each node in the MDP represents a state, where actions correspond to tests or class assignments.  The rewards in each state reflect either a reward (a) for making a test or the misclassification cost.  The transition probabilities depend on the data subset in each state after a test is made.", "section": "4 Decision Tree Learning as an MDP"}, {"figure_path": "TKozKEMKiw/figures/figures_12_2.jpg", "caption": "Figure 7: For \u03b1 = 0 and \u03b1 = 1, the values of Q*(s, a, \u03b1) are backpropagated from leaf states to the initial state and are given in squared brackets. The optimal policy \u03c0*(., \u03b1 = 1), in pink, is a depth-0 tree with accuracy 1. The optimal policy \u03c0*(., \u03b1 = 0), in green, is a depth-1 tree with accuracy 1.", "description": "This figure shows the backpropagation of the optimal Q-values for two different values of the regularization parameter (\u03b1 = 0 and \u03b1 = 1). The optimal policies (\u03c0*) corresponding to these values are visualized on the tree structure, highlighting the trade-off between accuracy and tree depth. When \u03b1 = 1 (pink), the optimal policy is a simple depth-0 tree with perfect accuracy. However, when \u03b1 = 0 (green), the optimal policy is a slightly deeper tree (depth 1) that also achieves perfect accuracy, indicating a potential complexity-accuracy trade-off controlled by the \u03b1 parameter.", "section": "5.2 Dynamic Programming"}, {"figure_path": "TKozKEMKiw/figures/figures_13_1.jpg", "caption": "Figure 6: MDP for a training dataset made of three samples (illustrated with an oval and 2 diamonds), two continuous attributes (x and y), and two classes. The tests generating function generated three possible tests. There is an initial state (D, 0) (the training dataset at depth 0), and six non-terminal states (three tests times two children states). Rewards are either a or the misclassification, and transition probabilities are one, or the size of the child state over the size of the parent.", "description": "This figure shows a Markov Decision Process (MDP) representation of a decision tree learning problem.  The MDP is built for a small dataset with 3 samples, two continuous attributes (x and y), and two classes. The states of the MDP are subsets of the dataset along with a depth. Actions are either tests (comparing an attribute to a threshold) or class assignments.  The figure depicts the states, actions, rewards (either \u03b1 or a misclassification penalty), and transition probabilities between states. This example illustrates how the decision tree learning problem is formulated as an MDP for solving.", "section": "4 Decision Tree Learning as an MDP"}, {"figure_path": "TKozKEMKiw/figures/figures_17_1.jpg", "caption": "Figure 8: Average number of tests-accuracies trade-offs of CART and DPDT-3 on classification training datasets. Both algorithms learn trees of depths at most 5. CART makes a trade-off with the minimal complexity post-pruning algorithm. DPDT-3 makes a trade-off by returning policies for 1000 different \u03b1.", "description": "This figure compares the performance of CART and DPDT-3 in terms of the average number of tests required to achieve a certain accuracy on 16 classification datasets.  CART uses post-pruning to control complexity, while DPDT-3 explores multiple complexity-accuracy trade-offs by using 1000 different values of \u03b1. The plots show that DPDT-3 generally outperforms CART in terms of accuracy for a given number of tests.", "section": "6.3 Selecting the best tree for unseen data"}, {"figure_path": "TKozKEMKiw/figures/figures_18_1.jpg", "caption": "Figure 1: Comparison of DPDT algorithm on the Iris dataset in terms of the number of states in the MDP when using different tests generating functions. \"TOP B\" are tests function returning the B most informative splits for each state. \"Exhaustive\" returns all possible states (equivalent to the search space of Quant-BnB). DPDT-Dcart are the tests functions that make calls to the CART algorithm.", "description": "This figure compares the performance of the DPDT algorithm on the Iris dataset using different tests generating functions.  The x-axis represents the number of states in the Markov Decision Process (MDP), and the y-axis represents the accuracy.  The different tests generating functions include: Exhaustive (evaluates all possible splits), TOP-5, TOP-10, TOP-55, and  DPDT-Dcart (uses the CART algorithm to select a subset of splits).  The figure shows how different tests generating functions affect the size and performance of the MDP, illustrating the trade-off between exploration and computational efficiency.", "section": "5.1.1 Tests generating functions"}]