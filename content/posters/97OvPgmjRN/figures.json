[{"figure_path": "97OvPgmjRN/figures/figures_2_1.jpg", "caption": "Figure 2: The AlphaGateau network, hs is the inner size of the feature vectors, and L is the number of residual blocks.", "description": "This figure shows the architecture of the AlphaGateau neural network.  It consists of two main branches, one for processing node features (representing squares on the chessboard) and another for processing edge features (representing moves). Node features are first processed through linear layers and then fed into a series of ResGATEAU (residual GATEAU) blocks. Similarly, edge features are processed through linear layers before being fed into the ResGATEAU blocks. The outputs of the ResGATEAU blocks are then used to predict the value (game outcome) and policy (move probabilities) of a given game state.", "section": "4 Proposed Models"}, {"figure_path": "97OvPgmjRN/figures/figures_4_1.jpg", "caption": "Figure 1: The starting positions of 8 \u00d7 8 and 5 \u00d7 5 chess games", "description": "This figure shows the initial setup of chessboards for both standard 8x8 chess and a smaller 5x5 variant.  The arrangement of pieces is the same in both, but scaled down in the 5x5 version. This highlights the similarity in game structure despite the difference in board size, which is relevant to the paper's exploration of generalizing chess models across different board sizes.", "section": "4 Proposed Models"}, {"figure_path": "97OvPgmjRN/figures/figures_5_1.jpg", "caption": "Figure 2: The AlphaGateau network, hs is the inner size of the feature vectors, and L is the number of residual blocks.", "description": "This figure shows the architecture of the AlphaGateau network.  It's a graph neural network that processes both node features (representing squares on the chessboard) and edge features (representing moves).  Node features are first passed through a linear layer, then multiple residual GATEAU layers (a modified GAT layer handling edge features) process both node and edge features. Finally, the processed node and edge features are fed into separate linear layers that predict the value (game outcome) and policy (move probabilities), respectively. The '\u00d7L' indicates that the residual GATEAU block is repeated L times, making the model deeper and more powerful.", "section": "4.4 AlphaGateau: A Full Model Architecture Based on AlphaZero and GATEAU"}, {"figure_path": "97OvPgmjRN/figures/figures_5_2.jpg", "caption": "Figure 3: Value head", "description": "This figure shows the architecture of the value head in the AlphaGateau model. The value head takes node features as input and uses batch normalization (BNR), linear layers, attention pooling, and a ReLU activation function to output a single value representing the game state's evaluation.", "section": "4.4 AlphaGateau: A Full Model Architecture Based on AlphaZero and GATEAU"}, {"figure_path": "97OvPgmjRN/figures/figures_7_1.jpg", "caption": "Figure 2: The AlphaGateau network, hs is the inner size of the feature vectors, and L is the number of residual blocks.", "description": "This figure shows the architecture of the AlphaGateau neural network.  The network processes both node features (representing squares on the chessboard) and edge features (representing moves). Node features are processed through a linear layer and then multiple residual GATEAU blocks (a novel GNN layer incorporating edge features) before being passed to the value head.  Edge features also go through a linear layer and the same residual GATEAU blocks before being passed to the policy head. The number of residual blocks, L, and the inner size of the feature vectors, hs, are hyperparameters.", "section": "4 Proposed Models"}, {"figure_path": "97OvPgmjRN/figures/figures_8_1.jpg", "caption": "Figure 5: The Elo ratings of AlphaZero and AlphaGateau with 5 residual layers trained over 500 iterations. The AlphaGateau model initially learns ~10 times faster than the AlphaZero model, and settles after 100 iterations to a comparable speed of growth to that of AlphaZero.", "description": "This figure shows the Elo ratings of two chess-playing models, AlphaZero and AlphaGateau, over 500 training iterations. AlphaGateau demonstrates significantly faster initial learning, achieving a comparable learning rate to AlphaZero after approximately 100 iterations.", "section": "5 Experiments"}, {"figure_path": "97OvPgmjRN/figures/figures_8_2.jpg", "caption": "Figure 6: The Elo ratings of the first 100 iterations of the AlphaGateau model from Figure 5 was included for comparison. The initial training on 5\u00d75 chess is able to increase its rating while evaluated on 8 \u00d7 8 chess during training, even without seeing any 8 \u00d7 8 chess position. The fine-tuned model starts with a good baseline, and reaches comparable performances to the 5-layer model despite being undertrained for its size.", "description": "This figure compares the Elo ratings over the first 100 iterations for three different models: a 10-layer AlphaGateau model fine-tuned on an 8x8 chessboard after initial training on a 5x5 board, a 5-layer AlphaGateau model trained directly on an 8x8 board, and a 10-layer AlphaGateau model trained only on a 5x5 board.  The plot demonstrates AlphaGateau's ability to generalize from a smaller board size (5x5) to a larger one (8x8), even without explicit training on the larger board. The fine-tuned model shows a rapid increase in Elo rating upon transfer to the 8x8 board, exceeding the performance of the 5-layer model trained directly on 8x8.", "section": "5 Experiments"}, {"figure_path": "97OvPgmjRN/figures/figures_8_3.jpg", "caption": "Figure 7: The two models with a frame window of size 131 072 only kept the latest generated games in the frame window. The model keeping no frame window and generating 256 games was trained in only 39 hours, but had the worst performance. Adding a 1M frame window improved the performance a little and lasted 60 hours, while increasing the number of self-play games to 1024 performed the best, but took 198 hours.", "description": "This figure shows the impact of frame window size and the number of self-play games on model performance and training time.  Using only the most recently generated games (131k window) resulted in the worst performance and fastest training time.  Increasing the frame window size to 1M improved performance but still resulted in relatively fast training.  Generating 1024 games per iteration with a 524k window resulted in the best performance but took significantly longer to train.", "section": "5.4 Impact of the Frame Window and the Number of Self-play Games"}, {"figure_path": "97OvPgmjRN/figures/figures_12_1.jpg", "caption": "Figure 8: The difference between BayesElo ratings and the Elo ratings according to our method. We removed to each Elo the average Elo of all players in its respective method, such that the average effective Elo for both BayesElo and our method is 0", "description": "This figure shows the difference between the Elo ratings calculated using the authors' custom method and the BayesElo method.  The y-axis represents the difference in Elo ratings (custom - BayesElo), and the x-axis represents the Elo rating calculated by the authors' custom method.  Each point represents a player's Elo rating. The plot reveals that weaker models (lower Elo) tend to be slightly over-rated by the authors' custom method compared to BayesElo, while stronger models (higher Elo) are slightly under-rated.  The trend suggests that while the two methods show similar rankings, there is a systematic difference.  The authors hypothesize this difference might arise from their use of a Jeffreys prior in their method, affecting the estimation of Elo differences.", "section": "A.3 Comparison with BayesElo"}, {"figure_path": "97OvPgmjRN/figures/figures_12_2.jpg", "caption": "Figure 5: The Elo ratings of AlphaZero and AlphaGateau with 5 residual layers trained over 500 iterations. The AlphaGateau model initially learns ~10 times faster than the AlphaZero model, and settles after 100 iterations to a comparable speed of growth to that of AlphaZero.", "description": "This figure shows the Elo ratings of two chess-playing agents, AlphaZero and AlphaGateau, over 500 training iterations. AlphaGateau, with a simpler architecture, demonstrates significantly faster initial learning, achieving a similar learning rate to AlphaZero after approximately 100 iterations.", "section": "5 Experiments"}, {"figure_path": "97OvPgmjRN/figures/figures_12_3.jpg", "caption": "Figure 5: The Elo ratings of AlphaZero and AlphaGateau with 5 residual layers trained over 500 iterations. The AlphaGateau model initially learns ~10 times faster than the AlphaZero model, and settles after 100 iterations to a comparable speed of growth to that of AlphaZero.", "description": "This figure shows the Elo ratings of two chess-playing models, AlphaZero and AlphaGateau, over 500 training iterations. AlphaGateau demonstrates significantly faster initial learning, achieving a comparable learning rate to AlphaZero after 100 iterations.", "section": "5 Experiments"}, {"figure_path": "97OvPgmjRN/figures/figures_13_1.jpg", "caption": "Figure 6: The Elo ratings of the first 100 iterations of the AlphaGateau model from Figure 5 was included for comparison. The initial training on 5\u00d75 chess is able to increase its rating while evaluated on 8 \u00d7 8 chess during training, even without seeing any 8 \u00d7 8 chess position. The fine-tuned model starts with a good baseline, and reaches comparable performances to the 5-layer model despite being undertrained for its size.", "description": "This figure compares the Elo ratings (a measure of skill in chess) of three different AlphaGateau models over 100 training iterations.  One model was trained from scratch on 8x8 chess (standard size), another was initially trained on a smaller 5x5 chessboard and then fine-tuned on 8x8 chess, and the third was a smaller 5-layer model trained only on 8x8 chess. The graph shows that the model pretrained on 5x5 chess exhibits strong generalization, achieving a high Elo rating after fine-tuning, while the 5-layer model serves as a baseline.", "section": "5 Experiments"}, {"figure_path": "97OvPgmjRN/figures/figures_13_2.jpg", "caption": "Figure 12: Using running time instead of iteration for Figure 5. Training the deeped model takes roughly 40 hours longer, for a similar amount of generated games and training steps.", "description": "This figure compares the Elo ratings of three different AlphaGateau models over time, using training time in hours instead of iterations as in Figure 5.  It shows that while the 5-layer AlphaGateau model and the 10-layer model trained on 5x5 chess achieve similar Elo ratings relatively quickly, the 10-layer model fine-tuned from 5x5 to 8x8 chess shows a longer training time but ultimately reaches higher Elo ratings.  The additional training time for the deeper model highlights the trade-off between model complexity and training speed.", "section": "5 Experiments"}, {"figure_path": "97OvPgmjRN/figures/figures_13_3.jpg", "caption": "Figure 7: The two models with a frame window of size 131 072 only kept the latest generated games in the frame window. The model keeping no frame window and generating 256 games was trained in only 39 hours, but had the worst performance. Adding a 1M frame window improved the performance a little and lasted 60 hours, while increasing the number of self-play games to 1024 performed the best, but took 198 hours.", "description": "This figure compares the performance of three AlphaGateau models trained with different frame window sizes and numbers of self-play games. The results show that using a larger frame window and a greater number of self-play games improves performance, although it significantly increases training time. The model with a 1M frame window and 256 games per iteration took 60 hours to train, showing modest improvement over the model with no frame window, which took only 39 hours but performed worst.  The model with 1024 games and a 524k window, which was the best-performing model, required 198 hours of training.", "section": "5.4 Impact of the Frame Window and the Number of Self-play Games"}, {"figure_path": "97OvPgmjRN/figures/figures_13_4.jpg", "caption": "Figure 7: The two models with a frame window of size 131 072 only kept the latest generated games in the frame window. The model keeping no frame window and generating 256 games was trained in only 39 hours, but had the worst performance. Adding a 1M frame window improved the performance a little and lasted 60 hours, while increasing the number of self-play games to 1024 performed the best, but took 198 hours.", "description": "This figure compares the performance of three AlphaGateau models trained with different frame window sizes and numbers of self-play games. The model using only the latest generated games (131k window) performed the worst, while the model using a larger frame window (1M) and more games showed improvement. The best performance was achieved using a larger frame window (524k) and even more games (1024), although at the cost of significantly increased training time.", "section": "5.4 Impact of the Frame Window and the Number of Self-play Games"}]