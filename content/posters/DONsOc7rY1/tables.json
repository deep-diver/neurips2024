[{"figure_path": "DONsOc7rY1/tables/tables_2_1.jpg", "caption": "Table 1: Properties of Various Methods: \u201cAttn\u201d indicates the use of the attention mechanism, \u201cV\u201d signifies the explicit utilization of information from V, and \u2018Large-scale\u2019 denotes the capability of the methods to generalize effortlessly to large-scale settings.", "description": "This table compares different methods for set encoding and subset selection.  It shows whether each method uses an attention mechanism, explicitly uses information from the entire input set V, and is capable of handling large-scale datasets.  The table highlights the differences in approach and capabilities of each method, making it easy to see the relative advantages of HORSE.", "section": "Related Work"}, {"figure_path": "DONsOc7rY1/tables/tables_6_1.jpg", "caption": "Table 2: Product recommendation results for 12 different product categories. The best results are indicated in bold black, while the second-best results are highlighted in blue. Due to space limitation, we use Set-T to denote Set Transformer.", "description": "This table presents the performance of different models on a product recommendation task across 12 different product categories.  The performance is measured using a metric (not specified in this excerpt).  The best and second-best results for each category are highlighted.  Set Transformer is abbreviated as \"Set-T\" due to space constraints.", "section": "5 Experiments"}, {"figure_path": "DONsOc7rY1/tables/tables_6_2.jpg", "caption": "Table 3: Performance results on the Two-Moons and Gaussian-Mixture datasets. Bolded numbers denote the best performance on each dataset", "description": "This table presents the performance of different methods (Random, PGM, DeepSet, Set Transformer, EquiVSet, INSET, and HORSE) on two synthetic datasets: Two-Moons and Gaussian Mixture.  The Mean Jaccard Coefficient (MJC) is used as the evaluation metric, representing the similarity between the predicted and true subsets.  Higher MJC values indicate better performance.  The results show that HORSE achieves the highest MJC scores on both datasets, outperforming the other methods.", "section": "5 Experiments"}, {"figure_path": "DONsOc7rY1/tables/tables_7_1.jpg", "caption": "Table 4: Empirircal results of compound selection Tasks. Bolded numbers denote the best performance on each dataset. Due to space limitations, we use \"Set-T\" to denote Set Transformer.", "description": "This table presents the results of compound selection tasks using various methods, including HORSE and several baselines.  The best performing method for each dataset is shown in bold.  The table shows that HORSE significantly outperforms the baselines in most of the tasks, demonstrating its effectiveness in handling large scale compound selection problems.", "section": "5.3 Compound Selection in AI-aided Drug Discovery"}, {"figure_path": "DONsOc7rY1/tables/tables_16_1.jpg", "caption": "Table 2: Product recommendation results for 12 different product categories. The best results are indicated in bold black, while the second-best results are highlighted in blue. Due to space limitation, we use Set-T to denote Set Transformer.", "description": "This table presents the performance of different models on a product recommendation task across 12 different product categories.  The models' performance is measured using a metric (not explicitly defined in the excerpt).  The best and second-best results for each category are highlighted.  Set Transformer is abbreviated as \"Set-T\" due to space constraints.", "section": "5 Experiments"}, {"figure_path": "DONsOc7rY1/tables/tables_17_1.jpg", "caption": "Table 6: Empirical results of set anomaly detection Tasks. Bolded numbers denote the best performance. HORSE outperforms all the baselines on the four datasets.", "description": "This table presents the performance of the proposed HORSE model and several baseline models on four set anomaly detection tasks (Double MNIST, CelebA, F-MNIST, and CIFAR-10).  The performance metric used is not explicitly stated in the provided caption but can be inferred from the context of the paper.  The results show that HORSE consistently outperforms the baselines across all four datasets, demonstrating its effectiveness in set anomaly detection tasks.", "section": "5 Experiments"}, {"figure_path": "DONsOc7rY1/tables/tables_18_1.jpg", "caption": "Table 7: In the table, we report the performance of different sample numbers denoted by \"k\" and compare them against the best-performing baselines.", "description": "This table presents the results of an ablation study on the impact of the number of Monte Carlo samples (k) on the performance of the proposed HORSE model.  It compares the performance of HORSE with different values of k (2, 4, 6, 8, 10) against the best-performing baseline models for the 'Media' and 'Safety' product categories in a product recommendation task. The table shows that increasing k generally improves performance, but the effect diminishes beyond a certain point.", "section": "D.5 Ablation Study"}]