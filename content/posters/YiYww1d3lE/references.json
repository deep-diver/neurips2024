{"references": [{"fullname_first_author": "Alec Radford", "paper_title": "Learning transferable visual models from natural language supervision", "publication_date": "2021-00-00", "reason": "This paper introduces CLIP, a foundational vision-language model that is extensively used and compared against in the current work."}, {"fullname_first_author": "Chao Jia", "paper_title": "Scaling up visual and vision-language representation learning with noisy text supervision", "publication_date": "2021-00-00", "reason": "This paper introduces ALIGN, another significant vision-language model that serves as a basis for comparison in the current research."}, {"fullname_first_author": "Kaiyang Zhou", "paper_title": "Learning to prompt for vision-language models", "publication_date": "2022-00-00", "reason": "This paper is highly relevant as it explores prompt-based methods for vision-language models, a key area of focus in the current work."}, {"fullname_first_author": "Yuhan Zhu", "paper_title": "Efficient test-time prompt tuning for vision-language models", "publication_date": "2024-00-00", "reason": "This paper is highly relevant because it is another work from the same research group and focuses on test-time adaptation of VLMs, a topic directly addressed in the current paper."}, {"fullname_first_author": "Gaspard Monge", "paper_title": "M\u00e9moire sur la th\u00e9orie des d\u00e9blais et des remblais", "publication_date": "1781-00-00", "reason": "This paper introduces the foundational theory of optimal transport, a core methodology used in the current work."}]}