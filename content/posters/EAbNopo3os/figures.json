[{"figure_path": "EAbNopo3os/figures/figures_6_1.jpg", "caption": "Algorithm 1: Learning algorithm from winning strategy", "description": "This algorithm is designed to learn from a winning strategy in a game-theoretic setting.  It iteratively refines its understanding by updating its knowledge (U) based on whether its predictions (\u0177t) match the true values (Yt). The algorithm incorporates a winning strategy (gu) to guide its predictions. If the prediction is incorrect (\u0177t \u2260 Yt), it updates its mistake set (L) and adjusts its parameters (k and m) accordingly.  The algorithm attempts to reach a state where its predictions consistently match the true values and achieves a low error rate.", "section": "4 Sufficient and Necessary Condition that ALL Processes Admit Universal Online Learning"}, {"figure_path": "EAbNopo3os/figures/figures_12_1.jpg", "caption": "Algorithm 2: Subroutine for learning a partial concept class H with VC dimension d on the data process X.", "description": "This algorithm is a subroutine used within a larger online learning algorithm. It focuses on learning a partial concept class H (a subset of the overall concept class), which has a finite VC dimension.  The algorithm iteratively makes predictions (\u0177t) using a probability-based approach, updating its knowledge (L) whenever a prediction error occurs. The algorithm is designed to handle a sequence of data points (Xt) and their corresponding labels (Yt).  It involves adjusting a parameter (m) to control the size of the batch considered for prediction and updating.", "section": "A Omitted Proofs"}]