{"references": [{"fullname_first_author": "Robin Rombach", "paper_title": "High-resolution image synthesis with latent diffusion models", "publication_date": "2022-06-01", "reason": "This paper introduces the foundation of latent diffusion models, a crucial technique upon which many subsequent text-to-image generation and editing models are built."}, {"fullname_first_author": "Alec Radford", "paper_title": "Learning transferable visual models from natural language supervision", "publication_date": "2021-03-01", "reason": "CLIP, introduced in this paper, provides a powerful mechanism for aligning text and image embeddings, which is directly relevant to the task of text-image fusion for object synthesis."}, {"fullname_first_author": "Amir Hertz", "paper_title": "Prompt-to-prompt image editing with cross attention control", "publication_date": "2023-01-01", "reason": "This paper introduces a method for image editing using cross-attention mechanisms, inspiring the approach to text-image fusion within the ATIH model."}, {"fullname_first_author": "Prafulla Dhariwal", "paper_title": "Diffusion models beat gans on image synthesis", "publication_date": "2021-12-01", "reason": "This work establishes the superior performance of diffusion models compared to GANs for image synthesis, providing a strong rationale for adopting a diffusion-based framework in this paper."}, {"fullname_first_author": "Johannes Ackermann", "paper_title": "High-resolution image editing via multi-stage blended diffusion", "publication_date": "2022-12-01", "reason": "This paper demonstrates effective high-resolution image editing using diffusion models, providing a benchmark for assessing image manipulation techniques within the context of object synthesis."}]}