[{"figure_path": "NnAi0L5H8J/tables/tables_5_1.jpg", "caption": "Table 1: Characteristics of the benchmark and real-world MIPL datasets.", "description": "This table presents a detailed overview of the characteristics of eight datasets used in the paper's experiments.  These include four benchmark datasets (MNIST-MIPL, FMNIST-MIPL, Birdsong-MIPL, SIVAL-MIPL) and four real-world datasets derived from a colorectal cancer classification task (C-Row, C-SBN, C-KMeans, C-SIFT, C-R34-16, C-R34-25). For each dataset, the table lists the number of bags (#bag), the total number of instances (#ins), the maximum, minimum, and average number of instances per bag (max. #ins, min. #ins, avg. #ins), the dimensionality of the instance-level features (#dim), the number of classes (#class), and the average number of candidate labels per bag (avg. #CLs). This information is crucial for understanding the scale and complexity of the datasets used to evaluate the proposed MIPLMA algorithm and compare its performance against other methods.", "section": "3.1 Experimental Configurations"}, {"figure_path": "NnAi0L5H8J/tables/tables_6_1.jpg", "caption": "Table 2: The classification accuracies (mean\u00b1std) of MIPLMA and comparative algorithms on the benchmark datasets with the varying numbers of false positive labels (r \u2208 {1, 2, 3}).", "description": "This table presents the mean and standard deviation of classification accuracies achieved by the proposed MIPLMA algorithm and several other algorithms (ELIMIPL, DEMIPL, MIPLGP, PRODEN, RC, Lws, CAVL, POP, PL-AGGD) across four benchmark datasets (MNIST-MIPL, FMNIST-MIPL, Birdsong-MIPL, SIVAL-MIPL). The results are shown for different numbers of false positive labels (r = 1, 2, 3), offering a comparison of performance under varying levels of label noise.", "section": "3.2.1 Results on the Benchmark Datasets"}, {"figure_path": "NnAi0L5H8J/tables/tables_7_1.jpg", "caption": "Table 3: The classification accuracies (mean\u00b1std) of MIPLMA and comparative algorithms on the real-world datasets.", "description": "This table presents the classification accuracies achieved by the proposed MIPLMA algorithm and several other comparative algorithms on four real-world datasets.  Each dataset is a variation of the CRC-MIPL dataset, which is based on colorectal cancer classification. The variations differ in how the multi-instance features are extracted. The table shows the average accuracy and standard deviation across multiple runs. It allows for comparison of MIPLMA against other algorithms including those based on Multi-Instance Learning (MIL) and Partial-Label Learning (PLL).", "section": "3.2.2 Results on the Real-World Datasets"}, {"figure_path": "NnAi0L5H8J/tables/tables_7_2.jpg", "caption": "Table 4: The classification accuracies (mean\u00b1std) on the CRC-MIPL dataset with deep multi-instance features.", "description": "This table presents the classification accuracies achieved by MIPLMA, ELIMIPL, and DEMIPL on the CRC-MIPL dataset using deep multi-instance features extracted with ResNet-34.  It shows the performance of the algorithms on two variations of the dataset: C-R34-16 (ResNet-34 with 16 image patches per image bag) and C-R34-25 (ResNet-34 with 25 image patches per image bag). The results demonstrate the superior performance of MIPLMA, which consistently outperforms the other two algorithms across both variations.", "section": "3.2.3 Results of the CRC-MIPL Dataset with Deep Features"}, {"figure_path": "NnAi0L5H8J/tables/tables_8_1.jpg", "caption": "Table 5: The classification accuracies (mean\u00b1std) of MAAM, ATTEN, and ATTEN-GATE on the MIL datasets with bag-level true labels.", "description": "This table presents the mean and standard deviation of classification accuracies achieved by three different algorithms (MAAM, ATTEN, and ATTEN-GATE) on two MIL datasets (MNIST-MIPL and FMNIST-MIPL).  The results show the performance of these algorithms when using only bag-level true labels, not the instance-level or candidate label set information used in other parts of the paper.  MAAM significantly outperforms the other two algorithms.", "section": "3.4 Margin Adjustment for MIL and PLL Algorithms"}, {"figure_path": "NnAi0L5H8J/tables/tables_8_2.jpg", "caption": "Table 6: The classification accuracies (mean\u00b1std) of PRODEN-MA and PRODEN on the Kuzushiji-MNIST dataset with varying flipping probability q.", "description": "This table shows the classification accuracy comparison between two algorithms, PRODEN-MA and PRODEN, on the Kuzushiji-MNIST dataset under different levels of label noise. PRODEN-MA incorporates the margin distribution loss proposed in the paper, while PRODEN is the baseline algorithm. The results are presented in terms of mean accuracy and standard deviation across multiple runs for each flipping probability (q).", "section": "3.3 Effectiveness of the Margin Adjustment"}, {"figure_path": "NnAi0L5H8J/tables/tables_15_1.jpg", "caption": "Table 2: The classification accuracies (mean\u00b1std) of MIPLMA and comparative algorithms on the benchmark datasets with the varying numbers of false positive labels (r \u2208 {1, 2, 3}).", "description": "This table presents the classification accuracies of the proposed MIPLMA algorithm and several other algorithms (ELIMIPL, DEMIPL, MIPLGP, PRODEN, RC, Lws, CAVL, POP, PL-AGGD) across four benchmark datasets (MNIST-MIPL, FMNIST-MIPL, Birdsong-MIPL, SIVAL-MIPL).  The results are shown for different numbers of false positive labels (r=1, 2, 3), demonstrating the performance of each algorithm under varying levels of label noise.", "section": "3.2 Comparison with MIPL and PLL Algorithms"}, {"figure_path": "NnAi0L5H8J/tables/tables_16_1.jpg", "caption": "Table 2: The classification accuracies (mean\u00b1std) of MIPLMA and comparative algorithms on the benchmark datasets with the varying numbers of false positive labels (r \u2208 {1, 2, 3}).", "description": "This table presents the classification accuracy results of the proposed MIPLMA algorithm and several other algorithms (including ELIMIPL, DEMIPL, MIPLGP, PRODEN, RC, LWS, CAVL, POP, and PL-AGGD) on four benchmark datasets (MNIST-MIPL, FMNIST-MIPL, Birdsong-MIPL, and SIVAL-MIPL).  The results are shown for different numbers of false positive labels (r=1, 2, 3), demonstrating the performance of each algorithm under varying levels of label noise.", "section": "3.2.1 Results on the Benchmark Datasets"}, {"figure_path": "NnAi0L5H8J/tables/tables_16_2.jpg", "caption": "Table 3: The classification accuracies (mean\u00b1std) of MIPLMA and comparative algorithms on the real-world datasets.", "description": "This table presents the classification accuracies achieved by MIPLMA and several other algorithms on four real-world datasets related to colorectal cancer classification.  Each dataset has different types of multi-instance features extracted using different methods. The table shows the mean and standard deviation of the accuracy across multiple runs of the algorithms, and it allows comparison of the performance of MIPLMA against other methods on the same datasets. Note that some values are marked as unavailable due to computational constraints.", "section": "3.2.2 Results on the Real-World Datasets"}, {"figure_path": "NnAi0L5H8J/tables/tables_17_1.jpg", "caption": "Table 2: The classification accuracies (mean\u00b1std) of MIPLMA and comparative algorithms on the benchmark datasets with the varying numbers of false positive labels (r \u2208 {1, 2, 3}).", "description": "This table presents the classification accuracies of the proposed MIPLMA algorithm and several other algorithms (ELIMIPL, DEMIPL, MIPLGP, PRODEN, RC, Lws, CAVL, POP, PL-AGGD) on four benchmark datasets (MNIST-MIPL, FMNIST-MIPL, Birdsong-MIPL, SIVAL-MIPL).  The results are shown for different numbers of false positive labels (r = 1, 2, 3), indicating the robustness of each algorithm under varying levels of label noise.  The mean and standard deviation of the accuracy across multiple runs are provided.", "section": "3.2.1 Results on the Benchmark Datasets"}, {"figure_path": "NnAi0L5H8J/tables/tables_18_1.jpg", "caption": "Table A5: The classification accuracies (mean\u00b1std) of MIPLMA and MIPL-MAMM on the benchmark datasets with the varying numbers of false positive labels (r \u2208 {1,2,3}).", "description": "This table presents the classification accuracies achieved by MIPLMA and its variant MIPL-MAMM on four benchmark datasets.  The performance is evaluated across different numbers of false positive labels (r). The results show the mean and standard deviation of the accuracy across multiple runs, providing a statistical assessment of the algorithm's performance under different conditions.  Comparing the results of MIPLMA and MIPL-MAMM allows for an evaluation of the impact of the margin distribution loss implemented in MIPLMA.", "section": "3.3 Effectiveness of the Margin Adjustment"}, {"figure_path": "NnAi0L5H8J/tables/tables_21_1.jpg", "caption": "Table 2: The classification accuracies (mean\u00b1std) of MIPLMA and comparative algorithms on the benchmark datasets with the varying numbers of false positive labels (r \u2208 {1, 2, 3}).", "description": "This table presents the classification accuracy results for the proposed MIPLMA algorithm and several other algorithms on four benchmark datasets (MNIST-MIPL, FMNIST-MIPL, Birdsong-MIPL, and SIVAL-MIPL). The results are shown for three different settings of the number of false positive labels (r = 1, 2, and 3).  The table helps to demonstrate the performance of MIPLMA against other state-of-the-art algorithms in a multi-instance partial-label learning setting.", "section": "3.2 Comparative Algorithms"}]