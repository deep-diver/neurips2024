[{"type": "text", "text": "Quantile Activation: departing from single point estimation for better generalization across distortions ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Anonymous Author(s)   \nAffiliation   \nAddress   \nemail ", "page_idx": 0}, {"type": "text", "text": "Abstract ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "1 A classifier is, in its essence, a function which takes an input and returns the class   \n2 of the input and implicitly assumes an underlying distribution. We argue in this   \n3 article that one has to move away from this basic tenet to obtain generalization   \n4 across distributions. Specifically, the class of the sample should depend on the   \n5 points from its \u201ccontext distribution\u201d for better generalization across distributions.   \n6 How does one achieve this? \u2013 The key idea is to \u201cadapt\u201d the outputs of each neuron   \n7 of the network to its context distribution. We propose quantile activation,QACT,   \n8 which, in simple terms, outputs the relative quantile of the sample in its context   \n9 distribution, instead of the actual values in traditional networks.   \n10 The scope of this article is to validate the proposed activation across several experi  \n11 mental settings, and compare it with conventional techniques. For this, we use the   \n12 datasets developed to test robustness against distortions \u2013 CIFAR10C, CIFAR100C,   \n13 MNISTC, TinyImagenetC, and show that we achieve a significantly higher gen  \n14 eralization across distortions than the conventional classifiers, across different   \n15 architectures. Although this paper is only a proof of concept, we surprisingly find   \n16 that this approach outperforms DINOv2(small) at large distortions, even though   \n17 DINOv2 is trained with a far bigger network on a considerably larger dataset. ", "page_idx": 0}, {"type": "text", "text": "18 1 Introduction ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "19 Deep learning approaches have significantly influenced image classification tasks on the machine   \n20 learning pipelines over the past decade. They can easily beat human performance on such tasks by non  \n21 trivial margins by using innovative ideas such as Batch Normalization [19] and other normalization   \n22 techniques [3, 31], novel rectifiers such as ReLU/PReLU [26, 31, 3] and by using large datasets and   \n23 large models.   \n24 However, these classification systems do not generalize across distributions [2, 34], which leads to   \n25 instability when used in practice. [22] shows that deep networks with ReLU activation degrades in   \n26 performance under distortions. [4] observes that there exists a feature collapse which inhibits the   \n27 networks to be reliable.   \n28 Fundamental Problem of Classification: We trace the source of the problem to the fact that \u2013 Ex  \n29 isting classification pipelines necessitates single point prediction, i.e., they should allow classification   \n30 of a single sample given in isolation. We argue that, for good generalization, one should move away   \n31 from this basic tenet and instead allow the class to be dependent on the \u201ccontext distribution\u201d of the   \n32 sample. That is, when performing classification, one needs to know both the sample and the context   \n33 of the sample for classification.   \n34 While this is novel in the context of classification systems, it is widely prevalent in the specific domain   \n35 of Natural Language Processing (NLP) \u2013 The meaning of a word is dependent on the context of the   \n36 word. However, to our knowledge, this has not been considered for general classification systems.   \n37 Even when using dominant NLP architectures such as Transformers for vision [8], the technique has   \n38 been to split the image into patches and then obtain the embedding for an individual image.   \n39 Obtaining a classification framework for incorporating context distribution: We suspect that   \n40 the main reason why the context distribution is not incorporated into the classification system is   \n41 \u2013 The naive approach of considering a lot of samples in the pipeline to classify a single sample   \n42 is computationally expensive. We solve this problem by considering the context distribution of   \n43 each neuron specifically. We introduce Quantile Activation (QACT), which outputs a probability   \n44 depending upon the context of all outputs. This, however, gives rise to new challenges in training,   \n45 which we address in section 2.   \n46 Figure 1 illustrates the differences of the proposed framework with the existing framework. As   \n47 severity increases (w.r.t Gaussian Noise), we observe that ReLU activation loses the class structure.   \n48 This behaviour can be attributed to the fact that, as the input distribution changes, the activations   \n49 either increase/decrease, and due to the multiplicative effect of numerous layers, this leads to very   \n50 different features. On the other hand, the proposed QACT framework does not suffer from this, since   \n51 if all the pre-activations1 change in a systematic way, the quantiles adjust automatically to ensure that   \n52 the inputs for the next layer does not change by much. This is reflected in the fact that class structure   \n53 is preserved with QACT.   \n54 Remark: Quantile activation is different from existing quantile neural network based approaches,   \n55 such as regression [30], binary quantile classification [36], Anomaly Detection [24, 33]. Our approach   \n56 is achieving best in-class performance by incorporating context distribution in the classification   \n57 paradigm. Our approach is also markedly different from Machine unlearning which is based on   \n58 selective forgetting of certain data points or retraining from scratch [32].   \n59 Contributions: A decent amount of literature on neuronal activation is available. However, to the   \n60 best of our knowledge, none matches the central idea proposed in this work.   \n61 In [5], the authors propose an approach to calibrate a pre-trained classifier $f_{\\boldsymbol{\\theta}}(\\mathbf{\\boldsymbol{x}})$ by extending it   \n62 to learn a quantile function, $Q(x,\\theta,\\tau)$ $\\tau$ denotes the quantile), and then estimate the probabilities   \n63 using $\\begin{array}{r}{\\int_{\\tau}I[Q(\\pmb{x},\\theta,\\tau)\\geq0.5]d\\tau^{2}}\\end{array}$ . They show that this results in probabilities which are robust to   \n64 distortions.   \n65 1. In this article, we extend this approach to the level of a neuron, by suitably deriving the   \n66 forward and backward propagation equations required for learning (section 2).   \n67 2. We then show that a suitable incorporation of our extension produces context dependent   \n68 outputs at the level of each neuron of the neural network.   \n69 3. Our approach contributes to achieving better generalization across distributions and is   \n70 more robust to distortions, across architectures. We evaluate our method using different   \n71 architectures and datasets, and compare with the current state-of-the-art \u2013 DINOv2. We   \n72 show that QACT proposed here is more robust to distortions than DINOv2, even if we   \n73 have considerably less number of parameters (22M for DINOv2 vs 11M for Resnet18).   \n74 Additionally, DINOv2 is trained on 20 odd datasets, before being applied on CIFAR10C; in   \n75 contrast, our framework is trained on CIFAR10, and produces more robust outcome (see   \n76 figures 3,5).   \n77 4. The proposed QACT is consistent with all the existing techniques used in DINOv2, and   \n78 hence can be easily incorporated into any ML framework.   \n79 5. We also adapt QACT to design a classifier which returns better calibrated probabilities.   \n80 Related Works on Domain Generalization (DG): The problem of domain generalizations tries   \n81 to answer the question \u2013 Can we use a classifier trained on one domain across several other related   \n82 domains? The earliest known approach for this is Transfer Learning [28, 37], where a classifier   \n83 from a single domain is applied to a different domain with/without fine-tuning. Several approaches   \n84 have been proposed to achieve DG, such as extracting domain-invariant features over single/multiple   \n85 source domains [11, 1, 9, 29, 16], Meta Learning [17, 9], Invariant Risk Minimization [2]. Self   \n86 supervised learning is another proposed approach which tries to extract features on large scale datasets   \n87 in an unsupervised manner, the most recent among them being DINOv2 [27]. Very large foundation   \n88 models, such as GPT-4V, are also known to perform better with respect to distribution shifts [12].   \n89 Nevertheless, to the best of our knowledge, none of these models incorporates context distributions   \n90 for classification. ", "page_idx": 0}, {"type": "text", "text": "", "page_idx": 0}, {"type": "text", "text": "", "page_idx": 0}, {"type": "text", "text": "", "page_idx": 0}, {"type": "image", "img_path": "MbbTN9rPzC/tmp/8aca2bb8a9a53448538173a5f9cc3fa684a43f07a9e1f190e6651fb9ee9382bb.jpg", "img_caption": ["Figure 1: Comparing TSNE plots of QACT and ReLU activation on CIFAR10C with Gaussian distortions. Observe that QACT maintains the class structure extremely well across distortions, while the usual ReLU activations loses the class structure as severity increases. "], "img_footnote": [], "page_idx": 1}, {"type": "text", "text": "", "page_idx": 1}, {"type": "text", "text": "", "page_idx": 1}, {"type": "text", "text": "", "page_idx": 1}, {"type": "text", "text": "", "page_idx": 1}, {"type": "text", "text": "", "page_idx": 1}, {"type": "text", "text": "", "page_idx": 1}, {"type": "text", "text": "", "page_idx": 1}, {"type": "text", "text": "", "page_idx": 2}, {"type": "text", "text": "", "page_idx": 2}, {"type": "text", "text": "91 2 Quantile Activation ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "92 Rethinking Outputs from a Neuron: To recall \u2013 if $\\mathbf{x}$ denotes the input, a typical neuron does the   \n93 following \u2013 (i) Applies a linear transformation with parameters $w,b_{i}$ , giving $\\boldsymbol{w}^{t}\\mathbf{x}+\\boldsymbol{b}$ as the output,   \n94 and (ii) applies a rectifier $g$ , returning $g(w^{t}\\mathbf{x}+b)$ . Typically, $g$ is taken to be the ReLU activation -   \n95 $g_{r e l u}(x)=\\operatorname*{max}(0,x)$ . Intuitively, we expect that each neuron captures an \u201cabstract\u201d feature, usually   \n96 not understood by a human observer.   \n97 An alternate way to model a neuron is to consider it as predicting a latent variable $\\mathbf{y}$ , where $\\mathbf y=1$   \n98 if the feature is present and $\\mathbf y=0$ if the feature is absent. Mathematically, we have the following   \n99 model: ", "page_idx": 2}, {"type": "text", "text": "", "page_idx": 2}, {"type": "equation", "text": "$$\n\\mathbf{z}=w^{t}\\mathbf{x}+b+\\epsilon\\quad a n d\\quad\\mathbf{y}=I[\\mathbf{z}\\geq0]\n$$", "text_format": "latex", "page_idx": 2}, {"type": "text", "text": "100 This is very similar to the standard latent variable model for logistic regression, with the main   \n101 exception being, the outputs y are not known for each neuron beforehand. If $\\mathbf{y}$ is known, it is rather   \n102 easy to obtain the probabilities \u2013 $\\mathbf{\\nabla}\\cdot P(\\mathbf{z}\\geq0)$ . Can we still predict the probabilities, even when $\\mathbf{y}$ itself   \n103 is a latent variable? ", "page_idx": 2}, {"type": "text", "text": "104 The authors in [5] propose the following algorithm to estimate the probabilities: ", "page_idx": 2}, {"type": "text", "text": "105 1. Let $\\{x_{i}\\}$ denote the set of input samples from the input distribution $\\mathbf{x}$ and $\\{z_{i}\\}$ denote their   \n106 corresponding latent outputs, which would be from the distribution $\\mathbf{z}$   \n107 2. Assign $\\mathbf y=1$ whenever $\\dot{\\mathbf{z}}>(1-\\tau)^{t h}$ quantile of ${\\bf z}$ , and 0 otherwise. For a specific sample,   \n108 we have $y_{i}=1$ if $z_{i}>(1-\\tau)^{t h}$ quantile of $\\{z_{i}\\}$   \n109 3. Fit the model $Q(x,\\tau;\\theta)$ to the dataset $\\{((\\mathbf{\\emx}_{i},\\bar{\\tau}),\\bar{y}_{i})\\}$ , and estimate the probability as, ", "page_idx": 2}, {"type": "equation", "text": "$$\nP(y_{i}=1)=\\int_{\\tau=0}^{1}I[Q(x,\\tau;\\theta)\\geq0.5]d\\tau\n$$", "text_format": "latex", "page_idx": 2}, {"type": "text", "text": "110 The key idea: Observe that in step 2., the labelling is done without resorting to actual ground  \n111 truth labels. This allows us to obtain the probabilities on the fly for any set of parameters, only by   \n112 considering the quantiles of $\\mathbf{z}$ .   \n113 Defining the Quantile Activation QACT Let $\\mathbf{z}$ denote the pre-activation of the neuron, and let   \n114 $\\{z_{i}\\}$ denote the samples from this distribution. Let $F_{\\mathbf{z}}$ denote the cumulative distribution function   \n115 (CDF), and let $f_{\\mathbf{z}}$ denote the density of the distribution. Accordingly, we have that $F_{\\mathbf{z}}^{-1}(\\tau)$ denotes ", "page_idx": 2}, {"type": "text", "text": "", "page_idx": 2}, {"type": "text", "text": "Algorithm 1 Forward Propagation for a single neuron ", "page_idx": 3}, {"type": "text", "text": "Input: $[z_{i}]$ a vector of pre-activations, $0<\\tau_{1}<\\tau_{2}<\\cdots<\\tau_{n_{\\tau}}<1-\\mathrm{a}$ list of quantile indices at   \nwhich we compute the quantiles. Append two large values, $c$ and $-c$ , to the vector $\\left[z_{i}\\right]$ . Count $n_{+}=$ number of positive values, $n_{-}=$ number of negative values, and assign the weight $w_{+}=1/n_{+}$ to the positive values, and $w_{-}=1/n_{-}$ to the negative values. Compute weighted quantiles $\\{q_{i}\\}$ at each of $\\{\\tau_{i}\\}$ over the set $\\{z_{i}\\}\\cup\\{c,-c\\}$ Compute $\\mathrm{QACT}\\big(z_{i}\\big)$ using the function, ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\mathrm{QACT}(x)=\\frac{1}{n_{\\tau}}\\sum_{i}I[x\\ge q_{i}]\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "Remember $\\left[z_{i}\\right]$ , $w_{+},w_{-}$ , $\\left[{\\sf Q A C T}(z_{i})\\right]$ for backward propagation. return $\\left[\\mathrm{QACT}\\left(z_{i}\\right)\\right]$ ", "page_idx": 3}, {"type": "text", "text": "Algorithm 2 Backward Propagation for a single neuron ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "Input: grad_output, $0<\\tau_{1}<\\tau_{2}<\\cdot\\cdot<\\tau_{n_{\\tau}}<1-$ a list of quantile indices at which we compute the quantiles. ", "page_idx": 3}, {"type": "text", "text": "Context from Forward Propagation: $[z_{i}]$ $_{i}],\\,w_{+},w_{-}$ , $\\left[{\\sf Q A C T}(z_{i})\\right]$ ", "page_idx": 3}, {"type": "text", "text": "Obtain a weighted sample from $[z_{i}]$ with weights $w_{+},w_{-}-(\\mathrm{say})\\ S$ .   \nObtain a kernel density estimate, using points from $S$ , at each of the points in $z_{i}-(\\mathrm{say})\\,\\hat{f}_{\\mathbf{z}}(z_{i})$ Set, ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\mathtt{g r a d\\_i n p u t}=\\mathtt{g r a d\\_o u t p u t}\\odot[\\hat{f}_{\\mathbf{z}}(z_{i})]\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "return grad_input ", "page_idx": 3}, {"type": "text", "text": "116 the $\\tau^{t h}$ quantile of $\\mathbf{z}$ . Using step (2) of the algorithm above, we define, ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\mathrm{QACT}(z)=\\int_{\\tau=0}^{1}I[z>F_{\\mathbf{z}}^{-1}(1-\\tau)]d\\tau\\overset{\\mathrm{Subsitute}}{\\underset{\\tau\\to(1-\\tau)}{=}}\\int_{\\tau=0}^{1}I[z>F_{\\mathbf{z}}^{-1}(\\tau)]d\\tau\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "117 Computing the gradient of QACT: However, to use QACT in a neural network, we need to   \n118 compute the gradient which is required for back-propagation. Let $\\tau_{z}$ denote the quantile at which   \n119 $F_{\\mathbf{z}}^{-1}\\bar{(\\tau_{z})}=z$ . Then we have that $\\mathrm{QACT}(z)=\\tau_{z}$ since $F_{\\mathbf{z}}^{-1}(\\tau)$ is an increasing function. So, we   \n120 have that $\\mathrm{QACT}(F_{\\mathbf{z}}^{-1}(\\tau))=\\tau$ . In other words, we have that ${\\bigcirc}\\mathbf{A}\\mathbf{C}\\mathbf{T}(z)$ is $F_{\\mathbf{z}}(z)$ , which is nothing   \n121 but the CDF of ${\\bf z}$ . Hence, we have, ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\frac{\\partial\\mathrm{QACT}(z)}{\\partial z}=f_{\\mathbf{z}}(z)\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "122 where $f_{\\mathbf{z}}(z)$ denotes the density of the distribution. ", "page_idx": 3}, {"type": "text", "text": "123 Grounding the Neurons: With the above formulation, observe that since QACT is identical to   \n124 CDF, it follows that, $\\mathbf{QACT}(\\mathbf{z})$ is always a uniform distribution between 0 and 1, irrespective of the   \n125 distribution ${\\bf z}$ . When training numerous neurons in a layer, this could cause all the neurons to learn   \n126 the same behaviour. Specifically, if, half the time, a particular abstract feature is more prevalent   \n127 than others, QACT (as presented above) would not be able to learn this feature. To correct this, we   \n128 enforce that positive values and negative values have equal weight. Given the input distribution $\\mathbf{z}$ ,   \n129 We perform the following transformation before applying QACT. Let ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\mathbf{z}^{+}=\\left\\{\\mathbf{z}\\quad{\\mathrm{~if~}}\\mathbf{z}\\geq0\\qquad\\qquad\\qquad\\qquad\\mathbf{z}^{-}=\\left\\{\\mathbf{z}\\quad{\\mathrm{~if~}}\\mathbf{z}<0}\\\\ {0\\quad{\\mathrm{~otherwise}}\\qquad\\qquad\\qquad\\qquad\\qquad\\mathbf{z}^{-}={\\left\\{\\mathbf{0}\\quad{\\mathrm{~otherwise}}\\right.\\qquad}}\\end{array}\\right.\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "130 denote the truncated distributions. Then, ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\mathbf{z}^{\\ddagger}=\\left\\{{\\begin{array}{l l}{\\mathbf{z}^{+}\\,}&{\\mathrm{~with~probability~0.5~}}\\\\ {\\mathbf{z}^{-}\\,}&{\\mathrm{~with~probability~0.5~}}\\end{array}}\\right.\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "131 From definition of $\\mathbf{z}^{\\ddag}$ , we get that the median of $\\mathbf{z}^{\\ddag}$ is 0. This grounds the input distribution to have   \n132 the same positive and negative weight.   \n133 Dealing with corner cases: It is possible that during training, some neurons either only get positive   \n134 values or only get negative values. However, for smooth outputs, one should still only give the weight   \n135 of 0.5 for positive values. To handle this, we include two values $c$ (large positive) and $-c$ (large   \n136 negative) for each neuron. Since, the quantiles are conventionally computed using linear interpolation,   \n137 this allows the outputs to vary smoothly. We take $c=100$ in this article.   \n138 Estimating the Density for Back-Propagation: Note that the gradient for the back propagation is   \n139 given by the density of $\\mathbf{z}^{\\ddag}$ (weighted distribution). We use the Kernel Density Estimation (KDE), to   \n140 estimate the density. We, (i) First sample $N$ points with weights $w_{+},w_{-}$ , and (ii) then estimate the   \n141 density at all the input points $[z_{i}]$ . This is point-wise multiplied with the backward gradient to get the   \n142 gradient for the input. In this article we use $N=1000$ , which we observe gets reasonable estimates.   \n143 Computational Complexity: Computational Complexity (for a single neuron) is majorly decided   \n144 by 2 functions \u2013 (i) Computing the quantiles has the complexity for a vector $[z_{i}]$ of size $n$ can be   \n145 performed in ${\\mathcal{O}}(n\\log(n))$ . Since this is log-linear in $n$ , it does not increase the complexity drastically   \n146 compared to other operations in a deep neural network. (ii) Computational complexity of the KDE   \n147 estimates is ${\\mathcal O}(S n_{\\tau})$ where $S$ is the size of sample (weighted sample from $[z_{i}],$ ) and $n_{\\tau}$ is the number   \n148 of quantiles, giving a total of $O(n+S n_{\\tau})$ . In practice, we consider $S=1000$ and $n_{\\tau}=100$ which   \n149 works well, and hence does not increase with the batch size. This too scales linearly with batch size   \n150 $n$ , and hence does not drastically increase the complexity.   \n151 Remark: Algorithms 1, and 2 provide the pseudocode for the quantile activation. For stable   \n152 training, in practice, we prepend and append the quantile activation with BatchNorm layers.   \n153 Why QACT is robust to distortions? To understand the idea behind quantile activation, consider a   \n154 simple toy example in figure 2. For ease of visualization, assume that the input features (blue) are in 2   \n155 dimensions, and also assume that the line of the linear projection is given by the red line in figure 2a.   \n156 Now, assume that the blue input features are rotated, leading to a different distribution (indicated here   \n157 by orange). Since activations are essentially (unnormalized) signed distances from the line, we plot   \n158 the histograms corresponding to the two distributions in figure 2b. As expected, these distributions   \n159 are different. However, after performing the quantile activation in equation 3, we have that both are   \n160 uniform distribution. This is illustrated in figures 2c and 2d. This behaviour has a normalizing effect   \n161 across different distributions, and hence has better distribution generalization than other activations. ", "page_idx": 3}, {"type": "image", "img_path": "MbbTN9rPzC/tmp/203eb6f7e2323b0a3b1a6382d683628327a71be732aa883aba06fec041f3fbe6.jpg", "img_caption": ["Figure 2: Intuition behind quantile activation. (a) shows a simple toy distribution of points (blue), it\u2019s distortion (orange) and a simple line (red) on which the samples are projected to obtain activations. (b) shows the distribution of the pre-activations. (c) shows the distributions of the activations with QACT of the original distribution (blue). (d) shows the distributions of the activations with QACT under the distorted distribution (orange). Observe that the distributions match perfectly under small distortions. Note that even if the distribution matches perfectly, the quantile activation is actually a deterministic function. "], "img_footnote": [], "page_idx": 4}, {"type": "text", "text": "", "page_idx": 4}, {"type": "text", "text": "", "page_idx": 4}, {"type": "text", "text": "", "page_idx": 4}, {"type": "text", "text": "", "page_idx": 4}, {"type": "text", "text": "", "page_idx": 4}, {"type": "text", "text": "162 3 Training with QACT ", "text_level": 1, "page_idx": 5}, {"type": "text", "text": "163 In the previous section, we described the procedure to adapt a single neuron to its context distribution.   \n164 In this section we discuss how this extends to the Dense/Convolution layers, the loss functions to   \n165 train the network and the inference aspect.   \n166 Extending to standard layers: The extension of equation 3 to dense outputs is straightforward.   \n167 A typical output of the dense layer would be of the shape $(B,N_{c})\\cdot B$ denotes the batch size, $N_{c}$   \n168 denotes the width of the network. The principle is - The context distribution of a neuron is all the   \n169 values which are obtained using the same parameters. In this case, each of the values across the $^{\\star}B$ \u2019   \ndimension are considered to be samples from the context distribution.   \n171 For a convolution layer, the typical outputs are of the form - $(B,N_{c},H,W)\\cdot B$ denotes the size of   \n172 the batch, $N_{c}$ denotes the number of channels, $H,W$ denotes the sizes of the images. In this case we   \n173 should consider all values across the 1st,3rd and 4th dimension to be from the context distribution,   \n174 since all these values are obtained using the same parameters. So, the number of samples would be   \n175 $B\\times H\\times W$ .   \n176 Loss Functions: One can use any differentiable loss function to train with quantile activation. We   \n177 specifically experiment with the standard Cross-Entropy Loss, Triplet Loss, and the recently proposed   \n178 Watershed Loss [6] (see section 4). However, if one requires that the boundaries between classes   \n179 adapt to the distribution, then learning similarities instead of boundaries can be beneficial. Both   \n180 Triplet Loss and Watershed Loss fall into this category. We see that learning similarities does have   \n181 slight benefits when considering the embedding quality.   \n182 Inference with QACT: As stated before, we want to assign a label for classification based on the   \n183 context of the sample. There exist two approaches for this \u2013 (1) One way is to keep track of the   \n184 quantiles and the estimated densities for all neurons and use it for inference. This allows inference   \n185 for a single sample in the traditional sense. However, this also implies that one would not be able   \n186 to assign classes based on the context at evaluation. (2) Another way is to make sure that, even for   \n187 inference on a single sample, we include several samples from the context distribution, but only use   \n188 the output for a specific sample. This allows one to assign classes based on the context. In this article,   \n189 we follow the latter approach.   \n190 Quantile Classifier: Observe that the proposed QACT (without normalization) returns the values in   \n191 [0, 1] which can be interpreted as probabilities. Hence, one can also use this for the classification layer.   \n192 Nonetheless, two changes are required \u2013 (i) Traditional softmax used in conjunction with negative  \n193 log-likelihoood loss already considers \u201crelative\u201d activations of the classification in normalization.   \n194 However, QACT does not. Hence, one should use Binary-Cross-Entropy loss with QACT, which   \n195 amounts to one-vs-rest classification. (ii) Also, unlike a neuron in the middle layers, the bias of the   \n196 neuron in the classification layer depends on the class imbalance. For instance, with 10 classes, one   \n197 would have only $1/10$ of the samples labelled 1 and $9/10$ of the samples labelled 0. To address this,   \n198 we require that the median of the outputs be at 0.9, and hence weight the positive class with 0.9 and   \n199 the negative class with 0.1 respectively. In this article, whenever QACT is used, we use this approach   \n200 for inference.   \n201 We observe that (figures 13 and 14) using quantile classifier on the learned features in general   \n202 improves the consistency of the calibration error and also leads to the reducing the calibration error.   \n203 In this article, for all networks trained with quantile activation, we use quantile classifier to compute   \n204 the accracies/calibration errors. ", "page_idx": 5}, {"type": "text", "text": "", "page_idx": 5}, {"type": "text", "text": "", "page_idx": 5}, {"type": "text", "text": "", "page_idx": 5}, {"type": "text", "text": "", "page_idx": 5}, {"type": "text", "text": "", "page_idx": 5}, {"type": "text", "text": "205 4 Evaluation ", "text_level": 1, "page_idx": 5}, {"type": "text", "text": "206 To summarize, we make the following changes to the existing classification pipeline \u2013 (i) Replace the   \n207 usual ReLU activation with QACT and (ii) Use triplet or watershed loss instead of standard cross   \n208 entropy loss. We expect this framework to learn context dependent features, and hence be robust   \n209 to distortions. (iii) Also, use quantile classifier to train the classifier on the embedding for better   \n210 calibrated probabilities.   \n211 Evaluation Protocol: To evaluate our approach, we consider the two datasets developed for this   \n212 purpose \u2013 CIFAR10C, CIFAR100C, TinyImagenetC [15], MNISTC[25]. These datasets have a   \n213 set of 15 distortions at 5 severity levels. To ensure diversity we evaluate our method on 4 ar  \n214 chitectures \u2013 (overparametrized) LeNet, ResNet18[14] (11M parameters), VGG[35](15M param  \n215 eters) and DenseNet [18](1M parameters). The code to reproduce the results can be found at   \n216 https://anonymous.4open.science/r/QuantAct-2B41.   \n217 Baselines for Comparison: To our knowledge, there exists no other framework which proposed   \n218 classification based on context distribution. So, for comparison, we consider standard ReLU activation   \n219 [10], pReLU [13], and SELU [20] for all the architectures stated above. Also, we compare our   \n220 results with DINOv2 (small) [27] (22M parameters) which is current state-of-the-art for domain   \n221 generalization. Note that for DINOv2, architecture and datasets used for training are substantially   \n222 different (and substantially larger) from what we consider in this article. Nevertheless, we include the   \n223 results for understanding where our proposed approach lies on the spectrum. We consider the small   \n224 version of DINOv2 to match the number of parameters with the compared models.   \n225 Metrics: We consider four metrics \u2013 Accuracy (ACC), calibration error (ECE) [23] (both marginal   \n226 and Top-Label) and mean average precision at $K$ $\\zeta\\,(\\mathbf{MAP}@\\mathbf{K})$ to evaluate the embedding. For the case   \n227 of ReLU/pReLU/SELU activation with Cross-Entropy, we use the logistic regression trained on the   \n228 train set embeddings, and for QACT we use the calibrated linear classifier, as proposed above. We do   \n229 not perform any additional calibration and use the probabilities. We discuss a selected set of results   \n230 in the main article. Please see appendix C for more comprehensive results.   \n231 Calibration error measures the reliability of predicted probabilities. In simple words, if one predicts   \n232 100 samples with (say) probability 0.7, then we expect 70 of the samples to belong to class 1 and the   \n233 rest to class 0. This is measured using either the marginal or top-label calibration error. We refer the   \n234 reader to [23] for details, which also provides an implementation to estimate the calibration error.   \n235 Remark: For all the baselines we use the standard Cross-Entropy loss for training. For inference   \n236 on corrupted datasets, we retrain the last layer with logistic regression on the train embedding and   \n237 evaluate it on test/corrupted embedding. For QACT, we as a convention use watershed loss unless   \n238 otherwise stated, for training. For inference, we train the Quantile Classifier on the train embedding   \n239 and evaluate it on test/corrupted embedding.   \n240 The proposed QACT approach is robust to distortions: In fig. 3 we compare the proposed   \n241 QACT approach with predominant existing pipeline \u2013 ReLU+Cross-Entropy and DINOv2(small)   \n242 on CIFAR10C. In figure 3a we see that as the severity of the distortion increases, the accuracy of   \n243 ReLU and DINOv2 drops significantly. On the other hand, while at small distortions the results are   \n244 comparable, as severity increases QACT performs substantially better than conventional approaches. ", "page_idx": 5}, {"type": "image", "img_path": "MbbTN9rPzC/tmp/7d92a1be2608fe661b9eefb26c184dc4cb8c8ef8830279f1c275d850e75c68be.jpg", "img_caption": ["(b) Top-Label Calibration Error "], "img_footnote": [], "page_idx": 6}, {"type": "image", "img_path": "MbbTN9rPzC/tmp/276525ced93abfadde79b2233493926d1e5c4bff166ac3e3c8c10fcc71ed8dde.jpg", "img_caption": ["Figure 3: Comparing QACT with ReLU activation and Dinov2 (small) on CIFAR10C. We observe that, while at low severity of distortions QACT has a similar accuracy as existing pipelines, at higher levels the drop in accuracy is substantially smaller than existing approaches. With respect to calibration, we observe that the calibration error remains constant (up to standard deviations) across distortions. ", "(a) Accuracy "], "img_footnote": [], "page_idx": 6}, {"type": "text", "text": "", "page_idx": 6}, {"type": "text", "text": "", "page_idx": 6}, {"type": "text", "text": "", "page_idx": 6}, {"type": "text", "text": "", "page_idx": 6}, {"type": "text", "text": "", "page_idx": 6}, {"type": "text", "text": "", "page_idx": 6}, {"type": "image", "img_path": "MbbTN9rPzC/tmp/a6c5ddab3d80632c327ffc127743843048d4132cab28237beb3ae16525e8433c.jpg", "img_caption": [], "img_footnote": [], "page_idx": 7}, {"type": "text", "text": "Figure 4: (a) Dependence on Loss functions. Here we compare watershed with other popular loss functions \u2013 Triplet and Cross-Entropy when used with QACT. We see that watershed performs slightly better with respect to MAP. (b) Comparing QACT with other popular activations \u2013 ReLU/pReLU/SELU with respect to accuracy. (c) Comparing QACT with other popular activations \u2013 ReLU/pReLU/SELU with respect to Calibration Error (Marginal). From both (b) and (c) we can conclude that QACT is notably more robust across distortions than several of the existing activation. All the plots use ResNet18 with CIFAR10C dataset. ", "page_idx": 7}, {"type": "image", "img_path": "MbbTN9rPzC/tmp/d9f2a9712aabc3019254b3abab2fb2dd888b7f96504b587ebcfb514bf201dff0.jpg", "img_caption": ["Figure 5: Results on CIFAR100C/TinyImagenetC. We compare QACT $^+$ watershed to ReLU and DinoV2 small on CIFAR100C/TinyImagenetC dataset with ResNet18. Note that the observations are consistent with CIFAR10C. (a) shows how accuracy changes across distortions. Observe that QACT is similar to DINOv2(s) with respect to embedding quality across all distortions, even if DINOv2 has 22M parameters as compared to Resnet18 11M parameters and is trained on larger datasets. (b) shows how calibration error (marginal) changes across severities. While other approaches lead to an increase in calibration error, QACT has similar calibration error across distortions. "], "img_footnote": [], "page_idx": 7}, {"type": "text", "text": "245 At severity 5, QACT outperforms DINOv2. On the other hand, we observe that in figure 3b, the   \n246 calibration error stays consistent across distortions.   \n247 How much does QACT depend on the loss function? Figure 4a compares the watershed classifier   \n248 with other popular losses \u2013 Triplet and Cross-Entropy. We see that all the loss functions perform com  \n249 parably when used in conjunction with QACT. We observe that watershed has a slight improvement   \n250 when considering MAP and hence, we consider that as the default setting. However, we point out   \n251 that QACT is compatible with several loss functions as well.   \n252 QACT vs ReLU/pReLU/SELU activations: To verify that most existing activations do not share   \n253 the robustness property of QACT, we compare QACT with other activations in figures 4b and 4c. We   \n254 observe that QACT is greatly more robust with respect to distortions in both accuracy and calibration   \n255 error than other activation functions.   \n256 Results on Larger Datasets: To verify that our observations hold for larger datasets, we use   \n257 CIFAR100C/TinyImagenetC to compare the proposed QACT+watershed with existing approaches.   \n258 We observe on figure 5 that QACT performs comparably well as DINOv2, although DINOv2(s)   \n259 has 22M parameters and is trained on significantly larger datasets. Moreover, we also observe that   \n260 QACT has approximately constant calibration error across distortions, as opposed to a significantly   \n261 increasing calibration error for ReLU or DINOv2. ", "page_idx": 7}, {"type": "text", "text": "", "page_idx": 7}, {"type": "text", "text": "", "page_idx": 7}, {"type": "text", "text": "", "page_idx": 7}, {"type": "text", "text": "", "page_idx": 8}, {"type": "text", "text": "262 5 Conclusion And Future Work ", "text_level": 1, "page_idx": 8}, {"type": "text", "text": "263 To summarize, traditional classification systems do not consider the \u201ccontext distributions\u201d when   \n264 assigning labels. In this article, we propose a framework to achieve this by \u2013 (i) Making the activation   \n265 adaptive by using quantiles and (ii) Learning a kernel instead of the boundary for the last layer. We   \n266 show that our method is more robust to distortions by considering MNISTC, CIFAR10C, CIFAR100C,   \n267 TinyImagenetC datasets across varying architectures.   \n268 The scope of this article is to provide a proof of concept and a framework for performing inference in   \n269 a context-dependent manner. We outline several potential directions for future research:   \n270 I. The key idea in our proposed approach is that the quantiles capture the distribution of each   \n271 neuron from the batch of samples, providing outputs accordingly. This poses a challenge for   \n272 inference, and we have discussed two potential solutions: (i) remember the quantiles and   \n273 density estimates for single sample evaluation, or (ii) ensure that a batch of samples from   \n274 the same distribution is processed together. We adopt the latter method in this article. An   \n275 alternative approach would be to learn the distribution of each neuron using auxiliary loss   \n276 functions, adjusting these distributions to fit the domain at test time. This gives us more   \n277 control over the network at test time compared to current workflows.   \n278 II. Since the aim of the article was to establish a proof-of-concept, we did not focus on scaling,   \n279 and use only a single GPU for all the experiments. To extend it to multi-GPU training,   \n280 one needs to synchronize the quantiles across GPU, in a similar manner as that for Batch  \n281 Normalization. We expect this to improve the statistics, and to allow considerably larger   \n282 batches of training.   \n283 III. On the theoretical side, there is an interesting analogy between our quantile activation and   \n284 how a biological neuron behaves. It is known that when the inputs to a biological neuron   \n285 change, the neuron adapts to these changes [7]. Quantile activation does something very   \n286 similar, which leads to an open question \u2013 can we establish a formal link between the   \n287 adaptability of a biological neuron and the accuracy of classification systems?   \n288 IV. Another theoretical direction to explore involves considering distributions not just at the   \n289 neuron level, but at the layer level, introducing a high-dimensional aspect to the problem.   \n290 The main challenge here is defining and utilizing high dimensional quantiles, which remains   \n291 an open question [21].   \n292 Broad Impact: In this article, we propose an approach to maintain calibration and generalization   \n293 across small distortions. While, we do not foresee any direct societal consequences of our work, we   \n294 expect the potential future consequences of the technique to reduce the bias in the following ways   \n295 \u2013 (i) Since we do not assume normal distribution, our approach is likely to handle long tails better   \n296 than existing methods. This would help in reducing the dataset bias where marginal groups are less   \n297 represented. (ii) Note that the output of each QACT layer is a uniform distribution. This can allow us   \n298 to understand the working of each layer in isolation and possibly reduce the black-box nature of the   \n299 current classification systems. (iii) Moreover, by directly modifying the context distribution of each   \n300 neuron, one can easily make the networks more reliable without resorting to expensive re-training the   \n301 entire network. ", "page_idx": 8}, {"type": "text", "text": "", "page_idx": 8}, {"type": "text", "text": "", "page_idx": 8}, {"type": "text", "text": "", "page_idx": 8}, {"type": "text", "text": "302 References ", "text_level": 1, "page_idx": 8}, {"type": "text", "text": "303 [1] Kei Akuzawa, Yusuke Iwasawa, and Yutaka Matsuo. Adversarial invariant feature learning with   \n304 accuracy constraint for domain generalization. In European Conf. Mach. Learning, 2019.   \n305 [2] Mart\u00edn Arjovsky, L\u00e9on Bottou, Ishaan Gulrajani, and David Lopez-Paz. Invariant risk mini  \n306 mization. arXiv:1907.02893, 2019.   \n307 [3] Lei Jimmy Ba, Jamie Ryan Kiros, and Geoffrey E. Hinton. Layer normalization.   \n308 arXiv:1607.06450, 2016.   \n309 [4] Jens Behrmann, Paul Vicol, Kuan-Chieh Wang, Roger B. Grosse, and J\u00f6rn-Henrik Jacobsen.   \n310 Understanding and mitigating exploding inverses in invertible neural networks. In Artificial   \n311 Intelligence and Statistics, 2021.   \n312 [5] Aditya Challa, Snehanshu Saha, and Soma Dhavala. Quantprob: Generalizing probabilities   \n313 along with predictions for a pre-trained classifier. arXiv:2304.12766, 2023.   \n314 [6] Aditya Challa, Sravan Danda, and Laurent Najman. A novel approach to regularising 1nn   \n315 classifier for improved generalization. arXiv:2402.08405, 2024.   \n316 [7] Colin WG Clifford, Michael A Webster, Garrett B Stanley, Alan A Stocker, Adam Kohn,   \n317 Tatyana O Sharpee, and Odelia Schwartz. Visual adaptation: Neural, psychological and   \n318 computational aspects. Vision research, 2007.   \n319 [8] Alexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov, Dirk Weissenborn, Xiaohua Zhai,   \n320 Thomas Unterthiner, Mostafa Dehghani, Matthias Minderer, Georg Heigold, Sylvain Gelly,   \n321 Jakob Uszkoreit, and Neil Houlsby. An image is worth 16x16 words: Transformers for image   \n322 recognition at scale. In Int. Conf. on Learning Representations, 2021.   \n323 [9] Qi Dou, Daniel Coelho de Castro, Konstantinos Kamnitsas, and Ben Glocker. Domain gener  \n324 alization via model-agnostic learning of semantic features. In Neural Inform. Process. Syst.,   \n325 2019.   \n326 [10] Kunihiko Fukushima. Correction to \"visual feature extraction by a multilayered network of   \n327 analog threshold elements\". IEEE Trans. Syst. Sci. Cybern., 1970.   \n328 [11] Muhammad Ghifary, W. Bastiaan Kleijn, Mengjie Zhang, and David Balduzzi. Domain   \n329 generalization for object recognition with multi-task autoencoders. In Proc. Int. Conf. Comput.   \n330 Vision, 2015.   \n331 [12] Zhongyi Han, Guanglin Zhou, Rundong He, Jindong Wang, Tailin Wu, Yilong Yin, Salman H.   \n332 Khan, Lina Yao, Tongliang Liu, and Kun Zhang. How well does gpt-4v(ision) adapt to   \n333 distribution shifts? A preliminary investigation. arXiv:2312.07424, 2023.   \n334 [13] Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Delving deep into rectifiers:   \n335 Surpassing human-level performance on imagenet classification. In Proc. Int. Conf. Comput.   \n336 Vision, 2015.   \n337 [14] Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep residual learning for image   \n338 recognition. In Proc. Conf. Comput. Vision Pattern Recognition, 2016.   \n339 [15] Dan Hendrycks and Thomas G. Dietterich. Benchmarking neural network robustness to common   \n340 corruptions and perturbations. In Int. Conf. on Learning Representations, 2019.   \n341 [16] Shoubo Hu, Kun Zhang, Zhitang Chen, and Laiwan Chan. Domain generalization via multido  \n342 main discriminant analysis. In Uncertainity in Artificial Intelligence, 2019.   \n343 [17] Bincheng Huang, Si Chen, Fan Zhou, Cheng Zhang, and Feng Zhang. Episodic training for   \n344 domain generalization using latent domains. In Int. Conf. on Cogni. Systems and Signal Process.,   \n345 2020.   \n346 [18] Gao Huang, Zhuang Liu, Laurens van der Maaten, and Kilian Q. Weinberger. Densely connected   \n347 convolutional networks. In 2017 IEEE Conference on Computer Vision and Pattern Recognition,   \n348 CVPR 2017, Honolulu, HI, USA, July 21-26, 2017, pages 2261\u20132269. IEEE Computer Society,   \n349 2017. doi: 10.1109/CVPR.2017.243. URL https://doi.org/10.1109/CVPR.2017.243.   \n350 [19] Sergey Ioffe and Christian Szegedy. Batch normalization: Accelerating deep network training   \n351 by reducing internal covariate shift. In Int. Conf. Mach. Learning, 2015.   \n352 [20] G\u00fcnter Klambauer, Thomas Unterthiner, Andreas Mayr, and Sepp Hochreiter. Self-normalizing   \n353 neural networks. In Neural Inform. Process. Syst., 2017.   \n354 [21] Roger Koenker. Quantile Regression. Econometric Society Monographs. Cambridge University   \n355 Press, 2005. doi: 10.1017/CBO9780511754098.   \n356 [22] Agustinus Kristiadi, Matthias Hein, and Philipp Hennig. Being bayesian, even just a bit, fixes   \n357 overconfidence in relu networks. In Int. Conf. Mach. Learning, 2020.   \n358 [23] Ananya Kumar, Percy Liang, and Tengyu Ma. Verified uncertainty calibration. In Neural Inform.   \n359 Process. Syst., 2019.   \n360 [24] Zhong Li and Matthijs van Leeuwen. Explainable contextual anomaly detection using quantile   \n361 regression forests. Data Min. Knowl. Discov., 2023.   \n362 [25] Norman Mu and Justin Gilmer. MNIST-C: A robustness benchmark for computer vision.   \n363 arXiv:1906.02337, 2019.   \n364 [26] Vinod Nair and Geoffrey E. Hinton. Rectified linear units improve restricted boltzmann   \n365 machines. In Int. Conf. Mach. Learning, 2010.   \n366 [27] Maxime Oquab, Timoth\u00e9e Darcet, Th\u00e9o Moutakanni, Huy Vo, Marc Szafraniec, Vasil Khalidov,   \n367 Pierre Fernandez, Daniel Haziza, Francisco Massa, Alaaeldin El-Nouby, Mahmoud Assran,   \n368 Nicolas Ballas, Wojciech Galuba, Russell Howes, Po-Yao Huang, Shang-Wen Li, Ishan Misra,   \n369 Michael G. Rabbat, Vasu Sharma, Gabriel Synnaeve, Hu Xu, Herv\u00e9 J\u00e9gou, Julien Mairal, Patrick   \n370 Labatut, Armand Joulin, and Piotr Bojanowski. Dinov2: Learning robust visual features without   \n371 supervision. arXiv:2304.07193, 2023.   \n372 [28] Sinno Jialin Pan and Qiang Yang. A survey on transfer learning. IEEE Trans. Knowl. Data   \n373 Eng., 2010.   \n374 [29] Vihari Piratla, Praneeth Netrapalli, and Sunita Sarawagi. Efficient domain generalization via   \n375 common-specific low-rank decomposition. In Int. Conf. Mach. Learning, 2020.   \n376 [30] Tejas Prashanth, Snehanshu Saha, Sumedh Basarkod, Suraj Aralihalli, Soma S. Dhavala,   \n377 Sriparna Saha, and Raviprasad Aduri. Lipgene: Lipschitz continuity guided adaptive learning   \n378 rates for fast convergence on microarray expression data sets. IEEE ACM Trans. Comput. Biol.   \n379 Bioinform., 2022.   \n380 [31] Tim Salimans and Diederik P. Kingma. Weight normalization: A simple reparameterization to   \n381 accelerate training of deep neural networks. In Neural Inform. Process. Syst., 2016.   \n382 [32] Aditi Seetha, Satyendra Singh Chouhan, Emmanuel S Pilli, Vaskar Raychoudhury, and Snehan  \n383 shu Saha. Dievd-sf: Disruptive event detection using continual machine learning with selective   \n384 forgetting. IEEE Transactions on Computational Social Systems, 2024.   \n385 [33] Hogeon Seo, Seunghyoung Ryu, Jiyeon Yim, Junghoon Seo, and Yonggyun Yu. Quantile   \n386 autoencoder for anomaly detection. In AAAI,Workshop on AI for Design and Manufacturing   \n387 (ADAM), 2022.   \n388 [34] Zheyan Shen, Peng Cui, Tong Zhang, and Kun Kuang. Stable learning via sample reweighting.   \n389 In AAAI Conf. on Artificial Intelligence, 2020.   \n390 [35] Karen Simonyan and Andrew Zisserman. Very deep convolutional networks for large-scale   \n391 image recognition. In Int. Conf. on Learning Representations, 2015.   \n392 [36] Anuj Tambwekar, Anirudh Maiya, Soma S. Dhavala, and Snehanshu Saha. Estimation and   \n393 applications of quantiles in deep binary classification. IEEE Trans. Artif. Intell., 2022.   \n394 [37] Fuzhen Zhuang, Zhiyuan Qi, Keyu Duan, Dongbo Xi, Yongchun Zhu, Hengshu Zhu, Hui Xiong,   \n395 and Qing He. A comprehensive survey on transfer learning. Proc. IEEE, 2021. ", "page_idx": 8}, {"type": "text", "text": "", "page_idx": 9}, {"type": "text", "text": "", "page_idx": 10}, {"type": "image", "img_path": "MbbTN9rPzC/tmp/6378be1acb21d86efbc784517ed6f7b57237231596fcecefeed7977ba56de5c4.jpg", "img_caption": ["Figure 6: Comparing QACT with ReLU activation and Dinov2 (small). "], "img_footnote": [], "page_idx": 11}, {"type": "text", "text": "396 A Experiment details for figure 1 ", "text_level": 1, "page_idx": 11}, {"type": "text", "text": "397 We consider the features obtained from ResNet18 with both QACT and RelU activations for the   \n398 datasets of CIFAR10C with gaussian_noise at all the severity levels. Hence, we have 6 datasets   \n399 in total. To use TSNE for visualization, we consider 1000 samples from each dataset and obtain   \n400 the combined TSNE visualizations. Each figure shows a scatter plot of the 2d visualization for the   \n401 corresponding dataset. ", "page_idx": 11}, {"type": "text", "text": "402 B Compute Resources and Other Experimental Details ", "text_level": 1, "page_idx": 11}, {"type": "text", "text": "403 All experiments were performed on a single NVidia GPU with 32GB memory with Intel Xeon CPU   \n404 (10 cores). For training, we perform an 80:20 split of the train dataset with seed 42 for reproducibility.   \n405 All networks are initialized using default pytorch initialization technique.   \n406 We use Adam optimizer with initial learning rate $1e-3$ . We use ReduceLRonPlateau learning   \n407 rate scheduler with parameters \u2013 factor $=\\!0.1$ , patience $\\mathrel{\\left<=}50\\right>$ , cooldown $_{1=10}$ , threshold $=\\!0.01$ , thresh  \n408 old_mode $=$ abs, min_lr=1e-6. We monitor the validation accuracy for learning rate scheduling. We   \n409 also use early_stopping when the validation accuracy does not increase by 0.001. ", "page_idx": 11}, {"type": "text", "text": "", "page_idx": 11}, {"type": "text", "text": "410 C Extended Results Section ", "text_level": 1, "page_idx": 11}, {"type": "text", "text": "411 Comparing QACT $^+$ watershed and ReLU $^+$ Cross-Entropy: Figure 6 shows the corresponding   \n412 results. The first experiment compares QACT $^+$ watershed with ReLU $^+$ Cross-Entropy on two   \n413 standard networks \u2013 ResNet18 and DenseNet. With respect to accuracy, we observe that while at   \n414 severity 0, ReLU $^+$ Cross-Entropy slightly outperforms QACT $^+$ watershed, as severity increases   \n415 QACT $^+$ watershed is far more stable. We even outperform DinoV2(small) (22M parameters) at   \n416 severity 5. Moreover, with respect to calibration error, we see a consistent trend across distortions.   \n417 As [5] argues, this helps in building more robust systems compared to one where calibration error   \n418 increases across distortions.   \n419 Does loss function make a lot of difference? Figure 7 compares three different loss functions   \n420 Watershed, Triplet and Cross-Entropy when used in conjunction with QACT. We observe similar   \n421 trends across all loss functions. However, Watershed performs better with respect to Mean Average   \n422 Precision (MAP) and hence we use this as a default strategy.   \n423 Why Mean-Average-Precision? \u2013 We argue that the key indicator of distortion invariance should   \n424 be the quality of embedding. While, accuracy (as measured by a linear classifier) is a good metric,   \n425 a better one would be to measure the Mean-Average-Precision. With respect to calibration error,   \n426 due to the scale on the Y-axis, the figures suggest reducing calibration error. However, the standard   \n427 deviations overlap, and hence, these are assumed to be constant across distortions.   \n428 How well does watershed perform when used with ReLU activation? Figure 8 shows the   \n429 corresponding results. We observe that both the watershed loss and cross-entropy have large overlaps   \n430 in the standard deviations at all severity levels. So, this shows that, when used in conjunction with   \n431 ReLU watershed and cross-entropy loss are very similar. But in conjunction with QACT, we see that   \n432 watershed has a slightly higher Mean-Average-Precision.   \n433 What if we consider an easy classification task? In figure 9, we perform the comparison of   \n434 QACT+Watershed and ReLU and cross-entropy on MNISTC dataset. Across different architectures,   \n435 we observe a lot less variation (standard deviation) of QACT+Watershed compared to RelU and   \n436 cross-entropy. This again suggests robustness against distortions of QACT $\\dot{+}$ Watershed.   \n437 Comparing with other popular activations: Figures 10 and 11 shows the comparison of QACT   \n438 with ReLU, pReLU and SeLU. We observe the same trend across ReLU, pReLU and SeLU, while   \n439 QACT is far more stable across distortions.   \n440 Results on CIFAR100/TinyImagenetC: Figure 12 compares QACT $^+$ Watershed and ReLU $^+$ Cross  \n441 Entropy on CIFAR100C dataset. We also include the results of QACT $^+$ Cross-Entropy vs.   \n442 ReLU $^+$ Cross-Entropy on TinyImagenetC. The results are consistent with what we observe on   \n443 CIFAR10C, and hence, draw the same conclusions as before. ", "page_idx": 11}, {"type": "image", "img_path": "MbbTN9rPzC/tmp/a2a203b9856536228b618a29d98013845da6df1125b84cd3a19417ef89c0d12b.jpg", "img_caption": ["Figure 7: Triplet vs Watershed vs Cross-Entropy "], "img_footnote": [], "page_idx": 12}, {"type": "text", "text": "", "page_idx": 12}, {"type": "text", "text": "", "page_idx": 12}, {"type": "text", "text": "", "page_idx": 12}, {"type": "text", "text": "", "page_idx": 12}, {"type": "text", "text": "", "page_idx": 12}, {"type": "text", "text": "", "page_idx": 12}, {"type": "image", "img_path": "MbbTN9rPzC/tmp/a8a61f4195b5d2ebbd738803146e2550fc70c25a2d2fdf49c853261a3c61d078.jpg", "img_caption": ["(c) Marginal Calibration Error ", "Figure 8: Watershed vs Cross-Entropy when using ReLU activation ", "(d) Top-Label Calibration Error "], "img_footnote": [], "page_idx": 13}, {"type": "image", "img_path": "MbbTN9rPzC/tmp/9f4cbecff1715c9f553ae59979f9538cc501071af191176bc5aebf75fa826065.jpg", "img_caption": ["(c) Marginal Calibration Error ", "Figure 9: Results on MNIST ", "(d) Top-Label Calibration Error "], "img_footnote": [], "page_idx": 13}, {"type": "image", "img_path": "MbbTN9rPzC/tmp/cca33f03c60c0d1e65a995a49950eee85329d5e1ff49cb0530d944595c11d75d.jpg", "img_caption": ["(c) Marginal Calibration Error ", "Figure 10: QACTvs ReLU vs pReLU vs Selu activations on ResNet18 ", "(d) Top-Label Calibration Error "], "img_footnote": [], "page_idx": 14}, {"type": "image", "img_path": "MbbTN9rPzC/tmp/a00a973f0fd4ca24a10e531feb9b50224b0918aba2a5caa4ccd9d8512198f182.jpg", "img_caption": ["(c) Marginal Calibration Error ", "Figure 11: QACTvs ReLU vs pReLU vs Selu activations on Densenet ", "(d) Top-Label Calibration Error "], "img_footnote": [], "page_idx": 14}, {"type": "image", "img_path": "MbbTN9rPzC/tmp/e0198ea606b164b8dc06f6999cf6c23551325fb90dc7ba7d6afeb6df478fbd17.jpg", "img_caption": ["(c) Marginal Calibration Error ", "Figure 12: QACTvs ReLU on Resnet18+CIFAR100 ", "(d) Top-Label Calibration Error "], "img_footnote": [], "page_idx": 15}, {"type": "image", "img_path": "MbbTN9rPzC/tmp/4de48abc810d082d21ec6a1ce1992d9694fe18d706a213c9d3624a66c265adb9.jpg", "img_caption": ["(c) Marginal Calibration Error ", "(d) Top-Label Calibration Error "], "img_footnote": [], "page_idx": 15}, {"type": "text", "text": "Figure 13: Effect of Quantile Classifier. We use ResNet18 and DinoV2 architectures on CIFAR10. ", "page_idx": 15}, {"type": "image", "img_path": "MbbTN9rPzC/tmp/fadbf138fb2bf8179f70cdfb8ff8b466a0a089c9311365d3df48bb22268908f7.jpg", "img_caption": [], "img_footnote": [], "page_idx": 16}, {"type": "text", "text": "Figure 14: Effect of Quantile Classifier. We use ResNet18 and DinoV2 architectures on CIFAR100. ", "page_idx": 16}, {"type": "text", "text": "444 Effect of Quantile Classifier: Figures 13 and 14 shows the effect of quantile classifier on standard   \n445 ResNet10/DinoV2 outputs with CIFAR10C/CIFAR100C datasets. While the accuracy values are   \n446 almost equivalent, we observe a \u201cflatter\u201d trend of the calibration errors, sometimes reducing the error   \n447 as in the case of CIFAR100C. ", "page_idx": 16}, {"type": "text", "text": "448 D Watershed Loss ", "text_level": 1, "page_idx": 16}, {"type": "text", "text": "449 The authors in [6] proposed a novel classifier \u2013 watershed classifier, which works by learning   \n450 similarities instead of the boundaries. Below we give the brief idea of the loss function, and refer the   \n451 reader to the original paper for further details.   \n2 1. Let $({\\pmb x}_{i},y_{i})$ denote the samples in each batch, and let $f_{\\theta}$ denote the embedding network.   \n3 $f_{\\theta}(\\mathbf{\\boldsymbol{x}}_{i})$ denotes the corresponding embedding.   \n2. Starting from randomly selected seeds in the batch, propagate the labels to all the samples.   \n5 Let $\\hat{y_{i}}$ denote the estimated samples. For each $f_{\\theta}(\\mathbf{x}_{i})$ and for each label $l$ , obtain the nearest   \n6 neighbour in the samples in the set, ", "page_idx": 16}, {"type": "text", "text": "", "page_idx": 16}, {"type": "equation", "text": "$$\n{\\cal{S}}_{l}=\\{f_{\\theta}({\\pmb x}_{i})\\mid\\hat{y}_{i}=y_{i}=l\\}\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "457   \n458   \n459 ", "page_idx": 16}, {"type": "text", "text": "that is, all the samples of class $l$ labelled correctly. Denote this nearest neighbour using $f_{\\theta}({\\bf{\\boldsymbol{x}}}_{i,l,1n n})$ . 3. Then the loss is given by, $\\mathrm{Watershed\\;Loss}=\\frac{-1}{n_{\\mathrm{samples}}}\\sum_{i=1}^{n_{\\mathrm{samples}}}\\sum_{l=1}^{L}I[y_{i}=l]\\log\\left(\\frac{\\exp{(-\\|f_{\\theta}(\\mathbf{x}_{i})-f_{\\theta}(\\mathbf{x}_{i,l,1n n})\\|)}}{\\sum_{j=1}^{L}\\exp{(-\\|f_{\\theta}(\\mathbf{x}_{i})-f_{\\theta}(\\mathbf{x}_{i,j,1n n})\\|)}}\\right)$ 10) ", "page_idx": 16}, {"type": "text", "text": "460 Why Watershed Loss?: Observe that the loss in equation 10 implicitly learns representations   \n461 consistent with the RBF kernel, which is known to be translation invariant. Minimizing this loss   \n462 function, hence, will learn translation invariant kernels. This is important for obtaining networks   \n463 robust to distortions.   \n464 If one uses (say) Cross Entropy loss, then the features learned would be such that the classes are   \n465 linearly separable. Contrast this with watershed, which instead learns a similarity between two points   \n466 in a translation invariant manner.   \n467 Remark: Observe that the watershed loss is very similar to metric learning losses. The authors in   \n468 [6] claim that this offers better generalization, and show that this is consistent with 1NN classifier.   \n469 Moreover, they show that this classifier (without considering $f_{\\theta})$ has a VC dimension which is equal   \n470 to the number of classes. While metric learning losses are similar, there is no such guarantee with   \n471 respect to classification. This motivated our choice of using watershed loss over other metric learning   \n472 losses.   \n474 The checklist is designed to encourage best practices for responsible machine learning research,   \n475 addressing issues of reproducibility, transparency, research ethics, and societal impact. Do not remove   \n476 the checklist: The papers not including the checklist will be desk rejected. The checklist should   \n477 follow the references and precede the (optional) supplemental material. The checklist does NOT   \n478 count towards the page limit.   \n479 Please read the checklist guidelines carefully for information on how to answer these questions. For   \n480 each question in the checklist:   \n481 \u2022 You should answer [Yes] , [No] , or [NA] .   \n482 \u2022 [NA] means either that the question is Not Applicable for that particular paper or the   \n483 relevant information is Not Available.   \n484 \u2022 Please provide a short (1\u20132 sentence) justification right after your answer (even for NA).   \n485 The checklist answers are an integral part of your paper submission. They are visible to the   \n486 reviewers, area chairs, senior area chairs, and ethics reviewers. You will be asked to also include it   \n487 (after eventual revisions) with the final version of your paper, and its final version will be published   \n488 with the paper.   \n489 The reviewers of your paper will be asked to use the checklist as one of the factors in their evaluation.   \n490 While \"[Yes] \" is generally preferable to \"[No] \", it is perfectly acceptable to answer \"[No] \" provided a   \n491 proper justification is given (e.g., \"error bars are not reported because it would be too computationally   \n492 expensive\" or \"we were unable to find the license for the dataset we used\"). In general, answering   \n493 \"[No] \" or \"[NA] \" is not grounds for rejection. While the questions are phrased in a binary way, we   \n494 acknowledge that the true answer is often more nuanced, so please just use your best judgment and   \n495 write a justification to elaborate. All supporting evidence can appear either in the main paper or the   \n496 supplemental material, provided in appendix. If you answer [Yes] to a question, in the justification   \n497 please point to the section(s) where related material for the question can be found. ", "page_idx": 16}, {"type": "text", "text": "", "page_idx": 17}, {"type": "text", "text": "", "page_idx": 17}, {"type": "text", "text": "", "page_idx": 18}, {"type": "text", "text": "", "page_idx": 18}, {"type": "text", "text": "", "page_idx": 18}, {"type": "text", "text": "", "page_idx": 18}, {"type": "text", "text": "", "page_idx": 18}, {"type": "text", "text": "498 IMPORTANT, please: ", "page_idx": 18}, {"type": "text", "text": "499 \u2022 Delete this instruction block, but keep the section heading \u201cNeurIPS paper checklist\",   \n500 \u2022 Keep the checklist subsection headings, questions/answers and guidelines below.   \n501 \u2022 Do not modify the questions and only use the provided macros for your answers.   \n502 1. Claims   \n503 Question: Do the main claims made in the abstract and introduction accurately reflect the   \n504 paper\u2019s contributions and scope?   \n505 Answer: [Yes]   \n506 Justification: Yes. The main contribution is a proof-of-concept that one should move away   \n507 from single point estimation for better generalization across distortions.   \n508 Guidelines:   \n509 \u2022 The answer NA means that the abstract and introduction do not include the claims   \n510 made in the paper.   \n511 \u2022 The abstract and/or introduction should clearly state the claims made, including the   \n512 contributions made in the paper and important assumptions and limitations. A No or   \n513 NA answer to this question will not be perceived well by the reviewers.   \n514 \u2022 The claims made should match theoretical and experimental results, and reflect how   \n515 much the results can be expected to generalize to other settings.   \n516 \u2022 It is fine to include aspirational goals as motivation as long as it is clear that these goals   \n517 are not attained by the paper.   \n518 2. Limitations   \n519 Question: Does the paper discuss the limitations of the work performed by the authors?   \n520 Answer: [Yes]   \n521 Justification: Since, the scope is only a proof-of-concept, we have not considered scaling   \n522 to large datasets/models in this work. Scaling these ideas would require rethinking current   \n523 strategies and does not fit perfectly into existing framework. Moreover, the proposed   \n524 approach slightly more resource intensive than ReLU activation.   \n525 Guidelines: ", "page_idx": 18}, {"type": "text", "text": "\u2022 The answer NA means that the paper has no limitation while the answer No means that the paper has limitations, but those are not discussed in the paper.   \n\u2022 The authors are encouraged to create a separate \"Limitations\" section in their paper.   \n\u2022 The paper should point out any strong assumptions and how robust the results are to violations of these assumptions (e.g., independence assumptions, noiseless settings, model well-specification, asymptotic approximations only holding locally). The authors should reflect on how these assumptions might be violated in practice and what the implications would be.   \n\u2022 The authors should reflect on the scope of the claims made, e.g., if the approach was only tested on a few datasets or with a few runs. In general, empirical results often depend on implicit assumptions, which should be articulated.   \n\u2022 The authors should reflect on the factors that influence the performance of the approach. For example, a facial recognition algorithm may perform poorly when image resolution is low or images are taken in low lighting. Or a speech-to-text system might not be used reliably to provide closed captions for online lectures because it fails to handle technical jargon.   \n\u2022 The authors should discuss the computational efficiency of the proposed algorithms and how they scale with dataset size.   \n\u2022 If applicable, the authors should discuss possible limitations of their approach to address problems of privacy and fairness.   \n\u2022 While the authors might fear that complete honesty about limitations might be used by reviewers as grounds for rejection, a worse outcome might be that reviewers discover limitations that aren\u2019t acknowledged in the paper. The authors should use their best judgment and recognize that individual actions in favor of transparency play an important role in developing norms that preserve the integrity of the community. Reviewers will be specifically instructed to not penalize honesty concerning limitations. ", "page_idx": 19}, {"type": "text", "text": "3. Theory Assumptions and Proofs ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "526   \n527   \n528   \n529   \n530   \n531   \n532   \n533   \n534   \n535   \n536   \n537   \n538   \n539   \n540   \n541   \n542   \n543   \n544   \n545   \n546   \n547   \n548   \n549   \n550   \n551   \n552   \n553   \n554   \n555   \n556   \n557   \n558   \n559   \n560   \n561   \n562   \n563   \n564   \n565   \n566   \n567   \n568   \n569   \n570   \n571   \n572   \n573   \n574   \n575   \n576   \n577   \n578   \n579   \n580   \n581   \n582   \n583   \n584 ", "page_idx": 19}, {"type": "text", "text": "Question: For each theoretical result, does the paper provide the full set of assumptions and   \na complete (and correct) proof?   \nAnswer: [NA]   \nJustification: We do not consider theoretical aspects in this article. While there are interesting   \ntheoretical connections, we leave it for future work.   \nGuidelines: \u2022 The answer NA means that the paper does not include theoretical results. \u2022 All the theorems, formulas, and proofs in the paper should be numbered and crossreferenced. \u2022 All assumptions should be clearly stated or referenced in the statement of any theorems. \u2022 The proofs can either appear in the main paper or the supplemental material, but if they appear in the supplemental material, the authors are encouraged to provide a short proof sketch to provide intuition. \u2022 Inversely, any informal proof provided in the core of the paper should be complemented by formal proofs provided in appendix or supplemental material. \u2022 Theorems and Lemmas that the proof relies upon should be properly referenced. ", "page_idx": 19}, {"type": "text", "text": "4. Experimental Result Reproducibility ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "Question: Does the paper fully disclose all the information needed to reproduce the main ex  \nperimental results of the paper to the extent that it affects the main claims and/or conclusions   \nof the paper (regardless of whether the code and data are provided or not)?   \nAnswer: [Yes]   \nJustification: We provide an anonymous link to generate all the results provided in the article.   \nMoreover, we describe all the hyper-parameters used in the appendix as well.   \nGuidelines: \u2022 The answer NA means that the paper does not include experiments. \u2022 If the paper includes experiments, a No answer to this question will not be perceived well by the reviewers: Making the paper reproducible is important, regardless of whether the code and data are provided or not. \u2022 If the contribution is a dataset and/or model, the authors should describe the steps taken to make their results reproducible or verifiable. \u2022 Depending on the contribution, reproducibility can be accomplished in various ways. For example, if the contribution is a novel architecture, describing the architecture fully might suffice, or if the contribution is a specific model and empirical evaluation, it may be necessary to either make it possible for others to replicate the model with the same dataset, or provide access to the model. In general. releasing code and data is often one good way to accomplish this, but reproducibility can also be provided via detailed instructions for how to replicate the results, access to a hosted model (e.g., in the case of a large language model), releasing of a model checkpoint, or other means that are appropriate to the research performed. \u2022 While NeurIPS does not require releasing code, the conference does require all submissions to provide some reasonable avenue for reproducibility, which may depend on the nature of the contribution. For example (a) If the contribution is primarily a new algorithm, the paper should make it clear how to reproduce that algorithm. (b) If the contribution is primarily a new model architecture, the paper should describe the architecture clearly and fully. (c) If the contribution is a new model (e.g., a large language model), then there should either be a way to access this model for reproducing the results or a way to reproduce the model (e.g., with an open-source dataset or instructions for how to construct the dataset). (d) We recognize that reproducibility may be tricky in some cases, in which case authors are welcome to describe the particular way they provide for reproducibility. In the case of closed-source models, it may be that access to the model is limited in some way (e.g., to registered users), but it should be possible for other researchers to have some path to reproducing or verifying the results.   \n5. Open access to data and code Question: Does the paper provide open access to the data and code, with sufficient instructions to faithfully reproduce the main experimental results, as described in supplemental material? Answer: [Yes] Justification: We provide the code using an anonymous link at https://anonymous. 4open.science/r/QuantAct-2B41. The datasets are all public datasets which can be downloaded. Guidelines: \u2022 The answer NA means that paper does not include experiments requiring code. \u2022 Please see the NeurIPS code and data submission guidelines (https://nips.cc/ public/guides/CodeSubmissionPolicy) for more details. \u2022 While we encourage the release of code and data, we understand that this might not be possible, so \u201cNo\u201d is an acceptable answer. Papers cannot be rejected simply for not including code, unless this is central to the contribution (e.g., for a new open-source benchmark). \u2022 The instructions should contain the exact command and environment needed to run to reproduce the results. See the NeurIPS code and data submission guidelines (https: //nips.cc/public/guides/CodeSubmissionPolicy) for more details. \u2022 The authors should provide instructions on data access and preparation, including how to access the raw data, preprocessed data, intermediate data, and generated data, etc. \u2022 The authors should provide scripts to reproduce all experimental results for the new proposed method and baselines. If only a subset of experiments are reproducible, they should state which ones are omitted from the script and why. \u2022 At submission time, to preserve anonymity, the authors should release anonymized versions (if applicable). \u2022 Providing as much information as possible in supplemental material (appended to the paper) is recommended, but including URLs to data and code is permitted.   \n6. Experimental Setting/Details Question: Does the paper specify all the training and test details (e.g., data splits, hyperparameters, how they were chosen, type of optimizer, etc.) necessary to understand the results? ", "page_idx": 19}, {"type": "text", "text": "", "page_idx": 20}, {"type": "text", "text": "585   \n586   \n587   \n588   \n589   \n590   \n591   \n592   \n593   \n594   \n595   \n596   \n597   \n598   \n599   \n600   \n601   \n602   \n603   \n604   \n605   \n606   \n607   \n608   \n609   \n610   \n611   \n612   \n613   \n614   \n615   \n616   \n617   \n618   \n619   \n620   \n621   \n622   \n623   \n624   \n625   \n626   \n627   \n628   \n629   \n630   \n631   \n632   \n633   \n634   \n635   \n636   \n637   \n638   \n639   \n640   \n641   \n642   \n643 ", "page_idx": 20}, {"type": "text", "text": "Answer: [Yes]   \nJustification: We explain the experimental setting in complete detail in the article.   \nGuidelines: \u2022 The answer NA means that the paper does not include experiments. ", "page_idx": 20}, {"type": "text", "text": "\u2022 The experimental setting should be presented in the core of the paper to a level of detail that is necessary to appreciate the results and make sense of them. \u2022 The full details can be provided either with the code, in appendix, or as supplemental material. ", "page_idx": 21}, {"type": "text", "text": "7. Experiment Statistical Significance ", "text_level": 1, "page_idx": 21}, {"type": "text", "text": "Question: Does the paper report error bars suitably and correctly defined or other appropriate   \ninformation about the statistical significance of the experiments?   \nAnswer: [Yes] Justification: The datasets used incorporate 15 kinds of distortions across 5 severity levels. We report the error bars across the 15 kinds of distortions which should provide a good picture of the reliability of the results.   \nGuidelines:   \n\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 The authors should answer \"Yes\" if the results are accompanied by error bars, confidence intervals, or statistical significance tests, at least for the experiments that support the main claims of the paper.   \n\u2022 The factors of variability that the error bars are capturing should be clearly stated (for example, train/test split, initialization, random drawing of some parameter, or overall run with given experimental conditions).   \n\u2022 The method for calculating the error bars should be explained (closed form formula, call to a library function, bootstrap, etc.)   \n\u2022 The assumptions made should be given (e.g., Normally distributed errors).   \n\u2022 It should be clear whether the error bar is the standard deviation or the standard error of the mean.   \n\u2022 It is OK to report 1-sigma error bars, but one should state it. The authors should preferably report a 2-sigma error bar than state that they have a $96\\%$ CI, if the hypothesis of Normality of errors is not verified.   \n\u2022 For asymmetric distributions, the authors should be careful not to show in tables or figures symmetric error bars that would yield results that are out of range (e.g. negative error rates).   \n\u2022 If error bars are reported in tables or plots, The authors should explain in the text how they were calculated and reference the corresponding figures or tables in the text. ", "page_idx": 21}, {"type": "text", "text": "", "page_idx": 21}, {"type": "text", "text": "", "page_idx": 21}, {"type": "text", "text": "644   \n645   \n646   \n647   \n648   \n649   \n650   \n651   \n652   \n653   \n654   \n655   \n656   \n657   \n658   \n659   \n660   \n661   \n662   \n663   \n664   \n665   \n666   \n667   \n668   \n669   \n670   \n671   \n672   \n673   \n674   \n675   \n676   \n677   \n678   \n679   \n680   \n681   \n682   \n683   \n684   \n685   \n686   \n687   \n688   \n689   \n690   \n691   \n692   \n693   \n694   \n695   \n696   \n697   \n698   \n699   \n700   \n701 ", "page_idx": 21}, {"type": "text", "text": "8. Experiments Compute Resources ", "text_level": 1, "page_idx": 21}, {"type": "text", "text": "Question: For each experiment, does the paper provide sufficient information on the computer resources (type of compute workers, memory, time of execution) needed to reproduce the experiments? ", "page_idx": 21}, {"type": "text", "text": "Justification: Yes. we include the entire information about the compute resources in the appendix.   \nGuidelines:   \n\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 The paper should indicate the type of compute workers CPU or GPU, internal cluster, or cloud provider, including relevant memory and storage.   \n\u2022 The paper should provide the amount of compute required for each of the individual experimental runs as well as estimate the total compute.   \n\u2022 The paper should disclose whether the full research project required more compute than the experiments reported in the paper (e.g., preliminary or failed experiments that didn\u2019t make it into the paper). ", "page_idx": 21}, {"type": "text", "text": "", "page_idx": 21}, {"type": "text", "text": "9. Code Of Ethics ", "text_level": 1, "page_idx": 21}, {"type": "text", "text": "Question: Does the research conducted in the paper conform, in every respect, with the NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines? Answer: [Yes] ", "page_idx": 21}, {"type": "text", "text": "Justification: We have tried to maintain the double-blind policy to the maximum extent   \npossible.   \nGuidelines: \u2022 The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics. \u2022 If the authors answer No, they should explain the special circumstances that require a deviation from the Code of Ethics. ", "page_idx": 21}, {"type": "text", "text": "The authors should make sure to preserve anonymity (e.g., if there is a special consideration due to laws or regulations in their jurisdiction). ", "page_idx": 22}, {"type": "text", "text": "10. Broader Impacts ", "text_level": 1, "page_idx": 22}, {"type": "text", "text": "Question: Does the paper discuss both potential positive societal impacts and negative   \nsocietal impacts of the work performed?   \nAnswer: [Yes]   \nJustification: In this article we propose a novel way to allow robustness against distortions.   \nWe do not expect any negative societal impacts. There could be positive societal impact   \nsince this can potentially stop hallucinations/bias of the ML models.   \nGuidelines: \u2022 The answer NA means that there is no societal impact of the work performed. \u2022 If the authors answer NA or No, they should explain why their work has no societal impact or why the paper does not address societal impact. \u2022 Examples of negative societal impacts include potential malicious or unintended uses (e.g., disinformation, generating fake profiles, surveillance), fairness considerations (e.g., deployment of technologies that could make decisions that unfairly impact specific groups), privacy considerations, and security considerations. \u2022 The conference expects that many papers will be foundational research and not tied to particular applications, let alone deployments. However, if there is a direct path to any negative applications, the authors should point it out. For example, it is legitimate to point out that an improvement in the quality of generative models could be used to generate deepfakes for disinformation. On the other hand, it is not needed to point out that a generic algorithm for optimizing neural networks could enable people to train models that generate Deepfakes faster. \u2022 The authors should consider possible harms that could arise when the technology is being used as intended and functioning correctly, harms that could arise when the technology is being used as intended but gives incorrect results, and harms following from (intentional or unintentional) misuse of the technology. \u2022 If there are negative societal impacts, the authors could also discuss possible mitigation strategies (e.g., gated release of models, providing defenses in addition to attacks, mechanisms for monitoring misuse, mechanisms to monitor how a system learns from feedback over time, improving the efficiency and accessibility of ML). ", "page_idx": 22}, {"type": "text", "text": "11. Safeguards ", "text_level": 1, "page_idx": 22}, {"type": "text", "text": "Question: Does the paper describe safeguards that have been put in place for responsible release of data or models that have a high risk for misuse (e.g., pretrained language models, image generators, or scraped datasets)? ", "page_idx": 22}, {"type": "text", "text": "Justification: We do not use any datasets/models that have high risk for misuse.   \nGuidelines: \u2022 The answer NA means that the paper poses no such risks. \u2022 Released models that have a high risk for misuse or dual-use should be released with necessary safeguards to allow for controlled use of the model, for example by requiring that users adhere to usage guidelines or restrictions to access the model or implementing safety filters. \u2022 Datasets that have been scraped from the Internet could pose safety risks. The authors should describe how they avoided releasing unsafe images. \u2022 We recognize that providing effective safeguards is challenging, and many papers do not require this, but we encourage authors to take this into account and make a best faith effort. ", "page_idx": 22}, {"type": "text", "text": "751 12. Licenses for existing assets ", "text_level": 1, "page_idx": 22}, {"type": "text", "text": "2 Question: Are the creators or original owners of assets (e.g., code, data, models), used in   \n3 the paper, properly credited and are the license and terms of use explicitly mentioned and   \n4 properly respected?   \n55 Answer: [Yes]   \n6 Justification: We have cited the original articles of all the datasets/models we use in the   \n7 article. We have ensured that these can be used with credit for academic purposes.   \n8 Guidelines:   \n9 \u2022 The answer NA means that the paper does not use existing assets.   \n0 \u2022 The authors should cite the original paper that produced the code package or dataset. ", "page_idx": 22}, {"type": "text", "text": "\u2022 The authors should state which version of the asset is used and, if possible, include a URL.   \n\u2022 The name of the license (e.g., CC-BY 4.0) should be included for each asset.   \n\u2022 For scraped data from a particular source (e.g., website), the copyright and terms of service of that source should be provided.   \n\u2022 If assets are released, the license, copyright information, and terms of use in the package should be provided. For popular datasets, paperswithcode.com/datasets has curated licenses for some datasets. Their licensing guide can help determine the license of a dataset.   \n\u2022 For existing datasets that are re-packaged, both the original license and the license of the derived asset (if it has changed) should be provided.   \n\u2022 If this information is not available online, the authors are encouraged to reach out to the asset\u2019s creators. ", "page_idx": 23}, {"type": "text", "text": "13. New Assets ", "text_level": 1, "page_idx": 23}, {"type": "text", "text": "Question: Are new assets introduced in the paper well documented and is the documentation   \nprovided alongside the assets?   \nAnswer: [Yes] Justification: We share the code at https://anonymous.4open.science/r/ QuantAct-2B41.   \nGuidelines:   \n\u2022 The answer NA means that the paper does not release new assets.   \n\u2022 Researchers should communicate the details of the dataset/code/model as part of their submissions via structured templates. This includes details about training, license, limitations, etc.   \n\u2022 The paper should discuss whether and how consent was obtained from people whose asset is used.   \n\u2022 At submission time, remember to anonymize your assets (if applicable). You can either create an anonymized URL or include an anonymized zip file. ", "page_idx": 23}, {"type": "text", "text": "", "page_idx": 23}, {"type": "text", "text": "", "page_idx": 23}, {"type": "text", "text": "761   \n762   \n763   \n764   \n765   \n766   \n767   \n768   \n769   \n770   \n771   \n772   \n773   \n774   \n775   \n776   \n777   \n778   \n779   \n780   \n781   \n782   \n783   \n784   \n785   \n786   \n787   \n788   \n789   \n790   \n791   \n792   \n793   \n794   \n795   \n796   \n797   \n798   \n799   \n800   \n801   \n802   \n803   \n804   \n805   \n806   \n807   \n808   \n809   \n810   \n811   \n812   \n813   \n814   \n815   \n816   \n817 ", "page_idx": 23}, {"type": "text", "text": "14. Crowdsourcing and Research with Human Subjects ", "text_level": 1, "page_idx": 23}, {"type": "text", "text": "Question: For crowdsourcing experiments and research with human subjects, does the paper include the full text of instructions given to participants and screenshots, if applicable, as well as details about compensation (if any)?   \nAnswer: [NA]   \nustification: The paper does not involve crowdsourcing nor research with human subjects.   \nGuidelines:   \n\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects. \u2022 Including this information in the supplemental material is fine, but if the main contribution of the paper involves human subjects, then as much detail as possible should be included in the main paper. \u2022 According to the NeurIPS Code of Ethics, workers involved in data collection, curation, or other labor should be paid at least the minimum wage in the country of the data collector. ", "page_idx": 23}, {"type": "text", "text": "", "page_idx": 23}, {"type": "text", "text": "15. Institutional Review Board (IRB) Approvals or Equivalent for Research with Human Subjects ", "text_level": 1, "page_idx": 23}, {"type": "text", "text": "Question: Does the paper describe potential risks incurred by study participants, whether such risks were disclosed to the subjects, and whether Institutional Review Board (IRB) approvals (or an equivalent approval/review based on the requirements of your country or institution) were obtained? ", "page_idx": 23}, {"type": "text", "text": "Justification: the paper does not involve crowdsourcing nor research with human subjects.   \nGuidelines: \u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects. \u2022 Depending on the country in which research is conducted, IRB approval (or equivalent) may be required for any human subjects research. If you obtained IRB approval, you should clearly state this in the paper.   \n\u2022 We recognize that the procedures for this may vary significantly between institutions and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the guidelines for their institution.   \n\u2022 For initial submissions, do not include any information that would break anonymity (if applicable), such as the institution conducting the review. ", "page_idx": 23}, {"type": "text", "text": "", "page_idx": 24}]