{"references": [{"fullname_first_author": "Lee, J.", "paper_title": "Deep neural networks as gaussian processes", "publication_date": "2017-11-00", "reason": "This paper is foundational for the theoretical understanding of neural networks as Gaussian processes, influencing the development of deep kernel machines."}, {"fullname_first_author": "Novak, R.", "paper_title": "Bayesian deep convolutional networks with many channels are gaussian processes", "publication_date": "2018-10-00", "reason": "This paper demonstrates that deep convolutional neural networks behave like Gaussian processes in the infinite-width limit, directly relevant to the deep kernel machine approach."}, {"fullname_first_author": "Yang, A. X.", "paper_title": "A theory of representation learning gives a deep generalisation of kernel methods", "publication_date": "2023-00-00", "reason": "This paper provides the theoretical framework for deep kernel machines, extending the concept of deep Gaussian processes to a purely kernel-based method."}, {"fullname_first_author": "Milsom, E.", "paper_title": "Convolutional deep kernel machines", "publication_date": "2024-00-00", "reason": "This paper introduces convolutional deep kernel machines, which directly builds upon the work of Yang et al. (2023) and serves as a direct precursor to the current paper."}, {"fullname_first_author": "Adlam, B.", "paper_title": "Kernel regression with infinite-width neural networks on millions of examples", "publication_date": "2023-00-00", "reason": "This paper provides a strong baseline result using infinite-width neural networks that the current paper aims to improve upon with deep kernel machines."}]}