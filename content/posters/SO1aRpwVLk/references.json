{"references": [{"fullname_first_author": "Sherwin Bahmani", "paper_title": "4D-Fy: Text-to-4D Generation Using Hybrid Score Distillation Sampling", "publication_date": "2023-00-00", "reason": "This paper is highly relevant due to its focus on text-to-4D generation, a topic central to the current work, and its use of score distillation sampling, a technique explored and contrasted in the current paper."}, {"fullname_first_author": "Andreas Blattmann", "paper_title": "Stable Video Diffusion: Scaling Latent Video Diffusion Models to Large Datasets", "publication_date": "2023-00-00", "reason": "This paper is crucial due to its advancement of video diffusion models, the foundation of the method used in this paper to generate photorealistic videos, and its scalability to large datasets relevant to photorealism."}, {"fullname_first_author": "Bernhard Kerbl", "paper_title": "3D Gaussian Splatting for Real-Time Radiance Field Rendering", "publication_date": "2023-00-00", "reason": "This paper is highly relevant due to the introduction of 3D Gaussian Splats, a core component of the dynamic scene representation adopted in this paper, and its real-time rendering capabilities, important for practical generation."}, {"fullname_first_author": "Ben Poole", "paper_title": "DreamFusion: Text-to-3D Using 2D Diffusion", "publication_date": "2023-00-00", "reason": "This paper is highly influential due to its introduction of text-to-3D generation using score distillation, providing a key technique for 3D scene synthesis that is considered and refined upon in this research."}, {"fullname_first_author": "Willi Menapace", "paper_title": "Snap Video: Scaled Spatiotemporal Transformers for Text-to-Video Synthesis", "publication_date": "2024-00-00", "reason": "This paper is highly relevant as it introduces a powerful text-to-video diffusion model that this paper leverages for reference video generation, demonstrating the impact of advanced video generation techniques on 4D scene generation."}]}