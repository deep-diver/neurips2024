[{"figure_path": "u1b1dJtyxc/figures/figures_4_1.jpg", "caption": "Figure 1: Comparing different approaches for creating train-test splits in the Pereira dataset. Within each panel, EXP1 results are on the left and EXP2 results are on the right (same formatting in Figure 2,3) (a) R2 values across layers for GPT2-XL on shuffled train-test splits (gray) and contiguous (unshuffled) splits (blue). (b) Each dot shows the mean R2 value across voxels within a participant, with bars indicating mean R\u00b2 across participants.", "description": "This figure compares two methods of creating training and testing data splits for neural predictivity analysis of GPT2-XL in the Pereira fMRI dataset.  Panel (a) shows the R-squared values across different layers of the GPT2-XL model, comparing the results obtained using shuffled versus contiguous splits.  Panel (b) presents the average R-squared values per participant, again comparing the two split methods.  The results show significant differences in model performance depending on the data splitting method used.  Shuffled splits show a different trend in performance across layers than contiguous splits, highlighting the impact of temporal autocorrelation in the fMRI data.", "section": "3 Pereira dataset"}, {"figure_path": "u1b1dJtyxc/figures/figures_5_1.jpg", "caption": "Figure 2: For all panels, EXP1 results are on the left and EXP2 results are on the right. (a) Brain score (R2) for different combinations of features. Each dot represents R\u00b2 values averaged across voxels in a single participant, with bars showing mean across participants. (b) 2D histogram of R2 values for the best model without GPT2-XLU (SP+SL), and the best model with GPT2-XLU (GPT2-XLU+SP+SL). The dotted lines show y = x, y = 0, and x = 0. Values below y = 0 or left of x = 0 were clipped when averaging, but are shown here to visualize the full distribution. (c) Same as (a), but after voxel-wise correction; lines connect data-points from the same participant. (d) Glass brain plots showing R\u00b2 values of SP+SL (left) and GPT2-XLU+SP+SL (right) after voxel-wise correction. Conventions are the same as Figure 1.", "description": "This figure presents the results of analyzing different feature combinations for predicting brain activity using the Pereira fMRI dataset.  Panel (a) compares the predictive power (R\u00b2) of various feature combinations, showing individual participant data points and mean R\u00b2 values. Panel (b) shows a 2D histogram illustrating the relationship between model performance with and without GPT2-XLU, highlighting the additional variance explained by the model. Panel (c) repeats the analysis after voxel-wise correction, emphasizing the change in the relationship.  Panel (d) displays glass brain plots visualizing the spatial distribution of R\u00b2 values for the best-performing models with and without GPT2-XLU. The figure demonstrates that even with GPT2-XL, simple features such as sentence length and position are the primary drivers of the predictive accuracy.", "section": "3.2 Untrained LLM neural predictivity is fully accounted for by sentence length and position"}, {"figure_path": "u1b1dJtyxc/figures/figures_7_1.jpg", "caption": "Figure 2: For all panels, EXP1 results are on the left and EXP2 results are on the right. (a) Brain score (R2) for different combinations of features. Each dot represents R\u00b2 values averaged across voxels in a single participant, with bars showing mean across participants. (b) 2D histogram of R2 values for the best model without GPT2-XLU (SP+SL), and the best model with GPT2-XLU (GPT2-XLU+SP+SL). The dotted lines show y = x, y = 0, and x = 0. Values below y = 0 or left of x = 0 were clipped when averaging, but are shown here to visualize the full distribution. (c) Same as (a), but after voxel-wise correction; lines connect data-points from the same participant. (d) Glass brain plots showing R\u00b2 values of SP+SL (left) and GPT2-XLU+SP+SL (right) after voxel-wise correction. Conventions are the same as Figure 1.", "description": "This figure analyzes the neural predictivity of different feature combinations in the Pereira dataset, comparing models with and without GPT2-XLU. Panel (a) shows the brain scores (R\u00b2) for various feature combinations, with dots representing individual participants and bars showing the mean. Panel (b) presents a 2D histogram comparing the best models with and without GPT2-XLU, illustrating the relationship between their R\u00b2 values. Panel (c) repeats the analysis in (a) after voxel-wise correction. Finally, panel (d) displays glass brain plots visualizing the R\u00b2 values of the best models with and without GPT2-XLU after voxel-wise correction.", "section": "3.2 Untrained LLM neural predictivity is fully accounted for by sentence length and position"}, {"figure_path": "u1b1dJtyxc/figures/figures_8_1.jpg", "caption": "Figure 1: Comparing different approaches for creating train-test splits in the Pereira dataset. Within each panel, EXP1 results are on the left and EXP2 results are on the right (same formatting in Figure 2,3) (a) R2 values across layers for GPT2-XL on shuffled train-test splits (gray) and contiguous (unshuffled) splits (blue). (b) Each dot shows the mean R2 value across voxels within a participant, with bars indicating mean R\u00b2 across participants.", "description": "This figure compares two methods for creating training and testing data splits in the Pereira fMRI dataset: shuffled and contiguous.  Panel (a) shows the R-squared values (a measure of how well a model predicts brain activity) across different layers of the GPT-2 XL language model for both split methods. The graph illustrates a significant difference in performance between shuffled and contiguous splits across layers of the model.  Panel (b) further elaborates by showing the average R-squared values across participants for both methods, providing a clearer visualization of the difference.  This difference highlights how the choice of splitting method dramatically impacts the interpretation of the model's performance in predicting brain activity.", "section": "3 Pereira dataset"}, {"figure_path": "u1b1dJtyxc/figures/figures_13_1.jpg", "caption": "Figure 5: a) Across layer performances in Pereira dataset for GPT2-XLU for each functional network when using the sum-pooling method. EXP1 is on the left, and EXP2 is on the right. b) Same as a but for GPT2-XL, also using the sum-pooling method. c) Same as a but when using the last token method. Dotted grey line shows performance of best layer of GPT2-XLU in language network when sum pooling. d) Same as b but when using the last token method. Dotted grey line shows performance of best layer of GPT2-XL in language network when sum pooling.", "description": "This figure compares the performance of GPT2-XL and GPT2-XLU across different layers in the Pereira dataset, using two different pooling methods (sum pooling and last token).  It shows R2 values for different functional brain networks (language, DMN, MD, and visual). The dotted lines indicate the best layer's performance for each model in the language network using the sum pooling method. This aids in understanding how the model's representation of language changes as the information passes through different layers, and how these representations correlate with brain activity in various networks.", "section": "A.5 Across layer R2 values in the Pereira dataset"}, {"figure_path": "u1b1dJtyxc/figures/figures_14_1.jpg", "caption": "Figure 3: For all panels, EXP1 results are on the left and EXP2 results are on the right. (a) For each model, we display the sub-model which includes the added feature. Dots represent participants and bars are mean across participants. Grey dashed line is the performance of GPT2-XL alone. (b) 2d histogram comparing full model and full model with GPT2-XL. (c) Same as (a) but after voxel-wise correction for SP+SL+WORD and SP+SL+WORD+GPT2-XL. (d) Glass brain plots showing R2 values of SP+SL+WORD (left) and SP+SL+WORD+GPT2-XLU (right) after voxel-wise correction.", "description": "This figure displays the results of the analysis of the impact of adding complex linguistic features to a baseline model that already includes sentence position (SP) and sentence length (SL). The left panels always show results for Experiment 1, while the right panels always show results for Experiment 2.  Panel (a) shows the R-squared (R2) values for various models, highlighting the contribution of each added feature (WORD, SENSE, SYNT).  Panel (b) provides a 2D histogram visualizing the relationship between R2 values obtained with and without GPT2-XL. Panel (c) repeats the analysis from (a) but after correcting for voxel-wise variability. Finally, panel (d) presents brain plots illustrating the spatial distribution of R2 values for the best-performing models with and without GPT2-XL.", "section": "3.3 Sentence length, sentence position, and static word embeddings account for the majority of trained LLM encoding performance"}, {"figure_path": "u1b1dJtyxc/figures/figures_16_1.jpg", "caption": "Figure 7: Word Position feature for a single sentence in the Fedorenko dataset.", "description": "This figure shows a heatmap representing the word position feature for a single sentence in the Fedorenko dataset. The heatmap visualizes the similarity between different word positions.  The color intensity represents the strength of the similarity, with darker colors indicating higher similarity.  This feature was created by applying a Gaussian filter to an 8-dimensional one-hot positional signal, reflecting the expectation that similar positions would have a higher correlation.", "section": "4.2 Word position explains all of untrained, and most of trained, GPT2-XL brain score"}, {"figure_path": "u1b1dJtyxc/figures/figures_16_2.jpg", "caption": "Figure 1: Comparing different approaches for creating train-test splits in the Pereira dataset. Within each panel, EXP1 results are on the left and EXP2 results are on the right (same formatting in Figure 2,3) (a) R2 values across layers for GPT2-XL on shuffled train-test splits (gray) and contiguous (unshuffled) splits (blue). (b) Each dot shows the mean R2 value across voxels within a participant, with bars indicating mean R\u00b2 across participants.", "description": "This figure compares two different methods of creating training and testing datasets: shuffled and contiguous splits.  Panel (a) shows the R-squared values (a measure of how well a model predicts brain activity) across different layers of a GPT-2 language model, for both shuffled and contiguous splits on two experiments (EXP1 and EXP2).  Panel (b) shows the average R-squared values across voxels within participants, again for both shuffled and contiguous splits, highlighting the significant difference in performance between the two methods. The results reveal a considerable effect of the data split method on the evaluation results, raising concerns about using shuffled splits in this type of analysis.", "section": "3 Pereira dataset"}]