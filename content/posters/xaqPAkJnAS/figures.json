[{"figure_path": "xaqPAkJnAS/figures/figures_1_1.jpg", "caption": "Figure 1: (a) and (b) illustrate that in a non-redundant multiplex graph, view-specific task-relevant edges exist in certain graphs. The color of nodes represents class, edges between nodes of the same class are considered relevant edges, and \"unique\" indicates that the edge exists only in one graph. (c) The unique relevant edge ratio = (the number of unique relevant edges) / (the total number of relevant edges in this graph). Each graph contains a significant amount of unique task-relevant information.", "description": "This figure illustrates the concept of non-redundancy in multiplex graphs.  Panel (a) shows a Venn diagram representing the overlap and unique information between multiple graphs (views).  Panel (b) provides a concrete example of a multiplex graph, highlighting shared and unique task-relevant edges. Panel (c) presents an empirical study demonstrating the significant amount of unique task-relevant information in real-world multiplex graphs, particularly in the ACM dataset.", "section": "Introduction"}, {"figure_path": "xaqPAkJnAS/figures/figures_2_1.jpg", "caption": "Figure 2: The overall framework of the proposed InfoMGF. Specifically, InfoMGF first generates refined graphs and the fused graph through the graph learner. Subsequently, it maximizes shared and unique task-relevant information within the multiplex graph and facilitates graph fusion. The learned fused graph and node representations are used for various downstream tasks.", "description": "The figure illustrates the InfoMGF framework which consists of two main modules: Graph Structure Refinement and Task-Relevant Information Maximization.  The Graph Structure Refinement module refines each individual graph in the multiplex graph to remove irrelevant noise, resulting in refined graphs. These refined graphs are then fed into the Task-Relevant Information Maximization module. This module aims to maximize both shared and unique task-relevant information across the refined graphs, ultimately leading to a fused graph.  This fused graph, along with learned node representations, is then used for various downstream tasks such as node classification and node clustering.", "section": "3 Methodology"}, {"figure_path": "xaqPAkJnAS/figures/figures_7_1.jpg", "caption": "Figure 3: Heatmaps of the subgraph adjacency matrices of the original and learned graphs on ACM.", "description": "The figure visualizes the adjacency matrices of the original multiplex graphs (PAP and PSP) and the learned fused graph (Gs) on a subgraph of the ACM dataset.  The heatmaps show the relationships between nodes in each view.  Darker colors indicate stronger connections. The figure highlights InfoMGF's ability to effectively remove inter-class edges (irrelevant noise) and retain intra-class edges (task-relevant information) from the original graphs, resulting in a cleaner, more informative fused graph.", "section": "3 Methodology"}, {"figure_path": "xaqPAkJnAS/figures/figures_8_1.jpg", "caption": "Figure 4: Robustness analysis on ACM.", "description": "The figure shows the robustness analysis of InfoMGF and other methods (GCN, SUBLIME, and HDMI) against random noise on the ACM dataset.  Three types of noise are considered: (a) adding edges, (b) deleting edges, and (c) masking features.  The plots show the Macro-F1 scores for node classification as the noise rate increases. InfoMGF consistently demonstrates superior robustness compared to the other methods, maintaining high performance even with significant noise injection.", "section": "4.3 Robustness Analysis (RQ2)"}, {"figure_path": "xaqPAkJnAS/figures/figures_9_1.jpg", "caption": "Figure 3: Heatmaps of the subgraph adjacency matrices of the original and learned graphs on ACM.", "description": "The figure visualizes the adjacency matrices of subgraphs from the ACM dataset, comparing the original graphs (PAP and PSP views) with the learned fused graph (Gs) produced by InfoMGF-LA.  The heatmaps show the edge weights between nodes, with warmer colors indicating stronger connections.  The goal is to illustrate how InfoMGF refines the graph structure by removing inter-class edges and retaining intra-class edges, leading to improved performance in downstream tasks.  Nodes are reordered by class label (C1 and C2) to highlight the differences more clearly.", "section": "4.2 Effectiveness Analysis (RQ1)"}, {"figure_path": "xaqPAkJnAS/figures/figures_22_1.jpg", "caption": "Figure 4: Robustness analysis on ACM. (a) Adding edges (b) Deleting edges (c) Masking features", "description": "This figure presents a robustness analysis of the InfoMGF model on the ACM dataset against different types of noise: edge addition, edge deletion, and feature masking.  The performance of InfoMGF is compared to other baselines (GCN, SUBLIME, and HDMI) across varying levels of noise. The results demonstrate InfoMGF's superior robustness compared to baselines, especially under high noise levels.  This highlights the model's ability to effectively manage task-irrelevant information and retain sufficient task-relevant information.", "section": "4.3 Robustness Analysis (RQ2)"}, {"figure_path": "xaqPAkJnAS/figures/figures_23_1.jpg", "caption": "Figure 7: Heatmaps of the subgraph adjacency matrices of the original and learned graphs on DBLP.", "description": "This figure visualizes the adjacency matrices of the original and learned graphs for the DBLP dataset.  It shows three heatmaps: one for each of the original graph views (APA and APCPA), and one for the fused graph (Gs) learned by the InfoMGF model. The heatmaps use color intensity to represent the edge weights, allowing for a visual comparison of the original graph structures to the refined structure learned by the model. The red lines divide the heatmaps to show different classes of nodes.", "section": "4.5 Node Correlation Visualization"}, {"figure_path": "xaqPAkJnAS/figures/figures_23_2.jpg", "caption": "Figure 8: Heatmaps of the subgraph adjacency matrices of the original and learned graphs on Yelp.", "description": "The figure visualizes the adjacency matrices of the original and learned graphs for the Yelp dataset.  It shows heatmaps of the original BUB, BSB, and BLB graphs, alongside the fused graph (Gs) generated by InfoMGF-LA.  The heatmaps illustrate the relationships between nodes (businesses) within each graph, with warmer colors representing stronger connections.  The comparison highlights how InfoMGF refines the graph structure, removing inter-class edges and enhancing intra-class connections, improving the quality of the graph representation for downstream tasks.", "section": "4.5 Node Correlation Visualization"}]