[{"figure_path": "2vMvh5XP0P/tables/tables_7_1.jpg", "caption": "Table 1: Quantitative results on test views of our mehod on large images and a bigger dataset (top) and comparison against KiloOSF [46] within their setting (bottom). We excluded runs of KiloOSF that couldn't reconstruct anything for more comparable results. The best results are highlighted in bold. All experiments where timed and run on a single NVIDIA RTX 4090. *: cropped images with one side length of 800.", "description": "This table presents a quantitative comparison of the proposed method against the KiloOSF method for novel view synthesis on both synthetic and real-world datasets.  Metrics include PSNR, SSIM, LPIPS, and FPS.  The table shows that the proposed method achieves comparable or better results than KiloOSF at significantly higher frame rates, even when using a smaller dataset and lower resolution images.", "section": "4.3 Quantitative Results"}, {"figure_path": "2vMvh5XP0P/tables/tables_14_1.jpg", "caption": "Table 2: Component Ablation we show ablations on a subset of the dataset consisting of two synthetic and two real world scenes. \"Full\" refers to the method used in the paper. We trained four variants of our method without crucial components \"w/o Deferred\", \"w/o PBR\", \"w/o Joint MLP\" and \"w/o Residual\". The last row adds a comparison of a variant of R3DGS [10] which combines R3DGS with our incident light field.", "description": "This table presents the results of an ablation study evaluating the impact of different components of the proposed method.  It shows the PSNR, SSIM, and LPIPS scores for several variations of the method, including versions without deferred shading, without the physically-based rendering (PBR) model, without the joint multi-layer perceptron (MLP), and without the subsurface scattering residual. A comparison with a version of R3DGS [10] that incorporates the incident light field from the proposed method is also included.", "section": "4.3 Quantitative Results"}, {"figure_path": "2vMvh5XP0P/tables/tables_15_1.jpg", "caption": "Table 1: Quantitative results on test views of our mehod on large images and a bigger dataset (top) and comparison against KiloOSF [46] within their setting (bottom). We excluded runs of KiloOSF that couldn't reconstruct anything for more comparable results. The best results are highlighted in bold. All experiments where timed and run on a single NVIDIA RTX 4090. *: cropped images with one side length of 800.", "description": "This table presents a quantitative comparison of the proposed method against the state-of-the-art KiloOSF method for novel view synthesis on large images and bigger datasets.  It shows metrics such as PSNR, SSIM, LPIPS, and FPS for both synthetic and real-world datasets, highlighting the superior performance of the proposed approach in terms of image quality and speed. The table also includes training time and data size used.", "section": "4.3 Quantitative Results"}, {"figure_path": "2vMvh5XP0P/tables/tables_16_1.jpg", "caption": "Table 4: Intrinsic Comparison of Blender renders against ours. We report RMSE for all synthetic measurable scenes, a subset of 25 renders with 5 different camera and light poses, and \\\"Average\\\" over all of our synthetic scenes.", "description": "This table presents a quantitative comparison of intrinsic properties (base color, roughness, metalness, normal, SSS residual, specular, diffuse, and render) obtained from Blender renders against the results produced by the authors' method. The comparison is performed on a subset of 25 renders from five synthetic scenes, each with five different camera and light poses.  The average RMSE across all scenes is also included. Note that Blender doesn't provide SSS intrinsics, so the residual shown here represents the difference between diffuse light rendered with and without SSS.", "section": "E Intrinsics"}]