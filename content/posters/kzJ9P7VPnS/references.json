{"references": [{"fullname_first_author": "Ben Mildenhall", "paper_title": "Nerf: Representing scenes as neural radiance fields for view synthesis", "publication_date": "2021-00-00", "reason": "This paper introduces NeRF, a foundational work in novel view synthesis that uses neural networks to represent 3D scenes implicitly, which is a major influence on subsequent work including 3D Gaussian splatting."}, {"fullname_first_author": "Bernhard Kerbl", "paper_title": "3D Gaussian splatting for real-time radiance field rendering", "publication_date": "2023-00-00", "reason": "This paper introduces 3D Gaussian splatting, the core method that this paper improves upon, and is therefore a highly relevant reference."}, {"fullname_first_author": "Michael Niemeyer", "paper_title": "Radsplat: Radiance field-informed gaussian splatting for robust real-time rendering with 900+ fps", "publication_date": "2024-00-00", "reason": "Radsplat is a key comparative method in this paper's experiments, representing the state-of-the-art in pruning Gaussian splatting and is directly compared against."}, {"fullname_first_author": "Jonathan T Barron", "paper_title": "Mip-nerf 360: Unbounded anti-aliased neural radiance fields", "publication_date": "2022-00-00", "reason": "Mip-NeRF 360 is one of the datasets used for evaluating the proposed method, and its scale and complexity make it a significant benchmark in novel view synthesis."}, {"fullname_first_author": "Joo Chan Lee", "paper_title": "Compact 3D Gaussian representation for radiance field", "publication_date": "2023-00-00", "reason": "Compact3D is another important comparative method in this work because it also addresses the problem of efficient 3D Gaussian representation, using a different approach than the one proposed in this paper."}]}