[{"figure_path": "z4duW3KzlD/figures/figures_2_1.jpg", "caption": "Figure 1: Generated sequences from GIN in the irregular polygon environments. The videos are shown as single images, with color intensity representing the incremental sequence index.", "description": "This figure shows several frames from videos generated by the Gated Inference Network (GIN) model. Each frame is a single image, representing one time step in a sequence. The color intensity within each image represents the progression of time within the sequence, with darker shades indicating earlier time steps. The videos depict a ball moving within irregular polygon environments. The figure highlights the model's ability to generate plausible and temporally consistent sequences of video frames.", "section": "4 Gated Inference Network"}, {"figure_path": "z4duW3KzlD/figures/figures_3_1.jpg", "caption": "Figure 2: Graphical model. Dashed nodes are task dependent output.", "description": "This figure shows a graphical model representing the relationships between variables in the Gated Inference Network (GIN).  The nodes represent variables, such as latent states (x), transferred observations (w), original observations (o), and task-dependent outputs (s).  The arrows indicate the probabilistic dependencies between the variables.  Dashed nodes represent task-dependent outputs, meaning that their presence and values depend on the specific task being performed (either state estimation or image imputation). The model demonstrates the flow of information and the dependencies between sensory observations, latent states, and the final outputs. ", "section": "4 Gated Inference Network"}, {"figure_path": "z4duW3KzlD/figures/figures_3_2.jpg", "caption": "Figure 3: The GIN as a HW model for system identification. By appropriate structure selection for e(.) and d(.), the GIN can handle high-dimensional observations. The relation between the internal variables, wt and xt, is simulated by the transition block.", "description": "This figure illustrates the Gated Inference Network (GIN) as a Hammerstein-Wiener (HW) model.  The GIN consists of three main components: an encoder (e(.)), a transition block, and a decoder (d(.)). The encoder maps the original high-dimensional sensory observations (o<sub>1:T</sub>) to a lower-dimensional representation (w<sub>1:T</sub>). The transition block models the temporal dynamics of the system, updating the latent states (x<sub>1:T</sub>) based on the transformed observations.  Finally, the decoder maps the latent states and transformed observations to the task-specific output, which can either be the original observations (denoised and imputed) or the physical system's states (s<sub>1:T</sub>). The flexibility of the GIN comes from its ability to handle high-dimensional observations through the appropriate selection of the encoder and decoder structures, e(.) and d(.).", "section": "4 Gated Inference Network"}, {"figure_path": "z4duW3KzlD/figures/figures_4_1.jpg", "caption": "Figure 4: Transition block of figure 3 in details. In each time step, the last posterior xt\u22121|W1:t\u22121 is fed to the Dynamic Net to compute yt. In the filtering steps, by using the last posterior xt-1|W1:t-1 and the observation wt, the next posterior xt|W1:t is obtained. Having posterior xt|W1:t and the next smoothing state xt+1|W1:T, applying smoothing for the current state is feasible so that the smoothing state xt|W1:T is obtained.", "description": "This figure details the transition block's operation within the Gated Inference Network (GIN).  It shows how, at each time step, the posterior probability of the previous state (xt\u22121|W1:t\u22121) is used by the Dynamic Network to estimate parameters, these estimates along with the current observation (wt) are used to obtain a filtered state estimate (xt|W1:t), and finally, combining the filtered estimate with a smoothed estimate of the next state (xt+1|W1:T) yields a smoothed estimate for the current state (xt|W1:T). This process involves both filtering and smoothing steps to achieve accurate state estimation within a dynamic system.", "section": "4 Gated Inference Network"}, {"figure_path": "z4duW3KzlD/figures/figures_7_1.jpg", "caption": "Figure 1: Generated sequences from GIN in the irregular polygon environments. The videos are shown as single images, with color intensity representing the incremental sequence index.", "description": "This figure shows a series of images generated by the Gated Inference Network (GIN) model while simulating a ball bouncing inside an irregular polygon. Each image represents a single frame from a video sequence, with the color intensity indicating the time progression within the sequence.  The irregular polygon environment introduces complex dynamics due to the changing boundary conditions as the ball collides with the walls of the polygon at various angles and locations. The figure showcases the GIN's ability to generate realistic and coherent video sequences in a challenging dynamic environment, where the object\u2019s motion is not predictable.", "section": "1 Introduction"}, {"figure_path": "z4duW3KzlD/figures/figures_7_2.jpg", "caption": "Figure 1: Generated sequences from GIN in the irregular polygon environments. The videos are shown as single images, with color intensity representing the incremental sequence index.", "description": "This figure shows a series of images generated by the Gated Inference Network (GIN) model while simulating a ball bouncing inside an irregular polygon. Each image represents a single frame from a video sequence, and the color intensity corresponds to the frame's position within the sequence.  It demonstrates the model's ability to handle and represent dynamic situations. The irregular polygon shape indicates the model's capacity to manage varying scenarios.", "section": "4 Gated Inference Network"}, {"figure_path": "z4duW3KzlD/figures/figures_8_1.jpg", "caption": "Figure 7: State (position) estimation in irregular polygon (6 edges) at 35-th and 45-th time steps. The upper row shows the ground truth ball position in 35, 39, 42 and 45-th time steps, respectively.", "description": "The figure displays the state estimation results for a bouncing ball in a hexagon-shaped environment at the 35th and 45th time steps.  The top row shows the ground truth ball positions.  The bottom rows showcase the estimated positions from the GIN, LGSSM, and KVAE models. The results highlight how the GIN more accurately predicts the ball's position compared to the other models, especially in irregular polygon environments.", "section": "Bouncing Ball In Irregular Polygon"}, {"figure_path": "z4duW3KzlD/figures/figures_15_1.jpg", "caption": "Figure 8: Graphical models for different parameterizations of the process noise.", "description": "The figure shows two graphical models representing different parameterizations for the process noise in the Gated Inference Network (GIN).  Model (a) depicts a simpler model where the process noise, Qt, is parameterized as a function of the previous state's posterior mean (\u00b5t\u22121|t\u22121), the previous process noise (Qt\u22121), and the learned transition and emission matrices (Ft and Ht).  The model in (b) is more complex with an explicit recurrent structure where Qt depends on the previous process noise, Qt\u22121, through a recurrent connection.", "section": "A.2 Process Noise Matrix"}, {"figure_path": "z4duW3KzlD/figures/figures_21_1.jpg", "caption": "Figure 3: The GIN as a HW model for system identification. By appropriate structure selection for e(.) and d(.), the GIN can handle high-dimensional observations. The relation between the internal variables, wt and xt, is simulated by the transition block.", "description": "This figure illustrates the Gated Inference Network (GIN) architecture as a Hammerstein-Wiener (HW) model.  The GIN disentangles observations into two representations: a transformed observation (wt) obtained by a nonlinear mapping (e(.)) from the original observation (ot), and a latent state (xt) that describes the dynamics of wt. The transition block, a core component of the GIN, simulates the relationship between wt and xt to infer the high-dimensional state space.", "section": "4 Gated Inference Network"}, {"figure_path": "z4duW3KzlD/figures/figures_25_1.jpg", "caption": "Figure 10: Informed(left column) and uninformed(right column) image imputation task for the single pendulum experiments.", "description": "This figure shows the results of image imputation for a single pendulum experiment.  The left column shows the results when the model is given information about which frames are missing (informed). The right column displays the results when the model is not given this information (uninformed). The top row is the ground truth sequence of images. The second row presents the observed sequence with missing frames (represented by black images).  The following rows show the reconstruction using LGSSM (filtering and smoothing) and GIN (filtering and smoothing), respectively. The results illustrate the model's ability to handle missing data and the potential benefits of using informed masks, given the superior performance of the informed approach.", "section": "7 Evaluation and Experiments"}, {"figure_path": "z4duW3KzlD/figures/figures_25_2.jpg", "caption": "Figure 1: Generated sequences from GIN in the irregular polygon environments. The videos are shown as single images, with color intensity representing the incremental sequence index.", "description": "This figure shows a sequence of images generated by the Gated Inference Network (GIN) model. Each image represents a frame from a video sequence, where the color intensity indicates the time progression. The model simulates a bouncing ball within irregularly shaped polygons, demonstrating the GIN's ability to capture complex dynamics.", "section": "4 Gated Inference Network"}, {"figure_path": "z4duW3KzlD/figures/figures_26_1.jpg", "caption": "Figure 10: Informed(left column) and uninformed(right column) image imputation task for the single pendulum experiments.", "description": "This figure shows the results of image imputation experiments for a single pendulum.  The top row displays the ground truth images. The middle row shows the observed sequence, which has missing frames. The bottom rows show the reconstruction of the missing frames using LGSSM (filter), LGSSM (smooth), GIN (filter), and GIN (smooth).  The left column represents experiments using an informed mask, where the model knows which frames are missing, while the right column depicts uninformed masks, where the model is given just black images for the missing frames.", "section": "7 Evaluation and Experiments"}, {"figure_path": "z4duW3KzlD/figures/figures_26_2.jpg", "caption": "Figure 1: Generated sequences from GIN in the irregular polygon environments. The videos are shown as single images, with color intensity representing the incremental sequence index.", "description": "This figure shows a series of images generated by the Gated Inference Network (GIN) model. Each image represents a single frame from a video sequence of a ball bouncing in an irregularly shaped polygon. The color intensity in each image indicates the time progression of the video sequence, allowing one to visually track the movement of the ball over time.", "section": "1 Introduction"}, {"figure_path": "z4duW3KzlD/figures/figures_27_1.jpg", "caption": "Figure 14: Inference for the single pendulum s1 position at 100-th time step. Generated samples from smoothened distribution, (s1100|01:150), trained by the GIN, LGSSM and KVAE, respectively. The dashed red line p(gt1100) is the ground truth state with distribution of \u03b4(s1100 -0.7). We calculate the sample mean and fit a distribution on the samples for further visualization and comparison purpose.", "description": "This figure compares the performance of three different models (GIN, LGSSM, and KVAE) in estimating the state of a single pendulum at a specific time step (100th). The violin plots show the distributions of samples generated from the smoothened state distribution for each model.  The red dashed line indicates the ground truth state, which is compared to the estimated states to assess each model's accuracy. The plot provides a visual comparison of the accuracy and uncertainty of each model's estimations.", "section": "7 Evaluation and Experiments"}, {"figure_path": "z4duW3KzlD/figures/figures_27_2.jpg", "caption": "Figure 14: Inference for the single pendulum s1 position at 100-th time step. Generated samples from smoothened distribution, (s1100|o1:150), trained by the GIN, LGSSM and KVAE, respectively. The dashed red line p(gt1100) is the ground truth state with distribution of \u03b4(s1100 - 0.7). We calculate the sample mean and fit a distribution on the samples for further visualization and comparison purpose.", "description": "This figure shows the inference results for the single pendulum's first joint position (s1) at the 100th time step.  It compares the generated samples from the smoothed distribution obtained using three different methods: GIN, LGSSM, and KVAE. The dashed red line indicates the ground truth state's distribution, centered at 0.7.  The plot provides a visual comparison of the three models' performance in estimating this specific position, highlighting differences in accuracy and uncertainty.", "section": "7 Evaluation and Experiments"}, {"figure_path": "z4duW3KzlD/figures/figures_27_3.jpg", "caption": "Figure 16: Generated samples from the trained smoothened joint distribution of the single pendulum position, (s1, s2), at 100-th time step for the GIN, LGSSM and KVAE, respectively. The ground truth is shown with a black point.", "description": "This figure compares the performance of three different models (GIN, LGSSM, and KVAE) in estimating the joint distribution of the single pendulum's position at time step 100.  Each subplot displays a 2D density plot showing the probability distribution of the pendulum's position in the s1 and s2 dimensions.  The black point represents the ground truth values for s1 and s2 at time step 100. The spread and shape of the distributions illustrate the accuracy and uncertainty of each model's estimate.", "section": "Evaluation and Experiments"}, {"figure_path": "z4duW3KzlD/figures/figures_28_1.jpg", "caption": "Figure 17: Inference for the double pendulum s1 position at 100-th time step. Generated samples from smoothened distribution, (s1100|o1:150), trained by the GIN, LGSSM and KVAE, respectively. The dashed red line p(gt1100) is the ground truth state with distribution of \u03b4(s1100 \u2013 0.35).", "description": "This figure compares the performance of three different models (GIN, LGSSM, and KVAE) in estimating the state of a double pendulum at a specific time step (100th).  It shows the distributions of generated samples from the models' smoothened distribution for the first joint's position (s1), which is compared against the ground truth. The red dashed line indicates the ground truth state.", "section": "7 Evaluation and Experiments"}, {"figure_path": "z4duW3KzlD/figures/figures_28_2.jpg", "caption": "Figure 18: Inference for the double pendulum s2 position at 100-th time step. Generated samples from smoothened distribution, (s2100|01:150), trained by the GIN, LGSSM and KVAE, respectively. The dashed red line p(gt2100) is the ground truth state with distribution of \u03b4(s2100 \u2013 0.35).", "description": "This figure shows the inference results for the double pendulum's second joint position (s2) at the 100th time step.  It presents generated samples from the smoothened distribution, comparing the performance of the Gated Inference Network (GIN), the Linear Gaussian State Space Model (LGSSM), and the Kalman Variational Autoencoder (KVAE). The ground truth state distribution is also indicated by a dashed red line.", "section": "7 Evaluation and Experiments"}, {"figure_path": "z4duW3KzlD/figures/figures_28_3.jpg", "caption": "Figure 19: Generated samples from the trained smoothened joint distribution of the double pendulum second joint position, (s3, s4), at 100-th time step for the GIN, LGSSM and KVAE, respectively. The ground truth is shown with a black point.", "description": "This figure shows the comparison of the performance of GIN, LGSSM, and KVAE in estimating the joint distribution of the double pendulum's second joint position at time step 100.  The plots display the estimated distributions as density maps, allowing for a visual comparison of the accuracy and uncertainty of each model's predictions. The ground truth is shown as a black point for reference.", "section": "7 Evaluation and Experiments"}, {"figure_path": "z4duW3KzlD/figures/figures_29_1.jpg", "caption": "Figure 14: Inference for the single pendulum s1 position at 100-th time step. Generated samples from smoothened distribution, (s1100|o1:150), trained by the GIN, LGSSM and KVAE, respectively. The dashed red line p(gt1100) is the ground truth state with distribution of \u03b4(s1100 - 0.7). We calculate the sample mean and fit a distribution on the samples for further visualization and comparison purpose.", "description": "The figure shows the inference results for the single pendulum's s1 position at the 100th time step.  It presents violin plots comparing the generated samples from the smoothened distribution obtained using three different methods: GIN, LGSSM, and KVAE. The plots show the distribution of the samples, highlighting the difference in uncertainty and accuracy of each method. A dashed red line indicates the ground truth state.", "section": "7 Evaluation and Experiments"}, {"figure_path": "z4duW3KzlD/figures/figures_29_2.jpg", "caption": "Figure 14: Inference for the single pendulum s1 position at 100-th time step. Generated samples from smoothened distribution, (s1100|o1:150), trained by the GIN, LGSSM and KVAE, respectively. The dashed red line p(gt1100) is the ground truth state with distribution of \u03b4(s1100 - 0.7). We calculate the sample mean and fit a distribution on the samples for further visualization and comparison purpose.", "description": "This figure compares the state estimations of the GIN, LGSSM, and KVAE models for the single pendulum's s1 position at the 100th time step.  The GIN's estimates show a tighter distribution around the ground truth (red dashed line), indicating better accuracy and lower uncertainty compared to the other two methods.", "section": "7 Evaluation and Experiments"}, {"figure_path": "z4duW3KzlD/figures/figures_29_3.jpg", "caption": "Figure 19: Generated samples from the trained smoothened joint distribution of the double pendulum second joint position, (s3, s4), at 100-th time step for the GIN, LGSSM and KVAE, respectively. The ground truth is shown with a black point.", "description": "This figure compares the performance of three different models (GIN, LGSSM, and KVAE) in estimating the joint distribution of the double pendulum's second joint position (s3, s4) at the 100th time step. The generated samples from the smoothened distributions are shown as contour plots, with the ground truth marked by a black point.  The plots visualize the uncertainty and accuracy of each model's prediction, providing a visual comparison of their performance in state estimation.", "section": "7 Evaluation and Experiments"}, {"figure_path": "z4duW3KzlD/figures/figures_30_1.jpg", "caption": "Figure 23: Inference for the visual odometry s1 and s2 positions at 100-th time step. Generated samples from smoothened distribution, (s1100, s2100|o1:500), trained by the GIN, LGSSM and KVAE, respectively. The dashed red line p(gt1100, gt2100) is the ground truth state with distribution of (\u03b4(s1100 + 50), \u03b4(s2100 \u2013 10)).", "description": "This figure shows the results of visual odometry experiments using GIN, LGSSM, and KVAE.  Specifically, it displays the generated samples from the smoothened distribution of the visual odometry's s1 and s2 positions at the 100th time step.  The red dashed lines represent the ground truth state distributions.", "section": "7 Evaluation and Experiments"}, {"figure_path": "z4duW3KzlD/figures/figures_31_1.jpg", "caption": "Figure 23: Inference for the visual odometry s1 and s2 positions at 100-th time step. Generated samples from smoothened distribution, (s1100, s2100|o1:500), trained by the GIN, LGSSM and KVAE, respectively. The dashed red line p(gt1100, gt2100) is the ground truth state with distribution of (\u03b4(s1100 + 50), \u03b4(s2100 \u2013 10)).", "description": "This figure shows the visual odometry results at the 100th time step.  It compares the performance of the GIN, LGSSM, and KVAE models in estimating the s1 and s2 positions. The ground truth is represented by a dashed red line, indicating a distribution centered around specific values. The violin plots visually represent the distribution of samples generated from the smoothened distribution obtained by each model, giving an idea of the uncertainty associated with each model's estimation. The GIN shows better performance in terms of both accuracy and lower uncertainty.", "section": "7 Evaluation and Experiments"}]