{"references": [{"fullname_first_author": "Marco Tulio Ribeiro", "paper_title": "\"Why Should I Trust You?\": Explaining the Predictions of Any Classifier", "publication_date": "2016-00-00", "reason": "This paper is foundational for the field of explainable AI (XAI), introducing a method to explain predictions of any classifier."}, {"fullname_first_author": "Scott M. Lundberg", "paper_title": "A Unified Approach to Interpreting Model Predictions", "publication_date": "2017-00-00", "reason": "This paper provides a unified approach to interpreting model predictions, improving understanding and trust in model outputs."}, {"fullname_first_author": "Ramprasaath R. Selvaraju", "paper_title": "Grad-CAM: Visual Explanations from Deep Networks via Gradient-Based Localization", "publication_date": "2017-00-00", "reason": "Grad-CAM provides a way to visualize the decision-making process of deep neural networks, enhancing interpretability."}, {"fullname_first_author": "Rishabh Agarwal", "paper_title": "Neural Additive Models: Interpretable Machine Learning with Neural Nets", "publication_date": "2021-00-00", "reason": "This paper introduces Neural Additive Models (NAMs), combining the interpretability of GAMs with the power of neural networks."}, {"fullname_first_author": "Chun-Hao Chang", "paper_title": "NODE-GAM: Neural Generalized Additive Model for Interpretable Deep Learning", "publication_date": "2022-00-00", "reason": "This paper presents NODE-GAM, a neural generalized additive model that leverages the interpretability of GAMs with the ability of deep learning models to handle complex relationships."}]}