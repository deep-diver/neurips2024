[{"figure_path": "DLNOBJa7TM/tables/tables_5_1.jpg", "caption": "Table 2: Results and comparisons on real-world datasets in the form of mean accuracy \u00b1 standard deviation and are obtained over 3 repetitions in different random seeds. Results are averaged over the last 50 rounds. The total number of global rounds is 2000 for SVHN, CIFAR-10 and CINIC-10. Algorithms are categorized into two groups: (1) ones not aided by memory or known statistics; (2) ones assisted by memory or known statistics. For a fair competition, we boldface the best accuracy in the first group, while the second best is underlined.", "description": "This table presents the results of experiments conducted on three real-world datasets (SVHN, CIFAR-10, and CINIC-10) to compare the performance of FedAWE against several baseline federated learning algorithms.  The results show mean accuracy and standard deviation, averaged over the final 50 rounds of 2000 total rounds.  Algorithms are grouped into those that do not use memory or prior knowledge of client availability and those that do, to allow for a fair comparison. The best performing algorithm in the first group is highlighted in boldface.", "section": "7 Numerical Experiments"}, {"figure_path": "DLNOBJa7TM/tables/tables_9_1.jpg", "caption": "Table 2: Results and comparisons on real-world datasets in the form of mean accuracy \u00b1 standard deviation and are obtained over 3 repetitions in different random seeds. Results are averaged over the last 50 rounds. The total number of global rounds is 2000 for SVHN, CIFAR-10 and CINIC-10. Algorithms are categorized into two groups: (1) ones not aided by memory or known statistics; (2) ones assisted by memory or known statistics. For a fair competition, we boldface the best accuracy in the first group, while the second best is underlined.", "description": "This table presents the results of several federated learning algorithms on three benchmark datasets (SVHN, CIFAR-10, and CINIC-10).  The algorithms are compared across four different client unavailability scenarios, and the results are presented in terms of mean test accuracy and standard deviation.  The table is divided into groups based on whether the algorithms use memory or prior knowledge of client availability.  The best performing algorithm in the first group (no memory or prior knowledge) is bolded for each scenario.", "section": "7 Numerical Experiments"}, {"figure_path": "DLNOBJa7TM/tables/tables_16_1.jpg", "caption": "Table 2: Results and comparisons on real-world datasets in the form of mean accuracy \u00b1 standard deviation and are obtained over 3 repetitions in different random seeds. Results are averaged over the last 50 rounds. The total number of global rounds is 2000 for SVHN, CIFAR-10 and CINIC-10. Algorithms are categorized into two groups: (1) ones not aided by memory or known statistics; (2) ones assisted by memory or known statistics. For a fair competition, we boldface the best accuracy in the first group, while the second best is underlined.", "description": "This table presents the results of experiments conducted on three real-world datasets (SVHN, CIFAR-10, and CINIC-10) comparing FedAWE with other state-of-the-art algorithms.  The table shows the train and test accuracy for various algorithms under different client unavailability dynamics (stationary and non-stationary).  Algorithms are categorized based on whether they leverage additional memory or prior knowledge of client availability.", "section": "Numerical Experiments"}, {"figure_path": "DLNOBJa7TM/tables/tables_17_1.jpg", "caption": "Table 2: Results and comparisons on real-world datasets in the form of mean accuracy \u00b1 standard deviation and are obtained over 3 repetitions in different random seeds. Results are averaged over the last 50 rounds. The total number of global rounds is 2000 for SVHN, CIFAR-10 and CINIC-10. Algorithms are categorized into two groups: (1) ones not aided by memory or known statistics; (2) ones assisted by memory or known statistics. For a fair competition, we boldface the best accuracy in the first group, while the second best is underlined.", "description": "This table presents the results of several federated learning algorithms on three real-world datasets (SVHN, CIFAR-10, and CINIC-10).  The algorithms are grouped into those that do not use memory or prior knowledge of client availability, and those that do.  Performance is measured by mean accuracy \u00b1 standard deviation, averaged over the last 50 rounds of 2000 total rounds. The best performing algorithm in the memory-agnostic group is highlighted in bold, while the second-best is underlined.  The table allows for comparison of FedAWE's performance against various baselines under different client unavailability scenarios.", "section": "7 Numerical Experiments"}, {"figure_path": "DLNOBJa7TM/tables/tables_17_2.jpg", "caption": "Table 2: Results and comparisons on real-world datasets in the form of mean accuracy \u00b1 standard deviation and are obtained over 3 repetitions in different random seeds. Results are averaged over the last 50 rounds. The total number of global rounds is 2000 for SVHN, CIFAR-10 and CINIC-10. Algorithms are categorized into two groups: (1) ones not aided by memory or known statistics; (2) ones assisted by memory or known statistics. For a fair competition, we boldface the best accuracy in the first group, while the second best is underlined.", "description": "The table compares the performance of FedAWE with other state-of-the-art algorithms on three real-world datasets (SVHN, CIFAR-10, and CINIC-10) under various client unavailability dynamics.  It shows the mean test accuracy and standard deviation, averaged over the last 50 rounds of training, for different algorithms. The algorithms are grouped by whether they use memory or prior knowledge of client availability.", "section": "Numerical Experiments"}, {"figure_path": "DLNOBJa7TM/tables/tables_41_1.jpg", "caption": "Table 6: Neural network architecture, loss function, learning rate scheduling, training steps and batch size specifications", "description": "This table details the specifications used for the neural networks in the experiments.  It shows the architecture (convolutional layers, ReLU activation, max-pooling, dropout, fully connected layers), the loss function (cross-entropy), the learning rate scheduling (a formula based on the global training round), the number of local steps per round, the total number of global training rounds, and the batch size used for training.", "section": "J Numerical Experiments"}, {"figure_path": "DLNOBJa7TM/tables/tables_42_1.jpg", "caption": "Table 2: Results and comparisons on real-world datasets in the form of mean accuracy \u00b1 standard deviation and are obtained over 3 repetitions in different random seeds. Results are averaged over the last 50 rounds. The total number of global rounds is 2000 for SVHN, CIFAR-10 and CINIC-10. Algorithms are categorized into two groups: (1) ones not aided by memory or known statistics; (2) ones assisted by memory or known statistics. For a fair competition, we boldface the best accuracy in the first group, while the second best is underlined.", "description": "This table presents the results of several federated learning algorithms on three real-world datasets (SVHN, CIFAR-10, CINIC-10).  The algorithms are grouped into those that do not use additional memory or prior knowledge of client availability, and those that do.  The table shows the training and testing accuracy for each algorithm on each dataset.  The best performing algorithm among those without memory or prior knowledge is shown in boldface, while the second-best is underlined.", "section": "7 Numerical Experiments"}, {"figure_path": "DLNOBJa7TM/tables/tables_43_1.jpg", "caption": "Table 2: Results and comparisons on real-world datasets in the form of mean accuracy \u00b1 standard deviation and are obtained over 3 repetitions in different random seeds. Results are averaged over the last 50 rounds. The total number of global rounds is 2000 for SVHN, CIFAR-10 and CINIC-10. Algorithms are categorized into two groups: (1) ones not aided by memory or known statistics; (2) ones assisted by memory or known statistics. For a fair competition, we boldface the best accuracy in the first group, while the second best is underlined.", "description": "This table presents the results of several federated learning algorithms on three benchmark datasets (SVHN, CIFAR-10, CINIC-10) under various client unavailability dynamics.  The results are categorized into algorithms that don't use extra memory or prior knowledge of client availability and those that do. The table shows mean test accuracy with standard deviation, averaged over the final 50 rounds of 2000 total rounds. The best performing algorithm in the first category is highlighted in bold.", "section": "7 Numerical Experiments"}, {"figure_path": "DLNOBJa7TM/tables/tables_45_1.jpg", "caption": "Table 2: Results and comparisons on real-world datasets in the form of mean accuracy \u00b1 standard deviation and are obtained over 3 repetitions in different random seeds. Results are averaged over the last 50 rounds. The total number of global rounds is 2000 for SVHN, CIFAR-10 and CINIC-10. Algorithms are categorized into two groups: (1) ones not aided by memory or known statistics; (2) ones assisted by memory or known statistics. For a fair competition, we boldface the best accuracy in the first group, while the second best is underlined.", "description": "This table presents the results of several federated learning algorithms on three real-world datasets (SVHN, CIFAR-10, and CINIC-10).  It compares the performance of FedAWE against several baseline algorithms under different client unavailability dynamics (stationary and non-stationary).  The table highlights the accuracy achieved by each algorithm and categorizes them based on whether they leverage memory or prior knowledge of client availability.  The best performing algorithm among those not using extra memory or knowledge is shown in boldface, while the second best is underlined.", "section": "7 Numerical Experiments"}, {"figure_path": "DLNOBJa7TM/tables/tables_45_2.jpg", "caption": "Table 2: Results and comparisons on real-world datasets in the form of mean accuracy \u00b1 standard deviation and are obtained over 3 repetitions in different random seeds. Results are averaged over the last 50 rounds. The total number of global rounds is 2000 for SVHN, CIFAR-10 and CINIC-10. Algorithms are categorized into two groups: (1) ones not aided by memory or known statistics; (2) ones assisted by memory or known statistics. For a fair competition, we boldface the best accuracy in the first group, while the second best is underlined.", "description": "The table compares the performance of FedAWE and other federated learning algorithms on three real-world datasets (SVHN, CIFAR-10, and CINIC-10) under different client unavailability dynamics.  It shows the training and testing accuracy with standard deviation, averaged over the last 50 rounds of 2000 total rounds. Algorithms are grouped by whether they use memory or prior knowledge of client availability.", "section": "7 Numerical Experiments"}]