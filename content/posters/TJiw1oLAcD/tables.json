[{"figure_path": "TJiw1oLAcD/tables/tables_7_1.jpg", "caption": "Table 1: Comparison of segmentation, reconstruction, and generation results. All values represent the mean of three trials. The best scores are in bold, and the second-best scores are underlined.", "description": "This table presents a quantitative comparison of the proposed AVS model against several baseline methods across three datasets (CLEVRTEX, GSO, ShapeNet) and four evaluation metrics (ARI-A, ARI-O, mIoU, LPIPS, FID).  ARI-A and ARI-O measure the quality of unsupervised object segmentation, considering both objects and background (ARI-A) or only objects (ARI-O). mIoU represents the mean Intersection over Union, a common segmentation metric. LPIPS measures the perceptual image reconstruction quality, and FID assesses the diversity and quality of generated images. The results demonstrate that AVS achieves superior or comparable performance across all datasets and metrics compared to baselines, particularly in segmentation and generation.", "section": "4 Experiments"}, {"figure_path": "TJiw1oLAcD/tables/tables_12_1.jpg", "caption": "Table 2: Configurations of datasets", "description": "This table presents the configurations used for the three datasets: CLEVRTEX, GSO, and ShapeNet.  For each dataset, it details the number of images in the training, validation, and testing splits; the range of the number of objects present in each scene; the number of viewpoints captured for each scene; the image size (resolution); and the range of values used for the spherical coordinates (distance \u03c1, elevation \u03b8, and azimuth \u03c6) defining the camera positions for capturing the different viewpoints.  These parameters are crucial for understanding the characteristics of the datasets used in the experiments and for reproducing the results.", "section": "4 Experiments"}, {"figure_path": "TJiw1oLAcD/tables/tables_13_1.jpg", "caption": "Table 3: Hyperparameters of our model used in experiments.", "description": "This table lists the hyperparameters used for training the proposed model (AVS) and baseline models (SIMONE, OCLOC, LSD) on three different datasets (CLEVRTEX, GSO, ShapeNet).  The hyperparameters are categorized by model modules (General, DINO, Viewpoint Encoder, Slot Attention, Auto-Encoder, MLP Decoder, LSD Decoder). For each module and dataset, different hyperparameters such as batch size, number of training steps, input/output resolution and channels, learning rate, number of iterations, number of slots, and others are specified. This detailed breakdown provides complete information for reproducibility.", "section": "3 Method"}, {"figure_path": "TJiw1oLAcD/tables/tables_14_1.jpg", "caption": "Table 1: Comparison of segmentation, reconstruction, and generation results. All values represent the mean of three trials. The best scores are in bold, and the second-best scores are underlined.", "description": "This table compares the performance of different methods across three datasets (CLEVRTEX, GSO, ShapeNet) on four tasks: unsupervised object segmentation (ARI-A, ARI-O, mIoU), scene reconstruction (LPIPS), and image generation (FID).  For each dataset and task, the table shows the mean performance of three trials for several methods, including SIMONe, OCLOC, LSD, and the authors' model with both random and active viewpoint selection strategies.  The best and second-best scores for each metric are highlighted.", "section": "4 Experiments"}]