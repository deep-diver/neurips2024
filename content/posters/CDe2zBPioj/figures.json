[{"figure_path": "CDe2zBPioj/figures/figures_1_1.jpg", "caption": "Figure 1: Green and red lines represent positive and negative edges, resp. Solid lines represent edges in the training set, while dashed lines represent edges in the test set.", "description": "This figure illustrates two issues in Signed Graph Neural Networks (SGNNs). Issue 1 shows the challenge of predicting the edge sign between two nodes in a sparse graph, which is mitigated by adding extra edges through data augmentation. Issue 2 depicts the problem of unbalanced triangles, where the relationship between two nodes is uncertain, leading to difficulty in learning representations for these nodes.  The figure uses green and red lines to represent positive and negative edges, respectively; solid lines indicate edges in the training set, while dashed lines show test set edges.", "section": "1 Introduction"}, {"figure_path": "CDe2zBPioj/figures/figures_1_2.jpg", "caption": "Figure 6: Effectiveness of data augmentation through random structural perturbations (SGCN [11] as backbone model) on link sign prediction performance. (a) Randomly increasing or decreasing positive edges. (b) Randomly increasing or decreasing negative edges. (c) Randomly flipping the sign of edges.", "description": "This figure shows the results of experiments using SGCN with three different random structural perturbation methods to augment the training data for link sign prediction.  The methods tested are: randomly increasing/decreasing positive edges, randomly increasing/decreasing negative edges, and randomly flipping edge signs.  The results demonstrate that none of these random augmentation methods consistently improve SGCN's performance.", "section": "A Experimental results of data augmentation through random structural perturbations"}, {"figure_path": "CDe2zBPioj/figures/figures_3_1.jpg", "caption": "Figure 3: The overall process of SGA. Green lines represent positive edges and red lines represent negative edges.", "description": "The figure illustrates the three main steps of the Signed Graph Augmentation (SGA) framework: 1) generating candidate training samples by using a Signed Graph Convolutional Network (SGCN) to predict potential edges based on node embeddings and structural balance theory, 2) selecting beneficial candidate samples that do not introduce new unbalanced triangles, and 3) introducing edge difficulty scores as a new feature for training samples which is used in a curriculum learning approach to focus on easier samples first. The framework aims to alleviate the issues of graph sparsity and unbalanced triangles in signed graph neural networks.", "section": "3 Proposed Method"}, {"figure_path": "CDe2zBPioj/figures/figures_7_1.jpg", "caption": "Figure 4: Case Study of SGA. Note that green lines denote positive edges and red lines denote negative edges.", "description": "This figure presents two case studies from the Bitcoin-alpha dataset to illustrate how SGA improves link sign prediction. Case 1 shows that SGA, by utilizing latent structure, helps SGCN to correctly predict the sign of initially mispredicted edges. Case 2 demonstrates how SGA, by modifying edge signs in existing structures, reduces the impact of unbalanced triangles and enables SGCN to achieve correct prediction results.", "section": "5.1 Performance Evaluation (Q1)"}, {"figure_path": "CDe2zBPioj/figures/figures_8_1.jpg", "caption": "Figure 6: Effectiveness of data augmentation through random structural perturbations (SGCN [11] as backbone model) on link sign prediction performance. (a) Randomly increasing or decreasing positive edges. (b) Randomly increasing or decreasing negative edges. (c) Randomly flipping the sign of edges.", "description": "The figure shows the results of experiments conducted to evaluate the effectiveness of three different random structural perturbation methods for data augmentation in link sign prediction tasks. The methods are: randomly increasing or decreasing positive edges; randomly increasing or decreasing negative edges; and randomly flipping the sign of edges.  The results, based on the SGCN model, indicate that none of these random perturbation methods consistently improve performance.", "section": "A Experimental results of data augmentation through random structural perturbations"}, {"figure_path": "CDe2zBPioj/figures/figures_14_1.jpg", "caption": "Figure 6: Effectiveness of data augmentation through random structural perturbations (SGCN [11] as backbone model) on link sign prediction performance. (a) Randomly increasing or decreasing positive edges. (b) Randomly increasing or decreasing negative edges. (c) Randomly flipping the sign of edges.", "description": "This figure displays the results of experiments testing the effectiveness of three different random structural perturbation methods for data augmentation on a link sign prediction task using the SGCN model.  The methods tested were: randomly increasing or decreasing the number of positive edges, randomly increasing or decreasing the number of negative edges, and randomly flipping the sign of existing edges.  The results, shown across six different datasets, demonstrate that none of these random perturbation methods consistently improved the SGCN model's performance on this task. This suggests that simple random structural perturbations are not an effective data augmentation strategy for signed graph neural networks.", "section": "A Experimental results of data augmentation through random structural perturbations"}, {"figure_path": "CDe2zBPioj/figures/figures_15_1.jpg", "caption": "Figure 3: The overall process of SGA. Green lines represent positive edges and red lines represent negative edges.", "description": "The figure illustrates the overall process of the Signed Graph Augmentation (SGA) framework. It comprises three main stages: 1. Generating candidate training samples using a pre-trained SGNN to project nodes into an embedding space and predict the probability of forming positive or negative edges.  2. Selecting beneficial candidates by prioritizing those that don't introduce new unbalanced triangles and removing existing unbalanced ones. 3. Introducing a new feature (edge difficulty score) for training samples, influencing the training weight of edges based on their difficulty scores in a curriculum learning approach to mitigate the negative impact of unbalanced triangles. The figure uses color-coded lines (green for positive edges, red for negative edges) to visually represent the edge signs and their changes throughout the process.", "section": "3 Proposed Method"}, {"figure_path": "CDe2zBPioj/figures/figures_15_2.jpg", "caption": "Figure 3: The overall process of SGA. Green lines represent positive edges and red lines represent negative edges.", "description": "This figure illustrates the three main steps of the Signed Graph Augmentation (SGA) framework.  First, it generates candidate training samples by using a pre-trained SGNN model to predict potential positive and negative edges based on node embeddings.  The predicted edges are then filtered to select only those that don't introduce new unbalanced triangles, ensuring that SGA doesn't negatively impact training.  Finally, new features, specifically edge difficulty scores, are introduced to the training samples. These difficulty scores are used in a curriculum learning approach, starting with easier edges (edges in balanced triangles) and progressing to harder edges (edges in unbalanced triangles) during training to improve SGNN performance. The figure uses color-coded lines to visualize positive (green) and negative (red) edges.", "section": "3 Proposed Method"}, {"figure_path": "CDe2zBPioj/figures/figures_16_1.jpg", "caption": "Figure 3: The overall process of SGA. Green lines represent positive edges and red lines represent negative edges.", "description": "This figure illustrates the three main stages of the Signed Graph Augmentation (SGA) framework: generating candidate samples, selecting beneficial candidates, and introducing new features.  The first stage uses a pre-trained Signed Graph Convolutional Network (SGCN) to predict potential edges in the graph based on node embeddings. The second stage filters these candidates, keeping only those that do not introduce new unbalanced triangles. The final stage assigns each edge a difficulty score based on its contribution to unbalanced triangles and incorporates a curriculum-based training schedule. This process aims to improve the training of SGNNs by addressing issues of graph sparsity and unbalanced triangles.", "section": "3 Proposed Method"}, {"figure_path": "CDe2zBPioj/figures/figures_22_1.jpg", "caption": "Figure 6: Effectiveness of data augmentation through random structural perturbations (SGCN [11] as backbone model) on link sign prediction performance. (a) Randomly increasing or decreasing positive edges. (b) Randomly increasing or decreasing negative edges. (c) Randomly flipping the sign of edges.", "description": "The figure displays the results of experiments assessing the impact of three different random structural perturbation methods on link sign prediction using SGCN as the backbone model. Each subfigure shows the F1 score across six real-world datasets, varying the rate of positive edge modification (a), negative edge modification (b), and sign flipping (c).  The results demonstrate that none of these random methods consistently improves SGCN performance.", "section": "A Experimental results of data augmentation through random structural perturbations"}, {"figure_path": "CDe2zBPioj/figures/figures_22_2.jpg", "caption": "Figure 6: Effectiveness of data augmentation through random structural perturbations (SGCN [11] as backbone model) on link sign prediction performance. (a) Randomly increasing or decreasing positive edges. (b) Randomly increasing or decreasing negative edges. (c) Randomly flipping the sign of edges.", "description": "This figure displays the results of experiments evaluating the effectiveness of three different random structural perturbation methods for data augmentation on link sign prediction using the SGCN model.  The three methods are: (a) randomly modifying the number of positive edges, (b) randomly modifying the number of negative edges, and (c) randomly flipping the signs of existing edges. The results show that none of these methods consistently improve SGCN's performance across different datasets. This indicates the limitations of simple random structural perturbations for data augmentation in this specific task.", "section": "A Experimental results of data augmentation through random structural perturbations"}, {"figure_path": "CDe2zBPioj/figures/figures_22_3.jpg", "caption": "Figure 6: Effectiveness of data augmentation through random structural perturbations (SGCN [11] as backbone model) on link sign prediction performance. (a) Randomly increasing or decreasing positive edges. (b) Randomly increasing or decreasing negative edges. (c) Randomly flipping the sign of edges.", "description": "This figure shows the results of experiments using three different random structural perturbation methods on the link sign prediction task using SGCN as the backbone model.  The methods tested were randomly increasing/decreasing positive edges, randomly increasing/decreasing negative edges, and randomly flipping the sign of existing edges. The results demonstrate that none of these methods consistently improve the performance of SGCN, suggesting that these data augmentation techniques are not effective for SGNNs.", "section": "A Experimental results of data augmentation through random structural perturbations"}]