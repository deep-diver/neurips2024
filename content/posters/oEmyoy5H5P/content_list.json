[{"type": "text", "text": "Grounding and Validation of Algorithmic Recourse in Real-World Contexts: A Systematized Literature Review ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Anonymous Author(s)   \nAffiliation   \nAddress   \nemail ", "page_idx": 0}, {"type": "text", "text": "Abstract ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "1 The aim of algorithmic recourse (AR) is generally understood to be the provision   \n2 of \u201cactionable\u201d recommendations to individuals affected by algorithmic decision  \n3 making systems, in an attempt to offer the capacity for taking actions that may   \n4 lead to more desirable outcomes in the future. Over the past few years, AR   \n5 literature has largely focused on theoretical frameworks to generate \u201cactionable\u201d   \n6 counterfactual explanations that further satisfy various desiderata, such as diversity   \n7 or robustness. We believe that algorithmic recourse, by its nature, should be seen   \n8 as a practical problem: real-world socio-technical decision-making systems are   \n9 complex dynamic entities involving various actors (end users, domain experts,   \n10 civil servants, system owners, etc.) engaged in social and technical processes.   \n11 Thus, research needs to account for the specificities of systems where it would   \n12 be applied. To evaluate how authors envision AR \u201cin the wild\u201d, we carry out a   \n13 systematized review of 127 publications pertaining to the problem and identify the   \n14 real-world considerations that motivate them. Among others, we look at the ways   \n15 to make recourse (individually) actionable, the involved stakeholders, the perceived   \n16 challenges, and the availability of practitioner-friendly open-source codebases.   \n17 We find that there is a strong disconnect between the existing research and the   \n18 practical requirements for AR. Most importantly, the grounding and validation of   \n19 algorithmic recourse in real-world contexts remain underexplored. As an attempt   \n20 to bridge this gap, we provide other authors with five recommendations to make   \n21 future solutions easier to adapt to their potential real-world applications. ", "page_idx": 0}, {"type": "text", "text": "22 1 Introduction ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "23 Algorithmic decision-making (ADM) tools are frequently seen as a way to improve decision processes   \n24 in a variety of high-stakes domains such as public administration [47, 146] or healthcare [45, 87].   \n25 Deep learning models have attracted much attention due to their perceived high performance, but   \n26 the predictions of such models cannot be interpreted by humans, hence end users \u2013 both individuals   \n27 subjected to algorithmic decisions and decision-makers operating on them \u2013 are placed in a position   \n28 where they are unable to understand the grounds of a prediction, act on it, or trust it [159].   \n29 To help address this problem, a variety of explanation methods has been proposed. Of particular   \n30 interest for this paper are counterfactual explanations (CEs) that attempt to explain the predictions for   \n31 individual instances of data, taking the form of conditional statements such as \u201cif the value of feature   \n32 x was a instead of b, the model would have predicted class y instead of $z$ \u201d. They are perceived to be   \n33 an attractive approach to explanation that does not require \u201copening the black box\u201d [151] and have   \n34 been argued to align with the ways that humans naturally reason about events [84].   \n35 CEs are also seen as the go-to method for algorithmic recourse (AR), or the generation of actionable   \n36 recommendations that provide people with the knowledge needed to achieve more desirable predic  \n37 tions in ADM systems. Recourse is distinct from the \u201cexplanation\u201d or \u201cjustification\u201d of algorithmic   \n38 decisions, and more closely related to the notion of contestability of Artificial Intelligence [7] in that   \n39 it aims not only to improve the trust in the algorithm, but also embrace human agency [142].   \n40 Algorithmic recourse is an inherently practical problem in that it resembles a bureaucratic complaint   \n41 process: an individual unhappy with some decision engages with a representative of the issuing   \n42 organization, in an attempt to overturn it. Yet, we observe that much of the existing work is highly   \n43 theoretical, with little consideration of whether it could be applied in organizational settings [see   \n44 also 18]. Deploying AR in realistic systems without analyzing its mechanics in a broader context   \n45 and without knowing what types of dynamics are expected to arise is bound to lead to unanticipated   \n46 outcomes. Many of them will be undesirable and even potentially unsafe, and impossible to validate   \n47 with respect to a set of requirements because the requirements for AR are necessarily socio-technical. ", "page_idx": 0}, {"type": "text", "text": "", "page_idx": 0}, {"type": "text", "text": "", "page_idx": 1}, {"type": "text", "text": "", "page_idx": 1}, {"type": "text", "text": "48 Societal and institutional components of algorithmic recourse are the focal point of our work, 49 as we look beyond the typical technical considerations to assess the practical aspects of the problem. ", "text_level": 1, "page_idx": 1}, {"type": "text", "text": "50 To that end, we contribute a systematized review of 127 publications that address the goals of   \n51 algorithmic recourse and we evaluate to what extent they incorporate such practical considerations.   \n52 We characterize our approach as systematized because we follow a fully systematic approach to the   \n53 collection of publications, but their selection is not necessarily exhaustive [46] as many impactful   \n54 ideas in computer science are published only in the form of pre-prints. Based on our analysis, we also   \n55 provide other authors with five recommendations on how to improve the practicality of AR research.   \n56 The rest of the manuscript is structured as follows. In Section 2 we elaborate on the background of   \n57 our work. Then, in Section 3 we describe our approach to this review. Next, Section 4 introduces   \n58 our findings. Section 5 provides a discussion of our results, introduces our recommendations, and   \n59 addresses the limitations of the current work. Finally, Section 6 forms the conclusion to this paper. ", "page_idx": 1}, {"type": "text", "text": "", "page_idx": 1}, {"type": "text", "text": "60 2 Background ", "text_level": 1, "page_idx": 1}, {"type": "text", "text": "61 2.1 On algorithmic recourse ", "text_level": 1, "page_idx": 1}, {"type": "text", "text": "62 Algorithmic \u2013 or actionable, individual \u2013 recourse was introduced in [138] as \u201cthe ability of a person   \n63 to change the decision of the model through actionable input variables\u201d, building on the earlier   \n64 work of [151] who argued that CEs are a psychologically-grounded way to (1) help decision-subjects   \n65 understand an algorithmic decision, (2) provide them with information needed to contest it, and (3)   \n66 inform about actions that could be taken to overturn it. For instance, consider a person who has   \n67 unsuccessfully applied for a loan; they may then receive AR such as \u201cif you requested $\\mathbb{S}50O O$ less,   \n68 you would qualify for this loan\u201d. The key consideration for AR is \u201cactionability\u201d, which entails that   \n69 the recipient of the recommendation should be capable of implementing it. If they had been informed   \n70 \u201cif you were 10 years younger, you would qualify for the loan\u201d, they would have still received a   \n71 valid CE, but not recourse. More recently [69] has recast the problem as reasoning about minimal   \n72 interventions on the structural causal model. This formulation (at least theoretically) addresses an   \n73 important shortcoming of \u201ccorrelational\u201d recourse. Without accounting for the downstream causal   \n74 effects of actions, an individual may exert more effort than necessary and still fail to achieve the   \n75 target outcome. Indeed, counterfactuals are an inherently causal concept [103].   \n76 We note that problems similar to AR have been studied under a variety of different names: actionable   \n77 knowledge discovery [e.g., 2], action rules mining [e.g., 110], inverse classification [e.g., 5], why   \n78 not questions [e.g., 58], or actionable feature tweaking [134]. These alternative formulations have   \n79 generally focused on \u201cbusiness\u201d knowledge, rather than individual recommendations, but ultimately   \n80 the goal of all these approaches is to extract information from a (black-box) model that allows the   \n81 user \u2013 an individual or a decision-maker \u2013 to act. We highlight them to emphasize that AR does   \n82 not have to be achieved through the means of CEs. Rather CEs should be seen as one of the means   \n83 to achieve AR, particularly promising in that they do not require expert-level understanding of the   \n84 model to be useful. Nonetheless, we decide to distinguish between the literature on AR (commonly   \n85 equated with actionable CEs), and these alternative formulations in our work.   \n86 Existing research has generally considered AR in simplistic settings that are far removed from   \n87 real-world socio-technical decision-making systems, where it would be implemented as a process.   \n88 For example, such systems are dynamic [113, 137], must support the implementation of AR at scale   \n89 [9, 94], and involve various stakeholders beyond the end users [17, 151]. Moreover, if the intended   \n90 goal of AR is to help individuals subjected to algorithmic decisions in an effective manner, research   \n91 must entail a rich understanding of \u201cactionability\u201d to account for the differences between them [142]. ", "page_idx": 1}, {"type": "text", "text": "", "page_idx": 1}, {"type": "text", "text": "", "page_idx": 1}, {"type": "text", "text": "", "page_idx": 2}, {"type": "text", "text": "92 2.2 On the position of our review ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "93 Several groups of authors have previously surveyed the landscape of counterfactual explanations in   \n94 general, and algorithmic recourse specifically. Perhaps the most relevant to our work is [71], which   \n95 discusses five deficits of research on CEs, with a special focus on the (lack of) psychological grounding.   \n96 Another pertinent publication is [70], which attempts to unify the definitions and formulations of   \n97 AR in existing literature, but the work primarily focuses on technical aspects. Next, [143] develops   \n98 a rubric to compare counterfactual explainers (equated with AR) and identifies 21 research challenges.   \n99 While these also remain mostly technical, several of them are relevant to our work, for instance, CEs   \n100 \u201cas an interactive service to the applicants\u201d or reinforcing \u201cthe ties between machine learning and   \n101 regulatory communities\u201d. More recently, [48] reviewed and benchmarked a number of CE generators,   \n102 but AR is only a secondary consideration in the work. We also highlight [130], which is the only   \n103 systematic review of counterfactual and contrastive approaches to date. The authors understand CEs   \n104 as a way to justify model predictions (i.e., they are different from AR). We agree with this distinction   \n105 in that CEs can be useful for reasons other than recourse, such as model debugging [e.g., 1, 122].   \n106 Finally, although not reviews, [13] and [142] are particularly relevant to our work, offering critical   \n107 perspectives on AR and addressing multiple shortcomings of recourse literature. ", "page_idx": 2}, {"type": "text", "text": "108 3 Methods ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "109 In this section, we briefly discuss our approach to the literature review following the SALSA \u2013 Search,   \n110 Appraisal, Synthesis, Analysis \u2013 framework introduced in [46]. We also provide a more detailed   \n111 description to allow for the reproduction of our process in the supplementary materials. Figure 1   \n112 presents our process in the form of a PRISMA flow diagram [97]. ", "page_idx": 2}, {"type": "text", "text": "113 3.1 Search ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "114 We make use of three search engines to collect the initial set of studies: ACM Digital Library, IEEE   \n115 Xplore, and SCOPUS. Given the previously mentioned blurry distinction between AR and CEs,   \n116 we consider the papers discussing either problem. In a small scoping review, we identify several   \n117 keywords common to publications on recourse, as well as several equivalent terms to build the query.   \n118 We search in titles, abstracts, and keywords, arriving at 3092 records after de-duplication. To facilitate   \n119 the screening process, we employ the open-source ASReview tool, which makes use of an active   \n120 learning approach to re-order the set of publications, such that the most relevant ones are always   \n121 \u201cat the top of the stack\u201d [139]. The researchers behind the tool suggest employing a stopping rule   \n122 measured in the number of consecutive irrelevant records, which we set to 30, or $1\\%$ of the entire   \n123 dataset. We accept all papers that focus on algorithmic recourse and counterfactual explanations,   \n124 completing the screening after evaluating 1040 abstracts, leading to 499 relevant records.   \n125 We observe that some important publications may be missing from our results. For instance, [151]   \n126 was published in a legal journal that is not indexed by computer science search engines. Thus, we   \n127 decide to augment the set of records by applying snowballing, which has been shown as a good   \n128 alternative to databases in systematic reviews in software engineering [162]. We collect the references   \n129 for the top 50 $(10\\%)$ \u201cmost impactful\u201d publications, measured by the number of citations. While this   \n130 introduces several pre-prints into our result set [52, 61, 91, 113, 143, 150], we decide not to exclude   \n131 them. Our review remains primarily concerned with peer-reviewed work. After adding the snowballed   \n132 references to our dataset, we are left with 2018 records for the second screening with ASReview.   \n133 This time, we look for publications that specifically refer to the problem of AR, \u201cactionable\u201d CEs, or   \n134 modifying outcomes of automated decision-making systems. We employ a stricter stopping rule to   \n135 minimize the risk of false negatives, completing the screening after 60 consecutive irrelevant records   \n136 with 203 records considered for full-text appraisal. To allow for complete reproducibility of the   \n137 search process, we provide an extended discussion (including queries) in the technical Appendix A. ", "page_idx": 2}, {"type": "text", "text": "", "page_idx": 2}, {"type": "text", "text": "138 3.2 Appraisal ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "139 We were able to retrieve all of the remaining 203 documents. For each document, we require that the   \n140 authors explicitly cite recourse as the center of interest, or look at (1) explanations (2) provided for   \n141 individual instances (3) with the goal of acting upon them (4) in an attempt to modify the predictions   \n142 (5) of a classification model. We exclude 51 publications as they are not on topic, primarily because   \n143 they focus on CEs for the sake of explanation. Four works in this category look at (what they   \n144 call) recourse but extend the problem to settings beyond the scope of this review: recommender   \n145 systems [31, 43, 145], text classification [37], and anomaly detection [27]. Further 15 publications   \n146 are duplicates, typically pre-prints of other documents that were included in the review. Next, 8   \n147 documents were published before [151] that sparked the research on AR, and thus we exclude them as   \n148 well. These look at the alternative formulations discussed earlier in Section 2.1. Finally, 2 documents   \n149 are not publications: one is an abstract of a talk, and the other is a student poster. For each document,   \n150 we answer a number of questions relating to the practical considerations introduced by the authors. ", "page_idx": 3}, {"type": "image", "img_path": "oEmyoy5H5P/tmp/5a09f12d41f2465b25c86a5bb97e2ef3271711e0e41f25a052178d0d60bd8faf.jpg", "img_caption": ["Figure 1: Identification of studies via databases and snowballing "], "img_footnote": [], "page_idx": 3}, {"type": "text", "text": "151 3.3 Synthesis ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "152 To compile the results we carry out a standard thematic content analysis following the approach   \n153 presented in [40]. First, we explore the data extracted from the set of publications relevant to each   \n154 question to find the commonalities, which serves as the grounds for creating the initial set of codes.   \n155 We evaluate the documents against these codes and keep track of any other considerations. If such   \n156 considerations appear in multiple documents, we create new codes for them. Afterward, we re  \n157 evaluate all documents against the new code. As the coding exercise is carried out by one author, they   \n158 do a third pass over all documents to double-check for potential errors. Finally, where relevant, we   \n159 cluster the codes into larger themes. In this analysis we only look at the explicit statements provided   \n160 by the authors, we do not attempt to infer their understanding of the problem. Thus, the numbers   \n161 provided in Section 4 should be understood as describing how algorithmic recourse is discussed in   \n162 the literature. For brevity, we focus our discussion on the main themes, but we still highlight specific   \n163 publications if we observe that the authors introduce novel, highly relevant considerations that do not   \n164 fit into other themes. Finally, even though we also evaluated the technical aspects of the proposed   \n165 solutions \u2013 requirements for methods and datasets used in evaluations \u2013 they are not covered in this   \n166 review. Instead, we point the interested readers to [48, 70, 143].   \n168 The following nine sections introduce the results of the thematic analysis. For each question, we   \n169 explain why it is relevant to the analysis and examine the main themes. We also highlight highly   \n170 important but underexplored themes. We start with the general points such as contributions and   \n171 definitions in Sections 4.1 to 4.3. Then, in Sections 4.4 to 4.7 we investigate the societal components   \n172 of AR research. Finally, in Sections 4.8 and 4.9 we look at the aspects relevant to practitioners. ", "page_idx": 3}, {"type": "text", "text": "", "page_idx": 4}, {"type": "text", "text": "173 4.1 What types of contributions do the authors choose to make to the AR research? ", "text_level": 1, "page_idx": 4}, {"type": "text", "text": "174 We start by looking at the main goals of the collected publications to validate our assumption that   \n175 AR literature is primarily concerned with technical solutions. We annotate each entry with at most   \n176 two codes based on the form of contributions. By far the largest group is propose methods, which   \n177 applies to 88 $(69.3\\%)$ out of the 127 publications. These are primarily generators for individual CEs,   \n178 but we also find 18 $.14.2\\%)$ documents that propose other methods. Next, 20 $(15.7\\%)$ publications   \n179 develop theoretical frameworks, for instance by grounding AR in user studies or providing critical   \n180 perspectives on the problem. Further, 15 $(11.8\\%)$ focus on empirical or theoretical analyses of the   \n181 properties of AR and another 15 publications apply it in a variety of domains. We did not identify   \n182 any applications evaluated with humans in the loop. Then, 5 $(3.9\\%)$ publications benchmark existing   \n183 methods, while 3 $(2.4\\%)$ review them. We make our annotations available in technical Appendix B. ", "page_idx": 4}, {"type": "text", "text": "184 4.2 What are the criteria covered in the authors\u2019 definitions of AR? ", "text_level": 1, "page_idx": 4}, {"type": "text", "text": "185 We also evaluate what is understood as the problem to be addressed by AR mechanisms. In particular,   \n186 what are the criteria to satisfy authors\u2019 definitions of recourse. A similar question was posed by [70]   \n187 who combined six definitions into \u201crecourse can be achieved by an affected individual if they can   \n188 understand and accordingly act to alleviate an unfavorable situation, thus exercising temporally  \n189 extended agency\u201d, but this approach was far from systematic. Instead, we are interested in the   \n190 underlying concepts. 74 $(58.3\\%)$ publications explicitly define AR, 16 $(12.6\\%)$ mention it but do not   \n191 include a definition, while 37 $(29.1\\%)$ do not mention AR, even though they align with its (overall)   \n192 goals. The most common theme is overturning undesirable decisions, present in 47 definitions $(63.5\\%$   \n193 of all definitions), but specifically overturning algorithmic decisions is mentioned only 43 $(58.1\\%)$   \n194 times. It is generally understood that AR is provided to affected individuals (44, or $59.5\\%$ ) but 4 $(5.4\\%)$   \n195 definitions consider stakeholders more broadly. Actionability as a requirement for recourse is noted   \n196 in only 39 $(52.7\\%)$ definitions. Then, 20 $(27.0\\%)$ publications specifically mention counterfactual   \n197 explanations as means to AR, while 26 $(35.1\\%)$ include various other technical considerations in the   \n198 definitions, such as \u201cchanges to actionable input variables\u201d or \u201cdesired classes\u201d.   \n199 We also point to several themes that are, interestingly, underrepresented. Only 18 $(24.3\\%)$ documents   \n200 mention explanation, justification, or understanding of a decision as the pre-requisite for AR. Next,   \n201 10 $(13.5\\%)$ highlight future-orientation or other temporal aspects of the provided recommendations.   \n202 Although \u201cconsequential settings\u201d, typically bank lending, are given as examples in nine $(12.2\\%)$   \n203 definitions, they are never explicitly mentioned as the scenarios where recourse ought to be provided,   \n204 which may be akin to the \u201cenjoyment of recourse\u201d as defined by [142] where people are aware that   \n205 there exists a way to reverse undesirable decisions.1 8 publications $(10.8\\%)$ promote $A R$ as an ability.   \n206 Finally, only 2 $(2.7\\%)$ publications require that recourse accounts for the preferences of its recipients. ", "page_idx": 4}, {"type": "text", "text": "", "page_idx": 4}, {"type": "text", "text": "207 4.3 What are the criteria covered in the authors\u2019 definitions of actionability? ", "text_level": 1, "page_idx": 4}, {"type": "text", "text": "208 As we observe, \u201cactionability\u201d is a concept that underpins AR but we discover that, in general, its   \n209 understanding is limited. 91 $(71.6\\%)$ publications attempt to define what it means (for a CE) to be   \n210 actionable. Most commonly, in 48 $(52.7\\%)$ out of 91 definitions, it is understood as acting only on   \n211 directly-mutable features, 6 $(6.6\\%)$ distinguish that features may be indirectly-mutable but still not   \n212 actionable, while 22 $(24.2\\%)$ also highlight that feature values may need to be constrained. Next, 19   \n213 $(20.9\\%)$ definitions rely on a tautology that actionability means people can take actions, 11 $(12.1\\%)$   \n214 emphasize that these actions must be successful or lead to change, and 3 $(3.3\\%)$ further require   \n215 that they are aligned with people\u2019s real-world objectives. Only 14 $\\left[15.4\\%\\right)$ definitions put users   \n216 at the center stage, indicating that actionability depends on the user or their preferences, while 2   \n217 $(2.2\\%)$ highlight the importance of the context [144, 156], for instance, that the ability to act on a   \n218 recommendation may change over time. Importantly, ethical considerations are never mentioned as   \n219 the pre-requisite for actionability, but we find some broader discussions about this [e.g., 142]. ", "page_idx": 4}, {"type": "text", "text": "", "page_idx": 5}, {"type": "text", "text": "220 4.4 What is the role of end users? What other stakeholders are envisioned in the AR process? ", "text_level": 1, "page_idx": 5}, {"type": "text", "text": "221 Given that AR is to be implemented in socio-technical systems that include a variety of actors, we   \n222 are interested in the types of stakeholders acknowledged in the literature. A total of 105 publications   \n223 provide explicit consideration of this type. In general, end users subject to algorithmic decisions   \n224 are envisioned to be the recipients of AR, but this is not always the case: it may also be provided to   \n225 experts [e.g., 21, 22, 76] or organizations [e.g., 65, 72, 147], which highlights that in some cases AR   \n226 may be carried out on behalf of the affected individuals. In any case, 47 $(44.8\\%)$ publications in the   \n227 subset agree that end users should inform actionability, but it is rarely clear how these preferences   \n228 should be specified. User-friendly (interactive) interfaces are a consideration in only 14 $(13.3\\%)$   \n229 documents. A total of 29 $(27.6\\%)$ publications envision domain experts as someone who inform   \n230 the recourse process. They are either expected to inform actionability in the AR system or provide   \n231 other forms of knowledge, typically in the form of a causal structure. Besides the experts, authors   \n232 of 35 $(33.3\\%)$ papers have discussed a variety of stakeholders. Most commonly system owners   \n233 [e.g., 20, 34, 38, 89], but also auditors [e.g., 138, 158], data scientists [e.g., 28, 82], developers [e.g.,   \n234 22, 131], practitioners [e.g., 100, 156], regulators [e.g., 28, 120], or even potential attackers [102]. ", "page_idx": 5}, {"type": "text", "text": "235 4.5 What types of real-world considerations motivate existing research? ", "text_level": 1, "page_idx": 5}, {"type": "text", "text": "236 With the multitude of challenges that stand ahead of real-world AR, we are interested in the considera  \n237 tions that motivate existing work. The main theme we find is ensuring proper individual actionability,   \n238 which is addressed in 46 $(37.4\\%)$ of 123 publications relevant to this question. This is typically   \n239 achieved with the encoding of user preferences as constraints, but other means include providing   \n240 diverse CEs. In fact, tackling specific desiderata for AR (beyond actionability) is the second largest   \n241 area of research with 28 $(22.8\\%)$ publications. Various other technical challenges are considered   \n242 in 24 $(19.5\\%)$ documents, for example, integrating background knowledge [e.g., 16, 62, 64, 98], or   \n243 incorporating feature importance [e.g., 4, 6, 96, 116]. We also find 19 $(15.4\\%)$ publications that   \n244 discuss the problem of communicating recourse to the end users. 16 $(13.0\\%)$ focus on the dynamics   \n245 of real-world systems, typically addressing the robustness of AR [e.g., 75, 91, 93, 137], while 14   \n246 $(11.4\\%)$ look at recourse in multi-agent systems. This also relates to performance considerations   \n247 emphasized in 15 $(12.2\\%)$ of documents. Causality drives research in 14 $(11.4\\%)$ cases. We also   \n248 find several themes that are under-emphasized: only 9 $(7.3\\%)$ publications are directly motivated by   \n249 research in psychology, while ethics of $A R$ are emphasized in only 7 $(5.7\\%)$ documents. ", "page_idx": 5}, {"type": "text", "text": "250 4.6 What types of real-world considerations are seen as challenges for future work? ", "text_level": 1, "page_idx": 5}, {"type": "text", "text": "251 While the previous section looked at the considerations that drive existing research, in this section we   \n252 distill the recommendations for future research going beyond the improvement of own work, which   \n253 are provided in 74 documents. Causality is highlighted as a challenge in 22 $(29.7\\%)$ of them, while   \n254 other technical considerations are given in 20 $(27.0\\%)$ cases. These range from robustness [e.g.,   \n255 51, 117, 137], support for categorical features [e.g., 36, 157], or distinguishing between valid CEs and   \n256 adversarial examples [101]. Next, 19 $(25.6\\%)$ documents highlight the importance of ensuring proper   \n257 individual actionability, which also relates to communicating recourse to the end users (9, or $12.2\\%$ )   \n258 and supporting realistic cost functions (8, or $10.8\\%$ ). Ethics of AR are highlighted in 11 $(14.9\\%)$   \n259 publications, for example, that AR research may detract from other obligations of model owners   \n260 [77, 133]. The same number of publications emphasize the need to (1) ground research in user studies,   \n261 and (2) accommodate for the dynamics of real-world systems. Privacy or security is highlighted in 10   \n262 $(13.5\\%)$ documents, while the abuse of recourse, such as strategic behaviors, surfaces in 7 $(9.4\\%)$   \n263 papers. Other challenges include improving performance (8, or $10.8\\%$ ), considering multi-agent   \n264 systems (4, or $5.4\\%$ ), and developing legal frameworks (4, or $5.4\\%$ ) for recourse. We also highlight   \n265 several challenges particularly relevant to our work: (the usefulness of) recourse is perceived as   \n266 difficult to evaluate in practice [41, 60, 115], it must account for individual, contextual, societal, and   \n267 even cultural factors [123], which further means that engagement with recourse mechanisms and the   \n268 likelihood of its implementation are context-dependent [e.g., 6, 42, 128].   \n270 Real-world systems entail the implementation of recourse by more than one agent, which may   \n271 introduce group-level dynamics. Nonetheless, out of 119 documents relevant to this question, 93   \n272 $(78.2\\%)$ seem to understand recourse as a purely individual phenomenon. Among the remaining   \n273 26 documents we find considerations for several different group-level effects. Various perspectives   \n274 on the problem of fair AR, covering both individual and group formulations are addressed by   \n275 [12, 36, 52, 120, 121, 131, 149, 154]. Next, [9] shows that the implementation of AR on a large scale   \n276 may lead to domain and model shifts, which introduce unexpected costs for the stakeholders.2 In [42]   \n277 the authors focus on another negative consequence of AR at scale, showing that it may reinforce   \n278 social segregation. The impact of the \u201cright to be forgotten\u201d, where data deletion requests trigger   \n279 model retraining that may invalidate existing recourses is addressed in [75]. Then, [94] develop a   \n280 game-theoretic framework for AR in multi-agent settings, attempting to optimize for \u201csocial welfare\u201d   \n281 rather than the profits of individual agents. We find two further similar perspectives on recourse:   \n282 [38] proposes auditing and subsidies to minimize the risks of strategic behaviors in a multi-agent   \n283 setting, while [136] attempts to incentivize actual improvement for a population of agents. Finally,   \n284 [65] provides a framework that generates transparent and consistent recourses for a sub-population.   \n285 We also note two other lines of research that account for the remaining documents with group-level   \n286 considerations. First, in a causal setting [e.g., 68, 73] subpopulations are necessary to estimate   \n287 the interventional effects on individuals. Second, several works highlight the importance of global   \n288 insights into the data [22, 41, 44, 78, 108, 112, 152], such as recourse summaries [78, 112]. ", "page_idx": 5}, {"type": "text", "text": "", "page_idx": 6}, {"type": "text", "text": "289 4.8 What are the approaches to the realistic evaluation of proposed methods? ", "text_level": 1, "page_idx": 6}, {"type": "text", "text": "290 We now explore the different forms of \u201creal-world\u201d evaluations, going beyond quantitative experi  \n291 ments, which are present in 51 publications. Most commonly, in 28 $(54.9\\%)$ of those, the authors   \n292 make use of case studies presenting the methods in an end-to-end manner. Among those, the appli  \n293 cation of recourse in the Hired.com marketplace goes furthest in simulating real-world conditions   \n294 for AR [89], but the recommendations are still not evaluated with humans in the loop. Further, 9   \n295 $(17.6\\%)$ documents include other forms of short walk-through examples. We also identify 14 $(27.5\\%)$   \n296 papers that evaluate the methods with user experiments, 10 of which involve non-expert users and   \n297 4 involve expert users. While we do not observe any interviews with non-expert users, we find 1   \n298 $(2.0\\%)$ publication where experts are interviewed [22]. Other involvement of non-experts applies to   \n299 [116], where they inform the development of methods. Other involvement of experts is featured in   \n300 two documents where they evaluated the outputs of methods [25, 132]. Altogether, end users were   \n301 involved in 17 publications, which is only $13.3\\%$ of all publications covered in our study, even more   \n302 striking than the $21\\%$ of CE methods evaluated with user studies as reported in [71]. ", "page_idx": 6}, {"type": "text", "text": "303 4.9 What are the open source and documentation practices in AR research? ", "text_level": 1, "page_idx": 6}, {"type": "text", "text": "304 Finally, we note that the lack of availability of well-documented open-source code may be an important   \n305 obstacle to the application of AR in real-world systems. For all 116 publications that involve some   \n306 form of computational experiments, we verify whether the source code is publicly available. If the   \n307 authors do not explicitly link to their code in the paper, we attempt to find it independently. Ultimately,   \n308 we collect open-source implementations for 64 $(55.2\\%)$ publications. Then, for each of them, we   \n309 evaluate the quality of documentation. The instructions on the general usage (such as installation and   \n310 workflow) are provided with 27 $(41.5\\%)$ repositories, while instructions on the reproduction of results   \n311 in 23 $(35.4\\%)$ . In 19 $(29.2\\%)$ cases we find walk-through tutorials, typically in the form of Jupyter   \n312 Notebooks, although we note that they differ in quality. For instance, 5 repositories include code-only   \n313 notebooks with no further textual explanation that could guide the practitioner. Implementations   \n314 for 4 papers include more \u201cprofessionalized\u201d documentation [9, 86, 100, 156]. The latter sets a   \n315 golden standard as it further includes a tutorial video and a live demo. We do not find any additional   \n316 materials for practitioners for 13 $(20.0\\%)$ of the available implementations. ", "page_idx": 6}, {"type": "text", "text": "317 5 Discussion ", "text_level": 1, "page_idx": 7}, {"type": "text", "text": "318 Regardless of whether AR can be normatively expected or not [77], many systems can genuinely   \n319 benefti from recourse mechanisms, especially when the interests of the system owner and the end users   \n320 are aligned [72], such as in the healthcare system to improve the well-being of patients [76, 96, 155],   \n321 or on the online platforms that attempt to improve the experience of their users [89, 134]. Nonetheless,   \n322 the values and norms underlying recourse \u2013 trust, agency, fairness, safety, and so on \u2013 are emergent   \n323 properties of systems where recourse mechanisms would be introduced. Such norms can only be   \n324 understood and evaluated when accounting for the technical, social, and institutional components of   \n325 the system [32], but the latter two remain largely unexplored in the recourse literature.   \n326 Recourse is not inherently safe or unsafe, but its (incorrect) implementation may lead to the emer  \n327 gence of unsafe dynamics, such as the unexpected costs to stakeholders as discussed by [9] or the   \n328 reinforcement of social segregation addressed in [42]. While it may be too challenging to provide   \n329 accurate system-level evaluations at this stage of research, authors can still expand the boundaries   \n330 of their analyses to account for global effects or look at the position of recourse mechanisms in the   \n331 broader context of a complete socio-technical AI system [33]. As AR is a \u201creality-centric AI\u201d problem   \n332 [140] by its nature, working towards its integration into existing systems will require a design-oriented   \n333 approach, potentially with specific systems in mind. The \u201cAbstraction Traps\u201d discussed by [119] in   \n334 the context of research on fair machine learning apply here: that technical solutions designed for one   \n335 social context cannot be directly repurposed for another application, that values to which they are   \n336 expected to adhere to cannot be captured with mathematical formulas, that their insertion into an   \n337 existing process will impact its behavior, or that the best solutions may not necessarily be technical.   \n338 It is perhaps most telling that only $12\\%$ of surveyed publications attempt to apply recourse in realistic   \n339 settings. We will discuss two of these settings to highlight the stark differences in system properties.   \n340 Most of the applications included in our review focus on the provision of actionable individual   \n34 recommendations to students [3, 4, 24, 109, 126, 135, 160]. In this relatively low-stakes domain   \n342 almost any recourse will be actionable in that following a personalized set of learning activities   \n343 does not require any resources other than time. Even then, the system involves multiple actors   \n344 \u2013 students, teachers, parents \u2013 whose interactions will impact the process, for example, because   \n345 students may fail to benefit from certain learning activities without additional support. Conversely,   \n346 we find several publications where authors attempt to provide recourse in the high-stakes medical   \n347 domain [76, 96, 155]. Here, recommendations must be tailored to the preferences, resources, or   \n348 lifestyles of patients in order to have a chance of being actionable. Moreover, certain aspects of their   \n349 implementation fully rely on other actors, such as a clinician prescribing the medications. Finally, it   \n350 may happen that recourse does not exist at all when the outcomes of a patient cannot be improved. ", "page_idx": 7}, {"type": "text", "text": "", "page_idx": 7}, {"type": "text", "text": "", "page_idx": 7}, {"type": "text", "text": "351 5.1 Recommendations for future research ", "text_level": 1, "page_idx": 7}, {"type": "text", "text": "352 We distill our findings into five key recommendations. First, in Sections 4.2, 4.3 we observed that   \n353 operational definitions for recourse are still unavailable. Second, Sections 4.4 and 4.8 underlined   \n354 little consideration for people involved in recourse processes. Third, Sections 4.5, 4.6 highlighted the   \n355 overwhelmingly technical approaches to recourse. Fourth, Section 4.7 stressed the lack of group-level   \n356 analyses. Fifth, from Sections 4.8, and 4.9 we learned about the missing consideration of practitioners.   \n357 1. Broadening the scope of research. AR is generally seen as a service for affected individuals,   \n358 but this formalization may be unnecessarily limiting. In fact, in many systems, these individuals may   \n359 be unable to directly act on recommendations [see also 142]. Instead, we propose to operationalize   \n360 the aim of AR as the provision of recommendations aligned with the preferences of non-expert users   \n361 in an attempt to help them improve outcomes in an ADM setting, which emphasizes that providing   \n362 easy to understand and individually actionable recommendations remains the key research problem.   \n363 2. Engaging end users, affected individuals, and communities. AR solutions are rarely evaluated   \n364 with humans. Instead, they attempt to satisfy a variety of desiderata formulated by authors and   \n365 assessed in an automated manner. Sparsity, proximity, or mutability of features are far from perfect   \n366 proxies for individual actionability. For AR to be truly useful, it must be able to satisfy the preferences   \n367 of its end users. Research is also necessary to learn about the needs of the affected individuals   \n368 concerning recourse, and to validate its potential contributions and inherent limitations. Authors may   \n369 also benefit from the rich literature on human-computer interaction [e.g., 11, 23] or psychology.   \n370 3. Accepting a socio-technical perspective. A pervasive assumption in the literature is that all   \n371 challenges of AR require purely technical solutions. For instance, many authors emphasize the   \n372 importance of causal modeling to guarantee recourse, but the models that aim to be explained are   \n373 themselves not causal. Similarly, to improve the performance of CE generators many authors turn to   \n374 deep generative models [35, 42, 61, 67, 81, 90, 99]. Not only do they explain the data rather than the   \n375 model [10], but more importantly they shift the problem from improving the trust in non-interpretable   \n376 models, to attempting to trust non-interpretable explainers. Although a socio-technical perspective   \n377 on AR brings its own challenges, such as accounting for the roles of stakeholders involved in the   \n378 provision of recourse, it creates important opportunities. For example, developing \u201crecourse contracts\u201d   \n379 [34, 39] or designing feedback processes to account for imperfect robustness.   \n380 4. Accounting for emergent effects. Decision-making systems involve multiple individuals who   \n381 may be interested in receiving recourse and may have competing interests. Research on AR should,   \n382 from the onset, explore group-level effects such as external costs or fairness. While this may require   \n383 expanding the boundaries of analysis, it is necessary to anticipate the emergent outcomes of recourse.   \n384 These may even occur due to the multi-system dynamics of AR: recommendations implemented by   \n385 an individual to improve their outcomes in one system will affect them in other contexts [see also 13].   \n386 5. Attending to other operational aspects. Finally, the artifacts of AR research should be   \n387 practitioner-friendly. On the one hand, this requires being explicit about the position of the proposed   \n388 methods in a broader system, for example, in the form of end-to-end case studies that allow practi  \n389 tioners to better understand the benefits of the proposed solutions. On the other hand, this suggests   \n390 that authors should attempt to move away from merely providing scripts for experiments, and focus   \n391 on developing well-documented frameworks that can be adapted to different ADM systems. ", "page_idx": 7}, {"type": "text", "text": "", "page_idx": 7}, {"type": "text", "text": "", "page_idx": 7}, {"type": "text", "text": "", "page_idx": 8}, {"type": "text", "text": "", "page_idx": 8}, {"type": "text", "text": "", "page_idx": 8}, {"type": "text", "text": "392 5.2 Limitations of our work ", "text_level": 1, "page_idx": 8}, {"type": "text", "text": "393 Our review is not without shortcomings. Most importantly, for each paper the extraction and coding   \n394 of data was performed by a single author, which means that the quantitative results may be imperfect.   \n395 We account for this by focusing the analysis on the overarching themes represented in existing   \n396 publications, thus, even if another researcher would have carried out the coding in a somewhat   \n397 different manner, they should arrive at similar results and our analysis remains valid. Additionally, as   \n398 our review ultimately looks at the authors\u2019 perception of recourse, we do not want to misconstrue   \n399 their views. Thus, we do not infer any considerations unless they are provided explicitly. Our reading   \n400 may be more strict than intended by the authors and the numbers reported in our results may be   \n401 underestimated. At the same time, we believe that if certain considerations are deemed important   \n402 by the researchers, they would choose to be explicit about them. Finally, although we followed a   \n403 systematic process, we cannot claim that we collected AR literature in an exhaustive manner due to   \n404 the specificities of computer science publishing. Thus, we acknowledge that there may exist some   \n405 insightful publications addressing recourse that have not been covered in this literature review. ", "page_idx": 8}, {"type": "text", "text": "406 6 Conclusions ", "text_level": 1, "page_idx": 8}, {"type": "text", "text": "407 Algorithmic recourse concerns the provision of recommendations aligned with the preferences of   \n408 non-expert users of algorithmic decision-making systems to help them achieve more desirable out  \n409 comes in the future. Existing research on the topic is predominantly theoretical, even though recourse,   \n410 in expectation, is a real-world problem with strong practical implications. To that end, we conducted   \n411 a systematized literature review of 127 publications that focus on algorithmic recourse, and more gen  \n412 erally on actionable counterfactual explanations. We evaluated the practical considerations provided   \n413 by the authors. Our findings indicate that, indeed, AR tends to be perceived as a (predominantly)   \n414 technical problem. Although we think highly of fundamental research, we note that for algorithmic   \n415 recourse to leave computer science labs, it must be more strongly grounded and validated in the real   \n416 world, and consider the requirements for systems that include not only technical but also social and   \n417 institutional components. To help bridge this gap, we synthesize a list of five recommendations for   \n418 other authors that aim to reinforce recourse as a practical problem. We believe that AR should not be   \n419 seen as only a simple ad-hoc solution to improve the acceptance of black-box models in consequential   \n420 domains, but rather as a full-fledged socio-technical mechanism that can benefit many systems and   \n421 improve the agency of affected individuals and decision-makers across a variety of settings. ", "page_idx": 8}, {"type": "text", "text": "422 References ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "423 [1] Abubakar Abid, Mert Yuksekgonul, and James Zou. Meaningfully Debugging Model Mistakes   \n424 using Conceptual Counterfactual Explanations. In Proceedings of the 39th International   \n425 Conference on Machine Learning, volume 162 of Proceedings of Machine Learning Research,   \n426 pages 66\u201388. PMLR, 17\u201323 Jul 2022. URL https://proceedings.mlr.press/v162/a   \n427 bid22a.html.   \n428 [2] Gediminas Adomavicius and Alexander Tuzhilin. Discovery of Actionable Patterns in   \n429 Databases: The Action Hierarchy Approach. In Proceedings of the Third International   \n430 Conference on Knowledge Discovery and Data Mining, KDD\u201997, page 111\u2013114. AAAI Press,   \n431 1997.   \n432 [3] Farzana Afrin, Margaret Hamilton, and Charles Thevathyan. Exploring Counterfactual Ex  \n433 planations for Predicting Student Success. In Computational Science \u2013 ICCS 2023, volume   \n434 14074 LNCS, pages 413\u2013420. Springer Nature Switzerland, 2023. doi: 10.1007/978-3-031-3   \n435 6021-3_44.   \n436 [4] Muhammad Afzaal, Jalal Nouri, Aayesha Zia, Panagiotis Papapetrou, Uno Fors, Xiu Wu,   \n437 Yongchaoand Li, and Rebecka Weegar. Automatic and Intelligent Recommendations to   \n438 Support Students\u2019 Self-Regulation. In 2021 International Conference on Advanced Learning   \n439 Technologies (ICALT), pages 336\u2013338, July 2021. ISBN 2161-377X. doi: 10.1109/ICALT522   \n440 72.2021.00107.   \n441 [5] Charu C. Aggarwal, Chen Chen, and Jiawei Han. The Inverse Classification Problem. Journal   \n442 of Computer Science and Technology, 25:458\u2013468, 2010.   \n443 [6] Emanuele Albini, Jason Long, Danial Dervovic, and Daniele Magazzeni. Counterfactual   \n444 Shapley Additive Explanations. In Proceedings of the 2022 ACM Conference on Fairness,   \n445 Accountability, and Transparency, FAccT \u201922, page 1054\u20131070, New York, NY, USA, 2022.   \n446 Association for Computing Machinery. ISBN 9781450393522. doi: 10.1145/3531146.3533168.   \n447 URL https://doi.org/10.1145/3531146.3533168.   \n448 [7] Kars Alfrink, Ianus Keller, Gerd Kortuem, and Neelke Doorn. Contestable AI by design:   \n449 Towards a framework. Minds and Machines, pages 1\u201327, 2022.   \n450 [8] Hissah Alotaibi and Ronal Singh. Metrics for Evaluating Actionability in Explainable AI. In   \n451 PRICAI 2023: Trends in Artificial Intelligence, pages 481\u2013487. Springer Nature Singapore,   \n452 2023. ISBN 978-981-99-7022-3.   \n453 [9] Patrick Altmeyer, Giovan Angela, Aleksander Buszydlik, Karol Dobiczek, Arie van Deursen,   \n454 and Cynthia C. S. Liem. Endogenous Macrodynamics in Algorithmic Recourse. In 2023 IEEE   \n455 Conference on Secure and Trustworthy Machine Learning (SaTML), pages 418\u2013431, 2023.   \n456 doi: 10.1109/SaTML54575.2023.00036.   \n457 [10] Patrick Altmeyer, Mojtaba Farmanbar, Arie van Deursen, and Cynthia C. S. Liem. Faithful   \n458 Model Explanations through Energy-Constrained Conformal Counterfactuals. In Proceedings   \n459 of the AAAI Conference on Artificial Intelligence, volume 38, pages 10829\u201310837, 2024.   \n460 [11] Saleema Amershi, Maya Cakmak, William Bradley Knox, and Todd Kulesza. Power to the   \n461 People: The Role of Humans in Interactive Machine Learning. AI Magazine, 35(4):105\u2013120,   \n462 2014.   \n463 [12] Andr\u00e9 Artelt, Valerie Vaquet, Riza Velioglu, Fabian Hinder, Johannes Brinkrolf, Malte   \n464 Schilling, and Barbara Hammer. Evaluating Robustness of Counterfactual Explanations. In   \n465 2021 IEEE Symposium Series on Computational Intelligence (SSCI), pages 01\u201309, December   \n466 2021. doi: 10.1109/SSCI50451.2021.9660058.   \n467 [13] Solon Barocas, Andrew D. Selbst, and Manish Raghavan. The Hidden Assumptions Behind   \n468 Counterfactual Explanations and Principal Reasons. In Proceedings of the 2020 Conference on   \n469 Fairness, Accountability, and Transparency, FAT\\* \u201920, page 80\u201389, New York, NY, USA, 2020.   \n470 Association for Computing Machinery. ISBN 9781450369367. doi: 10.1145/3351095.3372830.   \n471 URL https://doi.org/10.1145/3351095.3372830.   \n472 [14] Hosein Barzekar and Susan McRoy. Achievable Minimally-Contrastive Counterfactual   \n473 Explanations. Machine Learning and Knowledge Extraction, 5(3):922\u2013936, 2023. doi:   \n474 10.3390/make5030048.   \n475 [15] Sander Beckers. Causal Explanations and XAI. In Bernhard Sch\u00f6lkopf, Caroline Uhler, and   \n476 Kun Zhang, editors, Proceedings of the First Conference on Causal Learning and Reasoning,   \n477 volume 177 of Proceedings of Machine Learning Research, pages 90\u2013109. PMLR, 11\u201313 Apr   \n478 2022. URL https://proceedings.mlr.press/v177/beckers22a.html.   \n479 [16] Alexander Berman, Ellen Breitholtz, Christine Howes, and Jean-Philippe Bernardy. Explaining   \n480 Predictions with Enthymematic Counterfactuals. In CEUR Workshop Proceedings, volume   \n481 3319, pages 95\u2013100. CEUR-WS, 2022.   \n482 [17] Umang Bhatt, Alice Xiang, Shubham Sharma, Adrian Weller, Ankur Taly, Yunhan Jia, Joy  \n483 deep Ghosh, Ruchir Puri, Jos\u00e9 M. F. Moura, and Peter Eckersley. Explainable Machine   \n484 Learning in Deployment. In Proceedings of the 2020 Conference on Fairness, Accountability,   \n485 and Transparency, FAT\\* \u201920, page 648\u2013657, New York, NY, USA, 2020. Association for   \n486 Computing Machinery. ISBN 9781450369367. doi: 10.1145/3351095.3375624. URL   \n487 https://doi.org/10.1145/3351095.3375624.   \n488 [18] Abeba Birhane, Pratyusha Kalluri, Dallas Card, William Agnew, Ravit Dotan, and Michelle   \n489 Bao. The Values Encoded in Machine Learning Research. In Proceedings of the 2022 ACM   \n490 Conference on Fairness, Accountability, and Transparency, FAccT \u201922, page 173\u2013184, New   \n491 York, NY, USA, 2022. Association for Computing Machinery. ISBN 9781450393522. doi:   \n492 10.1145/3531146.3533083. URL https://doi.org/10.1145/3531146.3533083.   \n493 [19] Miguel \u00c1. Carreira-Perpi\u00f1\u00e1n and Suryabhan Singh Hada. Counterfactual Explanations for   \n494 Oblique Decision Trees: Exact, Efficient Algorithms. Proceedings of the AAAI Conference   \n495 on Artificial Intelligence, 35:6903\u20136911, May 2021. doi: 10.1609/aaai.v35i8.16851. URL   \n496 https://ojs.aaai.org/index.php/AAAI/article/view/16851.   \n497 [20] Yatong Chen, Jialu Wang, and Yang Liu. Strategic Recourse in Linear Classification. In   \n498 Workshop on Consequential Decision Making in Dynamic Environments, 2020.   \n499 [21] Ziheng Chen, Fabrizio Silvestri, Gabriele Tolomei, Jia Wang, He Zhu, and Hongshik Ahn.   \n500 Explain the Explainer: Interpreting Model-Agnostic Counterfactual Explanations of a Deep   \n501 Reinforcement Learning Agent. IEEE Transactions on Artificial Intelligence, 5(4):1443\u20131457,   \n502 2024. doi: 10.1109/TAI.2022.3223892.   \n503 [22] Furui Cheng, Yao Ming, and Huamin Qu. DECE: Decision Explorer with Counterfactual   \n504 Explanations for Machine Learning Models. IEEE Transactions on Visualization & Computer   \n505 Graphics, 27(02):1438\u20131447, feb 2021. ISSN 1941-0506. doi: 10.1109/TVCG.2020.3030342.   \n506 [23] Hao-Fei Cheng, Ruotong Wang, Zheng Zhang, Fiona O\u2019Connell, Terrance Gray, F. Maxwell   \n507 Harper, and Haiyi Zhu. Explaining Decision-Making Algorithms through UI: Strategies   \n508 to Help Non-Expert Stakeholders. In Proceedings of the 2019 CHI Conference on Human   \n509 Factors in Computing Systems, CHI \u201919, page 1\u201312, New York, NY, USA, 2019. Association   \n510 for Computing Machinery. ISBN 9781450359702. doi: 10.1145/3290605.3300789. URL   \n511 https://doi.org/10.1145/3290605.3300789.   \n512 [24] Lea Cohausz. Towards Real Interpretability of Student Success Prediction Combining Methods   \n513 of XAI and Social Science. In Proceedings of the 15th International Conference on Educational   \n514 Data Mining, pages 361\u2013367, Durham, United Kingdom, July 2022. International Educational   \n515 Data Mining Society. ISBN 978-1-7336736-3-1. doi: 10.5281/zenodo.6853069.   \n516 [25] Riccardo Crupi, Alessandro Castelnovo, Daniele Regoli, and Beatriz San Miguel Gonzalez.   \n517 Counterfactual Explanations as Interventions in Latent Space. Data Mining and Knowledge   \n518 Discovery, 2022. doi: 10.1007/s10618-022-00889-2.   \n519 [26] Susanne Dandl, Christoph Molnar, Martin Binder, and Bernd Bischl. Multi-Objective Coun  \n520 terfactual Explanations. In Parallel Problem Solving from Nature \u2013 PPSN XVI, pages   \n521 448\u2013469, Cham, 2020. Springer International Publishing. ISBN 978-3-030-58112-1. doi:   \n522 10.1007/978-3-030-58112-1_3.   \n523 [27] Debanjan Datta, Feng Chen, and Naren Ramakrishnan. Framing Algorithmic Recourse for   \n524 Anomaly Detection. In Proceedings of the 28th ACM SIGKDD Conference on Knowledge   \n525 Discovery and Data Mining, KDD \u201922, page 283\u2013293, New York, NY, USA, 2022. Association   \n526 for Computing Machinery. ISBN 9781450393850. doi: 10.1145/3534678.3539344. URL   \n527 https://doi.org/10.1145/3534678.3539344.   \n528 [28] Randall Davis, Andrew W. Lo, Sudhanshu Mishra, Arash Nourian, Manish Singh, Nicholas   \n529 Wu, and Ruixun Zhang. Explainable Machine Learning Models of Consumer Credit Risk.   \n530 Journal of Financial Data Science, 5(4):9\u201339, 2022. doi: 10.3905/jfds.2023.1.141.   \n531 [29] Marcelo de Sousa Balbino, Luis Enrique Z\u00e1rate G\u00e1lvez, and Cristiane Neri Nobre. CSSE   \n532 - An agnostic method of counterfactual, selected, and social explanations for classification   \n533 models. Expert Systems with Applications, 228:120373, 2023. ISSN 0957-4174. doi: https:   \n534 //doi.org/10.1016/j.eswa.2023.120373. URL https://www.sciencedirect.com/scienc   \n535 e/article/pii/S0957417423008758.   \n536 [30] Giovanni De Toni, Bruno Lepri, and Andrea Passerini. Synthesizing explainable counterfactual   \n537 policies for algorithmic recourse with program synthesis. Machine Learning, 112(4):1389\u2013   \n538 1409, 2023. ISSN 0885-6125. doi: 10.1007/s10994-022-06293-7.   \n539 [31] Sarah Dean, Sarah Rich, and Benjamin Recht. Recommendations and User Agency: The   \n540 Reachability of Collaboratively-Filtered Information. In Proceedings of the 2020 Conference   \n541 on Fairness, Accountability, and Transparency, FAT\\* \u201920, page 436\u2013445, New York, NY, USA,   \n542 2020. Association for Computing Machinery. ISBN 9781450369367. doi: 10.1145/3351095.   \n543 3372866. URL https://doi.org/10.1145/3351095.3372866.   \n544 [32] Roel Dobbe and Anouk Wolters. Toward Sociotechnical AI: Mapping Vulnerabilities for   \n545 Machine Learning in Context. Minds and Machines, 34(2):1\u201351, 2024.   \n546 [33] Roel Dobbe, Thomas Krendl Gilbert, and Yonatan Mintz. Hard choices in artificial intelligence.   \n547 Artificial Intelligence, 300:103555, 2021. ISSN 0004-3702. doi: https://doi.org/10.1016/j.arti   \n548 nt.2021.103555. URL https://www.sciencedirect.com/science/article/pii/S0   \n549 004370221001065.   \n550 [34] Ricardo Dominguez-Olmedo, Amir-Hossein Karimi, and Bernhard Sch\u00f6lkopf. On the Adver  \n551 sarial Robustness of Causal Algorithmic Recourse. In Proceedings of the 39th International   \n552 Conference on Machine Learning, volume 162 of Proceedings of Machine Learning Research,   \n553 pages 5324\u20135342. PMLR, 17\u201323 2022.   \n554 [35] Michael Downs, Jonathan L. Chu, Yaniv Yacoby, Finale Doshi-Velez, and Weiwei Pan.   \n555 CRUDS: Counterfactual Recourse Using Disentangled Subspaces. ICML Workshop on Human   \n556 Interpretability in Machine Learning, pages 1\u201323, 2020.   \n557 [36] Ahmad-Reza Ehyaei, Amir-Hossein Karimi, Bernhard Schoelkopf, and Setareh Maghsudi.   \n558 Robustness Implies Fairness in Causal Algorithmic Recourse. In Proceedings of the 2023   \n559 ACM Conference on Fairness, Accountability, and Transparency, FAccT \u201923, page 984\u20131001,   \n560 New York, NY, USA, 2023. Association for Computing Machinery. ISBN 9798400701924.   \n561 doi: 10.1145/3593013.3594057. URL https://doi.org/10.1145/3593013.3594057.   \n562 [37] Julia El Zini and Mariette Awad. Beyond Model Interpretability: On the Faithfulness and   \n563 Adversarial Robustness of Contrastive Textual Explanations. In Findings of the Association for   \n564 Computational Linguistics: EMNLP 2022, pages 1391\u20131402. Association for Computational   \n565 Linguistics, 2022. doi: 10.18653/v1/2022.findings-emnlp.100.   \n566 [38] Andrew Estornell, Yatong Chen, Sanmay Das, Yang Liu, and Yevgeniy Vorobeychik. Incen  \n567 tivizing Recourse through Auditing in Strategic Classification. In Proceedings of the Thirty  \n568 Second International Joint Conference on Artificial Intelligence, IJCAI-23, pages 400\u2013408.   \n569 International Joint Conferences on Artificial Intelligence, 8 2023. doi: 10.24963/ijcai.2023/45.   \n570 URL https://doi.org/10.24963/ijcai.2023/45.   \n571 [39] Andrea Ferrario and Michele Loi. The Robustness of Counterfactual Explanations Over Time.   \n572 IEEE Access, 10:82736\u201382750, 2022. ISSN 2169-3536. doi: 10.1109/ACCESS.2022.3196917.   \n573 [40] Susanne Friese, Jacks Soratto, and Denise Pires de Pires. Carrying out a computer-aided   \n574 thematic content analysis with ATLAS.ti. IWMI Working Papers, 18, 04 2018.   \n575 [41] Sainyam Galhotra, Romila Pradhan, and Babak Salimi. Explaining Black-Box Algorithms   \n576 Using Probabilistic Contrastive Counterfactuals. In Proceedings of the 2021 International   \n577 Conference on Management of Data, SIGMOD \u201921, pages 577\u2013590, New York, NY, USA,   \n578 2021. Association for Computing Machinery. ISBN 978-1-4503-8343-1. doi: 10.1145/344801   \n579 6.3458455.   \n580 [42] Ruijiang Gao and Himabindu Lakkaraju. On the Impact of Algorithmic Recourse on Social   \n581 Segregation. In Proceedings of the 40th International Conference on Machine Learning,   \n582 ICML\u201923. JMLR.org, 2023.   \n583 [43] Azin Ghazimatin, Oana Balalau, Rishiraj Saha Roy, and Gerhard Weikum. PRINCE: Provider  \n584 Side Interpretability with Counterfactual Explanations in Recommender Systems. In Pro  \n585 ceedings of the 13th International Conference on Web Search and Data Mining, WSDM \u201920,   \n586 pages 196\u2013204, New York, NY, USA, 2020. Association for Computing Machinery. ISBN   \n587 978-1-4503-6822-3. doi: 10.1145/3336191.3371824.   \n588 [44] Oscar Gomez, Steffen Holter, Jun Yuan, and Enrico Bertini. ViCE: Visual Counterfactual Ex  \n589 planations for Machine Learning Models. In Proceedings of the 25th International Conference   \n590 on Intelligent User Interfaces, IUI \u201920, pages 531\u2013535, New York, NY, USA, 2020. Association   \n591 for Computing Machinery. ISBN 978-1-4503-7118-6. doi: 10.1145/3377325.3377536.   \n592 [45] Crystal Grant. Algorithms Are Making Decisions About Health Care, Which May Only   \n593 Worsen Medical Racism, October 2022. URL https://www.aclu.org/news/privacy-t   \n594 echnology/algorithms-in-health-care-may-worsen-medical-racism. Accessed   \n595 22.05.2024.   \n596 [46] Maria J. Grant and Andrew Booth. A typology of reviews: an analysis of 14 review types and   \n597 associated methodologies. Health Information & Libraries Journal, 26(2):91\u2013108, 2009. doi:   \n598 https://doi.org/10.1111/j.1471-1842.2009.00848.x.   \n599 [47] Stephan Grimmelikhuijsen and Albert Meijer. Legitimacy of Algorithmic Decision-Making:   \n600 Six Threats and the Need for a Calibrated Institutional Response. Perspectives on Public   \n601 Management and Governance, 5(3):232\u2013242, 03 2022. ISSN 2398-4910. doi: 10.1093/ppmg   \n602 ov/gvac008. URL https://doi.org/10.1093/ppmgov/gvac008.   \n603 [48] Riccardo Guidotti. Counterfactual Explanations and How to Find Them: Literature Review   \n604 and Benchmarking. Data Mining and Knowledge Discovery, 2022. doi: 10.1007/s10618-022   \n605 -00831-6.   \n606 [49] Riccardo Guidotti and Salvatore Ruggieri. Ensemble of Counterfactual Explainers. In   \n607 Discovery Science: 24th International Conference, DS 2021, Halifax, NS, Canada, October   \n608 11\u201313, 2021, Proceedings, pages 358\u2013368, Berlin, Heidelberg, 2021. Springer-Verlag. ISBN   \n609 978-3-030-88941-8. doi: 10.1007/978-3-030-88942-5_28.   \n610 [50] Riccardo Guidotti, Anna Monreale, Salvatore Ruggieri, Francesca Naretto, Franco Turini,   \n611 Dino Pedreschi, and Fosca Giannotti. Stable and Actionable Explanations of Black-Box   \n612 Models through Factual and Counterfactual Rules. Data Mining and Knowledge Discovery,   \n613 2022. doi: 10.1007/s10618-022-00878-5.   \n614 [51] Hangzhi Guo, Feiran Jia, Jinghui Chen, Anna Squicciarini, and Amulya Yadav. RoCourseNet:   \n615 Robust Training of a Prediction Aware Recourse Model. In Proceedings of the 32nd ACM   \n616 International Conference on Information and Knowledge Management, CIKM \u201923, pages 619\u2013   \n617 628, New York, NY, USA, 2023. Association for Computing Machinery. ISBN 9798400701245.   \n618 doi: 10.1145/3583780.3615040.   \n619 [52] Vivek Gupta, Pegah Nokhiz, Chitradeep Dutta Roy, and Suresh Venkatasubramanian. Equaliz  \n620 ing Recourse Across Groups. arXiv, 2019.   \n621 [53] Victor Guyomard, Fran\u00e7oise Fessant, Tassadit Bouadi, and Thomas Guyet. Post-hoc Coun  \n622 terfactual Generation with Supervised Autoencoder. In Communications in Computer and   \n623 Information Science, volume 1524 CCIS, pages 105\u2013114. Springer Science and Business   \n624 Media Deutschland GmbH, 2021. doi: 10.1007/978-3-030-93736-2_10.   \n625 [54] Victor Guyomard, Fran\u00e7oise Fessant, Thomas Guyet, Tassadit Bouadi, and Alexandre Termier.   \n626 Generating Robust Counterfactual Explanations. In Machine Learning and Knowledge Discov  \n627 ery in Databases: Research Track. ECML PKDD 2023, pages 394\u2013409, Berlin, Heidelberg,   \n628 2023. Springer-Verlag. ISBN 978-3-031-43417-4. doi: 10.1007/978-3-031-43418-1_24.   \n629 [55] Suryabhan Singh Hada and Miguel \u00c1. Carreira-Perpi\u00f1\u00e1n. Exploring Counterfactual Ex  \n630 planations for Classification and Regression Trees. In Communications in Computer and   \n631 Information Science, volume 1524 CCIS, pages 489\u2013504. Springer Science and Business   \n632 Media Deutschland GmbH, 2021. doi: 10.1007/978-3-030-93736-2_37.   \n633 [56] Aparajita Haldar, Teddy Cunningham, and Hakan Ferhatosmanoglu. RAGUEL: Recourse  \n634 Aware Group Unfairness Elimination. In Proceedings of the 31st ACM International Con  \n635 ference on Information & Knowledge Management, CIKM \u201922, pages 666\u2013675, New York,   \n636 NY, USA, 2022. Association for Computing Machinery. ISBN 978-1-4503-9236-5. doi:   \n637 10.1145/3511808.3557424.   \n638 [57] Ian Hardy, Jayanth Yetukuri, and Yang Liu. Adaptive Adversarial Training Does Not Increase   \n639 Recourse Costs. In Proceedings of the 2023 AAAI/ACM Conference on AI, Ethics, and Society,   \n640 AIES \u201923, pages 432\u2013442, New York, NY, USA, 2023. Association for Computing Machinery.   \n641 ISBN 9798400702310. doi: 10.1145/3600211.3604704.   \n642 [58] Zhian He and Eric Lo. Answering Why-not Questions on Top-k Queries. 2012 IEEE 28th   \n643 International Conference on Data Engineering, pages 750\u2013761, 2012. doi: 10.1109/ICDE.201   \n644 2.8.   \n645 [59] Hans Hofmann. Statlog (German Credit Data). UCI Machine Learning Repository, 1994. DOI:   \n646 https://doi.org/10.24432/C5NC77.   \n647 [60] Jacqueline H\u00f6llig, Aniek F. Markus, JJef de Slegte, and Prachi Bagave. Semantic Mean  \n648 ingfulness: Evaluating Counterfactual Approaches for Real-World Plausibility and Fea  \n649 sibility. In Communications in Computer and Information Science, volume 1902 CCIS,   \n650 pages 636\u2013659. Springer Science and Business Media Deutschland GmbH, 2023. doi:   \n651 10.1007/978-3-031-44067-0_32.   \n652 [61] Shalmali Joshi, Oluwasanmi Koyejo, Warut Vijitbenjaronk, Been Kim, and Joydeep Ghosh.   \n653 Towards Realistic Individual Recourse and Actionable Explanations in Black-Box Decision   \n654 Making Systems. arXiv, 2019.   \n655 [62] Sarathi K, Shania Mitra, Deepak P, and Sutanu Chakraborti. Counterfactuals as Explanations   \n656 for Monotonic Classifiers. In CEUR Workshop Proceedings, volume 3389, pages 177\u2013188.   \n657 CEUR-WS, 2022.   \n658 [63] Kentaro Kanamori, Takuya Takagi, Ken Kobayashi, and Hiroki Arimura. Distribution-Aware   \n659 Counterfactual Explanation by Mixed-Integer Linear Optimization. Transactions of the   \n660 Japanese Society for Artificial Intelligence, 36(6), 2021. doi: 10.1527/TJSAI.36-6_C-L44.   \n661 [64] Kentaro Kanamori, Takuya Takagi, Ken Kobayashi, Yuichi Ike, Kento Uemura, and Hiroki   \n662 Arimura. Ordered Counterfactual Explanation by Mixed-Integer Linear Optimization. In 35th   \n663 AAAI Conference on Artificial Intelligence, AAAI 2021, volume 13A, pages 11564\u201311574.   \n664 Association for the Advancement of Artificial Intelligence, 2021.   \n665 [65] Kentaro Kanamori, Takuya Takagi, Ken Kobayashi, and Yuichi Ike. Counterfactual Explanation   \n666 Trees: Transparent and Consistent Actionable Recourse with Decision Trees. In Proceedings   \n667 of The 25th International Conference on Artificial Intelligence and Statistics, volume 151,   \n668 pages 1846\u20131870. PMLR, 2022.   \n669 [66] Amir-Hossein Karimi, Gilles Barthe, Borja Balle, and Isabel Valera. Model-Agnostic Coun  \n670 terfactual Explanations for Consequential Decisions. In Proceedings of the Twenty Third   \n671 International Conference on Artificial Intelligence and Statistics, volume 108, pages 895\u2013905.   \n672 PMLR, 2020.   \n673 [67] Amir-Hossein Karimi, Julius Von K\u00fcgelgen, Bernhard Sch\u00f6lkopf, and Isabel Valera. Algorith  \n674 mic recourse under imperfect causal knowledge: a probabilistic approach. Advances in Neural   \n675 Information Processing Systems, 33:265\u2013277, 2020.   \n676 [68] Amir-Hossein Karimi, Julius von K\u00fcgelgen, Bernhard Sch\u00f6lkopf, and Isabel Valera. Towards   \n677 Causal Algorithmic Recourse. In xxAI - Beyond Explainable AI: International Workshop, Held   \n678 in Conjunction with ICML 2020, July 18, 2020, Vienna, Austria, Revised and Extended Papers,   \n679 pages 139\u2013166, Cham, 2020. Springer International Publishing. ISBN 978-3-031-04082-5.   \n680 doi: 10.1007/978-3-031-04083-2_8.   \n681 [69] Amir-Hossein Karimi, Bernhard Sch\u00f6lkopf, and Isabel Valera. Algorithmic Recourse: From   \n682 Counterfactual Explanations to Interventions. In Proceedings of the 2021 ACM Conference on   \n683 Fairness, Accountability, and Transparency, FAccT \u201921, pages 353\u2013362, New York, NY, USA,   \n684 2021. Association for Computing Machinery. ISBN 978-1-4503-8309-7. doi: 10.1145/344218   \n685 8.3445899.   \n686 [70] Amir-Hossein Karimi, Gilles Barthe, Bernhard Sch\u00f6lkopf, and Isabel Valera. A Survey of   \n687 Algorithmic Recourse: Contrastive Explanations and Consequential Recommendations. ACM   \n688 Computing Surveys, 55(5), December 2022. ISSN 0360-0300. doi: 10.1145/3527848.   \n689 [71] Mark T. Keane, Eoin M. Kenny, Eoin Delaney, and Barry Smyth. If Only We Had Better   \n690 Counterfactual Explanations: Five Key Deficits to Rectify in the Evaluation of Counterfactual   \n691 XAI Techniques. In Zhi-Hua Zhou, editor, Proceedings of the Thirtieth International Joint   \n692 Conference on Artificial Intelligence, IJCAI-21, pages 4466\u20134474. International Joint Con  \n693 ferences on Artificial Intelligence Organization, 8 2021. doi: 10.24963/ijcai.2021/609. URL   \n694 https://doi.org/10.24963/ijcai.2021/609. Survey Track.   \n695 [72] Nwaike Kelechi and Licheng Jiao. Quantifying Actionability: Evaluating Human-Recipient   \n696 Models. IEEE Access, 11:119811\u2013119823, 2023. ISSN 2169-3536. doi: 10.1109/ACCESS.2   \n697 023.3324906.   \n698 [73] Gunnar K\u00f6nig, Timo Freiesleben, and Moritz Grosse-Wentrup. Causal Perspective on Mean  \n699 ingful and Robust Algorithmic Recourse. ICML Workshop on Algorithmic Recourse, 2021.   \n700 [74] Gunnar K\u00f6nig, Timo Freiesleben, and Moritz Grosse-Wentrup. Improvement-Focused   \n701 Causal Recourse (ICR). In Proceedings of the Thirty-Seventh AAAI Conference on Arti  \n702 ficial Intelligence and Thirty-Fifth Conference on Innovative Applications of Artificial In  \n703 telligence and Thirteenth Symposium on Educational Advances in Artificial Intelligence,   \n704 AAAI\u201923/IAAI\u201923/EAAI\u201923. AAAI Press, 2023. ISBN 978-1-57735-880-0. doi: 10.1609/aa   \n705 ai.v37i10.26398.   \n706 [75] Satyapriya Krishna, Jiaqi Ma, and Himabindu Lakkaraju. Towards Bridging the Gaps between   \n707 the Right to Explanation and the Right to Be Forgotten. In Proceedings of the 40th International   \n708 Conference on Machine Learning, ICML\u201923. JMLR.org, 2023.   \n709 [76] Anisio Lacerda, Claudio Almeida, Leonardo Ferreira, Adriano Pereira, Gisele L. Pappa, Wag  \n710 ner Meira, Debora Miranda, Marco A. Romano-Silva, and Leandro Malloy Diniz. Algorithmic   \n711 Recourse in Mental Healthcare. In 2023 International Joint Conference on Neural Networks   \n712 (IJCNN), pages 1\u20138, June 2023. ISBN 2161-4407. doi: 10.1109/IJCNN54540.2023.10191158.   \n713 [77] Derek Leben. Explainable AI as evidence of fair decisions. Frontiers in Psychology, 14, 2023.   \n714 doi: 10.3389/fpsyg.2023.1069426.   \n715 [78] Dan Ley, Saumitra Mishra, and Daniele Magazzeni. GLOBE-CE: A Translation Based   \n716 Approach for Global Counterfactual Explanations. In Proceedings of the 40th International   \n717 Conference on Machine Learning, ICML\u201923. JMLR.org, 2023.   \n718 [79] Ana Lucic, Harrie Oosterhuis, Hinda Haned, and Maarten de Rijke. FOCUS: Flexible   \n719 Optimizable Counterfactual Explanations for Tree Ensembles. In Proceedings of the 36th   \n720 AAAI Conference on Artificial Intelligence, AAAI 2022, volume 36, pages 5313\u20135322, 2022.   \n721 [80] Shucen Ma, Jianqi Shi, Yanhong Huang, Shengchao Qin, and Zhe Hou. Minimal-unsatisfiable  \n722 core-driven Local Explainability Analysis for Random Forest. International Journal of   \n723 Software and Informatics, 12(4):355\u2013376, 2022. doi: 10.21655/ijsi.1673-7288.00280.   \n724 [81] Divyat Mahajan, Chenhao Tan, and Amit Sharma. Preserving Causal Constraints in Counter  \n725 factual Explanations for Machine Learning Classifiers. In NeurIPS 2019 Workshop \u201cDo the   \n726 right thing\u201d: machine learning and causal inference for improved decision making, 2019.   \n727 [82] Raphael Mazzine, Sofie Goethals, Dieter Brughmans, and David Martens. Counterfactual   \n728 Explanations for Employment Services. International workshop on AI for Human Resources   \n729 and Public Employment Services, 2021.   \n730 [83] Md Golam Moula Mehedi Hasan and Douglas A. Talbert. Mitigating the Rashomon Effect in   \n731 Counterfactual Explanation: A Game-theoretic Approach. In Proceedings of the International   \n732 Florida Artificial Intelligence Research Society Conference, FLAIRS, volume 35. Florida   \n733 Online Journals, University of Florida, 2022. doi: 10.32473/flairs.v35i.130711.   \n734 [84] Tim Miller. Explanation in artificial intelligence: Insights from the social sciences. Artificial   \n735 Intelligence, 267:1\u201338, 2019. ISSN 0004-3702. doi: https://doi.org/10.1016/j.artint.2018.07.0   \n736 07. URL https://www.sciencedirect.com/science/article/pii/S00043702183   \n737 05988.   \n738 [85] Jonathan Moore, Nils Hammerla, and Chris Watkins. Explaining Deep Learning Models with   \n739 Constrained Adversarial Examples. In PRICAI 2019: Trends in Artificial Intelligence: 16th   \n740 Pacific Rim International Conference on Artificial Intelligence, Cuvu, Yanuca Island, Fiji,   \n741 August 26\u201330, 2019, Proceedings, Part I, pages 43\u201356, Berlin, Heidelberg, 2019. Springer  \n742 Verlag. ISBN 978-3-030-29907-1. doi: 10.1007/978-3-030-29908-8_4.   \n743 [86] Ramaravind K. Mothilal, Amit Sharma, and Chenhao Tan. Explaining Machine Learning   \n744 Classifiers through Diverse Counterfactual Explanations. In Proceedings of the 2020 Confer  \n745 ence on Fairness, Accountability, and Transparency, FAT\\* \u201920, pages 607\u2013617, New York,   \n746 NY, USA, 2020. Association for Computing Machinery. ISBN 978-1-4503-6936-7. doi:   \n747 10.1145/3351095.3372850.   \n748 [87] Madhumita Murgia. Algorithms are deciding who gets organ transplants. Are their decisions   \n749 fair?, November 2023. URL https://www.ft.com/content/5125c83a-b82b-40c5-8   \n750 b35-99579e087951. Accessed 22.05.2024.   \n751 [88] Philip Naumann and Eirini Ntoutsi. Consequence-Aware Sequential Counterfactual Generation.   \n752 In Machine Learning and Knowledge Discovery in Databases. Research Track: European   \n753 Conference, ECML PKDD 2021, Bilbao, Spain, September 13\u201317, 2021, Proceedings, Part II,   \n754 pages 682\u2013698, Berlin, Heidelberg, 2021. Springer-Verlag. ISBN 978-3-030-86519-1. doi:   \n755 10.1007/978-3-030-86520-7_42.   \n756 [89] Daniel Nemirovsky, Nicolas Thiebaut, Ye Xu, and Abhishek Gupta. Providing Actionable   \n757 Feedback in Hiring Marketplaces using Generative Adversarial Networks. In WSDM 2021 -   \n758 Proceedings of the 14th ACM International Conference on Web Search and Data Mining, pages   \n759 1089\u20131092. Association for Computing Machinery, 2021. doi: 10.1145/3437963.3441705.   \n760 [90] Daniel Nemirovsky, Nicolas Thiebaut, Ye Xu, and Abhishek Gupta. CounteRGAN: Gener  \n761 ating Counterfactuals for Real-Time Recourse and Interpretability using Residual GANs. In   \n762 Proceedings of the 38th Conference on Uncertainty in Artificial Intelligence, UAI 2022, pages   \n763 1488\u20131497. Association For Uncertainty in Artificial Intelligence (AUAI), 2022.   \n764 [91] Duy Nguyen, Ngoc Bui, and Viet Anh Nguyen. Distributionally Robust Recourse Action.   \n765 arXiv, 2023.   \n766 [92] Duy Nguyen, Ngoc Bui, and Viet Anh Nguyen. Feasible Recourse Plan via Diverse Interpo  \n767 lation. In Proceedings of The 26th International Conference on Artificial Intelligence and   \n768 Statistics, volume 206, pages 4679\u20134698. PMLR, 2023.   \n769 [93] Tuan-Duy H. Nguyen, Ngoc Bui, Duy Nguyen, Man-Chung Yue, and Viet Anh Nguyen.   \n770 Robust Bayesian Recourse. In Proceedings of the Thirty-Eighth Conference on Uncertainty in   \n771 Artificial Intelligence, volume 180, pages 1498\u20131508. PMLR, 2022.   \n772 [94] Andrew O\u2019Brien and Edward Kim. Toward Multi-Agent Algorithmic Recourse: Challenges   \n773 From a Game-Theoretic Perspective. In Proceedings of the International Florida Artificial   \n774 Intelligence Research Society Conference, FLAIRS, volume 35. Florida Online Journals,   \n775 University of Florida, 2022. doi: 10.32473/flairs.v35i.130614.   \n776 [95] Andrew O\u2019Brien, Edward Kim, and Rosina Weber. Investigating Causally Augmented Sparse   \n777 Learning as a Tool for Meaningful Classification. In 2023 IEEE Sixth International Conference   \n778 on Artificial Intelligence and Knowledge Engineering (AIKE), pages 33\u201337, September 2023.   \n779 ISBN 2831-7203. doi: 10.1109/AIKE59827.2023.00013.   \n780 [96] Ming Lun Ong, Anthony Li, and Mehul Motani. Explainable and Actionable Machine Learning   \n781 Models for Electronic Health Record Data. In IFMBE Proceedings, volume 79, pages 91\u201399,   \n782 Cham, 2021. Springer International Publishing. doi: 10.1007/978-3-030-62045-5_9.   \n783 [97] Matthew J. Page, Joanne E. McKenzie, Patrick M. Bossuyt, Isabelle Boutron, Tammy C.   \n784 Hoffmann, Cynthia D. Mulrow, Larissa Shamseer, Jennifer M. Tetzlaff, Elie A. Akl, Sue E.   \n785 Brennan, et al. The PRISMA 2020 statement: an updated guideline for reporting systematic   \n786 reviews. Bmj, 372, 2021.   \n787 [98] Axel Parmentier and Thibaut Vidal. Optimal Counterfactual Explanations in Tree Ensembles.   \n788 In Proceedings of the 38th International Conference on Machine Learning, volume 139, pages   \n789 8422\u20138431. PMLR, 2021.   \n790 [99] Martin Pawelczyk, Klaus Broelemann, and Gjergji Kasneci. Learning Model-Agnostic Counter  \n791 factual Explanations for Tabular Data. In The Web Conference 2020 - Proceedings of the World   \n792 Wide Web Conference, WWW 2020, pages 3126\u20133132, 2020. doi: 10.1145/3366423.3380087.   \n793 [100] Martin Pawelczyk, Sascha Bielawski, Johannes van den Heuvel, Tobias Richter, and Gjergji   \n794 Kasneci. CARLA: A Python Library to Benchmark Algorithmic Recourse and Counterfactual   \n795 Explanation Algorithms. In Proceedings of the Neural Information Processing Systems Track   \n796 on Datasets and Benchmarks 1 (NeurIPS Datasets and Benchmarks 2021), 2021.   \n797 [101] Martin Pawelczyk, Chirag Agarwal, Shalmali Joshi, Sohini Upadhyay, and Himabindu   \n798 Lakkaraju. Exploring Counterfactual Explanations Through the Lens of Adversarial Ex  \n799 amples: A Theoretical and Empirical Analysis. In Proceedings of The 25th International   \n800 Conference on Artificial Intelligence and Statistics, volume 151, pages 4574\u20134594. PMLR,   \n801 2022.   \n802 [102] Martin Pawelczyk, Himabindu Lakkaraju, and Seth Neel. On the Privacy Risks of Algorithmic   \n803 Recourse. In Proceedings of The 26th International Conference on Artificial Intelligence and   \n804 Statistics, volume 206, pages 9680\u20139696. PMLR, 2023.   \n805 [103] Judea Pearl. Causality. Cambridge University Press, 2 edition, 2009. ISBN 9780511803161.   \n806 [104] Rafael Poyiadzi, Kacper Sokol, Raul Santos-Rodriguez, Tijl De Bie, and Peter Flach. FACE:   \n807 Feasible and actionable counterfactual explanations. In Proceedings of the AAAI/ACM Con  \n808 ference on AI, Ethics, and Society, AIES \u201920, pages 344\u2013350, New York, NY, USA, 2020.   \n809 Association for Computing Machinery. doi: 10.1145/3375627.3375850.   \n810 [105] Wenting Qi and Charalampos Chelmis. Improving Algorithmic Decision\u2013Making in the   \n811 Presence of Untrustworthy Training Data. In 2021 IEEE International Conference on Big   \n812 Data (Big Data), pages 1102\u20131108, 2021. doi: 10.1109/BigData52589.2021.9671677.   \n813 [106] Marcos M. Raimundo, Luis Gustavo Nonato, and Jorge Poco. Mining Pareto-optimal Counter  \n814 factual Antecedents with a Branch-and-Bound Model-Agnostic Algorithm. Data Mining and   \n815 Knowledge Discovery, 2022. doi: 10.1007/s10618-022-00906-4.   \n816 [107] Goutham Ramakrishnan, Yun Chan Lee, and Aws Albarghouthi. Synthesizing Action Se  \n817 quences for Modifying Model Decisions. In Proceedings of the AAAI Conference on Artificial   \n818 Intelligence, volume 34, pages 5462\u20135469, 2020.   \n819 [108] Natraj Raman, Daniele Magazzeni, and Sameena. Shah. Bayesian Hierarchical Models for   \n820 Counterfactual Estimation. In Proceedings of The 26th International Conference on Artificial   \n821 Intelligence and Statistics, volume 206, pages 1115\u20131128. PMLR, 2023.   \n822 [109] Gomathy Ramaswami, Teo Susnjak, and Anuradha Mathrani. Supporting Students\u2019 Academic   \n823 Performance Using Explainable Machine Learning with Automated Prescriptive Analytics.   \n824 Big Data and Cognitive Computing, 6(4), 2022. doi: 10.3390/bdcc6040105.   \n825 [110] Zbigniew W. Ras and Alicja Wieczorkowska. Action-Rules: How to Increase Profit of a   \n826 Company. In Principles of Data Mining and Knowledge Discovery, pages 587\u2013592. Springer   \n827 Berlin Heidelberg, 2000. ISBN 978-3-540-45372-7.   \n828 [111] Peyman Rasouli and Ingrid Chieh Yu. CARE: Coherent Actionable Recourse Based on Sound   \n829 Counterfactual Explanations. International Journal of Data Science and Analytics, 17, 2022.   \n830 doi: 10.1007/s41060-022-00365-6.   \n831 [112] Kaivalya Rawal and Himabindu Lakkaraju. Beyond Individualized Recourse: Interpretable   \n832 and Interactive Summaries of Actionable Recourses. In Proceedings of the 34th International   \n833 Conference on Neural Information Processing Systems, NIPS\u201920, Red Hook, NY, USA, 2020.   \n834 Curran Associates Inc. ISBN 978-1-71382-954-6.   \n835 [113] Kaivalya Rawal, Ece Kamar, and Himabindu Lakkaraju. Algorithmic Recourse in the Wild:   \n836 Understanding the Impact of Data and Model Shifts. arXiv, 2021.   \n837 [114] Annabelle Redelmeier, Martin Jullum, Kjersti Aas, and Anders L\u00f8land. MCCE: Monte Carlo   \n838 sampling of realistic counterfactual explanations. In Data Mining and Knowledge Discovery,   \n839 pages 421\u2013437. Springer Nature, 2024. doi: 10.1007/s10618-024-01017-y.   \n840 [115] Alexis Ross, Himabindu Lakkaraju, and Osbert Bastani. Learning models for actionable   \n841 recourse. In Advances in Neural Information Processing Systems, volume 34, pages 18734\u2013   \n842 18746, 2021.   \n843 [116] Pedram Salimi, Nirmalie Wiratunga, David Corsar, and Anjana Wijekoon. Towards Feasible   \n844 Counterfactual Explanations: A Taxonomy Guided Template-Based NLG Method. In Frontiers   \n845 in Artificial Intelligence and Applications, volume 372, pages 2057\u20132064. IOS Press BV, 2023.   \n846 doi: 10.3233/FAIA230499.   \n847 [117] Maximilian Schleich, Zixuan Geng, Yihong Zhang, and Dan Suciu. GeCo: Quality Counter  \n848 factual Explanations in Real Time. Proc. VLDB Endow., 14(9):1681\u20131693, may 2021. ISSN   \n849 2150-8097. doi: 10.14778/3461535.3461555. URL https://doi.org/10.14778/34615   \n850 35.3461555.   \n851 [118] Jakob Schoeffer, Niklas Kuehl, and Yvette Machowski. \u201cThere Is Not Enough Information\u201d:   \n852 On the Effects of Explanations on Perceptions of Informational Fairness and Trustworthiness   \n853 in Automated Decision-Making. In Proceedings of the 2022 ACM Conference on Fairness,   \n854 Accountability, and Transparency, FAccT \u201922, pages 1616\u20131628, New York, NY, USA, 2022.   \n855 Association for Computing Machinery. ISBN 978-1-4503-9352-2. doi: 10.1145/3531146.35   \n856 33218.   \n857 [119] Andrew D. Selbst, danah boyd, Sorelle A. Friedler, Suresh Venkatasubramanian, and Janet   \n858 Vertesi. Fairness and abstraction in sociotechnical systems. In Proceedings of the Conference on   \n859 Fairness, Accountability, and Transparency, FAT\\* \u201919, page 59\u201368, New York, NY, USA, 2019.   \n860 Association for Computing Machinery. ISBN 9781450361255. doi: 10.1145/3287560.3287598.   \n861 URL https://doi.org/10.1145/3287560.3287598.   \n862 [120] Shubham Sharma, Jette Henderson, and Joydeep Ghosh. CERTIFAI: A Common Framework   \n863 to Provide Explanations and Analyse the Fairness and Robustness of Black-Box Models.   \n864 In Proceedings of the AAAI/ACM Conference on AI, Ethics, and Society, AIES \u201920, pages   \n865 166\u2013172, New York, NY, USA, 2020. Association for Computing Machinery. ISBN 978-1-   \n866 4503-7110-0. doi: 10.1145/3375627.3375812.   \n867 [121] Shubham Sharma, Alan H. Gee, David Paydarfar, and Joydeep Ghosh. FaiR-N: Fair and Robust   \n868 Neural Networks for Structured Data. In Proceedings of the 2021 AAAI/ACM Conference on   \n869 AI, Ethics, and Society, AIES \u201921, pages 946\u2013955, New York, NY, USA, 2021. Association for   \n870 Computing Machinery. ISBN 978-1-4503-8473-5. doi: 10.1145/3461702.3462559.   \n871 [122] Sunny Shree, Jaganmohan Chandrasekaran, Yu Lei, Raghu N. Kacker, and D. Richard Kuhn.   \n872 DeltaExplainer: A Software Debugging Approach to Generating Counterfactual Explanations.   \n873 In 2022 IEEE International Conference On Artificial Intelligence Testing (AITest), pages   \n874 103\u2013110, 2022. doi: 10.1109/AITest55621.2022.00023.   \n875 [123] Manan Singh, Sai Srinivas Kancheti, Shivam Gupta, Ganesh Ghalme, Shweta Jain, and   \n876 Narayanan C. Krishnan. Algorithmic Recourse Based on User\u2019s Feature-Order Preference.   \n877 In Proceedings of the 6th Joint International Conference on Data Science & Management of   \n878 Data (10th ACM IKDD CODS and 28th COMAD), CODS-COMAD \u201923, pages 293\u2013294, New   \n879 York, NY, USA, 2023. Association for Computing Machinery. ISBN 978-1-4503-9797-1. doi:   \n880 10.1145/3570991.3571039.   \n881 [124] Ronal Singh, Tim Miller, Henrietta Lyons, Liz Sonenberg, Eduardo Velloso, Frank Vetere,   \n882 Piers Howe, and Paul Dourish. Directive Explanations for Actionable Explainability in   \n883 Machine Learning Applications. ACM Trans. Interact. Intell. Syst., 13(4), December 2023.   \n884 ISSN 2160-6455. doi: 10.1145/3579363.   \n885 [125] Dylan Slack, Sophie Hilgard, Himabindu Lakkaraju, and Sameer Singh. Counterfactual   \n886 Explanations Can Be Manipulated. In Advances in Neural Information Processing Systems,   \n887 volume 34, pages 62\u201375, 2021.   \n888 [126] Bevan I. Smith, Charles Chimedza, and Jacoba H. B\u00fchrmann. Individualized Help for At-Risk   \n889 Students Using Model-Agnostic and Counterfactual Explanations. Education and Information   \n890 Technologies, 27(2):1539\u20131558, March 2022. ISSN 1360-2357. doi: 10.1007/s10639-021-1   \n891 0661-6.   \n892 [127] Jan-Tobias Sohns, Christoph Garth, and Heike Leitte. Decision Boundary Visualization for   \n893 Counterfactual Reasoning. Computer Graphics Forum, 42(1):7\u201320, 2023. doi: 10.1111/cgf.14   \n894 650.   \n895 [128] Nina Spreitzer, Hinda Haned, and Ilse van der Linden. Evaluating the Practicality of Counter  \n896 factual Explanations. In CEUR Workshop Proceedings, volume 3277, pages 31\u201350. CEUR-WS,   \n897 2022.   \n898 [129] Laura State, Salvatore Ruggieri, and Franco Turini. Reason to Explain: Interactive Contrastive   \n899 Explanations (REASONX). In Explainable Artificial Intelligence, volume 1901 CCIS, pages   \n900 421\u2013437, Cham, 2023. Springer Nature Switzerland. ISBN 978-3-031-44064-9.   \n901 [130] Ilia Stepin, Jose M. Alonso, Alejandro Catala, and Mart\u00edn Pereira-Fari\u00f1a. A Survey of   \n902 Contrastive and Counterfactual Explanation Generation Methods for Explainable Artificial   \n903 Intelligence. IEEE Access, 9:11974\u201312001, 2021.   \n904 [131] Muhammad Suffian and Alessandro Bogliolo. Investigation and Mitigation of Bias in Ex  \n905 plainable AI. In CEUR Workshop Proceedings, volume 3319, pages 89\u201394. CEUR-WS,   \n906 2022.   \n907 [132] Muhammad Suffian, Pierluigi Graziani, Jose M. Alonso, and Alessandro Bogliolo. FCE:   \n908 Feedback Based Counterfactual Explanations for Explainable AI. IEEE Access, 10:72363\u2013   \n909 72372, 2022. ISSN 2169-3536. doi: 10.1109/ACCESS.2022.3189432.   \n910 [133] Emily Sullivan and Philippe Verreault-Julien. From Explanation to Recommendation: Ethical   \n911 Standards for Algorithmic Recourse. In Proceedings of the 2022 AAAI/ACM Conference on   \n912 AI, Ethics, and Society, AIES \u201922, pages 712\u2013722, New York, NY, USA, 2022. Association for   \n913 Computing Machinery. ISBN 978-1-4503-9247-1. doi: 10.1145/3514094.3534185.   \n914 [134] Gabriele Tolomei, Fabrizio Silvestri, Andrew Haines, and Mounia Lalmas. Interpretable   \n915 Predictions of Tree-Based Ensembles via Actionable Feature Tweaking. In Proceedings of   \n916 the 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining,   \n917 pages 465\u2013474, 2017. doi: 10.1145/3097983.3098039.   \n918 [135] Maria Tsiakmaki and Omiros Ragos. A Case Study of Interpretable Counterfactual Explana  \n919 tions for the Task of Predicting Student Academic Performance. In 2021 25th International   \n920 Conference on Circuits, Systems, Communications and Computers (CSCC), pages 120\u2013125,   \n921 July 2021. doi: 10.1109/CSCC53858.2021.00029.   \n922 [136] Stratis Tsirtsis and Manuel Gomez-Rodriguez. Decisions, Counterfactual Explanations and   \n923 Strategic Behavior. In Proceedings of the 34th International Conference on Neural Information   \n924 Processing Systems, NIPS\u201920, Red Hook, NY, USA, 2020. Curran Associates Inc. ISBN   \n925 978-1-71382-954-6.   \n926 [137] Sohini Upadhyay, Shalmali Joshi, and Himabindu Lakkaraju. Towards Robust and Reliable   \n927 Algorithmic Recourse. In Advances in Neural Information Processing Systems, volume 20,   \n928 pages 16926\u201319937, 2021.   \n929 [138] Berk Ustun, Alexander Spangher, and Yang Liu. Actionable Recourse in Linear Classification.   \n930 In Proceedings of the Conference on Fairness, Accountability, and Transparency, FAT\\* \u201919,   \n931 pages 10\u201319, New York, NY, USA, 2019. Association for Computing Machinery. ISBN   \n932 978-1-4503-6125-5. doi: 10.1145/3287560.3287566.   \n933 [139] Rens Van De Schoot, Jonathan De Bruin, Raoul Schram, Parisa Zahedi, Jan De Boer, Fe  \n934 lix Weijdema, Bianca Kramer, Martijn Huijts, Maarten Hoogerwerf, Gerbrich Ferdinands,   \n935 Albert Harkema, Joukje Willemsen, Yongchao Ma, Qixiang Fang, Sybren Hindriks, Lars   \n936 Tummers, and Daniel L. Oberski. An open source machine learning framework for efficient   \n937 and transparent systematic reviews. Nature Machine Intelligence, 3(2):125\u2013133, 2021. doi:   \n938 10.1038/s42256-020-00287-7.   \n939 [140] Mihaela van der Schaar and Andrew Rashbass. The case for Reality-centric AI, Feb 2023.   \n940 URL https://www.vanderschaar-lab.com/the-case-for-reality-centric-ai/.   \n941 Accessed 21.05.2024.   \n942 [141] Peter M. VanNostrand, Huayi Zhang, Dennis M. Hofmann, and Elke A. Rundensteiner. FACET:   \n943 Robust Counterfactual Explanation Analytics. Proc. ACM Manag. Data, 1(4), December 2023.   \n944 doi: 10.1145/3626729.   \n945 [142] Suresh Venkatasubramanian and Mark Alfano. The Philosophical Basis of Algorithmic Re  \n946 course. In Proceedings of the 2020 Conference on Fairness, Accountability, and Transparency,   \n947 FAT\\* \u201920, pages 284\u2013293, New York, NY, USA, 2020. Association for Computing Machinery.   \n948 ISBN 978-1-4503-6936-7. doi: 10.1145/3351095.3372876.   \n949 [143] Sahil Verma, Varich Boonsanong, Minh Hoang, Keegan E. Hines, John P. Dickerson, and   \n950 Chirag Shah. Counterfactual Explanations and Algorithmic Recourses for Machine Learning:   \n951 A Review. arXiv, 2022.   \n952 [144] Sahil Verma, Keegan Hines, and John P. Dickerson. Amortized Generation of Sequential   \n953 Algorithmic Recourses for Black-Box Models. In Proceedings of the 36th AAAI Conference   \n954 on Artificial Intelligence, AAAI 2022, volume 36, pages 8512\u20138519. Association for the   \n955 Advancement of Artificial Intelligence, 2022.   \n956 [145] Sahil Verma, Ashudeep Singh, Varich Boonsanong, John P. Dickerson, and Chirag Shah.   \n957 RecRec: Algorithmic Recourse for Recommender Systems. In Proceedings of the 32nd   \n958 ACM International Conference on Information and Knowledge Management, CIKM $^{\\prime}23$ ,   \n959 pages 4325\u20134329, New York, NY, USA, 2023. Association for Computing Machinery. ISBN   \n960 9798400701245. doi: 10.1145/3583780.3615181.   \n961 [146] Kilian Vieth-Ditlmann. The algorithmic administration: automated decision-making in the   \n962 public sector, May 2024. URL https://algorithmwatch.org/en/algorithmic-admin   \n963 istration-explained/. Accessed 22.05.2024.   \n964 [147] Marco Virgolin and Saverio Fracaros. On the Robustness of Sparse Counterfactual Explana  \n965 tions to Adverse Perturbations. Artificial Intelligence, 316(C), March 2023. ISSN 0004-3702.   \n966 doi: 10.1016/j.artint.2022.103840.   \n967 [148] Vy Vo, Trung Le, Van Nguyen, He Zhao, Edwin V. Bonilla, Gholamreza Haffari, and Dinh   \n968 Phung. Feature-Based Learning for Diverse and Privacy-Preserving Counterfactual Expla  \n969 nations. In Proceedings of the 29th ACM SIGKDD Conference on Knowledge Discovery   \n970 and Data Mining, KDD \u201923, pages 2211\u20132222, New York, NY, USA, 2023. Association for   \n971 Computing Machinery. ISBN 9798400701030. doi: 10.1145/3580305.3599343.   \n972 [149] Julius Von Kugelgen, Amir-Hossein Karimi, Umang Bhatt, Isabel Valera, Adrian Weller, and   \n973 Bernhard Scholkopf. On the Fairness of Causal Algorithmic Recourse. In Proceedings of the   \n974 36th AAAI Conference on Artificial Intelligence, AAAI 2022, volume 36, pages 9584\u20139594.   \n975 Association for the Advancement of Artificial Intelligence, 2022.   \n976 [150] Julius von K\u00fcgelgen, Nikita Agarwal, Jakob Zeitler, Afsaneh Mastouri, and Bernhard   \n977 Sch\u00f6lkopf. Algorithmic Recourse in Partially and Fully Confounded Settings Through Bound  \n978 ing Counterfactual Effects. arXiv, 2021.   \n979 [151] Sandra Wachter, Brent Mittelstadt, and Chris Russell. Counterfactual explanations without   \n980 opening the black box: Automated decisions and the GDPR. Harvard Journal of Law &   \n981 Technology, 31:841, 2017.   \n982 [152] Paul Y. Wang, Sainyam Galhotra, Romila Pradhan, and Babak Salimi. Demonstration of   \n983 Generating Explanations for Black-Box Algorithms Using Lewis. Proc. VLDB Endow., 14   \n984 (12):2787\u20132790, July 2021. ISSN 2150-8097. doi: 10.14778/3476311.3476345.   \n985 [153] Yongjie Wang, Qinxu Ding, Ke Wang, Yue Liu, Xingyu Wu, Jinglong Wang, Yong Liu, and   \n986 Chunyan Miao. The Skyline of Counterfactual Explanations for Machine Learning Decision   \n987 Models. In Proceedings of the 30th ACM International Conference on Information & Knowl  \n988 edge Management, CIKM \u201921, pages 2030\u20132039, New York, NY, USA, 2021. Association for   \n989 Computing Machinery. ISBN 978-1-4503-8446-9. doi: 10.1145/3459637.3482397.   \n990 [154] Yongjie Wang, Hangwei Qian, Yongjie Liu, Wei Guo, and Chunyan Miao. Flexible and Robust   \n991 Counterfactual Explanations with Minimal Satisfiable Perturbations. In Proceedings of the   \n992 32nd ACM International Conference on Information and Knowledge Management, CIKM \u201923,   \n993 pages 2596\u20132605, New York, NY, USA, 2023. Association for Computing Machinery. ISBN   \n994 9798400701245. doi: 10.1145/3583780.3614885.   \n995 [155] Zhendong Wang, Isak Samsten, Vasiliki Kougia, and Panagiotis Papapetrou. Style-Transfer   \n996 Counterfactual Explanations: An Application to Mortality Prevention of ICU Patients. Artif.   \n997 Intell. Med., 135(C), January 2023. ISSN 0933-3657. doi: 10.1016/j.artmed.2022.102457.   \n998 [156] Zijie J. Wang, Jennifer Wortman Vaughan, Rich Caruana, and Duen Horng Chau. GAM   \n999 Coach: Towards Interactive and User-Centered Algorithmic Recourse. In Proceedings of   \n1000 the 2023 CHI Conference on Human Factors in Computing Systems, CHI \u201923, New York,   \n1001 NY, USA, 2023. Association for Computing Machinery. ISBN 978-1-4503-9421-5. doi:   \n1002 10.1145/3544548.3580816.   \n1003 [157] Greta Warren, Mark T. Keane, and Ruth M. J. Byrne. Features of Explainability: How Users   \n1004 Understand Counterfactual and Causal Explanations for Categorical and Continuous Features   \n1005 in XAI. In CEUR Workshop Proceedings, volume 3251. CEUR-WS, 2022.   \n1006 [158] Greta Warren, Barry Smyth, and Mark T. Keane. \u201cBetter\u201d Counterfactuals, Ones People   \n1007 Can Understand: Psychologically-Plausible Case-Based Counterfactuals Using Categorical   \n1008 Features for Explainable AI (XAI). In Case-Based Reasoning Research and Development: 30th   \n1009 International Conference, ICCBR 2022, Nancy, France, September 12\u201315, 2022, Proceedings,   \n1010 pages 63\u201378, Berlin, Heidelberg, 2022. Springer-Verlag. ISBN 978-3-031-14922-1. doi:   \n1011 10.1007/978-3-031-14923-8_5.   \n1012 [159] Daniel S. Weld and Gagan Bansal. The Challenge of Crafting Intelligible Intelligence. Commun.   \n1013 ACM, 62(6):70\u201379, may 2019. ISSN 0001-0782. doi: 10.1145/3282486. URL https:   \n1014 //doi.org/10.1145/3282486.   \n1015 [160] Anjana Wijekoon, Nirmalie Wiratunga, Ikechukwu Nkisi-Orji, Kyle Martin, Chamath Pali  \n1016 hawadana, and David Corsar. Counterfactual Explanations for Student Outcome Prediction   \n1017 with Moodle Footprints. In CEUR Workshop Proceedings, volume 2894, pages 1\u20138. CEUR  \n1018 WS, 2021.   \n1019 [161] Nirmalie Wiratunga, Anjana Wijekoon, Ikechukwu Nkisi-Orji, Kyle Martin, Chamath Pal  \n1020 ihawadana, and David Corsar. DisCERN: Discovering Counterfactual Explanations using   \n1021 Relevance Features from Neighbourhoods. In 2021 IEEE 33rd International Conference on   \n1022 Tools with Artificial Intelligence (ICTAI), pages 1466\u20131473, November 2021. ISBN 2375-0197.   \n1023 doi: 10.1109/ICTAI52525.2021.00233.   \n1024 [162] Claes Wohlin. Guidelines for Snowballing in Systematic Literature Studies and a Replication   \n1025 in Software Engineering. EASE \u201914: Proceedings of the 18th International Conference on   \n1026 Evaluation and Assessment in Software Engineering, 2014. doi: 10.1145/2601248.2601268.   \n1027 URL https://doi.org/10.1145/2601248.2601268.   \n1028 [163] Jingquan Yan and Hao Wang. Self-Interpretable Time Series Prediction with Counterfactual   \n1029 Explanations. In Proceedings of the 40th International Conference on Machine Learning,   \n1030 ICML\u201923. JMLR.org, 2023.   \n1031 [164] Jayanth Yetukuri, Ian Hardy, and Yang Liu. Towards User Guided Actionable Recourse.   \n1032 In Proceedings of the 2023 AAAI/ACM Conference on AI, Ethics, and Society, AIES \u201923,   \n1033 pages 742\u2013751, New York, NY, USA, 2023. Association for Computing Machinery. ISBN   \n1034 9798400702310. doi: 10.1145/3600211.3604708.   \n1035 [165] Songming Zhang, Xiaofeng Chen, Shiping Wen, and Zhongshan Li. Density-Based Reliable   \n1036 and Robust Explainer for Counterfactual Explanation. Expert Syst. Appl., 226(C), September   \n1037 2023. ISSN 0957-4174. doi: 10.1016/j.eswa.2023.120214. ", "page_idx": 9}, {"type": "text", "text": "", "page_idx": 10}, {"type": "text", "text": "", "page_idx": 11}, {"type": "text", "text": "", "page_idx": 12}, {"type": "text", "text": "", "page_idx": 13}, {"type": "text", "text": "", "page_idx": 14}, {"type": "text", "text": "", "page_idx": 15}, {"type": "text", "text": "", "page_idx": 16}, {"type": "text", "text": "", "page_idx": 17}, {"type": "text", "text": "", "page_idx": 18}, {"type": "text", "text": "", "page_idx": 19}, {"type": "text", "text": "", "page_idx": 20}, {"type": "text", "text": "", "page_idx": 21}, {"type": "text", "text": "1038 A Extended discussion of the search process ", "text_level": 1, "page_idx": 22}, {"type": "text", "text": "1039 While our discussion of the search process in Section 3.1 in the main body of the document is   \n1040 complete, we also provide an extended version of this discussion to allow for full reproducibility.   \n1041 We make use of 3 search engines to collect the initial set of studies: ACM Digital Library, IEEE   \n1042 Xplore, and SCOPUS. Given the blurry distinction between AR and CEs, we consider the papers   \n1043 discussing either problem. In a small scoping review, we identify several keywords common to   \n1044 publications on recourse, as well as several equivalent terms to build the query shown below. ", "page_idx": 22}, {"type": "text", "text": "", "page_idx": 22}, {"type": "text", "text": "(\u201cMachine Learning\u201d OR \u201cArtificial Intelligence\u201d   \nOR \u201cAlgorithmic Decision\\*\u201d OR \u201cConsequential Decision\\*\u201d   \nOR Classif\\* OR Predict\\* OR \u201cExplainable AI\u201d OR AI OR XAI)   \nAND (((Counterfactual OR Contrastive OR Actionable) AND Explanation\\*)   \nOR ((Algorithmic OR Individual $^*$ OR Actionable) AND Recourse)   \nOR Counterfactual?) ", "page_idx": 22}, {"type": "text", "text": "1045 We modify this query to account for the semantic differences between the search engines. ", "page_idx": 22}, {"type": "text", "text": "1046 For ACM Digital Library: ", "page_idx": 22}, {"type": "text", "text": "Title:(( \"Machine Learning\" OR \"Artificial Intelligence\"   \nOR \"Algorithmic Decision\\*\" OR \"Consequential Decision\\*\"   \nOR classif\\* OR predict\\* OR \"Explainable AI\" OR ai OR xai )   \nAND ( ( ( counterfactual OR contrastive OR actionable )   \nAND explanation\\* ) OR ( ( algorithmic OR individual $^*$ OR actionable )   \nAND recourse ) OR counterfactual? ))   \nOR Abstract:(( \"Machine Learning\" OR \"Artificial Intelligence\"   \nOR \"Algorithmic Decision\\*\" OR \"Consequential Decision\\*\"   \nOR classif\\* OR predict\\* OR \"Explainable AI\" OR ai OR xai )   \nAND ( ( ( counterfactual OR contrastive OR actionable )   \nAND explanation\\* ) OR ( ( algorithmic OR individual\\* OR actionable )   \nAND recourse ) OR counterfactual? ))   \nOR Keyword:(( \"Machine Learning\" OR \"Artificial Intelligence\"   \nOR \"Algorithmic Decision\\*\" OR \"Consequential Decision\\*\"   \nOR classif\\* OR predict\\* OR \"Explainable AI\" OR ai OR xai )   \nAND ( ( ( counterfactual OR contrastive OR actionable )   \nAND explanation\\* ) OR ( ( algorithmic OR individual\\* OR actionable )   \nAND recourse ) OR counterfactual? )) ", "page_idx": 22}, {"type": "text", "text": "1047 For IEEE Xplore: ", "page_idx": 22}, {"type": "text", "text": "(((\"All Metadata\":\"Machine Learning\"   \nOR \"All Metadata\":\"Artificial Intelligence\"   \nOR \"All Metadata\":\"Algorithmic Decision\\*\"   \nOR \"All Metadata\":\"Consequential Decision\\*\"   \nOR \"All Metadata\":classif\\* OR \"All Metadata\":predict\\*   \nOR \"All Metadata\":\"Explainable AI\" OR \"All Metadata\":ai   \nOR \"All Metadata\":xai )   \nAND (((\"All Metadata\":counterfactual OR \"All Metadata\":contrastive   \nOR \"All Metadata\":actionable ) AND \"All Metadata\":explanation\\* )   \nOR ( (\"All Metadata\":algorithmic OR \"All Metadata\":individual\\*   \nOR \"All Metadata\":actionable )   \nAND \"All Metadata\":recourse )   \nOR \"All Metadata\":counterfactual? ))) ", "page_idx": 22}, {"type": "text", "text": "1048 For SCOPUS: ", "page_idx": 23}, {"type": "text", "text": "TITLE-ABS-KEY ( ( \"Machine Learning\" OR \"Artificial Intelligence\" OR \"Algorithmic Decision\\*\" OR \"Consequential Decision\\*\" OR classif\\* OR predict\\* OR \"Explainable AI\" OR ai OR xai ) AND ( ( ( counterfactual OR contrastive OR actionable ) AND explanation\\* ) OR ( ( algorithmic OR individual $^*$ OR actionable ) AND recourse ) OR counterfactual? ) ) ", "page_idx": 23}, {"type": "text", "text": "1049 The search is carried out on January $12^{\\mathrm{th}}\\ 2024$ in titles, abstracts, and keywords, with 1267 results   \n1050 from ACM Digital Library (The ACM Guide to Computing Literature), 513 results from IEEE Xplore,   \n1051 and 2139 results from SCOPUS. This leads to a total of 3919 results, which are imported to the   \n1052 Zotero reference management software for de-duplication. After removing the duplicates, we are left   \n1053 with 3136 results, 44 of which are the meta-data of conference proceedings that we also remove.   \n1054 To facilitate the screening process, we employ the open-source ASReview tool, which makes use of   \n1055 an active learning approach to re-order the set of publications, such that the most relevant ones are   \n1056 always \u201cat the top of the stack\u201d [139]. We run ASReview on the default settings, i.e.: ", "page_idx": 23}, {"type": "text", "text": "", "page_idx": 23}, {"type": "text", "text": "Feature extraction technique: TF-IDF   \nClassifier: Naive Bayes   \nQuery strategy: Maximum   \nBalance strategy: Dynamic resampling (Double) ", "page_idx": 23}, {"type": "text", "text": "1057 The researchers behind the tool suggest employing a stopping rule measured in the number of   \n1058 consecutive irrelevant records, which we set to 30, or $1\\%$ of the entire dataset. We accept all papers   \n1059 that focus on algorithmic recourse and counterfactual explanations, completing the screening after   \n1060 evaluating 1040 abstracts $33.67\\%$ of the dataset), leading to 504 $\\left(16.30\\%\\right)$ records among which we   \n1061 identify further 4 duplicates to remove. This results in the reported number of 499 relevant records.   \n1062 We observe that some important publications may be missing from our results. For instance, [151]   \n1063 was published in the Harvard Journal of Law & Technology that is not indexed by computer science   \n1064 search engines. Thus, we decide to augment the set of records by applying snowballing, which has   \n1065 been shown as a good alternative to databases in systematic reviews in software engineering [162].   \n1066 We decide to make use of citation counts as a proxy for impact. Due to the lack of a suitable tool that   \n1067 would provide unbiased citation counts for all papers in our dataset, we collect them from Google   \n1068 Scholar. Unfortunately, citation counts on Google Scholar tend to be inflated, but as we make use of   \n1069 snowballing purely to enrich the dataset, these does not impact the validity of our study. We manually   \n1070 collect Google Scholar citation counts for all 499 results from the first screening on January $27^{\\mathrm{th}}$   \n1071 and $28^{\\mathrm{th}}$ , order them descendingly, and collect references for the top 50 $(10\\%)$ \u201cmost impactful\u201d   \n1072 publications. Snowballing results in a total of 1519 new records. Indeed, we observe that [151]   \n1073 (mentioned above) is referenced by 39 of the 50 publications used for snowballing.   \n1074 While this strategy introduces several pre-prints into our result set [52, 61, 91, 113, 143, 150], we   \n1075 decide not to exclude them. Our review remains primarily concerned with peer-reviewed work. Here,   \n1076 we also note that [114], which we collected as a pre-print has been published between the search and   \n1077 appraisal. As such we decided to evaluate its published version and refer to it in this paper.   \n1078 After adding the snowballed references into our dataset, we are left with 2018 records for the second   \n1079 screening with ASReview, again on the default settings. This time, we look for publications that   \n1080 specifically refer to the problem of AR, \u201cactionable\u201d CEs, or modifying outcomes of automated   \n1081 decision-making systems. We employ a stricter stopping rule to minimize the risk of false neg  \n1082 atives, completing the screening after 60 consecutive irrelevant records. We evaluate 538 results   \n1083 $26.71\\%$ of the dataset), with 203 $(10.06\\%)$ relevant results that are considered for full-text appraisal.   \n1084 This concludes the extended discussion of the search process. ", "page_idx": 23}, {"type": "text", "text": "", "page_idx": 23}, {"type": "text", "text": "", "page_idx": 23}, {"type": "text", "text": "", "page_idx": 23}, {"type": "text", "text": "", "page_idx": 23}, {"type": "text", "text": "1085 B Evaluation of contributions ", "text_level": 1, "page_idx": 24}, {"type": "table", "img_path": "oEmyoy5H5P/tmp/7828b61e11590cc5fac33f51d3c2a3f73179eea47841c5e908f7483506aa25ae.jpg", "table_caption": ["Table 1: Evaluation of the collected publications on the types of contributions, 2017-2021. "], "table_footnote": [], "page_idx": 24}, {"type": "table", "img_path": "oEmyoy5H5P/tmp/5416cac438e8cd6cb4500dad47ca1e3ff8673d5687290b5c893086af26f4e9a3.jpg", "table_caption": ["Table 2: Evaluation of the collected publications on the types of contributions, 2022. "], "table_footnote": [], "page_idx": 25}, {"type": "table", "img_path": "oEmyoy5H5P/tmp/be874104d14e2d8c2a89eccab258025989826a9bcad18eaa0eff823dafe8e353.jpg", "table_caption": ["Table 3: Evaluation of the collected publications on the types of contributions, 2023-2024. "], "table_footnote": [], "page_idx": 26}, {"type": "text", "text": "1086 NeurIPS Paper Checklist ", "text_level": 1, "page_idx": 27}, {"type": "text", "text": "087 1. Claims   \n088 Question: Do the main claims made in the abstract and introduction accurately reflect the   \n089 paper\u2019s contributions and scope?   \n090 Answer: [Yes]   \n1091 Justification: Our main claim is that existing research on recourse is disconnected from the   \n092 practical requirements of systems where it would be applied (see Section 4 and Section 5.1).   \n093 Our claim is supported by a systematized literature review which is the contribution of this   \n094 work (Section 3). These are reflected in the abstract and the introduction.   \n095 Guidelines:   \n096 \u2022 The answer NA means that the abstract and introduction do not include the claims   \n097 made in the paper.   \n098 \u2022 The abstract and/or introduction should clearly state the claims made, including the   \n099 contributions made in the paper and important assumptions and limitations. A No or   \n100 NA answer to this question will not be perceived well by the reviewers.   \n101 \u2022 The claims made should match theoretical and experimental results, and reflect how   \n102 much the results can be expected to generalize to other settings.   \n103 \u2022 It is fine to include aspirational goals as motivation as long as it is clear that these goals   \n104 are not attained by the paper.   \n105 2. Limitations ", "page_idx": 27}, {"type": "text", "text": "Question: Does the paper discuss the limitations of the work performed by the authors? Answer: [Yes] ", "page_idx": 27}, {"type": "text", "text": "Justification: We highlight and discuss the three main limitations of our work in Section 5.2. Guidelines: ", "page_idx": 27}, {"type": "text", "text": "\u2022 The answer NA means that the paper has no limitation while the answer No means that the paper has limitations, but those are not discussed in the paper.   \n\u2022 The authors are encouraged to create a separate \"Limitations\" section in their paper.   \n\u2022 The paper should point out any strong assumptions and how robust the results are to violations of these assumptions (e.g., independence assumptions, noiseless settings, model well-specification, asymptotic approximations only holding locally). The authors should reflect on how these assumptions might be violated in practice and what the implications would be.   \n\u2022 The authors should reflect on the scope of the claims made, e.g., if the approach was only tested on a few datasets or with a few runs. In general, empirical results often depend on implicit assumptions, which should be articulated.   \n\u2022 The authors should reflect on the factors that influence the performance of the approach. For example, a facial recognition algorithm may perform poorly when image resolution is low or images are taken in low lighting. Or a speech-to-text system might not be used reliably to provide closed captions for online lectures because it fails to handle technical jargon.   \n\u2022 The authors should discuss the computational efficiency of the proposed algorithms and how they scale with dataset size.   \n\u2022 If applicable, the authors should discuss possible limitations of their approach to address problems of privacy and fairness.   \n\u2022 While the authors might fear that complete honesty about limitations might be used by reviewers as grounds for rejection, a worse outcome might be that reviewers discover limitations that aren\u2019t acknowledged in the paper. The authors should use their best judgment and recognize that individual actions in favor of transparency play an important role in developing norms that preserve the integrity of the community. Reviewers will be specifically instructed to not penalize honesty concerning limitations. ", "page_idx": 27}, {"type": "text", "text": "3. Theory Assumptions and Proofs ", "text_level": 1, "page_idx": 27}, {"type": "text", "text": "37 Question: For each theoretical result, does the paper provide the full set of assumptions and   \n38 a complete (and correct) proof? ", "page_idx": 27}, {"type": "text", "text": "Answer: [NA]   \nJustification: Our work, as a literature review, does not rely on theoretical results or proofs. Nonetheless, we are explicit about the \u201cassumptions\u201d in that we discuss our approach to the collection and analysis of results in depth in Section 3.   \n\u2022 The answer NA means that the paper does not include theoretical results.   \n\u2022 All the theorems, formulas, and proofs in the paper should be numbered and crossreferenced.   \n\u2022 All assumptions should be clearly stated or referenced in the statement of any theorems.   \n\u2022 The proofs can either appear in the main paper or the supplemental material, but if they appear in the supplemental material, the authors are encouraged to provide a short proof sketch to provide intuition.   \n\u2022 Inversely, any informal proof provided in the core of the paper should be complemented by formal proofs provided in appendix or supplemental material.   \n\u2022 Theorems and Lemmas that the proof relies upon should be properly referenced. ", "page_idx": 28}, {"type": "text", "text": "", "page_idx": 28}, {"type": "text", "text": "4. Experimental Result Reproducibilit ", "text_level": 1, "page_idx": 28}, {"type": "text", "text": "Question: Does the paper fully disclose all the information needed to reproduce the main experimental results of the paper to the extent that it affects the main claims and/or conclusions of the paper (regardless of whether the code and data are provided or not)? ", "page_idx": 28}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 28}, {"type": "text", "text": "Justification: Our work does not rely on any experiments, so this question is not applicable. Nonetheless, we believe that we provide sufficiently in-depth characterization of the review process where other authors should be able to reproduce it (Section 3 and Appendix A). ", "page_idx": 28}, {"type": "text", "text": "1139   \n1140   \n1141   \n1142   \n1143   \n1144   \n1145   \n1146   \n1147   \n1148   \n1149   \n1150   \n1151   \n1152   \n1153   \n1154   \n1155   \n1156   \n1157   \n1158   \n1159   \n1160   \n1161   \n1162   \n1163   \n1164   \n1165   \n1166   \n1167   \n1168   \n1169   \n1170   \n1171   \n1172   \n1173   \n1174   \n1175   \n1176   \n1177   \n1178   \n1179   \n1180   \n1181   \n1182   \n1183   \n1184   \n1185   \n1186   \n1187   \n1188   \n1189   \n1190   \n1191   \n1192   \n1193 ", "page_idx": 28}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 If the paper includes experiments, a No answer to this question will not be perceived well by the reviewers: Making the paper reproducible is important, regardless of whether the code and data are provided or not.   \n\u2022 If the contribution is a dataset and/or model, the authors should describe the steps taken to make their results reproducible or verifiable.   \n\u2022 Depending on the contribution, reproducibility can be accomplished in various ways. For example, if the contribution is a novel architecture, describing the architecture fully might suffice, or if the contribution is a specific model and empirical evaluation, it may be necessary to either make it possible for others to replicate the model with the same dataset, or provide access to the model. In general. releasing code and data is often one good way to accomplish this, but reproducibility can also be provided via detailed instructions for how to replicate the results, access to a hosted model (e.g., in the case of a large language model), releasing of a model checkpoint, or other means that are appropriate to the research performed.   \n\u2022 While NeurIPS does not require releasing code, the conference does require all submissions to provide some reasonable avenue for reproducibility, which may depend on the nature of the contribution. For example (a) If the contribution is primarily a new algorithm, the paper should make it clear how to reproduce that algorithm. (b) If the contribution is primarily a new model architecture, the paper should describe the architecture clearly and fully. (c) If the contribution is a new model (e.g., a large language model), then there should either be a way to access this model for reproducing the results or a way to reproduce the model (e.g., with an open-source dataset or instructions for how to construct the dataset). (d) We recognize that reproducibility may be tricky in some cases, in which case authors are welcome to describe the particular way they provide for reproducibility. In the case of closed-source models, it may be that access to the model is limited in some way (e.g., to registered users), but it should be possible for other researchers to have some path to reproducing or verifying the results. ", "page_idx": 28}, {"type": "text", "text": "5. Open access to data and code ", "text_level": 1, "page_idx": 29}, {"type": "text", "text": "95 Question: Does the paper provide open access to the data and code, with sufficient instruc  \n96 tions to faithfully reproduce the main experimental results, as described in supplemental   \n97 material?   \n98 Answer: [NA]   \n99 Justification: Our work does not rely on any experiments, so this question is not applicable.   \n00 Nonetheless, we provide the complete list of publications covered in this review. We will   \n01 also release the review data upon acceptance.   \n02 Guidelines:   \n03 \u2022 The answer NA means that paper does not include experiments requiring code.   \n04 \u2022 Please see the NeurIPS code and data submission guidelines (https://nips.cc/pu   \n05 blic/guides/CodeSubmissionPolicy) for more details.   \n06 \u2022 While we encourage the release of code and data, we understand that this might not be   \n07 possible, so \u201cNo\u201d is an acceptable answer. Papers cannot be rejected simply for not   \n08 including code, unless this is central to the contribution (e.g., for a new open-source   \n09 benchmark).   \n10 \u2022 The instructions should contain the exact command and environment needed to run to   \n11 reproduce the results. See the NeurIPS code and data submission guidelines (https:   \n12 //nips.cc/public/guides/CodeSubmissionPolicy) for more details.   \n13 \u2022 The authors should provide instructions on data access and preparation, including how   \n14 to access the raw data, preprocessed data, intermediate data, and generated data, etc.   \n15 \u2022 The authors should provide scripts to reproduce all experimental results for the new   \n16 proposed method and baselines. If only a subset of experiments are reproducible, they   \n17 should state which ones are omitted from the script and why.   \n18 \u2022 At submission time, to preserve anonymity, the authors should release anonymized   \n19 versions (if applicable).   \n20 \u2022 Providing as much information as possible in supplemental material (appended to the   \n21 paper) is recommended, but including URLs to data and code is permitted. ", "page_idx": 29}, {"type": "text", "text": "6. Experimental Setting/Details ", "text_level": 1, "page_idx": 29}, {"type": "text", "text": "Question: Does the paper specify all the training and test details (e.g., data splits, hyperparameters, how they were chosen, type of optimizer, etc.) necessary to understand the results? ", "page_idx": 29}, {"type": "text", "text": "Answer: [NA]   \nJustification: Our work does not rely on any experiments, so this question is not applicable. Guidelines: ", "page_idx": 29}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments. \u2022 The experimental setting should be presented in the core of the paper to a level of detail that is necessary to appreciate the results and make sense of them. \u2022 The full details can be provided either with the code, in appendix, or as supplemental material. ", "page_idx": 29}, {"type": "text", "text": "7. Experiment Statistical Significance ", "text_level": 1, "page_idx": 29}, {"type": "text", "text": "Question: Does the paper report error bars suitably and correctly defined or other appropriate information about the statistical significance of the experiments? ", "page_idx": 29}, {"type": "text", "text": "\u2022 The factors of variability that the error bars are capturing should be clearly stated (for example, train/test split, initialization, random drawing of some parameter, or overall run with given experimental conditions).   \n\u2022 The method for calculating the error bars should be explained (closed form formula, call to a library function, bootstrap, etc.)   \n\u2022 The assumptions made should be given (e.g., Normally distributed errors).   \n\u2022 It should be clear whether the error bar is the standard deviation or the standard error of the mean.   \n\u2022 It is OK to report 1-sigma error bars, but one should state it. The authors should preferably report a 2-sigma error bar than state that they have a $96\\%$ CI, if the hypothesis of Normality of errors is not verified.   \n\u2022 For asymmetric distributions, the authors should be careful not to show in tables or figures symmetric error bars that would yield results that are out of range (e.g. negative error rates).   \n\u2022 If error bars are reported in tables or plots, The authors should explain in the text how they were calculated and reference the corresponding figures or tables in the text. ", "page_idx": 30}, {"type": "text", "text": "0 8. Experiments Compute Resources ", "text_level": 1, "page_idx": 30}, {"type": "text", "text": "Question: For each experiment, does the paper provide sufficient information on the computer resources (type of compute workers, memory, time of execution) needed to reproduce the experiments? ", "page_idx": 30}, {"type": "text", "text": "Justification: Our work does not rely on any experiments, so this question is not applicable. Guidelines: ", "page_idx": 30}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 The paper should indicate the type of compute workers CPU or GPU, internal cluster, or cloud provider, including relevant memory and storage.   \n\u2022 The paper should provide the amount of compute required for each of the individual experimental runs as well as estimate the total compute.   \n\u2022 The paper should disclose whether the full research project required more compute than the experiments reported in the paper (e.g., preliminary or failed experiments that didn\u2019t make it into the paper). ", "page_idx": 30}, {"type": "text", "text": "9. Code Of Ethics ", "text_level": 1, "page_idx": 30}, {"type": "text", "text": "Question: Does the research conducted in the paper conform, in every respect, with the NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines? ", "page_idx": 30}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 30}, {"type": "text", "text": "Justification: We have reviewed the NeurIPS Code of Ethics and we confirm that our work conforms to it in every respect. ", "page_idx": 30}, {"type": "text", "text": "\u2022 The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics.   \n\u2022 If the authors answer No, they should explain the special circumstances that require a deviation from the Code of Ethics.   \n\u2022 The authors should make sure to preserve anonymity (e.g., if there is a special consideration due to laws or regulations in their jurisdiction). ", "page_idx": 30}, {"type": "text", "text": "1287 10. Broader Impacts ", "text_level": 1, "page_idx": 30}, {"type": "text", "text": "Question: Does the paper discuss both potential positive societal impacts and negative societal impacts of the work performed? ", "page_idx": 30}, {"type": "text", "text": "Justification: Although this is not covered in a separate section, positive and negative societal impacts of our work (and algorithmic recourse in general) are a key consideration throughout this paper. See for instance Section 1 or Section 6.   \nGuidelines: ", "page_idx": 30}, {"type": "text", "text": "1295 \u2022 The answer NA means that there is no societal impact of the work performed.   \n1296 \u2022 If the authors answer NA or No, they should explain why their work has no societal   \n1297 impact or why the paper does not address societal impact.   \n1298 \u2022 Examples of negative societal impacts include potential malicious or unintended uses   \n1299 (e.g., disinformation, generating fake profiles, surveillance), fairness considerations   \n1300 (e.g., deployment of technologies that could make decisions that unfairly impact specific   \n1301 groups), privacy considerations, and security considerations.   \n1302 \u2022 The conference expects that many papers will be foundational research and not tied   \n1303 to particular applications, let alone deployments. However, if there is a direct path to   \n1304 any negative applications, the authors should point it out. For example, it is legitimate   \n1305 to point out that an improvement in the quality of generative models could be used to   \n1306 generate deepfakes for disinformation. On the other hand, it is not needed to point out   \n1307 that a generic algorithm for optimizing neural networks could enable people to train   \n1308 models that generate Deepfakes faster.   \n1309 \u2022 The authors should consider possible harms that could arise when the technology is   \n1310 being used as intended and functioning correctly, harms that could arise when the   \n1311 technology is being used as intended but gives incorrect results, and harms following   \n1312 from (intentional or unintentional) misuse of the technology.   \n1313 \u2022 If there are negative societal impacts, the authors could also discuss possible mitigation   \n1314 strategies (e.g., gated release of models, providing defenses in addition to attacks,   \n1315 mechanisms for monitoring misuse, mechanisms to monitor how a system learns from   \n1316 feedback over time, improving the efficiency and accessibility of ML).   \n1317 11. Safeguards   \n1318 Question: Does the paper describe safeguards that have been put in place for responsible   \n1319 release of data or models that have a high risk for misuse (e.g., pretrained language models,   \n1320 image generators, or scraped datasets)?   \n1321 Answer: [NA]   \n1322 Justification: Our work poses no such risks, so this question is not applicable. We do not   \n1323 introduce any data or models.   \n1324 Guidelines:   \n1325 \u2022 The answer NA means that the paper poses no such risks.   \n1326 \u2022 Released models that have a high risk for misuse or dual-use should be released with   \n1327 necessary safeguards to allow for controlled use of the model, for example by requiring   \n1328 that users adhere to usage guidelines or restrictions to access the model or implementing   \n1329 safety filters.   \n1330 \u2022 Datasets that have been scraped from the Internet could pose safety risks. The authors   \n1331 should describe how they avoided releasing unsafe images.   \n1332 \u2022 We recognize that providing effective safeguards is challenging, and many papers do   \n1333 not require this, but we encourage authors to take this into account and make a best   \n1334 faith effort.   \n1335 12. Licenses for existing assets   \n1336 Question: Are the creators or original owners of assets (e.g., code, data, models), used in   \n1337 the paper, properly credited and are the license and terms of use explicitly mentioned and   \n1338 properly respected?   \n1339 Answer: [NA]   \n1340 Justification: Our work does not use existing assets (other than the referenced papers), so   \n1341 this question is not applicable. All papers covered in the review are referenced in sufficient   \n1342 detail, so that the readers can access them.   \n1343 Guidelines:   \n1344 \u2022 The answer NA means that the paper does not use existing assets.   \n1345 \u2022 The authors should cite the original paper that produced the code package or dataset.   \n1346 \u2022 The authors should state which version of the asset is used and, if possible, include a   \n1347 URL.   \n1348 \u2022 The name of the license (e.g., CC-BY 4.0) should be included for each asset.   \n1349 \u2022 For scraped data from a particular source (e.g., website), the copyright and terms of   \n1350 service of that source should be provided.   \n1351 \u2022 If assets are released, the license, copyright information, and terms of use in the package   \n1352 should be provided. For popular datasets, paperswithcode.com/datasets has   \n1353 curated licenses for some datasets. Their licensing guide can help determine the license   \n1354 of a dataset.   \n1355 \u2022 For existing datasets that are re-packaged, both the original license and the license of   \n1356 the derived asset (if it has changed) should be provided.   \n1357 \u2022 If this information is not available online, the authors are encouraged to reach out to   \n1358 the asset\u2019s creators.   \n1359 13. New Assets   \n1360 Question: Are new assets introduced in the paper well documented and is the documentation   \n1361 provided alongside the assets?   \n1362 Answer: [NA]   \n1363 Justification: Our work does not release any new assets, so this question is not applicable.   \n1364 We release the paper with the most permissible license available for NeurIPS submissions.   \n1365 Finally, we will release the review data upon acceptance.   \n1366 Guidelines:   \n1367 \u2022 The answer NA means that the paper does not release new assets.   \n1368 \u2022 Researchers should communicate the details of the dataset/code/model as part of their   \n1369 submissions via structured templates. This includes details about training, license,   \n1370 limitations, etc.   \n1371 \u2022 The paper should discuss whether and how consent was obtained from people whose   \n1372 asset is used.   \n1373 \u2022 At submission time, remember to anonymize your assets (if applicable). You can either   \n1374 create an anonymized URL or include an anonymized zip file.   \n1375 14. Crowdsourcing and Research with Human Subjects   \n1376 Question: For crowdsourcing experiments and research with human subjects, does the paper   \n1377 include the full text of instructions given to participants and screenshots, if applicable, as   \n1378 well as details about compensation (if any)?   \n1379 Answer: [NA]   \n1380 Justification: Our paper does not involve crowdsourcing or research with human subjects, so   \n1381 this question is not applicable. The work was in its entirety carried out by the authors.   \n1382 Guidelines:   \n1383 \u2022 The answer NA means that the paper does not involve crowdsourcing nor research with   \n1384 human subjects.   \n1385 \u2022 Including this information in the supplemental material is fine, but if the main contribu  \n1386 tion of the paper involves human subjects, then as much detail as possible should be   \n1387 included in the main paper.   \n1388 \u2022 According to the NeurIPS Code of Ethics, workers involved in data collection, curation,   \n1389 or other labor should be paid at least the minimum wage in the country of the data   \n1390 collector.   \n1391 15. Institutional Review Board (IRB) Approvals or Equivalent for Research with Human   \n1392 Subjects   \n1393 Question: Does the paper describe potential risks incurred by study participants, whether   \n1394 such risks were disclosed to the subjects, and whether Institutional Review Board (IRB)   \n1395 approvals (or an equivalent approval/review based on the requirements of your country or   \n1396 institution) were obtained?   \n1397 Answer: [NA]   \n1398 Justification: Our work does not involve crowdsourcing or research with human subjects, so   \n1399 this question is not applicable. We did not require an IRB approval or equivalent to carry   \n1400 out this work.   \n02 \u2022 The answer NA means that the paper does not involve crowdsourcing nor research with   \n03 human subjects.   \n04 \u2022 Depending on the country in which research is conducted, IRB approval (or equivalent)   \n05 may be required for any human subjects research. If you obtained IRB approval, you   \n06 should clearly state this in the paper.   \n07 \u2022 We recognize that the procedures for this may vary significantly between institutions   \n08 and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the   \n09 guidelines for their institution.   \n10 \u2022 For initial submissions, do not include any information that would break anonymity (if   \n11 applicable), such as the institution conducting the review. ", "page_idx": 31}, {"type": "text", "text": "", "page_idx": 32}, {"type": "text", "text": "", "page_idx": 33}]