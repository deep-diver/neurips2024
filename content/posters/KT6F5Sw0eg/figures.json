[{"figure_path": "KT6F5Sw0eg/figures/figures_1_1.jpg", "caption": "Figure 1: (a) Illustration of two tokens that are decoded by autoregressive decoding vs. two tokens drafted by BPD. (b) Outputs from our proposed rescoring algorithms, where the top-k token-level predictions are refined using local neural or global n-gram rescoring, which selects the p most probable sequences by dynamic programming, for batched verification.", "description": "This figure compares autoregressive decoding with blockwise parallel decoding (BPD).  Panel (a) shows how autoregressive decoding generates one token at a time, while BPD generates multiple tokens (a block draft) in parallel.  Panel (b) illustrates how the proposed rescoring algorithms refine these block drafts by using local neural or global n-gram language models to select the most probable sequences from a top-k lattice, leading to improved decoding speed.", "section": "2 Our contributions"}, {"figure_path": "KT6F5Sw0eg/figures/figures_4_1.jpg", "caption": "Figure 2: (a) Entropy distributions across block draft heads on LAMBADA [33]. The density plots illustrate the entropy distribution for each head in the model. (b) Correlation between block efficiency and hmax, the head until which the average entropy in a task increases nearly monotonically.", "description": "This figure shows two plots. Plot (a) shows the distribution of entropy for each prediction head in a blockwise parallel language model on the LAMBADA dataset. The x-axis represents entropy, and the y-axis represents density.  Each line represents a different head, showing how the entropy (uncertainty) changes across heads. Plot (b) shows the correlation between block efficiency (a measure of how quickly the model decodes text) and hmax (the last head where the average entropy increases monotonically).  This demonstrates that the confidence of the prediction heads in blockwise parallel language models correlates with block efficiency.", "section": "Exploration of block drafts"}, {"figure_path": "KT6F5Sw0eg/figures/figures_5_1.jpg", "caption": "Figure 1: (a) Illustration of two tokens that are decoded by autoregressive decoding vs. two tokens drafted by BPD. (b) Outputs from our proposed rescoring algorithms, where the top-k token-level predictions are refined using local neural or global n-gram rescoring, which selects the p most probable sequences by dynamic programming, for batched verification.", "description": "This figure shows a comparison between autoregressive decoding and blockwise parallel decoding (BPD). (a) illustrates how autoregressive decoding generates tokens sequentially, while BPD predicts multiple tokens simultaneously (block drafts).  (b) demonstrates the authors' proposed rescoring methods which improve BPD by refining block drafts using either neural or n-gram language models. These methods select the most likely token sequences for verification by the base autoregressive language model, leading to faster inference.", "section": "2 Our contributions"}, {"figure_path": "KT6F5Sw0eg/figures/figures_6_1.jpg", "caption": "Figure 5: Oracle block efficiency over the top-k lattice as a function k. Each plot (a-f) represents a different task, demonstrating the relative improvement in block efficiency of the oracle draft with respect to the standard block draft as a function of the number of block draft heads used.", "description": "This figure displays the potential gains in block efficiency if the best possible sequence (oracle) is selected from a lattice created by combining the k most probable tokens at each head. The plots show that even with a limited number of heads, significant improvements can be achieved by using this oracle selection method.  The improvement varies across tasks, highlighting that some tasks are more conducive to improving efficiency with this approach than others.", "section": "5.3 Oracle top-k block efficiency"}, {"figure_path": "KT6F5Sw0eg/figures/figures_7_1.jpg", "caption": "Figure 5: Oracle block efficiency over the top-k lattice as a function k. Each plot (a-f) represents a different task, demonstrating the relative improvement in block efficiency of the oracle draft with respect to the standard block draft as a function of the number of block draft heads used.", "description": "This figure shows the potential for improvement in block efficiency by considering the top-k tokens at each head (oracle efficiency). The x-axis represents the value of k (number of top tokens considered), and the y-axis represents the relative improvement in block efficiency compared to the standard approach.  Each sub-plot (a-f) corresponds to a different task (LAMBADA, SQUAD V1, CNN/Daily, SAMSUM, MultiNews, XSUM) demonstrating the varying degree of potential improvement across different tasks. The figure highlights the headroom for improvement in block efficiency that can be achieved by selecting a better set of tokens at each head during decoding.", "section": "5.3 Oracle top-k block efficiency"}, {"figure_path": "KT6F5Sw0eg/figures/figures_8_1.jpg", "caption": "Figure 7: Block efficiency and speedup ratio relative to the standard autoregressive decoding on sub-categories of MT-Bench dataset [53] when greedily decoding with Vicuna 13B.", "description": "This figure shows the results of experiments comparing the block efficiency and speedup ratio of different decoding methods on various sub-categories of the MT-Bench dataset using the Vicuna 13B language model.  The methods compared include standard blockwise parallel decoding (BPD), BPD with local neural rescoring, standard Medusa decoding, and Medusa decoding with local neural rescoring. The x-axis represents the different sub-categories of tasks in the MT-Bench dataset, while the y-axis represents either block efficiency or speedup ratio. The figure demonstrates the improvement in both block efficiency and speedup ratio achieved by incorporating local neural rescoring into both BPD and Medusa decoding methods.", "section": "Lattice rescoring on open-source blockwise parallel LLMs"}, {"figure_path": "KT6F5Sw0eg/figures/figures_9_1.jpg", "caption": "Figure 7: Block efficiency and speedup ratio relative to the standard autoregressive decoding on sub-categories of MT-Bench dataset [53] when greedily decoding with Vicuna 13B.", "description": "This figure shows the results of applying blockwise parallel decoding (BPD) and the proposed rescoring methods to the Vicuna 13B language model.  The left panel (a) presents the block efficiency, which is a metric representing the average number of tokens decoded per serial call to the language model; higher values denote greater efficiency. The right panel (b) displays the speedup ratio relative to standard autoregressive decoding. Both metrics are shown for various sub-categories of the MT-Bench dataset, allowing for a comparison of performance across different task types (e.g., writing, roleplay, reasoning). The figure demonstrates that both BPD and Medusa decoding (an extension of BPD) show significant improvements in efficiency and speedup when using the proposed local rescoring technique. This improvement is consistent across multiple tasks, highlighting the effectiveness of the method.", "section": "Lattice rescoring on open-source blockwise parallel LLMs"}, {"figure_path": "KT6F5Sw0eg/figures/figures_18_1.jpg", "caption": "Figure 7: Block efficiency and speedup ratio relative to the standard autoregressive decoding on sub-categories of MT-Bench dataset [53] when greedily decoding with Vicuna 13B.", "description": "This figure shows a comparison of block efficiency and speedup ratio between different decoding methods (BPD, BPD with rescoring, Medusa, Medusa with rescoring) on various sub-categories of the MT-Bench dataset using the Vicuna 13B language model.  The x-axis represents different task categories, and the y-axis shows either block efficiency or speedup ratio compared to standard autoregressive decoding.  The results demonstrate the impact of rescoring methods on improving decoding efficiency and speed.", "section": "Lattice rescoring on open-source blockwise parallel LLMs"}]