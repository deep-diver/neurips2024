[{"type": "text", "text": "Follow Hamiltonian Leader: An Efficient Energy-Guided Sampling Method ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Anonymous Author(s)   \nAffiliation   \nAddress   \nemail ", "page_idx": 0}, {"type": "text", "text": "Abstract ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "1 Our research underscores the value of leveraging zeroth-order information for   \n2 addressing sampling challenges, particularly when first-order data is unreliable or   \n3 unavailable. In light of this, we have developed a novel parallel sampling method   \n4 that incorporates a leader-guiding mechanism. This mechanism forges connections   \n5 between multiple sampling instances via a selected leader, enhancing both the   \n6 efficiency and effectiveness of the entire sampling process. Our experimental   \n7 results demonstrate that our method markedly expedites the exploration of the   \n8 target distribution and produces superior quality outcomes compared to traditional   \n9 sampling techniques. Furthermore, our method also shows greater resilience against   \n10 the detrimental impacts of corrupted gradients as intended. ", "page_idx": 0}, {"type": "text", "text": "11 1 Introduction ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "12 Score-based generative models [35, 26, 36, 20] introduce a novel approach to generative modeling   \n13 that revolves around the estimation and sampling of the Stein score [26, 36]. The score represents   \n14 the gradient of the log-density function $\\nabla_{x}\\log\\pi(x)$ evaluated at the input data point $x$ . This type   \n15 of approach usually relies on effectively training a deep neural network to accurately estimate the   \n16 score. The estimated score is then utilized to navigate the sampling process, ultimately resulting   \n17 in the production of high-quality data samples that closely match the areas of high density in the   \n18 original distribution.   \n19 In our research, we investigate the sampling of a probability distribution given by $\\pi(x)\\propto e^{-U(x)}$ ,   \n20 where $U(x)$ is the energy function. In the context of energy-based score-matching generative models,   \n21 the objective often involves sampling the modes in areas of high probability density. An approach   \n22 as suggested in [36, 20], is to smooth the original distribution by convolving $\\pi(x)$ with an isotropic   \n23 Gaussian distribution of variance $\\sigma^{2}$ , yielding $\\begin{array}{r}{\\pi_{\\sigma}(x)\\,=\\,\\int\\pi(\\dot{x}^{\\prime})\\mathcal{N}(x;x^{\\prime},\\overset{\\circ}{\\sigma}^{2}\\dot{I})\\,d x^{\\prime}}\\end{array}$ . By gradually   \n24 decreasing the variance $\\sigma$ , $\\pi_{\\sigma}(x)$ recovers the original distribution $\\pi(x)$ .   \n25 Typically, the sampling of score-based approaches are integrated with numerical SDE solvers [38], for   \n26 example, the Euler-Maruyama solver, as well as Monte Carlo Markov Chain (MCMC) techniques like   \n27 Langevin Dynamics [30]. Furthermore, there is a notable similarity between score-based sampling   \n28 algorithms and first-order optimization algorithms. Efforts have been made to merge these two   \n29 methodologies, particularly from a perspective of sampling [42, 10, 28, 9, 44]. All these methods   \n30 primarily concentrates on first-order information $\\nabla_{x}U(x)$ to improve performance, while typically   \n31 treating the zeroth-order information $U(x)$ merely as a basis for rejecting samples [18, 32, 29].   \n32 We argue that incorporating zeroth-order information can significantly enhance the algorithm\u2019s overall   \n33 effectiveness, particularly in instances where the first-order information is compromised. To address   \n34 this, we draw inspiration from parallel tempering [39], a simulation method commonly used to   \n35 identify the lowest energy state in systems of interacting particles. The fundamental principle of   \n36 parallel tempering involves operating multiple sampling replicas simultaneously, each at a different   \n37 temperature level. These temperatures typically range from low, where the system is prone to being   \n38 trapped in local minima, to high, which facilitates the system\u2019s ability to surmount energy barriers   \n39 and more thoroughly explore the energy landscape.   \n40 Drawing inspiration from this concept, we extend the Hamiltonian Monte Carlo (HMC) framework   \n41 [29] and introduce a novel algorithm that concurrently runs multiple replicas, sampling at both high   \n42 and low Hamiltonian energy levels. Moreover, this methodology combines both zeroth and first   \n43 order information from various chains, hence enhancing the effectiveness of sampling approaches.   \n44 The experimental findings demonstrate the efficacy of our approach in scenarios where relying   \n45 solely on first-order knowledge is insufficient. These findings illustrate the capacity of incorporating   \n46 zeroth-order information to greatly enhance the efficiency and accuracy of sampling operations in   \n47 energy-based score-matching algorithms. ", "page_idx": 0}, {"type": "text", "text": "", "page_idx": 0}, {"type": "text", "text": "", "page_idx": 0}, {"type": "text", "text": "", "page_idx": 0}, {"type": "text", "text": "", "page_idx": 1}, {"type": "text", "text": "", "page_idx": 1}, {"type": "text", "text": "48 2 Background ", "text_level": 1, "page_idx": 1}, {"type": "text", "text": "49 2.1 Hamiltonian Monte Carlo ", "text_level": 1, "page_idx": 1}, {"type": "text", "text": "50 The primary purpose of MCMC is to construct a Markov chain that matches its equilibrium distribution   \n51 to the target distribution. One of the most popular MCMC methods is Langevin Monte Carlo [17, 32],   \n52 which proposes samples in a Metropolis-Hastings [18] framework for more efficient state space   \n53 exploration. Another advanced method is HMC [29, 11, 2], which incorporates an auxiliary variable   \n54 $p$ and employs Hamiltonian dynamics to facilitate the sampling process. The Hamiltonian function is   \n55 structured as a composite of potential energy $U(x)$ and kinetic energy $K(p)$ , defined as follows: ", "page_idx": 1}, {"type": "equation", "text": "$$\nH(x,p)=U(x)+K(p),\n$$", "text_format": "latex", "page_idx": 1}, {"type": "text", "text": "56 where $x$ represents the position of a particle and $p$ denotes its momentum. Kinetic energy $K(p)$   \n57 is commonly formulated as $K(p)\\,=\\,^{\\bullet}\\textstyle{\\frac{1}{2}}p^{T}M^{-1}p$ , where $M$ corresponds to the mass matrix. For   \n58 simplicity, we assume in this paper that the mass matrix $M$ is equal to the identity matrix $I$ . The joint   \n59 distribution of position and momentum conforms to the canonical distribution: ", "page_idx": 1}, {"type": "equation", "text": "$$\n\\pi(x,p)=e^{-H(x,p)}/Z,\n$$", "text_format": "latex", "page_idx": 1}, {"type": "text", "text": "60 where $Z=\\int\\!\\!\\!\\int e^{-H(x,p)}$ dxdp. Samples from $\\pi(x)$ can then be obtained by marginalizing $p$ from   \n61 $\\pi(x,p)$ , which further requires $\\textstyle\\int_{p}\\pi(x,p)\\ d p=$ constant. In the HMC algorithm, proposals are   \n62 generated by simulating Hamiltonian dynamics and then subjected to a Metropolis criterion to   \n63 determine their acceptance or rejection. A commonly employed numerical method for solving these   \n64 equations is the Leapfrog integrator [3].   \n65 Recent progress in HMC techniques has focused on increasing their adaptability and applicability in a   \n66 variety of contexts. Such developments include the NUTS sampler [21], which features an automatic   \n67 mechanism for adjusting the number of simulation steps. The Riemann manifold HMC [15] leverages   \n68 Riemannian geometry to modify the mass matrix $M$ , making use of curvature information to improve   \n69 sampling efficiency. Additionally, Stochastic Gradient Hamiltonian Monte Carlo [11, 27] investigates   \n70 a stochastic gradient approach within the HMC framework. Our contribution is distinct from these   \n71 methods and can be easily integrated with them. ", "page_idx": 1}, {"type": "text", "text": "", "page_idx": 1}, {"type": "text", "text": "72 2.2 Energy-based score-matching model ", "text_level": 1, "page_idx": 1}, {"type": "text", "text": "73 Probabilistic models often require normalization, which can become infeasible when dealing with   \n74 high-dimensional data [25, 13]. Since the exact probabilities of less probable alternatives become   \n75 less crucial as long as they remain relatively lower, rather than solely predicting the most probable   \n76 outcome, models can be structured to interpret relationships between variables via an energy function.   \n77 Within the context of generative models, these energy-based models (EBMs) are devised to assign   \n78 higher energy values to regions of lower probability and lower energy values to regions of higher   \n79 probability.   \n80 Score matching [22, 36] is a method used in statistical modeling and machine learning to estimate a   \n81 probability distribution or a probability density function from observed data. It is particularly useful   \n82 when direct estimation of the probability distribution is challenging, especially in high-dimensional   \n83 spaces. In score matching, the goal is to find an approximation to the probability density function   \n84 (PDF) of a dataset by estimating the score function, also known as the gradient of the log-density.   \n85 The score function represents the derivative of the log PDF with respect to the data. By matching the   \n86 estimated score function to the observed data, one can indirectly estimate the underlying probability   \n87 distribution.   \n88 A relationship between EBMs and score matching can be established by training EBMs through   \n89 denoising score matching [37]. The training objective is described below: ", "page_idx": 1}, {"type": "text", "text": "", "page_idx": 1}, {"type": "text", "text": "", "page_idx": 2}, {"type": "text", "text": "", "page_idx": 2}, {"type": "equation", "text": "$$\n\\mathbb{E}_{\\pi(x),N(\\epsilon;0,I)}\\left[\\left\\|\\frac{\\epsilon}{\\sigma}\\!-\\!\\nabla_{x}U_{\\theta}\\left(x+\\sigma\\epsilon\\right)\\right\\|_{2}^{2}.\n$$", "text_format": "latex", "page_idx": 2}, {"type": "text", "text": "90 $U_{\\theta}$ is typically represented as a neural network, with $\\theta$ denoting its parameters. Minimizing this   \n91 objective ensures that $\\nabla_{x}U_{\\theta}(x)=-\\nabla_{x}\\log\\pi_{\\sigma}(x)$ and thus $e^{-U_{\\theta}(x)}$ shall be proportional to $\\pi_{\\sigma}(x)$ . ", "page_idx": 2}, {"type": "text", "text": "92 3 Motivation ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "93 In our work, we assume to have access to both the gradi  \n94 ent information $\\nabla_{x}U(x)$ as well as the energy information   \n95 $U(x)$ . In certain scenarios, gradients may yield informa  \n96 tion that is either of limited or potentially detrimental. Our   \n97 research examines situations where gradients are compro  \n98 mised, highlighting the importance of zeroth-order infor  \n99 mation, often associated with energy-based sampling.   \n100 We concentrate on showcasing the strengths of our method   \n101 in three types of challenging but common scenarios, sum  \n102 marized as instability, metastability and pseudo-stability.   \n103 Instability refers to a state in which a system lacks equilibrium or steadiness, often leading to unpre  \n104 dictable or erratic behavior. Metastability describes a condition where a system appears stable over a   \n105 short period but is not in its most stable state, and it can transition to a more stable state under certain   \n106 conditions. Pseudo-stability, on the other hand, denotes a situation where a system seems stable but   \n107 is actually in an incorrect, suboptimal, or misleadingly stable state.   \n108 Instability. In high-dimensional spaces, sampling algo  \n109 rithms may struggle to converge in the presence of a com  \n110 plex probability distribution. This instability can arise in   \n111 situations where the local Hessian matrix is ill-conditioned   \n112 or spectrum of the local Hessian matrix is exceptionally   \n113 large. Such conditions often lead to inaccuracies or insta  \n114 bilities in numerical calculations, potentially causing the   \n115 convergence process to fail. The samples generated could   \n116 substantially diverge from the true mode, resulting in subpar sample quality. However, employing an ", "page_idx": 2}, {"type": "text", "text": "", "page_idx": 2}, {"type": "image", "img_path": "34dHGTri2w/tmp/93cc08f8b89bb704f0fc8608301522387eac7e1b8ada2572fa9a00df47621864.jpg", "img_caption": ["Figure 1: A good anchor point could help improve convergence even if the gradient is unexpectedly disturbed from original gradient to the disturbed gradient, getting closer to the optimal point. "], "img_footnote": [], "page_idx": 2}, {"type": "text", "text": "", "page_idx": 2}, {"type": "text", "text": "", "page_idx": 2}, {"type": "image", "img_path": "34dHGTri2w/tmp/60a4a0ccf61b572924f37ba4b418c7f7dd5877da2a00c94e7f435f9139f1a14f.jpg", "img_caption": ["Figure 2: To enhance exploratory capabilities, it\u2019s important to encourage particle to explore the landscape. "], "img_footnote": [], "page_idx": 2}, {"type": "text", "text": "117 anchor point can enhance the stability of convergence, as demonstrated in Figure 1. ", "page_idx": 2}, {"type": "text", "text": "118 Metastability. Particles are prone to getting stuck in local minima when the gradients are not   \n119 informative. For example, on the saddle point or a pleaute loss landscape. As a result, simulations   \n120 frequently end up in a state of intermediate energy, which is different from the system\u2019s lowest energy   \n121 state. This scenario is illustrated in Figure 2.   \n122 Pseudo-Stability. Certain situations may present a diver  \n123 gence between the gradient information and the ground   \n124 truth. This divergence can hinder algorithms from accu  \n125 rately converging to the appropriate modes. In these in  \n126 stances, it becomes essential to incorporate energy informa  \n127 tion to rectify inaccuracies that arise from solely depending   \n128 on gradients. An example of misleading gradients could be   \n129 observed in Figure 3. ", "page_idx": 2}, {"type": "text", "text": "", "page_idx": 2}, {"type": "text", "text": "130 4 Algorithm ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "131 Many sampling methods typically rely on independent   \n132 Markov chains, which can lead to the issues mentioned   \n133 in Section 3. Taking inspiration from [39], our approach   \n134 involves the utilization of multiple replicas. This approach ", "page_idx": 2}, {"type": "image", "img_path": "34dHGTri2w/tmp/dd27f4b8432dc7e4fba0ddbba8a5b67a72afa3053ab37e3f65df78ea5e250d50.jpg", "img_caption": ["Figure 3: There is a potential for particles to unintentionally follow the gradient flow towards these regions of high energy. A more comprehensive description could be found at Section 5.1.3. "], "img_footnote": [], "page_idx": 2}, {"type": "text", "text": "Input: A collection of positions $\\{x^{i}\\}_{i=1}^{n}\\ \\in\\ \\mathbb{R}^{n\\times d}$ , a collection of momenta $\\{p^{i}\\}_{i=1}^{n}\\,\\in\\,\\mathbb{R}^{n\\times d}$ , learning rate $\\eta>0$ , pulling strength $\\lambda\\geq0$ , number of Leapfrog steps $L$ . ", "page_idx": 3}, {"type": "text", "text": "for $s=1,\\cdot\\cdot\\cdot\\,,L\\,\\mathbf{do}$ ", "page_idx": 3}, {"type": "text", "text": "for $i=1,\\cdots,n$ do Choose the leader $x^{l}$ and calculate $\\rho^{i}$ $g^{i}\\leftarrow\\nabla_{x}U(x^{i})+\\rho^{i}\\cdot(x^{i}-x^{l});p^{i}\\leftarrow p^{i}-\\frac{\\eta}{2}\\cdot g^{i}$ $x^{i}\\leftarrow x^{i}+\\eta\\cdot p^{i}$ Choose the leader $x^{l}$ and calculate $\\rho^{i}$ $g^{i}\\leftarrow\\nabla_{x}U(x^{i})+\\rho^{i}\\cdot(x^{i}-x^{l});p^{i}\\leftarrow p^{i}-\\frac{\\eta}{2}\\cdot g^{i}$   \nend for ", "page_idx": 3}, {"type": "text", "text": "$\\triangleright$ Half step for momentum \u25b7Full step for position ", "page_idx": 3}, {"type": "text", "text": "end for ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "Output: $x\\in\\mathbb{R}^{d},p\\in\\mathbb{R}^{d}$ ", "page_idx": 3}, {"type": "text", "text": "135 enables us to implicitly encourage greater exploration among multiple particles while simultaneously   \n136 preserving the optimal outcomes for exploitation purposes. We will elaborate on how our algorithm   \n137 can be employed to tackle these challenges.   \n138 Firstly, we introduce a modified version of the leapfrog method, called the Elastic Leapfrog   \n139 (eLeapfrog). In this approach, additional elastic forces are applied between each particle and a   \n140 leader, incorporating an extra elastic energy term into the traditional Hamiltonian function. This   \n141 modification aims to prevent particles from straying significantly from each other, thereby promoting   \n142 local exploitation. We then divide the particles into groups and designate the particle with the lowest   \n143 energy as the leader. Moreover, when combined with the eLeapfrog method, this approach encourages   \n144 other particles to explore around the leader, efficiently addressing the problem of instability.   \n145 Due to the properties of HMC, introducing such an extra elastic energy term when pulling the particles   \n146 towards the leader implicitly incorporates this energy into the momentum, thereby increasing the   \n147 search ability of each particle. As a result, non-leading particles gain more energy for exploration,   \n148 while the leading particle is more likely to concentrate on local exploitation. This approach helps   \n149 mitigate the issue of metastability.   \n150 Finally, we integrate these techniques to present our compplete Follow Hamiltonian Leader (FHL)   \n151 algorithm. The FHL algorithm capitalizes on both first-order and zeroth-order information while   \n152 significantly improving the efficiency of space sampling compared to traditional sequential sampling   \n153 methods. This enhanced approach fosters convergence towards the lowest energy states and increases   \n154 the likelihood of escaping states with pseudo stability. ", "page_idx": 3}, {"type": "text", "text": "", "page_idx": 3}, {"type": "text", "text": "", "page_idx": 3}, {"type": "text", "text": "", "page_idx": 3}, {"type": "text", "text": "155 4.1 Elastic Leapfrog ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "156 To improve the efficiency of sampling, we integrate an elastic force component into the conventional   \n157 leapfrog technique. This enhancement aims to dynamically guide particles towards a leading particle,   \n158 facilitating their movement and improve their exploration ability. The method could be treated like   \n159 temporarily storing potential energy within an elastic spring, which is then converted into kinetic   \n160 energy. By adding extra elastic force, we could define the energy of elastic HMC as: ", "page_idx": 3}, {"type": "equation", "text": "$$\nH_{e}(x,p;\\tilde{x})=U_{e}(x;\\tilde{x})+K(p)=\\underbrace{[U(x)+E(x;\\tilde{x})]}_{U_{e}(x,\\tilde{x})}+K(p),\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "116612 where $E(x;\\tilde{x})$ is the extra elastic energy imposed by Elastic Leapfrog and is defined as $E(x;\\tilde{x})=$   \n163 $\\frac{\\rho}{2}\\left\\|\\boldsymbol{x}-\\boldsymbol{\\tilde{x}}\\right\\|_{2}^{2}$ . Our approach enables particles to efficiently navigate the sample space, guided by the   \n164 leader. This local exploration strategy, though similar to concepts in [46, 7, 8, 40], is uniquely tailored   \n165 for application in the realm of sampling. ", "page_idx": 3}, {"type": "text", "text": "166 4.2 Leader Pulling ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "167 Next, we introduce our leader pulling method. Initially, we represent the $i^{t h}$ particle inside a group   \n168 as $x^{i}$ and select a leader based on a their energies $U({\\boldsymbol{x}}^{i})$ . The motivation is that we encourage each   \n169 particle $x^{i}$ to be guided towards a chosen leader. The leader is chosen as the one of minimum energy   \n170 and thus its index is $l=\\arg\\operatorname*{min}_{i}U(x^{i})$ . The objective function for a group of $n$ particles is: ", "page_idx": 3}, {"type": "text", "text": "", "page_idx": 4}, {"type": "equation", "text": "$$\nU_{e}(x^{1},\\cdots,x^{n};x^{l})=\\sum_{i=1}^{n}U(x^{i})+\\frac{\\rho^{i}}{2}\\cdot\\|x^{i}-x^{l}\\|_{2}^{2},\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "117712 where $\\begin{array}{r}{\\pi^{i}=\\exp\\left(-U(x^{i})\\right)/\\sum_{j}\\exp\\left(-U(x^{j})\\right)}\\end{array}$ and $\\rho^{i}=\\lambda\\cdot(\\pi^{l}-\\pi^{i})/(\\pi^{l}+\\pi^{i})$ . The specifics of   \n173 the Elastic Leapfrog algorithm combined with leader pulling technique are detailed in Algorithm 1. ", "page_idx": 4}, {"type": "text", "text": "174 4.3 Follow Hamiltonian Leader ", "text_level": 1, "page_idx": 4}, {"type": "text", "text": "175 Incorporating zeroth-order information (i.e., function values rather than derivatives) serves two key   \n176 purposes. Firstly, it provides a search direction that accelerates convergence and helps mitigate issues   \n177 arising from corrupted first-order information (i.e., gradient inaccuracies), thereby speeding up the   \n178 optimization process. Second, it helps ensure that we are sampling from the correct underlying   \n179 distribution by properly accepting or rejecting the proposal.   \n180 To ensure that the sampling method maintains detailed balance\u2014a requirement for most sampling   \n181 algorithms\u2014we evaluate the joint distribution of a group of particles. This evaluation determines   \n182 whether to accept or reject a proposed move for the whole group, thereby preserving the integrity   \n183 of the sampling process. This adaptation results in the creation of our algorithm FHL, extensively   \n184 elucidated in Algorithm 2. ", "page_idx": 4}, {"type": "text", "text": "", "page_idx": 4}, {"type": "text", "text": "Algorithm 2 Follow Hamiltonian Leader ", "text_level": 1, "page_idx": 4}, {"type": "text", "text": "Input: A collection of positions $\\{x^{i}\\}_{i=1}^{n}\\in\\mathbb{R}^{n\\times d}$ , learning rate $\\eta\\,>\\,0$ , pulling strength $\\lambda\\geq0$ , number of steps . ", "page_idx": 4}, {"type": "text", "text": "for $t=1,2,\\cdot\\cdot\\cdot,T\\,.$ do # Run sampling in parallel for $i=1,\\cdots,n$ do Randomly sample the momentum $p_{t-1}^{i}\\sim\\mathcal{N}(0,I)$ $x_{\\mathrm{prop}}^{i},p_{\\mathrm{prop}}^{i}\\leftarrow$ eLeapfrog $(x_{t-1}^{i},p_{t-1}^{i},\\eta,\\lambda,L)$ end for Sample a random variable $u\\sim\\mathrm{Uniform}(0,1)$ if $\\begin{array}{r}{u<\\prod_{i=1}^{n}\\exp\\left(H(x_{\\mathrm{prop}}^{i},p_{\\mathrm{prop}}^{i})-H(x_{t-1}^{i},p_{t-1}^{i})\\right)}\\end{array}$ then for $i=1,\\cdots,n$ do $x_{t}^{i}\\gets x_{p r o p}^{i}$ , $p_{t}^{i}\\gets p_{\\mathrm{prop}}^{i}$ end for else for $i=1,\\cdots,n$ do $x_{t}^{i}\\gets x_{t-1}^{i}$ , $p_{t}^{i}\\gets p_{t-1}^{i}$ end for end if   \nend for   \nOutput: $X_{T}=\\{x_{T}^{i}\\}_{i=1}^{n}\\in\\mathbb{R}^{n\\times d}$ ", "page_idx": 4}, {"type": "text", "text": "", "page_idx": 4}, {"type": "text", "text": "185 5 Experiment ", "text_level": 1, "page_idx": 4}, {"type": "text", "text": "186 In this section, we showcase the efficacy of incorporating zeroth-order information, specifically   \n187 energy information, into our proposed method to improve the sampling process. We focus on   \n188 demonstrating the advantages of our approach in addressing the beneftis of our approach in handling   \n189 three distinct adversarial gradient scenarios, as outlined in Section 3. To evaluate our method on the   \n190 performance of the concerned questions, we conduct a comparative analysis against the following   \n191 baseline algorithms:   \n192 \u2022 LMC (Langevin Monte Carlo): An MCMC method as described in [17] that uses Langevin   \n193 dynamics to sample from probability distributions. It is also known as the Metropolis  \n194 adjusted Langevin algorithm.   \n95 \u2022 HMC (Hamiltonian Monte Carlo): An MCMC algorithm that employs Hamiltonian dynamics   \n96 for more efficient traversal of the state space, leading to better exploration and sampling   \n97 from complex distributions [29, 11, 2].   \n198 \u2022 U-LMC (Unadjusted Langevin Dynamics): A variation of LMC without the Metropolis correc  \n199 tion, referred to [32, 1, 42].   \n200 \u2022 U-HMC (Unadjusted Hamiltonian Monte Carlo): A form of HMC that excludes the Metropolis   \n201 correction step, as in [34, 14]. ", "page_idx": 4}, {"type": "text", "text": "", "page_idx": 4}, {"type": "text", "text": "", "page_idx": 4}, {"type": "text", "text": "", "page_idx": 4}, {"type": "text", "text": "", "page_idx": 5}, {"type": "text", "text": "202 5.1 Motivating Examples ", "text_level": 1, "page_idx": 5}, {"type": "text", "text": "203 We report on results addressing the challenges identified as instability, metastability, and pseudo  \n204 stability. Our findings lead us to conclude that the FTH method consistently outperforms other   \n205 approaches in all scenarios examined. Detailed discussions and further analyses of these findings will   \n206 be presented in the following subsections.   \n207 In our experiment, we simultaneously execute sampling with $N$ particles, each completing a total of   \n208 $T$ sampling steps. For the FTH method, these particles are divided into $N/n$ groups, with each group   \n209 containing $n$ particles. Throughout all experiments, we set $n$ to 4. For hyperparameter search, we   \n210 select step sizes $\\eta=\\{0.002,0.0002,0.005,0.0005\\}$ for all methods and number of leapfrog steps   \n211 $L=\\{4,\\bar{8},16\\}$ for HMC-type methods. ", "page_idx": 5}, {"type": "text", "text": "", "page_idx": 5}, {"type": "text", "text": "212 5.1.1 Instability ", "text_level": 1, "page_idx": 5}, {"type": "image", "img_path": "34dHGTri2w/tmp/988b7d49dd798d1bbd60280e88d7ba902d4c5e44324c70205823ac20942614e3.jpg", "img_caption": ["(b) Sampling from the approximated distribution in the form of $e^{-U_{\\theta}(x)}$ . $T=2000$ in all experiments. Figure 4: Sample from a Gaussian distribution $\\mathcal{N}(\\mu,\\Sigma)$ where $\\mu\\in\\mathbb{R}^{d}$ corresponds to the clean image. For each method, we plot the lowest-energy particle (in terms of $U(x)$ among all particles in $X_{T}$ ). The upper-left image represents a direct sample from the distribution $\\mathcal{N}(\\mu,\\Sigma)$ ; The lower-left image is generated by performing HMC sampling for $T$ steps on the function $U_{\\theta}(x)$ , with an initial point set to x0 = \u00b5 . "], "img_footnote": [], "page_idx": 5}, {"type": "text", "text": "213 In our sampling process, we focus on efficiently directing particles to high probability density regions,   \n214 thereby avoiding unproductive exploration in regions with low probability. When sampling from a   \n215 single image, our goal becomes attaining the global optima, aligning this objective with those found   \n216 in optimization tasks.   \n217 For our experiment, we chose an image resembling the GitHub logo (https://github.com/logos),   \n218 converted it into a vector format, and use this as the mean of a multivariate Gaussian distribution.   \n219 The covariance matrix for this distribution, represented by $\\Sigma$ , is diagonal. The variance for each   \n220 dimension of the distribution is randomly determined by a uniform distribution within the range of   \n221 (0.25, 1.25). We carry out two similar but different types of experiments:   \n222 In the first experiment, we focus on sampling from the original distribution. This distribution   \n223 is described mathematically as $e^{-U(x)}\\,\\propto\\,{\\mathcal{N}}(\\mu,\\Sigma)$ , with $U(x)$ being the energy function that   \n224 characterizes the system.   \n225 For the energy-based score-matching model, we employ a ResNet [19] architecture with 6 layers   \n226 of a hidden dimension of 256. The results of the sampling process are detailed in Figure 4, where   \n227 the main objective is to assess the particles\u2019 capacity for effective convergence to the mode of the   \n228 distribution. In the first scenario, $U(x)$ represents a convex function, whereas in the second scenario,   \n229 $U_{\\theta}(x)$ is presumed to be non-convex. The findings demonstrate that our approach, FHL, surpasses   \n230 other baseline methods in both situations. ", "page_idx": 5}, {"type": "text", "text": "", "page_idx": 5}, {"type": "text", "text": "", "page_idx": 5}, {"type": "text", "text": "", "page_idx": 5}, {"type": "text", "text": "231 5.1.2 Metastability ", "text_level": 1, "page_idx": 6}, {"type": "text", "text": "232 Our research explores the concept of   \n233 metastability, which arises in specific   \n234 scenarios. Metastability refers to a   \n235 state of intermediate energy in a dy  \n236 namic system, differing from its low  \n237 est energy state. We examine an ex  \n238 treme scenario where gradients are en  \n239 tirely absent, and sampling methods   \n240 only get access to the energy informa  \n241 tion about the distribution.   \n242 In Figure 5, it\u2019s evident that in this par  \n243 ticular situation, we enforce the gra  \n244 dient to be near zero, resulting in all   \n245 sampling methods, except FHL and   \n246 LMC, behaving almost like random   \n247 sampling. Nevertheless, owing to the   \n248 leader pulling strategy, FHL retains its   \n249 ability to locate the mode much faster. ", "page_idx": 6}, {"type": "text", "text": "", "page_idx": 6}, {"type": "text", "text": "250 5.1.3 Pseudo-stability ", "text_level": 1, "page_idx": 6}, {"type": "image", "img_path": "34dHGTri2w/tmp/8c22f09cd6188d5769ef727b77b972f8c6f48834ade91e345c96fbde4474455c.jpg", "img_caption": ["Figure 5: Plot of $N=256$ particles of $X_{T}$ on $d=2$ starting from random initialization $\\bar{\\mathcal{N}}(0,4\\!\\cdot\\!I)$ . The target distribution is $\\mathcal{N}([1,1],I)$ . Energy State corresponds to the target density $\\pi$ . The baseline methods U-LMC,LMC,U-HMC,HMC and our proposed method FHL generate $X_{T}$ after $T\\,=\\,1000$ steps. There are no gradient flows and the samplers are only able to sample by the energy information. "], "img_footnote": [], "page_idx": 6}, {"type": "text", "text": "251 This section highlights the phenomenon showcased in Figure 3. Here, particles can become ensnared   \n252 by gradient flows and be coerced into pseudo-stable regions. Despite the eventual recovery of the   \n253 correct distribution by the sampling method, the convergence process can be exceptionally sluggish.   \n254 To elaborate, we examine a scenario where the samplers solely depend on gradients from $\\nabla\\log Q$ ,   \n255 while the energy function $P$ remains deliberately undisclosed. The distributions $P$ and $Q$ are: ", "page_idx": 6}, {"type": "text", "text": "", "page_idx": 6}, {"type": "text", "text": "256 ", "page_idx": 6}, {"type": "text", "text": "257 ", "page_idx": 6}, {"type": "equation", "text": "$$\n\\begin{array}{l}{{\\bullet\\,\\,Q\\sim\\frac{1}{4}\\left[N\\left(\\mu_{1},I\\right)+{\\mathcal N}\\left(\\mu_{2},I\\right)+{\\mathcal N}\\left(\\mu_{3},I\\right)+{\\mathcal N}\\left(\\mu_{4},I\\right)\\right]}}\\\\ {{\\bullet\\,\\,P\\sim\\frac{1}{2}\\left[{\\mathcal N}\\left(\\mu_{1},I\\right)+{\\mathcal N}\\left(\\mu_{2},I\\right)\\right]}}\\end{array}\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "258 where $\\mu_{1}=[-2,0]$ , $\\mu_{2}=[2,0]$ , $\\mu_{3}=[0,2]$ and $\\mu_{4}=[0,-2]$ . ", "page_idx": 6}, {"type": "text", "text": "259 From Figure 6 we can see that FTH   \n260 does not only capture the modes more   \n261 quickly compared to the other meth  \n262 ods but also successfully get out of the   \n263 trap of the pseudo-stable regions.   \n264 Our study addresses the challenges   \n265 of instability, metastability, and   \n266 pseudo-stability, demonstrating that   \n267 the FTH method consistently outper  \n268 forms other approaches across various   \n269 scenarios. Through illustrative experi  \n270 ments, we show that FTH rapidly cap  \n271 tures modes and effectively escapes   \n272 pseudo-stable regions, even when gra  \n273 dients are entirely absent. This su  \n274 perior performance is attributed to   \n275 FTH\u2019s unique leader pulling strat  \n276 egy, which directs particles efficiently   \n277 to high-probability density regions,   \n278 thereby avoiding unproductive explo  \n279 ration in low-probability areas. ", "page_idx": 6}, {"type": "text", "text": "", "page_idx": 6}, {"type": "image", "img_path": "34dHGTri2w/tmp/b9caa8ff6559970e4094c676afc47fed14fe4b5657c9671bbf4e6c8042962a8f.jpg", "img_caption": [], "img_footnote": [], "page_idx": 6}, {"type": "text", "text": "Figure 6: Plot of $N\\,=\\,256$ particles of $X_{T}$ for a 2-mode Gaussian mixture model on $d\\,=\\,2$ starting from random initialization ${\\mathcal{N}}(0,4\\cdot I)$ . Energy State corresponds to the target density $\\pi$ . The baseline methods U-LMC,LMC,UHMC,HMC and our proposed method FHL generate $X_{T}$ after $T=200$ steps. ", "page_idx": 6}, {"type": "text", "text": "280 In the following section, we will illustrate the advantages of FTH in more general applications,   \n281 particularly for energy-based (score-matching) models.   \n283 Energy-based models (EBMs) offer significant advantages for sampling because they naturally   \n284 provide energy information that can be utilized to guide the sampling process. In an EBM, the energy   \n285 function assigns lower energy values to more probable configurations, enabling the sampler to more   \n286 effectively navigate the probability landscape and generate high-quality samples. This makes EBMs   \n287 a powerful tool in scenarios where precise sampling is essential.   \n288 We investigate a scenario where energy functions guide the sampling process. We use the generative   \n289 model outlined in [16] and adopt a conditional generation method that leverages classifier-derived   \n290 gradients for sampling. The classifier\u2019s output is considered as the energy for guided sampling.   \n291 The common classification tasks involving $C$ classes are often solved by using a neural network   \n292 $f_{\\theta}:\\mathbb{R}^{d}\\rightarrow\\mathbb{R}^{C}$ , which maps each input data point $\\boldsymbol{x}\\in\\mathbb{R}^{d}$ to $C$ -categorical outputs. The output are   \n293 then used to define a categorical distribution of class $y$ through a softmax function: ", "page_idx": 6}, {"type": "text", "text": "", "page_idx": 7}, {"type": "text", "text": "", "page_idx": 7}, {"type": "equation", "text": "$$\np_{\\theta}(y\\mid x)=\\frac{\\exp(f_{\\theta}(x)[y])}{\\sum_{y^{\\prime}}\\exp(f_{\\theta}(x)[y^{\\prime}])},\n$$", "text_format": "latex", "page_idx": 7}, {"type": "text", "text": "294 where $f_{\\boldsymbol{\\theta}}(x)[y]$ represents the $y$ -th component of $f_{\\boldsymbol{\\theta}}(\\boldsymbol{x})$ , corresponding to the logit for class $y$ . Once   \n295 the classifier is trained, $p_{\\theta}^{\\prime}(y\\mid x)=\\exp(f_{\\theta}(x)[y])$ could be used to sample for a specific class $y$ .   \n296 We compare FTH with the standard HMC method using a limited number of sampling steps, con  \n297 sistently accepting new proposals based on the potential energy during sampling. It is evident that   \n298 FTH produces higher-quality images than HMC. Additionally, our experiments reveal that FTH tends   \n299 to generate sharper images compared to the other method. This can be attributed to the assumption   \n300 that the classifier focuses on the object\u2019s features rather than the entire image. As a result, when the   \n301 prediction probability is high, the features that increase confidence become more prominent, while   \n302 unrelated background elements are filtered out. ", "page_idx": 7}, {"type": "image", "img_path": "34dHGTri2w/tmp/2381a1f5bc2799880a9a6186a4a13d5252c8643a27312c78e22a57ad3b8c8566.jpg", "img_caption": ["Figure 7: Sample from joint energy model by different classes (Left: HMC; Right: FTH). "], "img_footnote": [], "page_idx": 7}, {"type": "text", "text": "", "page_idx": 7}, {"type": "text", "text": "303 5.3 Energy-Based Score-Matching Models ", "text_level": 1, "page_idx": 7}, {"type": "text", "text": "304 As indicated in [12], when two diffusion models are combined into a product model $q^{\\mathrm{prod}}(x)\\propto$   \n305 $q^{1}(x)q^{2}(x)$ , problems can arise if the model reversing the diffusion uses a score estimate derived   \n306 by simply adding the score estimates of the two independent models. We use energy-based score  \n307 matching models to illustrate this issue. It is important to note that such inconsistencies typically   \n308 involve the composition of two or more diffusion models. ", "page_idx": 7}, {"type": "text", "text": "309 5.3.1 Synthetic Dataset ", "text_level": 1, "page_idx": 8}, {"type": "text", "text": "310 We first show an example of composing two distributions $p_{1}(x)$ and $p_{2}(x)$ , as illustrated in the left   \n311 column of Figure 8. The results show that FTH demonstrates a strong ability to converge to the   \n312 correct composition, with less particles fall out of the high-density region compared to others. ", "page_idx": 8}, {"type": "image", "img_path": "34dHGTri2w/tmp/2a5457147b1b990f29269bb2c6433b0de275eeff26ffc2256c4f34b5a3a011e0.jpg", "img_caption": ["Figure 8: Compose sampling with DDPM. "], "img_footnote": [], "page_idx": 8}, {"type": "text", "text": "313 5.3.2 CLEVR Dataset ", "text_level": 1, "page_idx": 8}, {"type": "text", "text": "314 We use CLEVR dataset from [23] for our gen  \n315 eration and sampling tasks. The energy model   \n316 is adopted from [12], and we employ different   \n317 samplers for generation. The dataset includes   \n318 three classes: cube, sphere, and cylinder. We   \n319 explore scenarios where we first sample from   \n320 only one category and then from two categories.   \n321 In the first experiment, there is no composition   \n322 of models. As depicted in Figure 9, it is evident   \n323 that FTH effectively generates the desired image   \n324 without any extraneous shapes, whereas both   \n325 MALA and HMC generate additional shapes.   \n326 In the second experiment, we combine two in  \n327 dependent diffusion models, each trained sepa  \n328 rately to generate sphere and cylinder. As shown   \n329 in Figure 10, it is clear that FTH excels at pro  \n330 ducing high-quality images with almost no over", "page_idx": 8}, {"type": "text", "text": "", "page_idx": 8}, {"type": "text", "text": "", "page_idx": 8}, {"type": "image", "img_path": "34dHGTri2w/tmp/1a3ed1e5d3917263f77686bb0ebadd95888e47ae268e20df75a4df1455536501.jpg", "img_caption": [], "img_footnote": [], "page_idx": 8}, {"type": "text", "text": "Figure 9: Generation of cube. The zoomed images could be found at Figure 19. ", "page_idx": 8}, {"type": "image", "img_path": "34dHGTri2w/tmp/1b9249e67d07d6d31cb64bae4e28a5b0e69ba7810664b4426b17a32480962d7c.jpg", "img_caption": [""], "img_footnote": [], "page_idx": 8}, {"type": "text", "text": "Figure 10: Generation of sphere and cylinder. The zoomed images could be found at Figure 20. ", "page_idx": 8}, {"type": "text", "text": "331 lapping between objects, accurately rendering the intended shapes in a pristine manner. In contrast,   \n332 the other methods generate the undesired shape cube. Additionally, FTH exhibits less noise, indicating   \n333 greater stability for sampling. ", "page_idx": 8}, {"type": "text", "text": "334 6 Conclusion", "text_level": 1, "page_idx": 8}, {"type": "text", "text": "335 In this study, we first recognize the significance of incorporating zeroth-order information into the   \n336 sampling process, highlighting the common limitations faced by conventional sampling methods.   \n337 These limitations include unstable sampling outcomes frequently associated with energy-based   \n338 score-matching models, the potential metastability arising from the multi-modal nature of the energy   \n339 function, and errors in gradient computation stemming from the complex structure of the composi  \n340 tional distribution. Subsequently, we present an innovative approach that leverages parallel HMC   \n341 sampling to address the issues. Building upon HMC, we incorporate energy modulation techniques   \n342 to enhance the sampling process. Through this approach, our method is able to systematically reduce   \n343 the potential energy, leading to substantial advantages in practical implementations of sampling. ", "page_idx": 8}, {"type": "text", "text": "344 References ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "345 [1] Christophe Andrieu, \u00c9ric Moulines, and Francis J Samson. Particle markov chain monte carlo   \n346 for efficient numerical simulation. Statistical Science, 25(4):332\u2013350, 2010.   \n347 [2] Michael Betancourt. A Conceptual Introduction to Hamiltonian Monte Carlo, July 2018.   \n348 [3] Charles K. Birdsall and A. Bruce Langdon. Plasma physics via computer simulation. Taylor   \n349 and Francis, New York, 2005.   \n350 [4] J\u00e9r\u00f4me Bolte and Edouard Pauwels. A mathematical model for automatic differentiation in   \n351 machine learning. Advances in Neural Information Processing Systems, 33:10809\u201310819, 2020.   \n352 [5] Steve P. Brooks, Andrew Gelman, Galin L. Jones, and Xiao-Li Meng. Handbook of markov   \n353 chain monte carlo: Hardcover: 619 pages publisher: Chapman and hall/crc press (first edition,   \n354 may 2011) language: English isbn-10: 1420079417. CHANCE, 25:53 \u2013 55, 2012.   \n355 [6] Augustin Louis Cauchy. M\u00e9thode g\u00e9n\u00e9rale pour la r\u00e9solution des syst\u00e9mes d\u2019\u00e9quations simul  \n356 tan\u00e9es. Comptes Rendus de l\u2019Acad\u00e9mie des Sciences Paris, 25:536\u2013538, 1847.   \n357 [7] P. Chaudhari, A. Choromanska, S. Soatto, Y. LeCun, C. Baldassi, C. Borgs, J. T. Chayes,   \n358 L. Sagun, and R. Zecchina. Entropy-SGD: Biasing gradient descent into wide valleys. In ICLR,   \n359 2017.   \n360 [8] Pratik Chaudhari, Carlo Baldassi, Riccardo Zecchina, Stefano Soatto, Ameet Talwalkar,   \n361 and Adam Oberman. Parle: parallelizing stochastic gradient descent. arXiv preprint   \n362 arXiv:1707.00424, 2017.   \n363 [9] Changyou Chen, David Carlson, Zhe Gan, Chunyuan Li, and Lawrence Carin. Bridging the   \n364 gap between stochastic gradient mcmc and stochastic optimization. In Arthur Gretton and   \n365 Christian C. Robert, editors, Proceedings of the 19th International Conference on Artificial   \n366 Intelligence and Statistics, volume 51 of Proceedings of Machine Learning Research, pages   \n367 1051\u20131060, Cadiz, Spain, 09\u201311 May 2016. PMLR.   \n368 [10] Tianqi Chen, Emily Fox, and Carlos Guestrin. Stochastic Gradient Hamiltonian Monte Carlo.   \n369 In Proceedings of the 31st International Conference on Machine Learning, pages 1683\u20131691.   \n370 PMLR, June 2014.   \n371 [11] Tianqi Chen, Emily Fox, and Carlos Guestrin. Stochastic gradient hamiltonian monte carlo.   \n372 In Eric P. Xing and Tony Jebara, editors, Proceedings of the 31st International Conference on   \n373 Machine Learning, volume 32 of Proceedings of Machine Learning Research, pages 1683\u20131691,   \n374 Bejing, China, 22\u201324 Jun 2014. PMLR.   \n375 [12] Yilun Du, Conor Durkan, Robin Strudel, Joshua B. Tenenbaum, Sander Dieleman, Rob Fer  \n376 gus, Jascha Sohl-Dickstein, Arnaud Doucet, and Will Grathwohl. Reduce, reuse, recycle:   \n377 Compositional generation with energy-based diffusion models and mcmc. JMLR.org, 2023.   \n378 [13] Yilun Du and Igor Mordatch. Implicit generation and modeling with energy based models. In   \n379 H. Wallach, H. Larochelle, A. Beygelzimer, F. dAlch\u00e9-Buc, E. Fox, and R. Garnett, editors,   \n380 Advances in Neural Information Processing Systems, volume 32. Curran Associates, Inc., 2019.   \n381 [ 14] Tomas Geffner and Justin Domke. MCMC Variational Inference via Uncorrected Hamiltonian   \n382 Annealing. In Advances in Neural Information Processing Systems, volume 34, pages 639\u2013651.   \n383 Curran Associates, Inc., 2021.   \n384 [15] Mark Girolami, Ben Calderhead, and Siu A Chin. Riemann Manifold Langevin and Hamiltonian   \n385 Monte Carlo.   \n386 [16] Will Grathwohl, Kuan-Chieh Wang, Joern-Henrik Jacobsen, David Duvenaud, Mohammad   \n387 Norouzi, and Kevin Swersky. Your classifier is secretly an energy based model and you should   \n388 treat it like one. In International Conference on Learning Representations, 2020.   \n389 [17] Ulf Grenander and Michael I. Miller. Representations of Knowledge in Complex Systems.   \n390 Journal of the Royal Statistical Society. Series B (Methodological), 56(4):549\u2013603, 1994.   \n391 [18] W. K. Hastings. Monte carlo sampling methods using markov chains and their applications.   \n392 Biometrika, 57(1):97\u2013109, 1970.   \n393 [19] Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep residual learning for image   \n394 recognition. In Proceedings of the IEEE conference on computer vision and pattern recognition,   \n395 pages 770\u2013778, 2016.   \n396 [20] Jonathan Ho, Ajay Jain, and Pieter Abbeel. Denoising diffusion probabilistic models. In   \n397 H. Larochelle, M. Ranzato, R. Hadsell, M.F. Balcan, and H. Lin, editors, Advances in Neural   \n398 Information Processing Systems, volume 33, pages 6840\u20136851. Curran Associates, Inc., 2020.   \n399 [21] Matthew D. Hoffman and Andrew Gelman. The No-U-Turn Sampler: Adaptively Setting Path   \n400 Lengths in Hamiltonian Monte Carlo, November 2011.   \n401 [22] Aapo Hyv\u00e4rinen. Estimation of non-normalized statistical models by score matching. Journal   \n402 of Machine Learning Research, 6(24):695\u2013709, 2005.   \n403 [23] Justin Johnson, Bharath Hariharan, Laurens van der Maaten, Li Fei-Fei, C. Lawrence Zitnick,   \n404 and Ross B. Girshick. Clevr: A diagnostic dataset for compositional language and elementary   \n405 visual reasoning. 2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR),   \n406 pages 1988\u20131997, 2016.   \n407 [24] S. Kirkpatrick, C. D. Gelatt, and M. P. Vecchi. Optimization by simulated annealing. Science   \n408 (New York, N.Y.), 220(4598):671\u2013680, 1983.   \n409 [25] Yann LeCun, Sumit Chopra, Raia Hadsell, Marc Aurelio Ranzato, and Fu Jie Huang. A tutorial   \n410 on energy-based learning. 2006.   \n411 [26] Qiang Liu, Jason Lee, and Michael Jordan. A kernelized stein discrepancy for goodness-of-fit   \n412 tests. In Maria Florina Balcan and Kilian Q. Weinberger, editors, Proceedings of The 33rd   \n413 International Conference on Machine Learning, volume 48 of Proceedings of Machine Learning   \n414 Research, pages 276\u2013284, New York, New York, USA, 20\u201322 Jun 2016. PMLR.   \n415 [27] Yi-An Ma, Tianqi Chen, and Emily Fox. A Complete Recipe for Stochastic Gradient MCMC.   \n416 In Advances in Neural Information Processing Systems, volume 28. Curran Associates, Inc.,   \n417 2015.   \n418 [28] Yi-An Ma, Yuansi Chen, Chi Jin, Nicolas Flammarion, and Michael I. Jordan. Sampling can be   \n419 faster than optimization. Proceedings of the National Academy of Sciences, 116(42):20881\u2013   \n420 20885, 2019.   \n421 [29] Radford M. Neal. MCMC Using Hamiltonian Dynamics. May 2011.   \n422 [30] G. Parisi. Correlation functions and computer simulations. Nuclear Physics B, 180(3):378\u2013384,   \n423 1981.   \n424 [31] B.T. Polyak. Some methods of speeding up the convergence of iteration methods. USSR   \n425 Computational Mathematics and Mathematical Physics, 4(5):1\u201317, 1964.   \n426 [32] Gareth O. Roberts and Richard L. Tweedie. Exponential convergence of Langevin distributions   \n427 and their discrete approximations. Bernoulli, 2(4):341 \u2013 363, 1996.   \n428 [33] Olaf Ronneberger, Philipp Fischer, and Thomas Brox. U-net: Convolutional networks for   \n429 biomedical image segmentation. In International Conference on Medical image computing and   \n430 computer-assisted intervention, pages 234\u2013241. Springer, 2015.   \n431 [34] Jascha Sohl-Dickstein, Mayur Mudigonda, and Michael DeWeese. Hamiltonian monte carlo   \n432 without detailed balance. In Eric P. Xing and Tony Jebara, editors, Proceedings of the 31st   \n433 International Conference on Machine Learning, volume 32 of Proceedings of Machine Learning   \n434 Research, pages 719\u2013726, Bejing, China, 22\u201324 Jun 2014. PMLR.   \n435 [35] Jascha Sohl-Dickstein, Eric Weiss, Niru Maheswaranathan, and Surya Ganguli. Deep unsu  \n436 pervised learning using nonequilibrium thermodynamics. In Francis Bach and David Blei,   \n437 editors, Proceedings of the 32nd International Conference on Machine Learning, volume 37 of   \n438 Proceedings of Machine Learning Research, pages 2256\u20132265, Lille, France, 07\u201309 Jul 2015.   \n439 PMLR.   \n440 [36] Yang Song and Stefano Ermon. Generative modeling by estimating gradients of the data   \n441 distribution. In H. Wallach, H. Larochelle, A. Beygelzimer, F. dAlch\u00e9-Buc, E. Fox, and   \n442 R. Garnett, editors, Advances in Neural Information Processing Systems, volume 32. Curran   \n443 Associates, Inc., 2019.   \n444 [37] Yang Song and Diederik P. Kingma. How to Train Your Energy-Based Models, February 2021.   \n445 [38] Yang Song, Jascha Sohl-Dickstein, Diederik P Kingma, Abhishek Kumar, Stefano Ermon, and   \n446 Ben Poole. Score-based generative modeling through stochastic differential equations. In   \n447 International Conference on Learning Representations, 2021.   \n448 [39] Robert Swendsen and Jian-Sheng Wang. Replica monte carlo simulation of spin-glasses.   \n449 Physical review letters, 57:2607\u20132609, 12 1986.   \n450 [40] Y. Teng, W. Gao, F. Chalus, A. Choromanska, D. Goldfarb, and A. Weller. Leader stochastic   \n451 gradient descent for distributed training of deep learning models. In NeurIPS, 2019.   \n452 [41] Yunfei Teng, Wenbo Gao, Francois Chalus, Anna Choromanska, Donald Goldfarb, and Adrian   \n453 Weller. Leader Stochastic Gradient Descent for Distributed Training of Deep Learning Models:   \n454 Extension, April 2022.   \n455 [42] Max Welling and Yee Whye Teh. Bayesian learning via stochastic gradient langevin dynamics.   \n456 In Proceedings of the 28th International Conference on International Conference on Machine   \n457 Learning, ICML\u201911, page 681\u2013688, Madison, WI, USA, 2011. Omnipress.   \n458 [43] Han Xiao, Kashif Rasul, and Roland Vollgraf. Fashion-mnist: a novel image dataset for   \n459 benchmarking machine learning algorithms, 2017.   \n460 [44] Qiwei Ye, Yuxuan Song, Chang Liu, Fangyun Wei, Tao Qin, and Tie-Yan Liu. Particle based   \n461 stochastic policy optimization. 2021.   \n462 [45] Sergey Zagoruyko and Nikos Komodakis. Wide residual networks. arXiv preprint   \n463 arXiv:1605.07146, 2016.   \n464 [46] S. Zhang, A. Choromanska, and Y. LeCun. Deep learning with elastic averaging SGD. In NIPS,   \n465 2015. ", "page_idx": 9}, {"type": "text", "text": "", "page_idx": 10}, {"type": "text", "text": "", "page_idx": 11}, {"type": "text", "text": "Follow Hamiltonian Leader: An Efficient Energy-Guided Sampling Method (Supplementary Material) ", "text_level": 1, "page_idx": 12}, {"type": "text", "text": "470 ", "page_idx": 12}, {"type": "text", "text": "471 A Additional Discussion for Section 3 ", "text_level": 1, "page_idx": 12}, {"type": "text", "text": "472 A.1 Instability & Metastability ", "text_level": 1, "page_idx": 12}, {"type": "text", "text": "473 We now approach this problem from an optimization perspective. There is a strong connection   \n474 between optimization and sampling, particularly through the principle of simulated annealing [24],   \n475 which demonstrates how sampling methods can be transformed into optimization techniques. ", "page_idx": 12}, {"type": "text", "text": "476 With a slight abuse of notation, we consider the following objective function: ", "page_idx": 12}, {"type": "equation", "text": "$$\nU(x)=x[1]^{2}+0.01\\cdot x[2]^{2},\n$$", "text_format": "latex", "page_idx": 12}, {"type": "text", "text": "477 where $x\\in\\mathbb{R}^{2}$ and $x[i]$ denotes the $i^{t h}$ dimension of $x$ . This is a 2-dimensional optimization problem   \n478 with a condition number of 100, indicating it is somewhat ill-conditioned. ", "page_idx": 12}, {"type": "text", "text": "479 For $n$ particles, the objective function is: ", "page_idx": 12}, {"type": "equation", "text": "$$\nU_{e}(x^{1},\\cdot\\cdot\\cdot,x^{n};x^{l})=\\sum_{i=1}^{n}U(x^{i})+\\frac{\\rho}{2}\\cdot\\|x^{i}-x^{l}\\|_{2}^{2},\n$$", "text_format": "latex", "page_idx": 12}, {"type": "text", "text": "480 where we set $\\rho=0.1$ . We initialize $x^{1}=(2,2)$ and $x^{2}=(-1,-3)$ respectively, and optimize the   \n481 objective function using the gradient descent method. Note that when $n=1$ , this method reduces to   \n482 vanilla gradient descent, while $n=2$ incorporates our leader-pulling scheme.   \n483 From Figure 11, we can see that incorporating the leader-pulling scheme helps improve convergence.   \n484 This demonstrates that the leader-pulling scheme can address the issue of instability in optimization.   \n485 However, we also observe that a carefully chosen leader is usually required for our method, which   \n486 we will leave for future discussion.   \n487 Furthermore, as shown in Figure 12, the particle using the leader-pulling scheme explores much   \n488 further compared to the vanilla heavy-ball method. This outcome is expected, as we want the method   \n489 to enhance exploration and thereby resolve the metastability issue. ", "page_idx": 12}, {"type": "image", "img_path": "34dHGTri2w/tmp/0a9d2fbbf3efde5ba79d0ebc31205267f2d18f29d3339e07b55d9fe7aa743c38.jpg", "img_caption": ["Figure 11: $U(x^{1})$ with gradient descent method [6]. The learning rate is set to 0.1. "], "img_footnote": [], "page_idx": 12}, {"type": "image", "img_path": "34dHGTri2w/tmp/5ef139d6a243d5f00c8cb9e363969f124944857868a07ecb1a87332057d943d1.jpg", "img_caption": ["Figure 12: $U(x^{1})$ with heavy-ball method [31]. The learning rate and momentum are set to 0.02 and 0.9 respectively. ", "Loss "], "img_footnote": [], "page_idx": 13}, {"type": "text", "text": "", "page_idx": 13}, {"type": "text", "text": "", "page_idx": 13}, {"type": "text", "text": "490 A.2 Pseudo Stability ", "text_level": 1, "page_idx": 13}, {"type": "text", "text": "491 These challenges are commonly encountered when sampling from compositional models, particularly   \n492 when one of the distributions is a piecewise-constant distribution with its gradients are zero almost   \n493 everywhere in its domain. To illustrate this, consider the example $\\pi(x)\\stackrel{.}{\\propto}\\pi_{1}(x)\\cdot\\pi_{2}(x)$ . Here we   \n494 consider $\\partial\\log\\pi_{2}$ equals to zero everywhere.   \n495 It\u2019s worth noting that while combining distributions in their logarithmic forms is straightforward,   \n496 which leads to $\\log\\pi(x)=\\log\\pi_{1}(x)\\,\\bar{+}\\,\\log\\pi_{2}(x)\\,+$ constant , omitting the constant $\\log\\pi(x)$ can   \n497 be readily derived from the individual $\\log\\pi_{1}(x)$ and $\\log\\pi_{2}(x)$ . However, the composition of their   \n498 gradients becomes problematic, as the computation of the sub-gradient $\\partial_{x}\\log\\pi(x)\\neq\\nabla_{x}\\log\\pi_{1}(x)+$   \n499 $\\bar{\\partial}_{x}\\log\\pi_{2}(x)$ in general due to the use of automatic differentiation in machine learning [4].   \n500 In this section, we focus on the disparity between gradient and energy in the context of combining   \n501 two distributions as indicated in Section 3.   \n502 We analyze a composite probability distribution structured as $\\pi(x)\\propto\\pi_{1}(x)\\cdot\\pi_{2}(x)$ , leading to the   \n503 construction of two specific distributions: ", "page_idx": 13}, {"type": "text", "text": "", "page_idx": 13}, {"type": "text", "text": "", "page_idx": 13}, {"type": "text", "text": "", "page_idx": 13}, {"type": "text", "text": "\u2022 The first distribution, $\\pi_{1}(x)$ , is given by: ", "page_idx": 13}, {"type": "equation", "text": "$$\n\\pi_{1}(x)={\\frac{1}{|X|}}\\sum_{\\mu\\in X}{\\mathcal{N}}(\\mu,\\sigma^{2}I),\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "505   \n506 ", "page_idx": 13}, {"type": "text", "text": "where $|X|$ represents the cardinality of the set $X$ , indicating the total number of elements in $X$ . ", "page_idx": 13}, {"type": "text", "text": "508 ", "page_idx": 13}, {"type": "text", "text": "\u2022 The second distribution $\\pi_{2}(x)$ , is defined as ", "page_idx": 13}, {"type": "equation", "text": "$$\n\\pi_{2}(x)=\\frac{\\mathbb{1}_{x\\in\\Omega_{Y}}}{\\mathrm{Vol}(\\Omega_{Y})},\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "509   \n510   \n511   \n512 ", "page_idx": 13}, {"type": "text", "text": "with $\\Omega_{Y}$ being the set where $\\Omega_{Y}=\\{x|\\,d(x,Y)<\\epsilon\\}$ . In this context, the distance metric $d$ is specified by $d(x,Y)=\\arg\\operatorname*{min}_{y\\in Y}\\left\\|x-y\\right\\|_{2}$ , indicating the minimum Euclidean distance from $x$ to any point in the set $Y$ . ", "page_idx": 13}, {"type": "text", "text": "513 Observe that $\\pi_{1}$ constitutes a smooth distribution, whereas $\\pi_{2}$ is a piecewise-constant distribution.   \n514 Consequently, for $\\pi_{2}$ , the gradients are zero almost everywhere. When we consider the expression   \n515 $\\nabla_{x}\\log\\pi_{1}(x)+\\partial_{x}\\log\\pi_{2}(x)$ , it could be simplified to $\\nabla_{x}\\log\\pi_{1}(x)$ , which is not equivalent to   \n516 $\\partial_{x}\\log\\pi(x)$ in general.   \n517 In the subsequent subsections, we present two motivating examples: one in a low-dimensional setting   \n518 and the other in a high-dimensional context. Throughout these experiments, we set $\\sigma^{2}=0.002$ and   \n519 $\\epsilon=0.2$ . In this section, the outcomes of U-LMC and U-HMC are omitted because both techniques   \n520 succumb to the issue of misleading gradients by nature, causing worse performance. ", "page_idx": 13}, {"type": "text", "text": "", "page_idx": 14}, {"type": "text", "text": "521 A.2.1 Low-dimensional Example ", "text_level": 1, "page_idx": 14}, {"type": "text", "text": "We propose an example inspired from [12] but in a different setting. In this revision, we begin by providing a more specific definition for two distributions. For the first distribution $\\pi_{1}$ , we define: ", "page_idx": 14}, {"type": "equation", "text": "$$\nX=\\{\\left(\\cos\\left(2\\pi i/8\\right),\\;\\sin\\left(2\\pi i/8\\right)\\right)|\\;i=1,2,\\ldots,8\\},\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "and for the second distribution $\\pi_{2}$ , we specify: ", "page_idx": 14}, {"type": "equation", "text": "$$\nY=\\{\\left(\\cos\\left(2\\pi i/8\\right),\\;\\sin\\left(2\\pi i/8\\right)\\right)|\\;i=2,4,6,8\\}.\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "522 It\u2019s important to note that, by definition, $Y$ is a subset of $X$ . ", "page_idx": 14}, {"type": "image", "img_path": "34dHGTri2w/tmp/99db2b83bdeb250cb6efb8635ff3c1417e85f073eaa4cbc2691e4b40642ce462.jpg", "img_caption": ["Figure 13: Plot of $N=512$ particles of $X_{T}$ for a 4-mode compositional Gaussian mixture model $\\pi\\propto\\pi_{1}\\cdot\\pi_{2}$ on $d=2$ . We sample by gradient $\\nabla\\log\\pi_{1}$ and energy $\\pi_{1}\\cdot\\pi_{2}$ . The baseline methods LMC, HMC and our proposed method FHL generate $X_{T}$ after $T\\,=\\,4000$ steps, using the initial particles $X_{0}=\\{x_{0}^{i}\\}$ with $\\boldsymbol{x}_{0}^{i}$ sampled from a common distribution. "], "img_footnote": [], "page_idx": 14}, {"type": "text", "text": "523 We perform a comparative study of our methods against established benchmarks, and the visual   \n524 representations of this comparison can be found in Figure 13. Notably, among the compared methods,   \n525 FTH distinguishes itself due to its outstanding performance, mainly attributed to its precise adjustment   \n526 of particle positions. The comparative results highlight that the baseline methods often exhibit the   \n527 tendency to erroneously converge towards incorrect modes due to the misleading gradients. Although   \n528 rejection steps of HMC and LMC might mitigate incorrect sampling, particles initialized near   \n529 high-energy modes struggle to escape this erroneous attraction by misleading gradients. ", "page_idx": 14}, {"type": "text", "text": "530 A.2.2 High-dimensional Example ", "text_level": 1, "page_idx": 14}, {"type": "text", "text": "531 We then present a case study in which we generate examples from a particular category within the   \n532 Fashion MNIST dataset [43]. In this experiment, we select a total of 200 images, with 100 images   \n533 from the coat category and another 100 from trouser category. We denote the sets of data points from   \n534 the coat and trouser categories as $X_{\\mathrm{coat}}$ and $X_{\\mathrm{trouser}}$ respectively. Furthermore, we define $X$ as the   \n535 union of $X_{\\mathrm{coat}}$ and $X_{\\mathrm{trouser}}$ , and $Y$ is set to $X_{\\mathrm{coat}}$ in this case.   \n536 To increase the difficulty of the sampling task, we initially position each particle at the mean location   \n537 of $X_{\\mathrm{trouser}}$ . The outcomes of the sampling are depicted in Figure 15.This setup showcases the FHL   \n538 method\u2019s ability to accurately target and sample from the specified coat category, in contrast to   \n539 baseline methods that undesirably draw samples from the trouser category. ", "page_idx": 14}, {"type": "text", "text": "", "page_idx": 15}, {"type": "image", "img_path": "34dHGTri2w/tmp/a25fda8276e2edbbd2c0d7064dfc79fee17b323e5cf8ca38a7ba365bfd67168f.jpg", "img_caption": ["Figure 14: Sample from a 100-mode compositional Gaussian mixture model $\\pi\\propto\\pi_{1}\\cdot\\pi_{2}$ on $d=784$ , where each mode corresponds to a clean image from coat category. We sample by gradient $\\nabla\\log\\pi_{1}$ and energy $\\pi_{1}\\cdot\\pi_{2}$ . For each method, we plot the smallest-energy particle (in terms of $U(x)$ among all particles in $X_{T}$ ). The correct samples are displayed in the upper-left corner. "], "img_footnote": [], "page_idx": 15}, {"type": "text", "text": "", "page_idx": 15}, {"type": "text", "text": "540 B Supplementary Experiment ", "text_level": 1, "page_idx": 15}, {"type": "text", "text": "541 B.1 Experiment Setup ", "text_level": 1, "page_idx": 15}, {"type": "text", "text": "542 In Section 5.2, we utilize a pre-trained classifier available on the public GitHub repository at   \n543 https://github.com/wgrathwohl/JEM. This classifier is a WideResNet model [45] with a depth   \n544 of 28 and a width of 2.   \n545 We use a technique called one-step HMC [5] and thus the momentum gets refreshed for each step.   \n546 More specifically, for both FTH and HMC we set the momentum damping factor to 0.9 and the mass   \n547 matrix as $0.004^{2}\\cdot I$ . We take step size as $\\eta=0.2$ . Since the mass matrix is set to a relatively small   \n548 value which easily causes the instability of training, we always accept the proposed states based on   \n549 the potential energy and ignore the kinetic energy.   \n550 In Section 5.3, we mainly adapted the codes and models from https://github.com/yilundu/   \n551 reduce_reuse_recycle.   \n552 For Section 5.3.1, we initially train a 4-layer ResNet as the energy-based score-matching model on $p_{1}$   \n553 and $p_{2}$ independently. During the sampling process, we combine these models. We employ step sizes   \n554 $\\eta=\\{0.002,0.0002,0.005,0.0005\\}$ for all methods and the number of leapfrog steps $L=\\{4,8\\}$ for   \n555 HMC-type methods.   \n556 For Section 5.3.2, we utilize a U-net architecture [33] as the energy-based score-matching model.   \n557 This architecture is directly obtained from a pre-trained model available at . For sampling, we use step   \n558 sizes $\\eta=\\{0.01,0.035,0.05,0.1,0.2\\}$ for all methods and set the number of leapfrog steps $L=4$   \n559 for HMC-type methods. ", "page_idx": 15}, {"type": "text", "text": "", "page_idx": 15}, {"type": "text", "text": "", "page_idx": 15}, {"type": "text", "text": "", "page_idx": 15}, {"type": "text", "text": "", "page_idx": 15}, {"type": "text", "text": "561 B.2.1 Additional Images for Section 5.2 ", "page_idx": 16}, {"type": "image", "img_path": "34dHGTri2w/tmp/b5a82e6a94ddefa92ac9616d9f3db8a844272804264c61e6521497517f6a461d.jpg", "img_caption": [], "img_footnote": [], "page_idx": 16}, {"type": "text", "text": "Figure 15: Sample from joint energy model by different classes (Left: HMC; Right: FTH). ", "page_idx": 16}, {"type": "text", "text": "562 B.2.2 Additional Images for Section 5.3.2 ", "page_idx": 16}, {"type": "image", "img_path": "34dHGTri2w/tmp/0c1b713dcf1c96d119ab753903b0975284983cb755ad229b87fd9bb889172d5a.jpg", "img_caption": ["Figure 16: Generation of cylinder. "], "img_footnote": [], "page_idx": 16}, {"type": "image", "img_path": "34dHGTri2w/tmp/ead46a998d1a4751fafbfbc1f1c81041ccf1a2d9bec1b3ed0b6f348f78dd66a9.jpg", "img_caption": ["Figure 17: Generation of cube and cylinder. "], "img_footnote": [], "page_idx": 16}, {"type": "image", "img_path": "34dHGTri2w/tmp/d2c233b50a7307149ab3fc5ce8a836608d56ada61093e7d66f2e46c2604c0bbe.jpg", "img_caption": ["Figure 18: Generation of cube and sphere. "], "img_footnote": [], "page_idx": 16}, {"type": "image", "img_path": "34dHGTri2w/tmp/a7c1d239d69c3fecd85bd6b7dc9430ccca9ba5014d0ec117e7b4dd57c18f4aa4.jpg", "img_caption": [], "img_footnote": [], "page_idx": 17}, {"type": "image", "img_path": "", "img_caption": ["Figure 20: Generation of sphere and cylinder. "], "img_footnote": [], "page_idx": 17}, {"type": "text", "text": "564 C Supplementary Theorem ", "text_level": 1, "page_idx": 17}, {"type": "text", "text": "565 We now consider a scenario where the leader becomes corrupted, meaning the corrupted leader always   \n566 reports an unreasonably low energy but it is not actually in the lowest-energy position. In this situation,   \n567 the particles are optimizing a biased objective function. For simplicity, we consider a $d$ -dimensional   \n568 Gaussian distribution $p\\sim\\bar{e}^{-U(x)}$ and its modification $q\\sim e^{-\\psi(\\bar{x})}$ with $\\begin{array}{r}{\\psi(x)=U(x)+\\frac{\\lambda}{2}\\|x-z\\|^{2}}\\end{array}$ .   \n569 We will analyze the Wasserstein distance between $p$ and $q$ for a fixed $z\\in\\mathbb{R}^{d}$ as a function of $\\lambda>0$ .   \n570 We will demonstrate that even though we sample from the distribution $q$ instead of $p$ , the bias of the   \n571 sampler (i.e., the distance between $p$ and $q$ ) can be controlled by $\\lambda$ and vanishes as $\\lambda\\to0$ .   \n572 Assumption 1. $U:\\mathbb{R}^{d}\\rightarrow\\mathbb{R}$ is $M$ -Lipschitz-differentiable, i.e. $\\forall x,y\\in\\mathbb{R}^{d}$ , ", "page_idx": 17}, {"type": "equation", "text": "$$\nU(y)\\leq U(x)+\\nabla U(x)^{T}(y-x)+\\frac{M}{2}\\|y-x\\|^{2},\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "573 and $U$ is $m$ -Strongly-convex, i.e. $\\forall x,y\\in\\mathbb{R}^{d}$ , ", "page_idx": 17}, {"type": "equation", "text": "$$\nU(y)\\geq U(x)+\\nabla U(x)^{T}(y-x)+\\frac{m}{2}\\|y-x\\|^{2}.\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "Theorem 1. Let $U$ be the negative logarithmic probability density function of a $d$ -dimensional Gaussian distribution, which satisfies Assumption 1. Let us define the function $\\psi(x)$ as $\\psi(x)\\,=$ $\\begin{array}{r}{U(x)+\\frac{\\lambda}{2}\\|x-z\\|^{2}}\\end{array}$ . Given this setup, the Wasserstein-2 distance between the modified Boltzmann distribution $q$ , characterized by $q\\sim e^{-\\psi(x)}$ , and the original Gaussian distribution $p$ , denoted as $p\\sim e^{-U(x)}$ , can be bounded as: ", "page_idx": 17}, {"type": "equation", "text": "$$\nW_{2}(p,q)^{2}\\leq\\frac{\\lambda^{2}\\|\\Sigma\\|}{I+\\lambda\\|\\Sigma\\|}\\|z-x^{*}\\|^{2}+d\\|\\Sigma\\|\\cdot\\left(1-\\frac{1}{\\sqrt{\\lambda\\|\\Sigma\\|+1}}\\right)^{2}\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "574 where $\\|\\cdot\\|$ represents the matrix norm. Obviously, $W_{2}(p,q)\\to0$ when $\\lambda\\to0$ . ", "page_idx": 17}, {"type": "text", "text": "575 Proof. By definition, $U$ is $m$ -strongly convex since ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\begin{array}{l}{{U(x)=-\\log\\left[(2\\pi)^{-k/2}\\operatorname*{det}(\\Sigma)^{-1/2}\\exp\\left(-\\frac{1}{2}(x-x^{*})^{T}\\Sigma^{-1}(x-x^{*})\\right)\\right]}}\\\\ {{\\mathrm{}\\ ~~~~~=\\frac{k}{2}\\log(2\\pi)+\\frac{1}{2}\\log\\operatorname*{det}(\\Sigma)+\\frac{1}{2}(x-x^{*})^{T}\\Sigma^{-1}(x-x^{*}).}}\\end{array}\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "576 The $m$ corresponds to the smallest eigenvalue of $\\Sigma^{-1}$ which is therefore $1/||\\Sigma||$ . Then ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\slash(x)=\\frac{k}{2}\\log(2\\pi)+\\frac{1}{2}\\log\\operatorname*{det}(\\Sigma)+\\frac{1}{2}(x-x^{*})^{T}\\Sigma^{-1}(x-x^{*})+\\frac{\\lambda}{2}(x-z)^{T}(x-z)}\\\\ &{\\qquad=\\frac{1}{2}\\left[x^{T}(\\Sigma^{-1}+\\lambda I)x-2x^{T}(\\Sigma^{-1}x^{*}+\\lambda z)\\right]+\\mathrm{constant}}\\\\ &{\\qquad=\\frac{1}{2}\\left[(x-(\\Sigma^{-1}+\\lambda I)^{-1}(\\Sigma^{-1}x^{*}+\\lambda z))^{T}(\\Sigma^{-1}+\\lambda I)(x-(\\Sigma^{-1}+\\lambda I)^{-1}(\\Sigma^{-1}x^{*}+\\lambda z))\\right]+}\\end{array}\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "577 The last equation was done by completing the square. Thus the new distribution is still a Gaussian   \n578 distribution, represented as ", "page_idx": 18}, {"type": "equation", "text": "$$\nq\\sim\\mathcal{N}\\left((\\Sigma^{-1}+\\lambda I)^{-1}(\\Sigma^{-1}x^{*}+\\lambda z)\\right),(\\Sigma^{-1}+\\lambda I)^{-1}\\right).\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "579 Consequently, the Wasserstein-2 distance can be determined as follows: ", "page_idx": 18}, {"type": "equation", "text": "$$\nW_{2}(p,q)^{2}=\\|\\mu_{p}-\\mu_{q}\\|^{2}+\\mathrm{Tr}\\left(\\Sigma_{p}+\\Sigma_{q}-2(\\Sigma_{p}^{1/2}\\Sigma_{q}\\Sigma_{p}^{1/2})^{1/2}\\right)\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "In our case $\\mu_{p}=x^{*},\\mu_{q}=(\\Sigma^{-1}+\\lambda I)^{-1}(\\Sigma^{-1}x^{*}+\\lambda z),\\Sigma_{q}=\\Sigma,\\Sigma_{p}=(\\Sigma^{-1}+\\lambda I)^{-1}.$ Since $\\Sigma_{q}$ and $\\Sigma_{p}$ can be jointly diagonalized by some orthonormal basis $T$ , ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\Sigma_{q}\\Sigma_{p}=T D_{q}T^{-1}T D_{p}T^{-1}=T D_{p}D_{q}T^{-1}=T D_{p}T^{-1}T D_{q}T^{-1}=\\Sigma_{p}\\Sigma_{q},\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "thus $\\Sigma_{q}$ and $\\Sigma_{p}$ commute. We can simplify the Wasserstein distance to ", "page_idx": 18}, {"type": "equation", "text": "$$\nW_{2}(p,q)^{2}=\\|\\mu_{p}-\\mu_{q}\\|^{2}+\\|\\Sigma_{p}^{1/2}-\\Sigma_{q}^{1/2}\\|_{F}^{2}.\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "Then ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\begin{array}{r}{W_{2}(p,q)^{2}=\\|(\\Sigma^{-1}+\\lambda I)^{-1}(\\Sigma^{-1}x^{*}+\\lambda z)-x^{*}\\|^{2}+\\|\\Sigma^{1/2}-(\\Sigma^{-1}+\\lambda I)^{-1/2}\\|_{F}^{2}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "Now we bound the first and second term independently. The first term is a direct conclusion from Theorem 15 in [41], ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\|(\\Sigma^{-1}+\\lambda I)^{-1}(\\Sigma^{-1}x^{*}+\\lambda z)-x^{*}\\|^{2}\\leq\\frac{\\lambda^{2}}{m(m+\\lambda)}\\|z-x^{*}\\|^{2},\\quad\\mathrm{where~}m=\\|\\Sigma^{-1}\\|,\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "580 For the second term. We denote $i^{t h}$ eigenvalue of matrix $\\Sigma$ as $\\sigma_{i}$ , then $\\|\\Sigma\\|=\\operatorname*{max}_{i}\\sigma^{i}$ , such that ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\|\\Sigma^{1/2}-(\\Sigma^{-1}+\\lambda I)^{-1/2}\\|_{F}^{2}=\\displaystyle\\sum_{i\\leq d}[\\sigma_{i}^{1/2}-(\\sigma_{i}^{-1}+\\lambda)^{-1/2}]^{2}}&{}\\\\ {=\\displaystyle\\sum_{i\\leq d}[\\sqrt{\\sigma_{i}}\\cdot(1-\\frac{1}{\\sqrt{\\lambda\\sigma_{i}+1}})]^{2}}&{}\\\\ {\\leq d\\|\\Sigma\\|\\cdot\\left(1-\\frac{1}{\\sqrt{\\lambda\\|\\Sigma\\|+1}}\\right)^{2}}&{}\\end{array}\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "Thus, by combing the two terms together, the total Wassertein distance is bounded by ", "page_idx": 18}, {"type": "equation", "text": "$$\nW_{2}(p,q)^{2}\\leq\\frac{\\lambda^{2}}{m(m+\\lambda)}\\|z-x^{*}\\|^{2}+d M\\cdot\\left(1-\\frac{1}{\\sqrt{\\lambda M+1}}\\right)^{2}\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "582 NeurIPS Paper Checklist ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "583 1. Claims   \n584 Question: Do the main claims made in the abstract and introduction accurately reflect the   \n585 paper\u2019s contributions and scope?   \n586 Answer: [Yes]   \n587 Justification: We clearly indicate the purpose and contribution of our paper.   \n588 2. Limitations   \n589 Question: Does the paper discuss the limitations of the work performed by the authors?   \n590 Answer: [No]   \n591 Justification: Our work builds upon previous research, serving as a complementary addition   \n592 to it. However, we shall add further discussion in the future.   \n593 3. Theory Assumptions and Proofs   \n594 Question: For each theoretical result, does the paper provide the full set of assumptions and   \n595 a complete (and correct) proof?   \n596 Answer: [Yes]   \n597 Justification: We do provide assumption and proof for our theorem.   \n598 4. Experimental Result Reproducibility   \n599 Question: Does the paper fully disclose all the information needed to reproduce the main ex  \n600 perimental results of the paper to the extent that it affects the main claims and/or conclusions   \n601 of the paper (regardless of whether the code and data are provided or not)?   \n602 Answer: [Yes]   \n603 Justification: We show the details of how to reproduce the results and provide the codes for   \n604 reproduction.   \n605 5. Open access to data and code   \n606 Question: Does the paper provide open access to the data and code, with sufficient instruc  \n607 tions to faithfully reproduce the main experimental results, as described in supplemental   \n608 material?   \n609 Answer: [Yes]   \n610 Justification: We will do it once the paper gets accepted.   \n611 6. Experimental Setting/Details   \n612 Question: Does the paper specify all the training and test details (e.g., data splits, hyper  \n613 parameters, how they were chosen, type of optimizer, etc.) necessary to understand the   \n614 results?   \n615 Answer: [Yes]   \n616 Justification: Yes we do.   \n617 7. Experiment Statistical Significance   \n618 Question: Does the paper report error bars suitably and correctly defined or other appropriate   \n619 information about the statistical significance of the experiments?   \n620 Answer: [No]   \n621 Justification: Due to time constraints, we were unable to include that. However, we plan to   \n622 add such statistics in the future.   \n623 8. Experiments Compute Resources   \n624 Question: For each experiment, does the paper provide sufficient information on the com  \n625 puter resources (type of compute workers, memory, time of execution) needed to reproduce   \n626 the experiments?   \n627 Answer: [No]   \n628 Justification: We primarily focus on proposing a new algorithm, and most of our experiments   \n629 require only a moderate amount of resources.   \n630 9. Code Of Ethics   \n631 Question: Does the research conducted in the paper conform, in every respect, with the   \n632 NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines?   \n633 Answer: [Yes]   \n634 Justification: Yes we do.   \n635 10. Broader Impacts   \n636 Question: Does the paper discuss both potential positive societal impacts and negative   \n637 societal impacts of the work performed?   \n638 Answer: [NA]   \n639 Justification: There is no social impact of our work.   \n640 11. Safeguards   \n641 Question: Does the paper describe safeguards that have been put in place for responsible   \n642 release of data or models that have a high risk for misuse (e.g., pretrained language models,   \n643 image generators, or scraped datasets)?   \n644 Answer: [NA]   \n645 Justification: There is no such a risk.   \n646 12. Licenses for existing assets   \n647 Question: Are the creators or original owners of assets (e.g., code, data, models), used in   \n648 the paper, properly credited and are the license and terms of use explicitly mentioned and   \n649 properly respected?   \n650 Answer: [NA]   \n651 Justification: No we don\u2019t have such a problem.   \n652 13. New Assets   \n653 Question: Are new assets introduced in the paper well documented and is the documentation   \n654 provided alongside the assets?   \n655 Answer: [NA]   \n656 Justification: No we don\u2019t have such a problem.   \n657 14. Crowdsourcing and Research with Human Subjects   \n658 Question: For crowdsourcing experiments and research with human subjects, does the paper   \n659 include the full text of instructions given to participants and screenshots, if applicable, as   \n660 well as details about compensation (if any)?   \n661 Answer: [NA]   \n662 Justification: No we don\u2019t have such a problem.   \n663 15. Institutional Review Board (IRB) Approvals or Equivalent for Research with Human   \n664 Subjects   \n665 Question: Does the paper describe potential risks incurred by study participants, whether   \n666 such risks were disclosed to the subjects, and whether Institutional Review Board (IRB)   \n667 approvals (or an equivalent approval/review based on the requirements of your country or   \n668 institution) were obtained?   \n669 Answer: [NA]   \n670 Justification: No we don\u2019t have such a problem. ", "page_idx": 19}, {"type": "text", "text": "", "page_idx": 20}]