[{"figure_path": "NG16csOmcA/figures/figures_1_1.jpg", "caption": "Figure 1: Neural Residual-style Diffusion Models framework with massively scalable gating-based minimum residual stacking unit (mrs-unit).", "description": "This figure shows the framework of Neural Residual Diffusion Models (Neural-RDM). It consists of two parts: (a) mrs-unit block and (b) Neural Residual Denoising Models. The mrs-unit block is a minimum residual stacking unit that uses a learnable gating residual mechanism to modulate the non-trivial transformation of the input signal.  The Neural Residual Denoising Models framework combines multiple mrs-unit blocks to build a deep generative model.  The framework aims to unify mainstream residual-style generative architectures and guide the emergence of brand new scalable network architectures.", "section": "2 Neural Residual Diffusion Models"}, {"figure_path": "NG16csOmcA/figures/figures_2_1.jpg", "caption": "Figure 2: Overview. (a) Flow-shaped residual stacking networks. (b) U-shaped residual stacking networks. (c) Our proposed unified and massively scalable residual stacking architecture (i.e., Neural-RDM) with learnable gating-residual mechanism. (d) Residual denoising process via Neural-RDM.", "description": "This figure illustrates the three different residual stacking network architectures. (a) shows the flow-shaped residual stacking, which is a linear chain of residual units, where each unit takes the output of the previous unit as input. (b) shows the U-shaped residual stacking, which is a more complex architecture that uses skip connections to connect the earlier layers to the later layers. (c) shows the proposed Neural-RDM architecture, which combines the features of both flow-shaped and U-shaped residual stacking to achieve a more unified and massively scalable architecture. (d) shows how Neural-RDM processes the residual denoising.", "section": "2 Neural Residual Diffusion Models"}, {"figure_path": "NG16csOmcA/figures/figures_3_1.jpg", "caption": "Figure 3: Compared with the latest baseline (SDXL-1.0 [7]), the samples produced by Neural-RDM (trained on JourneyDB [53]) exhibit exceptional quality, particularly in terms of fidelity and consistency in the details of the subjects in adhering to the provided textual prompts.", "description": "This figure compares image generation results between the state-of-the-art model SDXL-1.0 and the proposed Neural-RDM.  Neural-RDM shows improved fidelity and consistency in generated images, especially in terms of detail and adherence to text prompts.  Six examples of image generation are shown for both models, demonstrating Neural-RDM's superiority.", "section": "3 Experiments"}, {"figure_path": "NG16csOmcA/figures/figures_5_1.jpg", "caption": "Figure 4: Compared with the latest baseline (Latte-XL [60]), the sample videos from SkyTime-lapse [62], Taichi-HD[63] and UCF101 [64] all exhibit better frame quality, temporal consistency and coherence.", "description": "This figure compares video generation results from the proposed Neural-RDM model against the Latte-XL baseline model on three different datasets: SkyTimelapse, Taichi-HD, and UCF101.  Each row shows a sequence of frames generated from a single video. The comparison highlights the superior frame quality, temporal consistency (smooth transitions between frames), and coherence (meaningful progression of events) achieved by the Neural-RDM model.", "section": "3.3 Experiments on Video Generation with Deep Scalable Temporal Learning"}, {"figure_path": "NG16csOmcA/figures/figures_7_1.jpg", "caption": "Figure 6: (a), (b), and (c) respectively illustrate the performance of the five residual structures variant models across the SkyTimelapsee [62], Taichi-HD[63], and UCF-101 [64].", "description": "This figure displays the training curves for five different variants of residual structures in the Neural-RDM model.  The performance is measured by FVD score (Fr\u00e9chet Video Distance) across three different video datasets: SkyTimelapse, Taichi-HD, and UCF-101.  Each curve represents a variant, showing how the FVD score changes over training iterations (10k-100k).  The shaded regions around each line likely indicate confidence intervals, showing the variability in results for each variant.", "section": "3.5 Comparison Experiments of Gating Residual Variants and Deep Scalability"}, {"figure_path": "NG16csOmcA/figures/figures_7_2.jpg", "caption": "Figure 6: (a), (b), and (c) respectively illustrate the performance of the five residual structures variant models across the SkyTimelapsee [62], Taichi-HD[63], and UCF-101 [64].", "description": "This figure shows the performance comparison of five different residual structure variants of the proposed Neural-RDM model on three video datasets: SkyTimelapse, Taichi-HD, and UCF-101.  Each subfigure (a, b, c) represents a different dataset.  The x-axis represents the number of training iterations, the y-axis represents the FVD score, and the z-axis represents the depth of the residual network.  Different colored lines depict the performance of different residual structure variants. The figure aims to demonstrate the impact of different residual structures on training stability and final model performance across different video datasets.", "section": "3.3 Experiments on Video Generation with Deep Scalable Temporal Learning"}, {"figure_path": "NG16csOmcA/figures/figures_8_1.jpg", "caption": "Figure 7: The performance of Neural-RDM with different network depths on the UCF-101 dataset [64].", "description": "This figure shows the performance of Neural-RDM models with varying depths (number of residual units) on the UCF-101 video dataset.  The x-axis represents the number of training iterations, and the y-axis represents the Fr\u00e9chet Video Distance (FVD) score, a metric used to evaluate the quality of generated videos.  Lower FVD scores indicate better video generation quality. The different colored lines represent Neural-RDM models trained with different depths. The shaded areas represent confidence intervals. The results demonstrate the effect of network depth on the model's performance in terms of video generation quality.", "section": "3.5 Comparison Experiments of Gating Residual Variants and Deep Scalability"}, {"figure_path": "NG16csOmcA/figures/figures_18_1.jpg", "caption": "Figure 2: Overview. (a) Flow-shaped residual stacking networks. (b) U-shaped residual stacking networks. (c) Our proposed unified and massively scalable residual stacking architecture (i.e., Neural-RDM) with learnable gating-residual mechanism. (d) Residual denoising process via Neural-RDM.", "description": "This figure illustrates three different residual stacking network architectures: flow-shaped, U-shaped, and the proposed Neural-RDM.  It highlights the key difference of Neural-RDM which introduces a learnable gating-residual mechanism.  The figure also shows the process of residual denoising using Neural-RDM.", "section": "2 Neural Residual Diffusion Models"}]