{"references": [{"fullname_first_author": "Manuel L\u00f3pez Antequera", "paper_title": "Mapillary planet-scale depth dataset", "publication_date": "2020-XX-XX", "reason": "This paper is cited as a large-scale depth dataset used for training and evaluation of depth estimation models."}, {"fullname_first_author": "Jimmy Ba", "paper_title": "Do deep nets really need to be deep?", "publication_date": "2014-XX-XX", "reason": "This paper challenges the conventional wisdom regarding deep neural networks and discusses the potential of less deep architectures, relevant to efficient depth estimation model design."}, {"fullname_first_author": "Shariq Farooq Bhat", "paper_title": "Zoedepth: Zero-shot transfer by combining relative and metric depth", "publication_date": "2023-XX-XX", "reason": "This paper presents Zoedepth, a zero-shot depth estimation model that achieves strong performance on multiple datasets, and its techniques are relevant to the zero-shot capabilities of the proposed method."}, {"fullname_first_author": "Reiner Birkl", "paper_title": "MiDaS v3.1 - a model zoo for robust monocular relative depth estimation", "publication_date": "2023-XX-XX", "reason": "This paper introduces MiDaS v3.1, a state-of-the-art depth estimation model used for comparison; it's crucial to the benchmark and context of the research."}, {"fullname_first_author": "Xingyu Fu", "paper_title": "Blink: Multimodal large language models can see but not perceive", "publication_date": "2024-XX-XX", "reason": "This paper discusses the limitations of current multimodal large language models' perception capabilities, which is relevant to the challenges faced by depth estimation models in complex scenes."}]}