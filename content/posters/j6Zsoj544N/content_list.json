[{"type": "text", "text": "Does Worst-Performing Agent Lead the Pack? Analyzing Agent Dynamics in Unified Distributed SGD ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Jie Hu Yi-Ting Ma Do Young Eun Department of Electrical and Computer Engineering North Carolina State University {jhu29, yma42, dyeun}@ncsu.edu ", "page_idx": 0}, {"type": "text", "text": "Abstract ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Distributed learning is essential to train machine learning algorithms across heterogeneous agents while maintaining data privacy. We conduct an asymptotic analysis of Unified Distributed SGD (UD-SGD), exploring a variety of communication patterns, including decentralized SGD and local SGD within Federated Learning (FL), as well as the increasing communication interval in the FL setting. In this study, we assess how different sampling strategies, such as i.i.d. sampling, shuffling, and Markovian sampling, affect the convergence speed of UD-SGD by considering the impact of agent dynamics on the limiting covariance matrix as described in the Central Limit Theorem (CLT). Our findings not only support existing theories on linear speedup and asymptotic network independence, but also theoretically and empirically show how efficient sampling strategies employed by individual agents contribute to overall convergence in UD-SGD. Simulations reveal that a few agents using highly efficient sampling can achieve or surpass the performance of the majority employing moderately improved strategies, providing new insights beyond traditional analyses focusing on the worst-performing agent. ", "page_idx": 0}, {"type": "text", "text": "1 Introduction ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Distributed learning deals with the training of models across multiple agents over a communication network in a distributed manner, while addressing the challenges of privacy, scalability, and highdimensional data [11, 55]. Each agent $i\\,\\in\\,[N]$ holds a private dataset $\\mathcal{X}_{i}$ and an agent-specified loss function $F_{i}:\\mathbb{R}^{d}\\times\\mathcal{X}_{i}\\rightarrow\\mathbb{R}$ that depends on the model parameter $\\theta\\in\\mathbb{R}^{d}$ and a data point $X\\in\\mathcal{X}_{i}$ . The goal is then to find a local minima $\\theta^{*}$ of the objective function $\\begin{array}{r}{f(\\theta)\\triangleq\\frac{1}{N}\\sum_{i=1}^{N}\\bar{f}_{i}(\\theta)}\\end{array}$ where agent $i$ \u2019s loss function $f_{i}(\\theta)\\triangleq\\mathbb{E}_{X\\sim\\mathcal{D}_{i}}[F_{i}(\\theta,X)]$ and $\\mathcal{D}_{i}$ represents the target distribution of data for agent $i$ .1 Each agent $i$ can locally compute the gradient $\\nabla F_{i}(\\theta,X)\\in\\mathbb{R}^{d}$ w.r.t. $\\theta$ for every sampled data point $X\\in\\mathcal{X}_{i}$ . Due to the distributed nature, $\\{{\\mathcal{D}}_{i}\\}_{i\\in[N]}$ and $\\{\\mathcal{X}_{i}\\}_{i\\in[N]}$ are not necessarily identically distributed over $[N]$ so that the minima of each local function $f_{i}(\\theta)$ can be far away from $\\mathcal{L}$ . This is particularly relevant in decentralized training data, e.g., Federated Learning (FL) with heterogeneous data across data centers or devices [81, 31]. ", "page_idx": 0}, {"type": "text", "text": "In this paper, we focus on Unified Distributed SGD (UD-SGD), where each agent $i\\in[N]$ updates its model parameter $\\theta_{n+1}^{i}$ in a two-step process: ", "page_idx": 0}, {"type": "text", "text": "where $\\gamma_{n}$ denotes the step size, $X_{n}^{i}$ is the data sampled by agent $i$ at time $n$ (i.e., agent dynamics), and $\\mathbf{W}_{n}\\!=\\![w_{n}(i,j)]_{i,j\\in[N]}$ represents the doubly-stochastic communication matrix satisfying $w_{n}(i,j)\\ge$ 0 and $\\mathbf{1}^{T}\\mathbf{W}_{n}\\!=\\!\\mathbf{1}^{T}$ , ${\\bf W}_{n}{\\bf1}\\!=\\!{\\bf1}$ . In the special case of $N=1$ , (1) simplifies to the vanilla SGD where ${\\bf W}_{n}=1$ for all $n$ . UD-SGD covers a wide range of distributed algorithms, e.g., decentralized SGD (DSGD) [71, 80, 61, 68], distributed SGD with changing topology (DSGD-CT) [24, 43], local SGD (LSGD) in FL [55, 76], and its variant aimed at reducing communication costs (LSGD-RC) [51]. ", "page_idx": 1}, {"type": "text", "text": "Versatile Communication Patterns $\\left\\{\\mathbf{W}_{n}\\right\\}$ : For visualization, we depict the scenarios of UD-SGD (1) in Figure 1. In DSGD, each agent (node) in the graph communicates with its neighbors after each SGD computation via $\\mathbf{W}_{n}$ , representing the underlying network topology. As a special case, central server-based aggregation, forming a fully connected network, translates $\\mathbf{W}_{n}$ into a rank-1 matrix ${\\bf W}_{n}={\\bf11}^{T}/N$ . To minimize communication expenses, FL variants allow each agent to perform multiple SGD steps before aggregation [55, 67, 76], resulting in a communication interval of length $K$ and a consistent pattern ${\\mathbf W}_{n}={\\mathbf W}$ for $n=m K,\\forall m\\in$ $\\mathbb{N}$ , and ${\\mathbf{W}}_{n}\\,=\\,{\\mathbf{I}}_{N}$ otherwise. In particular, i) ", "page_idx": 1}, {"type": "image", "img_path": "j6Zsoj544N/tmp/73d5878596cfde0a9759b55eb77d5d5764ce98adfc365675f862c7d425940da6.jpg", "img_caption": ["Figure 1: GD-SGD algorithm with a communication network of $N\\,=\\,5$ agents, each holding potentially distinct datasets; e.g., agent $j$ (in blue) samples $\\chi_{j}$ i.i.d. and agent $i$ (in red) samples $\\mathbf{\\mathcal{X}}_{i}$ via Markovian trajectory. "], "img_footnote": [], "page_idx": 1}, {"type": "text", "text": "$\\mathbf{W}\\!=\\!\\mathbf{11}^{T}/N$ corresponds to LSGD with full agent participation (LSGD-FP) [76, 42, 51]; ii) W is a random matrix generated by partial agent participation (LSGD-PP) [55, 18, 74]; iii) W is generated by Metropolis-Hasting algorithm in decentralized setting, e.g., hybrid LSGD (HLSGD) [37, 32] and decentralized FL (DFL) [46, 77, 16]. We defer further discussion of W to Appendix F.1. ", "page_idx": 1}, {"type": "text", "text": "Markovian vs i.i.d. Sampling: Agents typically employ i.i.d. or Markovian sampling, as illustrated in the bottom brown box of Figure 1. In cases where agents have full access to their data, DSGD with i.i.d sampling has been extensively studied [60, 43, 61, 47]. In FL, many application-oriented LSGD variants have been investigated [51, 18, 77, 32, 37, 53]. However, these works solely focus on i.i.d. sampling, restricting their applicability to Markovian sampling scenarios. ", "page_idx": 1}, {"type": "text", "text": "Markovian sampling, which has received increased attention in limited settings (see Table 1), is vital where agents lack independent data access. For instance, in statistical applications, agents with an unknown a priori distribution often use Markovian sampling over i.i.d. sampling [40, 63]. In HLSGD across device-to-device (D2D) networks [32, 37], random walks reduce communication costs compared to the frequent aggregations required by Gossip algorithms [38, 28, 4]. For single-agent scenarios, vanilla SGD with Markovian noise, as applied in a D2D network, has shown improved communication efficiency and privacy [69, 28, 35]. In contrast, for agents with full data access, Markov Chain Monte Carlo (MCMC) methods can be more efficient than i.i.d. sampling, especially in high-dimensional spaces with constraints [27, 40], where acceptance-rejection methods [12] lead to computational inefficiency (e.g., wasted samples) due to multiple rejections before obtaining a sample that satisfies constraints [26, 69]. In addition, shuffling methods can be considered as high-order Markov chains [38], which achieves faster convergence than i.i.d. sampling [1, 79, 78]. ", "page_idx": 1}, {"type": "text", "text": "Limitations of Non-Asymptotic Analysis on Agent\u2019s Sampling Strategy: Recent studies on the non-asymptotic behavior of DSGD and LSGD variants under Markovian sampling, as summarized in Table 1, have made significant strides. However, these works often fall short in accurately revealing the statistical influence of each agent dynamics $\\{X_{n}^{i}\\}$ on the performance of UD-SGD. For instance, [71, 68] proposed the error bound $O({\\frac{1/\\log^{2}(1/\\rho)}{n^{1-a}}})$ , where $a\\in(0.5,1]$ and $\\rho$ denotes the identical mixing rate for all agents, overlooking agent heterogeneity in sampling strategy. A similar assumption to $\\rho$ is also evident in [42]. More recent contributions from [80, 72] have attempted to relax these constraints by considering a finite-time bound of $O(\\tau_{m i x}^{2}/(n+1))$ , where $\\tau_{m i x}$ is the mixing time of the slowest agent. This approach, however, inherently focuses on the worst-performing agent, neglecting how other agents with faster mixing rates might positively influence the system.2 Such an analysis fails to capture the collective impact of other agents on the overall system performance, ", "page_idx": 1}, {"type": "text", "text": "Table 1: Comparison of recent works in distributed learning: We classify the communication patterns into seven categories, i.e., DSGD, DSGD-CT, LSGD-FP, LSGD-PP, LSGD-RC, HLSGD and DFL. We mark \u2018UD-SGD\u2019 when all aforementioned patterns are included and the detailed discussion on $\\left\\{\\mathbf{W}_{n}\\right\\}$ is referred to Appendix F.1. Abbreviations: \u2018Asym.\u2019 $=$ \u2018Asymptotic\u2019, $\\mathbf{\\nabla}\\mathbf{D}.\\mathbf{A}.\\mathbf{B}^{\\prime}=\\mathbf{\\nabla}^{\\prime}$ \u2018Differentiating Agent Behavior\u2019, $\\mathbf{\\dot{L}}.\\mathbf{S}.^{\\circ}=$ \u2018Linear Speedup\u2019, \u2018A.N.I.\u2019 $=$ \u2018Asymptotic Network Independence\u2019. ", "page_idx": 2}, {"type": "table", "img_path": "j6Zsoj544N/tmp/178a3d527c579b21de96ec2bf9b67c28525ee03a67cfe81d54012e0fe66ce6a6.jpg", "table_caption": [], "table_footnote": [], "page_idx": 2}, {"type": "text", "text": "a crucial aspect in large-scale applications where identifying and managing the worst-performing agent is challenging due to privacy concerns or sporadic unreachability. Since agents in distributed learning have the freedom to choose their sampling strategies, it\u2019s vital to understand how each agent\u2019s improved sampling approach contributes to the overall convergence speed of the UD-SGD algorithm. This understanding is key to enhancing system performance, particularly in large-scale machine learning scenarios where agent heterogeneity is a defining feature. ", "page_idx": 2}, {"type": "text", "text": "Rationale for Asymptotic Analysis: Recent trends in convergence analysis have leaned towards non-asymptotic methods, yet it\u2019s crucial to recognize the complementary role of asymptotic analysis for a better understanding of convergence behaviors, as highlighted in [9, 56, 25, 39]. For vanilla SGD, [59, 17] emphasized that central limit theorem (CLT) is far less asymptotic than it may appear under both i.i.d. and Markovian sampling. Notably, the limiting covariance matrix, a key statistical feature in vanilla SGD\u2019s CLT, also prominently features in high-probability bound [59], explicit finite-time bound [17] and 1-Wasserstein distance in the non-asymptotic CLT [66]. [38] further underscored this by numerically showing that the limiting covariance matrix provides a more precise depiction of convergence than the mixing rates often used in finite-time upper bounds [26, 69]. Moreover, they argued that finite-time analysis may not suitably apply to certain efficient high-order Markov chains, due to the lack of comparative mixing-rate metrics. ", "page_idx": 2}, {"type": "text", "text": "Our Contributions: We present an asymptotic analysis of the UD-SGD algorithm (1) under heterogeneous agent dynamics $\\left\\{X_{n}^{i}\\right\\}$ and a large family of communication patterns $\\left\\{\\mathbf{W}_{n}\\right\\}$ . Specifically, \u2022 Under appropriate assumptions, all agents performing (1) asymptotically reach the consensus and find $\\begin{array}{r}{\\theta^{*}\\colon\\forall i\\in[N],\\theta_{n}\\triangleq\\frac{1}{N}\\sum_{i=1}^{N}\\theta_{n}^{i}}\\end{array}$ denotes the average model parameter among all agents, we have ", "page_idx": 2}, {"type": "text", "text": "", "page_idx": 2}, {"type": "equation", "text": "$$\n\\operatorname*{lim}_{n\\to\\infty}\\lVert\\theta_{n}^{i}-\\theta_{n}\\rVert=0,\\ \\ \\operatorname*{lim}_{n\\to\\infty}\\lVert\\theta_{n}-\\theta^{*}\\rVert=0\\ \\mathrm{~a.s.}\n$$", "text_format": "latex", "page_idx": 2}, {"type": "text", "text": "Moreover, we derive the CLT of UD-SGD in the form of ", "page_idx": 2}, {"type": "equation", "text": "$$\n\\gamma_{n}^{-1/2}(\\theta_{n}-\\theta^{*})\\xrightarrow[n\\rightarrow\\infty]{d i s t.}\\mathcal{N}\\left({\\bf0},{\\bf V}\\right).\n$$", "text_format": "latex", "page_idx": 2}, {"type": "text", "text": "Our framework addresses technical challenges in quantifying consensus error under various communication patterns and slowly increasing communication interval. This shows a substantial extension compared to previous studies [58, 43, 51], particularly in regulating the growth of communication intervals (Assumption 2.3-ii) and in proving the scaled consensus error\u2019s boundedness (Lemma B.1). Furthermore, we reformulate UD-SGD as a stochastic approximation-like iteration and tackle the Markovian noise term using the Poisson equation, a technique previously confined only to vanilla SGD with Markovian sampling [17, 38, 52]. The key here is to devise the noise decomposition that separates the consensus error among all agents from the error caused by the bias from the Markov chain, which aligns with the target distribution only asymptotically at infinity, not at finite times. ", "page_idx": 2}, {"type": "text", "text": "", "page_idx": 3}, {"type": "text", "text": "\u2022 In analyzing (3), we derive the exact form of V asN12 iN=1 Vi. Here, Vi is the limiting covariance matrix of agent $i$ , which depends mainly on its sampling strategy $\\{X_{n}^{i}\\}$ . This allows us to show that improving individual agents\u2019 sampling strategy can reduce the covariance in CLT, which in turn implies a smaller mean-square error (MSE) for large time $n$ . This is a significant advancement over previous finite-sample bounds that only account for the worst-performing agent and do not fully capture the effect of individual agent dynamics on overall system performance. Our CLT result (3) also treats recent findings in [38] as a very special case with $N=1$ , where the relationship therein between the sampling efficiency of the Markov chain and the limiting covariance matrix in the CLT of vanilla SGD, can carry over to our UD-SGD. ", "page_idx": 3}, {"type": "text", "text": "\u2022 We demonstrate that our analysis supports recent findings from studies such as [42], which exhibited linear speedup scaling with the number of agents under LSGD-FP with Markovian sampling; and [62, 61], which examined the notion of \u2018asymptotic network independence\u2019 for DSGD with i.i.d. sampling, where the convergence of the algorithm (1) at large time $n$ depends solely on the left eigenvector of $\\mathbf{W}_{n}$ ( $\\scriptstyle{\\frac{1}{N}}\\mathbf{1}$ considered in this paper) rather than the specific communication network topology encoded in $\\dot{\\mathbf{W}}_{n}$ , but now under Markovian sampling. We extend these findings in view of CLT to a broader range of communication patterns $\\left\\{\\mathbf{W}_{n}\\bar{\\right\\}$ and general sampling strategies $\\{X_{n}^{i}\\}$ . ", "page_idx": 3}, {"type": "text", "text": "\u2022 We conduct numerical experiments using logistic regression and neural network training with several choices of agents\u2019 sampling strategies, including a recently proposed one via nonlinear Markov chain [25]. Our results uncover a key phenomenon: a handful of compliant agents adopting highly efficient sampling strategies can match or exceed the performance of the majority using moderately improved strategies. This finding is crucial for practical optimization in large-scale learning systems, moving beyond the current literature that only considers the worst-performing agent in more restrictive settings. ", "page_idx": 3}, {"type": "text", "text": "2 Preliminaries ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "Basic Notations: We use $\\|\\mathbf{v}\\|$ to indicate the Euclidean norm of a vector $\\mathbf{v}\\in\\mathbb{R}^{d}$ and $\\lVert\\bf M\\rVert$ to indicate the spectral norm of a matrix $\\mathbf{M}\\in\\mathbb{R}^{d\\times d}$ . The identity matrix of dimension $d$ is denoted by $\\mathbf{I}_{d}$ , and the all-one (resp. all-zero) vector of dimension $N$ is denoted by 1 (resp. 0). Let $\\mathbf{J}\\triangleq\\mathbf{1}\\mathbf{1}^{T}/N$ . The diagonal matrix with the entries of $\\mathbf{v}$ on the main diagonal is written as $\\mathrm{diag}(\\mathbf{v})$ . We also use $\\ '\\succeq$ for Loewner ordering such that $\\mathbf A\\succeq\\mathbf B$ is equivalent to $\\mathbf{x}^{T}(\\mathbf{A}-\\mathbf{B})\\mathbf{x}\\geq0$ for any $\\mathbf{x}\\in\\mathbb{R}^{d}$ . ", "page_idx": 3}, {"type": "text", "text": "Asymptotic Covariance Matrix: Asymptotic variance is a widely used metric for evaluating the second-order properties of Markov chains associated with a scalar-valued test function in the MCMC literature, e.g., Chapter 6.3 [12], and asymptotic covariance matrix is its multivariate version for a vector-valued function. Specifically, we consider a finite, irreducible, aperiodic and positive recurrent (ergodic) Markov chain $\\{X_{n}\\}_{n\\ge0}$ with transition matrix $\\mathbf{P}$ and stationary distribution $\\pi$ , and the estimator \u00b5\u02c6n(g) \u225c n1 sn=\u221201 for any vector-valued function $\\mathbf{g}:[N]\\to\\mathbb{R}^{d}$ . According to the ergodic theorem [12, 13], we have $\\begin{array}{r}{\\operatorname*{lim}_{n\\to\\infty}\\hat{\\mu}_{n}(\\mathbf{g})=\\mathbb{E}_{\\pmb{\\pi}}(\\mathbf{g})}\\end{array}$ a.s.. As defined in [13, 38], the asymptotic covariance matrix $\\Sigma_{X}(\\mathbf{g})$ for a vector-valued function $\\mathbf{g}(\\cdot)$ is given by ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\pmb{\\Sigma}_{X}(\\mathbf{g})\\triangleq\\operatorname*{lim}_{n\\rightarrow\\infty}n\\cdot\\mathbf{Var}(\\hat{\\mu}_{n}(\\mathbf{g}))\\!=\\!\\operatorname*{lim}_{n\\rightarrow\\infty}\\frac{1}{n}\\cdot\\mathbb{E}\\left\\{\\Delta_{n}\\Delta_{n}^{T}\\right\\},\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "where $\\begin{array}{r}{\\Delta_{n}\\triangleq\\sum_{s=0}^{n-1}(\\mathbf{g}(X_{s})-\\mathbb{E}_{\\pmb{\\pi}}(\\mathbf{g}))}\\end{array}$ . By following the algebraic manipulations in [12, Theorem 6.3.7] for asymptotic variance (univariate version), we can rewrite (4) in a matrix form such that ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\begin{array}{r}{{\\pmb{\\Sigma}}_{X}({\\bf g})={\\bf G}^{T}\\mathrm{diag}(\\pi)\\left({\\bf Z}-{\\bf I}_{N}+{\\bf1}\\pi^{T}\\right){\\bf G},}\\end{array}\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "where $\\mathbf{G}\\triangleq[\\mathbf{g}(1),\\cdot\\cdot\\cdot\\mathbf{\\Phi},\\mathbf{g}(N)]^{T}\\in\\mathbb{R}^{N\\times d}$ and ${\\mathbf{Z}}\\triangleq[{\\mathbf{I}}_{N}-{\\mathbf{P}}+{\\mathbf{1}}{\\boldsymbol{\\pi}}^{T}]^{-1}$ . This matrix form explicitly shows the dependence on the transition matrix $\\mathbf{P}$ and its stationary distribution $\\pi$ , and will be utilized in our Theorem 3.3. ", "page_idx": 3}, {"type": "text", "text": "Model Description: The UD-SGD in (1) can be expressed in a compact iterative form, i.e., we have ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\theta_{n+1}^{i}=\\sum_{j=1}^{N}w_{n}(i,j)(\\theta_{n}^{j}-\\gamma_{n+1}\\nabla F_{j}(\\theta_{n}^{j},X_{n}^{j})),}\\end{array}\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "at each time $n$ , where each agent $i$ samples according to its own Markovian trajectory $\\{X_{n}^{i}\\}_{n\\ge0}$ with stationary distribution $\\pi_{i}$ such that $\\bar{\\mathbb{E}}_{X\\sim\\pi_{i}}[F_{i}(\\theta,\\bar{X^{}})]\\!=\\!f_{i}(\\theta)$ . Let $K_{l}$ denote the communication interval between the $(l-1)$ -th and $l_{\\cdot}$ -th aggregation among $N$ agents, and $\\begin{array}{r}{n_{l}\\triangleq\\sum_{m=1}^{l}K_{m}}\\end{array}$ be the time instance for the $l$ -th aggregation. We also define $\\tau_{n}\\triangleq\\operatorname*{min}_{l}\\{l:n_{l}\\ge n\\}$ as the index of the upcoming aggregation at time $n$ such that $K_{\\tau_{n}}$ indicates the communication interval for the $\\tau_{n}$ -th aggregation, or more precisely, the length of the communication interval that includes the time index $n$ . The communication pattern follows that ${\\mathbf{W}}_{n}\\,=\\,{\\mathbf{I}}_{n}$ if $n\\ne n_{l}$ and ${\\mathbf W}_{n}\\,=\\,{\\mathbf W}$ otherwise for $l\\geq1$ , where the examples of W will be discussed in Appendix F.1. Note that i) when $K_{l}=1$ , (6) reduces to DSGD; ii) when $K_{l}=K>1$ , (6) becomes the local SGD in FL. iii) When $K_{l}$ increases with $l$ , we recover some choices of $K_{l}$ studied in [51] beyond LSGD-RC with i.i.d. sampling. This increasing communication interval aims to further reduce the frequency of aggregation among agents for lower communication costs, but now under a Markovian sampling setting and a wider range of communication patterns. We below state the assumptions needed for the main theoretical results. ", "page_idx": 4}, {"type": "text", "text": "Assumption 2.1 (Regularity of the gradient). For each $i\\in[N]$ and $X\\in\\mathcal{X}^{i}$ , the function $F_{i}(\\theta,X)$ is $L$ -smooth in terms of $\\theta$ , i.e., for any $\\theta_{1},\\theta_{2}\\in\\mathbb{R}^{d}$ , ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\|\\nabla F_{i}(\\theta_{1},X)-\\nabla F_{i}(\\theta_{2},X)\\|\\leq L\\|\\theta_{1}-\\theta_{2}\\|.\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "In addition, we assume that the objective function $f$ is twice continuously differentiable and $\\mu$ -strongly convex only around the local minima $\\theta^{*}\\in{\\mathcal{L}},$ , i.e., ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\mathbf{H}\\triangleq\\nabla^{2}f(\\theta^{*})\\succeq\\mu\\mathbf{I}_{d}.\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "Assumption 2.1 imposes the regularity conditions on the gradient $\\nabla F_{i}(\\cdot,X)$ and Hessian matrix of the objective function $f(\\cdot)$ , as is commonly assumed in [10, 45, 29, 38]. Note that (7) requires per-sample Lipschitzness of $\\nabla F_{i}$ and is stronger than the Lipschitzness of its expected version $\\nabla f_{i}$ , which is commonly assumed under $i.i.d$ sampling setting [73, 50, 30]. However, we remark that this is in line with previous work on DSGD and LSGD-FP under Markovian sampling as well [71, 42, 80], because $\\nabla F_{i}(\\theta,X)$ is no longer the unbiased stochastic version of $\\nabla f_{i}(\\theta)\\bar{$ and the effect of $\\{X_{n}^{i}\\}$ has to be taken into account in the analysis. The local strong convexity at the minimizer is commonly assumed to analyze the convergence of the algorithm under both asymptotic and non-asymptotic analysis [10, 29, 38, 45, 52, 80]. ", "page_idx": 4}, {"type": "text", "text": "Assumption 2.2 (Ergodicity of Markovian sampling). $\\{X_{n}^{i}\\}_{n\\ge0}$ is an ergodic Markov chain with stationary distribution $\\pi_{i}$ such that $\\mathbb{E}_{X\\sim\\pmb{\\pi}_{i}}[F_{i}(\\theta,\\dot{X})]\\stackrel{\\cdot\\cdot}{=}\\,\\overline{{f}}_{i}(\\theta)$ , and is independent from $\\{X_{n}^{j}\\}_{n\\ge0},j\\neq i$ . ", "page_idx": 4}, {"type": "text", "text": "The ergodicity of the underlying Markov chains, as stated in Assumption 2.2, is commonly assumed in the literature [26, 69, 80, 42, 38]. This assumption ensures the asymptotic unbiasedness of the loss function $F_{i}(\\theta,\\cdot)$ , which takes i.i.d. sampling as a special case. ", "page_idx": 4}, {"type": "text", "text": "Assumption 2.3 (Decreasing step size and slowly increasing communication interval). i) For bounded communication interval $K_{\\tau_{n}}\\,\\leq\\,K,\\forall n$ , we assume the polynomial step size $\\gamma_{n}=1/n^{a}$ and $a\\in$ (0.5, 1]; Or ii) If $K_{\\tau_{n}}\\rightarrow\\infty$ nas $n\\to\\infty$ , we assume $\\gamma_{n}=1/n$ and define $\\eta_{n}=\\gamma_{n}K_{\\tau_{n}}^{L+1}$ , where the sequence $\\{K_{l}\\}_{l\\ge0}$ satisfies $\\textstyle\\sum_{n}\\eta_{n}^{2}<\\infty$ , $K_{\\tau_{n}}=o(\\gamma_{n}^{-1/2(L+1)})$ n\u22121/2(L+1)), and liml\u2192\u221e\u03b7nl+1/\u03b7nl+1+1 = 1. ", "page_idx": 4}, {"type": "text", "text": "In Assumption 2.3, the polynomial step size $\\gamma_{n}$ is standard in the literature and it has the property $\\textstyle\\sum_{n}\\gamma_{n}\\,=\\,\\infty$ , $\\textstyle\\sum_{n}\\gamma_{n}^{2}\\ {\\bar{<}}\\ {\\dot{\\infty}}$ [17, 38]. Inspired by [51], we introduce $\\eta_{n}$ to control the step size within each $l$ -th communication interval with length $K_{l}$ to restrict the growth of $K_{l}$ . Specifically, $\\textstyle\\sum_{n}\\eta_{n}^{2}\\,<\\,\\infty$ and $K_{\\tau_{n}}\\,=\\,o(\\gamma_{n}^{-1/2(L+1)})$ ensure that $\\eta_{n}\\rightarrow0$ and $K_{\\tau_{n}}$ does not increase too fast in $n$ . $\\begin{array}{r}{\\operatorname*{lim}_{l\\to\\infty}\\eta_{n_{l}+1}/\\eta_{n_{l+1}+1}=1}\\end{array}$ sets the restriction on the increment from $n_{l}$ to $n_{l+1}$ . Several practical forms of $K_{l}$ suggested by [51], including $K_{l}\\sim\\log(l)$ and $K_{l}\\sim\\log\\log(l)$ , also satisfy Assumption 2.3-ii). We defer to Appendix A the mathematical verification of these two types of $K_{l}$ , together with the practical implications of increasing communication interval $K_{l}$ . ", "page_idx": 4}, {"type": "text", "text": "Remark 1. In Assumption 2.3, we incorporate an increasing communication interval along with a step size $\\gamma_{n}=1/n$ . This complements the choice of step size $\\gamma_{n}$ in $[5l$ , Assumption $3.3J,$ where $\\gamma_{n}=1/n^{a}$ for $a\\in(0.5,1)$ . It is important to note, however, that the increasing communication interval specified in $I5I$ , Assumption $3.2J$ is applicable only in i.i.d sampling. Under the Markovian sampling framework, the expression $\\nabla F_{i}(\\theta,X){-}\\nabla f_{i}(\\theta)$ loses its unbiased and Martingale difference properties. Consequently, the Martingale CLT application as utilized by $I5I J$ does not directly extend to Markovian sampling. To address this, we adapted techniques from [29, 58] to accommodate the increasing communication interval within the Markovian sampling setting and various communication patterns. This adaptation necessitates $\\gamma_{n}=1/n,$ , a specification not covered in [51]. Exploring more general forms of $K_{l}$ that could relax this assumption is outside the scope of our current study. ", "page_idx": 4}, {"type": "text", "text": "", "page_idx": 5}, {"type": "text", "text": "Assumption 2.4 (Stability on model parameter). We assume $\\operatorname*{sup}_{n}\\|\\theta_{n}^{i}\\|<\\infty$ almost surely $\\forall i\\in[N]$ . Assumption 2.4 claims that the sequence of $\\{\\theta_{n}^{i}\\}$ always remains in a path-dependent compact set. It is to ensure the stability of the algorithm that serves the purpose of analyzing the convergence, which is often assumed under the asymptotic analysis of vanilla SGD with Markovian noise [23, 29, 52]. As mentioned in [58, 70], checking Assumption 2.4 is challenging and requires case-by-case analysis, even under i.i.d. sampling. Only recently the stability of SGD under Markovian sampling has been studied in [9], but the result for UD-SGD remains unknown in the literature. Thus, we analyze each agent\u2019s sampling strategy in the asymptotic regime under this stability condition. ", "page_idx": 5}, {"type": "text", "text": "Assumption 2.5 (Contraction property of communication matrix). i). $\\{\\mathbf{W}_{n}\\}_{n\\ge0}$ is independent of the sampling strategy $\\{X_{n}^{i}\\}_{n\\ge0}$ for all $i\\in[N]$ and is assumed to be doubly-stochastic for all $n;\\,i i)$ . At each aggregation step $n_{l}$ , $\\bar{\\mathbf{W}}_{n_{l}}$ is independently generated from some distribution $\\mathcal{P}_{n_{l}}$ such that $\\|\\mathbb{E}_{\\mathbf{W}\\sim\\mathcal{P}_{n_{l}}}[\\mathbf{W}^{T}\\mathbf{W}]\\!-\\!\\mathbf{J}\\|\\!\\leq\\!C_{1}\\!<\\!1$ for some constant $C_{1}$ . ", "page_idx": 5}, {"type": "text", "text": "The doubly-stochasticity of $\\mathbf{W}_{n}$ in Assumption 2.5-i) is widely assumed in the literature [54, 24, 43, 80]. Assumption 2.5-ii) is a contraction property to ensure that agents employing UD-SGD will asymptotically achieve the consensus, which is also common in [7, 24, 80]. Examples of W that satisfy Assumption 2.5-ii), e.g., Metropolis-Hasting matrix, partial agent participation in FL, are deferred to Appendix F.1 due to space constraint. ", "page_idx": 5}, {"type": "text", "text": "3 Asymptotic Analysis of UD-SGD ", "text_level": 1, "page_idx": 5}, {"type": "text", "text": "Almost Sure Convergence: Let $\\begin{array}{r}{\\theta_{n}\\triangleq{\\frac{1}{N}}\\sum_{i=1}^{N}\\theta_{n}^{i}}\\end{array}$ represent the consensus among all the agents at time $n$ , we establish the asymptotic consensus of the local parameters $\\theta_{n}^{i}$ , as stated in Lemma 3.1. ", "page_idx": 5}, {"type": "text", "text": "Lemma 3.1. Under Assumptions 2.1, 2.3, 2.4 and 2.5, the consensus error $\\theta_{n}^{i}\\!-\\!\\theta_{n}$ diminishes to zero at the rate specified below: Almost surely, for every agent $i\\in[N]$ , ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\|\\theta_{n}^{i}-\\theta_{n}\\|\\!=\\!\\left\\{\\!\\!\\begin{array}{c c}{{O(\\gamma_{n})}}&{{u n d e r\\:A s s u m.\\ 2.3\\ \u2013i),}}\\\\ {{O(\\eta_{n})}}&{{u n d e r\\:A s s u m.\\ 2.3\\ \u2013i i).}}\\end{array}\\right.\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "Lemma 3.1 indicates that all agents asymptotically reach consensus at a rate of $O(\\gamma_{n})$ (or $O(\\eta_{n}))$ . This finding extends the scope of [58, Proposition 1], incorporating considerations for Markovian sampling, $\\mathrm{FL}$ settings, and increasing communication interval $K_{l}$ . The proof, detailed in Appendix B, primarily tackles the challenge of establishing the boundedness of the sequences $\\{\\gamma_{n}^{-1}({\\boldsymbol{\\theta}}_{n}^{i}-{\\boldsymbol{\\theta}}_{n})\\}$ (or $\\left\\{\\eta_{n}^{-1}(\\theta_{n}^{i}-\\theta_{n})\\right\\}$ almost surely for all $i\\in[N]$ . This is specifically analyzed in Lemma B.1. Next, with additional Assumption 2.2, we are able to obtain the almost sure convergence of $\\theta_{n}$ to $\\theta^{*}\\in\\mathcal{L}$ . ", "page_idx": 5}, {"type": "text", "text": "Theorem 3.2. Under Assumptions 2.1 - 2.5, the consensus $\\theta_{n}$ converges to $\\mathcal{L}$ almost surely, i.e., ", "page_idx": 5}, {"type": "text", "text": "Theorem 3.2 is achieved by decomposing the Markovian noise term $\\nabla F_{i}(\\theta_{n}^{i},X_{n}^{i})-\\nabla f_{i}(\\theta_{n}^{i})$ , using the Poisson equation technique as discussed in [6, 29, 17], into a Martingale difference noise term, along with additional noise terms. We then reformulate (6) into an iteration akin to stochastic approximation, as depicted in (56). The subsequent step involves verifying the conditions on these noise terms under our stated assumptions. Crucially, this theorem also establishes that UD-SGD ensures an almost sure convergence of each agent to a local minimum $\\theta^{*}\\in\\mathcal{L}$ , even in scenarios where the communication interval $K_{l}$ gradually increases, in accordance with Assumption 2.3-ii). The detailed proof of this theorem is provided in Appendix C. ", "page_idx": 5}, {"type": "text", "text": "Central Limit Theorem: Let $\\begin{array}{r}{\\mathbf{U}_{i}\\triangleq\\sum_{X^{i}}\\bigl(\\nabla F_{i}(\\theta^{*},\\cdot)\\bigr)}\\end{array}$ represent the asymptotic covariance matrix (defined in (5)) associated with each agent $i\\in[N]$ , given their sampling strategy $\\{X_{n}^{i}\\}$ and function \u2207Fi(\u03b8\u2217, \u00b7). Define U \u225c 12 N . We assume the polynomial step-size $\\gamma_{n}\\!\\sim\\!\\gamma_{\\star}/n^{a}$ , $a\\!\\in\\!(0.5,1]$ and $\\gamma_{\\star}~>~0$ . In the case of $a\\,=\\,1$ , we further assume $\\gamma_{\\star}\\,>\\,1/2\\mu$ , where $\\mu$ is defined in (8). For notational simplicity, and without loss of generality, our remaining CLT result is stated while conditioning on the event that $\\{\\theta_{n}\\to\\theta^{*}\\}$ for some $\\theta^{*}\\in\\mathcal{L}$ . ", "page_idx": 5}, {"type": "text", "text": "Theorem 3.3. Let Assumptions 2.1 - 2.5 hold. Then, ", "page_idx": 6}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\gamma_{n}^{-1/2}(\\theta_{n}-\\theta^{*})\\xrightarrow[n\\rightarrow\\infty]{d i s t.}\\mathcal{N}(\\mathbf{0},\\mathbf{V}),}\\end{array}\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "where the limiting covariance matrix $\\mathbf{V}$ is in the form of ", "page_idx": 6}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathbf{V}=\\int_{0}^{\\infty}e^{\\mathbf{M}t}\\mathbf{U}e^{\\mathbf{M}t}d t.}\\end{array}\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "Here, we have $\\mathbf{M}=-\\mathbf{H}$ if $a\\in(0.5,1)$ , or ${\\bf M}={\\bf I}_{d}/2\\gamma_{\\star}-{\\bf H}\\,i f a=1,$ , where $\\mathbf{H}$ is defined in (8). Moreover, let $\\begin{array}{r}{\\bar{\\theta}_{n}=\\frac{1}{n}\\sum_{s=0}^{n-1}\\theta_{s}}\\end{array}$ and $\\mathbf{V}^{\\prime}=\\mathbf{H}^{-1}\\mathbf{U}\\mathbf{H}^{-1}$ . For $a\\in(0.5,1)$ , we have ", "page_idx": 6}, {"type": "equation", "text": "$$\n\\sqrt{n}(\\bar{\\theta}_{n}-\\theta^{*})\\ \\xrightarrow[n\\rightarrow\\infty]{d i s t.}{\\mathcal{N}}(\\mathbf{0},\\mathbf{V}^{\\prime}),\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "The proof, presented in Appendix $\\mathrm{D}$ , addresses the technical challenges in deriving the CLT for UD-SGD, specifically the second-order conditions in decomposing the Markovian noise term, which is not present in the i.i.d. sampling case [58, 43, 51]. We decompose $\\nabla F_{i}(\\theta_{n},X_{n}^{i})\\!-\\!\\nabla f_{i}(\\theta_{n})$ into three parts in (48) using Poisson equation: $e_{n+1}^{i},\\nu_{n+1}^{i},\\xi_{n+1}^{i}$ . The consensus error $\\theta_{n}^{i}-\\theta_{n}$ embedded in noise terms $e_{n+1}^{i}$ and $\\xi_{n+1}^{i}$ is a new factor, whose characteristics have been quantified in our Lemma 3.1 but are not present in the single-agent scenario analyzed as an application of stochastic approximation in [22, 29]. The specifics of this analysis are expanded upon in Appendices D.1 to D.3. We require $\\gamma_{\\star}\\,{>}\\,1/2\\mu$ for $a\\!=\\!1$ to ensure that the largest eigenvalue of $\\mathbf{M}$ is negative, as this is a necessary condition for the existence of $\\mathbf{V}$ in (12) (otherwise integration diverges). In the case where there is only one agent ( $N\\!=\\!1)$ , $\\mathbf{V}$ and ${\\bf V}^{\\prime}$ reduce to the matrices specified in the CLT result of vanilla SGD [29, 38, 52]. In addition, for a special case of constant communication interval in Assumption 2.3-i) and i.i.d. sampling as shown in Table 1, we recover the CLT of LSGD-RC in [51]. See Appendix E for detailed discussions. ", "page_idx": 6}, {"type": "text", "text": "Theorem 3.3 has significant implications for the MSE of $\\{\\theta_{n}\\}$ for large time $n$ , i.e., $\\mathbb{E}[\\|\\theta_{n}-\\theta^{*}\\|^{2}]{=}$ $\\begin{array}{r}{\\sum_{i=1}^{d}\\mathbf{e}_{i}^{T}\\mathbb{E}[(\\theta_{n}-\\theta^{*})(\\theta_{n}-\\theta^{*})^{T}]\\mathbf{e}_{i}\\approx\\gamma_{n}\\sum_{i=1}^{d}\\mathbf{e}_{i}^{T}\\mathbf{V}\\mathbf{e}_{i}=\\gamma_{n}\\mathrm{Tr}(\\mathbf{V})}\\end{array}$ , where $\\mathbf{e}_{i}$ is the $d$ -dimensional vector of all zeros except 1 at the $i$ -th entry. This indicates that a smaller limiting covariance matrix $\\mathbf{V}$ , according to the Loewner order, results in a smaller trace of $\\mathbf{V}$ and consequently in a reduced MSE for large $n$ . Consideration for smaller $\\mathbf{V}$ will be presented in the next section, where agents have the opportunity to improve their sampling strategies. ", "page_idx": 6}, {"type": "text", "text": "Remark 2. Studies by [62, 61] have shown that in DSGD with a fixed doubly-stochastic matrix W, the influence of communication topology diminishes after a transient period. Our Theorem 3.3 extends these findings to Markovian sampling and a broader spectrum of communication patterns as in Table 1. This extension is based on the fact that the consensus error, impacted primarily by the communication pattern, decreases faster than the CLT scale $O(\\sqrt{\\gamma_{n}})$ and is thus not the dominant factor in the asymptotic regime, as suggested by Lemma 3.1. ", "page_idx": 6}, {"type": "text", "text": "Remark 3. Recent studies have highlighted linear speedup with increasing number of agents $N$ in the dominant term of their finite-sample error bounds under DSGD-CT with i.i.d. sampling $[43]$ and LSGD-FC with Markovian sampling $[42]$ . However, our Theorem 3.3 demonstrates this phenomenon uVn dine ro muro rCe LdTi.v eSrpsee ccifoicmamlluy,n iitc astciaolne sp awttitehr $1/N$ ,d  i.Me.a ${\\bf V}\\!=\\!\\bar{\\bf V}/N,$ ,m pwlhinegr ei $\\begin{array}{r}{\\bar{\\mathbf{V}}\\!=\\!\\frac{1}{N}\\sum_{i=1}^{N}\\mathbf{V}_{i}}\\end{array}$ $^{\\,\\,\\,I}$ edaedniontge st etrhme average limiting covariance matrices across all $N$ agents and $\\begin{array}{r}{{\\bf V}_{i}\\!=\\!\\int_{0}^{\\infty}e^{\\mathbf{M}t}\\mathbf{U}_{i}e^{\\mathbf{M}t}d t,}\\end{array}$ , suggesting that the MSE $\\mathbb{E}[\\|\\theta_{n}-\\theta^{*}\\|^{2}]$ will be improved by $1/N$ . A similar argument also applies to ${\\bf V}^{\\prime}$ in (13), i.e., ${\\bf V}^{\\prime}=\\bar{\\bf V}^{\\prime}/N$ , where $\\begin{array}{r}{\\bar{\\mathbf{V}}^{\\prime}=\\frac{1}{N}\\sum_{i=1}^{N}\\mathbf{V}_{i}^{\\prime}}\\end{array}$ and $\\mathbf{V}_{i}^{\\prime}=\\mathbf{H}^{-1}\\mathbf{U}_{i}\\mathbf{H}^{-1}$ . ", "page_idx": 6}, {"type": "text", "text": "Impact of Agent\u2019s Sampling Strategy: In the literature, the mixing time-based technique has been widely used in the non-asymptotic analysis in SGD, DSGD and various LSGD variants in FL [26, 69, 68, 80, 42], i.e., for each agent $i\\in[N]$ and some constant $C$ , ", "page_idx": 6}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\|\\nabla F_{i}(\\theta,X_{n}^{i})-\\nabla f_{i}(\\theta)\\|\\le C\\|\\theta\\|\\rho_{i}^{n},}\\end{array}\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "where $\\rho_{i}$ is the mixing rate of the underlying Markov chain. However, typical non-asymptotic analyses often rely on $\\rho\\ {\\triangleq}\\ \\operatorname*{max}_{i}\\rho_{i}$ among $N$ agents, i.e., the worst-performing agent in their finite-time bounds [80, 72], or assume an identical mixing rate across all $N$ agents [42, 68]. ", "page_idx": 6}, {"type": "text", "text": "In contrast, Remark 3 highlights that each agent holds its own limiting covariance matrices $\\mathbf{V}_{i}$ and $\\mathbf{V}_{i}^{\\prime}$ , which are predominantly governed by the matrix $\\mathbf{U}_{i}$ , capturing the agent\u2019s sampling strategy $\\{X_{n}^{i}\\}$ and contributing equally to the overall performance of UD-SGD. For each agent $i$ , denote by $\\dot{\\mathbf{U}}_{i}^{X}$ and $\\mathbf{U}_{i}^{Y}$ the asymptotic covariance matrices associated with two candidate sampling strategies $\\{X_{n}^{i}\\}$ and $\\{Y_{n}^{i}\\}$ , respectively. Let $\\mathbf{V}^{X}$ and $\\mathbf{V}^{Y}$ be the limiting covariance matrices of the distributed system in (12), where agent $i$ employs $\\{X_{n}^{i}\\}$ and $\\{Y_{n}^{i}\\}$ , respectively, while keeping other agents\u2019 sampling strategies unchanged. Then, we have the following result. ", "page_idx": 6}, {"type": "text", "text": "", "page_idx": 7}, {"type": "text", "text": "Corollary 3.4. For agent $i$ , if there exist two sampling strategies $\\{X_{n}^{i}\\}_{n\\ge0}$ and $\\{Y_{n}^{i}\\}_{n\\ge0}$ such that $\\mathbf{U}_{i}^{X}\\succeq\\mathbf{U}_{i}^{Y}$ , we have $\\mathbf{V}^{X}\\succeq\\mathbf{V}^{Y}$ . ", "page_idx": 7}, {"type": "text", "text": "Corollary 3.4 directly follows from the definition of Loewner ordering, and Loewner ordering being closed under addition (i.e., $\\mathbf{A}\\!\\succeq\\!\\mathbf{B}$ implies $\\mathbf{A}\\!+\\!\\mathbf{C}\\!\\succeq\\!\\mathbf{B}\\!+\\!\\mathbf{C})$ . It demonstrates that even a single agent improves its sampling strategy from $\\left\\{X_{n}^{i}\\right\\}$ to $\\{Y_{n}^{i}\\}$ , it leads to an overall reduction in $\\mathbf{V}$ (in terms of Loewner ordering), thereby decreasing the MSE and benefiting the entire group of $N$ agents. The subsequent question arises: How do we identify an improved sampling strategy $\\bigl\\{Y_{n}^{i}\\bigr\\}$ over the baseline $\\{\\dot{X}_{n}^{i}\\}$ ? ", "page_idx": 7}, {"type": "text", "text": "This question has been partially addressed by [57, 48, 38], which qualitatively investigates the \u2018efficiency ordering\u2019 of two sampling strategies. In particular, [38, Theorem 3.6 (i)] shows that sampling strategy $\\{Y_{n}\\}$ is more efficient than $\\{X_{n}\\}$ if and only if $\\pmb{\\Sigma}_{X}(\\mathbf{g})\\ \\succeq\\ \\pmb{\\Sigma}_{Y}(\\mathbf{g})$ for any vector-valued function $\\mathbf{g}(\\cdot)\\in\\mathbb{R}^{d}$ . Consequently, in the UD-SGD framework, employing a more efficient sampling strategy $\\{Y_{n}^{i}\\}$ over the baseline $\\{X_{n}^{i}\\}$ by agent $i$ leads to $\\Sigma_{X^{i}}(\\nabla{\\dot{F}}_{i}({\\bar{\\theta}}^{*},\\cdot))\\succeq$ $\\Sigma_{Y^{i}}(\\nabla F_{i}({\\theta^{*}},\\cdot))$ , thus satisfying $\\mathbf{U}_{i}^{X}\\succeq\\mathbf{U}_{i}^{Y}$ . This finding, as per Corollary 3.4, implies an overall improvement in UD-SGD. ", "page_idx": 7}, {"type": "text", "text": "For illustration purposes, we list a few examples where two competing sampling strategies follow efficiency ordering: i) When an agent has complete access to the entire dataset (e.g., deep learning), shuffilng techniques like single shuffilng and random reshuffilng are more efficient than i.i.d. sampling [38, 78]; ii) When an agent works with a graph-like data structure and employs a random walk, e.g., agent $i$ in Figure 1, using non-backtracking random walk (NBRW) is more efficient than simple random walk (SRW) [48]. iii) A recently proposed self-repellent random walk (SRRW) is shown to achieve near-zero sampling variance, indicating even higher sampling efficiency than NBRW and SRW [25].3 This random-walk-based sampling finds a particular application in large-scale FL within D2D networks (e.g., mobile networks, wireless sensor networks), where each agent acts as an edge server or access point, gathering information from the local D2D network [37, 32]. Employing a random walk over local D2D network for each agent constitutes the sampling strategy. ", "page_idx": 7}, {"type": "text", "text": "Theorem 3.3 and Corollary 3.4 not only qualitatively compare these sampling strategies but also allow for a quantitative assessment of the overall system enhancement. Since every agent contributes equally to the limiting covariance matrix V of the distributed system as in Remark 3, a key application scenario is to encourage a subset of compliant agents to adopt highly efficient strategies like SRRW, potentially yielding better performance than universally upgrading to slightly improved strategies like NBRW. This approach, more feasible and impactful in large-scale machine learning scenarios where some agents cannot freely modify their sampling strategies, is a unique aspect of our framework not addressed in previous works focusing on the worst-performing agent [80, 42, 68, 72]. ", "page_idx": 7}, {"type": "text", "text": "4 Experiments ", "text_level": 1, "page_idx": 7}, {"type": "text", "text": "In this section, we empirically evaluate the effect of agents\u2019 sampling strategies under various communication patterns in UD-SGD. We consider the $L_{2}$ -regularized binary classification problem ", "page_idx": 7}, {"type": "equation", "text": "$$\n\\underset{\\theta}{\\operatorname*{min}}\\;f(\\theta)\\triangleq\\frac{1}{N}\\sum_{i=1}^{N}f_{i}(\\theta),\\mathrm{~with~}f_{i}(\\theta)\\!=\\!\\frac{1}{B}\\!\\sum_{j=1}^{B}\\!\\log\\!\\left(\\!1\\!+\\!e^{\\theta^{T}\\mathbf{x}_{i,j}}\\!\\right)\\!-\\!y_{i,j}\\left(\\theta^{T}\\mathbf{x}_{i,j}\\right)\\!+\\!\\frac{\\kappa}{2}\\|\\theta\\|^{2},\n$$", "text_format": "latex", "page_idx": 7}, {"type": "text", "text": "where the feature vector ${\\bf x}_{i,j}$ and its corresponding label $y_{i,j}$ are held by agent $i$ , with a penalty parameter $\\kappa$ set to 1. We use the ijcnn1 dataset [14] with 22 features in each data point and $50\\mathbf{k}$ data points in total, which is evenly distributed to two groups with 50 agents each $N=100$ agents in total) and each agent holds $B=500$ distinct data points. Each agent in the first group has full access to its entire dataset, and thus can employ i.i.d. sampling (baseline) or single shuffling. On the other hand, each agent in the other group has a graph-like structure and uses SRW (baseline), NBRW or SRRW with reweighting to sample its local dataset with uniform weight. In this simulation, we assume that agents can only communicate through a communication network using the DSGD algorithm. This scenario with heterogeneous agents, as depicted in Figure 1, is of great interest in large-scale machine learning [37, 32]. In addition, we employ a decreasing step size $\\bar{\\gamma}_{n}=1/n$ in our UD-SGD framework (1) because it is typically used for the strongly convex objective function and is tested to have the fastest convergence in this simulation setup. Due to space constraints, we defer detailed simulation setup, including the introduction of SRW, NBRW, and SRRW, to Appendix G.1. ", "page_idx": 7}, {"type": "image", "img_path": "j6Zsoj544N/tmp/5b95c08ebfeb514bae7c87d527d9650d5105ccfe85b9614553b3893e08bb064d.jpg", "img_caption": ["Figure 2: Binary classification problem. From left to right: (a) Impact of efficient sampling strategies on convergence. (b) Performance gains from partial adoption of efficient sampling. (c) Comparative advantage of SRRW over NBRW in a small subset of agents. (d) Asymptotic network independence of four algorithms under UD-SGD framework with fixed sampling strategy (shuffling, SRRW). (e) Different sampling strategies in the DSGD algorithm with time-varying topology (DSGD-VT). (f) Different sampling strategies in the DFL algorithm with increasing communication interval. "], "img_footnote": [], "page_idx": 8}, {"type": "text", "text": "", "page_idx": 8}, {"type": "text", "text": "The simulation results are obtained through 120 independent trials. In Figure 2(a), we assume that the first group of agents perform either i.i.d. sampling or shuffilng method, while the other group of agents all change their sampling strategies from baseline SRW to NBRW and SRRW, as shown in the legend. This plot shows that improved sampling strategy leads to overall convergence speedup since NBRW and SRRW are more efficient than SRW [38, 25]. Furthermore, it illustrates that SRRW is significantly more efficient than NBRW in this simulation setup, i.e., $\\mathbf{SRRW}\\gg\\mathbf{NBRW}>\\mathbf{SRW}$ in terms of sampling efficiency. While keeping the second group of agents unchanged, we can see that shuffilng method outperforms i.i.d. sampling with smaller asymptotic MSE. However, shuffilng method may not perform perfectly for small time $n$ due to slow mixing behavior in the initial period, which is also observed in the single-agent scenario in [65, 1, 38]. The error bar therein also indicates that the random-walk sampling strategy has a significant impact on the overall system performance and SRRW has smaller variance than NBRW and SRW. ", "page_idx": 8}, {"type": "text", "text": "In Figure 2(b), we let the first group of agents perform i.i.d. sampling while only changing a portion of agents in the second group to upgrade from SRW to SRRW, e.g., 30 SRW 20 SRRW in the legend means that there are 30 agents using SRW while the rest 20 agents in the second group upgrade to SRRW. We observe that more agents willing to upgrade from SRW to SRRW lead to smaller asymptotic MSE, as predicted by Theorem 3.3 and Remark 3. This improvement in MSE reduction doesn\u2019t scale linearly with more agents adopting SRRW because each agent holds its own dataset that are not necessarily identical, resulting in different individual limiting covariance matrices $\\mathbf{V}_{i}\\neq\\mathbf{V}_{j}$ . ", "page_idx": 8}, {"type": "text", "text": "While maintaining i.i.d. sampling for the first group of agents, we compare the performance when the second group of agents in Figure 2(c) employ NBRW or SRRW. Remarkably, the case with only 10 agents out of 50 agents in the second group adopting far more efficient sampling strategy (40 SRW, 10 SRRW) through incentives or compliance already produces a smaller MSE than all 50 agents using slightly better strategy (50 NBRW). The performance gap becomes even more pronounced when 20 agents upgrade from SRW to SRRW (30 SRW, 20 SRRW). We show that the performance of a distributed system can be improved significantly when a small proportion of agents adopt highly efficient sampling strategies. ", "page_idx": 8}, {"type": "text", "text": "", "page_idx": 9}, {"type": "text", "text": "Figure 2(d) empirically illustrates the asymptotic network independence property via four algorithms under our UD-SGD framework: Centralized SGD (communication interval $K=1$ , communication matrix $\\mathbf{W}=\\mathbf{11}^{T}/N)$ ; LSGD-FP (FL with full client participation, $K=5$ , $\\mathbf{W}=\\mathbf{11}^{T}/N)$ ; DSGDVT (DSGD with time-varying topologies, randomly chosen from 5 doubly stochastic matrices); DFL (decentralized $\\mathrm{FL}$ with fixed MH-generated W and increasing communication interval $K_{l}=$ $\\operatorname*{max}\\{1,\\log(l)\\}$ after $l$ -th aggregation). We fix the sampling strategy (shuffling, SRRW) throughout this plot. All four algorithms overlap around 1000 steps, implying that they have entered the asymptotic regime with similar performance where the CLT result dominates, implying the asymptotic network independence in the long run. ", "page_idx": 9}, {"type": "text", "text": "Figure 2(e) and 2(f) show the performance of different sampling strategies in DSGD-VT and DFL algorithms in terms of MSE. Both plots consistently demonstrate that improving agent\u2019s sampling strategies (e.g., shuffilng $>$ iid sampling, and $\\mathrm{SRRW}>\\mathrm{NBRW}>\\mathrm{SRW})$ leads to faster convergence with smaller MSE, supporting our theory. ", "page_idx": 9}, {"type": "text", "text": "Furthermore, in Appendix G.2, we simulate an image classification task with CIFAR-10 dataset [44] by training a 5-layer CNN and ResNet-18 model collaboratively through a 10-agent network. The result is illustrated in Figure 3, where SRRW outperforms NBRW and SRW as expected. In summary, we find that upgrading even a small portion of agents to efficient sampling strategies (e.g., shuffling method, NBRW, SRRW under different dataset structures) improves system performance in UD-SGD. These results are consistent in binary and image classification tasks, underscoring that every agent matters in distributed learning. ", "page_idx": 9}, {"type": "text", "text": "5 Conclusion ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "In this work, we develop an UD-SGD framework that establishes the CLT of various distributed algorithms with Markovian sampling. We overcome technical challenges such as quantifying consensus error under very general communication patterns and decomposing Markovian noise through the Poisson equation, which extends the analysis beyond the single-agent scenario. We demonstrate that even if only a few agents optimize their sampling strategies, the entire distributed system will benefti with a smaller limiting covariance in the CLT, suggesting a reduced MSE. This finding challenges the current established upper bounds where the worst-performing agent leads the pack. Future studies could pivot towards developing fine-grained finite-time bounds to individually characterize each agent\u2019s behavior, and theoretically analyze the effect of SRRW in UD-SGD. ", "page_idx": 9}, {"type": "text", "text": "6 Acknowledgments and Disclosure of Funding ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "We thank the anonymous reviewers for their constructive comments. This work was supported in part by National Science Foundation under Grant Nos. CNS-2007423, IIS-1910749, and IIS-2421484. ", "page_idx": 9}, {"type": "text", "text": "References ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "[1] Kwangjun Ahn, Chulhee Yun, and Suvrit Sra. Sgd with shuffling: optimal rates without component convexity and large epoch requirements. In Proceedings of the 34th International Conference on Neural Information Processing Systems, pages 17526\u201317535, 2020.   \n[2] Noga Alon, Itai Benjamini, Eyal Lubetzky, and Sasha Sodin. Non-backtracking random walks mix faster. Communications in Contemporary Mathematics, 9(04):585\u2013603, 2007.   \n[3] Christophe Andrieu, \u00c9ric Moulines, and Pierre Priouret. Stability of stochastic approximation under verifiable conditions. SIAM Journal on control and optimization, 44(1):283\u2013312, 2005.   \n[4] Ghadir Ayache, Venkat Dassari, and Salim El Rouayheb. Walk for learning: A random walk approach for federated learning from heterogeneous data. IEEE Journal on Selected Areas in Communications, 41(4):929\u2013940, 2023.   \n[5] Anna Ben-Hamou, Eyal Lubetzky, and Yuval Peres. Comparing mixing times on sparse random graphs. In Proceedings of the Twenty-Ninth Annual ACM-SIAM Symposium on Discrete Algorithms, pages 1734\u20131740. SIAM, 2018.   \n[6] Albert Benveniste, Michel M\u00e9tivier, and Pierre Priouret. Adaptive algorithms and stochastic approximations, volume 22. Springer Science & Business Media, 2012.   \n[7] Pascal Bianchi, Gersende Fort, and Walid Hachem. Performance of a distributed stochastic approximation algorithm. IEEE Transactions on Information Theory, 59(11):7405\u20137418, 2013. [8] Patrick Billingsley. Convergence of probability measures. John Wiley & Sons, 2013. [9] Vivek Borkar, Shuhang Chen, Adithya Devraj, Ioannis Kontoyiannis, and Sean Meyn. The ode method for asymptotic statistics in stochastic approximation and reinforcement learning. arXiv preprint arXiv:2110.14427, 2021.   \n[10] V.S. Borkar. Stochastic Approximation: A Dynamical Systems Viewpoint: Second Edition. Texts and Readings in Mathematics. Hindustan Book Agency, 2022.   \n[11] Stephen Boyd, Neal Parikh, Eric Chu, Borja Peleato, Jonathan Eckstein, et al. Distributed optimization and statistical learning via the alternating direction method of multipliers. Foundations and Trends\u00ae in Machine learning, 3(1):1\u2013122, 2011.   \n[12] Pierre Br\u00e9maud. Markov chains: Gibbs fields, Monte Carlo simulation, and queues, volume 31. Springer Science & Business Media, 2013.   \n[13] Steve Brooks, Andrew Gelman, Galin Jones, and Xiao-Li Meng. Handbook of markov chain monte carlo. CRC press, 2011.   \n[14] Chih-Chung Chang and Chih-Jen Lin. Libsvm: a library for support vector machines. ACM transactions on intelligent systems and technology (TIST), 2(3):1\u201327, 2011.   \n[15] VijaySekhar Chellaboina and Wassim M Haddad. Nonlinear dynamical systems and control: A Lyapunov-based approach. Princeton University Press, 2008.   \n[16] Vishnu Pandi Chellapandi, Antesh Upadhyay, Abolfazl Hashemi, and Stanislaw H Zak. On the convergence of decentralized federated learning under imperfect information sharing. arXiv preprint arXiv:2303.10695, 2023.   \n[17] Shuhang Chen, Adithya Devraj, Ana Busic, and Sean Meyn. Explicit mean-square error bounds for monte-carlo and linear stochastic approximation. In International Conference on Artificial Intelligence and Statistics, pages 4173\u20134183. PMLR, 2020.   \n[18] Wenlin Chen, Samuel Horv\u00e1th, and Peter Richt\u00e1rik. Optimal client sampling for federated learning. Transactions on Machine Learning Research, 2022.   \n[19] Anna Choromanska, Mikael Henaff, Michael Mathieu, G\u00e9rard Ben Arous, and Yann LeCun. The loss surfaces of multilayer networks. In Artificial intelligence and statistics, pages 192\u2013204, 2015.   \n[20] Yann N Dauphin, Razvan Pascanu, Caglar Gulcehre, Kyunghyun Cho, Surya Ganguli, and Yoshua Bengio. Identifying and attacking the saddle point problem in high-dimensional nonconvex optimization. In Advances in neural information processing systems, volume 27, 2014.   \n[21] Burgess Davis. On the intergrability of the martingale square function. Israel Journal of Mathematics, 8:187\u2013190, 1970.   \n[22] Bernard Delyon. Stochastic approximation with decreasing gain: Convergence and asymptotic theory. Technical report, 2000.   \n[23] Bernard Delyon, Marc Lavielle, and Eric Moulines. Convergence of a stochastic approximation version of the em algorithm. Annals of statistics, pages 94\u2013128, 1999.   \n[24] Thinh Doan, Siva Maguluri, and Justin Romberg. Finite-time analysis of distributed td (0) with linear function approximation on multi-agent reinforcement learning. In International Conference on Machine Learning, pages 1626\u20131635. PMLR, 2019.   \n[25] Vishwaraj Doshi, Jie Hu, and Do Young Eun. Self-repellent random walks on general graphs\u2013 achieving minimal sampling variance via nonlinear markov chains. In International Conference on Machine Learning. PMLR, 2023.   \n[26] John C Duchi, Alekh Agarwal, Mikael Johansson, and Michael I Jordan. Ergodic mirror descent. SIAM Journal on Optimization, 22(4):1549\u20131578, 2012.   \n[27] Martin Dyer, Alan Frieze, Ravi Kannan, Ajai Kapoor, Ljubomir Perkovic, and Umesh Vazirani. A mildly exponential time algorithm for approximating the number of solutions to a multidimensional knapsack problem. Combinatorics, Probability and Computing, 2(3):271\u2013284, 1993.   \n[28] Mathieu Even. Stochastic gradient descent under markovian sampling schemes. In International Conference on Machine Learning, 2023.   \n[29] Gersende Fort. Central limit theorems for stochastic approximation with controlled markov chain dynamics. ESAIM: Probability and Statistics, 19:60\u201380, 2015.   \n[30] Yann Fraboni, Richard Vidal, Laetitia Kameni, and Marco Lorenzi. A general theory for client sampling in federated learning. In International Workshop on Trustworthy Federated Learning in conjunction with IJCAI, 2022.   \n[31] Avishek Ghosh, Jichan Chung, Dong Yin, and Kannan Ramchandran. An efficient framework for clustered federated learning. In Proceedings of the 34th International Conference on Neural Information Processing Systems, pages 19586\u201319597, 2020.   \n[32] Yuanxiong Guo, Ying Sun, Rui Hu, and Yanmin Gong. Hybrid local SGD for federated learning with heterogeneous communications. In International Conference on Learning Representations, 2022.   \n[33] P. Hall, C.C. Heyde, Z.W. Birnbauam, and E. Lukacs. Martingale Limit Theory and Its Application. Communication and Behavior. Elsevier Science, 2014.   \n[34] Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep residual learning for image recognition. In Proceedings of the IEEE conference on computer vision and pattern recognition, pages 770\u2013778, 2016.   \n[35] Hadrien Hendrikx. A principled framework for the design and analysis of token algorithms. In International Conference on Artificial Intelligence and Statistics, pages 470\u2013489. PMLR, 2023.   \n[36] Roger A. Horn and Charles R. Johnson. Topics in Matrix Analysis. Cambridge University Press, 1991.   \n[37] Seyyedali Hosseinalipour, Sheikh Shams Azam, Christopher G Brinton, Nicolo Michelusi, Vaneet Aggarwal, David J Love, and Huaiyu Dai. Multi-stage hybrid federated learning over large-scale d2d-enabled fog networks. IEEE/ACM Transactions on Networking, 2022.   \n[38] Jie Hu, Vishwaraj Doshi, and Do Young Eun. Efficiency ordering of stochastic gradient descent. In Advances in Neural Information Processing Systems, 2022.   \n[39] Jie Hu, Vishwaraj Doshi, and Do Young Eun. Accelerating distributed stochastic optimization via self-repellent random walks. In The Twelfth International Conference on Learning Representations, 2024.   \n[40] Mark Jerrum and Alistair Sinclair. The markov chain monte carlo method: an approach to approximate counting and integration. Approximation Algorithms for NP-hard problems, PWS Publishing, 1996.   \n[41] Thomas Kailath, Ali H Sayed, and Babak Hassibi. Linear estimation. Prentice Hall, 2000.   \n[42] Sajad Khodadadian, Pranay Sharma, Gauri Joshi, and Siva Theja Maguluri. Federated reinforcement learning: Linear speedup under markovian sampling. In International Conference on Machine Learning, pages 10997\u201311057, 2022.   \n[43] Anastasia Koloskova, Nicolas Loizou, Sadra Boreiri, Martin Jaggi, and Sebastian Stich. A unified theory of decentralized sgd with changing topology and local updates. In International Conference on Machine Learning, pages 5381\u20135393, 2020.   \n[44] Alex Krizhevsky and Geoffrey Hinton. Learning multiple layers of features from tiny images. Technical report, 2009.   \n[45] Harold Kushner and G George Yin. Stochastic approximation and recursive algorithms and applications, volume 35. Springer Science & Business Media, 2003.   \n[46] Anusha Lalitha, Shubhanshu Shekhar, Tara Javidi, and Farinaz Koushanfar. Fully decentralized federated learning. In Advances in neural information processing systems, 2018.   \n[47] Batiste Le Bars, Aur\u00e9lien Bellet, Marc Tommasi, Erick Lavoie, and Anne-Marie Kermarrec. Refined convergence and topology learning for decentralized sgd with heterogeneous data. In International Conference on Artificial Intelligence and Statistics, pages 1672\u20131702. PMLR, 2023.   \n[48] Chul-Ho Lee, Xin Xu, and Do Young Eun. Beyond random walk and metropolis-hastings samplers: why you should not backtrack for unbiased graph sampling. ACM SIGMETRICS Performance evaluation review, 40(1):319\u2013330, 2012.   \n[49] Jure Leskovec and Andrej Krevl. Snap datasets: Stanford large network dataset collection, 2014.   \n[50] Xiang Li, Kaixuan Huang, Wenhao Yang, Shusen Wang, and Zhihua Zhang. On the convergence of fedavg on non-iid data. In International Conference on Learning Representations, 2020.   \n[51] Xiang Li, Jiadong Liang, Xiangyu Chang, and Zhihua Zhang. Statistical estimation and online inference via local sgd. In Proceedings of Thirty Fifth Conference on Learning Theory, volume 178 of Proceedings of Machine Learning Research, pages 1613\u20131661, 02\u201305 Jul 2022.   \n[52] Xiang Li, Jiadong Liang, and Zhihua Zhang. Online statistical inference for nonlinear stochastic approximation with markovian data. arXiv preprint arXiv:2302.07690, 2023.   \n[53] Yunming Liao, Yang Xu, Hongli Xu, Lun Wang, and Chen Qian. Adaptive configuration for heterogeneous participants in decentralized federated learning. In IEEE INFOCOM 2023. IEEE, 2023.   \n[54] Adwaitvedant S Mathkar and Vivek S Borkar. Nonlinear gossip. SIAM Journal on Control and Optimization, 54(3):1535\u20131557, 2016.   \n[55] Brendan McMahan, Eider Moore, Daniel Ramage, Seth Hampson, and Blaise Aguera y Arcas. Communication-efficient learning of deep networks from decentralized data. In Artificial intelligence and statistics, pages 1273\u20131282. PMLR, 2017.   \n[56] Sean Meyn. Control systems and reinforcement learning. Cambridge University Press, 2022.   \n[57] Antonietta Mira. Ordering and improving the performance of monte carlo markov chains. Statistical Science, pages 340\u2013350, 2001.   \n[58] Gemma Morral, Pascal Bianchi, and Gersende Fort. Success and failure of adaptation-diffusion algorithms with decaying step size in multiagent networks. IEEE Transactions on Signal Processing, 65(11):2798\u20132813, 2017.   \n[59] Wenlong Mou, Chris Junchi Li, Martin J Wainwright, Peter L Bartlett, and Michael I Jordan. On linear stochastic approximation: Fine-grained polyak-ruppert and non-asymptotic concentration. In Conference on Learning Theory, pages 2947\u20132997. PMLR, 2020.   \n[60] Giovanni Neglia, Chuan Xu, Don Towsley, and Gianmarco Calbi. Decentralized gradient methods: does topology matter? In International Conference on Artificial Intelligence and Statistics, pages 2348\u20132358. PMLR, 2020.   \n[61] Alex Olshevsky. Asymptotic network independence and step-size for a distributed subgradient method. Journal of Machine Learning Research, 23(69):1\u201332, 2022.   \n[62] Shi Pu, Alex Olshevsky, and Ioannis Ch Paschalidis. Asymptotic network independence in distributed stochastic optimization for machine learning: Examining distributed and centralized stochastic gradient descent. IEEE signal processing magazine, 37(3):114\u2013122, 2020.   \n[63] Christian P Robert, George Casella, and George Casella. Monte Carlo statistical methods, volume 2. Springer, 1999.   \n[64] Sheldon M Ross, John J Kelly, Roger J Sullivan, William James Perry, Donald Mercer, Ruth M Davis, Thomas Dell Washburn, Earl V Sager, Joseph B Boyce, and Vincent L Bristow. Stochastic processes, volume 2. Wiley New York, 1996.   \n[65] Itay Safran and Ohad Shamir. How good is sgd with random shuffling? In Conference on Learning Theory, pages 3250\u20133284. PMLR, 2020.   \n[66] R. Srikant. Rates of Convergence in the Central Limit Theorem for Markov Chains, with an Application to TD Learning. arXiv e-prints, page arXiv:2401.15719, January 2024.   \n[67] Sebastian U Stich. Local sgd converges fast and communicates little. In International Conference on Learning Representations, 2018.   \n[68] Tao Sun, Dongsheng li, and Bao Wang. On the decentralized stochastic gradient descent with markov chain sampling. IEEE Transactions on Signal Processing, PP, 07 2023.   \n[69] Tao Sun, Yuejiao Sun, and Wotao Yin. On markov chain gradient descent. In Advances in neural information processing systems, volume 31, 2018.   \n[70] M Vidyasagar. Convergence of stochastic approximation via martingale and converse lyapunov methods. arXiv preprint arXiv:2205.01303, 2022.   \n[71] Hoi-To Wai. On the convergence of consensus algorithms with markovian noise and gradient bias. In 2020 59th IEEE Conference on Decision and Control (CDC), pages 4897\u20134902. IEEE, 2020.   \n[72] Han Wang, Aritra Mitra, Hamed Hassani, George J Pappas, and James Anderson. Federated temporal difference learning with linear function approximation under environmental heterogeneity. arXiv preprint arXiv:2302.02212, 2023.   \n[73] Jianyu Wang, Qinghua Liu, Hao Liang, Gauri Joshi, and H. Vincent Poor. Tackling the objective inconsistency problem in heterogeneous federated optimization. In Advances in Neural Information Processing Systems, volume 33, pages 7611\u20137623, 2020.   \n[74] Shiqiang Wang and Mingyue Ji. A unified analysis of federated learning with arbitrary client participation. In Advances in neural information processing systems, 2022.   \n[75] Stephan Wojtowytsch. Stochastic gradient descent with noise of machine learning type part i: Discrete time analysis. Journal of Nonlinear Science, 33(3):45, 2023.   \n[76] Blake Woodworth, Kumar Kshitij Patel, Sebastian Stich, Zhen Dai, Brian Bullins, Brendan Mcmahan, Ohad Shamir, and Nathan Srebro. Is local sgd better than minibatch sgd? In International Conference on Machine Learning, pages 10334\u201310343. PMLR, 2020.   \n[77] Hao Ye, Le Liang, and Geoffrey Ye Li. Decentralized federated learning with unreliable communications. IEEE Journal of Selected Topics in Signal Processing, 16(3):487\u2013500, 2022.   \n[78] Chulhee Yun, Shashank Rajput, and Suvrit Sra. Minibatch vs local SGD with shuffling: Tight convergence bounds and beyond. In International Conference on Learning Representations, 2022.   \n[79] Chulhee Yun, Suvrit Sra, and Ali Jadbabaie. Open problem: Can single-shuffle sgd be better than reshuffilng sgd and gd? In Proceedings of Thirty Fourth Conference on Learning Theory, volume 134, pages 4653\u20134658. PMLR, Aug 2021.   \n[80] Sihan Zeng, Thinh T Doan, and Justin Romberg. Finite-time convergence rates of decentralized stochastic approximation with applications in multi-agent and multi-task learning. IEEE Transactions on Automatic Control, 2022.   \n[81] Yue Zhao, Meng Li, Liangzhen Lai, Naveen Suda, Damon Civin, and Vikas Chandra. Federated learning with non-iid data. arXiv preprint arXiv:1806.00582, 2018. ", "page_idx": 9}, {"type": "text", "text": "", "page_idx": 10}, {"type": "text", "text": "", "page_idx": 11}, {"type": "text", "text": "", "page_idx": 12}, {"type": "text", "text": "", "page_idx": 13}, {"type": "text", "text": "", "page_idx": 14}, {"type": "text", "text": "A Discussion of Assumption 2.3-ii) ", "text_level": 1, "page_idx": 15}, {"type": "text", "text": "A.1 Suitable choices of $K_{l}$ ", "text_level": 1, "page_idx": 15}, {"type": "text", "text": "When wet let $K_{l}\\;\\sim\\;\\log(l)$ (resp. $K_{l}\\;\\sim\\;\\log\\log(l))$ , as suggested by [51], it trivially satisfies $K_{\\tau_{n}}=o\\big(\\gamma_{n}^{-1/2(L+1)}\\big)=o\\big(n^{1/2(L+1)}\\big)$ since by definition $K_{\\tau_{n}}<K_{n}\\sim\\log(n)$ (resp. $\\log\\log(n))$ , and $\\log(n)=o(n^{\\epsilon})$ (resp. $\\log\\log(n)=o(n^{\\epsilon}))$ for any $\\epsilon>0$ . Besides, $\\begin{array}{r}{\\sum_{n}\\eta_{n}^{2}=\\sum_{n}\\gamma_{n}^{2}K_{\\tau_{n}}^{2(L+1)}\\lesssim}\\end{array}$ $\\begin{array}{r}{\\sum_{n}n^{-2}n^{2(L+1)\\epsilon}=\\sum_{n}n^{2(L+1)\\epsilon-2}}\\end{array}$ . To ensure $\\textstyle\\sum_{n}\\eta_{n}^{2}<\\infty$ , it is suff icient to ha ve $2(L\\!+\\!1)\\epsilon-2<$ $-1$ , or equivalently, $\\dot{\\epsilon}\\,<\\,1/2(L+1)$ . Since $\\epsilon$ can be arbitrarily small to satisfy the condition, $\\textstyle\\sum_{n}\\eta_{n}^{2}<^{\\prime}\\infty$ is satisfied. When $K_{l}\\sim\\log(l)$ , we can rewrite the last condition as ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\frac{\\eta_{n_{l}+1}}{\\eta_{n_{l+1}+1}}=\\frac{\\gamma_{n_{l}+1}}{\\gamma_{n_{l+1}+1}}\\frac{K_{l}^{L+1}}{K_{l+1}^{L+1}}=\\left(\\frac{n_{l+1}+1}{n_{l}+1}\\right)\\left(\\frac{\\log(l+1)+1}{\\log(l)+1}\\right)^{L+1}}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad=\\left(1+\\frac{K_{l+1}}{n_{l}+1}\\right)\\left(\\frac{\\log(l+1)+1}{\\log(l)+1}\\right)^{L+1},}\\end{array}\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "where we have $n_{l}\\sim\\log(l!)$ such that $K_{l+1}/n_{l}=\\log(l+1)/\\log(l!)\\to0$ and $\\log(l\\!+\\!1)/\\log(l)\\to1$ as $l~\\rightarrow~\\infty$ , which leads to $\\begin{array}{r}{\\operatorname*{lim}_{n\\to\\infty}\\eta_{n_{l}+1}/\\eta_{n_{l+1}+1}\\;=\\;1}\\end{array}$ . Similarly, for $K_{l}\\;\\sim\\;\\log\\log(l)$ , we have $n_{l}\\sim\\log(\\prod_{s=1}^{l}\\log(s))$ such that $K_{l+1}/n_{l}\\sim\\log\\log(l+1)/\\log\\log(\\prod_{s=1}^{l}\\log(s))\\to0$ and $\\log\\log(l+1)/\\log\\log(l)\\to1$ as $l\\rightarrow\\infty$ , which also leads to $\\begin{array}{r}{\\operatorname*{lim}_{n\\to\\infty}\\eta_{n_{l}+1}/\\eta_{n_{l+1}+1}=1}\\end{array}$ . ", "page_idx": 15}, {"type": "text", "text": "A.2 Practical implications of Assumption 2.3-ii) ", "text_level": 1, "page_idx": 15}, {"type": "text", "text": "In this assumption, we allow the number of local iterations to go to infinity asymptotically. In distributed learning environments such as mobile, IoT, and wireless sensor networks, where nodes are often constrained by battery life, increasing communication interval in Assumption 2.3-ii) plays a crucial role in balancing energy costs with communication effectiveness. It allows agents to communicate more frequently early on, leading to a faster initial convergence to the neighborhood of $\\theta^{*}$ . Then, we slow down the communication frequency between agents to conserve energy, leveraging the diminishing returns on accuracy improvements from additional communications. ", "page_idx": 15}, {"type": "text", "text": "Consider the scenario where devices across multiple clusters collaborate on a distributed optimization task, utilizing local datasets. Devices within each cluster form a communication network that allows a virtual agent to perform a heterogeneous Markov chain trajectory via random walk, or an i.i.d. sequence in a complete graph with self-loops, depending on the application context. Each cluster features an edge server that supports the exchange of model estimates with neighboring clusters. By performing $K$ local updates before uploading these to the cluster\u2019s edge server, the model benefits from reduced communication overhead. As the frequency of updates between devices and edge servers decreases \u2014 optimized by gradually increasing $K$ \u2014 we effectively lower communication costs, particularly as the model estimation $\\theta_{n}$ is close to $\\theta^{*}$ . ", "page_idx": 15}, {"type": "text", "text": "B Proof of Lemma 3.1 ", "text_level": 1, "page_idx": 15}, {"type": "text", "text": "Let $\\mathbf{J}_{\\perp}\\triangleq\\mathbf{I}_{N}-\\mathbf{J}\\in\\mathbb{R}^{N\\times N}$ and $\\mathcal{I}_{\\perp}\\triangleq\\mathbf{J}_{\\perp}\\otimes\\mathbf{I}_{d}\\in\\mathbb{R}^{N d\\times N d}$ , where $\\otimes$ is the Kronecker product. Let $\\Theta_{n}\\,=\\,[(\\theta_{n}^{1})^{T},\\cdot\\cdot\\cdot\\cdot\\,,(\\theta_{n}^{N})^{T}]^{T}\\,\\in\\,\\mathbb{R}^{N d}$ . Then, motivated by [58], we define a sequence $\\phi_{n}\\triangleq$ $\\eta_{n+1}^{-1}\\mathcal{I}_{\\perp}\\Theta_{n}\\in\\mathbb{R}^{N d}$ in the increasing communication interval case (resp. $\\phi_{n}\\triangleq\\gamma_{n+1}^{-1}\\mathcal{J}_{\\perp}\\Theta_{n}$ in the bounded communication interval case), where $\\eta_{n+1}$ is defined in Assumption 2.3-ii). ${\\mathcal{I}}_{\\perp}\\Theta_{n}\\,=$ $\\begin{array}{r}{\\Theta_{n}-\\frac{1}{N}(\\mathbf{1}\\mathbf{1}^{T}\\otimes\\mathbf{I}_{d})\\Theta_{n}}\\end{array}$ represents the consensus error of the model. ", "page_idx": 15}, {"type": "text", "text": "We first give the following lemma that shows the pathwise boundedness of $\\phi_{n}$ ", "page_idx": 15}, {"type": "text", "text": "Lemma B.1. Let Assumptions 2.1, 2.3, 2.4 and 2.5 hold. For any compact set $\\Omega\\,\\subset\\,\\mathbb{R}^{N d}$ , the sequence $\\phi_{n}$ satisfies $\\begin{array}{r}{\\operatorname*{sup}_{n}\\mathbb{E}[\\|\\phi_{n}\\|^{2}\\mathbb{1}_{\\cap_{j\\leq n-1}\\{\\Theta_{j}\\in\\Omega\\}}]<\\infty}\\end{array}$ . ", "page_idx": 15}, {"type": "text", "text": "Lemma B.1 and Assumption 2.3-ii) imply that for any $n\\,\\geq\\,0,\\,\\mathbb{E}[\\|\\mathcal{I}_{\\bot}\\Theta_{n}\\|^{2}\\mathbb{1}_{\\cap_{j\\leq n-1}\\{\\Theta_{j}\\in\\Omega\\}}]\\,=$ $\\eta_{n+1}^{2}\\mathbb{E}[\\|\\phi_{n}\\|^{2}\\mathbb{1}_{\\cap_{j\\leq n-1}\\{\\Theta_{j}\\in\\Omega\\}}]\\leq C\\eta_{n+1}^{2}$ for some constant $C$ that depends on $C_{1}$ and $\\Omega$ . Along with Assumption 2.4 such that $\\|\\mathcal{I}_{\\bot}\\Theta_{n}\\|$ is always bounded per each trajectory, it means ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\|\\mathcal{I}_{\\perp}\\Theta_{n}\\|\\mathbb{1}_{\\cap_{\\substack{\\zeta\\leq n-1}}\\left\\{\\Theta_{j}\\in\\Omega\\right\\}}=O(\\eta_{n})\\quad a.s.\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "Let $\\{\\Omega_{m}\\}_{m\\ge0}$ be a sequence of increasing compact subset of $\\mathbb{R}^{N d}$ such that $\\bigcup_{m}\\Omega_{m}=\\mathbb{R}^{N d}$ . Then, we know that for any $m\\geq0$ , ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\|\\mathcal{I}_{\\perp}\\Theta_{n}\\|\\mathbb{1}_{\\cap_{j\\leq n-1}\\left\\{\\Theta_{j}\\in\\Omega_{m}\\right\\}}=O(\\eta_{n})\\quad a.s.\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "(17) indicates either one of the following two cases: ", "page_idx": 16}, {"type": "text", "text": "\u2022 there exists some trajectory-dependent index $m^{\\prime}$ such that each trajectory $\\{\\Theta_{n}\\}_{n\\ge0}$ is always within the compact set $\\Omega_{m^{\\prime}}$ , i.e., $\\mathbb{1}_{\\cap_{j\\le n}\\{\\Theta_{j}\\in\\Omega_{m^{\\prime}}\\}}=1$ (satisfied by the construction of increasing compact sets $\\{\\Omega_{m}\\}_{m\\ge0}$ and Assumption 2.4), and we have $\\|\\mathcal{J}_{\\perp}\\Theta_{n}\\|=O(\\eta_{n})$ such that $\\operatorname*{lim}_{n\\to\\infty}\\mathcal{J}_{\\perp}\\Theta_{n}=\\mathbf{0}$ ;   \n\u2022 $\\Theta_{n}$ will escape the compact set $\\Omega_{m}$ eventually for any $m\\,\\geq\\,0$ in finite time such that $\\mathbb{1}_{\\cap_{j\\le n-1}\\{\\Theta_{j}\\in\\Omega_{m}\\}}=0$ when $n$ is large enough. ", "page_idx": 16}, {"type": "text", "text": "We can see the second case contradicts Assumption 2.4 because we assume every trajectory $\\{\\Theta_{n}\\}_{n\\ge0}$ is within some compact set. Therefore, (17) for any $m\\geq0$ is equivalent to showing $\\|{\\mathcal{I}}_{\\perp}\\Theta_{n}\\|=$ ${\\cal O}(\\eta_{n})$ and $\\begin{array}{r}{\\operatorname*{lim}_{n\\to\\infty}\\mathcal{I}_{\\perp}\\Theta_{n}=\\mathbf{0}}\\end{array}$ . Under Assumption 2.3-i) we can obtain similar result $\\|\\mathcal{I}_{\\perp}\\Theta_{n}\\|=$ $O(\\gamma_{n})$ by following the same steps as above, which completes the proof of Lemma 3.1. ", "page_idx": 16}, {"type": "text", "text": "Proof of Lemma B.1. We begin by rewriting (6) in the matrix form, ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\Theta_{n+1}=\\mathcal{W}_{n}\\left(\\Theta_{n}-\\gamma_{n+1}\\nabla\\mathbf{F}(\\Theta_{n},\\mathbf{X}_{n})\\right),\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "where $\\mathbf{X}_{n}\\triangleq(X_{n}^{1},X_{n}^{2},\\cdot\\cdot\\cdot\\mathbf{\\Phi},X_{n}^{N})$ and $\\nabla{\\mathbf F}(\\Theta_{n},{\\mathbf X}_{n})\\triangleq[\\nabla F_{1}(\\theta_{n}^{1},X_{n}^{1})^{T},\\cdot\\cdot\\cdot\\,,\\nabla F_{N}(\\theta_{n}^{N},X_{n}^{N})^{T}]^{T}\\in$ $\\mathbb{R}^{N d}$ . Recall $\\begin{array}{r}{\\theta_{n}\\triangleq\\frac{1}{N}\\sum_{i=1}^{N}\\theta_{n}^{i}\\in\\mathbb{R}^{d}}\\end{array}$ and we have $\\begin{array}{r}{[\\theta_{n}^{T},\\cdot\\cdot\\cdot\\cdot,\\theta_{n}^{T}]^{T}=\\frac{1}{N}(\\mathbf{11}^{T}\\otimes\\mathbf{I}_{d})\\Theta_{n}\\in\\mathbb{R}^{N d}}\\end{array}$ . ", "page_idx": 16}, {"type": "text", "text": "Case 1 (Increasing communication interval $K_{\\tau_{n}}$ ): By left multiplying (18) with $\\begin{array}{r}{\\frac{1}{N}\\left(\\mathbf{1}\\mathbf{1}^{T}\\otimes\\mathbf{I}_{d}\\right)}\\end{array}$ , along with $\\gamma_{n+1}=\\eta_{n+1}/K_{\\tau_{n+1}}^{L+1}$ in Assumption 2.3-ii), we have the following iteration ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\frac{1}{N}(\\mathbf{11}^{T}\\otimes\\mathbf{I}_{d})\\Theta_{n+1}=\\frac{1}{N}(\\mathbf{11}^{T}\\otimes\\mathbf{I}_{d})\\Theta_{n}-\\eta_{n+1}\\frac{1}{N}(\\mathbf{11}^{T}\\otimes\\mathbf{I}_{d})\\frac{\\nabla\\mathbf{F}(\\Theta_{n},\\mathbf{X}_{n})}{K_{\\tau_{n+1}}^{L+1}},\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "where the equality comes from $\\begin{array}{r}{\\frac{1}{N}(\\mathbf{1}\\mathbf{1}^{T}\\otimes\\mathbf{I}_{d})\\mathcal{W}_{n}=\\frac{1}{N}(\\mathbf{1}\\mathbf{1}^{T}\\mathbf{W}_{n}\\otimes\\mathbf{I}_{d})=\\frac{1}{N}(\\mathbf{1}\\mathbf{1}^{T}\\otimes\\mathbf{I}_{d})}\\end{array}$ . With (18) and (19), we have ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\quad\\Theta_{n+1}-\\cfrac{1}{N}(\\mathbf{1}^{\\mathbf{T}}\\otimes\\mathbf{I}_{d})\\Theta_{n+1}}\\\\ &{=\\left(\\mathcal{W}_{n}-\\cfrac{1}{N}\\left(\\mathbf{1}^{\\mathbf{T}}\\otimes\\mathbf{I}_{d}\\right)\\right)\\Theta_{n}-\\eta_{n+1}\\left(\\mathcal{W}_{n}-\\cfrac{1}{N}(\\mathbf{1}^{\\mathbf{T}}\\otimes\\mathbf{I}_{d})\\right)\\cfrac{\\nabla\\mathbf{F}(\\Theta_{n},\\mathbf{X}_{n})}{K_{\\tau_{n+1}}^{L+1}}}\\\\ &{=(\\mathbf{J}_{\\bot}\\mathbf{W}_{n}\\otimes\\mathbf{I}_{d})\\mathcal{I}_{\\bot}\\Theta_{n}-\\eta_{n+1}(\\mathbf{J}_{\\bot}\\mathbf{W}_{n}\\otimes\\mathbf{I}_{d})\\cfrac{\\nabla\\mathbf{F}(\\Theta_{n},X_{n})}{K_{\\tau_{n+1}}^{L+1}}}\\\\ &{=\\!\\eta_{n+1}(\\mathbf{J}_{\\bot}\\mathbf{W}_{n}\\otimes\\mathbf{I}_{d})\\left(\\eta_{n+1}^{-1}\\mathcal{I}_{\\bot}\\Theta_{n}-\\cfrac{\\nabla\\mathbf{F}(\\Theta_{n},\\mathbf{X}_{n})}{K_{\\tau_{n+1}}^{L+1}}\\right),}\\end{array}\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "where the second equality comes from $\\begin{array}{r}{\\mathcal{W}_{n}-\\frac{1}{N}\\big(\\mathbf{1}\\mathbf{1}^{T}\\otimes\\mathbf{I}_{d}\\big)=\\big(\\mathbf{W}_{n}-\\frac{1}{N}\\mathbf{1}\\mathbf{1}^{T}\\big)\\otimes\\mathbf{I}_{d}=\\mathbf{J}_{\\perp}\\mathbf{W}_{n}\\otimes\\mathbf{I}_{d}}\\end{array}$ and $(\\mathbf{J}_{\\perp}\\mathbf{W}_{n}\\otimes\\mathbf{I}_{d})\\mathcal{I}_{\\perp}=\\mathbf{J}_{\\perp}\\mathbf{W}_{n}\\mathbf{J}_{\\perp}\\otimes\\mathbf{I}_{d}=\\mathbf{J}_{\\perp}\\mathbf{W}_{n}\\otimes\\mathbf{I}_{d}$ . Let $a_{n}\\triangleq\\eta_{n}/\\eta_{n+1}$ , dividing both sides of (20) by $\\eta_{n+2}$ gives ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\phi_{n+1}=a_{n+1}(\\mathbf{J}_{\\perp}\\mathbf{W}_{n}\\otimes\\mathbf{I}_{d})\\left(\\phi_{n}-\\frac{\\nabla\\mathbf{F}(\\Theta_{n},\\mathbf{X}_{n})}{K_{\\tau_{n+1}}^{L+1}}\\right).\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "Define the flitration $\\{\\mathcal{F}_{n}\\}_{n\\ge0}$ as $\\mathcal{F}_{n}\\triangleq\\sigma\\{\\boldsymbol{\\Theta}_{0},\\mathbf{X}_{0},\\mathbf{W}_{0},\\boldsymbol{\\Theta}_{1},\\mathbf{X}_{1},\\mathbf{W}_{1},\\cdots,\\mathbf{X}_{n-1},\\mathbf{W}_{n-1},\\boldsymbol{\\Theta}_{n},\\mathbf{X}_{n}\\}.$ Recursively computing (21) w.r.t the time interval $[n_{l},n_{l+1}]$ gives ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\phi_{n_{l+1}}=\\displaystyle\\left[\\prod_{k=n_{l}+1}^{n_{l+1}}a_{k}\\right]\\left(\\left[\\mathbf{J}_{\\perp}\\prod_{k=n_{l}}^{n_{l+1}-1}\\mathbf{W}_{k}\\right]\\otimes\\mathbf{I}_{d}\\right)\\phi_{n_{l}}}\\\\ &{\\qquad-\\displaystyle\\sum_{k=n_{l}}^{n_{l+1}-1}\\left[\\prod_{i=k+1}^{n_{l+1}}a_{i}\\right]\\left(\\left[\\mathbf{J}_{\\perp}\\prod_{i=k}^{n_{l+1}-1}\\mathbf{W}_{i}\\right]\\otimes\\mathbf{I}_{d}\\right)\\frac{\\nabla\\mathbf{F}(\\boldsymbol\\Theta_{k},\\mathbf{X}_{k})}{K_{l+1}^{L+1}}}\\\\ &{\\qquad=\\displaystyle\\frac{\\eta_{n_{l}+1}}{\\eta_{n_{l+1}+1}}\\left(\\mathbf{J}_{\\perp}\\mathbf{W}_{n_{l}}\\otimes\\mathbf{I}_{d}\\right)\\phi_{n_{l}}-\\displaystyle\\sum_{k=n_{l}}^{n_{l+1}-1}\\frac{\\eta_{n_{l}+1}}{\\eta_{k+2}}\\left(\\mathbf{J}_{\\perp}\\mathbf{W}_{n_{l}}\\otimes\\mathbf{I}_{d}\\right)\\frac{\\nabla\\mathbf{F}(\\boldsymbol\\Theta_{k},\\mathbf{X}_{k})}{K_{l+1}^{L+1}},}\\end{array}\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "where $\\prod$ is the backward multiplier, the second equality comes from $\\mathbf{J}_{\\perp}\\mathbf{W}_{n}\\mathbf{J}_{\\perp}\\ =\\ \\mathbf{J}_{\\perp}\\mathbf{W}_{n}$ and $\\bar{\\mathbf{W}_{k}}^{-}\\ =\\ \\mathbf{I}_{N}$ for $k\\ \\notin\\ \\{n_{l}\\}$ . In Assumption 2.5, we have $\\begin{array}{r l}{\\|\\mathbb{E}_{\\mathbf{W}\\sim\\mathcal{P}_{n_{l}}}[\\mathbf{W}^{T}\\mathbf{J}_{\\bot}\\mathbf{W}]\\|}&{=}\\end{array}$ $\\begin{array}{r}{\\|\\mathbb{E}_{\\mathbf{W}\\sim\\mathcal{P}_{n_{l}}}[\\mathbf{W}^{T}\\mathbf{W}-\\mathbf{J}]\\|\\leq C_{1}<1.}\\end{array}$ . Then, ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{E}\\left\\{\\left\\|\\bar{\\mathbf{S}}_{j}\\times\\bar{\\mathbf{R}}_{j}\\right\\|^{2}\\hat{\\mathbf{P}}_{j}\\right\\}}\\\\ &{=\\left(\\frac{\\mathbf{\\bar{P}}_{j}}{\\Phi_{j}+1}\\right)^{2}\\hat{\\mathbf{P}}_{j}\\mathbf{E}_{W,\\alpha}\\gamma_{\\alpha,\\gamma}\\left[\\left(\\mathbf{\\bar{A}}_{j}\\mathbf{W}_{\\alpha}\\Phi_{j}\\right)^{T}\\bar{\\mathbf{f}}_{j}(\\bar{\\mathbf{X}}_{W}\\Phi_{\\alpha},\\Phi_{0}\\mathbf{L})\\right]\\phi_{\\alpha}\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!}\\\\ &{\\quad-\\alpha\\left[\\sum_{i=1}^{N}\\frac{\\alpha_{i}}{\\Phi_{j}+1}\\frac{\\alpha_{j}}{(\\Phi_{i}-1)!}\\!\\!\\left(\\frac{\\mathbf{\\bar{P}}_{i}}{\\Phi_{j}}(\\mathbf{\\bar{X}}_{W}\\!\\!\\!\\cdot\\!\\!\\mathbf{u}_{i})\\!\\!\\!\\!\\right)^{T}\\!\\!\\!\\!\\!\\!+\\!\\frac{\\left(\\!\\mathbf{\\bar{P}}_{j}(\\bar{\\mathbf{u}},\\mathbf{R}_{i})\\!\\!\\!\\right)^{T}}{N_{i}!}\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\! \n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "where the first inequality comes from $\\mathbf{J}_{\\perp}^{T}\\mathbf{J}_{\\perp}\\,=\\,\\mathbf{J}_{\\perp}$ and $\\eta_{k+2}\\,\\geq\\,\\eta_{n_{l+1}+1}$ for $k\\,\\in\\,[n_{l},n_{l+1}-1]$ . Then, we analyze the norm of the gradient $\\|\\nabla\\mathbf{F}(\\Theta_{k},\\mathbf{X}_{k})\\|$ in the second term on the RHS of (23) conditioned on ${\\mathcal{F}}_{n_{l}}$ . By Assumption 2.4, we assume $\\Theta_{n_{l}}$ is within some compact set $\\Omega$ at time $n_{l}$ such that $\\begin{array}{r}{\\operatorname*{sup}_{i\\in[N],\\dot{X^{i}}\\in\\mathcal{X}_{i}}\\nabla\\bar{F_{i}}(\\theta_{n_{l}}^{i},X^{i})\\leq C_{\\Omega}}\\end{array}$ for some constant $C_{\\Omega}$ . For $n=n_{l}+1$ and any $\\mathbf{X}\\in\\mathcal{X}_{1}\\times\\mathcal{X}_{2}\\times\\cdots\\tilde{\\times}\\,\\mathcal{X}_{N}$ , we have ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\|\\nabla\\mathbf{F}(\\Theta_{n_{l}+1},\\mathbf{X})\\|\\leq\\|\\nabla\\mathbf{F}(\\Theta_{n_{l}+1},\\mathbf{X})-\\nabla\\mathbf{F}(\\Theta_{n_{l}},\\mathbf{X})\\|+\\|\\nabla\\mathbf{F}(\\Theta_{n_{l}},\\mathbf{X})\\|.\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "Considering $\\|\\nabla\\mathbf{F}(\\Theta_{n_{l}},\\mathbf{X})\\|$ , we have $\\operatorname*{sup}_{\\mathbf{X}}\\|\\nabla\\mathbf{F}(\\Theta_{n_{l}},\\mathbf{X})\\|^{2}$ \u2264 $\\begin{array}{r}{\\sum_{i=1}^{N}\\operatorname*{sup}_{X^{i}\\in\\mathcal{X}_{i}}\\|\\nabla F_{i}(\\theta_{n_{l}}^{i},X^{i})\\|^{2}\\leq N C_{\\Omega}^{2}}\\end{array}$ such that $\\lVert\\nabla\\mathbf{F}(\\Theta_{n_{l}},\\mathbf{X})\\rVert\\,\\leq\\,\\sqrt{N}C_{\\Omega}$ . In addition, we ", "page_idx": 17}, {"type": "text", "text": "have ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\|\\nabla\\mathbf{F}(\\Theta_{n_{l}+1},\\mathbf{X})-\\nabla\\mathbf{F}(\\Theta_{n_{l}},\\mathbf{X})\\|^{2}=\\displaystyle\\sum_{i=1}^{N}\\|\\nabla F_{i}(\\theta_{n_{l}+1}^{i},X^{i})-\\nabla F_{i}(\\theta_{n_{l}}^{i},X^{i})\\|^{2}}\\\\ &{\\phantom{\\|}\\leq\\displaystyle\\sum_{i=1}^{N}L^{2}\\|\\theta_{n_{l}+1}^{i}-\\theta_{n_{l}}^{i}\\|^{2}}\\\\ &{\\phantom{\\|}\\leq\\displaystyle\\sum_{i=1}^{N}\\gamma_{n_{l}+1}^{2}L^{2}\\|\\nabla F_{i}(\\theta_{n_{l}}^{i},X_{n_{l}}^{i})\\|^{2}}\\\\ &{\\phantom{\\|}\\leq\\displaystyle\\sum_{i=1}^{2}C_{n_{l}+1}^{2}C_{0}^{2}N L^{2}}\\end{array}\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "such that $\\|\\nabla\\mathbf{F}(\\Theta_{n_{l}+1},\\mathbf{X})-\\nabla\\mathbf{F}(\\Theta_{n_{l}},\\mathbf{X})\\|\\leq\\gamma_{n_{l}+1}C_{\\Omega}\\sqrt{N}L$ . Thus, for any $\\mathbf{X}$ , ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\|\\nabla\\mathbf{F}(\\Theta_{n_{l}+1},\\mathbf{X})\\|\\le(1+\\gamma_{n_{l}+1}L)\\,\\sqrt{N}C_{\\Omega}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "For $n=n_{l}+2$ and any $\\mathbf{X}$ , we have ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\|\\nabla\\mathbf{F}(\\Theta_{n_{l}+2},\\mathbf{X})\\|\\leq\\|\\nabla\\mathbf{F}(\\Theta_{n_{l}+2},\\mathbf{X})-\\nabla\\mathbf{F}(\\Theta_{n_{l}+1},\\mathbf{X})\\|+\\|\\nabla\\mathbf{F}(\\Theta_{n_{l}+1},\\mathbf{X})\\|.\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "Similar to the steps in (24), we have ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\|\\nabla\\mathbf{F}(\\Theta_{n_{l}+2},\\mathbf{X})-\\nabla\\mathbf{F}(\\Theta_{n_{l}+1},\\mathbf{X})\\|^{2}\\leq\\displaystyle\\sum_{i=1}^{N}\\gamma_{n_{l}+2}^{2}L^{2}\\|\\nabla F_{i}(\\theta_{n_{l}+1}^{i},X_{n_{l}+1}^{i})\\|^{2}}\\\\ {=\\gamma_{n_{l}+2}^{2}L^{2}\\|\\nabla\\mathbf{F}(\\Theta_{n_{l}+1},\\mathbf{X}_{n_{l}+1})\\|^{2}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "Then, $\\|\\nabla\\mathbf{F}(\\Theta_{n_{l}+2},\\mathbf{X})\\|\\leq(1+\\gamma_{n_{l}+2}L)\\operatorname*{sup}_{\\mathbf{X}}\\|\\nabla\\mathbf{F}(\\Theta_{n_{l}+1},\\mathbf{X})\\|$ and, together with (25), we have ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\|\\nabla\\mathbf{F}(\\Theta_{n_{l}+2},\\mathbf{X})\\|\\le(1+\\gamma_{n_{l}+2}L)(1+\\gamma_{n_{l}+1}L)\\sqrt{N}C_{\\Omega}.\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "By induction, $\\begin{array}{r}{\\|\\nabla\\mathbf{F}(\\Theta_{n_{l}+m},\\mathbf{X})\\|\\leq\\prod_{s=1}^{m}(1+\\gamma_{n_{l}+s}L)\\sqrt{N}C_{\\Omega}}\\end{array}$ or $m\\in[1,K_{l+1}-1]$ ", "page_idx": 18}, {"type": "text", "text": "The next step is to analyze the growth rate of $\\begin{array}{r}{\\prod_{s=1}^{m}(1+\\gamma_{n_{l}+s}L)}\\end{array}$ . By $1+x\\leq e^{x}$ for $x\\geq0$ , we have ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\prod_{s=1}^{m}(1+\\gamma_{n_{l}+s}L)\\leq e^{L\\sum_{s=1}^{m}\\gamma_{n_{l}+s}}.\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "For step size $\\gamma_{n}=1/n$ , we have $\\begin{array}{r}{L\\sum_{s=1}^{m}\\gamma_{n_{l}+s}=L\\sum_{s=1}^{m}1/(n_{l}+s)<L\\sum_{s=1}^{m}1/s<L(\\log(m)+}\\end{array}$ 1) such that $\\begin{array}{r}{\\prod_{s=1}^{m}(1+\\gamma_{n_{l}+s}L)<(e m)^{L}}\\end{array}$ . Then, ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\left\\|\\displaystyle\\sum_{k=n_{l}}^{n_{l+1}-1}\\frac{\\nabla\\mathbf{F}(\\Theta_{k},\\mathbf{X}_{k})}{K_{l+1}^{L+1}}\\right\\|\\leq\\displaystyle\\frac{1}{K_{l+1}^{L+1}}\\displaystyle\\sum_{k=n_{l}}^{n_{l+1}-1}\\|\\nabla\\mathbf{F}(\\Theta_{k},\\mathbf{X}_{k})\\|\\leq\\displaystyle\\frac{1}{K_{l+1}^{L+1}}\\sqrt{N}e^{L}C_{\\Omega}\\displaystyle\\sum_{m=0}^{K_{l+1}-1}m^{L}}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\leq\\sqrt{N}e^{L}C_{\\Omega},}\\end{array}\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "where the last inequality comes from Kml=+01\u2212 $\\begin{array}{r}{\\sum_{m=0}^{K_{l+1}-1}m^{L}<K_{l+1}(K_{l+1}-1)^{L}<K_{l+1}^{L+1}}\\end{array}$ . We can see the sum of the norm of the gradients are bounded by $\\sqrt{N}e^{L}C_{\\Omega}$ , which only depends on the compact set \u2126at time n = nl. ", "page_idx": 18}, {"type": "text", "text": "Let $\\delta_{1}\\in(C_{1},1)$ . Since from Assumption 2.3-ii), $\\begin{array}{r}{\\operatorname*{lim}_{l\\to\\infty}\\eta_{n_{l}+1}/\\eta_{n_{l+1}+1}=1}\\end{array}$ , there exists some large enough $l_{0}$ such that $\\begin{array}{r}{(\\frac{\\eta_{n_{l}+1}}{\\eta_{n_{l+1}+1}})^{2}C_{1}<\\delta_{1}<\\delta_{2}:=(\\delta_{1}+1)/2<1}\\end{array}$ for any $l>l_{0}$ . Note that $\\delta_{1}$ depends only on $C_{1}$ and is independent of ${\\mathcal{F}}_{n}$ . Then, let $\\tilde{C}_{\\Omega}:=\\sqrt{N}e^{L}C_{\\Omega}$ , we can rewrite (23) as ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{E}[\\|\\phi_{n_{l+1}}\\|^{2}|{\\mathcal{F}}_{n_{l}}]\\le\\!\\delta_{1}\\|\\phi_{n_{l}}\\|^{2}+2\\delta_{1}{\\tilde{C}}_{\\Omega}\\|\\phi_{n_{l}}\\|+\\delta_{1}{\\tilde{C}}_{\\Omega}^{2}}\\\\ &{\\qquad\\qquad\\qquad\\leq\\!\\delta_{2}\\|\\phi_{n_{l}}\\|^{2}+M_{\\Omega},}\\end{array}\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "where $M_{\\Omega}$ satisfies $M_{\\Omega}\\ >\\ 8\\tilde{C}_{\\Omega}^{2}/(1\\,-\\,\\delta_{1})\\,+\\,\\delta_{1}\\tilde{C}_{\\Omega}^{2}$ , which is derived from rearranging (29) as $M_{\\Omega}\\,\\geq\\,(\\delta_{1}-\\delta_{2})\\|\\phi_{n_{l}}\\|^{2}+2\\delta_{1}\\tilde{C}_{\\Omega}\\|\\phi_{n_{l}}\\|+\\delta_{1}\\tilde{C}_{\\Omega}^{2}$ and upper bounding the RHS. Upon noting that $\\mathbb{1}_{\\cap_{j\\le n_{l}}\\{\\Theta_{j}\\in\\Omega\\}}\\le\\mathbb{1}_{\\cap_{j\\le n_{l-1}}\\{\\Theta_{j}\\in\\Omega\\}}$ , we obtain ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathbb{E}\\left[\\|\\phi_{n_{l+1}}\\|^{2}\\mathbb{1}_{\\cap_{j\\leq n_{l}}\\{\\Theta_{j}\\in\\Omega\\}}\\right]\\leq\\delta_{2}\\mathbb{E}\\left[\\|\\phi_{n_{l}}\\|^{2}\\mathbb{1}_{\\cap_{j\\leq n_{l-1}}\\{\\Theta_{j}\\in\\Omega\\}}\\right]+M_{\\Omega}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "The induction leads to $\\begin{array}{r l}{\\mathbb{E}[\\|\\phi_{n_{l+1}}\\|^{2}\\mathbb{1}_{\\cap_{j\\leq n_{l}}\\{\\Theta_{j}\\in\\Omega\\}}]}&{\\leq\\}\\ \\delta_{2}^{n_{l+1}-n_{l_{0}}}\\mathbb{E}[\\|\\phi_{n_{l_{0}}}\\|^{2}\\mathbb{1}_{\\cap_{j\\leq n_{l_{0}-1}}\\{\\Theta_{j}\\in\\Omega\\}}]\\ +}\\end{array}$ $M/(1-\\delta_{2})\\,<\\,\\infty$ for any $l~\\geq~l_{0}$ . Besides, for $m\\;\\in\\;(n_{l},n_{l+1})$ , by following the above steps (23) applied to (21), we have ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{E}[\\|\\phi_{m}\\|^{2}|\\mathcal{F}_{n_{l}}]\\leq\\left(\\frac{\\eta_{n_{l}+1}}{\\eta_{m+1}}\\right)^{2}\\|\\phi_{n_{l}}\\|^{2}+2\\left(\\frac{\\eta_{n_{l}+1}}{\\eta_{m+1}}\\right)^{2}\\|\\phi_{n_{l}}\\|\\mathbb{E}\\left[\\left\\|\\displaystyle\\sum_{k=n_{l}}^{m-1}\\frac{\\nabla\\mathbf{F}(\\Theta_{k},\\mathbf{X}_{k})}{K_{l+1}^{L+1}}\\right\\|\\bigg|\\mathcal{F}_{n_{l}}\\right]}\\\\ &{\\qquad\\qquad+\\left(\\frac{\\eta_{n_{l}+1}}{\\eta_{m+1}}\\right)^{2}\\mathbb{E}\\left[\\left\\|\\displaystyle\\sum_{k=n_{l}}^{m-1}\\frac{\\nabla\\mathbf{F}(\\Theta_{k},\\mathbf{X}_{k})}{K_{l+1}^{L+1}}\\right\\|^{2}\\bigg|\\mathcal{F}_{n_{l}}\\right].}\\end{array}\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "By (28) we already show that $\\begin{array}{r}{\\|\\sum_{k=n_{l}}^{n_{l+1}-1}\\frac{\\nabla\\mathbf{F}(\\Theta_{k},\\mathbf{X}_{k})}{K_{l+1}^{L+1}}\\|~<~\\infty}\\end{array}$ conditioned on ${\\mathcal{F}}_{n_{l}}$ . Therefore, $\\mathbb{E}[\\|\\phi_{m}\\|^{2}\\mathbb{1}_{\\cap_{j\\leq n_{l}}\\{\\Theta_{j}\\in\\Omega\\}}]\\,<\\,\\infty$ for $m\\,\\in\\,(n_{l},n_{l+1})$ . This completes the boundedness analysis of $\\mathbb{E}[\\|\\phi_{n}\\|^{2}\\mathbb{1}_{\\cap_{j\\leq n-1}\\{\\Theta_{j}\\in\\Omega\\}}]$ . ", "page_idx": 19}, {"type": "text", "text": "Case 2 (Bounded communication interval $K_{\\tau_{n}}\\leq K)$ : In this case, we do not need the auxiliary step size $\\eta_{n}$ and can directly work on $\\gamma_{n}=1/n^{a}$ for $a\\in(0.5,1]$ . Similar to (20), we have ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\Theta_{n+1}-\\frac{1}{N}(\\mathbf{11}^{T}\\otimes\\mathbf{I}_{d})\\Theta_{n+1}=\\gamma_{n+1}(\\mathbf{J}_{\\perp}\\mathbf{W}_{n}\\otimes\\mathbf{I}_{d})\\left(\\gamma_{n+1}^{-1}\\mathcal{J}_{\\perp}\\Theta_{n}-\\nabla\\mathbf{F}(\\Theta_{n},\\mathbf{X}_{n})\\right),\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "and let $b_{n}\\triangleq\\gamma_{n}/\\gamma_{n+1}$ , dividing both sides of above equation by $\\gamma_{n+2}$ gives ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\phi_{n+1}=b_{n+1}(\\mathbf{J}_{\\perp}\\mathbf{W}_{n}\\otimes\\mathbf{I}_{d})\\left(\\phi_{n}-\\nabla\\mathbf{F}(\\Theta_{n},\\mathbf{X}_{n})\\right).\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "Then, by following the similar steps in (22) and (23), we obtain ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{E}[\\|\\phi_{n_{l+1}}\\|^{2}|\\mathcal{F}_{n_{l}}]\\leq\\left(\\frac{\\gamma_{n_{l}+1}}{\\gamma_{n_{l+1}+1}}\\right)^{2}C_{1}\\Bigg(\\|\\phi_{n_{l}}\\|^{2}+2\\|\\phi_{n_{l}}\\|\\mathbb{E}\\left[\\left\\|\\sum_{k=n_{l}}^{n_{l+1}-1}\\nabla\\mathbf{F}(\\Theta_{k},\\mathbf{X}_{k})\\right\\|\\right]\\bigg|\\mathcal{F}_{n_{l}}\\Bigg)}\\\\ &{\\qquad\\qquad\\qquad+\\mathbb{E}\\left[\\left\\|\\sum_{k=n_{l}}^{n_{l+1}-1}\\nabla\\mathbf{F}(\\Theta_{k},\\mathbf{X}_{k})\\right\\|^{2}\\Bigg|\\mathcal{F}_{n_{l}}\\right]\\Bigg).}\\end{array}\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "Also similar to (25) - (28), we can bound the sum of the norm of the gradients as ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\left\\|\\sum_{k=n_{l}}^{n_{l+1}-1}\\nabla\\mathbf{F}(\\Theta_{k},\\mathbf{X}_{k})\\right\\|\\leq\\sum_{k=n_{l}}^{n_{l+1}-1}\\left[\\prod_{s=n_{l}}^{k}(1+\\gamma_{s+1}L)\\right]\\sqrt{N}C_{\\Omega}.\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "Now that $K_{l}$ is bounded above by $\\begin{array}{r}{K,\\prod_{s=n_{l}}^{k}(1+\\gamma_{s+1}L)\\le e^{L\\sum_{s=n_{l}}^{k}\\gamma_{s}+1}<e^{L\\sum_{s=0}^{K-1}\\gamma_{s+1}}:=C_{K}.}\\end{array}$ Then, we further bound (35) as ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\left\\|\\sum_{k=n_{l}}^{n_{l+1}-1}\\nabla\\mathbf{F}(\\Theta_{k},\\mathbf{X}_{k})\\right\\|\\leq\\sqrt{N}K C_{K}C_{\\Omega}.\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "The subsequent proof is basically a replication of (29) - (31) and is therefore omitted. ", "page_idx": 19}, {"type": "text", "text": "C Proof of Theorem 3.2 ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "We focus on analyzing the convergence property of $\\theta$ , which is obtained by left multiplying (18) with $\\begin{array}{r}{\\frac{1}{N}\\big(\\mathbf{1}^{T}\\otimes\\mathbf{I}_{d}\\big)}\\end{array}$ , i.e., ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\begin{array}{l}{\\displaystyle\\theta_{n+1}=\\frac{1}{N}(\\mathbf{1}^{T}\\otimes\\mathbf{I}_{d})\\theta_{n+1}}\\\\ {\\displaystyle=\\theta_{n}-\\gamma_{n+1}\\frac{1}{N}(\\mathbf{1}^{T}\\otimes\\mathbf{I}_{d})\\nabla\\mathbf{F}(\\Theta_{n},\\mathbf{X}_{n}).}\\end{array}\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "where the second equality comes from $\\mathbf{W}_{n}$ being doubly stochastic and $\\begin{array}{r l}{\\frac{1}{N}(\\mathbf{1}^{T}\\otimes\\mathbf{I}_{d})\\mathcal{W}_{n}}&{=}\\end{array}$ $\\begin{array}{r}{\\frac{1}{N}(\\mathbf{1}^{T}\\mathbf{W}_{n}\\otimes\\mathbf{I}_{d})=\\frac{1}{N}(\\mathbf{1}^{T}\\otimes\\mathbf{I}_{d})}\\end{array}$ . ", "page_idx": 19}, {"type": "text", "text": "For self-contained purpose, we first give the almost sure convergence result for the stochastic approximation that will be used in our proof. ", "page_idx": 19}, {"type": "text", "text": "Theorem C.1 (Theorem 2 [23]). Consider the stochastic approximation in the form of ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\theta_{n+1}=\\theta_{n}+\\gamma_{n+1}h(\\theta_{n})+\\gamma_{n+1}e_{n+1}+\\gamma_{n+1}r_{n+1}.\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "Assume that ", "page_idx": 20}, {"type": "text", "text": "C1. w.p.1, the closure of $\\{\\theta_{n}\\}_{n\\ge0}$ is a compact subset of $\\mathbb{R}^{d}$ ;   \nC2. $\\{\\gamma_{n}\\}$ is a decreasing sequence of positive number such that $\\textstyle\\sum_{n}\\gamma_{n}=\\infty$ ;   \nC3. w.p.1, $\\begin{array}{r}{\\operatorname*{lim}_{p\\to\\infty}\\sum_{n=1}^{p}\\gamma_{n}e_{n}}\\end{array}$ exists and is finite. Moreover, $\\operatorname*{lim}_{n\\to\\infty}r_{n}=0$ .   \nC4. vector-valued function $h$ is continuous on $R^{d}$ and there exists a continuously differentiable function $V:\\dot{\\mathbb{R}}^{d}\\rightarrow\\mathbb{R}$ such that $\\langle\\nabla V(\\theta),h(\\theta)\\rangle\\leq0$ for all $\\theta\\in\\ensuremath{\\mathbb{R}}^{d}$ . Besides, the interior of $V({\\mathcal{L}})$ is empty where $\\mathcal{L}\\triangleq\\{\\theta\\in\\mathbb{R}^{d}:\\langle\\nabla V(\\theta),h(\\theta)\\rangle=0\\}$ . ", "page_idx": 20}, {"type": "text", "text": "7 $\\gamma_{h e n,\\;w.p.I,\\;\\operatorname*{lim}\\operatorname*{sup}_{n}d(\\theta_{n},\\mathcal{L})}=0.$ ", "page_idx": 20}, {"type": "text", "text": "We can rewrite (37) as ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\begin{array}{l}{\\displaystyle\\theta_{n+1}=\\!\\theta_{n}-\\gamma_{n+1}\\frac{1}{N}({\\mathbf1}^{T}\\otimes{\\mathbf I}_{d})\\nabla{\\mathbf F}(\\Theta_{n},{\\mathbf X}_{n})}\\\\ {\\displaystyle\\qquad=\\!\\theta_{n}-\\gamma_{n+1}\\nabla f(\\theta_{n})-\\gamma_{n+1}\\left(\\frac{1}{N}\\sum_{i=1}^{N}\\nabla f_{i}(\\theta_{n}^{i})-\\nabla f(\\theta_{n})\\right)}\\\\ {\\displaystyle\\qquad-\\,\\gamma_{n+1}\\left(\\frac{1}{N}\\sum_{i=1}^{N}\\nabla F_{i}(\\theta_{n}^{i},X_{n}^{i})-\\frac{1}{N}\\sum_{i=1}^{N}\\nabla f_{i}(\\theta_{n}^{i})\\right),}\\end{array}\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "and work on the converging behavior of the third and fourth term. By definition of function $\\nabla f(\\cdot)$ , we have ", "page_idx": 20}, {"type": "equation", "text": "$$\nr_{n}\\triangleq\\frac{1}{N}\\sum_{i=1}^{N}\\nabla f_{i}(\\boldsymbol{\\theta}_{n}^{i})-\\nabla f(\\boldsymbol{\\theta}_{n})=\\frac{1}{N}\\sum_{i=1}^{N}\\left[\\nabla f_{i}(\\boldsymbol{\\theta}_{n}^{i})-\\nabla f_{i}(\\boldsymbol{\\theta}_{n})\\right].\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "By the Lipschitz continuity of function $\\nabla F_{i}(\\cdot,X)$ in (7), we have ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\|r_{n}\\|\\leq\\frac{1}{N}\\sum_{i=1}^{N}L\\|\\theta_{n}^{i}-\\theta_{n}\\|\\leq\\frac{L}{\\sqrt{N}}\\left\\|\\Theta_{n}-\\frac{1}{N}(\\mathbf{11}^{T}\\otimes\\mathbf{I}_{d})\\Theta_{n}\\right\\|=\\frac{L}{\\sqrt{N}}\\|\\mathcal{I}_{\\bot}\\Theta_{n}\\|,\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "where the second inequality comes from the Cauchy-Schwartz inequality. In Appendix B, we have shown $\\operatorname*{lim}_{n}\\mathcal{I}_{\\perp}\\Theta_{n}=\\mathbf{0}$ almost surely such that $\\operatorname*{lim}_{n\\to\\infty}r_{n}=0$ almost surely. ", "page_idx": 20}, {"type": "text", "text": "Next, we further decompose the fourth term in (39). For an ergodic transition matrix $\\mathbf{P}$ and a function $v$ associated with the same state space $\\mathcal{X}$ , define the operator $\\begin{array}{r}{\\mathbf{P}^{k}v(x)\\triangleq\\sum_{y\\in\\mathcal{X}}\\mathbf{P}^{k}(x,y)v(y)}\\end{array}$ for the $k$ -step transition probability $\\mathbf{P}^{k}(x,y)$ . Denote by $\\mathbf{P}_{1},\\cdots,\\mathbf{P}_{N}$ the underlying transition matrices of all $N$ agents with corresponding stationary distribution $\\pi_{1},\\cdot\\cdot\\cdot,\\pi_{N}$ . Then, for every function $\\nabla F_{i}(\\theta^{i},\\cdot)\\dot{:}\\mathcal{X}_{i}\\rightarrow\\mathbb{R}^{d}$ , there exists a corresponding function $m_{\\theta^{i}}(\\cdot):\\mathcal{X}_{i}\\rightarrow\\mathbb{R}^{d}$ such that ", "page_idx": 20}, {"type": "equation", "text": "$$\nm_{\\theta^{i}}(x)-\\mathbf{P}_{i}m_{\\theta^{i}}(x)=\\nabla F_{i}(\\theta^{i},x)-\\nabla f_{i}(\\theta^{i}).\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "The solution of the Poisson equation (42) has been studied in the literature, e.g., [17, 38]. For self-contained purpose, we derive the closed-form $m_{\\theta^{i}}(x)$ from scratch. First of all, we can obtain function $m_{\\theta^{i}}(x)$ in the recursive form as follows, ", "page_idx": 20}, {"type": "equation", "text": "$$\nn_{\\theta^{i}}(x)=\\nabla F_{i}(\\theta^{i},x)-\\nabla f_{i}(\\theta^{i})+\\mathbf{P}_{i}[\\nabla F_{i}(\\theta^{i},\\cdot)-\\nabla f_{i}(\\theta^{i})](x)+\\mathbf{P}_{i}^{2}[\\nabla F_{i}(\\theta^{i},\\cdot)-\\nabla f_{i}(\\theta^{i})](x)+\\cdots\\,.\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "It is not hard to check that (43) satisfies (42). Note that by induction we get ", "page_idx": 20}, {"type": "equation", "text": "$$\n{\\bf P}_{i}^{k}-{\\bf1}(\\pi_{i})^{T}=\\left({\\bf P}_{i}-{\\bf1}(\\pi_{i})^{T}\\right)^{k},\\forall k\\in\\mathbb{N},k\\geq1.\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "Then, we can further simplify (43), and the closed-form expression of $m_{\\theta^{i}}(x)$ is given as ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\lefteqn{m_{\\theta^{i}}\\left(x\\right)=\\sum_{y\\in\\mathcal{X}_{i}}\\left[\\mathbf{P}_{i}-\\mathbf{1}(\\pi_{i})^{T}\\right]^{0}\\left(x,y\\right)\\!\\left(\\nabla F_{i}(\\theta^{i},y)-\\nabla f_{i}(\\theta^{i})\\right)}}\\\\ &{+\\sum_{y\\in\\mathcal{X}^{i}}\\left[\\mathbf{P}_{i}^{1}-\\mathbf{1}(\\pi_{i})^{T}\\right]\\left(x,y\\right)\\!\\left(\\nabla F_{i}(\\theta^{i},y)-\\nabla f_{i}(\\theta^{i})\\right)+\\cdot\\cdot\\cdot}\\\\ &{=\\displaystyle\\sum_{y\\in\\mathcal{X}_{i}}\\left[\\sum_{k=0}^{\\infty}\\left[\\mathbf{P}_{i}-\\mathbf{1}(\\pi_{i})^{T}\\right]^{k}\\right]\\left(x,y\\right)\\!\\left(\\nabla F_{i}(\\theta^{i},y)-\\nabla f_{i}(\\theta^{i})\\right)}\\\\ &{=\\displaystyle\\sum_{y\\in\\mathcal{X}_{i}}\\left(\\mathbf{I}-\\mathbf{P}_{i}+\\mathbf{1}(\\pi_{i})^{T}\\right)^{-1}\\left(x,y\\right)\\!\\left(\\nabla F_{i}(\\theta^{i},y)-\\nabla f_{i}(\\theta^{i})\\right)\\!,}\\end{array}\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "where the fourth equality comes from (44). Note that the so-called \u2018fundamental matrix\u2019 $(\\mathbf{I}-\\mathbf{P}_{i}+$ ${\\bf1}(\\pmb{\\pi}_{i})^{T})^{-1}$ exists for every ergodic Markov chain $X^{i}$ from Assumption 2.2. Since function $\\nabla F_{i}$ is Lipschitz continuous, we have the following lemma. ", "page_idx": 21}, {"type": "text", "text": "Lemma C.2. Under assumption $(A l),$ , functions $m_{\\theta^{i}}(x)$ and $\\mathbf{P}_{i}m_{\\theta^{i}}(x)$ are both Lipschitz continuous in $\\theta^{i}$ for any $x\\in\\mathcal{X}_{i}$ . ", "page_idx": 21}, {"type": "text", "text": "Proof. By (45), for any $\\theta_{1}^{i},\\theta_{2}^{i}\\in\\mathbb{R}^{d}$ and $x\\in\\mathcal{X}_{i}$ , we have ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\left\\|m_{\\theta_{1}^{i}}(x)-m_{\\theta_{2}^{i}}(x)\\right\\|\\leq\\left\\|\\displaystyle\\sum_{y\\in\\mathcal{X}_{i}}\\left(\\mathbf{I}-\\mathbf{P}_{i}+\\mathbf{1}(\\pi_{i})^{T}\\right)^{-1}(x,y)\\left[\\nabla F_{i}(\\theta_{1}^{i},y)-\\nabla F_{i}(\\theta_{2}^{i},y)\\right]\\right\\|}\\\\ &{\\qquad\\qquad\\qquad+\\left\\|\\nabla f_{i}(\\theta_{1}^{i})-\\nabla f_{i}(\\theta_{2}^{i})\\right\\|}\\\\ &{\\qquad\\qquad\\qquad\\leq C_{i}\\displaystyle\\operatorname*{max}_{y\\in\\mathcal{X}_{i}}\\left\\|\\nabla F_{i}(\\theta_{1}^{i},y)-\\nabla F_{i}(\\theta_{2}^{i},y)\\right\\|+\\left\\|\\nabla f_{i}(\\theta_{1}^{i})-\\nabla f_{i}(\\theta_{2}^{i})\\right\\|}\\\\ &{\\qquad\\qquad\\qquad\\leq(C_{i}L+1)\\|\\theta_{1}^{i}-\\theta_{2}^{i}\\|,}\\end{array}\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "where the second inequality holds for a constant $C_{i}$ that is the largest absolute value of the entry in the matrix $(\\mathbf{I}-\\mathbf{P}_{i}^{~}+\\mathbf{1}(\\mathbf{\\dot{\\pi}}_{i})^{T})^{-1}$ . Therefore, $m_{\\theta^{i}}(x)$ is Lipschitz continuous in $\\theta^{i}$ . Moreover, following the similar steps as above, we have ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\Big\\|\\mathbf{P}_{i}m_{\\theta_{1}^{i}}(x)-\\mathbf{P}_{i}m_{\\theta_{2}^{i}}(x)\\Big\\|=\\Bigg\\|\\displaystyle{\\sum_{y\\in\\mathcal{X}_{i}}\\mathbf{P}_{i}(x,y)m_{\\theta_{1}^{i}}(y)-\\sum_{y\\in\\mathcal{X}_{i}}\\mathbf{P}_{i}(x,y)m_{\\theta_{2}^{i}}(y)}\\Bigg\\|}\\\\ &{\\qquad\\qquad\\qquad=\\left\\|\\displaystyle{\\sum_{y\\in\\mathcal{X}_{i}}\\mathbf{P}_{i}(x,y)\\left(m_{\\theta_{1}^{i}}(y)-m_{\\theta_{2}^{i}}(y)\\right)}\\right\\|}\\\\ &{\\qquad\\qquad\\qquad\\leq\\displaystyle{\\sum_{y\\in\\mathcal{X}^{i}}\\mathbf{P}_{i}(x,y)\\left\\|m_{\\theta_{1}^{i}}(y)-m_{\\theta_{2}^{i}}(y)\\right\\|}}\\\\ &{\\qquad\\qquad\\leq|\\mathcal{X}_{i}|\\left\\|m_{\\theta_{1}^{i}}(y)-m_{\\theta_{2}^{i}}(y)\\right\\|}\\\\ &{\\qquad\\qquad\\leq|\\mathcal{X}_{i}|\\left(\\mathcal{C}_{i}L+1\\right)\\|\\theta_{i}^{i}-\\theta_{i}^{i}\\right\\|}\\end{array}\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "such that $\\mathbf{P}_{i}m_{\\theta^{i}}(x)$ is also Lipschitz continuous in $\\theta^{i}$ , which comletes the proof. ", "page_idx": 21}, {"type": "text", "text": "Now with (42) we can decompose $\\nabla F_{i}(\\theta_{n}^{i},X_{n}^{i})-\\nabla f_{i}(\\theta_{n}^{i})$ as ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\nabla F_{i}(\\theta_{n}^{i},X_{n}^{i})-\\nabla f_{i}(\\theta_{n}^{i})=\\!m_{\\theta_{n}^{i}}(X_{n}^{i})-\\mathbf{P}_{i}m_{\\theta_{n}^{i}}(X_{n}^{i})}\\\\ &{=\\!\\underbrace{m_{\\theta_{n}^{i}}(X_{n}^{i})-\\mathbf{P}_{i}m_{\\theta_{n}^{i}}(X_{n-1}^{i})}_{\\epsilon_{n+1}^{i}}}\\\\ &{\\quad\\quad\\quad\\quad\\quad\\quad+\\underbrace{\\mathbf{P}_{i}m_{\\theta_{n}^{i}}(X_{n-1}^{i})}_{\\nu_{n}^{i}}-\\underbrace{\\mathbf{P}_{i}m_{\\theta_{n}^{i}+1}(X_{n}^{i})}_{\\nu_{n+1}^{i}}}\\\\ &{\\quad\\quad\\quad\\quad\\quad\\quad+\\underbrace{\\mathbf{P}_{i}m_{\\theta_{n+1}^{i}}(X_{n}^{i})-\\mathbf{P}_{i}m_{\\theta_{n}^{i}}(X_{n}^{i})}_{\\xi_{n+1}^{i}}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "Here $\\{\\gamma_{n}e_{n}^{i}\\}$ is a Martingale difference sequence and we need the martingale convergence theorem in Theorem C.3. ", "page_idx": 22}, {"type": "text", "text": "Theorem C.3 (Theorem 6.4.6 [64]). For an ${\\mathcal{F}}_{n}$ -Martingale $S_{n}$ , set $X_{n-1}=S_{n}-S_{n-1}$ . If for some $1\\le p\\le2$ , ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\sum_{n=1}^{\\infty}\\mathbb{E}[\\|X_{n-1}\\|^{p}|\\mathcal{F}_{n-1}]<\\infty\\quad a.s.\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "then $S_{n}$ converges almost surely. ", "page_idx": 22}, {"type": "text", "text": "We want to show that $\\begin{array}{r}{\\sum_{n}\\gamma_{n+1}^{2}\\mathbb{E}[\\|e_{n+1}^{i}\\|^{2}|\\mathcal{F}_{n}]<\\infty}\\end{array}$ such that $\\sum_{n}\\gamma_{n}e_{n}^{i}$ converges almost surely by Theorem C.3. As we can see in (45), with Lemma C.2 a nd Assumption 2.4, for a sample path ( $\\left(\\Theta_{n}\\right)$ within a compact set $\\Omega$ ), $\\mathrm{sup}_{n}\\left\\|m_{\\theta_{n}^{i}}(x)\\right\\|\\;<\\;\\infty$ and $\\mathrm{\\boldmath~\\sup}_{n}\\left\\|{\\bf P}_{i}m_{\\theta_{n}^{i}}(x)\\right\\|\\ <\\ \\infty$ almost surely for all $x\\in\\mathcal{X}_{i}$ . This ensures that $e_{n+1}^{i}$ is an $L_{2}$ -bounded martingale difference sequence, i.e., $\\begin{array}{r}{\\operatorname*{sup}_{n}\\|e_{n+1}^{i}\\|\\le\\operatorname*{sup}_{n}(\\|m_{\\theta_{n}^{i}}(X_{n+1}^{i})\\|+\\|\\mathbf{P}_{i}m_{\\theta_{n}^{i}}(X_{n}^{i})\\|)\\le D_{\\Omega}<\\infty.}\\end{array}$ . Together with Assumption 2.3, we get ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\sum_{n}\\gamma_{n+1}^{2}\\mathbb{E}[\\|e_{n+1}^{i}\\|^{2}|\\mathcal{F}_{n}]\\leq D_{\\Omega}\\sum_{n}\\gamma_{n+1}^{2}<\\infty\\quad a.s.\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "and thus $\\sum_{n}\\gamma_{n}e_{n}^{i}$ converges almost surely. ", "page_idx": 22}, {"type": "text", "text": "Next, for the term $\\nu_{n}^{i}$ we have ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\sum_{k=0}^{p}\\gamma_{k+1}(\\nu_{k}^{i}-\\nu_{k+1}^{i})=\\sum_{k=0}^{p}(\\gamma_{k+1}-\\gamma_{k})\\nu_{k}^{i}+\\gamma_{0}\\nu_{0}^{i}-\\gamma_{p+1}\\nu_{p+1}^{i}.\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "As is shown before, for a given sample path, $\\left\\|\\mathbf{P}_{i}m_{\\theta_{n}^{i}}(x)\\right\\|$ is bounded almost surely for all $n$ and $x\\ \\in\\ \\chi^{i}$ such that $\\operatorname{sup}_{n}\\|\\nu_{n}^{i}\\|\\,<\\,\\infty$ almost surely. Since $\\begin{array}{r}{\\operatorname*{lim}_{n\\rightarrow\\infty}(\\gamma_{n+1}-\\gamma_{n})\\,=\\,0}\\end{array}$ , we have $\\begin{array}{r}{\\operatorname*{lim}_{n\\rightarrow\\infty}(\\gamma_{n+1}-\\gamma_{n})\\nu_{n}^{i}=0}\\end{array}$ . Note that there exists a path-dependent constant $C$ (that bounds $\\lVert\\nu_{n}^{i}\\rVert)$ such that for any $n\\geq m$ , ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\left\\|\\sum_{k=m}^{n}(\\gamma_{k+1}-\\gamma_{k})\\nu_{k}^{i}\\right\\|\\leq C\\sum_{k=m}^{n}(\\gamma_{k}-\\gamma_{k+1})=C(\\gamma_{m}-\\gamma_{n+1})<C\\gamma_{m}.\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "Since $\\textstyle\\operatorname*{lim}_{n\\to\\infty}\\gamma_{n}=0$ , there exists a positive integer $M$ such that for all $n\\geq m\\geq M$ , $\\gamma_{m}<\\epsilon/C$ and $\\begin{array}{r}{\\|\\sum_{k=m}^{n}\\bigl(\\gamma_{k+1}-\\gamma_{k}\\bigr)\\nu_{k}^{i}\\|<\\epsilon}\\end{array}$ for every $\\epsilon>0$ . Therefore, $\\begin{array}{r}{\\{\\sum_{k=0}^{p}(\\gamma_{k+1}-\\gamma_{k})\\nu_{k}^{i}\\}_{p\\ge0}}\\end{array}$ is a Cauchy sequence and $\\begin{array}{r}{\\sum_{k=0}^{\\infty}(\\gamma_{k+1}-\\gamma_{k})\\nu_{k}^{i}}\\end{array}$ converges by Cauchy convergence criterion. The last term of (51) tends to zero. Therefore, $\\begin{array}{r}{\\sum_{k=0}^{\\infty}\\gamma_{k+1}(\\nu_{k}^{i}-\\nu_{k+1}^{i})}\\end{array}$ converges and is finite. ", "page_idx": 22}, {"type": "text", "text": "For the last term $\\xi_{n}^{i}$ , Lemma C.2 leads to ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\frac{1}{N}\\sum_{i=1}^{N}\\big\\|\\xi_{n+1}^{i}\\big\\|\\leq\\frac{C^{\\prime}}{N}\\sum_{i=1}^{N}\\|\\theta_{n+1}^{i}-\\theta_{n}^{i}\\|\\leq\\frac{C^{\\prime}}{\\sqrt{N}}\\|\\Theta_{n+1}-\\Theta_{n}\\|.\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "for the Lipschitz constant $C^{\\prime}$ of $\\mathbf{P}_{i}m_{\\theta^{i}}(x)$ . However, the relationship between $\\theta_{n}$ and $\\theta_{n+1}$ is not obvious in the D-SGD and FL setting due to the update rule (18) with communication matrix $\\mathcal{W}_{n}$ , unlike the classical stochastic approximation shown in (38). We come up with the novel decomposition of $\\xi_{n}^{i}$ , which takes the consensus error into account, to solve this issue, i.e., ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\xi_{n+1}^{i}=\\left[{\\bf P}_{i}m_{\\theta_{n+1}^{i}}(X_{n}^{i})-{\\bf P}_{i}m_{\\theta_{n+1}}(X_{n}^{i})\\right]+\\left[{\\bf P}_{i}m_{\\theta_{n}}(X_{n}^{i})-{\\bf P}_{i}m_{\\theta_{n}^{i}}(X_{n}^{i})\\right]}\\\\ &{\\quad\\quad\\quad+\\left[{\\bf P}_{i}m_{\\theta_{n+1}}(X_{n}^{i})-{\\bf P}_{i}m_{\\theta_{n}}(X_{n}^{i})\\right].}\\end{array}\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "Using the Lipschitzness property of $\\mathbf{P}_{i}m_{\\theta}(X)$ in Lemma C.2, we have ", "page_idx": 23}, {"type": "equation", "text": "$$\n\\begin{array}{l}{\\displaystyle\\frac{1}{N}\\sum_{i=1}^{N}\\left\\|\\xi_{n+1}^{i}\\right\\|\\leq\\displaystyle\\frac{C^{\\prime}}{N}\\sum_{i=1}^{N}\\left(\\left\\|\\theta_{n+1}^{i}-\\theta_{n+1}\\right\\|+\\left\\|\\theta_{n+1}-\\theta_{n}\\right\\|+\\left\\|\\theta_{n}-\\theta_{n}^{i}\\right\\|\\right)}\\\\ {\\displaystyle\\leq\\frac{C^{\\prime}}{\\sqrt{N}}\\left\\|\\Theta_{n+1}-\\frac{1}{N}\\left(\\mathbf{1}\\mathbf{1}^{T}\\otimes\\mathbf{I}_{d}\\right)\\Theta_{n+1}\\right\\|+\\displaystyle\\frac{C^{\\prime}}{\\sqrt{N}}\\left\\|\\Theta_{n}-\\frac{1}{N}\\left(\\mathbf{1}\\mathbf{1}^{T}\\otimes\\mathbf{I}_{d}\\right)\\Theta_{n}\\right\\|}\\\\ {\\displaystyle\\quad\\quad+C^{\\prime}\\left\\|\\theta_{n+1}-\\theta_{n}\\right\\|}\\\\ {\\displaystyle=\\frac{C^{\\prime}}{\\sqrt{N}}\\left(\\|\\mathcal{I}_{\\perp}\\Theta_{n+1}\\|+\\|\\mathcal{I}_{\\perp}\\Theta_{n}\\|\\right)+C^{\\prime}\\left\\|\\theta_{n+1}-\\theta_{n}\\right\\|}\\\\ {\\displaystyle=\\frac{C^{\\prime}}{\\sqrt{N}}\\left(\\|\\mathcal{I}_{\\perp}\\Theta_{n+1}\\|+\\|\\mathcal{I}_{\\perp}\\Theta_{n}\\|\\right)+C^{\\prime}\\gamma_{n+1}\\left\\|\\frac{1}{N}(\\mathbf{1}^{T}\\otimes\\mathbf{I}_{d})\\nabla\\mathbf{F}(\\Theta_{n},\\mathbf{X}_{n})\\right\\|.}\\end{array}\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "In Appendix $\\mathbf{B}$ we have shown $\\operatorname*{lim}_{n\\to\\infty}\\mathcal{I}_{\\perp}\\Theta_{n}~=~\\mathbf{0}$ almost surely. Moreover, $\\|{\\frac{1}{N}}(\\mathbf{1}^{T}\\otimes$ $\\mathbf{I}_{d})\\nabla\\mathbf{F}(\\Theta_{n},\\mathbf{X}_{n})\\|$ is bounded per sample path. Therefore, $\\begin{array}{r}{\\operatorname*{lim}_{n\\rightarrow\\infty}\\frac{1}{N}\\sum_{i=1}^{N}\\|\\xi_{n+1}^{i}\\|\\,=\\,0}\\end{array}$ such that $\\begin{array}{r}{\\operatorname*{lim}_{n\\to\\infty}\\frac{1}{N}\\sum_{i=1}^{N}\\xi_{n+1}^{i}=0}\\end{array}$ almost surely. ", "page_idx": 23}, {"type": "text", "text": "To sum up, we decompose (39) into ", "page_idx": 23}, {"type": "equation", "text": "$$\n\\theta_{n+1}=\\theta_{n}-\\gamma_{n+1}\\nabla f(\\theta_{n})-\\gamma_{n+1}r_{n}-\\gamma_{n+1}\\frac{1}{N}\\sum_{i=1}^{N}\\left(e_{n+1}^{i}+\\nu_{n}^{i}-\\nu_{n+1}^{i}+\\xi_{n+1}^{i}\\right).\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "Now that $\\begin{array}{r}{\\operatorname*{lim}_{p\\to\\infty}\\sum_{n=1}^{p}\\frac{1}{N}\\sum_{i=1}^{N}\\gamma_{n}e_{n}^{i}}\\end{array}$ and $\\begin{array}{r}{\\operatorname*{lim}_{p\\to\\infty}\\sum_{n=0}^{p}\\frac{1}{N}\\sum_{i=1}^{N}\\gamma_{n+1}(\\nu_{n}^{i}-\\nu_{n+1}^{i})}\\end{array}$ converge aCn.1d  aarree  sfaitniistef,ie $\\textstyle\\operatorname*{lim}_{n\\to\\infty}r_{n}\\,=\\,0$ ,A $\\begin{array}{r}{\\operatorname*{lim}_{n\\to\\infty}\\frac{1}{N}\\sum_{i=1}^{N}\\xi_{n}^{i}\\,=\\,0}\\end{array}$ s,  taol lC t1h, e Acsosnudmitpitoinosn  o2f. 3C m3 eient sT Che2,o raenmd d. Additionally,  ssumption 2.4 correspond C4 is automatically satisfied when we choose the lyapunov function ${\\bar{V(\\theta)}}\\,=\\,f(\\theta)$ . Therefore, l $\\mathrm{m}\\,\\mathrm{sup}_{n}\\,\\mathrm{inf}_{\\theta^{*}\\in{\\cal{L}}}\\,\\|\\theta_{n}-\\theta^{*}\\|=0$ . ", "page_idx": 23}, {"type": "text", "text": "D Proof of Theorem 3.3 ", "text_level": 1, "page_idx": 23}, {"type": "text", "text": "To obtain Theorem 3.3, we need to utilize the existing CLT result for general SA in Theorem D.1 and check all the necessary conditions therein. ", "page_idx": 23}, {"type": "text", "text": "Theorem D.1 (Theorem 2.1 [29]). Consider the stochastic approximation iteration (38), assume ", "page_idx": 23}, {"type": "text", "text": "C1. Let $\\theta^{*}$ be the root of function $h$ , i.e., $h(\\theta^{*})=0$ , and assume $\\begin{array}{r}{\\operatorname*{lim}_{n\\to\\infty}\\theta_{n}=\\theta^{*}}\\end{array}$ . Moreover, assume the mean field $h$ is twice continuously differentiable in a neighborhood of $\\theta^{*}$ , and the Jacobian $\\mathbf{H}\\triangleq\\nabla h(\\theta^{*})$ is Hurwitz, i.e., the largest real part of its eigenvalues $B<0$ ;   \nC2. The step size $\\textstyle\\sum_{n}\\gamma_{n}=\\infty,$ , $\\textstyle\\sum_{n}\\gamma_{n}^{2}<\\infty$ , and either $(i)$ . $\\log(\\gamma_{n-1}/\\gamma_{n})=o(\\gamma_{n}),$ , or $(i i)$ . $\\log(\\gamma_{n-1}/\\gamma_{n})\\sim\\gamma_{n}/\\gamma_{\\star}$ for some $\\gamma_{\\star}>1/2|B|$ ;   \nC3. $\\operatorname*{sup}_{n}\\|\\theta_{n}^{i}\\|<\\infty$ almost surely for any $i\\in[N]$ ;   \n$C4$ . (a) $\\{e_{n}\\}_{n\\ge0}$ is an ${\\mathcal{F}}_{n}$ -Martingale difference sequence, i.e., $\\mathbb{E}[e_{n}|\\mathcal{F}_{n-1}]=0,$ , and there exists $\\tau>0$ such that $\\mathrm{sup}_{n\\ge0}^{\\bar{}}\\mathbb{E}[\\|e_{n}\\|^{2+\\tau}|\\mathcal{F}_{n-1}^{-}]<\\infty$ ; (b) $\\mathbb{E}[e_{n+1}e_{n+1}^{T}|\\mathcal{F}_{n}]=\\mathbf{U}+\\mathbf{D}_{n}^{(A)}+\\mathbf{D}_{n}^{(B)}$ , where $\\mathbf{U}$ is a symmetric positive semi-definite $\\left\\{\\begin{array}{l l}{\\ \\mathbf{D}_{n}^{(A)}\\to0\\ a l m o s t\\,s u r e l y,}\\\\ {\\ \\operatorname*{lim}_{n}\\gamma_{n}\\mathbb{E}\\left[\\left\\|\\sum_{k=1}^{n}\\mathbf{D}_{k}^{(B)}\\right\\|\\right]=0.}\\end{array}\\right.$ (57) ", "page_idx": 23}, {"type": "text", "text": "C5. Let rn = rn $r_{n}=r_{n}^{(1)}+r_{n}^{(2)}$ , $r_{n}$ is ${\\mathcal{F}}_{n}$ -adapted, and ", "page_idx": 23}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\left\\{\\begin{array}{l l}{\\phantom{-}\\left.\\left\\|r_{n}^{(1)}\\right\\|=o(\\sqrt{\\gamma_{n}})\\quad a.s.}\\\\ {\\phantom{-}\\sqrt{\\gamma_{n}}\\left\\|\\sum_{k=1}^{n}r_{k}^{(2)}\\right\\|=o(1)\\quad a.s.}\\end{array}\\right.}\\end{array}\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "Then, ", "page_idx": 24}, {"type": "equation", "text": "$$\n\\frac{1}{\\sqrt{\\gamma_{n}}}(\\theta_{n}-\\theta^{*})\\;\\frac{d i s t.}{n{\\rightarrow}{\\infty}}{\\mathcal N}(0,{\\bf V}),\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "where ", "page_idx": 24}, {"type": "equation", "text": "$$\n\\left\\{\\begin{array}{l l}{\\begin{array}{r l}{\\mathbf{V}\\mathbf{H}^{T}+\\mathbf{H}\\mathbf{V}=-\\mathbf{U}}\\\\ {\\mathbf{V}(\\mathbf{I}_{d}+2\\gamma_{\\star}\\mathbf{H}^{T})+(\\mathbf{I}_{d}+2\\gamma_{\\star}\\mathbf{H})\\mathbf{V}=-2\\gamma_{\\star}\\mathbf{U}}\\end{array}}\\end{array}\\right.\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "Note that the matrix $\\mathbf{U}$ in the condition ${\\mathrm{C}}4({\\mathsf{b}})$ of Theorem D.1 was assumed to be positive definite in the original Theorem 2.1 [29]. It was only to ensure that the solution $\\mathbf{V}$ to the Lyapunov equation (60) is positive definite, which was only used for the stability of the related autonomous linear ODE (e.g., Theorem 3.16 [15] or Theorem 2.2.3 [36]). However, in this paper, we do not need strict positive definite matrix $\\mathbf{V}$ . Therefore, we extend U to be positive semi-definite such that $\\mathbf{V}$ is also positive semi-definite (see Lemma D.2 for the closed form of matrix $\\mathbf{V}$ ). Such kind of extension does not change any of the proof steps in [29]. ", "page_idx": 24}, {"type": "text", "text": "D.1 Discussion about C1-C3 ", "text_level": 1, "page_idx": 24}, {"type": "text", "text": "Our Assumption 2.1 corresponds to C1 by letting function $h(\\theta)=-\\nabla f(\\theta)$ therein. We can also let $\\gamma_{\\star}$ in Theorem 3.3 large enough to satisfy C2. The typical form of step size, also indicated in [29], is polynomial step size $\\gamma_{n}\\sim\\gamma_{\\star}/n^{a}$ for $a\\in(0.5,1]$ . Note that $a\\in(0.5,1)$ satisfies C2 (i) and $a=1$ satisfies C2 (ii). Assumption 2.4 corresponds to C3.4 ", "page_idx": 24}, {"type": "text", "text": "D.2 Analysis of C4 ", "text_level": 1, "page_idx": 24}, {"type": "text", "text": "To check condition $\\mathrm{C4}$ , we need to analyze the Martingale difference sequence $\\{e_{n}^{i}\\}$ . Recall $e_{n+1}^{i}=m_{\\theta_{n}^{i}}(X_{n}^{i})-\\mathbf{P}_{i}m_{\\theta_{n}^{i}}(X_{n-1}^{i})$ such that there exists a constant $C$ , ", "page_idx": 24}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{E}\\left[\\left\\Vert e_{n+1}^{i}\\right\\Vert^{2+\\tau}|\\mathcal{F}_{n}\\right]\\leq C\\mathbb{E}\\left[\\left\\Vert m_{\\theta_{n}^{i}}(X_{n}^{i})\\right\\Vert^{2+\\tau}+\\left\\Vert\\mathbf{P}_{i}m_{\\theta_{n}^{i}}(X_{n-1}^{i})\\right\\Vert^{2+\\tau}\\right]\\mathcal{F}_{n}\\right]}\\\\ &{\\qquad\\qquad\\qquad=C\\displaystyle\\sum_{Y\\in\\mathcal{X}^{i}}\\mathbf{P}_{i}(X_{n-1}^{i},Y)\\left\\Vert m_{\\theta_{n}^{i}}(Y)\\right\\Vert^{2+\\tau}+C\\left\\Vert\\mathbf{P}_{i}m_{\\theta_{n}^{i}}(X_{n-1}^{i})\\right\\Vert^{2+\\tau}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "Since $\\|m_{\\theta_{n}^{i}}(Y)\\|<\\infty$ almost surely by Assumption 2.4 and $\\chi^{i}$ is a finite state space, at all time $n$ we have ", "page_idx": 24}, {"type": "equation", "text": "$$\n\\sum_{Y\\in\\mathcal{X}^{i}}\\mathbf{P}_{i}(X_{n-1}^{i},Y)\\left\\|m_{\\theta_{n}^{i}}(Y)\\right\\|^{2+\\tau}<\\infty\\quad a.s.\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "and there exists another constant $C^{\\prime}$ such that by definition of $\\mathbf{P}_{i}m_{\\theta_{n}^{i}}(X_{n-1}^{i})$ , we have ", "page_idx": 24}, {"type": "equation", "text": "$$\n\\left\\|\\mathbf{P}_{i}m_{\\theta_{n}^{i}}(X_{n-1}^{i})\\right\\|^{2+\\tau}\\leq C^{\\prime}\\sum_{Y\\in\\mathcal{X}^{i}}\\mathbf{P}_{i}(X_{n-1}^{i},Y)\\left\\|m_{\\theta_{n}^{i}}(Y)\\right\\|^{2+\\tau}<\\infty\\quad a.s.\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "Therefore, $\\mathbb{E}[\\|e_{n+1}^{i}\\|^{2+\\tau}|\\mathcal{F}_{n}]<\\infty$ a.s. for all $n$ and C4.(a) is satisfied. ", "page_idx": 24}, {"type": "text", "text": "We now turn to C4.(b). Note that for any $i\\neq j$ , we have $\\mathbb E[e_{n+1}^{i}(e_{n+1}^{j})^{T}|\\mathcal F_{n}]\\,=\\,\\mathbb E[e_{n+1}^{i}|\\mathcal F_{n}]$ \u00b7 $\\mathbb{E}[(e_{n+1}^{j})^{T}|\\mathcal{F}_{n}]=0$ due to the independence between agent $i$ and $j$ , and $\\mathbb{E}[e_{n+1}^{i}|\\mathcal{F}_{n}]=0$ . Then, we have ", "page_idx": 24}, {"type": "equation", "text": "$$\n\\mathbb{E}\\left[\\left(\\frac{1}{N}\\sum_{i=1}^{N}e_{n+1}^{i}\\right)\\left(\\frac{1}{N}\\sum_{i=1}^{N}e_{n+1}^{i}\\right)^{T}\\Bigg|\\mathcal{F}_{n}\\right]=\\frac{1}{N^{2}}\\sum_{i=1}^{N}\\mathbb{E}\\left[e_{n+1}^{i}(e_{n+1}^{i})^{T}\\big|\\,\\mathcal{F}_{n}\\right].\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "The analysis of $\\mathbb E[e_{n+1}^{i}(e_{n+1}^{i})^{T}|\\mathcal F_{n}]$ is inspired by Section 4 [29] and Section 4.3.3 [22], where they constructed another Poisson equation to further decompose the noise terms therein.5 Here, expanding ", "page_idx": 24}, {"type": "text", "text": "$\\mathbb E[e_{n+1}^{i}(e_{n+1}^{i})^{T}|\\mathcal F_{n}]$ gives ", "page_idx": 25}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\Xi\\left[e_{n+1}^{i}(e_{n+1}^{i})^{T}\\right|\\mathcal{F}_{n}\\right]=\\mathbb{E}[m_{\\theta_{n}^{i}}(X_{n}^{i})m_{\\theta_{n}^{i}}(X_{n}^{i})^{T}|\\mathcal{F}_{n}]+\\mathbf{P}_{i}m_{\\theta_{n}^{i}}(X_{n-1}^{i})\\left(\\mathbf{P}_{i}m_{\\theta_{n}^{i}}(X_{n-1}^{i})\\right)^{T}}\\\\ &{\\qquad\\qquad\\qquad\\qquad-\\mathbb{E}[m_{\\theta_{n}^{i}}(X_{n}^{i})|\\mathcal{F}_{n}]\\left(\\mathbf{P}_{i}m_{\\theta_{n}^{i}}(X_{n-1}^{i})\\right)^{T}\\!\\!-\\!\\mathbf{P}_{i}m_{\\theta_{n}^{i}}(X_{n-1}^{i})\\mathbb{E}[m_{\\theta_{n}^{i}}(X_{n}^{i})^{T}|\\mathcal{F}_{n}]}\\\\ &{\\qquad\\qquad\\qquad\\qquad=\\underset{y\\in\\mathcal{X}_{i}}{\\sum}\\mathbf{P}_{i}(X_{n-1},y)m_{\\theta_{n}^{i}}(y)m_{\\theta_{n}^{i}}(y)^{T}\\!-\\!\\mathbf{P}_{i}m_{\\theta_{n}^{i}}(X_{n-1}^{i})\\left(\\mathbf{P}_{i}m_{\\theta_{n}^{i}}(X_{n-1}^{i})\\right)^{T}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "Denote by ", "page_idx": 25}, {"type": "equation", "text": "$$\nG_{i}(\\theta^{i},x)\\triangleq\\sum_{y\\in\\mathcal{X}_{i}}\\mathbf{P}_{i}(x,y)m_{\\theta^{i}}(y)m_{\\theta^{i}}(y)^{T}-\\mathbf{P}_{i}m_{\\theta^{i}}(x)\\left(\\mathbf{P}_{i}m_{\\theta^{i}}(x)\\right)^{T},\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "and let its expectation w.r.t the stationary distribution $\\pi_{i}$ be $g_{i}(\\theta^{i})\\,\\triangleq\\,\\mathbb{E}_{x\\sim{\\pmb\\pi}_{i}}[G_{i}(\\theta^{i},x)]$ , we can construct another Poisson equation, i.e., ", "page_idx": 25}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\quad\\mathbb{E}\\left[\\left.e_{n+1}^{i}(e_{n+1}^{i})^{T}\\right\\rvert\\mathcal{F}_{n}\\right]-\\displaystyle\\sum_{X_{n}^{i}\\in\\mathcal{X}_{i}}\\pi(X_{n}^{i})\\mathbb{E}\\left[\\left.e_{n+1}^{i}(e_{n+1}^{i})^{T}\\right\\rvert\\mathcal{F}_{n}\\right]}\\\\ &{=\\!G_{i}(\\theta_{n}^{i},X_{n-1}^{i})-g_{i}(\\theta_{n}^{i})}\\\\ &{=\\!\\varphi_{\\theta_{n}^{i}}^{i}(X_{n-1}^{i})-\\mathbf{P}_{i}\\varphi_{\\theta_{n}^{i}}^{i}(X_{n-1}^{i}),}\\end{array}\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "for some matrix-valued function $\\varphi^{i}:\\mathbb{R}^{d}\\times\\mathcal{X}_{i}\\rightarrow\\mathbb{R}^{d\\times d}$ . Following the similar steps shown in (42) - (45), we can obtain the closed-form expression ", "page_idx": 25}, {"type": "equation", "text": "$$\n\\varphi_{\\theta^{i}}^{i}(x)=\\sum_{y\\in\\mathcal{X}_{i}}\\left(\\mathbf{I}-\\mathbf{P}_{i}+\\mathbf{1}(\\pi_{i})^{T}\\right)^{-1}(x,y)G_{i}(\\theta^{i},x)-g_{i}(\\theta^{i}).\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "Then, we can decompose (65) into ", "page_idx": 25}, {"type": "equation", "text": "$$\n\\mathbb{\\tilde{r}}_{i}(\\theta_{n}^{i},X_{n-1}^{i})=\\underbrace{g_{i}(\\theta^{*})}_{\\mathbf{U}_{i}}+\\underbrace{g_{i}(\\theta_{n}^{i})-g_{i}(\\theta^{*})}_{\\mathbf{D}_{i,n}^{(1)}}+\\underbrace{\\varphi_{\\theta_{n}^{i}}^{i}(X_{n}^{i})-\\mathbf{P}_{i}\\varphi_{\\theta_{n}^{i}}^{i}(X_{n-1}^{i})}_{\\mathbf{D}_{i,n}^{(2,a)}}+\\underbrace{\\varphi_{\\theta_{n}^{i}}^{i}(X_{n-1}^{i})-\\varphi_{\\theta_{n}^{i}}^{i}(X_{n}^{i})}_{\\mathbf{D}_{i,n}^{(2,b)}}.\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "Let $\\begin{array}{r}{\\textbf{U}\\triangleq~\\frac{1}{N^{2}}\\sum_{i=1}^{N}\\mathbf{U}_{i}}\\end{array}$ $\\begin{array}{r l r}{\\sum_{i=1}^{N}{\\bf U}_{i},~{\\bf D}_{n}^{(1)}}&{\\triangleq}&{\\frac{1}{N^{2}}\\sum_{i=1}^{N}{\\bf D}_{1,n}^{(1)},~{\\bf D}_{n}^{(2,a)}~\\triangleq~\\frac{1}{N^{2}}\\sum_{i=1}^{N}{\\bf D}_{i,n}^{(2,a)},}\\end{array}$ , and $\\mathbf{D}_{n}^{(2,b)}\\ \\triangleq$ N12 iN=1 Di(,2n,b ), we want to prove that D(n1)satisfies the first condition in C4, and D(n2,a), D(n2,b) meet the second condition in C4. ", "page_idx": 25}, {"type": "text", "text": "We now show that for all $i$ , $G_{i}(\\theta^{i},x)$ is Lipschitz continuous in $\\theta^{i}\\in\\Omega$ for some compact subset $\\Omega\\subset\\mathbb{R}^{d}$ . For any $x\\in\\mathcal{X}_{i}$ and $\\theta_{1}^{i},\\theta_{2}^{i}\\in\\Omega$ , we can get ", "page_idx": 25}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\quad\\|m_{\\theta_{1}^{i}}(x)m_{\\theta_{1}^{i}}(x)^{T}-m_{\\theta_{2}^{i}}(x)m_{\\theta_{2}^{i}}(x)^{T}\\|}\\\\ &{=\\!\\|m_{\\theta_{1}^{i}}(x)(m_{\\theta_{1}^{i}}(x)-m_{\\theta_{2}^{i}}(x))^{T}-(m_{\\theta_{1}^{i}}(x)-m_{\\theta_{2}^{i}}(x))m_{\\theta_{2}^{i}}(x)^{T}\\|}\\\\ &{\\le\\!\\|m_{\\theta_{1}^{i}}(x)-m_{\\theta_{2}^{i}}(x)\\|(m_{\\theta_{1}^{i}}(x)\\|+\\|m_{\\theta_{2}^{i}}(x)\\|)}\\\\ &{\\le\\!C\\|\\theta_{1}^{i}-\\theta_{2}^{i}\\|,}\\end{array}\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "for some constant $C$ , where the last inequality comes from $\\|m_{\\theta_{1}^{i}}(x)\\|<\\infty$ since $\\theta_{1}^{i}\\in\\Omega$ and the Lipschitz continuous function $m_{\\theta^{i}}(x)$ . Similarly, we can get $\\|\\mathbf{P}_{i}m_{\\theta_{1}^{i}}(x)\\!-\\!\\mathbf{P}_{i}m_{\\theta_{2}^{i}}(x)\\|\\leq C\\|\\theta_{1}^{i}-\\theta_{2}^{i}\\|$ . Therefore, $G_{i}(\\theta^{i},x)$ and $g_{i}(\\theta^{i})$ are Lipschitz continuous in $\\theta^{i}\\in\\Omega$ for any $x\\in\\mathcal{X}_{i}$ . ", "page_idx": 25}, {"type": "text", "text": "For the sequence $\\{\\mathbf{D}_{i,n}^{(1)}\\}_{n\\ge0}$ , by applying Theorem 3.2 and conditioned on $\\operatorname*{lim}_{n\\to\\infty}\\theta_{n}=\\theta^{*}$ for an optimal point $\\theta^{*}\\in\\mathcal{L}$ , we have $\\begin{array}{r}{\\operatorname*{lim}_{n\\to\\infty}\\|g_{i}(\\theta_{n}^{i})-g_{i}(\\theta^{*})\\|\\leq\\operatorname*{lim}_{n\\to\\infty}C\\|\\theta_{n}^{i}-\\theta^{*}\\|=0}\\end{array}$ . This implies D(1) $\\mathbf{D}_{i,n}^{(1)}\\to0$ for every $i\\in[N]$ and thus $\\mathbf{D}_{n}^{(1)}\\to0$ as $n\\to\\infty$ almost surely, which satisfies the first condition in (57). ", "page_idx": 25}, {"type": "text", "text": "For the Martingale difference sequence $\\{\\mathbf{D}_{i,n}^{(2,a)}\\}_{n\\ge0}$ , we use Burkholder inequality (e.g., Theorem 2.10 [33], [21]) such that for $p\\geq1$ and some constant $C_{p}$ , ", "page_idx": 25}, {"type": "equation", "text": "$$\n\\mathbb{E}\\left[\\left\\Vert\\sum_{i=1}^{n}\\mathbf{D}_{i,n}^{(2,a)}\\right\\Vert^{p}\\right]\\leq C_{p}\\mathbb{E}\\left[\\left(\\sum_{i=1}^{n}\\left\\Vert\\mathbf{D}_{i,n}^{(2,a)}\\right\\Vert^{2}\\right)^{p/2}\\right].\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "By the definition (66) and Assumption 2.4, for a sample path, $\\operatorname*{sup}_{n}\\|G_{i}(\\theta_{n}^{i},x)\\|<\\infty$ for any $x\\in\\mathcal{X}_{i}$ , as well as $\\operatorname*{sup}_{n}\\|g_{i}(\\theta_{n}^{i})\\|<\\infty$ , which leads to $\\operatorname*{sup}_{n}\\bar{\\|\\varphi_{\\theta_{n}^{i}}^{i}(x)\\|}<\\tilde{\\infty}$ for any $x\\in\\mathcal{X}_{i}$ because of (68). Then, we have $\\operatorname*{sup}_{n}\\|\\mathbf{D}_{i,n}^{(2,a)}\\|\\leq C<\\infty$ for the path-dependent constant $C$ . Taking $p=1$ and we have ", "page_idx": 26}, {"type": "equation", "text": "$$\n\\operatorname*{lim}_{n\\rightarrow\\infty}\\gamma_{n}C_{p}\\sqrt{\\sum_{i=1}^{n}\\left\\lVert\\mathbf{D}_{i,n}^{(2,a)}\\right\\rVert^{2}}\\leq\\operatorname*{lim}_{n\\rightarrow\\infty}C_{p}C\\gamma_{n}\\sqrt{n}=0\\quad a.s.\n$$", "text_format": "latex", "page_idx": 26}, {"type": "text", "text": "Thus, Lebesgue dominated convergence theorem gives ", "page_idx": 26}, {"type": "equation", "text": "$$\n\\operatorname*{lim}_{n\\to\\infty}\\gamma_{n}C_{p}\\mathbb{E}\\left[\\sqrt{\\sum_{i=1}^{n}\\|\\mathbf{D}_{i,n}^{(2,a)}\\|^{2}}\\right]=\\mathbb{E}\\left[\\operatorname*{lim}_{n\\to\\infty}\\gamma_{n}C_{p}\\sqrt{\\sum_{i=1}^{n}\\|\\mathbf{D}_{i,n}^{(2,a)}\\|^{2}}\\right]=0\n$$", "text_format": "latex", "page_idx": 26}, {"type": "text", "text": "and we have $\\begin{array}{r}{\\operatorname*{lim}_{n\\rightarrow{}\\infty}\\gamma_{n}\\mathbb{E}[\\|\\sum_{i=1}^{n}\\mathbf{D}_{i,n}^{(2,a)}\\|]=0.}\\end{array}$ ", "page_idx": 26}, {"type": "text", "text": "For the sequence $\\{\\mathbf{D}_{i,n}^{(2,b)}\\}_{n\\geq0}$ , we have ", "page_idx": 26}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\displaystyle\\sum_{k=1}^{n}\\mathbf{D}_{i,k}^{(2,k)}=\\displaystyle\\sum_{k=1}^{n}\\Big(\\varphi_{\\theta_{k}^{i}}^{i}(X_{k-1}^{i})-\\varphi_{\\theta_{k-1}^{i}}^{i}(X_{k-1}^{i})\\Big)+\\varphi_{\\theta_{0}^{i}}^{i}(X_{0}^{i})-\\varphi_{\\theta_{n}^{i}}^{i}(X_{n}^{i})}&{}\\\\ {\\displaystyle=\\sum_{k=1}^{n}\\Big(\\varphi_{\\theta_{k}^{i}}^{i}(X_{k-1}^{i})-\\varphi_{\\theta_{k}}^{i}(X_{k-1}^{i})+\\varphi_{\\theta_{k}}^{i}(X_{k-1}^{i})-\\varphi_{\\theta_{k-1}}^{i}(X_{k-1}^{i})+\\varphi_{\\theta_{k-1}}^{i}(X_{k-1}^{i})-\\varphi_{\\theta_{k-1}}^{i}(X_{k-1}^{i})}\\\\ {\\displaystyle}&{~~~~+\\,\\varphi_{\\theta_{0}^{i}}^{i}(X_{0}^{i})-\\varphi_{\\theta_{n}^{i}}^{i}(X_{n}^{i}).}&{}\\end{array}\n$$", "text_format": "latex", "page_idx": 26}, {"type": "text", "text": "Since $G_{i}(\\theta^{i},x)$ and $g_{i}(\\theta^{i})$ are Lipschitz continuous in $\\theta^{i}\\in\\Omega,\\varphi_{\\theta^{i}}^{i}(x)$ is also Lipschitz continuous in $\\theta^{i}\\in\\Omega$ and is bounded. We have ", "page_idx": 26}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\left\\|\\displaystyle\\sum_{k=1}^{n}\\mathbf{D}_{i,k}^{(2,b)}\\right\\|\\leq\\left\\|\\displaystyle\\sum_{k=1}^{n}\\varphi_{\\theta_{k}^{i}}^{i}(X_{k-1}^{i})-\\varphi_{\\theta_{k-1}^{i}}^{i}(X_{k-1}^{i})\\right\\|+\\left\\|\\varphi_{\\theta_{0}^{i}}^{i}(X_{0}^{i})\\right\\|+\\left\\|\\varphi_{\\theta_{n}^{i}}^{i}(X_{n}^{i})\\right\\|}\\\\ &{\\phantom{\\leq\\left\\|\\displaystyle\\sum_{k=1}^{n}\\varphi_{\\theta_{k}^{i}}^{i}(X_{k-1}^{i})-\\varphi_{\\theta_{k-1}^{i}}^{i}(X_{k-1}^{i})\\right\\|+D_{1}}\\right\\|}\\\\ &{\\leq\\displaystyle\\sum_{k=1}^{n}D_{2}D_{\\Omega}\\gamma_{k}+D_{1}}\\end{array}\n$$", "text_format": "latex", "page_idx": 26}, {"type": "text", "text": "where $\\lVert\\varphi_{\\theta_{0}^{i}}^{i}(X_{0}^{i})\\rVert+\\lVert\\varphi_{\\theta_{n}^{i}}^{i}(X_{n}^{i})\\rVert\\,\\le\\,D_{1}$ for a given sample path, $D_{2}$ is the Lipschitz constant of $\\varphi_{\\theta^{i}}^{i}(x)$ , and $\\|\\nabla F_{i}(x^{i},X^{i})\\|\\le D_{\\Omega}$ for any $x^{i}\\in\\Omega$ and $X^{i}\\in\\mathcal{X}^{i}$ . Then, ", "page_idx": 26}, {"type": "equation", "text": "$$\n\\gamma_{n}\\left\\|\\sum_{k=1}^{n}\\mathbf{D}_{i,k}^{(2,b)}\\right\\|\\leq D_{2}D_{\\Omega}\\gamma_{n}\\sum_{k=1}^{n}\\gamma_{k}+\\gamma_{n}D_{1}\\rightarrow0\\quad\\mathrm{as}\\ n\\rightarrow\\infty\n$$", "text_format": "latex", "page_idx": 26}, {"type": "text", "text": "because $\\begin{array}{r}{\\gamma_{n}\\sum_{k=1}^{n}\\gamma_{k}\\,=\\,O(n^{1-2a})}\\end{array}$ by assumption 2.3. Therefore, the second condition of C4 is satisfied. ", "page_idx": 26}, {"type": "text", "text": "D.3 Analysis of C5 ", "text_level": 1, "page_idx": 26}, {"type": "text", "text": "We now analyze condition C5. The decreasing rate of each term in (56) has been proved in Appendix C. Specifically, by assumption 2.4, there exists a compact subset for a given sample path, and ", "page_idx": 26}, {"type": "text", "text": "\u2022 we have shown that $\\left\\|r_{n}^{(A)}\\right\\|=O(\\eta_{n})$ a.s., which implies $\\left\\|r_{n}^{(A)}\\right\\|=o(\\sqrt{\\gamma_{n}})$ a.s. \u2022 For $\\textstyle{\\frac{1}{N}}\\sum_{i=1}^{N}\\xi_{n}^{i}$ , in the case of increasing commun\u221aication i\u221anterval,\u221a $\\begin{array}{r}{\\frac{1}{N}\\sum_{i=1}^{N}\\xi_{n}^{i}=O(\\gamma_{n}+}\\end{array}$ $\\eta_{n},$ ), by Assumption 2.3-i\u221ai), we know $(\\gamma_{n}+\\eta_{n})/\\sqrt{\\gamma_{n}}=\\sqrt{\\gamma_{n}}+\\sqrt{\\gamma_{n}}K_{\\tau_{n}}^{L+1}=o(1)$ such that $\\begin{array}{r}{\\|\\frac{1}{N}\\sum_{i=1}^{N}\\xi_{n}^{i}\\|\\,=\\,o(\\sqrt{\\gamma_{n}})}\\end{array}$ almost surely. On the other hand, in the case of bounded communication interval, $\\begin{array}{r}{\\frac{1}{N}\\sum_{i=1}^{N}\\xi_{n}^{i}=O(\\gamma_{n})}\\end{array}$ such that $\\begin{array}{r}{\\|\\frac{1}{N}\\sum_{i=1}^{N}\\xi_{n}^{i}\\|=o(\\sqrt{\\gamma_{n}})}\\end{array}$ a.s. ", "page_idx": 26}, {"type": "text", "text": "\u2022 Since $\\operatorname{sup}_{n}\\|\\nu_{n}^{i}\\|\\,<\\,\\infty$ almost surely, we have $\\begin{array}{r l}{\\operatorname*{sup}_{p}\\|\\frac{1}{N}\\sum_{i=1}^{N}\\sum_{k=0}^{p}(\\nu_{k}^{i}\\,-\\,\\nu_{k+1}^{i})\\|\\,=}&{}\\end{array}$ $\\begin{array}{r l}{\\operatorname*{sup}_{p}\\|\\frac{1}{N}\\sum_{i=1}^{N}(\\nu_{0}^{i}\\,-\\,\\nu_{p+1}^{i})\\|}&{<\\,\\infty}\\end{array}$ almost surely. Then, $\\begin{array}{r}{\\sqrt{\\gamma_{p}}\\lVert\\frac{1}{N}\\sum_{i=1}^{N}\\sum_{k=0}^{p}(\\nu_{k}^{i}\\ -}\\end{array}$ $\\nu_{k+1}^{i})\\|=O(\\sqrt{\\gamma_{p}})$ leads to $\\begin{array}{r}{\\sqrt{\\gamma_{p}}\\|\\frac{1}{N}\\sum_{i=1}^{N}\\sum_{k=0}^{p}(\\nu_{k}^{i}-\\nu_{k+1}^{i})\\|=o(1)}\\end{array}$ a.s. ", "page_idx": 27}, {"type": "text", "text": "Let $\\begin{array}{r}{r_{n}^{(1)}\\triangleq r_{n}^{(A)}+\\frac{1}{N}\\sum_{i=1}^{N}\\xi_{n}^{i}}\\end{array}$ and $\\begin{array}{r}{r_{n}^{(2)}\\triangleq\\frac{1}{N}\\sum_{i=1}^{N}(\\nu_{k\\_}^{i}-\\nu_{k+1}^{i})_{i}}\\end{array}$ . From above, we can see that C5 in Theorem D.1 is satisfied and we show that all the conditions in Theorem D.1 have been satisfied. ", "page_idx": 27}, {"type": "text", "text": "D.4 CLosed Form of Limitimg Covariance Matrix ", "text_level": 1, "page_idx": 27}, {"type": "text", "text": "Lastly, we need to analyze the closed-form expression of $\\mathbf{U}$ as in C4 (b) of Theorem D.1. Recall that $\\begin{array}{r}{\\dot{\\mathbf U}=\\frac{1}{N^{2}}\\sum_{i=1}^{N}\\mathbf{U}_{i}}\\end{array}$ and $\\mathbf{U}_{i}=g_{i}(\\theta^{*})$ in (69). We now give the exact form of function $g_{i}(\\theta^{*})$ as follows: ", "page_idx": 27}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\Vert\\widehat{\\mathbf{u}}^{(1)}\\Vert}&{=\\sum_{t\\leq t}\\bigg[\\sum_{i=1}^{t}\\widehat{v}_{i}(x,y)\\log(\\gamma^{\\top}-\\left(\\sum_{i=1}^{N}r_{i}(x,y)\\log(x,y)\\right)\\left(\\sum_{i=1}^{N}\\varrho_{i}(x,y)\\log(x)\\right)^{T}\\bigg]}\\\\ &{=\\mathbb{E}\\left[\\left(\\sum_{i=1}^{N}\\nabla F_{i}(x^{(i)},X_{i})-\\nabla f_{i}(y^{(i)})\\right)\\left(\\sum_{i=1}^{N}r_{i}(x^{(i)},X_{i})-\\nabla f_{i}(y^{(i)})\\right)^{T}\\right]}\\\\ &{\\quad-\\mathbb{E}\\left[\\left(\\sum_{i=1}^{N}r_{i}(x^{(i)},X_{i})-\\nabla f_{i}(y^{(i)})\\right)\\left(\\sum_{i=1}^{N}r_{i}(x^{(i)},X_{i})-\\nabla f_{i}(y^{(i)})\\right)^{T}\\right]}\\\\ &{=\\mathbb{E}\\left[\\left(\\nabla F_{i}(x^{(i)},X_{i})-\\nabla f_{i}(y^{(i)})\\left(\\nabla F_{i}(x^{(i)},X_{i})-\\nabla f_{i}(y^{(i)})\\right)^{T}\\right]}\\\\ &{\\quad+\\mathbb{E}\\left[\\left(\\nabla F_{i}(x^{(i)},X_{i})-\\nabla f_{i}(y^{(i)})\\left(\\sum_{i=1}^{N}r_{i}(x^{(i)},X_{i})-\\nabla f_{i}(y^{(i)})\\right)^{T}\\right]}\\\\ &{\\quad+\\mathbb{E}\\left[\\left(\\sum_{i=1}^{N}r_{i}(x^{(i)},X_{i})-\\nabla f_{i}(y^{(i)})\\right)\\left(\\sum_{i=1}^{N}r_{i}(x^{(i)},X_{i})-\\nabla f_{i}(y^{(i)})\\right)^{T}\\right]}\\\\ &{\\quad+\\mathbb{E}\\left[\\left(\\sum_{i=1}^{N}r_{i}(x^{(i)},X_{i})-\\nabla f_{i}(y^{(i)})\\right)\\left(\\nabla F_{i}(x^{(i)},X_{i})-\\nabla f_{i}(y^{(i)})\\right)^{T}\\right]}\\\\ &{=\\mathrm{ComC}[\\nabla F_{i}(x \n$$", "text_format": "latex", "page_idx": 27}, {"type": "text", "text": "where the second equality comes from the recursive form of $m_{\\theta^{i}}(x)$ in (45), and that the process $\\{X_{n}\\}_{n\\ge0}$ is in its stationary regime, i.e., $X_{0}\\sim\\pi_{i}$ from the beginning. The last equality comes from rewriting $\\operatorname{Cov}(\\nabla F_{i}(\\theta^{*},X_{i}),\\nabla F_{i}(\\theta^{*},X_{j}))$ in a matrix form. Note that $g_{i}(\\theta^{*})$ is exactly the asymptotic covariance matrix of the underlying Markov chain $\\{X_{n}^{i}\\}_{n\\ge0}$ associated with the test function $\\nabla F_{i}(\\theta^{*},\\cdot)$ . By utilizing the following lemma, we can obtain the explicit form of $\\mathbf{V}$ as defined in (60). ", "page_idx": 27}, {"type": "text", "text": "Lemma D.2 (Lemma D.2.2 [41]). If all the eigenvalues of matrix M have negative real part, then for every positive semi-definite matrix $\\mathbf{U}$ there exists a unique positive semi-definite matrix $\\mathbf{V}$ satisfying $\\mathbf{U}+\\mathbf{\\bar{M}}\\mathbf{V}+\\mathbf{V}\\mathbf{M}^{T}=\\mathbf{0}$ . The explicit solution $\\mathbf{V}$ is given as ", "page_idx": 27}, {"type": "equation", "text": "$$\n\\mathbf{V}=\\int_{0}^{\\infty}e^{\\mathbf{M}t}\\mathbf{U}e^{(\\mathbf{M}^{T})t}d t.\n$$", "text_format": "latex", "page_idx": 27}, {"type": "text", "text": "D.5 CLT of Polyak-Ruppert Averaging ", "text_level": 1, "page_idx": 27}, {"type": "text", "text": "We now consider the CLT result of Polyak-Ruppert averaging $\\begin{array}{r}{\\bar{\\theta}_{n}=\\frac{1}{n}\\sum_{k=0}^{n-1}\\theta_{k}}\\end{array}$ . The steps follow similar way by verifying that the conditions in the related CLT of Polyak-Ruppert averaging for the stochastic approximation are satisfied. The additional assumption is given below. ", "page_idx": 27}, {"type": "text", "text": "C6. For the sequence $\\{r_{n}\\}$ in (38), $\\begin{array}{r}{n^{-1/2}\\sum_{k=0}^{n}r_{k}^{(1)}\\to0}\\end{array}$ with probability 1. ", "page_idx": 28}, {"type": "text", "text": "Then, the CLT of Polyak-Ruppert averaging is as follows. ", "page_idx": 28}, {"type": "text", "text": "Theorem D.3 (Theorem 3.2 of [29]). Consider the iteration (38), assume C1, $C3$ , C4, C5 in Theorem D.1 are satisfied. Moreover, assume $C6$ is satisfied. Then, with step size $\\gamma_{n}\\sim\\gamma_{\\star}/n^{a}$ for $a\\in(0.5,1)$ , we have ", "page_idx": 28}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\sqrt{n}(\\bar{\\theta}_{n}-\\theta^{*})\\xrightarrow[n\\rightarrow\\infty]{d i s t.}\\mathcal{N}(0,\\mathbf{V}^{\\prime}),}\\end{array}\n$$", "text_format": "latex", "page_idx": 28}, {"type": "text", "text": "where $\\mathbf{V}^{\\prime}=\\mathbf{H}^{-1}\\mathbf{U}\\mathbf{H}^{-T}$ . ", "page_idx": 28}, {"type": "text", "text": "Discussion about C1 and C3 can be found in Section D.1. Condition C4 has been analyzed in Section D.2 and condition C5 has been examined in Section D.3. The only condition left to analyze is C6, which is based on the results obtained in Section D.3. In view of (56), $\\begin{array}{r}{r_{n}^{(1)}=r_{n}^{(A)}+\\frac{1}{N}\\sum_{i=1}^{N}\\xi_{n+1}^{i}}\\end{array}$ , so C6 is equivalent to ", "page_idx": 28}, {"type": "equation", "text": "$$\nn^{-1/2}\\sum_{k=1}^{n}\\left[r_{k}^{(A)}+\\frac{1}{N}\\sum_{i=1}^{N}\\left(\\xi_{k+1}^{i}\\right)\\right]\\rightarrow0\\quad w.p.1.\n$$", "text_format": "latex", "page_idx": 28}, {"type": "text", "text": "In Section D.3, we have shown that $\\begin{array}{r}{\\left\\|r_{n}^{(A)}\\right\\|=O(\\eta_{n}),\\,\\frac{1}{N}\\sum_{i=1}^{N}\\xi_{n}^{i}=O(\\gamma_{n})}\\end{array}$ . Note that by Assumption 2.3, we consider bounded communication interval for step size $\\gamma_{n}\\sim\\gamma_{\\star}/n^{a}$ for $a\\in(0.5,1)$ , and hence, $\\eta_{n}={\\cal O}(\\gamma_{n})$ such that $\\left\\|r_{n}^{(A)}\\right\\|=O(\\gamma_{n})$ . We then know that ", "page_idx": 28}, {"type": "equation", "text": "$$\n\\sum_{k=1}^{n}\\left\\|r_{n}^{(A)}\\right\\|=O(n^{1-a}),\\quad\\sum_{k=1}^{n}\\|{\\frac{1}{N}}\\sum_{i=1}^{N}\\xi_{n}^{i}\\|=O(n^{1-a}),\n$$", "text_format": "latex", "page_idx": 28}, {"type": "text", "text": "such that ", "page_idx": 28}, {"type": "equation", "text": "$$\nn^{-1/2}\\sum_{k=1}^{n}\\left\\|r_{k}^{(A)}+\\frac{1}{N}\\sum_{i=1}^{N}\\left(\\xi_{k+1}^{i}\\right)\\right\\|=O(n^{1/2-a})=o(1),\n$$", "text_format": "latex", "page_idx": 28}, {"type": "text", "text": "which proved (79) and C6 is verified. Therefore, Theorem D.3 is proved under our Assumptions 2.1 - 2.5. ", "page_idx": 28}, {"type": "text", "text": "E Discussion on the comparison of Theorem 3.3 to the CLT result in [51] ", "text_level": 1, "page_idx": 28}, {"type": "text", "text": "As a byproduct of our Theorem 3.3, we have the following corollary. ", "page_idx": 28}, {"type": "text", "text": "Corollary E.1. Under Assumptions 2.1 - 2.5, for the sub-sequence $\\{n_{l}\\}_{l\\ge0}$ where $K_{l}=K$ for all $l$ , we have ", "page_idx": 28}, {"type": "equation", "text": "$$\n\\frac{1}{\\sqrt{n_{l}}}\\sum_{k=1}^{l}(\\bar{\\theta}_{n_{k}}-\\theta^{*})\\xrightarrow[l\\rightarrow\\infty]{d i s t.}N(0,{\\bf V}^{\\prime})\n$$", "text_format": "latex", "page_idx": 28}, {"type": "text", "text": "Proof. Since $K_{l}=K$ for all $l$ , we have $n_{l}=K l$ . There is an existing result showing the CLT result of the partial sum of a sub-sequence (after normalization) has the same normal distribution as the partial sum of the original sequence. ", "page_idx": 28}, {"type": "text", "text": "Theorem E.2 (Theorem 14.4 of [8]). Given a sequence of random variable $\\theta_{1},\\theta_{2},\\cdots$ with partial sum $\\begin{array}{r}{S_{n}\\triangleq\\sum_{k=1}^{n}\\theta_{k}}\\end{array}$ such that \u2212nd\u2212i\u2192\u2212st\u2212\u221e.\u2192N(0, V). Let nl be some positive random variable taking integer value such that $\\theta_{n_{l}}$ is on the same space as $\\theta_{n}$ . In addition, for some sequence $\\{b_{l}\\}_{l\\ge0}$ going to infinity, nl/bl \u2192c for a positive constant c. Then,\u221a1nl Snl l\u2212d\u2212\u2192is\u2212t\u221e.\u2192 $\\begin{array}{r}{{\\frac{1}{\\sqrt{n_{l}}}}S_{n_{l}}\\ {\\frac{d i s t.}{l\\rightarrow\\infty}}\\,{\\mathcal{N}}(0,\\mathbf{V})}\\end{array}$ ", "page_idx": 28}, {"type": "text", "text": "From Theorem E.2 and our Theorem 3.3, we have $\\begin{array}{r}{\\frac{1}{\\sqrt{n_{l}}}\\sum_{k=1}^{l}(\\bar{\\theta}_{n_{k}}-\\theta^{*})\\xrightarrow[l\\rightarrow\\infty]{d i s t.}\\mathcal{N}(0,\\mathbf{V}^{\\prime})}\\end{array}$ . ", "page_idx": 28}, {"type": "text", "text": "Recently, [51] studied the CLT result under the LSGD-FP algorithm with $i.i.d$ sampling (with slightly different setting of the step size). We are able recover Theorem 3.1 of [51] under the constant communication interval while adjusting their step size to make a fair comparison. We state their algorithm below for self-contained purpose. During each communication interval $n\\in(n_{l},n_{l+1}]$ , ", "page_idx": 29}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\theta_{n+1}^{i}=\\left\\{\\theta_{n}^{i}-\\gamma_{l}\\nabla F_{i}(\\theta_{n}^{i},X_{n}^{i})\\right.\\quad}&{\\mathrm{if~}\\,n\\in(n_{l},n_{l+1}),}\\\\ &{\\left.\\frac{1}{N}\\sum_{i=1}^{N}(\\theta_{n}^{i}-\\gamma_{l}\\nabla F_{i}(\\theta_{n}^{i},X_{n}^{i}))\\quad\\right.\\quad\\mathrm{if~}\\,n=n_{l+1}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 29}, {"type": "text", "text": "The CLT result associated with (83) is given below. ", "page_idx": 29}, {"type": "text", "text": "Theorem E.3 (Theorem 3.1 of [51]). Under LSGD-FP algorithm with i.i.d. sampling, we have ", "page_idx": 29}, {"type": "equation", "text": "$$\n\\frac{\\sqrt{n_{l}}}{l}\\sum_{k=1}^{l}\\left(\\bar{\\theta}_{n_{k}}-\\theta^{*}\\right)\\xrightarrow[l\\rightarrow\\infty]{d i s t.}\\mathcal{N}(0,\\nu{\\bf V}^{\\prime}),\n$$", "text_format": "latex", "page_idx": 29}, {"type": "text", "text": "where $\\begin{array}{r}{\\nu\\triangleq\\operatorname*{lim}_{l\\to\\infty}\\frac{1}{l^{2}}(\\sum_{k=1}^{l}K_{l})(\\sum_{k=1}^{l}K_{l}^{-1}).}\\end{array}$ . ", "page_idx": 29}, {"type": "text", "text": "Note that $\\nu=1$ for constant $K$ . We can rewrite (84) as ", "page_idx": 29}, {"type": "equation", "text": "$$\n\\frac{\\sqrt{n_{l}}}{l}\\sum_{k=1}^{l}\\left(\\bar{\\theta}_{n_{k}}-\\theta^{*}\\right)=\\frac{\\sqrt{n_{l}}}{\\sqrt{l}}\\frac{1}{\\sqrt{l}}\\sum_{k=1}^{l}(\\bar{\\theta}_{n_{k}}-\\theta^{*})=\\sqrt{K}\\frac{1}{\\sqrt{l}}\\sum_{k=1}^{l}(\\bar{\\theta}_{n_{k}}-\\theta^{*})\n$$", "text_format": "latex", "page_idx": 29}, {"type": "text", "text": "such that ", "page_idx": 29}, {"type": "equation", "text": "$$\n\\frac{1}{\\sqrt{l}}\\sum_{k=1}^{l}(\\bar{\\theta}_{n_{k}}-\\theta^{*})\\xrightarrow[l\\rightarrow\\infty]{d i s t.}{\\mathcal{N}}(0,\\frac{1}{K}{\\bf V}^{\\prime}).\n$$", "text_format": "latex", "page_idx": 29}, {"type": "text", "text": "Note that the step size in (83) keeps unchanged during each communication interval, while ours in (1) keeps decreasing even in the same communication interval. This makes our step size decreasing faster than theirs. To make a fair comparison, we only choose a sub-sequence $\\{n_{K l}\\}_{l\\ge0}$ in (86) such that it is \u2018equivalent\u2019 to see that our step sizes become the same at each aggregation step. In this case, we again use Theorem E.2 to obtain ", "page_idx": 29}, {"type": "equation", "text": "$$\n\\frac{1}{\\sqrt{K l}}\\sum_{s=1}^{l}(\\bar{\\theta}_{n_{K s}}-\\theta^{*})\\xrightarrow[l\\rightarrow\\infty]{d i s t.}\\mathcal{N}(0,\\frac{1}{K}{\\bf V}^{\\prime}),\n$$", "text_format": "latex", "page_idx": 29}, {"type": "text", "text": "such that ", "page_idx": 29}, {"type": "equation", "text": "$$\n\\frac{1}{\\sqrt{l}}\\sum_{s=1}^{l}(\\bar{\\theta}_{n_{K s}}-\\theta^{*})=\\sqrt{K}\\frac{1}{\\sqrt{K l}}\\sum_{s=1}^{l}(\\bar{\\theta}_{n_{K s}}-\\theta^{*})\\xrightarrow[l\\rightarrow\\infty]{d i s t.}\\mathcal{N}(0,\\mathbf{V}^{\\prime}).\n$$", "text_format": "latex", "page_idx": 29}, {"type": "text", "text": "Therefore, our Corollary E.1 also recovers Theorem 3.1 of [51] under the constant communication interval $K$ , but with more general communication patterns and Markovian sampling. ", "page_idx": 29}, {"type": "text", "text": "F Discussion on Communication Patterns ", "text_level": 1, "page_idx": 29}, {"type": "text", "text": "F.1 Examples of Communication Matrix W ", "text_level": 1, "page_idx": 29}, {"type": "text", "text": "Metropolis Hasting Algorithm: In the decentralized learning such as D-SGD, HLSGD and DFL, W at the aggregation step can be generated locally using the Metropolis Hasting algorithm based on the underlying communication topology, and is deterministic [62, 43, 80]. Specifically, each agent $i$ exchanges its degree $d_{i}$ with its neighbors $j\\in N(i)$ , forming the weight $\\mathbf{W}(i,j)=\\operatorname*{min}\\{1/d_{i},\\bar{1}/d_{j}\\}$ for $j~\\in~N(i)$ and $\\begin{array}{r}{\\mathbf{W}(i,i)\\,=\\,1\\,-\\,\\sum_{j\\neq N(i)}\\mathbf{W}(i,j)}\\end{array}$ . In this case, W is doubly stochastic and symmetric. By Perron-Frobenius theorem, its SLEM $\\lambda_{2}(\\mathbf{W})~<~1$ . Then, $\\|\\mathbf{W}^{T}\\mathbf{W}\\mathrm{~-~}\\mathbf{J}\\|\\mathrm{~=~}$ $\\|\\mathbf{\\bar{W}}^{2}-\\mathbf{J}\\|=\\dot{\\lambda}_{2}^{2}(\\mathbf{W})<1$ , which satisfies Assumption 2.5-ii). It is worth noting that this algorithm is robust to time-varying communication topologies. ", "page_idx": 29}, {"type": "text", "text": "Client Sampling in FL: For LSGD-FP studied in [67, 76, 42], $\\mathbf{W}\\,=\\,\\mathbf{11}^{T}/N$ trivially satisfies Assumption 2.5-ii). For LSGD-PP on the other hand, only a small fraction of agents participate in each aggregation step for consensus [50, 30]. Denote by $\\boldsymbol{S}$ a randomly selected set of agents (without replacement) of fixed size $|S|\\in\\{1,2,\\cdots\\,,N\\}$ at time $n$ and $\\mathbf{W}_{S}$ plays a role of aggregating $\\theta_{n}^{i}$ for agent $i\\in S$ . Additionally, the central server needs to broadcast updated parameter $\\theta_{n+1}$ to the newly selected set $S^{\\prime}$ with the same size, which results in a bijective mapping $\\sigma$ (for $s\\rightarrow s^{\\prime}$ and $[N]/S\\to[N]/S^{\\prime})$ and a corresponding permutation matrix ${\\mathbf{T}}_{\\ensuremath{S}\\rightarrow S^{\\prime}}$ . Then, the communication matrix becomes $\\dot{\\mathbf{W}}=\\mathbf{T}_{\\mathcal{S}\\rightarrow\\mathcal{S}^{\\prime}}\\mathbf{W}_{\\mathcal{S}}.$ .6 Specifically, $\\mathbf{T}_{S\\rightarrow S^{\\prime}}(i,j)=1$ if $j=\\sigma(i)$ and $\\mathbf{T}_{S\\rightarrow S^{\\prime}}(i,j)=0$ otherwise. Besides, $\\mathbf{W}_{S}(i,j)=1/|S|$ for $i,j\\in S$ , $\\mathbf{W}_{S}(i,i)=1$ for $i\\not\\in{\\cal S}$ , and $\\mathbf{W}_{S}(i,j)=0$ otherwise. Note that $\\mathbf{W}_{S}$ is now a random matrix, since $\\boldsymbol{S}$ is a randomly chosen subset of size $|{\\mathcal{S}}|$ . Clearly, for each choice of $\\boldsymbol{S}$ , $\\mathbf{W}_{S}$ is doubly stochastic, symmetric and ${\\mathbf W}_{S}^{2}={\\mathbf W}_{S}$ . Taking the expectation of $\\mathbf{W}_{S}$ w.r.t the randomly selected set $\\boldsymbol{S}$ gives $\\mathbb{E}_{S}[\\mathbf{W}_{S}](i,i)=\\mathbf{\\bar{1}}-(|S|-1)/N$ for $i~\\in~[N]$ and $\\mathbb{E}_{S}[\\mathbf{W}_{S}](i,j)\\,=\\,(|S|\\,-\\,1)/N(N\\,-\\,1)$ for $i\\ne j$ . Note that ${\\mathbb E}_{S}[\\mathbf{W}_{S}]$ has all positive entries. Therefore, we use the fact $\\mathbf{T}^{T}\\mathbf{T}=\\mathbf{I}$ for permutation matrix $\\mathbf{T}$ such that $\\|\\bar{\\mathbb{E}}[\\mathbf{W}]-$ $\\mathbf{\\dot{J}}\\|\\ =\\ \\|\\mathbb{E}_{S,S^{\\prime}}[\\mathbf{W}_{S}^{T}\\mathbf{T}_{S,S^{\\prime}}^{T}\\mathbf{T}_{S,S^{\\prime}}\\mathbf{W}_{S}]-\\mathbf{J}\\|\\ =\\ \\|\\mathbb{E}_{S}[\\mathbf{W}_{S}^{T}\\mathbf{\\dot{W}}_{S}]-\\mathbf{J}\\|\\ =\\ \\|\\mathbb{E}_{S}[\\mathbf{W}_{S}]-\\mathbf{J}\\|^{\\top}\\ <\\ 1$ by Perron\u2013Frobenius theorem and eigendecomposition, which satisfies Assumption 2.5-ii). ", "page_idx": 29}, {"type": "text", "text": "", "page_idx": 30}, {"type": "text", "text": "F.2 Discussion on partial client sampling ", "text_level": 1, "page_idx": 30}, {"type": "text", "text": "The commonly used partial client sampling algorithm in the FL literature [50, 30] is FedAvg as follows: ", "page_idx": 30}, {"type": "text", "text": "1. At time $n$ , the central server updates its global parameter $\\begin{array}{r}{\\theta_{n}\\;=\\;\\frac{1}{|S|}\\sum_{i\\in S}\\theta_{n}^{i}}\\end{array}$ from the agents in the previous set $\\boldsymbol{S}$ . Then, the central server selects a new subset of agents $S^{\\prime}$ and broadcasts $\\theta_{n}$ to agent $i\\in\\mathcal{S}^{\\prime}$ , i.e., $\\theta_{n}^{i}=\\theta_{n}$ ;   \n2. Each selected agent $i$ computes $K$ steps of SGD locally and consecutively updates its local parameter $\\theta_{n+1}^{i},\\cdot\\cdot\\cdot,\\theta_{n+K}^{i}$ according to (1a);   \n3. Each selected agent $i\\in S^{\\prime}$ uploads $\\theta_{n+K}^{i}$ to the central server. ", "page_idx": 30}, {"type": "text", "text": "Then, the central server repeats the above three steps with $\\theta_{n+K}$ and a new set of selected agents. ", "page_idx": 30}, {"type": "text", "text": "In our client sampling scheme, at the aggregation step $n$ , the design of $\\mathbf{W}_{S}$ results in $\\tilde{\\theta}_{n}^{i}\\ =$ $\\textstyle{\\frac{1}{|S|}}\\sum_{j\\in S}\\theta_{n}^{j}$ for a selected agent $i\\ \\in\\ S$ , and $\\widetilde{\\theta}_{n}^{i}\\,=\\,\\theta_{n}^{i}$ for an unselected agent $i\\not\\in\\mathcal{S}$ . Meanwhile, the central server updates the global parameter ${\\tilde{\\theta}}_{n}={\\tilde{\\theta}}_{n}^{i}$ for $i\\in S$ . Then, the permutation matrix ${\\mathbf{T}}_{S\\rightarrow S^{\\prime}}$ ensures that the newly selected agent $i\\in\\mathcal{S}^{\\prime}$ will use $\\widetilde{\\theta}_{n}$ as the initial point for its subsequent SGD iterations. Consequently, from the selected agents\u2019 perspective, the communication matrix $\\dot{\\mathbf{W}}=\\mathbf{T}_{\\mathcal{S}\\rightarrow\\mathcal{S}^{\\prime}}\\mathbf{W}_{\\mathcal{S}}$ corresponds to step 1 in FedAvg. As we can observe, both algorithms update the global parameter identically from the central server\u2019s viewpoint, rendering them mathematically equivalent regarding the global parameter update. ", "page_idx": 30}, {"type": "text", "text": "We acknowledge that under the $i.i.d$ sampling strategy, the behavior of unselected agents in our algorithm differs from FedAvg. Specifically, unselected agents are idle in FedAvg, while they continue the SGD computation in our algorithm (despite not contributing to the global parameter update). Importantly, when an unselected agent is later selected, the central server overwrites its local parameter during the broadcasting process. This ensures that the activities of agents when they are unselected have no impact on the global parameter update. ", "page_idx": 30}, {"type": "text", "text": "To our knowledge, the FedAvg algorithm under the Markovian sampling strategy remains unexplored in the FL literature. Extrapolating the behavior of unselected agents in FedAvg from $i.i.d$ sampling to Markovian sampling suggests that unselected agents would remain idle. In contrast, our algorithm enables unselected agents to continue evolving ${\\bar{X}}_{n}^{i}$ . These additional transitions contribute to faster mixing of the Markov chain for each unselected agent and a smaller bias of $F_{i}(\\theta,X_{n}^{i})$ relative to its mean field $f_{i}(\\theta)$ , potentially accelerating the convergence. ", "page_idx": 30}, {"type": "text", "text": "G Additional Simulation ", "text_level": 1, "page_idx": 30}, {"type": "text", "text": "G.1 Simulation Setup in Section 4 ", "text_level": 1, "page_idx": 30}, {"type": "text", "text": "This simulation is performed on a PC with an AMD R9 5950X, RTX 3080 and 128 GB RAM. In this simulation, we assume that agents follow the DSGD algorithm (1). In Figure 2(a) - 2(c), each agent holds a disjoint local dataset (non-overlapping data points for every agent), while we distribute the ijcnn1 dataset [14] with more varied distribution among 100 agents by leveraging Dirichlet distribution with the default alpha value of 0.5 in Figure 2(d) - 2(f). ", "page_idx": 30}, {"type": "text", "text": "", "page_idx": 31}, {"type": "text", "text": "Moreover, we assume that all agents are distributed over a communication network. In order to create this network among 100 agents and the graph-like dataset structure held by each agent, we utilize connected sub-graphs from the real-world graph Facebook in SNAP [49]. All 100 agents collaborate together to generate a deterministic communication matrix $\\mathbf{W}=[W_{i j}]$ with Metropolis Hasting algorithm of the following form: For $i,j\\in[N]$ , we have ", "page_idx": 31}, {"type": "equation", "text": "$$\n\\begin{array}{l}{W_{i j}=\\left\\{\\underset{0}{\\mathrm{min}}\\left\\{\\frac{1}{d_{i}},\\frac{1}{d_{j}}\\right\\}\\quad\\mathrm{if~agent}\\;j\\;\\mathrm{i}}\\\\ {W_{i i}=1-\\displaystyle\\sum_{j\\in[N]}W_{i j},}\\end{array}\\right.}\\\\ {W_{i i}=1-\\sum_{j\\in[N]}W_{i j},}\\end{array}\n$$", "text_format": "latex", "page_idx": 31}, {"type": "text", "text": "where $d_{i}$ represents the degree of agent $i$ in the graph. The communication interval $K$ is set to 1, as is the usual choice in DSGD [71, 80, 61, 68]. ", "page_idx": 31}, {"type": "text", "text": "For the first group of agents, we assume they have full access to their datasets, thus performing i.i.d. sampling or single shuffling. In particular, ", "page_idx": 31}, {"type": "text", "text": "\u2022 i.i.d. sampling employed by agent $i$ means that the data point $X_{n}^{i}$ is independently and uniformly sampled from its dataset $\\mathcal{X}_{i}$ at each time $n$ .   \n\u2022 Single shuffilng, by its name, only shuffles the dataset once and adheres to that specific order throughout the training process. ", "page_idx": 31}, {"type": "text", "text": "On the other hand, within the second group of agents, we assume that they hold graph-like datasets. Now, we introduce simple random walk (SRW), non-backtracking random walk (NBRW), and self-repellent random walk (SRRW) in order: ", "page_idx": 31}, {"type": "text", "text": "\u2022 SRW refers to the walker that chooses one of the neighboring nodes uniformly at random. \u2022 NBRW, as studied in [2, 48, 5], is a variation of SRW, which selects one of the neighbors uniformly at random, with the exception of the one visited in the last step. \u2022 SRRW, recently proposed by [25], is designed with a nonlinear transition kernel $\\mathbf{K}[\\mathbf{x}]\\in$ $[0,1]^{N\\times N}$ of the following form: ", "page_idx": 31}, {"type": "equation", "text": "$$\nK_{i j}[\\mathbf{x}]\\triangleq\\frac{P_{i j}(x_{j}/\\mu_{j})^{-\\alpha}}{\\sum_{k\\in[N]}P_{i k}(x_{k}/\\mu_{k})^{-\\alpha}},\\quad\\forall i,j\\in[N],\n$$", "text_format": "latex", "page_idx": 31}, {"type": "text", "text": "where matrix $\\mathbf{P}=[P_{i j}]$ is the transition kernel of the baseline Markov chain and $\\pmb{\\mu}=[\\mu_{i}]$ is its corresponding stationary distribution. Additionally, $\\alpha$ denotes the force of self repellence, and larger $\\alpha$ leads to stronger force of self repellence, thus higher sampling efficiency [25, Corollary 4.3]. Moreover, vector $\\mathbf{x}\\,\\in\\,\\mathbb{R}^{N}$ is in the interior of probability simplex, representing the empirical distribution, in other words, the visit frequency of each node in the graph. The update rule of this empirical distribution is in the following form: ", "page_idx": 31}, {"type": "equation", "text": "$$\n{\\bf x}_{n+1}={\\bf x}_{n}+\\beta_{n+1}(\\delta_{X_{n+1}}-{\\bf x}_{n}),\n$$", "text_format": "latex", "page_idx": 31}, {"type": "text", "text": "where $\\beta_{n}\\triangleq(n+1)^{-b}$ is the step size of SRRW iterates. $b=1$ was original proposed in [25] and is recently extended to $b\\in(0.5,1)$ in [39]. In this simulation, we use SRW as the baseline Markov chain of SRRW, and in turn $\\pmb{\\mu}$ is proportional to the degree distribution. We also assume $\\mathbf{x}_{0}\\,=\\,\\mathbf{1}/N$ , i.e., each node has been visited once, and choose the step size $\\beta_{n}=(n+1)^{-0.8}$ , force of self repellence $\\alpha=20$ according to the suggestion in [39, Section 4]. ", "page_idx": 31}, {"type": "text", "text": "Since SRW, NBRW, and SRRW all admit the stationary distribution that is proportional to degree distribution, in order to obtain unfirom target in (15), we need to reweight the gradient computed by each agent $i$ in order to maintain an asymptotic unbiased gradient. Thus, agent $i$ should modify its SGD update from (1a) to the following: ", "page_idx": 31}, {"type": "equation", "text": "$$\n\\theta_{n+1/2}^{i}=\\theta_{n}^{i}-\\gamma_{n+1}\\nabla F_{i}(\\theta_{n}^{i},X_{n}^{i})/d(X_{n}^{i}).\n$$", "text_format": "latex", "page_idx": 31}, {"type": "image", "img_path": "j6Zsoj544N/tmp/c3ce724558190e557f8b9b5d15c7f1d762541dc7f183c9be4e8e48eaefbd9642.jpg", "img_caption": ["Figure 3: Image classification experiment. From left to right: (a) Comparison of various sampling strategies in image classification problem using 5-layer neural network. (b) Train a 5-layer CNN model with different number of total agents (clients) to show the linear speedup effect. (c) Train ResNet-18 model with different sampling strategies among 10 agents with participation ratio 0.4. "], "img_footnote": [], "page_idx": 32}, {"type": "text", "text": "G.2 Image Classification Task ", "text_level": 1, "page_idx": 32}, {"type": "text", "text": "In this part, we perform the image classification task through a 5-layer neural network, where the CIFAR10 dataset [44] with 50k image data is evenly distributed to 10 agents. Each agent possesses $5\\mathbf{k}$ images, which are further divided into 200 batches, each batch with 25 images. ", "page_idx": 32}, {"type": "text", "text": "The Convolutional Neural Network (CNN) model used in this simulation encompasses: ", "page_idx": 32}, {"type": "text", "text": "\u2022 Two convolutional layers (i.e., $n n.C o n\\nu2d(3,\\,6,\\,5)$ and nn.Conv2d(6, 16, 5)), each followed by ReLU activation functions to introduce non-linearity and max pooling (i.e., nn.MaxPool2d(2, 2)) to reduce spatial dimensions.   \n\u2022 Three fully connected (linear) layers, concluding with a softmax output to handle the multi-class classification problem. ", "page_idx": 32}, {"type": "text", "text": "Similar to the simulation setup in Section 4, among the 10 participating agents, five have unrestricted access to their respective data allocations, enabling them to utilize the shuffling method to iterate through their batches. The other five agents are designed to simulate limited data access scenarios. Their data access is structured using five distinct graph topologies extracted from the SNAP dataset collection [49], each graph simulating a unique communication pattern among the batches (nodes) of data. Within these topologies, agents adopt one of three random walk strategies \u2014 SRW, NBRW, and SRRW, all with importance reweighting \u2014 to sample the batches for training. ", "page_idx": 32}, {"type": "text", "text": "Local model training is conducted for five epochs at each agent before aggregating the updates at a central server \u2014 a process repeated for a total of 200 communication rounds. Each epoch consists of a full traversal of the local dataset of agents in the first group, or 200 batches sampled for training in the second group of agents. To mimic realistic conditions, we also introduce partial agent participation where only $40\\%$ of agents are selected randomly to transmit their updates in each round, reflecting the intermittent communication in real-world FL deployments. Lastly, the selection of the step size $\\beta_{n}$ for SRRW iterates (90) is a critical aspect of our experiments. In this simulation, we experiment with various values of $b\\in\\{0.501,0.6,0.7,0.8,0.9\\}$ to determine the most advantageous setting for maximizing the beneftis of the SRRW strategy. Based on our findings, the best choice for the SRRW step size is $b=0.501$ , in other words, $\\beta_{n}=\\dot{(n+1)}^{-0.501}$ . ", "page_idx": 32}, {"type": "text", "text": "The simulation result is quantified by averaging the training loss across ten repeated trials for each configuration. As depicted in Figure 3(a), the training results are consistent with our previous findings in Figure 2(a) in the context of the FL framework and the training of neural networks: the use of a more effective sampling approach, even for a portion of the agents, results in significant enhancements in the overall training of the model, and this improvement is further enhanced through the highly efficient sampling strategy SRRW. ", "page_idx": 32}, {"type": "text", "text": "In Figure 3(b) and 3(c), we perform image classification experiments in the FL setting with partial client participation. Only 4 random agents will participate in the training process at each aggregation phase. In Figure 3(b), we fix the sampling strategy (shuffling, SRRW with $\\alpha\\,=\\,10_{\\circ}$ ) and test the linear speedup effect for the 5-layer CNN model by duplicating 10 agents to $N$ agents with $N\\in\\{10,\\bar{20},30,\\bar{4}0\\}$ , keeping the same participation ratio 0.4. As can be seen from the plot, the training loss is inversely proportional to the number of agents, i.e., at 200 rounds, the training loss is 0.52 for 10 agents, 0.23 for 20 agents, 0.18 for 30 agents, and 0.12 for 40 agents. In Figure 3(c), we extend the current simulation from 5-layer CNN model to ResNet-18 model [34] in order to numerically test the performance of different sampling strategies in a more complex neural network training task. By fixing the shuffilng in the first group of agents, we observe that improving Markovian sampling from SRW to NBRW, then to SRRW, gives accelerated training process with smaller training loss. ", "page_idx": 32}, {"type": "text", "text": "", "page_idx": 33}, {"type": "text", "text": "H Limitations ", "text_level": 1, "page_idx": 33}, {"type": "text", "text": "Our study provides crucial insights into the identification of nuanced agents\u2019 sampling behaviors in UD-SGD, where improving each agent\u2019s sampling strategy speeds up overall system performance without additional computational burden except the additional storage for the visit counts used for sampling their datasets. Our UD-SGD is scalable in terms of larger datasets as the sampling strategy (i.e., random walk) utilized by each agent leverages only local information for its dataset. However, our work has two limitations that should be acknowledged. ", "page_idx": 33}, {"type": "text", "text": "1. Assumption 2.4 posits that the parameter trajectory $\\{\\theta_{n}\\}$ is almost surely bounded, which is a strong assumption. This is crucial for guaranteeing the well-defined nature of all related quantities. Some mechanisms such as projections onto a compact subset [45, Chapter 5.1], or truncation-based method with expanding compact subsets can do the trick to ensure that the iteration is always bounded [3]. As mentioned in our discussion after Assumption 2.4, only recently the stability of SGD under Markovian sampling has been guaranteed to hold for some class of objective function $f$ [9], while the discussion on stability issue under multi-agent scenario with Markovian sampling remains an open problem and we do not pursue to remove this stability assumption in this paper. ", "page_idx": 33}, {"type": "text", "text": "2. Asymptotic analysis: The main results of our work, i.e., almost sure convergence and central limit theorem in distributed optimization, are based on asymptotic analysis and might not accurately represent the finite-sample performance of each contributing agent in the system. The state-of-the-art finite-sample analysis in the literature only focuses on the worst-performing agent that cannot capture the nuanced differences between agents\u2019 sampling strategies, with the explanation detailed in Footnote 2. Thus, a finite-sample error bound that distinguish every agent\u2019s dynamics is still unknown and regarded as a future direction. ", "page_idx": 33}, {"type": "text", "text": "Checklist ", "text_level": 1, "page_idx": 33}, {"type": "text", "text": "1. Claims ", "text_level": 1, "page_idx": 33}, {"type": "text", "text": "Question: Do the main claims made in the abstract and introduction accurately reflect the paper\u2019s contributions and scope? ", "page_idx": 33}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 33}, {"type": "text", "text": "Justification: The abstract and the introduction clearly state the claims made, including the contributions made in the paper and important assumptions and limitations. The claims made match theoretical and experimental results, and reflect how much the results can be expected to generalize to other settings. ", "page_idx": 33}, {"type": "text", "text": "2. Limitations ", "text_level": 1, "page_idx": 33}, {"type": "text", "text": "Question: Does the paper discuss the limitations of the work performed by the authors? Answer: [Yes] ", "page_idx": 33}, {"type": "text", "text": "Justification: The \u2018Limitations\u2019 section is provided in Appendix H. ", "page_idx": 33}, {"type": "text", "text": "3. Theory Assumptions and Proofs ", "text_level": 1, "page_idx": 33}, {"type": "text", "text": "Question: For each theoretical result, does the paper provide the full set of assumptions and a complete (and correct) proof? ", "page_idx": 33}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 33}, {"type": "text", "text": "Justification: All the theorems, formulas, and proofs in the paper have been numbered and cross-referenced. All assumptions have been clearly stated or referenced in the statement of any theorems. The complete and correct proofs have been provided in appendices. ", "page_idx": 33}, {"type": "text", "text": "4. Experimental Result Reproducibility ", "text_level": 1, "page_idx": 33}, {"type": "text", "text": "Question: Does the paper fully disclose all the information needed to reproduce the main experimental results of the paper to the extent that it affects the main claims and/or conclusions of the paper (regardless of whether the code and data are provided or not)? ", "page_idx": 34}, {"type": "text", "text": "Answer: [Yes] Justification: The detailed simulation setups have been provided in Appendix G. ", "page_idx": 34}, {"type": "text", "text": "5. Open access to data and code ", "text_level": 1, "page_idx": 34}, {"type": "text", "text": "Question: Does the paper provide open access to the data and code, with sufficient instructions to faithfully reproduce the main experimental results, as described in supplemental material? ", "page_idx": 34}, {"type": "text", "text": "Answer: [No] ", "page_idx": 34}, {"type": "text", "text": "Justification: We do not provide clean source codes, but detailed instructions to perform the experiment have been provided in Appendix G. ", "page_idx": 34}, {"type": "text", "text": "6. Experimental Setting/Details ", "text_level": 1, "page_idx": 34}, {"type": "text", "text": "Question: Does the paper specify all the training and test details (e.g., data splits, hyperparameters, how they were chosen, type of optimizer, etc.) necessary to understand the results? ", "page_idx": 34}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 34}, {"type": "text", "text": "Justification: The full details have been provided in Appendix G. ", "page_idx": 34}, {"type": "text", "text": "7. Experiment Statistical Significance ", "text_level": 1, "page_idx": 34}, {"type": "text", "text": "Question: Does the paper report error bars suitably and correctly defined or other appropriate information about the statistical significance of the experiments? ", "page_idx": 34}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 34}, {"type": "text", "text": "Justification: We plot the error bars in Figure 2(a). However, error bars are intentionally omitted in Figure 2 in the main body to avoid a cluttered plot and deliver the main message. ", "page_idx": 34}, {"type": "text", "text": "8. Experiments Compute Resources ", "text_level": 1, "page_idx": 34}, {"type": "text", "text": "Question: For each experiment, does the paper provide sufficient information on the computer resources (type of compute workers, memory, time of execution) needed to reproduce the experiments? ", "page_idx": 34}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 34}, {"type": "text", "text": "Justification: We specify the platform that runs the simulation in Appendix G.1. ", "page_idx": 34}, {"type": "text", "text": "9. Code Of Ethics ", "text_level": 1, "page_idx": 34}, {"type": "text", "text": "Question: Does the research conducted in the paper conform, in every respect, with the NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines? ", "page_idx": 34}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 34}, {"type": "text", "text": "Justification: We fully obey the NeurIPS Code of Ethics. ", "page_idx": 34}, {"type": "text", "text": "10. Broader Impacts ", "text_level": 1, "page_idx": 34}, {"type": "text", "text": "Question: Does the paper discuss both potential positive societal impacts and negative societal impacts of the work performed? ", "page_idx": 34}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 34}, {"type": "text", "text": "Justification: This work mainly aims to demonstrate how the improvement of partial agents sampling strategies can accelerate the overall system\u2019s performance. It advocates for improving common wealth and has no negative social impact. ", "page_idx": 34}, {"type": "text", "text": "11. Safeguards ", "text_level": 1, "page_idx": 34}, {"type": "text", "text": "Question: Does the paper describe safeguards that have been put in place for responsible release of data or models that have a high risk for misuse (e.g., pretrained language models, image generators, or scraped datasets)? ", "page_idx": 34}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 34}, {"type": "text", "text": "Justification: The paper poses no such risks. ", "page_idx": 34}, {"type": "text", "text": "12. Licenses for existing assets ", "text_level": 1, "page_idx": 35}, {"type": "text", "text": "Question: Are the creators or original owners of assets (e.g., code, data, models), used in the paper, properly credited and are the license and terms of use explicitly mentioned and properly respected? ", "page_idx": 35}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 35}, {"type": "text", "text": "Justification: We have cited correctly the datasets ijcnn1 and CIFAR-10 used for experiments in our paper. ", "page_idx": 35}, {"type": "text", "text": "13. New Assets ", "text_level": 1, "page_idx": 35}, {"type": "text", "text": "Question: Are new assets introduced in the paper well documented and is the documentation provided alongside the assets? ", "page_idx": 35}, {"type": "text", "text": "Answer: [NA] Justification: The paper does not release new assets. ", "page_idx": 35}, {"type": "text", "text": "14. Crowdsourcing and Research with Human Subjects ", "page_idx": 35}, {"type": "text", "text": "Question: For crowdsourcing experiments and research with human subjects, does the paper include the full text of instructions given to participants and screenshots, if applicable, as well as details about compensation (if any)? ", "page_idx": 35}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 35}, {"type": "text", "text": "Justification: The paper does not involve crowdsourcing nor research with human subjects. ", "page_idx": 35}, {"type": "text", "text": "15. Institutional Review Board (IRB) Approvals or Equivalent for Research with Human Subjects ", "page_idx": 35}, {"type": "text", "text": "Question: Does the paper describe potential risks incurred by study participants, whether such risks were disclosed to the subjects, and whether Institutional Review Board (IRB) approvals (or an equivalent approval/review based on the requirements of your country or institution) were obtained? ", "page_idx": 35}, {"type": "text", "text": "Answer: [NA] Justification: The paper does not involve crowdsourcing nor research with human subjects. ", "page_idx": 35}]