[{"type": "text", "text": "Generative Modeling of Individual Behavior At Scale ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Anonymous Author(s)   \nAffiliation   \nAddress   \nemail ", "page_idx": 0}, {"type": "text", "text": "Abstract ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "1 There has been a growing interest in using AI to model human behavior, particularly   \n2 in domains where humans interact with this technology. While most existing work   \n3 models human behavior at an aggregate level, our goal is to model behavior at   \n4 the individual level. Recent approaches to behavioral stylometry\u2014or the task of   \n5 identifying a person from their actions alone\u2014have shown promise in domains   \n6 like chess, but these approaches are either not scalable (e.g., fine-tune a model for   \n7 each person) or not generative, in that they cannot generate actions in the style of   \n8 each person. We address these limitations by casting behavioral stylometry as a   \n9 multi-task learning problem\u2014where each task represents a distinct person\u2014and   \n10 using parameter-efficient fine-tuning (PEFT) methods to learn an explicit style   \n11 vector for each person. Style vectors are generative: they selectively activate   \n12 shared \"skill\" parameters to generate actions in the style of each person. They also   \n13 induce a latent style space that we can interpret and manipulate algorithmically.   \n14 In particular, we develop a general technique for style steering that identifies a   \n15 subset of players with a desired style property, and steers a new player towards that   \n16 property. We apply our approach to two very different games, at unprecedented   \n17 scale: chess (47,864 players) and Rocket League (2,000 players). ", "page_idx": 0}, {"type": "text", "text": "18 1 Introduction ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "19 The rapid advances in machine learning in recent years has made it increasingly important to find   \n20 constructive ways for humans to interact with this technology. Even in domains where AI has   \n21 achieved proficiency, it is often important to understand how humans approach these tasks. Such an   \n22 understanding can help identify areas for improvement in humans, develop better AI collaborators or   \n23 teachers, create more human-like experiences, and more.   \n24 A common method for capturing human behavior is behavioral cloning (BC), a form of imitation   \n25 learning [Schaal, 1996] that applies supervised learning to fixed demonstrations collected for a given   \n26 task. While traditionally used in domains such as robotics [Florence et al., 2022] and self-driving   \n27 vehicles [Pomerleau, 1988], BC has seen increasing use in gaming, such as in Counter-Strike [Pearce   \n28 and Zhu, 2022], Overcooked [Carroll et al., 2019], Minecraft [Sch\u00e4fer et al., 2023], Bleeding   \n29 Edge [Jelley et al., 2024], and chess McIlroy-Young et al. [2020].   \n30 The above work focuses on modeling human behavior in aggregate, with the goal of developing better   \n31 AI partners, opponents, and training tools. However, we believe that the most value for such goals can   \n32 be derived by modeling human behavior at the individual level. To that end, recent results in chess   \n33 have shown the most promise. McIlroy-Young et al. [2020] used behavior cloning to create a set of   \n34 models called Maia that match human play at 9 aggregate skill levels. By fine-tuning these models on   \n35 the data of 400 individual players, they created 400 personalized models that achieve $4.5\\%$ higher   \n36 move-matching accuracy on average [McIlroy-Young et al., 2022]. The authors use these models to   \n37 perform behavioral stylometry with high accuracy, where the goal is to identify which person played   \n38 a given query set of games; in this case, they simply apply each of the 400 models to the query set   \n39 and output the one with the highest accuracy. McIlroy-Young et al. [2021] propose a more scalable   \n40 approach of training a Transformer-based embedding on the games of each player, and use this to   \n41 perform accurate stylometry across 2,844 players; in this case, they compute the embedding of the   \n42 query set of games and match it to the closest player\u2019s embedding.   \n43 These approaches have different merits. The individual model approach creates a generative model   \n44 for each player, but it is not scalable and shares only initial (base model) knowledge across the   \n45 players; adding a new player requires fine-tuning a separate model. The embedding approach is   \n46 much more scalable: it learns a compact (single-vector) representation of each player in a shared   \n47 style space, and supports few-shot learning to embed a new player in this space. It cannot be used to   \n48 generate moves, however, and hence cannot reason about player behavior in practice.   \n49 An ideal solution would combine these properties: generative, scalable, shared knowledge, compact   \n50 representation. Our key insight for achieving this is to view behavioral stylometry as a multi-task   \n51 learning problem, where each task represents an individual person. The goal here is to generalize   \n52 across an initial set of players (tasks) while supporting few-shot learning of new players (tasks). To   \n53 do this efficiently, we leverage recent advances in parameter-efficient fine-tuning (PEFT) [Ponti et al.,   \n54 2023, Caccia et al., 2022]. Specifically, we augment an existing BC model with a set of Low Rank   \n55 Adapters (LoRAs) as well as a routing matrix that specifies a distribution over these adapters for   \n56 each player. Unlike approaches that train a separate LoRA for each task, this modular design allows   \n57 players to softly share parameters in a fine-grained manner. We apply this adapter framework to two   \n58 very different game models (which we create): a modified version of the Maia model for chess, and a   \n59 Transformer-based BC model for Rocket League, a 3D soccer video game played by cars in a caged   \n60 arena. (Our models scale beyond the prior art and may be of independent interest.) Our methodology   \n61 first trains the BC models to convergence across all player data, and then fine-tunes the adapters   \n62 and routing matrix on per-player data. This encourages the adapters to learn different latent skills   \n63 that explain the variance between players, while each row of the routing matrix induces a weight   \n64 distribution over these skills. We call each row the style vector for the corresponding player.   \n65 Style vectors are versatile and powerful. They support few-shot learning which enables stylometry at   \n66 scale. They induce a generative model for each player that we can run and observe. They induce a   \n67 shared style space that we can interpret and manipulate algorithmically. Leveraging these properties,   \n68 we develop a general technique for style steering that identifies a subset of players who exhibit a   \n69 desired style property, and steers a new player towards that property. Our main results include:   \n70 1. We perform behavioral stylometry at an unprecedented scale for chess (47,864 players, $94.4\\%$   \n71 accuracy) and Rocket League (2,000 players, $86.7\\%$ accuracy), using a query set of 100 games.   \n72 2. Our per-player generative models achieve move-matching accuracy in the range $45{-}69\\%$ for   \n73 chess and $44\u201372\\%$ for Rocket League, even for players with very few (e.g., 50) games.   \n74 3. Style vectors capture a wide diversity of playing styles and strengths. They can be combined,   \n75 interpolated, and steered, while reflecting consistent changes to play style and strength. ", "page_idx": 0}, {"type": "text", "text": "", "page_idx": 0}, {"type": "text", "text": "", "page_idx": 0}, {"type": "text", "text": "", "page_idx": 1}, {"type": "text", "text": "", "page_idx": 1}, {"type": "text", "text": "", "page_idx": 1}, {"type": "text", "text": "", "page_idx": 1}, {"type": "text", "text": "", "page_idx": 1}, {"type": "text", "text": "76 2 Background and Framing ", "text_level": 1, "page_idx": 1}, {"type": "text", "text": "77 We frame behavioral stylometry and per-player generative modeling as a multitask learning problem,   \n78 to which we apply PEFT methods. In multitask learning [Caruana, 1997, Ruder et al., 2019],   \n79 we are given a collection of tasks $\\mathcal{T}\\,=\\,\\left(\\mathcal{T}_{1},\\dots,\\mathcal{T}_{|\\mathcal{T}|}\\right)$ , each task ${\\mathcal{T}}_{i}$ associated with a dataset   \n80 $\\mathcal{D}_{i}=\\left\\{(x_{1},y_{1}),...,(x_{n_{i}},y_{n_{i}})\\right\\}$ . Multitask learning exploits the similarities among related training   \n81 tasks by transferring knowledge among them; ideally, this builds representations that are easily   \n82 adaptable to new tasks using potentially few target examples. The premise of this paper is that   \n83 modeling individual human behavior from a pool of players can be interpreted as a multitask learning   \n84 problem. In other words, each task $\\mathcal{T}_{i}$ consists of modeling the behavior of a specific player $i$ ; and   \n85 dataset $\\mathcal{D}_{i}$ corresponds to the sequence of game actions taken by player $i$ . Specifically, an $(x,y)$ tuple   \n86 denotes a game state $x$ at a specific point in time during game, along with the action $y$ that player $i$   \n87 took in this state. For the rest of the paper, we use the notion of tasks and players interchangeably. ", "page_idx": 1}, {"type": "text", "text": "88 2.1 Parameter-efficient fine-tuning ", "text_level": 1, "page_idx": 1}, {"type": "text", "text": "89 Popularized in NLP, parameter-efficient fine-tuning (PEFT) [Houlsby et al., 2019, Hu et al., 2022, Liu   \n90 et al., 2022] approaches have emerged as a scalable solution for adapting Large Language Models to   \n91 several downstream tasks. Indeed, standard finetuning of pretrained LLMs requires updating (and   \n92 storing) possibly billions of parameters for each task. PEFT methods instead freeze the pretrained   \n93 model and inject a small set of trainable task-specific weights, or \u201cadapters\".   \n94 One such approach is the use of Low Rank Adapters (LoRA) [Hu et al., 2022], which modify linear   \n95 transformations in the network by adding a learnable low rank shift ", "page_idx": 1}, {"type": "text", "text": "", "page_idx": 2}, {"type": "text", "text": "", "page_idx": 2}, {"type": "equation", "text": "$$\nh=\\left(W_{0}+\\Delta W\\right)x=\\left(W_{0}+A B^{T}\\right)x.\n$$", "text_format": "latex", "page_idx": 2}, {"type": "text", "text": "96 Here, $W_{0}\\in\\mathbb{R}^{d\\times d}$ are the (frozen) weights of the pre-trained model, and $\\pmb{A},\\pmb{B}\\in\\mathbb{R}^{d\\times r}$ the learnable   \n97 low-rank parameters of rank $r\\ll d$ . With this approach, practitioners can trade off parameter   \n98 efficiency with expressivity by increasing the rank $r$ of the transformation. ", "page_idx": 2}, {"type": "text", "text": "99 2.2 Polytropon and Multi-Head Adapter Routing ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "Standard PEFT methods such as LoRA can adapt a pretrained model for a given task. In multitask settings, training a separate set of adapters for each task is suboptimal, as it does not enable any sharing of information, or transfer, across similar tasks. On the other hand, using the same set of adapters for all tasks risks negative interference [Wang et al., 2021] across dissimilar tasks. Polytropon [Ponti et al., 2019] (Poly) addresses this transfer/interference tradeoff by softly sharing parameters across tasks. That is, each Poly layer contains 1) an inventory of LoRA adapters ", "page_idx": 2}, {"type": "equation", "text": "$$\n\\mathcal{M}=\\{A^{(1)}B^{(1)},\\,\\dots\\,,\\,A^{(m)}B^{(m)}\\},\n$$", "text_format": "latex", "page_idx": 2}, {"type": "text", "text": "100 with $m\\ll|\\tau|$ , and 2) a task-routing matrix $\\boldsymbol{Z}\\,\\in\\,\\mathbb{R}^{|T|\\times m}$ , where $\\mathbf{Z}_{\\tau}\\,\\in\\,\\mathbb{R}^{m}$ specifies task $\\tau$ \u2019s   \n101 distribution over the shared modules. This formulation allows similar tasks to share adapters, while   \n102 allowing dissimilar tasks to have non-overlapping parameters. The collection of adapters $\\mathcal{M}$ can be   \n103 interpreted as capturing different facets of knowledge, or latent skills, of the full multitask distribution. ", "page_idx": 2}, {"type": "text", "text": "104 At each forward pass, Poly LoRA adapters for task $\\tau$ are constructed as follows: ", "page_idx": 2}, {"type": "equation", "text": "$$\n{\\pmb A}^{\\tau}=\\sum_{i}\\alpha_{i}{\\pmb A}^{(i)};\\,{\\pmb B}^{\\tau}=\\sum_{i}\\alpha_{i}{\\pmb B}^{(i)}\n$$", "text_format": "latex", "page_idx": 2}, {"type": "text", "text": "105 where $\\alpha_{i}=\\mathsf{s o f}\\mathsf{t m a x}(Z\\left[\\tau\\right])_{i}$ denotes the mixing weight of the $i$ -th adapter in the inventory, and   \n106 $\\pmb{A}^{(i)},\\pmb{B}^{(i)},\\pmb{A}^{\\tau},\\pmb{B}^{\\tau}\\,\\in\\,\\mathbb{R}^{d\\times r}$ . Here, the $\\tau$ -th row of the routing matrix $Z$ is effectively selecting   \n107 which adapter modules to include in the linear combination. In our setting, where each task consists   \n108 of modeling an individual, $Z\\left[\\tau\\right]$ specifies which latent skills are activated for user $\\tau$ ; we call this their   \n109 style vector. As per Eqn 1, the final output of the linear mapping becomes $h=\\left(W_{0}+A^{\\tau}(B^{\\tau})^{T}\\right)x$ .   \n110 In Poly, the module combination step remains coarse, as only linear combinations of the existing   \n111 modules can be generated. Caccia et al. [2022] propose a more fine-grained approach, called Multi  \n112 Head Routing (MHR), which is what we use in our work. Similar to Multi-Head Attention [Vaswani   \n113 et al., 2017], the input dimension of $\\pmb{A}$ (and output dimensions of $_B$ ) are partitioned into $h$ heads,   \n114 where a Poly-style procedure occurs for each head. The resulting parameters from each head are   \n115 then concatenated, recovering the full input (and output) dimensions. See A.1 for more details.   \n116 Routing-only fine-tuning. While LoRA adapters can reduce the parameter cost from billions to   \n117 millions [Liu et al., 2022], training the adapters for each new task can still be prohibitive when dealing   \n118 with thousands of tasks. To this end, Caccia et al. [2022] proposed routing-only finetuning, where   \n119 after an initial phase of pretraining, the adapter modules are fixed, and only the routing parameters $_{z}$   \n120 are learned for a new task. This reduces the parameter cost for each additional task by several orders   \n121 of magnitude, while maintaining similar performance. We use this method for few-shot learning. ", "page_idx": 2}, {"type": "text", "text": "", "page_idx": 2}, {"type": "text", "text": "", "page_idx": 2}, {"type": "text", "text": "122 3 ML Methodology ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "123 In this section, we detail our methodology for creating a generative model of individual behavior that   \n124 enables our style analyses. Our methodology applies to any behavior cloning scenario with access to   \n125 human demonstrations from multiple individuals. To demonstrate this generality, we apply it to two   \n126 very different games: chess and Rocket League. We start with a base model for each and apply the   \n127 MHR adapter framework to it, and then discuss model training and evaluation. ", "page_idx": 2}, {"type": "image", "img_path": "QsxldAFMFx/tmp/15973cc165434d9086b8d70cb94cd831efdecf61edbfc12e477ad9e7f3daa56f.jpg", "img_caption": ["Figure 1: (left) Our overall architecture. We augment a base model with a set of MHR adapters and a routing matrix composed of each player\u2019s style vector. (right) Detailed view of an MHR layer, showing a skill inventory of adapters shared across players. The player\u2019s style vector specifies which skills are active (in this case, the first and third) to generate the final low-rank weight shift that is applied to the (frozen) base model layer. "], "img_footnote": [], "page_idx": 3}, {"type": "text", "text": "128 3.1 Model architecture ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "129 For chess, we follow McIlroy-Young et al. [2022] and use the Squeeze-and-Excitation (S&E) Residual   \n130 Network [Hu et al., 2018] as a base model, but with a deeper and wider configuration (see A.2).   \n131 At every residual block, an additional 2-layer MLP rescales the residual output along the channel   \n132 dimension to explicitly model channel interdependencies. The input is a 112-channel $8\\times8$ image   \n133 representation of the chess board; the output is the predicted move represented as a 1858-dimensional   \n134 vector. The total parameters is 15.7M. For Rocket League, we use the GPT-2 architecture from   \n135 Radford et al. [2019] with a dimensionality of 768, 12 attention heads, and 12 layers. The input is a   \n136 49-dimensional vector with game physics information; the output is 8 heads: 5 with 3 bins of $[-1,0$ ,   \n137 1] and 3 binary. The model has no embedding layer, as the game data points are passed directly as   \n138 tokens after processing. The total parameters is $87.7\\mathbf{M}$ .   \n139 To enable user-based adaptation, we incorporate the MHR adapters described in $\\S2.2$ into our base   \n140 models, as illustrated in Fig. 1. In chess, for every linear transformation in the MLP used for channel  \n141 wise rescaling, we add an MHR layer built of LoRA adapters with rank 16, for a total of $12\\!\\times\\!2\\!\\!=\\!24$   \n142 MHR layers. We use an adapter inventory of size 32 and a multi-head routing strategy with 8 heads.   \n143 Therefore, for each user we must learn $32\\!\\times\\!8\\!=\\!256$ routing parameters as their style vector. This yields   \n144 5M additional parameters. For Rocket League, we attach the adapters to the fully connected layer of   \n145 each transformer block, resulting in $12\\;\\mathtt{M H R}$ layers of LoRAs with rank 16. We use an inventory size   \n146 of 16 and 64 heads. This yields 13.8M additional parameters. To facilitate interpretability and style   \n147 analysis, we use the same routing (style vector) across all MHR layers. ", "page_idx": 3}, {"type": "text", "text": "", "page_idx": 3}, {"type": "text", "text": "148 3.2 Data collection and partitioning ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "149 We use data from the largest open-source online chess platform, Lichess.org [Duplessis, 2021], which   \n150 boasts a database of over 4.8 billion games. We collected Blitz games played between 2013 and   \n151 2020 inclusive\u2014these are games with 3 or 5 minutes per side, optionally with a few seconds of   \n152 time increment per move\u2014and applied the same player filtering criteria as McIlroy-Young et al.   \n153 [2022]. The resulting dataset comprises 47,864 unique players and over 244 million games. (See A.2   \n154 for a discussion on data imbalance.) For Rocket League, we collect data from a large open-source   \n155 replay database, Ballchasing.com [CantFlyRL, 2024]. We use 2.2 million 1v1 replays from 2015 to   \n156 mid-2022, totalling several decades of human game play hours at 5 minutes per game. After parsing,   \n157 each Rocket League game state is a vector holding the player\u2019s 3D position, linear and angular   \n158 velocity, boost remaining, rotation, and team; we also include the opponent\u2019s state and the position,   \n159 linear and angular velocity of the ball. Given a game state, we have to predict the user\u2019s throttle, steer   \n60 (while grounded), pitch, yaw, roll (while aerial), jump, boost, and handbrake. Additional processing   \n161 was needed to correct for missing aerial controls and inconsistent sampling rates (24-27hz). Our full   \n162 data processing procedure, including the challenges we faced, are detailed in A.3.   \n163 We divide the set of players into a few subsets to support our training methodology. The base player   \n164 set comprises all data and is used to train the base models. The fine-tuning player set is used to   \n165 fine-tune the MHR architecture shown in Fig. 1. (For both, we split each player\u2019s data into 80/10/10 for   \n166 train/test/validation.) The few-shot player set is used for few-shot learning based on a reference set of   \n167 100 games per player. For our chess experiments, to enable a direct comparison with prior work, we   \n168 create an additional fine-tuning player set consisting of the same 400 players used in those studies.   \n169 Currently, we treat each player\u2019s data holistically, but in principle one could partition a player\u2019s data   \n170 in different ways to perform a finer analysis of their playing style. We explore this in A.4. ", "page_idx": 3}, {"type": "text", "text": "", "page_idx": 3}, {"type": "text", "text": "", "page_idx": 4}, {"type": "text", "text": "171 3.3 Model training and evaluation ", "text_level": 1, "page_idx": 4}, {"type": "text", "text": "172 Base model. We train our base Maia model for chess using data from a base player set of all 47,864   \n173 players, treating this as a classification task of predicting human move $y$ made in chess position $x$ ,   \n174 given a datapoint $(x,y)$ . We use the same loss functions and evaluation criteria as the original Maia   \n175 work: Maia\u2019s policy head uses a cross entropy loss while the value head uses MSE; the output of the   \n176 policy head is used to evaluate the model\u2019s move-matching accuracy.   \n177 We train our Rocket League model using a base player set of over 800,000 players, though the vast   \n178 majority of players have 5 games or fewer. We discretize the actions into 3 bins for throttle, steer,   \n179 pitch, yaw, and roll, as most of this data is close to 0, -1, or 1. We use binary outputs for jump, boost,   \n180 and handbrake. A next-move prediction is labelled correct if and only if all of the outputs are correct.   \n181 MHR fine-tuning. To train the MHR LoRA adapters, we adopt the methodology used in Caccia et al.   \n182 [2022]: namely, we freeze the base model and fine-tune the MHR layers and routing matrix using data   \n183 from a fine-tuning player set. Recall that the routing matrix $Z$ has a row (style vector) for each player   \n184 in the fine-tuning set. Following Ponti et al. [2019], we use a two-speed learning rate, where the style   \n185 vectors\u2019 learning rate is higher than the adapters\u2019, to enable better specialization.   \n186 For chess, we use two fine-tuning player sets in our experiments, creating two separate MHR-Maia   \n187 models. The first set comprises all 47,864 players and is used to evaluate behavioral cloning and   \n188 stylometry at very large scale. The second set is comprised of the same 400 players used by McIlroy  \n189 Young et al. [2022], which we use to compare few-shot learning and stylometry results. For Rocket   \n190 League, we train an MHR-Rocket model on a fine-tuning set of 2,000 players with 100 games each.   \n191 Few-shot learning. To perform few-shot learning on our MHR models, we perform the \u201crouting-only   \n192 fine-tuning\" described in section 2.2 that additionally freezes all MHR LoRA adapters. Given a few  \n193 shot player, we add a (randomly-initialized) new row to $Z$ and fine-tune it on the player\u2019s reference   \n194 set of games, eventually learning a style vector for the player. Using this style vector, we can invoke   \n195 a generative model of the player and use it to evaluate move-matching accuracy, as described above.   \n196 To perform stylometry, if the player is a seen player (i.e., part of the fine-tuning set), then a matching   \n197 style vector already exists in $_{z}$ , and we can find it using cosine similarity. Otherwise, if the player is   \n198 unseen, then we simply repeat the few-shot learning process on a query set of games (from the same   \n199 player), and compare this new style vector to the entries in $_{z}$ .   \n200 For chess, (unless stated otherwise), all of our few-shot experiments use the MHR-Maia model fine  \n201 tuned on the 400-player set from McIlroy-Young et al. [2022]. For Rocket League, the few-shot   \n202 player set consists of 1,000 of the 2,000-player set used to fine-tune MHR-Rocket.   \n203 Evaluation. We evaluate a fine-tuned MHR model in two ways. First, we measure its move-matching   \n204 accuracy, similar to how we evaluate the base models. However, since our MHR models provide a   \n205 generative model for each player (invoked through their style vector), we can separately evaluate each   \n206 player\u2019s model by applying it to their test set and measuring move-matching accuracy. The overall   \n207 move-matching accuracy for the model is simply the average of these per-player accuracies.   \n208 Our second evaluation method uses the model to perform behavioral stylometry among all players in   \n209 the fine-tuning set. This is done by leveraging our few-shot learning methodology (above). That is,   \n210 given a query set of games from some player, we learn a new style vector in $Z$ for those games via   \n211 few-shot learning, and compare this vector to every other vector in $Z$ . Using cosine similarity as our   \n212 distance metric, we simply output the player with the highest cosine similarity to the query set vector. ", "page_idx": 4}, {"type": "text", "text": "", "page_idx": 4}, {"type": "text", "text": "", "page_idx": 4}, {"type": "text", "text": "", "page_idx": 4}, {"type": "text", "text": "", "page_idx": 4}, {"type": "text", "text": "", "page_idx": 4}, {"type": "text", "text": "", "page_idx": 4}, {"type": "text", "text": "", "page_idx": 4}, {"type": "text", "text": "213 4 Style methodology ", "text_level": 1, "page_idx": 4}, {"type": "text", "text": "214 The style vectors in $_{z}$ represent distinct distributions over latent skills that give us a starting point for   \n215 comparing player styles. For example, our stylometry method above uses the cosine similarity of   \n216 these vectors to determine how similar or different players are. However, style vectors also enable   \n217 much more powerful capabilities, such as the ability to synthesize new (human-like) styles.   \n218 To begin, we measure the intra-player consistency of style vectors by splitting a player\u2019s dataset   \n219 into disjoint subsets of varying size, and few-shot learning a style vector for each subset. We then   \n220 investigate inter-player consistency by merging the datasets of two players and seeing if the style   \n221 vector trained on the merged dataset is similar to the average of the two player\u2019s style vectors.   \n222 The latter method actually creates a new playing style that is human-like and yet previously unseen   \n223 in the world. This suggests a more general approach to style synthesis: interpolate between players   \n224 using a convex combination of their style vectors. To determine the playing strength of these new   \n225 players, we can simulate games between them and the players they are derived from. The results of   \n226 these games can be used to calculate a win rate, which can then be converted to a strength rating.   \n227 Currently, our advanced style synthesis techniques focus on chess, where there is a robust mapping   \n228 between win rates and playing strength (the Elo rating system), and simulating games is cheap.   \n229 Rocket League simulations are quite costly at present, but in principle the same methodology should   \n230 apply and we plan to reduce these costs in future work.   \nIn order to make style comparisons more human-understandable, we again exploit the generative   \n232 nature of our MHR models. Inspired by the concept probing technique used to analyze AlphaZero   \n233 (a deep RL chess engine) [McGrath et al., 2022], we use a set of human-coded heuristic functions   \nfound in Stockfish (a traditional chess engine) to evaluate a player\u2019s model. These functions capture   \n235 concepts such as: king safety, material imbalance, piece mobility, and so on. By invoking a player\u2019s   \n236 model on a fixed set of chess positions and seeing which move they select, we can use this to   \n237 summarize how much emphasis the player places on the corresponding concepts.   \n238 Finally, we combine the above methods to design a simple but general method for steering a player\u2019s   \n239 game style towards a specific attribute $a$ , such as increasing their king safety, while limiting the   \n240 changes on other attributes (so as to preserve their style). To achieve this, we first collect a set players   \n241 $X$ who exhibit high values for attribute $a_{\\mathrm{{}}}$ \u2014determined, for example, by running their generative   \n242 models on a fixed set of game states. We then extract the common direction among these players, by   \n243 averaging their style vectors and subtracting the population average. This yields a style delta vector   \n244 that can be added to any player\u2019s style vector to elicit the desired change. ", "page_idx": 4}, {"type": "table", "img_path": "QsxldAFMFx/tmp/efcfbcbab3b9b3434d89bc620a9c35e4b6bd77b3e858ea57ee85018010fa357e.jpg", "table_caption": [], "table_footnote": ["Table 1: Stylometry accuracy results. Seen few-shot players are a subset of the fine-tuning player set, unlike unseen players. Numbers for McIlroy-Young et al. [2022] and McIlroy-Young et al. [2021] are borrowed from their respective papers. "], "page_idx": 5}, {"type": "text", "text": "", "page_idx": 5}, {"type": "text", "text": "245 5 Experiments ", "text_level": 1, "page_idx": 5}, {"type": "text", "text": "246 In this section, we demonstrate two main findings. First, MHR-Maia performs competitively with   \n247 prior methods for behavior cloning and stylometry in chess, while achieving unprecedented scale.   \n248 We also show that our approach can be applied to Rocket League, for both stylometry and move   \n249 prediction. Second, we show that explicitly capturing style vectors allows us to reason about and   \n250 perform arithmetic operations on generated behaviors.   \n252 In this section, we show that our models perform competitively with previous behavioral stylometry   \n253 methods for both seen and unseen players. Here, the goal is to predict the player who produced a given   \n254 set of games. We compare to individual model fine-tuning [McIlroy-Young et al., 2022], fitting a   \n255 pre-trained Maia to the data from a single player, and to a Transformer-based method [McIlroy-Young   \n256 et al., 2021], which embeds players in a 512-dimensional style space based on their gameplay. All   \n257 reported accuracies are top-1 unless stated otherwise.   \n258 To perform stylometry on a query set of games, McIlroy-Young et al. [2022] suggest measuring   \n259 the move-matching accuracy of each available fine-tuned model and selecting the best performing   \n260 model. As seen in Table 1, this procedure works well, but is tremendously expensive\u2014requiring   \n261 computationally intensive inference calls on the entire query set for every candidate player.   \n262 In contrast, both the Transformer-based method and MHR-Maia scale much better to large numbers of   \n263 players. The Transformer-based method needs only to condition on these games to produce a vector,   \n264 while MHR-Maia needs only to fit a new vector. In either case, the produced vectors need only be   \n265 matched to those in the player set, e.g., using cosine similarity. Table 1 compares both approaches,   \n266 showing that MHR-Maia performs competitively or better, on a much larger universe. To do this, we   \n267 use few-shot learning to compute style vectors for 10,000 players based on their 100 game reference   \n268 sets, then fit new style vectors for each player based on their respective query sets. Note that the   \n269 individual model fine-tuning method is omitted from the larger few-shot study due to scalability   \n270 reasons. The Transformer-based method can scale, but it is not a generative model.   \n271 For Rocket League, to the best of our knowledge, we are the first to attempt stylometry. We report   \n272 player identification results averaged over the few-shot player set. For each prediction, our MHR  \n273 Rocket approach must correctly identify each of the 1,000 players among a pool of 2,000 players.   \n274 Yet, it reaches an accuracy of $86.7\\%$ (random: $0.05\\%$ ), showcasing the validity of our approach. ", "page_idx": 5}, {"type": "text", "text": "", "page_idx": 6}, {"type": "text", "text": "", "page_idx": 6}, {"type": "text", "text": "", "page_idx": 6}, {"type": "text", "text": "", "page_idx": 6}, {"type": "text", "text": "275 5.2 Move generation ", "text_level": 1, "page_idx": 6}, {"type": "text", "text": "276 Here we compare the efficacy of our method to using   \n277 individually fine-tuned models for each player. Fine  \n278 tuning individual models generally results in superior   \n279 results compared to PEFT methods, as the increased pa  \n280 rameter count produces more expressive models. How  \n281 ever, they are also more computationally intensive to   \n282 train and store. That said, in the domain of modeling in  \n283 dividual behavior in chess, MHR-Maia is able to perform   \n284 comparatively well despite using a much smaller pa  \n285 rameter budget. Figure 2 shows that MHR-Maia matches   \n286 individual model fine-tuning over a wide range of game   \n287 counts. The base model is frozen for all game counts   \n288 in MHR-Maia. The model has already learned the set   \n289 of skills required to differentiate the players, all that is ", "page_idx": 6}, {"type": "text", "text": "", "page_idx": 6}, {"type": "image", "img_path": "QsxldAFMFx/tmp/4b217ea55e69dd0a5a84b4303340064e9b0369962ad62b3967cc580a0276a660.jpg", "img_caption": [], "img_footnote": [], "page_idx": 6}, {"type": "text", "text": "Figure 2: Accuracy at various game counts of the individual models (Maia) and our method (MHR-Maia). ", "page_idx": 6}, {"type": "text", "text": "290 needed with very few-shot learning is to find a proper recombination of the learned skills within the   \n291 new style vectors. The Transformer-based method is omitted, as it is incapable of generating moves.   \n292 For Rocket League, we compare the next move prediction of our base model, with MHR-Rocket,   \n293 to validate that our user-based conditioning generates better predictions. We find that, on average,   \n294 MHR-Rocket increases the next move prediction from $53.1\\%$ to $56.1\\%$ . ", "page_idx": 6}, {"type": "text", "text": "", "page_idx": 6}, {"type": "text", "text": "295 5.3 Analysis of style vectors ", "text_level": 1, "page_idx": 6}, {"type": "text", "text": "296 In this section, we explore the consistency of our style vectors across different players and datasets. ", "page_idx": 6}, {"type": "text", "text": "297 Consistency across a single player. To showcase intra-player consistency, we first partition 50   \n298 players\u2019 datasets into disjoint subsets. We use 50 splits for chess and 20 for Rocket League. The   \n299 subsets are sampled across a wide range of dates, opposing players, and playing sessions. Next,   \n300 we train a style vector for every split across all players. We find that vectors corresponding to the   \n301 same player will be similar to each other, and have low similarity with the other players and general   \n302 population. This is visualized in Figure 3. This suggests that our neural network is able to find   \n303 distinct tendencies for each player. To confirm, we sampled 5 random chess players, predicted their   \n304 preferred move across $2^{17}$ positions, and measured a series of Stockfish evaluation metrics per player.   \n305 Figure 4 shows the distribution of these metrics for each player, demonstrating that these vectors   \n306 store a wide diversity of styles.   \n307 Consistency across merged players. To parse out whether we can generate new styles using this   \n308 information, we merged two players\u2019 datasets together to generate a new set with the tendencies   \n309 of both players, measuring inter-player consistency. We then compared this new set of vectors to a   \n310 different set of vectors generated by simply averaging the style vectors of the player pair. As seen   \n311 in Figure 5 (left and center), vectors with the same two source players have very high similarity in   \n312 both chess and Rocket League. We then sampled a random pair in the merged dataset, created a new   \n313 player by averaging the two players\u2019 vectors, and recorded their gameplay according to the previous   \n314 section. The results are visualized in Figure 5 (right), showing that the new player (green) has an   \n315 intermediate playing style to the source players (red, blue). ", "page_idx": 6}, {"type": "image", "img_path": "QsxldAFMFx/tmp/1496853b9add3c51f46f316d1e8f5ec1ca863a13f6dd1ff764be8ef2abea4030.jpg", "img_caption": ["Figure 3: Cosine similarity between style vectors learned from different partitions of the same player (red) vs across different players (blue). "], "img_footnote": [], "page_idx": 7}, {"type": "image", "img_path": "QsxldAFMFx/tmp/019765b163a0e0e183f1661f7ff46931dca46d4d438edb647e0bbff1f4e0b8ac.jpg", "img_caption": ["Figure 4: Comparing player styles using human-interpretable evaluation metrics. "], "img_footnote": [], "page_idx": 7}, {"type": "image", "img_path": "QsxldAFMFx/tmp/5a9e75443cd9e173779fd81aff131f307aa48e86c1a487d325af7cb2d2312618.jpg", "img_caption": ["Figure 5: Cosine similarity between averaged style vectors of two players, and the learned style vectors on their merged datasets (red) vs across the full population (blue). The style of an intermediate player (green) is shown along with the two component players (blue and red) on the right. "], "img_footnote": [], "page_idx": 7}, {"type": "text", "text": "", "page_idx": 7}, {"type": "text", "text": "", "page_idx": 7}, {"type": "text", "text": "316 5.4 Synthesis of new styles ", "text_level": 1, "page_idx": 7}, {"type": "text", "text": "317 Convex combinations. We show that interpolating between skill vectors results in a player whose   \n318 level is a weighted average of the interpolated players. Here, we take 100 pairs of learned player   \n319 vectors, such that one item in the pair corresponds to a strong player and the other to a weaker player.   \n320 We then gradually interpolate between the weak and strong player as $(1-\\lambda)u_{w}+\\lambda u_{s}$ , $0\\leq\\lambda\\leq1$ ,   \n321 where $u_{w}$ and $u_{s}$ are respectively vectors representing the weak and strong player. For each value of   \n322 $\\lambda$ we simulate 1,000 games between the interpolated vector and $u_{s}$ , the stronger player.   \n323 Figure 6 plots the win rate of the interpolated player as a function of $\\lambda$ for each player pair we   \n324 considered. This plot demonstrates that win rate progresses in a roughly linear fashion, starting off   \n325 winning infrequently against the stronger player and eventually winning roughly half the time as the   \n326 interpolated player converges to the stronger player.   \n327 Directly steering player style. Finally, we directly control the playing style of a player by creating   \n328 skill vectors according to the procedure described in 4. We choose players in our chess dataset with   \n329 high $_{\\cdot>2}$ std) bishop pair utilization, and separately players with high king danger. Figure 7 shows   \n330 the change in 2,000 randomly sampled player\u2019s stockfish evaluations after adding the skill vector   \n331 corresponding to each heuristic to their style vectors. Indeed, we see that the player\u2019s style is steered   \n332 towards the attribute in question, with model impact on other attributes. ", "page_idx": 7}, {"type": "text", "text": "", "page_idx": 7}, {"type": "text", "text": "", "page_idx": 7}, {"type": "image", "img_path": "QsxldAFMFx/tmp/6111b44e96d23ff38985a7d99178e566aaf6208e64fe48cf7547422249ed2f0a.jpg", "img_caption": ["Figure 6: Winrate as a weaker player is interpolated with a stronger player as a function of $\\lambda$ . "], "img_footnote": [], "page_idx": 8}, {"type": "image", "img_path": "QsxldAFMFx/tmp/91fecb936c6cd49d718e72b47603ee9af8f8604d84fa6193fd0f8e9092be1c07.jpg", "img_caption": ["Figure 7: Modifying the a player\u2019s style towards a specific attribute "], "img_footnote": [], "page_idx": 8}, {"type": "text", "text": "", "page_idx": 8}, {"type": "text", "text": "333 6 Related Work ", "text_level": 1, "page_idx": 8}, {"type": "text", "text": "334 Stylometry and player style modeling. Originally referring to performing author attribution via   \n335 statistical analysis of text [Tweedie et al., 1996, Neal et al., 2017], stylometry has since come to refer   \n336 to the general task of identifying individuals given a set of samples or actions, and has found broad   \n337 application for tasks such as handwriting recognition [Bromley et al., 1993], speaker verification   \n338 [Wan et al., 2018], identifying programmers from code [Caliskan-Islam et al., 2015], determining   \n339 user age and gender from blog posts [Goswami et al., 2009], and identifying characteristics of authors   \n340 of scientific articles [Bergsma et al., 2012]. In the context of gaming (covered in the introduction),   \n341 stylometry is closely related to playstyle modeling, where the goal is to associate a player with a   \n342 reference style, such as by building agents representative of different playstyles and find the closest   \n343 behavioral match [Holmg\u00e5rd et al., 2014], or gathering gameplay data and applying methods such   \n344 as clustering [Ingram et al., 2022], LDA [Gow et al., 2012], Bayesian approaches [Normoyle and   \n345 Jensen, 2015] and sequential models [Valls-Vargas et al., 2015] to identify groups of players with   \n346 similar styles. Unlike our work, these approaches focus on aggregate playstyles, and do not learn   \n347 generative models that can be conditioned on an individual\u2019s style.   \n348 Our method for style synthesis is inspired by earlier work on vector arithmetic with embed  \n349 dings [Church, 2017], as well as recent work on steering multiask models with task vectors [Ilharco   \n350 et al., 2023]. Finally, our steering method is reminiscent of Radford et al. [2016], which manipulates   \n351 the model\u2019s latent space to generate images containing specific attributes.   \n352 Parameter-efficient adaptation Approaches for efficient adaption of a pretrained model can   \n353 be broadly grouped in two categories. Adapter based methods inject new parameters within a   \n354 pretrained model, and only updates the newly inserted parameters while keeping the backbone   \n355 fixed. Houlsby et al. [2019] defines an adapter as a two-layer feed-forward neural network with a   \n356 bottleneck representation, and are inserted before the multi-head attention layer in Transformers.   \n357 Similar approaches have been used for cross-lingual transfer [Pfeiffer et al., 2020]. Adapters have   \n358 also been used in vision based multitask settings [Rebuff iet al., 2017]. More recently, Ansell et al.   \n359 [2022] propose to learn sparse masks, and show that these marks are composable, enabling zero-shot   \n360 transfer. Lastly, Hu et al. [2022] learn low-rank shifts on the original weights, and [Liu et al., 2022]   \n361 learns an elementwise multiplier of the pretrained model\u2019s activations. Adapters have also been used   \n362 in multitask settings. Chronopoulou et al. [2023] independently trains adapters for each task. In order   \n363 to transfer to new tasks, the authors merge the parameters of the adapters of relevant training tasks. ", "page_idx": 8}, {"type": "text", "text": "", "page_idx": 8}, {"type": "text", "text": "", "page_idx": 8}, {"type": "text", "text": "364 7 Conclusion ", "text_level": 1, "page_idx": 8}, {"type": "text", "text": "365 We show that individual player behavior can be modeled at very large scale in games as different as   \n366 chess and Rocket League. We cast this problem in the framework of multi-task learning and employ   \n367 modular PEFT methods to learn a shared set of skills across players, modulated by a distinct style   \n368 vector for each player. We use these style vectors to perform behavioral stylometry, analyze player   \n369 styles, and synthesize and steer new styles. ", "page_idx": 8}, {"type": "text", "text": "370 References ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "371 A. Ansell, E. Ponti, A. Korhonen, and I. Vuli\u00b4c. Composable sparse fine-tuning for cross-lingual   \n372 transfer. In Proceedings of the 60th Annual Meeting of the Association for Computational   \n373 Linguistics (Volume 1: Long Papers), pages 1778\u20131796, Dublin, Ireland, May 2022. Asso  \n374 ciation for Computational Linguistics. doi: 10.18653/v1/2022.acl-long.125. URL https:   \n375 //aclanthology.org/2022.acl-long.125.   \n376 S. Bergsma, M. Post, and D. Yarowsky. Stylometric analysis of scientific articles. In Proceedings   \n377 of the 2012 Conference of the North American Chapter of the Association for Computational   \n378 Linguistics: Human Language Technologies, pages 327\u2013337, 2012.   \n379 R.-A. Braaten. Rl-rpt - rocket league replay pre-training. https://github.com/Rolv-Arild/replay  \n380 pretraining, 2022.   \n381 J. Bromley, I. Guyon, Y. LeCun, E. S\u00e4ckinger, and R. Shah. Signature verification using a\" siamese\"   \n382 time delay neural network. Advances in neural information processing systems, 6, 1993.   \n383 L. Caccia, E. Ponti, L. Liu, M. Pereira, N. L. Roux, and A. Sordoni. Multi-head adapter routing for   \n384 data-efficient fine-tuning. arXiv preprint arXiv:2211.03831, 2022.   \n385 A. Caliskan-Islam, R. Harang, A. Liu, A. Narayanan, C. Voss, F. Yamaguchi, and R. Greenstadt.   \n386 De-anonymizing programmers via code stylometry. In 24th USENIX security symposium (USENIX   \n387 Security 15), pages 255\u2013270, 2015.   \n388 CantFlyRL. Ballchasing.com. https://ballchasing.com/, 2024.   \n389 M. Carroll, R. Shah, M. K. Ho, T. Griffiths, S. Seshia, P. Abbeel, and A. Dragan. On the utility of   \n390 learning about humans for human-ai coordination. Advances in neural information processing   \n391 systems, 32, 2019.   \n392 R. Caruana. Multitask learning. Machine learning, 28:41\u201375, 1997.   \n393 A. Chronopoulou, M. Peters, A. Fraser, and J. Dodge. AdapterSoup: Weight averaging to   \n394 improve generalization of pretrained language models. In Findings of the Association for   \n395 Computational Linguistics: EACL 2023, pages 2054\u20132063, Dubrovnik, Croatia, May 2023.   \n396 Association for Computational Linguistics. doi: 10.18653/v1/2023.findings-eacl.153. URL   \n397 https://aclanthology.org/2023.findings-eacl.153.   \n398 K. W. Church. Word2vec. Natural Language Engineering, 23(1):155\u2013162, 2017.   \n399 T. Duplessis. Lichess. http://lichess.org, 2021. Accessed: 2021-01-01.   \n400 L. Emery. Rlgym - the rocket league gym. https://rlgym.org/, 2021.   \n401 P. Florence, C. Lynch, A. Zeng, O. A. Ramirez, A. Wahid, L. Downs, A. Wong, J. Lee, I. Mordatch,   \n402 and J. Tompson. Implicit behavioral cloning. In Conference on Robot Learning, pages 158\u2013168.   \n403 PMLR, 2022.   \n404 S. Goswami, S. Sarkar, and M. Rustagi. Stylometric analysis of bloggers\u2019 age and gender. In   \n405 Proceedings of the International AAAI Conference on Web and Social Media, volume 3, pages   \n406 214\u2013217, 2009.   \n407 J. Gow, R. Baumgarten, P. Cairns, S. Colton, and P. Miller. Unsupervised modeling of player style   \n408 with lda. IEEE Transactions on Computational Intelligence and AI in Games, 4(3):152\u2013166, 2012.   \n409 C. Holmg\u00e5rd, A. Liapis, J. Togelius, and G. N. Yannakakis. Evolving personas for player decision   \n410 modeling. In 2014 IEEE Conference on Computational Intelligence and Games, pages 1\u20138. IEEE,   \n411 2014.   \n412 N. Houlsby, A. Giurgiu, S. Jastrzebski, B. Morrone, Q. De Laroussilhe, A. Gesmundo, M. Attariyan,   \n413 and S. Gelly. Parameter-efficient transfer learning for NLP. In International Conference on   \n414 Machine Learning, pages 2790\u20132799, 2019. URL http://proceedings.mlr.press/v97/   \n415 houlsby19a/houlsby19a.pdf.   \n416 E. J. Hu, Y. Shen, P. Wallis, Z. Allen-Zhu, Y. Li, S. Wang, L. Wang, and W. Chen. LoRA: Low-rank   \n417 adaptation of large language models. In International Conference on Learning Representations,   \n418 2022. URL https://openreview.net/forum?id $\\cdot$ nZeVKeeFYf9.   \n419 J. Hu, L. Shen, and G. Sun. Squeeze-and-excitation networks. In Proceedings of the IEEE conference   \n420 on computer vision and pattern recognition, pages 7132\u20137141, 2018.   \n421 G. Ilharco, M. T. Ribeiro, M. Wortsman, L. Schmidt, H. Hajishirzi, and A. Farhadi. Editing models   \n422 with task arithmetic. In The Eleventh International Conference on Learning Representations, 2023.   \n423 URL https://openreview.net/forum?id=6t0Kwf8-jrj.   \n424 B. Ingram, B. Rosman, C. van Alten, and R. Klein. Play-style identification through deep unsupervised   \n425 clustering of trajectories. In 2022 IEEE Conference on Games (CoG), pages 393\u2013400. IEEE, 2022.   \n426 A. Jelley, Y. Cao, D. Bignell, S. Devlin, and T. Rashid. Aligning agents like large language models,   \n427 2024. URL https://openreview.net/forum?id=kQqZVayz07.   \n428 H. Liu, D. Tam, M. Muqeeth, J. Mohta, T. Huang, M. Bansal, and C. Raffel. Few-shot parameter  \n429 efficient fine-tuning is better and cheaper than in-context learning, 2022. URL https://arxiv.   \n430 org/abs/2205.05638.   \n431 T. McGrath, A. Kapishnikov, N. Toma\u0161ev, A. Pearce, M. Wattenberg, D. Hassabis, B. Kim, U. Paquet,   \n432 and V. Kramnik. Acquisition of chess knowledge in alphazero. Proceedings of the National   \n433 Academy of Sciences, 119(47):e2206625119, 2022.   \n434 R. McIlroy-Young, S. Sen, J. Kleinberg, and A. Anderson. Aligning superhuman ai with human   \n435 behavior: Chess as a model system. In Proceedings of the 26th ACM SIGKDD International   \n436 Conference on Knowledge Discovery and Data Mining, page 1677\u20131687, 2020.   \n437 R. McIlroy-Young, Y. Wang, S. Sen, J. Kleinberg, and A. Anderson. Detecting individual decision  \n438 making style: Exploring behavioral stylometry in chess. Advances in Neural Information Process  \n439 ing Systems, 34:24482\u201324497, 2021.   \n440 R. McIlroy-Young, R. Wang, S. Sen, J. Kleinberg, and A. Anderson. Learning models of individual   \n441 behavior in chess. In Proceedings of the 28th ACM SIGKDD Conference on Knowledge Discovery   \n442 and Data Mining, page 1253\u20131263, 2022.   \n443 T. Neal, K. Sundararajan, A. Fatima, Y. Yan, Y. Xiang, and D. Woodard. Surveying stylometry   \n444 techniques and applications. ACM Computing Surveys (CSuR), 50(6):1\u201336, 2017.   \n445 A. Normoyle and S. Jensen. Bayesian clustering of player styles for multiplayer games. In Pro  \n446 ceedings of the AAAI Conference on Artificial Intelligence and Interactive Digital Entertainment,   \n447 volume 11, pages 163\u2013169, 2015.   \n448 T. Pearce and J. Zhu. Counter-strike deathmatch with large-scale behavioural cloning. In 2022 IEEE   \n449 Conference on Games (CoG), pages 104\u2013111. IEEE, 2022.   \n450 J. Pfeiffer, I. Vulic\u00b4, I. Gurevych, and S. Ruder. MAD-X: An Adapter-based framework for multi-task   \n451 cross-lingual transfer. In Proceedings of the 2020 Conference on Empirical Methods in Natural   \n452 Language Processing (EMNLP), pages 7654\u20137673, Nov. 2020. URL https://aclanthology.   \n453 org/2020.emnlp-main.617.   \n454 D. A. Pomerleau. Alvinn: An autonomous land vehicle in a neural network. Advances in neural   \n455 information processing systems, 1, 1988.   \n456 E. M. Ponti, H. O\u2019Horan, Y. Berzak, I. Vuli\u00b4c, R. Reichart, T. Poibeau, E. Shutova, and A. Ko  \n457 rhonen. Modeling language variation and universals: A survey on typological linguistics   \n458 for natural language processing. Computational Linguistics, 45(3):559\u2013601, 2019. URL   \n459 https://watermark.silverchair.com/coli_a_00357.pdf.   \n460 E. M. Ponti, A. Sordoni, Y. Bengio, and S. Reddy. Combining parameter-efficient modules for task  \n461 level generalisation. In Proceedings of the 17th Conference of the European Chapter of the Associ  \n462 ation for Computational Linguistics, pages 687\u2013702, Dubrovnik, Croatia, May 2023. Association   \n463 for Computational Linguistics. URL https://aclanthology.org/2023.eacl-main.49.   \n464 A. Radford, L. Metz, and S. Chintala. Unsupervised representation learning with deep convolutional   \n465 generative adversarial networks. In International Conference on Learning Representations, 2016.   \n466 A. Radford, J. Wu, R. Child, D. Luan, D. Amodei, and I. Sutskever. Language models are unsupervised   \n467 multitask learners. 2019.   \n468 S.-A. Rebuff,i H. Bilen, and A. Vedaldi. Learning multiple visual domains with residual adapters.   \n469 Advances in neural information processing systems, 30, 2017.   \n470 RLBot. Rlbot. https://github.com/RLBot/RLBot, 2017.   \n471 S. Ruder, M. E. Peters, S. Swayamdipta, and T. Wolf. Transfer learning in natural language   \n472 processing. In Proceedings of the 2019 Conference of the North American Chapter of the   \n473 Association for Computational Linguistics: Tutorials, pages 15\u201318, Minneapolis, Minnesota,   \n474 June 2019. Association for Computational Linguistics. doi: 10.18653/v1/N19-5004. URL   \n475 https://aclanthology.org/N19-5004.   \n476 SaltieRL. Carball. https://github.com/SaltieRL/carball, 2024.   \n477 S. Schaal. Learning from demonstration. Advances in neural information processing systems, 9,   \n478 1996.   \n479 L. Sch\u00e4fer, L. Jones, A. Kanervisto, Y. Cao, T. Rashid, R. Georgescu, D. Bignell, S. Sen, A. T. Gavito,   \n480 and S. Devlin. Visual encoders for data-efficient imitation learning in modern video games, 2023.   \n481 F. J. Tweedie, S. Singh, and D. I. Holmes. Neural network applications in stylometry: The federalist   \n482 papers. Computers and the Humanities, 30:1\u201310, 1996.   \n483 J. Valls-Vargas, S. Ontan\u00f3n, and J. Zhu. Exploring player trace segmentation for dynamic play style   \n484 prediction. In Proceedings of the AAAI Conference on Artificial Intelligence and Interactive Digital   \n485 Entertainment, volume 11, pages 93\u201399, 2015.   \n486 A. Vaswani, N. Shazeer, N. Parmar, J. Uszkoreit, L. Jones, A. N. Gomez, L. Kaiser, and I. Polosukhin.   \n487 Attention is all you need. CoRR, abs/1706.03762, 2017. URL http://arxiv.org/abs/1706.   \n488 03762.   \n489 L. Wan, Q. Wang, A. Papir, and I. L. Moreno. Generalized end-to-end loss for speaker verification.   \n490 In 2018 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP),   \n491 pages 4879\u20134883. IEEE, 2018.   \n492 Z. Wang, Y. Tsvetkov, O. Firat, and Y. Cao. Gradient vaccine: Investigating and improving multi  \n493 task optimization in massively multilingual models. In International Conference on Learning   \n494 Representations, 2021. URL https://openreview.net/forum?id=F1vEjWK-lH_.   \n495 Y. Zhou, C. Barnes, J. Lu, J. Yang, and H. Li. On the continuity of rotation representations in neural   \n496 networks, 2020. ", "page_idx": 9}, {"type": "text", "text": "", "page_idx": 10}, {"type": "text", "text": "", "page_idx": 11}, {"type": "text", "text": "497 A Appendix ", "text_level": 1, "page_idx": 12}, {"type": "text", "text": "498 A.1 Multi-Head Adapter Routing ", "text_level": 1, "page_idx": 12}, {"type": "text", "text": "499 In Poly, the module combination step remains coarse, as only linear combinations of the existing   \n500 modules can be generated. Caccia et al. [2022] propose a more fine-grained module combination   \n501 approach, referred to as Multi-Head Routing (MHR). Similar to Multi-Head Attention [Vaswani et al.,   \n502 2017], the input dimension of $\\pmb{A}$ (and output dimensions of $_B$ ) are partitioned into $h$ heads, where   \n503 a Poly-style procedure occurs for each head. The resulting parameters from each head are then   \n504 concatenated, recovering the full input (and output) dimensions. This makes the module combination   \n505 step piecewise linear, with a separate task-routing matrix $_{z}$ learned for each head.   \n506 Formally, a MHR layer learns a 3-dimensional task-routing tensor $\\pmb{\\ Z}\\in\\mathbb{R}^{|T|\\times|\\mathcal{M}|\\times h}$ . The 2D slice   \n507 $\\bar{\\mathbf{Z}}_{:,:,k}\\,\\in\\,\\bar{\\mathbb{R}}^{|\\mathcal{T}|\\,\\times\\,|\\mathcal{M}|}$ of the tensor ${\\sf z}$ denotes the distribution over modules for the $k$ -th head, and   \n508 $W[k]\\in\\mathbb{R}^{\\frac{d}{h}\\times r}$ the $k$ -th partition along the rows of the matrix $W\\in\\mathbb{R}^{d\\times r}$ . The adapter parameters   \n509 $A^{\\tau}\\in\\mathbb{R}^{d\\times r}$ for task $\\tau$ , and for each adapter layer, are computed as (similarly for $B^{\\tau}$ ): ", "page_idx": 12}, {"type": "text", "text": "", "page_idx": 12}, {"type": "equation", "text": "$$\n\\begin{array}{c}{\\pmb{A}_{k}^{\\tau}=\\displaystyle\\sum_{j}\\alpha_{i,k}\\cdot\\pmb{A}_{j}[k]\\ \\mathrm{with}\\ \\pmb{A}_{k}^{\\tau}\\in\\mathbb{R}^{\\frac{d}{h}\\times r},}\\\\ {\\pmb{A}^{\\tau}=\\mathsf{c o n c a t}(\\pmb{A}_{1}^{\\tau},\\ldots,\\pmb{A}_{h}^{\\tau}),}\\end{array}\n$$", "text_format": "latex", "page_idx": 12}, {"type": "text", "text": "510 where $\\alpha_{i,k}=\\mathsf{s o f t m a x}(Z\\left[\\tau,:,\\mathbf{k}\\right])_{i}$ . Importantly, the number of LoRA adapter parameters does   \n511 not increase with the number of heads. Only the task-routing parameters linearly increase with $h$ for   \n512 MHR vs. Poly. However, this cost is negligible as the parameter count of the routing matrices is much   \n513 smaller than for the LoRA modules themselves. ", "page_idx": 12}, {"type": "text", "text": "514 A.2 Maia Architecture/Data ", "text_level": 1, "page_idx": 12}, {"type": "text", "text": "515 Our base Maia architecture follows McIlroy-Young et al. [2022] and uses the Squeeze-and-Excitation   \n516 (S&E) Residual Network of $[\\mathrm{Hu}$ et al., 2018]. At every residual block, channel information is   \n517 aggregated across spatial dimensions via a global pooling operation. The resulting vector is then   \n518 processed by a 2-layer MLP, with a bottleneck representation compressing the number of channels   \n519 by $r$ . The output of this MLP is a one-dimensional vector used to scale the output of the residual   \n520 block along the channel dimension. We use 12 residual blocks containing 256 fliters, and a bottleneck   \n521 compression factor of $r=8$ . We note that this differs from the base Maia model in McIlroy-Young   \n522 et al. [2022], which uses 64 filters and 6 residual blocks.   \n523 While our dataset has a median game count of 3,479 games, many players may have as few as 10-50   \n524 games, implying some degree of data imbalance. Our evaluation of few-shot learning shows that 100   \n525 games is sufficient to learn the style vector of an unseen player. However, one might still ask how   \n526 accurately such a style vector is given a very small number of games. To explore this, we first split a   \n527 player into disjoint sets of 10, 25, 50, 100, 500, and 1,000 games. We then train a style vector on   \n528 each set. As a baseline, we train a style vector on 10,000 games and track the cosine similarity of the   \n529 smaller-set style vectors relative to this baseline vector. We show the results in Figure 8. ", "page_idx": 12}, {"type": "text", "text": "", "page_idx": 12}, {"type": "text", "text": "530 A.3 Rocket League Architecture/Data ", "text_level": 1, "page_idx": 12}, {"type": "text", "text": "531 The 1v1 replays dataset was scraped over the course of several weeks from the Ballchasing.com API   \n532 using the Grand Champion subscription tier, though the API does have a slower free tier. This API   \n533 yields raw game replays, which are uploaded by users either manually or using a community-made   \n534 plugin for the game. The replays are in a binary format which must be parsed using community-made   \n535 projects such as Carball [SaltieRL, 2024].   \n536 The Carball library allows us to convert the binary replay format to a more standard CSV format,   \n537 which we save to a Cloud binary blob storage. The data present in both is a lossy reconstruction   \n538 of game states, and requires some processing to be usable. In particular, the data is sampled at an   \n539 inconsistent rate (varying between 24hz and 27hz), contains repeated physics ticks, and is missing   \n540 action data for aerial controls (pitch, yaw, roll).   \n541 We resolve the issue of sampling rate and repeated ticks by removing repeated ticks, and doing a   \n542 time-weighted resampling and interpolation to a standard 10hz for model training, though we found   \n543 that 30hz also works well. Note that the actual game physics ticks occur at $120\\mathrm{hz}$ , so any value   \n544 aligned with this should work. Without these changes, the model performs extremely poorly and is   \n545 unable to navigate the arena.   \n546 We resolve the issue of missing aerial controls through the physics-based solver present in the Carball   \n547 library. The estimation of these controls is not perfect, but it is sufficient for our purposes. Some   \n548 previous community work has used inverse dynamics [Braaten, 2022] trained from rollouts of in-game   \n549 bots to solve for these actions, though we opted to not use this due to the inconsistency in replay data   \n550 sampling.   \n551 The data returned by the CSVs are fairly large, messy, and inconsistent. We apply the following   \n552 transformations to the dataframe to bring the values closer to 0:   \n553 \u2022 Divide position by 2300   \n554 \u2022 Divide linear velocity by 23000   \n555 \u2022 Divide angular velocity by 5500   \n556 \u2022 Divide boost by 255   \n557 \u2022 Encode rotation Euler angles according to Zhou et al. [2020]   \n558 Additionally, when turning the data into tokens for use in our model, we add in an extra dimension to   \n559 represent the team, and concatenate the opponent\u2019s data points along with the position, linear and   \n560 angular velocity of the ball. We complete all of these transformations at runtime.   \n561 We also have to align the data returned by the simulators for Rocket League with the data used to   \n562 train the model, RLBot [RLBot, 2017] and RLGym [Emery, 2021]. Along with including an extra   \n563 dimension to represent the team, we apply the following transformations to all samples obtained from   \n564 the game:   \n565 \u2022 Divide position by 2300   \n566 \u2022 Divide linear velocity by 2300   \n567 \u2022 Divide angular velocity by 5.5   \n568 \u2022 Divide boost by 100 ", "page_idx": 12}, {"type": "text", "text": "", "page_idx": 12}, {"type": "text", "text": "", "page_idx": 12}, {"type": "image", "img_path": "QsxldAFMFx/tmp/a56871f4a8d7068775e42a192855374f5a13cbf97e8d59af07e69f8ad51b57f5.jpg", "img_caption": ["Figure 8: Cosine similarity of style vectors trained with varying game sizes compared to a style vector trained with 10,000 games, run on 50 players. "], "img_footnote": [], "page_idx": 13}, {"type": "text", "text": "", "page_idx": 13}, {"type": "text", "text": "", "page_idx": 13}, {"type": "text", "text": "", "page_idx": 13}, {"type": "text", "text": "", "page_idx": 13}, {"type": "text", "text": "", "page_idx": 13}, {"type": "text", "text": "", "page_idx": 13}, {"type": "text", "text": "", "page_idx": 13}, {"type": "text", "text": "569 The skill distribution of the players in our dataset can be found in Figure 9. ", "page_idx": 13}, {"type": "text", "text": "570 A.4 Implicit Stationarity Assumptions ", "text_level": 1, "page_idx": 13}, {"type": "text", "text": "571 Most of the existing work in chess assumes that a player remains stationary over time and across   \n572 gameplay situations. However, in reality, a player\u2019s style may depend on the type of opponent they   \n573 are facing, which opening is used, which stage of the game they are in (opening, middle, endgame),   \n574 and so on. For instance, McIlroy-Young et al. [2021] observe that stylometry accuracy drops when   \n575 removing the opening (e.g., the first 15 moves) moves, suggesting that the opening has an outsized   \n576 effect on style identification. Our approach does not rely on these assumptions and can in principle   \n577 be applied to arbitrary subsets of a player\u2019s data. For instance, one could split a player\u2019s data into   \n578 opening, middlegame, and endgame moves and train a separate style vector for each. One could   \n579 further split the data based on which defense the opponent uses, what time of the day it is, etc..   \n580 Despite treating players holistically and avoiding any splits of their data, we are still able to capture   \n581 the peculiarities of each individual\u2019s playing style and perform stylometry with high accuracy. This   \n582 also enables us to compare our results to those of prior work, which also treats player data holistically. ", "page_idx": 13}, {"type": "image", "img_path": "QsxldAFMFx/tmp/878467ca6e1763bad486971d607965cc2dc6dfe83d3966b381c59fd35a90b6a1.jpg", "img_caption": ["Figure 9: Skill distribution of Rocket League players in our dataset. "], "img_footnote": [], "page_idx": 14}, {"type": "text", "text": "", "page_idx": 14}, {"type": "text", "text": "583 A.5 Delta Style Vector Computation ", "text_level": 1, "page_idx": 14}, {"type": "table", "img_path": "QsxldAFMFx/tmp/10e7bdd87059ca922bc9ed7db6f34a8c6b2e8d47507248e01aad2317e2416d19.jpg", "table_caption": [], "table_footnote": [], "page_idx": 14}, {"type": "text", "text": "584 NeurIPS Paper Checklist ", "text_level": 1, "page_idx": 15}, {"type": "text", "text": "Question: Do the main claims made in the abstract and introduction accurately reflect the paper\u2019s contributions and scope? ", "page_idx": 15}, {"type": "text", "text": "Justification: The abstract directly summarizes the key results of the paper, which focus on performing behavioral stylometry at scale in games (chess and Rocket League) ", "page_idx": 15}, {"type": "text", "text": "\u2022 The answer NA means that the abstract and introduction do not include the claims made in the paper.   \n\u2022 The abstract and/or introduction should clearly state the claims made, including the contributions made in the paper and important assumptions and limitations. A No or NA answer to this question will not be perceived well by the reviewers.   \n\u2022 The claims made should match theoretical and experimental results, and reflect how much the results can be expected to generalize to other settings.   \n\u2022 It is fine to include aspirational goals as motivation as long as it is clear that these goals are not attained by the paper. ", "page_idx": 15}, {"type": "text", "text": "2. Limitations ", "text_level": 1, "page_idx": 15}, {"type": "text", "text": "Question: Does the paper discuss the limitations of the work performed by the authors? Answer: [Yes] ", "page_idx": 15}, {"type": "text", "text": "Justification: Please see Related work and explanation of our limited style synthesis/steering results for Rocket League. ", "page_idx": 15}, {"type": "text", "text": "\u2022 The answer NA means that the paper has no limitation while the answer No means that the paper has limitations, but those are not discussed in the paper.   \n\u2022 The authors are encouraged to create a separate \"Limitations\" section in their paper.   \n\u2022 The paper should point out any strong assumptions and how robust the results are to violations of these assumptions (e.g., independence assumptions, noiseless settings, model well-specification, asymptotic approximations only holding locally). The authors should reflect on how these assumptions might be violated in practice and what the implications would be.   \n\u2022 The authors should reflect on the scope of the claims made, e.g., if the approach was only tested on a few datasets or with a few runs. In general, empirical results often depend on implicit assumptions, which should be articulated.   \n\u2022 The authors should reflect on the factors that influence the performance of the approach. For example, a facial recognition algorithm may perform poorly when image resolution is low or images are taken in low lighting. Or a speech-to-text system might not be used reliably to provide closed captions for online lectures because it fails to handle technical jargon.   \n\u2022 The authors should discuss the computational efficiency of the proposed algorithms and how they scale with dataset size.   \n\u2022 If applicable, the authors should discuss possible limitations of their approach to address problems of privacy and fairness.   \n\u2022 While the authors might fear that complete honesty about limitations might be used by reviewers as grounds for rejection, a worse outcome might be that reviewers discover limitations that aren\u2019t acknowledged in the paper. The authors should use their best judgment and recognize that individual actions in favor of transparency play an important role in developing norms that preserve the integrity of the community. Reviewers will be specifically instructed to not penalize honesty concerning limitations. ", "page_idx": 15}, {"type": "text", "text": "3. Theory Assumptions and Proofs ", "text_level": 1, "page_idx": 15}, {"type": "text", "text": "Question: For each theoretical result, does the paper provide the full set of assumptions and a complete (and correct) proof? ", "page_idx": 15}, {"type": "text", "text": "39 \u2022 The answer NA means that the paper does not include theoretical results.   \n40 \u2022 All the theorems, formulas, and proofs in the paper should be numbered and cross  \n41 referenced.   \n42 \u2022 All assumptions should be clearly stated or referenced in the statement of any theorems.   \n43 \u2022 The proofs can either appear in the main paper or the supplemental material, but if   \n44 they appear in the supplemental material, the authors are encouraged to provide a short   \n45 proof sketch to provide intuition.   \n46 \u2022 Inversely, any informal proof provided in the core of the paper should be complemented   \n47 by formal proofs provided in appendix or supplemental material.   \n48 \u2022 Theorems and Lemmas that the proof relies upon should be properly referenced. ", "page_idx": 16}, {"type": "text", "text": "649 4. Experimental Result Reproducibility ", "text_level": 1, "page_idx": 16}, {"type": "text", "text": "650 Question: Does the paper fully disclose all the information needed to reproduce the main ex  \n651 perimental results of the paper to the extent that it affects the main claims and/or conclusions   \n652 of the paper (regardless of whether the code and data are provided or not)? ", "page_idx": 16}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 16}, {"type": "text", "text": "Justification: We provide thorough implementation details, some of which appear in the appendix. ", "page_idx": 16}, {"type": "text", "text": "Guidelines: ", "page_idx": 16}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 If the paper includes experiments, a No answer to this question will not be perceived well by the reviewers: Making the paper reproducible is important, regardless of whether the code and data are provided or not.   \n\u2022 If the contribution is a dataset and/or model, the authors should describe the steps taken to make their results reproducible or verifiable.   \n\u2022 Depending on the contribution, reproducibility can be accomplished in various ways. For example, if the contribution is a novel architecture, describing the architecture fully might suffice, or if the contribution is a specific model and empirical evaluation, it may be necessary to either make it possible for others to replicate the model with the same dataset, or provide access to the model. In general. releasing code and data is often one good way to accomplish this, but reproducibility can also be provided via detailed instructions for how to replicate the results, access to a hosted model (e.g., in the case of a large language model), releasing of a model checkpoint, or other means that are appropriate to the research performed.   \n\u2022 While NeurIPS does not require releasing code, the conference does require all submissions to provide some reasonable avenue for reproducibility, which may depend on the nature of the contribution. For example (a) If the contribution is primarily a new algorithm, the paper should make it clear how to reproduce that algorithm. (b) If the contribution is primarily a new model architecture, the paper should describe the architecture clearly and fully. (c) If the contribution is a new model (e.g., a large language model), then there should either be a way to access this model for reproducing the results or a way to reproduce the model (e.g., with an open-source dataset or instructions for how to construct the dataset). (d) We recognize that reproducibility may be tricky in some cases, in which case authors are welcome to describe the particular way they provide for reproducibility. In the case of closed-source models, it may be that access to the model is limited in some way (e.g., to registered users), but it should be possible for other researchers to have some path to reproducing or verifying the results. ", "page_idx": 16}, {"type": "text", "text": "688 5. Open access to data and code ", "text_level": 1, "page_idx": 16}, {"type": "text", "text": "689 Question: Does the paper provide open access to the data and code, with sufficient instruc  \n690 tions to faithfully reproduce the main experimental results, as described in supplemental   \n691 material?   \n692 Answer: [Yes]   \n693 Justification: We will open source our data and models upon publication.   \n694 Guidelines:   \n695 \u2022 The answer NA means that paper does not include experiments requiring code.   \n696 \u2022 Please see the NeurIPS code and data submission guidelines (https://nips.cc/   \n697 public/guides/CodeSubmissionPolicy) for more details.   \n698 \u2022 While we encourage the release of code and data, we understand that this might not be   \n699 possible, so \u201cNo\u201d is an acceptable answer. Papers cannot be rejected simply for not   \n700 including code, unless this is central to the contribution (e.g., for a new open-source   \n701 benchmark).   \n702 \u2022 The instructions should contain the exact command and environment needed to run to   \n703 reproduce the results. See the NeurIPS code and data submission guidelines (https:   \n704 //nips.cc/public/guides/CodeSubmissionPolicy) for more details.   \n705 \u2022 The authors should provide instructions on data access and preparation, including how   \n706 to access the raw data, preprocessed data, intermediate data, and generated data, etc.   \n707 \u2022 The authors should provide scripts to reproduce all experimental results for the new   \n708 proposed method and baselines. If only a subset of experiments are reproducible, they   \n709 should state which ones are omitted from the script and why.   \n710 \u2022 At submission time, to preserve anonymity, the authors should release anonymized   \n711 versions (if applicable).   \n712 \u2022 Providing as much information as possible in supplemental material (appended to the   \n713 paper) is recommended, but including URLs to data and code is permitted.   \n714 6. Experimental Setting/Details   \n715 Question: Does the paper specify all the training and test details (e.g., data splits, hyper  \n716 parameters, how they were chosen, type of optimizer, etc.) necessary to understand the   \n717 results?   \n718 Answer: [Yes]   \n719 Justification: See Appendix and main paper for full experimental details.   \n720 Guidelines:   \n721 \u2022 The answer NA means that the paper does not include experiments.   \n722 \u2022 The experimental setting should be presented in the core of the paper to a level of detail   \n723 that is necessary to appreciate the results and make sense of them.   \n724 \u2022 The full details can be provided either with the code, in appendix, or as supplemental   \n725 material.   \n726 7. Experiment Statistical Significance   \n727 Question: Does the paper report error bars suitably and correctly defined or other appropriate   \n728 information about the statistical significance of the experiments?   \n729 Answer: [Yes]   \n730 Justification: While we do not use error bars, our methodology is properly described and   \n731 clarifies the significance or our results.   \n732 Guidelines:   \n733 \u2022 The answer NA means that the paper does not include experiments.   \n734 \u2022 The authors should answer \"Yes\" if the results are accompanied by error bars, confi  \n735 dence intervals, or statistical significance tests, at least for the experiments that support   \n736 the main claims of the paper.   \n737 \u2022 The factors of variability that the error bars are capturing should be clearly stated (for   \n738 example, train/test split, initialization, random drawing of some parameter, or overall   \n739 run with given experimental conditions).   \n40 \u2022 The method for calculating the error bars should be explained (closed form formula,   \n41 call to a library function, bootstrap, etc.)   \n42 \u2022 The assumptions made should be given (e.g., Normally distributed errors).   \n43 \u2022 It should be clear whether the error bar is the standard deviation or the standard error   \n44 of the mean.   \n45 \u2022 It is OK to report 1-sigma error bars, but one should state it. The authors should   \n46 preferably report a 2-sigma error bar than state that they have a $96\\%$ CI, if the hypothesis   \n47 of Normality of errors is not verified.   \n48 \u2022 For asymmetric distributions, the authors should be careful not to show in tables or   \n49 figures symmetric error bars that would yield results that are out of range (e.g. negative   \n50 error rates).   \n51 \u2022 If error bars are reported in tables or plots, The authors should explain in the text how   \n52 they were calculated and reference the corresponding figures or tables in the text. ", "page_idx": 17}, {"type": "text", "text": "", "page_idx": 18}, {"type": "text", "text": "753 8. Experiments Compute Resources ", "text_level": 1, "page_idx": 18}, {"type": "text", "text": "754 Question: For each experiment, does the paper provide sufficient information on the com  \n755 puter resources (type of compute workers, memory, time of execution) needed to reproduce   \n756 the experiments?   \n57 Answer: [Yes]   \n58 Justification: We talk about the exact model parameter sizes, and use standard models that   \n59 are very small. Due to the use of standard base models, information on computational   \n60 resources required to train them based on token count is readily available. ", "page_idx": 18}, {"type": "text", "text": "", "page_idx": 18}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 The paper should indicate the type of compute workers CPU or GPU, internal cluster, or cloud provider, including relevant memory and storage.   \n\u2022 The paper should provide the amount of compute required for each of the individual experimental runs as well as estimate the total compute.   \n\u2022 The paper should disclose whether the full research project required more compute than the experiments reported in the paper (e.g., preliminary or failed experiments that didn\u2019t make it into the paper). ", "page_idx": 18}, {"type": "text", "text": "770 9. Code Of Ethics ", "text_level": 1, "page_idx": 18}, {"type": "text", "text": "771 Question: Does the research conducted in the paper conform, in every respect, with the   \n772 NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines? ", "page_idx": 18}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 18}, {"type": "text", "text": "Justification: Upon reading the code of Ethics, the paper conforms to the code of ethics. 5 Guidelines: ", "page_idx": 18}, {"type": "text", "text": "76 \u2022 The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics.   \n77 \u2022 If the authors answer No, they should explain the special circumstances that require a   \n78 deviation from the Code of Ethics.   \n79 \u2022 The authors should make sure to preserve anonymity (e.g., if there is a special consid  \n780 eration due to laws or regulations in their jurisdiction). ", "page_idx": 18}, {"type": "text", "text": "781 10. Broader Impacts ", "text_level": 1, "page_idx": 18}, {"type": "text", "text": "782 Question: Does the paper discuss both potential positive societal impacts and negative   \n783 societal impacts of the work performed?   \n4 Answer: [Yes]   \n5 Justification: This paper extends prior work on behavior cloning of individual behavior, but   \n6 it is not the first to perform such fine-grained behavior cloning or observe their societal   \n7 implications. Prior work by McIlroy-Young et al. discusses the implications of mimicking   \n88 individual behavior with high fidelity (see \"Mimetic Models: Ethical Implications of AI that   \n89 Acts Like You\" in AIES \u20192022).   \n90 Guidelines:   \n791 \u2022 The answer NA means that there is no societal impact of the work performed.   \n792 \u2022 If the authors answer NA or No, they should explain why their work has no societal   \n793 impact or why the paper does not address societal impact.   \n794 \u2022 Examples of negative societal impacts include potential malicious or unintended uses   \n795 (e.g., disinformation, generating fake profiles, surveillance), fairness considerations   \n796 (e.g., deployment of technologies that could make decisions that unfairly impact specific   \n797 groups), privacy considerations, and security considerations.   \n798 \u2022 The conference expects that many papers will be foundational research and not tied   \n799 to particular applications, let alone deployments. However, if there is a direct path to   \n800 any negative applications, the authors should point it out. For example, it is legitimate   \n801 to point out that an improvement in the quality of generative models could be used to   \n802 generate deepfakes for disinformation. On the other hand, it is not needed to point out   \n803 that a generic algorithm for optimizing neural networks could enable people to train   \n804 models that generate Deepfakes faster.   \n805 \u2022 The authors should consider possible harms that could arise when the technology is   \n806 being used as intended and functioning correctly, harms that could arise when the   \n807 technology is being used as intended but gives incorrect results, and harms following   \n808 from (intentional or unintentional) misuse of the technology.   \n809 \u2022 If there are negative societal impacts, the authors could also discuss possible mitigation   \n810 strategies (e.g., gated release of models, providing defenses in addition to attacks,   \n811 mechanisms for monitoring misuse, mechanisms to monitor how a system learns from   \n812 feedback over time, improving the efficiency and accessibility of ML).   \n813 11. Safeguards   \n814 Question: Does the paper describe safeguards that have been put in place for responsible   \n815 release of data or models that have a high risk for misuse (e.g., pretrained language models,   \n816 image generators, or scraped datasets)?   \n817 Answer: [NA]   \n818 Guidelines:   \n819 \u2022 The answer NA means that the paper poses no such risks.   \n820 \u2022 Released models that have a high risk for misuse or dual-use should be released with   \n821 necessary safeguards to allow for controlled use of the model, for example by requiring   \n822 that users adhere to usage guidelines or restrictions to access the model or implementing   \n823 safety filters.   \n824 \u2022 Datasets that have been scraped from the Internet could pose safety risks. The authors   \n825 should describe how they avoided releasing unsafe images.   \n826 \u2022 We recognize that providing effective safeguards is challenging, and many papers do   \n827 not require this, but we encourage authors to take this into account and make a best   \n828 faith effort.   \n829 12. Licenses for existing assets   \n830 Question: Are the creators or original owners of assets (e.g., code, data, models), used in   \n831 the paper, properly credited and are the license and terms of use explicitly mentioned and   \n832 properly respected?   \n833 Answer: [Yes]   \n834 Justification: Papers and codebases are properly cited.   \n835 Guidelines:   \n836 \u2022 The answer NA means that the paper does not use existing assets.   \n837 \u2022 The authors should cite the original paper that produced the code package or dataset.   \n838 \u2022 The authors should state which version of the asset is used and, if possible, include a   \n839 URL.   \n840 \u2022 The name of the license (e.g., CC-BY 4.0) should be included for each asset.   \n841 \u2022 For scraped data from a particular source (e.g., website), the copyright and terms of   \n842 service of that source should be provided. ", "page_idx": 18}, {"type": "text", "text": "", "page_idx": 18}, {"type": "text", "text": "", "page_idx": 19}, {"type": "text", "text": "\u2022 If assets are released, the license, copyright information, and terms of use in the package should be provided. For popular datasets, paperswithcode.com/datasets has curated licenses for some datasets. Their licensing guide can help determine the license of a dataset.   \n\u2022 For existing datasets that are re-packaged, both the original license and the license of the derived asset (if it has changed) should be provided.   \n\u2022 If this information is not available online, the authors are encouraged to reach out to the asset\u2019s creators. ", "page_idx": 20}, {"type": "text", "text": "13. New Assets ", "page_idx": 20}, {"type": "text", "text": "Question: Are new assets introduced in the paper well documented and is the documentation provided alongside the assets? ", "page_idx": 20}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not release new assets.   \n\u2022 Researchers should communicate the details of the dataset/code/model as part of their submissions via structured templates. This includes details about training, license, limitations, etc.   \n\u2022 The paper should discuss whether and how consent was obtained from people whose asset is used.   \n\u2022 At submission time, remember to anonymize your assets (if applicable). You can either create an anonymized URL or include an anonymized zip file. ", "page_idx": 20}, {"type": "text", "text": "14. Crowdsourcing and Research with Human Subjects ", "text_level": 1, "page_idx": 20}, {"type": "text", "text": "Question: For crowdsourcing experiments and research with human subjects, does the paper include the full text of instructions given to participants and screenshots, if applicable, as well as details about compensation (if any)? ", "page_idx": 20}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 20}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u2022 Including this information in the supplemental material is fine, but if the main contribution of the paper involves human subjects, then as much detail as possible should be included in the main paper.   \n\u2022 According to the NeurIPS Code of Ethics, workers involved in data collection, curation, or other labor should be paid at least the minimum wage in the country of the data collector. ", "page_idx": 20}, {"type": "text", "text": "15. Institutional Review Board (IRB) Approvals or Equivalent for Research with Human Subjects ", "page_idx": 20}, {"type": "text", "text": "Question: Does the paper describe potential risks incurred by study participants, whether such risks were disclosed to the subjects, and whether Institutional Review Board (IRB) approvals (or an equivalent approval/review based on the requirements of your country or 3 institution) were obtained? ", "page_idx": 20}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 20}, {"type": "text", "text": "Guidelines: ", "page_idx": 20}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u2022 Depending on the country in which research is conducted, IRB approval (or equivalent) may be required for any human subjects research. If you obtained IRB approval, you should clearly state this in the paper.   \n\u2022 We recognize that the procedures for this may vary significantly between institutions and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the guidelines for their institution.   \n\u2022 For initial submissions, do not include any information that would break anonymity (if applicable), such as the institution conducting the review. ", "page_idx": 20}]