[{"figure_path": "u6FuiKzT1K/figures/figures_1_1.jpg", "caption": "Figure 1: A toy example to illustrate the difference of the token generator between the token generator in our method and that used in the previous node tokenized graph Transformers. Previous methods only sample nodes with high similarity to construct token sequences. In contrast, our method introduces both positive and negative token sampling to preserve information carried by diverse nodes in the graph.", "description": "This figure illustrates the difference between previous node tokenized graph transformer methods and the proposed GCFormer method in terms of token generation. Previous methods only selected nodes with high similarity scores to the target node, ignoring other nodes. GCFormer, on the other hand, uses a hybrid token generator to create both positive (similar nodes) and negative (dissimilar nodes) token sequences, thus incorporating information from a more diverse set of nodes.", "section": "1 Introduction"}, {"figure_path": "u6FuiKzT1K/figures/figures_7_1.jpg", "caption": "Figure 2: Performance of GCFormer with different sampling sizes on all datasets.", "description": "This figure shows the performance of GCFormer model with different sampling sizes (pk and nk) for both positive and negative tokens on eight datasets. The x-axis represents the size of positive tokens (pk), and the y-axis represents the size of negative tokens (nk). Each subplot corresponds to a different dataset. The color intensity represents the accuracy of the model on the specific dataset and sampling sizes.", "section": "5.3 Parameter Sensitivity Analysis"}, {"figure_path": "u6FuiKzT1K/figures/figures_8_1.jpg", "caption": "Figure 2: Performance of GCFormer with different sampling sizes on all datasets.", "description": "This figure visualizes the performance of the GCFormer model across eight datasets with varying sizes of positive (pk) and negative (nk) token samples. Each subplot represents a dataset and shows how the accuracy changes with different combinations of pk and nk values. The x-axis represents pk and the y-axis represents the accuracy. The purpose is to analyze the influence of token sampling sizes on the model's performance across different datasets and graph characteristics.", "section": "5.3 Parameter Sensitivity Analysis"}, {"figure_path": "u6FuiKzT1K/figures/figures_8_2.jpg", "caption": "Figure 2: Performance of GCFormer with different sampling sizes on all datasets.", "description": "This figure displays the performance of the GCFormer model with varying sizes of positive and negative token samples. The x-axis represents the number of positive tokens (pk) and the number of negative tokens (nk).  The y-axis shows the accuracy achieved on eight different datasets, categorized by homophily levels.  Each subplot represents a different dataset, allowing for a visual comparison of how sample size affects performance across various graph structures. This helps demonstrate the impact of carefully selecting token sequences on model accuracy in different graph contexts.", "section": "5.3 Parameter Sensitivity Analysis"}]