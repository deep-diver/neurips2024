[{"figure_path": "u6FuiKzT1K/tables/tables_6_1.jpg", "caption": "Table 1: Comparison of all models in terms of mean accuracy \u00b1 stdev (%). The best results appear in bold. The second results appear in underline.", "description": "This table presents a comparison of various node classification models on eight different datasets.  The models include several Graph Neural Networks (GNNs) and Graph Transformers.  For each dataset and model, the table shows the mean accuracy and standard deviation. The best-performing model for each dataset is highlighted in bold, and the second-best is underlined. The datasets are categorized by their level of homophily (the tendency for similar nodes to connect).", "section": "5 Experiments"}, {"figure_path": "u6FuiKzT1K/tables/tables_13_1.jpg", "caption": "Table 1: Comparison of all models in terms of mean accuracy \u00b1 stdev (%). The best results appear in bold. The second results appear in underline.", "description": "This table presents a comparison of the performance of various node classification models on eight different datasets.  The models include both Graph Neural Networks (GNNs) and Graph Transformers. The performance metric is mean accuracy, calculated with standard deviation.  The best and second-best performing models are highlighted for each dataset.  The datasets vary in size, features, and level of homophily (a measure of the similarity between connected nodes).", "section": "5 Experiments"}, {"figure_path": "u6FuiKzT1K/tables/tables_14_1.jpg", "caption": "Table 1: Comparison of all models in terms of mean accuracy \u00b1 stdev (%). The best results appear in bold. The second results appear in underline.", "description": "This table compares the performance of GCFormer against other state-of-the-art graph neural networks and graph transformers on eight benchmark datasets.  The datasets vary in size, and the homophily level (the tendency for nodes of the same class to be connected) is also indicated. The table shows the mean accuracy and standard deviation for each model on each dataset.  Bold values indicate the best-performing model on each dataset, while underlined values show the second-best performance. The results demonstrate the superiority of GCFormer in node classification.", "section": "5 Experiments"}, {"figure_path": "u6FuiKzT1K/tables/tables_14_2.jpg", "caption": "Table 4: Performance of different GraphGPS's implementations. \"T\" and \"P\" indicate the original Transformer and Performer. \"L\", \"R\" and \"D\" indicate the Laplacian positional encoding, RWSE structural encoding and degree-based encoding. \"OOM\" indicates the out-of-memory issue.", "description": "This table compares the performance of different GraphGPS implementations on eight datasets with varying homophily levels.  It shows the mean accuracy of node classification for each dataset and model variant. The variations explore different positional encoding methods combined with Transformer and Performer architectures.  The \"OOM\" indicates that the model ran out of memory on those datasets.", "section": "5 Experiments"}]