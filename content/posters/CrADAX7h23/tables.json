[{"figure_path": "CrADAX7h23/tables/tables_2_1.jpg", "caption": "Table 2: Comparison of sequence reconstruction from gradients between DAGER and the baseline algorithms TAG and LAMP on various batch sizes and datasets. R-1 and R-2 denote the ROUGE-1 and ROUGE-2 scores respectively.", "description": "This table compares the performance of DAGER against two state-of-the-art gradient inversion attack algorithms, TAG and LAMP.  The comparison is done across different datasets (COLA, SST-2, Rotten Tomatoes) and varying batch sizes (B=1, 2, 4, 8).  The results are presented in terms of ROUGE-1 and ROUGE-2 scores, which measure the overlap of unigrams and bigrams, respectively, between the original text and the reconstructed text.  Higher ROUGE scores indicate better reconstruction quality.", "section": "6 Experimental Evaluation"}, {"figure_path": "CrADAX7h23/tables/tables_5_1.jpg", "caption": "Table 2: Comparison of sequence reconstruction from gradients between DAGER and the baseline algorithms TAG and LAMP on various batch sizes and datasets. R-1 and R-2 denote the ROUGE-1 and ROUGE-2 scores respectively.", "description": "This table compares the performance of DAGER against two state-of-the-art gradient inversion attack algorithms, TAG and LAMP.  The comparison is made across different datasets (COLA, SST-2, Rotten Tomatoes) and varying batch sizes (B=1, 2, 4, 8). The results are evaluated using ROUGE-1 and ROUGE-2 scores, which measure the overlap of unigrams and bigrams, respectively, between the original and reconstructed sequences.  Higher ROUGE scores indicate better reconstruction quality.", "section": "6 Experimental Evaluation"}, {"figure_path": "CrADAX7h23/tables/tables_6_1.jpg", "caption": "Table 2: Comparison of sequence reconstruction from gradients between DAGER and the baseline algorithms TAG and LAMP on various batch sizes and datasets. R-1 and R-2 denote the ROUGE-1 and ROUGE-2 scores respectively.", "description": "This table compares the performance of DAGER against two state-of-the-art gradient inversion algorithms, TAG and LAMP.  The comparison is done across different datasets (COLA, SST-2, Rotten Tomatoes) and varying batch sizes (B=1, 2, 4, 8).  The results are presented as ROUGE-1 and ROUGE-2 scores, which measure the overlap of unigrams and bigrams between the reconstructed and original sequences, respectively.  Higher scores indicate better reconstruction quality.", "section": "6 Experimental Evaluation"}, {"figure_path": "CrADAX7h23/tables/tables_8_1.jpg", "caption": "Table 2: Comparison of sequence reconstruction from gradients between DAGER and the baseline algorithms TAG and LAMP on various batch sizes and datasets. R-1 and R-2 denote the ROUGE-1 and ROUGE-2 scores respectively.", "description": "This table compares the performance of the proposed DAGER algorithm against two state-of-the-art gradient inversion algorithms, TAG and LAMP, across different datasets (COLA, SST-2, Rotten Tomatoes) and batch sizes (B=1, 2, 4, 8).  The results are presented as ROUGE-1 and ROUGE-2 scores, which measure the overlap of unigrams and bigrams between the reconstructed sequences and the ground truth, respectively.  Higher ROUGE scores indicate better reconstruction quality.", "section": "Experimental Evaluation"}, {"figure_path": "CrADAX7h23/tables/tables_8_2.jpg", "caption": "Table 2: Comparison of sequence reconstruction from gradients between DAGER and the baseline algorithms TAG and LAMP on various batch sizes and datasets. R-1 and R-2 denote the ROUGE-1 and ROUGE-2 scores respectively.", "description": "This table compares the performance of DAGER against two state-of-the-art gradient inversion attack algorithms, TAG and LAMP.  The comparison is done across different datasets (COLA, SST-2, Rotten Tomatoes) and varying batch sizes (B=1, 2, 4, 8). The results are presented in terms of ROUGE-1 and ROUGE-2 scores, which measure the overlap of unigrams and bigrams respectively between the reconstructed and original sequences. Higher ROUGE scores indicate better reconstruction quality.", "section": "6 Experimental Evaluation"}, {"figure_path": "CrADAX7h23/tables/tables_8_3.jpg", "caption": "Table 4: Experiments on the FedAVG setting on the GPT-2 model with a batch size of 16 on the Rotten Tomatoes dataset. We use default set of hyperparameters of E = 10 epochs, learning rate \u03b7 = 10-4 and mini-batch size Bmini = 4. R-1 and R-2 denote ROUGE-1 and ROUGE-2 respectively.", "description": "This table shows the results of experiments conducted using the FedAvg algorithm on the GPT-2 model.  The experiments were performed on the Rotten Tomatoes dataset with a batch size of 16. The table explores how different hyperparameters (number of epochs, learning rate, and mini-batch size) impact the performance of the gradient inversion attack (DAGER) in terms of ROUGE-1 and ROUGE-2 scores.  ROUGE-1 and ROUGE-2 are metrics that measure the quality of the reconstruction of the original data.", "section": "Effect of Fine-tuning Methods"}, {"figure_path": "CrADAX7h23/tables/tables_9_1.jpg", "caption": "Table 3: Main experiments on the GPT-2BASE and LLaMa-2 (7B) models with higher batch sizes on various datasets. R-1 and R-2 denote the ROUGE-1 and ROUGE-2 scores respectively.", "description": "This table presents the main experimental results of DAGER, showing its performance on GPT-2BASE and LLaMa-2 (7B) models for different batch sizes (16, 32, 64, and 128) and datasets (COLA, SST-2, and Rotten Tomatoes).  ROUGE-1 and ROUGE-2 scores are used to evaluate the reconstruction quality. The results demonstrate DAGER's ability to achieve near-perfect reconstructions even at large batch sizes, especially for the larger LLaMa-2 model.", "section": "6 Experimental Evaluation"}, {"figure_path": "CrADAX7h23/tables/tables_19_1.jpg", "caption": "Table 6: Specifications of models that were used in our work.", "description": "This table lists the specifications of the language models used in the paper's experiments.  For each model, it provides the model type (encoder or decoder), the number of layers, the hidden dimension (d), the number of attention heads, the feed-forward size, the vocabulary size (V), the type of positional embedding used, and the total number of parameters.", "section": "6.1 Experimental Setup"}, {"figure_path": "CrADAX7h23/tables/tables_19_2.jpg", "caption": "Table 2: Comparison of sequence reconstruction from gradients between DAGER and the baseline algorithms TAG and LAMP on various batch sizes and datasets. R-1 and R-2 denote the ROUGE-1 and ROUGE-2 scores respectively.", "description": "This table compares the performance of DAGER against two state-of-the-art gradient inversion attack algorithms, TAG and LAMP.  The comparison is done across different datasets (COLA, SST-2, Rotten Tomatoes) and varying batch sizes (B=1, 2, 4, 8). The results are measured using ROUGE-1 and ROUGE-2 scores, which evaluate the overlap of unigrams and bigrams between the reconstructed and original sequences, respectively.  Higher ROUGE scores indicate better reconstruction quality.", "section": "6 Experimental Evaluation"}, {"figure_path": "CrADAX7h23/tables/tables_20_1.jpg", "caption": "Table 2: Comparison of sequence reconstruction from gradients between DAGER and the baseline algorithms TAG and LAMP on various batch sizes and datasets. R-1 and R-2 denote the ROUGE-1 and ROUGE-2 scores respectively.", "description": "This table compares the performance of DAGER against two state-of-the-art gradient inversion algorithms, TAG and LAMP, across different batch sizes (B=1, 2, 4, 8) and datasets (COLA, SST-2, Rotten Tomatoes).  The results are presented in terms of ROUGE-1 and ROUGE-2 scores, which measure the overlap of unigrams and bigrams, respectively, between the reconstructed and original sequences.  Higher ROUGE scores indicate better reconstruction quality.", "section": "Experimental Evaluation"}, {"figure_path": "CrADAX7h23/tables/tables_21_1.jpg", "caption": "Table 2: Comparison of sequence reconstruction from gradients between DAGER and the baseline algorithms TAG and LAMP on various batch sizes and datasets. R-1 and R-2 denote the ROUGE-1 and ROUGE-2 scores respectively.", "description": "This table compares the performance of DAGER against two state-of-the-art gradient inversion algorithms, TAG and LAMP, across different batch sizes and datasets.  It shows the ROUGE-1 and ROUGE-2 scores, which measure the overlap of unigrams and bigrams respectively between the original text and the reconstructed text.  Higher ROUGE scores indicate better reconstruction quality.", "section": "6 Experimental Evaluation"}, {"figure_path": "CrADAX7h23/tables/tables_21_2.jpg", "caption": "Table 2: Comparison of sequence reconstruction from gradients between DAGER and the baseline algorithms TAG and LAMP on various batch sizes and datasets. R-1 and R-2 denote the ROUGE-1 and ROUGE-2 scores respectively.", "description": "This table compares the performance of DAGER against two state-of-the-art gradient inversion attack algorithms, TAG and LAMP, across various datasets and batch sizes.  It shows ROUGE-1 and ROUGE-2 scores, which measure the overlap of unigrams and bigrams respectively, to evaluate the quality of the reconstructed sequences.  The table highlights the significant improvement in reconstruction quality, achieved by DAGER, particularly for larger batch sizes.", "section": "6 Experimental Evaluation"}, {"figure_path": "CrADAX7h23/tables/tables_22_1.jpg", "caption": "Table 10: Experiments on the differential privacy setting under Gaussian noise on the GPT-2 model with a batch size of 1 on the Rotten Tomatoes dataset. R-1 and R-2 denote the ROUGE-1 and ROUGE-2 scores respectively.", "description": "This table presents the results of experiments evaluating the performance of the DAGER attack against a model protected with differential privacy.  The experiments were conducted on the GPT-2 model using the Rotten Tomatoes dataset with a batch size of 1.  Different levels of Gaussian noise (\u03c3) were added to the gradients, and the ROUGE-1 and ROUGE-2 scores, which measure the quality of the reconstructed text, were recorded for each noise level.  The results show how the effectiveness of the DAGER attack decreases as the level of noise increases.", "section": "Experimental Evaluation"}, {"figure_path": "CrADAX7h23/tables/tables_22_2.jpg", "caption": "Table 11: Miscallaneous experiments, referenced in the evaluation section. We applied DAGER on the Rotten Tomatoes dataset for B = 16, if not specified otherwise.", "description": "This table presents results from several supplementary experiments to further illustrate DAGER's versatility and robustness.  It shows the performance of DAGER under different model sizes (LLaMa-3 70B and LLaMa-3.1 8B), different loss functions (Frobenius norm loss and the standard cross-entropy loss), different activation functions (ReLU activation), and with LoRA (Low-Rank Adaptation) finetuning. The results demonstrate near-perfect reconstruction across various settings and modifications. This highlights the effectiveness of DAGER across different model architectures and fine-tuning methods.", "section": "6 Experimental Evaluation"}]