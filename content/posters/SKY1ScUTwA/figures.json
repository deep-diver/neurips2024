[{"figure_path": "SKY1ScUTwA/figures/figures_4_1.jpg", "caption": "Figure 1: Visualization of the distance and feature functions, learned on Mutagenicity. As the features are binary, the feature functions are evaluated only on the value 1. These plots provide an exact description of the functions' signal processing and a global explanation of how the model uses the distances and features.", "description": "This figure visualizes the learned distance and feature functions of a GNAN model trained on the Mutagenicity dataset.  The left panel shows the distance function, illustrating how the model weighs the influence of nodes based on their distance from a given node. The right panel displays the feature functions for each atom type, indicating their individual contribution to the model's predictions. Because the features are binary (0 or 1), the feature functions are only shown for the value 1.  Together, these plots provide a complete and interpretable representation of the model's inner workings.", "section": "4 Inteligibility"}, {"figure_path": "SKY1ScUTwA/figures/figures_6_1.jpg", "caption": "Figure 1: Visualization of the distance and feature functions, learned on Mutagenicity. As the features are binary, the feature functions are evaluated only on the value 1. These plots provide an exact description of the functions' signal processing and a global explanation of how the model uses the distances and features.", "description": "This figure visualizes the distance and feature functions learned by the GNAN model on the Mutagenicity dataset. The left panel shows the distance function (p), illustrating how the distance between atoms influences the model's prediction. Since the features are binary (0 or 1), the right panel displays the feature functions (fk) only for the value 1, showing the impact of each atom type on the mutagenicity prediction.  The plots together provide a complete, global view of how the model integrates distance and feature information for predictions.", "section": "4 Inteligibility"}, {"figure_path": "SKY1ScUTwA/figures/figures_6_2.jpg", "caption": "Figure 3: Visualization of the distance shape function learned on the PubMed dataset. As the output of the function is of dimension three, we plot it as three shape functions, one for each class. We plot them on the same figure to compare them. The shape functions show that the model uses only the local neighborhood of each node. It also shows a difference between the classes; while for type 2 diabetes, the longer the distance, the less their information is used (converges to 0), for type 1 and gestational diabetes, nodes of long-distance have a negative effect.", "description": "This figure visualizes the distance shape function learned by the GNAN model on the PubMed dataset.  Because the model predicts three classes (Type 1, Type 2, and Gestational diabetes), three separate functions are shown, one for each class. The plot reveals that the model primarily uses information from nodes within a short distance; the influence decreases as the distance increases.  A key observation is the difference in how distance affects the three classes: for Type 2 diabetes, the effect diminishes to almost zero at longer distances, while for Type 1 and Gestational diabetes, more distant nodes have a negative influence.", "section": "4 Inteligibility"}, {"figure_path": "SKY1ScUTwA/figures/figures_7_1.jpg", "caption": "Figure 1: Visualization of the distance and feature functions, learned on Mutagenicity. As the features are binary, the feature functions are evaluated only on the value 1. These plots provide an exact description of the functions' signal processing and a global explanation of how the model uses the distances and features.", "description": "The figure visualizes the learned distance and feature functions of a GNAN model trained on the Mutagenicity dataset.  The left panel shows the distance function, illustrating how the model weights the influence of nodes based on their distance from a given node. The right panel displays the feature functions, showing the relationship between each atom type (feature) and the model's prediction. Because features are binary, only the function output for the value '1' is shown. Together, these plots offer a complete, visual explanation of the model's behavior, demonstrating the global interpretability of GNAN.", "section": "4 Inteligibility"}, {"figure_path": "SKY1ScUTwA/figures/figures_7_2.jpg", "caption": "Figure 3: Visualization of the distance shape function learned on the PubMed dataset. As the output of the function is of dimension three, we plot it as three shape functions, one for each class. We plot them on the same figure to compare them. The shape functions show that the model uses only the local neighborhood of each node. It also shows a difference between the classes; while for type 2 diabetes, the longer the distance, the less their information is used (converges to 0), for type 1 and gestational diabetes, nodes of long-distance have a negative effect.", "description": "This figure visualizes the distance shape functions learned by the GNAN model on the PubMed dataset for the three different diabetes types.  It shows how the model weighs the importance of information from different distances of nodes. The plots reveal that the model primarily utilizes information from nearby nodes and that the influence of distant nodes diminishes, especially for type 2 diabetes.  Type 1 and gestational diabetes show a different pattern, where distant nodes have a negative influence.", "section": "4 Inteligibility"}, {"figure_path": "SKY1ScUTwA/figures/figures_8_1.jpg", "caption": "Figure 6: Local explanations of two molecules from the Mutagenicity datasets, through visualizations of the molecules. The area of each atom corresponds to the node importance according to Equation 3.", "description": "This figure provides local explanations for two molecules from the Mutagenicity dataset. Each molecule is represented as a graph where nodes are atoms and edges are bonds. The size of each node is proportional to its importance in the model's prediction, calculated using Equation 3.  The figure highlights the crucial substructures contributing to the model's classification of each molecule as mutagenic.  In (a), a carbon ring is highlighted, and in (b), a NO2 subgraph is highlighted, showcasing known mutagenic features.  These visualizations demonstrate GNAN's ability to provide easily interpretable local explanations, aligning with prior biological knowledge.", "section": "4 Inteligibility"}, {"figure_path": "SKY1ScUTwA/figures/figures_15_1.jpg", "caption": "Figure 1: Visualization of the distance and feature functions, learned on Mutagenicity. As the features are binary, the feature functions are evaluated only on the value 1. These plots provide an exact description of the functions' signal processing and a global explanation of how the model uses the distances and features.", "description": "The figure visualizes the learned distance and feature functions of a GNAN model trained on the Mutagenicity dataset.  The left plot shows the distance function (p), illustrating how the model weighs the influence of nodes based on their distance from a target node. The right plot displays the feature functions (fk), demonstrating the relationship between each feature and the target variable. The visualizations offer a global interpretation of the model's inner workings, showing how it leverages both distance and feature information.", "section": "4 Inteligibility"}, {"figure_path": "SKY1ScUTwA/figures/figures_16_1.jpg", "caption": "Figure 8: Visualization of the products between the outputs of the 'fat' feature function over the input range [0, 1] and the outputs of the distance function, learned over the PubMed dataset.", "description": "This figure visualizes the interaction between the 'fat' feature and distance in predicting the three types of diabetes.  The heatmaps show how the importance of the 'fat' feature changes with distance for each diabetes type. Warmer colors (red/green) indicate stronger positive/negative contribution to the prediction for each diabetes type. This allows for a detailed understanding of how the model utilizes the feature across different distances and how this impacts its classification of the diabetes types.", "section": "4 Inteligibility"}, {"figure_path": "SKY1ScUTwA/figures/figures_16_2.jpg", "caption": "Figure 3: Visualization of the distance shape function learned on the PubMed dataset. As the output of the function is of dimension three, we plot it as three shape functions, one for each class. We plot them on the same figure to compare them. The shape functions show that the model uses only the local neighborhood of each node. It also shows a difference between the classes; while for type 2 diabetes, the longer the distance, the less their information is used (converges to 0), for type 1 and gestational diabetes, nodes of long-distance have a negative effect.", "description": "This figure visualizes the distance shape functions learned by the GNAN model for the PubMed dataset. Because there are three classes (type 1 diabetes, type 2 diabetes, and gestational diabetes), the output of the distance function is three-dimensional.  The plot shows each of the three shape functions, facilitating a direct comparison. Notably, the functions indicate that the model primarily utilizes information from the local neighborhood of each node. Furthermore, the model's behavior differs across the three classes: for type 2 diabetes, the influence diminishes as the distance increases, ultimately approaching zero; however, for type 1 and gestational diabetes, there is a negative effect with increasing distance.", "section": "4 Inteligibility"}, {"figure_path": "SKY1ScUTwA/figures/figures_16_3.jpg", "caption": "Figure 10: Visualization of the feature functions learned over the Tolokers dataset.", "description": "The figure visualizes the learned shape functions for nine features in the Tolokers dataset. Each line represents a different feature's shape function, showing its non-linear relationship with the prediction. The x-axis represents the feature value, ranging from 0 to 1, and the y-axis shows the feature function output. The plot reveals how each feature contributes to the model's prediction, illustrating non-monotonic relationships for some features.", "section": "4 Inteligibility"}, {"figure_path": "SKY1ScUTwA/figures/figures_17_1.jpg", "caption": "Figure 11: Visualization of the distance shape function learned on the Tolokers dataset.", "description": "This figure shows the distance shape function learned by the GNAN model on the Tolokers dataset. The x-axis represents the distance between nodes in the graph, and the y-axis represents the output of the distance function.  The plot shows how the model weighs the influence of nodes based on their distance. We can see that the model gives more weight to nodes that are closer, and less weight to nodes that are farther away. The shape of the function suggests that the model is able to learn complex relationships between nodes based on their distance.", "section": "4 Inteligibility"}, {"figure_path": "SKY1ScUTwA/figures/figures_17_2.jpg", "caption": "Figure 2: Visualization of products of the outputs of the distance function and the feature functions, trained on Mutagenicity. Each cell shows the exact contribution, positive or negative, of features at a certain distance to the prediction. Positive values (green) contribute to classifying a molecule as mutagenic, and negative values (red) contribute to classifying a molecule as non-mutagenic.", "description": "This heatmap visualizes the interaction between features and their distances from a node in the Mutagenicity dataset.  The color of each cell represents the combined influence of a specific feature at a specific distance on the model's prediction. Green indicates a positive contribution (increasing mutagenicity), while red shows a negative contribution (decreasing mutagenicity).  This allows for a detailed understanding of how the model integrates both local feature information and the graph structure to make predictions.", "section": "4 Inteligibility"}, {"figure_path": "SKY1ScUTwA/figures/figures_18_1.jpg", "caption": "Figure 2: Visualization of products of the outputs of the distance function and the feature functions, trained on Mutagenicity. Each cell shows the exact contribution, positive or negative, of features at a certain distance to the prediction. Positive values (green) contribute to classifying a molecule as mutagenic, and negative values (red) contribute to classifying a molecule as non-mutagenic.", "description": "This heatmap visualizes the interplay between the distance and feature functions in the GNAN model trained on the Mutagenicity dataset. Each cell represents the combined effect of a specific feature at a particular distance on the model's prediction.  Positive values (green) indicate a contribution towards classifying a molecule as mutagenic, while negative values (red) suggest a contribution towards classifying it as non-mutagenic. The heatmap provides insight into how the model integrates both local features and the graph structure to make predictions.", "section": "4 Inteligibility"}]