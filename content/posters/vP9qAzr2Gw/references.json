{"references": [{"fullname_first_author": "Uri Alon", "paper_title": "On the bottleneck of graph neural networks and its practical implications", "publication_date": "2021-05-03", "reason": "This paper discusses the limitations of graph neural networks, providing a theoretical foundation for the superiority of graph transformers which are the basis for the current work."}, {"fullname_first_author": "Vijay Prakash Dwivedi", "paper_title": "A Generalization of Transformer Networks to Graphs", "publication_date": "2020-12-17", "reason": "This paper introduces graph transformers, which are central to the approach taken in the current work."}, {"fullname_first_author": "Devin Kreuzer", "paper_title": "Rethinking Graph Transformers with Spectral Attention", "publication_date": "2021-06-21", "reason": "This paper explores the use of spectral attention in graph transformers, which is a crucial element of the current work's method."}, {"fullname_first_author": "Jiaxuan You", "paper_title": "ROLAND: Graph Learning Framework for Dynamic Graphs", "publication_date": "2022-08-15", "reason": "This paper proposes a generic framework for dynamic graph learning, serving as a strong baseline for the current work's experimental evaluation."}, {"fullname_first_author": "Le Yu", "paper_title": "Towards better dynamic graph learning: New architecture and unified library", "publication_date": "2023-06-27", "reason": "This paper presents an improved dynamic graph learning architecture, offering a comparative analysis for the methods proposed in the current work."}]}