[{"figure_path": "5bR2l1b2eh/figures/figures_1_1.jpg", "caption": "Figure 1: Contextual sparse models struggle at challenging text generation tests that require high-level reasoning and understanding, e.g. GSM8K. On these tasks, contextually sparse models lead to significant quality degradation. In (a), we contrast CS Llama-3-8B-Instruct on GSM8K (green) and CNN DailyMail (coral). (b) Contextual Sparsity Llama-3-70B-Instruct crashes at 50% global sparsity, making the smaller dense model Llama-3-8B-Instruct (green star) a significantly more efficient choice than the sparse 70B model. (c) Sparse model crashing at reasoning tasks has patterns, and ideally only correcting 11% unlikely tokens recovers the sparse model performance fully.", "description": "This figure shows the limitations of contextual sparsity in complex reasoning tasks.  Panel (a) compares the performance of a contextual sparsity model on tasks requiring prompt understanding (CNN/DailyMail) versus those requiring reasoning (GSM8K), revealing significantly worse performance on the latter. Panel (b) illustrates that applying contextual sparsity to a larger model (Llama-3-70B-Instruct) leads to model crashes at higher sparsity levels, highlighting the inefficiency of this approach for complex tasks. Finally, panel (c) suggests that sparse model failures are not random; by correcting a small percentage (11%) of tokens, the model's performance can be restored to that of the full model. This observation motivates the development of a correction mechanism.", "section": "Observations"}, {"figure_path": "5bR2l1b2eh/figures/figures_2_1.jpg", "caption": "Figure 2: Overview of Sirius. Contextual Sparsity requires full model weights to be placed on the GPU memory. While the sparse model doesn't perform well on complex reasoning tasks, Sirius uses the Full Model to correct the Sparse model. The full model is called fairly infrequently. During the correction, the Full Model will rewrite the KV Cache, interleave with high-quality tokens to the sparse outputs, and then roll back only when the token is deemed extremely unlikely by the Full Model.", "description": "This figure illustrates the SIRIUS framework for correcting errors in contextual sparsity models.  The sparse model generates text, but if errors occur, the full model is called infrequently to correct those errors. The correction process involves rewriting the key-value (KV) cache, interleaving high-quality tokens with the sparse model's output, and rolling back corrections only if the full model deems them unlikely.", "section": "4 Methods"}, {"figure_path": "5bR2l1b2eh/figures/figures_4_1.jpg", "caption": "Figure 1: Contextual sparse models struggle at challenging text generation tests that require high-level reasoning and understanding, e.g. GSM8K. On these tasks, contextually sparse models lead to significant quality degradation. In (a), we contrast CS Llama-3-8B-Instruct on GSM8K (green) and CNN DailyMail (coral). (b) Contextual Sparsity Llama-3-70B-Instruct crashes at 50% global sparsity, making the smaller dense model Llama-3-8B-Instruct (green star) a significantly more efficient choice than the sparse 70B model. (c) Sparse model crashing at reasoning tasks has patterns, and ideally only correcting 11% unlikely tokens recovers the sparse model performance fully.", "description": "This figure compares the performance of contextual sparse models against full models on different tasks.  Panel (a) shows that contextual sparsity (CS) performs worse on GSM8K (arithmetic reasoning) than on CNN DailyMail (text summarization), highlighting a weakness of CS for complex reasoning tasks. Panel (b) demonstrates that increasing the model size (from Llama-3-8B to Llama-3-70B) while applying CS does not necessarily improve performance and can lead to model crashes.  Panel (c) reveals that surprisingly, correcting only a small fraction (11%) of the sparse model's outputs can fully restore performance, suggesting a potential for efficient correction mechanisms.", "section": "Observations"}, {"figure_path": "5bR2l1b2eh/figures/figures_6_1.jpg", "caption": "Figure 1: Contextual sparse models struggle at challenging text generation tests that require high-level reasoning and understanding, e.g., GSM8K. On these tasks, contextually sparse models lead to significant quality degradation. In (a), we contrast CS Llama-3-8B-Instruct on GSM8K (green) and CNN DailyMail (coral). (b) Contextual Sparsity Llama-3-70B-Instruct crashes at 50% global sparsity, making the smaller dense model Llama-3-8B-Instruct (green star) a significantly more efficient choice than the sparse 70B model. (c) Sparse model crashing at reasoning tasks has patterns, and ideally only correcting 11% unlikely tokens recovers the sparse model performance fully.", "description": "This figure demonstrates the challenges of contextual sparsity (CS) in complex reasoning tasks.  Subfigure (a) compares the performance of a contextually sparse Llama-3-8B-Instruct model on GSM8K (a challenging arithmetic reasoning benchmark) and CNN/DailyMail (a relatively easier text summarization task).  Subfigure (b) shows that applying contextual sparsity to a larger model (Llama-3-70B-Instruct) leads to model failure at high sparsity levels, highlighting the inefficiency of CS for large models on demanding tasks.  Finally, subfigure (c) suggests that the failures are not random; correcting a small fraction (around 11%) of tokens in the sparse model's output is sufficient to recover its performance to that of the full model.", "section": "Observations"}, {"figure_path": "5bR2l1b2eh/figures/figures_13_1.jpg", "caption": "Figure 1: Contextual sparse models struggle at challenging text generation tests that require high-level reasoning and understanding, e.g. GSM8K. On these tasks, contextually sparse models lead to significant quality degradation. In (a), we contrast CS Llama-3-8B-Instruct on GSM8K (green) and CNN DailyMail (coral). (b) Contextual Sparsity Llama-3-70B-Instruct crashes at 50% global sparsity, making the smaller dense model Llama-3-8B-Instruct (green star) a significantly more efficient choice than the sparse 70B model. (c) Sparse model crashing at reasoning tasks has patterns, and ideally only correcting 11% unlikely tokens recovers the sparse model performance fully.", "description": "This figure demonstrates the challenges of using contextual sparsity (CS) in large language models (LLMs) for complex reasoning tasks.  Subfigure (a) compares the performance of a contextually sparse model on two different tasks:  text summarization (CNN/DailyMail) and arithmetic reasoning (GSM8K). The results show that CS significantly degrades performance on the reasoning task (GSM8K). Subfigure (b) shows that increasing the model size (70B vs 8B) does not alleviate this performance degradation and may even exacerbate it. Subfigure (c) illustrates that the performance of sparse models can often be recovered by correcting a relatively small percentage of tokens.", "section": "Observations"}, {"figure_path": "5bR2l1b2eh/figures/figures_14_1.jpg", "caption": "Figure 1: Contextual sparse models struggle at challenging text generation tests that require high-level reasoning and understanding, e.g. GSM8K. On these tasks, contextually sparse models lead to significant quality degradation. In (a), we contrast CS Llama-3-8B-Instruct on GSM8K (green) and CNN DailyMail (coral). (b) Contextual Sparsity Llama-3-70B-Instruct crashes at 50% global sparsity, making the smaller dense model Llama-3-8B-Instruct (green star) a significantly more efficient choice than the sparse 70B model. (c) Sparse model crashing at reasoning tasks has patterns, and ideally only correcting 11% unlikely tokens recovers the sparse model performance fully.", "description": "This figure shows the limitations of contextual sparsity (CS) in complex reasoning tasks. Subfigure (a) compares the performance of CS models on two tasks: text summarization (CNN/DailyMail) and arithmetic reasoning (GSM8K).  CS models perform well on summarization but poorly on reasoning. Subfigure (b) shows that increasing the size of the model with CS does not improve the results for complex reasoning tasks. Subfigure (c) demonstrates that surprisingly few token corrections are needed to recover full performance on reasoning tasks from CS models. This illustrates the potential of using a correction mechanism to boost the performance of CS models. ", "section": "Observations"}, {"figure_path": "5bR2l1b2eh/figures/figures_15_1.jpg", "caption": "Figure 1: Contextual sparse models struggle at challenging text generation tests that require high-level reasoning and understanding, e.g. GSM8K. On these tasks, contextually sparse models lead to significant quality degradation. In (a), we contrast CS Llama-3-8B-Instruct on GSM8K (green) and CNN DailyMail (coral). (b) Contextual Sparsity Llama-3-70B-Instruct crashes at 50% global sparsity, making the smaller dense model Llama-3-8B-Instruct (green star) a significantly more efficient choice than the sparse 70B model. (c) Sparse model crashing at reasoning tasks has patterns, and ideally only correcting 11% unlikely tokens recovers the sparse model performance fully.", "description": "This figure shows the limitations of contextual sparsity (CS) in complex reasoning tasks.  Subfigure (a) compares the performance of a contextually sparse model on two different tasks: CNN/DailyMail (a summarization task) and GSM8K (an arithmetic reasoning task). It demonstrates that while CS performs reasonably well on the summarization task, it significantly degrades performance on the reasoning task. Subfigure (b) shows that applying CS to a larger model (Llama-3-70B-Instruct) leads to a performance crash at a 50% sparsity level, highlighting the inefficiency of CS for complex tasks when applied to large models. Finally, subfigure (c) illustrates that even with significant sparsity, surprisingly few tokens need correction to recover the original performance of the model.", "section": "Observations"}, {"figure_path": "5bR2l1b2eh/figures/figures_15_2.jpg", "caption": "Figure 9: Illustration of Tree Building Process.", "description": "This figure illustrates the tree building process used in SIRIUS.  The process starts with a token from the full model. Each node then generates multiple possible next tokens (children), forming a tree structure where the number of branches at each level is controlled by the treewidth parameter.  The likelihood of each path is calculated, and the top-k most likely paths are kept while others are discarded. This process is repeated until the stopping criteria is met, resulting in a set of corrected output tokens.", "section": "4.2 How to Correct the Sparse Output Tokens"}, {"figure_path": "5bR2l1b2eh/figures/figures_18_1.jpg", "caption": "Figure 1: Contextual sparse models struggle at challenging text generation tests that require high-level reasoning and understanding, e.g., GSM8K. On these tasks, contextually sparse models lead to significant quality degradation. In (a), we contrast CS Llama-3-8B-Instruct on GSM8K (green) and CNN DailyMail (coral). (b) Contextual Sparsity Llama-3-70B-Instruct crashes at 50% global sparsity, making the smaller dense model Llama-3-8B-Instruct (green star) a significantly more efficient choice than the sparse 70B model. (c) Sparse model crashing at reasoning tasks has patterns, and ideally only correcting 11% unlikely tokens recovers the sparse model performance fully.", "description": "This figure demonstrates the challenges of using contextual sparsity (CS) in large language models (LLMs), especially for complex reasoning tasks.  Subfigure (a) compares the performance of a contextually sparse model on two tasks:  the CNN/DailyMail summarization task and the GSM8K arithmetic reasoning task.  It shows that while CS performs relatively well on summarization, its performance degrades significantly on the more complex reasoning task. Subfigure (b) illustrates that applying CS to a larger model (Llama-3-70B-Instruct) leads to model failure at higher sparsity levels.  Finally, subfigure (c) indicates that correcting a small fraction (11%) of tokens in a sparse model is sufficient to recover the original model's performance, suggesting that an efficient correction mechanism could significantly improve the performance of CS methods.", "section": "Observations"}]