[{"figure_path": "o9Lkiv1qpc/figures/figures_1_1.jpg", "caption": "Figure 1: The issue of existing I2V-DMs. Regardless of input motion scores (Input MS), the output motion scores (Output MS) are consistently lower than expected. In contrast, our method yields output motion scores either higher or lower than Input MS with reduced error.", "description": "This figure shows a comparison of motion scores between existing image-to-video diffusion models (I2V-DMs) and the proposed method.  The input motion score (Input MS) represents the motion content of the input video. The output motion score (Output MS) is the motion content of the video generated by the model.  Existing I2V-DMs consistently produce videos with lower motion scores than expected, regardless of the input motion score. The proposed method, however, generates videos with motion scores that are more accurately aligned with the Input MS, showing improved motion control.", "section": "1 Introduction"}, {"figure_path": "o9Lkiv1qpc/figures/figures_2_1.jpg", "caption": "Figure 2: Identifying conditional image leakage. As time step progresses, the noisy input becomes heavily corrupted, whereas the conditional image retains considerable detail from GT. This biases the model to over-rely on the conditional image at large t, resulting in videos with less motion than GT.", "description": "This figure illustrates the phenomenon of conditional image leakage in image-to-video diffusion models.  As the diffusion process advances (time step increases), the noisy input representing motion information gets increasingly corrupted. However, the conditional image (the input image guiding the video generation) retains a lot of detail about the target video. This causes the model to heavily rely on the conditional image, ignoring the increasingly noisy input. As a consequence, the resulting video has significantly less motion than expected, which is the effect of conditional image leakage.", "section": "3.1 Identifying Conditional Image Leakage in Image-to-video Diffusion Models"}, {"figure_path": "o9Lkiv1qpc/figures/figures_3_1.jpg", "caption": "Figure 3: Benefits of Analytic-Init. (a) An early start time M enhances motion but a too-small M degrades visual quality due to the training-inference gap, which Analytic-Init helps to reduce. (b) Analytic-Init produces higher motion scores with lower errors, mitigating conditional image leakage.", "description": "This figure shows the benefits of using Analytic-Init, a method proposed in the paper to improve image-to-video generation.  The left panel (a) demonstrates that starting the generation process from an earlier time step (M) increases motion, but excessively early start times reduce image quality due to a training-inference gap.  Analytic-Init bridges this gap, improving image quality even when starting early. The right panel (b) quantitatively shows how Analytic-Init reduces the error in motion scores, indicating a reduction in conditional image leakage.", "section": "3.2 Solving Conditional Image Leakage in Image-to-video Diffusion Models"}, {"figure_path": "o9Lkiv1qpc/figures/figures_4_1.jpg", "caption": "Figure 4: Visualization of TimeNoise and the impact of tuning its hyperparameters. (a) The designed pt(Bs) favors high noise levels at large t, gradually shifting to lower noise levels as t decreases. This is achieved by (b) \u03bc(t) increasing monotonically with t. Finally, (c) modifying a and Bm enables a trade-off between dynamic motion and image alignment.", "description": "This figure visualizes the TimeNoise, a time-dependent noise distribution, and its hyperparameters' impact on video generation.  Panel (a) shows the probability density function of the noise distribution, demonstrating its ability to favor high noise levels at larger time steps (t) and gradually decrease noise levels as time progresses. Panel (b) illustrates how the center (\u00b5(t)) of the distribution monotonically increases with time, further highlighting the time-dependent nature. Lastly, panel (c) shows the effect of tuning hyperparameters 'a' and 'Bm' on a balance between increasing video motion and maintaining image alignment, indicating a trade-off where higher noise levels can lead to more motion but potentially less accurate image alignment.", "section": "3.2 Solving Conditional Image Leakage in Image-to-video Diffusion Models"}, {"figure_path": "o9Lkiv1qpc/figures/figures_4_2.jpg", "caption": "Figure 4: Visualization of TimeNoise and the impact of tuning its hyperparameters. (a) The designed pt(Bs) favors high noise levels at large t, gradually shifting to lower noise levels as t decreases. This is achieved by (b) \u03bc(t) increasing monotonically with t. Finally, (c) modifying a and Bm enables a trade-off between dynamic motion and image alignment.", "description": "This figure visualizes the TimeNoise and its hyperparameters. Subfigure (a) shows the time-dependent noise distribution pt(Bs), which favors high noise levels at large t and gradually shifts to lower noise levels as t decreases. Subfigure (b) illustrates the monotonically increasing behavior of \u03bc(t), the distribution center. Subfigure (c) demonstrates the impact of tuning hyperparameters \u03b1 and \u03b2m on the trade-off between dynamic motion and image alignment.", "section": "3.2 Solving Conditional Image Leakage in Image-to-video Diffusion Models"}, {"figure_path": "o9Lkiv1qpc/figures/figures_4_3.jpg", "caption": "Figure 4: Visualization of TimeNoise and the impact of tuning its hyperparameters. (a) The designed pt(Bs) favors high noise levels at large t, gradually shifting to lower noise levels as t decreases. This is achieved by (b) \u03bc(t) increasing monotonically with t. Finally, (c) modifying a and Bm enables a trade-off between dynamic motion and image alignment.", "description": "This figure visualizes the TimeNoise distribution and its hyperparameters' effects.  Panel (a) shows how the probability density of the time-dependent noise (pt(Bs)) changes across different time steps (t), favoring higher noise levels at later steps and gradually reducing noise levels as the generation progresses. Panel (b) illustrates how the distribution center (\u03bc(t)) changes monotonically over time, allowing for flexible control of the noise level.  Panel (c) demonstrates the impact of tuning hyperparameters 'a' (influencing the shape of \u03bc(t)) and 'Bm' (maximum noise) on the balance between motion and image alignment. Higher noise levels enhance motion but can reduce image alignment.", "section": "3.2 Solving Conditional Image Leakage in Image-to-video Diffusion Models"}, {"figure_path": "o9Lkiv1qpc/figures/figures_5_1.jpg", "caption": "Figure 5: Benefits of TimeNoise. TimeNoise (a) generates Xt\u21920 that maintains motion dynamics comparable to the GT across all time steps, and (b) achieves higher motion scores with lower errors, effectively reducing conditional image leakage.", "description": "This figure demonstrates the effectiveness of the proposed TimeNoise method in mitigating conditional image leakage.  (a) shows that one-step predictions from noisy inputs using TimeNoise maintain motion comparable to ground truth across different time steps. This contrasts with previous methods which show a reduction in motion at later time steps. (b) quantifies the improvement showing higher motion scores and lower errors with TimeNoise compared to a baseline.", "section": "3.2 Solving Conditional Image Leakage in Image-to-video Diffusion Models"}, {"figure_path": "o9Lkiv1qpc/figures/figures_5_2.jpg", "caption": "Figure 1: The issue of existing I2V-DMs. Regardless of input motion scores (Input MS), the output motion scores (Output MS) are consistently lower than expected. In contrast, our method yields output motion scores either higher or lower than Input MS with reduced error.", "description": "This figure shows a comparison of motion scores between existing image-to-video diffusion models (I2V-DMs) and the proposed method. The x-axis represents the input motion scores, and the y-axis represents the difference between the output and input motion scores.  Existing I2V-DMs consistently produce lower output motion scores than expected, regardless of the input motion score. In contrast, the proposed method's output motion scores are more variable, sometimes higher and sometimes lower than expected, but always with a smaller error. This indicates that the proposed method addresses the issue of conditional image leakage, allowing for more accurate motion control.", "section": "1 Introduction"}, {"figure_path": "o9Lkiv1qpc/figures/figures_6_1.jpg", "caption": "Figure 6: Understanding exiting work from conditional image leakage. I2VGen-XL [69] and VideoCrafter1 [12] mitigates the leakage at the expense of image alignment. The SVD produces videos with camera movements while keeping objects relatively static to meet high motion scores, while ours generates videos that feature both natural and dynamic object movements.", "description": "This figure compares the results of several image-to-video generation models, including I2VGen-XL, VideoCrafter1, SVD, and the authors' proposed method.  It demonstrates how the authors' method addresses the issue of conditional image leakage, which causes existing models to generate videos with less motion than expected.  The comparison highlights that while other methods either compromise image alignment or produce unrealistic motion (static objects with camera movements), the proposed method generates videos with both natural object movements and dynamic camera movements.", "section": "3.3 Understanding Existing Work from Conditional Image Leakage"}, {"figure_path": "o9Lkiv1qpc/figures/figures_7_1.jpg", "caption": "Figure 7: Qualitative results of TimeNoise and Analytic-Init applied to various I2V-DMs. Ours significantly enhances video dynamism while maintaining image alignment and temporal consistency. VC. and DC. denote VideoCrafter1 [12] and DynamiCrafter [63] respectively.", "description": "This figure shows the qualitative results of applying TimeNoise and Analytic-Init to different image-to-video diffusion models (I2V-DMs).  It compares the results of baseline models with those enhanced by the proposed methods.  The figure demonstrates that the proposed methods improve the dynamism of generated videos while preserving image alignment and temporal consistency.", "section": "4 Experiments"}, {"figure_path": "o9Lkiv1qpc/figures/figures_9_1.jpg", "caption": "Figure 6: Understanding exiting work from conditional image leakage. I2VGen-XL [69] and VideoCrafter1 [12] mitigates the leakage at the expense of image alignment. The SVD produces videos with camera movements while keeping objects relatively static to meet high motion scores, while ours generates videos that feature both natural and dynamic object movements.", "description": "This figure compares the results of three different image-to-video generation models (I2VGen-XL, VideoCrafter1, and the authors' model) in terms of their ability to generate videos with dynamic object movement while maintaining image alignment.  I2VGen-XL and VideoCrafter1 show some mitigation of conditional image leakage, but at a cost of reduced image alignment. SVD, on the other hand, prioritizes generating videos with high motion scores but often does so by creating camera movement and largely stationary objects, rather than more natural dynamic object movement. The authors' method is presented as achieving both natural and dynamic movement with good image alignment.", "section": "3.3 Understanding Existing Work from Conditional Image Leakage"}, {"figure_path": "o9Lkiv1qpc/figures/figures_18_1.jpg", "caption": "Figure 9: The qualitative comparison between our TimeNoise and baselines mentioned in Sec. 3.2. The constant results in poor image alignment, while the CDM [25] shows low motion. Ours achieves the best visual quality.", "description": "This figure compares the visual quality of videos generated by four different methods: a baseline method, a method using a constant noise level, a method using CDM (Conditional Diffusion Model), and the proposed method (TimeNoise).  The conditional image shows a kitten approaching a bowl. The baseline method produces a video with a blurry kitten and some artifacts. The constant noise method produces a slightly better result but still has some blurriness. CDM produces a video with acceptable image quality but less motion. The proposed method (TimeNoise) produces a video with sharp details, good motion, and the best overall visual quality.", "section": "4.2 Results"}, {"figure_path": "o9Lkiv1qpc/figures/figures_18_2.jpg", "caption": "Figure 10: Adjusting the noise schedule towards more noise further exacerbate conditional image leakage.", "description": "This figure shows that increasing noise levels (by adjusting the noise schedule towards more noise) in the process of video generation leads to a greater over-reliance on the conditional image by the model. This, in turn, results in generated videos that lack dynamic motion and therefore worsen the issue of conditional image leakage.", "section": "3.2 Solving Conditional Image Leakage in Image-to-video Diffusion Models"}, {"figure_path": "o9Lkiv1qpc/figures/figures_18_3.jpg", "caption": "Figure 6: Understanding exiting work from conditional image leakage. I2VGen-XL [69] and VideoCrafter1 [12] mitigates the leakage at the expense of image alignment. The SVD produces videos with camera movements while keeping objects relatively static to meet high motion scores, while ours generates videos that feature both natural and dynamic object movements.", "description": "This figure compares the results of three different image-to-video generation models. The first two, I2VGen-XL and VideoCrafter1, reduce conditional image leakage but at the cost of reducing image alignment in the generated videos. The third model, the authors' proposed method, achieves both high motion scores and natural, dynamic object movements.", "section": "3.3 Understanding Existing Work from Conditional Image Leakage"}, {"figure_path": "o9Lkiv1qpc/figures/figures_19_1.jpg", "caption": "Figure 7: Qualitative results of TimeNoise and Analytic-Init applied to various I2V-DMs. Ours significantly enhances video dynamism while maintaining image alignment and temporal consistency. VC. and DC. denote VideoCrafter1 [12] and DynamiCrafter [63] respectively.", "description": "This figure shows the qualitative results of applying the proposed TimeNoise and Analytic-Init methods to different image-to-video diffusion models (I2V-DMs).  It visually demonstrates that the proposed methods improve the dynamism of the generated videos while preserving the alignment of the images and consistency in the temporal aspects. The models compared are SVD, VideoCrafter1, and DynamiCrafter. The images show example video frames generated by different models.", "section": "4 Experiments"}, {"figure_path": "o9Lkiv1qpc/figures/figures_20_1.jpg", "caption": "Figure 2: Identifying conditional image leakage. As time step progresses, the noisy input becomes heavily corrupted, whereas the conditional image retains considerable detail from GT. This biases the model to over-rely on the conditional image at large t, resulting in videos with less motion than GT.", "description": "This figure demonstrates the phenomenon of conditional image leakage in image-to-video diffusion models. As the diffusion process progresses (time step t increases), the noisy input loses detail, whereas the conditional image retains substantial detail. This causes the model to over-rely on the conditional image, resulting in generated videos that lack motion compared to the ground truth.", "section": "3.1 Identifying Conditional Image Leakage in Image-to-video Diffusion Models"}]