[{"figure_path": "FoGwiFXzuN/figures/figures_1_1.jpg", "caption": "Figure 1: Illustration of the cycle task for n = 4 (left) and the complexity to learn it (right).", "description": "This figure illustrates the Cycle task used in the paper for evaluating the reasoning capabilities of Transformers.  The left panel shows two example graphs used in the binary classification task. Class 1 represents two disjoint cycles of length n, while Class 2 represents a single cycle of length 2n. The red squares highlight the pair of vertices whose connectivity is being predicted. The right panel shows the experimental results, illustrating the number of iterations required to achieve 95% accuracy in training GPT-2 style models with varying parameter sizes (10M, 25M, and 85M) as a function of the problem size (n). This demonstrates the exponential increase in learning difficulty as the problem size grows.", "section": "1.2 Hardness of long compositions"}, {"figure_path": "FoGwiFXzuN/figures/figures_1_2.jpg", "caption": "Figure 1: Illustration of the cycle task for n = 4 (left) and the complexity to learn it (right).", "description": "The figure consists of two subfigures. The left subfigure illustrates the cycle task for n=4, which is a binary classification problem to predict whether two given vertices are connected in a graph.  The graph can be one of two types: two disjoint cycles of length n or one cycle of length 2n.  The red squares in the illustration represent the two queried vertices. The right subfigure shows the number of iterations required by GPT2-style models with different sizes (10M, 25M, and 85M parameters) to achieve at least 95% accuracy on the cycle task as the problem size (n) increases. This illustrates the difficulty of learning this task efficiently as the size increases; the learning complexity increases exponentially with n.", "section": "Hardness of long compositions"}, {"figure_path": "FoGwiFXzuN/figures/figures_5_1.jpg", "caption": "Figure 2: The cycle task variant used in Theorem 1: the above example is stored as a_0>b_1;b_0>c_1;c_0>a_1;a_1>a_2;b_1>c_2;c_1>b_2;a_2>b_3;b_2>c_3;c_2>a_3;a_3>b_0;b_3>a_0;c_3>c_0;a_0?b_0?c_0", "description": "This figure depicts a variant of the cycle task used to prove Theorem 1 in the paper. The graph consists of a cycle of length 3n with probability 2/3 and 3 cycles of length n otherwise. Vertices are labeled a_i, b_i, c_i according to their distance from a set of three starting vertices (a_0, b_0, c_0), which are chosen randomly from the cycle.  The task is to determine whether a_0, b_0, and c_0 are in the same cycle or not, requiring the model to analyze the global structure of the graph.", "section": "2.3 Agnostic scratchpads cannot break the globality"}, {"figure_path": "FoGwiFXzuN/figures/figures_6_1.jpg", "caption": "Figure 3: An illustration showing how scratchpads can break the globality. The target may be efficiently learned if each scratchpad step is of low globality given the previous ones.", "description": "This figure illustrates the concept of educated scratchpads and how they can break the globality barrier in machine learning. The figure shows a sequence of intermediate targets (Y1, Y2, Y3) leading to the final target (Y4). Each step has a low globality, meaning that a small number of input tokens are sufficient to predict the next target in the sequence. By breaking down the complex task into simpler subtasks, the scratchpad helps the model learn more efficiently.", "section": "3 Scratchpads to break the globality"}, {"figure_path": "FoGwiFXzuN/figures/figures_7_1.jpg", "caption": "Figure 4: (Left) Learning the cycle task with a scratchpad. (Right) OOD generalization for the DFS and inductive scratchpads (see Section 3.2.1).", "description": "The left plot shows that using DFS or inductive scratchpad helps the model learn the cycle task easily as the size of the problem scales. The right plot shows that the DFS scratchpad fails to generalize out-of-distribution (OOD) while the inductive scratchpad generalizes to unseen data easily.", "section": "3 Scratchpads to break the globality"}, {"figure_path": "FoGwiFXzuN/figures/figures_7_2.jpg", "caption": "Figure 4: (Left) Learning the cycle task with a scratchpad. (Right) OOD generalization for the DFS and inductive scratchpads (see Section 3.2.1).", "description": "The figure on the left shows the learning curves for the cycle task with and without the DFS scratchpad. It demonstrates that using the DFS scratchpad significantly improves the learning performance. The figure on the right compares the in-distribution and out-of-distribution generalization performance of the DFS and inductive scratchpads. It highlights that while the DFS scratchpad performs well in-distribution, it fails to generalize out-of-distribution, unlike the inductive scratchpad which maintains good performance in both settings.", "section": "3 Scratchpads to break the globality"}, {"figure_path": "FoGwiFXzuN/figures/figures_9_1.jpg", "caption": "Figure 5: Length generalization for parity and addition tasks using different random seeds. The medians of the results are highlighted in bold.", "description": "This figure shows the length generalization results for parity and addition tasks.  The left subplot (a) displays the accuracy of the model on parity tasks with varying numbers of bits, demonstrating its ability to generalize to longer sequences than those seen during training (up to 55 bits). The right subplot (b) presents the accuracy for addition tasks, showcasing length generalization capabilities from 4 to 26 digits (using the shift method) and from 10 to 18 digits (using the random space method). The median accuracies are highlighted in bold for each task.  The results show the models ability to extrapolate beyond the training data. ", "section": "3.2 Inductive Scratchpads"}, {"figure_path": "FoGwiFXzuN/figures/figures_9_2.jpg", "caption": "Figure 5: Length generalization for parity and addition tasks using different random seeds. The medians of the results are highlighted in bold.", "description": "This figure shows the length generalization results for parity and addition tasks using two different inductive scratchpad methods. The x-axis represents the number of bits (for parity) or digits (for addition) in the input, while the y-axis shows the accuracy achieved by the model. Each line represents the results obtained with a different random seed, and the bold line indicates the median across all runs.  The figure demonstrates that the inductive scratchpad enables the model to generalize to significantly longer inputs (e.g., up to 55 bits for parity and 26 digits for addition) than those seen during training.", "section": "3.2.2 Inductive scratchpad: definition and experimental results"}, {"figure_path": "FoGwiFXzuN/figures/figures_21_1.jpg", "caption": "Figure 6: The average of the maximum and average distance in directed random graphs with n = 128 nodes and a varying number of edges.", "description": "This figure shows the average maximum distance and average distance between nodes in directed random graphs with 128 nodes. The number of edges varies along the x-axis, while the average distance is plotted on the y-axis. As the number of edges increases, both the average maximum distance and average distance decrease.  This illustrates the impact of graph density on connectivity; denser graphs lead to shorter average paths between nodes.", "section": "B.1 Implications on random graphs"}, {"figure_path": "FoGwiFXzuN/figures/figures_21_2.jpg", "caption": "Figure 7: Performance of a model trained on a balanced distribution of random graphs with 24 nodes and edges where with probability 0.5 the query nodes are not connected and with probability 0.5 they are connected and their distance is uniformly selected from 1, 2, 3, 4. The validation set has the same distribution as the training set showing that the model reaches around 80% accuracy on in-distribution samples. Particularly, the model has perfect accuracy on connected nodes (distance 1-4) and around 60% accuracy on the nodes that are not connected. However, when we tested the model on OOD samples (where some spurious correlations are not present) the model showed a chance level performance. Note that these samples would be of low complexity if the model was actually checking whether there exists a path or not.", "description": "This figure shows the performance of a model trained on random graphs with 24 nodes and edges. The model achieves high accuracy on the training data, but its performance drops significantly on out-of-distribution (OOD) data where spurious correlations are less present. This suggests that the model is not effectively composing syllogisms, but rather relying on low-level heuristics.", "section": "Hardness of long compositions"}, {"figure_path": "FoGwiFXzuN/figures/figures_23_1.jpg", "caption": "Figure 8: Accuracy for cycle tasks of varying sizes where a mixed distribution (left) and curriculum learning (right) have been used during training. It can be seen that using both a mixed distribution of samples with different difficulties and curriculum learning can reduce the learning time.", "description": "This figure shows the accuracy curves for training a model on the cycle task with samples of mixed difficulties (left) and curriculum learning (right).  The mixed distribution setting involves training on cycle tasks of sizes 2 through 7, each with equal probability.  In the curriculum learning setting, the model trains sequentially on tasks of increasing size, starting with the simplest (size 2) and proceeding to the most complex (size 7).  The results indicate that both the mixed distribution and curriculum learning approaches reduce the training time compared to training only on the most complex task (size 7).", "section": "3.2 Inductive Scratchpads"}, {"figure_path": "FoGwiFXzuN/figures/figures_23_2.jpg", "caption": "Figure 8: Accuracy for cycle tasks of varying sizes where a mixed distribution (left) and curriculum learning (right) have been used during training. It can be seen that using both a mixed distribution of samples with different difficulties and curriculum learning can reduce the learning time.", "description": "This figure shows the accuracy curves for different sizes of the cycle task (the number of nodes/edges in the graph). The left plot shows the results when the training samples come from a mixture of cycle tasks of different sizes.  The right plot shows the results when the training is done using curriculum learning (easier tasks are shown to the model first). The shaded areas represent confidence intervals. Both plots demonstrate that combining mixed difficulty samples and curriculum learning results in faster training convergence.", "section": "3.2 Inductive Scratchpads"}, {"figure_path": "FoGwiFXzuN/figures/figures_23_3.jpg", "caption": "Figure 8: Accuracy for cycle tasks of varying sizes where a mixed distribution (left) and curriculum learning (right) have been used during training. It can be seen that using both a mixed distribution of samples with different difficulties and curriculum learning can reduce the learning time.", "description": "This figure shows the results of two experiments on the cycle task, one using a mixed distribution of training samples and the other using curriculum learning.  In both, the model was trained on cycle tasks with varying lengths (n). The left plot shows that a mixed distribution of sample sizes helped the model learn faster. The right plot shows that curriculum learning, where the difficulty gradually increases during training, also resulted in faster learning.", "section": "3.2 Inductive Scratchpads"}, {"figure_path": "FoGwiFXzuN/figures/figures_23_4.jpg", "caption": "Figure 4: (Left) Learning the cycle task with a scratchpad. (Right) OOD generalization for the DFS and inductive scratchpads (see Section 3.2.1).", "description": "The figure shows two plots. The left plot shows the number of iterations needed to learn the cycle task with different sizes (n) using a model with a DFS scratchpad. It demonstrates that using the DFS scratchpad makes learning the cycle task significantly easier. The right plot presents the accuracy of the models with DFS and inductive scratchpads on in-distribution and out-of-distribution (OOD) samples. It shows that the inductive scratchpad generalizes better to OOD samples compared to the DFS scratchpad.", "section": "3 Scratchpads to break the globality"}, {"figure_path": "FoGwiFXzuN/figures/figures_24_1.jpg", "caption": "Figure 10: Learning the half-parity function (learning the parity of the first n/2 bits from the total n bits) for different numbers of bits using a scratchpad. It can be seen that the half-parity targets can be learned efficiently as the number of bits n grows. Note that the random seed of the experiment can cause some variation in the number of iterations required for learning the parity.", "description": "This figure shows the number of iterations required to learn the half-parity function for different numbers of total bits (n). The half-parity function is defined as the parity of the first n/2 bits.  The results demonstrate that using a scratchpad, the model efficiently learns the half-parity function as the number of bits increases.  However, there is some variation in the number of iterations due to the randomness introduced by the different random seeds used in the experiments. The shaded area in the plot shows the variability in the results across multiple trials.", "section": "B.3 Learning parities with scratchpad"}, {"figure_path": "FoGwiFXzuN/figures/figures_38_1.jpg", "caption": "Figure 11: For complexity n we have 3n + 2 people and there are n people between the two names we query (see example above). We found out that ChatGPT(3.5) can hardly go beyond the random baseline on this task even for n = 1 while GPT4 performs much better. However, if GPT4 does not use CoT reasoning, its performance would be near random for n > 1. Note that we used 1000 examples for each value of n.", "description": "This figure shows the accuracy of different GPT models (GPT-3.5-turbo-0125, GPT-4-turbo-2024-04-09 with and without chain-of-thought prompting) on a height comparison task. The x-axis represents the complexity of the task (n), and the y-axis represents the accuracy. The results indicate that GPT-4 performs significantly better than GPT-3.5, especially when chain-of-thought reasoning is used. Without chain-of-thought, GPT-4's performance drops to near random accuracy for n > 1.", "section": "I Experiments with ChatGPT"}]