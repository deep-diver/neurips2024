[{"figure_path": "XRNN9i1xpi/figures/figures_2_1.jpg", "caption": "Figure 1: Illustration of key concepts of CITRUS. a) Cartesian product between three-factor graphs. b) Continous product graph function (CITRUS) operating on the multidomain graph data U.", "description": "This figure illustrates the core concepts of the CITRUS model.  Panel (a) shows a Cartesian product graph, which is a graph formed by combining multiple factor graphs (in this case, three).  Each factor graph represents a different domain of data. Panel (b) demonstrates how the continuous product graph function (CITRUS) operates on multi-domain graph data (represented by U).  The function uses continuous heat kernels on each factor graph, and the combination of these kernels is what gives the CITRUS model its ability to perform efficient multi-domain graph learning.  The figure shows how the multi-domain graph data is transformed by a continuous function that takes into account the interactions between different domains.", "section": "Methodology and Theoretical Analysis"}, {"figure_path": "XRNN9i1xpi/figures/figures_5_1.jpg", "caption": "Figure 2: Stability analysis vs. different SNR scenarios, related the results in Theorem 3.7.", "description": "This figure shows the result of an experiment designed to test the stability of the CITRUS model against noise in the input data. The x-axis represents the signal-to-noise ratio (SNR) of the first factor graph, and the y-axis represents the mean squared error (MSE) of the model's predictions. Different lines represent different SNR values for the second factor graph. The results show that the model's performance improves as the SNR of both factor graphs increases, confirming the theoretical findings in Theorem 3.7.", "section": "4.1 Experimental Stability Analysis"}, {"figure_path": "XRNN9i1xpi/figures/figures_6_1.jpg", "caption": "Figure 3: Over-smoothing analysis using Theorem 3.10. left: ln s \u2212 tx < 0, right: ln s \u2212 tx > 0.", "description": "This figure shows the results of an experimental validation of Theorem 3.10, which concerns the over-smoothing analysis of the proposed CITRUS model.  Two scenarios are presented: one where ln s \u2212 tx < 0 (left panel) and one where ln s \u2212 tx > 0 (right panel). The plots compare the actual log relative distance obtained from experiments to the theoretical upper bound given by the theorem, as a function of the number of layers in the model. The left panel demonstrates that the theoretical bound is a good approximation of the actual behavior when ln s \u2212 tx < 0, indicating the effectiveness of the theorem in predicting over-smoothing. In contrast, the right panel shows that the theoretical bound is less accurate when ln s \u2212 tx > 0, suggesting the need for a tighter theoretical upper bound in this case.", "section": "Experimental Over-smoothing Analysis"}, {"figure_path": "XRNN9i1xpi/figures/figures_18_1.jpg", "caption": "Figure 4: Explained variance ratio vs. selected principal components.", "description": "This figure shows the explained variance ratio plotted against the selected principal components of the spatial Laplacian for the MetrLA dataset.  It demonstrates that a large portion of the variance is captured by a relatively small number of principal components, supporting the use of a low-rank approximation for computational efficiency in the proposed CITRUS method.", "section": "G Choosing Appropriate k"}, {"figure_path": "XRNN9i1xpi/figures/figures_19_1.jpg", "caption": "Figure 5: Log relative distance vs. increasing the number of layers for different values of t in actual bounds.", "description": "This figure shows the results of an experiment designed to validate the theoretical findings about over-smoothing in graph neural networks. The log relative distance is plotted against the number of layers for different values of the graph receptive field parameter, t.  The plot illustrates how the rate of over-smoothing is affected by the choice of t, demonstrating that controlling the graph receptive field helps mitigate the issue of over-smoothing.", "section": "3.3 Over-smoothing Analysis"}]