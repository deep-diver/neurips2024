[{"figure_path": "XRNN9i1xpi/tables/tables_7_1.jpg", "caption": "Table 1: Traffic forecasting comparison between CITRUS and previous methods.", "description": "This table presents a comparison of the performance of CITRUS against other state-of-the-art methods on two benchmark traffic forecasting datasets (MetrLA and PemsBay).  The comparison is made across three different prediction horizons (H=3, H=6, H=12), using three different metrics: Mean Absolute Error (MAE), Mean Absolute Percentage Error (MAPE), and Root Mean Squared Error (RMSE).  The results show that CITRUS outperforms many existing methods in terms of accuracy and generalizability, especially for longer prediction horizons.", "section": "4.3 Experiments on Real-world Data"}, {"figure_path": "XRNN9i1xpi/tables/tables_7_2.jpg", "caption": "Table 2: Weather forecasting comparison (by rNMSE) between CITRUS and previous methods.", "description": "This table presents the root normalized mean squared error (rNMSE) for weather forecasting using different methods on the Molene and NOAA datasets.  The results are shown for different prediction horizons (H=1 to H=5), representing the number of hours into the future that the model is predicting. Lower rNMSE values indicate better forecasting accuracy.  The table allows for a comparison of the proposed CITRUS model against other state-of-the-art methods in weather forecasting.", "section": "4.3 Experiments on Real-world Data"}, {"figure_path": "XRNN9i1xpi/tables/tables_8_1.jpg", "caption": "Table 3: Ablation study on comparison between the proposed CITRUS and typically ST pipelines.", "description": "This table presents the ablation study comparing the proposed CITRUS model with other state-of-the-art methods such as TTS, STT, CTTS and CSTT. The performance metrics MAE, MAPE and RMSE are reported for different prediction horizons (H=3, H=6, H=12) on the MetrLA dataset.  The results highlight CITRUS's superior performance compared to other ST pipelines, demonstrating the effectiveness of its joint learning approach for spatio-temporal data.", "section": "4.4 Ablation Study and Hyperparameter Sensitivity Analysis"}, {"figure_path": "XRNN9i1xpi/tables/tables_8_2.jpg", "caption": "Table 4: Training time (per epoch) and forecasting results vs. number of selected eig-eiv on MetrLA.", "description": "This table presents the results of an ablation study on the effect of the number of selected eigenvector-eigenvalue pairs (k) on the performance of the CITRUS model for traffic forecasting on the MetrLA dataset.  It shows the mean absolute error (MAE) and the training time per epoch for different values of k. The results indicate a trade-off between accuracy and computational cost, with diminishing returns in accuracy improvement as k increases.", "section": "4.4 Ablation Study and Hyperparameter Sensitivity Analysis"}, {"figure_path": "XRNN9i1xpi/tables/tables_16_1.jpg", "caption": "Table 5: Experiments on more than two factor graphs (PER(1) = PER(2) = 0.3).", "description": "This table presents the results of experiments conducted on more than two factor graphs. The node regression task is performed on three Erd\u0151s-R\u00e9nyi factor graphs with varying edge probabilities to evaluate the model's performance under different connectivity scenarios. The results are compared against a Graph Convolutional Network (GCN) baseline to highlight the effectiveness of the proposed CITRUS model in handling over-smoothing and maintaining performance even as the number of layers increases.", "section": "4.2 Experimental Over-smoothing Analysis"}, {"figure_path": "XRNN9i1xpi/tables/tables_16_2.jpg", "caption": "Table 6: Standard deviation of traffic forecasting comparison in Table 1.", "description": "This table shows the standard deviation of the Mean Absolute Error (MAE), Mean Absolute Percentage Error (MAPE), and Root Mean Squared Error (RMSE) for the CITRUS model on the MetrLA and PemsBay datasets. The standard deviations are presented for different forecasting horizons (H=3, H=6, H=12).  These values provide insight into the variability of the model's predictions across different experimental runs.", "section": "4.1 Experimental Stability Analysis"}, {"figure_path": "XRNN9i1xpi/tables/tables_17_1.jpg", "caption": "Table 7: Standard deviation of weather forecasting comparison in Table 2.", "description": "This table shows the standard deviation of the root normalized mean square error (rNMSE) for weather forecasting using the CITRUS model on the Molene and NOAA datasets. The results are broken down by prediction horizon (H) ranging from 1 to 5 hours.", "section": "4.3 Experiments on Real-world Data"}, {"figure_path": "XRNN9i1xpi/tables/tables_17_2.jpg", "caption": "Table 8: Intra and Inter-homophily measures on the real-world graphs of MetrLA and PemsBay datasets.", "description": "This table presents the intra-graph and inter-graph homophily measures for four real-world datasets: MetrLA, PemsBay, Molene, and NOAA.  Homophily refers to the tendency for nodes with similar characteristics to be connected. Intra-graph homophily measures the homophily within each individual graph (spatial graph), while inter-graph homophily measures homophily between the graphs (spatial-temporal correlation). Three metrics are used to quantify homophily: \nPs: Pearson correlation between adjacency matrices and node attributes\nqP: The proportion of edges in the graph connecting node pairs with similar attributes\nqN: The number of neighbor pairs with the same attribute divided by the total number of pairs. This table provides quantitative insights into the degree of homophily and heterophily within and between the graphs of each dataset, showing significant variability across them.", "section": "E Homophily-Heterophily Trade-off across the Studied Real Datasets"}, {"figure_path": "XRNN9i1xpi/tables/tables_18_1.jpg", "caption": "Table 9: Details of the training settings and hyperparameters, i.e., T (auto-regressive order), emb (dimension of embedding size in the spatiotemporal encoder), hid (dimension of linear mapping size in the spatiotemporal encoder), FMLP (dimension of linear mapping size in the MLP layers), NCITRUS (number of CITRUS blocks), F (second dimension of W\u2081 in (6)), ki (number of selected eigenvalue-eigenvector pairs in the i-th factor graph), lr (learning rate), nbatch (batch size), and nepochs (number of epochs).", "description": "This table shows the hyperparameters used in the experiments for different datasets. It includes parameters related to the autoregressive order, embedding dimensions, number of layers in MLPs and CITRUS blocks,  number of selected eigenvectors, learning rate, batch size, and number of epochs.", "section": "4.4 Ablation Study and Hyperparameter Sensitivity Analysis"}]