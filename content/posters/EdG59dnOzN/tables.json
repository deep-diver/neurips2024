[{"figure_path": "EdG59dnOzN/tables/tables_2_1.jpg", "caption": "Table 1: Summary of convergence guarantees for closely-related adaptive algorithms to solve smooth non-convex stochastic optimization problems. Convergence rates are given in terms of mint\u2208[T] E [||\u2207f(wt)||]\u00b2. We highlight KATE's scale-invariance property for problems of type (4).", "description": "The table summarizes the convergence rates and scale invariance properties of several adaptive optimization algorithms, including AdaGradNorm, AdaGrad, Adam, and the newly proposed KATE algorithm.  It shows that KATE achieves a convergence rate comparable to the others (O(log T/\u221aT)) but is uniquely scale-invariant.", "section": "1.2 Main Contribution"}]