[{"figure_path": "RrTjcbcHEH/figures/figures_1_1.jpg", "caption": "Figure 1: Can one model learn to localize any point of the human body in 3D from a single RGB image? We propose to build a generalist human pose and shape estimator that can readily learn from any annotated points at training time and can estimate any user-chosen points at test time.", "description": "This figure illustrates the core idea of the Neural Localizer Field (NLF) method proposed in the paper.  The NLF aims to learn a single model capable of localizing any point on the human body from a single RGB image, regardless of the type of annotation used during training (mesh, 2D/3D skeleton, dense pose). The model achieves this by learning a continuous neural field that stores all localization functions, allowing for flexibility at test time to query and predict the 3D coordinates of any user-specified point. This approach allows the model to handle diverse data sources seamlessly, avoiding the need for re-annotation or conversion between different formats.", "section": "1 Introduction"}, {"figure_path": "RrTjcbcHEH/figures/figures_3_1.jpg", "caption": "Figure 2: Overview of NLF. Given image features F and any arbitrarily chosen 3D query point p within the canonical human volume, we aim to estimate the observation-space 3D point p'. To control which point gets estimated, we dynamically modulate a convolutional layer at the output, to produce heatmaps for the requested point. During training, the points p can be picked per training example based on whichever points are annotated for it, allowing natural dataset mixing. At test time, the model can flexibly estimate any surface point and any skeletal joint inside the body volume, as required.", "description": "This figure illustrates the Neural Localizer Field (NLF) method.  Image features are processed through a vision backbone and fed into a 1x1 convolutional layer.  The key innovation is a dynamic modulation of this layer by a neural field, which takes a 3D query point (p) as input and outputs the weights (W(p)) for the convolutional layer.  This allows the model to localize any arbitrary point within the human body volume by generating a heatmap that, after a soft-argmax operation, provides the 3D observation-space coordinates (p'). The process allows for flexible training with diverse data sources and flexible estimation of any point during inference.", "section": "3 Method"}, {"figure_path": "RrTjcbcHEH/figures/figures_8_1.jpg", "caption": "Figure 3: Qualitative result on SSP-3D. left: NLF's nonparametric output (front and side view), right: result of our proposed fast SMPL fitting algorithm (front and side). Our nonparametric prediction already has high quality, allowing us to use a simple and efficient fitting algorithm to obtain body model parameters that faithfully represent the nonparametric output.", "description": "This figure shows a qualitative comparison of the results obtained using the proposed Neural Localizer Field (NLF) method for 3D human pose and shape estimation. The left side displays the nonparametric output of the NLF, which provides a high-quality prediction without the constraints of a parametric model. The right side shows the output obtained after applying a fast SMPL fitting algorithm to the nonparametric output. This demonstrates the method's ability to produce both nonparametric and parametric representations, allowing flexibility and efficiency in applications. The results are shown on SSP-3D (Shape and Pose estimation from a Single image)", "section": "4 Experiments"}, {"figure_path": "RrTjcbcHEH/figures/figures_8_2.jpg", "caption": "Figure 4: Customizable point localization. By selecting points p in the continuous canonical space, we can predict any landmark set both at training and test time. The first column depicts the query points we estimate: SMPL(-X) joints and vertices, COCO joints, Human3.6M joints, and arbitrary points sampled within the human volume. The fourth and seventh column show rotated views.", "description": "This figure demonstrates the flexibility of the Neural Localizer Field (NLF) model in localizing any point in the human body. It shows that the model can predict various landmark sets (SMPL, SMPL-X, COCO, Human3.6M) as well as arbitrary points sampled within the canonical human volume. The results show that the model is capable of estimating points on both the surface and inside the volume of the body, and that it can be customized to output any user-defined landmark set.", "section": "3 Method"}, {"figure_path": "RrTjcbcHEH/figures/figures_20_1.jpg", "caption": "Figure 5: Uncertainty estimation results. High uncertainty is indicated in yellow, while low is shown in blue. Occluded body parts tend to have higher uncertainty prediction.", "description": "This figure shows the uncertainty estimation results of the Neural Localizer Field (NLF) method.  The color coding represents the level of uncertainty for each estimated 3D point, with yellow indicating high uncertainty and blue indicating low uncertainty. The figure illustrates that occluded body parts tend to have higher uncertainty estimates, as expected. This demonstrates the NLF's ability to provide uncertainty information, which is valuable for downstream tasks and applications.", "section": "E Uncertainty Estimation"}, {"figure_path": "RrTjcbcHEH/figures/figures_20_2.jpg", "caption": "Figure 4: Customizable point localization. By selecting points p in the continuous canonical space, we can predict any landmark set both at training and test time. The first column depicts the query points we estimate: SMPL(-X) joints and vertices, COCO joints, Human3.6M joints, and arbitrary points sampled within the human volume. The fourth and seventh column show rotated views.", "description": "This figure demonstrates the Neural Localizer Field's (NLF) ability to localize any point in the 3D human body from a single RGB image.  The model can estimate any user-defined points at test time, including SMPL/SMPL-X joints and vertices, COCO and Human3.6M joints, as well as arbitrary internal points.  The figure shows examples of these various point localizations, illustrating the model's flexibility and generalizability.", "section": "Method"}, {"figure_path": "RrTjcbcHEH/figures/figures_21_1.jpg", "caption": "Figure 7: Convergence of SMPL fitting. We analyze the convergence properties of our iterative SMPL fitting algorithm on the SSP-3D benchmark. We use the nonparametric predictions from our NLF-S model as the fitting target. We can observe that approximately three iterations are sufficient for convergence to the SOTA result. (For PVE-T-SC lower is better, and for mIoU higher is better.)", "description": "The figure shows the convergence properties of the iterative SMPL fitting algorithm.  The algorithm iteratively refines the SMPL body model parameters to fit the non-parametric predictions.  The plot shows that the error (PVE-T-SC) decreases and the IoU increases with each iteration, converging within approximately three iterations to the state-of-the-art results.", "section": "3.3 Efficient Body Model Fitting in Post-Processing"}, {"figure_path": "RrTjcbcHEH/figures/figures_21_2.jpg", "caption": "Figure 2: Overview of NLF. Given image features F and any arbitrarily chosen 3D query point p within the canonical human volume, we aim to estimate the observation-space 3D point p'. To control which point gets estimated, we dynamically modulate a convolutional layer at the output, to produce heatmaps for the requested point. During training, the points p can be picked per training example based on whichever points are annotated for it, allowing natural dataset mixing. At test time, the model can flexibly estimate any surface point and any skeletal joint inside the body volume, as required.", "description": "This figure illustrates the Neural Localizer Field (NLF) architecture. It shows how image features are processed through a vision backbone to obtain feature maps. These maps are then used by a dynamically modulated convolutional layer to generate heatmaps which are decoded to obtain 3D point coordinates. The key component is the Neural Localizer Field, which modulates the convolutional layer based on a query point, allowing the network to localize any point in the human body volume, both during training and testing. This flexibility enables the model to seamlessly handle various data formats and annotations.", "section": "Method"}, {"figure_path": "RrTjcbcHEH/figures/figures_24_1.jpg", "caption": "Figure 9: Architecture of the neural localizer field itself.", "description": "The figure shows the architecture of the neural network that parameterizes the point localizer network. The neural field has an MLP-like structure, starting with learnable Fourier features (fully connected layer followed by sine and cosine activations). After two further fully connected layers with a GELU activation in between, we arrive at the layer whose output is initially trained to approximate the global point signature (GPS) derived from the volumetric Laplacian. Further two FC layers with GELU in between yield the parameters to modulate the convolutional layer of the point localizer network.", "section": "3.2 Neural Localizer Field"}, {"figure_path": "RrTjcbcHEH/figures/figures_25_1.jpg", "caption": "Figure 1: Can one model learn to localize any point of the human body in 3D from a single RGB image? We propose to build a generalist human pose and shape estimator that can readily learn from any annotated points at training time and can estimate any user-chosen points at test time.", "description": "This figure illustrates the core idea of the Neural Localizer Fields (NLF) method.  It shows that the model can learn to localize any point on a human body from a single RGB image, regardless of the annotation type used during training (mesh, 2D/3D skeleton, dense pose).  This flexibility allows for training on diverse, heterogeneous datasets without the need for re-annotation, leading to a more general and robust human pose and shape estimation model.", "section": "1 Introduction"}, {"figure_path": "RrTjcbcHEH/figures/figures_26_1.jpg", "caption": "Figure 4: Customizable point localization. By selecting points p in the continuous canonical space, we can predict any landmark set both at training and test time. The first column depicts the query points we estimate: SMPL(-X) joints and vertices, COCO joints, Human3.6M joints, and arbitrary points sampled within the human volume. The fourth and seventh column show rotated views.", "description": "This figure demonstrates the Neural Localizer Field's ability to localize arbitrary points in the 3D human body.  It shows examples of localizing different types of points (SMPL/SMPL-X joints and vertices, COCO keypoints, Human3.6M keypoints) and arbitrary points from within the human volume, showcasing the flexibility and generality of the proposed method.", "section": "3 Method"}]