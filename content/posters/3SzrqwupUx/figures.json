[{"figure_path": "3SzrqwupUx/figures/figures_9_1.jpg", "caption": "Figure 1: Comparison of the Linear CDE, Mamba, and S4 on the anti-symmetric signature prediction tasks. For each model, we plotted the mean and range of the validation accuracy over 5 independent runs.", "description": "This figure compares the performance of three different models (Linear CDE, Mamba, and S4) on two anti-symmetric signature prediction tasks (Area and Volume).  Each model is trained for different depths (1 and 2 layers, and 2 layers with a non-linearity), and the training progression is shown in terms of validation RMSE.  Error bars represent the range of accuracy across 5 separate runs. The figure helps to illustrate the differences in performance and efficiency between these models.", "section": "6 Empirical Validation"}, {"figure_path": "3SzrqwupUx/figures/figures_9_2.jpg", "caption": "Figure 2: For each sequence length, the plot shows the minimum number of blocks required to achieve at least 90% validation accuracy, with each grey band corresponding to a number of blocks. Missing points mean the model did not achieve at least 90% validation accuracy with 4 blocks or less.", "description": "This figure shows the minimum number of blocks required for different sequence-to-sequence models (Mamba, S4, Transformer, RNN, and Linear CDE) to achieve at least 90% validation accuracy on the A5 benchmark dataset.  The x-axis represents sequence length, and the y-axis represents the minimum number of blocks needed.  The plot demonstrates that the number of blocks required for S4, Mamba, and the Transformer models to achieve high accuracy increases with sequence length, while RNN and Linear CDE models maintain high accuracy with a single block regardless of sequence length.", "section": "6 Empirical Validation"}]