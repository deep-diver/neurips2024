{"references": [{"fullname_first_author": "Alec Radford", "paper_title": "Learning transferable visual models from natural language supervision", "publication_date": "2021-12-01", "reason": "This paper introduces CLIP, a highly influential multi-modal model that demonstrates impressive zero-shot capabilities and has spurred extensive research in multi-modal brain encoding."}, {"fullname_first_author": "Rohit Girdhar", "paper_title": "ImageBind: One embedding space to bind them all", "publication_date": "2023-06-01", "reason": "ImageBind is a significant advancement in multi-modal learning, creating a single embedding space for multiple modalities and showing strong potential for applications in brain-computer interface research."}, {"fullname_first_author": "Zineng Tang", "paper_title": "TVLT: Textless vision-language transformer", "publication_date": "2022-12-01", "reason": "This paper introduces TVLT, a text-less vision-language transformer, providing a powerful multi-modal representation for video and audio that is highly relevant to the study of brain encoding."}, {"fullname_first_author": "Subba Reddy Oota", "paper_title": "Deep neural networks and brain alignment: Brain encoding and decoding (survey)", "publication_date": "2023-07-01", "reason": "This survey paper provides a comprehensive overview of the field of brain encoding and decoding, highlighting the importance of multi-modal models and laying a foundation for the current research."}, {"fullname_first_author": "Mariya Toneva", "paper_title": "Combining computational controls with natural text reveals aspects of meaning composition", "publication_date": "2022-12-01", "reason": "This paper uses computational controls and natural language processing to investigate meaning composition, which is vital for multi-modal brain encoding model development and interpretation."}]}