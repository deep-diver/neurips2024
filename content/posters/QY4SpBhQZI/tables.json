[{"figure_path": "QY4SpBhQZI/tables/tables_6_1.jpg", "caption": "Table 1: Comparison between the proposed FFHQ-Ref and existing datasets.", "description": "This table compares the FFHQ-Ref dataset with two other datasets: FFHQ and CelebRef-HQ.  It shows whether each dataset includes reference images, if it is licensed appropriately, the overall quality of the images, the number of images included, and the number of distinct identities represented in the images.", "section": "4 FFHQ-Ref dataset"}, {"figure_path": "QY4SpBhQZI/tables/tables_7_1.jpg", "caption": "Table 2: Comparison between CacheKV and other mechanisms for input reference images (run with five reference images on a single GTX 1080).", "description": "This table compares the performance of four different mechanisms for integrating reference images into the diffusion denoising process: Channel-concatenation, Cross-attention, Spatial-concatenation, and the proposed CacheKV.  The comparison is based on several metrics: identity similarity (IDS), natural image quality evaluator (NIQE), learned perceptual image patch similarity (LPIPS), inference time, and GPU memory usage. The results show that CacheKV significantly outperforms the other methods in terms of IDS, while maintaining comparable efficiency in inference time and memory usage.", "section": "5.2.1 CacheKV and other mechanisms"}, {"figure_path": "QY4SpBhQZI/tables/tables_7_2.jpg", "caption": "Table 3: Ablation results for the timestep-scaled identity loss.", "description": "This table presents the ablation study results for the timestep-scaled identity loss. It compares three different loss settings: using only the classic LDM loss, adding a naive identity loss, and adding the proposed timestep-scaled identity loss. The results are evaluated using the Identity Similarity (IDS) metric and the Natural Image Quality Evaluator (NIQE) metric. The table shows that the timestep-scaled identity loss improves the identity similarity without sacrificing image quality.", "section": "5.2 Ablation studies"}, {"figure_path": "QY4SpBhQZI/tables/tables_7_3.jpg", "caption": "Table 4: Design choices for ID loss scaling.", "description": "This table presents the results of an ablation study on different scaling factors for the identity loss in the ReF-LDM model.  The identity loss is designed to improve the model's ability to accurately represent the identity of the subject in the generated image.  The study compares three different scaling factors: \u221a\u03b1t, 1t<100, and 1t<500. The results show the impact of each scaling factor on the identity similarity (IDS) and Natural Image Quality Evaluator (NIQE) scores.  A lower NIQE score indicates better image quality.", "section": "5.2 Ablation studies"}, {"figure_path": "QY4SpBhQZI/tables/tables_8_1.jpg", "caption": "Table 5: Image quality with different numbers of reference images.", "description": "This table shows the impact of the number of reference images on the image quality.  As the number of reference images increases, both the identity similarity (IDS) and the perceptual similarity (LPIPS) improve, indicating better restoration results.", "section": "5.2.3 Multiple input reference images"}, {"figure_path": "QY4SpBhQZI/tables/tables_8_2.jpg", "caption": "Table 6: Inference time with different numbers of reference images.", "description": "This table shows the inference time taken by the ReF-LDM model with different numbers of reference images used. The inference time is measured on two different GPUs: GTX 1080 and RTX 3090. As the number of reference images increases, the inference time also increases significantly. When using 8 reference images, the model runs out of memory on the GTX 1080 GPU.", "section": "5.2.3 Multiple input reference images"}, {"figure_path": "QY4SpBhQZI/tables/tables_8_3.jpg", "caption": "Table 7: Comparison of ReF-LDM with state-of-the-art methods across three benchmarks. Note the highlighting 1st, 2nd, and a gray cell indicating evaluation data leakage for prior methods.", "description": "This table compares the performance of ReF-LDM against several state-of-the-art methods on three benchmark datasets: FFHQ-Ref-Severe, FFHQ-Ref-Moderate, and CelebA-Test-Ref.  The metrics used for comparison are IDS (Identity Similarity), fLPIPS (face-region Learned Perceptual Image Patch Similarity), LPIPS (Learned Perceptual Image Patch Similarity), and FID (Fr\u00e9chet Inception Distance).  The table highlights the superior performance of ReF-LDM in terms of identity preservation, particularly on the more challenging FFHQ-Ref-Severe dataset.  It also indicates potential data leakage issues in some competing methods, suggesting a possible reason for their lower performance relative to ReF-LDM.", "section": "5.3 Comparison with state-of-the-art methods"}]