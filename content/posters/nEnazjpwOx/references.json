{"references": [{"fullname_first_author": "Yasin Abbasi-Yadkori", "paper_title": "Improved algorithms for linear stochastic bandits", "publication_date": "2011-01-01", "reason": "This paper provides improved algorithms for linear stochastic bandits, which are fundamental to the contextual bandit setting used in this paper."}, {"fullname_first_author": "Shipra Agrawal", "paper_title": "Thompson sampling for contextual bandits with linear payoffs", "publication_date": "2013-01-01", "reason": "This paper introduces Thompson sampling for contextual bandits with linear payoffs, a core algorithm used and extended upon in this paper."}, {"fullname_first_author": "Shipra Agrawal", "paper_title": "Further optimal regret bounds for Thompson sampling", "publication_date": "2013-01-01", "reason": "This paper provides further optimal regret bounds for Thompson sampling, which is crucial for the theoretical analysis of contextual bandit algorithms."}, {"fullname_first_author": "Daniel Russo", "paper_title": "Learning to optimize via posterior sampling", "publication_date": "2014-01-01", "reason": "This paper introduces the concept of Bayes regret, a key metric used to evaluate the performance of Bayesian bandit algorithms, and is crucial for this paper's theoretical analysis."}, {"fullname_first_author": "Jascha Sohl-Dickstein", "paper_title": "Deep unsupervised learning using nonequilibrium thermodynamics", "publication_date": "2015-01-01", "reason": "This paper introduces diffusion models, which are leveraged in this paper to model correlations between actions, leading to more efficient exploration."}]}