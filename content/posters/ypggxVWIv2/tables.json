[{"figure_path": "ypggxVWIv2/tables/tables_3_1.jpg", "caption": "Table 1: Game environments explored in GTBENCH.", "description": "This table presents a taxonomy of 10 different game-theoretic tasks included in the GTBENCH benchmark.  Each game is categorized across several dimensions:  information completeness (complete vs. incomplete), game dynamics (static vs. dynamic), and the nature of chance (deterministic vs. probabilistic).  Additionally, the table indicates which strategic reasoning abilities are most relevant to success in each game (board strategy, bids, collaboration, bluffing, and mathematical skills).  This provides a comprehensive overview of the diverse strategic reasoning challenges assessed by the benchmark.", "section": "3 GTBENCH: Game-Theoretic Evaluation of LLMs"}, {"figure_path": "ypggxVWIv2/tables/tables_6_1.jpg", "caption": "Table 2: Code-pretraining benefits strategic reasoning. Gray rows are code-pretrained LLMs.", "description": "This table shows the average NRA (Normalized Relative Advantage) scores for different LLMs across two categories of games: deterministic and probabilistic.  It highlights how code-pretrained LLMs perform comparatively to other LLMs, indicating the impact of code-pretraining on strategic reasoning abilities in game-playing scenarios.", "section": "4.3 LLM-vs.-LLM Competition"}, {"figure_path": "ypggxVWIv2/tables/tables_6_2.jpg", "caption": "Table 3: Code-pretraining benefits strategic reasoning. Gray rows are code-pretrained LLMs.", "description": "This table shows the average NRA (Normalized Relative Advantage) scores for different LLMs across two categories of games: deterministic and probabilistic.  It compares the performance of LLMs with and without code-pretraining, highlighting how code-pretraining impacts strategic reasoning abilities in these game scenarios. Higher NRA values indicate better performance compared to a baseline agent.", "section": "4.3 LLM-vs.-LLM Competition"}, {"figure_path": "ypggxVWIv2/tables/tables_7_1.jpg", "caption": "Table 4: The average NRA of LLM-driven agents when Breakthrough is included and excluded.", "description": "This table shows the average normalized relative advantage (NRA) scores for different LLMs across various game-theoretic tasks.  It compares the performance with and without the Breakthrough game included, highlighting how the inclusion or exclusion of more complex games can affect the overall performance scores of different LLMs. The results suggest that some LLMs struggle more with complex game rules.", "section": "4.3 LLM-vs.-LLM Competition"}, {"figure_path": "ypggxVWIv2/tables/tables_7_2.jpg", "caption": "Table 5: Quantitative results of error patterns.", "description": "This table presents the quantitative results of five common error patterns observed in the GTBENCH experiments.  The error patterns are: Endgame Misdetection, Misinterpretation, Overconfidence, Calculation Error, and Factual Error.  The table shows the percentage of each error pattern observed when GPT-4 with Chain-of-Thought reasoning was used as an agent in the games.", "section": "4.4 Error Profiles"}, {"figure_path": "ypggxVWIv2/tables/tables_7_3.jpg", "caption": "Table 6: The Elo rating results of LLM-vs.-LLM experiments.", "description": "This table presents the Elo ratings of various LLMs competing against each other in different game-theoretic tasks.  The Elo rating system is used to quantify the relative skill levels of the players, higher Elo indicating better performance.  The table shows the average Elo rating for each LLM across five games: Tic-Tac-Toe, Breakthrough, Blind Auction, Kuhn Poker, and Liar's Dice.  This allows for a comparison of the strategic reasoning abilities of different LLMs.", "section": "4.3 LLM-vs.-LLM Competition"}, {"figure_path": "ypggxVWIv2/tables/tables_21_1.jpg", "caption": "Table 1: Game environments explored in GTBENCH.", "description": "This table presents a taxonomy of games used in GTBENCH, categorized by information completeness (complete vs. incomplete), game dynamics (static vs. dynamic), and outcome determinism (deterministic vs. probabilistic).  Each game is further analyzed based on the strategic abilities required to excel.  The table lists 10 games, their categories, and the primary strategic abilities needed to play effectively (Board Strategy, Bidding, Collaboration, Bluff, Math).", "section": "3 GTBENCH: Game-Theoretic Evaluation of LLMs"}, {"figure_path": "ypggxVWIv2/tables/tables_22_1.jpg", "caption": "Table 2: Code-pretraining benefits strategic reasoning. Gray rows are code-pretrained LLMs.", "description": "This table shows the average Normalized Relative Advantage (NRA) scores achieved by different LLMs across different game categories (deterministic and probabilistic).  It highlights the impact of code-pretraining on the strategic reasoning capabilities of LLMs by comparing the performance of code-pretrained models against non-code-pretrained models. The results demonstrate that code-pretraining significantly improves the performance of LLMs in game-theoretic tasks.", "section": "4 Are LLMs Capable of Strategic Reasoning?"}, {"figure_path": "ypggxVWIv2/tables/tables_23_1.jpg", "caption": "Table A8: The affect of various temperatures for generation sampling.", "description": "This table shows the average Normalized Relative Advantage (NRA) in probabilistic and deterministic games for different LLMs at various temperatures (0.4, 0.6, and 0.8).  It demonstrates how the temperature setting affects the performance of LLMs in different game types.", "section": "A6 How Temperature Affects LLM Performance"}, {"figure_path": "ypggxVWIv2/tables/tables_24_1.jpg", "caption": "Table 1: Game environments explored in GTBENCH.", "description": "This table presents a taxonomy of ten games used in the GTBENCH benchmark.  For each game, it indicates whether it is zero-sum, has a first-player advantage, involves complete or incomplete information, is dynamic or static, and is probabilistic or deterministic.  It also lists the preferred reasoning abilities (board strategy, bidding, collaboration, bluffing, math) required for success in each game.  The table helps to categorize the games based on their properties, highlighting their diversity and the range of strategic reasoning abilities they test.", "section": "3 GTBENCH: Game-Theoretic Evaluation of LLMs"}, {"figure_path": "ypggxVWIv2/tables/tables_24_2.jpg", "caption": "Table 1: Game environments explored in GTBENCH.", "description": "This table presents ten different game environments used in the GTBENCH benchmark.  Each game is categorized according to several game-theoretic properties, such as whether it has complete or incomplete information, whether it is deterministic or probabilistic, and whether it is static or dynamic.  The table also lists the preferred cognitive abilities needed to succeed in each game, such as board strategy, bidding, collaboration, bluffing, and mathematical skills.", "section": "3 GTBENCH: Game-Theoretic Evaluation of LLMs"}, {"figure_path": "ypggxVWIv2/tables/tables_25_1.jpg", "caption": "Table 1: Game environments explored in GTBENCH.", "description": "This table presents a taxonomy of games used in the GTBENCH benchmark.  For each game (Tic-Tac-Toe, Connect-4, Kuhn Poker, Breakthrough, Liar's Dice, Blind Auction, Negotiation, Nim, Pig, Iterated Prisoner's Dilemma), it indicates whether it is zero-sum or not, whether it has a first-player advantage, whether it has complete or incomplete information, whether it is deterministic or probabilistic, whether it is static or dynamic, and what strategic abilities it requires (board strategy, bids, collaboration, bluff, math). This information helps to categorize and understand the characteristics of the games included in the benchmark, which aids in evaluating different strategic reasoning capabilities of LLMs.", "section": "3 GTBENCH: Game-Theoretic Evaluation of LLMs"}, {"figure_path": "ypggxVWIv2/tables/tables_28_1.jpg", "caption": "Table A6: NRA confusion matrix of LLM vs. LLM across ten games ranked by average NRA. GPT-3.5-turbo with Prompt Agent serve as the common opponent against multiple combinations of LLMs with agents.", "description": "This table presents the Normalized Relative Advantage (NRA) scores for various LLMs competing against GPT-3.5-turbo with a Prompt Agent in ten different games.  The table shows the results of LLM vs. LLM competitions, enabling comparison of different LLMs' strategic reasoning abilities across diverse gaming scenarios.  The average NRA is shown, along with NRA for each individual game.", "section": "A4 LLM-vs-LLM Results"}]