[{"figure_path": "O8yHsRLwPl/figures/figures_4_1.jpg", "caption": "Figure 1: Experiments with logistic regression.", "description": "The plots show the results of logistic regression experiments on the MNIST dataset, comparing Shadowheart SGD's performance with various baselines (QSGD, Asynchronous SGD, Minibatch SGD, SGDone). Three different communication speed regimes are considered: high, medium, and low. The figure illustrates Shadowheart SGD's robustness to varying communication speeds, consistently achieving strong performance across all regimes.", "section": "Q.1 Experiments with Logistic Regression"}, {"figure_path": "O8yHsRLwPl/figures/figures_4_2.jpg", "caption": "Figure 1: Time complexities of centralized distributed algorithms in different regimes. (a) high communication speed; (b) low communication speed; (c) medium communication speed.", "description": "This figure compares the time complexities of different centralized distributed algorithms (Minibatch SGD, QSGD, Rennala SGD, Asynchronous SGD, and Shadowheart SGD) across three communication speed regimes: high, low, and medium. The x-axis represents the time in seconds, and the y-axis represents the difference between the current function value and optimal function value. Different colors represent different algorithms. The figure illustrates the performance of Shadowheart SGD relative to existing methods under varying communication conditions.", "section": "Q.1 Experiments with Logistic Regression"}, {"figure_path": "O8yHsRLwPl/figures/figures_54_1.jpg", "caption": "Figure 1: Experiments with logistic regression.", "description": "This figure presents the results of experiments on logistic regression using the MNIST dataset, comparing Shadowheart SGD with QSGD, Asynchronous SGD, Minibatch SGD, and SGDone.  Three communication speed setups are shown: high, medium, and low.  The plots illustrate the convergence rate of each algorithm measured in terms of f(x<sub>t</sub>) - f(x*) against time in seconds. Different step sizes were used for each algorithm to fine-tune performance and the parameter \u03c3\u00b2/\u025b was tuned for Shadowheart SGD.  The high communication speed setup shows all the distributed algorithms performing similarly, while the lower speed communications demonstrate how Shadowheart SGD is robust across different scenarios.", "section": "Q.1 Experiments with Logistic Regression"}, {"figure_path": "O8yHsRLwPl/figures/figures_55_1.jpg", "caption": "Figure 2: SGDone starts to slow down relative to Shadowheart SGD and other methods when we increase the noise.", "description": "This figure compares the performance of various algorithms on synthetic quadratic optimization tasks with multiplicative noise.  The x-axis represents the time in seconds, and the y-axis represents the objective function value.  The plots show that as noise increases (comparing (a) and (b)), the performance of SGDone degrades significantly relative to Shadowheart SGD, while other methods also show some performance degradation.  Shadowheart SGD demonstrates superior robustness to increasing noise levels.", "section": "Q.2 Plots"}, {"figure_path": "O8yHsRLwPl/figures/figures_56_1.jpg", "caption": "Figure 2: SGDone starts to slow down relative to Shadowheart SGD and other methods when we increase the noise.", "description": "This figure compares the performance of Shadowheart SGD against other methods (Asynchronous SGD, SGDone, Minibatch SGD, and QSGD) on synthetic quadratic optimization tasks with multiplicative noise.  The x-axis represents the time in seconds, and the y-axis represents the difference between the function value at the current iterate and the optimal function value (f(xt) - f(x*)). The plots show that as noise increases (from p = 10\u207b\u00b3 in (a) to p = 10\u207b\u2074 in (b)), SGDone's performance deteriorates significantly, whereas Shadowheart SGD maintains its relative advantage over other methods.", "section": "Q.2.2 Plots"}, {"figure_path": "O8yHsRLwPl/figures/figures_56_2.jpg", "caption": "Figure 4: Shadowheart SGD improves when we decrease the computation times from \u221ai to 1.", "description": "This figure compares the performance of Shadowheart SGD against other methods (Asynchronous SGD, SGDone, Minibatch SGD, QSGD) under different computation times.  In (a), computation times are \u221ai, showcasing Shadowheart SGD's robustness and improved convergence compared to others, particularly as the communication time increases. Part (b) uses a constant computation time of 1 for all workers.  The difference highlights how Shadowheart SGD's performance benefits from reducing the variance in computation times.", "section": "Q.2.2 Plots"}, {"figure_path": "O8yHsRLwPl/figures/figures_57_1.jpg", "caption": "Figure 5: h\u1d62 ~ U(0.1, 1), t\u1d62 = \u221ai/d<sup>\u03b2</sup>, \u03b2 \u2208 {1/2, 3/4, 1}", "description": "This figure presents the results of experiments comparing the convergence speed of various algorithms for different numbers of workers (n).  The x-axis represents the time in seconds, and the y-axis represents the value of ||\u2207f(x)||\u00b2.  The figure showcases the performance of Asynchronous SGD, SGDone, Minibatch SGD, QSGD, and Shadowheart SGD across three different communication speed settings (\u03b2 = 1/2, 3/4, 1), which are indicated in subplots (a), (b), and (c) respectively.  Each subplot corresponds to a different number of workers: (a) n = 10, (b) n = 10\u00b2, and (c) n = 10\u00b3.  The goal is to show how the convergence of Shadowheart SGD compares with the other algorithms under various worker and communication conditions.", "section": "Q.3.1 Plots"}, {"figure_path": "O8yHsRLwPl/figures/figures_57_2.jpg", "caption": "Figure 4: Shadowheart SGD improves when we decrease the computation times from \u221ai to 1.", "description": "This figure displays the convergence of different SGD methods (Shadowheart SGD, Asynchronous SGD, SGDone, Minibatch SGD, and QSGD) when the computation time for each worker changes. The y-axis shows the convergence speed, measured as ||\u2207f(xk)||\u00b2, while the x-axis represents the time. The three subfigures correspond to different noise levels (\u03c3\u00b2/\u03b5 = 1, 10, 102). Shadowheart SGD is shown to improve in all noise levels when computation time decreases from \u221ai to 1.", "section": "Q.2.2 Plots"}, {"figure_path": "O8yHsRLwPl/figures/figures_57_3.jpg", "caption": "Figure 7: h ~ U(0.1, 1), \u2020 ~ c \u00b7 U(0.1, 1)", "description": "This figure shows the convergence speed of different algorithms under additive noise, where computation and communication times are sampled from the uniform distribution U(0.1, 1). The communication times are scaled by a factor c, which represents different communication speed regimes: c = 10\u207b\u00b9, c = 1, and c = 10\u00b2. Shadowheart SGD demonstrates robustness and high convergence speed across different regimes, particularly excelling in high and medium-speed communication. SGDone, while competitive in scenarios with expensive communications (c = 10\u00b2), is outperformed by Shadowheart SGD as communication speed improves.", "section": "Q.3.1 Plots"}, {"figure_path": "O8yHsRLwPl/figures/figures_57_4.jpg", "caption": "Figure 3: The non-compressed methods Asynchronous SGD and Minibatch SGD slow down relative to Shadowheart SGD when we increase the communication times.", "description": "This figure compares the performance of Shadowheart SGD against Asynchronous SGD, Minibatch SGD, and QSGD across three different communication time regimes. The x-axis represents time in seconds, and the y-axis represents the convergence metric ||\u2207f(x)||\u00b2. The plots show that Shadowheart SGD consistently outperforms the other methods, particularly in high-communication cost scenarios, showcasing its robustness to communication delays.", "section": "Q.2 Plots"}]