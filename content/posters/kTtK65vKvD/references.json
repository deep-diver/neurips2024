{"references": [{"fullname_first_author": "A. Radford", "paper_title": "Learning transferable visual models from natural language supervision", "publication_date": "2021-07-01", "reason": "CLIP, introduced in this paper, is a crucial component of ODGEN, used for text encoding and generating visual prompts for object detection."}, {"fullname_first_author": "R. Rombach", "paper_title": "High-resolution image synthesis with latent diffusion models", "publication_date": "2022-06-01", "reason": "Stable Diffusion, presented here, is the foundation of ODGEN, providing the core diffusion model for image generation."}, {"fullname_first_author": "P. Dhariwal", "paper_title": "Diffusion models beat gans on image synthesis", "publication_date": "2021-12-01", "reason": "This work established the high-quality image generation capabilities of diffusion models, motivating their use in ODGEN for data augmentation."}, {"fullname_first_author": "L. Zhang", "paper_title": "Adding conditional control to text-to-image diffusion models", "publication_date": "2023-10-01", "reason": "ControlNet, the method introduced here, directly inspired the visual control mechanism in ODGEN, allowing for precise bounding box and object control during image synthesis."}, {"fullname_first_author": "N. Dvornik", "paper_title": "Modeling visual context is key to augmenting object detection datasets", "publication_date": "2018-09-01", "reason": "This paper's approach to data augmentation using visual context is foundational to ODGEN's strategy of enhancing object detection datasets with synthetic images."}]}