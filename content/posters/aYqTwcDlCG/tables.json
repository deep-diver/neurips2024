[{"figure_path": "aYqTwcDlCG/tables/tables_4_1.jpg", "caption": "Table 7: Compound Model Prediction Error.", "description": "This table presents a quantitative comparison of the world model prediction quality between MUN and its baseline methods across various benchmark environments. It shows the compounding prediction error (multi-step prediction error) of learned world models, calculated by generating simulated trajectories and comparing them to real trajectories. Lower values indicate better prediction accuracy.", "section": "4.3 Results"}, {"figure_path": "aYqTwcDlCG/tables/tables_16_1.jpg", "caption": "Table 7: Compound Model Prediction Error.", "description": "This table presents the multi-step prediction error of learned world models for different tasks.  It shows the compounding error (accumulated error over multiple prediction steps) of various models (MUN, MUN-noDAD, PEG-G, MEGA-G, and GC-Dreamer) when generating simulated trajectories of the same length as real trajectories.  Lower values indicate better model performance in accurately predicting the future states.", "section": "F.3 World Model Assessment"}, {"figure_path": "aYqTwcDlCG/tables/tables_16_2.jpg", "caption": "Table 6: One-step Model Prediction Error.", "description": "This table presents the one-step prediction error for learned world models across different environments and baselines (MUN, MUN-noDAD, PEG-G, MEGA-G, and GC-Dreamer).  The error is calculated using a validation dataset of randomly sampled state-transition tuples from the replay buffers of each method. Lower values indicate better model accuracy in predicting the next state based on the current state and action.", "section": "F.3 World Model Assessment"}, {"figure_path": "aYqTwcDlCG/tables/tables_17_1.jpg", "caption": "Table 3: Success rate of navigation experiments on 3-Block Stacking", "description": "This table presents the success rates achieved by different algorithms (MUN, MUN-noDAD, GC-Dreamer, MEGA-G, and PEG-G) when performing navigation tasks in the 3-Block Stacking environment.  The success rate is the percentage of times the algorithm successfully navigated from a randomly selected starting state to a randomly selected goal state within the environment.  These results highlight the comparative performance of MUN and the effectiveness of its subgoal discovery method compared to other algorithms.", "section": "F.2 Navigation Experiments"}, {"figure_path": "aYqTwcDlCG/tables/tables_17_2.jpg", "caption": "Table 6: One-step Model Prediction Error.", "description": "This table presents the one-step prediction error for each environment. The error is calculated as the mean squared error between the model's prediction and the actual next state. Lower values indicate better model accuracy.  The table compares the performance of the proposed MUN method against several baselines: MUN-noDAD, PEG-G, MEGA-G, and GC-Dreamer.", "section": "F.3 World Model Assessment"}, {"figure_path": "aYqTwcDlCG/tables/tables_19_1.jpg", "caption": "Table 1: Runtimes per experiment.", "description": "This table shows the total runtime in hours and the total number of steps for each of the six experiments conducted in the paper: 3-Block Stacking, Walker, Ant Maze, Block Rotation, Pen Rotation, and Fetch Slide.  The runtimes provide a sense of the computational cost associated with training the models in each environment.", "section": "E.2 Runtime"}, {"figure_path": "aYqTwcDlCG/tables/tables_19_2.jpg", "caption": "Table 1: Runtimes per experiment.", "description": "This table presents the runtime and total number of steps for each of the six experiments conducted in the paper.  The experiments involved robotic manipulation and navigation tasks with varying complexities.", "section": "E.2 Runtime"}, {"figure_path": "aYqTwcDlCG/tables/tables_20_1.jpg", "caption": "Table 2: Hyperparameters of MUN.", "description": "This table lists the hyperparameters used in the MUN algorithm for each of the six different environments.  The hyperparameters include: \n\n*   `Nsubgoals`: The number of candidate subgoals stored.\n*   `Ns`: The number of subgoals used for navigation when sampling in the environment.\n*   `L`: The total episode length.\n*   `Ts`: The maximum number of timesteps allocated for navigating to a specific subgoal.", "section": "E Implementation Details"}, {"figure_path": "aYqTwcDlCG/tables/tables_21_1.jpg", "caption": "Table 3: Success rate of navigation experiments on 3-Block Stacking", "description": "This table presents the success rates achieved by different algorithms in navigation experiments conducted on the 3-Block Stacking environment.  The algorithms compared include MUN, MUN-noDAD (an ablation of MUN), GC-Dreamer (a goal-conditioned Dreamer baseline), MEGA-G (a Go-Explore baseline), and PEG-G (another Go-Explore baseline). The success rate reflects the percentage of successful navigation attempts between arbitrary subgoals within this environment.", "section": "F.2 Navigation Experiments"}, {"figure_path": "aYqTwcDlCG/tables/tables_21_2.jpg", "caption": "Table 4: Success rate of navigation experiments on Ant Maze", "description": "This table presents the success rates achieved by different algorithms in the Ant Maze navigation task.  The algorithms compared are MUN, MUN-noDAD (a variant of MUN without the DAD subgoal selection method), GC-Dreamer (a goal-conditioned Dreamer baseline), MEGA-G (a Go-Explore baseline using MEGA's goal selection), and PEG-G (a Go-Explore baseline using PEG's goal selection).  The results show the percentage of successful navigation attempts for each algorithm.", "section": "4.3 Results"}, {"figure_path": "aYqTwcDlCG/tables/tables_21_3.jpg", "caption": "Table 5: Success rate of navigation experiments on Walker", "description": "This table presents the success rates achieved by different algorithms (MUN, MUN-noDAD, GC-Dreamer, MEGA-G, and PEG-G) when performing navigation tasks in the Walker environment.  The success rate is calculated as the percentage of successful navigation trials from a set of initial and goal positions. The results showcase the performance differences between MUN and its ablations (MUN-noDAD) and various baselines (GC-Dreamer, MEGA-G, and PEG-G), highlighting the impact of the MUN's exploration strategy and the DAD method for subgoal discovery.", "section": "4.3 Results"}, {"figure_path": "aYqTwcDlCG/tables/tables_23_1.jpg", "caption": "Table 6: One-step Model Prediction Error.", "description": "This table presents the one-step prediction error for various world models across different environments.  The error is calculated as the mean squared error between the model's prediction and the ground truth for a randomly sampled set of state transitions from the replay buffer.  Lower values indicate better model accuracy in predicting the next state given the current state and action.", "section": "F.3 World Model Assessment"}, {"figure_path": "aYqTwcDlCG/tables/tables_23_2.jpg", "caption": "Table 7: Compound Model Prediction Error.", "description": "This table presents the multi-step prediction error for different learned world models across various tasks.  The error is calculated by comparing the simulated trajectories generated by the models against the ground truth trajectories from the real environment. Lower values indicate better model generalization and prediction accuracy. The results show that the models trained by MUN generally have lower compounding errors compared to other baselines across all tasks.", "section": "F.3 World Model Assessment"}]