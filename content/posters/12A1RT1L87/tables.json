[{"figure_path": "12A1RT1L87/tables/tables_6_1.jpg", "caption": "Table 2: Tiny-ImageNet label pruning results. The standard deviation is attained from three different runs. \u2020 denotes the reported results.", "description": "This table presents the results of label pruning experiments conducted on the Tiny-ImageNet dataset.  It compares the performance of the proposed method against state-of-the-art (SOTA) methods (SRe2L and CDA) across various pruning ratios (1x, 10x, 20x, 30x, 40x) and image-per-class (IPC) values (50 and 100). The performance is measured in terms of accuracy, and standard deviations are reported to reflect the variability across different runs of the experiments. Results marked with \u2020 indicate previously reported values from other works. The table showcases the effectiveness of the proposed label pruning technique in achieving competitive accuracy levels while using significantly fewer soft labels compared to existing approaches.", "section": "4.2 Primary Result"}, {"figure_path": "12A1RT1L87/tables/tables_6_2.jpg", "caption": "Table 2: Tiny-ImageNet label pruning results. The standard deviation is attained from three different runs. \u2020 denotes the reported results.", "description": "This table presents the results of label pruning experiments conducted on the Tiny-ImageNet dataset.  It compares the performance of three different methods (SRe2L, CDA, and the proposed 'Ours') across various pruning ratios (1x, 10x, 20x, 30x, 40x) and images-per-class (IPC) values (50 and 100). The standard deviation is calculated from three separate runs for each configuration, indicating the variability of the results.  The symbol \u2020 denotes results reported in other papers. The table helps to demonstrate the effectiveness of the proposed label pruning method in achieving comparable or better performance compared to existing methods while significantly reducing the required soft labels storage.", "section": "4 Experiments"}, {"figure_path": "12A1RT1L87/tables/tables_6_3.jpg", "caption": "Table 3: ImageNet-1K label pruning result. Our method consistently shows a better performance under various pruning ratios. \u2020 denotes the reported results.", "description": "This table presents the results of label pruning experiments conducted on the ImageNet-1K dataset using ResNet-18 as the validation model.  The table compares the performance of the proposed method against existing state-of-the-art (SOTA) methods (SRe2L and CDA) across different image-per-class (IPC) settings and various pruning ratios (1x, 10x, 20x, 30x, 40x).  The results demonstrate the consistent superior performance of the proposed method, even with significantly fewer labels.", "section": "4 Experiments"}, {"figure_path": "12A1RT1L87/tables/tables_7_1.jpg", "caption": "Table 5: Comparison between different pruning metrics. Results are obtained from ImageNet-1K IPC10 and validated using ResNet-18.", "description": "This table compares the performance of different label pruning methods on the ImageNet-1K dataset with an Images Per Class (IPC) of 10, using the ResNet-18 model for validation.  The methods compared include pruning based on different metrics ('correct', 'diff', 'diff_signed', 'cut_ratio', 'confidence') and random pruning.  The table shows the average accuracy for each method, providing insights into the effectiveness of different pruning strategies. The 'correct' metric focuses on the accuracy of the correctly classified images and is calculated based on the top 2 predictions. The 'diff' and 'diff_signed' metrics use the absolute and signed difference between the top 2 predictions respectively, intending to identify labels with high uncertainty. The 'cut_ratio' metric captures the mixup ratio, and the 'confidence' metric reflects the prediction confidence.", "section": "4.3 Analysis"}, {"figure_path": "12A1RT1L87/tables/tables_7_2.jpg", "caption": "Table 5: Comparison between different pruning metrics. Results are obtained from ImageNet-1K IPC10 and validated using ResNet-18.", "description": "This table presents the results of an ablation study comparing different label pruning methods on the ImageNet-1K dataset with an IPC of 10.  The methods compared include random pruning and several other pruning strategies (indicated by \"Easy\" and \"Hard\" columns, which refer to the label pruning strategies targeting easy or hard samples respectively) with different pruning ratios (20x, 30x, 50x, 100x). The results are validated using the ResNet-18 model and show the impact of different pruning strategies and ratios on model performance. The table demonstrates that simple random pruning is comparable to more sophisticated methods.", "section": "4.3 Analysis"}, {"figure_path": "12A1RT1L87/tables/tables_7_3.jpg", "caption": "Table 4: Ablation study of the proposed method. C denotes using class-wise matching. CS denotes suing class-wise supervision. ILP denotes using an improved label pool. (IPC50, ResNet18, ImageNet-1K).", "description": "This table presents the ablation study of the proposed method, showing the impact of class-wise matching (+C), class-wise supervision (+CS), and the improved label pool (+ILP) on the performance at different pruning ratios (1x, 10x, 20x, 30x, 50x, 100x) using ResNet18 on ImageNet-1K with IPC50.  Each row represents a different combination of these components, allowing for the isolation and evaluation of their individual effects.", "section": "4.3 Analysis"}, {"figure_path": "12A1RT1L87/tables/tables_8_1.jpg", "caption": "Table 2: Tiny-ImageNet label pruning results. The standard deviation is attained from three different runs. \u2020 denotes the reported results.", "description": "This table presents the results of label pruning experiments on the Tiny-ImageNet dataset.  It compares the performance of the proposed method against state-of-the-art (SOTA) methods (SRe2L and CDA) across various network architectures (ResNet-18, ResNet-50, ResNet-101) and different pruning ratios (1x, 10x, 20x, 30x, 40x). The results are averaged over three different runs, and the standard deviation is reported to provide a measure of variability. The symbol \u2020 indicates results reported by other researchers for comparison.", "section": "4.2 Primary Result"}, {"figure_path": "12A1RT1L87/tables/tables_8_2.jpg", "caption": "Table 2: Tiny-ImageNet label pruning results. The standard deviation is attained from three different runs. \u2020 denotes the reported results.", "description": "This table presents the results of label pruning experiments conducted on the Tiny-ImageNet dataset.  It compares the performance of three different methods (SRe2L, CDA, and the proposed 'Ours' method) across various pruning ratios (1x, 10x, 20x, 30x, 40x) and image-per-class (IPC) values (50 and 100). The performance is measured in terms of accuracy. The table shows that the proposed method consistently outperforms the other two methods, especially at higher pruning ratios, demonstrating its effectiveness in reducing the storage requirements for soft labels.", "section": "4.2 Primary Result"}, {"figure_path": "12A1RT1L87/tables/tables_8_3.jpg", "caption": "Table 9: Compare with G-VBSM [9]. \"Ours+\" uses ensemble and MSE+GT loss.", "description": "This table compares the performance of the proposed method with G-VBSM [9] on the ImageNet-1K dataset using ResNet-18 at different pruning ratios (1x, 10x, 20x, 30x, 40x). The 'Ours+' column represents an enhanced version of the proposed method that incorporates ensemble learning and a modified loss function (MSE+GT). The results show that even with a simple implementation, the proposed method outperforms G-VBSM across all pruning ratios.  The significant gains shown in the 'Ours+' column demonstrate the potential of further optimization by incorporating techniques from other advanced methods.", "section": "4.3 Analysis"}, {"figure_path": "12A1RT1L87/tables/tables_15_1.jpg", "caption": "Table 10: Squeezing and class-wise BN statistics of ImageNet-1K.", "description": "This table shows the number of total images, batch size, the number of BN updates during the squeezing phase, and the source of the pretrained model used for ImageNet-1K experiments.  The information is crucial for understanding the preprocessing steps and setting up the experiment.", "section": "C Hyperparameter Settings"}, {"figure_path": "12A1RT1L87/tables/tables_16_1.jpg", "caption": "Table 11: Data Synthesis of ImageNet-1K.", "description": "This table describes the hyperparameters and settings used during the data synthesis phase for ImageNet-1K in the experiment.  It includes the number of iterations, the optimizer used (Adam), learning rates for images, batch size (which is dependent on the images per class), initialization method, and the weight of the batch normalization loss.", "section": "4.1 Experiment Settings"}, {"figure_path": "12A1RT1L87/tables/tables_16_2.jpg", "caption": "Table 12: Relabel and Validation of ImageNet-1K.", "description": "This table details the hyperparameters used in the relabeling and validation phases of the ImageNet-1K experiments.  It includes the number of epochs, optimizer used (AdamW), model learning rate, batch size, scheduler (CosineAnnealing), EMA rate (not used), and augmentations applied (RandomResizedCrop, RandomHorizontalFlip, CutMix) along with their respective parameters.", "section": "4.1 Experiment Settings"}, {"figure_path": "12A1RT1L87/tables/tables_16_3.jpg", "caption": "Table 13: Squeezing and class-wise BN statistics of Tiny-Imagenet.", "description": "This table shows the details of the squeezing phase for the Tiny-ImageNet dataset. It provides the total number of images, batch size used, the number of BN updates performed, and the source of the dataset.", "section": "C Hyperparameter Settings"}, {"figure_path": "12A1RT1L87/tables/tables_17_1.jpg", "caption": "Table 15: Relabel and Validation of Tiny-ImageNet.", "description": "This table details the hyperparameters used in the relabeling and validation phases for the Tiny-ImageNet dataset.  It specifies the number of epochs, optimizer used (SGD), model learning rate, batch size, warm-up scheduler details, overall scheduler (Cosine Annealing), EMA rate, and augmentations applied (RandomResizedCrop and RandomHorizontalFlip) along with their parameters.  These settings are crucial for understanding how the synthetic Tiny-ImageNet dataset was refined and evaluated.", "section": "C Hyperparameter Settings"}, {"figure_path": "12A1RT1L87/tables/tables_17_2.jpg", "caption": "Table 3: ImageNet-1K label pruning result. Our method consistently shows a better performance under various pruning ratios. \u2020 denotes the reported results.", "description": "This table presents the results of label pruning experiments on the ImageNet-1K dataset using ResNet-18 as the validation model.  It compares the performance of the proposed method against state-of-the-art (SOTA) methods (SRe2L and CDA) across different image-per-class (IPC) settings and various pruning ratios (1x, 10x, 20x, 30x, 40x). The table shows that the proposed method consistently outperforms SOTA methods, achieving better accuracy with significantly fewer soft labels.", "section": "4 Experiments"}, {"figure_path": "12A1RT1L87/tables/tables_18_1.jpg", "caption": "Table 4: Ablation study of the proposed method. C denotes using class-wise matching. CS denotes using class-wise supervision. ILP denotes using an improved label pool. (IPC50, ResNet18, ImageNet-1K).", "description": "This table presents the results of an ablation study conducted to evaluate the impact of different components of the proposed method on the model's performance.  The study varied the inclusion of class-wise matching (+C), class-wise supervision (+CS), and an improved label pool (+ILP). The results are shown for different label pruning ratios (1x, 10x, 20x, 30x, 50x, 100x) using the ResNet18 model on the ImageNet-1K dataset with Images Per Class (IPC) set to 50. Each row represents a different combination of the components, allowing for the assessment of their individual and combined effects on model accuracy.", "section": "4.3 Analysis"}, {"figure_path": "12A1RT1L87/tables/tables_18_2.jpg", "caption": "Table 20: Experiment on the scalability of large IPCs. T denotes the total storage of images and labels, and storage is measured in GB. The validation model is ResNet18.", "description": "This table shows the scalability of the proposed method with large IPCs (Images Per Class). It demonstrates the total storage (in GB) for images and labels at different pruning ratios (1x, 30x, 40x). The results are presented for IPC300 and IPC400, showing that the method maintains good accuracy even with significantly reduced storage.", "section": "4.3 Analysis"}, {"figure_path": "12A1RT1L87/tables/tables_19_1.jpg", "caption": "Table 21: Different storage components between FKD and the proposed method. FKD, originally for model distillation, requires storage only for components 1, 2, and 6. Adapting it to dataset distillation requires additional storage for components 3, 4, and 5.", "description": "This table compares the storage requirements for different components between the Fast Knowledge Distillation (FKD) method and the proposed Label Pruning for Large-scale Distillation (LPLD) method.  It highlights that FKD, in its original model distillation context, only needs to store components related to coordinates of crops, flip status, and prediction logits. However, when adapted for dataset distillation, it additionally requires storage for cutmix-related components (index of cutmix images, strength of cutmix, and coordinates of cutmix bounding box).  The proposed LPLD method addresses all six components.", "section": "D.3 Comparison with Fast Knowledge Distillation [25]"}, {"figure_path": "12A1RT1L87/tables/tables_19_2.jpg", "caption": "Table 22: Breakdown explanation for component 6 (prediction logits) storage between FKD's label quantization and the proposed label pruning. The number of condensed images is computed by N = IPC \u00d7 number_of_classes. FKD's compression target is dimension_of_logits, while the proposed method's target is number_of_augmentations.", "description": "This table compares the storage of prediction logits between the baseline (no compression), FKD (label quantization), and the proposed label pruning method. It shows how different compression strategies (reducing the number of augmentations per image or the dimension of logits) affect the total storage requirements. The table highlights the proposed method's efficiency in reducing storage by significantly reducing the number of augmentations while keeping a high dimension of logits.", "section": "D.3 Comparison with Fast Knowledge Distillation [25]"}, {"figure_path": "12A1RT1L87/tables/tables_19_3.jpg", "caption": "Table 2: Tiny-ImageNet label pruning results. The standard deviation is attained from three different runs. \u2020 denotes the reported results.", "description": "This table presents the results of label pruning experiments conducted on the Tiny-ImageNet dataset.  It compares the performance of three methods (SRe2L, CDA, and Ours) across different pruning ratios (1x, 10x, 20x, 30x, and 40x) and Image Per Class (IPC) values (50 and 100). The results show the accuracy achieved by each method under various label pruning levels.  The \"\u2020\" symbol indicates that the result is taken from a previously published paper. Standard deviation is provided to demonstrate the consistency of the results.", "section": "4.2 Primary Result"}, {"figure_path": "12A1RT1L87/tables/tables_20_1.jpg", "caption": "Table 24: Image and label storage. I denotes image storage. L denotes label storage. \"Ratio\" is label-to-image ratio.", "description": "This table presents the storage size (in GB or MB) of images and labels for different datasets (ImageNet-1K, Tiny-ImageNet, ImageNet-21K-P) and varying numbers of images per class (IPC).  It shows the significant increase in label storage compared to image storage, highlighting the storage issue addressed by the paper's proposed method.", "section": "E.2 Image and Label Storage"}, {"figure_path": "12A1RT1L87/tables/tables_22_1.jpg", "caption": "Table 25: Additional storage required for class-wise statistics. The model is ResNet-18, and storage is measured in MB.", "description": "This table shows the additional storage required when using class-wise batch normalization statistics instead of global statistics for three different datasets: Tiny-ImageNet, ImageNet-1K, and ImageNet-21K-P.  The \"Original\" row represents the storage needed for the original BN statistics. The \"+ Class Stats\" row indicates the storage required when class-wise statistics are added. The \"Diff.\" row shows the difference in storage between the two approaches. The table highlights that the additional storage for class-wise statistics increases substantially with larger datasets.", "section": "E.4 Class-wise Statistics Storage"}]