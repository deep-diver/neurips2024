[{"figure_path": "12A1RT1L87/figures/figures_0_1.jpg", "caption": "Figure 1: The relationship between performance and total storage of auxiliary information needed. Our method achieves SOTA performance with fewer soft labels than images.", "description": "This figure shows the relationship between the model's accuracy and the total storage space required for both the condensed dataset images and the auxiliary soft labels.  It compares the performance of several state-of-the-art (SOTA) methods, including SRe2L, G-VBSM, RDED, CDA, and the proposed method.  The x-axis represents the total storage size (in GB), and the y-axis represents the accuracy achieved.  The figure demonstrates that the proposed method achieves superior performance with significantly less storage compared to the other methods, particularly in terms of reduced soft label requirements.", "section": "1 Introduction"}, {"figure_path": "12A1RT1L87/figures/figures_1_1.jpg", "caption": "Figure 2: Visual comparison between SRe\u00b2L and the proposed method. The classes are hammer shark (top), pineapple (middle), and pomegranate (bottom). Our method is more visually diverse.", "description": "This figure compares the visual diversity of synthetic images generated by the SRe\u00b2L method and the proposed LPLD method.  Three classes are shown: hammer shark, pineapple, and pomegranate. Each class has multiple generated images displayed. The figure highlights that the LPLD method generates images with noticeably greater within-class diversity compared to SRe\u00b2L.", "section": "1 Introduction"}, {"figure_path": "12A1RT1L87/figures/figures_4_1.jpg", "caption": "Figure 4: Illustration of existing methods (left, grey) and the proposed method (right, blue). Existing methods (i.e., SRe\u00b2L, CDA) independently generate along the IPC (Image-Per-Class) dimension, causing a high similarity between images of the same class. The proposed method allows images of the same class to collaborate, leaving different classes naturally independent. In addition, synthetic images are updated under class-wise supervision. The classification loss is omitted for simplicity.", "description": "This figure compares the existing dataset distillation methods (SRe2L, CDA, SC-DD) with the proposed method (Ours) in terms of how synthetic images are generated and updated. Existing methods independently generate images per class, leading to high within-class similarity. In contrast, the proposed method re-batches images within the same class before generating them. This promotes collaboration among images of the same class, increasing within-class diversity. Additionally, the proposed method introduces class-wise supervision during the image synthesis process. The classification loss is omitted for simplicity in this illustration.", "section": "3 Method"}, {"figure_path": "12A1RT1L87/figures/figures_5_1.jpg", "caption": "Figure 5: Illustration of two random processes in label pruning with improved label pool. First, we need a smaller soft label pool due to the storage budget. We can conduct pruning at two levels: (1) epoch-level and (2) batch-level. Batch-level pruning can provide a more diverse label pool since augmentations (e.g., Mixup or CutMix) are different across batches. The illustrated pruning ratio is 25%; the crossed-out labels denote the pruned labels, and the remaining form the label pool. Second, we randomly sample soft labels for model training.", "description": "This figure illustrates the two-stage random pruning strategy used in the Label Pruning for Large-scale Distillation (LPLD) method.  First, the soft labels are pruned at the epoch level and the batch level to create a diverse and smaller pool. Then, a random subset of this label pool is selected for training each epoch. This helps manage memory constraints and enhance the diversity of training data.", "section": "3.3 Label Pruning for Large-scale Distillation (LPLD)"}, {"figure_path": "12A1RT1L87/figures/figures_23_1.jpg", "caption": "Figure 1: The relationship between performance and total storage of auxiliary information needed. Our method achieves SOTA performance with fewer soft labels than images.", "description": "This figure shows the relationship between the model's performance (accuracy) and the total storage required for both the images in the condensed dataset and the auxiliary soft labels.  Different methods for dataset distillation are compared, demonstrating that the proposed method achieves state-of-the-art (SOTA) performance while requiring significantly less storage for soft labels compared to the size of the condensed image dataset itself.  This highlights the effectiveness of the proposed label pruning technique in reducing storage needs without sacrificing accuracy.", "section": "1 Introduction"}, {"figure_path": "12A1RT1L87/figures/figures_24_1.jpg", "caption": "Figure 7: Visualization of Tiny-ImageNet. Images are randomly sampled.", "description": "This figure shows randomly sampled images from the Tiny-ImageNet dataset.  Two subfigures are presented, one for IPC50 (Images Per Class = 50) and another for IPC100 (Images Per Class = 100). Each subfigure displays a grid of synthesized images generated by the proposed method for dataset distillation. The visualization helps illustrate the within-class diversity achieved by the method in generating synthetic images.", "section": "F.2 Tiny-ImageNet"}, {"figure_path": "12A1RT1L87/figures/figures_24_2.jpg", "caption": "Figure 8: Visualization of ImageNet-21K-P. Images are randomly sampled.", "description": "This figure visualizes a random sample of images from the ImageNet-21K-P dataset at two different Images Per Class (IPC) values: 10 and 20.  The images are generated using the proposed Label Pruning for Large-scale Distillation (LPLD) method.  The visualization demonstrates the visual diversity achieved by LPLD, which is a key aspect of their method's success in reducing soft label storage.", "section": "F Visualization"}]