[{"figure_path": "3RxcarQFRn/tables/tables_8_1.jpg", "caption": "Table 1: Constrained Budget (k = 1) Oracle Evaluation Each method proposes a single design that is evaluated using the oracle function to report the final score (higher is better) across 10 random seeds reported as mean \u00b1 standard deviation. D (best) reports the top oracle value in the task dataset. Each of the MBO methods are ranked by their mean one-shot oracle score, and the average rank (lower is better) across all eight tasks is reported in the final table column. Bold (Underlined) entries indicate the best (second best) entry in the column. *Denotes the life sciences-related discrete MBO tasks from Design-Bench (Trabucco et al., 2022).", "description": "This table presents the results of a single-design evaluation (k=1) using eight different offline model-based optimization (MBO) methods across eight diverse tasks.  The table shows the mean and standard deviation of the oracle function scores for each method and task, and ranks the methods by average rank across all tasks.  The \"D (best)\" column shows the best oracle score observed in the dataset for each task.  A lower average rank indicates better performance.", "section": "5.2 Policy Optimization and Evaluation"}, {"figure_path": "3RxcarQFRn/tables/tables_8_2.jpg", "caption": "Table 1: Constrained Budget (k = 1) Oracle Evaluation Each method proposes a single design that is evaluated using the oracle function to report the final score (higher is better) across 10 random seeds reported as mean \u00b1 standard deviation. D (best) reports the top oracle value in the task dataset. Each of the MBO methods are ranked by their mean one-shot oracle score, and the average rank (lower is better) across all eight tasks is reported in the final table column. Bold (Underlined) entries indicate the best (second best) entry in the column. *Denotes the life sciences-related discrete MBO tasks from Design-Bench (Trabucco et al., 2022).", "description": "This table presents the results of evaluating different model-based optimization (MBO) methods on eight tasks using a constrained budget of one oracle query (k=1).  For each method and task, the table shows the mean and standard deviation of the top-1 oracle score over 10 random trials. The best performing method for each task is bolded.  The average rank across all eight tasks is also provided, with a lower average rank indicating better overall performance.  The tasks are diverse, spanning multiple domains and including several from the Design-Bench benchmark.", "section": "5.2 Policy Optimization and Evaluation"}, {"figure_path": "3RxcarQFRn/tables/tables_9_1.jpg", "caption": "Table 1: Constrained Budget (k = 1) Oracle Evaluation Each method proposes a single design that is evaluated using the oracle function to report the final score (higher is better) across 10 random seeds reported as mean \u00b1 standard deviation. D (best) reports the top oracle value in the task dataset. Each of the MBO methods are ranked by their mean one-shot oracle score, and the average rank (lower is better) across all eight tasks is reported in the final table column. Bold (Underlined) entries indicate the best (second best) entry in the column. *Denotes the life sciences-related discrete MBO tasks from Design-Bench (Trabucco et al., 2022).", "description": "This table presents the results of the constrained budget (k=1) oracle evaluation for eight different optimization tasks using various methods.  Each method proposes a single design, which is then evaluated using the oracle function (true objective function). The table shows the mean and standard deviation of the scores across 10 random trials for each method on each task.  The best observed score in each task's dataset is also included for comparison.  Methods are ranked based on average score across all tasks, and the best and second-best methods for each task are highlighted.", "section": "5.2 Policy Optimization and Evaluation"}, {"figure_path": "3RxcarQFRn/tables/tables_15_1.jpg", "caption": "Table 1: Constrained Budget (k = 1) Oracle Evaluation Each method proposes a single design that is evaluated using the oracle function to report the final score (higher is better) across 10 random seeds reported as mean \u00b1 standard deviation. D (best) reports the top oracle value in the task dataset. Each of the MBO methods are ranked by their mean one-shot oracle score, and the average rank (lower is better) across all eight tasks is reported in the final table column. Bold (Underlined) entries indicate the best (second best) entry in the column. *Denotes the life sciences-related discrete MBO tasks from Design-Bench (Trabucco et al., 2022).", "description": "This table presents the results of a constrained budget (k=1) oracle evaluation for eight different tasks. Each optimization method proposes a single design, and its score is evaluated using the oracle function.  The table shows the mean and standard deviation of the scores across 10 random trials, and ranks each method based on its average score across all tasks.  The best and second-best methods for each task are also highlighted.", "section": "5.2 Policy Optimization and Evaluation"}, {"figure_path": "3RxcarQFRn/tables/tables_15_2.jpg", "caption": "Table 1: Constrained Budget (k = 1) Oracle Evaluation Each method proposes a single design that is evaluated using the oracle function to report the final score (higher is better) across 10 random seeds reported as mean \u00b1 standard deviation. D (best) reports the top oracle value in the task dataset. Each of the MBO methods are ranked by their mean one-shot oracle score, and the average rank (lower is better) across all eight tasks is reported in the final table column. Bold (Underlined) entries indicate the best (second best) entry in the column. *Denotes the life sciences-related discrete MBO tasks from Design-Bench (Trabucco et al., 2022).", "description": "This table presents the results of the constrained budget (k=1) oracle evaluation for eight different optimization tasks.  For each task, multiple optimization methods are compared based on their average rank and the top-performing design's score using the oracle function.  Lower rank indicates better performance. The table includes the best oracle score observed in the dataset as a benchmark. The table highlights the best and second-best performing methods for each task.", "section": "5.2 Policy Optimization and Evaluation"}, {"figure_path": "3RxcarQFRn/tables/tables_16_1.jpg", "caption": "Table 1: Constrained Budget (k = 1) Oracle Evaluation Each method proposes a single design that is evaluated using the oracle function to report the final score (higher is better) across 10 random seeds reported as mean \u00b1 standard deviation.  D (best) reports the top oracle value in the task dataset. Each of the MBO methods are ranked by their mean one-shot oracle score, and the average rank (lower is better) across all eight tasks is reported in the final table column. Bold (Underlined) entries indicate the best (second best) entry in the column. *Denotes the life sciences-related discrete MBO tasks from Design-Bench (Trabucco et al., 2022).", "description": "This table presents the results of the constrained budget (k=1) oracle evaluation.  For each of eight tasks, multiple model-based optimization methods are compared based on their mean score, standard deviation, and average rank.  The best performing method for each task, and overall, is highlighted.", "section": "5.2 Policy Optimization and Evaluation"}, {"figure_path": "3RxcarQFRn/tables/tables_19_1.jpg", "caption": "Table 1: Constrained Budget (k = 1) Oracle Evaluation Each method proposes a single design that is evaluated using the oracle function to report the final score (higher is better) across 10 random seeds reported as mean \u00b1 standard deviation. D (best) reports the top oracle value in the task dataset. Each of the MBO methods are ranked by their mean one-shot oracle score, and the average rank (lower is better) across all eight tasks is reported in the final table column. Bold (Underlined) entries indicate the best (second best) entry in the column. *Denotes the life sciences-related discrete MBO tasks from Design-Bench (Trabucco et al., 2022).", "description": "This table presents the results of the one-shot (k=1) oracle evaluation for eight different tasks, comparing several model-based optimization (MBO) methods.  Each method proposes a single design, which is then evaluated using the true objective function (oracle).  The table shows the mean and standard deviation of the oracle scores across 10 random trials for each method and task.  The best performing method for each task is highlighted in bold, and the average rank across all tasks is included as a final measure of overall performance.", "section": "5.2 Policy Optimization and Evaluation"}, {"figure_path": "3RxcarQFRn/tables/tables_20_1.jpg", "caption": "Table 1: Constrained Budget (k = 1) Oracle Evaluation Each method proposes a single design that is evaluated using the oracle function to report the final score (higher is better) across 10 random seeds reported as mean \u00b1 standard deviation.  D (best) reports the top oracle value in the task dataset. Each of the MBO methods are ranked by their mean one-shot oracle score, and the average rank (lower is better) across all eight tasks is reported in the final table column. Bold (Underlined) entries indicate the best (second best) entry in the column. *Denotes the life sciences-related discrete MBO tasks from Design-Bench (Trabucco et al., 2022).", "description": "This table presents the results of a constrained budget (k=1) oracle evaluation for eight different model-based optimization (MBO) methods on eight benchmark tasks, including both continuous and discrete tasks from various scientific domains. For each task, the table shows the mean and standard deviation of the oracle score achieved by each method across 10 random trials. It also provides the best oracle score observed in the dataset and the average rank of each method across all tasks.  The table highlights the best-performing method for each task.", "section": "5.2 Policy Optimization and Evaluation"}, {"figure_path": "3RxcarQFRn/tables/tables_21_1.jpg", "caption": "Table 1: Constrained Budget (k = 1) Oracle Evaluation Each method proposes a single design that is evaluated using the oracle function to report the final score (higher is better) across 10 random seeds reported as mean \u00b1 standard deviation.  D (best) reports the top oracle value in the task dataset. Each of the MBO methods are ranked by their mean one-shot oracle score, and the average rank (lower is better) across all eight tasks is reported in the final table column. Bold (Underlined) entries indicate the best (second best) entry in the column. *Denotes the life sciences-related discrete MBO tasks from Design-Bench (Trabucco et al., 2022).", "description": "This table presents the results of the constrained budget (k=1) oracle evaluation.  For eight different tasks, various model-based optimization (MBO) methods proposed a single design.  The table shows the mean and standard deviation of the oracle scores achieved across 10 random trials. The best oracle score from the dataset is included for comparison. Methods are ranked by their average performance across all eight tasks, providing a comprehensive comparison of their effectiveness in this offline optimization scenario.", "section": "5.2 Policy Optimization and Evaluation"}, {"figure_path": "3RxcarQFRn/tables/tables_21_2.jpg", "caption": "Table 1: Constrained Budget (k = 1) Oracle Evaluation Each method proposes a single design that is evaluated using the oracle function to report the final score (higher is better) across 10 random seeds reported as mean \u00b1 standard deviation.  D (best) reports the top oracle value in the task dataset. Each of the MBO methods are ranked by their mean one-shot oracle score, and the average rank (lower is better) across all eight tasks is reported in the final table column. Bold (Underlined) entries indicate the best (second best) entry in the column. *Denotes the life sciences-related discrete MBO tasks from Design-Bench (Trabucco et al., 2022).", "description": "This table presents the results of the constrained budget (k=1) oracle evaluation for eight different model-based optimization (MBO) tasks.  Each method proposes a single design, which is then evaluated using the oracle function. The table shows the mean and standard deviation of the scores across 10 random seeds, along with the best observed score from the dataset. Methods are ranked according to their average score across the tasks.  The table is broken down by task, with each having its best and second-best performing methods highlighted.", "section": "5.2 Policy Optimization and Evaluation"}, {"figure_path": "3RxcarQFRn/tables/tables_22_1.jpg", "caption": "Table B7: Computational Tractability Runtimes on a single node using one NVIDIA RTX A6000 GPU are averaged across 10 random seeds and reported as mean \u00b1 standard deviation.", "description": "This table shows the computational cost of running the algorithms. It compares the runtime of gradient ascent (Grad.), Generative Adversarial Gradient Ascent (GAGA), Bayesian optimization (BO), and Generative Adversarial Bayesian Optimization (GABO) on the Branin and Penalized LogP tasks. The percent increase in runtime when using Adaptive Source Critic Regularization (aSCR) is also shown.  The table highlights that while aSCR adds computational cost, the increase is less significant for the more complex LogP task, suggesting that the added cost is worthwhile for real-world applications.", "section": "B Additional Experimental Results"}]