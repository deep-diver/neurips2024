[{"type": "text", "text": "Out-of-Distribution Detection with a Single Unconditional Diffusion Model ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Alvin Heng1, Alexandre H. Thiery2, Harold Soh1,3 ", "page_idx": 0}, {"type": "text", "text": "1Department of Computer Science, National University of Singapore 2Department of Statistics and Data Science, National University of Singapore 3Smart Systems Institute, National University of Singapore {alvinh, harold}@comp.nus.edu.sg ", "page_idx": 0}, {"type": "text", "text": "Abstract ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Out-of-distribution (OOD) detection is a critical task in machine learning that seeks to identify abnormal samples. Traditionally, unsupervised methods utilize a deep generative model for OOD detection. However, such approaches require a new model to be trained for each inlier dataset. This paper explores whether a single model can perform OOD detection across diverse tasks. To that end, we introduce Diffusion Paths (DiffPath), which uses a single diffusion model originally trained to perform unconditional generation for OOD detection. We introduce a novel technique of measuring the rate-of-change and curvature of the diffusion paths connecting samples to the standard normal. Extensive experiments show that with a single model, DiffPath is competitive with prior work using individual models on a variety of OOD tasks involving different distributions. Our code is publicly available at https://github.com/clear-nus/diffpath. ", "page_idx": 0}, {"type": "text", "text": "1 Introduction ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Out-of-distribution (OOD) detection, also known as anomaly or outlier detection, seeks to detect abnormal samples that are far from a given distribution. This is a vital problem as deep neural networks are known to be overconfident when making incorrect predictions on outlier samples [1, 2], leading to potential issues in safety-critical applications such as robotics, healthcare, finance, and criminal justice [3]. Traditionally, OOD detection using only unlabeled data relies on training a generative model on in-distribution data. Thereafter, measures such as model likelihood or its variants are used as an OOD detection score [4\u20136]. An alternative approach is to utilize the excellent sampling capabilities of diffusion models (DMs) to reconstruct corrupted samples, and use the reconstruction loss as an OOD measure [7\u20139]. ", "page_idx": 0}, {"type": "text", "text": "However, these conventional methods require separate generative models tailored to specific inlier distributions and require retraining if the inlier data changes, such as in continual learning setups. This prompts the question: can OOD detection be performed using a single generative model? We answer in the affirmative and present Diffusion Paths (DiffPath) in this paper. While the use of a single model for OOD detection has been proposed in the discriminative setting [10], to the best of our knowledge, we are the first to explore this for generative models. We believe that the generative setting is particularly salient in light of recent trends where single generative foundation models are utilized across various tasks [11, 12]. ", "page_idx": 0}, {"type": "text", "text": "Our method utilizes a single pretrained DM. In a departure from prior works that utilize variants of likelihoods [6, 5, 4] or reconstruction losses [7\u20139], we propose to perform OOD detection by measuring characteristics of the forward diffusion trajectory, specifically its rate-of-change and curvature, which can be computed from the score predicted by the diffusion model. We provide theoretical and empirical analyses that motivate these quantities as useful OOD detectors; their magnitudes are similar for samples from the same distribution and different otherwise. We summarize our contributions as follows: ", "page_idx": 0}, {"type": "text", "text": "", "page_idx": 1}, {"type": "text", "text": "1. We introduce a novel approach to OOD detection by examining the rate-ofchange and curvature along the diffusion path connecting different distributions to standard normal.   \n2. Through comprehensive experiments with various datasets, we show that a single generative model is competitive with baselines that necessitates separate models for each distribution.   \n3. We offer a theoretical framework demonstrating that our method characterizes properties of the optimal transport (OT) path between the data distribution and the standard normal. ", "page_idx": 1}, {"type": "image", "img_path": "tTnFH7D1h4/tmp/792fa3c16dfa8490b8082ec4857255a16a673d13555b452a90fa5762f9e68a05.jpg", "img_caption": ["Figure 1: Illustration of the diffusion paths of samples from two different distributions (CIFAR10 and SVHN) obtained via DDIM integration. The paths have different first and second derivatives (rate-ofchange and curvature). We propose to measure these quantities for OOD detection. "], "img_footnote": [], "page_idx": 1}, {"type": "text", "text": "2 Background ", "text_level": 1, "page_idx": 1}, {"type": "text", "text": "Score-based Diffusion Models. Let $p_{0}(\\mathbf{x})$ denote the data distribution. We define a stochastic differential equation (SDE), also known as the forward process, to diffuse $p_{0}(\\mathbf{x})$ to a noise distribution $p_{T}(\\mathbf{x})$ : ", "page_idx": 1}, {"type": "equation", "text": "$$\n\\mathrm{d}\\mathbf{x}_{t}=f(\\mathbf{x}_{t},t)\\mathrm{d}t+g(t)\\mathrm{d}\\mathbf{w}_{t},\\ \\ \\mathbf{x}_{0}\\sim p_{0}(\\mathbf{x})\n$$", "text_format": "latex", "page_idx": 1}, {"type": "text", "text": "where $\\pmb{f}(\\cdot,t):\\mathbb{R}^{D}\\rightarrow\\mathbb{R}^{D}$ is the drift coefficient, $g(t)\\in\\mathbb{R}$ is the diffusion coefficient and $\\mathbf{w}_{t}\\in\\mathbb{R}^{D}$ is the standard Wiener process (Brownian motion). We denote $p_{t}$ as the marginal distribution of Eq. 1 at time $t$ . By starting from noise samples $\\mathbf{x}_{T}\\sim p_{T}$ , new samples $\\mathbf{x}_{0}\\sim p_{0}(\\mathbf{x})$ can be sampled by simulating the reverse SDE ", "page_idx": 1}, {"type": "equation", "text": "$$\n\\mathrm{d}\\mathbf{x}_{t}=[\\mathbf{f}(\\mathbf{x}_{t},t)-g(t)^{2}\\nabla_{\\mathbf{x}}\\log p_{t}(\\mathbf{x}_{t})]\\mathrm{d}t+g(t)\\mathrm{d}\\bar{\\mathbf{w}}_{t},\\ \\ \\mathbf{x}_{T}\\sim p_{T}(\\mathbf{x})\n$$", "text_format": "latex", "page_idx": 1}, {"type": "text", "text": "where $\\bar{\\bf w}_{t}$ is the standard Wiener process when time flows backwards from $T$ to 0, and $\\mathrm{d}t$ is an infinitesimal negative timestep. The diffusion process described by Eq. 1 also has an equivalent ODE formulation, termed the probability flow (PF) ODE [13], given by ", "page_idx": 1}, {"type": "equation", "text": "$$\n\\mathrm{d}\\mathbf{x}_{t}=\\left[\\pmb{f}(\\mathbf{x}_{t},t)-\\frac{1}{2}g(t)^{2}\\nabla_{\\mathbf{x}}\\log p_{t}(\\mathbf{x}_{t})\\right]\\mathrm{d}t.\n$$", "text_format": "latex", "page_idx": 1}, {"type": "text", "text": "The ODE and SDE formulations are equivalent in the sense that trajectories under both processes share the same marginal distribution $p_{t}(\\mathbf{x}_{t})$ . Hence, given an estimate of the score function $s_{\\theta}(\\mathbf{x}_{t},t)\\approx$ $\\nabla_{\\mathbf{x}}\\log p_{t}(\\mathbf{x}_{t})$ , which can be obtained using score-matching approaches [14, 13], one can sample from the diffusion model by solving the reverse SDE or integrating the PF ODE backwards in time. ", "page_idx": 1}, {"type": "text", "text": "In this work, we focus on the variance-preserving formulation used in DDPM [15], which is given by an Ornstein-Uhlenbeck forward process ", "page_idx": 1}, {"type": "equation", "text": "$$\n\\mathrm{d}\\mathbf{x}_{t}=-\\frac{1}{2}\\beta_{t}\\mathbf{x}_{t}\\mathrm{d}t+\\sqrt{\\beta_{t}}\\mathrm{d}\\mathbf{w}_{t},\\ \\ \\mathbf{x}_{0}\\sim p_{0}(\\mathbf{x})\n$$", "text_format": "latex", "page_idx": 1}, {"type": "text", "text": "where $\\beta_{t}$ are time-dependent constants. Under Eq. 4, diffused samples $\\mathbf{x}_{t}$ can be sampled analytically via $p_{t}(\\mathbf{x}_{t}|\\mathbf{x}_{0})=\\mathcal{N}(\\mathbf{x}_{t};\\sqrt{\\bar{\\alpha}_{t}}\\mathbf{x}_{0},\\sigma_{t}^{2}\\mathbf{I})$ , where $\\begin{array}{r}{\\beta_{t}=-\\frac{\\mathrm{d}}{\\mathrm{d}t}\\log\\bar{\\alpha}_{t}}\\end{array}$ and $\\sigma_{t}^{2}=1-\\bar{\\alpha}_{t}$ . The score estimator, $\\begin{array}{r}{\\epsilon_{\\theta}(\\mathbf{x}_{t},t)\\approx-\\sigma_{t}\\nabla_{\\mathbf{x}}\\log p_{t}(\\mathbf{x}_{t})}\\end{array}$ , can be trained via the following objective ", "page_idx": 1}, {"type": "equation", "text": "$$\n\\operatorname*{min}_{\\theta}\\mathbb{E}_{t\\sim\\mathcal{U}[0,1]\\mathbf{x}_{0}\\sim p_{0}(\\mathbf{x}_{0})\\mathbf{x}_{t}\\sim p_{t}(\\mathbf{x}_{t}|\\mathbf{x}_{0})}\\left[\\left\\|\\epsilon_{\\theta}(\\mathbf{x}_{t},t)-\\epsilon\\right\\|_{2}^{2}\\right],\n$$", "text_format": "latex", "page_idx": 1}, {"type": "text", "text": "where $\\begin{array}{r}{\\epsilon=-\\sigma_{t}\\nabla_{\\mathbf x}\\log p_{t}(\\mathbf x_{t}|\\mathbf x_{0})=(\\mathbf x_{t}-\\sqrt{\\bar{\\alpha}}_{t}\\mathbf x_{0})/\\sigma_{t}.}\\end{array}$ ", "page_idx": 1}, {"type": "image", "img_path": "tTnFH7D1h4/tmp/bfb30750ef3819e39c0a8fd62c707817193e58ca741c5ae140608897c71c4208.jpg", "img_caption": ["Figure 2: Histograms of various statistics of the respective training sets. The NLL is calculated using a diffusion model trained on CIFAR10, while the other two statistics are calculated with a model trained on ImageNet. "], "img_footnote": [], "page_idx": 2}, {"type": "text", "text": "Unsupervised OOD Detection. Given a distribution of interest $p(\\mathbf x)$ , the goal of OOD detection is to construct a scoring function which outputs a quantity $S_{\\theta}(\\mathbf{x})\\in\\mathbb{R}$ that identifies if a given test point $\\mathbf{x}_{\\mathrm{test}}$ is from $p(\\mathbf x)$ . In this work, a higher value of $S_{\\theta}(\\mathbf{x}_{\\mathrm{test}})$ indicates that the sample is more likely to be drawn from $p(\\mathbf{x})$ . We will use the notation \u201cA vs $\\mathbf{B}^{\\bullet}$ to denote the task of distinguishing samples between A and B, where A is the inlier distribution and B is the outlier distribution. In unsupervised OOD detection, one must construct the function $S_{\\theta}$ using only knowledge of A. ", "page_idx": 2}, {"type": "text", "text": "3 Diffusion Models for OOD Detection ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "An overview of our method, DiffPath, is illustrated in Fig. 1. DiffPath is based on the insight that the rate-of-change and curvature of the diffusion path connecting samples to standard normal differ between distributions, making them effective indicators for OOD detection. This section outlines the methodology behind DiffPath. We begin in Sec. 3.1, where we provide evidence that likelihoods from a diffusion model are insufficient for OOD detection. Next, Sec. 3.2 shows that the score function is a measure of the rate-of-change and motivates the use of a single generative model. We then motivate the curvature as the derivative of the score in Sec. 3.3. We consider the curvature statistic as one variation of our method and abbreviate it as DiffPath-1D. In Sec. 3.4, we contextualize our method in terms of the optimal transport path between samples and standard normal, and finally propose a higher-order, hybrid variation called DiffPath-6D in Sec. 3.5, which incorporates both the rate-of-change and curvature quantities. ", "page_idx": 2}, {"type": "text", "text": "3.1 Diffusion Model Likelihoods Do Not Work for OOD Detection ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "When leveraging a likelihood-based generative model for OOD detection, the most natural statistic to consider is the likelihood itself. As DMs are trained to maximize the evidence lower bound (ELBO) of the data, one would expect that in-distribution samples have higher ELBO under the model compared to out-of-distribution samples. However, prior works [2, 16] have shown that the opposite behavior was observed in deep generative models, such as normalizing flows, where the model assigned higher likelihoods to OOD samples. ", "page_idx": 2}, {"type": "text", "text": "In Fig. 2, we plot the distributions of the negative ELBO (denoted NLL) of the CIFAR10 and SVHN training sets for a DM trained on CIFAR10. Our results corroborate earlier findings that likelihoods are not good OOD detectors; the NLL of CIFAR10 samples are higher than SVHN samples, meaning in-distribution samples have lower likelihoods than out-of-distribution samples. The poor AUROC score in Table 1 quantitatively demonstrates the inability of likelihoods to distinguish between inlier and outlier samples. This motivates us to search for better statistics that we can extract from DMs for OOD detection. ", "page_idx": 2}, {"type": "text", "text": "3.2 Scores as an OOD Statistic ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "Scores as KL Divergence Proxy. We start by rewriting the PF ODE, Eq. 3, in the following form: ", "page_idx": 2}, {"type": "equation", "text": "$$\n\\frac{\\mathrm{d}\\mathbf{x}_{t}}{\\mathrm{d}t}=f(\\mathbf{x}_{t},t)+\\frac{g(t)^{2}}{2\\sigma_{t}}\\epsilon_{p}(\\mathbf{x}_{t},t)\n$$", "text_format": "latex", "page_idx": 2}, {"type": "image", "img_path": "tTnFH7D1h4/tmp/0a2bd7ddee801610daab75843d32fe5c59377de32863725d5f5740c55a1cfab9.jpg", "img_caption": ["Figure 3: Illustration of the forward integration of Eq. 7 on samples from CIFAR10, SVHN and CelebA. Both the ImageNet and CelebA models are able bring the samples approximately to standard normal. Other than the case where the CelebA model is used to integrate CelebA samples (last row of the right figure), the samples shown here have not been seen by the models during training. While in certain cases the end result appears to contain features of the original image, thus deviating from an isotropic Gaussian (e.g., first row of the right figure), empirically we find that the scores remain accurate enough for outlier detection; see Sec. 5 for quantitative results. "], "img_footnote": [], "page_idx": 3}, {"type": "text", "text": "where we have parameterized the score as $\\begin{array}{r}{\\epsilon_{p}(\\mathbf{x}_{t},t)=-\\sigma_{t}\\nabla_{\\mathbf{x}}\\log p_{t}(\\mathbf{x}).}\\end{array}$ ", "page_idx": 3}, {"type": "text", "text": "Theorem 1. Denote $\\phi_{t}$ and $\\psi_{t}$ as the marginals from evolving two distinct distributions $\\phi_{0}$ and $\\psi_{0}$ via their respective probability flow ODEs (Eq. 6) forward in time. We consider the case with the same forward process, i.e., the two PF ODEs have the same $f(\\mathbf{x}_{t},t),g(t)$ and $\\sigma_{t}$ . Under some regularity conditions stated in Appendix A.1, ", "page_idx": 3}, {"type": "equation", "text": "$$\nD_{\\mathrm{KL}}(\\phi_{0}\\|\\psi_{0})=\\frac{1}{2}\\int_{0}^{T}\\mathbb{E}_{\\mathbf{x}\\sim\\phi_{t}}\\frac{g(t)^{2}}{\\sigma_{t}}\\left\\|\\epsilon_{\\phi}(\\mathbf{x}_{t},t)-\\epsilon_{\\psi}(\\mathbf{x}_{t},t)\\right\\|_{2}^{2}\\mathrm{d}t+D_{\\mathrm{KL}}(\\phi_{T}\\|\\psi_{T}).\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "The term $D_{\\mathrm{KL}}(\\phi_{T}\\|\\psi_{T})$ vanishes as $\\phi_{T}=\\psi_{T}=\\mathcal{N}(\\mathbf{0},\\mathbf{I})$ by construction, assuming the true scores are available. In practice, we rely on a score estimator $\\epsilon_{\\theta}$ obtained via score matching approaches. Theorem 1 suggests that the scores of the marginal distributions along the ODE path serve as a proxy for the KL divergence: as $D_{\\mathrm{KL}}(\\phi_{0}\\Vert\\psi_{0})$ increases, so should the difference in the norms of their scores. Another interpretation is that this difference, $\\mathbb{E}[\\|\\epsilon_{\\phi}(\\mathbf{x}_{t},t)-\\epsilon_{\\psi}(\\mathbf{x}_{t},t)\\|_{2}^{2}]$ , is a measure of the Fisher divergence between the two distributions, which forms the foundation for score matching [17]. This motivates using the norm of the scores as a statistic for distinguishing two distributions. ", "page_idx": 3}, {"type": "text", "text": "However, Theorem 1 is not immediately useful as it requires a priori knowledge of both distributions, whereas in unsupervised OOD detection, only knowledge of the inlier distribution is available. Interestingly, we empirically observe that it is possible to approximate the forward probability flow ODE for different distributions using a single diffusion model. Recall that as the PF ODE has the same marginal as the forward SDE, if the score estimate $\\epsilon_{\\theta}$ has converged to the true score, then forward integration of a sample $\\mathbf{x}_{\\mathrm{0}}$ using Eq. 6 should bring the sample to approximately standard normal, $\\mathbf{x}_{T}\\sim\\mathcal{N}(\\mathbf{0},\\mathbf{I})$ . ", "page_idx": 3}, {"type": "text", "text": "Specifically, we consider the following parameterization [18] of the PF ODE ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\mathrm{d}\\bar{\\mathbf{x}}_{t}=\\epsilon_{\\theta}(\\mathbf{x}_{t},t)\\mathrm{d}\\gamma_{t}\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "where \u03b3t = $\\begin{array}{r}{\\gamma_{t}\\,=\\,\\sqrt{\\frac{1-\\bar{\\alpha}_{t}^{2}}{\\bar{\\alpha}_{t}}}}\\end{array}$ and $\\bar{\\mathbf{x}}_{t}\\,=\\,\\mathbf{x}_{t}\\sqrt{1+\\gamma_{t}^{2}}$ . Let $\\epsilon_{\\theta}(\\mathbf{x}_{t},t)\\,=\\,-\\sigma_{t}\\nabla_{\\mathbf{x}}\\log p_{t}(\\mathbf{x})$ be a score model trained on $p_{0}(\\mathbf{x})$ . It is known that the DDIM sampler [19] is Euler\u2019s method applied to Eq. 7. In Fig. 3, we integrate Eq. 7 forward in time using DDIM for samples from various distributions, most of which are unseen by the model during training. Qualitatively, we observe the surprising fact that both the ImageNet and CelebA models are able to bring the samples approximately to the standard normal. We ablate the choice of $p_{0}$ in Sec. 5.2. ", "page_idx": 3}, {"type": "text", "text": "This motivates $\\epsilon_{\\theta}$ as a replacement for arbitrary $\\epsilon_{\\phi}$ when integrating Eq. 7 forward with samples from $\\phi_{0}$ . In Fig. 2, we see that the distributions of $\\sqrt{\\sum_{t}\\left\\|\\epsilon_{\\theta}(\\mathbf{x}_{t},t)\\right\\|_{2}^{2}}$ , the square root of the sum of $L^{2}$ norms of scores over time, applied to the two datasets using a single model trained on ImageNet are better separated than the likelihoods. Note that Theorem 1 tells us only that the score norms of inlier and outlier samples are different, not whether one is higher or lower than the other. Thus, we propose the following OOD detection scheme: fti a Kernel Density Estimator (KDE) to $\\sqrt{\\sum_{t}\\left\\|\\epsilon_{\\theta}(\\mathbf{x}_{t},t)\\right\\|_{2}^{2}}$ of the training set for a given distribution, then use the KDE likelihoods of a test sample as the OOD score ", "page_idx": 3}, {"type": "table", "img_path": "tTnFH7D1h4/tmp/951060a17fb71231b6c762d039a4d7f58a9a55806accebf8a459135be26b2202.jpg", "table_caption": [], "table_footnote": [], "page_idx": 4}, {"type": "text", "text": "$S_{\\theta}$ . This way, the likelihoods of outlier samples under the KDE are lower than for inlier samples, allowing us to compute the AUROC. We provide pseudocode in Algorithm 1. With this scheme, the AUROC scores in Table 1 show a large improvement over likelihoods; however, we would like to pursue even better OOD statistics, which we discuss in Sec. 3.3. ", "page_idx": 4}, {"type": "text", "text": "Score as First-Order Taylor Expansion. We provide a second interpretation of the score, and subsequently motivate a new statistic that can be used for OOD detection. Recall that the numerical DDIM solver is the first-order Euler\u2019s method applied to Eq. 7. In general, we can expand the ODE to higher-order terms using the truncated Taylor method [20, 18]: ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\bar{\\mathbf{x}}_{t_{n+1}}=\\bar{\\mathbf{x}}_{t_{n}}+h_{n}\\frac{\\mathrm{d}\\bar{\\mathbf{x}}_{t}}{\\mathrm{d}\\gamma_{t}}\\big|_{(\\bar{\\mathbf{x}}_{t_{n}},t_{n})}+\\frac{1}{2!}h_{n}^{2}\\frac{\\mathrm{d}^{2}\\bar{\\mathbf{x}}_{t}}{\\mathrm{d}\\gamma_{t}^{2}}\\big|_{(\\bar{\\mathbf{x}}_{t_{n}},t_{n})}+\\dots}\\\\ {=\\bar{\\mathbf{x}}_{t_{n}}+h_{n}\\epsilon_{\\theta}(\\mathbf{x}_{t_{n}},t_{n})+\\frac{1}{2!}h_{n}^{2}\\frac{\\mathrm{d}\\epsilon_{\\theta}}{\\mathrm{d}\\gamma_{t}}\\big|_{(\\bar{\\mathbf{x}}_{t_{n}},t_{n})}+\\dots}\\end{array}\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "where $h_{n}=\\gamma_{t_{n+1}}-\\gamma_{t_{n}}$ . The norm of the first-order score, ${\\|\\epsilon_{\\theta}\\|}_{2}$ , therefore measures the rate-ofchange of the ODE integration path. Intuitively, the ODE integration path necessary to bring different distributions to the standard normal in finite time differs (c.f. the PF ODE path is also the optimal transport path, see Sec. 3.4) , hence the rate-of-change differs as well. ", "page_idx": 4}, {"type": "text", "text": "3.3 Second-Order Taylor Expansion (DiffPath-1D) ", "text_level": 1, "page_idx": 4}, {"type": "text", "text": "Based on the preceding discussion, it is natural to consider if higher-order terms in the ODE Taylor expansion can also serve as an effective OOD statistic. We answer in the affirmative by considering the second order term, dd\u03f5\u03b3\u03b8t . Intuitively, the second-order term measures the curvature of the ODE integration path. We expand the derivative as follows [18]: ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\displaystyle\\frac{\\mathrm{d}\\epsilon_{\\theta}}{\\mathrm{d}\\gamma_{t}}=\\frac{\\partial\\epsilon_{\\theta}(\\mathbf{x}_{t},t)}{\\partial\\mathbf{x}_{t}}\\frac{\\mathrm{d}\\mathbf{x}_{t}}{\\mathrm{d}\\gamma_{t}}+\\frac{\\partial\\epsilon_{\\theta}(\\mathbf{x}_{t},t)}{\\partial t}\\frac{\\mathrm{d}t}{\\mathrm{d}\\gamma_{t}}}\\\\ &{\\displaystyle\\qquad=\\frac{1}{\\sqrt{\\gamma_{t}^{2}+1}}\\underbrace{\\frac{\\partial\\epsilon_{\\theta}(\\mathbf{x}_{t},t)}{\\partial\\mathbf{x}_{t}}\\epsilon_{\\theta}(\\mathbf{x}_{t},t)}_{\\mathrm{JVP}}-\\frac{\\gamma_{t}}{1+\\gamma_{t}^{2}}\\underbrace{\\frac{\\partial\\epsilon_{\\theta}(\\mathbf{x}_{t},t)}{\\partial\\mathbf{x}_{t}}\\mathbf{x}_{t}}_{\\mathrm{JVP}}+\\frac{\\partial\\epsilon_{\\theta}(\\mathbf{x}_{t},t)}{\\partial t}\\frac{\\mathrm{d}t}{\\mathrm{d}\\gamma_{t}}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "We see that the derivative contains two Jacobian-Vector Products (JVP) and a simple time derivative term. In principle, all three terms can be computed using automatic differentiation. However, this makes inference twice as costly due to the need for an additional backward pass after every forward pass of the network, and significantly more memory-intensive due to storage of the full computation graph. Fortunately, the time derivative term can be computed using simple finite difference: ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\frac{\\partial\\epsilon_{\\theta}(\\mathbf{x}_{t},t)}{\\partial t}\\approx\\frac{\\epsilon_{\\theta}(\\mathbf{x}_{t+\\Delta t},t+\\Delta t)-\\epsilon_{\\theta}(\\mathbf{x}_{t},t)}{\\Delta t}\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "where the pairs $(\\mathbf{x}_{t},\\mathbf{x}_{t+\\Delta t})$ are obtained during standard DDIM integration. Thus, no additional costs associated with gradient computation are incurred. ", "page_idx": 4}, {"type": "text", "text": "Surprisingly, we observe that for high-dimensional distributions such as images that we consider in this work, the time derivative in Eq. 10 alone provides an accurate enough estimate for OOD detection. Using the same ImageNet model as in Sec. 3.2, we observe an improvement in AUROC scores in CIFAR10 vs SVHN in Table 1 when using the second-order statistic. Qualitatively, the distributions of $\\sqrt{\\sum_{t}\\|\\partial_{t}\\epsilon_{\\theta}(\\mathbf{x}_{t},t)\\|_{2}^{2}}$ are more spread out in Fig. 2 as compared to the first-order scores, although the distinction is subtle; the quantitative results provide a more reliable confirmation of the benefit of using the second-order statistic. ", "page_idx": 4}, {"type": "text", "text": "", "page_idx": 5}, {"type": "text", "text": "We thus consider the second-order statistic alone, $\\sqrt{\\sum_{t}\\|\\partial_{t}\\epsilon_{\\theta}(\\mathbf{x}_{t},t)\\|_{2}^{2}}$ , as a possible statistic for OOD detection. As it is a one-dimensional quantity, we abbreviate it as DiffPath-1D. We evaluate DiffPath1D in Sec. 5.2. ", "page_idx": 5}, {"type": "text", "text": "3.4 Connections to Optimal Transport ", "text_level": 1, "page_idx": 5}, {"type": "text", "text": "Recent works have viewed DDIM integration as an encoder that maps the data distribution to standard normal [21, 22]. They prove that this map is the optimal transport (OT) path if the data distribution is Gaussian, while providing numerical results suggesting likewise for high-dimensional data like images. As a result, we can view the OOD statistics proposed in Sec. 3.2 and Sec. 3.3 as characterizing different derivatives of the OT path: the score ${\\|\\pmb{\\epsilon}_{\\theta}\\|}_{2}$ represents the rate-of-change of the path, while the time derivative $\\lVert\\partial_{t}\\epsilon_{\\theta}\\rVert_{2}$ represents its curvature. ", "page_idx": 5}, {"type": "text", "text": "To justify our proposition that derivatives of OT paths serve as meaningful OOD statistics, we consider the following toy example [21] of distinguishing two multivariate Gaussians (detailed derivation in Appendix A.2). Let the distributions be $\\bar{p_{0}^{i}}(\\mathbf{x})\\sim\\bar{\\mathcal{N}}(\\mathbf{a}_{i},\\mathbf{I}),i\\in\\{0,1\\}$ , where $\\mathbf{a}_{i}\\in\\mathbb{R}^{d}$ and $\\mathbf{I}\\in\\mathbb{R}^{d\\times d}$ . The marginal densities along the forward diffusion can be computed exactly using the transition formulas for SDEs [23] and is given by $p_{t}^{i}(\\mathbf{x})\\sim\\mathcal{N}(\\mathbf{a}_{i}e^{-t},\\mathbf{I})$ , with PF ODE $\\begin{array}{r}{\\frac{\\mathrm{d}\\mathbf{x}_{i}}{\\mathrm{d}t}=-\\mathbf{a}_{i}e^{-t}}\\end{array}$ . This path corresponds exactly to the OT map between $p_{0}^{i}$ and $\\mathcal{N}(\\mathbf{0},\\mathbf{I})$ . In this case, the corresponding first and second-order OOD statistics are equal and given by $\\begin{array}{r}{\\left\\|\\frac{\\mathrm{d}\\mathbf{x}_{i}}{\\mathrm{d}t}\\right\\|_{2}=\\left\\|\\frac{\\mathrm{d}^{2}\\mathbf{x}_{i}}{\\mathrm{d}t^{2}}\\right\\|_{2}=\\left\\|\\mathbf{a}_{i}e^{-t}\\right\\|_{2}}\\end{array}$ . Crucially, they are proportional to $\\lVert\\mathbf{a}_{i}\\rVert_{2}$ , meaning that as the two distributions move farther apart (i.e., as $\\lVert{\\bf a}_{0}-{\\bf a}_{1}\\rVert_{2}$ increases), so should the $L^{2}$ norms of the OOD statistics, thereby increasing their ability to distinguish samples between the two. ", "page_idx": 5}, {"type": "text", "text": "3.5 Higher-dimensional Statistic (DiffPath-6D) ", "text_level": 1, "page_idx": 5}, {"type": "table", "img_path": "tTnFH7D1h4/tmp/460011b8e4e3ac2fd26585b40083599f83c0ef5bee64d6356d6345f638026368.jpg", "table_caption": ["Table 2: AUROC of DiffPath 1D vs 6D. "], "table_footnote": [], "page_idx": 5}, {"type": "text", "text": "Owing to its simplicity, the one-dimensional statistic proposed in Sec. 3.3 may suffer from edge cases or perform suboptimally as information is condensed to a single scalar. For instance, given an image $\\mathbf{x}_{\\mathrm{0}}$ with pixels normalized to the range $[-1,1]$ , one such edge case is distinguishing $\\mathbf{x}_{\\mathrm{0}}$ from itself with the sign of the pixels filpped, $-\\mathbf{x}_{\\mathrm{0}}$ . The two samples will produce symmetric OT paths differing only by a negative sign, resulting in identical statistics after taking the $L^{2}$ norm. We can see this from Table 2 where DiffPath-1D fails to distinguish CIFAR10 samples from itself with signs filpped, which we call negative CIFAR10. As such, we propose a higher-dimensional statistic that does not utilize the standard form of the $L^{p}$ norm: $\\begin{array}{r}{\\|\\mathbf{x}\\|_{p}=\\sum_{i}|\\mathbf{x}_{i}|^{p}}\\end{array}$ . We define a new scalar quantity, $\\begin{array}{r}{\\langle\\mathbf{x}\\rangle_{p}=\\sum_{i}(\\mathbf{x}_{i})^{p}}\\end{array}$ , which retains the sign information, and propose a new six-dimensional statistic we dub Dif fPath-6D: ", "page_idx": 5}, {"type": "text", "text": "", "page_idx": 5}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\Big[\\sum_{t}\\langle\\epsilon_{\\theta}({\\bf x}_{t},t)\\rangle_{1},\\sum_{t}\\langle\\epsilon_{\\theta}({\\bf x}_{t},t)\\rangle_{2},\\sum_{t}\\langle\\epsilon_{\\theta}({\\bf x}_{t},t)\\rangle_{3},\\sum_{t}\\langle\\partial_{t}\\epsilon_{\\theta}({\\bf x}_{t},t)\\rangle_{1},\\sum_{t}\\langle\\partial_{t}\\epsilon_{\\theta}({\\bf x}_{t},t)\\rangle_{2},\\sum_{t}\\langle\\partial_{t}\\epsilon_{\\theta}({\\bf x}_{t},t)\\rangle_{3}\\Big]^{\\top}}\\end{array}\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "which concatenates scalars based on the first, second and third powers of $\\epsilon_{\\theta}$ and $\\partial_{t}\\epsilon_{\\theta}$ into a vector. From Table 2, DiffPath-6D is able to distinguish CIFAR10 from neg. CIFAR10 near perfectly. We validate both DiffPath-1D and DiffPath-6D on a wider suite of experiments in Sec. 5. ", "page_idx": 5}, {"type": "text", "text": "4 Related Works ", "text_level": 1, "page_idx": 5}, {"type": "text", "text": "Modern OOD detection can be divided roughly into three categories: feature-based, likelihood-based, reconstruction-based. Feature-based methods extract features from inlier samples and fti a likelihood or distance function as an OOD detector. For instance, one can obtain the latent representations of a test sample using an autoencoder and measure its Mahalanobis distance to the representations of inlier samples [24]. Distances between features derived from self-supervised learning models are also utilized in similar contexts [25, 26]. Similar to our work, Xiao et al. [10] showed that one can perform OOD detection using features from a single discriminative model. ", "page_idx": 5}, {"type": "text", "text": "", "page_idx": 6}, {"type": "text", "text": "Likelihood-based approaches leverage a generative model trained on inlier samples. These methods typically employ variants of the log-likelihood of a test sample under the model as the OOD detection score. Nalisnick et al. [2] first pointed out that deep generative models might erroneously assign higher likelihoods to outlier samples. Several explanations have been proposed, such as the input complexity [16] and typicality [27] of samples. As a result, just as we show in Sec. 3.1, vanilla likelihoods are rarely used. Instead, variants derived from the log-likelihood have been proposed, such as likelihood ratios [4], ensembles of the likelihood [5], density of states [6], energy-based models [28] and typicality tests [27]. Diffusion Time Estimation [29] estimates the distribution over the diffusion time of a noisy test sample and uses the mean or mode as the OOD score. MSMA [30] uses the score function over discrete noise levels for OOD detection. One can view MSMA as a specific case of DiffPath which only utilizes the first-order statistic, while we generalize to higherorder terms. MSMA proposes to measure the score at various noise levels, while our method sums over the entire diffusion path. It is worth emphasizing that MSMA requires different models for different inlier distributions, unlike our single model setup. ", "page_idx": 6}, {"type": "text", "text": "Reconstruction-based approaches evaluate how well a generative model, trained on in-distribution data, can reconstruct a test sample. Earlier works utilize autoencoders [31] and GANs [32] for reconstruction. Recent works have adapted unconditional DMs to this approach due to its impressive sample quality. A test sample is first artificially corrupted before being reconstructed using the DM\u2019s sampling process. DDPM-OOD [7] noises a sample using the forward process and evaluates the perceptual quality [33] of the reconstructed sample. Projection Regret [9] adopts a similar approach, but uses a Consistency Model [34] and introduces an additional projection regret score. LMD [8] corrupts the image by masking and reconstructs the sample via inpainting. Evidently, DiffPath differs from these diffusion approaches as we do not utilize reconstructions. We also stress again that these baselines require different models for different inlier tasks. ", "page_idx": 6}, {"type": "text", "text": "5 Experiments ", "text_level": 1, "page_idx": 6}, {"type": "text", "text": "Based on our earlier analysis, we hypothesize that DiffPath can be utilized for OOD detection across diverse tasks using a single model. In this section, we validate our hypothesis with comprehensive experiments across numerous pairwise OOD detection tasks and compare DiffPath\u2019s performance against state-of-the-art baselines. ", "page_idx": 6}, {"type": "text", "text": "Datasets. All experiments are conducted as of pairwise OOD detection tasks using CIFAR10 (C10), SVHN, and CelebA as inlier datasets, and CIFAR100 (C100) and Textures as additional outlier datasets. Unconditional diffusion models are employed at resolutions of $32\\times32$ and $64\\times64$ . The model utilizing ImageNet as the base distribution is trained at $64\\times64$ resolution, while all other models are trained at $32\\times32$ . ", "page_idx": 6}, {"type": "text", "text": "Methodology and Baselines. Our methodology features two variants of our model, DiffPath-1D using KDE and DiffPath-6D using a Gaussian Mixture Model for OOD scoring, as outlined in Sec. 3. We compare against a variety of generative baselines, including Energy-based Model (EBM) such as IGEBM [28], VAEBM [35] and Improved CD [36], as well as Input Complexity (IC) [16], Density of States (DOS) [6], Watanabe-Akaike Information Criterion (WAIC) [5], Typicality Test (TT) [27] and Likelihood Ratio (LR) [4] applied to the Glow [37] model. Additionally, we compare against diffusion baselines such as vanilla NLL and IC based on the DM\u2019s likelihoods and re-implementations of DDPM-OOD [7], LMD [8], and MSMA [30] based on open-source code for full comparisons. ", "page_idx": 6}, {"type": "text", "text": "5.1 Main Results ", "text_level": 1, "page_idx": 6}, {"type": "text", "text": "Table 3 summarizes our main results. Here, we report outcomes for DiffPath-6D using ImageNet and CelebA as base distributions. DiffPath-6D-CelebA achieves an average AUROC of 0.931, comparable to the leading diffusion-based approach MSMA and outperforming all other baselines, while utilizing only a single model. Similar to MSMA, we attain this result using 10 NFEs, significantly surpassing other diffusion baselines that require an order of magnitude or more NFEs. When using ImageNet as the base distribution, the average AUROC of 0.850 is competitive with LMD, which requires several magnitudes more NFEs due to multiple reconstructions. This is despite the ImageNet model never having seen any samples from the evaluated distributions during training. ", "page_idx": 6}, {"type": "table", "img_path": "tTnFH7D1h4/tmp/fb7dc0b17d7175b2a81814ec2e7d950df9ed584bf71e61ebb011eebcbac6b43e.jpg", "table_caption": ["Table 3: AUROC scores for various in-distribution vs out-of-distribution tasks. Higher is better. DiffPath-6D-ImageNet and DiffPath-6D-CelebA denote our method using diffusion models trained with ImageNet and CelebA as base distributions respectively. Bold and underline denotes the best and second best result respectively. We also show the number of function evaluations (NFE) for diffusion methods, where lower is better. "], "table_footnote": [], "page_idx": 7}, {"type": "table", "img_path": "tTnFH7D1h4/tmp/fdd8393338a5f493bc88e889c9c2688e6dc5f6527d3af473c1bd760095cd8958.jpg", "table_caption": ["Table 4: Ablation results when we vary $p_{0}(\\mathbf{x})$ , the distribution the single DM is trained on. We use DiffPath-6D with 10 NFEs. Random denotes a randomly initialized model. "], "table_footnote": [], "page_idx": 7}, {"type": "text", "text": "", "page_idx": 7}, {"type": "text", "text": "The empirical results indicate that the CelebA-based model outperforms the ImageNet-based model primarily due to its superior performance on tasks involving CelebA samples, whether they are in-distribution or out-of-distribution. For instance, DiffPath-6D-CelebA achieves near-perfect performance on all tasks where CelebA is in-distribution (rightmost columns), and in the CIFAR10 vs CelebA task. On tasks that do not involve CelebA samples, the two models exhibit roughly comparable performance. This suggests that distinguishing CelebA from other samples is particularly challenging, and that DiffPath benefits from exposure to inlier samples from the respective distributions during training. Next, we discuss the effect of the base datasets and other design considerations via ablations. ", "page_idx": 7}, {"type": "table", "img_path": "tTnFH7D1h4/tmp/27608bd523dc4e8643daf14c02fd3e002b0596f71a6378679cc3826f55f19b98.jpg", "table_caption": ["Table 5: Ablation on the number of DDIM steps (NFE). We use DiffPath-6D-CelebA. "], "table_footnote": [], "page_idx": 8}, {"type": "table", "img_path": "tTnFH7D1h4/tmp/8d2e029ca3d8d1c4a89a43284e5092693014e41a8c41b4c1d87bcf87886374bc.jpg", "table_caption": ["Table 6: Ablation results comparing DiffPath-1D and DiffPath-6D using models trained with ImageNet and CelebA as base distributions. "], "table_footnote": [], "page_idx": 8}, {"type": "text", "text": "5.2 Ablations ", "text_level": 1, "page_idx": 8}, {"type": "text", "text": "Choice of Diffusion Training Set. We investigate the impact of the base dataset on the performance of DiffPath-6D. In Table 4, we compare four different base distributions alongside a randomly initialized model. As a baseline check, we observe that the average AUROC of the randomly initialized model is 0.501, which is consistent with random guessing. This indicates that training on a base distribution is essential for the model to learn features for effective OOD detection. ", "page_idx": 8}, {"type": "text", "text": "Our ablations include CIFAR10 and SVHN as base distributions, in addition to CelebA and ImageNet shown in Table 3. Among these four base distributions, CelebA yields the best performance overall. Notably, the models trained on SVHN and CelebA demonstrate superior results when the inlier data aligns with their respective training distributions. This supports the established principle of training models on in-distribution samples, and we show that DiffPath-6D similarly benefits from such training. However, we underscore the key finding of our work: while in-distribution training enhances performance, it is not strictly necessary. DiffPath-6D exhibits strong performance even on tasks involving samples from distributions that the model has not encountered during training. ", "page_idx": 8}, {"type": "text", "text": "DiffPath 1D vs 6D. Here we ablate on the choice of DiffPath-1D and DiffPath-6D. Table 6 shows that DiffPath-6D performs better than its 1D counterpart for both choices of base distributions. We attribute this to the increased robustness of aggregating multiple statistics, c.f. Sec. 3.5, and recommend practitioners to use DiffPath-6D in general. However, DiffPath-1D outperforms DiffPath-6D in certain instances. For instance, for the ImageNet model, DiffPath-1D achieves the best performance on CIFAR10 vs SVHN and in three out of four tasks where SVHN is the inlier distribution. ", "page_idx": 8}, {"type": "text", "text": "Number of DDIM Steps. We investigate how the performance of our method varies with the number of NFEs (DDIM steps) in Table 5. Overall, the changes in average AUROC are relatively minor as the NFEs are varied, suggesting that DiffPath is robust to the number of integration steps. The best result is obtained at 10 NFEs. While the finite difference approximation of the derivative (Eq. 10) should become more accurate as the number of NFEs increases, the aggregation of multiple statistics involving scores and its derivatives makes this effect less pronounced. We leave the investigation of this phenomena in greater detail to future work. ", "page_idx": 8}, {"type": "text", "text": "5.3 Proper Image Resizing with a Single Model ", "text_level": 1, "page_idx": 8}, {"type": "text", "text": "Using a single DM with a fixed input resolution necessitates resizing all images to match the model\u2019s resolution during evaluation. However, when datasets have differing original resolutions, naive resizing\u2014upsampling lower-resolution images and downsampling higher-resolution ones\u2014can lead to evaluation inaccuracies. Specifically, upsampling introduces blurriness due to pixel interpolation, while downsampling does not. This discrepancy allows the model to differentiate samples based on image blur rather than semantic content, resulting in overly optimistic performance metrics. ", "page_idx": 8}, {"type": "table", "img_path": "tTnFH7D1h4/tmp/a85b1b04f66bcb0480069052449321a805d36ba33c8a449b3bfb63b25c18e6c2.jpg", "table_caption": ["Table 7: Difference in performance when the incorrect resizing technique is used, which leads to overly optimistic results. Results on DiffPath-6D with ImageNet $64\\times64$ as the base distribution. The results with asterisk $(^{*})$ denote the scores that have been computed inaccurately. "], "table_footnote": [], "page_idx": 9}, {"type": "text", "text": "", "page_idx": 9}, {"type": "text", "text": "For instance, when evaluating DiffPath-6D trained at $64\\times64$ pixels on the CelebA $\\nu s$ CIFAR10 task, CIFAR10 images are upsampled (introducing blur) while CelebA images are downsampled. This imbalance enables trivial distinction between the samples. As illustrated in the first row of Table 7, tasks where only one distribution undergoes upsampling yield artificially high AUROC scores. ", "page_idx": 9}, {"type": "text", "text": "To mitigate this issue, we propose equalizing the resizing process by first downsampling higherresolution images to the lower resolution of the other distribution, then upsampling both to the model\u2019s required resolution. In the CelebA vs CIFAR10 example, CelebA images are downsampled to $32\\times32$ pixels before both samples are upsampled to $64\\times64$ pixels. This method ensures consistent blurring effects across all samples, reducing confounding factors. The second row of Table 7 demonstrates more accurate evaluations using this approach. We adopt this resizing procedure in all relevant experiments to ensure fair comparisons. In short, we highlight the importance of consistent image resizing for fair evaluation in OOD detection, which we hope will guide future research. ", "page_idx": 9}, {"type": "text", "text": "5.4 Near-OOD Tasks ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "Near-OOD tasks refer to setups where the inlier and outlier samples are semantically similar, making them challenging for most methods. From Table 3, DiffPath, like most baselines, does not perform strongly on near-OOD tasks like CIFAR10 vs CIFAR100. This motivated us to conduct further near-OOD experiments, the results of which are presented in Table 8 of Sec. C of the appendix. Note that near-OOD tasks are not a standard evaluation on generative methods. We defer detailed analysis of the results to the appendix, and leave further investigations on near-OOD tasks to future work. ", "page_idx": 9}, {"type": "text", "text": "6 Conclusion ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "In this work, we proposed Diffusion Paths (DiffPath), a method of OOD detection using a single diffusion model by characterizing properties of the forward diffusion path. In light of the growing popularity of generative foundation models, our work demonstrates that a single diffusion model can also be applied to OOD detection. There are several interesting future directions that arise from our work; for instance, applying DiffPath to other modalities such as video, audio, language, time series and tabular data, as well as investigating if higher-order terms of the Taylor expansion, or leveraging different instantiations of the PF ODE might lead to better performance. ", "page_idx": 9}, {"type": "text", "text": "Limitations and Future Work. We only calculate the simple time derivative and found that it works well experimentally, although one might compute the full derivative to quantify the curvature completely. We leave this for future work. Also, we consider DMs trained on natural images like CelebA and ImageNet, which may not be appropriate for specialized applications such as medical images. For such purposes, one could consider including domain-specific data during training. ", "page_idx": 9}, {"type": "text", "text": "7 Acknowledgements ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "This research is supported by the National Research Foundation Singapore and DSO National Laboratories under the AI Singapore Programme (AISG Award No: AISG2-RP-2020-017). AHT acknowledges support from the Singaporean Ministry of Education Grant MOE-000537-01 and MOE-000618-01. We would like to thank Pranav Goyal for help with the experiments. ", "page_idx": 9}, {"type": "text", "text": "References ", "text_level": 1, "page_idx": 10}, {"type": "text", "text": "[1] Anh Nguyen, Jason Yosinski, and Jeff Clune. Deep neural networks are easily fooled: High confidence predictions for unrecognizable images. In Proceedings of the IEEE conference on computer vision and pattern recognition, pages 427\u2013436, 2015. [2] Eric Nalisnick, Akihiro Matsukawa, Yee Whye Teh, Dilan Gorur, and Balaji Lakshminarayanan. Do deep generative models know what they don\u2019t know? In International Conference on Learning Representations, 2018. [3] Jingkang Yang, Kaiyang Zhou, Yixuan Li, and Ziwei Liu. Generalized out-of-distribution detection: A survey. arXiv preprint arXiv:2110.11334, 2021.   \n[4] Jie Ren, Peter J Liu, Emily Fertig, Jasper Snoek, Ryan Poplin, Mark Depristo, Joshua Dillon, and Balaji Lakshminarayanan. Likelihood ratios for out-of-distribution detection. Advances in neural information processing systems, 32, 2019. [5] Hyunsun Choi, Eric Jang, and Alexander A Alemi. Waic, but why? generative ensembles for robust anomaly detection. arXiv preprint arXiv:1810.01392, 2018. [6] Warren Morningstar, Cusuh Ham, Andrew Gallagher, Balaji Lakshminarayanan, Alex Alemi, and Joshua Dillon. Density of states estimation for out of distribution detection. In International Conference on Artificial Intelligence and Statistics, pages 3232\u20133240. PMLR, 2021. [7] Mark S Graham, Walter HL Pinaya, Petru-Daniel Tudosiu, Parashkev Nachev, Sebastien Ourselin, and Jorge Cardoso. Denoising diffusion models for out-of-distribution detection. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 2947\u20132956, 2023. [8] Zhenzhen Liu, Jin Peng Zhou, Yufan Wang, and Kilian Q Weinberger. Unsupervised out-of-distribution detection with diffusion inpainting. In International Conference on Machine Learning, pages 22528\u201322538. PMLR, 2023. [9] Sungik Choi, Hankook Lee, Honglak Lee, and Moontae Lee. Projection regret: Reducing background bias for novelty detection via diffusion models. Advances in Neural Information Processing Systems, 36, 2024.   \n[10] Zhisheng Xiao, Qing Yan, and Yali Amit. Do we really need to learn representations from in-domain data for outlier detection? arXiv preprint arXiv:2105.09270, 2021.   \n[11] Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, et al. Language models are few-shot learners. Advances in neural information processing systems, 33:1877\u20131901, 2020.   \n[12] Rishi Bommasani, Drew A Hudson, Ehsan Adeli, Russ Altman, Simran Arora, Sydney von Arx, Michael S Bernstein, Jeannette Bohg, Antoine Bosselut, Emma Brunskill, et al. On the opportunities and risks of foundation models. arXiv preprint arXiv:2108.07258, 2021.   \n[13] Yang Song, Jascha Sohl-Dickstein, Diederik P Kingma, Abhishek Kumar, Stefano Ermon, and Ben Poole. Score-based generative modeling through stochastic differential equations. In International Conference on Learning Representations, 2020.   \n[14] Yang Song and Stefano Ermon. Generative modeling by estimating gradients of the data distribution. Advances in neural information processing systems, 32, 2019.   \n[15] Jonathan Ho, Ajay Jain, and Pieter Abbeel. Denoising diffusion probabilistic models. Advances in neural information processing systems, 33:6840\u20136851, 2020.   \n[16] Joan Serr\u00e0, David \u00c1lvarez, Vicen\u00e7 G\u00f3mez, Olga Slizovskaia, Jos\u00e9 F N\u00fa\u00f1ez, and Jordi Luque. Input complexity and out-of-distribution detection with likelihood-based generative models. In International Conference on Learning Representations, 2019.   \n[17] Aapo Hyv\u00e4rinen and Peter Dayan. Estimation of non-normalized statistical models by score matching. Journal of Machine Learning Research, 6(4), 2005.   \n[18] Tim Dockhorn, Arash Vahdat, and Karsten Kreis. Genie: Higher-order denoising diffusion solvers. Advances in Neural Information Processing Systems, 35:30150\u201330166, 2022.   \n[19] Jiaming Song, Chenlin Meng, and Stefano Ermon. Denoising diffusion implicit models. In International Conference on Learning Representations, 2020.   \n[20] Peter E. Kloeden and Eckhard Platen. Numerical Solution of Stochastic Differential Equations. Springer, Berlin, 1992.   \n[21] Valentin Khrulkov, Gleb Ryzhakov, Andrei Chertkov, and Ivan Oseledets. Understanding ddpm latent codes through optimal transport. In The Eleventh International Conference on Learning Representations, 2022.   \n[22] Xuan Su, Jiaming Song, Chenlin Meng, and Stefano Ermon. Dual diffusion implicit bridges for image-toimage translation. In The Eleventh International Conference on Learning Representations, 2022.   \n[23] Simo S\u00e4rkk\u00e4 and Arno Solin. Applied stochastic differential equations, volume 10. Cambridge University Press, 2019.   \n[24] Taylor Denouden, Rick Salay, Krzysztof Czarnecki, Vahdat Abdelzad, Buu Phan, and Sachin Vernekar. Improving reconstruction autoencoder out-of-distribution detection with mahalanobis distance. arXiv preprint arXiv:1812.02765, 2018.   \n[25] Jihoon Tack, Sangwoo Mo, Jongheon Jeong, and Jinwoo Shin. Csi: Novelty detection via contrastive learning on distributionally shifted instances. Advances in neural information processing systems, 33: 11839\u201311852, 2020.   \n[26] Vikash Sehwag, Mung Chiang, and Prateek Mittal. Ssd: A unified framework for self-supervised outlier detection. arXiv preprint arXiv:2103.12051, 2021.   \n[27] Eric Nalisnick, Akihiro Matsukawa, Yee Whye Teh, and Balaji Lakshminarayanan. Detecting out-ofdistribution inputs to deep generative models using typicality. arXiv preprint arXiv:1906.02994, 2019.   \n[28] Yilun Du and Igor Mordatch. Implicit generation and modeling with energy based models. Advances in Neural Information Processing Systems, 32, 2019.   \n[29] Victor Livernoche, Vineet Jain, Yashar Hezaveh, and Siamak Ravanbakhsh. On diffusion modeling for anomaly detection. In The Twelfth International Conference on Learning Representations.   \n[30] Ahsan Mahmood, Junier Oliva, and Martin Andreas Styner. Multiscale score matching for out-ofdistribution detection. In International Conference on Learning Representations, 2020.   \n[31] Chong Zhou and Randy C Paffenroth. Anomaly detection with robust deep autoencoders. In Proceedings of the 23rd ACM SIGKDD international conference on knowledge discovery and data mining, pages 665\u2013674, 2017.   \n[32] Thomas Schlegl, Philipp Seeb\u00f6ck, Sebastian M Waldstein, Ursula Schmidt-Erfurth, and Georg Langs. Unsupervised anomaly detection with generative adversarial networks to guide marker discovery. In International conference on information processing in medical imaging, pages 146\u2013157. Springer, 2017.   \n[33] Richard Zhang, Phillip Isola, Alexei A Efros, Eli Shechtman, and Oliver Wang. The unreasonable effectiveness of deep features as a perceptual metric. In Proceedings of the IEEE conference on computer vision and pattern recognition, pages 586\u2013595, 2018.   \n[34] Yang Song, Prafulla Dhariwal, Mark Chen, and Ilya Sutskever. Consistency models. In International Conference on Machine Learning, pages 32211\u201332252. PMLR, 2023.   \n[35] Zhisheng Xiao, Karsten Kreis, Jan Kautz, and Arash Vahdat. Vaebm: A symbiosis between variational autoencoders and energy-based models. In International Conference on Learning Representations, 2020.   \n[36] Yilun Du, Shuang Li, Joshua Tenenbaum, and Igor Mordatch. Improved contrastive divergence training of energy-based models. In International Conference on Machine Learning, pages 2837\u20132848. PMLR, 2021.   \n[37] Durk P Kingma and Prafulla Dhariwal. Glow: Generative flow with invertible 1x1 convolutions. Advances in neural information processing systems, 31, 2018.   \n[38] Yang Song, Conor Durkan, Iain Murray, and Stefano Ermon. Maximum likelihood training of score-based diffusion models. Advances in neural information processing systems, 34:1415\u20131428, 2021.   \n[39] Gabriel Peyr\u00e9 and Marco Cuturi. Computational optimal transport. Foundations and Trends in Machine Learning, 11(5-6):355\u2013607, 2019.   \n[40] Alexander Quinn Nichol and Prafulla Dhariwal. Improved denoising diffusion probabilistic models. In International conference on machine learning, pages 8162\u20138171. PMLR, 2021.   \n[41] Jingkang Yang, Pengyun Wang, Dejian Zou, Zitang Zhou, Kunyuan Ding, Wenxuan Peng, Haoqi Wang, Guangyao Chen, Bo Li, Yiyou Sun, et al. Openood: Benchmarking generalized out-of-distribution detection. Advances in Neural Information Processing Systems, 35:32598\u201332611, 2022.   \n[42] Sagar Vaze, Kai Han, Andrea Vedaldi, and Andrew Zisserman. Open-set recognition: A good closed-set classifier is all you need. In International Conference on Learning Representations.   \n[43] Julian Bitterwolf, Maximilian M\u00fcller, and Matthias Hein. In or out? fixing imagenet out-of-distribution detection evaluation. In International Conference on Machine Learning, pages 2471\u20132506. PMLR, 2023.   \n[44] Dan Hendrycks, Steven Basart, Mantas Mazeika, Andy Zou, Joseph Kwon, Mohammadreza Mostajabi, Jacob Steinhardt, and Dawn Song. Scaling out-of-distribution detection for real-world settings. In International Conference on Machine Learning, pages 8759\u20138773. PMLR, 2022.   \n[45] Haoqi Wang, Zhizhong Li, Litong Feng, and Wayne Zhang. Vim: Out-of-distribution with virtual-logit matching. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition, pages 4921\u20134930, 2022.   \n[46] Yiyou Sun, Yifei Ming, Xiaojin Zhu, and Yixuan Li. Out-of-distribution detection with deep nearest neighbors. In International Conference on Machine Learning, pages 20827\u201320840. PMLR, 2022.   \n[47] Yiyou Sun and Yixuan Li. Dice: Leveraging sparsification for out-of-distribution detection. In European Conference on Computer Vision, pages 691\u2013708. Springer, 2022. ", "page_idx": 10}, {"type": "text", "text": "", "page_idx": 11}, {"type": "text", "text": "", "page_idx": 12}, {"type": "text", "text": "Supplementary Material for \u201cOut-of-Distribution Detection with a Single Unconditional Diffusion Model\u201d ", "text_level": 1, "page_idx": 13}, {"type": "text", "text": "A Proofs ", "text_level": 1, "page_idx": 13}, {"type": "text", "text": "A.1 Theorem 1 ", "text_level": 1, "page_idx": 13}, {"type": "text", "text": "Theorem 1. Denote $\\phi_{t}$ and $\\psi_{t}$ as the marginals from evolving two distinct distributions $\\phi_{0}$ and $\\psi_{0}$ via their respective probability flow ODEs (Eq. 6) forward in time. We consider the case with the same forward process, i.e., the two PF ODEs have the same $f(\\mathbf{x}_{t},t),g(t)$ and $\\sigma_{t}$ . Under some regularity conditions stated in Appendix A.1, ", "page_idx": 13}, {"type": "equation", "text": "$$\nD_{\\mathrm{KL}}(\\phi_{0}\\|\\psi_{0})=\\frac{1}{2}\\int_{0}^{T}\\mathbb{E}_{\\mathbf{x}\\sim\\phi_{t}}\\frac{g(t)^{2}}{\\sigma_{t}}\\left\\|\\epsilon_{\\phi}(\\mathbf{x}_{t},t)-\\epsilon_{\\psi}(\\mathbf{x}_{t},t)\\right\\|_{2}^{2}\\mathrm{d}t+D_{\\mathrm{KL}}(\\phi_{T}\\|\\psi_{T}).\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "Proof. The proof is a modification from Song et al. [38]. Let us first state the PF ODEs of the two distributions explicitly: ", "page_idx": 13}, {"type": "equation", "text": "$$\n\\begin{array}{l l}{\\displaystyle\\frac{\\mathrm{d}\\mathbf{x}_{t}}{\\mathrm{d}t}={\\pmb f}(\\mathbf{x}_{t},t)+\\frac{g(t)^{2}}{2\\sigma_{t}}\\epsilon_{\\phi}(\\mathbf{x}_{t},t),}&{\\epsilon_{\\phi}(\\mathbf{x}_{t},t)=-\\sigma_{t}\\nabla_{\\mathbf{x}}\\log\\phi_{t}(\\mathbf{x})}\\\\ {\\displaystyle\\frac{\\mathrm{d}\\mathbf{x}_{t}}{\\mathrm{d}t}={\\pmb f}(\\mathbf{x}_{t},t)+\\frac{g(t)^{2}}{2\\sigma_{t}}\\epsilon_{\\psi}(\\mathbf{x}_{t},t),}&{\\epsilon_{\\psi}(\\mathbf{x}_{t},t)=-\\sigma_{t}\\nabla_{\\mathbf{x}}\\log\\psi_{t}(\\mathbf{x}).}\\end{array}\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "We make the following assumption about $\\phi_{t}$ and $\\psi_{t}$ : ", "page_idx": 13}, {"type": "equation", "text": "$$\n\\forall t\\in[0,T],\\ \\exists k>0\\ \\mathrm{s.t.}\\ \\phi_{t}(\\mathbf{x})=O(e^{-\\|\\mathbf{x}\\|_{2}^{k}}),\\ \\ \\psi_{t}(\\mathbf{x})=O(e^{-\\|\\mathbf{x}\\|_{2}^{k}})\\ \\mathrm{as}\\ \\|\\mathbf{x}\\|_{2}\\to\\infty.\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "We start by rewriting the KL divergence between $\\phi_{0}$ and $\\psi_{0}$ in integral form: ", "page_idx": 13}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{D_{\\mathrm{KL}}(\\phi_{0}\\|\\psi_{0})=D_{\\mathrm{KL}}(\\phi_{0}\\|\\psi_{0})-D_{\\mathrm{KL}}(\\phi_{T}\\|\\psi_{T})+D_{\\mathrm{KL}}(\\phi_{T}\\|\\psi_{T})}\\\\ &{\\qquad\\qquad\\qquad=-\\int_{0}^{T}\\frac{\\partial D_{\\mathrm{KL}}(\\phi_{t}\\|\\psi_{t})}{\\partial t}\\mathrm{d}t+D_{\\mathrm{KL}}(\\phi_{T}\\|\\psi_{T}).}\\end{array}\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "As we can treat the PF ODE as a special case of an SDE with zero diffusion term, we can obtain the Fokker-Planck of the marginal density of the PF ODEs, also known as the continuity equation, as follows: ", "page_idx": 13}, {"type": "equation", "text": "$$\n\\frac{\\partial\\phi_{t}}{\\partial t}=\\nabla_{\\mathbf{x}}\\cdot\\bigg(-f(\\mathbf{x}_{t},t)\\phi_{t}(\\mathbf{x})-\\frac{g(t)^{2}}{2\\sigma_{t}}\\epsilon_{\\phi}(\\mathbf{x}_{t},t)\\phi_{t}(\\mathbf{x})\\bigg)=\\nabla_{\\mathbf{x}}\\cdot\\big(h_{\\phi}\\phi_{t}(\\mathbf{x})\\big)\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "where we define $\\begin{array}{r}{\\pmb{h}_{\\phi}:=-\\pmb{f}(\\mathbf{x}_{t},t)-\\frac{g(t)^{2}}{2\\sigma_{t}}\\pmb{\\epsilon}_{\\phi}(\\mathbf{x}_{t},t)}\\end{array}$ for simplicity. Similarly, $\\begin{array}{r}{\\frac{\\partial\\psi_{t}}{\\partial t}=\\nabla_{\\mathbf{x}}\\cdot(h_{\\psi}\\psi_{t}(\\mathbf{x}))}\\end{array}$ Let us now rewrite the time-derivative \u2202DKL(\u03d5t\u2225\u03c8t)in Eq. 14 as follows: ", "page_idx": 13}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\frac{\\partial D_{\\mathrm{KL}}(\\phi_{t}\\|\\psi_{t})}{\\partial t}=\\frac{\\partial}{\\partial t}\\int\\phi_{t}(\\mathbf{x})\\log\\frac{\\phi_{t}(\\mathbf{x})}{\\psi_{t}(\\mathbf{x})}\\mathrm{d}\\mathbf{x}}\\\\ &{\\qquad\\qquad=\\int\\frac{\\partial\\phi_{t}}{\\partial t}\\log\\frac{\\phi_{t}(\\mathbf{x})}{\\psi_{t}(\\mathbf{x})}\\mathrm{d}\\mathbf{x}+\\underbrace{\\int\\frac{\\partial\\phi_{t}(\\mathbf{x})}{\\partial t}\\mathrm{d}\\mathbf{x}}_{=0}-\\int\\frac{\\phi_{t}(\\mathbf{x})}{\\psi_{t}(\\mathbf{x})}\\frac{\\partial\\psi_{t}(\\mathbf{x})}{\\partial t}\\mathrm{d}\\mathbf{x}}\\\\ &{\\qquad\\qquad=\\int\\nabla_{\\mathbf{x}}\\cdot(h_{\\phi}(\\mathbf{x},t)\\phi_{t}(\\mathbf{x}))\\log\\frac{\\phi_{t}(\\mathbf{x})}{\\psi_{t}(\\mathbf{x})}\\mathrm{d}\\mathbf{x}-\\int\\frac{\\phi_{t}(\\mathbf{x})}{\\psi_{t}(\\mathbf{x})}\\nabla_{\\mathbf{x}}\\cdot(h_{\\psi}(\\mathbf{x},t)\\psi_{t}(\\mathbf{x}))\\mathrm{d}\\mathbf{x}}\\\\ &{\\qquad\\qquad\\overset{(i)}{=}\\int\\phi_{t}(\\mathbf{x})[h_{\\phi}^{\\top}(\\mathbf{x},t)-h_{\\psi}^{\\top}(\\mathbf{x},t)][\\nabla_{\\mathbf{x}}\\log\\phi_{t}(\\mathbf{x})-\\nabla_{x}\\log\\psi_{t}(\\mathbf{x})]\\mathrm{d}\\mathbf{x}}\\\\ &{\\qquad\\qquad=-\\frac{1}{2}\\int\\phi_{t}(\\mathbf{x})\\frac{g(t)^{2}}{\\sigma_{t}}\\left\\|\\epsilon_{\\phi}(\\mathbf{x},t)-\\epsilon_{\\psi}(\\mathbf{x},t)\\right\\|_{2}^{2}\\mathrm{d}\\mathbf{x},}\\end{array}\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "where (i) is due to integration by parts and the fact that $\\begin{array}{r}{\\operatorname*{lim}_{\\mathbf{x}\\rightarrow\\infty}h_{\\phi}(\\mathbf{x},t)\\phi_{t}(\\mathbf{x})~=~0}\\end{array}$ and $\\begin{array}{r}{\\operatorname*{lim}_{\\mathbf{x}\\rightarrow\\infty}h_{\\psi}(\\mathbf{x},t)\\psi_{t}(\\mathbf{x})\\stackrel{{}}{=}0}\\end{array}$ due to assumption 13. Combining with Eq. 14 gives us the desired result: ", "page_idx": 13}, {"type": "equation", "text": "$$\nD_{\\mathrm{KL}}(\\phi_{0}\\|\\psi_{0})=\\frac{1}{2}\\int_{0}^{T}\\mathbb{E}_{x\\sim\\phi_{t}}\\frac{g(t)^{2}}{\\sigma_{t}}\\left\\|\\epsilon_{\\phi}(\\mathbf{x}_{t},t)-\\epsilon_{\\psi}(\\mathbf{x}_{t},t)\\right\\|_{2}^{2}\\mathrm{d}t+D_{\\mathrm{KL}}(\\phi_{T}\\|\\psi_{T}).\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "A.2 OT Toy Example ", "text_level": 1, "page_idx": 14}, {"type": "text", "text": "We derive here in detail the toy example discussed in Sec. 3.4, where we will prove the optimal transport map between a multivariate Gaussian and standard normal is identical to the diffusion PF ODE path. We consider our source distribution as $p_{0}(\\mathbf{x})\\sim\\mathcal{N}(\\mathbf{a},\\mathbf{I})$ , $\\mathbf{a}\\in\\mathbb{R}^{d}$ and $\\mathbf{I}\\in\\mathbb{R}^{d\\times d}$ . We choose our forward SDE to be parameterized as: ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\mathrm{d}\\mathbf{x}_{t}=-\\mathbf{x}\\mathrm{d}t+\\sqrt{2}\\mathrm{d}\\mathbf{w}_{t},\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "which is the same Ornstein\u2013Uhlenbeck process as the DDPM forward SDE Eq. 4 with a constant noise schedule $\\beta(t)=2$ . This is also commonly referred to as the Langevin equation. ", "page_idx": 14}, {"type": "text", "text": "As Eq. 17 has affine drift coefficients and a starting distribution which is normal, we know that the marginal distributions at intermediate times are also normal, $p_{t}(\\mathbf{x})\\sim\\mathcal{N}(\\pmb{\\mu}(t),\\pmb{\\Sigma}(t))$ . Furthermore, we can calculate the means and variances analytically using Eq. 5.50 and Eq. 5.51 of S\u00e4rkk\u00e4 and Solin [23]: ", "page_idx": 14}, {"type": "equation", "text": "$$\n{\\frac{\\mathrm{d}\\pmb{\\mu}(t)}{\\mathrm{d}t}}=-\\pmb{\\mu}(t),\\quad{\\frac{\\mathrm{d}\\pmb{\\Sigma}(t)}{\\mathrm{d}t}}=-2\\pmb{\\Sigma}(t)+2\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "with solutions ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\mu(t)=\\mu(0)e^{-t}=\\mathbf{a}e^{-t},\\quad\\Sigma(t)=\\mathbf{I}+e^{-2t}(\\Sigma(0)-\\mathbf{I})=\\mathbf{I}.\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "Thus, the marginal density has the form $p_{t}(\\mathbf{x})=\\mathcal{N}(\\mathbf{a}e^{-t},\\mathbf{I})$ , from which we compute the score as $\\nabla_{\\mathbf{x}}\\log p_{t}(\\mathbf{x})\\stackrel{*}{=}-\\mathbf{x}+\\mathbf{a}e^{-t}$ . We can substitute this into the corresponding PF ODE to obtain: ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\frac{\\mathrm{d}\\mathbf{x}_{t}}{\\mathrm{d}t}=-\\mathbf{x}-\\nabla_{\\mathbf{x}}\\log p_{t}(\\mathbf{x})}\\\\ {=-\\mathbf{a}e^{-t}.\\qquad\\qquad\\qquad\\qquad\\qquad}\\end{array}\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "The optimal transport map denoted $E_{p_{0}}(\\mathbf{x})$ is obtained by solving Eq. 20 to get ${\\bf x}_{t}={\\bf x}_{0}+{\\bf a}(e^{-t}-{\\bf I})$ and taking the limit $t\\to\\infty$ . This gives us $E_{p_{0}}(\\mathbf{x})=\\mathbf{x}-\\mathbf{a}$ , which is precisely the OT map between $p_{0}(\\mathbf{x})\\sim\\bar{\\mathcal{N}}(\\mathbf{a},\\mathbf{I})$ and $\\mathcal{N}(\\mathbf{0},\\mathbf{I})$ (cf. Eq. 2.40 in Peyr\u00e9 and Cuturi [39]). ", "page_idx": 14}, {"type": "text", "text": "B Experimental Details ", "text_level": 1, "page_idx": 14}, {"type": "text", "text": "DiffPath. As mentioned in Sec. 5, we utilize a single unconditional diffusion model trained on CelebA and ImageNet at $32\\times32$ and $64\\times64$ resolution respectively. We train our own CelebA model and utilize the ImageNet checkpoint trained using Improved DDPM\u2019s $L_{\\mathrm{hybrid}}$ objective (Eq. 16 of Nichol and Dhariwal [40]) from the official repository2. Both models use a cosine noise schedule with a total of 4000 diffusion steps. For DiffPath-1D, we fit a KDE using a Gaussian kernel with a bandwith of 5. For DiffPath-6D, we fit a GMM with hyperparameters obtained by sweeping over a predefined number of mixture components (e.g., 50, 100) and covariance type (e.g., diagonal, full, tied). Both are implemented using the sklearn library. ", "page_idx": 14}, {"type": "text", "text": "On a single Nvidia A5000 GPU, DiffPath takes approximately 0.25s and 0.94s per integration step on $32\\times32$ and $64\\times64$ images respectively with a batch size of 256. ", "page_idx": 14}, {"type": "text", "text": "Diffusion Baselines. For all diffusion baselines, we rely on the official GitHub repositories and open-source checkpoints where possible. The repositories are listed as follows: MSMA3, DDPM$\\bar{\\mathrm{OOD^{4}}}$ , $\\mathrm{LMD^{5}}$ . For NLL and IC, we use the pre-trained CIFAR10 checkpoint from Improved DDPM and train our own model for SVHN using the same hyperparameters at $32\\times32$ resolution. We calculate the NLL using the default implementation in Improved DDPM, while we compute IC using code from the LR repository6 due to lack of official code from the IC authors. We train all baselines using 1-3 A5000 GPUs. ", "page_idx": 14}, {"type": "text", "text": "Table 8: Average AUROC results for near-OOD tasks as proposed in OpenOOD [41]. We use DiffPath-6D with ImageNet as the base distribution with 10 DDIM steps. Bold and underline denotes the best and second best result respectively. We also show the number of function evaluations (NFE) for diffusion methods, where lower is better. ", "page_idx": 15}, {"type": "table", "img_path": "tTnFH7D1h4/tmp/d634d4cf9dd791d3a9e117be78df8b572710aa66578baa39767ad28c1195fcc1.jpg", "table_caption": [], "table_footnote": [], "page_idx": 15}, {"type": "text", "text": "C Near-OOD Results ", "text_level": 1, "page_idx": 15}, {"type": "text", "text": "To further investigate the performance of DiffPath on near-OOD tasks, we ran experiments on two tasks proposed in OpenOOD [41]. The first task involves CIFAR10 as the in-distribution data with CIFAR100 and TinyImageNet (also known as ImageNet200) as out-of-distribution datasets. The second involves TinyImageNet as in-distribution data and SSB [42] (hard split) and NINCO [43] as out-of-distribution data (see the official repository7 for full details). ", "page_idx": 15}, {"type": "text", "text": "We compare our results against the four latest discriminative baselines reported in OpenOOD [41] under the \u201cw/o Extra Data, w/o Training\" category, which are KLM [44], VIM [45], KNN [46] and DICE [47]. We report the average AUROC of each task in Table 8. The results are mixed: DiffPath performs the best for the TinyImageNet task, but obtains the poorest result for the CIFAR10 task. ", "page_idx": 15}, {"type": "text", "text": "As noted in the main text, to our knowledge near-OOD tasks are not a standard evaluation setup for generative methods. We hypothesize that such tasks are better suited to discriminative methods as gradient-based classification training enables the model to learn fine-grained features specific to each in-distribution class, which we believe is crucial in this context. In contrast, generative models focus on maximizing the likelihood of the overall data distribution and are not explicitly trained to identify subtle discriminative features. This could potentially lead to weaker performance in tasks where the distributions exhibit a high degree of overlap. It should be noted that discriminative methods typically require class labels, while unconditional generative methods do not, thus constraining the use of the former to cases with labelled in-distribution data. ", "page_idx": 15}, {"type": "text", "text": "NeurIPS Paper Checklist ", "text_level": 1, "page_idx": 16}, {"type": "text", "text": "1. Claims ", "text_level": 1, "page_idx": 16}, {"type": "text", "text": "Question: Do the main claims made in the abstract and introduction accurately reflect the paper\u2019s contributions and scope? ", "page_idx": 16}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 16}, {"type": "text", "text": "Justification: Framework proposed in the introduction is thoroughly discussed in the methods section. Experimental results support the claim that we are competitive with baselines. ", "page_idx": 16}, {"type": "text", "text": "Guidelines: ", "page_idx": 16}, {"type": "text", "text": "\u2022 The answer NA means that the abstract and introduction do not include the claims made in the paper.   \n\u2022 The abstract and/or introduction should clearly state the claims made, including the contributions made in the paper and important assumptions and limitations. A No or NA answer to this question will not be perceived well by the reviewers.   \n\u2022 The claims made should match theoretical and experimental results, and reflect how much the results can be expected to generalize to other settings.   \n\u2022 It is fine to include aspirational goals as motivation as long as it is clear that these goals are not attained by the paper. ", "page_idx": 16}, {"type": "text", "text": "2. Limitations ", "text_level": 1, "page_idx": 16}, {"type": "text", "text": "Question: Does the paper discuss the limitations of the work performed by the authors? ", "page_idx": 16}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 16}, {"type": "text", "text": "Justification: We include a limitations section in the conclusion. ", "page_idx": 16}, {"type": "text", "text": "Guidelines: ", "page_idx": 16}, {"type": "text", "text": "\u2022 The answer NA means that the paper has no limitation while the answer No means that the paper has limitations, but those are not discussed in the paper.   \n\u2022 The authors are encouraged to create a separate \"Limitations\" section in their paper.   \n\u2022 The paper should point out any strong assumptions and how robust the results are to violations of these assumptions (e.g., independence assumptions, noiseless settings, model well-specification, asymptotic approximations only holding locally). The authors should reflect on how these assumptions might be violated in practice and what the implications would be.   \n\u2022 The authors should reflect on the scope of the claims made, e.g., if the approach was only tested on a few datasets or with a few runs. In general, empirical results often depend on implicit assumptions, which should be articulated.   \n\u2022 The authors should reflect on the factors that influence the performance of the approach. For example, a facial recognition algorithm may perform poorly when image resolution is low or images are taken in low lighting. Or a speech-to-text system might not be used reliably to provide closed captions for online lectures because it fails to handle technical jargon.   \n\u2022 The authors should discuss the computational efficiency of the proposed algorithms and how they scale with dataset size.   \n\u2022 If applicable, the authors should discuss possible limitations of their approach to address problems of privacy and fairness.   \n\u2022 While the authors might fear that complete honesty about limitations might be used by reviewers as grounds for rejection, a worse outcome might be that reviewers discover limitations that aren\u2019t acknowledged in the paper. The authors should use their best judgment and recognize that individual actions in favor of transparency play an important role in developing norms that preserve the integrity of the community. Reviewers will be specifically instructed to not penalize honesty concerning limitations. ", "page_idx": 16}, {"type": "text", "text": "3. Theory Assumptions and Proofs ", "text_level": 1, "page_idx": 16}, {"type": "text", "text": "Question: For each theoretical result, does the paper provide the full set of assumptions and a complete (and correct) proof? ", "page_idx": 16}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 16}, {"type": "text", "text": "Justification: Complete proofs for Theorem 1 and the optimal transport example are provided in the appendix. ", "page_idx": 17}, {"type": "text", "text": "Guidelines: ", "page_idx": 17}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include theoretical results.   \n\u2022 All the theorems, formulas, and proofs in the paper should be numbered and crossreferenced.   \n\u2022 All assumptions should be clearly stated or referenced in the statement of any theorems.   \n\u2022 The proofs can either appear in the main paper or the supplemental material, but if they appear in the supplemental material, the authors are encouraged to provide a short proof sketch to provide intuition.   \n\u2022 Inversely, any informal proof provided in the core of the paper should be complemented by formal proofs provided in appendix or supplemental material.   \n\u2022 Theorems and Lemmas that the proof relies upon should be properly referenced. ", "page_idx": 17}, {"type": "text", "text": "4. Experimental Result Reproducibility ", "text_level": 1, "page_idx": 17}, {"type": "text", "text": "Question: Does the paper fully disclose all the information needed to reproduce the main experimental results of the paper to the extent that it affects the main claims and/or conclusions of the paper (regardless of whether the code and data are provided or not)? ", "page_idx": 17}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 17}, {"type": "text", "text": "Justification: Full experimental details are provided in main paper and appendix. Opensource code is provided. ", "page_idx": 17}, {"type": "text", "text": "Guidelines: ", "page_idx": 17}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 If the paper includes experiments, a No answer to this question will not be perceived well by the reviewers: Making the paper reproducible is important, regardless of whether the code and data are provided or not.   \n\u2022 If the contribution is a dataset and/or model, the authors should describe the steps taken to make their results reproducible or verifiable.   \n\u2022 Depending on the contribution, reproducibility can be accomplished in various ways. For example, if the contribution is a novel architecture, describing the architecture fully might suffice, or if the contribution is a specific model and empirical evaluation, it may be necessary to either make it possible for others to replicate the model with the same dataset, or provide access to the model. In general. releasing code and data is often one good way to accomplish this, but reproducibility can also be provided via detailed instructions for how to replicate the results, access to a hosted model (e.g., in the case of a large language model), releasing of a model checkpoint, or other means that are appropriate to the research performed.   \n\u2022 While NeurIPS does not require releasing code, the conference does require all submissions to provide some reasonable avenue for reproducibility, which may depend on the nature of the contribution. For example (a) If the contribution is primarily a new algorithm, the paper should make it clear how to reproduce that algorithm. (b) If the contribution is primarily a new model architecture, the paper should describe the architecture clearly and fully. (c) If the contribution is a new model (e.g., a large language model), then there should either be a way to access this model for reproducing the results or a way to reproduce the model (e.g., with an open-source dataset or instructions for how to construct the dataset). (d) We recognize that reproducibility may be tricky in some cases, in which case authors are welcome to describe the particular way they provide for reproducibility. In the case of closed-source models, it may be that access to the model is limited in some way (e.g., to registered users), but it should be possible for other researchers to have some path to reproducing or verifying the results. ", "page_idx": 17}, {"type": "text", "text": "5. Open access to data and code ", "text_level": 1, "page_idx": 17}, {"type": "text", "text": "Question: Does the paper provide open access to the data and code, with sufficient instructions to faithfully reproduce the main experimental results, as described in supplemental material? ", "page_idx": 18}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 18}, {"type": "text", "text": "Justification: Open-source code is provided. ", "page_idx": 18}, {"type": "text", "text": "Guidelines: ", "page_idx": 18}, {"type": "text", "text": "\u2022 The answer NA means that paper does not include experiments requiring code.   \n\u2022 Please see the NeurIPS code and data submission guidelines (https://nips.cc/ public/guides/CodeSubmissionPolicy) for more details.   \n\u2022 While we encourage the release of code and data, we understand that this might not be possible, so \u201cNo\u201d is an acceptable answer. Papers cannot be rejected simply for not including code, unless this is central to the contribution (e.g., for a new open-source benchmark).   \n\u2022 The instructions should contain the exact command and environment needed to run to reproduce the results. See the NeurIPS code and data submission guidelines (https: //nips.cc/public/guides/CodeSubmissionPolicy) for more details.   \n\u2022 The authors should provide instructions on data access and preparation, including how to access the raw data, preprocessed data, intermediate data, and generated data, etc.   \n\u2022 The authors should provide scripts to reproduce all experimental results for the new proposed method and baselines. If only a subset of experiments are reproducible, they should state which ones are omitted from the script and why.   \n\u2022 At submission time, to preserve anonymity, the authors should release anonymized versions (if applicable).   \n\u2022 Providing as much information as possible in supplemental material (appended to the paper) is recommended, but including URLs to data and code is permitted. ", "page_idx": 18}, {"type": "text", "text": "6. Experimental Setting/Details ", "text_level": 1, "page_idx": 18}, {"type": "text", "text": "Question: Does the paper specify all the training and test details (e.g., data splits, hyperparameters, how they were chosen, type of optimizer, etc.) necessary to understand the results? ", "page_idx": 18}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 18}, {"type": "text", "text": "Justification: Provided in the appendix and code. ", "page_idx": 18}, {"type": "text", "text": "Guidelines: ", "page_idx": 18}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments. \u2022 The experimental setting should be presented in the core of the paper to a level of detail that is necessary to appreciate the results and make sense of them. \u2022 The full details can be provided either with the code, in appendix, or as supplemental material. ", "page_idx": 18}, {"type": "text", "text": "7. Experiment Statistical Significance ", "text_level": 1, "page_idx": 18}, {"type": "text", "text": "Question: Does the paper report error bars suitably and correctly defined or other appropriate information about the statistical significance of the experiments? ", "page_idx": 18}, {"type": "text", "text": "Answer: [No] ", "page_idx": 18}, {"type": "text", "text": "Justification: Error bars are not conventionally reported for AUROC performance. Furthermore, our method is deterministic (ODE-based), so repeated evaluations produce the same result (up to initialization of the EM algorithm when fitting the GMM, which is negligible in our experiments). ", "page_idx": 18}, {"type": "text", "text": "Guidelines: ", "page_idx": 18}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments. \u2022 The authors should answer \"Yes\" if the results are accompanied by error bars, confidence intervals, or statistical significance tests, at least for the experiments that support the main claims of the paper. ", "page_idx": 18}, {"type": "text", "text": "\u2022 The factors of variability that the error bars are capturing should be clearly stated (for example, train/test split, initialization, random drawing of some parameter, or overall run with given experimental conditions).   \n\u2022 The method for calculating the error bars should be explained (closed form formula, call to a library function, bootstrap, etc.)   \n\u2022 The assumptions made should be given (e.g., Normally distributed errors).   \n\u2022 It should be clear whether the error bar is the standard deviation or the standard error of the mean.   \n\u2022 It is OK to report 1-sigma error bars, but one should state it. The authors should preferably report a 2-sigma error bar than state that they have a $96\\%$ CI, if the hypothesis of Normality of errors is not verified.   \n\u2022 For asymmetric distributions, the authors should be careful not to show in tables or figures symmetric error bars that would yield results that are out of range (e.g. negative error rates).   \n\u2022 If error bars are reported in tables or plots, The authors should explain in the text how they were calculated and reference the corresponding figures or tables in the text. ", "page_idx": 19}, {"type": "text", "text": "8. Experiments Compute Resources ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "Question: For each experiment, does the paper provide sufficient information on the computer resources (type of compute workers, memory, time of execution) needed to reproduce the experiments? ", "page_idx": 19}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 19}, {"type": "text", "text": "Justification: Provided in the appendix. ", "page_idx": 19}, {"type": "text", "text": "Guidelines: ", "page_idx": 19}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 The paper should indicate the type of compute workers CPU or GPU, internal cluster, or cloud provider, including relevant memory and storage.   \n\u2022 The paper should provide the amount of compute required for each of the individual experimental runs as well as estimate the total compute.   \n\u2022 The paper should disclose whether the full research project required more compute than the experiments reported in the paper (e.g., preliminary or failed experiments that didn\u2019t make it into the paper). ", "page_idx": 19}, {"type": "text", "text": "9. Code Of Ethics ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "Question: Does the research conducted in the paper conform, in every respect, with the NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines? ", "page_idx": 19}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 19}, {"type": "text", "text": "Justification: We believe the research conforms to the NeurIPS Code of Ethics. ", "page_idx": 19}, {"type": "text", "text": "Guidelines: ", "page_idx": 19}, {"type": "text", "text": "\u2022 The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics.   \n\u2022 If the authors answer No, they should explain the special circumstances that require a deviation from the Code of Ethics.   \n\u2022 The authors should make sure to preserve anonymity (e.g., if there is a special consideration due to laws or regulations in their jurisdiction). ", "page_idx": 19}, {"type": "text", "text": "10. Broader Impacts ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "Question: Does the paper discuss both potential positive societal impacts and negative societal impacts of the work performed? ", "page_idx": 19}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 19}, {"type": "text", "text": "Justification: While we utilize a diffusion model, we are not leveraging its generation abilities, so societal impacts of generative models like bias/disinformation/deepfakes etc are not relevant to our work. ", "page_idx": 19}, {"type": "text", "text": "Guidelines: ", "page_idx": 19}, {"type": "text", "text": "\u2022 The answer NA means that there is no societal impact of the work performed. ", "page_idx": 19}, {"type": "text", "text": "\u2022 If the authors answer NA or No, they should explain why their work has no societal impact or why the paper does not address societal impact.   \n\u2022 Examples of negative societal impacts include potential malicious or unintended uses (e.g., disinformation, generating fake profiles, surveillance), fairness considerations (e.g., deployment of technologies that could make decisions that unfairly impact specific groups), privacy considerations, and security considerations.   \n\u2022 The conference expects that many papers will be foundational research and not tied to particular applications, let alone deployments. However, if there is a direct path to any negative applications, the authors should point it out. For example, it is legitimate to point out that an improvement in the quality of generative models could be used to generate deepfakes for disinformation. On the other hand, it is not needed to point out that a generic algorithm for optimizing neural networks could enable people to train models that generate Deepfakes faster.   \n\u2022 The authors should consider possible harms that could arise when the technology is being used as intended and functioning correctly, harms that could arise when the technology is being used as intended but gives incorrect results, and harms following from (intentional or unintentional) misuse of the technology.   \n\u2022 If there are negative societal impacts, the authors could also discuss possible mitigation strategies (e.g., gated release of models, providing defenses in addition to attacks, mechanisms for monitoring misuse, mechanisms to monitor how a system learns from feedback over time, improving the efficiency and accessibility of ML). ", "page_idx": 20}, {"type": "text", "text": "11. Safeguards ", "text_level": 1, "page_idx": 20}, {"type": "text", "text": "Question: Does the paper describe safeguards that have been put in place for responsible release of data or models that have a high risk for misuse (e.g., pretrained language models, image generators, or scraped datasets)? ", "page_idx": 20}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 20}, {"type": "text", "text": "Justification: The diffusion models utilized in this work are trained on standardized, publicly available image datasets (e.g., CelebA, ImageNet) that to our knowledge, do not contain risks of misuse or harmful generation. ", "page_idx": 20}, {"type": "text", "text": "Guidelines: ", "page_idx": 20}, {"type": "text", "text": "\u2022 The answer NA means that the paper poses no such risks.   \n\u2022 Released models that have a high risk for misuse or dual-use should be released with necessary safeguards to allow for controlled use of the model, for example by requiring that users adhere to usage guidelines or restrictions to access the model or implementing safety filters.   \n\u2022 Datasets that have been scraped from the Internet could pose safety risks. The authors should describe how they avoided releasing unsafe images.   \n\u2022 We recognize that providing effective safeguards is challenging, and many papers do not require this, but we encourage authors to take this into account and make a best faith effort. ", "page_idx": 20}, {"type": "text", "text": "12. Licenses for existing assets ", "text_level": 1, "page_idx": 20}, {"type": "text", "text": "Question: Are the creators or original owners of assets (e.g., code, data, models), used in the paper, properly credited and are the license and terms of use explicitly mentioned and properly respected? ", "page_idx": 20}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 20}, {"type": "text", "text": "Justification: Citations to relevant models and works are given. ", "page_idx": 20}, {"type": "text", "text": "Guidelines: ", "page_idx": 20}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not use existing assets.   \n\u2022 The authors should cite the original paper that produced the code package or dataset.   \n\u2022 The authors should state which version of the asset is used and, if possible, include a URL.   \n\u2022 The name of the license (e.g., CC-BY 4.0) should be included for each asset.   \n\u2022 For scraped data from a particular source (e.g., website), the copyright and terms of service of that source should be provided.   \n\u2022 If assets are released, the license, copyright information, and terms of use in the package should be provided. For popular datasets, paperswithcode.com/datasets has curated licenses for some datasets. Their licensing guide can help determine the license of a dataset.   \n\u2022 For existing datasets that are re-packaged, both the original license and the license of the derived asset (if it has changed) should be provided.   \n\u2022 If this information is not available online, the authors are encouraged to reach out to the asset\u2019s creators. ", "page_idx": 20}, {"type": "text", "text": "", "page_idx": 21}, {"type": "text", "text": "13. New Assets ", "text_level": 1, "page_idx": 21}, {"type": "text", "text": "Question: Are new assets introduced in the paper well documented and is the documentation provided alongside the assets? ", "page_idx": 21}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 21}, {"type": "text", "text": "Justification: Documentation is provided in the appendix and open-source code. ", "page_idx": 21}, {"type": "text", "text": "Guidelines: ", "page_idx": 21}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not release new assets.   \n\u2022 Researchers should communicate the details of the dataset/code/model as part of their submissions via structured templates. This includes details about training, license, limitations, etc.   \n\u2022 The paper should discuss whether and how consent was obtained from people whose asset is used.   \n\u2022 At submission time, remember to anonymize your assets (if applicable). You can either create an anonymized URL or include an anonymized zip file. ", "page_idx": 21}, {"type": "text", "text": "14. Crowdsourcing and Research with Human Subjects ", "text_level": 1, "page_idx": 21}, {"type": "text", "text": "Question: For crowdsourcing experiments and research with human subjects, does the paper include the full text of instructions given to participants and screenshots, if applicable, as well as details about compensation (if any)? ", "page_idx": 21}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 21}, {"type": "text", "text": "Justification: No human subjects are required in this work. ", "page_idx": 21}, {"type": "text", "text": "Guidelines: ", "page_idx": 21}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u2022 Including this information in the supplemental material is fine, but if the main contribution of the paper involves human subjects, then as much detail as possible should be included in the main paper.   \n\u2022 According to the NeurIPS Code of Ethics, workers involved in data collection, curation, or other labor should be paid at least the minimum wage in the country of the data collector. ", "page_idx": 21}, {"type": "text", "text": "15. Institutional Review Board (IRB) Approvals or Equivalent for Research with Human Subjects ", "text_level": 1, "page_idx": 21}, {"type": "text", "text": "Question: Does the paper describe potential risks incurred by study participants, whether such risks were disclosed to the subjects, and whether Institutional Review Board (IRB) approvals (or an equivalent approval/review based on the requirements of your country or institution) were obtained? ", "page_idx": 21}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 21}, {"type": "text", "text": "Justification: No human subjects or crowdsourcing are required in this work. ", "page_idx": 21}, {"type": "text", "text": "Guidelines: ", "page_idx": 21}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects. ", "page_idx": 21}, {"type": "text", "text": "\u2022 Depending on the country in which research is conducted, IRB approval (or equivalent) may be required for any human subjects research. If you obtained IRB approval, you should clearly state this in the paper.   \n\u2022 We recognize that the procedures for this may vary significantly between institutions and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the guidelines for their institution.   \n\u2022 For initial submissions, do not include any information that would break anonymity (if applicable), such as the institution conducting the review. ", "page_idx": 22}]