[{"figure_path": "0d50Il6enG/figures/figures_1_1.jpg", "caption": "Figure 1: Top: A point x \u2208 R2 (coordinate-wise values are different shades of gray) and its projection y = \u0398x \u2208 R15 (coordinate-wise values are different shades of red). The sparsification step sets the largest 5 values of y to 1 (black squares) and the rest to zero. Bottom: Activated response regions Cj, x \u2208 Cj, (x is a red dot), are shown using different colors. The points from the training set that intersects with these activated response regions are shown using black dots.", "description": "This figure illustrates the expand-and-sparsify (EaS) representation of a data point.  The top part shows a 2D point being randomly projected into a higher 15D space. The sparsification process then selects the top 5 largest values and sets them to 1 (shown as black squares), setting the rest to zero. The bottom part depicts the activated response regions (Cj) in the original 2D space, which serve as neighborhoods for the data point (shown as a red dot). Black dots represent training data points that fall within these regions.", "section": "1 Introduction"}, {"figure_path": "0d50Il6enG/figures/figures_3_1.jpg", "caption": "Figure 2: Empirical evaluation of Alg. 1, k-NN (for k = 1 and 10) and RF on eight datasets Here expansion factor is m/d. An error bar in the form of a shaded graph is provided for Alg. 1 over 10 independent runs.", "description": "This figure compares the performance of the proposed algorithm (Alg. 1) against k-Nearest Neighbors (k-NN) and Random Forest (RF) classifiers on eight different datasets. The x-axis represents the expansion factor (m/d), which is the ratio of the projection dimensionality (m) to the original dimensionality (d). The y-axis represents the test accuracy of each classifier.  Error bars are included for Alg. 1 to show variability across 10 independent runs. The figure illustrates how the accuracy of Alg. 1 improves with increasing expansion factor, eventually becoming comparable to k-NN and RF.", "section": "5 Empirical evaluations"}, {"figure_path": "0d50Il6enG/figures/figures_9_1.jpg", "caption": "Figure 2: Empirical evaluation of Alg. 1, k-NN (for k = 1 and 10) and RF on eight datasets Here expansion factor is m/d. An error bar in the form of a shaded graph is provided for Alg. 1 over 10 independent runs.", "description": "This figure compares the performance of the proposed algorithm (Alg. 1) with k-NN and random forest (RF) on eight benchmark datasets.  The x-axis represents the expansion factor (m/d), which is a key hyperparameter in Alg. 1.  The y-axis shows the test accuracy achieved by each method. Error bars are included for Alg. 1, representing results from 10 independent runs to demonstrate the variability. The results indicate how the proposed algorithm's performance changes with varying levels of dimensionality expansion and compares its accuracy to other commonly used non-parametric methods.", "section": "5 Empirical evaluations"}]