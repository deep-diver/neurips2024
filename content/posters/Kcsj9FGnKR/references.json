{"references": [{"fullname_first_author": "Kaiming He", "paper_title": "Deep residual learning for image recognition", "publication_date": "2016-00-00", "reason": "This paper is foundational to many modern image classification models, and its concepts are implicitly used and extended in this work."}, {"fullname_first_author": "Alexey Dosovitskiy", "paper_title": "An image is worth 16x16 words: Transformers for image recognition at scale", "publication_date": "2021-00-00", "reason": "This paper introduces the Vision Transformer architecture, a crucial development in image processing that is relevant to the architecture used in this paper."}, {"fullname_first_author": "Ze Liu", "paper_title": "Swin transformer: Hierarchical vision transformer using shifted windows", "publication_date": "2021-00-00", "reason": "The Swin Transformer, introduced in this paper, is a significant improvement to the Vision Transformer that is directly relevant to the model used in this work."}, {"fullname_first_author": "Tsung-Yi Lin", "paper_title": "Focal loss for dense object detection", "publication_date": "2017-00-00", "reason": "This paper presents Focal Loss, a loss function crucial in addressing class imbalance in object detection and classification, and it's directly relevant to the approach of this paper."}, {"fullname_first_author": "Jonathan Ho", "paper_title": "Denoising diffusion probabilistic models", "publication_date": "2020-00-00", "reason": "This paper introduces denoising diffusion probabilistic models (DDPMs), which form the basis of the generative model used in this work."}]}