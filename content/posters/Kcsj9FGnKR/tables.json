[{"figure_path": "Kcsj9FGnKR/tables/tables_3_1.jpg", "caption": "Table 1: FID of different generation models and their corresponding classifiers' accuracy.", "description": "This table presents the Fr\u00e9chet Inception Distance (FID) scores and the corresponding classification accuracy for different generative models.  Lower FID scores indicate that the generated samples are more realistic and closer to the real data distribution.  The models compared are a baseline (no generation), a standard Denoising Diffusion Probabilistic Model (DDPM), and variations of the Class-Balancing Diffusion Model (CBDM) with different hyperparameters (\u03c4). The table shows that as the FID decreases (meaning better generation quality), the classification accuracy tends to increase.", "section": "3.2 DiffuLT: Diffusion model for Long-Tail recognition"}, {"figure_path": "Kcsj9FGnKR/tables/tables_3_2.jpg", "caption": "Table 2: Percentage of different types of generated samples for each model.", "description": "This table presents the percentage of In-distribution (ID), Approximately in-distribution (AID), and Out-of-distribution (OOD) samples generated by different models.  The models compared are DDPM and CBDM with different tau (\u03c4) values.  The results show how the different models' generated samples are distributed across these three categories, indicating the model's ability to generate samples that closely resemble the original data distribution.", "section": "3.2 DiffuLT: Diffusion model for Long-Tail recognition"}, {"figure_path": "Kcsj9FGnKR/tables/tables_4_1.jpg", "caption": "Table 3: Quantities, overall classifier enhancement, and average improvement per sample for different groups of data generated by diffusion model.", "description": "This table presents a quantitative analysis of the impact of different types of generated samples (ID, AID, OOD) on classifier accuracy.  It shows the number of samples generated for each category, the resulting classifier accuracy when those samples are added to the training dataset, and the average accuracy improvement per sample.  The results highlight the significant contribution of AID samples to improving classifier performance, while OOD samples have a negative impact.", "section": "4.2 Experimental Results"}, {"figure_path": "Kcsj9FGnKR/tables/tables_4_2.jpg", "caption": "Table 4: Diffusion trained with varying proportions of head class data and the corresponding results for tail classes.", "description": "This table presents the results of experiments conducted to investigate how varying the proportion of head class data in the training process affects the generation of AID samples and the performance of the classifier on tail classes. The proportion of head class data (ph) is varied from 0% to 100%, and for each proportion, the proportion of AID samples (pAID) and the accuracy of the classifier on the tail classes (Acct) are reported.  The results show a correlation between the proportion of head class data and the performance on tail classes. As the proportion of head class data increases, the proportion of AID samples and the accuracy on tail classes also tend to increase, suggesting that the inclusion of head class data in the generative process can improve the quality and diversity of the samples generated for tail classes.", "section": "4.2 Experimental Results"}, {"figure_path": "Kcsj9FGnKR/tables/tables_7_1.jpg", "caption": "Table 2: Percentage of different types of generated samples for each model.", "description": "This table presents the percentage of In-distribution (ID), Approximately in-distribution (AID), and Out-of-distribution (OOD) samples generated by different models (DDPM, CBDM with different tau values, and the proposed method).  It shows how the proposed method improves the generation of AID samples, which are crucial for enhancing classifier accuracy.", "section": "3.2 DiffuLT: Diffusion model for Long-Tail recognition"}, {"figure_path": "Kcsj9FGnKR/tables/tables_7_2.jpg", "caption": "Table 6: Methods and types of retained samples, pre-filtering counts, and classification accuracy.", "description": "This table compares different methods for retaining generated samples and their impact on classification accuracy.  It shows the number of samples kept (after filtering), the total number of generated samples before filtering, and the resulting classification accuracy. The methods compared include CBDM with different sample selection criteria (all, AID only, ID and AID) and the proposed \"Ours\" method.", "section": "4.2 Experimental Results"}, {"figure_path": "Kcsj9FGnKR/tables/tables_7_3.jpg", "caption": "Table 7: Results on CIFAR100-LT and CIFAR10-LT datasets. The imbalance ratio r is set to 100, 50 and 10. The highest-performing results are in bold, with the second-best in underline. Additionally, we present the results for different groups (many, medium, and few) in CIFAR100-LT with r = 100.", "description": "This table presents the quantitative results of the proposed DiffuLT model and several baseline methods on CIFAR100-LT and CIFAR10-LT datasets. The performance is evaluated under different long-tail ratios (r=100, 50, 10) and is broken down into three groups based on the number of samples in each class (many, medium, few) for CIFAR100-LT with r=100.  The best performing methods are highlighted in bold, with the second best underlined.", "section": "4.2 Experimental Results"}, {"figure_path": "Kcsj9FGnKR/tables/tables_8_1.jpg", "caption": "Table 8: Results on ImageNet-LT. We deploy ResNet-10 and ResNet-50 as classifier backbones. Top-performing results are highlighted in bold, with second-best outcomes underlined.", "description": "This table presents the performance of different long-tailed recognition methods on the ImageNet-LT dataset.  The results are broken down by the classifier backbone used (ResNet-10 and ResNet-50) and further categorized by the number of samples in each class (All, Many, Medium, Few).  The top-performing methods are highlighted in bold, while the second-best performers are underlined. This allows for a comparison of various methods across different scales of class imbalance.", "section": "4.2 Experimental Results"}, {"figure_path": "Kcsj9FGnKR/tables/tables_8_2.jpg", "caption": "Table 9: Ablation experiments to verify the effect of each module.", "description": "This table presents the ablation study results on CIFAR100-LT with an imbalance ratio of 100. It systematically evaluates the impact of different components of the proposed DiffuLT method, namely the generation of samples (Gen.), the AID-biased loss (LAID), the filtering of OOD samples (Filt.), and the weighting of generated samples in the classification loss (Weight). The accuracy (Acc.) achieved by each configuration is reported, showcasing the significance of each component for improved performance.", "section": "4.3 Ablation Study"}, {"figure_path": "Kcsj9FGnKR/tables/tables_14_1.jpg", "caption": "Table 11: Repeated experiments on CIFAR100-LT and CIFAR10-LT to test the robustness of our methods.", "description": "This table presents the results of repeated experiments conducted on the CIFAR100-LT and CIFAR10-LT datasets to evaluate the robustness of the DiffuLT method. The experiments were repeated three times (DiffuLT(1), DiffuLT(2), DiffuLT(3)), and the table shows the accuracy achieved for each repetition at different long-tail ratios (r = 100, 50, 10).  The consistency of the results across the repetitions demonstrates the robustness and reliability of the proposed method.", "section": "4.2 Experimental Results"}, {"figure_path": "Kcsj9FGnKR/tables/tables_14_2.jpg", "caption": "Table 12: Repeated experiments on ImageNet-LT to test the robustness of methods.", "description": "This table presents the results of repeated experiments conducted on the ImageNet-LT dataset to evaluate the robustness of the DiffuLT method. Three separate experiments (DiffuLT(1), DiffuLT(2), and DiffuLT(3)) were performed using ResNet-10 and ResNet-50 as classifier backbones.  The table demonstrates the consistency of the method's performance across multiple runs, showcasing its robustness.", "section": "4.2 Experimental Results"}, {"figure_path": "Kcsj9FGnKR/tables/tables_16_1.jpg", "caption": "Table 13: Results on CIFAR100-LT using an alternative pipeline based on the implementation guidelines from BSCE Ren et al. [2020], with imbalance ratios r set at 100, 50, and 10.", "description": "This table presents the results of experiments on the CIFAR100-LT dataset using a modified pipeline. The baseline results are compared to the results obtained using the BSCE, PaCo, and GPaCo methods.  The table also shows the performance of the DiffuLT method, both alone and when combined with GPaCo.  The imbalance ratio (r) is varied across three levels (100, 50, and 10) to evaluate performance across different levels of class imbalance.", "section": "A.5 Other Methods"}]