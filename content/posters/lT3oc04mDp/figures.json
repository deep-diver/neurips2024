[{"figure_path": "lT3oc04mDp/figures/figures_1_1.jpg", "caption": "Figure 1: Comparison of various self-drafting speculative decoding methods without tree mask on Spec-Bench [22] for Vicuna-7B [12]. Kangaroo outperforms all other methods w.r.t. end-to-end speedup ratio across all the four subtasks. Specifically, Kangaroo (without tree) achieves speedups of 1.68\u00d7 on MT-bench [23], outperforming Medusa with 88.7% fewer additional parameters.", "description": "This figure compares the performance of Kangaroo against other self-drafting speculative decoding methods (Medusa, REST, and Lookahead) on the Spec-Bench benchmark using the Vicuna-7B language model.  The comparison focuses on the token acceptance rate (the percentage of draft tokens accepted by the main model) and end-to-end speedup. Kangaroo demonstrates superior performance in terms of speedup across multiple subtasks, even with significantly fewer parameters than Medusa.", "section": "1 Introduction"}, {"figure_path": "lT3oc04mDp/figures/figures_1_2.jpg", "caption": "Figure 1: Comparison of various self-drafting speculative decoding methods without tree mask on Spec-Bench [22] for Vicuna-7B [12]. Kangaroo outperforms all other methods w.r.t. end-to-end speedup ratio across all the four subtasks. Specifically, Kangaroo (without tree) achieves speedups of 1.68\u00d7 on MT-bench [23], outperforming Medusa with 88.7% fewer additional parameters.", "description": "This figure compares the performance of Kangaroo and other self-drafting speculative decoding methods on four subtasks of the Spec-Bench benchmark using the Vicuna-7B language model.  The left subplot shows the token acceptance rate for each method, plotting the rate against the token position, revealing how quickly each method confirms the generated tokens. The right subplot shows the end-to-end speedup of each method across the four subtasks (MT Bench, Math, RAG, Summarization). Kangaroo consistently demonstrates superior performance compared to other methods, showing substantial improvements in overall efficiency with fewer additional parameters.", "section": "1 Introduction"}, {"figure_path": "lT3oc04mDp/figures/figures_3_1.jpg", "caption": "Figure 2: The framework of Kangaroo under single-sequence verification. The adapter network A consists of only one multi-head attention and two normalization layers. The self-drafting model Ms = A M\u266d[: 1] will reuse the LM Head of the target LLM M\u266d for better alignment, where I denotes the early exit layer. To avoid unnecessary costs on more difficult tokens, Ms stops drafting once the top-1 probability of the current sampled token falls below a certain threshold, e.g., Ms(13 | 20:2) \u2264 \u03b7. Note that we will concatenate the stopped token's next early feature f3 with all previous exited features into a parallel compute unit [fo, f1,\u00b7\u00b7\u00b7, f3], which will be verified by the remaining layers M\u2081[l :] in parallel. Once all drafted tokens are accepted (i = x; for i = 1, 2, 3), we could start the next round with x4 rather than x3 if we have not calculated f3 in advance. The decoding on parallel unit [f3, f4] could save the latency for a single forward pass of A.", "description": "This figure illustrates the Kangaroo framework during single-sequence verification. It highlights the use of a self-drafting model (Ms) composed of an adapter network (A) and a shallow sub-network of the target LLM (M\u266d).  The self-drafting model generates draft tokens until a confidence threshold is met, at which point parallel computation is used to verify the tokens.  The diagram shows two rounds of this process, illustrating how parallel computation reduces latency.", "section": "4 Kangaroo"}, {"figure_path": "lT3oc04mDp/figures/figures_4_1.jpg", "caption": "Figure 4: The density of top-1 conditional probability on the mathematical reasoning subtask. \u201cAccept\u201d denotes the top-1 confidence of accepted draft tokens while \u201cReject\u201d denotes the corresponding confidence of rejected tokens.", "description": "This figure shows the distribution of the top-1 probability (confidence) scores from the self-drafting model in Kangaroo.  It compares the distributions for tokens that were accepted by the main language model (Accept) versus tokens that were rejected (Reject).  The x-axis represents the top-1 probability, while the y-axis represents the probability density.  The distributions clearly show that accepted tokens have significantly higher confidence scores than rejected tokens, demonstrating the effectiveness of the early exiting mechanism.", "section": "4.2 Dynamic Drafting Steps via Token-Level Early-Exiting"}, {"figure_path": "lT3oc04mDp/figures/figures_5_1.jpg", "caption": "Figure 5: Comparison of various speculative decoding methods on Spec-Bench [22] for Vicuna-7B, where Kangaroo outperforms other approaches in most subtasks, especially in mathematical reasoning and retrieval-augmented generation.", "description": "This figure compares the performance of various speculative decoding methods, including Kangaroo, Lookahead, Medusa, SpS, and REST, across six subtasks in Spec-Bench for the Vicuna-7B model. The left plot shows the compression rate, and the right plot shows the end-to-end speedup ratio. Kangaroo consistently outperforms other methods in most subtasks, particularly in mathematical reasoning and retrieval-augmented generation, demonstrating its effectiveness in accelerating large language model decoding.", "section": "5 Experiments"}, {"figure_path": "lT3oc04mDp/figures/figures_7_1.jpg", "caption": "Figure 6: The optimal early-exit ratio.", "description": "This figure shows the relationship between the early-exit ratio (l/N) and the walltime speedup achieved by Kangaroo on four different LLMs: Vicuna-7B, Vicuna-13B, Vicuna-33B, and Llama2-13B-Chat.  The x-axis represents the ratio of the number of early-exit layers (l) to the total number of layers (N) in the model. The y-axis represents the walltime speedup achieved by Kangaroo compared to standard decoding. The figure demonstrates that there is an optimal early-exit ratio for each model, beyond which the speedup decreases. The shaded area highlights the recommended range of early-exit ratios. ", "section": "5.2 Ablation Studies"}, {"figure_path": "lT3oc04mDp/figures/figures_8_1.jpg", "caption": "Figure 7: Ablation studies on hyper-parameters. The compression rate and walltime speedup is averaged across all sub-benchmarks in Spec-Bench [22]. It can be seen that there is a trade-off between token acceptance rate and drafting efficiency. While deeper early-exit layer l can enhance the expressive power of the equivalent draft model in Kangaroo, the increased inference latency can actually hinder the overall acceleration performance of the system.", "description": "This figure shows the ablation study results on two hyperparameters: the depth of the shallow sub-network (l) and the early stopping threshold (\u03b7).  The left two subfigures (a) show that increasing the depth of the shallow sub-network initially improves compression rate and speedup, but after a certain point, increasing the depth leads to diminishing returns and even performance degradation due to increased latency. The right two subfigures (b) illustrate that the optimal threshold (\u03b7) for the early stopping mechanism varies slightly with the number of drafting steps (\u03b3) but remains relatively stable across different scenarios.", "section": "5.2 Ablation Studies"}, {"figure_path": "lT3oc04mDp/figures/figures_12_1.jpg", "caption": "Figure 8: The density of top-1 conditional probability on various subtasks for Vicuna-7B [12].", "description": "This figure shows the distribution of the top-1 conditional probability on various subtasks for Vicuna-7B. The x-axis represents the top-1 probability, and the y-axis represents the probability density. The figure is divided into six subplots, each corresponding to a different subtask: Translation, QA, Summarization, Math, RAG, and MT Bench. For each subtask, the distribution of the top-1 probability is shown for both accepted and rejected tokens. The figure helps visualize the relationship between the top-1 probability and the likelihood of a token being accepted or rejected.", "section": "Appendix"}, {"figure_path": "lT3oc04mDp/figures/figures_12_2.jpg", "caption": "Figure 8: The density of top-1 conditional probability on various subtasks for Vicuna-7B [12].", "description": "This figure shows the distribution of the top-1 conditional probability generated by the self-drafting model (Ms) for accepted and rejected tokens across six subtasks of the Spec-Bench benchmark.  The x-axis represents the top-1 probability, and the y-axis represents the probability density. Separate distributions are shown for accepted (green) and rejected (red) tokens, providing insights into how well the self-drafting model's confidence correlates with token acceptance by the full model (Mb).", "section": "5.2 Ablation Studies"}]