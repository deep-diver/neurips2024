[{"figure_path": "vx4NgdyyVG/figures/figures_4_1.jpg", "caption": "Figure 1: Dynamic trend of the RDR weights well inversely aligns with B' throughout the training process in different categories. B denotes \u221a\u03c0y[1 \u2013 softmax(By(m))], where By(m) denotes the minimal prediction on the ground-truth class y, i.e., minx\u2208Sy m(x)y. Experiments were conducted on CIFAR-10-LT dataset with an imbalance factor of 10.", "description": "This figure shows the dynamic trend of RDR weights in different categories (many and few) throughout the training process.  The RDR weights show an inverse relationship with B', a value calculated based on the minimal prediction on the ground truth class. This demonstrates that RDR weights effectively adapt to the changing importance of classes during training, aligning well with the theoretical prediction. The experiment was done using the CIFAR-10-LT dataset with an imbalance factor of 10.", "section": "3.3 Dynamic Re-weighting with Density Ratio"}, {"figure_path": "vx4NgdyyVG/figures/figures_5_1.jpg", "caption": "Figure 1: Dynamic trend of the RDR weights well inversely aligns with B' throughout the training process in different categories. B denotes \u221a\u03c0y[1 \u2212 softmax(By(m))], where By(m) denotes the minimal prediction on the ground-truth class y, i.e., minx\u2208Sy m(x)y. Experiments were conducted on CIFAR-10-LT dataset with an imbalance factor of 10.", "description": "This figure shows the dynamic relationship between RDR weights and the term B' during the training process on the CIFAR-10-LT dataset, which has an imbalance factor of 10.  The plots illustrate how the weights for both many-category and few-category samples change over epochs. It shows that the RDR weights exhibit an inverse relationship to B', suggesting that RDR effectively adapts its weighting strategy to balance class distributions during training.", "section": "3.4 Generalization Bound Analysis"}, {"figure_path": "vx4NgdyyVG/figures/figures_5_2.jpg", "caption": "Figure 2: Visualization of the time cost for training 200 epochs using four methods: CE, RDR, SAM and RDR(SAM) on CIFAR-10-LT and CIFAR-100-LT datasets.", "description": "This figure compares the training time of four different methods: Cross-Entropy (CE), Re-weighting with Density Ratio (RDR), Sharpness-Aware Minimization (SAM), and a combination of RDR and SAM (SAM(RDR)) on two datasets, CIFAR-10-LT and CIFAR-100-LT.  The bar charts show that RDR and SAM are relatively more computationally expensive than CE, but SAM(RDR) is the most computationally expensive. The time cost is measured in seconds for 200 training epochs.", "section": "4 Expriments"}, {"figure_path": "vx4NgdyyVG/figures/figures_9_1.jpg", "caption": "Figure 5: Top-1 accuracy (%) (\u2191) results for overall classes on CIFAR-10-LT-NL and CIFAR-100-LT-NL with 5% noise ratio, categorized by imbalance factors (IF) of 100 and 10.", "description": "This figure visualizes the impact of noise on the performance of different methods across two datasets (CIFAR-10-LT-NL and CIFAR-100-LT-NL) with varying levels of class imbalance (IF=10 and IF=100).  It compares the performance of baseline methods (CE, LA) with and without the addition of the RDR and SAM techniques.", "section": "4.3 Ablation Study"}, {"figure_path": "vx4NgdyyVG/figures/figures_15_1.jpg", "caption": "Figure 6: Framework of RDR", "description": "This figure illustrates the framework of the Re-weighting with Density Ratio (RDR) method. The left side shows the ordinary process of feature extraction (f) and classification (g), where the feature extractor learns features from the training data and updates its feature prototypes using a momentum update mechanism. The extracted features are then used by the classifier for classification. The right side shows the dynamic re-weighting process. The RDR method dynamically adjusts the weights of different classes by using the density ratio estimation. The weights are calculated based on the difference between the balanced data distribution and the real data distribution. The figure highlights the difference between constant re-weighting and dynamic re-weighting. Constant re-weighting doesn't adapt to changes during training, while dynamic re-weighting adjusts the importance of each class during training, thereby mitigating learning disparities in imbalanced distributions.", "section": "3.3 Dynamic Re-weighting with Density Ratio"}, {"figure_path": "vx4NgdyyVG/figures/figures_18_1.jpg", "caption": "Figure 8: Visualization of top-1 accuracy (\u2191) across different categories on CIFAR-100-LT, under three different methods: CE, Inverse Frequency (1/n) and RDR. Experiments conducted under IF=10 (Plot (a) and Plot (b)) and 100 (Plot (c) and Plot (d)).", "description": "This figure visualizes the top-1 accuracy achieved by three different methods (Cross-Entropy, Inverse Frequency weighting, and the proposed Re-weighting with Density Ratio method) across three categories of classes (Many, Medium, Few) in the CIFAR-100-LT dataset.  The results are shown for two different imbalance factors (IF): 10 and 100. The plots show how the accuracy changes depending on the method and the imbalance in the dataset.  This illustrates the effect of the proposed RDR method on mitigating the performance drop caused by class imbalance.", "section": "4.2 Comparison Results"}, {"figure_path": "vx4NgdyyVG/figures/figures_18_2.jpg", "caption": "Figure 8: Visualization of top-1 accuracy (\u2191) across different categories on CIFAR-100-LT, under three different methods: CE, Inverse Frequency (1/n) and RDR. Experiments conducted under IF=10 (Plot (a) and Plot (b)) and 100 (Plot (c) and Plot (d)).", "description": "This figure visualizes the top-1 accuracy achieved by three different methods (CE, Inverse Frequency, and RDR) across three categories of classes (Many, Medium, Few) in the CIFAR-100-LT dataset.  It shows results under two different imbalance factors (IF=10 and IF=100).  The plots illustrate how the accuracy changes across categories for each method and imbalance level, showcasing the relative performance of each approach in handling class imbalance.", "section": "4.2 Comparison Results"}, {"figure_path": "vx4NgdyyVG/figures/figures_18_3.jpg", "caption": "Figure 8: Visualization of top-1 accuracy (\u2191) across different categories on CIFAR-100-LT, under three different methods: CE, Inverse Frequency (1/n) and RDR. Experiments conducted under IF=10 (Plot (a) and Plot (b)) and 100 (Plot (c) and Plot (d)).", "description": "This figure visualizes the top-1 accuracy achieved by three different methods (Cross-Entropy, Inverse Frequency, and the proposed Re-weighting with Density Ratio method) across three categories of classes (Many, Medium, and Few) in the CIFAR-100-LT dataset.  Two different imbalance factors (IF=10 and IF=100) are shown, illustrating the performance under varying levels of class imbalance.  The plots demonstrate how the proposed RDR method performs compared to the baselines, especially in the more challenging scenarios with a higher imbalance factor and fewer samples.", "section": "4.2 Comparison Results"}, {"figure_path": "vx4NgdyyVG/figures/figures_18_4.jpg", "caption": "Figure 8: Visualization of top-1 accuracy (\u2191) across different categories on CIFAR-100-LT, under three different methods: CE, Inverse Frequency (1/n) and RDR. Experiments conducted under IF=10 (Plot (a) and Plot (b)) and 100 (Plot (c) and Plot (d)).", "description": "This figure compares the performance of three different methods (Cross-Entropy, Inverse Frequency, and Re-weighting with Density Ratio) in classifying images from the CIFAR-100-LT dataset under two different imbalance factors (10 and 100).  The x-axis represents the category of images (Many, Medium, Few), and the y-axis shows the accuracy.  The plots demonstrate how each method performs across these categories, with a focus on the difference in performance under varying levels of class imbalance.", "section": "4.2 Comparison Results"}, {"figure_path": "vx4NgdyyVG/figures/figures_18_5.jpg", "caption": "Figure 8: Visualization of top-1 accuracy (\u2191) across different categories on CIFAR-100-LT, under three different methods: CE, Inverse Frequency (1/n) and RDR. Experiments conducted under IF=10 (Plot (a) and Plot (b)) and 100 (Plot (c) and Plot (d)).", "description": "This figure shows the performance comparison of three different methods (Cross Entropy, Inverse Frequency, and Re-weighting with Density Ratio) on CIFAR-100-LT dataset in terms of top-1 accuracy across different categories (Many, Medium, and Few).  The comparison is shown for two different imbalance factors (10 and 100). The results indicate that RDR generally outperforms the other two methods, especially when the imbalance factor is high.", "section": "4.2 Comparison Results"}, {"figure_path": "vx4NgdyyVG/figures/figures_18_6.jpg", "caption": "Figure 8: Visualization of top-1 accuracy (\u2191) across different categories on CIFAR-100-LT, under three different methods: CE, Inverse Frequency (1/n) and RDR. Experiments conducted under IF=10 (Plot (a) and Plot (b)) and 100 (Plot (c) and Plot (d)).", "description": "This figure visualizes the top-1 accuracy achieved by three different methods (Cross-Entropy, Inverse Frequency, and Re-weighting with Density Ratio) across three categories of classes (Many, Medium, Few) in the CIFAR-100-LT dataset.  Two different imbalance factors (IF=10 and IF=100) are shown, comparing the performance of each method under varying levels of class imbalance. The plots demonstrate how each method's accuracy changes as the number of samples per class decreases.", "section": "4.2 Comparison Results"}, {"figure_path": "vx4NgdyyVG/figures/figures_18_7.jpg", "caption": "Figure 8: Visualization of top-1 accuracy (\u2191) across different categories on CIFAR-100-LT, under three different methods: CE, Inverse Frequency (1/n) and RDR. Experiments conducted under IF=10 (Plot (a) and Plot (b)) and 100 (Plot (c) and Plot (d)).", "description": "This figure visualizes the top-1 accuracy achieved by three different methods (Cross-Entropy, Inverse Frequency, and Re-weighting with Density Ratio) across three categories of classes (Many, Medium, Few) in the CIFAR-100-LT dataset.  The results are shown for two different imbalance factors (IF=10 and IF=100).  It demonstrates the performance difference of the three methods in handling imbalanced datasets.", "section": "4.2 Comparison Results"}, {"figure_path": "vx4NgdyyVG/figures/figures_18_8.jpg", "caption": "Figure 8: Visualization of top-1 accuracy (\u2191) across different categories on CIFAR-100-LT, under three different methods: CE, Inverse Frequency (1/n) and RDR. Experiments conducted under IF=10 (Plot (a) and Plot (b)) and 100 (Plot (c) and Plot (d)).", "description": "The figure shows the performance comparison of three different methods (Cross-Entropy loss, Inverse Frequency weighting, and the proposed Re-weighting with Density Ratio) in addressing class imbalance on the CIFAR-100-LT dataset. The results are categorized into three groups (Many, Medium, Few) based on the number of samples in each class.  The plots illustrate how each method performs under two imbalance factors (IF=10 and IF=100), highlighting the impact of class imbalance on model accuracy.", "section": "4.2 Comparison Results"}]