[{"type": "text", "text": "Revive Re-weighting in Imbalanced Learning by Density Ratio Estimation ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Jiaan Luo1,3\u2020 Feng Hong1\u2020 Jiangchao $\\mathbf{Yao^{1,3\\frac{1}{\\div}}}$ Bo Han4 Ya Zhang2,3 Yanfeng Wang2,3 ", "page_idx": 0}, {"type": "text", "text": "1Cooperative Medianet Innovation Center, Shanghai Jiao Tong University 2School of Artificial Intelligence, Shanghai Jiao Tong University 3Shanghai Artificial Intelligence Laboratory 4Hong Kong Baptist University {luojiaan, feng.hong, Sunarker, ya_zhang, wangyanfeng}@sjtu.edu.cn bhanml@comp.hkbu.edu.hk ", "page_idx": 0}, {"type": "text", "text": "Abstract ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "In deep learning, model performance often deteriorates when trained on highly imbalanced datasets, especially when evaluation metrics require robust generalization across underrepresented classes. To address the challenges posed by imbalanced data distributions, this study introduces a novel method utilizing density ratio estimation for dynamic class weight adjustment, termed as Re-weighting with Density Ratio (RDR). Our method adaptively adjusts the importance of each class during training, mitigates overftiting on dominant classes and enhances model adaptability across diverse datasets. Extensive experiments conducted on various large scale benchmark datasets validate the effectiveness of our method. Results demonstrate substantial improvements in generalization capabilities, particularly under severely imbalanced conditions. The code is available here. ", "page_idx": 0}, {"type": "text", "text": "1 Introduction ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "In recent years, deep learning has made significant strides across various domains by utilizing complex architectures and large-scale datasets, setting new benchmarks for performance. However, these advancements often rely on well-curated datasets that ensure balanced class distributions [Russakovsky et al., 2015]. In contrast, real-world datasets typically exhibit a long-tailed distribution, where few classes dominate the majority of samples, while many others are underrepresented [Krizhevsky et al., 2009]. This imbalance leads to model biases favoring frequent classes, thereby reducing performance on the less common ones. Yet, in many applications\u2014such as medical diagnostics and financial analysis\u2014greater emphasis is placed on ensuring strong generalization for underrepresented classes. Addressing this challenge not only reduces data collection costs but also improves the robustness and fairness of the models. ", "page_idx": 0}, {"type": "text", "text": "Many excellent methods, such as re-sampling [Bowyer et al., 2011], re-weighting [Morik et al., 1999], decoupled learning [Kang et al., 2020], margin-based learning [Cao et al., 2019, Menon et al., 2020], transfer learning [Yin et al., 2019] and contrastive learning [Tian et al., 2021], have been proposed to tackle the issue of imbalanced data. Despite the simplicity of re-weighting, it falls behind in performance significantly compared with other directions of methods due to the inappropriate weighting coefficients during training. Cui et al. [2019] proposes a method for re-weighting by effective number, which accounts for potential overlaps among data samples and adjusts the weights for each category based on the actual effective number of samples. Chen et al. [2023b] leverages the effective area to re-weight, considering the actual spanned space of each class. However, such subsequent improvements can alleviate but still cannot effectively push that forward. Wang et al. ", "page_idx": 0}, {"type": "text", "text": "[2023] obtains a fine-grained generalization bound for re-weighting in imbalanced learning through the data-dependent contraction technique. Limited research has focused on the intrinsic limitations of the commonly employed re-weighting-based loss functions and the corresponding balancing mechanisms designed to enhance parity in class representation. ", "page_idx": 1}, {"type": "text", "text": "This study rethinks the characteristics of re-weighted loss and explores the question \"Why is reweighting necessary under conditions of sample imbalance?\" Under conditions of sample imbalance, the variation in weights of samples arises due to discrepancies between the distribution of collected data and a balanced data distribution. In scenarios where class balance exists, such discrepancies are absent, thus obviating the need for re-weighting. Conversely, in imbalanced settings, re-weighting becomes essential to bridge the gap between these distributions. The weights must therefore represent a suitable compromise between balanced and imbalanced distributions and necessarily reflect accurately on each sample. Additionally, as model training progresses dynamically, optimizing the fit to feature distributions, the weights applied to each sample should be continuously updated to maintain robust performance. ", "page_idx": 1}, {"type": "text", "text": "This research introduces a novel method, Reweighting with Density Ratio (RDR), designed to mitigate learning disparities in imbalanced distributions. In this method, a feature extractor is employed to discern the features from the training data. A more balanced feature distribution is approximated by continuously updating the momentum on the feature level. This enables real-time density ratio estimation with features learned under imbalanced distributions, thereby obtaining the sample-wise weights. Notably, as the learned features evolve, our method dynamically adjusts weights in response to observed shifts in class density throughout the training cycle, ensuring that the model remains adaptive and effective. This method significantly enhances the robustness and adaptability of the training process. By integrating density ratio estimation to evaluate the difference between the balanced and real data distributions, our approach more accurately reflects the underlying class distribution and improves the model\u2019s generalization capabilities across diverse datasets. The contributions are summarized as follows: ", "page_idx": 1}, {"type": "text", "text": "\u2022 We explore the existing re-weighting techniques, and model the performance of various algorithms during training under different data distributions. This approach offers a novel perspective on understanding re-weighting methods in the scenarios of sample imbalance. \u2022 We introduce a novel methodology, Re-weighting with Density Ratio (RDR), which leverages the method of density ratio estimation to dynamically adjust class weights during model training. This approach not only addresses the limitations of prior re-weighting methods but also introduces a mechanism to continuously adapt to the changing importance of classes as learning progresses, thereby enhancing model robustness and adaptability. \u2022 We conduct extensive experiments to validate the effectiveness of our proposed RDR method. These experiments are conducted across various large-scale, long-tailed datasets, demonstrating substantial improvements in handling class imbalance. Our results illustrate significant enhancements in generalization capabilities, particularly under severely imbalanced scenarios. ", "page_idx": 1}, {"type": "text", "text": "2 Related Work ", "text_level": 1, "page_idx": 1}, {"type": "text", "text": "2.1 Re-weighting Based Methods ", "text_level": 1, "page_idx": 1}, {"type": "text", "text": "Re-weighting methods for addressing class imbalance have evolved significantly over the years. Early techniques, such as [Zadrozny et al., 2003], employed inverse frequency techniques to address class imbalances but failed to consider deeper data distribution traits, leading to sub-optimal outcomes. Addressing these shortcomings, Huang et al. [2016] introduced a cost-sensitive learning framework that, beyond simple frequency adjustments, incorporated misclassification costs to achieve a more nuanced balance. However, this approach still struggled with complexities like class overlap and label noise. To further refine this approach, Lin et al. [2017] developed Focal Loss, which employs a modulation factor based on the prediction probability to adjust the loss function, thereby amplifying the impact of hard-to-classify samples while reducing the loss contribution of easy-to-classify samples. Cui et al. [2019] introduced Class-Balanced Loss, which adjusts loss by data overlap, calculating the effective number of each class. Advancements continued with methods based on training gradients, such as [Ren et al., 2020b, Wang et al., 2021a]. Chen et al. [2023b] proposed Adaptive Re-weighting via effective area, which enhances model accuracy by considering the spatial distribution and density of data points within classes. Ma et al. [2023] introduced a re-weighting method that adjusts based on semantic richness and visual variability. However, no prior work has tackled the issue of sample imbalance by dynamically re-weighting based on the model\u2019s performance across training and test sets with differing distributions during the training process. ", "page_idx": 1}, {"type": "text", "text": "", "page_idx": 2}, {"type": "text", "text": "2.2 Non-re-weighting Based Methods ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "In addition to re-weighting, many other methods are available to address the issue of sample imbalance. Re-sampling techniques [Kubat and Matwin, 1997, Wallace et al., 2011, Han et al., 2005, Hong et al., 2024a] mitigate category imbalances by under-sampling dominant classes [Buda et al., 2018] or over-sampling minority classes [Bowyer et al., 2011]. However, under-sampling may degrade feature representation by discarding valuable majority class data, whereas over-sampling could cause overfitting by duplicating minority class samples. Decoupled training approaches, such as [Kang et al., 2020], challenge the traditional joint training model by separating representation learning from classification. Margin-based methods such as, LADM [Cao et al., 2019], LA [Menon et al., 2020] and VS [Kini et al., 2021], adjust training processes to increase minority class margins, therefore to obtain a more balanced decision boundary. More flexible and robust methods are proposed, including Transfer Learning [Yin et al., 2019, Liu et al., 2019], Contrastive Learning [Li et al., 2022, Chen et al., 2023a], Ensemble Learning [Wang et al., 2021b, Cai et al., 2021] and Self-supervised Learning [Liu et al., 2022, Zhou et al., 2023b]. Please refer to Appendix B for more discussions. ", "page_idx": 2}, {"type": "text", "text": "3 Method ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "3.1 Problem Setup ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "For a typical classification task in imbalanced learning, suppose given a training dataset ${\\boldsymbol{S}}\\,=$ $\\textstyle\\bigcup_{i=1}^{n}\\{{\\bar{({\\pmb x_{i}},{\\pmb y_{i}})}}\\}$ , where $n$ is the total number of samples. Denote $\\{n_{1},n_{2},...,n_{d}\\}\\mathbf{a}$ s the sample number of each class. We assume, without loss of generality, that $n_{i}<n_{j}$ , when $i<j$ , with $n_{d}$ typically much larger than $n_{1}$ , reflecting a pronounced imbalance in class distribution. We use a typical loss function like $l\\colon{\\mathcal{W}}\\times{\\mathcal{X}}\\times{\\mathcal{Y}}\\to{\\mathbb{R}}_{+}$ . Denote $\\{\\pi_{1},\\pi_{2},...,\\pi_{d}\\}$ as the proportions of each class, such that $\\textstyle\\sum_{i=1}^{d}\\pi_{i}\\;=\\;1$ . Define a family of deep learning models parameterized by $\\omega\\in\\mathcal{W}\\subseteq\\mathbb{R}^{k}$ . Typically, a model consists of a feature extractor $f(x;\\phi)$ and a classifier $h(z;\\theta)$ , with $\\omega=\\cup\\{\\phi,\\theta\\}$ . The notations used in this paper are summarized in Appendix A. ", "page_idx": 2}, {"type": "text", "text": "3.2 Motivation ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "Inspired by our review of prior methods, we observe a gap in the adaptation of dynamic class-weight adjustments during training phases. Building on the groundwork of static re-weighting strategies, we introduce a novel approach utilizing the method of density ratio estimation to dynamically recalibrate class weights. This innovation aims to provide a more refined adjustment by estimating real-time class density, thereby promoting an equitable influence of all classes throughout the training. ", "page_idx": 2}, {"type": "text", "text": "3.3 Dynamic Re-weighting with Density Ratio ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "In a typical training optimization problem, our objective is to minimize the empirical risk of the loss function, i.e., $\\begin{array}{r}{\\overline{{R}}=\\frac{1}{n}\\sum_{i=1}^{n}l(x_{i},y_{i};\\omega)}\\end{array}$ . However, in imbalanced datasets, where the frequency of samples across different classes varies, it is necessary to adjust for these gaps by applying different weights for the samples. We assume that the weight of each sample is denoted by $\\alpha(x,y;\\omega)$ , then the empirical risk can be formulated like $\\begin{array}{r}{\\overline{{R}}=\\frac{1}{n}\\sum_{i=1}^{n}\\alpha(x_{i},y_{i};\\omega)l(x_{i},y_{i};\\omega)}\\end{array}$ . ", "page_idx": 2}, {"type": "text", "text": "In naive re-weighting approaches, the weight $\\alpha$ of class $y$ is often set to $\\frac{1}{\\pi_{y}}$ . This setting is based on the assumption that the distribution of the training set $P$ and the distribution balanced data set $P_{b a l}$ satisfy the equation $\\overline{{P}}(x|y;\\omega)=P_{b a l}(x|y;\\omega)$ . However, in practical training scenarios, both training and test sets are subsets drawn from the actual distribution, leading to potential missing of feature patterns. Furthermore, classes with more complex features and lower sample frequencies tend to exhibit more pronounced missing of patterns. Therefore, in the training process, there exists a discrepancy between $\\overline{{P}}(x|y;\\omega)$ and $P_{b a l}(x|y;\\omega)$ . We measure the extent of this discrepancy using the ratio $r(x|y;w)=\\overline{{P}}(x|y;\\omega)/P_{b a l}(x|y;\\omega)$ , incorporating it as a correction term into our weighting scheme. Consequently, the empirical risk can be reformulated as follows ", "page_idx": 2}, {"type": "text", "text": "", "page_idx": 3}, {"type": "equation", "text": "$$\n\\overline{{R}}=\\frac{1}{n}\\sum_{i=1}^{n}\\frac{r(x_{i}|y_{i};\\omega)}{\\pi_{y_{i}}}l(x_{i},y_{i};\\omega)\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "We can explain the rationality of this formula as follows. Considering each class $i$ , where $P_{b a l}(y_{i};\\omega)\\,\\bar{\\mathrm{~\\alpha~}}\\pi_{i}^{-1}P(y_{i};\\omega)$ and $P_{b a l}(x_{i}|y_{i};\\omega)\\,=\\,r(x_{i}|y_{i};\\omega)P(x_{i}|y_{i};\\omega)$ , with conditional probability formula, we can derive: ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{R=\\mathbb{E}_{P}\\frac{1}{\\pi_{i}}(r(x_{i}|y_{i};\\omega)l(x_{i},y_{i};\\omega))=\\mathbb{E}_{P}\\frac{P_{b a l}(y;\\omega)}{P(y;\\omega)}\\frac{P_{b a l}(x|y;\\omega)}{P(x|y;\\omega)}l(x,y;\\omega)}\\\\ &{\\quad=\\mathbb{E}_{P}\\left(\\frac{P_{b a l}(x,y;\\omega)}{P(x,y;\\omega)}l(x,y;\\omega)\\right)=\\mathbb{E}_{P_{b a l}}l(x,y;\\omega)}\\end{array}\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "Eq. (2) demonstrates that our approach aligns with the balanced risk of the loss function. Consequently, minimizing Eq. (1) also serves to minimize the balanced risk. ", "page_idx": 3}, {"type": "text", "text": "Let\u2019s take a closer look at $r(x|y;w)=\\overline{{P}}(x|y;\\omega)/P_{b a l}(x|y;\\omega)$ . The variable $r$ represents the ratio of two different distributions. We approximate this ratio using methods of density ratio estimation. This problem can be solved by first-order moment matching approach. Our goal is to minimize ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\underset{r}{\\arg\\!\\operatorname*{min}}\\left\\|\\int x r(x|y;\\omega)P_{b a l}(x|y;\\omega)\\mathrm{d}x-\\int x P(x|y;\\omega)\\mathrm{d}x\\right\\|^{2}\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "where $\\lVert\\cdot\\rVert$ denotes the Euclidean norm. Recall that we capture the features of the input samples by the feature extractor $f(x;\\phi)$ in our model, and these features are a good reflection of what our model learned from the distribution of the input samples. Therefore, in order to capture more complex structures and patterns in raw data, we use $f(x;\\phi)$ to obtain a variant of Eq. (3). Our goal can be achieved by obtaining argminr $\\mathrm{MM}^{'}(r)$ , where $\\mathrm{MM}^{'}(r)$ denotes ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\left\\|\\int f(x;\\phi)r(x|y;\\omega)P_{b a l}(x|y;\\omega)\\mathrm{d}x-\\int f(x;\\phi)P(x|y;\\omega)\\mathrm{d}x\\right\\|^{2}\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "where MM stands for \u2019moment matching\u2019. Let us ignore the irrelevant constant in $\\mathrm{MM}^{'}(r)$ , and define the rest as $\\mathrm{MM}(r)$ : ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\left|\\int f(x;\\phi)r(x|y;\\omega)P_{b a l}(x|y;\\omega)\\mathrm{d}x\\right|\\right|^{2}-2\\left\\langle\\int f(x;\\phi)r(x|y;\\omega)P(x|y;\\omega)\\mathrm{d}x,\\int f(x;\\phi)P(x|y;\\omega)\\mathrm{d}x\\right|^{2}\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "where $\\langle\\cdot,\\cdot\\rangle$ denotes the inner product. In practice, as for the real-world imbalanced data distribution $P$ , we denote $\\Phi_{P}$ to dynamically reflect the knowledge learned from the distribution $P$ , that is $\\Phi_{P}=(f(x_{1};\\phi),\\dots,f(x_{n};\\phi))$ . Remember that the output of feature extractor is $z$ , i.e., $z=f(x;\\phi)$ is a $Z$ -dimensional vector, then $\\Phi_{P}$ would be a $[Z,n]$ -dimensional vector. Similarly, we denote $\\Phi_{P}^{i}$ for class $i$ , which is a $[Z,n_{i}]$ -dimensional vector. As for the balanced data distribution $P_{b a l}$ , we design a momentum mechanism to accumulatively estimate the expectation of features learned from balanced data distribution along with the training. Concretely, for each class, we maintain a prototype feature $F$ for the entire training progress, using each batch\u2019s feature expectation for momentum updates. Therefore, we define $F_{P_{b a l}}$ as follows $\\bar{F}_{P_{b a l}}=(F_{1},\\ldots,F_{d})$ . ", "page_idx": 3}, {"type": "text", "text": "Since the total number of classes is $d$ , $F_{P_{b a l}}$ would be a $[Z,d]$ -dimensional vector. For each batch, we can obtain $\\overline{{z}}=(\\overline{{z}}_{1},...,\\overline{{z}}_{d})$ , where ${\\overline{{z}}}_{i}$ the mean of $z$ of all samples in class $i$ . Then, the momentum updates works as follows ", "page_idx": 3}, {"type": "equation", "text": "$$\nF_{P_{b a l}}\\gets m F_{P_{b a l}}+(1-m)\\overline{{z}}\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "where $m\\in[0,1)$ is a momentum coefficient. Back to Eq. (5), replace the expectations over $P_{b a l}$ and $P$ by $\\Phi_{P}$ and $F_{P_{b a l}}$ , respectively. Then, take the derivative of $\\mathrm{MM}(r)$ with respect to $r$ and set it to zero. Detailed derivations are provided in Appendix C.1. For each class $i$ , we can obtain the estimation of density ratio in imbalanced learning as follows ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\widehat{r_{i}}=n_{i}\\left({\\pmb{\\Phi}}_{P}^{i}\\,^{\\top}{\\pmb{\\Phi}}_{P}^{i}\\right)^{-1}{\\pmb{\\Phi}}_{P}^{i}^{\\,\\top}F_{i}\n$$", "text_format": "latex", "page_idx": 3}, {"type": "image", "img_path": "vx4NgdyyVG/tmp/35b91cd8dc08a509dab773ced0f45098443790121f3359683836cfd202ff2595.jpg", "img_caption": [], "img_footnote": [], "page_idx": 4}, {"type": "text", "text": "Figure 1: Dynamic trend of the RDR weigh\u221ats well inversely aligns with $B^{\\prime}$ throughout the training process in different categories. $B_{y}^{\\prime}$ denotes $\\sqrt{\\pi_{y}}\\left[1-\\mathrm{softmax}\\left(\\bar{B}_{y}(m)\\right)\\right]$ , where $B_{y}(m)$ denotes the minimal prediction on the ground-truth class $y$ , i.e., $\\operatorname*{min}_{\\mathbf{x}\\in S_{y}}m(\\mathbf{x})_{y}$ . Experiments were conducted on CIFAR-10-LT dataset with an imbalance factor of 10. ", "page_idx": 4}, {"type": "text", "text": "Substitute Eq. (7) into Eq. (1), we can obtain our object to optimize ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\overline{{R}}=\\displaystyle\\sum_{i=1}^{d}\\frac{1}{\\pi_{i}}\\sum_{y_{j}=i}n_{i}\\left(\\boldsymbol{\\Phi}_{P}^{i}^{\\top}\\boldsymbol{\\Phi}_{P}^{i}\\right)^{-1}\\boldsymbol{\\Phi}_{P}^{i}^{\\top}F_{i}\\cdot\\boldsymbol{l}(x_{j},y_{j};\\omega)}\\\\ &{\\quad\\propto\\displaystyle\\sum_{i=1}^{d}\\sum_{y_{j}=i}\\left(\\boldsymbol{\\Phi}_{P}^{i}^{\\top}\\boldsymbol{\\Phi}_{P}^{i}\\right)^{-1}\\boldsymbol{\\Phi}_{P}^{i}^{\\top}F_{i}\\cdot\\boldsymbol{l}(x_{j},y_{j};\\omega)}\\end{array}\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "In our implementation, we introduced a warm-up phase to pre-adapt the feature distribution in $F_{P_{b a l}}$ , thereby mitigating excessive oscillations during the initial stages of training. Additionally, we employed a temperature coefficient $\\gamma$ to modulate the influence of weights, which is typically set to 1. When integrating with logit adjustment (LA) [Menon et al., 2020], we adhere to the same procedures outlined in [Wang et al., 2023] to ensure the fisher consistency. The framework and pseudo-code of our method are shown in Appendix C.2 and Appendix C.3. ", "page_idx": 4}, {"type": "text", "text": "3.4 Generalization Bound Analysis ", "text_level": 1, "page_idx": 4}, {"type": "text", "text": "Here, we use a formal generalization analysis to characterize the interesting point of our method. ", "page_idx": 4}, {"type": "text", "text": "Theorem 1. Given a model $m\\in\\mathcal{M}$ and the loss function l, for any $\\delta\\in(0,1)$ , with probability at least $1-\\delta$ over the training set $\\boldsymbol{S}$ , according to [Wang et al., 2023], the following generalization bound holds for the risk on the balanced distribution ", "page_idx": 4}, {"type": "equation", "text": "$$\nR_{b a l}^{l}(m)\\preccurlyeq\\Phi\\left(l,\\delta\\right)+\\frac{\\mathfrak{S}_{S}(\\mathcal{M})}{d\\pi_{1}}\\sum_{y=1}^{d}w_{y}\\sqrt{\\pi_{y}}\\left[1-\\mathrm{softmax}\\left(B_{y}(m)\\right)\\right]\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "where $\\Phi\\left(l,\\delta\\right)$ is positively correlated with the empirical re-weighting risk of the training set. $\\mathfrak{C}_{S}(\\mathcal{M})$ denotes the empirical complexity of the function set $\\mathcal{M}$ . $B_{y}(f)$ denotes the minimal prediction on the ground-truth class y in the training set. $w_{y}$ refers to the weight of class y of the re-weighting loss. ", "page_idx": 4}, {"type": "text", "text": "Specifically, from the above generalization bound, we can find two inherent requirements for reweighting methods. 1) Why re-weighting is necessary: $w_{y}$ helps to re-balance the imbalanced term $\\bar{\\sqrt{\\pi_{y}}}\\left[1-\\mathrm{softmax}\\left(B_{y}(m)\\right)\\right]$ to get a sharper bound. 2) Why dynamic re-weighting is necessary: The term $B_{y}(m)$ changes dynamically with model training. Therefore, we need a $w_{y}$ that can adapt dynamically to the changes of $B_{y}(m)$ . 3) Why RDR works: From Fig. 1, we can observe that the dynamic trend of the RDR weight aligns well with $\\sqrt{\\pi_{y}}\\,[1-\\mathrm{softmax}\\,(B_{y}(m))].$ , denoted as $B_{y}^{\\prime}$ . This shows that our RDR can adapt to the dynamics in $B_{y}^{\\prime}$ , maintaining a sharp bound during training. ", "page_idx": 4}, {"type": "text", "text": "3.5 Implementation and Complexity Analysis ", "text_level": 1, "page_idx": 4}, {"type": "text", "text": "At the end of each epoch, a global variable is maintained and updated using momentum, as described by Eq. (6). Within each minibatch, the weight of each sample is computed dynamically. Typical optimization procedures for deep neural networks entail both forward and backward passes per minibatch, characterized by a computational complexity of $\\mathcal{O}(B\\Lambda)$ , where $B$ represents the batch size and $\\Lambda$ denotes the overall parameter size. Within the RDR framework, suppose the feature dimension used as input to the classifier is $K$ , and the sample weights are computed according to Eq. (8). This computation for all $d$ classes aggregates to a complexity of $\\mathcal{O}(\\sum_{i=1}^{d}(n_{i}\\times K^{2}+K^{3}))$ where $n_{i}$ is the sample count of class $i$ in a minibatch. Given that $K$ generally exceeds $n_{i}$ , the complexity predominantly stems from the matrix inversion, approximating to $\\bar{\\cal O}(d K^{3})$ . The complexity for momentum updates is ${\\mathcal{O}}(B K)$ . Notice that $K$ and $B$ are considerably minor relative to the scale of the model parameters, rendering the time overhead of this method manageable. ", "page_idx": 4}, {"type": "text", "text": "", "page_idx": 5}, {"type": "text", "text": "On the storage front, the memory cost of the RDR primarily arises from the matrix inversion step in Eq. (8), resulting in a space complexity of $\\mathcal{O}(K^{\\bar{2}})$ . Given the scales of $K$ is much lower than $\\Lambda$ , the extra memory usage is negligible when compared with the memory utilization of the model parameters. To this end, RDR imposes a relatively small computational or space cost, enabling its integration with existing approaches at a reduced cost. An empirical evaluation of the computational expense is presented in Fig. 2. For more discussions about limitations of RDR , please refer to Appendix E. ", "page_idx": 5}, {"type": "image", "img_path": "vx4NgdyyVG/tmp/01201ea243c16f2a9d2378e2f60ea5575707f2b4329d066096d96cef588c5d33.jpg", "img_caption": [], "img_footnote": [], "page_idx": 5}, {"type": "image", "img_path": "vx4NgdyyVG/tmp/3868701adec6c025a20bd530cc4375bcc2ba6044787208ae45197fab6f3b4670.jpg", "img_caption": ["Figure 2: Visualization of the time cost for training 200 epochs using four methods: CE, RDR, SAM and RDR(SAM) on CIFAR-10-LT and CIFAR-100-LT datasets. ", "Figure 3: The impact of momentum coefficient $m$ in RDR under the measure of top-1 accuracy. "], "img_footnote": [], "page_idx": 5}, {"type": "text", "text": "4 Expriments ", "text_level": 1, "page_idx": 5}, {"type": "text", "text": "4.1 Experimental Setup ", "text_level": 1, "page_idx": 5}, {"type": "text", "text": "Datasets. We conduct experiments on four major long-tailed datasets, CIFAR-10-LT, CIFAR-100-LT, ImageNet-LT [Liu et al., 2019] and Places-LT [Liu et al., 2019]. CIFAR-10-LT and CIFAR-100-LT are two datasets sampled from the original CIFAR [Krizhevsky et al., 2009] dataset with a total of 10 and 100 classes, respectively. We conduct experiments with different imbalance factors $\\begin{array}{r}{I F=\\frac{n_{m a x}}{n_{m,i n}}}\\end{array}$ , where $n_{m a x}$ and $n_{m i n}$ denotes the number of the most and least frequent classes [Kang et al., 2020, Hong et al., 2023, 2024b]. Following the mainstream protocol [Wang et al., 2023], we set the imbalance factor as 100 and 10 for evaluation. ImageNet-LT has $115.8\\mathrm{K}$ training images covering 1000 classes, with imbalance factor being 256. The number of samples per class ranges from 1280 to 5 images. Places-LT contains $62.5\\mathrm{K}$ training images covering 365 categories, with imbalance factor being 996. The number of samples per class ranges from 4980 to 5 images. ", "page_idx": 5}, {"type": "text", "text": "Evaluation Protocol. In the task of long-tailed classification, all classes are treated equally during testing. Following [Rangwani et al., 2022, Zhou et al., 2023c], we also report accuracy on three splits of classes according to the number of training data. Since the number of samples per class increases by its class index, for CIFAR-10-LT dataset, class[0, 3), class[3, 7) and class[7, 10) are reported as Many, Medium and Few classes, respectively. Similarly, CIFAR-100-LT is splited as class[0, 35), class[35, 69) and class[69, 100). ImageNet-LT is splited as class[0, 390), class[390, 835) and class[835, 1000), while Places-LT is splited as class[0, 131), class[131, 288) and class[288, 365). ", "page_idx": 5}, {"type": "text", "text": "Baselines. Our method is combined with existing long-tailed classification methods to demonstrate the efficacy, including the baseline trained by cross-entropy loss (CE), focal loss (Focal) [Lin et al., 2017], class-balanced loss (CB) [Cui et al., 2019] and logit adjustment (LA) [Menon et al., 2020]. Recently, Sharpness-Aware minimization (SAM) [Foret et al., 2021] has been proved to be a powerful method in imbalanced learning, therefore we also adopt baseline including SAM [Foret et al., 2021], ", "page_idx": 5}, {"type": "table", "img_path": "vx4NgdyyVG/tmp/d407a6e528ead701d588bf1322c21641d77870fdf3e6497a5aad31b18d98fccc.jpg", "table_caption": ["Table 1: Top-1 accuracy $(\\%)$ (\u2191) results for overall classes on CIFAR-10-LT, CIFAR-100-LT, ImageNet-LT and Places-LT, CIFAR-10-LT and CIFAR-100-LT are employed with imbalance factors of 10 and 100, respectively. "], "table_footnote": ["ImbSAM [Zhou et al., 2023a] and CCSAM [Zhou et al., 2023c], the latter two are also SAM-based methods. The strategies above have been demonstrated superior performance in imbalanced learning. "], "page_idx": 6}, {"type": "text", "text": "Implementation details. Our code is implemented with Pytorch 1.12.1. Experiments based on CIFAR-10-LT and CIFAR-100-LT are carried out on NVIDIA GeForce RTX 3090 GPUs, while experiments based on ImageNet-LT and Places-LT are carried out on NVIDIA A100 GPUs. For a fair comparison, we use ResNet32 on CIFAR-10-LT and CIFAR-100-LT, ResNet50 on ImageNet-LT and pre-trained ResNet-152 on Places-LT. We train each model with batch size of 128 (for CIFAR-10-LT and CIFAR-100-LT) / 256 (for Places-LT and ImageNet-LT), SGD optimizer with momentum of 0.9, weight decay of 0.0002. The initial learning rate is set to 0.1, with cosine learning-rate scheduling along training. The results of ImbSAM and CCSAM are obtained by implementing the official codes. ", "page_idx": 6}, {"type": "text", "text": "4.2 Comparison Results ", "text_level": 1, "page_idx": 6}, {"type": "text", "text": "Comparative analyses have been performed to evaluate the effectiveness of the proposed RDR. The results are presented in Table 1, Table 2 and Table 4. The metric employed to measure performance is the top-1 accuracy on the test sets. ", "page_idx": 6}, {"type": "text", "text": "Results on CIFAR-10-LT and CIFAR-100-LT. We first evaluate RDR on CIFAR-10-LT and CIFAR100-LT. We report the final accuracy of different methods with imbalance factor ratio $\\{10,100\\}$ in Table 1 and Table 2. We can observe that RDR significantly outperforms all baselines under different imbalance factor ratios across the two datasets. Our observations highlight that RDR consistently outperforms baselines across various class distributions\u2014Many, Medium, and Few\u2014particularly under severe imbalance $(I F{=}100)$ ). ", "page_idx": 6}, {"type": "text", "text": "In CIFAR-10-LT, combined with CE and LA, our method shows substantial improvement in the categories with fewer samples, increasing the accuracy by $19.8\\%$ and $9.5\\%$ respectively in the Few category under $I F{=}100$ . This improvement is notable as it effectively addresses the challenge of learning from scarce data. With the inclusion of SAM, the performance of RDR is further enhanced. Under a less severe imbalance $(I F{=}10)$ ), where the results show less performance drop-off between categories, RDR combined methods still maintain high performance across all categories, suggesting scalability and reliability of our approach in different imbalance contexts. ", "page_idx": 6}, {"type": "text", "text": "In CIFAR-100-LT, where the data distributions are more diverse and challenging, RDR also enhances the overall performance, particularly for the Medium and Few categories. Under the imbalance factor of 10 and 100, RDR increases the accuracy in Few classes by $11.8\\%$ and $20.0\\%$ respectively, compared to the original CE loss. Furthermore, it is notable that techniques like ImbSAM and CCSAM, which especially focus on the Few categories, may heavily sacrifice the performance on Many classes. The results in both datasets show that RDR generally outperforms in the Many classes compared to the other two variants of SAM, indicating that RDR can efficiently address the overftiting issues for Few classes. For more experimental details, please refer to Appendix D.2 and Appendix D.1. ", "page_idx": 6}, {"type": "text", "text": "Flat minima of loss landscape. Key metrics associated with Eigen Spectral Density, such as the maximum and minimum eigenvalues $\\lambda_{m a x}$ and $\\lambda_{m i n.}$ ) and the trace of the Hessian matrix $(T r(H))$ , effectively reflect the smoothness of the loss landscape. Lower values of $\\lambda_{m a x}$ and $T r(H)$ indicate a smoother loss landscape. Rangwani et al. [2022] have demonstrated that smoother loss landscapes correlate with stronger model generalization, which is particularly crucial when dealing with imbalanced data. $\\lambda_{m i n}$ also serves as a significant indicator of the loss landscape characteristics. A preponderance of negative eigenvalues from the Hessian spectrum, resulting in smaller $\\lambda_{m i n}$ values, empirically suggests convergence to saddle points. Saddle points typically represent regions in the loss landscape characterized by a plateau with some negative curvature. In non-convex settings, it has been shown that an exponential number of saddle points exist, and convergence to these points is indicative of poor generalization. ", "page_idx": 6}, {"type": "table", "img_path": "vx4NgdyyVG/tmp/17e107ec3935aecaf8655d3875fbd42e5ae886caab4aef7425d93769ce583850.jpg", "table_caption": ["Table 2: Top-1 accuracy $(\\%)$ (\u2191) results for Many, Medium, Few and overall classes on CIFAR-10- LT, categorized by imbalance factors $(I F)$ of 100 and 10. The experiments are employed with the integration of Sharpness-Aware-Minimization-based methods. "], "table_footnote": [], "page_idx": 7}, {"type": "image", "img_path": "", "img_caption": ["Figure 4: Eigen spectral density for the class with the fewest samples across different methods. Experiments conduct on the CIFAR-10-LT, under an imbalance factor of 100. Maximum eigenvalue $\\lambda_{m a x}$ (\u2193) minimum eigenvalue $\\lambda_{m i n}$ $(\\uparrow)$ in the top right corner of each panel. A lower $\\lambda_{m a x}$ indicates a smoother loss landscape, while a higher $\\lambda_{m i n}$ suggests conditions more favorable for escaping from saddle points, thereby enhancing the model\u2019s generalization capabilities. "], "img_footnote": [], "page_idx": 7}, {"type": "text", "text": "", "page_idx": 7}, {"type": "text", "text": "Fig. 4 illustrates the Eigen Spectral Density under different loss function training regimes. It is evident that combining our method with the CE technique significantly improves the loss landscape. On one hand, $\\lambda_{m a x}$ is substantially reduced, indicating a flatter loss landscape. On the other hand, there is an increase in $\\lambda_{m i n}$ , suggesting our method\u2019s effectiveness in escaping from saddle points. ", "page_idx": 7}, {"type": "text", "text": "Table 3 delves deeper into the changes in the loss landscape for all Few classes. It reveals that combining our method with CE and SAM results in average reductions in $\\lambda_{m a x}$ by $58.5\\%$ and $66.1\\%$ , respectively, and increases in $\\lambda_{m i n}$ by $49.2\\%$ and $7.6\\%$ , respectively. Furthermore, our method significantly reduces $T r(H)$ for minority classes (class7, class8 and class9). The average value of $T r(H)$ decreases by $55.7\\%$ and $66.0\\%$ when combined with CE and SAM, respectively. These findings underscore the efficacy of our method in improving the loss landscape and enhancing the generalization capability of the model [Dauphin et al., 2014]. ", "page_idx": 7}, {"type": "text", "text": "Results on ImageNet-LT and Places-LT. Our experiments conducted on ImageNet-LT and PlacesLT, two large-scale datasets characterized by irregular and complex data distributions, demonstrate notable accuracy improvements through the application of RDR, as shown in Table 1 and Table 4. ", "page_idx": 7}, {"type": "text", "text": "Table 3: Loss landscape metrics across different methods on CIFAR-10-LT, with imbalance factor 100. Average minimum eigenvalues $\\overline{{\\lambda_{\\operatorname*{min}}}}$ (\u2191), average maximum eigenvalues $\\overline{{\\lambda_{\\mathrm{{max}}}}}$ (\u2193), and the trace $T r\\left(\\downarrow\\right)$ of the Hessian matrix for classes with few samples. $T r_{6},T r_{7},T r_{8},$ , and $T r_{9}$ represent the traces of the Hessian matrix for class 6, 7, 8 and 9, respectively, with descending sample quantities. $\\overline{{T r}}_{F e w}$ denotes average trace of Hessian matrix over Few classes. Lower $\\lambda_{\\mathrm{max}}$ and $T r$ values indicate a flatter loss landscape, while a higher $\\lambda_{\\operatorname*{min}}$ suggests a landscape more conducive to escaping from saddle points, thereby potentially enhancing model generalization. ", "page_idx": 8}, {"type": "table", "img_path": "vx4NgdyyVG/tmp/630e09c1a0760038060821e13d3be648e1697d81ec1643039b9d07701e94ca6d.jpg", "table_caption": [], "table_footnote": [], "page_idx": 8}, {"type": "text", "text": "Specifically, when combined with CE and LA on ImageNet-LT, our method achieves accuracy enhancements of $18.7\\%$ and $2\\%$ in Few classes, respectively. While the SAM technique combined with CE and LA offers limited accuracy improvements, its integration with our approach still results in an overall accuracy increase of approximately $2.3\\%$ compared to other methods. Notably, the LA method tends to suppress accuracy in Many classes more than the CE method; however, this side effect is effectively mitigated when LA is combined with RDR. ", "page_idx": 8}, {"type": "table", "img_path": "vx4NgdyyVG/tmp/82e52a85495b66ec20602d1b66d2867785f332f6b32fef7ffa9af0af0a507931.jpg", "table_caption": ["Table 4: Top-1 accuracy $(\\%)$ (\u2191) results for Many, Medium, Few and overall classes on ImageNet-LT and Places-LT. The experiments are employed with the integration of Sharpness-Aware-Minimizationbased methods. "], "table_footnote": [], "page_idx": 8}, {"type": "text", "text": "In the Places-LT dataset, the performance of RDR is even more pronounced. Combinations of our method with CE and LA result in accuracy gains of $10.1\\%$ and $2\\%$ in overall classes, respectively. Additionally, integrating SAM with our method also yields incremental improvements of $10.3\\%$ and $0.5\\%$ under CE and LA conditions, respectively. Our approach not only enhances accuracy in Few classes but also surpasses other methods in Medium classes, indicating its comprehensive efficacy across different categories. This broad applicability is particularly crucial for addressing the challenges of imbalanced learning. ", "page_idx": 8}, {"type": "text", "text": "Results on data with label noise. We further investigate the performance of our approach on datasets with label noise. Specifically, we evaluate two datasets: CIFAR-10-LT-NL and CIFAR-100-LT-NL, both of which exhibit class imbalance and label noise. Experiments are conducted with a noise ratio of $5\\%$ , and the results are presented in Fig. 5. As shown, our method demonstrates consistent and significant improvements on more datasets with label noise. ", "page_idx": 8}, {"type": "text", "text": "4.3 Ablation Study ", "text_level": 1, "page_idx": 8}, {"type": "text", "text": "In our study, we perform an ablation experiment to validate the efficacy of the multiple components that comprise our method. The outcomes from experiments across four datasets are delineated in Table 5. It is crucial to note that our weighting definition for each category $i$ follows the formula $w\\,=\\,r/n_{i}$ . When $r\\,=\\,1$ , our method simplifies to the traditional inverse frequency weighting $w=1/n_{i}$ . We explored the differences between our approach with and without the integration of SAM compared to this conventional weighting method. ", "page_idx": 8}, {"type": "image", "img_path": "vx4NgdyyVG/tmp/4807dd444a6c406ffdec779269a0a4fc336fe09a61f1ae173d64bdf5084fd016.jpg", "img_caption": ["Figure 5: Top-1 accuracy $(\\%)$ $(\\uparrow)$ results for overall classes on CIFAR-10-LT-NL and CIFAR-100-LTNL with $5\\%$ noise ratio, categorized by imbalance factors $(I F)$ of 100 and 10. "], "img_footnote": [], "page_idx": 9}, {"type": "table", "img_path": "vx4NgdyyVG/tmp/1734f1578bcc1dd205830de97ec99ef2a1b3ea5ee505a79530ff5b7a6cc3d85d.jpg", "table_caption": ["Table 5: Top-1 accuracy $(\\%)$ (\u2191) results from ablation studies across diverse datasets. Experiments conduct on CIFAR-10-LT, CIFAR-100-LT, ImageNet-LT, and Places-LT, comparing different method combinations. $1/n$ denote classic inverse frequency weighting method, assigning weights of $1/n_{i}$ for class $i$ . "], "table_footnote": [], "page_idx": 9}, {"type": "text", "text": "The results depicted in Table 5 reveal that our dynamic weighting approach consistently outperforms the classic method under various scenarios. Without SAM, when combined with CE and LA, our method achieves accuracy improvements ranging from $0.4\\%$ to $4.3\\%$ and $0.3\\%$ to $2.3\\%$ , respectively. When integrated with SAM, the improvement in accuracy is particularly notable on large datasets. Specifically, the accuracy enhancements on ImageNet-LT and Places-LT reach $7.1\\%$ and $1.9\\%$ respectively when combined with LA. These results underscore the tangible beneftis of our dynamic weighting strategy in enhancing model performance. The impact of momentum coefficient $m$ in RDR is shown in Fig. 3. For more experimental details, please refer to Appendix D.3. ", "page_idx": 9}, {"type": "text", "text": "5 Conclusion ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "In this work, we have introduced RDR, a novel approach for mitigating model degradation in imbalanced learning scenarios by dynamically adjusting class weights using density ratio estimation. Our method dynamically adjusts class weights during training based on density ratio estimation, enhancing both model robustness and adaptability. Extensive experiments on diverse large-scale datasets demonstrate the effectiveness of RDR, particularly in severely imbalanced settings. Future work will focus on refining the dynamic adjustment mechanisms and exploring broader applicability across various domains and dataset complexities. ", "page_idx": 9}, {"type": "text", "text": "Acknowledgement ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "Jiaan Luo, Feng Hong, Jiangchao Yao, Ya Zhang and Yanfeng Wang are supported by the National Key R&D Program of China (No. 2022ZD0160702), STCSM (No. 22511106101, No. 22DZ2229005), 111 plan (No. BP0719010) and National Natural Science Foundation of China (No. 62306178). Bo Han is supported by NSFC General Program No. 62376235, Guangdong Basic and Applied Basic Research Foundation No. 2022A1515011652 and No. 2024A1515012399, HKBU Faculty Niche Research Areas No. RC-FNRA-IG/22-23/SCI/04 and HKBU CSD Departmental Incentive Scheme. ", "page_idx": 9}, {"type": "text", "text": "References ", "text_level": 1, "page_idx": 10}, {"type": "text", "text": "Kevin W. Bowyer, Nitesh V. Chawla, Lawrence O. Hall, and W. Philip Kegelmeyer. SMOTE: synthetic minority over-sampling technique. CoRR, abs/1106.1813, 2011. URL http://arxiv. org/abs/1106.1813.   \nMateusz Buda, Atsuto Maki, and Maciej A. Mazurowski. A systematic study of the class imbalance problem in convolutional neural networks. Neural Networks, 106:249\u2013259, 2018. doi: 10.1016/J. NEUNET.2018.07.011. URL https://doi.org/10.1016/j.neunet.2018.07.011.   \nJiarui Cai, Yizhou Wang, and Jenq-Neng Hwang. Ace: Ally complementary experts for solving long-tailed recognition in one-shot. In Proceedings of the IEEE/CVF international conference on computer vision, pages 112\u2013121, 2021.   \nKaidi Cao, Colin Wei, Adrien Gaidon, Nikos Arechiga, and Tengyu Ma. Learning imbalanced datasets with label-distribution-aware margin loss. Advances in neural information processing systems, 32, 2019.   \nMengxi Chen, Jiangchao Yao, Linyu Xing, Yu Wang, Ya Zhang, and Yanfeng Wang. Redundancy adaptive multimodal learning for imperfect data. arXiv preprint arXiv:2310.14496, 2023a.   \nXiaohua Chen, Yucan Zhou, Dayan Wu, Chule Yang, Bo Li, Qinghua Hu, and Weiping Wang. Area: adaptive reweighting via effective area for long-tailed classification. In Proceedings of the IEEE/CVF International Conference on Computer Vision, pages 19277\u201319287, 2023b.   \nYin Cui, Menglin Jia, Tsung-Yi Lin, Yang Song, and Serge Belongie. Class-balanced loss based on effective number of samples. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition, pages 9268\u20139277, 2019.   \nYann N Dauphin, Razvan Pascanu, Caglar Gulcehre, Kyunghyun Cho, Surya Ganguli, and Yoshua Bengio. Identifying and attacking the saddle point problem in high-dimensional non-convex optimization. Advances in neural information processing systems, 27, 2014.   \nPierre Foret, Ariel Kleiner, Hossein Mobahi, and Behnam Neyshabur. Sharpness-aware minimization for efficiently improving generalization. In 9th International Conference on Learning Representations, ICLR 2021, Virtual Event, Austria, May 3-7, 2021. OpenReview.net, 2021. URL https://openreview.net/forum?id $\\equiv$ 6Tm1mposlrM.   \nYu Gong, Greg Mori, and Frederick Tung. Ranksim: Ranking similarity regularization for deep imbalanced regression. In Kamalika Chaudhuri, Stefanie Jegelka, Le Song, Csaba Szepesv\u00e1ri, Gang Niu, and Sivan Sabato, editors, International Conference on Machine Learning, ICML 2022, 17-23 July 2022, Baltimore, Maryland, USA, volume 162 of Proceedings of Machine Learning Research, pages 7634\u20137649. PMLR, 2022. URL https://proceedings.mlr.press/v162/ gong22a.html.   \nHui Han, Wenyuan Wang, and Binghuan Mao. Borderline-smote: A new over-sampling method in imbalanced data sets learning. In ICIC, volume 3644 of Lecture Notes in Computer Science, pages 878\u2013887. Springer, 2005.   \nFeng Hong, Jiangchao Yao, Zhihan Zhou, Ya Zhang, and Yanfeng Wang. Long-tailed partial label learning via dynamic rebalancing. In International Conference on Learning Representations. OpenReview.net, 2023.   \nFeng Hong, Yueming Lyu, Jiangchao Yao, Ya Zhang, Ivor W. Tsang, and Yanfeng Wang. Diversified batch selection for training acceleration. In International Conference on Machine Learning. OpenReview.net, 2024a.   \nFeng Hong, Jiangchao Yao, Yueming Lyu, Zhihan Zhou, Ivor W. Tsang, Ya Zhang, and Yanfeng Wang. On harmonizing implicit subpopulations. In International Conference on Learning Representations. OpenReview.net, 2024b.   \nChen Huang, Yining Li, Chen Change Loy, and Xiaoou Tang. Learning deep representation for imbalanced classification. In 2016 IEEE Conference on Computer Vision and Pattern Recognition, CVPR 2016, Las Vegas, NV, USA, June 27-30, 2016, pages 5375\u20135384. IEEE Computer Society, 2016. doi: 10.1109/CVPR.2016.580. URL https://doi.org/10.1109/CVPR.2016.580.   \nBingyi Kang, Saining Xie, Marcus Rohrbach, Zhicheng Yan, Albert Gordo, Jiashi Feng, and Yannis Kalantidis. Decoupling representation and classifier for long-tailed recognition. In 8th International Conference on Learning Representations, ICLR 2020, Addis Ababa, Ethiopia, April 26-30, 2020. OpenReview.net, 2020. URL https://openreview.net/forum?id $=$ r1gRTCVFvB.   \nMahsa Keramati, Lili Meng, and R. David Evans. Conr: Contrastive regularizer for deep imbalanced regression. In The Twelfth International Conference on Learning Representations, ICLR 2024, Vienna, Austria, May 7-11, 2024. OpenReview.net, 2024. URL https://openreview.net/ forum?id $\\equiv$ RIuevDSK5V.   \nGanesh Ramachandra Kini, Orestis Paraskevas, Samet Oymak, and Christos Thrampoulidis. Labelimbalanced and group-sensitive classification under overparameterization. In Marc\u2019Aurelio Ranzato, Alina Beygelzimer, Yann N. Dauphin, Percy Liang, and Jennifer Wortman Vaughan, editors, Advances in Neural Information Processing Systems 34: Annual Conference on Neural Information Processing Systems 2021, NeurIPS 2021, December 6-14, 2021, virtual, pages 18970\u201318983, 2021. URL https://proceedings.neurips.cc/paper/2021/hash/ 9dfcf16f0adbc5e2a55ef02db36bac7f-Abstract.html.   \nAlex Krizhevsky, Geoffrey Hinton, et al. Learning multiple layers of features from tiny images. Handbook of Systemic Autoimmune Diseases, 2009.   \nMiroslav Kubat and Stan Matwin. Addressing the curse of imbalanced training sets: One-sided selection. In ICML, pages 179\u2013186. Morgan Kaufmann, 1997.   \nTianhong Li, Peng Cao, Yuan Yuan, Lijie Fan, Yuzhe Yang, Rogerio S Feris, Piotr Indyk, and Dina Katabi. Targeted supervised contrastive learning for long-tailed recognition. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 6918\u20136928, 2022.   \nTsung-Yi Lin, Priya Goyal, Ross Girshick, Kaiming He, and Piotr Doll\u00e1r. Focal loss for dense object detection. In Proceedings of the IEEE international conference on computer vision, pages 2980\u20132988, 2017.   \nHong Liu, Jeff Z. HaoChen, Adrien Gaidon, and Tengyu Ma. Self-supervised learning is more robust to dataset imbalance. In The Tenth International Conference on Learning Representations, ICLR 2022, Virtual Event, April 25-29, 2022. OpenReview.net, 2022. URL https://openreview. net/forum?id=4AZz9osqrar.   \nZiwei Liu, Zhongqi Miao, Xiaohang Zhan, Jiayun Wang, Boqing Gong, and Stella X Yu. Large-scale long-tailed recognition in an open world. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition, pages 2537\u20132546, 2019.   \nYanbiao Ma, Licheng Jiao, Fang Liu, Yuxin Li, Shuyuan Yang, and Xu Liu. Delving into semantic scale imbalance. In The Eleventh International Conference on Learning Representations, ICLR 2023, Kigali, Rwanda, May 1-5, 2023. OpenReview.net, 2023. URL https://openreview.net/ pdf?id=07tc5kKRIo.   \nAditya Krishna Menon, Sadeep Jayasumana, Ankit Singh Rawat, Himanshu Jain, Andreas Veit, and Sanjiv Kumar. Long-tail learning via logit adjustment. In 9th International Conference on Learning Representations, ICLR 2021, Virtual Event, Austria, May 3-7, 2021, 2020.   \nKatharina Morik, Peter Brockhausen, and Thorsten Joachims. Combining statistical learning with a knowledge-based approach - A case study in intensive care monitoring. In Ivan Bratko and Saso Dzeroski, editors, Proceedings of the Sixteenth International Conference on Machine Learning (ICML 1999), Bled, Slovenia, June 27 - 30, 1999, pages 268\u2013277. Morgan Kaufmann, 1999.   \nHarsh Rangwani, Sumukh K. Aithal, Mayank Mishra, and Venkatesh Babu R. Escaping saddle points for effective generalization on class-imbalanced data. In Sanmi Koyejo, S. Mohamed, A. Agarwal, Danielle Belgrave, K. Cho, and A. Oh, editors, Advances in Neural Information Processing Systems 35: Annual Conference on Neural Information Processing Systems 2022, NeurIPS 2022, New Orleans, LA, USA, November 28 - December 9, 2022, 2022. URL http://papers.nips.cc/paper_files/paper/2022/hash/ 8f4d70db9ecec97b6723a86f1cd9cb4b-Abstract-Conference.html. ", "page_idx": 10}, {"type": "text", "text": "", "page_idx": 11}, {"type": "text", "text": "Jiawei Ren, Cunjun Yu, Shunan Sheng, Xiao Ma, Haiyu Zhao, Shuai Yi, and Hongsheng Li. Balanced meta-softmax for long-tailed visual recognition. In Hugo Larochelle, Marc\u2019Aurelio Ranzato, Raia Hadsell, Maria-Florina Balcan, and Hsuan-Tien Lin, editors, Advances in Neural Information Processing Systems 33: Annual Conference on Neural Information Processing Systems 2020, NeurIPS 2020, December 6-12, 2020, virtual, 2020a. URL https://proceedings.neurips. cc/paper/2020/hash/2ba61cc3a8f44143e1f2f13b2b729ab3-Abstract.html. ", "page_idx": 12}, {"type": "text", "text": "Jiawei Ren, Cunjun Yu, Shunan Sheng, Xiao Ma, Haiyu Zhao, Shuai Yi, and Hongsheng Li. Balanced meta-softmax for long-tailed visual recognition. In Hugo Larochelle, Marc\u2019Aurelio Ranzato, Raia Hadsell, Maria-Florina Balcan, and Hsuan-Tien Lin, editors, Advances in Neural Information Processing Systems 33: Annual Conference on Neural Information Processing Systems 2020, NeurIPS 2020, December 6-12, 2020, virtual, 2020b. URL https://proceedings.neurips. cc/paper/2020/hash/2ba61cc3a8f44143e1f2f13b2b729ab3-Abstract.html. ", "page_idx": 12}, {"type": "text", "text": "Jiawei Ren, Mingyuan Zhang, Cunjun Yu, and Ziwei Liu. Balanced MSE for imbalanced visual regression. In IEEE/CVF Conference on Computer Vision and Pattern Recognition, CVPR 2022, New Orleans, LA, USA, June 18-24, 2022, pages 7916\u20137925. IEEE, 2022. doi: 10.1109/CVPR52688. 2022.00777. URL https://doi.org/10.1109/CVPR52688.2022.00777. ", "page_idx": 12}, {"type": "text", "text": "Olga Russakovsky, Jia Deng, Hao Su, Jonathan Krause, Sanjeev Satheesh, Sean Ma, Zhiheng Huang, Andrej Karpathy, Aditya Khosla, Michael S. Bernstein, Alexander C. Berg, and Li Fei-Fei. Imagenet large scale visual recognition challenge. Int. J. Comput. Vis., 115(3):211\u2013252, 2015. doi: 10.1007/S11263-015-0816-Y. URL https://doi.org/10.1007/s11263-015-0816-y. ", "page_idx": 12}, {"type": "text", "text": "Yonglong Tian, Olivier J. H\u00e9naff, and A\u00e4ron van den Oord. Divide and contrast: Self-supervised learning from uncurated data. In 2021 IEEE/CVF International Conference on Computer Vision, ICCV 2021, Montreal, QC, Canada, October 10-17, 2021, pages 10043\u201310054. IEEE, 2021. ", "page_idx": 12}, {"type": "text", "text": "Byron C. Wallace, Kevin Small, Carla E. Brodley, and Thomas A. Trikalinos. Class imbalance, redux. In ICDM, pages 754\u2013763. IEEE Computer Society, 2011. ", "page_idx": 12}, {"type": "text", "text": "Jiaqi Wang, Wenwei Zhang, Yuhang Zang, Yuhang Cao, Jiangmiao Pang, Tao Gong, Kai Chen, Ziwei Liu, Chen Change Loy, and Dahua Lin. Seesaw loss for long-tailed instance segmentation. In IEEE Conference on Computer Vision and Pattern Recognition, CVPR 2021, virtual, June 19-25, 2021, pages 9695\u20139704. Computer Vision Foundation / IEEE, 2021a. doi: 10.1109/CVPR46437.2021. 00957. URL https://openaccess.thecvf.com/content/CVPR2021/html/Wang_Seesaw_ Loss_for_Long-Tailed_Instance_Segmentation_CVPR_2021_paper.html. ", "page_idx": 12}, {"type": "text", "text": "Xudong Wang, Long Lian, Zhongqi Miao, Ziwei Liu, and Stella X. Yu. Long-tailed recognition by routing diverse distribution-aware experts. In 9th International Conference on Learning Representations, ICLR 2021, Virtual Event, Austria, May 3-7, 2021. OpenReview.net, 2021b. URL https://openreview.net/forum?id $\\equiv$ D9I3drBz4UC. ", "page_idx": 12}, {"type": "text", "text": "Zitai Wang, Qianqian Xu, Zhiyong Yang, Yuan He, Xiaochun Cao, and Qingming Huang. A unified generalization analysis of re-weighting and logit-adjustment for imbalanced learning. In Alice Oh, Tristan Naumann, Amir Globerson, Kate Saenko, Moritz Hardt, and Sergey Levine, editors, Advances in Neural Information Processing Systems 36: Annual Conference on Neural Information Processing Systems 2023, NeurIPS 2023, New Orleans, LA, USA, December 10 - 16, 2023, 2023. URL http://papers.nips.cc/paper_files/paper/2023/hash/ 973a0f50d43cf99118cdab456edcacda-Abstract-Conference.html. ", "page_idx": 12}, {"type": "text", "text": "Ziyan Wang and Hao Wang. Variational imbalanced regression: Fair uncertainty quantification via probabilistic smoothing. In Alice Oh, Tristan Naumann, Amir Globerson, Kate Saenko, Moritz Hardt, and Sergey Levine, editors, Advances in Neural Information Processing Systems 36: Annual Conference on Neural Information Processing Systems 2023, NeurIPS 2023, New Orleans, LA, USA, December 10 - 16, 2023, 2023. URL http://papers.nips.cc/paper_files/paper/ 2023/hash/612a56f193d031687683445cd0001083-Abstract-Conference.html. ", "page_idx": 12}, {"type": "text", "text": "Yuzhe Yang, Kaiwen Zha, Ying-Cong Chen, Hao Wang, and Dina Katabi. Delving into deep imbalanced regression. In Marina Meila and Tong Zhang, editors, Proceedings of the 38th International Conference on Machine Learning, ICML 2021, 18-24 July 2021, Virtual Event, volume 139 of Proceedings of Machine Learning Research, pages 11842\u201311851. PMLR, 2021. URL http://proceedings.mlr.press/v139/yang21m.html. ", "page_idx": 12}, {"type": "text", "text": "Xi Yin, Xiang Yu, Kihyuk Sohn, Xiaoming Liu, and Manmohan Chandraker. Feature transfer learning for face recognition with under-represented data. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition, pages 5704\u20135713, 2019.   \nBianca Zadrozny, John Langford, and Naoki Abe. Cost-sensitive learning by cost-proportionate example weighting. In Proceedings of the 3rd IEEE International Conference on Data Mining (ICDM 2003), 19-22 December 2003, Melbourne, Florida, USA, page 435. IEEE Computer Society, 2003. doi: 10.1109/ICDM.2003.1250950. URL https://doi.org/10.1109/ICDM. 2003.1250950.   \nYixuan Zhou, Yi Qu, Xing Xu, and Hengtao Shen. Imbsam: A closer look at sharpness-aware minimization in class-imbalanced recognition. In Proceedings of the IEEE/CVF International Conference on Computer Vision, pages 11345\u201311355, 2023a.   \nZhihan Zhou, Jiangchao Yao, Feng Hong, Ya Zhang, Bo Han, and Yanfeng Wang. Combating representation learning disparity with geometric harmonization. Advances in Neural Information Processing Systems, 36, 2023b.   \nZhipeng Zhou, Lanqing Li, Peilin Zhao, Pheng-Ann Heng, and Wei Gong. Class-conditional sharpness-aware minimization for deep long-tailed recognition. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 3499\u20133509, 2023c. ", "page_idx": 13}, {"type": "text", "text": "A Notations ", "text_level": 1, "page_idx": 14}, {"type": "text", "text": "In Table 6, we summarize the notations used in this paper. ", "page_idx": 14}, {"type": "text", "text": "Table 6: Description of Notations ", "page_idx": 14}, {"type": "table", "img_path": "vx4NgdyyVG/tmp/29d3de239d2e7dfaced0b4c7a7851034b5e0f31d8c763192643da5c674fd17e5.jpg", "table_caption": [], "table_footnote": [], "page_idx": 14}, {"type": "text", "text": "B More Discussions of Related Work ", "text_level": 1, "page_idx": 14}, {"type": "text", "text": "Beyond imbalanced classification that has discretized label space, an noteworthy area, imbalanced regression that has a continuous label space is also very common in real applications [Yang et al., 2021, Gong et al., 2022]. In this direction, the empirical label distribution often does not accurately reflect the true label density in regression tasks, which limits the effectiveness of traditional re-weighting techniques [Yang et al., 2021, Wang and Wang, 2023]. Label Distribution Smoothing (LDS) [Yang et al., 2021] and Variational Imbalanced Regression (VIR) [Wang and Wang, 2023] propose using kernel smoothing and other techniques to estimate an accurate label density distribution. Ranking Similarity (Ranksim) [Gong et al., 2022] leverages local and global dependencies by encouraging the correspondence between the similarity order of labels and features. Balanced Mean Squared Error (Balanced MSE) [Ren et al., 2022] extends the concept of Balanced Softmax [Ren et al., 2020a] to regression tasks to achieve a balanced predictive distribution. Contrastive Regularizer (ConR) [Keramati et al., 2024] improves contrastive learning techniques to translate label similarities into the feature space. ", "page_idx": 14}, {"type": "text", "text": "C Algorithm Details ", "text_level": 1, "page_idx": 14}, {"type": "text", "text": "C.1 Detailed Derivations of Eq. (7) ", "text_level": 1, "page_idx": 14}, {"type": "text", "text": "Back to Eq. (5), replace the expectations over $P_{b a l}$ and $P$ by $\\Phi_{P}$ and $F_{P_{b a l}}$ , respectively. For each class $i$ , We can obtain $\\widehat{r_{i}}=\\widehat{\\mathrm{MM}}(r)$ , where ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\widehat{\\mathrm{MM}}(r)=\\frac{1}{n_{i}^{2}}{r_{i}}^{\\top}{\\Phi_{P}^{i}}^{\\top}\\Phi_{P}^{i}r_{i}-\\frac{2}{n_{i}}r_{i}^{\\top}{\\Phi_{P}^{i}}^{\\top}F_{i}\n$$", "text_format": "latex", "page_idx": 14}, {"type": "image", "img_path": "vx4NgdyyVG/tmp/7e668012093daabc5b8deba975e10da143053f6c9d589266b7c55f769d5159c9.jpg", "img_caption": ["Figure 6: Framework of RDR "], "img_footnote": [], "page_idx": 15}, {"type": "text", "text": "Then, taking the derivative of $\\widehat{\\mathrm{MM}}(r)$ with respect to $r$ and setting it to zero, we can obtain the estimation of density ratio in imbalanced learning as follows ", "page_idx": 15}, {"type": "equation", "text": "$$\n{\\frac{2}{n_{i}^{2}}}{\\Phi_{P}^{i}}^{\\top}\\Phi_{P}^{i}r_{i}-{\\frac{2}{n_{i}}}{\\Phi_{P}^{i}}^{\\top}F_{i}=0\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "Solving equation above with respect to $r_{i}$ , we can obtain the solution as ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\widehat{r_{i}}=n_{i}\\left({\\pmb{\\Phi}}_{P}^{i}\\,^{\\top}{\\pmb{\\Phi}}_{P}^{i}\\right)^{-1}{\\pmb{\\Phi}}_{P}^{i}^{\\,\\top}F_{i}\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "C.2 Framework of RDR ", "text_level": 1, "page_idx": 15}, {"type": "text", "text": "We provide the framework of RDR, which is shown in Fig. 6. ", "page_idx": 15}, {"type": "text", "text": "C.3 Pseudo-code of RDR ", "text_level": 1, "page_idx": 15}, {"type": "text", "text": "We provide the pseudo-code of RDR to demonstrate the process of implementing our method in detail, as shown in Algorithm 1. In addition, we also provide pseudo-code that combines our method with the SAM method, as shown in Algorithm 2. ", "page_idx": 15}, {"type": "text", "text": "D Supplement for Experiments ", "text_level": 1, "page_idx": 15}, {"type": "text", "text": "D.1 Experiment with More Imbalanced Data ", "text_level": 1, "page_idx": 15}, {"type": "text", "text": "We conduct experiments on the more imbalanced CIFAR-10-LT and CIFAR-100-LT datasets, specifically with imbalance factors of 200 and 500. As shown in Table 7, our method consistently achieves significant improvements. ", "page_idx": 15}, {"type": "text", "text": "D.2 Dynamically Re-weighting Process ", "text_level": 1, "page_idx": 15}, {"type": "text", "text": "Our approach dynamically adjusts the weights assigned to each category throughout the training process. To gain more insights into RDR, we sampled the weights of each category during training. Fig. 7 presents the results of four samplings during the training processes at imbalance factors of 10 and 100, respectively. ", "page_idx": 15}, {"type": "text", "text": "The analysis of these results reveals a consistent trend in weight changes across different imbalance factors. For the Many classes, the weights of the categories consistently decrease during training. Specifically, under the $I F$ of 10, the weights of class0, class1, and class2 (the three classes with the highest sample counts, in descending order) decrease by $5.6\\%$ , $6.7\\%$ , and $8.0\\%$ , respectively. Under the $I F$ of 100, these decreases are more pronounced, with reductions of $10.3\\%$ , $15.4\\%$ , and $14.7\\%$ , respectively. For the Medium classes, the weight changes are less marked, with an average decrease ", "page_idx": 15}, {"type": "text", "text": "1: Input: Training dataset ${\\cal S}=\\cup_{i=1}^{n}\\{(x_{i},y_{i})\\}$ , model $\\mathcal{M}_{\\omega}$ with feature extractor $f_{\\phi}$ and classifier   \n$h_{\\theta}$ , loss function $l$ , momentem coefficient $m$ , learning rate $\\alpha$ , weight decay coefficient $\\lambda$ , batch   \nsize $b$ , temperature coefficient $\\gamma$   \n2: Output: Trained parameters $\\phi^{*}$ , $\\theta^{*}$   \n3: Initialize the model parameters $\\phi$ and $\\theta$ ramdomly, $F_{P_{b a l}}=(F_{1},\\ldots,F_{d})\\leftarrow0$   \n4: for $t=1$ to $T$ do   \n5: $B\\leftarrow\\S$ ampleMiniBatch $(S,b)$   \n6: $z\\gets f(x,\\phi_{t})$   \n7: $o u t p u t\\leftarrow h(z,\\theta_{t})$   \n8: if $t<T_{0}$ then   \n9: // warm up   \n10: w \u21901   \n11: else   \n12: for class $i$ to $d$ do   \n13: $\\Phi_{P}^{i}\\leftarrow(z_{j})$ where $y_{j}=i$   \n14: compute $w_{i}$ via Eq. (8) and $\\gamma$   \n15: end for   \n16: $w\\gets\\mathsf{n o r m a l i z e}(w^{\\gamma})$   \n17: end if   \n18: $\\begin{array}{r}{\\mathcal{L}(\\omega_{t},B)\\gets\\frac{1}{h}\\sum_{B}w\\cdot l(o u t p u t,y)}\\end{array}$   \n19: $\\omega_{t}=\\omega_{t}-\\alpha_{t}\\left[\\nabla\\mathcal{L}(\\omega_{t},B)+\\lambda\\omega_{t}\\right]$   \n20: $F_{P_{b a l}}\\gets m F_{P_{b a l}}+(1-m)\\overline{{z}}$   \n21: Optional: anneal the learning rate $\\alpha_{t}$   \n22: end for ", "page_idx": 16}, {"type": "text", "text": "Algorithm 2 Training Paradigm of RDR combined with SAM. ", "text_level": 1, "page_idx": 16}, {"type": "text", "text": "1: Input: Training dataset ${\\cal S}=\\cup_{i=1}^{n}\\{(x_{i},y_{i})\\}$ , model $\\mathcal{M}_{\\omega}$ with feature extractor $f_{\\phi}$ and classifier   \n$h_{\\theta}$ , loss function $l$ , momentem coefficient $m$ , learning rate $\\alpha$ , weight decay coefficient $\\lambda$ , batch   \nsize $b$ , neighborhood size $\\rho$ , temperature coefficient $\\gamma$   \n2: Output: Trained parameters $\\phi^{*}$ , $\\theta^{*}$   \n3: Initialize the model parameters $\\phi$ and $\\theta$ ramdomly, $F_{P_{b a l}}=(F_{1},\\ldots,F_{d})\\leftarrow0$   \n4: for $t=1$ to $T$ do   \n5: $B\\leftarrow S$ ampleMiniBatch $(S,b)$   \n6: $z\\gets f(x,\\phi_{t})$   \n7: $o u t p u t\\leftarrow h(z,\\theta_{t})$   \n8: if $t<T_{0}$ then   \n9: // warm up   \n10: $w\\gets1$   \n11: else   \n12: for class $i$ to $d$ do   \n13: $\\Phi_{P}^{i}\\leftarrow(z_{j})$ where $y_{j}=i$   \n14: compute $w_{i}$ via Equation 8 and $\\gamma$   \n15: end for   \n16: 17: $\\begin{array}{r l}&{\\quad w\\leftarrow\\mathrm{normallze}(w\\:^{\\prime})}\\\\ &{\\;\\;\\mathbf{end\\:if}}\\\\ &{\\;\\;\\mathcal{L}_{1}(\\omega_{t},B)\\leftarrow\\frac{1}{b}\\sum_{B}w\\cdot l(o u t p u t,y)}\\\\ &{\\epsilon_{t}\\leftarrow\\rho\\frac{\\nabla\\mathcal{L}_{1}(\\omega_{t},B)}{|\\nabla\\mathcal{L}_{1}(\\omega_{t},B)|}}\\\\ &{\\;\\mathcal{L}_{2}(\\omega_{t}+\\epsilon_{t},B)\\leftarrow\\frac{1}{b}\\sum_{B}w\\cdot l\\big(f_{\\omega_{t}+\\epsilon_{t}}(\\cdot),y\\big)}\\\\ &{\\omega_{t}=\\omega_{t}-\\alpha_{t}\\left[\\nabla\\mathcal{L}_{2}(\\omega_{t}+\\epsilon_{t},B)+\\lambda\\omega_{t}\\right]}\\\\ &{F_{b a l}\\leftarrow m F_{P b a l}+(1-m)\\overline{{z}}}\\\\ &{\\;\\Delta\\mathbf{n}\\mathtt{i n d}\\backslash\\mathbf{in}.}\\end{array}$   \n18:   \n19:   \n20:   \n21:   \n22:   \n23: Optional: anneal the learning rate $\\alpha_{t}$   \n24: end for ", "page_idx": 16}, {"type": "table", "img_path": "vx4NgdyyVG/tmp/6667cbd257014378c78e9f210139f4860f5800811db696ea2864803227b1e7b0.jpg", "table_caption": ["Table 7: Top-1 accuracy $(\\%)$ (\u2191) results under more imbalanced conditions. "], "table_footnote": [], "page_idx": 17}, {"type": "text", "text": "of $3.7\\%$ at $I F{=}10$ and $0.3\\%$ at $I F{=}100$ . For the Few classes, there exits a notable increase in weights during training; at $I F{=}10$ , the weights of class7, class8, and class9 increase by $2.3\\%$ , $6.3\\%$ , and $9.4\\%$ , respectively, while at $I F{=}100$ , they increase by $6.2\\%$ , $6.5\\%$ , and $3.2\\%$ . ", "page_idx": 17}, {"type": "text", "text": "These results suggest that our method increasingly focuses on minority classes as training progresses. Initially, our method effectively learns common features across all categories, while later in training, increasing the weights helps to target learning towards minority samples, thereby enhancing the model\u2019s generalizability. Wang et al. [2023] also corroborate these findings. ", "page_idx": 17}, {"type": "text", "text": "D.3 Ablation Study ", "text_level": 1, "page_idx": 17}, {"type": "text", "text": "We provide more detailed experimental results for each category in ablation study, as illustrated in Fig. 8 and Fig. 9. From these figures, we can find that across various datasets and different imbalance factors, our method significantly enhances the generalizability of both Few classes and Medium classes. Moreover, our method maintains superior performance when combined with the SAM method. ", "page_idx": 17}, {"type": "image", "img_path": "vx4NgdyyVG/tmp/ef552b010964b768ff41efb4ae53fee34bb249d32460056995db19b489e6b197.jpg", "img_caption": ["(a) Accuracy under $I F{=}10$ "], "img_footnote": [], "page_idx": 18}, {"type": "image", "img_path": "vx4NgdyyVG/tmp/e60b05bbeaeea7e35a366a5374653d10fd2b2b0b19020299d5ad323042599447.jpg", "img_caption": ["(b) Accuracy under $I F{=}10$ with SAM "], "img_footnote": [], "page_idx": 18}, {"type": "image", "img_path": "vx4NgdyyVG/tmp/f023e20a2162039270789b49338eddada698e655b6eadce49c0ce637786f98f9.jpg", "img_caption": ["(c) Accuracy under $I F{=}100$ "], "img_footnote": [], "page_idx": 18}, {"type": "image", "img_path": "vx4NgdyyVG/tmp/ccbf13b9d3607d09839a455eee984d78b67baef04754b63c9c504fc721a8778d.jpg", "img_caption": ["(d) Accuracy under $I F{=}100$ with SAM "], "img_footnote": [], "page_idx": 18}, {"type": "text", "text": "Figure 8: Visualization of top-1 accuracy (\u2191) across different categories on CIFAR-100-LT, under three different methods: CE, Inverse Frequency $(1/n)$ and RDR. Experiments conducted under $I F{=}10$ (Plot (a) and Plot (b)) and 100 (Plot (c) and Plot (d)). ", "page_idx": 18}, {"type": "image", "img_path": "vx4NgdyyVG/tmp/1bcc303b4dc02707bb19939d20bcbd2fb9029ae9e2f8b2de8eff145ed0175021.jpg", "img_caption": ["(a) Accuracy on ImageNet-LT "], "img_footnote": [], "page_idx": 18}, {"type": "image", "img_path": "vx4NgdyyVG/tmp/8f6515052c4dae9c4711748edeee1000652ce77bffd7f4a04e19ee2b93329067.jpg", "img_caption": ["(b) Accuracy on ImageNet-LT with SAM "], "img_footnote": [], "page_idx": 18}, {"type": "image", "img_path": "vx4NgdyyVG/tmp/63bab6d05a5d16609173b5d2a63b7b1da4a3e224c55791f456ab19eaa3e96608.jpg", "img_caption": ["(c) Accuracy on Places-LT "], "img_footnote": [], "page_idx": 18}, {"type": "image", "img_path": "vx4NgdyyVG/tmp/a0f48f19e2d7ff8e6b3795063a4b051bb14dd8d0dcad1da02eb57ddb916a8b7a.jpg", "img_caption": ["(d) Accuracy on Places-LT with SAM "], "img_footnote": [], "page_idx": 18}, {"type": "text", "text": "Figure 9: Visualization of top-1 accuracy $(\\uparrow)$ across different categories on ImageNet-LT (Plot (a) and Plot (b)) and Places-LT (Plot (c) and Plot (d)), under three different methods: CE, Inverse Frequency $(1/n)$ and RDR. Plot (b) and Plot (d) are integrated with SAM while Plot (a) and Plot (c) are not. ", "page_idx": 18}, {"type": "text", "text": "E More Discussions about Limitations ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "While our approach demonstrates promising results, there are potential challenges that warrant further attention. In particular, as the number of classes increases to a very large scale, especially in certain tasks such as face recognition, retail product recommendation, or landmark detection, there could be concerns regarding computational efficiency. It is important to consider lightweight techniques to ensure that scalability does not compromise practical applicability. Additionally, in addressing imbalanced learning, care must be taken to avoid excessive rebalancing toward minority groups, as this could unintentionally affect the learning performance of the majority class, which would not align with the broader goals of fairness. Rebalancing should be conducted within a reasonable framework, mindful of avoiding misuse or overcompensation that could arise from improper manipulation by any group. Ensuring fairness for all remains a critical consideration. ", "page_idx": 19}, {"type": "text", "text": "NeurIPS Paper Checklist ", "text_level": 1, "page_idx": 20}, {"type": "text", "text": "1. Claims ", "text_level": 1, "page_idx": 20}, {"type": "text", "text": "Question: Do the main claims made in the abstract and introduction accurately reflect the paper\u2019s contributions and scope? ", "page_idx": 20}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 20}, {"type": "text", "text": "Justification: The abstract and introduction have stated the claims. ", "page_idx": 20}, {"type": "text", "text": "Guidelines: ", "page_idx": 20}, {"type": "text", "text": "\u2022 The answer NA means that the abstract and introduction do not include the claims made in the paper.   \n\u2022 The abstract and/or introduction should clearly state the claims made, including the contributions made in the paper and important assumptions and limitations. A No or NA answer to this question will not be perceived well by the reviewers.   \n\u2022 The claims made should match theoretical and experimental results, and reflect how much the results can be expected to generalize to other settings.   \n\u2022 It is fine to include aspirational goals as motivation as long as it is clear that these goals are not attained by the paper. ", "page_idx": 20}, {"type": "text", "text": "2. Limitations ", "text_level": 1, "page_idx": 20}, {"type": "text", "text": "Question: Does the paper discuss the limitations of the work performed by the authors? ", "page_idx": 20}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 20}, {"type": "text", "text": "Justification: See Section 3.5 and Appendix E. ", "page_idx": 20}, {"type": "text", "text": "Guidelines: ", "page_idx": 20}, {"type": "text", "text": "\u2022 The answer NA means that the paper has no limitation while the answer No means that the paper has limitations, but those are not discussed in the paper.   \n\u2022 The authors are encouraged to create a separate \"Limitations\" section in their paper.   \n\u2022 The paper should point out any strong assumptions and how robust the results are to violations of these assumptions (e.g., independence assumptions, noiseless settings, model well-specification, asymptotic approximations only holding locally). The authors should reflect on how these assumptions might be violated in practice and what the implications would be.   \n\u2022 The authors should reflect on the scope of the claims made, e.g., if the approach was only tested on a few datasets or with a few runs. In general, empirical results often depend on implicit assumptions, which should be articulated.   \n\u2022 The authors should reflect on the factors that influence the performance of the approach. For example, a facial recognition algorithm may perform poorly when image resolution is low or images are taken in low lighting. Or a speech-to-text system might not be used reliably to provide closed captions for online lectures because it fails to handle technical jargon.   \n\u2022 The authors should discuss the computational efficiency of the proposed algorithms and how they scale with dataset size.   \n\u2022 If applicable, the authors should discuss possible limitations of their approach to address problems of privacy and fairness.   \n\u2022 While the authors might fear that complete honesty about limitations might be used by reviewers as grounds for rejection, a worse outcome might be that reviewers discover limitations that aren\u2019t acknowledged in the paper. The authors should use their best judgment and recognize that individual actions in favor of transparency play an important role in developing norms that preserve the integrity of the community. Reviewers will be specifically instructed to not penalize honesty concerning limitations. ", "page_idx": 20}, {"type": "text", "text": "3. Theory Assumptions and Proofs ", "text_level": 1, "page_idx": 20}, {"type": "text", "text": "Question: For each theoretical result, does the paper provide the full set of assumptions and a complete (and correct) proof? ", "page_idx": 20}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 20}, {"type": "text", "text": "Justification: This paper does not include theoretical results. ", "page_idx": 21}, {"type": "text", "text": "Guidelines: ", "page_idx": 21}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include theoretical results.   \n\u2022 All the theorems, formulas, and proofs in the paper should be numbered and crossreferenced.   \n\u2022 All assumptions should be clearly stated or referenced in the statement of any theorems.   \n\u2022 The proofs can either appear in the main paper or the supplemental material, but if they appear in the supplemental material, the authors are encouraged to provide a short proof sketch to provide intuition.   \n\u2022 Inversely, any informal proof provided in the core of the paper should be complemented by formal proofs provided in appendix or supplemental material.   \n\u2022 Theorems and Lemmas that the proof relies upon should be properly referenced. ", "page_idx": 21}, {"type": "text", "text": "4. Experimental Result Reproducibility ", "text_level": 1, "page_idx": 21}, {"type": "text", "text": "Question: Does the paper fully disclose all the information needed to reproduce the main experimental results of the paper to the extent that it affects the main claims and/or conclusions of the paper (regardless of whether the code and data are provided or not)? ", "page_idx": 21}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 21}, {"type": "text", "text": "Justification: See Section 4 and Appendix C. ", "page_idx": 21}, {"type": "text", "text": "Guidelines: ", "page_idx": 21}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 If the paper includes experiments, a No answer to this question will not be perceived well by the reviewers: Making the paper reproducible is important, regardless of whether the code and data are provided or not.   \n\u2022 If the contribution is a dataset and/or model, the authors should describe the steps taken to make their results reproducible or verifiable.   \n\u2022 Depending on the contribution, reproducibility can be accomplished in various ways. For example, if the contribution is a novel architecture, describing the architecture fully might suffice, or if the contribution is a specific model and empirical evaluation, it may be necessary to either make it possible for others to replicate the model with the same dataset, or provide access to the model. In general. releasing code and data is often one good way to accomplish this, but reproducibility can also be provided via detailed instructions for how to replicate the results, access to a hosted model (e.g., in the case of a large language model), releasing of a model checkpoint, or other means that are appropriate to the research performed.   \n\u2022 While NeurIPS does not require releasing code, the conference does require all submissions to provide some reasonable avenue for reproducibility, which may depend on the nature of the contribution. For example (a) If the contribution is primarily a new algorithm, the paper should make it clear how to reproduce that algorithm. (b) If the contribution is primarily a new model architecture, the paper should describe the architecture clearly and fully. (c) If the contribution is a new model (e.g., a large language model), then there should either be a way to access this model for reproducing the results or a way to reproduce the model (e.g., with an open-source dataset or instructions for how to construct the dataset). (d) We recognize that reproducibility may be tricky in some cases, in which case authors are welcome to describe the particular way they provide for reproducibility. In the case of closed-source models, it may be that access to the model is limited in some way (e.g., to registered users), but it should be possible for other researchers to have some path to reproducing or verifying the results. ", "page_idx": 21}, {"type": "text", "text": "5. Open access to data and code ", "text_level": 1, "page_idx": 21}, {"type": "text", "text": "Question: Does the paper provide open access to the data and code, with sufficient instructions to faithfully reproduce the main experimental results, as described in supplemental material? ", "page_idx": 21}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 22}, {"type": "text", "text": "Justification: The code of this paper will be released after anonymized review. Guidelines: ", "page_idx": 22}, {"type": "text", "text": "\u2022 The answer NA means that paper does not include experiments requiring code.   \n\u2022 Please see the NeurIPS code and data submission guidelines (https://nips.cc/ public/guides/CodeSubmissionPolicy) for more details.   \n\u2022 While we encourage the release of code and data, we understand that this might not be possible, so \u201cNo\u201d is an acceptable answer. Papers cannot be rejected simply for not including code, unless this is central to the contribution (e.g., for a new open-source benchmark).   \n\u2022 The instructions should contain the exact command and environment needed to run to reproduce the results. See the NeurIPS code and data submission guidelines (https: //nips.cc/public/guides/CodeSubmissionPolicy) for more details.   \n\u2022 The authors should provide instructions on data access and preparation, including how to access the raw data, preprocessed data, intermediate data, and generated data, etc.   \n\u2022 The authors should provide scripts to reproduce all experimental results for the new proposed method and baselines. If only a subset of experiments are reproducible, they should state which ones are omitted from the script and why.   \n\u2022 At submission time, to preserve anonymity, the authors should release anonymized versions (if applicable).   \n\u2022 Providing as much information as possible in supplemental material (appended to the paper) is recommended, but including URLs to data and code is permitted. ", "page_idx": 22}, {"type": "text", "text": "6. Experimental Setting/Details ", "text_level": 1, "page_idx": 22}, {"type": "text", "text": "Question: Does the paper specify all the training and test details (e.g., data splits, hyperparameters, how they were chosen, type of optimizer, etc.) necessary to understand the results? ", "page_idx": 22}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 22}, {"type": "text", "text": "Justification: See Section 4. Guidelines: ", "page_idx": 22}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments. \u2022 The experimental setting should be presented in the core of the paper to a level of detail that is necessary to appreciate the results and make sense of them. \u2022 The full details can be provided either with the code, in appendix, or as supplemental material. ", "page_idx": 22}, {"type": "text", "text": "7. Experiment Statistical Significance ", "text_level": 1, "page_idx": 22}, {"type": "text", "text": "Question: Does the paper report error bars suitably and correctly defined or other appropriate information about the statistical significance of the experiments? ", "page_idx": 22}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 22}, {"type": "text", "text": "Justification: We report error bars for CIFAR-10-LT and CIFAR-100-LT dataset. For the large scale ImageNet-LT and Places-LT, we do not report error bars due to computational constraints. ", "page_idx": 22}, {"type": "text", "text": "Guidelines: ", "page_idx": 22}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 The authors should answer \"Yes\" if the results are accompanied by error bars, confidence intervals, or statistical significance tests, at least for the experiments that support the main claims of the paper.   \n\u2022 The factors of variability that the error bars are capturing should be clearly stated (for example, train/test split, initialization, random drawing of some parameter, or overall run with given experimental conditions).   \n\u2022 The method for calculating the error bars should be explained (closed form formula, call to a library function, bootstrap, etc.)   \n\u2022 The assumptions made should be given (e.g., Normally distributed errors).   \n\u2022 It should be clear whether the error bar is the standard deviation or the standard error of the mean.   \n\u2022 It is OK to report 1-sigma error bars, but one should state it. The authors should preferably report a 2-sigma error bar than state that they have a $96\\%$ CI, if the hypothesis of Normality of errors is not verified.   \n\u2022 For asymmetric distributions, the authors should be careful not to show in tables or figures symmetric error bars that would yield results that are out of range (e.g. negative error rates).   \n\u2022 If error bars are reported in tables or plots, The authors should explain in the text how they were calculated and reference the corresponding figures or tables in the text. ", "page_idx": 22}, {"type": "text", "text": "", "page_idx": 23}, {"type": "text", "text": "8. Experiments Compute Resources ", "text_level": 1, "page_idx": 23}, {"type": "text", "text": "Question: For each experiment, does the paper provide sufficient information on the computer resources (type of compute workers, memory, time of execution) needed to reproduce the experiments? ", "page_idx": 23}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 23}, {"type": "text", "text": "Justification: See Section 3 and Section 4. ", "page_idx": 23}, {"type": "text", "text": "Guidelines: ", "page_idx": 23}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 The paper should indicate the type of compute workers CPU or GPU, internal cluster, or cloud provider, including relevant memory and storage.   \n\u2022 The paper should provide the amount of compute required for each of the individual experimental runs as well as estimate the total compute.   \n\u2022 The paper should disclose whether the full research project required more compute than the experiments reported in the paper (e.g., preliminary or failed experiments that didn\u2019t make it into the paper). ", "page_idx": 23}, {"type": "text", "text": "9. Code Of Ethics ", "text_level": 1, "page_idx": 23}, {"type": "text", "text": "Question: Does the research conducted in the paper conform, in every respect, with the NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines? ", "page_idx": 23}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 23}, {"type": "text", "text": "Justification: This paper is conducted with the NeurIPS Code of Ethics. ", "page_idx": 23}, {"type": "text", "text": "Guidelines: ", "page_idx": 23}, {"type": "text", "text": "\u2022 The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics.   \n\u2022 If the authors answer No, they should explain the special circumstances that require a deviation from the Code of Ethics.   \n\u2022 The authors should make sure to preserve anonymity (e.g., if there is a special consideration due to laws or regulations in their jurisdiction). ", "page_idx": 23}, {"type": "text", "text": "10. Broader Impacts ", "text_level": 1, "page_idx": 23}, {"type": "text", "text": "Question: Does the paper discuss both potential positive societal impacts and negative societal impacts of the work performed? ", "page_idx": 23}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 23}, {"type": "text", "text": "Justification: Our proposed method can enhance the efficiency and robustness of imbalance learning, thereby increasing productivity. ", "page_idx": 23}, {"type": "text", "text": "Guidelines: ", "page_idx": 23}, {"type": "text", "text": "\u2022 The answer NA means that there is no societal impact of the work performed.   \n\u2022 If the authors answer NA or No, they should explain why their work has no societal impact or why the paper does not address societal impact.   \n\u2022 Examples of negative societal impacts include potential malicious or unintended uses (e.g., disinformation, generating fake profiles, surveillance), fairness considerations (e.g., deployment of technologies that could make decisions that unfairly impact specific groups), privacy considerations, and security considerations.   \n\u2022 The conference expects that many papers will be foundational research and not tied to particular applications, let alone deployments. However, if there is a direct path to any negative applications, the authors should point it out. For example, it is legitimate to point out that an improvement in the quality of generative models could be used to generate deepfakes for disinformation. On the other hand, it is not needed to point out that a generic algorithm for optimizing neural networks could enable people to train models that generate Deepfakes faster.   \n\u2022 The authors should consider possible harms that could arise when the technology is being used as intended and functioning correctly, harms that could arise when the technology is being used as intended but gives incorrect results, and harms following from (intentional or unintentional) misuse of the technology.   \n\u2022 If there are negative societal impacts, the authors could also discuss possible mitigation strategies (e.g., gated release of models, providing defenses in addition to attacks, mechanisms for monitoring misuse, mechanisms to monitor how a system learns from feedback over time, improving the efficiency and accessibility of ML). ", "page_idx": 23}, {"type": "text", "text": "", "page_idx": 24}, {"type": "text", "text": "11. Safeguards ", "text_level": 1, "page_idx": 24}, {"type": "text", "text": "Question: Does the paper describe safeguards that have been put in place for responsible release of data or models that have a high risk for misuse (e.g., pretrained language models, image generators, or scraped datasets)? ", "page_idx": 24}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 24}, {"type": "text", "text": "Justification: This paper poses no such risks. ", "page_idx": 24}, {"type": "text", "text": "Guidelines: ", "page_idx": 24}, {"type": "text", "text": "\u2022 The answer NA means that the paper poses no such risks.   \n\u2022 Released models that have a high risk for misuse or dual-use should be released with necessary safeguards to allow for controlled use of the model, for example by requiring that users adhere to usage guidelines or restrictions to access the model or implementing safety filters.   \n\u2022 Datasets that have been scraped from the Internet could pose safety risks. The authors should describe how they avoided releasing unsafe images.   \n\u2022 We recognize that providing effective safeguards is challenging, and many papers do not require this, but we encourage authors to take this into account and make a best faith effort. ", "page_idx": 24}, {"type": "text", "text": "12. Licenses for existing assets ", "text_level": 1, "page_idx": 24}, {"type": "text", "text": "Question: Are the creators or original owners of assets (e.g., code, data, models), used in the paper, properly credited and are the license and terms of use explicitly mentioned and properly respected? ", "page_idx": 24}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 24}, {"type": "text", "text": "Justification: This paper does not use such assets. ", "page_idx": 24}, {"type": "text", "text": "Guidelines: ", "page_idx": 24}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not use existing assets.   \n\u2022 The authors should cite the original paper that produced the code package or dataset.   \n\u2022 The authors should state which version of the asset is used and, if possible, include a URL.   \n\u2022 The name of the license (e.g., CC-BY 4.0) should be included for each asset.   \n\u2022 For scraped data from a particular source (e.g., website), the copyright and terms of service of that source should be provided.   \n\u2022 If assets are released, the license, copyright information, and terms of use in the package should be provided. For popular datasets, paperswithcode.com/datasets has curated licenses for some datasets. Their licensing guide can help determine the license of a dataset.   \n\u2022 For existing datasets that are re-packaged, both the original license and the license of the derived asset (if it has changed) should be provided. ", "page_idx": 24}, {"type": "text", "text": "\u2022 If this information is not available online, the authors are encouraged to reach out to the asset\u2019s creators. ", "page_idx": 25}, {"type": "text", "text": "13. New Assets ", "text_level": 1, "page_idx": 25}, {"type": "text", "text": "Question: Are new assets introduced in the paper well documented and is the documentation provided alongside the assets? ", "page_idx": 25}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 25}, {"type": "text", "text": "Justification: This paper does not release new assets. ", "page_idx": 25}, {"type": "text", "text": "Guidelines: ", "page_idx": 25}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not release new assets.   \n\u2022 Researchers should communicate the details of the dataset/code/model as part of their submissions via structured templates. This includes details about training, license, limitations, etc.   \n\u2022 The paper should discuss whether and how consent was obtained from people whose asset is used.   \n\u2022 At submission time, remember to anonymize your assets (if applicable). You can either create an anonymized URL or include an anonymized zip file. ", "page_idx": 25}, {"type": "text", "text": "14. Crowdsourcing and Research with Human Subjects ", "text_level": 1, "page_idx": 25}, {"type": "text", "text": "Question: For crowdsourcing experiments and research with human subjects, does the paper include the full text of instructions given to participants and screenshots, if applicable, as well as details about compensation (if any)? ", "page_idx": 25}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 25}, {"type": "text", "text": "Justification: This paper does not involve crowdsourcing nor research with human subjects. Guidelines: ", "page_idx": 25}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u2022 Including this information in the supplemental material is fine, but if the main contribution of the paper involves human subjects, then as much detail as possible should be included in the main paper.   \n\u2022 According to the NeurIPS Code of Ethics, workers involved in data collection, curation, or other labor should be paid at least the minimum wage in the country of the data collector. ", "page_idx": 25}, {"type": "text", "text": "15. Institutional Review Board (IRB) Approvals or Equivalent for Research with Human Subjects ", "text_level": 1, "page_idx": 25}, {"type": "text", "text": "Question: Does the paper describe potential risks incurred by study participants, whether such risks were disclosed to the subjects, and whether Institutional Review Board (IRB) approvals (or an equivalent approval/review based on the requirements of your country or institution) were obtained? ", "page_idx": 25}, {"type": "text", "text": "Answer: [NA] ", "text_level": 1, "page_idx": 25}, {"type": "text", "text": "Justification: This paper does not involve crowdsourcing nor research with human subjects. Guidelines: ", "page_idx": 25}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u2022 Depending on the country in which research is conducted, IRB approval (or equivalent) may be required for any human subjects research. If you obtained IRB approval, you should clearly state this in the paper.   \n\u2022 We recognize that the procedures for this may vary significantly between institutions and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the guidelines for their institution.   \n\u2022 For initial submissions, do not include any information that would break anonymity (if applicable), such as the institution conducting the review. ", "page_idx": 25}]