{"references": [{"fullname_first_author": "Jasper Snoek", "paper_title": "Practical Bayesian Optimization of Machine Learning Algorithms", "publication_date": "2012-01-01", "reason": "This paper is foundational for Bayesian Optimization, a key method used for hyperparameter optimization (HPO), and its practical applications are directly relevant to the current work."}, {"fullname_first_author": "Kevin Jamieson", "paper_title": "Non-stochastic best arm identification and hyperparameter optimization", "publication_date": "2016-01-01", "reason": "This paper introduces Successive Halving, a highly efficient method for HPO, which is extended and improved upon in the current research."}, {"fullname_first_author": "Stefan Falkner", "paper_title": "BOHB: Robust and efficient hyperparameter optimization at scale", "publication_date": "2018-01-01", "reason": "This paper presents BOHB, a state-of-the-art HPO algorithm that combines the strengths of Bayesian Optimization and Successive Halving, providing a benchmark for comparison in the current work."}, {"fullname_first_author": "Xuanyi Dong", "paper_title": "NAS-Bench-201: Extending the scope of reproducible neural architecture search", "publication_date": "2020-01-01", "reason": "This paper introduces NAS-Bench-201, a widely used benchmark dataset for neural architecture search (NAS), providing a standard dataset for evaluating HPO methods in the current work."}, {"fullname_first_author": "Lucas Zimmer", "paper_title": "Auto-PyTorch: Multi-fidelity metalearning for efficient and robust AutoDL", "publication_date": "2021-01-01", "reason": "This paper introduces Auto-PyTorch, another significant benchmark dataset for automated machine learning (AutoML), providing another standard dataset for evaluating HPO methods."}]}