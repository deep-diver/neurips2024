[{"figure_path": "k9uZfaeerK/figures/figures_2_1.jpg", "caption": "Figure 1: Demonstration of the negative impact from uncertainty on HPO; Successive Halving (SH) is used; the benchmark is NAS-BENCH-2.0 [9]. More detailed are in Section 4.1 and Appendix F. Due to its overlooking at model uncertainty, at each halving point, SH discards the actual best candidates, causing an increase in the regret.", "description": "This figure demonstrates how model uncertainty negatively affects hyperparameter optimization (HPO) using the Successive Halving (SH) method on the NAS-BENCH-2.0 benchmark.  The blue line shows the best validation loss observed so far during the optimization process, while the orange dashed line represents the true best validation loss after training has fully converged. The red dashed lines show the points at which SH discards half of the candidates.  The figure highlights that SH, relying only on current validation loss, prematurely discards candidates that would ultimately have performed well due to uncertainty during the initial training stages. This leads to increased regret (the difference between the true best and the selected model).  Further details are provided in Section 4.1 and Appendix F of the paper.", "section": "3.1 Uncertainty in Iterative Machine Learning"}, {"figure_path": "k9uZfaeerK/figures/figures_4_1.jpg", "caption": "Figure 2: Illustration of using UQ-guided scheme to enhance Successive Halving. The goal is to select an optimal hyperparameter configuration from K candidates. It involves multiple rounds. R is the predefined budget resources (e.g., training epochs) for each round. For the first round, K candidates each get trained for epochs. Based on the observed validation loss and the quantified uncertainty for each candidate, our method represents each candidate's converged loss with a probability distribution. From that, it constructs a confidence curve, capturing the probability that the best configuration is among the current top k candidates for 1 \u2264 k \u2264 K. From the curve, it then calculates f((\u03bc\u03b9, \u03c3\u00b2)\u2081, k), which captures the effects of keeping k top candidates (1 \u2264 k \u2264 K) for the next round, by considering the tradeoff between the risks of discarding the best candidate and the training budget each top candidate can get. From that, it identifies the best k value, discards the least promising K - k candidates, and enters the next round. The process continues until the total budget is used up.", "description": "This figure illustrates the UQ-guided scheme, a method for enhancing the Successive Halving algorithm by incorporating uncertainty quantification. It shows how the scheme uses a probabilistic model to estimate the uncertainty in model training, constructs a confidence curve to assess the probability of selecting the best candidate, and employs a discarding mechanism to eliminate less promising candidates while optimizing resource allocation across multiple rounds.", "section": "3 Uncertainty Quantification (UQ)-Guided Hyperparameter Optimization"}, {"figure_path": "k9uZfaeerK/figures/figures_8_1.jpg", "caption": "Figure 3: Experimental results of UQ-oblivious HPO methods and their UQ-guided enhancements on NAS-BENCH-2.0.", "description": "This figure presents the experimental results comparing the performance of UQ-oblivious HPO methods (original methods) against their UQ-guided enhancements (methods enhanced with the proposed UQ-guided scheme). The experiment was conducted on NAS-BENCH-201.  Three performance metrics are shown for each method: Top-1 Rank on different trials, Top-1 Rank on different fractions of budgets, and Regret on different fractions of budgets. The results demonstrate that the UQ-guided enhancements consistently achieve lower regret and improved Top-1 Rank across various budget fractions, highlighting the effectiveness of incorporating uncertainty quantification into HPO.", "section": "4.2 Experimental Results"}, {"figure_path": "k9uZfaeerK/figures/figures_19_1.jpg", "caption": "Figure 4: Landscape of the uncertainty scope for different epochs.", "description": "This figure visualizes the model uncertainty over training epochs. The left subplot displays the uncertainty (\u03c3) for individual candidates, showing varying trends and magnitudes. The right subplot shows the average uncertainty across all candidates, illustrating an overall trend of initially high uncertainty that decreases, then slightly increases again during later training stages.", "section": "3.1 Uncertainty in Iterative Machine Learning"}, {"figure_path": "k9uZfaeerK/figures/figures_19_2.jpg", "caption": "Figure 5: Illustration for confidence curve and discarding mechanisms. After obtaining the confidence curve, a threshold \u03c4 determines the number of candidates we will keep (k\u2081 for round 1, k2 for round 2, and k3 for round 3). We choose the smallest k such that Pk > \u03c4 for each round, proceed training with the best performed k candidates, and discard the rest configurations.", "description": "This figure illustrates the process of using the confidence curve to determine how many candidates to keep for further training in each round of the Hyperparameter Optimization (HPO).  The confidence curve shows the probability that the best candidate is among the top k candidates. A threshold, \u03c4, is set; any candidates below this threshold for a given round are discarded.", "section": "3.3 UQ-Guided Scheme"}, {"figure_path": "k9uZfaeerK/figures/figures_19_3.jpg", "caption": "Figure 5: Illustration for confidence curve and discarding mechanisms. After obtaining the confidence curve, a threshold \u03c4 determines the number of candidates we will keep (k\u2081 for round 1, k2 for round 2, and k3 for round 3). We choose the smallest k such that Pk > \u03c4 for each round, proceed training with the best performed k candidates, and discard the rest configurations.", "description": "This figure illustrates the concept of a confidence curve and how it's used in the UQ-guided scheme for discarding candidates in each round of the HPO process. The confidence curve shows the probability that the best candidate is among the top k candidates. A threshold (\u03c4) is set, and the algorithm selects the smallest k that exceeds this threshold. This approach balances exploration and exploitation by dynamically adjusting the number of candidates retained in each round.", "section": "3.3 UQ-Guided Scheme"}, {"figure_path": "k9uZfaeerK/figures/figures_20_1.jpg", "caption": "Figure 3: Experimental results of UQ-oblivious HPO methods and their UQ-guided enhancements on NAS-BENCH-2.0.", "description": "This figure shows the experimental results of comparing UQ-oblivious HPO methods and their UQ-guided enhancements on NAS-BENCH-201.  It presents three different metrics: Top-1 Rank on different trials, Top-1 Rank on different fractions of budgets, and Regret on different fractions of budgets.  The x-axis represents the fraction of budgets used, and the y-axis represents the metric being measured.  The results demonstrate the improvements achieved by the UQ-guided enhancements across different trials and budget fractions, showcasing a significant reduction in regret.", "section": "4.1 Experimental Setup"}, {"figure_path": "k9uZfaeerK/figures/figures_21_1.jpg", "caption": "Figure 3: Experimental results of UQ-oblivious HPO methods and their UQ-guided enhancements on NAS-BENCH-2.0.", "description": "The figure presents the experimental results comparing the performance of UQ-oblivious HPO methods (SH, HB, BOHB, SS) against their UQ-guided counterparts (SH+, HB+, BOHB+, SS+).  Three key metrics are shown across different trials and fractions of the budget: Top-1 rank (the actual ranking of the selected candidate), fraction of budgets used, and regret (accuracy difference between the chosen candidate and the actual best candidate). The UQ-guided methods consistently demonstrate significant improvements in regret reduction (21-55%) and reduced exploration time (30-75%).", "section": "4. Experimental Results"}, {"figure_path": "k9uZfaeerK/figures/figures_21_2.jpg", "caption": "Figure 3: Experimental results of UQ-oblivious HPO methods and their UQ-guided enhancements on NAS-BENCH-2.0.", "description": "The figure presents a comparison of the performance of five different hyperparameter optimization (HPO) methods with and without the UQ-guided scheme on the NAS-BENCH-2.0 benchmark. Each method is evaluated using three metrics: Top-1 Rank (accuracy of the best candidate selected by the method), Regret (performance difference between the selected candidate and the true best candidate), and fraction of budgets used (proportion of training budget utilized).  The results illustrate that UQ-guided versions consistently outperform their UQ-oblivious counterparts across all three metrics, demonstrating the effectiveness of the proposed UQ-guided scheme.", "section": "4.2 Experimental Results"}, {"figure_path": "k9uZfaeerK/figures/figures_22_1.jpg", "caption": "Figure 3: Experimental results of UQ-oblivious HPO methods and their UQ-guided enhancements on NAS-BENCH-2.0.", "description": "This figure presents the experimental results comparing the performance of UQ-oblivious and UQ-guided HPO methods on the NAS-BENCH-2.0 benchmark.  It shows three metrics: Top-1 Rank (across different trials and budget fractions), and Regret (the accuracy difference between the chosen candidate and the best candidate). The results demonstrate that the UQ-guided enhancements significantly improve performance, showing a 21-55% reduction in regret and achieving comparable accuracy with a fraction of the original methods' budget.", "section": "4 Experimental Results"}, {"figure_path": "k9uZfaeerK/figures/figures_22_2.jpg", "caption": "Figure 3: Experimental results of UQ-oblivious HPO methods and their UQ-guided enhancements on NAS-BENCH-2.0.", "description": "This figure displays the experimental results of comparing the UQ-oblivious HPO methods and their UQ-guided enhancements on the NAS-BENCH-2.0 benchmark.  It shows three metrics across different trials and fractions of the budget: Top-1 rank, regret, and the fraction of budgets. The results demonstrate the improvements achieved by the UQ-guided enhancements in terms of reducing regret (accuracy difference between returned candidate and the actual best candidate) and improving top-1 rank accuracy. The uncertainty bands (30th and 70th percentiles) are also shown, highlighting the robustness of the UQ-guided approach.", "section": "4.2 Experimental Results"}, {"figure_path": "k9uZfaeerK/figures/figures_22_3.jpg", "caption": "Figure 3: Experimental results of UQ-oblivious HPO methods and their UQ-guided enhancements on NAS-BENCH-2.0.", "description": "This figure presents the experimental results comparing the performance of UQ-oblivious HPO methods (SH, HB, BOHB, SS) against their UQ-guided counterparts (SH+, HB+, BOHB+, SS+).  The results are shown for NAS-BENCH-2.0 across three metrics: Top-1 Rank (performance of the best candidate selected by each method), Regret (difference in performance between the selected candidate and the actual best candidate), and Fraction of Budgets (the proportion of the total budget used).  The UQ-guided methods consistently demonstrate improved performance across all three metrics and different budget fractions, highlighting the benefit of incorporating uncertainty quantification into the HPO process.", "section": "4.2 Experimental Results"}, {"figure_path": "k9uZfaeerK/figures/figures_23_1.jpg", "caption": "Figure 12: Results of Top-1 Rank and Regret on test error for optimizing ridge regression.", "description": "This figure presents the results of experiments comparing the performance of standard Successive Halving (SH) and the proposed uncertainty-quantification guided SH+ method for hyperparameter optimization using ridge regression.  Two key metrics are shown: Top-1 Rank (the ranking of the best hyperparameter configuration found by each method) and Regret (a measure of the performance difference between the best configuration found and the true best configuration). The x-axis represents the fraction of the total budget used.  The results demonstrate that SH+ consistently outperforms SH across different budget fractions, achieving both better Top-1 Rank and lower Regret, showcasing the effectiveness of incorporating uncertainty quantification into hyperparameter optimization.", "section": "H Experiments on Other Iterative Learners"}]