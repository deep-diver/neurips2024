[{"type": "text", "text": "UQ-Guided Hyperparameter Optimization for Iterative Learners ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Jiesong $\\mathbf{Liu}^{\\diamond}$ , Feng Zhang\u22c6, Jiawei Guan\u22c6, Xipeng Shen\u22c4, ", "page_idx": 0}, {"type": "text", "text": "\u22c4Department of Computer Science, North Carolina State University \u22c6School of Information, Renmin University of China jliu93 $@$ ncsu.edu, guanjw $@$ ruc.edu.cn, fengzhang $@$ ruc.edu.cn, xshen5 $@$ ncsu.edu ", "page_idx": 0}, {"type": "text", "text": "Abstract ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Hyperparameter Optimization (HPO) plays a pivotal role in unleashing the potential of iterative machine learning models. This paper addresses a crucial aspect that has largely been overlooked in HPO: the impact of uncertainty in ML model training. The paper introduces the concept of uncertainty-aware $H P O$ and presents a novel approach called the UQ-guided scheme for quantifying uncertainty. This scheme offers a principled and versatile method to empower HPO techniques in handling model uncertainty during their exploration of the candidate space. By constructing a probabilistic model and implementing probability-driven candidate selection and budget allocation, this approach enhances the quality of the resulting model hyperparameters. It achieves a notable performance improvement of over $50\\%$ in terms of accuracy regret and exploration time. ", "page_idx": 0}, {"type": "text", "text": "1 Introduction ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Hyperparameter optimization (HPO) is essential for unleashing the power of iterative machine learning models [4, 18, 40]. Hyperparameters include traditional parameters like learning rates and more complex ones like neural architectures and data augmentation policies. For iterative learners (multi-fidelity and early stopping methods specifically), practitioners can obtain intermediate validation loss after each iteration and use them for model assessment; the main goal of HPO is to explore a vast candidate space to find candidates that lead to optimal model performance. ", "page_idx": 0}, {"type": "text", "text": "There are many designs in the literature to solve the HPO problem. Successive Halving (SH) [19], for example, terminates training of candidate configurations with poor performance early so as to save computing resources for more well-behaved candidates. Bayesian optimization [17, 34], another optimization method, uses a surrogate model to guide the selection of candidate configurations for assessment. ", "page_idx": 0}, {"type": "text", "text": "There is however a lack of systematic treatment of an important factor in HPO designs, the uncertainty inherent in the dynamics of the training process of iterative machine learning applications. Because of the uncertainty, a model with a candidate hyperparameter configuration (or candidate in short) performing poorly in an early stage of its training could turn out to be the best model after convergence. Such candidates are however likely to be stopped from proceeding further or be completely discarded by existing HPO methods in the early stages, because their selections of candidates are mostly based on the currently observed performance, for lack of a way to treat the uncertainty properly. In 100 experiments of Successive Halving, for instance, the actually best candidates were discarded in the first 8\u201322 iterations of training, causing $48\\%$ performance regrets in validation loss (details in Section 3.1 Figure 1 and Section 4 Figure 3). ", "page_idx": 0}, {"type": "text", "text": "This paper introduces model uncertainty into the design of HPO methods for iterative learners and establishes the concept of uncertainty-aware HPO. At the core of uncertainty-aware HPO is a novel uncertainty quantization (UQ) guided scheme, named UQ-guided scheme, which unifies the selection of candidates and the scheduling of training budget\u2014two most important operations in HPO\u2014into a single UQ-based formal decision process. The UQ-guided scheme builds on a probabilistic uncertainty-based model, designed to approximate the statistical effects of discarding a set of candidates at the end of a step in HPO. It uses a lightweight method to efficiently quantify model uncertainty on the fly. It offers a principled, efficient way for HPO to treat model training uncertainty. ", "page_idx": 0}, {"type": "text", "text": "", "page_idx": 1}, {"type": "text", "text": "As a general scheme, the UQ-guided scheme can be integrated into a variety of HPO methods for iterative learners, especially DNNs. This paper demonstrates its usefulness and generality for DNNs by integrating it into four existing HPO methods. Experiments on two widely used HPO benchmarks, NAS-BENCH-201 [9] and LCBench [42], show that the enhanced methods produce models that have $21{-}55\\%$ regret reduction over the models from the original methods at the same exploration cost. And those enhanced methods need only $30\u201375\\%$ time to produce models with accuracy comparable to those by the original HPO methods. The paper further gives a theoretical analysis of the impact of the $U\\boldsymbol{Q}$ -guided scheme for HPO. ", "page_idx": 1}, {"type": "text", "text": "2 Background and Related Work ", "text_level": 1, "page_idx": 1}, {"type": "text", "text": "Many studies are committed to solving the HPO problem for iterative learners efficiently [26, 20, 29, 39, 41]. Bayesian optimization, early stop-based mechanisms, and multi-fidelity optimizations are some important approaches. ", "page_idx": 1}, {"type": "text", "text": "Bayesian Optimization (BO). BO is a sequential design strategy used to optimize black-box functions [34, 17, 11]. In HPO scenarios, it can be used as a surrogate model to sample high-quality candidates. ", "page_idx": 1}, {"type": "text", "text": "Early Stop Mechanisms. Early stop-based approaches can be effective since they evaluate different candidates during training and make adaptive selections accordingly [2, 8, 35]. The early stopping mechanism, which stops the training of poorly-performed candidates early, has been widely employed in the HPO community including Successive Halving (SH) [19] and Hyperband (HB) [25]; BOHB [11] combines both BO and HB methods to take advantage of both the BO surrogate model and the early stopping mechanism. ", "page_idx": 1}, {"type": "text", "text": "Multi-fidelity Optimizations. Multi-fidelity evaluation focuses on using low-fidelity results trained with small resources to accelerate the evaluation of candidates [2, 3, 8, 22, 23, 38, 21, 35, 36, 14, 26]. Sub-sampling (SS) [15] is proposed mainly using multi-fidelity methods to collect high-quality data to select good configurations without early stopping. ", "page_idx": 1}, {"type": "text", "text": "Model Uncertainty in HPO. Various optimization methods in HPO scenarios focus on specific training metrics to assess candidate performance. However, these methods typically overlook the uncertainty in the candidate selection process. Machine learning models inherently have approximation uncertainties [5, 6, 10, 12, 24, 28, 31]. Some HPO designs sample the candidate space based on distributions on the effect of each hyperparameter dimension on the quality of the candidates, but without considering the uncertainty in the model training process. For example, one of the studies [33] separates candidates into \u201cgood\u201d or \u201cbad\u201d groups in order to build the distributions. The separation is based on the same deterministic metrics as other HPO methods use, giving no consideration of the uncertainty in model trainings. The only work we find that considers uncertainty in training metrics [32] selects configurations for further training based on its assessment of the upperbound of those configurations. In each round, the configurations it chooses are those that, considering the best possible performance at the last iteration, show a smaller validation loss than the validation loss current best configuration shows. The selection treats model uncertainty preliminarily and does not use it to guide the allocation of training budget. We compare other related works in Appendix E. ", "page_idx": 1}, {"type": "text", "text": "3 Uncertainty Quantification (UQ)-Guided Hyperparameter Optimization ", "text_level": 1, "page_idx": 1}, {"type": "text", "text": "This section gives an exploration of model uncertainty, introduces UQ-guided scheme for incorporating UQ into the design of HPO, discusses examples of ways to use the UQ-guided scheme to enhance existing HPO methods, and theoretically analyzes its effects. ", "page_idx": 1}, {"type": "text", "text": "3.1 Uncertainty in Iterative Machine Learning ", "text_level": 1, "page_idx": 1}, {"type": "text", "text": "Uncertainty in iterative machine learning originates mainly from two factors: inherent noise in the data and the variability of model predictions due to restricted knowledge [16, 1]. Since data uncertainty is constant, it is the variability in model predictions, referred to as model uncertainty, that primarily influences decisions on HPO. To estimate the model uncertainty, we can incur small perturbations to the model, evaluate these model variants, and calculate the variance of the results as the approximation for the model uncertainty [16]. ", "page_idx": 1}, {"type": "text", "text": "Figure 1 shows how the model uncertainty affects the quality of the returned candidate. In a given SH run, half of the candidates are eliminated at each checkpoint marked by a vertical red dashed line. The solid blue line represents the best validation loss up to the current point, while the orange dashed line signifies the true quality (in terms of validation loss after convergence) of the candidates SH retains at that specific juncture. From the figure, we see that in every round, SH discards the actually best candidates, causing a continuous increase of the regret. The reason is that the discarding decision of SH is solely based on the current validation loss, but model uncertainty, particularly pronounced in the early stages, obfuscating the true model potential. ", "page_idx": 2}, {"type": "text", "text": "3.2 Quantify Uncertainty and the Impact ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "We explain how we quantify model uncertainty, and how, based on it, at any point of time, estimate the performance and uncertainty of a candidate model when its training converges. ", "page_idx": 2}, {"type": "text", "text": "High efficiency is essential here as the UQ happens during the HPO process. We employ a lightweight approach to conduct the UQ efficiently on the fly, as explained next. ", "page_idx": 2}, {"type": "text", "text": "Let $\\gamma_{1},\\gamma_{2},\\cdot\\cdot\\cdot\\ ,\\gamma_{K}\\ \\in\\ \\Gamma$ be $K$ candidates drawn from the hyperparameter space $\\Gamma$ . Consider a supervised learning setting, where a machine learning model $M$ is trained on some training set $D_{T r a i n}=$ $\\left\\{(\\mathbf{x}_{1},y_{1}),(\\mathbf{x}_{2},y_{2}),\\cdot\\cdot\\cdot\\mathbf{\\xi},(\\mathbf{x}_{n_{t r a i n}},y_{n_{t r a i n}})\\right\\}$ . Let $M_{\\gamma}^{t}$ denote the model with hyperparameter $\\gamma$ trained on $D_{T r a i n}$ after $t$ epochs, and $M_{\\gamma}^{*}$ the converged model. $M_{\\gamma}^{t}(\\mathbf{x})$ gives the prediction on a given input $\\mathbf{x}\\in\\mathbb{R}^{d}$ . ", "page_idx": 2}, {"type": "image", "img_path": "k9uZfaeerK/tmp/7f98b67c2194dfa0c66a877f5d267766508311cfc0b90789d639fb08fe6d6497.jpg", "img_caption": ["Figure 1: Demonstration of the negative impact from uncertainty on HPO; Successive Halving (SH) is used; the benchmark is NASBENCH-2.0 [9]. More detailed are in Section 4.1 and Appendix F. Due to its overlooking at model uncertainty, at each halving point, SH discards the actual best candidates, causing an increase in the regret. "], "img_footnote": [], "page_idx": 2}, {"type": "text", "text": "We use $\\ell(\\cdot,\\cdot)$ to denote the metric that evaluates the   \nperformance of a candidate model. Given a hyperparameter configuration $\\gamma_{c}$ , the validation loss of a model instance, $\\ell(\\mathbf{y},M_{\\gamma_{c}}^{*}(\\mathbf{X}))$ , can be affected by training data and other factors, and hence has some uncertainty. Let $\\mathcal{N}(\\mu_{c}*,\\sigma_{c}^{2}*)$ represent the distribution of $\\ell(\\mathbf{y},M_{\\gamma_{c}}^{*}(\\mathbf{X}))$ , where, $\\sigma_{c}^{2}{*}$ embodies the uncertainty. ", "page_idx": 2}, {"type": "text", "text": "Our objective here is a way that can, at any point in the HPO process, estimate $\\sigma_{c}^{*2}$ and $\\mu_{c}^{*}$ for a candidate model configured with $\\gamma_{c}$ . Our solution leverages the validation history in the HPO process, $\\ell(\\mathbf{y},M_{\\gamma_{c}}^{1}(\\mathbf{X})),\\cdot\\cdot\\cdot\\mathbf{\\xi},\\ell(\\mathbf{\\bar{y}},M_{\\gamma_{c}}^{t}(\\mathbf{X}))$ , to construct an estimated loss curve, explained as follows. ", "page_idx": 2}, {"type": "text", "text": "Decomposition of momentum and the underlying structure of the metric. This part uses breakdowns to characterize the loss curve and introduces the objective function we want to minimize to estimate the curve parameters. The first component, referred to as momentum, models the decaying trend of the loss curve. The second component is the bias term for each candidate\u2019s loss curve; it models a latent effect underlying the hyperparameter space by allowing correlation among the candidates. The details are as follows. ", "page_idx": 2}, {"type": "text", "text": "Typically a candidate in HPO can be represented as a vector. We use a set $\\mathcal{U}_{r}\\subset\\mathbb{R}^{r}$ to represent the candidates $\\{\\gamma_{i},i\\in[n]\\};r>0$ is the vector length. For modeling the loss curve, we set $\\bar{\\mathbf{k}}_{t}\\in\\mathbb{R}^{L}$ as a vector whose elements are functions of training epochs $t=1,2,\\cdot\\cdot\\cdot.$ . (In our experiments, we set $\\mathbf{k}_{t}=[t^{-1/2},t^{-1}]$ , for the general decreasing trend of loss curves as training epochs increase.) We model metric $\\mathbf{\\boldsymbol{\\ell}}_{t}^{\\mathbf{u}}$ of candidate $\\mathbf{u}\\in\\mathcal{U}_{r}$ at time $t$ as the summation of the impact from three sources: ", "page_idx": 2}, {"type": "equation", "text": "$$\n\\ell_{t}^{\\mathbf{u}}=\\ell(\\mathbf{y},M_{\\gamma_{c}}^{t}(\\mathbf{X}))=\\mathbf{k}_{t}^{\\top}\\boldsymbol{\\eta}^{\\mathbf{u}}+\\mathbf{u}^{\\top}\\mathbf{Z}+\\boldsymbol{\\epsilon}_{t}^{\\mathbf{u}},\n$$", "text_format": "latex", "page_idx": 2}, {"type": "text", "text": "where $\\eta^{\\mathbf{u}}$ and $\\mathbf{Z}$ are the parameter vectors to determine. The three components in Equation 3.1 are (1) the momentum part $(\\bar{\\mathbf{k}}_{t}^{\\top}\\boldsymbol{\\eta}^{\\mathbf{u}})$ that denotes the contribution from the trends in the loss curve of the training specific candidate model variant, (2) the contribution from the underlying model structure $(\\mathbf{u}^{\\top}\\mathbf{Z})$ , and (3) the noises by other elements $\\epsilon_{t}^{\\mathbf{u}}$ , which is asssumed to follow a Gaussian distribution $\\mathcal{N}(0,\\sigma_{t}^{2})$ independent of each other and of $\\mathbf{Z}$ . ", "page_idx": 2}, {"type": "text", "text": "For a candidate $\\mathbf{u}\\in\\mathcal{U}_{r}$ , let $\\alpha^{\\mathbf{u}}=\\mathbf{u}^{\\top}\\mathbf{Z}$ . The loss curve parameters $\\{\\alpha^{\\mathbf{u}},\\eta^{\\mathbf{u}}\\}$ can be determined by optimizing a weighted least squares objective ", "page_idx": 2}, {"type": "equation", "text": "$$\n\\mathcal{G}=\\operatorname*{min}_{\\alpha^{\\mathbf{u}},\\eta^{\\mathbf{u}}}\\sum_{t=1}^{T}\\sum_{j=1}^{F_{k}}w_{j t}(\\ell_{j t}^{\\mathbf{u}}-\\alpha^{\\mathbf{u}}-\\mathbf{k}_{t}^{\\top}\\eta^{\\mathbf{u}})^{2}\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "where $\\begin{array}{r}{w_{j t}=\\frac{1}{F_{t}\\sigma_{t}^{2}}}\\end{array}$ . $F_{t}$ is the number of models trained with time $t$ . ", "page_idx": 3}, {"type": "text", "text": "Solving for the Momentum Mean and Variance. This part analyzes the mean and variance of the loss curve we constructed and makes inferences to the converged loss based on the loss curve. The quantified uncertainty of the estimated converged loss is then used for model selection and budget resource allocation. The specifics are as follows. ", "page_idx": 3}, {"type": "text", "text": "For a candidate $i$ at iteration $T$ , concatenating the validation losses across training epochs (indexed by $t^{\\th}$ ) will lead to a validation loss vector $\\mathbf{v}$ of dimension $\\begin{array}{r}{D=\\sum_{t=1}^{T}F_{t}}\\end{array}$ . For each $d\\in\\{1,\\cdots,D\\}$ , the $d^{t h}$ element in $\\mathbf{v}$ is an observation of loss at time $t_{d}$ that follows $\\mathcal{N}(\\mu_{i_{t_{d}}},\\sigma_{t_{d}}^{2})$ with $t_{d}$ mapping $d$ to its corresponding epoch $t$ . ", "page_idx": 3}, {"type": "text", "text": "For a given candidate $\\mathbf{u}$ (for better readability, we omit the superscript $\\mathbf{u}$ in the notations in the following discussion), the weighted least squares problem can be formulated as solving the equation W12 v = W21 A\u03b2 for \u03b2 with W \u2208RD\u00d7D being a diagonal matrix of weights Wdd = Ftd1\u03c3t2 . $\\begin{array}{r}{\\mathbf{A}=\\left[\\mathbf{1}\\quad\\mathbf{K}\\right]}\\end{array}$ , $\\mathbf{K}\\in\\mathbb{R}^{D\\times(L+1)}$ with $\\mathbf{K}[d,:]=\\mathbf{k}_{t_{d}}^{\\top}$ , and $\\boldsymbol{\\beta}^{\\top}=[\\alpha\\textbf{\\boldsymbol{\\eta}}]$ . The empirical estimate of $\\sigma_{i}^{2}$ is computed as the variance of the loss in the recent several epochs of $i$ \u2014those instances can be regarded as results of small perturbations to the model at epoch $i$ . ", "page_idx": 3}, {"type": "text", "text": "Solving the weighted least square objective, we have the estimator as $\\hat{\\beta}=(\\mathbf{A}^{\\top}\\mathbf{W}\\mathbf{A})^{-1}(\\mathbf{A}^{\\top}\\mathbf{W}\\mathbf{v})$ .   \nThe covariance of the estimator is given by $\\Sigma_{\\hat{\\beta}}=(\\mathbf{A}^{\\top}\\mathbf{W}\\mathbf{A})^{-1}$ . ", "page_idx": 3}, {"type": "text", "text": "Since the estimated curve is given by $\\hat{v}(t)=[1\\quad\\mathbf{k}_{t}^{\\top}]\\hat{\\beta}$ , the variance of this estimation is given by ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\hat{\\sigma}^{2}(t)=[1\\quad\\mathbf{k}_{t}^{\\top}]\\Sigma_{\\hat{\\beta}}\\left[\\mathbf{{k}}_{t}\\right].\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "With the formulas for ${\\hat{v}}(t)$ and ${\\hat{\\sigma}}^{2}(t)$ , we can then approximate the distribution of $\\ell(\\mathbf{y},M_{\\gamma_{i}}^{*}(\\mathbf{X}))$ as $\\mathcal{N}(\\hat{v}(N),\\hat{\\sigma}^{2}(N))$ for a large $N$ value $N=200$ in our experiments). ", "page_idx": 3}, {"type": "text", "text": "Algorithm. Based on the analysis, we devise an iterative algorithm to compute the estimated loss and variance. Without the loss of generality, we make the following assumption. ", "page_idx": 3}, {"type": "text", "text": "Assumption 1. There exist positive constants $\\overline{{u}}$ such that for any $r$ $r,\\,\\operatorname*{max}_{\\mathbf{u}\\in\\mathcal{U}_{r}}\\left\\|\\mathbf{u}\\right\\|\\leq\\overline{{u}}$ , and the set of candidates $\\mathcal{U}_{r}\\subset\\mathbb{R}^{r}$ has $r$ linearly independent elements $\\mathbf{b}_{1},\\cdots,\\mathbf{b}_{r}$ . ", "page_idx": 3}, {"type": "text", "text": "The algorithm goes as follows. At the beginning of HPO, it sets $\\mathbf{Z}$ with a random vector. At the end of each epoch, it conducts the following two operations. First, it solves the weighted least squares objective 3.2 for each of the $r$ candidates (mentioned in Assumption 1) by following the formulas described earlier in this section, with the current $\\mathbf{Z}$ value being used. Second, for $p=1,2,\\cdot\\cdot\\cdot r$ , it observes the metrics $X^{\\mathbf{b}_{p}}(t)=\\ell_{t}^{\\mathbf{b}_{\\mathbf{p}}}-\\mathbf{k}_{t}^{\\top}\\hat{\\boldsymbol{\\eta}}^{\\mathbf{b}_{p}}$ and refines the ordinary least square estimate for $\\mathbf{Z}$ as follows: ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\widehat{\\mathbf{Z}}=\\left(\\sum_{p=1}^{r}\\mathbf{b}_{p}\\mathbf{b}_{p}^{\\top}\\right)^{-1}\\sum_{p=1}^{r}\\mathbf{b}_{p}X^{\\mathbf{b}_{p}}\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "At the end of an HPO round (e.g., at the halving time in SH), it performs the first step for every candidate model to compute the estimated distributions of their $\\ell(\\bar{\\mathbf{y}},M_{\\gamma_{i}}^{*}(\\mathbf{X}))$ , so that the HPO can use the estimates to select promising candidates to continue in the next round. ", "page_idx": 3}, {"type": "text", "text": "We next show how to use the approximated loss and uncertainty to compare two candidates: ", "page_idx": 3}, {"type": "text", "text": "Definition 1 (UQ-guided comparison of candidates). $U\\boldsymbol{Q}$ -guided comparison of candidates compares two candidates based on the probability that the validation loss of the converged model $\\gamma_{c_{1}}$ is lower than that of $\\gamma_{c_{2}}$ , represented as follows based on the approximation from the current validation losses and uncertainty of the two candidates: ", "page_idx": 3}, {"type": "equation", "text": "$$\nP=\\mathrm{Pr}\\left\\{\\ell(\\mathbf{y},M_{\\gamma_{c_{1}}}^{*}(\\mathbf{X}))>\\ell(\\mathbf{y},M_{\\gamma_{c_{2}}}^{*}(\\mathbf{X}))\\Big|\\ell(\\mathbf{y},M_{\\gamma_{c_{1}}}^{t=1,2,\\dots}(\\mathbf{X})),\\hat{\\sigma}_{c_{1}},\\ell(\\mathbf{y},M_{\\gamma_{c_{2}}}^{t=1,2,\\dots}(\\mathbf{X})),\\hat{\\sigma}_{c_{2}}\\right\\}.\n$$", "text_format": "latex", "page_idx": 3}, {"type": "image", "img_path": "k9uZfaeerK/tmp/6d8e7589bf15f80f75cfca36b039a3010ec5958b5bb8e6801e50f0e109d6e73a.jpg", "img_caption": ["Figure 2: Illustration of using UQ-guided scheme to enhance Successive Halving. The goal is to select an optimal hyperparameter configuration from $K$ candidates. It involves multiple rounds. $R$ is the predefined budget resources (e.g., training epochs) for each round. For the first round, $K$ candidates each get trained fo r KR epochs. Based on the observed validation loss and the quantified uncertainty for each candidate, our method represents each candidate\u2019s converged loss with a probability distribution. From that, it constructs a confidence curve, capturing the probability that the best configuration is among the current top $k$ candidates for $1\\le k\\le K$ . From the curve, it then calculates $\\!\\!\\!\\!\\!f((\\mu_{i},\\sigma_{i}^{2})_{i=1}^{K},k)$ , which captures the effects of keeping $k$ top candidates $(1\\leq k\\leq K)$ ) for the next round, by considering the tradeoff between the risks of discarding the best candidate and the training budget each top candidate can get. From that, it identifies the best $k$ value, discards the least promising $K-k$ candidates, and enters the next round. The process continues until the total budget is used up. "], "img_footnote": [], "page_idx": 4}, {"type": "text", "text": "The main idea of Definition 1 is to use the current validation loss history and quantified uncertainty to approximate the converged validation loss, so that we compare two candidates \u2013 more precisely, we compute the probability that one candidate is better than the other \u2013 based on the probability distribution of their converged validation loss. For example, if the approximated loss and uncertainty of two candidates $\\gamma_{j}$ and $\\gamma_{k}$ , at epoch $t$ , are $(\\mu_{j},\\sigma_{j})$ and $(\\mu_{k},\\sigma_{k})$ , using converged validation loss as the metric, we have $\\begin{array}{r}{\\operatorname*{Pr}(\\ell(\\mathbf{y},M_{\\gamma_{j}}^{t}(\\mathbf{X}))>\\ell(\\mathbf{y},M_{\\gamma_{k}}^{t}(\\mathbf{X}))){=\\Phi\\Big(\\frac{\\mu_{k}-\\mu_{j}}{\\sqrt{\\sigma_{j}^{2}+\\sigma_{k}^{2}}}\\Big)}}\\end{array}$ , where $\\Phi$ denotes the cumulative distribution function (CDF) of the standard normal distribution. ", "page_idx": 4}, {"type": "text", "text": "We next present $U\\boldsymbol{Q}$ -guided scheme, a principled way to use UQ to guide HPO. ", "page_idx": 4}, {"type": "text", "text": "3.3 UQ-Guided Scheme ", "text_level": 1, "page_idx": 4}, {"type": "text", "text": "Figure 2 illustrates how UQ-guided scheme works in HPO. For the purpose of clarity, we base our explanation of the scheme on HPO that uses early stop mechanisms, but will show in Section 3.5 that the scheme is general, applicable to other HPO methods for iterative learners as well. ", "page_idx": 4}, {"type": "text", "text": "The original HPO method, Successive Halving [19], evaluates and eliminates candidates over multiple rounds. At the end of each round, it drops those candidates regarded as unpromising. With our UQ-guided scheme, at the end of each round, the scheme derives a confidence curve from the current probabilistic model, and uses a discarding mechanism to drop candidates that are unlikely to perform well after convergence. In contrast to the original HPO that drops a fixed amount (or fraction) of candidates in each round, the UQ-guided scheme carefully calculates the number of candidates to drop in a round based on the probabilistic model such that the expected quality of the HPO outcomes can be maximized, as explained later. ", "page_idx": 4}, {"type": "text", "text": "The UQ-guided scheme respects the HPO budget\u2014that is, the total amount of time usable by the HPO for identifying the best candidate. By default, it works around the given budget constraint: the budget for each round $(R)$ equals the total budget divided by the number of rounds. We next discuss each step. ", "page_idx": 4}, {"type": "text", "text": "3.3.1 Confidence Curve Derived from Uncertainty Quantification ", "text_level": 1, "page_idx": 4}, {"type": "text", "text": "The concept of confidence curve is central in UQ-guided HPO. Define $[n]=\\{1,2,\\cdots\\,,n\\}$ . ", "page_idx": 4}, {"type": "text", "text": "Definition 2 (Confidence curve). At epoch $t_{\\perp}$ , we evaluate each candidate\u2019s performance and sort them based on validation loss. $A$ confidence curve $\\mathcal{C}$ is a trajectory of a series of probabilities, $\\{P_{k}|k\\in[n]\\}$ , that depicts the probability that the optimal configuration (with the lowest loss after convergence) is among the first $k$ configurations. For $k\\in[n]$ , $P_{k}$ can be expressed as ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathsf{\\boldsymbol{\\gamma}}_{k}=\\operatorname*{Pr}\\Big\\{\\operatorname*{min}(\\ell(\\mathbf{y},M_{\\gamma_{1}}^{*}(\\mathbf{X})),\\cdots,\\ell(\\mathbf{y},M_{\\gamma_{k}}^{*}(\\mathbf{X})))\\leq\\operatorname*{min}(\\ell(\\mathbf{y},M_{\\gamma_{k+1}}^{*}(\\mathbf{X})),\\cdots,\\ell(\\mathbf{y},M_{\\gamma_{n}}^{*}(\\mathbf{X})))\\Big\\}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "The confidence curve is derived based on joint probability distribution in the following way. Suppose there are $n$ candidates. At the end of a certain round, the probabilistic model returns $n$ pairs of $(\\mu_{1},\\sigma_{1}),(\\mu_{2},\\sigma_{2}),\\cdot\\cdot\\cdot\\,,(\\mu_{n},\\sigma_{n})$ as estimations for $\\ell(\\mathbf{y},M_{\\gamma_{1}}^{*}(\\mathbf{X}))$ , $\\ell({\\mathbf{y}},M_{\\gamma_{2}}^{*}({\\mathbf{X}})),\\,.$ \u00b7 \u00b7 , $\\ell(\\mathbf{y},M_{\\gamma_{n}}^{*}(\\mathbf{X}))$ . For simplicity, assume that $\\mu_{1}<\\mu_{2}<\\dots<\\mu_{n}$ , and $\\sigma_{1}=\\sigma_{2}=\\cdots=\\sigma$ . ", "page_idx": 5}, {"type": "text", "text": "Let $\\Phi$ and $\\phi$ be the CDF and PDF of the standard normal distribution. For $k=m$ , we can calculate ", "page_idx": 5}, {"type": "equation", "text": "$$\nP_{m}=\\int_{-\\infty}^{\\infty}\\frac{1}{\\sigma}\\sum_{i=1}^{m}\\frac{\\phi(\\frac{y+\\mu_{i}}{\\sigma})}{\\Phi(\\frac{y+\\mu_{i}}{\\sigma})}\\cdot\\prod_{i=1}^{n}\\Phi(\\frac{y+\\mu_{i}}{\\sigma})d y.\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "The details of obtaining Equation 3.4 are in Appendix A.1. ", "page_idx": 5}, {"type": "text", "text": "3.3.2 Discarding Mechanism ", "text_level": 1, "page_idx": 5}, {"type": "text", "text": "The next step is to decide, at the end of each round, the appropriate value of $k$ , which determines how many $(n-k)$ lowest-ranked candidates will be discarded in this round. Our scheme decides $k$ based on the confidence curve: choosing the smallest $k$ that satisfies $P_{k}\\ge\\tau$ , where $\\tau$ is a parameter determined by our scheme adaptively as follows. ", "page_idx": 5}, {"type": "text", "text": "Choosing $\\tau$ . At the end of round $i$ , we have the confidence curve $\\mathcal{C}_{i}(P_{1}^{i},P_{2}^{i},\\cdot\\cdot\\cdot\\,,P_{n}^{i})$ that is the trajectory of a series of probabilities. We quantify how $\\tau$ influences the probability for the HPO to select the best candidate. ", "page_idx": 5}, {"type": "text", "text": "Let $\\tau_{i}$ be the value of $\\tau$ for round $i$ , $k_{i}$ be $\\operatorname*{min}\\{k:{\\mathcal{C}}_{i}(P_{k})\\geq\\tau_{i}\\}$ . As the scheme discards the worst $n-k_{i}$ candidates and further trains the best $k_{i}$ candidates in round $i+1$ , we can derive the confidence curve of round $i+1$ as $\\mathcal{C}_{i+1}(P_{1}^{i+1},P_{2}^{i+1},\\cdot\\cdot\\cdot\\,,P_{k_{i}}^{i+1})$ based on those selected $k_{i}$ candidates. Since we want to quantify the effect of $\\tau$ on the probability that the scheme returns the best candidate (that is, to suppose round $i+1$ is our final round), $P_{1}^{i+1}$ is the target we desire to maximize. Define $\\xi_{i}$ to be the current condition $(\\mu_{i},\\sigma_{i})_{i=1}^{n}$ . Let $f(\\cdot,\\cdot)$ be a mapping such that $f(\\pmb{\\xi}_{i},\\tau_{i})=P_{1}^{i+1}$ . We want to use a selector function $\\Psi:D\\rightarrow[0,1]$ where $D=([0,\\stackrel{..}{\\infty})^{.}\\times[0,\\infty))^{\\bar{n}}\\stackrel{..}{\\times}[0,\\bar{1}]$ . $\\Psi$ takes $\\xi_{i}$ as input and returns an optimal $\\tau_{i}$ : ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\Psi(\\pmb{\\xi}_{i})=\\arg\\operatorname*{max}_{\\tau_{i}\\in[0,1]}\\{f(\\pmb{\\xi}_{i},\\tau_{i})\\}.\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "The effect of $\\tau_{i}$ on $f$ manifests through its influence on the number of candidates $k_{i}$ retained in the subsequent round, and can be ultimately broken down into the influence of (1) exploration, meaning keeping more candidates in the next round can reduce this round\u2019s discarding error, and (2) exploitation, meaning keeping fewer candidates in the next round can allow each candidate to receive more training time (recall that the training time budget is fixed for each round) and hence will increase the reliability of the validation at the end of the next round. ", "page_idx": 5}, {"type": "text", "text": "Exploration. If $k_{i}$ drops by 1 to $k_{i}^{\\prime}$ , according to the definition of the confidence curve, the probability that the final optimal configuration is among the remaining candidates we keep drops by $\\Delta c_{\\downarrow}=$ $P_{k_{i}}-P_{k_{i}^{\\prime}}$ : ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\Delta c_{\\downarrow}=\\int_{-\\infty}^{\\infty}\\frac{1}{\\sigma}\\cdot\\frac{\\phi(\\frac{y+\\mu_{k_{i}}}{\\sigma})}{\\Phi(\\frac{y+\\mu_{k_{i}}}{\\sigma})}\\cdot\\prod_{i=1}^{n}\\Phi(\\frac{y+\\mu_{i}}{\\sigma})d y.\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "Exploitation. At the same time, a drop in $k_{i}$ leads to an increase in the individual training budget $b$ Let $\\bar{\\zeta}$ be the coefficient that relates the increase in the number of training epochs to its corresponding effect on confidence. Using an approach similar to that employed in formulating the confidence curve, ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\zeta=\\int_{-\\infty}^{\\infty}\\frac{1}{\\sigma-\\Delta_{t}\\sigma}\\phi(\\frac{y+\\mu_{1}}{\\sigma-\\Delta_{t}\\sigma})\\cdot\\prod_{i=2}^{k_{i}}\\Phi(\\frac{y+\\mu_{i}}{\\sigma-\\Delta_{t}\\sigma})d y-\\int_{-\\infty}^{\\infty}\\frac{1}{\\sigma}\\phi(\\frac{y+\\mu_{1}}{\\sigma})\\cdot\\prod_{i=2}^{k_{i}}\\Phi(\\frac{y+\\mu_{i}}{\\sigma})d y\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "where $t$ represents the current total number of epochs and $\\Delta_{t}\\sigma$ represents the reduction in the uncertainty $\\sigma$ that would result from training each candidate for one additional epoch. The specifics for Equations 3.6 and 3.7 can be found in Appendix A.2. Given that $b$ increases by ${\\frac{R}{k_{i}^{\\prime}}}-{\\frac{R}{k_{i}}}$ , the overall influence of exploitation on the probability of selecting an optimal candidate is \u2206c\u2191=ki(kRi\u22121)\u03b6. ", "page_idx": 5}, {"type": "text", "text": "Let $\\zeta(k_{i},\\pmb{\\xi}_{i})$ be the confidence increase, given condition $\\xi_{i}$ , when each of the $k_{i}$ candidates gets a unit extra training budget. $\\mathcal{C}_{i}(P_{k}),k\\in[\\bar{n}]$ are the confidence curves. Balancing exploration and exploitation leads to a sweet point where $\\Delta c_{\\downarrow}=\\Delta c_{\\uparrow}$ . That gives the way to derive the appropriate value for $\\tau$ , which just needs to make the following hold: ", "page_idx": 6}, {"type": "equation", "text": "$$\nP_{k_{i}}-P_{k_{i}-1}=\\frac{R}{k_{i}(k_{i}-1)}\\zeta(k_{i},{\\pmb\\xi}_{i}).\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "3.4 Theoretical Analysis ", "text_level": 1, "page_idx": 6}, {"type": "text", "text": "We consider how the method performs in terms of identifying the best candidate. For convenience, we let $\\ell_{i,t}$ be the approximation of the converged loss for the model with hyperparameter $\\gamma_{i}$ at time $t$ . For each $i$ , assume $\\begin{array}{r}{\\nu_{i}=\\operatorname*{lim}_{\\tau\\rightarrow\\infty}\\ell_{i,\\tau}}\\end{array}$ exists. The goal is to identify arg $\\operatorname*{min}_{i}\\nu_{i}$ . Without loss of generality, assume that $\\nu_{1}<\\nu_{2}\\leq\\cdots\\leq\\nu_{n}$ . The assumption that $\\begin{array}{r}{\\operatorname*{lim}_{\\tau\\rightarrow\\infty}\\ell_{i,\\tau}}\\end{array}$ exists implies that as $\\tau$ grows, the overall gap between $\\ell_{i,\\tau}$ and $\\nu_{i}$ decreases. Let $\\sigma_{t}=f(t)$ be the model uncertainty at epoch $t$ . We then introduce a random variable that characterizes the approximation error of $\\ell_{i,t}$ relative to $\\nu_{i}$ , modeling it as a distribution that incorporates $t$ as a parameter: ", "page_idx": 6}, {"type": "equation", "text": "$$\nX_{t}=\\ell_{i,t}-\\nu_{i},X_{t}\\sim\\mathcal{N}(0,\\sigma_{t}^{2})\\quad\\forall t.\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "By applying Chebyshev inequality, we have ", "page_idx": 6}, {"type": "equation", "text": "$$\n\\operatorname*{Pr}\\left\\{|\\ell_{i,t}-\\nu_{i}|>\\frac{\\nu_{i}-\\nu_{1}}{2}\\right\\}\\leq\\frac{4\\sigma_{t}^{2}}{(\\nu_{i}-\\nu_{1})^{2}}=\\frac{4f(t)^{2}}{(\\nu_{i}-\\nu_{1})^{2}}\\,\\,\\,\\,i=2,\\cdots\\,,n.\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "Let $\\boldsymbol{\\mathcal{A}}$ denote the event $\\ell_{i,t}>\\ell_{1,t}$ , then by Equation 3.9 ", "page_idx": 6}, {"type": "equation", "text": "$$\n\\operatorname*{Pr}(A)=\\operatorname*{Pr}\\Big\\{\\big(\\ell_{i,t}-\\nu_{i}\\big)+\\big(\\nu_{1}-\\ell_{1,t}\\big)+2\\cdot\\big(\\frac{\\nu_{i}-\\nu_{1}}{2}\\big)>0\\Big\\}\\geq1-\\Big(\\frac{4f(t)^{2}}{(\\nu_{i}-\\nu_{1})^{2}}\\Big)^{2}.\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "Equation 3.10 tells us that $\\ell_{i,t}>\\ell_{1,t}$ has a high probability with respect to $t$ if $f(t)\\in O(t^{-1/4})$ (see Lemma in Appendix C). That is, comparing the intermediate values at a certain time $t$ is likely to establish an order similar to the order of the final values of $\\nu_{i}$ and $\\nu_{1}$ . ", "page_idx": 6}, {"type": "text", "text": "The following theorem is stated using the abovementioned quantities with proofs in Appendix C.1. ", "page_idx": 6}, {"type": "text", "text": "Theorem 1. Let n be the number of total candidates, and $\\nu_{i}=\\operatorname*{lim}_{\\tau\\to\\infty}\\ell_{i,\\tau}$ . For a given $c>0$ , there exists a $T>0$ s.t. $\\prod_{i=2}^{n}(1-\\big(\\frac{4f(T)^{2}}{(\\nu_{i}\\!-\\!\\nu_{1})^{2}}\\big)^{2}\\big)>1-c$ . If the round budget $R>T\\cdot n_{*}$ , then the best candidate is returned with probability $\\begin{array}{r}{P>(1-\\lfloor\\frac{B}{R}\\rfloor c)(1-c),}\\end{array}$ , where $B$ is the total budget. ", "page_idx": 6}, {"type": "text", "text": "In comparison, the bound in the UQ-oblivious approach is as follows: ", "page_idx": 6}, {"type": "text", "text": "Theorem 2. Let $\\delta>0,\\nu_{i}=\\operatorname*{lim}_{\\tau\\rightarrow\\infty}\\ell_{i,\\tau}$ and assume $\\nu_{1}\\leq\\nu_{2}\\leq\\cdots\\leq\\nu_{n}$ . Let $\\gamma^{-1}(\\epsilon,\\delta)=\\operatorname*{min}\\{t\\in$ $\\mathbb{N}:\\frac{f(t)}{\\epsilon}\\leq\\delta^{\\frac{1}{4}}\\}$ , and ", "page_idx": 6}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{z_{o b}=2\\lceil\\log_{2}(n)\\rceil\\underset{i=2,\\ldots,n}{\\operatorname*{max}}i\\left(1+\\gamma^{-1}\\big(\\frac{\\nu_{i}-\\nu_{1}}{2},\\delta\\big)\\right)}\\\\ &{\\quad\\le2\\lceil\\log_{2}(n)\\rceil(n+\\displaystyle\\sum_{i=2,\\ldots,n}\\gamma^{-1}\\big(\\frac{\\nu_{i}-\\nu_{1}}{2},\\delta\\big)).}\\end{array}\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "If the UQ-oblivious early stopping method is run with any budget $B_{o b}>z_{o b}$ then the best candidate is returned with probability $P_{o b}>1-n\\delta$ . ", "page_idx": 6}, {"type": "text", "text": "Example 3. Consider $\\begin{array}{r l r}{f(t)}&{{}=}&{\\frac{1}{t}}\\end{array}$ . According to Theorem 2, if $B_{o b}\\;\\;>\\;\\;2\\lceil\\log_{2}(n)\\rceil(n\\;+$ $\\begin{array}{r}{\\sum_{i=1,\\dots,n}\\gamma^{-1}\\big(\\frac{\\nu_{i}-\\nu_{1}}{2},\\delta\\big)\\big)}\\end{array}$ , the UQ-oblivious method can return the best candidate with probability over $1-n\\delta$ . But if $\\begin{array}{r}{B_{U Q}\\simeq\\gamma_{.}^{-1}(\\frac{\\nu_{2}-\\nu_{1}}{2},\\delta)\\cdot n_{..}^{\\;1}}\\end{array}$ , the UQ method can return the best candidate with probability over $1-n\\delta$ . As shown in Appendix C.2, Theorems $^{\\,l}$ and 2 together show that the UQ approach guarantees the same probability of identifying the optimal candidate as the UQ-oblivious counterpart with a smaller budget lowerbound $B$ (see Corollary $^{6}$ ). ", "page_idx": 6}, {"type": "text", "text": "3.5 UQ-Guided HPO Family ", "text_level": 1, "page_idx": 7}, {"type": "text", "text": "The $U\\boldsymbol{Q}$ -guided scheme is a general approach to enhancing HPO with uncertainty awareness. We next explain how it is integrated into several existing HPO methods to transform them into UQ-guided ones, yielding a UQ-guided HPO family. In the following, we use the suffix \u201cplus $(+)\"$ to indicate the UQ-guided HPO methods. ", "page_idx": 7}, {"type": "text", "text": "Successive Halving plus $\\left(\\mathbf{S}\\mathbf{H}+\\right)$ is derived from the early stop-based HPO design Successive Halving (SH) [19]. Algorithms 1 and 2 in Appendix A.3 show the pseudo-code. Given total budget $B$ and round budget $R$ and an initial $K$ , $\\mathrm{SH+}$ first trains $K$ candidates each with the initial $\\begin{array}{r}{\\overline{{b}}=\\left.\\lfloor\\frac{R}{K}\\right\\rfloor}\\end{array}$ units of budget, and ranks them by the evaluation performance. Then $\\mathrm{SH+}$ updates $K$ based on Section 3.3.2 and keeps the top $K$ configurations according to the UQ-guided scheme (OracleModel in Algorithms 1 and 2), and continues the process until the budget runs out. ", "page_idx": 7}, {"type": "text", "text": "Hyperband plus $\\mathbf{(HB+)}$ originates from the popular HPO design Hyperband (HB). HB is an HPO method trying to better balance exploration and exploitation than SH does [25] by adding an outer loop for grid search of the value of $K$ . $\\mathrm{HB+}$ simply extends HB by using $\\mathrm{SH+}$ rather than SH as its inner loop, changing the target of the grid search to the initial value of $K$ . ", "page_idx": 7}, {"type": "text", "text": "Bayesian Optimization and Hyperband plus $({\\bf{B O H B+}})$ ) is developed from BOHB [11]. BOHB is similar to HB except that it replaces the random sampling from the uniform distribution with BO-based sampling. $\\mathrm{{BOHB+}}$ makes the corresponding changes from $\\mathrm{HB+}$ by adopting BO-based sampling for its outer loop. ", "page_idx": 7}, {"type": "text", "text": "Sub-sampling plus $(\\mathbf{S}\\mathbf{S}+)$ is derived from the Sub-sampling (SS) algorithm [15]. It showcases the applicability of the UQ-guided scheme to non-early stop\u2013based methods. Similar to other methods, in each round, SS also chooses candidates for further training based on its assessment of the potential of those candidates. But unlike the other methods, SS does not discard any candidates, but keeps all in play throughout the entire HPO process. In each round, the candidates it chooses are those that show smaller validation loss than the most trained candidate shows. If there is none, it trains only the most trained candidate in that round. $\\mathrm{SS+}$ integrates the UQ-guided scheme into the candidate selection process of SS. When $s s+$ compares a candidate $(c_{i})$ against the most trained candidate $\\left(c_{m}\\right)$ , rather than checking their validation losses, it uses the UQ-guided scheme to compute the probability for the convergence loss of $c_{i}$ to be smaller than that of $c_{m}$ and checks whether the probability is over a threshold $\\tau$ (0.9 in our experiments), that is, $\\operatorname*{Pr}(\\ell(y,M_{\\gamma_{c_{m}}}^{*}(\\mathbf{x}))\\ge\\ell(y,M_{\\gamma_{c_{i}}}^{*}(\\mathbf{x})\\bar{)})\\ge\\tau$ . ", "page_idx": 7}, {"type": "text", "text": "4 Experiments ", "text_level": 1, "page_idx": 7}, {"type": "text", "text": "We conduct a series of experiments on the four UQ-guided HPO methods to validate the efficacy of the UQ-guided scheme for HPO. ", "page_idx": 7}, {"type": "text", "text": "4.1 Experimental Setup ", "text_level": 1, "page_idx": 7}, {"type": "text", "text": "Methodology. To check the benefits of the UQ-guided scheme for HPO, we apply the proposed UQ-guided HPO family to different HPO benchmarks, including NAS-BENCH-201 and LCBench, each for 30 repetitions, to measure the performance for different hyperparameter optimization tasks, and compared those with their original UQ-oblivious versions. ", "page_idx": 7}, {"type": "text", "text": "Platform. Our experiments are conducted on a platform equipped with an Intel i9-9900k CPU and an NVIDIA GEFORCE RTX 2080 TI GPU. The CPU has 8 cores, each of which can support 2 threads. The GPU has 4,352 cores of Turing architecture with a computing capability of 7.5. The GPU can achieve a maximum memory bandwidth of 616 GB/s, 0.4 tera floating-point operations per second (TFLOPS) on double-precision, and 13 TFLOPS on single-precision. ", "page_idx": 7}, {"type": "text", "text": "Workloads. We evaluate the UQ-guided methods on two real-world benchmarks. Nas-Bench-201 [9] (CC-BY 4.0) encompasses three heavyweight neural architecture search tasks (NAS) on CIFAR-10, CIFAR-100, and ImageNet-16-12 (CC-BY 4.0) datasets. In addition, we investigate the performance of optimizing traditional ML pipelines, hyperparameters, and neural architecture in LCBench [42]. For example, we optimized 7 parameters for the Fashion-MNIST dataset [7], where the resource type is determined by the number of iterations. Additional information regarding these benchmarks can be found in Appendix F. In this context, one unit of budget equates to a single training epoch, and by default, the total HPO budget $(B)$ allocated for each method is 4 hours. ", "page_idx": 7}, {"type": "text", "text": "4.2 Experimental Results ", "text_level": 1, "page_idx": 7}, {"type": "text", "text": "Figure 3 illustrates the results of NAS-BENCH-201 trained on ImageNet-16-120. It shows the results of four UQ-guided methods compared to their original ones. For each comparison, we show three metrics, namely top-1 rank on different trials, top-1 rank on different fractions of budgets, and regret on different fractions of budgets. The fraction of budgets denotes the portion of the budget that we allocate for that particular experiment compared to the standard full budget. Top-1 rank refers to the real ranking of the candidate ultimately chosen by the method. Regret $(\\%)$ refers to the accuracy difference between the returned candidate and the real best candidate. In Figure 3, the average results of 30 repetitions are reported. For the right two columns, we also report the uncertainty bands, defined as the interval between the 30th and 70th percentiles. The beneftis of the UQ-guided scheme are obvious, both for individual trials and across different fractions of budgets. It brings a $21.55\\%$ regret reduction. Similar results are observed on other benchmarks (LCBench results shown in Appendix G). ", "page_idx": 7}, {"type": "image", "img_path": "k9uZfaeerK/tmp/28693b3fcc99df34a2d4f17d2e654f00ded729440ece9f768d89cbb899008580.jpg", "img_caption": ["Figure 3: Experimental results of UQ-oblivious HPO methods and their UQ-guided enhancements on NAS-BENCH-2.0. "], "img_footnote": [], "page_idx": 8}, {"type": "text", "text": "", "page_idx": 8}, {"type": "text", "text": "Table 1 provides the fraction of the total exploration time needed for the UQ-guided methods to achieve comparable model accuracy as the original methods do. The UQ-guided methods need much less time than their counterparts to obtain a similar performance. For instance, $\\mathrm{SH+}$ achieves the same average regret of $5\\%$ on NAS with only half of the budgets required by SH. These results indicate that the UQ technique can conduct HPO efficiently and effectively. ", "page_idx": 8}, {"type": "text", "text": "Table 1: Fraction of time $(\\%)$ required for the UQ-guided methods to achieve comparable model performance as the original HPO methods do. ", "page_idx": 8}, {"type": "table", "img_path": "k9uZfaeerK/tmp/20b06f2b3c9e1e38de99c549da016eb2dbc175e89aa665ec7d726c7538c5eebe.jpg", "table_caption": [], "table_footnote": [], "page_idx": 8}, {"type": "text", "text": "Our paper\u2019s experiments concentrate on DNN because efficient HPO is crucial for the time-consuming nature of DNN training. We also use the ridge regression in Section H as a demonstration to show the ", "page_idx": 8}, {"type": "text", "text": "5 Conclusion ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "This paper points out the importance of systematic treatment to the uncertainty in model trainings for HPO. It introduces a novel scheme named UQ-guided scheme, which offers a general way to enhance HPO methods for DNNs with uncertainty awareness. Experiments demonstrate that the UQ-guided scheme can be easily integrated into various HPO methods. The enhanced methods achieve $21{-}55\\%$ reduction of regret over their original versions, and require only $30\u201375\\%$ time to identify a candidate with a matching performance as the original methods do. The paper in addition provides a theoretical analysis of the effects of the UQ-guided scheme for HPO. ", "page_idx": 9}, {"type": "text", "text": "The key characteristic of the UQ method is the necessity to rank multiple learners during the HPO process. Gradient-based HPO methods [30], for instance, may not benefit from our UQ-guided scheme because of their sequential properties. One limitation of this paper is that it is mostly suitable for iterative learners, and needs adaptations for other learners: To go beyond, it could be, for instance, applied to the model selection work in previous studies [31] that use training dataset size as the budget dimension. In this case, the learner does not need to be iterative; the selection is based on the validation loss history trained with incremental dataset sizes. The UQ component can still guide the configuration selection and budget allocation in the HPO process. ", "page_idx": 9}, {"type": "text", "text": "Overall, this study concludes that UQ is important for HPO to consider, simple on-the-fly UQ goes a long way for HPO, and the UQ-guided scheme can serve as a general effective scheme for enhancing HPO designs. ", "page_idx": 9}, {"type": "text", "text": "References ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "[1] Moloud Abdar, Farhad Pourpanah, Sadiq Hussain, Dana Rezazadegan, Li Liu, Mohammad Ghavamzadeh, Paul Fieguth, Xiaochun Cao, Abbas Khosravi, U Rajendra Acharya, et al. A review of uncertainty quantification in deep learning: Techniques, applications and challenges. Information fusion, 76:243\u2013297, 2021.   \n[2] Bowen Baker, Otkrist Gupta, Ramesh Raskar, and Nikhil Naik. Accelerating neural architecture search using performance prediction. arXiv preprint arXiv:1705.10823, 2017.   \n[3] Hadrien Bertrand, Roberto Ardon, Matthieu Perrot, and Isabelle Bloch. Hyperparameter optimization of deep neural networks: Combining hyperband with bayesian model selection. In Conf\u00e9rence sur l\u2019Apprentissage Automatique, 2017.   \n[4] Bernd Bischl, Martin Binder, Michel Lang, Tobias Pielok, Jakob Richter, Stefan Coors, Janek Thomas, Theresa Ullmann, Marc Becker, Anne-Laure Boulesteix, et al. Hyperparameter optimization: Foundations, algorithms, best practices, and open challenges. Wiley Interdisciplinary Reviews: Data Mining and Knowledge Discovery, 13(2):e1484, 2023.   \n[5] Charles Blundell, Julien Cornebise, Koray Kavukcuoglu, and Daan Wierstra. Weight uncertainty in neural network. In International conference on machine learning, pages 1613\u20131622. PMLR, 2015.   \n[6] Danruo Deng, Guangyong Chen, Yang Yu, Furui Liu, and Pheng-Ann Heng. Uncertainty estimation by fisher information-based evidential deep learning. In International conference on machine learning. PMLR, 2023.   \n[7] Li Deng. The mnist database of handwritten digit images for machine learning research [best of the web]. IEEE signal processing magazine, 29(6):141\u2013142, 2012.   \n[8] Tobias Domhan, Jost Tobias Springenberg, and Frank Hutter. Speeding up automatic hyperparameter optimization of deep neural networks by extrapolation of learning curves. In Twenty-fourth international joint conference on artificial intelligence, 2015.   \n[9] Xuanyi Dong and Yi Yang. Nas-bench-201: Extending the scope of reproducible neural architecture search. arXiv preprint arXiv:2001.00326, 2020.   \n[10] Vincent Dumont, Casey Garner, Anuradha Trivedi, Chelsea Jones, Vidya Ganapati, Juliane Mueller, Talita Perciano, Mariam Kiran, and Marc Day. Hyppo: A surrogate-based multi-level parallelism tool for hyperparameter optimization. In 2021 IEEE/ACM Workshop on Machine Learning in High Performance Computing Environments (MLHPC), pages 81\u201393. IEEE, 2021.   \n[11] Stefan Falkner, Aaron Klein, and Frank Hutter. BOHB: Robust and efficient hyperparameter optimization at scale. In Jennifer Dy and Andreas Krause, editors, Proceedings of the 35th International Conference on Machine Learning, volume 80 of Proceedings of Machine Learning Research, pages 1437\u20131446. PMLR, 10\u201315 Jul 2018.   \n[12] Yarin Gal and Zoubin Ghahramani. Dropout as a bayesian approximation: Representing model uncertainty in deep learning. In Maria Florina Balcan and Kilian Q. Weinberger, editors, Proceedings of The 33rd International Conference on Machine Learning, volume 48 of Proceedings of Machine Learning Research, pages 1050\u20131059, New York, New York, USA, 20\u201322 Jun 2016. PMLR.   \n[13] Pieter Gijsbers, Erin LeDell, Janek Thomas, S\u00e9bastien Poirier, Bernd Bischl, and Joaquin Vanschoren. An open source automl benchmark. arXiv preprint arXiv:1907.00909, 2019.   \n[14] Yi-Qi Hu, Yang Yu, Wei-Wei Tu, Qiang Yang, Yuqiang Chen, and Wenyuan Dai. Multi-fidelity automatic hyper-parameter tuning via transfer series expansion. In Proceedings of the AAAI Conference on Artificial Intelligence, volume 33, pages 3846\u20133853, 2019.   \n[15] Yimin Huang, Yujun Li, Hanrong Ye, Zhenguo Li, and Zhihua Zhang. Improving model training with multi-fidelity hyperparameter evaluation. In D. Marculescu, Y. Chi, and C. Wu, editors, Proceedings of Machine Learning and Systems, volume 4, pages 485\u2013502, 2022.   \n[16] Eyke H\u00fcllermeier and Willem Waegeman. Aleatoric and epistemic uncertainty in machine learning: An introduction to concepts and methods. Machine Learning, 110:457\u2013506, 2021.   \n[17] Frank Hutter, Holger H. Hoos, and Kevin Leyton-Brown. Sequential model-based optimization for general algorithm configuration. In Carlos A. Coello Coello, editor, Learning and Intelligent Optimization, pages 507\u2013523, Berlin, Heidelberg, 2011. Springer Berlin Heidelberg.   \n[18] Frank Hutter, Lars Kotthoff, and Joaquin Vanschoren. Automated machine learning: methods, systems, challenges. Springer Nature, 2019.   \n[19] Kevin Jamieson and Ameet Talwalkar. Non-stochastic best arm identification and hyperparameter optimization. In Arthur Gretton and Christian C. Robert, editors, Proceedings of the 19th International Conference on Artificial Intelligence and Statistics, volume 51 of Proceedings of Machine Learning Research, pages 240\u2013248, Cadiz, Spain, 09\u201311 May 2016. PMLR.   \n[20] Jie Jiang, Jiawei Jiang, Bin Cui, and Ce Zhang. Tencentboost: A gradient boosting tree system with parameter server. In 2017 IEEE 33rd International Conference on Data Engineering (ICDE), pages 281\u2013284. IEEE, 2017.   \n[21] Kirthevasan Kandasamy, Gautam Dasarathy, Jeff Schneider, and Barnab\u00e1s P\u00f3czos. Multi-fidelity bayesian optimisation with continuous approximations. In International Conference on Machine Learning, pages 1799\u20131808. PMLR, 2017.   \n[22] Aaron Klein, Stefan Falkner, Simon Bartels, Philipp Hennig, and Frank Hutter. Fast bayesian optimization of machine learning hyperparameters on large datasets. In Artificial intelligence and statistics, pages 528\u2013536. PMLR, 2017.   \n[23] Aaron Klein, Stefan Falkner, Jost Tobias Springenberg, and Frank Hutter. Learning curve prediction with bayesian neural networks. In International Conference on Learning Representations, 2016.   \n[24] Balaji Lakshminarayanan, Alexander Pritzel, and Charles Blundell. Simple and scalable predictive uncertainty estimation using deep ensembles. Advances in neural information processing systems, 30, 2017.   \n[25] Lisha Li, Kevin Jamieson, Giulia DeSalvo, Afshin Rostamizadeh, and Ameet Talwalkar. Hyperband: A novel bandit-based approach to hyperparameter optimization. J. Mach. Learn. Res., 18(1):6765\u20136816, jan 2017.   \n[26] Yang Li, Yu Shen, Jiawei Jiang, Jinyang Gao, Ce Zhang, and Bin Cui. Mfes-hb: Efficient hyperband with multi-fidelity quality measurements. In Proceedings of the AAAI Conference on Artificial Intelligence, volume 35, pages 8491\u20138500, 2021.   \n[27] M. Lichman. Uci machine learning repository, 2013. Accessed: [Insert access date here].   \n[28] Siyan Liu, Pei Zhang, Dan Lu, and Guannan Zhang. PI3NN: Out-of-distribution-aware prediction intervals from three neural networks. In International Conference on Learning Representations, 2022.   \n[29] Jingwei Ma, Jiahui Wen, Mingyang Zhong, Weitong Chen, and Xue Li. Mmm: multi-source multi-net micro-video recommendation with clustered hidden item representation learning. Data Science and Engineering, 4:240\u2013253, 2019.   \n[30] Paul Micaelli and Amos J Storkey. Gradient-based hyperparameter optimization over long horizons. Advances in Neural Information Processing Systems, 34:10798\u201310809, 2021.   \n[31] Felix Mohr and Jan N van Rijn. Towards model selection using learning curve cross-validation. In 8th ICML Workshop on automated machine learning (AutoML), 2021.   \n[32] Felix Mohr and Jan N van Rijn. Fast and informative model selection using learning curve cross-validation. IEEE Transactions on Pattern Analysis and Machine Intelligence, 2023.   \n[33] Alejandro Morales-Hern\u00e1ndez, Inneke Van Nieuwenhuyse, and Gonzalo N\u00e1poles. Multi-objective hyperparameter optimization with performance uncertainty. Communications in Computer and Information Science, 1684:37\u201346, 2022.   \n[34] Jasper Snoek, Hugo Larochelle, and Ryan P Adams. Practical bayesian optimization of machine learning algorithms. In F. Pereira, C.J. Burges, L. Bottou, and K.Q. Weinberger, editors, Advances in Neural Information Processing Systems, volume 25. Curran Associates, Inc., 2012.   \n[35] Kevin Swersky, Jasper Snoek, and Ryan P Adams. Multi-task bayesian optimization. Advances in neural information processing systems, 26, 2013.   \n[36] Shion Takeno, Hitoshi Fukuoka, Yuhki Tsukada, Toshiyuki Koyama, Motoki Shiga, Ichiro Takeuchi, and Masayuki Karasuyama. Multi-fidelity bayesian optimization with max-value entropy search and its parallelization. In International Conference on Machine Learning, pages 9334\u20139345. PMLR, 2020.   \n[37] Joaquin Vanschoren, Jan N Van Rijn, Bernd Bischl, and Luis Torgo. Openml: networked science in machine learning. ACM SIGKDD Explorations Newsletter, 15(2):49\u201360, 2014.   \n[38] Jiazhuo Wang, Jason Xu, and Xuejun Wang. Combination of hyperband and bayesian optimization for hyperparameter optimization in deep learning. arXiv preprint arXiv:1801.01596, 2018.   \n[39] Shiwen Wu, Yuanxing Zhang, Chengliang Gao, Kaigui Bian, and Bin Cui. Garg: anonymous recommendation of point-of-interest in mobile networks by graph convolution network. Data Science and Engineering, 5:433\u2013447, 2020.   \n[40] Quanming Yao, Mengshuo Wang, Yuqiang Chen, Wenyuan Dai, Yu-Feng Li, Wei-Wei Tu, Qiang Yang, and Yang Yu. Taking human out of learning applications: A survey on automated machine learning. arXiv preprint arXiv:1810.13306, 2018.   \n[41] Wentao Zhang, Jiawei Jiang, Yingxia Shao, and Bin Cui. Snapshot boosting: a fast ensemble framework for deep neural networks. Science China Information Sciences, 63:1\u201312, 2020.   \n[42] Lucas Zimmer, Marius Lindauer, and Frank Hutter. Auto-pytorch: Multi-fidelity metalearning for efficient and robust autodl. IEEE Transactions on Pattern Analysis and Machine Intelligence, 43(9):3079\u20133090, 2021. ", "page_idx": 9}, {"type": "text", "text": "", "page_idx": 10}, {"type": "text", "text": "", "page_idx": 11}, {"type": "text", "text": "A Method Details ", "text_level": 1, "page_idx": 12}, {"type": "text", "text": "A.1 Formulation of Confidence Curve ", "text_level": 1, "page_idx": 12}, {"type": "text", "text": "The following contents detail how to compute the confidence curve $\\mathcal{C}(P_{1},P_{2},\\cdot\\cdot\\cdot,P_{n})$ based on current validation loss and quantified uncertainty of the $n$ candidates. ", "page_idx": 12}, {"type": "text", "text": "Let $Y$ be the random variable denoting the negation of the lowest converged validation loss: ", "page_idx": 12}, {"type": "equation", "text": "$$\nY=\\operatorname*{max}(-\\ell(\\mathbf{y},M_{\\gamma_{1}}^{*}(\\mathbf{X})),-\\ell(\\mathbf{y},M_{\\gamma_{2}}^{*}(\\mathbf{X})),\\cdot\\cdot\\cdot,-\\ell(\\mathbf{y},M_{\\gamma_{n}}^{*}(\\mathbf{X}))).\n$$", "text_format": "latex", "page_idx": 12}, {"type": "text", "text": "Since $\\ell(\\mathbf{y},M_{\\gamma_{i}}^{*}(\\mathbf{X}))\\sim\\mathcal{N}(\\mu_{i},\\sigma_{i}^{2})$ , the cumulative distribution function (CDF) of $Y$ , $F_{Y}(y)$ , is ", "page_idx": 12}, {"type": "equation", "text": "$$\n\\begin{array}{l}{{^{\\ast}\\!Y}(y)=\\operatorname*{Pr}(Y\\leq y)=\\operatorname*{Pr}(-\\ell(\\mathbf{y},M_{\\gamma_{1}}^{\\ast}(\\mathbf{X}))\\leq y,-\\ell(\\mathbf{y},M_{\\gamma_{2}}^{\\ast}(\\mathbf{X}))\\leq y,\\cdots,-\\ell(\\mathbf{y},M_{\\gamma_{n}}^{\\ast}(\\mathbf{X}))\\leq y)}\\\\ {\\quad\\quad=\\displaystyle\\prod_{i=1}^{n}\\Phi(\\frac{y+\\mu_{i}}{\\sigma})=\\exp(\\displaystyle\\sum_{i=1}^{n}\\ln\\Phi(\\frac{y+\\mu_{i}}{\\sigma})).}\\end{array}\n$$", "text_format": "latex", "page_idx": 12}, {"type": "text", "text": "Accordingly, the probability density function (PDF) of $Y,\\,f_{Y}(y)$ , is ", "page_idx": 12}, {"type": "equation", "text": "$$\nf_{Y}(y)={\\frac{d F_{Y}(y)}{d y}}={\\frac{1}{\\sigma}}\\sum_{i=1}^{n}{\\frac{\\phi\\big({\\frac{y+\\mu_{i}}{\\sigma}}\\big)}{\\Phi\\big({\\frac{y+\\mu_{i}}{\\sigma}}\\big)}}\\cdot\\prod_{i=1}^{n}\\Phi\\big({\\frac{y+\\mu_{i}}{\\sigma}}\\big).\n$$", "text_format": "latex", "page_idx": 12}, {"type": "text", "text": "Now we can construct the confidence curve by calculating each $P_{k}$ $(k\\in[n])$ . For $k=m$ , $P_{k}$ can be expressed as ", "page_idx": 12}, {"type": "equation", "text": "$$\n\\mathsf{\\xi}_{m}^{>}=\\operatorname*{Pr}(\\operatorname*{min}(\\ell(\\mathbf{y},M_{\\gamma_{1}}^{*}(\\mathbf{X})),\\cdots,\\ell(\\mathbf{y},M_{\\gamma_{m}}^{*}(\\mathbf{X})))\\leq\\operatorname*{min}(\\ell(\\mathbf{y},M_{\\gamma_{m+1}}^{*}(\\mathbf{X})),\\cdots,\\ell(\\mathbf{y},M_{\\gamma_{n}}^{*}(\\mathbf{X})))).\n$$", "text_format": "latex", "page_idx": 12}, {"type": "text", "text": "Let $\\ell(\\mathbf{y},M_{\\gamma_{1}}^{*}(\\mathbf{X})),\\cdot\\cdot\\cdot\\mathbf{\\xi},\\ell(\\mathbf{y},M_{\\gamma_{n}}^{*}(\\mathbf{X}))$ be mutually independent, thus ", "page_idx": 12}, {"type": "equation", "text": "$$\n\\begin{array}{l l}{{P_{m}=\\displaystyle\\int_{-\\infty}^{\\infty}f_{Y}(y)\\operatorname*{Pr}(-\\mathcal{N}(\\mu_{m+1},\\sigma_{m+1})\\leq y,\\cdots,-\\mathcal{N}(\\mu_{n},\\sigma_{n})\\leq y)d y}}\\\\ {{\\displaystyle~~~~=\\int_{-\\infty}^{\\infty}f_{Y}(y)\\Phi(\\frac{y+\\mu_{m+1}}{\\sigma})\\times\\cdots\\times\\Phi(\\frac{y+\\mu_{n}}{\\sigma})d y}}\\\\ {{\\displaystyle~~~~=\\int_{-\\infty}^{\\infty}\\frac{1}{\\sigma}\\sum_{i=1}^{m}\\frac{\\phi(\\frac{y+\\mu_{i}}{\\sigma})}{\\Phi(\\frac{y+\\mu_{i}}{\\sigma})}\\cdot\\prod_{i=1}^{n}\\Phi(\\frac{y+\\mu_{i}}{\\sigma})d y.}}\\end{array}\n$$", "text_format": "latex", "page_idx": 12}, {"type": "text", "text": "A.2 Computing $\\zeta$ ", "text_level": 1, "page_idx": 12}, {"type": "text", "text": "Equation 3.6 can be calculated by directly subtracting $P_{k_{i}}$ by $P_{k_{i}-1}$ : ", "page_idx": 12}, {"type": "equation", "text": "$$\n\\begin{array}{l l}{\\Delta c_{\\downarrow}=\\int_{-\\infty}^{\\infty}\\frac{1}{\\sigma}\\displaystyle\\sum_{i=1}^{k_{i}}\\frac{\\phi(\\frac{y+\\mu_{i}}{\\sigma})}{\\Phi(\\frac{y+\\mu_{i}}{\\sigma})}\\cdot\\prod_{i=1}^{n}\\Phi(\\frac{y+\\mu_{i}}{\\sigma})d y-\\int_{-\\infty}^{\\infty}\\frac{1}{\\sigma}\\displaystyle\\sum_{i=1}^{k_{i}-1}\\frac{\\phi(\\frac{y+\\mu_{i}}{\\sigma})}{\\Phi(\\frac{y+\\mu_{i}}{\\sigma})}\\cdot\\prod_{i=1}^{n}\\Phi(\\frac{y+\\mu_{i}}{\\sigma})d y}\\\\ {=\\displaystyle\\int_{-\\infty}^{\\infty}\\frac{1}{\\sigma}\\cdot\\frac{\\phi(\\frac{y+\\mu_{k_{i}}}{\\sigma})}{\\Phi(\\frac{y+\\mu_{k_{i}}}{\\sigma})}\\cdot\\prod_{i=1}^{n}\\Phi(\\frac{y+\\mu_{i}}{\\sigma})d y.}\\end{array}\n$$", "text_format": "latex", "page_idx": 12}, {"type": "text", "text": "$\\zeta$ is the coefficient that relates the increase in the number of training epochs to its corresponding effect on confidence. Consider a working round that starts with $k$ candidates. We have approximations at the end of the round for the converged loss $\\ell(y,M_{\\gamma_{i}}^{*}(\\mathbf{x}))\\sim\\mathcal{N}(\\mu_{i},\\sigma^{2})$ for $i\\in[k]$ . Here, $t$ denotes the epochs. Letting each candidate train one extra unit of resource results in lower uncertainty, thus increasing the $f$ score. First compute $f(\\pmb{\\xi},\\tau)$ at epoch $t$ : ", "page_idx": 12}, {"type": "equation", "text": "$$\nf(\\pmb{\\xi},\\tau)_{t}=\\int_{-\\infty}^{\\infty}\\frac{1}{\\sigma}\\phi(\\frac{y+\\mu_{1}}{\\sigma})\\cdot\\prod_{i=2}^{k}\\Phi(\\frac{y+\\mu_{i}}{\\sigma})d y.\n$$", "text_format": "latex", "page_idx": 12}, {"type": "text", "text": "If each configuration is trained with one extra unit of resource (a total of $t+1$ epochs), model uncertainty would be reduced. We use the same $\\mu_{i}$ to approximate the converged validation loss ", "page_idx": 12}, {"type": "text", "text": "for $t+1$ epochs, and use $\\sigma-\\Delta_{t}\\sigma$ as an approximation for model uncertainty. Here $\\Delta_{t}\\sigma$ is the decrease in model uncertainty that is determined through offline profiling with details in Section $\\mathrm{D}$ . This approximation leads us to $f(\\pmb{\\xi},\\tau)$ at epoch $t+1$ as ", "page_idx": 13}, {"type": "equation", "text": "$$\nf(\\pmb{\\xi},\\tau)_{t+1}=\\int_{-\\infty}^{\\infty}\\frac{1}{\\sigma-\\Delta_{t}\\sigma}\\phi(\\frac{y+\\mu_{1}}{\\sigma-\\Delta_{t}\\sigma})\\cdot\\prod_{i=2}^{k}\\Phi(\\frac{y+\\mu_{i}}{\\sigma-\\Delta_{t}\\sigma})d y.\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "Subtracting Equation A.3 by Equation A.2 gives us the result in Equation 3.7: ", "page_idx": 13}, {"type": "equation", "text": "$$\n:=f(\\xi,\\tau)_{t+1}-f(\\xi,\\tau)_{t}=\\int_{-\\infty}^{\\infty}\\frac{1}{\\sigma-\\Delta_{t}\\sigma}\\phi(\\frac{y+\\mu_{1}}{\\sigma-\\Delta_{t}\\sigma})\\cdot\\prod_{i=2}^{k}\\Phi(\\frac{y+\\mu_{i}}{\\sigma-\\Delta_{t}\\sigma})d y-\\int_{-\\infty}^{\\infty}\\frac{1}{\\sigma}\\phi(\\frac{y+\\mu_{1}}{\\sigma})\\cdot\\prod_{i=2}^{k}\\Phi(\\frac{y-\\mu_{i}}{\\sigma-\\Delta_{t}\\sigma})d y.\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "A.3 Pseudo-code for UQ-Guided Hyperparameter Optimization $\\left(\\mathbf{SH+}\\right)$ ", "text_level": 1, "page_idx": 13}, {"type": "text", "text": "Algorithm 1 UQ-Guided Hyperparameter Optimization $\\mathrm{(SH+)}$ ", "text_level": 1, "page_idx": 13}, {"type": "text", "text": "Input: Total budget $B$ , the set of $K$ configurations $\\Gamma=\\{\\gamma_{1},\\gamma_{2},\\cdot\\cdot\\cdot,\\gamma_{K}\\}$ , minimum round budget   \n$R$   \nOutput: The configuration with the best performance   \n$\\textstyle b={\\left\\{{\\frac{R}{K}}\\right\\}}$   \nrepeat for $i=1$ to $K$ do Evaluate $M_{\\gamma_{i}}^{t_{i}}$ with budget $b$ and get $M_{\\gamma_{i}}^{t_{i}+b}$ $t_{i}+=b$ end for Rank according to performance and obtain new $M_{\\gamma_{1}}^{t_{1}}$ , $M_{\\gamma_{2}}^{t_{2}},\\cdot\\cdot\\cdot\\,,M_{\\gamma_{K}}^{t_{K}}$ $\\begin{array}{r}{K=O r a c l e M o d e l(M_{\\gamma_{1}}^{t_{1}},M_{\\gamma_{2}}^{t_{2}},\\cdot\\cdot\\cdot\\,,M_{\\gamma_{K}}^{t_{K}})}\\end{array}$ Keep top $K$ candidates   \nuntil total budget $B$ runs out ", "page_idx": 13}, {"type": "text", "text": "Algorithm 2 OracleModel for determining $K$ candidates into the next round. ", "text_level": 1, "page_idx": 13}, {"type": "text", "text": "Input: $K$ instances of Machine Learning models $M_{\\gamma_{1}}^{t_{1}}$ , $M_{\\gamma_{2}}^{t_{2}},\\cdot\\cdot\\cdot\\,,M_{\\gamma_{K}}^{t_{K}}$   \nOutput: A new $K$ that tells the model how many candidates to keep   \nGet a $\\tau$ from the probabilistic model   \nConstruct the confidence curve C(P1, P2, \u00b7 \u00b7 \u00b7 , PK) based on   \n$\\ell(\\mathbf{y},M_{\\gamma_{1}}^{t_{1}}(\\mathbf{X})),\\ell(\\mathbf{y},M_{\\gamma_{2}}^{t_{2}}(\\mathbf{X})),\\cdot\\cdot\\cdot\\mathbf{\\xi},\\ell(\\mathbf{y},M_{\\gamma_{K}}^{t_{K}}(\\mathbf{X}))$   \nreturn $\\operatorname*{min}\\{k:P_{k}>\\tau\\}$ ", "page_idx": 13}, {"type": "text", "text": "A.4 Pseudo-code for UQ-Guided Hyperparameter Optimization $\\mathbf{(HB+)}$ ", "text_level": 1, "page_idx": 13}, {"type": "text", "text": "Algorithm 3 Hyperband plus $\\mathrm{(HB+)}$ ", "text_level": 1, "page_idx": 13}, {"type": "text", "text": "Input: Total budget $B$ , the set of $K$ configurations $\\Gamma=\\{\\gamma_{1},\\gamma_{2},\\cdot\\cdot\\cdot,\\gamma_{K}\\}$ , maximum budget $R$ ,   \nratio $\\eta$   \nOutput: The configuration with the best performance   \nsmax = \u230alog\u03b7 R\u230b, b =sB   \nfor $s=1$ to $s_{\\mathrm{max}}$ do $\\begin{array}{r}{k=\\lceil\\frac{b\\eta^{s}}{s+1}\\rceil}\\end{array}$ Sample $k$ configurations randomly Call $\\mathrm{SH+}$ with $\\bar{(k,b,\\frac{b}{s})}$   \nend for ", "page_idx": 13}, {"type": "text", "text": "A.5 Pseudo-code for UQ-Guided Hyperparameter Optimization $({\\bf{B O H B+}})$ ) ", "text_level": 1, "page_idx": 13}, {"type": "text", "text": "Input: Total budget $B$ , the set of $K$ configurations $\\Gamma=\\{\\gamma_{1},\\gamma_{2},\\cdot\\cdot\\cdot,\\gamma_{K}\\}$ , maximum budget $R$ ,   \nratio $\\eta$ (default $\\eta=3$ )   \nOutput: The configuration with the best performance   \n$\\begin{array}{r}{\\bar{s}_{\\mathrm{max}}=\\lfloor\\log_{\\eta}R\\rfloor,\\breve{b}=\\frac{B}{s_{\\mathrm{max}}}}\\end{array}$   \nfor $s=1$ to $s_{\\mathrm{max}}$ do $\\begin{array}{r}{k=\\lceil\\frac{b\\eta^{s}}{s+1}\\rceil}\\end{array}$ Sample $k$ configurations using Bayesian optimizer Call $\\mathrm{SH+}$ with $\\bar{(k,b,\\frac{b}{s})}$   \nend for ", "page_idx": 14}, {"type": "text", "text": "A.6 Pseudo-code for UQ-Guided Hyperparameter Optimization $(\\mathbf{S}\\mathbf{S}+)$ ", "text_level": 1, "page_idx": 14}, {"type": "text", "text": "Algorithm 5 Sub-Sampling plus $({\\mathrm{SS}}+)$ ", "text_level": 1, "page_idx": 14}, {"type": "text", "text": "Input: Total budget $B$ , the set of $K$ configurations $\\Gamma=\\{\\gamma_{1},\\gamma_{2},\\cdot\\cdot\\cdot,\\gamma_{K}\\}$ , maximum budget $R$ ,   \nminimum budget $b$ , ratio $\\eta$ (default $\\eta=3$ )   \nOutput: The configuration with the best performance   \n$r=1$ , evaluate all configurations with budget $b$ .   \nfor $r=2$ to $\\lfloor\\log_{\\eta}(R/\\bar{b)}\\rfloor$ do Select $\\gamma_{\\zeta}$ with the most observations. $\\mathcal{T}^{\\prime}=\\{k:c_{k}\\in\\Gamma\\backslash\\gamma_{\\zeta},\\gamma_{k}\\preceq\\gamma_{\\zeta}\\wedge$ pass UQ check} if $\\mathcal{T}^{\\prime}==\\emptyset$ then Evaluate $\\gamma_{\\zeta}$ with budget $\\eta^{r}b$ . else Evaluate $\\gamma_{k}$ with budget $\\eta^{r}b$ for each $k\\in\\mathcal{T}^{\\prime}$ . end if   \nend for ", "page_idx": 14}, {"type": "text", "text": "B More Theoretical Analysis ", "text_level": 1, "page_idx": 14}, {"type": "text", "text": "We have been concerned with identifying the best candidate, while in practice, it is often sufficient to consider a situation where the difference between the result of candidate $i_{\\epsilon}$ $(\\nu_{i_{\\epsilon}})$ and the result of the best candidate $\\left(\\nu_{1}\\right)$ is less than or equal to a small value $\\epsilon$ . We obtain the following theorem with proofs in Appendix C.3. ", "page_idx": 14}, {"type": "text", "text": "Theorem 4. For a budget $B>R$ and a set of n candidates, let $\\hat{i}$ be the output of the UQ-guided approach. Then ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\mathbb{E}(\\nu_{\\hat{i}}-\\nu_{1})\\leq\\frac{2\\lfloor\\frac{B}{R}\\rfloor\\sqrt{2}f(R)}{\\sqrt{\\pi}}.\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "In comparison, $\\hat{i}_{D}$ , the output of the UQ-oblivious counterpart, satisfies ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\mathbb{E}(\\nu_{\\hat{i}_{D}}-\\nu_{1})\\leq\\frac{2\\lceil\\log_{2}(n)\\rceil\\sqrt{2}f(\\lfloor\\frac{B}{n\\lceil\\log_{2}(n)\\rceil}\\rfloor)}{\\sqrt{\\pi}}.\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "Example 5. Consider $\\textstyle f(t)={\\frac{1}{t}}$ . Substitution of $f(t)$ in Theorem $^{4}$ can clearly show a smaller upperbound of the UQ-guided approach than that of the UQ-oblivious counterpart (see Appendix C.3 for details). ", "page_idx": 14}, {"type": "text", "text": "The theorems provide some insights into the theoretical benefits of the UQ-guided scheme. But it is worth noting that neither this bound comparison nor the budget bound comparison in Example 3 is sufficient to prove that the UQ-guided approach definitely would outperform the UQ-oblivious approach, a reason for the empirical comparisons in Section 4. ", "page_idx": 14}, {"type": "text", "text": "C Proofs ", "text_level": 1, "page_idx": 15}, {"type": "text", "text": "In this section, we provide proofs for the theorems presented in Section 3.4. At the end of the proof, we let $\\textstyle f(t)={\\frac{1}{t}}$ and obtained the results in Example 3 and Example 5. ", "page_idx": 15}, {"type": "text", "text": "The Lemma stated next will prove to be useful. ", "page_idx": 15}, {"type": "text", "text": "Lemma 1. For $i>1$ , $i f\\operatorname*{min}\\{t_{1},t_{i}\\}>t_{i}$ , then we have a high probability that $\\ell_{i,t_{i}}\\,>\\,\\ell_{1,t_{1}}$ with respect to t if $f(t)\\in O(t^{-1/4})$ . ", "page_idx": 15}, {"type": "text", "text": "Proof. In Section 3.4, we come to the conclusion that ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\operatorname*{Pr}(\\ell_{i,t}>\\ell_{1,t})\\geq1-(\\frac{4f(t)^{2}}{(\\nu_{i}-\\nu_{1})^{2}})^{2}=1-(\\frac{2}{\\nu_{i}-\\nu_{1}})^{4}\\cdot f(t)^{4}>1-O\\bigg(\\frac{1}{t}\\bigg).\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "This shows that the event $\\ell_{i,t}>\\ell_{1,t}$ happens with high probability with respect to $t$ . ", "page_idx": 15}, {"type": "text", "text": "Now consider a more general setting, where each $\\ell_{i}$ has its own $t_{i}$ : ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\operatorname*{Pr}(|\\ell_{i,t_{i}}-\\nu_{i}|>\\frac{\\nu_{i}-\\nu_{1}}{2})\\leq\\frac{4f(t_{i})^{2}}{(\\nu_{i}-\\nu_{1})^{2}}\\ \\overset{\\cdot}{=}1,\\cdots\\,,n.\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "Comparing $\\ell_{i,t_{i}}$ and $\\ell_{1,t_{1}}$ for a particular $i\\in[n]$ gives us the following: ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\mathrm{v}_{\\Upsilon}(\\ell_{i,t_{i}}>\\ell_{1,t_{1}})=\\mathrm{Pr}((\\ell_{i,t_{i}}-\\nu_{i})+(\\nu_{1}-\\ell_{1,t_{1}})+2\\cdot\\frac{\\nu_{i}-\\nu_{1}}{2}>0)\\geq1-\\frac{4f(t_{1})^{2}}{(\\nu_{i}-\\nu_{1})^{2}}\\cdot\\frac{4f(t_{i})^{2}}{(\\nu_{i}-\\nu_{1})^{2}}.\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "Since $t_{1}>t$ and $t_{i}>t$ , ", "page_idx": 15}, {"type": "equation", "text": "$$\n(C.1)>1-O\\!\\left({\\frac{1}{t}}\\right)\\!.\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "C.1 Proof of Theorem 1 ", "text_level": 1, "page_idx": 15}, {"type": "text", "text": "Proof. Let $S_{i}$ be the set of candidates the UQ scheme evaluates at the beginning of the $i$ -th round.   \nWe assume that the $n$ infinitely long loss sequences $[\\ell_{i,t}]$ with limits $\\{\\nu_{i}\\}_{i=1}^{n}$ . ", "page_idx": 15}, {"type": "text", "text": "We compute the probability that the algorithm includes the best candidate in the last round, namely, $1\\in S_{\\lfloor\\frac{B}{R}\\rfloor}$ , and the probability that the UQ scheme returns the best candidate in $\\begin{array}{r}{S_{\\lfloor\\frac{B}{R}\\rfloor}}\\end{array}$ . ", "page_idx": 15}, {"type": "text", "text": "Let $r_{k}$ be the round budget for each candidate in $S_{k}$ . $\\textstyle R_{k}=\\sum_{j=0}^{k}r_{k}$ . The probability that the best candidate is among the final kept candidate set is ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\operatorname*{Pr}(1\\in S_{\\lfloor\\frac{B}{R}\\rfloor})=1-\\displaystyle\\sum_{k=1}^{r=\\lfloor\\frac{B}{R}\\rfloor}\\operatorname*{Pr}(1\\not\\in S_{k},1\\in S_{k-1})}\\\\ &{\\qquad\\qquad\\qquad=1-\\displaystyle\\sum_{k=0}^{r=\\lfloor\\frac{B}{R}\\rfloor-1}(\\operatorname*{Pr}(1\\in S_{k-1})-\\operatorname*{Pr}(1\\in S_{k},1\\in S_{k-1}))}\\\\ &{\\qquad\\qquad\\qquad=1-\\displaystyle\\sum_{k=0}^{r=\\lfloor\\frac{B}{R}\\rfloor-1}\\left(1-\\operatorname*{Pr}\\Big(\\bigwedge_{i\\in S_{k}\\setminus\\{1\\}}\\ell_{i,R_{k}}>\\ell_{1,R_{k}}\\Big)\\right).}\\end{array}\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "Since the probability that $\\ell_{1,t}$ is the smallest among all $\\ell_{k,t}$ $k\\in[n])$ is greater than ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\prod_{i=2}^{n}\\operatorname*{Pr}(\\ell_{i,t}>\\ell_{1,t})\\geq\\prod_{i=2}^{n}(1-\\Big(\\frac{4f(t)^{2}}{(\\nu_{i}-\\nu_{1})^{2}}\\Big)^{2}),\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "we have ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{(C.2)\\geq1-\\displaystyle\\sum_{k=0}^{\\lfloor\\frac{B}{R}\\rfloor-1}\\big(1-\\displaystyle\\prod_{i=2}^{n}(1-(\\frac{4f(R_{k})^{2}}{(\\nu_{i}-\\nu_{1})^{2}})^{2})\\big)}\\\\ &{\\qquad=1-\\displaystyle\\sum_{k=0}^{\\lfloor\\frac{B}{R}\\rfloor-1}\\big(1-\\displaystyle\\prod_{i=2}^{n}(1-(\\frac{4f\\big(\\sum_{j=0}^{k}\\frac{R}{|S_{j}|}\\big)^{2}}{(\\nu_{i}-\\nu_{1})^{2}})^{2})\\big)}\\\\ &{\\qquad\\geq1-\\lfloor\\frac{B}{R}\\rfloor c.}\\end{array}\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "Therefore, the probability that the scheme returns the best candidate is no less than ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\mathrm{Pr}(1\\in S_{\\lfloor\\frac{B}{R}\\rfloor})\\cdot\\mathrm{Pr}\\left(\\bigwedge_{i\\in S_{\\lfloor\\frac{B}{R}\\rfloor}}\\ell_{i,R_{\\lfloor\\frac{B}{R}\\rfloor}}>\\ell_{1,R_{\\lfloor\\frac{B}{R}\\rfloor}}\\right)\\geq(1-\\lfloor\\frac{B}{R}\\rfloor c)(1-c).\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "That is to say, for a given confidence threshold $c$ , there exists a $T$ such that as long as $\\operatorname*{min}\\{t_{1},t_{2},...,t_{n}\\}>T$ , then $\\mathrm{Pr}(\\wedge_{i=2,\\ldots,n}(\\ell_{i,t_{i}}>\\ell_{1,t_{1}}))>1-c$ . Recall that in the UQ scheme design, the goal is to select an optimal hyperparameter configuration from $n$ candidates, and each round is allocated for $R$ resources. This means that if choose $R\\geq T\\cdot n$ , then the best candidate is returned from the algorithm with probability $\\begin{array}{r}{P>(1-\\lfloor\\frac{B}{R}\\rfloor c)(1\\overline{{-c}})}\\end{array}$ . ", "page_idx": 16}, {"type": "text", "text": "C.2 Proof of Theorem 2 ", "text_level": 1, "page_idx": 16}, {"type": "text", "text": "The representation of ${z}_{o b}$ on the right-hand-side of the inequality is very intuitive: For each $i$ , to confirm that the final loss of the $i$ -th candidate is greater than the best candidate\u2019s with a probability of at least $1-\\delta$ , it is necessary to train both candidates for at least the number of steps indicated by the $i$ -th term in the sum. Repeating this reasoning for all $i$ justifies the sum over all candidates. ", "page_idx": 16}, {"type": "text", "text": "Proof. First we show that, given budget $z=z_{o b}$ , round budget for round $k$ satisfies ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{r_{k}\\geq\\frac{z}{|S_{k}|\\lceil\\log_{2}n\\rceil}-1}\\\\ &{\\quad=\\frac{2}{|S_{k}|}\\operatorname*{max}_{i=2,\\ldots,n}i\\left(1+\\gamma^{-1}(\\frac{\\nu_{i}-\\nu_{1}}{2},\\delta)\\right)-1}\\\\ &{\\quad\\geq\\frac{2}{|S_{k}|}(\\lfloor|S_{k}|/2\\rfloor+1)\\left(1+\\gamma^{-1}(\\frac{\\nu_{\\lfloor|S_{k}|/2\\rfloor+1}-\\nu_{1}}{2},\\delta)\\right)-1}\\\\ &{\\quad\\geq\\gamma^{-1}(\\frac{\\nu_{\\lfloor|S_{k}|/2\\rfloor+1}-\\nu_{1}}{2},\\delta).}\\end{array}\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "The last inequality is derived because $\\lfloor|S_{k}|/2\\rfloor\\ge|S_{k}|/2-1$ . ", "page_idx": 16}, {"type": "text", "text": "Let $\\begin{array}{r}{\\tau_{i}:=\\gamma^{-1}(\\frac{\\nu_{i}-\\nu_{1}}{2},\\delta)}\\end{array}$ . We then show that, for a time $t$ : ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{t\\geq\\tau_{i}\\Rightarrow t\\geq\\gamma^{-1}\\big(\\frac{\\nu_{i}-\\nu_{1}}{2},\\delta\\big)}\\\\ &{\\qquad\\quad\\Leftrightarrow1-\\bigg(\\frac{4f(t)^{2}}{(\\nu_{i}-\\nu_{1})^{2}}\\bigg)^{2}\\geq1-\\delta}\\\\ &{\\qquad\\quad\\Rightarrow\\mathrm{Pr}(\\ell_{i,t}>\\ell_{1,t})\\geq1-\\delta.}\\end{array}\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "The second line follows by the definition of $\\gamma^{-1}(\\epsilon,\\delta)$ . Since $r_{k}\\ge\\tau_{\\lfloor\\mid S_{k}\\mid/2\\rfloor+1}$ , we can compute the following probability ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\operatorname*{Pr}(1\\in S_{k+1}|1\\in S_{k})=\\operatorname*{Pr}\\Big(\\sum_{i\\in S_{k}}\\mathbf{1}\\{\\ell_{i,R_{k}}>\\ell_{1,R_{k}}\\}\\geq\\lfloor\\lvert S_{k}\\rvert/2\\rfloor\\Big)}\\\\ &{\\qquad\\qquad\\qquad\\geq\\operatorname*{Pr}\\!\\big(\\displaystyle\\sum_{i=\\lfloor\\lvert S_{k}\\rvert/2\\rfloor+1}^{\\lfloor S_{k}\\rfloor}\\mathbf{1}\\{\\ell_{i,R_{k}}>\\ell_{1,R_{k}}\\}\\geq\\lfloor\\lvert S_{k}\\rvert/2\\rfloor\\big)}\\\\ &{\\qquad\\qquad\\geq(1-\\delta)^{\\lfloor\\frac{\\lvert S_{k}\\rvert}{2}\\rfloor}}\\end{array}\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "where the first line follows by the definition of the early stopping algorithm (Successive Halving), the second by $\\tau_{i}$ being non-increasing. Namely, for all $i\\dot{>}\\lfloor|\\bar{S_{k}}|/\\bar{2}\\rfloor+1$ , we have $\\tau_{i}\\le\\tau_{\\lceil|S_{k}|/2\\rceil+1}$ and consequently, $\\operatorname*{Pr}(\\ell_{i,R_{k}}>\\ell_{1,R_{k}})\\ge\\operatorname*{Pr}(\\ell_{\\lfloor|S_{k}|/2\\rfloor,R_{k}}>\\ell_{1,R_{k}})\\ge1-\\delta$ . ", "page_idx": 17}, {"type": "text", "text": "Consequently, the probability that the UQ-oblivious approach returns the optimal candidate is ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{P_{o b}\\geq\\operatorname*{Pr}\\Big(\\underset{i=0,\\ldots,\\lceil\\log_{2}n\\rceil-1}{\\bigwedge}\\big(1\\in S_{k+1}|1\\in S_{k}\\big)\\Big)}\\\\ &{\\quad\\geq\\underset{k=0}{\\overset{\\lceil\\log_{2}n\\rceil-1}{\\prod}}(1-\\delta)^{\\lfloor\\frac{|S_{k}|}{2}\\rfloor}}\\\\ &{\\quad\\geq1-n\\delta.}\\end{array}\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "We show in the next Corollary that, for $\\begin{array}{r}{c=\\frac{n\\cdot\\delta}{2}}\\end{array}$ , the probability $P$ obtained in Theorem 1 is no less than $1-n\\delta$ . \u53e3 ", "page_idx": 17}, {"type": "text", "text": "Corollary 6. For the threshold c in Theorem $^{\\,l}$ and $\\delta$ in Theorem 2, let $\\begin{array}{r l r}{c}&{{}=}&{\\frac{n\\cdot\\delta}{2}}\\end{array}$ and $\\beta^{-1}(\\epsilon_{2},\\epsilon_{3},\\cdot\\cdot\\cdot\\,,\\epsilon_{n},c)\\;=\\;\\operatorname*{min}\\{T\\;:\\;\\prod_{i=2}^{n}(1\\,-\\,(\\frac{f(T)}{\\epsilon_{i}})^{4})\\;\\geq\\,1\\,-\\,c\\}$ . Then by Theorem $^{\\,l}$ the UQ approach returns the best candidate with probability over $\\begin{array}{r}{1-n\\delta\\;i f\\,B\\simeq\\gamma^{-1}(\\frac{\\nu_{2}-\\nu_{1}}{2},\\delta)\\cdot n.}\\end{array}$ ", "page_idx": 17}, {"type": "text", "text": "Proof. Let $\\begin{array}{r}{T>\\sqrt[4]{2}\\cdot\\gamma^{-1}(\\frac{\\nu_{2}-\\nu_{1}}{2},\\delta)}\\end{array}$ , we have ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\prod_{i=2}^{n}(1-(\\frac{4f(T)^{2}}{(\\nu_{i}-\\nu_{1})^{2}})^{2})>(1-\\frac{\\delta}{2})^{n}\\geq1-\\frac{n\\delta}{2}=1-c.\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "This shows us that $\\begin{array}{r}{T\\,>\\,\\,\\beta^{-1}(\\frac{\\nu_{2}-\\nu_{1}}{2},...,\\frac{\\nu_{n}-\\nu_{1}}{2},c)}\\end{array}$ . Consequently, according to Theorem 1, for $B=R>T\\cdot n$ , the UQ approach returns the best candidate with probability ", "page_idx": 17}, {"type": "equation", "text": "$$\n(1-c)^{2}\\geq1-2c=1-n\\delta.\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "The UQ-oblivious approach returns the optimal candidate with probability ov\u221aer $1-n\\delta$ if the budget $B_{o b}>z_{o b}$ . But the UQ approach achieves the guarantee with budget $\\begin{array}{r}{B>\\sqrt[4]{2}\\cdot\\gamma^{-1}(\\frac{\\nu_{2}-\\nu_{1}}{2},\\delta)\\cdot n}\\end{array}$ which can be empirically substantially smaller than the budget required in Theorem 2. ", "page_idx": 17}, {"type": "text", "text": "C.3 Proof of Theorem 4 ", "text_level": 1, "page_idx": 17}, {"type": "text", "text": "Proof. Let $\\textstyle R_{k}=\\sum_{j=0}^{k}r_{k}$ , namely, the total number of epochs allocated for each candidate in $S_{k}$ . We can guarantee that, for the UQ-oblivious approach, the output candidate $\\hat{i}_{D}$ satisfies ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\mathbb{E}(\\nu_{i_{D}}-\\nu_{1})=\\mathbb{E}\\bigg(\\underset{i\\in S_{h/\\log(n)}}{\\operatorname*{min}}\\nu_{i}-\\nu_{1}\\bigg)}&{}\\\\ {=\\mathbb{E}\\bigg(\\sum_{k=0}^{\\lfloor\\log_{2}(n)\\rfloor-1}}&{\\underset{i\\in S_{h+1}}{\\operatorname*{min}}\\nu_{i}-\\underset{i\\in S_{h}}{\\operatorname*{min}}\\nu_{i}\\bigg)}\\\\ &{\\leq\\mathbb{E}\\bigg(\\underset{k=0}{\\overset{\\mathrm{\\tiny~(leg.~}/\\log(n))-1}{\\sum}}2|\\nu_{i}-\\ell_{i},\\mu_{k}|+\\underset{i\\in S_{h+1}}{\\operatorname*{min}}\\;\\ell_{i,R_{k}}-\\underset{i\\in S_{h}}{\\operatorname*{min}}\\ell_{i,R_{k}}\\bigg)}\\\\ &{=\\mathbb{E}\\bigg(\\underset{k=0}{\\overset{\\mathrm{\\tiny~(leg.~}/\\log(n))-1}{\\sum}}2|\\nu_{i}-\\ell_{i,R_{k}}|\\bigg)}\\\\ &{\\leq\\frac{2\\lceil\\log_{2}(n)\\rceil\\sqrt{2}f(\\frac{1}{\\lfloor\\log_{2}(n)\\rfloor})\\rceil}{\\sqrt{\\pi}}=\\frac{2\\sqrt{2}n\\lceil\\log_{2}(n)\\rceil^{2}}{\\sqrt{\\pi}B}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "by inspecting how the approach eliminates candidates and plugging in an upper bound for $\\mathbb{E}(2|\\nu_{i}-$ $\\ell_{i,R_{k}}|)$ for all $k$ in the last inequality. We can calculate the bound for the UQ-guided method in a ", "page_idx": 17}, {"type": "text", "text": "similar way: ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\lefteqn{\\mathbb{E}\\left(\\nu_{q}-\\nu_{q}\\right)=\\mathbb{E}\\left(\\sum_{i=1}^{B}\\operatorname*{min}_{i}\\,\\mu_{i}-\\nu_{i}\\right)}}\\\\ &{=\\mathbb{E}\\left(\\sum_{i=1}^{B}\\operatorname*{min}_{i}\\,\\mu_{i}\\right)}\\\\ &{=\\mathbb{E}\\left(\\sum_{i=1}^{B}\\operatorname*{min}_{i}\\,\\mu_{i}-\\operatorname*{min}_{i}\\,\\nu_{i}\\right)}\\\\ &{\\leq\\mathbb{E}\\left(\\sum_{i=1}^{B}w_{i}\\leq\\mu_{i+1},\\,\\mu_{i+1}+\\ell_{i,i+1}\\right)-\\operatorname*{min}_{i}\\{\\mu_{i}-\\ell_{i,B_{i}}+\\ell_{i,B_{i}+1}\\}}\\\\ &{\\leq\\mathbb{E}\\left(\\sum_{i=1}^{B}w_{i}\\leq\\mu_{i+1},\\,\\mu_{i+1}-\\ell_{i,B_{i}+1}\\right)\\-\\mathbb{E}\\left(\\ell_{i,B_{i}}-w_{i}\\leq\\mu_{i},\\,\\mu_{i+1}\\right)}\\\\ &{\\leq\\mathbb{E}\\left(\\sum_{i=1}^{B}2\\operatorname*{min}_{i}\\,\\ell_{i}-\\ell_{i,B_{i}+1}\\,\\ldots,\\,\\ell_{i+1}\\right)}\\\\ &{\\leq\\mathbb{E}\\left(\\sum_{i=1}^{B}2\\operatorname*{min}_{i}-\\ell_{i,B_{i}}\\right)+\\operatorname*{min}_{i}\\left(\\operatorname*{min}_{i}\\,\\ell_{i,B_{i}+1}-\\frac{\\operatorname*{min}_{i}}{\\ell_{i,B_{i}+1}}\\,\\ell_{i,B_{i}}\\right)}\\\\ &{\\leq\\mathbb{E}\\left(\\sum_{i=1}^{B}2\\operatorname*{min}_{i}-\\ell_{i,B_{i}+1}\\right)+\\operatorname*{min}_{i}\\left(\\operatorname*{min}_{i}\\,\\ell_{i,B_{i}+1}-\\operatorname*{min}_{i}\\,\\ell_{i,B_{i}+1}\\right)+\\left(\\operatorname*{min}_{i}\\,\\ell_{i,B_{i}}-\\operatorname*{min}_{i}\\,\\ell_{i,B_{i}}\\right)}\\\\ &{\\leq\\mathbb{E}\\left(\\sum_{i=1}^{B}2\\operatorname*{min}_{i}-\\ell_{i,B_{i}+1}\\right)}\\\\ &{\\leq\\mathbb{E}\\left(\\sum_{i=\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "The smaller upperbound of the UQ-guided approach than that of the UQ-oblivious counterpart in Theorem 4. ", "page_idx": 18}, {"type": "text", "text": "A simple calculation reveals that ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\frac{2\\lfloor\\frac{B}{R}\\rfloor}{R^{2}\\epsilon}<\\frac{2n^{2}\\lceil\\log_{2}(n)\\rceil^{3}}{B^{2}\\epsilon}\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "by diving the first term by the second: ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\frac{2\\lfloor\\frac{B}{R}\\rfloor}{R\\epsilon}\\Big/\\frac{2n\\lceil\\log_{2}(n)\\rceil^{2}}{B\\epsilon}=\\lfloor\\frac{B}{R}\\rfloor\\frac{B}{R}\\cdot\\frac{1}{n\\lceil\\log_{2}(n)\\rceil^{2}}<1.\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "The last inequality holds because both $\\textstyle{\\frac{B}{R}}$ and $\\lceil\\log_{2}(n)\\rceil$ are the number of rounds and are considered the same. ", "page_idx": 18}, {"type": "text", "text": "D Computational Details ", "text_level": 1, "page_idx": 18}, {"type": "text", "text": "Approximating $\\Delta\\sigma$ for Candidates. In our probabilistic model, $\\ell(\\mathbf{y},M_{\\gamma_{c}}^{*}(\\mathbf{X}))$ is approximated by a Gaussian distribution parameterized by $\\mu_{c}$ and $\\sigma_{c}$ . To compute the uncertainty reduction that would result from training each candidate for one additional epoch, we consider the uncertainty as a time series in the form of $(\\sigma_{c}(t))_{t=1}^{T}$ . We examine the uncertainty trendings in NAS-BENCH201 [9]. Figure 4 shows a certain pattern of uncertainty behavior as $t$ increases, both individually and aggregately, for different candidates. ", "page_idx": 18}, {"type": "text", "text": "We then model $(\\sigma_{c}(t))_{t=1}^{T}$ according to different phases in the following way: ", "page_idx": 18}, {"type": "text", "text": "1. For $t\\,\\in\\,(0,6),\\,\\sigma(t)$ increases. We use linear regression to fit the $\\sigma(t)$ , namely, $\\sigma(t)\\,=$ $a_{1}t+b_{1}$ .   \n2. For $t\\,\\in\\,(6,50)$ , $\\sigma(t)$ drops quickly. We use the exponential model to fit $\\sigma(t)$ , namely, $\\sigma(t)=a_{1}e^{-b_{1}x}$ .   \n3. For $t\\in(50,180)$ , $\\sigma(t)$ increases steadily. We use another linear regression to fit $\\sigma(t)$ . ", "page_idx": 18}, {"type": "image", "img_path": "k9uZfaeerK/tmp/537ccdfac6336cd627a5e104ce1abefcfd4e50a2d6e24aef00d7a787277b5a20.jpg", "img_caption": ["(a) Uncertainty scope for different candidates. (b) Average uncertainty for different candidates. ", "Figure 4: Landscape of the uncertainty scope for different epochs. "], "img_footnote": [], "page_idx": 19}, {"type": "image", "img_path": "k9uZfaeerK/tmp/bdb0cad50dda30726ac30faa8b58498c808e48c828b1605e0f0429658ca750b0.jpg", "img_caption": [], "img_footnote": [], "page_idx": 19}, {"type": "image", "img_path": "k9uZfaeerK/tmp/b54abf391ea3820ff91776bd6cdad0a8cfc2fc26eaedd21fb3c5ac3733f91466.jpg", "img_caption": [], "img_footnote": [], "page_idx": 19}, {"type": "text", "text": "Figure 5: Illustration for confidence curve and discarding mechanisms. After obtaining the confidence curve, a threshold $\\tau$ determines the number of candidates we will keep ( $k_{1}$ for round 1, $k_{2}$ for round 2, and $k_{3}$ for round 3). We choose the smallest $k$ such that $P_{k}\\ge\\tau$ for each round, proceed training with the best performed $k$ candidates, and discard the rest configurations. ", "page_idx": 19}, {"type": "text", "text": "4. For $t\\in(180,200)$ , $\\sigma(t)$ reverses the trend and decreases again. We use linear regression. ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "For each launch, we sample a few candidates and train each one fully till convergence. We then use the abovementioned way to model the uncertainty behavior for the whole dataset. This makes the approximation for $\\Delta_{t}\\sigma\\stackrel{.}{=}\\sigma(t)-\\sigma(t+1)$ effective and efficient. ", "page_idx": 19}, {"type": "text", "text": "An alternative way to approximate $\\Delta_{t}\\sigma$ is to use ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\frac{!}{\\widehat{\\mathfrak{z}}}\\sum_{b\\in D_{t-1}}(\\ell(\\mathbf{y},M_{\\gamma_{c}}^{b}(\\mathbf{X}))-\\mathbb{E}_{D_{t-1}}[\\ell(\\mathbf{y},M_{\\gamma_{c}}^{b}(\\mathbf{X}))])^{2}-\\frac{1}{\\widehat{\\mathcal{S}}}\\sum_{b\\in D_{t}}(\\ell(\\mathbf{y},M_{\\gamma_{c}}^{b}(\\mathbf{X}))-\\mathbb{E}_{D_{t}}[\\ell(\\mathbf{y},M_{\\gamma_{c}}^{b}(\\mathbf{X}))])^{2}.\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "Building Probabilistic Model. At any given time $t$ , the approximation of converged validation loss follows the Gaussian distribution: $\\ell(\\mathbf{\\bar{y}},\\mathbf{\\bar{\\boldsymbol{M}}}_{\\gamma_{c}}^{*}(\\mathbf{\\mathbf{X}}))\\sim\\mathcal{N}(\\bar{\\mu_{c}},\\sigma_{c}^{2})$ . In our experiments, $\\delta=10$ , $\\mu_{c}$ is the current accuracy $\\ell(\\mathbf{y},M_{\\gamma_{c}}^{t}(\\mathbf{X}))$ , and $\\sigma_{c}$ is the unbiased estimation of the standard deviation of $\\ell(\\mathbf{y},M_{\\gamma_{c}}^{i}(\\mathbf{X}))_{i=t-10}^{t}$ . ", "page_idx": 19}, {"type": "text", "text": "E Additional Related Work ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "Freeze-thaw Bayesian optimization. This paper proposes a new method to improve Bayesian optimization (BO) for HPO. It avoids the limits of the expected improvement (EI) criterion in naive BO which always favors picking new candidates rather than running old ones for more iterations. Instead of always sampling new candidates, it can also choose old candidates for further evaluation based on the modified EI in each round. This method, however, is limited to BO method. In contrast, our UQ scheme is applicable to the vast number of early stopped and multi-fidelity-based HPO methods. ", "page_idx": 19}, {"type": "text", "text": "HyperJump improves HB in that, during HPO, it skips certain rounds for certain candidates if the risk of skipping is within a threshold. For the NAS-BENCH-201 trained on ImageNet-16-120, HJ reduces the running time compared to the original HB method (only needs a $5.3\\%$ fraction of budget to achieve close to optimal results achieved by the original HB with a standard full budget), but it does not improve the HPO performance (i.e., Top-1 Rank and Regret). In contrast, our method only needs less than a $3\\%$ fraction of the budget to achieve close to optimal results and when using around $5\\%$ fraction of budget, our method reduces the regret by $33\\%$ . ", "page_idx": 20}, {"type": "text", "text": "F Benchmark and Dataset Information ", "text_level": 1, "page_idx": 20}, {"type": "text", "text": "Table 2 consolidates information on the datasets, hyperparameters, fidelity, and dataset sizes for Nas-Bench-201 and LCBench. The datasets for LCBench are drawn from various sources [37, 13]. ", "page_idx": 20}, {"type": "table", "img_path": "k9uZfaeerK/tmp/767f4e9d81b40dc9ff800af7836146b285a9decde9b87ad23934d096e19b6a90.jpg", "table_caption": ["Table 2: Benchmark and Dataset information. "], "table_footnote": [], "page_idx": 20}, {"type": "text", "text": "G More Results on Experiments ", "text_level": 1, "page_idx": 20}, {"type": "text", "text": "We include more results on NAS-Bench-201 and LCBench. For example, Figure 10 and 11 show the results on LCBench, where we proved the consistently better performance of the UQ-guided approaches than the UQ-oblivious methods on Fashion-MNIST. Figure 10 shows the results of the validation loss while Figure 11 demonstrates the results of regret. UQ-guided approaches obtained an average of over $50\\%$ improvement over the UQ-oblivious counterparts. ", "page_idx": 20}, {"type": "image", "img_path": "k9uZfaeerK/tmp/444e6dd9ebc5052096fbda9aacf26514e4778d7d7097c8d622fa4185191da717.jpg", "img_caption": ["Figure 6: Results of test accuracy when optimizing on CIFAR-10. "], "img_footnote": [], "page_idx": 20}, {"type": "image", "img_path": "k9uZfaeerK/tmp/5a3ac8b00f18eef802ededf0bbbda2c82bdafd63ffb0b0d2d531fdb5ac2cbb32.jpg", "img_caption": ["Figure 7: Results of regret $(\\%)$ when optimizing on CIFAR-10. "], "img_footnote": [], "page_idx": 21}, {"type": "image", "img_path": "k9uZfaeerK/tmp/ac15902f6512bcdd1e5dd2f1132c63e1e0eb6d978faf69bfedaccea956685285.jpg", "img_caption": ["Figure 8: Results of test accuracy when optimizing on CIFAR-100. "], "img_footnote": [], "page_idx": 21}, {"type": "image", "img_path": "k9uZfaeerK/tmp/f9323c1baa4a3fe2b967a7b2add56c5a928e1a16d0408c19bcf8da3a67863cc7.jpg", "img_caption": ["Figure 9: Results of test accuracy when optimizing on CIFAR-100. "], "img_footnote": [], "page_idx": 22}, {"type": "image", "img_path": "k9uZfaeerK/tmp/c2643153154b742c5ea8ce782942f088e2df1fe812c5e99aa3d69d7d73e40490.jpg", "img_caption": ["Figure 10: Results of validation error for optimizing on Fashion-MNIST. "], "img_footnote": [], "page_idx": 22}, {"type": "image", "img_path": "k9uZfaeerK/tmp/f731492ade2aa07989e5e528c26193dd48033c4bfcbb6d3cad411eae527e6ffc.jpg", "img_caption": ["Figure 11: Results of regret $(\\%)$ on test accuracy for optimizing on Fashion-MNIST. "], "img_footnote": [], "page_idx": 22}, {"type": "text", "text": "H Experiments on Other Iterative Learners ", "text_level": 1, "page_idx": 23}, {"type": "text", "text": "We focus on DNNs in our experiments because (1) DNNs are among the most influential models today and (2) DNN training takes a long time so selecting the optimal hyperparameters is a critical concern, making the problem more pressing. ", "page_idx": 23}, {"type": "text", "text": "Even though we focus on DNN methods, our approach can be applied to other iterative learners. We consider a ridge regression problem trained with stochastic gradient descent on this objective function with step size . $01/\\sqrt{2+T}$ . The $l_{2}$ penalty hyperparameter $\\lambda\\in[10^{-6},10^{0}]$ was chosen uniformly at random on a log scale per trial. We use the Million Song Dataset year prediction task [27] with the same experiment settings as in the original SH paper. We show the results of ridge regression on \"SH\" and $\"S\\mathrm{H}+\"$ . Figure 12 shows the Top-1 Rank results and the regret of the test error for different fractions of budgets. The average results of 30 repetitions are reported. The benefits are obvious: $\\mathrm{SH+}$ obtained an average of over $40\\%$ improvement over the SH. ", "page_idx": 23}, {"type": "image", "img_path": "k9uZfaeerK/tmp/a43e392ba5b633579665a09e0b9bda399b53d089f2ee4644e9ce736150c7f711.jpg", "img_caption": ["Figure 12: Results of Top-1 Rank and Regret on test error for optimizing ridge regression. "], "img_footnote": [], "page_idx": 23}, {"type": "text", "text": "Checklist ", "text_level": 1, "page_idx": 23}, {"type": "text", "text": "1. Claims ", "text_level": 1, "page_idx": 23}, {"type": "text", "text": "Question: Do the main claims made in the abstract and introduction accurately reflect the paper\u2019s contributions and scope? ", "page_idx": 23}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 23}, {"type": "text", "text": "Justification: See Section 1, Section 3.4, and Section 4. ", "page_idx": 23}, {"type": "text", "text": "Guidelines: ", "page_idx": 23}, {"type": "text", "text": "\u2022 The answer NA means that the abstract and introduction do not include the claims made in the paper.   \n\u2022 The abstract and/or introduction should clearly state the claims made, including the contributions made in the paper and important assumptions and limitations. A No or NA answer to this question will not be perceived well by the reviewers.   \n\u2022 The claims made should match theoretical and experimental results, and reflect how much the results can be expected to generalize to other settings.   \n\u2022 It is fine to include aspirational goals as motivation as long as it is clear that these goals are not attained by the paper. ", "page_idx": 23}, {"type": "text", "text": "2. Limitations ", "text_level": 1, "page_idx": 23}, {"type": "text", "text": "Question: Does the paper discuss the limitations of the work performed by the authors? Answer: [Yes] ", "page_idx": 23}, {"type": "text", "text": "Justification: We state them at the end of Section 5. The key characteristic of the UQ method is the necessity to rank multiple learners during the HPO process. Gradient-based HPO methods [30], for instance, may not benefit from our UQ-guided scheme because of their sequential properties. One limitation of this paper is that it is mostly suitable for iterative learners, and needs adaptations for other learners: To go beyond, it could be, for instance, applied to the model selection work in previous studies [31] that use training dataset size as the budget dimension. In this case, the learner does not need to be iterative; the selection is based on the validation loss history trained with incremental dataset sizes. The UQ component can still guide the configuration selection and budget allocation in the HPO process. ", "page_idx": 23}, {"type": "text", "text": "", "page_idx": 24}, {"type": "text", "text": "Guidelines: ", "page_idx": 24}, {"type": "text", "text": "\u2022 The answer NA means that the paper has no limitation while the answer No means that the paper has limitations, but those are not discussed in the paper.   \n\u2022 The authors are encouraged to create a separate \"Limitations\" section in their paper.   \n\u2022 The paper should point out any strong assumptions and how robust the results are to violations of these assumptions (e.g., independence assumptions, noiseless settings, model well-specification, asymptotic approximations only holding locally). The authors should reflect on how these assumptions might be violated in practice and what the implications would be.   \n\u2022 The authors should reflect on the scope of the claims made, e.g., if the approach was only tested on a few datasets or with a few runs. In general, empirical results often depend on implicit assumptions, which should be articulated.   \n\u2022 The authors should reflect on the factors that influence the performance of the approach. For example, a facial recognition algorithm may perform poorly when image resolution is low or images are taken in low lighting. Or a speech-to-text system might not be used reliably to provide closed captions for online lectures because it fails to handle technical jargon.   \n\u2022 The authors should discuss the computational efficiency of the proposed algorithms and how they scale with dataset size.   \n\u2022 If applicable, the authors should discuss possible limitations of their approach to address problems of privacy and fairness.   \n\u2022 While the authors might fear that complete honesty about limitations might be used by reviewers as grounds for rejection, a worse outcome might be that reviewers discover limitations that aren\u2019t acknowledged in the paper. The authors should use their best judgment and recognize that individual actions in favor of transparency play an important role in developing norms that preserve the integrity of the community. Reviewers will be specifically instructed to not penalize honesty concerning limitations. ", "page_idx": 24}, {"type": "text", "text": "3. Theory Assumptions and Proofs ", "text_level": 1, "page_idx": 24}, {"type": "text", "text": "Question: For each theoretical result, does the paper provide the full set of assumptions and a complete (and correct) proof? ", "page_idx": 24}, {"type": "text", "text": "Answer: [Yes] . ", "text_level": 1, "page_idx": 24}, {"type": "text", "text": "Justification: See Section 3.4 and appendix C. ", "page_idx": 24}, {"type": "text", "text": "Guidelines: ", "page_idx": 24}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include theoretical results.   \n\u2022 All the theorems, formulas, and proofs in the paper should be numbered and crossreferenced.   \n\u2022 All assumptions should be clearly stated or referenced in the statement of any theorems.   \n\u2022 The proofs can either appear in the main paper or the supplemental material, but if they appear in the supplemental material, the authors are encouraged to provide a short proof sketch to provide intuition.   \n\u2022 Inversely, any informal proof provided in the core of the paper should be complemented by formal proofs provided in appendix or supplemental material.   \n\u2022 Theorems and Lemmas that the proof relies upon should be properly referenced. ", "page_idx": 24}, {"type": "text", "text": "4. Experimental Result Reproducibility ", "text_level": 1, "page_idx": 24}, {"type": "text", "text": "Question: Does the paper fully disclose all the information needed to reproduce the main experimental results of the paper to the extent that it affects the main claims and/or conclusions of the paper (regardless of whether the code and data are provided or not)? ", "page_idx": 24}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 24}, {"type": "text", "text": "Justification: We include them in Section 4 and the supplemental material. Guidelines: ", "page_idx": 24}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 If the paper includes experiments, a No answer to this question will not be perceived well by the reviewers: Making the paper reproducible is important, regardless of whether the code and data are provided or not.   \n\u2022 If the contribution is a dataset and/or model, the authors should describe the steps taken to make their results reproducible or verifiable.   \n\u2022 Depending on the contribution, reproducibility can be accomplished in various ways. For example, if the contribution is a novel architecture, describing the architecture fully might suffice, or if the contribution is a specific model and empirical evaluation, it may be necessary to either make it possible for others to replicate the model with the same dataset, or provide access to the model. In general. releasing code and data is often one good way to accomplish this, but reproducibility can also be provided via detailed instructions for how to replicate the results, access to a hosted model (e.g., in the case of a large language model), releasing of a model checkpoint, or other means that are appropriate to the research performed.   \n\u2022 While NeurIPS does not require releasing code, the conference does require all submissions to provide some reasonable avenue for reproducibility, which may depend on the nature of the contribution. For example (a) If the contribution is primarily a new algorithm, the paper should make it clear how to reproduce that algorithm. (b) If the contribution is primarily a new model architecture, the paper should describe the architecture clearly and fully. (c) If the contribution is a new model (e.g., a large language model), then there should either be a way to access this model for reproducing the results or a way to reproduce the model (e.g., with an open-source dataset or instructions for how to construct the dataset). (d) We recognize that reproducibility may be tricky in some cases, in which case authors are welcome to describe the particular way they provide for reproducibility. In the case of closed-source models, it may be that access to the model is limited in some way (e.g., to registered users), but it should be possible for other researchers to have some path to reproducing or verifying the results. ", "page_idx": 25}, {"type": "text", "text": "5. Open access to data and code ", "text_level": 1, "page_idx": 25}, {"type": "text", "text": "Question: Does the paper provide open access to the data and code, with sufficient instructions to faithfully reproduce the main experimental results, as described in supplemental material? ", "page_idx": 25}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 25}, {"type": "text", "text": "Justification: We include them in the supplemental material. ", "page_idx": 25}, {"type": "text", "text": "Guidelines: ", "text_level": 1, "page_idx": 25}, {"type": "text", "text": "\u2022 The answer NA means that paper does not include experiments requiring code.   \n\u2022 Please see the NeurIPS code and data submission guidelines (https://nips.cc/ public/guides/CodeSubmissionPolicy) for more details.   \n\u2022 While we encourage the release of code and data, we understand that this might not be possible, so \u201cNo\u201d is an acceptable answer. Papers cannot be rejected simply for not including code, unless this is central to the contribution (e.g., for a new open-source benchmark).   \n\u2022 The instructions should contain the exact command and environment needed to run to reproduce the results. See the NeurIPS code and data submission guidelines (https: //nips.cc/public/guides/CodeSubmissionPolicy) for more details.   \n\u2022 The authors should provide instructions on data access and preparation, including how to access the raw data, preprocessed data, intermediate data, and generated data, etc.   \n\u2022 The authors should provide scripts to reproduce all experimental results for the new proposed method and baselines. If only a subset of experiments are reproducible, they should state which ones are omitted from the script and why.   \n\u2022 At submission time, to preserve anonymity, the authors should release anonymized versions (if applicable). ", "page_idx": 25}, {"type": "text", "text": "\u2022 Providing as much information as possible in supplemental material (appended to the paper) is recommended, but including URLs to data and code is permitted. ", "page_idx": 26}, {"type": "text", "text": "6. Experimental Setting/Details ", "text_level": 1, "page_idx": 26}, {"type": "text", "text": "Question: Does the paper specify all the training and test details (e.g., data splits, hyperparameters, how they were chosen, type of optimizer, etc.) necessary to understand the results? ", "page_idx": 26}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 26}, {"type": "text", "text": "Justification: See Section 4. Guidelines: ", "page_idx": 26}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments. \u2022 The experimental setting should be presented in the core of the paper to a level of detail that is necessary to appreciate the results and make sense of them. \u2022 The full details can be provided either with the code, in appendix, or as supplemental material. ", "page_idx": 26}, {"type": "text", "text": "7. Experiment Statistical Significance ", "text_level": 1, "page_idx": 26}, {"type": "text", "text": "Question: Does the paper report error bars suitably and correctly defined or other appropriate information about the statistical significance of the experiments? ", "page_idx": 26}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 26}, {"type": "text", "text": "Justification: We conducted 30 repetitions for the experiments. For the right two columns in Figure 3, besides the average results of the repetitions, we also report the interval between the 30th and 70th percentiles. ", "page_idx": 26}, {"type": "text", "text": "Guidelines: ", "page_idx": 26}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 The authors should answer \"Yes\" if the results are accompanied by error bars, confidence intervals, or statistical significance tests, at least for the experiments that support the main claims of the paper.   \n\u2022 The factors of variability that the error bars are capturing should be clearly stated (for example, train/test split, initialization, random drawing of some parameter, or overall run with given experimental conditions).   \n\u2022 The method for calculating the error bars should be explained (closed form formula, call to a library function, bootstrap, etc.)   \n\u2022 The assumptions made should be given (e.g., Normally distributed errors).   \n\u2022 It should be clear whether the error bar is the standard deviation or the standard error of the mean.   \n\u2022 It is OK to report 1-sigma error bars, but one should state it. The authors should preferably report a 2-sigma error bar than state that they have a $96\\%$ CI, if the hypothesis of Normality of errors is not verified.   \n\u2022 For asymmetric distributions, the authors should be careful not to show in tables or figures symmetric error bars that would yield results that are out of range (e.g. negative error rates).   \n\u2022 If error bars are reported in tables or plots, The authors should explain in the text how they were calculated and reference the corresponding figures or tables in the text. ", "page_idx": 26}, {"type": "text", "text": "8. Experiments Compute Resources ", "text_level": 1, "page_idx": 26}, {"type": "text", "text": "Question: For each experiment, does the paper provide sufficient information on the computer resources (type of compute workers, memory, time of execution) needed to reproduce the experiments? ", "page_idx": 26}, {"type": "text", "text": "Answer: [Yes] . ", "page_idx": 26}, {"type": "text", "text": "Justification: See Section 4.1. ", "page_idx": 26}, {"type": "text", "text": "Guidelines: \u2022 The answer NA means that the paper does not include experiments. ", "page_idx": 26}, {"type": "text", "text": "\u2022 The paper should indicate the type of compute workers CPU or GPU, internal cluster, or cloud provider, including relevant memory and storage.   \n\u2022 The paper should provide the amount of compute required for each of the individual experimental runs as well as estimate the total compute.   \n\u2022 The paper should disclose whether the full research project required more compute than the experiments reported in the paper (e.g., preliminary or failed experiments that didn\u2019t make it into the paper). ", "page_idx": 27}, {"type": "text", "text": "9. Code Of Ethics ", "text_level": 1, "page_idx": 27}, {"type": "text", "text": "Question: Does the research conducted in the paper conform, in every respect, with the NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines? ", "page_idx": 27}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 27}, {"type": "text", "text": "Justification: We conform with the NeurIPS Code of Ethics. ", "page_idx": 27}, {"type": "text", "text": "Guidelines: ", "page_idx": 27}, {"type": "text", "text": "\u2022 The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics.   \n\u2022 If the authors answer No, they should explain the special circumstances that require a deviation from the Code of Ethics.   \n\u2022 The authors should make sure to preserve anonymity (e.g., if there is a special consideration due to laws or regulations in their jurisdiction). ", "page_idx": 27}, {"type": "text", "text": "10. Broader Impacts ", "text_level": 1, "page_idx": 27}, {"type": "text", "text": "Question: Does the paper discuss both potential positive societal impacts and negative societal impacts of the work performed? ", "page_idx": 27}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 27}, {"type": "text", "text": "Justification: As stated in Section 5, our work is a general algorithm aiming at optimizing HPO and belongs to a foundational research; its societal impacts are neutral. ", "page_idx": 27}, {"type": "text", "text": "Guidelines: ", "page_idx": 27}, {"type": "text", "text": "\u2022 The answer NA means that there is no societal impact of the work performed.   \n\u2022 If the authors answer NA or No, they should explain why their work has no societal impact or why the paper does not address societal impact.   \n\u2022 Examples of negative societal impacts include potential malicious or unintended uses (e.g., disinformation, generating fake profiles, surveillance), fairness considerations (e.g., deployment of technologies that could make decisions that unfairly impact specific groups), privacy considerations, and security considerations.   \n\u2022 The conference expects that many papers will be foundational research and not tied to particular applications, let alone deployments. However, if there is a direct path to any negative applications, the authors should point it out. For example, it is legitimate to point out that an improvement in the quality of generative models could be used to generate deepfakes for disinformation. On the other hand, it is not needed to point out that a generic algorithm for optimizing neural networks could enable people to train models that generate Deepfakes faster.   \n\u2022 The authors should consider possible harms that could arise when the technology is being used as intended and functioning correctly, harms that could arise when the technology is being used as intended but gives incorrect results, and harms following from (intentional or unintentional) misuse of the technology.   \n\u2022 If there are negative societal impacts, the authors could also discuss possible mitigation strategies (e.g., gated release of models, providing defenses in addition to attacks, mechanisms for monitoring misuse, mechanisms to monitor how a system learns from feedback over time, improving the efficiency and accessibility of ML). ", "page_idx": 27}, {"type": "text", "text": "11. Safeguards ", "text_level": 1, "page_idx": 27}, {"type": "text", "text": "Question: Does the paper describe safeguards that have been put in place for responsible release of data or models that have a high risk for misuse (e.g., pretrained language models, image generators, or scraped datasets)? ", "page_idx": 27}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 27}, {"type": "text", "text": "Justification: The paper poses no such risks. ", "page_idx": 28}, {"type": "text", "text": "Guidelines: ", "page_idx": 28}, {"type": "text", "text": "\u2022 The answer NA means that the paper poses no such risks.   \n\u2022 Released models that have a high risk for misuse or dual-use should be released with necessary safeguards to allow for controlled use of the model, for example by requiring that users adhere to usage guidelines or restrictions to access the model or implementing safety filters.   \n\u2022 Datasets that have been scraped from the Internet could pose safety risks. The authors should describe how they avoided releasing unsafe images.   \n\u2022 We recognize that providing effective safeguards is challenging, and many papers do not require this, but we encourage authors to take this into account and make a best faith effort. ", "page_idx": 28}, {"type": "text", "text": "12. Licenses for existing assets ", "text_level": 1, "page_idx": 28}, {"type": "text", "text": "Question: Are the creators or original owners of assets (e.g., code, data, models), used in the paper, properly credited and are the license and terms of use explicitly mentioned and properly respected? ", "page_idx": 28}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 28}, {"type": "text", "text": "Justification: We have cited the creators for the existing assets and included the name of the license. See Section 4.1. ", "page_idx": 28}, {"type": "text", "text": "Guidelines: ", "page_idx": 28}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not use existing assets.   \n\u2022 The authors should cite the original paper that produced the code package or dataset.   \n\u2022 The authors should state which version of the asset is used and, if possible, include a URL.   \n\u2022 The name of the license (e.g., CC-BY 4.0) should be included for each asset.   \n\u2022 For scraped data from a particular source (e.g., website), the copyright and terms of service of that source should be provided.   \n\u2022 If assets are released, the license, copyright information, and terms of use in the package should be provided. For popular datasets, paperswithcode.com/datasets has curated licenses for some datasets. Their licensing guide can help determine the license of a dataset.   \n\u2022 For existing datasets that are re-packaged, both the original license and the license of the derived asset (if it has changed) should be provided.   \n\u2022 If this information is not available online, the authors are encouraged to reach out to the asset\u2019s creators. ", "page_idx": 28}, {"type": "text", "text": "13. New Assets ", "text_level": 1, "page_idx": 28}, {"type": "text", "text": "Question: Are new assets introduced in the paper well documented and is the documentation provided alongside the assets? ", "page_idx": 28}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 28}, {"type": "text", "text": "Justification: See supplementary materials. ", "page_idx": 28}, {"type": "text", "text": "Guidelines: ", "page_idx": 28}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not release new assets.   \n\u2022 Researchers should communicate the details of the dataset/code/model as part of their submissions via structured templates. This includes details about training, license, limitations, etc.   \n\u2022 The paper should discuss whether and how consent was obtained from people whose asset is used.   \n\u2022 At submission time, remember to anonymize your assets (if applicable). You can either create an anonymized URL or include an anonymized zip file. ", "page_idx": 28}, {"type": "text", "text": "14. Crowdsourcing and Research with Human Subjects ", "page_idx": 28}, {"type": "text", "text": "Question: For crowdsourcing experiments and research with human subjects, does the paper include the full text of instructions given to participants and screenshots, if applicable, as well as details about compensation (if any)? ", "page_idx": 29}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 29}, {"type": "text", "text": "Justification: The paper does not involve crowdsourcing nor research with human subjects. Guidelines: ", "page_idx": 29}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u2022 Including this information in the supplemental material is fine, but if the main contribution of the paper involves human subjects, then as much detail as possible should be included in the main paper.   \n\u2022 According to the NeurIPS Code of Ethics, workers involved in data collection, curation, or other labor should be paid at least the minimum wage in the country of the data collector. ", "page_idx": 29}, {"type": "text", "text": "15. Institutional Review Board (IRB) Approvals or Equivalent for Research with Human Subjects ", "text_level": 1, "page_idx": 29}, {"type": "text", "text": "Question: Does the paper describe potential risks incurred by study participants, whether such risks were disclosed to the subjects, and whether Institutional Review Board (IRB) approvals (or an equivalent approval/review based on the requirements of your country or institution) were obtained? ", "page_idx": 29}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 29}, {"type": "text", "text": "Justification: The paper does not involve crowdsourcing nor research with human subjects. Guidelines: ", "page_idx": 29}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u2022 Depending on the country in which research is conducted, IRB approval (or equivalent) may be required for any human subjects research. If you obtained IRB approval, you should clearly state this in the paper.   \n\u2022 We recognize that the procedures for this may vary significantly between institutions and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the guidelines for their institution.   \n\u2022 For initial submissions, do not include any information that would break anonymity (if applicable), such as the institution conducting the review. ", "page_idx": 29}]