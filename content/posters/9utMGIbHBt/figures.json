[{"figure_path": "9utMGIbHBt/figures/figures_0_1.jpg", "caption": "Figure 1: The Upsampling Diffusion Probabilistic Model (UDPM) scheme for 3 diffusion steps (L = 3). In addition to the gradual noise perturbation in traditional DDPMs, UDPM also downsamples the latent variables. Accordingly, in the reverse process, UDPM denoises and upsamples the latent variables to generate images from the data distribution.", "description": "This figure illustrates the process of the Upsampling Diffusion Probabilistic Model (UDPM).  It shows how UDPM differs from traditional Denoising Diffusion Probabilistic Models (DDPMs) by incorporating downsampling steps in the forward diffusion process (adding noise and reducing resolution) and corresponding upsampling steps in the reverse diffusion process (denoising and increasing resolution). The forward process starts with an image (X0) and gradually adds noise while downsampling the image until pure noise (X3) is achieved.  The reverse process learns to denoise and upsample the latent variables, eventually reconstructing the original image.", "section": "Introduction"}, {"figure_path": "9utMGIbHBt/figures/figures_2_1.jpg", "caption": "Figure 2: Generated 64 \u00d7 64 images of AFHQv2 [6] with FID=7.10142, produced using unconditional UDPM with only 3 steps, which are equivalent to 0.3 of a single typical 64 \u00d7 64 diffusion step.", "description": "This figure shows 64x64 images of animals generated using the proposed unconditional Upsampling Diffusion Probabilistic Model (UDPM).  The model uses only three diffusion steps to generate these images.  The Fr\u00e9chet Inception Distance (FID) score, a metric for evaluating the quality of generated images, is reported as 7.10142, indicating high fidelity.  The caption highlights the efficiency of the UDPM, noting that its three steps are computationally equivalent to only 0.3 of a single step in traditional diffusion models.", "section": "4 Unconditional Generation"}, {"figure_path": "9utMGIbHBt/figures/figures_4_1.jpg", "caption": "Figure 3: Generated 64 \u00d7 64 images of FFHQ with FID=7.41065, produced using unconditional UDPM with only 3 steps, which are equivalent to 0.3 of a single typical 64 \u00d7 64 diffusion step.", "description": "This figure shows 64 examples of 64x64 images generated from the FFHQ dataset using the proposed UDPM model.  The model only required 3 diffusion steps, which is significantly fewer than traditional diffusion models.  The FID score of 7.41065 indicates high-quality image generation.", "section": "4 Experiments"}, {"figure_path": "9utMGIbHBt/figures/figures_5_1.jpg", "caption": "Figure 1: The Upsampling Diffusion Probabilistic Model (UDPM) scheme for 3 diffusion steps (L = 3). In addition to the gradual noise perturbation in traditional DDPMs, UDPM also downsamples the latent variables. Accordingly, in the reverse process, UDPM denoises and upsamples the latent variables to generate images from the data distribution.", "description": "This figure illustrates the forward and reverse diffusion processes in the proposed Upsampling Diffusion Probabilistic Model (UDPM).  The forward process starts with data samples (X0) and iteratively adds noise while simultaneously downsampling the latent variables (X1, X2, X3).  Conversely, the reverse process starts with pure noise (XL) and gradually denoises and upsamples the latent variables to reconstruct the data samples (X0).  This contrasts with traditional DDPMs that only add noise and do not downsample, resulting in a more efficient generation process.", "section": "Introduction"}, {"figure_path": "9utMGIbHBt/figures/figures_6_1.jpg", "caption": "Figure 4: The training and sampling procedures of UDPM. During the training phase, an image x0 is randomly selected from the dataset. It is then degraded using (9) to obtain a downsampled noisy version x1, which is then plugged into f(L)(.), that is trained to predict H<sup>L\u22121</sup>x0. In the sampling phase, we start from pure noise xL ~ N(0, I). This noise is passed through the network f(L)(.) to estimate H<sup>L\u22121</sup>x0, used to compute \u03bc1 through (12), with \u03a31 obtained from (11). Afterwards, xL\u22121 is drawn from N(\u03bc1, \u03a31) using the technique described in Appendix B.6. By repeating this procedure for L iterations, the final sample x0 is obtained.", "description": "This figure illustrates the training and sampling processes of the Upsampling Diffusion Probabilistic Model (UDPM). The training process involves downsampling an image using a blur filter and subsampling, adding noise, and training a neural network to predict the original image from the noisy, downsampled version.  The sampling process begins with pure noise and iteratively upsamples and denoises the image using the trained network to generate a sample from the data distribution.", "section": "3.2 Image Generation using UDPM"}, {"figure_path": "9utMGIbHBt/figures/figures_6_2.jpg", "caption": "Figure 5: Latent space interpolation for 64 \u00d7 64 generated images. The four corner images are interpolated by a weighted mixture of their latent noises, such that the other images are \u201cin-between\u201d images from the latent perspective, similar to what has been done in GANs [19].", "description": "This figure shows the results of latent space interpolation using UDPM. Four corner images are generated, and the intervening images are created by weighted mixtures of the corner images' latent noise.  This demonstrates the model's ability to generate images that smoothly transition between different styles.", "section": "4.1 Unconditional Generation"}, {"figure_path": "9utMGIbHBt/figures/figures_7_1.jpg", "caption": "Figure 5: Latent space interpolation for 64 \u00d7 64 generated images. The four corner images are interpolated by a weighted mixture of their latent noises, such that the other images are \u201cin-between\u201d images from the latent perspective, similar to what has been done in GANs [19].", "description": "This figure shows the results of latent space interpolation in the UDPM model.  Four corner images (different faces and animals) were generated using UDPM. The images in between these corners are generated by taking a weighted average of the latent noise vectors used to generate the corners. This demonstrates the UDPM model's ability to smoothly interpolate between different image samples in latent space, similar to what is possible with GANs. This highlights the interpretability of UDPM's latent space.", "section": "4.1 Unconditional Generation"}, {"figure_path": "9utMGIbHBt/figures/figures_9_1.jpg", "caption": "Figure 7: Visual comparison of the loss terms effect on the FFHQ64 dataset generation results.", "description": "This figure shows the impact of different loss functions on the quality of generated images using the FFHQ64 dataset. Three different models were trained with different combinations of loss terms: (1)  l1 + lper + ladv (using all three loss terms,  l1 loss, perceptual loss, and adversarial loss), (2) l1 + lper (using l1 loss and perceptual loss), and (3) l1 (only using l1 loss). The results demonstrate that incorporating both perceptual and adversarial loss functions significantly improves the quality of generated images, as evidenced by the lower FID scores (Fr\u00e9chet Inception Distance), and visual inspection of the generated images.  Lower FID scores indicate better image quality.", "section": "Ablation studies"}, {"figure_path": "9utMGIbHBt/figures/figures_19_1.jpg", "caption": "Figure 8: The first 8 principal components of the covariance matrix computed over 128 images generated by fixing two diffusion steps and adding small perturbation noise to the third (indexed above).", "description": "This figure shows the top 8 principal components of a covariance matrix. The matrix was calculated from 128 images. These images were generated using a diffusion model. Two of the diffusion steps were fixed and a small amount of noise was added to the third step. Each row of images represents the principal components of the covariance matrix for a different diffusion step. This visualization helps to understand how the different diffusion steps affect the generated images.", "section": "5 Ablation studies"}, {"figure_path": "9utMGIbHBt/figures/figures_19_2.jpg", "caption": "Figure 1: The Upsampling Diffusion Probabilistic Model (UDPM) scheme for 3 diffusion steps (L = 3). In addition to the gradual noise perturbation in traditional DDPMs, UDPM also downsamples the latent variables. Accordingly, in the reverse process, UDPM denoises and upsamples the latent variables to generate images from the data distribution.", "description": "This figure illustrates the process of the Upsampling Diffusion Probabilistic Model (UDPM).  It shows the forward diffusion process, where noise is gradually added to an image while simultaneously downsampling the latent representation. This is followed by the reverse process, where the model denoises and upsamples the latent representation to reconstruct the original image. The figure highlights the key difference between UDPM and traditional DDPMs: the incorporation of downsampling in the forward pass.", "section": "1 Introduction"}, {"figure_path": "9utMGIbHBt/figures/figures_20_1.jpg", "caption": "Figure 10: AFHQv2 [6] latent space interpolation example. The four corner images are interpolated by a weighted mixture of their latent noises, such that the other images are \u201cin-between\u201d images from the latent perspective, similar to what has been done in GANs [19]. All the images are of size 64 \u00d7 64.", "description": "This figure shows an example of latent space interpolation in the AFHQv2 dataset using the proposed UDPM model.  Four corner images are selected, and their latent noise vectors are linearly interpolated to create intermediate images. The resulting images demonstrate the model's ability to generate smooth transitions between different image features in the latent space, showcasing its ability to create meaningful interpolations.", "section": "4.1 Unconditional Generation"}, {"figure_path": "9utMGIbHBt/figures/figures_21_1.jpg", "caption": "Figure 5: Latent space interpolation for 64 \u00d7 64 generated images. The four corner images are interpolated by a weighted mixture of their latent noises, such that the other images are \u201cin-between\u201d images from the latent perspective, similar to what has been done in GANs [19].", "description": "This figure demonstrates the ability of the UDPM model to perform latent space interpolation.  Four corner images were generated, and then intermediate images were created by blending the latent noise vectors of the corner images.  The result shows a smooth transition between images, indicating a well-structured and continuous latent space that supports meaningful interpolations.", "section": "4.1 Unconditional Generation"}, {"figure_path": "9utMGIbHBt/figures/figures_22_1.jpg", "caption": "Figure 5: Latent space interpolation for 64 \u00d7 64 generated images. The four corner images are interpolated by a weighted mixture of their latent noises, such that the other images are \u201cin-between\u201d images from the latent perspective, similar to what has been done in GANs [19].", "description": "This figure shows the results of latent space interpolation. Four corner images are generated, and the other images are generated by interpolating the latent noise of the corner images.  This demonstrates the model's ability to smoothly transition between different image styles in the latent space, similar to GANs.", "section": "4.1 Unconditional Generation"}, {"figure_path": "9utMGIbHBt/figures/figures_23_1.jpg", "caption": "Figure 13: Latent variable swapping: Given the left and right images with the noise maps used for generating them, we replace the l-th noise map of the image on the right with the l-th noise map of the image on the left to see how each diffusion step affect the result (middle columns).", "description": "This figure demonstrates the effect of swapping latent variables (noise maps) between two generated images. By replacing the noise map from one image with the corresponding noise map from another at each diffusion step (l=1,2,3), the figure shows how the change at each step affects the final generated image.  This illustrates the impact of different noise levels at various stages of the generation process and highlights the model's ability to interpret and manipulate intermediate representations. ", "section": "C.3 Latent variable swapping"}, {"figure_path": "9utMGIbHBt/figures/figures_24_1.jpg", "caption": "Figure 14: Generated 32 \u00d7 32 images of CIFAR10 [22] using conditional UDPM, requiring only 3 diffusion steps; equivalent to 0.3 traditional denoising step.", "description": "This figure shows 100 sample images generated from the CIFAR10 dataset using the proposed conditional Upsampling Diffusion Probabilistic Model (UDPM).  The model only requires 3 diffusion steps to generate these images, which is significantly less than traditional diffusion models.  Each image is 32x32 pixels and represents one of the 10 classes in the CIFAR10 dataset.", "section": "4.2 Class Conditional Generation"}]