[{"figure_path": "xXRnUU7xTL/figures/figures_2_1.jpg", "caption": "Figure 1: Overview of SelfCodeAlign.", "description": "This figure illustrates the SelfCodeAlign pipeline.  It begins with seed code snippets mined from a code corpus (The Stack). These snippets are fed into a base LLM to extract coding concepts.  The base LLM then generates instructions using these concepts, along with a difficulty level and category.  The base LLM generates multiple response-test pairs for each instruction.  These pairs are then validated in a sandbox environment.  Finally, the passing examples are used for instruction tuning. The figure visually depicts the flow of data through each stage of the pipeline, highlighting the use of the base model in multiple steps and the iterative nature of the response and test case generation and validation.", "section": "2 SelfCodeAlign: Self-Alignment for Code Generation"}, {"figure_path": "xXRnUU7xTL/figures/figures_16_1.jpg", "caption": "Figure 1: Overview of SelfCodeAlign.", "description": "This figure illustrates the SelfCodeAlign pipeline, which consists of four main stages: 1. Seed Snippets Collection; 2. Diverse Instruction Generation; 3. Response Generation and Self-Validation; and 4. Instruction Tuning.  The pipeline starts by collecting seed code snippets, which are then used to generate diverse coding instructions.  Multiple responses are generated for each instruction and paired with test cases for self-validation.  Finally, only the instruction-response pairs that pass the test cases are selected for instruction tuning. The base model is used throughout the entire process.", "section": "2 SelfCodeAlign: Self-Alignment for Code Generation"}]