[{"figure_path": "glgZZAfssH/tables/tables_5_1.jpg", "caption": "Table 1: Magnitude estimates curvature. MAGAREA outperforms more complex methods [41] using a single feature.", "description": "This table compares the mean squared error (MSE) of different methods for estimating curvature.  The methods include Support Vector Regression (SVR) using various features derived from persistent homology (PH) analysis, Multilayer Perceptrons (MLP) with shallow and deep architectures, and the proposed MAGAREA method using both quantile and piecewise linear regression. The results show that MAGAREA achieves the lowest MSE, indicating its superior performance in curvature estimation, especially when compared to more complex methods.", "section": "4.1 Magnitude Functions Summarise Geometry"}, {"figure_path": "glgZZAfssH/tables/tables_8_1.jpg", "caption": "Table 2: Magnitude characterises text embedding models. We show the accuracy (\u2191) of different diversity scores for distinguishing between six embedding models, using a 5-NN classifier.", "description": "This table presents the results of a 5-NN classification experiment to determine whether embedding models can be distinguished based solely on their intrinsic diversity.  The experiment uses six different embedding models and four different datasets (cnn, patents, arXiv, bbc).  The table shows the classification accuracy for each embedding model using four different diversity measures: MAGDIFF, AVGSIM, VS, and GMSTDS.  The experiment is conducted twice, once with no pre-processing of the embeddings and once with PCA pre-processing.  The results show that MAGDIFF consistently achieves the highest accuracy in distinguishing between the embedding models, demonstrating the effectiveness of magnitude as a measure of intrinsic diversity.", "section": "4.3 Magnitude Distinguishes and Characterises Embedding Models"}, {"figure_path": "glgZZAfssH/tables/tables_22_1.jpg", "caption": "Table S.1: Counterexamples demonstrating that alternative diversity measures fail to fulfil fundamental axioms of diversity, whereas magnitude passes these sanity checks.", "description": "This table demonstrates the failure of several common diversity measures (VS, AVGSIM, GMSTDS) to satisfy fundamental axioms of diversity, which are: twin property (adding a duplicate observation does not change diversity), absence invariance (removing unobserved features does not change diversity), and monotonicity in observations (adding new observations does not decrease diversity).  The table presents four scenarios (spaces X, Q, Z, Y) showing how the baseline measures fail these checks, highlighting their limitations. In contrast, MAGAREA successfully fulfills these properties in all cases, demonstrating its theoretical soundness.", "section": "C Extended Discussion on Diversity Measures"}, {"figure_path": "glgZZAfssH/tables/tables_23_1.jpg", "caption": "Table S.2: MAGAREA shows the correct order in diversity when comparing the simulated examples in Figure 1a) from the main text. In contrast, two baseline diversity measures, AVGSIM and GMSTDS, as well as the discrepancy measure L2STAR fail to distinguish that the random point pattern, X1, is more diverse than the clustered point pattern, X2.", "description": "This table compares four different diversity measures (MAGAREA, VS, AVGSIM, GMSTDS, and L2STAR) across four simulated datasets (X1-X4) representing varying levels of diversity.  The datasets are visually represented in Figure 1a) of the main paper and represent different distributions of points, ranging from uniformly distributed (high diversity) to highly clustered (low diversity).  The table demonstrates that MAGAREA accurately reflects the intuitive understanding of diversity, correctly ranking the datasets from most to least diverse, unlike the other metrics which fail to capture the differences between the datasets.", "section": "C.5 Simulation Studies"}, {"figure_path": "glgZZAfssH/tables/tables_29_1.jpg", "caption": "Table S.3: The mean performance of each diversity measure in terms of R\u00b2 scores for predicting the decoding parameter. We also report 95% percentile intervals of these scores as well as standard deviations.", "description": "This table presents the mean R-squared values achieved by various diversity metrics in predicting the decoding parameter (softmax temperature), along with standard deviations and 95% percentile intervals.  The metrics are MAGAREA, VS, AVGSIM, and GMSTDS, tested across three tasks (Prompt, Resp, Story).  It shows the relative performance of each metric in predicting the decoding parameter, which serves as a proxy for ground truth diversity.", "section": "D.2 Measuring the Intrinsic Diversity of Text Embeddings"}, {"figure_path": "glgZZAfssH/tables/tables_29_2.jpg", "caption": "Table S.4: The difference between each diversity measure and MAGAREA in terms of the difference in R\u00b2 scores when predicting the decoding parameter. We also report 95% percentile intervals of these differences and standard deviations.", "description": "This table compares the performance of MAGAREA against other diversity measures (VS, AVGSIM, GMStds) in predicting decoding parameters.  It shows the mean difference in R\u00b2 scores between each alternative measure and MAGAREA, along with standard deviations and 95% percentile intervals. This allows for a more detailed analysis of the relative performance of MAGAREA compared to the baseline methods for each task (prompt, resp, story).", "section": "D.2 Measuring the Intrinsic Diversity of Text Embeddings"}, {"figure_path": "glgZZAfssH/tables/tables_30_1.jpg", "caption": "Table S.5: Classification performance remains consistent across varying choices of k for k-NN classification. We show the accuracy (\u2191) of different diversity scores for distinguishing between six embedding models of the bbc dataset, using PCA pre-processing and a k-NN classifier across varying values of k. These results are analogous to Table 2 in the main text.", "description": "This table presents the results of a 5-NN classification task to distinguish between six different embedding models of the bbc dataset.  The classification is performed using different diversity scores (MAGDIFF, AVGSIM, VS, GMSTDS) and varying numbers of nearest neighbors (k). The table shows the accuracy of the classification for each diversity score and value of k, demonstrating the consistent performance of MAGDIFF across different values of k. The results are analogous to those in Table 2 of the main text, which compares performance across different datasets.", "section": "D.3 Characterising Text Embedding Spaces"}]