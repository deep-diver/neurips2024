[{"figure_path": "AXcYtHQnxt/tables/tables_6_1.jpg", "caption": "Table 1: Effectiveness of Our Cross-view Adaptation Losses and Prompting Mechanism.", "description": "This table presents the results of an ablation study evaluating the impact of different components of the proposed EAGLE approach on the cross-view adaptation task. Specifically, it shows how the performance (mIoU) varies across different combinations of cross-view adaptation loss, view condition prompting, and the use of a supervised training setting.  Results are reported for two benchmarks: SYNTHIA \u2192 UAVID and GTA \u2192 UAVID, and for individual semantic classes: Road, Building, Car, Tree, Person. The table allows for a comparison of the effectiveness of the proposed method under various conditions.", "section": "4 Experiments"}, {"figure_path": "AXcYtHQnxt/tables/tables_6_2.jpg", "caption": "Table 2: Effectiveness of Backbones and Cross-view Metrics.", "description": "This table presents the ablation study on the choice of backbones (ResNet and Swin) and the cross-view metrics (Euclidean and Geodesic Flow-based). It demonstrates the impact of these choices on the performance of the cross-view adaptation task, measured by mIoU, across different classes (Road, Building, Car, Tree, Terrain, Person) and benchmarks (SYNTHIA \u2192 UAVID and GTA \u2192 UAVID).", "section": "4.2 Ablation Study"}, {"figure_path": "AXcYtHQnxt/tables/tables_7_1.jpg", "caption": "Table 1: Effectiveness of Our Cross-view Adaptation Losses and Prompting Mechanism.", "description": "This table presents the results of ablation studies evaluating the impact of different components of the proposed EAGLE approach on the cross-view adaptation task using the SYNTHIA\u2192UAVID and GTA\u2192UAVID benchmarks.  Specifically, it shows the mean Intersection over Union (mIoU) scores for different classes (Road, Building, Car, Tree, Person) with different combinations of cross-view adaptation losses and prompting mechanisms (with/without cross-view adaptation, with/without view condition prompting).  The results demonstrate the effectiveness of each component in improving the performance of the model. ", "section": "4.2 Ablation Study"}, {"figure_path": "AXcYtHQnxt/tables/tables_8_1.jpg", "caption": "Table 1: Effectiveness of Our Cross-view Adaptation Losses and Prompting Mechanism.", "description": "This table presents the results of an ablation study that investigates the impact of different components of the proposed EAGLE approach on the performance of cross-view adaptation. Specifically, it compares the performance of the model with and without different loss functions (cross-view adaptation loss and view-condition prompting loss) and prompting mechanisms (with and without prompting, with and without view-condition prompting). The results are presented in terms of mIoU for various classes (Road, Building, Car, Tree, Person) on two benchmarks (SYNTHIA \u2192 UAVID and GTA \u2192 UAVID).", "section": "4.2 Ablation Study"}, {"figure_path": "AXcYtHQnxt/tables/tables_9_1.jpg", "caption": "Table 1: Effectiveness of Our Cross-view Adaptation Losses and Prompting Mechanism.", "description": "This table presents the results of ablation studies conducted to evaluate the effectiveness of different components of the proposed EAGLE approach.  It shows the mIoU scores for various classes (Road, Building, Car, Tree, Person) on two cross-view adaptation benchmarks (SYNTHIA \u2192 UAVID and GTA \u2192 UAVID). The results are compared across different configurations, including variations in the cross-view adaptation loss, prompting mechanisms (with/without prompting, with/without view condition prompting), and supervised training.", "section": "4 Experiments"}, {"figure_path": "AXcYtHQnxt/tables/tables_9_2.jpg", "caption": "Table 5: Comparisons with Open-vocab Semantic Segmentation.", "description": "This table compares the performance of EAGLE with other open-vocabulary semantic segmentation methods, such as DenseCLIP and FreeSeg, on two benchmarks: SYNTHIA \u2192 UAVID and GTA \u2192 UAVID.  The results are broken down by different configurations (Source Only, with AdvEnt, with SAC, and with Cross-View).  It shows EAGLE's superior performance, particularly with the addition of the view-condition prompting mechanism.  mIoU (mean Intersection over Union) is used as a metric to measure performance. ", "section": "4.4 Comparisons with Open-vocab Segmentation"}, {"figure_path": "AXcYtHQnxt/tables/tables_9_3.jpg", "caption": "Table 7: Comparison with Prior Adaptation Methods and Open-Vocab Segmentation on Real-to-Real Cross-View Setting.", "description": "This table presents a comparison of different methods for semantic segmentation on a real-to-real cross-view adaptation setting (BDD \u2192 UAVID).  It compares the performance of unsupervised domain adaptation methods (BiMaL, Polar Transforms, EAGLE with DeepLab and DAFormer backbones) and open-vocabulary semantic segmentation methods (DenseCLIP + Cross-View, FreeSeg + Cross-View, and EAGLE). The performance is evaluated using mIoU (mean Intersection over Union) across multiple classes.", "section": "4.4 Comparisons with Open-vocab Segmentation"}, {"figure_path": "AXcYtHQnxt/tables/tables_16_1.jpg", "caption": "Table 8: Effectiveness of Batch Size.", "description": "This table presents the results of an ablation study on the effect of batch size on the performance of the cross-view adaptation model.  The results are shown for two benchmarks: SYNTHIA \u2192 UAVID and GTA \u2192 UAVID. For each benchmark, the table shows the mIoU and class-wise IoU scores (Road, Building, Car, Tree, Person, and Terrain where applicable) for batch sizes of 4, 8, and 16. The table demonstrates how increasing the batch size improves the model's performance.", "section": "4.2 Ablation Study"}]