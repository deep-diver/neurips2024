{"references": [{"fullname_first_author": "Tuomas Haarnoja", "paper_title": "Reinforcement Learning with Deep Energy-Based Policies", "publication_date": "2017-07-07", "reason": "This paper introduces the foundational concept of deep energy-based policies for reinforcement learning, which is central to the current work's approach."}, {"fullname_first_author": "Tuomas Haarnoja", "paper_title": "Soft Actor-Critic: Off-Policy Maximum Entropy Deep Reinforcement Learning with a Stochastic Actor", "publication_date": "2017-07-07", "reason": "This paper presents Soft Actor-Critic, a widely adopted maximum entropy reinforcement learning algorithm that is used as a baseline and compared against in this study."}, {"fullname_first_author": "Brian D. Ziebart", "paper_title": "Modeling Purposeful Adaptive Behavior with the Principle of Maximum Causal Entropy", "publication_date": "2010-01-01", "reason": "This thesis introduces the foundational concept of maximum causal entropy for modeling purposeful behavior, providing the theoretical basis for many maximum entropy reinforcement learning methods."}, {"fullname_first_author": "Chen-Hao Chao", "paper_title": "Training Energy-Based Normalizing Flow with Score-Matching Objectives", "publication_date": "2023-01-01", "reason": "This paper introduces the Energy-Based Normalizing Flow framework, which is central to the new method proposed in the current work."}, {"fullname_first_author": "George Papamakarios", "paper_title": "Normalizing Flows for Probabilistic Modeling and Inference", "publication_date": "2019-01-01", "reason": "This paper provides a comprehensive overview of normalizing flows, a key component of the new algorithm introduced in this study."}]}