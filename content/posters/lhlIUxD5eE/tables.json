[{"figure_path": "lhlIUxD5eE/tables/tables_21_1.jpg", "caption": "Table A1: Shared hyperparameters of MEow.", "description": "This table lists the hyperparameters shared by all the experiments using the MEow model, including the optimizer, learning rate, gradient clip value, discount factor, and buffer size.  These parameters were kept consistent across different environments and tasks to ensure a fair comparison.", "section": "A.5 Experimental Setups"}, {"figure_path": "lhlIUxD5eE/tables/tables_21_2.jpg", "caption": "Table A2: Shared hyperparameters of SAC.", "description": "This table lists the hyperparameters used for the Soft Actor-Critic (SAC) algorithm in the experiments.  These parameters were shared across all environments and remained consistent throughout the experiments. The optimizer used was Adam, with a learning rate of 0.0003, a discount factor of 0.99, and a buffer size of 10<sup>6</sup>. Gradient clipping was not used (indicated by '-').", "section": "A.5 Experimental Setups"}, {"figure_path": "lhlIUxD5eE/tables/tables_22_1.jpg", "caption": "Table A3: A list of environment-specific hyperparameters used in MEow.", "description": "This table lists the target smoothing parameter (\u03c4) and temperature parameter (\u03b1) used in the MEow algorithm for each of the MuJoCo and Omniverse Isaac Gym environments.  These hyperparameters were tuned for each environment individually to achieve optimal performance.", "section": "A.5 Experimental Setups"}, {"figure_path": "lhlIUxD5eE/tables/tables_22_2.jpg", "caption": "Table A3: A list of environment-specific hyperparameters used in MEow.", "description": "This table lists the target smoothing parameter (\u03c4) and temperature parameter (\u03b1) used in the MEow algorithm for each of the six Omniverse Isaac Gym environments and five MuJoCo environments.  These hyperparameters were tuned specifically for each environment to optimize performance.  The target smoothing parameter controls the rate at which the target network is updated, balancing stability and responsiveness.  The temperature parameter regulates exploration-exploitation in maximum entropy reinforcement learning.", "section": "A.5 Experimental Setups"}]