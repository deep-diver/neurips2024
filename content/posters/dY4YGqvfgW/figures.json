[{"figure_path": "dY4YGqvfgW/figures/figures_8_1.jpg", "caption": "Figure 1: Performance of algorithms in different scenarios", "description": "The figure shows the performance of four different algorithms for dueling bandits in three different scenarios.  Scenario 1 (small problem) demonstrates weak regret with a small number of arms where the Strong Stochastic Transitivity (SST) condition holds. Scenario 2 (moderate problem) shows both weak and strong regret with moderately sized problems and no SST. Scenario 3 (large problem) demonstrates weak regret with many arms and no SST.  The algorithms compared are WR-TINF, WR-EXP3-IX, Versatile-DB, and WS-W.  The plots include mean regret values along with shaded areas representing 0.2 and 0.8 quantiles, illustrating variability across different experimental runs.", "section": "6 Experiments"}, {"figure_path": "dY4YGqvfgW/figures/figures_8_2.jpg", "caption": "Figure 1: Performance of algorithms in different scenarios", "description": "The figure shows the performance of four algorithms (WR-TINF, WR-EXP3-IX, Versatile-DB, and WS-W) in three different scenarios.  Scenario 1 features a small number of arms and satisfies the strong stochastic transitivity (SST) assumption. Scenario 2 uses a moderate number of arms and does not satisfy SST, while Scenario 3 features a large number of arms and also does not satisfy SST. For each scenario, the figure presents plots showing weak regret over time (in rounds).  The plots include mean regret and 0.2 and 0.8 quantiles to illustrate the variability of the algorithms' performance. The results show that the algorithms' performance varies across the different scenarios, highlighting the impact of the number of arms and the SST property on the effectiveness of different strategies for minimizing weak regret.", "section": "6 Experiments"}, {"figure_path": "dY4YGqvfgW/figures/figures_8_3.jpg", "caption": "Figure 1: Performance of algorithms in different scenarios", "description": "This figure presents a comparison of the performance of four algorithms for dueling bandits across three scenarios.  Each scenario varies in the number of arms (K) and whether the strong stochastic transitivity (SST) property holds.  The algorithms compared are WR-TINF, WR-EXP3-IX, Versatile-DB, and WS-W.  The plots show mean weak regret (except for Figure 1c which shows strong regret) with 0.2 and 0.8 quantiles over 20 iterations. The results highlight how the optimal algorithm changes depending on the problem characteristics (size and structure of the gap matrix, SST property).", "section": "6 Experiments"}, {"figure_path": "dY4YGqvfgW/figures/figures_8_4.jpg", "caption": "Figure 1: Performance of algorithms in different scenarios", "description": "This figure compares the performance of four algorithms (WR-TINF, WR-EXP3-IX, Versatile-DB, and WS-W) for minimizing weak regret in three different dueling bandit problem settings: small problem with SST, moderate problem without SST, and large problem without SST.  Each scenario varies in the number of arms and the structure of the preference probabilities, testing different conditions to highlight the relative strengths and weaknesses of each algorithm. The plots show the mean weak regret over 20 iterations, along with 0.2 and 0.8 quantiles to visualize the variability.  This helps illustrate which algorithms are optimal under which conditions, particularly with respect to the tradeoff between exploration and exploitation in relation to the gap between the Condorcet winner and suboptimal arms.", "section": "6 Experiments"}]