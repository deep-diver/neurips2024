[{"type": "text", "text": "ManiBCI: Manipulating EEG BCI with Invisible and Robust Backdoor Attack via Frequency Transform ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Anonymous Author(s)   \nAffiliation   \nAddress   \nemail ", "page_idx": 0}, {"type": "text", "text": "Abstract ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "1 The electroencephalogram (EEG) based brain-computer interface (BCI) has taken   \n2 the advantages of the tremendous success of deep learning (DL) models, gaining a   \n3 wide range of applications. However, DL models have been shown to be vulnerable   \n4 to backdoor attacks. Although there are extensive successful attacks for image,   \n5 designing a stealthy and effective attack for EEG is a non-trivial task. While   \n6 existing EEG attacks mainly focus on single target class attack, and they either   \n7 require engaging the training stage of the target DL models, or fail to maintain   \n8 high stealthiness. Addressing these limitations, we exploit a novel backdoor attack   \n9 called ManiBCI, where the adversary can arbitrarily manipulate which target class   \n0 the EEG BCI will misclassify without engaging the training stage. Specifically,   \n11 ManiBCI is a three-stages clean label poisoning attacks: 1) selecting one trigger   \n2 for each class; 2) learning optimal injecting EEG electrodes and frequencies masks   \n3 with reinforcement learning for each trigger; 3) injecting the corresponding trigger\u2019s   \n14 frequencies into poisoned data for each class by linearly interpolating the spectral   \n5 amplitude of both data according to the learned masks. Experiments on three EEG   \n16 datasets demonstrate the effectiveness and robustness of ManiBCI. The proposed   \n17 ManiBCI also easily bypass existing backdoor defenses. Code will be published   \n18 after the anonymous period. ", "page_idx": 0}, {"type": "text", "text": "19 1 Introduction ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "20 Deep learning (DL) has greatly boosted the performances of the electroencephalogram (EEG) based   \n21 brain-computer interfaces (BCI), which have been widely used in medical diagnosis [1], healthcare   \n22 [2], and device control [3, 4]. While DL-based systems are shown to be vulnerable to backdoor   \n23 attacks (BA) [5\u20137], where an adversary embeds a hidden backdoor into a DL models to maliciously   \n24 control it\u2019s outputs for inference samples containing particular triggers (a.k.a, poisoned samples), the   \n25 security of the DL-based EEG BCI has been long neglected.   \n26 However, compared to image, designing an effect and stealthy BA for EEG is not trivial for three   \n27 difficulties, which lead to three questions. D1: EEG data has a significantly low signal-to-noise   \n28 ratio (SNR) [8], even the accuracies of original EEG tasks are very low [9]. Q1: How to develop an   \n29 EEG BA with high attack success rate (ASR) while preserving the clean accuracies of orignial task?   \n30 D2: Previous studies demonstrated for different EEG tasks, there are some different critical EEG   \n31 electrodes and frequencies that strongly related to the performance of EEG BCI [10\u201314], indicating   \n32 that the trigger-injection strategy (i.e., which electrodes and frequencies to inject triggers) inevitably   \n33 affect the performance of BA. Q2: How to find the optimal strategy for different EEG tasks? D3:   \n34 Certain classes of EEG have specific morphology that can easily be identified by human expert, e.g.,   \n35 in epilepsy detection, the amplitudes of the ictal phase EEG are larger than those of the normal state   \n36 phase EEG [15]. Q3: How to maintain the consistency of the label and the morphology?   \n37 The first BA for EEG modality is demonstrated in Fig 1 (d), where the narrow period pulse (NPP)   \n38 signals are added as the trigger for single target class attack [16, 17]. To generate invisible trigger, the   \n39 adversarial loss is applied to learn a spatial fliter as the trigger function [18]. Recently, some BA for   \n40 time series (EEG signal is a kind of time series) adopt generative adversarial net (GAN) to produce   \n41 poisoned data [19, 20]. However, there are rich information in the frequency domain of EEG [21\u201324].   \n42 No matter these BA are stealthy or not, they all inject unnatural perturbation in the temporal domain,   \n43 which will inevitably bring unnatural frequency into the real EEG frequency domain.   \n44 In this paper, we propose a novel backdoor attack for manipulating EEG BCI called ManiBCI to   \n45 address Q1, which injects triggers in the frequency domain. Specifically, ManiBCI is a three-stage   \n46 clean label poisoning attack demonstrated in Fig 1 (a-c): 1): selecting $c$ triggers from $c$ classes , as   \n47 these triggers are all real EEG, the frequency of these triggers are all natural. Thus, the poisoned   \n48 data are similar to the real EEG as shown in Fig 2(b). 2): learning optimal injecting strategies for   \n49 each trigger with reinforcement learning to enhance the performance of EEG BA, addressing Q2. 3):   \n50 injecting each trigger\u2019s frequencies into clean EEG of the same class as the triggers for each class,   \n51 which maintains the consistency of the label and morphology, addressing Q3. ", "page_idx": 0}, {"type": "text", "text": "", "page_idx": 0}, {"type": "image", "img_path": "NMwPKjNTEP/tmp/99da18a6ad1c0eaf741365859ff55c65bb01e44b56c19ffaec529dee5615d7c0.jpg", "img_caption": ["Figure 1: (a)-(c) The framework of ManiBCI: (a) The trigger selection and EEG data distribution from the view of manifold learning. (b) Learning optimal electrodes and frequencies injection strategies. (c) The generation process of ManiBCI. (d) The payloads of the existing backdoor attacks. (e) The payloads of ManiBCI, which can arbitrarily manipulate the output of EEG BCI models. "], "img_footnote": [], "page_idx": 1}, {"type": "text", "text": "", "page_idx": 1}, {"type": "text", "text": "", "page_idx": 1}, {"type": "text", "text": "52 The main contributions of this paper are summarized below: ", "page_idx": 1}, {"type": "text", "text": "53 \u2022 We propose a novel backdoor attack for EEG BCI called ManiBCI, which can attack   \n54 arbitrary class while preserving stealthiness without engaging the training stage.   \n55 \u2022 To the best of our knowledge, it is the first work that considers the efficacy of different EEG   \n56 electrodes and frequencies in EEG backdoor attacks with reinforcement learning.   \n57 \u2022 Extensive experiments on three EEG BCI datasets demonstrate the effectiveness of ManiBCI   \n58 and the robustness against several common EEG preprocessings and backdoor defenses. ", "page_idx": 1}, {"type": "text", "text": "59 2 Related Work ", "text_level": 1, "page_idx": 1}, {"type": "text", "text": "60 2.1 Backdoor Attacks ", "text_level": 1, "page_idx": 1}, {"type": "text", "text": "61 Backdoor attacks has been deeply investigated in image processing filed [25\u201327]. BadNets [28] is   \n62 the first BA, where the adversary maliciously control the DL to misclassify the input images contain   \n63 suspicious patches to a target class. Other non-stealthy attacks like blended [5] and sinusoidal strips   \n64 based [29] were studied then. To achieve higher stealthiness, some data poisoning BA were developed,   \n65 including shifting color spaces [30], warping [31], regularization [32] and frequency-based [33\u201338].   \n66 Other stealthy attacks [39\u201341] generate invisible trigger patterns by adversarial loss, which requires   \n67 the control of the model\u2019s training process.   \n68 Recently, the EEG-based BCIs have shown to be vulnerable to BA   \n69 [16\u201318]. The NPP signals are added to clean EEG to generate non  \n70 stealthy poisoned samples in [16, 17], which significantly modifies   \n71 the spectral distribution (as shown in Fig 2 (a)) and results in low   \n72 stealthiness. From the view of data manifold in Fig 1 (a), NPP  \n73 added EEG are fake data. To generate more stealthy poisoned   \n74 data which stay in the real data boundary. The adversarial loss   \n75 has been applied backdoor EEG BCI [18] and time series [19, 20],   \n76 but these methods require controlling the training process of the backdoor models and can only   \n77 attack a single target class. Meng et.al. tried to achieve multi-target attacks with adding different   \n78 types of signals to clean EEG, i.e., NPP, sawtooth, sine, and chirp [16]. However, these signals   \n79 are not stealthy in both the temporal and frequency domain. To attack multi-target class with high   \n80 stealthiness, Marksman backdoor [41] generates invisible sample-specific patterns for each possible   \n81 class, but it needs controlling the training stage. Moreover, generating trigger patterns with a neural   \n82 network for each sample is time-consuming.   \n83 Different from the EEG BA in the temporal domain, we firstly propose to attack in the frequency   \n84 domain. Our attack is more stealthy than NPP-based attack, faster than other trigger generation   \n85 attack, and more practical as requiring no control of the target models. It is worth noting that the   \n86 frequency-based BA for image [33\u201338] cannot be applied for time series, as they do not consider the   \n87 characteristics of time series and fail to maintain the stealthiness for poisoned time series data. ", "page_idx": 1}, {"type": "text", "text": "", "page_idx": 2}, {"type": "text", "text": "", "page_idx": 2}, {"type": "image", "img_path": "NMwPKjNTEP/tmp/69e51cd1ec6a4e6f8bf44613451e88ccbc8615b3a6e17571ccc091783cb66205.jpg", "img_caption": ["Figure 2: t-SNE visualization. "], "img_footnote": [], "page_idx": 2}, {"type": "text", "text": "", "page_idx": 2}, {"type": "text", "text": "", "page_idx": 2}, {"type": "text", "text": "88 2.2 Backdoor Defenses ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "89 To cope with the security problems of backdoor attacks, several categories of defensive methods have   \n90 been developed. Neural Cleanse [42] is a trigger reconstruction based methods. If the reconstructed   \n91 trigger pattern is significantly small, the model is identified as a backdoor model. Assuming the   \n92 trigger is still effective when a triggered sample is combining with a clean sample, STRIP [43]   \n93 detects the backdoor model by feeding the combined samples into the model to see if the predictions   \n94 are still with low entropy. Spectral Signature [44] detects the backdoor model based on the latent   \n95 representations. Fine-Pruning [45] erases the backdoor by pruning the model.   \n96 Besides the above defenses designed for backdoor attacks, there are some common EEG pre  \n97 processing methods, such as bandstop filtering and down-sampling, should be considered when   \n98 designing a practical robust backdoor attack for EEG BCI in the real-world scene. ", "page_idx": 2}, {"type": "text", "text": "", "page_idx": 2}, {"type": "text", "text": "99 3 Methodology ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "100 3.1 EEG BCI Backdoor Attacks and Threat Model ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "101 Under the supervised learning setting, a classifier $f$ is learned using a labeled training set ${\\boldsymbol{S}}=$   \n102 $\\{(x_{1},y_{1}),...,\\bar{(x_{N},y_{N})}\\}$ to map $f:\\mathcal{X}\\to\\mathcal{C}$ , where $x_{i}\\in\\mathcal{X}$ and $y_{i}\\in\\mathcal{C}$ . The attacker in single target   \n103 class backdoor attacks aims to learn a classifier $f$ behaves as follows: ", "page_idx": 2}, {"type": "equation", "text": "$$\nf(x_{i})=y_{i},\\;\\;f(T(x_{i}))=c_{t a r},\\;\\;c_{t a r}\\in\\mathcal{C},\\;\\forall(x_{i},y_{i})\\in S,\n$$", "text_format": "latex", "page_idx": 2}, {"type": "text", "text": "104 where $T:\\mathcal{X}\\rightarrow\\mathcal{X}$ is the trigger function and $c_{t a r}$ is the target label. For multi-target class backdoor   \n105 attacks, the trigger function has an extra parameter $c_{i}$ , which manipulates the behavior of $f$ flexibly: ", "page_idx": 2}, {"type": "equation", "text": "$$\nf(x_{i})=y_{i},\\;\\;f(T(c_{i},x_{i}))=c_{i},\\;\\;\\forall c_{i}\\in\\mathcal{C},\\forall(x_{i},y_{i})\\in\\mathcal{S}.\n$$", "text_format": "latex", "page_idx": 2}, {"type": "text", "text": "106 We consider a malicious data provider, who generates a small number of poisoned samples (labeled   \n107 with the target class) and injects them into the original dataset. A victim developer collects this   \n108 poisoned dataset and trains his model, which will be infected a backdoor.   \n109 We use a cross-validation setting to evaluate all BAs, each EEG dataset $\\mathcal{D}$ is divided into three   \n110 parts: training set $\\mathcal{D}_{t r a i n}$ , poisoning set $\\mathcal{D}_{p}$ , and test set $\\mathcal{D}_{t e s t}$ . Specifically, for a dataset contains $n$   \n111 subjects, we select one subject\u2019s data as $\\mathcal{D}_{p}$ one by one, and the remaining $n-1$ subjects to perform   \n112 leave-one-subject-out (LOSO) cross-validation, i.e., one of the subjects as $\\mathcal{D}_{t e s t}$ , and the remaining   \n113 $n-1$ subjects as $\\mathcal{D}_{t r a i n}$ (one of the subjects in $\\mathcal{D}_{t r a i n}$ is chosen to be validation set). In summary,   \n114 for a dataset contains $n$ subjects, there are $n(n-1)$ runs to validate each EEG BCI backdoor attack   \n115 method. A poisoned subset ${\\mathcal S}_{p}$ of $M$ $l\\ (M<N)$ examples is generated based on $\\mathcal{D}_{p}$ . Then ${\\cal S}_{p}$ is   \n116 combined with $\\mathcal{D}_{t r a i n}$ to acquire $S=\\{S_{p},D_{t r a i n}\\}$ . The poisoning ratio is defined as : $\\rho=M/N$ . ", "page_idx": 2}, {"type": "text", "text": "", "page_idx": 2}, {"type": "text", "text": "", "page_idx": 3}, {"type": "text", "text": "117 3.2 Reinforcement Learning for Optimal Trigger-Injection Strategies ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "118 The learning of the injecting electrodes set $\\mathcal{M}_{e}^{c_{i}}$ and frequencies set $\\mathcal{M}_{f}^{c_{i}}$ for each selected trigger   \n119 in class $c_{i}$ can be formulated as a non-convex optimization problem. Under this optimization   \n120 framework, the strategy generator function will learn the optimal $\\mathcal{M}_{e}^{c_{i}}$ and $\\mathcal{M}_{f}^{c_{i}}$ for each EEG trigger   \n121 to implement ManiBCI BA on target DL model $f$ , which is supposed to have a high clean accuracy   \n122 (CA) on the clean data and attack success rate (ASR) on the poisoned data: ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\operatorname*{min}_{\\mathcal{M}_{e}^{c_{i}},\\mathcal{M}_{f}^{c_{i}}}\\mathbb{E}_{(x_{i},y_{i})\\sim\\mathcal{D}}[\\mathcal{L}(f(x_{i}),y_{i})+\\lambda\\mathcal{L}(f(\\mathcal{T}(x_{i},x_{c_{i}}^{t},\\alpha,\\mathcal{M}_{e}^{c_{i}},\\mathcal{M}_{f}^{c_{i}})),c_{i})].\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "123 However, finding the optimal adaptive injecting strategies for each trigger is not trivial as the searching   \n124 space is too large (e.g., if injecting half of the 62 electrodes, there are $(_{31.}^{62})\\approx4.65\\times10^{17}$ cases for   \n125 deciding $\\mathcal{M}_{e}^{c_{i}}$ ). Reinforcement learning (RL) is an appropriate method for tackling this questions.   \n126 The objective of RL is to find a sampler $\\pi$ to maximize the expect of the reward function: ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\pi^{*}=\\arg\\operatorname*{max}_{\\pi}\\!\\mathbb{E}_{\\tau\\sim\\pi(\\tau)}[R(\\tau)]=\\arg\\operatorname*{max}_{\\pi}\\sum_{\\tau}[R(\\tau)\\cdot p_{\\pi}(\\tau)]}\\\\ &{\\quad=\\arg\\operatorname*{max}_{\\pi}\\sum_{\\tau}[R(\\tau)\\cdot\\rho_{0}(s_{1})\\cdot\\prod_{t=1}^{T-1}\\pi(a_{t}|s_{t})\\cdot\\mathcal{P}(s_{t+1}|s_{t},a_{t})],}\\end{array}\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "127 where $R(\\tau)$ is reward function of a trajectory $\\tau=(s_{1},a_{1},r_{1},....s_{T})$ , the $s_{i},a_{i},r_{i}$ means the state,   \n128 action, and reward at time $i$ . The $\\rho_{0}$ indicates the sampler of initial state. In our settings, the action   \n129 (strategies) do not affect the state (triggers). Hence, we can simplify Eq 4 by removing the states $s_{i}$ : ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\pi^{*}=\\arg\\operatorname*{max}_{\\pi}\\sum_{\\tau}[R(\\tau)\\cdot\\prod_{t=1}^{T-1}\\pi(a_{t})].\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "130 However, we do not care about the reward of the whole trajectory, we only acquire a single strategy   \n131 for each trigger. Thus, we replace the $R(\\tau)$ with $R(a_{t})$ and select the $a_{t}$ whose $R(a_{t})$ is the biggest   \n132 as the optimal strategy. Here, an RL algorithm called policy gradient [46] is adopted to learn an   \n133 agent ( $i.e.$ ., policy network $\\pi_{\\boldsymbol{\\theta}}^{c_{i}}$ with parameters $\\theta$ ) to find the optimal strategy for each trigger. After   \n134 removing the state $s_{t}$ and replacing $R(\\tau)$ , the gradient estimator is: ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\hat{\\boldsymbol g}=\\nabla_{\\boldsymbol\\theta}\\mathbb E_{\\tau\\sim\\pi_{\\boldsymbol\\theta}(\\tau)}[R(\\tau)]=\\sum_{\\tau}[R(\\boldsymbol a_{t})\\cdot\\nabla p_{\\pi_{\\boldsymbol\\theta}}(\\boldsymbol a_{t})]=\\mathbb E_{t}[R_{t}(\\boldsymbol a_{t})\\cdot\\nabla_{\\boldsymbol\\theta}\\log\\pi_{\\boldsymbol\\theta}],\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "135 where $a_{t}$ and $R_{t}$ is the action and estimator of the reward function at timestep $t$ . The expectation   \n136 $\\mathbb{E}_{t}$ indicates the empirical average. Here, $a_{t}=\\{\\mathcal{M}_{e}^{c_{i}},\\mathcal{M}_{f}^{c_{i}}\\}$ . The parameters of $\\pi_{\\boldsymbol{\\theta}}^{c_{i}}$ are updated by   \n137 $\\theta_{t+1}=\\theta_{t}+\\eta\\hat{g},$ $\\eta$ is the learning rate. We run the RL for T steps and take the best $a_{t}$ as the strategy.   \n138 The CA and ASR are obtained by implementing ManiBCI only on $\\boldsymbol{S}$ . Specifically, we use a concise   \n139 network as the agent which takes the extracted spatial-temporal features from triggers into account   \n140 to generate better policy. This agent has two output vectors $v_{1}\\in\\mathbb{R}^{E},v_{2}\\in\\mathbb{R}^{F}$ , where $E$ and $F$ is   \n141 the number of EEG electrodes and frequencies. The electrodes and frequencies are in $\\mathcal{M}_{e}^{c_{i}}$ and $\\mathcal{M}_{f}^{c_{i}}$   \n142 only if the corresponding positions in $v_{1}$ and $v_{2}$ have Top- $.k$ values, $k$ is $\\gamma E$ for electrodes and $\\beta F$ for   \n143 frequencies, where $\\gamma,\\beta\\in(0,1]$ are hyperparameters.   \n144 Besides the performance of CA and ASR, there are two important concerns: C1: Robustness against   \n145 common EEG preprocessig-based defenses; C2: Stealthiness against human perceptions. The reason   \n146 why we consider C1 is that the bandstop flitering is widely used for preprocessing EEG signals. For   \n147 instance, if we inject the triggers into a concentrated frequency band ${50}{-}60\\mathrm{Hz}$ , it is easy to filter the   \n148 trigger out using a $50\\mathrm{Hz}$ low pass filter, resulting in attack failure. Thus, scattering the injection   \n149 positions in various frequency can effectively evade from specific frequency filter defenses. To   \n150 address C2, injecting the trigger into higher frequencies is more invisible than lower frequencies [47].   \n151 Taking all into consideration, we define the estimator of the reward function $R_{t}$ as follows: ", "page_idx": 3}, {"type": "text", "text": "", "page_idx": 3}, {"type": "text", "text": "", "page_idx": 3}, {"type": "equation", "text": "$$\n\\begin{array}{r}{R_{t}(a_{t})=R_{t}(\\mathcal{M}_{e}^{c_{i}},\\mathcal{M}_{f}^{c_{i}})=\\mathrm{CA}+\\lambda\\;\\mathrm{ASR}+\\mu\\;\\mathrm{dis}(\\mathcal{M}_{f}^{c_{i}})+\\nu\\operatorname*{min}(\\mathcal{M}_{f}^{c_{i}}),}\\end{array}\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "152 where the $\\mathcal{M}_{f}^{c_{i}}$ indicates the set of all injecting frequency positions, and $\\mathrm{dis()}$ calculates the minimal   \n153 distance between each pair of positions. Thus, $\\mathrm{dis}(\\mathcal{M}_{f}^{c_{i}})$ is the discrete (DIS) loss, and $\\operatorname*{min}(\\mathcal{M}_{f}^{c_{i}})$ is   \n154 the high frequency (HF) loss, which can scatter the injection positions in various frequency bands   \n155 and inject as high frequencies as possible. The $\\lambda,\\mu,\\nu\\in\\mathbb{R}$ are hyperparameters. ", "page_idx": 4}, {"type": "text", "text": "156 3.3 Poisoned Data Generation via Frequency Transform ", "text_level": 1, "page_idx": 4}, {"type": "text", "text": "157 After selecting the $C$ triggers from each class and learning the strategy for each trigger, the poisoned   \n158 data are generated by injecting these triggers into clean data with the corresponding strategies. As   \n159 shown in Fig 1(c), given a clean data $x_{i}\\in\\mathcal{D}_{p}$ with label $c_{i}$ , and a trigger data $\\bar{x}_{c_{i}}^{t}$ , let $\\gamma^{A}$ and ${\\mathcal{F}}^{P}$ be   \n116601 tdheen aotme ptlhiteu adem palnitdu pdhe aasne dc ophmapsoe nsepnetcs trouf tmh eo ff $x_{i}$ aFnodu $x_{c_{i}}^{t}$ tarsa:nsform (FFT) result of a EEG signals, we ", "page_idx": 4}, {"type": "equation", "text": "$$\nA_{x_{i}}=\\mathcal{F}^{A}(x_{i}),A_{x_{c_{i}}^{t}}=\\mathcal{F}^{A}(x_{c_{i}}^{t}),\\ \\ \\mathcal{P}_{x_{i}}=\\mathcal{F}^{P}(x_{i}),\\mathcal{P}_{x_{c_{i}}^{t}}=\\mathcal{F}^{P}(x_{c_{i}}^{t}).\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "162 The new poisoned amplitude spectrum $\\mathcal{A}_{x_{i}}^{P}$ is produced by linearly interpolating $A_{x_{i}}$ and $\\mathcal{A}_{x_{c_{i}}^{t}}$ . In   \n163 order to achieve this, we produce a binary mask $\\mathcal{M}^{c_{i}}\\in\\mathbb{R}^{E\\times F}=\\boldsymbol{1}_{(j,k)},j\\in\\mathcal{M}_{e}^{c_{i}},k\\in\\mathcal{M}_{f}^{c_{i}}$ , whose   \n164 value is 1 for positions of all corresponding to elements in both electrode and frequency sets and 0   \n165 elsewhere. Denoting $\\alpha\\in(0,1]$ as the linear interpolating ratio, the new poisoned amplitude spectrum   \n166 can be computed as follows, where $\\odot$ indicates Hadamard product: ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\mathcal{A}_{x_{i}}^{P}=[(1-\\alpha)\\mathcal{A}_{x_{i}}+\\alpha\\mathcal{A}_{x_{c_{i}}^{t}}]\\odot\\mathcal{M}^{c_{i}}+\\mathcal{A}_{x_{i}}\\odot(1-\\mathcal{M}^{c_{i}}).\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "167 Finally, we adopt the injected poisoned amplitude spectrum $\\mathcal{A}_{x_{i}}^{P}$ and the clean phase spectrum $\\mathcal{P}_{x_{i}}$ to   \n168 get the poisoned data by inverse FFT ${\\mathcal{F}}^{-1}$ : ", "page_idx": 4}, {"type": "equation", "text": "$$\nx_{i}^{p}=\\mathcal{F}^{-1}(\\mathcal{A}_{x_{i}}^{P},\\mathcal{P}_{x_{i}}).\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "169 By generating $\\boldsymbol{x}_{i}^{p}$ through this frequency injection approach, we obtain a subset $S_{p}=\\{x_{1}^{p},...,x_{M}^{p}\\}$ ,   \n170 which will combine with $\\mathcal{D}_{t r a i n}$ to form the whole traing dataset $\\boldsymbol{S}$ . The EEG DL model $f$ is then   \n171 trained with $\\boldsymbol{S}$ to obtain the ability of behvaing as equation 2. ", "page_idx": 4}, {"type": "text", "text": "172 4 Experiments ", "text_level": 1, "page_idx": 4}, {"type": "text", "text": "173 4.1 Datasets, Baselines, and Experimental Setup ", "text_level": 1, "page_idx": 4}, {"type": "text", "text": "174 Emotion Recognition (ER) Dataset SEED [12] is a discrete EEG emotion dataset studying three   \n175 types of emotions: happy, neutral, and sad. SEED collected EEG from 15 subjects.   \n176 Motor Imagery (MI) Dataset BCIC-IV-2a [48] dataset recorded EEG from 9 subjects while they   \n177 were instructed to imagine four types of movements: left hand, right hand, feet, and tongue.   \n178 Epilepsy Detection (ED) Dataset CHB-MIT [49] is an epilepsy dataset required from 23 patients.   \n179 We cropped and resampled the CHB-MIT dataset to build an ED dataset with four types of EEG:   \n180 ictal, preictal, postictal, and interictal phase EEG.   \n181 Non-stealthy Baselines As mentioned in previous sections, to the best of our knowledge, ManiBCI   \n182 is the first work that studies multi-trigger and multi-target class (MT) backdoor in EEG BCI. For   \n183 comparison, we design several baseline approaches which can be divided into two main groups:   \n184 non-stealthy and stealthy. Non-stealthy attacks contains PatchMT and PulseMT. For a benign EEG   \n185 segment $\\boldsymbol{x}\\in\\mathbb{R}^{E\\times T}$ . PatchMT is a multi-trigger and MT extension of BadNets [28] where we flil the   \n186 first $\\beta T$ timepoints of a EEG segments with a constant number, e.g., {0.1, 0.3, 0.5} for three-class   \n187 task. PulseMT is a multi-trigger and MT extension of NPP-based backdoor attacks [16] where we   \n188 use NPP signals with different amplitudes, e.g., {-0.8, -0.3, 0.3, 0.8} for different target classes.   \n189 Stealthy Baselines Previous works generate stealthy poisioned samples by controlling the training   \n190 stage and can only attack single target class [18\u201320]. As they control the training of target model,   \n191 it is unfair to directly compare their methods with ManiBCI. There is no stealthy MT BA for EEG.   \n192 Thus, we design two MT stealthy attacks baselines: CompMT and AdverMT. CompMT generates   \n193 poisoned samples for different target classes by compressing the amplitude of EEG with different   \n194 ratios, e.g., $\\{-0.1,0,0.1\\}$ for three-class task. AdverseMT is a multi-trigger and MT extension of   \n195 adversarial flitering based attacks [18], where we using a local model trained only on ${\\mathcal S}_{p}$ to generate   \n196 different spatial filters $\\mathbf{W}_{i}^{*}$ for different target classes, then we apply these spatial filters to generate   \n197 poisoned samples. More details are written in Appendix D.   \n198 Experimental Setup We demonstrate the effectiveness of the proposed ManiBCI backdoor through   \n199 comprehensive experiments on the above three EEG datasets, more details of each dataset and   \n200 preprocessings are illustrated in Appendix C. We follow the poisoning attack setting as the previous   \n201 works [16] and consider three EEG DL models for classifier $f$ : EEGNet [50], DeepCNN [51], and   \n202 LSTM [52, 53]. For all methods, we train the classifiers using the Adam optimizer with learning rate   \n203 of 0.001. The batch size is 32 and the number of epochs is 100. For all datasets and baselines, the   \n204 interpolating ratio $\\alpha=0.8$ , the electrode poisoning ratio $\\beta=0.1$ , the electrode poisoning ratio $\\gamma=$   \n205 0.5. For the reinforcement learning of ManiBCI, we train $\\pi_{\\xi}$ using the Adam optimizer with learning   \n206 rate of 0.01. The hyperparameters in advantage function is set to $\\lambda=2$ , $\\mu=0.3$ , and $\\nu=0.005$ .   \n207 More details of the experimental setup can be found in the supplementary material. ", "page_idx": 4}, {"type": "text", "text": "", "page_idx": 4}, {"type": "text", "text": "", "page_idx": 4}, {"type": "text", "text": "", "page_idx": 4}, {"type": "text", "text": "", "page_idx": 4}, {"type": "table", "img_path": "NMwPKjNTEP/tmp/9b93295756dc2ad4c73ce021ea5ff1d8a109a28c1d2e6a8f61f15cc76f40c21e.jpg", "table_caption": ["Table 1: The clean accuraciy and attack success rate for each target class with $40\\%$ poisoning rate. The best results are in bold and the second best are underlined. "], "table_footnote": [], "page_idx": 5}, {"type": "text", "text": "", "page_idx": 5}, {"type": "text", "text": "", "page_idx": 5}, {"type": "text", "text": "208 4.2 Effectiveness of ManiBCI ", "text_level": 1, "page_idx": 5}, {"type": "text", "text": "209 This section presents the attack success rates of ManiBCI and baselines. To evaluate the performance   \n210 in the multi-trigger multi-payload scenario, for each test sample $(x,y)\\in\\mathcal{D}_{t e s t}$ , we enumerate all   \n211 possible target labels $c_{i}\\in{\\mathcal{C}}$ including the true label $y$ and inject the trigger to activate the backdoor.   \n212 The attack is successful only when the backdoor classifier $f$ correctly predicts $c_{i}$ for each poisoned   \n213 input $x$ with a target label $c_{i}$ . ", "page_idx": 5}, {"type": "text", "text": "214 4.2.1 Attack Performance ", "text_level": 1, "page_idx": 5}, {"type": "text", "text": "215 The clean-data accuracy (Clean) and ASR (Attack) for each class of all attack methods on three EEG   \n216 tasks with three EEG DL models are presented in Table 1. The AdverMT, designed for single-target   \n217 attack, fails to attacks multiple target classes. Our ManiBCI significantly outperforms baselines at   \n218 almost all cases $(p<0.05)$ except attacking DeepCNN on the ED dataset, having ASRs above 0.8 on   \n219 three datasets and even achieving an ASR of 1.000 on the MI dataset. These results demonstrate that   \n220 our ManiBCI is effective across different EEG tasks and EEG models. PulseMT achieves the second   \n221 best on ER and ED dataset, CompMT achieves the second best on the MI dataset. ", "page_idx": 5}, {"type": "text", "text": "222 4.2.2 Performance of the Reinforcement Learning: Policy Gradient ", "text_level": 1, "page_idx": 5}, {"type": "text", "text": "223 Displaying in Table 2, the performance of the policy gradient was compared with other common   \n224 optimazation algorithms, including genetic algorithm (GA) [54] and random selection (The search   \n225 space is too large for performing grid search as explained in Section 3.2). It can be observed that the   \n226 policy gradient outperforms GA while only spending $16\\%$ training time of GA. We plot the learning   \n227 curve of RL in Appendix F.3, which demonstrates that RL learns well strategies within 50 epochs, i.e.,   \n228 only trains 50 backdoor models and saves lots of time. The random algorithm can achieve a not bad   \n229 results, proving that our methods can be applied without RL if some performance drop is acceptable. ", "page_idx": 5}, {"type": "text", "text": "", "page_idx": 6}, {"type": "table", "img_path": "NMwPKjNTEP/tmp/5f079075cbea838e2a9b4a005cea406f98c309c4e670c8b54f708651b1548565.jpg", "table_caption": ["Table 2: Clean and attack performance with with different trigger search optimization algorithms, the poisoning rate is set to $10\\%$ . The target model is EEGNet. "], "table_footnote": [], "page_idx": 6}, {"type": "text", "text": "230 4.2.3 Performance of Learned Mask Strategies on Other Target Models ", "text_level": 1, "page_idx": 6}, {"type": "text", "text": "231 We demonstrate that the injecting strategies learned on a EEG classifier $f$ can be used to attack   \n232 other EEG classifiers $\\hat{f}$ . In other words, Marksman can still be effective when the adversary has no   \n233 knowledge of the target models $\\hat{f}$ . To perform the experiments, we use the strategy learned with a   \n234 classifier $f$ , then generate poisoned samples to attack another classifier $\\hat{f}$ whose network is different   \n235 from $f$ . Table 3 shows the performance difference, it can be observed that the difference is relatively   \n236 small in most of the cases, demonstrating the transferability of the injecting strategy learned with   \n237 reinforcement learning. ", "page_idx": 6}, {"type": "table", "img_path": "NMwPKjNTEP/tmp/6d485fccdb2ec89bdd96835023d15b3af29b9d57a99a2a00bb4d83397e28bd38.jpg", "table_caption": ["Table 3: Clean and attack performance on other models. Red values represent the decreasing performance in attacks with $f$ is the same as $\\hat{f}$ . Blue values mean increments or unchanged . "], "table_footnote": [], "page_idx": 6}, {"type": "text", "text": "238 4.2.4 Attack Performance with Different Hyperparameters ", "text_level": 1, "page_idx": 6}, {"type": "text", "text": "239 We investigate the influences of three different hyperparameters: poisoning rate $\\rho$ , frequency injection   \n240 rate $\\beta$ , and electrode injection rate $\\gamma$ . The performance of attacking EEGNet on the ED dataset are   \n241 displayed in Fig 3. It can be seen that the ASRs are positively correlated with poisoning rate. Note   \n242 that it is non-trivial for multi-target class attack, thus the ASR is not high compared to the single class   \n243 attack. ManiBCI outperforms other attacks in all cases and is robust to the change of $\\beta$ and $\\gamma$ . ", "page_idx": 6}, {"type": "image", "img_path": "NMwPKjNTEP/tmp/cc6fb1903a640426cf48aac502af7c42f66be1a381ce63538e8b1602e5015744.jpg", "img_caption": ["Figure 3: Clean (/C) and attack (/B) performance with different poisoning or injection rates. "], "img_footnote": [], "page_idx": 6}, {"type": "text", "text": "244 4.3 Robustness of ManiBCI ", "text_level": 1, "page_idx": 7}, {"type": "text", "text": "245 In this section, we evaluate the robustness of our ManiBCI against different EEG preprocessing   \n246 method and various representative backdoor defenses. ", "page_idx": 7}, {"type": "text", "text": "247 4.3.1 Robustness against EEG Preprocessing Methods ", "text_level": 1, "page_idx": 7}, {"type": "text", "text": "248 To develop an EEG BCI, it is very common to preprocess the raw EEG signals, e.g., 1) band-stop   \n249 filtering and 2) down-sampling. An EEG backdoor attack is impractical in real scenarios if it is no   \n250 longer effective when the target model is trained with the preprocessed poisoned EEG. Hence, we   \n251 must take the robustness against preprocessing methods into account, which is widely ignored in   \n252 the image backdoor attack field. The performance of each method facing different preprocessing   \n253 methods are presented in Table 4. It can be observed that our ManiBCI is robust in all cases. However,   \n254 when removing the DIS loss, the performance of ManiBCI decreases a lot after EEG preprocessing,   \n255 especially facing the $30\\,\\mathrm{Hz}$ high-stop filtering preprocessing due to the HF loss that encourages the   \n256 policy network learns to injecting high frequency. ", "page_idx": 7}, {"type": "table", "img_path": "NMwPKjNTEP/tmp/d2b33c14b5fc71ed5dced5e037f599fd4b0016ef1ca955c74590bade950fa5f7.jpg", "table_caption": ["Table 4: Clean and attack performance on three datasets after different EEG preprocessing methods. The target model is EEGNet. M w.o. DIS means removing the DIS loss in ManiBCI. "], "table_footnote": [], "page_idx": 7}, {"type": "text", "text": "257 4.3.2 Robustness against Neural Cleanse: Trigger Inversion ", "text_level": 1, "page_idx": 7}, {"type": "text", "text": "258 Neural Cleanse (NC) [42] calculate a metric called Anomaly   \n259 Index by reconstructing trigger pattern for each possible label.   \n260 The Anomaly Index is positively correlated with the size of the   \n261 reconstruction trigger. A model with Anomaly Index $>2$ is   \n262 considered to be backdoor-injected. We display the Anomaly   \n263 Indexes of the clean models and the backdoor-injected model   \n264 by ManiBCI in Fig 4. It can be seen that ManiBCI can easily   \n265 bypass NC. The reconstructed trigger patterns on three datasets   \n266 are presented in Appendix F.1. ", "page_idx": 7}, {"type": "text", "text": "267 4.3.3 Robustness against STRIP: Input Perturbation ", "text_level": 1, "page_idx": 7}, {"type": "image", "img_path": "NMwPKjNTEP/tmp/2d15223e996f39da444873181c1e71e71a27e67ed92a8db570efe487c468abcb.jpg", "img_caption": ["Figure 4: Anomaly Index of three models on three datasets. "], "img_footnote": [], "page_idx": 7}, {"type": "text", "text": "268 We evaluate the robustness of ManiBCI against STRIP [43], which perturbs the input EEG and   \n269 calculates the entropy of the predictions of these perturbed EEG data. Based on the assumption that   \n270 the trigger is still effective after perturbation, the entropy of backdoor input tends to be lower than   \n271 that of the clean one. The results are plotted in Fig 5, it can be seen that the entropy distributions of   \n272 the backdoor and clean samples are similar. ", "page_idx": 7}, {"type": "image", "img_path": "NMwPKjNTEP/tmp/8c07eb555bbda8651d766dbef085595857f1a39cef954b241eab6c8d9453fb23.jpg", "img_caption": ["Figure 5: Performance against STRIP on three datasets, the target model is EEGNet. "], "img_footnote": [], "page_idx": 7}, {"type": "text", "text": "273 4.3.4 Robustness against Spectral Signature: Latent Space Correlation ", "text_level": 1, "page_idx": 8}, {"type": "text", "text": "274 Spectral Signature [44] detects the backdoor samples by statistical analysis of clean data and backdoor   \n275 data in the latent space. Following the same experimental settings in [44], we randomly select 5,000   \n276 clean samples and 500 ManiBCI backdoor samples and plot the histograms of the correlation scores   \n277 in Fig 6. There is no clear separation between these two sets of samples, showing the stealthiness of   \n278 ManiBCI backdoor samples in the latent space. ", "page_idx": 8}, {"type": "image", "img_path": "NMwPKjNTEP/tmp/184d94afec6c01a749c1580f7396eaa3097ae76cccad9f1af9ba54552a230c95.jpg", "img_caption": ["Figure 6: Performance against Spectral Signature on three datasets, the target model is EEGNet. "], "img_footnote": [], "page_idx": 8}, {"type": "text", "text": "279 4.3.5 Robustness against Fine-Pruning ", "text_level": 1, "page_idx": 8}, {"type": "text", "text": "280 We evaluate the robustness of Marksman against Fine-Pruning   \n281 [45], a model analysis based defense which finds a classifier\u2019s   \n282 low-activated neurons given a small clean dataset. Then it   \n283 gradually prunes these low-activated neurons to mitigate the   \n284 backdoor without affecting the CA. We can observe from Fig   \n285 7 that the ASR drops considerably small when pruning ratio   \n286 is less than 0.7, suggesting that the Fine-Pruning is ineffective   \n287 against ManiBCI. ", "page_idx": 8}, {"type": "text", "text": "288 4.4 Visualization of Backdoor Attack Samples ", "text_level": 1, "page_idx": 8}, {"type": "image", "img_path": "NMwPKjNTEP/tmp/81a2bf7b664ebf2c7ce62a507f1c38cb200f899b02372211895e169dff8dcd2d.jpg", "img_caption": ["Figure 7: Performances of EEGNet against Fine-Pruning on three datasets. "], "img_footnote": [], "page_idx": 8}, {"type": "text", "text": "289 To evade from human perception (C2 in Section 3.2), we design to obatin injecting strategies with   \n290 HF loss. It can be seen from the bottom row of Fig 8 that ManiBCI (with HF loss) generates stealthy   \n291 poisoned EEG, which is almost the same as the clean EEG, demonstrating the High Stealthiness.   \n292 The poisoned EEG will be conspicuous compared to the clean EEG if remove the HF loss. ", "page_idx": 8}, {"type": "image", "img_path": "NMwPKjNTEP/tmp/07a02acbff6e709eadaf31b1dae4cab63f3ba8bd126e2829b2a263c7e4ebdef1.jpg", "img_caption": ["Figure 8: The Clean EEG (Blue), Trigger-injected EEG (Orange) and the Residual (Red) of the ED dataset. The $x$ -axis is the timepoints, the $y$ -axis is the normalized amplitude. Top row: w.o. HF loss; Bottom row: with HF loss. Each column indicates each possible class. "], "img_footnote": [], "page_idx": 8}, {"type": "text", "text": "293 5 Conclusion ", "text_level": 1, "page_idx": 8}, {"type": "text", "text": "294 In this paper, we proposed ManiBCI, a novel EEG backdoor for manipulating EEG BCI, where the   \n295 adversary can arbitrarily control the output for any input samples. To the best of our knowledge,   \n296 ManiBCI is the first method that considers which EEG electrodes and frequencies to be injected by   \n297 adopting a reinforcement learning called policy gradient to learn the adaptive injecting strategies   \n298 for different EEG triggers and tasks. We specially design the reward function in RL to enhance the   \n299 robustness and stealthiness of ManiBCI. The perturbation of the trigger on clean EEG is almost   \n300 invisible. Our experimental results over three common EEG datasets demonstrate the effectiveness   \n301 of ManibCI and the stealthiness against the existing representative defenses. This work calls for   \n302 defensive studies to counter ManiBCI for EEG modality. ", "page_idx": 8}, {"type": "text", "text": "303 References ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "304 [1] I. Ahmad, X. Wang, M. Zhu, C. Wang, Y. Pi, J. A. Khan, S. Khan, O. W. Samuel, S. Chen, G. Li   \n305 et al., \u201cEEG-based epileptic seizure detection via machine/deep learning approaches: a systematic review,\u201d   \n306 Computational Intelligence and Neuroscience, vol. 2022, 2022.   \n307 [2] M. Jafari, A. Shoeibi, M. Khodatars, S. Bagherzadeh, A. Shalbaf, D. L. Garc\u00eda, J. M. Gorriz, and U. R.   \n308 Acharya, \u201cEmotion recognition in EEG signals using deep learning methods: A review,\u201d Computers in   \n309 Biology and Medicine, p. 107450, 2023.   \n310 [3] H. Lorach, A. Galvez, V. Spagnolo, F. Martel, S. Karakas, N. Intering, M. Vat, O. Faivre, C. Harte, S. Komi   \n311 et al., \u201cWalking naturally after spinal cord injury using a brain\u2013spine interface,\u201d Nature, vol. 618, no. 7963,   \n312 pp. 126\u2013133, 2023.   \n313 [4] H. Altaheri, G. Muhammad, M. Alsulaiman, S. U. Amin, G. A. Altuwaijri, W. Abdul, M. A. Bencherif,   \n314 and M. Faisal, \u201cDeep learning techniques for classification of electroencephalogram (EEG) motor imagery   \n315 (MI) signals: A review,\u201d Neural Computing and Applications, vol. 35, no. 20, pp. 14 681\u201314 722, 2023.   \n316 [5] X. Chen, C. Liu, B. Li, K. Lu, and D. Song, \u201cTargeted backdoor attacks on deep learning systems using   \n317 data poisoning,\u201d arXiv preprint arXiv:1712.05526, 2017.   \n318 [6] Y. Gao, B. G. Doan, Z. Zhang, S. Ma, J. Zhang, A. Fu, S. Nepal, and H. Kim, \u201cBackdoor attacks and   \n319 countermeasures on deep learning: A comprehensive review,\u201d arXiv preprint arXiv:2007.10760, 2020.   \n320 [7] R. Shokri et al., \u201cBypassing backdoor detection algorithms in deep learning,\u201d in 2020 IEEE European   \n321 Symposium on Security and Privacy (EuroS&P). IEEE, 2020, pp. 175\u2013183.   \n322 [8] S. L. Kappel, D. Looney, D. P. Mandic, and P. Kidmose, \u201cPhysiological artifacts in scalp EEG and ear-EEG,\u201d   \n323 Biomedical Engineering Online, vol. 16, pp. 1\u201316, 2017.   \n324 [9] M. Tangermann, K.-R. M\u00fcller, A. Aertsen, N. Birbaumer, C. Braun, C. Brunner, R. Leeb, C. Mehring, K. J.   \n325 Miller, G. R. M\u00fcller-Putz et al., \u201cReview of the bci competition iv,\u201d Frontiers in Neuroscience, vol. 6, p. 55,   \n326 2012.   \n327 [10] M. Z. Parvez and M. Paul, \u201cEEG signal classification using frequency band analysis towards epileptic   \n328 seizure prediction,\u201d in 16th Int\u2019l Conf. Computer and Information Technology. IEEE, 2014, pp. 126\u2013130.   \n329 [11] R. Jana and I. Mukherjee, \u201cDeep learning based efficient epileptic seizure prediction with EEG channel   \n330 optimization,\u201d Biomedical Signal Processing and Control, vol. 68, p. 102767, 2021.   \n331 [12] W.-L. Zheng and B.-L. Lu, \u201cInvestigating critical frequency bands and channels for EEG-based emotion   \n332 recognition with deep neural networks,\u201d IEEE Transactions on Autonomous Mental Development, vol. 7,   \n333 no. 3, pp. 162\u2013175, 2015.   \n334 [13] M. Z. Baig, N. Aslam, and H. P. Shum, \u201cFiltering techniques for channel selection in motor imagery EEG   \n335 applications: a survey,\u201d Artificial Intelligence Review, vol. 53, no. 2, pp. 1207\u20131232, 2020.   \n336 [14] P. Herman, G. Prasad, T. M. McGinnity, and D. Coyle, \u201cComparative analysis of spectral approaches to   \n337 feature extraction for EEG-based motor imagery classification,\u201d IEEE Transactions on Neural Systems and   \n338 Rehabilitation Engineering, vol. 16, no. 4, pp. 317\u2013326, 2008.   \n339 [15] W. T. Blume, G. B. Young, and J. F. Lemieux, \u201cEEG morphology of partial epileptic seizures,\u201d Electroen  \n340 cephalography and Clinical Neurophysiology, vol. 57, no. 4, pp. 295\u2013302, 1984.   \n341 [16] L. Meng, X. Jiang, J. Huang, Z. Zeng, S. Yu, T.-P. Jung, C.-T. Lin, R. Chavarriaga, and D. Wu, \u201cEEG-based   \n342 brain-computer interfaces are vulnerable to backdoor attacks,\u201d IEEE Transactions on Neural Systems and   \n343 Rehabilitation Engineering, 2023.   \n344 [17] X. Jiang, L. Meng, S. Li, and D. Wu, \u201cActive poisoning: efficient backdoor attacks on transfer learning  \n345 based brain-computer interfaces,\u201d Science China Information Sciences, vol. 66, no. 8, p. 182402, 2023.   \n346 [18] L. Meng, X. Jiang, X. Chen, W. Liu, H. Luo, and D. Wu, \u201cAdversarial flitering based evasion and backdoor   \n347 attacks to EEG-based brain-computer interfaces,\u201d Information Fusion, p. 102316, 2024.   \n348 [19] D. Ding, M. Zhang, Y. Huang, X. Pan, F. Feng, E. Jiang, and M. Yang, \u201cTowards backdoor attack on   \n349 deep learning based time series classification,\u201d in 2022 IEEE 38th International Conference on Data   \n350 Engineering (ICDE). IEEE, 2022, pp. 1274\u20131287.   \n351 [20] Y. Jiang, X. Ma, S. M. Erfani, and J. Bailey, \u201cBackdoor attacks on time series: A generative approach,\u201d   \n352 in 2023 IEEE Conference on Secure and Trustworthy Machine Learning (SaTML). IEEE, 2023, pp.   \n353 392\u2013403.   \n354 [21] S. Arroyo and S. Uematsu, \u201cHigh-frequency eeg activity at the start of seizures,\u201d Journal of Clinical   \n355 Neurophysiology, vol. 9, no. 3, pp. 441\u2013448, 1992.   \n356 [22] M. Kostyunina and M. Kulikov, \u201cFrequency characteristics of eeg spectra in the emotions,\u201d Neuroscience   \n357 and Behavioral Physiology, vol. 26, no. 4, pp. 340\u2013343, 1996.   \n358 [23] M. Salinsky, B. Oken, and L. Morehead, \u201cTest-retest reliability in eeg frequency analysis,\u201d Electroen  \n359 cephalography and clinical neurophysiology, vol. 79, no. 5, pp. 382\u2013392, 1991.   \n360 [24] S. D. Muthukumaraswamy, \u201cHigh-frequency brain activity and muscle artifacts in meg/eeg: a review and   \n361 recommendations,\u201d Frontiers in human neuroscience, vol. 7, p. 138, 2013.   \n362 [25] M. Weber, X. Xu, B. Karla\u0161, C. Zhang, and B. Li, \u201cRab: Provable robustness against backdoor attacks,\u201d in   \n363 2023 IEEE Symposium on Security and Privacy (S&P). IEEE, 2023, pp. 1311\u20131328.   \n364 [26] Y. Yu, Y. Wang, W. Yang, S. Lu, Y.-P. Tan, and A. C. Kot, \u201cBackdoor attacks against deep image   \n365 compression via adaptive frequency trigger,\u201d in Proceedings of the IEEE/CVF Conference on Computer   \n366 Vision and Pattern Recognition (CVPR), 2023, pp. 12 250\u201312 259.   \n367 [27] Z. Yuan, P. Zhou, K. Zou, and Y. Cheng, \u201cYou are catching my attention: Are vision transformers bad   \n368 learners under backdoor attacks?\u201d in Proceedings of the IEEE/CVF Conference on Computer Vision and   \n369 Pattern Recognition (CVPR), 2023, pp. 24 605\u201324 615.   \n370 [28] T. Gu, K. Liu, B. Dolan-Gavitt, and S. Garg, \u201cBadNets: Evaluating backdooring attacks on deep neural   \n371 networks,\u201d IEEE Access, vol. 7, pp. 47 230\u201347 244, 2019.   \n372 [29] M. Barni, K. Kallas, and B. Tondi, \u201cA new backdoor attack in cnns by training set corruption without   \n373 label poisoning,\u201d in 2019 IEEE International Conference on Image Processing (ICIP). IEEE, 2019, pp.   \n374 101\u2013105.   \n375 [30] W. Jiang, H. Li, G. Xu, and T. Zhang, \u201cColor backdoor: A robust poisoning attack in color space,\u201d in   \n376 Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), 2023, pp.   \n377 8133\u20138142.   \n378 [31] T. A. Nguyen and A. T. Tran, \u201cWanet-imperceptible warping-based backdoor attack,\u201d in International   \n379 Conference on Learning Representations (ICLR), 2020.   \n380 [32] S. Li, M. Xue, B. Z. H. Zhao, H. Zhu, and X. Zhang, \u201cInvisible backdoor attacks on deep neural networks   \n381 via steganography and regularization,\u201d IEEE Transactions on Dependable and Secure Computing, vol. 18,   \n382 no. 5, pp. 2088\u20132105, 2020.   \n383 [33] Y. Zeng, W. Park, Z. M. Mao, and R. Jia, \u201cRethinking the backdoor attacks\u2019 triggers: A frequency   \n384 perspective,\u201d in Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV), 2021,   \n385 pp. 16 473\u201316 481.   \n386 [34] T. Wang, Y. Yao, F. Xu, S. An, H. Tong, and T. Wang, \u201cAn invisible black-box backdoor attack through   \n387 frequency domain,\u201d in European Conference on Computer Vision (ECCV). Springer, 2022, pp. 396\u2013413.   \n388 [35] H. A. A. K. Hammoud and B. Ghanem, \u201cCheck your other door! creating backdoor attacks in the frequency   \n389 domain,\u201d arXiv preprint arXiv:2109.05507, 2021.   \n390 [36] R. Hou, T. Huang, H. Yan, L. Ke, and W. Tang, \u201cA stealthy and robust backdoor attack via frequency   \n391 domain transform,\u201d World Wide Web (WWW), vol. 26, no. 5, pp. 2767\u20132783, 2023.   \n392 [37] Y. Feng, B. Ma, J. Zhang, S. Zhao, Y. Xia, and D. Tao, \u201cFiba: Frequency-injection based backdoor attack   \n393 in medical image analysis,\u201d in Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern   \n394 Recognition (CVPR), 2022, pp. 20 876\u201320 885.   \n395 [38] Y. Gao, H. Chen, P. Sun, J. Li, A. Zhang, Z. Wang, and W. Liu, \u201cA dual stealthy backdoor: From both   \n396 spatial and frequency perspectives,\u201d in Proceedings of the AAAI Conference on Artificial Intelligence   \n397 (AAAI), vol. 38, no. 3, 2024, pp. 1851\u20131859.   \n398 [39] T. A. Nguyen and A. Tran, \u201cInput-aware dynamic backdoor attack,\u201d Advances in Neural Information   \n399 Processing Systems (NeurIPS), vol. 33, pp. 3454\u20133464, 2020.   \n400 [40] K. Doan, Y. Lao, W. Zhao, and P. Li, \u201cLira: Learnable, imperceptible and robust backdoor attacks,\u201d in   \n401 Proceedings of the IEEE/CVF international conference on computer vision (ICCV), 2021, pp. 11 966\u2013   \n402 11 976.   \n403 [41] K. D. Doan, Y. Lao, and P. Li, \u201cMarksman backdoor: Backdoor attacks with arbitrary target class,\u201d   \n404 Advances in Neural Information Processing Systems (NeurIPS), vol. 35, pp. 38 260\u201338 273, 2022.   \n405 [42] B. Wang, Y. Yao, S. Shan, H. Li, B. Viswanath, H. Zheng, and B. Y. Zhao, \u201cNeural Cleanse: Identifying   \n406 and mitigating backdoor attacks in neural networks,\u201d in 2019 IEEE Symposium on Security and Privacy   \n407 (S&P). IEEE, 2019, pp. 707\u2013723.   \n408 [43] Y. Gao, C. Xu, D. Wang, S. Chen, D. C. Ranasinghe, and S. Nepal, \u201cSTRIP: A defence against trojan   \n409 attacks on deep neural networks,\u201d in Proceedings of the 35th Annual Computer Security Applications   \n410 Conference, 2019, pp. 113\u2013125.   \n411 [44] B. Tran, J. Li, and A. Madry, \u201cSpectral signatures in backdoor attacks,\u201d Advances in Neural Information   \n412 Processing Systems (NeurIPS), vol. 31, 2018.   \n413 [45] K. Liu, B. Dolan-Gavitt, and S. Garg, \u201cFine-pruning: Defending against backdooring attacks on deep   \n414 neural networks,\u201d in International Symposium on Research in Attacks, Intrusions, and Defenses. Springer,   \n415 2018, pp. 273\u2013294.   \n416 [46] R. S. Sutton, D. McAllester, S. Singh, and Y. Mansour, \u201cPolicy gradient methods for reinforcement learning   \n417 with function approximation,\u201d Advances in Neural Information Processing Systems (NeurIPS), vol. 12,   \n418 1999.   \n419 [47] S. V. Gliske, Z. T. Irwin, K. A. Davis, K. Sahaya, C. Chestek, and W. C. Stacey, \u201cUniversal automated high   \n420 frequency oscillation detector for real-time, long term eeg,\u201d Clinical Neurophysiology, vol. 127, no. 2, pp.   \n421 1057\u20131066, 2016.   \n422 [48] C. Brunner, R. Leeb, G. M\u00fcller-Putz, A. Schl\u00f6gl, and G. Pfurtscheller, \u201cBCI competition 2008\u2013graz data   \n423 set A,\u201d Institute for Knowledge Discovery (Laboratory of Brain-Computer Interfaces), Graz University of   \n424 Technology, vol. 16, pp. 1\u20136, 2008.   \n425 [49] A. H. Shoeb and J. V. Guttag, \u201cApplication of machine learning to epileptic seizure detection,\u201d in Proceed  \n426 ings of the 27th International Conference on Machine Learning (ICML), 2010, pp. 975\u2013982.   \n427 [50] V. J. Lawhern, A. J. Solon, N. R. Waytowich, S. M. Gordon, C. P. Hung, and B. J. Lance, \u201cEEGNet:   \n428 a compact convolutional neural network for EEG-based brain\u2013computer interfaces,\u201d Journal of Neural   \n429 Engineering, vol. 15, no. 5, p. 056013, 2018.   \n430 [51] R. T. Schirrmeister, J. T. Springenberg, L. D. J. Fiederer, M. Glasstetter, K. Eggensperger, M. Tangermann,   \n431 F. Hutter, W. Burgard, and T. Ball, \u201cDeep learning with convolutional neural networks for EEG decoding   \n432 and visualization,\u201d Human Brain Mapping, vol. 38, no. 11, pp. 5391\u20135420, 2017.   \n433 [52] S. Hochreiter and J. Schmidhuber, \u201cLong short-term memory,\u201d Neural Computation, vol. 9, no. 8, pp.   \n434 1735\u20131780, 1997.   \n435 [53] K. M. Tsiouris, V. C. Pezoulas, M. Zervakis, S. Konitsiotis, D. D. Koutsouris, and D. I. Fotiadis, \u201cA   \n436 long short-term memory deep learning network for the prediction of epileptic seizures using eeg signals,\u201d   \n437 Computers in biology and medicine, vol. 99, pp. 24\u201337, 2018.   \n438 [54] S. Katoch, S. S. Chauhan, and V. Kumar, \u201cA review on genetic algorithm: past, present, and future,\u201d   \n439 Multimedia tools and applications, vol. 80, pp. 8091\u20138126, 2021. ", "page_idx": 9}, {"type": "text", "text": "", "page_idx": 10}, {"type": "text", "text": "", "page_idx": 11}, {"type": "text", "text": "440 Appendix ", "text_level": 1, "page_idx": 12}, {"type": "text", "text": "441 A Limitations ", "text_level": 1, "page_idx": 12}, {"type": "text", "text": "442 Our ManiBCI is a backdoor attack in the frequency domain, which requires to transform the EEG   \n443 signals into frequency domain through fast Fourier transform (FFT) and return to temporal domain   \n444 through inverse FFT (iFFT). The operation of FFT and iFFT in the trigger injection function are a   \n445 little more time-consuming compared to other backdoor attack directly in the temporal domain, like   \n446 PatchMT [28] and PulseMT [16]. Future effort will be devoted into the faster implementation of FFT   \n447 and iFFT, for example, taking the advantage of modern GPUs.   \n448 It is a little more time-consuming for the reinforcement learning to acquire the optimal strategies for   \n449 each trigger. However, we can obtain a general injecting strategy for each EEG BCI tasks, which can   \n450 achieve a relatively good performance without reinforcement learning, as we can see from Table 3   \n451 that random injection strategy has an acceptable performance. ", "page_idx": 12}, {"type": "text", "text": "", "page_idx": 12}, {"type": "text", "text": "452 B Broader Impacts ", "text_level": 1, "page_idx": 12}, {"type": "text", "text": "453 With the rapid development of techniques, EEG BCIs gain a wide range of applications from health   \n454 care to human-computer interaction. Some companies like Neuralink adopt the EEG BCI to assist   \n455 paralytic patients helping themselves in daily lives. However, if the EEG BCI is backdoor attacked   \n456 by ManiBCI, which allows the attacker to arbitrarily control BCI\u2019s outputs, the BCI users may fall   \n457 into tremendous fatal troubles. For instance, one paralytic patient controls his/her wheelchair by   \n458 EEG BCI, the attacker can manipulate the wheelchair to run down a steep staircase. For an epileptic   \n459 patient, the attacker can let all the output be Normal State, even when the patient is experiencing   \n460 an epileptic seizure. This paper reveals the severe danger faced by EEG BCIs, demonstrating the   \n461 possibility that someone can maliciously manipulate the outputs of EEG BCIs with arbitrary target   \n462 class.   \n463 ManiBCI can also be used for positive purposes, like protecting intellectual property of EEG dataset   \n464 and EEG models with watermarking. As our ManiBCI has a very small impact of the clean accuracy,   \n465 and the poisoning approach is clean label poisoning, ManiBCI is a fantastic method for watermarking   \n466 EEG dataset and models.   \n467 For a company that provides EEG dataset, it can select different EEG triggers for different customs   \n468 to generate poisoned data and inject into the dataset provided to customs who buy the dataset. As a   \n469 result, the company have the information of which trigger is corresponding to which customs, e.g.,   \n470 trigger $x$ is in the dataset provided to custom $X,$ , trigger $y$ is in the dataset provided to custom Y. If an   \n471 EEG model from a company which didn\u2019t buy dataset is detected having this watermark (backdoor)   \n472 with trigger $x_{i}$ , the company knows that the custom $X$ leaked the dataset. Similarly, if an EEG model   \n473 is detected having this watermark (backdoor) with trigger $y$ , the company knows that the custom $Y$   \n474 leaked the dataset. ", "page_idx": 12}, {"type": "text", "text": "", "page_idx": 12}, {"type": "text", "text": "", "page_idx": 12}, {"type": "text", "text": "475 C Datasets and Preprocessing ", "text_level": 1, "page_idx": 12}, {"type": "text", "text": "476 In this section, we introduce the three datasets used in our experiments, and explain the preprocessing.   \n477 Table 5 presents some basic information of these datasets.   \n479 The SJTU Emotion EEG Dataset (SEED) was incoporated as the representative dataset of emotion   \n480 recogniton tasks [12]. It consists of EEG recordings from 15 subjects watching 15 emotional video   \n481 clips with three repeated session each on different days. Each video clip is supposed to evoke one   \n482 of the three target emotions: positive, neutral, and negative. The EEG signals were acquired by   \n483 the 62-channel electrode cap at a sampling rate of $1000\\ \\mathrm{Hz}$ . We performed below preprocessing   \n484 procedures for the 62-channel EEG signals: 1) Down-sampling from $1000\\,\\mathrm{Hz}$ to $200\\,\\mathrm{Hz}$ , 2) Band-pass   \n485 filtering at $0.3\u201350\\,\\mathrm{Hz}$ , 3) Segmenting EEG signals into 1-second (200 timepoints), obtaining 3394   \n486 EEG segments in each session for each subject. ", "page_idx": 12}, {"type": "table", "img_path": "NMwPKjNTEP/tmp/1cfbc8369b72aed51be72c0bc663c8a3d3699ed50d30b7fdbf50f66e3c805bee.jpg", "table_caption": ["Table 5: Basic information of the three datasets "], "table_footnote": [], "page_idx": 12}, {"type": "text", "text": "", "page_idx": 13}, {"type": "text", "text": "487 C.2 Motor Imagery (MI) ", "text_level": 1, "page_idx": 13}, {"type": "text", "text": "488 We employ the BCIC-IV-2a as a representative dataset of MI classification tasks [48]. It contains   \n489 EEG recordings in a four-class motor-imagery task from nine subjects with two repeated session each   \n490 on different days. During the task, the subjects were instructed to imagine four types of movements   \n491 (i.e., right hand, left hand, feet, and tongue) for four seconds. Each session consists of a total of   \n492 288 trials with 72 trials for each type of the motor imagery. The EEG signals were recorded by 22   \n493 $\\mathrm{Ag/AgCl}$ EEG electrodes in a sampling rate of $250\\,\\mathrm{Hz}$ . We segment the 22-channel EEG signals into   \n494 1-second segments, resulting in totally 1152 EEG data for each subject. ", "page_idx": 13}, {"type": "text", "text": "495 C.3 Epilepsy Detection (ED) ", "text_level": 1, "page_idx": 13}, {"type": "text", "text": "496 The CHB-MIT, one of the largest and most used public datasets for epilepsy, is adopted as a   \n497 representative dataset of ED tasks [49]. It recorded 877.39 hours of multi-channel EEG in a sampling   \n498 rate of $256\\,\\mathrm{Hz}$ from 23 pediatric patients with intractable seizures. However, as the montages (i.e.,   \n499 the number and the places of electrodes) of EEG signals vary significantly among different subjects\u2019   \n500 recordings, we select to use only the EEG recordings with the same 23 channels (see Appendix A)   \n501 and discard other channels or the recordings don\u2019t have all these 23 channels. Due to the purpose is to   \n502 test whether the backdoor attack works on the ED task, not to study the epilepsy EEG classification,   \n503 we segment part of the CHB-MIT dataset to form a four-class ED dataset (i.e., the preictal, ictal,   \n504 postictal, and interictal phases). Specifically, for a ictal phase EEG recording of $t_{i}$ seconds from   \n505 $[s_{i},e_{i}]$ timepoints, we segment the $[s_{i}-t_{i},e_{i}]$ EEG as the preictal phase, the $[e_{i},e_{i}+t_{i}]$ EEG as the   \n506 postictal phase, and another $t_{i}$ seconds EEG recordings as the interictal phase which satisfying there   \n507 is no ictal phase within half an hour before or after. Then we segment the 23-channel EEG signals   \n508 into 1-second segments, consequently, there are 41336 segments left in total from all subjects, 10334   \n509 for each phase. As the imbalanced amount of data across different subjects, we separate these 41336   \n510 segments into 10 groups and treat the ten groups as 10 subjects. ", "page_idx": 13}, {"type": "text", "text": "511 D Implementation Details ", "text_level": 1, "page_idx": 13}, {"type": "text", "text": "512 D.1 Experiment Computing Resources ", "text_level": 1, "page_idx": 13}, {"type": "text", "text": "513 We use two servers for conducting our experiments. A server with one Nvidia Tesla V100 GPU is   \n514 used for running reinforcement learning, the CUDA version is 12.3. Another server with four Nvidia   \n515 RTX 3090 GPUs is used for running the backdoor attacks, the CUDA version is 11.4. ", "page_idx": 13}, {"type": "text", "text": "516 D.2 Details of Baseline Methods ", "text_level": 1, "page_idx": 13}, {"type": "text", "text": "517 In our ManiBCI backdoor attacks, for an EEG segment $x_{i}\\in\\mathbb{R}^{E\\times T}$ , we modify the $\\beta F$ frequency  \n518 points and $\\gamma E$ electrodes of a EEG segments with a constant number.   \n519 There are four baseline methods in our study for multi-target backdoor attacks, two of them are   \n520 non-stealthy attacks (PatchMT and PulseMT) and two are stealthy attacks (CompressMT and   \n521 AdverseMT). In order to achieve a fair comparison, we modify only first $\\gamma E$ electrodes for all   \n522 baseline attack methods. For the non-stealthy attacks, which are all on the temporal domains, we   \n523 modify $\\beta T$ timepoints of EEG signals. For the stealthy attacks, there is no constraint of the numbers   \n524 of the modify timepoints as these attacks achieve stealthiness in another way.   \n525 For each baseline method, we try our best to find out the best performance, as demonstrated below.   \n526 We promise that we did not maliciously lower the performances of the baseline methods. ", "page_idx": 13}, {"type": "text", "text": "", "page_idx": 13}, {"type": "text", "text": "", "page_idx": 14}, {"type": "text", "text": "527 D.2.1 PatchMT ", "text_level": 1, "page_idx": 14}, {"type": "text", "text": "528 PatchMT is a multi-trigger and MT extension of BadNets [28] where we fill the first $\\beta T$ timepoints   \n529 and $\\gamma E$ electrodes of a EEG segments with a constant number. Specifically, for an EEG segment   \n530 $\\boldsymbol{x}_{i}\\in\\mathbb{R}^{E\\times T}$ , we set the first $\\gamma E$ electrodes and the first $\\beta T$ timepoints of the EEG segment to a   \n531 constant number. We normalize the EEG segment $\\boldsymbol{x}_{i}\\in\\mathbb{R}^{E\\times T}$ to let $\\mathbf{X}_{i}$ \u2019s mean is 0 and std is 1.   \n532 Then set the first $\\gamma E$ electrodes and the first $\\beta T$ timepoints of $\\mathbf{X}_{i}$ to a different constant number for   \n533 different class. The constant number for each class of $\\{0,1,2,3\\}$ for four classes, and $\\{-0.1,0.0,1.0\\}$   \n534 for three classes. Finally, denormalize $\\mathbf{X}_{i}$ to original signal $x_{i}$ \u2019s scale to generate $\\boldsymbol{x}_{i}^{p}$ .   \n535 Although we try our best to find the best performance of PatchMT, and BadNets [28] is really efficient   \n536 in image backdoor attacks, PatchMT cannot have satisfactory results in EEG BCI attack. ", "page_idx": 14}, {"type": "text", "text": "", "page_idx": 14}, {"type": "text", "text": "537 D.2.2 PulseMT ", "text_level": 1, "page_idx": 14}, {"type": "text", "text": "538 For PulseMT, we met the same questions as the PatchMT: how to identify the amplitude of each NPP   \n539 signal for each class? If the numbers are too large then normal EEG signals, it will be unfair. If the   \n540 numbers are too small, the efficacy of PulseMT is too negative.   \n541 We normalize the EEG segment $x_{i}\\in\\mathbb{R}^{E\\times T}$ to let $\\mathbf{X}_{i}$ \u2019s mean is 0 and std is 1. The constant amplitude   \n542 for each class of $\\{-0.8,-0.3,0.3,0.8\\}$ . Finally, denormalize $\\mathbf{X}_{i}$ to original signal $x_{i}$ \u2019s scale to   \n543 generate $\\boldsymbol{x}_{i}^{p}$ . ", "page_idx": 14}, {"type": "text", "text": "", "page_idx": 14}, {"type": "text", "text": "544 D.2.3 CompressMT ", "text_level": 1, "page_idx": 14}, {"type": "text", "text": "545 Compressing the amplitude of EEG signals in the temporal domain will not change the morphology   \n546 and the frequency distribution of EEG signals, thus obtaining stealthiness. For three-class Emotion   \n547 datasets, the compress rate is {0.8, 0.6, 0.4}. For four-class Motor Imagery and Epilepsy datasets, the   \n548 compress rate is {0.8, 0.6, 0.4, 0.2}. ", "page_idx": 14}, {"type": "text", "text": "549 D.2.4 AdverseMT ", "text_level": 1, "page_idx": 14}, {"type": "text", "text": "550 AdverseMT is another stealthy EEG backdoor attacks, which is the multi-trigger and multi-target   \n551 extension of adversarial spatial filter attacks [18], in wihch, for EEG segment $\\bar{x_{i}}\\in\\mathbb{R}^{E\\times T}$ , it learns   \n552 an Spatial Filter $\\mathbf{W}\\in\\mathbb{R}^{E\\times E}$ by the adversarial loss to let the model $f$ misclassify $x_{i}$ : ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\operatorname*{min}_{\\mathbf{W}}\\mathbb{E}_{(x_{i},y_{i})\\sim\\mathcal{D}}[-\\mathcal{L}_{C E}(\\mathbf{W}x_{i},y_{i})+\\alpha\\mathcal{L}_{M S E}(\\mathbf{W}x_{i},x_{i})],\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "553 However, the original version of [18] requires the access to all training dataset $\\mathcal{D}$ and the control of   \n554 the training process of the model $f$ . We modify the AdverseMT to only access to the training dataset   \n555 $\\mathcal{D}_{t r a i n}$ . Note that the adversarial loss dose not have the special design for multi-target backdoor   \n556 attacks, we only run the process $c$ times for obtaining $c$ spatial filters for different classes. So the   \n557 poisoned subset are $S_{p}=\\left\\{(\\mathbf{W}_{0}(x),0),(\\mathbf{W}_{1}(x),1),(\\Breve{\\mathbf{W}}_{2}(\\Breve{x}),2),(\\mathbf{W}_{3}(x),3)\\right\\}$ . ", "page_idx": 14}, {"type": "text", "text": "558 D.3 Reinforcement Learning Policy Network Architecture ", "text_level": 1, "page_idx": 14}, {"type": "text", "text": "559 Here, we design a concise but effective convolutional neural networks as the our policy network,   \n560 which is defined as belows: ", "page_idx": 14}, {"type": "table", "img_path": "NMwPKjNTEP/tmp/8e6dc2a5e8aa2bcaab993ea6af6c31d3676363d72694235c42cf209acc1bea19.jpg", "table_caption": ["Table 6: The Architecture of Policy Network "], "table_footnote": [], "page_idx": 15}, {"type": "text", "text": "561 E Attack Performance of ManiBCI ", "text_level": 1, "page_idx": 15}, {"type": "text", "text": "562 E.1 Different Poisoning Rates ", "text_level": 1, "page_idx": 15}, {"type": "text", "text": "563 We present the performance of each backdoor attacks\u2019 performance under different poisoning rates in   \n564 Table 7. We can see that our ManiBCI outperforms other baseline at all poisoning rates, demonstrating   \n565 the superiority of ManiBCI. Note that the performance of ManiBCI on the MI dataset is significantly   \n566 robust to low poisoning rates, i.e., ASR of 1.000 when $\\rho=0.05$ . ", "page_idx": 15}, {"type": "text", "text": "567 E.2 Hyperparameter Analysis: Frequency and Electrodes Injection Ratio ", "text_level": 1, "page_idx": 15}, {"type": "text", "text": "568 We present the performance of each backdoor attacks performance under different rates in Table 8   \n569 and Table 9. It can be observed with the increment of $\\beta$ and $\\gamma$ , the attack performance increases.   \n570 Because the trigger is bigger in clean EEG data. ", "page_idx": 15}, {"type": "text", "text": "571 E.3 Hyperparameter Analysis in Reinforcement Learning ", "text_level": 1, "page_idx": 15}, {"type": "text", "text": "572 We applied the following reward function to acquire the optimal mask strategies for each triggers: ", "page_idx": 15}, {"type": "equation", "text": "$$\nQ_{t}=\\operatorname{CA}+\\lambda\\operatorname{ASR}+\\mu\\operatorname{dis}(\\mathcal{M}_{f}^{c_{i}})+\\nu\\operatorname*{min}(\\mathcal{M}_{f}^{c_{i}}),\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "573 where the first part means the clean accuracy, the second part means the attack success rate, the third   \n574 part is aiming to scatter the injection positions in various frequency bands, and the fourth part is   \n575 aiming to inject as high frequencies in EEG signals as possible. Here, we give a simple example to   \n576 demonstrate the reward function. For an 10 timepoints long EEG segment $x_{i}$ , $\\widetilde{x}_{i}=\\mathcal{F}(x_{i})$ . If the   \n577 $\\mathcal{M}_{f}^{c_{i}}=\\{2,3,5,7,9\\}$ , because the minimal distance between each pair in $\\mathcal{M}_{f}^{c_{i}}$ is $|2-3|=1$ , thus   \n578 $\\mathrm{dis}(\\mathcal{M}_{f}^{c_{i}})=1$ . The $\\operatorname*{min}(\\mathcal{M}_{f}^{c_{i}})$ means the lowest position in $\\mathcal{M}_{f}^{c_{i}}$ , thus $\\operatorname*{min}(\\dot{\\mathcal{M}}_{f}^{c_{i}})=2$ .   \n579 The analysis of the $\\lambda$ are presented in Table 10. When $\\lambda$ increase, the Attack performance increases   \n580 while the Clean performance declines slightly.   \n582 In this section, we plot the reconstructed triggers and masks on three datasets in Section F.1, then   \n583 plot more visualizations of backdoor samples in Section ??, and plot the learning curve of our   \n584 reinforcement learning in Section F.3. ", "page_idx": 15}, {"type": "text", "text": "", "page_idx": 15}, {"type": "table", "img_path": "NMwPKjNTEP/tmp/55876aa9f1df6eb2ba5af4148b6dddbad76eba10c2d6c53552b91d4355e7d180.jpg", "table_caption": ["Table 10: Clean $(/{\\bf C})$ and attack (/B) performance with ASR\u2019s hyperparameter $\\lambda$ , $\\mu=0.3,\\nu=0.005$ "], "table_footnote": [], "page_idx": 15}, {"type": "table", "img_path": "NMwPKjNTEP/tmp/6d4317aa53193a6f566c138c291bb7f460b789964774e06a93f8b871f0dfe561.jpg", "table_caption": ["Table 7: Clean $(/\\mathbf{C})$ and attack (/B) performance with different poisoning rates for ManiBCI and other baseline methods. The target model is EEGNet for all cases. "], "table_footnote": [], "page_idx": 16}, {"type": "table", "img_path": "NMwPKjNTEP/tmp/cb571cbd2cf4899b521d16871b4164ca2b7bdfae072047f7e015b6e03d9221e7.jpg", "table_caption": ["Table 8: Clean (/C) and attack (/B) performance with frequency injection rate $\\beta,\\gamma=0.5$ "], "table_footnote": [], "page_idx": 17}, {"type": "table", "img_path": "NMwPKjNTEP/tmp/f432b9142efdd585931e8ba4e4bbf1b5a3bc589d6890f87fef17cb2fb8596f1d.jpg", "table_caption": ["Table 9: Clean (/C) and attack (/B) performance with electrodes injection rate \u03b3, $\\beta=0.1$ "], "table_footnote": [], "page_idx": 18}, {"type": "text", "text": "", "page_idx": 19}, {"type": "text", "text": "585 F.1 Neural Cleanse: Reconstruction Trigger Patterns ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "586 Here, we present more visualization in Figure 9, Figure 10, and Figure 11 of the reconstructed trigger   \n587 patterns and mask patterns for each possible label on three dataset (i.e., the CHB-MIT dataset, the   \n588 BCIC-IV-2a dataset and the SEED dataset) the target model is EEGnet. It can be observed that the   \n589 reconstructed trigger patterns and mask patterns of the clean models and ManiBCI backdoor-injected   \n590 models are very similar to each other. Thus, our ManiBCI backdoor attack can easily bypass the   \n591 defense of Neural Cleanse. ", "page_idx": 19}, {"type": "image", "img_path": "NMwPKjNTEP/tmp/570d432b1ba12416ad91b1a0f1187cf923b9d2ceff38471629443ca33be94be1.jpg", "img_caption": ["Figure 9: The reconstructed trigger patterns and mask patterns for each possible class in the CHB-MIT dataset. The results in the left column are reconstructed based on the clean model, the results in the right column are reconstructed based on the backdoor model. The EEG segments in the CHB-MIT dataset have 23 electrodes and 256 timepoints. "], "img_footnote": [], "page_idx": 19}, {"type": "image", "img_path": "NMwPKjNTEP/tmp/3fc25d2bf845afd51bf2d4b2b8a9c3a96beb74e26a6e329fee0874d2cc0b10a5.jpg", "img_caption": ["Figure 10: The reconstructed trigger patterns and mask patterns for each possible class in the MI dataset. The results in the left column are reconstructed based on the clean model, the results in the right column are reconstructed based on the backdoor model. The EEG segments in the MI dataset have 22 electrodes and 250 timepoints. "], "img_footnote": [], "page_idx": 20}, {"type": "image", "img_path": "NMwPKjNTEP/tmp/0cee7de8dcc38c842ac97c4268074c9a063a8ea0f9a14b24d3426f18ca76b0e3.jpg", "img_caption": ["Figure 11: The reconstructed trigger patterns and mask patterns for each possible class in the ER dataset (i.e., SEED dataset). The results in the left column are reconstructed based on the clean model, the results in the right column are reconstructed based on the backdoor model. The EEG segments in the SEED dataset have 62 electrodes and 200 timepoints. "], "img_footnote": [], "page_idx": 21}, {"type": "text", "text": "592 F.2 Visualization of Backdoor Attack Samples ", "text_level": 1, "page_idx": 22}, {"type": "text", "text": "593 We present more visualization of the backdoor attack samples generated by our ManiBCI on ER   \n594 dataset and MI dataset in Fig 12 and 13. The ${\\bf X}$ -axis is the timepoints, the y-axis is the normalized   \n595 amplitude. Top row: w.o. HF loss; Bottom row: with HF loss. Each column indicates each possible   \n596 class. ", "page_idx": 22}, {"type": "image", "img_path": "NMwPKjNTEP/tmp/eb1212da452bd6cbd1fa19027f87eef2b8d0e899304ff9d45a358092915e392f.jpg", "img_caption": [], "img_footnote": [], "page_idx": 22}, {"type": "text", "text": "Figure 12: The Clean EEG (Blue), Trigger-injected EEG (Orange) and the Residual (Red) of the ER dataset. ", "page_idx": 22}, {"type": "image", "img_path": "NMwPKjNTEP/tmp/f3668b588ff7b6847dcb2af2a21eca3566ad279800aedcececd907e2a5d623bd.jpg", "img_caption": [], "img_footnote": [], "page_idx": 22}, {"type": "text", "text": "Figure 13: The Clean EEG (Blue), Trigger-injected EEG (Orange) and the Residual (Red) of the MI dataset. ", "page_idx": 22}, {"type": "text", "text": "597 F.3 Visualization of Learning Curves of Reinforcement Learning ", "text_level": 1, "page_idx": 23}, {"type": "text", "text": "598 We present the visualization of the learning curves of the reinforcement learning of three dataset in   \n599 Fig 14. We can see the effectiveness of our reinforcement, which converged within 50 epochs on the   \n600 ER dataset, that is, only trained 50 backdoor models with different injection strategies. Our RL is   \n601 more effective on the MI dataset and ED dataset, which finds a good strategy within less 10 epochs.   \n602 Our RL is robust when learning strategies for different triggers as demonstrated in Fig 14(c) and (d),   \n603 where the learning curves are quite similar when RL is performing on different triggers. ", "page_idx": 23}, {"type": "image", "img_path": "NMwPKjNTEP/tmp/db2da72a3ea5c30c8bd0d4964d77271d1232486f96123a235ff3d2160967ade7.jpg", "img_caption": ["(d) The RL curve on the Epilepsy Detection dataset, for another tirrger with label 2 "], "img_footnote": [], "page_idx": 23}, {"type": "text", "text": "Figure 14: The learning curves of RL on three datasets. The right column is the curve we sort the (ACC,ASR) according to the ASR. The backdoor models are all EEGNet. ", "page_idx": 23}, {"type": "text", "text": "604 NeurIPS Paper Checklist ", "text_level": 1, "page_idx": 24}, {"type": "text", "text": "606 Question: Do the main claims made in the abstract and introduction accurately reflect the   \n607 paper\u2019s contributions and scope? ", "page_idx": 24}, {"type": "text", "text": "Guidelines: \u2022 The answer NA means that the abstract and introduction do not include the claims made in the paper. \u2022 The abstract and/or introduction should clearly state the claims made, including the contributions made in the paper and important assumptions and limitations. A No or NA answer to this question will not be perceived well by the reviewers. \u2022 The claims made should match theoretical and experimental results, and reflect how much the results can be expected to generalize to other settings. \u2022 It is fine to include aspirational goals as motivation as long as it is clear that these goals are not attained by the paper. ", "page_idx": 24}, {"type": "text", "text": "2. Limitations ", "text_level": 1, "page_idx": 24}, {"type": "text", "text": "Question: Does the paper discuss the limitations of the work performed by the authors? Answer: [Yes] ", "page_idx": 24}, {"type": "text", "text": "Justification: We discussed the limitations of our proposed method in Appendix. ", "page_idx": 24}, {"type": "text", "text": "\u2022 The answer NA means that the paper has no limitation while the answer No means that the paper has limitations, but those are not discussed in the paper.   \n\u2022 The authors are encouraged to create a separate \"Limitations\" section in their paper.   \n\u2022 The paper should point out any strong assumptions and how robust the results are to violations of these assumptions (e.g., independence assumptions, noiseless settings, model well-specification, asymptotic approximations only holding locally). The authors should reflect on how these assumptions might be violated in practice and what the implications would be.   \n\u2022 The authors should reflect on the scope of the claims made, e.g., if the approach was only tested on a few datasets or with a few runs. In general, empirical results often depend on implicit assumptions, which should be articulated.   \n\u2022 The authors should reflect on the factors that influence the performance of the approach. For example, a facial recognition algorithm may perform poorly when image resolution is low or images are taken in low lighting. Or a speech-to-text system might not be used reliably to provide closed captions for online lectures because it fails to handle technical jargon.   \n\u2022 The authors should discuss the computational efficiency of the proposed algorithms and how they scale with dataset size.   \n\u2022 If applicable, the authors should discuss possible limitations of their approach to address problems of privacy and fairness.   \n\u2022 While the authors might fear that complete honesty about limitations might be used by reviewers as grounds for rejection, a worse outcome might be that reviewers discover limitations that aren\u2019t acknowledged in the paper. The authors should use their best judgment and recognize that individual actions in favor of transparency play an important role in developing norms that preserve the integrity of the community. Reviewers will be specifically instructed to not penalize honesty concerning limitations. ", "page_idx": 24}, {"type": "text", "text": "51 3. Theory Assumptions and Proofs ", "text_level": 1, "page_idx": 24}, {"type": "text", "text": "52 Question: For each theoretical result, does the paper provide the full set of assumptions and   \n53 a complete (and correct) proof? ", "page_idx": 24}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 24}, {"type": "text", "text": "Justification: Our paper dose not include theoretical results. Guidelines: ", "page_idx": 25}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include theoretical results.   \n\u2022 All the theorems, formulas, and proofs in the paper should be numbered and crossreferenced.   \n\u2022 All assumptions should be clearly stated or referenced in the statement of any theorems.   \n\u2022 The proofs can either appear in the main paper or the supplemental material, but if they appear in the supplemental material, the authors are encouraged to provide a short proof sketch to provide intuition.   \n\u2022 Inversely, any informal proof provided in the core of the paper should be complemented by formal proofs provided in appendix or supplemental material.   \n\u2022 Theorems and Lemmas that the proof relies upon should be properly referenced. ", "page_idx": 25}, {"type": "text", "text": "67 4. Experimental Result Reproducibility ", "text_level": 1, "page_idx": 25}, {"type": "text", "text": "Question: Does the paper fully disclose all the information needed to reproduce the main experimental results of the paper to the extent that it affects the main claims and/or conclusions of the paper (regardless of whether the code and data are provided or not)? ", "page_idx": 25}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 25}, {"type": "text", "text": "Justification: We demonstrated our method and the experiment settings clearly in Section 3.1 and Section 4.2. The implementation details of all baselines are written in appendix. Guidelines: ", "page_idx": 25}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 If the paper includes experiments, a No answer to this question will not be perceived well by the reviewers: Making the paper reproducible is important, regardless of whether the code and data are provided or not.   \n\u2022 If the contribution is a dataset and/or model, the authors should describe the steps taken to make their results reproducible or verifiable.   \n\u2022 Depending on the contribution, reproducibility can be accomplished in various ways. For example, if the contribution is a novel architecture, describing the architecture fully might suffice, or if the contribution is a specific model and empirical evaluation, it may be necessary to either make it possible for others to replicate the model with the same dataset, or provide access to the model. In general. releasing code and data is often one good way to accomplish this, but reproducibility can also be provided via detailed instructions for how to replicate the results, access to a hosted model (e.g., in the case of a large language model), releasing of a model checkpoint, or other means that are appropriate to the research performed.   \n\u2022 While NeurIPS does not require releasing code, the conference does require all submissions to provide some reasonable avenue for reproducibility, which may depend on the nature of the contribution. For example (a) If the contribution is primarily a new algorithm, the paper should make it clear how to reproduce that algorithm. (b) If the contribution is primarily a new model architecture, the paper should describe the architecture clearly and fully. (c) If the contribution is a new model (e.g., a large language model), then there should either be a way to access this model for reproducing the results or a way to reproduce the model (e.g., with an open-source dataset or instructions for how to construct the dataset). (d) We recognize that reproducibility may be tricky in some cases, in which case authors are welcome to describe the particular way they provide for reproducibility. In the case of closed-source models, it may be that access to the model is limited in some way (e.g., to registered users), but it should be possible for other researchers to have some path to reproducing or verifying the results. ", "page_idx": 25}, {"type": "text", "text": "5. Open access to data and code ", "text_level": 1, "page_idx": 25}, {"type": "text", "text": "Question: Does the paper provide open access to the data and code, with sufficient instructions to faithfully reproduce the main experimental results, as described in supplemental material? ", "page_idx": 25}, {"type": "text", "text": "Justification: Sorry for not providing the whole code at the submitting phase as we have no   \ntime to organize our code well. However, we will publish our code after the anonymous   \nperiod (Or we can organize and upload our code during rebuttal phase if possible).   \nGuidelines: \u2022 The answer NA means that paper does not include experiments requiring code. \u2022 Please see the NeurIPS code and data submission guidelines (https://nips.cc/ public/guides/CodeSubmissionPolicy) for more details. \u2022 While we encourage the release of code and data, we understand that this might not be possible, so \u201cNo\u201d is an acceptable answer. Papers cannot be rejected simply for not including code, unless this is central to the contribution (e.g., for a new open-source benchmark). \u2022 The instructions should contain the exact command and environment needed to run to reproduce the results. See the NeurIPS code and data submission guidelines (https: //nips.cc/public/guides/CodeSubmissionPolicy) for more details. \u2022 The authors should provide instructions on data access and preparation, including how to access the raw data, preprocessed data, intermediate data, and generated data, etc. \u2022 The authors should provide scripts to reproduce all experimental results for the new proposed method and baselines. If only a subset of experiments are reproducible, they should state which ones are omitted from the script and why. \u2022 At submission time, to preserve anonymity, the authors should release anonymized versions (if applicable). \u2022 Providing as much information as possible in supplemental material (appended to the paper) is recommended, but including URLs to data and code is permitted. ", "page_idx": 26}, {"type": "text", "text": "6. Experimental Setting/Details ", "text_level": 1, "page_idx": 26}, {"type": "text", "text": "Question: Does the paper specify all the training and test details (e.g., data splits, hyperparameters, how they were chosen, type of optimizer, etc.) necessary to understand the results? ", "page_idx": 26}, {"type": "text", "text": "Justification: We demonstrated our method and the experiment settings clearly in Section3.1 and Section 4.2. The implementation details of all baselines are written in appendix. Guidelines: ", "page_idx": 26}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments. \u2022 The experimental setting should be presented in the core of the paper to a level of detail that is necessary to appreciate the results and make sense of them. \u2022 The full details can be provided either with the code, in appendix, or as supplemental material. ", "page_idx": 26}, {"type": "text", "text": "747 7. Experiment Statistical Significance ", "text_level": 1, "page_idx": 26}, {"type": "text", "text": "748 Question: Does the paper report error bars suitably and correctly defined or other appropriate   \n749 information about the statistical significance of the experiments? ", "page_idx": 26}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 26}, {"type": "text", "text": "Justification: We give all the statistical significance of our experiments. 52 Guidelines: ", "page_idx": 26}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 The authors should answer \"Yes\" if the results are accompanied by error bars, confidence intervals, or statistical significance tests, at least for the experiments that support the main claims of the paper.   \n\u2022 The factors of variability that the error bars are capturing should be clearly stated (for example, train/test split, initialization, random drawing of some parameter, or overall run with given experimental conditions).   \n\u2022 The method for calculating the error bars should be explained (closed form formula, call to a library function, bootstrap, etc.) ", "page_idx": 26}, {"type": "text", "text": "762 \u2022 The assumptions made should be given (e.g., Normally distributed errors).   \n763 \u2022 It should be clear whether the error bar is the standard deviation or the standard error   \n764 of the mean.   \n765 \u2022 It is OK to report 1-sigma error bars, but one should state it. The authors should   \n766 preferably report a 2-sigma error bar than state that they have a $96\\%$ CI, if the hypothesis   \n767 of Normality of errors is not verified.   \n768 \u2022 For asymmetric distributions, the authors should be careful not to show in tables or   \n769 figures symmetric error bars that would yield results that are out of range (e.g. negative   \n770 error rates).   \n771 \u2022 If error bars are reported in tables or plots, The authors should explain in the text how   \n772 they were calculated and reference the corresponding figures or tables in the text.   \n773 8. Experiments Compute Resources   \n774 Question: For each experiment, does the paper provide sufficient information on the com  \n775 puter resources (type of compute workers, memory, time of execution) needed to reproduce   \n776 the experiments?   \n777 Answer: [Yes]   \n778 Justification: Yes, we provide the type of GPU and version of CUDA in Appendix D.   \n779 Guidelines:   \n780 \u2022 The answer NA means that the paper does not include experiments.   \n781 \u2022 The paper should indicate the type of compute workers CPU or GPU, internal cluster,   \n782 or cloud provider, including relevant memory and storage.   \n783 \u2022 The paper should provide the amount of compute required for each of the individual   \n784 experimental runs as well as estimate the total compute.   \n785 \u2022 The paper should disclose whether the full research project required more compute   \n786 than the experiments reported in the paper (e.g., preliminary or failed experiments that   \n787 didn\u2019t make it into the paper).   \n788 9. Code Of Ethics   \n789 Question: Does the research conducted in the paper conform, in every respect, with the   \n790 NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines?   \n791 Answer: [Yes]   \n792 Justification: Yes, we conform with the NeurIPS Code of Ethics.   \n793 Guidelines:   \n794 \u2022 The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics.   \n795 \u2022 If the authors answer No, they should explain the special circumstances that require a   \n796 deviation from the Code of Ethics.   \n797 \u2022 The authors should make sure to preserve anonymity (e.g., if there is a special consid  \n798 eration due to laws or regulations in their jurisdiction).   \n799 10. Broader Impacts   \n800 Question: Does the paper discuss both potential positive societal impacts and negative   \n801 societal impacts of the work performed?   \n802 Answer: [Yes]   \n803 Justification: We discuss the broader impacts of our backdoor attacks in Appendix.   \n804 Guidelines:   \n805 \u2022 The answer NA means that there is no societal impact of the work performed.   \n806 \u2022 If the authors answer NA or No, they should explain why their work has no societal   \n807 impact or why the paper does not address societal impact.   \n808 \u2022 Examples of negative societal impacts include potential malicious or unintended uses   \n809 (e.g., disinformation, generating fake profiles, surveillance), fairness considerations   \n810 (e.g., deployment of technologies that could make decisions that unfairly impact specific   \n811 groups), privacy considerations, and security considerations.   \n812 \u2022 The conference expects that many papers will be foundational research and not tied   \n813 to particular applications, let alone deployments. However, if there is a direct path to   \n814 any negative applications, the authors should point it out. For example, it is legitimate   \n815 to point out that an improvement in the quality of generative models could be used to   \n816 generate deepfakes for disinformation. On the other hand, it is not needed to point out   \n817 that a generic algorithm for optimizing neural networks could enable people to train   \n818 models that generate Deepfakes faster.   \n819 \u2022 The authors should consider possible harms that could arise when the technology is   \n820 being used as intended and functioning correctly, harms that could arise when the   \n821 technology is being used as intended but gives incorrect results, and harms following   \n822 from (intentional or unintentional) misuse of the technology.   \n823 \u2022 If there are negative societal impacts, the authors could also discuss possible mitigation   \n824 strategies (e.g., gated release of models, providing defenses in addition to attacks,   \n825 mechanisms for monitoring misuse, mechanisms to monitor how a system learns from   \n826 feedback over time, improving the efficiency and accessibility of ML).   \n827 11. Safeguards   \n828 Question: Does the paper describe safeguards that have been put in place for responsible   \n829 release of data or models that have a high risk for misuse (e.g., pretrained language models,   \n830 image generators, or scraped datasets)?   \n831 Answer: [NA]   \n832 Justification: We do not release any dataset or model. However, our paper proposes   \n833 a backdoor attack method in EEG BCIs, which is challenging to be guarded and have   \n834 dangerous impact in EEG BCIs. The only safeguard way we can come up with is to check   \n835 and guarantee the clean of training datasets EEG BCIs employ.   \n836 Guidelines:   \n837 \u2022 The answer NA means that the paper poses no such risks.   \n838 \u2022 Released models that have a high risk for misuse or dual-use should be released with   \n839 necessary safeguards to allow for controlled use of the model, for example by requiring   \n840 that users adhere to usage guidelines or restrictions to access the model or implementing   \n841 safety filters.   \n842 \u2022 Datasets that have been scraped from the Internet could pose safety risks. The authors   \n843 should describe how they avoided releasing unsafe images.   \n844 \u2022 We recognize that providing effective safeguards is challenging, and many papers do   \n845 not require this, but we encourage authors to take this into account and make a best   \n846 faith effort.   \n847 12. Licenses for existing assets   \n848 Question: Are the creators or original owners of assets (e.g., code, data, models), used in   \n849 the paper, properly credited and are the license and terms of use explicitly mentioned and   \n850 properly respected?   \n851 Answer: [Yes]   \n852 Justification: We conduct our experiments on three public datasets. The original papers of   \n853 these three datasets were cited in our paper.   \n854 Guidelines:   \n855 \u2022 The answer NA means that the paper does not use existing assets.   \n856 \u2022 The authors should cite the original paper that produced the code package or dataset.   \n857 \u2022 The authors should state which version of the asset is used and, if possible, include a   \n858 URL.   \n859 \u2022 The name of the license (e.g., CC-BY 4.0) should be included for each asset.   \n860 \u2022 For scraped data from a particular source (e.g., website), the copyright and terms of   \n861 service of that source should be provided.   \n862 \u2022 If assets are released, the license, copyright information, and terms of use in the   \n863 package should be provided. For popular datasets, paperswithcode.com/datasets   \n864 has curated licenses for some datasets. Their licensing guide can help determine the   \n865 license of a dataset. ", "page_idx": 27}, {"type": "text", "text": "", "page_idx": 28}, {"type": "text", "text": "\u2022 For existing datasets that are re-packaged, both the original license and the license of the derived asset (if it has changed) should be provided. ", "page_idx": 29}, {"type": "text", "text": "67   \n868 \u2022 If this information is not available online, the authors are encouraged to reach out to   \n869 the asset\u2019s creators.   \n870 13. New Assets   \n871 Question: Are new assets introduced in the paper well documented and is the documentation   \n872 provided alongside the assets?   \n873 Answer: [NA]   \n874 Justification: This paper does not release new assets.   \n875 Guidelines:   \n876 \u2022 The answer NA means that the paper does not release new assets.   \n877 \u2022 Researchers should communicate the details of the dataset/code/model as part of their   \n878 submissions via structured templates. This includes details about training, license,   \n879 limitations, etc.   \n880 \u2022 The paper should discuss whether and how consent was obtained from people whose   \n881 asset is used.   \n882 \u2022 At submission time, remember to anonymize your assets (if applicable). You can either   \n883 create an anonymized URL or include an anonymized zip file.   \n884 14. Crowdsourcing and Research with Human Subjects   \n885 Question: For crowdsourcing experiments and research with human subjects, does the paper   \n886 include the full text of instructions given to participants and screenshots, if applicable, as   \n887 well as details about compensation (if any)?   \n888 Answer: [NA]   \n889 Justification: This paper does not involve crowdsourcing nor research with human subjects.   \n890 Guidelines:   \n891 \u2022 The answer NA means that the paper does not involve crowdsourcing nor research with   \n892 human subjects.   \n893 \u2022 Including this information in the supplemental material is fine, but if the main contribu  \n894 tion of the paper involves human subjects, then as much detail as possible should be   \n895 included in the main paper.   \n896 \u2022 According to the NeurIPS Code of Ethics, workers involved in data collection, curation,   \n897 or other labor should be paid at least the minimum wage in the country of the data   \n898 collector.   \n899 15. Institutional Review Board (IRB) Approvals or Equivalent for Research with Human   \n900 Subjects   \n901 Question: Does the paper describe potential risks incurred by study participants, whether   \n902 such risks were disclosed to the subjects, and whether Institutional Review Board (IRB)   \n903 approvals (or an equivalent approval/review based on the requirements of your country or   \n904 institution) were obtained?   \n905 Answer: [NA]   \n906 Justification: This paper does not involve crowdsourcing nor research with human subjects.   \n907 Guidelines:   \n\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with ", "page_idx": 29}, {"type": "text", "text": "human subjects.   \n\u2022 Depending on the country in which research is conducted, IRB approval (or equivalent) may be required for any human subjects research. If you obtained IRB approval, you should clearly state this in the paper.   \n\u2022 We recognize that the procedures for this may vary significantly between institutions and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the guidelines for their institution.   \n\u2022 For initial submissions, do not include any information that would break anonymity (if applicable), such as the institution conducting the review. ", "page_idx": 29}]