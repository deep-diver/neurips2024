[{"type": "text", "text": "Stochastic Optimal Control Matching ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Carles Domingo-Enrich Jiequn Han NYU & FAIR, Meta Flatiron Institute cd2754@nyu.edu jhan@flatironinstitute.org ", "page_idx": 0}, {"type": "text", "text": "Brandon Amos Joan Bruna Ricky T. Q. Chen FAIR, Meta NYU & Flatiron Institute FAIR, Meta bda@meta.com bruna@cims.nyu.edu rtqichen@meta.com ", "page_idx": 0}, {"type": "text", "text": "Abstract ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Stochastic optimal control, which has the goal of driving the behavior of noisy systems, is broadly applicable in science, engineering and artificial intelligence. Our work introduces Stochastic Optimal Control Matching (SOCM), a novel Iterative Diffusion Optimization (IDO) technique for stochastic optimal control that stems from the same philosophy as the conditional score matching loss for diffusion models. That is, the control is learned via a least squares problem by trying to fit a matching vector field. The training loss, which is closely connected to the cross-entropy loss, is optimized with respect to both the control function and a family of reparameterization matrices which appear in the matching vector field. The optimization with respect to the reparameterization matrices aims at minimizing the variance of the matching vector field. Experimentally, our algorithm achieves lower error than all the existing IDO techniques for stochastic optimal control for three out of four control problems, in some cases by an order of magnitude. The key idea underlying SOCM is the path-wise reparameterization trick, a novel technique that may be of independent interest. ", "page_idx": 0}, {"type": "text", "text": "1 Introduction ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Stochastic optimal control aims to drive the behavior of a noisy system in order to minimize a given cost. It has myriad applications in science and engineering: examples include the simulation of rare events in molecular dynamics [37, 36, 85, 41], finance and economics [63, 25], stochastic filtering and data assimilation [58, 68], nonconvex optimization [19], sampling [9], power systems and energy markets [8, 66], and robotics [77, 32]. Stochastic optimal has also been impactful in fields such as mean-field games [17], optimal transport [80, 81], backward stochastic differential equations (BSDEs) [14] and large deviations [24]. Recently, it has been the basis of algorithms to sample from unnormalized densities [84, 79, 9, 71]. ", "page_idx": 0}, {"type": "text", "text": "For continuous-time problems with low-dimensional state spaces, the standard approach to learn the optimal control is to solve the Hamilton-Jacobi-Bellman (HJB) partial differential equation (PDE) by gridding the space and using classical numerical methods. For high-dimensional problems, a large number of works parameterize the control using a neural network and train it applying a stochastic optimization algorithm on a loss function. These methods are known as Iterative Diffusion Optimization (IDO) techniques [59] (see Subsec. 2.2). ", "page_idx": 0}, {"type": "text", "text": "It is convenient to draw an analogy between stochastic optimal control and continuous normalizing flows (CNFs), which are a generative modeling technique where samples are generated by solving an ordinary differential equation (ODE) for which the vector field has been learned, initialized at a Gaussian sample. CNFs were introduced by [20] (building on top of Rezende and Mohamed [70]), and training them is similar to solving control problems because in both cases one needs to learn high-dimensional vector fields using neural networks, in continuous time. ", "page_idx": 0}, {"type": "text", "text": "", "page_idx": 1}, {"type": "text", "text": "The first algorithm developed to train normalizing flows was based on maximizing the likelihood of the generated samples [20, Sec. 4]. Obtaining the gradient of the maximum likelihood loss with respect to the vector field parameters requires backpropagating through the computation of the ODE trajectory, or equivalently, solving the adjoint ODE in parallel to the original ODE. Maximum likelihood CNFs (ML-CNFs) were superseded by diffusion models [75, 40, 76] and flow-matching, a.k.a. stochastic interpolant, methods [55, 1, 65, 2], which are currently the preferred algorithms to train CNFs. Aside from architectural improvements such as the UNet [73], a potential reason for the success of diffusion and flow matching models is that their functional landscape is convex, unlike for ML-CNFs. Namely, vector fields are learned by solving least squares regression problems where the goal is to fit a random matching vector field. Convex functional landscapes in combination with overparameterized models and moderate gradient variance can yield very stable training dynamics and help achieve low error. ", "page_idx": 1}, {"type": "text", "text": "Returning to stochastic optimal control, one of the best-performing IDO techniques amounts to choosing the control objective (equation 1) as the training loss (see (12)). As in ML-CNFs, computing the gradient of this loss requires backpropagating through the computation of the trajectories of the SDE (2), or equivalently, using an adjoint method. The functional landscape of the loss is highly non-convex, and the method is prone to unstable training (see green curve in the bottom right plot of Figure 3). In light of this, a natural idea is to develop the analog of diffusion model losses for the stochastic optimal control problem, to obtain more stable training and lower error, and this is what we set out to do in our work. Our contributions are as follows: ", "page_idx": 1}, {"type": "text", "text": "\u2022 We introduce Stochastic Optimal Control Matching (SOCM), a novel IDO algorithm in which the control is learned by solving a least-squares regression problem where the goal is to fti a random matching vector field which depends on a family of reparameterization matrices that are also optimized.   \n\u2022 We derive a bias-variance decomposition of the SOCM loss (Prop. 2). The bias term is equal to an existing IDO loss: the cross-entropy loss, which shows that both algorithms have the same landscape in expectation. However, SOCM has an extra flexibility in the choice of reparameterization matrices, which affect only the variance. Hence, we propose optimizing the reparameterization matrices to reduce the variance of the SOCM objective.   \n\u2022 The key idea that underlies the SOCM algorithm is the path-wise reparameterization trick (Prop. 1), which is a novel technique for estimating gradients of an expectation of a functional of a random process with respect to its initial value. It is of independent interest and may be more generally applicable outside of the settings considered in this paper.   \n\u2022 We perform experiments on four different settings where we have access to the ground-truth control. For three of these, SOCM obtains a lower $L^{2}$ error with respect to the ground-truth control than all the existing IDO techniques, with around $10\\times$ lower error than competing methods in some instances. ", "page_idx": 1}, {"type": "text", "text": "2 Framework ", "text_level": 1, "page_idx": 1}, {"type": "text", "text": "2.1 Setup and Preliminaries ", "text_level": 1, "page_idx": 1}, {"type": "text", "text": "Let $(\\Omega,\\mathcal{F},(\\mathcal{F}_{t})_{t\\geq0},\\mathcal{P})$ be a fixed filtered probability space on which is defined a Brownian motion $B=(B_{t})_{t\\geq0}$ . We consider the control-affine problem ", "page_idx": 1}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\underset{u\\in\\mathcal{U}}{\\operatorname*{min}}\\mathbb{E}\\big[\\int_{0}^{T}\\big(\\frac{1}{2}\\|u(X_{t}^{u},t)\\|^{2}\\!+\\!f(X_{t}^{u},t)\\big)\\,\\mathrm{d}t\\!+\\!g(X_{T}^{u})\\big],}\\\\ &{\\mathrm{s.t.}\\;\\mathrm{d}X_{t}^{u}\\!=\\!(b(X_{t}^{u},t)\\!+\\!\\sigma(t)u(X_{t}^{u},t))\\,\\mathrm{d}t\\!+\\!\\sqrt{\\lambda}\\sigma(t)\\mathrm{d}B_{t},X_{0}^{u}\\sim p_{0}}\\end{array}\n$$", "text_format": "latex", "page_idx": 1}, {"type": "text", "text": "and where $X_{t}^{u}\\in\\mathbb{R}^{d}$ is the state, $u:\\mathbb{R}^{d}\\times[0,T]\\rightarrow\\mathbb{R}^{d}$ is the feedback control and belongs to the set of admissible controls $\\boldsymbol{\\mathcal{U}}$ , $f:\\mathbb{R}^{d}\\times[0,T]\\rightarrow\\mathbb{R}$ is the state cost, $g:\\mathbb{R}^{d}\\rightarrow\\mathbb{R}$ is the terminal cost, $b:\\mathbb{R}^{d}\\times[0,T]\\rightarrow\\mathbb{R}^{d}$ is the base drift, and $\\bar{\\sigma}:[0,T]\\rightarrow\\mathbb{R}^{d\\times d}$ is the invertible diffusion coefficient and $\\lambda\\in(0,+\\infty)$ is the noise level. In App. A we formally define the set $\\boldsymbol{\\mathcal{U}}$ of admissible controls and describe the regularity assumptions needed on the control functions. In the remainder of the section we introduce relevant concepts in stochastic optimal control; we provide the most relevant proofs in App. B and refer the reader to Oksendal [60, Chap. 11] and N\u00fcsken and Richter [59, Sec. 2] for a similar, more extensive treatment. ", "page_idx": 1}, {"type": "text", "text": "Cost functional and value function The cost functional for the control $u$ , point $x$ and time $t$ is defined as $\\begin{array}{r}{J(u;x,t):=\\mathbb{E}\\big[\\int_{t}^{T}\\big(\\frac{1}{2}\\|u_{s}(X_{s}^{u})\\|^{2}+f_{s}(X_{s}^{u})\\big)\\,\\mathrm{d}t+g(X_{T}^{u})\\big|X_{t}^{u}=x\\big].}\\end{array}$ . That is, the cost functional is the expected value of the control objective restricted to the times $[t,T]$ with the initial value $x$ at time $t$ . The value function or optimal cost-to-go at $(x,t)$ is defined as the minimum value of the cost functional across all possible controls: ", "page_idx": 2}, {"type": "equation", "text": "$$\nV(x,t):=\\operatorname*{inf}_{u\\in\\mathcal{U}}J(u;x,t).\n$$", "text_format": "latex", "page_idx": 2}, {"type": "text", "text": "Hamilton-Jacobi-Bellman equation and optimal control If we define the infinitesimal generator $\\begin{array}{r}{L:=\\frac{\\lambda}{2}\\sum_{i,j=1}^{d}(\\sigma\\sigma^{\\top})_{i j}(t)\\partial_{x_{i}}\\partial_{x_{j}}+\\sum_{i=1}^{d}b_{i}(x,t)\\partial_{x_{i}}}\\end{array}$ , the value function solves the following Hamilton-Jacobi-Bellman (HJB) partial differential equation: ", "page_idx": 2}, {"type": "equation", "text": "$$\n\\begin{array}{r}{(\\partial_{t}+L)V(x,t)-\\frac{1}{2}\\|(\\sigma^{\\top}\\nabla V)(x,t)\\|^{2}+f(x,t)=0,\\quad\\quad\\quad\\quad V(x,T)=g(x).}\\end{array}\n$$", "text_format": "latex", "page_idx": 2}, {"type": "text", "text": "The verification theorem [62, Sec. 2.3] states that if a function $V$ solves the HJB equation above and has certain regularity conditions, then $V$ is the value function (3) of the problem (1)-(2). An implication of the verification theorem is that for every $u\\in\\mathcal{U}$ , ", "page_idx": 2}, {"type": "equation", "text": "$$\n\\begin{array}{r}{V(x,t)+\\mathbb{E}\\big[\\frac{1}{2}\\int_{t}^{T}\\|\\sigma^{\\top}\\nabla V+u\\|^{2}(X_{s}^{u},s)\\,\\mathrm{d}s\\big|\\,X_{t}^{u}=x\\big]=J(u,x,t).}\\end{array}\n$$", "text_format": "latex", "page_idx": 2}, {"type": "text", "text": "In particular, this implies that the unique optimal control is given in terms of the value function as $\\boldsymbol{u}^{*}\\dot{(\\boldsymbol{x},t)}=-{\\sigma}(t)^{\\top}\\dot{\\nabla}V(\\boldsymbol{x},t)$ . Equation (5) can be deduced by integrating the HJB equation (4) over $[t,T]$ , and taking the conditional expectation with respect to $X_{t}^{u}=x$ . We include the proof of (5) in App. B for completeness. ", "page_idx": 2}, {"type": "text", "text": "A pair of forward and backward SDEs (FBSDEs) Consider the pair of SDEs ", "page_idx": 2}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathrm{d}X_{t}=b(X_{t},t)\\,\\mathrm{d}t+\\sqrt{\\lambda}\\sigma(t)\\mathrm{d}B_{t},\\qquad X_{0}\\sim p_{0},}\\\\ &{\\mathrm{d}Y_{t}=(-f(X_{t},t)+\\frac{1}{2}\\|Z_{t}\\|^{2})\\,\\mathrm{d}t+\\sqrt{\\lambda}\\langle Z_{t},\\mathrm{d}B_{t}\\rangle,\\qquad Y_{T}=g(X_{T}).}\\end{array}\n$$", "text_format": "latex", "page_idx": 2}, {"type": "text", "text": "where $Y:\\Omega\\times[0,T]\\rightarrow\\mathbb{R}$ and $Z:\\Omega\\times[0,T]\\rightarrow\\mathbb{R}^{d}$ are progressively measurable 1 random processes. It turns out that $Y_{t}$ and $Z_{t}$ defined as $Y_{t}:=V(X_{t},t)$ and $Z_{t}:=\\sigma(t)^{\\top}\\nabla V(X_{t},t)\\,=\\,-u^{*}(X_{t},t)$ satisfy (7). We include the proof in App. B for completeness. ", "page_idx": 2}, {"type": "text", "text": "An analytic expression for the value function From the forward-backward equations (6)-(7), one can derive a closed-form expression for the value function $V$ : ", "page_idx": 2}, {"type": "equation", "text": "$$\n\\begin{array}{r}{V(x,t)\\!=\\!-\\lambda\\log\\mathbb{E}\\big[\\exp\\big(-\\lambda^{-1}\\int_{t}^{T}f(X_{s},s)\\,\\mathrm{d}s-\\lambda^{-1}g(X_{T})\\big)\\big|X_{t}=x\\big],}\\end{array}\n$$", "text_format": "latex", "page_idx": 2}, {"type": "text", "text": "where $X_{t}$ is the solution of the uncontrolled SDE (6). This is a classical result, but we still include its proof in App. B. Given that $\\boldsymbol{u}^{*}(\\boldsymbol{x},t)=-\\boldsymbol{\\sigma}(t)^{\\top}\\nabla\\dot{V}(\\boldsymbol{x},t)$ , an immediate, yet important, consequence of (8) is the following path-integral representation of the optimal control: ", "page_idx": 2}, {"type": "equation", "text": "$$\n\\begin{array}{r}{u^{*}(x,t)\\!=\\!\\lambda\\sigma(t)^{\\top}\\nabla_{x}\\log\\mathbb{E}\\big[\\exp\\big(-\\lambda^{-1}\\int_{t}^{T}f(X_{s},s)\\,\\mathrm{d}s\\!-\\!\\lambda^{-1}g(X_{T})\\big)\\big|X_{t}=x\\big]\\;.}\\end{array}\n$$", "text_format": "latex", "page_idx": 2}, {"type": "text", "text": "Remark this equation involves the gradient of logarithm of a conditional expectation, which is reminiscent of the vector fields that are learned when training diffusion models. For example, the target vector field for variance-exploding score-based diffusion loss [76] can be expressed as $\\begin{array}{r}{\\nabla_{x}\\log{p_{t}(x)}\\,=\\,\\nabla_{x}\\log\\mathbb{E}_{Y\\sim p_{\\mathrm{data}}}[\\frac{\\exp\\left(-\\|x-Y\\|^{2}/\\left(2\\sigma_{t}^{2}\\right)\\right)}{\\left(2\\pi\\sigma_{t}^{2}\\right)^{d/2}}]}\\end{array}$ a[ exp(\u2212(\u22252x\u03c0\u2212\u03c3Y2 )\u2225d2//2(2\u03c3t2 ))]. Note, however, that in (9) the gradient is taken with respect to the initial condition of the process, which requires the development of novel techniques. ", "page_idx": 2}, {"type": "text", "text": "Conditioned diffusions Let $\\mathcal{C}=C([0,T];\\mathbb{R}^{d})$ be the Wiener space of continuous functions from $[0,T]$ to $\\mathbb{R}^{d}$ equipped with the supremum norm, and let $\\mathcal{P}(\\mathcal{C})$ be the space of Borel probability measures over $\\mathcal{C}$ . For each control $u\\in\\mathcal{U}$ , the controlled process in equation (2) induces a probability measure in $\\mathscr{P}(\\mathscr{C})$ , as the law of the paths $X_{t}^{u}$ , which we refer to as $\\mathbb{P}^{u}$ . We let $\\mathbb{P}$ be the probability measure induced by the uncontrolled process (6), and define the work functional ", "page_idx": 2}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathcal{W}(X,t):=\\int_{t}^{T}f(X_{s},s)\\,\\mathrm{d}s+g(X_{T}).}\\end{array}\n$$", "text_format": "latex", "page_idx": 2}, {"type": "text", "text": "It turns out (Lemma 2 in App. B) that the Radon-Nikodym derivative $\\frac{d\\mathbb{P}^{u^{*}}}{d\\mathbb{P}}$ satisfies ${\\frac{d\\mathbb{P}^{u^{*}}}{d\\mathbb{P}}}(X)=$ exp $\\left(\\lambda^{-1}\\big(V(X_{0},0)-\\mathcal{W}(X,0)\\big)\\right)$ . Also, a straight-forward application of the Girsanov theorem for SDEs (Cor. 1) shows that ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\frac{d\\mathbb{P}^{u^{*}}}{\\vert\\mathbb{P}^{u^{*}}}(X^{u^{*}})\\!=\\!\\exp\\left(-\\lambda^{-1/2}\\int_{0}^{T}\\langle u^{*}(X_{t}^{u^{*}},t)\\!-\\!u(X_{t}^{u^{*}},t),\\mathrm{d}B_{t}\\rangle-\\frac{\\lambda^{-1}}{2}\\int_{0}^{T}\\Vert u^{*}(X_{t}^{u^{*}},t)-u(X_{t}^{u^{*}},t)\\Vert^{2}\\,\\mathrm{d}t\\right).}\\end{array}\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "which means that the only control $u\\in\\mathcal{U}$ such that $\\mathbb{P}^{u}=\\mathbb{P}^{u^{*}}$ is the optimal control itself. ", "page_idx": 3}, {"type": "text", "text": "2.2 Existing approaches and related work ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "Low-dimensional case: solving the HJB equation For low-dimensional control problems $(d\\leq3)$ ), it is possible to grid the domain and use a numerical PDE solver to find a solution to the HJB equation (4). The main approaches include finite difference methods [11, 57, 4], which approximate the derivatives and gradients of the value function using finite differences, finite element methods [47], which involve restricting the solution to domain-dependent function spaces, and semi-Lagrangian schemes [21, 13, 12], which trace back characteristics and have better stability than finite difference methods. See Greif [33] for an overview on these techniques, and Ban\u02c7as et al. [4] for a comparison between them. Hutzenthaler et al. [44] introduced the multilevel Picard method, which leverages the Feynman-Kac and the Bismut-Elworthy-Li formulas to beat the curse of dimensionality in some settings [6, 46, 45, 43]. ", "page_idx": 3}, {"type": "text", "text": "High dimensional methods leveraging FBSDEs The FBSDE formulation in equations (6)-(7) has given rise to multiple methods to learn controls. One such approach is least-squares Monte Carlo (see Pham [63, Chapter 3] and Gobet [28] for an introduction, and Gobet et al. [30], Zhang et al. [83] for an extensive analysis), where trajectories from the forward process (6) are sampled, and then regression problems are solved backwards in time to estimate the expected future cost in the spirit of dynamic programming. A second method that exploits FBSDEs was proposed by E et al. [22], Han et al. [35]. They parameterize the control using a neural network $u_{\\theta}$ , and use stochastic gradient algorithms to minimize the loss $\\mathcal{L}(u_{\\theta},y_{0})=\\mathbb{E}[\\bar{(Y_{T}(y_{0},u_{\\theta})-g(X_{T}))^{2}}]$ , where $Y_{T}(y_{0},u_{\\theta})$ is the process in (7) with initial condition $y_{0}$ and control $u_{\\theta}$ . This algorithm can be seen as a shooting method, where the initial condition and the control are learned to match the terminal condition. Multiple recent works have combined neural networks with FBSDE Monte Carlo methods for parabolic and elliptic PDEs [5, 18, 86], control [7, 39], multi-agent games [34, 15, 16]; see [23] for a more comprehensive review. ", "page_idx": 3}, {"type": "text", "text": "Many of the methods referenced above and some additional ones can be seen from a common perspective using controlled diffusions. As observed in equation (11), the key idea is that learning the optimal control is equivalent to finding a control $u$ such that the induced probability measure $\\mathbb{P}^{u}$ on paths is equal to the probability measure $\\mathbb{P}^{u^{*}}$ for the optimal control. In the paragraphs below we cover several loss that fall into this framework. All the losses below can be optimized using a common algorithmic framework, which we describe in Algorithm 1. For more details, we refer the reader to N\u00fcsken and Richter [59], which introduced this perspective and named such methods Iterative Diffusion Optimization (IDO) techniques. For simplicity, we introduce the losses for the setting in which the initial distribution $p_{0}$ is concentrated at a single point $x_{\\mathrm{init}}$ ; we cover the general setting in App. B. ", "page_idx": 3}, {"type": "text", "text": "The relative entropy loss and the adjoint method The relative entropy loss is defined as the Kullback-Leibler divergence between $\\mathbb{P}^{u}$ and $\\mathbb{P}^{u^{*}}\\colon\\mathbb{E}_{\\mathbb{P}^{u}}[\\log\\frac{d\\mathbb{P}^{u}}{d\\mathbb{P}^{u^{*}}}]$ . Upon removing constant terms and factors, this loss is equivalent to (see Lemma 3 in App. B): ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\textstyle\\mathcal{L}_{\\mathrm{Adj}}(u):=\\mathbb{E}\\big[\\int_{0}^{T}\\big(\\frac{1}{2}\\|u(X_{t}^{u},t)\\|^{2}\\!+f(X_{t}^{u},t)\\big)\\,\\mathrm{d}t\\!+g(X_{T}^{u})\\big].}\\end{array}\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "This is exactly the control objective in (1). This fact has been studied extensively [10, 31, 36, 48, 67]. Hence, the relative entropy loss is very natural and widely used; see Onken et al. [61], Zhang and Chen [84] for examples on multiagent systems and sampling. ", "page_idx": 3}, {"type": "text", "text": "Solving optimization problems of the form (12) has a long history that dates back to Pontryagin [64]. Note that $\\mathcal{L}_{\\mathrm{Adj}}(u)$ depends on $u$ both explicitly, and implicitly through the process $X^{u}$ . To compute the gradient $\\nabla_{\\theta}\\hat{\\mathcal{L}}_{\\mathrm{Adj}}(u_{\\theta_{n}})$ of a Monte Carlo approximation $\\hat{\\mathscr{L}}_{\\mathrm{Adj}}(u_{\\theta_{n}})$ of $\\mathcal{L}_{\\mathrm{Adj}}(u_{\\theta_{n}})$ as required by Algorithm 1, we need to backpropagate through the simulation of the trajectories, which is why ", "page_idx": 3}, {"type": "text", "text": "Input: State cost $f(x,t)$ , terminal cost $g(x)$ , diffusion coeff. $\\sigma(t)$ , base drift $b(x,t)$ , noise level $\\lambda$ , number of iterations $N$ , batch size $m$ , number of time steps $K$ , initial control parameters $\\theta_{0}$ , loss $\\mathcal{L}\\in\\left\\{\\mathcal{L}_{\\mathrm{Adj}}(12),\\mathcal{L}_{\\mathrm{CE}}(13),\\mathcal{L}_{\\mathrm{Var}_{v}}(16),\\mathcal{L}_{\\mathrm{Var}_{v}}^{\\mathrm{log}}(17),\\mathcal{L}_{\\mathrm{Mom}_{v}}(18)\\right\\}$   \n1 for $n\\in\\{0,\\dots,N-1\\}$ do   \n2 Simulate $m$ trajectories of the process $X^{v}$ controlled by $v=u_{\\theta_{n}}$ , e.g., using Euler-Maruyama updates   \n3 if $\\mathcal{L}\\ \\neq\\ \\mathcal{L}_{\\mathrm{Adj}}$ then detach the $m$ trajectories from the computational graph, so that gradients do not backpropagate;   \n4 Using the $m$ trajectories, compute an $m$ -sample Monte Carlo approximation $\\hat{\\mathcal{L}}(u_{\\theta_{n}})$ of the loss $\\mathcal{L}(u_{\\theta_{n}})$   \n5 Compute the gradients $\\nabla_{\\boldsymbol{\\theta}}\\hat{\\mathcal{L}}(u_{\\boldsymbol{\\theta}_{n}})$ of $\\hat{\\mathcal{L}}(u_{\\theta_{n}})$ w.r.t. $\\theta_{n}$   \n6 Obtain $\\theta_{n+1}$ with via an Adam update on $\\theta_{n}$ (or another stochastic algorithm)   \n7 end Output: Learned control $u_{\\theta_{N}}$ ", "page_idx": 4}, {"type": "text", "text": "we do not detach them from the computational graph. One can alternatively compute the gradient $\\nabla_{\\theta}\\hat{\\mathcal{L}}_{\\mathrm{Adj}}(u_{\\theta_{n}})$ by explicitly solving an ODE, a technique known as the adjoint method. The adjoint method was introduced by Pontryagin [64], popularized in deep learning by Chen et al. [20], and further developed for SDEs in Li et al. [54]. ", "page_idx": 4}, {"type": "text", "text": "The cross-entropy loss The cross-entropy loss is defined as the Kullback-Leibler divergence between $\\mathbb{P}^{u^{*}}$ and $\\mathbb{P}^{u}$ , i.e., flipping the order of the two measures: $\\mathbb{E}_{\\mathbb{P}^{u^{*}}}[\\log\\frac{d\\mathbb{P}^{u^{*}}}{d\\mathbb{P}^{u}}]$ . For an arbitrary , this loss is equivalent to the following one (see Prop. 3(i) in App. B): ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathsf{\\lambda}_{\\mathrm{{CE}}}(u):=\\mathbb{E}\\big[\\big(-\\lambda^{-1/2}\\int_{0}^{T}\\langle u(X_{t}^{v},t),\\mathrm{d}B_{t}\\rangle-\\lambda^{-1}\\int_{0}^{T}\\langle u(X_{t}^{v},t),v(X_{t}^{v},t)\\rangle\\,\\mathrm{d}t+\\frac{\\lambda^{-1}}{2}\\int_{0}^{T}\\|u(X_{t}^{v},t)\\|^{2}\\,\\mathrm{d}B_{t}\\big)\\big]}\\\\ &{\\qquad\\qquad\\times\\,\\exp\\big(-\\lambda^{-1}\\mathcal{W}(X^{v},0)\\!-\\!\\lambda^{-1/2}\\int_{0}^{T}\\langle v(X_{t}^{v},t),\\mathrm{d}B_{t}\\rangle\\!-\\!\\frac{\\lambda^{-1}}{2}\\int_{0}^{T}\\|v(X_{t}^{v},t)\\|^{2}\\,\\mathrm{d}t\\big)\\big]\\,.}\\end{array}\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "The cross-entropy loss has a rich literature [38, 49, 74, 85] and has been recently used in applications such as molecular dynamics [41]. Furthermore, we note that the cross-entropy loss can be significantly simplified and written in terms of the unnormalized $L^{2}$ error of the control $u$ with respect to the optimal control $u^{*}$ : ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathcal{L}_{\\mathrm{CE}}(u)=\\frac{\\lambda^{-1}}{2}\\mathbb{E}\\big[\\int_{0}^{T}\\|u^{*}(X_{t}^{u^{*}},t)-u(X_{t}^{u^{*}},t)\\|^{2}\\,\\mathrm{d}t\\times\\exp\\big(-\\lambda^{-1}V(X_{0}^{u^{*}},0)\\big)\\big]\\;.}\\end{array}\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "This characterization, which is proven in Prop. 3(ii) in App. B, is relevant for us because a similar one can be written for the loss that we propose (see Prop. 2). ", "page_idx": 4}, {"type": "text", "text": "Variance and log-variance losses For an arbitrary $v\\in\\mathcal{U}$ , the variance and the log-variance losses are defined as $\\begin{array}{r}{\\tilde{\\mathcal{L}}_{\\mathrm{Var}_{v}}(u)=\\mathrm{Var}_{\\mathbb{P}^{v}}\\big(\\frac{\\mathrm{d}\\mathbb{P}^{u^{*}}}{\\mathrm{d}\\mathbb{P}^{u}}\\big)}\\end{array}$ and $\\begin{array}{r}{\\tilde{\\mathcal{L}}_{\\mathrm{Var}_{v}}^{\\mathrm{log}}(u)=\\mathrm{Var}_{\\mathbb{P}^{v}}(\\log\\frac{\\mathrm{d}\\mathbb{P}^{u^{*}}}{\\mathrm{d}\\mathbb{P}^{u}})}\\end{array}$ whenever $\\mathbb{E}_{\\mathbb{P}^{v}}|\\frac{\\mathrm{d}\\mathbb{P}^{u^{*}}}{\\mathrm{d}\\mathbb{P}^{u}}|<$ $+\\infty$ and $\\begin{array}{r}{\\mathbb{E}_{\\mathbb{P}^{v}}|\\log\\frac{d\\mathbb{P}^{u^{*}}}{d\\mathbb{P}^{u}}|<+\\infty}\\end{array}$ , respectively. Define ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\tilde{Y}_{T}^{u,v}=-\\lambda^{-1}\\int_{0}^{T}\\langle u(X_{t}^{v},t),v(X_{t}^{v},t)\\rangle\\,\\mathrm{d}t}\\\\ &{\\ -\\lambda^{-1}\\int_{0}^{T}f(X_{t}^{v},t)\\,\\mathrm{d}t-\\lambda^{-1/2}\\int_{0}^{T}\\langle u(X_{t}^{v},t),\\mathrm{d}B_{t}\\rangle}\\\\ &{\\ +\\frac{\\lambda^{-1}}{2}\\int_{0}^{T}\\|u(X_{t}^{v},t)\\|^{2}\\,\\mathrm{d}t.}\\end{array}\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "Then, $\\tilde{\\mathcal{L}}_{\\mathrm{Var}_{v}}$ and $\\tilde{\\mathcal{L}}_{\\mathrm{Var}_{v}}^{\\mathrm{log}}$ are equivalent, respectively, to the following losses (see Lemma 4): ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathcal{L}_{\\operatorname{Var}_{v}}(u):=\\operatorname{Var}\\big(\\exp\\big(\\tilde{Y}_{T}^{u,v}-\\lambda^{-1}g(X_{T}^{v})\\big)\\big),}\\\\ &{\\mathcal{L}_{\\operatorname{Var}_{v}}^{\\log}(u):=\\operatorname{Var}\\big(\\tilde{Y}_{T}^{u,v}-\\lambda^{-1}g(X_{T}^{v})\\big),}\\end{array}\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "The variance and log-variance losses were introduced by N\u00fcsken and Richter [59]. Unlike for the cross-entropy loss, the choice of the control $v$ does lead to different losses. When using $\\mathcal{L}_{\\mathrm{Var}_{v}}$ or LlVoagrv in Algorithm 1, the variance is computed across the m trajectories in each batch. ", "page_idx": 4}, {"type": "text", "text": "Moment loss For an arbitrary $v\\in\\mathcal{U}$ , the moment loss is defined as ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\mathcal{L}_{\\mathrm{Mom}_{v}}(u,y_{0})=\\mathbb{E}[(\\tilde{Y}_{T}^{u,v}+y_{0}-\\lambda^{-1}g(X_{T}^{v}))^{2}],\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "where $\\tilde{Y}_{T}^{u,v}$ is defined in (15). Note the similarity with the log-variance loss (17); the optimal value of $y_{0}$ for a fixed $u$ is $y_{0}^{*}\\,=\\,\\mathbb{E}[\\lambda^{-1}g(X_{T}^{v})\\,-\\,\\tilde{Y}_{T}^{u,v}]$ , and plugging this into (18) yields exactly the log-variance loss. The moment loss was introduced by Hartmann et al. [39, Section III.B], and it is a generalization of the FBSDE method pioneered by E et al. [22], Han et al. [35] and referenced earlier in this subsection, which corresponds to setting $v=0$ . ", "page_idx": 5}, {"type": "text", "text": "3 Stochastic Optimal Control Matching ", "text_level": 1, "page_idx": 5}, {"type": "text", "text": "In this section we present our loss, Stochastic Optimal Control Matching (SOCM). The corresponding method, which we describe in Algorithm 2, falls into the class of IDO techniques described in Subsec. 2.2. The general idea is to leverage the analytic expression of $u^{*}$ in (9) to write a least squares loss for $u$ , and the main challenge is to reexpress the gradient of a conditional expectation with respect to the initial condition of the process. We do that using a novel technique which introduces certain arbitrary matrix-valued functions $M_{t}$ , that we also optimize. ", "page_idx": 5}, {"type": "text", "text": "Theorem 1 (SOCM loss). For each $t\\,\\in\\,[0,T],$ , let $M_{t}:[t,T]\\rightarrow\\mathbb{R}^{d\\times d}$ be an arbitrary matrixvalued differentiable function such that $M_{t}(t)\\,=\\,\\mathrm{Id}$ . Let $v\\,\\in\\,{\\mathcal{U}}$ be an arbitrary control. Let $\\mathcal{L}_{\\mathrm{SOCM}}:L^{2}(\\mathbb{R}^{d}\\times[0,T];\\mathbb{R}^{d})\\times L^{2}([0,T]^{2};\\mathbb{R}^{d\\times d})\\to\\mathbb{R}$ be the loss function defined as ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathcal{L}_{\\mathrm{SOCM}}(u,M):=\\mathbb{E}\\big[\\frac{1}{T}\\int_{0}^{T}\\big\\|u(X_{t}^{v},t)-w(t,v,X^{v},B,M_{t})\\big\\|^{2}\\,\\mathrm{d}t\\times\\alpha(v,X^{v},B)\\big]\\,,}\\end{array}\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "where $X^{v}$ is the process controlled by $v$ (i.e., $d X_{t}^{v}=\\left(b(X_{t}^{v},t)+\\sigma(t)v(X_{t}^{v},t)\\right)\\mathrm{d}t+\\sqrt{\\lambda}\\sigma(t)\\,\\mathrm{d}B_{t}$ and $X_{0}^{v}\\sim p_{0},$ , and ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{w(t,v,X^{v},B,M_{t})=\\sigma(t)^{\\top}\\big(-\\int_{t}^{T}M_{t}(s)\\nabla_{x}f(X_{s}^{v},s)\\,\\mathrm{d}s-M_{t}(T)\\nabla g(X_{T}^{v})}\\\\ &{\\qquad\\qquad\\qquad\\quad+\\int_{t}^{T}(M_{t}(s)\\nabla_{x}b(X_{s}^{v},s)-\\partial_{s}M_{t}(s))(\\sigma^{-1})^{\\top}(s)v(X_{s}^{v},s)\\,\\mathrm{d}s}\\\\ &{\\qquad\\qquad\\qquad\\quad+\\lambda^{1/2}\\int_{t}^{T}(M_{t}(s)\\nabla_{x}b(X_{s}^{v},s)-\\partial_{s}M_{t}(s))(\\sigma^{-1})^{\\top}(s)\\mathrm{d}B_{s}\\big),}\\\\ &{\\qquad\\qquad\\alpha(v,X^{v},B)=\\exp\\big(-\\lambda^{-1}\\int_{0}^{T}f(X_{t}^{v},t)\\,\\mathrm{d}s-\\lambda^{-1}g(X_{T}^{v})}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\quad-\\lambda^{-1/2}\\int_{0}^{T}\\langle v(X_{t}^{v},t),\\mathrm{d}B_{t}\\rangle-\\frac{\\lambda^{-1}}{2}\\int_{0}^{T}\\|v(X_{t}^{v},t)\\|^{2}\\,\\mathrm{d}t\\big).}\\end{array}\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "$\\mathcal{L}_{\\mathrm{SOCM}}$ has a unique optimum $(u^{*},M^{*})$ , where $u^{*}$ is the optimal control. ", "page_idx": 5}, {"type": "text", "text": "We refer to $M=(M_{t})_{t\\in[0,T]}$ as the family of reparametrization matrices, to the random vector field $w$ as the matching vector field, and to $\\alpha$ as the importance weight. We present a proof sketch of Thm. 1; the full proofs for all the results in this section are in App. C. ", "page_idx": 5}, {"type": "text", "text": "Proof sketch of Thm. 1 Let $X$ be the uncontrolled process (6). Consider the loss ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\tilde{\\mathcal{L}}(u)=\\mathbb{E}\\big[\\frac{1}{T}\\int_{0}^{T}\\big\\lVert u(X_{t},t)-u^{*}(X_{t},t)\\big\\rVert^{2}\\,\\mathrm{d}t\\,\\exp\\big(-\\lambda^{-1}\\int_{0}^{T}f(X_{t},t)\\,\\mathrm{d}t-\\lambda^{-1}g(X_{T})\\big)\\big]}\\\\ &{\\qquad=\\mathbb{E}\\big[\\frac{1}{T}\\int_{0}^{T}\\big(\\big\\lVert u(X_{t},t)\\big\\rVert^{2}-2\\langle u(X_{t},t),u^{*}(X_{t},t)\\rangle+\\big\\lVert u^{*}(X_{t},t)\\big\\rVert^{2}\\big)\\,\\mathrm{d}t}\\\\ &{\\qquad\\qquad\\qquad\\times\\,\\exp\\big(-\\lambda^{-1}\\int_{0}^{T}f(X_{t},t)\\,\\mathrm{d}t-\\lambda^{-1}g(X_{T})\\big)\\big].}\\end{array}\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "Clearly, the only optimum of this loss is the optimal control $\\boldsymbol{u}^{*}$ . Using the analytic expression of $\\boldsymbol{u}^{*}$ in (9), the cross-term can be rewritten as (see Lemma 5 in App. C): ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{E}\\big[\\frac{1}{T}\\int_{0}^{T}\\langle u(X_{t},t),u^{*}(X_{t},t)\\rangle\\,\\mathrm{d}t\\,\\exp\\big(-\\lambda^{-1}\\int_{0}^{T}f(X_{t},t)\\,\\mathrm{d}t-\\lambda^{-1}g(X_{T})\\big)\\big]}\\\\ &{=\\lambda\\mathbb{E}\\big[\\frac{1}{T}\\int_{0}^{T}\\big\\langle u(X_{t},t),\\sigma(t)^{\\top}\\nabla_{x}\\mathbb{E}\\big[\\exp\\big(-\\lambda^{-1}\\int_{t}^{T}f(X_{s},s)\\,\\mathrm{d}s-\\lambda^{-1}g(X_{T})\\big)\\big|X_{t}=x\\big]\\big\\rangle}\\\\ &{\\qquad\\qquad\\times\\exp\\big(-\\lambda^{-1}\\int_{0}^{t}f(X_{s},s)\\,\\mathrm{d}s\\big)\\,\\mathrm{d}t\\big].}\\end{array}\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "It remains to evaluate the conditional expectation $\\begin{array}{r l}{\\nabla_{x}\\mathbb{E}\\big[\\exp\\big(\\mathrm{~-~}\\,\\lambda^{-1}\\int_{t}^{T}f(X_{s},s)\\,\\mathrm{d}s}&{{}-}\\end{array}$ $\\lambda^{-1}g(X_{T})\\big)\\big|X_{t}\\,=\\,x\\big]$ , which we do by a \u201creparameterization trick\u201d that shifts the dependence on the initial value $x$ into the stochastic processes\u2014here we introduce a free variable $M_{t}$ \u2014and then applying Girsanov theorem. We coin this the path-wise reparameterization trick: ", "page_idx": 5}, {"type": "text", "text": "Proposition 1 (Path-wise reparameterization trick for stochastic optimal control). For each $t\\in[0,T]$ , let $M_{t}:[t,T]\\rightarrow\\mathbb{R}^{d\\times d}$ be an arbitrary continuously differentiable function matrix-valued function ", "page_idx": 5}, {"type": "text", "text": "such that $M_{t}(t)={\\mathrm{Id}}.$ . We have that ", "page_idx": 6}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\nabla_{x}\\mathbb{E}\\big[\\exp\\big(-\\lambda^{-1}\\int_{t}^{T}f(X_{s},s)\\,\\mathrm{d}s-\\lambda^{-1}g(X_{T})\\big)\\big\\vert X_{t}=x\\big]}\\\\ &{=\\mathbb{E}\\big[\\big(-\\lambda^{-1}\\int_{t}^{T}M_{t}(s)\\nabla_{x}f(X_{s},s)\\,\\mathrm{d}s-\\lambda^{-1}M_{t}(T)\\nabla g(X_{T})}\\\\ &{\\qquad\\qquad+\\,\\lambda^{-1/2}\\int_{t}^{T}(M_{t}(s)\\nabla_{x}b(X_{s},s)-\\partial_{s}M_{t}(s))(\\sigma^{-1})^{\\top}(s)\\mathrm{d}B_{s}\\big)}\\\\ &{\\qquad\\qquad\\times\\exp\\big(-\\lambda^{-1}\\int_{t}^{T}f(X_{s},s)\\,\\mathrm{d}s-\\lambda^{-1}g(X_{T})\\big)\\big\\vert X_{t}=x\\big].}\\end{array}\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "We prove a more general form of this result (Prop. 4) in Subsec. C.2 and also provide an intuitive derivation in Subsec. C.3. In the proof of Prop. 4, the reparameterization matrices $M_{t}$ arise as the gradients of a perturbation to the process $X_{t}$ . Similar ideas can potentially be applied to derive losses for generative modeling. If we plug (23) into the right-hand side of (22), and then this back into (21), and we complete the square, we obtain that for some constant $K$ independent of $u$ , ", "page_idx": 6}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\tilde{\\mathcal{L}}(u)=\\mathbb{E}\\big[\\frac{1}{T}\\int_{0}^{T}\\big\\|u(X_{t},t)+\\sigma(t)\\big(\\int_{t}^{T}M_{t}(s)\\nabla_{x}f(X_{s},s)\\,\\mathrm{d}s+M_{t}(T)\\nabla g(X_{T})}\\\\ &{\\qquad\\qquad\\qquad-\\lambda^{1/2}\\int_{t}^{T}(M_{t}(s)\\nabla_{x}b(X_{s},s)-\\partial_{s}M_{t}(s))(\\sigma^{-1})^{\\top}(s)\\mathrm{d}B_{s}\\big)\\big\\|^{2}\\,\\mathrm{d}t}\\\\ &{\\qquad\\qquad\\quad\\times\\exp\\big(-\\lambda^{-1}\\int_{0}^{T}f(X_{t},t)\\,\\mathrm{d}t-\\lambda^{-1}g(X_{T})\\big)\\big]+K.}\\end{array}\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "If we perform a change of process from $X$ to $X^{v}$ applying the Girsanov theorem (Cor. 1 in App. C), we obtain the loss $\\bar{\\mathcal{L}_{\\mathrm{SOCM}}}(u,M)$ . \u53e3 ", "page_idx": 6}, {"type": "text", "text": "The following result clarifies the role of reparameterization matrices, connecting the SOCM and cross-entropy losses. ", "page_idx": 6}, {"type": "text", "text": "Proposition 2 (Bias-variance decomposition of the SOCM loss). The SOCM loss decomposes into $a$ bias term that only depends on u and a variance term that only depends on $M$ : ", "page_idx": 6}, {"type": "equation", "text": "$$\n\\mathcal{L}_{\\mathrm{SOCM}}(u,M)=\\underbrace{\\mathrm{CondVar}(w;M)}_{U n n o r m a l i z e d\\ e x p e c t e d}+\\underbrace{\\mathbb{E}\\Big[\\frac{1}{T}\\int_{0}^{T}\\big|\\big|u(X_{t}^{u^{*}},t)-u^{*}(X_{t}^{u^{*}},t)\\big|\\big|^{2}\\,\\mathrm{d}t\\,e^{-\\lambda^{-1}V(X_{0}^{u^{*}},0)}\\Big]}_{U n n o r m a l i z e d\\ t h a s\\,o f u},\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "where ", "page_idx": 6}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathrm{>ondVar}(w;M)\\!=\\!\\mathbb{E}\\big[\\!\\frac{1}{T}\\!\\int_{0}^{T}\\big\\|{w}(t,v,X^{v},B,M_{t})\\!-\\!\\underbrace{\\frac{\\mathbb{E}[w(t,v,X^{v},B,M_{t})\\alpha(v,X^{v},B)|X_{t}^{v},t]}{\\mathbb{E}[\\alpha(v,X^{v},B)|X_{t}^{v},t]}}_{u^{*}(X_{t}^{v},t)}\\big\\|^{2}\\,\\mathrm{d}t\\,\\alpha(v,X^{v},B)\\big]}\\end{array}\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "Remark that the bias term in equation (24) is equal to the characterization of the cross-entropy loss in (14). In other words, the landscape of $\\mathcal{L}_{\\mathrm{SOCM}}(u,M)$ with respect to $u$ is the landscape of the cross-entropy loss $\\mathcal{L}_{\\mathrm{CE}}(u)$ . Thus, the SOCM loss can be seen as some form of variance reduction method for the cross-entropy loss, and performs substantially better experimentally (Sec. 4). Yet, the expressions of the SOCM loss and the cross-entropy loss are very different; the former is a least squares loss and is expressed in terms of the gradients of the costs. ", "page_idx": 6}, {"type": "text", "text": "Algorithm 2 Stochastic Optimal Control Matching (SOCM) ", "text_level": 1, "page_idx": 6}, {"type": "text", "text": "Input: State cost $f(x,t)$ , terminal cost $g(x)$ , diffusion coeff. $\\sigma(t)$ , base drift $b(x,t)$ , noise level $\\lambda$ , number of iterations $N$ , batch size $m$ , number of time steps $K$ , initial control parameters $\\theta_{0}$ , initial matrix parameters $\\omega_{0}$ , loss $\\mathcal{L}_{\\mathrm{SOCM}}$ in (19)   \n1 for $n\\in\\^{-}\\{0,\\dots,N-1\\}$ do   \n2 Simulate $m$ trajectories of the process $X^{v}$ controlled by $v=u_{\\theta_{n}}$ , e.g., using Euler-Maruyama updates   \n3 Detach the $m$ trajectories from the computational graph, so that gradients do not backpropagate   \n4 Using the $m$ trajectories, compute an $m$ -sample Monte-Carlo approximation $\\hat{\\mathcal{L}}_{\\mathrm{SOCM}}(u_{\\theta_{n}},M_{\\omega_{n}})$ of the loss $\\mathcal{L}_{\\mathrm{SOCM}}(u_{\\theta_{n}},M_{\\omega_{n}})$ in (19) Compute the gradients $\\nabla_{(\\theta,\\omega)}\\hat{\\mathcal{L}}_{\\mathrm{SOCM}}(u_{\\theta_{n}},M_{\\omega_{n}})$ of $\\hat{\\mathcal{L}}_{\\mathrm{SOCM}}(u_{\\theta_{n}},M_{\\omega_{n}})$ at $(\\theta_{n},\\omega_{n})$ Obtain $\\theta_{n+1}$ , $\\omega_{n+1}$ with via an Adam update on $\\theta_{n}$ , $\\omega_{n}$ , resp. ", "page_idx": 6}, {"type": "text", "text": "7 end ", "text_level": 1, "page_idx": 6}, {"type": "text", "text": "Output: Learned control $u_{\\theta_{N}}$ ", "page_idx": 6}, {"type": "text", "text": "For good training performance, it is critical that the gradients have high signal-to-noise ratio. Looking at the SOCM loss, a good proxy for low gradient variance is to have low variance for $\\begin{array}{r}{\\frac{1}{T}\\int_{0}^{T}\\left\\|u(X_{t}^{v},t)-w(t,v,X^{v},B,M_{t})\\right\\|^{2}\\mathrm{d}t\\times\\alpha(v,X^{v},B)}\\end{array}$ , and this holds when both $\\alpha(v,X^{v},B)$ and $w(t,v,X^{v},B,M_{t})$ have low variance. Next, we present strategies to lower the variance of these two objects. ", "page_idx": 6}, {"type": "text", "text": "Minimizing the variance of the importance weight $\\alpha$ We want to use a vector field $v$ such that $\\mathrm{Var}[\\alpha(v,\\Bar{X^{v}},B)]$ is as low as possible. As shown by the following lemma, which is well-known in the literature, setting $v$ to be the optimal control $u^{*}$ actually achieves variance zero when we condition on the starting point of the controlled process $X^{v}$ . The proof of this result can be found in Hartmann et al. [38], but we include it in Subsec. C.5 for completeness. ", "page_idx": 7}, {"type": "text", "text": "Lemma 1. When we set $v=u^{*}$ , the conditional variance $\\mathrm{Var}[\\alpha(v,X^{v},B)|X_{0}^{v}=x_{\\mathrm{init}}]$ is zero for any $x_{\\mathrm{init}}\\in\\mathbb{R}^{d}$ . ", "page_idx": 7}, {"type": "text", "text": "Of course, we do not have access to the optimal control $u^{*}$ , but it is still a good idea to set $v$ as the closest vector field to $\\boldsymbol{u}^{*}$ that we have access to, which is typically the currently learned control. In some instances, one may benefit from using a warm-started control parameterized as $u_{\\mathrm{WS}}(x,t)+u_{\\theta}(x,t)$ , where the warm-start $u_{\\mathrm{WS}}$ is a reasonably good control obtained via a different strategy (see App. E). ", "page_idx": 7}, {"type": "text", "text": "Minimizing the variance of the matching vector field $w$ We are interested in finding the family $M\\;=\\;(M_{t})_{t\\in[0,T]}$ that minimizes the variance of $w(t,v,X^{v},B,M_{t})$ conditioned on $t$ and $X_{t}$ . Note that this is exactly the term $\\operatorname{CondVar}(w;M)$ in the right-hand side of equation (24). Since $\\operatorname{CondVar}(w;M)$ does not depend on the specific $v$ , the optimal $M$ does not depend on $v$ either. And since the second term in the right-hand side of equation (24) does not depend on $M=(M_{t})_{t\\in[0,T]}$ , minimizing $\\operatorname{CondVar}(w;M)$ is equivalent to minimizing $\\mathcal{L}(u)$ with respect to $M$ . ", "page_idx": 7}, {"type": "text", "text": "Parameterizing the matrices $M_{t}$ vs solving for the optimal matrices In practice, we parameterize the matrices $(M_{t})_{t\\in[0,T]}$ using a function $M_{\\omega}$ with two arguments $(\\boldsymbol{t},\\boldsymbol{s})$ . To enforce that $M_{\\omega}(t,t)=$ Id, we set $M_{\\omega}(t,s)\\stackrel{{\\cdot}}{=}e^{-\\gamma(s-t)}\\mathrm{Id}+(1-e^{-\\gamma(s-t)})\\tilde{M}_{\\tilde{\\omega}}(t,s).$ , where $\\omega=(\\gamma,\\tilde{\\omega})$ , and $\\tilde{M}_{\\tilde{\\omega}}:\\mathbb{R}\\times\\mathbb{R}\\rightarrow$ $\\mathbb{R}^{d\\times d}$ is an unconstrained neural network. Alternatively, Thm. 4 in App. D shows that the optimal family $M^{*}\\;=\\;(M_{t}^{*})_{t\\in[0,T]}$ can be characterized as the solution of a linear equation in infinite dimensions (a Fredholm equation of the first kind). The discretized linear system has $d^{2}K$ equations and variables, $K$ being the number of discretization time points. However, since the optimal $M^{*}$ does not depend on $v$ (see Remark 1), this is a computation that must be done only once and that may be affordable in some settings. We did not test this approach experimentally. ", "page_idx": 7}, {"type": "text", "text": "4 Experiments ", "text_level": 1, "page_idx": 7}, {"type": "text", "text": "We consider four experimental settings that we adapt from N\u00fcsken and Richter [59]: QUADRATIC ORNSTEIN UHLENBECK (EASY), QUADRATIC ORNSTEIN UHLENBECK (HARD), LINEAR ORNSTEIN UHLENBECK and DOUBLE WELL. We describe them in detail in App. F. For all of them, we have access to the ground-truth optimal control, which means that we are able to estimate the $L^{2}$ error incurred by the learned control $u$ . In Figure 2 we plot the control $L^{2}$ error for each IDO algorithm described in Subsec. 2.2, and for the SOCM algorithm (Algorithm 2), for the QUADRATIC OU (EASY) and (HARD) settings. We also include two ablations of SOCM: $(i)$ a version of SOCM where the reparameterization matrices $M_{t}$ are set fixed to the identity $I$ , (ii) SOCM-Adjoint, where we estimate the conditional expectation in equation (23) using the adjoint method for SDEs instead of the path-wise reparameterization trick (see Subsec. C.4). Code can be found at https://github.com/facebookresearch/SOC-matching. ", "page_idx": 7}, {"type": "text", "text": "At the end of training, SOCM obtains the lowest $L^{2}$ error, improving over all existing methods by a factor of around ten. The two SOCM ablations come in second and third by a substantial difference, which underlines the importance of the path-wise reparameterization trick. The best among existing methods is the adjoint method (the relative entropy loss). In Figure 2 (bottom) we show the squared norm of the gradient of each loss with respect to the parameters $\\theta$ of the control: algorithms with small noise variance have low error values. ", "page_idx": 7}, {"type": "text", "text": "In Figure 3, we plot the control $L^{2}$ error for LINEAR ORNSTEIN UHLENBECK and DOUBLE WELL. For LINEAR OU, the error is around five times smaller for SOCM than for any existing method. For DOUBLE WELL, the SOCM algorithm achieves the third smallest error, slightly behind the variance loss and the adjoint method, but the latter shows instabilities. As we show in Figure 9 in App. F, these instabilities are inherent to the adjoint method and they do not disappear for small learning rates. Both in Figure 2 and Figure 3, we observe that learning the reparameterization matrices is critical to obtain gradient estimates with high signal-to-noise ratio. DOUBLE WELL is a particularly interesting and challenging setting because its solution is highly multimodal: $g$ has 1024 modes. Multimodality is a feature observed in realistic settings, and is hard to handle because it involves learning the control correctly in each mode. ", "page_idx": 7}, {"type": "text", "text": "", "page_idx": 8}, {"type": "text", "text": "The costs $f$ and $g$ and the base drift $b$ for QUADRATIC OU (HARD) are five times those of QUADRATIC OU (EASY). Consequently, the factor $\\alpha(v,X^{v},B)$ initially has a much larger variance for the SOCM methods, and for cross-entropy. As training progresses, $u_{\\theta_{n}}$ gets closer to $\\boldsymbol{u}^{*}$ , and consequently the variance of $\\alpha(v,X^{v},B)$ decreases, which in turn makes learning easier. This explains the initial slow decrease in the control error, followed by a fast drop that places SOCM well below existing algorithms. In App. E, we showcase a control warm-start strategy that can help and speed up convergence. ", "page_idx": 8}, {"type": "text", "text": "We also present experimental results on two-mode Gaussian mixture sampling in increasing dimension, using the Path Integral Sampler [84]. We take Gaussians with means that are 2 units apart, and identity variance. Figure 1 shows control objective estimates obtained after running the Adjoint, SOCM, and Cross-entropy algorithms for 40000 iterations, at dimensions $d=2,8,16,32,64$ , and error bars show standard errors. By Theorem 4 of [84], we know that the optimal value of the control objective is zero; Figure 1 shows the suboptimality gaps incurred by each algorithm. Cross-entropy, which uses the same importance weight as SOCM, performs worse than the other two losses for all dimensions, and its results are particularly poor for dimension 64, because the variance of $\\alpha$ is too large for learning to happen. In this case, we see that SOCM has better variance reduction than cross-entropy, despite both using importance weighted objectives for training. We observe that the values for SOCM are slightly below that of Adjoint for most dimensions, which confirms that our method is better for this range of dimensions. If we keep increasing the dimension, SOCM also fails due to higher variance of $\\alpha$ : for $n=128$ , the control objective estimates for the Adjoint, SOCM, and Cross-Entropy losses are $0.146\\pm0.001$ , $7.49\\pm0.01$ , and $12.61\\pm0.02$ , respectively. ", "page_idx": 8}, {"type": "image", "img_path": "wfU2CdgmWt/tmp/0cd816c2ec59cec1cead33355c00bd55b047424ed914a46d7d1567156b5b0a40.jpg", "img_caption": ["Figure 1: This plot shows the control objective values for different algorithms (Adjoint, SOCM, and Cross-entropy) across multiple dimensions, with error bars indicating the standard deviations. The y-axis is restricted to [0, 0.1] for better visibility of the lower range values; cross-entropy takes value $2.915\\pm0.008$ at $d=64$ . "], "img_footnote": [], "page_idx": 8}, {"type": "text", "text": "", "page_idx": 8}, {"type": "text", "text": "5 Conclusion ", "text_level": 1, "page_idx": 8}, {"type": "text", "text": "Our work introduces Stochastic Optimal Control Matching, a novel Iterative Diffusion Optimization technique for stochastic optimal control that stems from the same philosophy as the conditional score matching loss for diffusion models. That is, the control is learned via a least-squares problem by trying to fit a matching vector field. The training loss is optimized with respect to both the control function and a family of reparameterization matrices which appear in the matching vector field. Optimizing the reparameterization matrices reduces the variance of the matching vector field. Experimentally, our algorithm achieves lower error than all existing IDO techniques in four settings. ", "page_idx": 8}, {"type": "text", "text": "One of the key ideas for deriving the SOCM algorithm is the path-wise reparameterization trick, a novel technique to obtain low-variance estimates of the gradient of the conditional expectation of a functional of a random process with respect to its initial value. An interesting future direction is to use the path-wise reparameterization trick to decrease the variance of the matching vector field for diffusion models. The main roadblock when we try to apply SOCM to more challenging problems is that the variance of the factor $\\alpha(v,X^{v},B)$ explodes when $f$ and/or $g$ are large, or when the dimension $d$ is high. The large variance of $\\alpha$ is due to the mismatch between the probability measures induced by the learned control and the optimal control, and it decreases as the learned control approaches the optimal control. ", "page_idx": 8}, {"type": "text", "text": "The research presented is foundational, but it may serve as the basis of algorithms that improve the quality of generative models. ", "page_idx": 8}, {"type": "image", "img_path": "wfU2CdgmWt/tmp/5e7be9a927f2de85cd428713ae14ef5b066295097b70898770db13a4af9d715b.jpg", "img_caption": ["Figure 2: Plots of the $L^{2}$ error incurred by the learned control (left), and the norm squared of the gradient with respect to the parameters $\\theta$ of the control (right), for the QUADRATIC ORNSTEIN UHLENBECK (EASY) (top) and (HARD) (bottom) settings and for each IDO loss. Both plots show exponential moving averages. "], "img_footnote": [], "page_idx": 9}, {"type": "image", "img_path": "wfU2CdgmWt/tmp/5316cf4860bf80bfac908323b5012c1e5b535c22550e049d665a426246fb8b10.jpg", "img_caption": ["Figure 3: Plots of the $L^{2}$ error of the learned control for the LINEAR ORNSTEIN UHLENBECK and DOUBLE WELL settings. "], "img_footnote": [], "page_idx": 9}, {"type": "text", "text": "Funding disclosure Funded by respective author affiliations. ", "page_idx": 9}, {"type": "text", "text": "References ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "[1] Michael S. Albergo and Eric Vanden-Eijnden. Building normalizing flows with stochastic interpolants, 2022.   \n[2] Michael S Albergo, Nicholas M Boff,i and Eric Vanden-Eijnden. Stochastic interpolants: A unifying framework for flows and diffusions. arXiv preprint arXiv:2303.08797, 2023.   \n[3] Jonathan Baxter and Peter L Bartlett. Infinite-horizon policy-gradient estimation. Journal of Artificial Intelligence Research, 15:319\u2013350, 2001. [4] L\u2019ubom\u00edr Ban\u02c7as, Herbert Dawid, Tsiry Avisoa Randrianasolo, Johannes Storn, and Xin Wen. Numerical approximation of a system of hamilton\u2013jacobi\u2013bellman equations arising in innovation dynamics. Journal of Scientific Computing, 92, 2022. [5] Christian Beck, Sebastian Becker, Philipp Grohs, Nor Jaafari, and Arnulf Jentzen. Solving stochastic differential equations and Kolmogorov equations by means of deep learning. arXiv:1806.00421, 2018. [6] Christian Beck, Fabian Hornung, Martin Hutzenthaler, Arnulf Jentzen, and Thomas Kruse. Overcoming the curse of dimensionality in the numerical approximation of Allen-Cahn partial differential equations via truncated full-history recursive multilevel Picard approximations. arXiv:1907.06729, 2019.   \n[7] Sebastian Becker, Patrick Cheridito, and Arnulf Jentzen. Deep optimal stopping. Journal of Machine Learning Research, 20, 2019. [8] Andrea Belloni, Luigi Piroddi, and Maria Prandini. A stochastic optimal control solution to the energy management of a microgrid with storage and renewables. In 2016 American Control Conference (ACC), pages 2340\u20132345, 2016. [9] Julius Berner, Lorenz Richter, and Karen Ullrich. An optimal control perspective on diffusionbased generative modeling, 2023.   \n[10] Joris Bierkens and Hilbert J Kappen. Explicit solution of relative entropy weighted control. Systems & Control Letters, 72:36\u201343, 2014.   \n[11] J. Bonnans, Elisabeth Ottenwaelter, and Hasnaa Zidani. A fast algorithm for the two dimensional hjb equation of stochastic control. M2AN. Mathematical Modelling and Numerical Analysis. ESAIM, European Series in Applied and Industrial Mathematics, 38, 07 2004.   \n[12] Elisa Calzola, Elisabetta Carlini, Xavier Dupuis, and Francisco Silva. A semi-Lagrangian scheme for Hamilton\u2013Jacobi\u2013Bellman equations with oblique derivatives boundary conditions. Numerische Mathematik, page 153, 2022.   \n[13] E. Carlini, A. Festa, and N. Forcadel. A semi-Lagrangian scheme for Hamilton\u2013Jacobi\u2013Bellman equations on networks. SIAM J. Numer. Anal., 58(6):3165\u20133196, 2020.   \n[14] Ren\u00e9 Carmona. Lectures on BSDEs, stochastic control, and stochastic differential games with financial applications, volume 1. SIAM, 2016.   \n[15] Ren\u00e9 Carmona and Mathieu Lauri\u00e8re. Convergence analysis of machine learning algorithms for the numerical solution of mean field control and games i: The ergodic case. SIAM Journal on Numerical Analysis, 59(3):1455\u20131485, 2021.   \n[16] Ren\u00e9 Carmona and Mathieu Lauri\u00e8re. Convergence analysis of machine learning algorithms for the numerical solution of mean field control and games: Ii\u2014the finite horizon case. The Annals of Applied Probability, 32(6):4065\u20134105, 2022.   \n[17] Ren\u00e9 Carmona, Fran\u00e7ois Delarue, et al. Probabilistic Theory of Mean Field Games with Applications I-II. Springer, 2018.   \n[18] Quentin Chan-Wai-Nam, Joseph Mikael, and Xavier Warin. Machine learning for semilinear PDEs. Journal of Scientific Computing, 79(3):1667\u20131712, 2019.   \n[19] Pratik Chaudhari, Adam Oberman, Stanley Osher, Stefano Soatto, and Guillaume Carlier. Deep relaxation: partial differential equations for optimizing deep neural networks. Research in the Mathematical Sciences, 5(3):30, 2018.   \n[20] Ricky T. Q. Chen, Yulia Rubanova, Jesse Bettencourt, and David K Duvenaud. Neural ordinary differential equations. In Advances in Neural Information Processing Systems, volume 31. Curran Associates, Inc., 2018.   \n[21] Kristian Debrabant and Espen R. Jakobsen. Semi-lagrangian schemes for linear and fully non-linear diffusion equations. Mathematics of Computation, 82(283):1433\u20131462, 2013.   \n[22] W. E, Jiequn Han, and Arnulf Jentzen. Deep learning-based numerical methods for highdimensional parabolic partial differential equations and backward stochastic differential equations. Communications in Mathematics and Statistics, 5(4):349\u2013380, 2017.   \n[23] Weinan E, Jiequn Han, and Arnulf Jentzen. Algorithms for solving high dimensional pdes: from nonlinear monte carlo to machine learning. Nonlinearity, 35(1):278, 2021.   \n[24] Jin Feng and Thomas G Kurtz. Large deviations for stochastic processes. Number 131. American Mathematical Soc., 2006.   \n[25] Wendell H Fleming and Jerome L Stein. Stochastic optimal control, international finance and debt. Journal of Banking & Finance, 28(5):979\u2013996, 2004.   \n[26] Paul Glasserman and David D. Yao. Some guidelines and guarantees for common random numbers. Manage. Sci., 38(6):884\u2013908, jun 1992.   \n[27] Peter W. Glynn. Stochastic approximation for monte carlo optimization. In Proceedings of the 18th Conference on Winter Simulation, page 356\u2013365. Association for Computing Machinery, 1986.   \n[28] Emmanuel Gobet. Monte-Carlo methods and stochastic processes: from linear to non-linear. CRC Press, 2016.   \n[29] Emmanuel Gobet and R\u00e9mi Munos. Sensitivity analysis using It\u00f4\u2013Malliavin calculus and martingales, and application to stochastic optimal control. SIAM Journal on control and optimization, 43(5):1676\u20131713, 2005.   \n[30] Emmanuel Gobet, Jean-Philippe Lemor, Xavier Warin, et al. A regression-based Monte Carlo method to solve backward stochastic differential equations. The Annals of Applied Probability, 15(3):2172\u20132202, 2005.   \n[31] Vicen\u00e7 G\u00f3mez, Hilbert J Kappen, Jan Peters, and Gerhard Neumann. Policy search for path integral control. In Joint European Conference on Machine Learning and Knowledge Discovery in Databases, pages 482\u2013497. Springer, 2014.   \n[32] Alex Gorodetsky, Sertac Karaman, and Youssef Marzouk. High-dimensional stochastic optimal control using continuous tensor decompositions. International Journal of Robotics Research, 37(2-3), 3 2018.   \n[33] Constantin Greif. Numerical methods for hamilton-jacobi-bellman equations. 2017.   \n[34] Jiequn Han and Ruimeng Hu. Deep fictitious play for finding markovian nash equilibrium in multi-agent games. In Mathematical and scientific machine learning, pages 221\u2013245. PMLR, 2020.   \n[35] Jiequn Han, Arnulf Jentzen, and W. E. Solving high-dimensional partial differential equations using deep learning. Proceedings of the National Academy of Sciences, 115(34):8505\u20138510, 2018.   \n[36] Carsten Hartmann and Christof Sch\u00fctte. Efficient rare event simulation by optimal nonequilibrium forcing. Journal of Statistical Mechanics: Theory and Experiment, 2012(11):P11004, 2012.   \n[37] Carsten Hartmann, Ralf Banisch, Marco Sarich, Tomasz Badowski, and Christof Sch\u00fctte. Characterization of rare events in molecular dynamics. Entropy, 16(1):350\u2013376, 2014.   \n[38] Carsten Hartmann, Lorenz Richter, Christof Sch\u00fctte, and Wei Zhang. Variational characterization of free energy: Theory and algorithms. Entropy, 19(11), 2017.   \n[39] Carsten Hartmann, Omar Kebiri, Lara Neureither, and Lorenz Richter. Variational approach to rare event simulation using least-squares regression. Chaos: An Interdisciplinary Journal of Nonlinear Science, 29(6):063107, 2019.   \n[40] Jonathan Ho, Ajay Jain, and Pieter Abbeel. Denoising diffusion probabilistic models. In Advances in Neural Information Processing Systems, volume 33. Curran Associates, Inc., 2020.   \n[41] Lars Holdijk, Yuanqi Du, Ferry Hooft, Priyank Jaini, Bernd Ensing, and Max Welling. Stochastic optimal control for collective variable free sampling of molecular transition paths, 2023.   \n[42] James E. Hutton and Paul I. Nelson. Interchanging the order of differentiation and stochastic integration. Stochastic Processes and their Applications, 18(2):371\u2013377, 1984.   \n[43] Martin Hutzenthaler and Thomas Kruse. Multilevel picard approximations of high-dimensional semilinear parabolic differential equations with gradient-dependent nonlinearities. SIAM Journal on Numerical Analysis, 58(2):929\u2013961, 2020.   \n[44] Martin Hutzenthaler, Arnulf Jentzen, Thomas Kruse, et al. Multilevel picard iterations for solving smooth semilinear parabolic heat equations. arXiv preprint arXiv:1607.03295, 2016.   \n[45] Martin Hutzenthaler, Arnulf Jentzen, Thomas Kruse, Tuan Anh Nguyen, and Philippe von Wurstemberger. Overcoming the curse of dimensionality in the numerical approximation of semilinear parabolic partial differential equations. arXiv:1807.01212, 2018.   \n[46] Martin Hutzenthaler, Arnulf Jentzen, and Thomas Kruse. Overcoming the curse of dimensionality in the numerical approximation of parabolic partial differential equations with gradientdependent nonlinearities. arXiv:1912.02571, 2019.   \n[47] Max Jensen and Iain Smears. On the convergence of finite element methods for hamilton\u2013 jacobi\u2013bellman equations. SIAM Journal on Numerical Analysis, 51(1):137\u2013162, 2013.   \n[48] Hilbert J Kappen, Vicen\u00e7 G\u00f3mez, and Manfred Opper. Optimal control as a graphical model inference problem. Machine learning, 87(2):159\u2013182, 2012.   \n[49] Hilbert Johan Kappen and Hans Christian Ruiz. Adaptive importance sampling for control and inference. Journal of Statistical Physics, 162(5):1244\u20131266, 2016.   \n[50] I. Karatzas and S. Shreve. Brownian Motion and Stochastic Calculus. Graduate Texts in Mathematics (113) (Book 113). Springer New York, 1991.   \n[51] Patrick Kidger, James Foster, Xuechen Li, Harald Oberhauser, and Terry Lyons. Neural sdes as infinite-dimensional gans. In International Conference on Machine Learning, 2021.   \n[52] Harold Kushner and Paul G Dupuis. Numerical methods for stochastic control problems in continuous time, volume 24. Springer Science & Business Media, 2013.   \n[53] Pierre L\u2019Ecuyer and Ga\u00e9tan Perron. On the convergence rates of ipa and fdc derivative estimators. Operations Research, 42(4):643\u2013656, 1994.   \n[54] Xuechen Li, Ting-Kam Leonard Wong, Ricky TQ Chen, and David Duvenaud. Scalable gradients for stochastic differential equations. In International Conference on Artificial Intelligence and Statistics, pages 3870\u20133882. PMLR, 2020.   \n[55] Yaron Lipman, Ricky T. Q. Chen, Heli Ben-Hamu, Maximilian Nickel, and Matt Le. Flow matching for generative modeling, 2022.   \n[56] Guan-Horng Liu, Yaron Lipman, Maximilian Nickel, Brian Karrer, Evangelos A. Theodorou, and Ricky T. Q. Chen. Generalized schr\u00f6dinger bridge matching, 2023.   \n[57] Jingtang Ma and Jianjun Ma. Finite difference methods for the hamilton-jacobi-bellman equations arising in regime switching utility maximization. J. Sci. Comput., 85(3):55, 2020.   \n[58] Sanjoy K Mitter. Filtering and stochastic control: A historical perspective. IEEE Control Systems Magazine, 16(3):67\u201376, 1996.   \n[59] Nikolas N\u00fcsken and Lorenz Richter. Solving high-dimensional Hamilton\u2013Jacobi\u2013Bellman pdes using neural networks: perspectives from the theory of controlled diffusions and measures on path space. Partial differential equations and applications, 2:1\u201348, 2021.   \n[60] Bernt Oksendal. Stochastic differential equations: an introduction with applications. Springer Science & Business Media, 2013.   \n[61] Derek Onken, Levon Nurbekyan, Xingjian Li, Samy Wu Fung, Stanley Osher, and Lars Ruthotto. A neural network approach for high-dimensional optimal control applied to multiagent path finding. IEEE Transactions on Control Systems Technology, 31(1):235\u2013251, jan 2023.   \n[62] Grigorios A Pavliotis. Stochastic processes and applications: diffusion processes, the FokkerPlanck and Langevin equations, volume 60. Springer, 2014.   \n[63] Huy\u00ean Pham. Continuous-time stochastic control and optimization with financial applications, volume 61. Springer Science & Business Media, 2009.   \n[64] L.S. Pontryagin. The Mathematical Theory of Optimal Processes. Interscience Publishers, 1962.   \n[65] Aram-Alexandre Pooladian, Heli Ben-Hamu, Carles Domingo-Enrich, Brandon Amos, Yaron Lipman, and Ricky T. Q. Chen. Multisample flow matching with optimal transport couplings. In International Conference on Machine Learning, 2023.   \n[66] Warren B. Powell and Stephan Meisel. Tutorial on stochastic optimization in energy\u2014part i: Modeling and policies. IEEE Transactions on Power Systems, 31(2):1459\u20131467, 2016.   \n[67] Konrad Rawlik, Marc Toussaint, and Sethu Vijayakumar. On stochastic optimal control and reinforcement learning by approximate inference. In Twenty-Third International Joint Conference on Artificial Intelligence, 2013.   \n[68] Sebastian Reich. Data assimilation: The Schr\u00f6dinger perspective. Acta Numerica, 28:635\u2013711, 2019.   \n[69] Martin I. Reiman and Alan Weiss. Sensitivity analysis for simulations via likelihood ratios. Oper. Res., 37:830\u2013844, 1989.   \n[70] Danilo Rezende and Shakir Mohamed. Variational inference with normalizing flows. In Proceedings of the 32nd International Conference on Machine Learning, 2015.   \n[71] Lorenz Richter and Julius Berner. Improved sampling via learned diffusions. In The Twelfth International Conference on Learning Representations, 2024.   \n[72] Geoffrey Roeder, Yuhuai Wu, and David K Duvenaud. Sticking the landing: Simple, lowervariance gradient estimators for variational inference. In Advances in Neural Information Processing Systems, volume 30. Curran Associates, Inc., 2017.   \n[73] Olaf Ronneberger, Philipp Fischer, and Thomas Brox. U-net: Convolutional networks for biomedical image segmentation. In Medical Image Computing and Computer-Assisted Intervention\u2013MICCAI 2015: 18th International Conference, Munich, Germany, October 5-9, 2015, Proceedings, Part III 18, pages 234\u2013241. Springer, 2015.   \n[74] Reuven Y Rubinstein and Dirk P Kroese. The cross-entropy method: a unified approach to combinatorial optimization, Monte-Carlo simulation and machine learning. Springer Science & Business Media, 2013.   \n[75] Yang Song and Stefano Ermon. Generative modeling by estimating gradients of the data distribution. arXiv preprint arXiv:1907.05600, 2019.   \n[76] Yang Song, Jascha Sohl-Dickstein, Diederik P. Kingma, Abhishek Kumar, Stefano Ermon, and Ben Poole. Score-based generative modeling through stochastic differential equations. In International Conference on Learning Representations (ICLR 2021), 2021.   \n[77] Evangelos Theodorou, Freek Stulp, Jonas Buchli, and Stefan Schaal. An iterative path integral stochastic optimal control approach for learning robotic tasks. IFAC Proceedings Volumes, 44 (1):11594\u201311601, 2011. 18th IFAC World Congress.   \n[78] Ramon Van Handel. Stochastic calculus, filtering, and stochastic control. Course notes, URL http://www. prince- ton. edu/rvan/acm217/ACM217, 2007.   \n[79] Francisco Vargas, Will Sussman Grathwohl, and Arnaud Doucet. Denoising diffusion samplers. In The Eleventh International Conference on Learning Representations, 2023.   \n[80] C. Villani. Topics in Optimal Transportation. Graduate studies in mathematics. American Mathematical Society, 2003.   \n[81] C. Villani. Optimal Transport: Old and New. Grundlehren der mathematischen Wissenschaften. Springer Berlin Heidelberg, 2008.   \n[82] Jichuan Yang and Harold J. Kushner. A monte carlo method for sensitivity analysis and parametric optimization of nonlinear stochastic systems. SIAM Journal on Control and Optimization, 29(5):1216\u20131249, 1991.   \n[83] Jianfeng Zhang et al. A numerical scheme for BSDEs. The annals of applied probability, 14(1): 459\u2013488, 2004.   \n[84] Qinsheng Zhang and Yongxin Chen. Path integral sampler: A stochastic control approach for sampling. In International Conference on Learning Representations, 2022.   \n[85] Wei Zhang, Han Wang, Carsten Hartmann, Marcus Weber, and Christof Sch\u00fctte. Applications of the cross-entropy method to importance sampling and optimal control of diffusions. SIAM Journal on Scientific Computing, 36(6):A2654\u2013A2672, 2014.   \n[86] Mo Zhou, Jiequn Han, and Jianfeng Lu. Actor-critic method for high dimensional static Hamilton\u2013Jacobi\u2013Bellman partial differential equations based on neural networks. SIAM Journal on Scientific Computing, 43(6):A4043\u2013A4066, 2021. ", "page_idx": 9}, {"type": "text", "text": "", "page_idx": 10}, {"type": "text", "text": "", "page_idx": 11}, {"type": "text", "text": "", "page_idx": 12}, {"type": "text", "text": "", "page_idx": 13}, {"type": "text", "text": "", "page_idx": 14}, {"type": "text", "text": "Contents ", "text_level": 1, "page_idx": 15}, {"type": "text", "text": "1 Introduction ", "page_idx": 15}, {"type": "text", "text": "2 Framework 2   \n2.1 Setup and Preliminaries . . 2   \n2.2 Existing approaches and related work 4 ", "page_idx": 15}, {"type": "text", "text": "3 Stochastic Optimal Control Matching 6 ", "page_idx": 15}, {"type": "text", "text": "4 Experiments 8 ", "page_idx": 15}, {"type": "text", "text": "5 Conclusion 9 ", "page_idx": 15}, {"type": "text", "text": "A Technical assumptions 16 ", "page_idx": 15}, {"type": "text", "text": "B Proofs of Sec. 2 16 ", "page_idx": 15}, {"type": "text", "text": "C Proofs of Sec. 3 21   \nC.1 Proof of Thm. 1 and Prop. 2 21   \nC.2 Proof of the path-wise reparameterization trick (Prop. 1) 24   \nC.3 Informal derivation of the path-wise reparameterization trick 26   \nC.4 SOCM-Adjoint: replacing the path-wise reparameterization trick with the adjoint   \nmethod . 28   \nC.5 Proof of Lemma 1 30 ", "page_idx": 15}, {"type": "text", "text": "D Optimal reparameterization matrices 30 ", "page_idx": 15}, {"type": "text", "text": "E Control warm-starting 32 ", "page_idx": 15}, {"type": "text", "text": "F Experimental details and additional plots 34   \nF.1 Experimental details 34   \nF.2 Model architectures . . 35   \nF.3 Additional tables and plots . . . 35 ", "page_idx": 15}, {"type": "text", "text": "A Technical assumptions ", "text_level": 1, "page_idx": 15}, {"type": "text", "text": "Throughout our work, we make the same assumptions as [59], which are needed for all the objects considered to be well-defined. Namely, we assume that: ", "page_idx": 15}, {"type": "text", "text": "(i) The set $\\boldsymbol{\\mathcal{U}}$ of admissible controls is given by ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\mathcal{U}=\\{u\\in C^{1}(\\mathbb{R}^{d}\\times[0,T];\\mathbb{R}^{d})\\,|\\,\\exists C>0,\\,\\forall(x,s)\\in\\mathbb{R}^{d}\\times[0,T],\\,b(x,s)\\le C(1+|x|)\\}.\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "(ii) The coefficients $b$ and $\\sigma$ are continuously differentiable, $\\sigma$ has bounded first-order spatial derivatives, and $(\\sigma\\sigma^{\\top})(x,s)$ is positive definite for all $(x,s)\\in\\mathbb{R}^{d}\\times[0,T]$ . Furthermore, there exist constants $C,c_{1},c_{2}>0$ such that $\\begin{array}{r l}{\\|b(x,s)\\|\\le C(1+\\|x\\|),}&{\\quad\\mathrm{(linear~growth)}}\\\\ {c_{1}\\|\\xi\\|^{2}\\le\\xi^{\\top}(\\sigma\\sigma^{\\top})(x,s)\\xi\\le c_{2}\\|\\xi\\|^{2},}&{\\quad\\mathrm{(ellipticity)}}\\end{array}$ for all $(x,s)\\in\\mathbb{R}^{d}\\times[0,T]$ and $\\xi\\in\\mathbb{R}^{d}$ . ", "page_idx": 15}, {"type": "text", "text": "B Proofs of Sec. 2 ", "text_level": 1, "page_idx": 15}, {"type": "text", "text": "Proof of (5) By It\u00f4\u2019s lemma, we have that ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{V(X_{T}^{u},T)-V(X_{t}^{u},t)=\\int_{t}^{T}\\left(\\partial_{s}V(X_{s}^{u},s)+\\langle b(X_{s}^{u},s)+\\sigma(X_{s}^{u},s)u(X_{s}^{u},s),\\nabla V(X_{s}^{u},s)\\rangle\\right.}\\\\ &{\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\left.+\\,\\frac{\\lambda}{2}\\sum_{i,j=1}^{d}(\\sigma\\sigma^{\\top})_{i j}(X_{s}^{u},s)\\partial_{x_{i}}\\partial_{x_{j}}V(X_{s}^{u},s)\\right)\\mathrm{d}s+S_{t}^{u},}\\end{array}\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "where $\\begin{array}{r}{S_{t}^{u}=\\sqrt{\\lambda}\\int_{t}^{T}\\nabla V(X_{s}^{u},s)^{\\top}\\sigma(X_{s}^{u},s)\\,\\mathrm{d}B_{s}}\\end{array}$ . Note that by (4), ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\partial_{s}V(X_{s}^{u},s)+\\langle b(X_{s}^{u},s)+\\sigma(X_{s}^{u},s)u(X_{s}^{u},s),\\nabla V(X_{s}^{u},s)\\rangle}\\\\ &{\\qquad+\\frac{\\lambda}{2}\\sum_{i,j=1}^{d}(\\sigma\\sigma^{\\top})_{i j}(X_{s}^{u},s)\\partial_{x_{i}}\\partial_{x_{j}}V(X_{s}^{u},s)}\\\\ &{=\\frac{1}{2}\\|(\\sigma^{\\top}\\nabla V)(X_{s}^{u},s)\\|^{2}-f(X_{s}^{u},s)+\\langle\\sigma(X_{s}^{u},s)u(X_{s}^{u},s),\\nabla V(X_{s}^{u},s)\\rangle}\\\\ &{=\\frac{1}{2}\\|(\\sigma^{\\top}\\nabla V)(X_{s}^{u},s)+u(X_{s}^{u},s)\\|^{2}-\\frac{1}{2}\\|u(X_{s}^{u},s)\\|^{2}-f(X_{s}^{u},s),}\\end{array}\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "and this implies that ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\iota(X_{T}^{u})-V(X_{t}^{u},t)=\\int_{t}^{T}\\left(\\frac12\\|(\\sigma^{\\top}\\nabla V)(X_{s}^{u},s)+u(X_{s}^{u},s)\\|^{2}-\\frac12\\|u(X_{s}^{u},s)\\|^{2}-f(X_{s}^{u},s)\\right)\\mathrm{d}s+S_{t}^{u}}\\end{array}\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "Since $\\mathbb{E}[S_{t}^{u}\\,|\\,X_{t}^{u}=x]=0$ , rearranging (26) and taking the conditional expectation with respect to $X_{t}^{u}$ yields the final result. ", "page_idx": 16}, {"type": "text", "text": "Proof of (6)-(7) By It\u00f4\u2019s lemma, we have that ", "text_level": 1, "page_idx": 16}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\langle V(X_{s},s)=\\big(\\partial_{s}V(X_{s},s)+\\langle b(X_{s},s),\\nabla V(X_{s},s)\\rangle}\\\\ &{\\qquad\\qquad+\\frac{\\lambda}{2}\\sum_{i,j=1}^{d}(\\sigma\\sigma^{\\top})_{i j}(X_{s},s)\\partial_{x_{i}}\\partial_{x_{j}}V(X_{s},s)\\big)\\,\\mathrm{d}s+\\sqrt{\\lambda}\\nabla V(X_{s}^{u},s)^{\\top}\\sigma(X_{s}^{u},s)\\,\\mathrm{d}B_{s},}\\end{array}\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "Note that by (4), ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\partial_{s}V(X_{s},s)+\\langle b(X_{s},s),\\nabla V(X_{s},s)\\rangle+\\frac{\\lambda}{2}\\sum_{i,j=1}^{d}(\\sigma\\sigma^{\\top})_{i j}(X_{s},s)\\partial_{x_{i}}\\partial_{x_{j}}V(X_{s},s)}\\\\ &{=\\frac{1}{2}\\|(\\sigma^{\\top}\\nabla V)(X_{s},s)\\|^{2}-f(X_{s},s).}\\end{array}\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "Plugging this into (27) concludes the proof. ", "page_idx": 16}, {"type": "text", "text": "Proof of (8) Since $Y_{s}=V(X_{s},s)$ and $Z_{s}=\\sigma^{\\top}(s)\\nabla V(X_{s},s)=-u^{*}(X_{s},s)$ satisfy (7), we have that ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\begin{array}{r}{g(X_{T})=Y_{T}=Y_{t}-\\int_{t}^{T}(f(X_{s},s)-\\frac12\\|u^{*}(X_{s},s)\\|^{2})\\,\\mathrm{d}s-\\sqrt{\\lambda}\\int_{t}^{T}\\langle u^{*}(X_{s},s),\\mathrm{d}B_{s}\\rangle.}\\end{array}\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "Hence, recalling the definition of the work functional in (10), we have that ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathcal{W}(X,t)=Y_{t}+\\frac{1}{2}\\int_{t}^{T}\\|u^{*}(X_{s},s)\\|^{2}\\,\\mathrm{d}s-\\sqrt{\\lambda}\\int_{t}^{T}\\langle u^{*}(X_{s},s),\\mathrm{d}B_{s}\\rangle.}\\end{array}\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "By Novikov\u2019s theorem (Thm. 2), we have that ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{E}[\\exp(-\\lambda^{-1}\\mathcal{W}(X,t))|X_{t}]}\\\\ &{\\ =e^{-\\lambda^{-1}Y_{t}}\\mathbb{E}\\bigl[\\exp\\left(\\lambda^{-1/2}\\int_{t}^{T}\\langle u^{*}(X_{s},s),\\mathrm{d}B_{s}\\rangle-\\frac{\\lambda^{-1}}{2}\\int_{t}^{T}\\|u^{*}(X_{s},s)\\|^{2}\\,\\mathrm{d}s\\right)\\big|X_{t}\\bigr]=e^{-\\lambda^{-1}Y_{t}},}\\end{array}\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "which concludes the proof of (8). ", "page_idx": 16}, {"type": "text", "text": "Theorem 2 (Novikov\u2019s theorem). Let $\\theta_{s}$ be a locally- $\\mathcal{H}_{2}$ process which is adapted to the natural filtration of the Brownian motion $(B_{t})_{t\\geq0}$ . Define ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\begin{array}{r}{Z(t)=\\exp\\big(\\int_{0}^{t}\\theta_{s}\\,\\mathrm{d}B_{s}-\\frac{1}{2}\\int_{0}^{t}\\|\\theta_{s}\\|^{2}\\,\\mathrm{d}s\\big).}\\end{array}\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "If for each $t\\geq0$ , ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathbb{E}\\big[\\exp\\big(\\int_{0}^{t}\\|\\theta_{s}\\|^{2}\\,\\mathrm{d}s\\big)\\big]<+\\infty,}\\end{array}\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "then for each $t\\geq0$ , ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\mathbb{E}[Z(t)]=1.\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "Moreover, the process $Z(t)$ is a positive martingale, i.e. $i f(\\mathcal{F}_{t})_{t\\geq0}$ is the filtration associated to the Brownian motion $(B_{t})_{t\\geq0}$ , then for $t\\geq s$ , $\\mathbb{E}[Z_{t}|\\mathcal{F}_{s}]=Z_{s}$ . ", "page_idx": 16}, {"type": "text", "text": "Theorem 3 (Girsanov theorem). Let $W=(W_{t})_{t\\in[0,T]}$ be a standard Wiener process, and let $\\mathbb{P}$ be its induced probability measure over $C([0,T];\\mathbb{R}^{d})$ , known as the Wiener measure. Let $Z(t)$ be as defined in (29) and suppose that the assumptions of Theorem 2 hold. Let $(\\Omega,{\\mathcal{F}})$ be the $\\sigma$ -algebra associated to $B_{T}$ . For any $F\\in{\\mathcal{F}}$ , define the measure ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\mathbb{Q}(F)=\\mathbb{E}_{\\mathbb{P}}[Z(T)\\mathbf{1}_{F}]\\;.\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "$\\mathbb{Q}$ is a probability measure because of (30). Under the probability measure $\\mathbb{Q}$ , the stochastic process $\\{\\tilde{W}(t)\\}_{0\\leq t\\leq T}$ defined as ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\tilde{W}(t)=W(t)-\\int_{0}^{t}\\theta_{s}\\,\\mathrm{d}s}\\end{array}\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "is a standard Wiener process. That is, for any $n\\geq0$ and any $0=t_{0}<t_{1}<\\cdot\\cdot<t_{n},$ , the increments $\\{\\tilde{W}(t_{i+1})-\\tilde{W}(t_{i})\\}_{i=0}^{\\bar{n}-1}$ are independent and $\\mathbb{Q}$ -Gaussian distributed with mean zero and covariance $(t_{i+1}-t_{i})\\mathrm{I},$ , which means that for any $\\alpha\\in\\mathbb{R}^{d}$ , the moment generating function of $\\tilde{W}(t_{i+1})-\\tilde{W}(t_{i})$ with respect to $\\mathbb{Q}$ is as follows: ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{{\\mathbb E}_{\\mathbb Q}[\\exp(\\langle\\alpha,\\tilde{W}(t_{i+1})-\\tilde{W}(t_{i})\\rangle)]}\\\\ &{:={\\mathbb E}_{\\mathbb P}\\left[\\exp\\left(\\left\\langle\\alpha,W(t_{i+1})-\\int_{0}^{t_{i+1}}\\theta_{s}\\,{\\mathrm d}s-W(t_{i})+\\int_{0}^{t_{i}}\\theta_{s}\\,{\\mathrm d}s\\right\\rangle\\right)Z(T)\\right]=\\exp\\left(\\frac{(t_{i+1}-t_{i})\\|\\alpha\\|^{2}}{2}\\right).}\\end{array}\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "Corollary 1 (Girsanov theorem for SDEs). If the two SDEs ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathrm{d}X_{t}=b_{1}(X_{t},t)\\,\\mathrm{d}t+\\sigma(X_{t},t)\\,\\mathrm{d}B_{t},\\qquad X_{0}=x_{\\mathrm{init}}}\\\\ &{\\,\\,d Y_{t}=(b_{1}(Y_{t},t)+b_{2}(Y_{t},t))\\,\\mathrm{d}t+\\sigma(Y_{t},t)\\,\\mathrm{d}B_{t},\\qquad Y_{0}=x_{\\mathrm{init}}}\\end{array}\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "admit unique strong solutions on $[0,T]$ , then for any bounded continuous functional $\\Phi$ on $C([0,T])$ , we have that ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\begin{array}{r l r}&{}&{\\mathbb{E}[\\Phi(X)]=\\mathbb{E}\\big[\\Phi(Y)\\exp\\big(-\\int_{0}^{T}\\sigma(Y_{t},t)^{-1}b_{2}(Y_{t},t)\\,\\mathrm{d}B_{t}-\\frac{1}{2}\\int_{0}^{T}\\|\\sigma(Y_{t},t)^{-1}b_{2}(Y_{t},t)\\|^{2}\\,\\mathrm{d}t\\big)\\big]}\\\\ &{}&{\\quad=\\mathbb{E}\\big[\\Phi(Y)\\exp\\big(-\\int_{0}^{T}\\sigma(Y_{t},t)^{-1}b_{2}(Y_{t},t)\\,d\\tilde{B}_{t}+\\frac{1}{2}\\int_{0}^{T}\\|\\sigma(Y_{t},t)^{-1}b_{2}(Y_{t},t)\\|^{2}\\,\\mathrm{d}t\\big)\\big],}\\end{array}\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "where $\\begin{array}{r}{\\tilde{B}_{t}=B_{t}+\\int_{0}^{t}\\sigma(Y_{s},s)^{-1}b_{2}(Y_{s},s)}\\end{array}$ ds. More generally, $b_{1}$ and $b_{2}$ can be random processes that are adapted to filtration of $B$ . ", "page_idx": 17}, {"type": "text", "text": "Lemma 2. For an arbitrary $v\\in\\mathcal{U}$ , let $\\mathbb{P}^{v}$ and $\\mathbb{P}$ be respectively the laws of the SDEs ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathrm{d}X_{t}^{v}=(b(X_{t}^{v},t)+\\sigma(t)v(X_{t}^{v},t))\\,\\mathrm{d}t+\\sqrt{\\lambda}\\sigma(t)\\mathrm{d}B_{t},\\qquad X_{0}^{v}\\sim p_{0},}\\\\ &{\\mathrm{d}X_{t}=b(X_{t},t)\\,\\mathrm{d}t+\\sqrt{\\lambda}\\sigma(t)\\mathrm{d}B_{t},\\qquad X_{0}\\sim p_{0}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "We have that ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\frac{d\\mathbb{P}}{d\\mathbb{P}^{v}}(X^{v})=\\exp\\big(-\\lambda^{-1/2}\\int_{0}^{T}\\langle v(X_{t}^{v},t),\\mathrm{d}B_{t}^{v}\\rangle+\\frac{\\lambda^{-1}}{2}\\int_{0}^{T}\\|v(X_{t}^{v},t)\\|^{2}\\,\\mathrm{d}t\\big)}\\\\ &{\\qquad\\qquad=\\exp\\big(-\\lambda^{-1/2}\\int_{0}^{T}\\langle v(X_{t}^{v},t),\\mathrm{d}B_{t}\\rangle-\\frac{\\lambda^{-1}}{2}\\int_{0}^{T}\\|v(X_{t}^{v},t)\\|^{2}\\,\\mathrm{d}t\\big),}\\\\ &{\\frac{d\\mathbb{P}^{v}}{d\\mathbb{P}}(X)=\\exp\\big(\\lambda^{-1/2}\\int_{0}^{T}\\langle v(X_{t},t),\\mathrm{d}B_{t}\\rangle-\\frac{\\lambda^{-1}}{2}\\int_{0}^{T}\\|v(X_{t},t)\\|^{2}\\,\\mathrm{d}t\\big).}\\end{array}\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "where $\\begin{array}{r}{B_{t}^{v}:=B_{t}+\\lambda^{-1/2}\\int_{0}^{t}v(X_{s}^{v},s)}\\end{array}$ ds. For the optimal control $\\boldsymbol{u}^{*}$ , we have that ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\frac{d\\mathbb{P}}{d\\mathbb{P}^{u^{*}}}(X^{u^{*}})=\\exp\\big(\\lambda^{-1}\\big(-V(X_{0}^{u^{*}},0)+\\mathcal{W}(X^{u^{*}},0)\\big)\\big),}\\\\ &{\\quad\\frac{d\\mathbb{P}^{u^{*}}}{d\\mathbb{P}}(X)=\\exp\\big(\\lambda^{-1}\\big(V(X_{0},0)-\\mathcal{W}(X,0)\\big)\\big),}\\end{array}\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "where the functional $\\mathcal{W}$ is defined in (10). ", "page_idx": 17}, {"type": "text", "text": "Proof. The proof of (31)-(32) follows directly from Cor. 1. To prove (34), we use that by (28), ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathcal{W}(X,0)=V(X_{0},0)+\\frac{1}{2}\\int_{0}^{T}\\|u^{*}(X_{s},s)\\|^{2}\\,\\mathrm{d}s-\\sqrt{\\lambda}\\int_{0}^{T}\\langle u^{*}(X_{s},s),\\mathrm{d}B_{s}\\rangle,}\\end{array}\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "which implies that ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\frac{d\\mathbb{P}^{u^{*}}}{d\\mathbb{P}}(X)=\\exp\\left(\\lambda^{-1/2}\\int_{0}^{T}\\langle u^{*}(X_{t},t),\\mathrm{d}B_{t}\\rangle-\\frac{\\lambda^{-1}}{2}\\int_{0}^{T}\\|u^{*}(X_{t},t)\\|^{2}\\,\\mathrm{d}t\\right)}\\\\ &{\\qquad\\qquad=\\exp\\left(\\lambda^{-1}\\big(V(X_{0},0)-\\mathcal{W}(X,0)\\big)\\right).}\\end{array}\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "To prove (33), we use that since $\\mathrm{d}X_{t}^{u^{*}}=b(X_{t}^{u^{*}},t)\\,\\mathrm{d}t+\\sqrt{\\lambda}\\sigma(t)\\mathrm{d}B_{t}^{u^{*}}$ , equation (35) holds if we replace $X$ and $B$ by $X^{u^{*}}$ and $B^{u^{*}}$ , which reads ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathcal{W}(X^{u^{*}},0)=V(X_{0}^{u^{*}},0)+\\frac{1}{2}\\int_{t}^{T}\\|u^{*}(X_{s}^{u^{*}},s)\\|^{2}\\,\\mathrm{d}s-\\sqrt{\\lambda}\\int_{t}^{T}\\langle u^{*}(X_{s}^{u^{*}},s),\\mathrm{d}B_{s}^{v}\\rangle.}\\end{array}\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "Hence, ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\frac{d\\mathbb{P}}{d\\mathbb{P}^{u^{*}}}(X^{u^{*}})=\\exp\\big(-\\lambda^{-1/2}\\int_{0}^{T}\\langle u^{*}(X_{t}^{u^{*}},t),\\mathrm{d}B_{t}^{u^{*}}\\rangle+\\frac{\\lambda^{-1}}{2}\\int_{0}^{T}\\|u^{*}(X_{t}^{u^{*}},t)\\|^{2}\\,\\mathrm{d}t\\big)}\\\\ &{\\qquad\\qquad\\qquad=\\exp\\big(\\lambda^{-1}\\big(-V(X_{0}^{u^{*}},0)+\\mathcal{W}(X^{u^{*}},0)\\big)\\big).}\\end{array}\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "Lemma 3. The following expression holds: ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathbb{E}_{\\mathbb{P}^{u}}\\left[\\log\\frac{d\\mathbb{P}^{u}}{d\\mathbb{P}^{u^{*}}}\\right]=\\lambda^{-1}\\mathbb{E}\\!\\left[\\int_{0}^{T}\\left(\\frac{1}{2}\\|u(X_{t}^{u},t)\\|^{2}+f(X_{t}^{u},t)\\right)\\mathrm{d}t+g(X_{T}^{u})-V(X_{0}^{u},0)\\right]\\!,}\\end{array}\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "Proof. To prove (36), we write ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\log\\frac{d\\mathbb{P}^{u^{*}}}{d\\mathbb{P}^{u}}(X^{u})=\\log\\left(\\frac{d\\mathbb{P}^{u^{*}}}{d\\mathbb{P}}(X^{u})\\frac{d\\mathbb{P}}{d\\mathbb{P}^{u}}(X^{u})\\right)=\\log\\frac{d\\mathbb{P}^{u^{*}}}{d\\mathbb{P}}(X^{u})+\\log\\frac{d\\mathbb{P}}{d\\mathbb{P}^{u}}(X^{u})}\\\\ &{\\qquad\\qquad\\qquad=\\lambda^{-1}\\bigl(V(X_{0}^{u},0)-\\int_{0}^{T}f(X_{t}^{u},t)\\,\\mathrm{d}t-g(X_{T}^{u})\\bigr)}\\\\ &{\\qquad\\qquad\\qquad\\qquad-\\lambda^{-1/2}\\int_{0}^{T}\\langle u(X_{t}^{u},t),\\mathrm{d}B_{t}\\rangle-\\frac{\\lambda^{-1}}{2}\\int_{0}^{T}\\|u(X_{t}^{u},t)\\|^{2}\\,\\mathrm{d}t\\,.}\\end{array}\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "Since $\\begin{array}{r}{\\mathbb{E}_{\\mathbb{P}^{u}}\\left[\\log\\frac{d\\mathbb{P}^{u}}{d\\mathbb{P}^{u^{*}}}\\right]\\;=\\;-\\mathbb{E}_{\\mathbb{P}^{u}}\\left[\\log\\frac{d\\mathbb{P}^{u^{*}}}{d\\mathbb{P}^{u}}\\right]}\\end{array}$ , and $\\begin{array}{r}{\\mathbb{E}_{\\mathbb{P}^{u}}\\left[\\int_{0}^{T}\\langle u(X_{t}^{u},t),\\mathrm{d}B_{t}\\rangle\\right]\\,=\\,0}\\end{array}$ , the result follows.\u53e3", "page_idx": 18}, {"type": "text", "text": "Proposition 3. (i) The following two expressions hold for arbitrary controls $u,v$ in the class $\\boldsymbol{\\mathcal{U}}$ of admissible controls: ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\dot{\\boldsymbol{\\zeta}}_{\\mathrm{CE}}(u)=\\mathbb{E}_{\\mathbb{P}^{u^{*}}}\\left[\\log\\frac{d\\mathbb{P}^{u^{*}}}{d\\mathbb{P}^{u}}\\right]=\\mathbb{E}\\big[\\big(-\\lambda^{-1/2}\\int_{0}^{T}\\langle u(X_{t}^{v},t),\\mathrm{d}B_{t}\\rangle-\\lambda^{-1}\\int_{0}^{T}\\langle u(X_{t}^{v},t),v(X_{t}^{v},t)\\rangle\\,\\mathrm{d}t}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad(37)}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\qquad+\\frac{\\lambda^{-1}}{2}\\int_{0}^{T}\\|u(X_{t}^{v},t)\\|^{2}\\,\\mathrm{d}t+\\lambda^{-1}\\big(V(X_{0}^{v},0)-\\mathcal{W}(X^{v},0)\\big)\\big)}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\qquad\\times\\exp\\left(\\lambda^{-1}\\big(V(X_{0}^{v},0)-\\mathcal{W}(X^{v},0)\\big)\\right.}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\qquad\\left.-\\lambda^{-1/2}\\int_{0}^{T}\\langle v(X_{t}^{v},t),\\mathrm{d}B_{t}\\rangle-\\frac{\\lambda^{-1}}{2}\\int_{0}^{T}\\|v(X_{t}^{v},t)\\|^{2}\\,\\mathrm{d}t\\right)\\!\\!\\big]}\\end{array}\n$$", "text_format": "latex", "page_idx": 18}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\tilde{\\mathcal{L}}_{\\mathrm{CE}}(u)=\\frac{\\lambda^{-1}}{2}\\mathbb{E}\\big[\\int_{0}^{T}\\|u^{*}(X_{t}^{u^{*}},t)-u(X_{t}^{u^{*}},t)\\|^{2}\\,\\mathrm{d}t\\big].}\\end{array}\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "When $p_{0}$ is concentrated at a single point $x_{\\mathrm{init}}$ , the terms $V(x_{\\mathrm{init}},0)$ are constant and can be removed without modifying the landscape. In other words, $\\tilde{\\mathcal{L}}_{\\mathrm{CE}}$ and $\\mathcal{L}_{\\mathrm{CE}}$ are equal up to constant terms and constant factors. ", "page_idx": 18}, {"type": "text", "text": "$(i i)$ $p_{0}$ . $\\tilde{\\mathcal{L}}_{\\mathrm{CE}}$ ill th $\\mathcal{L}_{\\mathrm{CE}}$ y minimizer of the loss , a $\\mathcal{L}_{\\mathrm{CE}}(u)=$ $\\begin{array}{r}{\\mathbb{E}_{\\mathbb{P}^{u^{*}}}\\left[\\log\\frac{d\\mathbb{P}^{u^{*}}}{d\\mathbb{P}^{u}}\\exp\\left(-\\lambda^{-1}V(\\boldsymbol{X}_{0}^{u^{*}},0)\\right)\\right]}\\end{array}$ $u^{*}$ $\\mathcal{L}_{\\mathrm{CE}}$ $K$ ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathcal{L}_{\\mathrm{CE}}(u,0)=\\frac{\\lambda^{-1}}{2}\\mathbb{E}\\big[\\int_{0}^{T}\\|u^{*}(X_{t}^{u^{*}},t)-u(X_{t}^{u^{*}},t)\\|^{2}\\,\\mathrm{d}t\\exp\\big(-\\lambda^{-1}V(X_{0}^{u^{*}},0)\\big)\\big]+K.}\\end{array}\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "Proof. We begin with the proof of (i), and prove (37) first. Note that by the Girsanov theorem (Thm. 3), ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{E}_{\\mathbb{P}^{u^{*}}}\\left[\\log\\frac{d\\mathbb{P}^{u^{*}}}{d\\mathbb{P}^{u}}(X^{u^{*}})\\right]=-\\mathbb{E}_{\\mathbb{P}^{u^{*}}}\\left[\\log\\frac{d\\mathbb{P}^{u}}{d\\mathbb{P}^{u^{*}}}(X^{u^{*}})\\right]=-\\mathbb{E}_{\\mathbb{P}^{u^{*}}}\\left[\\log\\frac{d\\mathbb{P}^{u}}{d\\mathbb{P}}(X^{u^{*}})+\\log\\frac{d\\mathbb{P}}{d\\mathbb{P}^{u^{*}}}(X^{u^{*}})\\right]}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\qquad=-\\mathbb{E}_{\\mathbb{P}^{v}}\\left[\\left(\\log\\frac{d\\mathbb{P}^{u}}{d\\mathbb{P}}(X^{v})+\\log\\frac{d\\mathbb{P}}{d\\mathbb{P}^{u^{*}}}(X^{v})\\right)\\frac{d\\mathbb{P}^{u^{*}}}{d\\mathbb{P}}(X^{v})\\frac{d\\mathbb{P}}{d\\mathbb{P}^{v}}(X^{v})\\right]}\\end{array}\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "Note that by equations (32) and (34), ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\log\\frac{d\\mathbb{P}^{u}}{d\\mathbb{P}}(X^{v})=\\lambda^{-1/2}\\int_{0}^{T}\\langle u(X_{t}^{v},t),\\mathrm{d}B_{t}^{v}\\rangle-\\frac{\\lambda^{-1}}{2}\\int_{0}^{T}\\|u(X_{t}^{v},t)\\|^{2}\\,\\mathrm{d}t,}\\\\ &{\\qquad\\qquad\\qquad=\\lambda^{-1/2}\\int_{0}^{T}\\langle u(X_{t}^{v},t),\\mathrm{d}B_{t}\\rangle+\\lambda^{-1}\\int_{0}^{T}\\langle u(X_{t}^{v},t),v(X_{t}^{v},t)\\rangle\\,\\mathrm{d}t-\\frac{\\lambda^{-1}}{2}\\int_{0}^{T}\\|u(X_{t}^{v},t)\\|^{2}\\,\\mathrm{d}t}\\\\ &{\\operatorname{og}\\frac{d\\mathbb{P}}{d\\mathbb{P}^{u^{*}}}(X^{v})=\\lambda^{-1}\\big(-V(X_{0}^{v},0)+\\mathcal{W}(X^{v},0)\\big).}\\end{array}\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "where $\\begin{array}{r}{B_{t}^{v}:=B_{t}+\\lambda^{-1/2}\\int_{0}^{t}v(X_{s}^{v},s)}\\end{array}$ ds. Also, ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\frac{d\\mathbb{P}^{u^{*}}}{d\\mathbb{P}}(X^{v})=\\exp\\big(\\lambda^{-1}\\big(V(X_{0}^{v},0)-\\mathcal W(X^{v},0)\\big)\\big),}\\\\ &{\\frac{d\\mathbb{P}}{d\\mathbb{P}^{v}}(X^{v})=\\exp\\big(-\\lambda^{-1/2}\\int_{0}^{T}\\langle v(X_{t}^{v},t),\\mathrm{d}B_{t}\\rangle-\\frac{\\lambda^{-1}}{2}\\int_{0}^{T}\\|v(X_{t}^{v},t)\\|^{2}\\,\\mathrm{d}t\\big).}\\end{array}\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "If we plug (41) and (42) into the right-hand side of (40), we obtain ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{\\bar{z}}_{\\mathbb{P}^{u^{*}}}\\left[\\log\\frac{d\\mathbb{P}^{u^{*}}}{d\\mathbb{P}^{u}}(X^{u^{*}})\\right]=-\\mathbb{E}_{\\mathbb{P}^{u^{*}}}\\left[(\\log\\frac{d\\mathbb{P}^{u}}{d\\mathbb{P}}(X^{v})+\\log\\frac{d\\mathbb{P}}{d\\mathbb{P}^{u^{*}}}(X^{v}))\\frac{d\\mathbb{P}^{u^{*}}}{d\\mathbb{P}}(X^{v})\\frac{d\\mathbb{P}}{d\\mathbb{P}^{u}}(X^{v})\\right]}\\\\ &{=-\\mathbb{E}\\bigl[\\bigl(\\lambda^{-1/2}\\int_{0}^{T}\\langle u(X_{t}^{v},t),\\mathrm{d}B_{t}\\rangle+\\lambda^{-1}\\int_{0}^{T}\\langle u(X_{t}^{v},t),v(X_{t}^{v},t)\\rangle\\,\\mathrm{d}t}\\\\ &{\\qquad\\qquad-\\,\\frac{\\lambda^{-1}}{2}\\int_{0}^{T}\\|u(X_{t}^{v},t)\\|^{2}\\,\\mathrm{d}t+\\lambda^{-1}\\bigl(-V(X_{0}^{v},0)+\\mathcal{W}(X^{v},0)\\bigr)\\bigr)}\\\\ &{\\qquad\\times\\exp\\left(\\lambda^{-1}\\bigl(V(X_{0}^{v},0)-\\mathcal{W}(X^{v},0)\\bigr)-\\lambda^{-1/2}\\int_{0}^{T}\\langle v(X_{t}^{v},t),\\mathrm{d}B_{t}\\rangle-\\frac{\\lambda^{-1}}{2}\\int_{0}^{T}\\|v(X_{t}^{v},t)\\|^{2}\\,\\mathrm{d}t\\right)}\\end{array}\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "which concludes the proof. ", "page_idx": 19}, {"type": "text", "text": "To show (38), we use that by Cor. 1, ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\frac{d\\mathbb{P}^{u^{*}}}{|\\mathbb{P}^{u^{*}}}(X^{u^{*}})\\!=\\!\\exp\\left(-\\lambda^{-1/2}\\int_{0}^{T}\\langle u^{*}(X_{t}^{u^{*}},t)\\!-\\!u(X_{t}^{u^{*}},t),\\mathrm{d}B_{t}\\rangle-\\frac{\\lambda^{-1}}{2}\\int_{0}^{T}\\|u^{*}(X_{t}^{u^{*}},t)-u(X_{t}^{u^{*}},t)\\|^{2}\\,\\mathrm{d}t\\right).}\\end{array}\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "Hence, ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathbb{E}_{\\mathbb{P}^{u^{*}}}\\left[\\log\\frac{d\\mathbb{P}^{u^{*}}}{d\\mathbb{P}^{u}}\\right]=-\\mathbb{E}_{\\mathbb{P}^{u^{*}}}\\left[\\log\\frac{d\\mathbb{P}^{u}}{d\\mathbb{P}^{u^{*}}}\\right]=\\frac{\\lambda^{-1}}{2}\\mathbb{E}\\left[\\int_{0}^{T}\\|u^{*}(X_{t}^{u^{*}},t)-u(X_{t}^{u^{*}},t)\\|^{2}\\,\\mathrm{d}t\\right].}\\end{array}\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "Next, we prove (ii). The first instance of $V(X_{0}^{v},0)$ in (37) can be removed without modifying the landscape of the loss. Hence, we are left with ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\bar{\\mathsf{\\Sigma}}_{\\mathrm{CE}}(u)=\\mathbb{E}\\big[\\big(-\\lambda^{-1/2}\\int_{0}^{T}\\langle u(X_{t}^{v},t),\\mathrm{d}B_{t}^{v}\\rangle-\\lambda^{-1}\\int_{0}^{T}\\langle u(X_{t}^{v},t),v(X_{t}^{v},t)\\rangle\\,\\mathrm{d}t}\\\\ &{\\qquad\\qquad\\qquad+\\frac{\\lambda^{-1}}{2}\\int_{0}^{T}\\|u(X_{t}^{v},t)\\|^{2}\\,\\mathrm{d}t-\\lambda^{-1}\\mathcal{W}(X^{v},0)\\big)}\\\\ &{\\qquad\\qquad\\times\\,\\exp\\big(\\lambda^{-1}\\big(V(X_{0}^{v},0)\\!-\\!\\mathcal{W}(X^{v},0)\\big)-\\lambda^{-1/2}\\int_{0}^{T}\\langle v(X_{t}^{v},t),\\mathrm{d}B_{t}\\rangle-\\frac{\\lambda^{-1}}{2}\\int_{0}^{T}\\|v(X_{t}^{v},t)\\|^{2}\\,\\mathrm{d}s}\\end{array}\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "And this can be expressed as ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\bar{\\mathcal{L}}_{\\mathrm{CE}}(u)=\\mathbb{E}\\big[g(u;X_{0}^{v})\\exp\\big(\\lambda^{-1}V(X_{0}^{v},0)\\big)\\big],\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "where ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\iota(u;x)=\\mathbb{E}\\big[\\big(-\\lambda^{-1/2}\\int_{0}^{T}\\langle u(X_{t}^{v},t),\\mathrm{d}B_{t}^{v}\\rangle-\\lambda^{-1}\\int_{0}^{T}\\langle u(X_{t}^{v},t),v(X_{t}^{v},t)\\rangle\\,\\mathrm{d}t}\\\\ &{\\qquad\\qquad+\\,\\frac{\\lambda^{-1}}{2}\\int_{0}^{T}\\|u(X_{t}^{v},t)\\|^{2}\\,\\mathrm{d}t-\\lambda^{-1}\\mathcal{W}(X^{v},0)\\big)}\\\\ &{\\qquad\\qquad\\times\\,\\exp\\big(-\\lambda^{-1}\\mathcal{W}(X^{v},0)-\\lambda^{-1/2}\\int_{0}^{T}\\langle v(X_{t}^{v},t),\\mathrm{d}B_{t}\\rangle-\\frac{\\lambda^{-1}}{2}\\int_{0}^{T}\\|v(X_{t}^{v},t)\\|^{2}\\,\\mathrm{d}t\\big)|X_{0}^{v}=x^{\\prime}}\\end{array}\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "If we consider $g(u;x)$ as a loss function for $u$ , note that it is equivalent to the loss $\\bar{L}_{\\mathrm{CE}}(u)$ equation in (43) for the choice $p_{0}=\\delta_{x}$ , i.e., $p_{0}$ concentrated at $x$ . Since the optimal control $\\boldsymbol{u}^{*}$ is independent of the starting distribution $p_{\\mathrm{0}}$ , we deduce that $u^{*}$ is the unique minimizer of $g(u;x)$ , for all $\\dot{x}\\in\\mathbb{R}^{d}$ . In consequence, $\\boldsymbol{u}^{*}$ is the unique minimizer of $\\mathcal{L}_{\\mathrm{CE}}(u)=\\mathbb{E}[g(u;X_{0}^{v})]$ . ", "page_idx": 19}, {"type": "text", "text": "To prove (39), note that up to a constant term, the only difference between $\\bar{\\mathcal{L}}_{\\mathrm{CE}}(u)$ and $\\mathcal{L}_{\\mathrm{CE}}(u)$ is the expectation is reweighted importance weight $\\exp\\big(-\\lambda^{-1}V(X_{0}^{v},0)\\big)$ . \u53e3 ", "page_idx": 19}, {"type": "text", "text": "Lemma 4. (i) We can rewrite ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\tilde{\\mathcal{L}}_{\\mathrm{Var}_{v}}(u)=\\mathrm{Var}\\big(\\exp\\big(\\tilde{Y}_{T}^{u,v}-\\lambda^{-1}g(X_{T}^{v})+\\lambda^{-1}V(X_{0}^{v},0)\\big)\\big),}\\\\ &{\\tilde{\\mathcal{L}}_{\\mathrm{Var}_{v}}^{\\mathrm{log}}(u)=\\mathrm{Var}\\big(\\tilde{Y}_{T}^{u,v}-\\lambda^{-1}g(X_{T}^{v})+\\lambda^{-1}V(X_{0}^{v},0)\\big).}\\end{array}\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "When $p_{0}$ is concentrated at $x_{\\mathrm{init}}$ , the terms $V(x_{\\mathrm{init}},0)$ are constants and can be removed without modifying the landscape. In other words, $\\tilde{\\mathcal{L}}_{\\mathrm{Var}_{v}}$ and $\\tilde{\\mathcal{L}}_{\\mathrm{Var}_{v}}^{\\mathrm{log}}$ are equal to $\\mathcal{L}_{\\mathrm{Var}_{v}}$ and $\\mathcal{L}_{\\mathrm{Var}_{v}}^{\\mathrm{log}}$ up to $a$ constant term and a constant factor, respectively. ", "page_idx": 19}, {"type": "text", "text": "(ii) When $p_{0}$ is general, $\\tilde{\\mathcal{L}}_{\\mathrm{Var}_{v}}$ and $\\mathcal{L}_{\\mathrm{Var}_{v}}$ have a different landscape, and the optimum of $\\mathcal{L}_{\\mathrm{Var}_{v}}$ may be different from $\\boldsymbol{u}^{*}$ . $A$ related loss that does preserve the optimum is: ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\bar{\\mathcal{L}}_{\\mathrm{Var}_{v}}(u)=\\mathbb{E}[\\mathrm{Var}_{\\mathbb{P}^{v}}(\\frac{d\\mathbb{P}^{u^{*}}}{d\\mathbb{P}^{u}}(X^{v})|X_{0}^{v})\\exp(-\\lambda^{-1}V(X_{0}^{v},0))]}\\\\ &{\\qquad\\qquad=\\mathbb{E}[\\mathrm{Var}\\big(\\exp(\\tilde{Y}_{T}^{u,v}-\\lambda^{-1}g(X_{T}^{v}))|X_{0}^{v}\\big)].}\\end{array}\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "In practice, this is implemented by sampling the m trajectories in one batch starting at the same point $X_{0}^{v}$ . ", "page_idx": 20}, {"type": "text", "text": "(iii) Also, L\u02dclVoagrv and LV agrv have a different landscape, and the optimum of LlVoagrv may be different from $\\boldsymbol{u}^{*}$ . In particular, $\\begin{array}{r}{\\mathcal{L}_{\\mathrm{Var}_{v}}^{\\mathrm{log}}(u)=\\mathrm{Var}_{\\mathbb{P}^{v}}(\\log\\frac{d\\mathbb{P}^{u^{*}}}{d\\mathbb{P}^{u}}(X^{v})\\exp(-\\lambda^{-1}V(X_{0}^{v},0)))}\\end{array}$ ). A loss that does preserve the optimum $u^{*}$ is ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\bar{\\mathcal L}_{\\mathrm{Var}_{v}}^{\\log}(u)={\\mathbb E}[\\mathrm{Var}_{\\mathbb{P}^{v}}(\\log\\frac{d\\mathbb{P}^{u^{*}}}{d\\mathbb{P}^{u}}(X^{v})|X_{0}^{v})\\exp(-\\lambda^{-1}V(X_{0}^{v},0))]}\\\\ &{\\qquad\\qquad={\\mathbb E}[\\mathrm{Var}\\big(\\tilde{Y}_{T}^{u,v}-\\lambda^{-1}g(X_{T}^{v})|X_{0}^{v}\\big)].}\\end{array}\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "Proof. Using (34) and (31), we have that ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\frac{d\\mathbb{P}^{u^{*}}}{d\\mathbb{P}}(X^{v})=\\exp\\big(\\lambda^{-1}\\big(V(X_{0}^{v},0)-\\mathcal{W}(X^{v},0)\\big)\\big),}\\\\ &{\\frac{d\\mathbb{P}}{d\\mathbb{P}^{u}}(X^{v})=\\exp\\big(-\\lambda^{-1/2}\\int_{0}^{T}\\langle u(X_{t}^{v},t),\\mathrm{d}B_{t}^{v}\\rangle+\\frac{\\lambda^{-1}}{2}\\int_{0}^{T}\\|u(X_{t}^{v},t)\\|^{2}\\,\\mathrm{d}t\\big)}\\\\ &{\\qquad\\qquad=\\exp\\big(-\\lambda^{-1/2}\\int_{0}^{T}\\langle u(X_{t}^{v},t),\\mathrm{d}B_{t}\\rangle-\\lambda^{-1}\\int_{0}^{T}\\langle u(X_{t}^{v},t),v(X_{t}^{v},t)\\rangle\\,\\mathrm{d}t}\\\\ &{\\qquad\\qquad\\qquad\\qquad+\\frac{\\lambda^{-1}}{2}\\int_{0}^{T}\\|u(X_{t}^{v},t)\\|^{2}\\,\\mathrm{d}t\\big).}\\end{array}\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "Hence, ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\log\\frac{d\\mathbb{P}^{u^{*}}}{d\\mathbb{P}^{u}}(X^{v})=\\log\\frac{d\\mathbb{P}^{u^{*}}}{d\\mathbb{P}}(X^{v})+\\log\\frac{d\\mathbb{P}}{d\\mathbb{P}^{u}}(X^{v})=\\tilde{Y}_{T}^{u,v}-\\lambda^{-1}g(X_{T}^{v})+\\lambda^{-1}V(X_{0}^{v},0).}\\end{array}\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "Since $\\begin{array}{r}{\\tilde{\\mathcal{L}}_{\\mathrm{Var}_{v}}(u)=\\mathrm{Var}_{\\mathbb{P}^{v}}\\big(\\frac{d\\mathbb{P}^{u^{*}}}{d\\mathbb{P}^{u}}\\big)}\\end{array}$ and $\\begin{array}{r}{\\tilde{\\mathcal{L}}_{\\mathrm{Var}_{v}}^{\\mathrm{log}}(u)=\\mathrm{Var}_{\\mathbb{P}^{v}}(\\log\\frac{d\\mathbb{P}^{u^{*}}}{d\\mathbb{P}^{u}})}\\end{array}$ , this concludes the proof of (i). To prove (ii), note that for general $p_{0},V(X_{0}^{v},0)$ is no longer a constant, but it is if we condition on $X_{0}^{v}$ . The proof of (iii) is analogous. \u53e3 ", "page_idx": 20}, {"type": "text", "text": "C Proofs of Sec. 3 ", "text_level": 1, "page_idx": 20}, {"type": "text", "text": "C.1 Proof of Thm. 1 and Prop. 2 ", "text_level": 1, "page_idx": 20}, {"type": "text", "text": "We prove Thm. 1 and Prop. 2 at the same time. Recall that by (9), the optimal control is of the form $\\boldsymbol{u}^{*}(\\dot{\\boldsymbol{x}},t)=-{\\sigma}(t)^{\\top}\\nabla V(\\dot{\\boldsymbol{x}_{,}}t)$ . Consider the loss ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\tilde{\\mathcal{L}}(u)=\\mathbb{E}\\big[\\frac{1}{T}\\int_{0}^{T}\\|u(X_{t},t)+\\sigma(t)^{\\top}\\nabla V(X_{t},t)\\|^{2}\\,\\mathrm{d}t\\,\\exp\\big(-\\lambda^{-1}\\int_{0}^{T}f(X_{t},t)\\,\\mathrm{d}t-\\lambda^{-1}g(X_{T})\\big)\\big].}\\end{array}\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "Clearly, the unique optimum of $\\tilde{\\mathcal{L}}$ is $-\\sigma(t)^{\\top}\\nabla V$ . We can rewrite $\\tilde{\\mathcal{L}}$ as ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\tilde{\\mathcal{L}}(u)=\\mathbb{E}\\big[\\frac{1}{T}\\int_{0}^{T}\\big(\\big\\|u(X_{t},t)\\big\\|^{2}+2\\langle u(X_{t},t),\\sigma(t)^{\\top}\\nabla V(X_{t},t)\\rangle+\\|\\sigma(t)^{\\top}\\nabla V(X_{t},t)\\|^{2}\\big)\\,\\mathrm{d}t(4\\,)^{-1}\\big]}\\\\ &{\\qquad\\qquad\\times\\exp\\big(-\\lambda^{-1}\\int_{0}^{T}f(X_{t},t)\\,\\mathrm{d}t-\\lambda^{-1}g(X_{T})\\big)\\big]\\;.}\\end{array}\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "Hence, we can express $\\tilde{\\mathcal{L}}$ as a sum of three terms: one involving $\\|u(X_{t},t)\\|^{2}$ , another involving $\\langle u(X_{t},t),\\sigma(t)^{\\top}V(X_{t},t)\\rangle$ , and a third one, which is constant with respect to $u$ , involving $\\|\\nabla V(X_{t},t)\\|^{2}$ . The following lemma provides an alternative expression for the cross term: ", "page_idx": 20}, {"type": "text", "text": "Lemma 5. The following equality holds: ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{E}\\big[\\frac{1}{T}\\int_{0}^{T}\\langle u(X_{t},t),\\sigma(t)^{\\top}\\nabla V(X_{t},t)\\rangle\\,{\\mathrm d}t\\,\\exp\\big(-\\lambda^{-1}\\int_{0}^{T}f(X_{t},t)\\,{\\mathrm d}t-\\lambda^{-1}g(X_{T})\\big)\\big]}\\\\ &{=-\\lambda\\mathbb{E}\\big[\\frac{1}{T}\\int_{0}^{T}\\big\\langle u(X_{t},t),\\sigma(t)^{\\top}\\nabla_{x}\\mathbb{E}\\big[\\exp\\big(-\\lambda^{-1}\\int_{t}^{T}f(X_{s},s)\\,{\\mathrm d}s-\\lambda^{-1}g(X_{T})\\big)\\big|X_{t}=x\\big]\\backslash{\\mathrm d}5\\big)}\\\\ &{\\qquad\\qquad\\times\\exp\\big(-\\lambda^{-1}\\int_{0}^{t}f(X_{s},s)\\,{\\mathrm d}s\\big)\\,{\\mathrm d}t\\big].}\\end{array}\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "Proof. Recall the definition of $\\mathcal{W}(X,t)$ in (35), which means that ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathcal{W}(X,0)=\\mathcal{W}(X,t)+\\int_{0}^{t}f(X_{s},s)\\,\\mathrm{d}s.}\\end{array}\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "Let $\\{{\\mathcal{F}}_{t}\\}_{t\\in[0,T]}$ be the filtration generated by the Brownian motion $B$ . Then, equation (9) implies that ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\sigma(t)^{\\top}\\nabla V(X_{t},t)=-\\frac{\\lambda\\sigma(t)^{\\top}\\nabla_{x}\\mathbb{E}\\left[\\exp\\left(-\\lambda^{-1}\\mathcal{W}(X,t)\\right)\\Big\\vert\\mathcal{F}_{t}\\right]}{\\mathbb{E}\\left[\\exp\\left(-\\lambda^{-1}\\mathcal{W}(X,t)\\right)\\Big\\vert\\mathcal{F}_{t}\\right]}}\\end{array}\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "We proceed as follows: ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{\\xi}\\big[\\frac{1}{T}\\int_{0}^{T}\\langle u(X_{t},t),\\sigma(t)^{\\top}\\nabla V(X_{t},t)\\rangle\\,\\mathrm{d}t\\,\\exp\\big(-\\lambda^{-1}\\mathcal{W}(X,0)\\big)\\big]}\\\\ &{\\overset{\\mathrm{(i)}}{=}-\\lambda\\mathbb{E}\\big[\\frac{1}{T}\\int_{0}^{T}\\big\\langle u(X_{t},t),\\frac{\\sigma(t)^{\\top}\\nabla_{x}\\mathbb{E}\\big[\\exp\\big(-\\lambda^{-1}\\mathcal{W}(X,t)\\big)\\big|\\mathcal{F}_{t}\\big]}{\\mathbb{E}\\big[\\exp\\big(-\\lambda^{-1}\\mathcal{W}(X,t)\\big)\\big]\\mathcal{F}_{t}\\big]}\\big\\rangle}\\\\ &{\\qquad\\qquad\\times\\mathbb{E}\\big[\\exp\\big(-\\lambda^{-1}\\mathcal{W}(X,t)\\big)\\big|\\mathcal{F}_{t}\\big]\\exp\\big(-\\lambda^{-1}\\int_{0}^{t}f(X_{s},s)\\,\\mathrm{d}s\\big)\\,\\mathrm{d}t\\big]}\\\\ &{=-\\lambda\\mathbb{E}\\big[\\frac{1}{T}\\int_{0}^{T}\\big\\langle u(X_{t},t),\\sigma(t)^{\\top}\\nabla_{x}\\mathbb{E}\\big[\\exp\\big(-\\lambda^{-1}\\mathcal{W}(X,t)\\big)\\big|\\mathcal{F}_{t}\\big]\\big\\rangle\\exp\\big(-\\lambda^{-1}\\int_{0}^{t}f(X_{s},s)\\,\\mathrm{d}s\\big)\\,\\mathrm{d}t\\big]}\\\\ &{\\overset{\\mathrm{(ii)}}{=}-\\lambda\\mathbb{E}\\big[\\frac{1}{T}\\int_{0}^{T}\\big\\langle u(X_{t},t),\\sigma(t)^{\\top}\\nabla_{x}\\mathbb{E}\\big[\\exp\\big(-\\lambda^{-1}\\mathcal{W}(X,t)\\big)\\big|X_{t}=x\\big]\\big\\rangle\\exp\\big(-\\lambda^{-1}\\int_{0}^{t}f(X_{s},s)\\,\\mathrm{d}s\\big)}\\end{array}\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "Here, (i) holds by equation (47), the law of total expectation and equation (46), and (ii) holds by the Markov property of the solution of an SDE. \u53e3 ", "page_idx": 21}, {"type": "text", "text": "The following proposition, which we prove in Subsec. C.2, provides an alternative expression for $\\begin{array}{r l}&{\\nabla_{x}\\mathbb{E}\\big[\\exp\\big(-\\lambda^{-1}\\int_{t}^{T}f(X_{s},s)\\,\\mathrm{d}s-\\lambda^{-1}g(X_{T})\\big)\\big|X_{t}=x\\big]}\\end{array}$ . The technique, which is novel and we denote by Girsanov reparamaterization trick, is of independent interest and may be applied in other settings, as we discuss in Sec. 5. ", "page_idx": 21}, {"type": "text", "text": "Proposition 1 (Path-wise reparameterization trick for stochastic optimal control). For each $t\\in[0,T]$ , let $M_{t}:[t,T]\\rightarrow\\mathbb{R}^{d\\times d}$ be an arbitrary continuously differentiable function matrix-valued function such that $M_{t}\\dot{({t})}=\\operatorname{Id}$ . We have that ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\nabla_{x}\\mathbb{E}\\big[\\exp\\big(-\\lambda^{-1}\\int_{t}^{T}f(X_{s},s)\\,\\mathrm{d}s-\\lambda^{-1}g(X_{T})\\big)\\big\\vert X_{t}=x\\big]}\\\\ &{=\\mathbb{E}\\big[\\big(-\\lambda^{-1}\\int_{t}^{T}M_{t}(s)\\nabla_{x}f(X_{s},s)\\,\\mathrm{d}s-\\lambda^{-1}M_{t}(T)\\nabla g(X_{T})}\\\\ &{\\qquad\\qquad+\\,\\lambda^{-1/2}\\int_{t}^{T}(M_{t}(s)\\nabla_{x}b(X_{s},s)-\\partial_{s}M_{t}(s))(\\sigma^{-1})^{\\top}(s)\\mathrm{d}B_{s}\\big)}\\\\ &{\\qquad\\qquad\\times\\exp\\big(-\\lambda^{-1}\\int_{t}^{T}f(X_{s},s)\\,\\mathrm{d}s-\\lambda^{-1}g(X_{T})\\big)\\big\\vert X_{t}=x\\big].}\\end{array}\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "Plugging (23) into the right-hand side of (45), we obtain that ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{E}\\big[\\frac{1}{T}\\int_{0}^{T}\\langle u(X_{t},t),\\sigma(t)^{\\top}\\nabla V(X_{t},t)\\rangle\\,\\mathrm{d}t\\,\\exp\\big(-\\lambda^{-1}\\int_{0}^{T}f(X_{t},t)\\,\\mathrm{d}t-\\lambda^{-1}g(X_{T})\\big)\\big]}\\\\ &{=\\mathbb{E}\\big[\\frac{1}{T}\\int_{0}^{T}\\big\\langle u(X_{t},t),\\sigma(t)^{\\top}\\big(\\int_{t}^{T}M_{t}(s)\\nabla_{x}f(X_{s},s)\\,\\mathrm{d}s+M_{t}(T)\\nabla g(X_{T})}\\\\ &{\\qquad\\qquad-\\lambda^{1/2}\\int_{t}^{T}(M_{t}(s)\\nabla_{x}b(X_{s},s)-\\partial_{s}M_{t}(s))(\\sigma^{-1})^{\\top}(s)\\mathrm{d}B_{s}\\big)\\big\\rangle\\,\\mathrm{d}t}\\\\ &{\\qquad\\qquad\\times\\exp\\big(-\\lambda^{-1}\\int_{0}^{T}f(X_{t},t)\\,\\mathrm{d}t-\\lambda^{-1}g(X_{T})\\big)\\big].}\\end{array}\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "If we plug this into the right-hand side of (44) and complete the squared norm, we get that ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\tilde{\\mathcal{L}}(u)=\\mathbb{E}\\big[\\frac{1}{T}\\int_{0}^{T}(\\left\\|u(X_{t},t)-\\tilde{w}(t,X,B,M_{t})\\right\\|^{2}-\\left\\|\\tilde{w}(t,X,B,M_{t})\\right\\|^{2}}\\\\ &{\\qquad\\qquad\\qquad+\\left\\|u^{*}(X_{t},t)\\right\\|^{2})\\,\\mathrm{d}t\\exp\\left(-\\lambda^{-1}\\mathcal{W}(X,0)\\right)\\big]}\\end{array}\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "where $\\tilde{w}$ is defined as: ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\tilde{w}(t,X,B,M_{t})=\\sigma(t)^{\\top}\\big(-\\int_{t}^{T}M_{t}(s)\\nabla_{x}f(X_{s},s)\\,\\mathrm{d}s-M_{t}(T)\\nabla g(X_{T})}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\qquad+\\,\\lambda^{1/2}\\int_{t}^{T}(M_{t}(s)\\nabla_{x}b(X_{s},s)-\\partial_{s}M_{t}(s))(\\sigma^{-1})^{\\top}(s)\\mathrm{d}B_{s}\\big).}\\end{array}\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "We also define $\\Phi(u;X,B)$ as ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\Phi(u;X,B)=\\frac{1}{T}\\int_{0}^{T}(\\left|\\left|u(X_{t},t)-\\tilde{w}(t,X,B,M_{t})\\right|\\right|^{2})\\mathrm{d}t.}\\end{array}\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "Now, by the Girsanov theorem (Thm. 3), we have that for an arbitrary control $v\\in\\mathcal{U}$ , ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathfrak{L}[\\Phi(u;X,B)\\exp\\big(-\\lambda^{-1}\\mathcal{W}(X,0)\\big)]}\\\\ &{=\\mathbb{E}\\big[\\Phi(u;X^{v},B^{v})\\exp\\big(-\\lambda^{-1}\\mathcal{W}(X^{v},0)-\\lambda^{-1/2}\\int_{0}^{T}\\langle v(X_{t}^{v},t),\\mathrm{d}B_{t}^{v}\\rangle+\\frac{\\lambda^{-1}}{2}\\int_{0}^{T}\\|v(X_{t}^{v},t)\\|^{2}\\,\\mathrm{d}t\\big)\\big]}\\\\ &{=\\mathbb{E}\\big[\\Phi(u;X^{v},B^{v})\\exp\\big(-\\lambda^{-1}\\mathcal{W}(X^{v},0)-\\lambda^{-1/2}\\int_{0}^{T}\\langle v(X_{t}^{v},t),\\mathrm{d}B_{t}\\rangle-\\frac{\\lambda^{-1}}{2}\\int_{0}^{T}\\|v(X_{t}^{v},t)\\|^{2}\\,\\mathrm{d}t\\big)\\big],}\\end{array}\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "where $\\begin{array}{r}{B_{t}^{v}\\ :=\\ B_{t}\\,+\\,\\lambda^{-1/2}\\int_{0}^{t}v(X_{s}^{v},s)\\,\\mathrm{d}s}\\end{array}$ . Reexpressing $B^{v}$ in terms of $B$ , we can rewrite $\\Phi(u;X^{v},B^{v})$ and $\\tilde{w}(t,X^{v},B^{v},M_{t})$ as follows: ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\qquad\\Phi(u;X^{v},B^{v})=\\frac{1}{T}\\int_{0}^{T}\\left\\|u(X_{t}^{v},t)-\\tilde{w}(t,X^{v},B^{v},M_{t})\\right\\|^{2}\\mathrm{d}t,}\\\\ &{\\qquad\\tilde{w}(t,X^{v},B^{v},M_{t})=\\sigma(t)^{\\top}\\big(-\\int_{t}^{T}M_{t}(s)\\nabla_{x}f(X_{s}^{v},s)\\,\\mathrm{d}s-M_{t}(T)\\nabla g(X_{T}^{v})}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\qquad+\\lambda^{1/2}\\int_{t}^{T}(M_{t}(s)\\nabla_{x}b(X_{s}^{v},s)-\\partial_{s}M_{t}(s))(\\sigma^{-1})^{\\top}(X_{s}^{v},s)\\mathrm{d}B_{s}}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\qquad+\\int_{t}^{T}(M_{t}(s)\\nabla_{x}b(X_{s}^{v},s)-\\partial_{s}M_{t}(s))(\\sigma^{-1})^{\\top}(X_{s}^{v},s)v(X_{s}^{v},s)\\mathrm{d}s\\big).}\\end{array}\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "Putting everything together, we obtain that ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\tilde{\\mathcal{L}}(u)=\\mathcal{L}_{\\mathrm{SOCM}}(u,M)-K,\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "where $\\mathcal{L}(u,M)$ is the loss defined in (19) (note that $w(t,v,X^{v},B,M_{t}):=\\tilde{w}(t,X^{v},B^{v},M_{t}))$ , and ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\begin{array}{r}{K=\\mathbb{E}\\big[\\frac{1}{T}\\int_{0}^{T}(\\big\\|\\tilde{w}(t,X,B,M_{t})\\big\\|^{2}-\\big\\|u^{*}(X_{t},t)\\big\\|^{2})\\,\\mathrm{d}t\\,\\exp\\big(-\\lambda^{-1}\\mathcal{W}(X,0)\\big)\\big]}\\end{array}\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "To complete the proof of equation (24), remark that $\\tilde{\\mathcal{L}}(u)$ can be rewritten as ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\tilde{\\mathcal{L}}(u)=\\mathbb{E}\\big[\\frac{1}{T}\\int_{0}^{T}\\|u(X_{t},t)-u^{*}(X_{t},t)\\|^{2}\\,\\mathrm{d}t\\,\\exp\\big(-\\lambda^{-1}\\mathcal{W}(X,0)\\big)\\big]}\\\\ &{\\qquad=\\mathbb{E}\\big[\\frac{1}{T}\\int_{0}^{T}\\|u(X_{t},t)-u^{*}(X_{t},t)\\|^{2}\\,\\mathrm{d}t\\,\\frac{d\\mathbb{D}^{u^{*}}}{d\\mathbb{P}}(X)\\exp(-\\lambda^{-1}V(X_{0},0))\\big]}\\\\ &{\\qquad=\\mathbb{E}\\big[\\frac{1}{T}\\int_{0}^{T}\\|u(X_{t}^{u^{*}},t)-u^{*}(X_{t}^{u^{*}},t)\\|^{2}\\,\\mathrm{d}t\\,\\exp(-\\lambda^{-1}V(X_{0}^{u^{*}},0))\\big].}\\end{array}\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "It only remains to reexpress $K$ . Note that by Prop. 1, we have that ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{u^{*}(X_{t},t)=\\frac{\\mathbb{E}\\big[\\tilde{w}(t,X,B,M_{t})\\exp\\big(-\\lambda^{-1}\\mathcal{W}(X,0)\\big)|\\mathcal{F}_{t}\\big]}{\\mathbb{E}\\big[\\exp\\big(-\\lambda^{-1}\\mathcal{W}(X,0)\\big)|\\mathcal{F}_{t}\\big]}}\\\\ &{\\qquad\\qquad=\\frac{\\mathbb{E}\\big[\\tilde{w}(t,X,B,M_{t})\\frac{d\\mathbb{P}u^{*}}{d\\mathbb{P}}(X)|\\mathcal{F}_{t}\\big]\\exp(-\\lambda^{-1}V(X_{0},0))}{\\mathbb{E}\\big[\\frac{d\\mathbb{P}^{u}}{d\\mathbb{P}}(X)|\\mathcal{F}_{t}\\big]\\exp(-\\lambda^{-1}V(X_{0},0))}=\\frac{\\mathbb{E}\\big[\\tilde{w}(t,X,B,M_{t})\\frac{d\\mathbb{P}^{u^{*}}}{d\\mathbb{P}}(X)|\\mathcal{F}_{t}\\big]}{\\mathbb{E}\\big[\\frac{d\\mathbb{P}^{u^{*}}}{d\\mathbb{P}}(X)|\\mathcal{F}_{t}\\big]}}\\\\ &{\\qquad\\qquad=\\mathbb{E}\\big[\\tilde{w}(t,X^{u^{*}},B^{u^{*}},M_{t})|X_{t}^{u^{*}}=X_{t}\\big]}\\end{array}\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "Hence, using the Girsanov theorem (Thm. 3) several times, we have that ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{K=\\mathbb{E}\\big[\\frac{1}{T}\\int_{0}^{T}\\big\\lVert\\tilde{w}(t,X^{\\boldsymbol{u}^{*}},B^{\\boldsymbol{u}^{*}},M_{t})\\big\\rVert^{2}-\\big\\lVert\\mathbb{E}\\big[\\tilde{w}(t,X^{\\boldsymbol{u}^{*}},B^{\\boldsymbol{u}^{*}},M_{t})\\big|X_{t}^{\\boldsymbol{u}^{*}}\\big]\\big\\rVert^{2}\\,\\mathrm{d}t\\,\\exp(-\\lambda^{-1}V(X_{0}^{\\boldsymbol{u}^{*}},\\boldsymbol{0}))\\big\\rVert^{2}\\,\\mathrm{d}t}\\\\ &{\\quad=\\mathbb{E}\\big[\\frac{1}{T}\\int_{0}^{T}\\big\\lVert\\tilde{w}(t,X^{\\boldsymbol{u}^{*}},B^{\\boldsymbol{u}^{*}},M_{t})-\\mathbb{E}\\big[\\tilde{w}(t,X^{\\boldsymbol{u}^{*}},B^{\\boldsymbol{u}^{*}},M_{t})\\big|X_{t}^{\\boldsymbol{u}^{*}}\\big]\\big\\rVert^{2}\\,\\mathrm{d}t\\,\\exp(-\\lambda^{-1}V(X_{0}^{\\boldsymbol{u}^{*}},0))\\big]}\\\\ &{\\quad=\\mathbb{E}\\big[\\frac{1}{T}\\int_{0}^{T}\\big\\lVert\\tilde{w}(t,X,B,M_{t})-\\frac{\\mathbb{E}\\big[\\tilde{w}(t,X,B,M_{t})\\exp(-\\lambda^{-1}\\mathcal{W}(X,0))\\big|X_{t}\\big]}{\\mathbb{E}\\big[\\exp(-\\lambda^{-1}\\mathcal{W}(X,0))\\big|X_{t}\\big]}\\big\\rVert^{2}\\,\\mathrm{d}t\\,\\exp(-\\lambda^{-1}\\mathcal{W}(X,0))\\big]}\\\\ &{\\quad=\\mathbb{E}\\big[\\frac{1}{T}\\int_{0}^{T}\\big\\lVert\\boldsymbol{w}(t,X^{\\boldsymbol{v}},B,M_{t})-\\frac{\\mathbb{E}\\big[w(t,v,X^{\\boldsymbol{v}},B,M_{t})\\alpha(v,X^{\\boldsymbol{v}},B)\\big|X_{t}^{\\boldsymbol{v}}\\big]}{\\mathbb{E}\\big[\\alpha(v,X^{\\boldsymbol{v}},B)\\big|X_{t}^{\\boldsymbol{v}}\\big]}\\big\\rVert^{2}\\,\\mathrm{d}t\\,\\alpha(v,X^{\\boldsymbol{v}},B)\\big],}\\end{array}\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "which concludes the proof, noticing that $K=\\mathrm{Var}(w;M)$ . ", "page_idx": 22}, {"type": "text", "text": "Remark 1 (The optimal $M_{t}$ is the same for all $v$ ). Looking at equation (48), we observe that $\\mathrm{Var}(w;M)$ does not depend on the base control $v$ . Since minimizing $\\mathcal{L}_{\\mathrm{SOCM}}(u,M)$ with respect to $M$ is equivalent to minimizing $\\mathrm{Var}(w;M)$ , we deduce that the optimal $M$ does not depend on the vector field $v$ . ", "page_idx": 22}, {"type": "text", "text": "C.2 Proof of the path-wise reparameterization trick (Prop. 1) ", "text_level": 1, "page_idx": 23}, {"type": "text", "text": "We prove a more general statement (Prop. 4), and show that Prop. 1 is a particular case of it. ", "page_idx": 23}, {"type": "text", "text": "Proposition 4 (Path-wise reparameterization trick). Let $\\textstyle(\\Omega,{\\mathcal{F}},\\mathbb{P})$ be a probability space, and $B:\\Omega\\times[0,T]\\rightarrow\\mathbb{R}^{d}$ be a Brownian motion. Let $X:\\Omega\\times[0,T]\\rightarrow\\ensuremath{\\mathbb{R}}^{d}$ be the uncontrolled process given by (6), and let $\\psi:\\Omega\\times\\mathbb{R}^{d}\\times[0,T]\\rightarrow\\mathbb{R}^{d}$ be an arbitrary random process such that: ", "page_idx": 23}, {"type": "text", "text": "\u2022 For all $z~\\in~\\mathbb{R}^{d}$ , the process $\\psi(\\cdot,z,\\cdot)\\,:\\,\\Omega\\,\\times\\,[0,T]\\,\\,\\rightarrow\\,\\mathbb{R}^{d}$ is adapted to the filtration $({\\mathcal{F}}_{s})_{s\\in[0,T]}$ of the Brownian motion $B$ . \u2022 For all $\\omega\\in{\\Omega}$ , $\\psi(\\omega,\\cdot,\\cdot):\\mathbb{R}^{d}\\times[0,T]\\rightarrow\\mathbb{R}^{d}$ is a twice-continuously differentiable function such that $\\psi(\\omega,z,0)=z$ for all $z\\in\\mathbb{R}^{d}$ , and $\\psi(\\omega,0,s)=0$ for all $s\\in[0,T]$ . ", "page_idx": 23}, {"type": "text", "text": "Let $F:C([0,T];\\mathbb{R}^{d})\\rightarrow\\mathbb{R}$ be a Fr\u00e9chet-differentiable functional. We use the notation $X+\\psi(z,\\cdot)=$ $(X_{s}(\\omega)+\\psi(\\omega,z,s))_{s\\in[0,T]}$ to denote the shifted process, and we will omit the dependency of $\\psi$ on $\\omega$ in the proof. Then, ", "page_idx": 23}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\nabla_{x}\\mathbb{E}\\big[\\exp\\big(-F(X)\\big)\\big|X_{0}=x\\big]}\\\\ &{=\\mathbb{E}\\big[\\big(-\\nabla_{z}F(X+\\psi(z,\\cdot))\\big|_{z=0}+\\lambda^{-1/2}\\int_{0}^{T}(\\nabla_{z}\\psi(0,s)\\nabla_{x}b(X_{s},s)-\\nabla_{z}\\partial_{s}\\psi(0,s))(\\sigma^{-1})^{\\top}(s)\\mathrm{d}B_{s}}\\\\ &{\\qquad\\quad\\times\\exp\\big(-F(X)\\big)\\big|X_{0}=x\\big]}\\end{array}\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "Proof of Prop. 1. Given a family of functions $(M_{t})_{t\\in[0,T]}$ satisfying the conditions in Prop. 1, we can define a family $(\\psi_{t})_{t\\in[0,T]}$ of functions $\\psi_{t}:\\mathbb{R}^{d}\\times[t,T]\\rightarrow\\mathbb{R}^{d}$ as $\\psi_{t}(z,s)=M_{t}(s)^{\\top}z$ . Note that $\\psi_{t}(z,t)=z$ for all $z\\in\\mathbb{R}^{d}$ and $\\psi_{t}(0,s)=0$ for all $s\\in[t,T]$ , and that $\\nabla_{z}\\psi_{t}(z,s)=M_{t}(s)$ . Hence, $\\psi_{t}$ can be seen as a random process which is constant with respect to $\\omega\\in{\\Omega}$ , and which fulfills the conditions in Prop. 4 up to a trivial time change of variable from $[t,T]$ to $[0,T]$ . ", "page_idx": 23}, {"type": "text", "text": "We also define the family $(F_{t})_{t\\in[0,T]}$ of functionals $F_{t}\\ :\\ C([t,T];\\mathbb{R}^{d})\\ \\rightarrow\\ \\mathbb{R}$ as $\\mathbf{\\Psi}_{t}(X)\\mathbf{\\Psi}=\\mathbf{\\Psi}$ $\\begin{array}{r}{\\lambda^{-1}\\int_{t}^{T}f(X_{s},s)\\,\\mathrm{d}s+\\lambda^{-1}g(X_{T})}\\end{array}$ . We have that ", "page_idx": 23}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\nabla_{z}F_{t}(X+\\psi_{t}(z,\\cdot))}\\\\ &{=\\nabla_{z}\\big(\\lambda^{-1}\\int_{t}^{T}f(X_{s}+\\psi_{t}(z,s),s)\\,\\mathrm{d}s+\\lambda^{-1}g(X_{T}+\\psi_{t}(z,T))\\big)}\\\\ &{\\overset{(i)}{=}\\lambda^{-1}\\int_{t}^{T}\\nabla_{z}\\psi_{t}(z,s)\\nabla f(X_{s}+\\psi_{t}(z,s),s)\\,\\mathrm{d}s+\\lambda^{-1}\\nabla_{z}\\psi_{t}(z,T)\\nabla g(X_{T}+\\psi_{t}(z,T))}\\\\ &{=\\lambda^{-1}\\int_{t}^{T}M_{t}(s)\\nabla f(X_{s}+\\psi_{t}(z,s),s)\\,\\mathrm{d}s+\\lambda^{-1}M_{t}(T)\\nabla g(X_{T}+\\psi_{t}(z,T)),}\\end{array}\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "where equality (i) holds by the Leibniz rule. Using that $\\psi_{t}(0,s)=0$ , we obtain that: ", "page_idx": 23}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\nabla_{z}F_{t}(X+\\psi_{t}(z,\\cdot))\\big|_{z=0}=\\lambda^{-1}\\int_{t}^{T}\\nabla_{z}\\psi_{t}(0,s)\\nabla f(X_{s},s)\\,\\mathrm{d}s+\\lambda^{-1}\\nabla_{z}\\psi_{t}(T,0)\\nabla g(X_{T}),}\\end{array}\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "Up to a trivial time change of variable from $[t,T]$ to $[0,T]$ , Prop. 1 follows from plugging these choices into equation (49). ", "page_idx": 23}, {"type": "text", "text": "Remark 2. We can use matrices $M_{t}(s)$ that depend on the process $X$ up to time s, since the resulting processes $\\psi_{t}(\\cdot,z,\\cdot)$ are adapted to the filtration of the Brownian motion $B$ . More specifically, if we let $M_{t}:\\mathbb{R}^{d}\\times[t,T]\\rightarrow\\mathbb{R}^{d\\times d}$ be an arbitrary continuously differentiable function matrix-valued function such that $M_{t}(x,t)=\\mathrm{Id}$ for all $\\boldsymbol{x}\\in\\mathbb{R}^{d}$ , and we define the exponential moving average of $X$ as the process $X^{(\\upsilon)}$ given by ", "page_idx": 23}, {"type": "equation", "text": "$$\n\\begin{array}{r}{X_{t}^{(\\upsilon)}={\\upsilon}\\int_{0}^{t}e^{-{\\upsilon}\\left(t-s\\right)}X_{s}\\,\\mathrm{d}s,}\\end{array}\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "we have that ", "page_idx": 23}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\frac{\\mathrm{d}}{\\mathrm{s}}M_{t}(X_{s}^{(v)},s)\\!=\\!\\langle\\nabla M_{t}(X_{s}^{(v)},s),\\frac{\\,\\mathrm{d}X_{s}^{(v)}}{\\,\\mathrm{d}s}\\rangle\\!+\\!\\partial_{s}M_{t}(X_{s}^{(v)},s)\\!=\\!\\lambda\\langle\\nabla_{x}M_{t}(X_{s}^{(v)},s),X_{s}-X_{s}^{(v)}\\rangle\\!+\\!\\partial_{s}M_{t}(X_{s}^{(v)},s),}\\end{array}\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "and we can write ", "page_idx": 24}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\nabla_{x}\\mathbb{E}\\big[\\exp\\big(-\\lambda^{-1}\\int_{t}^{T}f(X_{s},s)\\,\\mathrm{d}s-\\lambda^{-1}g(X_{T})\\big)\\big|X_{t}=x\\big]}\\\\ &{=\\mathbb{E}\\big[\\big(-\\lambda^{-1}\\int_{t}^{T}M_{t}(X_{s}^{(v)},s)\\nabla_{x}f(X_{s},s)\\,\\mathrm{d}s-\\lambda^{-1}M_{t}(X_{T}^{(v)},T)\\nabla g(X_{T})}\\\\ &{\\qquad\\qquad+\\lambda^{-1/2}\\int_{t}^{T}(M_{t}(X_{s}^{(v)},s)\\nabla_{x}b(X_{s},s)-\\frac{\\mathrm{d}}{\\mathrm{d}s}M_{t}(X_{s}^{(v)},s))(\\sigma^{-1})^{\\top}(s)\\mathrm{d}B_{s}\\big)}\\\\ &{\\qquad\\qquad\\times\\exp\\big(-\\lambda^{-1}\\int_{t}^{T}f(X_{s},s)\\,\\mathrm{d}s-\\lambda^{-1}g(X_{T})\\big)\\big|X_{t}=x\\big].}\\end{array}\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "Plugging this into the proof of Thm. $^{\\,l}$ , we would obtain a variant of SOCM (Alg. 2) where the matrix-valued neural network $M_{\\omega}$ takes inputs $(t,s,x)$ instead of $(\\boldsymbol{t},\\boldsymbol{s})$ . Since the optimization class is larger, from the bias-variance in Prop. 2 we deduce that this variant would yield a lower variance of the vector field $w$ , and likely an algorithm with lower error. This is at the expense of an increased number of function evaluations (NFE) of $M_{\\omega}$ ; one would need $\\textstyle{\\frac{K(K+1)m}{2}}$ NFE per batch instead of only K(K2+1), which may be too expensive if the architecture of M\u03c9 is large. A way to speed up the computation per batch is to parameterize $M_{t}$ using cubic splines. ", "page_idx": 24}, {"type": "text", "text": "Proof of Prop. 4. Recall that ", "page_idx": 24}, {"type": "equation", "text": "$$\n\\mathrm{d}X_{s}=b(X_{s},s)\\,\\mathrm{d}s+\\sqrt{\\lambda}\\sigma(s)\\,\\mathrm{d}B_{s},\\qquad X_{0}\\sim p_{0},\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "is the SDE for the uncontrolled process. For arbitrary $\\boldsymbol{x},\\boldsymbol{z}\\in\\mathbb{R}^{d}$ , we consider the following SDEs conditioned on the initial points: ", "page_idx": 24}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathrm{d}X_{s}^{(x+z)}=b(X_{s}^{(x+z)},s)\\,\\mathrm{d}s+\\sqrt\\lambda\\sigma(s)\\,\\mathrm{d}B_{s},\\qquad X_{0}^{(x+z)}=x+z,}\\\\ &{\\quad\\,\\mathrm{d}X_{s}^{(x)}=b(X_{s}^{(x)},s)\\,\\mathrm{d}s+\\sqrt\\lambda\\sigma(s)\\,\\mathrm{d}B_{s},\\qquad X_{0}^{(x)}=x.}\\end{array}\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "Suppose that $\\psi:\\mathbb{R}^{d}\\times[0,T]\\rightarrow\\mathbb{R}^{d}$ satisfies the properties in the statement of Prop. 4. If $\\tilde{X}^{(x)}$ is a solution of ", "page_idx": 24}, {"type": "equation", "text": "$$\n\\mathrm{d}\\tilde{X}_{s}^{(x)}=\\left(b(\\tilde{X}_{s}^{(x)}+\\psi(z,s),s)-\\partial_{s}\\psi(z,s)\\right)\\mathrm{d}s+\\sqrt{\\lambda}\\sigma(s)\\,\\mathrm{d}B_{s},\\qquad\\tilde{X}_{0}^{(x)}=x,\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "then $X^{(x+z)}={\\tilde{X}}^{(x)}+\\psi(z,\\cdot)$ is a solution of (50). This is because $X_{0}^{(x+z)}=\\tilde{X}_{0}^{(x)}+\\psi(z,0)=$ $\\tilde{X}_{0}^{(x)}+z=x+z$ , and ", "page_idx": 24}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathrm{d}X_{s}^{(x+z)}=\\mathrm{d}\\tilde{X}_{s}^{(x)}+\\partial_{s}\\psi(z,s)\\,\\mathrm{d}s}\\\\ &{\\qquad\\qquad=(b(\\tilde{X}_{s}^{(x)}+\\psi(z,s),s)-\\partial_{s}\\psi(z,s))\\,\\mathrm{d}s+\\sqrt{\\lambda}\\sigma(s)\\,\\mathrm{d}B_{s}+\\partial_{s}\\psi(z,s)\\,\\mathrm{d}s}\\\\ &{\\qquad\\qquad=b(X_{s}^{(x+z)},s)\\,\\mathrm{d}s+\\sqrt{\\lambda}\\sigma(s)\\,\\mathrm{d}B_{s},}\\end{array}\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "Note that we may rewrite (51) as ", "page_idx": 24}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\lfloor X_{s}^{(x)}=(b(X_{s}^{(x)}+\\psi(z,s),s)-\\partial_{s}\\psi(z,s))\\,\\mathrm{d}s}\\\\ &{\\qquad\\qquad+\\,(b(X_{s}^{(x)},s)-b(X_{s}^{(x)}+\\psi(z,s),s)+\\partial_{s}\\psi(z,s))\\,\\mathrm{d}s+\\sqrt{\\lambda}\\sigma(s)\\,\\mathrm{d}B_{s},\\qquad X_{t}^{(x)}\\sim p_{0}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "Hence, since $\\psi(z,s)$ is a random process adapted to the filtration of $B$ , we can apply the Girsanov theorem for SDEs (Corollary 1) on $\\tilde{X}^{(x)}$ and $X^{(x)}$ , and we have that for any bounded continuous functional $\\Phi$ , ", "page_idx": 24}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{\\Sigma}[\\Phi(\\tilde{X}^{(x)})]}\\\\ &{=\\mathbb{E}\\big[\\Phi(X^{(x)})\\exp\\big(\\int_{0}^{T}\\lambda^{-1/2}\\sigma(s)^{-1}(b(X_{s}^{(x)}+\\psi(z,s),s)-b(X_{s}^{(x)},s)-\\partial_{s}\\psi(z,s))\\,\\mathrm{d}B_{s}}\\\\ &{\\qquad\\qquad\\qquad\\qquad-\\frac{1}{2}\\int_{0}^{T}\\|\\lambda^{-1/2}\\sigma(s)^{-1}(b(X_{s}^{(x)}+\\psi(z,s),s)-b(X_{s}^{(x)},s)-\\partial_{s}\\psi(z,s))\\|^{2}\\,\\mathrm{d}s\\big)\\big].}\\end{array}\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "We can write ", "page_idx": 25}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{\\ E}\\big[\\exp\\big(-F(X)\\big)\\big|X_{0}=x+z\\big]\\stackrel{()}{=}\\mathbb{E}\\big[\\exp\\big(-F(X^{(x+z)})\\big)\\big]\\stackrel{()}{=}\\mathbb{E}\\big[\\exp\\big(-F(\\tilde{X}^{(x)}+\\psi(z,\\cdot))\\big)\\big]}\\\\ &{\\stackrel{(\\mathrm{ii})}{=}\\mathbb{E}\\big[\\exp\\big(-F(X^{(x)}+\\psi(z,\\cdot))\\big)}\\\\ &{\\qquad\\times\\exp\\big(\\int_{0}^{T}\\lambda^{-1/2}\\sigma(s)^{-1}(b(X_{s}^{(x)}+\\psi(z,s),s)-b(X_{s}^{(x)},s)-\\partial_{s}\\psi(z,s)\\big)\\,\\mathrm{d}B_{s}}\\\\ &{\\qquad\\qquad\\qquad-\\frac{1}{2}\\int_{0}^{T}\\|\\lambda^{-1/2}\\sigma(s)^{-1}(b(X_{s}^{(x)}+\\psi(z,s),s)-b(X_{s}^{(x)},s)-\\partial_{s}\\psi(z,s))\\|^{2}\\,\\mathrm{d}s\\big)\\big]}\\\\ &{\\stackrel{(\\mathrm{ii})}{=}\\mathbb{E}\\big[\\exp\\big(-F(X+\\psi(z,\\cdot))+\\!\\int_{0}^{T}\\lambda^{-1/2}\\sigma(s)^{-1}(b(X_{s}+\\psi(z,s),s){-}b(X_{s},s){-}\\partial_{s}\\psi(z,s))\\,\\mathrm{d}B_{s}}\\\\ &{\\qquad\\qquad\\qquad-\\frac{1}{2}\\int_{0}^{T}\\|\\lambda^{-1/2}\\sigma(s)^{-1}(b(X_{s}+\\psi(z,s),s)-b(X_{s},s)-\\partial_{s}\\psi(z,s))\\|^{2}\\,\\mathrm{d}s)\\big|X_{0}=x\\big]}\\end{array}\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "Equality (i) holds by the definition of $X^{(x+z)}$ , equality (ii) holds by the fact $X_{s}^{(x+z)}=\\tilde{X}_{s}^{(x)}\\!+\\!\\psi(z,s)$ , equality (iii) holds by equation (52), and equality (iv) holds by the definition of $X_{s}^{(x)}$ . We conclude the proof by differentiating the right-hand side of (53) with respect to $z$ . Namely, ", "page_idx": 25}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\overline{{\\nabla}}_{x}\\mathbb{E}\\big[\\exp\\big(-F(X)\\big)\\big|X_{0}=x\\big]=\\nabla_{z}\\mathbb{E}\\big[\\exp\\big(-F(X)\\big)\\big|X_{0}=x+z\\big]\\big|_{z=0}}\\\\ &{\\overset{(i)}{=}\\mathbb{E}\\big[\\big(-\\nabla_{z}F(X+\\psi(z,\\cdot))+\\lambda^{-1/2}\\int_{0}^{T}(\\nabla_{z}\\psi(0,s)\\nabla_{x}b(X_{s},s)-\\nabla_{z}\\partial_{s}\\psi(0,s))(\\sigma^{-1})^{\\top}(s)\\mathrm{d}B_{s}\\big)}\\\\ &{\\qquad\\qquad\\times\\exp\\big(-F(X)\\big)\\big|X_{0}=x\\big]}\\end{array}\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "In equality (i) we used (53), and that: ", "page_idx": 25}, {"type": "text", "text": "\u2022 by the Leibniz rule, ", "page_idx": 25}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\nabla_{z}\\int_{0}^{T}\\|\\sigma(s)^{-1}(b(X_{s}+\\psi(z,s),s)-b(X_{s},s)-\\partial_{s}\\psi(z,s))\\|^{2}\\,\\mathrm{d}s\\big|_{z=0}}\\\\ &{=\\int_{0}^{T}\\nabla_{z}\\|\\sigma(s)^{-1}(b(X_{s}+\\psi(z,s),s)-b(X_{s},s)-\\partial_{s}\\psi(z,s))\\|^{2}\\big|_{z=0}\\,\\mathrm{d}s=0.}\\end{array}\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "\u2022 and by the Leibniz rule for stochastic integrals (see [42]), ", "page_idx": 25}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\nabla_{z}\\big(\\int_{0}^{T}\\sigma(s)^{-1}(b(X_{s}+\\psi(z,s),s)-b(X_{s},s)-\\partial_{s}\\psi(z,s))\\,\\mathrm{d}B_{s}\\big)\\big|_{z=0}}\\\\ &{\\quad=\\int_{0}^{T}(\\nabla_{z}\\psi(0,s)\\nabla_{x}b(X_{s},s)-\\nabla_{z}\\partial_{s}\\psi(0,s))(\\sigma^{-1})^{\\top}(s)\\,\\mathrm{d}B_{s}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "C.3 Informal derivation of the path-wise reparameterization trick ", "text_level": 1, "page_idx": 25}, {"type": "text", "text": "In this subsection, we provide an informal, intuitive derivation of the path-wise reparameterization trick as stated in Prop. 4. For simplicity, we particularize the functional $F$ to $F(X)\\ =$ $\\begin{array}{r}{\\lambda^{-1}\\int_{0}^{T}f(X_{s},s)\\,\\mathrm{d}s+\\lambda^{-1}g(X_{T})}\\end{array}$ . Consider the Euler-Maruyama discretization of the uncontrolled process $X$ defined in (6), with $K+1$ time steps (let $\\delta=T/K$ be the step size). This is a family of random variables $\\hat{X}=(\\hat{X}_{k})_{k=0:K}$ defined as ", "page_idx": 25}, {"type": "equation", "text": "$$\n\\hat{X}_{0}\\sim p_{0},\\qquad\\hat{X}_{k+1}=\\hat{X}_{k}+\\delta b(\\hat{X}_{k},k\\delta)+\\sqrt{\\delta\\lambda}\\sigma(k\\delta)\\varepsilon_{k},\\qquad\\varepsilon_{k}\\sim N(0,I).\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "Note that we can approximate ", "page_idx": 25}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{E}\\big[\\exp\\big(-\\lambda^{-1}\\int_{0}^{T}f(X_{s},s)\\,\\mathrm{d}s-\\lambda^{-1}g(X_{T})\\big)\\big|X_{0}=x\\big]}\\\\ &{~\\approx\\mathbb{E}\\big[\\exp\\big(-\\lambda^{-1}\\delta\\sum_{k=0}^{K-1}f(\\hat{X}_{k},s)-\\lambda^{-1}g(\\hat{X}_{K})\\big)\\big|\\hat{X}_{0}=x\\big],}\\end{array}\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "and that this is an equality in the limit $K\\,\\rightarrow\\,\\infty$ , as the interpolation of the Euler-Maruyama discretization $\\hat{X}^{(x)}$ converges to the process $X^{(x)}$ . Now, remark that for $k\\;\\in\\;\\{0,\\ldots,K-1\\}$ , $\\hat{X}_{k+1}|\\hat{X}_{k}\\sim N(\\hat{X}_{k}+\\delta b(\\hat{X}_{k},k\\delta),\\delta\\lambda(\\sigma\\sigma^{\\top})(k\\delta))$ . Hence, ", "page_idx": 25}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{E}\\big[\\exp\\big(-\\lambda^{-1}\\delta\\sum_{k=0}^{K-1}f(\\hat{X}_{k},s)-\\lambda^{-1}g(\\hat{X}_{K})\\big)\\big|\\hat{X}_{0}=x\\big]}\\\\ &{=C^{-1}\\int\\!\\!\\int_{(\\mathbb{R}^{d})^{K}}\\exp\\big(-\\lambda^{-1}\\delta\\sum_{k=0}^{K-1}f(\\hat{x}_{k},s)-\\lambda^{-1}g(\\hat{x}_{K})}\\\\ &{\\qquad\\qquad\\qquad\\quad-\\frac{1}{2\\delta\\lambda}\\sum_{k=1}^{K-1}\\|\\sigma^{-1}(k\\delta)(\\hat{x}_{k+1}\\!-\\!\\hat{x}_{k}\\!-\\!\\delta b(\\hat{x}_{k},k\\delta))\\|^{2}}\\\\ &{\\qquad\\qquad\\qquad\\quad-\\frac{1}{2\\delta\\lambda}\\|\\sigma^{-1}(0)(\\hat{x}_{1}\\!-\\!x\\!-\\!\\delta b(x,0))\\|^{2}\\big)\\,\\mathrm{d}\\hat{x}_{1}\\cdot\\cdot\\cdot\\mathrm{d}\\hat{x}_{K},}\\end{array}\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "where $\\begin{array}{r}{C=\\sqrt{(2\\pi\\delta\\lambda)^{K}\\prod_{k=0}^{K-1}\\operatorname*{det}((\\sigma\\sigma^{\\top})(k\\delta))}}\\end{array}$ . Now, let $\\psi:\\mathbb{R}^{d}\\times[0,T]\\rightarrow\\mathbb{R}^{d}$ be an arbitrary twice differentiable function such that $\\psi(z,0)=z$ for all $z\\in\\mathbb{R}^{d}$ , and $\\psi(0,s)=0$ for all $s\\in[0,T]$ . We can write ", "page_idx": 26}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathcal{T}_{x}\\mathbb{E}\\big[\\exp\\big(-\\lambda^{-1}\\delta\\sum_{k=0}^{K-1}f(\\hat{X}_{k},s)-\\lambda^{-1}g(\\hat{X}_{K})\\big)|\\hat{X}_{0}=x\\big]}\\\\ &{=\\nabla_{z}\\mathbb{E}\\big[\\exp\\big(-\\lambda^{-1}\\delta\\sum_{k=0}^{K-1}f(\\hat{X}_{k},s)-\\lambda^{-1}g(\\hat{X}_{K})\\big)|\\hat{X}_{0}=x+z\\big]|_{z=0}}\\\\ &{=C^{-1}\\nabla_{z}\\big(\\int_{(\\mathbb{R}^{d})^{k}}\\exp\\big(-\\lambda^{-1}\\delta\\sum_{k=0}^{K-1}f(\\hat{x}_{k},s)-\\lambda^{-1}g(\\hat{x}_{K})\\big)}\\\\ &{\\qquad\\qquad\\qquad\\qquad-\\frac{1}{2\\delta\\lambda}\\sum_{k=1}^{K-1}\\|\\sigma^{-1}(k\\delta)\\big(\\hat{x}_{k+1}-\\hat{x}_{k}-\\delta b(\\hat{x}_{k},k\\delta)\\big)\\|^{2}}\\\\ &{\\qquad\\qquad\\qquad\\qquad-\\frac{1}{2\\delta\\lambda}\\|\\sigma^{-1}(0)(\\hat{x}_{1}-(x+z)-\\delta b(x+z,0))\\|^{2}\\big)\\,\\mathrm{d}\\hat{x}_{1}\\cdots\\hat{\\mathbf{d}}\\hat{x}_{K}\\big)|_{z=0}}\\\\ &{=C^{-1}\\nabla_{z}\\big(\\int_{(\\mathbb{R}^{d})^{k}}\\exp\\big(-\\lambda^{-1}\\delta\\sum_{k=0}^{K-1}f(\\hat{x}_{k}+\\psi(z,k\\delta),s)-\\lambda^{-1}g(\\hat{x}_{K}+\\psi(z,K\\delta))}\\\\ &{\\qquad\\qquad\\qquad-\\frac{1}{2\\delta\\lambda}\\sum_{k=1}^{K-1}\\|\\sigma^{-1}(k\\delta)(\\hat{x}_{k+1}+\\psi(z,(k+1)\\delta)-\\hat{x}_{k}-\\psi(z,k\\delta)-\\delta b(\\hat{x}_{k}+\\psi(z,k\\delta),k\\delta)\\big)\\|}\\\\ &{\\qquad\\qquad\\qquad\\qquad-\\frac{1}{2\\delta\\lambda}\\|\\sigma^{-1}(0)(\\hat{x}_{1}+\\psi(z,\\delta)-(x+\\psi(z,0))-\\delta b(x+\\psi(z,0),0))\\|^ \n$$", "text_format": "latex", "page_idx": 26}, {"type": "text", "text": "In the last equality, we used that for $k\\in\\{1,\\ldots,K\\}$ , the variables $\\hat{x}_{k}$ are integrated over $\\mathbb{R}^{d}$ , which means that adding an offset $\\psi(z,k\\delta)$ does not change the value of the integral. We also used that $\\psi(z,0)=z$ . Now, for fixed values of $\\hat{\\boldsymbol x}=\\left(\\hat{x}_{1},\\ldots,\\hat{x}_{K}\\right)$ , and letting $\\hat{x}_{0}=x$ , we define ", "page_idx": 26}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\bar{\\tau}_{\\hat{x}}(z)=\\lambda^{-1}\\delta\\sum_{k=0}^{K-1}f(\\hat{x}_{k}+\\psi(z,k\\delta),s)+\\lambda^{-1}g(\\hat{x}_{K}+\\psi(z,K\\delta))}\\\\ &{\\qquad\\qquad+\\frac{1}{2\\delta\\lambda}\\sum_{k=0}^{K-1}\\|\\sigma^{-1}(k\\delta)(\\hat{x}_{k+1}+\\psi(z,(k+1)\\delta)\\!-\\!\\hat{x}_{k}\\!-\\!\\psi(z,k\\delta)\\!-\\!\\delta b(\\hat{x}_{k}\\!+\\!\\psi(z,k\\delta),k\\delta))\\|^{2}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 26}, {"type": "text", "text": "Using that $\\psi(0,s)=0$ for all $s\\in[0,T]$ , we have that: ", "page_idx": 26}, {"type": "equation", "text": "$$\n\\begin{array}{r}{G_{\\hat{x}}(0)=\\lambda^{-1}\\delta\\sum_{k=0}^{K-1}f(\\hat{x}_{k},s)+\\lambda^{-1}g(\\hat{x}_{K})+\\frac{1}{2\\delta\\lambda}\\sum_{k=0}^{K-1}\\|\\sigma^{-1}(k\\delta)(\\hat{x}_{k+1}-\\hat{x}_{k}-\\delta b(\\hat{x}_{k},k\\delta))\\|^{2}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 26}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\nabla G_{\\hat{x}}(z)|_{z=0}=\\lambda^{-1}\\delta\\sum_{k=0}^{K-1}\\nabla\\psi(0,k\\delta)\\nabla f(\\hat{x}_{k},s)+\\lambda^{-1}\\nabla\\psi(0,K\\delta)\\nabla g(\\hat{x}_{K})}\\\\ &{\\qquad\\qquad\\qquad+\\frac{1}{\\delta\\lambda}\\sum_{k=0}^{K-1}(\\nabla_{z}\\psi(0,(k+1)\\delta)-\\nabla_{z}\\psi(0,k\\delta)-\\delta\\nabla\\psi(0,k\\delta)\\nabla b(\\hat{x}_{k},k\\delta))}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\times\\big((\\sigma^{-1})^{\\top}\\sigma^{-1}\\big)(k\\delta)(\\hat{x}_{k+1}-\\hat{x}_{k}-\\delta b(\\hat{x}_{k},k\\delta))}\\end{array}\n$$", "text_format": "latex", "page_idx": 26}, {"type": "text", "text": "And we can express the right-hand side of (54) in terms of $G_{\\hat{x}}(0)$ and $\\nabla G_{\\hat{x}}(z)|_{z=0}$ : ", "page_idx": 26}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\nabla_{z}\\big(C^{-1}\\iint_{(\\mathbb{R}^{d})^{K}}\\exp\\big(-G_{\\hat{x}}(z)\\big)\\,\\mathrm{d}y_{1}\\cdot\\cdot\\cdot\\mathrm{d}y_{K}\\big)}\\\\ &{\\quad=-C^{-1}\\int_{(\\mathbb{R}^{d})^{K}}\\nabla G_{\\hat{x}}(z)|_{z=0}\\exp\\big(-G_{\\hat{x}}(0)\\big)\\,\\mathrm{d}y_{1}\\cdot\\cdot\\cdot\\mathrm{d}y_{K}}\\end{array}\n$$", "text_format": "latex", "page_idx": 26}, {"type": "text", "text": "We define $\\begin{array}{r}{\\epsilon_{k}=\\frac{1}{\\sqrt{\\delta\\lambda}}\\sigma^{-1}(k\\delta)(\\hat{x}_{k+1}\\!-\\!\\hat{x}_{k}\\!-\\!\\delta b(\\hat{x}_{k},k\\delta))}\\end{array}$ , and then, we are able to write ", "page_idx": 26}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\quad\\quad\\hat{x}_{k+1}=\\hat{x}_{k}+\\delta b(\\hat{x}_{k},k\\delta)+\\sqrt{\\delta\\lambda}\\sigma(k\\delta)\\epsilon_{k},\\qquad\\hat{x}_{0}=x}\\\\ &{\\quad\\quad G_{\\hat{x}}(0)=\\lambda^{-1}\\delta\\sum_{k=0}^{K-1}f(\\hat{x}_{k},s)+\\lambda^{-1}g(\\hat{x}_{K})+\\frac12\\sum_{k=0}^{K-1}\\|\\epsilon_{k}\\|^{2},}\\\\ &{\\quad G_{\\hat{x}}(z)|_{z=0}=\\lambda^{-1}\\delta\\sum_{k=0}^{K-1}\\nabla\\psi(0,k\\delta)\\nabla f(\\hat{x}_{k},s)+\\lambda^{-1}\\nabla\\psi(0,K\\delta)\\nabla g(\\hat{x}_{K})}\\\\ &{\\quad\\quad\\quad\\quad\\quad+\\sqrt{\\delta\\lambda^{-1}}\\sum_{k=0}^{K-1}(\\partial_{s}\\nabla_{z}\\psi(0,k\\delta)+O(\\delta)-\\nabla\\psi(0,k\\delta)\\nabla b(\\hat{x}_{k},k\\delta))(\\sigma^{-1})^{\\top}(k\\delta)\\epsilon_{k}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 26}, {"type": "text", "text": "Then, taking the limit $K\\rightarrow\\infty$ (i.e. $\\delta\\:\\rightarrow\\:0$ ), we recognize (55) as Euler-Maruyama discretization of the uncontrolled process $X$ in equation (6) conditioned on $X_{0}~=~x$ , and the last term in (56) as the Euler-Maruyama discretization of the stochastic integral $\\begin{array}{r l}{\\lambda^{-1/2}\\int_{0}^{T}(\\partial_{s}\\nabla_{z}\\psi(0,s)\\,-}&{{}}\\end{array}$ $\\nabla\\psi(0,s)\\nabla b(X_{s}^{(x)},s))(\\sigma^{-1})^{\\top}(s)\\,\\mathrm{d}B_{s}$ . Thus, ", "page_idx": 26}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\operatorname*{lim}_{K\\to\\infty}\\nabla_{x}\\mathbb{E}\\big[\\exp\\big(-\\lambda^{-1}\\delta\\sum_{k=0}^{K-1}f(\\hat{X}_{k},s)-\\lambda^{-1}g(\\hat{X}_{K})\\big)\\big]}\\\\ &{=\\mathbb{E}\\big[\\big(-\\lambda^{-1}\\int_{0}^{T}\\nabla\\psi(0,s)\\nabla_{x}f(X_{s},s)\\,\\mathrm{d}s-\\lambda^{-1}\\nabla\\psi(0,T)\\nabla g(X_{T})}\\\\ &{\\qquad\\qquad+\\lambda^{-1/2}\\int_{0}^{T}(\\nabla\\psi(0,s)\\nabla_{x}b(X_{s},s)-\\partial_{s}\\nabla\\psi(0,s))(\\sigma^{-1})^{\\top}(s)\\,\\mathrm{d}B_{s}\\big)}\\\\ &{\\qquad\\quad\\times\\exp\\big(-\\lambda^{-1}\\int_{0}^{T}f(X_{s},s)\\,\\mathrm{d}s-\\lambda^{-1}g(X_{T})\\big)\\big|X_{0}=x\\big],}\\end{array}\n$$", "text_format": "latex", "page_idx": 26}, {"type": "text", "text": "which concludes the derivation. ", "page_idx": 26}, {"type": "text", "text": "C.4 SOCM-Adjoint: replacing the path-wise reparameterization trick with the adjoint method ", "text_level": 1, "page_idx": 27}, {"type": "text", "text": "Proposition 5. Let $\\mathcal{L}_{\\mathrm{SOCM-Adj}}:L^{2}(\\mathbb{R}^{d}\\times[0,T];\\mathbb{R}^{d})\\to\\mathbb{R}$ be the loss function defined as ", "page_idx": 27}, {"type": "text", "text": "where $X^{v}$ is the process controlled by $v$ (i.e., $d X_{t}=\\left(b(X_{t},t)+\\sigma(t)v(X_{t},t)\\right){\\mathrm{d}}t+{\\sqrt{\\lambda}}\\sigma(X_{t},t)\\,\\mathrm{d}B_{t}$ and $X_{0}\\sim p_{0},$ ), $\\alpha(v,X^{v},B)$ is the importance weight defined in (20), and $a(t,X^{v})$ is the solution of the ODE ", "page_idx": 27}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\frac{d a(t)}{d t}=-\\nabla_{x}b(X_{t}^{v},t)a(t)-\\nabla_{x}f(X_{t}^{v},t),}\\\\ &{a(T)=\\nabla g(X_{T}^{v}),}\\end{array}\n$$", "text_format": "latex", "page_idx": 27}, {"type": "text", "text": "$\\mathcal{L}_{\\mathrm{SOCM-Adj}}$ has a unique optimum, which is the optimal control $u^{*}$ . ", "page_idx": 27}, {"type": "text", "text": "Proof. The proof follows the same structure as that of Thm. 1. Instead of plugging the path-wise reparameterization trick (Prop. 1) in the right-hand side of (22), we make use of Lemma 6 to evaluate $\\begin{array}{r}{\\dot{\\nabla_{x}}\\mathbb{E}\\big[\\exp\\big(-\\lambda^{-1}\\int_{0}^{T}f(X_{t},t)\\,d t-\\lambda^{-1}\\dot{g}(X_{T})\\big)\\vert X_{0}=x\\big].}\\end{array}$ . Particular cases of the result in Lemma 6 have been used in previous works such as [54, 51]. We present a more general form that covers state costs $f$ , as well as stochastic integrals. We also present a simpler proof of the result based on Lagrange multipliers. \u53e3 ", "page_idx": 27}, {"type": "text", "text": "Lemma 6 (Adjoint method for SDEs). [54, 51] Let $X:\\Omega\\times[0,T]\\rightarrow\\ensuremath{\\mathbb{R}}^{d}$ be the uncontrolled process defined in (6), with initial condition $X_{0}=x$ . We define the random process $a:\\Omega\\times[0,T]\\rightarrow\\mathbb{R}^{d}$ such that for all $\\omega\\in\\Omega$ , using the short-hand $a(t):=a(\\omega,t)$ , ", "page_idx": 27}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathrm{d}a_{t}(\\omega)=\\big(-\\nabla_{x}b(X_{t}(\\omega),t)a_{t}(\\omega)-\\nabla_{x}f(X_{t}(\\omega),t)\\big)\\,\\mathrm{d}t-\\nabla_{x}h(X_{t}(\\omega),t)\\,\\mathrm{d}B_{t},}\\\\ &{\\mathrm{~}a_{T}(\\omega)=\\nabla_{x}g(X_{T}(\\omega)),}\\end{array}\n$$", "text_format": "latex", "page_idx": 27}, {"type": "text", "text": "we have that ", "page_idx": 27}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\nabla_{x}\\mathbb{E}\\big[\\int_{0}^{T}f(X_{t}(\\omega),t)\\,\\mathrm{d}t+\\int_{0}^{T}\\langle h(X_{t}(\\omega),t),\\,\\mathrm{d}B_{t}\\rangle+g(X_{T}(\\omega))|X_{0}(\\omega)=x\\big]=\\mathbb{E}\\big[a_{0}(\\omega)\\big],}\\\\ &{\\nabla_{x}\\mathbb{E}\\big[\\exp\\big(-\\int_{0}^{T}f(X_{t}(\\omega),t)\\,\\mathrm{d}t-\\int_{0}^{T}\\langle h(X_{t}(\\omega),t),\\,\\mathrm{d}B_{t}\\rangle-g(X_{T}(\\omega))\\big)|X_{0}(\\omega)=x\\big]}\\\\ &{=-\\mathbb{E}\\big[a_{0}(\\omega)\\exp\\big(-\\int_{0}^{T}f(X_{t}(\\omega),t)\\,\\mathrm{d}t-\\int_{0}^{T}\\langle h(X_{t}(\\omega),t),\\,\\mathrm{d}B_{t}\\rangle-g(X_{T}(\\omega))\\big)|X_{0}(\\omega)=x\\big].}\\end{array}\n$$", "text_format": "latex", "page_idx": 27}, {"type": "text", "text": "Proof. We will use an approach based on Lagrange multipliers. Define a process $a:\\Omega\\times[0,T]\\rightarrow\\mathbb{R}^{d}$ such that for any $\\omega\\in{\\Omega}$ , $a(\\omega,\\cdot)$ is differentiable. For a given $\\omega\\in\\Omega$ , we can write ", "page_idx": 27}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\int_{0}^{T}f(X_{t}(\\omega),t)\\,\\mathrm{d}t+\\int_{0}^{T}\\langle h(X_{t}(\\omega),t),\\,\\mathrm{d}B_{t}\\rangle+g(X_{T}(\\omega))}\\\\ &{=\\int_{0}^{T}f(X_{t}(\\omega),t)\\,\\mathrm{d}t+\\int_{0}^{T}\\langle h(X_{t}(\\omega),t),\\,\\mathrm{d}B_{t}\\rangle+g(X_{T}(\\omega))}\\\\ &{\\qquad-\\int_{0}^{T}\\langle a_{t}(\\omega),(d X_{t}(\\omega)-b(X_{t}(\\omega),t)\\,\\mathrm{d}t-\\sigma(t)\\,\\mathrm{d}B_{t})\\rangle.}\\end{array}\n$$", "text_format": "latex", "page_idx": 27}, {"type": "text", "text": "By Lemma 7, we have that ", "page_idx": 27}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\int_{0}^{T}\\langle a_{t}(\\omega),d X_{t}(\\omega)\\rangle=\\langle a_{T}(\\omega),X_{T}(\\omega)\\rangle-\\langle a_{0}(\\omega),X_{0}(\\omega)\\rangle-\\int_{0}^{T}\\langle X_{t}(\\omega),\\frac{d a_{t}}{d t}(\\omega)\\rangle\\,\\mathrm{d}t.}\\end{array}\n$$", "text_format": "latex", "page_idx": 27}, {"type": "text", "text": "Hence, ", "page_idx": 27}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\nabla_{x}\\left(\\int_{0}^{T}f(X_{t}(\\omega),t)\\,\\mathrm{d}t+\\int_{0}^{T}\\langle h(X_{t}(\\omega),t),\\,\\mathrm{d}B_{t}\\rangle+g(X_{T}(\\omega))\\right)}\\\\ &{=\\nabla_{x}\\left(\\int_{0}^{T}f(X_{t}(\\omega),t)\\,\\mathrm{d}t+\\int_{0}^{T}\\langle h(X_{t}(\\omega),t),\\,\\mathrm{d}B_{t}\\rangle+g(X_{T}(\\omega))\\right.}\\\\ &{\\qquad\\left.-\\left.\\langle a_{T}(\\omega),X_{T}(\\omega)\\rangle+\\langle a_{0}(\\omega),X_{0}(\\omega)\\rangle+\\int_{0}^{T}\\left(\\langle a_{t}(\\omega),b(X_{t}(\\omega),t)\\rangle+\\langle\\frac{d a_{t}}{d t}(\\omega),X_{t}(\\omega)\\rangle\\right)\\,\\mathrm{d}t}\\\\ &{\\qquad+\\int_{0}^{T}\\langle a_{t}(\\omega),\\sigma(t)\\,\\mathrm{d}B_{t}\\rangle\\right)}\\\\ &{=\\int_{0}^{T}\\nabla_{x}X_{t}(\\omega)\\nabla_{x}f(X_{t}(\\omega),t)\\,\\mathrm{d}t+\\int_{0}^{T}\\nabla_{x}X_{t}(\\omega)\\nabla_{x}h(X_{t}(\\omega),t)\\,\\mathrm{d}B_{t}+\\nabla_{x}X_{T}(\\omega)\\nabla_{x}g(X_{T}(\\omega))}\\\\ &{\\qquad-\\nabla_{x}X_{T}(\\omega)\\alpha_{T}(\\omega)\\nabla_{x}(\\omega)+\\nabla_{x}X_{0}(\\omega)\\alpha_{0}(\\omega)}\\\\ &{\\qquad+\\int_{0}^{T}\\left(\\nabla_{x}X_{t}(\\omega)\\nabla_{x}b(X_{t}(\\omega),t)\\alpha_{t}(\\omega)+\\nabla_{x}X_{t}(\\omega)\\frac{d a_{t}}{d t}(\\omega)\\right)\\,\\mathrm{d}t}\\\\ &{=\\int_{0}^{T}\\nabla_{x}X_{t}(\\omega)\\big(\\nabla_{x}f(X_{t}(\\omega),t)+\\nabla_{x}b(X_{t}(\\omega),t)\\alpha_{t}(\\omega)+\\frac{d}{d t}\\frac{d}{d t}(\\omega)\\big)\\,\\mathrm{d}t}\\\\ &{\\qquad+\\nabla_{x}X_{T}(\\omega)\\big(\\nabla_{x}g(X_{T}(\\omega))-a_{T}(\\omega)\\big)+a_{0}(\n$$", "text_format": "latex", "page_idx": 27}, {"type": "text", "text": "In the last line we used that $\\nabla_{x}X_{0}(\\omega)=\\nabla_{x}x=\\operatorname{I}.$ . If choose $a$ such that ", "page_idx": 28}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{d a_{t}(\\omega)=\\big(-\\nabla_{x}b(X_{t}(\\omega),t)a_{t}(\\omega)-\\nabla_{x}f(X_{t}(\\omega),t)\\big)\\,\\mathrm{d}t-\\nabla_{x}h(X_{t}(\\omega),t)\\,\\mathrm{d}B_{t},}\\\\ &{\\mathfrak{a}_{T}(\\omega)=\\nabla_{x}g(X_{T}(\\omega)),}\\end{array}\n$$", "text_format": "latex", "page_idx": 28}, {"type": "text", "text": "then we obtain that ", "page_idx": 28}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\nabla_{x}\\big(\\int_{0}^{T}f(X_{t}(\\omega),t)\\,\\mathrm{d}t+\\int_{0}^{T}\\langle h(X_{t}(\\omega),t),\\,\\mathrm{d}B_{t}\\rangle+g(X_{T}(\\omega))\\big)=a_{0}(\\omega),}\\end{array}\n$$", "text_format": "latex", "page_idx": 28}, {"type": "text", "text": "and by the Leibniz rule, ", "page_idx": 28}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\nabla_{x}\\mathbb{E}\\big[\\int_{0}^{T}f(X_{t}(\\omega),t)\\,\\mathrm{d}t+\\int_{0}^{T}\\langle h(X_{t}(\\omega),t),\\,\\mathrm{d}B_{t}\\rangle+g(X_{T}(\\omega))\\big]}\\\\ &{=\\mathbb{E}\\big[\\nabla_{x}\\big(\\int_{0}^{T}f(X_{t}(\\omega),t)\\,\\mathrm{d}t+\\int_{0}^{T}\\langle h(X_{t}(\\omega),t),\\,\\mathrm{d}B_{t}\\rangle+g(X_{T}(\\omega))\\big)\\big]=\\mathbb{E}\\big[a_{0}(\\omega)\\big],}\\end{array}\n$$", "text_format": "latex", "page_idx": 28}, {"type": "text", "text": "and ", "page_idx": 28}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\nabla_{x}\\mathbb{E}\\big[\\exp\\big(-\\int_{0}^{T}f(X_{t}(\\omega),t)\\,\\mathrm{d}t-\\int_{0}^{T}\\langle h(X_{t}(\\omega),t),\\,\\mathrm{d}B_{t}\\rangle-g(X_{T}(\\omega))\\big)\\big]}\\\\ &{=-\\mathbb{E}\\big[\\nabla_{x}\\big(\\int_{0}^{T}f(X_{t}(\\omega),t)\\,\\mathrm{d}t+\\int_{0}^{T}\\langle h(X_{t}(\\omega),t),\\,\\mathrm{d}B_{t}\\rangle+g(X_{T}(\\omega))\\big)}\\\\ &{\\qquad\\qquad\\times\\,\\exp\\big(-\\int_{0}^{T}f(X_{t}(\\omega),t)\\,\\mathrm{d}t-\\int_{0}^{T}\\langle h(X_{t}(\\omega),t),\\,\\mathrm{d}B_{t}\\rangle-g(X_{T}(\\omega))\\big)\\big]}\\\\ &{=-\\mathbb{E}\\big[a_{0}(\\omega)\\exp\\big(-\\int_{0}^{T}f(X_{t}(\\omega),t)\\,\\mathrm{d}t-\\int_{0}^{T}\\langle h(X_{t}(\\omega),t),\\,\\mathrm{d}B_{t}\\rangle-g(X_{T}(\\omega))\\big)\\big].}\\end{array}\n$$", "text_format": "latex", "page_idx": 28}, {"type": "text", "text": "Lemma 7 (Stochastic integration by parts, [60]). Let ", "page_idx": 28}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathrm{d}X_{t}=a_{t}\\,\\mathrm{d}t+b_{t}\\,\\mathrm{d}W_{t}^{1},}\\\\ {\\mathrm{d}Y_{t}=f_{t}\\,\\mathrm{d}t+g_{t}\\,\\mathrm{d}W_{t}^{2}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 28}, {"type": "text", "text": "where $a_{t},\\,b_{t},\\,f_{t},\\,g_{t}$ are continuous square integrable processes adapted to a filtration $({\\mathcal{F}}_{t})_{t\\in[0,T]}$ , and $W^{1}$ , $W^{2}$ are Brownian motions adapted to the same filtration. Then, ", "page_idx": 28}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{X_{t}Y_{t}-X_{0}Y_{0}=\\int_{0}^{t}X_{s}\\,\\mathrm{d}Y_{s}+\\int_{0}^{t}Y_{s}\\,\\mathrm{d}X_{s}+\\int_{0}^{t}\\langle\\mathrm{d}X_{s},\\mathrm{d}Y_{s}\\rangle}\\\\ &{\\qquad\\qquad\\qquad=\\int_{0}^{t}X_{s}\\,\\mathrm{d}Y_{s}+\\int_{0}^{t}Y_{s}\\,\\mathrm{d}X_{s}+\\int_{0}^{t}\\langle b_{s}\\,\\mathrm{d}W_{s}^{1},g_{s}\\,\\mathrm{d}W_{s}^{2}\\rangle.}\\end{array}\n$$", "text_format": "latex", "page_idx": 28}, {"type": "text", "text": "Remark 3 (Related work to the path-wise reparameterization trick: sensitivity analysis). As shown above, the adjoint method for SDEs is an alternative to the path-wise reparameterization trick. Prior to $I54J,$ an array of works developed methods to compute derivatives of functionals of stochastic processes with respect to generic parameters $\\alpha$ that appear either in the drift or diffusion coefficients $[52]$ . This area is known as sensitivity analysis, and has been developed largely with financial applications in mind (more specifically, to compute the \"Greeks\"). In low dimensions, dynamic programming $[3J$ or finite differences [26, 53] work well, but they scale poorly to high dimensions. In high dimensions, several approaches have been proposed (see the section 1 of [29] for a comprehensive although dated overview): ", "page_idx": 28}, {"type": "text", "text": "\u2022 The path-wise method (which we refer to as adjoint method) involves taking the gradient $\\nabla_{\\alpha}\\Bar{\\mathbb{E}}[f(X_{t})]$ inside of the expectation as $\\mathbb{E}[\\nabla_{\\alpha}f(\\dot{X}_{t})]$ and was first described by $I82J$ . \u2022 The likelihood method or score method [27, 69] consists in rewriting $\\nabla_{\\alpha}\\mathbb{E}[f(X_{T})]$ as $\\mathbb{E}[f(X_{T})H]$ , where $H$ is a random variable which is equal to $\\nabla_{\\alpha}\\log p(\\alpha,X_{T}),$ , $p(\\alpha,\\cdot)$ being the density of the law of $X_{T}$ with respect to the Lebesgue measure. $I82J$ provide explicit weights $H$ , under the restrictions that \u03b1 appears only in the drift of the SDE (and not in the diffusion coefficient) and that the diffusion coefficient is elliptic, using the Girsanov theorem. $I29J$ provide an expression for $H$ in the case where $H$ also appears in the diffusion coefficient, using Malliavin calculus. ", "page_idx": 28}, {"type": "text", "text": "The estimator of the path-wise reparameterization trick is formally similar to the likelihood method estimator, but it is different in that $\\alpha$ is the initial condition of the process, and does not appear either in the drift nor the diffusion coefficient. ", "page_idx": 28}, {"type": "text", "text": "C.5 Proof of Lemma 1 ", "text_level": 1, "page_idx": 29}, {"type": "text", "text": "Proof. Since the equality (28) holds almost surely for the pair $(X,B)$ , it must also hold almost surely for $(X^{v},B^{v})$ , which satisfy the same SDE. That is ", "page_idx": 29}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathcal{W}(X^{v},0)=V(X_{0}^{v},0)+\\frac{1}{2}\\int_{0}^{T}\\|u^{*}(X_{s}^{v},s)\\|^{2}\\,\\mathrm{d}s-\\sqrt{\\lambda}\\int_{0}^{T}\\langle u^{*}(X_{s}^{v},s),\\mathrm{d}B_{s}^{v}\\rangle,}\\end{array}\n$$", "text_format": "latex", "page_idx": 29}, {"type": "text", "text": "Thus, we obtain that ", "page_idx": 29}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\alpha(v,X^{v},B)=\\exp\\big(-\\lambda^{-1}\\mathcal{W}(X^{v},0)-\\lambda^{-1/2}\\int_{0}^{T}\\langle v(X_{t}^{v},t),\\mathrm{d}B_{t}^{v}\\rangle+\\frac{\\lambda^{-1}}{2}\\int_{0}^{T}\\|v(X_{t}^{v},t)\\|^{2}\\,\\mathrm{d}t\\big)}\\\\ &{\\qquad\\qquad\\quad=\\exp\\big(-\\lambda^{-1}V(X_{0}^{v},0)-\\frac{\\lambda^{-1}}{2}\\int_{0}^{T}\\|u^{*}(X_{s}^{v},s)\\|^{2}\\,\\mathrm{d}s+\\lambda^{-1/2}\\int_{0}^{T}\\langle u^{*}(X_{s}^{v},s),\\mathrm{d}B_{s}^{v}\\rangle}\\end{array}\n$$", "text_format": "latex", "page_idx": 29}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{-\\,\\lambda^{-1/2}\\int_{0}^{T}\\langle v(X_{t}^{v},t),\\mathrm{d}B_{t}^{v}\\rangle+\\frac{\\lambda^{-1}}{2}\\int_{0}^{T}\\|v(X_{t}^{v},t)\\|^{2}\\,\\mathrm{d}t\\big),}\\end{array}\n$$", "text_format": "latex", "page_idx": 29}, {"type": "text", "text": "and this is equal to $\\exp\\big(-V(X_{0}^{v},0)\\big)$ when $v=u^{*}$ . Since we condition on $X_{0}^{v}=x_{\\mathrm{init}}$ , we have obtained that the random variable takes constant value $\\exp\\big(-V(x_{\\mathrm{init}},0)\\big)$ almost surely, which means that its variance is zero. \u53e3 ", "page_idx": 29}, {"type": "text", "text": "D Optimal reparameterization matrices ", "text_level": 1, "page_idx": 29}, {"type": "text", "text": "Theorem 4 (Optimal reparameterization matrices). Let v be an arbitrary control in U. Define the integral operator $\\mathcal{T}_{t}:L^{\\dot{2}}([t,T];\\mathbb{R}^{d\\times d})\\to L^{2}([t,T];\\mathbb{R}^{d\\times d})$ as ", "page_idx": 29}, {"type": "equation", "text": "$$\n\\begin{array}{r}{[\\mathcal{T}_{t}(\\dot{M}_{t})](s)=\\int_{t}^{T}\\dot{M}_{t}(s^{\\prime})\\mathbb{E}\\big[\\chi(s^{\\prime},X^{v},B)\\chi(s,X^{v},B)^{\\top}\\times\\alpha(v,X^{v},B)\\big]\\,\\mathrm{d}s^{\\prime},}\\end{array}\n$$", "text_format": "latex", "page_idx": 29}, {"type": "text", "text": "where ", "page_idx": 29}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\langle(t,X^{v},B):=\\int_{t}^{T}\\nabla_{x}f(X_{s}^{v},s)\\,\\mathrm{d}s+\\nabla g(X_{T}^{v})+(\\sigma_{t}^{-1})^{\\top}(t)v(X_{t}^{v},t)}\\\\ &{\\qquad\\qquad\\qquad-\\int_{t}^{T}\\nabla_{x}b(X_{s}^{v},s)(\\sigma_{s}^{-1})^{\\top}(s)v(X_{t}^{v},t)\\,\\mathrm{d}s-\\int_{t}^{T}\\nabla_{x}b(X_{s}^{v},s)(\\sigma_{s}^{-1})^{\\top}(s)\\,\\mathrm{d}B_{s}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 29}, {"type": "text", "text": "If we define $\\begin{array}{r}{N_{t}(s)\\,=\\,-\\mathbb{E}\\bigl[\\bigl(\\nabla g(X_{T}^{v})+\\int_{t}^{T}\\nabla_{x}f(X_{s^{\\prime}}^{v},s^{\\prime})\\,\\mathrm{d}s^{\\prime}\\bigr)\\chi(t,X^{v},B)^{\\top}\\,\\times\\,\\alpha(v,X^{v},B)\\bigr]}\\end{array}$ , the optimal $M^{*}=(M_{t}^{*})_{t\\in[0,T]}$ is of the form $\\begin{array}{r}{M_{t}^{*}(s)=I+\\int_{t}^{s}\\dot{M}_{t}^{*}(s^{\\prime})\\,\\mathrm{d}s^{\\prime}}\\end{array}$ , where $\\dot{M}_{t}^{*}$ is the unique solution of the following Fredholm equation of the first kind: ", "page_idx": 29}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathcal{T}_{t}(\\dot{M}_{t})=N_{t}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 29}, {"type": "text", "text": "The proof of (25) shows that minimizing $\\mathrm{Var}(w;M)$ is equivalent to minimizing ", "page_idx": 29}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathbb{E}\\big[\\frac{1}{T}\\int_{0}^{T}\\big\\|w(t,v,X^{v},B,M_{t})\\big\\|^{2}\\,\\mathrm{d}t\\,\\alpha(v,X^{v},B)\\big].}\\end{array}\n$$", "text_format": "latex", "page_idx": 29}, {"type": "text", "text": "To optimize with respect to $M$ , it is convenient to reexpress it in terms of $\\dot{M}\\,=\\,(\\dot{M}_{t})_{t\\in[0,T]}$ as $\\begin{array}{r}{M_{t}(s)=I+\\int_{t}^{s}\\dot{M}_{t}(s^{\\prime})\\,\\mathrm{d}s^{\\prime}}\\end{array}$ . By Fubini\u2019s theorem, we have that ", "page_idx": 29}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\ \\ \\ \\ \\int_{t}^{T}M_{t}(s)\\nabla_{x}f(X_{s}^{v},s)\\,\\mathrm{d}s=\\int_{t}^{T}\\big(I+\\int_{t}^{s}\\dot{M}_{t}(s^{\\prime})\\,\\mathrm{d}s^{\\prime}\\big)\\nabla_{x}f(X_{s}^{v},s)\\,\\mathrm{d}s}\\\\ &{\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad=\\int_{t}^{T}\\nabla_{x}f(X_{s}^{v},s)\\,\\mathrm{d}s+\\int_{t}^{T}\\dot{M}_{t}(s)\\int_{s}^{T}\\nabla_{x}f(X_{s^{\\prime}}^{v},s^{\\prime})\\,\\mathrm{d}s^{\\prime}\\,\\mathrm{d}s,}\\\\ &{-\\int_{t}^{T}(M_{t}(s)\\nabla_{x}b(X_{s}^{v},s)-\\dot{M}_{t}(s))(\\sigma^{-1})^{\\top}(s)v(X_{s}^{v},s)\\,\\mathrm{d}s}\\\\ &{=\\int_{t}^{T}\\dot{M}_{t}(s)(\\sigma^{-1})^{\\top}(s)v(X_{s}^{v},s)\\,\\mathrm{d}s-\\int_{t}^{T}\\dot{M}_{t}(s)\\int_{s}^{T}\\nabla_{x}b(X_{s^{\\prime}}^{v},s^{\\prime})(\\sigma_{s^{\\prime}}^{-1})^{\\top}(s^{\\prime})v(X_{s}^{v},s)\\,\\mathrm{d}s^{\\prime}\\,\\mathrm{d}s,}\\\\ &{-\\,\\lambda^{1/2}\\int_{t}^{T}(M_{t}(s)\\nabla_{x}b(X_{s}^{v},s)-\\dot{M}_{t}(s))(\\sigma^{-1})^{\\top}(s)\\,\\mathrm{d}B_{s}}\\\\ &{=\\lambda^{1/2}\\big(\\int_{t}^{T}\\dot{M}_{t}(s)(\\sigma^{-1})^{\\top}(s)v(X_{s}^{v},s)\\,\\mathrm{d}s-\\int_{t}^{T}\\dot{M}_{t}(s)\\int_{s}^{T}\\nabla_{x}b(X_{s^{\\prime}}^{v},s^{\\prime})(\\sigma_{s^{\\prime}}^{-1})^{\\top}(s^{\\prime})\\,\\mathrm{d}B_{s^{\\prime}}\\,\\mathrm{d}s\\big).}\\end{array}\n$$", "text_format": "latex", "page_idx": 29}, {"type": "text", "text": "Hence, we can rewrite (57) as ", "page_idx": 29}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathcal{G}(\\dot{M})\\!=\\!\\mathbb{E}\\big[\\frac{1}{T}\\int_{0}^{T}\\big\\lVert\\sigma(t)^{\\top}\\big(\\int_{t}^{T}\\nabla_{x}f(X_{s}^{v},s)\\,\\mathrm{d}s+\\nabla g(X_{T}^{v})}\\\\ &{\\qquad\\quad+\\int_{t}^{T}\\dot{M}_{t}(s)\\big(\\int_{s}^{T}\\nabla_{x}f(X_{s^{\\prime}}^{v},s^{\\prime})\\,\\mathrm{d}s^{\\prime}+\\nabla g(X_{T}^{v})+(\\sigma^{-1})^{\\top}(s)v(X_{s}^{v},s)}\\\\ &{\\qquad\\quad-\\int_{s}^{T}\\!\\nabla_{x}b(X_{s^{\\prime}}^{v},s^{\\prime})(\\sigma_{s^{\\prime}}^{-1})^{\\top}(s^{\\prime})v(X_{s}^{v},s)\\,\\mathrm{d}s^{\\prime}-\\int_{s}^{T}\\nabla_{x}b(X_{s^{\\prime}}^{v},s^{\\prime})(\\sigma_{s^{\\prime}}^{-1})^{\\top}(s^{\\prime})\\,\\mathrm{d}B_{s^{\\prime}})\\,\\mathrm{d}s\\big)\\big\\rVert^{2}\\,\\mathrm{d}t}\\\\ &{\\qquad\\qquad\\qquad\\times\\alpha(v,X^{v},B)\\big]}\\end{array}\n$$", "text_format": "latex", "page_idx": 29}, {"type": "text", "text": "The first variation $\\frac{\\delta\\mathcal{G}}{\\delta\\dot{M}}(\\dot{M})$ of $\\mathcal{G}$ at $\\dot{M}$ is defined as the family $Q=(Q_{t})_{t\\in[0,T]}$ of matrix-valued functions such that for any collection of matrix-valued functions $P=(P_{t})_{t\\in[0,T]}$ , ", "page_idx": 30}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\partial_{\\epsilon}\\mathcal{V}(\\dot{M}+\\epsilon P)|_{\\epsilon=0}=\\operatorname*{lim}_{\\epsilon\\rightarrow0}\\frac{\\mathcal{V}(\\dot{M}+\\epsilon P)-\\mathcal{V}(M)}{\\epsilon}=\\langle P,Q\\rangle:=\\int_{0}^{T}\\int_{t}^{T}\\langle P_{t}(s),Q_{t}(s)\\rangle_{F}\\,\\mathrm{d}s\\,\\mathrm{d}t,}\\end{array}\n$$", "text_format": "latex", "page_idx": 30}, {"type": "text", "text": "where $\\dot{M}+\\epsilon P:=(\\dot{M}_{t}+\\epsilon P_{t})_{t\\in[0,T]}$ . Now, note that ", "page_idx": 30}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{J}_{\\tau}\\langle V(\\dot{M}+e P)|_{\\tau=0}=\\partial_{\\tau}\\mathbb{E}[\\frac{1}{\\tau}]\\int_{0}^{T}\\left\\|\\sigma(t)^{\\top}\\left(f^{T}\\nabla_{x}f(X_{s}^{v},s)\\right)\\Delta s+\\nabla g(X_{x}^{v})\\right.}\\\\ &{\\qquad+\\int_{t}^{T}(\\dot{M}_{t}(s)+e P(s))\\big(\\int_{s}^{T}\\nabla_{x}f(X_{s}^{v},s)^{\\prime}\\big)\\,\\mathrm{d}s^{\\prime}+\\nabla g(X_{T}^{v})+(\\sigma^{-1})^{\\top}(s)v(X_{s}^{v},s)}\\\\ &{\\qquad\\qquad-\\int_{s}^{T}\\nabla_{x}b(X_{s}^{v},s)(\\sigma_{x}^{-1})^{T}(s)\\d s^{\\prime}(X_{s}^{v},s)\\,\\mathrm{d}s^{\\prime}-\\int_{s}^{T}\\nabla_{x}b(X_{s}^{v},s^{\\prime})(\\sigma_{x}^{-1})^{\\top}(s)\\d s\\big)\\,\\mathrm{d}s\\big\\}\\Big\\|^{2}\\,\\mathrm{d}t}\\\\ &{\\qquad\\times\\alpha(e,X^{v},B)\\Big\\|_{s=0}}\\\\ &{=\\mathbb{E}[\\frac{2}{\\tau}]\\int_{0}^{T}\\big\\langle\\sigma(t)^{\\top}(\\nabla_{x}^{T}\\nabla_{x}\\rho)\\,\\mathrm{d}s+\\nabla g(X_{s}^{v})\\big\\rangle}\\\\ &{\\qquad+\\int_{t}^{T}\\dot{M}_{t}(s)\\int_{s}^{T}\\nabla_{x}f(X_{s}^{v},s^{\\prime})\\,\\mathrm{d}s^{\\prime}+\\nabla g(X_{T}^{v})+(\\sigma^{-1})^{\\top}(s)v(X_{s}^{v},s)}\\\\ &{\\qquad\\qquad-\\int_{s}^{T}\\nabla_{x}b(X_{s}^{v},s^{\\prime})(\\sigma_{x}^{-1})^{\\top}(s)v(X_{s}^{v},s)\\,\\mathrm{d}s^{\\prime}-\\int_{s}^{T}\\nabla_{x}b(X_{s}^{v},s)(\\sigma_{x}^{-1})^{\\top}(s)\\,\\mathrm{d}s,)\\,\\mathrm{d}s),}\\\\ &{\\qquad\\qquad\\int_{t}^{T}P_{t}(s)\\big(\\int_{s}^\n$$", "text_format": "latex", "page_idx": 30}, {"type": "text", "text": "If we define ", "page_idx": 30}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\langle(s,X^{v},B):=\\int_{s}^{T}\\nabla_{x}f(X_{s^{\\prime}}^{v},s^{\\prime})\\,\\mathrm{d}s^{\\prime}+\\nabla g(X_{T}^{v})+(\\sigma^{-1})^{\\top}(s)v(X_{s}^{v},s)}\\\\ &{\\qquad\\qquad\\qquad-\\int_{s}^{T}\\nabla_{x}b(X_{s^{\\prime}}^{v},s^{\\prime})(\\sigma_{s^{\\prime}}^{-1})^{\\top}(s^{\\prime})v(X_{s}^{v},s)\\,\\mathrm{d}s^{\\prime}-\\int_{s}^{T}\\nabla_{x}b(X_{s^{\\prime}}^{v},s^{\\prime})(\\sigma_{s^{\\prime}}^{-1})^{\\top}(s^{\\prime})\\,\\mathrm{d}B}\\end{array}\n$$", "text_format": "latex", "page_idx": 30}, {"type": "text", "text": "we can rewrite (58) as ", "page_idx": 30}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\gamma_{\\epsilon}\\mathcal{V}(\\dot{M}+\\epsilon P)\\big|_{\\epsilon=0}=\\mathbb E\\big[\\frac{1}{T}\\int_{0}^{T}\\langle\\sigma(t)\\sigma(t)^{\\top}\\big(\\!\\int_{t}^{T}\\nabla_{x}f(X_{s}^{v},s)\\mathrm{d}s\\!+\\!\\nabla g(X_{T}^{v})\\!+\\!\\int_{t}^{T}\\!M_{t}(s)\\chi(s,X^{v},B)\\,\\mathrm{d}s\\big),}\\end{array}\n$$", "text_format": "latex", "page_idx": 30}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\int_{t}^{T}P_{t}(s)\\chi(s,X^{v},B)\\mathrm{d}s\\rangle\\,\\mathrm{d}s\\times\\alpha(v,X^{v},B)\\big]}\\end{array}\n$$", "text_format": "latex", "page_idx": 30}, {"type": "text", "text": "Now let us reexpress equation (59) as: ", "page_idx": 30}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\xi\\big[\\frac{1}{T}\\int_{0}^{T}\\big\\langle\\sigma\\sigma^{\\top}(t)\\big(\\nabla g(X_{T}^{\\nu})+\\int_{t}^{T}\\big(\\nabla_{x}f(X_{s}^{\\nu},s)+\\dot{M}_{t}(s)\\chi(s,X^{\\nu},B)\\big)\\,\\mathrm{d}s\\big\\rangle,}\\\\ &{\\qquad\\qquad\\qquad\\int_{t}^{T}P_{t}(s)\\chi(s,X^{\\nu},B)\\,\\mathrm{d}s\\big)\\,\\mathrm{d}s\\times\\alpha(v,X^{\\nu},B)\\big]}\\\\ &{\\overset{(i)}{=}\\mathbb{E}\\big[\\frac{1}{T}\\int_{0}^{T}\\int_{0}^{s}\\Big\\langle P_{t}(s)\\chi(s,X^{\\nu},B),}\\\\ &{\\qquad\\qquad\\sigma\\sigma^{\\top}(t)\\big(\\nabla g(X_{T}^{\\nu})+\\int_{t}^{T}\\big(\\nabla_{x}f(X_{s}^{\\nu},s^{\\prime})+\\dot{M}_{t}(s^{\\prime})\\chi(s^{\\prime},X^{\\nu},B)\\big)\\,\\mathrm{d}s^{\\prime}\\big)\\big\\rangle\\,\\mathrm{d}t\\,\\mathrm{d}s\\times\\alpha(v,X^{\\nu},B)\\big]}\\\\ &{\\overset{(i i)}{=}\\mathbb{E}\\big[\\frac{1}{T}\\int_{0}^{T}\\int_{0}^{s}\\big\\langle\\sigma\\sigma^{\\top}(t)\\big(\\nabla g(X_{T}^{\\nu})+\\int_{t}^{T}\\big(\\nabla_{x}f(X_{s}^{\\nu},s^{\\prime})+\\dot{M}_{t}(s^{\\prime})\\chi(s^{\\prime},X^{\\nu},B)\\big)\\,\\mathrm{d}s^{\\prime}\\big\\rangle\\chi(X^{\\nu},s,B)^{\\top},}\\\\ &{\\qquad\\qquad\\qquad P_{t}(s)\\big\\rangle_{F}\\,\\mathrm{d}t\\,\\mathrm{d}s\\times\\alpha(v,X^{\\nu},B)\\big]}\\\\ &{=\\int_{0}^{T}\\int_{0}^{s}\\langle\\frac{1}{T}\\sigma\\sigma^{\\top}(t)\\mathbb{E}\\big[\\big(\\nabla g(X_{T}^{\\nu})\\big+\\int_{t}^{T}\\big(\\nabla_{x}f(X_{s}^{\\nu},s^{\\prime})+\\dot{M}_{t}(s^{\\prime})\\chi(X^{\\nu},s^{\\prime},B)\\big)\\,\\mathrm{d}s^{\\prime}\\big)\\chi(X^{\\\n$$", "text_format": "latex", "page_idx": 30}, {"type": "text", "text": "Here, equality (i) holds by Lemma 8 with the choices $\\alpha(t,s)\\;=\\;P_{t}(s)\\chi(X^{v},s,B)$ , $\\gamma(t)\\;=\\;$ $\\begin{array}{r}{\\sigma\\sigma^{\\top}(t)\\big(\\nabla g(X_{T}^{v})+\\int_{t}^{T}\\big(\\nabla_{x}f(X_{s}^{v},s)+\\dot{M}_{t}(s)\\chi(X^{v},s,B)\\big)}\\end{array}$ ds. Equality (ii) follows from the fact that for any matrix $A$ and vectors $b,c,$ $c,\\,\\langle A b,c\\rangle=c^{\\top}A b=\\operatorname{\\mathrm{Tr}}(c^{\\top}A b)=\\operatorname{Tr}(A b c^{\\top})=\\langle B,c b^{\\top}\\rangle_{F}$ , where $\\langle\\cdot,\\cdot\\rangle_{F}$ denotes the Frobenius inner product. ", "page_idx": 30}, {"type": "text", "text": "The first-order necessary condition for optimality states that at the optimal $\\dot{M}^{\\ast}$ , the first variation $\\frac{\\delta\\mathcal{G}}{\\delta\\dot{M}}(\\dot{M}^{*})$ is zero. In other words, $\\partial_{\\epsilon}\\gamma(\\dot{M}+\\epsilon P)|_{\\epsilon=0}$ is zero for any $P$ . Hence, the right-hand side of (60) must be zero for any $P$ , which implies that almost everywhere with respect to $t\\in[0,T]$ , $s\\in[s,T]$ , ", "page_idx": 30}, {"type": "text", "text": "", "page_idx": 31}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathbb{E}\\big[\\big(\\nabla g(X_{T}^{v})\\!+\\!\\int_{t}^{T}\\!\\big(\\nabla_{x}f(X_{s^{\\prime}}^{v},s^{\\prime})\\!+\\!\\dot{M}_{t}(s^{\\prime})\\chi(X^{v},s^{\\prime},B)\\big)\\,\\mathrm{d}s^{\\prime}\\big)\\chi(X^{v},s,B)^{\\top}\\alpha(v,X^{v},B)\\big]=0.}\\end{array}\n$$", "text_format": "latex", "page_idx": 31}, {"type": "text", "text": "To derive this, we also used that $\\sigma(t)$ is invertible by assumption. ", "page_idx": 31}, {"type": "text", "text": "Define the integral operator $\\mathcal{T}_{t}:L^{2}([t,T];\\mathbb{R}^{d\\times d})\\to L^{2}([t,T];\\mathbb{R}^{d\\times d})$ as ", "page_idx": 31}, {"type": "equation", "text": "$$\n\\begin{array}{r}{[\\mathcal{T}_{t}(\\dot{M}_{t})](s)=\\int_{t}^{T}\\dot{M}_{t}(s^{\\prime})\\mathbb{E}\\big[\\chi(X^{v},s^{\\prime},B)\\chi(X^{v},s,B)^{\\top}\\times\\alpha(v,X^{v},B)\\big]\\,\\mathrm{d}s^{\\prime}}\\end{array}\n$$", "text_format": "latex", "page_idx": 31}, {"type": "text", "text": "If we define $\\begin{array}{r}{N_{t}(s)\\,=\\,-\\mathbb{E}\\bigl[\\bigl(\\nabla g(X_{T}^{v})+\\int_{t}^{T}\\nabla_{x}f(X_{s^{\\prime}}^{v},s^{\\prime})\\,\\mathrm{d}s^{\\prime}\\bigr)\\chi(X^{v},s,B)^{\\top}\\,\\times\\,\\alpha(v,X^{v},B)\\bigr]}\\end{array}$ , the problem that we need to solve to find the optimal $\\dot{M_{t}}$ is ", "page_idx": 31}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathcal{T}_{t}(\\dot{M}_{t})=N_{t}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 31}, {"type": "text", "text": "This is a Fredholm equation of the first kind. ", "page_idx": 31}, {"type": "text", "text": "Lemma 8. If $\\alpha,\\beta\\,:\\,[0,T]\\times[0,T]\\,\\rightarrow\\,\\mathbb{R}^{d},\\,\\gamma\\,:\\,[0,T]\\,\\rightarrow\\,\\mathbb{R}^{d},\\,\\delta\\,:\\,[0,T]\\,\\rightarrow\\,\\mathbb{R}^{d\\times d}$ are arbitrary integrable functions, we have that ", "page_idx": 31}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\int_{0}^{T}\\left\\langle\\int_{t}^{T}\\alpha(t,s)\\,\\mathrm{d}s,\\gamma(t)\\right\\rangle\\mathrm{d}t=\\int_{0}^{T}\\int_{0}^{s}\\left\\langle\\alpha(t,s),\\gamma(t)\\right\\rangle\\mathrm{d}t\\,\\mathrm{d}s,}\\end{array}\n$$", "text_format": "latex", "page_idx": 31}, {"type": "text", "text": "Proof. We have that: ", "page_idx": 31}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\int_{0}^{T}\\int_{t}^{T}\\left\\langle\\alpha(t,s),\\gamma(t)\\right\\rangle\\mathrm{d}s\\,\\mathrm{d}t\\stackrel{(\\mathrm{i})}{=}\\int_{0}^{T}\\int_{0}^{T-t}\\left\\langle\\alpha(t,T-s),\\gamma(t)\\right\\rangle\\mathrm{d}s\\,\\mathrm{d}t}\\\\ &{\\stackrel{(\\mathrm{ii})}{=}\\int_{0}^{T}\\int_{0}^{t}\\left\\langle\\alpha(T-t,T-s),\\gamma(T-t)\\right\\rangle\\mathrm{d}s\\,\\mathrm{d}t\\stackrel{(\\mathrm{iii})}{=}\\int_{0}^{T}\\int_{s}^{T}\\left\\langle\\alpha(T-t,T-s),\\gamma(T-t)\\right\\rangle\\mathrm{d}t\\,\\mathrm{d}s}\\\\ &{\\stackrel{(\\mathrm{iv})}{=}\\int_{0}^{T}\\int_{T-s}^{T}\\left\\langle\\alpha(T-t,s),\\gamma(T-t)\\right\\rangle\\mathrm{d}t\\,\\mathrm{d}s\\stackrel{(\\mathrm{v})}{=}\\int_{0}^{T}\\int_{0}^{s}\\left\\langle\\alpha(t,s),\\gamma(t)\\right\\rangle\\mathrm{d}t\\,\\mathrm{d}s}\\end{array}\n$$", "text_format": "latex", "page_idx": 31}, {"type": "text", "text": "Here, in equalities (i), (ii), (iv) and (v) we make changes of variables of the form $t\\,\\mapsto\\,T\\,-\\,t$ , $s\\mapsto T-s$ , $s^{\\prime}\\mapsto T-s^{\\prime}$ . In equality (iii) we use Fubini\u2019s theorem. \u53e3 ", "page_idx": 31}, {"type": "text", "text": "E Control warm-starting ", "text_level": 1, "page_idx": 31}, {"type": "text", "text": "We introduce the Gaussian warm-start, a control warm-start strategy that we adapt from [56], and that we use in our experiments in Figure 7. Their work tackles generalized Schr\u00f6dinger bridge problems, which are different from the control setting in that the final distribution is known and there is no terminal cost. The following proposition, that provides an analytic expression of the control needed for the density of the process to be Gaussian at all times, is the foundation of our method. ", "page_idx": 31}, {"type": "text", "text": "Proposition 6. Given $Z\\sim N(0,I)$ define the random process $Y$ as ", "page_idx": 31}, {"type": "equation", "text": "$$\nY_{t}=\\mu(t)+\\tilde{\\Gamma}(t)Z,\\ \\ \\ \\ \\ \\ w h e r e\\,\\mu(t)\\in\\mathbb{R}^{d},\\,\\tilde{\\Gamma}(t)=\\sqrt{t}\\Gamma(t)\\in\\mathbb{R}^{d\\times d}.\n$$", "text_format": "latex", "page_idx": 31}, {"type": "text", "text": "Define the control $u:\\mathbb{R}^{d}\\times[0,T]\\rightarrow\\mathbb{R}^{d}$ as ", "page_idx": 31}, {"type": "equation", "text": "$$\n\\begin{array}{r}{u(x,t)=\\sigma(t)^{-1}\\big(\\partial_{t}\\mu(t)+\\big(\\big(\\partial_{t}\\Gamma(t)\\big)\\Gamma(t)^{-1}+\\frac{I-(\\sigma\\sigma^{\\top})(t)(\\Sigma\\Sigma^{\\top})^{-1}(t)}{2t}\\big)(x-\\mu(t))-b(x,t)\\big)(x-\\mu(t))}\\end{array}\n$$", "text_format": "latex", "page_idx": 31}, {"type": "text", "text": "Then, if $\\mathrm{'}_{0}=\\sigma(0),$ , the controlled process $X^{u}$ defined in equation (2) has the same marginals as $Y$ .   \nThat is, for all $t\\in[0,T]$ , $\\operatorname{Law}(Y_{t})=\\operatorname{Law}(X_{t}^{u})$ . ", "page_idx": 31}, {"type": "text", "text": "Proof. Following [56], we have that ", "page_idx": 31}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\qquad\\qquad\\partial_{t}X_{t}=\\partial_{t}\\mu_{t}+\\partial_{t}\\tilde{\\Gamma}(t)Z=\\partial_{t}\\mu(t)+(\\partial_{t}\\tilde{\\Gamma}(t))\\tilde{\\Gamma}(t)^{-1}(X_{t}-\\mu(t)),}\\\\ &{\\nabla\\log p_{t}(x)=-\\tilde{\\Sigma}(t)^{-1}(x-\\mu(t)),\\qquad\\tilde{\\Sigma}(t)=\\tilde{\\Gamma}(t)\\tilde{\\Gamma}(t)^{\\top}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 31}, {"type": "text", "text": "Now, $p_{t}$ satisfies the continuity equation equation ", "page_idx": 31}, {"type": "equation", "text": "$$\n\\partial_{t}p_{t}=-\\nabla\\cdot\\left((\\partial_{t}\\mu(t)+(\\partial_{t}\\tilde{\\Gamma}(t))\\tilde{\\Gamma}(t)^{-1}(x-\\mu(t)))p_{t}\\right)\n$$", "text_format": "latex", "page_idx": 31}, {"type": "text", "text": "Let $\\begin{array}{r}{D(t)=\\frac{1}{2}\\sigma(t)\\sigma(t)^{\\top}}\\end{array}$ . We want to reexpress (63) as a Fokker-Planck equation of the form ", "page_idx": 32}, {"type": "equation", "text": "$$\n\\begin{array}{r}{=-\\nabla\\cdot(v(x,t)p_{t})+\\!\\sum_{i=1}^{d}\\sum_{j=1}^{d}\\partial_{i}\\partial_{j}(D_{i j}(t)p_{t})\\!=\\!-\\nabla\\cdot(v(x,t)p_{t})\\!+\\!\\sum_{i=1}^{d}\\partial_{i}\\sum_{j=1}^{d}\\!(D_{i j}(t)\\partial_{j}p_{t})\\!=\\!-\\nabla\\cdot(D_{i j}(t)p_{t})\\!=\\!-\\nabla\\cdot(D_{i}(t)p_{t}),}\\end{array}\n$$", "text_format": "latex", "page_idx": 32}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{=-\\nabla\\cdot(v(x,t)p_{t})+\\nabla\\cdot(D(t)\\nabla p_{t})=-\\nabla\\cdot(v(x,t)p_{t})+\\nabla\\cdot(D(t)\\nabla\\log p_{t}(x)p_{t})}\\\\ &{=-\\nabla\\cdot((v(x,t)\\!-\\!D(t)\\nabla\\log p_{t}(x))p_{t}).}\\end{array}\n$$", "text_format": "latex", "page_idx": 32}, {"type": "text", "text": "Hence, we need that ", "page_idx": 32}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{v(x,t)-D(t)\\nabla\\log p_{t}=\\partial_{t}\\mu(t)+(\\partial_{t}\\tilde{\\Gamma}(t))\\tilde{\\Gamma}(t)^{-1}(x-\\mu(t)),}\\\\ &{\\implies v_{t}(x)=\\partial_{t}\\mu(t)+((\\partial_{t}\\tilde{\\Gamma}(t))\\tilde{\\Gamma}(t)^{-1}(x-\\mu(t))+\\frac{(\\sigma\\sigma^{\\top})(t)}{2}\\nabla\\log p_{t}(x)}\\\\ &{\\qquad\\qquad\\qquad\\qquad=\\partial_{t}\\mu(t)+(\\partial_{t}\\tilde{\\Gamma}(t))\\tilde{\\Gamma}(t)^{-1}(x-\\mu(t))-\\frac{(\\sigma\\sigma^{\\top})(t)}{2}\\Sigma(t)^{-1}(x-\\mu(t)).}\\end{array}\n$$", "text_format": "latex", "page_idx": 32}, {"type": "text", "text": "If we let $\\tilde{\\Gamma}(t)=\\Gamma(t)\\sqrt{t}$ , then $\\tilde{\\Sigma}(t)=t\\Gamma(t)\\Gamma(t)^{\\top}=t\\Sigma(t)$ and $\\begin{array}{r}{\\partial_{t}\\tilde{\\Gamma}(t)=\\partial_{t}\\Gamma(t)\\sqrt{t}+\\frac{\\Gamma(t)}{2\\sqrt{t}}}\\end{array}$ . That is, ", "page_idx": 32}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{v(x,t)=\\partial_{t}\\mu(t)+\\big(\\partial_{t}\\Gamma(t)\\sqrt{t}+\\frac{\\Gamma(t)}{2\\sqrt{t}}\\big)\\frac{\\Gamma(t)^{-1}}{\\sqrt{t}}(x-\\mu(t))-\\frac{(\\sigma\\sigma^{\\top})(t)}{2}\\frac{\\Sigma(t)^{-1}}{t}(x-\\mu(t))}\\\\ &{\\qquad=\\partial_{t}\\mu(t)+\\big(\\partial_{t}\\Gamma(t)\\big)\\Gamma(t)^{-1}(x-\\mu(t))+\\frac{1}{2t}(x-\\mu(t))-\\frac{(\\sigma\\sigma^{\\top})(t)\\Sigma(t)^{-1}}{2t}(x-\\mu(t))}\\end{array}\n$$", "text_format": "latex", "page_idx": 32}, {"type": "text", "text": "For $v$ to be finite at $t\\,=\\,0$ , we need that $(\\sigma\\sigma^{\\top})(0)\\Sigma(0)^{-1}\\,=\\,I$ , which holds, for example, if $\\Gamma(0)=\\sigma(0)$ . Also, to match the form of (2), we need that ", "page_idx": 32}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{v(x,t)=b(x,t)+\\sigma(t)u(x,t),}\\\\ &{\\Longrightarrow\\ u(x,t)=\\sigma(t)^{-1}\\big(\\partial_{t}\\mu_{t}+\\big(\\big(\\partial_{t}\\Gamma(t)\\big)\\Gamma(t)^{-1}+\\frac{I-(\\sigma\\sigma^{\\top})(t)\\Sigma(t)^{-1}}{2t}\\big)(x-\\mu_{t})-b(x,t)\\big).}\\end{array}\n$$", "text_format": "latex", "page_idx": 32}, {"type": "text", "text": "The warm-start control is computed as the solution of a Restricted Gaussian Stochastic Optimal Control problem, where we constrain the space of controls to those that induce Gaussian paths as described in Prop. 6. In practice, we learn a linear spline $\\boldsymbol{\\mu}=(\\boldsymbol{\\mu}^{(b)})_{b=0}^{\\mathcal{B}}$ , where $\\boldsymbol{\\mu}^{(b)}\\in\\mathbb{R}^{d}$ , and a linear spline $\\Gamma=(\\Gamma^{(b)})_{b=0}^{\\beta}$ , where $\\Gamma^{(b)}\\in\\mathbb{R}^{d\\times d}$ . These linear splines take the role of $\\mu(t)$ and $\\Sigma(t)$ in (61). Given splines $\\mu$ and $\\Gamma$ , we obtain the warm-start control using (62); for a given $t\\in[0,T)$ , if we let $b_{-}=\\lfloor\\beta\\bar{t}/T\\rfloor$ $,b_{+}=b_{-}+1,\\Delta=T/B$ , we have that ", "page_idx": 32}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\widehat{\\mu}(t)=\\frac{(t-b_{-}\\Delta)\\mu^{(b_{+})}+(b_{+}\\Delta-t)\\mu^{(b_{-})}}{\\Delta},\\qquad\\widehat{\\partial_{t}\\mu}(t)=\\frac{\\mu^{(b_{+})}-\\mu^{(b_{-})}}{\\Delta},}\\\\ &{\\widehat{\\Gamma}(t)=\\frac{(t-b_{-}\\Delta)\\Gamma^{(b_{+})}+(b_{+}\\Delta-t)\\Gamma^{(b_{-})}}{\\Delta},\\qquad\\widehat{\\partial_{t}\\Gamma}(t)=\\frac{\\Gamma^{(b_{+})}-\\Gamma^{(b_{-})}}{\\Delta},}\\\\ &{\\widehat{\\iota}(x,t)=\\sigma(t)^{-1}\\widehat{(\\partial_{t}u}(t)+\\widehat{(\\partial_{t}\\Gamma(t)\\Gamma(t)^{-1}+\\frac{I-(\\sigma\\sigma^{\\top})(t)(\\widehat{\\Sigma}\\widehat{\\Sigma}^{\\top})^{-1}(t)}{\\widehat{\\omega}_{-}})}\\,\\bigr(x-\\widehat{\\partial_{t}\\Gamma}(t)\\bigr)(x-x)}\\end{array}\n$$$$\n\\begin{array}{r}{\\hat{u}(x,t)=\\sigma(t)^{-1}\\big(\\widehat{\\partial_{t}\\mu}(t)+\\big(\\widehat{\\partial_{t}\\Gamma}(t)\\widehat{\\Gamma}(t)^{-1}+\\frac{I-(\\sigma\\sigma^{\\top})(t)(\\widehat{\\Sigma}\\widehat{\\Sigma}^{\\top})^{-1}(t)}{2t}\\big)(x-\\widehat\\mu(t))-b(x,t)\\big).}\\end{array}\n$$", "text_format": "latex", "page_idx": 32}, {"type": "equation", "text": "", "text_format": "latex", "page_idx": 32}, {"type": "text", "text": "Algorithm 3 provides a method to learn the splines $\\mu,\\Gamma.$ It is a stochastic optimization algorithms in which the spline parameters are updated by sampling $Y_{t}$ in (61) at different times, computing the control cost relying on (66), and taking its gradient. ", "page_idx": 32}, {"type": "text", "text": "Input: State cost $f(x,t)$ , terminal cost $g(x)$ , diffusion coeff. $\\sigma(t)$ , base drift $b(x,t)$ , noise level $\\lambda$ , number of iterations $N$ , batch size $m$ , number of time steps $K$ , number of spline knots $\\boldsymbol{\\mathrm{\\Delta}}\\boldsymbol{\\mathrm{\\Omega}}_{\\boldsymbol{B}}$ , initial mean spline knots $\\mu_{0}=(\\mu_{0}^{(b)})_{b=0}^{\\mathcal{B}}$ , initial noise spline knots $\\Gamma_{0}=(\\Gamma_{0}^{(b)})_{b=0}^{\\beta}$ .   \n1 for $n=0:(N-1)\\}$ do   \n2 Sample $m$ i.i.d. variables $(Z_{i})_{i=1}^{n}\\sim N(0,I)$ and $m$ times $(t_{i})_{i=1}^{n}\\sim\\operatorname{Unif}([0,T])$ .   \n3 for $j=0:K$ do   \n4 Set $t_{j}=j T/K$ , and compute $\\widehat{\\mu}_{n}(t_{j}),\\widehat{\\partial_{t}\\mu}_{n}(t_{j}),\\widehat{\\Gamma}_{n}(t_{j}),\\widehat{\\partial_{t}\\Gamma}_{n}(t_{j})$ according to (64), (65) using $\\mu_{n}$ , \u0393n   \n5 for $i=1:m$ do compute $Y_{i j}=\\hat{\\mu}(t_{j})+\\sqrt{t_{j}}\\widehat{\\Gamma}(t_{j})Z_{i}$ and $\\hat{u}_{n}(Y_{i j},t_{j})$ using (66);   \n6 end   \n7 Compute $\\begin{array}{r}{\\hat{\\mathcal{L}}_{\\mathrm{RGSOC}}(\\mu_{n},\\Gamma_{n})=\\frac{1}{m}\\sum_{i=1}^{m}\\left(\\frac{T}{K}\\sum_{j=0}^{K-1}\\left(\\frac{1}{2}\\|\\hat{u}(Y_{i j},t_{j})\\|^{2}+f(Y_{i j},t_{j})\\right)+g(Y_{i K})\\right)}\\end{array}$   \n8 Compute the gradient of $\\hat{\\mathcal{L}}_{\\mathrm{RGSOC}}(\\mu_{n},\\Gamma_{n})$ with respect to the spline parameters $\\left(\\mu_{n},\\Gamma_{n}\\right)$ .   \n9 Obtain $\\mu_{n+1}$ , $\\Gamma_{n+1}$ with via an Adam update on $\\mu_{n}$ , $\\Gamma_{n}$ resp. (or another stochastic algorithm)   \n10 end Output: Learned splines $\\mu_{N}$ , $\\Gamma_{N}$ , control $\\hat{u}_{N}$ ", "page_idx": 32}, {"type": "text", "text": "Once we have access to the restricted control $\\hat{u}_{N}$ , we can warm-start the control in Algorithms 1 and 2 by introducing $\\hat{u}_{N}$ as an offset. That is, we parameterize the control as $u_{\\theta}=\\hat{u}_{N}+\\tilde{u}_{\\theta}$ . ", "page_idx": 33}, {"type": "text", "text": "F Experimental details and additional plots ", "text_level": 1, "page_idx": 33}, {"type": "text", "text": "F.1 Experimental details ", "text_level": 1, "page_idx": 33}, {"type": "text", "text": "The control $L^{2}$ error curves show the following quantity: ", "page_idx": 33}, {"type": "equation", "text": "$$\n\\mathbb{E}_{t,\\mathbb{P}^{u^{*}}}[\\|u^{*}(X_{t}^{u^{*}},t)-u(X_{t}^{u^{*}},t)\\|^{2}e^{-\\lambda^{-1}V(X_{0}^{u^{*}},0)}]/\\mathbb{E}_{t,\\mathbb{P}^{u^{*}}}[e^{-\\lambda^{-1}V(X_{0}^{u^{*}},0)}]\n$$", "text_format": "latex", "page_idx": 33}, {"type": "text", "text": "That is, we sample trajectories using the optimal control, and compute the error using a Monte Carlo estimate. In all our experiments, the distribution $X_{0}^{u^{*}}$ is a delta, which means that we do not need to compute $V(X_{0}^{u^{*}},0)$ . We keep an exponential moving average (EMA) estimate of the control $L^{2}$ error, which we show in the plots. To compute it, we sample ten batches of optimally controlled trajectories every 10 training iterations, and we update the quantity with the average of the ten batches, using EMA coefficient 0.02. All other quantities shown in the plots are also smoothed out using EMA with coefficient 0.01, except for control objective values, which are computed as the average of 65536 samples, every 5000 training steps. ", "page_idx": 33}, {"type": "text", "text": "For all losses and all settings, we train the control using Adam with learning rate $1\\!\\times\\!10^{-4}$ . For SOCM, we train the reparametrization matrices using Adam with learning rate $\\bar{1}\\times10^{-2}$ . We use batch size $m=128$ unless otherwise specified. When used, we run the warm-start algorithm (Algorithm 3) with $B=20$ knots, $K=200$ time steps, and batch size $m=512$ , and we use Adam with learning rate $3\\times10^{-4}$ for $N=60000$ iterations. ", "page_idx": 33}, {"type": "text", "text": "QUADRATIC ORNSTEIN-UHLENBECK The choices for the functions of the control problem are: ", "page_idx": 33}, {"type": "equation", "text": "$$\nb(\\boldsymbol{x},t)=A\\boldsymbol{x},\\quad\\boldsymbol{f}(\\boldsymbol{x},t)=\\boldsymbol{x}^{\\top}P\\boldsymbol{x},\\quad\\boldsymbol{g}(\\boldsymbol{x})=\\boldsymbol{x}^{\\top}Q\\boldsymbol{x},\\quad\\sigma(t)=\\sigma_{0}.\n$$", "text_format": "latex", "page_idx": 33}, {"type": "text", "text": "where $Q$ is a positive definite matrix. Control problems of this form are better known as linear quadratic regulator (LQR) and they admit a closed form solution [78, Thm. 6.5.1]. The optimal control is given by: ", "page_idx": 33}, {"type": "equation", "text": "$$\nu_{t}^{*}(x)=-2\\sigma_{0}^{\\top}F_{t}x,\n$$", "text_format": "latex", "page_idx": 33}, {"type": "text", "text": "where $F_{t}$ is the solution of the Ricatti equation ", "page_idx": 33}, {"type": "equation", "text": "$$\n\\frac{d F_{t}}{d t}+A^{\\top}F_{t}+F_{t}A-2F_{t}\\sigma_{0}\\sigma_{0}^{\\top}F_{t}+P=0\n$$", "text_format": "latex", "page_idx": 33}, {"type": "text", "text": "with the final condition $F_{T}=Q$ . Within the QUADRATIC OU class, we consider two settings: ", "page_idx": 33}, {"type": "text", "text": "\u2022 Easy: We set $d\\:=\\:20\\:$ , $A\\:=\\:0.2I$ , $P\\:=\\:0.2I$ , $Q\\ =\\ 0.1I$ , $\\sigma_{0}\\,\\mathrm{~=~}\\,I$ , $\\lambda\\,=\\,1$ , $T\\ =\\ 1$ , $x_{\\mathrm{init}}=0.5N(0,I)$ . We do not use warm-start for any algorithm. We take $K=50$ time discretization steps, and we use random seed 0.   \n\u2022 Hard: We set $d=20$ , $A=I$ , $P=I$ , $Q=0.5I$ , $\\sigma_{0}=I$ , $\\lambda=1$ , $T=1$ , $x_{\\mathrm{init}}=0.5N(0,I)$ . We use the Gaussian warm-start (App. E). We take batch size $m=64$ and $K=150$ time discretization steps, and we use random seed 0. ", "page_idx": 33}, {"type": "text", "text": "LINEAR ORNSTEIN-UHLENBECK The functions of the control problem are chosen as follows: ", "page_idx": 33}, {"type": "equation", "text": "$$\nb(x,t)=A x,\\quad f(x,t)=0,\\quad g(x)=\\langle\\gamma,x\\rangle,\\quad\\sigma(t)=\\sigma_{0}.\n$$", "text_format": "latex", "page_idx": 33}, {"type": "text", "text": "The optimal control for this class of problems is given by [59, Sec. A.4]: ", "page_idx": 33}, {"type": "equation", "text": "$$\nu_{t}^{*}(x)=-\\sigma_{0}^{\\top}e^{A^{\\top}(T-t)}\\gamma.\n$$", "text_format": "latex", "page_idx": 33}, {"type": "text", "text": "We use exactly the same functions as [59]: we sample $(\\xi_{i j})_{1\\leq i,j\\leq d}$ once at the beginning of the simulation, and set: ", "page_idx": 33}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{d=10,\\quad A=-I+(\\xi_{i j})_{1\\leq i,j\\leq d},\\quad\\gamma=\\mathbb{1},\\quad\\sigma_{0}=I+(\\xi_{i j})_{1\\leq i,j\\leq d},}\\\\ &{T=1,\\quad\\lambda=1,\\quad x_{\\mathrm{{init}}}=0.5N(0,I).}\\end{array}\n$$", "text_format": "latex", "page_idx": 33}, {"type": "text", "text": "We take $K=100$ time discretization steps, and we use random seed 0. ", "page_idx": 33}, {"type": "text", "text": "DOUBLE WELL We also use exactly the same functions as [59], which are the following: ", "page_idx": 34}, {"type": "equation", "text": "$$\n\\langle\\boldsymbol{x},t\\rangle=-\\nabla\\Psi(\\boldsymbol{x}),\\quad\\Psi(\\boldsymbol{x})=\\sum_{i=1}^{d}\\kappa_{i}(x_{i}^{2}-1)^{2},\\quad\\boldsymbol{f}(\\boldsymbol{x})=0,\\quad\\boldsymbol{g}(\\boldsymbol{x})=\\sum_{i=1}^{d}\\nu_{i}(x_{i}^{2}-1)^{2},\\quad\\sigma_{0}=\\operatorname{I},\n$$", "text_format": "latex", "page_idx": 34}, {"type": "text", "text": "where $d=10$ , and $\\kappa_{i}=5$ , $\\nu_{i}=3$ for $i\\in\\{1,2,3\\}$ and $\\kappa_{i}=1$ , $\\nu_{i}=1$ for $i\\in\\{4,\\ldots,10\\}$ . We set $T=1$ , $\\lambda=1$ and $x_{\\mathrm{init}}=0$ . We take $K=200$ time discretization steps, and we use random seed 0. The Double Well problem is actually highly non-trivial, and is multimodal. The only reason we can produce a \"ground truth\" control to compare to in this setting is that we use significant knowledge of the problem; we analytically reduce it to 1D problems by decoupling each dimension and apply numerical methods to solve the Hamilton-Jacobi-Bellman equation for these 1D problems. It is not a problem where we actually have the ground truth control in closed form. ", "page_idx": 34}, {"type": "text", "text": "PATH INTEGRAL SAMPLER ON MIXTURE OF GAUSSIANS We set ", "text_level": 1, "page_idx": 34}, {"type": "equation", "text": "$$\n\\begin{array}{r}{b(x,t)=0,\\qquad f(x,t)=0,\\qquad g(x)=\\log(\\mu^{0}(x)/\\mu(x))=-\\frac{\\|x\\|^{2}}{2}-\\frac{d}{2}\\log(2\\pi)-\\log\\mu(x),}\\end{array}\n$$", "text_format": "latex", "page_idx": 34}, {"type": "text", "text": "where $T=1$ , and $\\mu$ is the density of a mixture of two Gaussians with means $\\pm e_{1}$ , where $e_{1}=$ $(1,0,\\dots,0)$ , and variance Id. Note that we take $\\mu$ to be normalized, i.e. $\\textstyle\\int\\mu(x)\\,\\mathrm{d}x\\;=\\;1$ , or equivalently, $\\begin{array}{r}{\\log Z=\\log\\left(\\,\\int\\mu(x)\\,\\mathrm{d}x\\right)=0}\\end{array}$ . In Figure 1, we use the following Monte Carlo estimator of the control objective at the control $u$ : ", "page_idx": 34}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\hat{S}^{u}(X)=\\int_{0}^{T}\\left(\\frac{1}{2}\\|u(X_{t}^{u},t)\\|^{2}+f(X_{t}^{u},t)\\right)\\mathrm{d}t+g(X_{T}^{u})+\\int\\langle u(X_{t}^{u},t),\\mathrm{d}B_{t}\\rangle.}\\end{array}\n$$", "text_format": "latex", "page_idx": 34}, {"type": "text", "text": "Note that this estimator is unbiased because $\\mathbb{E}[\\int\\langle u(X_{t}^{u},t),\\mathrm{d}B_{t}\\rangle]=0$ . This is known as the Sticking the Landing estimator, as it has zero variance when $u$ is the optimal control [72]. The fact that $\\mathbb{E}[-\\hat{S}^{u}(X)]\\leq\\log Z=0$ with equality when $u=u^{*}$ is stated as [84, Thm. 4]. ", "page_idx": 34}, {"type": "text", "text": "F.2 Model architectures ", "text_level": 1, "page_idx": 34}, {"type": "text", "text": "As a general guideline, the control function can be thought of as the analog of the score function in diffusion models; hence, a natural choice for the architecture can be U-Nets or diffusion transformers if the control task is on images, audio or video. Other domains may require different architectures. In the experiments we report, we used the architecture implemented in the class FullyConnectedUNet within the flie SOC_matching/models.py. It is a simplified version of the U-Net architecture where both the down-sampling and up-sampling layers are fully connected with ReLU activations, and the horizontal layers are linear transformations. We use three down-sampling and up-sampling steps, with widths 256, 128 and 64 (hence, the first down-sampling step is actually an up-sampling, because the data dimensions in our experiments range from 10 to 20). ", "page_idx": 34}, {"type": "text", "text": "The reparameterization matrices have an unusual trait, which is that their input dimension is small (two) while their output dimension is large $(d^{2})$ . Hence, the kind of functions that they need to learn are low dimensional and hence easy. In our case, we used the architecture implemented in the class SigmoidMLP within the flie SOC_matching/models.py, which is essentially a three layer multilayer perceptron with ReLU activations and output dimension $d^{2}$ , whose output is averaged with the identity matrix using sigmoid weights, in order to enforce that $M_{t}(t)$ be the identity matrix. ", "page_idx": 34}, {"type": "text", "text": "F.3 Additional tables and plots ", "text_level": 1, "page_idx": 34}, {"type": "text", "text": "Table 1 shows the average times per iteration for each algorithm. Each algorithm was run using a 16GB V100 GPU. ", "page_idx": 34}, {"type": "table", "img_path": "wfU2CdgmWt/tmp/48cd6dd0e22a66673561eb34a1e62be994df8eaa78248ca4f1ae0b16ce5b4bfc.jpg", "table_caption": [], "table_footnote": [], "page_idx": 34}, {"type": "text", "text": "Table 1: Time per iteration (exponential moving average) for various algorithms in seconds per iteration, for the QUADRATIC OU (EASY) experiments (Figure 2). ", "page_idx": 34}, {"type": "text", "text": "Figure 4 shows the control objective (1) for the four settings. The error bars for the control objective plots show the confidence intervals for $\\pm$ one standard deviation, computed via a Monte Carlo estimate using 65536 trajectories per data point. They show the standard error of the mean. As expected, SOCM also obtains the lowest values for the control objective, up to the estimation error. ", "page_idx": 34}, {"type": "text", "text": "", "page_idx": 35}, {"type": "text", "text": "Figure 5 shows the normalized standard deviation of the importance weight for the learned control $u$ : $\\sqrt{\\mathrm{Var}[\\alpha(u,X^{u},B)]}/\\mathbb{E}[\\alpha(u,X^{u},B)]$ . By Lemma 1, when $X_{0}^{u}=x_{\\mathrm{init}}$ for an arbitrary $x_{\\mathrm{{init}}}$ (which is the case for all our experiments), this quantity is zero for the optimal control $u^{*}$ . Hence, the normalized standard deviation of $\\alpha$ is an alternative metric to measure the optimality of the learned control. ", "page_idx": 35}, {"type": "text", "text": "Figure 6 shows an exponential moving average of the norm squared of the gradient for LINEAR OU and DOUBLE WELL. For LINEAR OU, the minimum gradient norm is achieved by the adjoint method, while for DOUBLE WELL it is achieved by the cross entropy loss. The training instabilities of the adjoint method become apparent as well. Interestingly, in both settings the algorithms with smallest gradients are not SOCM, which is the algorithm with smallest error as shown in Figure 3. Understanding this phenomenon is outside of the scope of this paper. ", "page_idx": 35}, {"type": "text", "text": "Figure 7 shows plots of the control $L^{2}$ error, the norm squared of the gradient, and the control objective for the QUADRATIC OU (HARD) setting, using a warm-start strategy detailed in App. E. Figure 7 shows that SOCM is once again the algorithm that achieves the lowest error and the smallest gradients. Remark that the warm-start control is a reasonable approximation of the optimal control, as the initial control $L^{2}$ error is much lower than in the other figures. ", "page_idx": 35}, {"type": "text", "text": "Figure 8 shows the value of the training loss for SOCM and its two ablations: SOCM with constant $M_{t}=I$ , and SOCM-Adjoint. For all such algorithms, the training loss is the sum of the $L^{2}$ error of the learned control $u$ , and the expected conditional variance of the matching vector field $w$ . Thus, the difference between the training loss plots and the $L^{2}$ error plots is the expected conditional variance of $w$ . We observe that the expected conditional variance in the QUADRATIC OU setting is orders of magnitude smaller for SOCM than for its two ablations. For LINEAR OU, SOCM and SOCM-adjoint have similar expected conditional variance, and a possible explanation is that the LINEAR OU setting is very simple. In the DOUBLE WELL setting, the SOCM-adjoint training loss curve has spikes that are probably caused by instabilities of the adjoint method. These spikes can be attributed mostly to the expected conditional variance term, since the corresponding $L^{2}$ error curve in Figure 3 does not present them. ", "page_idx": 35}, {"type": "text", "text": "Figure 9 shows that the instabilities of the adjoint method are inherent to the loss, because they also appear at small learning rates: $3\\times10^{-5}$ is smaller than the learning rates typically used for Adam, which hover from $1\\times\\bar{1}0^{-4}$ to $1\\times10^{-3}$ . ", "page_idx": 35}, {"type": "image", "img_path": "wfU2CdgmWt/tmp/bbc165f126e1c47773492074fefc6ac45b9e818c473feb1fd84d4df9eebf702d.jpg", "img_caption": ["Figure 4: Plots of the control objective for the four settings. "], "img_footnote": [], "page_idx": 36}, {"type": "image", "img_path": "wfU2CdgmWt/tmp/2a405ba72bb8e5df3149965c3a794c04bfc90325fe3bb5ce66564d7e36bfab1c.jpg", "img_caption": ["Figure 5: Plots of the normalized standard deviation of the importance weights: $\\sqrt{\\mathrm{Var}[\\alpha(u,X^{u},B)]}/\\mathbb{E}[\\alpha(u,X^{u},B)]$ . "], "img_footnote": [], "page_idx": 36}, {"type": "image", "img_path": "wfU2CdgmWt/tmp/942cb099f4dc82c5f3985bc7aa254361d1272cbf4e6c2ae81b8e7200d4d9ad55.jpg", "img_caption": ["Figure 6: Plots of the norm squared of the gradient for the LINEAR ORNSTEIN UHLENBECK and DOUBLE WELL settings. "], "img_footnote": [], "page_idx": 37}, {"type": "image", "img_path": "wfU2CdgmWt/tmp/ca4a3fc5bb134c1e27379a48e0b86edbf9ae4f0429802b5c66fe7224fcd946df.jpg", "img_caption": ["Figure 7: Plots of the control $L^{2}$ error, the norm squared of the gradient, and the control objective for the QUADRATIC ORNSTEIN-UHLENBECK (HARD) setting, without using warm-start. "], "img_footnote": [], "page_idx": 37}, {"type": "image", "img_path": "wfU2CdgmWt/tmp/ff4b8cb8e3ecbf923d25047ee18c61c6badee308096d8501b4bd891d88f97e80.jpg", "img_caption": ["Figure 8: Plots of the training loss for SOCM and its two ablations: SOCM with constant $M_{t}=I$ , and SOCM-Adjoint. "], "img_footnote": [], "page_idx": 38}, {"type": "image", "img_path": "wfU2CdgmWt/tmp/d4a58665567b9b30ab2b0f691d93f877181de10e6670e81f407c31e2604b343b.jpg", "img_caption": ["Figure 9: Plots of the control $L^{2}$ error and the norm squared of the gradient for the adjoint method on DOUBLE WELL, for two different values of the Adam learning rate. The instabilities of the adjoint method persist for small learning rates, signaling an inherent issue with the loss. "], "img_footnote": [], "page_idx": 38}, {"type": "text", "text": "NeurIPS Paper Checklist ", "text_level": 1, "page_idx": 39}, {"type": "text", "text": "1. Claims ", "text_level": 1, "page_idx": 39}, {"type": "text", "text": "Question: Do the main claims made in the abstract and introduction accurately reflect the paper\u2019s contributions and scope? ", "page_idx": 39}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 39}, {"type": "text", "text": "Justification: In the abstract and introduction we state that we introduce SOCM, a novel algorithm to solve stochastic optimal control problems, and we claim that it outperforms all existing algorithms in three out of four settings. All of these claims are supported by our paper. ", "page_idx": 39}, {"type": "text", "text": "Guidelines: ", "page_idx": 39}, {"type": "text", "text": "\u2022 The answer NA means that the abstract and introduction do not include the claims made in the paper.   \n\u2022 The abstract and/or introduction should clearly state the claims made, including the contributions made in the paper and important assumptions and limitations. A No or NA answer to this question will not be perceived well by the reviewers.   \n\u2022 The claims made should match theoretical and experimental results, and reflect how much the results can be expected to generalize to other settings.   \n\u2022 It is fine to include aspirational goals as motivation as long as it is clear that these goals are not attained by the paper. ", "page_idx": 39}, {"type": "text", "text": "2. Limitations ", "text_level": 1, "page_idx": 39}, {"type": "text", "text": "Question: Does the paper discuss the limitations of the work performed by the authors? ", "page_idx": 39}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 39}, {"type": "text", "text": "Justification: Yes, in the second-to-last paragraph of Sec. 5 we discuss the main limitation of SOCM (our algorithm), which is that the variance of the importance weight $\\alpha$ is too large in certain settings. Regarding the computational efficiency of our algorithm, Table 1 shows a comparison between our algorithm and existing ones. ", "page_idx": 39}, {"type": "text", "text": "Guidelines: ", "text_level": 1, "page_idx": 39}, {"type": "text", "text": "\u2022 The answer NA means that the paper has no limitation while the answer No means that the paper has limitations, but those are not discussed in the paper.   \n\u2022 The authors are encouraged to create a separate \"Limitations\" section in their paper.   \n\u2022 The paper should point out any strong assumptions and how robust the results are to violations of these assumptions (e.g., independence assumptions, noiseless settings, model well-specification, asymptotic approximations only holding locally). The authors should reflect on how these assumptions might be violated in practice and what the implications would be.   \n\u2022 The authors should reflect on the scope of the claims made, e.g., if the approach was only tested on a few datasets or with a few runs. In general, empirical results often depend on implicit assumptions, which should be articulated.   \n\u2022 The authors should reflect on the factors that influence the performance of the approach. For example, a facial recognition algorithm may perform poorly when image resolution is low or images are taken in low lighting. Or a speech-to-text system might not be used reliably to provide closed captions for online lectures because it fails to handle technical jargon.   \n\u2022 The authors should discuss the computational efficiency of the proposed algorithms and how they scale with dataset size.   \n\u2022 If applicable, the authors should discuss possible limitations of their approach to address problems of privacy and fairness.   \n\u2022 While the authors might fear that complete honesty about limitations might be used by reviewers as grounds for rejection, a worse outcome might be that reviewers discover limitations that aren\u2019t acknowledged in the paper. The authors should use their best judgment and recognize that individual actions in favor of transparency play an important role in developing norms that preserve the integrity of the community. Reviewers will be specifically instructed to not penalize honesty concerning limitations. ", "page_idx": 39}, {"type": "text", "text": "3. Theory Assumptions and Proofs ", "text_level": 1, "page_idx": 40}, {"type": "text", "text": "Question: For each theoretical result, does the paper provide the full set of assumptions and a complete (and correct) proof? ", "page_idx": 40}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 40}, {"type": "text", "text": "Justification: All the theoretical results stated in the paper are numbered and have a corresponding detailed proof in the appendices. In the main text, we indicate the precise location of the proofs. We provide a proof sketch for Theorem 1 in the main paper, and a full proof in the appendix. ", "page_idx": 40}, {"type": "text", "text": "Guidelines: ", "page_idx": 40}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include theoretical results.   \n\u2022 All the theorems, formulas, and proofs in the paper should be numbered and crossreferenced.   \n\u2022 All assumptions should be clearly stated or referenced in the statement of any theorems.   \n\u2022 The proofs can either appear in the main paper or the supplemental material, but if they appear in the supplemental material, the authors are encouraged to provide a short proof sketch to provide intuition.   \n\u2022 Inversely, any informal proof provided in the core of the paper should be complemented by formal proofs provided in appendix or supplemental material.   \n\u2022 Theorems and Lemmas that the proof relies upon should be properly referenced. ", "page_idx": 40}, {"type": "text", "text": "4. Experimental Result Reproducibility ", "text_level": 1, "page_idx": 40}, {"type": "text", "text": "Question: Does the paper fully disclose all the information needed to reproduce the main experimental results of the paper to the extent that it affects the main claims and/or conclusions of the paper (regardless of whether the code and data are provided or not)? ", "page_idx": 40}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 40}, {"type": "text", "text": "Justification: We provide a description of experimental details in Subsec. F.1, and of model architectures in Subsec. F.2. We also provide a link to the GitHub repository that contains the code for this paper. ", "page_idx": 40}, {"type": "text", "text": "Guidelines: ", "page_idx": 40}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 If the paper includes experiments, a No answer to this question will not be perceived well by the reviewers: Making the paper reproducible is important, regardless of whether the code and data are provided or not.   \n\u2022 If the contribution is a dataset and/or model, the authors should describe the steps taken to make their results reproducible or verifiable.   \n\u2022 Depending on the contribution, reproducibility can be accomplished in various ways. For example, if the contribution is a novel architecture, describing the architecture fully might suffice, or if the contribution is a specific model and empirical evaluation, it may be necessary to either make it possible for others to replicate the model with the same dataset, or provide access to the model. In general. releasing code and data is often one good way to accomplish this, but reproducibility can also be provided via detailed instructions for how to replicate the results, access to a hosted model (e.g., in the case of a large language model), releasing of a model checkpoint, or other means that are appropriate to the research performed.   \n\u2022 While NeurIPS does not require releasing code, the conference does require all submissions to provide some reasonable avenue for reproducibility, which may depend on the nature of the contribution. For example (a) If the contribution is primarily a new algorithm, the paper should make it clear how to reproduce that algorithm. (b) If the contribution is primarily a new model architecture, the paper should describe the architecture clearly and fully. (c) If the contribution is a new model (e.g., a large language model), then there should either be a way to access this model for reproducing the results or a way to reproduce the model (e.g., with an open-source dataset or instructions for how to construct the dataset). ", "page_idx": 40}, {"type": "text", "text": "(d) We recognize that reproducibility may be tricky in some cases, in which case authors are welcome to describe the particular way they provide for reproducibility. In the case of closed-source models, it may be that access to the model is limited in some way (e.g., to registered users), but it should be possible for other researchers to have some path to reproducing or verifying the results. ", "page_idx": 41}, {"type": "text", "text": "5. Open access to data and code ", "text_level": 1, "page_idx": 41}, {"type": "text", "text": "Question: Does the paper provide open access to the data and code, with sufficient instructions to faithfully reproduce the main experimental results, as described in supplemental material? ", "page_idx": 41}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 41}, {"type": "text", "text": "Justification: We also provide a link to the GitHub repository that contains the code for this paper. ", "page_idx": 41}, {"type": "text", "text": "Guidelines: ", "page_idx": 41}, {"type": "text", "text": "\u2022 The answer NA means that paper does not include experiments requiring code.   \n\u2022 Please see the NeurIPS code and data submission guidelines (https://nips.cc/ public/guides/CodeSubmissionPolicy) for more details.   \n\u2022 While we encourage the release of code and data, we understand that this might not be possible, so \u201cNo\u201d is an acceptable answer. Papers cannot be rejected simply for not including code, unless this is central to the contribution (e.g., for a new open-source benchmark).   \n\u2022 The instructions should contain the exact command and environment needed to run to reproduce the results. See the NeurIPS code and data submission guidelines (https: //nips.cc/public/guides/CodeSubmissionPolicy) for more details.   \n\u2022 The authors should provide instructions on data access and preparation, including how to access the raw data, preprocessed data, intermediate data, and generated data, etc.   \n\u2022 The authors should provide scripts to reproduce all experimental results for the new proposed method and baselines. If only a subset of experiments are reproducible, they should state which ones are omitted from the script and why.   \n\u2022 At submission time, to preserve anonymity, the authors should release anonymized versions (if applicable).   \n\u2022 Providing as much information as possible in supplemental material (appended to the paper) is recommended, but including URLs to data and code is permitted. ", "page_idx": 41}, {"type": "text", "text": "6. Experimental Setting/Details ", "text_level": 1, "page_idx": 41}, {"type": "text", "text": "Question: Does the paper specify all the training and test details (e.g., data splits, hyperparameters, how they were chosen, type of optimizer, etc.) necessary to understand the results? ", "page_idx": 41}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 41}, {"type": "text", "text": "Justification: We provide a description of experimental details in Subsec. F.1, and of model architectures in Subsec. F.2. ", "page_idx": 41}, {"type": "text", "text": "Guidelines: ", "page_idx": 41}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments. \u2022 The experimental setting should be presented in the core of the paper to a level of detail that is necessary to appreciate the results and make sense of them. \u2022 The full details can be provided either with the code, in appendix, or as supplemental material. ", "page_idx": 41}, {"type": "text", "text": "7. Experiment Statistical Significance ", "text_level": 1, "page_idx": 41}, {"type": "text", "text": "Question: Does the paper report error bars suitably and correctly defined or other appropriate information about the statistical significance of the experiments? ", "page_idx": 41}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 41}, {"type": "text", "text": "Justification: Most of the plots in the paper do not contain error bars, because the lines show exponential moving averages, which means that the error is already smoothed out and very small. The error bars for the control objective plots do show the confidence intervals for $\\pm$ one standard deviation, computed via a Monte Carlo estimate using 65536 trajectories per data point. They show the standard error of the mean. We state this in Subsec. F.3. ", "page_idx": 41}, {"type": "text", "text": "", "page_idx": 42}, {"type": "text", "text": "Guidelines: ", "page_idx": 42}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 The authors should answer \"Yes\" if the results are accompanied by error bars, confidence intervals, or statistical significance tests, at least for the experiments that support the main claims of the paper.   \n\u2022 The factors of variability that the error bars are capturing should be clearly stated (for example, train/test split, initialization, random drawing of some parameter, or overall run with given experimental conditions).   \n\u2022 The method for calculating the error bars should be explained (closed form formula, call to a library function, bootstrap, etc.)   \n\u2022 The assumptions made should be given (e.g., Normally distributed errors).   \n\u2022 It should be clear whether the error bar is the standard deviation or the standard error of the mean.   \n\u2022 It is OK to report 1-sigma error bars, but one should state it. The authors should preferably report a 2-sigma error bar than state that they have a $96\\%$ CI, if the hypothesis of Normality of errors is not verified.   \n\u2022 For asymmetric distributions, the authors should be careful not to show in tables or figures symmetric error bars that would yield results that are out of range (e.g. negative error rates).   \n\u2022 If error bars are reported in tables or plots, The authors should explain in the text how they were calculated and reference the corresponding figures or tables in the text. ", "page_idx": 42}, {"type": "text", "text": "8. Experiments Compute Resources ", "text_level": 1, "page_idx": 42}, {"type": "text", "text": "Question: For each experiment, does the paper provide sufficient information on the computer resources (type of compute workers, memory, time of execution) needed to reproduce the experiments? ", "page_idx": 42}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 42}, {"type": "text", "text": "Justification: We explain the type and amount of GPUs we use in Subsec. F.3. Guidelines: ", "page_idx": 42}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 The paper should indicate the type of compute workers CPU or GPU, internal cluster, or cloud provider, including relevant memory and storage.   \n\u2022 The paper should provide the amount of compute required for each of the individual experimental runs as well as estimate the total compute.   \n\u2022 The paper should disclose whether the full research project required more compute than the experiments reported in the paper (e.g., preliminary or failed experiments that didn\u2019t make it into the paper). ", "page_idx": 42}, {"type": "text", "text": "9. Code Of Ethics ", "text_level": 1, "page_idx": 42}, {"type": "text", "text": "Question: Does the research conducted in the paper conform, in every respect, with the NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines? ", "page_idx": 42}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 42}, {"type": "text", "text": "Justification: We reviewed the NeurIPS Code of Ethics and our research conforms to it. We made sure to preserve our anonymity. ", "page_idx": 42}, {"type": "text", "text": "Guidelines: ", "page_idx": 42}, {"type": "text", "text": "\u2022 The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics.   \n\u2022 If the authors answer No, they should explain the special circumstances that require a deviation from the Code of Ethics.   \n\u2022 The authors should make sure to preserve anonymity (e.g., if there is a special consideration due to laws or regulations in their jurisdiction). ", "page_idx": 42}, {"type": "text", "text": "10. Broader Impacts ", "text_level": 1, "page_idx": 42}, {"type": "text", "text": "Question: Does the paper discuss both potential positive societal impacts and negative societal impacts of the work performed? ", "page_idx": 43}, {"type": "text", "text": "Answer: [No] ", "page_idx": 43}, {"type": "text", "text": "Justification: The research presented is foundational, and the code released does not have direct societal impact. Yet, it may serve as the basis to develop algorithms that improve the quality of generative models. We state this in Sec. 5. ", "page_idx": 43}, {"type": "text", "text": "Guidelines: ", "page_idx": 43}, {"type": "text", "text": "\u2022 The answer NA means that there is no societal impact of the work performed.   \n\u2022 If the authors answer NA or No, they should explain why their work has no societal impact or why the paper does not address societal impact.   \n\u2022 Examples of negative societal impacts include potential malicious or unintended uses (e.g., disinformation, generating fake profiles, surveillance), fairness considerations (e.g., deployment of technologies that could make decisions that unfairly impact specific groups), privacy considerations, and security considerations.   \n\u2022 The conference expects that many papers will be foundational research and not tied to particular applications, let alone deployments. However, if there is a direct path to any negative applications, the authors should point it out. For example, it is legitimate to point out that an improvement in the quality of generative models could be used to generate deepfakes for disinformation. On the other hand, it is not needed to point out that a generic algorithm for optimizing neural networks could enable people to train models that generate Deepfakes faster.   \n\u2022 The authors should consider possible harms that could arise when the technology is being used as intended and functioning correctly, harms that could arise when the technology is being used as intended but gives incorrect results, and harms following from (intentional or unintentional) misuse of the technology.   \n\u2022 If there are negative societal impacts, the authors could also discuss possible mitigation strategies (e.g., gated release of models, providing defenses in addition to attacks, mechanisms for monitoring misuse, mechanisms to monitor how a system learns from feedback over time, improving the efficiency and accessibility of ML). ", "page_idx": 43}, {"type": "text", "text": "11. Safeguards ", "text_level": 1, "page_idx": 43}, {"type": "text", "text": "Question: Does the paper describe safeguards that have been put in place for responsible release of data or models that have a high risk for misuse (e.g., pretrained language models, image generators, or scraped datasets)? ", "page_idx": 43}, {"type": "text", "text": "Answer: [No] ", "text_level": 1, "page_idx": 43}, {"type": "text", "text": "Justification: The paper poses no such risks. ", "page_idx": 43}, {"type": "text", "text": "Guidelines: ", "page_idx": 43}, {"type": "text", "text": "\u2022 The answer NA means that the paper poses no such risks.   \n\u2022 Released models that have a high risk for misuse or dual-use should be released with necessary safeguards to allow for controlled use of the model, for example by requiring that users adhere to usage guidelines or restrictions to access the model or implementing safety filters.   \n\u2022 Datasets that have been scraped from the Internet could pose safety risks. The authors should describe how they avoided releasing unsafe images.   \n\u2022 We recognize that providing effective safeguards is challenging, and many papers do not require this, but we encourage authors to take this into account and make a best faith effort. ", "page_idx": 43}, {"type": "text", "text": "12. Licenses for existing assets ", "text_level": 1, "page_idx": 43}, {"type": "text", "text": "Question: Are the creators or original owners of assets (e.g., code, data, models), used in the paper, properly credited and are the license and terms of use explicitly mentioned and properly respected? ", "page_idx": 43}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 43}, {"type": "text", "text": "Justification: We did not use existing assets. Guidelines: ", "page_idx": 43}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not use existing assets.   \n\u2022 The authors should cite the original paper that produced the code package or dataset.   \n\u2022 The authors should state which version of the asset is used and, if possible, include a URL.   \n\u2022 The name of the license (e.g., CC-BY 4.0) should be included for each asset.   \n\u2022 For scraped data from a particular source (e.g., website), the copyright and terms of service of that source should be provided.   \n\u2022 If assets are released, the license, copyright information, and terms of use in the package should be provided. For popular datasets, paperswithcode.com/datasets has curated licenses for some datasets. Their licensing guide can help determine the license of a dataset.   \n\u2022 For existing datasets that are re-packaged, both the original license and the license of the derived asset (if it has changed) should be provided.   \n\u2022 If this information is not available online, the authors are encouraged to reach out to the asset\u2019s creators. ", "page_idx": 44}, {"type": "text", "text": "13. New Assets ", "text_level": 1, "page_idx": 44}, {"type": "text", "text": "Question: Are new assets introduced in the paper well documented and is the documentation provided alongside the assets? ", "page_idx": 44}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 44}, {"type": "text", "text": "Justification: We present code implementing our algorithm. The code folder contains a README which explains how to reproduce the experiments. We describe our algorithm throughout the paper, and provide details in App. F. ", "page_idx": 44}, {"type": "text", "text": "Guidelines: ", "page_idx": 44}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not release new assets.   \n\u2022 Researchers should communicate the details of the dataset/code/model as part of their submissions via structured templates. This includes details about training, license, limitations, etc.   \n\u2022 The paper should discuss whether and how consent was obtained from people whose asset is used.   \n\u2022 At submission time, remember to anonymize your assets (if applicable). You can either create an anonymized URL or include an anonymized zip file. ", "page_idx": 44}, {"type": "text", "text": "14. Crowdsourcing and Research with Human Subjects ", "text_level": 1, "page_idx": 44}, {"type": "text", "text": "Question: For crowdsourcing experiments and research with human subjects, does the paper include the full text of instructions given to participants and screenshots, if applicable, as well as details about compensation (if any)? ", "page_idx": 44}, {"type": "text", "text": "Answer: [No] ", "page_idx": 44}, {"type": "text", "text": "Justification: The paper does not involve crowdsourcing nor research with human subjects. Guidelines: ", "page_idx": 44}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u2022 Including this information in the supplemental material is fine, but if the main contribution of the paper involves human subjects, then as much detail as possible should be included in the main paper.   \n\u2022 According to the NeurIPS Code of Ethics, workers involved in data collection, curation, or other labor should be paid at least the minimum wage in the country of the data collector. ", "page_idx": 44}, {"type": "text", "text": "15. Institutional Review Board (IRB) Approvals or Equivalent for Research with Human Subjects ", "text_level": 1, "page_idx": 44}, {"type": "text", "text": "Question: Does the paper describe potential risks incurred by study participants, whether such risks were disclosed to the subjects, and whether Institutional Review Board (IRB) approvals (or an equivalent approval/review based on the requirements of your country or institution) were obtained? ", "page_idx": 44}, {"type": "text", "text": "Answer: [No] ", "page_idx": 45}, {"type": "text", "text": "Justification: The paper does not involve crowdsourcing nor research with human subjects. Guidelines: ", "page_idx": 45}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u2022 Depending on the country in which research is conducted, IRB approval (or equivalent) may be required for any human subjects research. If you obtained IRB approval, you should clearly state this in the paper.   \n\u2022 We recognize that the procedures for this may vary significantly between institutions and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the guidelines for their institution.   \n\u2022 For initial submissions, do not include any information that would break anonymity (if applicable), such as the institution conducting the review. ", "page_idx": 45}]