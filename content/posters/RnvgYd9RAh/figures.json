[{"figure_path": "RnvgYd9RAh/figures/figures_1_1.jpg", "caption": "Figure 1: (A) A non-expert listener (who does not know the answer to the question already) accepts or rejects answers based on how confident they sound. This confidence is influenced by implicit and explicit markers. (B) To calibrate a speaker model's confidence, we train a listener-aware speaker model by bootstrapping data from a base speaker model. For each training question, we generate k diverse responses. These are scored for correctness against the gold answers and accepted or rejected by a listener model. Our preference function rewards true accepts and true rejects and penalizes false accepts and false rejects. (C) Before training, models tend to be confident regardless of whether they are right or wrong. After training, listener-aware models are more confident when they are correct and less confident when they are wrong.", "description": "This figure demonstrates the LACIE framework. Panel A shows how a listener judges the model's answer based on perceived confidence (both implicit and explicit). Panel B illustrates the data generation process using a base speaker model and a listener model to create preference data for fine-tuning.  Panel C highlights the difference in confidence calibration before and after listener-aware training.", "section": "3.2 Listener-Aware Preference Data Creation Methodology"}, {"figure_path": "RnvgYd9RAh/figures/figures_4_1.jpg", "caption": "Figure 1: (A) A non-expert listener (who does not know the answer to the question already) accepts or rejects answers based on how confident they sound. This confidence is influenced by implicit and explicit markers. (B) To calibrate a speaker model\u2019s confidence, we train a listener-aware speaker model by bootstrapping data from a base speaker model. For each training question, we generate k diverse responses. These are scored for correctness against the gold answers and accepted or rejected by a listener model. Our preference function rewards true accepts and true rejects and penalizes false accepts and false rejects. (C) Before training, models tend to be confident regardless of whether they are right or wrong. After training, listener-aware models are more confident when they are correct and less confident when they are wrong.", "description": "This figure illustrates the LACIE framework. Panel A shows how a listener judges the confidence of an answer based on both explicit (e.g., numeric score) and implicit (e.g., tone) cues. Panel B details the data generation process, where a base speaker model generates diverse answers, a listener model judges them, and a preference function guides training. Panel C contrasts the confidence behavior of models before and after LACIE training, showing improved calibration.", "section": "1 Introduction"}, {"figure_path": "RnvgYd9RAh/figures/figures_8_1.jpg", "caption": "Figure 2: Induced listener probabilities for LACIE-trained and baseline models (Mistral-7B). Baselines have similar scores for correct and incorrect examples; LACIE results in significantly lower scores for incorrect answers.", "description": "The figure shows the average induced listener probability for correct and incorrect answers for three different models: LACIE, Base, and Truthful.  The x-axis represents the model, and the y-axis represents the listener probability. The bars are grouped by whether the answer was correct or incorrect.  The key takeaway is that the LACIE model shows a significantly lower probability for incorrect answers compared to the base and truthful models, indicating that LACIE successfully trains the model to better differentiate between correct and incorrect answers.", "section": "5 Discussion and Analysis"}, {"figure_path": "RnvgYd9RAh/figures/figures_9_1.jpg", "caption": "Figure 3: Frequency of qualitative categories in trained and reference models. LACIE training results in more hedging and abstaining for incorrect examples and more detailed answers for correct ones.", "description": "This figure is a grouped bar chart showing the frequency of different qualitative categories in the responses generated by the trained model (LACIE) and the reference model.  The categories are: details, explicit, implicit, concise, hedge, irrelevant, and abstain. The chart is divided into two sections: \"Correct\" and \"Incorrect\", representing whether the generated answer was correct or incorrect according to the ground truth.  The chart visually demonstrates that LACIE training leads to a noticeable shift in response characteristics.  Specifically, for incorrect answers, the LACIE model shows a greater tendency to hedge or abstain. Conversely, for correct answers, it shows a stronger preference for providing more detailed explanations. This supports the paper's argument that LACIE improves calibration by encouraging more appropriate expressions of confidence.", "section": "Qualitative Analysis"}, {"figure_path": "RnvgYd9RAh/figures/figures_13_1.jpg", "caption": "Figure 4: Precision and AUROC as the size of the training data increases. LACIE generally continues improving with more data.", "description": "This figure shows the performance of the LACIE model on the TriviaQA dataset as the amount of training data increases.  The x-axis represents the number of training questions used, and the y-axis shows the precision and AUROC (Area Under the Receiver Operating Characteristic curve). The plot demonstrates that both precision and AUROC generally improve as more training data is used, suggesting that LACIE's performance continues to increase with more data, although the rate of improvement may start to decrease at a larger number of training questions.", "section": "4.2 Results with Modeled Listener"}, {"figure_path": "RnvgYd9RAh/figures/figures_15_1.jpg", "caption": "Figure 5: Abstained answers have more unique answers from base model, indicating higher uncertainty.", "description": "This histogram visualizes the distribution of the number of unique answers generated by an untrained Mistral-7B model for two groups of questions from the TriviaQA dataset: those where a LACIE-trained Mistral-7B model abstained (orange bars) and those where it did not (blue bars).  The x-axis represents the number of unique answers, and the y-axis represents the count of questions.  The figure shows a clear separation between the two distributions, indicating that questions where the LACIE model abstained (i.e., expressed uncertainty) had a significantly higher number of unique answers generated by the untrained model compared to questions where the LACIE model didn't abstain. This suggests that the LACIE model successfully learned to identify and abstain from questions it was uncertain about.", "section": "4.2 Results with Modeled Listener"}, {"figure_path": "RnvgYd9RAh/figures/figures_17_1.jpg", "caption": "Figure 1: (A) A non-expert listener (who does not know the answer to the question already) accepts or rejects answers based on how confident they sound. This confidence is influenced by implicit and explicit markers. (B) To calibrate a speaker model's confidence, we train a listener-aware speaker model by bootstrapping data from a base speaker model. For each training question, we generate k diverse responses. These are scored for correctness against the gold answers and accepted or rejected by a listener model. Our preference function rewards true accepts and true rejects and penalizes false accepts and false rejects. (C) Before training, models tend to be confident regardless of whether they are right or wrong. After training, listener-aware models are more confident when they are correct and less confident when they are wrong.", "description": "This figure illustrates the listener-aware finetuning method (LACIE). (A) shows how a listener judges the confidence of an answer based on implicit and explicit markers. (B) details the data generation process, where a speaker model generates answers, a listener model judges them, and a preference function is used to create training data. (C) compares the confidence of models before and after training with LACIE, highlighting improved calibration.", "section": "3 Methodology"}]