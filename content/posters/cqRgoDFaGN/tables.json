[{"figure_path": "cqRgoDFaGN/tables/tables_1_1.jpg", "caption": "Figure 1: (Left) Problem Setting. We find the same sampling strategy gets different performances with different data. (Right) Performance of FasterDiT. We improve Diffusion Transformers (DiT) training speed by a large margin without any architecture modification.", "description": "This figure shows a comparison of the performance of different methods for training diffusion transformers. The left side shows that the same sampling strategy can have different performances depending on the data. The right side shows that the proposed method, FasterDiT, significantly improves the training speed of diffusion transformers without any architectural modifications.", "section": "1 Introduction"}, {"figure_path": "cqRgoDFaGN/tables/tables_6_1.jpg", "caption": "Table 7: Training Details. Our training pipeline involves only minimal modifications to the code.", "description": "This table displays ablation studies conducted to analyze the impact of two key modifications to the training pipeline on the FID-50k score. The first modification is 'multi-step balance', and the second is 'velocity direction loss'.  The table shows the FID-50k scores achieved at 150k, 200k, and 400k training steps with different combinations of these modifications, demonstrating their effects on training efficiency.", "section": "4 Improving DiT Training"}, {"figure_path": "cqRgoDFaGN/tables/tables_7_1.jpg", "caption": "Table 1: Performance of FasterDiT on ImageNet 256\u00d7256. Employing the identical architecture as DiT [37], FasterDiT achieves comparable performance with an FID of 2.30, yet requires only 1,000k iterations to converge.", "description": "This table compares the performance of FasterDiT with other state-of-the-art image generation models on the ImageNet dataset at a resolution of 256x256.  The key metrics compared are FID (Frechet Inception Distance), which measures the similarity between generated images and real images, and Inception Score (IS), which measures the quality and diversity of the generated images.  FasterDiT shows a comparable FID score to other top-performing models but achieves this in significantly fewer training iterations, highlighting its improved training efficiency.  The table also includes other metrics such as  sFID, Precision, and Recall.", "section": "4.3 Comparison with Previous Methods"}, {"figure_path": "cqRgoDFaGN/tables/tables_9_1.jpg", "caption": "Table 3: Performance with Different Architectures", "description": "This table shows the performance of FasterDiT when applied to different diffusion model architectures beyond DiT, including Latent Diffusion Models (LDM) using the UNet architecture and U-ViT.  The results demonstrate improvements in FID-10k scores for both U-ViT and UNet when using FasterDiT's training methodology, suggesting that the approach can generalize across a broader range of architectures.", "section": "4.5 Performance with Different Diffusion Architectures"}, {"figure_path": "cqRgoDFaGN/tables/tables_16_1.jpg", "caption": "Table 4: Training Details of Section 3", "description": "This table details the hyperparameters used for training the model in Section 3 of the paper.  It includes specifications for the optimizer, learning rate, weight decay, batch size, number of training iterations, dataset used, image resolution, number of workers utilized for parallel processing, loss function, pre-computation of VAE features, timestep sampling strategy and data augmentation techniques. This information is crucial for understanding the experimental setup of the experiments presented in that section.", "section": "3 What can we learn from SNR PDF?"}, {"figure_path": "cqRgoDFaGN/tables/tables_16_2.jpg", "caption": "Table 5: Training Details of Section 4", "description": "This table shows the hyperparameters used in the training process of the FasterDiT model in Section 4 of the paper. It includes details such as the optimizer, learning rate, weight decay, batch size, number of training iterations, dataset used, image resolution, number of workers, loss function, whether VAE features were precomputed, the timestep sampling strategy, and data augmentation techniques.", "section": "4 Improving DiT Training"}, {"figure_path": "cqRgoDFaGN/tables/tables_16_3.jpg", "caption": "Table 6: Sampling Details of Section 3", "description": "This table presents the hyperparameters used for sampling in Section 3 of the paper.  It details the resolution, batch size per GPU, number of classes, CFG scale, number of samples, number of sampling steps, global seed, and whether tf32 was used.", "section": "A.2 Details of Sampling"}, {"figure_path": "cqRgoDFaGN/tables/tables_16_4.jpg", "caption": "Table 7: Sampling Details of Section 4", "description": "This table lists the hyperparameters used for sampling in Section 4 of the paper.  It details settings for resolution, batch size per GPU, number of classes, CFG (classifier-free guidance) scale, the number of samples used for evaluation, the adaptive sampling step scheme, the global random seed, and the use of tf32 precision.", "section": "4.1 Improving Multiple Step Balance"}]