[{"figure_path": "ZJBBeyEAyX/tables/tables_1_1.jpg", "caption": "Table 1: Comparison to previous label-only attacks. We report the highest attack precision that these attacks can achieve with a recall greater than 1% on CIFAR-10 using a ResNet18 model.", "description": "This table compares the proposed One-Shot Label-Only (OSLO) membership inference attack with existing state-of-the-art label-only attacks. It shows that OSLO significantly outperforms existing methods in terms of attack precision while requiring only a single query, in contrast to thousands of queries needed by other methods.", "section": "Comparison to previous label-only attacks"}, {"figure_path": "ZJBBeyEAyX/tables/tables_4_1.jpg", "caption": "Table 1: Comparison to previous label-only attacks. We report the highest attack precision that these attacks can achieve with a recall greater than 1% on CIFAR-10 using a ResNet18 model.", "description": "This table compares the performance of the proposed One-Shot Label-Only (OSLO) membership inference attack against existing state-of-the-art label-only attacks.  It shows that OSLO significantly outperforms previous methods in terms of attack precision, even though it requires only a single query to the target model, while others need thousands of queries. The table highlights the number of queries each attack requires and the highest attack precision achieved with a recall above 1% on the CIFAR-10 dataset using a ResNet18 model.", "section": "Comparison to previous label-only attacks"}, {"figure_path": "ZJBBeyEAyX/tables/tables_8_1.jpg", "caption": "Table 2: OSLO performance on CIFAR-10 with ResNet18 when target and surrogate models are trained using different algorithms.", "description": "This table presents the results of the OSLO attack on the CIFAR-10 dataset using a ResNet18 model.  The experiment investigates the impact of training the target and surrogate models with different optimization algorithms (SGD vs. Adam) on the attack's performance. It reports the attack precision (when recall is greater than 1%) and the true positive rate (TPR) at a 1% false positive rate (FPR). The results show that OSLO maintains high precision and TPR even when the target and surrogate models are trained with different optimizers.", "section": "5 Ablation study"}, {"figure_path": "ZJBBeyEAyX/tables/tables_8_2.jpg", "caption": "Table 3: Attack TPR and FPR of OSLO without validation models on CIFAR-10 using ResNet18.", "description": "This table presents the results of the OSLO attack on CIFAR-10 using a ResNet18 model without the use of validation models.  It shows the true positive rate (TPR) and false positive rate (FPR) achieved by the attack at different perturbation budgets (epsilon). The absence of validation models causes significantly reduced attack effectiveness as the TPR and FPR are very low at all perturbation budgets.", "section": "5.3 Impact of validation models in OSLO"}, {"figure_path": "ZJBBeyEAyX/tables/tables_13_1.jpg", "caption": "Table 4: Summary of dataset splits for training and evaluation.", "description": "This table details the data split used for training the target model and the source/validation models for the experiments.  For CIFAR-10 and CIFAR-100, half of the training set (25,000 samples) was used for each.  For SVHN, two disjoint subsets of 5,000 samples were created. The table shows the number of samples used for training the target model, the number of samples used for training the source and validation models, and the number of samples used for evaluation (1,000 members and 1,000 non-members for each dataset).", "section": "4.1 Experimental setup"}, {"figure_path": "ZJBBeyEAyX/tables/tables_13_2.jpg", "caption": "Table 5: Source and validation model configurations per dataset in the default OSLO setup.", "description": "This table details the specific model architectures used for both source and validation models in the OSLO attack.  For each dataset (CIFAR-10, CIFAR-100, and SVHN), it lists the number of models of each architecture type used for generating adversarial examples (source models) and for regulating the perturbation magnitude (validation models). The total number of surrogate models used in the attack for each dataset is also provided.", "section": "4.1 Experimental setup"}, {"figure_path": "ZJBBeyEAyX/tables/tables_14_1.jpg", "caption": "Table 6: Hyperparameter configurations for defenses evaluated against OSLO.", "description": "This table presents the hyperparameter configurations used for evaluating six different defense mechanisms against OSLO. For each defense, three different hyperparameter values were used to train the defended models. The defenses include L2 Regularization, L1 Regularization, Adversarial Regularization, Dropout, and DPSGD. The hyperparameters for each defense are listed, along with the specific values used in the experiments.  This allows reproducibility of the experiments and better understanding of the experimental setup.", "section": "4.1 Experimental setup"}, {"figure_path": "ZJBBeyEAyX/tables/tables_15_1.jpg", "caption": "Table 1: Comparison to previous label-only attacks. We report the highest attack precision that these attacks can achieve with a recall greater than 1% on CIFAR-10 using a ResNet18 model.", "description": "This table compares the performance of the proposed OSLO attack against existing state-of-the-art label-only membership inference attacks.  It shows that OSLO achieves significantly higher attack precision than previous methods, even though it only requires a single query to the target model, while others require many more queries (~6000). The table highlights the significant improvement in attack precision of OSLO even under strict conditions (recall greater than 1% on CIFAR-10 using a ResNet18 model).", "section": "1 Introduction"}, {"figure_path": "ZJBBeyEAyX/tables/tables_16_1.jpg", "caption": "Table 8: OSLO's performance against target models trained with adversarial training on CIFAR-10.", "description": "This table presents the results of evaluating OSLO's performance against ResNet18 target models that were trained with and without adversarial training.  The table shows the test accuracy (ACC), training time, and OSLO's attack performance (TPR and FPR) at different thresholds (T) for both scenarios. It demonstrates the impact of adversarial training on the effectiveness of the OSLO attack.", "section": "5.3 Impact of validation models in OSLO"}, {"figure_path": "ZJBBeyEAyX/tables/tables_16_2.jpg", "caption": "Table 8: OSLO's performance against target models trained with adversarial training on CIFAR-10.", "description": "This table presents the results of evaluating OSLO's performance against target models trained with adversarial training using ResNet18 on CIFAR-10. It shows the attack's TPR and FPR under different thresholds (T) when the target model was trained without adversarial training or with adversarial training (\u20ac=4/255).  This highlights the impact of adversarial training on OSLO's effectiveness.", "section": "5.3 Impact of validation models in OSLO"}]