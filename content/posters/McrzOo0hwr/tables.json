[{"figure_path": "McrzOo0hwr/tables/tables_8_1.jpg", "caption": "Table 1: Average 5-way 1-shot classification accuracies in mini-ImageNet with reported standard deviations (3 runs). With \u03b1 = 0.5, the best results are in bold.", "description": "This table presents the average 5-way 1-shot classification accuracies achieved by different meta-learning methods on the mini-ImageNet dataset.  The results are averaged over three runs, and the standard deviations are also reported.  The best-performing method for each metric (average, worst-case, and CVaR) is highlighted in bold.  The confidence level (\u03b1) used for the CVaR calculation is 0.5.", "section": "5.3 Few-shot Image Classification"}, {"figure_path": "McrzOo0hwr/tables/tables_8_2.jpg", "caption": "Table 2: Meta testing returns in point robot navigation (4 runs). The chart reports average return and CVaR return with \u03b1 = 0.5.", "description": "This table presents the results of meta-testing in a 2D point robot navigation task. Four runs were conducted with a confidence level of \u03b1 = 0.5.  The table compares the average return and the Conditional Value at Risk (CVaR) for several methods: MAML, DRO-MAML, DR-MAML, and the proposed DR-MAML+.  The average return reflects the overall performance, while the CVaR indicates robustness to the worst-case scenarios.", "section": "5.4 Meta Reinforcement Learning"}, {"figure_path": "McrzOo0hwr/tables/tables_18_1.jpg", "caption": "Table 3: A summary of robust fast adaptation methods. We take MAML as an example, list related methods, and report their characteristics in literature. We mainly report the statistics according to whether existing literature works include the generalization analysis and convergence analysis. The form of meta learner and the robustness type are generally connected.", "description": "This table compares several meta-learning methods focusing on their robustness to distributional shifts in the task space.  It highlights key differences in the meta-learning objective function, whether generalization and convergence properties have been theoretically analyzed, and the type of robustness each method aims to achieve (e.g., worst-case robustness or robustness to tail risk). The table helps to contextualize the proposed DR-MAML+ method within the existing landscape of robust fast adaptation techniques.", "section": "A.1 Technical Comparison in Robust Fast Adaptation"}, {"figure_path": "McrzOo0hwr/tables/tables_30_1.jpg", "caption": "Table 4: Computational and memory cost in MaPLe relevant experiments.", "description": "This table shows the computational time and memory usage for three different methods: MaPLe, DR-MaPLe, and DR-MaPLe+.  The baseline MaPLe's time and memory are given, and the additional time and memory required by DR-MaPLe and DR-MaPLe+ are shown relative to MaPLe. This allows for comparison of the computational cost associated with each method.", "section": "D Implementation Details"}, {"figure_path": "McrzOo0hwr/tables/tables_31_1.jpg", "caption": "Table 5: MSEs for Sinusoid 5-shot with reported standard deviations (5 runs). With \u03b1 = 0.7, the best results are in bold.", "description": "This table presents the Mean Squared Errors (MSEs) for the Sinusoid 5-shot experiment, comparing different meta-learning methods.  The results are averaged over five runs, and the best performance for each metric (Average, Worst, CVaRa) is highlighted in bold.  The \u03b1 value of 0.7 indicates the confidence level used for calculating the CVaRa (Conditional Value at Risk).  The table showcases the performance of various methods in handling task distribution shifts, particularly focusing on robustness to tail risk events.", "section": "E.1 Evaluation with Other Robust Meta Learners"}, {"figure_path": "McrzOo0hwr/tables/tables_32_1.jpg", "caption": "Table 5: MSEs for Sinusoid 5-shot with reported standard deviations (5 runs). With \u03b1 = 0.7, the best results are in bold.", "description": "This table presents the Mean Squared Errors (MSEs) for the Sinusoid 5-shot experiment across different methods.  It compares the performance of various robust meta-learning approaches, including CNP, TR-CNP, DRO-CNP, DR-CNP, and the proposed DR-CNP+. The results are averaged over 5 runs, and the best performance for each metric (Average, Worst, and CVaR\u03b1) is highlighted in bold. The confidence level (\u03b1) used for the CVaR\u03b1 calculation is 0.7. This table demonstrates the relative performance of different robustness strategies in handling tail risks in the task distribution.", "section": "E.1 Evaluation with Other Robust Meta Learners"}, {"figure_path": "McrzOo0hwr/tables/tables_32_2.jpg", "caption": "Table 7: Test average mean square errors (MSEs) with reported standard deviations for sinusoid regression (5 runs). We respectively consider 5-shot and 10-shot cases with \u03b1 = 0.7. The results are evaluated across the 490 meta-test tasks, as in [42]. The best results are in bold.", "description": "This table presents the average, worst-case, and CVaR mean squared errors (MSEs) for 5-shot and 10-shot sinusoid regression tasks.  The results are based on five runs and cover 490 unseen test tasks.  Lower MSE values indicate better performance.  The bold values highlight the best-performing method for each metric.", "section": "5.1 Sinusoid Regression"}, {"figure_path": "McrzOo0hwr/tables/tables_32_3.jpg", "caption": "Table 1: Average 5-way 1-shot classification accuracies in mini-ImageNet with reported standard deviations (3 runs). With a = 0.5, the best results are in bold.", "description": "This table presents the average 5-way 1-shot classification accuracies achieved by different meta-learning methods on the mini-ImageNet dataset.  The results are reported with standard deviations, calculated over three runs. The table compares the performance of various methods under two different experimental setups, using eight meta-training tasks and four meta-testing tasks.  The best results are highlighted in bold for each evaluation metric (Average, Worst, CVaR\u03b1).  \u03b1 = 0.5 represents the confidence level.", "section": "5.3 Few-shot Image Classification"}]