[{"figure_path": "McrzOo0hwr/figures/figures_3_1.jpg", "caption": "Figure 1: Illustration of optimization stages in distributionally robust meta learning from a Stackelberg game. Given the DR-MAML example, the pipeline can be interpreted as bi-level optimization: the leader's move for characterizing tail task risk and the follower's move for robust fast adaptation.", "description": "This figure illustrates the two-stage optimization process in distributionally robust meta-learning, framed as a Stackelberg game.  Stage I (the leader's move) involves modeling the risk distribution using kernel density estimation (KDE) and selecting a subset of tasks based on their risk. Stage II (the follower's move) updates the meta-learner's parameters using a sub-gradient method based on the screened subset from Stage I. The figure highlights the interplay between risk assessment and parameter updates, demonstrating how this approach increases robustness in meta-learning.", "section": "4 Theoretical Investigations"}, {"figure_path": "McrzOo0hwr/figures/figures_4_1.jpg", "caption": "Figure 2: The sketch of theoretical and empirical contributions in two-stage robust strategies. On the left side is the two-stage distributionally robust strategy [1]. The contributed theoretical understanding is right-down, with the right-up the empirical improvement. Arrows show connections between components.", "description": "This figure summarizes the theoretical and empirical contributions of the paper's proposed two-stage robust strategy.  The left side depicts the original two-stage strategy from existing work [1]. The right-hand side shows the contributions made by this paper. The theoretical contributions, including the solution concept, convergence rate analysis, and generalization bound, are shown in the lower right.  The empirical improvements, which involve extensive evaluations, are shown in the upper right. The arrows illustrate the relationships and connections between different parts of the approach and the findings.", "section": "Theoretical Investigations"}, {"figure_path": "McrzOo0hwr/figures/figures_7_1.jpg", "caption": "Figure 3: Meta testing performance in sinusoid regression problems (5 runs). The charts report testing mean square errors (MSEs) over 490 unseen tasks [42] with \u03b1 = 0.7, where black vertical lines indicate standard error bars.", "description": "This figure presents the results of meta-testing on sinusoid regression problems.  Five runs were conducted, and the mean squared error (MSE) is reported for each of the algorithms being compared. The x-axis shows the type of risk being minimized (Average, Worst-case, CVaR), while the y-axis shows the MSE values.  The different colored bars represent the various methods tested: MAML, TR-MAML, DRO-MAML, DR-MAML, and the proposed DR-MAML+. The black vertical lines indicate the standard error bars for each data point.  The figure demonstrates the performance differences among the methods when considering various risk measures, particularly when evaluating the robustness against unseen tasks.", "section": "5 Empirical Findings"}, {"figure_path": "McrzOo0hwr/figures/figures_8_1.jpg", "caption": "Figure 5: VaRa approximation errors with the crude MC and KDE. We compute the difference between the estimated VaR and the Oracle VaR in the absolute value |VaRa - VaR|.", "description": "This figure compares the approximation errors of two methods for estimating the Value at Risk (VaR) - Monte Carlo (MC) and Kernel Density Estimation (KDE).  The x-axis shows the size of the task batch used, representing the amount of data used in the approximation. The y-axis represents the absolute difference between the estimated VaR (from MC and KDE) and the true, or \"Oracle,\" VaR.  The plot demonstrates that KDE provides significantly more accurate VaR estimates, especially with smaller task batch sizes, indicating superior performance in scenarios with limited data.", "section": "Empirical Findings"}, {"figure_path": "McrzOo0hwr/figures/figures_9_1.jpg", "caption": "Figure 6: Meta testing results on 5-way 1-shot classification accuracies with reported standard deviations (3 runs). The charts respectively report classification accuracies over 150 unseen tasks. We further conduct few-shot image classification experiments in the presence of large model. Note that CLIP [68] exhibits strong zero-shot adaptation capability; hence, we employ \\\"ViT-B/16\\\"-based CLIP as the backbone to enable few-shot learning in the same way as MaPLe with training setup N_CTX = 2 and MAX_EPOCH = 30 [69], scaling to large neural networks in evaluation (See Appendix Section D for details).", "description": "This figure compares the performance of different meta-learning methods (CLIP, MaPLe, DR-MaPLe, DR-MaPLe+) on three different few-shot image classification datasets (tiered-ImageNet, ImageNetA, ImageNetSketch).  The results show classification accuracies (average and CVaR) across 150 unseen tasks for each method.  DR-MaPLe+ consistently outperforms other methods, demonstrating the effectiveness of the proposed approach, particularly in achieving robustness.", "section": "5.7 Compatibility with Large Models"}, {"figure_path": "McrzOo0hwr/figures/figures_20_1.jpg", "caption": "Figure 7: Diagram of risk concepts in this work. Here, the x-axis is the task risk value in fast adaptation given a specific \u03b8. The shadow-lined region illustrates the tail risk with a probability 1 \u2013 \u03b1 in the probability density. The area of the shadow-lined region after 1 \u2013 \u03b1 normalization corresponds to the expected tail risk CVaRa.", "description": "This figure visually explains the concepts of risk in the context of fast adaptation.  The x-axis represents the risk (l), and the y-axis shows both the probability density and the cumulative distribution function.  The blue curve is the probability density function of the risk, while the red curve is the cumulative distribution function. The figure highlights the mean, VaR\u03b1 (Value at Risk at level \u03b1), and CVaR\u03b1 (Conditional Value at Risk at level \u03b1). The shaded area represents the tail risk beyond VaR\u03b1, and its area (after normalization by 1-\u03b1) represents CVaR\u03b1.", "section": "3 Preliminaries"}, {"figure_path": "McrzOo0hwr/figures/figures_20_2.jpg", "caption": "Figure 8: Illustration of the asymptotic behavior in approximating the equilibrium. Here, the x-axis is the feasible task risk value in fast adaptation. The dark blue region indicates the histogram of the task risk values in the local Stackelberg equilibrium (q*, \u03b8*). The shallow blue region describes the histogram of the task risk values at some iterated point (qT-1, \u03b8meta). The sets T\u2081 and T\u2082 respectively collect the tasks resulting the opposite order.", "description": "This figure illustrates the concept of the asymptotic performance gap in the bi-level optimization process of the distributionally robust meta-learning algorithm. It shows two distributions: one representing the optimal equilibrium (q*, \u03b8*) and the other one representing an intermediate step (qT\u22121, \u03b8meta).  The dark blue area shows the distribution of task risk values at the equilibrium, while the light blue area highlights the difference between the intermediate and the equilibrium distributions. The sets T\u2081 and T\u2082 represent the tasks that contribute to the discrepancy between these two distributions. The figure visually explains how the algorithm iteratively approaches the Stackelberg equilibrium by reducing the difference between the two distributions.", "section": "4.2 Solution Concept & Properties"}, {"figure_path": "McrzOo0hwr/figures/figures_23_1.jpg", "caption": "Figure 9: Partition of the task subspace. Here we take two probability measure {q1,q2} \u2208 Qa for illustration. T\u2081 \u222a Tc and T\u2082 \u222a Tc defines the corresponding task subspaces for q1 and q2 with non-zero probability mass in the whole space T.", "description": "This figure illustrates the partitioning of the task space T into subsets based on the probability measures q1 and q2.  The overlap between the subsets represents tasks that have non-zero probability in both q1 and q2.", "section": "C.3 Proof of Proposition 1"}, {"figure_path": "McrzOo0hwr/figures/figures_29_1.jpg", "caption": "Figure 10: Typical meta learning benchmarks in evaluation.", "description": "This figure shows four typical meta-learning benchmarks used in the paper's experiments: (a) Sinusoid Regression, (b) System Identification, (c) Few-Shot Image Classification, and (d) Continuous Control.  Each subfigure visually represents the task structure and data involved in the respective benchmark.  The benchmarks are chosen to evaluate the performance of meta-learning models in various settings, testing their adaptability to diverse tasks and data characteristics.", "section": "Implementation Details"}, {"figure_path": "McrzOo0hwr/figures/figures_33_1.jpg", "caption": "Figure 11: Histograms of meta-testing performance in system identification. With \u03b1 = 0.5, we visualize the comprision results of baselines and our DR-MAML+ in 10-shot prediction. The lower, the better for Average and CVaR values.", "description": "This figure compares the performance of different meta-learning methods (MAML, TR-MAML, DRO-MAML, DR-MAML, and DR-MAML+) on a system identification task using 10-shot prediction.  The histograms show the distributions of mean squared errors (MSEs) for each method.  Lower MSEs indicate better performance. The figure also provides the average MSE and the Conditional Value at Risk (CVaR) for each method, offering a comprehensive view of the performance under both average and worst-case scenarios.", "section": "5 Empirical Findings"}, {"figure_path": "McrzOo0hwr/figures/figures_33_2.jpg", "caption": "Figure 12: Meta testing performance of DR-MAML and DR-MAML+ with different confidence level on Sinusoid 5-shot tasks. In the plots, the vertical axis is the MSEs, the horizontal axis is the confidence level, and the shaded area represents the standard deviation.", "description": "The figure shows the performance comparison of DR-MAML and DR-MAML+ under different confidence levels (alpha values) in the 5-shot sinusoid regression task.  It compares the average, worst-case, and CVaR (Conditional Value-at-Risk) performance of the two models across various confidence levels. The shaded area represents the standard deviation. DR-MAML+ shows more stable performance across different confidence levels, highlighting the robustness provided by the use of the KDE method for quantile estimation, compared to the more volatile performance of the original DR-MAML method.", "section": "5.3 Sensitivity Analysis to Confidence Level"}, {"figure_path": "McrzOo0hwr/figures/figures_33_3.jpg", "caption": "Figure 13: Meta testing performance of DR-MAML and DR-MAML+ with different confidence level on Sinusoid 5-shot tasks. In the plots, the vertical axis is the MSEs, the horizontal axis is the confidence level, and the shaded area represents the standard deviation.", "description": "The figure shows the impact of different confidence levels on the performance of DR-MAML and DR-MAML+ in the sinusoid 5-shot regression task.  Three subplots display the average, worst-case, and CVaR MSEs across various confidence levels. The shaded area in each subplot represents the standard deviation.  It illustrates the relative robustness and stability of DR-MAML+ compared to DR-MAML across different confidence levels.", "section": "5.3 Sensitivity Analysis to Confidence Level"}, {"figure_path": "McrzOo0hwr/figures/figures_34_1.jpg", "caption": "Figure 13: Meta testing performance of DR-MAML and DR-MAML+ with different confidence level on Sinusoid 5-shot tasks. In the plots, the vertical axis is the MSEs, the horizontal axis is the confidence level, and the shaded area represents the standard deviation.", "description": "This figure displays the meta-testing performance of DR-MAML and DR-MAML+ on 5-shot sinusoid regression tasks using different confidence levels.  The vertical axis represents the Mean Squared Error (MSE), and the horizontal axis represents the confidence level. Shaded areas indicate standard deviations, showing the variability in performance at each confidence level. The plots illustrate how performance varies across different evaluation metrics (Average, Worst, CVaR) as confidence level changes. This allows for a comparison of the two methods under varying levels of risk aversion.", "section": "5.3 Sensitivity Analysis to Confidence Level"}, {"figure_path": "McrzOo0hwr/figures/figures_34_2.jpg", "caption": "Figure 15: The fast adaptation risk landscape of meta-trained MAML, TR-MAML, DRO-MAML, DR-MAML and DR-MAML+. The figure illustrates a 5-shot sinusoid regression example, mapping to the function space f(x) = A sin(x - B). The X-axis and Y-axis represent the amplitude parameter a and phase parameter b respectively. The plots exhibit testing MSEs on the Z-axis across random trials of task generation.", "description": "This figure displays the risk landscapes for five different meta-learning methods (MAML, TR-MAML, DRO-MAML, DR-MAML, and DR-MAML+) on a 5-shot sinusoid regression task.  Each landscape shows how the mean squared error (MSE) of the model's fast adaptation varies depending on the amplitude (A) and phase (B) parameters of the sinusoidal function.  It allows for a visual comparison of the robustness of each method to variations in the task parameters.", "section": "E.4 Further Exploration on Adaptation"}]