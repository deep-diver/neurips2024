[{"type": "text", "text": "Quantifying Aleatoric Uncertainty of the Treatment Effect: A Novel Orthogonal Learner ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Valentyn Melnychuk1\\*, Stefan Feuerriegel' , Mihaela van der Schaar2   \n'LMU Munich & Munich Center for Machine Learning (MCML), Germany 2University of Cambridge & Alan Turing Institute, United Kingdom \\*Correspondence: melnychuk@lmu.de ", "page_idx": 0}, {"type": "text", "text": "Abstract ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Estimating causal quantities from observational data is crucial for understanding the safety and effectiveness of medical treatments. However, to make reliable inferences, medical practitioners require not only estimating averaged causal quantities, such as the conditional average treatment effect, but also understanding the randomness of the treatment effect as a random variable. This randomness is referred to as aleatoric uncertainty and is necessary for understanding the probability of benefit from treatment or quantiles of the treatment effect. Yet, the aleatoric uncertainty of the treatment effect has received surprisingly little attention in the causal machine learning community. To fill this gap, we aim to quantify the aleatoric uncertainty of the treatment effect at the covariate-conditional level, namely, the conditional distribution of the treatment effect (CDTE). Unlike average causal quantities, the CDTE is not point identifiable without strong additional assumptions. As a remedy, we employ partial identification to obtain sharp bounds on the CDTE and thereby quantify the aleatoric uncertainty of the treatment effect. We then develop a novel, orthogonal learner for the bounds on the CDTE, which we call AU-learner. We further show that our AU-learner has several strengths in that it satisfies Neymanorthogonality and is doubly robust. Finally, we propose a fully-parametric deep learning instantiation of our AU-learner. ", "page_idx": 0}, {"type": "text", "text": "1 Introduction ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Estimating causal quantities from observational data is crucial for decision-making in medicine [9, 12, 22, 30, 70]. For example, medical practitioners are interested in estimating the effect of chemotherapy vs. immunotherapy on patient survival from electronic health records to understand the best treatment strategies in cancer care. Here, common estimation targets are averaged causal quantities such as the average treatment effect (ATE) and the conditional average treatment effect (CATE), yet averaged causal quantities do not allow for understanding the variability of the treatment effect. ", "page_idx": 0}, {"type": "text", "text": "What is needed for the reliability of causal quantities in medicine? To obtain reliable causal quantities, one often needs to \u201cmove beyond the mean\" [44, 68] and consider the inherent randomness in the treatment effect as a random variable. This randomness is referred to as aleatoric uncertainty [17, 60, 110]. Quantifying the aleatoric uncertainty of the treatment effect is relevant in medical practice to understand the probability of benefit from treatment [26, 60] and the quantiles and variance of the treatment effect [5, 17, 26, 33, 59]. As an example, averaged quantities such as the CATE would simply suggest a positive effect for some patients, while the probability of benefit from treatment can inform patients about the odds of being negatively affected by the treatment. Hence, aleatoric uncertainty of the treatment effect promises additional, fine-grained insights beyond simple averages. ", "page_idx": 0}, {"type": "text", "text": "Methods for quantifying the aleatoric uncertainty of the treatment effect have gained surprisingly little attention in the causal machine learning community. So far, machine learning for treatment effect estimation was primarily focused on estimating averaged causal quantities [20, 57, 64, 69, 96, 98, 114, 125, 128]. Some research aims to quantify the epistemic uncertainty in treatment effect estimation [51] or the total uncertainty (but without distinguishing the types of uncertainty) [1, 67] 76]. Other works focused on the aleatoric uncertainty of the potential outcomes [13, 31, 65, 66, 94] or on contrasts between distributions of potential outcomes (also known as distributional treatment effects) [16, 29, 62, 92, 100].2 However, to the best of our knowledge, there is no comprehensive meta-learning theory for the estimation of the aleatoric uncertainty in the treatment effect. ", "page_idx": 0}, {"type": "image", "img_path": "RDsDvSHGkA/tmp/402543687971df5c59eaf1eb5d5bac0288ffb4a086262eda344cb190f700854d.jpg", "img_caption": ["Figure 1: Identification and estimation of the conditional distribution of the treatment effect (CDTE) $\\equiv$ our setting) compared to the (well-studied) identification and estimation of the CATE. In this paper, we focus specifically on the CDF of the CDTE, $\\mathbb{P}(Y[1]-Y[0]\\leq\\delta\\mid x)$ , shown in orange. Our main contribution relates to the estimation, shown in yellow. However, moving from CATE identification and estimation to our setting comes with important challenges: $\\textcircled{1}$ CATE (shown in green) is point identifiable but the CDTE is not (shown in blue); $\\circled{2}$ there is no closed-form expression of the target estimand in terms of nuisance functions and, because of that, CATE learners cannot be directly adapted for estimation; and $\\circled{3}$ CATE is an unconstrained target estimand whereas Makarov bounds (shown in gray\uff09 are monotonous and contained in the interval $[0,1]$ "], "img_footnote": [], "page_idx": 1}, {"type": "text", "text": "", "page_idx": 1}, {"type": "text", "text": "In this paper, we aim to quantify the aleatoric uncertainty of the treatment effect at the covariateconditional level in the form of a conditional distribution of the treatment effect (CDTE). Knowing the CDTE would automatically allow one to compute the above-mentioned quantities of aleatoric uncertainty, namely, the probability of benefit from treatment and the quantiles and variance of the treatment effect, at both population and covariate-conditional levels. ", "page_idx": 1}, {"type": "text", "text": "1.1 Challenges ", "text_level": 1, "page_idx": 1}, {"type": "text", "text": "Yet, the identification and estimation of the CDTE in contrast to CATE come with three challenges as follows (see Fig. 1): ", "page_idx": 1}, {"type": "text", "text": "Challenge $\\textcircled{1}$ is that the CDTE does not allow for point identifiable, neither in the potential outcomes framework nor in randomized control trials due to the fundamental problem of causal inference as counterfactual outcomes can not be observed [26, 88]. We thus employ partial identification [48] to obtain bounds on the CDTE and thereby quantify the aleatoric uncertainty of the treatment effect. Specifically, we focus on Makarov bounds [87, 126, 129] that give sharp bounds for both the cumulative distribution function (CDF) and the quantiles of the CDTE. ", "page_idx": 1}, {"type": "text", "text": "Challenge $\\circled{2}$ is that there is no closed-form expression of the target estimand in terms of nuisance functions. Because of this, existing CATE learners cannot be directly adapted to our task of estimating Makarov bounds. For example, there are no orthogonal learners in the general setting, and existing approaches only use naive plug-in estimators/learners. Furthermore, even the derivation of the orthogonal loss is non-trivial as there is no efficient influence function at hand for the Makarov bounds. ", "page_idx": 1}, {"type": "text", "text": "", "page_idx": 2}, {"type": "text", "text": "Challenge $\\circled{3}$ is that CATE is an unconstrained target estimand whereas Makarov bounds are monotonous and contained in the interval [o, 1]. Notably, any constraints of the target estimand could be violated by orthogonal learners [71, 125]. Therefore, an orthogonal learner for Makarov bounds needs to be carefully adapted, especially to perform well in low-sample settings. ", "page_idx": 2}, {"type": "text", "text": "1.2 Our contributions ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "In this paper, we develop a novel, orthogonal learner for estimating Makarov bounds which we call $A U.$ learner, which allows to quantify the aleatoric uncertainty of the treatment effect. Our $A U$ -learner addresses allof the above-mentioned challenges $\\textcircled{1}-\\textcircled{3}$ .Further, our $A U.$ learner has several useful theoretical properties, such as satisfying Neyman-orthogonality and double robustness. Finally, we propose a flexible, fully-parametric deep learning instantiation of our $A U$ -learner. For this, we make use of conditional normalizing flows and call our method AU-CNFs. ", "page_idx": 2}, {"type": "text", "text": "To summarize, our contributions are as follows: 3 ", "page_idx": 2}, {"type": "text", "text": "1. We derive a novel, orthogonal leaner called AU-learner to quantify the aleatoric uncertainty of the treatment effect. For this, we estimate Makarov bounds on the CDF/quantiles of the conditional distribution of the treatment effect (CDTE).   \n2. We prove several favorable theoretical properties of our AU-learner, such as Neyman-orthogonality and double robustness.   \n3. We propose a flexible deep learning instantiation of our AU-learner based on conditional normalizing fows, which we call AU-CNFs, and demonstrate its effectiveness over several benchmarks. ", "page_idx": 2}, {"type": "image", "img_path": "RDsDvSHGkA/tmp/10c2f6c4d140249d843f194bb87c586d3209f350d7dda171f03b79261e0710f0.jpg", "img_caption": ["Figure 2: Total uncertainty of the treatment effect can have different sources. Both upper and lower plots have the same total uncertainty but vastly different aleatoric and epistemic components. Yet, aleatoric uncertainty is nonidentifiable (see Challenge $\\odot)$ "], "img_footnote": [], "page_idx": 2}, {"type": "text", "text": "2 Related Work ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "In the following, we briefly summarize the existing works on uncertainty quantification in the potential outcomes framework; on the identification of the CDTE; and on the estimation of Makarov bounds. For a more detailed overview of literature, we refer to Appendix A. ", "page_idx": 2}, {"type": "text", "text": "Uncertainty quantification in the potential outcomes framework. The (total) uncertainty of a predictive model in machine learning is generally split into (a) epistemic and (b) aleatoric uncertainty [41, 50].4 This split is important, as it informs a decision-maker about the source of uncertainty (see Fig. 2), especially in the context of the potential outcomes framework. (a) Epistemic uncertainty was studied for predictive models targeting at identifiable averaged causal quantities, such as conditional average potential outcomes (CAPOs) and CATE [51, 52]. (b) Aleatoric uncertainty, on the other hand, is only identifiable for potential outcomes [88]. Prominent methods focus on interventional (counterfactual) quantities such as: (i) CDF/quantiles estimation [6, 13, 31, 43, 86]; (ii) density estimation [65, 66, 91, 94, 97, 102, 124]; and (ii) distributional distances (also known as distributional treatment effects) estimation [16, 29, 62, 92, 100]. Yet, our work differs substantially from the above, as we aim at inferring the aleatoric uncertainty of the treatment effect, which is only partially identifiable. ", "page_idx": 2}, {"type": "table", "img_path": "RDsDvSHGkA/tmp/dbe71e9deb64c234bff93435458933753cd693204a48325ee94931b383bea8d6.jpg", "table_caption": ["Table 1: Overview of methods for estimating Makarov bounds on the CDF/quantiles of the CDTE. "], "table_footnote": ["(A-)IPTW: (augmented) inverse propensity of treatment weighted; DR: doubly robust "], "page_idx": 3}, {"type": "text", "text": "Identification of the distribution of the treatment effect. Point identification of the distribution of the treatment effect (or, equivalently, a joint distribution of potential outcomes) is only possible under additional assumptions on the data-generating mechanism. A common example is, e. g., invertibility of latent outcome noise [2, 3, 6]. Other works have rather focused on partial identification [48]. For example, [88] proposed sharp bounds for the distribution of the treatment effect under a monotonicity assumption. Later, assumption-free sharp bounds were proposed for both the joint CDF of potential outcomes [26] and for the variance of treatment effect [5], both known as Fr\u00e9chet-Hoeffding bounds [39, 49]. Finally, [26, 28, 33] proposed sharp bounds on the CDF/quantiles of the treatment effect without any additional assumptions, so-called Makarov bounds [87, 126]. Makarov bounds were further generalized [81, 129] and applied to other settings [17, 25, 27, 36, 59] but different from ours. ", "page_idx": 3}, {"type": "text", "text": "Estimation of Makarov bounds. Table 1 provides a comparison of key methods for estimating Makarov bounds, at both covariate-conditional and population levels. Existing methods build mainly upon plug-in (single-stage) estimators/learners. Examples are methods tailored for randomized controlled trials [26, 110] and for potential outcomes framework [17, 77, 110]. Crucially, these methods are not orthogonal and, thus, are sensitive to the misspecification of the nuisance functions. Nevertheless, we include the latter methods [17, 77] as baselines for our experiments as they use a highly flexible CDF estimator based on kernel density estimators. Some works also developed efficient estimators for Makarov bounds at the population level (analogous to the two-stage orthogonal learners at the covariate-conditional level) but only in highly restricted settings. In particular, [60] is restricted to binary outcomes, [112] assumed a known propensity score, and [54] made special optimization assumptions. In addition, all three works [54, 60, 112] suggest fixing a value of $\\delta/\\alpha$ which the CDF/quantiles of the treatment effect are evaluated at; when our work suggests targeting at severalvalues of $\\delta/\\alpha$ at once. Therefore, the previous methods are not applicable to our general setting of estimating covariate-conditional level Makarov bounds. ", "page_idx": 3}, {"type": "text", "text": "Research gap. To the best of our knowledge, we are the first to propose an orthogonal learner for estimating Makarov bounds on the CDF/quantiles of conditional distribution of the treatment effect. ", "page_idx": 3}, {"type": "text", "text": "3 Identification of Distribution of Treatment Effect ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "Notation. Let capital letters $X,A,Y,\\Delta$ denote random variables and small letters $x,a,y,\\delta$ their realizations from domains $\\mathcal{X},\\mathcal{A},\\mathcal{Y},\\varDelta$ . Let $\\mathbb{P}(Z)$ denote a distribution of some random variable $Z$ and let $\\mathbb{P}(Z=z)$ be the corresponding density or probability mass function. Furthermore, $\\pi(x)=$ $\\mathbb{P}(A=1\\mid X=\\stackrel{.}{x})$ is propensity score, $\\mu_{a}(x)\\stackrel{.}{=}\\mathbb{E}[Y\\mid X=\\dot{x},A=a)$ are conditional expectations, and $\\mathbb{F}_{a}(y\\mid x)=\\mathbb{P}(Y\\leq y\\mid x,a)$ is a conditional outcome CDF. For other conditional quantities or distributions, we use short forms whenever possible; e. g., $\\mathbb{E}(Y\\mid x)=\\mathbb{E}(Y\\mid X=x)$ . Further, $\\begin{array}{r}{\\mathbb{P}_{n}\\{f(Z)\\}=\\frac{1}{n}\\sum_{i=1}^{n}f(z_{i})}\\end{array}$ is a sample average of a random $f(Z)$ , where $n$ is the sample size. We denote linear rectifier functions as $[x]_{+}=\\operatorname*{max}(x,0)$ and $[x]_{-}=\\operatorname*{min}(x,0)$ , and sup/inf convolutions of two functions [1 $16]\\;f_{1}(\\cdot\\mid x),\\:f_{2}^{'}(\\cdot\\mid x)$ as $\\begin{array}{r}{(f_{1}\\mp f_{2})_{\\mathcal{Y}}(\\delta\\stackrel{\\cdot}{\\mid}x)=\\operatorname*{sup}_{y\\in\\mathcal{Y}}\\{f_{1}(y\\mid x)-f_{2}(y-\\delta\\mid x)\\}}\\end{array}$ and $\\begin{array}{r}{(f_{1}\\Eplus f_{2})_{\\mathcal{Y}}(\\delta\\mid x)=\\operatorname*{inf}_{y\\in\\mathcal{Y}}\\{f_{1}(y\\mid x)-f_{2}(y-\\delta\\mid x)\\}}\\end{array}$ ", "page_idx": 3}, {"type": "text", "text": "Problem setup. We consider the standard setting of the Neyman-Rubin potential outcomes framework [109]. That is, we have an observational dataset $\\mathcal{D}$ with a binary treatment $A\\in{\\mathcal{A}}=\\{0,1\\}$ \uff0c potentially high-dimensional covariates $X\\in\\mathcal{X}\\subseteq\\mathbb{R}^{d_{x}}$ and a continuous outcome $Y\\in\\mathcal{Y}\\subseteq\\mathbb{R}$ . For instance, a typical scenario is in cancer therapy, where the outcome is tumor growth, the treatment is whether chemotherapy is given, and the covariates include patient details like age and sex. We define a joint random variable $Z=(X,A,Y)$ $D=\\{x_{i},a_{i},y_{i}\\}_{i=1}^{n}$ is sampled i.i.d. from the observational distribution $\\mathbb{P}(Z)=\\mathbb{P}(X,Y,A)$ , where $n$ is the sample size. The potential outcomes framework then makes three (causal) assumptions, i. e., (1) consistency: if $A=a$ , then $Y[a]=Y$ ; (2) overlap: $\\mathbb{P}(0\\leq\\pi(X)\\leq1)=1$ ; and (3) exchangeability: $A\\perp(Y[0],Y[1])\\mid X.$ ", "page_idx": 3}, {"type": "text", "text": "", "page_idx": 4}, {"type": "text", "text": "Treatment effect distribution. In this paper, we refer to the treatment effect $\\Delta=Y[1]-Y[0]$ asa random variable.6 The CATE is given by $\\overrightharpoon{\\tau(x)}=\\mathbb{E}(\\Delta\\mid x)$ which is identifiable as $\\bar{\\mu_{1}}(x)-\\bar{\\mu}_{0}(x)$ under the causal assumptions (1)-(3). We are interested in identifying a conditional distribution of thetreatmenteffect $'C D T E)$ , specifically, its CDF or quantiles: ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathrm{\\mathbb{F}}(\\delta\\mid x)=\\mathbb{P}(\\Delta\\leq\\delta\\mid x)=\\mathbb{P}(Y[1]-Y[0]\\leq\\delta\\mid x),\\quad\\delta\\in\\varDelta}\\\\ &{\\mathrm{\\Sigma^{-1}}(\\alpha\\mid x)=\\operatorname*{inf}\\{\\delta\\in\\varDelta\\mid\\alpha\\leq\\mathbb{F}(\\delta\\mid x)\\},\\quad\\alpha\\in[0,1].}\\end{array}\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "The CDF and the quantiles of the CDTE are point non-identifiable due to the fundamental problem of causal inference, i. e., that the counterfactual outcome, $Y[1-A]$ , is never observed. This is illustrated in Fig. 3, where both conditional potential outcome distributions are identifiable as $\\mathbb{P}(Y[a]\\mid x)=\\bar{\\mathbb{P}}(Y\\mid x,a)$ ; but a conditional joint distribution, $\\mathbb{P}(Y[0],Y[1]\\mid x)$ , and the CDTE, $\\mathbb{P}(\\Delta\\mid x)$ ,arenot. ", "page_idx": 4}, {"type": "text", "text": "Partial identification of the CDTE. Fan et al. [26] proposed pointwise sharp bounds on the CDF and the quantiles of the CDTE, so-called Makarov bounds [87, 126, 129]. Given that the outcome $Y$ is continuous, the Makarov bounds for the CDF of the CDTE are given by linearly rectified sup/inf convolutions [116] of conditional CDFs of potential outcomes: ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\underline{{\\mathbf{F}}}(\\delta\\mid x)\\le\\mathbb{F}(\\delta\\mid x)\\le\\overline{{\\mathbf{F}}}(\\delta\\mid x),}&{}\\\\ {\\underline{{\\mathbf{F}}}(\\delta\\mid x)=[(\\mathbb{F}_{1}\\ast\\mathbb{F}_{0})_{\\mathcal{V}}(\\delta\\mid x)]_{+}\\quad\\mathrm{and}\\quad\\overline{{\\mathbf{F}}}(\\delta\\mid x)=1+[(\\mathbb{F}_{1}\\ast\\mathbb{F}_{0})_{\\mathcal{V}}(\\delta\\mid x)]_{-}\\,,}\\end{array}\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "where $\\delta\\in{\\varDelta}$ and $\\mathbb{F}_{a}(y\\mid x)$ is the CDF of $\\mathbb{P}(Y[a]\\mid x)$ . Similarly, Makarov bounds can be formulated for the quantiles of the CDTE: ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\overline{{\\mathbf{F}}}^{-1}(\\alpha\\mid x)\\le\\mathbb{F}^{-1}(\\alpha\\mid x)\\le\\underline{{\\mathbf{F}}}^{-1}(\\alpha\\mid x),}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad}\\\\ &{\\mathrm{~\\int_{-}^{-1}(\\alpha\\mid x)=\\left\\{\\!\\!\\begin{array}{l l}{(\\mathbb{F}_{1}^{-1}\\,\\pm\\mathbb{F}_{0}^{-1})_{[\\alpha,1]}(\\alpha\\mid x),}&{\\mathrm{~if~}\\alpha\\neq0,}\\\\ {\\mathbb{F}_{1}^{-1}(0\\mid x)-\\mathbb{F}_{0}^{-1}(1\\mid x),}&{\\mathrm{~if~}\\alpha=0,}\\end{array}\\right.}}\\end{array}\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "where $\\alpha~\\in~[0,1]$ and $\\mathbb{F}_{a}^{-1}(u~|~x)$ are the quantiles of $\\mathbb{P}(Y[a]\\ \\mid\\ x)$ : Then, under the causal assumptions (1)-(3), conditional distributions of potential outcomes coincide with observed ones, i. e., $\\mathbb{P}(Y[a])=\\mathbb{P}(Y\\mid x,a)$ . Notably, Makarov bounds on the CDFs are CDFs themselves, but these CDFs do not correspond to the solution of the partial identification task (which implies pointwise sharpness). We refer to Appendix B for more illustrations about the inference of the Makarov bounds, the explanation of pointwise sharpness, and Makarov bounds for categorical/mixed-type outcomes. ", "page_idx": 4}, {"type": "text", "text": "4 An AU-learner for estimating Makarov bounds ", "text_level": 1, "page_idx": 4}, {"type": "text", "text": "In the following, we develop a theory of orthogonal learning for Makarov bounds, which then gives rise to our $A U$ -learner. For this, we first review the plug-in learner and its shortcomings. Motivated by this, we then derive two-stage learners. Here, we first present a novel CA-learner in an intermediate step and finally our $A U.$ -learner. Note that both are novel but we frame our contributions around the $A U.$ -learner because of favorable theoretical properties. For notation, we use over- and underlines as in, e. g., $\\,{\\overline{{\\mathbf{F}}}}(\\delta\\mid x)$ to refer to the upper and/or lower bound. ", "page_idx": 4}, {"type": "text", "text": "4.1  Single-stage learners for Makarov bounds ", "text_level": 1, "page_idx": 4}, {"type": "text", "text": "Plug-in learner. A naive way to construct estimators for Makarov bounds [17, 26, 77, 110] is to estimate conditional outcome CDFs, $\\widehat{\\mathbb{F}}_{a}(y\\mid x)$ , and plug them into Eq. (3): ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\underline{{\\widehat{\\mathbf{F}}}}_{\\mathrm{PI}}(\\delta\\mid x)=\\left[(\\widehat{\\mathbb{F}}_{1}\\mp\\widehat{\\mathbb{F}}_{0})y(\\delta\\mid x)\\right]_{+}\\quad\\mathrm{and}\\quad\\widehat{\\overline{{\\mathbf{F}}}}_{\\mathrm{PI}}(\\delta\\mid x)=1+\\left[(\\widehat{\\mathbb{F}}_{1}\\ddag\\widehat{\\mathbb{F}}_{0})y(\\delta\\mid x)\\right]_{-}.\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "The plug-in learner for the bounds of the quantiles, $\\widehat{\\underline{{\\mathbf{F}}}}_{\\mathrm{PI}}^{-1}(\\alpha\\mid x)$ , can be obtained in a similar way but where one uses Eq. (4) and relies on the estimators of either the conditional outcome quantiles or inverse of the estimated conditional outcome CDFs, $\\widehat{\\mathbb{F}}_{a}^{-1}(u\\,|\\,x)$ ", "page_idx": 4}, {"type": "image", "img_path": "RDsDvSHGkA/tmp/bf0fbdfb9df302991c6f1eb4962d6c7b82c27320ed7bfa90b58d1b2050fce7d8.jpg", "img_caption": ["Figure 3: An example showing point non-identifiability of the distribution of the treatment effect based on the $i=7$ -th instance of the semi-synthetic IHDP100 dataset [46]. Shown are two datageneration models, indistinguishable in potential outcomes framework or RCTs, i. e., a monotone, $\\mathcal{M}_{\\mathrm{m}}$ , and an antitone, $\\mathcal{M}_{\\mathrm{a}}$ . For both models we also plot (a) conditional densities of potential outcomes, $\\mathbb{P}(Y[a]=y\\mid x_{7})$ and conditional joint laws of potential outcomes, $\\mathbb{P}(Y[0],Y[1]\\mid x_{7})$ and (b) corresponding CDFs of the CDTE (shown in blue), $\\mathbb{F}(\\delta\\ |\\ x_{7})=\\mathbb{P}(Y[1]-\\Bar{Y}[0]\\le\\Bar{\\delta}\\ |\\ x_{7})$ \uff0c together with Makarov bounds (shown in $\\underline{{\\overline{{\\mathrm{gray}}}}})$ and point identifiable CATE (shown in green), $\\tau(x_{7})=\\mathbb{E}(\\Delta\\mid x_{7})\\approx2.342$ .Non-identifiability of the CDTE is easy to see: Both data-generation models have the same conditional distributions of potential outcomes but different conditional joint laws and, thus, different CDTEs. The latter figures, ${\\bf(b)}$ , also demonstrate the bounds on the probability of benefit from treatment (a special case of Makarov bounds), $\\mathbb{P}(Y[1]-Y[0]\\le0\\mid x_{7})\\in[0,0.242]$ Hence, Makarov bounds are informative almost everywhere (except $\\delta=\\tau(x_{7}),$ "], "img_footnote": [], "page_idx": 5}, {"type": "text", "text": "Shortcomings. The plug-in learner suffers from two important shortcomings [96]. (a) The plug-in learner does not account for the selection bias, meaning that $\\mathbb{F}_{1}$ is estimated better for the treated population and $\\mathbb{F}_{0}$ for the untreated. Hence, it could be necessary to re-weight the loss wrt. to the propensity score. A remedy is to employ an inverse propensity of treatment weighted (IPTW) learner for both $\\mathbb{F}_{0}$ and $\\mathbb{F}_{1}$ [6, 43] (see Appendix C). (b) The plug-in learner does not target the Makarov bounds directly but rather the conditional outcome distributions. Therefore, it is unclear how to incorporate an inductive bias that the Makarov bounds are less heterogeneous than either of the conditional outcome $C D F s$ (i. e., the Makarov bounds can depend on a subset of covariates $X$ ).The second shortcoming thus motivates our derivation of two-stage learners. ", "page_idx": 5}, {"type": "text", "text": "4.2Two-stage learners for Makarov bounds ", "text_level": 1, "page_idx": 5}, {"type": "text", "text": "In order to address the above shortcomings of the plug-in learners, a two-stage learning theory was proposed [15, 35, 72, 96]. Yet, the two-staged learning theory is primarily built for simple target estimands (e. g., CATE) and therefore requires non-trivial adaptations by us to extend to Makarov bounds, which we do in the following. ", "page_idx": 5}, {"type": "text", "text": "Working model $\\&$ target risk. Our two-stage learners seek to find the best approximation of the ground-truth Makarov bounds, functional target estimands, by a (parametric) working model $\\mathcal{G}$ Formally, the working model is given $\\mathcal{G}=\\{g(\\delta,x)~\\vert~g:\\varDelta\\times\\mathcal{X}\\rightarrow[0,1]$ $g(\\cdot,x)$ is non-decreasing}. The best approximation $g_{*}$ is then obtained by minimizing a (population) target risk via $g_{\\ast}=$ arg $\\operatorname*{min}_{g\\in\\mathcal{G}}\\mathcal{L}(g)$ .7 In our setting, $\\mathcal{L}$ is chosen as some distributional distance between the target estimands and the working model. Specifically, we use continuous ranked probability score (CRPS) [40, 117] as a target risk for learning Makarov bounds on the CDF via ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\underline{{\\boldsymbol{\\overline{{Z}}}}}_{\\mathrm{CRPS}}(g)=\\mathbb{E}\\left(\\int_{\\boldsymbol{\\varDelta}}\\left(\\underline{{\\boldsymbol{\\overline{{\\mathbf{F}}}}}}(\\delta\\mid\\boldsymbol{X})-g(\\delta,\\boldsymbol{X})\\right)^{2}\\mathrm{d}\\delta\\right),\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "or squared Wasserstein-2 distance as a target risk for learning Makarov bounds on the quantiles via ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\overline{{\\mathcal{L}}}_{W_{2}^{2}}(g^{-1})=\\mathbb{E}\\left(\\int_{0}^{1}\\left(\\overline{{\\mathbf{E}}}^{-1}(\\alpha\\mid X)-g^{-1}(\\alpha,X)\\right)^{2}\\mathrm{d}\\alpha\\right).\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "The target risks in Eq. (6) and (7) cannot be directly minimized as we do not observe the ground-truth Makarov bounds. Yet, due to the identifiability results in Sec. 3, the Makarov bounds depend on the nuisance functions, $\\mathbb{F}_{a}(y\\mid x)$ , which can be estimated from the observational data. We perform that in the following. ", "page_idx": 6}, {"type": "text", "text": "From now on, we denote the ground-truth nuisance functions as $\\eta$ and their estimates as $\\hat{\\eta}$ .Also, we make the dependence on the target risks of the nuisance functions explicit; that is, we write the target risk as $\\mathcal{L}(g,\\eta)$ and the target estimands as $\\overline{{\\mathbf{f}}}(\\delta\\mid X;\\eta)$ and $\\underline{{\\mathbf{F}}}^{-1}(\\alpha\\mid X;\\eta)$ ", "page_idx": 6}, {"type": "text", "text": "Covariate-adjusted learner. A straightforward way to estimate and then minimize the target risk is to plug-in the estimates of conditional outcome CDFs, $\\widehat{\\mathbb{F}}_{a}(y\\mid x)$ , into Eq. (6) and (7), respectively. This yields the so-called covariateadjusted $(C A)$ learner, which aims at minimizing the following losses (empirical risks): ", "page_idx": 6}, {"type": "image", "img_path": "RDsDvSHGkA/tmp/f41d8c3626743f437c55e6fb69ba492baee086f012d8ef8a10d06118cdf38aa0.jpg", "img_caption": ["Figure 4: Comparison of learners for estimating Makarov bounds. "], "img_footnote": [], "page_idx": 6}, {"type": "equation", "text": "$$\n\\widehat{\\underline{{\\mathcal{L}}}}_{\\mathrm{PI,\\,CRPS}}(g,\\hat{\\eta}=(\\widehat{\\mathbb{F}}_{0},\\widehat{\\mathbb{F}}_{1}))=\\mathbb{P}_{n}\\Big\\{\\int_{{\\cal A}}\\big(\\underline{{\\overline{{\\mathbf{F}}}}}_{\\mathrm{PI}}(\\delta\\mid X;\\hat{\\eta})-g(\\delta,X)\\big)^{2}\\,\\mathrm{d}\\delta\\Big\\},\n$$", "text_format": "latex", "page_idx": 6}, {"type": "equation", "text": "$$\n\\widehat{\\underline{{\\mathcal{L}}}}_{\\mathrm{PI},W_{2}^{2}}(g^{-1},\\hat{\\eta}=(\\widehat{\\mathbb{F}}_{0}^{-1},\\widehat{\\mathbb{F}}_{1}^{-1}))=\\mathbb{P}_{n}\\Big\\{\\int_{0}^{1}\\big(\\overline{{\\mathbf{E}}}_{\\mathsf{P I}}^{-1}(\\alpha\\mid X;\\hat{\\eta})-g^{-1}(\\alpha,X)\\big)^{2}\\,\\mathrm{d}\\alpha\\Big\\},\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "where we call both $\\underline{{\\widehat{\\mathbf{F}}}}_{\\mathrm{PI}}(\\delta\\mid x;\\hat{\\eta})=\\underline{{\\widehat{\\mathbf{F}}}}_{\\mathrm{PI}}(\\delta\\mid x)$ and $\\underline{{\\overline{{\\mathbf{F}}}}}_{\\mathrm{PI}}^{-1}(\\alpha\\mid x;\\hat{\\eta})=\\underline{{\\widehat{\\mathbf{F}}}}_{\\mathrm{PI}}^{-1}(\\alpha\\mid x)$ pseudo $C D F s$ and pseudo-quantiles, respectively, and where both can be obtained from Eq. (5). ", "page_idx": 6}, {"type": "text", "text": "The CA-learner addresses the shortcoming ${\\bf(b)}$ of the plug-in learner from above in that loss minimization in the equations above targets directly at Makarov bounds. However, the shortcoming (a) of the selection bias still persists. Furthermore, a new shortcoming (c) now emerges: The losses can be highly sensitive to badly estimated nuisance functions so that $\\widehat{\\mathcal{L}}_{\\mathrm{PI}}(g,\\eta)$ and $\\widehat{\\mathcal{L}}_{\\mathrm{PI}}(g,\\widehat{\\eta})$ differ significantly. Next, we develop an orthogonal learner that addresses all of the shortcomings. ", "page_idx": 6}, {"type": "text", "text": "One-step bias correction. In order to address the before-mentioned shortcomings of the CA-learner, we employ the concept of (Neyman-)orthogonal losses [15, 35]. Informally, orthogonal losses are first-order insensitive to the misspecification of the nuisance functions, which introduces many favorable properties such as double robustness [127]. The CA-learner losses in Eq. (8) and (9) can be made orthogonal by performing a one-step bias correction [10, 63]. The one-step bias correction requires the knowledge of an efficient infuence function, which has not yet been derived for Makarov bounds $\\rightrightarrows$ Challenge $\\circled{2}$ ). Hence, the following theorem presents one of our main theoretical results. ", "page_idx": 6}, {"type": "text", "text": "Theorem 1 (Efficient influence function for Makarov bounds). Let $\\mathbb{P}$ denotes $\\mathbb{P}(Z)=\\mathbb{P}(X,A,Y)$ and let $y_{\\mathcal{V}}^{\\mp}(\\cdot\\mid x)$ and $u_{[\\alpha,1]}^{\\ast}(\\cdot\\mid x)$ be argmax/argmin sets of the convolutions $(\\mathbb{F}_{1}\\mp\\mathbb{F}_{0})_{\\mathcal{V}}(\\cdot\\mid x)$ and $(\\mathbb{F}_{1}^{-1}\\pm\\mathbb{F}_{0}^{-1})_{[\\alpha,1]}(\\cdot-0\\ensuremath{\\mathrm{~}}|\\ensuremath{\\mathrm{~}}x),$ respectively. Then, under mild conditions on the conditional outcome distributionsandfor almost allvalues of $\\delta\\in{\\varDelta}$ and for all values of $\\alpha\\in(0,1)$ (see Appendix $D$ average Makarov bounds are pathwise differentiable.Further, the corresponding efcient infuence functions, $\\phi$ are as follows: ", "page_idx": 6}, {"type": "equation", "text": "$$\n\\begin{array}{r l r}&{\\langle\\mathbb{E}(\\overline{{\\mathbf{E}}}(\\delta\\mid X));\\mathbb{P})=\\overline{{\\mathcal{L}}}(\\delta,Z;\\eta)+\\overline{{\\mathbf{E}}}(\\delta\\mid X;\\eta)-\\mathbb{E}(\\overline{{\\mathbf{E}}}(\\delta\\mid X;\\eta))}&{\\mathrm{(10)}}\\\\ &{\\langle\\mathbb{E}(\\overline{{\\mathbf{E}}}^{-1}(\\alpha\\mid X));\\mathbb{P})=\\overline{{\\mathcal{L}}}^{-1}(\\alpha,Z;\\eta)+\\overline{{\\mathbf{E}}}^{-1}(\\alpha\\mid X;\\eta)-\\mathbb{E}(\\overline{{\\mathbf{E}}}^{-1}(\\alpha\\mid X;\\eta)),}&\\\\ &{\\langle\\mathbb{J}(\\delta,Z;\\eta)=I(X;\\eta)\\left[\\frac{A}{\\pi(X)}\\left(\\mathbf{1}\\{Y\\leq y^{*}\\}-\\mathbb{P}_{1}\\left(y^{*}\\mid X\\right)\\right)-\\frac{1-A}{1-\\pi(X)}\\left(\\mathbf{1}\\{Y\\leq y^{*}-\\delta\\}-\\mathbb{P}_{0}\\left(y^{*}-\\delta\\mid X\\right)\\right)\\right],}&{\\mathrm{(11)}}\\\\ &{\\quad\\geq-1(\\alpha,Z;\\eta)=\\frac{A}{\\pi(X)}\\left(\\frac{\\mathbf{1}\\{Y\\leq\\mathbb{F}_{1}^{-1}\\left(u^{*}\\mid X\\right)\\}-u^{*}}{\\mathbb{P}\\left(Y=\\mathbb{F}_{1}^{-1}\\left(u^{*}\\mid X\\right)\\mid X,A=1\\right)}\\right)-\\frac{1-A}{1-\\pi(X)}\\left(\\frac{\\mathbf{1}\\{Y\\leq\\mathbb{F}_{0}^{-1}\\left(u^{*}-\\alpha+0\\mid X\\right)\\}-\\left(u^{*}-\\alpha+0\\mid X\\right)}{\\mathbb{P}\\left(Y=\\mathbb{F}_{0}^{-1}\\left(u^{*}-\\alpha+0\\mid X\\right)\\mid X,A=0\\right)}\\right)}&\\end{array}\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "where $I(X;\\eta)=\\mathbb{1}\\big\\{(\\mathbb{F}_{1}\\,\\mp\\mathbb{F}_{0})_{\\mathcal{Y}}(\\delta\\mid X)>0\\big\\}$ $y^{\\ast}$ is some value from the finite set $y_{\\mathcal{V}}^{\\mp}(\\delta\\mid X);\\,u^{*}$ is some valuefrom the fite set $u_{[\\alpha,1]}^{*}(\\alpha\\mid X)$ and $\\overline{{C}}(\\delta,Z;\\eta)$ and $\\overline{{C}}^{-1}(\\delta,Z;\\eta)$ can be then obtained by swapping the symbols $\\{\\mp,>,y_{\\mathcal{Y}}^{\\mp},u_{[\\alpha,1]}^{\\pm},-0,+0\\}\\;t o\\;\\{\\pm,<,y_{\\mathcal{Y}}^{\\pm},u_{[0,\\alpha]}^{\\mp},-1,+1\\}.$ Proof. See Appendix D. ", "page_idx": 6}, {"type": "text", "text": "In the above theorem, we use red color to show the nuisance functions of $\\mathbb{P}$ that are influencing the target estimand, i. e., averaged Makarov bounds. Therein, we also provide a Corollary 1, where we derive efficient influence functions for the target risks from Eq. (6) and (7), namely $\\phi(\\mathcal{L}(g);\\mathbb{P})$ ", "page_idx": 6}, {"type": "text", "text": "Note on infinite argmax/argmin sets. When argmax/argmin sets of the sup/inf-convolutions are infinite, average Makarov bounds are pathwise non-differentiable, and, thus, one-step bias correction is not possible as statistical inference becomes non-regular [47]. This result also holds for other causal quantities that contain sup/inf operators (e. g., for the policy value of the optimal treatment strategy [84, 106]). Although, there exist approaches to perform inference in the non-regular setting [84], we focus solely on the regular setting where pathwise differentiability holds (see Appendix D for a discussion on the generality of such a setting). ", "page_idx": 7}, {"type": "text", "text": "Orthogonalleaner $\\textbf{\\em A}\\!U$ learner). Given the derived efficient influence function for the target risks, weperform a $\\gamma.$ -scaled one-step bias correction [63] of the CA-learner losses, namely, $\\widehat{\\mathcal{L}}_{\\mathrm{PI}}(g,\\hat{\\eta})+$ $\\gamma\\mathbb{P}_{n}\\left\\{\\phi(\\mathcal{L}(g);\\hat{\\mathbb{P}})\\right\\}$ . The latter then yields our novel orthogonal $A U$ -learner (see Corollary 2 in Appendix D). Our $A U.$ -learner effectively resolves all the above-mentioned shortcomings (see a comparison in Fig. 4). Formally, it aims at minimizing one of the following losses: ", "page_idx": 7}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\widehat{\\underline{{C}}}_{\\mathrm{AU,\\,CRPS}}(g,\\widehat{\\eta}=(\\widehat{\\pi},\\widehat{\\mathbb{R}}_{0},\\widehat{\\mathbb{R}}_{1}))=\\mathbb{P}_{n}\\Big\\{\\int_{\\varDelta}\\big(\\overline{{\\mathbb{E}}}_{\\mathrm{DR}}(\\delta,Z;\\widehat{\\eta},\\gamma)-g(\\delta,X)\\big)^{2}\\,\\mathrm{d}\\delta\\Big\\},}\\\\ &{\\widehat{\\underline{{Z}}}_{\\mathrm{AU},W_{2}^{2}}(g^{-1},\\widehat{\\eta}=(\\widehat{\\pi},\\widehat{\\mathbb{R}}_{0}^{-1},\\widehat{\\mathbb{R}}_{1}^{-1}))=\\mathbb{P}_{n}\\Big\\{\\int_{0}^{1}\\big(\\overline{{\\mathbb{E}}}_{\\mathrm{DR}}^{-1}(\\alpha,Z;\\widehat{\\eta},\\gamma)-g^{-1}(\\alpha,X)\\big)^{2}\\,\\mathrm{d}\\alpha\\Big\\},}\\\\ &{\\overline{{\\mathbb{E}}}_{\\mathrm{DR}}(\\delta,Z;\\widehat{\\eta},\\gamma)=\\overline{{\\mathbb{E}}}_{\\mathrm{PI}}(\\delta\\ |\\ X;\\widehat{\\eta})+\\gamma\\overline{{\\mathbb{C}}}(\\delta,Z;\\widehat{\\eta})\\quad\\mathrm{and}\\quad\\overline{{\\mathbb{E}}}_{\\mathrm{DR}}^{-1}(\\alpha,Z;\\widehat{\\eta},\\gamma)=\\overline{{\\mathbb{E}}}_{\\mathrm{F}}^{-1}(\\alpha\\ |\\ X;\\widehat{\\eta})+\\gamma\\overline{{\\mathbb{C}}}^{-1}(\\alpha,Z;\\widehat{\\eta}),}\\end{array}\n$$", "text_format": "latex", "page_idx": 7}, {"type": "text", "text": "where $\\overline{{C}}(\\delta,Z;\\hat{\\eta})$ and $\\underline{{\\overline{{C}}}}^{-1}(\\alpha,Z;\\hat{\\eta})$ are given by Eq. (11) and (12), respectively; and $\\gamma\\in(0,1]$ is a scaling hyperparameter. We present a meta-algorithm of our $A U$ -learner (with the CRPS target risk) based on cross-fitting in Algorithm 1 ( $A U$ learner with the $W_{2}^{2}$ target risk follows analogously). ", "page_idx": 7}, {"type": "text", "text": "Scaling hyperparameter. The scaling hyperparameter $\\gamma$ is introduced to tackle Challenge $\\circled{3}$ from above, namely, that the pseudo-CDF term, $\\underline{{\\overline{{\\mathbf{F}}}}}_{\\mathrm{DR}}(\\delta,Z;\\hat{\\eta},\\gamma)$ , is not guaranteed to be a valid CDF for $\\gamma>0$ (both monotonicity wrt. $\\delta$ and $[0,1]$ -constraint can be violated).8 The same happens with the pseudo-quantiles of the $A U$ learner, $\\underline{{\\overline{{\\mathbf{F}}}}}_{\\mathrm{DR}}^{}{}^{-1}(\\alpha,Z;\\hat{\\eta},\\gamma)$ whichcouldbenonmontonouswt. $\\alpha$ The main intuition behind scaling is that it interpolates between the full $A U$ -learner $(\\gamma=1)$ , that has favorable theoretical properties; and the CA-learner $(\\gamma=0,$ ), for which the pseudo-CDFs and pseudoquantiles are valid CDFs and quantiles, respectively (we refer to Appendix E with visual examples). Hence, scaling mimics a learning rate of a Newton-Raphson method (usually considered as an analogy to the one-step bias correction [34]). We found fixed values for the scaling hyperparameter $\\gamma$ to work well in all of our experiments and to improve the low-sample performance of our $A U$ -learner. ", "page_idx": 7}, {"type": "text", "text": "4.3 Theoretical properties of AU-learner ", "text_level": 1, "page_idx": 7}, {"type": "text", "text": "In the following, we formulate our second main theoretical result. For the results to hold, the nuisance functions $\\eta=$ $(\\pi,\\mathbb{F}_{0},\\mathbb{F}_{1})/\\eta=(\\pi,\\mathbb{F}_{0}^{-1},\\mathbb{F}_{1}^{-1})$ need to be estimated independently from the second stage model $g/\\dot{g}^{-1}$ . This could be done by either assuming a not-too-flexible class of models (such as a Donsker class of estimators and fitting all the models on the same dataset $\\mathcal{D}$ ) or by using a generic approach of cross-fitting [15, 35]. ", "page_idx": 7}, {"type": "text", "text": "Algorithm 1 AU-learner (CRPS) via cross-fitting   \n1: Input. Training dataset $D\\,=\\,\\{x_{i},a_{i},y_{i}\\}_{i=1}^{n}$ , scaling $\\gamma\\in(0,1]$ ,folds $K\\geq2$ $\\delta$ grid $\\{\\delta_{j}\\in\\varDelta\\}_{j=1}^{n_{\\delta}}$   \n2: Output. Estimator of Makarov bounds $\\widehat{\\overline{{g}}}(\\delta,x)$   \n3: for $k\\in\\{1,\\ldots,K\\}$ do First stage   \n4: Use $\\{x_{i},a_{i},y_{i}\\}_{k-1\\neq(i\\mathrm{~mod~}K)}$ to fit $\\widehat{\\eta}=(\\widehat{\\pi},\\widehat{\\mathbb{F}}_{0},\\widehat{\\mathbb{F}}_{1})$   \n5: for $i:k-1=(i\\bmod K)$ do   \n6: Use $\\hat{\\eta}$ to infer the pseudo-CDF for the $\\delta$ -grid: $\\left\\{\\overline{{\\mathbf{E}}}_{\\mathrm{DR}}(\\delta_{j},z_{i};\\hat{\\eta})\\right\\}_{j=1}^{n_{\\delta}}$ (Eq (13)   \n7: end for ", "page_idx": 7}, {"type": "text", "text": "8: end for ", "text_level": 1, "page_idx": 7}, {"type": "text", "text": "9:Fit the working model based on $\\delta$ grid: $\\triangleright$ Secondstage $\\widehat{\\underline{{\\overline{{g}}}}}=\\arg\\operatorname*{min}_{g\\in\\mathcal{G}}\\widehat{\\underline{{\\overline{{\\mathcal{L}}}}}}_{\\mathrm{AU,\\,CRPS}}(g,\\hat{\\eta})$ ", "page_idx": 7}, {"type": "text", "text": "Theorem  2  (Neyman-orthogonality  of ", "page_idx": 7}, {"type": "text", "text": "AU-learner (informal). Under the assumptions of the Theorem $^{\\,l}$ , the following holds for AU-learner from Algorithm 1 with the scaling hyperparameter $\\gamma=1$ ", "page_idx": 7}, {"type": "text", "text": "1. Neyman-orthogonality. Losses in Eq. (13) and Eq. (14) are first-order insensitive wrt. to the misspecificationofthenuisancefunctions. 2. Rate double robustness. The bias from the misspecification of the nuisance functions is of second order and vanishes at the same rate as the fastest estimated nuisance functions. ", "page_idx": 7}, {"type": "text", "text": "We refer to the Appendix D for the detailed formulation of the theorem and the proof. Notably, the rate double robustness has two important implications. (i) If at least one of the nuisance functions is estimated consistently, the target estimands are also estimated consistently. (ii) It allows to achieve a so-called quasi-oracle property [98]. This means that our $A U.$ learner with (sufficiently fast) estimated nuisance functions performs nearly identical to the $A U$ -learner with the ground-truth nuisance functions. ", "page_idx": 8}, {"type": "text", "text": "5 Neural instantiation with AU-CNFs ", "text_level": 1, "page_idx": 8}, {"type": "text", "text": "We now introduce a flexible fully-parametric instantiation of our AU-learner, which we call AU-CNFs. Therein, we employ conditional normalizing fows (CNFs) [105, 121] as main backbone for our AU-learner. CNFs are a flexible neural probabilistic method with tractable conditional densities, CDFs, and quantiles. Importantly, all three attributes of the CNFs (densities, CDFs, and quantiles) can be used for both training via back-propagation and inference [115], which makes them a perfect model for both stages of our AU-learner. ", "page_idx": 8}, {"type": "text", "text": "Architecture. The architecture of our AU-CNFs is inspired by interventional normalizing flows (INFs) [94] (a two-stage model for efficient estimation of potential outcomes densities). Our AUCNFs consist of several CNFs corresponding to the two stages of learning, namely a nuisance CNF, which fts the nuisance functions, $(\\widehat{\\pi},\\widehat{\\mathbb{F}}_{0},\\widehat{\\mathbb{F}}_{1})$ or, equivalently, $(\\hat{\\pi},\\widehat{\\mathbb{F}}_{0}^{-1},\\widehat{\\mathbb{F}}_{1}^{-1})$ ; and two target $C N F s$ which implement second stage working models for upper and lower bounds, $\\overline{{\\mathcal{G}}}$ and $\\mathcal{G}$ , respectively. ", "page_idx": 8}, {"type": "text", "text": "Training & implementation. At the first stage of AU-CNFs learning, the nuisance CNF aims at maximizing the conditional log-likelihood and minimizing a binary cross-entropy via a joint loss. Then, we generate the pseudo-CDFs and pseudo-pseudo quantiles, as described in Algorithm 1. Therein, we set the $\\delta/\\alpha$ grid size to $n_{\\delta}=n_{\\alpha}=50$ and discretize the $\\boldsymbol{\\wp}$ -spacel $[0,1]$ -interval to infer the argmax/argmin values, $\\hat{y}^{\\pm}/\\hat{u}^{\\frac{\\ast}{\\ast}}$ . Then, we proceed with the second stage of AU-CNFs learning, where we set $\\gamma=0.25$ for the CRPS loss and $\\gamma=0.01$ for the $W_{2}^{2}$ loss. We found the fixed values of $\\gamma$ to work well in all of the synthetic and semi-synthetic experiments (except for the IHDP100 dataset, where the overlap assumption is violated). We use the same training data for two stages of learning, as (regularized) CNFs as neural networks belong to the Donsker class of estimators [123]. We refer to Appendix F for more details on our AU-CNFs. ", "page_idx": 8}, {"type": "text", "text": "6 Experiments ", "text_level": 1, "page_idx": 8}, {"type": "text", "text": "We now evaluate our AU-learner. For this, we use (semi-)synthetic benchmarks with the ground-truth conditional CDFs/quantiles of potential outcomes, i. e., $\\mathring{\\mathbb{F}}_{a}(y\\mid x)/\\mathbb{F}_{a}^{-1}(u\\mid x)$ . In this way, we can infer the ground-truth Makarov bounds and use them for evaluation. ", "page_idx": 8}, {"type": "text", "text": "Evaluation metric. We use evaluation metrics based on the target risks (as introduced in Sec 4.2). Specifically, we report root continuous ranked probability score (rCRPS) and Wasserstein-2 distance $(W_{2})$ based on training data (in-sample) and test data (out-sample). ", "page_idx": 8}, {"type": "text", "text": "Baselines. We compare the proposed hierarchy of learners from Sec. 4 with CNFs as backbones. These are the plug-in learner (Plug-in CNF), IPTW-learner (IPTW-CNF), CA-learners (CA-CNFs $(\\mathbf{CRPS}\\,/\\,W_{2}^{2})$ ), and AU-learners (AU-CNFs $\\left(\\mathbf{CRPS}\\,/\\,W_{2}^{2}\\right)$ ). The only relevant baseline found in the literature is a plug-in learner based on kernel density estimation [17, 77, 110].9 For this, we used distributional kernel mean embeddings [97] (Plug-in DKME), a standard conditional kernel density estimation method. Details on the baselines are in Appendix G. ", "page_idx": 8}, {"type": "text", "text": "Synthetic data. We adapt the synthetic data generator ( ${d_{x}}\\mathrm{~=~}2)$ from [61, 93] by creating three settings with different conditional outcome distributions: normal, multi-modal, and exponential (see data generation details in Appendix H). In the synthetic data, the ground-truth Makarov bounds are less heterogeneous than the potential outcomes, and, hence, two-stage learners are expected to perform the best. We sample $\\bar{n}_{\\mathrm{train}}\\,\\in\\,\\{100;250;500;750;1000\\}$ training and $n_{\\mathrm{test}}=1000$ test datapoints. The out-sample results are in Fig. 5. Here, our AU-CNFs perform the best wrt. rCRPS in the majority of settings and different sizes of training data. We also report the results wrt. $W_{2}^{2}$ in Appendix I. ", "page_idx": 8}, {"type": "table", "img_path": "RDsDvSHGkA/tmp/0675c29cbbff2d73e3f3ef866b6b65e720412aa82720ff547acc77fb78acba67.jpg", "table_caption": ["Table 2: Results for HC-MNIST. Reported: median out-sample rCRPS $\\pm$ sd / $W_{2}\\pm\\mathrm{sd}$ over 10 runs. "], "table_footnote": ["Lower $\\equiv$ better (best in bold) "], "page_idx": 9}, {"type": "image", "img_path": "RDsDvSHGkA/tmp/f0aefb3da182df9ca89fca6e02224e696c03cba5076e1d1e69280c7606a420a1.jpg", "img_caption": ["Figure 5: Results for synthetic experiments with varying size of training data, $n_{\\mathrm{train}}$ , in 3 settings: normal, multi-modal, and exponential. Reported: mean out-sample rCRPS over 20 runs. "], "img_footnote": [], "page_idx": 9}, {"type": "text", "text": "HC-MNIST dataset. HC-MNIST is a high-dimensional semi-synthetic dataset $(d_{x}=785)$ , built on top of the MNIST dataset [52] (see details in Appendix H). Here, the heterogeneity of Makarov bounds is also smaller than that of potential outcomes, reflecting inductive biases in the real world. We report the out-sample performance of different methods in Table 2 (the Plug-in DKME is omitted due to a too-long runtime). Therein, our AU-CNFs (CRPS) achieve the best performance and, thus, scale well with the dataset size and the dimensionality of covariates. Further, our AU-CNFs $(W_{2}^{2})$ improve the performance of CA-CNFs $(W_{2}^{2})$ . In general, we observe that the loss based on the CDF distance (i. e., CRPS) has a lower variance and is easier to fit. In Appendix I, we additionally report the results for another popular semi-synthetic benchmark, IHDP100 [46, 114]. ", "page_idx": 9}, {"type": "text", "text": "Case study. In Appendix J, we provide a real-world case study based on the observational dataset from [7]. Therein, we demonstrate how our $A U$ -learner (AU-CNFs) can be used to estimate the effectiveness of lockdowns during the COVID-19 pandemic. We estimate the probability of benefit from intervention (a special case of Makarov bounds with $\\delta=0$ ). As expected, we observe a drop in the incidence rate is highly probable after the implementation of a strict lockdown. ", "page_idx": 9}, {"type": "text", "text": "7 Discussion ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "Low-sample & asymptotic performance. In several experiments, especially in low-sample settings, the CA-learner or even the plug-in approach are performing nearly as well or even sometimes better than the $A U$ -learner. This can be expected, as the best low-sample learner and the asymptotically best learner can, in general, be different [20], and there is no single \u201cone-fits-all' data-driven solution to choose the former one [19]. This can be explained by too small dataset sizes or the severe overlap violations (as is the case with the IHDP100 dataset; see Appendix I). Yet, only our doubly robust AU-learner offers asymptotic properties in the sense that it is asymptotically closest to the oracle (see Fig. 4). We thus argue for a pragmatic choice in practice (i. e., in the absence of ground-truth counterfactuals or additional RCT data) where our $A U$ -learner should be the preferred method for the covariate-conditional Makarov bounds even in low-sample data. ", "page_idx": 9}, {"type": "text", "text": "Future work. Our work sets a foundation for several extensions to estimate covariate-conditional Makarov bounds. For example, the estimation of the interval probabilities (see Appendix B) of the treatment effect can provide a connection with the existing works on total uncertainty with conformal prediction [1]. Additionally, one might want to study possible extensions of Makarov bounds tailored to high-dimensional outcomes. ", "page_idx": 9}, {"type": "text", "text": "Limitations & broader impact. Our work is subject to the standard assumptions of the potential outcomes framework. We further make assumptions on the outcome distribution, though these are very mild. Nevertheless, we expect our work to have a positive impact, as it will help to improve the reliability of decision-making in medicine and other safety-critical fields. ", "page_idx": 9}, {"type": "text", "text": "Conclusion. We are the first to offer a theory of orthogonal learning to quantify the aleatoric uncertainty of the treatment effect at the covariate-conditional level and present flexible neural instantiation. ", "page_idx": 9}, {"type": "text", "text": "Acknowledgments ", "text_level": 1, "page_idx": 10}, {"type": "text", "text": "This paper is supported by the DAAD program \u201cKonrad Zuse Schools of Excellence in Artificial Intelligence\", sponsored by the Federal Ministry of Education and Research. Additionally, the authors would like to thank Lars van der Laan, Dennis Frauen, and Alicia Curth for their helpful remarks and comments on the content of this paper. SF also acknowledges funding from the Swiss National Science Foundation (SNSF) via Grant 186932. ", "page_idx": 10}, {"type": "text", "text": "References ", "text_level": 1, "page_idx": 10}, {"type": "text", "text": "[1] Ahmed M. Alaa, Zaid Ahmad, and Mark van der Laan. \u201cConformal meta-learners for predictive inference of individual treatment effects\". In: Advances in Neural Information Processing Systems. 2024.   \n[2]   Ahmed M. Alaa and Mihaela van der Schaar. \u201c\"Bayesian inference of individualized treatment effects using multi-task Gaussian processes\". In: Advances in Neural Information Processing Systems. 2017.   \n[3]   Ahmed M. Alaa and Mihaela van der Schaar. \u201cBayesian nonparametric causal inference: Information rates and learning algorithms\". In: IEEE Journal of Selected Topics in Signal Processing 12.5 (2018), pp. 1031-1046.   \n[4]   Joshua D. Angrist, Guido W. Imbens, and Donald B. Rubin. \u201cIdentification of causal effects using instrumental variables\". In: Journal of the American statistical Association 91.434 (1996), Pp. 444-455.   \n[5]  Peter M. Aronow, Donald P. Green, and Donald K.K. Lee.\u201cSharp bounds on the variance in randomized experiments\". In: The Annals of Statistics 42.3 (2014), pp. 850-871.   \n[6]  Sivaraman Balakrishnan, Edward Kennedy, and Larry Wasserman. \"Conservative inference for counterfactuals\"'. In: arXiv preprint arXiv:2310.12757 (2023).   \n[7]   Nicolas Banholzer et al. \u201cEstimating the effects of non-pharmaceutical interventions on the number of new infections with COVID-19 during the first epidemic wave\". In: PLoS one 16.6 (2021), e0252827.   \n[8]  Elias Bareinboim et al. \u201cOn Pearl's hierarchy and the foundations of causal inference\". In: Probabilistic and Causal Inference: The Works of Judea Pearl. Association for Computing Machinery, 2022, pp. 507-556.   \n[9]   Ioana Bica et al. \u201cFrom real-world patient data to individualized treatment effects using machine learning: Current and future methods to address underlying challenges\". In: Clinical Pharmacology & Therapeutics 109 (2021), pp. 87-100.   \n[10]  Peter J. Bickelet al. Efficient and adaptive estimation for semiparametric models. Springer New York, 1993.   \n[11]  Matteo Bonvini et al. \"Sensitivity analysis for marginal structural models\". In: arXiv preprint arXiv:2210.04681 (2022).   \n[12]  Kevin G. Buell et al. \u201cIndividualized treatment effects of oxygen targets in mechanically ventilated critically ill adults\"'. In: JAMA (2024).   \n[13] Victor Chernozhukov, Ivan Fernandez-Val, and Blaise Melly. \u201cInference on counterfactual distributions\". In: Econometrica 81.6 (2013), pp. 2205-2268.   \n[14] Victor Chernozhukov, Sokbae Lee, and Adam M. Rosen. \u201cIntersection bounds: Estimation and inference\". In: Econometrica 81.2 (2013), pp. 667-737.   \n[15]   Victor Chernozhukov et al. \u201cDouble/debiased machine learning for treatment and structural parameters\". In: The Econometrics Journal 21.1 (2018), pp. C1-C68.   \n[16]  Yoichi Chikahara, Makoto Yamada, and Hisashi Kashima. \u201cFeature selection for discovering distributional treatment effect modifiers\". In: Uncertainty in Artificial Intelligence. 2022.   \n[17]  Yifan Cui and Sukjin Han. \u201cPolicy learning with distributional welfare?\". In: arXiv preprint arXiv:2311.15878 (2024).   \n[18]  Alicia Curth, Ahmed M. Alaa, and Mihaela van der Schaar. \u201cEstimating structural target functions using machine learning and influence functions\". In: arXiv preprint arXiv:2008.06461 (2020).   \n[19]  Alicia Curth and Mihaela van der Schaar. \u201cIn search of insights, not magic bullets: Towards demystification of the model selection dilemma in heterogeneous treatment effect estimation\". In: International Conference on Machine Learning. 2023.   \n[20]  Alicia Curth and Mihaela van der Schar. \u201cNonparametric estimation of heterogeneous treatment effects: From theory to learning algorithms\". In: International Conference on Artificial Intelligence and Statistics. 2021.   \n[21]  Alicia Curth et al. \u201cReally doing great at estimating CATE? A critical look at ML benchmarking practices in treatment effect estimation\". In: Advances in Neural Information Processing Systems. 2021.   \n[22]   Alicia Curth et al. \u201cUsing machine learning to individualize treatment effect estimation: Challenges and opportunities\". In: Clinical Pharmacology & Therapeutics (2024).   \n[23]  Jacob Dorn and Kevin Guo. \u201c\"Sharp sensitivity analysis for inverse propensity weighting via quantile balancing\". In: Journal of the American Statistical Association 118.544 (2023), Pp. 2645-2657.   \n[24]   Conor Durkan et a. \u201cNeural spline fows\". In: Advances in Neural Information Processing Systems. 2019.   \n[25]  Yanqin Fan, Emmanuel Guerre, and Dongming Zhu. \u201cPartial identification of functionals of the joint distribution of \u201cpotential outcomes\"\". In: Journal of Econometrics 197.1 (2017), pp. 42-59.   \n[26]  Yanqin Fan and Sang Soo Park. \u201c\"Sharp bounds on the distribution of treatment efects and their statistical inference\". In: Econometric Theory 26.3 (2010),pp. 931-951.   \n[27]  Yanqin Fan, Robert Sherman, and Matthew Shum. \u201cIdentifying treatment effects under data combination\". In: Econometrica 82.2 (2014), pp. 811-822.   \n[28]  Yanqin Fan and Sang Soo Park. \u201cPartial identification of the distribution of treatment effects and its confidence sets\" In: Nonparametric Econometric Methods. Emerald Group Publishing Limited, 2009, pp. 3-70.   \n[29]  Jake Fawkes et al. \"Doubly robust kernel statistics for testing distributional treatment effects\". In: Transactions on Machine Learning Research (2024).   \n[30]  Stefan Feuerriegel et al. \u201cCausal machine learning for predicting treatment outcomes\". In: Nature Medicine 30.4 (2024), pp. 958-968.   \n[31]  Sergio Firpo. \u201cEficient semiparametric estimation of quantile treatment effects\". In: Econometrica 75.1 (2007), pp. 259-276.   \n[32]  Sergio Firpo, Nicole M. Fortin, and Thomas Lemieux. \u201c\"Unconditional quantile regressions\". In: Econometrica 77.3 (2009), pp. 953-973.   \n[33] Sergio Firpo and Geert Ridder. \u201cPartial identification of the treatment effect distribution and its functionals\". In: Journal of Econometrics 213.1 (2019), pp. 210-234.   \n[34]  Aaron Fisher and Edward H. Kennedy. \"Visually communicating and teaching intuition for infuence functions\". In: The American Statistician 75.2 (2021), pp. 162-172.   \n[35]  Dylan J. Foster and Vasilis Syrgkanis. \"Orthogonal statistical learning\". In: The Annals of Statistics 51.3 (2023), pp. 879-908.   \n[36]  Brigham R. Frandsen and Lars J. Lefgren. \u201cPartial identification of the distribution of treatment effcts with anapplication to the knowledge is power program (KIPP). In: Quantitative Economics 12.1 (202i), pp. 143-171.   \n[37]  Dennis Frauen, Valentyn Melnychuk, and Stefan Feuerriegel. \u201cSharp bounds for generalized causal sensitivity analysis\". In: Advances in Neural Information Processing Systems. 2023.   \n[38]  Dennis Frauen et al. \u201cA neural framework for generalized causal sensitivity analysis\". In: International Conference on Learning Representations. 2024.   \n[39]  Maurice Fr\u00e9chet. \u201cSur les tableaux de correlation dont les marges sont donnees\". In: Ann. Univ. Lyon, $3^{\\star}e$ serie, Sciences, Sect. A 14 (1951), pp. 53-77.   \n[40]  Tilmann Gneiting and Adrian E. Raftery. \u201cStrictly proper scoring rules, prediction, and estimation\". In: Journal of the American Statistical Association 102.477 (2007), pp. 359-378.   \n[41]  Cornelia Gruber et al. \u201cSources of uncertainty in machine learning - a statisticians view\". In: arXiv preprint arXiv:2305.16703 (2023).   \n[42]  Wenshuo Guo et al. \u201cPartial identification with noisy covariates: A robust optimization approach\". In: Conference on Causal Learning and Reasoning. 2022.   \n[43]  Daeyoung Ham, Ted Westling, and Charles R. Doss. \u201c\"Doubly robust estimation and inference for a log-concave counterfactual density\". In: arXiv preprint arXiv:2403.19917 (2024).   \n[44]  James J. Heckman, Jeffrey Smith, and Nancy Clements. \u201cMaking the most out of programme evaluations and social experiments: Accounting for heterogeneity in programme impacts\". In: The Review of Economic Studies 64.4 (1997), pp. 487-535.   \n[45]  Miguel A Hernan and James M. Robins. \u201cInstruments for causal inference: An epidemiologist's dream? In: Epidemiology 17.4 (2006),Pp. 360-372.   \n[46] Jennifer L. Hill. \u201cBayesian nonparametric modeling for causal inference\". In: Journal of Computational and Graphical Statistics 20.1 (2011),p. 217-240.   \n[47]  Keisuke Hirano and Jack R. Porter. \u201cImpossibility results for nondifferentiable functionals\". In: Econometrica 80.4 (2012), pp. 1769-1790.   \n[48] Kate Ho and Adam M. Rosen. \u201cPartial identification in applied research: Benefits and challenges\" In: Advances in Economics and Econometrics: Eleventh World Congress. Econometric Society Monographs. Cambridge University Press, 2017, pp. 307-359.   \n[49]  Wasilij Hoeffding. \"Masstabinvariante Korrelationstheorie\". In: Schriften des Mathematischen Instituts und Instituts fir Angewandte Mathematik der Universitit Berlin 5 (1940), pp.181-233.   \n[50]  Eyke Huillermeier and Willem Waegeman. \"Aleatoric and epistemic uncertainty in machine learning: An introduction to concepts and methods\". In: Machine learning 110.3 (2021), Pp. 457-506.   \n[51]  Andrew Jesson et a. \u201cIdentifying causal-effect inference failure with uncertainty-aware models\". In: Advances in Neural Information Processing Systems. 2020.   \n[52]  Andrew Jeson et al. \"Quantifying ignorance in individual-level causal-effect estimates under hidden confounding\". In: International Conference on Machine Learning. 2021.   \n[53]  Andrew Jesson et al. \"'Scalable sensitivity and uncertainty analyses for causal-effect estimates of continuous-valued interventions\". In: Advances in Neural Information Processing Systems. 2022.   \n[54]  Wenlong Ji, Lihua Lei, and Asher Spector. \u201cModel-agnostic covariate-assisted inference on partially identified causal effects\". In: arXiv preprint arXiv:2310.08115 (2023).   \n[55]  Ying Jin, Zhimei Ren, and Emmanuel J. Candes. \u201c\"Sensitivity analysis of individual treatment effects: A robust conformal inference approach\". In: Proceedings of the National Academy of Sciences 120.6 (2023), e2214889120.   \n[56]  Ying Jin, Zhimei Ren, and Zhengyuan Zhou. \"'Sensitivity analysis under the $f$ sensitivity models: A distributional robustness perspective' In: arXiv preprint arXiv:2203.04373 (2022).   \n[57]  Fredrik D. Johansson et al. \u201cGeneralization bounds and representation learning for estimation of potential outcomes and causal effects\". In: Journal of Machine Learning Research 23 (2022), Pp. 7489-7538.   \n[58]  Jef Jonkers et al. \u201cConformal Monte Carlo meta-learners for predictive inference of individual treatment effects\"'. In: arXiv preprint arXiv:2402.04906 (2024).   \n[59]  Tetsuya Kaji and Jianfei Cao.\"Assessing heterogeneity of treatment effects\". In: arXiv preprint arXiv:2306.15048 (2023).   \n[60]  Nathan Kallus. \"What's the harm? Sharp bounds on the fraction negatively affected by treatment\". In: Advances in Neural Information Processing Systems. 2022.   \n[61]  Nathan Kallus, Xiaojie Mao, and Angela Zhou. \u201cInterval estimation of individual-level causal effects under unobserved confounding\". In: International Conference on Artificial Intelligence and Statistics. 2019.   \n[62]  Nathan Kallus and Miruna Oprescu. \"'Robust and agnostic learning of conditional distributional treatment effects\". In: International Conference on Artijfcial Inteligence and Statistics. 2023.   \n[63]  Edward H. Kennedy. \u201cSemiparametric doubly robust targeted double machine learning: A review'. In: arXiv preprint arXiv:2203.06469 (2022).   \n[64]  Edward H. Kennedy. \u201cTowards optimal doubly robust estimation of heterogeneous causal effects\". In: Electronic Journal of Statistics 17.2 (2023), pp. 3008-3049.   \n[65]  Edward H. Kennedy, Sivaraman Balakrishnan, and L.A. Wasserman. \u201cSemiparametric counterfactual density estimation\". In: Biometrika 110.4 (2023), pp. 875-896.   \n[66] Kwangho Kim, Jisu Kim, and Edward H. Kennedy. \u201c\"Causal effects based on distributional distances\". In: arXiv preprint arXiv: 1806.02935 (2018).   \n[67] Danijel Kivaranovic et al. \"Conformal prediction intervals for the individual treatment effect\". In: arXiv preprint arXiv:2006.01474 (2020).   \n[68]  Thomas Kneib, Alexander Silbersdorff, and Benjamin Safken. \u201cRage against the mean-a review of distributional regression approaches\". In: Econometrics and Statistics 26 (2023), pp. 99-123.   \n[69]   Soren R. Kunzel et al. \u201cMetalearners for estimating heterogeneous treatment effects using machine learning\". In: Proceedings of the National Academy of Sciences 116.10 (2019), pp. 4156-4165.   \n[70]  Milan Kuzmanovic et al. \u201cCausal machine learning for cost-effective allocation of development aid'\". In: Conference on Knowledge Discovery and Data Mining. 2024.   \n[71]  Lars van der Lan, Marco Carone, and Alexander R. Luedtke. \u201cCombining T-learning and DR-learning: A framework for oracle-efficient estimation of causal contrasts\"'. In: arXiv preprint arXiv:2402.01972 (2024).   \n[72]   Lars van der Laan et al. \u201cAdaptive debiased machine learning using data-driven model selection techniques\"'. In: arXiv preprint arXiv:2307.12544 (2023).   \n[73]  Mark J. an der Laan and James M. Robins. Unified methods for censored longitudinal data and causality. Springer New York, 2003.   \n[74]  Mark J. van der Laan and Sherri Rose. Targeted Learning: Causal Inference for Observational and Experimental Data. Springer New York, 2011.   \n[75] Yann LeCun.  \u201cThe  MNISTo. database  of handwritten digits\". In: http://yann.lecun.com/exdb/mnist/ (1998).   \n[76]  Hyun-Suk Lee et al. \u201c'Robust recursive partitioning for heterogeneous treatment efects with uncertainty quantification\"'. In: Advances in Neural Information Processing Systems (2020).   \n[77]  Sungwon Lee. \u201cPartial identification and inference for conditional distributions of treatment effects\". In: Journal of Applied Econometrics 39.1 (2024), pp. 107-127.   \n[78]  Lihua Lei and Emmanuel J. Candes. \u201cConformal inference of counterfactuals and individual treatment effects\". In: Journal of the Royal Statistical Society 83.5 (2021), pp. 911-938.   \n[79]  Alexander W Levis, Edward H. Kennedy, and Luke Keele. \u201cNonparametric identification and effcient estimation of causal effects with instrumental variables\". In: arXiv preprint arXiv:2402.09332 (2024).   \n[80]   Kendrick Qijun Li et al. \u201cDoubly robust proximal causal inference under confounded outcomedependent sampling\". In: arXiv preprint arXiv:2208.01237 (2022).   \n[81]  Jiannan Lu, Peng Ding, and Tirthankar Dasgupta. \u201cTreatment effects on ordinal outcomes: Causal estimands and sharp bounds\". In: Journal of Educational and Behavioral Statistics 43.5 (2018), pp. 540-567.   \n[82] Alexander R. Luedtke. Evaluating Optimal Individualized Treatment Rules. University of California, Berkeley, 2016.   \n[83]  Alexander R. Luedtke. \"Simplifying debiased inference via automatic differentiation and probabilistic programming\". In: arXiv preprint arXiv:2405.08675 (2024).   \n[84]  Alexander R. Luedtke and Mark J. van der Laan. \u201cStatistical inference for the mean outcome under a possibly non-unique optimal treatment strategy\". In: Annals of statistics 44.2 (2016), p. 713.   \n[85]  Alexander R. Luedtke and Mark J. van der Laan. \u201c\"Super-learning of an optimal dynamic treatment rule\". In: The international journal of biostatistics 12.1 (2016), pp. 305-332.   \n[86]   Yuchen Ma et al. \u201cDiffPO: A causal diffusion model for predicting potential outcomes of treatments\". In: Advances in Neural Information Processing Systems. 2024.   \n[87]   G.D. Makarov. \u201c\"Estimates for the distribution function of a sum of two random variables when the marginal distributions are fixed\". In: Theory of Probability & its Applications 26.4 (1982), pp. 803-806.   \n[88]  Charles F. Manski. \u201cMonotone treatment response\u201d. In: Econometrica: Journal of the Econometric Society (1997), pp. 1311-1334.   \n[89]   Charles F. Manski. \"Nonparametric bounds on treatment efects\". In: The American Economic Review 80.2 (1990), pp. 319-323. [90] Myrl G. Marmarelis et al. \u201c\"Ensembled prediction intervals for causal outcomes under hidden confounding\"'. In: Causal Learning and Reasoning. 2024.   \n[91]  Diego Martinez-Taboada and Edward H. Kennedy. \u201cCounterfactual density estimation using kernel Stein discrepancies\". In: International Conference on Learning Representations. 2024.   \n[92]  Diego Martinez-Taboada, Aaditya Ramdas, and Edward Kennedy. \u201c\"An efficient doublyrobust test for the kernel treatment effect' In: Advances in Neural Information Processing Systems. 2023. [93]  Valentyn Melnychuk, Dennis Frauen, and Stefan Feuerriegel. \u201cBounds on representationinduced confounding bias for treatment effect estimation\". In: International Conference on Learning Representations. 2024.   \n[94]  Valentyn Melnychuk, Dennis Frauen, and Stefan Feuerriegel. Normalizing fows for interventional density estimation\"'. In: International Conference on Machine Learning. 2023. [95]  Valentyn Melnychuk, Dennis Frauen, and Stefan Feuerriegel. \u201cPartial counterfactual identification of continuous outcomes with a curvature sensitivity model\"'. In: Advances in Neural Information Processing Systems. 2023.   \n[96]  Pawel Morzywolek, Johan Decruyenaere, and Stijn Vansteelandt. \"On a general class of orthogonal learners for the estimation of heterogeneous treatment effects\". In: arXiv preprint arXiv:2303.12687 (2023).   \n[97]  Krikamol Muandet et al. \"Counterfactual mean embeddings\". In: Journal of Machine Learning Research 22 (2021), pp. 1-71.   \n[98]  Xinkun Nie and Stefan Wager. \u201cQuasi-oracle estimation of heterogeneous treatment effects\". In: Biometrika 108 (2021), pp. 299-319.   \n[99]  Miruna Oprescu et al. \u201c'B-Learner: Quasi-oracle bounds on heterogeneous causal effects under hidden confounding\"'. In: International Conference on Machine Learning. 2023.   \n[100]  Junhyung Park et al. \u201cConditional distributional treatment effect with kernel conditional mean embeddings and U-statistic regression\". In: International Conference on Machine Learning. 2021.   \n[101]  Judea Pearl. Causality. Cambridge University Press, 2009.   \n[102]  Thong Pham et al. \u201c\"Scalable counterfactual distribution estimation in multivariate causal models\". In: Causal Learning and Reasoning. 2024.   \n[103] Boris T. Polyak and Anatoli B. Juditsky. \u201c\"Acceleration of stochastic approximation by averaging\". In: SIAM Journal on Control and Optimization 30.4 (1992), pp. 838-855.   \n[104]  Ashesh Rambachan, Amanda Coston, and Edward Kennedy. \u201cCounterfactual risk assessments under unmeasured confounding\". In: arXiv preprint arXiv:2212.09844 (2022).   \n[105]  Danilo Rezende and Shakir Mohamed. \u201c\"Variational inference with normalizing flows\". In: International Conference on Machine Learning. 2015.   \n[106]  James M. Robins. \u201cOptimal structural nested models for optimal sequential decisions\", In: Second Seattle Symposium in Biostatistics: Analysis of correlated data. Springer New York. 2004, pp. 189-326.   \n[107]  James M. Robins and Andrea Rotnitzky. \u201c\"Semiparametric effciency in multivariate regression models with missing data\". In: Journal of the American Statistical Association 90.429 (1995), pp. 122-129.   \n[108]  Jonas Rothfuss et al. \u201cNoise regularization for conditional density estimation\". In: arXiv preprint arXiv: 1907.08982 (2019).   \n[109]   Donald B. Rubin. \u201cEstimating causal effects of treatments in randomized and nonrandomized studies\". In: Journal of Educational Psychology 66.5 (1974), p. 688.   \n[110] Gabriel Ruiz and Oscar Hernan Madrid Padilla. \u201cNon-asymptotic confidence bands on the probability an individual benefits from treatment (PIBT)\". In: arXiv preprint arXiv:2205.09094 (2022).   \n[111] Maresa Schroder et al. \u201cConformal prediction for causal effects of continuous treatments\". In: arXiv preprint arXiv:2407.03094 (2024).   \n[112]   Vira Semenova. \"Adaptive estimation of intersection bounds: A classification approach\". In: arXiv preprint arXiv:2303.00982 (2023).   \n[113] Vira Semenova.\u201cDebiased machine learning of set-identified linear models\". In: Journal of Econometrics 235.2 (2023), pp. 1725-1746.   \n[114] Uri Shalit, Fredrik D. Johansson, and David Sontag. \u201cEstimating individual treatment effect: Generalization bounds and algorithms\"'. In: International Conference on Machine Learning. 2017.   \n[115] Phillip Si, Allan Bishop, and Volodymyr Kuleshov. \u201cAutoregressive quantile fows for predictive uncertainty estimation\". In: International Conference on Learning Representations. 2021.   \n[116]  Thomas Stromberg. \u201c\"A study of the operation of infimal convolution\". PhD thesis. Lulea tekniska universitet, 1994.   \n[117]  Hongjun Su and Hong Zhang. \u201cDistances and kernels based on cumulative distribution functions\". In: Emerging Trends in Image Processing, Computer Vision and Pattern Recognition. Elsevier, 2015, pp. 551-559.   \n[118]   Erik Sverdrup and Yifan Cui. \u201cProximal causal learning of conditional average treatment effects\". In: International Conference on Machine Learning. 2023.   \n[119] Zhiqiang Tan. \u201cA distributional approach for causal inference using propensity scores\". In: Journal of the American Statistical Association 101.476 (2006), pp. 1619-1637.   \n[120] Eric J. Tchetgen Tchetgen et al. \u201cAn introduction to proximal causal learning\". In: Statistical Science 39.3 (2024), pp. 375-390.   \n[121] Brian L. Trippe and Richard E. Turner. \u201cConditional density estimation with Bayesian normalising fows\". In: arXiv preprint arXiv: 1802.04908 (2018).   \n[122]  Anastasios A. Tsiatis. Semiparametric theory and missing data. Springer New York, 2006.   \n[123]   Aad W. van der Vaart. Asymptotic statistics. Vol. 3. Cambridge university press, 2000.   \n[124]  Toon Vanderschueren, Jeroen Berrevoets, and Wouter Verbeke. \u201cNOFLITE: Learning to predict individual treatment effect distributions\". In: Transactions on Machine Learning Research (2023).   \n[125] Stijn Vansteelandt and Pawel Morzywolek. \u201cOrthogonal prediction of counterfactual outcomes\". In: arXiv preprint arXiv:2311.09423 (2023).   \n[126]  Robert C. Williamson and Tom Downs. \u201cProbabilistic arithmetic. I. Numerical methods for calculating convolutions and dependency bounds\". In: International Journal of Approximate Reasoning 4.2 (1990), pp. 89-158.   \n[127]   Andrew Ying. \u201cA geometric perspective on double robustness by semiparametric theory and information geometry\"'. In: arXiv preprint arXiv:2404.13960 (2024).   \n[128]  Yao Zhang, Alexis Bellot, and Mihaela van der Schaar. \u201cLearning overlapping representations for the estimation of individualized treatment effects\". In: International Conference on Artificial Intelligence and Statistics.2020.   \n[129] Zhehao Zhang and Thomas S. Richardson. \u201cBounds on the distribution of a sum of two random variables: Revisiting a problem of Kolmogorov with application to individual treatment effects\"'. In: arXiv preprint arXiv:2405.08806 (2024). ", "page_idx": 10}, {"type": "text", "text": "", "page_idx": 11}, {"type": "text", "text": "", "page_idx": 12}, {"type": "text", "text": "", "page_idx": 13}, {"type": "text", "text": "", "page_idx": 14}, {"type": "text", "text": "", "page_idx": 15}, {"type": "text", "text": "AExtended Related Work", "text_level": 1, "page_idx": 16}, {"type": "text", "text": "Partial identification and sensitivity models in the potential outcomes framework. Interventional quantities (such as CAPOs and distributions of potential outcomes) and some counterfactual quantities (e. g., CATE) are point identifiable in potential outcomes framework (see Fig. 6). However, relaxation of the unconfoundedness assumption renders those quantities partially identifiable or even nonidentifiable identifiable [89]. In this case, additional sensitivity models can be employed. Examples are the marginal sensitivity model [11, 23, 37, 38, 52, 53, 56, 119] and outcome sensitivity model [11, 104]. Other approaches suggest using instrumental variables [4, 45] or noisy proxy variables [42, 120]. Counterfactual quantities, on the other hand, are inherently non-identifiable (e. g., joint distribution of potential outcomes [26], expected counterfactual outcomes of (un)treated [95], and distribution of treatment effect [26]). There is no general approach for deriving sharp bounds for partially identifiable causal quantities, therefore the above-mentioned works are not relevant in our setting. ", "page_idx": 16}, {"type": "image", "img_path": "RDsDvSHGkA/tmp/d57cd171e683829f5020daed5a5fe11730e8d9bd1cb5581a943f3d481f9bfb11.jpg", "img_caption": [], "img_footnote": [], "page_idx": 16}, {"type": "text", "text": "Figure 6: Pearl's ladder of causation [8, 101] containing different observational, interventional, and counterfactual quantities related to the potential outcomes framework. Here, $X$ are covariates, $A$ is a binary treatment, and $Y$ is a continuous outcome. We also plot three exemplar causal diagrams, satisfying the assumptions of the potential outcomes framework, for each layer of causation, correspondingly. Quantities with the light gray background can be expressed with the quantities from lower layers (e. g., conditional average treatment effect) and quantities with yellow background require the information from the same layer. In this paper, we are interested in the CDTE, $\\mathbb{P}(Y[1]-$ $Y[0]\\mid x)$ , shown in orange. Notably, point non-identifiability of the CDTE can be seen with a parallel worlds network (the causal diagram of the counterfactual layer). ", "page_idx": 16}, {"type": "text", "text": "Distributional treatment effects and the distribution of the treatment effect. There are two seemingly similar notions in the existing literature: (a) distributional treatment effects [16, 29, 62, 92, 100] and (b) the distribution of the treatment effect [6, 26, 28, 33, 88]. However, (a) and (b) have two important differences: ", "page_idx": 16}, {"type": "text", "text": "\u00b7 (i) Interpretation. Distributional treatment effects represent the differences between different distributional aspects of the potential outcomes (e.g., Wasserstein distances, KL-divergence, or the quantile differences) [62]. Hence, they can answer questions like \u201cHow are $10\\%$ of the worst-possible outcomes with treatment different from the worst $10\\%$ of the outcomes without treatment?\". Here, the two groups (treated and untreated) of the worst $10\\%$ contain, in general, different individuals. This is problematic in many applications like clinical decision support and drug approval. Here, the aim is not to compare individuals from treated vs. untreated groups (where the groups may differ due to various, unobserved reasons). Instead, the aim is to accurately quantify the treatment response for each individual and allow for quantification of the personalized uncertainty of the treatment effect. The latter is captured in the distribution of the treatment effect, which allows us to answer the question about the CDF/quantiles of the treatment effect. For example, we would aim to answer a question like \u201cWhat are the worst $10\\%$ ofvalues of the treatment effect?\". Here, we focus on the treatment effect for every single individual. The latter is more complex because we reason about the difference of two potential outcomes simultaneously. Hence, in natural situations when the potential outcomes are non-deterministic, both (a) the distributional treatment effect and (b) the distribution of the treatment effect will lend to very different interpretations, especially in medical practice. In particular, the distribution of the treatment effect (which we study in our paper) is important in medicine, where it allows quantifying the amount of harm/benefit after the treatment [60]. This may warn doctors about ", "page_idx": 16}, {"type": "text", "text": "situations where the averaged treatment effects are positive but where the probability of the negative treatment effect is still large. \u00b7 (i) Inference. The efficient inference of the distributional treatment effects only requires the estimation of the relevant distributional aspects of the conditional outcome distributions (e. g., quantiles) and the propensity score [62]. However, in our setting of the bounds on the CDF/quantiles of the treatment effect, we also need to perform sup/inf convolutions of the CDF/quantiles of the conditional outcomes distributions. Hence, while the definitions of (a) the distributional treatment effects and (b) the distribution of the treatment effect appear related, their estimation is very different. ", "page_idx": 17}, {"type": "text", "text": "Alternatives to Makarov bounds. Potential alternatives to Makarov bounds vary depending on the type of aleatoric uncertainty. For example, explicit or implicit sharp bounds were proposed for: ", "page_idx": 17}, {"type": "text", "text": "\u00b7 The variance of the treatment effect, $\\mathrm{Var}(Y[1]-Y[0])$ [5]. Here, the sharp bounds are explicitly given by Fr\u00e9chet-Hoeffding bounds [39, 49] and are, in general, different from Makarov bounds. \u00b7 The interval probabilities, $\\mathbb{P}(\\delta_{1}\\,\\le\\,Y[1]-Y[0]\\,\\le\\,\\delta_{2})$ [33]. The sharp bounds on the interval probabilities are only defined implicitly and are also, in general, different from Makarov bounds (see AppendixB). ", "page_idx": 17}, {"type": "text", "text": "We are not aware of other bounds for measuring aleatoric uncertainty (e. g., kurtosis, skewness, or entropy). Importantly, the above-mentioned bounds on different measures of uncertainty are orthogonal to our work, and we focus on the bounds on the CDF/quantiles of the treatment effect. ", "page_idx": 17}, {"type": "text", "text": "Efficient estimators and orthogonal learners. Efficient estimation of causal quantities (target estimands) was studied in the scope of (i) semi-parametric efficient estimation theory and, more general, (i) orthogonal learning theory. Both theories (i) and (i) rely on the concept of influence functions (pathwise derivatives) [63, 72, 122], which allow performing a one-step bias correction for (i) a plug-in estimator of the target estimand or (i) the population risk containing target estimand, respectively. (i) Semi-parametric efficient estimation theory [10, 73, 74, 107, 122] provides asymptotically efficient estimators for finite-dimensional target estimands (e. g., average treatment effect (ATE) and average potential outcomes (APOs)). On the other hand, (i) orthogonal learning theory (or debiased ML) [15, 35, 96, 125] was developed for infinitely-dimensional (functional) estimands, like, CATE and CAPO. Orthogonal learning theory (or orthogonal learners) estimates target estimands by minimizing (Neyman-)orthogonal losses that are first-order insensitive to the misspecification of the nuisance functions. Specific examples of orthogonal learners for identifiable quantities include CAPO learners [125] and CATE learners [18, 64, 71, 96, 98]. ", "page_idx": 17}, {"type": "text", "text": "Estimation of partially identifiable quantities. Orthogonal learners were also proposed for bounds on partially identifiable causal quantities. Examples include different interventional quantities such, e. g., in marginal sensitivity model [99], in instrumental variables setting [79], in noisy proxy variables setting [80, 118]. Examples from counterfactual quantities are, e. g., the variance of treatment effect and joint CDF of potential outcomes (Fr\u00e9chet-Hoeffding bounds) [6]. More generally, estimation and learning for partially identifiable quantities was studied in econometrics as estimation of intersection bounds [14, 112, 113]. In this paper, we construct a novel orthogonal learner targeting at Makarov bounds on the CDF/quantiles of the CDTE. ", "page_idx": 17}, {"type": "text", "text": "Total uncertainty quantification. Total uncertainty in potential outcomes framework can be generally quantified with two approaches: (i) Bayesian methods (e. g., Gaussian processes) and (ii) conformal prediction framework. (i) Bayesian methods [2, 3, 46] allow to infer posterior predictive distributions or credible intervals and for both potential outcomes and treatment effect, but under additional identifiability assumptions (e. g., an assumption of additive latent outcome noise, which renders treatment effect distribution identifiable). (i) Conformal prediction aims at providing a valid predictive interval and was applied to quantify total uncertainty of predicting potential outcomes [76, 78, 90, 111] and treatment effect [1, 55, 58, 67, 78]. The latter works either make a similar additive latent outcome noise assumption or \u201chide\u2019 non-identifiable treatment effect into the predictive interval (however, oracle predictive interval could never be reached in this case). We argue that total uncertainty needs to be split into epistemic and aleatoric explicitly to provide insights on the origin of uncertainty [50], especially in our setting where aleatoric uncertainty of the treatment effect itself is partially identifiable (see Fig. 2). ", "page_idx": 17}, {"type": "text", "text": "B Makarov Bounds ", "text_level": 1, "page_idx": 18}, {"type": "text", "text": "B.1 Bounds Construction ", "text_level": 1, "page_idx": 18}, {"type": "text", "text": "In the following, we provide an additional intuition on how Makarov bounds are inferred from conditional distributions of the potential outcomes, $\\mathbb{P}(Y[a]\\mid x)$ . For example, Makarov bounds for the CDF of the CDTE are a composition of the sup/inf convolutions, applied to the conditional CDFs of the potential outcomes, and the rectifier functions (see Fig. 7). ", "page_idx": 18}, {"type": "text", "text": "Makarov bounds can be inferred (i) analytically or (i) numerically. (i) Analytic formulas were proposed for very simple distributions (e.g., a normal distribution [26]). At the same time, the (ii) numerical approach is more flexible. For example, we can discretize the $\\boldsymbol{\\wp}$ -spaceor $[0,1]$ -interval and perform maximization/minimization on that grid. Notably, in our experiments, we infer the ground-truth bounds with the approach (i), when the ground-truth conditional potential outcomes distributions are normal; and (i) otherwise. ", "page_idx": 18}, {"type": "image", "img_path": "RDsDvSHGkA/tmp/0893635456153486952cde302c528d07277c2754ded93bf45cf5120c2172d9c2.jpg", "img_caption": ["Figure 7: A example of the inference of Makarov bounds on the CDF of the CDTE based on $i=7$ -th instance of the semi-synthetic IHDP100 dataset [46]. The construction of the upper bound is shown in (a) and ${\\bf(b)}$ ; and the lower bound corresponds to subfigures (c) and (d). The subfigures on the left, (a) and (c), contain the conditional CDFs of both potential outcomes, namely, $\\mathbb{F}_{0}(\\cdot\\mid x_{7})$ and $\\mathbb{F}_{1}(\\cdot\\mid x_{7})$ . Therein, the conditional CDF $\\mathbb{F}_{0}(\\cdot\\mid x_{7})$ is shifted wrt. four values of $\\delta$ .The figures on the right, ${\\bf(b)}$ and $\\mathbf{\\mu(d)}$ , then demonstrate the corresponding Makarov bounds values for the same four values of $\\delta$ (shown in red). We also plot the full Makarov bounds with a gray color. "], "img_footnote": [], "page_idx": 18}, {"type": "text", "text": "B.2  Pointwise and Uniformly Sharp Bounds ", "text_level": 1, "page_idx": 18}, {"type": "text", "text": "The sharpness of Makarov bounds proposed in [26] has one important characteristic. Specifically, although the Makarov bounds on the CDFs, $\\underline{{\\overline{{\\mathbf{F}}}}}(\\delta\\mid X)$ , are CDFs themselves, they are not valid solutions to the partial identification task. This can be easily checked, i. e., the expectation wrt. to the Makarov bounds does not coincide with the point-identifiable CATE, $\\tau(x)=\\mathbb{E}\\!\\left(\\Delta\\mid x\\right)$ ", "page_idx": 18}, {"type": "equation", "text": "$$\n-\\int_{-\\infty}^{0}\\overline{{\\mathbf{F}}}(\\delta\\mid x)\\,\\mathrm{d}\\delta+\\int_{0}^{\\infty}\\left(1-\\overline{{\\mathbf{F}}}(\\delta\\mid x)\\right)\\mathrm{d}\\delta<\\tau(x)<-\\int_{-\\infty}^{0}\\underline{{\\mathbf{F}}}(\\delta\\mid x)\\,\\mathrm{d}\\delta+\\int_{0}^{\\infty}\\left(1-\\underline{{\\mathbf{F}}}(\\delta\\mid x)\\right)\\mathrm{d}\\delta.\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "Therefore, there is an important distinction between so-called pointwise sharpness and a uniform sharpness[33]. ", "page_idx": 18}, {"type": "text", "text": "In the case of uniform sharpness, a sharp bound coincides with the solution to the partial identification task. This implies that if a bound is uniformly sharp, then the joint bound on the set of quantities, evaluated in two (or more) points of $\\varDelta$ Or $[0,1]$ , is also sharp. Many known bounds (e. g., Fr\u00e9chetHoeffding bounds [39, 49], and marginal sensitivity model bounds [23, 37, 38, 119]) are uniformly sharp. Yet, Makarov bounds are only pointwise sharp. ", "page_idx": 18}, {"type": "text", "text": "", "page_idx": 19}, {"type": "text", "text": "Recent works developed uniformly sharp bounds on the CDF of the CDTE [33]. However, their inference requires a special computational routine for every value of $\\delta/\\alpha$ wrt. the CDF/quantiles of the CDTE. Their usage is further complicated by the fact that the CDFs of the uniformly sharp bounds correspond to mixed-type discrete/continuous random variables. We show an example of the uniformly sharp bounds on the CDF for $\\delta=0$ in Fig. 8. The uniformly sharp bounds may be useful for more complex aleatoric uncertainty quantities (e. g., interval quantities like $\\mathbb{P}(\\delta_{1}\\leq Y[\\dot{1}]-Y[0]\\leq$ $\\delta_{2}\\mid x)$ ) or simultaneous bounds on the variance and the CDF of the CDTE. Nevertheless, in many practical applications, pointwise sharp bounds (Makarov bounds) are enough and we focus on those in our paper. ", "page_idx": 19}, {"type": "image", "img_path": "RDsDvSHGkA/tmp/8477750a7ac23587860efb045a1f7beb48cb00d5c1c4d88662df2ea9a4f789bb.jpg", "img_caption": ["Figure 8: Comparison of pointwise (Makarov) and uniformly sharp bounds on the CDF of the CDTE basedon $i=7$ -th instance of the semi-synthetic IHDP100 dataset [46]. Pointwise (Makarov) bounds are shown in gray . Also, we show uniformly sharp bounds inferred for $\\mathbb{F}(0\\mid x_{7})=\\mathbb{P}(Y[1]\\!-\\!Y[0]\\leq$ $0\\mid x_{7}\\rangle$ ,namely $\\overline{{\\underline{{\\mathbb{F}}}^{0}}}(\\delta\\mid x_{7})$ (shown in red). We display the lower bound in (a) and the upper bounds in (b). Notably, the expectation wrt. $\\mathbb{F}^{0}(\\delta\\mid x_{7})$ coincides with the CATE, $\\tau(x_{7})=\\mathbb{E}(\\Delta\\mid x_{7})$ "], "img_footnote": [], "page_idx": 19}, {"type": "text", "text": "B.3  Makarov bounds for mixed-type outcomes ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "In the following, we provide a connection of the Makarov bounds for the continuous outcome $Y$ (the main target of our paper), with the bounds on the fraction of the negatively affected (FNA) from [60]. The FNA is defined for the binary outcome, $Y\\in\\{0,1\\}$ ,as ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\mathrm{FNA}=\\mathbb{P}(Y[1]-Y[0]<0)=\\mathbb{P}(Y[1]-Y[0]\\leq-1)=\\mathbb{E}(\\mathbb{F}(\\delta=-1\\mid X)).\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "As suggested by [60], sharp bounds on the FNA are given by ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\displaystyle\\frac{\\mathrm{FNA}}{\\mathrm{FNA}}\\leq\\mathrm{FNA}\\leq\\mathrm{FNA},}\\\\ &{\\displaystyle\\frac{\\mathrm{FNA}}{\\mathrm{FNA}}=-\\mathbb{E}\\Big[\\operatorname*{min}\\big(0,\\tau(X)\\big)\\Big]\\quad\\mathrm{and}\\quad\\overline{{\\mathrm{FNA}}}=\\mathbb{E}\\Big[\\operatorname*{min}\\big(\\mu_{0}(X),~1-\\mu_{1}(X)\\big)\\Big].}\\end{array}\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "To connect the Makarov bounds for continuous outcome and the bounds on the FNA, we formulate the following remark. ", "page_idx": 19}, {"type": "text", "text": "Remark 1 (Makarov bounds for mixed-type outcome [129]). Sharp bounds on the CDF of the treatment effect for themixed-type outcome $Y$ are $\\underline{{\\mathbf{F}}}(\\delta\\mid x)\\leq\\mathbb{F}(\\delta\\mid x)\\leq\\overline{{\\mathbf{F}}}(\\delta\\mid x),$ whichare ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\underline{{\\mathbf{F}}}(\\delta\\mid x)=\\left[(\\mathbb{F}_{1}\\mp(\\mathbb{F}_{0}-\\mathbb{F}_{0}))_{\\mathbb{R}}(\\delta\\mid x)\\right]_{+}\\quad a n d\\quad\\overline{{\\mathbf{F}}}(\\delta\\mid x)=1+\\left[(\\mathbb{F}_{1}\\pm(\\mathbb{F}_{0}-\\mathbb{F}_{0}))_{\\mathcal{R}}(\\delta\\mid x)\\right]_{-,\\mathcal{R}}(\\delta,\\eta)_{-,\\mathcal{R}}(\\delta,\\eta)_{-,\\mathcal{R}}(\\delta,\\eta)_{-,\\mathcal{R}}(\\delta,\\eta)_{+,\\mathcal{R}}(\\delta,\\eta)\\right]_{-,\\mathcal{R}}(\\delta,\\eta)_{+,\\mathcal{R}}(\\delta,\\eta),}\\end{array}\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "where $\\mathbb{P}_{0}=\\mathbb{P}(Y[0]=\\cdot\\mid x)=\\mathbb{P}(Y=\\cdot\\mid x,A=0)$ is a probability mass function. ", "page_idx": 19}, {"type": "text", "text": "Notably, for (absolutely) continuous outcome $\\mathbb{P}_{0}=0$ , Eq. (18) matches Eq. (3) of Sec. 3. ", "page_idx": 19}, {"type": "text", "text": "Remark 1 immediately yields the bounds on the FNA, proposed by [60]: ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\begin{array}{r l r}{\\lefteqn{\\frac{\\mathrm{FNA}}{\\mathrm{Sin}}=\\mathbb{E}\\Big[\\operatorname*{max}\\big(\\operatorname*{sup}\\{\\mathbb{P}(Y\\leq y\\mid X,A=1)-\\mathbb{P}(Y\\leq y+1\\mid X,A=0)+\\mathbb{P}(Y=y+1\\mid X,A=0)\\}}\\\\ &{}&{=\\mathbb{E}\\Big[\\operatorname*{max}\\big(0,\\,\\underbrace{0\\mathrm{~}\\!0\\mathrm{~}\\!0\\mathrm{~}(Y\\leq0\\mid X,A=0)+\\mathbb{P}(Y=0\\mid X,A=0)}_{=0},\\,\\underbrace{0\\mathrm{~}\\!0\\mathrm{~}\\!0\\mathrm{~}\\!0\\mathrm{~}\\!0\\mathrm{~}\\!0\\mathrm{~}\\!1\\leq0\\mathrm{~}\\!1\\mathrm{~}\\!0\\mathrm{~}\\!0\\mathrm{~}\\!0\\mathrm{~}\\!0\\mathrm{~}\\!0\\mathrm{~}\\!0\\mathrm{~}\\!0\\mathrm{~}\\!0\\mathrm{~}\\!0\\mathrm{~}\\!0\\mathrm{~}\\!0\\mathrm{~}\\!0\\mathrm{~}\\!0\\mathrm{~}\\!0\\mathrm{~}\\!0\\mathrm{~}\\!0\\mathrm{~}\\!0\\mathrm{~}\\!0\\mathrm{~}\\!0\\mathrm{~}\\!0\\mathrm{~}\\!0\\mathrm{~}\\!0\\mathrm{~}\\!0\\mathrm{~}\\!0\\mathrm{~}\\!0\\mathrm{~}\\!0\\mathrm{~}\\!0\\mathrm{~}\\!0\\mathrm{~}\\!0\\mathrm{~}\\!0\\mathrm{~}\\!0\\mathrm{~}\\!0\\mathrm{~}\\!0\\mathrm{~}\\!0\\mathrm{~}\\!0\\mathrm{~}\\!0\\mathrm{~}\\!0\\mathrm{~}\\!0\\mathrm{~}\\!0\\mathrm{~}\\!0\\mathrm{~}\\!0\\mathrm{~}\\!0\\mathrm{~}\\!0\\mathrm{~}\\!0\\mathrm{~}\\!0\\mathrm{~}\\!0\\mathrm{~}\\!0\\mathrm{~}\\!0\\mathrm{~}\\!0\\mathrm{~}\\!0\\mathrm{~}\\!0\\mathrm{~}\\!0\\mathrm{~}\\!0\\mathrm{~}\\!0\\mathrm{~}\\!0\\mathrm{~}\\!0\\mathrm{~}\\!0\\mathrm{~}\\!0\\mathrm{~}\\!0\\mathrm{~}\\!0\\mathrm{~}\\!0\\mathrm{~}\\!0\\mathrm{~}\\!0\\mathrm{~}\\!0\\mathrm{~}\\!0\\mathrm{~}\\!0\\mathrm{~}\\!0\\mathrm{~}\\!0\\mathrm{~}\\!0\\mathrm{~}\\!0\\mathrm{~}\\!0\\mathrm{~}\\!0\\mathrm{~}\\!0\\mathrm{~}\\!0\\mathrm{~}\\!0\\mathrm{~}\\!0\n$$", "text_format": "latex", "page_idx": 20}, {"type": "equation", "text": "$$\n=\\mathbb{E}\\Big[\\operatorname*{max}\\big(0,-\\mathbb{P}(Y=1\\mid X,A=1)+\\mathbb{P}(Y=1\\mid X,A=0)\\big)\\Big]=\\mathbb{E}\\Big[\\operatorname*{max}\\big(0,-\\tau(X)\\big)\\Big]=-\\mathbb{E}\\Big[\\operatorname*{min}\\big(0,\\tau(X)\\big)\\Big];\n$$", "text_format": "latex", "page_idx": 20}, {"type": "equation", "text": "$$\n\\begin{array}{r l r}{\\lefteqn{\\mathbb{F}\\mathrm{NA}=1+\\mathbb{E}\\Big[\\operatorname*{min}\\big(\\operatorname*{inf}_{\\stackrel{0}{y}\\in\\mathbb{R}}\\{\\mathbb{P}(Y\\leq y\\mid X,A=1)-\\mathbb{P}(Y\\leq y+1\\mid X,A=0)+\\mathbb{P}(Y=y+1\\mid X,A=0)\\},0\\big)\\Big]}\\\\ &{}&{\\stackrel{()}{=}1+\\mathbb{E}\\Big[\\operatorname*{min}\\big(0,\\underbrace{0\\mathrm{-}\\mathbb{P}(Y\\leq0\\mid X,A=0)+\\mathbb{P}(Y=0\\mid X,A=0)}_{=0},\\ 0-\\mathbb{P}(Y\\leq0\\mid X,A=0)+0\\big)}\\\\ &{}&{\\mathbb{P}(Y\\leq0\\mid X,A=1)-1+\\mathbb{P}(Y=1\\mid X,A=0),\\ \\mathbb{P}(Y\\leq0\\mid X,A=1)-1+0\\Big)\\Big]}\\\\ &{}&{=\\mathbb{E}\\Big[\\operatorname*{min}\\big(\\mathbb{P}(Y=1\\mid X,A=0),\\ 1+\\mathbb{P}(Y=1\\mid X,A=0)-\\mathbb{P}(Y=1\\mid X,A=1),\\ 1-\\mathbb{P}(Y=1\\mid X,0)\\big)}\\\\ &{}&{\\stackrel{()}{=}\\mathbb{E}\\Big[\\operatorname*{min}\\big(\\mu_{0}(X),\\underbrace{\\mu_{0}(X)+1-\\mu_{1}(X)}_{>\\mu_{0}(X)\\leq1-\\mu_{1}(X)},\\ 1-\\mu_{1}(X)\\big)\\Big]=\\mathbb{E}\\Big[\\operatorname*{min}\\big(\\mu_{0}(X),\\ 1-\\mu_{1}(X)\\big)\\Big].}\\\\ &{}&{\\stackrel{()}{=}\\sum\\!\\left[\\operatorname*{min}\\big(\\mu_{0}(X),\\underbrace{\\mu_{0}(X)+1-\\mu_{1}(X)}_{>\\mu_{0}(X)\\leq1-\\mu_{1}(X)}\\big)\\right]}\\end{array}\n$$3)454=1)]6\u300b", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "C IPTW-learner ", "text_level": 1, "page_idx": 21}, {"type": "text", "text": "In the following, we develop an improved single-stage learner, namely, an inverse propensity of treatment weighted (IPTW)-learner. First, we revisit the plug-in learner by defining its estimation objective. Then, we introduce the IPTW-learner, which addresses one of the shortcomings of the plug-in learner. At the end, we mention a surprising property of the IPTW-learner, namely, the orthogonality wrt. to target risk aiming at the potential outcome distributions. ", "page_idx": 21}, {"type": "text", "text": "Empirical risk of the plug-in learner. We assume that the plug-in learner (Sec. 4.1) uses the estimators of the conditional outcome CDFs, ${\\widehat{\\mathbb{F}}}_{a}$ , that aim at minimizing the following empirical risk: ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\widehat{\\mathcal{L}}_{\\mathrm{S}/\\mathrm{T},a}(\\widehat{\\boldsymbol{\\eta}}=\\widehat{\\mathbb{F}}_{a})=\\mathbb{P}_{n}\\Big\\{\\mathbb{1}\\{A=a\\}\\,l\\big(Y,\\widehat{\\mathbb{F}}_{a}(\\cdot\\mid X)\\big)\\Big\\},\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "where $l(\\cdot,\\cdot)>0$ is a probabilistic loss (e. g., negative log-likelihood, check score, or CRPS with an empirical CDF). Here, the plug-in learner has two possible variants, namely, S- and T-learner, depending on whether the conditional outcome distribution is learned by a single model or two models [20, 69]. ", "page_idx": 21}, {"type": "text", "text": "IPTW-learner. The IPTW-learner addresses the selection bias of the plug-in learner. For this, it additionally employs an estimated propensity score, $\\hat{\\pi}$ . The estimated propensity score is used to re-weight the original probabilistic loss, $l(\\cdot,\\cdot)$ , in the following way: ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\widehat{\\mathcal{L}}_{\\mathrm{IPTW},a}(\\hat{\\boldsymbol{\\eta}}=(\\hat{\\pi},\\widehat{\\mathbb{F}}_{a}))=\\mathbb{P}_{n}\\Bigg\\{\\frac{\\mathbb{1}\\{\\boldsymbol{A}=a\\}}{\\hat{\\pi}_{a}(\\boldsymbol{X})}\\,l\\big(\\boldsymbol{Y},\\widehat{\\mathbb{F}}_{a}(\\cdot\\mid\\boldsymbol{X})\\big)\\Bigg\\},\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "where $\\hat{\\pi}_{a}(x)=a\\,\\hat{\\pi}(x)+(1-a)\\,(1-\\hat{\\pi}(x))$ The IPTW-learner up-weights the loss of ${\\widehat{\\mathbb{F}}}_{0}$ and $\\widehat{\\mathbb{F}}_{1}$ in the treated and untreated populations, respectively. ", "page_idx": 21}, {"type": "text", "text": "Orthogonality of the IPTW-learner. Interestingly, the IPTW-learner from Eq. (29) can be seen as an orthogonal learner targeting at the following risk: ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\mathcal{L}_{a}(g)=\\mathbb{E}\\Big(l\\big(Y[a],g(\\cdot,X)\\big)\\Big),\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "where $g(\\cdot,x)\\in{\\mathcal{G}}$ is a working model defined as in Sec. 4.2. This target risk aims to find the best approximation of the conditional potential outcome distribution, $\\mathbb{P}(Y[a]\\mid x)$ , with the working model, $g\\in{\\mathcal{G}}$ ", "page_idx": 21}, {"type": "text", "text": "The orthogonality of the IPTW-learner wrt. the target risk aiming at the potential outcome distributions was formally proved in [125]. Therein, the authors notice that the target estimand (e. g., the CDF of one of the potential outcomes) coincides with one of the nuisance functions (i. e., $\\mathbb{F}_{a.}$ 0. Informally, the orthogonality follows from the fact that the working model, $g$ , simultaneously fits the target estimand and the nuisance function. ", "page_idx": 21}, {"type": "text", "text": "The orthogonality of the IPTW-learner can also be seen by (1) performing a one-step bias-correction of Eq. (28) and (2) setting the same estimator for the working model and the nuisance function, i. e., $\\boldsymbol{g}\\;=\\;\\widehat{\\mathbb{F}}_{a}$ . For example, if the probabilistic loss is the CRPS with the empirical CDF, $l(Y,g(\\cdot,X))=\\textstyle\\int_{\\mathcal{Y}}(\\mathbb{1}\\{Y\\leq y\\}\\,\\bar{-}\\,g(y,X))^{\\bar{2}}\\,\\mathrm{d}y,$ the (1) one-step bias-corrected loss is given by [6, 43] ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\widehat{Z}_{\\mathrm{DR},a}(g,\\widehat{\\eta}=(\\widehat{\\pi},\\widehat{\\mathbb{F}}_{a}))=\\!\\mathbb{P}_{n}\\Bigg\\{\\frac{1\\!\\{A=a\\}}{\\widehat{\\pi}_{a}(X)}\\bigg(\\int_{y}(1\\{Y\\leq y\\}-g(y,X))^{2}\\,\\mathrm{d}y}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\qquad-\\int_{y}\\big(\\widehat{\\mathbb{F}}_{a}(y\\mid X)-g(y,X)\\big)^{2}\\,\\mathrm{d}y\\Bigg)+\\int_{y}\\big(\\widehat{\\mathbb{F}}_{a}(y\\mid X)-g(y,X)\\big)^{2}\\,\\mathrm{d}y\\Bigg\\},}\\end{array}\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "where $\\hat{\\pi}_{a}(x)=a\\,\\hat{\\pi}(x)+(1-a)\\,(1-\\hat{\\pi}(x))$ . Then, after step (2), $g=\\widehat{\\mathbb{F}}_{a}$ , we immediately yield the IPTW-learner from Eq. (29). Similarly, for the negative log-likelihood loss (NLL) $l(Y,{\\dot{g}}(\\dot{\\cdot},X))=$ $-\\log g(Y,X)$ , the (1) one-step bias-correction is given by [65, 94] ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\widehat{Z}_{\\mathrm{DR},a}(g,\\widehat{\\eta}=(\\widehat{\\pi},\\widehat{\\mathbb{P}}))=\\mathbb{P}_{n}\\Bigg\\{\\frac{1\\,\\left\\{A=a\\right\\}}{\\widehat{\\pi}_{a}(X)}\\Bigg(-\\log g(Y,X)+\\displaystyle\\int_{\\mathcal{Y}}\\log g(y,X)\\,\\widehat{\\mathbb{P}}(Y=y\\mid X,A=a)\\,\\mathrm{d}y\\Bigg)}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\qquad-\\displaystyle\\int_{\\mathcal{Y}}\\log g(y,X)\\,\\widehat{\\mathbb{P}}(Y=y\\mid X,A=a)\\,\\mathrm{d}y\\Bigg\\},}\\end{array}\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "where $\\hat{\\pi}_{a}(x)\\,=\\,a\\,\\hat{\\pi}(x)+(1\\,-\\,a)\\,(1\\,-\\,\\hat{\\pi}(x))$ and $\\widehat{\\mathbb{P}}$ is an estimator of the conditional density of the outcome. Again, after (2) setting $g=\\widehat{\\mathbb{P}}$ , it is easy to see that the minimization of one-step bias corrected loss in Eq. (32) is equivalent to the minimization of the IPTW-learner's objective in Eq. (29) (where $\\widehat{\\mathbb{P}}$ is used in place of ${\\widehat{\\mathbb{F}}}_{a}$ ). This is possible due to two facts: (1) both entropy terms in Eq. (32), $-\\textstyle\\int_{\\mathcal{Y}}\\log g(\\boldsymbol{y},\\boldsymbol{X})\\,g{\\bar{(y},\\boldsymbol{X})}\\,\\mathrm{d}y$ , only require the minimization wrt. to the working model $g$ under the logarithm; and (2) these entropies are minimal as the cross-entropy for any distribution is minimal when evaluated with itself. ", "page_idx": 22}, {"type": "text", "text": "D Proofs ", "text_level": 1, "page_idx": 23}, {"type": "text", "text": "In the following, we provide the main theoretical results of our paper. We use the following additional notation: $\\delta\\{\\cdot\\}$ is a Dirac delta function, $a\\lesssim b$ means there exists $C$ such that $a\\leq C\\cdot b$ . Also, in the following theorems, we use red color to show the nuisance functions of $\\mathbb{P}$ that are influencing the target estimand. ", "page_idx": 23}, {"type": "text", "text": "D.1  Efficient influence functions ", "text_level": 1, "page_idx": 23}, {"type": "text", "text": "We start with deriving the efficient influence functions for the average Makarov bounds and, afterwards, for the target risks. For that, we make two mild assumptions: (1) one the conditional outcome distributions and (2) another on the set of $\\delta$ where linear rectifiers are differentiable. These assumptions allow us to (1) handle sup-/inf-convolutions as max-/min-convolutions with a finite number of argmax/argmin values and to (2) get a derivative of the linear rectifiers. ", "page_idx": 23}, {"type": "text", "text": "Assumption 1 (Finite argument sets). We assume that the outcome space $\\boldsymbol{\\wp}$ iscompact.Also,we assume that conditional outcomeCDFs, $\\mathbb{F}_{a}(y\\mid x)$ , are continuously differentiable and consist of a finite number of strictly concave / convex regions. ", "page_idx": 23}, {"type": "text", "text": "Assumption 1 implies that sup-/inf-convolutions are achieved by some finite set of values in $\\boldsymbol{\\wp}$ Furthermore, Assumption 1 is a special case of the margin assumption (Assumption 3.2) from [112]. Yet, we find our version to be more interpretable and many regular distributions satisfy it, e. g., an exponential family, finite mixtures of normal distributions, etc. ", "page_idx": 23}, {"type": "text", "text": "Assumption 2 (Differentiability of linear rectifiers). Values of $\\delta\\ \\in\\ \\varDelta$ are considered to satisfy differentiability oflinearrectifierforsome $x\\in{\\mathcal{X}}\\;i f\\left(\\mathbb{F}_{1}\\,{\\overline{{\\ast}}}\\,\\mathbb{F}_{0}\\right)\\!y\\left({\\delta\\mid x}\\right)\\neq0$ ", "page_idx": 23}, {"type": "text", "text": "It is easy to see that, if Assumption 1 holds, the new Assumption 2 will hold for almost all $\\delta\\in{\\varDelta}$ and $x\\in\\mathscr{X}$ . Notably, no additional requirements are needed for the values of $\\alpha\\in[0,1]$ .Therefore, the formulation of the following theorem is not too restrictive. ", "page_idx": 23}, {"type": "text", "text": "Theorem 1 (Efficient influence function for Makarov bounds). Let $\\mathbb{P}$ denotes $\\mathbb{P}(Z)=\\mathbb{P}(X,A,Y)$ and let $y_{\\mathcal{V}}^{\\mp}(\\cdot\\mid x)$ and $u_{[\\alpha,1]}^{\\ast}(\\cdot\\mid x)$ be argmax/argmin sets of the convolutions $(\\mathbb{F}_{1}\\mp\\mathbb{F}_{0})_{\\mathcal{V}}(\\cdot\\mid x)$ and $(\\mathbb{F}_{1}^{-1}\\pm\\mathbb{F}_{0}^{-1})_{[\\alpha,1]}(\\cdot-0\\mid x),$ reetivlmilsnftntu (Assumption $^{\\,l}$ average Makarovbounds are pathwise differentiableforvalues of $\\delta\\in\\Delta$ that satisfy the differentiability of linear rectifiers(Assumption 2) and for all values of $\\alpha\\in(0,1)$ Further,the corresponding efficient infuence functions, $\\phi,$ areasfollows: ", "page_idx": 23}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\quad_{\\phi}(\\mathbb{E}(\\mathbb{E}(\\delta\\mid X));\\mathbb{P})=\\underline{{C}}(\\delta,Z;\\eta)+\\underline{{\\mathbf{F}}}(\\delta\\mid X;\\eta)-\\mathbb{E}\\big(\\mathbb{E}(\\delta\\mid X;\\eta)\\big),}\\\\ &{\\phi(\\mathbb{E}(\\overline{{\\mathbf{E}}}^{-1}(\\alpha\\mid X));\\mathbb{P})=\\overline{{\\underline{{C}}}}^{-1}(\\alpha,Z;\\eta)+\\ \\overline{{\\mathbf{E}}}^{-1}(\\alpha\\mid X;\\eta)-\\mathbb{E}\\big(\\overline{{\\mathbf{E}}}^{-1}(\\alpha\\mid X;\\eta)\\big),}\\\\ &{\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\Big\\lceil\\frac{A}{\\pi(X)}\\Big(\\delta\\mid X)>0\\Big\\rceil\\Bigg[\\frac{A}{\\pi(X)}\\Big(1\\{Y\\leq y^{*}\\}-\\mathbb{F}_{1}\\{y^{*}\\}\\times1\\Big)}\\\\ &{\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad-\\ 1-A\\Big(1\\{Y\\leq y^{*}-\\delta\\}-\\mathbb{F}_{0}\\{y^{*}-\\delta\\mid X\\}\\Big)\\Bigg],}\\\\ &{\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\underline{{C}}^{-1}(\\alpha,Z;\\eta)}\\\\ &{\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\pi(X)\\Bigg(\\frac{1}{\\mathbb{P}\\left(Y=\\mathbb{F}_{1}^{-1}(u^{*}\\mid X)\\right)}\\mid X,A=1\\right)}\\\\ &{\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad-\\ \\frac{1-A}{1-\\pi(X)}\\Bigg(\\frac{1\\{Y\\leq\\mathbb{F}_{0}^{-1}\\left(u^{*}-\\alpha+0\\mid X\\right)\\}-\\left(u^{*}-\\alpha+0\\right)}{\\mathbb{P}\\left(Y=\\mathbb{F}_{0}^{-1}(u^{*}-\\alpha+0\\mid X)\\mid X,A=0\\right)}\\Bigg),}\\end{array}\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "where $y^{\\ast}$ is somevaluefrom $y_{\\mathcal{V}}^{\\ast}(\\delta\\mid X)$ \uff0c $u^{*}$ issomevaluefrom $u_{[\\alpha,1]}^{*}(\\alpha\\mid X)$ :and $\\overline{{C}}(\\delta,Z;\\eta)$ and $\\overline{{C}}^{-1}(\\delta,Z;\\eta)$ can be then obtained by swapping the symbols $\\{\\mp,>,y_{\\mathcal{Y}}^{\\mp},u_{[\\alpha,1]}^{\\pm},-0,+0\\}$ to $\\{\\underline{{*}},<,y_{\\mathcal{D}}^{*},u_{[0,\\alpha]}^{\\overline{{*}}},-1,+1\\}$ ", "page_idx": 23}, {"type": "text", "text": "Proof. We start the proof by employing the properties of the efficient influence functions, namely, product rule and chain rule; and some existing efficient influence functions (e. g., for conditional expectation [63]). ", "page_idx": 23}, {"type": "text", "text": "The efficient infuence function of the lower averaged Makarov bound is as follows: ", "page_idx": 24}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{~~~\\phi(\\mathbb{E}(\\underline{{\\mathbf{F}}}(\\delta\\mid X));\\mathbb{P})=\\mathbb{I}\\mathbb{P}\\Big(\\mathbb{E}\\big(\\underline{{\\mathbf{F}}}(\\delta\\mid X)\\big)\\Big)}\\\\ &{=\\displaystyle\\int_{x}\\Bigg[\\mathbb{I}\\mathbb{F}\\big(\\underline{{\\mathbf{F}}}(\\delta\\mid x)\\big)\\mathbb{P}(X=x)+\\underline{{\\mathbf{F}}}(\\delta\\mid x)\\,\\mathbb{I}\\mathbb{F}\\big(\\mathbb{P}(X=x)\\big)\\Bigg]\\,\\mathrm{d}x}\\\\ &{=\\displaystyle\\int_{x}\\Bigg[\\mathbb{I}\\mathbb{F}\\big(\\underline{{\\mathbf{F}}}(\\delta\\mid x)\\big)\\mathbb{P}(X=x)+\\underline{{\\mathbf{F}}}(\\delta\\mid x)\\,\\{\\delta\\{X-x\\}-\\mathbb{P}(X=x)\\}\\Bigg]\\,\\mathrm{d}x}\\\\ &{=\\displaystyle\\int_{x}\\mathbb{I}\\mathbb{F}\\big(\\underline{{\\mathbf{F}}}(\\delta\\mid x)\\big)\\,\\mathbb{P}(X=x)\\,\\mathrm{d}x+\\underline{{\\mathbf{F}}}(\\delta\\mid X)-\\mathbb{E}\\big(\\underline{{\\mathbf{F}}}(\\delta\\mid X)\\big).}\\end{array}\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "Furthermore, the inner term is ", "page_idx": 24}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{~~\\mathbb{I F}\\big(\\underline{{\\mathbf{F}}}\\big(\\delta\\mid x\\big)\\big)=\\mathbb{I F}\\big(\\,[(\\mathbb{F}_{1}\\mp\\mathbb{F}_{0})_{\\mathcal{Y}}(\\delta\\mid x)]_{+}\\,\\big)}\\\\ &{=\\Big\\{\\mathbb{I F}\\big(\\big(\\mathbb{F}_{1}\\mp\\mathbb{F}_{0}\\big)_{\\mathcal{Y}}(\\delta\\mid x)\\big),}&{~\\mathrm{if}\\quad(\\mathbb{F}_{1}\\mp\\mathbb{F}_{0})_{\\mathcal{Y}}(\\delta\\mid x)>0,}\\\\ &{~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\\mathrm{otherwise}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "Then, the efficient influence function of the sup-convolution can be derived under the finite argument sets assumption and using the envelope theorem (we refer to Appendix C.2.6 and C.2.7 of [83] for further details): ", "page_idx": 24}, {"type": "equation", "text": "$$\n\\mathbb{I\\mathbb{F}}\\big((\\mathbb{F}_{1}\\mp\\mathbb{F}_{0})y(\\delta\\mid x)\\big)=\\mathbb{I\\mathbb{F}}\\bigg(\\operatorname*{sup}_{y\\in\\mathcal{Y}}\\{\\mathbb{F}_{1}(y\\mid x)-\\mathbb{F}_{0}(y-\\delta\\mid x)\\}\\bigg)=\\mathbb{I\\mathbb{F}}\\big(\\mathbb{F}_{1}(y^{\\ast}\\mid x)-\\mathbb{F}_{0}(y^{\\ast}-\\delta\\mid x)\\big),\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "Where $y^{\\ast}$ is some valuefrom $y_{\\mathcal{V}}^{\\overline{{\\ast}}}(\\delta\\mid x)$ . The latter can be expanded by using product and chain rules and the efficient influence function for the conditional expectation. Specifically, we do the following: ", "page_idx": 24}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\quad\\mathbb{I F}\\big(\\mathbb{F}_{1}(y^{*}\\mid x)-\\mathbb{F}_{0}(y^{*}-\\delta\\mid x)\\big)=\\mathbb{I F}\\big(\\mathbb{F}_{1}(y^{*}\\mid x)\\big)-\\mathbb{I F}\\big(\\mathbb{F}_{0}(y^{*}-\\delta\\mid x)\\big)}\\\\ &{=\\mathbb{I F}\\big(\\mathbb{E}(\\mathbb{I}\\{Y\\leq y^{*}\\}\\mid x,A=1)\\big)-\\mathbb{I F}\\big(\\mathbb{E}(\\mathbb{I}\\{Y\\leq y^{*}-\\delta\\}\\mid x,A=0)\\big)}\\\\ &{=\\displaystyle\\int_{y}\\Bigg[\\underbrace{\\mathbb{I F}\\big(\\mathbb{I}\\{y\\leq y^{*}\\}\\big)\\,\\mathbb{P}(Y=y\\mid x,A=1)}_{(1)}+\\underbrace{\\mathbb{I}\\{y\\leq y^{*}\\}\\,\\mathbb{I F}\\big(\\mathbb{P}(Y=y\\mid x,A=1)\\big)}_{(2)}\\Bigg]\\,\\mathrm{d}y}\\\\ &{\\qquad-\\displaystyle\\int_{y}\\Bigg[\\underbrace{\\mathbb{I F}\\big(\\mathbb{I}\\{y\\leq y^{*}-\\delta\\}\\big)\\,\\mathbb{P}(Y=y\\mid x,A=0)}_{(3)}+\\underbrace{\\mathbb{I}\\{y\\leq y^{*}-\\delta\\}\\,\\mathbb{I F}\\big(\\mathbb{P}(Y=y\\mid x,A=0)\\big)}_{(4)}\\Bigg]\\,\\mathrm{d}y.}\\end{array}\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "The terms (2) and (4) yield well-known effcient influence function for CDFs, i. e., ", "page_idx": 24}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\displaystyle\\int_{y}\\left[\\mathbb{1}\\{y\\leq y^{*}\\}\\,\\mathbb{I}\\mathbb{F}\\big(\\mathbb{P}(Y=y\\mid x,A=1)\\big)-\\mathbb{1}\\{y\\leq y^{*}-\\delta\\}\\,\\mathbb{I}\\mathbb{F}\\big(\\mathbb{P}(Y=y\\mid x,A=0)\\right]\\,\\mathrm{d}y}&{{}\\mathrm{(47)}}\\\\ &{=\\!\\left(\\frac{A\\,\\delta\\{X-x\\}}{\\mathbb{P}(X=x,A=1)}\\Big(\\mathbb{1}\\{Y\\leq y^{*}\\}-\\mathbb{F}_{1}(y^{*}\\mid x)\\Big)-\\frac{(1-A)\\,\\delta\\{X-x\\}}{\\mathbb{P}(X=x,A=0)}\\Big(\\mathbb{1}\\{Y\\leq y^{*}-\\delta\\}-\\mathbb{F}_{0}(y^{*}-\\delta\\mid x)\\Big)}\\end{array}\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "Let us now consider the remaining terms (1) and (3): ", "page_idx": 24}, {"type": "equation", "text": "$$\n\\begin{array}{r l r}{\\lefteqn{\\int_{y}\\left[\\mathbb{I}\\mathbb{R}\\big(\\mathbb{1}\\{y\\leq y^{*}\\}\\big)\\,{\\mathbb{P}}(Y=y\\mid x,A=1)-\\mathbb{I}\\mathbb{R}\\big(\\mathbb{1}\\{y\\leq y^{*}-\\delta\\}\\big)\\,{\\mathbb{P}}(Y=y\\mid x,A=0)\\right]\\,\\mathrm{d}y}}&{{\\leq}}&{{(4)}}\\\\ &{}&{=\\!\\int_{y}\\left[-\\delta\\{y-y^{*}\\}\\,\\mathbb{I}\\mathbb{F}(y^{*})\\,{\\mathbb{P}}(Y=y\\mid x,A=1)+\\delta\\{y-(y^{*}-\\delta)\\}\\,\\mathbb{I}\\mathbb{F}(y^{*})\\,\\mathbb{P}(Y=y\\mid x,A=0)\\right]\\,\\mathrm{d}y}\\\\ &{}&{\\stackrel{}{\\times}}&{\\stackrel{}{=}}&{\\!\\left(5^{n},\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!}\\\\ &{}&{\\stackrel{}{\\times}\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!}\\end{/}\\mathbb{I}\\!\\!\\!\\!\\!\\!\\!\\!}\\end{array}\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "where the last equality holds due to the properties of the argmax, $y^{*}\\in y_{\\mathcal{Y}}^{\\overline{{*}}}(\\delta\\mid x)$ . Namely, under the necessary condition fo a local maximum, we have  (I $\\begin{array}{r}{\\frac{\\mathrm{d}}{\\mathrm{d}y}\\big(\\mathbb{F}_{1}(y\\mid x)-\\mathbb{F}_{0}(y-\\delta\\mid x)\\big)=\\mathbb{P}(Y=y\\mid}\\end{array}$ $x,A=1)-\\mathbb{P}(Y=y-\\delta\\mid x,A=0)=0$ . In the context of the efficient influence functions, this ", "page_idx": 24}, {"type": "text", "text": "means that the Makarov bounds are first-order insensitive to the misspecification of argmax/argmin Interestingly, a similar result was demonstrated for the efficient influence functions of the policy values of the optimal policies [82, 85]. ", "page_idx": 25}, {"type": "text", "text": "Finally, we obtain an efficient influence function for the lower Makarov bound by expanding the part $(*)$ of Eq.(40): ", "page_idx": 25}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\quad\\int_{x}\\mathbb{I}\\mathbb{F}\\big({\\bf E}(\\delta\\mid x)\\big)\\,\\mathbb{P}(X=x)\\,\\mathrm{d}x}\\\\ &{=\\!\\int_{x}\\Bigg[1\\!\\left\\{\\left(\\mathbb{F}_{1}\\!\\ast\\mathbb{F}_{0}\\}_{y}(\\delta\\mid x)>0\\right\\}\\!\\Bigg(\\frac{A\\,\\delta\\left\\{X-x\\right\\}}{\\mathbb{P}(X=x,A=1)}\\Big(1\\{Y\\leq y^{\\ast}\\}-\\mathbb{F}_{1}(y^{\\ast}\\mid x)\\Big)\\right.\\Bigg.}\\\\ &{\\quad\\quad\\quad\\quad\\quad\\left.\\left.-\\;\\frac{\\left(1-A\\right)\\,\\delta\\left\\{X-x\\right\\}}{\\mathbb{P}(X=x,A=0)}\\Big(1\\{Y\\leq y^{\\ast}-\\delta\\}-\\mathbb{F}_{0}(y^{\\ast}-\\delta\\mid x)\\Big)\\right)\\right]\\mathbb{P}(X=x)\\,\\mathrm{d}x}\\\\ &{=\\!C(\\delta,Z;\\eta),}\\end{array}\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "where $\\underline{{C}}(\\delta,Z;\\eta)$ is defined in Eq. (35). ", "page_idx": 25}, {"type": "text", "text": "The Makarov bounds on the quantiles are derived analogously. However, several last steps are different. The differences start from Eq. (44): ", "page_idx": 25}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathbb{I}\\mathbb{F}\\big(\\mathbb{F}_{1}^{-1}(u^{*}\\mid x)-\\mathbb{F}_{0}^{-1}(u^{*}-\\alpha\\mid x)\\big)=\\mathbb{I}\\mathbb{F}\\big(\\mathbb{F}_{1}^{-1}(u^{*}\\mid x)\\big)-\\mathbb{I}\\mathbb{F}\\big(\\mathbb{F}_{0}^{-1}(u^{*}-\\alpha\\mid x)\\big),}\\end{array}\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "where $\\boldsymbol{u}^{*}$ is some value from $u_{[\\alpha,1]}^{\\ast}(\\alpha\\mid x)$ ", "page_idx": 25}, {"type": "text", "text": "Now, again, the Makarov bounds for quantiles are first-order insensitive wrt. argmax/argmin values misspecification. Thus, we can employ the efficient influence function for the quantiles [31, 32]: ", "page_idx": 25}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\quad\\mathbb{I F}\\big(\\mathbb{F}_{1}^{-1}(u^{*}\\mid x)\\big)-\\mathbb{I F}\\big(\\mathbb{F}_{0}^{-1}(u^{*}-\\alpha\\mid x)\\big)}\\\\ &{=\\!\\frac{A\\,\\delta\\{X-x\\}}{\\mathbb{P}(X=x,A=1)}\\!\\left(\\!\\frac{\\mathbb{1}\\{Y\\leq\\mathbb{F}_{1}^{-1}\\big(u^{*}\\mid x\\big)\\}-u^{*}}{\\mathbb{P}\\left(Y=\\mathbb{F}_{1}^{-1}(u^{*}\\mid x)\\mid x,A=1\\right)}\\!\\right)}\\\\ &{\\qquad\\quad-\\,\\frac{(1-A)\\,\\delta\\{X-x\\}}{\\mathbb{P}(X=x,A=0)}\\!\\left(\\!\\frac{\\mathbb{1}\\{Y\\leq\\mathbb{F}_{0}^{-1}\\big(u^{*}-\\alpha\\mid x\\big)\\}-\\left(u^{*}-\\alpha\\right)}{\\mathbb{P}\\left(Y=\\mathbb{F}_{0}^{-1}(u^{*}-\\alpha\\mid x)\\mid x,A=0\\right)}\\!\\right)\\!.}\\end{array}\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "The latter then yields the final part $(*)$ of Eq. (40) for the efficient influence function: ", "page_idx": 25}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\quad\\displaystyle\\int_{x}\\mathbb{I}\\mathbb{F}\\big(\\underline{{\\mathbf{F}}}^{-1}(\\alpha\\mid x)\\big)\\,\\mathbb{P}(X=x)\\,\\mathrm{d}x}\\\\ &{=\\displaystyle\\int_{x}\\Bigg[\\frac{A\\,\\delta\\{X-x\\}}{\\mathbb{P}(X=x,A=1)}\\Bigg(\\frac{1\\{Y\\leq\\mathbb{F}_{1}^{-1}\\big(u^{*}\\mid x\\big)\\}-u^{*}}{\\mathbb{P}\\big(Y=\\mathbb{F}_{1}^{-1}(u^{*}\\mid x)\\mid x,A=1\\big)}\\Bigg)}\\\\ &{\\qquad\\qquad\\qquad-\\,\\frac{(1-A)\\,\\delta\\{X-x\\}}{\\mathbb{P}(X=x,A=0)}\\Bigg(\\frac{1\\{Y\\leq\\mathbb{F}_{0}^{-1}\\big(u^{*}-\\alpha\\mid x\\big)\\}-\\big(u^{*}-\\alpha\\big)}{\\mathbb{P}\\big(Y=\\mathbb{F}_{0}^{-1}(u^{*}-\\alpha\\mid x)\\mid x,A=0\\big)}\\Bigg)\\Bigg]\\mathbb{P}(X=x)\\,\\mathrm{d}x}\\\\ &{=\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "where $\\underline{{C}}^{-1}(\\alpha,Z;\\eta)$ is defined in Eq. (36). ", "page_idx": 25}, {"type": "text", "text": "Corollary 1 (Efficient influence functions of the target risks). Let the Assumption $^{\\,l}$ oftheTheorem $^{\\,l}$ hold. Then, the effcient influence functions, $\\phi$ of the target risks in Eq. (6) and Eq. (7) are as follows: ", "page_idx": 25}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\phi(\\overline{{\\mathcal{L}}}_{C R P S}(g);\\mathbb{P})=\\displaystyle\\int_{\\Delta}\\left[2\\left(\\overline{{\\mathbf{E}}}(\\delta\\mid X;\\eta)-g(\\delta,X)\\right)\\,\\overline{{\\underline{{C}}}}(\\delta,Z;\\eta)+\\left(\\overline{{\\mathbf{E}}}(\\delta\\mid X;\\eta)-g(\\delta,X)\\right)^{2}\\right]\\mathrm{d}\\delta}\\\\ &{\\quad\\quad\\quad\\quad\\quad\\quad-\\mathbb{E}\\left(\\int_{\\Delta}\\left(\\overline{{\\mathbf{E}}}(\\delta\\mid X;\\eta)-g(\\delta,X)\\right)^{2}\\mathrm{d}\\delta\\right),}\\\\ &{\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\times\\left(\\overline{{\\int_{\\Delta}}}\\left(\\overline{{\\mathbf{E}}}^{-1}(\\alpha\\mid X;\\eta)-g^{-1}(\\alpha,X)\\right)\\,\\overline{{\\underline{{C}}}}^{-1}(\\alpha,Z;\\eta)+\\left(\\overline{{\\mathbf{E}}}^{-1}(\\alpha\\mid X;\\eta)-g^{-1}(\\alpha,X)\\right)^{2}\\right],}\\end{array}\n$$", "text_format": "latex", "page_idx": 25}, {"type": "equation", "text": "$$\n-\\,\\mathbb{E}\\left(\\int_{0}^{1}\\left(\\underline{{\\mathbf{F}}}^{-1}(\\alpha\\mid X;\\eta)-g^{-1}(\\alpha,X)\\right)^{2}\\mathrm{d}\\alpha\\right),\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "where $\\overline{{C}}(\\delta,Z;\\eta)$ and $\\underline{{\\overline{{C}}}}^{-1}(\\alpha,Z;\\eta)$ are defined in Eq. (35) and (36), respectively. ", "page_idx": 25}, {"type": "text", "text": "Proof. We start by using the properties of the efficient influence function, namely, chain and product rules. Then, the efficient influence function for the CRPS risk of the lower bound is as follows ", "page_idx": 26}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\phi(\\mathcal{L}_{\\mathrm{CRPS}}(g);\\mathbb{P})=\\mathbb{I}\\mathbb{F}\\bigg(\\mathbb{E}\\left(\\int_{\\varDelta}\\left(\\mathbb{E}(\\delta\\mid X)-g(\\delta,X)\\right)^{2}\\mathrm{d}\\delta\\right)\\bigg)}\\\\ &{=\\displaystyle\\int_{\\varDelta}\\mathbb{I}\\mathbb{F}\\bigg(\\int_{\\varDelta}\\left(\\frac{\\mathbf{E}(\\delta\\mid x)-g(\\delta,x)\\right)^{2}\\mathrm{d}\\delta}{(\\ast)}\\right)\\mathbb{P}(X=x)\\,\\mathrm{d}x+\\int_{\\varDelta}\\left(\\frac{\\mathbf{F}(\\delta\\mid X)-g(\\delta,X)\\right)^{2}\\mathrm{d}\\delta}{2}}\\\\ &{-\\mathbb{E}\\left(\\int_{\\varDelta}\\left(\\mathbf{E}(\\delta\\mid X)-g(\\delta,X)\\right)^{2}\\mathrm{d}\\delta\\right).}\\end{array}\n$$", "text_format": "latex", "page_idx": 26}, {"type": "text", "text": "We then note, that the inner term of the $(*)$ can be expanded as: ", "page_idx": 26}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\displaystyle\\mathbb{I}\\mathbb{I}\\mathbb{F}\\bigg(\\int_{A}\\left(\\mathbf{\\underline{{F}}}(\\delta\\mid x)-g(\\delta,x)\\right)^{2}\\mathrm{d}\\delta\\bigg)=\\int_{A}\\mathbb{I}\\mathbb{F}\\bigg(\\left(\\mathbf{\\underline{{F}}}(\\delta\\mid x)-g(\\delta,x)\\right)^{2}\\bigg)\\,\\mathrm{d}\\delta}\\\\ &{\\displaystyle=2\\int_{A}\\left(\\mathbf{\\underline{{F}}}(\\delta\\mid x)-g(\\delta,x)\\right)\\mathbb{I}\\mathbb{F}\\big(\\mathbf{\\underline{{F}}}(\\delta\\mid x)\\big)\\,\\mathrm{d}\\delta.}\\end{array}\n$$", "text_format": "latex", "page_idx": 26}, {"type": "text", "text": "Finally, the term $(*)$ of Eq. (65) equals to ", "page_idx": 26}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\quad\\int_{X}\\mathbb{I}\\mathbb{F}\\bigg(\\int_{\\varDelta}\\left(\\frac{\\mathbf{F}}{\\imath}(\\delta\\mid x)-g(\\delta,x)\\right)^{2}\\mathrm{d}\\delta\\bigg)\\,\\mathbb{P}(X=x)\\,\\mathrm{d}x}\\\\ &{=\\!2\\int_{X}\\int_{\\varDelta}\\left(\\mathbf{E}(\\delta\\mid x)-g(\\delta,x)\\right)\\,\\mathbb{I}\\mathbb{F}\\big(\\mathbf{E}(\\delta\\mid x)\\big)\\,\\mathbb{P}(X=x)\\,\\mathrm{d}\\delta\\,\\mathrm{d}x}\\\\ &{=\\!2\\int_{A}\\left(\\mathbf{E}(\\delta\\mid X)-g(\\delta,X)\\right)\\,\\underline{{C}}(\\delta,Z;\\eta)\\,\\mathrm{d}\\delta.}\\end{array}\n$$", "text_format": "latex", "page_idx": 26}, {"type": "text", "text": "The derivations for the upper bound and for the $W_{2}^{2}$ target risk is fully analogous. ", "page_idx": 26}, {"type": "text", "text": "Corollary 2 (One-step bias-corrected estimator of the target risks). Let the Assumption 1 of the Theorem1hold.Then,the $\\gamma$ -scaled one-step bias-corrected estimator of the target risks Eq. (6) and Eq. (7) is given by the following: ", "page_idx": 26}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\widehat{\\underline{{\\mathcal{L}}}}_{A U,\\,C R P S}(g,\\widehat{\\eta}=\\big(\\widehat{\\pi},\\widehat{\\mathbb{R}}_{0},\\widehat{\\mathbb{R}}_{1}\\big))=\\mathbb{P}_{n}\\Big\\{\\ \\int_{\\varDelta}\\big(\\overline{{\\mathbb{E}}}_{D R}(\\delta,Z;\\widehat{\\eta},\\gamma)-g(\\delta,X)\\big)^{2}\\,\\mathrm{d}\\delta\\Big\\},}\\\\ &{\\ddot{\\lesssim}_{A U,\\mathcal{K}_{2}^{2}}(g^{-1},\\widehat{\\eta}=\\big(\\widehat{\\pi},\\widehat{\\mathbb{R}}_{0}^{-1},\\widehat{\\mathbb{F}}_{1}^{-1}\\big))=\\mathbb{P}_{n}\\Big\\{\\ \\int_{0}^{1}\\big(\\overline{{\\mathbb{E}}}_{D R}^{-1}(\\alpha,Z;\\widehat{\\eta},\\gamma)-g^{-1}(\\alpha,X)\\big)^{2}\\,\\mathrm{d}\\alpha\\Big\\},}\\\\ &{\\ddot{\\mathfrak{L}}_{D R}(\\delta,Z;\\widehat{\\eta},\\gamma)=\\overline{{\\mathbb{E}}}_{P I}(\\delta\\mid X;\\widehat{\\eta})+\\gamma\\overline{{\\mathcal{L}}}(\\delta,Z;\\widehat{\\eta})\\quad{a n d}\\quad\\overline{{\\mathbb{E}}}_{D R}^{-1}(\\alpha,Z;\\widehat{\\eta},\\gamma)=\\overline{{\\mathbb{E}}}_{P I}^{-1}(\\alpha\\mid X;\\widehat{\\eta})+\\gamma\\overline{{\\mathbb{C}}}^{-1}(\\alpha,\\gamma)}\\end{array}\n$$", "text_format": "latex", "page_idx": 26}, {"type": "text", "text": "\u03b1, Z;n): where $\\overline{{C}}(\\delta,Z;\\hat{\\eta})$ and $\\underline{{\\overline{{C}}}}^{-1}(\\alpha,Z;\\hat{\\eta})$ are given by Eq. (35) and (36), respectively; and $\\gamma\\in(0,1]$ $a$ scaling hyperparameter. ", "page_idx": 26}, {"type": "text", "text": "Proof.The $\\gamma$ scaled one-step bias-corrected estimator of the CRPS target risk proceeds as follows: ", "page_idx": 26}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\begin{array}{r l r}&{\\widehat{\\mathcal{L}}_{\\mathrm{FI,\\,CRPS}}\\!\\left(g,\\widehat{\\eta}\\right)\\!+\\gamma\\mathbb{P}_{n}\\!\\left\\{\\phi\\!\\left(\\overline{{\\mathcal{L}}}_{\\mathrm{CRPS}}(g);\\widehat{\\mathbb{P}}\\right)\\right\\}\\!\\!}&{=}&{\\!\\!\\left(73\\right)\\widehat{\\mathcal{L}}_{\\mathrm{FI}},}\\\\ &{=\\!\\!\\mathbb{P}_{n}\\!\\left\\{\\int_{\\varDelta}\\left(\\overline{{\\mathbb{E}}}_{\\mathrm{PI}}(\\delta,Z;\\widehat{\\eta},\\gamma)-g(\\delta,X)\\right)^{2}\\mathrm{d}\\delta\\right\\}\\!\\!}&{=\\!\\!\\left(74\\right)\\!}\\\\ &{\\quad+\\gamma\\mathbb{P}_{n}\\!\\left\\{\\int_{\\varDelta}\\left[2\\left(\\overline{{\\mathbb{E}}}_{\\mathrm{PI}}(\\delta\\mid X;\\widehat{\\eta})-g(\\delta,X)\\right)\\,\\overline{{\\mathbb{Z}}}(\\delta,Z;\\widehat{\\eta})+\\left(\\overline{{\\mathbb{E}}}_{\\mathrm{PI}}(\\delta\\mid X;\\widehat{\\eta})-g(\\delta,X)\\right)^{2}\\right]\\mathrm{d}\\delta\\right\\}\\!}&{}\\end{array}}\\\\ &{\\begin{array}{r l}&{\\quad-\\gamma\\mathbb{P}_{n}\\!\\left\\{\\int_{\\varDelta}\\left(\\overline{{\\mathbb{E}}}_{\\mathrm{PI}}(\\delta\\mid X;\\widehat{\\eta})-g(\\delta,X)\\right)^{2}\\mathrm{d}\\delta\\right\\}\\!=\\!\\!}&{\\!\\!\\!(75)\\!}\\\\ &{\\quad=\\!\\!\\mathbb{P}_{n}\\!\\left\\{\\int_{\\varDelta}\\left(\\overline{{\\mathbb{E}}}_{\\mathrm{PI}}(\\delta,Z;\\widehat{\\eta},\\gamma)-g(\\delta,X)\\right)^{2}\\mathrm{d}\\delta\\right\\}\\!+\\gamma\\mathbb{P}_{n}\\!\\left\\{\\int_{\\varDelta}2\\left(\\overline{{\\mathbb{E}}}_{\\mathrm{PI}}(\\delta\\mid X;\\widehat{\\eta})-g(\\delta,X)\\right)\\,\\overline{{\\mathbb{Z}}}(\\delta,Z;\\widehat{\\eta})\\,\\mathrm{d}\\delta\\right\\}\\!}\\end{array}}\\\\ &{\\begin{array}{r l}&{=\\!\\!\\mathbb{P}_{n}\\!\\left\\{\\int_{\\varDelta}\\left(\\overline{{\\mathbb{E}}}_{\\mathrm{PI}}(\\delta,Z;\\widehat{\\eta},\\gamma)-g(\\delta,X)\\right)^{2}\\mathrm{d}\\delta\\right\\}\\!+\\gamma\\mathbb{P}_{n}\n$$", "text_format": "latex", "page_idx": 26}, {"type": "text", "text": "The minimization of the latter wrt. $g$ is then equivalent to the minimization of ", "page_idx": 27}, {"type": "equation", "text": "$$\n\\mathbb{P}_{n}\\Big\\{\\int_{\\varDelta}\\big(\\overline{{\\underline{{\\mathbf{F}}}}}_{\\mathrm{PI}}(\\delta\\mid X;\\hat{\\eta})+\\gamma\\,\\overline{{\\underline{{C}}}}(\\delta,Z;\\hat{\\eta})-g(\\delta,X)\\big)^{2}\\,\\mathrm{d}\\delta\\Big\\}.\n$$", "text_format": "latex", "page_idx": 27}, {"type": "text", "text": "The proof for the $\\gamma.$ scaled one-step bias-corrected estimator of the $W_{2}^{2}$ target risk is analogous. ", "page_idx": 27}, {"type": "text", "text": "D.2  Neyman-orthogonality and double robustness ", "text_level": 1, "page_idx": 27}, {"type": "text", "text": "Now, we proceed with the second main theoretical result. Here, we use additional notation. ", "page_idx": 27}, {"type": "text", "text": "Definition 1 (Neyman-orthogonality [35, 96]). A risk $\\mathcal{L}$ is called Neyman-orthogonal if its pathwise cross-derivative equals to zero, namely, ", "page_idx": 27}, {"type": "equation", "text": "$$\nD_{\\eta}D_{g}\\mathcal{L}(g_{*},\\eta)[g-g_{*},\\hat{\\eta}-\\eta]=0\\quad f o r\\,a l l\\,g\\in\\mathcal{G},\n$$", "text_format": "latex", "page_idx": 27}, {"type": "text", "text": "where $\\begin{array}{r}{D_{f}F(f)[h]\\,=\\,\\frac{\\mathrm{d}}{\\mathrm{d}t}F(f+t h)|_{t=0}}\\end{array}$ and $\\begin{array}{r}{D_{f}^{k}F(f)[h_{1},\\ldots,h_{k}]\\,=\\,\\frac{\\partial^{k}}{\\partial t_{1}\\ldots\\partial t_{k}}F(f+t_{1}h_{1}+\\cdot\\cdot\\cdot+}\\end{array}$ $t_{k}h_{k})|_{t_{1}=\\cdots=t_{k}=0}$ are pathwise derivatives $[35J,$ $g_{*}=\\arg\\operatorname*{min}_{g\\in\\mathcal{G}}\\mathcal{L}(g,\\eta)$ and $\\eta$ is the ground-truth nuisance function. ", "page_idx": 27}, {"type": "text", "text": "Informally, this definition means that the risk is first-order insensitive wrt. to the misspecification of the nuisance functions. Notably, the pathwise derivative in the direction of the Dirac delta distribution coincides with to the efficient infuence function [34, 63], i. e., $D_{\\mathbb{P}}F(\\mathbb{P})[\\delta\\{Z-\\cdot\\}-\\mathbb{P}(Z=\\cdot)]=$ $\\phi(\\mathbb{F}(\\mathbb{P});\\mathbb{P})$ ,where $\\mathbb{P}(Z=\\cdot)$ is the PDF of the $\\mathbb{P}(Z)$ ", "page_idx": 27}, {"type": "text", "text": "Theorem 2 (Neyman-orthogonality of AU-learner). Under the assumptions of the Theorem $^{\\,l}$ the followingholds for AU-learner from Algorithm $^{\\,l}$ withthescalinghyperparameter $\\gamma=1$ ", "page_idx": 27}, {"type": "text", "text": "1. Neyman-orthogonality. Population versions of the empirical risks in Eq. (71) and Eq. (71) are first-order insensitive wrt. to the misspecification of the nuisance functions, $i.\\,e.$ ", "page_idx": 27}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{D_{\\eta}D_{g}\\underline{{\\mathcal{L}}}_{A U,C R P S}(g_{*},\\eta)[g-g_{*},\\hat{\\eta}-\\eta]=0\\quad f o r\\;a l l\\;g\\in\\mathcal{G},}\\\\ &{D_{\\eta}D_{g}\\underline{{\\mathcal{L}}}_{A U,W_{2}^{2}}(g_{*}^{-1},\\eta)[g^{-1}-g_{*}^{-1},\\hat{\\eta}-\\eta]=0\\quad f o r\\;a l l\\;g^{-1}:g\\in\\mathcal{G},}\\end{array}\n$$", "text_format": "latex", "page_idx": 27}, {"type": "text", "text": "where $g_{*}=\\arg\\operatorname*{min}_{g\\in\\mathcal{G}}\\overline{{\\mathcal{L}}}_{A U,C R P S}(g,\\eta)$ and $\\begin{array}{r}{g_{*}^{-1}=\\arg\\operatorname*{min}_{g^{-1}:g\\in\\mathcal{G}}\\overline{{\\mathcal{L}}}_{A U,W_{2}^{2}}(g^{-1},\\eta).}\\end{array}$ ", "page_idx": 27}, {"type": "text", "text": "2. Rate double robustness. The bias from the misspecification of the nuisance functions is of second order and vanishes at the same rate as the fastest estimated nuisance functions.Specifically, with theprobability of at least $1-\\delta$ thefollowingholds ", "page_idx": 27}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\left\\lVert\\widehat{\\underline{{g}}}-g_{*}\\right\\rVert_{\\mathcal{G}}^{2}\\;\\;a n d\\;\\left(\\overline{{\\underline{{\\mathcal{L}}}}}_{A U,\\diamond}(\\widehat{\\underline{{g}}},\\eta)-\\overline{{\\underline{{\\mathcal{L}}}}}_{A U,\\diamond}(g_{*},\\eta)\\right)\\;\\lesssim\\;\\mathrm{Rate}_{\\mathcal{D}}(\\mathcal{G},\\delta/2;\\widehat{\\underline{{g}}},\\widehat{\\eta})+\\left\\lVert\\widehat{\\eta}-\\eta\\right\\rVert^{4},}\\end{array}\n$$", "text_format": "latex", "page_idx": 27}, {"type": "text", "text": "where $\\mathrm{Rate}_{\\mathcal{D}}(\\mathcal{G},\\delta/2;\\widehat{\\underline{{g}}},\\hat{\\eta})$ is the bound forthe estimation error of the second stage of learning, namely, ", "page_idx": 27}, {"type": "equation", "text": "$$\n\\big(\\overline{{\\underline{{\\mathcal{L}}}}}_{A U,\\diamond}(\\widehat{\\underline{{g}}},\\widehat{\\eta})-\\overline{{\\underline{{\\mathcal{L}}}}}_{A U,\\diamond}(g_{*},\\widehat{\\eta})\\big)\\leq\\mathrm{Rate}_{\\mathcal{D}}(\\mathcal{G},\\delta/2;\\widehat{\\underline{{g}}},\\widehat{\\eta}).\n$$", "text_format": "latex", "page_idx": 27}, {"type": "text", "text": "Furthermore, if the nuisance functions are estimated sufficiently fast, i.e., $\\left\\|{\\hat{\\eta}}-\\eta\\right\\|^{2}=o(n^{-1/2})$ then the AU-learner achieves the quasi-oracle property (the estimation error of the second stage with theestimated nuisancefunctionsbehavesin thesameway asif theground-truth nuisance functionswereused). ", "page_idx": 27}, {"type": "text", "text": "Proof. 1. Neyman-orthogonality. The Neyman-orthogonality follows by the construction of the AU-learner as a one-step bias-corrected estimator. Specifically, it is easy to verify that the pathwise cross-derivative from Eq. (78) is equal to zero. ", "page_idx": 27}, {"type": "text", "text": "Let us consider the CRPS risk. First, we find a pathwise derivative wrt. working model $g$ ", "page_idx": 27}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\quad{\\cal D}_{g}\\overline{{\\mathcal{L}}}_{\\mathrm{AU,CRPS}}(g_{*},\\eta)[g-g_{*}]=\\displaystyle\\frac{\\mathrm{d}}{\\mathrm{d}t}\\mathbb{E}\\bigg[\\int_{\\varDelta}\\left(\\overline{{\\mathbb{E}}}_{\\mathrm{DR}}(\\delta,Z;\\eta,\\gamma)-g_{*}(\\delta,X)-t(g(\\delta,X)-g_{*}(\\delta,X))\\right)^{2}\\mathrm{d}\\delta\\bigg]\\bigg\\rvert_{t=0}}\\\\ &{=-2\\mathbb{E}\\bigg[\\int_{\\varDelta}\\left(\\overline{{\\mathbb{E}}}_{\\mathrm{DR}}(\\delta,Z;\\eta,\\gamma)-g_{*}(\\delta,X)-t(g(\\delta,X)-g_{*}(\\delta,X))\\right)\\left.\\left(g(\\delta,X)-g_{*}(\\delta,X)\\right)\\mathrm{d}\\delta\\right]\\bigg\\rvert_{t=0}}\\\\ &{=-2\\mathbb{E}\\bigg[\\int_{\\varDelta}\\left(\\overline{{\\mathbb{E}}}_{\\mathrm{DR}}(\\delta,Z;\\eta,\\gamma)-g_{*}(\\delta,X)\\right)\\left.\\left(g(\\delta,X)-g_{*}(\\delta,X)\\right)\\mathrm{d}\\delta\\right].}\\end{array}\n$$", "text_format": "latex", "page_idx": 27}, {"type": "equation", "text": "$$\n\\begin{array}{r l r l}&{\\quad_{D}x_{D,\\varepsilon\\wedge(-1)}\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\! \n$$", "text_format": "latex", "page_idx": 28}, {"type": "equation", "text": "$$\n\\begin{array}{l}{\\displaystyle=2\\gamma\\mathbb{E}_{X}\\left[\\int_{\\Delta}I(X;\\eta)\\Bigg[\\frac{\\mathbb{P}(A=1\\mid X)}{(\\pi(X))^{2}}\\Big(\\mathbb{E}(1\\{Y\\leq y^{*}\\}\\mid X,A=1)-\\mathbb{F}_{1}\\big(y^{*}\\mid X\\big)\\Big)\\right.}\\\\ {\\displaystyle\\left.\\qquad+\\left.\\frac{\\mathbb{P}(A=0\\mid X)}{(1-\\pi(X))^{2}}\\left(\\mathbb{E}(1\\{Y\\leq y^{*}-\\delta\\}\\mid X,A=0)-\\mathbb{F}_{0}\\big(y^{*}-\\delta\\mid X\\big)\\right)\\right](\\hat{\\pi}(X)-\\pi(X))\\left(g(\\delta,X)-g_{*}(\\delta,X)\\right)}\\end{array}\n$$", "text_format": "latex", "page_idx": 28}, {"type": "equation", "text": "$$\n=2\\gamma\\mathbb{E}_{X}\\left[\\int_{\\varDelta}I(X;\\eta)\\left[\\frac{1}{\\pi(X)}\\,0+\\frac{1}{1-\\pi(X)}\\,0\\right](\\hat{\\pi}(X)-\\pi(X))\\left(g(\\delta,X)-g_{*}(\\delta,X)\\right)\\,\\mathrm{d}\\delta\\right]=0,\n$$", "text_format": "latex", "page_idx": 28}, {"type": "text", "text": "where $I(X;\\eta)=\\mathbb{1}\\big\\{(\\mathbb{F}_{1}\\mp\\mathbb{F}_{0})_{\\mathcal{Y}}(\\delta\\mid X)>0\\big\\}$ or $\\mathbb{1}\\big\\{(\\mathbb{F}_{1}\\pm\\mathbb{F}_{0})\\y(\\delta\\mid X)<0\\big\\}$ ; and $y^{\\ast}$ is some value from $y\\bar{\\frac{*}{y}}(\\delta\\mid X)$ ", "page_idx": 28}, {"type": "text", "text": "The derivatives wrt. the conditional CDF $\\mathbb{F}_{1}$ is ", "page_idx": 28}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{D_{P_{1}}D_{P_{2}}\\mathbb{E}_{\\omega,\\mathrm{C},\\mathrm{oross}}(\\phi_{P},\\eta)[\\phi-g_{s},\\Tilde{\\mathbf{p}}_{1}-\\Tilde{\\mathbf{p}}_{1}]}&{\\quad{\\scriptstyle(\\mathrm{SF})\\subseteq\\Omega_{\\mathrm{C}}\\quad(\\mathrm{SF})\\subseteq\\Omega_{\\mathrm{C}}\\quad}}\\\\ {=\\frac{\\displaystyle\\mathrm{d}}{\\displaystyle\\mathrm{d}t}-2\\mathbb{E}\\Bigg[\\int_{0}\\left(\\mathbb{E}_{\\mathbf{R}}(\\Tilde{\\delta},\\Tilde{\\xi};\\eta=(\\Tilde{\\mathbb{P}}_{0},\\Tilde{\\mathbb{P}}_{1}+t(\\Tilde{\\hat{P}}_{1}-\\Tilde{\\mathbb{P}}_{1})),\\gamma)-g_{s}(\\Tilde{\\delta},X)\\right)\\left(g(\\Tilde{\\delta},X)-g_{s}(\\Tilde{\\delta},X)\\right)\\mathbb{d}\\hat{d}\\Bigg]_{\\mathrm{reo}}}&{\\quad{\\scriptstyle(\\mathrm{SF})\\subseteq\\Omega_{\\mathrm{C}}\\quad}}\\\\ {=\\frac{\\displaystyle\\mathrm{d}}{\\mathrm{d}t}-2\\mathbb{E}\\Bigg[\\int_{0}\\left(\\mathbb{E}_{\\mathbf{R}}(\\Tilde{\\delta},\\Tilde{\\xi};\\eta=(\\mathbb{P}_{0},\\Tilde{\\mathbb{P}}_{1}+t(\\Tilde{\\hat{P}}_{1}-\\Tilde{\\mathbb{P}}_{1}))\\right)\\right.}\\\\ {\\qquad\\qquad\\qquad\\qquad\\left.+\\gamma\\overline{{Z}}(\\Tilde{\\delta},\\Tilde{\\xi};\\eta=(\\pi,\\mathbb{P}_{0},\\Tilde{\\mathbb{P}}_{1}+t(\\Tilde{\\hat{P}}_{1}-\\Tilde{\\mathbb{P}}_{1})))\\right)\\left(g(\\Tilde{\\delta},X)-g_{s}(\\Tilde{\\delta},X)\\right)\\mathbb{d}\\hat{d}\\Bigg]_{\\mathrm{reo}}}\\\\ {=-2\\mathbb{E}\\Bigg[\\int_{0}I(X;\\eta=(\\Tilde{\\mathbb{P}}_{0},\\Tilde{\\mathbb{P}}_{1}+0(\\Tilde{\\hat{\\mathbb{P}}}_{1}-\\mathbb{P}_{1}))\\frac{\\mathrm{d}}{\\mathrm{d}t}\\Bigg[\\mathbb{E}_{\\mathbf{I}}\\left(\\Tilde{\\phi}^{*}(t)\\mid X\\right)}\\\\ {\\qquad\\qquad\\qquad\\quad+t\\left(\\Tilde{\\mathbb{P}}_{1}(\\Tilde \n$$", "text_format": "latex", "page_idx": 28}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{-2\\nu\\Bigg[\\int_{\\Delta}t(\\nabla\\varphi(\\mathbf{u})|\\mathcal{S}_{\\alpha})^{\\perp}\\Bigg]_{\\alpha}}&{=\\beta\\Bigg[\\mathrm{s}_{0}(\\nabla\\varphi(\\mathbf{u})|\\mathcal{S}_{\\alpha})^{\\perp}\\Bigg]_{\\alpha}\\mathrm{e}^{-\\alpha\\beta}\\Bigg[\\mathrm{s}_{0}(\\nabla\\varphi(\\mathbf{u})|\\mathcal{S}_{\\alpha})^{\\perp}\\Bigg]_{\\alpha}}\\\\ &{\\qquad+\\beta\\Bigg(\\nu\\nabla\\varphi(\\mathbf{u})|\\mathcal{S}_{\\alpha}-\\gamma_{0}(\\nabla\\varphi(\\mathbf{u})|\\mathcal{S}_{\\alpha})^{\\perp}\\Bigg)_{\\alpha}}\\\\ &{\\qquad+\\frac{\\alpha}{\\sqrt{\\pi}}\\Bigg(\\frac{\\alpha_{0}^{2}}{1+\\nu^{2}}\\left(\\nabla\\varphi(\\mathbf{u})|\\mathcal{S}_{\\alpha}-\\nabla\\varphi(\\varphi(\\mathbf{u}))\\right)\\Bigg]_{\\alpha}\\mathrm{e}^{-\\alpha\\beta}\\Bigg[\\mathrm{s}_{0}(\\nabla\\varphi(\\mathbf{u})|\\mathcal{S}_{\\alpha})^{\\perp}-\\mathrm{P}_{0}(\\nabla\\varphi(\\mathbf{u})|\\mathcal{S}_{\\alpha})^{\\perp}\\Bigg]_{\\alpha}}\\\\ &{\\qquad-\\frac{\\alpha_{0}^{2}}{1-\\nu^{2}}\\left(\\mathrm{s}_{0}(\\nabla\\varphi(\\mathbf{u})|\\mathcal{S}_{\\alpha})^{\\perp}-\\mathrm{P}_{0}(\\nabla\\varphi(\\mathbf{u})|\\mathcal{S}_{\\alpha})^{\\perp}\\right)_{\\alpha}}\\\\ &{\\qquad-\\frac{\\alpha_{0}^{2}}{1-\\nu^{2}}\\Bigg[\\int_{\\Delta}t(\\nabla\\varphi(\\mathbf{u})|\\mathcal{S}_{\\alpha})^{\\perp}\\Bigg]_{\\alpha}\\mathrm{e}^{-\\alpha\\beta}\\Bigg[\\mathrm{s}_{0}(\\nabla\\varphi(\\mathbf{u})|\\mathcal{S}_{\\alpha})^{\\perp}\\Bigg]_{\\alpha}\\mathrm{e}^{-\\alpha\\beta}\\Bigg[\\mathrm{s}_{0}(\\nabla\\varphi(\\mathbf{u})|\\mathcal{S}_{\\alpha})^{\\perp}\\Bigg]_{\\alpha}}\\\\ &{\\qquad-2\\alpha_{0}^{2}\\Bigg[\\int_{\\Delta}t(\\nabla\\varphi(\\mathbf{u})|\\mathcal{S}_{\\alpha})^{\\perp}\\Bigg]_{\\alpha}\\mathrm{e}^{-\\alpha\\beta}\\Bigg[\\mathrm{s}_{0}(\\nabla\\varphi(\\mathbf{u}) \n$$", "text_format": "latex", "page_idx": 29}, {"type": "text", "text": "where $I(X;\\eta)\\;\\;=\\;\\;\\mathbb{1}\\big\\{(\\mathbb{F}_{1}\\,\\mp\\mathbb{F}_{0})_{\\mathcal{Y}}(\\delta\\;\\;\\mid\\;\\;X)\\;\\>\\;\\;0\\big\\}$ or $\\mathbb{1}\\big\\{(\\mathbb{F}_{1}\\triangleq\\mathbb{F}_{0})_{\\mathcal{Y}}(\\delta\\textbf{\\textit{1}}X)\\ <\\ 0\\big\\}$ . $\\tilde{y}^{*}(t)$ is some value from $\\tilde{y}_{\\mathcal{D}}^{\\mp}(\\delta\\mathrm{~\\ensuremath~{~\\vert~}~}X);\\;\\;\\tilde{y}_{\\mathcal{D}}^{\\mp}(\\cdot\\mathrm{~\\ensuremath~{~\\vert~}~}X)$ are the argmax/argmin sets of the convolutions $(\\mathbb{F}_{1}+t(\\hat{\\mathbb{F}}_{1}-\\mathbb{F}_{1})\\,\\underline{{\\ast}}\\,\\underline{{\\lor}}_{0})_{\\mathcal{V}}(\\cdot\\,\\mid\\,X)$ ; and $(\\ast)~=~0$ follows from the the same considerations as in Eq. (51). Analogously, the pathwise derivative wrt. $\\mathbb{F}_{0}$ can be shown to be equal to zero. We refer to the appendices of [96] for more details. ", "page_idx": 29}, {"type": "text", "text": "The Neyman-orthogonality of the $W_{2}^{2}$ population risk can be proved in a similar fashion. First, the pathwise derivative wrt. $g^{-1}$ has a similar form to Eq. (85), namely ", "page_idx": 29}, {"type": "equation", "text": "$$\nD_{g}\\mathbb{\\overline{{Z}}}_{\\mathrm{AU},W_{2}^{2}}(g_{*}^{-1},\\eta)[g^{-1}-g_{*}^{-1}]=-2\\mathbb{E}\\Big[\\int_{0}^{1}\\big(\\overline{{\\mathbf{E}}}_{\\mathrm{DR}}^{-1}(\\alpha,Z;\\widehat{\\boldsymbol{\\eta}},\\gamma)-g_{*}^{-1}(\\alpha,X)\\big)\\,\\left(g^{-1}(\\alpha,X)-g_{*}^{-1}(\\alpha,X)\\right)\\,\\mathrm{d}\\alpha\\Big].\n$$", "text_format": "latex", "page_idx": 29}, {"type": "text", "text": "Furthermore, similarly to the CRPS target risk, the cross-derivative wrt. to the propensity score is ", "page_idx": 29}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\quad{\\cal D}_{\\tau}{\\cal D}_{\\phi}\\!\\!\\!\\!\\!C_{\\mathrm{s},\\mathrm{M},\\eta}^{\\epsilon}\\!\\!\\!\\int_{0}^{\\infty}\\!\\!\\!\\!\\!\\!C_{-1}^{-1}\\eta[\\phi^{-1}-g_{*}^{-1}]\\,\\hat{\\eta}-\\pi]}\\\\ &{\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\! \n$$", "text_format": "latex", "page_idx": 29}, {"type": "text", "text": "where $u^{*}$ is some value from $u_{[\\alpha,1]}^{\\ast}(\\alpha\\mid X)$ Thecro-eriative for theu bodfollow similarly. ", "page_idx": 29}, {"type": "text", "text": "Finally, to show that a cross-derivative wrt. $\\mathbb{F}_{1}^{-1}$ , we make use of the following property of the derivative of the quantiles (inverse function rule): ", "page_idx": 30}, {"type": "equation", "text": "$$\n\\frac{\\mathrm{d}}{\\mathrm{d}\\alpha}\\Big[\\mathbb{F}^{-1}(\\alpha)+t(\\hat{\\mathbb{F}}^{-1}(\\alpha)-\\mathbb{F}^{-1}(\\alpha))\\Big]=\\frac{1}{\\mathbb{P}(\\tilde{Y}=\\mathbb{F}^{-1}(\\alpha)+t(\\hat{\\mathbb{F}}^{-1}(\\alpha)-\\mathbb{F}^{-1}(\\alpha));t)},\n$$", "text_format": "latex", "page_idx": 30}, {"type": "text", "text": "where $\\mathbb{P}(\\tilde{Y}=\\cdot\\,;t)$ is the density function for a distribution with quantiles $\\mathbb{F}^{-1}(\\alpha)+t(\\hat{\\mathbb{F}}^{-1}(\\alpha)\\mathrm{~-~}$ $\\mathbb{F}^{-1}(\\alpha)\\rangle$ . Then, the pathwise derivative is ", "page_idx": 30}, {"type": "equation", "text": "$$\n\\frac{\\mathrm{d}}{\\mathrm{d}t}\\left[\\frac{1}{\\mathbb{P}(\\tilde{Y}=\\mathbb{F}^{-1}(\\alpha)+t(\\hat{\\mathbb{F}}^{-1}(\\alpha)-\\mathbb{F}^{-1}(\\alpha));t)}\\right]\\bigg|_{t=0}=\\frac{\\mathrm{d}}{\\mathrm{d}t}\\left[\\frac{\\mathrm{d}}{\\mathrm{d}\\alpha}\\left[\\mathbb{F}^{-1}(\\alpha)\\right]\\right]\\bigg|_{t=0}+\\frac{\\mathrm{d}}{\\mathrm{d}\\alpha}\\left[\\hat{\\mathbb{F}}^{-1}(\\alpha)-\\mathbb{F}^{-1}(\\alpha))\\right].\n$$", "text_format": "latex", "page_idx": 30}, {"type": "text", "text": "Therefore, the cross-derivative is ", "text_level": 1, "page_idx": 30}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\int_{\\mathbb{R}}(\\mu_{t},\\phi_{t})d\\mu^{\\star}}&{=\\phi_{s}^{(\\star)}\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\n$$", "text_format": "latex", "page_idx": 30}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\qquad-\\frac{1}{n}\\biggl[(\\nabla\\cdot\\mathbf{r}^{\\top}(\\hat{\\mathbf{r}}^{n}(\\theta)\\cdot\\mathbf{r})(X)\\cdot\\mathbf{A}\\cdot\\mathbf{a}\\cdot\\mathbf{a})^{\\top}\\left(\\vert\\nabla\\cdot\\mathbf{r}^{\\top}(\\theta)^{n}(\\theta)\\vert^{-1}\\right)-\\kappa^{n}(\\theta)}\\\\ &{\\qquad+\\frac{4}{n}\\biggl[(\\nabla\\cdot\\mathbf{r}^{\\top}(\\theta)\\cdot\\mathbf{r}^{n}(\\theta)\\cdot\\mathbf{r}^{n}(X)\\cdot\\mathbf{r}^{n}(\\theta))\\biggr]\\biggr]\\Biggr|_{2}-\\frac{4}{n}\\biggl[\\kappa^{n}(\\theta)\\cdot\\mathbf{r}^{\\top}(\\theta)}\\\\ &{\\qquad-\\frac{1}{n}-\\frac{4}{n}\\biggl(\\frac{4}{n}\\biggl[\\frac{4}{n}\\biggl[\\nabla\\cdot\\mathbf{r}^{\\top}(\\theta)\\cdot\\mathbf{r}-\\theta)+\\mathbf{r}\\cdot\\mathbf{r}^{n}(\\theta)\\biggr]\\biggr]\\biggr]\\Biggr|_{2}-\\frac{4}{n}\\biggl[(\\nabla\\cdot\\mathbf{r}^{\\top}(\\theta)\\cdot\\mathbf{r}^{n}(\\theta)\\cdot\\mathbf{r}^{n}(\\theta)}\\\\ &{\\qquad\\qquad-(\\theta)\\cdot\\mathbf{r}^{\\top}(\\theta)\\cdot\\mathbf{a}\\cdot\\mathbf{a})^{\\top}\\biggr]}\\\\ &{\\qquad\\qquad+\\frac{4}{n}\\biggl[(\\nabla\\cdot\\mathbf{r}^{\\top}(\\theta)\\cdot\\mathbf{r}^{n}(\\theta)-\\alpha+(\\theta)\\cdot\\mathbf{r}^{n}(\\theta)\\biggr]\\biggr]\\biggr]-\\frac{4}{n}\\biggl[(\\nabla\\cdot\\mathbf{r}^{\\top}(\\theta)\\cdot\\mathbf{r}+\\theta)\\biggr]\\biggr]\\Biggr|_{2}-\\frac{4}{n}\\biggl[\\kappa^{n}(\\theta)\\cdot\\mathbf{r}^{n}(\\theta)}\\\\ &{\\qquad-2\\kappa^{n}\\biggl[\\int_{\\mathbb{R}}\\biggl[\\nabla\\cdot\\mathbf{r}^{\\top}(\\theta)\\cdot\\mathbf{r}^{n}(\\theta)\\cdot\\mathbf{r}^{n}(\\theta)\\cdot\\mathbf{r}^{n}(\\theta)\\biggr]\\biggr]\\biggr]\\biggr|_{2}-\\frac{4}{n}\\biggl[(\\nabla\\cdot\\mathbf{r}^{\\top}(\\theta)\\cdot\\mathbf{r}^{n}(\\theta)\\cdot\\mathbf{r}^{n}(\\theta)\\biggr]\\biggr]\\biggr|_{2}-\\frac{4}{n}\\biggl[\\kappa^{n}(\\theta)\\cdot\\mathbf{r}^{n}(\\theta \n$$", "text_format": "latex", "page_idx": 30}, {"type": "equation", "text": "$$\n\\begin{array}{r l r}{\\lefteqn{\\circ-2\\mathbb{E}_{X}\\left[\\int_{0}^{1}\\bigg[\\hat{\\mathbf{f}}_{1}^{-1}\\big(\\hat{u}^{*}(0)\\mid X\\big)-\\mathbb{F}_{1}^{-1}\\big(\\hat{u}^{*}(0)\\mid X\\big)}\\\\ &{}&{\\qquad+\\,\\gamma\\bigg(\\frac{\\frac{\\mathrm{d}}{\\mathrm{d}t}\\left[\\hat{u}^{*}(t)\\right]\\bigg\\vert_{t=0}-\\mathbb{P}\\left(Y=\\mathbb{F}_{1}^{-1}\\big(\\hat{u}^{*}(0)\\mid X\\big)\\mid X,A=1\\right)\\big(\\hat{\\mathbb{F}}_{1}^{-1}\\big(\\hat{u}^{*}(0)\\mid X\\big)-\\mathbb{F}_{1}^{-1}\\big(\\hat{u}^{*}(0)\\mid X\\big)\\big)\\right)-\\,\\frac{\\mathrm{d}}{\\mathrm{d}t}\\left[\\hat{u}^{*}(Y)\\right]}\\\\ &{}&{\\mathbb{P}\\Big(Y=\\mathbb{F}_{1}^{-1}\\big(\\hat{u}^{*}(0)\\mid X\\big)\\mid X,A=1\\Big)}\\end{array}\n$$", "text_format": "latex", "page_idx": 31}, {"type": "equation", "text": "$$\n\\begin{array}{r l r}&{}&{-\\left.\\frac{\\mathrm{d}}{\\mathrm{d}t}\\left[\\hat{u}^{*}(t)\\right]\\right\\vert_{t=0}-\\left.\\frac{\\mathrm{d}}{\\mathrm{d}t}\\left[\\hat{u}^{*}(t)\\right]\\right\\vert_{t=0}}\\\\ &{}&{-\\left.\\frac{\\mathrm{d}}{\\mathrm{P}\\big(Y=\\mathrm{P}_{0}^{-1}\\big(\\tilde{u}^{*}(0)-\\alpha+0\\mid X\\mid X,A=0\\big)\\big)}\\right]\\left(g^{-1}(\\alpha,X)-g_{*}^{-1}(\\alpha,X)\\right)\\mathrm{d}\\alpha\\right]}\\\\ &{}&{=-\\,2\\mathbb{E}_{X}\\left[\\int_{0}^{1}(1-\\gamma)\\Big(\\hat{\\mathbb{P}}_{1}^{-1}\\big(\\tilde{u}^{*}(0)\\mid X\\big)-\\mathbb{P}_{1}^{-1}\\big(\\tilde{u}^{*}(0)\\mid X\\big)\\Big)\\left(g^{-1}(\\alpha,X)-g_{*}^{-1}(\\alpha,X)\\right)\\mathrm{d}\\alpha\\right]\\underbrace{\\mathrm{d}}_{\\gamma=1}0,\\quad}\\end{array}\n$$", "text_format": "latex", "page_idx": 31}, {"type": "text", "text": "Where $\\tilde{u}^{*}(t)$ is some value from $\\tilde{u}_{[\\alpha,1]}^{*}(\\alpha\\mid X)$ ; and $\\tilde{u}_{[\\alpha,1]}^{*}(\\alpha\\mid X)$ is the argmin set of the convolution $(\\mathbb{F}_{1}^{-1}+t(\\hat{\\mathbb{F}}_{1}^{-1}-\\mathbb{F}_{1}^{-1})\\pm\\mathbb{F}_{0}^{-1})_{[\\alpha,1]}(\\cdot-0\\mid X)$ . The cross-derivatives for the upper bound wrt. $\\mathbb{F}_{1}^{-1}$ and for both upper and lower bounds wrt. $\\mathbb{F}_{0}^{-1}$ follow similarly. ", "page_idx": 31}, {"type": "text", "text": "2. Rate double robustness. The result is a direct application of Theorem 1 in [35]. First, it is easy to see that the Assumptions 1-4 from [35] hold for the population versions of the empirical risks of our $A U$ learner (i.e., CRPS and $W_{2}^{2}$ \u53e3 ", "page_idx": 31}, {"type": "text", "text": "E  Scaling in pseudo-CDFs and pseudo-quantiles ", "text_level": 1, "page_idx": 32}, {"type": "text", "text": "Fig. 9 provides a visual comparison of different pseudo-CDFs for our AU-learner, with and without scaling $\\gamma$ Therein, we see that the scaling hyperparameter helps to enforce the constraints on the pseudo-CDFs (i.e., $[0,1]$ -boundedness and monotonicity). ", "page_idx": 32}, {"type": "image", "img_path": "RDsDvSHGkA/tmp/b337ac0e3c48f1ade3322bd17cd3200017cfb1d3e356f138620ff309fdcc8cc5.jpg", "img_caption": ["Figure 9: Comparison of estimated pseudo-CDFs based on $i=\\{1,\\dotsc,50\\}$ instances of the semisynthetic IHDP100 dataset [46]. Here, we compare CA-learner's pseudo-CDFs (first column) with two variants of $A U$ learner: w/o scaling $\\langle\\gamma=1$ , second column), and w/ scaling $\\langle\\gamma=0.25$ , third column). The scaling hyperparameter $\\gamma\\,=\\,0.25$ facilitates pseudo-CDFs to better comply with $[0,1]$ -boundedness and monotonicity constraints. "], "img_footnote": [], "page_idx": 32}, {"type": "text", "text": "F  Details on AU-CNFs ", "text_level": 1, "page_idx": 33}, {"type": "image", "img_path": "RDsDvSHGkA/tmp/61c50f3f95427da980e34595fe474558030010e535db7c9183ae30cfd48977b3.jpg", "img_caption": ["F.1  Architecture "], "img_footnote": [], "page_idx": 33}, {"type": "text", "text": "Figure 10: Overview of our AU-CNFs. AU-CNFs combine several conditional normalizing flows (CNFs), which we call a nuisance CNF and upper/lower target CNFs. The nuisance CNF is a first stage model and aims at estimating the nuisance functions, i. e., the propensity score, $\\hat{\\pi}_{a}(x)\\,=$ $a\\hat{\\pi}(x)+(1-a)\\hat{\\pi}(x)$ ; and the conditional outcome CDFs, $\\widehat{F}_{a}(y\\mid x)$ . Upper/lower target CNFs are the second stage working models, $\\overline{{\\mathcal G}}$ and $\\mathcal{G}$ , respectively. They aim at minimizing one of the losses of AU-learner, LAU. CRPs/W2\u00b7 ", "page_idx": 33}, {"type": "text", "text": "Our AU-CNFs allow us to implement the Algorithm 1 of our $A U.$ -learner (see Fig. 10) by combining several conditional normalizing flows (CNFs) [105, 121]. It consists of a (i) nuisance CNF and (ii) two target CNFs (upper and lower). (1) The nuisance CNF aims to fit the nuisance functions, $(\\widehat{\\pi},\\widehat{\\mathbb{F}}_{0},\\widehat{\\mathbb{F}}_{1})$ or, equivalently, $(\\hat{\\pi},\\widehat{\\mathbb{F}}_{0}^{-1},\\widehat{\\mathbb{F}}_{1}^{-1})$ . (2) Upper and lower target CNFs constitute the second stage working models, namely, $\\overline{{\\mathcal{G}}}$ and $\\mathcal{G}$ , and minimize the loss of our $A U$ learner. ", "page_idx": 33}, {"type": "text", "text": "(1) Nuisance CNF. The nuisance CNF has three components, similarly to [94]. These are two fully-connected subnetworks $\\mathrm{FC_{1}}$ and $\\mathrm{FC_{2}}$ ) and a CNF, parametrized by $\\theta$ . The two subnetworks $\\mathrm{FC_{1}}$ and $\\mathrm{FC_{2}}$ form a hypernetwork, which outputs the conditional parameters, $\\theta=\\theta(X,A)$ . This allows us to flexibly model the conditional outcome distribution. ", "page_idx": 33}, {"type": "text", "text": "The nuisance CNF has the following joint loss for the nuisance functions: $\\mathcal{L}_{\\mathrm{N}}=\\mathcal{L}_{\\mathrm{NLL}}+\\alpha\\mathcal{L}_{\\pi}$ .Here, $\\mathcal{L}_{\\mathrm{NLL}}$ is a conditional negative log-likelihood loss, ${\\mathcal{L}}_{\\pi}$ is a binary cross-entropy, and $\\alpha\\,>\\,0$ is a hyperparameter. We additionally employed noise regularization to regularize the conditional negative log-likelihood loss [108]. ", "page_idx": 33}, {"type": "text", "text": "(2) Upper and lower target CNFs. The upper and lower target CNFs use the pseudo-CDFs / pseudo-quantiles, generated by the nuisance CNF, and then implement a second stage loss of our $A U.$ -learner. Both target CNFs have the same structure. Specifically, they have a fully-connected subnetwork, $\\overline{{\\mathrm{FC}}}_{3}$ , and a CNF, parametrized by $\\overline{{\\beta}}$ .Analogously, $\\overline{{\\mathrm{FC}}}_{3}$ serves as a hypernetwork so that the parameters can be conditioned on $X{:}\\,{\\overline{{\\beta}}}={\\overline{{\\overline{{\\beta}}}}}(X)$ ", "page_idx": 33}, {"type": "text", "text": "To fit the target CNFs, we use a second stage loss of our $A U.$ learner, namely, Eq. (13) or Eq. (14). For that, we discretize the $\\boldsymbol{\\wp}$ -space or the $[0,1]$ -interval of $u$ into $n_{d}$ values and infer argmin/argmax values based on those grids. Then, to approximate the integrals, we do the same for the $\\varDelta_{\\mathrm{}}$ -space and the $[0,1]$ -interval of $\\alpha$ . The later creates a $\\delta/\\alpha$ -grid with $n_{\\delta}/n_{\\alpha}$ points. Those grids are later used for a rectangle quadrature integration. Furthermore, we also regularize the target CNFs by applying the noise regularization [108]. ", "page_idx": 33}, {"type": "text", "text": "F.2  Implementation ", "text_level": 1, "page_idx": 33}, {"type": "text", "text": "Implementation. We implemented our AU-CNFs using PyTorch and Pyro. For the CNFs of both stages of learning, we used neural spline fows [24] with a standard normal distribution as a base distribution. Neural spline flows build an invertible transformation based on invertible rationalquadratic splines and, thus, allow the direct inference of the (conditional) log-probability, CDF, and quantiles. Neural spline flows are characterized by two main hyperparameters, namely, a number ofknots $n_{\\mathrm{knots}}$ and a span of the transformation interval, $[-B,B]$ .The number of knots, $n_{\\mathrm{knots}}$ controls the expressiveness of the flow. The span $B$ defines the support of the transformation. In our experiments, we tune the number of knots $n_{\\mathrm{knots}}$ and set the span $B$ via a heuristic depending on sample max/min values (as $\\boldsymbol{\\wp}$ is assumed to be compact). ", "page_idx": 33}, {"type": "text", "text": "", "page_idx": 34}, {"type": "text", "text": "Training. To train our AU-CNFs, we make use of Algorithm 1. However, both first and second stage models are fit on the same training data $\\mathcal{D}$ without cross-fitting as (regularized) CNFs as neural networks belong to the Donsker class of estimators [123]. Training of our AU-CNFs proceeds as follows: (1) we fit the nuisance CNF; (2) we freeze the nuisance CNF and generate pseudoCDFs/pseudo-quantiles; and (3) we train the upper and lower target CNFs. The hyperparameters are then as follows: ", "page_idx": 34}, {"type": "text", "text": "1. First stage. We used stochastic gradient descent (SGD) with a minibatch size $b_{\\mathrm{N}}$ \uff0c $n_{e,\\mathrm{N}}=200$ epochs and a learning rate $\\eta_{\\mathrm{N}}$ . Furthermore, we set the loss coefficient to $\\alpha=1$ . Both the number of hidden units of $\\mathrm{FC_{1}/F C_{2}}$ and the size of the output of the $\\mathrm{FC_{1}}$ are set to 10. The nuisance CNF has the number of knots $n_{\\mathrm{knots,\\,N}}$ and the span $B=\\mathrm{max}_{i}(\\tilde{y}_{i})-\\mathrm{min}_{i}(\\tilde{y}_{i})+5$ where $\\tilde{y}_{i}$ are standard normalized outcomes $y_{i}$ : The intensities of the noise regularization for the input and the output are set to $\\sigma_{x}^{2}$ and $\\sigma_{y}^{2}$ , respectively. ", "page_idx": 34}, {"type": "text", "text": "2. Intermediate stage. We set $n_{d}=200$ and $n_{\\delta}=n_{\\alpha}=50$ . Furthermore, we set the scaling hyperparameters $\\gamma=0.25$ for the CRPS loss and $\\gamma=0.01$ for the $W_{2}^{2}$ loss. We clipped too low propensity scores (lower than 0.05). ", "page_idx": 34}, {"type": "text", "text": "3. Second stage. The upper and lower target CNFs are also fit via SGD with the minibatch size $b_{\\mathrm{T}}=64$ $n_{e,\\mathrm{T}}=200$ epochs, and the learning rate $\\eta_{\\mathrm{T}}=0.005$ . The intensities of the noise regularization for the input are the same as for the nuisance CNF, $\\sigma_{x}^{2}$ . The number of hidden units of $\\mathrm{FC_{3}}$ is also set to 10. The target CNFs have the number of knots twice larger than the nuisance flow, $n_{\\mathrm{knots,\\,T}}=2\\,n_{\\mathrm{knots,\\,N}},$ and the span $B=\\mathrm{max}_{i}(a_{i}\\,\\tilde{y}_{i})-\\mathrm{min}_{i}(a_{i}\\,\\tilde{y}_{i})+$ $\\operatorname*{max}_{i}((1-a_{i})\\,\\tilde{y}_{i})-\\operatorname*{min}_{i}(\\left(1-a_{i}\\right)\\tilde{y}_{i})+5$ , where $\\tilde{y}_{i}$ are standard normalized outcomes $y_{i}$ To further stabilize the training of the target CNFs, we employed an exponential moving average (EMA) of the target CNFs parameters [103] with a smoothing hyperparameter $\\lambda=0.995$ ", "page_idx": 34}, {"type": "text", "text": "We demonstrate the detailed training procedure of our AU-CNFs (CRPS) in Algorithm 2 (AU-CNFs $(W_{2}^{2})$ follow analogously). ", "page_idx": 34}, {"type": "text", "text": "Hyperparameter tuning. We performed extensive hyperparameter tuning only for the nuisance CNF. The following hyperparameters are subjects to tuning: the minibatch size $^{n}b{,}^{\\mathrm{N}}$ , the learning rate $\\eta_{\\mathrm{N}}$ the number of knots $n_{\\mathrm{knots,\\,N}}$ , and the intensities of the noise regularization, $\\sigma_{x}^{2}$ and $\\sigma_{y}^{2}$ . Further details of hyperparameter tuning are provided in Appendix G. The hyperparameters of the target CNFs for all the experiments are either kept fixed or are inherited from the nuisance CNF. ", "page_idx": 34}, {"type": "text", "text": "Algorithm 2 Training procedure of our AU-CNFs (CRPS) ", "text_level": 1, "page_idx": 35}, {"type": "text", "text": "1: Input. Training dataset $\\boldsymbol{\\mathcal{D}}=\\left\\{x_{i},a_{i},y_{i}\\right\\}_{i=1}^{n}$ ; scaling $\\gamma\\in\\,(0,1]$ ; hyperparameter $\\alpha$ ; number of epochs   \n$n_{e,\\mathrm{N}},n_{e,\\mathrm{T}}$ minibatch sizes $b_{\\mathrm{N}}$ \uff0c $b_{\\mathrm{T}}$ ; learming rates $\\eta_{\\mathrm{N}},m_{\\l}$ ntensiftslrizat $\\sigma_{x}^{2},\\sigma_{y}^{2}$ EMA   \nsmoothing >; 8-grid {; E }1; -grid {y E }1   \n2: Init Paramtersof t uisa NF $\\mathrm{FC_{1}^{(0)}}$ and $\\mathrm{FC_{2}^{(0)}}$ First stage   \n3: for $i=0$ to $\\lceil n_{e,\\mathrm{N}}\\cdot n/b_{\\mathrm{N}}\\rceil$ do   \n4: Draw a minibatch $\\boldsymbol{B}=\\{X,A,Y\\}$ of size $b_{\\mathrm{N}}$ from $\\mathcal{D}$   \n5: $\\big(R,\\hat{\\pi}_{a}(X)\\big)\\gets\\mathrm{FC}_{1}^{(i)}(X)$   \n6: Noise regularization: $\\dot{\\xi}_{x}\\sim N(0,\\sigma_{x}^{2}),\\xi_{y}\\sim N(0,\\sigma_{y}^{2}),~~~(\\tilde{R},\\tilde{Y})\\gets\\big(R+\\xi_{x},Y+\\xi_{y}\\big)$   \n7: $\\theta(X,A)\\leftarrow\\mathrm{FC}_{2}^{(i)}(A,\\tilde{R})$   \n8: ${\\hat{\\mathbb{P}}}(Y\\mid X,A)\\gets$ density of a CNF with parameters $\\theta(X,A)$   \n9: $\\hat{\\mathcal{L}}_{\\mathrm{N}}(\\hat{\\mathbb{P}},\\hat{\\pi})\\leftarrow\\mathbb{P}_{b_{\\mathrm{N}}}\\big\\{-\\log\\hat{\\mathbb{P}}(Y=\\tilde{Y}\\mid X,A)+\\alpha\\,\\mathrm{BCE}(\\hat{\\pi}_{A}(X),A)\\big\\}$   \n10: $\\left(\\mathrm{\\mathrm{~FC}}_{1}^{(i+1)},\\mathrm{\\mathrm{FC}}_{2}^{(i+1)}\\right)\\leftarrow$ optmizaton stp rt $\\hat{\\mathcal{L}}_{\\mathrm{N}}(\\hat{\\mathbb{P}},\\hat{\\pi})$ with the learming rate $\\eta_{\\mathrm{N}}$ ", "page_idx": 35}, {"type": "text", "text": "11: end for ", "text_level": 1, "page_idx": 35}, {"type": "text", "text": "12: Output. Estimator of the nuisance functions $\\widehat{\\eta}=(\\widehat{\\pi},\\widehat{\\mathbb{F}}_{0},\\widehat{\\mathbb{F}}_{1})$ ", "page_idx": 35}, {"type": "text", "text": "13: for $i=0$ to $_n$ do >Intermediate stage   \n14: Iferarmaafl $\\boldsymbol{\\wp}$ grid: $\\{\\hat{y}_{\\overline{{\\mathcal{V}}}-\\mathrm{grid}}^{\\overline{{*}}}(\\delta_{j}\\mid x_{i})\\}_{j=1}^{n_{\\delta}}$ ", "page_idx": 35}, {"type": "text", "text": "15: Clip propensity scores for bias-correction terms $\\{\\underline{{\\overline{{C}}}}(\\delta_{j},z_{i};\\hat{\\eta})\\}_{j=1}^{n_{\\delta}}$ (Eq. (11) ", "page_idx": 35}, {"type": "text", "text": "16: Use $\\hat{\\eta}$ to infer the pseudo-CDF for the $\\delta$ -grid: $\\{\\overline{{\\underline{{\\mathbf{F}}}}}_{\\mathrm{DR}}(\\delta_{j},z_{i};\\hat{\\eta})\\}_{j=1}^{n_{\\delta}}$ (Eq (13)) ", "page_idx": 35}, {"type": "text", "text": "17: end for ", "page_idx": 35}, {"type": "text", "text": "18: Initetersftplwe are: $\\overline{{\\mathrm{FC}}}_{3}^{(0)}$ and $\\underline{{\\mathrm{F}}}\\mathbf{C}_{3}^{(0)}$ Second stage   \n19: for $i=0$ to $\\lceil n_{e,\\mathrm{T}}\\cdot n/b_{\\mathrm{T}}\\rceil$ do   \n20: Draw a minibatch $\\mathcal{B}=\\{X,A,Y\\}$ of size $b_{\\mathrm{T}}$ from $\\mathcal{D}$   \n21: Noise regularization: $\\xi_{x}\\sim N(0,\\sigma_{x}^{2}),\\quad\\tilde{X}\\leftarrow X+\\xi_{x}$   \n22: $\\overline{{\\beta(X)}}\\leftarrow\\overline{{\\sf F C}}_{3}^{(i)}(\\tilde{X})$ $\\underline{{\\beta(X)}}\\leftarrow\\underline{{\\mathrm{F}}}\\underline{{\\boldsymbol{C}}}_{3}^{(i)}(\\tilde{X})$   \n23: $\\widehat{\\overline{{g}}}(\\cdot,X)\\gets\\mathrm{CDF}$ of a CNF with parameters $\\overline{{\\beta(X)}},\\quad\\widehat{\\underline{{g}}}(\\cdot,X)\\gets\\mathrm{CDF}$ of a CNF with parameters $\\beta(X)$   \n24: $\\begin{array}{r l}&{\\widehat{\\mathcal{L}}_{\\mathrm{AU,\\,CRPS}}(\\widehat{\\overline{{g}}},\\widehat{\\eta})=\\mathbb{P}_{b_{\\Gamma}}\\Big\\{\\frac{1}{n_{\\delta}}\\sum_{j=1}^{n_{\\delta}}\\big(\\overline{{\\mathbf{F}}}_{\\mathrm{DR}}(\\delta_{j},Z;\\widehat{\\eta})-\\widehat{\\overline{{g}}}(\\delta_{j},X)\\big)^{2}\\Big\\}}\\\\ &{\\widehat{\\mathcal{L}}_{\\mathrm{AU,\\,CRPS}}(\\widehat{\\underline{{g}}},\\widehat{\\eta})=\\mathbb{P}_{b_{\\Gamma}}\\Big\\{\\frac{1}{n_{\\delta}}\\sum_{j=1}^{n_{\\delta}}\\big(\\underline{{\\mathbf{F}}}_{\\mathrm{DR}}(\\delta_{j},Z;\\widehat{\\eta})-\\widehat{\\underline{{g}}}(\\delta_{j},X)\\big)^{2}\\Big\\}}\\end{array}$   \n25:   \n26: $\\overline{{\\mathrm{FC}}}_{3}^{(i+1)}\\leftarrow$ optimizatio step wt. $\\widehat{\\overline{{\\mathcal{L}}}}_{\\mathrm{AU,\\,CRPS}}(\\widehat{\\overline{{g}}},\\widehat{\\eta})$ with the carning rate $\\eta_{\\mathrm{T}}$   \n27: $\\underline{{\\mathrm{F}}}\\mathbf{C}_{3}^{(i+1)}\\leftarrow$ optimization step wrt. $\\underline{{\\widehat{\\mathcal{L}}}}_{\\mathrm{AU,\\,CRPS}}(\\underline{{\\widehat{g}}},\\widehat{\\eta})$ with the leaming rate $\\eta_{\\mathrm{T}}$   \n28: EMA update for $\\overline{{\\mathrm{FC}}}_{3}^{(i+1)}$ and C(i+1) with smoothing \u5165   \n29: end for ", "page_idx": 35}, {"type": "text", "text": "30: Output. Estimator of Makarov bounds with CNFs: EMA smoothed $\\widehat{\\overline{{g}}}$ and $\\widehat{\\underline{{g}}}$ ", "page_idx": 35}, {"type": "text", "text": "G Hyperparameter tuning ", "text_level": 1, "page_idx": 36}, {"type": "text", "text": "We performed hyperparameters tuning of the nuisance function estimators for all the baselines based on five-fold cross-validation using the training dataset. For each baseline, we did a grid search wrt. different tuning criteria (see the details in Table 3). The optimal hyperparameters can be found as YAML files in our GitHub. ", "page_idx": 36}, {"type": "table", "img_path": "RDsDvSHGkA/tmp/ffe4a993c2c1c33fd72b66aef4289672db92d9be7ceeaefcc8479e6ad737c519.jpg", "table_caption": ["Table 3: Hyperparameter tuning for baselines. "], "table_footnote": [], "page_idx": 36}, {"type": "text", "text": "H Dataset details ", "text_level": 1, "page_idx": 37}, {"type": "text", "text": "H.1 Synthetic data ", "text_level": 1, "page_idx": 37}, {"type": "text", "text": "Our synthetic data generator is adapted from [61, 93]. Although the original synthetic benchmark contains hidden confounding, we include the confounder as the second observed covariate. We created three settings with different conditional outcome distributions: (1) normal, (2) multi-modal and (3) exponential. Specifically, synthetic covariates, $X_{1},X_{2}$ ,a treatment, $A$ , and an outcome, $Y$ are sampled from the following data generating mechanisms: ", "page_idx": 37}, {"type": "equation", "text": "$$\n\\left\\{\\begin{array}{l l}{X_{1}\\sim\\mathrm{Unif}(-2,2),}\\\\ {X_{2}\\sim N(0,1),}\\\\ {A\\sim\\mathrm{Bern}\\left(\\frac{1}{1+\\exp(-(0.75\\,X_{1}-X_{2}+0.5))}\\right),}\\\\ {\\mu_{A}(X):=(2\\,A-1)\\,X_{1}+A-2\\,\\sin(2\\,X_{1}+X_{2})-2\\,X_{2}\\,(1+0.5\\,X_{1}),}\\\\ {Y\\sim\\mathbb{P}_{j}(Y\\mid\\mu_{A}(X),A),}\\end{array}\\right.\n$$", "text_format": "latex", "page_idx": 37}, {"type": "text", "text": "where $X_{1},X_{2}$ are mutually independent and $\\mathbb{P}_{j}(Y\\mid\\mu_{A}(X),A)$ are defined by three settings $j\\in\\{1,2,3\\}$ ", "page_idx": 37}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathfrak{z}_{1}(Y\\mid\\mu_{A}(X),A)=N(\\mu_{A}(X),1),}\\\\ &{\\mathfrak{z}_{2}(Y\\mid\\mu_{A}(X),A)=\\left\\{\\begin{array}{l l}{\\mathrm{Mixture}\\left\\{0.7\\,N(\\mu_{0}(X)-0.5,1.5^{2})+0.3\\,N(\\mu_{0}(X)+1.5,0.5^{2})\\right\\},}&{\\mathrm{~(117)~}}\\\\ {\\mathrm{Mixture}\\left\\{0.3\\,N(\\mu_{0}(X)-2.5,0.35^{2})+0.4\\,N(\\mu_{0}(X)+0.5,0.75^{2})+0.3\\,N(\\mu_{0}(X)+2,0.5^{2})\\right\\},}&{\\mathrm{~(107)~}}\\end{array}\\right.}\\end{array}\n$$", "text_format": "latex", "page_idx": 37}, {"type": "equation", "text": "$$\n\\mathbb{P}_{2}(Y\\mid\\mu_{A}(X),A)=\\operatorname{Exp}(1/\\left|\\mu_{A}(X)\\right|),\n$$", "text_format": "latex", "page_idx": 37}, {"type": "text", "text": "where $N(\\mu,\\sigma^{2})$ is the normal distribution and where $\\mathrm{Exp}(\\lambda)$ is the exponential distribution. ", "page_idx": 37}, {"type": "text", "text": "The synthetic benchmark allows us to infer or approximate the ground-truth Makarov bounds. For the (1) normal distribution, they are given by the analytical solution [26], namely, the CDFs of halfnormal distributions. However, in the settings (2) and (3), they need to be approximated numerically. Thus, for the (2) multi-modal distribution, we only infer the Makarov bounds on the CDF, as the quantiles are not directly available for the mixture distribution. For the (3) exponential distribution, however, we can infer both the Makarov bounds on the CDF and the quantiles. ", "page_idx": 37}, {"type": "text", "text": "H.2 HC-MNIST dataset ", "text_level": 1, "page_idx": 37}, {"type": "text", "text": "HC-MNIST dataset was introduced as a high-dimensional, semi-synthetic dataset [52] based on the MNIST image dataset [75]. The HC-MNIST dataset builds on $n_{\\mathrm{train}}~=~60,000$ train and $n_{\\mathrm{test}}=10$ , 000 test images. HC-MNIST takes original high-dimensional images and maps them onto a one-dimensional manifold, where potential outcomes depend in a complex way on the average intensity of light and the label of an image. The treatment also uses this one-dimensional summary, $\\phi$ together with an additional (hidden) synthetic confounder, $U$ (we consider this hidden confounder as another observed covariate). HC-MNIST is then defined by the following data-generating mechanism: ", "page_idx": 37}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\left\\vert\\ X\\sim\\mathrm{MNIST-image(cdot)}\\right.,}\\\\ &{\\phi:=\\left(\\mathrm{clip}\\left(\\frac{\\mu_{N_{x}}-\\mu_{c}}{\\sigma_{c}};-1.4,1.4\\right)-\\mathrm{Min}_{c}\\right)\\frac{\\mathrm{Max}_{c}-\\mathrm{Min}_{c}}{1.4-(-1.4)},}\\\\ &{\\left\\{\\alpha(\\phi;\\Gamma^{*}):=\\frac{1}{\\Gamma^{*}\\mathrm{sigmoid}(0.75\\phi+0.5)}+1-\\frac{1}{\\Gamma^{*}},\\right.}\\\\ &{\\left.\\beta(\\phi;\\Gamma^{*}):=\\frac{\\Gamma^{*}}{\\mathrm{sigmoid}(0.75\\phi+0.5)}+1-\\Gamma^{*},\\right.}\\\\ &{A\\sim\\mathrm{Bern}\\left(\\frac{u}{\\alpha(\\phi;\\Gamma^{*})}+\\frac{1-u}{\\beta(\\phi;\\Gamma^{*})}\\right),}\\\\ &{Y\\sim N\\big((2A-1)\\phi+(2A-1)-2\\sin(2(2A-1)\\phi)-2(2U-1)(1+0.5\\phi),1\\big),}\\end{array}\n$$", "text_format": "latex", "page_idx": 37}, {"type": "text", "text": "where $c$ is a label of the digit from the sampled image $X;\\mu_{N_{x}}$ is the average intensity of the sampled image; $\\mu_{c}$ and $\\sigma_{c}$ are the mean and standard deviation of the average intensities of the images with the label $c$ and $\\begin{array}{r}{\\mathrm{Min}_{c}\\,=\\,-2+\\frac{4}{10}c,\\mathrm{Max}_{c}\\,=\\,-2+\\frac{4}{10}(c+\\underline{{1}})}\\end{array}$ Theparameter $\\Gamma^{*}$ defines what factor influences the treatment assignment to a larger extent, i.e., the additional confounder or the one-dimensional summary. We set $\\Gamma^{*}=\\exp(1)$ . For further details, we refer to [52]. ", "page_idx": 37}, {"type": "text", "text": "Similarly to the synthetic data with the normal distribution, the ground-truth Makarov bounds for the HC-MNIST dataset are given by the analytical solution, namely, the CDFs of half-normal distributions [26]. ", "page_idx": 37}, {"type": "text", "text": "H.3 IHDP100 dataset ", "text_level": 1, "page_idx": 38}, {"type": "text", "text": "The Infant Health and Development Program (IHDP100) [46, 114] is a standard semi-synthetic benchmark for treatment effect estimation. It contains 100 train/test splits with $n_{\\mathrm{train}}=672$ $n_{\\mathrm{test}}=$ 75, and $d_{x}=25$ . Yet, this dataset contains severe overlap violations, which makes the methods using propensity re-weighting unstable [20, 21]. ", "page_idx": 38}, {"type": "text", "text": "The IHDP100 dataset samples synthetic outcomes from the conditional normal distribution, $N(\\mu_{i},1)$ where $\\mu_{i}$ are CAPOs provided in the dataset. Therefore, the ground-truth Makarov bounds are given by the half-normal distributions [26]. ", "page_idx": 38}, {"type": "text", "text": "I Additional results ", "text_level": 1, "page_idx": 39}, {"type": "text", "text": "In the following, we provide additional results for our experiments with synthetic data, the results of the semi-synthetic IHDPioo benchmark, and the runtime information for all the baselines. ", "page_idx": 39}, {"type": "text", "text": "1.1  Synthetic data ", "text_level": 1, "page_idx": 39}, {"type": "text", "text": "We provide additional results of our synthetic benchmark in Fig. 11. Therein, the out-of-sample performance is reported wrt. $W_{2}$ evaluation score for two settings, i.e., normal and exponential setting.10 Our AU-CNFs achieve superior performance in the normal setting and perform well in the exponential setting. Notably, the IPTW-CNF also perform well in the exponential setting, mainly due to the orthogonality wrt. potential outcome distributions. ", "page_idx": 39}, {"type": "image", "img_path": "RDsDvSHGkA/tmp/83e349197bb6b1b1d2ef5ca26df00ee985229574ad625099fbd6094dcbcb662d.jpg", "img_caption": ["Figure 11: Results for synthetic experiments with varying size of training data, $n_{\\mathrm{train}}$ , in the settings: normal and exponential setting. Reported: mean out-sample $W_{2}$ over 20 runs. The results for Plug-in DKME are omitted for the $W_{2}$ evaluation score, as Plug-in DKME does not provide direct quantiles inference. "], "img_footnote": [], "page_idx": 39}, {"type": "text", "text": "1.2 IHDP100 dataset ", "text_level": 1, "page_idx": 39}, {"type": "text", "text": "We report the in- and out-sample results for the IHDP100 dataset in Table 4. As expected, our CA-CNFs achieve the best performance. This happens due to the severe overlap violations in the IHDP100 dataset [20, 21], and learners with propensity-score re-weighting are theoretically expected to perform worse. ", "page_idx": 39}, {"type": "text", "text": "1.3  Runtime comparison ", "text_level": 1, "page_idx": 39}, {"type": "text", "text": "Table 5 provides the runtime comparison of different methods used to estimate Makarov bounds.   \nTherein, our AU-CNFs are well scalable. ", "page_idx": 39}, {"type": "table", "img_path": "RDsDvSHGkA/tmp/b4a344b939a3fce1183044ca94767cfcd4de3114b9b0ed41ace72d7335c79e83.jpg", "table_caption": ["Table 4: Results for IHDP100 dataset. Reported: median in-sample and out-sample $\\mathbf{rCRPS}\\pm\\mathbf{\\varsigma}$ sd / $W_{2}\\pm\\mathrm{sd}$ over 100 train/test splits. The results for Plug-in DKME are omitted for the $W_{2}$ evaluation score, as Plug-in DKME does not provide direct quantiles inference. "], "table_footnote": ["Lower $=$ better (best in bold, second best underlined) "], "page_idx": 40}, {"type": "table", "img_path": "RDsDvSHGkA/tmp/e19543eecdf4ccb69cadc81423139eddf83e98356f2bb27db60ffba167ec7b5f.jpg", "table_caption": [], "table_footnote": [], "page_idx": 40}, {"type": "text", "text": "Table 5: Total runtime (in seconds) for different methods to estimate Makarov bounds. Reported: average runtime duration (lower is better). Experiments were carried out on 2 GPUs (NVIDIA A100-PCIE-40GB) with IntelXeon Silver 4316 CPUs $\\textcircled{a}\\ 2.30\\mathrm{GHz}$ ", "page_idx": 40}, {"type": "text", "text": "JCase study: Lockdown effectiveness ", "text_level": 1, "page_idx": 41}, {"type": "text", "text": "In the following, we provide a case study, where we apply our AU-learner to a real-world problem. Here, we want to study the effectiveness of lockdowns during the COVID-19 pandemic by using the observational data collected in the first half-year of 2020 [7]. Specifically, we aim to estimate the probability that the incidence falls after the implementation of the strict lockdown, i. e., a probability of individual benefit from treatment (intervention) (PITB). ", "page_idx": 41}, {"type": "text", "text": "J.1Dataset ", "text_level": 1, "page_idx": 41}, {"type": "text", "text": "We used multi-county data provided by [7].11 The outcome $Y\\in[-7,0]$ is defined as the relative case growth per week (in log), namely, the number of new cases divided by the number of cumulative cases. Then, the treatment ${\\bar{A}}\\in\\{0,1\\}$ is taken as an implementation of the strict lockdown one week before. We also choose three ( $[d_{x}=3]$ pre-treatment covariates $X$ : the relative case growths from the previous week, the relative case growth from two weeks ago, and the implementation of the strict lockdown from two weeks ago. We assume that the data is i.i.d. and that the causal assumptions (1)-(3) are satisfied. We filtered out observations where the number of cumulative cases is fewer than 20. As a result, we ended up with $n=n_{0}+n_{1}=152+112$ treated and untreated observations, respectively. ", "page_idx": 41}, {"type": "text", "text": "J.2 Results ", "text_level": 1, "page_idx": 41}, {"type": "text", "text": "We present the results for our case study in Fig. 12. Therein, we report two quantities: the estimated bounds on the probability of the individual treatment benefit (PITB), $\\mathbb{P}(Y[1]\\stackrel{-}{-}Y[0]\\leq0\\mid x)$ ,for 20 countries during week 15 of 2020. Additionally, we show bounds on a population analogue of PITB, namely, a probability of the population treatment benefit, $\\mathbb{P}(Y[1]-\\bar{Y}[\\bar{0}]\\leq0)$ . We estimated the bounds on the PITB with both AU-CNFs (CRPS) and AU-CNFs $\\dot{(W_{2}^{2})}$ , and both methods produced very similar results (which implies a robustness of our $A U$ -learner). For the population analogue of the PITB, we first efficiently estimated the distributions of the potential outcomes with interventional normalizing flows (INFs) [94] and then used them to infer the Makarov bounds at the population level. ", "page_idx": 41}, {"type": "image", "img_path": "RDsDvSHGkA/tmp/afd9d45bf3c5c24f38f4078ab5d1c50d12ecaa5aad81259db216919d95339753.jpg", "img_caption": ["Figure 12: Results for the real-world case study analyzing the effectiveness of lockdowns during the COVID-19 pandemic. Reported: in-sample estimated bounds on the probability of the individual treatment benefit (PITB), $\\bar{\\mathbb{P}}(Y[1]-Y[0]\\stackrel{\\cdot}{\\leq}0\\mid x)$ , 0ver 20 runs for 20 countries during week 15 of 2020. Also, we show bounds on a probability of the population treatment benefit, i.e., $\\mathbb{P}(\\bar{Y}[1]\\!-\\!Y[0]\\leq$ 0). These are displayed in the small figure on the left. Each estimated bound is shown as two boxplots; hence, we also display the epistemic uncertainty. "], "img_footnote": [], "page_idx": 41}, {"type": "text", "text": "There are two important takeaways: (1) The bounds on the PITB are more shifted towards 1, suggesting the drop in the incidence is highly probable after the implementation of the strict lockdown in all the studied countries. (2) The bounds on PITB are much tighter than their population analogue (e. g., average upper-lower bound width is 0.66 for AU-CNFs (CRPS) and 0.88 for INFs). The latter implies that individualization enhances decision-making and makes the Makarov bounds on the aleatoric uncertainty tighter and, thus, more informative. ", "page_idx": 41}, {"type": "text", "text": "NeurIPS Paper Checklist ", "text_level": 1, "page_idx": 42}, {"type": "text", "text": "1. Claims ", "text_level": 1, "page_idx": 42}, {"type": "text", "text": "Question: Do the main claims made in the abstract and introduction accurately refect the paper's contributions and scope? ", "page_idx": 42}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 42}, {"type": "text", "text": "Justification: [NA] ", "page_idx": 42}, {"type": "text", "text": "Guidelines: ", "page_idx": 42}, {"type": "text", "text": "\u00b7 The answer NA means that the abstract and introduction do not include the claims made in the paper.   \n\u00b7 The abstract and/or introduction should clearly state the claims made, including the contributions made in the paper and important assumptions and limitations. A No or NA answer to this question will not be perceived well by the reviewers.   \n\u00b7 The claims made should match theoretical and experimental results, and reflect how much the results can be expected to generalize to other settings.   \n\u00b7 It is fine to include aspirational goals as motivation as long as it is clear that these goals are not attained by the paper. ", "page_idx": 42}, {"type": "text", "text": "2. Limitations ", "text_level": 1, "page_idx": 42}, {"type": "text", "text": "Question: Does the paper discuss the limitations of the work performed by the authors? ", "page_idx": 42}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 42}, {"type": "text", "text": "Justification: We include a paragraph discussing the limitations of our method in Sec. 7. ", "page_idx": 42}, {"type": "text", "text": "Guidelines: ", "text_level": 1, "page_idx": 42}, {"type": "text", "text": "\u00b7 The answer NA means that the paper has no limitation while the answer No means that the paper has limitations, but those are not discussed in the paper.   \n\u00b7 The authors are encouraged to create a separate \"Limitations\" section in their paper.   \n\u00b7 The paper should point out any strong assumptions and how robust the results are to violations of these assumptions (e.g., independence assumptions, noiseless settings, model well-specification, asymptotic approximations only holding locally). The authors should reflect on how these assumptions might be violated in practice and what the implications would be.   \n\u00b7 The authors should reflect on the scope of the claims made, e.g., if the approach was only tested on a few datasets or with a few runs. In general, empirical results often depend on implicit assumptions, which should be articulated.   \n\u00b7 The authors should reflect on the factors that influence the performance of the approach. For example, a facial recognition algorithm may perform poorly when image resolution is low or images are taken in low lighting. Or a speech-to-text system might not be used reliably to provide closed captions for online lectures because it fails to handle technical jargon.   \n\u00b7 The authors should discuss the computational efficiency of the proposed algorithms and how they scale with dataset size.   \n\u00b7 If applicable, the authors should discuss possible limitations of their approach to address problems of privacy and fairness.   \n\u00b7 While the authors might fear that complete honesty about limitations might be used by reviewers as grounds for rejection, a worse outcome might be that reviewers discover limitations that aren't acknowledged in the paper. The authors should use their best judgment and recognize that individual actions in favor of transparency play an important role in developing norms that preserve the integrity of the community. Reviewers will be specifically instructed to not penalize honesty concerning limitations. ", "page_idx": 42}, {"type": "text", "text": "3. Theory Assumptions and Proofs ", "text_level": 1, "page_idx": 42}, {"type": "text", "text": "Question: For each theoretical result, does the paper provide the full set of assumptions and a complete (and correct) proof? ", "page_idx": 42}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 42}, {"type": "text", "text": "Justification: We provide the full set of Assumptions in Sec. 3 and 4, and Appendix D. The proofs for the theoretic results are provided in Appendix D. ", "page_idx": 43}, {"type": "text", "text": "Guidelines: ", "page_idx": 43}, {"type": "text", "text": "\u00b7 The answer NA means that the paper does not include theoretical results.   \n\u00b7 All the theorems, formulas, and proofs in the paper should be numbered and crossreferenced.   \n\u00b7 All assumptions should be clearly stated or referenced in the statement of any theorems.   \n\u00b7 The proofs can either appear in the main paper or the supplemental material, but if they appear in the supplemental material, the authors are encouraged to provide a short proof sketch to provide intuition.   \n\u00b7 Inversely, any informal proof provided in the core of the paper should be complemented by formal proofs provided in appendix or supplemental material.   \n\u00b7 Theorems and Lemmas that the proof relies upon should be properly referenced. ", "page_idx": 43}, {"type": "text", "text": "4. Experimental Result Reproducibility ", "text_level": 1, "page_idx": 43}, {"type": "text", "text": "Question: Does the paper fully disclose all the information needed to reproduce the main experimental results of the paper to the extent that it affects the main claims and/or conclusions of the paper (regardless of whether the code and data are provided or not)? ", "page_idx": 43}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 43}, {"type": "text", "text": "Justification: We provide all the details needed to reproduce the experiments in Appendices F, G and H. ", "page_idx": 43}, {"type": "text", "text": "Guidelines: ", "page_idx": 43}, {"type": "text", "text": "\u00b7 The answer NA means that the paper does not include experiments.   \n\u00b7 If the paper includes experiments, a No answer to this question will not be perceived well by the reviewers: Making the paper reproducible is important, regardless of whether the code and data are provided or not.   \n\u00b7 If the contribution is a dataset and/or model, the authors should describe the steps taken to make their results reproducible or verifiable.   \n\u00b7 Depending on the contribution, reproducibility can be accomplished in various ways. For example, if the contribution is a novel architecture, describing the architecture fully might suffice, or if the contribution is a specific model and empirical evaluation, it may be necessary to either make it possible for others to replicate the model with the same dataset, or provide access to the model. In general. releasing code and data is often one good way to accomplish this, but reproducibility can also be provided via detailed instructions for how to replicate the results, access to a hosted model (e.g., in the case of a large language model), releasing of a model checkpoint, or other means that are appropriate to the research performed.   \n\u00b7 While NeurIPS does not require releasing code, the conference does require all submissions to provide some reasonable avenue for reproducibility, which may depend on the nature of the contribution. For example (a) If the contribution is primarily a new algorithm, the paper should make it clear how to reproduce that algorithm. (b) If the contribution is primarily a new model architecture, the paper should describe the architecture clearly and fully. () If the contribution is a new model (e.g., a large language model), then there should either be a way to access this model for reproducing the results or a way to reproduce the model (e.g., with an open-source dataset or instructions for how to construct the dataset). (d) We recognize that reproducibility may be tricky in some cases, in which case authors are welcome to describe the particular way they provide for reproducibility. In the case of closed-source models, it may be that access to the model is limited in some way (e.g., to registered users), but it should be possible for other researchers to have some path to reproducing or verifying the results. ", "page_idx": 43}, {"type": "text", "text": "5. Open access to data and code ", "page_idx": 43}, {"type": "text", "text": "Question: Does the paper provide open access to the data and code, with sufficient instructions to faithfully reproduce the main experimental results, as described in supplemental material? ", "page_idx": 44}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 44}, {"type": "text", "text": "Justification: We used openly available (semi-)synthetic datasets in our experiments. Also, we provide a link to our code: https: //github. com/Valentyn1997/AU-CNFs. ", "page_idx": 44}, {"type": "text", "text": "Guidelines: ", "page_idx": 44}, {"type": "text", "text": "\u00b7 The answer NA means that paper does not include experiments requiring code.   \n\u00b7 Please see the NeurIPS code and data submission guidelines (https://nips.cc/ public/guides/CodeSubmissionPolicy) for more details.   \n\u00b7 While we encourage the release of code and data, we understand that this might not be possible, so \u201cNo\" is an acceptable answer. Papers cannot be rejected simply for not including code, unless this is central to the contribution (e.g., for a new open-source benchmark).   \n\u00b7 The instructions should contain the exact command and environment needed to run to reproduce the results. See the NeurIPS code and data submission guidelines (https : //nips.cc/public/guides/CodeSubmissionPolicy) for more details.   \n\u00b7 The authors should provide instructions on data access and preparation, including how to access the raw data, preprocessed data, intermediate data, and generated data, etc.   \n\u00b7 The authors should provide scripts to reproduce all experimental results for the new proposed method and baselines. If only a subset of experiments are reproducible, they should state which ones are omitted from the script and why.   \n\u00b7 At submission time, to preserve anonymity, the authors should release anonymized versions (if applicable).   \n\u00b7 Providing as much information as possible in supplemental material (appended to the paper) is recommended, but including URLs to data and code is permitted. ", "page_idx": 44}, {"type": "text", "text": "6. Experimental Setting/Details ", "text_level": 1, "page_idx": 44}, {"type": "text", "text": "Question: Does the paper specify all the training and test details (e.g., data splits, hyperparameters, how they were chosen, type of optimizer, etc.) necessary to understand the results? ", "page_idx": 44}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 44}, {"type": "text", "text": "Justification: We provide all the details needed to reproduce the experiments in Appendices G and H. ", "page_idx": 44}, {"type": "text", "text": "Guidelines: ", "page_idx": 44}, {"type": "text", "text": "\u00b7 The answer NA means that the paper does not include experiments. \u00b7 The experimental setting should be presented in the core of the paper to a level of detail that is necessary to appreciate the results and make sense of them. \u00b7 The full details can be provided either with the code, in appendix, or as supplemental material. ", "page_idx": 44}, {"type": "text", "text": "7. Experiment Statistical Significance ", "text_level": 1, "page_idx": 44}, {"type": "text", "text": "Question: Does the paper report error bars suitably and correctly defined or other appropriate information about the statistical significance of the experiments? ", "page_idx": 44}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 44}, {"type": "text", "text": "Justification: Yes, we report standard deviation in all of the results. ", "page_idx": 44}, {"type": "text", "text": "Guidelines: ", "page_idx": 44}, {"type": "text", "text": "\u00b7 The answer NA means that the paper does not include experiments.   \n\u00b7 The authors should answer \"Yes\" if the results are accompanied by error bars, confidence intervals, or statistical significance tests, at least for the experiments that support the main claims of the paper.   \n\u00b7 The factors of variability that the error bars are capturing should be clearly stated (for example, train/test split, initialization, random drawing of some parameter, or overall run with given experimental conditions).   \n\u00b7 The method for calculating the error bars should be explained (closed form formula, call to a library function, bootstrap, etc.)   \n\u00b7 The assumptions made should be given (e.g., Normally distributed errors).   \n\u00b7 It should be clear whether the error bar is the standard deviation or the standard error of the mean.   \n\u00b7 It is OK to report 1-sigma error bars, but one should state it. The authors should preferably report a 2-sigma error bar than state that they have a $96\\%$ CI, if the hypothesis of Normality of errors is not verified.   \n\u00b7 For asymmetric distributions, the authors should be careful not to show in tables or figures symmetric error bars that would yield results that are out of range (e.g. negative error rates).   \n\u00b7 If error bars are reported in tables or plots, The authors should explain in the text how they were calculated and reference the corresponding figures or tables in the text. ", "page_idx": 44}, {"type": "text", "text": "", "page_idx": 45}, {"type": "text", "text": "8. Experiments Compute Resources ", "text_level": 1, "page_idx": 45}, {"type": "text", "text": "Question: For each experiment, does the paper provide sufficient information on the computer resources (type of compute workers, memory, time of execution) needed to reproduce the experiments? ", "page_idx": 45}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 45}, {"type": "text", "text": "Justification: We provide the details on the used resources and runtimes in the Appendix I. Guidelines: ", "page_idx": 45}, {"type": "text", "text": "\u00b7 The answer NA means that the paper does not include experiments.   \n\u00b7 The paper should indicate the type of compute workers CPU or GPU, internal cluster, or cloud provider, including relevant memory and storage.   \n\u00b7 The paper should provide the amount of compute required for each of the individual experimental runs as well as estimate the total compute.   \n\u00b7 The paper should disclose whether the full research project required more compute than the experiments reported in the paper (e.g., preliminary or failed experiments that didn't make it into the paper). ", "page_idx": 45}, {"type": "text", "text": "9. Code Of Ethics ", "text_level": 1, "page_idx": 45}, {"type": "text", "text": "Question: Does the research conducted in the paper conform, in every respect, with the NeurIPS Code of Ethics https: //neurips.cc/public/EthicsGuidelines? ", "page_idx": 45}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 45}, {"type": "text", "text": "Justification: [NA] Guidelines: ", "page_idx": 45}, {"type": "text", "text": "\u00b7 The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics.   \n\u00b7 If the authors answer No, they should explain the special circumstances that require a deviation from the Code of Ethics.   \n\u00b7 The authors should make sure to preserve anonymity (e.g., if there is a special consideration due to laws or regulations in their jurisdiction). ", "page_idx": 45}, {"type": "text", "text": "10. Broader Impacts ", "text_level": 1, "page_idx": 45}, {"type": "text", "text": "Question: Does the paper discuss both potential positive societal impacts and negative societal impacts of the work performed? ", "page_idx": 45}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 45}, {"type": "text", "text": "Justification: We include a paragraph discussing the broader impacts of our method in Sec. 7. Guidelines: ", "page_idx": 45}, {"type": "text", "text": "\u00b7 The answer NA means that there is no societal impact of the work performed.   \n\u00b7 If the authors answer NA or No, they should explain why their work has no societal impact or why the paper does not address societal impact.   \n\u00b7 Examples of negative societal impacts include potential malicious or unintended uses (e.g., disinformation, generating fake profiles, surveillance), fairness considerations (e.g., deployment of technologies that could make decisions that unfairly impact specific groups), privacy considerations, and security considerations.   \n\u00b7 The conference expects that many papers will be foundational research and not tied to particular applications, let alone deployments. However, if there is a direct path to any negative applications, the authors should point it out. For example, it is legitimate to point out that an improvement in the quality of generative models could be used to generate deepfakes for disinformation. On the other hand, it is not needed to point out that a generic algorithm for optimizing neural networks could enable people to train models that generate Deepfakes faster.   \n\u00b7 The authors should consider possible harms that could arise when the technology is being used as intended and functioning correctly, harms that could arise when the technology is being used as intended but gives incorrect results, and harms following from (intentional or unintentional) misuse of the technology.   \n\u00b7 If there are negative societal impacts, the authors could also discuss possible mitigation strategies (e.g., gated release of models, providing defenses in addition to attacks, mechanisms for monitoring misuse, mechanisms to monitor how a system learns from feedback over time, improving the efficiency and accessibility of ML). ", "page_idx": 45}, {"type": "text", "text": "", "page_idx": 46}, {"type": "text", "text": "11. Safeguards ", "text_level": 1, "page_idx": 46}, {"type": "text", "text": "Question: Does the paper describe safeguards that have been put in place for responsible release of data or models that have a high risk for misuse (e.g., pretrained language models, image generators, or scraped datasets)? ", "page_idx": 46}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 46}, {"type": "text", "text": "Justification: Our work does not pose such risks. ", "page_idx": 46}, {"type": "text", "text": "Guidelines: ", "page_idx": 46}, {"type": "text", "text": "\u00b7 The answer NA means that the paper poses no such risks.   \n\u00b7 Released models that have a high risk for misuse or dual-use should be released with necessary safeguards to allow for controlled use of the model, for example by requiring that users adhere to usage guidelines or restrictions to access the model or implementing safety filters.   \n\u00b7 Datasets that have been scraped from the Internet could pose safety risks. The authors should describe how they avoided releasing unsafe images.   \n\u00b7 We recognize that providing effective safeguards is challenging, and many papers do not require this, but we encourage authors to take this into account and make a best faith effort. ", "page_idx": 46}, {"type": "text", "text": "12. Licenses for existing assets ", "text_level": 1, "page_idx": 46}, {"type": "text", "text": "Question: Are the creators or original owners of assets (e.g., code, data, models), used in the paper, properly credited and are the license and terms of use explicitly mentioned and properly respected? ", "page_idx": 46}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 46}, {"type": "text", "text": "Justification: All the datasets, used in our work, are cited accordingly. ", "page_idx": 46}, {"type": "text", "text": "Guidelines: ", "page_idx": 46}, {"type": "text", "text": "\u00b7 The answer NA means that the paper does not use existing assets.   \n\u00b7 The authors should cite the original paper that produced the code package or dataset.   \n\u00b7 The authors should state which version of the asset is used and, if possible, include a URL.   \n\u00b7 The name of the license (e.g., CC-BY 4.0) should be included for each asset.   \n\u00b7 For scraped data from a particular source (e.g., website), the copyright and terms of service of that source should be provided.   \n\u00b7 If assets are released, the license, copyright information, and terms of use in the package should be provided. For popular datasets, paperswithcode . com/datasets has curated licenses for some datasets. Their licensing guide can help determine the license of a dataset.   \n\u00b7 For existing datasets that are re-packaged, both the original license and the license of the derived asset (if it has changed) should be provided. ", "page_idx": 46}, {"type": "text", "text": "\u00b7 If this information is not available online, the authors are encouraged to reach out to the asset's creators. ", "page_idx": 47}, {"type": "text", "text": "13. New Assets ", "text_level": 1, "page_idx": 47}, {"type": "text", "text": "Question: Are new assets introduced in the paper well documented and is the documentation provided alongside the assets? ", "page_idx": 47}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 47}, {"type": "text", "text": "Justification: We do not provide any assets in our work. ", "page_idx": 47}, {"type": "text", "text": "Guidelines: ", "page_idx": 47}, {"type": "text", "text": "\u00b7 The answer NA means that the paper does not release new assets.   \n\u00b7 Researchers should communicate the details of the dataset/code/model as part of their submissions via structured templates. This includes details about training, license, limitations, etc.   \n\u00b7 The paper should discuss whether and how consent was obtained from people whose assetisused.   \n\u00b7 At submission time, remember to anonymize your assets (if applicable). You can either create an anonymized URL or include an anonymized zip file. ", "page_idx": 47}, {"type": "text", "text": "14. Crowdsourcing and Research with Human Subjects ", "text_level": 1, "page_idx": 47}, {"type": "text", "text": "Question: For crowdsourcing experiments and research with human subjects, does the paper include the full text of instructions given to participants and screenshots, if applicable, as well as details about compensation (if any)? ", "page_idx": 47}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 47}, {"type": "text", "text": "Justification: Our work does not involve crowdsourcing nor research with human subjects. Guidelines: ", "page_idx": 47}, {"type": "text", "text": "\u00b7 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u00b7 Including this information in the supplemental material is fine, but if the main contribution of the paper involves human subjects, then as much detail as possible should be included in the main paper.   \n\u00b7 According to the NeurIPs Code of Ethics, workers involved in data collection, curation, or other labor should be paid at least the minimum wage in the country of the data collector. ", "page_idx": 47}, {"type": "text", "text": "15. Institutional Review Board (IRB) Approvals or Equivalent for Research with Human Subjects ", "text_level": 1, "page_idx": 47}, {"type": "text", "text": "Question: Does the paper describe potential risks incurred by study participants, whether such risks were disclosed to the subjects, and whether Institutional Review Board (IRB) approvals (or an equivalent approval/review based on the requirements of your country or institution)were obtained? ", "page_idx": 47}, {"type": "text", "text": "Answer: [NA] ", "text_level": 1, "page_idx": 47}, {"type": "text", "text": "Justification: Our work does not involve crowdsourcing nor research with human subjects. Guidelines: ", "page_idx": 47}, {"type": "text", "text": "\u00b7 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u00b7 Depending on the country in which research is conducted, IRB approval (or equivalent) may be required for any human subjects research. If you obtained IRB approval, you should clearly state this in the paper.   \n\u00b7 We recognize that the procedures for this may vary significantly between institutions and locations, and we expect authors to adhere to the NeurIPs Code of Ethics and the guidelines for their institution.   \n\u00b7 For initial submissions, do not include any information that would break anonymity (if applicable), such as the institution conducting the review. ", "page_idx": 47}]