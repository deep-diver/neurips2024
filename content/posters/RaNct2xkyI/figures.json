[{"figure_path": "RaNct2xkyI/figures/figures_1_1.jpg", "caption": "Figure 1: Security risks of VIReID in the physical world. Images with added noise are referred to as adversarial samples. Red indicates that adversarial samples will incorrectly match pedestrians. Green indicates that clean samples will correctly match pedestrians.", "description": "This figure illustrates the security vulnerabilities of Visible-Infrared Person Re-identification (VIReID) systems.  It shows two scenarios: (a) where an infrared image of a person with added adversarial noise (indicated by a colorful bar at the bottom) is incorrectly matched to a visible image of a different person, and (b) a visible image with adversarial noise is incorrectly matched to an infrared image of a different person.  Correct matches are indicated in green, and incorrect matches (due to adversarial attacks) are indicated in red. This highlights the risk of attackers manipulating images to deceive the VIReID system.", "section": "1 Introduction"}, {"figure_path": "RaNct2xkyI/figures/figures_3_1.jpg", "caption": "Figure 2: Overview of the proposed method. FSAM consists of FFT and IFFT along with a spatial focusing module, focusing on the frequency-domain spatial characteristics of the image. We propose a auxiliary quadruple adversarial loss function and provide a simple illustration of its operation.", "description": "This figure illustrates the overall architecture of the proposed method for feature-level adversarial attacks and ranking disruption in Visible-Infrared Person Re-identification (VIReID).  It shows a dual-stream ResNet network as the backbone, with universal adversarial perturbation (UAP) added to visible and infrared images. The Frequency-Spatial Attention Module (FSAM) extracts frequency-domain spatial features, and the Auxiliary Quadruple Adversarial Loss (LAQAL) amplifies modality differences to disrupt ranking results. The figure also includes a detailed diagram of the FSAM module, showing the FFT, spatial attention module (SAM), and IFFT processes.", "section": "3 Proposed Method"}, {"figure_path": "RaNct2xkyI/figures/figures_4_1.jpg", "caption": "Figure 3: Decomposition and reconstruction of visible and infrared image in the frequency domain. (a) denote visible and infrared images of pedestrian; (b)present the reconstructed images with amplitude information only; (c) are the reconstructed images with phase information only.", "description": "This figure shows the decomposition and reconstruction of visible and infrared images using Fast Fourier Transform (FFT).  Subfigure (a) displays the original visible and infrared images of a pedestrian. Subfigure (b) shows the reconstruction using only the amplitude information from the FFT, highlighting the overall brightness and contrast. Subfigure (c) shows the reconstruction using only the phase information from the FFT, emphasizing the structural details and shape of the pedestrian.", "section": "3.2 Frequency-Spatial Attention Module"}, {"figure_path": "RaNct2xkyI/figures/figures_9_1.jpg", "caption": "Figure 4: t-SNE visualization comparison before and after the attack. Different colors represent different identities. The \u2018asterisks\u2019 and \u2018rectangles\u2019 denote the infrared person features and visible person features, respectively. After the attack, the features are dispersed, enlarging the distance between modalities.", "description": "This figure shows the t-SNE visualization of the features before and after the adversarial attack.  Each point represents a pedestrian image feature from either the visible or infrared modality. Different colors indicate different identities. Before the attack (left), features from the same identity cluster tightly together, and visible and infrared features are closely related. After the attack (right), the feature clusters are significantly more dispersed, showing how the attack separates features across modalities and within identities. This demonstrates that the attack effectively disrupts the relationship between visible and infrared features, impacting the re-identification performance.", "section": "Visualization Analysis"}]