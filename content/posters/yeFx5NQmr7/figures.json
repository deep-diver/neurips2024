[{"figure_path": "yeFx5NQmr7/figures/figures_0_1.jpg", "caption": "Figure 1: Given the observed piece of cloth as shown on the left, we aim to animate various garments inheriting the attributes from the observations as shown in the middle and right. We disentangle the garment-wise learning into two sub-tasks: 1) learning constitutive relations by our proposed EUNet; 2) animating diverse garments through energy optimization constrained by EUNet.", "description": "This figure demonstrates the core idea of the paper.  The left shows a single piece of cloth whose movement is observed and used to learn the physical properties of the material. This learned information is then used to simulate the realistic movement of different garments (middle and right) made from that same material, showcasing the ability to animate various clothing items using only data from a simple cloth.", "section": "Introduction"}, {"figure_path": "yeFx5NQmr7/figures/figures_3_1.jpg", "caption": "Figure 2: Overview of the disentangled learning scheme and our EUNet for garment animation. Unlike traditional garment-wise learning which relies on large scale of garment data, we first aim to capture the constitutive relations from the observed piece of cloth using our EUNet. Without the prior of analytical clothing models or differentiable simulator, EUNet is able to extract the potential energies of the cloth under different deformations, such as stretching and bending, directly from the observed trajectories in a system with dissipation. Secondly, given the external force sequences and the garment templates, we dynamically animate various garments based on the energy optimizations, where EUNet serves as material priors. As a result, we can animate garments that inherit the attributes, such as the stiffness, from the observed cloth, and achieve robust and physically plausible animations.", "description": "This figure illustrates the two-step disentangled learning approach for garment animation. First, the EUNet learns constitutive relations from a single piece of cloth's trajectory, capturing energy changes from various deformations without using analytical physics models.  Then, this learned information is used to constrain energy optimization for animating various garments, resulting in realistic movements.", "section": "3 Methodology"}, {"figure_path": "yeFx5NQmr7/figures/figures_6_1.jpg", "caption": "Figure 2: Overview of the disentangled learning scheme and our EUNet for garment animation. Unlike traditional garment-wise learning which relies on large scale of garment data, we first aim to capture the constitutive relations from the observed piece of cloth using our EUNet. Without the prior of analytical clothing models or differentiable simulator, EUNet is able to extract the potential energies of the cloth under different deformations, such as stretching and bending, directly from the observed trajectories in a system with dissipation. Secondly, given the external force sequences and the garment templates, we dynamically animate various garments based on the energy optimizations, where EUNet serves as material priors. As a result, we can animate garments that inherit the attributes, such as the stiffness, from the observed cloth, and achieve robust and physically plausible animations.", "description": "This figure illustrates the two-step disentangled learning approach used in the paper. First, a constitutive model (EUNet) is trained on a single piece of cloth to learn the relationship between deformation and energy.  Then, this model is used to animate various garments by constraining energy optimization, allowing the animation to inherit material properties from the learned model.", "section": "3 Methodology"}, {"figure_path": "yeFx5NQmr7/figures/figures_8_1.jpg", "caption": "Figure 4: Qualitative results by our disentangled training scheme. We train MGN-S and MGN-H constrained by our EUNet through energy optimization scheme. Since the observed cloth to train EUNet is made of the same materials as the ground truth garments, the constitutive relations captured by EUNet are consistent with the ground truth data. As a result, MGN-S and MGN-H constrained by EUNet deliver similar deformation patterns as the ground truth garments without accessing any garment data. Even in long-term predictions, we can obtain plausible wrinkles, which are difficult for models trained in a garment-wise learning pipeline, and robust interactions with the human body.", "description": "This figure shows a qualitative comparison of garment animation results.  The top row displays ground truth garment movements. The middle and bottom rows show results from models trained using the proposed disentangled learning scheme, demonstrating their ability to generate realistic garment animations that closely match the ground truth, even for complex movements and over longer time periods.", "section": "4.2 Animating Garments"}, {"figure_path": "yeFx5NQmr7/figures/figures_8_2.jpg", "caption": "Figure 4: Qualitative results by our disentangled training scheme. We train MGN-S and MGN-H constrained by our EUNet through energy optimization scheme. Since the observed cloth to train EUNet is made of the same materials as the ground truth garments, the constitutive relations captured by EUNet are consistent with the ground truth data. As a result, MGN-S and MGN-H constrained by EUNet deliver similar deformation patterns as the ground truth garments without accessing any garment data. Even in long-term predictions, we can obtain plausible wrinkles, which are difficult for models trained in a garment-wise learning pipeline, and robust interactions with the human body.", "description": "This figure shows qualitative results comparing the garment animation generated by models trained using the proposed disentangled learning scheme (MGN-S and MGN-H with EUNet) against baselines. The results demonstrate that the proposed method achieves more realistic and robust garment animation, even for long-term predictions, by leveraging the learned constitutive relations from a single piece of cloth.", "section": "4.2 Animating Garments"}, {"figure_path": "yeFx5NQmr7/figures/figures_11_1.jpg", "caption": "Figure 6: The observed trajectories of cloth for training EUNet. The cloth is made of different materials and pinned by two corners on top. We randomly initialize the positions with different velocities for the cloth and let the cloth deform under the influence of forces.", "description": "This figure shows the training data used for the EUNet model in the paper.  It showcases five different time steps (T=1, T=7, T=13, T=19, T=25) in the simulated movement of two pieces of cloth, one made of leather and the other of silk. Both cloths are pinned at two corners, and their dynamic behaviors under gravity are captured. The purpose of this data is to train the EUNet model to learn the constitutive relationships between deformation and energy, which is independent of garment topology.", "section": "3.1 Data of A Piece of Cloth"}, {"figure_path": "yeFx5NQmr7/figures/figures_11_2.jpg", "caption": "Figure 7: We represent the angles between vertex normals n and n by [\u03b1eij, \u03b2eij], where \u03b1eij is the rotation angle along edge vector eij from ni to the plane defined by ni and eij, \u03b2eij is the angle between ni and the rotated vertex normal within the plane.", "description": "This figure shows how the angles between vertex normals are represented.  The angles \u03b1eij and \u03b2eij are defined to describe the change in orientation of the vertex normals (ni and nt) relative to the edge eij.  \u03b1eij represents a rotation around the edge, and \u03b2eij represents the angle between the rotated normal and the original normal within the plane formed by the edge and the original normal. This method helps in capturing both bending and stretching deformations.", "section": "A.1.2 Edge-Wise Potential Energy \u03a6p(\u00b7)"}, {"figure_path": "yeFx5NQmr7/figures/figures_12_1.jpg", "caption": "Figure 8: Demonstration of the impact caused by the disturbed vertex. Suppose figure (a) is the ground truth position for each vertex at time t + 1. When adding noise to the vertex i at the center, the vertex normals of the surrounding orange vertices j \u2208 Ni are disturbed. As a result, energy units for edges, which connect to both vertex i and vertices j \u2208 Ni and are marked by orange, change accordingly.", "description": "This figure demonstrates how a small change (noise) added to one vertex affects the energy of its neighboring vertices and their connecting edges. The left panel (a) shows the undisturbed mesh. The right panel (b) shows that when a noise is applied to vertex i (red), it changes the normal vectors of the nearby orange vertices (j \u2208 Ni). Consequently, the edge energy units between vertex i and j \u2208 Ni (orange edges) also change.", "section": "A.1.3 Vertex-Wise Contrastive Loss"}, {"figure_path": "yeFx5NQmr7/figures/figures_15_1.jpg", "caption": "Figure 4: Qualitative results by our disentangled training scheme. We train MGN-S and MGN-H constrained by our EUNet through energy optimization scheme. Since the observed cloth to train EUNet is made of the same materials as the ground truth garments, the constitutive relations captured by EUNet are consistent with the ground truth data. As a result, MGN-S and MGN-H constrained by EUNet deliver similar deformation patterns as the ground truth garments without accessing any garment data. Even in long-term predictions, we can obtain plausible wrinkles, which are difficult for models trained in a garment-wise learning pipeline, and robust interactions with the human body.", "description": "This figure displays qualitative results of garment animation using the proposed disentangled training scheme.  Models (MGN-S and MGN-H) constrained by the Energy Unit Network (EUNet) show similar deformation patterns to the ground truth garments, demonstrating the effectiveness of learning constitutive relations from a single piece of cloth.  The results highlight the model's ability to generate realistic wrinkles and interactions with a human body, even in long-term predictions, unlike garment-wise trained models.", "section": "4.2 Animating Garments"}]