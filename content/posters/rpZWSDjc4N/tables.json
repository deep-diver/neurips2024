[{"figure_path": "rpZWSDjc4N/tables/tables_7_1.jpg", "caption": "Table 1: Comparison of visual explanation accuracy metric for different categories. 'all' denotes the three categories are included.", "description": "This table compares the visual explanation accuracy of four different methods (Grad-CAM, ODAM, OccAM, and FFAM) across four categories (all, car, pedestrian, and cyclist).  The accuracy metric used is VEA (Visual Explanation Accuracy), a measure of how well the explanation highlights the relevant parts of the input point cloud.  Higher values indicate better accuracy. The results show that FFAM significantly outperforms the other methods in terms of visual explanation accuracy.", "section": "4.2 Quantitative Results"}, {"figure_path": "rpZWSDjc4N/tables/tables_7_2.jpg", "caption": "Table 2: AUC for Deletion and Insertion curves. The results of different categories are reported. 'all' means the combination of the three categories.", "description": "This table presents the Area Under the Curve (AUC) values for Deletion and Insertion experiments, evaluating the impact of removing or adding salient points on the model's prediction accuracy.  Results are shown for all object categories (car, pedestrian, cyclist) and a combined 'all' category. Lower Deletion AUC indicates a more significant impact of removing points, while higher Insertion AUC shows a greater influence of adding salient points.", "section": "4.2 Quantitative Results"}, {"figure_path": "rpZWSDjc4N/tables/tables_8_1.jpg", "caption": "Table 3: Comparison of Pointing game (PG) and energy-based Pointing game (enPG) metrics.", "description": "This table presents the results of two metrics used to evaluate the quality of visual explanations generated by different methods. Pointing Game (PG) measures the accuracy of the saliency map by calculating the ratio of hits to the total number of hits and misses. Energy-based Pointing Game (enPG) considers the energy within the ground truth region compared to the global scene.  The table shows the performance of Grad-CAM, ODAM, OccAM and the proposed FFAM method across all object categories (All), Cars, Pedestrians and Cyclists.  Higher scores in both PG and enPG indicate better performance.", "section": "4.2 Quantitative Results"}, {"figure_path": "rpZWSDjc4N/tables/tables_11_1.jpg", "caption": "Table 4: Results of different layer settings. 'conv1', 'conv2', 'conv3' and 'conv4' represent the 1st, 2nd, 3rd and 4th blocks in the 3D backbone.", "description": "This table presents the results of an ablation study where different layers (conv1-conv4) of the 3D backbone network were used as input for FFAM. The results are evaluated using the metrics Deletion, Insertion, VEA, PG, and enPG.  Lower Deletion scores and higher Insertion scores are better, indicating a stronger correlation between the saliency map and object detection performance. Higher VEA, PG, and enPG scores indicate better visual explanation quality.", "section": "A.1 Hyperparameters Analysis"}, {"figure_path": "rpZWSDjc4N/tables/tables_11_2.jpg", "caption": "Table 5: Results of different (Range, k) settings. \u2018Range\u2019 means the Manhattan distance threshold and k denotes the upper bound of neighbor number in the voxel upsampling strategy.", "description": "This table presents the results of an ablation study on the hyperparameters used in the voxel upsampling strategy of the FFAM method.  The study varies the Manhattan distance threshold (Range) and the number of neighbor voxels (k) considered when upsampling.  The table shows the impact of these hyperparameters on the performance metrics: Deletion, Insertion, Visual Explanation Accuracy (VEA), Pointing Game (PG), and energy-based Pointing Game (enPG).  Each metric measures a different aspect of the quality of the visual explanations generated by the model. The bolded values indicate the best-performing configuration for each metric.", "section": "A.1 Hyperparameters Analysis"}, {"figure_path": "rpZWSDjc4N/tables/tables_11_3.jpg", "caption": "Table 6: Results of different concept number settings. r denotes the concept number.", "description": "This table presents the results of an ablation study on the impact of the concept number (r) on the performance of FFAM. The metrics used to evaluate the performance are Deletion, Insertion, Visual Explanation Accuracy (VEA), Pointing Game (PG), and energy-based Pointing Game (enPG). The table shows that using r = 64 yields the best performance across most metrics.", "section": "A.1 Hyperparameters Analysis"}, {"figure_path": "rpZWSDjc4N/tables/tables_12_1.jpg", "caption": "Table 2: AUC for Deletion and Insertion curves. The results of different categories are reported. 'all' means the combination of the three categories.", "description": "This table presents the Area Under the Curve (AUC) values for Deletion and Insertion experiments.  These experiments measure the impact of removing (Deletion) or adding (Insertion) points identified as important by the model on the model's accuracy in object detection.  AUC values are provided for all object classes (all), cars, pedestrians, and cyclists separately. Higher AUC values for Insertion are better, showing that adding points quickly improves accuracy, while lower AUC values for Deletion are better, showing that removing important points quickly decreases accuracy. This table helps to quantitatively assess the quality of the visual explanations generated by the proposed method and compare it to other methods. ", "section": "4.2 Quantitative Results"}, {"figure_path": "rpZWSDjc4N/tables/tables_12_2.jpg", "caption": "Table 3: Comparison of Pointing game (PG) and energy-based Pointing game (enPG) metrics.", "description": "This table compares the performance of four different visual explanation methods (Grad-CAM, ODAM, OccAM, and FFAM) on the Pointing Game (PG) and energy-based Pointing Game (enPG) metrics.  The PG metric measures the accuracy of saliency maps by calculating the ratio of hits to the total number of hits and misses.  The enPG metric considers the energy within the ground truth region compared to the global scene.  Higher values in both PG and enPG indicate better localization performance of the explanation method.", "section": "4.2 Quantitative Results"}, {"figure_path": "rpZWSDjc4N/tables/tables_12_3.jpg", "caption": "Table 9: Comparison of visual explanation accuracy metric for different categories. 'all' denotes the three categories are included.", "description": "This table presents a comparison of the visual explanation accuracy (VEA) achieved by four different methods: Grad-CAM, ODAM, OccAM, and the proposed FFAM. The VEA metric is calculated for all three object categories (car, pedestrian, cyclist) and overall.  Higher VEA scores indicate better visual explanation accuracy, reflecting how well the saliency map highlights the most relevant regions in the input point cloud contributing to the detection.", "section": "4.2 Quantitative Results"}, {"figure_path": "rpZWSDjc4N/tables/tables_13_1.jpg", "caption": "Table 10: Effect of different components of FFAM. OG, VU and FF denote object-specific gradient, voxel upsampling and feature factorization, respectively.", "description": "This table presents the ablation study of the FFAM method. It shows the effect of each component (object-specific gradient, voxel upsampling, and feature factorization) on the overall performance, measured by Deletion, Insertion, VEA, PG, and enPG. The results demonstrate that each component contributes positively to the performance, with the combination of all three yielding the best results.", "section": "A.4 Ablation Study"}]