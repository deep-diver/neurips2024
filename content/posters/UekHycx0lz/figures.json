[{"figure_path": "UekHycx0lz/figures/figures_1_1.jpg", "caption": "Figure 1: DreamSteerer enables efficient editability enhancement for a source image with any existing T2I personalization models, leading to significantly improved editing fidelity in various challenging scenarios. When the structural difference between source and reference images are significant, it can naturally adapt to the source while maintaining the appearance learned from the personal concept.", "description": "This figure shows several examples of image editing using different personalization methods (Textual Inversion, DreamBooth, and Custom Diffusion) and compares the results with and without the proposed DreamSteerer method.  Each row represents a different editing task, with the source image to be edited displayed next to reference images that provide the desired personal concept.  The results demonstrate that DreamSteerer leads to significantly improved editing fidelity, especially when the source and reference images have significant structural differences. The model is able to adapt to the source image while preserving the learned appearance of the personal concept.", "section": "1 Introduction"}, {"figure_path": "UekHycx0lz/figures/figures_4_1.jpg", "caption": "Figure 1: DreamSteerer enables efficient editability enhancement for a source image with any existing T2I personalization models, leading to significantly improved editing fidelity in various challenging scenarios. When the structural difference between source and reference images are significant, it can naturally adapt to the source while maintaining the appearance learned from the personal concept.", "description": "This figure demonstrates the effectiveness of DreamSteerer in enhancing the editability of personalized diffusion models.  It shows several examples of image editing using different personalization methods (Textual Inversion, DreamBooth, and Custom Diffusion), where DreamSteerer consistently produces higher-fidelity results, particularly when the source and reference images have significant structural differences.  DreamSteerer adapts to the source image layout while preserving the appearance learned from the personalized concept.", "section": "1 Introduction"}, {"figure_path": "UekHycx0lz/figures/figures_5_1.jpg", "caption": "Figure 3: Overall framework of DreamSteerer (the gradient flows are illustrated with dashed lines).", "description": "This figure illustrates the overall framework of the DreamSteerer method. It shows how the method enhances source image conditioned editability by using an Editability Driven Score Distillation (EDSD) objective and a mode shifting regularization with spatial feature guided sampling. The EDSD objective aligns the score estimations of the pre-trained and personalized models, and the mode shifting regularization alleviates mode trapping issues.", "section": "4 The DreamSteerer Method"}, {"figure_path": "UekHycx0lz/figures/figures_6_1.jpg", "caption": "Figure 4: The effect of different regularization strategies on the editing and generation results of a DreamBooth baseline. The source prompt is \"a photo of a cat sitting next to a mirror\".", "description": "This figure shows the impact of different regularization techniques on image editing and generation using a DreamBooth model.  The source image depicts a cat sitting next to a mirror, which is then edited using various methods.  The image illustrates the baseline results without any regularization and the improvements observed after applying mode shifting regularization and spatial feature guided sampling.  The goal is to demonstrate how these techniques enhance the fidelity and consistency of the edits, specifically ensuring the edited image maintains a similar structure and background to the original source image while incorporating the desired changes.", "section": "4.2 Mode Shifting regularization with spatial feature guided sampling"}, {"figure_path": "UekHycx0lz/figures/figures_7_1.jpg", "caption": "Figure 1: DreamSteerer enables efficient editability enhancement for a source image with any existing T2I personalization models, leading to significantly improved editing fidelity in various challenging scenarios. When the structural difference between source and reference images are significant, it can naturally adapt to the source while maintaining the appearance learned from the personal concept.", "description": "This figure showcases the results of DreamSteerer applied to several source images, comparing its performance to other methods (Textual Inversion, DreamBooth, and Custom Diffusion). It demonstrates that DreamSteerer effectively enhances the editability of source images conditioned on the learned concepts from personalized diffusion models, resulting in improved editing fidelity and natural adaptation to the source image layout even when significant structural differences exist between the source and reference images.", "section": "1 Introduction"}, {"figure_path": "UekHycx0lz/figures/figures_8_1.jpg", "caption": "Figure 6: Ablation study on EDSD and Mode Shifting Regularization.", "description": "This figure presents an ablation study to demonstrate the effectiveness of the proposed methods, EDSD and Mode Shifting Regularization.  The left half shows the results when EDSD is not used, and the right half demonstrates results without Mode Shifting Regularization. By comparing the results with and without each component, the individual contributions of EDSD and Mode Shifting to the overall performance of DreamSteerer are highlighted. This helps to understand their impact on editability, image fidelity, and structural preservation.", "section": "4.2 Mode Shifting regularization with spatial feature guided sampling"}, {"figure_path": "UekHycx0lz/figures/figures_9_1.jpg", "caption": "Figure 1: DreamSteerer enables efficient editability enhancement for a source image with any existing T2I personalization models, leading to significantly improved editing fidelity in various challenging scenarios. When the structural difference between source and reference images are significant, it can naturally adapt to the source while maintaining the appearance learned from the personal concept.", "description": "This figure shows several examples of image editing using different methods: Textual Inversion, DreamBooth, and a custom diffusion model. The \"Ours\" column represents the results obtained using the proposed DreamSteerer method. The results demonstrate that DreamSteerer significantly improves the editing fidelity, especially when the source and reference images have significant structural differences.", "section": "1 Introduction"}, {"figure_path": "UekHycx0lz/figures/figures_16_1.jpg", "caption": "Figure 8: Results with different Jacobian omitting strategy.", "description": "This figure shows the results of using different Jacobian omitting strategies in the Editability Driven Score Distillation (EDSD) method. The results demonstrate that setting the Jacobian to -I leads to significantly better results with natural adaptation to the layout of the source image, while setting the Jacobian to I tends to destroy the structural layout and background of the source image. This indicates that setting the Jacobian to I maximizes the discrepancy between personalized and source model score estimations.", "section": "4.2 Mode Shifting regularization with spatial feature guided sampling"}, {"figure_path": "UekHycx0lz/figures/figures_17_1.jpg", "caption": "Figure 1: DreamSteerer enables efficient editability enhancement for a source image with any existing T2I personalization models, leading to significantly improved editing fidelity in various challenging scenarios. When the structural difference between source and reference images are significant, it can naturally adapt to the source while maintaining the appearance learned from the personal concept.", "description": "This figure showcases the results of DreamSteerer, a novel method for improving the source image conditioned editability of personalized diffusion models.  It presents several examples comparing the results of DreamSteerer with existing textual inversion, DreamBooth, and custom diffusion models.  In each example, a source image and several reference images are provided; DreamSteerer successfully adapts the style and appearance from the reference images to the source image, often with better fidelity and naturalness than the baselines, even when there are significant structural differences between the source and reference images.", "section": "1 Introduction"}, {"figure_path": "UekHycx0lz/figures/figures_17_2.jpg", "caption": "Figure 10: Comparison with Custom-Edit.", "description": "This figure shows a comparison of image editing results using Custom-Edit and Custom-Edit enhanced with DreamSteerer.  It demonstrates DreamSteerer's ability to improve editing fidelity and natural adaptation to the source image layout, particularly when challenging structural differences exist between the source and reference images.  The results showcase how DreamSteerer enhances the quality and accuracy of the editing process, providing more realistic and aligned results compared to the base Custom-Edit method.", "section": "5 Experiments"}, {"figure_path": "UekHycx0lz/figures/figures_18_1.jpg", "caption": "Figure 1: DreamSteerer enables efficient editability enhancement for a source image with any existing T2I personalization models, leading to significantly improved editing fidelity in various challenging scenarios. When the structural difference between source and reference images are significant, it can naturally adapt to the source while maintaining the appearance learned from the personal concept.", "description": "This figure showcases the results of DreamSteerer applied to different source images and personalized concepts.  Each row shows the reference images used for personalization, the original source image, and then the results of three different editing methods: Textual Inversion, DreamBooth, and a custom diffusion model.  DreamSteerer significantly improves the editing results by maintaining a high fidelity to the source image while incorporating the desired personalized concept. The results highlight DreamSteerer's ability to handle challenging scenarios where there are significant structural differences between the source and reference images.", "section": "1 Introduction"}, {"figure_path": "UekHycx0lz/figures/figures_18_2.jpg", "caption": "Figure 4: The effect of different regularization strategies on the editing and generation results of a DreamBooth baseline. The source prompt is \"a photo of a cat sitting next to a mirror\".", "description": "This figure shows an ablation study comparing different regularization strategies used in the DreamSteerer method for image editing with personalized diffusion models.  The baseline model is DreamBooth.  The source image is a photo of a cat next to a mirror. Four scenarios are displayed: (a) Baseline results without any mode shifting or additional regularization; (b) Results without mode shifting but with the EDSD method; (c) Results with mode shifting but without EDSD; (d) Results with both EDSD and mode shifting.  The figure demonstrates how each approach affects the fidelity and accuracy of the generated image in terms of incorporating the personalized concept and preserving the structure of the source image.", "section": "4.2 Mode Shifting regularization with spatial feature guided sampling"}, {"figure_path": "UekHycx0lz/figures/figures_19_1.jpg", "caption": "Figure 1: DreamSteerer enables efficient editability enhancement for a source image with any existing T2I personalization models, leading to significantly improved editing fidelity in various challenging scenarios. When the structural difference between source and reference images are significant, it can naturally adapt to the source while maintaining the appearance learned from the personal concept.", "description": "This figure shows the results of DreamSteerer applied to several source images using different personalization methods, including Textual Inversion, DreamBooth, and Custom Diffusion.  The results demonstrate that DreamSteerer successfully enhances the editability of these baselines, producing high-fidelity edits that closely match the reference images while preserving the structure and background of the source image, even in challenging scenarios with significant structural differences between the source and reference images.", "section": "1 Introduction"}, {"figure_path": "UekHycx0lz/figures/figures_20_1.jpg", "caption": "Figure 6: Ablation study on EDSD and Mode Shifting Regularization.", "description": "This figure shows the ablation study of the proposed method, DreamSteerer. The left part shows the comparison of the results with and without Editability Driven Score Distillation (EDSD). The right part shows the comparison of the results with and without mode shifting regularization.  Each row represents a different editing task, showcasing the source image, the reference image(s), and the results using various combinations of the proposed components.  The results highlight the individual and combined effects of EDSD and mode shifting on improving image editability.", "section": "4.2 Mode Shifting regularization with spatial feature guided sampling"}, {"figure_path": "UekHycx0lz/figures/figures_20_2.jpg", "caption": "Figure 5: Illustration on the effect of the proposed components on editing with a DreamBooth baseline (1st row shows the editing results; 2nd row shows the editing directions, where brown means zero).", "description": "This figure demonstrates the impact of different components of the DreamSteerer method on image editing using a DreamBooth baseline. The top row shows the edited images, comparing the results obtained with only SDS (score distillation sampling), DDS (delta denoising score) with and without source score bias correction, and DDS-S (modified DDS) with and without EDSD (editability driven score distillation) and mode shifting regularization. The bottom row displays the editing direction vectors, visualizing how much each pixel is changed in the process. Brown color indicates no changes in the pixel, suggesting the efficacy of DreamSteerer's approach to enhance source image conditioned editability.", "section": "3.1 Preliminary Editing with Existing Personalization Baseline"}, {"figure_path": "UekHycx0lz/figures/figures_20_3.jpg", "caption": "Figure 1: DreamSteerer enables efficient editability enhancement for a source image with any existing T2I personalization models, leading to significantly improved editing fidelity in various challenging scenarios. When the structural difference between source and reference images are significant, it can naturally adapt to the source while maintaining the appearance learned from the personal concept.", "description": "This figure shows several examples of image editing using DreamSteerer and compares it with other methods (Textual Inversion, DreamBooth, and Custom Diffusion).  Each row displays a reference image set used for personalization, the source image to be edited, and the results from different editing methods. The results demonstrate that DreamSteerer is better able to maintain the overall structure of the source image while incorporating the personalized concept, especially in cases with significant structural differences between the source and reference images.", "section": "1 Introduction"}, {"figure_path": "UekHycx0lz/figures/figures_21_1.jpg", "caption": "Figure 1: DreamSteerer enables efficient editability enhancement for a source image with any existing T2I personalization models, leading to significantly improved editing fidelity in various challenging scenarios. When the structural difference between source and reference images are significant, it can naturally adapt to the source while maintaining the appearance learned from the personal concept.", "description": "This figure demonstrates the capability of DreamSteerer to enhance the source image conditioned editability using existing personalized diffusion models.  It shows several examples of image editing where a personalized concept (e.g., a specific cat or dog) is applied to a source image.  Even when the source and reference images have significant structural differences, DreamSteerer successfully adapts, preserving the source image's structure while incorporating the personalized concept with high fidelity.", "section": "1 Introduction"}, {"figure_path": "UekHycx0lz/figures/figures_22_1.jpg", "caption": "Figure 1: DreamSteerer enables efficient editability enhancement for a source image with any existing T2I personalization models, leading to significantly improved editing fidelity in various challenging scenarios. When the structural difference between source and reference images are significant, it can naturally adapt to the source while maintaining the appearance learned from the personal concept.", "description": "This figure shows several examples of image editing using DreamSteerer.  Each row presents the reference images used for personalization, the source image to be edited, and the results of editing with three different methods: Textual Inversion, DreamBooth, and a custom diffusion model.  The results demonstrate DreamSteerer's ability to successfully integrate personalized concepts while preserving the structure and background of the source image, even when there are significant structural differences between the source and reference images.", "section": "1 Introduction"}, {"figure_path": "UekHycx0lz/figures/figures_23_1.jpg", "caption": "Figure 1: DreamSteerer enables efficient editability enhancement for a source image with any existing T2I personalization models, leading to significantly improved editing fidelity in various challenging scenarios. When the structural difference between source and reference images are significant, it can naturally adapt to the source while maintaining the appearance learned from the personal concept.", "description": "This figure shows several examples of image editing using DreamSteerer, a method that enhances the editability of personalized diffusion models. Each row shows the reference images used for personalization, the source image to be edited, and the results of editing using Textual Inversion, DreamBooth, and Custom Diffusion baselines with and without DreamSteerer.  DreamSteerer demonstrates improved editing fidelity, especially when there are significant structural differences between the source and reference images. It allows for the adaptation of the edited image to the source while preserving the appearance of the personalized concept.", "section": "1 Introduction"}, {"figure_path": "UekHycx0lz/figures/figures_24_1.jpg", "caption": "Figure 1: DreamSteerer enables efficient editability enhancement for a source image with any existing T2I personalization models, leading to significantly improved editing fidelity in various challenging scenarios. When the structural difference between source and reference images are significant, it can naturally adapt to the source while maintaining the appearance learned from the personal concept.", "description": "This figure showcases the results of DreamSteerer applied to several source images alongside the results of existing methods (Textual Inversion, DreamBooth, and Custom Diffusion).  For each row, a source image is edited using a reference image to incorporate a specific personalized concept (e.g., a cat statue, a brown cat). DreamSteerer significantly improves editing fidelity compared to existing methods, especially when source and reference images have significant structural differences. It adapts to the source image layout while incorporating the desired visual concept.", "section": "1 Introduction"}, {"figure_path": "UekHycx0lz/figures/figures_24_2.jpg", "caption": "Figure 4: The effect of different regularization strategies on the editing and generation results of a DreamBooth baseline. The source prompt is \"a photo of a cat sitting next to a mirror\".", "description": "This figure shows an ablation study on the effect of different regularization strategies for image editing using a personalized diffusion model. Specifically, it compares the results of using a DreamBooth baseline with and without mode shifting regularization and spatial feature guided sampling.  The results demonstrate that incorporating mode shifting regularization and spatial feature guided sampling significantly improves the editability of the personalized diffusion model, enabling the generation of images that preserve the structural layout of the source image while successfully incorporating the learned personal concept. This highlights the importance of these regularization techniques in achieving high-fidelity editing results with personalized diffusion models.", "section": "4.2 Mode Shifting regularization with spatial feature guided sampling"}, {"figure_path": "UekHycx0lz/figures/figures_25_1.jpg", "caption": "Figure 1: DreamSteerer enables efficient editability enhancement for a source image with any existing T2I personalization models, leading to significantly improved editing fidelity in various challenging scenarios. When the structural difference between source and reference images are significant, it can naturally adapt to the source while maintaining the appearance learned from the personal concept.", "description": "This figure demonstrates the effectiveness of DreamSteerer in enhancing the editability of source images when using personalized diffusion models.  It showcases several editing examples where the source image is modified based on a reference image and a text prompt. The results highlight DreamSteerer's ability to maintain the appearance learned from the personalized concept while adapting to the structure of the source image, even when there are significant differences between the source and reference images.", "section": "1 Introduction"}, {"figure_path": "UekHycx0lz/figures/figures_26_1.jpg", "caption": "Figure 1: DreamSteerer enables efficient editability enhancement for a source image with any existing T2I personalization models, leading to significantly improved editing fidelity in various challenging scenarios. When the structural difference between source and reference images are significant, it can naturally adapt to the source while maintaining the appearance learned from the personal concept.", "description": "This figure showcases example results of DreamSteerer applied to various source images and personalized concepts.  Each row represents an edit, comparing results from Textual Inversion, DreamBooth and a Custom Diffusion model (baselines) to the results produced by the same models enhanced with DreamSteerer.  The results demonstrate how DreamSteerer improves the fidelity and naturalness of the edits, especially when there's a significant structural difference between the reference images and the image being edited. It shows that DreamSteerer can seamlessly integrate the learned appearance of the personalized concepts with the structure of the source images.", "section": "1 Introduction"}, {"figure_path": "UekHycx0lz/figures/figures_26_2.jpg", "caption": "Figure 22: Visualization on averaged cross-attention maps of the DPM UNet encoder and decoder at different resolutions corresponding to 'astronaut' token in the prompt 'an astronaut riding a horse'.", "description": "This figure visualizes the averaged cross-attention maps from the UNet encoder and decoder of a diffusion probabilistic model at different resolutions. The visualization focuses on the 'astronaut' token within the prompt, 'an astronaut riding a horse'.  The maps highlight the areas of the image that the model focuses on when processing that specific token, demonstrating the model's attention mechanism at different resolution levels.", "section": "4.3 Automatic Subject Masking"}, {"figure_path": "UekHycx0lz/figures/figures_26_3.jpg", "caption": "Figure 1: DreamSteerer enables efficient editability enhancement for a source image with any existing T2I personalization models, leading to significantly improved editing fidelity in various challenging scenarios. When the structural difference between source and reference images are significant, it can naturally adapt to the source while maintaining the appearance learned from the personal concept.", "description": "This figure shows several examples of image editing using DreamSteerer and other methods (Textual Inversion, DreamBooth, Custom Diffusion).  For each example, the top row shows the reference images used for personalization. The second row displays the original image to be edited. The following columns display the results of editing that image with different methods.  The results demonstrate DreamSteerer's ability to maintain the appearance of personalized concepts while adapting to the source image structure.  This is particularly noticeable in challenging cases where source and reference images have significant differences in composition or structure.", "section": "1 Introduction"}, {"figure_path": "UekHycx0lz/figures/figures_27_1.jpg", "caption": "Figure 1: DreamSteerer enables efficient editability enhancement for a source image with any existing T2I personalization models, leading to significantly improved editing fidelity in various challenging scenarios. When the structural difference between source and reference images are significant, it can naturally adapt to the source while maintaining the appearance learned from the personal concept.", "description": "This figure shows several examples of image editing using DreamSteerer.  Each row presents a different image editing task. The \"Reference\" column displays the reference images used to personalize the diffusion model. The \"Source\" column shows the original image to be edited. The remaining columns demonstrate the editing results obtained using different methods: Textual Inversion, DreamBooth, and a custom diffusion model. DreamSteerer consistently produces higher-fidelity edits, seamlessly integrating the personalized concept into the source image while preserving its overall structure and background. The results highlight DreamSteerer's ability to handle even significant structural differences between the source and reference images.", "section": "1 Introduction"}, {"figure_path": "UekHycx0lz/figures/figures_27_2.jpg", "caption": "Figure 1: DreamSteerer enables efficient editability enhancement for a source image with any existing T2I personalization models, leading to significantly improved editing fidelity in various challenging scenarios. When the structural difference between source and reference images are significant, it can naturally adapt to the source while maintaining the appearance learned from the personal concept.", "description": "This figure demonstrates the effectiveness of DreamSteerer in enhancing the editability of source images when using existing text-to-image (T2I) personalization methods.  It showcases several examples where DreamSteerer successfully integrates personalized concepts into source images, even when there are substantial structural differences between the source and reference images.  The results highlight DreamSteerer's ability to maintain the appearance of the personalized concept while adapting to the structure of the source image.", "section": "1 Introduction"}]