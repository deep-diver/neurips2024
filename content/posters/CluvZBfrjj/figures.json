[{"figure_path": "CluvZBfrjj/figures/figures_1_1.jpg", "caption": "Figure 1: Comparison of the typical Training with Instance and the proposed Learning with Instruction: The former involves training the model at the instance level with parameter updates, while the latter generates a task-specific adapter at the task level with parameter generation.", "description": "This figure compares two approaches to training language models: training with instances and learning with instructions.  Training with instances involves updating model parameters through backpropagation on many labeled examples. Learning with instructions generates task-specific adapters using a hypernetwork that processes instructions instead of training on instance data. Both approaches are evaluated using seen and unseen tasks.", "section": "1 Introduction"}, {"figure_path": "CluvZBfrjj/figures/figures_3_1.jpg", "caption": "Figure 2: Overview of TAGI. The hypernetwork takes instruction as input and generates adapters subsequently integrated into the vanilla LLM, and constructed the task-specific model as student. After training the task models through instances on multiple basic tasks as a teacher, TAGI constructs task-specific models by aligning the labels, output logits, and adapter parameters between teacher and student models. To improve compliance with task instructions and the efficacy of weight generation, TAGI undergoes a two-stage hypernetwork training process: hypernetwork pretraining and finetuning. a-c are random divisions of the sampled sentences from pretraining datasets.", "description": "This figure illustrates the overall architecture of the Task Adapters Generation from Instructions (TAGI) model.  It shows a two-stage training process. The first stage involves training a hypernetwork to generate task-specific adapters (LoRA modules) based on task instructions. These adapters are then integrated into a vanilla language model (LLM). The second stage involves knowledge distillation, aligning the student model (vanilla LLM + adapters) with a teacher model trained on instance-level data, matching outputs, logits, and adapter parameters. This alignment enhances consistency and improves generalization. The hypernetwork undergoes pretraining and finetuning steps to improve efficiency and performance.", "section": "3.2 Task Adapters Generation from Instructions (TAGI)"}, {"figure_path": "CluvZBfrjj/figures/figures_8_1.jpg", "caption": "Figure 2: Overview of TAGI. The hypernetwork takes instruction as input and generates adapters subsequently integrated into the vanilla LLM, and constructed the task-specific model as student. After training the task models through instances on multiple basic tasks as a teacher, TAGI constructs task-specific models by aligning the labels, output logits, and adapter parameters between teacher and student models. To improve compliance with task instructions and the efficacy of weight generation, TAGI undergoes a two-stage hypernetwork training process: hypernetwork pretraining and finetuning. a-c are random divisions of the sampled sentences from pretraining datasets.", "description": "This figure illustrates the overall architecture of TAGI, a method that leverages instruction learning to enhance the cross-task generalization capabilities of LLMs. It comprises three main steps:\n\n1.  **LoRA Tuning with Instance:** Task-specific LoRA modules are trained on various upstream tasks using instance-based learning, establishing a teacher model.\n2.  **Hypernetwork Pretraining:** The hypernetwork is pretrained on standard text pretraining data, enabling it to generate effective adapters.\n3.  **Hypernetwork Finetuning with Distillation and Alignment:** The hypernetwork is finetuned to generate task-specific adapters based on instructions, aligning them with the teacher model through knowledge distillation and parameter alignment. The aligned student model enhances cross-task generalization.", "section": "3.2 Task Adapters Generation from Instructions (TAGI)"}, {"figure_path": "CluvZBfrjj/figures/figures_8_2.jpg", "caption": "Figure 2: Overview of TAGI. The hypernetwork takes instruction as input and generates adapters subsequently integrated into the vanilla LLM, and constructed the task-specific model as student. After training the task models through instances on multiple basic tasks as a teacher, TAGI constructs task-specific models by aligning the labels, output logits, and adapter parameters between teacher and student models. To improve compliance with task instructions and the efficacy of weight generation, TAGI undergoes a two-stage hypernetwork training process: hypernetwork pretraining and finetuning. a-c are random divisions of the sampled sentences from pretraining datasets.", "description": "This figure shows the architecture of the Task Adapters Generation from Instructions (TAGI) model.  It illustrates the two-stage training process: first, a hypernetwork is pre-trained on general text data, then fine-tuned using knowledge distillation to align a student model (vanilla LLM + generated adapters) with a teacher model (trained on instances). The hypernetwork takes instructions as input and generates task-specific adapters, which are added to the vanilla LLM to create a task-specific model.  The figure highlights the alignment of labels, output logits, and adapter parameters between the teacher and student models, emphasizing the model's ability to learn from instructions and improve efficiency.", "section": "3.2 Task Adapters Generation from Instructions (TAGI)"}, {"figure_path": "CluvZBfrjj/figures/figures_15_1.jpg", "caption": "Figure 2: Overview of TAGI. The hypernetwork takes instruction as input and generates adapters subsequently integrated into the vanilla LLM, and constructed the task-specific model as student. After training the task models through instances on multiple basic tasks as a teacher, TAGI constructs task-specific models by aligning the labels, output logits, and adapter parameters between teacher and student models. To improve compliance with task instructions and the efficacy of weight generation, TAGI undergoes a two-stage hypernetwork training process: hypernetwork pretraining and finetuning. a-c are random divisions of the sampled sentences from pretraining datasets.", "description": "This figure illustrates the overall architecture of the Task Adapters Generation from Instructions (TAGI) model.  It shows a two-stage training process: hypernetwork pretraining and finetuning. The hypernetwork takes instructions as input and generates task-specific adapters, which are then integrated into a vanilla language model (LLM). The resulting model is trained on instances of multiple basic tasks, acting as the 'teacher'. A student model is constructed by aligning the labels, output logits, and adapter parameters of the teacher and student models. This alignment enhances compliance with task instructions and improves the efficiency of weight generation. The figure highlights the process of converting instructions into parameter-efficient modules (LoRA) and shows the two-stage hypernetwork training process for improved compliance with task instructions and more efficient weight generation.", "section": "3.2 Task Adapters Generation from Instructions (TAGI)"}, {"figure_path": "CluvZBfrjj/figures/figures_16_1.jpg", "caption": "Figure 2: Overview of TAGI. The hypernetwork takes instruction as input and generates adapters subsequently integrated into the vanilla LLM, and constructed the task-specific model as student. After training the task models through instances on multiple basic tasks as a teacher, TAGI constructs task-specific models by aligning the labels, output logits, and adapter parameters between teacher and student models. To improve compliance with task instructions and the efficacy of weight generation, TAGI undergoes a two-stage hypernetwork training process: hypernetwork pretraining and finetuning. a-c are random divisions of the sampled sentences from pretraining datasets.", "description": "This figure illustrates the overall architecture of the Task Adapters Generation from Instructions (TAGI) model.  It shows a two-stage training process:  First, a hypernetwork is pre-trained on general text data and then fine-tuned using a knowledge distillation technique.  During fine-tuning, the hypernetwork learns to generate task-specific adapters (LoRA modules) from instructions.  These adapters are integrated into a vanilla language model (LLM) to create a task-specific student model. The student model's parameters are aligned with those of a teacher model trained on instances, to ensure consistency. This alignment is performed for labels, output logits, and adapter parameters. The entire process aims to improve the efficiency of adapting the LLM to unseen tasks by leveraging instructions rather than extensive instance-level training.", "section": "3.2 Task Adapters Generation from Instructions (TAGI)"}]