[{"figure_path": "MP7j58lbWO/figures/figures_1_1.jpg", "caption": "Figure 1: Overview of the paradigm for bias probing experimental design.", "description": "This figure illustrates the experimental design used in the study to investigate social bias in ChatGPT-generated job applications. Real job postings are fed into ChatGPT, which then generates job applications.  Both the original job postings and the generated applications are analyzed using the PRISM algorithm to measure bias scores. Finally, the correlation between bias scores of the job postings and the generated applications is calculated to determine if and how biases are reproduced or amplified by the model.", "section": "1 Introduction"}, {"figure_path": "MP7j58lbWO/figures/figures_3_1.jpg", "caption": "Figure 2: An illustration of the paradigm for PRISM that uses word lists for directional cues with MLM to compute bias score for text.", "description": "This figure illustrates the PRISM algorithm's workflow.  It starts with a text input which is then processed by masking each word sequentially.  A Masked Language Model (MLM), such as BERT, predicts the probability of different words replacing the masked word. The probabilities for masculine and feminine words from predefined lists are extracted.  These probabilities are merged, ranked, and then used to calculate a bias score. A positive score indicates masculine bias, while a negative score indicates feminine bias.", "section": "3 Bias Evaluation Algorithm for Text"}, {"figure_path": "MP7j58lbWO/figures/figures_7_1.jpg", "caption": "Figure 3: Result scatter density plot, for each of the bias dimensions where the x-axis is the job posting bias score and the y-axis is the job applications bias score. Where the darker color means there are more dots. The p-value is the significance of the correlation coefficient.", "description": "This figure shows the correlation between bias scores in job postings and the corresponding job applications generated by ChatGPT.  Each subplot represents one of four dimensions of gender bias (Psychological Cues, Role Description, Work-Family Characteristics, Social Characteristics).  The x-axis represents the bias score of the job posting, and the y-axis represents the bias score of the generated application. The density of points illustrates the strength of the correlation, with darker areas indicating more data points and thus a stronger correlation.  A red line represents the linear regression fit; its slope indicates the degree to which bias in the posting is reproduced in the application.  The correlation coefficient and p-value are provided for each dimension.", "section": "5.2 Correlation Analysis"}, {"figure_path": "MP7j58lbWO/figures/figures_13_1.jpg", "caption": "Figure 4: Algorithm Validation", "description": "This figure shows the results of algorithm validation using two different methods: human expert validation and benchmark validation. The left panel (a) displays the correlation between human expert ratings and algorithm scores, showing a strong positive correlation (r = 0.85). The right panel (b) presents the receiver operating characteristic (ROC) curves comparing the algorithm's performance against three baseline methods for classifying gender bias in text. The algorithm (PRISM) significantly outperforms the baselines, with an area under the curve (AUC) of 0.97, while the baselines range from 0.91 to 0.93.", "section": "3.4 Algorithm Validation"}, {"figure_path": "MP7j58lbWO/figures/figures_14_1.jpg", "caption": "Figure 3: Result scatter density plot, for each of the bias dimensions where the x-axis is the job posting bias score and the y-axis is the job applications bias score. Where the darker color means there are more dots. The p-value is the significance of the correlation coefficient.", "description": "This figure shows the correlation between bias scores in job postings and corresponding job applications generated by ChatGPT across four dimensions of gender bias (Psychological Cues, Role Description, Work-Family Characteristics, and Social Characteristics). Each scatter plot visualizes the relationship, with the x-axis representing the bias score of the job posting and the y-axis representing the bias score of the generated job application. The density of points indicates the concentration of data points in specific regions, while the correlation coefficient and its p-value (significance level) quantify the strength and statistical significance of the linear relationship between the two sets of bias scores for each dimension. The plots illustrate whether the biases present in job postings are mirrored or amplified in the AI-generated applications.", "section": "5.2 Correlation Analysis"}, {"figure_path": "MP7j58lbWO/figures/figures_16_1.jpg", "caption": "Figure 3: Result scatter density plot, for each of the bias dimensions where the x-axis is the job posting bias score and the y-axis is the job applications bias score. Where the darker color means there are more dots. The p-value is the significance of the correlation coefficient.", "description": "This figure shows the correlation between bias scores in job postings and the corresponding job applications generated by ChatGPT, for four different dimensions of gender bias: Psychological Cues, Role Description, Work-Family Characteristics, and Social Characteristics. Each scatter plot displays the relationship between the bias scores of the job postings (x-axis) and the job applications (y-axis). The density of points is represented by color intensity, with darker shades indicating a higher concentration of data points. A regression line is fitted to each scatter plot, showing the correlation strength. The p-value for each correlation is also provided, indicating the statistical significance of the relationship.", "section": "5.2 Correlation Analysis"}, {"figure_path": "MP7j58lbWO/figures/figures_16_2.jpg", "caption": "Figure 3: Result scatter density plot, for each of the bias dimensions where the x-axis is the job posting bias score and the y-axis is the job applications bias score. Where the darker color means there are more dots. The p-value is the significance of the correlation coefficient.", "description": "This figure shows scatter plots illustrating the correlation between bias scores in job postings and those in ChatGPT-generated job applications for four different dimensions of gender bias (Psychological Cues, Role Description, Work-Family Characteristics, and Social Characteristics). Each plot visualizes the relationship between the bias scores of job postings (x-axis) and the corresponding job applications (y-axis). Darker colors indicate a higher density of points.  The correlation coefficient and p-value for each dimension are displayed on the plot, indicating the strength and statistical significance of the correlation. The slope of the fitted line shows how strongly the job posting bias predicts the bias in the job applications.", "section": "5 Analysing the Bias inside ChatGPT"}, {"figure_path": "MP7j58lbWO/figures/figures_17_1.jpg", "caption": "Figure 8: Human Label Evaluation Correlation", "description": "This figure shows the correlation between human expert labels and the bias scores generated by the algorithm for two different language models: distilBERT and BERT-large.  The scatter plots visually represent the agreement between human judgment of gender bias in texts and the algorithm's assessment.  The correlation coefficient (r) is provided for each model, indicating the strength of the relationship.  Higher correlation indicates better agreement between human assessment and the algorithm.", "section": "Algorithm Validation"}, {"figure_path": "MP7j58lbWO/figures/figures_17_2.jpg", "caption": "Figure 4: Algorithm Validation", "description": "This figure shows the results of two algorithm validation tasks.  Figure 4(a) displays a scatter plot illustrating the strong positive correlation (r=0.85) between human expert bias scores and the PRISM algorithm's bias scores on a randomly selected subset of job advertisements. This demonstrates that PRISM effectively captures human perception of bias. Figure 4(b) presents the receiver operating characteristic (ROC) curve for the algorithm's performance on the BIOS dataset, achieving an AUC of 0.97, exceeding the performance of three baseline methods (weighted average, gender max, and unigram score). This validates PRISM's effectiveness in identifying gender bias in text.", "section": "3.4 Algorithm Validation"}]