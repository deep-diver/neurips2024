{"references": [{"fullname_first_author": "A. Dosovitskiy", "paper_title": "An image is worth 16x16 words: Transformers for image recognition at scale", "publication_date": "2021-00-00", "reason": "This paper introduces the Vision Transformer (ViT), a foundational model for the current work, and is the basis of the MoNE architecture."}, {"fullname_first_author": "A. Arnab", "paper_title": "Vivit: A video vision transformer", "publication_date": "2021-00-00", "reason": "This paper extends the ViT model to video processing, providing the foundation for the work on video data."}, {"fullname_first_author": "N. Shazeer", "paper_title": "Switch transformers: Scaling to trillion parameter models with simple and efficient sparsity", "publication_date": "2022-00-00", "reason": "This paper introduces the concept of Switch Transformers, a Mixture of Experts (MoE) model that relates to the MoNE approach for scalable and efficient computation."}, {"fullname_first_author": "W. Fedus", "paper_title": "Switch transformers: Scaling to trillion parameter models with simple and efficient sparsity", "publication_date": "2022-00-00", "reason": "This paper introduces the concept of Switch Transformers, a Mixture of Experts (MoE) model that relates to the MoNE approach for scalable and efficient computation."}, {"fullname_first_author": "Devvrit", "paper_title": "Matformer: Nested transformer for elastic inference", "publication_date": "2023-10-00", "reason": "This paper introduces the concept of nested models, which is a key component of the MoNE architecture and shares a similar training strategy."}]}