[{"figure_path": "HbV5vRJMOY/tables/tables_7_1.jpg", "caption": "Table 1: Real Time Latency and Throughput gains for MoNE on a single V100 GPU", "description": "This table presents a comparison of real-time performance between the baseline ViViT-FE-B/16 model and the MoNE model (with effective capacity ec=0.3) on a single V100 GPU.  It shows the FLOPs (floating-point operations), throughput (clips processed per second), latency (processing time in milliseconds), and top-1 accuracy for each model.  The results highlight that MoNE achieves significant gains in both throughput and latency while maintaining a comparable accuracy level compared to the ViViT model. This demonstrates the efficiency improvement introduced by MoNE.", "section": "5 Results"}, {"figure_path": "HbV5vRJMOY/tables/tables_9_1.jpg", "caption": "Table 2: SSv2 Performance of different capacity distribution methods", "description": "This table compares the performance of different capacity distribution methods for the Something-Something-v2 (SSv2) dataset.  The methods are categorized into static and dynamic budget allocation.  Static methods assign a fixed capacity to each expert, while dynamic methods allow for changes based on the input.  The results show the effective capacity (ec) and accuracy achieved by each method. MoNE (Mixture of Nested Experts) outperforms other methods, showing the advantages of dynamic capacity allocation.", "section": "7 Conclusion"}, {"figure_path": "HbV5vRJMOY/tables/tables_14_1.jpg", "caption": "Table 3: MONE Comparison on ImageNet-1K with other Adaptive Baselines", "description": "This table compares the performance of the proposed MoNE model against other adaptive baselines on the ImageNet-1K dataset.  It shows the FLOPs (floating-point operations), throughput (in clips per second), and Top-1 accuracy for each model.  The comparison highlights MoNE's ability to achieve comparable or better accuracy with significantly lower computational cost and higher throughput than other methods.", "section": "5 Results"}]