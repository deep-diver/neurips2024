[{"type": "text", "text": "Pricing and Competition for Generative AI ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Rafid Mahmood NVIDIA & University of Ottawa rmahmood@nvidia.com ", "page_idx": 0}, {"type": "text", "text": "Abstract ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Compared to classical machine learning (ML) models, generative models offer a new usage paradigm where (i) a single model can be used for many different tasks out-of-the-box; (ii) users interact with this model over a series of natural language prompts; and (iii) the model is ideally evaluated on binary user satisfaction with respect to model outputs. Given these characteristics, we explore the problem of how developers of new generative AI software can release and price their technology. We first develop a comparison of two different models for a specific task with respect to user cost-effectiveness. We then model the pricing problem of generative AI software as a game between two different companies who sequentially release their models before users choose their preferred model for each task. Here, the price optimization problem becomes piecewise continuous where the companies must choose a subset of the tasks on which to be cost-effective and forgo revenue for the remaining tasks. In particular, we reveal the value of market information by showing that a company who deploys later after knowing their competitor\u2019s price can always secure cost-effectiveness on at least one task, whereas the company who is the first-to-market must price their model in a way that incentivizes higher prices from the latecomer in order to gain revenue. Most importantly, we find that if the different tasks are sufficiently similar, the first-to-market model may become cost-ineffective on all tasks regardless of how this technology is priced. ", "page_idx": 0}, {"type": "text", "text": "1 Introduction ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "The recent explosion of generative artificial intelligence (AI) has introduced new machine learning (ML) frameworks for applications from chatbots to robotics [Wu et al., 2023, Nasiriany et al., 2024]. Whereas in classical ML, a user interacted with a single model designed for a specific predictive task (e.g., classification) via input data and output predictions, a single generative AI model can solve a variety of tasks for a user out-of-the-box [Brown et al., 2020]. Moreover, users interact with the generative model over a universal interface of natural language prompting [Arora et al., 2022]. ", "page_idx": 0}, {"type": "text", "text": "The prompt-based paradigm has fostered two recent human-AI interaction trends. First, prompting facilitates such a wide distribution of tasks (i.e., user inputs and model outputs) that conventional metrics for evaluating models have become insufficient, leaving the most effective evaluation metric to be a binary score of whether the user is satisfied with the model output [Li et al., 2024, Chiang et al., 2024]. For example, Ziegler et al. [2024] empirically analyzed the GitHub Copilot software to reveal that the frequency of generated code approved by a user \u2018is a better predictor of perceived [user] productivity than alternative measures.\u2019 Second, if a user does not receive a satisfactory output, they can try again in another prompting round by inputting to the model additional information [Castro et al., 2023]. For instance, the Anthropic HH and the Chatbot Arena datasets report on average 2.3 and 1.3 prompting rounds per conversation, respectively [Bai et al., 2022, Chiang et al., 2024]. ", "page_idx": 0}, {"type": "text", "text": "In this work, we study the impact of these interaction characteristics on the pricing of generative AI technology. While classical ML products can be priced by analyzing the user demand for a model that can achieve a given performance metric on a specific task [Gurkan and de V\u00e9ricourt, 2022, Mahmood et al., 2022], a generative AI model is priced per user prompt 1. This set price determines the user cost for multiple different tasks and variable number of prompting rounds, e.g., the cost of using GPT-4 for math reasoning or code generation depends only on the per-token price, and the length and number of prompts. Thus, developers of a generative AI product must factor the demand for all potential use-case tasks of the technology when setting a price. This pricing problem becomes further challenging when considering the rapidly growing marketplace of competing generative AI models, since companies must also ensure that their products do not become unattractive to users as soon as a competitor develops a newer and better model. ", "page_idx": 0}, {"type": "image", "img_path": "8LbJfEjIrT/tmp/2a9814c8f13eb15b1cb1d5ad476948f13a4f0b64cb56f0118d687acd508d9356.jpg", "img_caption": ["Figure 1: Overview of the competitive pricing problem for generative AI models. "], "img_footnote": [], "page_idx": 1}, {"type": "text", "text": "", "page_idx": 1}, {"type": "text", "text": "We first characterize when, for a given task, a user will prefer one generative AI model versus another. We argue that users minimize their total cost, measured by the cost-per-prompt times the number of prompting rounds needed for the model to produce a satisfactory output; this leads to a comparison of price-performance competitiveness between AI models. We then study a game with two firms developing competing models used for a set of tasks. Both firms know each other\u2019s model\u2019s performance on the tasks. The first firm deploys their product and sets a price, followed by the second firm with their product and price. Finally, a user decides which models to use for each task. Both firms seek to maximize revenue, but the first firm acts without knowledge of their competitor\u2019s price. Figure 1 summarizes the problem setting and insights. Our key observations include: ", "page_idx": 1}, {"type": "text", "text": "1. The pricing problem reduces to a piecewise optimization problem, where firms price their model to be competitive on a subset of the tasks while forgoing revenue from the others. This subset can be determined by ranking the tasks on the competitive ratio between the two models for each task and selecting the most competitive tasks. ", "page_idx": 1}, {"type": "text", "text": "2. A firm who deploys late always obtains revenue from at least one task by leveraging the available market information. In contrast, the first-to-market must strategically set their prices to encourage the latecomer to set higher prices and focus on fewer tasks.   \n3. Under certain conditions on model performance and user demand, the first-to-market may acquire zero revenue regardless of their price. In these settings, the latecomer naturally maximizes their revenue by being competitive for all tasks. Thus, developers that are first should have a minimum model performance before deploying their product. ", "page_idx": 1}, {"type": "text", "text": "2 Related literature ", "text_level": 1, "page_idx": 1}, {"type": "text", "text": "Evaluating ML models. ML models are typically evaluated on generalization error for a task via out-of-sample test dataset benchmarks and competitions [Deng et al., 2009]. Generative AI and large language models (LLMs) are evaluated on a suite of benchmark tasks such as for coding [Chen et al., 2021], math [Cobbe et al., 2021], and problem solving [Hendrycks et al., 2021]. However, standardized benchmarks become uninformative over time as new models are trained to overfit to these metrics [Roelofs et al., 2019, Koch et al., 2021]. Recently, Chiang et al. [2024] introduced the Chatbot Arena for comparing LLMs head-to-head on human preference. Here, a user poses a real-world prompt which is input to two models. The user reviews both model outputs and can even continue multiple conversation rounds, before ranking which model generated a satisfactory answer first. Although difficult to measure, user satisfaction rate is increasingly viewed as the most informative metric as seen from generated code approvals on GitHub Copilot [Ziegler et al., 2024], or perceived aesthetic quality of text-to-image generation such as MidJourney and Playground [Li et al., 2024]. Our work combines user satisfaction with a user cost to construct a price-performance ratio for comparing different models. ", "page_idx": 1}, {"type": "text", "text": "Human-generative AI interaction. Prompt-based interaction has increased the diversity of tasks where these models can be applied [Eloundou et al., 2023]. Castro et al. [2023] analyze how and when human users will use a generative AI model for a task versus performing it manually, as well as the characteristics of interacting over multiple prompt rounds. The quality of prompts is crucial to generating higher-quality answers [Liu et al., 2023, Binz and Schulz, 2023]. This has motivated studies on prompt techniques, such as chain-of-thought [Wei et al., 2022] and self-consistency [Wang et al., 2022]. In our work, we treat prompt quality as a random variable and to simplify the structural analysis, assume that users will interact with a generative AI model for as many prompting rounds as needed to get a satisfactory answer. ", "page_idx": 2}, {"type": "text", "text": "Pricing and competition. Duopolies of competitive products use game theoretic models such as the Bertrand (i.e., simultaneous pricing) and Stackelberg (i.e., sequential pricing) models of interaction [Gibbons, 1992]. Both deterministic and probabilistic demand can be used to study oligopolistic pricing of a single or multiple products Chintagunta and Rao [1996], Gallego and Hu [2014]. Specific structured demand frameworks allow for identifying market equilibria and failure settings where revenue is unobtainable [Federgruen and Hu, 2015, 2019]. Our work is most closely related to the Stackelberg literature by modeling a sequential game and exploring the conditions under exponential demand that make certain generative AI models unattractive [Hamilton and Slutsky, 1990]. ", "page_idx": 2}, {"type": "text", "text": "Pricing AI products. AI technology can be priced at various levels, ranging from training data to model queries [Liu et al., 2021, Chen et al., 2019, Cong et al., 2022]. A core aspect of the pricing problem involves valuating the ML model based on performance [Xu et al., 2024]. ML products are further susceptible to an AI flywheel effect where the release and price of an AI product will affect the subsequent collection of new training data from users, leading to a dynamic pricing problem [Gurkan and de V\u00e9ricourt, 2022, Chen and Xue, 2023]. More generally, novel technology products such as a new generative AI model with emergent use-cases may feature social-learning and dynamically growing market sizes [Feldman et al., 2019, Zhang et al., 2022]. The closest to our work is Gurkan and de V\u00e9ricourt [2022] who explore pricing and contracting the development of a classical ML model under the AI flywheel. In contrast, our work explores competition between ML model developers when faced with a diverse set of potential downstream tasks for which the model can be used. ", "page_idx": 2}, {"type": "text", "text": "3 Main model ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "We first define the characteristics of the pricing problem. We then propose a model of user choice between two competing models from a price-performance perspective. ", "page_idx": 2}, {"type": "text", "text": "3.1 Problem setup ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "Tasks. We define a task as a set of independent problem instances where for each instance, a user queries a machine learning model with an input prompt and receives an output generated the model. For example, a programming task may have instances where a user inputs a commented function definition and the model must complete the code to perform the function Chen et al. [2021], Ziegler et al. [2024]. Task instances are evaluated by a user via a binary correctness score. For tasks where correctness is unambiguous (e.g., whether the program runs), the score is equivalent to accuracy, whereas for open-ended tasks (e.g., whether the output meets the stylistic preferences of the user), we treat correctness simply as whether the user is satisfied with the output 2 ", "page_idx": 2}, {"type": "text", "text": "Generative AI model. Given a set of $T$ different tasks, a generative model is an ML model that can be used to solve instances of any of the different tasks via prompts. We define this model as a tuple $(p,V_{1},V_{2},\\ldots,V_{T})$ where $p$ denotes the price for using the model, as measured in dollars-per-prompt (see Appendix B for the extension to pricing per-token), and for each $t\\in[T]$ , $V_{t}\\in(0,1)$ denotes the average score of the model over instances of each task. We assume that $V_{t}\\to1$ implies that the model can always generate a correct output for any task instance and $V_{t}\\to0$ implies that the model will always generate an incorrect output. Therefore, for any random instance of task $t$ , $V_{t}$ can also be interpreted as a Bernoulli probability of the generative model producing a satisfactory output in a single attempt. ", "page_idx": 2}, {"type": "text", "text": "Users will not use the generative model if it\u2019s price is too high with respect to the user\u2019s valuation of the specific task. For any given task $t$ , let $D_{t}\\bar{(}p)\\in\\mathbb{R}_{+}$ be the demand function, i.e., the number of users who will use a generative AI model for task $t$ as a function of the price $p$ . Following standard assumptions, we assume that $D_{t}(p)$ is differentiable and non-increasing in the model price, as well as being known to the developer of the AI model [Gallego and Van Ryzin, 1994]. ", "page_idx": 3}, {"type": "text", "text": "Multi-round use. Most ML benchmarks typically evaluate models on whether the models can generate the correct output under a single prompt round [Chen et al., 2021, Cobbe et al., 2021, Hendrycks et al., 2021]. However, in-the-wild users of generative models typically have interactive multi-round conversations where if the model generates an unsatisfactory solution after the first prompt, the user can provide feedback via their preferences or corrections in a second prompt round [Castro et al., 2023, Liao et al., 2024]. For example in code completion, if the model fails to account for an edge-case input to the function, the user can identify the edge-case and ask the model to account for it. To characterize this multi-round use, we extend the single prompt to a sequence of Bernoulli trials that continue until the user is satisfied with the model output. For simplicity of modeling, we make the following assumptions on user behavior. ", "page_idx": 3}, {"type": "text", "text": "Assumption 1. The total number of prompting rounds $n_{t}(V_{t})$ that a user will engage with the model: (i) has a finite mean; and (ii) is independent of the model price p conditioned on the user knowing $V_{t}$ . ", "page_idx": 3}, {"type": "text", "text": "Assumption 1 implies that the price of a model only determines demand via whether the model is used at all, rather than how many times (i.e., prompting rounds) the model is used. Under this assumption, there are many choices for modeling the distribution of $n_{t}(V_{t})$ . We give three examples: ", "page_idx": 3}, {"type": "text", "text": "\u2022 Geometric: Because non-expert users tend to design uninformative prompts [ZamfirescuPereira et al., 2023], we may suppose the probability of success on any round does not depend on user input, and each round is an i.i.d. Bernoulli trial with probability $V_{t}$ . Then, the total number of rounds is $n_{t}\\sim\\mathrm{Geom}(V_{t})$ , following a Geometric distribution. \u2022 Truncated Geometric: Users may quit the model after a maximum $T_{t}$ rounds if it fails to generate a satisfactory response [Castro et al., 2023]. For instance, conversations in the Chatbot Arena dataset terminate after an average 1.3 rounds [Chiang et al., 2024]. Here, $\\operatorname*{Pr}\\{n_{t}=n\\}:=(1-V_{t})^{n-1}V_{t}$ for $1\\leq n<T_{t}$ and $\\operatorname*{Pr}\\{n_{t}=\\bar{T}_{t}\\}:=\\bar{(1-V_{t})}^{T_{t}-1}$ . \u2022 Prompt-dependent: Suppose the success probability is prompt-dependent $V_{t}(x_{i})$ where $x_{i}\\sim\\operatorname{Pr}\\{\\bar{x}\\}$ is the prompt on the $i$ -th round. If users prompt until the model generates a satisfactory answer, we have $\\begin{array}{r}{\\operatorname*{Pr}\\{n_{t}=n\\}:=\\mathbb{E}_{x_{1},\\cdots,x_{n}}\\overset{\\cdot}|V_{t}(\\bar{x_{n}})\\prod_{i=1}^{n-1}(1-V_{t}(\\bar{x_{i}}))],}\\end{array}$ . ", "page_idx": 3}, {"type": "text", "text": "Ultimately, the choice of characterizing $n_{t}$ depends on the information available to the generative AI model provider. With limited information, the Geometric assumption may be most practical, but given knowledge of user prompts, we may consider more sophisticated models. Our results all hold independent of the distribution as long as Assumption 1 is satisfied. For ease of notation and interpretability, we assume $n_{t}\\sim\\mathrm{Geom}(V_{t})$ in the remainder of this work. ", "page_idx": 3}, {"type": "text", "text": "3.2 Modeling user preference between AI models ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "Given the above task and user behavior framework, we analyze the problem of a user who must choose between two competing generative models to solve instances of their tasks. Since a user may prefer different models for different tasks, we consider a single task and omit subscript $t$ . ", "page_idx": 3}, {"type": "text", "text": "Consider two generative models: model A $(q,W)$ and model B $(p,V)$ . Under Assumption 1, given a sufficient number of prompt rounds, both models can eventually solve every task instance. Thus, a rational user will seek to minimize the expected cost of completing a task instance, measured by the average price-per-prompt times the expected number of rounds required to complete the task instance. In this comparison, model B will incur a lower cost for the user if ", "page_idx": 3}, {"type": "equation", "text": "$$\np\\mathbb{E}[n(V)]\\leq q\\mathbb{E}[n(W)]\\implies\\~\\frac{p}{V}\\leq\\frac{q}{W}.\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "Otherwise, model A incurs lower user costs. We assume that model $\\mathbf{B}$ is preferred in ties. Note that the implication follows from our Geometric assumption of $n(V)$ . ", "page_idx": 3}, {"type": "text", "text": "Condition (1) states that for any task, a specific generative AI model is preferred if the priceperformance ratio for this task (i.e., the cost of using this model over the model\u2019s performance) is lower than any other competing generative model. For example, if model B is twice as likely to generate a user-satisfactory output as model A for a given input prompt, i.e., $V\\,=\\,2W$ , then the user will prefer model B as long the cost of prompting this model is not twice as high, i.e., $p\\leq2q$ . Otherwise, the user will incur lower costs and still obtain their desired outputs by simply prompting the weaker model for twice as many rounds. ", "page_idx": 3}, {"type": "text", "text": "", "page_idx": 4}, {"type": "text", "text": "We note that (1) can also compare the use of a generative AI model versus manually performing the task [Castro et al., 2023]. For instance, if we treat model B as a human and a prompt round as a timed attempt at completing a task (e.g., coding the function within one hour), then $V$ is the probability of a human being able to perform the task in the single attempt and $p$ is the time-value of this labor. ", "page_idx": 4}, {"type": "text", "text": "Finally, this framework can also compare free-to-use generative AI models such as LLaMA [Touvron et al., 2023]. Although there may not be a given price-per-token for using these models, there is a fixed cost to set up the infrastructure and environment. Given an expected total number of task instances, this fixed cost can be approximated to an equivalent $p$ . ", "page_idx": 4}, {"type": "text", "text": "4 Pricing generative AI models ", "text_level": 1, "page_idx": 4}, {"type": "text", "text": "We now develop a general framework under which a provider of a generative AI model can price their product. We first define the pricing problem as a game between two firms developing competing generative AI models. We then create tractable reformulations for these problems for both firms, representing pricing with and without considering competition. ", "page_idx": 4}, {"type": "text", "text": "Pricing problem. Consider a set of $T$ tasks. Let $(q,W_{1},W_{2},\\ldots,W_{T})$ and $(p,V_{1},V_{2},\\ldots,V_{T})$ be the generative models released by two competing firms, A and B, respectively. Firm A deploys their generative AI model (i.e., model A) first and sets the price $q$ for this product. Then, firm B deploys their competing model (i.e., model B) and sets their price $p$ . After both firms deploy their models, a user with demand functions $D_{t}(\\cdot)$ for each $t$ will decide which models to use as determined by (1). We evaluate the total revenue obtained by each firm, given by $R_{A}(q|p)$ and $R_{B}(p|q)$ respectively: ", "page_idx": 4}, {"type": "equation", "text": "$$\nR_{A}(q|p):=q\\sum_{t=1}^{T}D_{t}(q)\\mathbb{1}\\left\\{{\\frac{q}{W_{t}}}<{\\frac{p}{V_{t}}}\\right\\}\\qquad\\;R_{B}(p|q):=p\\sum_{t=1}^{T}D_{t}(p)\\mathbb{1}\\left\\{{\\frac{p}{V_{t}}}\\leq{\\frac{q}{W_{t}}}\\right\\}.\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "Note that in practice, the user demand may depend on $p$ and $q$ simultaneously; for simplicity, we assume the demand for a specific model to be determined only after the user preference condition (1) is resolved. The results in this section easily generalize to more complex demand functions. The revenue functions are composed of the demand for each task times the price set by the firm [Van Ryzin and Talluri, 2005], summed over all tasks for which the firm\u2019s model is competitive according to the price-performance ratios. Each firm\u2019s objective is to maximize their revenue. However, because firm A is the first-to-market and they do not know the action that firm B will take; instead, firm A must optimize for the worst-case scenario as determined by firm B. On the other hand, firm B first observes the price set by firm A. Thus, the two firms set prices as follows: ", "page_idx": 4}, {"type": "equation", "text": "$$\nq^{*}:=\\operatorname*{arg\\,max}_{q\\geq0}\\;\\left\\{R_{A}(q|\\hat{p})\\;|\\;\\hat{p}\\in\\arg\\operatorname*{max}{R_{B}(p|q)}\\right\\}\\quad\\quad\\quad p^{*}:=\\operatorname*{arg\\,max}_{p\\geq0}\\;\\left\\{R_{B}(p|q^{*})\\right\\}.\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "We assume both firms know $V_{t}$ and $W_{t}$ for all $t\\,\\in\\,[T]$ . This is motivated by the availability of research papers and reported benchmark scores, and the predictability of model performance via power laws [Kaplan et al., 2020]. In practice, a firm may not know their competitor\u2019s performance, but they can forecast the state-of-the-art score in the short term. ", "page_idx": 4}, {"type": "text", "text": "4.1 Pricing in isolation ", "text_level": 1, "page_idx": 4}, {"type": "text", "text": "We first consider firm B\u2019s problem, who set their price after firm A has already released a competing model with price $q^{*}$ . Firm B\u2019s problem depends on the competitive ratio $\\kappa_{t}:=\\mathbb{E}[n(W_{t})]/\\mathbb{E}[n(V_{t})]$ for task $t\\in[T]$ , i.e., the relative ratio of number of prompting rounds between the two firms, which under a Geometric distribution assumption, simplifies to $\\kappa_{t}:=V_{t}/W_{t}$ . To maximize their revenue, firm B can rank the tasks in order of $\\kappa_{t}$ , select a subset of tasks in this order, and solve the optimization problem for each subset. This results in an overall piecewise optimization problem. ", "page_idx": 4}, {"type": "image", "img_path": "8LbJfEjIrT/tmp/ca06170194aa594b2791d57ca30d7031d05bf18508c8230d99692285d4931325.jpg", "img_caption": ["Figure 2: (Left) Three tasks with three different exponential demand functions $D_{1}(p)=100e^{-0.5p}$ , $\\bar{D_{2}}(p)=20\\dot{0}e^{-0.5p}$ , $D_{3}(p)=400e^{-0.5p}$ . (Right) The corresponding revenue from each task along with the total revenue function for a firm $R_{B}(p)$ . The vertical lines correspond to $\\kappa_{1}q,\\,\\kappa_{2}q$ , and $\\kappa_{3}q$ , where $\\kappa_{1}>\\kappa_{2}>\\kappa_{3}$ . For $p<\\kappa_{3}q$ , revenue is obtained from all three tasks, for $p\\in(\\kappa_{3}q,\\kappa_{2}q]$ , revenue is obtained from only the first two tasks, and for $p\\in(\\kappa_{2}q,\\kappa_{1}q]$ , revenue is only obtained from the first task. No revenue can be obtained if $p>\\kappa_{1}q$ . "], "img_footnote": [], "page_idx": 5}, {"type": "text", "text": "Theorem 1. Consider the following ordering $\\sigma:[T+1]\\to[T+1]$ for which ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\kappa_{\\sigma(1)}>\\kappa_{\\sigma(2)}>\\cdots>\\kappa_{\\sigma(T)}>\\kappa_{\\sigma(T+1)}:=0.\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "Then, firm B\u2019s pricing problem is equivalent to the piecewise optimization problem: ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\operatorname*{max}_{t\\in[T]}\\,\\operatorname*{max}_{p}\\,\\left\\{p\\sum_{s=1}^{t}D_{\\sigma(s)}(p)\\ \\bigg|\\ \\kappa_{\\sigma(t)}\\geq\\frac{p}{q}>\\kappa_{\\sigma(t+1)}\\right\\}.\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "Theorem 1 shows that a generative AI model should be priced by prioritizing a subset of the tasks and making the model price-performance competitive for those tasks only. Consequently, the firm ignores the remaining tasks for which the model has low competitive ratios $\\kappa_{t}$ , since they would need extremely low prices in order to satisfy (1) for these tasks. This strategy is due to the observation that for any task $\\sigma(t)$ , if a model satisfies (1), then the model will also satisfy the condition for all $\\sigma(t^{\\prime})$ for $t^{\\prime}\\leq t$ . Furthermore, Theorem holds without loss of generality with respect to the strict inequalities on (4), since tasks with the same competitive ratios can be grouped together by summing the constituent demand functions. Finally, Theorem 1 holds for arbitrary demand functions. In practice, the demand functions are known and typically have a parametric structure. Figure 2 gives an example using three tasks with demand that decays exponentially with price. ", "page_idx": 5}, {"type": "text", "text": "Theorem 1 reveals two key implications on how a firm can price a generative mode when given competitor information. First, pricing reduces to solving $T$ optimization problems, where each of these problems are of a single variable with a differentiable objective and boundary constraints. Thus, the inner problems can be solved via gradient descent. Second, as long as firm B sets a price $p\\le\\kappa_{\\sigma(1)}$ , they will obtain some non-zero revenue, i.e., problem (5) always has a feasible solution. This advantage is due to the fact that firm B sets their price given a fixed $q$ . ", "page_idx": 5}, {"type": "text", "text": "4.2 Pricing when accounting for competition ", "text_level": 1, "page_idx": 5}, {"type": "text", "text": "We next consider firm A\u2019s problem of setting a problem while assuming that firm B will act optimally next. This pricing problem is a bi-level optimization problem, but it can be solved by ranking the tasks according to the competitive ratios for firm A and prioritizing a subset of these tasks. ", "page_idx": 5}, {"type": "text", "text": "Theorem 2. Firm A\u2019s pricing problem is equivalent to the piecewise bi-level optimization problem: ", "page_idx": 6}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\underset{t\\in[T-1]}{\\operatorname*{max}}\\ \\underset{{q\\geq0}}{\\operatorname*{max}}}&{q\\underset{s=t+1}{\\overset{T}{\\sum}}D_{\\sigma(s)}(q)}\\\\ {\\mathrm{s.t.}\\ \\ \\ \\underset{p}{\\operatorname*{max}}\\left\\{p\\underset{s=1}{\\overset{t}{\\sum}}D_{\\sigma(s)}(p)\\ \\Bigg|\\ \\kappa_{\\sigma(t)}\\geq\\frac{p}{q}>\\kappa_{\\sigma(t+1)}\\right\\}}\\\\ &{\\qquad\\qquad\\geq\\underset{p^{\\prime}}{\\operatorname*{max}}\\left\\{p\\underset{s=1}{\\overset{t^{\\prime}}{\\sum}}D_{\\sigma(s)}(p^{\\prime})\\ \\Bigg|\\ \\kappa_{\\sigma(t^{\\prime})}\\geq\\frac{p^{\\prime}}{q}>\\kappa_{\\sigma(t^{\\prime}+1)}\\right\\}\\ \\ \\ \\forall t^{\\prime}\\neq t}\\end{array}\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "Theorem 2 relies on the observation that the reverse order of $\\sigma(\\cdot)$ in (4) cn rank the most to least competitive tasks for firm A. For any t, if q < p \u03ba\u03c3\u2212(1t), then model A is price-performance competitive for all tasks $\\sigma(t),\\cdot\\cdot\\cdot,\\sigma(T)$ and firm A will acquire revenue from all these tasks. ", "page_idx": 6}, {"type": "text", "text": "Firm A may not always be able to obtain revenue. Problem (6) is infeasible if for every $t\\in[T-1]$ , there is no $q\\geq0$ that satisfies the bi-level constraint. This infeasibility implies for any $q\\geq0$ , firm B always maximizes their revenue by setting a low price $p\\leq\\kappa_{\\sigma(T)}q$ . Thus, the key motivation of firm A is that the firm benefits only when their competitor is incentivized to set high prices. ", "page_idx": 6}, {"type": "text", "text": "5 Structural analysis under exponential demand ", "text_level": 1, "page_idx": 6}, {"type": "text", "text": "Demand is typically modeled via structured parametric functions [Van Ryzin and Talluri, 2005]. In this section, we specialize the pricing problem to the standard choice of exponentially decaying parametric demand to extend the previous general results. See Figure 2 (Left) for an example. ", "page_idx": 6}, {"type": "text", "text": "Assumption 2. For each task $t,$ , the demand function decays exponentially in price $D_{t}(p)\\;:=\\;$ $a_{t}\\exp(-b p)$ , where $a_{t}>0$ is the zero-price base demand and $b>0$ is the price-sensitivity of users. Furthermore, all tasks have the same price-sensitivty. ", "page_idx": 6}, {"type": "text", "text": "Under the exponential demand model, the demand for each task $t$ is equal to $a_{t}$ when $p=0$ , and decays at a rate $-b$ . We assume that the decay rate is the same for each task; this is motivated by the practical consideration that the different tasks should have relatively similar \u2018user value\u2019 to have the same price. If one task is uniquely price-sensitive to users, the firm may instead develop a finetuned model for that task or propose incentives such as task-specific discounts to better optimize revenue. ", "page_idx": 6}, {"type": "text", "text": "Below, we revisit both firm B\u2019s and firm A\u2019s problems under this demand model to derive globally optimal solutions and structural insights on the market dynamics. ", "page_idx": 6}, {"type": "text", "text": "5.1 Pricing in isolation under exponential demand ", "text_level": 1, "page_idx": 6}, {"type": "text", "text": "Under Assumption 2, firm B\u2019s problem (5) now simplifies to the maximum of up to $T$ possible values that are the globally optimal solution to each of the individual inner optimization problems. ", "page_idx": 6}, {"type": "text", "text": "Theorem 3. Suppose Assumption 2 holds. For any $t_{\\perp}$ , let $\\begin{array}{r}{\\bar{a}_{\\sigma(t)}\\,:=\\,\\sum_{s=1}^{t}a_{\\sigma(t)}}\\end{array}$ . Without loss of generality, let $t^{*}\\in[T]$ be the task index that satisfies $\\kappa_{\\sigma(t^{*})}q\\geq1/b>\\kappa_{\\sigma(t^{*}+1)}q$ . Then, firm $B\\,\\mathbf{\\dot{\\boldsymbol{s}}}$ pricing problem is equivalent to the following maximum value: ", "page_idx": 6}, {"type": "equation", "text": "$$\n\\operatorname*{max}{\\left(\\operatorname*{max}_{t>t^{*}}\\left\\{\\kappa_{\\sigma(t)}q\\bar{a}_{\\sigma(t)}e^{-b\\kappa_{\\sigma(t)}q}\\right\\}\\ ,\\ \\frac{1}{b}\\bar{a}_{\\sigma(t^{*})}e^{-1}\\right)}\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "Theorem 3 states that problem (5) can be solved by by solving each of the inner problems starting from the lowest price range up until we arrive at the zero-gradient solution of the revenue function, i.e., $1/b$ . Furthermore, for each of the price ranges before this point, the optimal solution is the upper price boundary. Note that if $1/b\\,>\\,\\kappa_{\\sigma(1)}q$ , i.e., there does not exist any $t^{*}$ satisfying the condition, then we take the maximum of all $T$ problems. Figure 2 (Right) visualizes the revenue function $R_{B}(p|q)$ for $T=3$ tasks with exponential demand. Finally, this structure also reveals that the optimal price is bounded from both above and below via these optima. ", "page_idx": 6}, {"type": "text", "text": "Corollary 1. The optimal price for firm $B$ is bounded $1/b\\geq p^{*}\\geq\\kappa_{\\sigma(1)}q.$ . ", "page_idx": 6}, {"type": "image", "img_path": "8LbJfEjIrT/tmp/c2ce37ee60f57899e191c322f01c21c82d20b3ce21361d5610dad7aad52b67f1.jpg", "img_caption": ["Figure 3: The relationship between $\\kappa_{2}/\\kappa_{1}$ and $a_{1}/(a_{1}+a_{2})$ for firm A. In the blue region, firm B will always set a price that is competitive on both tasks and firm A will acquire zero revenue. In the orange region, the maximum price that firm A can set is upper bounded (see problem (11)). In the green region, the maximum price that firm A can set has a higher upper bound (see problem (10)). "], "img_footnote": [], "page_idx": 7}, {"type": "text", "text": "5.2 Pricing when accounting for competition under exponential demand ", "text_level": 1, "page_idx": 7}, {"type": "text", "text": "We now revisit firm A\u2019s pricing problem, which is a bi-level problem with multiple inner optimization constraints. To obtain structural insights on the challenges of pricing under competition, we explore a special case with $T=2$ tasks. Without loss of generality, we assume $\\kappa_{1}>\\kappa_{2}$ , i.e., $\\sigma(t)=t$ . ", "page_idx": 7}, {"type": "text", "text": "When there are only two tasks, firm B will either set their price to be competitive for the first task only (i.e., the task with the higher competitive ratio) or for both tasks. In the latter case, model A would be unattractive for both tasks and firm A would obtain zero revenue. Therefore, firm A should set their price in such a way that they maximize revenue on the second task, while ensuring that firm B is motivated to be competitive only for the first task. Thus, problem (6) simplifies to ", "page_idx": 7}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{}&{\\underset{q}{\\operatorname*{max}}\\ \\ q D_{2}(q)}\\\\ &{\\mathrm{s.t.}\\ \\underset{p}{\\operatorname*{max}}\\left\\{p D_{1}(p)\\ \\big|\\ \\kappa_{1}q\\geq p>\\kappa_{2}q\\right\\}>\\underset{p}{\\operatorname*{max}}\\left\\{p\\left(D_{1}(p)+D_{2}(p)\\right)\\ \\big|\\ \\kappa_{2}q\\geq p>0\\right\\}}\\end{array}\n$$", "text_format": "latex", "page_idx": 7}, {"type": "text", "text": "If firm A sets a price $q$ that is infeasible for this problem, they will get zero revenue. Furthermore, this problem reduces to two single-level optimization problems with only bounding constraints. ", "page_idx": 7}, {"type": "text", "text": "Theorem 4. Suppose that $T=2$ , that Assumption 2 holds, and without loss of generality, assume $\\sigma(t)=t$ . For $z\\in\\mathbb{R}$ , let $\\mathcal{W}(z)$ be the Lambert $\\mathcal{W}$ function defined only over $z>-e^{-1}$ . If ", "page_idx": 7}, {"type": "equation", "text": "$$\n\\frac{\\kappa_{2}}{\\kappa_{1}}\\leq-\\mathcal{W}\\left(-\\frac{a_{1}e^{-1}}{a_{1}+a_{2}}\\right)\n$$", "text_format": "latex", "page_idx": 7}, {"type": "text", "text": "then, the firm $A$ \u2019s pricing problem is equivalent to ", "page_idx": 7}, {"type": "equation", "text": "$$\n\\operatorname*{max}\\left\\{q a_{2}e^{-b q}\\ \\bigg|\\ -\\frac{1}{b\\kappa_{2}}\\mathcal{W}\\left(-\\frac{a_{1}e^{-1}}{a_{1}+a_{2}}\\right)\\geq q>0\\right\\}.\n$$", "text_format": "latex", "page_idx": 7}, {"type": "text", "text": "Otherwise, firm A\u2019s problem is equivalent to ", "page_idx": 7}, {"type": "equation", "text": "$$\n\\operatorname*{max}\\left\\{q a_{2}e^{-b q}\\,\\left\\vert\\,\\,\\frac1{b(\\kappa_{1}-\\kappa_{2})}\\left(\\log\\frac{\\kappa_{1}}{\\kappa_{2}}+\\log\\frac{a_{1}}{a_{1}+a_{2}}\\right)\\ge q>0\\right\\}.\n$$", "text_format": "latex", "page_idx": 7}, {"type": "text", "text": "Recall from Theorem 3, the second-level problems in (8) can be solved analytically by checking the boundary points and zero-gradient solution. Theorem 4 uses this property to map problem (8) to two sub-problems based on whether condition (9) holds. ", "page_idx": 7}, {"type": "text", "text": "Determining which problem to solve to obtain the optimal price depends on a relationship between two constants $\\kappa_{2}/\\kappa_{1}$ and $a_{1}/(a_{1}+a_{2})$ . Here, $\\kappa_{2}/\\kappa_{1}$ is the relative competitive ratio with respect to the two tasks for firm B, where $\\kappa_{1}>\\kappa_{2}>0$ . Thus, $\\kappa_{2}/\\kappa_{1}\\rightarrow1$ suggests that the relative performance differences between model A and model B are similar for both tasks, whereas $\\kappa_{2}/\\kappa_{1}\\bar{\\rightarrow}\\,0$ suggests that relative to model A, model B\u2019s performance is much worse on the second task than for the first task. The second parameter $a_{1}/(a_{1}+a_{2})$ is the fraction of the total demand that is occupied by the first task. If this is close to 1, then the first task has significantly higher demand than the second, but if it is close to 0, then the first task has significantly lower demand than the second. ", "page_idx": 7}, {"type": "text", "text": "", "page_idx": 8}, {"type": "text", "text": "We now discuss the structural insights obtained from Theorem 4 (see Figure 3 for a visualization). First, note that when condition (9) is satisfied, firm A is able to set higher prices than it could if the condition were not satisfied. In the latter case, the optimal price that firm A can set must be upper bounded by the constraint in problem (11), which in this scenario, is less than the upper bound in problem (10). Intuitively, this condition partitions firm A\u2019s pricing problem into two regimes: a high-price and low-price regime. Furthermore, the high-price regime is only attainable if the relative performance difference between the two tasks is greater than the Lambert $\\mathcal{W}$ function of the fraction of total demand occupied by the first task. ", "page_idx": 8}, {"type": "text", "text": "Second, if firm B\u2019s relative performance difference between the two tasks is larger than the fraction of demand occupied by the first task, then firm A\u2019s pricing problem is infeasible. That is, no matter what price that firm A sets, firm B is always incentivized to set a price that ensures users will prefer model B and consequently, leave no revenue for firm A. ", "page_idx": 8}, {"type": "text", "text": "Proposition 1. If $\\kappa_{2}/\\kappa_{1}>a_{1}/(a_{1}+a_{2}),$ , then for any price that firm A sets, firm $B$ will always set a price that allows them to be price-performance competitive for both tasks. ", "page_idx": 8}, {"type": "text", "text": "Intuitively, if the relative performance difference is high, then model B\u2019s performance relative to model A is approximately the same for both tasks. Consequently, the range $(\\kappa_{2}q,\\kappa_{1}q]$ is small, meaning that a small perturbation from this price would not significantly decrease firm B\u2019s revenue from the first task, while permitting the firm to obtain revenue from the second task as well. Note that model B does not necessarily have to be \u2018better\u2019 than model A, only that the performance on the tasks must be similar. Finally, this ratio $\\kappa_{2}/\\kappa_{1}$ only needs to be larger than the fraction of total demand that is occupied by the first task. Consequently, even if the ratio is small, firm B can still be incentivized to set a competitive price for both tasks if the potential revenue that can be obtained from the second task is high. ", "page_idx": 8}, {"type": "text", "text": "Theorem 4 and Proposition 1 sets a guideline for when a firm should deploy their generative AI model. Consider a company that has developed a model for a new application area with no competitors. This company knows that upon releasing their model to the public, competitors will release their own models. If the first-to-market company believes that the use-cases for this model are sufficiently similar to each other with respect to model performance, but are differentiated with respect to user demand, then they must ensure that the model performs exceedingly well on at least one specific use-case that their competitors cannot match. That is, the company must differentiate their product [Schmalensee, 1982], or competitors can outprice the initial company with similar products. ", "page_idx": 8}, {"type": "text", "text": "Although firm A must price accounting for firm B\u2019s actions, if model A is sufficiently differentiated from model B, then firm A can acquire their maximum possible revenue. Recall that the zero-gradient optimal price for problem (8) is $\\bar{q^{*}}=1/b$ . Furthermore recall that if condition (9) is met, then firm A can set higher prices for their model. We show below that if condition (9) is satisfied and if $\\kappa_{2}$ is sufficiently low with respect to the demand ratio, then the optimal price is feasible. ", "page_idx": 8}, {"type": "text", "text": "Proposition 2. If $\\begin{array}{r}{\\cdot\\kappa_{2}\\leq-\\mathcal{W}(a_{1}e^{-1}/(a_{1}+a_{2}))\\operatorname*{min}(\\kappa_{1},1),}\\end{array}$ , then firm A maximizes their revenue by setting $q^{*}=1/b$ . ", "page_idx": 8}, {"type": "text", "text": "6 Conclusion ", "text_level": 1, "page_idx": 8}, {"type": "text", "text": "We study how a company developing a generative AI model can set the price for this technology. Generative AI models are a fundamentally different technology product compared to classical AI models due to two factors. First, a single generative AI model is performant on multiple distinct use-cases that each invite individual respective user demands. Second, generative AI models offer interactivity via prompting, thereby encouraging \u2018geometric\u2019 user interaction where users can repeatedly prompt the model until it generates a satisfactory answer, compared to classical non-interactive AI models that invite one-shot \u2018Bernoulli\u2019 interaction. These features combined with a singular unit price per-prompt for model use warrant new revenue maximization frameworks for this technology. ", "page_idx": 8}, {"type": "text", "text": "We find that for generative AI models, the pricing problem reduces to ranking the different tasks in order of the relative performance of the model versus a competing alternative. In isolation, a company can then always obtain non-zero revenue by setting a price to be competitive for at least one downstream task. However, when considering the competition from alternative models that may be released after the price is set, the company faces strict upper bounds on the prices they can set based on the performance of the company\u2019s model relative to the latecomers. In particular, if the relative difference in performances on the tasks is sufficiently small, then a competitor will always be able to outprice the company on all tasks. This result reveals that an outsized performance improvement on at least one of the downstream applications of a generative AI model is essential to maximizing revenue. ", "page_idx": 9}, {"type": "text", "text": "Limitations. We explore a theoretical market problem where firms know user demand and the performance of competing AI models. In practice, these would be estimated with some noise. Furthermore, we study a static marketplace where each firm sets their price once. In contrast, AI technologies feature a flywheel where a low price and an early release of a product can allow for a firm to collect more training data and improve their model downstream [Gurkan and de V\u00e9ricourt, 2022]. In particular, the opportunity to acquire high-quality data can significantly improve model performance, thereby motivating the first mover position. Finally, we do not include the cost of developing the generative AI models themselves, but assumes that the fims have already decided to build these models. The market dynamics can change when considering how large of a model to build, how much resources (e.g., compute hours) to spend, or even whether to build a generative AI model. We see these scenarios as important future extensions. ", "page_idx": 9}, {"type": "text", "text": "Societal impact. Pricing of generative AI can significantly affect the democratization of generative AI technology. This paper explores the conditions that incentivize firms to develop or deploy this technology, e.g., when firms can obtain revenue. Setting appropriate prices for these models can allow for this technology to be more easily accessible to a wider set of users. ", "page_idx": 9}, {"type": "text", "text": "Acknowledgments and Disclosure of Funding ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "The author thanks the NeurIPS 2024 editorial chairs and anonymous referees for providing valuable feedback that significantly improved this paper. The author also thanks David Acuna, Sanja Fidler, Marc Law, and James Lucas for providing insightful discussion and valuable suggestions on early versions of this paper. ", "page_idx": 9}, {"type": "text", "text": "References ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "Simran Arora, Avanika Narayan, Mayee F Chen, Laurel Orr, Neel Guha, Kush Bhatia, Ines Chami, and Christopher Re. Ask me anything: A simple strategy for prompting language models. In The Eleventh International Conference on Learning Representations, 2022.   \nYuntao Bai, Andy Jones, Kamal Ndousse, Amanda Askell, Anna Chen, Nova DasSarma, Dawn Drain, Stanislav Fort, Deep Ganguli, Tom Henighan, et al. Training a helpful and harmless assistant with reinforcement learning from human feedback. arXiv preprint arXiv:2204.05862, 2022.   \nMarcel Binz and Eric Schulz. Using cognitive psychology to understand gpt-3. Proceedings of the National Academy of Sciences, 120(6):e2218523120, 2023.   \nTom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, et al. Language models are few-shot learners. Advances in neural information processing systems, 33:1877\u20131901, 2020.   \nFrancisco Castro, Jian Gao, and S\u00e9bastien Martin. Human-ai interactions and societal pitfalls. arXiv preprint arXiv:2309.10448, 2023.   \nLingjiao Chen, Paraschos Koutris, and Arun Kumar. Towards model-based pricing for machine learning in a data marketplace. In Proceedings of the 2019 international conference on management of data, pages 1535\u20131552, 2019.   \nMark Chen, Jerry Tworek, Heewoo Jun, Qiming Yuan, Henrique Ponde de Oliveira Pinto, Jared Kaplan, Harri Edwards, Yuri Burda, Nicholas Joseph, Greg Brockman, Alex Ray, Raul Puri, Gretchen Krueger, Michael Petrov, Heidy Khlaaf, Girish Sastry, Pamela Mishkin, Brooke Chan, Scott Gray, Nick Ryder, Mikhail Pavlov, Alethea Power, Lukasz Kaiser, Mohammad Bavarian, Clemens Winter, Philippe Tillet, Felipe Petroski Such, Dave Cummings, Matthias Plappert, Fotios Chantzis, Elizabeth Barnes, Ariel Herbert-Voss, William Hebgen Guss, Alex Nichol, Alex Paino, Nikolas Tezak, Jie Tang, Igor Babuschkin, Suchir Balaji, Shantanu Jain, William Saunders, Christopher Hesse, Andrew N. Carr, Jan Leike, Josh Achiam, Vedant Misra, Evan Morikawa, Alec Radford, Matthew Knight, Miles Brundage, Mira Murati, Katie Mayer, Peter Welinder, Bob McGrew, Dario Amodei, Sam McCandlish, Ilya Sutskever, and Wojciech Zaremba. Evaluating large language models trained on code, 2021.   \nZhi Chen and Wenjie Xue. Learning by failing: The (unintended) consequence of test reporting on autonomous vehicle training. Available at SSRN, 2023.   \nWei-Lin Chiang, Lianmin Zheng, Ying Sheng, Anastasios Nikolas Angelopoulos, Tianle Li, Dacheng Li, Hao Zhang, Banghua Zhu, Michael Jordan, Joseph E Gonzalez, et al. Chatbot arena: An open platform for evaluating llms by human preference. arXiv preprint arXiv:2403.04132, 2024.   \nPradeep K Chintagunta and Vithala R Rao. Pricing strategies in a dynamic duopoly: A differential game model. Management Science, 42(11):1501\u20131514, 1996.   \nKarl Cobbe, Vineet Kosaraju, Mohammad Bavarian, Mark Chen, Heewoo Jun, Lukasz Kaiser, Matthias Plappert, Jerry Tworek, Jacob Hilton, Reiichiro Nakano, et al. Training verifiers to solve math word problems. arXiv preprint arXiv:2110.14168, 2021.   \nZicun Cong, Xuan Luo, Jian Pei, Feida Zhu, and Yong Zhang. Data pricing in machine learning pipelines. Knowledge and Information Systems, 64(6):1417\u20131455, 2022.   \nJia Deng, Wei Dong, Richard Socher, Li-Jia Li, Kai Li, and Li Fei-Fei. Imagenet: A large-scale hierarchical image database. In 2009 IEEE Conference on Computer Vision and Pattern Recognition, pages 248\u2013255. Ieee, 2009.   \nTyna Eloundou, Sam Manning, Pamela Mishkin, and Daniel Rock. Gpts are gpts: An early look at the labor market impact potential of large language models. arXiv preprint arXiv:2303.10130, 2023.   \nAwi Federgruen and Ming Hu. Multi-product price and assortment competition. Operations Research, 63(3): 572\u2013584, 2015.   \nAwi Federgruen and Ming Hu. Stability in a general oligopoly model. Naval Research Logistics (NRL), 66(1): 90\u2013102, 2019.   \nPnina Feldman, Yiangos Papanastasiou, and Ella Segev. Social learning and the design of new experience goods. Management Science, 65(4):1502\u20131519, 2019.   \nGuillermo Gallego and Ming Hu. Dynamic pricing of perishable assets under competition. Management Science, 60(5):1241\u20131259, 2014.   \nGuillermo Gallego and Garrett Van Ryzin. Optimal dynamic pricing of inventories with stochastic demand over finite horizons. Management science, 40(8):999\u20131020, 1994.   \nRobert Gibbons. Game theory for applied economists. Princeton University Press, 1992.   \nHuseyin Gurkan and Francis de V\u00e9ricourt. Contracting, pricing, and data collection under the ai flywheel effect. Management Science, 68(12):8791\u20138808, 2022.   \nJonathan H Hamilton and Steven M Slutsky. Endogenous timing in duopoly games: Stackelberg or cournot equilibria. Games and Economic Behavior, 2(1):29\u201346, 1990.   \nDan Hendrycks, Collin Burns, Steven Basart, Andy Zou, Mantas Mazeika, Dawn Song, and Jacob Steinhardt. Measuring massive multitask language understanding. Proceedings of the International Conference on Learning Representations (ICLR), 2021.   \nJared Kaplan, Sam McCandlish, Tom Henighan, Tom B Brown, Benjamin Chess, Rewon Child, Scott Gray, Alec Radford, Jeffrey Wu, and Dario Amodei. Scaling laws for neural language models. arXiv preprint arXiv:2001.08361, 2020.   \nBernard Koch, Emily Denton, Alex Hanna, and Jacob G Foster. Reduced, reused and recycled: The life of a dataset in machine learning research. arXiv preprint arXiv:2112.01716, 2021.   \nDaiqing Li, Aleks Kamko, Ehsan Akhgari, Ali Sabet, Linmiao Xu, and Suhail Doshi. Playground v2. 5: Three insights towards enhancing aesthetic quality in text-to-image generation. arXiv preprint arXiv:2402.17245, 2024.   \nYuan-Hong Liao, Rafid Mahmood, Sanja Fidler, and David Acuna. Can feedback enhance semantic grounding in large vision-language models? arXiv preprint arXiv:2404.06510, 2024.   \nJinfei Liu, Jian Lou, Junxu Liu, Li Xiong, Jian Pei, and Jimeng Sun. Dealer: an end-to-end model marketplace with differential privacy. Proceedings of the VLDB Endowment, 14(6), 2021.   \nPengfei Liu, Weizhe Yuan, Jinlan Fu, Zhengbao Jiang, Hiroaki Hayashi, and Graham Neubig. Pre-train, prompt, and predict: A systematic survey of prompting methods in natural language processing. ACM Computing Surveys, 55(9):1\u201335, 2023.   \nRafid Mahmood, James Lucas, Jose M Alvarez, Sanja Fidler, and Marc Law. Optimizing data collection for machine learning. Advances in Neural Information Processing Systems, 35:29915\u201329928, 2022.   \nSoroush Nasiriany, Fei Xia, Wenhao Yu, Ted Xiao, Jacky Liang, Ishita Dasgupta, Annie Xie, Danny Driess, Ayzaan Wahid, Zhuo Xu, et al. Pivot: Iterative visual prompting elicits actionable knowledge for vlms. arXiv preprint arXiv:2402.07872, 2024.   \nRebecca Roelofs, Vaishaal Shankar, Benjamin Recht, Sara Fridovich-Keil, Moritz Hardt, John Miller, and Ludwig Schmidt. A meta-analysis of overfitting in machine learning. Advances in Neural Information Processing Systems, 32, 2019.   \nRichard Schmalensee. Product differentiation advantages of pioneering brands. The American Economic Review, 72(3):349\u2013365, 1982.   \nHugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-Anne Lachaux, Timoth\u00e9e Lacroix, Baptiste Rozi\u00e8re, Naman Goyal, Eric Hambro, Faisal Azhar, et al. Llama: Open and efficient foundation language models. arXiv preprint arXiv:2302.13971, 2023.   \nGarrett J Van Ryzin and Kalyan T Talluri. An introduction to revenue management. In Emerging theory, methods, and applications, pages 142\u2013194. Informs, 2005.   \nXuezhi Wang, Jason Wei, Dale Schuurmans, Quoc Le, Ed Chi, Sharan Narang, Aakanksha Chowdhery, and Denny Zhou. Self-consistency improves chain of thought reasoning in language models. arXiv preprint arXiv:2203.11171, 2022.   \nJason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Fei Xia, Ed Chi, Quoc V Le, Denny Zhou, et al. Chain-of-thought prompting elicits reasoning in large language models. Advances in neural information processing systems, 35:24824\u201324837, 2022.   \nTianyu Wu, Shizhu He, Jingping Liu, Siqi Sun, Kang Liu, Qing-Long Han, and Yang Tang. A brief overview of chatgpt: The history, status quo and potential future development. IEEE/CAA Journal of Automatica Sinica, 10(5):1122\u20131136, 2023.   \nXinyi Xu, Thanh Lam, Chuan Sheng Foo, and Bryan Kian Hsiang Low. Model shapley: equitable model valuation with black-box access. Advances in Neural Information Processing Systems, 36, 2024.   \nJD Zamfirescu-Pereira, Richmond Y Wong, Bjoern Hartmann, and Qian Yang. Why johnny can\u2019t prompt: how non-ai experts try (and fail) to design llm prompts. In Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems, pages 1\u201321, 2023.   \nMengzhenyu Zhang, Hyun-Soo Ahn, and Joline Uichanco. Data-driven pricing for a new product. Operations Research, 70(2):847\u2013866, 2022.   \nAlbert Ziegler, Eirini Kalliamvakou, X Alice Li, Andrew Rice, Devon Rifkin, Shawn Simister, Ganesh Sittampalam, and Edward Aftandilian. Measuring github copilot\u2019s impact on productivity. Communications of the ACM, 67(3):54\u201363, 2024. ", "page_idx": 9}, {"type": "text", "text": "", "page_idx": 10}, {"type": "text", "text": "", "page_idx": 11}, {"type": "text", "text": "A Proofs ", "text_level": 1, "page_idx": 12}, {"type": "text", "text": "Proof of Theorem $^{\\,l}$ . Consider the ordering $\\sigma$ defined by (4) and note that for any $t$ , if we constrain $p$ to satisfy ", "page_idx": 12}, {"type": "equation", "text": "$$\n\\kappa_{\\sigma(t)}\\geq\\frac{p}{q}>\\kappa_{\\sigma(t+1)},\n$$", "text_format": "latex", "page_idx": 12}, {"type": "text", "text": "then all of the tasks $\\sigma(1),\\sigma(2),\\ldots,\\sigma(t)$ become competitive for firm B\u2019s generative model compared to firm A\u2019s model, i.e., by satisfying (1), whereas tasks $\\sigma(t+1),\\ldots,\\sigma(T)$ are competitive for firm A\u2019s model instead. As a result, for prices constrained in this range, the resulting problem becomes $\\begin{array}{r}{\\operatorname*{max}_{p}~p\\sum_{s=1}^{t}D_{\\sigma(s)}(p)}\\end{array}$ . Therefore, to solve the overall pricing problem, we only need to solve this resulting constrained problem for each value of $t$ . \u53e3 ", "page_idx": 12}, {"type": "text", "text": "Proof of Theorem 2. From Theorem 1, for any value of $q$ , there exists a $t\\in[T]$ such that firm B will prioritize revenue from tasks $\\sigma(1),\\sigma(2),\\cdots\\overset{\\cdot}{,}\\sigma(t)$ . This value of $t$ will satisfy ", "page_idx": 12}, {"type": "equation", "text": "$$\n\\operatorname*{max}_{p}\\left\\{p\\sum_{s=1}^{t}D_{\\sigma(s)}(p)\\~\\middle|~\\kappa_{\\sigma(t)}q\\geq p>\\kappa_{\\sigma(t+1)}q\\right\\}>\\operatorname*{max}_{p^{\\prime}}\\left\\{p^{\\prime}\\sum_{s=1}^{t^{\\prime}}D_{\\sigma(s)}(p^{\\prime})~\\middle|~\\kappa_{\\sigma(t^{\\prime})}q\\geq p^{\\prime}>\\kappa_{\\sigma(t^{\\prime}+1)}p\\right\\}.\n$$", "text_format": "latex", "page_idx": 12}, {"type": "text", "text": "for all $t^{\\prime}\\neq t$ . Furthermore, given this $t$ , firm A will only obtain revenue from tasks $\\sigma(t+1),\\sigma(t+$ $2),\\cdot\\cdot\\cdot,\\sigma(T)$ , thereby revealing the objective function. Finally, note that if $t=T$ , then firm A will not acquire any revenue since firm B will be price-performance competitive on all tasks. Therefore, firm A\u2019s optimization problem is to simultaneously solve for $q$ and for $t\\in[T-1]$ . \u53e3 ", "page_idx": 12}, {"type": "text", "text": "Proof of Theorem 3. First, note that under an exponential demand function the revenue function for each piece $t$ of problem (5) is $p\\bar{a}_{\\sigma(t)}\\exp(-b p)$ , and therefore has a zero-gradient point at $p^{*}=1/b$ . Thus, when solving problem (5), we can solve the inner problem by breaking into 3 cases based on which $t$ to consider. ", "page_idx": 12}, {"type": "text", "text": "For $t^{*}$ satisfying the condition. Here, the zero-gradient price $p^{*}$ is a feasible solution to the inner pricing problem, meaning that this must be the optimal price. Substituting this into the revenue function yields $\\bar{a}_{\\sigma(t^{*})}\\exp\\!\\left(-1\\right)/b$ . ", "page_idx": 12}, {"type": "text", "text": "For $t>t^{*}$ . Note that for any $t>t^{*}$ , the price is constrained to be less than $\\kappa_{\\sigma(t^{*}+1)}<1/b$ . In this regime, the revenue function $p\\bar{a}_{\\sigma(t)}\\exp(-b p)$ is monotonically increasing, meaning that the optimal price will be the maximum possible value, i.e., $p=q\\kappa_{\\sigma(t)}$ . Substituting this into the revenue function yields $\\kappa_{\\sigma(t)}q\\bar{a}_{\\sigma(t)}\\exp\\left(-b\\kappa_{\\sigma(t)}q\\right)$ . ", "page_idx": 12}, {"type": "text", "text": "For $t<t^{*}$ . Here, the set of feasible prices is strictly greater than $\\kappa_{\\sigma(t^{*})}>1/b$ . In this regime, the revenue function is monotonically decreasing, meaning that the optimal price will be the minimum value, i.e., $p\\to q\\kappa_{\\sigma(t+1)}$ , approaching from above. However, for any such setting, decreasing $p$ to equal the infinum would make firm B price-performance competitive for the $t+1$ -th task as well and thereby yield a higher return. Therefore, the optimal solution for any $t<t^{*}$ can always be upper bounded by the optimal solution for $t+1$ , leading up to $t^{*}$ . \u53e3 ", "page_idx": 12}, {"type": "text", "text": "Proof of Corollary $^{\\,I}$ . The upper bound follows from the proof of Theorem 3, as we show that the optimal revenue cannot be achieved without satisfying task $\\sigma(t^{*})$ . The lower bound follows from observing the optimal solution for $t=T$ . \u53e3 ", "page_idx": 12}, {"type": "text", "text": "Proof of Theorem 4. Let $p_{1}\\;:=\\;\\arg\\operatorname*{max}\\{p D_{1}(p)\\;\\mid\\;\\kappa_{1}q\\;\\geq\\;p\\;>\\;\\kappa_{2}q\\}$ . Furthermore, let $p_{2}:=$ arg $\\operatorname*{max}\\{p(D_{1}(p)+D_{2}(p))\\;\\mid\\;\\kappa_{2}q\\;\\geq\\;p\\,>\\;0\\}$ . Although $p_{1}$ and $p_{2}$ depend on $q$ , we omit this dependency to simplify the notation. We prove our theorem by exploring three regimes for $q$ : $(0,\\bar{1}/(b\\kappa_{1})\\bar{]}$ , $(1/(b\\bar{\\kappa_{1}}),\\dot{1}/(b\\kappa_{2})]$ , and $(1/(b\\bar{\\kappa_{2}}),\\infty)$ . We then show that whether condition (9), the problems for each regime simplify further into problems (10) and (11). ", "page_idx": 12}, {"type": "text", "text": "For $q\\in(1/(b\\kappa_{2}),\\infty)$ . For any $q>1/(b\\kappa_{2})$ , we have $\\kappa_{2}q\\geq1/b>0$ . From Theorem 3, $p_{2}=1/b$ is the optimal price. Furthermore, since $\\kappa_{1}q\\geq p_{1}>\\kappa_{2}q$ , we have $p_{1}>1/b$ . From Corollary 1, $p_{1}$ is priced too high and cannot achieve a higher revenue than $p_{2}$ . Therefore in this regime, firm B will set a price low enough that their model is competitive for both tasks, and consequently firm A will achieve zero revenue. ", "page_idx": 12}, {"type": "text", "text": "For $q\\in(1/(b\\kappa_{1}),1/(b\\kappa_{2})]$ . From Theorem 3, $p_{1}=1/b$ and $p_{2}=\\kappa_{2}q$ are the optimal prices that firm B can set for their two sub-problems. For firm A to achieve any revenue, the constraint in problem (8) becomes ", "page_idx": 13}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\frac{1}{b}a_{1}\\exp(-1)>\\kappa_{2}q(a_{1}+a_{2})\\exp(-b\\kappa_{2}q)\\;\\Rightarrow\\;-\\;b\\kappa_{2}q\\exp(-b\\kappa_{2}q)>-\\left(\\frac{a_{1}\\exp(-1)}{a_{1}+a_{2}}\\right)}\\\\ {\\Rightarrow\\;-\\;b\\kappa_{2}q>{\\mathcal W}\\left(-\\frac{a_{1}\\exp(-1)}{a_{1}+a_{2}}\\right)}\\\\ {\\Rightarrow\\;q<-\\frac{1}{b\\kappa_{2}}{\\mathcal W}\\left(-\\frac{a_{1}\\exp(-1)}{a_{1}+a_{2}}\\right)\\leq\\frac{1}{b\\kappa_{2}}}\\end{array}\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "Above, the first line follows from rearranging the terms and the second line follows from applying the definition of the Lambert $\\mathcal{W}$ function, i.e., $\\mathcal{W}(z)=y\\Leftrightarrow y\\exp(y)=z$ . The third line follows again from rearranging the terms. Finally, note that the Lambert $\\mathcal{W}$ function is bounded in $[-1,0]$ , meaning that this constraint dominates the original upper bound. Therefore, for $q$ in this regime, we can solve the problem ", "page_idx": 13}, {"type": "equation", "text": "$$\n\\operatorname*{max}\\left\\{q a_{2}\\exp(-b q)\\ \\middle|\\ -\\frac{1}{b\\kappa_{2}}\\mathcal{W}\\left(-\\frac{a_{1}\\exp(-1)}{a_{1}+a_{2}}\\right)\\geq q\\geq\\frac{1}{b\\kappa_{1}}\\right\\}\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "For $q\\in(0,1/(b\\kappa_{1})]$ . From Theorem 3, $p_{1}=\\kappa_{1}q$ and $p_{2}=\\kappa_{2}q$ are the optimal prices that firm B can set when $q\\leq1/(b\\kappa_{1})$ . Here, the constraint that ensures firm B will only prioritize the first task reduces to ", "page_idx": 13}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{q\\kappa_{1}a_{1}\\exp(-b\\kappa_{1}q)>q\\kappa_{2}(a_{1}+a_{2})\\exp(-b\\kappa_{2}q)\\,\\Rightarrow\\,\\frac{\\kappa_{1}}{\\kappa_{2}}\\left(\\frac{a_{1}}{a_{1}+a_{2}}\\right)>\\exp(b q(\\kappa_{1}-\\kappa_{2})q)}\\\\ &{\\Rightarrow\\,b(\\kappa_{1}-\\kappa_{2})q<\\log\\frac{\\kappa_{1}}{\\kappa_{2}}+\\log\\frac{a_{1}}{a_{1}+a_{2}}}\\\\ &{\\Rightarrow\\,q<\\frac{\\log\\frac{\\kappa_{1}}{\\kappa_{2}}+\\log\\frac{a_{1}}{a_{1}+a_{2}}}{b(\\kappa_{1}-\\kappa_{2})}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "Above, the first line follows from rearranging the terms and the second line follows from taking the log on both sides. The third line follows from rearranging the terms. Therefore, for $q$ in this regime, we can solve the problem ", "page_idx": 13}, {"type": "equation", "text": "$$\n\\operatorname*{max}\\left\\{q a_{2}\\exp(-b q)\\ \\middle|\\ \\operatorname*{min}\\left(\\frac{1}{b\\kappa_{1}},\\frac{1}{b(\\kappa_{1}-\\kappa_{2})}\\left(\\log\\frac{\\kappa_{1}}{\\kappa_{2}}+\\log\\frac{a_{1}}{a_{1}+a_{2}}\\right)\\right)\\geq q>0\\right\\}.\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "We now show that when condition (9) is satisfied, problems (12) and (13) join to have one continuous feasible set, whereas when the condition is not satisfied, problem (12) is infeasible and the minimum disappears. ", "page_idx": 13}, {"type": "text", "text": "First, to see that when the condition is satisfied, the two problems have one feasible set, we must prove ", "page_idx": 13}, {"type": "equation", "text": "$$\n\\frac{1}{b(\\kappa_{1}-\\kappa_{2})}\\left(\\log\\frac{\\kappa_{1}}{\\kappa_{2}}+\\log\\frac{a_{1}}{a_{1}+a_{2}}\\right)\\geq\\frac{1}{b\\kappa_{1}}.\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "Specifically, ", "page_idx": 13}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{-\\frac{\\kappa_{2}}{\\kappa_{1}}\\geq\\mathcal{W}\\left(-\\frac{a_{1}\\exp(-1)}{a_{1}+a_{2}}\\right)\\implies\\frac{\\kappa_{2}}{\\kappa_{1}}\\exp\\left(-\\frac{\\kappa_{2}}{\\kappa_{1}}\\right)\\leq\\frac{a_{1}\\exp(-1)}{a_{1}+a_{2}}}\\\\ {\\Rightarrow\\mathrm{~exp}\\left(1-\\frac{\\kappa_{2}}{\\kappa_{1}}\\right)\\leq\\frac{\\kappa_{1}}{\\kappa_{2}}\\left(\\frac{a_{1}}{a_{1}+a_{2}}\\right)}\\\\ {\\Rightarrow1-\\frac{\\kappa_{2}}{\\kappa_{1}}\\leq\\log\\frac{\\kappa_{1}}{\\kappa_{2}}+\\log\\frac{a_{1}}{a_{1}+a_{2}}}\\\\ {\\Rightarrow\\mathrm{~}\\frac{\\kappa_{1}-\\kappa_{2}}{\\kappa_{1}}\\leq\\log\\frac{\\kappa_{1}}{\\kappa_{2}}+\\log\\frac{a_{1}}{a_{1}+a_{2}}}\\\\ {\\Rightarrow\\frac{1}{b\\kappa_{1}}\\leq\\frac{1}{b(\\kappa_{1}-\\kappa_{2})}\\left(\\log\\frac{\\kappa_{1}}{\\kappa_{2}}+\\log\\frac{a_{1}}{a_{1}+a_{2}}\\right).}\\end{array}\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "Above, the first line follows from applying the Lambert $\\mathcal{W}$ function. The second line follows from rearranging the terms and the third line follows from taking the log on both sides. The fourth and fifth lines follow from rearranging the terms and multiplying both sides by $1/b$ . Note that when this condition is satisfied, the lower bound for problem (12) and the upper bound for problem (13) are equivalent, meaning that we can merge the two disjunctive regions. This results in obtaining problem (10). ", "page_idx": 14}, {"type": "text", "text": "Next, we first note that when the condition is not satisfied, the inequality in (14) is reversed and the minimum on the left-hand-side of the constraint in (13) can be removed. We then show that problem (12) becomes infeasible. Specifically, ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\lefteqn{\\frac{\\kappa_{2}}{\\kappa_{1}}>-\\mathcal{W}\\left(-\\frac{a_{1}\\exp(-1)}{a_{1}+a_{2}}\\right)\\,\\Rightarrow\\,\\frac{1}{\\kappa_{1}}>-\\frac{1}{\\kappa_{2}}\\mathcal{W}\\left(-\\frac{a_{1}\\exp(-1)}{a_{1}+a_{2}}\\right)}}\\\\ &{\\Rightarrow\\,\\frac{1}{b\\kappa_{1}}>-\\frac{1}{b\\kappa_{2}}\\mathcal{W}\\left(-\\frac{a_{1}\\exp(-1)}{a_{1}+a_{2}}\\right)}\\end{array}\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "The second line follows from multiplying both sides by $1/b$ . This condition means that problem (12) does not have a feasible region, meaning that the optimal price can only be obtained by solving problem (11). \u53e3 ", "page_idx": 14}, {"type": "text", "text": "Proof of Proposition $^{\\,l}$ . The proof of the follows from observing that when this condition is satisfied, the intermediate problems from the proof of Theorem 4, i.e., problems (12) and (13) both become infeasible. If those problems become infeasible, the nominal problems (10) and (11) also must be infeasible. First, ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\frac{\\kappa_{1}}{\\kappa_{2}}<\\frac{a_{1}+a_{2}}{a_{1}}\\implies\\log\\frac{\\kappa_{1}}{\\kappa_{2}}<\\log\\frac{a_{1}+a_{2}}{a_{1}}}&{}\\\\ {\\Rightarrow}&{\\log\\frac{\\kappa_{1}}{\\kappa_{2}}+\\log\\frac{a_{1}}{a_{1}+a_{2}}<0}\\end{array}\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "The first line follows from taking the log and the second line follows from rearranging the terms and simplifying. When this condition is satisfied, problem (13) becomes infeasible. ", "page_idx": 14}, {"type": "text", "text": "Next, observe that for any $z\\in[0,1]$ , we have $z\\geq-\\mathcal{W}(z\\exp(-1))$ . Because $a_{1}/(a_{1}+a_{2})\\in[0,1]$ , for any value of $a_{1}$ and $a_{2}$ , we have ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\frac{a_{1}}{a_{1}+a_{2}}\\geq-\\mathcal{W}\\left(\\frac{a_{1}\\exp(-1)}{a_{1}+a_{2}}\\right)\\,\\Rightarrow\\,\\frac{\\kappa_{2}}{\\kappa_{1}}>-\\mathcal{W}\\left(\\frac{a_{1}\\exp(-1)}{a_{1}+a_{2}}\\right)}\\\\ &{\\phantom{\\frac{a_{1}}{a_{1}+a_{2}}\\geq-\\mathcal{W}\\left(\\frac{a_{1}\\exp(-1)}{b\\kappa_{1}}\\right)}\\Rightarrow\\,\\frac{1}{b\\kappa_{1}}>-\\frac{1}{b\\kappa_{2}}\\mathcal{W}\\left(\\frac{a_{1}\\exp(-1)}{a_{1}+a_{2}}\\right)}\\end{array}\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "Thus, problem (12) is also infeasible. ", "page_idx": 14}, {"type": "text", "text": "Proof of Proposition 2. We show that if this condition holds, then problem (10) is the active problemto-solve and that the zero-gradient solution $1/b$ is a feasible solution. First, note that the condition implies that condition (9) holds, meaning that problem (10) is the problem-to-solve. We then note that condition implies ", "page_idx": 14}, {"type": "equation", "text": "$$\n1\\leq-\\frac{1}{\\kappa_{2}}\\mathcal{W}\\left(-\\frac{a_{1}\\exp(-1)}{a_{1}+a_{2}}\\right)\\operatorname*{min}\\left(\\frac{V_{1}}{W_{1}},1\\right)\\leq-\\frac{1}{\\kappa_{2}}\\mathcal{W}\\left(-\\frac{a_{1}\\exp(-1)}{a_{1}+a_{2}}\\right)\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "Multiplying both sides by $1/b$ completes the proof. ", "page_idx": 14}, {"type": "text", "text": "B Extensions from per-prompt to per-token pricing ", "text_level": 1, "page_idx": 14}, {"type": "text", "text": "In this paper, we assume that the generative AI models can be used at a fixed price per-prompt. In practice, generative AI models are priced either per-token or priced via a subscription mechanism where users pay a fixed cost for (potentially unlimited) use. Furthermore, different tasks may feature statistically different numbers of tokens either via longer (or shorter) prompts, or longer (or shorter) model outputs. Consequently under per-token pricing, different tasks will have different costs on average. The price-per-prompt framework of this paper naturally extends to pricing per-token with a small change of variables that preserves all fundamental results. ", "page_idx": 14}, {"type": "text", "text": "", "page_idx": 15}, {"type": "text", "text": "Suppose there are two firms, A and B, developing generative AI models with fixed price per-tokens $q_{0}$ and $p_{0}$ , respectively. We assume that the price is the same for both input and output tokens. For each task $t$ and model, there is now a distribution of the number of tokens $\\phi_{t}$ and $\\theta_{t}$ , that the user sends and receives through the respective model in a given prompt. Note that the corresponding price-per-prompt $p_{t}$ and $q_{t}$ are now random variables $p_{t}=p_{0}\\theta_{t}$ and $q_{t}=q_{0}\\phi_{t}$ , that depend on the specific task. For any given task $t$ , a user will prefer model B if ", "page_idx": 15}, {"type": "equation", "text": "$$\np_{0}\\mathbb{E}[\\theta_{t}n(V_{t})]\\leq q_{0}\\mathbb{E}[\\phi_{t}n(W_{t})]\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "where the expectation is taken over the randomness in the number of prompting rounds times the number of tokens per prompting round. The corresponding revenue functions for the two firms are ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\begin{array}{l}{{\\displaystyle R_{A}(q_{0}|p_{0}):=q_{0}\\sum_{t=1}^{T}D_{t}(q_{0})\\mathbb{1}\\left\\{q_{0}\\mathbb{E}[\\phi_{t}n(W_{t})]\\leq p_{0}\\mathbb{E}[\\theta_{t}n(V_{t})]\\right\\}}}\\\\ {{\\displaystyle R_{B}(p_{0}|q_{0}):=p_{0}\\sum_{t=1}^{T}D_{t}(p_{0})\\mathbb{1}\\left\\{p_{0}\\mathbb{E}[\\theta_{t}n(V_{t})]\\leq q_{0}\\mathbb{E}[\\phi_{t}n(W_{t})]\\right\\}.}}\\end{array}\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "To solve this problem, note that the inherent structure is equivalent to equation (3). Let $\\kappa_{t}:=$ $\\mathbb{E}[\\phi_{t}n(W_{t})]/\\bar{\\mathbb{E}}[\\theta_{t}n(V_{t})]$ be the corresponding competitive ratio of the two models and note that the set of tasks can be ranked according to this re-defined competitive ratio. Then, Theorem 1 follows using the same steps and the re-defined $\\kappa_{t}$ . Moreover, all subsequent results carry over from this result. ", "page_idx": 15}, {"type": "text", "text": "NeurIPS Paper Checklist ", "text_level": 1, "page_idx": 16}, {"type": "text", "text": "1. Claims ", "text_level": 1, "page_idx": 16}, {"type": "text", "text": "Question: Do the main claims made in the abstract and introduction accurately reflect the paper\u2019s contributions and scope? ", "page_idx": 16}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 16}, {"type": "text", "text": "Justification: The abstract summarizes the key insights obtained from our model as well as the problem setting and model assumptions. ", "page_idx": 16}, {"type": "text", "text": "Guidelines: ", "page_idx": 16}, {"type": "text", "text": "\u2022 The answer NA means that the abstract and introduction do not include the claims made in the paper.   \n\u2022 The abstract and/or introduction should clearly state the claims made, including the contributions made in the paper and important assumptions and limitations. A No or NA answer to this question will not be perceived well by the reviewers.   \n\u2022 The claims made should match theoretical and experimental results, and reflect how much the results can be expected to generalize to other settings.   \n\u2022 It is fine to include aspirational goals as motivation as long as it is clear that these goals are not attained by the paper. ", "page_idx": 16}, {"type": "text", "text": "2. Limitations ", "text_level": 1, "page_idx": 16}, {"type": "text", "text": "Question: Does the paper discuss the limitations of the work performed by the authors? ", "page_idx": 16}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 16}, {"type": "text", "text": "Justification: We have a Limitations subsection in the Conclusion. ", "page_idx": 16}, {"type": "text", "text": "Guidelines: ", "page_idx": 16}, {"type": "text", "text": "\u2022 The answer NA means that the paper has no limitation while the answer No means that the paper has limitations, but those are not discussed in the paper.   \n\u2022 The authors are encouraged to create a separate \"Limitations\" section in their paper.   \n\u2022 The paper should point out any strong assumptions and how robust the results are to violations of these assumptions (e.g., independence assumptions, noiseless settings, model well-specification, asymptotic approximations only holding locally). The authors should reflect on how these assumptions might be violated in practice and what the implications would be.   \n\u2022 The authors should reflect on the scope of the claims made, e.g., if the approach was only tested on a few datasets or with a few runs. In general, empirical results often depend on implicit assumptions, which should be articulated.   \n\u2022 The authors should reflect on the factors that influence the performance of the approach. For example, a facial recognition algorithm may perform poorly when image resolution is low or images are taken in low lighting. Or a speech-to-text system might not be used reliably to provide closed captions for online lectures because it fails to handle technical jargon.   \n\u2022 The authors should discuss the computational efficiency of the proposed algorithms and how they scale with dataset size.   \n\u2022 If applicable, the authors should discuss possible limitations of their approach to address problems of privacy and fairness.   \n\u2022 While the authors might fear that complete honesty about limitations might be used by reviewers as grounds for rejection, a worse outcome might be that reviewers discover limitations that aren\u2019t acknowledged in the paper. The authors should use their best judgment and recognize that individual actions in favor of transparency play an important role in developing norms that preserve the integrity of the community. Reviewers will be specifically instructed to not penalize honesty concerning limitations. ", "page_idx": 16}, {"type": "text", "text": "3. Theory Assumptions and Proofs ", "text_level": 1, "page_idx": 16}, {"type": "text", "text": "Question: For each theoretical result, does the paper provide the full set of assumptions and a complete (and correct) proof? ", "page_idx": 16}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 16}, {"type": "text", "text": "Justification: All proofs are in the Appendix. All assumptions are in the main paper. Guidelines: ", "page_idx": 17}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include theoretical results.   \n\u2022 All the theorems, formulas, and proofs in the paper should be numbered and crossreferenced.   \n\u2022 All assumptions should be clearly stated or referenced in the statement of any theorems.   \n\u2022 The proofs can either appear in the main paper or the supplemental material, but if they appear in the supplemental material, the authors are encouraged to provide a short proof sketch to provide intuition.   \n\u2022 Inversely, any informal proof provided in the core of the paper should be complemented by formal proofs provided in appendix or supplemental material.   \n\u2022 Theorems and Lemmas that the proof relies upon should be properly referenced. ", "page_idx": 17}, {"type": "text", "text": "4. Experimental Result Reproducibility ", "text_level": 1, "page_idx": 17}, {"type": "text", "text": "Question: Does the paper fully disclose all the information needed to reproduce the main experimental results of the paper to the extent that it affects the main claims and/or conclusions of the paper (regardless of whether the code and data are provided or not)? ", "page_idx": 17}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 17}, {"type": "text", "text": "Justification: This is primarily a theory-driven paper. The only numerical analysis is a computational example which we detail in the main paper. ", "page_idx": 17}, {"type": "text", "text": "Guidelines: ", "page_idx": 17}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 If the paper includes experiments, a No answer to this question will not be perceived well by the reviewers: Making the paper reproducible is important, regardless of whether the code and data are provided or not.   \n\u2022 If the contribution is a dataset and/or model, the authors should describe the steps taken to make their results reproducible or verifiable.   \n\u2022 Depending on the contribution, reproducibility can be accomplished in various ways. For example, if the contribution is a novel architecture, describing the architecture fully might suffice, or if the contribution is a specific model and empirical evaluation, it may be necessary to either make it possible for others to replicate the model with the same dataset, or provide access to the model. In general. releasing code and data is often one good way to accomplish this, but reproducibility can also be provided via detailed instructions for how to replicate the results, access to a hosted model (e.g., in the case of a large language model), releasing of a model checkpoint, or other means that are appropriate to the research performed.   \n\u2022 While NeurIPS does not require releasing code, the conference does require all submissions to provide some reasonable avenue for reproducibility, which may depend on the nature of the contribution. For example (a) If the contribution is primarily a new algorithm, the paper should make it clear how to reproduce that algorithm. (b) If the contribution is primarily a new model architecture, the paper should describe the architecture clearly and fully. (c) If the contribution is a new model (e.g., a large language model), then there should either be a way to access this model for reproducing the results or a way to reproduce the model (e.g., with an open-source dataset or instructions for how to construct the dataset). (d) We recognize that reproducibility may be tricky in some cases, in which case authors are welcome to describe the particular way they provide for reproducibility. In the case of closed-source models, it may be that access to the model is limited in some way (e.g., to registered users), but it should be possible for other researchers to have some path to reproducing or verifying the results. ", "page_idx": 17}, {"type": "text", "text": "5. Open access to data and code ", "text_level": 1, "page_idx": 17}, {"type": "text", "text": "Question: Does the paper provide open access to the data and code, with sufficient instructions to faithfully reproduce the main experimental results, as described in supplemental material? ", "page_idx": 17}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 18}, {"type": "text", "text": "Justification: We do not perform any experiments involving datasets. Guidelines: ", "page_idx": 18}, {"type": "text", "text": "\u2022 The answer NA means that paper does not include experiments requiring code.   \n\u2022 Please see the NeurIPS code and data submission guidelines (https://nips.cc/ public/guides/CodeSubmissionPolicy) for more details.   \n\u2022 While we encourage the release of code and data, we understand that this might not be possible, so \u201cNo\u201d is an acceptable answer. Papers cannot be rejected simply for not including code, unless this is central to the contribution (e.g., for a new open-source benchmark).   \n\u2022 The instructions should contain the exact command and environment needed to run to reproduce the results. See the NeurIPS code and data submission guidelines (https: //nips.cc/public/guides/CodeSubmissionPolicy) for more details.   \n\u2022 The authors should provide instructions on data access and preparation, including how to access the raw data, preprocessed data, intermediate data, and generated data, etc.   \n\u2022 The authors should provide scripts to reproduce all experimental results for the new proposed method and baselines. If only a subset of experiments are reproducible, they should state which ones are omitted from the script and why.   \n\u2022 At submission time, to preserve anonymity, the authors should release anonymized versions (if applicable).   \n\u2022 Providing as much information as possible in supplemental material (appended to the paper) is recommended, but including URLs to data and code is permitted. ", "page_idx": 18}, {"type": "text", "text": "6. Experimental Setting/Details ", "text_level": 1, "page_idx": 18}, {"type": "text", "text": "Question: Does the paper specify all the training and test details (e.g., data splits, hyperparameters, how they were chosen, type of optimizer, etc.) necessary to understand the results? ", "page_idx": 18}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 18}, {"type": "text", "text": "Justification: We do not train any neural networks. Guidelines: ", "page_idx": 18}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments. \u2022 The experimental setting should be presented in the core of the paper to a level of detail that is necessary to appreciate the results and make sense of them. \u2022 The full details can be provided either with the code, in appendix, or as supplemental material. ", "page_idx": 18}, {"type": "text", "text": "7. Experiment Statistical Significance ", "text_level": 1, "page_idx": 18}, {"type": "text", "text": "Question: Does the paper report error bars suitably and correctly defined or other appropriate information about the statistical significance of the experiments? ", "page_idx": 18}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 18}, {"type": "text", "text": "Justification: We do not have any experiments with statistical noise. ", "page_idx": 18}, {"type": "text", "text": "Guidelines: ", "page_idx": 18}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 The authors should answer \"Yes\" if the results are accompanied by error bars, confidence intervals, or statistical significance tests, at least for the experiments that support the main claims of the paper.   \n\u2022 The factors of variability that the error bars are capturing should be clearly stated (for example, train/test split, initialization, random drawing of some parameter, or overall run with given experimental conditions).   \n\u2022 The method for calculating the error bars should be explained (closed form formula, call to a library function, bootstrap, etc.)   \n\u2022 The assumptions made should be given (e.g., Normally distributed errors).   \n\u2022 It should be clear whether the error bar is the standard deviation or the standard error of the mean.   \n\u2022 It is OK to report 1-sigma error bars, but one should state it. The authors should preferably report a 2-sigma error bar than state that they have a $96\\%$ CI, if the hypothesis of Normality of errors is not verified.   \n\u2022 For asymmetric distributions, the authors should be careful not to show in tables or figures symmetric error bars that would yield results that are out of range (e.g. negative error rates).   \n\u2022 If error bars are reported in tables or plots, The authors should explain in the text how they were calculated and reference the corresponding figures or tables in the text. ", "page_idx": 18}, {"type": "text", "text": "", "page_idx": 19}, {"type": "text", "text": "8. Experiments Compute Resources ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "Question: For each experiment, does the paper provide sufficient information on the computer resources (type of compute workers, memory, time of execution) needed to reproduce the experiments? ", "page_idx": 19}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 19}, {"type": "text", "text": "Justification: There is no compute required. ", "page_idx": 19}, {"type": "text", "text": "Guidelines: ", "page_idx": 19}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 The paper should indicate the type of compute workers CPU or GPU, internal cluster, or cloud provider, including relevant memory and storage.   \n\u2022 The paper should provide the amount of compute required for each of the individual experimental runs as well as estimate the total compute.   \n\u2022 The paper should disclose whether the full research project required more compute than the experiments reported in the paper (e.g., preliminary or failed experiments that didn\u2019t make it into the paper). ", "page_idx": 19}, {"type": "text", "text": "9. Code Of Ethics ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "Question: Does the research conducted in the paper conform, in every respect, with the NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines? ", "page_idx": 19}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 19}, {"type": "text", "text": "Justification: We have reviewed the code of ethics. ", "page_idx": 19}, {"type": "text", "text": "Guidelines: ", "page_idx": 19}, {"type": "text", "text": "\u2022 The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics.   \n\u2022 If the authors answer No, they should explain the special circumstances that require a deviation from the Code of Ethics.   \n\u2022 The authors should make sure to preserve anonymity (e.g., if there is a special consideration due to laws or regulations in their jurisdiction). ", "page_idx": 19}, {"type": "text", "text": "10. Broader Impacts ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "Question: Does the paper discuss both potential positive societal impacts and negative societal impacts of the work performed? ", "page_idx": 19}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "Justification: Broader societal impacts are discussed in the conclusion. ", "page_idx": 19}, {"type": "text", "text": "Guidelines: ", "page_idx": 19}, {"type": "text", "text": "\u2022 The answer NA means that there is no societal impact of the work performed.   \n\u2022 If the authors answer NA or No, they should explain why their work has no societal impact or why the paper does not address societal impact.   \n\u2022 Examples of negative societal impacts include potential malicious or unintended uses (e.g., disinformation, generating fake profiles, surveillance), fairness considerations (e.g., deployment of technologies that could make decisions that unfairly impact specific groups), privacy considerations, and security considerations.   \n\u2022 The conference expects that many papers will be foundational research and not tied to particular applications, let alone deployments. However, if there is a direct path to any negative applications, the authors should point it out. For example, it is legitimate to point out that an improvement in the quality of generative models could be used to ", "page_idx": 19}, {"type": "text", "text": "generate deepfakes for disinformation. On the other hand, it is not needed to point out that a generic algorithm for optimizing neural networks could enable people to train models that generate Deepfakes faster. ", "page_idx": 20}, {"type": "text", "text": "\u2022 The authors should consider possible harms that could arise when the technology is being used as intended and functioning correctly, harms that could arise when the technology is being used as intended but gives incorrect results, and harms following from (intentional or unintentional) misuse of the technology. \u2022 If there are negative societal impacts, the authors could also discuss possible mitigation strategies (e.g., gated release of models, providing defenses in addition to attacks, mechanisms for monitoring misuse, mechanisms to monitor how a system learns from feedback over time, improving the efficiency and accessibility of ML). ", "page_idx": 20}, {"type": "text", "text": "11. Safeguards ", "text_level": 1, "page_idx": 20}, {"type": "text", "text": "Question: Does the paper describe safeguards that have been put in place for responsible release of data or models that have a high risk for misuse (e.g., pretrained language models, image generators, or scraped datasets)? ", "page_idx": 20}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 20}, {"type": "text", "text": "Justification: No data or models are released in this paper. ", "page_idx": 20}, {"type": "text", "text": "Guidelines: ", "page_idx": 20}, {"type": "text", "text": "\u2022 The answer NA means that the paper poses no such risks.   \n\u2022 Released models that have a high risk for misuse or dual-use should be released with necessary safeguards to allow for controlled use of the model, for example by requiring that users adhere to usage guidelines or restrictions to access the model or implementing safety filters.   \n\u2022 Datasets that have been scraped from the Internet could pose safety risks. The authors should describe how they avoided releasing unsafe images.   \n\u2022 We recognize that providing effective safeguards is challenging, and many papers do not require this, but we encourage authors to take this into account and make a best faith effort. ", "page_idx": 20}, {"type": "text", "text": "12. Licenses for existing assets ", "text_level": 1, "page_idx": 20}, {"type": "text", "text": "Question: Are the creators or original owners of assets (e.g., code, data, models), used in the paper, properly credited and are the license and terms of use explicitly mentioned and properly respected? ", "page_idx": 20}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 20}, {"type": "text", "text": "Justification: No assets are introduced in this paper. ", "page_idx": 20}, {"type": "text", "text": "Guidelines: ", "page_idx": 20}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not use existing assets.   \n\u2022 The authors should cite the original paper that produced the code package or dataset.   \n\u2022 The authors should state which version of the asset is used and, if possible, include a URL.   \n\u2022 The name of the license (e.g., CC-BY 4.0) should be included for each asset.   \n\u2022 For scraped data from a particular source (e.g., website), the copyright and terms of service of that source should be provided.   \n\u2022 If assets are released, the license, copyright information, and terms of use in the package should be provided. For popular datasets, paperswithcode.com/datasets has curated licenses for some datasets. Their licensing guide can help determine the license of a dataset.   \n\u2022 For existing datasets that are re-packaged, both the original license and the license of the derived asset (if it has changed) should be provided.   \n\u2022 If this information is not available online, the authors are encouraged to reach out to the asset\u2019s creators. ", "page_idx": 20}, {"type": "text", "text": "13. New Assets ", "text_level": 1, "page_idx": 20}, {"type": "text", "text": "Question: Are new assets introduced in the paper well documented and is the documentation provided alongside the assets? ", "page_idx": 20}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 21}, {"type": "text", "text": "Justification: No assets are introduced in this paper. ", "page_idx": 21}, {"type": "text", "text": "Guidelines: ", "page_idx": 21}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not release new assets.   \n\u2022 Researchers should communicate the details of the dataset/code/model as part of their submissions via structured templates. This includes details about training, license, limitations, etc.   \n\u2022 The paper should discuss whether and how consent was obtained from people whose asset is used.   \n\u2022 At submission time, remember to anonymize your assets (if applicable). You can either create an anonymized URL or include an anonymized zip file. ", "page_idx": 21}, {"type": "text", "text": "14. Crowdsourcing and Research with Human Subjects ", "text_level": 1, "page_idx": 21}, {"type": "text", "text": "Question: For crowdsourcing experiments and research with human subjects, does the paper include the full text of instructions given to participants and screenshots, if applicable, as well as details about compensation (if any)? ", "page_idx": 21}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 21}, {"type": "text", "text": "Justification: No human studies were performed. ", "page_idx": 21}, {"type": "text", "text": "Guidelines: ", "page_idx": 21}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u2022 Including this information in the supplemental material is fine, but if the main contribution of the paper involves human subjects, then as much detail as possible should be included in the main paper.   \n\u2022 According to the NeurIPS Code of Ethics, workers involved in data collection, curation, or other labor should be paid at least the minimum wage in the country of the data collector. ", "page_idx": 21}, {"type": "text", "text": "15. Institutional Review Board (IRB) Approvals or Equivalent for Research with Human Subjects ", "text_level": 1, "page_idx": 21}, {"type": "text", "text": "Question: Does the paper describe potential risks incurred by study participants, whether such risks were disclosed to the subjects, and whether Institutional Review Board (IRB) approvals (or an equivalent approval/review based on the requirements of your country or institution) were obtained? ", "page_idx": 21}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 21}, {"type": "text", "text": "Justification: No human studies were performed. ", "page_idx": 21}, {"type": "text", "text": "Guidelines: ", "page_idx": 21}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u2022 Depending on the country in which research is conducted, IRB approval (or equivalent) may be required for any human subjects research. If you obtained IRB approval, you should clearly state this in the paper.   \n\u2022 We recognize that the procedures for this may vary significantly between institutions and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the guidelines for their institution.   \n\u2022 For initial submissions, do not include any information that would break anonymity (if applicable), such as the institution conducting the review. ", "page_idx": 21}]