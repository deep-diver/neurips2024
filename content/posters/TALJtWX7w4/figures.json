[{"figure_path": "TALJtWX7w4/figures/figures_6_1.jpg", "caption": "Figure 1: Left. Comparison of LaSCal with temperature scaling on the source distribution (TempScal Source) or target distribution (TempScal Target), using labels. Right. CE after post-hoc calibration on iWildCam and Amazon when the target distribution exhibits both label and covariate shift w.r.t. the source. We report CE normalized by the number of classes (5 for Amazon and 20 for iWildCam) for illustration purposes. Lower numbers are better.", "description": "This figure compares the performance of the proposed LaSCal method with temperature scaling on source and target data for models facing label shift.  The left panel shows that LaSCal, without target labels, performs comparably to temperature scaling on the target data (which uses labels). The right panel demonstrates the robustness of LaSCal in a more challenging scenario where both the label and input distributions shift between source and target datasets.", "section": "4.1 Calibration under label shift"}, {"figure_path": "TALJtWX7w4/figures/figures_6_2.jpg", "caption": "Figure 1: Left. Comparison of LaSCal with temperature scaling on the source distribution (TempScal Source) or target distribution (TempScal Target), using labels. Right. CE after post-hoc calibration on iWildCam and Amazon when the target distribution exhibits both label and covariate shift w.r.t. the source. We report CE normalized by the number of classes (5 for Amazon and 20 for iWildCam) for illustration purposes. Lower numbers are better.", "description": "This figure presents a comparison of the LaSCal method with temperature scaling applied to both source and target data (using labels for the target).  The left panel shows the effectiveness of LaSCal under label shift without target labels, demonstrating its ability to close the performance gap with a fully supervised method (TempScal Target). The right panel demonstrates LaSCal's robustness against a more challenging scenario involving both label and covariate shift (changes in both the input data distribution and the label distribution). LaSCal is shown to perform comparably to, or better than, other methods in this complex setting.", "section": "4 Experiments and Discussion"}, {"figure_path": "TALJtWX7w4/figures/figures_7_1.jpg", "caption": "Figure 2: Reliability diagrams on Amazon using DistillRoBERTa before and after calibration. TempScal (Source) and EM-BCTS perform IID calibration on the source distribution. LaSCal calibrates the model on the unlabeled target distribution. We report L\u2081 top-label CE in the bottom right corner.", "description": "This figure displays reliability diagrams, illustrating the calibration performance of different methods on the Amazon dataset using the DistillRoBERTa model.  The diagrams compare the model's predicted confidence levels against its actual accuracy. The four plots represent different calibration scenarios:\n\n(a) **Before calibration:** Shows the model's initial calibration state, with significant miscalibration evident in lower confidence bins.\n(b) **TempScal (Source):** Represents post-hoc calibration applied using the temperature scaling method trained on the source data.\n(c) **EM-BCTS:** Shows the calibration after applying the EM-BCTS method, a technique designed for label shift adaptation but calibrated on source data.\n(d) **LaSCal:** Demonstrates the calibration results when using the proposed LaSCal method, which performs calibration directly on the unlabeled target data. \n\nThe L\u2081 top-label calibration error (ECE) is provided for each scenario. LaSCal is expected to achieve better calibration (lower ECE) than methods calibrated on the source domain.", "section": "4.1 Calibration under label shift"}, {"figure_path": "TALJtWX7w4/figures/figures_8_1.jpg", "caption": "Figure 3: Robustness analysis. We report mean and standard deviation over multiple iterations of resampling the data. 5:1 denotes \u201cno shift\u201d, and the severity increases from left to right. LaSCal generalizes well to a wide range of shifts, ratios of source to target samples, and sample sizes.", "description": "This figure demonstrates the robustness of the proposed CE estimator under various conditions.  The three subfigures show how the estimator performs under different levels of label shift, different ratios of source to target sample sizes, and different overall sample sizes. The shaded regions represent standard deviation, indicating the uncertainty of the estimate under each scenario.  The results suggest the estimator is reliable across a range of conditions.", "section": "4.2 Empirical analysis of the estimator's properties"}, {"figure_path": "TALJtWX7w4/figures/figures_9_1.jpg", "caption": "Figure 4: Left. Impact of the weight estimation method on our estimator. Right. Our estimator (CEt) effectively closes the gap to the ground truth (CEt). We report CE normalized by the number of classes (5 for Amazon and 20 for iWildCam) for illustration purposes.", "description": "The left plot shows the impact of different weight estimation methods (ELSA, RLLS, EM-BCTS) on the proposed CE estimator. The right plot compares the estimated CE using the RLLS importance weights with the ground truth CE, demonstrating that the estimator accurately captures the calibration error even in the absence of labeled target data.", "section": "4.2 Empirical analysis of the estimator's properties"}, {"figure_path": "TALJtWX7w4/figures/figures_15_1.jpg", "caption": "Figure 5: Number of target samples per class in simulated long-tail CIFAR-10/100 datasets with different imbalance factors (IF).", "description": "This figure shows the distribution of target samples across classes in simulated long-tail CIFAR-10 and CIFAR-100 datasets.  Different lines represent different imbalance factors (IF), which control the ratio between the most and least frequent classes.  An IF of 1.0 indicates a balanced dataset, while higher IF values represent increasingly imbalanced datasets. The x-axis represents the class index, and the y-axis shows the number of samples per class.  The plot illustrates how the number of samples per class decreases as the imbalance factor increases, showing the effect of the long-tail distribution on the data.", "section": "A.1 Details about the datasets"}, {"figure_path": "TALJtWX7w4/figures/figures_17_1.jpg", "caption": "Figure 2: Reliability diagrams on Amazon using DistillRoBERTa before and after calibration. TempScal (Source) and EM-BCTS perform IID calibration on the source distribution. LaSCal calibrates the model on the unlabeled target distribution. We report L\u2081 top-label CE in the bottom right corner.", "description": "This figure displays reliability diagrams which are used to visualize the calibration of a model's predicted probabilities. The x-axis represents the model's predicted confidence, and the y-axis represents the accuracy of the model's predictions at that confidence level.  The four subfigures show the reliability diagrams for a DistillRoBERTa model trained on the Amazon dataset, comparing four different scenarios:\n(a) Before calibration: shows the model's calibration before applying any post-hoc calibration method.\n(b) TempScal (Source): shows the calibration of the model after applying temperature scaling using only labeled source data.\n(c) EM-BCTS: displays the model's calibration after applying EM-Bias Corrected Temperature Scaling (EM-BCTS), which accounts for label shift and performs calibration using both source and target data. Note that, unlike LaSCal, EM-BCTS requires labeled target data.\n(d) LaSCal: shows the calibration performance of the model after applying LaSCal. LaSCal is the proposed calibration method which does not require labeled target data. The dotted line represents perfect calibration. The red bars illustrate the gap between the predicted confidence and the actual accuracy, indicating miscalibration. The lower the L\u2081 top-label CE value (shown in the lower right corner of each subplot), the better the calibration of the model. The figure indicates that LaSCal achieves the best calibration results among all the methods compared.", "section": "4.1 Calibration under label shift"}, {"figure_path": "TALJtWX7w4/figures/figures_17_2.jpg", "caption": "Figure 1: Left. Comparison of LaSCal with temperature scaling on the source distribution (TempScal Source) or target distribution (TempScal Target), using labels. Right. CE after post-hoc calibration on iWildCam and Amazon when the target distribution exhibits both label and covariate shift w.r.t. the source. We report CE normalized by the number of classes (5 for Amazon and 20 for iWildCam) for illustration purposes. Lower numbers are better.", "description": "The left plot compares LaSCal's performance against temperature scaling with and without target labels.  The right plot shows the calibration error (CE) after applying different calibration methods when both label and input distributions change between the source and target domains. LaSCal is shown to perform competitively, especially considering it does not require target labels.", "section": "4.1 Calibration under label shift"}]