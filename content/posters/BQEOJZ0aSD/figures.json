[{"figure_path": "BQEOJZ0aSD/figures/figures_1_1.jpg", "caption": "Figure 1: Existing diversification work vs SED. Unlike previous diversification approaches that require a separate OOD dataset on which the models are trained to diverge, our Scalable Ensemble Diversification (SED) operates on a single ID dataset where OOD samples are dynamically identified and are used to let the ensemble members diverge.", "description": "This figure compares existing ensemble diversification methods with the proposed SED method. Existing methods require separate in-distribution (ID) and out-of-distribution (OOD) datasets to train a diverse ensemble.  The SED method, however, only requires a single ID dataset.  It dynamically identifies OOD samples within the ID dataset and uses them to encourage diversity in the ensemble's predictions.", "section": "1 Introduction"}, {"figure_path": "BQEOJZ0aSD/figures/figures_4_1.jpg", "caption": "Figure 1: Existing diversification work vs SED. Unlike previous diversification approaches that require a separate OOD dataset on which the models are trained to diverge, our Scalable Ensemble Diversification (SED) operates on a single ID dataset where OOD samples are dynamically identified and are used to let the ensemble members diverge.", "description": "This figure compares traditional ensemble diversification methods with the proposed SED method. Traditional methods require separate in-distribution (ID) and out-of-distribution (OOD) datasets to train a diverse ensemble of models. In contrast, SED only uses a single ID dataset and dynamically identifies OOD samples within the ID dataset, encouraging the ensemble to make diverse predictions on them. This allows SED to scale to large-scale datasets where separating ID and OOD data may not be feasible.", "section": "1 Introduction"}, {"figure_path": "BQEOJZ0aSD/figures/figures_6_1.jpg", "caption": "Figure 2: ImageNet-R examples leading to the greatest and least disagreement. We show the 5 most divergent and 5 least divergent samples according to the SED ensemble. We measure the prediction diversity with the Prediction Diversity Score (PDS) in \u00a73.3. GT refers to the ground truth category. Ensemble predictions are shown in bold, in cases when ensemble members predict classes different from the ensemble prediction we provide them on the next line with standard font.", "description": "This figure showcases examples from the ImageNet-R dataset, highlighting instances where the SED ensemble exhibits the greatest and least prediction disagreement.  Five examples are shown for each category (high and low disagreement).  The ground truth category (GT) is provided for comparison with the SED ensemble's prediction and a prediction diversity score (PDS) is given to quantify the level of disagreement within the ensemble for each example.", "section": "4.2 Diversification"}, {"figure_path": "BQEOJZ0aSD/figures/figures_8_1.jpg", "caption": "Figure 3: Impact of diversity regulariser \u03bb on OOD detection. We show the model answer diversity, measured by PDS, and the OOD detection performance, measured by AUROC, against \u03bb values, the loss weight for the disagreement regularizer term.", "description": "This figure shows the effect of the diversity regularizer (\u03bb) on out-of-distribution (OOD) detection performance.  The left panel displays the Predictive Diversity Score (PDS), a measure of ensemble prediction diversity, plotted against \u03bb for four different OOD datasets (C-1, C-5, iNat, OI). The right panel shows the Area Under the Receiver Operating Characteristic curve (AUROC), a measure of OOD detection performance, also plotted against \u03bb for the same datasets.  The figure demonstrates that increasing \u03bb leads to greater ensemble diversity (higher PDS) and improved OOD detection performance (higher AUROC), particularly within a specific range of \u03bb values.", "section": "4.4 OOD Detection"}, {"figure_path": "BQEOJZ0aSD/figures/figures_8_2.jpg", "caption": "Figure 4: Impact of ensemble size on OOD detection.", "description": "This figure shows how the Area Under the ROC Curve (AUROC) for Out-of-Distribution (OOD) detection changes with different ensemble sizes (M). The AUROC is a measure of the model's ability to distinguish between in-distribution and out-of-distribution samples.  The figure shows AUROC values for four OOD datasets: C-1, C-5, iNat, and OI.  It demonstrates that increasing ensemble size generally improves the AUROC for OOD detection, with diminishing returns at larger ensemble sizes.", "section": "4.4 OOD Detection"}]