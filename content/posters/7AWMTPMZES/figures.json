[{"figure_path": "7AWMTPMZES/figures/figures_1_1.jpg", "caption": "Figure 1: (A) Blue and green curves are the learned probability density contours of the diffusion model for two data points. The red area is the discrete area of the blue data x0 and the boundary of this area is naturally a density contour. The discrete boundary is a complex hypersurface in the high-dimensional continuous space and we simplify it into a red line for convenience of description. As observed in the magnified part, the learned contours deviate from the boundary contour, resulting in inconsistent probability densities and gradient directions. (B) We consider the discrete boundary as priors for the diffusion process to estimate a more appropriate probability distribution, where the learned contours are expected to follow the shape of the discrete boundary.", "description": "This figure illustrates the core problem addressed in the paper: the discrepancy between the probability density contours learned by continuous diffusion models and the boundaries of discrete data. (A) shows how learned contours (blue and green) deviate from the actual discrete area boundary (red), leading to imprecise data generation.  (B) proposes a solution by incorporating discrete area boundaries as priors to guide the learning process and improve the precision of the probability distribution.", "section": "1 Introduction"}, {"figure_path": "7AWMTPMZES/figures/figures_2_1.jpg", "caption": "Figure 2: (A) Rescaled Probability Contours. The bold curve xto is the density contour of one standard deviation. As the time t decreases from T to 0, the rescaled contours will gradually fit the discrete boundary and probability densities will also concentrate to this boundary. (B) Rescaled Forward Trajectory. Original forward trajectory x0 \u2192 xto \u2192 xt is rescaled to be a boundary conditional trajectory x1 \u2192 xt that starts from x1 = xto. The rescaled forward distribution pt(xt|x0) is transformed from the discrete boundary to Gaussian distributions.", "description": "This figure illustrates the core idea of the proposed method. Panel (A) shows how the probability density contours are rescaled to fit the discrete boundaries, and panel (B) illustrates how the forward trajectory is rescaled to make the sampling process conditioned on the boundary. The process involves estimating the boundary as a prior distribution and then rescaling the forward trajectory.", "section": "3 Methodology"}, {"figure_path": "7AWMTPMZES/figures/figures_8_1.jpg", "caption": "Figure 3: Generated images of Bit Diffusion repro, DDIM, and Ours on CIFAR-10.", "description": "This figure compares the image generation results of three different models on the CIFAR-10 dataset.  (A) shows the results from a reproduced version of the Bit Diffusion model, which serves as a baseline. (B) presents the results from DDIM, another established diffusion model. Finally, (C) displays the results obtained using the novel boundary conditional diffusion process proposed in the paper.  The figure visually demonstrates the improved image quality achieved by the proposed method, particularly in terms of detail and realism compared to the baseline models.", "section": "5 Discrete Image Generation"}, {"figure_path": "7AWMTPMZES/figures/figures_17_1.jpg", "caption": "Figure 4: We demonstrate the trajectory differences among Markovian Diffusion Process, Deterministic Diffusion and Flow Matching.", "description": "This figure compares the trajectory differences between three different diffusion process: Markovian Diffusion Process, Deterministic Diffusion Process, and Flow Matching.  It visually shows how the forward and reverse processes unfold in each approach, highlighting the differences in the way noise is added and removed.  This helps illustrate the core differences between the three methods used in the paper for modeling diffusion processes.", "section": "D Different Diffusion Trajectories"}, {"figure_path": "7AWMTPMZES/figures/figures_22_1.jpg", "caption": "Figure 3: Generated images of Bit Diffusion repro, DDIM, and Ours on CIFAR-10.", "description": "This figure shows the image generation results of three different methods on the CIFAR-10 dataset.  (A) shows the results from a reproduced version of Bit Diffusion, (B) shows results from DDIM, and (C) shows the results from the proposed method in the paper.  The figure visually compares the image quality and diversity generated by each method.", "section": "5 Discrete Image Generation"}, {"figure_path": "7AWMTPMZES/figures/figures_24_1.jpg", "caption": "Figure 5: Generated TRAINABLE EMBEDDING images of reproduced Bit Diffusion and Ours on CIFAR-10.", "description": "This figure shows the qualitative results of image generation using two different models on the CIFAR-10 dataset. The images generated by the reproduced Bit Diffusion model show artifacts and blurriness, indicating that the model struggled to capture fine details and textures.  In contrast, images generated by the proposed \"Ours\" model exhibit sharper details, more realistic textures, and less blurriness, highlighting the improved performance of the new method.", "section": "5 Discrete Image Generation"}, {"figure_path": "7AWMTPMZES/figures/figures_25_1.jpg", "caption": "Figure 7: Generated TRAINABLE EMBEDDING images of reproduced Bit Diffusion and Ours on CIFAR-10.", "description": "This figure compares the image generation results of the reproduced Bit Diffusion model and the proposed model on the CIFAR-10 dataset using trainable embedding.  The images generated by the proposed model show a significant improvement in image quality and detail compared to the reproduced Bit Diffusion model, indicating that the proposed method effectively leverages trainable embeddings to generate higher-quality discrete images.", "section": "5 Discrete Image Generation"}]