[{"figure_path": "yAKuSbIwR7/figures/figures_4_1.jpg", "caption": "Figure 1: Two hidden units (1 and 7) connected by two different directed paths 1-2-3-4-7 and 1-5-6-7 in a BiLU network. Each unit i has a scaling factor Ai, and each directed edge from unit j to unit i has a scaling factor Mij = Ai/Aj. The products of the Mij's along each path is equal to: A2 A3 A4 A7 / A1 = A5 A6 A7 / A1. Therefore the variables Lij = log Mij must satisfy the linear equation: L21 + L32 + L43 + L74 = L51 + L65 + L76 = log A7 - log A1.", "description": "This figure illustrates two paths connecting two hidden units in a BiLU network. Each unit has a scaling factor, and each edge has a scaling factor that is the ratio of the scaling factors of the connected units. The product of the scaling factors along each path must be equal. This equality implies a linear constraint on the logarithms of the edge scaling factors.  This example demonstrates the non-commutative nature of balancing operations when neurons are connected.", "section": "5 Balancing Algorithms"}, {"figure_path": "yAKuSbIwR7/figures/figures_5_1.jpg", "caption": "Figure 2: The problem of minimizing the strictly convex regularizer R(Lij) = \u2211ij epLij |Wij|P (p > 0), over the linear (hence convex) manifold of self-consistent configurations defined by the linear constraints of the form \u03a3\u03c0 Lij = 0, where \u03c0 runs over input-output paths. The regularizer function depends on the weights. The linear manifold depends only on the architecture, i.e., the graph of connections. This is a strictly convex optimization problem with a unique solution associated with the point A. At A the corresponding weights must be balanced, or else a self-consistent configuration of lower cost could be found by balancing any non-balanced neuron. Finally, any other self-consistent configuration B cannot correspond to a balanced state of the network, since there must exist balancing moves that further reduce the regularizer cost (see main text). Stochastic balancing produces random paths from the origin, where Lij= log Mij = 0, to the unique optimum point A.", "description": "This figure illustrates the convergence of the stochastic balancing algorithm to a unique global optimum. The optimization problem involves minimizing a strictly convex regularizer function over a linear manifold of self-consistent configurations.  The unique solution (point A) represents a balanced network state, while any other self-consistent configuration (point B) can be improved by further balancing operations, demonstrating the uniqueness of the balanced state. The stochastic paths from the origin visually represent the algorithm's random exploration converging towards the unique optimum.", "section": "Balancing Algorithms"}, {"figure_path": "yAKuSbIwR7/figures/figures_6_1.jpg", "caption": "Figure 3: SGD applied to E alone, in general, does not converge to a balanced state, but SGD applied to E + R converges to a balanced state. (A-C) Simulations use a deep fully connected autoencoder trained on the MNIST dataset. (D-F) Simulations use a deep locally connected network trained on the CFAR10 dataset. (A,D) Regularization leads to neural balance. (B,E) The training loss decreases and converges during training (these panels are not meant for assessing the quality of learning when using a regularizer). (C,F) Using weight regularization decreases the norm of weights. (A-F) Shaded areas correspond to one s.t.d around the mean (in some cases the s.t.d. is small and the shaded area is not visible).", "description": "This figure compares the effects of using SGD with and without an L2 regularizer on the convergence of a neural network to a balanced state.  The top row shows the overall balance deficit, which is reduced significantly when using regularization. The middle row shows the training loss curves, while the bottom row displays the Frobenius norm of the weights (||W||F). The results indicate that regularization is crucial for achieving neural balance and illustrates the convergence behavior on two different datasets (MNIST and CIFAR-10).", "section": "Simulations"}, {"figure_path": "yAKuSbIwR7/figures/figures_7_1.jpg", "caption": "Figure 3: SGD applied to E alone, in general, does not converge to a balanced state, but SGD applied to E + R converges to a balanced state. (A-C) Simulations use a deep fully connected autoencoder trained on the MNIST dataset. (D-F) Simulations use a deep locally connected network trained on the CFAR10 dataset. (A,D) Regularization leads to neural balance. (B,E) The training loss decreases and converges during training (these panels are not meant for assessing the quality of learning when using a regularizer). (C,F) Using weight regularization decreases the norm of weights. (A-F) Shaded areas correspond to one s.t.d around the mean (in some cases the s.t.d. is small and the shaded area is not visible).", "description": "This figure shows the results of applying SGD (Stochastic Gradient Descent) to minimize an error function with and without a regularizer (R). The top row shows that without a regularizer, SGD does not converge to a balanced state, while with a regularizer, SGD does converge to a balanced state. The bottom two rows show that with a regularizer, the training loss decreases and converges, and the norm of the weights decreases. ", "section": "Simulations"}, {"figure_path": "yAKuSbIwR7/figures/figures_8_1.jpg", "caption": "Figure 5: Stochastic balancing converges to a unique global balanced state. (A-B) Simulations use a deep fully connected autoencoder trained on the MNIST dataset. (C-D) Simulations use a deep locally connected network trained on the CFAR10 dataset. (A,C) The weights of the network are initialized randomly and saved. The stochastic balancing algorithm is applied and the resulting balanced weights are denoted by Wbalanced. The stochastic balancing algorithm is applied 1,000 different times. In all repetitions, the weights converge to the same value Wbalanced. (B,D) Stochastic balancing decreases the norm of the weights. (A-D) Shaded areas correspond to one standard deviation around the mean.", "description": "This figure shows the results of applying the stochastic balancing algorithm to two different neural network architectures (a deep fully connected autoencoder trained on MNIST and a deep locally connected network trained on CIFAR10).  The algorithm converges to a unique global balanced state, regardless of the initial weight configuration and random variations in the algorithm's execution.  The panels (A,C) demonstrate the convergence of weights to the same balanced state across multiple runs, while (B,D) show the algorithm's effect of reducing the norm (magnitude) of the weights.  Shaded regions represent the standard deviation across runs.", "section": "5 Balancing Algorithms"}, {"figure_path": "yAKuSbIwR7/figures/figures_17_1.jpg", "caption": "Figure 6: Two hidden units (1 and 7) connected by two different directed paths 1-2-3-4-7 and 1-5-6-7 in a BiLU network. Each unit i has a scaling factor Ai, and each directed edge from unit j to unit i has a scaling factor Mij = Ai/Aj. The products of the Mij's along each path is equal to: A2 A3 A4 A7 A5 A6 A7 Therefore the variables Lij = log Mij must satisfy the linear equation: L21 + L32 + L43 + L74 = L51 + L65 + L76 = log A7 - log A1.", "description": "This figure illustrates two different paths connecting two hidden units in a BiLU network. Each unit has a scaling factor, and each edge has a scaling factor that is the ratio of scaling factors of connected units.  The products of the scaling factors along each path must be equal. This leads to a linear equation involving the logarithms of scaling factors, which constrains the network's weights. This is important for proving the convergence of the balancing algorithm.", "section": "5 Balancing Algorithms"}, {"figure_path": "yAKuSbIwR7/figures/figures_22_1.jpg", "caption": "Figure 1: Two hidden units (1 and 7) connected by two different directed paths 1-2-3-4-7 and 1-5-6-7 in a BiLU network. Each unit i has a scaling factor Ai, and each directed edge from unit j to unit i has a scaling factor Mij = Ai/Aj. The products of the Mij's along each path is equal to: A2A3A4A7/A1 = A5A6A7/A1. Therefore the variables Lij = log Mij must satisfy the linear equation: L21 + L32 + L43 + L74 = L51 + L65 + L76 = log A7 - log A1.", "description": "This figure illustrates two paths connecting two hidden units (1 and 7) in a BiLU network.  Each unit has a scaling factor (Ai), and each edge has a scaling factor (Mij = Ai/Aj). The product of the Mij values along each path must be equal. This equality creates a linear constraint on the log of the scaling factors (Lij = log Mij), demonstrating the linear relationships inherent in the network's structure, especially important for the later proof about convergence in stochastic balancing. ", "section": "5 Balancing Algorithms"}, {"figure_path": "yAKuSbIwR7/figures/figures_22_2.jpg", "caption": "Figure 1: Two hidden units (1 and 7) connected by two different directed paths 1-2-3-4-7 and 1-5-6-7 in a BiLU network. Each unit i has a scaling factor Ai, and each directed edge from unit j to unit i has a scaling factor Mij = Ai/Aj. The products of the Mij's along each path is equal to: A2 A3 A4 A7 A5 A6 A7. Therefore the variables Lij = log Mij must satisfy the linear equation: L21 + L32 + L43 + L74 = L51 + L65 + L76 = log A7 - log A1.", "description": "This figure illustrates a BiLU network with two hidden units connected by two different paths.  Each unit and connection has an associated scaling factor. The figure demonstrates how the product of scaling factors along each path must be equal, resulting in a linear equation relating the logarithmic scaling factors (Lij). This equation is crucial in understanding the constraints on the self-consistent set of Lij values.", "section": "5 Balancing Algorithms"}]