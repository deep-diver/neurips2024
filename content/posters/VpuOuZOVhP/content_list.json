[{"type": "text", "text": "LLM-AutoDA: Large Language Model-Driven Automatic Data Augmentation for Long-tailed Problems ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Pengkun Wang1,2,\u2217 Zhe Zhao $^{1,3*}$ Haibin Wen5, Fanfu Wang6, Binwu Wang1, Qingfu Zhang3,\u2020 Yang Wang1,2\u2020 ", "page_idx": 0}, {"type": "text", "text": "1University of Science and Technology of China (USTC), Hefei, China 2Suzhou Institute for Advanced Research, USTC, Suzhou, China 3City University of Hong Kong, Hong Kong, China 5MorongAI, Suzhou, China 6Lanzhou University, Lanzhou, China {pengkun $@$ ustc.edu.cn, $\\mathtt{z z4543}@$ mail.ustc.edu.cn, haibin65535 $@$ gmail.com wangff21 $@$ lzu.edu.cn, wbw2024 $@$ ustc.edu.cn, qingfu.zhang@cityu.edu.hk, angyan $@$ ustc.edu.cn} ", "page_idx": 0}, {"type": "text", "text": "", "page_idx": 0}, {"type": "text", "text": "Abstract ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "The long-tailed distribution is the underlying nature of real-world data, and it presents unprecedented challenges for training deep learning models. Existing long-tailed learning paradigms based on re-balancing or data augmentation have partially alleviated the long-tailed problem. However, they still have limitations, such as relying on manually designed augmentation strategies, having a limited search space, and using fixed augmentation strategies. To address these limitations, this paper proposes a novel LLM-based long-tailed data augmentation framework called LLM-AutoDA, which leverages large-scale pretrained models to automatically search for the optimal augmentation strategies suitable for long-tailed data distributions. In addition, it applies this strategy to the original imbalanced data to create an augmented dataset and fine-tune the underlying longtailed learning model. The performance improvement on the validation set serves as a reward signal to update the generation model, enabling the generation of more effective augmentation strategies in the next iteration. We conducted extensive experiments on multiple mainstream long-tailed learning benchmarks. The results show that LLM-AutoDA outperforms state-of-the-art data augmentation methods and other re-balancing methods significantly. The code is available in ", "page_idx": 0}, {"type": "text", "text": "1 Introduction ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "As a revolutionary technology, deep learning has shown a broad and significant impact on various tasks, including image classification [21], object detection [34], natural language processing [19], and many interdisciplinary research problems [40, 47]. The success of these endeavors relies heavily on the support of large-scale manually curated datasets, e.g., ImageNet [35]. However, for the convenience of training and evaluating models, most artificially constructed datasets typically follow the assumption of uniform distribution, which contradicts the real-world data distribution, i.e., longtailed distribution. This deviation between the ideal and real distributions has resulted in many deep models trained on balanced datasets failing to produce satisfactory results in real-world applications, e.g., they only perform well on a few classes and ignore many vulnerable classes [4, 36]. ", "page_idx": 0}, {"type": "image", "img_path": "VpuOuZOVhP/tmp/7497e9b4f74200dd88cbb8fcefdb34497f2092269f1ea20bdec4114946322aad.jpg", "img_caption": ["Figure 1: Different long-tailed data augmentation paradigms. (a) The traditional augmentation paradigm randomly samples augmentations from the fixed strategy. (b) The strategy fixed augmentation paradigm samples augmentations from the fixed strategy according to the data distribution. (c) The LLM-driven augmentation paradigm combines LLMs with long-tailed learning to learn the optimal augmentation strategy. "], "img_footnote": [], "page_idx": 1}, {"type": "text", "text": "", "page_idx": 1}, {"type": "text", "text": "To address the ubiquitous long-tailed problem, researchers have been continuously proposing various carefully designed research paradigms. One popular approach is to rebalance the training data by oversampling the tail classes or undersampling the head classes [6, 13]. However, this approach cannot fundamentally address the problem of insufficient global information, even though the data for the tail classes increases significantly. Another line of work focuses on designing specialized loss functions or reweighting strategies to alleviate the impact of class imbalance [11, 5, 37, 39]. However, these methods either introduce additional computational overhead or require careful manual design. ", "page_idx": 1}, {"type": "text", "text": "Recently, using data augmentation (DA) to improve long-tailed learning has attracted significant attention from researchers and is considered as a viable research paradigm [44]. For example, FASA [46] enhances the tail classes by generating class-level features based on Gaussian priors. Remix [8] achieves this goal through a rebalanced mixup approach. However, these DA-based methods either manipulate high-dimensional information in the feature space or directly apply traditional transformations (e.g., filpping, cropping, and rotation) to expand the training set and generate diverse data, without considering the underlying relationships between data augmentation and class classes. To avoid ineffective augmentation, some studies suggest applying different augmentations to different classes [41]. Typically, CUDA [2] improves the overall performance of models by dynamically adjusting the augmentation intensity for each class during training. Considering the issue of pseudo-boosting in augmentation, DODA [39] allows each class to choose its own suitable augmentation method, thereby avoiding weak classes being sacrificed. Unfortunately, they still have significant limitations: (i) these strategies are often based on manually designed human knowledge and experience, which may be suboptimal for specific data and tasks. (ii) the search space of these strategies is often limited. (iii) these fixed strategies lack flexibility to adapt to changes in the data distribution during the training process. ", "page_idx": 1}, {"type": "text", "text": "To address the above limitations, we leverage the recently popular large language models (LLMs) [29, 24, 45] to provide augmentation suggestions for long-tailed learning. We first designed a feasible and straightforward framework called SimpleLLM, which guides the LLM to generate augmentation strategies and apply them to long-tailed learning by providing specific prompts. Analysis revealed that the augmentation strategies generated by SimpleLLM are comparable to the effectiveness of CUDA [2] and DODA [39]. Figure 1 illustrates the differences between this framework and previous methods. ", "page_idx": 1}, {"type": "text", "text": "Furthermore, inspired by AutoML [17], particularly automated data augmentation [10], we propose LLM-AutoDA, a novel LLM-based long-tailed data augmentation framework. LLM-AutoDA leverages large-scale pretrained models to automatically search for the optimal augmentation strategies suitable for long-tailed data distributions. Specifically, we first define a broad search space that includes augmentation operations and their parameters. Then, we train an augmentation strategy generation model that generates augmentation strategies based on the class-wise statistics of the longtailed data. This strategy is applied to the original imbalanced data to create an augmented dataset, which is used to fine-tune the underlying long-tailed learning model. Importantly, the performance improvement on the validation set serves as a reward signal to update the generation model, enabling the generation of more effective augmentation strategies in the next iteration. This process is repeated until the performance converges or the computational budget is exhausted. ", "page_idx": 2}, {"type": "text", "text": "Compared to previous long-tailed data augmentation methods, LLM-AutoDA offers several advantages: (i) it leverages LLMs to automatically learn augmentation strategies tailored to the characteristics of long-tailed data, without relying on human expertise. (ii) it has a more extensive search space, allowing it to discover more novel strategies. (iii) it can dynamically adjust the augmentation strategies based on performance feedback during the training process, providing flexibility and robustness. Extensive experiments on multiple mainstream long-tailed learning benchmarks demonstrate that LLM-AutoDA outperforms state-of-the-art data augmentation methods and other rebalancing techniques significantly. ", "page_idx": 2}, {"type": "text", "text": "The main contributions of this work are summarized as follows: ", "page_idx": 2}, {"type": "text", "text": "\u2022 New augmentation paradigm: We combine LLMs with long-tail data augmentation for the first time, providing a novel perspective for efficient long-tail learning.   \n\u2022 New automated framework: We propose a novel AutoML framework called LLM-AutoDA, which automates the search for effective data augmentation strategies for long-tailed learning, significantly reducing the cost of manually designing augmentation strategies.   \n\u2022 Compelling empirical results: We conduct extensive experiments on multiple mainstream longtailde benchmarks, demonstrating the superiority of LLM-AutoDA compared to state-of-the-art methods.   \n\u2022 In-depth analysis and insights: We provide detailed analysis and insights into the discovered augmentation strategies, guiding future research in long-tailed learning. ", "page_idx": 2}, {"type": "text", "text": "2 Related Work ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "2.1 Long-tailed Learning (LTL) ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "Various approaches have been proposed to address the long-tailed learning problem, including rebalancing the training data through over-sampling the tail classes [6, 13] or under-sampling the head classes [12, 14], modifying loss functions or adjusting class weights during training [22, 11], and decoupling representation and classifier learning [18]. Among these methods, data augmentation has emerged as a promising solution for long-tailed learning [8, 9, 20, 25, 46]. The key idea is to generate additional samples for the tail classes to alleviate the data imbalance issue. Recent research has attempted to design sophisticated strategies by observing performance changes during the training process to adjust augmentation operator [39] or intensity [2]. However, these methods still rely on hand-crafted augmentation strategies that may not be optimal for the specific long-tailed data and have limited search space for discovering novel and effective strategies. In contrast, LLM-AutoDA automatically learns data augmentation strategies tailored to the long-tailed data distribution without manual design. ", "page_idx": 2}, {"type": "text", "text": "2.2 Large Language Models (LLMs) ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "Large language models (e.g., BERT [19], GPT [29, 30, 3], and T5 [31]) have achieved remarkable success in various natural language processing tasks. They exhibit strong generalization abilities and can be easily fine-tuned for downstream tasks with limited labeled data [16, 28]. Researchers have explored the potential of LLMs in automating algorithm design and implementation, such as generating source code [7], optimizing hyperparameters [42], and designing neural architectures [32]. However, the interaction between large and small language models and its impact on improving the design of small models have been less explored, particularly in the context of data augmentation for long-tailed learning. LLM-AutoDA aims to bridge this gap by harnessing the knowledge and generative capabilities of large language models to discover effective data augmentation strategies tailored to long-tailed distributions automatically. By defining a rich search space of augmentation operations and training an augmentation strategy model conditioned on the class-wise statistics, LLM-AutoDA can generate adaptive and optimized augmentations specifically designed for the given long-tailed data. This novel approach opens up new possibilities for leveraging the interaction between large and small language models to improve the design of machine learning algorithms in various imbalanced learning scenarios. ", "page_idx": 2}, {"type": "text", "text": "", "page_idx": 3}, {"type": "text", "text": "3 $\\mathbf{L}\\mathbf{L}\\mathbf{M}\\times\\mathbf{L}\\mathbf{T}\\mathbf{L}$ : Can LLMs Provide DA Strategies for Long-tailed Learning? ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "In this section, we attempt to analyze whether LLMs can be applied to long-tailed learning and how to implement this learning paradigm. ", "page_idx": 3}, {"type": "text", "text": "SimpleLLM. As shown in Figure 1(b), strategy fixed DA is the current mainstream paradigm for long-tailed data augmentation. It utilizes carefully designed augmentation strategies to dynamically adjust augmentation operators or intensities during the training process, allowing different classes to choose advantageous augmentation methods. In this paradigm, the key step is to design a high-quality augmentation strategy. When dealing with balanced data distributions, we often employ class-independent augmentation strategies, which apply the same data augmentation to all classes. However, as mentioned in DODA [39], when dealing with imbalanced data distributions, this class-independent augmentation strategy can potentially sacrifice certain classes, thus requiring the design of class-dependent augmentation strategies. However, the manual design process for such strategies is highly complex and costly. ", "page_idx": 3}, {"type": "text", "text": "Recent research has shown that LLMs can replace many manually engineered tasks [7]. Inspired by this, we first designed a simple yet efficient paradigm for generating augmentation strategies called SimpleLLM. As shown in Figure 2, we initially constructed a data augmentation-themed ", "page_idx": 3}, {"type": "image", "img_path": "VpuOuZOVhP/tmp/3519f44e4b3525dc815bc7e2cc72d30f96f3a962f736dc42225c3541343762ee.jpg", "img_caption": ["Figure 2: Strategy generation paradigm of SimpleLLM. "], "img_footnote": [], "page_idx": 3}, {"type": "text", "text": "prompt from the perspective of prompt engineering, including task description, algorithm input, algorithm output, parameter interpretation, etc. We then input this prompt into pre-trained LLMs to generate a functional function that conforms to the prompt, i.e., an algorithm implementation containing augmentation strategies. Finally, this augmentation strategy is applied to the conventional training process of long-tailed learning. It is worth noting that this paradigm allows us to generate multiple augmentation strategies suitable for long-tailed learning at a low cost. ", "page_idx": 3}, {"type": "text", "text": "Comparative Analysis. To further validate the effectiveness of the augmentation strategies generated by this paradigm, we conducted experiments on CIFAR-100-LT $({\\mathrm{IR}}{=}100)$ ) dataset. We selected several mainstream long-tailed learning baselines and integrated SimpleLLM with them. In addition, we compared the latest state-of-the-art long-tailed DA methods, CUDA and DODA, under the same settings. The experimental results, as shown in Figure 4, reveal that SimpleLLM achieves acceptable average performance, comparable to CUDA and DODA, indicating that LLMs can be used as generators of augmentation strategies to enhance the performance of long-tailed learning. ", "page_idx": 3}, {"type": "text", "text": "Under this paradigm, we believe that with appropriate prompts, augmentation strategies similar to CUDA and DODA can also be generated by LLMs. In other words, within a search space, we can obtain multiple similar locally optimal strategies. ", "page_idx": 3}, {"type": "image", "img_path": "VpuOuZOVhP/tmp/04c331bb82490ecce9b2fafe175dc35a9e907be0fdd65ce87c499c1515053531.jpg", "img_caption": ["Figure 3: Overview of LLM-AutoDA. LLM-AutoDA leverages large-scale pretrained models to automatically search for the optimal augmentation strategies suitable for long-tailed data distributions. "], "img_footnote": [], "page_idx": 4}, {"type": "text", "text": "4 LLM-AutoDA: A Resourceful Adviser for Long-tailed Learning ", "text_level": 1, "page_idx": 4}, {"type": "text", "text": "4.1 Framework ", "text_level": 1, "page_idx": 4}, {"type": "text", "text": "The overall framework of LLM-AutoDA is illustrated in Figure 3. The framework consists of two interactive modules: the LLM-based data augmentation strategy generation module and the long-tailed learning training and evaluation module. ", "page_idx": 4}, {"type": "text", "text": "LLM-based Data Augmentation Strategy Generation. As shown in Figure 3 (left, pink), to design the DA strategies automatically, LLM-AutoDA incorporates a pre-trained LLM $\\mathcal{L}$ as a search operator. Using prompt engineering techniques, a series of prompt templates are designed to incorporate prior knowledge about data augmentation into the generation process of LLM. LLM generates diverse data augmentation strategies based on these prompts, including both natural language descriptions and Python code implementations. Furthermore, the generated strategies are stored in a strategy pool and interact with the long-tail learning model to search for the optimal data augmentation strategy. ", "page_idx": 4}, {"type": "text", "text": "Long-tailed Learning Training and Evaluation. As shown in Figure 3 (right, pink), LLM-AutoDA utilizes a pretrained long-tailed learning model $\\mathcal{M}$ for fine-tuning on a given long-tailed distributed dataset $\\mathcal{D}$ . At the beginning of each training epoch, the algorithm adaptively determines the DA operator $\\mathbf{A}_{c}$ and DA intensity $\\mathbf{E}_{c}$ for each class based on information such as the accuracy of each class in the previous epoch and historical accuracy. ", "page_idx": 4}, {"type": "text", "text": "The key aspect of LLM-AutoDA lies in the synergy between the DA strategies generated by LLMs and the long-tailed learning model. This close interaction allows the discovered DA strategies to dynamically align with the model training process, effectively enhancing the performance of long-tailed learning in a targeted manner. ", "page_idx": 4}, {"type": "text", "text": "4.2 Strategy Evaluation ", "text_level": 1, "page_idx": 4}, {"type": "text", "text": "To evaluate the performance of candidate data augmentation strategies, we insert them into the model training process, conduct a small amount of additional training on the training set, and then test the accuracy on the validation set, using the accuracy as the ftiness score for the algorithm. Assuming the data augmentation function generated by LLM is denoted as $f_{a u g}$ and the training-testing function is denoted as $\\tau$ , the evaluation process can be represented as follows: ", "page_idx": 4}, {"type": "equation", "text": "$$\nF i t n e s s(f_{a u g})=T(f_{a u g},e_{c k p},N_{f t})\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "where $e_{c k p}$ is the starting checkpoint epoch number and $N_{f t}$ is the epoch number of fine-tune. The function $\\tau$ injects $f_{a u g}$ into the training flow: ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\tau(f_{a u g},e_{c k p},N_{f t})=A c c_{v a l}(F i n e-t u n e(f_{a u g},\\mathcal{D}_{t r a i n},e_{c k p},N_{f t}))}\\end{array}\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "The Finetune function starts training from the $e_{c k p}$ checkpoint and performs $N_{f t}$ epochs of training on the training set $\\mathcal{D}_{t r a i n}$ . At the beginning of each epoch, it dynamically selects data augmentation methods for each class using faug. ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\mathbf{A}_{c}^{(t)},\\mathbf{E}_{c}^{(t)}=f_{a u g}(\\mathbf{W}_{c}^{(t-1)},\\mathbf{a}_{c}^{(t-1)},\\mathbf{H}_{c}^{(t-1)},\\mathbf{A}_{c}^{(t-1)},\\mathbf{E}_{c}^{(t-1)},t)\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "Here, $\\mathbf{A}_{c}^{(t)}$ represents the DA selection matrix for class $c$ at time $t$ , $\\mathbf{E}_{c}^{(t)}$ represents the corresponding augmentation intensity, W(ct\u22121) represents the weights of each augmentation method on class $c$ from the previous time step, a(ct\u22121) represents the accuracy of class $c$ at time $t-1$ , and $\\mathbf{H}_{c}^{(t-1)}$ represents the historical accuracy of class $c$ when using different augmentation methods in the previous step. ", "page_idx": 5}, {"type": "text", "text": "After training, the model is evaluated using the no augmented validation set $\\mathcal{D}_{v a l}$ , and the overall accuracy $A c c_{v a l}$ is obtained as the fitness score for $f_{a u g}$ . ", "page_idx": 5}, {"type": "equation", "text": "$$\nF i t n e s s(f_{a u g})=A c c_{v a l}(F i n e t u n e(f_{a u g},\\mathcal{D}_{t r a i n},e_{c k p},N_{f t}),\\mathcal{D}_{v a l})\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "A higher fitness score indicates better performance of the algorithm on long-tailed distributions. By injecting candidate algorithms into the real training process and evaluating them on the validation set, we can accurately and efficiently measure their actual ability to address the long-tailed problem. ", "page_idx": 5}, {"type": "text", "text": "4.3 LLM-based Search Operator ", "text_level": 1, "page_idx": 5}, {"type": "text", "text": "LLM-AutoDA leverages Pretrained Language Models (PLMs) to automatically generate data augmentation algorithms. To guide the PLM in generating algorithms that meet specific requirements, we employ prompt engineering techniques and carefully design a series of prompts. By incorporating task descriptions, input-output formats, novelty requirements, and other prior knowledge through prompts, we can constrain the generation process of the PLM within the desired search space. We design the following three types of search operators, corresponding to different prompt templates: ", "page_idx": 5}, {"type": "text", "text": "\u2022 Initialization operator $I$ : Based on the task description prompt $P_{t a s k}$ and the knowledge base of data augmentation $\\kappa$ , a set of randomly initialized population algorithms $A_{i}^{(0)}{}_{i=1}^{N}$ i i=1 is generated. ", "page_idx": 5}, {"type": "text", "text": "\u2022 Crossover operator $E$ : Building upon $P_{t a s k}$ , $N_{p}$ parent algorithms $A_{i}^{(t)}i=1^{N_{p}}$ from the current population are used as references, along with the incorporation of knowledge base $\\kappa$ . The PLM is required to generate $N_{e}$ new algorithms $A_{\\underline{{{j}}},}^{(t)}j=1^{N_{e}}$ that are different in both form and logic from the existing algorithms, thereby expanding the search space. ", "page_idx": 5}, {"type": "text", "text": "\u2022 Mutation operator M: Based on Ptask, Nm individuals Ai(t)iN=m1 are selected from the current population, and local improvement directions are provided. The PLM is tasked with generating a mutated algorithm $\\hat{A}_{i}^{(t)}$ for each $A_{i}^{(t)}$ within its neighborhood for further exploration. ", "page_idx": 5}, {"type": "text", "text": "Taking the crossover operator $E$ as an example, its prompt $P_{E}$ can be represented as follows: ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathrm{\\Sigma}_{E}(P_{t a s k},\\{A_{i}^{(t)}\\}_{i=1}^{N_{p}},K,D_{f u n c})=P_{t a s k}+P_{r e f}(\\{A_{i}^{(t)}\\}_{i=1}^{N_{p}})+P_{k n o w}(K)+P_{d i f f}+P_{f o r m a t}(D_{f u n c})}\\end{array}\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "where $P_{t a s k}$ represents the task description, $A_{i}i=1^{N}$ represents $N$ parent algorithms, and $D f u n c$ represents the domain of the objective function. $P_{r e f}$ formats the parent algorithms into reference code, $P_{d i f f}$ requires the generation of new algorithms that are completely different from the existing ones, and $P_{f o r m a t}$ specifies the input and output of the objective function. ", "page_idx": 5}, {"type": "text", "text": "Once we have obtained the prompt $P_{E}$ , we input it into the pretrained language model $\\mathcal{L}$ , and as a result, we obtain $N_{e}$ new crossover algorithms. ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\{A_{j}^{(t)}\\}_{j=1}^{N_{e}}=\\mathcal{L}(P_{E}(P_{t a s k},\\{A_{i}^{(t)}\\}_{i=1}^{N_{p}},K,D_{f u n c}))\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "Each $A_{j}^{(t)}$ typically consists of a natural language description of the algorithm and its corresponding Python code implementation. Similarly, the prompts $P_{I}$ and $P_{M}$ for the initialization operator $I$ and the mutation operator $M$ can be constructed in a similar manner, with the main difference lying in the introduced prior information. ", "page_idx": 5}, {"type": "text", "text": "5 Experiments ", "text_level": 1, "page_idx": 6}, {"type": "text", "text": "5.1 Experimental Settings ", "text_level": 1, "page_idx": 6}, {"type": "text", "text": "Datasets and Metrics. Like most long-tailed learning methods, we conducted experiments on several mainstream long-tailed learning datasets, including CIFAR-100-LT [5], ImageNet-LT [26], and iNaturalist 2018 [38]. Among them, CIFAR-100-LT is the long-tailed version of CIFAR-100, with various imbalance ratios. To validate the effectiveness of LLM-AutoDA in addressing the long-tailed problem, we selected three testing environments: 50, 100, 200. Compared to CIFAR-100-LT, both ImageNetLT and iNaturalist 2018 have more classes and larger data sizes. It is worth noting that, similar to CIFAR-100-LT, ImageNet-LT is a long-tailed version artificially constructed from the well-known ImageNet [35] dataset. On the other hand, iNaturalist 2018 is a naturally occurring long-tailed dataset collected from the real world. We used the official complete versions of these datasets, and detailed information about the datasets is provided in Appendix B. We use Top-1 accuracy as the evaluation metric and provide the performance of subsets based on the class divisions provided by the official datasets. ", "page_idx": 6}, {"type": "text", "text": "Baselines. Following the settings of CUDA [2], we considered various research theories when selecting the baselines. In addition to the classic cross-entropy loss (CE) [15], we also validated different data augmentation methods on other baselines, such as loss-based re-balancing methods: CE-DRW [5], LDAM-DRW [5], Balanced Softmax (BS) [33], and model-based re-balancing methods: RIDE [43], BCL [48]. In terms of data augmentation methods, we compared LLM-AutoDA with the latest SOTA methods: CUDA [2] and DODA [39]. We observed their advantages and disadvantages by combining these DA methods ", "page_idx": 6}, {"type": "image", "img_path": "VpuOuZOVhP/tmp/5ea4b5a13918e2b8ea5e9462eeaab3741baab616ebe283abf906422fad00d48e.jpg", "img_caption": [], "img_footnote": [], "page_idx": 6}, {"type": "text", "text": "Figure 4: Average accuracy $(\\%)$ on CIFAR-100-LT dataset (Imbalance ratio $\\mathsf{=}100$ ) with CUDA and DODA. SimpleLLM is comparable to the effectiveness of CUDA and DODA when combined with long-tailed learning baselines. ", "page_idx": 6}, {"type": "text", "text": "with the long-tailed baselines. The relevant descriptions of the baselines are also provided in Appendix A. ", "page_idx": 6}, {"type": "text", "text": "Implementation Details. All our models are implemented based on PyTorch [27]. We trained and evaluated the models on 2 NVIDIA Tesla A100 GPUs and reported the experimental results. We utilized the powerful gpt-3.5-turbo for strategy generation and employed AEL [23] for strategy optimization. In the experimental process, we first trained the models for 50 epochs without using augmentation strategies, then continued training with augmentation strategies for an additional 20 epochs, employing a novel evaluation mechanism. Additionally, during the final evaluation stage of long-tailed learning, we adopted the same settings as DODA [39] for all baseline methods and our approach. ", "page_idx": 6}, {"type": "text", "text": "5.2 Comparison with the State-of-the-art ", "text_level": 1, "page_idx": 6}, {"type": "text", "text": "Results on CIFAR-100-LT. We first evaluated LLM-AutoDA and other long-tailed data augmentation (DA) methods on CIFAR-100-LT dataset $\\mathrm{J}\\!\\mathrm{R}=50$ , 100). The experimental results are shown in Table 1. From the results, it can be observed that both SimpleLLM and the improved version LLM-AutoDA significantly improve the global accuracy of the model compared to the original long-tailed learning baseline, achieving robust improvements. In the horizontal comparison with long-tailed DA methods CUDA [2] and DODA [39], as analyzed earlier, SimpleLLM achieves comparable performance to the former through a non-optimized way. This indicates that within our framework, a locally optimal strategy can replace a carefully designed complex strategy. In addition, LLM-AutoDA brings more significant and stable gains, reflecting that existing long-tailed DA methods may be suboptimal strategies within our augmentation strategy space, while LLM-AutoDA can provide the optimal augmentation strategy through continuous optimization. To evaluate the effectiveness of LLM-AutoDA in highly imbalanced scenarios, we adjusted the imbalance ratio to 200 and conducted comparative experiments in Appendix D. ", "page_idx": 6}, {"type": "table", "img_path": "VpuOuZOVhP/tmp/04145c9c9b5eae907b11fe896ae93a34c58cfe93c38a9a560bc93dc345ca2019.jpg", "table_caption": ["Table 1: Accuracy $(\\%)$ on CIFAR-100-LT dataset (Imbalance ratio $\\scriptstyle=\\{50,\\ 100\\})$ with SOTA DA methods. Blod indicates the best performance while underline indicates the second best. $(+)$ and (-) indicate the relative gain. "], "table_footnote": [], "page_idx": 7}, {"type": "image", "img_path": "VpuOuZOVhP/tmp/5af85c215866aad16c6943a15898da525f741d1e0c693a674f0dac90c26b695f.jpg", "img_caption": ["Figure 5: Impact of different LLMs on Figure 6: Impact of differ- Figure 7: Impact of differthe performance of long-tailed learn- ent population numbers in the ent population numbers in the ing models. mutation prompts. crossover prompts. "], "img_footnote": [], "page_idx": 7}, {"type": "text", "text": "", "page_idx": 7}, {"type": "text", "text": "Results on ImageNet-LT and iNaturalist 2018. We also conducted comparative experiments on large-scale benchmark datasets, ImageNet-LT and iNaturalist 2018. As expected, different long-tailed learning methods showed significant performance improvement when integrated with LLM-AutoDA. Similar to the highly imbalanced setting mentioned earlier, both of these large-scale datasets are inherently highly imbalanced. Therefore, the augmentation strategies provided by LLMAutoDA can consistently demonstrate superiority in various imbalanced environments. Importantly, LLM-AutoDA does not rely on meticulous manual design, which reduces the optimization cost on large-scale datasets. ", "page_idx": 7}, {"type": "table", "img_path": "VpuOuZOVhP/tmp/9b983b3a54242166a14fd05e11770b2525d4bba14771b3ca5b8610c3095bd5c0.jpg", "table_caption": ["Table 2: Accuracy $(\\%)$ on ImageNet-LT and iNaturalist 2018 datasets with SOTA DA methods. Blod indicates the best performance while underline indicates the second best. $(+)$ and (-) indicate the relative gain. "], "table_footnote": [], "page_idx": 8}, {"type": "text", "text": "5.3 More Analysis and Discussion ", "text_level": 1, "page_idx": 8}, {"type": "text", "text": "Do different LLMs produce differentiated effects? In the aforementioned experiments, we used GPT-3.5 [3] as the LLM to respond to the designed prompts. To analyze whether LLM-AutoDA is dependent on specific LLM models (e.g., GPT-3.5), we replaced the LLM model in LLM-AutoDA with other popular methods such as GPT-4 [1] and Claude-3-Opus, and conducted experiments. The experimental results, shown in Figure 5, demonstrate that all three LLMs exhibit consistent performance trends when selecting augmentation strategies in different score ranges. For instance, they all show high performance near the augmentation strategies with scores around 12, while augmentation strategies with excessively high scores lead to performance degradation across the three LLMs due to insufficient diversity. ", "page_idx": 8}, {"type": "text", "text": "Do different population numbers have an impact on performance? In LLM-AutoDA, we employed two different types of prompts: crossover prompts and mutation prompts. Crossover prompts involve transforming multiple parent populations into a single population, while mutation prompts replace the current augmentation strategy with an equivalent one. ", "page_idx": 8}, {"type": "text", "text": "Throughout the iterative process of framework evolution, when performing crossover and mutation operations, we need to specify the number of populations generated each time. Figures 6 and 7 illustrate the scores of strategies generated by two different mutation prompts (m1, m2) and two different crossover prompts (e1, e2), respectively. It can be observed that different prompts exhibit consistent trends in score variations. Particularly, compared to e1, e2 demonstrates a higher score variance, which indirectly reflects the bias in its prompt content. ", "page_idx": 8}, {"type": "image", "img_path": "VpuOuZOVhP/tmp/64a5ee1d406c31305fa4fa8f3837331895743aa9756b58f37a04fca3afcd4fe2.jpg", "img_caption": ["Figure 8: Visualization of the process of finding the optimal solution for different augmentation paradigms. "], "img_footnote": [], "page_idx": 8}, {"type": "text", "text": "Why are fixed strategy methods often local optima? Strategy ", "text_level": 1, "page_idx": 8}, {"type": "text", "text": "fixed data augmentation methods, such as CUDA and DODA, aim to adapt to long-tailed distributions by dynamically adjusting the augmentation operators or intensities. However, their focus is limited. We visualized the loss variations when searching for optimal augmentation strategies using different paradigms. From Figure 8, it can be observed that CUDA (i.e., green plane) and DODA (i.e., red plane) can only search for local optimal strategies on a single plane, while LLM-AutoDA is capable of flexibly searching for the points with the lowest loss across the entire curved surface to obtain a global optimal solution. ", "page_idx": 8}, {"type": "text", "text": "", "page_idx": 9}, {"type": "text", "text": "6 Conclusion ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "Existing paradigms for long-tailed learning have partially alleviated the long-tailed problem but still have limitations. To address this, this paper presents an LLM-driven long-tailed data augmentation framework called LLM-AutoDA, which utilizes large-scale pre-trained language models to automatically search for data augmentation strategies optimized for long-tailed data distributions. Experiments on multiple mainstream benchmark datasets demonstrate that LLM-AutoDA outperforms state-of-the-art methods. ", "page_idx": 9}, {"type": "text", "text": "Acknowledgements ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "This work was supported by the Natural Science Foundation of China Youth Project (No. 62402472), the Natural Science Foundation of Jiangsu Province of China Youth Project (No. BK20240461), the Research Grants Council of the Hong Kong Special Administrative Region, China (GRF Project No. CityU 11215723), National Natural Science Foundation of China (No.62072427, No.12227901), the Project of Stable Support for Youth Team in Basic Research Field, CAS (No.YSBR-005), and Academic Leaders Cultivation Program, USTC. ", "page_idx": 9}, {"type": "text", "text": "References ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "[1] Josh Achiam, Steven Adler, Sandhini Agarwal, Lama Ahmad, Ilge Akkaya, Florencia Leoni Aleman, Diogo Almeida, Janko Altenschmidt, Sam Altman, Shyamal Anadkat, et al. Gpt-4 technical report. arXiv preprint arXiv:2303.08774, 2023.   \n[2] Sumyeong Ahn, Jongwoo Ko, and Se-Young Yun. Cuda: Curriculum of data augmentation for long-tailed recognition. In The Eleventh International Conference on Learning Representations, 2023. [3] Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, et al. Language models are few-shot learners. Advances in neural information processing systems, 33:1877\u20131901, 2020. [4] Mateusz Buda, Atsuto Maki, and Maciej A Mazurowski. A systematic study of the class imbalance problem in convolutional neural networks. Neural networks, 106:249\u2013259, 2018.   \n[5] Kaidi Cao, Colin Wei, Adrien Gaidon, Nikos Arechiga, and Tengyu Ma. Learning imbalanced datasets with label-distribution-aware margin loss. Advances in neural information processing systems, 32, 2019.   \n[6] Nitesh V Chawla, Kevin W Bowyer, Lawrence O Hall, and W Philip Kegelmeyer. Smote: synthetic minority over-sampling technique. Journal of artificial intelligence research, 16:321\u2013 357, 2002. [7] Mark Chen, Jerry Tworek, Heewoo Jun, Qiming Yuan, Henrique Ponde de Oliveira Pinto, Jared Kaplan, Harri Edwards, Yuri Burda, Nicholas Joseph, Greg Brockman, et al. Evaluating large language models trained on code. arXiv preprint arXiv:2107.03374, 2021.   \n[8] Hsin-Ping Chou, Shih-Chieh Chang, Jia-Yu Pan, Wei Wei, and Da-Cheng Juan. Remix: rebalanced mixup. In European Conference on Computer Vision, pages 95\u2013110. Springer, 2020.   \n[9] Peng Chu, Xiao Bian, Shaopeng Liu, and Haibin Ling. Feature space augmentation for longtailed data. In European Conference on Computer Vision, pages 694\u2013710. Springer, 2020.   \n[10] Ekin D Cubuk, Barret Zoph, Dandelion Mane, Vijay Vasudevan, and Quoc V Le. Autoaugment: Learning augmentation strategies from data. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 113\u2013123, 2019.   \n[11] Yin Cui, Menglin Jia, Tsung-Yi Lin, Yang Song, and Serge Belongie. Class-balanced loss based on effective number of samples. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition, pages 9268\u20139277, 2019.   \n[12] Chris Drummond, Robert C Holte, et al. C4. 5, class imbalance, and cost sensitivity: why under-sampling beats over-sampling. In Workshop on learning from imbalanced datasets II, volume 11, 2003.   \n[13] Hui Han, Wen-Yuan Wang, and Bing-Huan Mao. Borderline-smote: a new over-sampling method in imbalanced data sets learning. In International conference on intelligent computing, pages 878\u2013887. Springer, 2005.   \n[14] Haibo He and Edwardo A Garcia. Learning from imbalanced data. IEEE Transactions on knowledge and data engineering, 21(9):1263\u20131284, 2009.   \n[15] Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep residual learning for image recognition. In Proceedings of the IEEE conference on computer vision and pattern recognition, pages 770\u2013778, 2016.   \n[16] Jeremy Howard and Sebastian Ruder. Universal language model fine-tuning for text classification. arXiv preprint arXiv:1801.06146, 2018.   \n[17] Frank Hutter, Lars Kotthoff, and Joaquin Vanschoren. Automated machine learning: methods, systems, challenges. Springer Nature, 2019.   \n[18] Bingyi Kang, Saining Xie, Marcus Rohrbach, Zhicheng Yan, Albert Gordo, Jiashi Feng, and Yannis Kalantidis. Decoupling representation and classifier for long-tailed recognition. arXiv preprint arXiv:1910.09217, 2019.   \n[19] Jacob Devlin Ming-Wei Chang Kenton and Lee Kristina Toutanova. Bert: Pre-training of deep bidirectional transformers for language understanding. In Proceedings of NAACL-HLT, pages 4171\u20134186, 2019.   \n[20] Jaehyung Kim, Jongheon Jeong, and Jinwoo Shin. M2m: Imbalanced classification via majorto-minor translation. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition, pages 13896\u201313905, 2020.   \n[21] Alex Krizhevsky, Ilya Sutskever, and Geoffrey E Hinton. Imagenet classification with deep convolutional neural networks. Advances in neural information processing systems, 25, 2012.   \n[22] Tsung-Yi Lin, Priya Goyal, Ross Girshick, Kaiming He, and Piotr Doll\u00e1r. Focal loss for dense object detection. In Proceedings of the IEEE international conference on computer vision, pages 2980\u20132988, 2017.   \n[23] Fei Liu, Xialiang Tong, Mingxuan Yuan, and Qingfu Zhang. Algorithm evolution using large language model. arXiv preprint arXiv:2311.15249, 2023.   \n[24] Fei Liu, Tong Xialiang, Mingxuan Yuan, Xi Lin, Fu Luo, Zhenkun Wang, Zhichao Lu, and Qingfu Zhang. Evolution of heuristics: Towards efficient automatic algorithm design using large language model. In Forty-first International Conference on Machine Learning, 2024.   \n[25] Jialun Liu, Yifan Sun, Chuchu Han, Zhaopeng Dou, and Wenhui Li. Deep representation learning on long-tailed data: A learnable embedding augmentation perspective. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition, pages 2970\u20132979, 2020.   \n[26] Ziwei Liu, Zhongqi Miao, Xiaohang Zhan, Jiayun Wang, Boqing Gong, and Stella X Yu. Largescale long-tailed recognition in an open world. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 2537\u20132546, 2019.   \n[27] Adam Paszke, Sam Gross, Soumith Chintala, Gregory Chanan, Edward Yang, Zachary DeVito, Zeming Lin, Alban Desmaison, Luca Antiga, and Adam Lerer. Automatic differentiation in pytorch. In Advances in Neural Information Processing Systems Workshops, 2017.   \n[28] ME Peters, M Neumann, M Iyyer, M Gardner, C Clark, K Lee, and L Zettlemoyer. Deep contextualized word representations. arxiv. org. arXiv preprint arXiv:1802.05365, 2018.   \n[29] Alec Radford, Karthik Narasimhan, Tim Salimans, Ilya Sutskever, et al. Improving language understanding by generative pre-training. 2018.   \n[30] Alec Radford, Jeffrey Wu, Rewon Child, David Luan, Dario Amodei, Ilya Sutskever, et al. Language models are unsupervised multitask learners. OpenAI blog, 1(8):9, 2019.   \n[31] Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael Matena, Yanqi Zhou, Wei Li, and Peter J Liu. Exploring the limits of transfer learning with a unified text-to-text transformer. Journal of machine learning research, 21(140):1\u201367, 2020.   \n[32] Md Hafizur Rahman and Prabuddha Chakraborty. Lemo-nade: Multi-parameter neural architecture discovery with llms. arXiv preprint arXiv:2402.18443, 2024.   \n[33] Jiawei Ren, Cunjun Yu, Xiao Ma, Haiyu Zhao, Shuai Yi, et al. Balanced meta-softmax for longtailed visual recognition. Advances in neural information processing systems, 33:4175\u20134186, 2020.   \n[34] Shaoqing Ren, Kaiming He, Ross Girshick, and Jian Sun. Faster r-cnn: Towards real-time object detection with region proposal networks. Advances in neural information processing systems, 28, 2015.   \n[35] Olga Russakovsky, Jia Deng, Hao Su, Jonathan Krause, Sanjeev Satheesh, Sean Ma, Zhiheng Huang, Andrej Karpathy, Aditya Khosla, Michael Bernstein, et al. Imagenet large scale visual recognition challenge. International journal of computer vision, 115(3):211\u2013252, 2015.   \n[36] Jiang-Xin Shi, Tong Wei, Zhi Zhou, Jie-Jing Shao, Xin-Yan Han, and Yu-Feng Li. Longtail learning with foundation model: Heavy fine-tuning hurts. In Proceedings of the 41st International Conference on Machine Learning, pages 45014\u201345039, 2024.   \n[37] Jingru Tan, Changbao Wang, Buyu Li, Quanquan Li, Wanli Ouyang, Changqing Yin, and Junjie Yan. Equalization loss for long-tailed object recognition. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition, pages 11662\u201311671, 2020.   \n[38] Grant Van Horn, Oisin Mac Aodha, Yang Song, Yin Cui, Chen Sun, Alex Shepard, Hartwig Adam, Pietro Perona, and Serge Belongie. The inaturalist species classification and detection dataset. In Proceedings of the IEEE conference on computer vision and pattern recognition, pages 8769\u20138778, 2018.   \n[39] Binwu Wang, Pengkun Wang, Wei Xu, Xu Wang, Yudong Zhang, Kun Wang, and Yang Wang. Kill two birds with one stone: Rethinking data augmentation for deep long-tailed learning. In The Twelfth International Conference on Learning Representations, 2024.   \n[40] Pengkun Wang, Chuancai Ge, Zhengyang Zhou, Xu Wang, Yuantao Li, and Yang Wang. Joint gated co-attention based multi-modal networks for subregion house price prediction. IEEE Transactions on Knowledge & Data Engineering, 35(02):1667\u20131680, 2023.   \n[41] Pengkun Wang, Xu Wang, Binwu Wang, Yudong Zhang, Lei Bai, and Yang Wang. Long-tailed time series classification via feature space rebalancing. In International Conference on Database Systems for Advanced Applications, pages 151\u2013166. Springer, 2023.   \n[42] Siyin Wang, Shimin Li, Tianxiang Sun, Jinlan Fu, Qinyuan Cheng, Jiasheng Ye, Junjie Ye, Xipeng Qiu, and Xuanjing Huang. Llm can achieve self-regulation via hyperparameter aware generation. arXiv preprint arXiv:2402.11251, 2024.   \n[43] Xudong Wang, Long Lian, Zhongqi Miao, Ziwei Liu, and Stella Yu. Long-tailed recognition by routing diverse distribution-aware experts. In International Conference on Learning Representations, 2021.   \n[44] Wei Xu, Pengkun Wang, Zhe Zhao, Binwu Wang, Xu Wang, and Yang Wang. When imbalance meets imbalance: Structure-driven learning for imbalanced graph classification. In Proceedings of the ACM on Web Conference 2024, pages 905\u2013913, 2024.   \n[45] Shunyu Yao, Fei Liu, Xi Lin, Zhichao Lu, Zhenkun Wang, and Qingfu Zhang. Multi-objective evolution of heuristic using large language model. arXiv preprint arXiv:2409.16867, 2024.   \n[46] Yuhang Zang, Chen Huang, and Chen Change Loy. Fasa: Feature augmentation and sampling adaptation for long-tailed instance segmentation. In Proceedings of the IEEE/CVF international conference on computer vision, pages 3457\u20133466, 2021.   \n[47] Guibin Zhang, Kun Wang, Wei Huang, Yanwei Yue, Yang Wang, Roger Zimmermann, Aojun Zhou, Dawei Cheng, Jin Zeng, and Yuxuan Liang. Graph lottery ticket automated. In The Twelfth International Conference on Learning Representations, 2024.   \n[48] Jianggang Zhu, Zheng Wang, Jingjing Chen, Yi-Ping Phoebe Chen, and Yu-Gang Jiang. Balanced contrastive learning for long-tailed visual recognition. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 6908\u20136917, 2022. ", "page_idx": 9}, {"type": "text", "text": "", "page_idx": 10}, {"type": "text", "text": "", "page_idx": 11}, {"type": "text", "text": "", "page_idx": 12}, {"type": "text", "text": "Appendix LLM-AutoDA: Large Language Model-Driven Automatic Data Augmentation for Long-tailed Problems ", "text_level": 1, "page_idx": 13}, {"type": "text", "text": "The content of the Appendix is summarized as follows: ", "page_idx": 13}, {"type": "text", "text": "1) in Sec. A, we summarize long-tailed learning baselines and data augmentation baselines.   \n2) in Sec. B, we demonstrate the details of datasets.   \n3) in Sec. C, We present the pseudocode corresponding to the LLM-AutoDA.   \n4) in Sec. D, we illustrate more detailed empirical results and analyses.   \n5) in Sec. E, we show the prompts used in our framework.   \n6) in Sec. F, we discuss the limitations of our framework.   \n7) in Sec. G, we discuss the broader impacts of our framework. ", "page_idx": 13}, {"type": "text", "text": "A Baselines Details ", "text_level": 1, "page_idx": 13}, {"type": "text", "text": "Cross-Entropy Loss (CE) [15] As a classic classification loss function, cross-entropy (CE) is widely used in both balanced and imbalanced data distributions, directly computing the loss based on the true labels of samples and the predicted probability distributions of the model. Although simple and effective, CE tends to overly focus on head classes while overlooking tail classes in long-tailed scenarios. ", "page_idx": 13}, {"type": "text", "text": "Loss-based Re-balancing Strategies ", "text_level": 1, "page_idx": 13}, {"type": "text", "text": "\u2022 CE-DRW [5] combines re-weighting of training samples based on the inverse class frequency and gradient reversal that considers class frequencies during backpropagation, enhancing the focus on tail classes.   \n\u2022 LDAM-DRW [5] further improves upon CE-DRW by introducing learnable amplification factors to automatically adjust the weight of each class, better optimizing the inter-class balance.   \n\u2022 Balanced Softmax (BS) [33] re-weights the logits based on the prior class probabilities, giving higher attention to tail classes. ", "page_idx": 13}, {"type": "text", "text": "Model-based Re-balancing Strategies ", "text_level": 1, "page_idx": 13}, {"type": "text", "text": "\u2022 RIDE [43] ensembles multiple expert models, each focusing on different class distributions, and adaptively combines their outputs based on the test data to adapt to distribution shifts. ", "page_idx": 13}, {"type": "text", "text": "\u2022 BCL [48] for CNN classifiers, optimizes the losses of head and tail components while considering intra-class variance and inter-class distances to enhance the separability of classification boundaries. ", "page_idx": 13}, {"type": "text", "text": "Data Augmentation Methods ", "text_level": 1, "page_idx": 13}, {"type": "text", "text": "\u2022 CUDA [2] proposes a contrastive learning-based automatic data augmentation method that generates transformations during training, significantly boosting performance in long-tailed scenarios. ", "page_idx": 13}, {"type": "text", "text": "\u2022 DODA [39] dynamically adjusts the data augmentation strategies for different classes from a distribution perspective, ensuring sufficient augmentation for tail classes while avoiding overaugmentation for head classes. ", "page_idx": 13}, {"type": "text", "text": "The above baseline methods offer unique insights into addressing long-tailed distributions, laying the foundation for our research. The experimental section will comprehensively compare and analyze the performance of these methods across different datasets and evaluation metrics. ", "page_idx": 13}, {"type": "text", "text": "B Evaluation Datasets ", "text_level": 1, "page_idx": 13}, {"type": "text", "text": "To comprehensively evaluate the effectiveness of our proposed method, we conduct experiments on four representative long-tailed datasets: CIFAR100-LT, ImageNet-LT, iNaturalist 2018, and Places365-LT. These datasets cover diverse domains and exhibit varying degrees of class imbalance, providing a comprehensive and challenging testbed for long-tailed learning algorithms. ", "page_idx": 13}, {"type": "table", "img_path": "VpuOuZOVhP/tmp/2de5551446f1ef2ee8752d5b06eaf95d730d1b4a3eb66eda7f0aef1d6637c656.jpg", "table_caption": ["Table 3: Statistics of the long-tailed datasets. "], "table_footnote": [], "page_idx": 14}, {"type": "text", "text": "CIFAR100-LT [5] is the long-tailed version of the renowned CIFAR100 dataset, comprising 60,000 $32\\times32$ color images across 100 classes. The long-tailed distribution is induced by exponentially decreasing the number of samples per class, with a maximum imbalance ratio of 100. ", "page_idx": 14}, {"type": "text", "text": "ImageNet-LT [26] is a long-tailed subset of the large-scale ImageNet dataset, containing over 115,000 images spanning 1,000 classes. The class cardinalities follow a Pareto distribution with $\\alpha=6$ , leading to a maximum imbalance ratio of 256. ", "page_idx": 14}, {"type": "text", "text": "iNaturalist 2018 [38] is a real-world dataset reflecting the long-tailed distribution in nature, comprising approximately 450,000 images across 8,142 species categories. Due to the drastic variation in the number of images per species, this dataset has a maximum imbalance ratio of 500, posing a significant challenge with extreme class imbalance and high intra-class variation. ", "page_idx": 14}, {"type": "text", "text": "C Pseudocode ", "text_level": 1, "page_idx": 14}, {"type": "text", "text": "Algorithm 1: LLM-AutoDA: Automatic Data Augmentation with Language Models   \n1: Input:   \n2: - Long-tailed datasets $\\mathcal{D}_{t r a i n},\\mathcal{D}_{v a l}$   \n3: - Pretrained language model $\\mathcal{L}$   \n4: - Initial data augmentation policies $\\kappa$   \n5: - Long-tailed learning model $f_{\\theta}$ with parameters $\\theta$   \n6: Output:   \n7: - Optimal data augmentation algorithm $A^{*}$   \n8: - Final model $f_{\\theta}$   \n9: Define task description prompt $\\mathcal{P}_{t a s k}$   \n10: Define exploration operator prompt template $\\mathcal{P}_{E}$   \n11: Define mutation operator prompt template $\\mathcal{P}_{M}$   \n12: Initialize algorithm population $\\{\\mathcal{A}_{i}^{(0)}\\}_{i=1}^{N}=\\mathrm{INITIALIZE}(\\mathcal{L},\\mathcal{P}_{t a s k},\\mathcal{K})$   \n13: for each generation $t$ do   \n14: $\\{\\boldsymbol{A}_{i}^{(t)}\\}_{i=1}^{\\bar{N}_{p}}=\\mathrm{SELECT}(\\{\\boldsymbol{A}_{i}^{(t-1)}\\}_{i=1}^{N})$ {Select parents}   \n15: $\\{\\mathcal{A}_{i}^{(t)}\\}_{i=1}^{N_{e}}=\\mathrm{ExPLORE}(\\mathcal{L},\\mathcal{P}_{E},\\{\\mathcal{A}_{i}^{(t)}\\}_{i=1}^{N_{p}},\\mathcal{K})\\ \\{\\mathrm{Explore}\\}$   \n16: $\\{\\hat{\\mathcal{A}}_{i}^{(t)}\\}_{i=1}^{N_{m}}=\\mathrm{MUTATE}(\\mathcal{L},\\mathcal{P}_{M},\\{\\mathcal{A}_{i}^{(t)}\\}_{i=1}^{N_{m}},K)$ {Mutate}   \n17: $\\{\\mathcal{A}_{i}^{(t)}\\}_{i=1}^{N}=\\{\\mathcal{A}_{i}^{(t)}\\}_{i=1}^{N_{p}}\\cup\\{\\mathcal{A}_{j}^{(t)}\\}_{j=1}^{N_{e}}\\cup\\{\\hat{\\mathcal{A}}_{i}^{(t)}\\}_{i=1}^{N_{m}}$   \n18: for each $\\mathcal{A}_{i}^{(t)}$ do   \n19: $f i t n e s s_{i}^{(t)}=\\operatorname{EvALUATE}(A_{i}^{(t)},f_{\\theta},\\mathcal{D}_{t r a i n},\\mathcal{D}_{v a l},e_{c k p},N_{f t})$   \n20: end for   \n21: end for   \n22: $A^{*}=_{A_{i}}$ fitnessi {Select algorithm with highest fitness}   \n23: return $A^{*}$ , $f_{\\theta}$   \n$=\\!0$ ", "page_idx": 14}, {"type": "text", "text": "where INITIALIZE uses an initialization operator to generate a random population of algorithms, EXPLORE and MUTATE correspond to the exploration and mutation operators respectively. In each generation, a subset of individuals is selected from the previous generation as parents, then new algorithms are generated using the exploration and mutation operators, and merged into the population. For each candidate algorithm, EVALUATE is called to compute its fitness: ", "page_idx": 14}, {"type": "table", "img_path": "VpuOuZOVhP/tmp/ceab3aafc07231607449766f7b1d56cfdd4deb37367d134e828330f937a38aa2.jpg", "table_caption": [], "table_footnote": [], "page_idx": 15}, {"type": "text", "text": "FINETUNE starts from the $e_{c k p}$ -th checkpoint and incrementally trains for $N_{f t}$ epochs on the training set, with the algorithm $\\boldsymbol{\\mathcal{A}}$ dynamically selecting augmentations for each class: ", "page_idx": 15}, {"type": "text", "text": "function $\\mathrm{FINETUNE}(\\mathcal{A},f_{\\theta},\\mathcal{D}_{t r a i n},e_{c k p},N_{f t})$ : Load checkpoint of f\u03b8 at epoch eckp   \nfor $e=e_{c k p}$ to $e_{c k p}+N_{f t}$ do for each class $c$ do $\\mathbf{\\mathcal{A}}_{c}^{(e)},\\boldsymbol{\\mathcal{E}}_{c}^{(e)}=\\mathcal{A}(\\mathbf{W}_{c}^{(e-1)},\\mathbf{H}_{c}^{(e-1)},a c c_{c}^{(e-1)},\\mathcal{A}_{c}^{(e-1)},\\mathcal{E}_{c}^{(e-1)},e)$ end for Train $f_{\\theta}$ for one epoch on $\\mathcal{D}_{t r a i n}$ using $\\{\\mathcal{A}_{c}^{(e)},\\mathcal{E}_{c}^{(e)}\\}$ for augmentation   \nend for   \nreturn $f_{\\theta}=\\!0$ ", "page_idx": 15}, {"type": "text", "text": "where $\\mathbf{W}_{c}^{(e-1)}$ are the weights of augmentation techniques for class $c$ , $\\mathbf{H}_{c}^{(e-1)}$ is the history of accuracies for $c$ , and $a c c_{c}^{(e-\\bar{1})}$ is the accuracy in the previous epoch. ", "page_idx": 15}, {"type": "text", "text": "D Future Anylysis ", "text_level": 1, "page_idx": 15}, {"type": "text", "text": "D.1 Highly Imbalanced Scenarios ", "text_level": 1, "page_idx": 15}, {"type": "text", "text": "To evaluate the effectiveness of LLM-AutoDA in highly imbalanced scenarios, we adjusted the imbalance ratio to 200 and conducted comparative experiments. The experimental results, as shown in Figure 9, demonstrate that LLM-AutoDA consistently outperforms other long-tailed data augmentation methods. ", "page_idx": 15}, {"type": "image", "img_path": "VpuOuZOVhP/tmp/4ae08f2a065a3acee6d2ca51eacfcb8271cf052ec1060dd19c46a08f4c43ee69.jpg", "img_caption": ["Figure 9: Accuracy $(\\%)$ on more imbalanced CIFAR-100-LT dataset (Imbalance ratio $\\scriptstyle=200$ ) with SOTA DA methods. "], "img_footnote": [], "page_idx": 15}, {"type": "image", "img_path": "VpuOuZOVhP/tmp/36754919b7d00002cefd52a9704657856ab55a368d20c6dd846f7011564bcfd9.jpg", "img_caption": ["Figure 10: Trends in the augmentation intensities and number of times different strategies are selected. "], "img_footnote": [], "page_idx": 16}, {"type": "text", "text": "In the figure13, we visualize the selection process of the data augmentation strategies provided by the model. We train the discovered data augmentation methods on CIFAR-100 with an imbalance ratio of 100 under the bi-entropy loss, where the $\\mathbf{X}$ -axis is the epoch. The y-axis represents the data augmentation techniques that may be used in this work, including Mirror, EdgeEnhance, Detail, Smooth, AutoContrast, Equalize, Invert, GaussianBlur, Rotate, and Flip. The augmentation intensity ranges from 0 to 1 for all of these techniques. For samples of the first class, on the right side, different data augmentation methods are represented, with a dot in the grid indicating that the method represented by that row is selected, and dots of different colors indicating multiple selections. The height in the grid represents the intensity given by our strategy. In the early stages of training, the selected data augmentation strategies are relatively random, but as the model continues training, the trends in the selected data augmentation methods, intensities, and number of times selected gradually stabilize. This shows that the data augmentation methods provided by the large model can effectively achieve convergence on the long-tailed learning model. This demonstrates the feasibility of using a large model to search for and design data augmentation strategies for long-tailed learning models. ", "page_idx": 16}, {"type": "text", "text": "D.3 Cost Analysis ", "text_level": 1, "page_idx": 16}, {"type": "text", "text": "Using LLM-AutoDA to optimize data augmentation strategies for long-tailed recognition tasks requires significantly less time compared to the manual design of data augmentation strategies by humans. LLM-AutoDA can obtain highly effective strategies within a mere 2 3 hours under a given framework. ", "page_idx": 16}, {"type": "text", "text": "You are requested to design a novel algorithm that, given a set of augmentation techniques, selects several of them based on the change in per-class accuracy between the current training time point and the previous one, to be employed in the subsequent training phase, with the aim of enhancing the model's ability to tackle longtail problems. This algorithm should deviate from existing methodologies present in the literature. ", "page_idx": 17}, {"type": "text", "text": "Describe the new algorithm and main steps in one sentence, place the sentence inside curly braces, Next, implement it in Python as a function named get_aug_type. This function should accept 6 input(s): 'aug_weight', 'ACCs', 'History_ACCs', 'lats_chose_matix', 'lats_chose_exts', 'epoch'. The function should return 1 output(s): 'chose_matrix,chose_exts'. aug_weight is a two-dimensional integer array initialized to 1, used to record the historical weight information for each category (indexed by rows) across every augmentation technique (indexed by columns). ACCs is a one-dimensional integer array showcasing the performance of each category at the current training instant, specifically, the count of correct predictions within that category. History_ACCs is a two-dimensional integer array that records the number of correct predictions made by each augmentation technique (column-wise) the last time they were employed for every category. lats_chose_matrix is a twodimensional Boolean array indicating whether specific augmentation techniques (by column index) were utilized for each category (row index) in the previous training step; True signifies usage, while False denotes non-usage. lats_chose_exts is a two-dimensional float array representing the application intensity of each augmentation method across classifications at the current point in time, with a range from 0 to 1, where higher numbers imply greater enhancement strength. epoch is an integer denoting the current training epoch, indicating the number of completed training cycles. chose_matrix is a twodimensional Boolean array marking which augmentation techniques (by column index) will be employed in the next training step; True values indicate adoption, and False, rejection. chose_exts is a twodimensional float array signifying the intensity of applying each augmentation technique to individual categories in the upcoming time step, also ranging from 0 to 1, with larger values indicating more substantial augmentation efforts. All are Numpy arrays. ", "page_idx": 17}, {"type": "text", "text": "Do not give additional explanations. ", "page_idx": 17}, {"type": "text", "text": "Figure 11: An example of initialization prompts. ", "page_idx": 17}, {"type": "text", "text": "You are requested to design a novel algorithm that, given a set of augmentation techniques, selects several of them based on the change in per-class accuracy between the current training time point and the previous one, to be employed in the subsequent training phase, with the aim of enhancing the model's ability to tackle long-tail problems. This algorithm should deviate from existing methodologies present in the literature. ", "page_idx": 18}, {"type": "text", "text": "No.1 algorithm and the corresponding code are:   \nThe algorithm dynamically adjusts augmentation technique selection and intensity based on per-class accuracy improvements,   \nhistorical usage, and a decay factor to address class imbalance and enhance model performance on underrepresented classes.   \nimport numpy as np   \nimport random   \ndef get_aug_type(aug_weight,ACCs, History_ACCs, lats_chose_matix, lats_chose_exts,epoch): cls_num,num_aug_type $\\sim$ History_ACCs.shape # solve a weight as self.aug_weight for cidx in range(cls_num): indices $-$ lats_chose_matix[cidx] assert indices.any() ,f'class index {cidx} has no chose_aug (num of aug must $>0$ ) aug_weight[cidx][indices] $-$ np.where(ACCs[cidx] $>$ History_ACCs[cidx][indices], aug_weight[cidx][indices] $+~1$ , aug_weight[cidx][indices] - 1) aug_weight $-$ np.maximum(aug_weight, 1) chose_aug $-$ np.zeros((cls_num ,num_aug_type)).astype(bool) chose_exts $-$ np.random.rand(\\*lats_chose_exts.shape) aug_lis $=$ [i for i in range(num_aug_type)] for i in range(cls_num): indexes $\\sim$ random.choices(aug_list , weights $-$ aug_weight[i , : ].tolist() , k = 1) #self.args.MAX_N for index in indexes: chose_aug[i][index] $-$ True return chose_aug,chose_exts ", "page_idx": 18}, {"type": "text", "text": "Please help me create a new algorithm that has a totally different form from the given ones. ", "page_idx": 18}, {"type": "text", "text": "Describe the new algorithm and main steps in one sentence, place the sentence inside curly braces. Next, implement it in Python as a function named get_aug_type. This function should accept 6 input(s): 'aug_weight', 'ACCs', 'History_ACCs', 'lats_chose_matix', 'lats_chose_exts', 'epoch'. The function should return 1 output(s): 'chose_matrix,chose_exts'. aug_weight is a two-dimensional integer array initialized to 1, used to record the historical weight information for each category (indexed by rows) across every augmentation technique (indexed by columns). ACCs is a one-dimensional integer array showcasing the performance of each category at the current training instant, specifically, the count of correct predictions within that category. History_ACCs is a two-dimensional integer array that records the number of correct predictions made by each augmentation technique (columnwise) the last time they were employed for every category. lats_chose_matrix is a two-dimensional Boolean array indicating whether specific augmentation techniques (by column index) were utilized for each category (row index) in the previous training step; True signifies usage, while False denotes non-usage. lats_chose_exts is a two-dimensional float array representing the application intensity of each augmentation method across classifications at the current point in time, with a range from 0 to 1, where higher numbers imply greater enhancement strength. epoch is an integer denoting the current training epoch, indicating the number of completed training cycles. chose_matrix is a two-dimensional Boolean array marking which augmentation techniques (by column index) will be employed in the next training step; True values indicate adoption, and False, rejection. chose_exts is a two-dimensional float array signifying the intensity of applying each augmentation technique to individual categories in the upcoming time step, also ranging from 0 to 1, with larger values indicating more substantial augmentation efforts. All are Numpy arrays. ", "page_idx": 18}, {"type": "text", "text": "Do not give additional explanations. ", "page_idx": 18}, {"type": "text", "text": "You are requested to design a novel algorithm that, given a set of augmentation techniques, selects several of them based on the change in per-class accuracy between the current training time point and the previous one, to be employed in the subsequent training phase, with the aim of enhancing the model's ability to tackle long-tail problems. This algorithm should deviate from existing methodologies present in the literature. ", "page_idx": 19}, {"type": "text", "text": "I have one algorithm with its code as follows. Algorithm description: The algorithm dynamically adjusts augmentation technique selection and intensity based on per-class accuracy improvements, historical usage, and a decay factor to address class imbalance and enhance model performance on underrepresented classes. ", "page_idx": 19}, {"type": "text", "text": "Code:   \nimport numpy as np   \nimport random   \ndef get_aug_type(aug_weight,ACCs, History_ACCs, lats_chose_matix, lats_chose_exts,epoch): cls_num,num_aug_type $\\sim$ History_ACCs.shape # solve a weight as self.aug_weight for cidx in range(cls_num): indices $^-$ lats_chose_matix[cidx] assert indices.any() ,f'class index {cidx} has no chose_aug (num of aug must $>0$ )' aug_weight[cidx][indices] $-$ np.where(ACCs[cidx] $>$ History_ACCs[cidx][indices], aug_weight[cidx][indices] $+~1$ , aug_weight[cidx][indices] - 1) aug_weight $-$ np.maximum(aug_weight, 1) chose_aug $-$ np.zeros((cls_num ,num_aug_type)).astype(bool) chose_exts $-$ np.random.rand(\\*lats_chose_exts.shape) aug_lis $=$ [i for i in range(num_aug_type)] for i in range(cls_num): indexes $\\sim$ random.choices(aug_list , weights $-$ aug_weight[i , : ].tolist() , k = 1) #self.args.MAX_N for index in indexes: chose_aug[i][index] = True return chose_aug,chose_exts ", "page_idx": 19}, {"type": "text", "text": "First, describe the new algorithm and main steps in one sentence, place the sentence inside curly braces.Next, implement it in Python as a function named get_aug_type. This function should accept 6 input(s): 'aug_weight', 'ACCs', 'History_ACCs', 'lats_chose_matix', 'lats_chose_exts', 'epoch'. The function should return 1 output(s): 'chose_matrix,chose_exts'. aug_weight is a two-dimensional integer array initialized to 1, used to record the historical weight information for each category (indexed by rows) across every augmentation technique (indexed by columns). ACCs is a one-dimensional integer array showcasing the performance of each category at the current training instant, specifically, the count of correct predictions within that category. History_ACCs is a two-dimensional integer array that records the number of correct predictions made by each augmentation technique (columnwise) the last time they were employed for every category. lats_chose_matrix is a two-dimensional Boolean array indicating whether specific augmentation techniques (by column index) were utilized for each category (row index) in the previous training step; True signifies usage, while False denotes non-usage. lats_chose_exts is a two-dimensional float array representing the application intensity of each augmentation method across classifications at the current point in time, with a range from 0 to 1, where higher numbers imply greater enhancement strength. epoch is an integer denoting the current training epoch, indicating the number of completed training cycles. chose_matrix is a two-dimensional Boolean array marking which augmentation techniques (by column index) will be employed in the next training step; True values indicate adoption, and False, rejection. chose_exts is a two-dimensional float array signifying the intensity of applying each augmentation technique to individual categories in the upcoming time step, also ranging from 0 to 1, with larger values indicating more substantial augmentation efforts. All are Numpy arrays. ", "page_idx": 19}, {"type": "text", "text": "Do not give additional explanations. ", "page_idx": 19}, {"type": "text", "text": "F Limitations ", "text_level": 1, "page_idx": 20}, {"type": "text", "text": "This paper aims to innovate the data augmentation paradigm in long-tailed learning, which greatly improves the degree of freedom of long-tailed data augmentation. However, there are still some limitations of our approach. For example, the scoring mechanism for augmentation strategies is not perfect, and a more comprehensive scoring mechanism is needed. In addition, how to break through the search space limitation and generate novel augmentation methods is also a problem to be solved. ", "page_idx": 20}, {"type": "text", "text": "G Broader Impacts ", "text_level": 1, "page_idx": 20}, {"type": "text", "text": "Traditional data augmentation is not the best choice for long-tail learning, and recent long-tail data augmentation methods still lack degrees of freedom. The positive impact of our method is that it can give a large number of augmentation strategies suitable for long-tail learning in a short time, which greatly reduces the time and human cost consumed to design the strategy. Of course, there is also a small negative impact, that is, it is easy to cause dependence on LLMs. ", "page_idx": 20}, {"type": "text", "text": "NeurIPS Paper Checklist ", "text_level": 1, "page_idx": 21}, {"type": "text", "text": "1. Claims ", "text_level": 1, "page_idx": 21}, {"type": "text", "text": "Question: Do the main claims made in the abstract and introduction accurately reflect the paper\u2019s contributions and scope? ", "page_idx": 21}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 21}, {"type": "text", "text": "Justification: We describe the contributions of this paper in detail. ", "page_idx": 21}, {"type": "text", "text": "Guidelines: ", "page_idx": 21}, {"type": "text", "text": "\u2022 The answer NA means that the abstract and introduction do not include the claims made in the paper.   \n\u2022 The abstract and/or introduction should clearly state the claims made, including the contributions made in the paper and important assumptions and limitations. A No or NA answer to this question will not be perceived well by the reviewers.   \n\u2022 The claims made should match theoretical and experimental results, and reflect how much the results can be expected to generalize to other settings.   \n\u2022 It is fine to include aspirational goals as motivation as long as it is clear that these goals are not attained by the paper. ", "page_idx": 21}, {"type": "text", "text": "2. Limitations ", "text_level": 1, "page_idx": 21}, {"type": "text", "text": "Question: Does the paper discuss the limitations of the work performed by the authors? ", "page_idx": 21}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 21}, {"type": "text", "text": "Justification: We discuss the limitations of this paper in the appendix. ", "page_idx": 21}, {"type": "text", "text": "Guidelines: ", "page_idx": 21}, {"type": "text", "text": "\u2022 The answer NA means that the paper has no limitation while the answer No means that the paper has limitations, but those are not discussed in the paper.   \n\u2022 The authors are encouraged to create a separate \"Limitations\" section in their paper.   \n\u2022 The paper should point out any strong assumptions and how robust the results are to violations of these assumptions (e.g., independence assumptions, noiseless settings, model well-specification, asymptotic approximations only holding locally). The authors should reflect on how these assumptions might be violated in practice and what the implications would be.   \n\u2022 The authors should reflect on the scope of the claims made, e.g., if the approach was only tested on a few datasets or with a few runs. In general, empirical results often depend on implicit assumptions, which should be articulated.   \n\u2022 The authors should reflect on the factors that influence the performance of the approach. For example, a facial recognition algorithm may perform poorly when image resolution is low or images are taken in low lighting. Or a speech-to-text system might not be used reliably to provide closed captions for online lectures because it fails to handle technical jargon.   \n\u2022 The authors should discuss the computational efficiency of the proposed algorithms and how they scale with dataset size.   \n\u2022 If applicable, the authors should discuss possible limitations of their approach to address problems of privacy and fairness.   \n\u2022 While the authors might fear that complete honesty about limitations might be used by reviewers as grounds for rejection, a worse outcome might be that reviewers discover limitations that aren\u2019t acknowledged in the paper. The authors should use their best judgment and recognize that individual actions in favor of transparency play an important role in developing norms that preserve the integrity of the community. Reviewers will be specifically instructed to not penalize honesty concerning limitations. ", "page_idx": 21}, {"type": "text", "text": "3. Theory Assumptions and Proofs ", "text_level": 1, "page_idx": 21}, {"type": "text", "text": "Question: For each theoretical result, does the paper provide the full set of assumptions and a complete (and correct) proof? ", "page_idx": 21}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 21}, {"type": "text", "text": "Justification: We provide a complete demonstration process and data support. Guidelines: ", "page_idx": 22}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include theoretical results.   \n\u2022 All the theorems, formulas, and proofs in the paper should be numbered and crossreferenced.   \n\u2022 All assumptions should be clearly stated or referenced in the statement of any theorems.   \n\u2022 The proofs can either appear in the main paper or the supplemental material, but if they appear in the supplemental material, the authors are encouraged to provide a short proof sketch to provide intuition.   \n\u2022 Inversely, any informal proof provided in the core of the paper should be complemented by formal proofs provided in appendix or supplemental material.   \n\u2022 Theorems and Lemmas that the proof relies upon should be properly referenced. ", "page_idx": 22}, {"type": "text", "text": "4. Experimental Result Reproducibility ", "text_level": 1, "page_idx": 22}, {"type": "text", "text": "Question: Does the paper fully disclose all the information needed to reproduce the main experimental results of the paper to the extent that it affects the main claims and/or conclusions of the paper (regardless of whether the code and data are provided or not)? ", "page_idx": 22}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 22}, {"type": "text", "text": "Justification: We provide implementation details and code. ", "page_idx": 22}, {"type": "text", "text": "Guidelines: ", "page_idx": 22}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 If the paper includes experiments, a No answer to this question will not be perceived well by the reviewers: Making the paper reproducible is important, regardless of whether the code and data are provided or not.   \n\u2022 If the contribution is a dataset and/or model, the authors should describe the steps taken to make their results reproducible or verifiable.   \n\u2022 Depending on the contribution, reproducibility can be accomplished in various ways. For example, if the contribution is a novel architecture, describing the architecture fully might suffice, or if the contribution is a specific model and empirical evaluation, it may be necessary to either make it possible for others to replicate the model with the same dataset, or provide access to the model. In general. releasing code and data is often one good way to accomplish this, but reproducibility can also be provided via detailed instructions for how to replicate the results, access to a hosted model (e.g., in the case of a large language model), releasing of a model checkpoint, or other means that are appropriate to the research performed.   \n\u2022 While NeurIPS does not require releasing code, the conference does require all submissions to provide some reasonable avenue for reproducibility, which may depend on the nature of the contribution. For example (a) If the contribution is primarily a new algorithm, the paper should make it clear how to reproduce that algorithm. (b) If the contribution is primarily a new model architecture, the paper should describe the architecture clearly and fully. (c) If the contribution is a new model (e.g., a large language model), then there should either be a way to access this model for reproducing the results or a way to reproduce the model (e.g., with an open-source dataset or instructions for how to construct the dataset). (d) We recognize that reproducibility may be tricky in some cases, in which case authors are welcome to describe the particular way they provide for reproducibility. In the case of closed-source models, it may be that access to the model is limited in some way (e.g., to registered users), but it should be possible for other researchers to have some path to reproducing or verifying the results. ", "page_idx": 22}, {"type": "text", "text": "5. Open access to data and code ", "text_level": 1, "page_idx": 22}, {"type": "text", "text": "Question: Does the paper provide open access to the data and code, with sufficient instructions to faithfully reproduce the main experimental results, as described in supplemental material? ", "page_idx": 22}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 23}, {"type": "text", "text": "Justification: We provide the complete code as well as the details of the publicly available datasets used. ", "page_idx": 23}, {"type": "text", "text": "Guidelines: ", "page_idx": 23}, {"type": "text", "text": "\u2022 The answer NA means that paper does not include experiments requiring code.   \n\u2022 Please see the NeurIPS code and data submission guidelines (https://nips.cc/ public/guides/CodeSubmissionPolicy) for more details.   \n\u2022 While we encourage the release of code and data, we understand that this might not be possible, so \u201cNo\u201d is an acceptable answer. Papers cannot be rejected simply for not including code, unless this is central to the contribution (e.g., for a new open-source benchmark).   \n\u2022 The instructions should contain the exact command and environment needed to run to reproduce the results. See the NeurIPS code and data submission guidelines (https: //nips.cc/public/guides/CodeSubmissionPolicy) for more details.   \n\u2022 The authors should provide instructions on data access and preparation, including how to access the raw data, preprocessed data, intermediate data, and generated data, etc.   \n\u2022 The authors should provide scripts to reproduce all experimental results for the new proposed method and baselines. If only a subset of experiments are reproducible, they should state which ones are omitted from the script and why.   \n\u2022 At submission time, to preserve anonymity, the authors should release anonymized versions (if applicable).   \n\u2022 Providing as much information as possible in supplemental material (appended to the paper) is recommended, but including URLs to data and code is permitted. ", "page_idx": 23}, {"type": "text", "text": "6. Experimental Setting/Details ", "text_level": 1, "page_idx": 23}, {"type": "text", "text": "Question: Does the paper specify all the training and test details (e.g., data splits, hyperparameters, how they were chosen, type of optimizer, etc.) necessary to understand the results? ", "page_idx": 23}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 23}, {"type": "text", "text": "Justification: We provide the relevant details and analysis of the experimental results. Guidelines: ", "page_idx": 23}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments. \u2022 The experimental setting should be presented in the core of the paper to a level of detail that is necessary to appreciate the results and make sense of them. \u2022 The full details can be provided either with the code, in appendix, or as supplemental material. ", "page_idx": 23}, {"type": "text", "text": "7. Experiment Statistical Significance ", "text_level": 1, "page_idx": 23}, {"type": "text", "text": "Question: Does the paper report error bars suitably and correctly defined or other appropriate information about the statistical significance of the experiments? ", "page_idx": 23}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 23}, {"type": "text", "text": "Justification: We reported the average results of multiple tests in the experiment. ", "page_idx": 23}, {"type": "text", "text": "Guidelines: ", "page_idx": 23}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 The authors should answer \"Yes\" if the results are accompanied by error bars, confidence intervals, or statistical significance tests, at least for the experiments that support the main claims of the paper.   \n\u2022 The factors of variability that the error bars are capturing should be clearly stated (for example, train/test split, initialization, random drawing of some parameter, or overall run with given experimental conditions).   \n\u2022 The method for calculating the error bars should be explained (closed form formula, call to a library function, bootstrap, etc.)   \n\u2022 The assumptions made should be given (e.g., Normally distributed errors).   \n\u2022 It should be clear whether the error bar is the standard deviation or the standard error of the mean.   \n\u2022 It is OK to report 1-sigma error bars, but one should state it. The authors should preferably report a 2-sigma error bar than state that they have a $96\\%$ CI, if the hypothesis of Normality of errors is not verified.   \n\u2022 For asymmetric distributions, the authors should be careful not to show in tables or figures symmetric error bars that would yield results that are out of range (e.g. negative error rates).   \n\u2022 If error bars are reported in tables or plots, The authors should explain in the text how they were calculated and reference the corresponding figures or tables in the text. ", "page_idx": 23}, {"type": "text", "text": "", "page_idx": 24}, {"type": "text", "text": "8. Experiments Compute Resources ", "text_level": 1, "page_idx": 24}, {"type": "text", "text": "Question: For each experiment, does the paper provide sufficient information on the computer resources (type of compute workers, memory, time of execution) needed to reproduce the experiments? ", "page_idx": 24}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 24}, {"type": "text", "text": "Justification: We have provided the code for easy reproduction. ", "page_idx": 24}, {"type": "text", "text": "Guidelines: ", "page_idx": 24}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 The paper should indicate the type of compute workers CPU or GPU, internal cluster, or cloud provider, including relevant memory and storage.   \n\u2022 The paper should provide the amount of compute required for each of the individual experimental runs as well as estimate the total compute.   \n\u2022 The paper should disclose whether the full research project required more compute than the experiments reported in the paper (e.g., preliminary or failed experiments that didn\u2019t make it into the paper). ", "page_idx": 24}, {"type": "text", "text": "9. Code Of Ethics ", "text_level": 1, "page_idx": 24}, {"type": "text", "text": "Question: Does the research conducted in the paper conform, in every respect, with the NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines? ", "page_idx": 24}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 24}, {"type": "text", "text": "Justification: We are fully qualified. ", "page_idx": 24}, {"type": "text", "text": "Guidelines: ", "page_idx": 24}, {"type": "text", "text": "\u2022 The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics.   \n\u2022 If the authors answer No, they should explain the special circumstances that require a deviation from the Code of Ethics.   \n\u2022 The authors should make sure to preserve anonymity (e.g., if there is a special consideration due to laws or regulations in their jurisdiction). ", "page_idx": 24}, {"type": "text", "text": "10. Broader Impacts ", "text_level": 1, "page_idx": 24}, {"type": "text", "text": "Question: Does the paper discuss both potential positive societal impacts and negative societal impacts of the work performed? ", "page_idx": 24}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 24}, {"type": "text", "text": "Justification: We discuss the implications in the appendix. ", "page_idx": 24}, {"type": "text", "text": "Guidelines: ", "page_idx": 24}, {"type": "text", "text": "\u2022 The answer NA means that there is no societal impact of the work performed.   \n\u2022 If the authors answer NA or No, they should explain why their work has no societal impact or why the paper does not address societal impact.   \n\u2022 Examples of negative societal impacts include potential malicious or unintended uses (e.g., disinformation, generating fake profiles, surveillance), fairness considerations (e.g., deployment of technologies that could make decisions that unfairly impact specific groups), privacy considerations, and security considerations.   \n\u2022 The conference expects that many papers will be foundational research and not tied to particular applications, let alone deployments. However, if there is a direct path to any negative applications, the authors should point it out. For example, it is legitimate to point out that an improvement in the quality of generative models could be used to generate deepfakes for disinformation. On the other hand, it is not needed to point out that a generic algorithm for optimizing neural networks could enable people to train models that generate Deepfakes faster.   \n\u2022 The authors should consider possible harms that could arise when the technology is being used as intended and functioning correctly, harms that could arise when the technology is being used as intended but gives incorrect results, and harms following from (intentional or unintentional) misuse of the technology.   \n\u2022 If there are negative societal impacts, the authors could also discuss possible mitigation strategies (e.g., gated release of models, providing defenses in addition to attacks, mechanisms for monitoring misuse, mechanisms to monitor how a system learns from feedback over time, improving the efficiency and accessibility of ML). ", "page_idx": 24}, {"type": "text", "text": "", "page_idx": 25}, {"type": "text", "text": "11. Safeguards ", "text_level": 1, "page_idx": 25}, {"type": "text", "text": "Question: Does the paper describe safeguards that have been put in place for responsible release of data or models that have a high risk for misuse (e.g., pretrained language models, image generators, or scraped datasets)? ", "page_idx": 25}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 25}, {"type": "text", "text": "Justification: Our paper poses no such risks. ", "page_idx": 25}, {"type": "text", "text": "Guidelines: ", "page_idx": 25}, {"type": "text", "text": "\u2022 The answer NA means that the paper poses no such risks.   \n\u2022 Released models that have a high risk for misuse or dual-use should be released with necessary safeguards to allow for controlled use of the model, for example by requiring that users adhere to usage guidelines or restrictions to access the model or implementing safety filters.   \n\u2022 Datasets that have been scraped from the Internet could pose safety risks. The authors should describe how they avoided releasing unsafe images.   \n\u2022 We recognize that providing effective safeguards is challenging, and many papers do not require this, but we encourage authors to take this into account and make a best faith effort. ", "page_idx": 25}, {"type": "text", "text": "12. Licenses for existing assets ", "text_level": 1, "page_idx": 25}, {"type": "text", "text": "Question: Are the creators or original owners of assets (e.g., code, data, models), used in the paper, properly credited and are the license and terms of use explicitly mentioned and properly respected? ", "page_idx": 25}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 25}, {"type": "text", "text": "Justification: We give references to the datasets and code used. ", "page_idx": 25}, {"type": "text", "text": "Guidelines: ", "page_idx": 25}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not use existing assets.   \n\u2022 The authors should cite the original paper that produced the code package or dataset.   \n\u2022 The authors should state which version of the asset is used and, if possible, include a URL.   \n\u2022 The name of the license (e.g., CC-BY 4.0) should be included for each asset.   \n\u2022 For scraped data from a particular source (e.g., website), the copyright and terms of service of that source should be provided.   \n\u2022 If assets are released, the license, copyright information, and terms of use in the package should be provided. For popular datasets, paperswithcode.com/datasets has curated licenses for some datasets. Their licensing guide can help determine the license of a dataset.   \n\u2022 For existing datasets that are re-packaged, both the original license and the license of the derived asset (if it has changed) should be provided. ", "page_idx": 25}, {"type": "text", "text": "\u2022 If this information is not available online, the authors are encouraged to reach out to the asset\u2019s creators. ", "page_idx": 26}, {"type": "text", "text": "13. New Assets ", "text_level": 1, "page_idx": 26}, {"type": "text", "text": "Question: Are new assets introduced in the paper well documented and is the documentation provided alongside the assets? ", "page_idx": 26}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 26}, {"type": "text", "text": "Justification: Our paper does not release new assets. ", "page_idx": 26}, {"type": "text", "text": "Guidelines: ", "page_idx": 26}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not release new assets.   \n\u2022 Researchers should communicate the details of the dataset/code/model as part of their submissions via structured templates. This includes details about training, license, limitations, etc.   \n\u2022 The paper should discuss whether and how consent was obtained from people whose asset is used.   \n\u2022 At submission time, remember to anonymize your assets (if applicable). You can either create an anonymized URL or include an anonymized zip file. ", "page_idx": 26}, {"type": "text", "text": "14. Crowdsourcing and Research with Human Subjects ", "text_level": 1, "page_idx": 26}, {"type": "text", "text": "Question: For crowdsourcing experiments and research with human subjects, does the paper include the full text of instructions given to participants and screenshots, if applicable, as well as details about compensation (if any)? ", "page_idx": 26}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 26}, {"type": "text", "text": "Justification: This paper does not involve crowdsourcing nor research with human subjects. Guidelines: ", "page_idx": 26}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u2022 Including this information in the supplemental material is fine, but if the main contribution of the paper involves human subjects, then as much detail as possible should be included in the main paper.   \n\u2022 According to the NeurIPS Code of Ethics, workers involved in data collection, curation, or other labor should be paid at least the minimum wage in the country of the data collector. ", "page_idx": 26}, {"type": "text", "text": "15. Institutional Review Board (IRB) Approvals or Equivalent for Research with Human Subjects ", "text_level": 1, "page_idx": 26}, {"type": "text", "text": "Question: Does the paper describe potential risks incurred by study participants, whether such risks were disclosed to the subjects, and whether Institutional Review Board (IRB) approvals (or an equivalent approval/review based on the requirements of your country or institution) were obtained? ", "page_idx": 26}, {"type": "text", "text": "Answer: [NA] ", "text_level": 1, "page_idx": 26}, {"type": "text", "text": "Justification: This paper does not involve crowdsourcing nor research with human subjects. Guidelines: ", "page_idx": 26}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u2022 Depending on the country in which research is conducted, IRB approval (or equivalent) may be required for any human subjects research. If you obtained IRB approval, you should clearly state this in the paper.   \n\u2022 We recognize that the procedures for this may vary significantly between institutions and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the guidelines for their institution.   \n\u2022 For initial submissions, do not include any information that would break anonymity (if applicable), such as the institution conducting the review. ", "page_idx": 26}]