[{"figure_path": "IoRT7EhFap/figures/figures_2_1.jpg", "caption": "Figure 1: Spectrum comparison of f := f1 + f2 \u00b0 f1 + f3 \u00b0 f2 \u00b0 f1 + f4 \u00b0 f3 \u00b0 f2 \u00b0 f1 and fj: Amplitude versus one-side frequency plots for function f (Left) and fj for j \u2208 N4 (Right). The function f is of high-frequency and functions fj all are of low-frequency.", "description": "This figure shows the frequency spectrum comparison between a high-frequency function (f) and its four low-frequency components (f1 to f4). The left side shows the spectrum of the high-frequency function f, which is composed of the four low-frequency functions. The right side shows the spectrum of each low-frequency component.  This illustrates the concept that a high-frequency function can be represented by composing several low-frequency functions.", "section": "1 Introduction"}, {"figure_path": "IoRT7EhFap/figures/figures_5_1.jpg", "caption": "Figure 2: Amplitude versus one-side frequency plot for the learned functions learned across four grades of MGDL for settings 1-4.", "description": "This figure displays the amplitude versus frequency for the functions learned by the Multi-Grade Deep Learning (MGDL) model across four different settings. Each setting represents a different level of complexity in the target function being approximated.  The plots show that MGDL learns low-frequency components in the first grade, and progressively learns higher-frequency components in subsequent grades.  This demonstrates MGDL's ability to capture high-frequency information by composing multiple low-frequency components.", "section": "3.1 Regression on the synthetic data"}, {"figure_path": "IoRT7EhFap/figures/figures_5_2.jpg", "caption": "Figure 3: Comparison of SGDL (left) and MGDL (right): training and validation loss across settings 1-4.", "description": "The figure shows the training and validation loss curves for both SGDL and MGDL across four different settings.  Each setting represents a different function with varying high-frequency characteristics.  The x-axis represents the number of epochs (training iterations), and the y-axis represents the loss (error).  The plot highlights how MGDL effectively reduces both training and validation loss compared to SGDL, especially in settings with strong high-frequency components. This demonstrates MGDL's ability to overcome the spectral bias observed in SGDL and learn high-frequency features more efficiently.", "section": "3 Numerical Experiments"}, {"figure_path": "IoRT7EhFap/figures/figures_8_1.jpg", "caption": "Figure 6: Comparison of PSNR values for SGDL and MGDL on images Cat, Sea, and Building: SGDL (a)-(c), MGDL (d)-(f).", "description": "This figure compares the Peak Signal-to-Noise Ratio (PSNR) values for SGDL and MGDL across three different images (Cat, Sea, and Building).  Subfigures (a)-(c) show the training and testing PSNR values for SGDL for each image.  Subfigures (d)-(f) show the same information for MGDL. The figure illustrates that MGDL achieves higher PSNR values than SGDL, demonstrating that MGDL is better at learning high-frequency features in images.", "section": "3.3 Regression on two-dimensional colored Images"}, {"figure_path": "IoRT7EhFap/figures/figures_13_1.jpg", "caption": "Figure 1: Spectrum comparison of f := f1 + f2 \u00b0 f1 + f3 \u00b0 f2 \u00b0 f1 + f4 \u00b0 f3 \u00b0 f2 \u00b0 f1 and fj: Amplitude versus one-side frequency plots for function f (Left) and fj for j \u2208 N4 (Right). The function f is of high-frequency and functions fj all are of low-frequency.", "description": "This figure compares the frequency spectrums of a high-frequency function (f) and its four low-frequency components (f1, f2, f3, f4).  The high-frequency function (f) is constructed by the composition of the low-frequency components. The left panel shows the spectrum of f, which has a wide range of frequencies, whereas the right panel shows the spectrums of individual components, which primarily show low-frequency information.  This illustrates the paper's core concept that high-frequency functions can be effectively approximated by the composition of several low-frequency functions.", "section": "1 Introduction"}, {"figure_path": "IoRT7EhFap/figures/figures_14_1.jpg", "caption": "Figure 1: Spectrum comparison of f := f1 + f2 \u00b0 f1 + f3 \u00b0 f2 \u00b0 f1 + f4 \u00b0 f3 \u00b0 f2 \u00b0 f1 and fj: Amplitude versus one-side frequency plots for function f (Left) and fj for j \u2208 N4 (Right). The function f is of high-frequency and functions fj all are of low-frequency.", "description": "This figure compares the frequency spectrums of a high-frequency function and its decomposition into several low-frequency functions.  The left panel shows the spectrum of the high-frequency function (f), while the right panel displays the spectrums of its individual low-frequency components (fj).  This illustrates the core concept of the MGDL method: approximating a complex high-frequency function using simpler, lower-frequency components.", "section": "1 Introduction"}, {"figure_path": "IoRT7EhFap/figures/figures_14_2.jpg", "caption": "Figure 9: Comparison of SGDL (1st row) and MGDL (2nd row) for settings 1-4 of Section 3.1: The evolution of spectrum.", "description": "This figure compares the evolution of the spectrum for SGDL and MGDL across four different settings. The top row shows the spectrum for SGDL, while the bottom row shows the spectrum for MGDL. Each column represents a different setting. The colorbar indicates the measured amplitude of the network spectrum at the corresponding frequency, normalized by the amplitude of \u03bb at the same frequency.", "section": "3 Numerical Experiments"}, {"figure_path": "IoRT7EhFap/figures/figures_15_1.jpg", "caption": "Figure 9: Comparison of SGDL (1st row) and MGDL (2nd row) for settings 1-4 of Section 3.1: The evolution of spectrum.", "description": "This figure compares the evolution of the frequency spectrum learned by SGDL and MGDL across four different settings (1-4) from Section 3.1 of the paper. Each setting represents a different high-frequency function. The top row shows the spectrum learned by SGDL, while the bottom row shows the spectrum learned by MGDL, illustrating how the multi-grade approach captures the high frequencies more effectively through incremental learning.", "section": "3 Numerical Experiments"}, {"figure_path": "IoRT7EhFap/figures/figures_15_2.jpg", "caption": "Figure 11: Comparison of MGDL and SGDL for image Cat. (a)-(d): Predictions of MGDL for grades 1-4, with the corresponding testing PSNR values indicated in the subtitles. (e): Prediction of SGDL with testing PSNR displayed in the subtitle. (f): Ground truth image", "description": "This figure compares the image reconstruction results of MGDL and SGDL on the \"Cat\" image.  MGDL is shown to progressively improve image quality across grades (a-d), achieving higher PSNR values than SGDL (e). The Ground Truth image is provided in (f) for comparison. This demonstrates MGDL's ability to capture high-frequency details more effectively than SGDL.", "section": "3.3 Regression on two-dimensional colored Images"}, {"figure_path": "IoRT7EhFap/figures/figures_16_1.jpg", "caption": "Figure 1: Spectrum comparison of f := f1 + f2 \u00b0 f1 + f3 \u00b0 f2 \u00b0 f1 + f4 \u00b0 f3 \u00b0 f2 \u00b0 f1 and fj: Amplitude versus one-side frequency plots for function f (Left) and fj for j \u2208 N4 (Right). The function f is of high-frequency and functions fj all are of low-frequency.", "description": "This figure compares the frequency spectrums of a high-frequency function (f) and four low-frequency functions (f1 to f4). Function f is constructed as a composition of functions f1 to f4 which demonstrates that high-frequency functions can be constructed by composing lower-frequency functions. This is the core idea of the proposed method that addresses the spectral bias of deep neural networks.", "section": "1 Introduction"}, {"figure_path": "IoRT7EhFap/figures/figures_16_2.jpg", "caption": "Figure 11: Comparison of MGDL and SGDL for image Cat. (a)-(d): Predictions of MGDL for grades 1-4, with the corresponding testing PSNR values indicated in the subtitles. (e): Prediction of SGDL with testing PSNR displayed in the subtitle. (f): Ground truth image", "description": "The figure compares the image reconstruction results of the proposed multi-grade deep learning (MGDL) method and the traditional single-grade deep learning (SGDL) method on a \"Cat\" image.  Subfigures (a) through (d) show the results for MGDL across four grades, each grade progressively capturing higher-frequency details, as evidenced by the increasing Peak Signal-to-Noise Ratio (PSNR) values. Subfigure (e) shows the result of SGDL, and subfigure (f) presents the ground truth image. The comparison highlights MGDL's ability to better capture high-frequency information, leading to improved image quality compared to SGDL.", "section": "3.3 Regression on two-dimensional colored Images"}, {"figure_path": "IoRT7EhFap/figures/figures_17_1.jpg", "caption": "Figure 3: Comparison of SGDL (left) and MGDL (right): training and validation loss across settings 1-4.", "description": "This figure compares the training and validation losses for both SGDL and MGDL across four different settings.  The x-axis represents the number of epochs (iterations of training), while the y-axis represents the loss.  It visually demonstrates the faster convergence and lower validation loss achieved by MGDL compared to SGDL, particularly beneficial in settings with high-frequency components.", "section": "3 Numerical Experiments"}, {"figure_path": "IoRT7EhFap/figures/figures_18_1.jpg", "caption": "Figure 14: Comparison of SGDL and MGDL with structure (14): training (dash curve) and validation (solid curve) loss versus training time for various values of \u03b2 and \u03ba: (a) \u03b2 = 0.5, (b) \u03b2 = 1, (c) \u03b2 = 3, (d) \u03b2 = 5.", "description": "This figure compares the performance of SGDL and MGDL using different structures, focusing on how training and validation loss change over time for various values of amplitude (\u03b2) and frequency (\u03ba).  Each subplot (a-d) represents a different amplitude level, showcasing how loss changes for both models across various frequencies, providing insights into their learning dynamics in high-frequency scenarios.", "section": "B.4 Section 3.4"}]