[{"figure_path": "859DtlwnAD/tables/tables_5_1.jpg", "caption": "Table 1: ROC-AUC scores (%) on benchmark datasets, compared with methods trained from scratch (first group) and methods that leverage pre-trained molecular encoder (second group). The best is marked with boldface and the second best is with underline. \u25b3Improve. indicates the relative improvements over the baseline models in percentage.", "description": "This table presents the ROC-AUC scores achieved by various methods on five benchmark datasets for few-shot molecular property prediction.  It compares methods trained from scratch with those using pre-trained molecular encoders.  The best performing method for each dataset and shot setting is highlighted, along with the percentage improvement relative to the best baseline method.", "section": "5 Experiments"}, {"figure_path": "859DtlwnAD/tables/tables_7_1.jpg", "caption": "Table 1: ROC-AUC scores (%) on benchmark datasets, compared with methods trained from scratch (first group) and methods that leverage pre-trained molecular encoder (second group). The best is marked with boldface and the second best is with underline. \u25b3Improve. indicates the relative improvements over the baseline models in percentage.", "description": "This table presents the ROC-AUC scores achieved by various models on five benchmark datasets for both 5-shot and 10-shot settings.  It compares models trained from scratch with those using pre-trained molecular encoders.  The best performing model for each dataset and shot scenario is highlighted, along with the relative improvement over the baseline model.", "section": "5 Experiments"}, {"figure_path": "859DtlwnAD/tables/tables_7_2.jpg", "caption": "Table 2: Ablation analysis on the MP-Adapter, in which we drop different components to form variants. We report ROC-AUC scores (%), and the best performance is highlighted in bold.", "description": "This table presents the results of ablation experiments conducted on the MP-Adapter component of the Pin-Tuning method.  The researchers systematically removed different parts of the MP-Adapter (adapter module, context integration, and layer normalization) to assess their individual contribution to the model's overall performance.  The ROC-AUC scores are reported for each ablation variant across five different datasets (Tox21, SIDER, MUV, ToxCast, and PCBA) under both 10-shot and 5-shot settings, allowing for a comprehensive evaluation of the impact of each component.", "section": "5.2 Performance comparison"}, {"figure_path": "859DtlwnAD/tables/tables_8_1.jpg", "caption": "Table 3: Ablation analysis on the Emb-BWC.", "description": "This ablation study analyzes the impact of different Emb-BWC regularizers on the model's performance. It compares the results of fine-tuning the embedding layers with and without different regularizers (Identity, Fisher Information Matrix, and Embedding-wise Fisher Information Matrix). The table shows the ROC-AUC scores achieved for each dataset (Tox21, SIDER, MUV, PCBA) with different configurations.", "section": "5.4 Sensitivity analysis"}, {"figure_path": "859DtlwnAD/tables/tables_16_1.jpg", "caption": "Table 1: ROC-AUC scores (%) on benchmark datasets, compared with methods trained from scratch (first group) and methods that leverage pre-trained molecular encoder (second group). The best is marked with boldface and the second best is with underline. \u25b3Improve. indicates the relative improvements over the baseline models in percentage.", "description": "This table presents the ROC-AUC scores achieved by various methods on five benchmark datasets for few-shot molecular property prediction.  The methods are categorized into two groups: those trained from scratch and those leveraging pre-trained molecular encoders.  The table highlights the best and second-best performing methods for each dataset and each shot setting (5-shot and 10-shot).  It also shows the percentage improvement of the best-performing method compared to the baseline methods.", "section": "5 Experiments"}, {"figure_path": "859DtlwnAD/tables/tables_17_1.jpg", "caption": "Table 4: Comparison of total model size. * indicates that the parameters are frozen.", "description": "This table compares the total size of the models used in the experiments, differentiating between the GS-Meta baseline and the proposed Pin-Tuning method.  It shows a breakdown of the model size into its components: molecular encoder, adapter, context encoder, and classifier. Importantly, it highlights that while the overall model size is slightly larger for Pin-Tuning, the number of tunable parameters is significantly reduced compared to GS-Meta, emphasizing the parameter efficiency of the proposed approach.", "section": "5 Experiments"}, {"figure_path": "859DtlwnAD/tables/tables_17_2.jpg", "caption": "Table 5: Dataset statistics.", "description": "This table presents the statistics of five datasets used in the paper's experiments.  For each dataset, it shows the number of compounds, the number of properties, the number of properties used for training and testing, and the percentage of positive, negative, and unknown labels.", "section": "5.1 Evaluation setups"}, {"figure_path": "859DtlwnAD/tables/tables_18_1.jpg", "caption": "Table 6: Statistics of sub-datasets of ToxCast.", "description": "This table shows the statistics of sub-datasets from ToxCast dataset used in the paper.  It includes the number of compounds, the number of properties, the number of training and test properties, and the percentage of positive, negative, and missing labels for each sub-dataset. This information is essential to understanding the characteristics of the data used for evaluation and comparing different models.", "section": "5.1 Evaluation setups"}, {"figure_path": "859DtlwnAD/tables/tables_19_1.jpg", "caption": "Table 7: 10-shot performance on each sub-dataset of ToxCast.", "description": "This table presents the 10-shot performance results on each sub-dataset of ToxCast for various models, including baselines and the proposed Pin-Tuning method.  It shows the ROC-AUC scores for each model on various sub-datasets of ToxCast, allowing for a comparison of model performance across different tasks and datasets. The final row displays the relative improvement (%) of Pin-Tuning over the best baseline model.", "section": "5.2 Performance comparison"}, {"figure_path": "859DtlwnAD/tables/tables_19_2.jpg", "caption": "Table 8: 5-shot performance on each sub-dataset of ToxCast.", "description": "This table presents the 5-shot performance results for various models on the sub-datasets of ToxCast.  It shows the ROC-AUC scores achieved by different methods, including baselines (ProtoNet, MAML, TPN, EGNN, Pre-GNN, Meta-MGNN, PAR, GS-Meta) and the proposed Pin-Tuning method. The last row indicates the relative improvement of Pin-Tuning over the best performing baseline for each dataset. This allows for a comparison of the effectiveness of each approach in few-shot scenarios.", "section": "5.2 Performance comparison"}]