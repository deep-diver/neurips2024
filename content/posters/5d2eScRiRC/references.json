{"references": [{"fullname_first_author": "Rishabh Agarwal", "paper_title": "On-policy distillation of language models: Learning from self-generated mistakes", "publication_date": "2024-00-00", "reason": "This paper directly addresses a key challenge of the current work by exploring the on-policy distillation of language models, which helps mitigate issues caused by self-generated data."}, {"fullname_first_author": "Rohan Anil", "paper_title": "PaLM 2 technical report", "publication_date": "2023-00-00", "reason": "As one of the models used in this study, the PaLM 2 model's technical report provides crucial context and details about the model's architecture and training, which is essential for understanding the experimental results."}, {"fullname_first_author": "Brenna D Argall", "paper_title": "A survey of robot learning from demonstration", "publication_date": "2009-00-00", "reason": "This paper provides a broad overview of robot learning from demonstration, which helps contextualize the inverse reinforcement learning approach discussed in the current study."}, {"fullname_first_author": "Gregor Bachmann", "paper_title": "The pitfalls of next-token prediction", "publication_date": "2024-00-00", "reason": "This paper directly addresses the limitations of MLE (maximum likelihood estimation) for next-token prediction in language models, which provides a strong rationale for exploring alternative approaches like IRL."}, {"fullname_first_author": "Jonathan Ho", "paper_title": "Generative adversarial imitation learning", "publication_date": "2016-00-00", "reason": "This paper introduces GAIL (Generative Adversarial Imitation Learning), a key algorithm used for comparison in this study, providing the foundation for the adversarial imitation learning approach."}]}