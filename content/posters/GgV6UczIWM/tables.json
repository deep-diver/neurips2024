[{"figure_path": "GgV6UczIWM/tables/tables_7_1.jpg", "caption": "Table 1: Sampling the clones. In the first row, we show part of a sentence taken from the test set of TinyStories. The second, third and fourth rows show how the original text is modified after 20 sweeps of Monte Carlo sampling associated to two and four layers factored architectures and BERT architectures, respectively.", "description": "This table shows examples of how the original text from the TinyStories dataset is modified after applying Monte Carlo sampling using different architectures (factored with 2 and 4 layers, and BERT).  It illustrates the effect of varying the model's capacity to capture higher-order interactions on the generated text.", "section": "4 Sequential learning in NLP"}]