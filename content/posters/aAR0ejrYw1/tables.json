[{"figure_path": "aAR0ejrYw1/tables/tables_5_1.jpg", "caption": "Table 1: Quantitative evaluation on images that sound. We report CLIP, CLAP, FID, and FAD metrics, along with 95% confidence intervals shown in gray. The best results are highlighted in bold.", "description": "This table presents a quantitative comparison of different methods for generating \"images that sound.\"  It uses four metrics to evaluate the quality of the generated samples: CLIP score (measuring image-text alignment), CLAP score (measuring audio-text alignment), FID score (measuring image quality), and FAD score (measuring audio quality).  The table compares the performance of the proposed method against three baselines: Stable Diffusion (image-only), Auffusion (audio-only), and two proposed alternative methods (Imprint and SDS).  Confidence intervals are included to show statistical significance, and the best results are highlighted.", "section": "4.2 Quantitative Evaluation"}, {"figure_path": "aAR0ejrYw1/tables/tables_5_2.jpg", "caption": "Table 1: Quantitative evaluation on images that sound. We report CLIP, CLAP, FID, and FAD metrics, along with 95% confidence intervals shown in gray. The best results are highlighted in bold.", "description": "This table presents a quantitative comparison of different methods for generating \"images that sound.\"  It uses four metrics: CLIP (evaluates image-text alignment), CLAP (evaluates audio-text alignment), FID (Fr\u00e9chet Inception Distance, measures image quality), and FAD (Fr\u00e9chet Audio Distance, measures audio quality).  Results are shown for three methods: Stable Diffusion (image-only), Auffusion (audio-only), and the proposed method (\"Ours\"). Confidence intervals are included to indicate the uncertainty in the results. The best performance for each metric is highlighted in bold, indicating the proposed approach's effectiveness in generating high-quality images and sounds.", "section": "4.2 Quantitative Evaluation"}, {"figure_path": "aAR0ejrYw1/tables/tables_16_1.jpg", "caption": "Table 1: Quantitative evaluation on images that sound. We report CLIP, CLAP, FID, and FAD metrics, along with 95% confidence intervals shown in gray. The best results are highlighted in bold.", "description": "This table presents a quantitative comparison of different methods for generating images that sound, using four metrics: CLIP (image-text alignment), CLAP (audio-text alignment), FID (image quality), and FAD (audio quality).  The results are shown for four methods: Stable Diffusion (image-only), Auffusion (audio-only), an imprint baseline (a simple subtraction method), and score distillation sampling (SDS) baseline (a multimodal score-based approach) and the authors' proposed method.  95% confidence intervals are provided, and the best result for each metric is shown in bold.  The table highlights the superior performance of the proposed method in terms of generating images that sound high quality and that align well with both the image and audio prompts.", "section": "4.2 Quantitative Evaluation"}, {"figure_path": "aAR0ejrYw1/tables/tables_17_1.jpg", "caption": "Table 1: Quantitative evaluation on images that sound. We report CLIP, CLAP, FID, and FAD metrics, along with 95% confidence intervals shown in gray. The best results are highlighted in bold.", "description": "This table presents a quantitative comparison of different methods for generating \"images that sound.\"  It evaluates the quality of generated samples using four metrics: CLIP (image-text alignment), CLAP (audio-text alignment), FID (Fr\u00e9chet Inception Distance, image quality), and FAD (Fr\u00e9chet Audio Distance, audio quality). The table includes results for three methods: Stable Diffusion (image-only), Auffusion (audio-only), and the proposed method (\"Ours\"), and two baselines (Imprint and SDS). The 95% confidence intervals for each metric are shown in gray, and the best result for each metric is bolded.  This allows for comparison of the quality and alignment of image and sound generation across the different models.", "section": "4.2 Quantitative Evaluation"}, {"figure_path": "aAR0ejrYw1/tables/tables_18_1.jpg", "caption": "Table 1: Quantitative evaluation on images that sound. We report CLIP, CLAP, FID, and FAD metrics, along with 95% confidence intervals shown in gray. The best results are highlighted in bold.", "description": "This table presents a quantitative comparison of different methods for generating \"images that sound.\"  It uses four metrics: CLIP (image-text alignment), CLAP (audio-text alignment), FID (Fr\u00e9chet Inception Distance, image quality), and FAD (Fr\u00e9chet Audio Distance, audio quality).  The results for three methods are shown: Stable Diffusion (image-only), Auffusion (audio-only), and the proposed method (multimodal).  Confidence intervals are given to show statistical significance, and the best-performing method for each metric is highlighted.", "section": "4.2 Quantitative Evaluation"}]