[{"figure_path": "Dzk2cRUFMt/figures/figures_1_1.jpg", "caption": "Figure 1: (a) RAG in NLP utilizes retrieval to enhance model responses, based on a query to retrieve related features (e.g., a tail, primarily feeds on mice) and answers (e.g., Cat). (b) In CV, RAG employs similar photo retrieval to enhance model comprehension, assisting in downstream tasks such as inpainting or image question answering. (c) For GNNs, RAG could leverage retrieval of similar historical subgraphs or scenarios to aid in graph-based tasks (e.g., recommendations or fraud detection).", "description": "This figure illustrates how Retrieval-Augmented Generation (RAG) works in three different domains: Natural Language Processing (NLP), Computer Vision (CV), and Graph Neural Networks (GNNs).  In each case, a query is made, and RAG is used to retrieve relevant information to help answer the query.  In NLP, this involves retrieving relevant text; in CV, it involves retrieving similar images; and in GNNs, it involves retrieving similar subgraphs. The figure shows how RAG can improve the accuracy and reliability of models in each domain by providing additional context.", "section": "Graph Learning Tasks"}, {"figure_path": "Dzk2cRUFMt/figures/figures_4_1.jpg", "caption": "Figure 2: The overall framework of RAGRAPH. \u25cf Given resource graph GR, we chunk it and augment toy graphs {GT}, and feed them into pre-trained GNNs to generate hidden embeddings via the encoder and task-specific output vectors via decoder, which are stored as values. Keys such as environment, history, position-aware, and hidden embeddings are stored to form the key-value database of toy graphs GT. For a given query graph G\u00ba, the keys are fetched to retrieve the topK toy graphs Gropk from the database. Leveraging Gropk, intra- and inter-propagation are performed to propagate hidden embeddings and task-specific output vectors to pass retrieved knowledge to center node ve. Through a weighted fusion, the aggregated output is used to perform graph-, node- and edge-level tasks.", "description": "This figure illustrates the overall framework of RAGRAPH, a retrieval-augmented graph learning framework. It shows the process of constructing a toy graph database, retrieving relevant toy graphs based on a query graph, and then using those retrieved graphs to enhance the learning process of a pre-trained GNN model for improved performance on graph-level, node-level, and edge-level tasks.", "section": "4 RAGRAPH Framework"}, {"figure_path": "Dzk2cRUFMt/figures/figures_8_1.jpg", "caption": "Figure 3: Hyper-parameter study with hopsk (Left) from 1 to 5 and topk from 1 to 20 (Right) on node classification with PROTEINS, and ENZYMES datasets with the setting in Table 1.", "description": "This figure shows the impact of varying the number of hops (k) in the toy graphs and the number of retrieved toy graphs (topk) on the accuracy of node classification.  The left panel shows that accuracy initially increases with k, reaching a peak before decreasing as k becomes too large. The right panel shows that accuracy increases with topk, plateauing after a certain point. Both panels show results for two different datasets, PROTEINS and ENZYMES, highlighting the consistency of the results across different datasets.", "section": "5.3 Hyper-parameter Study"}, {"figure_path": "Dzk2cRUFMt/figures/figures_27_1.jpg", "caption": "Figure 2: The overall framework of RAGRAPH. \u25cf Given resource graph GR, we chunk it and augment toy graphs {GT}, and feed them into pre-trained GNNs to generate hidden embeddings via the encoder and task-specific output vectors via decoder, which are stored as values. Keys such as environment, history, position-aware, and hidden embeddings are stored to form the key-value database of toy graphs GT. For a given query graph G\u00ba, the keys are fetched to retrieve the topK toy graphs Gropk from the database. Leveraging Gropk, intra- and inter-propagation are performed to propagate hidden embeddings and task-specific output vectors to pass retrieved knowledge to center node ve. Through a weighted fusion, the aggregated output is used to perform graph-, node- and edge-level tasks.", "description": "This figure illustrates the RAGRAPH framework. It shows how the resource graph is chunked into toy graphs, which are then embedded using pre-trained GNNs.  The embeddings and task-specific output vectors are stored as key-value pairs. A query graph is then used to retrieve relevant toy graphs based on key similarity. Finally, the retrieved information is integrated using intra and inter-propagation mechanisms to produce the final output for various downstream tasks.", "section": "4 RAGRAPH Framework"}, {"figure_path": "Dzk2cRUFMt/figures/figures_28_1.jpg", "caption": "Figure 5: Qualitative analyses of toy graphs retrieving \u2013 how \"generation\" works.", "description": "This figure shows a qualitative analysis of the toy graph retrieval process in RAGRAPH. It illustrates how the task-specific output vectors and hidden embeddings from retrieved toy graphs are propagated and combined to enhance the model's output. The example demonstrates how RAGRAPH uses retrieved toy graphs with similar patterns to the query node's to improve the accuracy of node classification by producing a refined output vector.", "section": "D.6 Qualitative Analyses of Toy Graphs Retrieving"}, {"figure_path": "Dzk2cRUFMt/figures/figures_29_1.jpg", "caption": "Figure 6: Difference Illustration between PRODIGY and RAGRAPH.", "description": "This figure compares and contrasts the approaches of PRODIGY and RAGRAPH for graph learning.  PRODIGY uses in-context learning (ICL) with static example graphs, learning a mapping from input features (X) to output labels (Y). RAGRAPH, on the other hand, incorporates Retrieval-Augmented Generation (RAG), using dynamic toy graphs to retrieve relevant knowledge (both X and Y) and inject it into the query graph.  This illustrates RAGRAPH's ability to handle dynamic data and integrate external information more effectively.", "section": "E Difference between ICL (PRODIGY) and RAG (RAGRAPH)"}]