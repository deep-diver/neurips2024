{"references": [{"fullname_first_author": "Tom Brown", "paper_title": "Language models are few-shot learners", "publication_date": "2020-12-01", "reason": "This paper introduces the foundational concept of few-shot learning in large language models, a technique heavily leveraged and built upon in the target paper's methods."}, {"fullname_first_author": "Edward J Hu", "paper_title": "Lora: Low-rank adaptation of large language models", "publication_date": "2021-06-09", "reason": "The LoRA method, introduced in this paper, is a core component of the target paper's efficient fine-tuning strategy for federated foundation models."}, {"fullname_first_author": "Tian Li", "paper_title": "Federated optimization in heterogeneous networks", "publication_date": "2020-12-01", "reason": "This paper's algorithms for federated optimization are fundamental to the target paper's approach to collaboratively training models across multiple clients."}, {"fullname_first_author": "Brendan McMahan", "paper_title": "Communication-efficient learning of deep networks from decentralized data", "publication_date": "2017-01-01", "reason": "This foundational paper lays the groundwork for communication-efficient federated learning, a key challenge addressed in the target paper's federated learning framework."}, {"fullname_first_author": "Liangze Jiang", "paper_title": "Test-time robust personalization for federated learning", "publication_date": "2023-01-01", "reason": "This work directly addresses the problem of test-time distribution shifts in personalized federated learning, a central focus of the target paper, providing a relevant baseline and context for comparison."}]}