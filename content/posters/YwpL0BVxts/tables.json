[{"figure_path": "YwpL0BVxts/tables/tables_6_1.jpg", "caption": "Table 1: Main results on CIFAR-10 dataset. P-20% denotes model pruning with a pruning rate p = 0.2; Adv-0.001 represents adversarial training with budget = 0.001. Fingerprint detection rate in bold indicates the best performance. For positive models, a higher fingerprint detection rate is preferred, suggesting better ability to verify IP infringement. In contrast, negative models are expected to yield a lower detection rate, avoiding false verification.", "description": "This table presents the main experimental results on the CIFAR-10 dataset.  It compares the performance of ADV-TRA against four existing model fingerprinting techniques (IPGuard, CAE, UAP, Ours) under various removal attacks (model pruning with different pruning rates, adversarial training with different budgets, and fine-tuning with different layers and training methods). The table shows the accuracy, mutation rate (rmut), and fingerprint detection rate for both positive (infringing) and negative (innocent) models, highlighting the superior performance of the proposed ADV-TRA in accurately distinguishing between them.", "section": "5.1 Main Performance"}, {"figure_path": "YwpL0BVxts/tables/tables_7_1.jpg", "caption": "Table 1: Main results on CIFAR-10 dataset. P-20% denotes model pruning with a pruning rate p = 0.2; Adv-0.001 represents adversarial training with budget = 0.001. Fingerprint detection rate in bold indicates the best performance. For positive models, a higher fingerprint detection rate is preferred, suggesting better ability to verify IP infringement. In contrast, negative models are expected to yield a lower detection rate, avoiding false verification.", "description": "This table presents the main experimental results on the CIFAR-10 dataset, comparing the performance of ADV-TRA against four existing fingerprinting methods under various removal attacks (model pruning and adversarial training).  It shows fingerprint detection rates for both positive (infringing) and negative (innocent) models.  Higher detection rates for positive models and lower rates for negative models indicate better performance in accurately identifying IP infringement.", "section": "5.1 Main Performance"}, {"figure_path": "YwpL0BVxts/tables/tables_8_1.jpg", "caption": "Table 1: Main results on CIFAR-10 dataset. P-20% denotes model pruning with a pruning rate p = 0.2; Adv-0.001 represents adversarial training with budget = 0.001. Fingerprint detection rate in bold indicates the best performance. For positive models, a higher fingerprint detection rate is preferred, suggesting better ability to verify IP infringement. In contrast, negative models are expected to yield a lower detection rate, avoiding false verification.", "description": "This table presents the main results of the CIFAR-10 experiments, comparing ADV-TRA's performance against other methods under various removal attacks (pruning and adversarial training).  It shows the fingerprint detection rates for both positive (infringing) and negative (innocent) models, highlighting ADV-TRA's superior ability to distinguish between them with high accuracy and low false positives.", "section": "5.1 Main Performance"}, {"figure_path": "YwpL0BVxts/tables/tables_20_1.jpg", "caption": "Table 1: Main results on CIFAR-10 dataset. P-20% denotes model pruning with a pruning rate p = 0.2; Adv-0.001 represents adversarial training with budget = 0.001. Fingerprint detection rate in bold indicates the best performance. For positive models, a higher fingerprint detection rate is preferred, suggesting better ability to verify IP infringement. In contrast, negative models are expected to yield a lower detection rate, avoiding false verification.", "description": "This table presents the main experimental results on the CIFAR-10 dataset, comparing the performance of ADV-TRA against other state-of-the-art fingerprinting methods under various removal attacks.  It shows fingerprint detection rates for both positive (infringing) and negative (innocent) models.  Higher detection rates for positive models and lower rates for negative models indicate better performance.", "section": "5.1 Main Performance"}, {"figure_path": "YwpL0BVxts/tables/tables_21_1.jpg", "caption": "Table 1: Main results on CIFAR-10 dataset. P-20% denotes model pruning with a pruning rate p = 0.2; Adv-0.001 represents adversarial training with budget = 0.001. Fingerprint detection rate in bold indicates the best performance. For positive models, a higher fingerprint detection rate is preferred, suggesting better ability to verify IP infringement. In contrast, negative models are expected to yield a lower detection rate, avoiding false verification.", "description": "This table presents the main experimental results on the CIFAR-10 dataset, comparing the performance of ADV-TRA against other state-of-the-art model fingerprinting methods under various removal attacks.  The results are shown for both positive (infringing) models and negative (innocent) models, highlighting the fingerprint detection rates, accuracy, and mutation rate (Tmut). The table demonstrates ADV-TRA's superior ability to accurately distinguish between infringing and innocent models, minimizing both false positives and false negatives.", "section": "5.1 Main Performance"}, {"figure_path": "YwpL0BVxts/tables/tables_21_2.jpg", "caption": "Table 1: Main results on CIFAR-10 dataset. P-20% denotes model pruning with a pruning rate p = 0.2; Adv-0.001 represents adversarial training with budget = 0.001. Fingerprint detection rate in bold indicates the best performance. For positive models, a higher fingerprint detection rate is preferred, suggesting better ability to verify IP infringement. In contrast, negative models are expected to yield a lower detection rate, avoiding false verification.", "description": "This table presents the main experimental results on the CIFAR-10 dataset, comparing the performance of ADV-TRA with other state-of-the-art model fingerprinting methods under various removal attacks (model pruning and adversarial training).  The table shows the fingerprint detection rate for both positive (infringing) and negative (innocent) models.  A higher detection rate is desired for positive models, and a lower detection rate is desired for negative models to avoid false positives.  The results demonstrate ADV-TRA\u2019s superior performance in distinguishing between infringing and innocent models.", "section": "5.1 Main Performance"}, {"figure_path": "YwpL0BVxts/tables/tables_22_1.jpg", "caption": "Table 1: Main results on CIFAR-10 dataset. P-20% denotes model pruning with a pruning rate p = 0.2; Adv-0.001 represents adversarial training with budget = 0.001. Fingerprint detection rate in bold indicates the best performance. For positive models, a higher fingerprint detection rate is preferred, suggesting better ability to verify IP infringement. In contrast, negative models are expected to yield a lower detection rate, avoiding false verification.", "description": "This table presents the main results of the experiments conducted on the CIFAR-10 dataset.  It compares the performance of ADV-TRA against other state-of-the-art model fingerprinting methods across various removal attacks (pruning, adversarial training, and fine-tuning). The table shows fingerprint detection rates for both positive (models derived from the source model) and negative (unrelated models) models under different attack scenarios, demonstrating the effectiveness of ADV-TRA in correctly identifying infringing vs. innocent models. ", "section": "5.1 Main Performance"}]