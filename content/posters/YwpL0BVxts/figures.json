[{"figure_path": "YwpL0BVxts/figures/figures_1_1.jpg", "caption": "Figure 1: Comparing single-point fingerprinting samples and our adversarial trajectories. As can be seen, when the decision boundary alters (from the solid black line to the dashed red line), (a) a portion of single-point fingerprinting samples near the boundary become invalid, while (b) the majority of samples in the trajectories remain effective.", "description": "This figure compares single-point fingerprinting with the proposed trajectory fingerprinting method.  When the decision boundary of a model changes (e.g., due to a removal attack), single-point samples near the boundary become invalid and lose their effectiveness for model verification. However, the trajectory-based approach is more robust; even with boundary alterations, the majority of the trajectory samples remain effective because they represent a range of adversarial examples across the boundary rather than single points.", "section": "1 Introduction"}, {"figure_path": "YwpL0BVxts/figures/figures_2_1.jpg", "caption": "Figure 2: Illustration of model stealing and verification.", "description": "This figure illustrates the process of model stealing and verification. The model owner trains a source model and deploys it as a cloud service or client-sided software. The attacker attempts to steal the source model in either black-box or white-box ways. Then, the attacker can leverage removal attacks to modify the model to evade the IP infringement detection. The model owner verifies the ownership of a suspect model by querying it with a set of fingerprinting samples. Based on the output results, the owner selects a testing metric and computes it to make the final judgment.", "section": "3 Problem Formation"}, {"figure_path": "YwpL0BVxts/figures/figures_4_1.jpg", "caption": "Figure 3: Exemplary illustration of ADV-TRA pipeline (the length of Tint 1 = 3; the length of Tsurf is 2lm, exclusive of co). A darker color of the trajectory sample indicates a higher level of adversarial strength towards the target class.", "description": "This figure illustrates the workflow of the proposed ADV-TRA model for fingerprinting DNNs.  It shows the process of generating adversarial trajectories, which starts with a base sample from one class and progressively moves toward another class, probing the decision boundary and creating fixed-length trajectories with dynamically adjusted step sizes. This results in a surface trajectory, a series of fixed-length trajectories spanning across multiple classes to capture global features. In the verification phase, this surface trajectory is used to determine if a suspect model is stolen from the source model by calculating the mutation rate.", "section": "4 Design of ADV-TRA"}, {"figure_path": "YwpL0BVxts/figures/figures_7_1.jpg", "caption": "Figure 4: The ROC curve (a) and the distribution (b) of fingerprint detection rate of different suspect models on CIFAR-10.", "description": "This figure shows the performance comparison of different fingerprinting methods on the CIFAR-10 dataset. The left plot (a) is a ROC curve showing the true positive rate (TPR) against the false positive rate (FPR) for each method.  The right plot (b) is a box plot that shows the distribution of fingerprint detection rates for positive and negative models for each method. The results demonstrate that ADV-TRA achieves a perfect AUC (Area Under the Curve) of 1.0, significantly outperforming other methods in distinguishing between positive (infringing) and negative (innocent) models.", "section": "5 Experiments"}, {"figure_path": "YwpL0BVxts/figures/figures_7_2.jpg", "caption": "Figure 5: Fingerprint detection rate vs. fine-tuning epochs. The gray area represents the range of fingerprint detection rate for negative models.", "description": "This figure shows the relationship between fingerprint detection rate and the number of fine-tuning epochs for both positive and negative models.  The detection rate for positive models (those subjected to fine-tuning attacks) is shown for four different fine-tuning strategies (FTLL, FTAL, RTLL, RTAL). The gray area represents the range of detection rates observed for negative models. This visualization helps in assessing the robustness of the proposed ADV-TRA fingerprinting method against fine-tuning attacks, demonstrating its effectiveness in distinguishing between genuine and fraudulent models.", "section": "5 Experiments"}, {"figure_path": "YwpL0BVxts/figures/figures_8_1.jpg", "caption": "Figure 8: Visualization for the decision surface under various removal attacks. Each color represents a class.", "description": "This figure visualizes the decision boundaries of a model under various removal attacks such as fine-tuning, pruning, and adversarial training. Each color represents a class, and changes in the decision boundary due to different attacks are clearly illustrated. The figure shows how the decision surface is affected by each attack, providing visual evidence for the effectiveness of different removal attacks in invalidating the original fingerprints.", "section": "5 Experiments"}, {"figure_path": "YwpL0BVxts/figures/figures_16_1.jpg", "caption": "Figure 8: Visualization for the decision surface under various removal attacks. Each color represents a class.", "description": "This figure visualizes the decision boundaries of a model under various removal attacks. Each color represents a different class.  The figure shows how different attacks (adversarial training with varying perturbation budgets, fine-tuning, retraining, and pruning) affect the decision boundary. The goal is to illustrate how the fingerprinting method proposed in the paper, ADV-TRA, is robust against these attacks, maintaining a consistent and distinguishable decision surface. The 'source' image shows the original decision surface, while the others show how the decision boundaries change after each attack.", "section": "5 Experiments"}, {"figure_path": "YwpL0BVxts/figures/figures_17_1.jpg", "caption": "Figure 9: T1%F and T10%F with the varying number of classes spanned by trajectories. Note that when the number of classes spanned by a trajectory is two, it is equivalent to a bilateral trajectory as defined in Section 4.1 in the main text.", "description": "This figure shows the impact of varying the number of classes spanned by the trajectories on the performance metrics T1%F and T10%F.  The results are shown for CIFAR-10, CIFAR-100, and ImageNet datasets.  A trajectory spanning only two classes is equivalent to a bilateral trajectory.  Increasing the number of classes generally improves performance, though the effect is less pronounced on ImageNet, likely due to the greater complexity of the decision boundary in datasets with more classes.", "section": "5.2 Robustness Against Removal Attacks"}, {"figure_path": "YwpL0BVxts/figures/figures_18_1.jpg", "caption": "Figure 10: The distribution and AUC value of fingerprint detection rate for two types of suspect models under different trajectory lengths. Length=1 corresponds to the single-point fingerprinting method. We choose UAP as the baseline in view of its excellent performance.", "description": "This figure shows the performance of ADV-TRA compared to a state-of-the-art baseline (UAP) when varying the length of the adversarial trajectories used for fingerprinting.  The box plots illustrate the distribution of detection rates for positive (legitimate) and negative (illegitimate) models.  The red line shows the AUC (Area Under the Curve) for ADV-TRA, highlighting its superior performance, particularly for longer trajectories (40-160). Shorter trajectories perform similarly to or worse than UAP.", "section": "5.1 Main Performance"}, {"figure_path": "YwpL0BVxts/figures/figures_18_2.jpg", "caption": "Figure 11: Performance over different brake factor  for various trajectory lengths.", "description": "This figure shows the performance of ADV-TRA model with different brake factors and trajectory lengths. The brake factor controls the proportional relationship between the step sizes of two adjacent steps in the trajectory, while the trajectory length determines the number of samples in the trajectory. The results are shown in terms of AUC (Area Under the Curve) for CIFAR-100 and ImageNet datasets, illustrating how the combination of these two hyperparameters affects the model's ability to distinguish between positive and negative models.", "section": "5.2 Robustness Against Removal Attacks"}, {"figure_path": "YwpL0BVxts/figures/figures_19_1.jpg", "caption": "Figure 12: t-SNE visualization of the adversarial trajectory. It depicts an adversarial trajectory traversing four classes starting from a base sample (red), where larger points denote the first samples crossing the decision boundary of a new class. We sample a base sample from class 0 and guide it through class 1, 2, and 3.", "description": "This figure shows a t-SNE visualization of an adversarial trajectory generated by ADV-TRA.  The trajectory starts at a base sample (red) and progressively moves through four different classes (blue, green, orange). The size of the points indicates the proximity to the decision boundary of each class, with larger points marking the transition to a new class. The trajectory demonstrates ADV-TRA's ability to generate a smooth, continuous path through the decision boundaries of multiple classes, which is more robust to changes in those boundaries compared to single-point fingerprinting methods.", "section": "4.1 Trajectory Generation"}]