[{"figure_path": "oMHpejyGdx/tables/tables_6_1.jpg", "caption": "Table 1: Comparison with other adversarial perturbation methods on the face generation task (including Celeb-HQ and VGGFace2 datasets, training prompt \"a photo of sks person\") and style imitation task (including Wikiart dataset, training prompt \"a sks painting\") using ten different test prompts, where the reported metric values are the average across these ten test prompts.", "description": "This table presents a comparison of different adversarial perturbation methods (AdvDM, Anti-DB, IAdvDM, and PAP) on three datasets (Celeb-HQ, VGGFace2, and Wikiart) for face generation and style imitation tasks.  For each dataset and method, the table shows the average values across ten different test prompts for six metrics: FID, CLIP-I, LPIPS, LAION, BRISQUE, and CLIP.  Higher FID and BRISQUE values indicate worse performance, while lower values for the remaining metrics indicate better performance. This table highlights the performance of the proposed PAP method relative to existing methods.", "section": "4.2 Comparison with State-of-the-Art Methods"}, {"figure_path": "oMHpejyGdx/tables/tables_7_1.jpg", "caption": "Table 1: Comparison with other adversarial perturbation methods on the face generation task (including Celeb-HQ and VGGFace2 datasets, training prompt \"a photo of sks person\") and style imitation task (including Wikiart dataset, training prompt \"a sks painting\") using ten different test prompts, where the reported metric values are the average across these ten test prompts.", "description": "This table presents a comparison of the proposed PAP method against several other state-of-the-art adversarial perturbation methods.  The comparison is done across three different datasets (Celeb-HQ, VGGFace2, and WikiArt) and two different tasks (face generation and style imitation).  For each dataset and task, the table shows the performance of each method on six different metrics: FID, CLIP-I, LPIPS, LAION, BRISQUE, and CLIP.  Ten different test prompts were used, and the table reports the average metric scores across those prompts.", "section": "4 Experiments"}, {"figure_path": "oMHpejyGdx/tables/tables_8_1.jpg", "caption": "Table 3: Results with the initial prompt \"\"", "description": "This table presents the results obtained when using an empty string as the initial prompt.  It highlights the decline in performance compared to the original PAP results, demonstrating the importance of the initial prompt in the parameter estimation and Hessian approximation.", "section": "4.2 Comparison with State-of-the-Art Methods"}, {"figure_path": "oMHpejyGdx/tables/tables_8_2.jpg", "caption": "Table 1: Comparison with other adversarial perturbation methods on the face generation task (including Celeb-HQ and VGGFace2 datasets, training prompt \"a photo of sks person\") and style imitation task (including Wikiart dataset, training prompt \"a sks painting\") using ten different test prompts, where the reported metric values are the average across these ten test prompts.", "description": "This table compares the performance of the proposed PAP method against existing methods (AdvDM, Anti-DB, IAdvDM) across three datasets (Celeb-HQ, VGGFace2, Wikiart) and two tasks (face generation and style imitation).  It evaluates the methods using six metrics: FID, CLIP-I, LPIPS, LAION, BRISQUE, and CLIP. The results shown are the average of the results from ten different test prompts to evaluate robustness to unseen prompts.", "section": "4.2 Comparison with State-of-the-Art Methods"}, {"figure_path": "oMHpejyGdx/tables/tables_9_1.jpg", "caption": "Table 5: Robustness of our method to different fine-tuning models.", "description": "This table presents the results of applying the proposed Prompt-Agnostic Adversarial Perturbation (PAP) method to different fine-tuning models, namely LoRA and Textual Inversion (TI).  It demonstrates the robustness of PAP across various customization techniques.  The table shows that the PAP method is effective in protecting images even when the underlying model is fine-tuned using these methods. For each model and configuration (with and without PAP), the table reports six metrics: FID (Fr\u00e9chet Inception Distance), CLIP-I (CLIP Image-to-Image Similarity), LPIPS (Learned Perceptual Image Patch Similarity), LAION (LAION aesthetic predictor), BRISQUE (BRISQUE image quality assessor), and CLIP (CLIP text-to-image similarity). Higher FID, LPIPS, and BRISQUE scores indicate better protection, while lower CLIP-I, LAION, and CLIP scores suggest better defense performance. ", "section": "4.4 Extending Experiments"}, {"figure_path": "oMHpejyGdx/tables/tables_9_2.jpg", "caption": "Table 1: Comparison with other adversarial perturbation methods on the face generation task (including Celeb-HQ and VGGFace2 datasets, training prompt \"a photo of sks person\") and style imitation task (including Wikiart dataset, training prompt \"a sks painting\") using ten different test prompts, where the reported metric values are the average across these ten test prompts.", "description": "This table compares the performance of the proposed Prompt-Agnostic Adversarial Perturbation (PAP) method against other state-of-the-art methods for protecting images from adversarial attacks.  The comparison is done across three datasets (Celeb-HQ, VGGFace2, and WikiArt) and includes six evaluation metrics that assess image similarity, text-image coherence, and image quality. Ten different test prompts were used to evaluate the robustness of each method.", "section": "4.2 Comparison with State-of-the-Art Methods"}, {"figure_path": "oMHpejyGdx/tables/tables_22_1.jpg", "caption": "Table 1: Comparison with other adversarial perturbation methods on the face generation task (including Celeb-HQ and VGGFace2 datasets, training prompt \"a photo of sks person\") and style imitation task (including Wikiart dataset, training prompt \"a sks painting\") using ten different test prompts, where the reported metric values are the average across these ten test prompts.", "description": "This table presents a comparison of the proposed PAP method against other state-of-the-art adversarial perturbation methods (AdvDM, Anti-DB, IAdvDM).  The comparison is performed across three different datasets (Celeb-HQ, VGGFace2, Wikiart) and for both face generation and style imitation tasks.  Ten different test prompts were used for each dataset and the results represent the average across these prompts.  The metrics used for comparison include FID, CLIP-I, LPIPS, LAION, BRISQUE, and CLIP, providing a comprehensive evaluation of performance across image quality, similarity to the original images, and alignment with the provided prompts.", "section": "4.2 Comparison with State-of-the-Art Methods"}, {"figure_path": "oMHpejyGdx/tables/tables_25_1.jpg", "caption": "Table 1: Comparison with other adversarial perturbation methods on the face generation task (including Celeb-HQ and VGGFace2 datasets, training prompt \"a photo of sks person\") and style imitation task (including Wikiart dataset, training prompt \"a sks painting\") using ten different test prompts, where the reported metric values are the average across these ten test prompts.", "description": "This table compares the performance of the proposed PAP method against existing adversarial perturbation methods (AdvDM, Anti-DB, and IAdvDM) across three datasets (Celeb-HQ, VGGFace2, and Wikiart) and using ten different test prompts.  The metrics used are FID, CLIP-I, LPIPS, LAION, BRISQUE, and CLIP. Higher FID and BRISQUE values indicate worse performance, while lower values are better for the rest of the metrics. The results demonstrate the superior performance of PAP in terms of defense stability and generalization to unseen prompts.", "section": "4.2 Comparison with State-of-the-Art Methods"}, {"figure_path": "oMHpejyGdx/tables/tables_26_1.jpg", "caption": "Table 1: Comparison with other adversarial perturbation methods on the face generation task (including Celeb-HQ and VGGFace2 datasets, training prompt \"a photo of sks person\") and style imitation task (including Wikiart dataset, training prompt \"a sks painting\") using ten different test prompts, where the reported metric values are the average across these ten test prompts.", "description": "This table compares the performance of the proposed Prompt-Agnostic Adversarial Perturbation (PAP) method against several state-of-the-art methods for protecting images from adversarial attacks.  The comparison is done across three datasets (Celeb-HQ, VGGFace2, and WikiArt) and two task types (face privacy protection and artistic style protection).  Multiple metrics are used to evaluate the effectiveness of each method, including FID, CLIP-I, LPIPS, LAION, BRISQUE, and CLIP.  The results show that PAP consistently outperforms the other methods across all datasets and metrics.", "section": "4 Experiments"}, {"figure_path": "oMHpejyGdx/tables/tables_26_2.jpg", "caption": "Table 1: Comparison with other adversarial perturbation methods on the face generation task (including Celeb-HQ and VGGFace2 datasets, training prompt \"a photo of sks person\") and style imitation task (including Wikiart dataset, training prompt \"a sks painting\") using ten different test prompts, where the reported metric values are the average across these ten test prompts.", "description": "This table presents a comparison of the proposed PAP method with other state-of-the-art adversarial perturbation methods. The comparison is done on three different datasets (Celeb-HQ, VGGFace2, and Wikiart) and across ten different test prompts. The metrics used for comparison include FID, CLIP-I, LPIPS, LAION, BRISQUE, and CLIP. The results show that the PAP method outperforms other methods in most cases, demonstrating its effectiveness in protecting images from adversarial attacks.", "section": "4.2 Comparison with State-of-the-Art Methods"}, {"figure_path": "oMHpejyGdx/tables/tables_27_1.jpg", "caption": "Table 1: Comparison with other adversarial perturbation methods on the face generation task (including Celeb-HQ and VGGFace2 datasets, training prompt \"a photo of sks person\") and style imitation task (including Wikiart dataset, training prompt \"a sks painting\") using ten different test prompts, where the reported metric values are the average across these ten test prompts.", "description": "This table compares the performance of the proposed Prompt-Agnostic Adversarial Perturbation (PAP) method against existing methods (AdvDM, Anti-DreamBooth, and IAdvDM) across three datasets: Celeb-HQ, VGGFace2, and WikiArt.  For each dataset and method, six metrics are reported: FID, CLIP-I, LPIPS, LAION, BRISQUE, and CLIP. These metrics assess image-to-image similarity, text-to-image similarity, and image quality. The results show the average performance across ten different test prompts.", "section": "4.2 Comparison with State-of-the-Art Methods"}, {"figure_path": "oMHpejyGdx/tables/tables_27_2.jpg", "caption": "Table 1: Comparison with other adversarial perturbation methods on the face generation task (including Celeb-HQ and VGGFace2 datasets, training prompt \"a photo of sks person\") and style imitation task (including Wikiart dataset, training prompt \"a sks painting\") using ten different test prompts, where the reported metric values are the average across these ten test prompts.", "description": "This table compares the performance of the proposed PAP method against three other state-of-the-art adversarial perturbation methods (AdvDM, Anti-DB, and IAdvDM) across three different datasets (Celeb-HQ, VGGFace2, and Wikiart).  The results are averaged over ten different test prompts for each method and dataset.  Metrics include FID (higher is better), CLIP-I (lower is better), LPIPS (lower is better), LAION (lower is better), BRISQUE (higher is better), and CLIP (lower is better), assessing image and text similarity, and overall image quality.", "section": "4.2 Comparison with State-of-the-Art Methods"}, {"figure_path": "oMHpejyGdx/tables/tables_28_1.jpg", "caption": "Table 1: Comparison with other adversarial perturbation methods on the face generation task (including Celeb-HQ and VGGFace2 datasets, training prompt \"a photo of sks person\") and style imitation task (including Wikiart dataset, training prompt \"a sks painting\") using ten different test prompts, where the reported metric values are the average across these ten test prompts.", "description": "This table compares the performance of the proposed PAP method against other state-of-the-art adversarial perturbation methods (AdvDM, Anti-DB, IAdvDM) on three datasets (Celeb-HQ, VGGFace2, WikiArt).  The comparison is performed across six metrics measuring image and text-image similarity, image quality, and visual aesthetics. Each dataset uses a different task (face generation or style imitation), and results are averaged across ten different test prompts to assess the generalization capability of each method.  The \"Clean\" row represents the baseline performance without any adversarial perturbation.", "section": "4 Experiments"}, {"figure_path": "oMHpejyGdx/tables/tables_28_2.jpg", "caption": "Table 3: Results with the initial prompt \"\"", "description": "This table presents the results of the experiment when using the initial prompt \"\". It compares the performance of the model with different metrics (FID, CLIP-I, LPIPS, LAION, BRISQUE, CLIP) when using the initial prompt \"\" against using the original prompt. The results show that using the initial prompt results in a significant decline in performance compared to the original PAP.", "section": "4.2 Comparison with State-of-the-Art Methods"}, {"figure_path": "oMHpejyGdx/tables/tables_29_1.jpg", "caption": "Table 1: Comparison with other adversarial perturbation methods on the face generation task (including Celeb-HQ and VGGFace2 datasets, training prompt \"a photo of sks person\") and style imitation task (including Wikiart dataset, training prompt \"a sks painting\") using ten different test prompts, where the reported metric values are the average across these ten test prompts.", "description": "This table presents a comparison of the proposed PAP method with several other state-of-the-art adversarial perturbation methods.  The comparison is done across three different datasets (Celeb-HQ, VGGFace2, and Wikiart) and two different tasks (face generation and style imitation).  For each dataset and task, the table shows the average performance across ten different test prompts for several metrics evaluating image similarity, text-image similarity, and image quality. This allows for a comprehensive comparison of the methods under various conditions and provides insights into the robustness and generalization capabilities of each approach.", "section": "4.2 Comparison with State-of-the-Art Methods"}, {"figure_path": "oMHpejyGdx/tables/tables_29_2.jpg", "caption": "Table 1: Comparison with other adversarial perturbation methods on the face generation task (including Celeb-HQ and VGGFace2 datasets, training prompt \"a photo of sks person\") and style imitation task (including Wikiart dataset, training prompt \"a sks painting\") using ten different test prompts, where the reported metric values are the average across these ten test prompts.", "description": "This table compares the performance of the proposed Prompt-Agnostic Adversarial Perturbation (PAP) method against several other state-of-the-art methods for protecting images from adversarial attacks.  The comparison is done across three datasets (Celeb-HQ, VGGFace2, and Wikiart) and six metrics (FID, CLIP-I, LPIPS, LAION, BRISQUE, and CLIP). The results show the average performance across 10 different test prompts for each method. This provides a comprehensive evaluation of the methods' robustness to various prompts and datasets.", "section": "4.2 Comparison with State-of-the-Art Methods"}]